{"id": "2505.05583", "pdf": "https://arxiv.org/pdf/2505.05583", "abs": "https://arxiv.org/abs/2505.05583", "authors": ["Qianbo Zang", "Christophe Zgrzendek", "Igor Tchappi", "Afshin Khadangi", "Johannes Sedlmeir"], "title": "KG-HTC: Integrating Knowledge Graphs into LLMs for Effective Zero-shot Hierarchical Text Classification", "categories": ["cs.CL"], "comment": null, "summary": "Hierarchical Text Classification (HTC) involves assigning documents to labels\norganized within a taxonomy. Most previous research on HTC has focused on\nsupervised methods. However, in real-world scenarios, employing supervised HTC\ncan be challenging due to a lack of annotated data. Moreover, HTC often faces\nissues with large label spaces and long-tail distributions. In this work, we\npresent Knowledge Graphs for zero-shot Hierarchical Text Classification\n(KG-HTC), which aims to address these challenges of HTC in applications by\nintegrating knowledge graphs with Large Language Models (LLMs) to provide\nstructured semantic context during classification. Our method retrieves\nrelevant subgraphs from knowledge graphs related to the input text using a\nRetrieval-Augmented Generation (RAG) approach. Our KG-HTC can enhance LLMs to\nunderstand label semantics at various hierarchy levels. We evaluate KG-HTC on\nthree open-source HTC datasets: WoS, DBpedia, and Amazon. Our experimental\nresults show that KG-HTC significantly outperforms three baselines in the\nstrict zero-shot setting, particularly achieving substantial improvements at\ndeeper levels of the hierarchy. This evaluation demonstrates the effectiveness\nof incorporating structured knowledge into LLMs to address HTC's challenges in\nlarge label spaces and long-tailed label distributions. Our code is available\nat: https://github.com/QianboZang/KG-HTC."}
{"id": "2505.05648", "pdf": "https://arxiv.org/pdf/2505.05648", "abs": "https://arxiv.org/abs/2505.05648", "authors": ["Abdelrahman Abouelenin", "Mohamed Abdelrehim", "Raffy Fahim", "Amr Hendy", "Mohamed Afify"], "title": "Privacy-Preserving Transformers: SwiftKey's Differential Privacy Implementation", "categories": ["cs.CL", "cs.CR", "cs.LG"], "comment": null, "summary": "In this paper we train a transformer using differential privacy (DP) for\nlanguage modeling in SwiftKey. We run multiple experiments to balance the\ntrade-off between the model size, run-time speed and accuracy. We show that we\nget small and consistent gains in the next-word-prediction and accuracy with\ngraceful increase in memory and speed compared to the production GRU. This is\nobtained by scaling down a GPT2 architecture to fit the required size and a two\nstage training process that builds a seed model on general data and DP\nfinetunes it on typing data. The transformer is integrated using ONNX offering\nboth flexibility and efficiency."}
{"id": "2505.05687", "pdf": "https://arxiv.org/pdf/2505.05687", "abs": "https://arxiv.org/abs/2505.05687", "authors": ["Cindy Kim", "Daniela Puchall", "Jiangyi Liang", "Jiwon Kim"], "title": "Exploration of COVID-19 Discourse on Twitter: American Politician Edition", "categories": ["cs.CL"], "comment": null, "summary": "The advent of the COVID-19 pandemic has undoubtedly affected the political\nscene worldwide and the introduction of new terminology and public opinions\nregarding the virus has further polarized partisan stances. Using a collection\nof tweets gathered from leading American political figures online (Republican\nand Democratic), we explored the partisan differences in approach, response,\nand attitude towards handling the international crisis. Implementation of the\nbag-of-words, bigram, and TF-IDF models was used to identify and analyze\nkeywords, topics, and overall sentiments from each party. Results suggest that\nDemocrats are more concerned with the casualties of the pandemic, and give more\nmedical precautions and recommendations to the public whereas Republicans are\nmore invested in political responsibilities such as keeping the public updated\nthrough media and carefully watching the progress of the virus. We propose a\nsystematic approach to predict and distinguish a tweet's political stance (left\nor right leaning) based on its COVID-19 related terms using different\nclassification algorithms on different language models."}
{"id": "2505.05704", "pdf": "https://arxiv.org/pdf/2505.05704", "abs": "https://arxiv.org/abs/2505.05704", "authors": ["Julia Shuieh", "Prasann Singhal", "Apaar Shanker", "John Heyer", "George Pu", "Samuel Denton"], "title": "Assessing Robustness to Spurious Correlations in Post-Training Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "ICLR '25 Workshop on Spurious Correlation and Shortcut Learning", "summary": "Supervised and preference-based fine-tuning techniques have become popular\nfor aligning large language models (LLMs) with user intent and correctness\ncriteria. However, real-world training data often exhibits spurious\ncorrelations -- arising from biases, dataset artifacts, or other \"shortcut\"\nfeatures -- that can compromise a model's performance or generalization. In\nthis paper, we systematically evaluate three post-training algorithms --\nSupervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and KTO\n(Kahneman-Tversky Optimization) -- across a diverse set of synthetic tasks and\nspuriousness conditions. Our tasks span mathematical reasoning, constrained\ninstruction-following, and document-grounded question answering. We vary the\ndegree of spurious correlation (10% vs. 90%) and investigate two forms of\nartifacts: \"Feature Ambiguity\" and \"Distributional Narrowness.\" Our results\nshow that the models often but not always degrade under higher spuriousness.\nThe preference-based methods (DPO/KTO) can demonstrate relative robustness in\nmathematical reasoning tasks. By contrast, SFT maintains stronger performance\nin complex, context-intensive tasks. These findings highlight that no single\npost-training strategy universally outperforms in all scenarios; the best\nchoice depends on the type of target task and the nature of spurious\ncorrelations."}
{"id": "2505.05654", "pdf": "https://arxiv.org/pdf/2505.05654", "abs": "https://arxiv.org/abs/2505.05654", "authors": ["John Vinyard"], "title": "Toward a Sparse and Interpretable Audio Codec", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Most widely-used modern audio codecs, such as Ogg Vorbis and MP3, as well as\nmore recent \"neural\" codecs like Meta's Encodec or the Descript Audio Codec are\nbased on block-coding; audio is divided into overlapping, fixed-size \"frames\"\nwhich are then compressed. While they often yield excellent reproductions and\ncan be used for downstream tasks such as text-to-audio, they do not produce an\nintuitive, directly-interpretable representation. In this work, we introduce a\nproof-of-concept audio encoder that represents audio as a sparse set of events\nand their times-of-occurrence. Rudimentary physics-based assumptions are used\nto model attack and the physical resonance of both the instrument being played\nand the room in which a performance occurs, hopefully encouraging a sparse,\nparsimonious, and easy-to-interpret representation."}
{"id": "2505.05657", "pdf": "https://arxiv.org/pdf/2505.05657", "abs": "https://arxiv.org/abs/2505.05657", "authors": ["Zhongweiyang Xu", "Xulin Fan", "Zhong-Qiu Wang", "Xilin Jiang", "Romit Roy Choudhury"], "title": "Unsupervised Blind Speech Separation with a Diffusion Prior", "categories": ["eess.AS", "cs.LG", "cs.MM", "cs.SD", "eess.SP"], "comment": "Paper Accepted at ICML2025 Demo:\n  https://arraydps.github.io/ArrayDPSDemo/ Code:\n  https://github.com/ArrayDPS/ArrayDPS", "summary": "Blind Speech Separation (BSS) aims to separate multiple speech sources from\naudio mixtures recorded by a microphone array. The problem is challenging\nbecause it is a blind inverse problem, i.e., the microphone array geometry, the\nroom impulse response (RIR), and the speech sources, are all unknown. We\npropose ArrayDPS to solve the BSS problem in an unsupervised, array-agnostic,\nand generative manner. The core idea builds on diffusion posterior sampling\n(DPS), but unlike DPS where the likelihood is tractable, ArrayDPS must\napproximate the likelihood by formulating a separate optimization problem. The\nsolution to the optimization approximates room acoustics and the relative\ntransfer functions between microphones. These approximations, along with the\ndiffusion priors, iterate through the ArrayDPS sampling process and ultimately\nyield separated voice sources. We only need a simple single-speaker speech\ndiffusion model as a prior along with the mixtures recorded at the microphones;\nno microphone array information is necessary. Evaluation results show that\nArrayDPS outperforms all baseline unsupervised methods while being comparable\nto supervised methods in terms of SDR. Audio demos are provided at:\nhttps://arraydps.github.io/ArrayDPSDemo/."}
{"id": "2505.05541", "pdf": "https://arxiv.org/pdf/2505.05541", "abs": "https://arxiv.org/abs/2505.05541", "authors": ["Markov Grey", "Charbel-Raphaël Segerie"], "title": "Safety by Measurement: A Systematic Literature Review of AI Safety Evaluation Methods", "categories": ["cs.AI"], "comment": null, "summary": "As frontier AI systems advance toward transformative capabilities, we need a\nparallel transformation in how we measure and evaluate these systems to ensure\nsafety and inform governance. While benchmarks have been the primary method for\nestimating model capabilities, they often fail to establish true upper bounds\nor predict deployment behavior. This literature review consolidates the rapidly\nevolving field of AI safety evaluations, proposing a systematic taxonomy around\nthree dimensions: what properties we measure, how we measure them, and how\nthese measurements integrate into frameworks. We show how evaluations go beyond\nbenchmarks by measuring what models can do when pushed to the limit\n(capabilities), the behavioral tendencies exhibited by default (propensities),\nand whether our safety measures remain effective even when faced with\nsubversive adversarial AI (control). These properties are measured through\nbehavioral techniques like scaffolding, red teaming and supervised fine-tuning,\nalongside internal techniques such as representation analysis and mechanistic\ninterpretability. We provide deeper explanations of some safety-critical\ncapabilities like cybersecurity exploitation, deception, autonomous\nreplication, and situational awareness, alongside concerning propensities like\npower-seeking and scheming. The review explores how these evaluation methods\nintegrate into governance frameworks to translate results into concrete\ndevelopment decisions. We also highlight challenges to safety evaluations -\nproving absence of capabilities, potential model sandbagging, and incentives\nfor \"safetywashing\" - while identifying promising research directions. By\nsynthesizing scattered resources, this literature review aims to provide a\ncentral reference point for understanding AI safety evaluations."}
{"id": "2505.05940", "pdf": "https://arxiv.org/pdf/2505.05940", "abs": "https://arxiv.org/abs/2505.05940", "authors": ["Rodrigo Diaz", "Mark Sandler"], "title": "Fast Differentiable Modal Simulation of Non-linear Strings, Membranes, and Plates", "categories": ["cs.SD", "cs.LG", "eess.AS", "physics.comp-ph"], "comment": "accepted to DAFx 2025", "summary": "Modal methods for simulating vibrations of strings, membranes, and plates are\nwidely used in acoustics and physically informed audio synthesis. However,\ntraditional implementations, particularly for non-linear models like the von\nK\\'arm\\'an plate, are computationally demanding and lack differentiability,\nlimiting inverse modelling and real-time applications. We introduce a fast,\ndifferentiable, GPU-accelerated modal framework built with the JAX library,\nproviding efficient simulations and enabling gradient-based inverse modelling.\nBenchmarks show that our approach significantly outperforms CPU and GPU-based\nimplementations, particularly for simulations with many modes. Inverse\nmodelling experiments demonstrate that our approach can recover physical\nparameters, including tension, stiffness, and geometry, from both synthetic and\nexperimental data. Although fitting physical parameters is more sensitive to\ninitialisation compared to other methods, it provides greater interpretability\nand more compact parameterisation. The code is released as open source to\nsupport future research and applications in differentiable physical modelling\nand sound synthesis."}
{"id": "2505.05487", "pdf": "https://arxiv.org/pdf/2505.05487", "abs": "https://arxiv.org/abs/2505.05487", "authors": ["Shrinivas Pundlik", "Seonggyu Choe", "Patrick Baker", "Chen-Yuan Lee", "Naser Al-Madi", "Alex R. Bowers", "Gang Luo"], "title": "Data extraction and processing methods to aid the study of driving behaviors at intersections in naturalistic driving", "categories": ["cs.CV", "cs.RO"], "comment": "19 pages, 11 figures", "summary": "Naturalistic driving studies use devices in participants' own vehicles to\nrecord daily driving over many months. Due to diverse and extensive amounts of\ndata recorded, automated processing is necessary. This report describes methods\nto extract and characterize driver head scans at intersections from data\ncollected from an in-car recording system that logged vehicle speed, GPS\nlocation, scene videos, and cabin videos. Custom tools were developed to mark\nthe intersections, synchronize location and video data, and clip the cabin and\nscene videos for +/-100 meters from the intersection location. A\ncustom-developed head pose detection AI model for wide angle head turns was run\non the cabin videos to estimate the driver head pose, from which head scans >20\ndeg were computed in the horizontal direction. The scene videos were processed\nusing a YOLO object detection model to detect traffic lights, stop signs,\npedestrians, and other vehicles on the road. Turning maneuvers were\nindependently detected using vehicle self-motion patterns. Stop lines on the\nroad surface were detected using changing intensity patterns over time as the\nvehicle moved. The information obtained from processing the scene videos, along\nwith the speed data was used in a rule-based algorithm to infer the\nintersection type, maneuver, and bounds. We processed 190 intersections from 3\nvehicles driven in cities and suburban areas from Massachusetts and California.\nThe automated video processing algorithm correctly detected intersection\nsignage and maneuvers in 100% and 94% of instances, respectively. The median\n[IQR] error in detecting vehicle entry into the intersection was 1.1[0.4-4.9]\nmeters and 0.2[0.1-0.54] seconds. The median overlap between ground truth and\nestimated intersection bounds was 0.88[0.82-0.93]."}
{"id": "2505.05522", "pdf": "https://arxiv.org/pdf/2505.05522", "abs": "https://arxiv.org/abs/2505.05522", "authors": ["Luke Darlow", "Ciaran Regan", "Sebastian Risi", "Jeffrey Seely", "Llion Jones"], "title": "Continuous Thought Machines", "categories": ["cs.LG", "cs.AI"], "comment": "Technical report accompanied by online project page", "summary": "Biological brains demonstrate complex neural activity, where the timing and\ninterplay between neurons is critical to how brains process information. Most\ndeep learning architectures simplify neural activity by abstracting away\ntemporal dynamics. In this paper we challenge that paradigm. By incorporating\nneuron-level processing and synchronization, we can effectively reintroduce\nneural timing as a foundational element. We present the Continuous Thought\nMachine (CTM), a model designed to leverage neural dynamics as its core\nrepresentation. The CTM has two core innovations: (1) neuron-level temporal\nprocessing, where each neuron uses unique weight parameters to process a\nhistory of incoming signals; and (2) neural synchronization employed as a\nlatent representation. The CTM aims to strike a balance between oversimplified\nneuron abstractions that improve computational efficiency, and biological\nrealism. It operates at a level of abstraction that effectively captures\nessential temporal dynamics while remaining computationally tractable for deep\nlearning. We demonstrate the CTM's strong performance and versatility across a\nrange of challenging tasks, including ImageNet-1K classification, solving 2D\nmazes, sorting, parity computation, question-answering, and RL tasks. Beyond\ndisplaying rich internal representations and offering a natural avenue for\ninterpretation owing to its internal process, the CTM is able to perform tasks\nthat require complex sequential reasoning. The CTM can also leverage adaptive\ncompute, where it can stop earlier for simpler tasks, or keep computing when\nfaced with more challenging instances. The goal of this work is to share the\nCTM and its associated innovations, rather than pushing for new\nstate-of-the-art results. To that end, we believe the CTM represents a\nsignificant step toward developing more biologically plausible and powerful\nartificial intelligence systems."}
{"id": "2505.06200", "pdf": "https://arxiv.org/pdf/2505.06200", "abs": "https://arxiv.org/abs/2505.06200", "authors": ["Shinkyu Park", "Lucas C. D. Bezerra"], "title": "Robust Multi-Agent Decision-Making in Finite-Population Games", "categories": ["cs.MA", "cs.SY", "eess.SY"], "comment": null, "summary": "We study the robustness of an agent decision-making model in\nfinite-population games, with a particular focus on the Kullback-Leibler\nDivergence Regularized Learning (KLD-RL) model. Specifically, we examine how\nthe model's parameters influence the effects of various sources of noise and\nmodeling inaccuracies -- factors commonly encountered in engineering\napplications of population games -- on agents' decision-making. Our analysis\nprovides insights into how these parameters can be effectively tuned to\nmitigate such effects. Theoretical results are supported by numerical examples\nand simulation studies that validate the analysis and illustrate practical\nstrategies for parameter selection."}
{"id": "2505.05504", "pdf": "https://arxiv.org/pdf/2505.05504", "abs": "https://arxiv.org/abs/2505.05504", "authors": ["Xingyu Jiang", "Ning Gao", "Xiuhui Zhang", "Hongkun Dou", "Shaowen Fu", "Xiaoqing Zhong", "Hongjue Li", "Yue Deng"], "title": "Image Restoration via Multi-domain Learning", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Due to adverse atmospheric and imaging conditions, natural images suffer from\nvarious degradation phenomena. Consequently, image restoration has emerged as a\nkey solution and garnered substantial attention. Although recent Transformer\narchitectures have demonstrated impressive success across various restoration\ntasks, their considerable model complexity poses significant challenges for\nboth training and real-time deployment. Furthermore, instead of investigating\nthe commonalities among different degradations, most existing restoration\nmethods focus on modifying Transformer under limited restoration priors. In\nthis work, we first review various degradation phenomena under multi-domain\nperspective, identifying common priors. Then, we introduce a novel restoration\nframework, which integrates multi-domain learning into Transformer.\nSpecifically, in Token Mixer, we propose a Spatial-Wavelet-Fourier multi-domain\nstructure that facilitates local-region-global multi-receptive field modeling\nto replace vanilla self-attention. Additionally, in Feed-Forward Network, we\nincorporate multi-scale learning to fuse multi-domain features at different\nresolutions. Comprehensive experimental results across ten restoration tasks,\nsuch as dehazing, desnowing, motion deblurring, defocus deblurring, rain\nstreak/raindrop removal, cloud removal, shadow removal, underwater enhancement\nand low-light enhancement, demonstrate that our proposed model outperforms\nstate-of-the-art methods and achieves a favorable trade-off among restoration\nperformance, parameter size, computational cost and inference latency. The code\nis available at: https://github.com/deng-ai-lab/SWFormer."}
{"id": "2505.05714", "pdf": "https://arxiv.org/pdf/2505.05714", "abs": "https://arxiv.org/abs/2505.05714", "authors": ["Jinze Lv", "Jian Chen", "Zi Long", "Xianghua Fu", "Yin Chen"], "title": "TopicVD: A Topic-Based Dataset of Video-Guided Multimodal Machine Translation for Documentaries", "categories": ["cs.CL"], "comment": "NLDB 2025", "summary": "Most existing multimodal machine translation (MMT) datasets are predominantly\ncomposed of static images or short video clips, lacking extensive video data\nacross diverse domains and topics. As a result, they fail to meet the demands\nof real-world MMT tasks, such as documentary translation. In this study, we\ndeveloped TopicVD, a topic-based dataset for video-supported multimodal machine\ntranslation of documentaries, aiming to advance research in this field. We\ncollected video-subtitle pairs from documentaries and categorized them into\neight topics, such as economy and nature, to facilitate research on domain\nadaptation in video-guided MMT. Additionally, we preserved their contextual\ninformation to support research on leveraging the global context of\ndocumentaries in video-guided MMT. To better capture the shared semantics\nbetween text and video, we propose an MMT model based on a cross-modal\nbidirectional attention module. Extensive experiments on the TopicVD dataset\ndemonstrate that visual information consistently improves the performance of\nthe NMT model in documentary translation. However, the MMT model's performance\nsignificantly declines in out-of-domain scenarios, highlighting the need for\neffective domain adaptation methods. Additionally, experiments demonstrate that\nglobal context can effectively improve translation performance. % Dataset and\nour implementations are available at https://github.com/JinzeLv/TopicVD"}
{"id": "2505.06042", "pdf": "https://arxiv.org/pdf/2505.06042", "abs": "https://arxiv.org/abs/2505.06042", "authors": ["Christos Plachouras", "Emmanouil Benetos", "Johan Pauwels"], "title": "Learning Music Audio Representations With Limited Data", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "Presented at ICASSP 2025", "summary": "Large deep-learning models for music, including those focused on learning\ngeneral-purpose music audio representations, are often assumed to require\nsubstantial training data to achieve high performance. If true, this would pose\nchallenges in scenarios where audio data or annotations are scarce, such as for\nunderrepresented music traditions, non-popular genres, and personalized music\ncreation and listening. Understanding how these models behave in limited-data\nscenarios could be crucial for developing techniques to tackle them.\n  In this work, we investigate the behavior of several music audio\nrepresentation models under limited-data learning regimes. We consider music\nmodels with various architectures, training paradigms, and input durations, and\ntrain them on data collections ranging from 5 to 8,000 minutes long. We\nevaluate the learned representations on various music information retrieval\ntasks and analyze their robustness to noise. We show that, under certain\nconditions, representations from limited-data and even random models perform\ncomparably to ones from large-dataset models, though handcrafted features\noutperform all learned representations in some tasks."}
{"id": "2505.06107", "pdf": "https://arxiv.org/pdf/2505.06107", "abs": "https://arxiv.org/abs/2505.06107", "authors": ["Faeze Ghorbanpour", "Thiago Zordan Malaguth", "Aliakbar Akbaritabar"], "title": "Differentiating Emigration from Return Migration of Scholars Using Name-Based Nationality Detection Models", "categories": ["cs.DL", "cs.CL", "cs.MM"], "comment": "Accepted to appear @ ICWSM 2025. The link to the camera-ready paper\n  will be added soon", "summary": "Most web and digital trace data do not include information about an\nindividual's nationality due to privacy concerns. The lack of data on\nnationality can create challenges for migration research. It can lead to a\nleft-censoring issue since we are uncertain about the migrant's country of\norigin. Once we observe an emigration event, if we know the nationality, we can\ndifferentiate it from return migration. We propose methods to detect the\nnationality with the least available data, i.e., full names. We use the\ndetected nationality in comparison with the country of academic origin, which\nis a common approach in studying the migration of researchers. We gathered 2.6\nmillion unique name-nationality pairs from Wikipedia and categorized them into\nfamilies of nationalities with three granularity levels to use as our training\ndata. Using a character-based machine learning model, we achieved a weighted F1\nscore of 84% for the broadest and 67% for the most granular, country-level\ncategorization. In our empirical study, we used the trained and tested model to\nassign nationality to 8+ million scholars' full names in Scopus data. Our\nresults show that using the country of first publication as a proxy for\nnationality underestimates the size of return flows, especially for countries\nwith a more diverse academic workforce, such as the USA, Australia, and Canada.\nWe found that around 48% of emigration from the USA was return migration once\nwe used the country of name origin, in contrast to 33% based on academic\norigin. In the most recent period, 79% of scholars whose affiliation has\nconsistently changed from the USA to China, and are considered emigrants, have\nChinese names in contrast to 41% with a Chinese academic origin. Our proposed\nmethods for addressing left-censoring issues are beneficial for other research\nthat uses digital trace data to study migration."}
{"id": "2505.05602", "pdf": "https://arxiv.org/pdf/2505.05602", "abs": "https://arxiv.org/abs/2505.05602", "authors": ["Lennart Luettgau", "Harry Coppock", "Magda Dubois", "Christopher Summerfield", "Cozmin Ududec"], "title": "HiBayES: A Hierarchical Bayesian Modeling Framework for AI Evaluation Statistics", "categories": ["cs.AI", "stat.AP"], "comment": "23 pages, 9 figures", "summary": "As Large Language Models (LLMs) and other AI systems evolve, robustly\nestimating their capabilities from inherently stochastic outputs while\nsystematically quantifying uncertainty in these estimates becomes increasingly\nimportant. Further, advanced AI evaluations often have a nested hierarchical\nstructure, exhibit high levels of complexity, and come with high costs in\ntesting the most advanced AI systems. To address these challenges, we introduce\nHiBayES, a generalizable Hierarchical Bayesian modeling framework for AI\nEvaluation Statistics. HiBayES supports robust inferences in classical\nquestion-answer benchmarks and advanced agentic evaluations, particularly in\nlow-data scenarios (e.g., < 20 data points per evaluation). Built on\nGeneralized Linear Models (GLMs), Bayesian data analysis, and formal model\ncomparison, HiBayES provides principled uncertainty quantification and robust\nparameter estimation. This paper offers a comprehensive introduction to\nHiBayES, including illustrative examples, comparisons to conventional\nstatistical methods, and practical guidance for implementing multilevel\nBayesian GLMs. Additionally, we provide a HiBayES software package [4] (Beta\nversion) for out-of-the-box implementation."}
{"id": "2505.05159", "pdf": "https://arxiv.org/pdf/2505.05159", "abs": "https://arxiv.org/abs/2505.05159", "authors": ["Linhan Ma", "Dake Guo", "He Wang", "Jin Xu", "Lei Xie"], "title": "FlexSpeech: Towards Stable, Controllable and Expressive Text-to-Speech", "categories": ["eess.AS"], "comment": "10 pages, 5 figures", "summary": "Current speech generation research can be categorized into two primary\nclasses: non-autoregressive and autoregressive. The fundamental distinction\nbetween these approaches lies in the duration prediction strategy employed for\npredictable-length sequences. The NAR methods ensure stability in speech\ngeneration by explicitly and independently modeling the duration of each\nphonetic unit. Conversely, AR methods employ an autoregressive paradigm to\npredict the compressed speech token by implicitly modeling duration with Markov\nproperties. Although this approach improves prosody, it does not provide the\nstructural guarantees necessary for stability. To simultaneously address the\nissues of stability and naturalness in speech generation, we propose\nFlexSpeech, a stable, controllable, and expressive TTS model. The motivation\nbehind FlexSpeech is to incorporate Markov dependencies and preference\noptimization directly on the duration predictor to boost its naturalness while\nmaintaining explicit modeling of the phonetic units to ensure stability.\nSpecifically, we decompose the speech generation task into two components: an\nAR duration predictor and a NAR acoustic model. The acoustic model is trained\non a substantial amount of data to learn to render audio more stably, given\nreference audio prosody and phone durations. The duration predictor is\noptimized in a lightweight manner for different stylistic variations, thereby\nenabling rapid style transfer while maintaining a decoupled relationship with\nthe specified speaker timbre. Experimental results demonstrate that our\napproach achieves SOTA stability and naturalness in zero-shot TTS. More\nimportantly, when transferring to a specific stylistic domain, we can\naccomplish lightweight optimization of the duration module solely with about\n100 data samples, without the need to adjust the acoustic model, thereby\nenabling rapid and stable style transfer."}
{"id": "2505.05488", "pdf": "https://arxiv.org/pdf/2505.05488", "abs": "https://arxiv.org/abs/2505.05488", "authors": ["Yunfan Lu", "Xiaogang Xu", "Pengteng Li", "Yusheng Wang", "Yi Cui", "Huizai Yao", "Hui Xiong"], "title": "From Events to Enhancement: A Survey on Event-Based Imaging Technologies", "categories": ["cs.CV"], "comment": null, "summary": "Event cameras offering high dynamic range and low latency have emerged as\ndisruptive technologies in imaging. Despite growing research on leveraging\nthese benefits for different imaging tasks, a comprehensive study of recently\nadvances and challenges are still lacking. This limits the broader\nunderstanding of how to utilize events in universal imaging applications. In\nthis survey, we first introduce a physical model and the characteristics of\ndifferent event sensors as the foundation. Following this, we highlight the\nadvancement and interaction of image/video enhancement tasks with events.\nAdditionally, we explore advanced tasks, which capture richer light information\nwith events, \\eg~light field estimation, multi-view generation, and\nphotometric. Finally, we discuss new challenges and open questions offering a\nperspective for this rapidly evolving field. More continuously updated\nresources are at this link: https://github.com/yunfanLu/Awesome-Event-Imaging"}
{"id": "2505.05525", "pdf": "https://arxiv.org/pdf/2505.05525", "abs": "https://arxiv.org/abs/2505.05525", "authors": ["Selim Mecanna", "Aurore Loisy", "Christophe Eloy"], "title": "A critical assessment of reinforcement learning methods for microswimmer navigation in complex flows", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "Navigating in a fluid flow while being carried by it, using only information\naccessible from on-board sensors, is a problem commonly faced by small\nplanktonic organisms. It is also directly relevant to autonomous robots\ndeployed in the oceans. In the last ten years, the fluid mechanics community\nhas widely adopted reinforcement learning, often in the form of its simplest\nimplementations, to address this challenge. But it is unclear how good are the\nstrategies learned by these algorithms. In this paper, we perform a\nquantitative assessment of reinforcement learning methods applied to navigation\nin partially observable flows. We first introduce a well-posed problem of\ndirectional navigation for which a quasi-optimal policy is known analytically.\nWe then report on the poor performance and robustness of commonly used\nalgorithms (Q-Learning, Advantage Actor Critic) in flows regularly encountered\nin the literature: Taylor-Green vortices, Arnold-Beltrami-Childress flow, and\ntwo-dimensional turbulence. We show that they are vastly surpassed by PPO\n(Proximal Policy Optimization), a more advanced algorithm that has established\ndominance across a wide range of benchmarks in the reinforcement learning\ncommunity. In particular, our custom implementation of PPO matches the\ntheoretical quasi-optimal performance in turbulent flow and does so in a robust\nmanner. Reaching this result required the use of several additional techniques,\nsuch as vectorized environments and generalized advantage estimation, as well\nas hyperparameter optimization. This study demonstrates the importance of\nalgorithm selection, implementation details, and fine-tuning for discovering\ntruly smart autonomous navigation strategies in complex flows."}
{"id": "2505.05797", "pdf": "https://arxiv.org/pdf/2505.05797", "abs": "https://arxiv.org/abs/2505.05797", "authors": ["Lucia Stephanie B. Sibala", "Novy Aila B. Rivas", "Giovanna Fae R. Oguis"], "title": "Assessing the Dynamics of the Coffee Value Chain in Davao del Sur: An Agent-Based Modeling Approach", "categories": ["econ.GN", "cs.CY", "cs.MA", "q-fin.EC"], "comment": "56 pages, 12 figures, 7 tables", "summary": "The study investigates the coffee value chain dynamics in Davao del Sur using\nan agent-based model. Three main factors driving interactions among key players\nwere identified: trust, risk, and transaction costs. The model was constructed\nusing NetLogo 6.3.0, and data from a survey questionnaire collected three data\npoints from BACOFA members. Five cases were explored, with each scenario\nsimulated 1000 times. Findings suggest that producers often sell to the market\nrather than the cooperative due to higher prices. However, producers tend to\nprioritize trust in buyers and their risk attitude, leading to increased sales\nto the cooperative. The producer's risk attitude significantly influences their\ndecision-making, affecting performance outcomes such as loans, demand, and\nprice changes. All three factors play a role and exert varying impacts on the\nvalue chain. So, the stakeholders' decisions on prioritizing factors in\nimproving relationships depend on their priorities. Nonetheless, simulations\nshow that establishing a harmonious system benefiting all parties is possible.\nHowever, achieving this requires adjustments to demand, pricing, trust, and\nrisk attitudes of key players, which may not align with the preferences of some\nparties in reality."}
{"id": "2505.05509", "pdf": "https://arxiv.org/pdf/2505.05509", "abs": "https://arxiv.org/abs/2505.05509", "authors": ["Yi Liu", "Xinyi Liu", "Panwang Xia", "Qiong Wu", "Yi Wan", "Yongjun Zhang"], "title": "StereoINR: Cross-View Geometry Consistent Stereo Super Resolution with Implicit Neural Representation", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Stereo image super-resolution (SSR) aims to enhance high-resolution details\nby leveraging information from stereo image pairs. However, existing stereo\nsuper-resolution (SSR) upsampling methods (e.g., pixel shuffle) often overlook\ncross-view geometric consistency and are limited to fixed-scale upsampling. The\nkey issue is that previous upsampling methods use convolution to independently\nprocess deep features of different views, lacking cross-view and non-local\ninformation perception, making it difficult to select beneficial information\nfrom multi-view scenes adaptively. In this work, we propose Stereo Implicit\nNeural Representation (StereoINR), which innovatively models stereo image pairs\nas continuous implicit representations. This continuous representation breaks\nthrough the scale limitations, providing a unified solution for arbitrary-scale\nstereo super-resolution reconstruction of left-right views. Furthermore, by\nincorporating spatial warping and cross-attention mechanisms, StereoINR enables\neffective cross-view information fusion and achieves significant improvements\nin pixel-level geometric consistency. Extensive experiments across multiple\ndatasets show that StereoINR outperforms out-of-training-distribution scale\nupsampling and matches state-of-the-art SSR methods within\ntraining-distribution scales."}
{"id": "2505.05755", "pdf": "https://arxiv.org/pdf/2505.05755", "abs": "https://arxiv.org/abs/2505.05755", "authors": ["Dhruvesh Patel", "Aishwarya Sahoo", "Avinash Amballa", "Tahira Naseem", "Tim G. J. Rudner", "Andrew McCallum"], "title": "Insertion Language Models: Sequence Generation with Arbitrary-Position Insertions", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Autoregressive models (ARMs), which predict subsequent tokens one-by-one\n``from left to right,'' have achieved significant success across a wide range\nof sequence generation tasks. However, they struggle to accurately represent\nsequences that require satisfying sophisticated constraints or whose sequential\ndependencies are better addressed by out-of-order generation. Masked Diffusion\nModels (MDMs) address some of these limitations, but the process of unmasking\nmultiple tokens simultaneously in MDMs can introduce incoherences, and MDMs\ncannot handle arbitrary infilling constraints when the number of tokens to be\nfilled in is not known in advance. In this work, we introduce Insertion\nLanguage Models (ILMs), which learn to insert tokens at arbitrary positions in\na sequence -- that is, they select jointly both the position and the vocabulary\nelement to be inserted. By inserting tokens one at a time, ILMs can represent\nstrong dependencies between tokens, and their ability to generate sequences in\narbitrary order allows them to accurately model sequences where token\ndependencies do not follow a left-to-right sequential structure. To train ILMs,\nwe propose a tailored network parameterization and use a simple denoising\nobjective. Our empirical evaluation demonstrates that ILMs outperform both ARMs\nand MDMs on common planning tasks. Furthermore, we show that ILMs outperform\nMDMs and perform on par with ARMs in an unconditional text generation task\nwhile offering greater flexibility than MDMs in arbitrary-length text\ninfilling."}
{"id": "2305.03568", "pdf": "https://arxiv.org/pdf/2305.03568", "abs": "https://arxiv.org/abs/2305.03568", "authors": ["Samir Sadok", "Simon Leglaive", "Renaud Séguier"], "title": "A vector quantized masked autoencoder for audiovisual speech emotion recognition", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "comment": "13 pages, 6 figures, https://samsad35.github.io/VQ-MAE-AudioVisual/", "summary": "An important challenge in emotion recognition is to develop methods that can\nleverage unlabeled training data. In this paper, we propose the VQ-MAE-AV\nmodel, a self-supervised multimodal model that leverages masked autoencoders to\nlearn representations of audiovisual speech without labels. The model includes\nvector quantized variational autoencoders that compress raw audio and visual\nspeech data into discrete tokens. The audiovisual speech tokens are used to\ntrain a multimodal masked autoencoder that consists of an encoder-decoder\narchitecture with attention mechanisms. The model is designed to extract both\nlocal (i.e., at the frame level) and global (i.e., at the sequence level)\nrepresentations of audiovisual speech. During self-supervised pre-training, the\nVQ-MAE-AV model is trained on a large-scale unlabeled dataset of audiovisual\nspeech, for the task of reconstructing randomly masked audiovisual speech\ntokens and with a contrastive learning strategy. During this pre-training, the\nencoder learns to extract a representation of audiovisual speech that can be\nsubsequently leveraged for emotion recognition. During the supervised\nfine-tuning stage, a small classification model is trained on top of the\nVQ-MAE-AV encoder for an emotion recognition task. The proposed approach\nachieves state-of-the-art emotion recognition results across several datasets\nin both controlled and in-the-wild conditions."}
{"id": "2505.06149", "pdf": "https://arxiv.org/pdf/2505.06149", "abs": "https://arxiv.org/abs/2505.06149", "authors": ["Faeze Ghorbanpour", "Daryna Dementieva", "Alexander Fraser"], "title": "Can Prompting LLMs Unlock Hate Speech Detection across Languages? A Zero-shot and Few-shot Study", "categories": ["cs.CL", "cs.CY", "cs.MM"], "comment": null, "summary": "Despite growing interest in automated hate speech detection, most existing\napproaches overlook the linguistic diversity of online content. Multilingual\ninstruction-tuned large language models such as LLaMA, Aya, Qwen, and BloomZ\noffer promising capabilities across languages, but their effectiveness in\nidentifying hate speech through zero-shot and few-shot prompting remains\nunderexplored. This work evaluates LLM prompting-based detection across eight\nnon-English languages, utilizing several prompting techniques and comparing\nthem to fine-tuned encoder models. We show that while zero-shot and few-shot\nprompting lag behind fine-tuned encoder models on most of the real-world\nevaluation sets, they achieve better generalization on functional tests for\nhate speech detection. Our study also reveals that prompt design plays a\ncritical role, with each language often requiring customized prompting\ntechniques to maximize performance."}
{"id": "2505.05612", "pdf": "https://arxiv.org/pdf/2505.05612", "abs": "https://arxiv.org/abs/2505.05612", "authors": ["Qing Wang", "Yining Pan", "Minghao Zhou", "Zijia Tang", "Yanfei Wang", "Guangyu Wang", "Qianqian Song"], "title": "scDrugMap: Benchmarking Large Foundation Models for Drug Response Prediction", "categories": ["cs.AI", "cs.LG", "q-bio.QM"], "comment": "14 pages, 7 figures", "summary": "Drug resistance presents a major challenge in cancer therapy. Single cell\nprofiling offers insights into cellular heterogeneity, yet the application of\nlarge-scale foundation models for predicting drug response in single cell data\nremains underexplored. To address this, we developed scDrugMap, an integrated\nframework featuring both a Python command-line interface and a web server for\ndrug response prediction. scDrugMap evaluates a wide range of foundation\nmodels, including eight single-cell models and two large language models, using\na curated dataset of over 326,000 cells in the primary collection and 18,800\ncells in the validation set, spanning 36 datasets and diverse tissue and cancer\ntypes. We benchmarked model performance under pooled-data and cross-data\nevaluation settings, employing both layer freezing and Low-Rank Adaptation\n(LoRA) fine-tuning strategies. In the pooled-data scenario, scFoundation\nachieved the best performance, with mean F1 scores of 0.971 (layer freezing)\nand 0.947 (fine-tuning), outperforming the lowest-performing model by over 50%.\nIn the cross-data setting, UCE excelled post fine-tuning (mean F1: 0.774),\nwhile scGPT led in zero-shot learning (mean F1: 0.858). Overall, scDrugMap\nprovides the first large-scale benchmark of foundation models for drug response\nprediction in single-cell data and serves as a user-friendly, flexible platform\nfor advancing drug discovery and translational research."}
{"id": "2505.04457", "pdf": "https://arxiv.org/pdf/2505.04457", "abs": "https://arxiv.org/abs/2505.04457", "authors": ["Shigeki Karita", "Yuma Koizumi", "Heiga Zen", "Haruko Ishikawa", "Robin Scheibler", "Michiel Bacchiani"], "title": "Miipher-2: A Universal Speech Restoration Model for Million-Hour Scale Data Restoration", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": null, "summary": "Training data cleaning is a new application for generative model-based speech\nrestoration (SR). This paper introduces Miipher-2, an SR model designed for\nmillion-hour scale data, for training data cleaning for large-scale generative\nmodels like large language models. Key challenges addressed include\ngeneralization to unseen languages, operation without explicit conditioning\n(e.g., text, speaker ID), and computational efficiency. Miipher-2 utilizes a\nfrozen, pre-trained Universal Speech Model (USM), supporting over 300\nlanguages, as a robust, conditioning-free feature extractor. To optimize\nefficiency and minimize memory, Miipher-2 incorporates parallel adapters for\npredicting clean USM features from noisy inputs and employs the WaveFit neural\nvocoder for waveform synthesis. These components were trained on 3,000 hours of\nmulti-lingual, studio-quality recordings with augmented degradations, while USM\nparameters remained fixed. Experimental results demonstrate Miipher-2's\nsuperior or comparable performance to conventional SR models in\nword-error-rate, speaker similarity, and both objective and subjective sound\nquality scores across all tested languages. Miipher-2 operates efficiently on\nconsumer-grade accelerators, achieving a real-time factor of 0.0078, enabling\nthe processing of a million-hour speech dataset in approximately three days\nusing only 100 such accelerators."}
{"id": "2505.05491", "pdf": "https://arxiv.org/pdf/2505.05491", "abs": "https://arxiv.org/abs/2505.05491", "authors": ["TianYi Yu"], "title": "MDDFNet: Mamba-based Dynamic Dual Fusion Network for Traffic Sign Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The Detection of small objects, especially traffic signs, is a critical\nsub-task in object detection and autonomous driving. Despite signficant\nprogress in previous research, two main challenges remain. First, the issue of\nfeature extraction being too singular. Second, the detection process struggles\nto efectively handle objects of varying sizes or scales. These problems are\nalso prevalent in general object detection tasks. To address these challenges,\nwe propose a novel object detection network, Mamba-based Dynamic Dual Fusion\nNetwork (MDDFNet), for traffic sign detection. The network integrates a dynamic\ndual fusion module and a Mamba-based backbone to simultaneously tackle the\naforementioned issues. Specifically, the dynamic dual fusion module utilizes\nmultiple branches to consolidate various spatial and semantic information, thus\nenhancing feature diversity. The Mamba-based backbone leverages global feature\nfusion and local feature interaction, combining features in an adaptive manner\nto generate unique classification characteristics. Extensive experiments\nconducted on the TT100K (Tsinghua-Tencent 100K) datasets demonstrate that\nMDDFNet outperforms other state-of-the-art detectors, maintaining real-time\nprocessing capabilities of single-stage models while achieving superior\nperformance. This confirms the efectiveness of MDDFNet in detecting small\ntraffic signs."}
{"id": "2505.05527", "pdf": "https://arxiv.org/pdf/2505.05527", "abs": "https://arxiv.org/abs/2505.05527", "authors": ["Giovanni Perin", "Cesare Bidini", "Riccardo Mazzieri", "Michele Rossi"], "title": "ADMM-Based Training for Spiking Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.NE", "eess.SP", "math.OC"], "comment": "6 pages, 4 figures. Preprint submitted to IEEE MLSP 2025", "summary": "In recent years, spiking neural networks (SNNs) have gained momentum due to\ntheir high potential in time-series processing combined with minimal energy\nconsumption. However, they still lack a dedicated and efficient training\nalgorithm. The popular backpropagation with surrogate gradients, adapted from\nstochastic gradient descent (SGD)-derived algorithms, has several drawbacks\nwhen used as an optimizer for SNNs. Specifically, it suffers from low\nscalability and numerical imprecision. In this paper, we propose a novel SNN\ntraining method based on the alternating direction method of multipliers\n(ADMM). Our ADMM-based training aims to solve the problem of the SNN step\nfunction's non-differentiability. We formulate the problem, derive closed-form\nupdates, and empirically show the optimizer's convergence properties, great\npotential, and possible new research directions to improve the method in a\nsimulated proof-of-concept."}
{"id": "2505.05968", "pdf": "https://arxiv.org/pdf/2505.05968", "abs": "https://arxiv.org/abs/2505.05968", "authors": ["Dan Qiao", "Wenhao Li", "Shanchao Yang", "Hongyuan Zha", "Baoxiang Wang"], "title": "Offline Multi-agent Reinforcement Learning via Score Decomposition", "categories": ["cs.LG", "cs.MA"], "comment": "Working papers", "summary": "Offline multi-agent reinforcement learning (MARL) faces critical challenges\ndue to distributional shifts, further exacerbated by the high dimensionality of\njoint action spaces and the diversity in coordination strategies and quality\namong agents. Conventional approaches, including independent learning\nframeworks and value decomposition methods based on pessimistic principles,\nremain susceptible to out-of-distribution (OOD) joint actions and often yield\nsuboptimal performance. Through systematic analysis of prevalent offline MARL\nbenchmarks, we identify that this limitation primarily stems from the\ninherently multimodal nature of joint collaborative policies induced by offline\ndata collection. To address these challenges, we propose a novel two-stage\nframework: First, we employ a diffusion-based generative model to explicitly\ncapture the complex behavior policy, enabling accurate modeling of diverse\nmulti-agent coordination patterns. Second, we introduce a sequential score\nfunction decomposition mechanism to regularize individual policies and enable\ndecentralized execution. Extensive experiments on continuous control tasks\ndemonstrate state-of-the-art performance across multiple standard offline MARL\nbenchmarks, outperforming existing methods by 26.3\\% in normalized returns. Our\napproach provides new insights into offline coordination and equilibrium\nselection in cooperative multi-agent systems."}
{"id": "2505.05518", "pdf": "https://arxiv.org/pdf/2505.05518", "abs": "https://arxiv.org/abs/2505.05518", "authors": ["Jaeyoung Huh", "Ankur Kapoor", "Young-Ho Kim"], "title": "Guidance for Intra-cardiac Echocardiography Manipulation to Maintain Continuous Therapy Device Tip Visibility", "categories": ["eess.IV", "cs.CV", "cs.RO"], "comment": null, "summary": "Intra-cardiac Echocardiography (ICE) plays a critical role in\nElectrophysiology (EP) and Structural Heart Disease (SHD) interventions by\nproviding real-time visualization of intracardiac structures. However,\nmaintaining continuous visibility of the therapy device tip remains a challenge\ndue to frequent adjustments required during manual ICE catheter manipulation.\nTo address this, we propose an AI-driven tracking model that estimates the\ndevice tip incident angle and passing point within the ICE imaging plane,\nensuring continuous visibility and facilitating robotic ICE catheter control.\n  A key innovation of our approach is the hybrid dataset generation strategy,\nwhich combines clinical ICE sequences with synthetic data augmentation to\nenhance model robustness. We collected ICE images in a water chamber setup,\nequipping both the ICE catheter and device tip with electromagnetic (EM)\nsensors to establish precise ground-truth locations. Synthetic sequences were\ncreated by overlaying catheter tips onto real ICE images, preserving motion\ncontinuity while simulating diverse anatomical scenarios. The final dataset\nconsists of 5,698 ICE-tip image pairs, ensuring comprehensive training\ncoverage.\n  Our model architecture integrates a pretrained ultrasound (US) foundation\nmodel, trained on 37.4M echocardiography images, for feature extraction. A\ntransformer-based network processes sequential ICE frames, leveraging\nhistorical passing points and incident angles to improve prediction accuracy.\n  Experimental results demonstrate that our method achieves 3.32 degree entry\nangle error, 12.76 degree rotation angle error. This AI-driven framework lays\nthe foundation for real-time robotic ICE catheter adjustments, minimizing\noperator workload while ensuring consistent therapy device visibility. Future\nwork will focus on expanding clinical datasets to further enhance model\ngeneralization."}
{"id": "2505.05772", "pdf": "https://arxiv.org/pdf/2505.05772", "abs": "https://arxiv.org/abs/2505.05772", "authors": ["Zehao Fan", "Garrett Gagnon", "Zhenyu Liu", "Liu Liu"], "title": "Sparse Attention Remapping with Clustering for Efficient LLM Decoding on PIM", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Transformer-based models are the foundation of modern machine learning, but\ntheir execution, particularly during autoregressive decoding in large language\nmodels (LLMs), places significant pressure on memory systems due to frequent\nmemory accesses and growing key-value (KV) caches. This creates a bottleneck in\nmemory bandwidth, especially as context lengths increase. Processing-in-memory\n(PIM) architectures are a promising solution, offering high internal bandwidth\nand compute parallelism near memory. However, current PIM designs are primarily\noptimized for dense attention and struggle with the dynamic, irregular access\npatterns introduced by modern KV cache sparsity techniques. Consequently, they\nsuffer from workload imbalance, reducing throughput and resource utilization.\nIn this work, we propose STARC, a novel sparsity-optimized data mapping scheme\ntailored specifically for efficient LLM decoding on PIM architectures. STARC\nclusters KV pairs by semantic similarity and maps them to contiguous memory\nregions aligned with PIM bank structures. During decoding, queries retrieve\nrelevant tokens at cluster granularity by matching against precomputed\ncentroids, enabling selective attention and parallel processing without\nfrequent reclustering or data movement overhead. Experiments on the HBM-PIM\nsystem show that, compared to common token-wise sparsity methods, STARC reduces\nattention-layer latency by 19%--31% and energy consumption by 19%--27%. Under a\nKV cache budget of 1024, it achieves up to 54%--74% latency reduction and\n45%--67% energy reduction compared to full KV cache retrieval. Meanwhile, STARC\nmaintains model accuracy comparable to state-of-the-art sparse attention\nmethods, demonstrating its effectiveness in enabling efficient and\nhardware-friendly long-context LLM inference on PIM architectures."}
{"id": "2402.00045", "pdf": "https://arxiv.org/pdf/2402.00045", "abs": "https://arxiv.org/abs/2402.00045", "authors": ["Li Lin", "Neeraj Gupta", "Yue Zhang", "Hainan Ren", "Chun-Hao Liu", "Feng Ding", "Xin Wang", "Xin Li", "Luisa Verdoliva", "Shu Hu"], "title": "Detecting Multimedia Generated by Large AI Models: A Survey", "categories": ["cs.MM", "cs.AI", "cs.LG"], "comment": null, "summary": "The rapid advancement of Large AI Models (LAIMs), particularly diffusion\nmodels and large language models, has marked a new era where AI-generated\nmultimedia is increasingly integrated into various aspects of daily life.\nAlthough beneficial in numerous fields, this content presents significant\nrisks, including potential misuse, societal disruptions, and ethical concerns.\nConsequently, detecting multimedia generated by LAIMs has become crucial, with\na marked rise in related research. Despite this, there remains a notable gap in\nsystematic surveys that focus specifically on detecting LAIM-generated\nmultimedia. Addressing this, we provide the first survey to comprehensively\ncover existing research on detecting multimedia (such as text, images, videos,\naudio, and multimodal content) created by LAIMs. Specifically, we introduce a\nnovel taxonomy for detection methods, categorized by media modality, and\naligned with two perspectives: pure detection (aiming to enhance detection\nperformance) and beyond detection (adding attributes like generalizability,\nrobustness, and interpretability to detectors). Additionally, we have presented\na brief overview of generation mechanisms, public datasets, online detection\ntools, and evaluation metrics to provide a valuable resource for researchers\nand practitioners in this field. Most importantly, we offer a focused analysis\nfrom a social media perspective to highlight their broader societal impact.\nFurthermore, we identify current challenges in detection and propose directions\nfor future research that address unexplored, ongoing, and emerging issues in\ndetecting multimedia generated by LAIMs. Our aim for this survey is to fill an\nacademic gap and contribute to global AI security efforts, helping to ensure\nthe integrity of information in the digital realm. The project link is\nhttps://github.com/Purdue-M2/Detect-LAIM-generated-Multimedia-Survey."}
{"id": "2505.05616", "pdf": "https://arxiv.org/pdf/2505.05616", "abs": "https://arxiv.org/abs/2505.05616", "authors": ["Lorenzo Di Fruscia", "Jana Marie Weber"], "title": "Leveraging Large Language Models for enzymatic reaction prediction and characterization", "categories": ["cs.AI", "cs.LG", "q-bio.BM"], "comment": null, "summary": "Predicting enzymatic reactions is crucial for applications in biocatalysis,\nmetabolic engineering, and drug discovery, yet it remains a complex and\nresource-intensive task. Large Language Models (LLMs) have recently\ndemonstrated remarkable success in various scientific domains, e.g., through\ntheir ability to generalize knowledge, reason over complex structures, and\nleverage in-context learning strategies. In this study, we systematically\nevaluate the capability of LLMs, particularly the Llama-3.1 family (8B and\n70B), across three core biochemical tasks: Enzyme Commission number prediction,\nforward synthesis, and retrosynthesis. We compare single-task and multitask\nlearning strategies, employing parameter-efficient fine-tuning via LoRA\nadapters. Additionally, we assess performance across different data regimes to\nexplore their adaptability in low-data settings. Our results demonstrate that\nfine-tuned LLMs capture biochemical knowledge, with multitask learning\nenhancing forward- and retrosynthesis predictions by leveraging shared\nenzymatic information. We also identify key limitations, for example challenges\nin hierarchical EC classification schemes, highlighting areas for further\nimprovement in LLM-driven biochemical modeling."}
{"id": "2505.05492", "pdf": "https://arxiv.org/pdf/2505.05492", "abs": "https://arxiv.org/abs/2505.05492", "authors": ["Ignacy Stępka", "Lukasz Sztukiewicz", "Michał Wiliński", "Jerzy Stefanowski"], "title": "DetoxAI: a Python Toolkit for Debiasing Deep Learning Models in Computer Vision", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "While machine learning fairness has made significant progress in recent\nyears, most existing solutions focus on tabular data and are poorly suited for\nvision-based classification tasks, which rely heavily on deep learning. To\nbridge this gap, we introduce DetoxAI, an open-source Python library for\nimproving fairness in deep learning vision classifiers through post-hoc\ndebiasing. DetoxAI implements state-of-the-art debiasing algorithms, fairness\nmetrics, and visualization tools. It supports debiasing via interventions in\ninternal representations and includes attribution-based visualization tools and\nquantitative algorithmic fairness metrics to show how bias is mitigated. This\npaper presents the motivation, design, and use cases of DetoxAI, demonstrating\nits tangible value to engineers and researchers."}
{"id": "2505.05530", "pdf": "https://arxiv.org/pdf/2505.05530", "abs": "https://arxiv.org/abs/2505.05530", "authors": ["Kai Liu", "Qian Zheng", "Kaiwen Tao", "Zhiteng Li", "Haotong Qin", "Wenbo Li", "Yong Guo", "Xianglong Liu", "Linghe Kong", "Guihai Chen", "Yulun Zhang", "Xiaokang Yang"], "title": "Low-bit Model Quantization for Deep Neural Networks: A Survey", "categories": ["cs.LG", "cs.AI"], "comment": "We have systematically collected and reviewed the state-of-the-art\n  quantization methods from the past five years, categorizing them into eight\n  distinct groups. A curated list of model quantization is provided at\n  https://github.com/Kai-Liu001/Awesome-Model-Quantization", "summary": "With unprecedented rapid development, deep neural networks (DNNs) have deeply\ninfluenced almost all fields. However, their heavy computation costs and model\nsizes are usually unacceptable in real-world deployment. Model quantization, an\neffective weight-lighting technique, has become an indispensable procedure in\nthe whole deployment pipeline. The essence of quantization acceleration is the\nconversion from continuous floating-point numbers to discrete integer ones,\nwhich significantly speeds up the memory I/O and calculation, i.e., addition\nand multiplication. However, performance degradation also comes with the\nconversion because of the loss of precision. Therefore, it has become\nincreasingly popular and critical to investigate how to perform the conversion\nand how to compensate for the information loss. This article surveys the recent\nfive-year progress towards low-bit quantization on DNNs. We discuss and compare\nthe state-of-the-art quantization methods and classify them into 8 main\ncategories and 24 sub-categories according to their core techniques.\nFurthermore, we shed light on the potential research opportunities in the field\nof model quantization. A curated list of model quantization is provided at\nhttps://github.com/Kai-Liu001/Awesome-Model-Quantization."}
{"id": "2505.03586", "pdf": "https://arxiv.org/pdf/2505.03586", "abs": "https://arxiv.org/abs/2505.03586", "authors": ["Songchen Fu", "Siang Chen", "Shaojing Zhao", "Letian Bai", "Ta Li", "Yonghong Yan"], "title": "Rainbow Delay Compensation: A Multi-Agent Reinforcement Learning Framework for Mitigating Delayed Observation", "categories": ["cs.MA", "cs.AI", "68T07 (Primary), 68T20, 68T42 (Secondary)", "I.2"], "comment": "The code will be open-sourced in the RDC-pymarl project under\n  https://github.com/linkjoker1006", "summary": "In real-world multi-agent systems (MASs), observation delays are ubiquitous,\npreventing agents from making decisions based on the environment's true state.\nAn individual agent's local observation often consists of multiple components\nfrom other agents or dynamic entities in the environment. These discrete\nobservation components with varying delay characteristics pose significant\nchallenges for multi-agent reinforcement learning (MARL). In this paper, we\nfirst formulate the decentralized stochastic individual delay partially\nobservable Markov decision process (DSID-POMDP) by extending the standard\nDec-POMDP. We then propose the Rainbow Delay Compensation (RDC), a MARL\ntraining framework for addressing stochastic individual delays, along with\nrecommended implementations for its constituent modules. We implement the\nDSID-POMDP's observation generation pattern using standard MARL benchmarks,\nincluding MPE and SMAC. Experiments demonstrate that baseline MARL methods\nsuffer severe performance degradation under fixed and unfixed delays. The\nRDC-enhanced approach mitigates this issue, remarkably achieving ideal\ndelay-free performance in certain delay scenarios while maintaining\ngeneralizability. Our work provides a novel perspective on multi-agent delayed\nobservation problems and offers an effective solution framework. The source\ncode is available at https://anonymous.4open.science/r/RDC-pymarl-4512/."}
{"id": "2505.05631", "pdf": "https://arxiv.org/pdf/2505.05631", "abs": "https://arxiv.org/abs/2505.05631", "authors": ["Jiachen Tu", "Yaokun Shi", "Fan Lam"], "title": "Score-based Self-supervised MRI Denoising", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Magnetic resonance imaging (MRI) is a powerful noninvasive diagnostic imaging\ntool that provides unparalleled soft tissue contrast and anatomical detail.\nNoise contamination, especially in accelerated and/or low-field acquisitions,\ncan significantly degrade image quality and diagnostic accuracy. Supervised\nlearning based denoising approaches have achieved impressive performance but\nrequire high signal-to-noise ratio (SNR) labels, which are often unavailable.\nSelf-supervised learning holds promise to address the label scarcity issue, but\nexisting self-supervised denoising methods tend to oversmooth fine spatial\nfeatures and often yield inferior performance than supervised methods. We\nintroduce Corruption2Self (C2S), a novel score-based self-supervised framework\nfor MRI denoising. At the core of C2S is a generalized denoising score matching\n(GDSM) loss, which extends denoising score matching to work directly with noisy\nobservations by modeling the conditional expectation of higher-SNR images given\nfurther corrupted observations. This allows the model to effectively learn\ndenoising across multiple noise levels directly from noisy data. Additionally,\nwe incorporate a reparameterization of noise levels to stabilize training and\nenhance convergence, and introduce a detail refinement extension to balance\nnoise reduction with the preservation of fine spatial features. Moreover, C2S\ncan be extended to multi-contrast denoising by leveraging complementary\ninformation across different MRI contrasts. We demonstrate that our method\nachieves state-of-the-art performance among self-supervised methods and\ncompetitive results compared to supervised counterparts across varying noise\nconditions and MRI contrasts on the M4Raw and fastMRI dataset."}
{"id": "2505.05815", "pdf": "https://arxiv.org/pdf/2505.05815", "abs": "https://arxiv.org/abs/2505.05815", "authors": ["Machi Shimmei", "Masaki Uto", "Yuichiroh Matsubayashi", "Kentaro Inui", "Aditi Mallavarapu", "Noboru Matsuda"], "title": "Tell Me Who Your Students Are: GPT Can Generate Valid Multiple-Choice Questions When Students' (Mis)Understanding Is Hinted", "categories": ["cs.CL"], "comment": "This is a pre-print version of a paper to appear in AIED2025", "summary": "The primary goal of this study is to develop and evaluate an innovative\nprompting technique, AnaQuest, for generating multiple-choice questions (MCQs)\nusing a pre-trained large language model. In AnaQuest, the choice items are\nsentence-level assertions about complex concepts. The technique integrates\nformative and summative assessments. In the formative phase, students answer\nopen-ended questions for target concepts in free text. For summative\nassessment, AnaQuest analyzes these responses to generate both correct and\nincorrect assertions. To evaluate the validity of the generated MCQs, Item\nResponse Theory (IRT) was applied to compare item characteristics between MCQs\ngenerated by AnaQuest, a baseline ChatGPT prompt, and human-crafted items. An\nempirical study found that expert instructors rated MCQs generated by both AI\nmodels to be as valid as those created by human instructors. However, IRT-based\nanalysis revealed that AnaQuest-generated questions - particularly those with\nincorrect assertions (foils) - more closely resembled human-crafted items in\nterms of difficulty and discrimination than those produced by ChatGPT."}
{"id": "2502.14439", "pdf": "https://arxiv.org/pdf/2502.14439", "abs": "https://arxiv.org/abs/2502.14439", "authors": ["Harin Lee", "Eline Van Geert", "Elif Celen", "Raja Marjieh", "Pol van Rijn", "Minsu Park", "Nori Jacoby"], "title": "Visual and Auditory Aesthetic Preferences Across Cultures", "categories": ["cs.MM"], "comment": "To be presented at CogSci 2025", "summary": "Research on how humans perceive aesthetics in shapes, colours, and music has\npredominantly focused on Western populations, limiting our understanding of how\ncultural environments shape aesthetic preferences. We present a large-scale\ncross-cultural study examining aesthetic preferences across five distinct\nmodalities extensively explored in the literature: shape, curvature, colour,\nmusical harmony and melody. We gather 401,403 preference judgements from 4,835\nparticipants across 10 countries, systematically sampling two-dimensional\nparameter spaces for each modality. The findings reveal both universal patterns\nand cultural variations. Preferences for shape and curvature cross-culturally\ndemonstrate a consistent preference for symmetrical forms. While colour\npreferences are categorically consistent, ratio-like preferences vary across\ncultures. Musical harmony shows strong agreement in interval relationships\ndespite differing regions of preference within the broad frequency spectrum,\nwhile melody shows the highest cross-cultural variation. These results suggest\nthat aesthetic preferences emerge from an interplay between shared perceptual\nmechanisms and cultural learning."}
{"id": "2505.05684", "pdf": "https://arxiv.org/pdf/2505.05684", "abs": "https://arxiv.org/abs/2505.05684", "authors": ["Han Wu", "Jie Yin"], "title": "Prompted Meta-Learning for Few-shot Knowledge Graph Completion", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Few-shot knowledge graph completion (KGC) has obtained significant attention\ndue to its practical applications in real-world scenarios, where new knowledge\noften emerges with limited available data. While most existing methods for\nfew-shot KGC have predominantly focused on leveraging relational information,\nrich semantics inherent in KGs have been largely overlooked. To address this\ngap, we propose a novel prompted meta-learning (PromptMeta) framework that\nseamlessly integrates meta-semantics with relational information for few-shot\nKGC. PrompMeta has two key innovations: (1) a meta-semantic prompt pool that\ncaptures and consolidates high-level meta-semantics, enabling effective\nknowledge transfer and adaptation to rare and newly emerging relations. (2) a\nlearnable fusion prompt that dynamically combines meta-semantic information\nwith task-specific relational information tailored to different few-shot tasks.\nBoth components are optimized together with model parameters within a\nmeta-learning framework. Extensive experiments on two benchmark datasets\ndemonstrate the effectiveness of our approach."}
{"id": "2505.05495", "pdf": "https://arxiv.org/pdf/2505.05495", "abs": "https://arxiv.org/abs/2505.05495", "authors": ["Siyuan Zhou", "Yilun Du", "Yuncong Yang", "Lei Han", "Peihao Chen", "Dit-Yan Yeung", "Chuang Gan"], "title": "Learning 3D Persistent Embodied World Models", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "The ability to simulate the effects of future actions on the world is a\ncrucial ability of intelligent embodied agents, enabling agents to anticipate\nthe effects of their actions and make plans accordingly. While a large body of\nexisting work has explored how to construct such world models using video\nmodels, they are often myopic in nature, without any memory of a scene not\ncaptured by currently observed images, preventing agents from making consistent\nlong-horizon plans in complex environments where many parts of the scene are\npartially observed. We introduce a new persistent embodied world model with an\nexplicit memory of previously generated content, enabling much more consistent\nlong-horizon simulation. During generation time, our video diffusion model\npredicts RGB-D video of the future observations of the agent. This generation\nis then aggregated into a persistent 3D map of the environment. By conditioning\nthe video model on this 3D spatial map, we illustrate how this enables video\nworld models to faithfully simulate both seen and unseen parts of the world.\nFinally, we illustrate the efficacy of such a world model in downstream\nembodied applications, enabling effective planning and policy learning."}
{"id": "2505.05533", "pdf": "https://arxiv.org/pdf/2505.05533", "abs": "https://arxiv.org/abs/2505.05533", "authors": ["Zhiyuan Ning", "Pengfei Wang", "Ziyue Qiao", "Pengyang Wang", "Yuanchun Zhou"], "title": "Rethinking Graph Contrastive Learning through Relative Similarity Preservation", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by IJCAI2025; full version including appendix", "summary": "Graph contrastive learning (GCL) has achieved remarkable success by following\nthe computer vision paradigm of preserving absolute similarity between\naugmented views. However, this approach faces fundamental challenges in graphs\ndue to their discrete, non-Euclidean nature -- view generation often breaks\nsemantic validity and similarity verification becomes unreliable. Through\nanalyzing 11 real-world graphs, we discover a universal pattern transcending\nthe homophily-heterophily dichotomy: label consistency systematically\ndiminishes as structural distance increases, manifesting as smooth decay in\nhomophily graphs and oscillatory decay in heterophily graphs. We establish\ntheoretical guarantees for this pattern through random walk theory, proving\nlabel distribution convergence and characterizing the mechanisms behind\ndifferent decay behaviors. This discovery reveals that graphs naturally encode\nrelative similarity patterns, where structurally closer nodes exhibit\ncollectively stronger semantic relationships. Leveraging this insight, we\npropose RELGCL, a novel GCL framework with complementary pairwise and listwise\nimplementations that preserve these inherent patterns through collective\nsimilarity objectives. Extensive experiments demonstrate that our method\nconsistently outperforms 20 existing approaches across both homophily and\nheterophily graphs, validating the effectiveness of leveraging natural relative\nsimilarity over artificial absolute similarity."}
{"id": "2403.10794", "pdf": "https://arxiv.org/pdf/2403.10794", "abs": "https://arxiv.org/abs/2403.10794", "authors": ["Zixuan Wu", "Sean Ye", "Manisha Natarajan", "Matthew C. Gombolay"], "title": "Diffusion-Reinforcement Learning Hierarchical Motion Planning in Multi-agent Adversarial Games", "categories": ["cs.RO", "cs.LG", "cs.MA"], "comment": "This work has been submitted to the IEEE Robotics and Automation\n  Letters (RA-L) for possible publication", "summary": "Reinforcement Learning (RL)-based motion planning has recently shown the\npotential to outperform traditional approaches from autonomous navigation to\nrobot manipulation. In this work, we focus on a motion planning task for an\nevasive target in a partially observable multi-agent adversarial\npursuit-evasion game (PEG). Pursuit-evasion problems are relevant to various\napplications, such as search and rescue operations and surveillance robots,\nwhere robots must effectively plan their actions to gather intelligence or\naccomplish mission tasks while avoiding detection or capture. We propose a\nhierarchical architecture that integrates a high-level diffusion model to plan\nglobal paths responsive to environment data, while a low-level RL policy\nreasons about evasive versus global path-following behavior. The benchmark\nresults across different domains and different observability show that our\napproach outperforms baselines by 77.18% and 47.38% on detection and goal\nreaching rate, which leads to 51.4% increasing of the performance score on\naverage. Additionally, our method improves interpretability, flexibility and\nefficiency of the learned policy."}
{"id": "2505.05643", "pdf": "https://arxiv.org/pdf/2505.05643", "abs": "https://arxiv.org/abs/2505.05643", "authors": ["Mark C. Eid", "Ana I. L. Namburete", "João F. Henriques"], "title": "UltraGauss: Ultrafast Gaussian Reconstruction of 3D Ultrasound Volumes", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "comment": null, "summary": "Ultrasound imaging is widely used due to its safety, affordability, and\nreal-time capabilities, but its 2D interpretation is highly operator-dependent,\nleading to variability and increased cognitive demand. 2D-to-3D reconstruction\nmitigates these challenges by providing standardized volumetric views, yet\nexisting methods are often computationally expensive, memory-intensive, or\nincompatible with ultrasound physics. We introduce UltraGauss: the first\nultrasound-specific Gaussian Splatting framework, extending view synthesis\ntechniques to ultrasound wave propagation. Unlike conventional\nperspective-based splatting, UltraGauss models probe-plane intersections in 3D,\naligning with acoustic image formation. We derive an efficient rasterization\nboundary formulation for GPU parallelization and introduce a numerically stable\ncovariance parametrization, improving computational efficiency and\nreconstruction accuracy. On real clinical ultrasound data, UltraGauss achieves\nstate-of-the-art reconstructions in 5 minutes, and reaching 0.99 SSIM within 20\nminutes on a single GPU. A survey of expert clinicians confirms UltraGauss'\nreconstructions are the most realistic among competing methods. Our CUDA\nimplementation will be released upon publication."}
{"id": "2505.05864", "pdf": "https://arxiv.org/pdf/2505.05864", "abs": "https://arxiv.org/abs/2505.05864", "authors": ["Junhyeong Lee", "Jong Min Yuk", "Chan-Woo Lee"], "title": "Symbol-based entity marker highlighting for enhanced text mining in materials science with generative AI", "categories": ["cs.CL"], "comment": "29 pages", "summary": "The construction of experimental datasets is essential for expanding the\nscope of data-driven scientific discovery. Recent advances in natural language\nprocessing (NLP) have facilitated automatic extraction of structured data from\nunstructured scientific literature. While existing approaches-multi-step and\ndirect methods-offer valuable capabilities, they also come with limitations\nwhen applied independently. Here, we propose a novel hybrid text-mining\nframework that integrates the advantages of both methods to convert\nunstructured scientific text into structured data. Our approach first\ntransforms raw text into entity-recognized text, and subsequently into\nstructured form. Furthermore, beyond the overall data structuring framework, we\nalso enhance entity recognition performance by introducing an entity marker-a\nsimple yet effective technique that uses symbolic annotations to highlight\ntarget entities. Specifically, our entity marker-based hybrid approach not only\nconsistently outperforms previous entity recognition approaches across three\nbenchmark datasets (MatScholar, SOFC, and SOFC slot NER) but also improve the\nquality of final structured data-yielding up to a 58% improvement in\nentity-level F1 score and up to 83% improvement in relation-level F1 score\ncompared to direct approach."}
{"id": "2501.02704", "pdf": "https://arxiv.org/pdf/2501.02704", "abs": "https://arxiv.org/abs/2501.02704", "authors": ["Anh Tu Ngo", "Chuan Song Heng", "Nandish Chattopadhyay", "Anupam Chattopadhyay"], "title": "Persistence of Backdoor-based Watermarks for Neural Networks: A Comprehensive Evaluation", "categories": ["cs.LG", "cs.CR", "cs.MM"], "comment": "Accepted by IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS)", "summary": "Deep Neural Networks (DNNs) have gained considerable traction in recent years\ndue to the unparalleled results they gathered. However, the cost behind\ntraining such sophisticated models is resource intensive, resulting in many to\nconsider DNNs to be intellectual property (IP) to model owners. In this era of\ncloud computing, high-performance DNNs are often deployed all over the internet\nso that people can access them publicly. As such, DNN watermarking schemes,\nespecially backdoor-based watermarks, have been actively developed in recent\nyears to preserve proprietary rights. Nonetheless, there lies much uncertainty\non the robustness of existing backdoor watermark schemes, towards both\nadversarial attacks and unintended means such as fine-tuning neural network\nmodels. One reason for this is that no complete guarantee of robustness can be\nassured in the context of backdoor-based watermark. In this paper, we\nextensively evaluate the persistence of recent backdoor-based watermarks within\nneural networks in the scenario of fine-tuning, we propose/develop a novel\ndata-driven idea to restore watermark after fine-tuning without exposing the\ntrigger set. Our empirical results show that by solely introducing training\ndata after fine-tuning, the watermark can be restored if model parameters do\nnot shift dramatically during fine-tuning. Depending on the types of trigger\nsamples used, trigger accuracy can be reinstated to up to 100%. Our study\nfurther explores how the restoration process works using loss landscape\nvisualization, as well as the idea of introducing training data in fine-tuning\nstage to alleviate watermark vanishing."}
{"id": "2505.05701", "pdf": "https://arxiv.org/pdf/2505.05701", "abs": "https://arxiv.org/abs/2505.05701", "authors": ["Jongchan Park", "Mingyu Park", "Donghwan Lee"], "title": "Pretraining a Shared Q-Network for Data-Efficient Offline Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Offline reinforcement learning (RL) aims to learn a policy from a static\ndataset without further interactions with the environment. Collecting\nsufficiently large datasets for offline RL is exhausting since this data\ncollection requires colossus interactions with environments and becomes tricky\nwhen the interaction with the environment is restricted. Hence, how an agent\nlearns the best policy with a minimal static dataset is a crucial issue in\noffline RL, similar to the sample efficiency problem in online RL. In this\npaper, we propose a simple yet effective plug-and-play pretraining method to\ninitialize a feature of a $Q$-network to enhance data efficiency in offline RL.\nSpecifically, we introduce a shared $Q$-network structure that outputs\npredictions of the next state and $Q$-value. We pretrain the shared $Q$-network\nthrough a supervised regression task that predicts a next state and trains the\nshared $Q$-network using diverse offline RL methods. Through extensive\nexperiments, we empirically demonstrate that our method enhances the\nperformance of existing popular offline RL methods on the D4RL, Robomimic and\nV-D4RL benchmarks. Furthermore, we show that our method significantly boosts\ndata-efficient offline RL across various data qualities and data distributions\ntrough D4RL and ExoRL benchmarks. Notably, our method adapted with only 10% of\nthe dataset outperforms standard algorithms even with full datasets."}
{"id": "2505.05501", "pdf": "https://arxiv.org/pdf/2505.05501", "abs": "https://arxiv.org/abs/2505.05501", "authors": ["Pu Cao", "Feng Zhou", "Junyi Ji", "Qingye Kong", "Zhixiang Lv", "Mingjian Zhang", "Xuekun Zhao", "Siqi Wu", "Yinghui Lin", "Qing Song", "Lu Yang"], "title": "Preliminary Explorations with GPT-4o(mni) Native Image Generation", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "Recently, the visual generation ability by GPT-4o(mni) has been unlocked by\nOpenAI. It demonstrates a very remarkable generation capability with excellent\nmultimodal condition understanding and varied task instructions. In this paper,\nwe aim to explore the capabilities of GPT-4o across various tasks. Inspired by\nprevious study, we constructed a task taxonomy along with a carefully curated\nset of test samples to conduct a comprehensive qualitative test. Benefiting\nfrom GPT-4o's powerful multimodal comprehension, its image-generation process\ndemonstrates abilities surpassing those of traditional image-generation tasks.\nThus, regarding the dimensions of model capabilities, we evaluate its\nperformance across six task categories: traditional image generation tasks,\ndiscriminative tasks, knowledge-based generation, commonsense-based generation,\nspatially-aware image generation, and temporally-aware image generation. These\ntasks not only assess the quality and conditional alignment of the model's\noutputs but also probe deeper into GPT-4o's understanding of real-world\nconcepts. Our results reveal that GPT-4o performs impressively well in\ngeneral-purpose synthesis tasks, showing strong capabilities in text-to-image\ngeneration, visual stylization, and low-level image processing. However,\nsignificant limitations remain in its ability to perform precise spatial\nreasoning, instruction-grounded generation, and consistent temporal prediction.\nFurthermore, when faced with knowledge-intensive or domain-specific scenarios,\nsuch as scientific illustrations or mathematical plots, the model often\nexhibits hallucinations, factual errors, or structural inconsistencies. These\nfindings suggest that while GPT-4o marks a substantial advancement in unified\nmultimodal generation, there is still a long way to go before it can be\nreliably applied to professional or safety-critical domains."}
{"id": "2505.05538", "pdf": "https://arxiv.org/pdf/2505.05538", "abs": "https://arxiv.org/abs/2505.05538", "authors": ["Md Kamrujjaman Mobin", "Md Saiful Islam", "Sadik Al Barid", "Md Masum"], "title": "Cardioformer: Advancing AI in ECG Analysis with Multi-Granularity Patching and ResNet", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Electrocardiogram (ECG) classification is crucial for automated cardiac\ndisease diagnosis, yet existing methods often struggle to capture local\nmorphological details and long-range temporal dependencies simultaneously. To\naddress these challenges, we propose Cardioformer, a novel multi-granularity\nhybrid model that integrates cross-channel patching, hierarchical residual\nlearning, and a two-stage self-attention mechanism. Cardioformer first encodes\nmulti-scale token embeddings to capture fine-grained local features and global\ncontextual information and then selectively fuses these representations through\nintra- and inter-granularity self-attention. Extensive evaluations on three\nbenchmark ECG datasets under subject-independent settings demonstrate that\nmodel consistently outperforms four state-of-the-art baselines. Our\nCardioformer model achieves the AUROC of 96.34$\\pm$0.11, 89.99$\\pm$0.12, and\n95.59$\\pm$1.66 in MIMIC-IV, PTB-XL and PTB dataset respectively outperforming\nPatchTST, Reformer, Transformer, and Medformer models. It also demonstrates\nstrong cross-dataset generalization, achieving 49.18% AUROC on PTB and 68.41%\non PTB-XL when trained on MIMIC-IV. These findings underscore the potential of\nCardioformer to advance automated ECG analysis, paving the way for more\naccurate and robust cardiovascular disease diagnosis. We release the source\ncode at https://github.com/KMobin555/Cardioformer."}
{"id": "2405.21027", "pdf": "https://arxiv.org/pdf/2405.21027", "abs": "https://arxiv.org/abs/2405.21027", "authors": ["Jiesong Lian", "Yucong Huang", "Chengdong Ma", "Mingzhi Wang", "Ying Wen", "Long Hu", "Yixue Hao"], "title": "Fusion-PSRO: Nash Policy Fusion for Policy Space Response Oracles", "categories": ["cs.GT", "cs.AI", "cs.LG", "cs.MA"], "comment": "11 pages, 11 figures", "summary": "For solving zero-sum games involving non-transitivity, a useful approach is\nto maintain a policy population to approximate the Nash Equilibrium (NE).\nPrevious studies have shown that the Policy Space Response Oracles (PSRO)\nalgorithm is an effective framework for solving such games. However, current\nmethods initialize a new policy from scratch or inherit a single historical\npolicy in Best Response (BR), missing the opportunity to leverage past policies\nto generate a better BR. In this paper, we propose Fusion-PSRO, which employs\nNash Policy Fusion to initialize a new policy for BR training. Nash Policy\nFusion serves as an implicit guiding policy that starts exploration on the\ncurrent Meta-NE, thus providing a closer approximation to BR. Moreover, it\ninsightfully captures a weighted moving average of past policies, dynamically\nadjusting these weights based on the Meta-NE in each iteration. This cumulative\nprocess further enhances the policy population. Empirical results on classic\nbenchmarks show that Fusion-PSRO achieves lower exploitability, thereby\nmitigating the shortcomings of previous research on policy initialization in\nBR."}
{"id": "2505.05659", "pdf": "https://arxiv.org/pdf/2505.05659", "abs": "https://arxiv.org/abs/2505.05659", "authors": ["Guilherme Vieira Neto", "Marcos Eduardo Valle"], "title": "V-EfficientNets: Vector-Valued Efficiently Scaled Convolutional Neural Network Models", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "Accepted at International Joint Conference on Neural Networks (IJCNN\n  2025)", "summary": "EfficientNet models are convolutional neural networks optimized for parameter\nallocation by jointly balancing network width, depth, and resolution. Renowned\nfor their exceptional accuracy, these models have become a standard for image\nclassification tasks across diverse computer vision benchmarks. While\ntraditional neural networks learn correlations between feature channels during\ntraining, vector-valued neural networks inherently treat multidimensional data\nas coherent entities, taking for granted the inter-channel relationships. This\npaper introduces vector-valued EfficientNets (V-EfficientNets), a novel\nextension of EfficientNet designed to process arbitrary vector-valued data. The\nproposed models are evaluated on a medical image classification task, achieving\nan average accuracy of 99.46% on the ALL-IDB2 dataset for detecting acute\nlymphoblastic leukemia. V-EfficientNets demonstrate remarkable efficiency,\nsignificantly reducing parameters while outperforming state-of-the-art models,\nincluding the original EfficientNet. The source code is available at\nhttps://github.com/mevalle/v-nets."}
{"id": "2505.05946", "pdf": "https://arxiv.org/pdf/2505.05946", "abs": "https://arxiv.org/abs/2505.05946", "authors": ["Vytenis Šliogeris", "Povilas Daniušis", "Artūras Nakvosas"], "title": "Elastic Weight Consolidation for Full-Parameter Continual Pre-Training of Gemma2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "8 pages, 4 figures", "summary": "This technical report describes an experiment on autoregressive pre-training\nof Gemma2 2 billion parameter large language model (LLM) with 10\\% on the\nLithuanian language component of CulturaX from the point of view of continual\nlearning. We apply elastic weight consolidation (EWC) to the full set of the\nmodel's parameters and investigate language understanding benchmarks,\nconsisting of Arc, Belebele, Gsm8K, Hellaswag, MMLU, TruthfulQA, and Winogrande\nsets (both in English and Lithuanian versions), and perplexity benchmarks. We\nempirically demonstrate that EWC regularisation allows us not only to mitigate\ncatastrophic forgetting effects but also that it is potentially beneficial for\nlearning of the new task with LLMs."}
{"id": "2505.02539", "pdf": "https://arxiv.org/pdf/2505.02539", "abs": "https://arxiv.org/abs/2505.02539", "authors": ["Nahuel Garcia-D'Urso", "Bernabe Sanchez-Sos", "Jorge Azorin-Lopez", "Andres Fuster-Guillo", "Antonio Macia-Lillo", "Higinio Mora-Mora"], "title": "Marker-Based Extrinsic Calibration Method for Accurate Multi-Camera 3D Reconstruction", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Accurate 3D reconstruction using multi-camera RGB-D systems critically\ndepends on precise extrinsic calibration to achieve proper alignment between\ncaptured views. In this paper, we introduce an iterative extrinsic calibration\nmethod that leverages the geometric constraints provided by a three-dimensional\nmarker to significantly improve calibration accuracy. Our proposed approach\nsystematically segments and refines marker planes through clustering,\nregression analysis, and iterative reassignment techniques, ensuring robust\ngeometric correspondence across camera views. We validate our method\ncomprehensively in both controlled environments and practical real-world\nsettings within the Tech4Diet project, aimed at modeling the physical\nprogression of patients undergoing nutritional treatments. Experimental results\ndemonstrate substantial reductions in alignment errors, facilitating accurate\nand reliable 3D reconstructions."}
{"id": "2505.05758", "pdf": "https://arxiv.org/pdf/2505.05758", "abs": "https://arxiv.org/abs/2505.05758", "authors": ["Azim Ospanov", "Roozbeh Yousefzadeh"], "title": "APOLLO: Automated LLM and Lean Collaboration for Advanced Formal Reasoning", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "Formal reasoning and automated theorem proving constitute a challenging\nsubfield of machine learning, in which machines are tasked with proving\nmathematical theorems using formal languages like Lean. A formal verification\nsystem can check whether a formal proof is correct or not almost\ninstantaneously, but generating a completely correct formal proof with large\nlanguage models (LLMs) remains a formidable task. The usual approach in the\nliterature is to prompt the LLM many times (up to several thousands) until one\nof the generated proofs passes the verification system. In this work, we\npresent APOLLO (Automated PrOof repair via LLM and Lean cOllaboration), a\nmodular, model-agnostic pipeline that combines the strengths of the Lean\ncompiler with an LLM's reasoning abilities to achieve better proof-generation\nresults at a low sampling budget. Apollo directs a fully automated process in\nwhich the LLM generates proofs for theorems, a set of agents analyze the\nproofs, fix the syntax errors, identify the mistakes in the proofs using Lean,\nisolate failing sub-lemmas, utilize automated solvers, and invoke an LLM on\neach remaining goal with a low top-K budget. The repaired sub-proofs are\nrecombined and reverified, iterating up to a user-controlled maximum number of\nattempts. On the miniF2F benchmark, we establish a new state-of-the-art\naccuracy of 75.0% among 7B-parameter models while keeping the sampling budget\nbelow one thousand. Moreover, Apollo raises the state-of-the-art accuracy for\nGoedel-Prover-SFT to 65.6% while cutting sample complexity from 25,600 to a few\nhundred. General-purpose models (o3-mini, o4-mini) jump from 3-7% to over 40%\naccuracy. Our results demonstrate that targeted, compiler-guided repair of LLM\noutputs yields dramatic gains in both efficiency and correctness, suggesting a\ngeneral paradigm for scalable automated theorem proving."}
{"id": "2505.05505", "pdf": "https://arxiv.org/pdf/2505.05505", "abs": "https://arxiv.org/abs/2505.05505", "authors": ["Yiming Qin", "Zhu Xu", "Yang Liu"], "title": "Apply Hierarchical-Chain-of-Generation to Complex Attributes Text-to-3D Generation", "categories": ["cs.CV", "eess.IV"], "comment": "Project page here:\n  https://hierarchical-chain-of-generation.github.io/", "summary": "Recent text-to-3D models can render high-quality assets, yet they still\nstumble on objects with complex attributes. The key obstacles are: (1) existing\ntext-to-3D approaches typically lift text-to-image models to extract semantics\nvia text encoders, while the text encoder exhibits limited comprehension\nability for long descriptions, leading to deviated cross-attention focus,\nsubsequently wrong attribute binding in generated results. (2) Occluded object\nparts demand a disciplined generation order and explicit part disentanglement.\nThough some works introduce manual efforts to alleviate the above issues, their\nquality is unstable and highly reliant on manual information. To tackle above\nproblems, we propose a automated method Hierarchical-Chain-of-Generation\n(HCoG). It leverages a large language model to decompose the long description\ninto blocks representing different object parts, and orders them from inside\nout according to occlusions, forming a hierarchical chain. Within each block we\nfirst coarsely create components, then precisely bind attributes via\ntarget-region localization and corresponding 3D Gaussian kernel optimization.\nBetween blocks, we introduce Gaussian Extension and Label Elimination to\nseamlessly generate new parts by extending new Gaussian kernels, re-assigning\nsemantic labels, and eliminating unnecessary kernels, ensuring that only\nrelevant parts are added without disrupting previously optimized parts.\nExperiments confirm that HCoG yields structurally coherent, attribute-faithful\n3D objects with complex attributes. The code is available at\nhttps://github.com/Wakals/GASCOL ."}
{"id": "2505.05568", "pdf": "https://arxiv.org/pdf/2505.05568", "abs": "https://arxiv.org/abs/2505.05568", "authors": ["Yanbo Wang", "Xiyuan Wang", "Quan Gan", "Minjie Wang", "Qibin Yang", "David Wipf", "Muhan Zhang"], "title": "Griffin: Towards a Graph-Centric Relational Database Foundation Model", "categories": ["cs.LG", "cs.AI", "cs.DB"], "comment": null, "summary": "We introduce Griffin, the first foundation model attemptation designed\nspecifically for Relational Databases (RDBs). Unlike previous smaller models\nfocused on single RDB tasks, Griffin unifies the data encoder and task decoder\nto handle diverse tasks. Additionally, we enhance the architecture by\nincorporating a cross-attention module and a novel aggregator. Griffin utilizes\npretraining on both single-table and RDB datasets, employing advanced encoders\nfor categorical, numerical, and metadata features, along with innovative\ncomponents such as cross-attention modules and enhanced message-passing neural\nnetworks (MPNNs) to capture the complexities of relational data. Evaluated on\nlarge-scale, heterogeneous, and temporal graphs extracted from RDBs across\nvarious domains (spanning over 150 million nodes), Griffin demonstrates\nsuperior or comparable performance to individually trained models, excels in\nlow-data scenarios, and shows strong transferability with similarity and\ndiversity in pretraining across new datasets and tasks, highlighting its\npotential as a universally applicable foundation model for RDBs. Code available\nat https://github.com/yanxwb/Griffin."}
{"id": "2503.05383", "pdf": "https://arxiv.org/pdf/2503.05383", "abs": "https://arxiv.org/abs/2503.05383", "authors": ["Weiyu Ma", "Yuqian Fu", "Zecheng Zhang", "Bernard Ghanem", "Guohao Li"], "title": "AVA: Attentive VLM Agent for Mastering StarCraft II", "categories": ["cs.AI", "cs.MA"], "comment": "Under Review", "summary": "We introduce Attentive VLM Agent (AVA), a multimodal StarCraft II agent that\naligns artificial agent perception with the human gameplay experience.\nTraditional frameworks such as SMAC rely on abstract state representations that\ndiverge significantly from human perception, limiting the ecological validity\nof agent behavior. Our agent addresses this limitation by incorporating RGB\nvisual inputs and natural language observations that more closely simulate\nhuman cognitive processes during gameplay. The AVA architecture consists of\nthree integrated components: (1) a vision-language model enhanced with\nspecialized self-attention mechanisms for strategic unit targeting and\nbattlefield assessment, (2) a retrieval-augmented generation system that\nleverages domain-specific StarCraft II knowledge to inform tactical decisions,\nand (3) a dynamic role-based task distribution system that enables coordinated\nmulti-agent behavior. The experimental evaluation in our proposed AVACraft\nenvironment, which contains 21 multimodal StarCraft II scenarios, demonstrates\nthat AVA powered by foundation models (specifically Qwen-VL and GPT-4o) can\nexecute complex tactical maneuvers without explicit training, achieving\ncomparable performance to traditional MARL methods that require substantial\ntraining iterations. This work establishes a foundation for developing\nhuman-aligned StarCraft II agents and advances the broader research agenda of\nmultimodal game AI. Our implementation is available at\nhttps://github.com/camel-ai/VLM-Play-StarCraft2."}
{"id": "2505.05689", "pdf": "https://arxiv.org/pdf/2505.05689", "abs": "https://arxiv.org/abs/2505.05689", "authors": ["Fuyao Chen", "Yuexi Du", "Tal Zeevi", "Nicha C. Dvornek", "John A. Onofrey"], "title": "Equivariant Imaging Biomarkers for Robust Unsupervised Segmentation of Histopathology", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "Accepted by MIDL 2025", "summary": "Histopathology evaluation of tissue specimens through microscopic examination\nis essential for accurate disease diagnosis and prognosis. However, traditional\nmanual analysis by specially trained pathologists is time-consuming,\nlabor-intensive, cost-inefficient, and prone to inter-rater variability,\npotentially affecting diagnostic consistency and accuracy. As digital pathology\nimages continue to proliferate, there is a pressing need for automated analysis\nto address these challenges. Recent advancements in artificial\nintelligence-based tools such as machine learning (ML) models, have\nsignificantly enhanced the precision and efficiency of analyzing\nhistopathological slides. However, despite their impressive performance, ML\nmodels are invariant only to translation, lacking invariance to rotation and\nreflection. This limitation restricts their ability to generalize effectively,\nparticularly in histopathology, where images intrinsically lack meaningful\norientation. In this study, we develop robust, equivariant histopathological\nbiomarkers through a novel symmetric convolutional kernel via unsupervised\nsegmentation. The approach is validated using prostate tissue micro-array (TMA)\nimages from 50 patients in the Gleason 2019 Challenge public dataset. The\nbiomarkers extracted through this approach demonstrate enhanced robustness and\ngeneralizability against rotation compared to models using standard convolution\nkernels, holding promise for enhancing the accuracy, consistency, and\nrobustness of ML models in digital pathology. Ultimately, this work aims to\nimprove diagnostic and prognostic capabilities of histopathology beyond\nprostate cancer through equivariant imaging."}
{"id": "2505.05947", "pdf": "https://arxiv.org/pdf/2505.05947", "abs": "https://arxiv.org/abs/2505.05947", "authors": ["Bianca Steffes", "Nils Torben Wiedemann", "Alexander Gratz", "Pamela Hochreither", "Jana Elina Meyer", "Katharina Luise Schilke"], "title": "Summarisation of German Judgments in conjunction with a Class-based Evaluation", "categories": ["cs.CL"], "comment": null, "summary": "The automated summarisation of long legal documents can be a great aid for\nlegal experts in their daily work. We automatically create summaries (guiding\nprinciples) of German judgments by fine-tuning a decoder-based large language\nmodel. We enrich the judgments with information about legal entities before the\ntraining. For the evaluation of the created summaries, we define a set of\nevaluation classes which allows us to measure their language, pertinence,\ncompleteness and correctness. Our results show that employing legal entities\nhelps the generative model to find the relevant content, but the quality of the\ncreated summaries is not yet sufficient for a use in practice."}
{"id": "2505.05880", "pdf": "https://arxiv.org/pdf/2505.05880", "abs": "https://arxiv.org/abs/2505.05880", "authors": ["Bettina Fazzinga", "Sergio Flesca", "Filippo Furfaro", "Luigi Pontieri", "Francesco Scala"], "title": "Combining Abstract Argumentation and Machine Learning for Efficiently Analyzing Low-Level Process Event Streams", "categories": ["cs.AI"], "comment": null, "summary": "Monitoring and analyzing process traces is a critical task for modern\ncompanies and organizations. In scenarios where there is a gap between trace\nevents and reference business activities, this entails an interpretation\nproblem, amounting to translating each event of any ongoing trace into the\ncorresponding step of the activity instance. Building on a recent approach that\nframes the interpretation problem as an acceptance problem within an Abstract\nArgumentation Framework (AAF), one can elegantly analyze plausible event\ninterpretations (possibly in an aggregated form), as well as offer explanations\nfor those that conflict with prior process knowledge. Since, in settings where\nevent-to-activity mapping is highly uncertain (or simply under-specified) this\nreasoning-based approach may yield lowly-informative results and heavy\ncomputation, one can think of discovering a sequencetagging model, trained to\nsuggest highly-probable candidate event interpretations in a context-aware way.\nHowever, training such a model optimally may require using a large amount of\nmanually-annotated example traces. Considering the urgent need of developing\nGreen AI solutions enabling environmental and societal sustainability (with\nreduced labor/computational costs and carbon footprint), we propose a\ndata/computation-efficient neuro-symbolic approach to the problem, where the\ncandidate interpretations returned by the example-driven sequence tagger is\nrefined by the AAF-based reasoner. This allows us to also leverage prior\nknowledge to compensate for the scarcity of example data, as confirmed by\nexperimental results; clearly, this property is particularly useful in settings\nwhere data annotation and model optimization costs are subject to stringent\nconstraints."}
{"id": "2505.05512", "pdf": "https://arxiv.org/pdf/2505.05512", "abs": "https://arxiv.org/abs/2505.05512", "authors": ["Zhang Zhang", "Qiang Zhang", "Wei Cui", "Shuai Shi", "Yijie Guo", "Gang Han", "Wen Zhao", "Jingkai Sun", "Jiahang Cao", "Jiaxu Wang", "Hao Cheng", "Xiaozhu Ju", "Zhengping Che", "Renjing Xu", "Jian Tang"], "title": "Occupancy World Model for Robots", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Understanding and forecasting the scene evolutions deeply affect the\nexploration and decision of embodied agents. While traditional methods simulate\nscene evolutions through trajectory prediction of potential instances, current\nworks use the occupancy world model as a generative framework for describing\nfine-grained overall scene dynamics. However, existing methods cluster on the\noutdoor structured road scenes, while ignoring the exploration of forecasting\n3D occupancy scene evolutions for robots in indoor scenes. In this work, we\nexplore a new framework for learning the scene evolutions of observed\nfine-grained occupancy and propose an occupancy world model based on the\ncombined spatio-temporal receptive field and guided autoregressive transformer\nto forecast the scene evolutions, called RoboOccWorld. We propose the\nConditional Causal State Attention (CCSA), which utilizes camera poses of next\nstate as conditions to guide the autoregressive transformer to adapt and\nunderstand the indoor robotics scenarios. In order to effectively exploit the\nspatio-temporal cues from historical observations, Hybrid Spatio-Temporal\nAggregation (HSTA) is proposed to obtain the combined spatio-temporal receptive\nfield based on multi-scale spatio-temporal windows. In addition, we restructure\nthe OccWorld-ScanNet benchmark based on local annotations to facilitate the\nevaluation of the indoor 3D occupancy scene evolution prediction task.\nExperimental results demonstrate that our RoboOccWorld outperforms\nstate-of-the-art methods in indoor 3D occupancy scene evolution prediction\ntask. The code will be released soon."}
{"id": "2505.05577", "pdf": "https://arxiv.org/pdf/2505.05577", "abs": "https://arxiv.org/abs/2505.05577", "authors": ["Alejandro Velez-Arce", "Marinka Zitnik"], "title": "PyTDC: A multimodal machine learning training, evaluation, and inference platform for biomedical foundation models", "categories": ["cs.LG", "cs.AI", "68-04, 92-04", "D.2.11; I.2.5; J.3"], "comment": "Proceedings of the 42nd International Conference on Machine Learning,\n  Vancouver, Canada. PMLR 267, 2025", "summary": "Existing biomedical benchmarks do not provide end-to-end infrastructure for\ntraining, evaluation, and inference of models that integrate multimodal\nbiological data and a broad range of machine learning tasks in therapeutics. We\npresent PyTDC, an open-source machine-learning platform providing streamlined\ntraining, evaluation, and inference software for multimodal biological AI\nmodels. PyTDC unifies distributed, heterogeneous, continuously updated data\nsources and model weights and standardizes benchmarking and inference\nendpoints. This paper discusses the components of PyTDC's architecture and, to\nour knowledge, the first-of-its-kind case study on the introduced single-cell\ndrug-target nomination ML task. We find state-of-the-art methods in graph\nrepresentation learning and domain-specific methods from graph theory perform\npoorly on this task. Though we find a context-aware geometric deep learning\nmethod that outperforms the evaluated SoTA and domain-specific baseline\nmethods, the model is unable to generalize to unseen cell types or incorporate\nadditional modalities, highlighting PyTDC's capacity to facilitate an exciting\navenue of research developing multimodal, context-aware, foundation models for\nopen problems in biomedical AI."}
{"id": "2503.14226", "pdf": "https://arxiv.org/pdf/2503.14226", "abs": "https://arxiv.org/abs/2503.14226", "authors": ["Huaifeng Zhang", "Ahmed Ali-Eldin"], "title": "The Hidden Bloat in Machine Learning Systems", "categories": ["cs.SE", "cs.MA"], "comment": null, "summary": "Software bloat refers to code and features that is not used by a software\nduring runtime. For Machine Learning (ML) systems, bloat is a major contributor\nto their technical debt leading to decreased performance and resource wastage.\nIn this work, we present, Negativa-ML, a novel tool to identify and remove\nbloat in ML frameworks by analyzing their shared libraries. Our approach\nincludes novel techniques to detect and locate unnecessary code within device\ncode - a key area overlooked by existing research, which focuses primarily on\nhost code. We evaluate Negativa-ML using four popular ML frameworks across ten\nworkloads over 300 shared libraries. The results demonstrate that the ML\nframeworks are highly bloated on both the device and host code side. On\naverage, Negativa-ML reduces the device code size in these frameworks by up to\n75% and the host code by up to 72%, resulting in total file size reductions of\nup to 55%. The device code is a primary source of bloat within ML frameworks.\nThrough debloating, we achieve reductions in peak host memory usage, peak GPU\nmemory usage, and execution time by up to 74.6%, 69.6%, and 44.6%,\nrespectively."}
{"id": "2505.05703", "pdf": "https://arxiv.org/pdf/2505.05703", "abs": "https://arxiv.org/abs/2505.05703", "authors": ["Haoyang Pei", "Ding Xia", "Xiang Xu", "William Moore", "Yao Wang", "Hersh Chandarana", "Li Feng"], "title": "Hybrid Learning: A Novel Combination of Self-Supervised and Supervised Learning for MRI Reconstruction without High-Quality Training Reference", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Purpose: Deep learning has demonstrated strong potential for MRI\nreconstruction, but conventional supervised learning methods require\nhigh-quality reference images, which are often unavailable in practice.\nSelf-supervised learning offers an alternative, yet its performance degrades at\nhigh acceleration rates. To overcome these limitations, we propose hybrid\nlearning, a novel two-stage training framework that combines self-supervised\nand supervised learning for robust image reconstruction.\n  Methods: Hybrid learning is implemented in two sequential stages. In the\nfirst stage, self-supervised learning is employed to generate improved images\nfrom noisy or undersampled reference data. These enhanced images then serve as\npseudo-ground truths for the second stage, which uses supervised learning to\nrefine reconstruction performance and support higher acceleration rates. We\nevaluated hybrid learning in two representative applications: (1) accelerated\n0.55T spiral-UTE lung MRI using noisy reference data, and (2) 3D T1 mapping of\nthe brain without access to fully sampled ground truth.\n  Results: For spiral-UTE lung MRI, hybrid learning consistently improved image\nquality over both self-supervised and conventional supervised methods across\ndifferent acceleration rates, as measured by SSIM and NMSE. For 3D T1 mapping,\nhybrid learning achieved superior T1 quantification accuracy across a wide\ndynamic range, outperforming self-supervised learning in all tested conditions.\n  Conclusions: Hybrid learning provides a practical and effective solution for\ntraining deep MRI reconstruction networks when only low-quality or incomplete\nreference data are available. It enables improved image quality and accurate\nquantitative mapping across different applications and field strengths,\nrepresenting a promising technique toward broader clinical deployment of deep\nlearning-based MRI."}
{"id": "2505.05949", "pdf": "https://arxiv.org/pdf/2505.05949", "abs": "https://arxiv.org/abs/2505.05949", "authors": ["Max Glockner", "Xiang Jiang", "Leonardo F. R. Ribeiro", "Iryna Gurevych", "Markus Dreyer"], "title": "NeoQA: Evidence-based Question Answering with Generated News Events", "categories": ["cs.CL"], "comment": null, "summary": "Evaluating Retrieval-Augmented Generation (RAG) in large language models\n(LLMs) is challenging because benchmarks can quickly become stale. Questions\ninitially requiring retrieval may become answerable from pretraining knowledge\nas newer models incorporate more recent information during pretraining, making\nit difficult to distinguish evidence-based reasoning from recall. We introduce\nNeoQA (News Events for Out-of-training Question Answering), a benchmark\ndesigned to address this issue. To construct NeoQA, we generated timelines and\nknowledge bases of fictional news events and entities along with news articles\nand Q\\&A pairs to prevent LLMs from leveraging pretraining knowledge, ensuring\nthat no prior evidence exists in their training data. We propose our dataset as\na new platform for evaluating evidence-based question answering, as it requires\nLLMs to generate responses exclusively from retrieved evidence and only when\nsufficient evidence is available. NeoQA enables controlled evaluation across\nvarious evidence scenarios, including cases with missing or misleading details.\nOur findings indicate that LLMs struggle to distinguish subtle mismatches\nbetween questions and evidence, and suffer from short-cut reasoning when key\ninformation required to answer a question is missing from the evidence,\nunderscoring key limitations in evidence-based reasoning."}
{"id": "2505.05976", "pdf": "https://arxiv.org/pdf/2505.05976", "abs": "https://arxiv.org/abs/2505.05976", "authors": ["Chico Sundermann", "Stefan Vill", "Elias Kuiter", "Sebastian Krieter", "Thomas Thüm", "Matthias Tichy"], "title": "Pseudo-Boolean d-DNNF Compilation for Expressive Feature Modeling Constructs", "categories": ["cs.AI", "cs.LO", "cs.SE"], "comment": null, "summary": "Configurable systems typically consist of reusable assets that have\ndependencies between each other. To specify such dependencies, feature models\nare commonly used. As feature models in practice are often complex, automated\nreasoning is typically employed to analyze the dependencies. Here, the de facto\nstandard is translating the feature model to conjunctive normal form (CNF) to\nenable employing off-the-shelf tools, such as SAT or #SAT solvers. However,\nmodern feature-modeling dialects often contain constructs, such as cardinality\nconstraints, that are ill-suited for conversion to CNF. This mismatch between\nthe input of reasoning engines and the available feature-modeling dialects\nlimits the applicability of the more expressive constructs. In this work, we\nshorten this gap between expressive constructs and scalable automated\nreasoning. Our contribution is twofold: First, we provide a pseudo-Boolean\nencoding for feature models, which facilitates smaller representations of\ncommonly employed constructs compared to Boolean encoding. Second, we propose a\nnovel method to compile pseudo-Boolean formulas to Boolean d-DNNF. With the\ncompiled d-DNNFs, we can resort to a plethora of efficient analyses already\nused in feature modeling. Our empirical evaluation shows that our proposal\nsubstantially outperforms the state-of-the-art based on CNF inputs for\nexpressive constructs. For every considered dataset representing different\nfeature models and feature-modeling constructs, the feature models can be\nsignificantly faster translated to pseudo-Boolean than to CNF. Overall,\nderiving d-DNNFs from a feature model with the targeted expressive constraints\ncan be substantially accelerated using our pseudo-Boolean approach.\nFurthermore, our approach is competitive on feature models with only basic\nconstructs."}
{"id": "2505.05513", "pdf": "https://arxiv.org/pdf/2505.05513", "abs": "https://arxiv.org/abs/2505.05513", "authors": ["Muhammad Junaid Asif", "Hamza Khan", "Rabia Tehseen", "Syed Tahir Hussain Rizvi", "Mujtaba Asad", "Shazia Saqib", "Rana Fayyaz Ahmad"], "title": "Exploring Convolutional Neural Networks for Rice Grain Classification: An Explainable AI Approach", "categories": ["cs.CV"], "comment": null, "summary": "Rice is an essential staple food worldwide that is important in promoting\ninternational trade, economic growth, and nutrition. Asian countries such as\nChina, India, Pakistan, Thailand, Vietnam, and Indonesia are notable for their\nsignificant contribution to the cultivation and utilization of rice. These\nnations are also known for cultivating different rice grains, including short\nand long grains. These sizes are further classified as basmati, jasmine, kainat\nsaila, ipsala, arborio, etc., catering to diverse culinary preferences and\ncultural traditions. For both local and international trade, inspecting and\nmaintaining the quality of rice grains to satisfy customers and preserve a\ncountry's reputation is necessary. Manual quality check and classification is\nquite a laborious and time-consuming process. It is also highly prone to\nmistakes. Therefore, an automatic solution must be proposed for the effective\nand efficient classification of different varieties of rice grains. This\nresearch paper presents an automatic framework based on a convolutional neural\nnetwork (CNN) for classifying different varieties of rice grains. We evaluated\nthe proposed model based on performance metrics such as accuracy, recall,\nprecision, and F1-Score. The CNN model underwent rigorous training and\nvalidation, achieving a remarkable accuracy rate and a perfect area under each\nclass's Receiver Operating Characteristic (ROC) curve. The confusion matrix\nanalysis confirmed the model's effectiveness in distinguishing between the\ndifferent rice varieties, indicating minimal misclassifications. Additionally,\nthe integration of explainability techniques such as LIME (Local Interpretable\nModel-agnostic Explanations) and SHAP (SHapley Additive exPlanations) provided\nvaluable insights into the model's decision-making process, revealing how\nspecific features of the rice grains influenced classification outcomes."}
{"id": "2505.05594", "pdf": "https://arxiv.org/pdf/2505.05594", "abs": "https://arxiv.org/abs/2505.05594", "authors": ["Sura Alhanouti", "Parinaz Naghizadeh"], "title": "Anticipating Gaming to Incentivize Improvement: Guiding Agents in (Fair) Strategic Classification", "categories": ["cs.LG"], "comment": "31 pages, 12 figures", "summary": "As machine learning algorithms increasingly influence critical decision\nmaking in different application areas, understanding human strategic behavior\nin response to these systems becomes vital. We explore individuals' choice\nbetween genuinely improving their qualifications (``improvement'') vs.\nattempting to deceive the algorithm by manipulating their features\n(``manipulation'') in response to an algorithmic decision system. We further\ninvestigate an algorithm designer's ability to shape these strategic responses,\nand its fairness implications. Specifically, we formulate these interactions as\na Stackelberg game, where a firm deploys a (fair) classifier, and individuals\nstrategically respond. Our model incorporates both different costs and\nstochastic efficacy for manipulation and improvement. The analysis reveals\ndifferent potential classes of agent responses, and characterizes optimal\nclassifiers accordingly. Based on these, we highlight the impact of the firm's\nanticipation of strategic behavior, identifying when and why a (fair) strategic\npolicy can not only prevent manipulation, but also incentivize agents to opt\nfor improvement."}
{"id": "2504.12345", "pdf": "https://arxiv.org/pdf/2504.12345", "abs": "https://arxiv.org/abs/2504.12345", "authors": ["Yutong Xia", "Ao Qu", "Yunhan Zheng", "Yihong Tang", "Dingyi Zhuang", "Yuxuan Liang", "Shenhao Wang", "Cathy Wu", "Lijun Sun", "Roger Zimmermann", "Jinhua Zhao"], "title": "Reimagining Urban Science: Scaling Causal Inference with Large Language Models", "categories": ["cs.CL", "cs.CY", "cs.MA"], "comment": null, "summary": "Urban causal research is essential for understanding the complex dynamics of\ncities and informing evidence-based policies. However, it is challenged by the\ninefficiency and bias of hypothesis generation, barriers to multimodal data\ncomplexity, and the methodological fragility of causal experimentation. Recent\nadvances in large language models (LLMs) present an opportunity to rethink how\nurban causal analysis is conducted. This Perspective examines current urban\ncausal research by analyzing taxonomies that categorize research topics, data\nsources, and methodological approaches to identify structural gaps. We then\nintroduce an LLM-driven conceptual framework, AutoUrbanCI, composed of four\ndistinct modular agents responsible for hypothesis generation, data\nengineering, experiment design and execution, and results interpretation with\npolicy recommendations. We propose evaluation criteria for rigor and\ntransparency and reflect on implications for human-AI collaboration, equity,\nand accountability. We call for a new research agenda that embraces\nAI-augmented workflows not as replacements for human expertise but as tools to\nbroaden participation, improve reproducibility, and unlock more inclusive forms\nof urban causal reasoning."}
{"id": "2505.05745", "pdf": "https://arxiv.org/pdf/2505.05745", "abs": "https://arxiv.org/abs/2505.05745", "authors": ["Bingan Yuan", "Bowei Liu", "Zheng Fang"], "title": "ProTCT: Projection quantification and fidelity constraint integrated deep reconstruction for Tangential CT", "categories": ["eess.IV"], "comment": null, "summary": "Tangential computed tomography (TCT) is a useful tool for imaging the\nlarge-diameter samples, such as oil pipelines and rockets. However, TCT\nprojections are truncated along the detector direction, resulting in degraded\nslices with radial artifacts. Meanwhile, existing methods fail to reconstruct\ndecent images because of the ill-defined sampling condition in the projection\ndomain and oversmoothing in the cross-section domain. In this paper, we propose\na projection quantification and fidelity constraint integrated deep TCT\nreconstruction method (ProTCT) to improve the slice quality. Specifically, the\nsampling conditions for reconstruction are analysed, offering practical\nguidelines for TCT system design. Besides, a deep artifact-suppression network\ntogether with a fidelity-constraint module that operates across both projection\nand cross-section domains to remove artifacts and restore edge details.\nDemonstrated on simulated and real datasets, the ProTCT shows good performance\nin structure restoration and detail retention. This work contributes to\nexploring the sampling condition and improving the slice quality of TCT,\nfurther promoting the application of large view field CT imaging."}
{"id": "2505.05970", "pdf": "https://arxiv.org/pdf/2505.05970", "abs": "https://arxiv.org/abs/2505.05970", "authors": ["Lennart Stöpler", "Rufat Asadli", "Mitja Nikolaus", "Ryan Cotterell", "Alex Warstadt"], "title": "Towards Developmentally Plausible Rewards: Communicative Success as a Learning Signal for Interactive Language Models", "categories": ["cs.CL"], "comment": null, "summary": "We propose a method for training language models in an interactive setting\ninspired by child language acquisition. In our setting, a speaker attempts to\ncommunicate some information to a listener in a single-turn dialogue and\nreceives a reward if communicative success is achieved. Unlike earlier related\nwork using image--caption data for interactive reference games, we\noperationalize communicative success in a more abstract language-only\nquestion--answering setting. First, we present a feasibility study\ndemonstrating that our reward provides an indirect signal about grammaticality.\nSecond, we conduct experiments using reinforcement learning to fine-tune\nlanguage models. We observe that cognitively plausible constraints on the\ncommunication channel lead to interpretable changes in speaker behavior.\nHowever, we do not yet see improvements on linguistic evaluations from our\ntraining regime. We outline potential modifications to the task design and\ntraining configuration that could better position future work to use our\nmethodology to observe the benefits of interaction on language learning in\ncomputational cognitive models."}
{"id": "2505.06020", "pdf": "https://arxiv.org/pdf/2505.06020", "abs": "https://arxiv.org/abs/2505.06020", "authors": ["Shuai Wang", "Ivona Najdenkoska", "Hongyi Zhu", "Stevan Rudinac", "Monika Kackovic", "Nachoem Wijnberg", "Marcel Worring"], "title": "ArtRAG: Retrieval-Augmented Generation with Structured Context for Visual Art Understanding", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Understanding visual art requires reasoning across multiple perspectives --\ncultural, historical, and stylistic -- beyond mere object recognition. While\nrecent multimodal large language models (MLLMs) perform well on general image\ncaptioning, they often fail to capture the nuanced interpretations that fine\nart demands. We propose ArtRAG, a novel, training-free framework that combines\nstructured knowledge with retrieval-augmented generation (RAG) for\nmulti-perspective artwork explanation. ArtRAG automatically constructs an Art\nContext Knowledge Graph (ACKG) from domain-specific textual sources, organizing\nentities such as artists, movements, themes, and historical events into a rich,\ninterpretable graph. At inference time, a multi-granular structured retriever\nselects semantically and topologically relevant subgraphs to guide generation.\nThis enables MLLMs to produce contextually grounded, culturally informed art\ndescriptions. Experiments on the SemArt and Artpedia datasets show that ArtRAG\noutperforms several heavily trained baselines. Human evaluations further\nconfirm that ArtRAG generates coherent, insightful, and culturally enriched\ninterpretations."}
{"id": "2505.05517", "pdf": "https://arxiv.org/pdf/2505.05517", "abs": "https://arxiv.org/abs/2505.05517", "authors": ["Hongyi Chen", "Yunchao Yao", "Yufei Ye", "Zhixuan Xu", "Homanga Bharadhwaj", "Jiashun Wang", "Shubham Tulsiani", "Zackory Erickson", "Jeffrey Ichnowski"], "title": "Web2Grasp: Learning Functional Grasps from Web Images of Hand-Object Interactions", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "Functional grasp is essential for enabling dexterous multi-finger robot hands\nto manipulate objects effectively. However, most prior work either focuses on\npower grasping, which simply involves holding an object still, or relies on\ncostly teleoperated robot demonstrations to teach robots how to grasp each\nobject functionally. Instead, we propose extracting human grasp information\nfrom web images since they depict natural and functional object interactions,\nthereby bypassing the need for curated demonstrations. We reconstruct human\nhand-object interaction (HOI) 3D meshes from RGB images, retarget the human\nhand to multi-finger robot hands, and align the noisy object mesh with its\naccurate 3D shape. We show that these relatively low-quality HOI data from\ninexpensive web sources can effectively train a functional grasping model. To\nfurther expand the grasp dataset for seen and unseen objects, we use the\ninitially-trained grasping policy with web data in the IsaacGym simulator to\ngenerate physically feasible grasps while preserving functionality. We train\nthe grasping model on 10 object categories and evaluate it on 9 unseen objects,\nincluding challenging items such as syringes, pens, spray bottles, and tongs,\nwhich are underrepresented in existing datasets. The model trained on the web\nHOI dataset, achieving a 75.8% success rate on seen objects and 61.8% across\nall objects in simulation, with a 6.7% improvement in success rate and a 1.8x\nincrease in functionality ratings over baselines. Simulator-augmented data\nfurther boosts performance from 61.8% to 83.4%. The sim-to-real transfer to the\nLEAP Hand achieves a 85% success rate. Project website is at:\nhttps://webgrasp.github.io/."}
{"id": "2505.05597", "pdf": "https://arxiv.org/pdf/2505.05597", "abs": "https://arxiv.org/abs/2505.05597", "authors": ["Jacek Karolczak", "Jerzy Stefanowski"], "title": "This part looks alike this: identifying important parts of explained instances and prototypes", "categories": ["cs.LG"], "comment": null, "summary": "Although prototype-based explanations provide a human-understandable way of\nrepresenting model predictions they often fail to direct user attention to the\nmost relevant features. We propose a novel approach to identify the most\ninformative features within prototypes, termed alike parts. Using feature\nimportance scores derived from an agnostic explanation method, it emphasizes\nthe most relevant overlapping features between an instance and its nearest\nprototype. Furthermore, the feature importance score is incorporated into the\nobjective function of the prototype selection algorithms to promote global\nprototypes diversity. Through experiments on six benchmark datasets, we\ndemonstrate that the proposed approach improves user comprehension while\nmaintaining or even increasing predictive accuracy."}
{"id": "2505.05768", "pdf": "https://arxiv.org/pdf/2505.05768", "abs": "https://arxiv.org/abs/2505.05768", "authors": ["Weiyi Zhang", "Peranut Chotcomwongse", "Yinwen Li", "Pusheng Xu", "Ruijie Yao", "Lianhao Zhou", "Yuxuan Zhou", "Hui Feng", "Qiping Zhou", "Xinyue Wang", "Shoujin Huang", "Zihao Jin", "Florence H. T. Chung", "Shujun Wang", "Yalin Zheng", "Mingguang He", "Danli Shi", "Paisan Ruamviboonsuk"], "title": "Predicting Diabetic Macular Edema Treatment Responses Using OCT: Dataset and Methods of APTOS Competition", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "42 pages,5 tables, 12 figures, challenge report", "summary": "Diabetic macular edema (DME) significantly contributes to visual impairment\nin diabetic patients. Treatment responses to intravitreal therapies vary,\nhighlighting the need for patient stratification to predict therapeutic\nbenefits and enable personalized strategies. To our knowledge, this study is\nthe first to explore pre-treatment stratification for predicting DME treatment\nresponses. To advance this research, we organized the 2nd Asia-Pacific\nTele-Ophthalmology Society (APTOS) Big Data Competition in 2021. The\ncompetition focused on improving predictive accuracy for anti-VEGF therapy\nresponses using ophthalmic OCT images. We provided a dataset containing tens of\nthousands of OCT images from 2,000 patients with labels across four sub-tasks.\nThis paper details the competition's structure, dataset, leading methods, and\nevaluation metrics. The competition attracted strong scientific community\nparticipation, with 170 teams initially registering and 41 reaching the final\nround. The top-performing team achieved an AUC of 80.06%, highlighting the\npotential of AI in personalized DME treatment and clinical decision-making."}
{"id": "2505.05973", "pdf": "https://arxiv.org/pdf/2505.05973", "abs": "https://arxiv.org/abs/2505.05973", "authors": ["M. Maziyah Mohamed", "R. H. Baayen"], "title": "An Exploratory Analysis on the Explanatory Potential of Embedding-Based Measures of Semantic Transparency for Malay Word Recognition", "categories": ["cs.CL"], "comment": "24 pages, 5 figures, and 9 tables. Submitted to the Journal of\n  Morphology", "summary": "Studies of morphological processing have shown that semantic transparency is\ncrucial for word recognition. Its computational operationalization is still\nunder discussion. Our primary objectives are to explore embedding-based\nmeasures of semantic transparency, and assess their impact on reading. First,\nwe explored the geometry of complex words in semantic space. To do so, we\nconducted a t-distributed Stochastic Neighbor Embedding clustering analysis on\n4,226 Malay prefixed words. Several clusters were observed for complex words\nvaried by their prefix class. Then, we derived five simple measures, and\ninvestigated whether they were significant predictors of lexical decision\nlatencies. Two sets of Linear Discriminant Analyses were run in which the\nprefix of a word is predicted from either word embeddings or shift vectors\n(i.e., a vector subtraction of the base word from the derived word). The\naccuracy with which the model predicts the prefix of a word indicates the\ndegree of transparency of the prefix. Three further measures were obtained by\ncomparing embeddings between each word and all other words containing the same\nprefix (i.e., centroid), between each word and the shift from their base word,\nand between each word and the predicted word of the Functional Representations\nof Affixes in Compositional Semantic Space model. In a series of Generalized\nAdditive Mixed Models, all measures predicted decision latencies after\naccounting for word frequency, word length, and morphological family size. The\nmodel that included the correlation between each word and their centroid as a\npredictor provided the best fit to the data."}
{"id": "2505.06030", "pdf": "https://arxiv.org/pdf/2505.06030", "abs": "https://arxiv.org/abs/2505.06030", "authors": ["Tobias Preintner", "Weixuan Yuan", "Qi Huang", "Adrian König", "Thomas Bäck", "Elena Raponi", "Niki van Stein"], "title": "Why Are You Wrong? Counterfactual Explanations for Language Grounding with 3D Objects", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": "Accepted at IJCNN 2025", "summary": "Combining natural language and geometric shapes is an emerging research area\nwith multiple applications in robotics and language-assisted design. A crucial\ntask in this domain is object referent identification, which involves selecting\na 3D object given a textual description of the target. Variability in language\ndescriptions and spatial relationships of 3D objects makes this a complex task,\nincreasing the need to better understand the behavior of neural network models\nin this domain. However, limited research has been conducted in this area.\nSpecifically, when a model makes an incorrect prediction despite being provided\nwith a seemingly correct object description, practitioners are left wondering:\n\"Why is the model wrong?\". In this work, we present a method answering this\nquestion by generating counterfactual examples. Our method takes a\nmisclassified sample, which includes two objects and a text description, and\ngenerates an alternative yet similar formulation that would have resulted in a\ncorrect prediction by the model. We have evaluated our approach with data from\nthe ShapeTalk dataset along with three distinct models. Our counterfactual\nexamples maintain the structure of the original description, are semantically\nsimilar and meaningful. They reveal weaknesses in the description, model bias\nand enhance the understanding of the models behavior. Theses insights help\npractitioners to better interact with systems as well as engineers to improve\nmodels."}
{"id": "2505.05519", "pdf": "https://arxiv.org/pdf/2505.05519", "abs": "https://arxiv.org/abs/2505.05519", "authors": ["Minkyu Choi", "Yunhao Yang", "Neel P. Bhatt", "Kushagra Gupta", "Sahil Shah", "Aditya Rai", "David Fridovich-Keil", "Ufuk Topcu", "Sandeep P. Chinchali"], "title": "Real-Time Privacy Preservation for Robot Visual Perception", "categories": ["cs.CV"], "comment": null, "summary": "Many robots (e.g., iRobot's Roomba) operate based on visual observations from\nlive video streams, and such observations may inadvertently include\nprivacy-sensitive objects, such as personal identifiers. Existing approaches\nfor preserving privacy rely on deep learning models, differential privacy, or\ncryptography. They lack guarantees for the complete concealment of all\nsensitive objects. Guaranteeing concealment requires post-processing techniques\nand thus is inadequate for real-time video streams. We develop a method for\nprivacy-constrained video streaming, PCVS, that conceals sensitive objects\nwithin real-time video streams. PCVS takes a logical specification constraining\nthe existence of privacy-sensitive objects, e.g., never show faces when a\nperson exists. It uses a detection model to evaluate the existence of these\nobjects in each incoming frame. Then, it blurs out a subset of objects such\nthat the existence of the remaining objects satisfies the specification. We\nthen propose a conformal prediction approach to (i) establish a theoretical\nlower bound on the probability of the existence of these objects in a sequence\nof frames satisfying the specification and (ii) update the bound with the\narrival of each subsequent frame. Quantitative evaluations show that PCVS\nachieves over 95 percent specification satisfaction rate in multiple datasets,\nsignificantly outperforming other methods. The satisfaction rate is\nconsistently above the theoretical bounds across all datasets, indicating that\nthe established bounds hold. Additionally, we deploy PCVS on robots in\nreal-time operation and show that the robots operate normally without being\ncompromised when PCVS conceals objects."}
{"id": "2505.05605", "pdf": "https://arxiv.org/pdf/2505.05605", "abs": "https://arxiv.org/abs/2505.05605", "authors": ["Andrew Qiu", "Shubham Barhate", "Hin Wai Lui", "Runze Su", "Rafael Rios Müller", "Kungang Li", "Ling Leng", "Han Sun", "Shayan Ehsani", "Zhifang Liu"], "title": "The Evolution of Embedding Table Optimization and Multi-Epoch Training in Pinterest Ads Conversion", "categories": ["cs.LG", "cs.CE", "cs.IR", "stat.AP", "F.2.2, I.2.7"], "comment": null, "summary": "Deep learning for conversion prediction has found widespread applications in\nonline advertising. These models have become more complex as they are trained\nto jointly predict multiple objectives such as click, add-to-cart, checkout and\nother conversion types. Additionally, the capacity and performance of these\nmodels can often be increased with the use of embedding tables that encode high\ncardinality categorical features such as advertiser, user, campaign, and\nproduct identifiers (IDs). These embedding tables can be pre-trained, but also\nlearned end-to-end jointly with the model to directly optimize the model\nobjectives. Training these large tables is challenging due to: gradient\nsparsity, the high cardinality of the categorical features, the non-uniform\ndistribution of IDs and the very high label sparsity. These issues make\ntraining prone to both slow convergence and overfitting after the first epoch.\nPrevious works addressed the multi-epoch overfitting issue by using: stronger\nfeature hashing to reduce cardinality, filtering of low frequency IDs,\nregularization of the embedding tables, re-initialization of the embedding\ntables after each epoch, etc. Some of these techniques reduce overfitting at\nthe expense of reduced model performance if used too aggressively. In this\npaper, we share key learnings from the development of embedding table\noptimization and multi-epoch training in Pinterest Ads Conversion models. We\nshowcase how our Sparse Optimizer speeds up convergence, and how multi-epoch\noverfitting varies in severity between different objectives in a multi-task\nmodel depending on label sparsity. We propose a new approach to deal with\nmulti-epoch overfitting: the use of a frequency-adaptive learning rate on the\nembedding tables and compare it to embedding re-initialization. We evaluate\nboth methods offline using an industrial large-scale production dataset."}
{"id": "2505.06105", "pdf": "https://arxiv.org/pdf/2505.06105", "abs": "https://arxiv.org/abs/2505.06105", "authors": ["Xilin Gong", "Yongkai Chen", "Shushan Wu", "Fang Wang", "Ping Ma", "Wenxuan Zhong"], "title": "S2MNet: Speckle-To-Mesh Net for Three-Dimensional Cardiac Morphology Reconstruction via Echocardiogram", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Echocardiogram is the most commonly used imaging modality in cardiac\nassessment duo to its non-invasive nature, real-time capability, and\ncost-effectiveness. Despite its advantages, most clinical echocardiograms\nprovide only two-dimensional views, limiting the ability to fully assess\ncardiac anatomy and function in three dimensions. While three-dimensional\nechocardiography exists, it often suffers from reduced resolution, limited\navailability, and higher acquisition costs. To overcome these challenges, we\npropose a deep learning framework S2MNet that reconstructs continuous and\nhigh-fidelity 3D heart models by integrating six slices of routinely acquired\n2D echocardiogram views. Our method has three advantages. First, our method\navoid the difficulties on training data acquasition by simulate six of 2D\nechocardiogram images from corresponding slices of a given 3D heart mesh.\nSecond, we introduce a deformation field-based method, which avoid spatial\ndiscontinuities or structural artifacts in 3D echocardiogram reconstructions.\nWe validate our method using clinically collected echocardiogram and\ndemonstrate that our estimated left ventricular volume, a key clinical\nindicator of cardiac function, is strongly correlated with the doctor measured\nGLPS, a clinical measurement that should demonstrate a negative correlation\nwith LVE in medical theory. This association confirms the reliability of our\nproposed 3D construction method."}
{"id": "2505.06004", "pdf": "https://arxiv.org/pdf/2505.06004", "abs": "https://arxiv.org/abs/2505.06004", "authors": ["Dawid Wisniewski", "Antoni Solarski", "Artur Nowakowski"], "title": "Exploring the Feasibility of Multilingual Grammatical Error Correction with a Single LLM up to 9B parameters: A Comparative Study of 17 Models", "categories": ["cs.CL"], "comment": "Accepted at MTSummit 2025 (The 20th Machine Translation Summit)", "summary": "Recent language models can successfully solve various language-related tasks,\nand many understand inputs stated in different languages. In this paper, we\nexplore the performance of 17 popular models used to correct grammatical issues\nin texts stated in English, German, Italian, and Swedish when using a single\nmodel to correct texts in all those languages. We analyze the outputs generated\nby these models, focusing on decreasing the number of grammatical errors while\nkeeping the changes small. The conclusions drawn help us understand what\nproblems occur among those models and which models can be recommended for\nmultilingual grammatical error correction tasks. We list six models that\nimprove grammatical correctness in all four languages and show that Gemma 9B is\ncurrently the best performing one for the languages considered."}
{"id": "2505.06049", "pdf": "https://arxiv.org/pdf/2505.06049", "abs": "https://arxiv.org/abs/2505.06049", "authors": ["Aleena Siji", "Joscha Cüppers", "Osman Ali Mian", "Jilles Vreeken"], "title": "Seqret: Mining Rule Sets from Event Sequences", "categories": ["cs.AI"], "comment": null, "summary": "Summarizing event sequences is a key aspect of data mining. Most existing\nmethods neglect conditional dependencies and focus on discovering sequential\npatterns only. In this paper, we study the problem of discovering both\nconditional and unconditional dependencies from event sequence data. We do so\nby discovering rules of the form $X \\rightarrow Y$ where $X$ and $Y$ are\nsequential patterns. Rules like these are simple to understand and provide a\nclear description of the relation between the antecedent and the consequent. To\ndiscover succinct and non-redundant sets of rules we formalize the problem in\nterms of the Minimum Description Length principle. As the search space is\nenormous and does not exhibit helpful structure, we propose the Seqret method\nto discover high-quality rule sets in practice. Through extensive empirical\nevaluation we show that unlike the state of the art, Seqret ably recovers the\nground truth on synthetic datasets and finds useful rules from real datasets."}
{"id": "2505.05520", "pdf": "https://arxiv.org/pdf/2505.05520", "abs": "https://arxiv.org/abs/2505.05520", "authors": ["Chengwei Ye", "Huanzhen Zhang", "Yufei Lin", "Kangsheng Wang", "Linuo Xu", "Shuyan Liu"], "title": "GaMNet: A Hybrid Network with Gabor Fusion and NMamba for Efficient 3D Glioma Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Gliomas are aggressive brain tumors that pose serious health risks. Deep\nlearning aids in lesion segmentation, but CNN and Transformer-based models\noften lack context modeling or demand heavy computation, limiting real-time use\non mobile medical devices. We propose GaMNet, integrating the NMamba module for\nglobal modeling and a multi-scale CNN for efficient local feature extraction.\nTo improve interpretability and mimic the human visual system, we apply Gabor\nfilters at multiple scales. Our method achieves high segmentation accuracy with\nfewer parameters and faster computation. Extensive experiments show GaMNet\noutperforms existing methods, notably reducing false positives and negatives,\nwhich enhances the reliability of clinical diagnosis."}
{"id": "2505.05609", "pdf": "https://arxiv.org/pdf/2505.05609", "abs": "https://arxiv.org/abs/2505.05609", "authors": ["Vasilis Pollatos", "Debmalya Mandal", "Goran Radanovic"], "title": "On Corruption-Robustness in Performative Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "In performative Reinforcement Learning (RL), an agent faces a\npolicy-dependent environment: the reward and transition functions depend on the\nagent's policy. Prior work on performative RL has studied the convergence of\nrepeated retraining approaches to a performatively stable policy. In the finite\nsample regime, these approaches repeatedly solve for a saddle point of a\nconvex-concave objective, which estimates the Lagrangian of a regularized\nversion of the reinforcement learning problem. In this paper, we aim to extend\nsuch repeated retraining approaches, enabling them to operate under corrupted\ndata. More specifically, we consider Huber's $\\epsilon$-contamination model,\nwhere an $\\epsilon$ fraction of data points is corrupted by arbitrary\nadversarial noise. We propose a repeated retraining approach based on\nconvex-concave optimization under corrupted gradients and a novel\nproblem-specific robust mean estimator for the gradients. We prove that our\napproach exhibits last-iterate convergence to an approximately stable policy,\nwith the approximation error linear in $\\sqrt{\\epsilon}$. We experimentally\ndemonstrate the importance of accounting for corruption in performative RL."}
{"id": "2505.06118", "pdf": "https://arxiv.org/pdf/2505.06118", "abs": "https://arxiv.org/abs/2505.06118", "authors": ["Jingguo Qu", "Xinyang Han", "Man-Lik Chui", "Yao Pu", "Simon Takadiyi Gunda", "Ziman Chen", "Jing Qin", "Ann Dorothy King", "Winnie Chiu-Wing Chu", "Jing Cai", "Michael Tin-Cheung Ying"], "title": "The Application of Deep Learning for Lymph Node Segmentation: A Systematic Review", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Automatic lymph node segmentation is the cornerstone for advances in computer\nvision tasks for early detection and staging of cancer. Traditional\nsegmentation methods are constrained by manual delineation and variability in\noperator proficiency, limiting their ability to achieve high accuracy. The\nintroduction of deep learning technologies offers new possibilities for\nimproving the accuracy of lymph node image analysis. This study evaluates the\napplication of deep learning in lymph node segmentation and discusses the\nmethodologies of various deep learning architectures such as convolutional\nneural networks, encoder-decoder networks, and transformers in analyzing\nmedical imaging data across different modalities. Despite the advancements, it\nstill confronts challenges like the shape diversity of lymph nodes, the\nscarcity of accurately labeled datasets, and the inadequate development of\nmethods that are robust and generalizable across different imaging modalities.\nTo the best of our knowledge, this is the first study that provides a\ncomprehensive overview of the application of deep learning techniques in lymph\nnode segmentation task. Furthermore, this study also explores potential future\nresearch directions, including multimodal fusion techniques, transfer learning,\nand the use of large-scale pre-trained models to overcome current limitations\nwhile enhancing cancer diagnosis and treatment planning strategies."}
{"id": "2505.06010", "pdf": "https://arxiv.org/pdf/2505.06010", "abs": "https://arxiv.org/abs/2505.06010", "authors": ["Dawid Wisniewski", "Mikolaj Pokrywka", "Zofia Rostek"], "title": "Do Not Change Me: On Transferring Entities Without Modification in Neural Machine Translation -- a Multilingual Perspective", "categories": ["cs.CL"], "comment": "Accepted at MTSummit 2025 (The 20th Machine Translation Summit)", "summary": "Current machine translation models provide us with high-quality outputs in\nmost scenarios. However, they still face some specific problems, such as\ndetecting which entities should not be changed during translation. In this\npaper, we explore the abilities of popular NMT models, including models from\nthe OPUS project, Google Translate, MADLAD, and EuroLLM, to preserve entities\nsuch as URL addresses, IBAN numbers, or emails when producing translations\nbetween four languages: English, German, Polish, and Ukrainian. We investigate\nthe quality of popular NMT models in terms of accuracy, discuss errors made by\nthe models, and examine the reasons for errors. Our analysis highlights\nspecific categories, such as emojis, that pose significant challenges for many\nmodels considered. In addition to the analysis, we propose a new multilingual\nsynthetic dataset of 36,000 sentences that can help assess the quality of\nentity transfer across nine categories and four aforementioned languages."}
{"id": "2505.06096", "pdf": "https://arxiv.org/pdf/2505.06096", "abs": "https://arxiv.org/abs/2505.06096", "authors": ["Sam Bush", "Matthew DeLorenzo", "Phat Tieu", "Jeyavijayan Rajendran"], "title": "Free and Fair Hardware: A Pathway to Copyright Infringement-Free Verilog Generation using LLMs", "categories": ["cs.AI"], "comment": "Accepted at DAC 2025", "summary": "Limitations in Large Language Model (LLM) capabilities for hardware design\ntasks, such as generating functional Verilog codes, have motivated various\nfine-tuning optimizations utilizing curated hardware datasets from open-source\nrepositories. However, these datasets remain limited in size and contain\nminimal checks on licensing for reuse, resulting in potential copyright\nviolations by fine-tuned LLMs. Therefore, we propose an evaluation benchmark to\nestimate the risk of Verilog-trained LLMs to generate copyright-protected\ncodes. To minimize this risk, we present an open-source Verilog dataset,\nFreeSet, containing over 220k files, along with the automated dataset curation\nframework utilized to provide additional guarantees of fair-use Verilog data.\nWe then execute an LLM fine-tuning framework consisting of continual\npre-training, resulting in a fine-tuned Llama model for Verilog, FreeV. Our\nresults indicate that FreeV demonstrates the smallest risk of\ncopyright-infringement among prior works, with only a 3% violation rate.\nFurthermore, experimental results demonstrate improvements in Verilog\ngeneration functionality over its baseline model, improving VerilogEval pass@10\nrates by over 10%."}
{"id": "2505.05528", "pdf": "https://arxiv.org/pdf/2505.05528", "abs": "https://arxiv.org/abs/2505.05528", "authors": ["Hanxun Huang", "Sarah Erfani", "Yige Li", "Xingjun Ma", "James Bailey"], "title": "X-Transfer Attacks: Towards Super Transferable Adversarial Attacks on CLIP", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "ICML 2025", "summary": "As Contrastive Language-Image Pre-training (CLIP) models are increasingly\nadopted for diverse downstream tasks and integrated into large vision-language\nmodels (VLMs), their susceptibility to adversarial perturbations has emerged as\na critical concern. In this work, we introduce \\textbf{X-Transfer}, a novel\nattack method that exposes a universal adversarial vulnerability in CLIP.\nX-Transfer generates a Universal Adversarial Perturbation (UAP) capable of\ndeceiving various CLIP encoders and downstream VLMs across different samples,\ntasks, and domains. We refer to this property as \\textbf{super\ntransferability}--a single perturbation achieving cross-data, cross-domain,\ncross-model, and cross-task adversarial transferability simultaneously. This is\nachieved through \\textbf{surrogate scaling}, a key innovation of our approach.\nUnlike existing methods that rely on fixed surrogate models, which are\ncomputationally intensive to scale, X-Transfer employs an efficient surrogate\nscaling strategy that dynamically selects a small subset of suitable surrogates\nfrom a large search space. Extensive evaluations demonstrate that X-Transfer\nsignificantly outperforms previous state-of-the-art UAP methods, establishing a\nnew benchmark for adversarial transferability across CLIP models. The code is\npublicly available in our\n\\href{https://github.com/HanxunH/XTransferBench}{GitHub repository}."}
{"id": "2505.05625", "pdf": "https://arxiv.org/pdf/2505.05625", "abs": "https://arxiv.org/abs/2505.05625", "authors": ["Wenqing Peng", "Zhi-Song Liu", "Michael Boy"], "title": "SPIN-ODE: Stiff Physics-Informed Neural ODE for Chemical Reaction Rate Estimation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Estimating rate constants from complex chemical reactions is essential for\nadvancing detailed chemistry. However, the stiffness inherent in real-world\natmospheric chemistry systems poses severe challenges, leading to training\ninstability and poor convergence that hinder effective rate constant estimation\nusing learning-based approaches. To address this, we propose a Stiff\nPhysics-Informed Neural ODE framework (SPIN-ODE) for chemical reaction\nmodelling. Our method introduces a three-stage optimisation process: first, a\nlatent neural ODE learns the continuous and differentiable trajectory between\nchemical concentrations and their time derivatives; second, an explicit\nChemical Reaction Neural Network (CRNN) extracts the underlying rate\ncoefficients based on the learned dynamics; and third, fine-tune CRNN using a\nneural ODE solver to further improve rate coefficient estimation. Extensive\nexperiments on both synthetic and newly proposed real-world datasets validate\nthe effectiveness and robustness of our approach. As the first work on stiff\nNeural ODEs for chemical rate coefficient discovery, our study opens promising\ndirections for integrating neural networks with detailed chemistry."}
{"id": "2505.06210", "pdf": "https://arxiv.org/pdf/2505.06210", "abs": "https://arxiv.org/abs/2505.06210", "authors": ["Diego Adame", "Jose A. Nunez", "Fabian Vazquez", "Nayeli Gurrola", "Huimin Li", "Haoteng Tang", "Bin Fu", "Pengfei Gu"], "title": "Topo-VM-UNetV2: Encoding Topology into Vision Mamba UNet for Polyp Segmentation", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Convolutional neural network (CNN) and Transformer-based architectures are\ntwo dominant deep learning models for polyp segmentation. However, CNNs have\nlimited capability for modeling long-range dependencies, while Transformers\nincur quadratic computational complexity. Recently, State Space Models such as\nMamba have been recognized as a promising approach for polyp segmentation\nbecause they not only model long-range interactions effectively but also\nmaintain linear computational complexity. However, Mamba-based architectures\nstill struggle to capture topological features (e.g., connected components,\nloops, voids), leading to inaccurate boundary delineation and polyp\nsegmentation. To address these limitations, we propose a new approach called\nTopo-VM-UNetV2, which encodes topological features into the Mamba-based\nstate-of-the-art polyp segmentation model, VM-UNetV2. Our method consists of\ntwo stages: Stage 1: VM-UNetV2 is used to generate probability maps (PMs) for\nthe training and test images, which are then used to compute topology attention\nmaps. Specifically, we first compute persistence diagrams of the PMs, then we\ngenerate persistence score maps by assigning persistence values (i.e., the\ndifference between death and birth times) of each topological feature to its\nbirth location, finally we transform persistence scores into attention weights\nusing the sigmoid function. Stage 2: These topology attention maps are\nintegrated into the semantics and detail infusion (SDI) module of VM-UNetV2 to\nform a topology-guided semantics and detail infusion (Topo-SDI) module for\nenhancing the segmentation results. Extensive experiments on five public polyp\nsegmentation datasets demonstrate the effectiveness of our proposed method. The\ncode will be made publicly available."}
{"id": "2505.06027", "pdf": "https://arxiv.org/pdf/2505.06027", "abs": "https://arxiv.org/abs/2505.06027", "authors": ["Stefan Vasilev", "Christian Herold", "Baohao Liao", "Seyyed Hadi Hashemi", "Shahram Khadivi", "Christof Monz"], "title": "Unilogit: Robust Machine Unlearning for LLMs Using Uniform-Target Self-Distillation", "categories": ["cs.CL", "cs.LG", "68T50", "I.2.7"], "comment": "16 pages, 6 figures, 5 tables, under review at ACL", "summary": "This paper introduces Unilogit, a novel self-distillation method for machine\nunlearning in Large Language Models. Unilogit addresses the challenge of\nselectively forgetting specific information while maintaining overall model\nutility, a critical task in compliance with data privacy regulations like GDPR.\nUnlike prior methods that rely on static hyperparameters or starting model\noutputs, Unilogit dynamically adjusts target logits to achieve a uniform\nprobability for the target token, leveraging the current model's outputs for\nmore accurate self-distillation targets. This approach not only eliminates the\nneed for additional hyperparameters but also enhances the model's ability to\napproximate the golden targets. Extensive experiments on public benchmarks and\nan in-house e-commerce dataset demonstrate Unilogit's superior performance in\nbalancing forget and retain objectives, outperforming state-of-the-art methods\nsuch as NPO and UnDIAL. Our analysis further reveals Unilogit's robustness\nacross various scenarios, highlighting its practical applicability and\neffectiveness in achieving efficacious machine unlearning."}
{"id": "2505.06191", "pdf": "https://arxiv.org/pdf/2505.06191", "abs": "https://arxiv.org/abs/2505.06191", "authors": ["Jiayuan Mao", "Joshua B. Tenenbaum", "Jiajun Wu"], "title": "Neuro-Symbolic Concepts", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "cs.RO"], "comment": "To appear in Communications of the ACM", "summary": "This article presents a concept-centric paradigm for building agents that can\nlearn continually and reason flexibly. The concept-centric agent utilizes a\nvocabulary of neuro-symbolic concepts. These concepts, such as object,\nrelation, and action concepts, are grounded on sensory inputs and actuation\noutputs. They are also compositional, allowing for the creation of novel\nconcepts through their structural combination. To facilitate learning and\nreasoning, the concepts are typed and represented using a combination of\nsymbolic programs and neural network representations. Leveraging such\nneuro-symbolic concepts, the agent can efficiently learn and recombine them to\nsolve various tasks across different domains, ranging from 2D images, videos,\n3D scenes, and robotic manipulation tasks. This concept-centric framework\noffers several advantages, including data efficiency, compositional\ngeneralization, continual learning, and zero-shot transfer."}
{"id": "2505.05531", "pdf": "https://arxiv.org/pdf/2505.05531", "abs": "https://arxiv.org/abs/2505.05531", "authors": ["Hanie Moghaddasi", "Christina Chambers", "Sarah N. Mattson", "Jeffrey R. Wozniak", "Claire D. Coles", "Raja Mukherjee", "Michael Suttie"], "title": "OXSeg: Multidimensional attention UNet-based lip segmentation using semi-supervised lip contours", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Lip segmentation plays a crucial role in various domains, such as lip\nsynchronization, lipreading, and diagnostics. However, the effectiveness of\nsupervised lip segmentation is constrained by the availability of lip contour\nin the training phase. A further challenge with lip segmentation is its\nreliance on image quality , lighting, and skin tone, leading to inaccuracies in\nthe detected boundaries. To address these challenges, we propose a sequential\nlip segmentation method that integrates attention UNet and multidimensional\ninput. We unravel the micro-patterns in facial images using local binary\npatterns to build multidimensional inputs. Subsequently, the multidimensional\ninputs are fed into sequential attention UNets, where the lip contour is\nreconstructed. We introduce a mask generation method that uses a few anatomical\nlandmarks and estimates the complete lip contour to improve segmentation\naccuracy. This mask has been utilized in the training phase for lip\nsegmentation. To evaluate the proposed method, we use facial images to segment\nthe upper lips and subsequently assess lip-related facial anomalies in subjects\nwith fetal alcohol syndrome (FAS). Using the proposed lip segmentation method,\nwe achieved a mean dice score of 84.75%, and a mean pixel accuracy of 99.77% in\nupper lip segmentation. To further evaluate the method, we implemented\nclassifiers to identify those with FAS. Using a generative adversarial network\n(GAN), we reached an accuracy of 98.55% in identifying FAS in one of the study\npopulations. This method could be used to improve lip segmentation accuracy,\nespecially around Cupid's bow, and shed light on distinct lip-related\ncharacteristics of FAS."}
{"id": "2505.05650", "pdf": "https://arxiv.org/pdf/2505.05650", "abs": "https://arxiv.org/abs/2505.05650", "authors": ["Tien Dang", "Truong-Son Hy"], "title": "EquiHGNN: Scalable Rotationally Equivariant Hypergraph Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Molecular interactions often involve high-order relationships that cannot be\nfully captured by traditional graph-based models limited to pairwise\nconnections. Hypergraphs naturally extend graphs by enabling multi-way\ninteractions, making them well-suited for modeling complex molecular systems.\nIn this work, we introduce EquiHGNN, an Equivariant HyperGraph Neural Network\nframework that integrates symmetry-aware representations to improve molecular\nmodeling. By enforcing the equivariance under relevant transformation groups,\nour approach preserves geometric and topological properties, leading to more\nrobust and physically meaningful representations. We examine a range of\nequivariant architectures and demonstrate that integrating symmetry constraints\nleads to notable performance gains on large-scale molecular datasets.\nExperiments on both small and large molecules show that high-order interactions\noffer limited benefits for small molecules but consistently outperform 2D\ngraphs on larger ones. Adding geometric features to these high-order structures\nfurther improves the performance, emphasizing the value of spatial information\nin molecular learning. Our source code is available at\nhttps://github.com/HySonLab/EquiHGNN/"}
{"id": "2505.05644", "pdf": "https://arxiv.org/pdf/2505.05644", "abs": "https://arxiv.org/abs/2505.05644", "authors": ["Tom Sander", "Moritz Tenthoff", "Kay Wohlfarth", "Christian Wöhler"], "title": "The Moon's Many Faces: A Single Unified Transformer for Multimodal Lunar Reconstruction", "categories": ["cs.CV", "eess.IV"], "comment": "14pages", "summary": "Multimodal learning is an emerging research topic across multiple disciplines\nbut has rarely been applied to planetary science. In this contribution, we\nidentify that reflectance parameter estimation and image-based 3D\nreconstruction of lunar images can be formulated as a multimodal learning\nproblem. We propose a single, unified transformer architecture trained to learn\nshared representations between multiple sources like grayscale images, digital\nelevation models, surface normals, and albedo maps. The architecture supports\nflexible translation from any input modality to any target modality. Predicting\nDEMs and albedo maps from grayscale images simultaneously solves the task of 3D\nreconstruction of planetary surfaces and disentangles photometric parameters\nand height information. Our results demonstrate that our foundation model\nlearns physically plausible relations across these four modalities. Adding more\ninput modalities in the future will enable tasks such as photometric\nnormalization and co-registration."}
{"id": "2505.06046", "pdf": "https://arxiv.org/pdf/2505.06046", "abs": "https://arxiv.org/abs/2505.06046", "authors": ["Joshua Harris", "Fan Grayson", "Felix Feldman", "Timothy Laurence", "Toby Nonnenmacher", "Oliver Higgins", "Leo Loman", "Selina Patel", "Thomas Finnie", "Samuel Collins", "Michael Borowitz"], "title": "Healthy LLMs? Benchmarking LLM Knowledge of UK Government Public Health Information", "categories": ["cs.CL", "cs.LG", "68T50"], "comment": "24 pages, 10 pages main text", "summary": "As Large Language Models (LLMs) become widely accessible, a detailed\nunderstanding of their knowledge within specific domains becomes necessary for\nsuccessful real world use. This is particularly critical in public health,\nwhere failure to retrieve relevant, accurate, and current information could\nsignificantly impact UK residents. However, currently little is known about LLM\nknowledge of UK Government public health information. To address this issue,\nthis paper introduces a new benchmark, PubHealthBench, with over 8000 questions\nfor evaluating LLMs' Multiple Choice Question Answering (MCQA) and free form\nresponses to public health queries, created via an automated pipeline. We also\nrelease a new dataset of the extracted UK Government public health guidance\ndocuments used as source text for PubHealthBench. Assessing 24 LLMs on\nPubHealthBench we find the latest private LLMs (GPT-4.5, GPT-4.1 and o1) have a\nhigh degree of knowledge, achieving >90% in the MCQA setup, and outperform\nhumans with cursory search engine use. However, in the free form setup we see\nlower performance with no model scoring >75%. Therefore, whilst there are\npromising signs that state of the art (SOTA) LLMs are an increasingly accurate\nsource of public health information, additional safeguards or tools may still\nbe needed when providing free form responses on public health topics."}
{"id": "2505.04999", "pdf": "https://arxiv.org/pdf/2505.04999", "abs": "https://arxiv.org/abs/2505.04999", "authors": ["Anthony Liang", "Pavel Czempin", "Matthew Hong", "Yutai Zhou", "Erdem Biyik", "Stephen Tu"], "title": "CLAM: Continuous Latent Action Models for Robot Learning from Unlabeled Demonstrations", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Latent Action Models, Self-supervised Pretraining, Learning from\n  Videos", "summary": "Learning robot policies using imitation learning requires collecting large\namounts of costly action-labeled expert demonstrations, which fundamentally\nlimits the scale of training data. A promising approach to address this\nbottleneck is to harness the abundance of unlabeled observations-e.g., from\nvideo demonstrations-to learn latent action labels in an unsupervised way.\nHowever, we find that existing methods struggle when applied to complex robot\ntasks requiring fine-grained motions. We design continuous latent action models\n(CLAM) which incorporate two key ingredients we find necessary for learning to\nsolve complex continuous control tasks from unlabeled observation data: (a)\nusing continuous latent action labels instead of discrete representations, and\n(b) jointly training an action decoder to ensure that the latent action space\ncan be easily grounded to real actions with relatively few labeled examples.\nImportantly, the labeled examples can be collected from non-optimal play data,\nenabling CLAM to learn performant policies without access to any action-labeled\nexpert data. We demonstrate on continuous control benchmarks in DMControl\n(locomotion) and MetaWorld (manipulation), as well as on a real WidowX robot\narm that CLAM significantly outperforms prior state-of-the-art methods,\nremarkably with a 2-3x improvement in task success rate compared to the best\nbaseline. Videos and code can be found at clamrobot.github.io."}
{"id": "2505.05540", "pdf": "https://arxiv.org/pdf/2505.05540", "abs": "https://arxiv.org/abs/2505.05540", "authors": ["Pranav Guruprasad", "Yangyue Wang", "Sudipta Chowdhury", "Harshvardhan Sikka"], "title": "Benchmarking Vision, Language, & Action Models in Procedurally Generated, Open Ended Action Environments", "categories": ["cs.CV", "cs.LG"], "comment": "16 pages, 26 figures", "summary": "Vision-language-action (VLA) models represent an important step toward\ngeneral-purpose robotic systems by integrating visual perception, language\nunderstanding, and action execution. However, systematic evaluation of these\nmodels, particularly their zero-shot generalization capabilities in\nout-of-distribution (OOD) environments, remains limited. In this paper, we\nintroduce MultiNet v0.2, a comprehensive benchmark designed to evaluate and\nanalyze the generalization performance of state-of-the-art VLM and VLA\nmodels-including GPT-4o, GPT-4.1, OpenVLA,Pi0 Base, and Pi0 FAST-on diverse\nprocedural tasks from the Procgen benchmark. Our analysis reveals several\ncritical insights: (1) all evaluated models exhibit significant limitations in\nzero-shot generalization to OOD tasks, with performance heavily influenced by\nfactors such as action representation and task complexit; (2) VLAs generally\noutperform other models due to their robust architectural design; and (3) VLM\nvariants demonstrate substantial improvements when constrained appropriately,\nhighlighting the sensitivity of model performance to precise prompt\nengineering."}
{"id": "2505.05677", "pdf": "https://arxiv.org/pdf/2505.05677", "abs": "https://arxiv.org/abs/2505.05677", "authors": ["Winston Chen", "Trenton Chang", "Jenna Wiens"], "title": "Conditional Front-door Adjustment for Heterogeneous Treatment Assignment Effect Estimation Under Non-adherence", "categories": ["cs.LG"], "comment": "Accepted by Conference on Health, Inference, and Learning (CHIL) 2025", "summary": "Estimates of heterogeneous treatment assignment effects can inform treatment\ndecisions. Under the presence of non-adherence (e.g., patients do not adhere to\ntheir assigned treatment), both the standard backdoor adjustment (SBD) and the\nconditional front-door adjustment (CFD) can recover unbiased estimates of the\ntreatment assignment effects. However, the estimation variance of these\napproaches may vary widely across settings, which remains underexplored in the\nliterature. In this work, we demonstrate theoretically and empirically that CFD\nyields lower-variance estimates than SBD when the true effect of treatment\nassignment is small (i.e., assigning an intervention leads to small changes in\npatients' future outcome). Additionally, since CFD requires estimating multiple\nnuisance parameters, we introduce LobsterNet, a multi-task neural network that\nimplements CFD with joint modeling of the nuisance parameters. Empirically,\nLobsterNet reduces estimation error across several semi-synthetic and\nreal-world datasets compared to baselines. Our findings suggest CFD with shared\nnuisance parameter modeling can improve treatment assignment effect estimation\nunder non-adherence."}
{"id": "2505.05710", "pdf": "https://arxiv.org/pdf/2505.05710", "abs": "https://arxiv.org/abs/2505.05710", "authors": ["Wooyoung Jeong", "Hyun Jae Park", "Seonghun Jeong", "Jong Wook Jang", "Tae Hoon Lim", "Dae Seoung Kim"], "title": "HyperspectralMAE: The Hyperspectral Imagery Classification Model using Fourier-Encoded Dual-Branch Masked Autoencoder", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "Hyperspectral imagery provides rich spectral detail but poses unique\nchallenges because of its high dimensionality in both spatial and spectral\ndomains. We propose \\textit{HyperspectralMAE}, a Transformer-based foundation\nmodel for hyperspectral data that employs a \\textit{dual masking} strategy:\nduring pre-training we randomly occlude 50\\% of spatial patches and 50\\% of\nspectral bands. This forces the model to learn representations capable of\nreconstructing missing information across both dimensions. To encode spectral\norder, we introduce learnable harmonic Fourier positional embeddings based on\nwavelength. The reconstruction objective combines mean-squared error (MSE) with\nthe spectral angle mapper (SAM) to balance pixel-level accuracy and\nspectral-shape fidelity.\n  The resulting model contains about $1.8\\times10^{8}$ parameters and produces\n768-dimensional embeddings, giving it sufficient capacity for transfer\nlearning. We pre-trained HyperspectralMAE on two large hyperspectral corpora --\nNASA EO-1 Hyperion ($\\sim$1\\,600 scenes, $\\sim$$3\\times10^{11}$ pixel spectra)\nand DLR EnMAP Level-0 ($\\sim$1\\,300 scenes, $\\sim$$3\\times10^{11}$ pixel\nspectra) -- and fine-tuned it for land-cover classification on the Indian Pines\nbenchmark. HyperspectralMAE achieves state-of-the-art transfer-learning\naccuracy on Indian Pines, confirming that masked dual-dimensional pre-training\nyields robust spectral-spatial representations. These results demonstrate that\ndual masking and wavelength-aware embeddings advance hyperspectral image\nreconstruction and downstream analysis."}
{"id": "2505.06062", "pdf": "https://arxiv.org/pdf/2505.06062", "abs": "https://arxiv.org/abs/2505.06062", "authors": ["Iuliia Zaitova", "Vitalii Hirak", "Badr M. Abdullah", "Dietrich Klakow", "Bernd Möbius", "Tania Avgustinova"], "title": "Attention on Multiword Expressions: A Multilingual Study of BERT-based Models with Regard to Idiomaticity and Microsyntax", "categories": ["cs.CL"], "comment": "10 pages, 3 figures. Findings 2025", "summary": "This study analyzes the attention patterns of fine-tuned encoder-only models\nbased on the BERT architecture (BERT-based models) towards two distinct types\nof Multiword Expressions (MWEs): idioms and microsyntactic units (MSUs). Idioms\npresent challenges in semantic non-compositionality, whereas MSUs demonstrate\nunconventional syntactic behavior that does not conform to standard grammatical\ncategorizations. We aim to understand whether fine-tuning BERT-based models on\nspecific tasks influences their attention to MWEs, and how this attention\ndiffers between semantic and syntactic tasks. We examine attention scores to\nMWEs in both pre-trained and fine-tuned BERT-based models. We utilize\nmonolingual models and datasets in six Indo-European languages - English,\nGerman, Dutch, Polish, Russian, and Ukrainian. Our results show that\nfine-tuning significantly influences how models allocate attention to MWEs.\nSpecifically, models fine-tuned on semantic tasks tend to distribute attention\nto idiomatic expressions more evenly across layers. Models fine-tuned on\nsyntactic tasks show an increase in attention to MSUs in the lower layers,\ncorresponding with syntactic processing requirements."}
{"id": "2505.05481", "pdf": "https://arxiv.org/pdf/2505.05481", "abs": "https://arxiv.org/abs/2505.05481", "authors": ["Ryan Williams"], "title": "Structure & Quality: Conceptual and Formal Foundations for the Mind-Body Problem", "categories": ["q-bio.NC", "cs.AI"], "comment": null, "summary": "This paper explores the hard problem of consciousness from a different\nperspective. Instead of drawing distinctions between the physical and the\nmental, an exploration of a more foundational relationship is examined: the\nrelationship between structure and quality.\n  Information-theoretic measures are developed to quantify the mutual\ndeterminability between structure and quality, including a novel Q-S space for\nanalyzing fidelity between the two domains. This novel space naturally points\ntoward a five-fold categorization of possible relationships between structural\nand qualitative properties, illustrating each through conceptual and formal\nmodels.\n  The ontological implications of each category are examined, shedding light on\ndebates around functionalism, emergentism, idealism, panpsychism, and neutral\nmonism.\n  This new line of inquiry has established a framework for deriving theoretical\nconstraints on qualitative systems undergoing evolution that is explored in my\ncompanion paper, Qualia & Natural Selection."}
{"id": "2505.05573", "pdf": "https://arxiv.org/pdf/2505.05573", "abs": "https://arxiv.org/abs/2505.05573", "authors": ["Mikhail Chaichuk", "Sushant Gautam", "Steven Hicks", "Elena Tutubalina"], "title": "Prompt to Polyp: Clinically-Aware Medical Image Synthesis with Diffusion Models", "categories": ["cs.CV", "cs.AI", "68T07, 68U10, 92C55", "I.2.10; I.4.8; J.3"], "comment": "code available at\n  https://github.com/THunderCondOR/ImageCLEFmed-MEDVQA-GI-2024-MMCP-Team", "summary": "The generation of realistic medical images from text descriptions has\nsignificant potential to address data scarcity challenges in healthcare AI\nwhile preserving patient privacy. This paper presents a comprehensive study of\ntext-to-image synthesis in the medical domain, comparing two distinct\napproaches: (1) fine-tuning large pre-trained latent diffusion models and (2)\ntraining small, domain-specific models. We introduce a novel model named MSDM,\nan optimized architecture based on Stable Diffusion that integrates a clinical\ntext encoder, variational autoencoder, and cross-attention mechanisms to better\nalign medical text prompts with generated images. Our study compares two\napproaches: fine-tuning large pre-trained models (FLUX, Kandinsky) versus\ntraining compact domain-specific models (MSDM). Evaluation across colonoscopy\n(MedVQA-GI) and radiology (ROCOv2) datasets reveals that while large models\nachieve higher fidelity, our optimized MSDM delivers comparable quality with\nlower computational costs. Quantitative metrics and qualitative evaluations by\nmedical experts reveal strengths and limitations of each approach."}
{"id": "2505.05683", "pdf": "https://arxiv.org/pdf/2505.05683", "abs": "https://arxiv.org/abs/2505.05683", "authors": ["Udaya Allani"], "title": "Interactive Diabetes Risk Prediction Using Explainable Machine Learning: A Dash-Based Approach with SHAP, LIME, and Comorbidity Insights", "categories": ["cs.LG", "cs.AI", "I.2.1; I.5.2; J.3"], "comment": "16 pages, 21 figures, submitted as a preprint for academic\n  dissemination", "summary": "This study presents a web-based interactive health risk prediction tool\ndesigned to assess diabetes risk using machine learning models. Built on the\n2015 CDC BRFSS dataset, the study evaluates models including Logistic\nRegression, Random Forest, XGBoost, LightGBM, KNN, and Neural Networks under\noriginal, SMOTE, and undersampling strategies. LightGBM with undersampling\nachieved the best recall, making it ideal for risk detection. The tool\nintegrates SHAP and LIME to explain predictions and highlights comorbidity\ncorrelations using Pearson analysis. A Dash-based UI enables user-friendly\ninteraction with model predictions, personalized suggestions, and feature\ninsights, supporting data-driven health awareness."}
{"id": "2505.05752", "pdf": "https://arxiv.org/pdf/2505.05752", "abs": "https://arxiv.org/abs/2505.05752", "authors": ["Amin Ghafourian", "Andrew Lee", "Dechen Gao", "Tyler Beer", "Kin Yen", "Iman Soltani"], "title": "Automating Infrastructure Surveying: A Framework for Geometric Measurements and Compliance Assessment Using Point Cloud Data", "categories": ["cs.CV", "cs.CY", "cs.LG", "cs.RO", "eess.IV"], "comment": "19 pages, 15 figures, 4 tables", "summary": "Automation can play a prominent role in improving efficiency, accuracy, and\nscalability in infrastructure surveying and assessing construction and\ncompliance standards. This paper presents a framework for automation of\ngeometric measurements and compliance assessment using point cloud data. The\nproposed approach integrates deep learning-based detection and segmentation, in\nconjunction with geometric and signal processing techniques, to automate\nsurveying tasks. As a proof of concept, we apply this framework to\nautomatically evaluate the compliance of curb ramps with the Americans with\nDisabilities Act (ADA), demonstrating the utility of point cloud data in survey\nautomation. The method leverages a newly collected, large annotated dataset of\ncurb ramps, made publicly available as part of this work, to facilitate robust\nmodel training and evaluation. Experimental results, including comparison with\nmanual field measurements of several ramps, validate the accuracy and\nreliability of the proposed method, highlighting its potential to significantly\nreduce manual effort and improve consistency in infrastructure assessment.\nBeyond ADA compliance, the proposed framework lays the groundwork for broader\napplications in infrastructure surveying and automated construction evaluation,\npromoting wider adoption of point cloud data in these domains. The annotated\ndatabase, manual ramp survey data, and developed algorithms are publicly\navailable on the project's GitHub page:\nhttps://github.com/Soltanilara/SurveyAutomation."}
{"id": "2505.06110", "pdf": "https://arxiv.org/pdf/2505.06110", "abs": "https://arxiv.org/abs/2505.06110", "authors": ["Jugal Gajjar", "Kaustik Ranaware"], "title": "Multimodal Sentiment Analysis on CMU-MOSEI Dataset using Transformer-based Models", "categories": ["cs.CL", "cs.AI"], "comment": "6 pages, 2 figures, 5 tables, and 19 references", "summary": "This project performs multimodal sentiment analysis using the CMU-MOSEI\ndataset, using transformer-based models with early fusion to integrate text,\naudio, and visual modalities. We employ BERT-based encoders for each modality,\nextracting embeddings that are concatenated before classification. The model\nachieves strong performance, with 97.87\\% 7-class accuracy and a 0.9682\nF1-score on the test set, demonstrating the effectiveness of early fusion in\ncapturing cross-modal interactions. The training utilized Adam optimization\n(lr=1e-4), dropout (0.3), and early stopping to ensure generalization and\nrobustness. Results highlight the superiority of transformer architectures in\nmodeling multimodal sentiment, with a low MAE (0.1060) indicating precise\nsentiment intensity prediction. Future work may compare fusion strategies or\nenhance interpretability. This approach utilizes multimodal learning by\neffectively combining linguistic, acoustic, and visual cues for sentiment\nanalysis."}
{"id": "2505.05486", "pdf": "https://arxiv.org/pdf/2505.05486", "abs": "https://arxiv.org/abs/2505.05486", "authors": ["Anthony Kiggundu", "Dennis Krummacker", "Hans D. Schotten"], "title": "FedAvgen: Metadata for Model Aggregation In Communication Systems", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": "Accepted in IEEE NetSoft 2025", "summary": "To improve business efficiency and minimize costs, Artificial Intelligence\n(AI) practitioners have adopted a shift from formulating models from scratch\ntowards sharing pretrained models. The pretrained models are then aggregated\ninto a global model with higher generalization capabilities, which is\nafterwards distributed to the client devices. This approach is known as\nfederated learning and inherently utilizes different techniques to select the\ncandidate client models averaged to obtain the global model. This approach, in\nthe case of communication systems, faces challenges arising from the\nexistential diversity in device profiles. The multiplicity in profiles\nmotivates our conceptual assessment of a metaheuristic algorithm (FedAvgen),\nwhich relates each pretrained model with its weight space as metadata, to a\nphenotype and genotype, respectively. This parent-child genetic evolution\ncharacterizes the global averaging step in federated learning. We then compare\nthe results of our approach to two widely adopted baseline federated learning\nalgorithms like Federated Averaging (FedAvg) and Federated Stochastic Gradient\nDescent (FedSGD)."}
{"id": "2505.05587", "pdf": "https://arxiv.org/pdf/2505.05587", "abs": "https://arxiv.org/abs/2505.05587", "authors": ["Peihao Wang", "Yuehao Wang", "Dilin Wang", "Sreyas Mohan", "Zhiwen Fan", "Lemeng Wu", "Ruisi Cai", "Yu-Ying Yeh", "Zhangyang Wang", "Qiang Liu", "Rakesh Ranjan"], "title": "Steepest Descent Density Control for Compact 3D Gaussian Splatting", "categories": ["cs.CV"], "comment": "CVPR 2025, Project page: https://vita-group.github.io/SteepGS/", "summary": "3D Gaussian Splatting (3DGS) has emerged as a powerful technique for\nreal-time, high-resolution novel view synthesis. By representing scenes as a\nmixture of Gaussian primitives, 3DGS leverages GPU rasterization pipelines for\nefficient rendering and reconstruction. To optimize scene coverage and capture\nfine details, 3DGS employs a densification algorithm to generate additional\npoints. However, this process often leads to redundant point clouds, resulting\nin excessive memory usage, slower performance, and substantial storage demands\n- posing significant challenges for deployment on resource-constrained devices.\nTo address this limitation, we propose a theoretical framework that demystifies\nand improves density control in 3DGS. Our analysis reveals that splitting is\ncrucial for escaping saddle points. Through an optimization-theoretic approach,\nwe establish the necessary conditions for densification, determine the minimal\nnumber of offspring Gaussians, identify the optimal parameter update direction,\nand provide an analytical solution for normalizing off-spring opacity. Building\non these insights, we introduce SteepGS, incorporating steepest density\ncontrol, a principled strategy that minimizes loss while maintaining a compact\npoint cloud. SteepGS achieves a ~50% reduction in Gaussian points without\ncompromising rendering quality, significantly enhancing both efficiency and\nscalability."}
{"id": "2505.05702", "pdf": "https://arxiv.org/pdf/2505.05702", "abs": "https://arxiv.org/abs/2505.05702", "authors": ["Seongjin Choi", "Gahee Kim", "Yong-Geun Oh"], "title": "Hypergraph Neural Sheaf Diffusion: A Symmetric Simplicial Set Framework for Higher-Order Learning", "categories": ["cs.LG", "05C65, 55U10, 68T07"], "comment": "This manuscript has been submitted to IEEE Access for publication", "summary": "The absence of intrinsic adjacency relations and orientation systems in\nhypergraphs creates fundamental challenges for constructing sheaf Laplacians of\narbitrary degrees. We resolve these limitations through symmetric simplicial\nsets derived directly from hypergraphs, which encode all possible oriented\nsubrelations within each hyperedge as ordered tuples. This construction\ncanonically defines adjacency via facet maps while inherently preserving\nhyperedge provenance. We establish that the normalized degree zero sheaf\nLaplacian on our induced symmetric simplicial set reduces exactly to the\ntraditional graph normalized sheaf Laplacian when restricted to graphs,\nvalidating its mathematical consistency with prior graph-based sheaf theory.\nFurthermore, the induced structure preserves all structural information from\nthe original hypergraph, ensuring that every multi-way relational detail is\nfaithfully retained. Leveraging this framework, we introduce Hypergraph Neural\nSheaf Diffusion (HNSD), the first principled extension of Neural Sheaf\nDiffusion (NSD) to hypergraphs. HNSD operates via normalized degree zero sheaf\nLaplacians over symmetric simplicial sets, resolving orientation ambiguity and\nadjacency sparsity inherent to hypergraph learning. Experimental evaluations\ndemonstrate HNSD's competitive performance across established benchmarks."}
{"id": "2505.05798", "pdf": "https://arxiv.org/pdf/2505.05798", "abs": "https://arxiv.org/abs/2505.05798", "authors": ["Youngjoon Lee", "Jinu Gong", "Joonhyuk Kang"], "title": "Improving Generalizability of Kolmogorov-Arnold Networks via Error-Correcting Output Codes", "categories": ["cs.LG", "cs.CV", "eess.IV", "eess.SP"], "comment": "4 pages", "summary": "Kolmogorov-Arnold Networks (KAN) offer universal function approximation using\nunivariate spline compositions without nonlinear activations. In this work, we\nintegrate Error-Correcting Output Codes (ECOC) into the KAN framework to\ntransform multi-class classification into multiple binary tasks, improving\nrobustness via Hamming-distance decoding. Our proposed KAN with ECOC method\noutperforms vanilla KAN on a challenging blood cell classification dataset,\nachieving higher accuracy under diverse hyperparameter settings. Ablation\nstudies further confirm that ECOC consistently enhances performance across\nFastKAN and FasterKAN variants. These results demonstrate that ECOC integration\nsignificantly boosts KAN generalizability in critical healthcare AI\napplications. To the best of our knowledge, this is the first integration of\nECOC with KAN for enhancing multi-class medical image classification\nperformance."}
{"id": "2505.06120", "pdf": "https://arxiv.org/pdf/2505.06120", "abs": "https://arxiv.org/abs/2505.06120", "authors": ["Philippe Laban", "Hiroaki Hayashi", "Yingbo Zhou", "Jennifer Neville"], "title": "LLMs Get Lost In Multi-Turn Conversation", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "Large Language Models (LLMs) are conversational interfaces. As such, LLMs\nhave the potential to assist their users not only when they can fully specify\nthe task at hand, but also to help them define, explore, and refine what they\nneed through multi-turn conversational exchange. Although analysis of LLM\nconversation logs has confirmed that underspecification occurs frequently in\nuser instructions, LLM evaluation has predominantly focused on the single-turn,\nfully-specified instruction setting. In this work, we perform large-scale\nsimulation experiments to compare LLM performance in single- and multi-turn\nsettings. Our experiments confirm that all the top open- and closed-weight LLMs\nwe test exhibit significantly lower performance in multi-turn conversations\nthan single-turn, with an average drop of 39% across six generation tasks.\nAnalysis of 200,000+ simulated conversations decomposes the performance\ndegradation into two components: a minor loss in aptitude and a significant\nincrease in unreliability. We find that LLMs often make assumptions in early\nturns and prematurely attempt to generate final solutions, on which they overly\nrely. In simpler terms, we discover that *when LLMs take a wrong turn in a\nconversation, they get lost and do not recover*."}
{"id": "2505.05494", "pdf": "https://arxiv.org/pdf/2505.05494", "abs": "https://arxiv.org/abs/2505.05494", "authors": ["Avanija Menon", "Ovidiu Serban"], "title": "An Automated LLM-based Pipeline for Asset-Level Database Creation to Assess Deforestation Impact", "categories": ["cs.DB", "cs.AI", "cs.IR", "cs.LG"], "comment": "Accepted to ACL ClimateNLP 2025", "summary": "The European Union Deforestation Regulation (EUDR) requires companies to\nprove their products do not contribute to deforestation, creating a critical\ndemand for precise, asset-level environmental impact data. Current databases\nlack the necessary detail, relying heavily on broad financial metrics and\nmanual data collection, which limits regulatory compliance and accurate\nenvironmental modeling. This study presents an automated, end-to-end data\nextraction pipeline that uses LLMs to create, clean, and validate structured\ndatabases, specifically targeting sectors with a high risk of deforestation.\nThe pipeline introduces Instructional, Role-Based, Zero-Shot Chain-of-Thought\n(IRZ-CoT) prompting to enhance data extraction accuracy and a\nRetrieval-Augmented Validation (RAV) process that integrates real-time web\nsearches for improved data reliability. Applied to SEC EDGAR filings in the\nMining, Oil & Gas, and Utilities sectors, the pipeline demonstrates significant\nimprovements over traditional zero-shot prompting approaches, particularly in\nextraction accuracy and validation coverage. This work advances NLP-driven\nautomation for regulatory compliance, CSR (Corporate Social Responsibility),\nand ESG, with broad sectoral applicability."}
{"id": "2505.05589", "pdf": "https://arxiv.org/pdf/2505.05589", "abs": "https://arxiv.org/abs/2505.05589", "authors": ["Jingzhong Lin", "Yuanyuan Qi", "Xinru Li", "Wenxuan Huang", "Xiangfeng Xu", "Bangyan Li", "Xuejiao Wang", "Gaoqi He"], "title": "ReactDance: Progressive-Granular Representation for Long-Term Coherent Reactive Dance Generation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Reactive dance generation (RDG) produces follower movements conditioned on\nguiding dancer and music while ensuring spatial coordination and temporal\ncoherence. However, existing methods overemphasize global constraints and\noptimization, overlooking local information, such as fine-grained spatial\ninteractions and localized temporal context. Therefore, we present ReactDance,\na novel diffusion-based framework for high-fidelity RDG with long-term\ncoherence and multi-scale controllability. Unlike existing methods that\nstruggle with interaction fidelity, synchronization, and temporal consistency\nin duet synthesis, our approach introduces two key innovations: 1)Group\nResidual Finite Scalar Quantization (GRFSQ), a multi-scale disentangled motion\nrepresentation that captures interaction semantics from coarse body rhythms to\nfine-grained joint dynamics, and 2)Blockwise Local Context (BLC), a sampling\nstrategy eliminating error accumulation in long sequence generation via local\nblock causal masking and periodic positional encoding. Built on the decoupled\nmulti-scale GRFSQ representation, we implement a diffusion model\nwithLayer-Decoupled Classifier-free Guidance (LDCFG), allowing granular control\nover motion semantics across scales. Extensive experiments on standard\nbenchmarks demonstrate that ReactDance surpasses existing methods, achieving\nstate-of-the-art performance."}
{"id": "2505.05707", "pdf": "https://arxiv.org/pdf/2505.05707", "abs": "https://arxiv.org/abs/2505.05707", "authors": ["Rushabh Solanki", "Meghana Bhange", "Ulrich Aïvodji", "Elliot Creager"], "title": "Crowding Out The Noise: Algorithmic Collective Action Under Differential Privacy", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "The integration of AI into daily life has generated considerable attention\nand excitement, while also raising concerns about automating algorithmic harms\nand re-entrenching existing social inequities. While the responsible deployment\nof trustworthy AI systems is a worthy goal, there are many possible ways to\nrealize it, from policy and regulation to improved algorithm design and\nevaluation. In fact, since AI trains on social data, there is even a\npossibility for everyday users, citizens, or workers to directly steer its\nbehavior through Algorithmic Collective Action, by deliberately modifying the\ndata they share with a platform to drive its learning process in their favor.\nThis paper considers how these grassroots efforts to influence AI interact with\nmethods already used by AI firms and governments to improve model\ntrustworthiness. In particular, we focus on the setting where the AI firm\ndeploys a differentially private model, motivated by the growing regulatory\nfocus on privacy and data protection. We investigate how the use of\nDifferentially Private Stochastic Gradient Descent (DPSGD) affects the\ncollective's ability to influence the learning process. Our findings show that\nwhile differential privacy contributes to the protection of individual data, it\nintroduces challenges for effective algorithmic collective action. We\ncharacterize lower bounds on the success of algorithmic collective action under\ndifferential privacy as a function of the collective's size and the firm's\nprivacy parameters, and verify these trends experimentally by simulating\ncollective action during the training of deep neural network classifiers across\nseveral datasets."}
{"id": "2505.05829", "pdf": "https://arxiv.org/pdf/2505.05829", "abs": "https://arxiv.org/abs/2505.05829", "authors": ["Zhiyuan Chen", "Keyi Li", "Yifan Jia", "Le Ye", "Yufei Ma"], "title": "Accelerating Diffusion Transformer via Increment-Calibrated Caching with Channel-Aware Singular Value Decomposition", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": "accepted by CVPR2025", "summary": "Diffusion transformer (DiT) models have achieved remarkable success in image\ngeneration, thanks for their exceptional generative capabilities and\nscalability. Nonetheless, the iterative nature of diffusion models (DMs)\nresults in high computation complexity, posing challenges for deployment.\nAlthough existing cache-based acceleration methods try to utilize the inherent\ntemporal similarity to skip redundant computations of DiT, the lack of\ncorrection may induce potential quality degradation. In this paper, we propose\nincrement-calibrated caching, a training-free method for DiT acceleration,\nwhere the calibration parameters are generated from the pre-trained model\nitself with low-rank approximation. To deal with the possible correction\nfailure arising from outlier activations, we introduce channel-aware Singular\nValue Decomposition (SVD), which further strengthens the calibration effect.\nExperimental results show that our method always achieve better performance\nthan existing naive caching methods with a similar computation resource budget.\nWhen compared with 35-step DDIM, our method eliminates more than 45%\ncomputation and improves IS by 12 at the cost of less than 0.06 FID increase.\nCode is available at https://github.com/ccccczzy/icc."}
{"id": "2505.06145", "pdf": "https://arxiv.org/pdf/2505.06145", "abs": "https://arxiv.org/abs/2505.06145", "authors": ["Xu Han", "Yumeng Sun", "Weiqiang Huang", "Hongye Zheng", "Junliang Du"], "title": "Towards Robust Few-Shot Text Classification Using Transformer Architectures and Dual Loss Strategies", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Few-shot text classification has important application value in low-resource\nenvironments. This paper proposes a strategy that combines adaptive\nfine-tuning, contrastive learning, and regularization optimization to improve\nthe classification performance of Transformer-based models. Experiments on the\nFewRel 2.0 dataset show that T5-small, DeBERTa-v3, and RoBERTa-base perform\nwell in few-shot tasks, especially in the 5-shot setting, which can more\neffectively capture text features and improve classification accuracy. The\nexperiment also found that there are significant differences in the\nclassification difficulty of different relationship categories. Some categories\nhave fuzzy semantic boundaries or complex feature distributions, making it\ndifficult for the standard cross entropy loss to learn the discriminative\ninformation required to distinguish categories. By introducing contrastive loss\nand regularization loss, the generalization ability of the model is enhanced,\neffectively alleviating the overfitting problem in few-shot environments. In\naddition, the research results show that the use of Transformer models or\ngenerative architectures with stronger self-attention mechanisms can help\nimprove the stability and accuracy of few-shot classification."}
{"id": "2505.05498", "pdf": "https://arxiv.org/pdf/2505.05498", "abs": "https://arxiv.org/abs/2505.05498", "authors": ["Noor ul Misbah Khanum", "Hayssam Dahrouj", "Ramesh C. Bansal", "Hissam Mouayad Tawfik"], "title": "An Overview of the Prospects and Challenges of Using Artificial Intelligence for Energy Management Systems in Microgrids", "categories": ["eess.SY", "cs.AI", "cs.SY"], "comment": "70 pages, 7 figures", "summary": "Microgrids have emerged as a pivotal solution in the quest for a sustainable\nand energy-efficient future. While microgrids offer numerous advantages, they\nare also prone to issues related to reliably forecasting renewable energy\ndemand and production, protecting against cyberattacks, controlling operational\ncosts, optimizing power flow, and regulating the performance of energy\nmanagement systems (EMS). Tackling these energy management challenges is\nessential to facilitate microgrid applications and seamlessly incorporate\nrenewable energy resources. Artificial intelligence (AI) has recently\ndemonstrated immense potential for optimizing energy management in microgrids,\nproviding efficient and reliable solutions. This paper highlights the combined\nbenefits of enabling AI-based methodologies in the energy management systems of\nmicrogrids by examining the applicability and efficiency of AI-based EMS in\nachieving specific technical and economic objectives. The paper also points out\nseveral future research directions that promise to spearhead AI-driven EMS,\nnamely the development of self-healing microgrids, integration with blockchain\ntechnology, use of Internet of things (IoT), and addressing interpretability,\ndata privacy, scalability, and the prospects to generative AI in the context of\nfuture AI-based EMS."}
{"id": "2505.05591", "pdf": "https://arxiv.org/pdf/2505.05591", "abs": "https://arxiv.org/abs/2505.05591", "authors": ["Yueh-Cheng Liu", "Lukas Höllein", "Matthias Nießner", "Angela Dai"], "title": "QuickSplat: Fast 3D Surface Reconstruction via Learned Gaussian Initialization", "categories": ["cs.CV"], "comment": "Project page: https://liu115.github.io/quicksplat, Video:\n  https://youtu.be/2IA_gnFvFG8", "summary": "Surface reconstruction is fundamental to computer vision and graphics,\nenabling applications in 3D modeling, mixed reality, robotics, and more.\nExisting approaches based on volumetric rendering obtain promising results, but\noptimize on a per-scene basis, resulting in a slow optimization that can\nstruggle to model under-observed or textureless regions. We introduce\nQuickSplat, which learns data-driven priors to generate dense initializations\nfor 2D gaussian splatting optimization of large-scale indoor scenes. This\nprovides a strong starting point for the reconstruction, which accelerates the\nconvergence of the optimization and improves the geometry of flat wall\nstructures. We further learn to jointly estimate the densification and update\nof the scene parameters during each iteration; our proposed densifier network\npredicts new Gaussians based on the rendering gradients of existing ones,\nremoving the needs of heuristics for densification. Extensive experiments on\nlarge-scale indoor scene reconstruction demonstrate the superiority of our\ndata-driven optimization. Concretely, we accelerate runtime by 8x, while\ndecreasing depth errors by up to 48% in comparison to state of the art methods."}
{"id": "2505.05732", "pdf": "https://arxiv.org/pdf/2505.05732", "abs": "https://arxiv.org/abs/2505.05732", "authors": ["Limai Jiang", "Yunpeng Cai"], "title": "Automated Learning of Semantic Embedding Representations for Diffusion Models", "categories": ["cs.LG", "cs.CV"], "comment": "Extended version of the paper published in SDM25", "summary": "Generative models capture the true distribution of data, yielding\nsemantically rich representations. Denoising diffusion models (DDMs) exhibit\nsuperior generative capabilities, though efficient representation learning for\nthem are lacking. In this work, we employ a multi-level denoising autoencoder\nframework to expand the representation capacity of DDMs, which introduces\nsequentially consistent Diffusion Transformers and an additional\ntimestep-dependent encoder to acquire embedding representations on the\ndenoising Markov chain through self-conditional diffusion learning.\nIntuitively, the encoder, conditioned on the entire diffusion process,\ncompresses high-dimensional data into directional vectors in latent under\ndifferent noise levels, facilitating the learning of image embeddings across\nall timesteps. To verify the semantic adequacy of embeddings generated through\nthis approach, extensive experiments are conducted on various datasets,\ndemonstrating that optimally learned embeddings by DDMs surpass\nstate-of-the-art self-supervised representation learning methods in most cases,\nachieving remarkable discriminative semantic representation quality. Our work\njustifies that DDMs are not only suitable for generative tasks, but also\npotentially advantageous for general-purpose deep learning applications."}
{"id": "2505.05870", "pdf": "https://arxiv.org/pdf/2505.05870", "abs": "https://arxiv.org/abs/2505.05870", "authors": ["Yimin Zhou", "Yichong Xia", "Bin Chen", "Baoyi An", "Haoqian Wang", "Zhi Wang", "Yaowei Wang", "Zikun Zhou"], "title": "Towards Facial Image Compression with Consistency Preserving Diffusion Prior", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "With the widespread application of facial image data across various domains,\nthe efficient storage and transmission of facial images has garnered\nsignificant attention. However, the existing learned face image compression\nmethods often produce unsatisfactory reconstructed image quality at low bit\nrates. Simply adapting diffusion-based compression methods to facial\ncompression tasks results in reconstructed images that perform poorly in\ndownstream applications due to insufficient preservation of high-frequency\ninformation. To further explore the diffusion prior in facial image\ncompression, we propose Facial Image Compression with a Stable Diffusion Prior\n(FaSDiff), a method that preserves consistency through frequency enhancement.\nFaSDiff employs a high-frequency-sensitive compressor in an end-to-end\nframework to capture fine image details and produce robust visual prompts.\nAdditionally, we introduce a hybrid low-frequency enhancement module that\ndisentangles low-frequency facial semantics and stably modulates the diffusion\nprior alongside visual prompts. The proposed modules allow FaSDiff to leverage\ndiffusion priors for superior human visual perception while minimizing\nperformance loss in machine vision due to semantic inconsistency. Extensive\nexperiments show that FaSDiff outperforms state-of-the-art methods in balancing\nhuman visual quality and machine vision accuracy. The code will be released\nafter the paper is accepted."}
{"id": "2505.06150", "pdf": "https://arxiv.org/pdf/2505.06150", "abs": "https://arxiv.org/abs/2505.06150", "authors": ["Ryan Lagasse", "Aidan Kiernans", "Avijit Ghosh", "Shiri Dori-Hacohen"], "title": "A Scaling Law for Token Efficiency in LLM Fine-Tuning Under Fixed Compute Budgets", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We introduce a scaling law for fine-tuning large language models (LLMs) under\nfixed compute budgets that explicitly accounts for data composition.\nConventional approaches measure training data solely by total tokens, yet the\nnumber of examples and their average token length -- what we term \\emph{dataset\nvolume} -- play a decisive role in model performance. Our formulation is tuned\nfollowing established procedures. Experiments on the BRICC dataset\n\\cite{salavati2024reducing} and subsets of the MMLU dataset\n\\cite{hendrycks2021measuringmassivemultitasklanguage}, evaluated under multiple\nsubsampling strategies, reveal that data composition significantly affects\ntoken efficiency. These results motivate refined scaling laws for practical LLM\nfine-tuning in resource-constrained settings."}
{"id": "2505.05516", "pdf": "https://arxiv.org/pdf/2505.05516", "abs": "https://arxiv.org/abs/2505.05516", "authors": ["Yue Wu", "Yibo Guo", "Yulong Yan", "Jiancheng Yang", "Xin Zhou", "Ching-Yu Cheng", "Danli Shi", "Mingguang He"], "title": "AI-powered virtual eye: perspective, challenges and opportunities", "categories": ["q-bio.TO", "cs.AI", "cs.HC"], "comment": "30 Pages, 3 figures, 1 table", "summary": "We envision the \"virtual eye\" as a next-generation, AI-powered platform that\nuses interconnected foundation models to simulate the eye's intricate structure\nand biological function across all scales. Advances in AI, imaging, and\nmultiomics provide a fertile ground for constructing a universal, high-fidelity\ndigital replica of the human eye. This perspective traces the evolution from\nearly mechanistic and rule-based models to contemporary AI-driven approaches,\nintegrating in a unified model with multimodal, multiscale, dynamic predictive\ncapabilities and embedded feedback mechanisms. We propose a development roadmap\nemphasizing the roles of large-scale multimodal datasets, generative AI,\nfoundation models, agent-based architectures, and interactive interfaces.\nDespite challenges in interpretability, ethics, data processing and evaluation,\nthe virtual eye holds the potential to revolutionize personalized ophthalmic\ncare and accelerate research into ocular health and disease."}
{"id": "2505.05599", "pdf": "https://arxiv.org/pdf/2505.05599", "abs": "https://arxiv.org/abs/2505.05599", "authors": ["Seraj Al Mahmud Mostafa", "Chenxi Wang", "Jia Yue", "Yuta Hozumi", "Jianwu Wang"], "title": "Enhancing Satellite Object Localization with Dilated Convolutions and Attention-aided Spatial Pooling", "categories": ["cs.CV", "cs.AI"], "comment": "This paper has been accepted to International conference on Advanced\n  Machine Learning and Data Science (AMLDS) 2025", "summary": "Object localization in satellite imagery is particularly challenging due to\nthe high variability of objects, low spatial resolution, and interference from\nnoise and dominant features such as clouds and city lights. In this research,\nwe focus on three satellite datasets: upper atmospheric Gravity Waves (GW),\nmesospheric Bores (Bore), and Ocean Eddies (OE), each presenting its own unique\nchallenges. These challenges include the variability in the scale and\nappearance of the main object patterns, where the size, shape, and feature\nextent of objects of interest can differ significantly. To address these\nchallenges, we introduce YOLO-DCAP, a novel enhanced version of YOLOv5 designed\nto improve object localization in these complex scenarios. YOLO-DCAP\nincorporates a Multi-scale Dilated Residual Convolution (MDRC) block to capture\nmulti-scale features at scale with varying dilation rates, and an\nAttention-aided Spatial Pooling (AaSP) module to focus on the global relevant\nspatial regions, enhancing feature selection. These structural improvements\nhelp to better localize objects in satellite imagery. Experimental results\ndemonstrate that YOLO-DCAP significantly outperforms both the YOLO base model\nand state-of-the-art approaches, achieving an average improvement of 20.95% in\nmAP50 and 32.23% in IoU over the base model, and 7.35% and 9.84% respectively\nover state-of-the-art alternatives, consistently across all three satellite\ndatasets. These consistent gains across all three satellite datasets highlight\nthe robustness and generalizability of the proposed approach. Our code is open\nsourced at\nhttps://github.com/AI-4-atmosphere-remote-sensing/satellite-object-localization."}
{"id": "2505.05738", "pdf": "https://arxiv.org/pdf/2505.05738", "abs": "https://arxiv.org/abs/2505.05738", "authors": ["Yiming Niu", "Jinliang Deng", "Lulu Zhang", "Zimu Zhou", "Yongxin Tong"], "title": "Accurate and Efficient Multivariate Time Series Forecasting via Offline Clustering", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate and efficient multivariate time series (MTS) forecasting is\nessential for applications such as traffic management and weather prediction,\nwhich depend on capturing long-range temporal dependencies and interactions\nbetween entities. Existing methods, particularly those based on Transformer\narchitectures, compute pairwise dependencies across all time steps, leading to\na computational complexity that scales quadratically with the length of the\ninput. To overcome these challenges, we introduce the Forecaster with Offline\nClustering Using Segments (FOCUS), a novel approach to MTS forecasting that\nsimplifies long-range dependency modeling through the use of prototypes\nextracted via offline clustering. These prototypes encapsulate high-level\nevents in the real-world system underlying the data, summarizing the key\ncharacteristics of similar time segments. In the online phase, FOCUS\ndynamically adapts these patterns to the current input and captures\ndependencies between the input segment and high-level events, enabling both\naccurate and efficient forecasting. By identifying prototypes during the\noffline clustering phase, FOCUS reduces the computational complexity of\nmodeling long-range dependencies in the online phase to linear scaling.\nExtensive experiments across diverse benchmarks demonstrate that FOCUS achieves\nstate-of-the-art accuracy while significantly reducing computational costs."}
{"id": "2505.06073", "pdf": "https://arxiv.org/pdf/2505.06073", "abs": "https://arxiv.org/abs/2505.06073", "authors": ["Rodrigo A. Lobos", "Javier Salazar Cavazos", "Raj Rao Nadakuditi", "Jeffrey A. Fessler"], "title": "Smooth optimization algorithms for global and locally low-rank regularizers", "categories": ["eess.SP", "eess.IV"], "comment": "41 pages, 7 figures", "summary": "Many inverse problems and signal processing problems involve low-rank\nregularizers based on the nuclear norm. Commonly, proximal gradient methods\n(PGM) are adopted to solve this type of non-smooth problems as they can offer\nfast and guaranteed convergence. However, PGM methods cannot be simply applied\nin settings where low-rank models are imposed locally on overlapping patches;\ntherefore, heuristic approaches have been proposed that lack convergence\nguarantees. In this work we propose to replace the nuclear norm with a smooth\napproximation in which a Huber-type function is applied to each singular value.\nBy providing a theoretical framework based on singular value function theory,\nwe show that important properties can be established for the proposed\nregularizer, such as: convexity, differentiability, and Lipschitz continuity of\nthe gradient. Moreover, we provide a closed-form expression for the regularizer\ngradient, enabling the use of standard iterative gradient-based optimization\nalgorithms (e.g., nonlinear conjugate gradient) that can easily address the\ncase of overlapping patches and have well-known convergence guarantees. In\naddition, we provide a novel step-size selection strategy based on a quadratic\nmajorizer of the line-search function that leverages the Huber characteristics\nof the proposed regularizer. Finally, we assess the proposed optimization\nframework by providing empirical results in dynamic magnetic resonance imaging\n(MRI) reconstruction in the context of locally low-rank models with overlapping\npatches."}
{"id": "2505.06151", "pdf": "https://arxiv.org/pdf/2505.06151", "abs": "https://arxiv.org/abs/2505.06151", "authors": ["Alice Rueda", "Argyrios Perivolaris", "Niloy Roy", "Dylan Weston", "Sarmed Shaya", "Zachary Cote", "Martin Ivanov", "Bazen G. Teferra", "Yuqi Wu", "Sirisha Rambhatla", "Divya Sharma", "Andrew Greenshaw", "Rakesh Jetly", "Yanbo Zhang", "Bo Cao", "Reza Samavi", "Sridhar Krishnan", "Venkat Bhat"], "title": "Estimating Quality in Therapeutic Conversations: A Multi-Dimensional Natural Language Processing Framework", "categories": ["cs.CL"], "comment": "12 pages, 4 figures, 7 tables", "summary": "Engagement between client and therapist is a critical determinant of\ntherapeutic success. We propose a multi-dimensional natural language processing\n(NLP) framework that objectively classifies engagement quality in counseling\nsessions based on textual transcripts. Using 253 motivational interviewing\ntranscripts (150 high-quality, 103 low-quality), we extracted 42 features\nacross four domains: conversational dynamics, semantic similarity as topic\nalignment, sentiment classification, and question detection. Classifiers,\nincluding Random Forest (RF), Cat-Boost, and Support Vector Machines (SVM),\nwere hyperparameter tuned and trained using a stratified 5-fold\ncross-validation and evaluated on a holdout test set. On balanced\n(non-augmented) data, RF achieved the highest classification accuracy (76.7%),\nand SVM achieved the highest AUC (85.4%). After SMOTE-Tomek augmentation,\nperformance improved significantly: RF achieved up to 88.9% accuracy, 90.0%\nF1-score, and 94.6% AUC, while SVM reached 81.1% accuracy, 83.1% F1-score, and\n93.6% AUC. The augmented data results reflect the potential of the framework in\nfuture larger-scale applications. Feature contribution revealed conversational\ndynamics and semantic similarity between clients and therapists were among the\ntop contributors, led by words uttered by the client (mean and standard\ndeviation). The framework was robust across the original and augmented datasets\nand demonstrated consistent improvements in F1 scores and recall. While\ncurrently text-based, the framework supports future multimodal extensions\n(e.g., vocal tone, facial affect) for more holistic assessments. This work\nintroduces a scalable, data-driven method for evaluating engagement quality of\nthe therapy session, offering clinicians real-time feedback to enhance the\nquality of both virtual and in-person therapeutic interactions."}
{"id": "2505.05523", "pdf": "https://arxiv.org/pdf/2505.05523", "abs": "https://arxiv.org/abs/2505.05523", "authors": ["Anna Kusetogullari", "Huseyin Kusetogullari", "Martin Andersson", "Tony Gorschek"], "title": "GenAI in Entrepreneurship: a systematic review of generative artificial intelligence in entrepreneurship research: current issues and future directions", "categories": ["econ.GN", "cs.AI", "q-fin.EC"], "comment": null, "summary": "Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs)\nare recognized to have significant effects on industry and business dynamics,\nnot least because of their impact on the preconditions for entrepreneurship.\nThere is still a lack of knowledge of GenAI as a theme in entrepreneurship\nresearch. This paper presents a systematic literature review aimed at\nidentifying and analyzing the evolving landscape of research on the effects of\nGenAI on entrepreneurship. We analyze 83 peer-reviewed articles obtained from\nleading academic databases: Web of Science and Scopus. Using natural language\nprocessing and unsupervised machine learning techniques with TF-IDF\nvectorization, Principal Component Analysis (PCA), and hierarchical clustering,\nfive major thematic clusters are identified: (1) Digital Transformation and\nBehavioral Models, (2) GenAI-Enhanced Education and Learning Systems, (3)\nSustainable Innovation and Strategic AI Impact, (4) Business Models and Market\nTrends, and (5) Data-Driven Technological Trends in Entrepreneurship. Based on\nthe review, we discuss future research directions, gaps in the current\nliterature, as well as ethical concerns raised in the literature. We highlight\nthe need for more macro-level research on GenAI and LLMs as external enablers\nfor entrepreneurship and for research on effective regulatory frameworks that\nfacilitate business experimentation, innovation, and further technology\ndevelopment."}
{"id": "2505.05621", "pdf": "https://arxiv.org/pdf/2505.05621", "abs": "https://arxiv.org/abs/2505.05621", "authors": ["Hao Yang", "Yan Yang", "Ruikun Zhang", "Liyuan Pan"], "title": "A Preliminary Study for GPT-4o on Image Restoration", "categories": ["cs.CV"], "comment": null, "summary": "OpenAI's GPT-4o model, integrating multi-modal inputs and outputs within an\nautoregressive architecture, has demonstrated unprecedented performance in\nimage generation. In this work, we investigate its potential impact on the\nimage restoration community. We present the first systematic evaluation of\nGPT-4o across diverse restoration tasks. Our experiments reveal that, although\nrestoration outputs from GPT-4o are visually appealing, they often suffer from\npixel-level structural fidelity when compared to ground-truth images. Common\nissues are variations in image proportions, shifts in object positions and\nquantities, and changes in viewpoint.To address it, taking image dehazing,\nderainning, and low-light enhancement as representative case studies, we show\nthat GPT-4o's outputs can serve as powerful visual priors, substantially\nenhancing the performance of existing dehazing networks. It offers practical\nguidelines and a baseline framework to facilitate the integration of GPT-4o\ninto future image restoration pipelines. We hope the study on GPT-4o image\nrestoration will accelerate innovation in the broader field of image generation\nareas. To support further research, we will release GPT-4o-restored images from\nover 10 widely used image restoration datasets."}
{"id": "2505.05740", "pdf": "https://arxiv.org/pdf/2505.05740", "abs": "https://arxiv.org/abs/2505.05740", "authors": ["Xi He", "Yi Miao", "Max A. Little"], "title": "Deep-ICE: The first globally optimal algorithm for empirical risk minimization of two-layer maxout and ReLU networks", "categories": ["cs.LG"], "comment": null, "summary": "This paper introduces the first globally optimal algorithm for the empirical\nrisk minimization problem of two-layer maxout and ReLU networks, i.e.,\nminimizing the number of misclassifications. The algorithm has a worst-case\ntime complexity of $O\\left(N^{DK+1}\\right)$, where $K$ denotes the number of\nhidden neurons and $D$ represents the number of features. It can be can be\ngeneralized to accommodate arbitrary computable loss functions without\naffecting its computational complexity. Our experiments demonstrate that the\nproposed algorithm provides provably exact solutions for small-scale datasets.\nTo handle larger datasets, we introduce a novel coreset selection method that\nreduces the data size to a manageable scale, making it feasible for our\nalgorithm. This extension enables efficient processing of large-scale datasets\nand achieves significantly improved performance, with a 20-30\\% reduction in\nmisclassifications for both training and prediction, compared to\nstate-of-the-art approaches (neural networks trained using gradient descent and\nsupport vector machines), when applied to the same models (two-layer networks\nwith fixed hidden nodes and linear models)."}
{"id": "2408.08456", "pdf": "https://arxiv.org/pdf/2408.08456", "abs": "https://arxiv.org/abs/2408.08456", "authors": ["Yusen Wu", "Phuong Nguyen", "Rose Yesha", "Yelena Yesha"], "title": "Distributional Drift Detection in Medical Imaging with Sketching and Fine-Tuned Transformer", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Distributional drift detection is important in medical applications as it\nhelps ensure the accuracy and reliability of models by identifying changes in\nthe underlying data distribution that could affect the prediction results of\nmachine learning models. However, current methods have limitations in detecting\ndrift, for example, the inclusion of abnormal datasets can lead to unfair\ncomparisons. This paper presents an accurate and sensitive approach to detect\ndistributional drift in CT-scan medical images by leveraging data-sketching and\nfine-tuning techniques. We developed a robust baseline library model for\nreal-time anomaly detection, allowing for efficient comparison of incoming\nimages and identification of anomalies. Additionally, we fine-tuned a\npre-trained Vision Transformer model to extract relevant features, using\nmammography as a case study, significantly enhancing model accuracy to 99.11%.\nCombining with data-sketches and fine-tuning, our feature extraction evaluation\ndemonstrated that cosine similarity scores between similar datasets provide\ngreater improvements, from around 50% increased to 99.1%. Finally, the\nsensitivity evaluation shows that our solutions are highly sensitive to even 1%\nsalt-and-pepper and speckle noise, and it is not sensitive to lighting noise\n(e.g., lighting conditions have no impact on data drift). The proposed methods\noffer a scalable and reliable solution for maintaining the accuracy of\ndiagnostic models in dynamic clinical environments."}
{"id": "2505.06186", "pdf": "https://arxiv.org/pdf/2505.06186", "abs": "https://arxiv.org/abs/2505.06186", "authors": ["Massimiliano Pronesti", "Joao Bettencourt-Silva", "Paul Flanagan", "Alessandra Pascale", "Oisin Redmond", "Anya Belz", "Yufang Hou"], "title": "Query-driven Document-level Scientific Evidence Extraction from Biomedical Studies", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Extracting scientific evidence from biomedical studies for clinical research\nquestions (e.g., Does stem cell transplantation improve quality of life in\npatients with medically refractory Crohn's disease compared to placebo?) is a\ncrucial step in synthesising biomedical evidence. In this paper, we focus on\nthe task of document-level scientific evidence extraction for clinical\nquestions with conflicting evidence. To support this task, we create a dataset\ncalled CochraneForest, leveraging forest plots from Cochrane systematic\nreviews. It comprises 202 annotated forest plots, associated clinical research\nquestions, full texts of studies, and study-specific conclusions. Building on\nCochraneForest, we propose URCA (Uniform Retrieval Clustered Augmentation), a\nretrieval-augmented generation framework designed to tackle the unique\nchallenges of evidence extraction. Our experiments show that URCA outperforms\nthe best existing methods by up to 10.3% in F1 score on this task. However, the\nresults also underscore the complexity of CochraneForest, establishing it as a\nchallenging testbed for advancing automated evidence synthesis systems."}
{"id": "2505.05543", "pdf": "https://arxiv.org/pdf/2505.05543", "abs": "https://arxiv.org/abs/2505.05543", "authors": ["Ahdiyeh Alipour", "Tilo Hartmann", "Maryam Alimardani"], "title": "Would You Rely on an Eerie Agent? A Systematic Review of the Impact of the Uncanny Valley Effect on Trust in Human-Agent Interaction", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "75 pages, Figure 11, Table 5", "summary": "Trust is a fundamental component of human-agent interaction. With the\nincreasing presence of artificial agents in daily life, it is essential to\nunderstand how people perceive and trust these agents. One of the key\nchallenges affecting this perception is the Uncanny Valley Effect (UVE), where\nincreasingly human-like artificial beings can be perceived as eerie or\nrepelling. Despite growing interest in trust and the UVE, existing research\nvaries widely in terms of how these concepts are defined and operationalized.\nThis inconsistency raises important questions about how and under what\nconditions the UVE influences trust in agents. A systematic understanding of\ntheir relationship is currently lacking. This review aims to examine the impact\nof the UVE on human trust in agents and to identify methodological patterns,\nlimitations, and gaps in the existing empirical literature. Following PRISMA\nguidelines, a systematic search identified 53 empirical studies that\ninvestigated both UVE-related constructs and trust or trust-related outcomes.\nStudies were analyzed based on a structured set of categories, including types\nof agents and interactions, methodological and measurement approaches, and key\nfindings. The results of our systematic review reveal that most studies rely on\nstatic images or hypothetical scenarios with limited real-time interaction, and\nthe majority use subjective trust measures. This review offers a novel\nframework for classifying trust measurement approaches with regard to the\nbest-practice criteria for empirically investigating the UVE. As the first\nsystematic attempt to map the intersection of UVE and trust, this review\ncontributes to a deeper understanding of their interplay and offers a\nfoundation for future research. Keywords: the uncanny valley effect, trust,\nhuman-likeness, affinity response, human-agent interaction"}
{"id": "2505.05626", "pdf": "https://arxiv.org/pdf/2505.05626", "abs": "https://arxiv.org/abs/2505.05626", "authors": ["Aarti Ghatkesar", "Uddeshya Upadhyay", "Ganesh Venkatesh"], "title": "Looking Beyond Language Priors: Enhancing Visual Comprehension and Attention in Multimodal Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Achieving deep alignment between vision and language remains a central\nchallenge for Multimodal Large Language Models (MLLMs). These models often fail\nto fully leverage visual input, defaulting to strong language priors. Our\napproach first provides insights into how MLLMs internally build visual\nunderstanding of image regions and then introduces techniques to amplify this\ncapability. Specifically, we explore techniques designed both to deepen the\nmodel's understanding of visual content and to ensure that these visual\ninsights actively guide language generation. We demonstrate the superior\nmultimodal understanding of our resultant model through a detailed upstream\nanalysis quantifying its ability to predict visually-dependent tokens as well\nas 10 pt boost on visually challenging tasks."}
{"id": "2505.05744", "pdf": "https://arxiv.org/pdf/2505.05744", "abs": "https://arxiv.org/abs/2505.05744", "authors": ["Ruxue Shi", "Hengrui Gu", "Xu Shen", "Xin Wang"], "title": "Harnessing LLMs Explanations to Boost Surrogate Models in Tabular Data Classification", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable ability in solving complex\ntasks, making them a promising tool for enhancing tabular learning. However,\nexisting LLM-based methods suffer from high resource requirements, suboptimal\ndemonstration selection, and limited interpretability, which largely hinder\ntheir prediction performance and application in the real world. To overcome\nthese problems, we propose a novel in-context learning framework for tabular\nprediction. The core idea is to leverage the explanations generated by LLMs to\nguide a smaller, locally deployable Surrogate Language Model (SLM) to make\ninterpretable tabular predictions. Specifically, our framework mainly involves\nthree stages: (i) Post Hoc Explanation Generation, where LLMs are utilized to\ngenerate explanations for question-answer pairs in candidate demonstrations,\nproviding insights into the reasoning behind the answer. (ii) Post Hoc\nExplanation-Guided Demonstrations Selection, which utilizes explanations\ngenerated by LLMs to guide the process of demonstration selection from\ncandidate demonstrations. (iii) Post Hoc Explanation-Guided Interpretable SLM\nPrediction, which utilizes the demonstrations obtained in step (ii) as\nin-context and merges corresponding explanations as rationales to improve the\nperformance of SLM and guide the model to generate interpretable outputs.\nExperimental results highlight the framework's effectiveness, with an average\naccuracy improvement of 5.31% across various tabular datasets in diverse\ndomains."}
{"id": "2501.15246", "pdf": "https://arxiv.org/pdf/2501.15246", "abs": "https://arxiv.org/abs/2501.15246", "authors": ["Vinith Kishore", "Valentin Debarnot", "Ricardo D. Righetto", "AmirEhsan Khorashadizadeh", "Benjamin D. Engel", "Ivan Dokmanić"], "title": "End-to-end localized deep learning for Cryo-ET", "categories": ["eess.IV"], "comment": null, "summary": "Cryo-electron tomography (cryo-ET) enables 3D visualization of cellular\nenvironments. Accurate reconstruction of high-resolution volumes is complicated\nby the very low signal-to-noise ratio and a restricted range of sample tilts,\ncreating a missing wedge of Fourier information. Recent self-supervised deep\nlearning approaches, which post-process initial reconstructions done by\nfiltered backprojection (FBP), have significantly improved reconstruction\nquality, but they are computationally expensive, demand large memory, and\nrequire retraining for each new dataset. End-to-end supervised learning is an\nappealing alternative but is impeded by the lack of ground truth and the large\nmemory demands of high-resolution volumetric data. Training on synthetic data\noften leads to overfitting and poor generalization to real data, and, to date,\nno general end-to-end deep learning reconstructors exist for cryo-ET. In this\nwork, we introduce CryoLithe, a local, memory-efficient reconstruction network\nthat directly estimates the volume from an aligned tilt-series, overcoming the\nsuboptimal FBP. We demonstrate that leveraging transform-domain locality makes\nour network robust to distribution shifts, enabling effective supervised\ntraining and giving excellent results on real data -- without retraining or\nfine-tuning."}
{"id": "2505.05665", "pdf": "https://arxiv.org/pdf/2505.05665", "abs": "https://arxiv.org/abs/2505.05665", "authors": ["Neeloy Chakraborty", "John Pohovey", "Melkior Ornik", "Katherine Driggs-Campbell"], "title": "Adaptive Stress Testing Black-Box LLM Planners", "categories": ["cs.RO", "cs.AI", "cs.CL"], "comment": "26 pages, 16 figures, 4 tables", "summary": "Large language models (LLMs) have recently demonstrated success in\ngeneralizing across decision-making tasks including planning, control and\nprediction, but their tendency to hallucinate unsafe and undesired outputs\nposes risks. We argue that detecting such failures is necessary, especially in\nsafety-critical scenarios. Existing black-box methods often detect\nhallucinations by identifying inconsistencies across multiple samples. Many of\nthese approaches typically introduce prompt perturbations like randomizing\ndetail order or generating adversarial inputs, with the intuition that a\nconfident model should produce stable outputs. We first perform a manual case\nstudy showing that other forms of perturbations (e.g., adding noise, removing\nsensor details) cause LLMs to hallucinate in a driving environment. We then\npropose a novel method for efficiently searching the space of prompt\nperturbations using Adaptive Stress Testing (AST) with Monte-Carlo Tree Search\n(MCTS). Our AST formulation enables discovery of scenarios and prompts that\ncause language models to act with high uncertainty. By generating MCTS prompt\nperturbation trees across diverse scenarios, we show that offline analyses can\nbe used at runtime to automatically generate prompts that influence model\nuncertainty, and to inform real-time trust assessments of an LLM."}
{"id": "2505.05588", "pdf": "https://arxiv.org/pdf/2505.05588", "abs": "https://arxiv.org/abs/2505.05588", "authors": ["Somrita Banerjee", "Abhishek Cauligi", "Marco Pavone"], "title": "Flight Validation of Learning-Based Trajectory Optimization for the Astrobee Free-Flyer", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Submitted to RSS 2025 Workshop on Space Robotics", "summary": "Although widely used in commercial and industrial robotics, trajectory\noptimization has seen limited use in space applications due to its high\ncomputational demands. In this work, we present flight results from experiments\nwith the Astrobee free-flying robot on board the International Space Station\n(ISS), that demonstrate how machine learning can accelerate on-board trajectory\noptimization while preserving theoretical solver guarantees. To the best of the\nauthors' knowledge, this is the first-ever demonstration of learning-based\ncontrol on the ISS. Our approach leverages the GuSTO sequential convex\nprogramming framework and uses a neural network, trained offline, to map\nproblem parameters to effective initial ``warm-start'' trajectories, paving the\nway for faster real-time optimization on resource-constrained space platforms."}
{"id": "2505.05635", "pdf": "https://arxiv.org/pdf/2505.05635", "abs": "https://arxiv.org/abs/2505.05635", "authors": ["Faizan Farooq Khan", "Jun Chen", "Youssef Mohamed", "Chun-Mei Feng", "Mohamed Elhoseiny"], "title": "VR-RAG: Open-vocabulary Species Recognition with RAG-Assisted Large Multi-Modal Models", "categories": ["cs.CV"], "comment": "7 figures", "summary": "Open-vocabulary recognition remains a challenging problem in computer vision,\nas it requires identifying objects from an unbounded set of categories. This is\nparticularly relevant in nature, where new species are discovered every year.\nIn this work, we focus on open-vocabulary bird species recognition, where the\ngoal is to classify species based on their descriptions without being\nconstrained to a predefined set of taxonomic categories. Traditional benchmarks\nlike CUB-200-2011 and Birdsnap have been evaluated in a closed-vocabulary\nparadigm, limiting their applicability to real-world scenarios where novel\nspecies continually emerge. We show that the performance of current systems\nwhen evaluated under settings closely aligned with open-vocabulary drops by a\nhuge margin. To address this gap, we propose a scalable framework integrating\nstructured textual knowledge from Wikipedia articles of 11,202 bird species\ndistilled via GPT-4o into concise, discriminative summaries. We propose Visual\nRe-ranking Retrieval-Augmented Generation(VR-RAG), a novel, retrieval-augmented\ngeneration framework that uses visual similarities to rerank the top m\ncandidates retrieved by a set of multimodal vision language encoders. This\nallows for the recognition of unseen taxa. Extensive experiments across five\nestablished classification benchmarks show that our approach is highly\neffective. By integrating VR-RAG, we improve the average performance of\nstate-of-the-art Large Multi-Modal Model QWEN2.5-VL by 15.4% across five\nbenchmarks. Our approach outperforms conventional VLM-based approaches, which\nstruggle with unseen species. By bridging the gap between encyclopedic\nknowledge and visual recognition, our work advances open-vocabulary\nrecognition, offering a flexible, scalable solution for biodiversity monitoring\nand ecological research."}
{"id": "2505.05763", "pdf": "https://arxiv.org/pdf/2505.05763", "abs": "https://arxiv.org/abs/2505.05763", "authors": ["Yize Zhou", "Jie Zhang", "Meijie Wang", "Lun Yu"], "title": "BMMDetect: A Multimodal Deep Learning Framework for Comprehensive Biomedical Misconduct Detection", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Academic misconduct detection in biomedical research remains challenging due\nto algorithmic narrowness in existing methods and fragmented analytical\npipelines. We present BMMDetect, a multimodal deep learning framework that\nintegrates journal metadata (SJR, institutional data), semantic embeddings\n(PubMedBERT), and GPT-4o-mined textual attributes (methodological statistics,\ndata anomalies) for holistic manuscript evaluation. Key innovations include:\n(1) multimodal fusion of domain-specific features to reduce detection bias; (2)\nquantitative evaluation of feature importance, identifying journal authority\nmetrics (e.g., SJR-index) and textual anomalies (e.g., statistical outliers) as\ndominant predictors; and (3) the BioMCD dataset, a large-scale benchmark with\n13,160 retracted articles and 53,411 controls. BMMDetect achieves 74.33% AUC,\noutperforming single-modality baselines by 8.6%, and demonstrates\ntransferability across biomedical subfields. This work advances scalable,\ninterpretable tools for safeguarding research integrity."}
{"id": "2502.04521", "pdf": "https://arxiv.org/pdf/2502.04521", "abs": "https://arxiv.org/abs/2502.04521", "authors": ["Valiyeh A. Nezhad", "Gokberk Elmas", "Bilal Kabas", "Fuat Arslan", "Tolga Çukur"], "title": "Generative Autoregressive Transformers for Model-Agnostic Federated MRI Reconstruction", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Although learning-based models hold great promise for MRI reconstruction,\nsingle-site models built on limited local datasets often suffer from poor\ngeneralization. This challenge has spurred interest in collaborative model\ntraining on multi-site datasets via federated learning (FL) -- a\nprivacy-preserving framework that aggregates model updates instead of sharing\nimaging data. Conventional FL aggregates locally trained model weights into a\nglobal model, inherently constraining all sites to use a homogeneous model\narchitecture. This rigidity forces sites to compromise on architectures\ntailored to their compute resources and application-specific needs, making\nconventional FL unsuitable for model-heterogeneous settings where each site may\nprefer a distinct architecture. To overcome this limitation, we introduce\nFedGAT, a novel model-agnostic FL technique based on generative autoregressive\ntransformers. FedGAT decentralizes the training of a global generative prior\nthat learns the distribution of multi-site MR images. For high-fidelity\nsynthesis, we propose a novel site-prompted GAT prior that controllably\nsynthesizes realistic MR images from desired sites via autoregressive\nprediction across spatial scales. Each site then trains its own reconstruction\nmodel -- using an architecture of its choice -- on a hybrid dataset augmenting\nits local MRI dataset with GAT-generated synthetic MR images emulating datasets\nfrom other sites. This hybrid training strategy enables site-specific\nreconstruction models to generalize more effectively across diverse data\ndistributions while preserving data privacy. Comprehensive experiments on\nmulti-institutional datasets demonstrate that FedGAT enables flexible,\nmodel-heterogeneous collaborations and achieves superior within-site and\ncross-site reconstruction performance compared to state-of-the-art FL\nbaselines."}
{"id": "2505.05736", "pdf": "https://arxiv.org/pdf/2505.05736", "abs": "https://arxiv.org/abs/2505.05736", "authors": ["Da Wu", "Zhanliang Wang", "Quan Nguyen", "Zhuoran Xu", "Kai Wang"], "title": "Multimodal Integrated Knowledge Transfer to Large Language Models through Preference Optimization with Biomedical Applications", "categories": ["q-bio.QM", "cs.CL", "cs.CV", "cs.LG"], "comment": "First Draft", "summary": "The scarcity of high-quality multimodal biomedical data limits the ability to\neffectively fine-tune pretrained Large Language Models (LLMs) for specialized\nbiomedical tasks. To address this challenge, we introduce MINT (Multimodal\nIntegrated kNowledge Transfer), a framework that aligns unimodal large decoder\nmodels with domain-specific decision patterns from multimodal biomedical data\nthrough preference optimization. While MINT supports different optimization\ntechniques, we primarily implement it with the Odds Ratio Preference\nOptimization (ORPO) framework as its backbone. This strategy enables the\naligned LLMs to perform predictive tasks using text-only or image-only inputs\nwhile retaining knowledge learnt from multimodal data. MINT leverages an\nupstream multimodal machine learning (MML) model trained on high-quality\nmultimodal data to transfer domain-specific insights to downstream text-only or\nimage-only LLMs. We demonstrate its effectiveness through two key applications:\n(1) Rare genetic disease prediction from texts, where MINT uses a multimodal\nencoder model, trained on facial photos and clinical notes, to generate a\npreference dataset for aligning a lightweight Llama 3.2-3B-Instruct. Despite\nrelying on text input only, the MINT-derived model outperforms models trained\nwith SFT, RAG, or DPO, and even outperforms Llama 3.1-405B-Instruct. (2) Tissue\ntype classification using cell nucleus images, where MINT uses a\nvision-language foundation model as the preference generator, containing\nknowledge learnt from both text and histopathological images to align\ndownstream image-only models. The resulting MINT-derived model significantly\nimproves the performance of Llama 3.2-Vision-11B-Instruct on tissue type\nclassification. In summary, MINT provides an effective strategy to align\nunimodal LLMs with high-quality multimodal expertise through preference\noptimization."}
{"id": "2505.05595", "pdf": "https://arxiv.org/pdf/2505.05595", "abs": "https://arxiv.org/abs/2505.05595", "authors": ["Wenhao Guo", "Yuda Wang", "Zeqiao Huang", "Changjiang Zhang", "Shumin ma"], "title": "Trading Under Uncertainty: A Distribution-Based Strategy for Futures Markets Using FutureQuant Transformer", "categories": ["q-fin.TR", "cs.AI", "cs.CE", "cs.LG"], "comment": "16 pages, 12 figures", "summary": "In the complex landscape of traditional futures trading, where vast data and\nvariables like real-time Limit Order Books (LOB) complicate price predictions,\nwe introduce the FutureQuant Transformer model, leveraging attention mechanisms\nto navigate these challenges. Unlike conventional models focused on point\npredictions, the FutureQuant model excels in forecasting the range and\nvolatility of future prices, thus offering richer insights for trading\nstrategies. Its ability to parse and learn from intricate market patterns\nallows for enhanced decision-making, significantly improving risk management\nand achieving a notable average gain of 0.1193% per 30-minute trade over\nstate-of-the-art models with a simple algorithm using factors such as RSI, ATR,\nand Bollinger Bands. This innovation marks a substantial leap forward in\npredictive analytics within the volatile domain of futures trading."}
{"id": "2505.05640", "pdf": "https://arxiv.org/pdf/2505.05640", "abs": "https://arxiv.org/abs/2505.05640", "authors": ["Anadil Hussein", "Anna Zamansky", "George Martvel"], "title": "Semantic Style Transfer for Enhancing Animal Facial Landmark Detection", "categories": ["cs.CV"], "comment": null, "summary": "Neural Style Transfer (NST) is a technique for applying the visual\ncharacteristics of one image onto another while preserving structural content.\nTraditionally used for artistic transformations, NST has recently been adapted,\ne.g., for domain adaptation and data augmentation. This study investigates the\nuse of this technique for enhancing animal facial landmark detectors training.\nAs a case study, we use a recently introduced Ensemble Landmark Detector for 48\nanatomical cat facial landmarks and the CatFLW dataset it was trained on,\nmaking three main contributions. First, we demonstrate that applying style\ntransfer to cropped facial images rather than full-body images enhances\nstructural consistency, improving the quality of generated images. Secondly,\nreplacing training images with style-transferred versions raised challenges of\nannotation misalignment, but Supervised Style Transfer (SST) - which selects\nstyle sources based on landmark accuracy - retained up to 98% of baseline\naccuracy. Finally, augmenting the dataset with style-transferred images further\nimproved robustness, outperforming traditional augmentation methods. These\nfindings establish semantic style transfer as an effective augmentation\nstrategy for enhancing the performance of facial landmark detection models for\nanimals and beyond. While this study focuses on cat facial landmarks, the\nproposed method can be generalized to other species and landmark detection\nmodels."}
{"id": "2505.05785", "pdf": "https://arxiv.org/pdf/2505.05785", "abs": "https://arxiv.org/abs/2505.05785", "authors": ["Henan Sun", "Xunkai Li", "Lei Zhu", "Junyi Han", "Guang Zeng", "Ronghua Li", "Guoren Wang"], "title": "Rethinking Graph Out-Of-Distribution Generalization: A Learnable Random Walk Perspective", "categories": ["cs.LG"], "comment": "Under Review", "summary": "Out-Of-Distribution (OOD) generalization has gained increasing attentions for\nmachine learning on graphs, as graph neural networks (GNNs) often exhibit\nperformance degradation under distribution shifts. Existing graph OOD methods\ntend to follow the basic ideas of invariant risk minimization and structural\ncausal models, interpreting the invariant knowledge across datasets under\nvarious distribution shifts as graph topology or graph spectrum. However, these\ninterpretations may be inconsistent with real-world scenarios, as neither\ninvariant topology nor spectrum is assured. In this paper, we advocate the\nlearnable random walk (LRW) perspective as the instantiation of invariant\nknowledge, and propose LRW-OOD to realize graph OOD generalization learning.\nInstead of employing fixed probability transition matrix (i.e.,\ndegree-normalized adjacency matrix), we parameterize the transition matrix with\nan LRW-sampler and a path encoder. Furthermore, we propose the kernel density\nestimation (KDE)-based mutual information (MI) loss to generate random walk\nsequences that adhere to OOD principles. Extensive experiment demonstrates that\nour model can effectively enhance graph OOD generalization under various types\nof distribution shifts and yield a significant accuracy improvement of 3.87%\nover state-of-the-art graph OOD generalization baselines."}
{"id": "2505.04105", "pdf": "https://arxiv.org/pdf/2505.04105", "abs": "https://arxiv.org/abs/2505.04105", "authors": ["Andrew Zhang", "Hao Wang", "Shuchang Ye", "Michael Fulham", "Jinman Kim"], "title": "MAISY: Motion-Aware Image SYnthesis for Medical Image Motion Correction", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Patient motion during medical image acquisition causes blurring, ghosting,\nand distorts organs, which makes image interpretation challenging. Current\nstate-of-the-art algorithms using Generative Adversarial Network (GAN)-based\nmethods with their ability to learn the mappings between corrupted images and\ntheir ground truth via Structural Similarity Index Measure (SSIM) loss\neffectively generate motion-free images. However, we identified the following\nlimitations: (i) they mainly focus on global structural characteristics and\ntherefore overlook localized features that often carry critical pathological\ninformation, and (ii) the SSIM loss function struggles to handle images with\nvarying pixel intensities, luminance factors, and variance. In this study, we\npropose Motion-Aware Image SYnthesis (MAISY) which initially characterize\nmotion and then uses it for correction by: (a) leveraging the foundation model\nSegment Anything Model (SAM), to dynamically learn spatial patterns along\nanatomical boundaries where motion artifacts are most pronounced and, (b)\nintroducing the Variance-Selective SSIM (VS-SSIM) loss which adaptively\nemphasizes spatial regions with high pixel variance to preserve essential\nanatomical details during artifact correction. Experiments on chest and head CT\ndatasets demonstrate that our model outperformed the state-of-the-art\ncounterparts, with Peak Signal-to-Noise Ratio (PSNR) increasing by 40%, SSIM by\n10%, and Dice by 16%."}
{"id": "2505.05828", "pdf": "https://arxiv.org/pdf/2505.05828", "abs": "https://arxiv.org/abs/2505.05828", "authors": ["Alba María Mármol-Romero", "Manuel García-Vega", "Miguel Ángel García-Cumbreras", "Arturo Montejo-Ráez"], "title": "An empathic GPT-based chatbot to talk about mental disorders with Spanish teenagers", "categories": ["cs.HC", "cs.CL"], "comment": "This is an Accepted Manuscript version of the following article,\n  accepted for publication in International Journal of Human-Computer\n  Interaction. It is deposited under the terms of the Creative Commons\n  Attribution-NonCommercial-NoDerivatives License", "summary": "This paper presents a chatbot-based system to engage young Spanish people in\nthe awareness of certain mental disorders through a self-disclosure technique.\nThe study was carried out in a population of teenagers aged between 12 and 18\nyears. The dialogue engine mixes closed and open conversations, so certain\ncontrolled messages are sent to focus the chat on a specific disorder, which\nwill change over time. Once a set of trial questions is answered, the system\ncan initiate the conversation on the disorder under the focus according to the\nuser's sensibility to that disorder, in an attempt to establish a more\nempathetic communication. Then, an open conversation based on the GPT-3\nlanguage model is initiated, allowing the user to express themselves with more\nfreedom. The results show that these systems are of interest to young people\nand could help them become aware of certain mental disorders."}
{"id": "2505.05622", "pdf": "https://arxiv.org/pdf/2505.05622", "abs": "https://arxiv.org/abs/2505.05622", "authors": ["Weichen Zhang", "Chen Gao", "Shiquan Yu", "Ruiying Peng", "Baining Zhao", "Qian Zhang", "Jinqiang Cui", "Xinlei Chen", "Yong Li"], "title": "CityNavAgent: Aerial Vision-and-Language Navigation with Hierarchical Semantic Planning and Global Memory", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Aerial vision-and-language navigation (VLN), requiring drones to interpret\nnatural language instructions and navigate complex urban environments, emerges\nas a critical embodied AI challenge that bridges human-robot interaction, 3D\nspatial reasoning, and real-world deployment. Although existing ground VLN\nagents achieved notable results in indoor and outdoor settings, they struggle\nin aerial VLN due to the absence of predefined navigation graphs and the\nexponentially expanding action space in long-horizon exploration. In this work,\nwe propose \\textbf{CityNavAgent}, a large language model (LLM)-empowered agent\nthat significantly reduces the navigation complexity for urban aerial VLN.\nSpecifically, we design a hierarchical semantic planning module (HSPM) that\ndecomposes the long-horizon task into sub-goals with different semantic levels.\nThe agent reaches the target progressively by achieving sub-goals with\ndifferent capacities of the LLM. Additionally, a global memory module storing\nhistorical trajectories into a topological graph is developed to simplify\nnavigation for visited targets. Extensive benchmark experiments show that our\nmethod achieves state-of-the-art performance with significant improvement.\nFurther experiments demonstrate the effectiveness of different modules of\nCityNavAgent for aerial VLN in continuous city environments. The code is\navailable at \\href{https://github.com/VinceOuti/CityNavAgent}{link}."}
{"id": "2505.05666", "pdf": "https://arxiv.org/pdf/2505.05666", "abs": "https://arxiv.org/abs/2505.05666", "authors": ["Alexander Most", "Joseph Winjum", "Ayan Biswas", "Shawn Jones", "Nishath Rajiv Ranasinghe", "Dan O'Malley", "Manish Bhattarai"], "title": "Lost in OCR Translation? Vision-Based Approaches to Robust Document Retrieval", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has become a popular technique for\nenhancing the reliability and utility of Large Language Models (LLMs) by\ngrounding responses in external documents. Traditional RAG systems rely on\nOptical Character Recognition (OCR) to first process scanned documents into\ntext. However, even state-of-the-art OCRs can introduce errors, especially in\ndegraded or complex documents. Recent vision-language approaches, such as\nColPali, propose direct visual embedding of documents, eliminating the need for\nOCR. This study presents a systematic comparison between a vision-based RAG\nsystem (ColPali) and more traditional OCR-based pipelines utilizing Llama 3.2\n(90B) and Nougat OCR across varying document qualities. Beyond conventional\nretrieval accuracy metrics, we introduce a semantic answer evaluation benchmark\nto assess end-to-end question-answering performance. Our findings indicate that\nwhile vision-based RAG performs well on documents it has been fine-tuned on,\nOCR-based RAG is better able to generalize to unseen documents of varying\nquality. We highlight the key trade-offs between computational efficiency and\nsemantic accuracy, offering practical guidance for RAG practitioners in\nselecting between OCR-dependent and vision-based document retrieval systems in\nproduction environments."}
{"id": "2505.05799", "pdf": "https://arxiv.org/pdf/2505.05799", "abs": "https://arxiv.org/abs/2505.05799", "authors": ["Haojie Duanmu", "Xiuhong Li", "Zhihang Yuan", "Size Zheng", "Jiangfei Duan", "Xingcheng Zhang", "Dahua Lin"], "title": "MxMoE: Mixed-precision Quantization for MoE with Accuracy and Performance Co-Design", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Mixture-of-Experts (MoE) models face deployment challenges due to their large\nparameter counts and computational demands. We explore quantization for MoE\nmodels and highlight two key insights: 1) linear blocks exhibit varying\nquantization sensitivity, and 2) divergent expert activation frequencies create\nheterogeneous computational characteristics. Based on these observations, we\nintroduce MxMoE, a mixed-precision optimization framework for MoE models that\nconsiders both algorithmic and system perspectives. MxMoE navigates the design\nspace defined by parameter sensitivity, expert activation dynamics, and\nhardware resources to derive efficient mixed-precision configurations.\nAdditionally, MxMoE automatically generates optimized mixed-precision GroupGEMM\nkernels, enabling parallel execution of GEMMs with different precisions.\nEvaluations show that MxMoE outperforms existing methods, achieving 2.4 lower\nWikitext-2 perplexity than GPTQ at 2.25-bit and delivering up to 3.4x speedup\nover full precision, as well as up to 29.4% speedup over uniform quantization\nat equivalent accuracy with 5-bit weight-activation quantization. Our code is\navailable at https://github.com/cat538/MxMoE."}
{"id": "2306.14070", "pdf": "https://arxiv.org/pdf/2306.14070", "abs": "https://arxiv.org/abs/2306.14070", "authors": ["Pu Ren", "N. Benjamin Erichson", "Junyi Guo", "Shashank Subramanian", "Omer San", "Zarija Lukic", "Michael W. Mahoney"], "title": "SuperBench: A Super-Resolution Benchmark Dataset for Scientific Machine Learning", "categories": ["cs.CV", "eess.IV", "physics.comp-ph"], "comment": "Accepted to Journal of Data-centric Machine Learning Research", "summary": "Super-resolution (SR) techniques aim to enhance data resolution, enabling the\nretrieval of finer details, and improving the overall quality and fidelity of\nthe data representation. There is growing interest in applying SR methods to\ncomplex spatiotemporal systems within the Scientific Machine Learning (SciML)\ncommunity, with the hope of accelerating numerical simulations and/or improving\nforecasts in weather, climate, and related areas. However, the lack of\nstandardized benchmark datasets for comparing and validating SR methods hinders\nprogress and adoption in SciML. To address this, we introduce SuperBench, the\nfirst benchmark dataset featuring high-resolution datasets, including data from\nfluid flows, cosmology, and weather. Here, we focus on validating spatial SR\nperformance from data-centric and physics-preserved perspectives, as well as\nassessing robustness to data degradation tasks. While deep learning-based SR\nmethods (developed in the computer vision community) excel on certain tasks,\ndespite relatively limited prior physics information, we identify limitations\nof these methods in accurately capturing intricate fine-scale features and\npreserving fundamental physical properties and constraints in scientific data.\nThese shortcomings highlight the importance and subtlety of incorporating\ndomain knowledge into ML models. We anticipate that SuperBench will help to\nadvance SR methods for science."}
{"id": "2505.05863", "pdf": "https://arxiv.org/pdf/2505.05863", "abs": "https://arxiv.org/abs/2505.05863", "authors": ["Reiji Suzuki", "Takaya Arita"], "title": "Evolutionary ecology of words", "categories": ["q-bio.PE", "cs.AI", "cs.CL", "92B20"], "comment": "8 pages, 5 figures. Preprint of the paper published in Proceedings of\n  2025 IEEE Symposium on Computational Intelligence in Artificial Life and\n  Cooperative Intelligent Systems (ALIFE-CIS)", "summary": "We propose a model for the evolutionary ecology of words as one attempt to\nextend evolutionary game theory and agent-based models by utilizing the rich\nlinguistic expressions of Large Language Models (LLMs). Our model enables the\nemergence and evolution of diverse and infinite options for interactions among\nagents. Within the population, each agent possesses a short word (or phrase)\ngenerated by an LLM and moves within a spatial environment. When agents become\nadjacent, the outcome of their interaction is determined by the LLM based on\nthe relationship between their words, with the loser's word being replaced by\nthe winner's. Word mutations, also based on LLM outputs, may occur. We\nconducted preliminary experiments assuming that ``strong animal species\" would\nsurvive. The results showed that from an initial population consisting of\nwell-known species, many species emerged both gradually and in a punctuated\nequilibrium manner. Each trial demonstrated the unique evolution of diverse\npopulations, with one type of large species becoming dominant, such as\nterrestrial animals, marine life, or extinct species, which were ecologically\nspecialized and adapted ones across diverse extreme habitats. We also conducted\na long-term experiment with a large population, demonstrating the emergence and\ncoexistence of diverse species."}
{"id": "2505.05638", "pdf": "https://arxiv.org/pdf/2505.05638", "abs": "https://arxiv.org/abs/2505.05638", "authors": ["Mohamed-Khalil Bouzidi", "Christian Schlauch", "Nicole Scheuerer", "Yue Yao", "Nadja Klein", "Daniel Göhring", "Jörg Reichardt"], "title": "Closing the Loop: Motion Prediction Models beyond Open-Loop Benchmarks", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Fueled by motion prediction competitions and benchmarks, recent years have\nseen the emergence of increasingly large learning based prediction models, many\nwith millions of parameters, focused on improving open-loop prediction accuracy\nby mere centimeters. However, these benchmarks fail to assess whether such\nimprovements translate to better performance when integrated into an autonomous\ndriving stack. In this work, we systematically evaluate the interplay between\nstate-of-the-art motion predictors and motion planners. Our results show that\nhigher open-loop accuracy does not always correlate with better closed-loop\ndriving behavior and that other factors, such as temporal consistency of\npredictions and planner compatibility, also play a critical role. Furthermore,\nwe investigate downsized variants of these models, and, surprisingly, find that\nin some cases models with up to 86% fewer parameters yield comparable or even\nsuperior closed-loop driving performance. Our code is available at\nhttps://github.com/continental/pred2plan."}
{"id": "2505.05672", "pdf": "https://arxiv.org/pdf/2505.05672", "abs": "https://arxiv.org/abs/2505.05672", "authors": ["Gengyan Li", "Paulo Gotardo", "Timo Bolkart", "Stephan Garbin", "Kripasindhu Sarkar", "Abhimitra Meka", "Alexandros Lattas", "Thabo Beeler"], "title": "TeGA: Texture Space Gaussian Avatars for High-Resolution Dynamic Head Modeling", "categories": ["cs.CV", "I.3.7; I.3.5"], "comment": "10 pages, 9 figures, supplementary results found at:\n  https://syntec-research.github.io/UVGA/, to be published in SIGGRAPH 2025", "summary": "Sparse volumetric reconstruction and rendering via 3D Gaussian splatting have\nrecently enabled animatable 3D head avatars that are rendered under arbitrary\nviewpoints with impressive photorealism. Today, such photoreal avatars are seen\nas a key component in emerging applications in telepresence, extended reality,\nand entertainment. Building a photoreal avatar requires estimating the complex\nnon-rigid motion of different facial components as seen in input video images;\ndue to inaccurate motion estimation, animatable models typically present a loss\nof fidelity and detail when compared to their non-animatable counterparts,\nbuilt from an individual facial expression. Also, recent state-of-the-art\nmodels are often affected by memory limitations that reduce the number of 3D\nGaussians used for modeling, leading to lower detail and quality. To address\nthese problems, we present a new high-detail 3D head avatar model that improves\nupon the state of the art, largely increasing the number of 3D Gaussians and\nmodeling quality for rendering at 4K resolution. Our high-quality model is\nreconstructed from multiview input video and builds on top of a mesh-based 3D\nmorphable model, which provides a coarse deformation layer for the head.\nPhotoreal appearance is modelled by 3D Gaussians embedded within the continuous\nUVD tangent space of this mesh, allowing for more effective densification where\nmost needed. Additionally, these Gaussians are warped by a novel UVD\ndeformation field to capture subtle, localized motion. Our key contribution is\nthe novel deformable Gaussian encoding and overall fitting procedure that\nallows our head model to preserve appearance detail, while capturing facial\nmotion and other transient high-frequency features such as skin wrinkling."}
{"id": "2505.05803", "pdf": "https://arxiv.org/pdf/2505.05803", "abs": "https://arxiv.org/abs/2505.05803", "authors": ["Yiming Li", "Man He", "Jiapeng Liu"], "title": "A novel Neural-ODE model for the state of health estimation of lithium-ion battery using charging curve", "categories": ["cs.LG"], "comment": "28 pages, 6 figures", "summary": "The state of health (SOH) of lithium-ion batteries (LIBs) is crucial for\nensuring the safe and reliable operation of electric vehicles. Nevertheless,\nthe prevailing SOH estimation methods often have limited generalizability. This\npaper introduces a data-driven approach for estimating the SOH of LIBs, which\nis designed to improve generalization. We construct a hybrid model named ACLA,\nwhich integrates the attention mechanism, convolutional neural network (CNN),\nand long short-term memory network (LSTM) into the augmented neural ordinary\ndifferential equation (ANODE) framework. This model employs normalized charging\ntime corresponding to specific voltages in the constant current charging phase\nas input and outputs the SOH as well as remaining useful of life. The model is\ntrained on NASA and Oxford datasets and validated on the TJU and HUST datasets.\nCompared to the benchmark models NODE and ANODE, ACLA exhibits higher accuracy\nwith root mean square errors (RMSE) for SOH estimation as low as 1.01% and\n2.24% on the TJU and HUST datasets, respectively."}
{"id": "2505.06032", "pdf": "https://arxiv.org/pdf/2505.06032", "abs": "https://arxiv.org/abs/2505.06032", "authors": ["Leon Eshuijs", "Shihan Wang", "Antske Fokkens"], "title": "Short-circuiting Shortcuts: Mechanistic Investigation of Shortcuts in Text Classification", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Reliance on spurious correlations (shortcuts) has been shown to underlie many\nof the successes of language models. Previous work focused on identifying the\ninput elements that impact prediction. We investigate how shortcuts are\nactually processed within the model's decision-making mechanism. We use actor\nnames in movie reviews as controllable shortcuts with known impact on the\noutcome. We use mechanistic interpretability methods and identify specific\nattention heads that focus on shortcuts. These heads gear the model towards a\nlabel before processing the complete input, effectively making premature\ndecisions that bypass contextual analysis. Based on these findings, we\nintroduce Head-based Token Attribution (HTA), which traces intermediate\ndecisions back to input tokens. We show that HTA is effective in detecting\nshortcuts in LLMs and enables targeted mitigation by selectively deactivating\nshortcut-related attention heads."}
{"id": "2505.05753", "pdf": "https://arxiv.org/pdf/2505.05753", "abs": "https://arxiv.org/abs/2505.05753", "authors": ["Bo Ai", "Liu Dai", "Nico Bohlinger", "Dichen Li", "Tongzhou Mu", "Zhanxin Wu", "K. Fay", "Henrik I. Christensen", "Jan Peters", "Hao Su"], "title": "Towards Embodiment Scaling Laws in Robot Locomotion", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "32 pages. Project website: https://embodiment-scaling-laws.github.io/", "summary": "Developing generalist agents that can operate across diverse tasks,\nenvironments, and physical embodiments is a grand challenge in robotics and\nartificial intelligence. In this work, we focus on the axis of embodiment and\ninvestigate embodiment scaling laws$\\unicode{x2013}$the hypothesis that\nincreasing the number of training embodiments improves generalization to unseen\nones. Using robot locomotion as a test bed, we procedurally generate a dataset\nof $\\sim$1,000 varied embodiments, spanning humanoids, quadrupeds, and\nhexapods, and train generalist policies capable of handling diverse observation\nand action spaces on random subsets. We find that increasing the number of\ntraining embodiments improves generalization to unseen ones, and scaling\nembodiments is more effective in enabling embodiment-level generalization than\nscaling data on small, fixed sets of embodiments. Notably, our best policy,\ntrained on the full dataset, zero-shot transfers to novel embodiments in the\nreal world, such as Unitree Go2 and H1. These results represent a step toward\ngeneral embodied intelligence, with potential relevance to adaptive control for\nconfigurable robots, co-design of morphology and control, and beyond."}
{"id": "2505.05678", "pdf": "https://arxiv.org/pdf/2505.05678", "abs": "https://arxiv.org/abs/2505.05678", "authors": ["Etai Sella", "Yanir Kleiman", "Hadar Averbuch-Elor"], "title": "InstanceGen: Image Generation with Instance-level Instructions", "categories": ["cs.CV"], "comment": "Project page: https://tau-vailab.github.io/InstanceGen/", "summary": "Despite rapid advancements in the capabilities of generative models,\npretrained text-to-image models still struggle in capturing the semantics\nconveyed by complex prompts that compound multiple objects and instance-level\nattributes. Consequently, we are witnessing growing interests in integrating\nadditional structural constraints, %leveraging additional structural inputs\ntypically in the form of coarse bounding boxes, to better guide the generation\nprocess in such challenging cases. In this work, we take the idea of structural\nguidance a step further by making the observation that contemporary image\ngeneration models can directly provide a plausible \\emph{fine-grained}\nstructural initialization. We propose a technique that couples this image-based\nstructural guidance with LLM-based instance-level instructions, yielding output\nimages that adhere to all parts of the text prompt, including object counts,\ninstance-level attributes, and spatial relations between instances."}
{"id": "2505.05813", "pdf": "https://arxiv.org/pdf/2505.05813", "abs": "https://arxiv.org/abs/2505.05813", "authors": ["Qiufu Li", "Huibin Xiao", "Linlin Shen"], "title": "BCE vs. CE in Deep Feature Learning", "categories": ["cs.LG"], "comment": "Accepted by ICML2025", "summary": "When training classification models, it expects that the learned features are\ncompact within classes, and can well separate different classes. As the\ndominant loss function for training classification models, minimizing\ncross-entropy (CE) loss maximizes the compactness and distinctiveness, i.e.,\nreaching neural collapse (NC). The recent works show that binary CE (BCE)\nperforms also well in multi-class tasks. In this paper, we compare BCE and CE\nin deep feature learning. For the first time, we prove that BCE can also\nmaximize the intra-class compactness and inter-class distinctiveness when\nreaching its minimum, i.e., leading to NC. We point out that CE measures the\nrelative values of decision scores in the model training, implicitly enhancing\nthe feature properties by classifying samples one-by-one. In contrast, BCE\nmeasures the absolute values of decision scores and adjust the\npositive/negative decision scores across all samples to uniformly high/low\nlevels. Meanwhile, the classifier biases in BCE present a substantial\nconstraint on the decision scores to explicitly enhance the feature properties\nin the training. The experimental results are aligned with above analysis, and\nshow that BCE could improve the classification and leads to better compactness\nand distinctiveness among sample features. The codes will be released."}
{"id": "2505.06184", "pdf": "https://arxiv.org/pdf/2505.06184", "abs": "https://arxiv.org/abs/2505.06184", "authors": ["Vahid Rahimzadeh", "Ali Hamzehpour", "Azadeh Shakery", "Masoud Asadpour"], "title": "From Millions of Tweets to Actionable Insights: Leveraging LLMs for User Profiling", "categories": ["cs.SI", "cs.CL", "cs.IR", "I.2.7"], "comment": "Accepted at MisD @ AAAI ICWSM 2025", "summary": "Social media user profiling through content analysis is crucial for tasks\nlike misinformation detection, engagement prediction, hate speech monitoring,\nand user behavior modeling. However, existing profiling techniques, including\ntweet summarization, attribute-based profiling, and latent representation\nlearning, face significant limitations: they often lack transferability,\nproduce non-interpretable features, require large labeled datasets, or rely on\nrigid predefined categories that limit adaptability. We introduce a novel large\nlanguage model (LLM)-based approach that leverages domain-defining statements,\nwhich serve as key characteristics outlining the important pillars of a domain\nas foundations for profiling. Our two-stage method first employs\nsemi-supervised filtering with a domain-specific knowledge base, then generates\nboth abstractive (synthesized descriptions) and extractive (representative\ntweet selections) user profiles. By harnessing LLMs' inherent knowledge with\nminimal human validation, our approach is adaptable across domains while\nreducing the need for large labeled datasets. Our method generates\ninterpretable natural language user profiles, condensing extensive user data\ninto a scale that unlocks LLMs' reasoning and knowledge capabilities for\ndownstream social network tasks. We contribute a Persian political Twitter (X)\ndataset and an LLM-based evaluation framework with human validation.\nExperimental results show our method significantly outperforms state-of-the-art\nLLM-based and traditional methods by 9.8%, demonstrating its effectiveness in\ncreating flexible, adaptable, and interpretable user profiles."}
{"id": "2505.05756", "pdf": "https://arxiv.org/pdf/2505.05756", "abs": "https://arxiv.org/abs/2505.05756", "authors": ["Antonio Jimeno Yepes", "Pieter Barnard"], "title": "Evolutionary thoughts: integration of large language models and evolutionary algorithms", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have unveiled remarkable capabilities in\nunderstanding and generating both natural language and code, but LLM reasoning\nis prone to hallucination and struggle with complex, novel scenarios, often\ngetting stuck on partial or incorrect solutions. However, the inherent ability\nof Evolutionary Algorithms (EAs) to explore extensive and complex search spaces\nmakes them particularly effective in scenarios where traditional optimization\nmethodologies may falter. However, EAs explore a vast search space when applied\nto complex problems.\n  To address the computational bottleneck of evaluating large populations,\nparticularly crucial for complex evolutionary tasks, we introduce a highly\nefficient evaluation framework. This implementation maintains compatibility\nwith existing primitive definitions, ensuring the generation of valid\nindividuals.\n  Using LLMs, we propose an enhanced evolutionary search strategy that enables\na more focused exploration of expansive solution spaces. LLMs facilitate the\ngeneration of superior candidate solutions, as evidenced by empirical results\ndemonstrating their efficacy in producing improved outcomes."}
{"id": "2505.05681", "pdf": "https://arxiv.org/pdf/2505.05681", "abs": "https://arxiv.org/abs/2505.05681", "authors": ["Giulio Cesare Mastrocinque Santo", "Patrícia Izar", "Irene Delval", "Victor de Napole Gregolin", "Nina S. T. Hirata"], "title": "Fine-Tuning Video-Text Contrastive Model for Primate Behavior Retrieval from Unlabeled Raw Videos", "categories": ["cs.CV"], "comment": null, "summary": "Video recordings of nonhuman primates in their natural habitat are a common\nsource for studying their behavior in the wild. We fine-tune pre-trained\nvideo-text foundational models for the specific domain of capuchin monkeys,\nwith the goal of developing useful computational models to help researchers to\nretrieve useful clips from videos. We focus on the challenging problem of\ntraining a model based solely on raw, unlabeled video footage, using weak audio\ndescriptions sometimes provided by field collaborators. We leverage recent\nadvances in Multimodal Large Language Models (MLLMs) and Vision-Language Models\n(VLMs) to address the extremely noisy nature of both video and audio content.\nSpecifically, we propose a two-folded approach: an agentic data treatment\npipeline and a fine-tuning process. The data processing pipeline automatically\nextracts clean and semantically aligned video-text pairs from the raw videos,\nwhich are subsequently used to fine-tune a pre-trained Microsoft's X-CLIP model\nthrough Low-Rank Adaptation (LoRA). We obtained an uplift in $Hits@5$ of\n$167\\%$ for the 16 frames model and an uplift of $114\\%$ for the 8 frame model\non our domain data. Moreover, based on $NDCG@K$ results, our model is able to\nrank well most of the considered behaviors, while the tested raw pre-trained\nmodels are not able to rank them at all. The code will be made available upon\nacceptance."}
{"id": "2505.05819", "pdf": "https://arxiv.org/pdf/2505.05819", "abs": "https://arxiv.org/abs/2505.05819", "authors": ["Lorenzo Beretta"], "title": "New Statistical and Computational Results for Learning Junta Distributions", "categories": ["cs.LG", "cs.DS"], "comment": null, "summary": "We study the problem of learning junta distributions on $\\{0, 1\\}^n$, where a\ndistribution is a $k$-junta if its probability mass function depends on a\nsubset of at most $k$ variables. We make two main contributions:\n  - We show that learning $k$-junta distributions is \\emph{computationally}\nequivalent to learning $k$-parity functions with noise (LPN), a landmark\nproblem in computational learning theory.\n  - We design an algorithm for learning junta distributions whose statistical\ncomplexity is optimal, up to polylogarithmic factors. Computationally, our\nalgorithm matches the complexity of previous (non-sample-optimal) algorithms.\n  Combined, our two contributions imply that our algorithm cannot be\nsignificantly improved, statistically or computationally, barring a\nbreakthrough for LPN."}
{"id": "2209.15373", "pdf": "https://arxiv.org/pdf/2209.15373", "abs": "https://arxiv.org/abs/2209.15373", "authors": ["Javier Huertas-Tato", "Alejandro Martin", "David Camacho"], "title": "PART: Pre-trained Authorship Representation Transformer", "categories": ["cs.CL"], "comment": null, "summary": "Authors writing documents imprint identifying information within their texts:\nvocabulary, registry, punctuation, misspellings, or even emoji usage. Previous\nworks use hand-crafted features or classification tasks to train their\nauthorship models, leading to poor performance on out-of-domain authors. Using\nstylometric representations is more suitable, but this by itself is an open\nresearch challenge. In this paper, we propose PART, a contrastively trained\nmodel fit to learn \\textbf{authorship embeddings} instead of semantics. We\ntrain our model on ~1.5M texts belonging to 1162 literature authors, 17287 blog\nposters and 135 corporate email accounts; a heterogeneous set with identifiable\nwriting styles. We evaluate the model on current challenges, achieving\ncompetitive performance. We also evaluate our model on test splits of the\ndatasets achieving zero-shot 72.39\\% accuracy when bounded to 250 authors, a\n54\\% and 56\\% higher than RoBERTa embeddings. We qualitatively assess the\nrepresentations with different data visualizations on the available datasets,\nobserving features such as gender, age, or occupation of the author."}
{"id": "2505.05762", "pdf": "https://arxiv.org/pdf/2505.05762", "abs": "https://arxiv.org/abs/2505.05762", "authors": ["Junhong Chen", "Ziqi Yang", "Haoyuan G Xu", "Dandan Zhang", "George Mylonas"], "title": "Multi-Agent Systems for Robotic Autonomy with LLMs", "categories": ["cs.RO", "cs.AI"], "comment": "11 pages, 2 figures, 5 tables, submitted for publication", "summary": "Since the advent of Large Language Models (LLMs), various research based on\nsuch models have maintained significant academic attention and impact,\nespecially in AI and robotics. In this paper, we propose a multi-agent\nframework with LLMs to construct an integrated system for robotic task\nanalysis, mechanical design, and path generation. The framework includes three\ncore agents: Task Analyst, Robot Designer, and Reinforcement Learning Designer.\nOutputs are formatted as multimodal results, such as code files or technical\nreports, for stronger understandability and usability. To evaluate\ngeneralizability comparatively, we conducted experiments with models from both\nGPT and DeepSeek. Results demonstrate that the proposed system can design\nfeasible robots with control strategies when appropriate task inputs are\nprovided, exhibiting substantial potential for enhancing the efficiency and\naccessibility of robotic system development in research and industrial\napplications."}
{"id": "2505.05711", "pdf": "https://arxiv.org/pdf/2505.05711", "abs": "https://arxiv.org/abs/2505.05711", "authors": ["Ho-Joong Kim", "Yearang Lee", "Jung-Ho Hong", "Seong-Whan Lee"], "title": "DiGIT: Multi-Dilated Gated Encoder and Central-Adjacent Region Integrated Decoder for Temporal Action Detection Transformer", "categories": ["cs.CV"], "comment": "CVPR 2025", "summary": "In this paper, we examine a key limitation in query-based detectors for\ntemporal action detection (TAD), which arises from their direct adaptation of\noriginally designed architectures for object detection. Despite the\neffectiveness of the existing models, they struggle to fully address the unique\nchallenges of TAD, such as the redundancy in multi-scale features and the\nlimited ability to capture sufficient temporal context. To address these\nissues, we propose a multi-dilated gated encoder and central-adjacent region\nintegrated decoder for temporal action detection transformer (DiGIT). Our\napproach replaces the existing encoder that consists of multi-scale deformable\nattention and feedforward network with our multi-dilated gated encoder. Our\nproposed encoder reduces the redundant information caused by multi-level\nfeatures while maintaining the ability to capture fine-grained and long-range\ntemporal information. Furthermore, we introduce a central-adjacent region\nintegrated decoder that leverages a more comprehensive sampling strategy for\ndeformable cross-attention to capture the essential information. Extensive\nexperiments demonstrate that DiGIT achieves state-of-the-art performance on\nTHUMOS14, ActivityNet v1.3, and HACS-Segment. Code is available at:\nhttps://github.com/Dotori-HJ/DiGIT"}
{"id": "2505.05857", "pdf": "https://arxiv.org/pdf/2505.05857", "abs": "https://arxiv.org/abs/2505.05857", "authors": ["Nathan Justin", "Qingshi Sun", "Andrés Gómez", "Phebe Vayanos"], "title": "Mixed-Integer Optimization for Responsible Machine Learning", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "56 pages, 10 figures", "summary": "In the last few decades, Machine Learning (ML) has achieved significant\nsuccess across domains ranging from healthcare, sustainability, and the social\nsciences, to criminal justice and finance. But its deployment in increasingly\nsophisticated, critical, and sensitive areas affecting individuals, the groups\nthey belong to, and society as a whole raises critical concerns around\nfairness, transparency, robustness, and privacy, among others. As the\ncomplexity and scale of ML systems and of the settings in which they are\ndeployed grow, so does the need for responsible ML methods that address these\nchallenges while providing guaranteed performance in deployment.\n  Mixed-integer optimization (MIO) offers a powerful framework for embedding\nresponsible ML considerations directly into the learning process while\nmaintaining performance. For example, it enables learning of inherently\ntransparent models that can conveniently incorporate fairness or other domain\nspecific constraints. This tutorial paper provides an accessible and\ncomprehensive introduction to this topic discussing both theoretical and\npractical aspects. It outlines some of the core principles of responsible ML,\ntheir importance in applications, and the practical utility of MIO for building\nML models that align with these principles. Through examples and mathematical\nformulations, it illustrates practical strategies and available tools for\nefficiently solving MIO problems for responsible ML. It concludes with a\ndiscussion on current limitations and open research questions, providing\nsuggestions for future work."}
{"id": "2403.19346", "pdf": "https://arxiv.org/pdf/2403.19346", "abs": "https://arxiv.org/abs/2403.19346", "authors": ["Jingyuan Ma", "Damai Dai", "Zihang Yuan", "Rui li", "Weilin Luo", "Bin Wang", "Qun Liu", "Lei Sha", "Zhifang Sui"], "title": "Large Language Models Are Struggle to Cope with Unreasonability in Math Problems", "categories": ["cs.CL"], "comment": "32 pages, 8 figures", "summary": "Recent research have demonstrated LLMs' impressive performance in math and\nreasoning. However, the capacity of LLMs to address math problems under\nunconventional conditions, such as internal inconsistencies and flawed\nassumptions, remains largely unexplored. In this paper, we propose a novel\nbenchmark Unreasonable Math Problem (UMP) designed to assess LLMs' ability to\nrecognize and respond to unreasonability in math problem. The benchmark\nconsists of a carefully curated collection of unreasonable math questions\nacross diverse types. Based on extensive experiments covering 19 LLMs, we\nobserve that even state-of-the-art models such as GPT-4o achieve only limited\nperformance of 0.6 in UMP, while reasoning models such as DeepSeek-R1 are prone\nto overthinking and unstable. We further explore strategies for improving the\nrecognition of unreasonable inputs, shedding light on both the possibility and\nlimitations of LLMs in this challenging setting."}
{"id": "2505.05777", "pdf": "https://arxiv.org/pdf/2505.05777", "abs": "https://arxiv.org/abs/2505.05777", "authors": ["Domenico Cotroneo", "Giuseppe De Rosa", "Pietro Liguori"], "title": "PyResBugs: A Dataset of Residual Python Bugs for Natural Language-Driven Fault Injection", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "This paper presents PyResBugs, a curated dataset of residual bugs, i.e.,\ndefects that persist undetected during traditional testing but later surface in\nproduction, collected from major Python frameworks. Each bug in the dataset is\npaired with its corresponding fault-free (fixed) version and annotated with\nmulti-level natural language (NL) descriptions. These NL descriptions enable\nnatural language-driven fault injection, offering a novel approach to\nsimulating real-world faults in software systems. By bridging the gap between\nsoftware fault injection techniques and real-world representativeness,\nPyResBugs provides researchers with a high-quality resource for advancing\nAI-driven automated testing in Python systems."}
{"id": "2505.05721", "pdf": "https://arxiv.org/pdf/2505.05721", "abs": "https://arxiv.org/abs/2505.05721", "authors": ["Zixuan Li", "Lei Meng", "Guoqing Chao", "Wei Wu", "Xiaoshuo Yan", "Yimeng Yang", "Zhuang Qi", "Xiangxu Meng"], "title": "Semantic-Space-Intervened Diffusive Alignment for Visual Classification", "categories": ["cs.CV"], "comment": null, "summary": "Cross-modal alignment is an effective approach to improving visual\nclassification. Existing studies typically enforce a one-step mapping that uses\ndeep neural networks to project the visual features to mimic the distribution\nof textual features. However, they typically face difficulties in finding such\na projection due to the two modalities in both the distribution of class-wise\nsamples and the range of their feature values. To address this issue, this\npaper proposes a novel Semantic-Space-Intervened Diffusive Alignment method,\ntermed SeDA, models a semantic space as a bridge in the visual-to-textual\nprojection, considering both types of features share the same class-level\ninformation in classification. More importantly, a bi-stage diffusion framework\nis developed to enable the progressive alignment between the two modalities.\nSpecifically, SeDA first employs a Diffusion-Controlled Semantic Learner to\nmodel the semantic features space of visual features by constraining the\ninteractive features of the diffusion model and the category centers of visual\nfeatures. In the later stage of SeDA, the Diffusion-Controlled Semantic\nTranslator focuses on learning the distribution of textual features from the\nsemantic space. Meanwhile, the Progressive Feature Interaction Network\nintroduces stepwise feature interactions at each alignment step, progressively\nintegrating textual information into mapped features. Experimental results show\nthat SeDA achieves stronger cross-modal feature alignment, leading to superior\nperformance over existing methods across multiple scenarios."}
{"id": "2505.05868", "pdf": "https://arxiv.org/pdf/2505.05868", "abs": "https://arxiv.org/abs/2505.05868", "authors": ["Changkun Ye", "Russell Tsuchida", "Lars Petersson", "Nick Barnes"], "title": "Open Set Label Shift with Test Time Out-of-Distribution Reference", "categories": ["cs.LG"], "comment": "Accepted at CVPR 2025", "summary": "Open set label shift (OSLS) occurs when label distributions change from a\nsource to a target distribution, and the target distribution has an additional\nout-of-distribution (OOD) class. In this work, we build estimators for both\nsource and target open set label distributions using a source domain\nin-distribution (ID) classifier and an ID/OOD classifier. With reasonable\nassumptions on the ID/OOD classifier, the estimators are assembled into a\nsequence of three stages: 1) an estimate of the source label distribution of\nthe OOD class, 2) an EM algorithm for Maximum Likelihood estimates (MLE) of the\ntarget label distribution, and 3) an estimate of the target label distribution\nof OOD class under relaxed assumptions on the OOD classifier. The sampling\nerrors of estimates in 1) and 3) are quantified with a concentration\ninequality. The estimation result allows us to correct the ID classifier\ntrained on the source distribution to the target distribution without\nretraining. Experiments on a variety of open set label shift settings\ndemonstrate the effectiveness of our model. Our code is available at\nhttps://github.com/ChangkunYe/OpenSetLabelShift."}
{"id": "2406.09519", "pdf": "https://arxiv.org/pdf/2406.09519", "abs": "https://arxiv.org/abs/2406.09519", "authors": ["Jack Merullo", "Carsten Eickhoff", "Ellie Pavlick"], "title": "Talking Heads: Understanding Inter-layer Communication in Transformer Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Neurips 2024", "summary": "Although it is known that transformer language models (LMs) pass features\nfrom early layers to later layers, it is not well understood how this\ninformation is represented and routed by the model. We analyze a mechanism used\nin two LMs to selectively inhibit items in a context in one task, and find that\nit underlies a commonly used abstraction across many context-retrieval\nbehaviors. Specifically, we find that models write into low-rank subspaces of\nthe residual stream to represent features which are then read out by later\nlayers, forming low-rank communication channels (Elhage et al., 2021) between\nlayers. A particular 3D subspace in model activations in GPT-2 can be traversed\nto positionally index items in lists, and we show that this mechanism can\nexplain an otherwise arbitrary-seeming sensitivity of the model to the order of\nitems in the prompt. That is, the model has trouble copying the correct\ninformation from context when many items ``crowd\" this limited space. By\ndecomposing attention heads with the Singular Value Decomposition (SVD), we\nfind that previously described interactions between heads separated by one or\nmore layers can be predicted via analysis of their weight matrices alone. We\nshow that it is possible to manipulate the internal model representations as\nwell as edit model weights based on the mechanism we discover in order to\nsignificantly improve performance on our synthetic Laundry List task, which\nrequires recall from a list, often improving task accuracy by over 20%. Our\nanalysis reveals a surprisingly intricate interpretable structure learned from\nlanguage model pretraining, and helps us understand why sophisticated LMs\nsometimes fail in simple domains, facilitating future analysis of more complex\nbehaviors."}
{"id": "2505.05784", "pdf": "https://arxiv.org/pdf/2505.05784", "abs": "https://arxiv.org/abs/2505.05784", "authors": ["Yang Li", "Zhi Chen", "Steve Yang"], "title": "FlowHFT: Flow Policy Induced Optimal High-Frequency Trading under Diverse Market Conditions", "categories": ["q-fin.TR", "cs.AI", "cs.CE", "q-fin.CP"], "comment": "14 pages, 1 figure, 6 tables, 2 algorithms", "summary": "High-frequency trading (HFT) is an investing strategy that continuously\nmonitors market states and places bid and ask orders at millisecond speeds.\nTraditional HFT approaches fit models with historical data and assume that\nfuture market states follow similar patterns. This limits the effectiveness of\nany single model to the specific conditions it was trained for. Additionally,\nthese models achieve optimal solutions only under specific market conditions,\nsuch as assumptions about stock price's stochastic process, stable order flow,\nand the absence of sudden volatility. Real-world markets, however, are dynamic,\ndiverse, and frequently volatile. To address these challenges, we propose the\nFlowHFT, a novel imitation learning framework based on flow matching policy.\nFlowHFT simultaneously learns strategies from numerous expert models, each\nproficient in particular market scenarios. As a result, our framework can\nadaptively adjust investment decisions according to the prevailing market\nstate. Furthermore, FlowHFT incorporates a grid-search fine-tuning mechanism.\nThis allows it to refine strategies and achieve superior performance even in\ncomplex or extreme market scenarios where expert strategies may be suboptimal.\nWe test FlowHFT in multiple market environments. We first show that flow\nmatching policy is applicable in stochastic market environments, thus enabling\nFlowHFT to learn trading strategies under different market conditions. Notably,\nour single framework consistently achieves performance superior to the best\nexpert for each market condition."}
{"id": "2505.05722", "pdf": "https://arxiv.org/pdf/2505.05722", "abs": "https://arxiv.org/abs/2505.05722", "authors": ["Valay Bundele", "Mehran Hosseinzadeh", "Hendrik Lensch"], "title": "You Are Your Best Teacher: Semi-Supervised Surgical Point Tracking with Cycle-Consistent Self-Distillation", "categories": ["cs.CV"], "comment": "Accepted at CVPR 2025 SynData4CV Workshop", "summary": "Synthetic datasets have enabled significant progress in point tracking by\nproviding large-scale, densely annotated supervision. However, deploying these\nmodels in real-world domains remains challenging due to domain shift and lack\nof labeled data-issues that are especially severe in surgical videos, where\nscenes exhibit complex tissue deformation, occlusion, and lighting variation.\nWhile recent approaches adapt synthetic-trained trackers to natural videos\nusing teacher ensembles or augmentation-heavy pseudo-labeling pipelines, their\neffectiveness in high-shift domains like surgery remains unexplored. This work\npresents SurgTracker, a semi-supervised framework for adapting\nsynthetic-trained point trackers to surgical video using filtered\nself-distillation. Pseudo-labels are generated online by a fixed\nteacher-identical in architecture and initialization to the student-and are\nfiltered using a cycle consistency constraint to discard temporally\ninconsistent trajectories. This simple yet effective design enforces geometric\nconsistency and provides stable supervision throughout training, without the\ncomputational overhead of maintaining multiple teachers. Experiments on the\nSTIR benchmark show that SurgTracker improves tracking performance using only\n80 unlabeled videos, demonstrating its potential for robust adaptation in\nhigh-shift, data-scarce domains."}
{"id": "2505.05869", "pdf": "https://arxiv.org/pdf/2505.05869", "abs": "https://arxiv.org/abs/2505.05869", "authors": ["Hao Xu", "Yuntian Chen", "Rui Cao", "Tianning Tang", "Mengge Du", "Jian Li", "Adrian H. Callaghan", "Dongxiao Zhang"], "title": "Generative Discovery of Partial Differential Equations by Learning from Math Handbooks", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "comment": null, "summary": "Data driven discovery of partial differential equations (PDEs) is a promising\napproach for uncovering the underlying laws governing complex systems. However,\npurely data driven techniques face the dilemma of balancing search space with\noptimization efficiency. This study introduces a knowledge guided approach that\nincorporates existing PDEs documented in a mathematical handbook to facilitate\nthe discovery process. These PDEs are encoded as sentence like structures\ncomposed of operators and basic terms, and used to train a generative model,\ncalled EqGPT, which enables the generation of free form PDEs. A loop of\ngeneration evaluation optimization is constructed to autonomously identify the\nmost suitable PDE. Experimental results demonstrate that this framework can\nrecover a variety of PDE forms with high accuracy and computational efficiency,\nparticularly in cases involving complex temporal derivatives or intricate\nspatial terms, which are often beyond the reach of conventional methods. The\napproach also exhibits generalizability to irregular spatial domains and higher\ndimensional settings. Notably, it succeeds in discovering a previously\nunreported PDE governing strongly nonlinear surface gravity waves propagating\ntoward breaking, based on real world experimental data, highlighting its\napplicability to practical scenarios and its potential to support scientific\ndiscovery."}
{"id": "2407.11963", "pdf": "https://arxiv.org/pdf/2407.11963", "abs": "https://arxiv.org/abs/2407.11963", "authors": ["Mo Li", "Songyang Zhang", "Taolin Zhang", "Haodong Duan", "Yunxin Liu", "Kai Chen"], "title": "NeedleBench: Can LLMs Do Retrieval and Reasoning in Information-Dense Context?", "categories": ["cs.CL"], "comment": "v2: updated with tested models and Multi-Needle Reasoning\n  implementation", "summary": "The capability of large language models to handle long-context information is\ncrucial across various real-world applications. Existing evaluation methods\noften rely either on real-world long texts, making it difficult to exclude the\ninfluence of models' inherent knowledge, or introduce irrelevant filler content\nto artificially achieve target lengths, reducing assessment effectiveness. To\naddress these limitations, we introduce NeedleBench, a synthetic framework for\nassessing retrieval and reasoning performance in bilingual long-context tasks\nwith adaptive context lengths. NeedleBench systematically embeds key data\npoints at varying depths to rigorously test model capabilities. Tasks are\ncategorized into two scenarios: information-sparse, featuring minimal relevant\ndetails within extensive irrelevant text to simulate simple retrieval tasks;\nand information-dense (the Ancestral Trace Challenge), where relevant\ninformation is continuously distributed throughout the context to simulate\ncomplex reasoning tasks. Our experiments reveal that although recent reasoning\nmodels like Deepseek-R1 and OpenAI's o3 excel in mathematical reasoning, they\nstruggle with continuous retrieval and reasoning in information-dense\nscenarios, even at shorter context lengths. We also characterize a phenomenon\ntermed 'under-thinking', where models prematurely conclude reasoning despite\navailable information. NeedleBench thus provides critical insights and targeted\ntools essential for evaluating and improving LLMs' long-context capabilities.\nAll resources are available at OpenCompass:\nhttps://github.com/open-compass/opencompass."}
{"id": "2505.05794", "pdf": "https://arxiv.org/pdf/2505.05794", "abs": "https://arxiv.org/abs/2505.05794", "authors": ["Renjie Li", "Wenjie Wei", "Qi Xin", "Xiaoli Liu", "Sixuan Mao", "Erik Ma", "Zijian Chen", "Malu Zhang", "Haizhou Li", "Zhaoyu Zhang"], "title": "What Is Next for LLMs? Next-Generation AI Computing Hardware Using Photonic Chips", "categories": ["cs.AR", "cs.AI", "cs.NE"], "comment": "36 pages, 22 figures", "summary": "Large language models (LLMs) are rapidly pushing the limits of contemporary\ncomputing hardware. For example, training GPT-3 has been estimated to consume\naround 1300 MWh of electricity, and projections suggest future models may\nrequire city-scale (gigawatt) power budgets. These demands motivate exploration\nof computing paradigms beyond conventional von Neumann architectures. This\nreview surveys emerging photonic hardware optimized for next-generation\ngenerative AI computing. We discuss integrated photonic neural network\narchitectures (e.g., Mach-Zehnder interferometer meshes, lasers,\nwavelength-multiplexed microring resonators) that perform ultrafast matrix\noperations. We also examine promising alternative neuromorphic devices,\nincluding spiking neural network circuits and hybrid spintronic-photonic\nsynapses, which combine memory and processing. The integration of\ntwo-dimensional materials (graphene, TMDCs) into silicon photonic platforms is\nreviewed for tunable modulators and on-chip synaptic elements.\nTransformer-based LLM architectures (self-attention and feed-forward layers)\nare analyzed in this context, identifying strategies and challenges for mapping\ndynamic matrix multiplications onto these novel hardware substrates. We then\ndissect the mechanisms of mainstream LLMs, such as ChatGPT, DeepSeek, and\nLLaMA, highlighting their architectural similarities and differences. We\nsynthesize state-of-the-art components, algorithms, and integration methods,\nhighlighting key advances and open issues in scaling such systems to mega-sized\nLLM models. We find that photonic computing systems could potentially surpass\nelectronic processors by orders of magnitude in throughput and energy\nefficiency, but require breakthroughs in memory, especially for long-context\nwindows and long token sequences, and in storage of ultra-large datasets."}
{"id": "2505.05741", "pdf": "https://arxiv.org/pdf/2505.05741", "abs": "https://arxiv.org/abs/2505.05741", "authors": ["Zhangchi Hu", "Peixi Wu", "Jie Chen", "Huyue Zhu", "Yijun Wang", "Yansong Peng", "Hebei Li", "Xiaoyan Sun"], "title": "Dome-DETR: DETR with Density-Oriented Feature-Query Manipulation for Efficient Tiny Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Tiny object detection plays a vital role in drone surveillance, remote\nsensing, and autonomous systems, enabling the identification of small targets\nacross vast landscapes. However, existing methods suffer from inefficient\nfeature leverage and high computational costs due to redundant feature\nprocessing and rigid query allocation. To address these challenges, we propose\nDome-DETR, a novel framework with Density-Oriented Feature-Query Manipulation\nfor Efficient Tiny Object Detection. To reduce feature redundancies, we\nintroduce a lightweight Density-Focal Extractor (DeFE) to produce clustered\ncompact foreground masks. Leveraging these masks, we incorporate Masked Window\nAttention Sparsification (MWAS) to focus computational resources on the most\ninformative regions via sparse attention. Besides, we propose Progressive\nAdaptive Query Initialization (PAQI), which adaptively modulates query density\nacross spatial areas for better query allocation. Extensive experiments\ndemonstrate that Dome-DETR achieves state-of-the-art performance (+3.3 AP on\nAI-TOD-V2 and +2.5 AP on VisDrone) while maintaining low computational\ncomplexity and a compact model size. Code will be released upon acceptance."}
{"id": "2505.05874", "pdf": "https://arxiv.org/pdf/2505.05874", "abs": "https://arxiv.org/abs/2505.05874", "authors": ["Anjie Qiao", "Hao Zhang", "Qianmu Yuan", "Qirui Deng", "Jingtian Su", "Weifeng Huang", "Huihao Zhou", "Guo-Bo Li", "Zhen Wang", "Jinping Lei"], "title": "A 3D pocket-aware and evolutionary conserved interaction guided diffusion model for molecular optimization", "categories": ["cs.LG", "physics.chem-ph", "q-bio.BM"], "comment": null, "summary": "Generating molecules that bind to specific protein targets via diffusion\nmodels has shown good promise for structure-based drug design and molecule\noptimization. Especially, the diffusion models with binding interaction\nguidance enables molecule generation with high affinity through forming\nfavorable interaction within protein pocket. However, the generated molecules\nmay not form interactions with the highly conserved residues, which are\nimportant for protein functions and bioactivities of the ligands. Herein, we\ndeveloped a new 3D target-aware diffusion model DiffDecip, which explicitly\nincorporates the protein-ligand binding interactions and evolutionary\nconservation information of protein residues into both diffusion and sampling\nprocess, for molecule optimization through scaffold decoration. The model\nperformance revealed that DiffDecip outperforms baseline model DiffDec on\nmolecule optimization towards higher affinity through forming more non-covalent\ninteractions with highly conserved residues in the protein pocket."}
{"id": "2408.00103", "pdf": "https://arxiv.org/pdf/2408.00103", "abs": "https://arxiv.org/abs/2408.00103", "authors": ["Riccardo Orlando", "Pere-Lluis Huguet Cabot", "Edoardo Barba", "Roberto Navigli"], "title": "ReLiK: Retrieve and LinK, Fast and Accurate Entity Linking and Relation Extraction on an Academic Budget", "categories": ["cs.CL", "cs.AI"], "comment": "Findings of the Association for Computational Linguistics ACL 2024", "summary": "Entity Linking (EL) and Relation Extraction (RE) are fundamental tasks in\nNatural Language Processing, serving as critical components in a wide range of\napplications. In this paper, we propose ReLiK, a Retriever-Reader architecture\nfor both EL and RE, where, given an input text, the Retriever module undertakes\nthe identification of candidate entities or relations that could potentially\nappear within the text. Subsequently, the Reader module is tasked to discern\nthe pertinent retrieved entities or relations and establish their alignment\nwith the corresponding textual spans. Notably, we put forward an innovative\ninput representation that incorporates the candidate entities or relations\nalongside the text, making it possible to link entities or extract relations in\na single forward pass and to fully leverage pre-trained language models\ncontextualization capabilities, in contrast with previous\nRetriever-Reader-based methods, which require a forward pass for each\ncandidate. Our formulation of EL and RE achieves state-of-the-art performance\nin both in-domain and out-of-domain benchmarks while using academic budget\ntraining and with up to 40x inference speed compared to competitors. Finally,\nwe show how our architecture can be used seamlessly for Information Extraction\n(cIE), i.e. EL + RE, and setting a new state of the art by employing a shared\nReader that simultaneously extracts entities and relations."}
{"id": "2505.05796", "pdf": "https://arxiv.org/pdf/2505.05796", "abs": "https://arxiv.org/abs/2505.05796", "authors": ["Xinyu Liang", "Frits de Nijs", "Buser Say", "Hao Wang"], "title": "Human-in-the-Loop AI for HVAC Management Enhancing Comfort and Energy Efficiency", "categories": ["eess.SY", "cs.AI", "cs.SY", "math.OC"], "comment": "ACM e-Energy 2025", "summary": "Heating, Ventilation, and Air Conditioning (HVAC) systems account for\napproximately 38% of building energy consumption globally, making them one of\nthe most energy-intensive services. The increasing emphasis on energy\nefficiency and sustainability, combined with the need for enhanced occupant\ncomfort, presents a significant challenge for traditional HVAC systems. These\nsystems often fail to dynamically adjust to real-time changes in electricity\nmarket rates or individual comfort preferences, leading to increased energy\ncosts and reduced comfort. In response, we propose a Human-in-the-Loop (HITL)\nArtificial Intelligence framework that optimizes HVAC performance by\nincorporating real-time user feedback and responding to fluctuating electricity\nprices. Unlike conventional systems that require predefined information about\noccupancy or comfort levels, our approach learns and adapts based on ongoing\nuser input. By integrating the occupancy prediction model with reinforcement\nlearning, the system improves operational efficiency and reduces energy costs\nin line with electricity market dynamics, thereby contributing to demand\nresponse initiatives. Through simulations, we demonstrate that our method\nachieves significant cost reductions compared to baseline approaches while\nmaintaining or enhancing occupant comfort. This feedback-driven approach\nensures personalized comfort control without the need for predefined settings,\noffering a scalable solution that balances individual preferences with economic\nand environmental goals."}
{"id": "2505.05748", "pdf": "https://arxiv.org/pdf/2505.05748", "abs": "https://arxiv.org/abs/2505.05748", "authors": ["Huan Yan", "Junjie Hu"], "title": "kFuse: A novel density based agglomerative clustering", "categories": ["cs.CV"], "comment": "13 pages, 11 figures", "summary": "Agglomerative clustering has emerged as a vital tool in data analysis due to\nits intuitive and flexible characteristics. However, existing agglomerative\nclustering methods often involve additional parameters for sub-cluster\npartitioning and inter-cluster similarity assessment. This necessitates\ndifferent parameter settings across various datasets, which is undoubtedly\nchallenging in the absence of prior knowledge. Moreover, existing agglomerative\nclustering techniques are constrained by the calculation method of connection\ndistance, leading to unstable clustering results. To address these issues, this\npaper introduces a novel density-based agglomerative clustering method, termed\nkFuse. kFuse comprises four key components: (1) sub-cluster partitioning based\non natural neighbors; (2) determination of boundary connectivity between\nsub-clusters through the computation of adjacent samples and shortest\ndistances; (3) assessment of density similarity between sub-clusters via the\ncalculation of mean density and variance; and (4) establishment of merging\nrules between sub-clusters based on boundary connectivity and density\nsimilarity. kFuse requires the specification of the number of clusters only at\nthe final merging stage. Additionally, by comprehensively considering adjacent\nsamples, distances, and densities among different sub-clusters, kFuse\nsignificantly enhances accuracy during the merging phase, thereby greatly\nimproving its identification capability. Experimental results on both synthetic\nand real-world datasets validate the effectiveness of kFuse."}
{"id": "2505.05877", "pdf": "https://arxiv.org/pdf/2505.05877", "abs": "https://arxiv.org/abs/2505.05877", "authors": ["Rong Yin", "Ruyue Liu", "Xiaoshuai Hao", "Xingrui Zhou", "Yong Liu", "Can Ma", "Weiping Wang"], "title": "Multi-Modal Molecular Representation Learning via Structure Awareness", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by IEEE Transactions on Image Processing (TIP) 2025", "summary": "Accurate extraction of molecular representations is a critical step in the\ndrug discovery process. In recent years, significant progress has been made in\nmolecular representation learning methods, among which multi-modal molecular\nrepresentation methods based on images, and 2D/3D topologies have become\nincreasingly mainstream. However, existing these multi-modal approaches often\ndirectly fuse information from different modalities, overlooking the potential\nof intermodal interactions and failing to adequately capture the complex\nhigher-order relationships and invariant features between molecules. To\novercome these challenges, we propose a structure-awareness-based multi-modal\nself-supervised molecular representation pre-training framework (MMSA) designed\nto enhance molecular graph representations by leveraging invariant knowledge\nbetween molecules. The framework consists of two main modules: the multi-modal\nmolecular representation learning module and the structure-awareness module.\nThe multi-modal molecular representation learning module collaboratively\nprocesses information from different modalities of the same molecule to\novercome intermodal differences and generate a unified molecular embedding.\nSubsequently, the structure-awareness module enhances the molecular\nrepresentation by constructing a hypergraph structure to model higher-order\ncorrelations between molecules. This module also introduces a memory mechanism\nfor storing typical molecular representations, aligning them with memory\nanchors in the memory bank to integrate invariant knowledge, thereby improving\nthe model generalization ability. Extensive experiments have demonstrated the\neffectiveness of MMSA, which achieves state-of-the-art performance on the\nMoleculeNet benchmark, with average ROC-AUC improvements ranging from 1.8% to\n9.6% over baseline methods."}
{"id": "2410.18234", "pdf": "https://arxiv.org/pdf/2410.18234", "abs": "https://arxiv.org/abs/2410.18234", "authors": ["Ashish Khisti", "M. Reza Ebrahimi", "Hassan Dbouk", "Arash Behboodi", "Roland Memisevic", "Christos Louizos"], "title": "Multi-Draft Speculative Sampling: Canonical Decomposition and Theoretical Limits", "categories": ["cs.CL", "cs.DC", "cs.IT", "cs.LG", "math.IT"], "comment": "Published as a (spotlight) conference paper at ICLR 2025", "summary": "We consider multi-draft speculative sampling, where the proposal sequences\nare sampled independently from different draft models. At each step, a\ntoken-level draft selection scheme takes a list of valid tokens as input and\nproduces an output token whose distribution matches that of the target model.\nPrevious works have demonstrated that the optimal scheme (which maximizes the\nprobability of accepting one of the input tokens) can be cast as a solution to\na linear program. In this work we show that the optimal scheme can be\ndecomposed into a two-step solution: in the first step an importance sampling\n(IS) type scheme is used to select one intermediate token; in the second step\n(single-draft) speculative sampling is applied to generate the output token.\nFor the case of two identical draft models we further 1) establish a necessary\nand sufficient condition on the distributions of the target and draft models\nfor the acceptance probability to equal one and 2) provide an explicit\nexpression for the optimal acceptance probability. Our theoretical analysis\nalso motives a new class of token-level selection schemes based on weighted\nimportance sampling. Our experimental results demonstrate consistent\nimprovements in the achievable block efficiency and token rates over baseline\nschemes in a number of scenarios."}
{"id": "2505.05849", "pdf": "https://arxiv.org/pdf/2505.05849", "abs": "https://arxiv.org/abs/2505.05849", "authors": ["Zhun Wang", "Vincent Siu", "Zhe Ye", "Tianneng Shi", "Yuzhou Nie", "Xuandong Zhao", "Chenguang Wang", "Wenbo Guo", "Dawn Song"], "title": "AgentXploit: End-to-End Redteaming of Black-Box AI Agents", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The strong planning and reasoning capabilities of Large Language Models\n(LLMs) have fostered the development of agent-based systems capable of\nleveraging external tools and interacting with increasingly complex\nenvironments. However, these powerful features also introduce a critical\nsecurity risk: indirect prompt injection, a sophisticated attack vector that\ncompromises the core of these agents, the LLM, by manipulating contextual\ninformation rather than direct user prompts. In this work, we propose a generic\nblack-box fuzzing framework, AgentXploit, designed to automatically discover\nand exploit indirect prompt injection vulnerabilities across diverse LLM\nagents. Our approach starts by constructing a high-quality initial seed corpus,\nthen employs a seed selection algorithm based on Monte Carlo Tree Search (MCTS)\nto iteratively refine inputs, thereby maximizing the likelihood of uncovering\nagent weaknesses. We evaluate AgentXploit on two public benchmarks, AgentDojo\nand VWA-adv, where it achieves 71% and 70% success rates against agents based\non o3-mini and GPT-4o, respectively, nearly doubling the performance of\nbaseline attacks. Moreover, AgentXploit exhibits strong transferability across\nunseen tasks and internal LLMs, as well as promising results against defenses.\nBeyond benchmark evaluations, we apply our attacks in real-world environments,\nsuccessfully misleading agents to navigate to arbitrary URLs, including\nmalicious sites."}
{"id": "2505.05759", "pdf": "https://arxiv.org/pdf/2505.05759", "abs": "https://arxiv.org/abs/2505.05759", "authors": ["Fangxue Liu", "Lei Fan"], "title": "A review of advancements in low-light image enhancement using deep learning", "categories": ["cs.CV"], "comment": null, "summary": "In low-light environments, the performance of computer vision algorithms\noften deteriorates significantly, adversely affecting key vision tasks such as\nsegmentation, detection, and classification. With the rapid advancement of deep\nlearning, its application to low-light image processing has attracted\nwidespread attention and seen significant progress in recent years. However,\nthere remains a lack of comprehensive surveys that systematically examine how\nrecent deep-learning-based low-light image enhancement methods function and\nevaluate their effectiveness in enhancing downstream vison tasks. To address\nthis gap, this review provides a detailed elaboration on how various recent\napproaches (from 2020) operate and their enhancement mechanisms, supplemented\nwith clear illustrations. It also investigates the impact of different\nenhancement techniques on subsequent vision tasks, critically analyzing their\nstrengths and limitations. Additionally, it proposes future research\ndirections. This review serves as a useful reference for determining low-light\nimage enhancement techniques and optimizing vision task performance in\nlow-light conditions."}
{"id": "2505.05916", "pdf": "https://arxiv.org/pdf/2505.05916", "abs": "https://arxiv.org/abs/2505.05916", "authors": ["Yifan Zhou", "Yibo Wang", "Chao Shang"], "title": "IRNN: Innovation-driven Recurrent Neural Network for Time-Series Data Modeling and Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Many real-world datasets are time series that are sequentially collected and\ncontain rich temporal information. Thus, a common interest in practice is to\ncapture dynamics of time series and predict their future evolutions. To this\nend, the recurrent neural network (RNN) has been a prevalent and effective\nmachine learning option, which admits a nonlinear state-space model\nrepresentation. Motivated by the resemblance between RNN and Kalman filter (KF)\nfor linear state-space models, we propose in this paper Innovation-driven RNN\n(IRNN), a novel RNN architecture tailored to time-series data modeling and\nprediction tasks. By adapting the concept of \"innovation\" from KF to RNN, past\nprediction errors are adopted as additional input signals to update hidden\nstates of RNN and boost prediction performance. Since innovation data depend on\nnetwork parameters, existing training algorithms for RNN do not apply to IRNN\nstraightforwardly. Thus, a tailored training algorithm dubbed input\nupdating-based back-propagation through time (IU-BPTT) is further proposed,\nwhich alternates between updating innovations and optimizing network parameters\nvia gradient descent. Experiments on real-world benchmark datasets show that\nthe integration of innovations into various forms of RNN leads to remarkably\nimproved prediction accuracy of IRNN without increasing the training cost\nsubstantially."}
{"id": "2411.11053", "pdf": "https://arxiv.org/pdf/2411.11053", "abs": "https://arxiv.org/abs/2411.11053", "authors": ["Bin Xu", "Yiguan Lin", "Yinghao Li", "Yang Gao"], "title": "SRA-MCTS: Self-driven Reasoning Augmentation with Monte Carlo Tree Search for Code Generation", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by IJCAI2025", "summary": "Large language models demonstrate exceptional performance in simple code\ngeneration tasks but still face challenges in tackling complex problems. These\nchallenges may stem from insufficient reasoning and problem decomposition\ncapabilities. To address this issue, we propose a reasoning-augmented data\ngeneration process, SRA-MCTS, which guides the model to autonomously generate\nhigh-quality intermediate reasoning paths. This creates a positive feedback\nloop, enabling continuous improvement. Our method operates entirely through the\nmodel itself without requiring additional supervision. By synthesizing natural\nlanguage reasoning paths and translating them into executable code, the\napproach ensures analytical accuracy and enhances the success rate in solving\ncomplex tasks. Experimental results show that, even without additional\nsupervisory signals, our method achieves performance improvements across\ndifferent model scales, demonstrating the significant potential of\nself-improvement in small models. Furthermore, the method remains robust when\ntraditional Chain-of-Thought (CoT) approaches exhibit performance degradation,\nwith notable improvements observed in diversity metrics such as pass@10. We\nencourage further exploration of reasoning processes within training data to\nenhance the ability of language models to address complex problems. Our code\nand data are public at https://github.com/DIRECT-BIT/SRA-MCTS."}
{"id": "2505.05893", "pdf": "https://arxiv.org/pdf/2505.05893", "abs": "https://arxiv.org/abs/2505.05893", "authors": ["Seunghee Han", "Soongyu Choi", "Joo-Young Kim"], "title": "LightNobel: Improving Sequence Length Limitation in Protein Structure Prediction Model via Adaptive Activation Quantization", "categories": ["cs.AR", "cs.AI", "cs.ET", "cs.LG", "B.7; I.2; J.3"], "comment": "To appear in the Proceedings of the 52nd IEEE/ACM International\n  Symposium on Computer Architecture (ISCA 2025)", "summary": "Recent advances in Protein Structure Prediction Models (PPMs), such as\nAlphaFold2 and ESMFold, have revolutionized computational biology by achieving\nunprecedented accuracy in predicting three-dimensional protein folding\nstructures. However, these models face significant scalability challenges,\nparticularly when processing proteins with long amino acid sequences (e.g.,\nsequence length > 1,000). The primary bottleneck that arises from the\nexponential growth in activation sizes is driven by the unique data structure\nin PPM, which introduces an additional dimension that leads to substantial\nmemory and computational demands. These limitations have hindered the effective\nscaling of PPM for real-world applications, such as analyzing large proteins or\ncomplex multimers with critical biological and pharmaceutical relevance.\n  In this paper, we present LightNobel, the first hardware-software co-designed\naccelerator developed to overcome scalability limitations on the sequence\nlength in PPM. At the software level, we propose Token-wise Adaptive Activation\nQuantization (AAQ), which leverages unique token-wise characteristics, such as\ndistogram patterns in PPM activations, to enable fine-grained quantization\ntechniques without compromising accuracy. At the hardware level, LightNobel\nintegrates the multi-precision reconfigurable matrix processing unit (RMPU) and\nversatile vector processing unit (VVPU) to enable the efficient execution of\nAAQ. Through these innovations, LightNobel achieves up to 8.44x, 8.41x speedup\nand 37.29x, 43.35x higher power efficiency over the latest NVIDIA A100 and H100\nGPUs, respectively, while maintaining negligible accuracy loss. It also reduces\nthe peak memory requirement up to 120.05x in PPM, enabling scalable processing\nfor proteins with long sequences."}
{"id": "2505.05804", "pdf": "https://arxiv.org/pdf/2505.05804", "abs": "https://arxiv.org/abs/2505.05804", "authors": ["Xi Xiao", "Yunbei Zhang", "Thanh-Huy Nguyen", "Ba-Thinh Lam", "Janet Wang", "Jihun Hamm", "Tianyang Wang", "Xingjian Li", "Xiao Wang", "Hao Xu", "Tianming Liu", "Min Xu"], "title": "Describe Anything in Medical Images", "categories": ["cs.CV"], "comment": null, "summary": "Localized image captioning has made significant progress with models like the\nDescribe Anything Model (DAM), which can generate detailed region-specific\ndescriptions without explicit region-text supervision. However, such\ncapabilities have yet to be widely applied to specialized domains like medical\nimaging, where diagnostic interpretation relies on subtle regional findings\nrather than global understanding. To mitigate this gap, we propose MedDAM, the\nfirst comprehensive framework leveraging large vision-language models for\nregion-specific captioning in medical images. MedDAM employs medical\nexpert-designed prompts tailored to specific imaging modalities and establishes\na robust evaluation benchmark comprising a customized assessment protocol, data\npre-processing pipeline, and specialized QA template library. This benchmark\nevaluates both MedDAM and other adaptable large vision-language models,\nfocusing on clinical factuality through attribute-level verification tasks,\nthereby circumventing the absence of ground-truth region-caption pairs in\nmedical datasets. Extensive experiments on the VinDr-CXR, LIDC-IDRI, and\nSkinCon datasets demonstrate MedDAM's superiority over leading peers (including\nGPT-4o, Claude 3.7 Sonnet, LLaMA-3.2 Vision, Qwen2.5-VL, GPT-4Rol, and\nOMG-LLaVA) in the task, revealing the importance of region-level semantic\nalignment in medical image understanding and establishing MedDAM as a promising\nfoundation for clinical vision-language integration."}
{"id": "2505.05926", "pdf": "https://arxiv.org/pdf/2505.05926", "abs": "https://arxiv.org/abs/2505.05926", "authors": ["Milad Khademi Nori", "Il-Min Kim", "Guanghui Wang"], "title": "Autoencoder-Based Hybrid Replay for Class-Incremental Learning", "categories": ["cs.LG"], "comment": "Accepted ICML 2025", "summary": "In class-incremental learning (CIL), effective incremental learning\nstrategies are essential to mitigate task confusion and catastrophic\nforgetting, especially as the number of tasks $t$ increases. Current exemplar\nreplay strategies impose $\\mathcal{O}(t)$ memory/compute complexities. We\npropose an autoencoder-based hybrid replay (AHR) strategy that leverages our\nnew hybrid autoencoder (HAE) to function as a compressor to alleviate the\nrequirement for large memory, achieving $\\mathcal{O}(0.1 t)$ at the worst case\nwith the computing complexity of $\\mathcal{O}(t)$ while accomplishing\nstate-of-the-art performance. The decoder later recovers the exemplar data\nstored in the latent space, rather than in raw format. Additionally, HAE is\ndesigned for both discriminative and generative modeling, enabling\nclassification and replay capabilities, respectively. HAE adopts the charged\nparticle system energy minimization equations and repulsive force algorithm for\nthe incremental embedding and distribution of new class centroids in its latent\nspace. Our results demonstrate that AHR consistently outperforms recent\nbaselines across multiple benchmarks while operating with the same\nmemory/compute budgets. The source code is included in the supplementary\nmaterial and will be open-sourced upon publication."}
{"id": "2501.12106", "pdf": "https://arxiv.org/pdf/2501.12106", "abs": "https://arxiv.org/abs/2501.12106", "authors": ["Stefan Lenz", "Arsenij Ustjanzew", "Marco Jeray", "Meike Ressing", "Torsten Panholzer"], "title": "Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes", "categories": ["cs.CL", "cs.AI"], "comment": "53 pages, 5 figures", "summary": "Tumor documentation in Germany is largely done manually, requiring reading\npatient records and entering data into structured databases. Large language\nmodels (LLMs) could potentially enhance this process by improving efficiency\nand reliability. This evaluation tests eleven different open source LLMs with\nsizes ranging from 1-70 billion model parameters on three basic tasks of the\ntumor documentation process: identifying tumor diagnoses, assigning ICD-10\ncodes, and extracting the date of first diagnosis. For evaluating the LLMs on\nthese tasks, a dataset of annotated text snippets based on anonymized doctors'\nnotes from urology was prepared. Different prompting strategies were used to\ninvestigate the effect of the number of examples in few-shot prompting and to\nexplore the capabilities of the LLMs in general. The models Llama 3.1 8B,\nMistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks.\nModels with less extensive training data or having fewer than 7 billion\nparameters showed notably lower performance, while larger models did not\ndisplay performance gains. Examples from a different medical domain than\nurology could also improve the outcome in few-shot prompting, which\ndemonstrates the ability of LLMs to handle tasks needed for tumor\ndocumentation. Open source LLMs show a strong potential for automating tumor\ndocumentation. Models from 7-12 billion parameters could offer an optimal\nbalance between performance and resource efficiency. With tailored fine-tuning\nand well-designed prompting, these models might become important tools for\nclinical documentation in the future. The code for the evaluation is available\nfrom https://github.com/stefan-m-lenz/UroLlmEval. We also release the dataset\nas a new valuable resource that addresses the shortage of authentic and easily\naccessible benchmarks in German-language medical NLP."}
{"id": "2505.05895", "pdf": "https://arxiv.org/pdf/2505.05895", "abs": "https://arxiv.org/abs/2505.05895", "authors": ["Benjamin Raphael Ernhofer", "Daniil Prokhorov", "Jannica Langner", "Dominik Bollmann"], "title": "Leveraging Vision-Language Models for Visual Grounding and Analysis of Automotive UI", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Modern automotive infotainment systems require intelligent and adaptive\nsolutions to handle frequent User Interface (UI) updates and diverse design\nvariations. We introduce a vision-language framework for understanding and\ninteracting with automotive infotainment systems, enabling seamless adaptation\nacross different UI designs. To further support research in this field, we\nrelease AutomotiveUI-Bench-4K, an open-source dataset of 998 images with 4,208\nannotations. Additionally, we present a synthetic data pipeline to generate\ntraining data. We fine-tune a Molmo-7B-based model using Low-Rank Adaptation\n(LoRa) and incorporating reasoning generated by our pipeline, along with visual\ngrounding and evaluation capabilities. The fine-tuned Evaluative Large Action\nModel (ELAM) achieves strong performance on AutomotiveUI-Bench-4K (model and\ndataset are available on Hugging Face) and demonstrating strong cross-domain\ngeneralization, including a +5.2% improvement on ScreenSpot over the baseline\nmodel. Notably, our approach achieves 80.4% average accuracy on ScreenSpot,\nclosely matching or even surpassing specialized models for desktop, mobile, and\nweb, such as ShowUI, despite being trained for the infotainment domain. This\nresearch investigates how data collection and subsequent fine-tuning can lead\nto AI-driven progress within automotive UI understanding and interaction. The\napplied method is cost-efficient and fine-tuned models can be deployed on\nconsumer-grade GPUs."}
{"id": "2505.05806", "pdf": "https://arxiv.org/pdf/2505.05806", "abs": "https://arxiv.org/abs/2505.05806", "authors": ["Kaili Qi", "Wenli Yang", "Ye Li", "Zhongyi Huang"], "title": "Image Segmentation via Variational Model Based Tailored UNet: A Deep Variational Framework", "categories": ["cs.CV"], "comment": null, "summary": "Traditional image segmentation methods, such as variational models based on\npartial differential equations (PDEs), offer strong mathematical\ninterpretability and precise boundary modeling, but often suffer from\nsensitivity to parameter settings and high computational costs. In contrast,\ndeep learning models such as UNet, which are relatively lightweight in\nparameters, excel in automatic feature extraction but lack theoretical\ninterpretability and require extensive labeled data. To harness the\ncomplementary strengths of both paradigms, we propose Variational Model Based\nTailored UNet (VM_TUNet), a novel hybrid framework that integrates the\nfourth-order modified Cahn-Hilliard equation with the deep learning backbone of\nUNet, which combines the interpretability and edge-preserving properties of\nvariational methods with the adaptive feature learning of neural networks.\nSpecifically, a data-driven operator is introduced to replace manual parameter\ntuning, and we incorporate the tailored finite point method (TFPM) to enforce\nhigh-precision boundary preservation. Experimental results on benchmark\ndatasets demonstrate that VM_TUNet achieves superior segmentation performance\ncompared to existing approaches, especially for fine boundary delineation."}
{"id": "2505.05950", "pdf": "https://arxiv.org/pdf/2505.05950", "abs": "https://arxiv.org/abs/2505.05950", "authors": ["Yuxin Zhou", "Zheng Li", "Jun Zhang", "Jue Wang", "Yiping Wang", "Zhongle Xie", "Ke Chen", "Lidan Shou"], "title": "FloE: On-the-Fly MoE Inference", "categories": ["cs.LG"], "comment": "Accepted at ICML 2025", "summary": "With the widespread adoption of Mixture-of-Experts (MoE) models, there is a\ngrowing demand for efficient inference on memory-constrained devices. While\noffloading expert parameters to CPU memory and loading activated experts on\ndemand has emerged as a potential solution, the large size of activated experts\noverburdens the limited PCIe bandwidth, hindering the effectiveness in\nlatency-sensitive scenarios. To mitigate this, we propose FloE, an on-the-fly\nMoE inference system on memory-constrained GPUs. FloE is built on the insight\nthat there exists substantial untapped redundancy within sparsely activated\nexperts. It employs various compression techniques on the expert's internal\nparameter matrices to reduce the data movement load, combined with low-cost\nsparse prediction, achieving perceptible inference acceleration in wall-clock\ntime on resource-constrained devices. Empirically, FloE achieves a 9.3x\ncompression of parameters per expert in Mixtral-8x7B; enables deployment on a\nGPU with only 11GB VRAM, reducing the memory footprint by up to 8.5x; and\ndelivers a 48.7x inference speedup compared to DeepSpeed-MII on a single\nGeForce RTX 3090."}
{"id": "2501.14851", "pdf": "https://arxiv.org/pdf/2501.14851", "abs": "https://arxiv.org/abs/2501.14851", "authors": ["Michael K. Chen", "Xikun Zhang", "Dacheng Tao"], "title": "JustLogic: A Comprehensive Benchmark for Evaluating Deductive Reasoning in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.LO"], "comment": null, "summary": "Logical reasoning is a critical component of Large Language Models (LLMs),\nand substantial research efforts in recent years have aimed to enhance their\ndeductive reasoning capabilities. However, existing deductive reasoning\nbenchmarks, which are crucial for evaluating and advancing LLMs, are inadequate\ndue to their lack of task complexity, presence of prior knowledge as a\nconfounder, and superficial error analysis. To address these deficiencies, we\nintroduce JustLogic, a synthetically generated deductive reasoning benchmark\ndesigned for rigorous evaluation of LLMs. JustLogic is (i) highly complex,\ncapable of generating a diverse range of linguistic patterns, vocabulary, and\nargument structures; (ii) prior knowledge independent, eliminating the\nadvantage of models possessing prior knowledge and ensuring that only deductive\nreasoning is used to answer questions; and (iii) capable of in-depth error\nanalysis on the heterogeneous effects of reasoning depth and argument form on\nmodel accuracy. Our experimental results on JustLogic reveal that (i)\nstate-of-the-art (SOTA) reasoning LLMs perform on par or better than the human\naverage but significantly worse than the human ceiling, and (ii) SOTA\nnon-reasoning models still underperform the human average. All code and data\nare available at https://github.com/michaelchen-lab/JustLogic"}
{"id": "2505.05901", "pdf": "https://arxiv.org/pdf/2505.05901", "abs": "https://arxiv.org/abs/2505.05901", "authors": ["Hanzhe Liang", "Aoran Wang", "Jie Zhou", "Xin Jin", "Can Gao", "Jinbao Wang"], "title": "Examining the Source of Defects from a Mechanical Perspective for 3D Anomaly Detection", "categories": ["cs.CV", "cs.AI"], "comment": "26 pages", "summary": "In this paper, we go beyond identifying anomalies only in structural terms\nand think about better anomaly detection motivated by anomaly causes. Most\nanomalies are regarded as the result of unpredictable defective forces from\ninternal and external sources, and their opposite forces are sought to correct\nthe anomalies. We introduced a Mechanics Complementary framework for 3D anomaly\ndetection (MC4AD) to generate internal and external Corrective forces for each\npoint. A Diverse Anomaly-Generation (DA-Gen) module is first proposed to\nsimulate various anomalies. Then, we present a Corrective Force Prediction\nNetwork (CFP-Net) with complementary representations for point-level\nrepresentation to simulate the different contributions of internal and external\ncorrective forces. A combined loss was proposed, including a new symmetric loss\nand an overall loss, to constrain the corrective forces properly. As a\nhighlight, we consider 3D anomaly detection in industry more comprehensively,\ncreating a hierarchical quality control strategy based on a three-way decision\nand contributing a dataset named Anomaly-IntraVariance with intraclass variance\nto evaluate the model. On the proposed and existing five datasets, we obtained\nnine state-of-the-art performers with the minimum parameters and the fastest\ninference speed. The source is available at\nhttps://github.com/hzzzzzhappy/MC4AD"}
{"id": "2505.05834", "pdf": "https://arxiv.org/pdf/2505.05834", "abs": "https://arxiv.org/abs/2505.05834", "authors": ["Chunlai Dong", "Haochao Ying", "Qibo Qiu", "Jinhong Wang", "Danny Chen", "Jian Wu"], "title": "Dual-level Fuzzy Learning with Patch Guidance for Image Ordinal Regression", "categories": ["cs.CV"], "comment": "Accepted by IJCAI 2025", "summary": "Ordinal regression bridges regression and classification by assigning objects\nto ordered classes. While human experts rely on discriminative patch-level\nfeatures for decisions, current approaches are limited by the availability of\nonly image-level ordinal labels, overlooking fine-grained patch-level\ncharacteristics. In this paper, we propose a Dual-level Fuzzy Learning with\nPatch Guidance framework, named DFPG that learns precise feature-based grading\nboundaries from ambiguous ordinal labels, with patch-level supervision.\nSpecifically, we propose patch-labeling and filtering strategies to enable the\nmodel to focus on patch-level features exclusively with only image-level\nordinal labels available. We further design a dual-level fuzzy learning module,\nwhich leverages fuzzy logic to quantitatively capture and handle label\nambiguity from both patch-wise and channel-wise perspectives. Extensive\nexperiments on various image ordinal regression datasets demonstrate the\nsuperiority of our proposed method, further confirming its ability in\ndistinguishing samples from difficult-to-classify categories. The code is\navailable at https://github.com/ZJUMAI/DFPG-ord."}
{"id": "2505.05967", "pdf": "https://arxiv.org/pdf/2505.05967", "abs": "https://arxiv.org/abs/2505.05967", "authors": ["Uyoata E. Uyoata", "Gilberto Berardinelli", "Ramoni Adeogun"], "title": "Learning Power Control Protocol for In-Factory 6G Subnetworks", "categories": ["cs.LG", "cs.NI", "eess.SP"], "comment": "Accepted for presented at IEEE EuCNC & 6G Summit 2025", "summary": "In-X Subnetworks are envisioned to meet the stringent demands of short-range\ncommunication in diverse 6G use cases. In the context of In-Factory scenarios,\neffective power control is critical to mitigating the impact of interference\nresulting from potentially high subnetwork density. Existing approaches to\npower control in this domain have predominantly emphasized the data plane,\noften overlooking the impact of signaling overhead. Furthermore, prior work has\ntypically adopted a network-centric perspective, relying on the assumption of\ncomplete and up-to-date channel state information (CSI) being readily available\nat the central controller. This paper introduces a novel multi-agent\nreinforcement learning (MARL) framework designed to enable access points to\nautonomously learn both signaling and power control protocols in an In-Factory\nSubnetwork environment. By formulating the problem as a partially observable\nMarkov decision process (POMDP) and leveraging multi-agent proximal policy\noptimization (MAPPO), the proposed approach achieves significant advantages.\nThe simulation results demonstrate that the learning-based method reduces\nsignaling overhead by a factor of 8 while maintaining a buffer flush rate that\nlags the ideal \"Genie\" approach by only 5%."}
{"id": "2501.16154", "pdf": "https://arxiv.org/pdf/2501.16154", "abs": "https://arxiv.org/abs/2501.16154", "authors": ["Xin Huang", "Tarun Kumar Vangani", "Zhengyuan Liu", "Bowei Zou", "Ai Ti Aw"], "title": "AdaCoT: Rethinking Cross-Lingual Factual Reasoning through Adaptive Chain-of-Thought", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models have shown impressive multilingual capabilities through\npretraining on diverse corpora. While these models show strong reasoning\nabilities, their performance varies significantly across languages due to\nimbalanced training data distribution. Existing approaches using sample-level\ntranslation for extensive multilingual pretraining and cross-lingual tuning\nface scalability challenges and often fail to capture nuanced reasoning\nprocesses across languages. In this paper, we introduce AdaCoT (Adaptive\nChain-of-Thought), a framework that enhances multilingual factual reasoning by\ndynamically routing thought processes in intermediary ``thinking languages''\nbefore generating target-language responses. AdaCoT leverages a\nlanguage-agnostic core and incorporates an adaptive, reward-based mechanism for\nselecting optimal reasoning pathways without requiring additional pretraining.\nOur comprehensive evaluation across multiple benchmarks demonstrates\nsubstantial improvements in both factual reasoning quality and cross-lingual\nconsistency, with particularly strong performance gains in low-resource\nlanguage settings. The results suggest that adaptive reasoning paths can\neffectively bridge the performance gap between high and low-resource languages\nwhile maintaining cultural and linguistic nuances."}
{"id": "2505.05943", "pdf": "https://arxiv.org/pdf/2505.05943", "abs": "https://arxiv.org/abs/2505.05943", "authors": ["Maan Alhazmi", "Abdulrahman Altahhan"], "title": "Achieving 3D Attention via Triplet Squeeze and Excitation Block", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "The emergence of ConvNeXt and its variants has reaffirmed the conceptual and\nstructural suitability of CNN-based models for vision tasks, re-establishing\nthem as key players in image classification in general, and in facial\nexpression recognition (FER) in particular. In this paper, we propose a new set\nof models that build on these advancements by incorporating a new set of\nattention mechanisms that combines Triplet attention with\nSqueeze-and-Excitation (TripSE) in four different variants. We demonstrate the\neffectiveness of these variants by applying them to the ResNet18, DenseNet and\nConvNext architectures to validate their versatility and impact. Our study\nshows that incorporating a TripSE block in these CNN models boosts their\nperformances, particularly for the ConvNeXt architecture, indicating its\nutility. We evaluate the proposed mechanisms and associated models across four\ndatasets, namely CIFAR100, ImageNet, FER2013 and AffectNet datasets, where\nConvNext with TripSE achieves state-of-the-art results with an accuracy of\n\\textbf{78.27\\%} on the popular FER2013 dataset, a new feat for this dataset."}
{"id": "2505.05845", "pdf": "https://arxiv.org/pdf/2505.05845", "abs": "https://arxiv.org/abs/2505.05845", "authors": ["Guohao Lin", "Shidong Pan", "Rasul Khanbayov", "Changxi Yang", "Ani Khaloian-Sarnaghi", "Andriy Kovryga"], "title": "Automated Knot Detection and Pairing for Wood Analysis in the Timber Industry", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Knots in wood are critical to both aesthetics and structural integrity,\nmaking their detection and pairing essential in timber processing. However,\ntraditional manual annotation was labor-intensive and inefficient,\nnecessitating automation. This paper proposes a lightweight and fully automated\npipeline for knot detection and pairing based on machine learning techniques.\nIn the detection stage, high-resolution surface images of wooden boards were\ncollected using industrial-grade cameras, and a large-scale dataset was\nmanually annotated and preprocessed. After the transfer learning, the YOLOv8l\nachieves an mAP@0.5 of 0.887. In the pairing stage, detected knots were\nanalyzed and paired based on multidimensional feature extraction. A triplet\nneural network was used to map the features into a latent space, enabling\nclustering algorithms to identify and pair corresponding knots. The triplet\nnetwork with learnable weights achieved a pairing accuracy of 0.85. Further\nanalysis revealed that he distances from the knot's start and end points to the\nbottom of the wooden board, and the longitudinal coordinates play crucial roles\nin achieving high pairing accuracy. Our experiments validate the effectiveness\nof the proposed solution, demonstrating the potential of AI in advancing wood\nscience and industry."}
{"id": "2505.05983", "pdf": "https://arxiv.org/pdf/2505.05983", "abs": "https://arxiv.org/abs/2505.05983", "authors": ["Vivek Mohan", "Biyan Zhou", "Zhou Wang", "Anil Bharath", "Emmanuel Drakakis", "Arindam Basu"], "title": "Architectural Exploration of Hybrid Neural Decoders for Neuromorphic Implantable BMI", "categories": ["cs.LG"], "comment": "The paper has been accepted for lecture presentation at the 2025 IEEE\n  International Symposium on Circuits and Systems in London", "summary": "This work presents an efficient decoding pipeline for neuromorphic\nimplantable brain-machine interfaces (Neu-iBMI), leveraging sparse neural event\ndata from an event-based neural sensing scheme. We introduce a tunable event\nfilter (EvFilter), which also functions as a spike detector (EvFilter-SPD),\nsignificantly reducing the number of events processed for decoding by 192X and\n554X, respectively. The proposed pipeline achieves high decoding performance,\nup to R^2=0.73, with ANN- and SNN-based decoders, eliminating the need for\nsignal recovery, spike detection, or sorting, commonly performed in\nconventional iBMI systems. The SNN-Decoder reduces computations and memory\nrequired by 5-23X compared to NN-, and LSTM-Decoders, while the ST-NN-Decoder\ndelivers similar performance to an LSTM-Decoder requiring 2.5X fewer resources.\nThis streamlined approach significantly reduces computational and memory\ndemands, making it ideal for low-power, on-implant, or wearable iBMIs."}
{"id": "2502.00290", "pdf": "https://arxiv.org/pdf/2502.00290", "abs": "https://arxiv.org/abs/2502.00290", "authors": ["Huan Ma", "Jingdong Chen", "Joey Tianyi Zhou", "Guangyu Wang", "Changqing Zhang"], "title": "Estimating LLM Uncertainty with Evidence", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Over the past few years, Large Language Models (LLMs) have developed rapidly\nand are widely applied in various domains. However, LLMs face the issue of\nhallucinations, generating responses that may be unreliable when the models\nlack relevant knowledge. To be aware of potential hallucinations, uncertainty\nestimation methods have been introduced, and most of them have confirmed that\nreliability lies in critical tokens. However, probability-based methods perform\npoorly in identifying token reliability, limiting their practical utility. In\nthis paper, we reveal that the probability-based method fails to estimate token\nreliability due to the loss of evidence strength information which is\naccumulated in the training stage. Therefore, we present Logits-induced token\nuncertainty (LogTokU), a framework for estimating decoupled token uncertainty\nin LLMs, enabling real-time uncertainty estimation without requiring multiple\nsampling processes. We employ evidence modeling to implement LogTokU and use\nthe estimated uncertainty to guide downstream tasks. The experimental results\ndemonstrate that LogTokU has significant effectiveness and promise."}
{"id": "2505.05965", "pdf": "https://arxiv.org/pdf/2505.05965", "abs": "https://arxiv.org/abs/2505.05965", "authors": ["Abdelfateh Bekkair", "Slimane Bellaouar", "Slimane Oulad-Naoui"], "title": "A Noise-Resilient Semi-Supervised Graph Autoencoder for Overlapping Semantic Community Detection", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "Community detection in networks with overlapping structures remains a\nsignificant challenge, particularly in noisy real-world environments where\nintegrating topology, node attributes, and prior information is critical. To\naddress this, we propose a semi-supervised graph autoencoder that combines\ngraph multi-head attention and modularity maximization to robustly detect\noverlapping communities. The model learns semantic representations by fusing\nstructural, attribute, and prior knowledge while explicitly addressing noise in\nnode features. Key innovations include a noise-resistant architecture and a\nsemantic semi-supervised design optimized for community quality through\nmodularity constraints. Experiments demonstrate superior performance the model\noutperforms state-of-the-art methods in overlapping community detection\n(improvements in NMI and F1-score) and exhibits exceptional robustness to\nattribute noise, maintaining stable performance under 60\\% feature corruption.\nThese results highlight the importance of integrating attribute semantics and\nstructural patterns for accurate community discovery in complex networks."}
{"id": "2505.05848", "pdf": "https://arxiv.org/pdf/2505.05848", "abs": "https://arxiv.org/abs/2505.05848", "authors": ["Yue Yin", "Enze Tao", "Weijian Deng", "Dylan Campbell"], "title": "RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects", "categories": ["cs.CV"], "comment": null, "summary": "Modern 3D reconstruction and novel view synthesis approaches have\ndemonstrated strong performance on scenes with opaque Lambertian objects.\nHowever, most assume straight light paths and therefore cannot properly handle\nrefractive and reflective materials. Moreover, datasets specialized for these\neffects are limited, stymieing efforts to evaluate performance and develop\nsuitable techniques. In this work, we introduce a synthetic RefRef dataset and\nbenchmark for reconstructing scenes with refractive and reflective objects from\nposed images. Our dataset has 50 such objects of varying complexity, from\nsingle-material convex shapes to multi-material non-convex shapes, each placed\nin three different background types, resulting in 150 scenes. We also propose\nan oracle method that, given the object geometry and refractive indices,\ncalculates accurate light paths for neural rendering, and an approach based on\nthis that avoids these assumptions. We benchmark these against several\nstate-of-the-art methods and show that all methods lag significantly behind the\noracle, highlighting the challenges of the task and dataset."}
{"id": "2505.06000", "pdf": "https://arxiv.org/pdf/2505.06000", "abs": "https://arxiv.org/abs/2505.06000", "authors": ["Stephan Bartl", "Kevin Innerebner", "Elisabeth Lex"], "title": "Differentiable Fuzzy Neural Networks for Recommender Systems", "categories": ["cs.LG"], "comment": "Accepted for publication at the HyPer workshop, co-located with ACM\n  UMAP 2025", "summary": "As recommender systems become increasingly complex, transparency is essential\nto increase user trust, accountability, and regulatory compliance.\nNeuro-symbolic approaches that integrate symbolic reasoning with sub-symbolic\nlearning offer a promising approach toward transparent and user-centric\nsystems. In this work-in-progress, we investigate using fuzzy neural networks\n(FNNs) as a neuro-symbolic approach for recommendations that learn logic-based\nrules over predefined, human-readable atoms. Each rule corresponds to a fuzzy\nlogic expression, making the recommender's decision process inherently\ntransparent. In contrast to black-box machine learning methods, our approach\nreveals the reasoning behind a recommendation while maintaining competitive\nperformance. We evaluate our method on a synthetic and MovieLens 1M datasets\nand compare it to state-of-the-art recommendation algorithms. Our results\ndemonstrate that our approach accurately captures user behavior while providing\na transparent decision-making process. Finally, the differentiable nature of\nthis approach facilitates an integration with other neural models, enabling the\ndevelopment of hybrid, transparent recommender systems."}
{"id": "2502.01210", "pdf": "https://arxiv.org/pdf/2502.01210", "abs": "https://arxiv.org/abs/2502.01210", "authors": ["Sam Kirkham", "Patrycja Strycharczuk", "Rob Davies", "Danielle Welburn"], "title": "Phonetic accommodation and inhibition in a dynamic neural field model", "categories": ["cs.CL"], "comment": null, "summary": "Short-term phonetic accommodation is a fundamental driver behind accent\nchange, but how does real-time input from another speaker's voice shape the\nspeech planning representations of an interlocutor? We advance a computational\nmodel of change in speech planning representations during phonetic\naccommodation, grounded in dynamic neural field equations for movement planning\nand memory dynamics. A dual-layer planning/memory field predicts that\nconvergence to a model talker on one trial can trigger divergence on subsequent\ntrials, due to a delayed inhibitory effect in the more slowly evolving memory\nfield. The model's predictions are compared with empirical patterns of\naccommodation from an experimental pilot study. We show that observed empirical\nphenomena may correspond to variation in the magnitude of inhibitory memory\ndynamics, which could reflect resistance to accommodation due to phonological\nand/or sociolinguistic pressures. We discuss the implications of these results\nfor the relations between short-term phonetic accommodation and sound change."}
{"id": "2505.05988", "pdf": "https://arxiv.org/pdf/2505.05988", "abs": "https://arxiv.org/abs/2505.05988", "authors": ["Jørgen Villadsen"], "title": "Minimal Sequent Calculus for Teaching First-Order Logic: Lessons Learned", "categories": ["cs.LO", "cs.AI", "F.4; I.2.3; K.3.1"], "comment": "In Proceedings ThEdu24, arXiv:2505.04677", "summary": "MiniCalc is a web app for teaching first-order logic based on a minimal\nsequent calculus. As an option the proofs can be verified in the Isabelle proof\nassistant. We present the lessons learned using the tool in recent years at our\nuniversity."}
{"id": "2505.05853", "pdf": "https://arxiv.org/pdf/2505.05853", "abs": "https://arxiv.org/abs/2505.05853", "authors": ["Tongda Xu", "Jiahao Li", "Bin Li", "Yan Wang", "Ya-Qin Zhang", "Yan Lu"], "title": "PICD: Versatile Perceptual Image Compression with Diffusion Rendering", "categories": ["cs.CV"], "comment": "CVPR 2025", "summary": "Recently, perceptual image compression has achieved significant advancements,\ndelivering high visual quality at low bitrates for natural images. However, for\nscreen content, existing methods often produce noticeable artifacts when\ncompressing text. To tackle this challenge, we propose versatile perceptual\nscreen image compression with diffusion rendering (PICD), a codec that works\nwell for both screen and natural images. More specifically, we propose a\ncompression framework that encodes the text and image separately, and renders\nthem into one image using diffusion model. For this diffusion rendering, we\nintegrate conditional information into diffusion models at three distinct\nlevels: 1). Domain level: We fine-tune the base diffusion model using text\ncontent prompts with screen content. 2). Adaptor level: We develop an efficient\nadaptor to control the diffusion model using compressed image and text as\ninput. 3). Instance level: We apply instance-wise guidance to further enhance\nthe decoding process. Empirically, our PICD surpasses existing perceptual\ncodecs in terms of both text accuracy and perceptual quality. Additionally,\nwithout text conditions, our approach serves effectively as a perceptual codec\nfor natural images."}
{"id": "2505.06017", "pdf": "https://arxiv.org/pdf/2505.06017", "abs": "https://arxiv.org/abs/2505.06017", "authors": ["Hiroki Shiraishi", "Yohei Hayamizu", "Tomonori Hashiyama"], "title": "Fuzzy-UCS Revisited: Self-Adaptation of Rule Representations in Michigan-Style Learning Fuzzy-Classifier Systems", "categories": ["cs.LG"], "comment": "Accepted by the ACM Genetic and Evolutionary Computation Conference\n  (GECCO) 2023", "summary": "This paper focuses on the impact of rule representation in Michigan-style\nLearning Fuzzy-Classifier Systems (LFCSs) on its classification performance. A\nwell-representation of the rules in an LFCS is crucial for improving its\nperformance. However, conventional rule representations frequently need help\naddressing problems with unknown data characteristics. To address this issue,\nthis paper proposes a supervised LFCS (i.e., Fuzzy-UCS) with a self-adaptive\nrule representation mechanism, entitled Adaptive-UCS. Adaptive-UCS incorporates\na fuzzy indicator as a new rule parameter that sets the membership function of\na rule as either rectangular (i.e., crisp) or triangular (i.e., fuzzy) shapes.\nThe fuzzy indicator is optimized with evolutionary operators, allowing the\nsystem to search for an optimal rule representation. Results from extensive\nexperiments conducted on continuous space problems demonstrate that\nAdaptive-UCS outperforms other UCSs with conventional crisp-hyperrectangular\nand fuzzy-hypertrapezoidal rule representations in classification accuracy.\nAdditionally, Adaptive-UCS exhibits robustness in the case of noisy inputs and\nreal-world problems with inherent uncertainty, such as missing values, leading\nto stable classification performance."}
{"id": "2502.04134", "pdf": "https://arxiv.org/pdf/2502.04134", "abs": "https://arxiv.org/abs/2502.04134", "authors": ["Bryan Guan", "Tanya Roosta", "Peyman Passban", "Mehdi Rezagholizadeh"], "title": "The Order Effect: Investigating Prompt Sensitivity to Input Order in LLMs", "categories": ["cs.CL"], "comment": "The first 3 authors have contributed equally", "summary": "As large language models (LLMs) become integral to diverse applications,\nensuring their reliability under varying input conditions is crucial. One key\nissue affecting this reliability is order sensitivity, wherein slight\nvariations in the input arrangement can lead to inconsistent or biased outputs.\nAlthough recent advances have reduced this sensitivity, the problem remains\nunresolved. This paper investigates the extent of order sensitivity in LLMs\nwhose internal components are hidden from users (such as closed-source models\nor those accessed via API calls). We conduct experiments across multiple tasks,\nincluding paraphrasing, relevance judgment, and multiple-choice questions. Our\nresults show that input order significantly affects performance across tasks,\nwith shuffled inputs leading to measurable declines in output accuracy.\nFew-shot prompting demonstrates mixed effectiveness and offers partial\nmitigation; however, fails to fully resolve the problem. These findings\nhighlight persistent risks, particularly in high-stakes applications, and point\nto the need for more robust LLMs or improved input-handling techniques in\nfuture development."}
{"id": "2505.06023", "pdf": "https://arxiv.org/pdf/2505.06023", "abs": "https://arxiv.org/abs/2505.06023", "authors": ["Qian Qi"], "title": "Universal Approximation Theorem for Deep Q-Learning via FBSDE System", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "The approximation capabilities of Deep Q-Networks (DQNs) are commonly\njustified by general Universal Approximation Theorems (UATs) that do not\nleverage the intrinsic structural properties of the optimal Q-function, the\nsolution to a Bellman equation. This paper establishes a UAT for a class of\nDQNs whose architecture is designed to emulate the iterative refinement process\ninherent in Bellman updates. A central element of our analysis is the\npropagation of regularity: while the transformation induced by a single Bellman\noperator application exhibits regularity, for which Backward Stochastic\nDifferential Equations (BSDEs) theory provides analytical tools, the uniform\nregularity of the entire sequence of value iteration iterates--specifically,\ntheir uniform Lipschitz continuity on compact domains under standard Lipschitz\nassumptions on the problem data--is derived from finite-horizon dynamic\nprogramming principles. We demonstrate that layers of a deep residual network,\nconceived as neural operators acting on function spaces, can approximate the\naction of the Bellman operator. The resulting approximation theorem is thus\nintrinsically linked to the control problem's structure, offering a proof\ntechnique wherein network depth directly corresponds to iterations of value\nfunction refinement, accompanied by controlled error propagation. This\nperspective reveals a dynamic systems view of the network's operation on a\nspace of value functions."}
{"id": "2505.05855", "pdf": "https://arxiv.org/pdf/2505.05855", "abs": "https://arxiv.org/abs/2505.05855", "authors": ["Hongyu Rui", "Yinzhe Wu", "Fanwen Wang", "Jiahao Huang", "Liutao Yang", "Zi Wang", "Guang Yang"], "title": "Decoupling Multi-Contrast Super-Resolution: Pairing Unpaired Synthesis with Implicit Representations", "categories": ["cs.CV"], "comment": null, "summary": "Magnetic Resonance Imaging (MRI) is critical for clinical diagnostics but is\noften limited by long acquisition times and low signal-to-noise ratios,\nespecially in modalities like diffusion and functional MRI. The multi-contrast\nnature of MRI presents a valuable opportunity for cross-modal enhancement,\nwhere high-resolution (HR) modalities can serve as references to boost the\nquality of their low-resolution (LR) counterparts-motivating the development of\nMulti-Contrast Super-Resolution (MCSR) techniques. Prior work has shown that\nleveraging complementary contrasts can improve SR performance; however,\neffective feature extraction and fusion across modalities with varying\nresolutions remains a major challenge. Moreover, existing MCSR methods often\nassume fixed resolution settings and all require large, perfectly paired\ntraining datasets-conditions rarely met in real-world clinical environments. To\naddress these challenges, we propose a novel Modular Multi-Contrast\nSuper-Resolution (MCSR) framework that eliminates the need for paired training\ndata and supports arbitrary upscaling. Our method decouples the MCSR task into\ntwo stages: (1) Unpaired Cross-Modal Synthesis (U-CMS), which translates a\nhigh-resolution reference modality into a synthesized version of the target\ncontrast, and (2) Unsupervised Super-Resolution (U-SR), which reconstructs the\nfinal output using implicit neural representations (INRs) conditioned on\nspatial coordinates. This design enables scale-agnostic and anatomically\nfaithful reconstruction by bridging un-paired cross-modal synthesis with\nunsupervised resolution enhancement. Experiments show that our method achieves\nsuperior performance at 4x and 8x upscaling, with improved fidelity and\nanatomical consistency over existing baselines. Our framework demonstrates\nstrong potential for scalable, subject-specific, and data-efficient MCSR in\nreal-world clinical settings."}
{"id": "2505.06047", "pdf": "https://arxiv.org/pdf/2505.06047", "abs": "https://arxiv.org/abs/2505.06047", "authors": ["Francesco Spinnato", "Cristiano Landi"], "title": "PYRREGULAR: A Unified Framework for Irregular Time Series, with Classification Benchmarks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Irregular temporal data, characterized by varying recording frequencies,\ndiffering observation durations, and missing values, presents significant\nchallenges across fields like mobility, healthcare, and environmental science.\nExisting research communities often overlook or address these challenges in\nisolation, leading to fragmented tools and methods. To bridge this gap, we\nintroduce a unified framework, and the first standardized dataset repository\nfor irregular time series classification, built on a common array format to\nenhance interoperability. This repository comprises 34 datasets on which we\nbenchmark 12 classifier models from diverse domains and communities. This work\naims to centralize research efforts and enable a more robust evaluation of\nirregular temporal data analysis methods."}
{"id": "2502.09667", "pdf": "https://arxiv.org/pdf/2502.09667", "abs": "https://arxiv.org/abs/2502.09667", "authors": ["Jairo Diaz-Rodriguez"], "title": "k-LLMmeans: Scalable, Stable, and Interpretable Text Clustering via LLM-based Centroids", "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "We introduce k-LLMmeans, a novel modification of the k-means algorithm for\ntext clustering that leverages LLM-generated summaries as cluster centroids,\ncapturing semantic nuances often missed by purely numerical averages. This\ndesign preserves the core optimization properties of k-means while enhancing\nsemantic interpretability and avoiding the scalability and instability issues\ntypical of modern LLM-based clustering. Unlike existing methods, our approach\ndoes not increase LLM usage with dataset size and produces transparent\nintermediate outputs. We further extend it with a mini-batch variant for\nefficient, real-time clustering of streaming text. Extensive experiments across\nmultiple datasets, embeddings, and LLMs show that k-LLMmeans consistently\noutperforms k-means and other traditional baselines and achieves results\ncomparable to state-of-the-art LLM-based clustering, with a fraction of the LLM\ncalls. Finally, we present a case study on sequential text streams and\nintroduce a new benchmark dataset constructed from StackExchange to evaluate\ntext-stream clustering methods."}
{"id": "2505.06085", "pdf": "https://arxiv.org/pdf/2505.06085", "abs": "https://arxiv.org/abs/2505.06085", "authors": ["Hiari Pizzini Cavagna", "Daniele Cesarini", "Andrea Bartolini"], "title": "Assessing Tenstorrent's RISC-V MatMul Acceleration Capabilities", "categories": ["cs.PF", "cs.AI", "cs.AR"], "comment": "Accepted to the Computational Aspects of Deep Learning Workshop at\n  ISC High Performance 2025. To appear in the ISC High Performance 2025\n  Workshop Proceedings", "summary": "The increasing demand for generative AI as Large Language Models (LLMs)\nservices has driven the need for specialized hardware architectures that\noptimize computational efficiency and energy consumption. This paper evaluates\nthe performance of the Tenstorrent Grayskull e75 RISC-V accelerator for basic\nlinear algebra kernels at reduced numerical precision, a fundamental operation\nin LLM computations. We present a detailed characterization of Grayskull's\nexecution model, gridsize, matrix dimensions, data formats, and numerical\nprecision impact computational efficiency. Furthermore, we compare Grayskull's\nperformance against state-of-the-art architectures with tensor acceleration,\nincluding Intel Sapphire Rapids processors and two NVIDIA GPUs (V100 and A100).\nWhilst NVIDIA GPUs dominate raw performance, Grayskull demonstrates a\ncompetitive trade-off between power consumption and computational throughput,\nreaching a peak of 1.55 TFLOPs/Watt with BF16."}
{"id": "2505.05892", "pdf": "https://arxiv.org/pdf/2505.05892", "abs": "https://arxiv.org/abs/2505.05892", "authors": ["Alexander Lappe", "Martin A. Giese"], "title": "Register and CLS tokens yield a decoupling of local and global features in large ViTs", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Recent work has shown that the attention maps of the widely popular DINOv2\nmodel exhibit artifacts, which hurt both model interpretability and performance\non dense image tasks. These artifacts emerge due to the model repurposing patch\ntokens with redundant local information for the storage of global image\ninformation. To address this problem, additional register tokens have been\nincorporated in which the model can store such information instead. We\ncarefully examine the influence of these register tokens on the relationship\nbetween global and local image features, showing that while register tokens\nyield cleaner attention maps, these maps do not accurately reflect the\nintegration of local image information in large models. Instead, global\ninformation is dominated by information extracted from register tokens, leading\nto a disconnect between local and global features. Inspired by these findings,\nwe show that the CLS token itself, which can be interpreted as a register,\nleads to a very similar phenomenon in models without explicit register tokens.\nOur work shows that care must be taken when interpreting attention maps of\nlarge ViTs. Further, by clearly attributing the faulty behaviour to register\nand CLS tokens, we show a path towards more interpretable vision models."}
{"id": "2505.06053", "pdf": "https://arxiv.org/pdf/2505.06053", "abs": "https://arxiv.org/abs/2505.06053", "authors": ["Rustem Islamov", "Yarden As", "Ilyas Fatkhullin"], "title": "Safe-EF: Error Feedback for Nonsmooth Constrained Optimization", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "Federated learning faces severe communication bottlenecks due to the high\ndimensionality of model updates. Communication compression with contractive\ncompressors (e.g., Top-K) is often preferable in practice but can degrade\nperformance without proper handling. Error feedback (EF) mitigates such issues\nbut has been largely restricted for smooth, unconstrained problems, limiting\nits real-world applicability where non-smooth objectives and safety constraints\nare critical. We advance our understanding of EF in the canonical non-smooth\nconvex setting by establishing new lower complexity bounds for first-order\nalgorithms with contractive compression. Next, we propose Safe-EF, a novel\nalgorithm that matches our lower bound (up to a constant) while enforcing\nsafety constraints essential for practical applications. Extending our approach\nto the stochastic setting, we bridge the gap between theory and practical\nimplementation. Extensive experiments in a reinforcement learning setup,\nsimulating distributed humanoid robot training, validate the effectiveness of\nSafe-EF in ensuring safety and reducing communication complexity."}
{"id": "2502.14338", "pdf": "https://arxiv.org/pdf/2502.14338", "abs": "https://arxiv.org/abs/2502.14338", "authors": ["Avinash Patil", "Siru Tao", "Aryan Jadon"], "title": "English Please: Evaluating Machine Translation with Large Language Models for Multilingual Bug Reports", "categories": ["cs.CL", "cs.SE"], "comment": "8 Pages, 4 Figures, 3 Tables", "summary": "Accurate translation of bug reports is critical for efficient collaboration\nin global software development. In this study, we conduct the first\ncomprehensive evaluation of machine translation (MT) performance on bug\nreports, analyzing the capabilities of DeepL, AWS Translate, and large language\nmodels such as ChatGPT, Claude, Gemini, LLaMA, and Mistral using data from the\nVisual Studio Code GitHub repository, specifically focusing on reports labeled\nwith the english-please tag. To assess both translation quality and source\nlanguage identification accuracy, we employ a range of MT evaluation\nmetrics-including BLEU, BERTScore, COMET, METEOR, and ROUGE-alongside\nclassification metrics such as accuracy, precision, recall, and F1-score. Our\nfindings reveal that while ChatGPT (gpt-4o) excels in semantic and lexical\ntranslation quality, it does not lead in source language identification. Claude\nand Mistral achieve the highest F1-scores (0.7182 and 0.7142, respectively),\nand Gemini records the best precision (0.7414). AWS Translate shows the highest\naccuracy (0.4717) in identifying source languages. These results highlight that\nno single system dominates across all tasks, reinforcing the importance of\ntask-specific evaluations. This study underscores the need for domain\nadaptation when translating technical content and provides actionable insights\nfor integrating MT into bug-triaging workflows. The code and dataset for this\npaper are available at GitHub-https://github.com/av9ash/English-Please"}
{"id": "2505.06091", "pdf": "https://arxiv.org/pdf/2505.06091", "abs": "https://arxiv.org/abs/2505.06091", "authors": ["Xinxin Li", "Juan Zhang", "Da Li", "Xingyu Liu", "Jin Xu", "Junping Yin"], "title": "UniSymNet: A Unified Symbolic Network Guided by Transformer", "categories": ["cs.LG", "cs.AI", "cs.SC"], "comment": null, "summary": "Symbolic Regression (SR) is a powerful technique for automatically\ndiscovering mathematical expressions from input data. Mainstream SR algorithms\nsearch for the optimal symbolic tree in a vast function space, but the\nincreasing complexity of the tree structure limits their performance. Inspired\nby neural networks, symbolic networks have emerged as a promising new paradigm.\nHowever, most existing symbolic networks still face certain challenges: binary\nnonlinear operators $\\{\\times, \\div\\}$ cannot be naturally extended to\nmultivariate operators, and training with fixed architecture often leads to\nhigher complexity and overfitting. In this work, we propose a Unified Symbolic\nNetwork that unifies nonlinear binary operators into nested unary operators and\ndefine the conditions under which UniSymNet can reduce complexity. Moreover, we\npre-train a Transformer model with a novel label encoding method to guide\nstructural selection, and adopt objective-specific optimization strategies to\nlearn the parameters of the symbolic network. UniSymNet shows high fitting\naccuracy, excellent symbolic solution rate, and relatively low expression\ncomplexity, achieving competitive performance on low-dimensional Standard\nBenchmarks and high-dimensional SRBench."}
{"id": "2505.05913", "pdf": "https://arxiv.org/pdf/2505.05913", "abs": "https://arxiv.org/abs/2505.05913", "authors": ["Jianjian Yin", "Yi Chen", "Chengyu Li", "Zhichao Zheng", "Yanhui Gu", "Junsheng Zhou"], "title": "DFEN: Dual Feature Equalization Network for Medical Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Current methods for medical image segmentation primarily focus on extracting\ncontextual feature information from the perspective of the whole image. While\nthese methods have shown effective performance, none of them take into account\nthe fact that pixels at the boundary and regions with a low number of class\npixels capture more contextual feature information from other classes, leading\nto misclassification of pixels by unequal contextual feature information. In\nthis paper, we propose a dual feature equalization network based on the hybrid\narchitecture of Swin Transformer and Convolutional Neural Network, aiming to\naugment the pixel feature representations by image-level equalization feature\ninformation and class-level equalization feature information. Firstly, the\nimage-level feature equalization module is designed to equalize the contextual\ninformation of pixels within the image. Secondly, we aggregate regions of the\nsame class to equalize the pixel feature representations of the corresponding\nclass by class-level feature equalization module. Finally, the pixel feature\nrepresentations are enhanced by learning weights for image-level equalization\nfeature information and class-level equalization feature information. In\naddition, Swin Transformer is utilized as both the encoder and decoder, thereby\nbolstering the ability of the model to capture long-range dependencies and\nspatial correlations. We conducted extensive experiments on Breast Ultrasound\nImages (BUSI), International Skin Imaging Collaboration (ISIC2017), Automated\nCardiac Diagnosis Challenge (ACDC) and PH$^2$ datasets. The experimental\nresults demonstrate that our method have achieved state-of-the-art performance.\nOur code is publicly available at https://github.com/JianJianYin/DFEN."}
{"id": "2505.06080", "pdf": "https://arxiv.org/pdf/2505.06080", "abs": "https://arxiv.org/abs/2505.06080", "authors": ["Luis Miguel Esquivel-Sancho", "Maryam Ghandchi Tehrani", "Mauricio Muñoz-Arias", "Mahmoud Askari"], "title": "Fault Diagnosis of 3D-Printed Scaled Wind Turbine Blades", "categories": ["cs.LG"], "comment": null, "summary": "This study presents an integrated methodology for fault detection in wind\nturbine blades using 3D-printed scaled models, finite element simulations,\nexperimental modal analysis, and machine learning techniques. A scaled model of\nthe NREL 5MW blade was fabricated using 3D printing, and crack-type damages\nwere introduced at critical locations. Finite Element Analysis was employed to\npredict the impact of these damages on the natural frequencies, with the\nresults validated through controlled hammer impact tests. Vibration data was\nprocessed to extract both time-domain and frequency-domain features, and key\ndiscriminative variables were identified using statistical analyses (ANOVA).\nMachine learning classifiers, including Support Vector Machine and K-Nearest\nNeighbors, achieved classification accuracies exceeding 94%. The results\nrevealed that vibration modes 3, 4, and 6 are particularly sensitive to\nstructural anomalies for this blade. This integrated approach confirms the\nfeasibility of combining numerical simulations with experimental validations\nand paves the way for structural health monitoring systems in wind energy\napplications."}
{"id": "2502.20364", "pdf": "https://arxiv.org/pdf/2502.20364", "abs": "https://arxiv.org/abs/2502.20364", "authors": ["Ryan C. Barron", "Maksim E. Eren", "Olga M. Serafimova", "Cynthia Matuszek", "Boian S. Alexandrov"], "title": "Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages, 8 figures, 5 tables", "summary": "Agentic Generative AI, powered by Large Language Models (LLMs) with\nRetrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and Vector Stores\n(VSs), represents a transformative technology applicable to specialized domains\nsuch as legal systems, research, recommender systems, cybersecurity, and global\nsecurity, including proliferation research. This technology excels at inferring\nrelationships within vast unstructured or semi-structured datasets. The legal\ndomain here comprises complex data characterized by extensive, interrelated,\nand semi-structured knowledge systems with complex relations. It comprises\nconstitutions, statutes, regulations, and case law. Extracting insights and\nnavigating the intricate networks of legal documents and their relations is\ncrucial for effective legal research. Here, we introduce a generative AI system\nthat integrates RAG, VS, and KG, constructed via Non-Negative Matrix\nFactorization (NMF), to enhance legal information retrieval and AI reasoning\nand minimize hallucinations. In the legal system, these technologies empower AI\nagents to identify and analyze complex connections among cases, statutes, and\nlegal precedents, uncovering hidden relationships and predicting legal\ntrends-challenging tasks that are essential for ensuring justice and improving\noperational efficiency. Our system employs web scraping techniques to\nsystematically collect legal texts, such as statutes, constitutional\nprovisions, and case law, from publicly accessible platforms like Justia. It\nbridges the gap between traditional keyword-based searches and contextual\nunderstanding by leveraging advanced semantic representations, hierarchical\nrelationships, and latent topic discovery. This framework supports legal\ndocument clustering, summarization, and cross-referencing, for scalable,\ninterpretable, and accurate retrieval for semi-structured data while advancing\ncomputational law and AI."}
{"id": "2505.06108", "pdf": "https://arxiv.org/pdf/2505.06108", "abs": "https://arxiv.org/abs/2505.06108", "authors": ["Lennart Justen"], "title": "LLMs Outperform Experts on Challenging Biology Benchmarks", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "This study systematically evaluates 27 frontier Large Language Models on\neight diverse biology benchmarks spanning molecular biology, genetics, cloning,\nvirology, and biosecurity. Models from major AI developers released between\nNovember 2022 and April 2025 were assessed through ten independent runs per\nbenchmark. The findings reveal dramatic improvements in biological\ncapabilities. Top model performance increased more than 4-fold on the\nchallenging text-only subset of the Virology Capabilities Test over the study\nperiod, with the top model now performing twice as well as expert virologists.\nSeveral models now match or exceed expert-level performance on other\nchallenging benchmarks, including LAB-Bench CloningScenarios and the biology\nsubsets of GPQA and WMDP. Contrary to expectations, chain-of-thought did not\nsubstantially improve performance over zero-shot evaluation, while extended\nreasoning features in o3-mini and Claude 3.7 Sonnet typically improved\nperformance as predicted by inference scaling. Benchmarks such as PubMedQA and\nthe MMLU and WMDP biology subsets exhibited performance plateaus well below\n100%, suggesting benchmark saturation and errors in the underlying benchmark\ndata. The analysis highlights the need for more sophisticated evaluation\nmethodologies as AI systems continue to advance."}
{"id": "2505.05936", "pdf": "https://arxiv.org/pdf/2505.05936", "abs": "https://arxiv.org/abs/2505.05936", "authors": ["Weihong Li", "Xiaoqiong Liu", "Heng Fan", "Libo Zhang"], "title": "CGTrack: Cascade Gating Network with Hierarchical Feature Aggregation for UAV Tracking", "categories": ["cs.CV"], "comment": "Accepted by ICRA 2025", "summary": "Recent advancements in visual object tracking have markedly improved the\ncapabilities of unmanned aerial vehicle (UAV) tracking, which is a critical\ncomponent in real-world robotics applications. While the integration of\nhierarchical lightweight networks has become a prevalent strategy for enhancing\nefficiency in UAV tracking, it often results in a significant drop in network\ncapacity, which further exacerbates challenges in UAV scenarios, such as\nfrequent occlusions and extreme changes in viewing angles. To address these\nissues, we introduce a novel family of UAV trackers, termed CGTrack, which\ncombines explicit and implicit techniques to expand network capacity within a\ncoarse-to-fine framework. Specifically, we first introduce a Hierarchical\nFeature Cascade (HFC) module that leverages the spirit of feature reuse to\nincrease network capacity by integrating the deep semantic cues with the rich\nspatial information, incurring minimal computational costs while enhancing\nfeature representation. Based on this, we design a novel Lightweight Gated\nCenter Head (LGCH) that utilizes gating mechanisms to decouple target-oriented\ncoordinates from previously expanded features, which contain dense local\ndiscriminative information. Extensive experiments on three challenging UAV\ntracking benchmarks demonstrate that CGTrack achieves state-of-the-art\nperformance while running fast. Code will be available at\nhttps://github.com/Nightwatch-Fox11/CGTrack."}
{"id": "2505.06087", "pdf": "https://arxiv.org/pdf/2505.06087", "abs": "https://arxiv.org/abs/2505.06087", "authors": ["Sergio García-Heredia", "Ángela Fernández", "Carlos M. Alaíz"], "title": "Deep Diffusion Maps", "categories": ["cs.LG"], "comment": null, "summary": "One of the fundamental problems within the field of machine learning is\ndimensionality reduction. Dimensionality reduction methods make it possible to\ncombat the so-called curse of dimensionality, visualize high-dimensional data\nand, in general, improve the efficiency of storing and processing large data\nsets. One of the best-known nonlinear dimensionality reduction methods is\nDiffusion Maps. However, despite their virtues, both Diffusion Maps and many\nother manifold learning methods based on the spectral decomposition of kernel\nmatrices have drawbacks such as the inability to apply them to data outside the\ninitial set, their computational complexity, and high memory costs for large\ndata sets. In this work, we propose to alleviate these problems by resorting to\ndeep learning. Specifically, a new formulation of Diffusion Maps embedding is\noffered as a solution to a certain unconstrained minimization problem and,\nbased on it, a cost function to train a neural network which computes Diffusion\nMaps embedding -- both inside and outside the training sample -- without the\nneed to perform any spectral decomposition. The capabilities of this approach\nare compared on different data sets, both real and synthetic, with those of\nDiffusion Maps and the Nystrom method."}
{"id": "2503.17460", "pdf": "https://arxiv.org/pdf/2503.17460", "abs": "https://arxiv.org/abs/2503.17460", "authors": ["Reem Gody", "Mahmoud Goudy", "Ahmed Y. Tawfik"], "title": "ConvoGen: Enhancing Conversational AI with Synthetic Data: A Multi-Agent Approach", "categories": ["cs.CL"], "comment": null, "summary": "In this paper, we present ConvoGen: an innovative framework for generating\nsynthetic conversational data using multi-agent systems. Our method leverages\nfew-shot learning and introduces iterative sampling from a dynamically updated\nfew-shot hub to create diverse and realistic conversational scenarios. The\ngenerated data has numerous applications, including training and evaluating\nconversational AI models, and augmenting existing datasets for tasks like\nconversational intent classification or conversation summarization. Our\nexperiments demonstrate the effectiveness of this method in producing\nhigh-quality diverse synthetic conversational data, highlighting its potential\nto enhance the development and evaluation of conversational AI systems."}
{"id": "2505.06111", "pdf": "https://arxiv.org/pdf/2505.06111", "abs": "https://arxiv.org/abs/2505.06111", "authors": ["Qingwen Bu", "Yanting Yang", "Jisong Cai", "Shenyuan Gao", "Guanghui Ren", "Maoqing Yao", "Ping Luo", "Hongyang Li"], "title": "UniVLA: Learning to Act Anywhere with Task-centric Latent Actions", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Accepted to RSS 2025. Code is available at\n  https://github.com/OpenDriveLab/UniVLA", "summary": "A generalist robot should perform effectively across various environments.\nHowever, most existing approaches heavily rely on scaling action-annotated data\nto enhance their capabilities. Consequently, they are often limited to single\nphysical specification and struggle to learn transferable knowledge across\ndifferent embodiments and environments. To confront these limitations, we\npropose UniVLA, a new framework for learning cross-embodiment\nvision-language-action (VLA) policies. Our key innovation is to derive\ntask-centric action representations from videos with a latent action model.\nThis enables us to exploit extensive data across a wide spectrum of embodiments\nand perspectives. To mitigate the effect of task-irrelevant dynamics, we\nincorporate language instructions and establish a latent action model within\nthe DINO feature space. Learned from internet-scale videos, the generalist\npolicy can be deployed to various robots through efficient latent action\ndecoding. We obtain state-of-the-art results across multiple manipulation and\nnavigation benchmarks, as well as real-robot deployments. UniVLA achieves\nsuperior performance over OpenVLA with less than 1/20 of pretraining compute\nand 1/10 of downstream data. Continuous performance improvements are observed\nas heterogeneous data, even including human videos, are incorporated into the\ntraining pipeline. The results underscore UniVLA's potential to facilitate\nscalable and efficient robot policy learning."}
{"id": "2505.06002", "pdf": "https://arxiv.org/pdf/2505.06002", "abs": "https://arxiv.org/abs/2505.06002", "authors": ["Congqi Cao", "Peiheng Han", "Yueran zhang", "Yating Yu", "Qinyi Lv", "Lingtong Min", "Yanning zhang"], "title": "Task-Adapter++: Task-specific Adaptation with Order-aware Alignment for Few-shot Action Recognition", "categories": ["cs.CV"], "comment": "arXiv admin note: substantial text overlap with arXiv:2408.00249", "summary": "Large-scale pre-trained models have achieved remarkable success in language\nand image tasks, leading an increasing number of studies to explore the\napplication of pre-trained image models, such as CLIP, in the domain of\nfew-shot action recognition (FSAR). However, current methods generally suffer\nfrom several problems: 1) Direct fine-tuning often undermines the\ngeneralization capability of the pre-trained model; 2) The exploration of\ntask-specific information is insufficient in the visual tasks; 3) The semantic\norder information is typically overlooked during text modeling; 4) Existing\ncross-modal alignment techniques ignore the temporal coupling of multimodal\ninformation. To address these, we propose Task-Adapter++, a parameter-efficient\ndual adaptation method for both image and text encoders. Specifically, to make\nfull use of the variations across different few-shot learning tasks, we design\na task-specific adaptation for the image encoder so that the most\ndiscriminative information can be well noticed during feature extraction.\nFurthermore, we leverage large language models (LLMs) to generate detailed\nsequential sub-action descriptions for each action class, and introduce\nsemantic order adapters into the text encoder to effectively model the\nsequential relationships between these sub-actions. Finally, we develop an\ninnovative fine-grained cross-modal alignment strategy that actively maps\nvisual features to reside in the same temporal stage as semantic descriptions.\nExtensive experiments fully demonstrate the effectiveness and superiority of\nthe proposed method, which achieves state-of-the-art performance on 5\nbenchmarks consistently. The code is open-sourced at\nhttps://github.com/Jaulin-Bage/Task-Adapter-pp."}
{"id": "2505.06114", "pdf": "https://arxiv.org/pdf/2505.06114", "abs": "https://arxiv.org/abs/2505.06114", "authors": ["Xiwen Chen", "Wenhui Zhu", "Peijie Qiu", "Hao Wang", "Huayu Li", "Zihan Li", "Yalin Wang", "Aristeidis Sotiras", "Abolfazl Razi"], "title": "FIC-TSC: Learning Time Series Classification with Fisher Information Constraint", "categories": ["cs.LG"], "comment": "Accepted by ICML2025. Pre camera-ready version", "summary": "Analyzing time series data is crucial to a wide spectrum of applications,\nincluding economics, online marketplaces, and human healthcare. In particular,\ntime series classification plays an indispensable role in segmenting different\nphases in stock markets, predicting customer behavior, and classifying worker\nactions and engagement levels. These aspects contribute significantly to the\nadvancement of automated decision-making and system optimization in real-world\napplications. However, there is a large consensus that time series data often\nsuffers from domain shifts between training and test sets, which dramatically\ndegrades the classification performance. Despite the success of (reversible)\ninstance normalization in handling the domain shifts for time series regression\ntasks, its performance in classification is unsatisfactory. In this paper, we\npropose \\textit{FIC-TSC}, a training framework for time series classification\nthat leverages Fisher information as the constraint. We theoretically and\nempirically show this is an efficient and effective solution to guide the model\nconverge toward flatter minima, which enhances its generalizability to\ndistribution shifts. We rigorously evaluate our method on 30 UEA multivariate\nand 85 UCR univariate datasets. Our empirical results demonstrate the\nsuperiority of the proposed method over 14 recent state-of-the-art methods."}
{"id": "2504.17480", "pdf": "https://arxiv.org/pdf/2504.17480", "abs": "https://arxiv.org/abs/2504.17480", "authors": ["Xin Yi", "Yue Li", "Shunfan Zheng", "Linlin Wang", "Xiaoling Wang", "Liang He"], "title": "Unified Attacks to Large Language Model Watermarks: Spoofing and Scrubbing in Unauthorized Knowledge Distillation", "categories": ["cs.CL"], "comment": null, "summary": "Watermarking has emerged as a critical technique for combating misinformation\nand protecting intellectual property in large language models (LLMs). A recent\ndiscovery, termed watermark radioactivity, reveals that watermarks embedded in\nteacher models can be inherited by student models through knowledge\ndistillation. On the positive side, this inheritance allows for the detection\nof unauthorized knowledge distillation by identifying watermark traces in\nstudent models. However, the robustness of watermarks against scrubbing attacks\nand their unforgeability in the face of spoofing attacks under unauthorized\nknowledge distillation remain largely unexplored. Existing watermark attack\nmethods either assume access to model internals or fail to simultaneously\nsupport both scrubbing and spoofing attacks. In this work, we propose\nContrastive Decoding-Guided Knowledge Distillation (CDG-KD), a unified\nframework that enables bidirectional attacks under unauthorized knowledge\ndistillation. Our approach employs contrastive decoding to extract corrupted or\namplified watermark texts via comparing outputs from the student model and\nweakly watermarked references, followed by bidirectional distillation to train\nnew student models capable of watermark removal and watermark forgery,\nrespectively. Extensive experiments show that CDG-KD effectively performs\nattacks while preserving the general performance of the distilled model. Our\nfindings underscore critical need for developing watermarking schemes that are\nrobust and unforgeable."}
{"id": "2505.06123", "pdf": "https://arxiv.org/pdf/2505.06123", "abs": "https://arxiv.org/abs/2505.06123", "authors": ["Philip Naumann", "Jacob Kauffmann", "Grégoire Montavon"], "title": "Wasserstein Distances Made Explainable: Insights into Dataset Shifts and Transport Phenomena", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Wasserstein distances provide a powerful framework for comparing data\ndistributions. They can be used to analyze processes over time or to detect\ninhomogeneities within data. However, simply calculating the Wasserstein\ndistance or analyzing the corresponding transport map (or coupling) may not be\nsufficient for understanding what factors contribute to a high or low\nWasserstein distance. In this work, we propose a novel solution based on\nExplainable AI that allows us to efficiently and accurately attribute\nWasserstein distances to various data components, including data subgroups,\ninput features, or interpretable subspaces. Our method achieves high accuracy\nacross diverse datasets and Wasserstein distance specifications, and its\npractical utility is demonstrated in two use cases."}
{"id": "2505.06003", "pdf": "https://arxiv.org/pdf/2505.06003", "abs": "https://arxiv.org/abs/2505.06003", "authors": ["Moritz Vandenhirtz", "Julia E. Vogt"], "title": "From Pixels to Perception: Interpretable Predictions via Instance-wise Grouped Feature Selection", "categories": ["cs.CV", "cs.LG"], "comment": "International Conference on Machine Learning", "summary": "Understanding the decision-making process of machine learning models provides\nvaluable insights into the task, the data, and the reasons behind a model's\nfailures. In this work, we propose a method that performs inherently\ninterpretable predictions through the instance-wise sparsification of input\nimages. To align the sparsification with human perception, we learn the masking\nin the space of semantically meaningful pixel regions rather than on\npixel-level. Additionally, we introduce an explicit way to dynamically\ndetermine the required level of sparsity for each instance. We show empirically\non semi-synthetic and natural image datasets that our inherently interpretable\nclassifier produces more meaningful, human-understandable predictions than\nstate-of-the-art benchmarks."}
{"id": "2505.06134", "pdf": "https://arxiv.org/pdf/2505.06134", "abs": "https://arxiv.org/abs/2505.06134", "authors": ["Julian F. Schumann", "Jeroen Hagenus", "Frederik Baymler Mathiesen", "Arkady Zgonnikov"], "title": "Realistic Adversarial Attacks for Robustness Evaluation of Trajectory Prediction Models via Future State Perturbation", "categories": ["cs.LG", "cs.HC"], "comment": "20 pages, 3 figures", "summary": "Trajectory prediction is a key element of autonomous vehicle systems,\nenabling them to anticipate and react to the movements of other road users.\nEvaluating the robustness of prediction models against adversarial attacks is\nessential to ensure their reliability in real-world traffic. However, current\napproaches tend to focus on perturbing the past positions of surrounding\nagents, which can generate unrealistic scenarios and overlook critical\nvulnerabilities. This limitation may result in overly optimistic assessments of\nmodel performance in real-world conditions.\n  In this work, we demonstrate that perturbing not just past but also future\nstates of adversarial agents can uncover previously undetected weaknesses and\nthereby provide a more rigorous evaluation of model robustness. Our novel\napproach incorporates dynamic constraints and preserves tactical behaviors,\nenabling more effective and realistic adversarial attacks. We introduce new\nperformance measures to assess the realism and impact of these adversarial\ntrajectories. Testing our method on a state-of-the-art prediction model\nrevealed significant increases in prediction errors and collision rates under\nadversarial conditions. Qualitative analysis further showed that our attacks\ncan expose critical weaknesses, such as the inability of the model to detect\npotential collisions in what appear to be safe predictions. These results\nunderscore the need for more comprehensive adversarial testing to better\nevaluate and improve the reliability of trajectory prediction models for\nautonomous vehicles."}
{"id": "2504.21463", "pdf": "https://arxiv.org/pdf/2504.21463", "abs": "https://arxiv.org/abs/2504.21463", "authors": ["Haowen Hou", "Zhiyi Huang", "Kaifeng Tan", "Rongchang Lu", "Fei Richard Yu"], "title": "RWKV-X: A Linear Complexity Hybrid Language Model", "categories": ["cs.CL"], "comment": "12 pages, typos corrected", "summary": "In this paper, we introduce RWKV-X, a novel hybrid architecture that combines\nthe efficiency of RWKV for short-range modeling with a sparse attention\nmechanism designed to capture long-range context. Unlike previous hybrid\napproaches that rely on full attention layers and retain quadratic complexity,\nRWKV-X achieves linear-time complexity in training and constant-time complexity\nin inference decoding. We demonstrate that RWKV-X, when continually pretrained\non 64K-token sequences, achieves near-perfect accuracy on the 64K passkey\nretrieval benchmark. It consistently outperforms prior RWKV-7 models on\nlong-context benchmarks, while maintaining strong performance on short-context\ntasks. These results highlight RWKV-X as a scalable and efficient backbone for\ngeneral-purpose language modeling, capable of decoding sequences up to 1\nmillion tokens with stable speed and memory usage. To facilitate further\nresearch and analysis, we have made the checkpoints and the associated code\npublicly accessible at: https://github.com/howard-hou/RWKV-X."}
{"id": "2505.06136", "pdf": "https://arxiv.org/pdf/2505.06136", "abs": "https://arxiv.org/abs/2505.06136", "authors": ["Yifeng Zhu"], "title": "Efficient Sensorimotor Learning for Open-world Robot Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": "Ph.D. Dissertation", "summary": "This dissertation considers Open-world Robot Manipulation, a manipulation\nproblem where a robot must generalize or quickly adapt to new objects, scenes,\nor tasks for which it has not been pre-programmed or pre-trained. This\ndissertation tackles the problem using a methodology of efficient sensorimotor\nlearning. The key to enabling efficient sensorimotor learning lies in\nleveraging regular patterns that exist in limited amounts of demonstration\ndata. These patterns, referred to as ``regularity,'' enable the data-efficient\nlearning of generalizable manipulation skills. This dissertation offers a new\nperspective on formulating manipulation problems through the lens of\nregularity. Building upon this notion, we introduce three major contributions.\nFirst, we introduce methods that endow robots with object-centric priors,\nallowing them to learn generalizable, closed-loop sensorimotor policies from a\nsmall number of teleoperation demonstrations. Second, we introduce methods that\nconstitute robots' spatial understanding, unlocking their ability to imitate\nmanipulation skills from in-the-wild video observations. Last but not least, we\nintroduce methods that enable robots to identify reusable skills from their\npast experiences, resulting in systems that can continually imitate multiple\ntasks in a sequential manner. Altogether, the contributions of this\ndissertation help lay the groundwork for building general-purpose personal\nrobots that can quickly adapt to new situations or tasks with low-cost data\ncollection and interact easily with humans. By enabling robots to learn and\ngeneralize from limited data, this dissertation takes a step toward realizing\nthe vision of intelligent robotic assistants that can be seamlessly integrated\ninto everyday scenarios."}
{"id": "2505.06038", "pdf": "https://arxiv.org/pdf/2505.06038", "abs": "https://arxiv.org/abs/2505.06038", "authors": ["Heng Li", "Xiangping Wu", "Qingcai Chen"], "title": "Document Image Rectification Bases on Self-Adaptive Multitask Fusion", "categories": ["cs.CV"], "comment": null, "summary": "Deformed document image rectification is essential for real-world document\nunderstanding tasks, such as layout analysis and text recognition. However,\ncurrent multi-task methods -- such as background removal, 3D coordinate\nprediction, and text line segmentation -- often overlook the complementary\nfeatures between tasks and their interactions. To address this gap, we propose\na self-adaptive learnable multi-task fusion rectification network named\nSalmRec. This network incorporates an inter-task feature aggregation module\nthat adaptively improves the perception of geometric distortions, enhances\nfeature complementarity, and reduces negative interference. We also introduce a\ngating mechanism to balance features both within global tasks and between local\ntasks effectively. Experimental results on two English benchmarks (DIR300 and\nDocUNet) and one Chinese benchmark (DocReal) demonstrate that our method\nsignificantly improves rectification performance. Ablation studies further\nhighlight the positive impact of different tasks on dewarping and the\neffectiveness of our proposed module."}
{"id": "2505.06169", "pdf": "https://arxiv.org/pdf/2505.06169", "abs": "https://arxiv.org/abs/2505.06169", "authors": ["Egor Bakaev", "Florestan Brunck", "Christoph Hertrich", "Daniel Reichman", "Amir Yehudayoff"], "title": "On the Depth of Monotone ReLU Neural Networks and ICNNs", "categories": ["cs.LG", "cs.DM", "cs.NE", "math.CO"], "comment": "27 pages, 17 figures", "summary": "We study two models of ReLU neural networks: monotone networks (ReLU$^+$) and\ninput convex neural networks (ICNN). Our focus is on expressivity, mostly in\nterms of depth, and we prove the following lower bounds. For the maximum\nfunction MAX$_n$ computing the maximum of $n$ real numbers, we show that\nReLU$^+$ networks cannot compute MAX$_n$, or even approximate it. We prove a\nsharp $n$ lower bound on the ICNN depth complexity of MAX$_n$. We also prove\ndepth separations between ReLU networks and ICNNs; for every $k$, there is a\ndepth-2 ReLU network of size $O(k^2)$ that cannot be simulated by a depth-$k$\nICNN. The proofs are based on deep connections between neural networks and\npolyhedral geometry, and also use isoperimetric properties of triangulations."}
{"id": "2505.00679", "pdf": "https://arxiv.org/pdf/2505.00679", "abs": "https://arxiv.org/abs/2505.00679", "authors": ["Xinchen Yang", "Marine Carpuat"], "title": "Steering Large Language Models with Register Analysis for Arbitrary Style Transfer", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong capabilities in\nrewriting text across various styles. However, effectively leveraging this\nability for example-based arbitrary style transfer, where an input text is\nrewritten to match the style of a given exemplar, remains an open challenge. A\nkey question is how to describe the style of the exemplar to guide LLMs toward\nhigh-quality rewrites. In this work, we propose a prompting method based on\nregister analysis to guide LLMs to perform this task. Empirical evaluations\nacross multiple style transfer tasks show that our prompting approach enhances\nstyle transfer strength while preserving meaning more effectively than existing\nprompting strategies."}
{"id": "2505.06152", "pdf": "https://arxiv.org/pdf/2505.06152", "abs": "https://arxiv.org/abs/2505.06152", "authors": ["Wenqi Zeng", "Yuqi Sun", "Chenxi Ma", "Weimin Tan", "Bo Yan"], "title": "MM-Skin: Enhancing Dermatology Vision-Language Model with an Image-Text Dataset Derived from Textbooks", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Medical vision-language models (VLMs) have shown promise as clinical\nassistants across various medical fields. However, specialized dermatology VLM\ncapable of delivering professional and detailed diagnostic analysis remains\nunderdeveloped, primarily due to less specialized text descriptions in current\ndermatology multimodal datasets. To address this issue, we propose MM-Skin, the\nfirst large-scale multimodal dermatology dataset that encompasses 3 imaging\nmodalities, including clinical, dermoscopic, and pathological and nearly 10k\nhigh-quality image-text pairs collected from professional textbooks. In\naddition, we generate over 27k diverse, instruction-following vision question\nanswering (VQA) samples (9 times the size of current largest dermatology VQA\ndataset). Leveraging public datasets and MM-Skin, we developed SkinVL, a\ndermatology-specific VLM designed for precise and nuanced skin disease\ninterpretation. Comprehensive benchmark evaluations of SkinVL on VQA,\nsupervised fine-tuning (SFT) and zero-shot classification tasks across 8\ndatasets, reveal its exceptional performance for skin diseases in comparison to\nboth general and medical VLM models. The introduction of MM-Skin and SkinVL\noffers a meaningful contribution to advancing the development of clinical\ndermatology VLM assistants. MM-Skin is available at\nhttps://github.com/ZwQ803/MM-Skin"}
{"id": "2505.06055", "pdf": "https://arxiv.org/pdf/2505.06055", "abs": "https://arxiv.org/abs/2505.06055", "authors": ["Dongqian Guo", "Wencheng Han", "Pang Lyu", "Yuxi Zhou", "Jianbing Shen"], "title": "Towards Better Cephalometric Landmark Detection with Diffusion Data Generation", "categories": ["cs.CV"], "comment": null, "summary": "Cephalometric landmark detection is essential for orthodontic diagnostics and\ntreatment planning. Nevertheless, the scarcity of samples in data collection\nand the extensive effort required for manual annotation have significantly\nimpeded the availability of diverse datasets. This limitation has restricted\nthe effectiveness of deep learning-based detection methods, particularly those\nbased on large-scale vision models. To address these challenges, we have\ndeveloped an innovative data generation method capable of producing diverse\ncephalometric X-ray images along with corresponding annotations without human\nintervention. To achieve this, our approach initiates by constructing new\ncephalometric landmark annotations using anatomical priors. Then, we employ a\ndiffusion-based generator to create realistic X-ray images that correspond\nclosely with these annotations. To achieve precise control in producing samples\nwith different attributes, we introduce a novel prompt cephalometric X-ray\nimage dataset. This dataset includes real cephalometric X-ray images and\ndetailed medical text prompts describing the images. By leveraging these\ndetailed prompts, our method improves the generation process to control\ndifferent styles and attributes. Facilitated by the large, diverse generated\ndata, we introduce large-scale vision detection models into the cephalometric\nlandmark detection task to improve accuracy. Experimental results demonstrate\nthat training with the generated data substantially enhances the performance.\nCompared to methods without using the generated data, our approach improves the\nSuccess Detection Rate (SDR) by 6.5%, attaining a notable 82.2%. All code and\ndata are available at: https://um-lab.github.io/cepha-generation"}
{"id": "2505.06178", "pdf": "https://arxiv.org/pdf/2505.06178", "abs": "https://arxiv.org/abs/2505.06178", "authors": ["Linjiang Cao", "Maonan Wang", "Xi Xiong"], "title": "A Large Language Model-Enhanced Q-learning for Capacitated Vehicle Routing Problem with Time Windows", "categories": ["cs.LG"], "comment": null, "summary": "The Capacitated Vehicle Routing Problem with Time Windows (CVRPTW) is a\nclassic NP-hard combinatorial optimization problem widely applied in logistics\ndistribution and transportation management. Its complexity stems from the\nconstraints of vehicle capacity and time windows, which pose significant\nchallenges to traditional approaches. Advances in Large Language Models (LLMs)\nprovide new possibilities for finding approximate solutions to CVRPTW. This\npaper proposes a novel LLM-enhanced Q-learning framework to address the CVRPTW\nwith real-time emergency constraints. Our solution introduces an adaptive\ntwo-phase training mechanism that transitions from the LLM-guided exploration\nphase to the autonomous optimization phase of Q-network. To ensure reliability,\nwe design a three-tier self-correction mechanism based on the Chain-of-Thought\n(CoT) for LLMs: syntactic validation, semantic verification, and physical\nconstraint enforcement. In addition, we also prioritized replay of the\nexperience generated by LLMs to amplify the regulatory role of LLMs in the\narchitecture. Experimental results demonstrate that our framework achieves a\n7.3\\% average reduction in cost compared to traditional Q-learning, with fewer\ntraining steps required for convergence."}
{"id": "2505.02410", "pdf": "https://arxiv.org/pdf/2505.02410", "abs": "https://arxiv.org/abs/2505.02410", "authors": ["Krzysztof Ociepa", "Łukasz Flis", "Krzysztof Wróbel", "Adrian Gwoździej", "Remigiusz Kinas"], "title": "Bielik 11B v2 Technical Report", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "comment": null, "summary": "We present Bielik 11B v2, a state-of-the-art language model optimized for\nPolish text processing. Built on the Mistral 7B v0.2 architecture and scaled to\n11B parameters using depth up-scaling, this model demonstrates exceptional\nperformance across Polish language benchmarks while maintaining strong\ncross-lingual capabilities. We introduce two key technical innovations:\nWeighted Instruction Cross-Entropy Loss, which optimizes learning across\ndiverse instruction types by assigning quality-based weights to training\nexamples, and Adaptive Learning Rate, which dynamically adjusts based on\ncontext length. Comprehensive evaluation across multiple benchmarks\ndemonstrates that Bielik 11B v2 outperforms many larger models, including those\nwith 2-6 times more parameters, and significantly surpasses other specialized\nPolish language models on tasks ranging from linguistic understanding to\ncomplex reasoning. The model's parameter efficiency and extensive quantization\noptions enable deployment across various hardware configurations, advancing\nPolish language AI capabilities and establishing new benchmarks for\nresource-efficient language modeling in less-represented languages."}
{"id": "2505.06175", "pdf": "https://arxiv.org/pdf/2505.06175", "abs": "https://arxiv.org/abs/2505.06175", "authors": ["Zihang Song", "Matteo Zecchin", "Bipin Rajendran", "Osvaldo Simeone"], "title": "Turbo-ICL: In-Context Learning-Based Turbo Equalization", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "This paper introduces a novel in-context learning (ICL) framework, inspired\nby large language models (LLMs), for soft-input soft-output channel\nequalization in coded multiple-input multiple-output (MIMO) systems. The\nproposed approach learns to infer posterior symbol distributions directly from\na prompt of pilot signals and decoder feedback. A key innovation is the use of\nprompt augmentation to incorporate extrinsic information from the decoder\noutput as additional context, enabling the ICL model to refine its symbol\nestimates iteratively across turbo decoding iterations. Two model variants,\nbased on Transformer and state-space architectures, are developed and\nevaluated. Extensive simulations demonstrate that, when traditional linear\nassumptions break down, e.g., in the presence of low-resolution quantization,\nICL equalizers consistently outperform conventional model-based baselines, even\nwhen the latter are provided with perfect channel state information. Results\nalso highlight the advantage of Transformer-based models under limited training\ndiversity, as well as the efficiency of state-space models in\nresource-constrained scenarios."}
{"id": "2505.06068", "pdf": "https://arxiv.org/pdf/2505.06068", "abs": "https://arxiv.org/abs/2505.06068", "authors": ["Kunpeng Qiu", "Zhiqiang Gao", "Zhiying Zhou", "Mingjie Sun", "Yongxin Guo"], "title": "Noise-Consistent Siamese-Diffusion for Medical Image Synthesis and Segmentation", "categories": ["cs.CV"], "comment": "Accepted by CVPR2025", "summary": "Deep learning has revolutionized medical image segmentation, yet its full\npotential remains constrained by the paucity of annotated datasets. While\ndiffusion models have emerged as a promising approach for generating synthetic\nimage-mask pairs to augment these datasets, they paradoxically suffer from the\nsame data scarcity challenges they aim to mitigate. Traditional mask-only\nmodels frequently yield low-fidelity images due to their inability to\nadequately capture morphological intricacies, which can critically compromise\nthe robustness and reliability of segmentation models. To alleviate this\nlimitation, we introduce Siamese-Diffusion, a novel dual-component model\ncomprising Mask-Diffusion and Image-Diffusion. During training, a Noise\nConsistency Loss is introduced between these components to enhance the\nmorphological fidelity of Mask-Diffusion in the parameter space. During\nsampling, only Mask-Diffusion is used, ensuring diversity and scalability.\nComprehensive experiments demonstrate the superiority of our method.\nSiamese-Diffusion boosts SANet's mDice and mIoU by 3.6% and 4.4% on the Polyps,\nwhile UNet improves by 1.52% and 1.64% on the ISIC2018. Code is available at\nGitHub."}
{"id": "2505.06185", "pdf": "https://arxiv.org/pdf/2505.06185", "abs": "https://arxiv.org/abs/2505.06185", "authors": ["Kodai Hirata", "Tsuyoshi Okita"], "title": "Brain Hematoma Marker Recognition Using Multitask Learning: SwinTransformer and Swin-Unet", "categories": ["cs.LG", "cs.CV"], "comment": "8 pages,4 figures", "summary": "This paper proposes a method MTL-Swin-Unet which is multi-task learning using\ntransformers for classification and semantic segmentation. For\nspurious-correlation problems, this method allows us to enhance the image\nrepresentation with two other image representations: representation obtained by\nsemantic segmentation and representation obtained by image reconstruction. In\nour experiments, the proposed method outperformed in F-value measure than other\nclassifiers when the test data included slices from the same patient (no\ncovariate shift). Similarly, when the test data did not include slices from the\nsame patient (covariate shift setting), the proposed method outperformed in AUC\nmeasure."}
{"id": "2505.02819", "pdf": "https://arxiv.org/pdf/2505.02819", "abs": "https://arxiv.org/abs/2505.02819", "authors": ["Dmitriy Shopkhoev", "Ammar Ali", "Magauiya Zhussip", "Valentin Malykh", "Stamatios Lefkimmiatis", "Nikos Komodakis", "Sergey Zagoruyko"], "title": "ReplaceMe: Network Simplification via Layer Pruning and Linear Transformations", "categories": ["cs.CL"], "comment": null, "summary": "We introduce ReplaceMe, a generalized training-free depth pruning method that\neffectively replaces transformer blocks with a linear operation, while\nmaintaining high performance for low compression ratios. In contrast to\nconventional pruning approaches that require additional training or\nfine-tuning, our approach requires only a small calibration dataset that is\nused to estimate a linear transformation to approximate the pruned blocks. This\nestimated linear mapping can be seamlessly merged with the remaining\ntransformer blocks, eliminating the need for any additional network parameters.\nOur experiments show that ReplaceMe consistently outperforms other\ntraining-free approaches and remains highly competitive with state-of-the-art\npruning methods that involve extensive retraining/fine-tuning and architectural\nmodifications. Applied to several large language models (LLMs), ReplaceMe\nachieves up to 25% pruning while retaining approximately 90% of the original\nmodel's performance on open benchmarks - without any training or healing steps,\nresulting in minimal computational overhead (see Fig.1). We provide an\nopen-source library implementing ReplaceMe alongside several state-of-the-art\ndepth pruning techniques, available at this repository."}
{"id": "2505.06218", "pdf": "https://arxiv.org/pdf/2505.06218", "abs": "https://arxiv.org/abs/2505.06218", "authors": ["Kwan-Yee Lin", "Stella X. Yu"], "title": "Let Humanoids Hike! Integrative Skill Development on Complex Trails", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "CVPR 2025. Project page:\n  https://lego-h-humanoidrobothiking.github.io/", "summary": "Hiking on complex trails demands balance, agility, and adaptive\ndecision-making over unpredictable terrain. Current humanoid research remains\nfragmented and inadequate for hiking: locomotion focuses on motor skills\nwithout long-term goals or situational awareness, while semantic navigation\noverlooks real-world embodiment and local terrain variability. We propose\ntraining humanoids to hike on complex trails, driving integrative skill\ndevelopment across visual perception, decision making, and motor execution. We\ndevelop a learning framework, LEGO-H, that enables a vision-equipped humanoid\nrobot to hike complex trails autonomously. We introduce two technical\ninnovations: 1) A temporal vision transformer variant - tailored into\nHierarchical Reinforcement Learning framework - anticipates future local goals\nto guide movement, seamlessly integrating locomotion with goal-directed\nnavigation. 2) Latent representations of joint movement patterns, combined with\nhierarchical metric learning - enhance Privileged Learning scheme - enable\nsmooth policy transfer from privileged training to onboard execution. These\ncomponents allow LEGO-H to handle diverse physical and environmental challenges\nwithout relying on predefined motion patterns. Experiments across varied\nsimulated trails and robot morphologies highlight LEGO-H's versatility and\nrobustness, positioning hiking as a compelling testbed for embodied autonomy\nand LEGO-H as a baseline for future humanoid development."}
{"id": "2505.06113", "pdf": "https://arxiv.org/pdf/2505.06113", "abs": "https://arxiv.org/abs/2505.06113", "authors": ["Anupkumar Bochare"], "title": "Camera-Only Bird's Eye View Perception: A Neural Approach to LiDAR-Free Environmental Mapping for Autonomous Vehicles", "categories": ["cs.CV"], "comment": null, "summary": "Autonomous vehicle perception systems have traditionally relied on costly\nLiDAR sensors to generate precise environmental representations. In this paper,\nwe propose a camera-only perception framework that produces Bird's Eye View\n(BEV) maps by extending the Lift-Splat-Shoot architecture. Our method combines\nYOLOv11-based object detection with DepthAnythingV2 monocular depth estimation\nacross multi-camera inputs to achieve comprehensive 360-degree scene\nunderstanding. We evaluate our approach on the OpenLane-V2 and NuScenes\ndatasets, achieving up to 85% road segmentation accuracy and 85-90% vehicle\ndetection rates when compared against LiDAR ground truth, with average\npositional errors limited to 1.2 meters. These results highlight the potential\nof deep learning to extract rich spatial information using only camera inputs,\nenabling cost-efficient autonomous navigation without sacrificing accuracy."}
{"id": "2505.06203", "pdf": "https://arxiv.org/pdf/2505.06203", "abs": "https://arxiv.org/abs/2505.06203", "authors": ["Hiroki Hasegawa", "Yukihiko Okada"], "title": "Auto Tensor Singular Value Thresholding: A Non-Iterative and Rank-Free Framework for Tensor Denoising", "categories": ["cs.LG"], "comment": "16 pages, 4 figures", "summary": "In modern data-driven tasks such as classification, optimization, and\nforecasting, mitigating the effects of intrinsic noise is crucial for improving\npredictive accuracy. While numerous denoising techniques have been developed,\nthe rising dimensionality of real-world datasets limits conventional\nmatrix-based methods in preserving data structure and accuracy. This challenge\nhas led to increasing interest in tensor-based approaches, which naturally\ncapture multi-way data relationships. However, classical tensor decomposition\nmethods (e.g., HOSVD, HOOI) typically require pre-specified ranks and iterative\noptimization, making them computationally expensive and less practical. In this\nwork, we propose a novel low-rank approximation method for tensor data that\navoids these limitations. Our approach applies statistically grounded singular\nvalue thresholding to mode-wise matricizations, enabling automatic extraction\nof significant components without requiring prior rank specification or\niterative refinement. Experiments on synthetic and real-world tensors show that\nour method consistently outperforms existing techniques in terms of estimation\naccuracy and computational efficiency, especially in noisy high-dimensional\nsettings."}
{"id": "2505.02847", "pdf": "https://arxiv.org/pdf/2505.02847", "abs": "https://arxiv.org/abs/2505.02847", "authors": ["Bang Zhang", "Ruotian Ma", "Qingxuan Jiang", "Peisong Wang", "Jiaqi Chen", "Zheng Xie", "Xingyu Chen", "Yue Wang", "Fanghua Ye", "Jian Li", "Yifan Yang", "Zhaopeng Tu", "Xiaolong Li"], "title": "Sentient Agent as a Judge: Evaluating Higher-Order Social Cognition in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "code: https://github.com/Tencent/digitalhuman/tree/main/SAGE", "summary": "Assessing how well a large language model (LLM) understands human, rather\nthan merely text, remains an open challenge. To bridge the gap, we introduce\nSentient Agent as a Judge (SAGE), an automated evaluation framework that\nmeasures an LLM's higher-order social cognition. SAGE instantiates a Sentient\nAgent that simulates human-like emotional changes and inner thoughts during\ninteraction, providing a more realistic evaluation of the tested model in\nmulti-turn conversations. At every turn, the agent reasons about (i) how its\nemotion changes, (ii) how it feels, and (iii) how it should reply, yielding a\nnumerical emotion trajectory and interpretable inner thoughts. Experiments on\n100 supportive-dialogue scenarios show that the final Sentient emotion score\ncorrelates strongly with Barrett-Lennard Relationship Inventory (BLRI) ratings\nand utterance-level empathy metrics, validating psychological fidelity. We also\nbuild a public Sentient Leaderboard covering 18 commercial and open-source\nmodels that uncovers substantial gaps (up to 4x) between frontier systems\n(GPT-4o-Latest, Gemini2.5-Pro) and earlier baselines, gaps not reflected in\nconventional leaderboards (e.g., Arena). SAGE thus provides a principled,\nscalable and interpretable tool for tracking progress toward genuinely\nempathetic and socially adept language agents."}
{"id": "2301.04709", "pdf": "https://arxiv.org/pdf/2301.04709", "abs": "https://arxiv.org/abs/2301.04709", "authors": ["Atticus Geiger", "Duligur Ibeling", "Amir Zur", "Maheep Chaudhary", "Sonakshi Chauhan", "Jing Huang", "Aryaman Arora", "Zhengxuan Wu", "Noah Goodman", "Christopher Potts", "Thomas Icard"], "title": "Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability", "categories": ["cs.AI"], "comment": null, "summary": "Causal abstraction provides a theoretical foundation for mechanistic\ninterpretability, the field concerned with providing intelligible algorithms\nthat are faithful simplifications of the known, but opaque low-level details of\nblack box AI models. Our contributions are (1) generalizing the theory of\ncausal abstraction from mechanism replacement (i.e., hard and soft\ninterventions) to arbitrary mechanism transformation (i.e., functionals from\nold mechanisms to new mechanisms), (2) providing a flexible, yet precise\nformalization for the core concepts of polysemantic neurons, the linear\nrepresentation hypothesis, modular features, and graded faithfulness, and (3)\nunifying a variety of mechanistic interpretability methods in the common\nlanguage of causal abstraction, namely, activation and path patching, causal\nmediation analysis, causal scrubbing, causal tracing, circuit analysis, concept\nerasure, sparse autoencoders, differential binary masking, distributed\nalignment search, and steering."}
{"id": "2505.06117", "pdf": "https://arxiv.org/pdf/2505.06117", "abs": "https://arxiv.org/abs/2505.06117", "authors": ["Dongying Li", "Binyi Su", "Hua Zhang", "Yong Li", "Haiyong Chen"], "title": "Photovoltaic Defect Image Generator with Boundary Alignment Smoothing Constraint for Domain Shift Mitigation", "categories": ["cs.CV"], "comment": null, "summary": "Accurate defect detection of photovoltaic (PV) cells is critical for ensuring\nquality and efficiency in intelligent PV manufacturing systems. However, the\nscarcity of rich defect data poses substantial challenges for effective model\ntraining. While existing methods have explored generative models to augment\ndatasets, they often suffer from instability, limited diversity, and domain\nshifts. To address these issues, we propose PDIG, a Photovoltaic Defect Image\nGenerator based on Stable Diffusion (SD). PDIG leverages the strong priors\nlearned from large-scale datasets to enhance generation quality under limited\ndata. Specifically, we introduce a Semantic Concept Embedding (SCE) module that\nincorporates text-conditioned priors to capture the relational concepts between\ndefect types and their appearances. To further enrich the domain distribution,\nwe design a Lightweight Industrial Style Adaptor (LISA), which injects\nindustrial defect characteristics into the SD model through cross-disentangled\nattention. At inference, we propose a Text-Image Dual-Space Constraints (TIDSC)\nmodule, enforcing the quality of generated images via positional consistency\nand spatial smoothing alignment. Extensive experiments demonstrate that PDIG\nachieves superior realism and diversity compared to state-of-the-art methods.\nSpecifically, our approach improves Frechet Inception Distance (FID) by 19.16\npoints over the second-best method and significantly enhances the performance\nof downstream defect detection tasks."}
{"id": "2505.06224", "pdf": "https://arxiv.org/pdf/2505.06224", "abs": "https://arxiv.org/abs/2505.06224", "authors": ["Christos Plachouras", "Julien Guinot", "George Fazekas", "Elio Quinton", "Emmanouil Benetos", "Johan Pauwels"], "title": "Towards a Unified Representation Evaluation Framework Beyond Downstream Tasks", "categories": ["cs.LG"], "comment": "Accepted at IJCNN 2025", "summary": "Downstream probing has been the dominant method for evaluating model\nrepresentations, an important process given the increasing prominence of\nself-supervised learning and foundation models. However, downstream probing\nprimarily assesses the availability of task-relevant information in the model's\nlatent space, overlooking attributes such as equivariance, invariance, and\ndisentanglement, which contribute to the interpretability, adaptability, and\nutility of representations in real-world applications. While some attempts have\nbeen made to measure these qualities in representations, no unified evaluation\nframework with modular, generalizable, and interpretable metrics exists.\n  In this paper, we argue for the importance of representation evaluation\nbeyond downstream probing. We introduce a standardized protocol to quantify\ninformativeness, equivariance, invariance, and disentanglement of factors of\nvariation in model representations. We use it to evaluate representations from\na variety of models in the image and speech domains using different\narchitectures and pretraining approaches on identified controllable factors of\nvariation. We find that representations from models with similar downstream\nperformance can behave substantially differently with regard to these\nattributes. This hints that the respective mechanisms underlying their\ndownstream performance are functionally different, prompting new research\ndirections to understand and improve representations."}
{"id": "2505.05026", "pdf": "https://arxiv.org/pdf/2505.05026", "abs": "https://arxiv.org/abs/2505.05026", "authors": ["Jaehyun Jeon", "Jang Han Yoon", "Min Soo Kim", "Sumin Shim", "Yejin Choi", "Hanbin Kim", "Youngjae Yu"], "title": "G-FOCUS: Towards a Robust Method for Assessing UI Design Persuasiveness", "categories": ["cs.CL", "cs.LG"], "comment": "31 pages, 17 figures", "summary": "Evaluating user interface (UI) design effectiveness extends beyond aesthetics\nto influencing user behavior, a principle central to Design Persuasiveness. A/B\ntesting is the predominant method for determining which UI variations drive\nhigher user engagement, but it is costly and time-consuming. While recent\nVision-Language Models (VLMs) can process automated UI analysis, current\napproaches focus on isolated design attributes rather than comparative\npersuasiveness-the key factor in optimizing user interactions. To address this,\nwe introduce WiserUI-Bench, a benchmark designed for Pairwise UI Design\nPersuasiveness Assessment task, featuring 300 real-world UI image pairs labeled\nwith A/B test results and expert rationales. Additionally, we propose G-FOCUS,\na novel inference-time reasoning strategy that enhances VLM-based\npersuasiveness assessment by reducing position bias and improving evaluation\naccuracy. Experimental results show that G-FOCUS surpasses existing inference\nstrategies in consistency and accuracy for pairwise UI evaluation. Through\npromoting VLM-driven evaluation of UI persuasiveness, our work offers an\napproach to complement A/B testing, propelling progress in scalable UI\npreference modeling and design optimization. Code and data will be released\npublicly."}
{"id": "2504.04430", "pdf": "https://arxiv.org/pdf/2504.04430", "abs": "https://arxiv.org/abs/2504.04430", "authors": ["Matej Šprogar"], "title": "AGITB: A Signal-Level Benchmark for Evaluating Artificial General Intelligence", "categories": ["cs.AI"], "comment": "13 pages", "summary": "Despite remarkable progress in machine learning, current AI systems continue\nto fall short of true human-like intelligence. While Large Language Models\n(LLMs) excel in pattern recognition and response generation, they lack genuine\nunderstanding - an essential hallmark of Artificial General Intelligence (AGI).\nExisting AGI evaluation methods fail to offer a practical, gradual, and\ninformative metric. This paper introduces the Artificial General Intelligence\nTest Bed (AGITB), comprising twelve rigorous tests that form a\nsignal-processing-level foundation for the potential emergence of cognitive\ncapabilities. AGITB evaluates intelligence through a model's ability to predict\nbinary signals across time without relying on symbolic representations or\npretraining. Unlike high-level tests grounded in language or perception, AGITB\nfocuses on core computational invariants reflective of biological intelligence,\nsuch as determinism, sensitivity, and generalisation. The test bed assumes no\nprior bias, operates independently of semantic meaning, and ensures\nunsolvability through brute force or memorization. While humans pass AGITB by\ndesign, no current AI system has met its criteria, making AGITB a compelling\nbenchmark for guiding and recognizing progress toward AGI."}
{"id": "2505.06133", "pdf": "https://arxiv.org/pdf/2505.06133", "abs": "https://arxiv.org/abs/2505.06133", "authors": ["Hongming Wang", "Yifeng Wu", "Huimin Huang", "Hongtao Wu", "Jia-Xuan Jiang", "Xiaodong Zhang", "Hao Zheng", "Xian Wu", "Yefeng Zheng", "Jinping Xu", "Jing Cheng"], "title": "BrainSegDMlF: A Dynamic Fusion-enhanced SAM for Brain Lesion Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "The segmentation of substantial brain lesions is a significant and\nchallenging task in the field of medical image segmentation. Substantial brain\nlesions in brain imaging exhibit high heterogeneity, with indistinct boundaries\nbetween lesion regions and normal brain tissue. Small lesions in single slices\nare difficult to identify, making the accurate and reproducible segmentation of\nabnormal regions, as well as their feature description, highly complex.\nExisting methods have the following limitations: 1) They rely solely on\nsingle-modal information for learning, neglecting the multi-modal information\ncommonly used in diagnosis. This hampers the ability to comprehensively acquire\nbrain lesion information from multiple perspectives and prevents the effective\nintegration and utilization of multi-modal data inputs, thereby limiting a\nholistic understanding of lesions. 2) They are constrained by the amount of\ndata available, leading to low sensitivity to small lesions and difficulty in\ndetecting subtle pathological changes. 3) Current SAM-based models rely on\nexternal prompts, which cannot achieve automatic segmentation and, to some\nextent, affect diagnostic efficiency.To address these issues, we have developed\na large-scale fully automated segmentation model specifically designed for\nbrain lesion segmentation, named BrainSegDMLF. This model has the following\nfeatures: 1) Dynamic Modal Interactive Fusion (DMIF) module that processes and\nintegrates multi-modal data during the encoding process, providing the SAM\nencoder with more comprehensive modal information. 2) Layer-by-Layer Upsampling\nDecoder, enabling the model to extract rich low-level and high-level features\neven with limited data, thereby detecting the presence of small lesions. 3)\nAutomatic segmentation masks, allowing the model to generate lesion masks\nautomatically without requiring manual prompts."}
{"id": "2503.03137", "pdf": "https://arxiv.org/pdf/2503.03137", "abs": "https://arxiv.org/abs/2503.03137", "authors": ["Changliang Zhou", "Xi Lin", "Zhenkun Wang", "Qingfu Zhang"], "title": "L2R: Learning to Reduce Search Space for Generalizable Neural Routing Solver", "categories": ["cs.AI", "cs.LG", "cs.NE"], "comment": "23 pages, 10 figures", "summary": "Constructive neural combinatorial optimization (NCO) has attracted growing\nresearch attention due to its ability to solve complex routing problems without\nrelying on handcrafted rules. However, existing NCO methods face significant\nchallenges in generalizing to large-scale problems due to high computational\ncomplexity and inefficient capture of structural patterns. To address this\nissue, we propose a novel learning-based search space reduction method that\nadaptively selects a small set of promising candidate nodes at each step of the\nconstructive NCO process. Unlike traditional methods that rely on fixed\nheuristics, our selection model dynamically prioritizes nodes based on learned\npatterns, significantly reducing the search space while maintaining solution\nquality. Experimental results demonstrate that our method, trained solely on\n100-node instances from uniform distribution, generalizes remarkably well to\nlarge-scale Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing\nProblem (CVRP) instances with up to 1 million nodes from the uniform\ndistribution and over 80K nodes from other distributions."}
{"id": "2505.05423", "pdf": "https://arxiv.org/pdf/2505.05423", "abs": "https://arxiv.org/abs/2505.05423", "authors": ["Ran Zhang", "Wei Zhao", "Lieve Macken", "Steffen Eger"], "title": "LiTransProQA: an LLM-based Literary Translation evaluation metric with Professional Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": "Update WIP", "summary": "The impact of Large Language Models (LLMs) has extended into literary\ndomains. However, existing evaluation metrics prioritize mechanical accuracy\nover artistic expression and tend to overrate machine translation (MT) as being\nsuperior to experienced professional human translation. In the long run, this\nbias could result in a permanent decline in translation quality and cultural\nauthenticity. In response to the urgent need for a specialized literary\nevaluation metric, we introduce LiTransProQA, a novel, reference-free,\nLLM-based question-answering framework designed specifically for literary\ntranslation evaluation. LiTransProQA uniquely integrates insights from\nprofessional literary translators and researchers, focusing on critical\nelements in literary quality assessment such as literary devices, cultural\nunderstanding, and authorial voice. Our extensive evaluation shows that while\nliterary-finetuned XCOMET-XL yields marginal gains, LiTransProQA substantially\noutperforms current metrics, achieving up to 0.07 gain in correlation (ACC-EQ\nand Kendall's tau) and surpassing the best state-of-the-art metrics by over 15\npoints in adequacy assessments. Incorporating professional translator insights\nas weights further improves performance, highlighting the value of translator\ninputs. Notably, LiTransProQA approaches human-level evaluation performance\ncomparable to trained linguistic annotators. It demonstrates broad\napplicability to open-source models such as LLaMA3.3-70b and Qwen2.5-32b,\nindicating its potential as an accessible and training-free literary evaluation\nmetric and a valuable tool for evaluating texts that require local processing\ndue to copyright or ethical considerations."}
{"id": "2504.14298", "pdf": "https://arxiv.org/pdf/2504.14298", "abs": "https://arxiv.org/abs/2504.14298", "authors": ["Xiucheng Wang", "Zhongsheng Fang", "Nan Cheng", "Ruijin Sun", "Zan Li", "Xuemin", "Shen"], "title": "RadioDiff-Inverse: Diffusion Enhanced Bayesian Inverse Estimation for ISAC Radio Map Construction", "categories": ["cs.AI"], "comment": "13 pages, 7 figures", "summary": "Radio maps (RMs) are essential for environment-aware communication and\nsensing, providing location-specific wireless channel information. Existing RM\nconstruction methods often rely on precise environmental data and base station\n(BS) locations, which are not always available in dynamic or privacy-sensitive\nenvironments. While sparse measurement techniques reduce data collection, the\nimpact of noise in sparse data on RM accuracy is not well understood. This\npaper addresses these challenges by formulating RM construction as a Bayesian\ninverse problem under coarse environmental knowledge and noisy sparse\nmeasurements. Although maximum a posteriori (MAP) filtering offers an optimal\nsolution, it requires a precise prior distribution of the RM, which is\ntypically unavailable. To solve this, we propose RadioDiff-Inverse, a\ndiffusion-enhanced Bayesian inverse estimation framework that uses an\nunconditional generative diffusion model to learn the RM prior. This approach\nnot only reconstructs the spatial distribution of wireless channel features but\nalso enables environmental structure perception, such as building outlines, and\nlocation of BS just relay on pathloss, through integrated sensing and\ncommunication (ISAC). Remarkably, RadioDiff-Inverse is training-free,\nleveraging a pre-trained model from Imagenet without task-specific fine-tuning,\nwhich significantly reduces the training cost of using generative large model\nin wireless networks. Experimental results demonstrate that RadioDiff-Inverse\nachieves state-of-the-art performance in accuracy of RM construction and\nenvironmental reconstruction, and robustness against noisy sparse sampling."}
{"id": "2505.06166", "pdf": "https://arxiv.org/pdf/2505.06166", "abs": "https://arxiv.org/abs/2505.06166", "authors": ["Radu Alexandru Rosu", "Keyu Wu", "Yao Feng", "Youyi Zheng", "Michael J. Black"], "title": "DiffLocks: Generating 3D Hair from a Single Image using Diffusion Models", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2025", "summary": "We address the task of generating 3D hair geometry from a single image, which\nis challenging due to the diversity of hairstyles and the lack of paired\nimage-to-3D hair data. Previous methods are primarily trained on synthetic data\nand cope with the limited amount of such data by using low-dimensional\nintermediate representations, such as guide strands and scalp-level embeddings,\nthat require post-processing to decode, upsample, and add realism. These\napproaches fail to reconstruct detailed hair, struggle with curly hair, or are\nlimited to handling only a few hairstyles. To overcome these limitations, we\npropose DiffLocks, a novel framework that enables detailed reconstruction of a\nwide variety of hairstyles directly from a single image. First, we address the\nlack of 3D hair data by automating the creation of the largest synthetic hair\ndataset to date, containing 40K hairstyles. Second, we leverage the synthetic\nhair dataset to learn an image-conditioned diffusion-transfomer model that\ngenerates accurate 3D strands from a single frontal image. By using a\npretrained image backbone, our method generalizes to in-the-wild images despite\nbeing trained only on synthetic data. Our diffusion model predicts a scalp\ntexture map in which any point in the map contains the latent code for an\nindividual hair strand. These codes are directly decoded to 3D strands without\npost-processing techniques. Representing individual strands, instead of guide\nstrands, enables the transformer to model the detailed spatial structure of\ncomplex hairstyles. With this, DiffLocks can recover highly curled hair, like\nafro hairstyles, from a single image for the first time. Data and code is\navailable at https://radualexandru.github.io/difflocks/"}
{"id": "2505.05478", "pdf": "https://arxiv.org/pdf/2505.05478", "abs": "https://arxiv.org/abs/2505.05478", "authors": ["Yufei Zhang", "Andrew Sonta"], "title": "OccuEMBED: Occupancy Extraction Merged with Building Energy Disaggregation for Occupant-Responsive Operation at Scale", "categories": ["eess.SP", "cs.LG", "cs.SY", "eess.SY"], "comment": "33 pages, 16 figures", "summary": "Buildings account for a significant share of global energy consumption and\nemissions, making it critical to operate them efficiently. As electricity grids\nbecome more volatile with renewable penetration, buildings must provide\nflexibility to support grid stability. Building automation plays a key role in\nenhancing efficiency and flexibility via centralized operations, but it must\nprioritize occupant-centric strategies to balance energy and comfort targets.\nHowever, incorporating occupant information into large-scale, centralized\nbuilding operations remains challenging due to data limitations. We investigate\nthe potential of using whole-building smart meter data to infer both occupancy\nand system operations. Integrating these insights into data-driven building\nenergy analysis allows more occupant-centric energy-saving and flexibility at\nscale. Specifically, we propose OccuEMBED, a unified framework for occupancy\ninference and system-level load analysis. It combines two key components: a\nprobabilistic occupancy profile generator, and a controllable and interpretable\nload disaggregator supported by Kolmogorov-Arnold Networks (KAN). This design\nembeds knowledge of occupancy patterns and load-occupancy-weather relationships\ninto deep learning models. We conducted comprehensive evaluations to\ndemonstrate its effectiveness across synthetic and real-world datasets compared\nto various occupancy inference baselines. OccuEMBED always achieved average F1\nscores above 0.8 in discrete occupancy inference and RMSE within 0.1-0.2 for\ncontinuous occupancy ratios. We further demonstrate how OccuEMBED integrates\nwith building load monitoring platforms to display occupancy profiles, analyze\nsystem-level operations, and inform occupant-responsive strategies. Our model\nlays a robust foundation in scaling occupant-centric building management\nsystems to meet the challenges of an evolving energy system."}
{"id": "2406.06600", "pdf": "https://arxiv.org/pdf/2406.06600", "abs": "https://arxiv.org/abs/2406.06600", "authors": ["Yutao Sun", "Mingshuai Chen", "Tiancheng Zhao", "Kangjia Zhao", "He Li", "Jintao Chen", "Zhongyi Wang", "Liqiang Lu", "Xinkui Zhao", "Shuiguang Deng", "Jianwei Yin"], "title": "HORAE: A Domain-Agnostic Language for Automated Service Regulation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Full version of IJCAI 2025", "summary": "Artificial intelligence is rapidly encroaching on the field of service\nregulation. However, existing AI-based regulation techniques are often tailored\nto specific application domains and thus are difficult to generalize in an\nautomated manner. This paper presents Horae, a unified specification language\nfor modeling (multimodal) regulation rules across a diverse set of domains. We\nshowcase how Horae facilitates an intelligent service regulation pipeline by\nfurther exploiting a fine-tuned large language model named RuleGPT that\nautomates the Horae modeling process, thereby yielding an end-to-end framework\nfor fully automated intelligent service regulation. The feasibility and\neffectiveness of our framework are demonstrated over a benchmark of various\nreal-world regulation domains. In particular, we show that our open-sourced,\nfine-tuned RuleGPT with 7B parameters suffices to outperform GPT-3.5 and\nperform on par with GPT-4o."}
{"id": "2504.18530", "pdf": "https://arxiv.org/pdf/2504.18530", "abs": "https://arxiv.org/abs/2504.18530", "authors": ["Joshua Engels", "David D. Baek", "Subhash Kantamneni", "Max Tegmark"], "title": "Scaling Laws For Scalable Oversight", "categories": ["cs.AI", "cs.CY", "cs.LG"], "comment": "32 pages, 18 figures; The first three authors contributed equally", "summary": "Scalable oversight, the process by which weaker AI systems supervise stronger\nones, has been proposed as a key strategy to control future superintelligent\nsystems. However, it is still unclear how scalable oversight itself scales. To\naddress this gap, we propose a framework that quantifies the probability of\nsuccessful oversight as a function of the capabilities of the overseer and the\nsystem being overseen. Specifically, our framework models oversight as a game\nbetween capability-mismatched players; the players have oversight-specific Elo\nscores that are a piecewise-linear function of their general intelligence, with\ntwo plateaus corresponding to task incompetence and task saturation. We\nvalidate our framework with a modified version of the game Nim and then apply\nit to four oversight games: Mafia, Debate, Backdoor Code and Wargames. For each\ngame, we find scaling laws that approximate how domain performance depends on\ngeneral AI system capability. We then build on our findings in a theoretical\nstudy of Nested Scalable Oversight (NSO), a process in which trusted models\noversee untrusted stronger models, which then become the trusted models in the\nnext step. We identify conditions under which NSO succeeds and derive\nnumerically (and in some cases analytically) the optimal number of oversight\nlevels to maximize the probability of oversight success. We also apply our\ntheory to our four oversight games, where we find that NSO success rates at a\ngeneral Elo gap of 400 are 13.5% for Mafia, 51.7% for Debate, 10.0% for\nBackdoor Code, and 9.4% for Wargames; these rates decline further when\noverseeing stronger systems."}
{"id": "2505.06217", "pdf": "https://arxiv.org/pdf/2505.06217", "abs": "https://arxiv.org/abs/2505.06217", "authors": ["Pengfei Gu", "Haoteng Tang", "Islam A. Ebeid", "Jose A. Nunez", "Fabian Vazquez", "Diego Adame", "Marcus Zhan", "Huimin Li", "Bin Fu", "Danny Z. Chen"], "title": "Adapting a Segmentation Foundation Model for Medical Image Classification", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in foundation models, such as the Segment Anything Model\n(SAM), have shown strong performance in various vision tasks, particularly\nimage segmentation, due to their impressive zero-shot segmentation\ncapabilities. However, effectively adapting such models for medical image\nclassification is still a less explored topic. In this paper, we introduce a\nnew framework to adapt SAM for medical image classification. First, we utilize\nthe SAM image encoder as a feature extractor to capture segmentation-based\nfeatures that convey important spatial and contextual details of the image,\nwhile freezing its weights to avoid unnecessary overhead during training. Next,\nwe propose a novel Spatially Localized Channel Attention (SLCA) mechanism to\ncompute spatially localized attention weights for the feature maps. The\nfeatures extracted from SAM's image encoder are processed through SLCA to\ncompute attention weights, which are then integrated into deep learning\nclassification models to enhance their focus on spatially relevant or\nmeaningful regions of the image, thus improving classification performance.\nExperimental results on three public medical image classification datasets\ndemonstrate the effectiveness and data-efficiency of our approach."}
{"id": "2505.05479", "pdf": "https://arxiv.org/pdf/2505.05479", "abs": "https://arxiv.org/abs/2505.05479", "authors": ["Finn Gueterbock", "Raul Santos-Rodriguez", "Jeffrey N. Clark"], "title": "Improving Local Air Quality Predictions Using Transfer Learning on Satellite Data and Graph Neural Networks", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Air pollution is a significant global health risk, contributing to millions\nof premature deaths annually. Nitrogen dioxide (NO2), a harmful pollutant,\ndisproportionately affects urban areas where monitoring networks are often\nsparse. We propose a novel method for predicting NO2 concentrations at\nunmonitored locations using transfer learning with satellite and meteorological\ndata. Leveraging the GraphSAGE framework, our approach integrates\nautoregression and transfer learning to enhance predictive accuracy in\ndata-scarce regions like Bristol. Pre-trained on data from London, UK, our\nmodel achieves a 8.6% reduction in Normalised Root Mean Squared Error (NRMSE)\nand a 32.6% reduction in Gradient RMSE compared to a baseline model. This work\ndemonstrates the potential of virtual sensors for cost-effective air quality\nmonitoring, contributing to actionable insights for climate and health\ninterventions."}
{"id": "2406.09831", "pdf": "https://arxiv.org/pdf/2406.09831", "abs": "https://arxiv.org/abs/2406.09831", "authors": ["Youyang Qu", "Ming Liu", "Tianqing Zhu", "Longxiang Gao", "Shui Yu", "Wanlei Zhou"], "title": "Recent Advances in Federated Learning Driven Large Language Models: A Survey on Architecture, Performance, and Security", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.NE"], "comment": null, "summary": "Federated Learning (FL) offers a promising paradigm for training Large\nLanguage Models (LLMs) in a decentralized manner while preserving data privacy\nand minimizing communication overhead. This survey examines recent advancements\nin FL-driven LLMs, with a particular emphasis on architectural designs,\nperformance optimization, and security concerns, including the emerging area of\nmachine unlearning. In this context, machine unlearning refers to the\nsystematic removal of specific data contributions from trained models to comply\nwith privacy regulations such as the Right to be Forgotten. We review a range\nof strategies enabling unlearning in federated LLMs, including\nperturbation-based methods, model decomposition, and incremental retraining,\nwhile evaluating their trade-offs in terms of efficiency, privacy guarantees,\nand model utility. Through selected case studies and empirical evaluations, we\nanalyze how these methods perform in practical FL scenarios. This survey\nidentifies critical research directions toward developing secure, adaptable,\nand high-performing federated LLM systems for real-world deployment."}
{"id": "2504.20007", "pdf": "https://arxiv.org/pdf/2504.20007", "abs": "https://arxiv.org/abs/2504.20007", "authors": ["Anita Srbinovska", "Angela Srbinovska", "Vivek Senthil", "Adrian Martin", "John McCluskey", "Jonathan Bateman", "Ernest Fokoué"], "title": "Towards AI-Driven Policing: Interdisciplinary Knowledge Discovery from Police Body-Worn Camera Footage", "categories": ["cs.AI", "cs.CV"], "comment": "6 pages, 2 figures, and 1 table", "summary": "This paper proposes a novel interdisciplinary framework for analyzing police\nbody-worn camera (BWC) footage from the Rochester Police Department (RPD) using\nadvanced artificial intelligence (AI) and statistical machine learning (ML)\ntechniques. Our goal is to detect, classify, and analyze patterns of\ninteraction between police officers and civilians to identify key behavioral\ndynamics, such as respect, disrespect, escalation, and de-escalation. We apply\nmultimodal data analysis by integrating video, audio, and natural language\nprocessing (NLP) techniques to extract meaningful insights from BWC footage. We\npresent our methodology, computational techniques, and findings, outlining a\npractical approach for law enforcement while advancing the frontiers of\nknowledge discovery from police BWC data."}
{"id": "2505.06219", "pdf": "https://arxiv.org/pdf/2505.06219", "abs": "https://arxiv.org/abs/2505.06219", "authors": ["Noah Frahm", "Dongxu Zhao", "Andrea Dunn Beltran", "Ron Alterovitz", "Jan-Michael Frahm", "Junier Oliva", "Roni Sengupta"], "title": "VIN-NBV: A View Introspection Network for Next-Best-View Selection for Resource-Efficient 3D Reconstruction", "categories": ["cs.CV", "cs.RO", "I.2.10; I.2.9"], "comment": "19 pages, 11 figures", "summary": "Next Best View (NBV) algorithms aim to acquire an optimal set of images using\nminimal resources, time, or number of captures to enable efficient 3D\nreconstruction of a scene. Existing approaches often rely on prior scene\nknowledge or additional image captures and often develop policies that maximize\ncoverage. Yet, for many real scenes with complex geometry and self-occlusions,\ncoverage maximization does not lead to better reconstruction quality directly.\nIn this paper, we propose the View Introspection Network (VIN), which is\ntrained to predict the reconstruction quality improvement of views directly,\nand the VIN-NBV policy. A greedy sequential sampling-based policy, where at\neach acquisition step, we sample multiple query views and choose the one with\nthe highest VIN predicted improvement score. We design the VIN to perform\n3D-aware featurization of the reconstruction built from prior acquisitions, and\nfor each query view create a feature that can be decoded into an improvement\nscore. We then train the VIN using imitation learning to predict the\nreconstruction improvement score. We show that VIN-NBV improves reconstruction\nquality by ~30% over a coverage maximization baseline when operating with\nconstraints on the number of acquisitions or the time in motion."}
{"id": "2505.05485", "pdf": "https://arxiv.org/pdf/2505.05485", "abs": "https://arxiv.org/abs/2505.05485", "authors": ["Antonio Arauzo-Azofra", "Jose Molina-Baena", "Maria Luque-Rodriguez"], "title": "Evolutionary Optimization for the Classification of Small Molecules Regulating the Circadian Rhythm Period: A Reliable Assessment", "categories": ["cs.NE", "cs.LG"], "comment": "13 pages, 5 figures, 8 tables. To be published", "summary": "The circadian rhythm plays a crucial role in regulating biological processes,\nand its disruption is linked to various health issues. Identifying small\nmolecules that influence the circadian period is essential for developing\ntargeted therapies. This study explores the use of evolutionary optimization\ntechniques to enhance the classification of these molecules. We applied an\nevolutionary algorithm to optimize feature selection and classification\nperformance. Several machine learning classifiers were employed, and\nperformance was evaluated using accuracy and generalization ability. The\nfindings demonstrate that the proposed evolutionary optimization method\nimproves classification accuracy and reduces overfitting compared to baseline\nmodels. Additionally, the use of variance in accuracy as a penalty factor may\nenhance the model's reliability for real-world applications. Our study confirms\nthat evolutionary optimization is an effective strategy for classifying small\nmolecules regulating the circadian rhythm. The proposed approach not only\nimproves predictive performance but also ensures a more robust model."}
{"id": "2503.24289", "pdf": "https://arxiv.org/pdf/2503.24289", "abs": "https://arxiv.org/abs/2503.24289", "authors": ["Jiacheng Lin", "Tian Wang", "Kun Qian"], "title": "Rec-R1: Bridging Generative Large Language Models and User-Centric Recommendation Systems via Reinforcement Learning", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "We propose Rec-R1, a general reinforcement learning framework that bridges\nlarge language models (LLMs) with recommendation systems through closed-loop\noptimization. Unlike prompting and supervised fine-tuning (SFT), Rec-R1\ndirectly optimizes LLM generation using feedback from a fixed black-box\nrecommendation model, without relying on synthetic SFT data from proprietary\nmodels such as GPT-4o. This avoids the substantial cost and effort required for\ndata distillation. To verify the effectiveness of Rec-R1, we evaluate it on two\nrepresentative tasks: product search and sequential recommendation.\nExperimental results demonstrate that Rec-R1 not only consistently outperforms\nprompting- and SFT-based methods, but also achieves significant gains over\nstrong discriminative baselines, even when used with simple retrievers such as\nBM25. Moreover, Rec-R1 preserves the general-purpose capabilities of the LLM,\nunlike SFT, which often impairs instruction-following and reasoning. These\nfindings suggest Rec-R1 as a promising foundation for continual task-specific\nadaptation without catastrophic forgetting."}
{"id": "2505.03332", "pdf": "https://arxiv.org/pdf/2505.03332", "abs": "https://arxiv.org/abs/2505.03332", "authors": ["Evgeny Markhasin"], "title": "AI-Driven Scholarly Peer Review via Persistent Workflow Prompting, Meta-Prompting, and Meta-Reasoning", "categories": ["cs.AI"], "comment": "22 pages, 36 pages (references and appendixes)", "summary": "Critical peer review of scientific manuscripts presents a significant\nchallenge for Large Language Models (LLMs), partly due to data limitations and\nthe complexity of expert reasoning. This report introduces Persistent Workflow\nPrompting (PWP), a potentially broadly applicable prompt engineering\nmethodology designed to bridge this gap using standard LLM chat interfaces\n(zero-code, no APIs). We present a proof-of-concept PWP prompt for the critical\nanalysis of experimental chemistry manuscripts, featuring a hierarchical,\nmodular architecture (structured via Markdown) that defines detailed analysis\nworkflows. We develop this PWP prompt through iterative application of\nmeta-prompting techniques and meta-reasoning aimed at systematically codifying\nexpert review workflows, including tacit knowledge. Submitted once at the start\nof a session, this PWP prompt equips the LLM with persistent workflows\ntriggered by subsequent queries, guiding modern reasoning LLMs through\nsystematic, multimodal evaluations. Demonstrations show the PWP-guided LLM\nidentifying major methodological flaws in a test case while mitigating LLM\ninput bias and performing complex tasks, including distinguishing claims from\nevidence, integrating text/photo/figure analysis to infer parameters, executing\nquantitative feasibility checks, comparing estimates against claims, and\nassessing a priori plausibility. To ensure transparency and facilitate\nreplication, we provide full prompts, detailed demonstration analyses, and logs\nof interactive chats as supplementary resources. Beyond the specific\napplication, this work offers insights into the meta-development process\nitself, highlighting the potential of PWP, informed by detailed workflow\nformalization, to enable sophisticated analysis using readily available LLMs\nfor complex scientific tasks."}
{"id": "2505.05477", "pdf": "https://arxiv.org/pdf/2505.05477", "abs": "https://arxiv.org/abs/2505.05477", "authors": ["Sainan xiao", "Wangdong Yang", "Buwen Cao", "Jintao Wu"], "title": "ECGDeDRDNet: A deep learning-based method for Electrocardiogram noise removal using a double recurrent dense network", "categories": ["eess.SP", "cs.CV"], "comment": null, "summary": "Electrocardiogram (ECG) signals are frequently corrupted by noise, such as\nbaseline wander (BW), muscle artifacts (MA), and electrode motion (EM), which\nsignificantly degrade their diagnostic utility. To address this issue, we\npropose ECGDeDRDNet, a deep learning-based ECG Denoising framework leveraging a\nDouble Recurrent Dense Network architecture. In contrast to traditional\napproaches, we introduce a double recurrent scheme to enhance information reuse\nfrom both ECG waveforms and the estimated clean image. For ECG waveform\nprocessing, our basic model employs LSTM layers cascaded with DenseNet blocks.\nThe estimated clean ECG image, obtained by subtracting predicted noise\ncomponents from the noisy input, is iteratively fed back into the model. This\ndual recurrent architecture enables comprehensive utilization of both temporal\nwaveform features and spatial image details, leading to more effective noise\nsuppression. Experimental results on the MIT-BIH dataset demonstrate that our\nmethod achieves superior performance compared to conventional image denoising\nmethods in terms of PSNR and SSIM while also surpassing classical ECG denoising\ntechniques in both SNR and RMSE."}
{"id": "2505.05489", "pdf": "https://arxiv.org/pdf/2505.05489", "abs": "https://arxiv.org/abs/2505.05489", "authors": ["Alberto Morando"], "title": "Akkumula: Evidence accumulation driver models with Spiking Neural Networks", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Processes of evidence accumulation for motor control contribute to the\necological validity of driver models. According to established theories of\ncognition, drivers make control adjustments when a process of accumulation of\nperceptual inputs reaches a decision boundary. Unfortunately, there is not a\nstandard way for building such models, limiting their use. Current\nimplementations are hand-crafted, lack adaptability, and rely on inefficient\noptimization techniques that do not scale well with large datasets. This paper\nintroduces Akkumula, an evidence accumulation modelling framework built using\ndeep learning techniques to leverage established coding libraries, gradient\noptimization, and large batch training. The core of the library is based on\nSpiking Neural Networks, whose operation mimic the evidence accumulation\nprocess in the biological brain. The model was tested on data collected during\na test-track experiment. Results are promising. The model fits well the time\ncourse of vehicle control (brake, accelerate, steering) based on vehicle sensor\ndata. The perceptual inputs are extracted by a dedicated neural network,\nincreasing the context-awareness of the model in dynamic scenarios. Akkumula\nintegrates with existing machine learning architectures, benefits from\ncontinuous advancements in deep learning, efficiently processes large datasets,\nadapts to diverse driving scenarios, and maintains a degree of transparency in\nits core mechanisms."}
{"id": "2505.02550", "pdf": "https://arxiv.org/pdf/2505.02550", "abs": "https://arxiv.org/abs/2505.02550", "authors": ["Krzysztof Ociepa", "Łukasz Flis", "Remigiusz Kinas", "Krzysztof Wróbel", "Adrian Gwoździej"], "title": "Bielik v3 Small: Technical Report", "categories": ["cs.LG", "cs.AI", "cs.CL", "68T50", "I.2.7"], "comment": null, "summary": "We introduce Bielik v3, a series of parameter-efficient generative text\nmodels (1.5B and 4.5B) optimized for Polish language processing. These models\ndemonstrate that smaller, well-optimized architectures can achieve performance\ncomparable to much larger counterparts while requiring substantially fewer\ncomputational resources. Our approach incorporates several key innovations: a\ncustom Polish tokenizer (APT4) that significantly improves token efficiency,\nWeighted Instruction Cross-Entropy Loss to balance learning across instruction\ntypes, and Adaptive Learning Rate that dynamically adjusts based on training\nprogress. Trained on a meticulously curated corpus of 292 billion tokens\nspanning 303 million documents, these models excel across multiple benchmarks,\nincluding the Open PL LLM Leaderboard, Complex Polish Text Understanding\nBenchmark, Polish EQ-Bench, and Polish Medical Leaderboard. The 4.5B parameter\nmodel achieves results competitive with models 2-3 times its size, while the\n1.5B model delivers strong performance despite its extremely compact profile.\nThese advances establish new benchmarks for parameter-efficient language\nmodeling in less-represented languages, making high-quality Polish language AI\nmore accessible for resource-constrained applications."}
{"id": "2505.05440", "pdf": "https://arxiv.org/pdf/2505.05440", "abs": "https://arxiv.org/abs/2505.05440", "authors": ["Biao Yi", "Xavier Hu", "Yurun Chen", "Shengyu Zhang", "Hongxia Yang", "Fan Wu", "Fei Wu"], "title": "EcoAgent: An Efficient Edge-Cloud Collaborative Multi-Agent Framework for Mobile Automation", "categories": ["cs.AI"], "comment": null, "summary": "Cloud-based mobile agents powered by (multimodal) large language models\n((M)LLMs) offer strong reasoning abilities but suffer from high latency and\ncost. While fine-tuned (M)SLMs enable edge deployment, they often lose general\ncapabilities and struggle with complex tasks. To address this, we propose\n\\textbf{EcoAgent}, an \\textbf{E}dge-\\textbf{C}loud c\\textbf{O}llaborative\nmulti-agent framework for mobile automation. EcoAgent features a closed-loop\ncollaboration among a cloud-based Planning Agent and two edge-based agents: the\nExecution Agent for action execution and the Observation Agent for verifying\noutcomes. The Observation Agent uses a Pre-Understanding Module to compress\nscreen images into concise text, reducing token usage and communication\noverhead. In case of failure, the Planning Agent retrieves screen history\nthrough a Memory Module and replans via a Reflection Module. Experiments on\nAndroidWorld show that EcoAgent achieves task success rates comparable to\ncloud-based mobile agents while significantly reducing MLLM token consumption,\nenabling efficient and practical mobile automation."}
{"id": "2505.05510", "pdf": "https://arxiv.org/pdf/2505.05510", "abs": "https://arxiv.org/abs/2505.05510", "authors": ["Thomas Sommariva", "Simone Calderara", "Angelo Porrello"], "title": "How to Train Your Metamorphic Deep Neural Network", "categories": ["cs.NE", "cs.CV", "cs.LG"], "comment": "14 pages, 7 figures", "summary": "Neural Metamorphosis (NeuMeta) is a recent paradigm for generating neural\nnetworks of varying width and depth. Based on Implicit Neural Representation\n(INR), NeuMeta learns a continuous weight manifold, enabling the direct\ngeneration of compressed models, including those with configurations not seen\nduring training. While promising, the original formulation of NeuMeta proves\neffective only for the final layers of the undelying model, limiting its\nbroader applicability. In this work, we propose a training algorithm that\nextends the capabilities of NeuMeta to enable full-network metamorphosis with\nminimal accuracy degradation. Our approach follows a structured recipe\ncomprising block-wise incremental training, INR initialization, and strategies\nfor replacing batch normalization. The resulting metamorphic networks maintain\ncompetitive accuracy across a wide range of compression ratios, offering a\nscalable solution for adaptable and efficient deployment of deep models. The\ncode is available at: https://github.com/TSommariva/HTTY_NeuMeta."}
{"id": "2505.05511", "pdf": "https://arxiv.org/pdf/2505.05511", "abs": "https://arxiv.org/abs/2505.05511", "authors": ["Yanghui Song", "Aoqi Li", "Lilei Huo"], "title": "Economic Analysis and Optimization of Energy Storage Configuration for Park Power Systems Based on Random Forest and Genetic Algorithm", "categories": ["cs.NE", "cs.LG", "cs.SI"], "comment": "8 pages, 8 figures,International Journal of New Developments in\n  Engineering and Society ISSN 2522-3488 Vol. 8, Issue 4: 22-29", "summary": "This study aims to analyze the economic performance of various parks under\ndifferent conditions, particularly focusing on the operational costs and power\nload balancing before and after the deployment of energy storage systems.\nFirstly, the economic performance of the parks without energy storage was\nanalyzed using a random forest model. Taking Park A as an example, it was found\nthat the cost had the greatest correlation with electricity purchase, followed\nby photovoltaic output, indicating that solar and wind power output are key\nfactors affecting economic performance. Subsequently, the operation of the\nparks after the configuration of a 50kW/100kWh energy storage system was\nsimulated, and the total cost and operation strategy of the energy storage\nsystem were calculated. The results showed that after the deployment of energy\nstorage, the amount of wind and solar power curtailment in each park decreased,\nand the operational costs were reduced. Finally, a genetic algorithm was used\nto optimize the energy storage configuration of each park. The energy storage\noperation strategy was optimized through fitness functions, crossover\noperations, and mutation operations. After optimization, the economic\nindicators of Parks A, B, and C all improved. The research results indicate\nthat by optimizing energy storage configuration, each park can reduce costs,\nenhance economic benefits, and achieve sustainable development of the power\nsystem."}
{"id": "2505.02835", "pdf": "https://arxiv.org/pdf/2505.02835", "abs": "https://arxiv.org/abs/2505.02835", "authors": ["Yi-Fan Zhang", "Xingyu Lu", "Xiao Hu", "Chaoyou Fu", "Bin Wen", "Tianke Zhang", "Changyi Liu", "Kaiyu Jiang", "Kaibing Chen", "Kaiyu Tang", "Haojie Ding", "Jiankang Chen", "Fan Yang", "Zhang Zhang", "Tingting Gao", "Liang Wang"], "title": "R1-Reward: Training Multimodal Reward Model Through Stable Reinforcement Learning", "categories": ["cs.CV", "cs.CL"], "comment": "Home page: https://github.com/yfzhang114/r1_reward", "summary": "Multimodal Reward Models (MRMs) play a crucial role in enhancing the\nperformance of Multimodal Large Language Models (MLLMs). While recent\nadvancements have primarily focused on improving the model structure and\ntraining data of MRMs, there has been limited exploration into the\neffectiveness of long-term reasoning capabilities for reward modeling and how\nto activate these capabilities in MRMs. In this paper, we explore how\nReinforcement Learning (RL) can be used to improve reward modeling.\nSpecifically, we reformulate the reward modeling problem as a rule-based RL\ntask. However, we observe that directly applying existing RL algorithms, such\nas Reinforce++, to reward modeling often leads to training instability or even\ncollapse due to the inherent limitations of these algorithms. To address this\nissue, we propose the StableReinforce algorithm, which refines the training\nloss, advantage estimation strategy, and reward design of existing RL methods.\nThese refinements result in more stable training dynamics and superior\nperformance. To facilitate MRM training, we collect 200K preference data from\ndiverse datasets. Our reward model, R1-Reward, trained using the\nStableReinforce algorithm on this dataset, significantly improves performance\non multimodal reward modeling benchmarks. Compared to previous SOTA models,\nR1-Reward achieves a $8.4\\%$ improvement on the VL Reward-Bench and a $14.3\\%$\nimprovement on the Multimodal Reward Bench. Moreover, with more inference\ncompute, R1-Reward's performance is further enhanced, highlighting the\npotential of RL algorithms in optimizing MRMs."}
{"id": "2308.14329", "pdf": "https://arxiv.org/pdf/2308.14329", "abs": "https://arxiv.org/abs/2308.14329", "authors": ["Jin Bok Park", "Jinkyu Lee", "Muhyun Back", "Hyunmin Han", "David T. Ma", "Sang Min Won", "Sung Soo Hwang", "Il Yong Chun"], "title": "End-to-End Driving via Self-Supervised Imitation Learning Using Camera and LiDAR Data", "categories": ["cs.RO", "cs.AI"], "comment": "9 pages, 6 figures", "summary": "In autonomous driving, the end-to-end (E2E) driving approach that predicts\nvehicle control signals directly from sensor data is rapidly gaining attention.\nTo learn a safe E2E driving system, one needs an extensive amount of driving\ndata and human intervention. Vehicle control data is constructed by many hours\nof human driving, and it is challenging to construct large vehicle control\ndatasets. Often, publicly available driving datasets are collected with limited\ndriving scenes, and collecting vehicle control data is only available by\nvehicle manufacturers. To address these challenges, this letter proposes the\nfirst fully self-supervised learning framework, self-supervised imitation\nlearning (SSIL), for E2E driving, based on the self-supervised regression\nlearning (SSRL) framework.The proposed SSIL framework can learn E2E driving\nnetworks \\emph{without} using driving command data or a pre-trained model. To\nconstruct pseudo steering angle data, proposed SSIL predicts a pseudo target\nfrom the vehicle's poses at the current and previous time points that are\nestimated with light detection and ranging sensors. In addition, we propose two\nE2E driving networks that predict driving commands depending on high-level\ninstruction. Our numerical experiments with three different benchmark datasets\ndemonstrate that the proposed SSIL framework achieves \\emph{very} comparable\nE2E driving accuracy with the supervised learning counterpart. The proposed\npseudo-label predictor outperformed an existing one using proportional integral\nderivative controller."}
{"id": "2505.05592", "pdf": "https://arxiv.org/pdf/2505.05592", "abs": "https://arxiv.org/abs/2505.05592", "authors": ["Noriaki Hirose", "Lydia Ignatova", "Kyle Stachowicz", "Catherine Glossop", "Sergey Levine", "Dhruv Shah"], "title": "Learning to Drive Anywhere with Model-Based Reannotation11", "categories": ["cs.RO", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "comment": "19 pages, 11 figures, 8 tables", "summary": "Developing broadly generalizable visual navigation policies for robots is a\nsignificant challenge, primarily constrained by the availability of\nlarge-scale, diverse training data. While curated datasets collected by\nresearchers offer high quality, their limited size restricts policy\ngeneralization. To overcome this, we explore leveraging abundant, passively\ncollected data sources, including large volumes of crowd-sourced teleoperation\ndata and unlabeled YouTube videos, despite their potential for lower quality or\nmissing action labels. We propose Model-Based ReAnnotation (MBRA), a framework\nthat utilizes a learned short-horizon, model-based expert model to relabel or\ngenerate high-quality actions for these passive datasets. This relabeled data\nis then distilled into LogoNav, a long-horizon navigation policy conditioned on\nvisual goals or GPS waypoints. We demonstrate that LogoNav, trained using\nMBRA-processed data, achieves state-of-the-art performance, enabling robust\nnavigation over distances exceeding 300 meters in previously unseen indoor and\noutdoor environments. Our extensive real-world evaluations, conducted across a\nfleet of robots (including quadrupeds) in six cities on three continents,\nvalidate the policy's ability to generalize and navigate effectively even\namidst pedestrians in crowded settings."}
{"id": "2505.05515", "pdf": "https://arxiv.org/pdf/2505.05515", "abs": "https://arxiv.org/abs/2505.05515", "authors": ["Zinan Liu", "Haoran Li", "Jingyi Lu", "Gaoyuan Ma", "Xu Hong", "Giovanni Iacca", "Arvind Kumar", "Shaojun Tang", "Lin Wang"], "title": "Nature's Insight: A Novel Framework and Comprehensive Analysis of Agentic Reasoning Through the Lens of Neuroscience", "categories": ["q-bio.NC", "cs.LG"], "comment": "39 pages, 17 figures", "summary": "Autonomous AI is no longer a hard-to-reach concept, it enables the agents to\nmove beyond executing tasks to independently addressing complex problems,\nadapting to change while handling the uncertainty of the environment. However,\nwhat makes the agents truly autonomous? It is agentic reasoning, that is\ncrucial for foundation models to develop symbolic logic, statistical\ncorrelations, or large-scale pattern recognition to process information, draw\ninferences, and make decisions. However, it remains unclear why and how\nexisting agentic reasoning approaches work, in comparison to biological\nreasoning, which instead is deeply rooted in neural mechanisms involving\nhierarchical cognition, multimodal integration, and dynamic interactions. In\nthis work, we propose a novel neuroscience-inspired framework for agentic\nreasoning. Grounded in three neuroscience-based definitions and supported by\nmathematical and biological foundations, we propose a unified framework\nmodeling reasoning from perception to action, encompassing four core types,\nperceptual, dimensional, logical, and interactive, inspired by distinct\nfunctional roles observed in the human brain. We apply this framework to\nsystematically classify and analyze existing AI reasoning methods, evaluating\ntheir theoretical foundations, computational designs, and practical\nlimitations. We also explore its implications for building more generalizable,\ncognitively aligned agents in physical and virtual environments. Finally,\nbuilding on our framework, we outline future directions and propose new\nneural-inspired reasoning methods, analogous to chain-of-thought prompting. By\nbridging cognitive neuroscience and AI, this work offers a theoretical\nfoundation and practical roadmap for advancing agentic reasoning in intelligent\nsystems. The associated project can be found at:\nhttps://github.com/BioRAILab/Awesome-Neuroscience-Agent-Reasoning ."}
{"id": "2505.03414", "pdf": "https://arxiv.org/pdf/2505.03414", "abs": "https://arxiv.org/abs/2505.03414", "authors": ["Fangming Cui", "Yonggang Zhang", "Xuan Wang", "Xinmei Tian", "Jun Yu"], "title": "Enhancing Target-unspecific Tasks through a Features Matrix", "categories": ["cs.CV", "cs.CL"], "comment": "ICML 2025", "summary": "Recent developments in prompt learning of large vision-language models have\nsignificantly improved performance in target-specific tasks. However, these\nprompt optimizing methods often struggle to tackle the target-unspecific or\ngeneralizable tasks effectively. It may be attributed to the fact that\noverfitting training causes the model to forget its general knowledge having\nstrong promotion on target-unspecific tasks. To alleviate this issue, we\npropose a novel Features Matrix (FM) regularization approach designed to\nenhance these models on target-unspecific tasks. Our method extracts and\nleverages general knowledge, shaping a Features Matrix (FM). Specifically, the\nFM captures the semantics of diverse inputs from a deep and fine perspective,\npreserving essential general knowledge, which mitigates the risk of\noverfitting. Representative evaluations demonstrate that: 1) the FM is\ncompatible with existing frameworks as a generic and flexible module, and 2)\nthe FM significantly showcases its effectiveness in enhancing target-unspecific\ntasks, achieving state-of-the-art performance."}
{"id": "2312.08365", "pdf": "https://arxiv.org/pdf/2312.08365", "abs": "https://arxiv.org/abs/2312.08365", "authors": ["Bernhard Jaeger", "Andreas Geiger"], "title": "An Invitation to Deep Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Published at Foundations and Trends in Optimization", "summary": "Training a deep neural network to maximize a target objective has become the\nstandard recipe for successful machine learning over the last decade. These\nnetworks can be optimized with supervised learning, if the target objective is\ndifferentiable. For many interesting problems, this is however not the case.\nCommon objectives like intersection over union (IoU), bilingual evaluation\nunderstudy (BLEU) score or rewards cannot be optimized with supervised\nlearning. A common workaround is to define differentiable surrogate losses,\nleading to suboptimal solutions with respect to the actual objective.\nReinforcement learning (RL) has emerged as a promising alternative for\noptimizing deep neural networks to maximize non-differentiable objectives in\nrecent years. Examples include aligning large language models via human\nfeedback, code generation, object detection or control problems. This makes RL\ntechniques relevant to the larger machine learning audience. The subject is,\nhowever, time intensive to approach due to the large range of methods, as well\nas the often very theoretical presentation. In this introduction, we take an\nalternative approach, different from classic reinforcement learning textbooks.\nRather than focusing on tabular problems, we introduce reinforcement learning\nas a generalization of supervised learning, which we first apply to\nnon-differentiable objectives and later to temporal problems. Assuming only\nbasic knowledge of supervised learning, the reader will be able to understand\nstate-of-the-art deep RL algorithms like proximal policy optimization (PPO)\nafter reading this tutorial."}
{"id": "2505.05647", "pdf": "https://arxiv.org/pdf/2505.05647", "abs": "https://arxiv.org/abs/2505.05647", "authors": ["Chin-Cheng Chan", "Justin P. Haldar"], "title": "A New k-Space Model for Non-Cartesian Fourier Imaging", "categories": ["eess.SP", "cs.CV"], "comment": null, "summary": "For the past several decades, it has been popular to reconstruct Fourier\nimaging data using model-based approaches that can easily incorporate physical\nconstraints and advanced regularization/machine learning priors. The most\ncommon modeling approach is to represent the continuous image as a linear\ncombination of shifted \"voxel\" basis functions. Although well-studied and\nwidely-deployed, this voxel-based model is associated with longstanding\nlimitations, including high computational costs, slow convergence, and a\npropensity for artifacts. In this work, we reexamine this model from a fresh\nperspective, identifying new issues that may have been previously overlooked\n(including undesirable approximation, periodicity, and nullspace\ncharacteristics). Our insights motivate us to propose a new model that is more\nresilient to the limitations (old and new) of the previous approach.\nSpecifically, the new model is based on a Fourier-domain basis expansion rather\nthan the standard image-domain voxel-based approach. Illustrative results,\nwhich are presented in the context of non-Cartesian MRI reconstruction,\ndemonstrate that the new model enables improved image quality (reduced\nartifacts) and/or reduced computational complexity (faster computations and\nimproved convergence)."}
{"id": "2505.05542", "pdf": "https://arxiv.org/pdf/2505.05542", "abs": "https://arxiv.org/abs/2505.05542", "authors": ["Guillaume Dalle", "Adrian Hill"], "title": "A Common Interface for Automatic Differentiation", "categories": ["cs.MS", "cs.LG", "cs.NA", "math.NA", "G.1.4"], "comment": "11 pages, 2 figures, 3 listings, 1 table", "summary": "For scientific machine learning tasks with a lot of custom code, picking the\nright Automatic Differentiation (AD) system matters. Our Julia package\nDifferentiationInterface.jl provides a common frontend to a dozen AD backends,\nunlocking easy comparison and modular development. In particular, its built-in\npreparation mechanism leverages the strengths of each backend by amortizing\none-time computations. This is key to enabling sophisticated features like\nsparsity handling without putting additional burdens on the user."}
{"id": "2401.14362", "pdf": "https://arxiv.org/pdf/2401.14362", "abs": "https://arxiv.org/abs/2401.14362", "authors": ["Inhwa Song", "Sachin R. Pendse", "Neha Kumar", "Munmun De Choudhury"], "title": "The Typing Cure: Experiences with Large Language Model Chatbots for Mental Health Support", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "The first two authors contributed equally to this work; typos\n  corrected and post-review revisions incorporated", "summary": "People experiencing severe distress increasingly use Large Language Model\n(LLM) chatbots as mental health support tools. Discussions on social media have\ndescribed how engagements were lifesaving for some, but evidence suggests that\ngeneral-purpose LLM chatbots also have notable risks that could endanger the\nwelfare of users if not designed responsibly. In this study, we investigate the\nlived experiences of people who have used LLM chatbots for mental health\nsupport. We build on interviews with 21 individuals from globally diverse\nbackgrounds to analyze how users create unique support roles for their\nchatbots, fill in gaps in everyday care, and navigate associated cultural\nlimitations when seeking support from chatbots. We ground our analysis in\npsychotherapy literature around effective support, and introduce the concept of\ntherapeutic alignment, or aligning AI with therapeutic values for mental health\ncontexts. Our study offers recommendations for how designers can approach the\nethical and effective use of LLM chatbots and other AI mental health support\ntools in mental health care."}
{"id": "2505.05800", "pdf": "https://arxiv.org/pdf/2505.05800", "abs": "https://arxiv.org/abs/2505.05800", "authors": ["Vineet Bhat", "Yu-Hsiang Lan", "Prashanth Krishnamurthy", "Ramesh Karri", "Farshad Khorrami"], "title": "3D CAVLA: Leveraging Depth and 3D Context to Generalize Vision Language Action Models for Unseen Tasks", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted at the 1st Workshop on 3D LLM/VLA, CVPR 2025", "summary": "Robotic manipulation in 3D requires learning an $N$ degree-of-freedom joint\nspace trajectory of a robot manipulator. Robots must possess semantic and\nvisual perception abilities to transform real-world mappings of their workspace\ninto the low-level control necessary for object manipulation. Recent work has\ndemonstrated the capabilities of fine-tuning large Vision-Language Models\n(VLMs) to learn the mapping between RGB images, language instructions, and\njoint space control. These models typically take as input RGB images of the\nworkspace and language instructions, and are trained on large datasets of\nteleoperated robot demonstrations. In this work, we explore methods to improve\nthe scene context awareness of a popular recent Vision-Language-Action model by\nintegrating chain-of-thought reasoning, depth perception, and task-oriented\nregion of interest detection. Our experiments in the LIBERO simulation\nenvironment show that our proposed model, 3D-CAVLA, improves the success rate\nacross various LIBERO task suites, achieving an average success rate of\n98.1$\\%$. We also evaluate the zero-shot capabilities of our method,\ndemonstrating that 3D scene awareness leads to robust learning and adaptation\nfor completely unseen tasks. 3D-CAVLA achieves an absolute improvement of\n8.8$\\%$ on unseen tasks. We will open-source our code and the unseen tasks\ndataset to promote community-driven research here: https://3d-cavla.github.io"}
{"id": "2505.05549", "pdf": "https://arxiv.org/pdf/2505.05549", "abs": "https://arxiv.org/abs/2505.05549", "authors": ["Vishnu Jejjala", "Suresh Nampuri", "Dumisani Nxumalo", "Pratik Roy", "Abinash Swain"], "title": "Machine learning automorphic forms for black holes", "categories": ["hep-th", "cs.LG", "math.NT"], "comment": null, "summary": "Modular, Jacobi, and mock-modular forms serve as generating functions for BPS\nblack hole degeneracies. By training feed-forward neural networks on Fourier\ncoefficients of automorphic forms derived from the Dedekind eta function,\nEisenstein series, and Jacobi theta functions, we demonstrate that machine\nlearning techniques can accurately predict modular weights from truncated\nexpansions. Our results reveal strong performance for negative weight modular\nand quasi-modular forms, particularly those arising in exact black hole\ncounting formulae, with lower accuracy for positive weights and more\ncomplicated combinations of Jacobi theta functions. This study establishes a\nproof of concept for using machine learning to identify how data is organized\nin terms of modular symmetries in gravitational systems and suggests a pathway\ntoward automated detection and verification of symmetries in quantum gravity."}
{"id": "2402.17410", "pdf": "https://arxiv.org/pdf/2402.17410", "abs": "https://arxiv.org/abs/2402.17410", "authors": ["Peter Dawood", "Felix Breuer", "Istvan Homolya", "Maximilian Gram", "Peter M. Jakob", "Moritz Zaiss", "Martin Blaimer"], "title": "Image space formalism of convolutional neural networks for k-space interpolation", "categories": ["cs.CV", "cs.AI", "cs.LG", "physics.med-ph"], "comment": null, "summary": "Purpose: Noise resilience in image reconstructions by scan-specific robust\nartificial neural networks for k-space interpolation (RAKI) is linked to\nnonlinear activations in k-space. To gain a deeper understanding of this\nrelationship, an image space formalism of RAKI is introduced for analyzing\nnoise propagation analytically, identifying and characterizing image\nreconstruction features and to describe the role of nonlinear activations in a\nhuman readable manner. Methods: The image space formalism for RAKI inference is\nemployed by expressing nonlinear activations in k-space as element-wise\nmultiplications with activation masks, which transform into convolutions in\nimage space. Jacobians of the de-aliased, coil-combined image relative to the\naliased coil images can be expressed algebraically, and thus, the noise\namplification is quantified analytically (g-factor maps). We analyze the role\nof nonlinearity for noise resilience by controlling the degree of nonlinearity\nin the reconstruction model via the negative slope parameter in leaky ReLU.\nResults: The analytical g-factor maps correspond with those obtained from Monte\nCarlo simulations and from an auto differentiation approach for in vivo brain\nimages. Apparent blurring and contrast loss artifacts are identified as\nimplications of enhanced noise resilience. These residual artifacts can be\ntraded against noise resilience by adjusting the degree of nonlinearity in the\nmodel (Tikhonov-like regularization) in case of limited training data. The\ninspection of image space activations reveals an autocorrelation pattern\nleading to a potential center artifact. Conclusion: The image space formalism\nof RAKI provides the means for analytical quantitative noisepropagation\nanalysis and human-readable visualization of the effects of the nonlinear\nactivation functions in k-space."}
{"id": "2505.05812", "pdf": "https://arxiv.org/pdf/2505.05812", "abs": "https://arxiv.org/abs/2505.05812", "authors": ["Ashkan Pakzad", "Robert Turnbull", "Simon J. Mutch", "Thomas A. Leatham", "Darren Lockie", "Jane Fox", "Beena Kumar", "Daniel Häsermann", "Christopher J. Hall", "Anton Maksimenko", "Benedicta D. Arhatari", "Yakov I. Nesterets", "Amir Entezam", "Seyedamir T. Taba", "Patrick C. Brennan", "Timur E. Gureyev", "Harry M. Quiney"], "title": "Towards order of magnitude X-ray dose reduction in breast cancer imaging using phase contrast and deep denoising", "categories": ["physics.med-ph", "cs.CV"], "comment": "16 pages, 3 figures, 1 table", "summary": "Breast cancer is the most frequently diagnosed human cancer in the United\nStates at present. Early detection is crucial for its successful treatment.\nX-ray mammography and digital breast tomosynthesis are currently the main\nmethods for breast cancer screening. However, both have known limitations in\nterms of their sensitivity and specificity to breast cancers, while also\nfrequently causing patient discomfort due to the requirement for breast\ncompression. Breast computed tomography is a promising alternative, however, to\nobtain high-quality images, the X-ray dose needs to be sufficiently high. As\nthe breast is highly radiosensitive, dose reduction is particularly important.\nPhase-contrast computed tomography (PCT) has been shown to produce\nhigher-quality images at lower doses and has no need for breast compression. It\nis demonstrated in the present study that, when imaging full fresh mastectomy\nsamples with PCT, deep learning-based image denoising can further reduce the\nradiation dose by a factor of 16 or more, without any loss of image quality.\nThe image quality has been assessed both in terms of objective metrics, such as\nspatial resolution and contrast-to-noise ratio, as well as in an observer study\nby experienced medical imaging specialists and radiologists. This work was\ncarried out in preparation for live patient PCT breast cancer imaging,\ninitially at specialized synchrotron facilities."}
{"id": "2505.05584", "pdf": "https://arxiv.org/pdf/2505.05584", "abs": "https://arxiv.org/abs/2505.05584", "authors": ["Mohamed Salah Bouafif", "Mohammad Hamdaqa", "Edward Zulkoski"], "title": "PRIMG : Efficient LLM-driven Test Generation Using Mutant Prioritization", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Mutation testing is a widely recognized technique for assessing and enhancing\nthe effectiveness of software test suites by introducing deliberate code\nmutations. However, its application often results in overly large test suites,\nas developers generate numerous tests to kill specific mutants, increasing\ncomputational overhead. This paper introduces PRIMG (Prioritization and\nRefinement Integrated Mutation-driven Generation), a novel framework for\nincremental and adaptive test case generation for Solidity smart contracts.\nPRIMG integrates two core components: a mutation prioritization module, which\nemploys a machine learning model trained on mutant subsumption graphs to\npredict the usefulness of surviving mutants, and a test case generation module,\nwhich utilizes Large Language Models (LLMs) to generate and iteratively refine\ntest cases to achieve syntactic and behavioral correctness.\n  We evaluated PRIMG on real-world Solidity projects from Code4Arena to assess\nits effectiveness in improving mutation scores and generating high-quality test\ncases. The experimental results demonstrate that PRIMG significantly reduces\ntest suite size while maintaining high mutation coverage. The prioritization\nmodule consistently outperformed random mutant selection, enabling the\ngeneration of high-impact tests with reduced computational effort. Furthermore,\nthe refining process enhanced the correctness and utility of LLM-generated\ntests, addressing their inherent limitations in handling edge cases and complex\nprogram logic."}
{"id": "2403.07887", "pdf": "https://arxiv.org/pdf/2403.07887", "abs": "https://arxiv.org/abs/2403.07887", "authors": ["Bhishma Dedhia", "Niraj K. Jha"], "title": "Neural Slot Interpreters: Grounding Object Semantics in Emergent Slot Representations", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Several accounts of human cognition posit that our intelligence is rooted in\nour ability to form abstract composable concepts, ground them in our\nenvironment, and reason over these grounded entities. This trifecta of human\nthought has remained elusive in modern intelligent machines. In this work, we\ninvestigate whether slot representations extracted from visual scenes serve as\nappropriate compositional abstractions for grounding and reasoning. We present\nthe Neural Slot Interpreter (NSI), which learns to ground object semantics in\nslots. At the core of NSI is a nested schema that uses simple syntax rules to\norganize the object semantics of a scene into object-centric schema primitives.\nThen, the NSI metric learns to ground primitives into slots through a\nstructured contrastive learning objective that reasons over the intermodal\nalignment. Experiments with a bi-modal object-property and scene retrieval task\ndemonstrate the grounding efficacy and interpretability of correspondences\nlearned by NSI. From a scene representation standpoint, we find that emergent\nNSI slots that move beyond the image grid by binding to spatial objects\nfacilitate improved visual grounding compared to conventional\nbounding-box-based approaches. From a data efficiency standpoint, we\nempirically validate that NSI learns more generalizable representations from a\nfixed amount of annotation data than the traditional approach. We also show\nthat the grounded slots surpass unsupervised slots in real-world object\ndiscovery and scale with scene complexity. Finally, we investigate the\ndownstream efficacy of the grounded slots. Vision Transformers trained on\ngrounding-aware NSI tokenizers using as few as ten tokens outperform\npatch-based tokens on challenging few-shot classification tasks."}
{"id": "2505.05957", "pdf": "https://arxiv.org/pdf/2505.05957", "abs": "https://arxiv.org/abs/2505.05957", "authors": ["Peter Röseler", "Oliver Schaudt", "Helmut Berg", "Christian Bauckhage", "Matthias Koch"], "title": "Efficient Quantum Convolutional Neural Networks for Image Classification: Overcoming Hardware Constraints", "categories": ["quant-ph", "cs.CV", "cs.LG"], "comment": null, "summary": "While classical convolutional neural networks (CNNs) have revolutionized\nimage classification, the emergence of quantum computing presents new\nopportunities for enhancing neural network architectures. Quantum CNNs (QCNNs)\nleverage quantum mechanical properties and hold potential to outperform\nclassical approaches. However, their implementation on current noisy\nintermediate-scale quantum (NISQ) devices remains challenging due to hardware\nlimitations. In our research, we address this challenge by introducing an\nencoding scheme that significantly reduces the input dimensionality. We\ndemonstrate that a primitive QCNN architecture with 49 qubits is sufficient to\ndirectly process $28\\times 28$ pixel MNIST images, eliminating the need for\nclassical dimensionality reduction pre-processing. Additionally, we propose an\nautomated framework based on expressibility, entanglement, and complexity\ncharacteristics to identify the building blocks of QCNNs, parameterized quantum\ncircuits (PQCs). Our approach demonstrates advantages in accuracy and\nconvergence speed with a similar parameter count compared to both hybrid QCNNs\nand classical CNNs. We validated our experiments on IBM's Heron r2 quantum\nprocessor, achieving $96.08\\%$ classification accuracy, surpassing the\n$71.74\\%$ benchmark of traditional approaches under identical training\nconditions. These results represent one of the first implementations of image\nclassifications on real quantum hardware and validate the potential of quantum\ncomputing in this area."}
{"id": "2505.05600", "pdf": "https://arxiv.org/pdf/2505.05600", "abs": "https://arxiv.org/abs/2505.05600", "authors": ["José Gonçalves", "Miguel Silva", "Eva Maia", "Isabel Praça"], "title": "Enhancing Large Language Models with Faster Code Preprocessing for Vulnerability Detection", "categories": ["cs.SE", "cs.LG"], "comment": "10 pages, 3 tables, DCAI'25: Distributed Computing and Artificial\n  Intelligence 2025", "summary": "The application of Artificial Intelligence has become a powerful approach to\ndetecting software vulnerabilities. However, effective vulnerability detection\nrelies on accurately capturing the semantic structure of code and its\ncontextual relationships. Given that the same functionality can be implemented\nin various forms, a preprocessing tool that standardizes code representation is\nimportant. This tool must be efficient, adaptable across programming languages,\nand capable of supporting new transformations. To address this challenge, we\nbuild on the existing SCoPE framework and introduce SCoPE2, an enhanced version\nwith improved performance. We compare both versions in terms of processing time\nand memory usage and evaluate their impact on a Large Language Model (LLM) for\nvulnerability detection. Our results show a 97.3\\% reduction in processing time\nwith SCoPE2, along with an improved F1-score for the LLM, solely due to the\nrefined preprocessing approach."}
{"id": "2403.16218", "pdf": "https://arxiv.org/pdf/2403.16218", "abs": "https://arxiv.org/abs/2403.16218", "authors": ["Juan Altmayer Pizzorno", "Emery D. Berger"], "title": "CoverUp: Effective High Coverage Test Generation for Python", "categories": ["cs.SE", "cs.AI", "cs.LG", "cs.PL", "I.2.0; D.2.5"], "comment": "21 pages; to appear at FSE'25", "summary": "Testing is an essential part of software development. Test generation tools\nattempt to automate the otherwise labor-intensive task of test creation, but\ngenerating high-coverage tests remains challenging. This paper proposes\nCoverUp, a novel approach to driving the generation of high-coverage Python\nregression tests. CoverUp combines coverage analysis, code context, and\nfeedback in prompts that iteratively guide the LLM to generate tests that\nimprove line and branch coverage. We evaluate our prototype CoverUp\nimplementation across a benchmark of challenging code derived from open-source\nPython projects and show that CoverUp substantially improves on the state of\nthe art. Compared to CodaMosa, a hybrid search/LLM-based test generator,\nCoverUp achieves a per-module median line+branch coverage of 80% (vs. 47%).\nCompared to MuTAP, a mutation- and LLM-based test generator, CoverUp achieves\nan overall line+branch coverage of 89% (vs. 77%). We also demonstrate that\nCoverUp's performance stems not only from the LLM used but from the combined\neffectiveness of its components."}
{"id": "2505.06079", "pdf": "https://arxiv.org/pdf/2505.06079", "abs": "https://arxiv.org/abs/2505.06079", "authors": ["Shuaiyi Huang", "Mara Levy", "Anubhav Gupta", "Daniel Ekpo", "Ruijie Zheng", "Abhinav Shrivastava"], "title": "TREND: Tri-teaching for Robust Preference-based Reinforcement Learning with Demonstrations", "categories": ["cs.RO", "cs.CV"], "comment": "ICRA 2025", "summary": "Preference feedback collected by human or VLM annotators is often noisy,\npresenting a significant challenge for preference-based reinforcement learning\nthat relies on accurate preference labels. To address this challenge, we\npropose TREND, a novel framework that integrates few-shot expert demonstrations\nwith a tri-teaching strategy for effective noise mitigation. Our method trains\nthree reward models simultaneously, where each model views its small-loss\npreference pairs as useful knowledge and teaches such useful pairs to its peer\nnetwork for updating the parameters. Remarkably, our approach requires as few\nas one to three expert demonstrations to achieve high performance. We evaluate\nTREND on various robotic manipulation tasks, achieving up to 90% success rates\neven with noise levels as high as 40%, highlighting its effective robustness in\nhandling noisy preference feedback. Project page:\nhttps://shuaiyihuang.github.io/publications/TREND."}
{"id": "2505.05613", "pdf": "https://arxiv.org/pdf/2505.05613", "abs": "https://arxiv.org/abs/2505.05613", "authors": ["Achraf Azize", "Yulian Wu", "Junya Honda", "Francesco Orabona", "Shinji Ito", "Debabrota Basu"], "title": "Optimal Regret of Bernoulli Bandits under Global Differential Privacy", "categories": ["stat.ML", "cs.CR", "cs.IT", "cs.LG", "math.IT", "math.ST", "stat.TH"], "comment": null, "summary": "As sequential learning algorithms are increasingly applied to real life,\nensuring data privacy while maintaining their utilities emerges as a timely\nquestion. In this context, regret minimisation in stochastic bandits under\n$\\epsilon$-global Differential Privacy (DP) has been widely studied. Unlike\nbandits without DP, there is a significant gap between the best-known regret\nlower and upper bound in this setting, though they \"match\" in order. Thus, we\nrevisit the regret lower and upper bounds of $\\epsilon$-global DP algorithms\nfor Bernoulli bandits and improve both. First, we prove a tighter regret lower\nbound involving a novel information-theoretic quantity characterising the\nhardness of $\\epsilon$-global DP in stochastic bandits. Our lower bound\nstrictly improves on the existing ones across all $\\epsilon$ values. Then, we\nchoose two asymptotically optimal bandit algorithms, i.e. DP-KLUCB and DP-IMED,\nand propose their DP versions using a unified blueprint, i.e., (a) running in\narm-dependent phases, and (b) adding Laplace noise to achieve privacy. For\nBernoulli bandits, we analyse the regrets of these algorithms and show that\ntheir regrets asymptotically match our lower bound up to a constant arbitrary\nclose to 1. This refutes the conjecture that forgetting past rewards is\nnecessary to design optimal bandit algorithms under global DP. At the core of\nour algorithms lies a new concentration inequality for sums of Bernoulli\nvariables under Laplace mechanism, which is a new DP version of the Chernoff\nbound. This result is universally useful as the DP literature commonly treats\nthe concentrations of Laplace noise and random variables separately, while we\ncouple them to yield a tighter bound."}
{"id": "2405.11928", "pdf": "https://arxiv.org/pdf/2405.11928", "abs": "https://arxiv.org/abs/2405.11928", "authors": ["Yiqing Xu", "Jiayuan Mao", "Yilun Du", "Tomas Lozáno-Pérez", "Leslie Pack Kaelbling", "David Hsu"], "title": "\"Set It Up!\": Functional Object Arrangement with Compositional Generative Models", "categories": ["cs.RO", "cs.AI"], "comment": "10 pages main paper, 21 pages appendix, RSS 2024", "summary": "This paper studies the challenge of developing robots capable of\nunderstanding under-specified instructions for creating functional object\narrangements, such as \"set up a dining table for two\"; previous arrangement\napproaches have focused on much more explicit instructions, such as \"put object\nA on the table.\" We introduce a framework, SetItUp, for learning to interpret\nunder-specified instructions. SetItUp takes a small number of training examples\nand a human-crafted program sketch to uncover arrangement rules for specific\nscene types. By leveraging an intermediate graph-like representation of\nabstract spatial relationships among objects, SetItUp decomposes the\narrangement problem into two subproblems: i) learning the arrangement patterns\nfrom limited data and ii) grounding these abstract relationships into object\nposes. SetItUp leverages large language models (LLMs) to propose the abstract\nspatial relationships among objects in novel scenes as the constraints to be\nsatisfied; then, it composes a library of diffusion models associated with\nthese abstract relationships to find object poses that satisfy the constraints.\nWe validate our framework on a dataset comprising study desks, dining tables,\nand coffee tables, with the results showing superior performance in generating\nphysically plausible, functional, and aesthetically pleasing object\narrangements compared to existing models."}
{"id": "2505.06176", "pdf": "https://arxiv.org/pdf/2505.06176", "abs": "https://arxiv.org/abs/2505.06176", "authors": ["Niladri Shekhar Dutt", "Duygu Ceylan", "Niloy J. Mitra"], "title": "MonetGPT: Solving Puzzles Enhances MLLMs' Image Retouching Skills", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": "Accepted at SIGGRAPH 2025 [ACM Transactions on Graphics]; Project\n  website: https://monetgpt.github.io", "summary": "Retouching is an essential task in post-manipulation of raw photographs.\nGenerative editing, guided by text or strokes, provides a new tool accessible\nto users but can easily change the identity of the original objects in\nunacceptable and unpredictable ways. In contrast, although traditional\nprocedural edits, as commonly supported by photoediting tools (e.g., Gimp,\nLightroom), are conservative, they are still preferred by professionals.\nUnfortunately, professional quality retouching involves many individual\nprocedural editing operations that is challenging to plan for most novices. In\nthis paper, we ask if a multimodal large language model (MLLM) can be taught to\ncritique raw photographs, suggest suitable remedies, and finally realize them\nwith a given set of pre-authored procedural image operations. We demonstrate\nthat MLLMs can be first made aware of the underlying image processing\noperations, by training them to solve specially designed visual puzzles.\nSubsequently, such an operation-aware MLLM can both plan and propose edit\nsequences. To facilitate training, given a set of expert-edited photos, we\nsynthesize a reasoning dataset by procedurally manipulating the expert edits\nand then grounding a pretrained LLM on the visual adjustments, to synthesize\nreasoning for finetuning. The proposed retouching operations are, by\nconstruction, understandable by the users, preserve object details and\nresolution, and can be optionally overridden. We evaluate our setup on a\nvariety of test examples and show advantages, in terms of explainability and\nidentity preservation, over existing generative and other procedural\nalternatives. Code, data, models, and supplementary results can be found via\nour project website at https://monetgpt.github.io."}
{"id": "2505.05619", "pdf": "https://arxiv.org/pdf/2505.05619", "abs": "https://arxiv.org/abs/2505.05619", "authors": ["Kalyan Nakka", "Jimmy Dani", "Ausmit Mondal", "Nitesh Saxena"], "title": "LiteLMGuard: Seamless and Lightweight On-Device Prompt Filtering for Safeguarding Small Language Models against Quantization-induced Risks and Vulnerabilities", "categories": ["cs.CR", "cs.LG"], "comment": "14 pages, 18 figures, and 4 tables", "summary": "The growing adoption of Large Language Models (LLMs) has influenced the\ndevelopment of their lighter counterparts-Small Language Models (SLMs)-to\nenable on-device deployment across smartphones and edge devices. These SLMs\noffer enhanced privacy, reduced latency, server-free functionality, and\nimproved user experience. However, due to resource constraints of on-device\nenvironment, SLMs undergo size optimization through compression techniques like\nquantization, which can inadvertently introduce fairness, ethical and privacy\nrisks. Critically, quantized SLMs may respond to harmful queries directly,\nwithout requiring adversarial manipulation, raising significant safety and\ntrust concerns.\n  To address this, we propose LiteLMGuard (LLMG), an on-device prompt guard\nthat provides real-time, prompt-level defense for quantized SLMs. Additionally,\nour prompt guard is designed to be model-agnostic such that it can be\nseamlessly integrated with any SLM, operating independently of underlying\narchitectures. Our LLMG formalizes prompt filtering as a deep learning\n(DL)-based prompt answerability classification task, leveraging semantic\nunderstanding to determine whether a query should be answered by any SLM. Using\nour curated dataset, Answerable-or-Not, we trained and fine-tuned several DL\nmodels and selected ELECTRA as the candidate, with 97.75% answerability\nclassification accuracy.\n  Our safety effectiveness evaluations demonstrate that LLMG defends against\nover 87% of harmful prompts, including both direct instruction and jailbreak\nattack strategies. We further showcase its ability to mitigate the Open\nKnowledge Attacks, where compromised SLMs provide unsafe responses without\nadversarial prompting. In terms of prompt filtering effectiveness, LLMG\nachieves near state-of-the-art filtering accuracy of 94%, with an average\nlatency of 135 ms, incurring negligible overhead for users."}
{"id": "2405.15047", "pdf": "https://arxiv.org/pdf/2405.15047", "abs": "https://arxiv.org/abs/2405.15047", "authors": ["Kaizheng Wang", "Fabio Cuzzolin", "Keivan Shariatmadar", "David Moens", "Hans Hallez"], "title": "Credal Wrapper of Model Averaging for Uncertainty Estimation in Classification", "categories": ["cs.LG", "cs.AI"], "comment": "The 13th International Conference on Learning Representations (ICLR).\n  2025 [Spotlight]", "summary": "This paper presents an innovative approach, called credal wrapper, to\nformulating a credal set representation of model averaging for Bayesian neural\nnetworks (BNNs) and deep ensembles (DEs), capable of improving uncertainty\nestimation in classification tasks. Given a finite collection of single\npredictive distributions derived from BNNs or DEs, the proposed credal wrapper\napproach extracts an upper and a lower probability bound per class,\nacknowledging the epistemic uncertainty due to the availability of a limited\namount of distributions. Such probability intervals over classes can be mapped\non a convex set of probabilities (a credal set) from which, in turn, a unique\nprediction can be obtained using a transformation called intersection\nprobability transformation. In this article, we conduct extensive experiments\non several out-of-distribution (OOD) detection benchmarks, encompassing various\ndataset pairs (CIFAR10/100 vs SVHN/Tiny-ImageNet, CIFAR10 vs CIFAR10-C,\nCIFAR100 vs CIFAR100-C and ImageNet vs ImageNet-O) and using different network\narchitectures (such as VGG16, ResNet-18/50, EfficientNet B2, and ViT Base).\nCompared to the BNN and DE baselines, the proposed credal wrapper method\nexhibits superior performance in uncertainty estimation and achieves a lower\nexpected calibration error on corrupted data."}
{"id": "2505.06227", "pdf": "https://arxiv.org/pdf/2505.06227", "abs": "https://arxiv.org/abs/2505.06227", "authors": ["Yufan Deng", "Yuhao Zhang", "Chen Geng", "Shangzhe Wu", "Jiajun Wu"], "title": "Anymate: A Dataset and Baselines for Learning 3D Object Rigging", "categories": ["cs.GR", "cs.CV"], "comment": "SIGGRAPH 2025. Project page: https://anymate3d.github.io/", "summary": "Rigging and skinning are essential steps to create realistic 3D animations,\noften requiring significant expertise and manual effort. Traditional attempts\nat automating these processes rely heavily on geometric heuristics and often\nstruggle with objects of complex geometry. Recent data-driven approaches show\npotential for better generality, but are often constrained by limited training\ndata. We present the Anymate Dataset, a large-scale dataset of 230K 3D assets\npaired with expert-crafted rigging and skinning information -- 70 times larger\nthan existing datasets. Using this dataset, we propose a learning-based\nauto-rigging framework with three sequential modules for joint, connectivity,\nand skinning weight prediction. We systematically design and experiment with\nvarious architectures as baselines for each module and conduct comprehensive\nevaluations on our dataset to compare their performance. Our models\nsignificantly outperform existing methods, providing a foundation for comparing\nfuture methods in automated rigging and skinning. Code and dataset can be found\nat https://anymate3d.github.io/."}
{"id": "2505.05691", "pdf": "https://arxiv.org/pdf/2505.05691", "abs": "https://arxiv.org/abs/2505.05691", "authors": ["Ruiqi Ni", "Zherong Pan", "Ahmed H Qureshi"], "title": "Physics-informed Temporal Difference Metric Learning for Robot Motion Planning", "categories": ["cs.RO", "cs.LG"], "comment": "Accepted to ICLR 2025", "summary": "The motion planning problem involves finding a collision-free path from a\nrobot's starting to its target configuration. Recently, self-supervised\nlearning methods have emerged to tackle motion planning problems without\nrequiring expensive expert demonstrations. They solve the Eikonal equation for\ntraining neural networks and lead to efficient solutions. However, these\nmethods struggle in complex environments because they fail to maintain key\nproperties of the Eikonal equation, such as optimal value functions and\ngeodesic distances. To overcome these limitations, we propose a novel\nself-supervised temporal difference metric learning approach that solves the\nEikonal equation more accurately and enhances performance in solving complex\nand unseen planning tasks. Our method enforces Bellman's principle of\noptimality over finite regions, using temporal difference learning to avoid\nspurious local minima while incorporating metric learning to preserve the\nEikonal equation's essential geodesic properties. We demonstrate that our\napproach significantly outperforms existing self-supervised learning methods in\nhandling complex environments and generalizing to unseen environments, with\nrobot configurations ranging from 2 to 12 degrees of freedom (DOF)."}
{"id": "2410.01966", "pdf": "https://arxiv.org/pdf/2410.01966", "abs": "https://arxiv.org/abs/2410.01966", "authors": ["Xinlong Hou", "Sen Shen", "Xueshen Li", "Xinran Gao", "Ziyi Huang", "Steven J. Holiday", "Matthew R. Cribbet", "Susan W. White", "Edward Sazonov", "Yu Gan"], "title": "Enhancing Screen Time Identification in Children with a Multi-View Vision Language Model and Screen Time Tracker", "categories": ["cs.CV", "cs.AI"], "comment": "Prepare for submission", "summary": "Being able to accurately monitor the screen exposure of young children is\nimportant for research on phenomena linked to screen use such as childhood\nobesity, physical activity, and social interaction. Most existing studies rely\nupon self-report or manual measures from bulky wearable sensors, thus lacking\nefficiency and accuracy in capturing quantitative screen exposure data. In this\nwork, we developed a novel sensor informatics framework that utilizes\negocentric images from a wearable sensor, termed the screen time tracker (STT),\nand a vision language model (VLM). In particular, we devised a multi-view VLM\nthat takes multiple views from egocentric image sequences and interprets screen\nexposure dynamically. We validated our approach by using a dataset of\nchildren's free-living activities, demonstrating significant improvement over\nexisting methods in plain vision language models and object detection models.\nResults supported the promise of this monitoring approach, which could optimize\nbehavioral research on screen exposure in children's naturalistic settings."}
{"id": "2303.17051", "pdf": "https://arxiv.org/pdf/2303.17051", "abs": "https://arxiv.org/abs/2303.17051", "authors": ["Julio Silva-Rodríguez", "Jose Dolz", "Ismail Ben Ayed"], "title": "Towards Foundation Models and Few-Shot Parameter-Efficient Fine-Tuning for Volumetric Organ Segmentation", "categories": ["cs.CV"], "comment": "Accepted in Medical Image Analysis. The pre-trained model and\n  adaptation code is available at: https://github.com/jusiro/fewshot-finetuning", "summary": "The recent popularity of foundation models and the pre-train-and-adapt\nparadigm, where a large-scale model is transferred to downstream tasks, is\ngaining attention for volumetric medical image segmentation. However, current\ntransfer learning strategies devoted to full fine-tuning for transfer learning\nmay require significant resources and yield sub-optimal results when the\nlabeled data of the target task is scarce. This makes its applicability in real\nclinical settings challenging since these institutions are usually constrained\non data and computational resources to develop proprietary solutions. To\naddress this challenge, we formalize Few-Shot Efficient Fine-Tuning (FSEFT), a\nnovel and realistic scenario for adapting medical image segmentation foundation\nmodels. This setting considers the key role of both data- and\nparameter-efficiency during adaptation. Building on a foundation model\npre-trained on open-access CT organ segmentation sources, we propose leveraging\nParameter-Efficient Fine-Tuning and black-box Adapters to address such\nchallenges. Furthermore, novel efficient adaptation methodologies are\nintroduced in this work, which include Spatial black-box Adapters that are more\nappropriate for dense prediction tasks and constrained transductive inference,\nleveraging task-specific prior knowledge. Our comprehensive transfer learning\nexperiments confirm the suitability of foundation models in medical image\nsegmentation and unveil the limitations of popular fine-tuning strategies in\nfew-shot scenarios."}
{"id": "2505.05694", "pdf": "https://arxiv.org/pdf/2505.05694", "abs": "https://arxiv.org/abs/2505.05694", "authors": ["Ohida Binte Amin", "Varun Mishra", "Tinashe M. Tapera", "Robert Volpe", "Aarti Sathyanarayana"], "title": "Extending Stress Detection Reproducibility to Consumer Wearable Sensors", "categories": ["cs.HC", "cs.LG"], "comment": "Accepted at IEEE EMBC 2025", "summary": "Wearable sensors are widely used to collect physiological data and develop\nstress detection models. However, most studies focus on a single dataset,\nrarely evaluating model reproducibility across devices, populations, or study\nconditions. We previously assessed the reproducibility of stress detection\nmodels across multiple studies, testing models trained on one dataset against\nothers using heart rate (with R-R interval) and electrodermal activity (EDA).\nIn this study, we extended our stress detection reproducibility to consumer\nwearable sensors. We compared validated research-grade devices, to consumer\nwearables - Biopac MP160, Polar H10, Empatica E4, to the Garmin Forerunner 55s,\nassessing device-specific stress detection performance by conducting a new\nstress study on undergraduate students. Thirty-five students completed three\nstandardized stress-induction tasks in a lab setting. Biopac MP160 performed\nthe best, being consistent with our expectations of it as the gold standard,\nthough performance varied across devices and models. Combining heart rate\nvariability (HRV) and EDA enhanced stress prediction across most scenarios.\nHowever, Empatica E4 showed variability; while HRV and EDA improved stress\ndetection in leave-one-subject-out (LOSO) evaluations (AUROC up to 0.953),\ndevice-specific limitations led to underperformance when tested with our\npre-trained stress detection tool (AUROC 0.723), highlighting generalizability\nchallenges related to hardware-model compatibility. Garmin Forerunner 55s\ndemonstrated strong potential for real-world stress monitoring, achieving the\nbest mental arithmetic stress detection performance in LOSO (AUROC up to 0.961)\ncomparable to research-grade devices like Polar H10 (AUROC 0.954), and Empatica\nE4 (AUROC 0.905 with HRV-only model and AUROC 0.953 with HRV+EDA model), with\nthe added advantage of consumer-friendly wearability for free-living contexts."}
{"id": "2410.09186", "pdf": "https://arxiv.org/pdf/2410.09186", "abs": "https://arxiv.org/abs/2410.09186", "authors": ["Noorbakhsh Amiri Golilarz", "Elias Hossain", "Abdoljalil Addeh", "Keyan Alexander Rahimi"], "title": "Learning Algorithms Made Simple", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this paper, we discuss learning algorithms and their importance in\ndifferent types of applications which includes training to identify important\npatterns and features in a straightforward, easy-to-understand manner. We will\nreview the main concepts of artificial intelligence (AI), machine learning\n(ML), deep learning (DL), and hybrid models. Some important subsets of Machine\nLearning algorithms such as supervised, unsupervised, and reinforcement\nlearning are also discussed in this paper. These techniques can be used for\nsome important tasks like prediction, classification, and segmentation.\nConvolutional Neural Networks (CNNs) are used for image and video processing\nand many more applications. We dive into the architecture of CNNs and how to\nintegrate CNNs with ML algorithms to build hybrid models. This paper explores\nthe vulnerability of learning algorithms to noise, leading to\nmisclassification. We further discuss the integration of learning algorithms\nwith Large Language Models (LLM) to generate coherent responses applicable to\nmany domains such as healthcare, marketing, and finance by learning important\npatterns from large volumes of data. Furthermore, we discuss the next\ngeneration of learning algorithms and how we may have an unified Adaptive and\nDynamic Network to perform important tasks. Overall, this article provides\nbrief overview of learning algorithms, exploring their current state,\napplications and future direction."}
{"id": "2404.09957", "pdf": "https://arxiv.org/pdf/2404.09957", "abs": "https://arxiv.org/abs/2404.09957", "authors": ["Hanxue Gu", "Haoyu Dong", "Jichen Yang", "Maciej A. Mazurowski"], "title": "How to build the best medical image segmentation algorithm using foundation models: a comprehensive empirical study with Segment Anything Model", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA)", "summary": "Automated segmentation is a fundamental medical image analysis task, which\nenjoys significant advances due to the advent of deep learning. While\nfoundation models have been useful in natural language processing and some\nvision tasks for some time, the foundation model developed with image\nsegmentation in mind - Segment Anything Model (SAM) - has been developed only\nrecently and has shown similar promise. However, there are still no systematic\nanalyses or \"best-practice\" guidelines for optimal fine-tuning of SAM for\nmedical image segmentation. This work summarizes existing fine-tuning\nstrategies with various backbone architectures, model components, and\nfine-tuning algorithms across 18 combinations, and evaluates them on 17\ndatasets covering all common radiology modalities. Our study reveals that (1)\nfine-tuning SAM leads to slightly better performance than previous segmentation\nmethods, (2) fine-tuning strategies that use parameter-efficient learning in\nboth the encoder and decoder are superior to other strategies, (3) network\narchitecture has a small impact on final performance, (4) further training SAM\nwith self-supervised learning can improve final model performance. We also\ndemonstrate the ineffectiveness of some methods popular in the literature and\nfurther expand our experiments into few-shot and prompt-based settings. Lastly,\nwe released our code and MRI-specific fine-tuned weights, which consistently\nobtained superior performance over the original SAM, at\nhttps://github.com/mazurowski-lab/finetune-SAM."}
{"id": "2505.05713", "pdf": "https://arxiv.org/pdf/2505.05713", "abs": "https://arxiv.org/abs/2505.05713", "authors": ["Jinkun Lin", "Ziheng Jiang", "Zuquan Song", "Sida Zhao", "Menghan Yu", "Zhanghan Wang", "Chenyuan Wang", "Zuocheng Shi", "Xiang Shi", "Wei Jia", "Zherui Liu", "Shuguang Wang", "Haibin Lin", "Xiu Liu", "Aurojit Panda", "Jinyang Li"], "title": "Understanding Stragglers in Large Model Training Using What-if Analysis", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Large language model (LLM) training is one of the most demanding distributed\ncomputations today, often requiring thousands of GPUs with frequent\nsynchronization across machines. Such a workload pattern makes it susceptible\nto stragglers, where the training can be stalled by few slow workers. At\nByteDance we find stragglers are not trivially always caused by hardware\nfailures, but can arise from multiple complex factors. This work aims to\npresent a comprehensive study on the straggler issues in LLM training, using a\nfive-month trace collected from our ByteDance LLM training cluster. The core\nmethodology is what-if analysis that simulates the scenario without any\nstragglers and contrasts with the actual case. We use this method to study the\nfollowing questions: (1) how often do stragglers affect training jobs, and what\neffect do they have on job performance; (2) do stragglers exhibit temporal or\nspatial patterns; and (3) what are the potential root causes for stragglers?"}
{"id": "2410.13415", "pdf": "https://arxiv.org/pdf/2410.13415", "abs": "https://arxiv.org/abs/2410.13415", "authors": ["Mikael Rinkinen", "Lauri Koskinen", "Olli Silven", "Mehdi Safarpour"], "title": "Shavette: Low Power Neural Network Acceleration via Algorithm-level Error Detection and Undervolting", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "Reduced voltage operation is an effective technique for substantial energy\nefficiency improvement in digital circuits. This brief introduces a simple\napproach for enabling reduced voltage operation of Deep Neural Network (DNN)\naccelerators by mere software modifications. Conventional approaches for\nenabling reduced voltage operation e.g., Timing Error Detection (TED) systems,\nincur significant development costs and overheads, while not being applicable\nto the off-the-shelf components. Contrary to those, the solution proposed in\nthis paper relies on algorithm-based error detection, and hence, is implemented\nwith low development costs, does not require any circuit modifications, and is\neven applicable to commodity devices. By showcasing the solution through\nexperimenting on popular DNNs, i.e., LeNet and VGG16, on a GPU platform, we\ndemonstrate 18% to 25% energy saving with no accuracy loss of the models and\nnegligible throughput compromise (< 3.9%), considering the overheads from\nintegration of the error detection schemes into the DNN. The integration of\npresented algorithmic solution into the design is simpler when compared\nconventional TED based techniques that require extensive circuit-level\nmodifications, cell library characterizations or special support from the\ndesign tools."}
{"id": "2404.12734", "pdf": "https://arxiv.org/pdf/2404.12734", "abs": "https://arxiv.org/abs/2404.12734", "authors": ["Da Chang", "Yu Li"], "title": "Mixed Text Recognition with Efficient Parameter Fine-Tuning and Transformer", "categories": ["cs.CV"], "comment": null, "summary": "With the rapid development of OCR technology, mixed-scene text recognition\nhas become a key technical challenge. Although deep learning models have\nachieved significant results in specific scenarios, their generality and\nstability still need improvement, and the high demand for computing resources\naffects flexibility. To address these issues, this paper proposes DLoRA-TrOCR,\na parameter-efficient hybrid text spotting method based on a pre-trained OCR\nTransformer. By embedding a weight-decomposed DoRA module in the image encoder\nand a LoRA module in the text decoder, this method can be efficiently\nfine-tuned on various downstream tasks. Our method requires no more than 0.7\\%\ntrainable parameters, not only accelerating the training efficiency but also\nsignificantly improving the recognition accuracy and cross-dataset\ngeneralization performance of the OCR system in mixed text scenes. Experiments\nshow that our proposed DLoRA-TrOCR outperforms other parameter-efficient\nfine-tuning methods in recognizing complex scenes with mixed handwritten,\nprinted, and street text, achieving a CER of 4.02 on the IAM dataset, a F1\nscore of 94.29 on the SROIE dataset, and a WAR of 86.70 on the STR Benchmark,\nreaching state-of-the-art performance."}
{"id": "2505.05816", "pdf": "https://arxiv.org/pdf/2505.05816", "abs": "https://arxiv.org/abs/2505.05816", "authors": ["Antti Koskela", "Mohamed Seif", "Andrea J. Goldsmith"], "title": "On the Price of Differential Privacy for Spectral Clustering over Stochastic Block Models", "categories": ["cs.SI", "cs.CR", "cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "We investigate privacy-preserving spectral clustering for community detection\nwithin stochastic block models (SBMs). Specifically, we focus on edge\ndifferential privacy (DP) and propose private algorithms for community\nrecovery. Our work explores the fundamental trade-offs between the privacy\nbudget and the accurate recovery of community labels. Furthermore, we establish\ninformation-theoretic conditions that guarantee the accuracy of our methods,\nproviding theoretical assurances for successful community recovery under edge\nDP."}
{"id": "2412.04378", "pdf": "https://arxiv.org/pdf/2412.04378", "abs": "https://arxiv.org/abs/2412.04378", "authors": ["Yassine Ouali", "Adrian Bulat", "Alexandros Xenos", "Anestis Zaganidis", "Ioannis Maniadis Metaxas", "Brais Martinez", "Georgios Tzimiropoulos"], "title": "VladVA: Discriminative Fine-tuning of LVLMs", "categories": ["cs.CV", "cs.AI"], "comment": "Published at CVPR 2025", "summary": "Contrastively-trained Vision-Language Models (VLMs) like CLIP have become the\nde facto approach for discriminative vision-language representation learning.\nHowever, these models have limited language understanding, often exhibiting a\n\"bag of words\" behavior. At the same time, Large Vision-Language Models\n(LVLMs), which combine vision encoders with LLMs, have been shown to be capable\nof detailed vision-language reasoning, yet their autoregressive nature renders\nthem less suitable for discriminative tasks.\n  In this work, we propose to combine \"the best of both worlds\": a new training\napproach for discriminative fine-tuning of LVLMs that results in strong\ndiscriminative and compositional capabilities. Essentially, our approach\nconverts a generative LVLM into a discriminative one, unlocking its capability\nfor powerful image-text discrimination combined with enhanced language\nunderstanding.\n  Our contributions include (1) a carefully designed training/optimization\nframework that utilizes image-text pairs of variable length and granularity for\ntraining the model with both contrastive and next-token prediction losses. This\nis accompanied by ablation studies that justify the necessity of our\nframework's components; (2) a parameter-efficient adaptation method using a\ncombination of soft prompting and LoRA adapters; (3) significant improvements\nover state-of-the-art CLIP-like models of similar size, including standard\nimage-text retrieval benchmarks and notable gains in compositionality."}
{"id": "2405.13745", "pdf": "https://arxiv.org/pdf/2405.13745", "abs": "https://arxiv.org/abs/2405.13745", "authors": ["Qiujie Dong", "Huibiao Wen", "Rui Xu", "Shuangmin Chen", "Jiaran Zhou", "Shiqing Xin", "Changhe Tu", "Taku Komura", "Wenping Wang"], "title": "NeurCross: A Neural Approach to Computing Cross Fields for Quad Mesh Generation", "categories": ["cs.CV"], "comment": "SIGGRAPH 2025", "summary": "Quadrilateral mesh generation plays a crucial role in numerical simulations\nwithin Computer-Aided Design and Engineering (CAD/E). Producing high-quality\nquadrangulation typically requires satisfying four key criteria. First, the\nquadrilateral mesh should closely align with principal curvature directions.\nSecond, singular points should be strategically placed and effectively\nminimized. Third, the mesh should accurately conform to sharp feature edges.\nLastly, quadrangulation results should exhibit robustness against noise and\nminor geometric variations. Existing methods generally involve first computing\na regular cross field to represent quad element orientations across the\nsurface, followed by extracting a quadrilateral mesh aligned closely with this\ncross field. A primary challenge with this approach is balancing the smoothness\nof the cross field with its alignment to pre-computed principal curvature\ndirections, which are sensitive to small surface perturbations and often\nill-defined in spherical or planar regions.\n  To tackle this challenge, we propose NeurCross, a novel framework that\nsimultaneously optimizes a cross field and a neural signed distance function\n(SDF), whose zero-level set serves as a proxy of the input shape. Our joint\noptimization is guided by three factors: faithful approximation of the\noptimized SDF surface to the input surface, alignment between the cross field\nand the principal curvature field derived from the SDF surface, and smoothness\nof the cross field. Acting as an intermediary, the neural SDF contributes in\ntwo essential ways. First, it provides an alternative, optimizable base surface\nexhibiting more regular principal curvature directions for guiding the cross\nfield. Second, we leverage the Hessian matrix of the neural SDF to implicitly\nenforce cross field alignment with principal curvature directions..."}
{"id": "2505.05842", "pdf": "https://arxiv.org/pdf/2505.05842", "abs": "https://arxiv.org/abs/2505.05842", "authors": ["Yun Xin", "Jianfeng Lu", "Shuqin Cao", "Gang Li", "Haozhao Wang", "Guanghui Wen"], "title": "DaringFed: A Dynamic Bayesian Persuasion Pricing for Online Federated Learning under Two-sided Incomplete Information", "categories": ["cs.GT", "cs.LG", "stat.ML"], "comment": null, "summary": "Online Federated Learning (OFL) is a real-time learning paradigm that\nsequentially executes parameter aggregation immediately for each random\narriving client. To motivate clients to participate in OFL, it is crucial to\noffer appropriate incentives to offset the training resource consumption.\nHowever, the design of incentive mechanisms in OFL is constrained by the\ndynamic variability of Two-sided Incomplete Information (TII) concerning\nresources, where the server is unaware of the clients' dynamically changing\ncomputational resources, while clients lack knowledge of the real-time\ncommunication resources allocated by the server. To incentivize clients to\nparticipate in training by offering dynamic rewards to each arriving client, we\ndesign a novel Dynamic Bayesian persuasion pricing for online Federated\nlearning (DaringFed) under TII. Specifically, we begin by formulating the\ninteraction between the server and clients as a dynamic signaling and pricing\nallocation problem within a Bayesian persuasion game, and then demonstrate the\nexistence of a unique Bayesian persuasion Nash equilibrium. By deriving the\noptimal design of DaringFed under one-sided incomplete information, we further\nanalyze the approximate optimal design of DaringFed with a specific bound under\nTII. Finally, extensive evaluation conducted on real datasets demonstrate that\nDaringFed optimizes accuracy and converges speed by 16.99%, while experiments\nwith synthetic datasets validate the convergence of estimate unknown values and\nthe effectiveness of DaringFed in improving the server's utility by up to\n12.6%."}
{"id": "2501.03119", "pdf": "https://arxiv.org/pdf/2501.03119", "abs": "https://arxiv.org/abs/2501.03119", "authors": ["Chao Feng", "Yuanzhe Gao", "Alberto Huertas Celdran", "Gerome Bovet", "Burkhard Stiller"], "title": "From Models to Network Topologies: A Topology Inference Attack in Decentralized Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated Learning (FL) is widely recognized as a privacy-preserving machine\nlearning paradigm due to its model-sharing mechanism that avoids direct data\nexchange. Nevertheless, model training leaves exploitable traces that can be\nused to infer sensitive information. In Decentralized FL (DFL), the topology,\ndefining how participants are connected, plays a crucial role in shaping the\nmodel's privacy, robustness, and convergence. However, the topology introduces\nan unexplored vulnerability: attackers can exploit it to infer participant\nrelationships and launch targeted attacks. This work uncovers the hidden risks\nof DFL topologies by proposing a novel Topology Inference Attack that infers\nthe topology solely from model behavior. A taxonomy of topology inference\nattacks is introduced, categorizing them by the attacker's capabilities and\nknowledge. Practical attack strategies are designed for various scenarios, and\nexperiments are conducted to identify key factors influencing attack success.\nThe results demonstrate that analyzing only the model of each node can\naccurately infer the DFL topology, highlighting a critical privacy risk in DFL\nsystems. These findings offer valuable insights for improving privacy\npreservation in DFL environments."}
{"id": "2407.06188", "pdf": "https://arxiv.org/pdf/2407.06188", "abs": "https://arxiv.org/abs/2407.06188", "authors": ["Yukang Cao", "Xinying Guo", "Mingyuan Zhang", "Haozhe Xie", "Chenyang Gu", "Ziwei Liu"], "title": "CrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation", "categories": ["cs.CV"], "comment": "Project page: https://yukangcao.github.io/CrowdMoGen", "summary": "While recent advances in text-to-motion generation have shown promising\nresults, they typically assume all individuals are grouped as a single unit.\nScaling these methods to handle larger crowds and ensuring that individuals\nrespond appropriately to specific events remains a significant challenge. This\nis primarily due to the complexities of scene planning, which involves\norganizing groups, planning their activities, and coordinating interactions,\nand controllable motion generation. In this paper, we present CrowdMoGen, the\nfirst zero-shot framework for collective motion generation, which effectively\ngroups individuals and generates event-aligned motion sequences from text\nprompts. 1) Being limited by the available datasets for training an effective\nscene planning module in a supervised manner, we instead propose a crowd scene\nplanner that leverages pre-trained large language models (LLMs) to organize\nindividuals into distinct groups. While LLMs offer high-level guidance for\ngroup divisions, they lack the low-level understanding of human motion. To\naddress this, we further propose integrating an SMPL-based joint prior to\ngenerate context-appropriate activities, which consists of both joint\ntrajectories and textual descriptions. 2) Secondly, to incorporate the assigned\nactivities into the generative network, we introduce a collective motion\ngenerator that integrates the activities into a transformer-based network in a\njoint-wise manner, maintaining the spatial constraints during the multi-step\ndenoising process. Extensive experiments demonstrate that CrowdMoGen\nsignificantly outperforms previous approaches, delivering realistic,\nevent-driven motion sequences that are spatially coherent. As the first\nframework of collective motion generation, CrowdMoGen has the potential to\nadvance applications in urban simulation, crowd planning, and other large-scale\ninteractive environments."}
{"id": "2505.05851", "pdf": "https://arxiv.org/pdf/2505.05851", "abs": "https://arxiv.org/abs/2505.05851", "authors": ["Janik Kaden", "Maximilian Hilger", "Tim Schreiter", "Marius Schaab", "Thomas Graichen", "Andrey Rudenko", "Ulrich Heinkel", "Achim J. Lilienthal"], "title": "Collecting Human Motion Data in Large and Occlusion-Prone Environments using Ultra-Wideband Localization", "categories": ["cs.RO", "cs.HC", "cs.LG"], "comment": "accepted for presentation at the 7th Workshop on Long-term Human\n  Motion Prediction (LHMP) at International Conference on Robotics and\n  Automation (ICRA) 2025", "summary": "With robots increasingly integrating into human environments, understanding\nand predicting human motion is essential for safe and efficient interactions.\nModern human motion and activity prediction approaches require high quality and\nquantity of data for training and evaluation, usually collected from motion\ncapture systems, onboard or stationary sensors. Setting up these systems is\nchallenging due to the intricate setup of hardware components, extensive\ncalibration procedures, occlusions, and substantial costs. These constraints\nmake deploying such systems in new and large environments difficult and limit\ntheir usability for in-the-wild measurements. In this paper we investigate the\npossibility to apply the novel Ultra-Wideband (UWB) localization technology as\na scalable alternative for human motion capture in crowded and occlusion-prone\nenvironments. We include additional sensing modalities such as eye-tracking,\nonboard robot LiDAR and radar sensors, and record motion capture data as ground\ntruth for evaluation and comparison. The environment imitates a museum setup,\nwith up to four active participants navigating toward random goals in a natural\nway, and offers more than 130 minutes of multi-modal data. Our investigation\nprovides a step toward scalable and accurate motion data collection beyond\nvision-based systems, laying a foundation for evaluating sensing modalities\nlike UWB in larger and complex environments like warehouses, airports, or\nconvention centers."}
{"id": "2501.13986", "pdf": "https://arxiv.org/pdf/2501.13986", "abs": "https://arxiv.org/abs/2501.13986", "authors": ["Vivek Bharadwaj", "Austin Glover", "Aydin Buluc", "James Demmel"], "title": "An Efficient Sparse Kernel Generator for O(3)-Equivariant Deep Networks", "categories": ["cs.LG", "cs.AI"], "comment": "To appear in the Proceedings of the 2025 SIAM Conference on Applied\n  and Computational Discrete Algorithms. 15 pages, 10 figures, 4 tables", "summary": "Rotation equivariant graph neural networks, i.e. networks designed to\nguarantee certain geometric relations between their inputs and outputs, yield\nstate of the art performance on spatial deep learning tasks. They exhibit high\ndata efficiency during training and significantly reduced inference time for\ninteratomic potential calculations compared to classical approaches. Key to\nthese models is the Clebsch-Gordon (CG) tensor product, a kernel that contracts\ntwo dense feature vectors with a highly-structured sparse tensor to produce a\ndense output vector. The operation, which may be repeated millions of times for\ntypical equivariant models, is a costly and inefficient bottleneck. We\nintroduce a GPU sparse kernel generator for the CG tensor product that provides\nsignificant speedups over the best existing open and closed-source\nimplementations. Our implementation achieves high performance by carefully\nmanaging the limited GPU shared memory through static analysis at model\ncompile-time, minimizing reads and writes to global memory. We break the tensor\nproduct into a series of smaller kernels with operands that fit entirely into\nregisters, enabling us to emit long arithmetic instruction streams that\nmaximize instruction-level parallelism. By fusing the CG tensor product with a\nsubsequent graph convolution, we reduce both intermediate storage and global\nmemory traffic over naive approaches that duplicate input data. We also provide\noptimized kernels for the gradient of the CG tensor product and a novel\nidentity for the higher partial derivatives required to predict interatomic\nforces. Our kernels offer up to 1.3x speedup over NVIDIA's closed-source\ncuEquivariance package, as well as 10x speedup over the widely-used e3nn\npackage. In FP64 precision, we offer up to 6.2x inference-time speedup for the\nMACE chemistry foundation model over the original unoptimized version."}
{"id": "2407.11243", "pdf": "https://arxiv.org/pdf/2407.11243", "abs": "https://arxiv.org/abs/2407.11243", "authors": ["Mang Ning", "Albert Ali Salah", "Itir Onal Ertugrul"], "title": "Representation Learning and Identity Adversarial Training for Facial Behavior Understanding", "categories": ["cs.CV"], "comment": "FG 2025", "summary": "Facial Action Unit (AU) detection has gained significant attention as it\nenables the breakdown of complex facial expressions into individual muscle\nmovements. In this paper, we revisit two fundamental factors in AU detection:\ndiverse and large-scale data and subject identity regularization. Motivated by\nrecent advances in foundation models, we highlight the importance of data and\nintroduce Face9M, a diverse dataset comprising 9 million facial images from\nmultiple public sources. Pretraining a masked autoencoder on Face9M yields\nstrong performance in AU detection and facial expression tasks. More\nimportantly, we emphasize that the Identity Adversarial Training (IAT) has not\nbeen well explored in AU tasks. To fill this gap, we first show that subject\nidentity in AU datasets creates shortcut learning for the model and leads to\nsub-optimal solutions to AU predictions. Secondly, we demonstrate that strong\nIAT regularization is necessary to learn identity-invariant features. Finally,\nwe elucidate the design space of IAT and empirically show that IAT circumvents\nthe identity-based shortcut learning and results in a better solution. Our\nproposed methods, Facial Masked Autoencoder (FMAE) and IAT, are simple, generic\nand effective. Remarkably, the proposed FMAE-IAT approach achieves new\nstate-of-the-art F1 scores on BP4D (67.1\\%), BP4D+ (66.8\\%), and DISFA (70.1\\%)\ndatabases, significantly outperforming previous work. We release the code and\nmodel at https://github.com/forever208/FMAE-IAT."}
{"id": "2505.05872", "pdf": "https://arxiv.org/pdf/2505.05872", "abs": "https://arxiv.org/abs/2505.05872", "authors": ["Aqsa Shabbir", "Halil İbrahim Kanpak", "Alptekin Küpçü", "Sinem Sav"], "title": "A Taxonomy of Attacks and Defenses in Split Learning", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Split Learning (SL) has emerged as a promising paradigm for distributed deep\nlearning, allowing resource-constrained clients to offload portions of their\nmodel computation to servers while maintaining collaborative learning. However,\nrecent research has demonstrated that SL remains vulnerable to a range of\nprivacy and security threats, including information leakage, model inversion,\nand adversarial attacks. While various defense mechanisms have been proposed, a\nsystematic understanding of the attack landscape and corresponding\ncountermeasures is still lacking. In this study, we present a comprehensive\ntaxonomy of attacks and defenses in SL, categorizing them along three key\ndimensions: employed strategies, constraints, and effectiveness. Furthermore,\nwe identify key open challenges and research gaps in SL based on our\nsystematization, highlighting potential future directions."}
{"id": "2502.08149", "pdf": "https://arxiv.org/pdf/2502.08149", "abs": "https://arxiv.org/abs/2502.08149", "authors": ["Cuong Manh Hoang", "Yeejin Lee", "Byeongkeun Kang"], "title": "Generalized Class Discovery in Instance Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "AAAI 2025", "summary": "This work addresses the task of generalized class discovery (GCD) in instance\nsegmentation. The goal is to discover novel classes and obtain a model capable\nof segmenting instances of both known and novel categories, given labeled and\nunlabeled data. Since the real world contains numerous objects with long-tailed\ndistributions, the instance distribution for each class is inherently\nimbalanced. To address the imbalanced distributions, we propose an\ninstance-wise temperature assignment (ITA) method for contrastive learning and\nclass-wise reliability criteria for pseudo-labels. The ITA method relaxes\ninstance discrimination for samples belonging to head classes to enhance GCD.\nThe reliability criteria are to avoid excluding most pseudo-labels for tail\nclasses when training an instance segmentation network using pseudo-labels from\nGCD. Additionally, we propose dynamically adjusting the criteria to leverage\ndiverse samples in the early stages while relying only on reliable\npseudo-labels in the later stages. We also introduce an efficient soft\nattention module to encode object-specific representations for GCD. Finally, we\nevaluate our proposed method by conducting experiments on two settings:\nCOCO$_{half}$ + LVIS and LVIS + Visual Genome. The experimental results\ndemonstrate that the proposed method outperforms previous state-of-the-art\nmethods."}
{"id": "2407.16291", "pdf": "https://arxiv.org/pdf/2407.16291", "abs": "https://arxiv.org/abs/2407.16291", "authors": ["Hongyang Li", "Hao Zhang", "Shilong Liu", "Zhaoyang Zeng", "Feng Li", "Tianhe Ren", "Bohan Li", "Lei Zhang"], "title": "TAPTRv2: Attention-based Position Update Improves Tracking Any Point", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "In this paper, we present TAPTRv2, a Transformer-based approach built upon\nTAPTR for solving the Tracking Any Point (TAP) task. TAPTR borrows designs from\nDEtection TRansformer (DETR) and formulates each tracking point as a point\nquery, making it possible to leverage well-studied operations in DETR-like\nalgorithms. TAPTRv2 improves TAPTR by addressing a critical issue regarding its\nreliance on cost-volume,which contaminates the point query\\'s content feature\nand negatively impacts both visibility prediction and cost-volume computation.\nIn TAPTRv2, we propose a novel attention-based position update (APU) operation\nand use key-aware deformable attention to realize. For each query, this\noperation uses key-aware attention weights to combine their corresponding\ndeformable sampling positions to predict a new query position. This design is\nbased on the observation that local attention is essentially the same as\ncost-volume, both of which are computed by dot-production between a query and\nits surrounding features. By introducing this new operation, TAPTRv2 not only\nremoves the extra burden of cost-volume computation, but also leads to a\nsubstantial performance improvement. TAPTRv2 surpasses TAPTR and achieves\nstate-of-the-art performance on many challenging datasets, demonstrating the\nsuperiority"}
{"id": "2505.05922", "pdf": "https://arxiv.org/pdf/2505.05922", "abs": "https://arxiv.org/abs/2505.05922", "authors": ["Haoqi Wu", "Wei Dai", "Li Wang", "Qiang Yan"], "title": "CAPE: Context-Aware Prompt Perturbation Mechanism with Differential Privacy", "categories": ["cs.CR", "cs.LG"], "comment": "to be published in ICML 2025", "summary": "Large Language Models (LLMs) have gained significant popularity due to their\nremarkable capabilities in text understanding and generation. However, despite\ntheir widespread deployment in inference services such as ChatGPT, concerns\nabout the potential leakage of sensitive user data have arisen. Existing\nsolutions primarily rely on privacy-enhancing technologies to mitigate such\nrisks, facing the trade-off among efficiency, privacy, and utility. To narrow\nthis gap, we propose Cape, a context-aware prompt perturbation mechanism based\non differential privacy, to enable efficient inference with an improved\nprivacy-utility trade-off. Concretely, we introduce a hybrid utility function\nthat better captures the token similarity. Additionally, we propose a\nbucketized sampling mechanism to handle large sampling space, which might lead\nto long-tail phenomenons. Extensive experiments across multiple datasets, along\nwith ablation studies, demonstrate that Cape achieves a better privacy-utility\ntrade-off compared to prior state-of-the-art works."}
{"id": "2502.10436", "pdf": "https://arxiv.org/pdf/2502.10436", "abs": "https://arxiv.org/abs/2502.10436", "authors": ["Tommaso Mencattini", "Adrian Robert Minut", "Donato Crisostomi", "Andrea Santilli", "Emanuele Rodolà"], "title": "MERGE$^3$: Efficient Evolutionary Merging on Consumer-grade GPUs", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": "In Proceedings of The Forty-Second International Conference on\n  Machine Learning (ICML 2025)", "summary": "Evolutionary model merging enables the creation of high-performing multi-task\nmodels but remains computationally prohibitive for consumer hardware. We\nintroduce MERGE$^3$, an efficient framework that makes evolutionary merging\nfeasible on a single GPU by reducing fitness computation costs 50$\\times$ while\npreserving performance. MERGE$^3$ achieves this by Extracting a reduced dataset\nfor evaluation, Estimating model abilities using Item Response Theory (IRT),\nand Evolving optimal merges via IRT-based performance estimators. Our method\nenables state-of-the-art multilingual and cross-lingual merging, transferring\nknowledge across languages with significantly lower computational overhead. We\nprovide theoretical guarantees and an open-source library, democratizing\nhigh-quality model merging."}
{"id": "2409.07967", "pdf": "https://arxiv.org/pdf/2409.07967", "abs": "https://arxiv.org/abs/2409.07967", "authors": ["Ling Xing", "Hongyu Qu", "Rui Yan", "Xiangbo Shu", "Jinhui Tang"], "title": "Locality-aware Cross-modal Correspondence Learning for Dense Audio-Visual Events Localization", "categories": ["cs.CV"], "comment": null, "summary": "Dense-localization Audio-Visual Events (DAVE) aims to identify time\nboundaries and corresponding categories for events that are both audible and\nvisible in a long video, where events may co-occur and exhibit varying\ndurations. However, complex audio-visual scenes often involve asynchronization\nbetween modalities, making accurate localization challenging. Existing DAVE\nsolutions extract audio and visual features through unimodal encoders, and fuse\nthem via dense cross-modal interaction. However, independent unimodal encoding\nstruggles to emphasize shared semantics between modalities without cross-modal\nguidance, while dense cross-modal attention may over-attend to semantically\nunrelated audio-visual features. To address these problems, we present LoCo, a\nLocality-aware cross-modal Correspondence learning framework for DAVE. LoCo\nleverages the local temporal continuity of audio-visual events as important\nguidance to filter irrelevant cross-modal signals and enhance cross-modal\nalignment throughout both unimodal and cross-modal encoding stages. i)\nSpecifically, LoCo applies Local Correspondence Feature (LCF) Modulation to\nenforce unimodal encoders to focus on modality-shared semantics by modulating\nagreement between audio and visual features based on local cross-modal\ncoherence. ii) To better aggregate cross-modal relevant features, we further\ncustomize Local Adaptive Cross-modal (LAC) Interaction, which dynamically\nadjusts attention regions in a data-driven manner. This adaptive mechanism\nfocuses attention on local event boundaries and accommodates varying event\ndurations. By incorporating LCF and LAC, LoCo provides solid performance gains\nand outperforms existing DAVE methods."}
{"id": "2505.05956", "pdf": "https://arxiv.org/pdf/2505.05956", "abs": "https://arxiv.org/abs/2505.05956", "authors": ["Xiyu Wang", "Gilberto Berardinelli", "Hei Victor Cheng", "Petar Popovski", "Ramoni Adeogun"], "title": "Multi-User Beamforming with Deep Reinforcement Learning in Sensing-Aided Communication", "categories": ["eess.SP", "cs.LG", "cs.NI"], "comment": "Accepted for Presentation at IEEE EuCNC & 6G Summit 2025", "summary": "Mobile users are prone to experience beam failure due to beam drifting in\nmillimeter wave (mmWave) communications. Sensing can help alleviate beam\ndrifting with timely beam changes and low overhead since it does not need user\nfeedback. This work studies the problem of optimizing sensing-aided\ncommunication by dynamically managing beams allocated to mobile users. A\nmulti-beam scheme is introduced, which allocates multiple beams to the users\nthat need an update on the angle of departure (AoD) estimates and a single beam\nto the users that have satisfied AoD estimation precision. A deep reinforcement\nlearning (DRL) assisted method is developed to optimize the beam allocation\npolicy, relying only upon the sensing echoes. For comparison, a heuristic\nAoD-based method using approximated Cram\\'er-Rao lower bound (CRLB) for\nallocation is also presented. Both methods require neither user feedback nor\nprior state evolution information. Results show that the DRL-assisted method\nachieves a considerable gain in throughput than the conventional beam sweeping\nmethod and the AoD-based method, and it is robust to different user speeds."}
{"id": "2503.11711", "pdf": "https://arxiv.org/pdf/2503.11711", "abs": "https://arxiv.org/abs/2503.11711", "authors": ["Ehsan Latif", "Xiaoming Zhai"], "title": "Privacy-Preserved Automated Scoring using Federated Learning for Educational Research", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to AIED25", "summary": "Data privacy remains a critical concern in educational research, requiring\nstrict adherence to ethical standards and regulatory protocols. While\ntraditional approaches rely on anonymization and centralized data collection,\nthey often expose raw student data to security vulnerabilities and impose\nsubstantial logistical overhead. In this study, we propose a federated learning\n(FL) framework for automated scoring of educational assessments that eliminates\nthe need to share sensitive data across institutions. Our approach leverages\nparameter-efficient fine-tuning of large language models (LLMs) with Low-Rank\nAdaptation (LoRA), enabling each client (school) to train locally while sharing\nonly optimized model updates. To address data heterogeneity, we implement an\nadaptive weighted aggregation strategy that considers both client performance\nand data volume. We benchmark our model against two state-of-the-art FL methods\nand a centralized learning baseline using NGSS-aligned multi-label science\nassessment data from nine middle schools. Results show that our model achieves\nthe highest accuracy (94.5%) among FL approaches, and performs within 0.5-1.0\npercentage points of the centralized model on these metrics. Additionally, it\nachieves comparable rubric-level scoring accuracy, with only a 1.3% difference\nin rubric match and a lower score deviation (MAE), highlighting its\neffectiveness in preserving both prediction quality and interpretability."}
{"id": "2409.08840", "pdf": "https://arxiv.org/pdf/2409.08840", "abs": "https://arxiv.org/abs/2409.08840", "authors": ["Yihang Tao", "Senkang Hu", "Zhengru Fang", "Yuguang Fang"], "title": "Directed-CP: Directed Collaborative Perception for Connected and Autonomous Vehicles via Proactive Attention", "categories": ["cs.CV"], "comment": "Accepted by ICRA'25", "summary": "Collaborative perception (CP) leverages visual data from connected and\nautonomous vehicles (CAV) to enhance an ego vehicle's field of view (FoV).\nDespite recent progress, current CP methods expand the ego vehicle's 360-degree\nperceptual range almost equally, which faces two key challenges. Firstly, in\nareas with uneven traffic distribution, focusing on directions with little\ntraffic offers limited benefits. Secondly, under limited communication budgets,\nallocating excessive bandwidth to less critical directions lowers the\nperception accuracy in more vital areas. To address these issues, we propose\nDirect-CP, a proactive and direction-aware CP system aiming at improving CP in\nspecific directions. Our key idea is to enable an ego vehicle to proactively\nsignal its interested directions and readjust its attention to enhance local\ndirectional CP performance. To achieve this, we first propose an RSU-aided\ndirection masking mechanism that assists an ego vehicle in identifying vital\ndirections. Additionally, we design a direction-aware selective attention\nmodule to wisely aggregate pertinent features based on ego vehicle's\ndirectional priorities, communication budget, and the positional data of CAVs.\nMoreover, we introduce a direction-weighted detection loss (DWLoss) to capture\nthe divergence between directional CP outcomes and the ground truth,\nfacilitating effective model training. Extensive experiments on the V2X-Sim 2.0\ndataset demonstrate that our approach achieves 19.8\\% higher local perception\naccuracy in interested directions and 2.5\\% higher overall perception accuracy\nthan the state-of-the-art methods in collaborative 3D object detection tasks."}
{"id": "2505.05989", "pdf": "https://arxiv.org/pdf/2505.05989", "abs": "https://arxiv.org/abs/2505.05989", "authors": ["Hongye Zheng", "Yue Xing", "Lipeng Zhu", "Xu Han", "Junliang Du", "Wanyu Cui"], "title": "Modeling Multi-Hop Semantic Paths for Recommendation in Heterogeneous Information Networks", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "This study focuses on the problem of path modeling in heterogeneous\ninformation networks and proposes a multi-hop path-aware recommendation\nframework. The method centers on multi-hop paths composed of various types of\nentities and relations. It models user preferences through three stages: path\nselection, semantic representation, and attention-based fusion. In the path\nselection stage, a path filtering mechanism is introduced to remove redundant\nand noisy information. In the representation learning stage, a sequential\nmodeling structure is used to jointly encode entities and relations, preserving\nthe semantic dependencies within paths. In the fusion stage, an attention\nmechanism assigns different weights to each path to generate a global user\ninterest representation. Experiments conducted on real-world datasets such as\nAmazon-Book show that the proposed method significantly outperforms existing\nrecommendation models across multiple evaluation metrics, including HR@10,\nRecall@10, and Precision@10. The results confirm the effectiveness of multi-hop\npaths in capturing high-order interaction semantics and demonstrate the\nexpressive modeling capabilities of the framework in heterogeneous\nrecommendation scenarios. This method provides both theoretical and practical\nvalue by integrating structural information modeling in heterogeneous networks\nwith recommendation algorithm design. It offers a more expressive and flexible\nparadigm for learning user preferences in complex data environments."}
{"id": "2504.14411", "pdf": "https://arxiv.org/pdf/2504.14411", "abs": "https://arxiv.org/abs/2504.14411", "authors": ["Xiang Zhang", "Yongfeng Zhang"], "title": "Planet as a Brain: Towards Internet of AgentSites based on AIOS Server", "categories": ["cs.NI", "cs.AI"], "comment": null, "summary": "The internet is undergoing a historical transformation from the \"Internet of\nWebsites\" to the \"Internet of AgentSites.\" While traditional Websites served as\nthe foundation for information hosting and dissemination, a new frontier is\nemerging where AgentSites serve as the hubs of the internet, where each\nAgentSite hosts one or more AI agents that receive tasks, address them, and\ndeliver actionable solutions, marking a significant shift in the digital\nlandscape and representing the next generation of online ecosystems. Under this\nvision, AIOS, the AI Agent Operating System, serves as the server for the\ndevelopment, deployment and execution of AI agents, which is a fundamental\ninfrastructure for the Internet of Agentsites.\n  In this paper, we introduce AIOS Server, a runtime framework to host agents\nand enable global-scale collaboration among decentralized agents. AIOS Server\nprovides a communication protocol leveraging the Model Context Protocol (MCP)\nand JSON-RPC to enable agent-agent or human-agent interactions. Each AIOS node\noperates as a server to host and execute agents, while supporting peer-to-peer\ncoordination without reliance on centralized orchestration. Based on AIOS\nServer, we further present the world's first practically deployed Internet of\nAgentsites (AIOS-IoA), including AgentHub for agent registration and discovery\nand AgentChat for interactive communication, at https://planet.aios.foundation.\nThe agent discovery mechanism based on Distributed Hash Tables (DHT) and a\nGossip protocol serves as the search engine for the internet of agentsites.\nThis work provides a practical foundation for building the Internet of\nAgentsites-a new paradigm where autonomous agents become first-class citizens\nof the web. The implementation is available at\nhttps://github.com/agiresearch/AIOS.Server and is integrated into the AIOS main\nbranch at https://github.com/agiresearch/AIOS."}
{"id": "2410.20621", "pdf": "https://arxiv.org/pdf/2410.20621", "abs": "https://arxiv.org/abs/2410.20621", "authors": ["Anirudh Thatipelli", "Shao-Yuan Lo", "Amit K. Roy-Chowdhury"], "title": "Egocentric and Exocentric Methods: A Short Survey", "categories": ["cs.CV"], "comment": "Accepted in Computer Vision and Image Understanding (CVIU), 2025", "summary": "Egocentric vision captures the scene from the point of view of the camera\nwearer, while exocentric vision captures the overall scene context. Jointly\nmodeling ego and exo views is crucial to developing next-generation AI agents.\nThe community has regained interest in the field of egocentric vision. While\nthe third-person view and first-person have been thoroughly investigated, very\nfew works aim to study both synchronously. Exocentric videos contain many\nrelevant signals that are transferrable to egocentric videos. This paper\nprovides a timely overview of works combining egocentric and exocentric\nvisions, a very new but promising research topic. We describe in detail the\ndatasets and present a survey of the key applications of ego-exo joint\nlearning, where we identify the most recent advances. With the presentation of\nthe current status of the progress, we believe this short but timely survey\nwill be valuable to the broad video-understanding community, particularly when\nmulti-view modeling is critical."}
{"id": "2505.06146", "pdf": "https://arxiv.org/pdf/2505.06146", "abs": "https://arxiv.org/abs/2505.06146", "authors": ["Idan Attias", "Xing Gao", "Lev Reyzin"], "title": "Learning-Augmented Algorithms for Boolean Satisfiability", "categories": ["cs.DS", "cs.CC", "cs.LG"], "comment": null, "summary": "Learning-augmented algorithms are a prominent recent development in beyond\nworst-case analysis. In this framework, a problem instance is provided with a\nprediction (``advice'') from a machine-learning oracle, which provides partial\ninformation about an optimal solution, and the goal is to design algorithms\nthat leverage this advice to improve worst-case performance. We study the\nclassic Boolean satisfiability (SAT) decision and optimization problems within\nthis framework using two forms of advice. ``Subset advice\" provides a random\n$\\epsilon$ fraction of the variables from an optimal assignment, whereas\n``label advice\" provides noisy predictions for all variables in an optimal\nassignment.\n  For the decision problem $k$-SAT, by using the subset advice we accelerate\nthe exponential running time of the PPSZ family of algorithms due to Paturi,\nPudlak, Saks and Zane, which currently represent the state of the art in the\nworst case. We accelerate the running time by a multiplicative factor of\n$2^{-c}$ in the base of the exponent, where $c$ is a function of $\\epsilon$ and\n$k$. For the optimization problem, we show how to incorporate subset advice in\na black-box fashion with any $\\alpha$-approximation algorithm, improving the\napproximation ratio to $\\alpha + (1 - \\alpha)\\epsilon$. Specifically, we\nachieve approximations of $0.94 + \\Omega(\\epsilon)$ for MAX-$2$-SAT, $7/8 +\n\\Omega(\\epsilon)$ for MAX-$3$-SAT, and $0.79 + \\Omega(\\epsilon)$ for MAX-SAT.\nMoreover, for label advice, we obtain near-optimal approximation for instances\nwith large average degree, thereby generalizing recent results on MAX-CUT and\nMAX-$2$-LIN."}
{"id": "2505.02129", "pdf": "https://arxiv.org/pdf/2505.02129", "abs": "https://arxiv.org/abs/2505.02129", "authors": ["Xiaoping Sun", "Hai Zhuge"], "title": "Subspace Aggregation Query and Index Generation for Multidimensional Resource Space Model", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "Organizing resources in a multidimensional classification space is an\napproach to efficiently managing and querying large-scale resources. This paper\ndefines an aggregation query on subspace defined by a range on the partial\norder on coordinate tree at each dimension, where each point contains resources\naggregated along the paths of partial order relations on the points so that\naggregated resources at each point within the subspace can be measured, ranked\nand selected. To efficiently locate non-empty points in a large subspace, an\napproach to generating graph index is proposed to build inclusion links with\npartial order relations on coordinates of dimensions to enable a subspace query\nto reach non-empty points by following indexing links and aggregate resources\nalong indexing paths back to their super points. Generating such an index is\ncostly as the number of children of an index node can be very large so that the\ntotal number of indexing nodes is unbounded. The proposed approach adopts the\nfollowing strategies to reduce the cost: (1) adding intersection links between\ntwo indexing nodes, which can better reduce query processing costs while\ncontrolling the number of nodes of the graph index; (2) intersection links are\nadded between two nodes according to the probabilistic distribution calculated\nfor estimating the costs of adding intersection between two nodes; (3)\ncoordinates at one dimension having more resources are split by coordinates at\nanother dimension to balance the number of resources hold by indexing nodes;\nand, (4) short-cut links are added between sibling coordinates of coordinate\ntrees to make an efficient query on linear order coordinates. Analysis and\nexperiments verified the effectiveness of the generated index in supporting\nsubspace aggregation query. This work makes significant contributions to the\ndevelopment of data model based on multi-dimensional classification."}
{"id": "2412.14123", "pdf": "https://arxiv.org/pdf/2412.14123", "abs": "https://arxiv.org/abs/2412.14123", "authors": ["Guillaume Astruc", "Nicolas Gonthier", "Clement Mallet", "Loic Landrieu"], "title": "AnySat: One Earth Observation Model for Many Resolutions, Scales, and Modalities", "categories": ["cs.CV"], "comment": null, "summary": "Geospatial models must adapt to the diversity of Earth observation data in\nterms of resolutions, scales, and modalities. However, existing approaches\nexpect fixed input configurations, which limits their practical applicability.\nWe propose AnySat, a multimodal model based on joint embedding predictive\narchitecture (JEPA) and scale-adaptive spatial encoders, allowing us to train a\nsingle model on highly heterogeneous data in a self-supervised manner. To\ndemonstrate the advantages of this unified approach, we compile GeoPlex, a\ncollection of 5 multimodal datasets with varying characteristics and $11$\ndistinct sensors. We then train a single powerful model on these diverse\ndatasets simultaneously. Once fine-tuned or probed, we reach state-of-the-art\nresults on the test sets of GeoPlex and for 6 external datasets across various\nenvironment monitoring tasks: land cover mapping, tree species identification,\ncrop type classification, change detection, climate type classification, and\nsegmentation of flood, burn scar, and deforestation. The code and models are\navailable at https://github.com/gastruc/AnySat."}
{"id": "2505.06182", "pdf": "https://arxiv.org/pdf/2505.06182", "abs": "https://arxiv.org/abs/2505.06182", "authors": ["Tim Schneider", "Cristiana de Farias", "Roberto Calandra", "Liming Chen", "Jan Peters"], "title": "Active Perception for Tactile Sensing: A Task-Agnostic Attention-Based Approach", "categories": ["cs.RO", "cs.LG"], "comment": "16 pages; 13 figures", "summary": "Humans make extensive use of haptic exploration to map and identify the\nproperties of the objects that we touch. In robotics, active tactile perception\nhas emerged as an important research domain that complements vision for tasks\nsuch as object classification, shape reconstruction, and manipulation. This\nwork introduces TAP (Task-agnostic Active Perception) -- a novel framework that\nleverages reinforcement learning (RL) and transformer-based architectures to\naddress the challenges posed by partially observable environments. TAP\nintegrates Soft Actor-Critic (SAC) and CrossQ algorithms within a unified\noptimization objective, jointly training a perception module and\ndecision-making policy. By design, TAP is completely task-agnostic and can, in\nprinciple, generalize to any active perception problem. We evaluate TAP across\ndiverse tasks, including toy examples and realistic applications involving\nhaptic exploration of 3D models from the Tactile MNIST benchmark. Experiments\ndemonstrate the efficacy of TAP, achieving high accuracies on the Tactile MNIST\nhaptic digit recognition task and a tactile pose estimation task. These\nfindings underscore the potential of TAP as a versatile and generalizable\nframework for advancing active tactile perception in robotics."}
{"id": "2505.02255", "pdf": "https://arxiv.org/pdf/2505.02255", "abs": "https://arxiv.org/abs/2505.02255", "authors": ["Jakub Wasala", "Bartlomiej Wrzalski", "Kornelia Noculak", "Yuliia Tarasenko", "Oliwer Krupa", "Jan Kocon", "Grzegorz Chodak"], "title": "Enhancing AI Face Realism: Cost-Efficient Quality Improvement in Distilled Diffusion Models with a Fully Synthetic Dataset", "categories": ["cs.CV", "cs.AI"], "comment": "25th International Conference on Computational Science", "summary": "This study presents a novel approach to enhance the cost-to-quality ratio of\nimage generation with diffusion models. We hypothesize that differences between\ndistilled (e.g. FLUX.1-schnell) and baseline (e.g. FLUX.1-dev) models are\nconsistent and, therefore, learnable within a specialized domain, like portrait\ngeneration. We generate a synthetic paired dataset and train a fast\nimage-to-image translation head. Using two sets of low- and high-quality\nsynthetic images, our model is trained to refine the output of a distilled\ngenerator (e.g., FLUX.1-schnell) to a level comparable to a baseline model like\nFLUX.1-dev, which is more computationally intensive. Our results show that the\npipeline, which combines a distilled version of a large generative model with\nour enhancement layer, delivers similar photorealistic portraits to the\nbaseline version with up to an 82% decrease in computational cost compared to\nFLUX.1-dev. This study demonstrates the potential for improving the efficiency\nof AI solutions involving large-scale image generation."}
{"id": "2412.20002", "pdf": "https://arxiv.org/pdf/2412.20002", "abs": "https://arxiv.org/abs/2412.20002", "authors": ["You Wu", "Yongxin Li", "Mengyuan Liu", "Xucheng Wang", "Xiangyang Yang", "Hengzhou Ye", "Dan Zeng", "Qijun Zhao", "Shuiwang Li"], "title": "Learning an Adaptive and View-Invariant Vision Transformer for Real-Time UAV Tracking", "categories": ["cs.CV"], "comment": null, "summary": "Visual tracking has made significant strides due to the adoption of\ntransformer-based models. Most state-of-the-art trackers struggle to meet\nreal-time processing demands on mobile platforms with constrained computing\nresources, particularly for real-time unmanned aerial vehicle (UAV) tracking.\nTo achieve a better balance between performance and efficiency, we introduce\nAVTrack, an adaptive computation framework designed to selectively activate\ntransformer blocks for real-time UAV tracking. The proposed Activation Module\n(AM) dynamically optimizes the ViT architecture by selectively engaging\nrelevant components, thereby enhancing inference efficiency without significant\ncompromise to tracking performance. Furthermore, to tackle the challenges posed\nby extreme changes in viewing angles often encountered in UAV tracking, the\nproposed method enhances ViTs' effectiveness by learning view-invariant\nrepresentations through mutual information (MI) maximization. Two effective\ndesign principles are proposed in the AVTrack. Building on it, we propose an\nimproved tracker, dubbed AVTrack-MD, which introduces the novel MI\nmaximization-based multi-teacher knowledge distillation (MD) framework. It\nharnesses the benefits of multiple teachers, specifically the off-the-shelf\ntracking models from the AVTrack, by integrating and refining their outputs,\nthereby guiding the learning process of the compact student network.\nSpecifically, we maximize the MI between the softened feature representations\nfrom the multi-teacher models and the student model, leading to improved\ngeneralization and performance of the student model, particularly in noisy\nconditions. Extensive experiments on multiple UAV tracking benchmarks\ndemonstrate that AVTrack-MD not only achieves performance comparable to the\nAVTrack baseline but also reduces model complexity, resulting in a significant\n17\\% increase in average tracking speed."}
{"id": "2505.06207", "pdf": "https://arxiv.org/pdf/2505.06207", "abs": "https://arxiv.org/abs/2505.06207", "authors": ["Muhy Eddin Za'ter", "Amir Sajad", "Bri-Mathias Hodge"], "title": "Leveraging Multi-Task Learning for Multi-Label Power System Security Assessment", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "This paper introduces a novel approach to the power system security\nassessment using Multi-Task Learning (MTL), and reformulating the problem as a\nmulti-label classification task. The proposed MTL framework simultaneously\nassesses static, voltage, transient, and small-signal stability, improving both\naccuracy and interpretability with respect to the most state of the art machine\nlearning methods. It consists of a shared encoder and multiple decoders,\nenabling knowledge transfer between stability tasks. Experiments on the IEEE\n68-bus system demonstrate a measurable superior performance of the proposed\nmethod compared to the extant state-of-the-art approaches."}
{"id": "2505.04787", "pdf": "https://arxiv.org/pdf/2505.04787", "abs": "https://arxiv.org/abs/2505.04787", "authors": ["Sriram Mandalika", "Harsha Vardhan", "Athira Nambiar"], "title": "Replay to Remember (R2R): An Efficient Uncertainty-driven Unsupervised Continual Learning Framework Using Generative Replay", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Submitted to the 28th European Conference on Artificial Intelligence\n  (ECAI-2025)", "summary": "Continual Learning entails progressively acquiring knowledge from new data\nwhile retaining previously acquired knowledge, thereby mitigating\n``Catastrophic Forgetting'' in neural networks. Our work presents a novel\nuncertainty-driven Unsupervised Continual Learning framework using Generative\nReplay, namely ``Replay to Remember (R2R)''. The proposed R2R architecture\nefficiently uses unlabelled and synthetic labelled data in a balanced\nproportion using a cluster-level uncertainty-driven feedback mechanism and a\nVLM-powered generative replay module. Unlike traditional memory-buffer methods\nthat depend on pretrained models and pseudo-labels, our R2R framework operates\nwithout any prior training. It leverages visual features from unlabeled data\nand adapts continuously using clustering-based uncertainty estimation coupled\nwith dynamic thresholding. Concurrently, a generative replay mechanism along\nwith DeepSeek-R1 powered CLIP VLM produces labelled synthetic data\nrepresentative of past experiences, resembling biological visual thinking that\nreplays memory to remember and act in new, unseen tasks. Extensive experimental\nanalyses are carried out in CIFAR-10, CIFAR-100, CINIC-10, SVHN and\nTinyImageNet datasets. Our proposed R2R approach improves knowledge retention,\nachieving a state-of-the-art performance of 98.13%, 73.06%, 93.41%, 95.18%,\n59.74%, respectively, surpassing state-of-the-art performance by over 4.36%."}
{"id": "2503.11341", "pdf": "https://arxiv.org/pdf/2503.11341", "abs": "https://arxiv.org/abs/2503.11341", "authors": ["Joona Kareinen", "Tuomas Eerola", "Kaisa Kraft", "Lasse Lensu", "Sanna Suikkanen", "Heikki Kälviäinen"], "title": "Self-Supervised Pretraining for Fine-Grained Plankton Recognition", "categories": ["cs.CV"], "comment": "CVPR 2025, FGVC12 workshop paper", "summary": "Plankton recognition is an important computer vision problem due to\nplankton's essential role in ocean food webs and carbon capture, highlighting\nthe need for species-level monitoring. However, this task is challenging due to\nits fine-grained nature and dataset shifts caused by different imaging\ninstruments and varying species distributions. As new plankton image datasets\nare collected at an increasing pace, there is a need for general plankton\nrecognition models that require minimal expert effort for data labeling. In\nthis work, we study large-scale self-supervised pretraining for fine-grained\nplankton recognition. We first employ masked autoencoding and a large volume of\ndiverse plankton image data to pretrain a general-purpose plankton image\nencoder. Then we utilize fine-tuning to obtain accurate plankton recognition\nmodels for new datasets with a very limited number of labeled training images.\nOur experiments show that self-supervised pretraining with diverse plankton\ndata clearly increases plankton recognition accuracy compared to standard\nImageNet pretraining when the amount of training data is limited. Moreover, the\naccuracy can be further improved when unlabeled target data is available and\nutilized during the pretraining."}
{"id": "2505.06228", "pdf": "https://arxiv.org/pdf/2505.06228", "abs": "https://arxiv.org/abs/2505.06228", "authors": ["Mariona Badenas-Agusti", "Siyi Xu", "Andrew Vanderburg", "Kishalay De", "Patrick Dufour", "Laura K. Rogers", "Susana Hoyos", "Simon Blouin", "Javier Viaña", "Amy Bonsor", "Ben Zuckerman"], "title": "A Machine-Learning Compositional Study of Exoplanetary Material Accreted Onto Five Helium-Atmosphere White Dwarfs with $\\texttt{cecilia}$", "categories": ["astro-ph.EP", "astro-ph.IM", "astro-ph.SR", "cs.LG"], "comment": "28 pages, 14 figures, 5 tables. Accepted for publication in MNRAS", "summary": "We present the first application of the Machine Learning (ML) pipeline\n$\\texttt{cecilia}$ to determine the physical parameters and photospheric\ncomposition of five metal-polluted He-atmosphere white dwarfs without\nwell-characterised elemental abundances. To achieve this, we perform a joint\nand iterative Bayesian fit to their $\\textit{SDSS}$ (R=2,000) and\n$\\textit{Keck/ESI}$ (R=4,500) optical spectra, covering the wavelength range\nfrom about 3,800\\r{A} to 9,000\\r{A}. Our analysis measures the abundances of at\nleast two $-$and up to six$-$ chemical elements in their atmospheres with a\npredictive accuracy similar to that of conventional WD analysis techniques\n($\\approx$0.20 dex). The white dwarfs with the largest number of detected heavy\nelements are SDSS J0859$+$5732 and SDSS J2311$-$0041, which simultaneously\nexhibit O, Mg, Si, Ca, and Fe in their $\\textit{Keck/ESI}$ spectra. For all\nsystems, we find that the bulk composition of their pollutants is largely\nconsistent with those of primitive CI chondrites to within 1-2$\\sigma$. We also\nfind evidence of statistically significant ($>2\\sigma$) oxygen excesses for\nSDSS J0859$+$5732 and SDSS J2311$-$0041, which could point to the accretion of\noxygen-rich exoplanetary material. In the future, as wide-field astronomical\nsurveys deliver millions of public WD spectra to the scientific community,\n$\\texttt{cecilia}$ aspires to unlock population-wide studies of polluted WDs,\ntherefore helping to improve our statistical knowledge of extrasolar\ncompositions."}
{"id": "2505.04852", "pdf": "https://arxiv.org/pdf/2505.04852", "abs": "https://arxiv.org/abs/2505.04852", "authors": ["Yifei Gao", "Chengpeng Wang", "Pengxiang Huang", "Xuwei Liu", "Mingwei Zheng", "Xiangyu Zhang"], "title": "PR2: Peephole Raw Pointer Rewriting with LLMs for Translating C to Safer Rust", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": null, "summary": "There has been a growing interest in translating C code to Rust due to Rust's\nrobust memory and thread safety guarantees. Tools such as C2RUST enable\nsyntax-guided transpilation from C to semantically equivalent Rust code.\nHowever, the resulting Rust programs often rely heavily on unsafe\nconstructs--particularly raw pointers--which undermines Rust's safety\nguarantees. This paper aims to improve the memory safety of Rust programs\ngenerated by C2RUST by eliminating raw pointers. Specifically, we propose a\npeephole raw pointer rewriting technique that lifts raw pointers in individual\nfunctions to appropriate Rust data structures. Technically, PR2 employs\ndecision-tree-based prompting to guide the pointer lifting process.\nAdditionally, it leverages code change analysis to guide the repair of errors\nintroduced during rewriting, effectively addressing errors encountered during\ncompilation and test case execution. We implement PR2 as a prototype and\nevaluate it using gpt-4o-mini on 28 real-world C projects. The results show\nthat PR2 successfully eliminates 13.22% of local raw pointers across these\nprojects, significantly enhancing the safety of the translated Rust code. On\naverage, PR2 completes the transformation of a project in 5.44 hours, at an\naverage cost of $1.46."}
{"id": "2503.20698", "pdf": "https://arxiv.org/pdf/2503.20698", "abs": "https://arxiv.org/abs/2503.20698", "authors": ["Saron Samuel", "Dan DeGenaro", "Jimena Guallar-Blasco", "Kate Sanders", "Oluwaseun Eisape", "Tanner Spendlove", "Arun Reddy", "Alexander Martin", "Andrew Yates", "Eugene Yang", "Cameron Carpenter", "David Etter", "Efsun Kayi", "Matthew Wiesner", "Kenton Murray", "Reno Kriz"], "title": "MMMORRF: Multimodal Multilingual Modularized Reciprocal Rank Fusion", "categories": ["cs.CV", "cs.IR"], "comment": null, "summary": "Videos inherently contain multiple modalities, including visual events, text\noverlays, sounds, and speech, all of which are important for retrieval.\nHowever, state-of-the-art multimodal language models like VAST and LanguageBind\nare built on vision-language models (VLMs), and thus overly prioritize visual\nsignals. Retrieval benchmarks further reinforce this bias by focusing on visual\nqueries and neglecting other modalities. We create a search system MMMORRF that\nextracts text and features from both visual and audio modalities and integrates\nthem with a novel modality-aware weighted reciprocal rank fusion. MMMORRF is\nboth effective and efficient, demonstrating practicality in searching videos\nbased on users' information needs instead of visual descriptive queries. We\nevaluate MMMORRF on MultiVENT 2.0 and TVR, two multimodal benchmarks designed\nfor more targeted information needs, and find that it improves nDCG@20 by 81%\nover leading multimodal encoders and 37% over single-modality retrieval,\ndemonstrating the value of integrating diverse modalities."}
{"id": "2310.04649", "pdf": "https://arxiv.org/pdf/2310.04649", "abs": "https://arxiv.org/abs/2310.04649", "authors": ["Michael Matena", "Colin Raffel"], "title": "Uncovering Model Processing Strategies with Non-Negative Per-Example Fisher Factorization", "categories": ["cs.LG"], "comment": null, "summary": "We introduce NPEFF (Non-Negative Per-Example Fisher Factorization), an\ninterpretability method that aims to uncover strategies used by a model to\ngenerate its predictions. NPEFF decomposes per-example Fisher matrices using a\nnovel decomposition algorithm that learns a set of components represented by\nlearned rank-1 positive semi-definite matrices. Through a combination of human\nevaluation and automated analysis, we demonstrate that these NPEFF components\ncorrespond to model processing strategies for a variety of language models and\ntext processing tasks. We further show how to construct parameter perturbations\nfrom NPEFF components to selectively disrupt a given component's role in the\nmodel's processing. Along with conducting extensive ablation studies, we\ninclude experiments to show how NPEFF can be used to analyze and mitigate\ncollateral effects of unlearning and use NPEFF to study in-context learning.\nFurthermore, we demonstrate the advantages of NPEFF over baselines such as\ngradient clustering and using sparse autoencoders for dictionary learning over\nmodel activations."}
{"id": "2505.05283", "pdf": "https://arxiv.org/pdf/2505.05283", "abs": "https://arxiv.org/abs/2505.05283", "authors": ["Kaixin Wang", "Tianlin Li", "Xiaoyu Zhang", "Chong Wang", "Weisong Sun", "Yang Liu", "Bin Shi"], "title": "Software Development Life Cycle Perspective: A Survey of Benchmarks for Code Large Language Models and Agents", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Code large language models (CodeLLMs) and agents have shown great promise in\ntackling complex software engineering tasks.Compared to traditional software\nengineering methods, CodeLLMs and agents offer stronger abilities, and can\nflexibly process inputs and outputs in both natural and code. Benchmarking\nplays a crucial role in evaluating the capabilities of CodeLLMs and agents,\nguiding their development and deployment. However, despite their growing\nsignificance, there remains a lack of comprehensive reviews of benchmarks for\nCodeLLMs and agents. To bridge this gap, this paper provides a comprehensive\nreview of existing benchmarks for CodeLLMs and agents, studying and analyzing\n181 benchmarks from 461 relevant papers, covering the different phases of the\nsoftware development life cycle (SDLC). Our findings reveal a notable imbalance\nin the coverage of current benchmarks, with approximately 60% focused on the\nsoftware development phase in SDLC, while requirements engineering and software\ndesign phases receive minimal attention at only 5% and 3%, respectively.\nAdditionally, Python emerges as the dominant programming language across the\nreviewed benchmarks. Finally, this paper highlights the challenges of current\nresearch and proposes future directions, aiming to narrow the gap between the\ntheoretical capabilities of CodeLLMs and agents and their application in\nreal-world scenarios."}
{"id": "2503.22976", "pdf": "https://arxiv.org/pdf/2503.22976", "abs": "https://arxiv.org/abs/2503.22976", "authors": ["Jiahui Zhang", "Yurui Chen", "Yanpeng Zhou", "Yueming Xu", "Ze Huang", "Jilin Mei", "Junhui Chen", "Yu-Jie Yuan", "Xinyue Cai", "Guowei Huang", "Xingyue Quan", "Hang Xu", "Li Zhang"], "title": "From Flatland to Space: Teaching Vision-Language Models to Perceive and Reason in 3D", "categories": ["cs.CV"], "comment": "Project page: https://fudan-zvg.github.io/spar", "summary": "Recent advances in LVLMs have improved vision-language understanding, but\nthey still struggle with spatial perception, limiting their ability to reason\nabout complex 3D scenes. Unlike previous approaches that incorporate 3D\nrepresentations into models to improve spatial understanding, we aim to unlock\nthe potential of VLMs by leveraging spatially relevant image data. To this end,\nwe introduce a novel 2D spatial data generation and annotation pipeline built\nupon scene data with 3D ground-truth. This pipeline enables the creation of a\ndiverse set of spatial tasks, ranging from basic perception tasks to more\ncomplex reasoning tasks. Leveraging this pipeline, we construct SPAR-7M, a\nlarge-scale dataset generated from thousands of scenes across multiple public\ndatasets. In addition, we introduce SPAR-Bench, a benchmark designed to offer a\nmore comprehensive evaluation of spatial capabilities compared to existing\nspatial benchmarks, supporting both single-view and multi-view inputs. Training\non both SPAR-7M and large-scale 2D datasets enables our models to achieve\nstate-of-the-art performance on 2D spatial benchmarks. Further fine-tuning on\n3D task-specific datasets yields competitive results, underscoring the\neffectiveness of our dataset in enhancing spatial reasoning."}
{"id": "2310.19470", "pdf": "https://arxiv.org/pdf/2310.19470", "abs": "https://arxiv.org/abs/2310.19470", "authors": ["Gouki Minegishi", "Yusuke Iwasawa", "Yutaka Matsuo"], "title": "Bridging Lottery Ticket and Grokking: Understanding Grokking from Inner Structure of Networks", "categories": ["cs.LG"], "comment": "Published at Transactions on Machine Learning Research (TMLR)", "summary": "Grokking is an intriguing phenomenon of delayed generalization, where neural\nnetworks initially memorize training data with perfect accuracy but exhibit\npoor generalization, subsequently transitioning to a generalizing solution with\ncontinued training. While factors such as weight norms and sparsity have been\nproposed to explain this delayed generalization, the influence of network\nstructure remains underexplored. In this work, we link the grokking phenomenon\nto the lottery ticket hypothesis to investigate the impact of internal network\nstructures. We demonstrate that utilizing lottery tickets obtained during the\ngeneralizing phase (termed grokked tickets) significantly reduces delayed\ngeneralization across various tasks, including multiple modular arithmetic\noperations, polynomial regression, sparse parity, and MNIST classification.\nThrough controlled experiments, we show that the mitigation of delayed\ngeneralization is not due solely to reduced weight norms or increased sparsity,\nbut rather to the discovery of good subnetworks. Furthermore, we find that\ngrokked tickets exhibit periodic weight patterns, beneficial graph properties\nsuch as increased average path lengths and reduced clustering coefficients, and\nundergo rapid structural changes that coincide with improvements in\ngeneralization. Additionally, pruning techniques like the edge-popup algorithm\ncan identify these effective structures without modifying the weights, thereby\ntransforming memorizing networks into generalizing ones. These results\nunderscore the novel insight that structural exploration plays a pivotal role\nin understanding grokking. The implementation code can be accessed via this\nlink: https://github.com/gouki510/Grokking-Tickets."}
{"id": "2505.05375", "pdf": "https://arxiv.org/pdf/2505.05375", "abs": "https://arxiv.org/abs/2505.05375", "authors": ["Kejie Zhao", "Wenjia Hua", "Aiersi Tuerhong", "Luziwei Leng", "Yuxin Ma", "Qinghai Guo"], "title": "Threshold Modulation for Online Test-Time Adaptation of Spiking Neural Networks", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.NE"], "comment": "Accepted by IJCNN 2025. \\c{opyright} 2025 IEEE. Personal use of this\n  material is permitted. Permission from IEEE must be obtained for all other\n  uses, including reprinting/republishing this material for advertising or\n  promotional purposes, collecting new collected works for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "Recently, spiking neural networks (SNNs), deployed on neuromorphic chips,\nprovide highly efficient solutions on edge devices in different scenarios.\nHowever, their ability to adapt to distribution shifts after deployment has\nbecome a crucial challenge. Online test-time adaptation (OTTA) offers a\npromising solution by enabling models to dynamically adjust to new data\ndistributions without requiring source data or labeled target samples.\nNevertheless, existing OTTA methods are largely designed for traditional\nartificial neural networks and are not well-suited for SNNs. To address this\ngap, we propose a low-power, neuromorphic chip-friendly online test-time\nadaptation framework, aiming to enhance model generalization under distribution\nshifts. The proposed approach is called Threshold Modulation (TM), which\ndynamically adjusts the firing threshold through neuronal dynamics-inspired\nnormalization, being more compatible with neuromorphic hardware. Experimental\nresults on benchmark datasets demonstrate the effectiveness of this method in\nimproving the robustness of SNNs against distribution shifts while maintaining\nlow computational cost. The proposed method offers a practical solution for\nonline test-time adaptation of SNNs, providing inspiration for the design of\nfuture neuromorphic chips. The demo code is available at\ngithub.com/NneurotransmitterR/TM-OTTA-SNN."}
{"id": "2503.24166", "pdf": "https://arxiv.org/pdf/2503.24166", "abs": "https://arxiv.org/abs/2503.24166", "authors": ["Fabian Fuchs", "Mario Ruben Fernandez", "Norman Ettrich", "Janis Keuper"], "title": "Foundation Models For Seismic Data Processing: An Extensive Review", "categories": ["cs.CV"], "comment": "In submission to Geophysics", "summary": "Seismic processing plays a crucial role in transforming raw data into\nhigh-quality subsurface images, pivotal for various geoscience applications.\nDespite its importance, traditional seismic processing techniques face\nchallenges such as noisy and damaged data and the reliance on manual,\ntime-consuming workflows. The emergence of deep learning approaches has\nintroduced effective and user-friendly alternatives, yet many of these deep\nlearning approaches rely on synthetic datasets and specialized neural networks.\nRecently, foundation models have gained traction in the seismic domain, due to\ntheir success in the natural image domain. Therefore, we investigate the\napplication of natural image foundation models on the three seismic processing\ntasks: demultiple, interpolation, and denoising. We evaluate the impact of\ndifferent model characteristics, such as pre-training technique and neural\nnetwork architecture, on performance and efficiency. Rather than proposing a\nsingle seismic foundation model, we critically examine various natural image\nfoundation models and suggest some promising candidates for future exploration."}
{"id": "2312.05698", "pdf": "https://arxiv.org/pdf/2312.05698", "abs": "https://arxiv.org/abs/2312.05698", "authors": ["Chen Liang", "Donghua Yang", "Zhiyu Liang", "Hongzhi Wang", "Zheng Liang", "Xiyang Zhang", "Jianfeng Huang"], "title": "Unsupervised Multi-modal Feature Alignment for Time Series Representation Learning", "categories": ["cs.LG"], "comment": null, "summary": "In recent times, the field of unsupervised representation learning (URL) for\ntime series data has garnered significant interest due to its remarkable\nadaptability across diverse downstream applications. Unsupervised learning\ngoals differ from downstream tasks, making it tricky to ensure downstream task\nutility by focusing only on temporal feature characterization. Researchers have\nproposed multiple transformations to extract discriminative patterns implied in\ninformative time series, trying to fill the gap. Despite the introduction of a\nvariety of feature engineering techniques, e.g. spectral domain, wavelet\ntransformed features, features in image form and symbolic features etc. the\nutilization of intricate feature fusion methods and dependence on heterogeneous\nfeatures during inference hampers the scalability of the solutions. To address\nthis, our study introduces an innovative approach that focuses on aligning and\nbinding time series representations encoded from different modalities, inspired\nby spectral graph theory, thereby guiding the neural encoder to uncover latent\npattern associations among these multi-modal features. In contrast to\nconventional methods that fuse features from multiple modalities, our proposed\napproach simplifies the neural architecture by retaining a single time series\nencoder, consequently leading to preserved scalability. We further demonstrate\nand prove mechanisms for the encoder to maintain better inductive bias. In our\nexperimental evaluation, we validated the proposed method on a diverse set of\ntime series datasets from various domains. Our approach outperforms existing\nstate-of-the-art URL methods across diverse downstream tasks."}
{"id": "2504.06751", "pdf": "https://arxiv.org/pdf/2504.06751", "abs": "https://arxiv.org/abs/2504.06751", "authors": ["Leszek Luchowski", "Dariusz Pojda"], "title": "Visualization of a multidimensional point cloud as a 3D swarm of avatars", "categories": ["cs.CV", "cs.HC"], "comment": "24 pages, 11 figures", "summary": "The article presents an innovative approach to the visualization of\nmultidimensional data, using icons inspired by Chernoff faces. The approach\nmerges classical projection techniques with the assignment of particular data\ndimensions to mimic features, capitalizing on the natural ability of the human\nbrain to interpret facial expressions. We introduce a semantic division of data\ndimensions into intuitive and technical categories, assigning the former to\navatar features and projecting the latter into a hyperspace of four, or\npotentially more dimensions. The technique is implemented as a plugin to the\ndpVision open-source image handling platform. The plugin allows the data to be\ninteractively explored in the form of a swarm of avatars whose position in\nhyperspace as well as facial features represent various aspects of the data.\nSample visualizations, based on synthetic test data as well as the\n12-dimensional database on Portuguese Vinho Verde wines, confirm the usefulness\nof our approach to the analysis of complex data structures."}
{"id": "2312.08598", "pdf": "https://arxiv.org/pdf/2312.08598", "abs": "https://arxiv.org/abs/2312.08598", "authors": ["Andreas Müller", "Carlo Curino", "Raghu Ramakrishnan"], "title": "MotherNet: Fast Training and Inference via Hyper-Network Transformers", "categories": ["cs.LG", "I.2.6"], "comment": "17 pages, 13 figures", "summary": "Foundation models are transforming machine learning across many modalities,\nwith in-context learning replacing classical model training. Recent work on\ntabular data hints at a similar opportunity to build foundation models for\nclassification for numerical data. However, existing meta-learning approaches\ncan not compete with tree-based methods in terms of inference time. In this\npaper, we propose MotherNet, a hypernetwork architecture trained on synthetic\nclassification tasks that, once prompted with a never-seen-before training set\ngenerates the weights of a trained ``child'' neural-network by in-context\nlearning using a single forward pass. In contrast to most existing\nhypernetworks that are usually trained for relatively constrained multi-task\nsettings, MotherNet can create models for multiclass classification on\narbitrary tabular datasets without any dataset specific gradient descent. The\nchild network generated by MotherNet outperforms neural networks trained using\ngradient descent on small datasets, and is comparable to predictions by TabPFN\nand standard ML methods like Gradient Boosting. Unlike a direct application of\nTabPFN, MotherNet generated networks are highly efficient at inference time. We\nalso demonstrate that HyperFast is unable to perform effective in-context\nlearning on small datasets, and heavily relies on dataset specific fine-tuning\nand hyper-parameter tuning, while MotherNet requires no fine-tuning or\nper-dataset hyper-parameters."}
{"id": "2504.08049", "pdf": "https://arxiv.org/pdf/2504.08049", "abs": "https://arxiv.org/abs/2504.08049", "authors": ["Angelina Ibarra", "Joshua Peeples"], "title": "Patch distribution modeling framework adaptive cosine estimator (PaDiM-ACE) for anomaly detection and localization in synthetic aperture radar imagery", "categories": ["cs.CV"], "comment": "Accepted to SPIE, Defense and Commercial Sensing, Algorithms for\n  Synthetic Aperture Radar Imagery XXXII (April 2025)", "summary": "This work presents a new approach to anomaly detection and localization in\nsynthetic aperture radar imagery (SAR), expanding upon the existing patch\ndistribution modeling framework (PaDiM). We introduce the adaptive cosine\nestimator (ACE) detection statistic. PaDiM uses the Mahalanobis distance at\ninference, an unbounded metric. ACE instead uses the cosine similarity metric,\nproviding bounded anomaly detection scores. The proposed method is evaluated\nacross multiple SAR datasets, with performance metrics including the area under\nthe receiver operating curve (AUROC) at the image and pixel level, aiming for\nincreased performance in anomaly detection and localization of SAR imagery. The\ncode is publicly available:\nhttps://github.com/Advanced-Vision-and-Learning-Lab/PaDiM-ACE."}
{"id": "2405.14432", "pdf": "https://arxiv.org/pdf/2405.14432", "abs": "https://arxiv.org/abs/2405.14432", "authors": ["Youssef Allouah", "Rachid Guerraoui", "Nirupam Gupta", "Ahmed Jellouli", "Geovani Rizk", "John Stephan"], "title": "Adaptive Gradient Clipping for Robust Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Robust federated learning aims to maintain reliable performance despite the\npresence of adversarial or misbehaving workers. While state-of-the-art (SOTA)\nrobust distributed gradient descent (Robust-DGD) methods were proven\ntheoretically optimal, their empirical success has often relied on\npre-aggregation gradient clipping. However, existing static clipping strategies\nyield inconsistent results: enhancing robustness against some attacks while\nbeing ineffective or even detrimental against others. To address this\nlimitation, we propose a principled adaptive clipping strategy, Adaptive Robust\nClipping (ARC), which dynamically adjusts clipping thresholds based on the\ninput gradients. We prove that ARC not only preserves the theoretical\nrobustness guarantees of SOTA Robust-DGD methods but also provably improves\nasymptotic convergence when the model is well-initialized. Extensive\nexperiments on benchmark image classification tasks confirm these theoretical\ninsights, demonstrating that ARC significantly enhances robustness,\nparticularly in highly heterogeneous and adversarial settings."}
{"id": "2504.13580", "pdf": "https://arxiv.org/pdf/2504.13580", "abs": "https://arxiv.org/abs/2504.13580", "authors": ["Yuchen Rao", "Stefan Ainetter", "Sinisa Stekovic", "Vincent Lepetit", "Friedrich Fraundorfer"], "title": "Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding", "categories": ["cs.CV"], "comment": "Project page: https://stefan-ainetter.github.io/SCANnotatepp; CVPR'25\n  Workshop", "summary": "High-level 3D scene understanding is essential in many applications. However,\nthe challenges of generating accurate 3D annotations make development of deep\nlearning models difficult. We turn to recent advancements in automatic\nretrieval of synthetic CAD models, and show that data generated by such methods\ncan be used as high-quality ground truth for training supervised deep learning\nmodels. More exactly, we employ a pipeline akin to the one previously used to\nautomatically annotate objects in ScanNet scenes with their 9D poses and CAD\nmodels. This time, we apply it to the recent ScanNet++ v1 dataset, which\npreviously lacked such annotations. Our findings demonstrate that it is not\nonly possible to train deep learning models on these automatically-obtained\nannotations but that the resulting models outperform those trained on manually\nannotated data. We validate this on two distinct tasks: point cloud completion\nand single-view CAD model retrieval and alignment. Our results underscore the\npotential of automatic 3D annotations to enhance model performance while\nsignificantly reducing annotation costs. To support future research in 3D scene\nunderstanding, we will release our annotations, which we call SCANnotate++,\nalong with our trained models."}
{"id": "2405.16731", "pdf": "https://arxiv.org/pdf/2405.16731", "abs": "https://arxiv.org/abs/2405.16731", "authors": ["Jeonghwan Cheon", "Sang Wan Lee", "Se-Bum Paik"], "title": "Pretraining with Random Noise for Fast and Robust Learning without Weight Transport", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "The brain prepares for learning even before interacting with the environment,\nby refining and optimizing its structures through spontaneous neural activity\nthat resembles random noise. However, the mechanism of such a process has yet\nto be thoroughly understood, and it is unclear whether this process can benefit\nthe algorithm of machine learning. Here, we study this issue using a neural\nnetwork with a feedback alignment algorithm, demonstrating that pretraining\nneural networks with random noise increases the learning efficiency as well as\ngeneralization abilities without weight transport. First, we found that random\nnoise training modifies forward weights to match backward synaptic feedback,\nwhich is necessary for teaching errors by feedback alignment. As a result, a\nnetwork with pre-aligned weights learns notably faster than a network without\nrandom noise training, even reaching a convergence speed comparable to that of\na backpropagation algorithm. Sequential training with both random noise and\ndata brings weights closer to synaptic feedback than training solely with data,\nenabling more precise credit assignment and faster learning. We also found that\neach readout probability approaches the chance level and that the effective\ndimensionality of weights decreases in a network pretrained with random noise.\nThis pre-regularization allows the network to learn simple solutions of a low\nrank, reducing the generalization loss during subsequent training. This also\nenables the network robustly to generalize a novel, out-of-distribution\ndataset. Lastly, we confirmed that random noise pretraining reduces the amount\nof meta-loss, enhancing the network ability to adapt to various tasks. Overall,\nour results suggest that random noise training with feedback alignment offers a\nstraightforward yet effective method of pretraining that facilitates quick and\nreliable learning without weight transport."}
{"id": "2505.04938", "pdf": "https://arxiv.org/pdf/2505.04938", "abs": "https://arxiv.org/abs/2505.04938", "authors": ["Ying Zhang", "Shuai Guo", "Chenxi Sun", "Yuchen Zhu", "Jinhai Xiang"], "title": "FF-PNet: A Pyramid Network Based on Feature and Field for Brain Image Registration", "categories": ["cs.CV", "cs.IR"], "comment": null, "summary": "In recent years, deformable medical image registration techniques have made\nsignificant progress. However, existing models still lack efficiency in\nparallel extraction of coarse and fine-grained features. To address this, we\nconstruct a new pyramid registration network based on feature and deformation\nfield (FF-PNet). For coarse-grained feature extraction, we design a Residual\nFeature Fusion Module (RFFM), for fine-grained image deformation, we propose a\nResidual Deformation Field Fusion Module (RDFFM). Through the parallel\noperation of these two modules, the model can effectively handle complex image\ndeformations. It is worth emphasizing that the encoding stage of FF-PNet only\nemploys traditional convolutional neural networks without any attention\nmechanisms or multilayer perceptrons, yet it still achieves remarkable\nimprovements in registration accuracy, fully demonstrating the superior feature\ndecoding capabilities of RFFM and RDFFM. We conducted extensive experiments on\nthe LPBA and OASIS datasets. The results show our network consistently\noutperforms popular methods in metrics like the Dice Similarity Coefficient."}
{"id": "2409.17264", "pdf": "https://arxiv.org/pdf/2409.17264", "abs": "https://arxiv.org/abs/2409.17264", "authors": ["Amey Agrawal", "Haoran Qiu", "Junda Chen", "Íñigo Goiri", "Chaojie Zhang", "Rayyan Shahid", "Ramachandran Ramjee", "Alexey Tumanov", "Esha Choukse"], "title": "Medha: Efficiently Serving Multi-Million Context Length LLM Inference Requests Without Approximations", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "As large language models (LLMs) handle increasingly longer contexts, serving\nlong inference requests of millions of tokens presents unique challenges. We\nshow that existing work for long context inference is largely based on\ntechniques from long context training, and does not handle the high variability\nin input lengths during inference. This leads to inefficient resource\nutilization, server fragmentation, and head-of-line (HOL) blocking.\n  We present Medha, an end-to-end system for efficient long-context LLM\ninference that addresses these challenges through fine-grained time sharing.\nMedha introduces three key innovations: (1) the mechanism of adaptive prefill\nchunking to help mitigate HOL blocking with preemption; (2) two new parallelism\nstrategies: Sequence Pipeline Parallelism (SPP) to reduce time-to-first-token\nby pipelining prefill chunks, and KV-Cache Parallelism (KVP) to lower\ntime-peroutput-token by distributing decoding across servers; and (3) a novel\ninput-length aware least remaining slack scheduling to meet Service Level\nObjectives (SLOs).\n  Medha enables exact inference scaling beyond 10 million tokens, maintaining\nhigh throughput and low latency across mixed-length workloads. Compared to\nstate-of-the-art systems, Medha reduces server fragmentation, cuts median\nlatency by up to 30x, and improves throughput by over 5x, delivering\nproduction-scale long-context inference without compromising performance on\nshorter requests."}
{"id": "2505.05049", "pdf": "https://arxiv.org/pdf/2505.05049", "abs": "https://arxiv.org/abs/2505.05049", "authors": ["Timo Kaiser", "Thomas Norrenbrock", "Bodo Rosenhahn"], "title": "UncertainSAM: Fast and Efficient Uncertainty Quantification of the Segment Anything Model", "categories": ["cs.CV"], "comment": "Accepted to ICML'25", "summary": "The introduction of the Segment Anything Model (SAM) has paved the way for\nnumerous semantic segmentation applications. For several tasks, quantifying the\nuncertainty of SAM is of particular interest. However, the ambiguous nature of\nthe class-agnostic foundation model SAM challenges current uncertainty\nquantification (UQ) approaches. This paper presents a theoretically motivated\nuncertainty quantification model based on a Bayesian entropy formulation\njointly respecting aleatoric, epistemic, and the newly introduced task\nuncertainty. We use this formulation to train USAM, a lightweight post-hoc UQ\nmethod. Our model traces the root of uncertainty back to under-parameterised\nmodels, insufficient prompts or image ambiguities. Our proposed deterministic\nUSAM demonstrates superior predictive capabilities on the SA-V, MOSE, ADE20k,\nDAVIS, and COCO datasets, offering a computationally cheap and easy-to-use UQ\nalternative that can support user-prompting, enhance semi-supervised pipelines,\nor balance the tradeoff between accuracy and cost efficiency."}
{"id": "2410.08709", "pdf": "https://arxiv.org/pdf/2410.08709", "abs": "https://arxiv.org/abs/2410.08709", "authors": ["Satoshi Hayakawa", "Yuhta Takida", "Masaaki Imaizumi", "Hiromi Wakaki", "Yuki Mitsufuji"], "title": "Distillation of Discrete Diffusion through Dimensional Correlations", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.ML"], "comment": "39 pages, ICML 2025 accepted", "summary": "Diffusion models have demonstrated exceptional performances in various fields\nof generative modeling, but suffer from slow sampling speed due to their\niterative nature. While this issue is being addressed in continuous domains,\ndiscrete diffusion models face unique challenges, particularly in capturing\ndependencies between elements (e.g., pixel relationships in image, sequential\ndependencies in language) mainly due to the computational cost of processing\nhigh-dimensional joint distributions. In this paper, (i) we propose \"mixture\"\nmodels for discrete diffusion that are capable of treating dimensional\ncorrelations while remaining scalable, and (ii) we provide a set of loss\nfunctions for distilling the iterations of existing models. Two primary\ntheoretical insights underpin our approach: First, conventional models with\nelement-wise independence can well approximate the data distribution, but\nessentially require {\\it many sampling steps}. Second, our loss functions\nenable the mixture models to distill such many-step conventional models into\njust a few steps by learning the dimensional correlations. Our experimental\nresults show the effectiveness of the proposed method in distilling pretrained\ndiscrete diffusion models across image and language domains. The code used in\nthe paper is available at https://github.com/sony/di4c ."}
{"id": "2312.09968", "pdf": "https://arxiv.org/pdf/2312.09968", "abs": "https://arxiv.org/abs/2312.09968", "authors": ["Doruk Aksoy", "Huolin L. Xin", "Timothy J. Rupert", "William J. Bowman"], "title": "Human Perception-Inspired Grain Segmentation Refinement Using Conditional Random Fields", "categories": ["cond-mat.mtrl-sci", "cs.CV"], "comment": null, "summary": "Automated detection of grain boundaries in electron microscope images of\npolycrystalline materials could help accelerate the nanoscale characterization\nof myriad engineering materials and novel materials under scientific research.\nAccurate segmentation of interconnected line networks, such as grain boundaries\nin polycrystalline material microstructures, poses a significant challenge due\nto the fragmented masks produced by conventional computer vision algorithms,\nincluding convolutional neural networks. These algorithms struggle with thin\nmasks, often necessitating post-processing for effective contour closure and\ncontinuity. Previous approaches in this domain have typically relied on custom\npost-processing techniques that are problem-specific and heavily dependent on\nthe quality of the mask obtained from a computer vision algorithm. Addressing\nthis issue, this paper introduces a fast, high-fidelity post-processing\ntechnique that is universally applicable to segmentation masks of\ninterconnected line networks. Leveraging domain knowledge about grain boundary\nconnectivity, this method employs conditional random fields and perceptual\ngrouping rules to refine segmentation masks of any image with a discernible\ngrain structure. This approach significantly enhances segmentation mask\naccuracy, achieving a 79% segment identification accuracy in validation with a\nU-Net model on electron microscopy images of a polycrystalline oxide.\nAdditionally, a novel grain alignment metric is introduced, showing a 51%\nimprovement in grain alignment. This method not only enables rapid and accurate\nsegmentation but also facilitates an unprecedented level of data analysis,\nsignificantly improving the statistical representation of grain boundary\nnetworks, making it suitable for a range of disciplines where precise\nsegmentation of interconnected line networks is essential."}
{"id": "2410.16386", "pdf": "https://arxiv.org/pdf/2410.16386", "abs": "https://arxiv.org/abs/2410.16386", "authors": ["Haoyan Xu", "Kay Liu", "Zhengtao Yao", "Philip S. Yu", "Mengyuan Li", "Kaize Ding", "Yue Zhao"], "title": "LEGO-Learn: Label-Efficient Graph Open-Set Learning", "categories": ["cs.LG", "cs.SI"], "comment": null, "summary": "How can we train graph-based models to recognize unseen classes while keeping\nlabeling costs low? Graph open-set learning (GOL) and out-of-distribution (OOD)\ndetection aim to address this challenge by training models that can accurately\nclassify known, in-distribution (ID) classes while identifying and handling\npreviously unseen classes during inference. It is critical for high-stakes,\nreal-world applications where models frequently encounter unexpected data,\nincluding finance, security, and healthcare. However, current GOL methods\nassume access to many labeled ID samples, which is unrealistic for large-scale\ngraphs due to high annotation costs. In this paper, we propose LEGO-Learn\n(Label-Efficient Graph Open-set Learning), a novel framework that tackles\nopen-set node classification on graphs within a given label budget by selecting\nthe most informative ID nodes. LEGO-Learn employs a GNN-based filter to\nidentify and exclude potential OOD nodes and then select highly informative ID\nnodes for labeling using the K-Medoids algorithm. To prevent the filter from\ndiscarding valuable ID examples, we introduce a classifier that differentiates\nbetween the C known ID classes and an additional class representing OOD nodes\n(hence, a C+1 classifier). This classifier uses a weighted cross-entropy loss\nto balance the removal of OOD nodes while retaining informative ID nodes.\nExperimental results on four real-world datasets demonstrate that LEGO-Learn\nsignificantly outperforms leading methods, with up to a 6.62% improvement in ID\nclassification accuracy and a 7.49% increase in AUROC for OOD detection."}
{"id": "2502.06380", "pdf": "https://arxiv.org/pdf/2502.06380", "abs": "https://arxiv.org/abs/2502.06380", "authors": ["Yiru Jiao", "Sander van Cranenburgh", "Simeon Calvert", "Hans van Lint"], "title": "Structure-preserving contrastive learning for spatial time series", "categories": ["cs.LG", "cs.CV"], "comment": "TL;DR: Preserving certain structures of similarity relations in\n  spatio-temporal data can improve downstream task performance via contrastive\n  learning", "summary": "The effectiveness of neural network models largely relies on learning\nmeaningful latent patterns from data, where self-supervised learning of\ninformative representations can enhance model performance and generalisability.\nHowever, self-supervised representation learning for spatially characterised\ntime series, which are ubiquitous in transportation domain, poses unique\nchallenges due to the necessity of maintaining fine-grained spatio-temporal\nsimilarities in the latent space. In this study, we introduce two\nstructure-preserving regularisers for the contrastive learning of spatial time\nseries: one regulariser preserves the topology of similarities between\ninstances, and the other preserves the graph geometry of similarities across\nspatial and temporal dimensions. To balance the contrastive learning objective\nand the need for structure preservation, we propose a dynamic weighting\nmechanism that adaptively manages this trade-off and stabilises training. We\nvalidate the proposed method through extensive experiments, including\nmultivariate time series classification to demonstrate its general\napplicability, as well as macroscopic and microscopic traffic prediction to\nhighlight its particular usefulness in encoding traffic interactions. Across\nall tasks, our method preserves the similarity structures more effectively and\nimproves state-of-the-art task performances. This method can be integrated with\nan arbitrary neural network model and is particularly beneficial for time\nseries data with spatial or geographical features. Furthermore, our findings\nsuggest that well-preserved similarity structures in the latent space indicate\nmore informative and useful representations. This provides insights to design\nmore effective neural networks for data-driven transportation research. Our\ncode is made openly accessible with all resulting data at\nhttps://github.com/yiru-jiao/spclt"}
{"id": "2410.18082", "pdf": "https://arxiv.org/pdf/2410.18082", "abs": "https://arxiv.org/abs/2410.18082", "authors": ["Renhao Wang", "Kevin Frans", "Pieter Abbeel", "Sergey Levine", "Alexei A. Efros"], "title": "Prioritized Generative Replay", "categories": ["cs.LG"], "comment": "Project page available at: https://pgenreplay.github.io", "summary": "Sample-efficient online reinforcement learning often uses replay buffers to\nstore experience for reuse when updating the value function. However, uniform\nreplay is inefficient, since certain classes of transitions can be more\nrelevant to learning. While prioritization of more useful samples is helpful,\nthis strategy can also lead to overfitting, as useful samples are likely to be\nmore rare. In this work, we instead propose a prioritized, parametric version\nof an agent's memory, using generative models to capture online experience.\nThis paradigm enables (1) densification of past experience, with new\ngenerations that benefit from the generative model's generalization capacity\nand (2) guidance via a family of \"relevance functions\" that push these\ngenerations towards more useful parts of an agent's acquired history. We show\nthis recipe can be instantiated using conditional diffusion models and simple\nrelevance functions such as curiosity- or value-based metrics. Our approach\nconsistently improves performance and sample efficiency in both state- and\npixel-based domains. We expose the mechanisms underlying these gains, showing\nhow guidance promotes diversity in our generated transitions and reduces\noverfitting. We also showcase how our approach can train policies with even\nhigher update-to-data ratios than before, opening up avenues to better scale\nonline RL agents."}
{"id": "2503.07085", "pdf": "https://arxiv.org/pdf/2503.07085", "abs": "https://arxiv.org/abs/2503.07085", "authors": ["Ruidan Xing", "Runyi Huang", "Qing Xu", "Lei He"], "title": "RS2AD: End-to-End Autonomous Driving Data Generation from Roadside Sensor Observations", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "End-to-end autonomous driving solutions, which process multi-modal sensory\ndata to directly generate refined control commands, have become a dominant\nparadigm in autonomous driving research. However, these approaches\npredominantly depend on single-vehicle data collection for model training and\noptimization, resulting in significant challenges such as high data acquisition\nand annotation costs, the scarcity of critical driving scenarios, and\nfragmented datasets that impede model generalization. To mitigate these\nlimitations, we introduce RS2AD, a novel framework for reconstructing and\nsynthesizing vehicle-mounted LiDAR data from roadside sensor observations.\nSpecifically, our method transforms roadside LiDAR point clouds into the\nvehicle-mounted LiDAR coordinate system by leveraging the target vehicle's\nrelative pose. Subsequently, high-fidelity vehicle-mounted LiDAR data is\nsynthesized through virtual LiDAR modeling, point cloud classification, and\nresampling techniques. To the best of our knowledge, this is the first approach\nto reconstruct vehicle-mounted LiDAR data from roadside sensor inputs.\nExtensive experimental evaluations demonstrate that incorporating the data\ngenerated by the RS2AD method (the RS2V-L dataset) into model training as a\nsupplement to the KITTI dataset can significantly enhance the accuracy of 3D\nobject detection and greatly improve the efficiency of end-to-end autonomous\ndriving data generation. These findings strongly validate the effectiveness of\nthe proposed method and underscore its potential in reducing dependence on\ncostly vehicle-mounted data collection while improving the robustness of\nautonomous driving models."}
{"id": "2412.02094", "pdf": "https://arxiv.org/pdf/2412.02094", "abs": "https://arxiv.org/abs/2412.02094", "authors": ["Abdullah Al Mamun", "Abyad Enan", "Debbie A. Indah", "Judith Mwakalonge", "Gurcan Comert", "Mashrur Chowdhury"], "title": "Crash Severity Risk Modeling Strategies under Data Imbalance", "categories": ["cs.LG", "cs.CY", "stat.AP"], "comment": "This second revised version has been resubmitted to the\n  Transportation Research Record: Journal of the Transportation Research Board\n  after addressing the reviewers' comments and is currently awaiting the final\n  decision", "summary": "This study investigates crash severity risk modeling strategies for work\nzones involving large vehicles (i.e., trucks, buses, and vans) under crash data\nimbalance between low-severity (LS) and high-severity (HS) crashes. We utilized\ncrash data involving large vehicles in South Carolina work zones from 2014 to\n2018, which included four times more LS crashes than HS crashes. The objective\nof this study is to evaluate the crash severity prediction performance of\nvarious statistical, machine learning, and deep learning models under different\nfeature selection and data balancing techniques. Findings highlight a disparity\nin LS and HS predictions, with lower accuracy for HS crashes due to class\nimbalance and feature overlap. Discriminative Mutual Information (DMI) yields\nthe most effective feature set for predicting HS crashes without requiring data\nbalancing, particularly when paired with gradient boosting models and deep\nneural networks such as CatBoost, NeuralNetTorch, XGBoost, and LightGBM. Data\nbalancing techniques such as NearMiss-1 maximize HS recall when combined with\nDMI-selected features and certain models such as LightGBM, making them\nwell-suited for HS crash prediction. Conversely, RandomUnderSampler, HS Class\nWeighting, and RandomOverSampler achieve more balanced performance, which is\ndefined as an equitable trade-off between LS and HS metrics, especially when\napplied to NeuralNetTorch, NeuralNetFastAI, CatBoost, LightGBM, and Bayesian\nMixed Logit (BML) using merged feature sets or models without feature\nselection. The insights from this study offer safety analysts guidance on\nselecting models, feature selection, and data balancing techniques aligned with\nspecific safety goals, providing a robust foundation for enhancing work-zone\ncrash severity prediction."}
{"id": "2501.18196", "pdf": "https://arxiv.org/pdf/2501.18196", "abs": "https://arxiv.org/abs/2501.18196", "authors": ["Qingxiang Liu", "Chenghao Liu", "Sheng Sun", "Di Yao", "Yuxuan Liang"], "title": "GDformer: Going Beyond Subsequence Isolation for Multivariate Time Series Anomaly Detection", "categories": ["cs.LG"], "comment": null, "summary": "Unsupervised anomaly detection of multivariate time series is a challenging\ntask, given the requirements of deriving a compact detection criterion without\naccessing the anomaly points. The existing methods are mainly based on\nreconstruction error or association divergence, which are both confined to\nisolated subsequences with limited horizons, hardly promising unified\nseries-level criterion. In this paper, we propose the Global\nDictionary-enhanced Transformer (GDformer) with a renovated dictionary-based\ncross attention mechanism to cultivate the global representations shared by all\nnormal points in the entire series. Accordingly, the cross-attention maps\nreflect the correlation weights between the point and global representations,\nwhich naturally leads to the representation-wise similarity-based detection\ncriterion. To foster more compact detection boundary, prototypes are introduced\nto capture the distribution of normal point-global correlation weights.\nGDformer consistently achieves state-of-the-art unsupervised anomaly detection\nperformance on five real-world benchmark datasets. Further experiments validate\nthe global dictionary has great transferability among various datasets. The\ncode is available at https://github.com/yuppielqx/GDformer."}
{"id": "2502.01778", "pdf": "https://arxiv.org/pdf/2502.01778", "abs": "https://arxiv.org/abs/2502.01778", "authors": ["Stavros Orfanoudakis", "Nanda Kishor Panda", "Peter Palensky", "Pedro P. Vergara"], "title": "GNN-DT: Graph Neural Network Enhanced Decision Transformer for Efficient Optimization in Dynamic Environments", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Reinforcement Learning (RL) methods used for solving real-world optimization\nproblems often involve dynamic state-action spaces, larger scale, and sparse\nrewards, leading to significant challenges in convergence, scalability, and\nefficient exploration of the solution space. This study introduces GNN-DT, a\nnovel Decision Transformer (DT) architecture that integrates Graph Neural\nNetwork (GNN) embedders with a novel residual connection between input and\noutput tokens crucial for handling dynamic environments. By learning from\npreviously collected trajectories, GNN-DT tackles the sparse rewards\nlimitations of online RL algorithms and delivers high-quality solutions in\nreal-time. We evaluate GNN-DT on the complex electric vehicle (EV) charging\noptimization problem and prove that its performance is superior and requires\nsignificantly fewer training trajectories, thus improving sample efficiency\ncompared to existing DT and offline RL baselines. Furthermore, GNN-DT exhibits\nrobust generalization to unseen environments and larger action spaces,\naddressing a critical gap in prior offline and online RL approaches."}
{"id": "2502.02428", "pdf": "https://arxiv.org/pdf/2502.02428", "abs": "https://arxiv.org/abs/2502.02428", "authors": ["Xu Wang", "Puyu Han", "Jiaju Kang", "Weichao Pan", "Luqi Gong"], "title": "RIE-SenseNet: Riemannian Manifold Embedding of Multi-Source Industrial Sensor Signals for Robust Pattern Recognition", "categories": ["cs.LG"], "comment": null, "summary": "Industrial sensor networks produce complex signals with nonlinear structure\nand shifting distributions. We propose RIE-SenseNet, a novel geometry-aware\nTransformer model that embeds sensor data in a Riemannian manifold to tackle\nthese challenges. By leveraging hyperbolic geometry for sequence modeling and\nintroducing a manifold-based augmentation technique, RIE-SenseNet preserves\nsensor signal structure and generates realistic synthetic samples. Experiments\nshow RIE-SenseNet achieves >90% F1-score, far surpassing CNN and Transformer\nbaselines. These results illustrate the benefit of combining non-Euclidean\nfeature representations with geometry-consistent data augmentation for robust\npattern recognition in industrial sensing."}
{"id": "2502.20162", "pdf": "https://arxiv.org/pdf/2502.20162", "abs": "https://arxiv.org/abs/2502.20162", "authors": ["Aristotelis Ballas", "Christos Diou"], "title": "Gradient-Guided Annealing for Domain Generalization", "categories": ["cs.LG"], "comment": "Paper accepted in CVPR2025", "summary": "Domain Generalization (DG) research has gained considerable traction as of\nlate, since the ability to generalize to unseen data distributions is a\nrequirement that eludes even state-of-the-art training algorithms. In this\npaper we observe that the initial iterations of model training play a key role\nin domain generalization effectiveness, since the loss landscape may be\nsignificantly different across the training and test distributions, contrary to\nthe case of i.i.d. data. Conflicts between gradients of the loss components of\neach domain lead the optimization procedure to undesirable local minima that do\nnot capture the domain-invariant features of the target classes. We propose\nalleviating domain conflicts in model optimization, by iteratively annealing\nthe parameters of a model in the early stages of training and searching for\npoints where gradients align between domains. By discovering a set of parameter\nvalues where gradients are updated towards the same direction for each data\ndistribution present in the training set, the proposed Gradient-Guided\nAnnealing (GGA) algorithm encourages models to seek out minima that exhibit\nimproved robustness against domain shifts. The efficacy of GGA is evaluated on\nfive widely accepted and challenging image classification domain generalization\nbenchmarks, where its use alone is able to establish highly competitive or even\nstate-of-the-art performance. Moreover, when combined with previously proposed\ndomain-generalization algorithms it is able to consistently improve their\neffectiveness by significant margins."}
{"id": "2503.14338", "pdf": "https://arxiv.org/pdf/2503.14338", "abs": "https://arxiv.org/abs/2503.14338", "authors": ["Daniel Herbst", "Stefanie Jegelka"], "title": "Higher-Order Graphon Neural Networks: Approximation and Cut Distance", "categories": ["cs.LG"], "comment": "53 pages, 6 figures, 2 tables. ICLR 2025 camera ready", "summary": "Graph limit models, like graphons for limits of dense graphs, have recently\nbeen used to study size transferability of graph neural networks (GNNs). While\nmost literature focuses on message passing GNNs (MPNNs), in this work we attend\nto the more powerful higher-order GNNs. First, we extend the $k$-WL test for\ngraphons (B\\\"oker, 2023) to the graphon-signal space and introduce\nsignal-weighted homomorphism densities as a key tool. As an exemplary focus, we\ngeneralize Invariant Graph Networks (IGNs) to graphons, proposing Invariant\nGraphon Networks (IWNs) defined via a subset of the IGN basis corresponding to\nbounded linear operators. Even with this restricted basis, we show that IWNs of\norder $k$ are at least as powerful as the $k$-WL test, and we establish\nuniversal approximation results for graphon-signals in $L^p$ distances. This\nsignificantly extends the prior work of Cai & Wang (2022), showing that IWNs--a\nsubset of their IGN-small--retain effectively the same expressivity as the full\nIGN basis in the limit. In contrast to their approach, our blueprint of IWNs\nalso aligns better with the geometry of graphon space, for example facilitating\ncomparability to MPNNs. We highlight that, while typical higher-order GNNs are\ndiscontinuous w.r.t. cut distance--which causes their lack of convergence and\nis inherently tied to the definition of $k$-WL--transferability remains\nachievable."}
{"id": "2503.21223", "pdf": "https://arxiv.org/pdf/2503.21223", "abs": "https://arxiv.org/abs/2503.21223", "authors": ["Zhihan Zhang", "Xunkai Li", "Zhu Lei", "Guang Zeng", "Ronghua Li", "Guoren Wang"], "title": "Rethinking Graph Structure Learning in the Era of LLMs", "categories": ["cs.LG"], "comment": "29 pages, 9 figures", "summary": "Recently, the emergence of LLMs has prompted researchers to integrate\nlanguage descriptions into graphs, aiming to enhance model encoding\ncapabilities from a data-centric perspective. This graph representation is\ncalled text-attributed graphs (TAGs). A review of prior advancements highlights\nthat graph structure learning (GSL) is a pivotal technique for improving data\nutility, making it highly relevant to efficient TAG learning. However, most GSL\nmethods are tailored for traditional graphs without textual information,\nunderscoring the necessity of developing a new GSL paradigm. Despite clear\nmotivations, it remains challenging: (1) How can we define a reasonable\noptimization objective for GSL in the era of LLMs, considering the massive\nparameters in LLM? (2) How can we design an efficient model architecture that\nenables seamless integration of LLM for this optimization objective? For\nQuestion 1, we reformulate existing GSL optimization objectives as a tree\noptimization framework, shifting the focus from obtaining a well-trained edge\npredictor to a language-aware tree sampler. For Question 2, we propose\ndecoupled and training-free model design principles for LLM integration,\nshifting the focus from computation-intensive fine-tuning to more efficient\ninference. Based on this, we propose Large Language and Tree Assistant (LLaTA),\nwhich leverages tree-based LLM in-context learning to enhance the understanding\nof topology and text, enabling reliable inference and generating improved graph\nstructure. Extensive experiments on 10 datasets demonstrate that LLaTA enjoys\nflexibility-incorporated with any backbone; scalability-outperforms other\nLLM-enhanced graph learning methods; effectiveness-achieves SOTA predictive\nperformance."}
{"id": "2503.22567", "pdf": "https://arxiv.org/pdf/2503.22567", "abs": "https://arxiv.org/abs/2503.22567", "authors": ["Josh Millar", "Yushan Huang", "Sarab Sethi", "Hamed Haddadi", "Anil Madhavapeddy"], "title": "Benchmarking Ultra-Low-Power $μ$NPUs", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "Efficient on-device neural network (NN) inference has various advantages over\ncloud-based processing, including predictable latency, enhanced privacy,\ngreater reliability, and reduced operating costs for vendors. This has sparked\nthe recent rapid development of microcontroller-scale NN accelerators, often\nreferred to as neural processing units ($\\mu$NPUs), designed specifically for\nultra-low-power applications.\n  In this paper we present the first comparative evaluation of a number of\ncommercially-available $\\mu$NPUs, as well as the first independent benchmarks\nfor several of these platforms. We develop and open-source a model compilation\nframework to enable consistent benchmarking of quantized models across diverse\n$\\mu$NPU hardware. Our benchmark targets end-to-end performance and includes\nmodel inference latency, power consumption, and memory overhead, alongside\nother factors. The resulting analysis uncovers both expected performance trends\nas well as surprising disparities between hardware specifications and actual\nperformance, including $\\mu$NPUs exhibiting unexpected scaling behaviors with\nincreasing model complexity. Our framework provides a foundation for further\nevaluation of $\\mu$NPU platforms alongside valuable insights for both hardware\ndesigners and software developers in this rapidly evolving space."}
{"id": "2504.03122", "pdf": "https://arxiv.org/pdf/2504.03122", "abs": "https://arxiv.org/abs/2504.03122", "authors": ["Abdelmonem Elrefaey", "Rong Pan"], "title": "From Observation to Orientation: an Adaptive Integer Programming Approach to Intervention Design", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Using both observational and experimental data, a causal discovery process\ncan identify the causal relationships between variables. A unique adaptive\nintervention design paradigm is presented in this work, where causal directed\nacyclic graphs (DAGs) are for effectively recovered with practical budgetary\nconsiderations. In order to choose treatments that optimize information gain\nunder these considerations, an iterative integer programming (IP) approach is\nproposed, which drastically reduces the number of experiments required.\nSimulations over a broad range of graph sizes and edge densities are used to\nassess the effectiveness of the suggested approach. Results show that the\nproposed adaptive IP approach achieves full causal graph recovery with fewer\nintervention iterations and variable manipulations than random intervention\nbaselines, and it is also flexible enough to accommodate a variety of practical\nconstraints."}
{"id": "2504.04202", "pdf": "https://arxiv.org/pdf/2504.04202", "abs": "https://arxiv.org/abs/2504.04202", "authors": ["Harvey Dam", "Tripti Agarwal", "Ganesh Gopalakrishnan"], "title": "Directional Sign Loss: A Topology-Preserving Loss Function that Approximates the Sign of Finite Differences", "categories": ["cs.LG", "I.2.6"], "comment": null, "summary": "Preserving critical topological features in learned latent spaces is a\nfundamental challenge in representation learning, particularly for\ntopology-sensitive data. This paper introduces directional sign loss (DSL), a\nnovel loss function that approximates the number of mismatches in the signs of\nfinite differences between corresponding elements of two arrays. By penalizing\ndiscrepancies in critical points between input and reconstructed data, DSL\nencourages autoencoders and other learnable compressors to retain the\ntopological features of the original data. We present the mathematical\nformulation, complexity analysis, and practical implementation of DSL,\ncomparing its behavior to its non-differentiable counterpart and to other\ntopological measures. Experiments on one-, two-, and three-dimensional data\nshow that combining DSL with traditional loss functions preserves topological\nfeatures more effectively than traditional losses alone. Moreover, DSL serves\nas a differentiable, efficient proxy for common topology-based metrics,\nenabling its use in gradient-based optimization frameworks."}
{"id": "2504.18091", "pdf": "https://arxiv.org/pdf/2504.18091", "abs": "https://arxiv.org/abs/2504.18091", "authors": ["Shota Deguchi", "Mitsuteru Asai"], "title": "Reliable and Efficient Inverse Analysis using Physics-Informed Neural Networks with Distance Functions and Adaptive Weight Tuning", "categories": ["cs.LG"], "comment": "Added Figures 9, 10(b), 11(b), and A1, which were previously omitted\n  for clarity, but are now included for completeness. All results remain\n  unchanged", "summary": "Physics-informed neural networks have attracted significant attention in\nscientific machine learning for their capability to solve forward and inverse\nproblems governed by partial differential equations. However, the accuracy of\nPINN solutions is often limited by the treatment of boundary conditions.\nConventional penalty-based methods, which incorporate boundary conditions as\npenalty terms in the loss function, cannot guarantee exact satisfaction of the\ngiven boundary conditions and are highly sensitive to the choice of penalty\nparameters. This paper demonstrates that distance functions, specifically\nR-functions, can be leveraged to enforce boundary conditions, overcoming these\nlimitations. R-functions provide normalized distance fields, enabling accurate\nrepresentation of boundary geometries, including non-convex domains, and\nfacilitating various types of boundary conditions. We extend this distance\nfunction-based boundary condition imposition method to inverse problems using\nPINNs and introduce an adaptive weight tuning technique to ensure reliable and\nefficient inverse analysis. We demonstrate the efficacy of the method through\nseveral numerical experiments. Numerical results show that the proposed method\nsolves inverse problems more accurately and efficiently than penalty-based\nmethods, even in the presence of complex non-convex geometries. This approach\noffers a reliable and efficient framework for inverse analysis using PINNs,\nwith potential applications across a wide range of engineering problems."}
{"id": "2504.21389", "pdf": "https://arxiv.org/pdf/2504.21389", "abs": "https://arxiv.org/abs/2504.21389", "authors": ["Jianyu Zhang"], "title": "Enhanced semi-supervised stamping process monitoring with physically-informed feature extraction", "categories": ["cs.LG"], "comment": null, "summary": "In tackling frequent batch anomalies in high-speed stamping processes, this\nstudy introduces a novel semi-supervised in-process anomaly monitoring\nframework, utilizing accelerometer signals and physics information, to capture\nthe process anomaly effectively. The proposed framework facilitates the\nconstruction of a monitoring model with imbalanced sample distribution, which\nenables in-process condition monitoring in real-time to prevent batch\nanomalies, which helps to reduce batch defects risk and enhance production\nyield. Firstly, to effectively capture key features from raw data containing\nredundant information, a hybrid feature extraction algorithm is proposed to\nutilize data-driven methods and physical mechanisms simultaneously. Secondly,\nto address the challenge brought by imbalanced sample distribution, a\nsemi-supervised anomaly detection model is established, which merely employs\nnormal samples to build a golden baseline model, and a novel deviation score is\nproposed to quantify the anomaly level of each online stamping stroke. The\neffectiveness of the proposed feature extraction method is validated with\nvarious classification algorithms. A real-world in-process dataset from\nstamping manufacturing workshop is employed to illustrate the superiority of\nproposed semi-supervised framework with enhance performance for process anomaly\nmonitoring."}
{"id": "2505.00307", "pdf": "https://arxiv.org/pdf/2505.00307", "abs": "https://arxiv.org/abs/2505.00307", "authors": ["Yu-Hsiang Lan", "Eric K. Oermann"], "title": "Gateformer: Advancing Multivariate Time Series Forecasting through Temporal and Variate-Wise Attention with Gated Representations", "categories": ["cs.LG"], "comment": null, "summary": "There has been a recent surge of interest in time series modeling using the\nTransformer architecture. However, forecasting multivariate time series with\nTransformer presents a unique challenge as it requires modeling both temporal\n(cross-time) and variate (cross-variate) dependencies. While Transformer-based\nmodels have gained popularity for their flexibility in capturing both\nsequential and cross-variate relationships, it is unclear how to best integrate\nthese two sources of information in the context of the Transformer architecture\nwhile optimizing for both performance and efficiency. We re-purpose the\nTransformer architecture to effectively model both cross-time and cross-variate\ndependencies. Our approach begins by embedding each variate independently into\na variate-wise representation that captures its cross-time dynamics, and then\nmodels cross-variate dependencies through attention mechanisms on these learned\nembeddings. Gating operations in both cross-time and cross-variate modeling\nphases regulate information flow, allowing the model to focus on the most\nrelevant features for accurate predictions. Our method achieves\nstate-of-the-art performance across 13 real-world datasets and can be\nseamlessly integrated into other Transformer-based and LLM-based forecasters,\ndelivering performance improvements up to 20.7\\% over original models. Code is\navailable at this repository: https://github.com/nyuolab/Gateformer."}
{"id": "2505.00410", "pdf": "https://arxiv.org/pdf/2505.00410", "abs": "https://arxiv.org/abs/2505.00410", "authors": ["Farhana Elias", "Md Shihab Reza", "Muhammad Zawad Mahmud", "Samiha Islam", "Shahran Rahman Alve"], "title": "Machine Learning Meets Transparency in Osteoporosis Risk Assessment: A Comparative Study of ML and Explainability Analysis", "categories": ["cs.LG"], "comment": "Submitted in an international conference", "summary": "The present research tackles the difficulty of predicting osteoporosis risk\nvia machine learning (ML) approaches, emphasizing the use of explainable\nartificial intelligence (XAI) to improve model transparency. Osteoporosis is a\nsignificant public health concern, sometimes remaining untreated owing to its\nasymptomatic characteristics, and early identification is essential to avert\nfractures. The research assesses six machine learning classifiers: Random\nForest, Logistic Regression, XGBoost, AdaBoost, LightGBM, and Gradient Boosting\nand utilizes a dataset based on clinical, demographic, and lifestyle variables.\nThe models are refined using GridSearchCV to calibrate hyperparameters, with\nthe objective of enhancing predictive efficacy. XGBoost had the greatest\naccuracy (91%) among the evaluated models, surpassing others in precision\n(0.92), recall (0.91), and F1-score (0.90). The research further integrates XAI\napproaches, such as SHAP, LIME, and Permutation Feature Importance, to\nelucidate the decision-making process of the optimal model. The study indicates\nthat age is the primary determinant in forecasting osteoporosis risk, followed\nby hormonal alterations and familial history. These results corroborate\nclinical knowledge and affirm the models' therapeutic significance. The\nresearch underscores the significance of explainability in machine learning\nmodels for healthcare applications, guaranteeing that physicians can rely on\nthe system's predictions. The report ultimately proposes directions for further\nresearch, such as validation across varied populations and the integration of\nsupplementary biomarkers for enhanced predictive accuracy."}
{"id": "2505.01386", "pdf": "https://arxiv.org/pdf/2505.01386", "abs": "https://arxiv.org/abs/2505.01386", "authors": ["Irene Wang", "Newsha Ardalani", "Mostafa Elhoushi", "Daniel Jiang", "Samuel Hsia", "Ekin Sumbul", "Divya Mahajan", "Carole-Jean Wu", "Bilge Acun"], "title": "Carbon Aware Transformers Through Joint Model-Hardware Optimization", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "The rapid growth of machine learning (ML) systems necessitates a more\ncomprehensive evaluation of their environmental impact, particularly their\ncarbon footprint, which comprises operational carbon from training and\ninference execution and embodied carbon from hardware manufacturing and its\nentire life-cycle. Despite the increasing importance of embodied emissions,\nthere is a lack of tools and frameworks to holistically quantify and optimize\nthe total carbon footprint of ML systems. To address this, we propose\nCATransformers, a carbon-aware architecture search framework that enables\nsustainability-driven co-optimization of ML models and hardware architectures.\nBy incorporating both operational and embodied carbon metrics into early design\nspace exploration of domain-specific hardware accelerators, CATransformers\ndemonstrates that optimizing for carbon yields design choices distinct from\nthose optimized solely for latency or energy efficiency. We apply our framework\nto multi-modal CLIP-based models, producing CarbonCLIP, a family of CLIP models\nachieving up to 17% reduction in total carbon emissions while maintaining\naccuracy and latency compared to state-of-the-art edge small CLIP baselines.\nThis work underscores the need for holistic optimization methods to design\nhigh-performance, environmentally sustainable AI systems."}
{"id": "2505.05192", "pdf": "https://arxiv.org/pdf/2505.05192", "abs": "https://arxiv.org/abs/2505.05192", "authors": ["Ruichu Cai", "Junjie Wan", "Weilin Chen", "Zeqin Yang", "Zijian Li", "Peng Zhen", "Jiecheng Guo"], "title": "Long-Term Individual Causal Effect Estimation via Identifiable Latent Representation Learning", "categories": ["cs.LG"], "comment": null, "summary": "Estimating long-term causal effects by combining long-term observational and\nshort-term experimental data is a crucial but challenging problem in many\nreal-world scenarios. In existing methods, several ideal assumptions, e.g.\nlatent unconfoundedness assumption or additive equi-confounding bias\nassumption, are proposed to address the latent confounder problem raised by the\nobservational data. However, in real-world applications, these assumptions are\ntypically violated which limits their practical effectiveness. In this paper,\nwe tackle the problem of estimating the long-term individual causal effects\nwithout the aforementioned assumptions. Specifically, we propose to utilize the\nnatural heterogeneity of data, such as data from multiple sources, to identify\nlatent confounders, thereby significantly avoiding reliance on idealized\nassumptions. Practically, we devise a latent representation learning-based\nestimator of long-term causal effects. Theoretically, we establish the\nidentifiability of latent confounders, with which we further achieve long-term\neffect identification. Extensive experimental studies, conducted on multiple\nsynthetic and semi-synthetic datasets, demonstrate the effectiveness of our\nproposed method."}
{"id": "2310.16688", "pdf": "https://arxiv.org/pdf/2310.16688", "abs": "https://arxiv.org/abs/2310.16688", "authors": ["Philipp Scholl", "Maged Iskandar", "Sebastian Wolf", "Jinoh Lee", "Aras Bacho", "Alexander Dietrich", "Alin Albu-Schäffer", "Gitta Kutyniok"], "title": "Learning-based adaption of robotic friction models", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "In the Fourth Industrial Revolution, wherein artificial intelligence and the\nautomation of machines occupy a central role, the deployment of robots is\nindispensable. However, the manufacturing process using robots, especially in\ncollaboration with humans, is highly intricate. In particular, modeling the\nfriction torque in robotic joints is a longstanding problem due to the lack of\na good mathematical description. This motivates the usage of data-driven\nmethods in recent works. However, model-based and data-driven models often\nexhibit limitations in their ability to generalize beyond the specific dynamics\nthey were trained on, as we demonstrate in this paper. To address this\nchallenge, we introduce a novel approach based on residual learning, which aims\nto adapt an existing friction model to new dynamics using as little data as\npossible. We validate our approach by training a base neural network on a\nsymmetric friction data set to learn an accurate relation between the velocity\nand the friction torque. Subsequently, to adapt to more complex asymmetric\nsettings, we train a second network on a small dataset, focusing on predicting\nthe residual of the initial network's output. By combining the output of both\nnetworks in a suitable manner, our proposed estimator outperforms the\nconventional model-based approach, an extended LuGre model, and the base neural\nnetwork significantly. Furthermore, we evaluate our method on trajectories\ninvolving external loads and still observe a substantial improvement,\napproximately 60-70%, over the conventional approach. Our method does not rely\non data with external load during training, eliminating the need for external\ntorque sensors. This demonstrates the generalization capability of our\napproach, even with a small amount of data--less than a minute--enabling\nadaptation to diverse scenarios based on prior knowledge about friction in\ndifferent settings."}
{"id": "2401.02940", "pdf": "https://arxiv.org/pdf/2401.02940", "abs": "https://arxiv.org/abs/2401.02940", "authors": ["Jonathan Z. Lu", "Lucy Jiao", "Kristina Wolinski", "Milan Kornjača", "Hong-Ye Hu", "Sergio Cantu", "Fangli Liu", "Susanne F. Yelin", "Sheng-Tao Wang"], "title": "Digital-analog quantum learning on Rydberg atom arrays", "categories": ["quant-ph", "cs.LG"], "comment": "23 pages, 22 figures. Version 2 for Quantum Science and Technology:\n  https://iopscience.iop.org/article/10.1088/2058-9565/ad9177", "summary": "We propose hybrid digital-analog learning algorithms on Rydberg atom arrays,\ncombining the potentially practical utility and near-term realizability of\nquantum learning with the rapidly scaling architectures of neutral atoms. Our\nconstruction requires only single-qubit operations in the digital setting and\nglobal driving according to the Rydberg Hamiltonian in the analog setting. We\nperform a comprehensive numerical study of our algorithm on both classical and\nquantum data, given respectively by handwritten digit classification and\nunsupervised quantum phase boundary learning. We show in the two representative\nproblems that digital-analog learning is not only feasible in the near term,\nbut also requires shorter circuit depths and is more robust to realistic error\nmodels as compared to digital learning schemes. Our results suggest that\ndigital-analog learning opens a promising path towards improved variational\nquantum learning experiments in the near term."}
{"id": "2401.05363", "pdf": "https://arxiv.org/pdf/2401.05363", "abs": "https://arxiv.org/abs/2401.05363", "authors": ["Jiquan Wang", "Sha Zhao", "Haiteng Jiang", "Shijian Li", "Tao Li", "Gang Pan"], "title": "Generalizable Sleep Staging via Multi-Level Domain Alignment", "categories": ["eess.SP", "cs.LG"], "comment": "Accepted by the Thirty-Eighth AAAI Conference on Artificial\n  Intelligence (AAAI-24)", "summary": "Automatic sleep staging is essential for sleep assessment and disorder\ndiagnosis. Most existing methods depend on one specific dataset and are limited\nto be generalized to other unseen datasets, for which the training data and\ntesting data are from the same dataset. In this paper, we introduce domain\ngeneralization into automatic sleep staging and propose the task of\ngeneralizable sleep staging which aims to improve the model generalization\nability to unseen datasets. Inspired by existing domain generalization methods,\nwe adopt the feature alignment idea and propose a framework called SleepDG to\nsolve it. Considering both of local salient features and sequential features\nare important for sleep staging, we propose a Multi-level Feature Alignment\ncombining epoch-level and sequence-level feature alignment to learn\ndomain-invariant feature representations. Specifically, we design an\nEpoch-level Feature Alignment to align the feature distribution of each single\nsleep epoch among different domains, and a Sequence-level Feature Alignment to\nminimize the discrepancy of sequential features among different domains.\nSleepDG is validated on five public datasets, achieving the state-of-the-art\nperformance."}
{"id": "2402.10088", "pdf": "https://arxiv.org/pdf/2402.10088", "abs": "https://arxiv.org/abs/2402.10088", "authors": ["Matteo Priorelli", "Ivilin Peev Stoianov"], "title": "Deep hybrid models: infer and plan in a dynamic world", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "To determine an optimal plan for complex tasks, one often deals with dynamic\nand hierarchical relationships between several entities. Traditionally, such\nproblems are tackled with optimal control, which relies on the optimization of\ncost functions; instead, a recent biologically-motivated proposal casts\nplanning and control as an inference process. Active inference assumes that\naction and perception are two complementary aspects of life whereby the role of\nthe former is to fulfill the predictions inferred by the latter. Here, we\npresent an active inference approach that exploits discrete and continuous\nprocessing, based on three features: the representation of potential body\nconfigurations in relation to the objects of interest; the use of hierarchical\nrelationships that enable the agent to easily interpret and flexibly expand its\nbody schema for tool use; the definition of potential trajectories related to\nthe agent's intentions, used to infer and plan with dynamic elements at\ndifferent temporal scales. We evaluate this deep hybrid model on a habitual\ntask: reaching a moving object after having picked a moving tool. We show that\nthe model can tackle the presented task under different conditions. This study\nextends past work on planning as inference and advances an alternative\ndirection to optimal control."}
{"id": "2403.11565", "pdf": "https://arxiv.org/pdf/2403.11565", "abs": "https://arxiv.org/abs/2403.11565", "authors": ["Siyuan Zhang", "Nachuan Xiao", "Xin Liu"], "title": "Convergence of Decentralized Stochastic Subgradient-based Methods for Nonsmooth Nonconvex functions", "categories": ["math.OC", "cs.LG"], "comment": "35 pages", "summary": "In this paper, we focus on the decentralized stochastic subgradient-based\nmethods in minimizing nonsmooth nonconvex functions without Clarke regularity,\nespecially in the decentralized training of nonsmooth neural networks. We\npropose a general framework that unifies various decentralized\nsubgradient-based methods, such as decentralized stochastic subgradient descent\n(DSGD), DSGD with gradient-tracking technique (DSGD-T), and DSGD with momentum\n(DSGD-M). To establish the convergence properties of our proposed framework, we\nrelate the discrete iterates to the trajectories of a continuous-time\ndifferential inclusion, which is assumed to have a coercive Lyapunov function\nwith a stable set $\\mathcal{A}$. We prove the asymptotic convergence of the\niterates to the stable set $\\mathcal{A}$ with sufficiently small and\ndiminishing step-sizes. These results provide first convergence guarantees for\nsome well-recognized of decentralized stochastic subgradient-based methods\nwithout Clarke regularity of the objective function. Preliminary numerical\nexperiments demonstrate that our proposed framework yields highly efficient\ndecentralized stochastic subgradient-based methods with convergence guarantees\nin the training of nonsmooth neural networks."}
{"id": "2407.04495", "pdf": "https://arxiv.org/pdf/2407.04495", "abs": "https://arxiv.org/abs/2407.04495", "authors": ["Kotaro Ikeda", "Tomoya Uda", "Daisuke Okanohara", "Sosuke Ito"], "title": "Speed-accuracy relations for diffusion models: Wisdom from nonequilibrium thermodynamics and optimal transport", "categories": ["cond-mat.stat-mech", "cs.LG", "stat.ML"], "comment": "37 pages, 9 figures", "summary": "We discuss a connection between a generative model, called the diffusion\nmodel, and nonequilibrium thermodynamics for the Fokker-Planck equation, called\nstochastic thermodynamics. Using techniques from stochastic thermodynamics, we\nderive the speed-accuracy relations for diffusion models, which are\ninequalities that relate the accuracy of data generation to the entropy\nproduction rate. This relation can be interpreted as the speed of the diffusion\ndynamics in the absence of the non-conservative force. From a stochastic\nthermodynamic perspective, our results provide quantitative insight into how\nbest to generate data in diffusion models. The optimal learning protocol is\nintroduced by the geodesic of space of the 2-Wasserstein distance in optimal\ntransport theory. We numerically illustrate the validity of the speed-accuracy\nrelations for diffusion models with different noise schedules and different\ndata. We numerically discuss our results for optimal and suboptimal learning\nprotocols. We also demonstrate the applicability of our results to data\ngeneration from the real-world image datasets."}
{"id": "2407.07179", "pdf": "https://arxiv.org/pdf/2407.07179", "abs": "https://arxiv.org/abs/2407.07179", "authors": ["Sascha Caron", "Nadezhda Dobreva", "Antonio Ferrer Sánchez", "José D. Martín-Guerrero", "Uraz Odyurt", "Roberto Ruiz de Austri Bazan", "Zef Wolffs", "Yue Zhao"], "title": "TrackFormers: In Search of Transformer-Based Particle Tracking for the High-Luminosity LHC Era", "categories": ["hep-ex", "cs.LG"], "comment": null, "summary": "High-Energy Physics experiments are facing a multi-fold data increase with\nevery new iteration. This is certainly the case for the upcoming\nHigh-Luminosity LHC upgrade. Such increased data processing requirements forces\nrevisions to almost every step of the data processing pipeline. One such step\nin need of an overhaul is the task of particle track reconstruction, a.k.a.,\ntracking. A Machine Learning-assisted solution is expected to provide\nsignificant improvements, since the most time-consuming step in tracking is the\nassignment of hits to particles or track candidates. This is the topic of this\npaper.\n  We take inspiration from large language models. As such, we consider two\napproaches: the prediction of the next word in a sentence (next hit point in a\ntrack), as well as the one-shot prediction of all hits within an event. In an\nextensive design effort, we have experimented with three models based on the\nTransformer architecture and one model based on the U-Net architecture,\nperforming track association predictions for collision event hit points. In our\nevaluation, we consider a spectrum of simple to complex representations of the\nproblem, eliminating designs with lower metrics early on. We report extensive\nresults, covering both prediction accuracy (score) and computational\nperformance. We have made use of the REDVID simulation framework, as well as\nreductions applied to the TrackML data set, to compose five data sets from\nsimple to complex, for our experiments. The results highlight distinct\nadvantages among different designs in terms of prediction accuracy and\ncomputational performance, demonstrating the efficiency of our methodology.\nMost importantly, the results show the viability of a one-shot\nencoder-classifier based Transformer solution as a practical approach for the\ntask of tracking."}
{"id": "2410.05336", "pdf": "https://arxiv.org/pdf/2410.05336", "abs": "https://arxiv.org/abs/2410.05336", "authors": ["Bart van Laatum", "Eldert J. van Henten", "Sjoerd Boersma"], "title": "GreenLight-Gym: Reinforcement learning benchmark environment for control of greenhouse production systems", "categories": ["eess.SY", "cs.LG", "cs.SY", "math.OC"], "comment": "This submission replaces our previous pre-print with the version\n  accepted to the 2025 IFAC conference. A new Git repository\n  (https://github.com/BartvLaatum/GreenLight-Gym) accompanies this paper; the\n  repository for the prior version remains live at\n  https://github.com/YourOrg/GreenLightGym. The earlier pre-print is still\n  available on ArXiv under the previous submission number", "summary": "This study presents GreenLight-Gym, a new, fast, open-source benchmark\nenvironment for developing reinforcement learning (RL) methods in greenhouse\ncrop production control. Built on the state-of-the-art GreenLight model, it\nfeatures a differentiable C++ implementation leveraging the CasADi framework\nfor efficient numerical integration. GreenLight-Gym improves simulation speed\nby a factor of 17 over the original GreenLight implementation. A modular Python\nenvironment wrapper enables flexible configuration of control tasks and\nRL-based controllers. This flexibility is demonstrated by learning controllers\nunder parametric uncertainty using two well-known RL algorithms. GreenLight-Gym\nprovides a standardized benchmark for advancing RL methodologies and evaluating\ngreenhouse control solutions under diverse conditions. The greenhouse control\ncommunity is encouraged to use and extend this benchmark to accelerate\ninnovation in greenhouse crop production."}
{"id": "2410.08222", "pdf": "https://arxiv.org/pdf/2410.08222", "abs": "https://arxiv.org/abs/2410.08222", "authors": ["Yulong Feng", "Jing Xu", "Liujun Hu", "Guanghui Yu", "Xiangyang Duan"], "title": "Variational Source-Channel Coding for Semantic Communication", "categories": ["eess.SP", "cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "Semantic communication technology emerges as a pivotal bridge connecting AI\nwith classical communication. The current semantic communication systems are\ngenerally modeled as an Auto-Encoder (AE). AE lacks a deep integration of AI\nprinciples with communication strategies due to its inability to effectively\ncapture channel dynamics. This gap makes it difficult to justify the need for\njoint source-channel coding (JSCC) and to explain why performance improves.\nThis paper begins by exploring lossless and lossy communication, highlighting\nthat the inclusion of data distortion distinguishes semantic communication from\nclassical communication. It breaks the conditions for the separation theorem to\nhold and explains why the amount of data transferred by semantic communication\nis less. Therefore, employing JSCC becomes imperative for achieving optimal\nsemantic communication. Moreover, a Variational Source-Channel Coding (VSCC)\nmethod is proposed for constructing semantic communication systems based on\ndata distortion theory, integrating variational inference and channel\ncharacteristics. Using a deep learning network, we develop a semantic\ncommunication system employing the VSCC method and demonstrate its capability\nfor semantic transmission. We also establish semantic communication systems of\nequivalent complexity employing the AE method and the VAE method. Experimental\nresults reveal that the VSCC model offers superior interpretability compared to\nAE model, as it clearly captures the semantic features of the transmitted data,\nrepresented as the variance of latent variables in our experiments. In\naddition, VSCC model exhibits superior semantic transmission capabilities\ncompared to VAE model. At the same level of data distortion evaluated by PSNR,\nVSCC model exhibits stronger human interpretability, which can be partially\nassessed by SSIM."}
{"id": "2412.16303", "pdf": "https://arxiv.org/pdf/2412.16303", "abs": "https://arxiv.org/abs/2412.16303", "authors": ["Daniel C. Hackett", "Joshua Isaacson", "Shirley Weishi Li", "Karla Tame-Narvaez", "Michael L. Wagman"], "title": "Machine Learning Neutrino-Nucleus Cross Sections", "categories": ["hep-ph", "cs.LG", "hep-ex", "nucl-th"], "comment": "5 pages, 2 figures + 6 pages Supplemental Material. v2: systematic\n  uncertainty checks and minor revisions", "summary": "Neutrino-nucleus scattering cross sections are critical theoretical inputs\nfor long-baseline neutrino oscillation experiments. However, robust modeling of\nthese cross sections remains challenging. For a simple but physically motivated\ntoy model of the DUNE experiment, we demonstrate that an accurate\nneural-network model of the cross section -- leveraging Standard Model\nsymmetries -- can be learned from near-detector data. We then perform a\nneutrino oscillation analysis with simulated far-detector events, finding that\nthe modeled cross section achieves results consistent with what could be\nobtained if the true cross section were known exactly. This proof-of-principle\nstudy highlights the potential of future neutrino near-detector datasets and\ndata-driven cross-section models."}
{"id": "2504.14002", "pdf": "https://arxiv.org/pdf/2504.14002", "abs": "https://arxiv.org/abs/2504.14002", "authors": ["Francesco Perciavalle", "Francesco Plastina", "Michele Pisarra", "Nicola Lo Gullo"], "title": "Predicting fermionic densities using a Projected Quantum Kernel method", "categories": ["quant-ph", "cond-mat.str-el", "cs.LG"], "comment": "12 pages, 7 figures", "summary": "We use a support vector regressor based on a projected quantum kernel method\nto predict the density structure of 1D fermionic systems of interest in quantum\nchemistry and quantum matter. The kernel is built on with the observables of a\nquantum reservoir implementable with interacting Rydberg atoms. Training and\ntest data of the fermionic system are generated using a Density Functional\nTheory approach. We test the performance of the method for several Hamiltonian\nparameters, finding a general common behavior of the error as a function of\nmeasurement time. At sufficiently large measurement times, we find that the\nmethod outperforms the classical linear kernel method and can be competitive\nwith the radial basis function method."}
{"id": "2504.16098", "pdf": "https://arxiv.org/pdf/2504.16098", "abs": "https://arxiv.org/abs/2504.16098", "authors": ["Tianning Feng", "Juntong Ni", "Ezequiel Gleichgerrcht", "Wei Jin"], "title": "SeizureFormer: A Transformer Model for IEA-Based Seizure Risk Forecasting", "categories": ["eess.SP", "cs.LG", "I.5.1; I.2.6"], "comment": "9 pages, 2 figures. Submitted as an undergraduate honors thesis at\n  Emory University", "summary": "We present SeizureFormer, a Transformer-based model for long-term seizure\nrisk forecasting using interictal epileptiform activity (IEA) surrogate\nbiomarkers and long episode (LE) biomarkers from responsive neurostimulation\n(RNS) systems. Unlike raw scalp EEG-based models, SeizureFormer leverages\nstructured, clinically relevant features and integrates CNN-based patch\nembedding, multi-head self-attention, and squeeze-and-excitation blocks to\nmodel both short-term dynamics and long-term seizure cycles. Tested across five\npatients and multiple prediction windows (1 to 14 days), SeizureFormer achieved\nstate-of-the-art performance with mean ROC AUC of 79.44 percent and mean PR AUC\nof 76.29 percent. Compared to statistical, machine learning, and deep learning\nbaselines, it demonstrates enhanced generalizability and seizure risk\nforecasting performance under class imbalance. This work supports future\nclinical integration of interpretable and robust seizure forecasting tools for\npersonalized epilepsy management."}
{"id": "2505.01454", "pdf": "https://arxiv.org/pdf/2505.01454", "abs": "https://arxiv.org/abs/2505.01454", "authors": ["Zhiyong Jin", "Runhua Xu", "Chao Li", "Yizhong Liu", "Jianxin Li"], "title": "Sparsification Under Siege: Defending Against Poisoning Attacks in Communication-Efficient Federated Learning", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Federated Learning (FL) enables collaborative model training across\ndistributed clients while preserving data privacy, yet it faces significant\nchallenges in communication efficiency and vulnerability to poisoning attacks.\nWhile sparsification techniques mitigate communication overhead by transmitting\nonly critical model parameters, they inadvertently amplify security risks:\nadversarial clients can exploit sparse updates to evade detection and degrade\nmodel performance. Existing defense mechanisms, designed for standard FL\ncommunication scenarios, are ineffective in addressing these vulnerabilities\nwithin sparsified FL. To bridge this gap, we propose FLARE, a novel federated\nlearning framework that integrates sparse index mask inspection and model\nupdate sign similarity analysis to detect and mitigate poisoning attacks in\nsparsified FL. Extensive experiments across multiple datasets and adversarial\nscenarios demonstrate that FLARE significantly outperforms existing defense\nstrategies, effectively securing sparsified FL against poisoning attacks while\nmaintaining communication efficiency."}
