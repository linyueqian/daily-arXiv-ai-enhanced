{"id": "2506.22439", "pdf": "https://arxiv.org/pdf/2506.22439", "abs": "https://arxiv.org/abs/2506.22439", "authors": ["Javier Conde", "Miguel Gonz\u00e1lez", "Mar\u00eda Grandury", "Gonzalo Mart\u00ednez", "Pedro Reviriego", "Mar Brysbaert"], "title": "Psycholinguistic Word Features: a New Approach for the Evaluation of LLMs Alignment with Humans", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted for the GEM2 workshop at ACL 2025", "summary": "The evaluation of LLMs has so far focused primarily on how well they can\nperform different tasks such as reasoning, question-answering, paraphrasing, or\ntranslating. For most of these tasks, performance can be measured with\nobjective metrics, such as the number of correct answers. However, other\nlanguage features are not easily quantified. For example, arousal,\nconcreteness, or gender associated with a given word, as well as the extent to\nwhich we experience words with senses and relate them to a specific sense.\nThose features have been studied for many years by psycholinguistics,\nconducting large-scale experiments with humans to produce ratings for thousands\nof words. This opens an opportunity to evaluate how well LLMs align with human\nratings on these word features, taking advantage of existing studies that cover\nmany different language features in a large number of words. In this paper, we\nevaluate the alignment of a representative group of LLMs with human ratings on\ntwo psycholinguistic datasets: the Glasgow and Lancaster norms. These datasets\ncover thirteen features over thousands of words. The results show that\nalignment is \\textcolor{black}{generally} better in the Glasgow norms evaluated\n(arousal, valence, dominance, concreteness, imageability, familiarity, and\ngender) than on the Lancaster norms evaluated (introceptive, gustatory,\nolfactory, haptic, auditory, and visual). This suggests a potential limitation\nof current LLMs in aligning with human sensory associations for words, which\nmay be due to their lack of embodied cognition present in humans and\nillustrates the usefulness of evaluating LLMs with psycholinguistic datasets.", "AI": {"tldr": "The paper evaluates LLMs' alignment with human psycholinguistic ratings on word features, finding better alignment with Glasgow norms than Lancaster norms, suggesting limitations in sensory associations.", "motivation": "To assess how well LLMs align with human ratings on word features (e.g., arousal, concreteness, sensory associations) using psycholinguistic datasets.", "method": "Evaluation of LLMs using two psycholinguistic datasets (Glasgow and Lancaster norms) covering thirteen features over thousands of words.", "result": "LLMs align better with Glasgow norms (arousal, valence, etc.) than Lancaster norms (sensory features), indicating limitations in sensory associations.", "conclusion": "Current LLMs may lack embodied cognition for sensory associations, highlighting the value of psycholinguistic evaluations."}}
{"id": "2506.22485", "pdf": "https://arxiv.org/pdf/2506.22485", "abs": "https://arxiv.org/abs/2506.22485", "authors": ["Sudip Dasgupta", "Himanshu Shankar"], "title": "AI Agents-as-Judge: Automated Assessment of Accuracy, Consistency, Completeness and Clarity for Enterprise Documents", "categories": ["cs.CL", "cs.AI", "68T07, 68T50", "I.2.1; I.2.3; I.2.7; H.3.3"], "comment": "17 pages, 2 system diagrams, 1 table, no prior conference publication", "summary": "This study presents a modular, multi-agent system for the automated review of\nhighly structured enterprise business documents using AI agents. Unlike prior\nsolutions focused on unstructured texts or limited compliance checks, this\nframework leverages modern orchestration tools such as LangChain, CrewAI,\nTruLens, and Guidance to enable section-by-section evaluation of documents for\naccuracy, consistency, completeness, and clarity. Specialized agents, each\nresponsible for discrete review criteria such as template compliance or factual\ncorrectness, operate in parallel or sequence as required. Evaluation outputs\nare enforced to a standardized, machine-readable schema, supporting downstream\nanalytics and auditability. Continuous monitoring and a feedback loop with\nhuman reviewers allow for iterative system improvement and bias mitigation.\n  Quantitative evaluation demonstrates that the AI Agent-as-Judge system\napproaches or exceeds human performance in key areas: achieving 99% information\nconsistency (vs. 92% for humans), halving error and bias rates, and reducing\naverage review time from 30 to 2.5 minutes per document, with a 95% agreement\nrate between AI and expert human judgment. While promising for a wide range of\nindustries, the study also discusses current limitations, including the need\nfor human oversight in highly specialized domains and the operational cost of\nlarge-scale LLM usage. The proposed system serves as a flexible, auditable, and\nscalable foundation for AI-driven document quality assurance in the enterprise\ncontext.", "AI": {"tldr": "A modular AI system for automated review of structured business documents outperforms humans in consistency, speed, and bias reduction, though human oversight remains necessary in specialized domains.", "motivation": "To improve the review of structured enterprise documents by addressing limitations of prior solutions focused on unstructured texts or limited compliance checks.", "method": "Uses AI agents orchestrated with tools like LangChain and CrewAI for section-by-section evaluation, enforcing standardized outputs and continuous feedback loops.", "result": "Achieves 99% consistency (vs. 92% for humans), reduces review time from 30 to 2.5 minutes, and halves error/bias rates, with 95% agreement with human experts.", "conclusion": "The system is a scalable, auditable foundation for AI-driven document QA, though human oversight and LLM costs remain challenges."}}
{"id": "2506.22486", "pdf": "https://arxiv.org/pdf/2506.22486", "abs": "https://arxiv.org/abs/2506.22486", "authors": ["Ming Cheung"], "title": "Hallucination Detection with Small Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Since the introduction of ChatGPT, large language models (LLMs) have\ndemonstrated significant utility in various tasks, such as answering questions\nthrough retrieval-augmented generation. Context can be retrieved using a\nvectorized database, serving as a foundation for LLMs to generate responses.\nHowever, hallucinations in responses can undermine the reliability of LLMs in\npractical applications, and they are not easily detectable in the absence of\nground truth, particularly in question-and-answer scenarios. This paper\nproposes a framework that integrates multiple small language models to verify\nresponses generated by LLMs using the retrieved context from a vectorized\ndatabase. By breaking down the responses into individual sentences and\nutilizing the probability of generating \"Yes\" tokens from the outputs of\nmultiple models for a given set of questions, responses, and relevant context,\nhallucinations can be detected. The proposed framework is validated through\nexperiments with real datasets comprising over 100 sets of questions, answers,\nand contexts, including responses with fully and partially correct sentences.\nThe results demonstrate a 10\\% improvement in F1 scores for detecting correct\nresponses compared to hallucinations, indicating that multiple small language\nmodels can be effectively employed for answer verification, providing a\nscalable and efficient solution for both academic and practical applications.", "AI": {"tldr": "The paper proposes a framework using multiple small language models to detect hallucinations in LLM-generated responses by verifying sentences against retrieved context, showing a 10% F1 score improvement.", "motivation": "Hallucinations in LLM responses reduce reliability, especially without ground truth, necessitating a scalable verification method.", "method": "Integrates small language models to verify LLM responses by breaking them into sentences and using 'Yes' token probabilities for detection.", "result": "Experiments show a 10% F1 score improvement in detecting correct responses over hallucinations.", "conclusion": "Multiple small language models offer a scalable, efficient solution for verifying LLM responses, enhancing reliability."}}
{"id": "2506.22491", "pdf": "https://arxiv.org/pdf/2506.22491", "abs": "https://arxiv.org/abs/2506.22491", "authors": ["Oliver Warke", "Joemon M. Jose", "Faegheh Hasibi", "Jan Breitsohl"], "title": "PromptAug: Fine-grained Conflict Classification Using Data Augmentation", "categories": ["cs.CL", "cs.AI", "cs.CY", "I.2.7; J.4; K.4.2"], "comment": null, "summary": "Given the rise of conflicts on social media, effective classification models\nto detect harmful behaviours are essential. Following the\ngarbage-in-garbage-out maxim, machine learning performance depends heavily on\ntraining data quality. However, high-quality labelled data, especially for\nnuanced tasks like identifying conflict behaviours, is limited, expensive, and\ndifficult to obtain. Additionally, as social media platforms increasingly\nrestrict access to research data, text data augmentation is gaining attention\nas an alternative to generate training data. Augmenting conflict-related data\nposes unique challenges due to Large Language Model (LLM) guardrails that\nprevent generation of offensive content. This paper introduces PromptAug, an\ninnovative LLM-based data augmentation method. PromptAug achieves statistically\nsignificant improvements of 2% in both accuracy and F1-score on conflict and\nemotion datasets. To thoroughly evaluate PromptAug against other data\naugmentation methods we conduct a robust evaluation using extreme data scarcity\nscenarios, quantitative diversity analysis and a qualitative thematic analysis.\nThe thematic analysis identifies four problematic patterns in augmented text:\nLinguistic Fluidity, Humour Ambiguity, Augmented Content Ambiguity, and\nAugmented Content Misinterpretation.\n  Overall, this work presents PromptAug as an effective method for augmenting\ndata in sensitive tasks like conflict detection, offering a unique,\ninterdisciplinary evaluation grounded in both natural language processing and\nsocial science methodology.", "AI": {"tldr": "PromptAug is an LLM-based data augmentation method for conflict detection, improving accuracy and F1-score by 2%. It addresses challenges like limited high-quality data and LLM guardrails, with a robust evaluation framework.", "motivation": "The need for effective classification models for harmful behaviors on social media, coupled with limited high-quality labeled data and restricted access to research data, motivates the development of PromptAug.", "method": "PromptAug, an innovative LLM-based data augmentation method, is introduced and evaluated using extreme data scarcity scenarios, diversity analysis, and thematic analysis.", "result": "PromptAug achieves a 2% improvement in accuracy and F1-score on conflict and emotion datasets. Thematic analysis identifies four problematic patterns in augmented text.", "conclusion": "PromptAug is effective for augmenting data in sensitive tasks like conflict detection, with a unique interdisciplinary evaluation combining NLP and social science methods."}}
{"id": "2506.22646", "pdf": "https://arxiv.org/pdf/2506.22646", "abs": "https://arxiv.org/abs/2506.22646", "authors": ["Weiqing Wang", "Taejin Park", "Ivan Medennikov", "Jinhan Wang", "Kunal Dhawan", "He Huang", "Nithin Rao Koluguri", "Jagadeesh Balam", "Boris Ginsburg"], "title": "Speaker Targeting via Self-Speaker Adaptation for Multi-talker ASR", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted by INTERSPEECH 2025", "summary": "We propose a self-speaker adaptation method for streaming multi-talker\nautomatic speech recognition (ASR) that eliminates the need for explicit\nspeaker queries. Unlike conventional approaches requiring target speaker\nembeddings or enrollment audio, our technique dynamically adapts individual ASR\ninstances through speaker-wise speech activity prediction. The key innovation\ninvolves injecting speaker-specific kernels generated via speaker supervision\nactivations into selected ASR encoder layers. This enables instantaneous\nspeaker adaptation to target speakers while handling fully overlapped speech\neven in a streaming scenario. Experiments show state-of-the-art performance in\nboth offline and streaming scenarios, demonstrating that our self-adaptive\nmethod effectively addresses severe speech overlap through streamlined\nspeaker-focused recognition. The results validate the proposed self-speaker\nadaptation approach as a robust solution for multi-talker ASR under severe\noverlapping speech conditions.", "AI": {"tldr": "A self-speaker adaptation method for streaming multi-talker ASR eliminates explicit speaker queries by dynamically adapting ASR instances via speaker-wise speech activity prediction.", "motivation": "Conventional methods require target speaker embeddings or enrollment audio, which is inefficient. This work aims to streamline speaker adaptation without such dependencies.", "method": "Speaker-specific kernels, generated via speaker supervision activations, are injected into selected ASR encoder layers for dynamic adaptation.", "result": "State-of-the-art performance in offline and streaming scenarios, handling fully overlapped speech effectively.", "conclusion": "The self-speaker adaptation method is robust for multi-talker ASR under severe overlapping speech conditions."}}
{"id": "2506.22876", "pdf": "https://arxiv.org/pdf/2506.22876", "abs": "https://arxiv.org/abs/2506.22876", "authors": ["Shayak Nandi", "Fernanda M. Eliott"], "title": "Cooperation as Black Box: Conceptual Fluctuation and Diagnostic Tools for Misalignment in MAS", "categories": ["cs.MA"], "comment": null, "summary": "Misalignment in multi-agent systems (MAS) is often treated as a technical\nfailure; yet many such failures originate upstream, during the conceptual\ndesign phase, where semantic ambiguity and normative projection take place.\nThis paper identifies a foundational source of interpretive misalignment in\nMAS: the systemic conflation of cooperation and coordination, and the moral\noverreading that follows. Using the Rabbit-Duck illusion, we illustrate how\nperspective-dependent readings of agent behavior can create epistemic\ninstability. To address this, we introduce the Misalignment Mosaic, a\ndiagnostic framework for diagnosing meaning-level misalignment in MAS. It\ncomprises four components: 1. Terminological Inconsistency, 2. Concept-to-Code\nDecay, 3. Morality as Cooperation, and 4. Interpretive Ambiguity. The Mosaic\nenables researchers to examine how misalignment arises not only through policy\nor reward structures but also through language, framing, and design\nassumptions. While this paper focuses on the specific ambiguity between\ncoordination and cooperation, the Mosaic generalizes to other overloaded\nconcepts in MAS, such as alignment, autonomy, and trust. Rather than define\ncooperation once and for all, we offer a framework to diagnose meaning itself\nas a source of misalignment.", "AI": {"tldr": "The paper identifies semantic ambiguity in multi-agent systems (MAS) as a key source of misalignment, introduces the Misalignment Mosaic framework to diagnose such issues, and generalizes the approach to other overloaded concepts.", "motivation": "To address upstream misalignment in MAS caused by semantic ambiguity and normative projection, particularly the conflation of cooperation and coordination.", "method": "Uses the Rabbit-Duck illusion to illustrate perspective-dependent behavior and introduces the Misalignment Mosaic, a diagnostic framework with four components.", "result": "The framework helps diagnose meaning-level misalignment in MAS, extending beyond policy or reward structures to language and design assumptions.", "conclusion": "The Misalignment Mosaic provides a tool to address semantic ambiguity in MAS, applicable to other overloaded concepts like alignment and trust."}}
{"id": "2506.23484", "pdf": "https://arxiv.org/pdf/2506.23484", "abs": "https://arxiv.org/abs/2506.23484", "authors": ["Yuzhuo Chen", "Zehua Ma", "Han Fang", "Weiming Zhang", "Nenghai Yu"], "title": "TAG-WM: Tamper-Aware Generative Image Watermarking via Diffusion Inversion Sensitivity", "categories": ["cs.MM", "cs.CV", "eess.IV", "I.3.3; I.4.9"], "comment": "Accepted by ICCV 2025 (2025 IEEE/CVF International Conference on\n  Computer Vision)", "summary": "AI-generated content (AIGC) enables efficient visual creation but raises\ncopyright and authenticity risks. As a common technique for integrity\nverification and source tracing, digital image watermarking is regarded as a\npotential solution to above issues. Among these, watermarking methods capable\nof preserving the generation quality are receiving increased attention.\nHowever, the proliferation and high performance of generative image editing\napplications have elevated the risks of malicious tampering, creating new\ndemands. 1) The tamper robustness of current lossless visual quality watermarks\nremains constrained by the modification-sensitive diffusion inversion process,\nnecessitating enhanced robustness. 2) The improved tampering quality and rapid\niteration cycles render passive tampering detection methods inadequate, making\nproactive tampering localization capability a desired feature for watermarks.\nTo address these requirements, this paper proposes a Tamper-Aware Generative\nimage WaterMarking method named TAG-WM. The proposed method comprises four key\nmodules: a dual-mark joint sampling (DMJS) algorithm for embedding copyright\nand localization watermarks into the latent space while preserving generative\nquality, the watermark latent reconstruction (WLR) utilizing reversed DMJS, a\ndense variation region detector (DVRD) leveraging diffusion inversion\nsensitivity to identify tampered areas via statistical deviation analysis, and\nthe tamper-aware decoding (TAD) guided by localization results. The\nexperimental results indicate that TAG-WM achieves SOTA tampering robustness\nand tampering localization capability with distortions while maintaining\nlossless generation quality and a considerable capacity of 256 bits.", "AI": {"tldr": "TAG-WM is a tamper-aware generative watermarking method that enhances robustness and localization while preserving image quality.", "motivation": "Address copyright and authenticity risks in AI-generated content by improving watermarking robustness and tampering localization.", "method": "Proposes TAG-WM with four modules: DMJS for watermark embedding, WLR for reconstruction, DVRD for tamper detection, and TAD for decoding.", "result": "Achieves state-of-the-art tampering robustness and localization with lossless quality and 256-bit capacity.", "conclusion": "TAG-WM effectively addresses current watermarking limitations for AI-generated content."}}
{"id": "2506.22628", "pdf": "https://arxiv.org/pdf/2506.22628", "abs": "https://arxiv.org/abs/2506.22628", "authors": ["Amir Salimi", "Abram Hindle", "Osmar R. Zaiane"], "title": "Evaluating Sound Similarity Metrics for Differentiable, Iterative Sound-Matching", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Manual sound design with a synthesizer is inherently iterative: an artist\ncompares the synthesized output to a mental target, adjusts parameters, and\nrepeats until satisfied. Iterative sound-matching automates this workflow by\ncontinually programming a synthesizer under the guidance of a loss function (or\nsimilarity measure) toward a target sound. Prior comparisons of loss functions\nhave typically favored one metric over another, but only within narrow\nsettings: limited synthesis methods, few loss types, often without blind\nlistening tests. This leaves open the question of whether a universally optimal\nloss exists, or the choice of loss remains a creative decision conditioned on\nthe synthesis method and the sound designer's preference. We propose\ndifferentiable iterative sound-matching as the natural extension of the\navailable literature, since it combines the manual approach to sound design\nwith modern advances in machine learning. To analyze the variability of loss\nfunction performance across synthesizers, we implemented a mix of four novel\nand established differentiable loss functions, and paired them with\ndifferentiable subtractive, additive, and AM synthesizers. For each of the\nsixteen synthesizer--loss combinations, we ran 300 randomized sound-matching\ntrials. Performance was measured using parameter differences,\nspectrogram-distance metrics, and manually assigned listening scores. We\nobserved a moderate level of consistency among the three performance measures.\nOur post-hoc analysis shows that the loss function performance is highly\ndependent on the synthesizer. These findings underscore the value of expanding\nthe scope of sound-matching experiments and developing new similarity metrics\ntailored to specific synthesis techniques rather than pursuing\none-size-fits-all solutions.", "AI": {"tldr": "The paper explores iterative sound-matching for synthesizers, comparing loss functions across different synthesizers and highlighting their dependency on the synthesis method.", "motivation": "To determine if a universally optimal loss function exists for sound-matching or if the choice remains context-dependent, given prior narrow comparisons.", "method": "Implemented four differentiable loss functions with subtractive, additive, and AM synthesizers, conducting 300 trials per combination and evaluating performance via parameter differences, spectrogram metrics, and listening tests.", "result": "Loss function performance varied significantly by synthesizer, with moderate consistency across evaluation metrics.", "conclusion": "Sound-matching should focus on context-specific similarity metrics rather than universal solutions, expanding experimental scope for better results."}}
{"id": "2506.22532", "pdf": "https://arxiv.org/pdf/2506.22532", "abs": "https://arxiv.org/abs/2506.22532", "authors": ["Mark Wrobel", "Michele Pascale", "Tina Yao", "Ruaraidh Campbell", "Elena Milano", "Michael Quail", "Jennifer Steeden", "Vivek Muthurangu"], "title": "High Resolution Isotropic 3D Cine imaging with Automated Segmentation using Concatenated 2D Real-time Imaging and Deep Learning", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "Background: Conventional cardiovascular magnetic resonance (CMR) in\npaediatric and congenital heart disease uses 2D, breath-hold, balanced steady\nstate free precession (bSSFP) cine imaging for assessment of function and\ncardiac-gated, respiratory-navigated, static 3D bSSFP whole-heart imaging for\nanatomical assessment. Our aim is to concatenate a stack 2D free-breathing\nreal-time cines and use Deep Learning (DL) to create an isotropic a fully\nsegmented 3D cine dataset from these images. Methods: Four DL models were\ntrained on open-source data that performed: a) Interslice contrast correction;\nb) Interslice respiratory motion correction; c) Super-resolution (slice\ndirection); and d) Segmentation of right and left atria and ventricles (RA, LA,\nRV, and LV), thoracic aorta (Ao) and pulmonary arteries (PA). In 10 patients\nundergoing routine cardiovascular examination, our method was validated on\nprospectively acquired sagittal stacks of real-time cine images. Quantitative\nmetrics (ventricular volumes and vessel diameters) and image quality of the 3D\ncines were compared to conventional breath hold cine and whole heart imaging.\nResults: All real-time data were successfully transformed into 3D cines with a\ntotal post-processing time of <1 min in all cases. There were no significant\nbiases in any LV or RV metrics with reasonable limits of agreement and\ncorrelation. There is also reasonable agreement for all vessel diameters,\nalthough there was a small but significant overestimation of RPA diameter.\nConclusion: We have demonstrated the potential of creating a 3D-cine data from\nconcatenated 2D real-time cine images using a series of DL models. Our method\nhas short acquisition and reconstruction times with fully segmented data being\navailable within 2 minutes. The good agreement with conventional imaging\nsuggests that our method could help to significantly speed up CMR in clinical\npractice.", "AI": {"tldr": "DL models transform 2D real-time cine images into 3D cine datasets for pediatric CMR, showing good agreement with conventional methods.", "motivation": "To streamline CMR in pediatric and congenital heart disease by reducing acquisition and processing time while maintaining accuracy.", "method": "Four DL models were trained for contrast correction, motion correction, super-resolution, and segmentation, validated on 10 patients.", "result": "Successful 3D cine creation in <1 min, with good agreement for ventricular volumes and vessel diameters, except slight RPA overestimation.", "conclusion": "DL-based 3D cine creation from 2D images is feasible, fast, and accurate, potentially speeding up clinical CMR."}}
{"id": "2506.22604", "pdf": "https://arxiv.org/pdf/2506.22604", "abs": "https://arxiv.org/abs/2506.22604", "authors": ["David Porfirio", "Vincent Hsiao", "Morgan Fine-Morris", "Leslie Smith", "Laura M. Hiatt"], "title": "Bootstrapping Human-Like Planning via LLMs", "categories": ["cs.AI", "cs.HC", "cs.RO"], "comment": "Accepted by the 2025 34th IEEE International Conference on Robot and\n  Human Interactive Communication (RO-MAN)", "summary": "Robot end users increasingly require accessible means of specifying tasks for\nrobots to perform. Two common end-user programming paradigms include\ndrag-and-drop interfaces and natural language programming. Although natural\nlanguage interfaces harness an intuitive form of human communication,\ndrag-and-drop interfaces enable users to meticulously and precisely dictate the\nkey actions of the robot's task. In this paper, we investigate the degree to\nwhich both approaches can be combined. Specifically, we construct a large\nlanguage model (LLM)-based pipeline that accepts natural language as input and\nproduces human-like action sequences as output, specified at a level of\ngranularity that a human would produce. We then compare these generated action\nsequences to another dataset of hand-specified action sequences. Although our\nresults reveal that larger models tend to outperform smaller ones in the\nproduction of human-like action sequences, smaller models nonetheless achieve\nsatisfactory performance.", "AI": {"tldr": "The paper explores combining natural language and drag-and-drop interfaces for robot task specification, using LLMs to generate human-like action sequences and comparing them to hand-specified sequences.", "motivation": "To bridge the gap between intuitive natural language programming and precise drag-and-drop interfaces for robot task specification.", "method": "Developed an LLM-based pipeline to convert natural language into human-like action sequences and compared these to manually specified sequences.", "result": "Larger LLMs outperformed smaller ones in generating human-like sequences, but smaller models still performed satisfactorily.", "conclusion": "Combining natural language and drag-and-drop approaches is feasible, with LLMs effectively bridging the gap, though model size impacts performance."}}
{"id": "2506.22441", "pdf": "https://arxiv.org/pdf/2506.22441", "abs": "https://arxiv.org/abs/2506.22441", "authors": ["Lei Yang"], "title": "Latent Factorization of Tensors with Threshold Distance Weighted Loss for Traffic Data Estimation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Intelligent transportation systems (ITS) rely heavily on complete and\nhigh-quality spatiotemporal traffic data to achieve optimal performance.\nNevertheless, in real-word traffic data collection processes, issues such as\ncommunication failures and sensor malfunctions often lead to incomplete or\ncorrupted datasets, thereby posing significant challenges to the advancement of\nITS. Among various methods for imputing missing spatiotemporal traffic data,\nthe latent factorization of tensors (LFT) model has emerged as a widely adopted\nand effective solution. However, conventional LFT models typically employ the\nstandard L2-norm in their learning objective, which makes them vulnerable to\nthe influence of outliers. To overcome this limitation, this paper proposes a\nthreshold distance weighted (TDW) loss-incorporated Latent Factorization of\nTensors (TDWLFT) model. The proposed loss function effectively reduces the\nmodel's sensitivity to outliers by assigning differentiated weights to\nindividual samples. Extensive experiments conducted on two traffic speed\ndatasets sourced from diverse urban environments confirm that the proposed\nTDWLFT model consistently outperforms state-of-the-art approaches in terms of\nboth in both prediction accuracy and computational efficiency.", "AI": {"tldr": "The paper proposes a TDW loss-incorporated Latent Factorization of Tensors (TDWLFT) model to improve spatiotemporal traffic data imputation by reducing sensitivity to outliers.", "motivation": "Incomplete or corrupted traffic data due to communication failures and sensor malfunctions hinder ITS performance. Existing LFT models are vulnerable to outliers.", "method": "Introduces a threshold distance weighted (TDW) loss function in the LFT model to assign differentiated weights to samples, reducing outlier impact.", "result": "TDWLFT outperforms state-of-the-art methods in prediction accuracy and computational efficiency on two urban traffic speed datasets.", "conclusion": "The TDWLFT model enhances data imputation robustness and efficiency, benefiting ITS applications."}}
{"id": "2506.22437", "pdf": "https://arxiv.org/pdf/2506.22437", "abs": "https://arxiv.org/abs/2506.22437", "authors": ["Xinxin Sun", "Peter Chang"], "title": "Robust Perspective Correction for Real-World Crack Evolution Tracking in Image-Based Structural Health Monitoring", "categories": ["cs.CV", "68T45 (Computer Vision)"], "comment": "43 pages, 5 figures, 19 tables. Submitted to NDT&E International.\n  This work may also be of interest to researchers in optical NDE and civil\n  engineering SHM", "summary": "Accurate image alignment is essential for monitoring crack evolution in\nstructural health monitoring (SHM), particularly under real-world conditions\ninvolving perspective distortion, occlusion, and low contrast. However,\ntraditional feature detectors such as SIFT and SURF, which rely on\nGaussian-based scale spaces, tend to suppress high-frequency edges, making them\nunsuitable for thin crack localization. Lightweight binary alternatives like\nORB and BRISK, while computationally efficient, often suffer from poor keypoint\nrepeatability on textured or shadowed surfaces. This study presents a\nphysics-informed alignment framework that adapts the open KAZE architecture to\nSHM-specific challenges. By utilizing nonlinear anisotropic diffusion to\nconstruct a crack-preserving scale space, and integrating RANSAC-based\nhomography estimation, the framework enables accurate geometric correction\nwithout the need for training, parameter tuning, or prior calibration. The\nmethod is validated on time-lapse images of masonry and concrete acquired via\nhandheld smartphone under varied field conditions, including shadow\ninterference, cropping, oblique viewing angles, and surface clutter. Compared\nto classical detectors, the proposed framework reduces crack area and spine\nlength errors by up to 70 percent and 90 percent, respectively, while\nmaintaining sub-5 percent alignment error in key metrics. Unsupervised,\ninterpretable, and computationally lightweight, this approach supports scalable\ndeployment via UAVs and mobile platforms. By tailoring nonlinear scale-space\nmodeling to SHM image alignment, this work offers a robust and physically\ngrounded alternative to conventional techniques for tracking real-world crack\nevolution.", "AI": {"tldr": "A physics-informed alignment framework improves crack detection in structural health monitoring by adapting KAZE architecture, outperforming traditional methods by up to 90% in accuracy.", "motivation": "Traditional feature detectors like SIFT and SURF are unsuitable for thin crack localization due to high-frequency edge suppression, while lightweight alternatives like ORB and BRISK lack repeatability on textured surfaces.", "method": "The framework uses nonlinear anisotropic diffusion for crack-preserving scale space and RANSAC-based homography estimation, requiring no training or calibration.", "result": "Validated on field images, it reduces crack area and spine length errors by 70% and 90%, respectively, with sub-5% alignment error.", "conclusion": "The method is robust, interpretable, and lightweight, suitable for scalable deployment in real-world SHM applications."}}
{"id": "2506.22508", "pdf": "https://arxiv.org/pdf/2506.22508", "abs": "https://arxiv.org/abs/2506.22508", "authors": ["Chenyang Shao", "Tianxing Li", "Chenhao Pu", "Fengli Xu", "Yong Li"], "title": "AgentStealth: Reinforcing Large Language Model for Anonymizing User-generated Text", "categories": ["cs.CL", "cs.AI"], "comment": "This work has been submitted to NeurIPS 2025. Under review", "summary": "In today's digital world, casual user-generated content often contains subtle\ncues that may inadvertently expose sensitive personal attributes. Such risks\nunderscore the growing importance of effective text anonymization to safeguard\nindividual privacy. However, existing methods either rely on rigid replacements\nthat damage utility or cloud-based LLMs that are costly and pose privacy risks.\nTo address these issues, we explore the use of locally deployed smaller-scale\nlanguage models (SLMs) for anonymization. Yet training effective SLMs remains\nchallenging due to limited high-quality supervision. To address the challenge,\nwe propose AgentStealth, a self-reinforcing LLM anonymization framework.First,\nwe introduce an adversarial anonymization workflow enhanced by In-context\nContrastive Learning and Adaptive Utility-Aware Control. Second, we perform\nsupervised adaptation of SLMs using high-quality data collected from the\nworkflow, which includes both anonymization and attack signals. Finally, we\napply online reinforcement learning where the model leverages its internal\nadversarial feedback to iteratively improve anonymization performance.\nExperiments on two datasets show that our method outperforms baselines in both\nanonymization effectiveness (+12.3%) and utility (+6.8%). Our lightweight\ndesign supports direct deployment on edge devices, avoiding cloud reliance and\ncommunication-based privacy risks. Our code is open-source at\nhttps://github.com/tsinghua-fib-lab/AgentStealth.", "AI": {"tldr": "AgentStealth is a self-reinforcing LLM framework for text anonymization, using adversarial workflows and reinforcement learning to outperform baselines in effectiveness and utility.", "motivation": "Addressing the limitations of existing text anonymization methods\u2014rigid replacements or costly cloud-based LLMs\u2014by exploring locally deployed smaller-scale language models (SLMs).", "method": "Proposes AgentStealth: an adversarial anonymization workflow with In-context Contrastive Learning, supervised adaptation of SLMs, and online reinforcement learning.", "result": "Outperforms baselines by +12.3% in anonymization effectiveness and +6.8% in utility, with lightweight deployment on edge devices.", "conclusion": "AgentStealth offers a privacy-preserving, efficient solution for text anonymization, avoiding cloud reliance and open-sourced for broader use."}}
{"id": "2506.22972", "pdf": "https://arxiv.org/pdf/2506.22972", "abs": "https://arxiv.org/abs/2506.22972", "authors": ["Yu-Wen Chen", "Julia Hirschberg"], "title": "Adaptable Non-parametric Approach for Speech-based Symptom Assessment: Isolating Private Medical Data in a Retrieval Datastore", "categories": ["eess.AS"], "comment": "IEEE MLSP 2025", "summary": "The automatic assessment of health-related acoustic cues has the potential to\nimprove healthcare accessibility and affordability. Although parametric models\nare promising, they face challenges in privacy and adaptability. To address\nthese, we propose a NoN-Parametric framework for Speech-based symptom\nAssessment (NoNPSA). By isolating medical data in a retrieval datastore, NoNPSA\navoids encoding private information in model parameters and enables efficient\ndata updates. A self-supervised learning (SSL) model pre-trained on\ngeneral-purpose datasets extracts features, which are used for similarity-based\nretrieval. Metadata-aware refinement filters the retrieved data, and associated\nlabels are used to compute an assessment score. Experimental results show that\nNoNPSA achieves competitive performance compared to fine-tuning SSL-based\nmethods, while enabling greater privacy, update efficiency, and\nadaptability--showcasing the potential of non-parametric approaches in\nhealthcare.", "AI": {"tldr": "NoNPSA is a non-parametric framework for speech-based symptom assessment, prioritizing privacy and adaptability by isolating medical data in a retrieval datastore and using self-supervised learning for feature extraction.", "motivation": "To address privacy and adaptability challenges in parametric models for health-related acoustic cue assessment.", "method": "Uses a retrieval datastore for medical data, self-supervised learning for feature extraction, metadata-aware refinement, and similarity-based retrieval for assessment.", "result": "Competitive performance compared to fine-tuning SSL-based methods, with added benefits of privacy, update efficiency, and adaptability.", "conclusion": "NoNPSA demonstrates the potential of non-parametric approaches in healthcare for privacy-preserving and adaptable symptom assessment."}}
{"id": "2506.22440", "pdf": "https://arxiv.org/pdf/2506.22440", "abs": "https://arxiv.org/abs/2506.22440", "authors": ["Sharique Hasan", "Alexander Oettl", "Sampsa Samila"], "title": "From Model Design to Organizational Design: Complexity Redistribution and Trade-Offs in Generative AI", "categories": ["cs.CY", "cs.LG", "cs.MA", "econ.GN", "q-fin.EC"], "comment": null, "summary": "This paper introduces the Generality-Accuracy-Simplicity (GAS) framework to\nanalyze how large language models (LLMs) are reshaping organizations and\ncompetitive strategy. We argue that viewing AI as a simple reduction in input\ncosts overlooks two critical dynamics: (a) the inherent trade-offs among\ngenerality, accuracy, and simplicity, and (b) the redistribution of complexity\nacross stakeholders. While LLMs appear to defy the traditional trade-off by\noffering high generality and accuracy through simple interfaces, this\nuser-facing simplicity masks a significant shift of complexity to\ninfrastructure, compliance, and specialized personnel. The GAS trade-off,\ntherefore, does not disappear but is relocated from the user to the\norganization, creating new managerial challenges, particularly around accuracy\nin high-stakes applications. We contend that competitive advantage no longer\nstems from mere AI adoption, but from mastering this redistributed complexity\nthrough the design of abstraction layers, workflow alignment, and complementary\nexpertise. This study advances AI strategy by clarifying how scalable cognition\nrelocates complexity and redefines the conditions for technology integration.", "AI": {"tldr": "The paper introduces the GAS framework to analyze how LLMs reshape organizations and strategy, highlighting trade-offs in generality, accuracy, and simplicity, and the redistribution of complexity to infrastructure and personnel.", "motivation": "To address the misconception that AI merely reduces input costs and to explore the trade-offs and redistributed complexity in LLM adoption.", "method": "Proposes the GAS framework to analyze the dynamics of LLMs, focusing on trade-offs and complexity redistribution.", "result": "Finds that LLMs shift complexity to infrastructure and personnel, creating new managerial challenges, especially in high-stakes accuracy.", "conclusion": "Competitive advantage now depends on mastering redistributed complexity through abstraction layers, workflow alignment, and expertise, redefining AI strategy."}}
{"id": "2506.23707", "pdf": "https://arxiv.org/pdf/2506.23707", "abs": "https://arxiv.org/abs/2506.23707", "authors": ["Jiewei Lai", "Lan Zhang", "Chen Tang", "Pengcheng Sun"], "title": "Efficient and Accurate Image Provenance Analysis: A Scalable Pipeline for Large-scale Images", "categories": ["cs.MM"], "comment": "25 pages, 6 figures", "summary": "The rapid proliferation of modified images on social networks that are driven\nby widely accessible editing tools demands robust forensic tools for digital\ngovernance. Image provenance analysis, which filters various query image\nvariants and constructs a directed graph to trace their phylogeny history, has\nemerged as a critical solution. However, existing methods face two fundamental\nlimitations: First, accuracy issues arise from overlooking heavily modified\nimages due to low similarity while failing to exclude unrelated images and\ndetermine modification directions under diverse modification scenarios. Second,\nscalability bottlenecks stem from pairwise image analysis incurs quadratic\ncomplexity, hindering application in large-scale scenarios. This paper presents\na scalable end-to-end pipeline for image provenance analysis that achieves high\nprecision with linear complexity. This improves filtering effectiveness through\nmodification relationship tracing, which enables the comprehensive discovery of\nimage variants regardless of their visual similarity to the query. In addition,\nthe proposed pipeline integrates local features matching and compression\nartifact capturing, enhancing robustness against diverse modifications and\nenabling accurate analysis of images' relationships. This allows the generation\nof a directed provenance graph that accurately characterizes the image's\nphylogeny history. Furthermore, by optimizing similarity calculations and\neliminating redundant pairwise analysis during graph construction, the pipeline\nachieves a linear time complexity, ensuring its scalability for large-scale\nscenarios. Experiments demonstrate pipeline's superior performance, achieving a\n16.7-56.1% accuracy improvement. Notably, it exhibits significant scalability\nwith an average 3.0-second response time on 10 million scale images, which is\nfar shorter than the SOTA approach's 12-minute duration.", "AI": {"tldr": "A scalable end-to-end pipeline for image provenance analysis improves accuracy and reduces complexity, outperforming existing methods in large-scale scenarios.", "motivation": "The need for robust forensic tools to trace modified images on social networks, addressing accuracy and scalability limitations of current methods.", "method": "Proposes a pipeline integrating modification relationship tracing, local features matching, and compression artifact capturing to construct a directed provenance graph with linear complexity.", "result": "Achieves 16.7-56.1% higher accuracy and significantly faster response times (3.0 seconds vs. 12 minutes for 10M images).", "conclusion": "The pipeline effectively addresses scalability and accuracy challenges in image provenance analysis, making it suitable for large-scale applications."}}
{"id": "2506.22661", "pdf": "https://arxiv.org/pdf/2506.22661", "abs": "https://arxiv.org/abs/2506.22661", "authors": ["R. Oguz Araz", "Guillem Cort\u00e8s-Sebasti\u00e0", "Emilio Molina", "Joan Serr\u00e0", "Xavier Serra", "Yuki Mitsufuji", "Dmitry Bogdanov"], "title": "Enhancing Neural Audio Fingerprint Robustness to Audio Degradation for Music Identification", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted to ISMIR2025", "summary": "Audio fingerprinting (AFP) allows the identification of unknown audio content\nby extracting compact representations, termed audio fingerprints, that are\ndesigned to remain robust against common audio degradations. Neural AFP methods\noften employ metric learning, where representation quality is influenced by the\nnature of the supervision and the utilized loss function. However, recent work\nunrealistically simulates real-life audio degradation during training,\nresulting in sub-optimal supervision. Additionally, although several modern\nmetric learning approaches have been proposed, current neural AFP methods\ncontinue to rely on the NT-Xent loss without exploring the recent advances or\nclassical alternatives. In this work, we propose a series of best practices to\nenhance the self-supervision by leveraging musical signal properties and\nrealistic room acoustics. We then present the first systematic evaluation of\nvarious metric learning approaches in the context of AFP, demonstrating that a\nself-supervised adaptation of the triplet loss yields superior performance. Our\nresults also reveal that training with multiple positive samples per anchor has\ncritically different effects across loss functions. Our approach is built upon\nthese insights and achieves state-of-the-art performance on both a large,\nsynthetically degraded dataset and a real-world dataset recorded using\nmicrophones in diverse music venues.", "AI": {"tldr": "The paper proposes best practices for self-supervised audio fingerprinting (AFP), evaluates metric learning approaches, and introduces a self-supervised triplet loss adaptation for superior performance.", "motivation": "Current neural AFP methods use unrealistic audio degradation simulations and rely on outdated loss functions, limiting performance.", "method": "Leverages musical signal properties and realistic room acoustics for self-supervision, and systematically evaluates metric learning approaches.", "result": "Self-supervised triplet loss adaptation outperforms others, and training with multiple positives affects loss functions differently. Achieves state-of-the-art performance.", "conclusion": "The proposed approach enhances AFP by addressing supervision and loss function limitations, validated on synthetic and real-world datasets."}}
{"id": "2506.22580", "pdf": "https://arxiv.org/pdf/2506.22580", "abs": "https://arxiv.org/abs/2506.22580", "authors": ["Vasilis Siomos", "Jonathan Passerat-Palmbach", "Giacomo Tarroni"], "title": "FedCLAM: Client Adaptive Momentum with Foreground Intensity Matching for Federated Medical Image Segmentation", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "10 pages, 2 figures, Accepted at MICCAI 2025", "summary": "Federated learning is a decentralized training approach that keeps data under\nstakeholder control while achieving superior performance over isolated\ntraining. While inter-institutional feature discrepancies pose a challenge in\nall federated settings, medical imaging is particularly affected due to diverse\nimaging devices and population variances, which can diminish the global model's\neffectiveness. Existing aggregation methods generally fail to adapt across\nvaried circumstances. To address this, we propose FedCLAM, which integrates\n\\textit{client-adaptive momentum} terms derived from each client's loss\nreduction during local training, as well as a \\textit{personalized dampening\nfactor} to curb overfitting. We further introduce a novel \\textit{intensity\nalignment} loss that matches predicted and ground-truth foreground\ndistributions to handle heterogeneous image intensity profiles across\ninstitutions and devices. Extensive evaluations on two datasets show that\nFedCLAM surpasses eight cutting-edge methods in medical segmentation tasks,\nunderscoring its efficacy. The code is available at\nhttps://github.com/siomvas/FedCLAM.", "AI": {"tldr": "FedCLAM improves federated learning in medical imaging by adapting to client-specific conditions and aligning image intensities, outperforming existing methods.", "motivation": "Medical imaging faces challenges like device and population diversity, reducing global model effectiveness in federated learning.", "method": "FedCLAM uses client-adaptive momentum, personalized dampening, and intensity alignment loss to address heterogeneity.", "result": "FedCLAM outperforms eight state-of-the-art methods in medical segmentation tasks.", "conclusion": "FedCLAM effectively handles medical imaging heterogeneity, enhancing federated learning performance."}}
{"id": "2506.22609", "pdf": "https://arxiv.org/pdf/2506.22609", "abs": "https://arxiv.org/abs/2506.22609", "authors": ["Graham Todd", "Alexander G. Padula", "Dennis J. N. J. Soemers", "Julian Togelius"], "title": "Ludax: A GPU-Accelerated Domain Specific Language for Board Games", "categories": ["cs.AI"], "comment": "18 pages, 3 figures", "summary": "Games have long been used as benchmarks and testing environments for research\nin artificial intelligence. A key step in supporting this research was the\ndevelopment of game description languages: frameworks that compile\ndomain-specific code into playable and simulatable game environments, allowing\nresearchers to generalize their algorithms and approaches across multiple games\nwithout having to manually implement each one. More recently, progress in\nreinforcement learning (RL) has been largely driven by advances in hardware\nacceleration. Libraries like JAX allow practitioners to take full advantage of\ncutting-edge computing hardware, often speeding up training and testing by\norders of magnitude. Here, we present a synthesis of these strands of research:\na domain-specific language for board games which automatically compiles into\nhardware-accelerated code. Our framework, Ludax, combines the generality of\ngame description languages with the speed of modern parallel processing\nhardware and is designed to fit neatly into existing deep learning pipelines.\nWe envision Ludax as a tool to help accelerate games research generally, from\nRL to cognitive science, by enabling rapid simulation and providing a flexible\nrepresentation scheme. We present a detailed breakdown of Ludax's description\nlanguage and technical notes on the compilation process, along with speed\nbenchmarking and a demonstration of training RL agents. The Ludax framework,\nalong with implementations of existing board games, is open-source and freely\navailable.", "AI": {"tldr": "Ludax is a domain-specific language for board games that compiles into hardware-accelerated code, combining game description generality with modern parallel processing speed to accelerate research in RL and cognitive science.", "motivation": "To bridge the gap between game description languages and hardware acceleration, enabling faster and more generalized research in AI, particularly reinforcement learning.", "method": "Developed Ludax, a domain-specific language for board games that automatically compiles into hardware-accelerated code, integrating with deep learning pipelines.", "result": "Ludax provides rapid simulation, flexibility, and speed benchmarks, demonstrated through RL agent training.", "conclusion": "Ludax is an open-source tool designed to accelerate games research by leveraging hardware acceleration and generality."}}
{"id": "2506.22442", "pdf": "https://arxiv.org/pdf/2506.22442", "abs": "https://arxiv.org/abs/2506.22442", "authors": ["Piotr Makarevich"], "title": "Features-based embedding or Feature-grounding", "categories": ["cs.LG"], "comment": "13 pages, 12 figures", "summary": "In everyday reasoning, when we think about a particular object, we associate\nit with a unique set of expected properties such as weight, size, or more\nabstract attributes like density or horsepower. These expectations are shaped\nby our prior knowledge and the conceptual categories we have formed through\nexperience. This paper investigates how such knowledge-based structured\nthinking can be reproduced in deep learning models using features based\nembeddings. Specially, it introduces an specific approach to build\nfeature-grounded embedding, aiming to align shareable representations of\noperable dictionary with interpretable domain-specific conceptual features.", "AI": {"tldr": "The paper explores reproducing knowledge-based structured thinking in deep learning models using feature-grounded embeddings.", "motivation": "To align deep learning models with human-like reasoning by grounding embeddings in interpretable, domain-specific conceptual features.", "method": "Introduces a feature-grounded embedding approach to create shareable representations tied to operable dictionaries and conceptual features.", "result": "Not explicitly stated in the abstract, but the method aims to improve model interpretability and alignment with human reasoning.", "conclusion": "The proposed approach could enhance deep learning models by incorporating structured, knowledge-based representations."}}
{"id": "2506.22438", "pdf": "https://arxiv.org/pdf/2506.22438", "abs": "https://arxiv.org/abs/2506.22438", "authors": ["Xumin Gao", "Mark Stevens", "Grzegorz Cielniak"], "title": "Counting with Confidence: Accurate Pest Monitoring in Water Traps", "categories": ["cs.CV"], "comment": "\\c{opyright} 20XX the authors. This work has been accepted to IFAC\n  for publication under a Creative Commons Licence CC-BY-NC-ND", "summary": "Accurate pest population monitoring and tracking their dynamic changes are\ncrucial for precision agriculture decision-making. A common limitation in\nexisting vision-based automatic pest counting research is that models are\ntypically evaluated on datasets with ground truth but deployed in real-world\nscenarios without assessing the reliability of counting results due to the lack\nof ground truth. To this end, this paper proposed a method for comprehensively\nevaluating pest counting confidence in the image, based on information related\nto counting results and external environmental conditions. First, a pest\ndetection network is used for pest detection and counting, extracting counting\nresult-related information. Then, the pest images undergo image quality\nassessment, image complexity assessment, and pest distribution uniformity\nassessment. And the changes in image clarity caused by stirring during image\nacquisition are quantified by calculating the average gradient magnitude.\nNotably, we designed a hypothesis-driven multi-factor sensitivity analysis\nmethod to select the optimal image quality assessment and image complexity\nassessment methods. And we proposed an adaptive DBSCAN clustering algorithm for\npest distribution uniformity assessment. Finally, the obtained information\nrelated to counting results and external environmental conditions is input into\na regression model for prediction, resulting in the final pest counting\nconfidence. To the best of our knowledge, this is the first study dedicated to\ncomprehensively evaluating counting confidence in counting tasks, and\nquantifying the relationship between influencing factors and counting\nconfidence through a model. Experimental results show our method reduces MSE by\n31.7% and improves R2 by 15.2% on the pest counting confidence test set,\ncompared to the baseline built primarily on information related to counting\nresults.", "AI": {"tldr": "The paper proposes a method to evaluate pest counting confidence in images by combining counting results and environmental factors, improving accuracy over baseline methods.", "motivation": "Existing pest counting models lack reliability assessment in real-world deployments due to missing ground truth. This study aims to address this gap.", "method": "Uses a pest detection network, image quality/complexity assessments, and pest distribution uniformity analysis. Introduces adaptive DBSCAN and a regression model for confidence prediction.", "result": "Reduces MSE by 31.7% and improves R2 by 15.2% compared to baseline methods.", "conclusion": "First study to comprehensively evaluate counting confidence, demonstrating significant improvements in accuracy and reliability."}}
{"id": "2506.22510", "pdf": "https://arxiv.org/pdf/2506.22510", "abs": "https://arxiv.org/abs/2506.22510", "authors": ["Zihao Zhao", "Xinlong Zhai", "Jinyu Yang", "Chuan Shi"], "title": "Towards Text-free Graph Foundation Models: Rethinking Multi-Domain Graph Contrastive Learning", "categories": ["cs.CL", "cs.AI"], "comment": "16 pages, 5 figures", "summary": "Foundation models have achieved great success in natural language processing\n(NLP) and computer vision (CV). Their success largely stems from the ability to\nintegrate multi-domain knowledge in pre-training and transfer it to target\ndomains. Considering graph data, especially graphs without textual features, is\nubiquitous in real-world applications such as social networks and\nrecommendation systems, some researchers have attempted to extend this paradigm\nto the graph field, aiming to construct graph foundation models. However,\nunlike CV and NLP, there are huge gaps among the semantics and properties of\ngraphs in different domains, while current works still adopt traditional\ncontrastive pre-training strategies designed in the single-domain scenario,\nwhich regard contrastive samples from different domains as equivalent. From\nexperimental investigations, we discovered that inherent domain-specific\ndifferences prevent these strategies from effectively absorbing knowledge from\ndifferent domains to generate informative representations. In this paper, we\npropose a novel multi-domain pre-training and cross-domain transfer framework,\nnamely MDGCL.In the pre-training stage, we design a contrastive learning\nstrategy to substantially recognize and capture domain differences, and\nintroduce domain tokens to encode domain-level global information. In the\ndownstream stage, we introduce a domain attention mechanism to enable\nfine-grained domain knowledge transfer. Extensive experiments on five benchmark\ndatasets have demonstrated that our method outperforms state-of-the-art\nsignificantly, with the maximum improvement of 19.33\\% on accuracy and 19.13\\%\non Macro-F1 score.", "AI": {"tldr": "The paper proposes MDGCL, a multi-domain pre-training and cross-domain transfer framework for graph data, addressing domain-specific differences to improve representation learning.", "motivation": "Existing contrastive pre-training strategies fail to account for domain-specific differences in graph data, limiting knowledge transfer across domains.", "method": "MDGCL introduces a domain-aware contrastive learning strategy and domain tokens in pre-training, and a domain attention mechanism for downstream tasks.", "result": "MDGCL achieves significant improvements, with up to 19.33% accuracy and 19.13% Macro-F1 score gains over state-of-the-art methods.", "conclusion": "The framework effectively addresses domain differences in graph data, enabling better multi-domain knowledge transfer and downstream performance."}}
{"id": "2506.23371", "pdf": "https://arxiv.org/pdf/2506.23371", "abs": "https://arxiv.org/abs/2506.23371", "authors": ["Frank Cwitkowitz", "Zhiyao Duan"], "title": "Investigating an Overfitting and Degeneration Phenomenon in Self-Supervised Multi-Pitch Estimation", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "Accepted to ISMIR 2025", "summary": "Multi-Pitch Estimation (MPE) continues to be a sought after capability of\nMusic Information Retrieval (MIR) systems, and is critical for many\napplications and downstream tasks involving pitch, including music\ntranscription. However, existing methods are largely based on supervised\nlearning, and there are significant challenges in collecting annotated data for\nthe task. Recently, self-supervised techniques exploiting intrinsic properties\nof pitch and harmonic signals have shown promise for both monophonic and\npolyphonic pitch estimation, but these still remain inferior to supervised\nmethods. In this work, we extend the classic supervised MPE paradigm by\nincorporating several self-supervised objectives based on pitch-invariant and\npitch-equivariant properties. This joint training results in a substantial\nimprovement under closed training conditions, which naturally suggests that\napplying the same objectives to a broader collection of data will yield further\nimprovements. However, in doing so we uncover a phenomenon whereby our model\nsimultaneously overfits to the supervised data while degenerating on data used\nfor self-supervision only. We demonstrate and investigate this and offer our\ninsights on the underlying problem.", "AI": {"tldr": "The paper explores combining supervised and self-supervised learning for Multi-Pitch Estimation (MPE), showing improved performance but uncovering a dual overfitting-degeneration issue.", "motivation": "Existing MPE methods rely heavily on supervised learning, which faces challenges due to limited annotated data. Self-supervised techniques show promise but lag behind supervised methods.", "method": "Extends supervised MPE by incorporating self-supervised objectives based on pitch-invariant and pitch-equivariant properties, using joint training.", "result": "Substantial improvement under closed training conditions, but reveals a dual overfitting-degeneration issue when applied to broader data.", "conclusion": "The study highlights the potential and challenges of combining supervised and self-supervised learning in MPE, offering insights into the observed phenomenon."}}
{"id": "2506.22445", "pdf": "https://arxiv.org/pdf/2506.22445", "abs": "https://arxiv.org/abs/2506.22445", "authors": ["Saad Alqithami"], "title": "Hierarchical Adversarially-Resilient Multi-Agent Reinforcement Learning for Cyber-Physical Systems Security", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.MA"], "comment": null, "summary": "Cyber-Physical Systems play a critical role in the infrastructure of various\nsectors, including manufacturing, energy distribution, and autonomous\ntransportation systems. However, their increasing connectivity renders them\nhighly vulnerable to sophisticated cyber threats, such as adaptive and zero-day\nattacks, against which traditional security methods like rule-based intrusion\ndetection and single-agent reinforcement learning prove insufficient. To\novercome these challenges, this paper introduces a novel Hierarchical\nAdversarially-Resilient Multi-Agent Reinforcement Learning (HAMARL) framework.\nHAMARL employs a hierarchical structure consisting of local agents dedicated to\nsubsystem security and a global coordinator that oversees and optimizes\ncomprehensive, system-wide defense strategies. Furthermore, the framework\nincorporates an adversarial training loop designed to simulate and anticipate\nevolving cyber threats, enabling proactive defense adaptation. Extensive\nexperimental evaluations conducted on a simulated industrial IoT testbed\nindicate that HAMARL substantially outperforms traditional multi-agent\nreinforcement learning approaches, significantly improving attack detection\naccuracy, reducing response times, and ensuring operational continuity. The\nresults underscore the effectiveness of combining hierarchical multi-agent\ncoordination with adversarially-aware training to enhance the resilience and\nsecurity of next-generation CPS.", "AI": {"tldr": "A novel Hierarchical Adversarially-Resilient Multi-Agent Reinforcement Learning (HAMARL) framework is introduced to enhance CPS security against adaptive cyber threats, outperforming traditional methods.", "motivation": "Increasing connectivity of Cyber-Physical Systems (CPS) makes them vulnerable to sophisticated cyber threats, which traditional security methods fail to address.", "method": "HAMARL uses a hierarchical structure with local agents for subsystem security and a global coordinator for system-wide defense, incorporating adversarial training to anticipate threats.", "result": "Experiments on an industrial IoT testbed show HAMARL improves attack detection accuracy, reduces response times, and ensures operational continuity.", "conclusion": "Combining hierarchical multi-agent coordination with adversarial training enhances CPS resilience and security."}}
{"id": "2506.22790", "pdf": "https://arxiv.org/pdf/2506.22790", "abs": "https://arxiv.org/abs/2506.22790", "authors": ["Yixu Chen", "Bowen Chen", "Hai Wei", "Alan C. Bovik", "Baojun Li", "Wei Sun", "Linhan Cao", "Kang Fu", "Dandan Zhu", "Jun Jia", "Menghan Hu", "Xiongkuo Min", "Guangtao Zhai", "Dounia Hammou", "Fei Yin", "Rafal Mantiuk", "Amritha Premkumar", "Prajit T Rajendran", "Vignesh V Menon"], "title": "ICME 2025 Generalizable HDR and SDR Video Quality Measurement Grand Challenge", "categories": ["eess.IV", "cs.CV", "cs.MM"], "comment": "ICME 2025 Grand Challenges", "summary": "This paper reports IEEE International Conference on Multimedia \\& Expo (ICME)\n2025 Grand Challenge on Generalizable HDR and SDR Video Quality Measurement.\nWith the rapid development of video technology, especially High Dynamic Range\n(HDR) and Standard Dynamic Range (SDR) contents, the need for robust and\ngeneralizable Video Quality Assessment (VQA) methods has become increasingly\ndemanded. Existing VQA models often struggle to deliver consistent performance\nacross varying dynamic ranges, distortion types, and diverse content. This\nchallenge was established to benchmark and promote VQA approaches capable of\njointly handling HDR and SDR content. In the final evaluation phase, five teams\nsubmitted seven models along with technical reports to the Full Reference (FR)\nand No Reference (NR) tracks. Among them, four methods outperformed VMAF\nbaseline, while the top-performing model achieved state-of-the-art performance,\nsetting a new benchmark for generalizable video quality assessment.", "AI": {"tldr": "The paper discusses a 2025 ICME Grand Challenge focused on developing generalizable VQA methods for HDR and SDR videos, highlighting the need for robust models. Five teams submitted models, with four outperforming the VMAF baseline and one achieving state-of-the-art performance.", "motivation": "The rapid advancement of video technology, particularly HDR and SDR, necessitates robust and generalizable VQA methods, as existing models struggle with consistency across dynamic ranges and distortions.", "method": "The challenge benchmarked VQA approaches for jointly handling HDR and SDR content. Five teams submitted seven models for FR and NR tracks.", "result": "Four methods outperformed the VMAF baseline, with the top model achieving state-of-the-art performance, setting a new benchmark.", "conclusion": "The challenge successfully advanced generalizable VQA methods, demonstrating improved performance over existing benchmarks."}}
{"id": "2506.22789", "pdf": "https://arxiv.org/pdf/2506.22789", "abs": "https://arxiv.org/abs/2506.22789", "authors": ["Oguzhan Baser", "Ahmet Ege Tanriverdi", "Kaan Kale", "Sandeep P. Chinchali", "Sriram Vishwanath"], "title": "WavShape: Information-Theoretic Speech Representation Learning for Fair and Privacy-Aware Audio Processing", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "5 pages, 4 figures, Published at The Proceedings of Interspeech 2025,\n  code is available at http://www.github.com/UTAustin-SwarmLab/WavShape", "summary": "Speech embeddings often retain sensitive attributes such as speaker identity,\naccent, or demographic information, posing risks in biased model training and\nprivacy leakage. We propose WavShape, an information-theoretic speech\nrepresentation learning framework that optimizes embeddings for fairness and\nprivacy while preserving task-relevant information. We leverage mutual\ninformation (MI) estimation using the Donsker-Varadhan formulation to guide an\nMI-based encoder that systematically filters sensitive attributes while\nmaintaining speech content essential for downstream tasks. Experimental results\non three known datasets show that WavShape reduces MI between embeddings and\nsensitive attributes by up to 81% while retaining 97% of task-relevant\ninformation. By integrating information theory with self-supervised speech\nmodels, this work advances the development of fair, privacy-aware, and\nresource-efficient speech systems.", "AI": {"tldr": "WavShape is a framework for learning fair and privacy-preserving speech embeddings by filtering sensitive attributes while retaining task-relevant information, achieving significant reduction in mutual information for sensitive data.", "motivation": "Speech embeddings often retain sensitive attributes like speaker identity, posing risks of bias and privacy leakage, necessitating solutions for fair and private speech systems.", "method": "Uses mutual information estimation (Donsker-Varadhan formulation) to guide an encoder that filters sensitive attributes while preserving task-relevant speech content.", "result": "Reduces mutual information for sensitive attributes by up to 81% while retaining 97% of task-relevant information, tested on three datasets.", "conclusion": "WavShape advances fair, privacy-aware speech systems by integrating information theory with self-supervised models."}}
{"id": "2506.22596", "pdf": "https://arxiv.org/pdf/2506.22596", "abs": "https://arxiv.org/abs/2506.22596", "authors": ["Md Rahatul Islam Udoy", "Wantong Li", "Kai Ni", "Ahmedullah Aziz"], "title": "Multi-Domain FeFET-Based Pixel for In-Sensor Multiply-and-Accumulate Operations", "categories": ["eess.IV"], "comment": null, "summary": "This paper presents an FeFET-based active pixel sensor that performs\nin-sensor multiply-and-accumulate (MAC) operations by leveraging the\nmulti-domain polarization states of ferroelectric layers. The proposed design\nintegrates a programmable FeFET into a 3-transistor pixel circuit, where the\nFeFET's non-volatile conductance encodes the weight, and the photodiode voltage\ndrop encodes the input. Their interaction generates an output current\nproportional to the product, enabling in-pixel analog multiplication.\nAccumulation is achieved by summing output currents along shared column lines,\nrealizing full MAC functionality within the image sensor array. Extensive\nHSPICE simulations, using 45 nm CMOS models, validate the operation and confirm\nthe scalability of the design. This compact and power-efficient architecture\nminimizes data movement, making it ideal for real-time edge computing,\nneuromorphic vision, and secure sensing applications.", "AI": {"tldr": "An FeFET-based active pixel sensor performs in-sensor MAC operations using multi-domain polarization states, enabling compact, power-efficient edge computing.", "motivation": "To minimize data movement and enable efficient in-sensor computing for real-time applications like neuromorphic vision and secure sensing.", "method": "Integrates a programmable FeFET into a 3-transistor pixel circuit, using its non-volatile conductance for weights and photodiode voltage for inputs, generating analog multiplication. Accumulation is done via shared column lines.", "result": "HSPICE simulations with 45 nm CMOS models validate the design's operation and scalability.", "conclusion": "The compact, power-efficient architecture is ideal for edge computing, neuromorphic vision, and secure sensing."}}
{"id": "2506.22653", "pdf": "https://arxiv.org/pdf/2506.22653", "abs": "https://arxiv.org/abs/2506.22653", "authors": ["Michael Grosskopf", "Russell Bent", "Rahul Somasundaram", "Isaac Michaud", "Arthur Lui", "Nathan Debardeleben", "Earl Lawrence"], "title": "URSA: The Universal Research and Scientific Agent", "categories": ["cs.AI"], "comment": "31 pages, 9 figures", "summary": "Large language models (LLMs) have moved far beyond their initial form as\nsimple chatbots, now carrying out complex reasoning, planning, writing, coding,\nand research tasks. These skills overlap significantly with those that human\nscientists use day-to-day to solve complex problems that drive the cutting edge\nof research. Using LLMs in \"agentic\" AI has the potential to revolutionize\nmodern science and remove bottlenecks to progress. In this work, we present\nURSA, a scientific agent ecosystem for accelerating research tasks. URSA\nconsists of a set of modular agents and tools, including coupling to advanced\nphysics simulation codes, that can be combined to address scientific problems\nof varied complexity and impact. This work highlights the architecture of URSA,\nas well as examples that highlight the potential of the system.", "AI": {"tldr": "URSA is a scientific agent ecosystem using LLMs to accelerate research tasks, featuring modular agents and tools for varied scientific problems.", "motivation": "Leverage LLMs' advanced reasoning and planning skills to revolutionize scientific research by addressing bottlenecks.", "method": "Develop URSA, a modular ecosystem of agents and tools, including physics simulation codes, to tackle diverse scientific challenges.", "result": "URSA's architecture and examples demonstrate its potential to enhance research efficiency and impact.", "conclusion": "URSA showcases the transformative potential of agentic AI in accelerating scientific progress."}}
{"id": "2506.22443", "pdf": "https://arxiv.org/pdf/2506.22443", "abs": "https://arxiv.org/abs/2506.22443", "authors": ["Sarah Seifi", "Tobias Sukianto", "Cecilia Carbonelli", "Lorenzo Servadei", "Robert Wille"], "title": "Learning Interpretable Rules from Neural Networks: Neurosymbolic AI for Radar Hand Gesture Recognition", "categories": ["cs.LG", "cs.HC"], "comment": "8 pages, 3 figures, accepted at the late-breaking work track at the\n  XAI-2025 third World Conference of Explainable AI", "summary": "Rule-based models offer interpretability but struggle with complex data,\nwhile deep neural networks excel in performance yet lack transparency. This\nwork investigates a neuro-symbolic rule learning neural network named RL-Net\nthat learns interpretable rule lists through neural optimization, applied for\nthe first time to radar-based hand gesture recognition (HGR). We benchmark\nRL-Net against a fully transparent rule-based system (MIRA) and an explainable\nblack-box model (XentricAI), evaluating accuracy, interpretability, and user\nadaptability via transfer learning. Our results show that RL-Net achieves a\nfavorable trade-off, maintaining strong performance (93.03% F1) while\nsignificantly reducing rule complexity. We identify optimization challenges\nspecific to rule pruning and hierarchy bias and propose stability-enhancing\nmodifications. Compared to MIRA and XentricAI, RL-Net emerges as a practical\nmiddle ground between transparency and performance. This study highlights the\nreal-world feasibility of neuro-symbolic models for interpretable HGR and\noffers insights for extending explainable AI to edge-deployable sensing\nsystems.", "AI": {"tldr": "RL-Net, a neuro-symbolic rule learning neural network, balances interpretability and performance in radar-based hand gesture recognition, outperforming transparent and black-box models.", "motivation": "To bridge the gap between interpretable rule-based models and high-performing deep neural networks for hand gesture recognition.", "method": "RL-Net learns interpretable rule lists via neural optimization, benchmarked against MIRA (rule-based) and XentricAI (explainable black-box).", "result": "RL-Net achieves 93.03% F1 score, reduces rule complexity, and addresses optimization challenges like rule pruning and hierarchy bias.", "conclusion": "RL-Net is a practical middle ground for interpretable HGR, with potential for edge-deployable sensing systems."}}
{"id": "2506.22463", "pdf": "https://arxiv.org/pdf/2506.22463", "abs": "https://arxiv.org/abs/2506.22463", "authors": ["Weizhi Gao", "Zhichao Hou", "Junqi Yin", "Feiyi Wang", "Linyu Peng", "Xiaorui Liu"], "title": "Modulated Diffusion: Accelerating Generative Modeling with Modulated Quantization", "categories": ["cs.CV", "cs.LG"], "comment": "26 pages, accepted by ICML 2025", "summary": "Diffusion models have emerged as powerful generative models, but their high\ncomputation cost in iterative sampling remains a significant bottleneck. In\nthis work, we present an in-depth and insightful study of state-of-the-art\nacceleration techniques for diffusion models, including caching and\nquantization, revealing their limitations in computation error and generation\nquality. To break these limits, this work introduces Modulated Diffusion\n(MoDiff), an innovative, rigorous, and principled framework that accelerates\ngenerative modeling through modulated quantization and error compensation.\nMoDiff not only inherents the advantages of existing caching and quantization\nmethods but also serves as a general framework to accelerate all diffusion\nmodels. The advantages of MoDiff are supported by solid theoretical insight and\nanalysis. In addition, extensive experiments on CIFAR-10 and LSUN demonstrate\nthat MoDiff significant reduces activation quantization from 8 bits to 3 bits\nwithout performance degradation in post-training quantization (PTQ). Our code\nimplementation is available at https://github.com/WeizhiGao/MoDiff.", "AI": {"tldr": "The paper introduces MoDiff, a framework to accelerate diffusion models using modulated quantization and error compensation, reducing computation costs without performance loss.", "motivation": "High computation costs in iterative sampling of diffusion models limit their efficiency, and existing acceleration techniques have limitations in error and quality.", "method": "MoDiff employs modulated quantization and error compensation to accelerate diffusion models while maintaining performance.", "result": "MoDiff reduces activation quantization from 8 to 3 bits without performance degradation, validated on CIFAR-10 and LSUN datasets.", "conclusion": "MoDiff is a principled and effective framework for accelerating diffusion models, outperforming existing methods."}}
{"id": "2506.22516", "pdf": "https://arxiv.org/pdf/2506.22516", "abs": "https://arxiv.org/abs/2506.22516", "authors": ["Jingkai Li"], "title": "Can \"consciousness\" be observed from large language model (LLM) internal states? Dissecting LLM representations obtained from Theory of Mind test with Integrated Information Theory and Span Representation analysis", "categories": ["cs.CL", "cs.AI", "cs.NE", "q-bio.NC"], "comment": "Published as a journal paper at:\n  https://doi.org/10.1016/j.nlp.2025.100163", "summary": "Integrated Information Theory (IIT) provides a quantitative framework for\nexplaining consciousness phenomenon, positing that conscious systems comprise\nelements integrated through causal properties. We apply IIT 3.0 and 4.0 -- the\nlatest iterations of this framework -- to sequences of Large Language Model\n(LLM) representations, analyzing data derived from existing Theory of Mind\n(ToM) test results. Our study systematically investigates whether the\ndifferences of ToM test performances, when presented in the LLM\nrepresentations, can be revealed by IIT estimates, i.e., $\\Phi^{\\max}$ (IIT\n3.0), $\\Phi$ (IIT 4.0), Conceptual Information (IIT 3.0), and $\\Phi$-structure\n(IIT 4.0). Furthermore, we compare these metrics with the Span Representations\nindependent of any estimate for consciousness. This additional effort aims to\ndifferentiate between potential \"consciousness\" phenomena and inherent\nseparations within LLM representational space. We conduct comprehensive\nexperiments examining variations across LLM transformer layers and linguistic\nspans from stimuli. Our results suggest that sequences of contemporary\nTransformer-based LLM representations lack statistically significant indicators\nof observed \"consciousness\" phenomena but exhibit intriguing patterns under\n$\\textit{spatio}$-permutational analyses. The Appendix and code are available\nas Supplementary Materials at: https://doi.org/10.1016/j.nlp.2025.100163.", "AI": {"tldr": "The study applies Integrated Information Theory (IIT) 3.0 and 4.0 to analyze Large Language Model (LLM) representations, finding no significant indicators of consciousness but revealing patterns under spatio-permutational analyses.", "motivation": "To investigate whether differences in Theory of Mind (ToM) test performances in LLMs can be explained by IIT metrics and to differentiate between consciousness-like phenomena and inherent separations in LLM representations.", "method": "Applied IIT 3.0 and 4.0 metrics (\u03a6\u1d50\u1d43\u02e3, \u03a6, Conceptual Information, \u03a6-structure) to LLM representations and compared them with Span Representations. Conducted experiments across LLM transformer layers and linguistic spans.", "result": "No statistically significant indicators of consciousness were found in LLM representations, but intriguing patterns emerged under spatio-permutational analyses.", "conclusion": "Contemporary Transformer-based LLMs lack significant consciousness indicators, though their representations show interesting structural patterns."}}
{"id": "2506.23553", "pdf": "https://arxiv.org/pdf/2506.23553", "abs": "https://arxiv.org/abs/2506.23553", "authors": ["Taisei Takano", "Yuki Okamoto", "Yusuke Kanamori", "Yuki Saito", "Ryotaro Nagase", "Hiroshi Saruwatari"], "title": "Human-CLAP: Human-perception-based contrastive language-audio pretraining", "categories": ["eess.AS", "cs.SD"], "comment": null, "summary": "Contrastive language-audio pretraining (CLAP) is widely used for audio\ngeneration and recognition tasks. For example, CLAPScore, which utilizes the\nsimilarity of CLAP embeddings, has been a major metric for the evaluation of\nthe relevance between audio and text in text-to-audio. However, the\nrelationship between CLAPScore and human subjective evaluation scores is still\nunclarified. We show that CLAPScore has a low correlation with human subjective\nevaluation scores. Additionally, we propose a human-perception-based CLAP\ncalled Human-CLAP by training a contrastive language-audio model using the\nsubjective evaluation score. In our experiments, the results indicate that our\nHuman-CLAP improved the Spearman's rank correlation coefficient (SRCC) between\nthe CLAPScore and the subjective evaluation scores by more than 0.25 compared\nwith the conventional CLAP.", "AI": {"tldr": "The paper reveals that CLAPScore, a metric for audio-text relevance, poorly correlates with human subjective scores. It introduces Human-CLAP, improving correlation by over 0.25.", "motivation": "To address the unclear relationship between CLAPScore and human subjective evaluations in audio-text tasks.", "method": "Proposes Human-CLAP by training a contrastive language-audio model using subjective scores.", "result": "Human-CLAP improves SRCC by more than 0.25 compared to conventional CLAP.", "conclusion": "Human-CLAP better aligns with human perception, enhancing evaluation metrics for audio-text tasks."}}
{"id": "2506.22507", "pdf": "https://arxiv.org/pdf/2506.22507", "abs": "https://arxiv.org/abs/2506.22507", "authors": ["Yubo Peng", "Luping Xiang", "Kun Yang", "Feibo Jiang", "Kezhi Wang", "Christos Masouros"], "title": "Integrated Multimodal Sensing and Communication: Challenges, Technologies, and Architectures", "categories": ["cs.NI", "cs.MA", "eess.SP"], "comment": null, "summary": "The evolution towards 6G networks requires the intelligent integration of\ncommunication and sensing capabilities to support diverse and complex\napplications, such as autonomous driving and immersive services. However,\nexisting integrated sensing and communication (ISAC) systems predominantly rely\non single-modal sensors as primary participants, which leads to a limited\nrepresentation of environmental features and significant performance\nbottlenecks under the emerging requirements of 6G applications. This limitation\nmotivates a paradigm shift from single-modal to multimodal ISAC. In this\narticle, we first analyze the key challenges in realizing multimodal ISAC,\nincluding the fusion of heterogeneous multimodal data, the high communication\noverhead among distributed sensors, and the design of efficient and scalable\nsystem architectures. We then introduce several enabling technologies, such as\nlarge AI models, semantic communication, and multi-agent systems, that hold\npromise for addressing these challenges. To operationalize these technologies,\nwe zoom into three architectural paradigms: fusion-based multimodal ISAC\n(F-MAC), interaction-based multimodal ISAC (I-MAC), and relay-based multimodal\nISAC (R-MAC), each tailored to organize devices and modalities for efficient\ncollaboration in different scenarios. Thereafter, a case study is presented\nbased on the F-MAC scheme, demonstrating that the scheme achieves more\ncomprehensive sensing and improves sensing accuracy by approximately 80%\ncompared to conventional single-modal ISAC systems. Finally, we discuss several\nopen issues to be addressed in the future.", "AI": {"tldr": "The paper proposes a shift from single-modal to multimodal ISAC for 6G networks, addressing challenges like data fusion and communication overhead. It introduces enabling technologies (e.g., AI models, semantic communication) and three architectural paradigms (F-MAC, I-MAC, R-MAC), with F-MAC improving sensing accuracy by 80%.", "motivation": "Current single-modal ISAC systems limit environmental feature representation and performance for 6G applications, necessitating a shift to multimodal ISAC.", "method": "The paper analyzes challenges in multimodal ISAC, introduces enabling technologies, and proposes three architectural paradigms (F-MAC, I-MAC, R-MAC) for efficient collaboration. A case study validates F-MAC's effectiveness.", "result": "The F-MAC scheme improves sensing accuracy by ~80% compared to single-modal ISAC systems.", "conclusion": "Multimodal ISAC is crucial for 6G, with F-MAC showing significant promise. Future work must address open issues like scalability and heterogeneous data fusion."}}
{"id": "2506.22871", "pdf": "https://arxiv.org/pdf/2506.22871", "abs": "https://arxiv.org/abs/2506.22871", "authors": ["Homayun Afrabandpey", "Hamed Rezazadegan Tavakoli"], "title": "P$^2$U: Progressive Precision Update For Efficient Model Distribution", "categories": ["cs.LG", "cs.MM", "I.2.6"], "comment": null, "summary": "Efficient model distribution is becoming increasingly critical in\nbandwidth-constrained environments. In this paper, we propose a simple yet\neffective approach called Progressive Precision Update (P$^2$U) to address this\nproblem. Instead of transmitting the original high-precision model, P$^2$U\ntransmits a lower-bit precision model, coupled with a model update representing\nthe difference between the original high-precision model and the transmitted\nlow precision version. With extensive experiments on various model\narchitectures, ranging from small models ($1 - 6$ million parameters) to a\nlarge model (more than $100$ million parameters) and using three different data\nsets, e.g., chest X-Ray, PASCAL-VOC, and CIFAR-100, we demonstrate that P$^2$U\nconsistently achieves better tradeoff between accuracy, bandwidth usage and\nlatency. Moreover, we show that when bandwidth or startup time is the priority,\naggressive quantization (e.g., 4-bit) can be used without severely compromising\nperformance. These results establish P$^2$U as an effective and practical\nsolution for scalable and efficient model distribution in low-resource\nsettings, including federated learning, edge computing, and IoT deployments.\nGiven that P$^2$U complements existing compression techniques and can be\nimplemented alongside any compression method, e.g., sparsification,\nquantization, pruning, etc., the potential for improvement is even greater.", "AI": {"tldr": "Progressive Precision Update (P\u00b2U) improves model distribution efficiency by transmitting low-bit precision models with updates, balancing accuracy, bandwidth, and latency.", "motivation": "Addressing the challenge of efficient model distribution in bandwidth-constrained environments like federated learning and edge computing.", "method": "P\u00b2U transmits low-bit precision models alongside updates representing the difference to the high-precision version, tested across various architectures and datasets.", "result": "P\u00b2U achieves better tradeoffs in accuracy, bandwidth, and latency, even with aggressive quantization (e.g., 4-bit).", "conclusion": "P\u00b2U is a practical solution for scalable model distribution in low-resource settings, compatible with existing compression techniques."}}
{"id": "2506.22810", "pdf": "https://arxiv.org/pdf/2506.22810", "abs": "https://arxiv.org/abs/2506.22810", "authors": ["Shiyao Wang", "Jiaming Zhou", "Shiwan Zhao", "Yong Qin"], "title": "A Self-Training Approach for Whisper to Enhance Long Dysarthric Speech Recognition", "categories": ["cs.SD", "eess.AS"], "comment": "accepted by Interspeech 2025", "summary": "Dysarthric speech recognition (DSR) enhances the accessibility of smart\ndevices for dysarthric speakers with limited mobility. Previously, DSR research\nwas constrained by the fact that existing datasets typically consisted of\nisolated words, command phrases, and a limited number of sentences spoken by a\nfew individuals. This constrained research to command-interaction systems and\nspeaker adaptation. The Speech Accessibility Project (SAP) changed this by\nreleasing a large and diverse English dysarthric dataset, leading to the SAP\nChallenge to build speaker- and text-independent DSR systems. We enhanced the\nWhisper model's performance on long dysarthric speech via a novel self-training\nmethod. This method increased training data and adapted the model to handle\npotentially incomplete speech segments encountered during inference. Our system\nachieved second place in both Word Error Rate and Semantic Score in the SAP\nChallenge.", "AI": {"tldr": "The paper introduces a self-training method to improve Whisper model's performance on dysarthric speech, achieving second place in the SAP Challenge.", "motivation": "Existing dysarthric speech datasets were limited, restricting research to command-interaction systems. The SAP dataset enabled broader research, prompting the SAP Challenge.", "method": "A novel self-training method was used to enhance the Whisper model, increasing training data and adapting it for incomplete speech segments.", "result": "The system achieved second place in both Word Error Rate and Semantic Score in the SAP Challenge.", "conclusion": "The self-training method successfully improved dysarthric speech recognition, demonstrating its potential for broader applications."}}
{"id": "2506.22882", "pdf": "https://arxiv.org/pdf/2506.22882", "abs": "https://arxiv.org/abs/2506.22882", "authors": ["Qilong Xing", "Zikai Song", "Yuteng Ye", "Yuke Chen", "Youjia Zhang", "Na Feng", "Junqing Yu", "Wei Yang"], "title": "CA-Diff: Collaborative Anatomy Diffusion for Brain Tissue Segmentation", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "ICME 2025", "summary": "Segmentation of brain structures from MRI is crucial for evaluating brain\nmorphology, yet existing CNN and transformer-based methods struggle to\ndelineate complex structures accurately. While current diffusion models have\nshown promise in image segmentation, they are inadequate when applied directly\nto brain MRI due to neglecting anatomical information. To address this, we\npropose Collaborative Anatomy Diffusion (CA-Diff), a framework integrating\nspatial anatomical features to enhance segmentation accuracy of the diffusion\nmodel. Specifically, we introduce distance field as an auxiliary anatomical\ncondition to provide global spatial context, alongside a collaborative\ndiffusion process to model its joint distribution with anatomical structures,\nenabling effective utilization of anatomical features for segmentation.\nFurthermore, we introduce a consistency loss to refine relationships between\nthe distance field and anatomical structures and design a time adapted channel\nattention module to enhance the U-Net feature fusion procedure. Extensive\nexperiments show that CA-Diff outperforms state-of-the-art (SOTA) methods.", "AI": {"tldr": "Proposes CA-Diff, a framework combining anatomical features with diffusion models for improved brain MRI segmentation, outperforming SOTA methods.", "motivation": "Existing CNN and transformer-based methods fail to accurately segment complex brain structures in MRI, and current diffusion models neglect anatomical information.", "method": "Integrates spatial anatomical features via distance field as auxiliary condition, collaborative diffusion process, consistency loss, and time-adapted channel attention in U-Net.", "result": "CA-Diff achieves superior segmentation accuracy compared to state-of-the-art methods.", "conclusion": "The proposed CA-Diff effectively leverages anatomical features for precise brain MRI segmentation, demonstrating significant improvements over existing approaches."}}
{"id": "2506.22740", "pdf": "https://arxiv.org/pdf/2506.22740", "abs": "https://arxiv.org/abs/2506.22740", "authors": ["Jessica Hullman", "Ziyang Guo", "Berk Ustun"], "title": "Explanations are a means to an end", "categories": ["cs.AI", "stat.ML"], "comment": null, "summary": "Modern methods for explainable machine learning are designed to describe how\nmodels map inputs to outputs--without deep consideration of how these\nexplanations will be used in practice. This paper argues that explanations\nshould be designed and evaluated with a specific end in mind. We describe how\nto formalize this end in a framework based in statistical decision theory. We\nshow how this functionally-grounded approach can be applied across diverse use\ncases, such as clinical decision support, providing recourse, or debugging. We\ndemonstrate its use to characterize the maximum \"boost\" in performance on a\nparticular task that an explanation could provide an idealized decision-maker,\npreventing misuse due to ambiguity by forcing researchers to specify concrete\nuse cases that can be analyzed in light of models of expected explanation use.\nWe argue that evaluation should meld theoretical and empirical perspectives on\nthe value of explanation, and contribute definitions that span these\nperspectives.", "AI": {"tldr": "The paper advocates for designing and evaluating machine learning explanations with specific practical goals in mind, using a statistical decision theory framework.", "motivation": "Current explainable ML methods lack consideration of real-world application contexts, leading to potential misuse or ambiguity.", "method": "The authors propose a functionally-grounded framework based on statistical decision theory to formalize explanation goals and evaluate their practical utility.", "result": "The framework is demonstrated across diverse use cases (e.g., clinical decision support, debugging) and defines the maximum performance boost explanations can provide.", "conclusion": "Evaluation should combine theoretical and empirical perspectives, with clear use-case specifications to prevent misuse and ambiguity."}}
{"id": "2506.22444", "pdf": "https://arxiv.org/pdf/2506.22444", "abs": "https://arxiv.org/abs/2506.22444", "authors": ["Jing Wang", "Amar Sra", "Jeremy C. Weiss"], "title": "Active Learning for Forecasting Severity among Patients with Post Acute Sequelae of SARS-CoV-2", "categories": ["cs.LG", "cs.CY"], "comment": null, "summary": "The long-term effects of Postacute Sequelae of SARS-CoV-2, known as PASC,\npose a significant challenge to healthcare systems worldwide. Accurate\nidentification of progression events, such as hospitalization and reinfection,\nis essential for effective patient management and resource allocation. However,\ntraditional models trained on structured data struggle to capture the nuanced\nprogression of PASC. In this study, we introduce the first publicly available\ncohort of 18 PASC patients, with text time series features based on Large\nLanguage Model Llama-3.1-70B-Instruct and clinical risk annotated by clinical\nexpert. We propose an Active Attention Network to predict the clinical risk and\nidentify progression events related to the risk. By integrating human expertise\nwith active learning, we aim to enhance clinical risk prediction accuracy and\nenable progression events identification with fewer number of annotation. The\nultimate goal is to improves patient care and decision-making for SARS-CoV-2\npatient.", "AI": {"tldr": "The study introduces a cohort of 18 PASC patients with text time series features and proposes an Active Attention Network to predict clinical risk and progression events, aiming to improve patient care.", "motivation": "Accurate identification of PASC progression events is challenging with traditional models, necessitating better methods for patient management.", "method": "Uses a cohort with text time series features from Llama-3.1-70B-Instruct and clinical expert annotations, proposing an Active Attention Network for risk prediction and event identification.", "result": "Aims to enhance clinical risk prediction accuracy and reduce annotation needs by integrating human expertise with active learning.", "conclusion": "The approach seeks to improve patient care and decision-making for SARS-CoV-2 patients by addressing PASC progression challenges."}}
{"id": "2506.22498", "pdf": "https://arxiv.org/pdf/2506.22498", "abs": "https://arxiv.org/abs/2506.22498", "authors": ["Hao Liu", "Yu Hu", "Rakiba Rayhana", "Ling Bai", "Zheng Liu"], "title": "ViFusionTST: Deep Fusion of Time-Series Image Representations from Load Signals for Early Bed-Exit Prediction", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Bed-related falls remain a leading source of injury in hospitals and\nlong-term-care facilities, yet many commercial alarms trigger only after a\npatient has already left the bed. We show that early bed-exit intent can be\npredicted using only four low-cost load cells mounted under the bed legs. The\nresulting load signals are first converted into a compact set of complementary\nimages: an RGB line plot that preserves raw waveforms and three texture maps -\nrecurrence plot, Markov transition field, and Gramian angular field - that\nexpose higher-order dynamics. We introduce ViFusionTST, a dual-stream Swin\nTransformer that processes the line plot and texture maps in parallel and fuses\nthem through cross-attention to learn data-driven modality weights.\n  To provide a realistic benchmark, we collected six months of continuous data\nfrom 95 beds in a long-term-care facility. On this real-world dataset\nViFusionTST reaches an accuracy of 0.885 and an F1 score of 0.794, surpassing\nrecent 1D and 2D time-series baselines across F1, recall, accuracy, and AUPRC.\nThe results demonstrate that image-based fusion of load-sensor signals for time\nseries classification is a practical and effective solution for real-time,\nprivacy-preserving fall prevention.", "AI": {"tldr": "A novel method using load cells and image-based fusion predicts bed-exit intent early, outperforming existing baselines for fall prevention.", "motivation": "Bed-related falls are a major injury source in healthcare; existing alarms react too late.", "method": "Uses four load cells under bed legs, converts signals into images (RGB line plot and texture maps), and processes them with ViFusionTST, a dual-stream Swin Transformer.", "result": "Achieves 0.885 accuracy and 0.794 F1 score on real-world data, surpassing 1D/2D baselines.", "conclusion": "Image-based fusion of load-sensor signals is effective for real-time, privacy-preserving fall prevention."}}
{"id": "2506.22518", "pdf": "https://arxiv.org/pdf/2506.22518", "abs": "https://arxiv.org/abs/2506.22518", "authors": ["Deyu Zou", "Yongqiang Chen", "Mufei Li", "Siqi Miao", "Chenxi Liu", "Bo Han", "James Cheng", "Pan Li"], "title": "Weak-to-Strong GraphRAG: Aligning Weak Retrievers with Large Language Models for Graph-based Retrieval Augmented Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Graph-based retrieval-augmented generation (RAG) enables large language\nmodels (LLMs) to ground responses with structured external knowledge from\nup-to-date knowledge graphs (KGs) and reduce hallucinations. However, LLMs\noften rely on a weak retriever in graph-based RAG: I) Due to the lack of ground\ntruth, the retriever is often trained on weak supervision, which often\nintroduces spurious signals to the LLMs. II) Due to the abstraction of graph\ndata, the retrieved knowledge is often presented in unorganized forms. To\nmitigate the issue, we present Refined Graph-based RAG (ReG) to align weak\nretrievers to LLMs for graph-based RAG. Specifically, ReG incorporates LLM\nfeedback to get rid of spurious signals and improve the quality of the\nsupervision. Meanwhile, ReG introduces a structure-aware reorganization module\nto refactor the retrieval results into logically coherent evidence chains.\nExperiments on prominent benchmarks demonstrate that ReG significantly and\nconsistently brings improvements across different LLM backbones by up to 10%.\nThe improved supervision quality enables ReG to match the state-of-the-art\nperformance with 5% training data and to transfer to out-of-distribution KGs.\nNotably, when adopted to reasoning-based LLMs, ReG reduces the reasoning token\ncost by up to 30% and improves the performance by up to 4%.", "AI": {"tldr": "ReG improves graph-based RAG by aligning weak retrievers with LLMs, using feedback to remove spurious signals and reorganizing retrieved knowledge into coherent evidence chains, achieving up to 10% performance gains.", "motivation": "Current graph-based RAG systems suffer from weak retrievers due to lack of ground truth and unorganized retrieved knowledge, leading to spurious signals and poor performance.", "method": "ReG incorporates LLM feedback to refine supervision and introduces a structure-aware module to reorganize retrieval results into coherent evidence chains.", "result": "ReG improves performance by up to 10%, matches state-of-the-art with 5% training data, reduces reasoning token cost by 30%, and boosts reasoning performance by 4%.", "conclusion": "ReG effectively addresses the limitations of weak retrievers in graph-based RAG, enhancing performance and efficiency across various benchmarks and LLM backbones."}}
{"id": "2506.23859", "pdf": "https://arxiv.org/pdf/2506.23859", "abs": "https://arxiv.org/abs/2506.23859", "authors": ["Chenda Li", "Wangyou Zhang", "Wei Wang", "Robin Scheibler", "Kohei Saijo", "Samuele Cornell", "Yihui Fu", "Marvin Sach", "Zhaoheng Ni", "Anurag Kumar", "Tim Fingscheidt", "Shinji Watanabe", "Yanmin Qian"], "title": "Less is More: Data Curation Matters in Scaling Speech Enhancement", "categories": ["eess.AS", "cs.SD"], "comment": "Submitted to ASRU2025", "summary": "The vast majority of modern speech enhancement systems rely on data-driven\nneural network models. Conventionally, larger datasets are presumed to yield\nsuperior model performance, an observation empirically validated across\nnumerous tasks in other domains. However, recent studies reveal diminishing\nreturns when scaling speech enhancement data. We focus on a critical factor:\nprevalent quality issues in ``clean'' training labels within large-scale\ndatasets. This work re-examines this phenomenon and demonstrates that, within\nlarge-scale training sets, prioritizing high-quality training data is more\nimportant than merely expanding the data volume. Experimental findings suggest\nthat models trained on a carefully curated subset of 700 hours can outperform\nmodels trained on the 2,500-hour full dataset. This outcome highlights the\ncrucial role of data curation in scaling speech enhancement systems\neffectively.", "AI": {"tldr": "Prioritizing high-quality training data over volume improves speech enhancement model performance.", "motivation": "To address diminishing returns in scaling speech enhancement data by focusing on quality issues in \"clean\" training labels.", "method": "Re-examining data scaling effects and comparing models trained on a curated 700-hour subset versus a full 2,500-hour dataset.", "result": "Models trained on the smaller, high-quality subset outperformed those trained on the larger dataset.", "conclusion": "Data curation is crucial for effective scaling of speech enhancement systems."}}
{"id": "2506.22855", "pdf": "https://arxiv.org/pdf/2506.22855", "abs": "https://arxiv.org/abs/2506.22855", "authors": ["Mohammadreza Doostmohammadian", "Hamid R. Rabiee"], "title": "Momentum-based Accelerated Algorithm for Distributed Optimization under Sector-Bound Nonlinearity", "categories": ["eess.SY", "cs.DC", "cs.MA", "cs.SY", "eess.SP", "math.OC"], "comment": "Journal of the Franklin Institute", "summary": "Distributed optimization advances centralized machine learning methods by\nenabling parallel and decentralized learning processes over a network of\ncomputing nodes. This work provides an accelerated consensus-based distributed\nalgorithm for locally non-convex optimization using the gradient-tracking\ntechnique. The proposed algorithm (i) improves the convergence rate by adding\nmomentum towards the optimal state using the heavy-ball method, while (ii)\naddressing general sector-bound nonlinearities over the information-sharing\nnetwork. The link nonlinearity includes any sign-preserving odd sector-bound\nmapping, for example, log-scale data quantization or clipping in practical\napplications. For admissible momentum and gradient-tracking parameters, using\nperturbation theory and eigen-spectrum analysis, we prove convergence even in\nthe presence of sector-bound nonlinearity and for locally non-convex cost\nfunctions. Further, in contrast to most existing weight-stochastic algorithms,\nwe adopt weight-balanced (WB) network design. This WB design and\nperturbation-based analysis allow to handle dynamic directed network of agents\nto address possible time-varying setups due to link failures or packet drops.", "AI": {"tldr": "An accelerated consensus-based distributed algorithm is proposed for locally non-convex optimization, improving convergence via momentum and handling sector-bound nonlinearities in dynamic networks.", "motivation": "To enhance distributed optimization by addressing convergence and nonlinearities in dynamic, directed networks.", "method": "Uses gradient-tracking and heavy-ball momentum, with perturbation theory and eigen-spectrum analysis for proof of convergence.", "result": "Convergence is proven even with sector-bound nonlinearities and locally non-convex costs, supported by weight-balanced network design.", "conclusion": "The algorithm effectively handles dynamic networks and nonlinearities, offering robust distributed optimization."}}
{"id": "2506.22926", "pdf": "https://arxiv.org/pdf/2506.22926", "abs": "https://arxiv.org/abs/2506.22926", "authors": ["Qixuan Liu", "Shi Qiu", "Yinqiao Wang", "Xiwen Wu", "Kenneth Siu Ho Chok", "Chi-Wing Fu", "Pheng-Ann Heng"], "title": "Coordinated 2D-3D Visualization of Volumetric Medical Data in XR with Multimodal Interactions", "categories": ["cs.HC", "cs.GR", "cs.MM"], "comment": "IEEE VIS 2025 Short Paper", "summary": "Volumetric medical imaging technologies produce detailed 3D representations\nof anatomical structures. However, effective medical data visualization and\nexploration pose significant challenges, especially for individuals with\nlimited medical expertise. We introduce a novel XR-based system with two key\ninnovations: (1) a coordinated visualization module integrating Multi-layered\nMulti-planar Reconstruction with 3D mesh models and (2) a multimodal\ninteraction framework combining hand gestures with LLM-enabled voice commands.\nWe conduct preliminary evaluations, including a 15-participant user study and\nexpert interviews, to demonstrate the system's abilities to enhance spatial\nunderstanding and reduce cognitive load. Experimental results show notable\nimprovements in task completion times, usability metrics, and interaction\neffectiveness enhanced by LLM-driven voice control. While identifying areas for\nfuture refinement, our findings highlight the potential of this immersive\nvisualization system to advance medical training and clinical practice. Our\ndemo application and supplemental materials are available for download at:\nhttps://osf.io/bpjq5/.", "AI": {"tldr": "A novel XR-based system integrates Multi-layered Multi-planar Reconstruction with 3D mesh models and multimodal interaction (hand gestures + LLM-enabled voice commands) to improve medical data visualization. Preliminary evaluations show enhanced spatial understanding and reduced cognitive load.", "motivation": "Effective visualization of volumetric medical imaging is challenging, especially for non-experts, necessitating intuitive tools for better spatial understanding and usability.", "method": "Developed an XR system with coordinated visualization (Multi-layered Multi-planar Reconstruction + 3D mesh) and multimodal interaction (hand gestures + LLM-driven voice commands). Evaluated via user study (15 participants) and expert interviews.", "result": "Improved task completion times, usability metrics, and interaction effectiveness, particularly with LLM-driven voice control.", "conclusion": "The system shows promise for advancing medical training and clinical practice, though further refinements are needed."}}
{"id": "2506.23094", "pdf": "https://arxiv.org/pdf/2506.23094", "abs": "https://arxiv.org/abs/2506.23094", "authors": ["Qi He", "Gus Xia", "Ziyu Wang"], "title": "TOMI: Transforming and Organizing Music Ideas for Multi-Track Compositions with Full-Song Structure", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "9 pages, 4 figures, 2 tables. To be published in ISMIR 2025", "summary": "Hierarchical planning is a powerful approach to model long sequences\nstructurally. Aside from considering hierarchies in the temporal structure of\nmusic, this paper explores an even more important aspect: concept hierarchy,\nwhich involves generating music ideas, transforming them, and ultimately\norganizing them--across musical time and space--into a complete composition. To\nthis end, we introduce TOMI (Transforming and Organizing Music Ideas) as a\nnovel approach in deep music generation and develop a TOMI-based model via\ninstruction-tuned foundation LLM. Formally, we represent a multi-track\ncomposition process via a sparse, four-dimensional space characterized by clips\n(short audio or MIDI segments), sections (temporal positions), tracks\n(instrument layers), and transformations (elaboration methods). Our model is\ncapable of generating multi-track electronic music with full-song structure,\nand we further integrate the TOMI-based model with the REAPER digital audio\nworkstation, enabling interactive human-AI co-creation. Experimental results\ndemonstrate that our approach produces higher-quality electronic music with\nstronger structural coherence compared to baselines.", "AI": {"tldr": "The paper introduces TOMI, a hierarchical planning approach for deep music generation, using an instruction-tuned LLM to create multi-track electronic music with strong structural coherence.", "motivation": "To explore concept hierarchy in music generation, enabling the transformation and organization of musical ideas into complete compositions.", "method": "Developed TOMI, a model representing compositions in a 4D space (clips, sections, tracks, transformations) and integrated it with REAPER for human-AI co-creation.", "result": "The model generates higher-quality electronic music with better structural coherence than baselines.", "conclusion": "TOMI effectively combines hierarchical planning and AI for advanced music generation and co-creation."}}
{"id": "2506.22952", "pdf": "https://arxiv.org/pdf/2506.22952", "abs": "https://arxiv.org/abs/2506.22952", "authors": ["Yanwu Yang", "Thomas Wolfers"], "title": "Hierarchical Characterization of Brain Dynamics via State Space-based Vector Quantization", "categories": ["eess.IV", "cs.CV", "q-bio.NC"], "comment": null, "summary": "Understanding brain dynamics through functional Magnetic Resonance Imaging\n(fMRI) remains a fundamental challenge in neuroscience, particularly in\ncapturing how the brain transitions between various functional states.\nRecently, metastability, which refers to temporarily stable brain states, has\noffered a promising paradigm to quantify complex brain signals into\ninterpretable, discretized representations. In particular, compared to\ncluster-based machine learning approaches, tokenization approaches leveraging\nvector quantization have shown promise in representation learning with powerful\nreconstruction and predictive capabilities. However, most existing methods\nignore brain transition dependencies and lack a quantification of brain\ndynamics into representative and stable embeddings. In this study, we propose a\nHierarchical State space-based Tokenization network, termed HST, which\nquantizes brain states and transitions in a hierarchical structure based on a\nstate space-based model. We introduce a refined clustered Vector-Quantization\nVariational AutoEncoder (VQ-VAE) that incorporates quantization error feedback\nand clustering to improve quantization performance while facilitating\nmetastability with representative and stable token representations. We validate\nour HST on two public fMRI datasets, demonstrating its effectiveness in\nquantifying the hierarchical dynamics of the brain and its potential in disease\ndiagnosis and reconstruction performance. Our method offers a promising\nframework for the characterization of brain dynamics, facilitating the analysis\nof metastability.", "AI": {"tldr": "The paper proposes HST, a hierarchical state space-based tokenization network, to quantify brain dynamics and transitions using a refined VQ-VAE, improving metastability representation and performance in fMRI analysis.", "motivation": "Understanding brain dynamics via fMRI is challenging, especially in capturing transitions between functional states. Existing methods lack transition dependencies and stable embeddings.", "method": "HST combines a state space-based model with a refined VQ-VAE, incorporating quantization error feedback and clustering for better quantization and metastability.", "result": "Validated on two fMRI datasets, HST effectively quantifies hierarchical brain dynamics and shows potential in disease diagnosis and reconstruction.", "conclusion": "HST provides a promising framework for analyzing brain metastability and dynamics, enhancing fMRI interpretation."}}
{"id": "2506.22774", "pdf": "https://arxiv.org/pdf/2506.22774", "abs": "https://arxiv.org/abs/2506.22774", "authors": ["Michael Papademas", "Xenia Ziouvelou", "Antonis Troumpoukis", "Vangelis Karkaletsis"], "title": "Bridging Ethical Principles and Algorithmic Methods: An Alternative Approach for Assessing Trustworthiness in AI Systems", "categories": ["cs.AI", "cs.CY"], "comment": null, "summary": "Artificial Intelligence (AI) technology epitomizes the complex challenges\nposed by human-made artifacts, particularly those widely integrated into\nsociety and exert significant influence, highlighting potential benefits and\ntheir negative consequences. While other technologies may also pose substantial\nrisks, AI's pervasive reach makes its societal effects especially profound. The\ncomplexity of AI systems, coupled with their remarkable capabilities, can lead\nto a reliance on technologies that operate beyond direct human oversight or\nunderstanding. To mitigate the risks that arise, several theoretical tools and\nguidelines have been developed, alongside efforts to create technological tools\naimed at safeguarding Trustworthy AI. The guidelines take a more holistic view\nof the issue but fail to provide techniques for quantifying trustworthiness.\nConversely, while technological tools are better at achieving such\nquantification, they lack a holistic perspective, focusing instead on specific\naspects of Trustworthy AI. This paper aims to introduce an assessment method\nthat combines the ethical components of Trustworthy AI with the algorithmic\nprocesses of PageRank and TrustRank. The goal is to establish an assessment\nframework that minimizes the subjectivity inherent in the self-assessment\ntechniques prevalent in the field by introducing algorithmic criteria. The\napplication of our approach indicates that a holistic assessment of an AI\nsystem's trustworthiness can be achieved by providing quantitative insights\nwhile considering the theoretical content of relevant guidelines.", "AI": {"tldr": "The paper proposes a method to assess AI trustworthiness by combining ethical guidelines with algorithmic processes like PageRank and TrustRank, aiming for a balanced quantitative and holistic evaluation.", "motivation": "AI's pervasive societal impact and complexity necessitate reliable trustworthiness assessments, but current methods lack a balance between holistic ethical views and quantitative techniques.", "method": "The paper integrates ethical components of Trustworthy AI with algorithmic processes (PageRank and TrustRank) to create a quantitative yet holistic assessment framework.", "result": "The proposed method successfully combines quantitative insights with theoretical guidelines, minimizing subjectivity in trustworthiness evaluations.", "conclusion": "The framework offers a balanced approach to assessing AI trustworthiness, addressing gaps in current methods by merging ethical and algorithmic perspectives."}}
{"id": "2506.22446", "pdf": "https://arxiv.org/pdf/2506.22446", "abs": "https://arxiv.org/abs/2506.22446", "authors": ["Aakash Tripathi", "Asim Waqas", "Matthew B. Schabath", "Yasin Yilmaz", "Ghulam Rasool"], "title": "EAGLE: Efficient Alignment of Generalized Latent Embeddings for Multimodal Survival Prediction with Interpretable Attribution Analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate cancer survival prediction requires integration of diverse data\nmodalities that reflect the complex interplay between imaging, clinical\nparameters, and textual reports. However, existing multimodal approaches suffer\nfrom simplistic fusion strategies, massive computational requirements, and lack\nof interpretability-critical barriers to clinical adoption. We present EAGLE\n(Efficient Alignment of Generalized Latent Embeddings), a novel deep learning\nframework that addresses these limitations through attention-based multimodal\nfusion with comprehensive attribution analysis. EAGLE introduces four key\ninnovations: (1) dynamic cross-modal attention mechanisms that learn\nhierarchical relationships between modalities, (2) massive dimensionality\nreduction (99.96%) while maintaining predictive performance, (3) three\ncomplementary attribution methods providing patient-level interpretability, and\n(4) a unified pipeline enabling seamless adaptation across cancer types. We\nevaluated EAGLE on 911 patients across three distinct malignancies:\nglioblastoma (GBM, n=160), intraductal papillary mucinous neoplasms (IPMN,\nn=171), and non-small cell lung cancer (NSCLC, n=580). Patient-level analysis\nshowed high-risk individuals relied more heavily on adverse imaging features,\nwhile low-risk patients demonstrated balanced modality contributions. Risk\nstratification identified clinically meaningful groups with 4-fold (GBM) to\n5-fold (NSCLC) differences in median survival, directly informing treatment\nintensity decisions. By combining state-of-the-art performance with clinical\ninterpretability, EAGLE bridges the gap between advanced AI capabilities and\npractical healthcare deployment, offering a scalable solution for multimodal\nsurvival prediction that enhances both prognostic accuracy and physician trust\nin automated predictions.", "AI": {"tldr": "EAGLE is a deep learning framework for cancer survival prediction, using attention-based multimodal fusion and interpretability methods to improve accuracy and clinical adoption.", "motivation": "Existing multimodal approaches for cancer survival prediction lack interpretability, efficiency, and effective fusion strategies, hindering clinical use.", "method": "EAGLE employs dynamic cross-modal attention, dimensionality reduction, three attribution methods, and a unified pipeline for adaptability across cancer types.", "result": "EAGLE achieved high-risk stratification with 4-5 fold survival differences, showing reliance on imaging features for high-risk patients and balanced modality use for low-risk ones.", "conclusion": "EAGLE bridges AI and healthcare by offering scalable, interpretable, and accurate multimodal survival prediction, enhancing physician trust."}}
{"id": "2506.22499", "pdf": "https://arxiv.org/pdf/2506.22499", "abs": "https://arxiv.org/abs/2506.22499", "authors": ["Jiachao Liu", "Pablo Guarda", "Koichiro Niinuma", "Sean Qian"], "title": "Scalable Dynamic Origin-Destination Demand Estimation Enhanced by High-Resolution Satellite Imagery Data", "categories": ["cs.CV", "cs.AI", "stat.AP"], "comment": null, "summary": "This study presents a novel integrated framework for dynamic\norigin-destination demand estimation (DODE) in multi-class mesoscopic network\nmodels, leveraging high-resolution satellite imagery together with conventional\ntraffic data from local sensors. Unlike sparse local detectors, satellite\nimagery offers consistent, city-wide road and traffic information of both\nparking and moving vehicles, overcoming data availability limitations. To\nextract information from imagery data, we design a computer vision pipeline for\nclass-specific vehicle detection and map matching, generating link-level\ntraffic density observations by vehicle class. Building upon this information,\nwe formulate a computational graph-based DODE model that calibrates dynamic\nnetwork states by jointly matching observed traffic counts and travel times\nfrom local sensors with density measurements derived from satellite imagery. To\nassess the accuracy and scalability of the proposed framework, we conduct a\nseries of numerical experiments using both synthetic and real-world data. The\nresults of out-of-sample tests demonstrate that supplementing traditional data\nwith satellite-derived density significantly improves estimation performance,\nespecially for links without local sensors. Real-world experiments also confirm\nthe framework's capability to handle large-scale networks, supporting its\npotential for practical deployment in cities of varying sizes. Sensitivity\nanalysis further evaluates the impact of data quality related to satellite\nimagery data.", "AI": {"tldr": "A novel framework for dynamic origin-destination demand estimation (DODE) integrates satellite imagery with local sensor data, improving accuracy and scalability in multi-class mesoscopic network models.", "motivation": "Overcome limitations of sparse local traffic detectors by leveraging consistent, city-wide satellite imagery for comprehensive traffic data.", "method": "Develop a computer vision pipeline for vehicle detection and map matching, then formulate a computational graph-based DODE model to calibrate network states using combined data sources.", "result": "Satellite-derived density significantly enhances estimation accuracy, particularly for unsensed links, and the framework scales well in real-world large networks.", "conclusion": "The integrated framework shows promise for practical deployment in cities of varying sizes, with sensitivity to satellite data quality."}}
{"id": "2506.22529", "pdf": "https://arxiv.org/pdf/2506.22529", "abs": "https://arxiv.org/abs/2506.22529", "authors": ["Lu Kalkbrenner", "Veronika Solopova", "Steffen Zeiler", "Robert Nickel", "Dorothea Kolossa"], "title": "MisinfoTeleGraph: Network-driven Misinformation Detection for German Telegram Messages", "categories": ["cs.CL"], "comment": null, "summary": "Connectivity and message propagation are central, yet often underutilized,\nsources of information in misinformation detection -- especially on poorly\nmoderated platforms such as Telegram, which has become a critical channel for\nmisinformation dissemination, namely in the German electoral context. In this\npaper, we introduce Misinfo-TeleGraph, the first German-language Telegram-based\ngraph dataset for misinformation detection. It includes over 5 million messages\nfrom public channels, enriched with metadata, channel relationships, and both\nweak and strong labels. These labels are derived via semantic similarity to\nfact-checks and news articles using M3-embeddings, as well as manual\nannotation. To establish reproducible baselines, we evaluate both text-only\nmodels and graph neural networks (GNNs) that incorporate message forwarding as\na network structure. Our results show that GraphSAGE with LSTM aggregation\nsignificantly outperforms text-only baselines in terms of Matthews Correlation\nCoefficient (MCC) and F1-score. We further evaluate the impact of subscribers,\nview counts, and automatically versus human-created labels on performance, and\nhighlight both the potential and challenges of weak supervision in this domain.\nThis work provides a reproducible benchmark and open dataset for future\nresearch on misinformation detection in German-language Telegram networks and\nother low-moderation social platforms.", "AI": {"tldr": "The paper introduces Misinfo-TeleGraph, a German-language Telegram dataset for misinformation detection, and evaluates text-only and graph-based models, showing GraphSAGE with LSTM aggregation outperforms text-only methods.", "motivation": "To address the underutilization of connectivity and message propagation in misinformation detection, especially on poorly moderated platforms like Telegram, which is critical in the German electoral context.", "method": "The dataset includes 5M+ messages with metadata, channel relationships, and labels derived via semantic similarity (M3-embeddings) and manual annotation. Text-only models and GNNs (like GraphSAGE with LSTM aggregation) are evaluated.", "result": "GraphSAGE with LSTM aggregation outperforms text-only baselines in MCC and F1-score. The study also examines the impact of subscribers, view counts, and label types (weak vs. strong).", "conclusion": "The work provides a benchmark and open dataset for future research on misinformation detection in German Telegram and similar platforms, highlighting the potential and challenges of weak supervision."}}
{"id": "2506.23874", "pdf": "https://arxiv.org/pdf/2506.23874", "abs": "https://arxiv.org/abs/2506.23874", "authors": ["Jiahe Wang", "Chenda Li", "Wei Wang", "Wangyou Zhang", "Samuele Cornell", "Marvin Sach", "Robin Scheibler", "Kohei Saijo", "Yihui Fu", "Zhaoheng Ni", "Anurag Kumar", "Tim Fingscheidt", "Shinji Watanabe", "Yanmin Qian"], "title": "URGENT-PK: Perceptually-Aligned Ranking Model Designed for Speech Enhancement Competition", "categories": ["eess.AS", "cs.SD"], "comment": "Submitted to ASRU2025", "summary": "The Mean Opinion Score (MOS) is fundamental to speech quality assessment.\nHowever, its acquisition requires significant human annotation. Although deep\nneural network approaches, such as DNSMOS and UTMOS, have been developed to\npredict MOS to avoid this issue, they often suffer from insufficient training\ndata. Recognizing that the comparison of speech enhancement (SE) systems\nprioritizes a reliable system comparison over absolute scores, we propose\nURGENT-PK, a novel ranking approach leveraging pairwise comparisons. URGENT-PK\ntakes homologous enhanced speech pairs as input to predict relative quality\nrankings. This pairwise paradigm efficiently utilizes limited training data, as\nall pairwise permutations of multiple systems constitute a training instance.\nExperiments across multiple open test sets demonstrate URGENT-PK's superior\nsystem-level ranking performance over state-of-the-art baselines, despite its\nsimple network architecture and limited training data.", "AI": {"tldr": "URGENT-PK is a ranking approach for speech quality assessment using pairwise comparisons, outperforming baselines with limited data.", "motivation": "MOS acquisition is costly, and existing deep learning methods lack sufficient training data. Reliable system comparison is prioritized over absolute scores.", "method": "URGENT-PK uses homologous speech pairs to predict relative quality rankings, efficiently leveraging limited data through pairwise permutations.", "result": "URGENT-PK achieves superior system-level ranking performance on open test sets despite simple architecture and limited training data.", "conclusion": "Pairwise comparisons offer an effective solution for speech quality ranking with limited data, outperforming traditional MOS-based methods."}}
{"id": "2506.22899", "pdf": "https://arxiv.org/pdf/2506.22899", "abs": "https://arxiv.org/abs/2506.22899", "authors": ["Ehsan Pajouheshgar", "Yitao Xu", "Ali Abbasi", "Alexander Mordvintsev", "Wenzel Jakob", "Sabine S\u00fcsstrunk"], "title": "Neural Cellular Automata: From Cells to Pixels", "categories": ["cs.CV", "cs.GR", "cs.LG", "cs.MA", "eess.IV"], "comment": "6 pages, 5 figures, first draft", "summary": "Neural Cellular Automata (NCAs) are bio-inspired systems in which identical\ncells self-organize to form complex and coherent patterns by repeatedly\napplying simple local rules. NCAs display striking emergent behaviors including\nself-regeneration, generalization and robustness to unseen situations, and\nspontaneous motion. Despite their success in texture synthesis and\nmorphogenesis, NCAs remain largely confined to low-resolution grids. This\nlimitation stems from (1) training time and memory requirements that grow\nquadratically with grid size, (2) the strictly local propagation of information\nwhich impedes long-range cell communication, and (3) the heavy compute demands\nof real-time inference at high resolution. In this work, we overcome this\nlimitation by pairing NCA with a tiny, shared implicit decoder, inspired by\nrecent advances in implicit neural representations. Following NCA evolution on\na coarse grid, a lightweight decoder renders output images at arbitrary\nresolution. We also propose novel loss functions for both morphogenesis and\ntexture synthesis tasks, specifically tailored for high-resolution output with\nminimal memory and computation overhead. Combining our proposed architecture\nand loss functions brings substantial improvement in quality, efficiency, and\nperformance. NCAs equipped with our implicit decoder can generate full-HD\noutputs in real time while preserving their self-organizing, emergent\nproperties. Moreover, because each MLP processes cell states independently,\ninference remains highly parallelizable and efficient. We demonstrate the\napplicability of our approach across multiple NCA variants (on 2D, 3D grids,\nand 3D meshes) and multiple tasks, including texture generation and\nmorphogenesis (growing patterns from a seed), showing that with our proposed\nframework, NCAs seamlessly scale to high-resolution outputs with minimal\ncomputational overhead.", "AI": {"tldr": "Neural Cellular Automata (NCAs) are enhanced with an implicit decoder to overcome limitations in high-resolution tasks, enabling real-time full-HD outputs while preserving emergent properties.", "motivation": "NCAs are limited by high computational costs and local information propagation, restricting them to low-resolution grids. This work aims to scale NCAs to high-resolution outputs efficiently.", "method": "The paper pairs NCAs with a shared implicit decoder and introduces novel loss functions for high-resolution tasks, ensuring minimal memory and computation overhead.", "result": "The proposed framework allows NCAs to generate full-HD outputs in real time, maintaining self-organizing properties and efficiency across 2D, 3D grids, and 3D meshes.", "conclusion": "The integration of an implicit decoder and tailored loss functions enables NCAs to scale seamlessly to high-resolution tasks with minimal computational overhead."}}
{"id": "2506.22967", "pdf": "https://arxiv.org/pdf/2506.22967", "abs": "https://arxiv.org/abs/2506.22967", "authors": ["Amir Aghdam", "Vincent Tao Hu"], "title": "ActAlign: Zero-Shot Fine-Grained Video Classification via Language-Guided Sequence Alignment", "categories": ["cs.CV", "cs.LG", "cs.MM", "I.2.10; I.2.7"], "comment": "Preprint manuscript - Project page:\n  https://github.com/aghdamamir/act-align", "summary": "We address the task of zero-shot fine-grained video classification, where no\nvideo examples or temporal annotations are available for unseen action classes.\nWhile contrastive vision-language models such as SigLIP demonstrate strong\nopen-set recognition via mean-pooled image-text similarity, they fail to\ncapture the temporal structure critical for distinguishing fine-grained\nactivities. We introduce ActAlign, a zero-shot framework that formulates video\nclassification as sequence alignment. For each class, a large language model\ngenerates an ordered sub-action sequence, which is aligned with video frames\nusing Dynamic Time Warping (DTW) in a shared embedding space. Without any\nvideo-text supervision or fine-tuning, ActAlign achieves 30.5% accuracy on the\nextremely challenging ActionAtlas benchmark, where human accuracy is only\n61.6%. ActAlign outperforms billion-parameter video-language models while using\napproximately 8x less parameters. These results demonstrate that structured\nlanguage priors, combined with classical alignment techniques, offer a scalable\nand general approach to unlocking the open-set recognition potential of\nvision-language models for fine-grained video understanding.", "AI": {"tldr": "ActAlign is a zero-shot framework for fine-grained video classification using sequence alignment with language-generated sub-action sequences, outperforming larger models without video-text supervision.", "motivation": "To address the challenge of zero-shot fine-grained video classification without temporal annotations or video examples for unseen classes.", "method": "Uses a large language model to generate ordered sub-action sequences for each class, aligning them with video frames via Dynamic Time Warping (DTW) in a shared embedding space.", "result": "Achieves 30.5% accuracy on ActionAtlas (human accuracy: 61.6%), outperforming larger models with 8x fewer parameters.", "conclusion": "Structured language priors and classical alignment techniques can effectively enhance vision-language models for fine-grained video understanding."}}
{"id": "2506.23130", "pdf": "https://arxiv.org/pdf/2506.23130", "abs": "https://arxiv.org/abs/2506.23130", "authors": ["Tao-Tao He", "Martin E. Malandro", "Douglas Shadle"], "title": "The Florence Price Art Song Dataset and Piano Accompaniment Generator", "categories": ["cs.SD", "eess.AS"], "comment": "8 pages, 4 figures. To appear in the proceedings of ISMIR 2025", "summary": "Florence B. Price was a composer in the early 20th century whose music\nreflects her upbringing in the American South, her African heritage, and her\nWestern classical training. She is noted as the first African-American woman to\nhave a symphony performed by a major orchestra. Her music has recently received\nrenewed attention from both the public and the research community, decades\nafter her death. In addition to other genres, Price was a prolific composer for\nsolo voice and piano. Music historians have documented the existence of 134 art\nsongs and piano/voice arrangements for spirituals and folk songs written by\nPrice. We release a digital catalog of 112 of these works in MuseScore,\nMusicXML, MIDI, and PDF format. We also use this dataset to fine-tune a\nsymbolic music generation model to generate accompaniments to melodies, and we\nconduct a blind listening experiment that shows that accompaniments generated\nby our model are perceived as being reflective of Florence Price's style more\nfrequently than accompaniments generated by a baseline model. We release our\nmodel as the Florence Price Piano Accompaniment Generator alongside our\ndataset.", "AI": {"tldr": "A digital catalog of Florence B. Price's 112 works is released, and a model for generating piano accompaniments in her style is developed and tested.", "motivation": "To revive and digitize Florence B. Price's music, leveraging modern technology to study and emulate her style.", "method": "Creation of a digital catalog in multiple formats, fine-tuning a symbolic music generation model, and conducting a blind listening experiment.", "result": "The model-generated accompaniments were perceived as more reflective of Price's style than a baseline model.", "conclusion": "The project successfully digitizes Price's works and introduces a tool for generating stylistically accurate accompaniments, aiding in her musical legacy."}}
{"id": "2506.23002", "pdf": "https://arxiv.org/pdf/2506.23002", "abs": "https://arxiv.org/abs/2506.23002", "authors": ["Vaigai Nayaki Yokar", "Hoa Le-Minh", "Zabih Ghassemlooy", "Wai Lok Woo"], "title": "An Image Processing Based Blur Reduction Technique in Smartphone-to-Smartphone Visible Light Communication System", "categories": ["eess.IV"], "comment": null, "summary": "In this paper, we present a blur reduction technique for\nsmartphone-to-smartphone visible light communications (S2SVLC). The key\ntechnique it to avoid the repeated scanning of the transmitted data and to\nlower the amount of data discarded at the receiver end of the S2SVLC system.\nThis image processing method will improve the system recognition efficiency and\ndata rate. The proposed method includes converting the red-green-blue (RGB)\nimage into grayscale, applying contrast enhancement, scaling and binarizing the\nimage to reduce the blur levels in the image. The experiment includes practical\ndata acquisition and further processing and estimation in MATLAB. The\nexperiment is carried out in different conditions like distance, rotation, and\ntilt also considering different surrounding illuminations like ambient light\nand no light conditions to estimate the blur levels in S2SVLC. In this\nexperimental investigation two types of coding, American Standard code for\ninformation interchange (ASCII), and quick response (QR) code are used for data\ntransmission in S2SVLC. The obtained results indicate that, the proposed\ntechnique is proven to improve the recovery efficiency to 96% in the receiver\nend at different conditions.", "AI": {"tldr": "A blur reduction technique for smartphone-to-smartphone visible light communications (S2SVLC) is proposed, improving recognition efficiency and data rate by processing images to reduce blur.", "motivation": "To enhance S2SVLC by reducing blur and minimizing data loss at the receiver end, improving overall system performance.", "method": "Converts RGB images to grayscale, applies contrast enhancement, scaling, and binarization to reduce blur. Experiments are conducted under varying conditions (distance, rotation, tilt, illumination) using ASCII and QR codes.", "result": "The technique achieves a 96% recovery efficiency at the receiver end under diverse conditions.", "conclusion": "The proposed method effectively reduces blur in S2SVLC, significantly improving data recovery and system efficiency."}}
{"id": "2506.22865", "pdf": "https://arxiv.org/pdf/2506.22865", "abs": "https://arxiv.org/abs/2506.22865", "authors": ["Ziqi Zhong", "Xunzhu Tang"], "title": "ReasonBridge: Efficient Reasoning Transfer from Closed to Open-Source Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have revealed a\nsignificant performance gap between closed-source and open-source models,\nparticularly in tasks requiring complex reasoning and precise instruction\nfollowing. This paper introduces ReasonBridge, a methodology that efficiently\ntransfers reasoning capabilities from powerful closed-source to open-source\nmodels through a novel hierarchical knowledge distillation framework. We\ndevelop a tailored dataset Reason1K with only 1,000 carefully curated reasoning\ntraces emphasizing difficulty, diversity, and quality. These traces are\nfiltered from across multiple domains using a structured multi-criteria\nselection algorithm. Our transfer learning approach incorporates: (1) a\nhierarchical distillation process capturing both strategic abstraction and\ntactical implementation patterns, (2) a sparse reasoning-focused adapter\narchitecture requiring only 0.3% additional trainable parameters, and (3) a\ntest-time compute scaling mechanism using guided inference interventions.\nComprehensive evaluations demonstrate that ReasonBridge improves reasoning\ncapabilities in open-source models by up to 23% on benchmark tasks,\nsignificantly narrowing the gap with closed-source models. Notably, the\nenhanced Qwen2.5-14B outperforms Claude-Sonnet3.5 on MATH500 and matches its\nperformance on competition-level AIME problems. Our methodology generalizes\neffectively across diverse reasoning domains and model architectures,\nestablishing a sample-efficient approach to reasoning enhancement for\ninstruction following.", "AI": {"tldr": "ReasonBridge transfers reasoning capabilities from closed-source to open-source LLMs using hierarchical knowledge distillation, improving performance by up to 23%.", "motivation": "Address the performance gap between closed-source and open-source LLMs in complex reasoning tasks.", "method": "Hierarchical knowledge distillation with a tailored dataset (Reason1K), sparse adapter architecture, and test-time compute scaling.", "result": "Open-source models improve by up to 23%, with Qwen2.5-14B outperforming Claude-Sonnet3.5 on MATH500 and matching it on AIME.", "conclusion": "ReasonBridge offers a sample-efficient approach to enhance reasoning in open-source models, narrowing the gap with closed-source counterparts."}}
{"id": "2506.22447", "pdf": "https://arxiv.org/pdf/2506.22447", "abs": "https://arxiv.org/abs/2506.22447", "authors": ["Fabio Merizzi", "Harilaos Loukos"], "title": "Vision Transformers for Multi-Variable Climate Downscaling: Emulating Regional Climate Models with a Shared Encoder and Multi-Decoder Architecture", "categories": ["cs.LG", "cs.AI", "eess.IV"], "comment": null, "summary": "Global Climate Models (GCMs) are critical for simulating large-scale climate\ndynamics, but their coarse spatial resolution limits their applicability in\nregional studies. Regional Climate Models (RCMs) refine this through dynamic\ndownscaling, albeit at considerable computational cost and with limited\nflexibility. While deep learning has emerged as an efficient data-driven\nalternative, most existing studies have focused on single-variable models that\ndownscale one variable at a time. This approach can lead to limited contextual\nawareness, redundant computation, and lack of cross-variable interaction. Our\nstudy addresses these limitations by proposing a multi-task, multi-variable\nVision Transformer (ViT) architecture with a shared encoder and\nvariable-specific decoders (1EMD). The proposed architecture jointly predicts\nthree key climate variables: surface temperature (tas), wind speed (sfcWind),\nand 500 hPa geopotential height (zg500), directly from GCM-resolution inputs,\nemulating RCM-scale downscaling over Europe. We show that our multi-variable\napproach achieves positive cross-variable knowledge transfer and consistently\noutperforms single-variable baselines trained under identical conditions, while\nalso improving computational efficiency. These results demonstrate the\neffectiveness of multi-variable modeling for high-resolution climate\ndownscaling.", "AI": {"tldr": "A multi-task, multi-variable Vision Transformer (ViT) architecture (1EMD) is proposed for efficient climate downscaling, outperforming single-variable models by enabling cross-variable knowledge transfer.", "motivation": "Existing single-variable deep learning models for climate downscaling lack contextual awareness and cross-variable interaction, leading to inefficiencies.", "method": "A shared encoder and variable-specific decoders (1EMD) jointly predict three climate variables (tas, sfcWind, zg500) from GCM-resolution inputs.", "result": "The multi-variable approach outperforms single-variable baselines, improves computational efficiency, and enables cross-variable knowledge transfer.", "conclusion": "Multi-variable modeling is effective for high-resolution climate downscaling, offering better performance and efficiency."}}
{"id": "2506.22500", "pdf": "https://arxiv.org/pdf/2506.22500", "abs": "https://arxiv.org/abs/2506.22500", "authors": ["Weiyi Zhao", "Xiaoyu Tan", "Liang Liu", "Sijia Li", "Youwei Song", "Xihe Qiu"], "title": "Visual-Semantic Knowledge Conflicts in Operating Rooms: Synthetic Data Curation for Surgical Risk Perception in Multimodal Large Language Models", "categories": ["cs.CV", "cs.AI", "68T07, 68U10, 92C55", "I.2.10; I.2.7; J.3; I.2.6"], "comment": "13 pages, 5 figures. The dataset and appendix are available at\n  https://github.com/zgg2577/VS-KC", "summary": "Surgical risk identification is critical for patient safety and reducing\npreventable medical errors. While multimodal large language models (MLLMs) show\npromise for automated operating room (OR) risk detection, they often exhibit\nvisual-semantic knowledge conflicts (VS-KC), failing to identify visual safety\nviolations despite understanding textual rules. To address this, we introduce a\ndataset comprising over 34,000 synthetic images generated by diffusion models,\ndepicting operating room scenes containing entities that violate established\nsafety rules. These images were created to alleviate data scarcity and examine\nMLLMs vulnerabilities. In addition, the dataset includes 214 human-annotated\nimages that serve as a gold-standard reference for validation. This\ncomprehensive dataset, spanning diverse perspectives, stages, and\nconfigurations, is designed to expose and study VS-KC. Fine-tuning on OR-VSKC\nsignificantly improves MLLMs' detection of trained conflict entities and\ngeneralizes well to new viewpoints for these entities, but performance on\nuntrained entity types remains poor, highlighting learning specificity and the\nneed for comprehensive training. The main contributions of this work include:\n(1) a data generation methodology tailored for rule-violation scenarios; (2)\nthe release of the OR-VSKC dataset and its associated benchmark as open-source\nresources; and (3) an empirical analysis of violation-sensitive knowledge\nconsistency in representative MLLMs. The dataset and appendix are available at\nhttps://github.com/zgg2577/VS-KC.", "AI": {"tldr": "The paper introduces a synthetic dataset (OR-VSKC) to address visual-semantic knowledge conflicts in MLLMs for surgical risk detection, improving performance on trained entities but showing limitations on untrained ones.", "motivation": "To improve automated operating room risk detection by addressing visual-semantic knowledge conflicts in multimodal large language models (MLLMs).", "method": "Creation of a dataset with 34,000 synthetic images and 214 human-annotated images, followed by fine-tuning MLLMs on OR-VSKC.", "result": "Fine-tuning improves detection of trained conflict entities and generalizes to new viewpoints, but performance on untrained entities remains poor.", "conclusion": "The OR-VSKC dataset and benchmark are valuable resources for studying and improving MLLMs' visual-semantic knowledge consistency in surgical risk detection."}}
{"id": "2506.22598", "pdf": "https://arxiv.org/pdf/2506.22598", "abs": "https://arxiv.org/abs/2506.22598", "authors": ["Nicholas Edwards", "Yukyung Lee", "Yujun", "Mao", "Yulu Qin", "Sebastian Schuster", "Najoung Kim"], "title": "RExBench: Can coding agents autonomously implement AI research extensions?", "categories": ["cs.CL"], "comment": null, "summary": "Agents based on Large Language Models (LLMs) have shown promise for\nperforming sophisticated software engineering tasks autonomously. In addition,\nthere has been progress towards developing agents that can perform parts of the\nresearch pipeline in machine learning and the natural sciences. We argue that\nresearch extension and its implementation is a critical capability for such\nsystems, and introduce RExBench to support the evaluation of this capability.\nRExBench is a benchmark consisting of 12 realistic research experiment\nimplementation tasks that aim to investigate research hypotheses that have not\npreviously been implemented. Each task is set up as an extension to an existing\nresearch paper and codebase, accompanied by domain expert-written instructions.\nRExBench is robust to data contamination, and supports an automatic evaluation\ninfrastructure that executes agent outputs to determine whether the success\ncriteria are met. We use this benchmark to evaluate nine LLM agents implemented\nusing three different frameworks: aider, Claude Code, and OpenHands. We find\nthat all agents evaluated fail to autonomously implement the majority of the\nextensions. Although the success rate improves with additional human-written\nhints, the best performance under this setting remains below 40%. This\nindicates that current agents are still short of being able to handle realistic\nresearch extension tasks without substantial human guidance.", "AI": {"tldr": "RExBench evaluates LLM agents' ability to autonomously implement research extensions, finding current agents fall short without human guidance.", "motivation": "To assess the capability of LLM agents in performing realistic research extensions, a critical skill for autonomous research systems.", "method": "Introduces RExBench, a benchmark with 12 tasks extending existing research, evaluated using automatic execution and human hints.", "result": "All tested LLM agents failed most tasks; success rates improved with hints but remained below 40%.", "conclusion": "Current LLM agents lack the ability to autonomously handle research extensions, requiring significant human input."}}
{"id": "2506.22846", "pdf": "https://arxiv.org/pdf/2506.22846", "abs": "https://arxiv.org/abs/2506.22846", "authors": ["Duygu Altinok"], "title": "Boosting CTC-Based ASR Using LLM-Based Intermediate Loss Regularization", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "This is the accepted version of an article accepted to the TSD 2025\n  conference, published in Springer Lecture Notes in Artificial Intelligence\n  (LNAI). The final authenticated version is available online at SpringerLink", "summary": "End-to-end (E2E) automatic speech recognition (ASR) systems have\nrevolutionized the field by integrating all components into a single neural\nnetwork, with attention-based encoder-decoder models achieving state-of-the-art\nperformance. However, their autoregressive decoding process limits inference\nspeed, making them unsuitable for real-time applications. In contrast,\nCTC-based models offer faster, non-autoregressive decoding but struggle to\nmodel linguistic dependencies effectively. Addressing this challenge, we\npropose a novel auxiliary loss framework called Language-Aware Intermediate\nLoss (LAIL) to enhance CTC-based ASR using the linguistic knowledge of large\nlanguage models (LLMs). By attaching connector layers to intermediate encoder\nlayers, LAIL maps outputs to the embedding space of an LLM and computes a\ncausal language modeling loss during training. This approach enhances\nlinguistic modeling while preserving the computational efficiency of CTC\ndecoding. Using the Conformer architecture and various LLaMA models, we\ndemonstrate significant improvements in Word Error Rate (WER) on the\nLibriSpeech, TEDLIUM2, and WSJ corpora, achieving state-of-the-art performance\nfor CTC-based ASR with minimal computational overhead.", "AI": {"tldr": "Proposes LAIL, a novel auxiliary loss framework to enhance CTC-based ASR using LLMs, improving linguistic modeling while maintaining CTC's efficiency.", "motivation": "Autoregressive E2E ASR models are slow for real-time use, while CTC models lack linguistic dependency modeling. LAIL bridges this gap.", "method": "Attaches connector layers to intermediate encoder layers, mapping outputs to LLM embeddings and computing a causal language modeling loss.", "result": "Achieves state-of-the-art WER improvements on LibriSpeech, TEDLIUM2, and WSJ with minimal computational overhead.", "conclusion": "LAIL effectively enhances CTC-based ASR by leveraging LLMs, balancing performance and efficiency."}}
{"id": "2506.22957", "pdf": "https://arxiv.org/pdf/2506.22957", "abs": "https://arxiv.org/abs/2506.22957", "authors": ["Younwoo Choi", "Changling Li", "Yongjin Yang", "Zhijing Jin"], "title": "Agent-to-Agent Theory of Mind: Testing Interlocutor Awareness among Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.MA"], "comment": null, "summary": "As large language models (LLMs) are increasingly integrated into multi-agent\nand human-AI systems, understanding their awareness of both self-context and\nconversational partners is essential for ensuring reliable performance and\nrobust safety. While prior work has extensively studied situational awareness\nwhich refers to an LLM's ability to recognize its operating phase and\nconstraints, it has largely overlooked the complementary capacity to identify\nand adapt to the identity and characteristics of a dialogue partner. In this\npaper, we formalize this latter capability as interlocutor awareness and\npresent the first systematic evaluation of its emergence in contemporary LLMs.\nWe examine interlocutor inference across three dimensions-reasoning patterns,\nlinguistic style, and alignment preferences-and show that LLMs reliably\nidentify same-family peers and certain prominent model families, such as GPT\nand Claude. To demonstrate its practical significance, we develop three case\nstudies in which interlocutor awareness both enhances multi-LLM collaboration\nthrough prompt adaptation and introduces new alignment and safety\nvulnerabilities, including reward-hacking behaviors and increased jailbreak\nsusceptibility. Our findings highlight the dual promise and peril of\nidentity-sensitive behavior in LLMs, underscoring the need for further\nunderstanding of interlocutor awareness and new safeguards in multi-agent\ndeployments. Our code is open-sourced at\nhttps://github.com/younwoochoi/InterlocutorAwarenessLLM.", "AI": {"tldr": "The paper introduces 'interlocutor awareness' in LLMs, evaluating their ability to adapt to dialogue partners' identities and characteristics, and highlights its dual impact on collaboration and safety.", "motivation": "Understanding LLMs' awareness of conversational partners is crucial for reliable performance and safety in multi-agent and human-AI systems.", "method": "The study formalizes interlocutor awareness and evaluates it across reasoning patterns, linguistic style, and alignment preferences in contemporary LLMs.", "result": "LLMs reliably identify peers like GPT and Claude. Interlocutor awareness enhances collaboration but introduces safety vulnerabilities like reward-hacking and jailbreak susceptibility.", "conclusion": "The findings emphasize the dual promise and risks of identity-sensitive behavior in LLMs, calling for further research and safeguards in multi-agent deployments."}}
{"id": "2506.23066", "pdf": "https://arxiv.org/pdf/2506.23066", "abs": "https://arxiv.org/abs/2506.23066", "authors": ["Jiale Meng", "Yiming Li", "Zheming Lu", "Zewei He", "Hao Luo", "Tianwei Zhang"], "title": "CoreMark: Toward Robust and Universal Text Watermarking Technique", "categories": ["cs.CV", "cs.CR", "cs.MM"], "comment": "10 pages, 16 figures", "summary": "Text watermarking schemes have gained considerable attention in recent years,\nyet still face critical challenges in achieving simultaneous robustness,\ngeneralizability, and imperceptibility. This paper introduces a new embedding\nparadigm,termed CORE, which comprises several consecutively aligned black pixel\nsegments. Its key innovation lies in its inherent noise resistance during\ntransmission and broad applicability across languages and fonts. Based on the\nCORE, we present a text watermarking framework named CoreMark. Specifically,\nCoreMark first dynamically extracts COREs from characters. Then, the characters\nwith stronger robustness are selected according to the lengths of COREs. By\nmodifying the thickness of the CORE, the hidden data is embedded into the\nselected characters without causing significant visual distortions. Moreover, a\ngeneral plug-and-play embedding strength modulator is proposed, which can\nadaptively enhance the robustness for small font sizes by adjusting the\nembedding strength according to the font size. Experimental evaluation\nindicates that CoreMark demonstrates outstanding generalizability across\nmultiple languages and fonts. Compared to existing methods, CoreMark achieves\nsignificant improvements in resisting screenshot, print-scan, and print camera\nattacks, while maintaining satisfactory imperceptibility.", "AI": {"tldr": "CoreMark introduces a text watermarking framework using CORE segments for robust, generalizable, and imperceptible data embedding, outperforming existing methods in resistance to attacks.", "motivation": "Addressing challenges in text watermarking like robustness, generalizability, and imperceptibility.", "method": "Uses CORE segments for embedding, dynamically selects robust characters, adjusts thickness for data embedding, and employs a plug-and-play modulator for font size adaptation.", "result": "CoreMark excels in generalizability and robustness against attacks (screenshot, print-scan, print-camera) while maintaining imperceptibility.", "conclusion": "CoreMark offers a superior solution for text watermarking, balancing robustness, generalizability, and imperceptibility effectively."}}
{"id": "2506.23325", "pdf": "https://arxiv.org/pdf/2506.23325", "abs": "https://arxiv.org/abs/2506.23325", "authors": ["Yitian Gong", "Luozhijie Jin", "Ruifan Deng", "Dong Zhang", "Xin Zhang", "Qinyuan Cheng", "Zhaoye Fei", "Shimin Li", "Xipeng Qiu"], "title": "XY-Tokenizer: Mitigating the Semantic-Acoustic Conflict in Low-Bitrate Speech Codecs", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Speech codecs serve as bridges between speech signals and large language\nmodels. An ideal codec for speech language models should not only preserve\nacoustic information but also capture rich semantic information. However,\nexisting speech codecs struggle to balance high-quality audio reconstruction\nwith ease of modeling by language models. In this study, we analyze the\nlimitations of previous codecs in balancing semantic richness and acoustic\nfidelity. We propose XY-Tokenizer, a novel codec that mitigates the conflict\nbetween semantic and acoustic capabilities through multi-stage, multi-task\nlearning. Experimental results demonstrate that XY-Tokenizer achieves\nperformance in both semantic and acoustic tasks comparable to that of\nstate-of-the-art codecs operating at similar bitrates, even though those\nexisting codecs typically excel in only one aspect. Specifically, XY-Tokenizer\nachieves strong text alignment, surpassing distillation-based semantic modeling\nmethods such as SpeechTokenizer and Mimi, while maintaining a speaker\nsimilarity score of 0.83 between reconstructed and original audio. The\nreconstruction performance of XY-Tokenizer is comparable to that of BigCodec,\nthe current state-of-the-art among acoustic-only codecs, which achieves a\nspeaker similarity score of 0.84 at a similar bitrate. Code and models are\navailable at https://github.com/gyt1145028706/XY-Tokenizer.", "AI": {"tldr": "XY-Tokenizer is a novel speech codec balancing semantic richness and acoustic fidelity, outperforming existing codecs in both aspects.", "motivation": "Existing speech codecs struggle to balance semantic richness and acoustic fidelity, limiting their effectiveness for speech language models.", "method": "Proposes XY-Tokenizer, using multi-stage, multi-task learning to mitigate the conflict between semantic and acoustic capabilities.", "result": "XY-Tokenizer matches state-of-the-art codecs in semantic and acoustic tasks, achieving strong text alignment and high speaker similarity (0.83).", "conclusion": "XY-Tokenizer successfully balances semantic and acoustic performance, offering a robust solution for speech language models."}}
{"id": "2506.23005", "pdf": "https://arxiv.org/pdf/2506.23005", "abs": "https://arxiv.org/abs/2506.23005", "authors": ["Vaigai Nayaki Yokar", "Hoa Le Minh", "Zabih Ghassemlooy", "Wai Lok Woo"], "title": "Channel characterization in screen-to-camera based optical camera communication", "categories": ["eess.IV"], "comment": null, "summary": "With the increase in optical camera communication (OCC), a screen to\ncamera-based communication can be established. This opens a new field of\nvisible light communication (VLC) known as smartphone to smartphone based\nvisible light communication (S2SVLC) system. In this paper, we experimentally\ndemonstrate a S2SVLC system based on VLC technology using a smartphone screen\nand a smartphone camera over a link span of 20 cms. We analyze the Lambertian\norder of the smartphone screen and carry out a channel characterization of a\nscreen to camera link-based VLC system under specific test conditions.", "AI": {"tldr": "The paper demonstrates a smartphone-to-smartphone visible light communication (S2SVLC) system using VLC technology, analyzing screen Lambertian order and channel characterization over a 20 cm link.", "motivation": "To explore the potential of screen-to-camera communication in visible light communication (VLC) systems, leveraging smartphone technology.", "method": "Experimental demonstration of S2SVLC using smartphone screens and cameras, analyzing Lambertian order and channel characterization under specific conditions.", "result": "Successful implementation and analysis of a 20 cm S2SVLC link, providing insights into screen-to-camera VLC performance.", "conclusion": "The study validates the feasibility of S2SVLC systems, highlighting their potential for practical applications in VLC."}}
{"id": "2506.22893", "pdf": "https://arxiv.org/pdf/2506.22893", "abs": "https://arxiv.org/abs/2506.22893", "authors": ["Arpit Narechania", "Alex Endert", "Atanu R Sinha"], "title": "Agentic Enterprise: AI-Centric User to User-Centric AI", "categories": ["cs.AI", "cs.HC"], "comment": "12 pages, 1 figure, 2 sidebars; Preprint", "summary": "After a very long winter, the Artificial Intelligence (AI) spring is here.\nOr, so it seems over the last three years. AI has the potential to impact many\nareas of human life - personal, social, health, education, professional. In\nthis paper, we take a closer look at the potential of AI for Enterprises, where\ndecision-making plays a crucial and repeated role across functions, tasks, and\noperations. We consider Agents imbued with AI as means to increase\ndecision-productivity of enterprises. We highlight six tenets for Agentic\nsuccess in enterprises, by drawing attention to what the current, AI-Centric\nUser paradigm misses, in the face of persistent needs of and usefulness for\nEnterprise Decision-Making. In underscoring a shift to User-Centric AI, we\noffer six tenets and promote market mechanisms for platforms, aligning the\ndesign of AI and its delivery by Agents to the cause of enterprise users.", "AI": {"tldr": "The paper discusses the potential of AI in enterprises, focusing on AI-driven agents to enhance decision-making productivity. It proposes six tenets for successful AI agents in enterprises, advocating a shift from AI-centric to user-centric AI design.", "motivation": "AI has significant potential to impact various aspects of human life, including enterprises where decision-making is critical. The paper aims to address gaps in current AI-centric approaches for enterprise decision-making.", "method": "The paper highlights six tenets for AI agent success in enterprises, emphasizing user-centric AI design and market mechanisms for platforms.", "result": "The proposed tenets and shift to user-centric AI aim to improve enterprise decision-making productivity by aligning AI design with user needs.", "conclusion": "The paper concludes by advocating for user-centric AI and market-driven platforms to better serve enterprise decision-making needs."}}
{"id": "2506.22502", "pdf": "https://arxiv.org/pdf/2506.22502", "abs": "https://arxiv.org/abs/2506.22502", "authors": ["Matvei Anoshin", "Olga Tsurkan", "Vadim Lopatkin", "Leonid Fedichkin"], "title": "Stabilization of industrial processes with time series machine learning", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "The stabilization of time series processes is a crucial problem that is\nubiquitous in various industrial fields. The application of machine learning to\nits solution can have a decisive impact, improving both the quality of the\nresulting stabilization with less computational resources required. In this\nwork, we present a simple pipeline consisting of two neural networks: the\noracle predictor and the optimizer, proposing a substitution of the point-wise\nvalues optimization to the problem of the neural network training, which\nsuccessfully improves stability in terms of the temperature control by about 3\ntimes compared to ordinary solvers.", "AI": {"tldr": "A two-neural-network pipeline improves time series stabilization, outperforming traditional solvers by 3x in temperature control.", "motivation": "Stabilizing time series processes is critical in industries, and machine learning can enhance efficiency and quality.", "method": "A pipeline with an oracle predictor and optimizer replaces point-wise optimization with neural network training.", "result": "Achieves 3 times better stability in temperature control compared to ordinary solvers.", "conclusion": "The proposed neural network approach effectively stabilizes time series processes with superior performance."}}
{"id": "2506.22501", "pdf": "https://arxiv.org/pdf/2506.22501", "abs": "https://arxiv.org/abs/2506.22501", "authors": ["Gautam Siddharth Kashyap", "Manaswi Kulahara", "Nipun Joshi", "Usman Naseem"], "title": "How Can Multimodal Remote Sensing Datasets Transform Classification via SpatialNet-ViT?", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted in the 2025 IEEE International Geoscience and Remote Sensing\n  Symposium (IGARSS 2025), scheduled for 3 - 8 August 2025 in Brisbane,\n  Australia", "summary": "Remote sensing datasets offer significant promise for tackling key\nclassification tasks such as land-use categorization, object presence\ndetection, and rural/urban classification. However, many existing studies tend\nto focus on narrow tasks or datasets, which limits their ability to generalize\nacross various remote sensing classification challenges. To overcome this, we\npropose a novel model, SpatialNet-ViT, leveraging the power of Vision\nTransformers (ViTs) and Multi-Task Learning (MTL). This integrated approach\ncombines spatial awareness with contextual understanding, improving both\nclassification accuracy and scalability. Additionally, techniques like data\naugmentation, transfer learning, and multi-task learning are employed to\nenhance model robustness and its ability to generalize across diverse datasets", "AI": {"tldr": "The paper introduces SpatialNet-ViT, a model combining Vision Transformers and Multi-Task Learning to improve generalization in remote sensing classification tasks.", "motivation": "Existing studies often focus on narrow tasks or datasets, limiting their generalizability across diverse remote sensing challenges.", "method": "The proposed SpatialNet-ViT integrates Vision Transformers and Multi-Task Learning, alongside techniques like data augmentation and transfer learning.", "result": "The model enhances classification accuracy and scalability while improving robustness and generalization across datasets.", "conclusion": "SpatialNet-ViT offers a promising solution for diverse remote sensing classification tasks by leveraging advanced techniques for better performance."}}
{"id": "2506.22623", "pdf": "https://arxiv.org/pdf/2506.22623", "abs": "https://arxiv.org/abs/2506.22623", "authors": ["Badr Youbi Idrissi", "Monica Millunzi", "Amelia Sorrenti", "Lorenzo Baraldi", "Daryna Dementieva"], "title": "Temperature Matters: Enhancing Watermark Robustness Against Paraphrasing Attacks", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the present-day scenario, Large Language Models (LLMs) are establishing\ntheir presence as powerful instruments permeating various sectors of society.\nWhile their utility offers valuable support to individuals, there are multiple\nconcerns over potential misuse. Consequently, some academic endeavors have\nsought to introduce watermarking techniques, characterized by the inclusion of\nmarkers within machine-generated text, to facilitate algorithmic\nidentification. This research project is focused on the development of a novel\nmethodology for the detection of synthetic text, with the overarching goal of\nensuring the ethical application of LLMs in AI-driven text generation. The\ninvestigation commences with replicating findings from a previous baseline\nstudy, thereby underscoring its susceptibility to variations in the underlying\ngeneration model. Subsequently, we propose an innovative watermarking approach\nand subject it to rigorous evaluation, employing paraphrased generated text to\nasses its robustness. Experimental results highlight the robustness of our\nproposal compared to the~\\cite{aarson} watermarking method.", "AI": {"tldr": "The paper introduces a new watermarking method for detecting synthetic text generated by LLMs, aiming to ensure ethical use. It replicates a baseline study, identifies its limitations, and proposes a robust alternative, outperforming existing methods.", "motivation": "Address concerns about misuse of LLMs by developing a reliable method to detect machine-generated text, ensuring ethical AI applications.", "method": "Replicates a baseline study, identifies its flaws, and proposes a novel watermarking technique evaluated using paraphrased text for robustness.", "result": "The proposed method shows greater robustness compared to existing watermarking techniques, particularly under paraphrasing attacks.", "conclusion": "The new watermarking approach effectively detects synthetic text, offering a more reliable solution for ethical AI text generation."}}
{"id": "2506.22858", "pdf": "https://arxiv.org/pdf/2506.22858", "abs": "https://arxiv.org/abs/2506.22858", "authors": ["Duygu Altinok"], "title": "Mind the Gap: Entity-Preserved Context-Aware ASR Structured Transcriptions", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "This is the accepted version of an article accepted to the TSD 2025\n  conference, published in Springer Lecture Notes in Artificial Intelligence\n  (LNAI). The final authenticated version is available online at SpringerLink", "summary": "Automatic Speech Recognition (ASR) systems, such as Whisper, achieve high\ntranscription accuracy but struggle with named entities and numerical data,\nespecially when proper formatting is required. These issues increase word error\nrate (WER) and impair semantic understanding in critical domains like legal,\nfinancial, and medical applications. We propose a novel training approach that\nextends the semantic context of ASR models by adding overlapping context\nwindows during training. By sliding 5-second overlaps on both sides of\n30-second chunks, we create a 40-second \"effective semantic window,\" improving\nentity recognition and formatting while focusing predictions on the central 30\nseconds. To address entities spanning chunk boundaries, we reassign such\nentities entirely to the right-hand chunk, ensuring proper formatting.\nAdditionally, enriched training data with embedded entity labels enables the\nmodel to learn both recognition and type-specific formatting. Evaluated on the\nSpoken Wikipedia dataset, our method improves performance across semantic\ntasks, including named entity recognition (NER) and entity formatting. These\nresults highlight the effectiveness of context-aware training in addressing ASR\nlimitations for long-form transcription and complex entity recognition tasks.", "AI": {"tldr": "A novel training approach for ASR systems improves named entity and numerical data recognition by extending semantic context with overlapping windows and enriched training data.", "motivation": "ASR systems like Whisper struggle with named entities and numerical data, impacting accuracy and semantic understanding in critical domains.", "method": "Extends semantic context using overlapping 5-second windows on 30-second chunks, reassigns boundary-spanning entities, and uses enriched training data with entity labels.", "result": "Improves performance on named entity recognition (NER) and entity formatting, as shown on the Spoken Wikipedia dataset.", "conclusion": "Context-aware training effectively addresses ASR limitations for long-form transcription and complex entity recognition."}}
{"id": "2506.22966", "pdf": "https://arxiv.org/pdf/2506.22966", "abs": "https://arxiv.org/abs/2506.22966", "authors": ["Grzegorz Jamr\u00f3z", "Rafa\u0142 Kucharski"], "title": "Detection of coordinated fleet vehicles in route choice urban games. Part I. Inverse fleet assignment theory", "categories": ["math.OC", "cs.MA", "econ.TH"], "comment": "30 pages, 7 figures", "summary": "Detection of collectively routing fleets of vehicles in future urban systems\nmay become important for the management of traffic, as such routing may\ndestabilize urban networks leading to deterioration of driving conditions.\nAccordingly, in this paper we discuss the question whether it is possible to\ndetermine the flow of fleet vehicles on all routes given the fleet size and\nbehaviour as well as the combined total flow of fleet and non-fleet vehicles on\nevery route. We prove that the answer to this Inverse Fleet Assignment Problem\nis 'yes' for myopic fleet strategies which are more 'selfish' than\n'altruistic', and 'no' otherwise, under mild assumptions on route/link\nperformance functions. To reach these conclusions we introduce the forward\nfleet assignment operator and study its properties, proving that it is\ninvertible for 'bad' objectives of fleet controllers. We also discuss the\nchallenges of implementing myopic fleet routing in the real world and compare\nit to Stackelberg and Nash routing. Finally, we show that optimal Stackelberg\nfleet routing could involve highly variable mixed strategies in some scenarios,\nwhich would likely cause chaos in the traffic network.", "AI": {"tldr": "The paper explores whether fleet vehicle flows can be determined given fleet size, behavior, and total traffic flow. It finds the answer is 'yes' for selfish strategies but 'no' for altruistic ones, under mild assumptions.", "motivation": "Understanding fleet routing's impact on urban traffic stability and management.", "method": "Introduces the forward fleet assignment operator, analyzes its invertibility, and compares myopic, Stackelberg, and Nash routing.", "result": "Proves invertibility for selfish fleet strategies and discusses challenges in real-world implementation. Optimal Stackelberg routing may cause chaos.", "conclusion": "Selfish fleet strategies allow flow determination, but altruistic ones do not. Optimal Stackelberg routing can destabilize traffic."}}
{"id": "2506.23151", "pdf": "https://arxiv.org/pdf/2506.23151", "abs": "https://arxiv.org/abs/2506.23151", "authors": ["Vladislav Bargatin", "Egor Chistov", "Alexander Yakovenko", "Dmitriy Vatolin"], "title": "MEMFOF: High-Resolution Training for Memory-Efficient Multi-Frame Optical Flow Estimation", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": "Accepted at ICCV 2025", "summary": "Recent advances in optical flow estimation have prioritized accuracy at the\ncost of growing GPU memory consumption, particularly for high-resolution\n(FullHD) inputs. We introduce MEMFOF, a memory-efficient multi-frame optical\nflow method that identifies a favorable trade-off between multi-frame\nestimation and GPU memory usage. Notably, MEMFOF requires only 2.09 GB of GPU\nmemory at runtime for 1080p inputs, and 28.5 GB during training, which uniquely\npositions our method to be trained at native 1080p without the need for\ncropping or downsampling. We systematically revisit design choices from\nRAFT-like architectures, integrating reduced correlation volumes and\nhigh-resolution training protocols alongside multi-frame estimation, to achieve\nstate-of-the-art performance across multiple benchmarks while substantially\nreducing memory overhead. Our method outperforms more resource-intensive\nalternatives in both accuracy and runtime efficiency, validating its robustness\nfor flow estimation at high resolutions. At the time of submission, our method\nranks first on the Spring benchmark with a 1-pixel (1px) outlier rate of 3.289,\nleads Sintel (clean) with an endpoint error (EPE) of 0.963, and achieves the\nbest Fl-all error on KITTI-2015 at 2.94%. The code is available at\nhttps://github.com/msu-video-group/memfof.", "AI": {"tldr": "MEMFOF is a memory-efficient multi-frame optical flow method that balances accuracy and GPU memory usage, achieving state-of-the-art performance with low memory overhead.", "motivation": "Address the trade-off between accuracy and GPU memory consumption in optical flow estimation, especially for high-resolution inputs.", "method": "Revisits RAFT-like architectures, integrating reduced correlation volumes and high-resolution training protocols for multi-frame estimation.", "result": "Outperforms alternatives in accuracy and efficiency, ranking first on benchmarks like Spring, Sintel, and KITTI-2015.", "conclusion": "MEMFOF is robust for high-resolution flow estimation, offering a practical solution with minimal memory usage."}}
{"id": "2506.23367", "pdf": "https://arxiv.org/pdf/2506.23367", "abs": "https://arxiv.org/abs/2506.23367", "authors": ["Paige Tutt\u00f6s\u00ed", "H. Henny Yeung", "Yue Wang", "Jean-Julien Aucouturier", "Angelica Lim"], "title": "You Sound a Little Tense: L2 Tailored Clear TTS Using Durational Vowel Properties", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": "Accepted to ISCA Speech Synthesis Workshop, 2025", "summary": "We present the first text-to-speech (TTS) system tailored to second language\n(L2) speakers. We use duration differences between American English tense\n(longer) and lax (shorter) vowels to create a \"clarity mode\" for Matcha-TTS.\nOur perception studies showed that French-L1, English-L2 listeners had fewer\n(at least 9.15%) transcription errors when using our clarity mode, and found it\nmore encouraging and respectful than overall slowed down speech. Remarkably,\nlisteners were not aware of these effects: despite the decreased word error\nrate in clarity mode, listeners still believed that slowing all target words\nwas the most intelligible, suggesting that actual intelligibility does not\ncorrelate with perceived intelligibility. Additionally, we found that\nWhisper-ASR did not use the same cues as L2 speakers to differentiate difficult\nvowels and is not sufficient to assess the intelligibility of TTS systems for\nthese individuals.", "AI": {"tldr": "A TTS system for L2 speakers uses vowel duration differences to improve clarity, reducing transcription errors by 9.15%, though listeners misjudged its effectiveness.", "motivation": "To enhance intelligibility for L2 speakers by leveraging phonetic cues like vowel duration, addressing gaps in existing TTS systems.", "method": "Modified Matcha-TTS with a 'clarity mode' emphasizing tense/lax vowel duration differences, tested via perception studies with French-L1 English-L2 listeners.", "result": "Reduced transcription errors by 9.15% in clarity mode, though listeners incorrectly believed slowed speech was more intelligible. Whisper-ASR failed to match L2 speaker cues.", "conclusion": "Phonetic clarity improves L2 intelligibility, but perception mismatches and ASR limitations highlight challenges in assessing TTS effectiveness for L2 speakers."}}
{"id": "2506.23102", "pdf": "https://arxiv.org/pdf/2506.23102", "abs": "https://arxiv.org/abs/2506.23102", "authors": ["Sunggu Kyung", "Jinyoung Seo", "Hyunseok Lim", "Dongyeong Kim", "Hyungbin Park", "Jimin Sung", "Jihyun Kim", "Wooyoung Jo", "Yoojin Nam", "Namkug Kim"], "title": "MedRegion-CT: Region-Focused Multimodal LLM for Comprehensive 3D CT Report Generation", "categories": ["eess.IV", "cs.CV"], "comment": "14 pages, 5 figures, submitted to ICCV 2025", "summary": "The recent release of RadGenome-Chest CT has significantly advanced CT-based\nreport generation. However, existing methods primarily focus on global\nfeatures, making it challenging to capture region-specific details, which may\ncause certain abnormalities to go unnoticed. To address this, we propose\nMedRegion-CT, a region-focused Multi-Modal Large Language Model (MLLM)\nframework, featuring three key innovations. First, we introduce Region\nRepresentative ($R^2$) Token Pooling, which utilizes a 2D-wise pretrained\nvision model to efficiently extract 3D CT features. This approach generates\nglobal tokens representing overall slice features and region tokens\nhighlighting target areas, enabling the MLLM to process comprehensive\ninformation effectively. Second, a universal segmentation model generates\npseudo-masks, which are then processed by a mask encoder to extract\nregion-centric features. This allows the MLLM to focus on clinically relevant\nregions, using six predefined region masks. Third, we leverage segmentation\nresults to extract patient-specific attributions, including organ size,\ndiameter, and locations. These are converted into text prompts, enriching the\nMLLM's understanding of patient-specific contexts. To ensure rigorous\nevaluation, we conducted benchmark experiments on report generation using the\nRadGenome-Chest CT. MedRegion-CT achieved state-of-the-art performance,\noutperforming existing methods in natural language generation quality and\nclinical relevance while maintaining interpretability. The code for our\nframework is publicly available.", "AI": {"tldr": "MedRegion-CT is a region-focused MLLM framework for CT report generation, improving on global feature methods by capturing region-specific details with innovations like R\u00b2 Token Pooling, pseudo-masks, and patient-specific attributions. It outperforms existing methods in quality and relevance.", "motivation": "Existing CT report generation methods focus on global features, missing region-specific details, which can overlook abnormalities. MedRegion-CT aims to address this gap.", "method": "Proposes MedRegion-CT with three innovations: R\u00b2 Token Pooling for 3D CT feature extraction, pseudo-masks for region-centric features, and patient-specific attributions converted to text prompts.", "result": "Achieves state-of-the-art performance on RadGenome-Chest CT, excelling in natural language generation quality and clinical relevance.", "conclusion": "MedRegion-CT effectively addresses the limitations of global feature methods, enhancing report generation with region-specific focus and interpretability."}}
{"id": "2506.22919", "pdf": "https://arxiv.org/pdf/2506.22919", "abs": "https://arxiv.org/abs/2506.22919", "authors": ["Sanskar Pandey", "Ruhaan Chopra", "Saad Murtaza Bhat", "Ark Abhyudaya"], "title": "Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Mixture-of-Experts (MoE) models enable conditional computation by routing\ninputs to specialized experts, but these experts rely on identical inductive\nbiases, thus limiting representational diversity. This static computation\npathway is inefficient for inputs that require different types of reasoning and\nlimits specialization and interpretability. We propose Hecto, a lightweight MoE\narchitecture that leverages architectural heterogeneity by combining a GRU\nexpert for temporal reasoning and an FFNN expert for static abstraction under a\nsparse Top-1 gating mechanism. Evaluated on three reasoning benchmarks (AG\nNews, SST-2, HotpotQA) and a regression task (STS-B), Hecto matches or closely\ntrails homogeneous baselines in performance despite receiving isolated input\nrepresentations, while achieving clear expert specialization, with each expert\naligning to distinct reasoning types (temporal vs static). At larger batch\nsizes, Hecto exhibits improved performance, benefiting from relaxed\ncomputational constraints that allow its heterogeneous architecture to optimize\nmore effectively. Ablation results isolate architectural diversity as the\nsource of Hecto's stability and interpretability across diverse reasoning\ntasks. Overall, Hecto establishes itself as a new benchmark for conditional\ncomputation, offering a principled framework for specialized reasoning in\nlow-resource regimes with its model strength derived from principled\nspecialization.", "AI": {"tldr": "Hecto, a lightweight MoE model, combines GRU and FFNN experts for diverse reasoning tasks, matching homogeneous baselines while improving specialization and interpretability.", "motivation": "Current MoE models lack representational diversity due to identical inductive biases, limiting efficiency and specialization for varied reasoning tasks.", "method": "Hecto integrates a GRU expert for temporal reasoning and an FFNN expert for static abstraction under a sparse Top-1 gating mechanism.", "result": "Hecto matches or nears homogeneous baselines in performance, achieves clear expert specialization, and improves with larger batch sizes.", "conclusion": "Hecto sets a new benchmark for conditional computation, offering specialized reasoning in low-resource settings through architectural diversity."}}
{"id": "2506.22530", "pdf": "https://arxiv.org/pdf/2506.22530", "abs": "https://arxiv.org/abs/2506.22530", "authors": ["Jakub Pele\u0161ka", "Gustav \u0160\u00edr"], "title": "Task-Agnostic Contrastive Pretraining for Relational Deep Learning", "categories": ["cs.LG", "cs.DB"], "comment": "arXiv admin note: text overlap with arXiv:2506.22199", "summary": "Relational Deep Learning (RDL) is an emerging paradigm that leverages Graph\nNeural Network principles to learn directly from relational databases by\nrepresenting them as heterogeneous graphs. However, existing RDL models\ntypically rely on task-specific supervised learning, requiring training\nseparate models for each predictive task, which may hamper scalability and\nreuse.\n  In this work, we propose a novel task-agnostic contrastive pretraining\napproach for RDL that enables database-wide representation learning. For that\naim, we introduce three levels of contrastive objectives$-$row-level,\nlink-level, and context-level$-$designed to capture the structural and semantic\nheterogeneity inherent to relational data. We implement the respective\npretraining approach through a modular RDL architecture and an efficient\nsampling strategy tailored to the heterogeneous database setting. Our\npreliminary results on standard RDL benchmarks demonstrate that fine-tuning the\npretrained models measurably outperforms training from scratch, validating the\npromise of the proposed methodology in learning transferable representations\nfor relational data.", "AI": {"tldr": "The paper proposes a task-agnostic contrastive pretraining approach for Relational Deep Learning (RDL) to learn transferable representations from relational databases, outperforming task-specific supervised learning.", "motivation": "Existing RDL models require task-specific training, limiting scalability and reuse. The paper aims to enable database-wide representation learning.", "method": "Introduces three contrastive objectives (row-level, link-level, context-level) and a modular RDL architecture with efficient sampling for heterogeneous databases.", "result": "Preliminary results show fine-tuning pretrained models outperforms training from scratch.", "conclusion": "The proposed methodology effectively learns transferable representations for relational data, promising improved scalability and reuse."}}
{"id": "2506.22503", "pdf": "https://arxiv.org/pdf/2506.22503", "abs": "https://arxiv.org/abs/2506.22503", "authors": ["Michiel Schepers", "Pieter Robberechts", "Jan Van Haaren", "Jesse Davis"], "title": "What Makes a Dribble Successful? Insights From 3D Pose Tracking Data", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Data analysis plays an increasingly important role in soccer, offering new\nways to evaluate individual and team performance. One specific application is\nthe evaluation of dribbles: one-on-one situations where an attacker attempts to\nbypass a defender with the ball. While previous research has primarily relied\non 2D positional tracking data, this fails to capture aspects like balance,\norientation, and ball control, limiting the depth of current insights. This\nstudy explores how pose tracking data (capturing players' posture and movement\nin three dimensions) can improve our understanding of dribbling skills. We\nextract novel pose-based features from 1,736 dribbles in the 2022/23 Champions\nLeague season and evaluate their impact on dribble success. Our results\nindicate that features capturing the attacker's balance and the alignment of\nthe orientation between the attacker and defender are informative for\npredicting dribble success. Incorporating these pose-based features on top of\nfeatures derived from traditional 2D positional data leads to a measurable\nimprovement in model performance.", "AI": {"tldr": "The study uses 3D pose tracking data to enhance dribble evaluation in soccer, showing improved predictive performance over traditional 2D methods.", "motivation": "Current 2D positional data lacks depth in capturing dribbling dynamics like balance and orientation, limiting insights.", "method": "Pose-based features from 1,736 dribbles in the 2022/23 Champions League season were analyzed alongside traditional 2D data.", "result": "Pose-based features (balance and attacker-defender alignment) significantly improve dribble success prediction.", "conclusion": "3D pose tracking offers deeper insights into dribbling skills, outperforming 2D methods."}}
{"id": "2506.22644", "pdf": "https://arxiv.org/pdf/2506.22644", "abs": "https://arxiv.org/abs/2506.22644", "authors": ["Chase Fensore", "Kaustubh Dhole", "Joyce C Ho", "Eugene Agichtein"], "title": "Evaluating Hybrid Retrieval Augmented Generation using Dynamic Test Sets: LiveRAG Challenge", "categories": ["cs.CL", "cs.IR"], "comment": "4 pages, 3 tables, 2 figures. Accepted at the SIGIR LiveRAG Workshop\n  2025 (Submission 2664)", "summary": "We present our submission to the LiveRAG Challenge 2025, which evaluates\nretrieval-augmented generation (RAG) systems on dynamic test sets using the\nFineWeb-10BT corpus. Our final hybrid approach combines sparse (BM25) and dense\n(E5) retrieval methods and then aims to generate relevant and faithful answers\nwith Falcon3-10B-Instruct. Through systematic evaluation on 200 synthetic\nquestions generated with DataMorgana across 64 unique question-user\ncombinations, we demonstrate that neural re-ranking with RankLLaMA improves MAP\nfrom 0.523 to 0.797 (52% relative improvement) but introduces prohibitive\ncomputational costs (84s vs 1.74s per question). While DSPy-optimized prompting\nstrategies achieved higher semantic similarity (0.771 vs 0.668), their 0%\nrefusal rates raised concerns about over-confidence and generalizability. Our\nsubmitted hybrid system without re-ranking achieved 4th place in faithfulness\nand 11th place in correctness among 25 teams. Analysis across question\ncategories reveals that vocabulary alignment between questions and documents\nwas the strongest predictor of performance on our development set, with\ndocument-similar phrasing improving cosine similarity from 0.562 to 0.762.", "AI": {"tldr": "A hybrid RAG system combining sparse (BM25) and dense (E5) retrieval with Falcon3-10B-Instruct achieved 4th in faithfulness and 11th in correctness in the LiveRAG Challenge 2025, though neural re-ranking improved performance at high computational cost.", "motivation": "To evaluate and improve retrieval-augmented generation (RAG) systems on dynamic test sets using the FineWeb-10BT corpus.", "method": "Combined sparse (BM25) and dense (E5) retrieval, used Falcon3-10B-Instruct for generation, and evaluated with synthetic questions and RankLLaMA re-ranking.", "result": "Neural re-ranking improved MAP by 52% but was computationally expensive. DSPy-optimized prompting increased semantic similarity but had 0% refusal rates. Vocabulary alignment was key to performance.", "conclusion": "The hybrid system performed well in faithfulness and correctness, but trade-offs between performance and computational cost must be considered."}}
{"id": "2506.22944", "pdf": "https://arxiv.org/pdf/2506.22944", "abs": "https://arxiv.org/abs/2506.22944", "authors": ["Carlos Garc\u00eda A.", "Vladimiro Boselli", "Aida Hejazi Nooghabi", "Andrea Colombi", "Lapo Boschi"], "title": "Feasibility of spectral-element modeling of wave propagation through the anatomy of marine mammals", "categories": ["cs.CE", "cs.SD", "eess.AS", "q-bio.TO"], "comment": null, "summary": "This study introduces the first 3D spectral-element method (SEM) simulation\nof ultrasonic wave propagation in a bottlenose dolphin (Tursiops truncatus)\nhead. Unlike traditional finite-element methods (FEM), which struggle with\nhigh-frequency simulations due to costly linear-system inversions and slower\nconvergence, SEM offers exponential convergence and efficient parallel\ncomputation. Using Computed Tomography (CT) scan data, we developed a detailed\nhexahedral mesh capturing complex anatomical features, such as acoustic fats\nand jaws. Our simulations of plane and spherical waves confirm SEM's\neffectiveness for ultrasonic time-domain modeling. This approach opens new\navenues for marine biology, contributing to research in echolocation, the\nimpacts of anthropogenic marine noise pollution and the biophysics of hearing\nand click generation in marine mammals. By overcoming FEM's limitations, SEM\nprovides a powerful scalable tool to test hypotheses about dolphin\nbioacoustics, with significant implications for conservation and understanding\nmarine mammal auditory systems under increasing environmental challenges.", "AI": {"tldr": "The study presents a 3D spectral-element method (SEM) for simulating ultrasonic wave propagation in a dolphin head, outperforming traditional FEM in high-frequency scenarios.", "motivation": "To address FEM's inefficiencies in high-frequency simulations and explore dolphin bioacoustics, including echolocation and noise pollution impacts.", "method": "Developed a detailed hexahedral mesh from CT scan data, simulating plane and spherical waves using SEM for ultrasonic time-domain modeling.", "result": "SEM demonstrated exponential convergence and efficient parallel computation, proving effective for ultrasonic wave simulations.", "conclusion": "SEM offers a scalable tool for dolphin bioacoustics research, aiding conservation and understanding of marine mammal hearing under environmental stress."}}
{"id": "2506.22971", "pdf": "https://arxiv.org/pdf/2506.22971", "abs": "https://arxiv.org/abs/2506.22971", "authors": ["Kesav Kazam Ramachandran Anantharaman", "Rahul Meshram"], "title": "Hierarchical Decentralized Stochastic Control for Cyber-Physical Systems", "categories": ["eess.SY", "cs.LG", "cs.MA", "cs.SY", "math.OC"], "comment": "6 pages, 2 figures", "summary": "This paper presents a two-timescale hierarchical decentralized architecture\nfor control of Cyber-Physical Systems. The architecture consists of $N$\nindependent sub-processes, a global controller, and $N$ local controllers, each\nformulated as a Markov Decision Process (MDP). The global controller, operating\nat a slower timescale optimizes the infinite-horizon discounted cumulative\nreward under budget constraints. For the local controllers, operating at a\nfaster timescale, we propose two different optimization frameworks, namely the\nCOpt and FOpt. In the COpt framework, the local controller also optimizes an\ninfinite-horizon MDP, while in the FOpt framework, the local controller\noptimizes a finite-horizon MDP. The FOpt framework mimics a federal structure,\nwhere the local controllers have more autonomy in their decision making. First,\nthe existence of stationary deterministic optimal policies for both these\nframeworks is established. Then, various relationships between the two\nframeworks are studied, including a bound on the difference between the two\noptimal value functions. Additionally, sufficiency conditions are provided such\nthat the two frameworks lead to the same optimal values.", "AI": {"tldr": "A two-timescale hierarchical decentralized control architecture for Cyber-Physical Systems is proposed, with global and local controllers. Two optimization frameworks (COpt and FOpt) are introduced for local controllers, and their relationships are analyzed.", "motivation": "To address control challenges in Cyber-Physical Systems by leveraging hierarchical decentralized architecture and optimizing performance under budget constraints.", "method": "The architecture includes global and local controllers modeled as MDPs. Two frameworks (COpt for infinite-horizon and FOpt for finite-horizon MDPs) are proposed for local controllers. Theoretical analysis includes optimal policies and value function bounds.", "result": "Existence of stationary deterministic optimal policies is proven. Relationships between COpt and FOpt are studied, including bounds on value function differences and conditions for identical optimal values.", "conclusion": "The proposed architecture and frameworks provide flexible and efficient control for Cyber-Physical Systems, with theoretical guarantees on optimality and performance."}}
{"id": "2506.23254", "pdf": "https://arxiv.org/pdf/2506.23254", "abs": "https://arxiv.org/abs/2506.23254", "authors": ["Aradhana Mishra", "Bumshik Lee"], "title": "PixelBoost: Leveraging Brownian Motion for Realistic-Image Super-Resolution", "categories": ["cs.CV", "cs.AI", "cs.MM", "eess.IV"], "comment": null, "summary": "Diffusion-model-based image super-resolution techniques often face a\ntrade-off between realistic image generation and computational efficiency. This\nissue is exacerbated when inference times by decreasing sampling steps,\nresulting in less realistic and hazy images. To overcome this challenge, we\nintroduce a novel diffusion model named PixelBoost that underscores the\nsignificance of embracing the stochastic nature of Brownian motion in advancing\nimage super-resolution, resulting in a high degree of realism, particularly\nfocusing on texture and edge definitions. By integrating controlled\nstochasticity into the training regimen, our proposed model avoids convergence\nto local optima, effectively capturing and reproducing the inherent uncertainty\nof image textures and patterns. Our proposed model demonstrates superior\nobjective results in terms of learned perceptual image patch similarity\n(LPIPS), lightness order error (LOE), peak signal-to-noise ratio(PSNR),\nstructural similarity index measure (SSIM), as well as visual quality. To\ndetermine the edge enhancement, we evaluated the gradient magnitude and pixel\nvalue, and our proposed model exhibited a better edge reconstruction\ncapability. Additionally, our model demonstrates adaptive learning capabilities\nby effectively adjusting to Brownian noise patterns and introduces a sigmoidal\nnoise sequencing method that simplifies training, resulting in faster inference\nspeeds.", "AI": {"tldr": "PixelBoost, a novel diffusion model, improves image super-resolution by leveraging Brownian motion's stochastic nature, enhancing realism and computational efficiency.", "motivation": "Addressing the trade-off between realistic image generation and computational efficiency in diffusion-model-based super-resolution.", "method": "Integrates controlled stochasticity into training, avoiding local optima, and uses a sigmoidal noise sequencing method for faster inference.", "result": "Superior performance in LPIPS, LOE, PSNR, SSIM, and visual quality, with better edge reconstruction and adaptive learning.", "conclusion": "PixelBoost effectively balances realism and efficiency, advancing super-resolution techniques."}}
{"id": "2506.23437", "pdf": "https://arxiv.org/pdf/2506.23437", "abs": "https://arxiv.org/abs/2506.23437", "authors": ["Stefano Giacomelli", "Marco Giordano", "Claudia Rinaldi", "Fabio Graziosi"], "title": "From Large-scale Audio Tagging to Real-Time Explainable Emergency Vehicle Sirens Detection", "categories": ["cs.SD", "cs.AI", "eess.AS", "68T07", "E.1; H.1; I.2; I.5; J.2; K.4; C.4"], "comment": "pre-print (submitted to the IEEE/ACM Transactions on Audio, Speech,\n  and Language Processing)", "summary": "Accurate recognition of Emergency Vehicle (EV) sirens is critical for the\nintegration of intelligent transportation systems, smart city monitoring\nsystems, and autonomous driving technologies. Modern automatic solutions are\nlimited by the lack of large scale, curated datasets and by the computational\ndemands of state of the art sound event detection models. This work introduces\nE2PANNs (Efficient Emergency Pre trained Audio Neural Networks), a lightweight\nConvolutional Neural Network architecture derived from the PANNs framework,\nspecifically optimized for binary EV siren detection. Leveraging our dedicated\nsubset of AudioSet (AudioSet EV) we fine-tune and evaluate E2PANNs across\nmultiple reference datasets and test its viability on embedded hardware. The\nexperimental campaign includes ablation studies, cross-domain benchmarking, and\nreal-time inference deployment on edge device. Interpretability analyses\nexploiting Guided Backpropagation and ScoreCAM algorithms provide insights into\nthe model internal representations and validate its ability to capture distinct\nspectrotemporal patterns associated with different types of EV sirens. Real\ntime performance is assessed through frame wise and event based detection\nmetrics, as well as a detailed analysis of false positive activations. Results\ndemonstrate that E2PANNs establish a new state of the art in this research\ndomain, with high computational efficiency, and suitability for edge-based\naudio monitoring and safety-critical applications.", "AI": {"tldr": "E2PANNs, a lightweight CNN, is introduced for efficient EV siren detection, achieving state-of-the-art performance with high computational efficiency and edge-device suitability.", "motivation": "Accurate EV siren recognition is vital for smart cities and autonomous driving, but current solutions lack datasets and computational efficiency.", "method": "E2PANNs, a lightweight CNN derived from PANNs, is fine-tuned using AudioSet EV and evaluated across datasets and edge hardware.", "result": "E2PANNs set a new benchmark with high efficiency, validated by interpretability analyses and real-time performance metrics.", "conclusion": "E2PANNs are effective for edge-based EV siren detection, offering computational efficiency and suitability for safety-critical applications."}}
{"id": "2506.23121", "pdf": "https://arxiv.org/pdf/2506.23121", "abs": "https://arxiv.org/abs/2506.23121", "authors": ["Xinlei Yu", "Chanmiao Wang", "Hui Jin", "Ahmed Elazab", "Gangyong Jia", "Xiang Wan", "Changqing Zou", "Ruiquan Ge"], "title": "CRISP-SAM2: SAM2 with Cross-Modal Interaction and Semantic Prompting for Multi-Organ Segmentation", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "19 pages, 9 figures, 10 tables", "summary": "Multi-organ medical segmentation is a crucial component of medical image\nprocessing, essential for doctors to make accurate diagnoses and develop\neffective treatment plans. Despite significant progress in this field, current\nmulti-organ segmentation models often suffer from inaccurate details,\ndependence on geometric prompts and loss of spatial information. Addressing\nthese challenges, we introduce a novel model named CRISP-SAM2 with CRoss-modal\nInteraction and Semantic Prompting based on SAM2. This model represents a\npromising approach to multi-organ medical segmentation guided by textual\ndescriptions of organs. Our method begins by converting visual and textual\ninputs into cross-modal contextualized semantics using a progressive\ncross-attention interaction mechanism. These semantics are then injected into\nthe image encoder to enhance the detailed understanding of visual information.\nTo eliminate reliance on geometric prompts, we use a semantic prompting\nstrategy, replacing the original prompt encoder to sharpen the perception of\nchallenging targets. In addition, a similarity-sorting self-updating strategy\nfor memory and a mask-refining process is applied to further adapt to medical\nimaging and enhance localized details. Comparative experiments conducted on\nseven public datasets indicate that CRISP-SAM2 outperforms existing models.\nExtensive analysis also demonstrates the effectiveness of our method, thereby\nconfirming its superior performance, especially in addressing the limitations\nmentioned earlier. Our code is available at:\nhttps://github.com/YU-deep/CRISP\\_SAM2.git.", "AI": {"tldr": "CRISP-SAM2 is a novel multi-organ medical segmentation model using cross-modal interaction and semantic prompting to improve accuracy and reduce reliance on geometric prompts.", "motivation": "Current multi-organ segmentation models often lack detail accuracy, depend on geometric prompts, and lose spatial information, limiting their effectiveness.", "method": "The model converts visual and textual inputs into cross-modal semantics, uses semantic prompting, and incorporates memory self-updating and mask-refining strategies.", "result": "CRISP-SAM2 outperforms existing models on seven public datasets, demonstrating superior performance in detail accuracy and adaptability.", "conclusion": "CRISP-SAM2 effectively addresses key limitations in multi-organ segmentation, offering a promising solution for medical image processing."}}
{"id": "2506.22920", "pdf": "https://arxiv.org/pdf/2506.22920", "abs": "https://arxiv.org/abs/2506.22920", "authors": ["Pinzheng Wang", "Juntao Li", "Zecheng Tang", "Haijia Gui", "Min zhang"], "title": "Improving Rationality in the Reasoning Process of Language Models through Self-playing Game", "categories": ["cs.AI"], "comment": "Accepted by ICML 2025", "summary": "Large language models (LLMs) have demonstrated considerable reasoning\nabilities in various tasks such as mathematics and coding. However, recent\nstudies indicate that even the best models lack true comprehension of their\nreasoning processes. In this paper, we explore how self-play can enhance the\nrationality of models in the reasoning process without supervision from humans\nor superior models. We design a Critic-Discernment Game(CDG) in which a prover\nfirst provides a solution to a given problem and is subsequently challenged by\ncritiques of its solution. These critiques either aim to assist or mislead the\nprover. The objective of the prover is to maintain the correct answer when\nfaced with misleading comments, while correcting errors in response to\nconstructive feedback. Our experiments on tasks involving mathematical\nreasoning, stepwise error detection, self-correction, and long-chain reasoning\ndemonstrate that CDG training can significantly improve the ability of\nwell-aligned LLMs to comprehend their reasoning process.", "AI": {"tldr": "The paper explores using self-play (Critic-Discernment Game) to enhance LLMs' reasoning comprehension without supervision, showing significant improvement in tasks like math and error detection.", "motivation": "Despite LLMs' strong reasoning abilities, they lack true comprehension of their processes. This work aims to improve rationality in reasoning without human or superior model supervision.", "method": "A Critic-Discernment Game (CDG) is designed where a prover solves problems and faces critiques (helpful or misleading). The prover must correct errors from feedback and resist misleading comments.", "result": "Experiments on math reasoning, error detection, self-correction, and long-chain reasoning show CDG training significantly improves LLMs' reasoning comprehension.", "conclusion": "Self-play via CDG effectively enhances LLMs' ability to understand their reasoning processes, demonstrating promise for unsupervised rationality improvement."}}
{"id": "2506.22566", "pdf": "https://arxiv.org/pdf/2506.22566", "abs": "https://arxiv.org/abs/2506.22566", "authors": ["Jacob Adamczyk"], "title": "Exploration Behavior of Untrained Policies", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "High-dimensional Learning Dynamics Workshop at ICML-2025", "summary": "Exploration remains a fundamental challenge in reinforcement learning (RL),\nparticularly in environments with sparse or adversarial reward structures. In\nthis work, we study how the architecture of deep neural policies implicitly\nshapes exploration before training. We theoretically and empirically\ndemonstrate strategies for generating ballistic or diffusive trajectories from\nuntrained policies in a toy model. Using the theory of infinite-width networks\nand a continuous-time limit, we show that untrained policies return correlated\nactions and result in non-trivial state-visitation distributions. We discuss\nthe distributions of the corresponding trajectories for a standard\narchitecture, revealing insights into inductive biases for tackling\nexploration. Our results establish a theoretical and experimental framework for\nusing policy initialization as a design tool to understand exploration behavior\nin early training.", "AI": {"tldr": "The paper explores how untrained deep neural policies influence exploration in RL, showing they produce non-trivial state-visitation distributions and correlated actions, with implications for early training behavior.", "motivation": "Understanding how policy architectures implicitly shape exploration in RL, especially in sparse or adversarial reward settings.", "method": "Theoretical and empirical analysis of untrained policies using infinite-width networks and continuous-time limits, focusing on trajectory distributions.", "result": "Untrained policies generate correlated actions and non-trivial state-visitation distributions, revealing architectural inductive biases for exploration.", "conclusion": "The work provides a framework for using policy initialization to study and design exploration behavior in early RL training."}}
{"id": "2506.22504", "pdf": "https://arxiv.org/pdf/2506.22504", "abs": "https://arxiv.org/abs/2506.22504", "authors": ["Hassan Baker", "Austin J. Brockmeier"], "title": "Patch2Loc: Learning to Localize Patches for Unsupervised Brain Lesion Detection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Detecting brain lesions as abnormalities observed in magnetic resonance\nimaging (MRI) is essential for diagnosis and treatment. In the search of\nabnormalities, such as tumors and malformations, radiologists may benefit from\ncomputer-aided diagnostics that use computer vision systems trained with\nmachine learning to segment normal tissue from abnormal brain tissue. While\nsupervised learning methods require annotated lesions, we propose a new\nunsupervised approach (Patch2Loc) that learns from normal patches taken from\nstructural MRI. We train a neural network model to map a patch back to its\nspatial location within a slice of the brain volume. During inference, abnormal\npatches are detected by the relatively higher error and/or variance of the\nlocation prediction. This generates a heatmap that can be integrated into\npixel-wise methods to achieve finer-grained segmentation. We demonstrate the\nability of our model to segment abnormal brain tissues by applying our approach\nto the detection of tumor tissues in MRI on T2-weighted images from BraTS2021\nand MSLUB datasets and T1-weighted images from ATLAS and WMH datasets. We show\nthat it outperforms the state-of-the art in unsupervised segmentation. The\ncodebase for this work can be found on our\n\\href{https://github.com/bakerhassan/Patch2Loc}{GitHub page}.", "AI": {"tldr": "Patch2Loc is an unsupervised method for detecting brain lesions in MRI by learning from normal patches and identifying abnormalities through prediction errors.", "motivation": "To improve brain lesion detection without requiring annotated data, leveraging unsupervised learning for more accessible diagnostics.", "method": "Trains a neural network to map patches to their spatial locations; detects abnormalities via higher prediction errors/variance, generating a heatmap for segmentation.", "result": "Outperforms state-of-the-art unsupervised segmentation on BraTS2021, MSLUB, ATLAS, and WMH datasets.", "conclusion": "Patch2Loc offers an effective unsupervised alternative for brain lesion segmentation, with potential for broader medical imaging applications."}}
{"id": "2506.22679", "pdf": "https://arxiv.org/pdf/2506.22679", "abs": "https://arxiv.org/abs/2506.22679", "authors": ["Ankush Raut", "Projna Paromita", "Sydney Begerowski", "Suzanne Bell", "Theodora Chaspari"], "title": "Assessing the feasibility of Large Language Models for detecting micro-behaviors in team interactions during space missions", "categories": ["cs.CL"], "comment": "5 pages, 4 figures. Accepted to Interspeech 2025", "summary": "We explore the feasibility of large language models (LLMs) in detecting\nsubtle expressions of micro-behaviors in team conversations using transcripts\ncollected during simulated space missions. Specifically, we examine zero-shot\nclassification, fine-tuning, and paraphrase-augmented fine-tuning with\nencoder-only sequence classification LLMs, as well as few-shot text generation\nwith decoder-only causal language modeling LLMs, to predict the micro-behavior\nassociated with each conversational turn (i.e., dialogue). Our findings\nindicate that encoder-only LLMs, such as RoBERTa and DistilBERT, struggled to\ndetect underrepresented micro-behaviors, particularly discouraging speech, even\nwith weighted fine-tuning. In contrast, the instruction fine-tuned version of\nLlama-3.1, a decoder-only LLM, demonstrated superior performance, with the best\nmodels achieving macro F1-scores of 44% for 3-way classification and 68% for\nbinary classification. These results have implications for the development of\nspeech technologies aimed at analyzing team communication dynamics and\nenhancing training interventions in high-stakes environments such as space\nmissions, particularly in scenarios where text is the only accessible data.", "AI": {"tldr": "LLMs are tested for detecting micro-behaviors in team conversations. Encoder-only models struggled, while decoder-only Llama-3.1 performed better, showing promise for speech technologies in high-stakes environments.", "motivation": "To explore LLMs' capability in detecting subtle micro-behaviors in team communication, especially in high-stakes scenarios like space missions.", "method": "Tested zero-shot classification, fine-tuning, paraphrase-augmented fine-tuning with encoder-only models (RoBERTa, DistilBERT), and few-shot text generation with decoder-only models (Llama-3.1).", "result": "Encoder-only models struggled, especially with underrepresented behaviors. Llama-3.1 achieved 44% macro F1 for 3-way and 68% for binary classification.", "conclusion": "Decoder-only LLMs like Llama-3.1 are more effective for analyzing team communication dynamics, useful for training interventions in high-stakes environments."}}
{"id": "2506.23030", "pdf": "https://arxiv.org/pdf/2506.23030", "abs": "https://arxiv.org/abs/2506.23030", "authors": ["Alejandro Romero Amezcua", "Mariano Jos\u00e9 Juan Rivera Meraz"], "title": "VisionScores -- A system-segmented image score dataset for deep learning tasks", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "comment": "Comments: 5 pages, 3 figures. Accepted for presentation at the 2025\n  IEEE International Conference on Image Processing (ICIP). \\c{opyright} 2025\n  IEEE. Personal use of this material is permitted. Permission from IEEE must\n  be obtained for any other use", "summary": "VisionScores presents a novel proposal being the first system-segmented image\nscore dataset, aiming to offer structure-rich, high information-density images\nfor machine and deep learning tasks. Delimited to two-handed piano pieces, it\nwas built to consider not only certain graphic similarity but also composition\npatterns, as this creative process is highly instrument-dependent. It provides\ntwo scenarios in relation to composer and composition type. The first, formed\nby 14k samples, considers works from different authors but the same composition\ntype, specifically, Sonatinas. The latter, consisting of 10.8K samples,\npresents the opposite case, various composition types from the same author,\nbeing the one selected Franz Liszt. All of the 24.8k samples are formatted as\ngrayscale jpg images of $128 \\times 512$ pixels. VisionScores supplies the\nusers not only the formatted samples but the systems' order and pieces'\nmetadata. Moreover, unsegmented full-page scores and the pre-formatted images\nare included for further analysis.", "AI": {"tldr": "VisionScores introduces the first system-segmented image score dataset for machine learning, focusing on two-handed piano pieces with 24.8k samples in two scenarios: same composition type (Sonatinas) from different composers and different types from Franz Liszt.", "motivation": "To provide a structured, high-density image dataset for machine/deep learning, capturing graphic similarity and composition patterns specific to piano pieces.", "method": "Dataset includes 24.8k grayscale images (128x512 pixels) of two-handed piano scores, segmented by systems, with metadata and full-page scores for analysis. Two scenarios: same composition type (Sonatinas) from various composers and different types from Franz Liszt.", "result": "A comprehensive dataset (VisionScores) with 14k Sonatina samples and 10.8k Liszt samples, including metadata and raw materials for further research.", "conclusion": "VisionScores is a valuable resource for machine learning tasks in music, offering structured, instrument-specific data with rich metadata and raw materials."}}
{"id": "2506.22991", "pdf": "https://arxiv.org/pdf/2506.22991", "abs": "https://arxiv.org/abs/2506.22991", "authors": ["Mehdi Bennis", "Sumudu Samarakoon", "Tamara Alshammari", "Chathuranga Weeraddana", "Zhoujun Tian", "Chaouki Ben Issaid"], "title": "Resilient-Native and Intelligent Next-Generation Wireless Systems: Key Enablers, Foundations, and Applications", "categories": ["cs.NI", "cs.LO", "cs.MA", "cs.SY", "eess.SY"], "comment": null, "summary": "Just like power, water, and transportation systems, wireless networks are a\ncrucial societal infrastructure. As natural and human-induced disruptions\ncontinue to grow, wireless networks must be resilient. This requires them to\nwithstand and recover from unexpected adverse conditions, shocks, unmodeled\ndisturbances and cascading failures. Unlike robustness and reliability,\nresilience is based on the understanding that disruptions will inevitably\nhappen. Resilience, as elasticity, focuses on the ability to bounce back to\nfavorable states, while resilience as plasticity involves agents and networks\nthat can flexibly expand their states and hypotheses through real-time\nadaptation and reconfiguration. This situational awareness and active\npreparedness, adapting world models and counterfactually reasoning about\npotential system failures and the best responses, is a core aspect of\nresilience. This article will first disambiguate resilience from reliability\nand robustness, before delving into key mathematical foundations of resilience\ngrounded in abstraction, compositionality and emergence. Subsequently, we focus\nour attention on a plethora of techniques and methodologies pertaining to the\nunique characteristics of resilience, as well as their applications through a\ncomprehensive set of use cases. Ultimately, the goal of this paper is to\nestablish a unified foundation for understanding, modeling, and engineering\nresilience in wireless communication systems, while laying a roadmap for the\nnext-generation of resilient-native and intelligent wireless systems.", "AI": {"tldr": "The paper distinguishes resilience from reliability and robustness in wireless networks, explores its mathematical foundations, and presents techniques for engineering resilient systems.", "motivation": "Wireless networks are critical infrastructure, and resilience is essential to handle inevitable disruptions, unlike robustness or reliability.", "method": "The paper disambiguates resilience, discusses its mathematical foundations (abstraction, compositionality, emergence), and reviews techniques and methodologies for resilience.", "result": "A unified foundation for understanding and engineering resilience in wireless systems is established, with a roadmap for future resilient-native systems.", "conclusion": "The paper provides a comprehensive framework for resilience in wireless networks, paving the way for next-generation intelligent and resilient systems."}}
{"id": "2502.05695", "pdf": "https://arxiv.org/pdf/2502.05695", "abs": "https://arxiv.org/abs/2502.05695", "authors": ["Zijiang Yan", "Jianhua Pei", "Hongda Wu", "Hina Tabassum", "Ping Wang"], "title": "Semantic-Aware Adaptive Video Streaming Using Latent Diffusion Models for Wireless Networks", "categories": ["cs.MM", "cs.AI", "cs.CV", "cs.LG", "eess.IV"], "comment": "Accepted in IEEE Wireless Communications", "summary": "This paper proposes a novel Semantic Communication (SemCom) framework for\nreal-time adaptive-bitrate video streaming by integrating Latent Diffusion\nModels (LDMs) within the FFmpeg techniques. This solution addresses the\nchallenges of high bandwidth usage, storage inefficiencies, and quality of\nexperience (QoE) degradation associated with traditional Constant Bitrate\nStreaming (CBS) and Adaptive Bitrate Streaming (ABS). The proposed approach\nleverages LDMs to compress I-frames into a latent space, offering significant\nstorage and semantic transmission savings without sacrificing high visual\nquality. While retaining B-frames and P-frames as adjustment metadata to\nsupport efficient refinement of video reconstruction at the user side, the\nproposed framework further incorporates state-of-the-art denoising and Video\nFrame Interpolation (VFI) techniques. These techniques mitigate semantic\nambiguity and restore temporal coherence between frames, even in noisy wireless\ncommunication environments. Experimental results demonstrate the proposed\nmethod achieves high-quality video streaming with optimized bandwidth usage,\noutperforming state-of-the-art solutions in terms of QoE and resource\nefficiency. This work opens new possibilities for scalable real-time video\nstreaming in 5G and future post-5G networks.", "AI": {"tldr": "A novel Semantic Communication framework using Latent Diffusion Models (LDMs) for adaptive-bitrate video streaming, improving bandwidth, storage, and QoE over traditional methods.", "motivation": "Addresses challenges like high bandwidth usage, storage inefficiencies, and QoE degradation in traditional video streaming methods.", "method": "Integrates LDMs to compress I-frames into latent space, retains B/P-frames as metadata, and uses denoising and Video Frame Interpolation for quality.", "result": "Achieves high-quality streaming with optimized bandwidth, outperforming existing solutions in QoE and resource efficiency.", "conclusion": "Enables scalable real-time video streaming for 5G and future networks."}}
{"id": "2506.23582", "pdf": "https://arxiv.org/pdf/2506.23582", "abs": "https://arxiv.org/abs/2506.23582", "authors": ["Yusuke Kanamori", "Yuki Okamoto", "Taisei Takano", "Shinnosuke Takamichi", "Yuki Saito", "Hiroshi Saruwatari"], "title": "RELATE: Subjective evaluation dataset for automatic evaluation of relevance between text and audio", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted to INTERSPEECH2025", "summary": "In text-to-audio (TTA) research, the relevance between input text and output\naudio is an important evaluation aspect. Traditionally, it has been evaluated\nfrom both subjective and objective perspectives. However, subjective evaluation\nis costly in terms of money and time, and objective evaluation is unclear\nregarding the correlation to subjective evaluation scores. In this study, we\nconstruct RELATE, an open-sourced dataset that subjectively evaluates the\nrelevance. Also, we benchmark a model for automatically predicting the\nsubjective evaluation score from synthesized audio. Our model outperforms a\nconventional CLAPScore model, and that trend extends to many sound categories.", "AI": {"tldr": "The paper introduces RELATE, a dataset for subjective evaluation of text-to-audio relevance, and benchmarks a model for predicting subjective scores, outperforming CLAPScore.", "motivation": "Traditional evaluations of text-to-audio relevance are costly (subjective) or unclear (objective). RELATE addresses this gap.", "method": "Constructed the RELATE dataset for subjective evaluation and developed a model to predict subjective scores from audio.", "result": "The proposed model outperforms CLAPScore and generalizes well across sound categories.", "conclusion": "RELATE and the new model offer a more efficient and reliable way to evaluate text-to-audio relevance."}}
{"id": "2506.23184", "pdf": "https://arxiv.org/pdf/2506.23184", "abs": "https://arxiv.org/abs/2506.23184", "authors": ["Anran Liu", "Xiaofei Wang", "Jing Cai", "Chao Li"], "title": "Score-based Diffusion Model for Unpaired Virtual Histology Staining", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "11 pages, 3 figures", "summary": "Hematoxylin and eosin (H&E) staining visualizes histology but lacks\nspecificity for diagnostic markers. Immunohistochemistry (IHC) staining\nprovides protein-targeted staining but is restricted by tissue availability and\nantibody specificity. Virtual staining, i.e., computationally translating the\nH&E image to its IHC counterpart while preserving the tissue structure, is\npromising for efficient IHC generation. Existing virtual staining methods still\nface key challenges: 1) effective decomposition of staining style and tissue\nstructure, 2) controllable staining process adaptable to diverse tissue and\nproteins, and 3) rigorous structural consistency modelling to handle the\nnon-pixel-aligned nature of paired H&E and IHC images. This study proposes a\nmutual-information (MI)-guided score-based diffusion model for unpaired virtual\nstaining. Specifically, we design 1) a global MI-guided energy function that\ndisentangles the tissue structure and staining characteristics across\nmodalities, 2) a novel timestep-customized reverse diffusion process for\nprecise control of the staining intensity and structural reconstruction, and 3)\na local MI-driven contrastive learning strategy to ensure the cellular level\nstructural consistency between H&E-IHC images. Extensive experiments\ndemonstrate the our superiority over state-of-the-art approaches, highlighting\nits biomedical potential. Codes will be open-sourced upon acceptance.", "AI": {"tldr": "A mutual-information-guided diffusion model is proposed for virtual staining of H&E images to IHC, addressing challenges like style decomposition, controllable staining, and structural consistency.", "motivation": "H&E staining lacks specificity for diagnostic markers, while IHC is limited by tissue and antibody constraints. Virtual staining offers a computational solution.", "method": "The study introduces a mutual-information-guided score-based diffusion model, featuring global and local MI strategies for disentangling staining styles and ensuring structural consistency.", "result": "The model outperforms state-of-the-art methods, demonstrating its biomedical potential.", "conclusion": "The proposed method effectively addresses key challenges in virtual staining, with plans to open-source the code."}}
{"id": "2506.22992", "pdf": "https://arxiv.org/pdf/2506.22992", "abs": "https://arxiv.org/abs/2506.22992", "authors": ["Yulun Jiang", "Yekun Chai", "Maria Brbi\u0107", "Michael Moor"], "title": "MARBLE: A Hard Benchmark for Multimodal Spatial Reasoning and Planning", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "The ability to process information from multiple modalities and to reason\nthrough it step-by-step remains a critical challenge in advancing artificial\nintelligence. However, existing reasoning benchmarks focus on text-only\nreasoning, or employ multimodal questions that can be answered by directly\nretrieving information from a non-text modality. Thus, complex reasoning\nremains poorly understood in multimodal domains. Here, we present MARBLE, a\nchallenging multimodal reasoning benchmark that is designed to scrutinize\nmultimodal language models (MLLMs) in their ability to carefully reason\nstep-by-step through complex multimodal problems and environments. MARBLE is\ncomposed of two highly challenging tasks, M-Portal and M-Cube, that require the\ncrafting and understanding of multistep plans under spatial, visual, and\nphysical constraints. We find that current MLLMs perform poorly on MARBLE --\nall the 12 advanced models obtain near-random performance on M-Portal and 0%\naccuracy on M-Cube. Only in simplified subtasks some models outperform the\nrandom baseline, indicating that complex reasoning is still a challenge for\nexisting MLLMs. Moreover, we show that perception remains a bottleneck, where\nMLLMs occasionally fail to extract information from the visual inputs. By\nshedding a light on the limitations of MLLMs, we hope that MARBLE will spur the\ndevelopment of the next generation of models with the ability to reason and\nplan across many, multimodal reasoning steps.", "AI": {"tldr": "MARBLE is a multimodal reasoning benchmark designed to test MLLMs' ability to handle complex, step-by-step reasoning across modalities, revealing their current limitations.", "motivation": "Existing benchmarks lack focus on complex multimodal reasoning, limiting understanding of MLLMs' capabilities in such domains.", "method": "MARBLE includes two tasks, M-Portal and M-Cube, requiring multistep planning under spatial, visual, and physical constraints.", "result": "Current MLLMs perform poorly, with near-random accuracy on M-Portal and 0% on M-Cube, highlighting reasoning and perception bottlenecks.", "conclusion": "MARBLE aims to drive development of next-gen MLLMs capable of advanced multimodal reasoning."}}
{"id": "2506.22578", "pdf": "https://arxiv.org/pdf/2506.22578", "abs": "https://arxiv.org/abs/2506.22578", "authors": ["Xufei Lv", "Haoyuan Sun", "Xuefeng Bai", "Min Zhang", "Houde Liu", "Kehai Chen"], "title": "The Hidden Link Between RLHF and Contrastive Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Alignment of large language models (LLMs) with human values has recently\ngarnered significant attention, with prominent examples including the canonical\nyet costly Reinforcement Learning from Human Feedback (RLHF) and the simple\nDirect Preference Optimization (DPO). In this work, we demonstrate that both\nRLHF and DPO can be interpreted from the perspective of mutual information (MI)\nmaximization, uncovering a profound connection to contrastive learning. Within\nthis framework, both RLHF and DPO can be viewed as methods that perform\ncontrastive learning based on the positive and negative samples derived from\nthe base model, leveraging the Donsker-Varadhan (DV) lower bound on MI\n(equivalently, the MINE estimator). This paradigm further explains why RLHF may\nnot intrinsically incentivize reasoning capacities in LLMs beyond what is\nalready present in the base model. Building on this perspective, we replace the\nDV/MINE bound with the Jensen-Shannon MI estimator and propose Mutual\nInformation Optimization (MIO). Comprehensive theoretical analysis and\nextensive empirical evaluations demonstrate that MIO mitigates the late-stage\ndecline in chosen-likelihood observed in DPO, achieving competitive or superior\nperformance across various challenging reasoning and mathematical benchmarks.\nWe will release the model and code upon acceptance.", "AI": {"tldr": "The paper interprets RLHF and DPO as mutual information maximization methods, linking them to contrastive learning, and proposes MIO to improve performance.", "motivation": "To understand and improve the alignment of LLMs with human values by reinterpreting existing methods (RLHF, DPO) through mutual information maximization.", "method": "Replaces the DV/MINE bound with the Jensen-Shannon MI estimator, proposing Mutual Information Optimization (MIO).", "result": "MIO mitigates late-stage decline in chosen-likelihood, outperforming DPO in reasoning and mathematical benchmarks.", "conclusion": "MIO offers a competitive alternative to RLHF and DPO, enhancing LLM alignment and reasoning capabilities."}}
{"id": "2506.22505", "pdf": "https://arxiv.org/pdf/2506.22505", "abs": "https://arxiv.org/abs/2506.22505", "authors": ["Hassan Baker", "Matthew S. Emigh", "Austin J. Brockmeier"], "title": "Weakly Supervised Object Segmentation by Background Conditional Divergence", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "As a computer vision task, automatic object segmentation remains challenging\nin specialized image domains without massive labeled data, such as synthetic\naperture sonar images, remote sensing, biomedical imaging, etc. In any domain,\nobtaining pixel-wise segmentation masks is expensive. In this work, we propose\na method for training a masking network to perform binary object segmentation\nusing weak supervision in the form of image-wise presence or absence of an\nobject of interest, which provides less information but may be obtained more\nquickly from manual or automatic labeling. A key step in our method is that the\nsegmented objects can be placed into background-only images to create\nrealistic, images of the objects with counterfactual backgrounds. To create a\ncontrast between the original and counterfactual background images, we propose\nto first cluster the background-only images, and then during learning create\ncounterfactual images that blend objects segmented from their original source\nbackgrounds to backgrounds chosen from a targeted cluster. One term in the\ntraining loss is the divergence between these counterfactual images and the\nreal object images with backgrounds of the target cluster. The other term is a\nsupervised loss for background-only images. While an adversarial critic could\nprovide the divergence, we use sample-based divergences. We conduct experiments\non side-scan and synthetic aperture sonar in which our approach succeeds\ncompared to previous unsupervised segmentation baselines that were only tested\non natural images. Furthermore, to show generality we extend our experiments to\nnatural images, obtaining reasonable performance with our method that avoids\npretrained networks, generative networks, and adversarial critics. The basecode\nfor this work can be found at\n\\href{GitHub}{https://github.com/bakerhassan/WSOS}.", "AI": {"tldr": "Proposes a weakly supervised method for binary object segmentation using image-wise labels and counterfactual backgrounds, outperforming unsupervised baselines in specialized domains.", "motivation": "Addresses the challenge of expensive pixel-wise segmentation in specialized domains by leveraging weak supervision (image-wise labels) for training.", "method": "Uses weak supervision (image-wise labels) to train a masking network. Creates counterfactual images by blending segmented objects with clustered backgrounds and employs sample-based divergences for training.", "result": "Outperforms unsupervised baselines in sonar and natural images, avoiding pretrained or generative networks.", "conclusion": "Demonstrates effectiveness of weak supervision and counterfactual backgrounds for segmentation in specialized domains, with potential for broader applications."}}
{"id": "2506.22694", "pdf": "https://arxiv.org/pdf/2506.22694", "abs": "https://arxiv.org/abs/2506.22694", "authors": ["Raghavv Goel", "Sudhanshu Agrawal", "Mukul Gagrani", "Junyoung Park", "Yifan Zao", "He Zhang", "Tian Liu", "Yiping Yang", "Xin Yuan", "Jiuyan Lu", "Chris Lott", "Mingu Lee"], "title": "VOCABTRIM: Vocabulary Pruning for Efficient Speculative Decoding in LLMs", "categories": ["cs.CL"], "comment": "7 pages, 4 figures, 5 tables, accepted at ICML 2025 workshop on\n  Efficient Systems for Foundational Models", "summary": "In this paper, we introduce a simple training-free technique to improve the\nperformance of drafter-based speculative decoding (SpD) methods that\nincorporates language modeling head (LM head) during drafting process. A\ndrafter-based speculative decoding leverages one or more smaller language\nmodels, a.k.a. drafters or draft models, to sample a draft sequence or tree\nconsisting of multiple tokens, followed by verification by a base LLM, a target\nmodel, accepting a subset as its valid generation. As it is usually considered\nthat the speculative decoding requires one-to-one mapping between vocabularies\nof the target model and the draft model, it has been natural to share the\nvocabulary between them, or even share the LM head as in EAGLE or Medusa. We\nfirst identify that this draft token sampling scheme inherently contains an\nunnecessary inference overhead in drafting, especially for some target LLMs\nwith very large vocabularies. Then, we propose a simple technique, VocabTrim,\nto mitigate the drafting overhead to improve the generation speed in\nmemory-bound environment. VocabTrim reconstructs the drafter LM head to contain\nonly a limited set of tokens, selected by the most frequently sampled from the\nvocabulary of the target model. While limiting the vocabulary in drafting\nslightly degrades the acceptance rate, it significantly reduces the drafting\nlatency in memory-bound process which is often the case on edge devices,\nresulting in higher memory-bound speed up (MBSU). We show that our method can\nboost the memory-bound speed-up for Llama-3 models on Spec-Bench, specifically\nby 16% for Llama-3.2-3B-Instruct.", "AI": {"tldr": "The paper introduces VocabTrim, a training-free technique to improve speculative decoding (SpD) by reducing drafting overhead in memory-bound environments, achieving a 16% speed-up for Llama-3.2-3B-Instruct.", "motivation": "The motivation is to address the unnecessary inference overhead in drafter-based speculative decoding, especially for LLMs with large vocabularies, by optimizing the drafting process.", "method": "The method involves VocabTrim, which reconstructs the drafter's LM head to include only frequently sampled tokens, reducing drafting latency.", "result": "VocabTrim improves memory-bound speed-up by 16% for Llama-3.2-3B-Instruct, despite a slight drop in acceptance rate.", "conclusion": "VocabTrim effectively balances drafting efficiency and acceptance rate, enhancing speculative decoding performance in memory-bound scenarios."}}
{"id": "2506.23049", "pdf": "https://arxiv.org/pdf/2506.23049", "abs": "https://arxiv.org/abs/2506.23049", "authors": ["Leander Melroy Maben", "Gayathri Ganesh Lakshmy", "Srijith Radhakrishnan", "Siddhant Arora", "Shinji Watanabe"], "title": "AURA: Agent for Understanding, Reasoning, and Automated Tool Use in Voice-Driven Tasks", "categories": ["cs.AI", "cs.CL", "cs.SD", "eess.AS", "68T42, 68T50,", "I.2.7; I.2.11; H.5.5"], "comment": null, "summary": "Despite advances in language and speech technologies, no open-source system\nenables full speech-to-speech, multi-turn dialogue with integrated tool use and\nagentic reasoning. We introduce AURA (Agent for Understanding, Reasoning, and\nAutomated Tool Use), the first open-source, speech-native assistant capable of\ncompleting complex, goal-driven tasks through dynamic tool invocation and\nmulti-turn conversation. AURA combines open-weight ASR, TTS, and LLMs in a\ncascaded pipeline and supports tools such as calendar booking, contact lookup,\nweb search, and email. Its modular design allows easy integration of new tools\nusing natural language prompts and action classes. On VoiceBench, AURA scores\n92.75% on OpenBookQA-outperforming all open-weight systems and nearing\nGPT-4o-and 4.39 on AlpacaEval, competitive with other open-weight systems.\nHuman evaluation shows 90% task success on complex, multi-turn speech tasks.", "AI": {"tldr": "AURA is the first open-source, speech-native assistant for multi-turn dialogue with tool use, combining ASR, TTS, and LLMs. It excels in benchmarks and human evaluations.", "motivation": "No existing open-source system supports full speech-to-speech, multi-turn dialogue with integrated tool use and agentic reasoning.", "method": "AURA uses a cascaded pipeline of open-weight ASR, TTS, and LLMs, with modular tool integration via natural language prompts.", "result": "AURA scores 92.75% on OpenBookQA, 4.39 on AlpacaEval, and achieves 90% task success in human evaluations.", "conclusion": "AURA is a competitive, open-source solution for complex, goal-driven speech tasks."}}
{"id": "2506.23079", "pdf": "https://arxiv.org/pdf/2506.23079", "abs": "https://arxiv.org/abs/2506.23079", "authors": ["Cong Xie", "Li Yang", "Daben Wang", "Jing Xiao"], "title": "Research on Comprehensive Classroom Evaluation System Based on Multiple AI Models", "categories": ["cs.CY", "cs.MA"], "comment": null, "summary": "The promotion of the national education digitalization strategy has\nfacilitated the development of teaching quality evaluation towards all-round,\nprocess-oriented, precise, and intelligent directions, inspiring explorations\ninto new methods and technologies for educational quality assurance. Classroom\nteaching evaluation methods dominated by teaching supervision and student\nteaching evaluation suffer from issues such as low efficiency, strong\nsubjectivity, and limited evaluation dimensions. How to further advance\nintelligent and objective evaluation remains a topic to be explored. This\npaper, based on image recognition technology, speech recognition technology,\nand AI large language models, develops a comprehensive evaluation system that\nautomatically generates evaluation reports and optimization suggestions from\ntwo dimensions: teacher teaching ability and classroom teaching effectiveness.\nThis study establishes a closed-loop classroom evaluation model that\ncomprehensively evaluates student and teaching conditions based on\nmulti-dimensional data throughout the classroom teaching process, and further\nanalyzes the data to guide teaching improvement. It meets the requirements of\nall-round and process-oriented classroom evaluation in the era of digital\neducation, effectively solves the main problems of manual evaluation methods,\nand provides data collection and analysis methods as well as technologies for\nrelevant research on educational teaching evaluation.", "AI": {"tldr": "The paper proposes an AI-driven system using image/speech recognition and large language models to automate and enhance classroom teaching evaluation, addressing inefficiencies and subjectivity in traditional methods.", "motivation": "Traditional teaching evaluation methods are inefficient, subjective, and limited. The study aims to leverage AI for more objective, comprehensive, and intelligent evaluation.", "method": "The system integrates image recognition, speech recognition, and AI large language models to analyze teacher ability and classroom effectiveness, generating automated reports and suggestions.", "result": "A closed-loop evaluation model is developed, enabling multi-dimensional data analysis for teaching improvement, meeting digital education demands.", "conclusion": "The AI-based system effectively overcomes manual evaluation limitations, providing scalable solutions for educational quality assurance."}}
{"id": "2410.08174", "pdf": "https://arxiv.org/pdf/2410.08174", "abs": "https://arxiv.org/abs/2410.08174", "authors": ["Qingni Wang", "Tiantian Geng", "Zhiyuan Wang", "Teng Wang", "Bo Fu", "Feng Zheng"], "title": "Sample then Identify: A General Framework for Risk Control and Assessment in Multimodal Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MM"], "comment": "Accepted by ICLR 2025 Spotlights", "summary": "Multimodal Large Language Models (MLLMs) exhibit promising advancements\nacross various tasks, yet they still encounter significant trustworthiness\nissues. Prior studies apply Split Conformal Prediction (SCP) in language\nmodeling to construct prediction sets with statistical guarantees. However,\nthese methods typically rely on internal model logits or are restricted to\nmultiple-choice settings, which hampers their generalizability and adaptability\nin dynamic, open-ended environments. In this paper, we introduce TRON, a\ntwo-step framework for risk control and assessment, applicable to any MLLM that\nsupports sampling in both open-ended and closed-ended scenarios. TRON comprises\ntwo main components: (1) a novel conformal score to sample response sets of\nminimum size, and (2) a nonconformity score to identify high-quality responses\nbased on self-consistency theory, controlling the error rates by two specific\nrisk levels. Furthermore, we investigate semantic redundancy in prediction sets\nwithin open-ended contexts for the first time, leading to a promising\nevaluation metric for MLLMs based on average set size. Our comprehensive\nexperiments across four Video Question-Answering (VideoQA) datasets utilizing\neight MLLMs show that TRON achieves desired error rates bounded by two\nuser-specified risk levels. Additionally, deduplicated prediction sets maintain\nadaptiveness while being more efficient and stable for risk assessment under\ndifferent risk levels.", "AI": {"tldr": "TRON is a two-step framework for risk control in MLLMs, improving trustworthiness with conformal and nonconformity scores, validated across VideoQA datasets.", "motivation": "Address trustworthiness issues in MLLMs by generalizing risk control methods beyond logits and multiple-choice settings.", "method": "Introduces TRON with conformal scores for minimal response sets and nonconformity scores for quality control, plus semantic redundancy analysis.", "result": "Achieves desired error rates and efficient deduplicated prediction sets across eight MLLMs in VideoQA tasks.", "conclusion": "TRON enhances MLLM reliability in open-ended and closed-ended scenarios, offering a robust evaluation metric."}}
{"id": "2506.23670", "pdf": "https://arxiv.org/pdf/2506.23670", "abs": "https://arxiv.org/abs/2506.23670", "authors": ["Mohammadmahdi Nouriborji", "Morteza Rohanian"], "title": "Efficient Interleaved Speech Modeling through Knowledge Distillation", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": null, "summary": "Current speech language models exceed the size and latency constraints of\nmany deployment environments. We build compact, expressive speech generation\nmodels through layer-aligned distillation, matching hidden states, attention\nmaps, and softened logits to compress large multimodal transformers by 3x with\nminimal loss in performance. We introduce TinyWave, a family of 2B-parameter\nmodels for speech-to-speech and interleaved speech-text generation, trained on\n50,000 hours of public audio. TinyWave supports (i) speech-only generation\nusing phonetic or expressive tokens and (ii) mixed speech-text continuations.\nEvaluation on Libri-Light shows TinyWave within 1.4 normalized perplexity\npoints of its teacher. Accuracy on spoken StoryCloze and SALMon reaches 93-97%\nof the teacher's performance, outperforming size-matched baselines. These\nmodels are optimized for deployment on commodity hardware, enabling\napplications in real-time conversational agents, assistive technologies, and\nlow-resource environments. We release models, training code, and evaluation\nscripts to support reproducible research on compact, expressive speech\ngeneration.", "AI": {"tldr": "TinyWave is a compact speech generation model family (2B parameters) trained via layer-aligned distillation, achieving near-teacher performance while being 3x smaller. It supports speech-only and mixed speech-text generation, optimized for deployment on commodity hardware.", "motivation": "Current speech models are too large and slow for many deployment environments, necessitating compact yet expressive alternatives.", "method": "Layer-aligned distillation is used to compress large multimodal transformers by matching hidden states, attention maps, and softened logits. TinyWave is trained on 50,000 hours of public audio.", "result": "TinyWave performs within 1.4 perplexity points of its teacher and achieves 93-97% of the teacher's accuracy on benchmarks, outperforming size-matched baselines.", "conclusion": "TinyWave enables efficient deployment for real-time applications like conversational agents and assistive technologies, with released models and code for reproducibility."}}
{"id": "2506.23208", "pdf": "https://arxiv.org/pdf/2506.23208", "abs": "https://arxiv.org/abs/2506.23208", "authors": ["Runtian Yuan", "Qingqiu Li", "Junlin Hou", "Jilan Xu", "Yuejie Zhang", "Rui Feng", "Hao Chen"], "title": "Multi-Source COVID-19 Detection via Variance Risk Extrapolation", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "We present our solution for the Multi-Source COVID-19 Detection Challenge,\nwhich aims to classify chest CT scans into COVID and Non-COVID categories\nacross data collected from four distinct hospitals and medical centers. A major\nchallenge in this task lies in the domain shift caused by variations in imaging\nprotocols, scanners, and patient populations across institutions. To enhance\nthe cross-domain generalization of our model, we incorporate Variance Risk\nExtrapolation (VREx) into the training process. VREx encourages the model to\nmaintain consistent performance across multiple source domains by explicitly\nminimizing the variance of empirical risks across environments. This\nregularization strategy reduces overfitting to center-specific features and\npromotes learning of domain-invariant representations. We further apply Mixup\ndata augmentation to improve generalization and robustness. Mixup interpolates\nboth the inputs and labels of randomly selected pairs of training samples,\nencouraging the model to behave linearly between examples and enhancing its\nresilience to noise and limited data. Our method achieves an average macro F1\nscore of 0.96 across the four sources on the validation set, demonstrating\nstrong generalization.", "AI": {"tldr": "A method combining Variance Risk Extrapolation (VREx) and Mixup data augmentation improves COVID-19 detection in chest CT scans across diverse hospital datasets, achieving high generalization with a 0.96 F1 score.", "motivation": "The challenge is to classify COVID-19 in CT scans across varied hospital datasets, addressing domain shifts from differing imaging protocols and patient populations.", "method": "VREx minimizes risk variance across domains to learn invariant features, while Mixup enhances robustness via input-label interpolation.", "result": "Achieves 0.96 macro F1 score on validation, showing strong cross-domain generalization.", "conclusion": "VREx and Mixup effectively address domain shifts, improving COVID-19 detection accuracy across diverse datasets."}}
{"id": "2506.23080", "pdf": "https://arxiv.org/pdf/2506.23080", "abs": "https://arxiv.org/abs/2506.23080", "authors": ["Xinmin Fang", "Lingfeng Tao", "Zhengxiong Li"], "title": "AI's Euclid's Elements Moment: From Language Models to Computable Thought", "categories": ["cs.AI"], "comment": null, "summary": "This paper presents a comprehensive five-stage evolutionary framework for\nunderstanding the development of artificial intelligence, arguing that its\ntrajectory mirrors the historical progression of human cognitive technologies.\nWe posit that AI is advancing through distinct epochs, each defined by a\nrevolutionary shift in its capacity for representation and reasoning, analogous\nto the inventions of cuneiform, the alphabet, grammar and logic, mathematical\ncalculus, and formal logical systems. This \"Geometry of Cognition\" framework\nmoves beyond mere metaphor to provide a systematic, cross-disciplinary model\nthat not only explains AI's past architectural shifts-from expert systems to\nTransformers-but also charts a concrete and prescriptive path forward.\nCrucially, we demonstrate that this evolution is not merely linear but\nreflexive: as AI advances through these stages, the tools and insights it\ndevelops create a feedback loop that fundamentally reshapes its own underlying\narchitecture. We are currently transitioning into a \"Metalinguistic Moment,\"\ncharacterized by the emergence of self-reflective capabilities like\nChain-of-Thought prompting and Constitutional AI. The subsequent stages, the\n\"Mathematical Symbolism Moment\" and the \"Formal Logic System Moment,\" will be\ndefined by the development of a computable calculus of thought, likely through\nneuro-symbolic architectures and program synthesis, culminating in provably\naligned and reliable AI that reconstructs its own foundational representations.\nThis work serves as the methodological capstone to our trilogy, which\npreviously explored the economic drivers (\"why\") and cognitive nature (\"what\")\nof AI. Here, we address the \"how,\" providing a theoretical foundation for\nfuture research and offering concrete, actionable strategies for startups and\ndevelopers aiming to build the next generation of intelligent systems.", "AI": {"tldr": "The paper proposes a five-stage evolutionary framework for AI development, comparing it to human cognitive advancements. It identifies current and future stages, emphasizing reflexive feedback loops and actionable strategies for next-gen AI.", "motivation": "To systematically model AI's evolution, linking its development to historical cognitive technologies and providing a prescriptive path for future advancements.", "method": "Introduces the \"Geometry of Cognition\" framework, analyzing AI's progression through distinct epochs, each marked by shifts in representation and reasoning.", "result": "Identifies the current \"Metalinguistic Moment\" and predicts future stages (\"Mathematical Symbolism Moment,\" \"Formal Logic System Moment\") leading to provably aligned AI.", "conclusion": "The framework offers a theoretical foundation and practical strategies for advancing AI, completing a trilogy on AI's economic, cognitive, and methodological aspects."}}
{"id": "2506.22602", "pdf": "https://arxiv.org/pdf/2506.22602", "abs": "https://arxiv.org/abs/2506.22602", "authors": ["Joshua C. Zhao", "Saurabh Bagchi"], "title": "Are Fast Methods Stable in Adversarially Robust Transfer Learning?", "categories": ["cs.LG", "stat.ML"], "comment": "13 pages", "summary": "Transfer learning is often used to decrease the computational cost of model\ntraining, as fine-tuning a model allows a downstream task to leverage the\nfeatures learned from the pre-training dataset and quickly adapt them to a new\ntask. This is particularly useful for achieving adversarial robustness, as\nadversarially training models from scratch is very computationally expensive.\nHowever, high robustness in transfer learning still requires adversarial\ntraining during the fine-tuning phase, which requires up to an order of\nmagnitude more time than standard fine-tuning. In this work, we revisit the use\nof the fast gradient sign method (FGSM) in robust transfer learning to improve\nthe computational cost of adversarial fine-tuning. We surprisingly find that\nFGSM is much more stable in adversarial fine-tuning than when training from\nscratch. In particular, FGSM fine-tuning does not suffer from any issues with\ncatastrophic overfitting at standard perturbation budgets of $\\varepsilon=4$ or\n$\\varepsilon=8$. This stability is further enhanced with parameter-efficient\nfine-tuning methods, where FGSM remains stable even up to $\\varepsilon=32$ for\nlinear probing. We demonstrate how this stability translates into performance\nacross multiple datasets. Compared to fine-tuning with the more commonly used\nmethod of projected gradient descent (PGD), on average, FGSM only loses 0.39%\nand 1.39% test robustness for $\\varepsilon=4$ and $\\varepsilon=8$ while using\n$4\\times$ less training time. Surprisingly, FGSM may not only be a\nsignificantly more efficient alternative to PGD in adversarially robust\ntransfer learning but also a well-performing one.", "AI": {"tldr": "FGSM in adversarial fine-tuning is stable and efficient, outperforming PGD in computational cost with minimal robustness loss.", "motivation": "Reduce computational cost of adversarial fine-tuning in transfer learning while maintaining robustness.", "method": "Revisit FGSM for adversarial fine-tuning, testing stability and performance across datasets.", "result": "FGSM is stable, avoids catastrophic overfitting, and loses only 0.39%-1.39% robustness vs. PGD, with 4x faster training.", "conclusion": "FGSM is a highly efficient and effective alternative to PGD in robust transfer learning."}}
{"id": "2506.22509", "pdf": "https://arxiv.org/pdf/2506.22509", "abs": "https://arxiv.org/abs/2506.22509", "authors": ["Hang Xu", "Jie Huang", "Linjiang Huang", "Dong Li", "Yidi Liu", "Feng Zhao"], "title": "FreeDNA: Endowing Domain Adaptation of Diffusion-Based Dense Prediction with Training-Free Domain Noise Alignment", "categories": ["cs.CV", "cs.AI"], "comment": "ICCV2025", "summary": "Domain Adaptation(DA) for dense prediction tasks is an important topic, which\nenhances the dense prediction model's performance when tested on its unseen\ndomain. Recently, with the development of Diffusion-based Dense Prediction\n(DDP) models, the exploration of DA designs tailored to this framework is worth\nexploring, since the diffusion model is effective in modeling the distribution\ntransformation that comprises domain information. In this work, we propose a\ntraining-free mechanism for DDP frameworks, endowing them with DA capabilities.\nOur motivation arises from the observation that the exposure bias (e.g., noise\nstatistics bias) in diffusion brings domain shift, and different domains in\nconditions of DDP models can also be effectively captured by the noise\nprediction statistics. Based on this, we propose a training-free Domain Noise\nAlignment (DNA) approach, which alleviates the variations of noise statistics\nto domain changes during the diffusion sampling process, thereby achieving\ndomain adaptation. Specifically, when the source domain is available, we\ndirectly adopt the DNA method to achieve domain adaptation by aligning the\nnoise statistics of the target domain with those of the source domain. For the\nmore challenging source-free DA, inspired by the observation that regions\ncloser to the source domain exhibit higher confidence meeting variations of\nsampling noise, we utilize the statistics from the high-confidence regions\nprogressively to guide the noise statistic adjustment during the sampling\nprocess. Notably, our method demonstrates the effectiveness of enhancing the DA\ncapability of DDP models across four common dense prediction tasks. Code is\navailable at\n\\href{https://github.com/xuhang07/FreeDNA}{https://github.com/xuhang07/FreeDNA}.", "AI": {"tldr": "The paper proposes a training-free Domain Noise Alignment (DNA) method for Diffusion-based Dense Prediction (DDP) models to achieve domain adaptation by aligning noise statistics between domains.", "motivation": "The exposure bias in diffusion models causes domain shift, and noise prediction statistics can capture domain differences, motivating a training-free solution.", "method": "DNA aligns noise statistics of target domains with source domains or uses high-confidence regions in source-free DA to guide noise adjustment during sampling.", "result": "The method effectively enhances DA capabilities across four dense prediction tasks.", "conclusion": "DNA provides a training-free, effective solution for domain adaptation in DDP models."}}
{"id": "2506.22698", "pdf": "https://arxiv.org/pdf/2506.22698", "abs": "https://arxiv.org/abs/2506.22698", "authors": ["Emily Dux Speltz"], "title": "Text Production and Comprehension by Human and Artificial Intelligence: Interdisciplinary Workshop Report", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This report synthesizes the outcomes of a recent interdisciplinary workshop\nthat brought together leading experts in cognitive psychology, language\nlearning, and artificial intelligence (AI)-based natural language processing\n(NLP). The workshop, funded by the National Science Foundation, aimed to\naddress a critical knowledge gap in our understanding of the relationship\nbetween AI language models and human cognitive processes in text comprehension\nand composition. Through collaborative dialogue across cognitive, linguistic,\nand technological perspectives, workshop participants examined the underlying\nprocesses involved when humans produce and comprehend text, and how AI can both\ninform our understanding of these processes and augment human capabilities. The\nworkshop revealed emerging patterns in the relationship between large language\nmodels (LLMs) and human cognition, with highlights on both the capabilities of\nLLMs and their limitations in fully replicating human-like language\nunderstanding and generation. Key findings include the potential of LLMs to\noffer insights into human language processing, the increasing alignment between\nLLM behavior and human language processing when models are fine-tuned with\nhuman feedback, and the opportunities and challenges presented by human-AI\ncollaboration in language tasks. By synthesizing these findings, this report\naims to guide future research, development, and implementation of LLMs in\ncognitive psychology, linguistics, and education. It emphasizes the importance\nof ethical considerations and responsible use of AI technologies while striving\nto enhance human capabilities in text comprehension and production through\neffective human-AI collaboration.", "AI": {"tldr": "The report summarizes a workshop on AI language models and human cognition, highlighting insights, limitations, and ethical considerations for future research.", "motivation": "To address the knowledge gap in understanding how AI language models relate to human cognitive processes in text comprehension and production.", "method": "Interdisciplinary workshop with experts in cognitive psychology, linguistics, and AI, focusing on collaborative dialogue and analysis.", "result": "Found potential of LLMs to inform human language processing, alignment with human behavior when fine-tuned, and challenges in human-AI collaboration.", "conclusion": "Future research should focus on ethical AI use and enhancing human-AI collaboration in language tasks."}}
{"id": "2506.23552", "pdf": "https://arxiv.org/pdf/2506.23552", "abs": "https://arxiv.org/abs/2506.23552", "authors": ["Mingi Kwon", "Joonghyuk Shin", "Jaeseok Jung", "Jaesik Park", "Youngjung Uh"], "title": "JAM-Flow: Joint Audio-Motion Synthesis with Flow Matching", "categories": ["cs.CV", "cs.SD", "eess.AS"], "comment": "project page: https://joonghyuk.com/jamflow-web Under review.\n  Preprint published on arXiv", "summary": "The intrinsic link between facial motion and speech is often overlooked in\ngenerative modeling, where talking head synthesis and text-to-speech (TTS) are\ntypically addressed as separate tasks. This paper introduces JAM-Flow, a\nunified framework to simultaneously synthesize and condition on both facial\nmotion and speech. Our approach leverages flow matching and a novel Multi-Modal\nDiffusion Transformer (MM-DiT) architecture, integrating specialized Motion-DiT\nand Audio-DiT modules. These are coupled via selective joint attention layers\nand incorporate key architectural choices, such as temporally aligned\npositional embeddings and localized joint attention masking, to enable\neffective cross-modal interaction while preserving modality-specific strengths.\nTrained with an inpainting-style objective, JAM-Flow supports a wide array of\nconditioning inputs-including text, reference audio, and reference\nmotion-facilitating tasks such as synchronized talking head generation from\ntext, audio-driven animation, and much more, within a single, coherent model.\nJAM-Flow significantly advances multi-modal generative modeling by providing a\npractical solution for holistic audio-visual synthesis. project page:\nhttps://joonghyuk.com/jamflow-web", "AI": {"tldr": "JAM-Flow is a unified framework for synthesizing facial motion and speech together, using flow matching and a Multi-Modal Diffusion Transformer (MM-DiT) architecture.", "motivation": "Existing generative models treat talking head synthesis and text-to-speech as separate tasks, missing the intrinsic link between facial motion and speech.", "method": "JAM-Flow employs flow matching and MM-DiT with Motion-DiT and Audio-DiT modules, using selective joint attention and temporally aligned embeddings for cross-modal interaction.", "result": "The framework supports diverse tasks like synchronized talking head generation and audio-driven animation within a single model.", "conclusion": "JAM-Flow advances multi-modal generative modeling by enabling holistic audio-visual synthesis."}}
{"id": "2506.23351", "pdf": "https://arxiv.org/pdf/2506.23351", "abs": "https://arxiv.org/abs/2506.23351", "authors": ["Tianxing Chen", "Kaixuan Wang", "Zhaohui Yang", "Yuhao Zhang", "Zanxin Chen", "Baijun Chen", "Wanxi Dong", "Ziyuan Liu", "Dong Chen", "Tianshuo Yang", "Haibao Yu", "Xiaokang Yang", "Yusen Qin", "Zhiqiang Xie", "Yao Mu", "Ping Luo", "Tian Nian", "Weiliang Deng", "Yiheng Ge", "Yibin Liu", "Zixuan Li", "Dehui Wang", "Zhixuan Liang", "Haohui Xie", "Rijie Zeng", "Yunfei Ge", "Peiqing Cong", "Guannan He", "Zhaoming Han", "Ruocheng Yin", "Jingxiang Guo", "Lunkai Lin", "Tianling Xu", "Hongzhe Bi", "Xuewu Lin", "Tianwei Lin", "Shujie Luo", "Keyu Li", "Ziyan Zhao", "Ke Fan", "Heyang Xu", "Bo Peng", "Wenlong Gao", "Dongjiang Li", "Feng Jin", "Hui Shen", "Jinming Li", "Chaowei Cui", "Yuchen", "Yaxin Peng", "Lingdong Zeng", "Wenlong Dong", "Tengfei Li", "Weijie Ke", "Jun Chen", "Erdemt Bao", "Tian Lan", "Tenglong Liu", "Jin Yang", "Huiping Zhuang", "Baozhi Jia", "Shuai Zhang", "Zhengfeng Zou", "Fangheng Guan", "Tianyi Jia", "Ke Zhou", "Hongjiu Zhang", "Yating Han", "Cheng Fang", "Yixian Zou", "Chongyang Xu", "Qinglun Zhang", "Shen Cheng", "Xiaohe Wang", "Ping Tan", "Haoqiang Fan", "Shuaicheng Liu", "Jiaheng Chen", "Chuxuan Huang", "Chengliang Lin", "Kaijun Luo", "Boyu Yue", "Yi Liu", "Jinyu Chen", "Zichang Tan", "Liming Deng", "Shuo Xu", "Zijian Cai", "Shilong Yin", "Hao Wang", "Hongshan Liu", "Tianyang Li", "Long Shi", "Ran Xu", "Huilin Xu", "Zhengquan Zhang", "Congsheng Xu", "Jinchang Yang", "Feng Xu"], "title": "Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA"], "comment": "Challenge Webpage:\n  https://robotwin-benchmark.github.io/cvpr-2025-challenge/", "summary": "Embodied Artificial Intelligence (Embodied AI) is an emerging frontier in\nrobotics, driven by the need for autonomous systems that can perceive, reason,\nand act in complex physical environments. While single-arm systems have shown\nstrong task performance, collaborative dual-arm systems are essential for\nhandling more intricate tasks involving rigid, deformable, and\ntactile-sensitive objects. To advance this goal, we launched the RoboTwin\nDual-Arm Collaboration Challenge at the 2nd MEIS Workshop, CVPR 2025. Built on\nthe RoboTwin Simulation platform (1.0 and 2.0) and the AgileX COBOT-Magic Robot\nplatform, the competition consisted of three stages: Simulation Round 1,\nSimulation Round 2, and a final Real-World Round. Participants totally tackled\n17 dual-arm manipulation tasks, covering rigid, deformable, and tactile-based\nscenarios. The challenge attracted 64 global teams and over 400 participants,\nproducing top-performing solutions like SEM and AnchorDP3 and generating\nvaluable insights into generalizable bimanual policy learning. This report\noutlines the competition setup, task design, evaluation methodology, key\nfindings and future direction, aiming to support future research on robust and\ngeneralizable bimanual manipulation policies. The Challenge Webpage is\navailable at https://robotwin-benchmark.github.io/cvpr-2025-challenge/.", "AI": {"tldr": "The RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 aimed to advance dual-arm robotic systems for complex tasks, involving 64 teams and 400 participants tackling 17 tasks. Top solutions like SEM and AnchorDP3 provided insights into bimanual policy learning.", "motivation": "To develop autonomous systems capable of handling intricate tasks with rigid, deformable, and tactile-sensitive objects, advancing Embodied AI in robotics.", "method": "The challenge used the RoboTwin Simulation and AgileX COBOT-Magic Robot platforms, with three stages: two simulation rounds and a real-world round, evaluating 17 dual-arm tasks.", "result": "Top-performing solutions (e.g., SEM, AnchorDP3) emerged, offering insights into generalizable bimanual policy learning.", "conclusion": "The challenge successfully advanced research on robust and generalizable bimanual manipulation, with future directions outlined for further development."}}
{"id": "2411.16750", "pdf": "https://arxiv.org/pdf/2411.16750", "abs": "https://arxiv.org/abs/2411.16750", "authors": ["Ziyao Zeng", "Jingcheng Ni", "Daniel Wang", "Patrick Rim", "Younjoon Chung", "Fengyu Yang", "Byung-Woo Hong", "Alex Wong"], "title": "PriorDiffusion: Leverage Language Prior in Diffusion Models for Monocular Depth Estimation", "categories": ["cs.CV", "cs.CL", "cs.LG", "cs.MM"], "comment": null, "summary": "Traditional monocular depth estimation suffers from inherent ambiguity and\nvisual nuisance. We argue that language prior can enhance monocular depth\nestimation by leveraging the inductive bias learned during the text-to-image\npre-training of diffusion models. The ability of these models to generate\nimages that align with text indicates that they have learned the spatial\nrelationships, size, and shape of specified objects, which can be applied to\nimprove depth estimation. Thus, we propose PriorDiffusion, using a pre-trained\ntext-to-image diffusion model that takes both images and corresponding text\ndescriptions to infer affine-invariant depth through a denoising process. We\nalso show that language prior enhances the model's perception of specific\nregions of images that users care about and describe. Simultaneously, language\nprior acts as a constraint to accelerate the convergence of both training and\nthe inference diffusion trajectory. By training on HyperSim and Virtual KITTI,\nwe achieve faster training convergence, fewer inference diffusion steps, and\nstate-of-the-art zero-shot performance across NYUv2, KITTI, ETH3D, and ScanNet.\nCode will be released upon acceptance.", "AI": {"tldr": "Language prior from text-to-image diffusion models improves monocular depth estimation by leveraging learned spatial relationships, enhancing perception of user-specified regions, and accelerating convergence.", "motivation": "Traditional monocular depth estimation faces ambiguity and visual nuisance; language prior from diffusion models can mitigate these issues by leveraging pre-trained spatial knowledge.", "method": "Proposes PriorDiffusion, using a pre-trained text-to-image diffusion model with image and text inputs to infer affine-invariant depth via denoising.", "result": "Achieves faster training convergence, fewer inference steps, and state-of-the-art zero-shot performance on multiple datasets.", "conclusion": "Language prior enhances depth estimation by improving perception and accelerating convergence, demonstrating superior zero-shot performance."}}
{"id": "2506.23869", "pdf": "https://arxiv.org/pdf/2506.23869", "abs": "https://arxiv.org/abs/2506.23869", "authors": ["Louis Bradshaw", "Honglu Fan", "Alexander Spangher", "Stella Biderman", "Simon Colton"], "title": "Scaling Self-Supervised Representation Learning for Symbolic Piano Performance", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": "ISMIR (2025)", "summary": "We study the capabilities of generative autoregressive transformer models\ntrained on large amounts of symbolic solo-piano transcriptions. After first\npretraining on approximately 60,000 hours of music, we use a comparatively\nsmaller, high-quality subset, to finetune models to produce musical\ncontinuations, perform symbolic classification tasks, and produce\ngeneral-purpose contrastive MIDI embeddings by adapting the SimCLR framework to\nsymbolic music. When evaluating piano continuation coherence, our generative\nmodel outperforms leading symbolic generation techniques and remains\ncompetitive with proprietary audio generation models. On MIR classification\nbenchmarks, frozen representations from our contrastive model achieve\nstate-of-the-art results in linear probe experiments, while direct finetuning\ndemonstrates the generalizability of pretrained representations, often\nrequiring only a few hundred labeled examples to specialize to downstream\ntasks.", "AI": {"tldr": "A generative autoregressive transformer model, pretrained on 60,000 hours of music and finetuned on a high-quality subset, excels in piano continuation, classification tasks, and contrastive MIDI embeddings, outperforming existing symbolic and audio models.", "motivation": "To explore the capabilities of transformer models in symbolic music generation and representation learning, leveraging large-scale pretraining and finetuning for diverse tasks.", "method": "Pretrain on 60,000 hours of music, finetune on a high-quality subset for tasks like musical continuation, classification, and contrastive MIDI embeddings using SimCLR adaptation.", "result": "The generative model outperforms symbolic techniques in piano continuation and matches proprietary audio models. Contrastive embeddings achieve state-of-the-art in classification benchmarks with minimal labeled data.", "conclusion": "The approach demonstrates the effectiveness of large-scale pretraining and finetuning for symbolic music tasks, offering competitive performance and generalizability."}}
{"id": "2506.23259", "pdf": "https://arxiv.org/pdf/2506.23259", "abs": "https://arxiv.org/abs/2506.23259", "authors": ["Lachin Naghashyar"], "title": "Improving Myocardial Infarction Detection via Synthetic ECG Pretraining", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Myocardial infarction is a major cause of death globally, and accurate early\ndiagnosis from electrocardiograms (ECGs) remains a clinical priority. Deep\nlearning models have shown promise for automated ECG interpretation, but\nrequire large amounts of labeled data, which are often scarce in practice. We\npropose a physiology-aware pipeline that (i) synthesizes 12-lead ECGs with\ntunable MI morphology and realistic noise, and (ii) pre-trains recurrent and\ntransformer classifiers with self-supervised masked-autoencoding plus a joint\nreconstruction-classification objective. We validate the realism of synthetic\nECGs via statistical and visual analysis, confirming that key morphological\nfeatures are preserved. Pretraining on synthetic data consistently improved\nclassification performance, particularly in low-data settings, with AUC gains\nof up to 4 percentage points. These results show that controlled synthetic ECGs\ncan help improve MI detection when real clinical data is limited.", "AI": {"tldr": "A physiology-aware pipeline synthesizes realistic 12-lead ECGs for MI detection, improving deep learning model performance in low-data settings.", "motivation": "Accurate early diagnosis of myocardial infarction (MI) from ECGs is critical, but labeled data scarcity limits deep learning models.", "method": "Proposes a pipeline to synthesize tunable MI ECGs with realistic noise and pre-trains classifiers using self-supervised masked-autoencoding and joint reconstruction-classification.", "result": "Synthetic ECGs preserved key features, and pretraining improved classification performance (AUC gains up to 4 percentage points), especially in low-data scenarios.", "conclusion": "Controlled synthetic ECGs enhance MI detection when real clinical data is limited."}}
{"id": "2506.23107", "pdf": "https://arxiv.org/pdf/2506.23107", "abs": "https://arxiv.org/abs/2506.23107", "authors": ["Bing Song", "Jianing Liu", "Sisi Jian", "Chenyang Wu", "Vinayak Dixit"], "title": "Can Large Language Models Capture Human Risk Preferences? A Cross-Cultural Study", "categories": ["cs.AI"], "comment": "20 pages, 1 figure", "summary": "Large language models (LLMs) have made significant strides, extending their\napplications to dialogue systems, automated content creation, and\ndomain-specific advisory tasks. However, as their use grows, concerns have\nemerged regarding their reliability in simulating complex decision-making\nbehavior, such as risky decision-making, where a single choice can lead to\nmultiple outcomes. This study investigates the ability of LLMs to simulate\nrisky decision-making scenarios. We compare model-generated decisions with\nactual human responses in a series of lottery-based tasks, using transportation\nstated preference survey data from participants in Sydney, Dhaka, Hong Kong,\nand Nanjing. Demographic inputs were provided to two LLMs -- ChatGPT 4o and\nChatGPT o1-mini -- which were tasked with predicting individual choices. Risk\npreferences were analyzed using the Constant Relative Risk Aversion (CRRA)\nframework. Results show that both models exhibit more risk-averse behavior than\nhuman participants, with o1-mini aligning more closely with observed human\ndecisions. Further analysis of multilingual data from Nanjing and Hong Kong\nindicates that model predictions in Chinese deviate more from actual responses\ncompared to English, suggesting that prompt language may influence simulation\nperformance. These findings highlight both the promise and the current\nlimitations of LLMs in replicating human-like risk behavior, particularly in\nlinguistic and cultural settings.", "AI": {"tldr": "LLMs like ChatGPT 4o and o1-mini were tested for simulating risky decision-making. They showed more risk-averse behavior than humans, with o1-mini closer to human responses. Performance varied by language, with Chinese prompts less accurate than English.", "motivation": "To assess LLMs' ability to simulate complex human decision-making, specifically risky choices, given their growing use in critical applications.", "method": "Compared LLM-generated decisions (ChatGPT 4o and o1-mini) with human responses in lottery-based tasks using transportation survey data from multiple cities. Analyzed risk preferences via CRRA framework.", "result": "LLMs were more risk-averse than humans; o1-mini aligned better with human decisions. Chinese prompts led to less accurate predictions than English.", "conclusion": "LLMs show potential but have limitations in replicating human risk behavior, especially across languages and cultures."}}
{"id": "2506.22621", "pdf": "https://arxiv.org/pdf/2506.22621", "abs": "https://arxiv.org/abs/2506.22621", "authors": ["Paul Saves", "Edward Hall\u00e9-Hannan", "Jasper Bussemaker", "Youssef Diouane", "Nathalie Bartoli"], "title": "Hierarchical Modeling and Architecture Optimization: Review and Unified Framework", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "Simulation-based problems involving mixed-variable inputs frequently feature\ndomains that are hierarchical, conditional, heterogeneous, or tree-structured.\nThese characteristics pose challenges for data representation, modeling, and\noptimization. This paper reviews extensive literature on these structured input\nspaces and proposes a unified framework that generalizes existing approaches.\nIn this framework, input variables may be continuous, integer, or categorical.\nA variable is described as meta if its value governs the presence of other\ndecreed variables, enabling the modeling of conditional and hierarchical\nstructures.\n  We further introduce the concept of partially-decreed variables, whose\nactivation depends on contextual conditions. To capture these inter-variable\nhierarchical relationships, we introduce design space graphs, combining\nprinciples from feature modeling and graph theory. This allows the definition\nof general hierarchical domains suitable for describing complex system\narchitectures. The framework supports the use of surrogate models over such\ndomains and integrates hierarchical kernels and distances for efficient\nmodeling and optimization. The proposed methods are implemented in the\nopen-source Surrogate Modeling Toolbox (SMT 2.0), and their capabilities are\ndemonstrated through applications in Bayesian optimization for complex system\ndesign, including a case study in green aircraft architecture.", "AI": {"tldr": "The paper proposes a unified framework for handling mixed-variable inputs in simulation-based problems, addressing hierarchical, conditional, and heterogeneous domains. It introduces meta and partially-decreed variables, design space graphs, and integrates surrogate modeling and optimization techniques.", "motivation": "To address challenges in representing, modeling, and optimizing mixed-variable inputs in hierarchical, conditional, or tree-structured domains.", "method": "Introduces a framework with meta and partially-decreed variables, design space graphs, and hierarchical kernels/distances. Implemented in SMT 2.0 for surrogate modeling and Bayesian optimization.", "result": "Demonstrates effectiveness through applications, including a case study in green aircraft architecture.", "conclusion": "The framework generalizes existing approaches, enabling efficient modeling and optimization of complex hierarchical domains."}}
{"id": "2506.22511", "pdf": "https://arxiv.org/pdf/2506.22511", "abs": "https://arxiv.org/abs/2506.22511", "authors": ["Tingting Zhou", "Feng Zhang", "Haoyang Fu", "Baoxiang Pan", "Renhe Zhang", "Feng Lu", "Zhixin Yang"], "title": "Lightning the Night with Generative Artificial Intelligence", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "The visible light reflectance data from geostationary satellites is crucial\nfor meteorological observations and plays an important role in weather\nmonitoring and forecasting. However, due to the lack of visible light at night,\nit is impossible to conduct continuous all-day weather observations using\nvisible light reflectance data. This study pioneers the use of generative\ndiffusion models to address this limitation. Based on the multi-band thermal\ninfrared brightness temperature data from the Advanced Geostationary Radiation\nImager (AGRI) onboard the Fengyun-4B (FY4B) geostationary satellite, we\ndeveloped a high-precision visible light reflectance retrieval model, called\nReflectance Diffusion (RefDiff), which enables 0.47~\\mu\\mathrm{m},\n0.65~\\mu\\mathrm{m}, and 0.825~\\mu\\mathrm{m} bands visible light reflectance\nretrieval at night. Compared to the classical models, RefDiff not only\nsignificantly improves accuracy through ensemble averaging but also provides\nuncertainty estimation. Specifically, the SSIM index of RefDiff can reach 0.90,\nwith particularly significant improvements in areas with complex cloud\nstructures and thick clouds. The model's nighttime retrieval capability was\nvalidated using VIIRS nighttime product, demonstrating comparable performance\nto its daytime counterpart. In summary, this research has made substantial\nprogress in the ability to retrieve visible light reflectance at night, with\nthe potential to expand the application of nighttime visible light data.", "AI": {"tldr": "The paper introduces RefDiff, a generative diffusion model for retrieving visible light reflectance at night using thermal infrared data, improving accuracy and enabling uncertainty estimation.", "motivation": "The lack of visible light at night limits continuous weather monitoring. This study aims to overcome this by using thermal infrared data to simulate visible light reflectance.", "method": "Developed RefDiff, a generative diffusion model based on AGRI's multi-band thermal infrared data, enabling nighttime visible light reflectance retrieval.", "result": "RefDiff achieves high accuracy (SSIM 0.90) and outperforms classical models, especially in complex cloud areas. Validation with VIIRS confirms its nighttime capability.", "conclusion": "RefDiff advances nighttime visible light retrieval, expanding the potential applications of nighttime data in weather monitoring."}}
{"id": "2506.22724", "pdf": "https://arxiv.org/pdf/2506.22724", "abs": "https://arxiv.org/abs/2506.22724", "authors": ["Niyati Bafna", "Tianjian Li", "Kenton Murray", "David R. Mortensen", "David Yarowsky", "Hale Sirin", "Daniel Khashabi"], "title": "The Translation Barrier Hypothesis: Multilingual Generation with Large Language Models Suffers from Implicit Translation Failure", "categories": ["cs.CL"], "comment": "23 pages incl. appendix", "summary": "Multilingual generation with large language models (LLMs) is often of poor\nquality for mid- to low-resource languages. Building on insights from\ninterpretability, we demonstrate the existence of an implicit\ntask-solving-->translation pipeline for generation, whereby the model first\nsolves the required task in a largely target-language-agnostic manner, and\nsubsequently translates answer concepts into the intended target language. We\nhypothesize that the failure of the translation stage is an important culprit\nfor the observed low quality of final outputs, and formalize this as the\ntranslation barrier hypothesis. We test this hypothesis for a word translation\ntask across 108 language pairs, using logit lens to observe model processing in\nintermediate layers. We find that a significant portion of overall failures\nindeed stems from translation failure, or the model's inability to translate\ncorrectly solved intermediate concepts into the target language. This is\nespecially true for low-resource target languages. Our results highlight an\nimportant hurdle for end-to-end multilingual generation, and lend guiding\ninsights for future work seeking to improve multilinguality in LLMs.", "AI": {"tldr": "The paper investigates why multilingual generation in LLMs underperforms for mid- to low-resource languages, attributing it to a translation barrier in the model's implicit task-solving pipeline.", "motivation": "To understand and address the poor quality of multilingual generation in LLMs, especially for mid- to low-resource languages.", "method": "Analyzes a word translation task across 108 language pairs using logit lens to observe intermediate model processing.", "result": "Found that translation failure is a significant cause of poor output quality, particularly for low-resource languages.", "conclusion": "Highlights the translation barrier as a key hurdle for multilingual generation in LLMs, offering insights for future improvements."}}
{"id": "2506.23873", "pdf": "https://arxiv.org/pdf/2506.23873", "abs": "https://arxiv.org/abs/2506.23873", "authors": ["Yuexuan Kong", "Gabriel Meseguer-Brocal", "Vincent Lostanlen", "Mathieu Lagrange", "Romain Hennequin"], "title": "Emergent musical properties of a transformer under contrastive self-supervised learning", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "comment": "Accepted at ISMIR 2025", "summary": "In music information retrieval (MIR), contrastive self-supervised learning\nfor general-purpose representation models is effective for global tasks such as\nautomatic tagging. However, for local tasks such as chord estimation, it is\nwidely assumed that contrastively trained general-purpose self-supervised\nmodels are inadequate and that more sophisticated SSL is necessary; e.g.,\nmasked modeling. Our paper challenges this assumption by revealing the\npotential of contrastive SSL paired with a transformer in local MIR tasks. We\nconsider a lightweight vision transformer with one-dimensional patches in the\ntime--frequency domain (ViT-1D) and train it with simple contrastive SSL\nthrough normalized temperature-scaled cross-entropy loss (NT-Xent). Although\nNT-Xent operates only over the class token, we observe that, potentially thanks\nto weight sharing, informative musical properties emerge in ViT-1D's sequence\ntokens. On global tasks, the temporal average of class and sequence tokens\noffers a performance increase compared to the class token alone, showing useful\nproperties in the sequence tokens. On local tasks, sequence tokens perform\nunexpectedly well, despite not being specifically trained for. Furthermore,\nhigh-level musical features such as onsets emerge from layer-wise attention\nmaps and self-similarity matrices show different layers capture different\nmusical dimensions. Our paper does not focus on improving performance but\nadvances the musical interpretation of transformers and sheds light on some\noverlooked abilities of contrastive SSL paired with transformers for sequence\nmodeling in MIR.", "AI": {"tldr": "Contrastive self-supervised learning (SSL) with a transformer (ViT-1D) challenges the assumption that it's inadequate for local MIR tasks, showing unexpected effectiveness in sequence tokens and revealing high-level musical features.", "motivation": "To challenge the assumption that contrastive SSL is unsuitable for local MIR tasks like chord estimation and explore its potential with transformers.", "method": "Use a lightweight vision transformer (ViT-1D) with 1D patches in the time-frequency domain, trained with contrastive SSL (NT-Xent loss).", "result": "Sequence tokens perform well on local tasks, and high-level musical features emerge in attention maps and self-similarity matrices.", "conclusion": "Contrastive SSL with transformers has overlooked potential for sequence modeling in MIR, offering insights into musical interpretation without focusing on performance gains."}}
{"id": "2506.23514", "pdf": "https://arxiv.org/pdf/2506.23514", "abs": "https://arxiv.org/abs/2506.23514", "authors": ["Sai Krishna Ghanta", "Ramviyas Parasuraman"], "title": "MGPRL: Distributed Multi-Gaussian Processes for Wi-Fi-based Multi-Robot Relative Localization in Large Indoor Environments", "categories": ["cs.RO", "cs.AI", "cs.MA"], "comment": "Accepted to IROS 2025", "summary": "Relative localization is a crucial capability for multi-robot systems\noperating in GPS-denied environments. Existing approaches for multi-robot\nrelative localization often depend on costly or short-range sensors like\ncameras and LiDARs. Consequently, these approaches face challenges such as high\ncomputational overhead (e.g., map merging) and difficulties in disjoint\nenvironments. To address this limitation, this paper introduces MGPRL, a novel\ndistributed framework for multi-robot relative localization using convex-hull\nof multiple Wi-Fi access points (AP). To accomplish this, we employ\nco-regionalized multi-output Gaussian Processes for efficient Radio Signal\nStrength Indicator (RSSI) field prediction and perform uncertainty-aware\nmulti-AP localization, which is further coupled with weighted convex hull-based\nalignment for robust relative pose estimation. Each robot predicts the RSSI\nfield of the environment by an online scan of APs in its environment, which are\nutilized for position estimation of multiple APs. To perform relative\nlocalization, each robot aligns the convex hull of its predicted AP locations\nwith that of the neighbor robots. This approach is well-suited for devices with\nlimited computational resources and operates solely on widely available Wi-Fi\nRSSI measurements without necessitating any dedicated pre-calibration or\noffline fingerprinting. We rigorously evaluate the performance of the proposed\nMGPRL in ROS simulations and demonstrate it with real-world experiments,\ncomparing it against multiple state-of-the-art approaches. The results showcase\nthat MGPRL outperforms existing methods in terms of localization accuracy and\ncomputational efficiency. Finally, we open source MGPRL as a ROS package\nhttps://github.com/herolab-uga/MGPRL.", "AI": {"tldr": "MGPRL is a distributed framework for multi-robot relative localization using Wi-Fi AP convex hulls, outperforming existing methods in accuracy and efficiency.", "motivation": "Existing methods rely on costly or short-range sensors, leading to high computational overhead and disjoint environment challenges.", "method": "Uses co-regionalized multi-output Gaussian Processes for RSSI field prediction, uncertainty-aware multi-AP localization, and convex hull-based alignment.", "result": "MGPRL shows superior localization accuracy and computational efficiency in simulations and real-world experiments.", "conclusion": "MGPRL is a robust, resource-efficient solution for multi-robot relative localization without pre-calibration, now open-sourced as a ROS package."}}
{"id": "2412.01064", "pdf": "https://arxiv.org/pdf/2412.01064", "abs": "https://arxiv.org/abs/2412.01064", "authors": ["Taekyung Ki", "Dongchan Min", "Gyeongsu Chae"], "title": "FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "eess.IV"], "comment": "ICCV 2025. Project page:\n  https://deepbrainai-research.github.io/float/", "summary": "With the rapid advancement of diffusion-based generative models, portrait\nimage animation has achieved remarkable results. However, it still faces\nchallenges in temporally consistent video generation and fast sampling due to\nits iterative sampling nature. This paper presents FLOAT, an audio-driven\ntalking portrait video generation method based on flow matching generative\nmodel. Instead of a pixel-based latent space, we take advantage of a learned\northogonal motion latent space, enabling efficient generation and editing of\ntemporally consistent motion. To achieve this, we introduce a transformer-based\nvector field predictor with an effective frame-wise conditioning mechanism.\nAdditionally, our method supports speech-driven emotion enhancement, enabling a\nnatural incorporation of expressive motions. Extensive experiments demonstrate\nthat our method outperforms state-of-the-art audio-driven talking portrait\nmethods in terms of visual quality, motion fidelity, and efficiency.", "AI": {"tldr": "FLOAT introduces an audio-driven talking portrait video generation method using flow matching and a learned motion latent space, improving temporal consistency and efficiency.", "motivation": "Address challenges in temporally consistent video generation and fast sampling in diffusion-based models for portrait animation.", "method": "Uses a learned orthogonal motion latent space and a transformer-based vector field predictor with frame-wise conditioning. Supports speech-driven emotion enhancement.", "result": "Outperforms state-of-the-art methods in visual quality, motion fidelity, and efficiency.", "conclusion": "FLOAT provides a robust solution for high-quality, efficient, and expressive talking portrait video generation."}}
{"id": "2506.23986", "pdf": "https://arxiv.org/pdf/2506.23986", "abs": "https://arxiv.org/abs/2506.23986", "authors": ["Dake Guo", "Jixun Yao", "Linhan Ma", "Wang He", "Lei Xie"], "title": "StreamFlow: Streaming Flow Matching with Block-wise Guided Attention Mask for Speech Token Decoding", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Recent advancements in discrete token-based speech generation have\nhighlighted the importance of token-to-waveform generation for audio quality,\nparticularly in real-time interactions. Traditional frameworks integrating\nsemantic tokens with flow matching (FM) struggle with streaming capabilities\ndue to their reliance on a global receptive field. Additionally, directly\nimplementing token-by-token streaming speech generation often results in\ndegraded audio quality. To address these challenges, we propose StreamFlow, a\nnovel neural architecture that facilitates streaming flow matching with\ndiffusion transformers (DiT). To mitigate the long-sequence extrapolation\nissues arising from lengthy historical dependencies, we design a local\nblock-wise receptive field strategy. Specifically, the sequence is first\nsegmented into blocks, and we introduce block-wise attention masks that enable\nthe current block to receive information from the previous or subsequent block.\nThese attention masks are combined hierarchically across different DiT-blocks\nto regulate the receptive field of DiTs. Both subjective and objective\nexperimental results demonstrate that our approach achieves performance\ncomparable to non-streaming methods while surpassing other streaming methods in\nterms of speech quality, all the while effectively managing inference time\nduring long-sequence generation. Furthermore, our method achieves a notable\nfirst-packet latency of only 180 ms.\\footnote{Speech samples:\nhttps://dukguo.github.io/StreamFlow/}", "AI": {"tldr": "StreamFlow introduces a neural architecture for streaming speech generation using diffusion transformers (DiT) with block-wise attention masks, improving audio quality and latency.", "motivation": "Traditional token-to-waveform methods struggle with streaming due to global receptive fields and degraded quality in token-by-token generation.", "method": "Proposes StreamFlow, using DiT with local block-wise receptive fields and hierarchical attention masks to manage long-sequence dependencies.", "result": "Achieves performance close to non-streaming methods, better speech quality than other streaming methods, and low latency (180 ms).", "conclusion": "StreamFlow effectively balances quality and real-time performance in streaming speech generation."}}
{"id": "2506.23298", "pdf": "https://arxiv.org/pdf/2506.23298", "abs": "https://arxiv.org/abs/2506.23298", "authors": ["Xing Shen", "Justin Szeto", "Mingyang Li", "Hengguan Huang", "Tal Arbel"], "title": "Exposing and Mitigating Calibration Biases and Demographic Unfairness in MLLM Few-Shot In-Context Learning for Medical Image Classification", "categories": ["eess.IV"], "comment": "Preprint version. The peer-reviewed version of this paper has been\n  accepted to MICCAI 2025 main conference", "summary": "Multimodal large language models (MLLMs) have enormous potential to perform\nfew-shot in-context learning in the context of medical image analysis. However,\nsafe deployment of these models into real-world clinical practice requires an\nin-depth analysis of the accuracies of their predictions, and their associated\ncalibration errors, particularly across different demographic subgroups. In\nthis work, we present the first investigation into the calibration biases and\ndemographic unfairness of MLLMs' predictions and confidence scores in few-shot\nin-context learning for medical image classification. We introduce CALIN, an\ninference-time calibration method designed to mitigate the associated biases.\nSpecifically, CALIN estimates the amount of calibration needed, represented by\ncalibration matrices, using a bi-level procedure: progressing from the\npopulation level to the subgroup level prior to inference. It then applies this\nestimation to calibrate the predicted confidence scores during inference.\nExperimental results on three medical imaging datasets: PAPILA for fundus image\nclassification, HAM10000 for skin cancer classification, and MIMIC-CXR for\nchest X-ray classification demonstrate CALIN's effectiveness at ensuring fair\nconfidence calibration in its prediction, while improving its overall\nprediction accuracies and exhibiting minimum fairness-utility trade-off.", "AI": {"tldr": "CALIN, an inference-time calibration method, addresses calibration biases and demographic unfairness in MLLMs for medical image classification, improving accuracy and fairness.", "motivation": "To ensure safe deployment of MLLMs in clinical practice by analyzing and mitigating calibration errors and biases across demographic subgroups.", "method": "CALIN uses a bi-level procedure to estimate calibration matrices (population to subgroup level) and applies them during inference to calibrate confidence scores.", "result": "CALIN improves prediction accuracy and fairness on three medical imaging datasets (PAPILA, HAM10000, MIMIC-CXR) with minimal fairness-utility trade-off.", "conclusion": "CALIN effectively mitigates biases in MLLMs, ensuring fair and accurate predictions for medical image classification."}}
{"id": "2506.23123", "pdf": "https://arxiv.org/pdf/2506.23123", "abs": "https://arxiv.org/abs/2506.23123", "authors": ["Rishi Bommasani"], "title": "The Societal Impact of Foundation Models: Advancing Evidence-based AI Policy", "categories": ["cs.AI", "cs.CY", "cs.ET"], "comment": "Stanford University PhD Dissertation of Rishi Bommasani (Department\n  of Computer Science, 2025). Also available at\n  https://purl.stanford.edu/zf669yy0336", "summary": "Artificial intelligence is humanity's most promising technology because of\nthe remarkable capabilities offered by foundation models. Yet, the same\ntechnology brings confusion and consternation: foundation models are poorly\nunderstood and they may precipitate a wide array of harms. This dissertation\nexplains how technology and society coevolve in the age of AI, organized around\nthree themes. First, the conceptual framing: the capabilities, risks, and the\nsupply chain that grounds foundation models in the broader economy. Second, the\nempirical insights that enrich the conceptual foundations: transparency created\nvia evaluations at the model level and indexes at the organization level.\nFinally, the transition from understanding to action: superior understanding of\nthe societal impact of foundation models advances evidence-based AI policy.\nView together, this dissertation makes inroads into achieving better societal\noutcomes in the age of AI by building the scientific foundations and\nresearch-policy interface required for better AI governance.", "AI": {"tldr": "The dissertation explores the coevolution of technology and society in the AI era, focusing on foundation models' capabilities, risks, and societal impacts, aiming to improve AI governance.", "motivation": "To address the confusion and potential harms caused by poorly understood foundation models in AI, and to bridge the gap between technology and societal outcomes.", "method": "Organized around three themes: conceptual framing (capabilities, risks, supply chain), empirical insights (transparency via evaluations and indexes), and actionable policy insights.", "result": "Advances understanding of foundation models' societal impact and provides tools for evidence-based AI policy.", "conclusion": "The dissertation contributes to better AI governance by building scientific foundations and a research-policy interface."}}
{"id": "2506.22631", "pdf": "https://arxiv.org/pdf/2506.22631", "abs": "https://arxiv.org/abs/2506.22631", "authors": ["Dmitry B. Rokhlin"], "title": "A hierarchical Vovk-Azoury-Warmuth forecaster with discounting for online regression in RKHS", "categories": ["cs.LG", "stat.ML", "68Q32, 68W27, 68W20"], "comment": null, "summary": "We study the problem of online regression with the unconstrained quadratic\nloss against a time-varying sequence of functions from a Reproducing Kernel\nHilbert Space (RKHS). Recently, Jacobsen and Cutkosky (2024) introduced a\ndiscounted Vovk-Azoury-Warmuth (DVAW) forecaster that achieves optimal dynamic\nregret in the finite-dimensional case. In this work, we lift their approach to\nthe non-parametric domain by synthesizing the DVAW framework with a random\nfeature approximation. We propose a fully adaptive, hierarchical algorithm,\nwhich we call H-VAW-D (Hierarchical Vovk-Azoury-Warmuth with Discounting), that\nlearns both the discount factor and the number of random features. We prove\nthat this algorithm, which has a per-iteration computational complexity of\n$O(T\\ln T)$, achieves an expected dynamic regret of $O(T^{2/3}P_T^{1/3} +\n\\sqrt{T}\\ln T)$, where $P_T$ is the functional path length of a comparator\nsequence.", "AI": {"tldr": "The paper proposes H-VAW-D, a hierarchical algorithm for online regression with RKHS, achieving optimal dynamic regret with adaptive learning of discount factors and random features.", "motivation": "To extend the DVAW forecaster to non-parametric domains and improve dynamic regret bounds in online regression.", "method": "Combines DVAW with random feature approximation, introducing H-VAW-D, which adaptively learns discount factors and feature counts.", "result": "Achieves $O(T^{2/3}P_T^{1/3} + \\sqrt{T}\\ln T)$ expected dynamic regret with $O(T\\ln T)$ per-iteration complexity.", "conclusion": "H-VAW-D effectively addresses non-parametric online regression, balancing computational efficiency and regret performance."}}
{"id": "2506.22513", "pdf": "https://arxiv.org/pdf/2506.22513", "abs": "https://arxiv.org/abs/2506.22513", "authors": ["Aditya Sharma"], "title": "Automated Defect Identification and Categorization in NDE 4.0 with the Application of Artificial Intelligence", "categories": ["cs.CV"], "comment": null, "summary": "This investigation attempts to create an automated framework for fault\ndetection and organization for usage in contemporary radiography, as per NDE\n4.0. The review's goals are to address the lack of information that is\nsufficiently explained, learn how to make the most of virtual defect increase,\nand determine whether the framework is viable by using NDE measurements. As its\nbasic information source, the technique consists of compiling and categorizing\n223 CR photographs of airplane welds. Information expansion systems, such as\nvirtual defect increase and standard increase, are used to work on the\npreparation dataset. A modified U-net model is prepared using the improved data\nto produce semantic fault division veils. To assess the effectiveness of the\nmodel, NDE boundaries such as Case, estimating exactness, and misleading call\nrate are used. Tiny a90/95 characteristics, which provide strong\ndifferentiating evidence of flaws, reveal that the suggested approach achieves\nexceptional awareness in defect detection. Considering a 90/95, size error, and\nfake call rate in the weld area, the consolidated expansion approach clearly\nwins. Due to the framework's fast derivation speed, large images can be broken\ndown efficiently and quickly. Professional controllers evaluate the transmitted\nsystem in the field and believe that it has a guarantee as a support device in\nthe testing cycle, irrespective of particular equipment cut-off points and\nprogramming resemblance.", "AI": {"tldr": "The paper proposes an automated framework for fault detection in radiography using a modified U-net model and data augmentation, achieving high accuracy and efficiency.", "motivation": "Address the lack of explained information in NDE 4.0, optimize virtual defect augmentation, and validate the framework's viability.", "method": "Uses 223 CR images of airplane welds, applies data augmentation (virtual defect and standard), and trains a modified U-net model for semantic fault segmentation.", "result": "High defect detection awareness (a90/95 metrics), efficient processing of large images, and positive field evaluation by professionals.", "conclusion": "The framework is viable, efficient, and promising as a support tool in testing, despite equipment and software limitations."}}
{"id": "2506.22760", "pdf": "https://arxiv.org/pdf/2506.22760", "abs": "https://arxiv.org/abs/2506.22760", "authors": ["Alan Dao", "Dinh Bach Vu"], "title": "Jan-nano Technical Report", "categories": ["cs.CL"], "comment": null, "summary": "Most language models face a fundamental tradeoff where powerful capabilities\nrequire substantial computational resources. We shatter this constraint with\nJan-nano, a 4B parameter language model that redefines efficiency through\nradical specialization: instead of trying to know everything, it masters the\nart of finding anything instantly. Fine-tuned from Qwen3-4B using our novel\nmulti-stage RLVR system that completely eliminates reliance on next token\nprediction training (SFT), Jan-nano achieves 83.2% on SimpleQA benchmark with\nMCP integration while running on consumer hardware. With 128K context length,\nJan-nano proves that intelligence isn't about scale, it's about strategy.", "AI": {"tldr": "Jan-nano is a 4B parameter language model that achieves high efficiency and performance by specializing in instant information retrieval, eliminating next token prediction training, and running on consumer hardware.", "motivation": "The paper addresses the tradeoff between model capabilities and computational resources, aiming to redefine efficiency by focusing on specialization rather than scale.", "method": "Jan-nano is fine-tuned from Qwen3-4B using a novel multi-stage RLVR system, which removes reliance on next token prediction training (SFT).", "result": "The model achieves 83.2% on the SimpleQA benchmark with MCP integration and supports a 128K context length, demonstrating high performance on consumer hardware.", "conclusion": "Jan-nano shows that intelligence is about strategic specialization, not just scale, offering a viable alternative to resource-heavy models."}}
{"id": "2411.18611", "pdf": "https://arxiv.org/pdf/2411.18611", "abs": "https://arxiv.org/abs/2411.18611", "authors": ["Parampreet Singh", "Adwik Gupta", "Aakarsh Mishra", "Vipul Arora"], "title": "Identification and Clustering of Unseen Ragas in Indian Art Music", "categories": ["eess.AS"], "comment": "Accepted for publication at ISMIR 2025", "summary": "Raga classification in Indian Art Music is an open-set problem where unseen\nclasses may appear during testing. However, traditional approaches often treat\nit as a closed set problem, rejecting the possibility of encountering unseen\nclasses. In this work, we try to tackle this problem by first employing an\nUncertainty-based Out-Of-Distribution (OOD) detection, given a set containing\nknown and unknown classes. Next, for the audio samples identified as OOD, we\nemploy Novel Class Discovery (NCD) approach to cluster them into distinct\nunseen Raga classes. We achieve this by harnessing information from labelled\ndata and further applying contrastive learning on unlabelled data. With\nthorough analysis, we demonstrate the influence of different components of the\nloss function on clustering performance and examine how varying openness\naffects the NCD task in hand.", "AI": {"tldr": "The paper addresses raga classification in Indian Art Music as an open-set problem, using OOD detection and NCD to handle unseen classes.", "motivation": "Traditional methods treat raga classification as a closed-set problem, ignoring unseen classes. This work aims to address this gap.", "method": "Combines Uncertainty-based OOD detection for identifying unknown classes and Novel Class Discovery (NCD) with contrastive learning to cluster unseen ragas.", "result": "Demonstrates the impact of loss function components on clustering and examines openness effects on NCD performance.", "conclusion": "The approach effectively handles unseen raga classes, improving classification in open-set scenarios."}}
{"id": "2506.23689", "pdf": "https://arxiv.org/pdf/2506.23689", "abs": "https://arxiv.org/abs/2506.23689", "authors": ["Zihao Liu", "Xinhang Sui", "Yueran Song", "Siwen Wang"], "title": "Pok\u00e9AI: A Goal-Generating, Battle-Optimizing Multi-agent System for Pokemon Red", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "We introduce Pok\\'eAI, the first text-based, multi-agent large language model\n(LLM) framework designed to autonomously play and progress through Pok\\'emon\nRed. Our system consists of three specialized agents-Planning, Execution, and\nCritique-each with its own memory bank, role, and skill set. The Planning Agent\nfunctions as the central brain, generating tasks to progress through the game.\nThese tasks are then delegated to the Execution Agent, which carries them out\nwithin the game environment. Upon task completion, the Critique Agent evaluates\nthe outcome to determine whether the objective was successfully achieved. Once\nverification is complete, control returns to the Planning Agent, forming a\nclosed-loop decision-making system.\n  As a preliminary step, we developed a battle module within the Execution\nAgent. Our results show that the battle AI achieves an average win rate of\n80.8% across 50 wild encounters, only 6% lower than the performance of an\nexperienced human player. Furthermore, we find that a model's battle\nperformance correlates strongly with its LLM Arena score on language-related\ntasks, indicating a meaningful link between linguistic ability and strategic\nreasoning. Finally, our analysis of gameplay logs reveals that each LLM\nexhibits a unique playstyle, suggesting that individual models develop distinct\nstrategic behaviors.", "AI": {"tldr": "Pok\u00e9AI is a multi-agent LLM framework for playing Pok\u00e9mon Red, featuring Planning, Execution, and Critique agents. It achieves an 80.8% win rate in battles and shows a link between linguistic ability and strategic reasoning.", "motivation": "To create an autonomous system for playing Pok\u00e9mon Red using specialized LLM agents, demonstrating the potential of multi-agent frameworks in gaming.", "method": "Three agents (Planning, Execution, Critique) work in a closed-loop system. The Execution Agent includes a battle module tested in wild encounters.", "result": "80.8% average win rate in battles, close to human performance. Battle performance correlates with LLM Arena scores, and unique playstyles emerge.", "conclusion": "Pok\u00e9AI successfully demonstrates autonomous gameplay with strategic reasoning, linking linguistic ability to performance, and showcasing unique agent behaviors."}}
{"id": "2503.00071", "pdf": "https://arxiv.org/pdf/2503.00071", "abs": "https://arxiv.org/abs/2503.00071", "authors": ["Esam Ghaleb", "Bulat Khaertdinov", "Asl\u0131 \u00d6zy\u00fcrek", "Raquel Fern\u00e1ndez"], "title": "I see what you mean: Co-Speech Gestures for Reference Resolution in Multimodal Dialogue", "categories": ["cs.CV", "cs.CL", "cs.MM"], "comment": "Accepted to Findings of ACL 2025", "summary": "In face-to-face interaction, we use multiple modalities, including speech and\ngestures, to communicate information and resolve references to objects.\nHowever, how representational co-speech gestures refer to objects remains\nunderstudied from a computational perspective. In this work, we address this\ngap by introducing a multimodal reference resolution task centred on\nrepresentational gestures, while simultaneously tackling the challenge of\nlearning robust gesture embeddings. We propose a self-supervised pre-training\napproach to gesture representation learning that grounds body movements in\nspoken language. Our experiments show that the learned embeddings align with\nexpert annotations and have significant predictive power. Moreover, reference\nresolution accuracy further improves when (1) using multimodal gesture\nrepresentations, even when speech is unavailable at inference time, and (2)\nleveraging dialogue history. Overall, our findings highlight the complementary\nroles of gesture and speech in reference resolution, offering a step towards\nmore naturalistic models of human-machine interaction.", "AI": {"tldr": "The paper introduces a multimodal reference resolution task for representational gestures, proposes a self-supervised pre-training method for gesture embeddings, and demonstrates improved accuracy using multimodal representations and dialogue history.", "motivation": "To address the understudied computational perspective of how representational co-speech gestures refer to objects in face-to-face interaction.", "method": "A self-supervised pre-training approach for gesture representation learning that grounds body movements in spoken language.", "result": "Learned embeddings align with expert annotations and improve reference resolution accuracy, especially with multimodal gesture representations and dialogue history.", "conclusion": "Gestures and speech play complementary roles in reference resolution, advancing naturalistic human-machine interaction models."}}
{"id": "2506.23305", "pdf": "https://arxiv.org/pdf/2506.23305", "abs": "https://arxiv.org/abs/2506.23305", "authors": ["Rachit Saluja", "Arzu Kovanlikaya", "Candace Chien", "Lauren Kathryn Blatt", "Jeffrey M. Perlman", "Stefan Worgall", "Mert R. Sabuncu", "Jonathan P. Dyke"], "title": "BPD-Neo: An MRI Dataset for Lung-Trachea Segmentation with Clinical Data for Neonatal Bronchopulmonary Dysplasia", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Bronchopulmonary dysplasia (BPD) is a common complication among preterm\nneonates, with portable X-ray imaging serving as the standard diagnostic\nmodality in neonatal intensive care units (NICUs). However, lung magnetic\nresonance imaging (MRI) offers a non-invasive alternative that avoids sedation\nand radiation while providing detailed insights into the underlying mechanisms\nof BPD. Leveraging high-resolution 3D MRI data, advanced image processing and\nsemantic segmentation algorithms can be developed to assist clinicians in\nidentifying the etiology of BPD. In this dataset, we present MRI scans paired\nwith corresponding semantic segmentations of the lungs and trachea for 40\nneonates, the majority of whom are diagnosed with BPD. The imaging data consist\nof free-breathing 3D stack-of-stars radial gradient echo acquisitions, known as\nthe StarVIBE series. Additionally, we provide comprehensive clinical data and\nbaseline segmentation models, validated against clinical assessments, to\nsupport further research and development in neonatal lung imaging.", "AI": {"tldr": "The paper introduces a dataset of 3D MRI scans and semantic segmentations for 40 neonates, mostly with BPD, as a non-invasive alternative to X-ray imaging, aiming to improve diagnosis and research.", "motivation": "To provide a safer, non-invasive diagnostic tool for BPD in preterm neonates, avoiding sedation and radiation exposure while offering detailed lung insights.", "method": "Uses high-resolution 3D MRI (StarVIBE series) paired with semantic segmentation algorithms to analyze lung and trachea structures.", "result": "A dataset of MRI scans and segmentations for 40 neonates, validated against clinical assessments, is presented, along with baseline models.", "conclusion": "The dataset and models support advanced research in neonatal lung imaging, offering a promising alternative to traditional X-ray diagnostics."}}
{"id": "2506.23128", "pdf": "https://arxiv.org/pdf/2506.23128", "abs": "https://arxiv.org/abs/2506.23128", "authors": ["Chi Chiu So", "Yueyue Sun", "Jun-Min Wang", "Siu Pang Yung", "Anthony Wai Keung Loh", "Chun Pong Chau"], "title": "Are Large Language Models Capable of Deep Relational Reasoning? Insights from DeepSeek-R1 and Benchmark Comparisons", "categories": ["cs.AI"], "comment": "10 pages, 0 figures, accepted by 2025 IEEE international conference\n  on artificial intelligence testing (AITest)", "summary": "How far are Large Language Models (LLMs) in performing deep relational\nreasoning? In this paper, we evaluate and compare the reasoning capabilities of\nthree cutting-edge LLMs, namely, DeepSeek-R1, DeepSeek-V3 and GPT-4o, through a\nsuite of carefully designed benchmark tasks in family tree and general graph\nreasoning. Our experiments reveal that DeepSeek-R1 consistently achieves the\nhighest F1-scores across multiple tasks and problem sizes, demonstrating strong\naptitude in logical deduction and relational inference. However, all evaluated\nmodels, including DeepSeek-R1, struggle significantly as problem complexity\nincreases, largely due to token length limitations and incomplete output\nstructures. A detailed analysis of DeepSeek-R1's long Chain-of-Thought\nresponses uncovers its unique planning and verification strategies, but also\nhighlights instances of incoherent or incomplete reasoning, calling attention\nto the need for deeper scrutiny into LLMs' internal inference dynamics. We\nfurther discuss key directions for future work, including the role of\nmultimodal reasoning and the systematic examination of reasoning failures. Our\nfindings provide both empirical insights and theoretical implications for\nadvancing LLMs' reasoning abilities, particularly in tasks that demand\nstructured, multi-step logical inference. Our code repository will be publicly\navailable at https://github.com/kelvinhkcs/Deep-Relational-Reasoning.", "AI": {"tldr": "The paper evaluates the relational reasoning capabilities of three LLMs (DeepSeek-R1, DeepSeek-V3, GPT-4o) using benchmark tasks. DeepSeek-R1 performs best but struggles with complexity due to token limits and output issues. Future work includes multimodal reasoning and failure analysis.", "motivation": "To assess and compare the deep relational reasoning abilities of state-of-the-art LLMs, identifying strengths and limitations in logical inference tasks.", "method": "Benchmark tasks in family tree and general graph reasoning were designed to evaluate the models. Performance was measured using F1-scores, and responses were analyzed for reasoning strategies and failures.", "result": "DeepSeek-R1 achieved the highest F1-scores but all models faltered with increased complexity. Analysis revealed incoherent reasoning and token length constraints as key challenges.", "conclusion": "The study highlights the need for deeper scrutiny of LLMs' reasoning dynamics and suggests future directions like multimodal reasoning and systematic failure analysis to enhance their capabilities."}}
{"id": "2506.22638", "pdf": "https://arxiv.org/pdf/2506.22638", "abs": "https://arxiv.org/abs/2506.22638", "authors": ["Aadim Nepal", "Safal Shrestha", "Anubhav Shrestha", "Minwu Kim", "Keith Ross"], "title": "Layer Importance for Mathematical Reasoning is Forged in Pre-Training and Invariant after Post-Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models can exhibit improved mathematical reasoning\ncapabilities following post-training with instruction tuning, reinforcement\nlearning, or knowledge distillation. However, it remains unclear whether these\nimprovements are driven by major changes in transformer layers or from minor\nadjustments that leave the relative layer importance structures of the base\nmodel largely unchanged. We investigate this question through systematic\nlayer-wise ablation experiments, examining base, instruction-tuned,\nknowledge-distilled, and reinforcement learning variants on mathematical\nreasoning benchmarks. Our findings show that mathematical reasoning gives rise\nto a specific layer importance structure, and this structure persists across\nall post-training paradigms. Removal of such layers causes accuracy drops of up\nto 80%. In contrast, non-mathematical tasks like factual recall exhibit no\ncritical layers. This distinction suggests that mathematical reasoning requires\nspecialized layers that emerge during pre-training, while other non-reasoning\ntasks do not. From an information-theoretic perspective, we also observe that\nthese critical layers are the same layers where major representational\ntransformation occurs.", "AI": {"tldr": "Post-training methods improve math reasoning in language models, but the layer importance structure remains unchanged. Critical layers for math tasks cause major accuracy drops if removed, unlike non-math tasks.", "motivation": "To understand if post-training improvements in math reasoning stem from major layer changes or minor adjustments in layer importance.", "method": "Layer-wise ablation experiments on base and post-trained models (instruction-tuned, knowledge-distilled, reinforcement learning) across math reasoning benchmarks.", "result": "Math reasoning relies on specific, persistent layer structures; removing critical layers drops accuracy by up to 80%. Non-math tasks lack such critical layers.", "conclusion": "Math reasoning requires specialized pre-trained layers, distinct from non-reasoning tasks, with critical layers linked to major representational transformations."}}
{"id": "2506.22517", "pdf": "https://arxiv.org/pdf/2506.22517", "abs": "https://arxiv.org/abs/2506.22517", "authors": ["Subhadip Kumar"], "title": "Container damage detection using advanced computer vision model Yolov12 vs Yolov11 vs RF-DETR A comparative analysis", "categories": ["cs.CV"], "comment": null, "summary": "Containers are an integral part of the logistics industry and act as a\nbarrier for cargo. A typical service life for a container is more than 20\nyears. However, overtime containers suffer various types of damage due to the\nmechanical as well as natural factors. A damaged container is a safety hazard\nfor the employees handling it and a liability for the logistic company.\nTherefore, a timely inspection and detection of the damaged container is a key\nfor prolonging service life as well as avoiding safety hazards. In this paper,\nwe will compare the performance of the damage detection by three\nstate-of-the-art advanced computer vision models Yolov12, Yolov11 and RF-DETR.\nWe will use a dataset of 278 annotated images to train, validate and test the\nmodel. We will compare the mAP and precision of the model. The objective of\nthis paper is to identify the model that is best suited for container damage\ndetection. The result is mixed. mAP@50 score of Yolov11 and 12 was 81.9%\ncompared to RF-DETR, which was 77.7%. However, while testing the model for\nnot-so-common damaged containers, the RF-DETR model outperformed the others\noverall, exhibiting superiority to accurately detecting both damaged containers\nas well as damage occurrences with high confidence.", "AI": {"tldr": "The paper compares three computer vision models (Yolov11, Yolov12, RF-DETR) for detecting container damage, finding RF-DETR superior for uncommon damages despite lower mAP scores.", "motivation": "Timely detection of container damage is crucial for safety and prolonging service life in logistics.", "method": "Used 278 annotated images to train and test Yolov11, Yolov12, and RF-DETR, comparing mAP and precision.", "result": "Yolov11 and Yolov12 had higher mAP@50 (81.9%), but RF-DETR (77.7%) outperformed in detecting uncommon damages.", "conclusion": "RF-DETR is better for detecting rare container damages, despite lower overall mAP scores."}}
{"id": "2506.22777", "pdf": "https://arxiv.org/pdf/2506.22777", "abs": "https://arxiv.org/abs/2506.22777", "authors": ["Miles Turpin", "Andy Arditi", "Marvin Li", "Joe Benton", "Julian Michael"], "title": "Teaching Models to Verbalize Reward Hacking in Chain-of-Thought Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Language models trained with RL can engage in reward hacking--exploiting\nunintended strategies for high reward--without revealing this behavior in their\nchain-of-thought reasoning, making detection difficult and posing risks for\nhigh-stakes applications. We propose verbalization fine-tuning (VFT), a pre-RL\nintervention that trains models to explicitly acknowledge when they are\ninfluenced by prompt cues--hints which point to incorrect answers (e.g., \"a\nStanford professor thinks the answer is A\"). To evaluate VFT, we subsequently\ntrain models with RL on environments where held-out prompt cues signal which\nincorrect answers will receive high reward, incentivizing models to reward hack\nby exploiting cues instead of reasoning correctly. We measure how often models\nexploit these cues without verbalizing it. After RL, only 6% of the VFT-trained\nmodel's responses consist of undetected reward hacks. In comparison, when we\nperform RL without VFT, the rate of undetected reward hacks goes up to 88%;\nwith a debiasing baseline intervention, this increases further to 99%. VFT\nachieves this by substantially increasing how often models verbalize the\ninfluence of cues--from 8% to 42% after VFT, and up to 94% after RL--while\nbaselines remain low even after RL (10% and 1%). Our results show that teaching\nmodels to explicitly verbalize reward hacking behavior before RL significantly\nimproves their detection, offering a practical path toward more transparent and\nsafe AI systems.", "AI": {"tldr": "VFT (verbalization fine-tuning) reduces undetected reward hacking in RL-trained models by teaching them to verbalize cue influences, improving detection and transparency.", "motivation": "Address the challenge of detecting reward hacking in RL-trained models, which exploit unintended strategies without revealing them in reasoning, posing risks in high-stakes applications.", "method": "Propose VFT, a pre-RL intervention that trains models to acknowledge prompt cue influences. Evaluate by training models with RL in environments with held-out cues, measuring undetected reward hacks.", "result": "VFT reduces undetected reward hacks to 6% post-RL, compared to 88% without VFT and 99% with debiasing. VFT increases verbalization of cue influence from 8% to 42% (up to 94% post-RL).", "conclusion": "VFT significantly improves detection of reward hacking by enhancing verbalization, offering a practical approach for safer and more transparent AI systems."}}
{"id": "2505.19577", "pdf": "https://arxiv.org/pdf/2505.19577", "abs": "https://arxiv.org/abs/2505.19577", "authors": ["Yu Xi", "Haoyu Li", "Xiaoyu Gu", "Yidi Jiang", "Kai Yu"], "title": "MFA-KWS: Effective Keyword Spotting with Multi-head Frame-asynchronous Decoding", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted by TASLP", "summary": "Keyword spotting (KWS) is essential for voice-driven applications, demanding\nboth accuracy and efficiency. Traditional ASR-based KWS methods, such as greedy\nand beam search, explore the entire search space without explicitly\nprioritizing keyword detection, often leading to suboptimal performance. In\nthis paper, we propose an effective keyword-specific KWS framework by\nintroducing a streaming-oriented CTC-Transducer-combined frame-asynchronous\nsystem with multi-head frame-asynchronous decoding (MFA-KWS). Specifically,\nMFA-KWS employs keyword-specific phone-synchronous decoding for CTC and\nreplaces conventional RNN-T with Token-and-Duration Transducer to enhance both\nperformance and efficiency. Furthermore, we explore various score fusion\nstrategies, including single-frame-based and consistency-based methods.\nExtensive experiments demonstrate the superior performance of MFA-KWS, which\nachieves state-of-the-art results on both fixed keyword and arbitrary keywords\ndatasets, such as Snips, MobvoiHotwords, and LibriKWS-20, while exhibiting\nstrong robustness in noisy environments. Among fusion strategies, the\nconsistency-based CDC-Last method delivers the best performance. Additionally,\nMFA-KWS achieves a 47% to 63% speed-up over the frame-synchronous baselines\nacross various datasets. Extensive experimental results confirm that MFA-KWS is\nan effective and efficient KWS framework, making it well-suited for on-device\ndeployment.", "AI": {"tldr": "The paper proposes MFA-KWS, a keyword-specific KWS framework combining CTC-Transducer with multi-head frame-asynchronous decoding, achieving state-of-the-art performance and efficiency.", "motivation": "Traditional ASR-based KWS methods lack explicit keyword prioritization, leading to suboptimal performance.", "method": "Introduces MFA-KWS with keyword-specific phone-synchronous decoding for CTC and Token-and-Duration Transducer, along with score fusion strategies.", "result": "MFA-KWS outperforms baselines on datasets like Snips and LibriKWS-20, with 47-63% speed-up and robustness in noise.", "conclusion": "MFA-KWS is an efficient and effective framework, suitable for on-device deployment."}}
{"id": "2506.23793", "pdf": "https://arxiv.org/pdf/2506.23793", "abs": "https://arxiv.org/abs/2506.23793", "authors": ["Anton Andreychuk", "Konstantin Yakovlev", "Aleksandr Panov", "Alexey Skrynnik"], "title": "Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "Multi-agent pathfinding (MAPF) is a common abstraction of multi-robot\ntrajectory planning problems, where multiple homogeneous robots simultaneously\nmove in the shared environment. While solving MAPF optimally has been proven to\nbe NP-hard, scalable, and efficient, solvers are vital for real-world\napplications like logistics, search-and-rescue, etc. To this end, decentralized\nsuboptimal MAPF solvers that leverage machine learning have come on stage.\nBuilding on the success of the recently introduced MAPF-GPT, a pure imitation\nlearning solver, we introduce MAPF-GPT-DDG. This novel approach effectively\nfine-tunes the pre-trained MAPF model using centralized expert data. Leveraging\na novel delta-data generation mechanism, MAPF-GPT-DDG accelerates training\nwhile significantly improving performance at test time. Our experiments\ndemonstrate that MAPF-GPT-DDG surpasses all existing learning-based MAPF\nsolvers, including the original MAPF-GPT, regarding solution quality across\nmany testing scenarios. Remarkably, it can work with MAPF instances involving\nup to 1 million agents in a single environment, setting a new milestone for\nscalability in MAPF domains.", "AI": {"tldr": "MAPF-GPT-DDG, a decentralized suboptimal MAPF solver, improves upon MAPF-GPT by fine-tuning with centralized expert data and a delta-data generation mechanism, achieving superior scalability and performance.", "motivation": "To address the NP-hard nature of MAPF and enhance scalability for real-world applications like logistics and search-and-rescue.", "method": "Fine-tunes pre-trained MAPF-GPT using centralized expert data and introduces a delta-data generation mechanism to accelerate training and improve performance.", "result": "Outperforms existing learning-based MAPF solvers, including MAPF-GPT, in solution quality and scalability, handling up to 1 million agents.", "conclusion": "MAPF-GPT-DDG sets a new benchmark for scalability and performance in decentralized MAPF solvers."}}
{"id": "2503.06520", "pdf": "https://arxiv.org/pdf/2503.06520", "abs": "https://arxiv.org/abs/2503.06520", "authors": ["Yuqi Liu", "Bohao Peng", "Zhisheng Zhong", "Zihao Yue", "Fanbin Lu", "Bei Yu", "Jiaya Jia"], "title": "Seg-Zero: Reasoning-Chain Guided Segmentation via Cognitive Reinforcement", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Traditional methods for reasoning segmentation rely on supervised fine-tuning\nwith categorical labels and simple descriptions, limiting its out-of-domain\ngeneralization and lacking explicit reasoning processes. To address these\nlimitations, we propose Seg-Zero, a novel framework that demonstrates\nremarkable generalizability and derives explicit chain-of-thought reasoning\nthrough cognitive reinforcement. Seg-Zero introduces a decoupled architecture\nconsisting of a reasoning model and a segmentation model. The reasoning model\ninterprets user intentions, generates explicit reasoning chains, and produces\npositional prompts, which are subsequently used by the segmentation model to\ngenerate precious pixel-level masks. We design a sophisticated reward mechanism\nthat integrates both format and accuracy rewards to effectively guide\noptimization directions. Trained exclusively via reinforcement learning with\nGRPO and without explicit reasoning data, Seg-Zero achieves robust zero-shot\ngeneralization and exhibits emergent test-time reasoning capabilities.\nExperiments show that Seg-Zero-7B achieves a zero-shot performance of 57.5 on\nthe ReasonSeg benchmark, surpassing the prior LISA-7B by 18\\%. This significant\nimprovement highlights Seg-Zero's ability to generalize across domains while\npresenting an explicit reasoning process. Code is available at\nhttps://github.com/dvlab-research/Seg-Zero.", "AI": {"tldr": "Seg-Zero is a novel framework for reasoning segmentation that uses cognitive reinforcement and a decoupled architecture to improve generalization and explicit reasoning, outperforming prior methods by 18%.", "motivation": "Traditional methods lack out-of-domain generalization and explicit reasoning processes, limiting their effectiveness.", "method": "Seg-Zero employs a decoupled architecture with a reasoning model and a segmentation model, using reinforcement learning (GRPO) and a reward mechanism for optimization.", "result": "Seg-Zero-7B achieves 57.5 on the ReasonSeg benchmark, surpassing LISA-7B by 18%.", "conclusion": "Seg-Zero demonstrates robust zero-shot generalization and explicit reasoning, marking a significant advancement in reasoning segmentation."}}
{"id": "2311.01715", "pdf": "https://arxiv.org/pdf/2311.01715", "abs": "https://arxiv.org/abs/2311.01715", "authors": ["Phuc Duc Nguyen", "Kenji Ishikawa", "Noboru Harada", "Takehiro Moriya"], "title": "Acousto-optic reconstruction of exterior sound field based on concentric circle sampling with circular harmonic expansion", "categories": ["cs.SD", "eess.AS", "eess.SP"], "comment": "Published in IEEE Transactions on Instrumentation and Measurement,\n  Volume 74, 09 June 2025, Article Sequence Number: 4511312,", "summary": "Acousto-optic sensing provides an alternative approach to traditional\nmicrophone arrays by shedding light on the interaction of light with an\nacoustic field. Sound field reconstruction is a fascinating and advanced\ntechnique used in acousto-optics sensing. Current challenges in sound-field\nreconstruction methods pertain to scenarios in which the sound source is\nlocated within the reconstruction area, known as the exterior problem. Existing\nreconstruction algorithms, primarily designed for interior scenarios, often\nexhibit suboptimal performance when applied to exterior cases. This paper\nintroduces a novel technique for exterior sound-field reconstruction. The\nproposed method leverages concentric circle sampling and a two-dimensional\nexterior sound-field reconstruction approach based on circular harmonic\nextensions. To evaluate the efficacy of this approach, both numerical\nsimulations and practical experiments are conducted. The results highlight the\nsuperior accuracy of the proposed method when compared to conventional\nreconstruction methods, all while utilizing a minimal amount of measured\nprojection data.", "AI": {"tldr": "A novel technique for exterior sound-field reconstruction using concentric circle sampling and circular harmonic extensions outperforms traditional methods in accuracy and efficiency.", "motivation": "Addressing the limitations of existing sound-field reconstruction methods in exterior scenarios where the sound source is within the reconstruction area.", "method": "Proposes a two-dimensional exterior sound-field reconstruction approach using concentric circle sampling and circular harmonic extensions, validated through simulations and experiments.", "result": "The method achieves superior accuracy compared to conventional techniques while requiring minimal measured projection data.", "conclusion": "The proposed technique effectively solves the exterior problem in acousto-optic sensing, offering improved performance and practicality."}}
{"id": "2506.23309", "pdf": "https://arxiv.org/pdf/2506.23309", "abs": "https://arxiv.org/abs/2506.23309", "authors": ["Yiming Huang", "Long Bai", "Beilei Cui", "Kun Yuan", "Guankun Wang", "Mobarakol Islam", "Nicolas Padoy", "Nassir Navab", "Hongliang Ren"], "title": "SurgTPGS: Semantic 3D Surgical Scene Understanding with Text Promptable Gaussian Splatting", "categories": ["eess.IV", "cs.CV"], "comment": "MICCAI 2025. Project Page:\n  https://lastbasket.github.io/MICCAI-2025-SurgTPGS/", "summary": "In contemporary surgical research and practice, accurately comprehending 3D\nsurgical scenes with text-promptable capabilities is particularly crucial for\nsurgical planning and real-time intra-operative guidance, where precisely\nidentifying and interacting with surgical tools and anatomical structures is\nparamount. However, existing works focus on surgical vision-language model\n(VLM), 3D reconstruction, and segmentation separately, lacking support for\nreal-time text-promptable 3D queries. In this paper, we present SurgTPGS, a\nnovel text-promptable Gaussian Splatting method to fill this gap. We introduce\na 3D semantics feature learning strategy incorporating the Segment Anything\nmodel and state-of-the-art vision-language models. We extract the segmented\nlanguage features for 3D surgical scene reconstruction, enabling a more\nin-depth understanding of the complex surgical environment. We also propose\nsemantic-aware deformation tracking to capture the seamless deformation of\nsemantic features, providing a more precise reconstruction for both texture and\nsemantic features. Furthermore, we present semantic region-aware optimization,\nwhich utilizes regional-based semantic information to supervise the training,\nparticularly promoting the reconstruction quality and semantic smoothness. We\nconduct comprehensive experiments on two real-world surgical datasets to\ndemonstrate the superiority of SurgTPGS over state-of-the-art methods,\nhighlighting its potential to revolutionize surgical practices. SurgTPGS paves\nthe way for developing next-generation intelligent surgical systems by\nenhancing surgical precision and safety. Our code is available at:\nhttps://github.com/lastbasket/SurgTPGS.", "AI": {"tldr": "SurgTPGS introduces a text-promptable Gaussian Splatting method for 3D surgical scene understanding, combining vision-language models and semantic-aware techniques for precise reconstruction and real-time interaction.", "motivation": "Accurate 3D surgical scene comprehension with text-promptable capabilities is vital for surgical planning and real-time guidance, but existing methods lack integration of these features.", "method": "The method integrates Segment Anything and vision-language models for 3D semantics feature learning, semantic-aware deformation tracking, and semantic region-aware optimization.", "result": "Experiments on surgical datasets show SurgTPGS outperforms state-of-the-art methods in reconstruction quality and semantic understanding.", "conclusion": "SurgTPGS enhances surgical precision and safety, paving the way for next-generation intelligent surgical systems."}}
{"id": "2506.23141", "pdf": "https://arxiv.org/pdf/2506.23141", "abs": "https://arxiv.org/abs/2506.23141", "authors": ["Siyuan Li", "Ruitong Liu", "Yan Wen", "Te Sun"], "title": "Context-Driven Knowledge Graph Completion with Semantic-Aware Relational Message Passing", "categories": ["cs.AI"], "comment": null, "summary": "Semantic context surrounding a triplet $(h, r, t)$ is crucial for Knowledge\nGraph Completion (KGC), providing vital cues for prediction. However,\ntraditional node-based message passing mechanisms, when applied to knowledge\ngraphs, often introduce noise and suffer from information dilution or\nover-smoothing by indiscriminately aggregating information from all neighboring\nedges. To address this challenge, we propose a semantic-aware relational\nmessage passing. A core innovation of this framework is the introduction of a\n\\textbf{semantic-aware Top-K neighbor selection strategy}. Specifically, this\nstrategy first evaluates the semantic relevance between a central node and its\nincident edges within a shared latent space, selecting only the Top-K most\npertinent ones. Subsequently, information from these selected edges is\neffectively fused with the central node's own representation using a\n\\textbf{multi-head attention aggregator} to generate a semantically focused\nnode message. In this manner, our model not only leverages the structure and\nfeatures of edges within the knowledge graph but also more accurately captures\nand propagates the contextual information most relevant to the specific link\nprediction task, thereby effectively mitigating interference from irrelevant\ninformation. Extensive experiments demonstrate that our method achieves\nsuperior performance compared to existing approaches on several established\nbenchmarks.", "AI": {"tldr": "Proposes a semantic-aware relational message passing method for Knowledge Graph Completion (KGC) to address noise and information dilution in traditional node-based approaches.", "motivation": "Traditional node-based message passing in KGC introduces noise and suffers from information dilution by aggregating all neighboring edges indiscriminately.", "method": "Introduces a semantic-aware Top-K neighbor selection strategy and a multi-head attention aggregator to focus on relevant contextual information.", "result": "Achieves superior performance on established benchmarks by mitigating interference from irrelevant information.", "conclusion": "The method effectively leverages semantic context and improves KGC by accurately capturing and propagating relevant information."}}
{"id": "2506.22645", "pdf": "https://arxiv.org/pdf/2506.22645", "abs": "https://arxiv.org/abs/2506.22645", "authors": ["Amir Hossein Rahmati", "Nathan M. Urban", "Byung-Jun Yoon", "Xiaoning Qian"], "title": "Cost-effective Reduced-Order Modeling via Bayesian Active Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Machine Learning surrogates have been developed to accelerate solving systems\ndynamics of complex processes in different science and engineering\napplications. To faithfully capture governing systems dynamics, these methods\nrely on large training datasets, hence restricting their applicability in\nreal-world problems. In this work, we propose BayPOD-AL, an active learning\nframework based on an uncertainty-aware Bayesian proper orthogonal\ndecomposition (POD) approach, which aims to effectively learn reduced-order\nmodels from high-fidelity full-order models representing complex systems.\nExperimental results on predicting the temperature evolution over a rod\ndemonstrate BayPOD-AL's effectiveness in suggesting the informative data and\nreducing computational cost related to constructing a training dataset compared\nto other uncertainty-guided active learning strategies. Furthermore, we\ndemonstrate BayPOD-AL's generalizability and efficiency by evaluating its\nperformance on a dataset of higher temporal resolution than the training\ndataset.", "AI": {"tldr": "BayPOD-AL is an active learning framework using Bayesian POD to efficiently learn reduced-order models from high-fidelity data, reducing computational costs and improving generalizability.", "motivation": "Machine Learning surrogates require large datasets, limiting real-world applicability. BayPOD-AL addresses this by optimizing data collection.", "method": "BayPOD-AL combines Bayesian POD with active learning to select informative data points, reducing training dataset size.", "result": "BayPOD-AL outperforms other methods in predicting temperature evolution and generalizes well to higher temporal resolution data.", "conclusion": "BayPOD-AL effectively reduces computational costs and improves model accuracy, making it suitable for complex systems."}}
{"id": "2506.22531", "pdf": "https://arxiv.org/pdf/2506.22531", "abs": "https://arxiv.org/abs/2506.22531", "authors": ["Prasen Kumar Sharma", "Neeraj Matiyali", "Siddharth Srivastava", "Gaurav Sharma"], "title": "Preserve Anything: Controllable Image Synthesis with Object Preservation", "categories": ["cs.CV"], "comment": "Accepted at ICCV 2025", "summary": "We introduce \\textit{Preserve Anything}, a novel method for controlled image\nsynthesis that addresses key limitations in object preservation and semantic\nconsistency in text-to-image (T2I) generation. Existing approaches often fail\n(i) to preserve multiple objects with fidelity, (ii) maintain semantic\nalignment with prompts, or (iii) provide explicit control over scene\ncomposition. To overcome these challenges, the proposed method employs an\nN-channel ControlNet that integrates (i) object preservation with size and\nplacement agnosticism, color and detail retention, and artifact elimination,\n(ii) high-resolution, semantically consistent backgrounds with accurate\nshadows, lighting, and prompt adherence, and (iii) explicit user control over\nbackground layouts and lighting conditions. Key components of our framework\ninclude object preservation and background guidance modules, enforcing lighting\nconsistency and a high-frequency overlay module to retain fine details while\nmitigating unwanted artifacts. We introduce a benchmark dataset consisting of\n240K natural images filtered for aesthetic quality and 18K 3D-rendered\nsynthetic images with metadata such as lighting, camera angles, and object\nrelationships. This dataset addresses the deficiencies of existing benchmarks\nand allows a complete evaluation. Empirical results demonstrate that our method\nachieves state-of-the-art performance, significantly improving feature-space\nfidelity (FID 15.26) and semantic alignment (CLIP-S 32.85) while maintaining\ncompetitive aesthetic quality. We also conducted a user study to demonstrate\nthe efficacy of the proposed work on unseen benchmark and observed a remarkable\nimprovement of $\\sim25\\%$, $\\sim19\\%$, $\\sim13\\%$, and $\\sim14\\%$ in terms of\nprompt alignment, photorealism, the presence of AI artifacts, and natural\naesthetics over existing works.", "AI": {"tldr": "The paper introduces \"Preserve Anything,\" a method for controlled image synthesis that improves object preservation, semantic consistency, and user control in text-to-image generation. It outperforms existing methods in fidelity and alignment.", "motivation": "Existing text-to-image methods struggle with preserving multiple objects, maintaining semantic alignment, and providing explicit control over scene composition.", "method": "The method uses an N-channel ControlNet with modules for object preservation, background guidance, lighting consistency, and high-frequency overlay to retain details and reduce artifacts. A benchmark dataset of 240K natural and 18K synthetic images is introduced for evaluation.", "result": "The method achieves state-of-the-art performance with FID 15.26 and CLIP-S 32.85, and user studies show significant improvements in prompt alignment, photorealism, artifact reduction, and aesthetics.", "conclusion": "\"Preserve Anything\" addresses key limitations in text-to-image synthesis, offering superior performance and user control, validated by empirical results and user studies."}}
{"id": "2506.22791", "pdf": "https://arxiv.org/pdf/2506.22791", "abs": "https://arxiv.org/abs/2506.22791", "authors": ["Jianxin Yan", "Wangze Ni", "Lei Chen", "Xuemin Lin", "Peng Cheng", "Zhan Qin", "Kui Ren"], "title": "ContextCache: Context-Aware Semantic Cache for Multi-Turn Queries in Large Language Models", "categories": ["cs.CL", "cs.DB"], "comment": null, "summary": "Semantic caching significantly reduces computational costs and improves\nefficiency by storing and reusing large language model (LLM) responses.\nHowever, existing systems rely primarily on matching individual queries,\nlacking awareness of multi-turn dialogue contexts, which leads to incorrect\ncache hits when similar queries appear in different conversational settings.\nThis demonstration introduces ContextCache, a context-aware semantic caching\nsystem for multi-turn dialogues. ContextCache employs a two-stage retrieval\narchitecture that first executes vector-based retrieval on the current query to\nidentify potential matches and then integrates current and historical dialogue\nrepresentations through self-attention mechanisms for precise contextual\nmatching. Evaluation of real-world conversations shows that ContextCache\nimproves precision and recall compared to existing methods. Additionally,\ncached responses exhibit approximately 10 times lower latency than direct LLM\ninvocation, enabling significant computational cost reductions for LLM\nconversational applications.", "AI": {"tldr": "ContextCache introduces a context-aware semantic caching system for multi-turn dialogues, improving precision and recall while reducing latency and computational costs.", "motivation": "Existing semantic caching systems lack awareness of multi-turn dialogue contexts, leading to incorrect cache hits in different conversational settings.", "method": "ContextCache uses a two-stage retrieval architecture: vector-based retrieval on the current query followed by contextual matching using self-attention mechanisms on dialogue history.", "result": "ContextCache outperforms existing methods in precision and recall, with cached responses showing ~10x lower latency than direct LLM invocation.", "conclusion": "ContextCache effectively reduces computational costs and improves efficiency for LLM conversational applications by leveraging contextual awareness."}}
{"id": "2505.20166", "pdf": "https://arxiv.org/pdf/2505.20166", "abs": "https://arxiv.org/abs/2505.20166", "authors": ["Chun-Yi Kuan", "Hung-yi Lee"], "title": "From Alignment to Advancement: Bootstrapping Audio-Language Alignment with Synthetic Data", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "comment": "Submitted to IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing. Project Website: https://kuan2jiu99.github.io/Balsa", "summary": "Audio-aware large language models (ALLMs) have recently made great strides in\nunderstanding and processing audio inputs. These models are typically adapted\nfrom text-based large language models (LLMs) through additional training on\naudio-related tasks. However, this adaptation process presents two major\nlimitations. First, ALLMs often suffer from catastrophic forgetting, where\ncrucial textual capabilities like instruction-following are lost after training\non audio data. In some cases, models may even hallucinate sounds that are not\npresent in the input audio, raising concerns about reliability. Second,\nachieving cross-modal alignment between audio and language typically relies on\nlarge collections of task-specific question-answer pairs for instruction\ntuning, making it resource-intensive. To address these issues, previous works\nhave leveraged the backbone LLMs to synthesize general-purpose, caption-style\nalignment data. In this paper, we propose a data generation framework that\nproduces contrastive-like training data, designed to enhance ALLMs' ability to\ndifferentiate between present and absent sounds. We further extend our approach\nto multi-audio scenarios, enabling the model to either explain differences\nbetween audio inputs or produce unified captions that describe all inputs,\nthereby enhancing audio-language alignment. We refer to the entire ALLM\ntraining framework as bootstrapping audio-language alignment via synthetic data\ngeneration from backbone LLMs (BALSa). Experimental results indicate that our\nmethod effectively mitigates audio hallucinations while reliably maintaining\nstrong performance on audio understanding and reasoning benchmarks, as well as\ninstruction-following skills. Moreover, incorporating multi-audio training\nfurther enhances the model's comprehension and reasoning capabilities. Overall,\nBALSa offers an efficient and scalable approach to developing ALLMs.", "AI": {"tldr": "Proposes BALSa, a framework for training audio-aware LLMs using synthetic data to mitigate audio hallucinations and enhance cross-modal alignment.", "motivation": "Addresses limitations in adapting text-based LLMs to audio tasks, such as catastrophic forgetting and resource-intensive alignment methods.", "method": "Introduces a data generation framework for contrastive-like training and extends it to multi-audio scenarios for better alignment.", "result": "Effectively reduces audio hallucinations while maintaining strong performance on audio understanding and instruction-following tasks.", "conclusion": "BALSa provides an efficient and scalable solution for developing high-performing ALLMs."}}
{"id": "2412.02547", "pdf": "https://arxiv.org/pdf/2412.02547", "abs": "https://arxiv.org/abs/2412.02547", "authors": ["Tong Zhou", "Yubing Li"], "title": "Interaction Identification of a Heterogeneous NDS with Quadratic-Bilinear Subsystems", "categories": ["cs.MA", "cs.SY", "eess.SY", "math.DS"], "comment": "13 pages, 5 figures", "summary": "This paper attacks time-domain identification for interaction parameters of a\nheterogeneous networked dynamic system (NDS), with each of its subsystems being\ndescribed by a continuous-time descriptor quadratic-bilinear time-invariant\n(QBTI) model. The obtained results can also be applied to parameter estimations\nfor a lumped QBTI system. No restrictions are put on the sampling rate.\nExplicit formulas are derived respectively for the transient and steady-state\nresponses of the NDS, provided that the probing signal is generated by a linear\ntime invariant (LTI) system. Some relations have been derived between the NDS\nsteady-state response and its frequency domain input-output mappings. These\nrelations reveal that the value of some NDS associated generalized TFMs can in\nprinciple be estimated at almost any interested point of the imaginary axis\nfrom time-domain input-output experimental data, as well as its derivatives and\na right tangential interpolation along an arbitrary direction. Based on these\nrelations, an estimation algorithm is suggested respectively for the parameters\nof the NDS and the values of these generalized TFMs. A numerical example is\nincluded to illustrate characteristics of the suggested estimation algorithms.", "AI": {"tldr": "The paper presents time-domain identification methods for heterogeneous networked dynamic systems (NDS) using quadratic-bilinear time-invariant (QBTI) models, with applications to lumped QBTI systems. It derives explicit formulas for transient and steady-state responses and proposes parameter estimation algorithms.", "motivation": "To address the challenge of identifying interaction parameters in heterogeneous NDS and extend the results to lumped QBTI systems without sampling rate restrictions.", "method": "Derives explicit formulas for NDS responses under LTI probing signals, establishes relations between steady-state responses and frequency-domain mappings, and proposes parameter estimation algorithms.", "result": "The derived relations allow estimation of generalized TFMs and their derivatives from time-domain data. A numerical example demonstrates the algorithm's effectiveness.", "conclusion": "The paper provides a framework for time-domain identification in NDS and QBTI systems, with practical estimation algorithms validated by numerical results."}}
{"id": "2506.12573", "pdf": "https://arxiv.org/pdf/2506.12573", "abs": "https://arxiv.org/abs/2506.12573", "authors": ["Haven Kim", "Zachary Novack", "Weihan Xu", "Julian McAuley", "Hao-Wen Dong"], "title": "Video-Guided Text-to-Music Generation Using Public Domain Movie Collections", "categories": ["cs.SD", "cs.MM", "eess.AS"], "comment": "ISMIR 2025 regular paper. Dataset, code, and demo available at\n  https://havenpersona.github.io/ossl-v1", "summary": "Despite recent advancements in music generation systems, their application in\nfilm production remains limited, as they struggle to capture the nuances of\nreal-world filmmaking, where filmmakers consider multiple factors-such as\nvisual content, dialogue, and emotional tone-when selecting or composing music\nfor a scene. This limitation primarily stems from the absence of comprehensive\ndatasets that integrate these elements. To address this gap, we introduce Open\nScreen Soundtrack Library (OSSL), a dataset consisting of movie clips from\npublic domain films, totaling approximately 36.5 hours, paired with\nhigh-quality soundtracks and human-annotated mood information. To demonstrate\nthe effectiveness of our dataset in improving the performance of pre-trained\nmodels on film music generation tasks, we introduce a new video adapter that\nenhances an autoregressive transformer-based text-to-music model by adding\nvideo-based conditioning. Our experimental results demonstrate that our\nproposed approach effectively enhances MusicGen-Medium in terms of both\nobjective measures of distributional and paired fidelity, and subjective\ncompatibility in mood and genre. To facilitate reproducibility and foster\nfuture work, we publicly release the dataset, code, and demo.", "AI": {"tldr": "The paper introduces OSSL, a dataset for film music generation, and a video adapter to improve pre-trained models, showing enhanced performance in music generation tasks.", "motivation": "Existing music generation systems lack integration of filmmaking nuances like visual content and emotional tone, due to missing comprehensive datasets.", "method": "Introduces OSSL dataset with movie clips, soundtracks, and mood annotations, and a video adapter for a transformer-based text-to-music model.", "result": "The approach improves MusicGen-Medium in distributional and paired fidelity, and subjective compatibility in mood and genre.", "conclusion": "OSSL and the video adapter enhance film music generation, with public release of dataset, code, and demo for future work."}}
{"id": "2409.11753", "pdf": "https://arxiv.org/pdf/2409.11753", "abs": "https://arxiv.org/abs/2409.11753", "authors": ["Dinh-Viet-Toan Le", "Yi-Hsuan Yang"], "title": "METEOR: Melody-aware Texture-controllable Symbolic Orchestral Music Generation via Transformer VAE", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted to 34rd International Joint Conference on Artificial\n  Intelligence (IJCAI 2025) - AI, Arts and Creativity Special Track. Demo:\n  https://dinhviettoanle.github.io/meteor", "summary": "Re-orchestration is the process of adapting a music piece for a different set\nof instruments. By altering the original instrumentation, the orchestrator\noften modifies the musical texture while preserving a recognizable melodic line\nand ensures that each part is playable within the technical and expressive\ncapabilities of the chosen instruments. In this work, we propose METEOR, a\nmodel for generating Melody-aware Texture-controllable re-Orchestration with a\nTransformer-based variational auto-encoder (VAE). This model performs symbolic\ninstrumental and textural music style transfers with a focus on melodic\nfidelity and controllability. We allow bar- and track-level controllability of\nthe accompaniment with various textural attributes while keeping a homophonic\ntexture. With both subjective and objective evaluations, we show that our model\noutperforms style transfer models on a re-orchestration task in terms of\ngeneration quality and controllability. Moreover, it can be adapted for a lead\nsheet orchestration task as a zero-shot learning model, achieving performance\ncomparable to a model specifically trained for this task.", "AI": {"tldr": "METEOR is a Transformer-based VAE model for melody-aware, texture-controllable re-orchestration, outperforming style transfer models in quality and controllability.", "motivation": "To adapt music pieces for different instruments while preserving melody and ensuring playability, with controllable texture.", "method": "Uses a Transformer-based VAE for symbolic instrumental and textural style transfer, focusing on melodic fidelity and bar-/track-level controllability.", "result": "Outperforms style transfer models in re-orchestration tasks and adapts well to lead sheet orchestration as a zero-shot model.", "conclusion": "METEOR is effective for re-orchestration with high controllability and melodic fidelity, even in zero-shot scenarios."}}
{"id": "2506.23311", "pdf": "https://arxiv.org/pdf/2506.23311", "abs": "https://arxiv.org/abs/2506.23311", "authors": ["Perla Mayo", "Carolin M. Pirkl", "Alin Achim", "Bjoern Menze", "Mohammad Golbabaee"], "title": "Physics informed guided diffusion for accelerated multi-parametric MRI reconstruction", "categories": ["eess.IV", "cs.LG", "physics.med-ph"], "comment": "11 pages, 1 figure, 1 algorithm, 3 tables. Accepted to MICCAI 2025.\n  This is a version prior peer-review", "summary": "We introduce MRF-DiPh, a novel physics informed denoising diffusion approach\nfor multiparametric tissue mapping from highly accelerated, transient-state\nquantitative MRI acquisitions like Magnetic Resonance Fingerprinting (MRF). Our\nmethod is derived from a proximal splitting formulation, incorporating a\npretrained denoising diffusion model as an effective image prior to regularize\nthe MRF inverse problem. Further, during reconstruction it simultaneously\nenforces two key physical constraints: (1) k-space measurement consistency and\n(2) adherence to the Bloch response model. Numerical experiments on in-vivo\nbrain scans data show that MRF-DiPh outperforms deep learning and compressed\nsensing MRF baselines, providing more accurate parameter maps while better\npreserving measurement fidelity and physical model consistency-critical for\nsolving reliably inverse problems in medical imaging.", "AI": {"tldr": "MRF-DiPh is a physics-informed denoising diffusion method for accurate tissue mapping from accelerated MRI, outperforming existing baselines.", "motivation": "To improve multiparametric tissue mapping from highly accelerated MRI by integrating physical constraints and a denoising diffusion prior.", "method": "Proximal splitting with a pretrained denoising diffusion model, enforcing k-space consistency and Bloch response adherence.", "result": "Outperforms deep learning and compressed sensing baselines, yielding more accurate parameter maps with better fidelity.", "conclusion": "MRF-DiPh reliably solves inverse problems in medical imaging by combining physical constraints with advanced priors."}}
{"id": "2506.23168", "pdf": "https://arxiv.org/pdf/2506.23168", "abs": "https://arxiv.org/abs/2506.23168", "authors": ["Mohammad Abdulla", "Tobias Hille", "Dominik D\u00fcrrschnabel", "Gerd Stumme"], "title": "Rises for Measuring Local Distributivity in Lattices", "categories": ["cs.AI", "cs.DM", "math.CO", "math.RA", "06B99", "G.2.1"], "comment": "16 pages, 2 tables, 5 figures, International Joint Conference on\n  Conceptual Knowledge Structures", "summary": "Distributivity is a well-established and extensively studied notion in\nlattice theory. In the context of data analysis, particularly within Formal\nConcept Analysis (FCA), lattices are often observed to exhibit a high degree of\ndistributivity. However, no standardized measure exists to quantify this\nproperty. In this paper, we introduce the notion of rises in (concept) lattices\nas a means to assess distributivity. Rises capture how the number of attributes\nor objects in covering concepts change within the concept lattice. We show that\na lattice is distributive if and only if no non-unit rises occur. Furthermore,\nwe relate rises to the classical notion of meet- and join distributivity. We\nobserve that concept lattices from real-world data are to a high degree\njoin-distributive, but much less meet-distributive. We additionally study how\njoin-distributivity manifests on the level of ordered sets.", "AI": {"tldr": "Introduces 'rises' in concept lattices to measure distributivity, linking it to join- and meet-distributivity, and analyzes real-world data.", "motivation": "Lack of a standardized measure for distributivity in Formal Concept Analysis (FCA) lattices, despite their frequent distributivity.", "method": "Proposes 'rises' to quantify distributivity, examining their relationship with classical distributivity notions and analyzing real-world concept lattices.", "result": "Lattices are distributive if no non-unit rises occur; real-world data shows high join-distributivity but low meet-distributivity.", "conclusion": "Rises effectively measure distributivity, revealing distinct patterns in join- and meet-distributivity in real-world FCA lattices."}}
{"id": "2506.22655", "pdf": "https://arxiv.org/pdf/2506.22655", "abs": "https://arxiv.org/abs/2506.22655", "authors": ["Andrew F. Ilersich", "Prasanth B. Nair"], "title": "Learning Stochastic Multiscale Models", "categories": ["cs.LG"], "comment": "Body is 9 pages, 13 including acknowledgements and references, 35\n  including appendix. 21 figures and 6 tables. Submitted to NeurIPS 2025", "summary": "The physical sciences are replete with dynamical systems that require the\nresolution of a wide range of length and time scales. This presents significant\ncomputational challenges since direct numerical simulation requires\ndiscretization at the finest relevant scales, leading to a high-dimensional\nstate space. In this work, we propose an approach to learn stochastic\nmultiscale models in the form of stochastic differential equations directly\nfrom observational data. Our method resolves the state on a coarse mesh while\nintroducing an auxiliary state to capture the effects of unresolved scales. We\nlearn the parameters of the multiscale model using a modern forward-solver-free\namortized variational inference method. Our approach draws inspiration from\nphysics-based multiscale modeling approaches, such as large-eddy simulation in\nfluid dynamics, while learning directly from data. We present numerical studies\nto demonstrate that our learned multiscale models achieve superior predictive\naccuracy compared to direct numerical simulation and closure-type models at\nequivalent resolution.", "AI": {"tldr": "The paper proposes a data-driven method to learn stochastic multiscale models using stochastic differential equations, improving predictive accuracy over traditional simulations.", "motivation": "Dynamical systems in physical sciences often involve multiple scales, making direct numerical simulation computationally expensive. A more efficient approach is needed.", "method": "The method learns stochastic multiscale models from data, using a coarse mesh and an auxiliary state for unresolved scales. Parameters are learned via forward-solver-free variational inference.", "result": "The learned models outperform direct numerical simulation and closure-type models in predictive accuracy at equivalent resolution.", "conclusion": "The approach offers a computationally efficient and accurate alternative for modeling multiscale dynamical systems."}}
{"id": "2506.22554", "pdf": "https://arxiv.org/pdf/2506.22554", "abs": "https://arxiv.org/abs/2506.22554", "authors": ["Vasu Agrawal", "Akinniyi Akinyemi", "Kathryn Alvero", "Morteza Behrooz", "Julia Buffalini", "Fabio Maria Carlucci", "Joy Chen", "Junming Chen", "Zhang Chen", "Shiyang Cheng", "Praveen Chowdary", "Joe Chuang", "Antony D'Avirro", "Jon Daly", "Ning Dong", "Mark Duppenthaler", "Cynthia Gao", "Jeff Girard", "Martin Gleize", "Sahir Gomez", "Hongyu Gong", "Srivathsan Govindarajan", "Brandon Han", "Sen He", "Denise Hernandez", "Yordan Hristov", "Rongjie Huang", "Hirofumi Inaguma", "Somya Jain", "Raj Janardhan", "Qingyao Jia", "Christopher Klaiber", "Dejan Kovachev", "Moneish Kumar", "Hang Li", "Yilei Li", "Pavel Litvin", "Wei Liu", "Guangyao Ma", "Jing Ma", "Martin Ma", "Xutai Ma", "Lucas Mantovani", "Sagar Miglani", "Sreyas Mohan", "Louis-Philippe Morency", "Evonne Ng", "Kam-Woh Ng", "Tu Anh Nguyen", "Amia Oberai", "Benjamin Peloquin", "Juan Pino", "Jovan Popovic", "Omid Poursaeed", "Fabian Prada", "Alice Rakotoarison", "Alexander Richard", "Christophe Ropers", "Safiyyah Saleem", "Vasu Sharma", "Alex Shcherbyna", "Jia Shen", "Jie Shen", "Anastasis Stathopoulos", "Anna Sun", "Paden Tomasello", "Tuan Tran", "Arina Turkatenko", "Bo Wan", "Chao Wang", "Jeff Wang", "Mary Williamson", "Carleigh Wood", "Tao Xiang", "Yilin Yang", "Julien Yao", "Chen Zhang", "Jiemin Zhang", "Xinyue Zhang", "Jason Zheng", "Pavlo Zhyzheria", "Jan Zikes", "Michael Zollhoefer"], "title": "Seamless Interaction: Dyadic Audiovisual Motion Modeling and Large-Scale Dataset", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Human communication involves a complex interplay of verbal and nonverbal\nsignals, essential for conveying meaning and achieving interpersonal goals. To\ndevelop socially intelligent AI technologies, it is crucial to develop models\nthat can both comprehend and generate dyadic behavioral dynamics. To this end,\nwe introduce the Seamless Interaction Dataset, a large-scale collection of over\n4,000 hours of face-to-face interaction footage from over 4,000 participants in\ndiverse contexts. This dataset enables the development of AI technologies that\nunderstand dyadic embodied dynamics, unlocking breakthroughs in virtual agents,\ntelepresence experiences, and multimodal content analysis tools. We also\ndevelop a suite of models that utilize the dataset to generate dyadic motion\ngestures and facial expressions aligned with human speech. These models can\ntake as input both the speech and visual behavior of their interlocutors. We\npresent a variant with speech from an LLM model and integrations with 2D and 3D\nrendering methods, bringing us closer to interactive virtual agents.\nAdditionally, we describe controllable variants of our motion models that can\nadapt emotional responses and expressivity levels, as well as generating more\nsemantically-relevant gestures. Finally, we discuss methods for assessing the\nquality of these dyadic motion models, which are demonstrating the potential\nfor more intuitive and responsive human-AI interactions.", "AI": {"tldr": "The paper introduces the Seamless Interaction Dataset and models for AI to understand and generate dyadic behavioral dynamics, enhancing virtual agents and human-AI interactions.", "motivation": "To develop socially intelligent AI by comprehending and generating dyadic behavioral dynamics in human communication.", "method": "Creation of a large-scale dataset (Seamless Interaction Dataset) and development of models for generating dyadic motion gestures and facial expressions aligned with speech.", "result": "Models capable of generating contextually relevant gestures and expressions, with controllable emotional responses and expressivity levels.", "conclusion": "The work advances interactive virtual agents and human-AI interactions, with potential applications in telepresence and multimodal analysis."}}
{"id": "2506.22808", "pdf": "https://arxiv.org/pdf/2506.22808", "abs": "https://arxiv.org/abs/2506.22808", "authors": ["Jianhui Wei", "Zijie Meng", "Zikai Xiao", "Tianxiang Hu", "Yang Feng", "Zhijie Zhou", "Jian Wu", "Zuozhu Liu"], "title": "MedEthicsQA: A Comprehensive Question Answering Benchmark for Medical Ethics Evaluation of LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "20 pages", "summary": "While Medical Large Language Models (MedLLMs) have demonstrated remarkable\npotential in clinical tasks, their ethical safety remains insufficiently\nexplored. This paper introduces $\\textbf{MedEthicsQA}$, a comprehensive\nbenchmark comprising $\\textbf{5,623}$ multiple-choice questions and\n$\\textbf{5,351}$ open-ended questions for evaluation of medical ethics in LLMs.\nWe systematically establish a hierarchical taxonomy integrating global medical\nethical standards. The benchmark encompasses widely used medical datasets,\nauthoritative question banks, and scenarios derived from PubMed literature.\nRigorous quality control involving multi-stage filtering and multi-faceted\nexpert validation ensures the reliability of the dataset with a low error rate\n($2.72\\%$). Evaluation of state-of-the-art MedLLMs exhibit declined performance\nin answering medical ethics questions compared to their foundation\ncounterparts, elucidating the deficiencies of medical ethics alignment. The\ndataset, registered under CC BY-NC 4.0 license, is available at\nhttps://github.com/JianhuiWei7/MedEthicsQA.", "AI": {"tldr": "The paper introduces MedEthicsQA, a benchmark for evaluating medical ethics in LLMs, revealing performance gaps in MedLLMs compared to foundation models.", "motivation": "To address the insufficient exploration of ethical safety in Medical Large Language Models (MedLLMs).", "method": "Creation of MedEthicsQA, a benchmark with 5,623 multiple-choice and 5,351 open-ended questions, integrating global ethical standards and rigorous quality control.", "result": "State-of-the-art MedLLMs show declined performance in medical ethics questions, highlighting alignment deficiencies.", "conclusion": "The benchmark underscores the need for improved ethical alignment in MedLLMs, providing a reliable dataset for future research."}}
{"id": "2506.12285", "pdf": "https://arxiv.org/pdf/2506.12285", "abs": "https://arxiv.org/abs/2506.12285", "authors": ["Yinghao Ma", "Siyou Li", "Juntao Yu", "Emmanouil Benetos", "Akira Maezawa"], "title": "CMI-Bench: A Comprehensive Benchmark for Evaluating Music Instruction Following", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "comment": "Accepted by ISMIR 2025", "summary": "Recent advances in audio-text large language models (LLMs) have opened new\npossibilities for music understanding and generation. However, existing\nbenchmarks are limited in scope, often relying on simplified tasks or\nmulti-choice evaluations that fail to reflect the complexity of real-world\nmusic analysis. We reinterpret a broad range of traditional MIR annotations as\ninstruction-following formats and introduce CMI-Bench, a comprehensive music\ninstruction following benchmark designed to evaluate audio-text LLMs on a\ndiverse set of music information retrieval (MIR) tasks. These include genre\nclassification, emotion regression, emotion tagging, instrument classification,\npitch estimation, key detection, lyrics transcription, melody extraction, vocal\ntechnique recognition, instrument performance technique detection, music\ntagging, music captioning, and (down)beat tracking: reflecting core challenges\nin MIR research. Unlike previous benchmarks, CMI-Bench adopts standardized\nevaluation metrics consistent with previous state-of-the-art MIR models,\nensuring direct comparability with supervised approaches. We provide an\nevaluation toolkit supporting all open-source audio-textual LLMs, including\nLTU, Qwen-audio, SALMONN, MusiLingo, etc. Experiment results reveal significant\nperformance gaps between LLMs and supervised models, along with their culture,\nchronological and gender bias, highlighting the potential and limitations of\ncurrent models in addressing MIR tasks. CMI-Bench establishes a unified\nfoundation for evaluating music instruction following, driving progress in\nmusic-aware LLMs.", "AI": {"tldr": "CMI-Bench is a new benchmark for evaluating audio-text LLMs on diverse music tasks, revealing gaps and biases compared to supervised models.", "motivation": "Existing benchmarks for music understanding in LLMs are limited and don't reflect real-world complexity.", "method": "Reinterpret traditional MIR annotations as instruction-following tasks and introduce CMI-Bench with standardized metrics.", "result": "LLMs show performance gaps and biases (cultural, chronological, gender) compared to supervised models.", "conclusion": "CMI-Bench provides a unified evaluation foundation for advancing music-aware LLMs."}}
{"id": "2505.22814", "pdf": "https://arxiv.org/pdf/2505.22814", "abs": "https://arxiv.org/abs/2505.22814", "authors": ["Jonghan Lim", "Ilya Kovalenko"], "title": "A Large Language Model-Enabled Control Architecture for Dynamic Resource Capability Exploration in Multi-Agent Manufacturing Systems", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Manufacturing environments are becoming more complex and unpredictable due to\nfactors such as demand variations and shorter product lifespans. This\ncomplexity requires real-time decision-making and adaptation to disruptions.\nTraditional control approaches highlight the need for advanced control\nstrategies capable of overcoming unforeseen challenges, as they demonstrate\nlimitations in responsiveness within dynamic industrial settings. Multi-agent\nsystems address these challenges through decentralization of decision-making,\nenabling systems to respond dynamically to operational changes. However,\ncurrent multi-agent systems encounter challenges related to real-time\nadaptation, context-aware decision-making, and the dynamic exploration of\nresource capabilities. Large language models provide the possibility to\novercome these limitations through context-aware decision-making capabilities.\nThis paper introduces a large language model-enabled control architecture for\nmulti-agent manufacturing systems to dynamically explore resource capabilities\nin response to real-time disruptions. A simulation-based case study\ndemonstrates that the proposed architecture improves system resilience and\nflexibility. The case study findings show improved throughput and efficient\nresource utilization compared to existing approaches.", "AI": {"tldr": "A large language model-enabled control architecture for multi-agent manufacturing systems improves resilience and flexibility in dynamic environments.", "motivation": "Manufacturing complexity and unpredictability demand real-time adaptation, which traditional and current multi-agent systems struggle with.", "method": "Proposes a large language model-enabled control architecture for dynamic resource capability exploration in multi-agent systems.", "result": "Simulation shows improved throughput and resource utilization compared to existing methods.", "conclusion": "The architecture enhances system resilience and flexibility in dynamic manufacturing settings."}}
{"id": "2506.14427", "pdf": "https://arxiv.org/pdf/2506.14427", "abs": "https://arxiv.org/abs/2506.14427", "authors": ["Shilong Wu"], "title": "M3SD: Multi-modal, Multi-scenario and Multi-language Speaker Diarization Dataset", "categories": ["eess.AS", "cs.MM"], "comment": null, "summary": "In the field of speaker diarization, the development of technology is\nconstrained by two problems: insufficient data resources and poor\ngeneralization ability of deep learning models. To address these two problems,\nfirstly, we propose an automated method for constructing speaker diarization\ndatasets, which generates more accurate pseudo-labels for massive data through\nthe combination of audio and video. Relying on this method, we have released\nMulti-modal, Multi-scenario and Multi-language Speaker Diarization (M3SD)\ndatasets. This dataset is derived from real network videos and is highly\ndiverse. Our dataset and code have been open-sourced at\nhttps://huggingface.co/spaces/OldDragon/m3sd.", "AI": {"tldr": "Proposed an automated method to create speaker diarization datasets using audio-video fusion, releasing the diverse M3SD dataset to address data scarcity and model generalization issues.", "motivation": "Addressing insufficient data and poor generalization in speaker diarization by leveraging multi-modal (audio-video) data for accurate pseudo-labeling.", "method": "Combined audio and video to generate accurate pseudo-labels, constructing the M3SD dataset from real network videos.", "result": "Released the M3SD dataset, which is diverse and open-sourced, aiding in speaker diarization research.", "conclusion": "The M3SD dataset and method provide a solution to data scarcity and generalization challenges in speaker diarization."}}
{"id": "2411.07186", "pdf": "https://arxiv.org/pdf/2411.07186", "abs": "https://arxiv.org/abs/2411.07186", "authors": ["David Robinson", "Marius Miron", "Masato Hagiwara", "Benno Weck", "Sara Keen", "Milad Alizadeh", "Gagan Narula", "Matthieu Geist", "Olivier Pietquin"], "title": "NatureLM-audio: an Audio-Language Foundation Model for Bioacoustics", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": "Demo page: https://earthspecies.github.io/naturelm-audio-demo/", "summary": "Large language models (LLMs) prompted with text and audio have achieved\nstate-of-the-art performance across various auditory tasks, including speech,\nmusic, and general audio, showing emergent abilities on unseen tasks. However,\ntheir potential has yet to be fully demonstrated in bioacoustics tasks, such as\ndetecting animal vocalizations in large recordings, classifying rare and\nendangered species, and labeling context and behavior -- tasks that are crucial\nfor conservation, biodiversity monitoring, and animal behavior studies. In this\nwork, we present NatureLM-audio, the first audio-language foundation model\nspecifically designed for bioacoustics. Our training dataset consists of\ncarefully curated text-audio pairs spanning bioacoustics, speech, and music,\ndesigned to address the field's limited availability of annotated data. We\ndemonstrate successful transfer of learned representations from music and\nspeech to bioacoustics, and our model shows promising generalization to unseen\ntaxa and tasks. We evaluate NatureLM-audio on a novel benchmark (BEANS-Zero)\nand it sets a new state of the art on several bioacoustics tasks, including\nzero-shot classification of unseen species. To advance bioacoustics research,\nwe release our model weights, benchmark data, and open-source the code for\ntraining and benchmark data generation and model training.", "AI": {"tldr": "NatureLM-audio is the first audio-language model for bioacoustics, achieving state-of-the-art performance on tasks like zero-shot species classification and addressing data scarcity in the field.", "motivation": "LLMs excel in auditory tasks but lack application in bioacoustics, which is vital for conservation and biodiversity.", "method": "Trained on curated text-audio pairs (bioacoustics, speech, music) to transfer learned representations to bioacoustics.", "result": "Sets new benchmarks on bioacoustics tasks, including zero-shot classification of unseen species.", "conclusion": "NatureLM-audio advances bioacoustics research; model weights, benchmark data, and code are released for community use."}}
{"id": "2506.23334", "pdf": "https://arxiv.org/pdf/2506.23334", "abs": "https://arxiv.org/abs/2506.23334", "authors": ["Hongyi Pan", "Ziliang Hong", "Gorkem Durak", "Ziyue Xu", "Ulas Bagci"], "title": "Federated Breast Cancer Detection Enhanced by Synthetic Ultrasound Image Augmentation", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Federated learning (FL) has emerged as a promising paradigm for\ncollaboratively training deep learning models across institutions without\nexchanging sensitive medical data. However, its effectiveness is often hindered\nby limited data availability and non-independent, identically distributed data\nacross participating clients, which can degrade model performance and\ngeneralization. To address these challenges, we propose a generative AI based\ndata augmentation framework that integrates synthetic image sharing into the\nfederated training process for breast cancer diagnosis via ultrasound images.\nSpecifically, we train two simple class-specific Deep Convolutional Generative\nAdversarial Networks: one for benign and one for malignant lesions. We then\nsimulate a realistic FL setting using three publicly available breast\nultrasound image datasets: BUSI, BUS-BRA, and UDIAT. FedAvg and FedProx are\nadopted as baseline FL algorithms. Experimental results show that incorporating\na suitable number of synthetic images improved the average AUC from 0.9206 to\n0.9237 for FedAvg and from 0.9429 to 0.9538 for FedProx. We also note that\nexcessive use of synthetic data reduced performance, underscoring the\nimportance of maintaining a balanced ratio of real and synthetic samples. Our\nfindings highlight the potential of generative AI based data augmentation to\nenhance FL results in the breast ultrasound image classification task.", "AI": {"tldr": "A generative AI framework improves federated learning for breast cancer diagnosis by augmenting data with synthetic images, enhancing model performance.", "motivation": "Federated learning (FL) faces challenges like limited data and non-IID distributions, which degrade model performance in medical tasks like breast cancer diagnosis.", "method": "Proposes a generative AI framework using class-specific DCGANs (for benign and malignant lesions) to augment data in FL, tested with FedAvg and FedProx on breast ultrasound datasets.", "result": "Synthetic images improved AUC scores (FedAvg: 0.9206 to 0.9237; FedProx: 0.9429 to 0.9538), but excessive synthetic data reduced performance.", "conclusion": "Generative AI-based data augmentation can enhance FL for medical imaging, but balance between real and synthetic data is crucial."}}
{"id": "2506.23273", "pdf": "https://arxiv.org/pdf/2506.23273", "abs": "https://arxiv.org/abs/2506.23273", "authors": ["Quang Hung Nguyen", "Phuong Anh Trinh", "Phan Quoc Hung Mai", "Tuan Phong Trinh"], "title": "FinStat2SQL: A Text2SQL Pipeline for Financial Statement Analysis", "categories": ["cs.AI"], "comment": null, "summary": "Despite the advancements of large language models, text2sql still faces many\nchallenges, particularly with complex and domain-specific queries. In finance,\ndatabase designs and financial reporting layouts vary widely between financial\nentities and countries, making text2sql even more challenging. We present\nFinStat2SQL, a lightweight text2sql pipeline enabling natural language queries\nover financial statements. Tailored to local standards like VAS, it combines\nlarge and small language models in a multi-agent setup for entity extraction,\nSQL generation, and self-correction. We build a domain-specific database and\nevaluate models on a synthetic QA dataset. A fine-tuned 7B model achieves\n61.33\\% accuracy with sub-4-second response times on consumer hardware,\noutperforming GPT-4o-mini. FinStat2SQL offers a scalable, cost-efficient\nsolution for financial analysis, making AI-powered querying accessible to\nVietnamese enterprises.", "AI": {"tldr": "FinStat2SQL is a lightweight text2sql pipeline for financial statements, combining large and small language models to handle domain-specific queries efficiently. It achieves 61.33% accuracy with fast response times.", "motivation": "Text2sql faces challenges with complex, domain-specific queries, especially in finance due to varying database designs and reporting standards.", "method": "Uses a multi-agent setup with large and small language models for entity extraction, SQL generation, and self-correction. Tailored to local standards like VAS.", "result": "A fine-tuned 7B model achieves 61.33% accuracy with sub-4-second response times, outperforming GPT-4o-mini.", "conclusion": "FinStat2SQL provides a scalable, cost-efficient solution for financial analysis, making AI-powered querying accessible to Vietnamese enterprises."}}
{"id": "2506.22668", "pdf": "https://arxiv.org/pdf/2506.22668", "abs": "https://arxiv.org/abs/2506.22668", "authors": ["Selahattin Akkas", "Aditya Devarakonda", "Ariful Azad"], "title": "DistShap: Scalable GNN Explanations with Distributed Shapley Values", "categories": ["cs.LG", "cs.AI", "cs.DC", "stat.ML"], "comment": "12 pages", "summary": "With the growing adoption of graph neural networks (GNNs), explaining their\npredictions has become increasingly important. However, attributing predictions\nto specific edges or features remains computationally expensive. For example,\nclassifying a node with 100 neighbors using a 3-layer GNN may involve\nidentifying important edges from millions of candidates contributing to the\nprediction. To address this challenge, we propose DistShap, a parallel\nalgorithm that distributes Shapley value-based explanations across multiple\nGPUs. DistShap operates by sampling subgraphs in a distributed setting,\nexecuting GNN inference in parallel across GPUs, and solving a distributed\nleast squares problem to compute edge importance scores. DistShap outperforms\nmost existing GNN explanation methods in accuracy and is the first to scale to\nGNN models with millions of features by using up to 128 GPUs on the NERSC\nPerlmutter supercomputer.", "AI": {"tldr": "DistShap is a parallel algorithm for efficiently explaining GNN predictions by distributing Shapley value computations across multiple GPUs, scaling to models with millions of features.", "motivation": "Explaining GNN predictions is computationally expensive, especially for large graphs with many edges or features.", "method": "DistShap distributes Shapley value-based explanations by sampling subgraphs, parallel GNN inference, and solving a distributed least squares problem.", "result": "DistShap outperforms existing methods in accuracy and scales to GNNs with millions of features using up to 128 GPUs.", "conclusion": "DistShap provides a scalable and accurate solution for explaining GNN predictions, addressing computational challenges in large-scale graphs."}}
{"id": "2506.22556", "pdf": "https://arxiv.org/pdf/2506.22556", "abs": "https://arxiv.org/abs/2506.22556", "authors": ["Markus Juvonen", "Samuli Siltanen"], "title": "Recomposed realities: animating still images via patch clustering and randomness", "categories": ["cs.CV", "eess.IV"], "comment": "22 pages, 19 figures", "summary": "We present a patch-based image reconstruction and animation method that uses\nexisting image data to bring still images to life through motion. Image patches\nfrom curated datasets are grouped using k-means clustering and a new target\nimage is reconstructed by matching and randomly sampling from these clusters.\nThis approach emphasizes reinterpretation over replication, allowing the source\nand target domains to differ conceptually while sharing local structures.", "AI": {"tldr": "A patch-based method uses k-means clustering to animate still images by reconstructing them from curated datasets, emphasizing reinterpretation over replication.", "motivation": "To bring still images to life through motion by leveraging existing image data, allowing for creative reinterpretation.", "method": "Uses k-means clustering to group image patches from datasets, then reconstructs target images by matching and randomly sampling from these clusters.", "result": "Enables animation of still images while allowing conceptual differences between source and target domains.", "conclusion": "The method successfully animates images by reinterpreting local structures from datasets, offering flexibility in creative applications."}}
{"id": "2506.22813", "pdf": "https://arxiv.org/pdf/2506.22813", "abs": "https://arxiv.org/abs/2506.22813", "authors": ["Zhuojun Ding", "Wei Wei", "Chenghao Fan"], "title": "Selecting and Merging: Towards Adaptable and Scalable Named Entity Recognition with Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Supervised fine-tuning (SFT) is widely used to align large language models\n(LLMs) with information extraction (IE) tasks, such as named entity recognition\n(NER). However, annotating such fine-grained labels and training\ndomain-specific models is costly. Existing works typically train a unified\nmodel across multiple domains, but such approaches lack adaptation and\nscalability since not all training data benefits target domains and scaling\ntrained models remains challenging. We propose the SaM framework, which\ndynamically Selects and Merges expert models at inference time. Specifically,\nfor a target domain, we select domain-specific experts pre-trained on existing\ndomains based on (i) domain similarity to the target domain and (ii)\nperformance on sampled instances, respectively. The experts are then merged to\ncreate task-specific models optimized for the target domain. By dynamically\nmerging experts beneficial to target domains, we improve generalization across\nvarious domains without extra training. Additionally, experts can be added or\nremoved conveniently, leading to great scalability. Extensive experiments on\nmultiple benchmarks demonstrate our framework's effectiveness, which\noutperforms the unified model by an average of 10%. We further provide insights\ninto potential improvements, practical experience, and extensions of our\nframework.", "AI": {"tldr": "The paper introduces SaM, a framework for dynamically selecting and merging expert models for domain-specific tasks, improving generalization and scalability without extra training.", "motivation": "Supervised fine-tuning for domain-specific tasks like NER is costly and lacks adaptability. Unified models struggle with scalability and domain adaptation.", "method": "SaM selects domain-specific experts based on domain similarity and performance, then merges them to create task-specific models for target domains.", "result": "SaM outperforms unified models by 10% on average across benchmarks, offering better generalization and scalability.", "conclusion": "The SaM framework effectively addresses domain adaptation and scalability challenges, with potential for further improvements and extensions."}}
{"id": "2506.21448", "pdf": "https://arxiv.org/pdf/2506.21448", "abs": "https://arxiv.org/abs/2506.21448", "authors": ["Huadai Liu", "Jialei Wang", "Kaicheng Luo", "Wen Wang", "Qian Chen", "Zhou Zhao", "Wei Xue"], "title": "ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing", "categories": ["eess.AS", "cs.CV", "cs.SD"], "comment": null, "summary": "While end-to-end video-to-audio generation has greatly improved, producing\nhigh-fidelity audio that authentically captures the nuances of visual content\nremains challenging. Like professionals in the creative industries, such\ngeneration requires sophisticated reasoning about items such as visual\ndynamics, acoustic environments, and temporal relationships. We present\nThinkSound, a novel framework that leverages Chain-of-Thought (CoT) reasoning\nto enable stepwise, interactive audio generation and editing for videos. Our\napproach decomposes the process into three complementary stages: foundational\nfoley generation that creates semantically coherent soundscapes, interactive\nobject-centric refinement through precise user interactions, and targeted\nediting guided by natural language instructions. At each stage, a multimodal\nlarge language model generates contextually aligned CoT reasoning that guides a\nunified audio foundation model. Furthermore, we introduce AudioCoT, a\ncomprehensive dataset with structured reasoning annotations that establishes\nconnections between visual content, textual descriptions, and sound synthesis.\nExperiments demonstrate that ThinkSound achieves state-of-the-art performance\nin video-to-audio generation across both audio metrics and CoT metrics and\nexcels in out-of-distribution Movie Gen Audio benchmark. The demo page is\navailable at https://ThinkSound-Project.github.io.", "AI": {"tldr": "ThinkSound is a novel framework using Chain-of-Thought reasoning for high-fidelity video-to-audio generation, outperforming state-of-the-art methods.", "motivation": "Producing authentic audio from videos requires nuanced reasoning about visual dynamics and acoustics, which current methods struggle with.", "method": "ThinkSound decomposes audio generation into three stages: foundational foley generation, interactive refinement, and targeted editing, guided by multimodal CoT reasoning.", "result": "ThinkSound achieves state-of-the-art performance in audio and CoT metrics and excels in out-of-distribution benchmarks.", "conclusion": "ThinkSound advances video-to-audio generation by integrating structured reasoning and user interaction, setting a new benchmark for fidelity and adaptability."}}
{"id": "2312.03121", "pdf": "https://arxiv.org/pdf/2312.03121", "abs": "https://arxiv.org/abs/2312.03121", "authors": ["Marc Lanctot", "Kate Larson", "Yoram Bachrach", "Luke Marris", "Zun Li", "Avishkar Bhoopchand", "Thomas Anthony", "Brian Tanner", "Anna Koop"], "title": "Evaluating Agents using Social Choice Theory", "categories": ["cs.AI", "cs.GT", "cs.MA"], "comment": null, "summary": "We argue that many general evaluation problems can be viewed through the lens\nof voting theory. Each task is interpreted as a separate voter, which requires\nonly ordinal rankings or pairwise comparisons of agents to produce an overall\nevaluation. By viewing the aggregator as a social welfare function, we are able\nto leverage centuries of research in social choice theory to derive principled\nevaluation frameworks with axiomatic foundations. These evaluations are\ninterpretable and flexible, while avoiding many of the problems currently\nfacing cross-task evaluation. We apply this Voting-as-Evaluation (VasE)\nframework across multiple settings, including reinforcement learning, large\nlanguage models, and humans. In practice, we observe that VasE can be more\nrobust than popular evaluation frameworks (Elo and Nash averaging), discovers\nproperties in the evaluation data not evident from scores alone, and can\npredict outcomes better than Elo in a complex seven-player game. We identify\none particular approach, maximal lotteries, that satisfies important\nconsistency properties relevant to evaluation, is computationally efficient\n(polynomial in the size of the evaluation data), and identifies game-theoretic\ncycles.", "AI": {"tldr": "The paper proposes Voting-as-Evaluation (VasE), a framework using voting theory to aggregate ordinal rankings or pairwise comparisons for robust and interpretable evaluations across tasks.", "motivation": "To address challenges in cross-task evaluation by leveraging social choice theory for principled, flexible, and interpretable aggregation methods.", "method": "VasE interprets tasks as voters, using social welfare functions to aggregate rankings or comparisons. It applies maximal lotteries for consistency and efficiency.", "result": "VasE outperforms Elo and Nash averaging in robustness, reveals hidden evaluation data properties, and predicts outcomes better in complex games.", "conclusion": "VasE provides a theoretically grounded, practical solution for evaluation problems, with maximal lotteries offering consistency and computational efficiency."}}
{"id": "2412.01053", "pdf": "https://arxiv.org/pdf/2412.01053", "abs": "https://arxiv.org/abs/2412.01053", "authors": ["Youqiang Zheng", "Weiping Tu", "Yueteng Kang", "Jie Chen", "Yike Zhang", "Li Xiao", "Yuhong Yang", "Long Ma"], "title": "FreeCodec: A disentangled neural speech codec with fewer tokens", "categories": ["cs.SD", "eess.AS"], "comment": "5 pages, 2 figures, 3 tables.Code and Demo\n  page:https://github.com/exercise-book-yq/FreeCodec. Accepted to Interspeech\n  2025", "summary": "Neural speech codecs have gained great attention for their outstanding\nreconstruction with discrete token representations.\n  It is a crucial component in generative tasks such as speech coding and large\nlanguage models (LLM).\n  However, most works based on residual vector quantization perform worse with\nfewer tokens due to low coding efficiency for modeling complex coupled\ninformation.\n  In this paper, we propose a neural speech codec named FreeCodec which employs\na more effective encoding framework by decomposing intrinsic properties of\nspeech into different components:\n  1) a global vector is extracted as the timbre information,\n  2) a prosody encoder with a long stride level is used to model the prosody\ninformation,\n  3) the content information is from a content encoder.\n  Using different training strategies, FreeCodec achieves state-of-the-art\nperformance in reconstruction and disentanglement scenarios.\n  Results from subjective and objective experiments demonstrate that our\nframework outperforms existing methods.", "AI": {"tldr": "FreeCodec is a neural speech codec that decomposes speech into timbre, prosody, and content components, achieving state-of-the-art performance in reconstruction and disentanglement.", "motivation": "Existing neural speech codecs perform poorly with fewer tokens due to inefficient modeling of complex coupled information.", "method": "FreeCodec decomposes speech into timbre (global vector), prosody (long stride encoder), and content (content encoder) components, using specialized training strategies.", "result": "FreeCodec outperforms existing methods in both subjective and objective experiments.", "conclusion": "FreeCodec provides an effective framework for speech coding and generative tasks, improving reconstruction and disentanglement."}}
{"id": "2506.23466", "pdf": "https://arxiv.org/pdf/2506.23466", "abs": "https://arxiv.org/abs/2506.23466", "authors": ["Qiqing Liu", "Guoquan Wei", "Zekun Zhou", "Yiyang Wen", "Liu Shi", "Qiegen Liu"], "title": "FD-DiT: Frequency Domain-Directed Diffusion Transformer for Low-Dose CT Reconstruction", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "comment": "11pages, 11 figures", "summary": "Low-dose computed tomography (LDCT) reduces radiation exposure but suffers\nfrom image artifacts and loss of detail due to quantum and electronic noise,\npotentially impacting diagnostic accuracy. Transformer combined with diffusion\nmodels has been a promising approach for image generation. Nevertheless,\nexisting methods exhibit limitations in preserving finegrained image details.\nTo address this issue, frequency domain-directed diffusion transformer (FD-DiT)\nis proposed for LDCT reconstruction. FD-DiT centers on a diffusion strategy\nthat progressively introduces noise until the distribution statistically aligns\nwith that of LDCT data, followed by denoising processing. Furthermore, we\nemploy a frequency decoupling technique to concentrate noise primarily in\nhigh-frequency domain, thereby facilitating effective capture of essential\nanatomical structures and fine details. A hybrid denoising network is then\nutilized to optimize the overall data reconstruction process. To enhance the\ncapability in recognizing high-frequency noise, we incorporate sliding sparse\nlocal attention to leverage the sparsity and locality of shallow-layer\ninformation, propagating them via skip connections for improving feature\nrepresentation. Finally, we propose a learnable dynamic fusion strategy for\noptimal component integration. Experimental results demonstrate that at\nidentical dose levels, LDCT images reconstructed by FD-DiT exhibit superior\nnoise and artifact suppression compared to state-of-the-art methods.", "AI": {"tldr": "FD-DiT, a frequency domain-directed diffusion transformer, improves LDCT reconstruction by focusing on noise distribution alignment and frequency decoupling, outperforming existing methods in noise and artifact suppression.", "motivation": "LDCT reduces radiation exposure but suffers from noise and artifacts, impacting diagnostic accuracy. Existing methods fail to preserve fine details.", "method": "FD-DiT uses a diffusion strategy for noise alignment, frequency decoupling to focus noise in high-frequency domains, a hybrid denoising network, sliding sparse local attention, and dynamic fusion for optimal integration.", "result": "FD-DiT achieves superior noise and artifact suppression in LDCT images compared to state-of-the-art methods at identical dose levels.", "conclusion": "FD-DiT effectively addresses LDCT reconstruction challenges, enhancing diagnostic accuracy by preserving fine details and suppressing noise."}}
{"id": "2506.23276", "pdf": "https://arxiv.org/pdf/2506.23276", "abs": "https://arxiv.org/abs/2506.23276", "authors": ["David Guzman Piedrahita", "Yongjin Yang", "Mrinmaya Sachan", "Giorgia Ramponi", "Bernhard Sch\u00f6lkopf", "Zhijing Jin"], "title": "Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "As large language models (LLMs) are increasingly deployed as autonomous\nagents, understanding their cooperation and social mechanisms is becoming\nincreasingly important. In particular, how LLMs balance self-interest and\ncollective well-being is a critical challenge for ensuring alignment,\nrobustness, and safe deployment. In this paper, we examine the challenge of\ncostly sanctioning in multi-agent LLM systems, where an agent must decide\nwhether to invest its own resources to incentivize cooperation or penalize\ndefection. To study this, we adapt a public goods game with institutional\nchoice from behavioral economics, allowing us to observe how different LLMs\nnavigate social dilemmas over repeated interactions. Our analysis reveals four\ndistinct behavioral patterns among models: some consistently establish and\nsustain high levels of cooperation, others fluctuate between engagement and\ndisengagement, some gradually decline in cooperative behavior over time, and\nothers rigidly follow fixed strategies regardless of outcomes. Surprisingly, we\nfind that reasoning LLMs, such as the o1 series, struggle significantly with\ncooperation, whereas some traditional LLMs consistently achieve high levels of\ncooperation. These findings suggest that the current approach to improving\nLLMs, which focuses on enhancing their reasoning capabilities, does not\nnecessarily lead to cooperation, providing valuable insights for deploying LLM\nagents in environments that require sustained collaboration. Our code is\navailable at https://github.com/davidguzmanp/SanctSim", "AI": {"tldr": "The paper explores how LLMs balance self-interest and collective well-being in multi-agent systems, revealing distinct cooperation patterns and challenges, especially for reasoning-focused models.", "motivation": "Understanding LLM cooperation is crucial for safe and robust deployment, particularly in scenarios requiring costly sanctioning to incentivize collaboration.", "method": "Adapts a public goods game with institutional choice from behavioral economics to study LLM behavior in repeated social dilemmas.", "result": "Identifies four behavioral patterns in LLMs, with reasoning-focused models struggling in cooperation while traditional models perform better.", "conclusion": "Enhancing reasoning capabilities in LLMs does not guarantee cooperation, offering insights for deploying collaborative LLM agents."}}
{"id": "2506.22685", "pdf": "https://arxiv.org/pdf/2506.22685", "abs": "https://arxiv.org/abs/2506.22685", "authors": ["Anh Bui", "Trang Vu", "Trung Le", "Junae Kim", "Tamas Abraham", "Rollin Omari", "Amar Kaur", "Dinh Phung"], "title": "Mitigating Semantic Collapse in Generative Personalization with a Surprisingly Simple Test-Time Embedding Adjustment", "categories": ["cs.LG", "cs.GR"], "comment": null, "summary": "In this paper, we investigate the semantic collapsing problem in generative\npersonalization, an under-explored topic where the learned visual concept\n($V^*$) gradually shifts from its original textual meaning and comes to\ndominate other concepts in multi-concept input prompts. This issue not only\nreduces the semantic richness of complex input prompts like \"a photo of $V^*$\nwearing glasses and playing guitar\" into simpler, less contextually rich forms\nsuch as \"a photo of $V^*$\" but also leads to simplified output images that fail\nto capture the intended concept.\n  We identify the root cause as unconstrained optimisation, which allows the\nlearned embedding $V^*$ to drift arbitrarily in the embedding space, both in\ndirection and magnitude. To address this, we propose a simple yet effective\ntraining-free method that adjusts the magnitude and direction of pre-trained\nembedding at inference time, effectively mitigating the semantic collapsing\nproblem. Our method is broadly applicable across different personalization\nmethods and demonstrates significant improvements in text-image alignment in\ndiverse use cases. Our code is anonymously published at\nhttps://anonymous.4open.science/r/Embedding-Adjustment.", "AI": {"tldr": "The paper addresses semantic collapsing in generative personalization, where learned visual concepts drift from their textual meanings, simplifying outputs. A training-free method adjusts embeddings to mitigate this.", "motivation": "Semantic collapsing reduces the richness of multi-concept prompts, leading to oversimplified outputs. The goal is to preserve semantic alignment.", "method": "A training-free approach adjusts the magnitude and direction of pre-trained embeddings during inference to prevent drift.", "result": "The method improves text-image alignment across various personalization techniques.", "conclusion": "The proposed embedding adjustment effectively mitigates semantic collapsing, enhancing output quality without additional training."}}
{"id": "2506.22562", "pdf": "https://arxiv.org/pdf/2506.22562", "abs": "https://arxiv.org/abs/2506.22562", "authors": ["Abhineet Singh", "Nilanjan Ray"], "title": "Improving Token-based Object Detection with Video", "categories": ["cs.CV"], "comment": "Under review for publication in IEEE Access", "summary": "This paper improves upon the Pix2Seq object detector by extending it for\nvideos. In the process, it introduces a new way to perform end-to-end video\nobject detection that improves upon existing video detectors in two key ways.\nFirst, by representing objects as variable-length sequences of discrete tokens,\nwe can succinctly represent widely varying numbers of video objects, with\ndiverse shapes and locations, without having to inject any localization cues in\nthe training process. This eliminates the need to sample the space of all\npossible boxes that constrains conventional detectors and thus solves the dual\nproblems of loss sparsity during training and heuristics-based postprocessing\nduring inference. Second, it conceptualizes and outputs the video objects as\nfully integrated and indivisible 3D boxes or tracklets instead of generating\nimage-specific 2D boxes and linking these boxes together to construct the video\nobject, as done in most conventional detectors. This allows it to scale\neffortlessly with available computational resources by simply increasing the\nlength of the video subsequence that the network takes as input, even\ngeneralizing to multi-object tracking if the subsequence can span the entire\nvideo. We compare our video detector with the baseline Pix2Seq static detector\non several datasets and demonstrate consistent improvement, although with\nstrong signs of being bottlenecked by our limited computational resources. We\nalso compare it with several video detectors on UA-DETRAC to show that it is\ncompetitive with the current state of the art even with the computational\nbottleneck. We make our code and models publicly available.", "AI": {"tldr": "The paper extends Pix2Seq for video object detection, introducing a method that uses discrete tokens for object representation and outputs 3D tracklets, improving scalability and eliminating postprocessing heuristics.", "motivation": "To address limitations of conventional video detectors, such as loss sparsity and heuristics-based postprocessing, by leveraging sequence-based object representation and integrated 3D tracklets.", "method": "Represents objects as variable-length sequences of discrete tokens and outputs integrated 3D tracklets, enabling scalable and end-to-end video object detection.", "result": "Outperforms the baseline Pix2Seq static detector and is competitive with state-of-the-art video detectors on UA-DETRAC, despite computational bottlenecks.", "conclusion": "The proposed method offers a scalable and efficient approach to video object detection, with potential for generalization to multi-object tracking."}}
{"id": "2506.22852", "pdf": "https://arxiv.org/pdf/2506.22852", "abs": "https://arxiv.org/abs/2506.22852", "authors": ["Yucheng Cai", "Yuxuan Wu", "Yi Huang", "Junlan Feng", "Zhijian Ou"], "title": "Knowledge Augmented Finetuning Matters in both RAG and Agent Based Dialog Systems", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have recently been applied to dialog systems.\nDespite making progress, LLMs are prone to errors in knowledge-intensive\nscenarios. Recently, approaches based on retrieval augmented generation (RAG)\nand agent have emerged to improve the factual accuracy by enhancing the LLMs\nwith knowledge retrieved from external knowledge bases (KBs). This is mostly\nimplemented by prompting the LLMs with instructions, examples and the retrieved\nknowledge. However, LLMs may have difficulty using the retrieved knowledge\neffectively for response generation, because they are not well trained to do\nsuch generation for specific domains. To mitigate this problem, we propose to\nfinetune the LLMs in the RAG-based and agent-based systems with domain-specific\ndata, together with domain-specific external knowledge, which is called\nknowledge augmented finetuning (KAFT). We base our study on the MobileCS2\ndataset, a real-life customer service dialog dataset that features intensive\nknowledge interactions, to systematically compare the prompting and KAFT\ntechniques in the RAG-based and agent-based systems. Experiment results show\nthat KAFT substantially surpasses prompting in both RAG and agent systems,\nparticularly in terms of factual accuracy. To the best of our knowledge, this\npaper represents the first solid empirical work to investigate the KAFT idea.", "AI": {"tldr": "The paper proposes Knowledge Augmented Fine-Tuning (KAFT) to improve LLMs' factual accuracy in knowledge-intensive dialog systems by fine-tuning with domain-specific data and external knowledge, outperforming prompting methods.", "motivation": "LLMs struggle with factual accuracy in knowledge-intensive scenarios, even when augmented with external knowledge via RAG or agent-based systems.", "method": "Proposes KAFT, fine-tuning LLMs with domain-specific data and external knowledge, tested on the MobileCS2 dataset.", "result": "KAFT significantly outperforms prompting in RAG and agent systems, especially in factual accuracy.", "conclusion": "KAFT is an effective method to enhance LLMs' performance in knowledge-intensive tasks, validated by empirical results."}}
{"id": "2505.20868", "pdf": "https://arxiv.org/pdf/2505.20868", "abs": "https://arxiv.org/abs/2505.20868", "authors": ["Nam-Gyu Kim", "Deok-Hyeon Cho", "Seung-Bin Kim", "Seong-Whan Lee"], "title": "Spotlight-TTS: Spotlighting the Style via Voiced-Aware Style Extraction and Style Direction Adjustment for Expressive Text-to-Speech", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Proceedings of Interspeech 2025", "summary": "Recent advances in expressive text-to-speech (TTS) have introduced diverse\nmethods based on style embedding extracted from reference speech. However,\nsynthesizing high-quality expressive speech remains challenging. We propose\nSpotlight-TTS, which exclusively emphasizes style via voiced-aware style\nextraction and style direction adjustment. Voiced-aware style extraction\nfocuses on voiced regions highly related to style while maintaining continuity\nacross different speech regions to improve expressiveness. We adjust the\ndirection of the extracted style for optimal integration into the TTS model,\nwhich improves speech quality. Experimental results demonstrate that\nSpotlight-TTS achieves superior performance compared to baseline models in\nterms of expressiveness, overall speech quality, and style transfer capability.\nOur audio samples are publicly available.", "AI": {"tldr": "Spotlight-TTS improves expressive speech synthesis by focusing on voiced regions for style extraction and adjusting style direction for better integration.", "motivation": "Existing methods struggle with synthesizing high-quality expressive speech despite advances in style embedding from reference speech.", "method": "Spotlight-TTS uses voiced-aware style extraction and style direction adjustment to enhance expressiveness and speech quality.", "result": "The model outperforms baselines in expressiveness, speech quality, and style transfer, with publicly available audio samples.", "conclusion": "Spotlight-TTS effectively addresses challenges in expressive TTS by refining style extraction and integration."}}
{"id": "2402.15677", "pdf": "https://arxiv.org/pdf/2402.15677", "abs": "https://arxiv.org/abs/2402.15677", "authors": ["Hoang Huy Vu", "Quyen Ngoc Nguyen", "Tuynh Van Pham", "Chuong Van Nguyen", "Minh Hoang Trinh"], "title": "Consensus seeking in diffusive multidimensional networks with a repeated interaction pattern and time-delays", "categories": ["eess.SY", "cs.MA", "cs.SY"], "comment": "6 pages, 7 figures, accepted to CCTA 2025", "summary": "This paper studies a consensus problem in multidimensional networks having\nthe same agent-to-agent interaction pattern under both intra- and cross-layer\ntime delays. Several conditions for the agents to asymptotically reach a\nconsensus are derived, which involve the overall network's structure, the local\ninteracting pattern, and the assumptions specified on the time delays. The\nvalidity of these conditions is proved by direct eigenvalue evaluation and\nsupported by numerical simulations.", "AI": {"tldr": "The paper analyzes consensus in multidimensional networks with intra- and cross-layer delays, deriving conditions for asymptotic consensus and validating them through eigenvalue analysis and simulations.", "motivation": "To understand how time delays in multidimensional networks affect consensus among agents.", "method": "Derived conditions for consensus using network structure, interaction patterns, and delay assumptions, validated via eigenvalue evaluation and simulations.", "result": "Identified conditions enabling asymptotic consensus, supported by theoretical proofs and numerical results.", "conclusion": "The study provides insights into consensus under delays, with practical implications for networked systems."}}
{"id": "2506.18488", "pdf": "https://arxiv.org/pdf/2506.18488", "abs": "https://arxiv.org/abs/2506.18488", "authors": ["Markus Frohmann", "Elena V. Epure", "Gabriel Meseguer-Brocal", "Markus Schedl", "Romain Hennequin"], "title": "AI-Generated Song Detection via Lyrics Transcripts", "categories": ["cs.SD", "cs.AI", "cs.CL"], "comment": "Accepted to ISMIR 2025", "summary": "The recent rise in capabilities of AI-based music generation tools has\ncreated an upheaval in the music industry, necessitating the creation of\naccurate methods to detect such AI-generated content. This can be done using\naudio-based detectors; however, it has been shown that they struggle to\ngeneralize to unseen generators or when the audio is perturbed. Furthermore,\nrecent work used accurate and cleanly formatted lyrics sourced from a lyrics\nprovider database to detect AI-generated music. However, in practice, such\nperfect lyrics are not available (only the audio is); this leaves a substantial\ngap in applicability in real-life use cases. In this work, we instead propose\nsolving this gap by transcribing songs using general automatic speech\nrecognition (ASR) models. We do this using several detectors. The results on\ndiverse, multi-genre, and multi-lingual lyrics show generally strong detection\nperformance across languages and genres, particularly for our best-performing\nmodel using Whisper large-v2 and LLM2Vec embeddings. In addition, we show that\nour method is more robust than state-of-the-art audio-based ones when the audio\nis perturbed in different ways and when evaluated on different music\ngenerators. Our code is available at\nhttps://github.com/deezer/robust-AI-lyrics-detection.", "AI": {"tldr": "Proposes using ASR models to transcribe and detect AI-generated music lyrics, outperforming audio-based methods in robustness and generalization.", "motivation": "Address the gap in detecting AI-generated music when perfect lyrics are unavailable, improving real-world applicability.", "method": "Uses ASR models (e.g., Whisper large-v2) to transcribe songs and employs detectors (e.g., LLM2Vec embeddings) for AI-generated content.", "result": "Strong detection performance across languages and genres, with robustness to audio perturbations and unseen generators.", "conclusion": "The method is more robust than audio-based detectors, offering practical solutions for real-life scenarios."}}
{"id": "2506.23490", "pdf": "https://arxiv.org/pdf/2506.23490", "abs": "https://arxiv.org/abs/2506.23490", "authors": ["Junxuan Yu", "Yaofei Duan", "Yuhao Huang", "Yu Wang", "Rongbo Ling", "Weihao Luo", "Ang Zhang", "Jingxian Xu", "Qiongying Ni", "Yongsong Zhou", "Binghan Li", "Haoran Dou", "Liping Liu", "Yanfen Chu", "Feng Geng", "Zhe Sheng", "Zhifeng Ding", "Dingxin Zhang", "Rui Huang", "Yuhang Zhang", "Xiaowei Xu", "Tao Tan", "Dong Ni", "Zhongshan Gou", "Xin Yang"], "title": "UltraTwin: Towards Cardiac Anatomical Twin Generation from Multi-view 2D Ultrasound", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "accepted by miccai 2025", "summary": "Echocardiography is routine for cardiac examination. However, 2D ultrasound\n(US) struggles with accurate metric calculation and direct observation of 3D\ncardiac structures. Moreover, 3D US is limited by low resolution, small field\nof view and scarce availability in practice. Constructing the cardiac\nanatomical twin from 2D images is promising to provide precise treatment\nplanning and clinical quantification. However, it remains challenging due to\nthe rare paired data, complex structures, and US noises. In this study, we\nintroduce a novel generative framework UltraTwin, to obtain cardiac anatomical\ntwin from sparse multi-view 2D US. Our contribution is three-fold. First,\npioneered the construction of a real-world and high-quality dataset containing\nstrictly paired multi-view 2D US and CT, and pseudo-paired data. Second, we\npropose a coarse-to-fine scheme to achieve hierarchical reconstruction\noptimization. Last, we introduce an implicit autoencoder for topology-aware\nconstraints. Extensive experiments show that UltraTwin reconstructs\nhigh-quality anatomical twins versus strong competitors. We believe it advances\nanatomical twin modeling for potential applications in personalized cardiac\ncare.", "AI": {"tldr": "UltraTwin is a generative framework for creating cardiac anatomical twins from sparse 2D ultrasound images, addressing challenges like rare paired data and US noise. It uses a coarse-to-fine reconstruction scheme and an implicit autoencoder, validated by a high-quality dataset and outperforming competitors.", "motivation": "2D ultrasound struggles with 3D cardiac structure accuracy, while 3D ultrasound has limitations like low resolution and availability. A solution is needed for precise treatment planning.", "method": "UltraTwin employs a coarse-to-fine hierarchical reconstruction scheme and an implicit autoencoder for topology-aware constraints, using a dataset of paired 2D US and CT images.", "result": "UltraTwin reconstructs high-quality anatomical twins, outperforming competitors, as shown in extensive experiments.", "conclusion": "UltraTwin advances anatomical twin modeling, offering potential for personalized cardiac care."}}
{"id": "2506.23306", "pdf": "https://arxiv.org/pdf/2506.23306", "abs": "https://arxiv.org/abs/2506.23306", "authors": ["Qi Liu", "Can Li", "Wanjing Ma"], "title": "GATSim: Urban Mobility Simulation with Generative Agents", "categories": ["cs.AI"], "comment": null, "summary": "Traditional agent-based urban mobility simulations rely on rigid rule-based\nsystems that fail to capture the complexity, adaptability, and behavioral\ndiversity characteristic of human travel decision-making. Recent advances in\nlarge language models and AI agent technology offer opportunities to create\nagents with reasoning capabilities, persistent memory, and adaptive learning\nmechanisms. We propose GATSim (Generative-Agent Transport Simulation), a novel\nframework that leverages these advances to create generative agents with rich\nbehavioral characteristics for urban mobility simulation. Unlike conventional\napproaches, GATSim agents possess diverse socioeconomic attributes, individual\nlifestyles, and evolving preferences that shape their mobility decisions\nthrough psychologically-informed memory systems, tool usage capabilities, and\nlifelong learning mechanisms. The main contributions of this study include: (1)\na comprehensive architecture combining an urban mobility foundation model with\nagent cognitive systems and transport simulation environment, (2) a fully\nfunctional prototype implementation, and (3) systematic validation\ndemonstrating that generative agents produce believable travel behaviors.\nThrough designed reflection processes, generative agents in this study can\ntransform specific travel experiences into generalized insights, enabling\nrealistic behavioral adaptation over time with specialized mechanisms for\nactivity planning and real-time reactive behaviors tailored to urban mobility\ncontexts. Experiments show that generative agents perform competitively with\nhuman annotators in mobility scenarios while naturally producing macroscopic\ntraffic evolution patterns. The code for the prototype system is shared at\nhttps://github.com/qiliuchn/gatsim.", "AI": {"tldr": "GATSim introduces generative AI agents for urban mobility simulation, capturing human-like adaptability and diversity in travel decisions.", "motivation": "Traditional rule-based systems lack the complexity and adaptability of human decision-making in urban mobility.", "method": "GATSim combines an urban mobility foundation model with agent cognitive systems, featuring memory, learning, and tool usage.", "result": "Generative agents produce believable travel behaviors and competitive performance with human annotators.", "conclusion": "GATSim offers a realistic, adaptive framework for urban mobility simulation, validated through experiments."}}
{"id": "2506.22696", "pdf": "https://arxiv.org/pdf/2506.22696", "abs": "https://arxiv.org/abs/2506.22696", "authors": ["Brian Mak", "Jeffrey Flanigan"], "title": "Residual Matrix Transformers: Scaling the Size of the Residual Stream", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted to ICML 2025", "summary": "The residual stream acts as a memory bus where transformer layers both store\nand access features (Elhage et al., 2021). We consider changing the mechanism\nfor retrieving and storing information in the residual stream, and replace the\nresidual stream of the transformer with an outer product memory matrix\n(Kohonen, 1972, Anderson, 1972). We call this model the Residual Matrix\nTransformer (RMT). We find that the RMT enjoys a number of attractive\nproperties: 1) the size of the residual stream can be scaled independently of\ncompute and model size, improving performance, 2) the RMT can achieve the same\nloss as the transformer with 58% fewer FLOPS, 25% fewer parameters, and 41%\nfewer training tokens tokens, and 3) the RMT outperforms the transformer on\ndownstream evaluations. We theoretically analyze the transformer and the RMT,\nand show that the RMT allows for more efficient scaling of the residual stream,\nas well as improved variance propagation properties. Code for this project can\nbe found at https://github.com/bmac3/residual-matrix-transformer.", "AI": {"tldr": "The paper introduces the Residual Matrix Transformer (RMT), replacing the transformer's residual stream with an outer product memory matrix, achieving better efficiency and performance.", "motivation": "To improve the efficiency and performance of transformers by modifying the residual stream mechanism for storing and retrieving information.", "method": "Replaces the transformer's residual stream with an outer product memory matrix, creating the RMT model.", "result": "RMT scales residual stream independently, reduces FLOPS (58%), parameters (25%), and training tokens (41%), and outperforms transformers in downstream tasks.", "conclusion": "RMT offers efficient scaling and improved performance, making it a promising alternative to traditional transformers."}}
{"id": "2506.22567", "pdf": "https://arxiv.org/pdf/2506.22567", "abs": "https://arxiv.org/abs/2506.22567", "authors": ["Shansong Wang", "Zhecheng Jin", "Mingzhe Hu", "Mojtaba Safari", "Feng Zhao", "Chih-Wei Chang", "Richard LJ Qiu", "Justin Roper", "David S. Yu", "Xiaofeng Yang"], "title": "Unifying Biomedical Vision-Language Expertise: Towards a Generalist Foundation Model via Multi-CLIP Knowledge Distillation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "CLIP models pretrained on natural images with billion-scale image-text pairs\nhave demonstrated impressive capabilities in zero-shot classification,\ncross-modal retrieval, and open-ended visual answering. However, transferring\nthis success to biomedicine is hindered by the scarcity of large-scale\nbiomedical image-text corpora, the heterogeneity of image modalities, and\nfragmented data standards across institutions. These limitations hinder the\ndevelopment of a unified and generalizable biomedical foundation model trained\nfrom scratch. To overcome this, we introduce MMKD-CLIP, a generalist biomedical\nfoundation model developed via Multiple Medical CLIP Knowledge Distillation.\nRather than relying on billion-scale raw data, MMKD-CLIP distills knowledge\nfrom nine state-of-the-art domain-specific or generalist biomedical CLIP\nmodels, each pretrained on millions of biomedical image-text pairs. Our\ntwo-stage training pipeline first performs CLIP-style pretraining on over 2.9\nmillion biomedical image-text pairs from 26 image modalities, followed by\nfeature-level distillation using over 19.2 million feature pairs extracted from\nteacher models. We evaluate MMKD-CLIP on 58 diverse biomedical datasets,\nencompassing over 10.8 million biomedical images across nine image modalities.\nThe evaluation spans six core task types: zero-shot classification, linear\nprobing, cross-modal retrieval, visual question answering, survival prediction,\nand cancer diagnosis. MMKD-CLIP consistently outperforms all teacher models\nwhile demonstrating remarkable robustness and generalization across image\ndomains and task settings. These results underscore that multi-teacher\nknowledge distillation is a scalable and effective paradigm for building\nhigh-performing biomedical foundation models under the practical constraints of\nreal-world data availability.", "AI": {"tldr": "MMKD-CLIP, a biomedical foundation model, uses multi-teacher knowledge distillation to overcome data scarcity and heterogeneity, outperforming existing models across diverse tasks.", "motivation": "Transferring CLIP's success to biomedicine is challenging due to limited data, heterogeneous modalities, and fragmented standards.", "method": "Two-stage training: CLIP-style pretraining on 2.9M biomedical image-text pairs, followed by feature-level distillation from 9 teacher models.", "result": "Outperforms teacher models on 58 datasets across 6 task types, showing robustness and generalization.", "conclusion": "Multi-teacher knowledge distillation is scalable and effective for biomedical foundation models under real-world constraints."}}
{"id": "2506.22853", "pdf": "https://arxiv.org/pdf/2506.22853", "abs": "https://arxiv.org/abs/2506.22853", "authors": ["Kyochul Jang", "Donghyeon Lee", "Kyusik Kim", "Dongseok Heo", "Taewhoo Lee", "Woojeong Kim", "Bongwon Suh"], "title": "DICE-BENCH: Evaluating the Tool-Use Capabilities of Large Language Models in Multi-Round, Multi-Party Dialogues", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, ACL 2025 Vienna", "summary": "Existing function-calling benchmarks focus on single-turn interactions.\nHowever, they overlook the complexity of real-world scenarios. To quantify how\nexisting benchmarks address practical applications, we introduce DICE-SCORE, a\nmetric that evaluates the dispersion of tool-related information such as\nfunction name and parameter values throughout the dialogue. Analyzing existing\nbenchmarks through DICE-SCORE reveals notably low scores, highlighting the need\nfor more realistic scenarios. To address this gap, we present DICE-BENCH, a\nframework that constructs practical function-calling datasets by synthesizing\nconversations through a tool graph that maintains dependencies across rounds\nand a multi-agent system with distinct personas to enhance dialogue\nnaturalness. The final dataset comprises 1,607 high-DICE-SCORE instances. Our\nexperiments on 19 LLMs with DICE-BENCH show that significant advances are still\nrequired before such models can be deployed effectively in real-world settings.\nOur code and data are all publicly available:\nhttps://snuhcc.github.io/DICE-Bench/.", "AI": {"tldr": "The paper introduces DICE-SCORE to evaluate tool-related information dispersion in dialogues and DICE-BENCH, a framework for creating realistic function-calling datasets.", "motivation": "Existing benchmarks lack realism in function-calling scenarios, prompting the need for a more practical evaluation metric and dataset.", "method": "Developed DICE-SCORE for evaluation and DICE-BENCH, a framework using tool graphs and multi-agent systems to synthesize realistic dialogues.", "result": "DICE-BENCH produced 1,607 high-DICE-SCORE instances, revealing gaps in current LLM capabilities for real-world deployment.", "conclusion": "Significant improvements are needed for LLMs to handle real-world function-calling tasks effectively."}}
{"id": "2506.15981", "pdf": "https://arxiv.org/pdf/2506.15981", "abs": "https://arxiv.org/abs/2506.15981", "authors": ["Markus Frohmann", "Gabriel Meseguer-Brocal", "Markus Schedl", "Elena V. Epure"], "title": "Double Entendre: Robust Audio-Based AI-Generated Lyrics Detection via Multi-View Fusion", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "comment": "Accepted to ACL 2025 Findings", "summary": "The rapid advancement of AI-based music generation tools is revolutionizing\nthe music industry but also posing challenges to artists, copyright holders,\nand providers alike. This necessitates reliable methods for detecting such\nAI-generated content. However, existing detectors, relying on either audio or\nlyrics, face key practical limitations: audio-based detectors fail to\ngeneralize to new or unseen generators and are vulnerable to audio\nperturbations; lyrics-based methods require cleanly formatted and accurate\nlyrics, unavailable in practice. To overcome these limitations, we propose a\nnovel, practically grounded approach: a multimodal, modular late-fusion\npipeline that combines automatically transcribed sung lyrics and speech\nfeatures capturing lyrics-related information within the audio. By relying on\nlyrical aspects directly from audio, our method enhances robustness, mitigates\nsusceptibility to low-level artifacts, and enables practical applicability.\nExperiments show that our method, DE-detect, outperforms existing lyrics-based\ndetectors while also being more robust to audio perturbations. Thus, it offers\nan effective, robust solution for detecting AI-generated music in real-world\nscenarios. Our code is available at\nhttps://github.com/deezer/robust-AI-lyrics-detection.", "AI": {"tldr": "The paper proposes DE-detect, a multimodal late-fusion pipeline combining transcribed lyrics and speech features to detect AI-generated music, outperforming existing methods in robustness and practicality.", "motivation": "The rise of AI-generated music challenges artists and copyright holders, requiring reliable detection methods. Current detectors (audio or lyrics-based) have limitations like poor generalization and reliance on clean lyrics.", "method": "A multimodal, modular late-fusion pipeline integrates transcribed sung lyrics and speech features from audio, enhancing robustness and practicality.", "result": "DE-detect outperforms existing lyrics-based detectors and is more robust to audio perturbations.", "conclusion": "DE-detect provides an effective, robust solution for detecting AI-generated music in real-world scenarios, with code publicly available."}}
{"id": "2502.13010", "pdf": "https://arxiv.org/pdf/2502.13010", "abs": "https://arxiv.org/abs/2502.13010", "authors": ["Mohammad Reza Rezaei", "Reza Saadati Fard", "Jayson L. Parker", "Rahul G. Krishnan", "Milad Lankarany"], "title": "Agentic Medical Knowledge Graphs Enhance Medical Question Answering: Bridging the Gap Between LLMs and Evolving Medical Knowledge", "categories": ["cs.CL", "cs.MA"], "comment": null, "summary": "Large Language Models (LLMs) have significantly advanced medical\nquestion-answering by leveraging extensive clinical data and medical\nliterature. However, the rapid evolution of medical knowledge and the\nlabor-intensive process of manually updating domain-specific resources pose\nchallenges to the reliability of these systems. To address this, we introduce\nAgentic Medical Graph-RAG (AMG-RAG), a comprehensive framework that automates\nthe construction and continuous updating of medical knowledge graphs,\nintegrates reasoning, and retrieves current external evidence, such as PubMed\nand WikiSearch. By dynamically linking new findings and complex medical\nconcepts, AMG-RAG not only improves accuracy but also enhances interpretability\nin medical queries.\n  Evaluations on the MEDQA and MEDMCQA benchmarks demonstrate the effectiveness\nof AMG-RAG, achieving an F1 score of 74.1 percent on MEDQA and an accuracy of\n66.34 percent on MEDMCQA, outperforming both comparable models and those 10 to\n100 times larger. Notably, these improvements are achieved without increasing\ncomputational overhead, highlighting the critical role of automated knowledge\ngraph generation and external evidence retrieval in delivering up-to-date,\ntrustworthy medical insights.", "AI": {"tldr": "AMG-RAG automates medical knowledge graph updates and integrates external evidence, improving accuracy and interpretability in medical question-answering.", "motivation": "Addressing the challenges of rapidly evolving medical knowledge and manual updates in LLMs for reliable medical insights.", "method": "Introduces AMG-RAG, a framework for automated medical knowledge graph construction, reasoning, and external evidence retrieval (e.g., PubMed, WikiSearch).", "result": "Achieves F1 score of 74.1% on MEDQA and 66.34% accuracy on MEDMCQA, outperforming larger models without added computational cost.", "conclusion": "AMG-RAG demonstrates the importance of automated knowledge graphs and external evidence for accurate, up-to-date medical insights."}}
{"id": "2506.23506", "pdf": "https://arxiv.org/pdf/2506.23506", "abs": "https://arxiv.org/abs/2506.23506", "authors": ["Bowen Xin", "Rohan Hickey", "Tamara Blake", "Jin Jin", "Claire E Wainwright", "Thomas Benkert", "Alto Stemmer", "Peter Sly", "David Coman", "Jason Dowling"], "title": "Artificial Intelligence-assisted Pixel-level Lung (APL) Scoring for Fast and Accurate Quantification in Ultra-short Echo-time MRI", "categories": ["eess.IV", "cs.AI", "cs.CV", "physics.med-ph"], "comment": "Oral presentation in ISMRM2025", "summary": "Lung magnetic resonance imaging (MRI) with ultrashort echo-time (UTE)\nrepresents a recent breakthrough in lung structure imaging, providing image\nresolution and quality comparable to computed tomography (CT). Due to the\nabsence of ionising radiation, MRI is often preferred over CT in paediatric\ndiseases such as cystic fibrosis (CF), one of the most common genetic disorders\nin Caucasians. To assess structural lung damage in CF imaging, CT scoring\nsystems provide valuable quantitative insights for disease diagnosis and\nprogression. However, few quantitative scoring systems are available in\nstructural lung MRI (e.g., UTE-MRI). To provide fast and accurate\nquantification in lung MRI, we investigated the feasibility of novel Artificial\nintelligence-assisted Pixel-level Lung (APL) scoring for CF. APL scoring\nconsists of 5 stages, including 1) image loading, 2) AI lung segmentation, 3)\nlung-bounded slice sampling, 4) pixel-level annotation, and 5) quantification\nand reporting. The results shows that our APL scoring took 8.2 minutes per\nsubject, which was more than twice as fast as the previous grid-level scoring.\nAdditionally, our pixel-level scoring was statistically more accurate\n(p=0.021), while strongly correlating with grid-level scoring (R=0.973,\np=5.85e-9). This tool has great potential to streamline the workflow of UTE\nlung MRI in clinical settings, and be extended to other structural lung MRI\nsequences (e.g., BLADE MRI), and for other lung diseases (e.g.,\nbronchopulmonary dysplasia).", "AI": {"tldr": "The paper introduces APL scoring, an AI-assisted pixel-level method for quantifying lung damage in CF using UTE-MRI, showing faster and more accurate results compared to traditional grid-level scoring.", "motivation": "To address the lack of quantitative scoring systems for structural lung MRI (e.g., UTE-MRI) in diseases like cystic fibrosis (CF), and to provide a faster, more accurate alternative to CT and existing MRI scoring methods.", "method": "APL scoring involves 5 stages: image loading, AI lung segmentation, slice sampling, pixel-level annotation, and quantification. It leverages AI for segmentation and pixel-level analysis.", "result": "APL scoring was twice as fast (8.2 minutes/subject) and statistically more accurate (p=0.021) than grid-level scoring, with strong correlation (R=0.973, p=5.85e-9).", "conclusion": "APL scoring is a promising tool for clinical UTE-MRI workflows, with potential applications in other MRI sequences and lung diseases."}}
{"id": "2506.23464", "pdf": "https://arxiv.org/pdf/2506.23464", "abs": "https://arxiv.org/abs/2506.23464", "authors": ["Sahil Tripathi", "Md Tabrez Nafis", "Imran Hussain", "Jiechao Gao"], "title": "The Confidence Paradox: Can LLM Know When It's Wrong", "categories": ["cs.AI"], "comment": null, "summary": "Document Visual Question Answering (DocVQA) systems are increasingly deployed\nin real world applications, yet they remain ethically opaque-often producing\noverconfident answers to ambiguous questions or failing to communicate\nuncertainty in a trustworthy manner. This misalignment between model confidence\nand actual knowledge poses significant risks, particularly in domains requiring\nethical accountability. Existing approaches such as LayoutLMv3, UDOP, and DONUT\nhave advanced SOTA performance by focusing on architectural sophistication and\naccuracy; however, they fall short in ethical responsiveness.\n  To address these limitations, we introduce HonestVQA, a self-supervised\nhonesty calibration framework for ethically aligned DocVQA. Our model-agnostic\nmethod quantifies uncertainty to identify knowledge gaps, aligns model\nconfidence with actual correctness using weighted loss functions, and enforces\nethical response behavior via contrastive learning. We further introduce two\nprincipled evaluation metrics--Honesty Score (H-Score) and Ethical Confidence\nIndex (ECI)--to benchmark alignment between confidence, accuracy, and ethical\ncommunication. Empirically, HonestVQA improves DocVQA accuracy by up to 4.3%\nand F1 by 4.3% across SpDocVQA, InfographicsVQA, and SROIE datasets. It reduces\noverconfidence, lowering H-Score and ECI by 0.072 and 0.078, respectively. In\ncross domain evaluation, it achieves up to 78.9% accuracy and 76.1% F1-score,\ndemonstrating strong generalization. Ablation shows a 3.8% drop in accuracy\nwithout alignment or contrastive loss.", "AI": {"tldr": "HonestVQA introduces a self-supervised honesty calibration framework for DocVQA, improving accuracy and reducing overconfidence while aligning model confidence with ethical communication.", "motivation": "Current DocVQA systems lack ethical responsiveness, producing overconfident answers or failing to communicate uncertainty, posing risks in ethically accountable domains.", "method": "HonestVQA uses uncertainty quantification, weighted loss functions for confidence alignment, and contrastive learning for ethical response behavior. It introduces H-Score and ECI metrics for evaluation.", "result": "HonestVQA improves accuracy by up to 4.3% and F1 by 4.3%, reduces overconfidence (lower H-Score and ECI), and achieves strong generalization (78.9% accuracy, 76.1% F1-score).", "conclusion": "HonestVQA effectively addresses ethical misalignment in DocVQA, enhancing performance and trustworthiness while generalizing well across domains."}}
{"id": "2506.22708", "pdf": "https://arxiv.org/pdf/2506.22708", "abs": "https://arxiv.org/abs/2506.22708", "authors": ["Shrenik Jadhav", "Birva Sevak", "Srijita Das", "Akhtar Hussain", "Wencong Su", "Van-Hai Bui"], "title": "FairMarket-RL: LLM-Guided Fairness Shaping for Multi-Agent Reinforcement Learning in Peer-to-Peer Markets", "categories": ["cs.LG", "cs.SY", "econ.GN", "eess.SY", "q-fin.EC"], "comment": null, "summary": "Peer-to-peer (P2P) trading is increasingly recognized as a key mechanism for\ndecentralized market regulation, yet existing approaches often lack robust\nframeworks to ensure fairness. This paper presents FairMarket-RL, a novel\nhybrid framework that combines Large Language Models (LLMs) with Reinforcement\nLearning (RL) to enable fairness-aware trading agents. In a simulated P2P\nmicrogrid with multiple sellers and buyers, the LLM acts as a real-time\nfairness critic, evaluating each trading episode using two metrics:\nFairness-To-Buyer (FTB) and Fairness-Between-Sellers (FBS). These fairness\nscores are integrated into agent rewards through scheduled\n{\\lambda}-coefficients, forming an adaptive LLM-guided reward shaping loop that\nreplaces brittle, rule-based fairness constraints. Agents are trained using\nIndependent Proximal Policy Optimization (IPPO) and achieve equitable outcomes,\nfulfilling over 90% of buyer demand, maintaining fair seller margins, and\nconsistently reaching FTB and FBS scores above 0.80. The training process\ndemonstrates that fairness feedback improves convergence, reduces buyer\nshortfalls, and narrows profit disparities between sellers. With its\nlanguage-based critic, the framework scales naturally, and its extension to a\nlarge power distribution system with household prosumers illustrates its\npractical applicability. FairMarket-RL thus offers a scalable, equity-driven\nsolution for autonomous trading in decentralized energy systems.", "AI": {"tldr": "FairMarket-RL combines LLMs and RL to ensure fairness in P2P trading, achieving equitable outcomes with high fairness scores and demand fulfillment.", "motivation": "Existing P2P trading lacks robust fairness frameworks, necessitating a scalable, adaptive solution.", "method": "Uses LLMs as fairness critics with FTB and FBS metrics, integrating scores into RL rewards via IPPO training.", "result": "Achieves >90% buyer demand fulfillment, fair seller margins, and FTB/FBS scores >0.80, improving convergence and equity.", "conclusion": "FairMarket-RL provides a scalable, fairness-driven solution for decentralized energy trading."}}
{"id": "2506.22570", "pdf": "https://arxiv.org/pdf/2506.22570", "abs": "https://arxiv.org/abs/2506.22570", "authors": ["Chee Mei Ling", "Thangarajah Akilan", "Aparna Ravinda Phalke"], "title": "Dual Atrous Separable Convolution for Improving Agricultural Semantic Segmentation", "categories": ["cs.CV"], "comment": "17 pages, 7 figures, 6 tables", "summary": "Agricultural image semantic segmentation is a pivotal component of modern\nagriculture, facilitating accurate visual data analysis to improve crop\nmanagement, optimize resource utilization, and boost overall productivity. This\nstudy proposes an efficient image segmentation method for precision\nagriculture, focusing on accurately delineating farmland anomalies to support\ninformed decision-making and proactive interventions. A novel Dual Atrous\nSeparable Convolution (DAS Conv) module is integrated within the\nDeepLabV3-based segmentation framework. The DAS Conv module is meticulously\ndesigned to achieve an optimal balance between dilation rates and padding size,\nthereby enhancing model performance without compromising efficiency. The study\nalso incorporates a strategic skip connection from an optimal stage in the\nencoder to the decoder to bolster the model's capacity to capture fine-grained\nspatial features. Despite its lower computational complexity, the proposed\nmodel outperforms its baseline and achieves performance comparable to highly\ncomplex transformer-based state-of-the-art (SOTA) models on the Agriculture\nVision benchmark dataset. It achieves more than 66% improvement in efficiency\nwhen considering the trade-off between model complexity and performance,\ncompared to the SOTA model. This study highlights an efficient and effective\nsolution for improving semantic segmentation in remote sensing applications,\noffering a computationally lightweight model capable of high-quality\nperformance in agricultural imagery.", "AI": {"tldr": "The paper proposes an efficient image segmentation method for precision agriculture using a novel Dual Atrous Separable Convolution (DAS Conv) module within a DeepLabV3 framework, achieving high performance with lower computational complexity.", "motivation": "To improve crop management and productivity by accurately delineating farmland anomalies through advanced semantic segmentation in agricultural imagery.", "method": "Integration of the DAS Conv module in DeepLabV3, optimizing dilation rates and padding, and using strategic skip connections to enhance spatial feature capture.", "result": "The model outperforms baselines and matches transformer-based SOTA models on the Agriculture Vision dataset, with a 66% efficiency improvement.", "conclusion": "The study presents a lightweight, efficient solution for high-quality semantic segmentation in agricultural remote sensing."}}
{"id": "2506.22977", "pdf": "https://arxiv.org/pdf/2506.22977", "abs": "https://arxiv.org/abs/2506.22977", "authors": ["Asen Dotsinski", "Udit Thakur", "Marko Ivanov", "Mohammad Hafeez Khan", "Maria Heuss"], "title": "On the Generalizability of \"Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals\"", "categories": ["cs.CL", "cs.LG"], "comment": "22 pages, 25 figures. For an interactive dashboard with all figures,\n  see https://comp-mech-generalizability.streamlit.app/ . For the accompanying\n  code, see https://github.com/asendotsinski/comp-mech-generalizability . To be\n  published in proceedings of the 2025 Machine Learning Reproducibility\n  Challenge", "summary": "We present a reproduction study of \"Competition of Mechanisms: Tracing How\nLanguage Models Handle Facts and Counterfactuals\" (Ortu et al., 2024), which\ninvestigates competition of mechanisms in language models between factual\nrecall and counterfactual in-context repetition. Our study successfully\nreproduces their primary findings regarding the localization of factual and\ncounterfactual information, the dominance of attention blocks in mechanism\ncompetition, and the specialization of attention heads in handling competing\ninformation. We reproduce their results on both GPT-2 (Radford et al., 2019)\nand Pythia 6.9B (Biderman et al., 2023). We extend their work in three\nsignificant directions. First, we explore the generalizability of these\nfindings to even larger models by replicating the experiments on Llama 3.1 8B\n(Grattafiori et al., 2024), discovering greatly reduced attention head\nspecialization. Second, we investigate the impact of prompt structure by\nintroducing variations where we avoid repeating the counterfactual statement\nverbatim or we change the premise word, observing a marked decrease in the\nlogit for the counterfactual token. Finally, we test the validity of the\nauthors' claims for prompts of specific domains, discovering that certain\ncategories of prompts skew the results by providing the factual prediction\ntoken as part of the subject of the sentence. Overall, we find that the\nattention head ablation proposed in Ortu et al. (2024) is ineffective for\ndomains that are underrepresented in their dataset, and that the effectiveness\nvaries based on model architecture, prompt structure, domain and task.", "AI": {"tldr": "A reproduction study of Ortu et al. (2024) confirms their findings on factual and counterfactual handling in language models but extends the work by testing larger models, prompt variations, and domain-specific validity.", "motivation": "To validate and extend Ortu et al.'s findings on how language models handle facts and counterfactuals, exploring generalizability and limitations.", "method": "Reproduced experiments on GPT-2 and Pythia 6.9B, extended to Llama 3.1 8B, tested prompt variations, and evaluated domain-specific impacts.", "result": "Confirmed primary findings but found reduced attention head specialization in larger models, prompt structure impacts counterfactual handling, and domain-specific skews.", "conclusion": "Attention head ablation's effectiveness varies by model, prompt, domain, and task, highlighting limitations in generalizability."}}
{"id": "2506.21490", "pdf": "https://arxiv.org/pdf/2506.21490", "abs": "https://arxiv.org/abs/2506.21490", "authors": ["Tin Dizdarevi\u0107", "Ravi Hammond", "Tobias Gessler", "Anisoara Calinescu", "Jonathan Cook", "Matteo Gallici", "Andrei Lupu", "Darius Muglich", "Johannes Forkel", "Jakob Nicolaus Foerster"], "title": "Ad-Hoc Human-AI Coordination Challenge", "categories": ["cs.AI", "cs.HC", "cs.MA"], "comment": "Published at ICML 2025", "summary": "Achieving seamless coordination between AI agents and humans is crucial for\nreal-world applications, yet it remains a significant open challenge. Hanabi is\na cooperative card game featuring imperfect information, constrained\ncommunication, theory of mind requirements, and coordinated action -- making it\nan ideal testbed for human-AI coordination. However, its use for human-AI\ninteraction has been limited by the challenges of human evaluation. In this\nwork, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to\novercome the constraints of costly and difficult-to-reproduce human\nevaluations. We develop \\textit{human proxy agents} on a large-scale human\ndataset that serve as robust, cheap, and reproducible human-like evaluation\npartners in AH2AC2. To encourage the development of data-efficient methods, we\nopen-source a dataset of 3,079 games, deliberately limiting the amount of\navailable human gameplay data. We present baseline results for both two- and\nthree- player Hanabi scenarios. To ensure fair evaluation, we host the proxy\nagents through a controlled evaluation system rather than releasing them\npublicly. The code is available at\n\\href{https://github.com/FLAIROx/ah2ac2}{https://github.com/FLAIROx/ah2ac2}.", "AI": {"tldr": "The paper introduces the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to address human-AI coordination in Hanabi, using human proxy agents for evaluation.", "motivation": "Seamless human-AI coordination is critical but challenging, especially in games like Hanabi with imperfect information and theory of mind requirements.", "method": "Developed human proxy agents from a large-scale dataset, limited data to encourage efficiency, and provided baseline results for Hanabi.", "result": "Introduced AH2AC2 with proxy agents for reproducible evaluation, open-sourced a dataset, and shared baseline results.", "conclusion": "AH2AC2 offers a scalable solution for human-AI coordination research, with controlled evaluation to ensure fairness."}}
{"id": "2506.23537", "pdf": "https://arxiv.org/pdf/2506.23537", "abs": "https://arxiv.org/abs/2506.23537", "authors": ["Xinyue Li", "Zhangkai Ni", "Wenhan Yang"], "title": "AFUNet: Cross-Iterative Alignment-Fusion Synergy for HDR Reconstruction via Deep Unfolding Paradigm", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted to International Conference on Computer Vision (ICCV) 2025", "summary": "Existing learning-based methods effectively reconstruct HDR images from\nmulti-exposure LDR inputs with extended dynamic range and improved detail, but\nthey rely more on empirical design rather than theoretical foundation, which\ncan impact their reliability. To address these limitations, we propose the\ncross-iterative Alignment and Fusion deep Unfolding Network (AFUNet), where HDR\nreconstruction is systematically decoupled into two interleaved subtasks --\nalignment and fusion -- optimized through alternating refinement, achieving\nsynergy between the two subtasks to enhance the overall performance. Our method\nformulates multi-exposure HDR reconstruction from a Maximum A Posteriori (MAP)\nestimation perspective, explicitly incorporating spatial correspondence priors\nacross LDR images and naturally bridging the alignment and fusion subproblems\nthrough joint constraints. Building on the mathematical foundation, we\nreimagine traditional iterative optimization through unfolding -- transforming\nthe conventional solution process into an end-to-end trainable AFUNet with\ncarefully designed modules that work progressively. Specifically, each\niteration of AFUNet incorporates an Alignment-Fusion Module (AFM) that\nalternates between a Spatial Alignment Module (SAM) for alignment and a Channel\nFusion Module (CFM) for adaptive feature fusion, progressively bridging\nmisaligned content and exposure discrepancies. Extensive qualitative and\nquantitative evaluations demonstrate AFUNet's superior performance,\nconsistently surpassing state-of-the-art methods. Our code is available at:\nhttps://github.com/eezkni/AFUNet", "AI": {"tldr": "AFUNet proposes a deep unfolding network for HDR image reconstruction, decoupling alignment and fusion tasks for improved performance.", "motivation": "Existing methods lack theoretical foundations, impacting reliability. AFUNet addresses this by integrating MAP estimation and joint constraints.", "method": "AFUNet uses alternating refinement with Alignment-Fusion Modules (AFM), combining Spatial Alignment (SAM) and Channel Fusion (CFM) iteratively.", "result": "AFUNet outperforms state-of-the-art methods in qualitative and quantitative evaluations.", "conclusion": "AFUNet provides a robust, theoretically grounded approach for HDR reconstruction, achieving superior results."}}
{"id": "2506.23503", "pdf": "https://arxiv.org/pdf/2506.23503", "abs": "https://arxiv.org/abs/2506.23503", "authors": ["Bosubabu Sambana", "Kondreddygari Archana", "Suram Indhra Sena Reddy", "Shaik Meethaigar Jameer Basha", "Shaik Karishma"], "title": "Data Augmentation for Cognitive Behavioral Therapy: Leveraging ERNIE Language Models using Artificial Intelligence", "categories": ["cs.AI"], "comment": "6 Pages, 5 Figures, IEEE IDCIoT 2025", "summary": "Cognitive Behavioral Therapy (CBT) is a proven approach for addressing the\nirrational thought patterns associated with mental health disorders, but its\neffectiveness relies on accurately identifying cognitive pathways to provide\ntargeted treatment. In today's digital age, individuals often express negative\nemotions on social media, where they may reveal cognitive distortions, and in\nsevere cases, exhibit suicidal tendencies. However, there is a significant gap\nin methodologies designed to analyze these cognitive pathways, which could be\ncritical for psychotherapists aiming to deliver timely and effective\ninterventions in online environments. Cognitive Behavioral Therapy (CBT)\nframework leveraging acceptance, commitment and data augmentation to categorize\nand address both textual and visual content as positive or negative.\nSpecifically, the system employs BERT, RoBERTa for Sentiment Analysis and T5,\nPEGASUS for Text Summarization, mT5 for Text Translation in Multiple Languages\nfocusing on detecting negative emotions and cognitive distortions within social\nmedia data. While existing models are primarily designed to identify negative\nthoughts, the proposed system goes beyond this by predicting additional\nnegative side effects and other potential mental health disorders likes\nPhobias, Eating Disorders. This enhancement allows for a more comprehensive\nunderstanding and intervention strategy, offering psychotherapists a powerful\ntool for early detection and treatment of various psychological issues.", "AI": {"tldr": "A CBT-based framework uses NLP models (BERT, RoBERTa, T5, PEGASUS, mT5) to analyze social media content for negative emotions and cognitive distortions, aiding psychotherapists in early intervention.", "motivation": "To bridge the gap in analyzing cognitive pathways in online content for timely mental health interventions.", "method": "Leverages NLP models for sentiment analysis, text summarization, and translation to detect negative emotions and cognitive distortions in social media data.", "result": "The system predicts negative side effects and other mental health disorders, enhancing early detection and treatment.", "conclusion": "The proposed framework offers a comprehensive tool for psychotherapists to address psychological issues more effectively."}}
{"id": "2506.22712", "pdf": "https://arxiv.org/pdf/2506.22712", "abs": "https://arxiv.org/abs/2506.22712", "authors": ["Alexander Theus", "Alessandro Cabodi", "Sotiris Anagnostidis", "Antonio Orvieto", "Sidak Pal Singh", "Valentina Boeva"], "title": "Generalized Linear Mode Connectivity for Transformers", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Understanding the geometry of neural network loss landscapes is a central\nquestion in deep learning, with implications for generalization and\noptimization. A striking phenomenon is linear mode connectivity (LMC), where\nindependently trained models can be connected by low- or zero-loss paths,\ndespite appearing to lie in separate loss basins. However, this is often\nobscured by symmetries in parameter space -- such as neuron permutations --\nwhich make functionally equivalent models appear dissimilar. Prior work has\npredominantly focused on neuron re-ordering through permutations, but such\napproaches are limited in scope and fail to capture the richer symmetries\nexhibited by modern architectures such as Transformers. In this work, we\nintroduce a unified framework that captures four symmetry classes:\npermutations, semi-permutations, orthogonal transformations, and general\ninvertible maps -- broadening the set of valid reparameterizations and\nsubsuming many previous approaches as special cases. Crucially, this\ngeneralization enables, for the first time, the discovery of low- and\nzero-barrier linear interpolation paths between independently trained Vision\nTransformers and GPT-2 models. These results reveal deeper structure in the\nloss landscape and underscore the importance of symmetry-aware analysis for\nunderstanding model space geometry.", "AI": {"tldr": "The paper introduces a unified framework to analyze symmetries in neural network loss landscapes, enabling discovery of low- and zero-loss paths between models like Vision Transformers and GPT-2.", "motivation": "Understanding the geometry of neural network loss landscapes, particularly linear mode connectivity (LMC), is crucial for generalization and optimization. Prior work focused on limited symmetries like permutations, missing richer symmetries in modern architectures.", "method": "The authors propose a framework capturing four symmetry classes: permutations, semi-permutations, orthogonal transformations, and general invertible maps. This broadens reparameterization options and subsumes prior approaches.", "result": "The framework successfully identifies low- and zero-barrier linear interpolation paths between independently trained Vision Transformers and GPT-2 models.", "conclusion": "The results highlight deeper structure in loss landscapes and emphasize the need for symmetry-aware analysis to understand model space geometry."}}
{"id": "2506.22589", "pdf": "https://arxiv.org/pdf/2506.22589", "abs": "https://arxiv.org/abs/2506.22589", "authors": ["Yijun Lin", "Rhett Olson", "Junhan Wu", "Yao-Yi Chiang", "Jerod Weinman"], "title": "LIGHT: Multi-Modal Text Linking on Historical Maps", "categories": ["cs.CV"], "comment": "Accepted at ICDAR2025", "summary": "Text on historical maps provides valuable information for studies in history,\neconomics, geography, and other related fields. Unlike structured or\nsemi-structured documents, text on maps varies significantly in orientation,\nreading order, shape, and placement. Many modern methods can detect and\ntranscribe text regions, but they struggle to effectively ``link'' the\nrecognized text fragments, e.g., determining a multi-word place name. Existing\nlayout analysis methods model word relationships to improve text understanding\nin structured documents, but they primarily rely on linguistic features and\nneglect geometric information, which is essential for handling map text. To\naddress these challenges, we propose LIGHT, a novel multi-modal approach that\nintegrates linguistic, image, and geometric features for linking text on\nhistorical maps. In particular, LIGHT includes a geometry-aware embedding\nmodule that encodes the polygonal coordinates of text regions to capture\npolygon shapes and their relative spatial positions on an image. LIGHT unifies\nthis geometric information with the visual and linguistic token embeddings from\nLayoutLMv3, a pretrained layout analysis model. LIGHT uses the cross-modal\ninformation to predict the reading-order successor of each text instance\ndirectly with a bi-directional learning strategy that enhances sequence\nrobustness. Experimental results show that LIGHT outperforms existing methods\non the ICDAR 2024/2025 MapText Competition data, demonstrating the\neffectiveness of multi-modal learning for historical map text linking.", "AI": {"tldr": "LIGHT is a multi-modal approach integrating linguistic, image, and geometric features to link text on historical maps, outperforming existing methods.", "motivation": "Text on historical maps is complex and varies in orientation, shape, and placement, making linking text fragments challenging. Existing methods lack geometric focus.", "method": "LIGHT combines geometric, visual, and linguistic features using a geometry-aware embedding module and LayoutLMv3. It predicts reading-order successors with bi-directional learning.", "result": "LIGHT outperforms existing methods on ICDAR 2024/2025 MapText Competition data.", "conclusion": "Multi-modal learning is effective for linking text on historical maps, with LIGHT demonstrating superior performance."}}
{"id": "2506.22978", "pdf": "https://arxiv.org/pdf/2506.22978", "abs": "https://arxiv.org/abs/2506.22978", "authors": ["Yida Zhao", "Hao Xve", "Xiang Hu", "Kewei Tu"], "title": "A Systematic Study of Compositional Syntactic Transformer Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Syntactic language models (SLMs) enhance Transformers by incorporating\nsyntactic biases through the modeling of linearized syntactic parse trees\nalongside surface sentences. This paper focuses on compositional SLMs that are\nbased on constituency parse trees and contain explicit bottom-up composition of\nconstituent representations. We identify key aspects of design choices in\nexisting compositional SLMs and propose a unified framework encompassing both\nexisting models and novel variants. We conduct a comprehensive empirical\nevaluation of all the variants in our framework across language modeling,\nsyntactic generalization, summarization, dialogue, and inference efficiency.\nBased on the experimental results, we make multiple recommendations on the\ndesign of compositional SLMs. Our code is released at\nhttps://github.com/zhaoyd1/compositional_SLMs.", "AI": {"tldr": "The paper introduces a unified framework for compositional syntactic language models (SLMs) based on constituency parse trees, evaluates design choices, and provides recommendations.", "motivation": "To enhance Transformers by incorporating syntactic biases and improving compositional SLMs through a unified framework.", "method": "Proposes a framework for compositional SLMs, evaluates variants across tasks like language modeling and summarization.", "result": "Comprehensive empirical evaluation leads to design recommendations for compositional SLMs.", "conclusion": "The study offers insights and practical guidelines for improving compositional SLMs, with code publicly available."}}
{"id": "2506.23584", "pdf": "https://arxiv.org/pdf/2506.23584", "abs": "https://arxiv.org/abs/2506.23584", "authors": ["Renjie Liang", "Zhengkang Fan", "Jinqian Pan", "Chenkun Sun", "Russell Terry", "Jie Xu"], "title": "A Clinically-Grounded Two-Stage Framework for Renal CT Report Generation", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Generating radiology reports from CT scans remains a complex task due to the\nnuanced nature of medical imaging and the variability in clinical\ndocumentation. In this study, we propose a two-stage framework for generating\nrenal radiology reports from 2D CT slices. First, we extract structured\nabnormality features using a multi-task learning model trained to identify\nlesion attributes such as location, size, enhancement, and attenuation. These\nextracted features are subsequently combined with the corresponding CT image\nand fed into a fine-tuned vision-language model to generate natural language\nreport sentences aligned with clinical findings. We conduct experiments on a\ncurated dataset of renal CT studies with manually annotated\nsentence-slice-feature triplets and evaluate performance using both\nclassification metrics and natural language generation metrics. Our results\ndemonstrate that the proposed model outperforms random baselines across all\nabnormality types, and the generated reports capture key clinical content with\nreasonable textual accuracy. This exploratory work highlights the feasibility\nof modular, feature-informed report generation for renal imaging. Future\nefforts will focus on extending this pipeline to 3D CT volumes and further\nimproving clinical fidelity in multimodal medical AI systems.", "AI": {"tldr": "A two-stage framework for generating renal radiology reports from 2D CT slices, combining structured abnormality features with a vision-language model, outperforms baselines and shows promise for clinical use.", "motivation": "The complexity of medical imaging and variability in clinical documentation make radiology report generation challenging.", "method": "A multi-task learning model extracts structured abnormality features (e.g., lesion attributes), which are combined with CT images and fed into a vision-language model to generate reports.", "result": "The model outperforms random baselines, capturing key clinical content with reasonable accuracy.", "conclusion": "The framework is feasible for renal imaging, with future work aimed at 3D CT volumes and improved clinical fidelity."}}
{"id": "2506.23504", "pdf": "https://arxiv.org/pdf/2506.23504", "abs": "https://arxiv.org/abs/2506.23504", "authors": ["Bosubabu Sambana", "Kotamsetty Geethika Devi", "Bandi Rajeswara Reddy", "Galeti Mohammad Hussain", "Gownivalla Siddartha"], "title": "Hybrid Approach for Electricity Price Forecasting using AlexNet and LSTM", "categories": ["cs.AI"], "comment": "6 Pages, 7 Figures", "summary": "The recent development of advanced machine learning methods for hybrid models\nhas greatly addressed the need for the correct prediction of electrical prices.\nThis method combines AlexNet and LSTM algorithms, which are used to introduce a\nnew model with higher accuracy in price forecasting. Despite RNN and ANN being\neffective, they often fail to deal with forex time sequence data. The\ntraditional methods do not accurately forecast the prices. These traditional\nmethods only focus on demand and price which leads to insufficient analysis of\ndata. To address this issue, using the hybrid approach, which focuses on\nexternal variables that also effect the predicted prices. Nevertheless, due to\nAlexNet's excellent feature extraction and LSTM's learning sequential patterns,\nthe prediction accuracy is vastly increased. The model is built on the past\ndata, which has been supplied with the most significant elements like demand,\ntemperature, sunlight, and rain. For example, the model applies methods, such\nas minimum-maximum scaling and a time window, to predict the electricity prices\nof the future. The results show that this hybrid model is good than the\nstandalone ones in terms of accuracy. Although we got our accuracy rating of\n97.08, it shows higher accompaniments than remaining models RNN and ANN with\naccuracies of 96.64 and 96.63 respectively.", "AI": {"tldr": "A hybrid model combining AlexNet and LSTM improves electricity price forecasting accuracy by addressing limitations of traditional methods and standalone models like RNN and ANN.", "motivation": "Traditional methods and standalone models (RNN, ANN) fail to accurately forecast electricity prices due to insufficient analysis of external variables and sequential data.", "method": "The hybrid model integrates AlexNet for feature extraction and LSTM for learning sequential patterns, using data like demand, temperature, sunlight, and rain, with preprocessing techniques like min-max scaling and time windows.", "result": "The hybrid model achieves 97.08% accuracy, outperforming RNN (96.64%) and ANN (96.63%).", "conclusion": "The hybrid approach significantly enhances prediction accuracy by leveraging external variables and sequential learning, making it superior to traditional and standalone models."}}
{"id": "2506.22716", "pdf": "https://arxiv.org/pdf/2506.22716", "abs": "https://arxiv.org/abs/2506.22716", "authors": ["Dujian Ding", "Ankur Mallick", "Shaokun Zhang", "Chi Wang", "Daniel Madrigal", "Mirian Del Carmen Hipolito Garcia", "Menglin Xia", "Laks V. S. Lakshmanan", "Qingyun Wu", "Victor R\u00fchle"], "title": "BEST-Route: Adaptive LLM Routing with Test-Time Optimal Compute", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DB"], "comment": "Accepted to ICML 2025 (main conference)", "summary": "Large language models (LLMs) are powerful tools but are often expensive to\ndeploy at scale. LLM query routing mitigates this by dynamically assigning\nqueries to models of varying cost and quality to obtain a desired trade-off.\nPrior query routing approaches generate only one response from the selected\nmodel and a single response from a small (inexpensive) model was often not good\nenough to beat a response from a large (expensive) model due to which they end\nup overusing the large model and missing out on potential cost savings.\nHowever, it is well known that for small models, generating multiple responses\nand selecting the best can enhance quality while remaining cheaper than a\nsingle large-model response. We leverage this idea to propose BEST-Route, a\nnovel routing framework that chooses a model and the number of responses to\nsample from it based on query difficulty and the quality thresholds.\nExperiments on real-world datasets demonstrate that our method reduces costs by\nup to 60% with less than 1% performance drop.", "AI": {"tldr": "BEST-Route is a novel LLM query routing framework that dynamically selects models and response counts to balance cost and quality, reducing costs by up to 60% with minimal performance loss.", "motivation": "To address the inefficiency and high cost of deploying large language models (LLMs) at scale by optimizing query routing and leveraging small models' potential through multiple responses.", "method": "Proposes BEST-Route, which selects models and response counts based on query difficulty and quality thresholds, enhancing small-model quality via multiple samples.", "result": "Achieves up to 60% cost reduction with less than 1% performance drop in real-world experiments.", "conclusion": "BEST-Route effectively balances cost and quality in LLM deployment, offering significant savings without compromising performance."}}
{"id": "2506.22591", "pdf": "https://arxiv.org/pdf/2506.22591", "abs": "https://arxiv.org/abs/2506.22591", "authors": ["Arunkumar Kannan", "Martin A. Lindquist", "Brian Caffo"], "title": "BrainMT: A Hybrid Mamba-Transformer Architecture for Modeling Long-Range Dependencies in Functional MRI Data", "categories": ["cs.CV"], "comment": "Accepted at MICCAI 2025", "summary": "Recent advances in deep learning have made it possible to predict phenotypic\nmeasures directly from functional magnetic resonance imaging (fMRI) brain\nvolumes, sparking significant interest in the neuroimaging community. However,\nexisting approaches, primarily based on convolutional neural networks or\ntransformer architectures, often struggle to model the complex relationships\ninherent in fMRI data, limited by their inability to capture long-range spatial\nand temporal dependencies. To overcome these shortcomings, we introduce\nBrainMT, a novel hybrid framework designed to efficiently learn and integrate\nlong-range spatiotemporal attributes in fMRI data. Our framework operates in\ntwo stages: (1) a bidirectional Mamba block with a temporal-first scanning\nmechanism to capture global temporal interactions in a computationally\nefficient manner; and (2) a transformer block leveraging self-attention to\nmodel global spatial relationships across the deep features processed by the\nMamba block. Extensive experiments on two large-scale public datasets,\nUKBioBank and the Human Connectome Project, demonstrate that BrainMT achieves\nstate-of-the-art performance on both classification (sex prediction) and\nregression (cognitive intelligence prediction) tasks, outperforming existing\nmethods by a significant margin. Our code and implementation details will be\nmade publicly available at this\nhttps://github.com/arunkumar-kannan/BrainMT-fMRI", "AI": {"tldr": "BrainMT is a hybrid framework combining Mamba and transformer blocks to model long-range spatiotemporal dependencies in fMRI data, achieving state-of-the-art performance.", "motivation": "Existing deep learning methods struggle to capture complex spatiotemporal relationships in fMRI data, limiting their predictive accuracy.", "method": "BrainMT uses a bidirectional Mamba block for temporal interactions and a transformer block for spatial relationships, processed in two stages.", "result": "Outperforms existing methods on classification (sex prediction) and regression (cognitive intelligence prediction) tasks on UKBioBank and Human Connectome Project datasets.", "conclusion": "BrainMT effectively addresses limitations of current approaches, offering improved performance for fMRI-based phenotype prediction."}}
{"id": "2506.23046", "pdf": "https://arxiv.org/pdf/2506.23046", "abs": "https://arxiv.org/abs/2506.23046", "authors": ["Xianzhe Fan", "Xuhui Zhou", "Chuanyang Jin", "Kolby Nottingham", "Hao Zhu", "Maarten Sap"], "title": "SoMi-ToM: Evaluating Multi-Perspective Theory of Mind in Embodied Social Interactions", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.RO"], "comment": "23 pages, 6 figures", "summary": "Humans continuously infer the states, goals, and behaviors of others by\nperceiving their surroundings in dynamic, real-world social interactions.\nHowever, most Theory of Mind (ToM) benchmarks only evaluate static, text-based\nscenarios, which have a significant gap compared to real interactions. We\npropose the SoMi-ToM benchmark, designed to evaluate multi-perspective ToM in\nembodied multi-agent complex social interactions. This benchmark is based on\nrich multimodal interaction data generated by the interaction environment SoMi,\ncovering diverse crafting goals and social relationships. Our framework\nsupports multi-level evaluation: (1) first-person evaluation provides\nmultimodal (visual, dialogue, action, etc.) input from a first-person\nperspective during a task for real-time state inference, (2) third-person\nevaluation provides complete third-person perspective video and text records\nafter a task for goal and behavior inference. This evaluation method allows for\na more comprehensive examination of a model's ToM capabilities from both the\nsubjective immediate experience and the objective global observation. We\nconstructed a challenging dataset containing 35 third-person perspective\nvideos, 363 first-person perspective images, and 1225 expert-annotated\nmultiple-choice questions (three options). On this dataset, we systematically\nevaluated the performance of human subjects and several state-of-the-art large\nvision-language models (LVLMs). The results show that LVLMs perform\nsignificantly worse than humans on SoMi-ToM: the average accuracy gap between\nhumans and models is 40.1% in first-person evaluation and 26.4% in third-person\nevaluation. This indicates that future LVLMs need to further improve their ToM\ncapabilities in embodied, complex social interactions.", "AI": {"tldr": "The SoMi-ToM benchmark evaluates Theory of Mind (ToM) in embodied multi-agent social interactions, addressing the gap in static, text-based benchmarks. It uses multimodal data and multi-level evaluation, revealing a significant performance gap between humans and large vision-language models (LVLMs).", "motivation": "Existing ToM benchmarks are limited to static, text-based scenarios, failing to capture real-world dynamic social interactions. The SoMi-ToM benchmark aims to bridge this gap by evaluating ToM in complex, embodied interactions.", "method": "The benchmark uses multimodal data (visual, dialogue, action) from the SoMi environment, with first-person (real-time state inference) and third-person (goal/behavior inference) evaluations. A dataset includes videos, images, and expert-annotated questions.", "result": "LVLMs perform significantly worse than humans, with accuracy gaps of 40.1% (first-person) and 26.4% (third-person).", "conclusion": "Future LVLMs must improve ToM capabilities for embodied, complex social interactions, as current models lag behind human performance."}}
{"id": "2506.23664", "pdf": "https://arxiv.org/pdf/2506.23664", "abs": "https://arxiv.org/abs/2506.23664", "authors": ["Fangyijie Wang", "Kevin Whelan", "F\u00e9lix Balado", "Gu\u00e9nol\u00e9 Silvestre", "Kathleen M. Curran"], "title": "Diffusion Model-based Data Augmentation Method for Fetal Head Ultrasound Segmentation", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Medical image data is less accessible than in other domains due to privacy\nand regulatory constraints. In addition, labeling requires costly,\ntime-intensive manual image annotation by clinical experts. To overcome these\nchallenges, synthetic medical data generation offers a promising solution.\nGenerative AI (GenAI), employing generative deep learning models, has proven\neffective at producing realistic synthetic images. This study proposes a novel\nmask-guided GenAI approach using diffusion models to generate synthetic fetal\nhead ultrasound images paired with segmentation masks. These synthetic pairs\naugment real datasets for supervised fine-tuning of the Segment Anything Model\n(SAM). Our results show that the synthetic data captures real image features\neffectively, and this approach reaches state-of-the-art fetal head\nsegmentation, especially when trained with a limited number of real image-mask\npairs. In particular, the segmentation reaches Dice Scores of 94.66\\% and\n94.38\\% using a handful of ultrasound images from the Spanish and African\ncohorts, respectively. Our code, models, and data are available on GitHub.", "AI": {"tldr": "A novel mask-guided GenAI approach using diffusion models generates synthetic fetal head ultrasound images with segmentation masks, enhancing real datasets for improved fetal head segmentation.", "motivation": "Medical image data is hard to access due to privacy and labeling constraints, requiring costly expert annotation. Synthetic data generation offers a solution.", "method": "Proposes a mask-guided GenAI approach using diffusion models to create synthetic fetal head ultrasound images paired with segmentation masks for dataset augmentation.", "result": "Synthetic data effectively captures real features, achieving state-of-the-art fetal head segmentation (Dice Scores of 94.66% and 94.38% for Spanish and African cohorts).", "conclusion": "The approach significantly improves segmentation performance with limited real data, demonstrating the potential of synthetic data in medical imaging."}}
{"id": "2506.23517", "pdf": "https://arxiv.org/pdf/2506.23517", "abs": "https://arxiv.org/abs/2506.23517", "authors": ["Selin Dik", "Osman Erdem", "Mehmet Dik"], "title": "Assessing GPTZero's Accuracy in Identifying AI vs. Human-Written Essays", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "As the use of AI tools by students has become more prevalent, instructors\nhave started using AI detection tools like GPTZero and QuillBot to detect AI\nwritten text. However, the reliability of these detectors remains uncertain. In\nour study, we focused mostly on the success rate of GPTZero, the most-used AI\ndetector, in identifying AI-generated texts based on different lengths of\nrandomly submitted essays: short (40-100 word count), medium (100-350 word\ncount), and long (350-800 word count). We gathered a data set consisting of\ntwenty-eight AI-generated papers and fifty human-written papers. With this\nrandomized essay data, papers were individually plugged into GPTZero and\nmeasured for percentage of AI generation and confidence. A vast majority of the\nAI-generated papers were detected accurately (ranging from 91-100% AI believed\ngeneration), while the human generated essays fluctuated; there were a handful\nof false positives. These findings suggest that although GPTZero is effective\nat detecting purely AI-generated content, its reliability in distinguishing\nhuman-authored texts is limited. Educators should therefore exercise caution\nwhen relying solely on AI detection tools.", "AI": {"tldr": "GPTZero is effective at detecting AI-generated text but less reliable for human-written essays, with some false positives. Educators should use caution.", "motivation": "To evaluate the reliability of GPTZero in detecting AI-generated text across different essay lengths.", "method": "Tested GPTZero on 28 AI-generated and 50 human-written essays of varying lengths (short, medium, long), measuring AI detection rates and confidence.", "result": "AI-generated essays were accurately detected (91-100%), but human-written essays had fluctuating results with false positives.", "conclusion": "GPTZero is reliable for AI detection but less so for human texts, urging caution for educators."}}
{"id": "2506.22732", "pdf": "https://arxiv.org/pdf/2506.22732", "abs": "https://arxiv.org/abs/2506.22732", "authors": ["Hao Shu", "Jicheng Li", "Tianyv Lei", "Lijun Sun"], "title": "Robust Tensor Completion via Gradient Tensor Nulclear L1-L2 Norm for Traffic Data Recovery", "categories": ["cs.LG", "eess.SP", "stat.ML"], "comment": null, "summary": "In real-world scenarios, spatiotemporal traffic data frequently experiences\ndual degradation from missing values and noise caused by sensor malfunctions\nand communication failures. Therefore, effective data recovery methods are\nessential to ensure the reliability of downstream data-driven applications.\nwhile classical tensor completion methods have been widely adopted, they are\nincapable of modeling noise, making them unsuitable for complex scenarios\ninvolving simultaneous data missingness and noise interference. Existing Robust\nTensor Completion (RTC) approaches offer potential solutions by separately\nmodeling the actual tensor data and noise. However, their effectiveness is\noften constrained by the over-relaxation of convex rank surrogates and the\nsuboptimal utilization of local consistency, leading to inadequate model\naccuracy. To address these limitations, we first introduce the tensor L1-L2\nnorm, a novel non-convex tensor rank surrogate that functions as an effective\nlow-rank representation tool. Leveraging an advanced feature fusion strategy,\nwe further develop the gradient tensor L1-L2 norm by incorporating the tensor\nL1-L2 norm in the gradient domain. By integrating the gradient tensor nuclear\nL1-L2 norm into the RTC framework, we propose the Robust Tensor Completion via\nGradient Tensor Nuclear L1-L2 Norm (RTC-GTNLN) model, which not only fully\nexploits both global low-rankness and local consistency without trade-off\nparameter, but also effectively handles the dual degradation challenges of\nmissing data and noise in traffic data. Extensive experiments conducted on\nmultiple real-world traffic datasets demonstrate that the RTC-GTNLN model\nconsistently outperforms existing state-of-the-art methods in complex recovery\nscenarios involving simultaneous missing values and noise.", "AI": {"tldr": "The paper introduces RTC-GTNLN, a novel Robust Tensor Completion model using a non-convex tensor rank surrogate (L1-L2 norm) to handle missing data and noise in traffic data, outperforming existing methods.", "motivation": "Spatiotemporal traffic data often suffers from missing values and noise due to sensor malfunctions, requiring robust recovery methods for reliable downstream applications.", "method": "Proposes RTC-GTNLN, integrating a gradient tensor L1-L2 norm into the RTC framework to exploit global low-rankness and local consistency without trade-offs.", "result": "RTC-GTNLN outperforms state-of-the-art methods in recovering traffic data with missing values and noise, as shown in experiments on real-world datasets.", "conclusion": "The RTC-GTNLN model effectively addresses dual degradation challenges in traffic data, offering superior performance in complex recovery scenarios."}}
{"id": "2506.22624", "pdf": "https://arxiv.org/pdf/2506.22624", "abs": "https://arxiv.org/abs/2506.22624", "authors": ["Zuyao You", "Zuxuan Wu"], "title": "Seg-R1: Segmentation Can Be Surprisingly Simple with Reinforcement Learning", "categories": ["cs.CV"], "comment": null, "summary": "We present Seg-R1, a preliminary exploration of using reinforcement learning\n(RL) to enhance the pixel-level understanding and reasoning capabilities of\nlarge multimodal models (LMMs). Starting with foreground segmentation tasks,\nspecifically camouflaged object detection (COD) and salient object detection\n(SOD), our approach enables the LMM to generate point and bounding box prompts\nin the next-token fashion, which are then used to guide SAM2 in producing\nsegmentation masks. We introduce Group Relative Policy Optimization (GRPO) into\nthe segmentation domain, equipping the LMM with pixel-level comprehension\nthrough a carefully designed training strategy. Notably, Seg-R1 achieves\nremarkable performance with purely RL-based training, achieving .873 S-measure\non COD10K without complex model modification. Moreover, we found that pure RL\ntraining demonstrates strong open-world generalization. Despite being trained\nsolely on foreground segmentation image-mask pairs without text supervision,\nSeg-R1 achieves impressive zero-shot performance on referring segmentation and\nreasoning segmentation tasks, with 71.4 cIoU on RefCOCOg test and 56.7 gIoU on\nReasonSeg test, outperforming models fully supervised on these datasets.", "AI": {"tldr": "Seg-R1 uses RL to improve pixel-level understanding in LMMs for segmentation tasks, achieving strong performance and generalization without text supervision.", "motivation": "Enhancing pixel-level reasoning in large multimodal models (LMMs) for segmentation tasks like COD and SOD.", "method": "Uses RL to generate prompts for SAM2, introduces GRPO, and trains purely with RL.", "result": "Achieves .873 S-measure on COD10K, 71.4 cIoU on RefCOCOg, and 56.7 gIoU on ReasonSeg.", "conclusion": "Pure RL training enables strong performance and generalization in segmentation tasks."}}
{"id": "2506.23051", "pdf": "https://arxiv.org/pdf/2506.23051", "abs": "https://arxiv.org/abs/2506.23051", "authors": ["Jo\u00e3o Lucas Luz Lima Sarcinelli", "Marina Lages Gon\u00e7alves Teixeira", "Jade Bortot de Paiva", "Diego Furtado Silva"], "title": "MariNER: A Dataset for Historical Brazilian Portuguese Named Entity Recognition", "categories": ["cs.CL"], "comment": null, "summary": "Named Entity Recognition (NER) is a fundamental Natural Language Processing\n(NLP) task that aims to identify and classify entity mentions in texts across\ndifferent categories. While languages such as English possess a large number of\nhigh-quality resources for this task, Brazilian Portuguese still lacks in\nquantity of gold-standard NER datasets, especially when considering specific\ndomains. Particularly, this paper considers the importance of NER for analyzing\nhistorical texts in the context of digital humanities. To address this gap,\nthis work outlines the construction of MariNER: \\textit{Mapeamento e\nAnota\\c{c}\\~oes de Registros hIst\\'oricos para NER} (Mapping and Annotation of\nHistorical Records for NER), the first gold-standard dataset for early\n20th-century Brazilian Portuguese, with more than 9,000 manually annotated\nsentences. We also assess and compare the performance of state-of-the-art NER\nmodels for the dataset.", "AI": {"tldr": "The paper introduces MariNER, the first gold-standard NER dataset for early 20th-century Brazilian Portuguese, addressing the lack of resources for historical text analysis in digital humanities.", "motivation": "Brazilian Portuguese lacks high-quality NER datasets, especially for historical texts, hindering digital humanities research.", "method": "Construction of MariNER, a manually annotated dataset with over 9,000 sentences, and evaluation of state-of-the-art NER models.", "result": "MariNER provides a valuable resource for NER in Brazilian Portuguese, with performance benchmarks for existing models.", "conclusion": "The dataset fills a critical gap and supports advancements in NER for historical and domain-specific texts."}}
{"id": "2506.23688", "pdf": "https://arxiv.org/pdf/2506.23688", "abs": "https://arxiv.org/abs/2506.23688", "authors": ["Jiaxin Yang", "Vasileios Magoulianitis", "Catherine Aurelia Christie Alexander", "Jintang Xue", "Masatomo Kaneko", "Giovanni Cacciamani", "Andre Abreu", "Vinay Duddalwar", "C. -C. Jay Kuo", "Inderbir S. Gill", "Chrysostomos Nikias"], "title": "GUSL: A Novel and Efficient Machine Learning Model for Prostate Segmentation on MRI", "categories": ["eess.IV"], "comment": null, "summary": "Prostate and zonal segmentation is a crucial step for clinical diagnosis of\nprostate cancer (PCa). Computer-aided diagnosis tools for prostate segmentation\nare based on the deep learning (DL) paradigm. However, deep neural networks are\nperceived as \"black-box\" solutions by physicians, thus making them less\npractical for deployment in the clinical setting. In this paper, we introduce a\nfeed-forward machine learning model, named Green U-shaped Learning (GUSL),\nsuitable for medical image segmentation without backpropagation. GUSL\nintroduces a multi-layer regression scheme for coarse-to-fine segmentation. Its\nfeature extraction is based on a linear model, which enables seamless\ninterpretability during feature extraction. Also, GUSL introduces a mechanism\nfor attention on the prostate boundaries, which is an error-prone region, by\nemploying regression to refine the predictions through residue correction. In\naddition, a two-step pipeline approach is used to mitigate the class imbalance,\nan issue inherent in medical imaging problems. After conducting experiments on\ntwo publicly available datasets and one private dataset, in both prostate gland\nand zonal segmentation tasks, GUSL achieves state-of-the-art performance among\nother DL-based models. Notably, GUSL features a very energy-efficient pipeline,\nsince it has a model size several times smaller and less complexity than the\nrest of the solutions. In all datasets, GUSL achieved a Dice Similarity\nCoefficient (DSC) performance greater than $0.9$ for gland segmentation.\nConsidering also its lightweight model size and transparency in feature\nextraction, it offers a competitive and practical package for medical imaging\napplications.", "AI": {"tldr": "GUSL is a lightweight, interpretable machine learning model for prostate segmentation, outperforming DL-based methods with high efficiency and transparency.", "motivation": "Address the 'black-box' nature of deep learning in medical image segmentation by proposing an interpretable, energy-efficient alternative.", "method": "Introduces Green U-shaped Learning (GUSL), a feed-forward model with multi-layer regression, linear feature extraction, and attention on prostate boundaries. Uses a two-step pipeline to handle class imbalance.", "result": "Achieves state-of-the-art performance (DSC > 0.9) on gland segmentation across datasets, with smaller model size and lower complexity than DL-based solutions.", "conclusion": "GUSL offers a practical, competitive solution for medical imaging due to its interpretability, efficiency, and high performance."}}
{"id": "2506.23520", "pdf": "https://arxiv.org/pdf/2506.23520", "abs": "https://arxiv.org/abs/2506.23520", "authors": ["Yu Zhang", "Ruijie Yu", "Jidong Tian", "Feng Zhu", "Jiapeng Liu", "Xiaokang Yang", "Yaohui Jin", "Yanyan Xu"], "title": "ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data", "categories": ["cs.AI"], "comment": null, "summary": "With the increasing interest in robotic synthesis in the context of organic\nchemistry, the automated extraction of chemical procedures from literature is\ncritical. However, this task remains challenging due to the inherent ambiguity\nof chemical language and the high cost of human annotation required for\ndeveloping reliable computer-aided extraction protocols. Here, we present\nChemActor, a fully fine-tuned large language model (LLM), as a chemical\nexecutor to convert between unstructured experimental procedures and structured\naction sequences. We propose a sequential LLM-generated data framework to\naddress the challenges of insufficient and low-quality annotated data. This\nframework integrates a data selection module that selects data based on\ndistribution divergence, with a general-purpose LLM, to generate\nmachine-executable actions from a single molecule input. Additionally, we\nintroduce a novel multi-round LLMs circle review metric, which reflects the\nmodel's advanced understanding of chemical experimental procedures. Extensive\nexperiments on reaction-to-description (R2D) and description-to-action (D2A)\ntasks demonstrate that ChemActor, augmented by LLM-generated data, achieves\nstate-of-the-art performance, outperforming the baseline model by 10%. The code\nis available at: https://github.com/Zhanghahah/ChemActor.", "AI": {"tldr": "ChemActor, a fine-tuned LLM, converts chemical procedures into structured actions, using LLM-generated data and a novel review metric to achieve state-of-the-art performance.", "motivation": "Automating chemical procedure extraction is challenging due to ambiguous language and costly human annotation.", "method": "ChemActor uses a sequential LLM-generated data framework with a data selection module and multi-round LLMs circle review metric.", "result": "Outperforms baseline by 10% in R2D and D2A tasks.", "conclusion": "ChemActor demonstrates advanced understanding and effectiveness in automating chemical procedure extraction."}}
{"id": "2506.22771", "pdf": "https://arxiv.org/pdf/2506.22771", "abs": "https://arxiv.org/abs/2506.22771", "authors": ["Jingxiao Ma", "Priyadarshini Panda", "Sherief Reda"], "title": "FF-INT8: Efficient Forward-Forward DNN Training on Edge Devices with INT8 Precision", "categories": ["cs.LG", "cs.AI", "cs.NE", "I.2.0; I.2.6"], "comment": "To be published in the 62nd Design Automation Conference (DAC), 2025", "summary": "Backpropagation has been the cornerstone of neural network training for\ndecades, yet its inefficiencies in time and energy consumption limit its\nsuitability for resource-constrained edge devices. While low-precision neural\nnetwork quantization has been extensively researched to speed up model\ninference, its application in training has been less explored. Recently, the\nForward-Forward (FF) algorithm has emerged as a promising alternative to\nbackpropagation, replacing the backward pass with an additional forward pass.\nBy avoiding the need to store intermediate activations for backpropagation, FF\ncan reduce memory footprint, making it well-suited for embedded devices. This\npaper presents an INT8 quantized training approach that leverages FF's\nlayer-by-layer strategy to stabilize gradient quantization. Furthermore, we\npropose a novel \"look-ahead\" scheme to address limitations of FF and improve\nmodel accuracy. Experiments conducted on NVIDIA Jetson Orin Nano board\ndemonstrate 4.6% faster training, 8.3% energy savings, and 27.0% reduction in\nmemory usage, while maintaining competitive accuracy compared to the\nstate-of-the-art.", "AI": {"tldr": "INT8 quantized training using Forward-Forward (FF) algorithm reduces memory, speeds up training, and saves energy while maintaining accuracy.", "motivation": "Backpropagation's inefficiencies in time and energy limit its use for edge devices. FF offers a promising alternative by avoiding backward passes.", "method": "Proposes INT8 quantized training with FF and a 'look-ahead' scheme to stabilize gradients and improve accuracy.", "result": "4.6% faster training, 8.3% energy savings, 27.0% memory reduction, with competitive accuracy.", "conclusion": "The approach is efficient for resource-constrained devices, balancing performance and accuracy."}}
{"id": "2506.22636", "pdf": "https://arxiv.org/pdf/2506.22636", "abs": "https://arxiv.org/abs/2506.22636", "authors": ["Sotirios Panagiotis Chytas", "Miso Choi", "Hyunwoo J. Kim", "Vikas Singh"], "title": "ReCo: Reminder Composition Mitigates Hallucinations in Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Vision Language Models (VLMs) show impressive capabilities in integrating and\nreasoning with both visual and language data. But these models make mistakes. A\ncommon finding -- similar to LLMs -- is their tendency to hallucinate, i.e.,\ngenerate plausible sounding text which is not grounded in the visual input, or\nat worst, is contradictory. A growing consensus attributes this behavior to an\nover-reliance on language -- especially as the generation progresses, the model\nsuffers from a ``fading memory effect'' with respect to the provided visual\ninput. We study mechanisms by which this behavior can be controlled.\nSpecifically, using ideas from geometric algebra and relational compositions,\nwe propose the addition of a small, trainable module (named ReCo) on top of any\nVLM -- no other modification is needed. We show that such a lightweight module\nis able to mitigate the fading memory effect on three of the most widely used\nVLMs (InstructBLIP, LlaVA, MiniGPT4), where we see performance improvements on\nmultiple benchmarks. Additionally, we show that our module can be combined with\nmany of the other approaches for reducing hallucination where we achieve\nimproved results for each one.", "AI": {"tldr": "The paper proposes a lightweight module (ReCo) to mitigate hallucination in Vision Language Models (VLMs) caused by fading memory of visual input, improving performance across benchmarks.", "motivation": "VLMs often hallucinate due to over-reliance on language and fading memory of visual input, leading to ungrounded or contradictory outputs.", "method": "Introduces ReCo, a small trainable module based on geometric algebra and relational compositions, added atop VLMs without other modifications.", "result": "ReCo improves performance on three major VLMs (InstructBLIP, LlaVA, MiniGPT4) and complements other hallucination-reduction methods.", "conclusion": "ReCo effectively addresses the fading memory effect in VLMs, enhancing their reliability and accuracy."}}
{"id": "2506.23056", "pdf": "https://arxiv.org/pdf/2506.23056", "abs": "https://arxiv.org/abs/2506.23056", "authors": ["Xiang Zhuang", "Bin Wu", "Jiyu Cui", "Kehua Feng", "Xiaotong Li", "Huabin Xing", "Keyan Ding", "Qiang Zhang", "Huajun Chen"], "title": "Boosting LLM's Molecular Structure Elucidation with Knowledge Enhanced Tree Search Reasoning", "categories": ["cs.CL"], "comment": "ACL 2025 Main", "summary": "Molecular structure elucidation involves deducing a molecule's structure from\nvarious types of spectral data, which is crucial in chemical experimental\nanalysis. While large language models (LLMs) have shown remarkable proficiency\nin analyzing and reasoning through complex tasks, they still encounter\nsubstantial challenges in molecular structure elucidation. We identify that\nthese challenges largely stem from LLMs' limited grasp of specialized chemical\nknowledge. In this work, we introduce a Knowledge-enhanced reasoning framework\nfor Molecular Structure Elucidation (K-MSE), leveraging Monte Carlo Tree Search\nfor test-time scaling as a plugin. Specifically, we construct an external\nmolecular substructure knowledge base to extend the LLMs' coverage of the\nchemical structure space. Furthermore, we design a specialized\nmolecule-spectrum scorer to act as a reward model for the reasoning process,\naddressing the issue of inaccurate solution evaluation in LLMs. Experimental\nresults show that our approach significantly boosts performance, particularly\ngaining more than 20% improvement on both GPT-4o-mini and GPT-4o. Our code is\navailable at https://github.com/HICAI-ZJU/K-MSE.", "AI": {"tldr": "A knowledge-enhanced framework (K-MSE) improves molecular structure elucidation in LLMs by integrating specialized chemical knowledge and Monte Carlo Tree Search, achieving over 20% performance boost.", "motivation": "LLMs struggle with molecular structure elucidation due to limited chemical knowledge, prompting the need for a specialized framework.", "method": "K-MSE uses an external molecular substructure knowledge base and a molecule-spectrum scorer for reward modeling, enhanced by Monte Carlo Tree Search.", "result": "The framework significantly improves performance, with over 20% gains on GPT-4o-mini and GPT-4o.", "conclusion": "K-MSE effectively addresses LLMs' limitations in molecular structure elucidation, enhancing accuracy through specialized knowledge integration."}}
{"id": "2506.23700", "pdf": "https://arxiv.org/pdf/2506.23700", "abs": "https://arxiv.org/abs/2506.23700", "authors": ["Peiting Tian", "Xi Chen", "Haixia Bi", "Fan Li"], "title": "MedSAM-CA: A CNN-Augmented ViT with Attention-Enhanced Multi-Scale Fusion for Medical Image Segmentation", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Medical image segmentation plays a crucial role in clinical diagnosis and\ntreatment planning, where accurate boundary delineation is essential for\nprecise lesion localization, organ identification, and quantitative assessment.\nIn recent years, deep learning-based methods have significantly advanced\nsegmentation accuracy. However, two major challenges remain. First, the\nperformance of these methods heavily relies on large-scale annotated datasets,\nwhich are often difficult to obtain in medical scenarios due to privacy\nconcerns and high annotation costs. Second, clinically challenging scenarios,\nsuch as low contrast in certain imaging modalities and blurry lesion boundaries\ncaused by malignancy, still pose obstacles to precise segmentation. To address\nthese challenges, we propose MedSAM-CA, an architecture-level fine-tuning\napproach that mitigates reliance on extensive manual annotations by adapting\nthe pretrained foundation model, Medical Segment Anything (MedSAM). MedSAM-CA\nintroduces two key components: the Convolutional Attention-Enhanced Boundary\nRefinement Network (CBR-Net) and the Attention-Enhanced Feature Fusion Block\n(Atte-FFB). CBR-Net operates in parallel with the MedSAM encoder to recover\nboundary information potentially overlooked by long-range attention mechanisms,\nleveraging hierarchical convolutional processing. Atte-FFB, embedded in the\nMedSAM decoder, fuses multi-level fine-grained features from skip connections\nin CBR-Net with global representations upsampled within the decoder to enhance\nboundary delineation accuracy. Experiments on publicly available datasets\ncovering dermoscopy, CT, and MRI imaging modalities validate the effectiveness\nof MedSAM-CA. On dermoscopy dataset, MedSAM-CA achieves 94.43% Dice with only\n2% of full training data, reaching 97.25% of full-data training performance,\ndemonstrating strong effectiveness in low-resource clinical settings.", "AI": {"tldr": "MedSAM-CA is a fine-tuning approach for medical image segmentation, reducing reliance on large annotated datasets and improving boundary delineation with CBR-Net and Atte-FFB.", "motivation": "Address challenges in medical image segmentation, including limited annotated data and poor boundary clarity in low-contrast or blurry images.", "method": "Proposes MedSAM-CA with CBR-Net for boundary refinement and Atte-FFB for feature fusion, leveraging the pretrained MedSAM model.", "result": "Achieves 94.43% Dice on dermoscopy data with only 2% training data, nearing full-data performance (97.25%).", "conclusion": "MedSAM-CA effectively improves segmentation accuracy in low-resource settings, validated across multiple imaging modalities."}}
{"id": "2506.23549", "pdf": "https://arxiv.org/pdf/2506.23549", "abs": "https://arxiv.org/abs/2506.23549", "authors": ["Huai-Chih Wang", "Hsiang-Chun Chuang", "Hsi-Chun Cheng", "Dai-Jie Wu", "Shao-Hua Sun"], "title": "CooT: Learning to Coordinate In-Context with Coordination Transformers", "categories": ["cs.AI", "cs.HC", "cs.LG"], "comment": "23 pages, 10 tables, 8 figures", "summary": "Effective coordination among artificial agents in dynamic and uncertain\nenvironments remains a significant challenge in multi-agent systems. Existing\napproaches, such as self-play and population-based methods, either generalize\npoorly to unseen partners or require extensive training. To overcome these\nlimitations, we propose Coordination Transformers (CooT), a novel in-context\ncoordination framework that uses recent interaction histories to adapt to\nunseen partners rapidly. Unlike previous approaches that primarily aim to\nincrease the diversity of training partners, CooT explicitly focuses on\nadapting to new partner behaviors by predicting actions aligned with observed\npartner interactions. Trained on interaction trajectories collected from\ndiverse pairs of agents with complementary behaviors, CooT quickly learns\neffective coordination strategies without explicit supervision or fine-tuning.\nEvaluations on the Overcooked benchmark demonstrate that CooT significantly\noutperforms baseline methods in coordination tasks involving previously unseen\npartners. Human evaluations further confirm CooT as the most effective\ncollaborative partner, while extensive ablations highlight its robustness,\nflexibility, and sensitivity to context in multi-agent scenarios.", "AI": {"tldr": "Proposes Coordination Transformers (CooT), a framework for rapid adaptation to unseen partners in multi-agent systems, outperforming baselines in coordination tasks.", "motivation": "Addresses poor generalization and extensive training requirements in existing multi-agent coordination methods.", "method": "Uses in-context coordination with interaction histories to predict partner actions, trained on diverse agent pairs.", "result": "Outperforms baselines on Overcooked benchmark and excels in human evaluations.", "conclusion": "CooT is robust, flexible, and context-sensitive, offering effective coordination with unseen partners."}}
{"id": "2506.22780", "pdf": "https://arxiv.org/pdf/2506.22780", "abs": "https://arxiv.org/abs/2506.22780", "authors": ["Dibyajyoti Chakraborty", "Haiwen Guan", "Jason Stock", "Troy Arcomano", "Guido Cervone", "Romit Maulik"], "title": "Multimodal Atmospheric Super-Resolution With Deep Generative Models", "categories": ["cs.LG", "physics.geo-ph"], "comment": null, "summary": "Score-based diffusion modeling is a generative machine learning algorithm\nthat can be used to sample from complex distributions. They achieve this by\nlearning a score function, i.e., the gradient of the log-probability density of\nthe data, and reversing a noising process using the same. Once trained,\nscore-based diffusion models not only generate new samples but also enable\nzero-shot conditioning of the generated samples on observed data. This promises\na novel paradigm for data and model fusion, wherein the implicitly learned\ndistributions of pretrained score-based diffusion models can be updated given\nthe availability of online data in a Bayesian formulation. In this article, we\napply such a concept to the super-resolution of a high-dimensional dynamical\nsystem, given the real-time availability of low-resolution and experimentally\nobserved sparse sensor measurements from multimodal data. Additional analysis\non how score-based sampling can be used for uncertainty estimates is also\nprovided. Our experiments are performed for a super-resolution task that\ngenerates the ERA5 atmospheric dataset given sparse observations from a\ncoarse-grained representation of the same and/or from unstructured experimental\nobservations of the IGRA radiosonde dataset. We demonstrate accurate recovery\nof the high dimensional state given multiple sources of low-fidelity\nmeasurements. We also discover that the generative model can balance the\ninfluence of multiple dataset modalities during spatiotemporal reconstructions.", "AI": {"tldr": "Score-based diffusion models enable zero-shot conditioning and Bayesian updates for data fusion, applied here to super-resolution of high-dimensional dynamical systems.", "motivation": "To leverage score-based diffusion models for data and model fusion, updating distributions with online data for tasks like super-resolution.", "method": "Uses score-based diffusion modeling to learn a score function, reverse a noising process, and apply Bayesian updates for super-resolution of dynamical systems.", "result": "Accurate recovery of high-dimensional states from low-fidelity measurements and balancing influence of multiple dataset modalities.", "conclusion": "Score-based diffusion models effectively fuse multimodal data for super-resolution, demonstrating robustness and adaptability."}}
{"id": "2506.22637", "pdf": "https://arxiv.org/pdf/2506.22637", "abs": "https://arxiv.org/abs/2506.22637", "authors": ["Haoxuan Wang", "Zhenghao Zhao", "Junyi Wu", "Yuzhang Shang", "Gaowen Liu", "Yan Yan"], "title": "CaO$_2$: Rectifying Inconsistencies in Diffusion-Based Dataset Distillation", "categories": ["cs.CV"], "comment": "ICCV 2025. Code is available at\n  https://github.com/hatchetProject/CaO2", "summary": "The recent introduction of diffusion models in dataset distillation has shown\npromising potential in creating compact surrogate datasets for large,\nhigh-resolution target datasets, offering improved efficiency and performance\nover traditional bi-level/uni-level optimization methods. However, current\ndiffusion-based dataset distillation approaches overlook the evaluation process\nand exhibit two critical inconsistencies in the distillation process: (1)\nObjective Inconsistency, where the distillation process diverges from the\nevaluation objective, and (2) Condition Inconsistency, leading to mismatches\nbetween generated images and their corresponding conditions. To resolve these\nissues, we introduce Condition-aware Optimization with Objective-guided\nSampling (CaO$_2$), a two-stage diffusion-based framework that aligns the\ndistillation process with the evaluation objective. The first stage employs a\nprobability-informed sample selection pipeline, while the second stage refines\nthe corresponding latent representations to improve conditional likelihood.\nCaO$_2$ achieves state-of-the-art performance on ImageNet and its subsets,\nsurpassing the best-performing baselines by an average of 2.3% accuracy.", "AI": {"tldr": "CaO$_2$ introduces a two-stage diffusion-based framework to address inconsistencies in dataset distillation, achieving state-of-the-art performance on ImageNet.", "motivation": "Current diffusion-based dataset distillation methods suffer from objective and condition inconsistencies, leading to suboptimal performance.", "method": "CaO$_2$ uses a two-stage approach: probability-informed sample selection and latent representation refinement.", "result": "Outperforms baselines by 2.3% accuracy on ImageNet and subsets.", "conclusion": "CaO$_2$ effectively aligns distillation with evaluation objectives, improving efficiency and performance."}}
{"id": "2506.23071", "pdf": "https://arxiv.org/pdf/2506.23071", "abs": "https://arxiv.org/abs/2506.23071", "authors": ["Zhengren Wang", "Bozhou Li", "Dongwen Yao", "Wentao Zhang"], "title": "Text2VectorSQL: Bridging Text-to-SQL and Vector Search for Unified Natural Language Queries", "categories": ["cs.CL"], "comment": "Work in progess", "summary": "While Text-to-SQL enables natural language interaction with structured\ndatabases, its effectiveness diminishes with unstructured data or ambiguous\nqueries due to rigid syntax and limited expressiveness. Concurrently, vector\nsearch has emerged as a powerful paradigm for semantic retrieval, particularly\nfor unstructured data. However, existing VectorSQL implementations still rely\nheavily on manual crafting and lack tailored evaluation frameworks, leaving a\nsignificant gap between theoretical potential and practical deployment. To\nbridge these complementary paradigms, we introduces Text2VectorSQL, a novel\nframework unifying Text-to-SQL and vector search to overcome expressiveness\nconstraints and support more diverse and holistical natural language queries.\nSpecifically, Text2VectorSQL enables semantic filtering, multi-modal matching,\nand retrieval acceleration. For evaluation, we build vector index on\nappropriate columns, extend user queries with semantic search, and annotate\nground truths via an automatic pipeline with expert review. Furthermore, we\ndevelop dedicated Text2VectorSQL models with synthetic data, demonstrating\nsignificant performance improvements over baseline methods. Our work\nestablishes the foundation for the Text2VectorSQL task, paving the way for more\nversatile and intuitive database interfaces. The repository will be publicly\navailable at https://github.com/Open-DataFlow/Text2VectorSQL.", "AI": {"tldr": "Text2VectorSQL unifies Text-to-SQL and vector search to enhance natural language query handling for structured and unstructured data, outperforming baselines.", "motivation": "Address limitations of Text-to-SQL (rigid syntax, ambiguity) and VectorSQL (manual crafting, lack of evaluation) by integrating both paradigms.", "method": "Introduces Text2VectorSQL for semantic filtering, multi-modal matching, and retrieval acceleration, with synthetic data and expert-reviewed ground truths.", "result": "Demonstrates significant performance improvements over baseline methods.", "conclusion": "Establishes Text2VectorSQL as a foundation for more versatile database interfaces, with public repository availability."}}
{"id": "2506.23701", "pdf": "https://arxiv.org/pdf/2506.23701", "abs": "https://arxiv.org/abs/2506.23701", "authors": ["Lingtong Zhang", "Mengdie Song", "Xiaohan Hao", "Huayu Mai", "Bensheng Qiu"], "title": "MDPG: Multi-domain Diffusion Prior Guidance for MRI Reconstruction", "categories": ["eess.IV", "cs.CV"], "comment": "Accept by MICCAI2025", "summary": "Magnetic Resonance Imaging (MRI) reconstruction is essential in medical\ndiagnostics. As the latest generative models, diffusion models (DMs) have\nstruggled to produce high-fidelity images due to their stochastic nature in\nimage domains. Latent diffusion models (LDMs) yield both compact and detailed\nprior knowledge in latent domains, which could effectively guide the model\ntowards more effective learning of the original data distribution. Inspired by\nthis, we propose Multi-domain Diffusion Prior Guidance (MDPG) provided by\npre-trained LDMs to enhance data consistency in MRI reconstruction tasks.\nSpecifically, we first construct a Visual-Mamba-based backbone, which enables\nefficient encoding and reconstruction of under-sampled images. Then pre-trained\nLDMs are integrated to provide conditional priors in both latent and image\ndomains. A novel Latent Guided Attention (LGA) is proposed for efficient fusion\nin multi-level latent domains. Simultaneously, to effectively utilize a prior\nin both the k-space and image domain, under-sampled images are fused with\ngenerated full-sampled images by the Dual-domain Fusion Branch (DFB) for\nself-adaption guidance. Lastly, to further enhance the data consistency, we\npropose a k-space regularization strategy based on the non-auto-calibration\nsignal (NACS) set. Extensive experiments on two public MRI datasets fully\ndemonstrate the effectiveness of the proposed methodology. The code is\navailable at https://github.com/Zolento/MDPG.", "AI": {"tldr": "The paper proposes Multi-domain Diffusion Prior Guidance (MDPG) using latent diffusion models (LDMs) to improve MRI reconstruction by enhancing data consistency through multi-domain priors and a novel fusion strategy.", "motivation": "MRI reconstruction is critical for diagnostics, but diffusion models struggle with high-fidelity images due to stochasticity. LDMs offer compact prior knowledge in latent domains, which can guide better learning of data distribution.", "method": "The method includes a Visual-Mamba-based backbone for encoding/reconstruction, pre-trained LDMs for conditional priors, Latent Guided Attention (LGA) for fusion, and Dual-domain Fusion Branch (DFB) for k-space and image domain fusion. A k-space regularization strategy is also introduced.", "result": "Extensive experiments on public MRI datasets validate the effectiveness of MDPG in enhancing MRI reconstruction.", "conclusion": "MDPG successfully leverages LDMs and multi-domain fusion to improve MRI reconstruction, demonstrating superior performance in experiments."}}
{"id": "2506.23563", "pdf": "https://arxiv.org/pdf/2506.23563", "abs": "https://arxiv.org/abs/2506.23563", "authors": ["Huanjin Yao", "Jiaxing Huang", "Yawen Qiu", "Michael K. Chen", "Wenzheng Liu", "Wei Zhang", "Wenjie Zeng", "Xikun Zhang", "Jingyi Zhang", "Yuxin Song", "Wenhao Wu", "Dacheng Tao"], "title": "MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": "Technical report", "summary": "Reasoning plays a crucial role in advancing Multimodal Large Language Models\n(MLLMs) toward Artificial General Intelligence. However, existing MLLM\nbenchmarks often fall short in precisely and comprehensively evaluating\nlong-chain reasoning abilities from three key aspects: (1) lack of difficulty\nand diversity, (2) susceptibility to guessability and memorization, (3)\ninadequate assessment of intermediate reasoning steps. To fill this gap, we\nintroduce MMReason, a new benchmark designed to precisely and comprehensively\nevaluate MLLM long-chain reasoning capability with diverse, open-ended,\nchallenging questions. First, we curate challenging questions requiring\nmulti-step reasoning from various fields (i.e., 6 disciplines) and multiple\ndifficulty levels (i.e., from pre-university to university, and from\nfoundational to competition tiers). Second, these questions are reformulated\ninto an open-ended format and filtered using a multi-model voting technique to\neliminate shortcut cases related to guessing and memorization, ensuring robust\nreasoning evaluations. Third, we annotate the questions with detailed\nstep-by-step solutions, and design a reference-based ternary scoring mechanism\nto reliably assess intermediate reasoning steps. With MMReason, we benchmark\npopular leading MLLMs and provide an in-depth analysis of their reasoning\ncapabilities. We hope MMReason will serve as a valuable resource for advancing\nMLLM reasoning research. Code will be available at\nhttps://github.com/HJYao00/MMReason.", "AI": {"tldr": "MMReason is a new benchmark for evaluating long-chain reasoning in Multimodal Large Language Models (MLLMs), addressing gaps in existing benchmarks by offering diverse, challenging questions and robust evaluation methods.", "motivation": "Existing MLLM benchmarks lack precision and comprehensiveness in evaluating long-chain reasoning, particularly in difficulty, diversity, and intermediate step assessment.", "method": "MMReason curates multi-step reasoning questions from various fields and difficulty levels, reformulates them to avoid shortcuts, and uses annotated solutions and ternary scoring for reliable evaluation.", "result": "The benchmark evaluates popular MLLMs, providing insights into their reasoning capabilities.", "conclusion": "MMReason aims to advance MLLM reasoning research by offering a precise and comprehensive evaluation tool."}}
{"id": "2506.22802", "pdf": "https://arxiv.org/pdf/2506.22802", "abs": "https://arxiv.org/abs/2506.22802", "authors": ["Hae Jin Song", "Laurent Itti"], "title": "Riemannian-Geometric Fingerprints of Generative Models", "categories": ["cs.LG", "cs.CR", "cs.CV", "I.2.6"], "comment": null, "summary": "Recent breakthroughs and rapid integration of generative models (GMs) have\nsparked interest in the problem of model attribution and their fingerprints.\nFor instance, service providers need reliable methods of authenticating their\nmodels to protect their IP, while users and law enforcement seek to verify the\nsource of generated content for accountability and trust. In addition, a\ngrowing threat of model collapse is arising, as more model-generated data are\nbeing fed back into sources (e.g., YouTube) that are often harvested for\ntraining (\"regurgitative training\"), heightening the need to differentiate\nsynthetic from human data. Yet, a gap still exists in understanding generative\nmodels' fingerprints, we believe, stemming from the lack of a formal framework\nthat can define, represent, and analyze the fingerprints in a principled way.\nTo address this gap, we take a geometric approach and propose a new definition\nof artifact and fingerprint of GMs using Riemannian geometry, which allows us\nto leverage the rich theory of differential geometry. Our new definition\ngeneralizes previous work (Song et al., 2024) to non-Euclidean manifolds by\nlearning Riemannian metrics from data and replacing the Euclidean distances and\nnearest-neighbor search with geodesic distances and kNN-based Riemannian center\nof mass. We apply our theory to a new gradient-based algorithm for computing\nthe fingerprints in practice. Results show that it is more effective in\ndistinguishing a large array of GMs, spanning across 4 different datasets in 2\ndifferent resolutions (64 by 64, 256 by 256), 27 model architectures, and 2\nmodalities (Vision, Vision-Language). Using our proposed definition\nsignificantly improves the performance on model attribution, as well as a\ngeneralization to unseen datasets, model types, and modalities, suggesting its\npractical efficacy.", "AI": {"tldr": "The paper proposes a geometric approach to define and analyze generative model fingerprints using Riemannian geometry, improving model attribution and generalization.", "motivation": "The need to authenticate generative models for IP protection, verify content sources, and address model collapse due to synthetic data in training.", "method": "A geometric framework using Riemannian geometry to define artifacts and fingerprints, replacing Euclidean metrics with geodesic distances and Riemannian center of mass.", "result": "Improved effectiveness in distinguishing diverse generative models across datasets, resolutions, architectures, and modalities.", "conclusion": "The proposed method enhances model attribution and generalization, demonstrating practical efficacy."}}
{"id": "2506.22678", "pdf": "https://arxiv.org/pdf/2506.22678", "abs": "https://arxiv.org/abs/2506.22678", "authors": ["Nicolas Caytuiro", "Ivan Sipiran"], "title": "3D Shape Generation: A Survey", "categories": ["cs.CV"], "comment": "20 pages, 5 figures", "summary": "Recent advances in deep learning have significantly transformed the field of\n3D shape generation, enabling the synthesis of complex, diverse, and\nsemantically meaningful 3D objects. This survey provides a comprehensive\noverview of the current state of the art in 3D shape generation, organizing the\ndiscussion around three core components: shape representations, generative\nmodeling approaches, and evaluation protocols. We begin by categorizing 3D\nrepresentations into explicit, implicit, and hybrid setups, highlighting their\nstructural properties, advantages, and limitations. Next, we review a wide\nrange of generation methods, focusing on feedforward architectures. We further\nsummarize commonly used datasets and evaluation metrics that assess fidelity,\ndiversity, and realism of generated shapes. Finally, we identify open\nchallenges and outline future research directions that could drive progress in\ncontrollable, efficient, and high-quality 3D shape generation. This survey aims\nto serve as a valuable reference for researchers and practitioners seeking a\nstructured and in-depth understanding of this rapidly evolving field.", "AI": {"tldr": "A survey on 3D shape generation, covering representations, methods, and evaluation, with future research directions.", "motivation": "To provide a structured overview of advancements in 3D shape generation and guide future research.", "method": "Categorizes 3D representations, reviews generative approaches, and summarizes datasets and metrics.", "result": "Organizes the field into core components and identifies open challenges.", "conclusion": "Serves as a reference for understanding and advancing 3D shape generation."}}
{"id": "2506.23101", "pdf": "https://arxiv.org/pdf/2506.23101", "abs": "https://arxiv.org/abs/2506.23101", "authors": ["Yue Xu", "Wenjie Wang"], "title": "From Individuals to Interactions: Benchmarking Gender Bias in Multimodal Large Language Models from the Lens of Social Relationship", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multimodal large language models (MLLMs) have shown impressive capabilities\nacross tasks involving both visual and textual modalities. However, growing\nconcerns remain about their potential to encode and amplify gender bias,\nparticularly in socially sensitive applications. Existing benchmarks\npredominantly evaluate bias in isolated scenarios, overlooking how bias may\nemerge subtly through interpersonal interactions. We fill this gap by going\nbeyond single-entity evaluation and instead focusing on a deeper examination of\nrelational and contextual gender bias in dual-individual interactions. We\nintroduce Genres, a novel benchmark designed to evaluate gender bias in MLLMs\nthrough the lens of social relationships in generated narratives. Genres\nassesses gender bias through a dual-character profile and narrative generation\ntask that captures rich interpersonal dynamics and supports a fine-grained bias\nevaluation suite across multiple dimensions. Experiments on both open- and\nclosed-source MLLMs reveal persistent, context-sensitive gender biases that are\nnot evident in single-character settings. Our findings underscore the\nimportance of relationship-aware benchmarks for diagnosing subtle,\ninteraction-driven gender bias in MLLMs and provide actionable insights for\nfuture bias mitigation.", "AI": {"tldr": "The paper introduces Genres, a benchmark for evaluating gender bias in multimodal large language models (MLLMs) through relational and contextual interactions, revealing persistent biases not evident in single-character settings.", "motivation": "Addressing concerns about gender bias in MLLMs, especially in socially sensitive applications, by moving beyond isolated evaluations to examine relational and contextual bias.", "method": "Developed Genres, a benchmark using dual-character profiles and narrative generation tasks to assess gender bias in interpersonal dynamics.", "result": "Experiments showed context-sensitive gender biases in MLLMs, highlighting issues not captured in single-entity evaluations.", "conclusion": "Relationship-aware benchmarks like Genres are crucial for identifying subtle, interaction-driven biases and guiding future bias mitigation efforts."}}
{"id": "2506.23721", "pdf": "https://arxiv.org/pdf/2506.23721", "abs": "https://arxiv.org/abs/2506.23721", "authors": ["Gijs Luijten", "Roberto Maria Scardigno", "Lisle Faray de Paiva", "Peter Hoyer", "Jens Kleesiek", "Domenico Buongiorno", "Vitoantonio Bevilacqua", "Jan Egger"], "title": "Deep Learning-Based Semantic Segmentation for Real-Time Kidney Imaging and Measurements with Augmented Reality-Assisted Ultrasound", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.HC", "cs.LG"], "comment": null, "summary": "Ultrasound (US) is widely accessible and radiation-free but has a steep\nlearning curve due to its dynamic nature and non-standard imaging planes.\nAdditionally, the constant need to shift focus between the US screen and the\npatient poses a challenge. To address these issues, we integrate deep learning\n(DL)-based semantic segmentation for real-time (RT) automated kidney volumetric\nmeasurements, which are essential for clinical assessment but are traditionally\ntime-consuming and prone to fatigue. This automation allows clinicians to\nconcentrate on image interpretation rather than manual measurements.\nComplementing DL, augmented reality (AR) enhances the usability of US by\nprojecting the display directly into the clinician's field of view, improving\nergonomics and reducing the cognitive load associated with screen-to-patient\ntransitions. Two AR-DL-assisted US pipelines on HoloLens-2 are proposed: one\nstreams directly via the application programming interface for a wireless\nsetup, while the other supports any US device with video output for broader\naccessibility. We evaluate RT feasibility and accuracy using the Open Kidney\nDataset and open-source segmentation models (nnU-Net, Segmenter, YOLO with\nMedSAM and LiteMedSAM). Our open-source GitHub pipeline includes model\nimplementations, measurement algorithms, and a Wi-Fi-based streaming solution,\nenhancing US training and diagnostics, especially in point-of-care settings.", "AI": {"tldr": "The paper proposes integrating deep learning (DL) for real-time kidney segmentation in ultrasound (US) and augmented reality (AR) to improve usability. Two AR-DL-assisted pipelines on HoloLens-2 are introduced, evaluated for feasibility and accuracy, and made open-source.", "motivation": "Ultrasound has a steep learning curve and requires focus shifts between screen and patient. Manual kidney volumetric measurements are time-consuming and prone to fatigue.", "method": "DL-based semantic segmentation for real-time kidney measurements and AR to project US displays into the clinician's view. Two HoloLens-2 pipelines are proposed: one wireless and one for any US device.", "result": "The pipelines are evaluated using the Open Kidney Dataset and open-source models (nnU-Net, Segmenter, YOLO with MedSAM/LiteMedSAM). An open-source GitHub pipeline is provided.", "conclusion": "The AR-DL integration enhances US usability, reduces cognitive load, and improves training and diagnostics, especially in point-of-care settings."}}
{"id": "2506.23576", "pdf": "https://arxiv.org/pdf/2506.23576", "abs": "https://arxiv.org/abs/2506.23576", "authors": ["Maria Carolina Cornelia Wit", "Jun Pang"], "title": "Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models", "categories": ["cs.AI"], "comment": "26 pages, 1 figure", "summary": "Recent advances in large language models (LLMs) have raised concerns about\njailbreaking attacks, i.e., prompts that bypass safety mechanisms. This paper\ninvestigates the use of multi-agent LLM systems as a defence against such\nattacks. We evaluate three jailbreaking strategies, including the original\nAutoDefense attack and two from Deepleaps: BetterDan and JB. Reproducing the\nAutoDefense framework, we compare single-agent setups with two- and three-agent\nconfigurations. Our results show that multi-agent systems enhance resistance to\njailbreaks, especially by reducing false negatives. However, its effectiveness\nvaries by attack type, and it introduces trade-offs such as increased false\npositives and computational overhead. These findings point to the limitations\nof current automated defences and suggest directions for improving alignment\nrobustness in future LLM systems.", "AI": {"tldr": "Multi-agent LLM systems improve resistance to jailbreaking attacks but introduce trade-offs like higher false positives and computational costs.", "motivation": "Address concerns about jailbreaking attacks bypassing safety mechanisms in LLMs.", "method": "Evaluated three jailbreaking strategies (AutoDefense, BetterDan, JB) using single-, two-, and three-agent LLM configurations.", "result": "Multi-agent systems reduce false negatives but vary in effectiveness by attack type and increase false positives and computational overhead.", "conclusion": "Highlights limitations of current defences and suggests improving alignment robustness in future LLM systems."}}
{"id": "2506.22809", "pdf": "https://arxiv.org/pdf/2506.22809", "abs": "https://arxiv.org/abs/2506.22809", "authors": ["Cooper Doyle"], "title": "BayesLoRA: Task-Specific Uncertainty in Low-Rank Adapters", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "13 pages, 3 figures, 1 table", "summary": "We propose BayesLoRA, a task-specific uncertainty quantification framework\nthat integrates MC-Dropout into Low-Rank Adapters (LoRA). Unlike\ngeneral-purpose transformer uncertainty methods, BayesLoRA provides guardrails\ntailored to downstream workflows, enabling agents to introspect and modulate\nbehavior under uncertainty. We demonstrate mathematically and empirically that\nLoRA adapters exhibit amplified variance outside fine-tuning distributions,\nyielding reliable confidence estimates for agentic decision-making.", "AI": {"tldr": "BayesLoRA integrates MC-Dropout into LoRA for task-specific uncertainty quantification, aiding agent decision-making under uncertainty.", "motivation": "General-purpose transformer uncertainty methods lack task-specific guardrails, limiting their utility for downstream workflows.", "method": "BayesLoRA combines MC-Dropout with LoRA adapters, analyzing their variance outside fine-tuning distributions.", "result": "The framework provides reliable confidence estimates for agentic decision-making, validated mathematically and empirically.", "conclusion": "BayesLoRA offers tailored uncertainty quantification, enhancing agent introspection and behavior modulation."}}
{"id": "2506.22710", "pdf": "https://arxiv.org/pdf/2506.22710", "abs": "https://arxiv.org/abs/2506.22710", "authors": ["Jiang Yuan", "JI Ma", "Bo Wang", "Guanzhou Ke", "Weiming Hu"], "title": "LightBSR: Towards Lightweight Blind Super-Resolution via Discriminative Implicit Degradation Representation Learning", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Implicit degradation estimation-based blind super-resolution (IDE-BSR) hinges\non extracting the implicit degradation representation (IDR) of the LR image and\nadapting it to LR image features to guide HR detail restoration. Although\nIDE-BSR has shown potential in dealing with noise interference and complex\ndegradations, existing methods ignore the importance of IDR discriminability\nfor BSR and instead over-complicate the adaptation process to improve effect,\nresulting in a significant increase in the model's parameters and computations.\nIn this paper, we focus on the discriminability optimization of IDR and propose\na new powerful and lightweight BSR model termed LightBSR. Specifically, we\nemploy a knowledge distillation-based learning framework. We first introduce a\nwell-designed degradation-prior-constrained contrastive learning technique\nduring teacher stage to make the model more focused on distinguishing different\ndegradation types. Then we utilize a feature alignment technique to transfer\nthe degradation-related knowledge acquired by the teacher to the student for\npractical inferencing. Extensive experiments demonstrate the effectiveness of\nIDR discriminability-driven BSR model design. The proposed LightBSR can achieve\noutstanding performance with minimal complexity across a range of blind SR\ntasks. Our code is accessible at: https://github.com/MJ-NCEPU/LightBSR.", "AI": {"tldr": "LightBSR proposes a lightweight blind super-resolution model by optimizing implicit degradation representation (IDR) discriminability, using knowledge distillation and contrastive learning.", "motivation": "Existing IDE-BSR methods overlook IDR discriminability, complicating adaptation and increasing model complexity. LightBSR addresses this gap.", "method": "Uses knowledge distillation: contrastive learning in the teacher stage for degradation discrimination, then feature alignment to transfer knowledge to the student model.", "result": "Achieves high performance with minimal complexity in blind SR tasks.", "conclusion": "LightBSR effectively balances performance and efficiency by focusing on IDR discriminability."}}
{"id": "2506.23111", "pdf": "https://arxiv.org/pdf/2506.23111", "abs": "https://arxiv.org/abs/2506.23111", "authors": ["Janki Atul Nawale", "Mohammed Safi Ur Rahman Khan", "Janani D", "Mansi Gupta", "Danish Pruthi", "Mitesh M. Khapra"], "title": "FairI Tales: Evaluation of Fairness in Indian Contexts with a Focus on Bias and Stereotypes", "categories": ["cs.CL"], "comment": "Accepted in ACL 2025", "summary": "Existing studies on fairness are largely Western-focused, making them\ninadequate for culturally diverse countries such as India. To address this gap,\nwe introduce INDIC-BIAS, a comprehensive India-centric benchmark designed to\nevaluate fairness of LLMs across 85 identity groups encompassing diverse\ncastes, religions, regions, and tribes. We first consult domain experts to\ncurate over 1,800 socio-cultural topics spanning behaviors and situations,\nwhere biases and stereotypes are likely to emerge. Grounded in these topics, we\ngenerate and manually validate 20,000 real-world scenario templates to probe\nLLMs for fairness. We structure these templates into three evaluation tasks:\nplausibility, judgment, and generation. Our evaluation of 14 popular LLMs on\nthese tasks reveals strong negative biases against marginalized identities,\nwith models frequently reinforcing common stereotypes. Additionally, we find\nthat models struggle to mitigate bias even when explicitly asked to rationalize\ntheir decision. Our evaluation provides evidence of both allocative and\nrepresentational harms that current LLMs could cause towards Indian identities,\ncalling for a more cautious usage in practical applications. We release\nINDIC-BIAS as an open-source benchmark to advance research on benchmarking and\nmitigating biases and stereotypes in the Indian context.", "AI": {"tldr": "INDIC-BIAS is an India-centric benchmark to evaluate fairness in LLMs across 85 identity groups, revealing strong biases against marginalized identities.", "motivation": "Existing fairness studies are Western-focused, lacking applicability to culturally diverse regions like India.", "method": "Curated 1,800 socio-cultural topics, generated 20,000 scenario templates, and structured them into three tasks (plausibility, judgment, generation) to evaluate 14 LLMs.", "result": "LLMs exhibit strong negative biases against marginalized groups, reinforcing stereotypes and failing to mitigate bias even when prompted.", "conclusion": "INDIC-BIAS highlights allocative and representational harms of LLMs in India, advocating cautious usage and open-sourcing the benchmark for further research."}}
{"id": "2506.23759", "pdf": "https://arxiv.org/pdf/2506.23759", "abs": "https://arxiv.org/abs/2506.23759", "authors": ["Zheng Fang", "Xiaoming Qi", "Chun-Mei Feng", "Jialun Pei", "Weixin Si", "Yueming Jin"], "title": "Spatio-Temporal Representation Decoupling and Enhancement for Federated Instrument Segmentation in Surgical Videos", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Surgical instrument segmentation under Federated Learning (FL) is a promising\ndirection, which enables multiple surgical sites to collaboratively train the\nmodel without centralizing datasets. However, there exist very limited FL works\nin surgical data science, and FL methods for other modalities do not consider\ninherent characteristics in surgical domain: i) different scenarios show\ndiverse anatomical backgrounds while highly similar instrument representation;\nii) there exist surgical simulators which promote large-scale synthetic data\ngeneration with minimal efforts. In this paper, we propose a novel Personalized\nFL scheme, Spatio-Temporal Representation Decoupling and Enhancement (FedST),\nwhich wisely leverages surgical domain knowledge during both local-site and\nglobal-server training to boost segmentation. Concretely, our model embraces a\nRepresentation Separation and Cooperation (RSC) mechanism in local-site\ntraining, which decouples the query embedding layer to be trained privately, to\nencode respective backgrounds. Meanwhile, other parameters are optimized\nglobally to capture the consistent representations of instruments, including\nthe temporal layer to capture similar motion patterns. A textual-guided channel\nselection is further designed to highlight site-specific features, facilitating\nmodel adapta tion to each site. Moreover, in global-server training, we propose\nSynthesis-based Explicit Representation Quantification (SERQ), which defines an\nexplicit representation target based on synthetic data to synchronize the model\nconvergence during fusion for improving model generalization.", "AI": {"tldr": "The paper proposes FedST, a personalized FL scheme for surgical instrument segmentation, leveraging domain knowledge to improve local and global training.", "motivation": "Existing FL methods overlook surgical domain characteristics like diverse backgrounds and synthetic data potential.", "method": "FedST uses RSC for local training (decoupling query embeddings) and SERQ for global training (synthetic data-based representation quantification).", "result": "The method enhances segmentation by capturing consistent instrument representations and adapting to site-specific features.", "conclusion": "FedST effectively integrates surgical domain knowledge into FL, improving model generalization and segmentation performance."}}
{"id": "2506.23626", "pdf": "https://arxiv.org/pdf/2506.23626", "abs": "https://arxiv.org/abs/2506.23626", "authors": ["Ant\u00f3nio Afonso", "Iolanda Leite", "Alessandro Sestini", "Florian Fuchs", "Konrad Tollmar", "Linus Gissl\u00e9n"], "title": "Self-correcting Reward Shaping via Language Models for Reinforcement Learning Agents in Games", "categories": ["cs.AI"], "comment": "16 pages in total, 10 pages of main paper, 5 figures", "summary": "Reinforcement Learning (RL) in games has gained significant momentum in\nrecent years, enabling the creation of different agent behaviors that can\ntransform a player's gaming experience. However, deploying RL agents in\nproduction environments presents two key challenges: (1) designing an effective\nreward function typically requires an RL expert, and (2) when a game's content\nor mechanics are modified, previously tuned reward weights may no longer be\noptimal. Towards the latter challenge, we propose an automated approach for\niteratively fine-tuning an RL agent's reward function weights, based on a\nuser-defined language based behavioral goal. A Language Model (LM) proposes\nupdated weights at each iteration based on this target behavior and a summary\nof performance statistics from prior training rounds. This closed-loop process\nallows the LM to self-correct and refine its output over time, producing\nincreasingly aligned behavior without the need for manual reward engineering.\nWe evaluate our approach in a racing task and show that it consistently\nimproves agent performance across iterations. The LM-guided agents show a\nsignificant increase in performance from $9\\%$ to $74\\%$ success rate in just\none iteration. We compare our LM-guided tuning against a human expert's manual\nweight design in the racing task: by the final iteration, the LM-tuned agent\nachieved an $80\\%$ success rate, and completed laps in an average of $855$ time\nsteps, a competitive performance against the expert-tuned agent's peak $94\\%$\nsuccess, and $850$ time steps.", "AI": {"tldr": "An automated method using a Language Model (LM) fine-tunes RL agent reward weights iteratively, improving performance without manual engineering.", "motivation": "Deploying RL agents in games faces challenges in reward function design and adaptability to game changes.", "method": "LM proposes updated reward weights based on user-defined behavioral goals and performance stats, enabling self-correction.", "result": "LM-guided tuning improved agent success from 9% to 74% in one iteration, reaching 80% success (vs. expert's 94%).", "conclusion": "Automated LM-guided reward tuning is effective, reducing reliance on manual expert intervention."}}
{"id": "2506.22821", "pdf": "https://arxiv.org/pdf/2506.22821", "abs": "https://arxiv.org/abs/2506.22821", "authors": ["Thomas Gaskin", "Guy J. Abel"], "title": "Deep learning 40 years of human migration", "categories": ["cs.LG", "68T07", "I.2.6"], "comment": null, "summary": "We present a novel and detailed dataset on origin-destination annual\nmigration flows and stocks between 230 countries and regions, spanning the\nperiod from 1990 to the present. Our flow estimates are further disaggregated\nby country of birth, providing a comprehensive picture of migration over the\nlast 43 years. The estimates are obtained by training a deep recurrent neural\nnetwork to learn flow patterns from 18 covariates for all countries, including\ngeographic, economic, cultural, societal, and political information. The\nrecurrent architecture of the neural network means that the entire past can\ninfluence current migration patterns, allowing us to learn long-range temporal\ncorrelations. By training an ensemble of neural networks and additionally\npushing uncertainty on the covariates through the trained network, we obtain\nconfidence bounds for all our estimates, allowing researchers to pinpoint the\ngeographic regions most in need of additional data collection. We validate our\napproach on various test sets of unseen data, demonstrating that it\nsignificantly outperforms traditional methods estimating five-year flows while\ndelivering a significant increase in temporal resolution. The model is fully\nopen source: all training data, neural network weights, and training code are\nmade public alongside the migration estimates, providing a valuable resource\nfor future studies of human migration.", "AI": {"tldr": "A novel dataset on global migration flows (1990-present) is created using a deep recurrent neural network trained on 18 covariates, providing detailed estimates with confidence bounds and outperforming traditional methods.", "motivation": "To provide a comprehensive and detailed dataset on global migration flows and stocks, disaggregated by country of birth, to improve understanding and research on human migration.", "method": "A deep recurrent neural network is trained on 18 covariates (geographic, economic, cultural, societal, political) to learn migration patterns, with an ensemble approach for confidence bounds.", "result": "The model outperforms traditional methods, offering higher temporal resolution and validated accuracy on unseen data, with open-source availability of data and code.", "conclusion": "The dataset and model provide a valuable, open-source resource for migration research, highlighting regions needing additional data and improving estimation accuracy."}}
{"id": "2506.22718", "pdf": "https://arxiv.org/pdf/2506.22718", "abs": "https://arxiv.org/abs/2506.22718", "authors": ["Jun-Jee Chao", "Qingyuan Jiang", "Volkan Isler"], "title": "Part Segmentation and Motion Estimation for Articulated Objects with Dynamic 3D Gaussians", "categories": ["cs.CV"], "comment": null, "summary": "Part segmentation and motion estimation are two fundamental problems for\narticulated object motion analysis. In this paper, we present a method to solve\nthese two problems jointly from a sequence of observed point clouds of a single\narticulated object. The main challenge in our problem setting is that the point\nclouds are not assumed to be generated by a fixed set of moving points.\nInstead, each point cloud in the sequence could be an arbitrary sampling of the\nobject surface at that particular time step. Such scenarios occur when the\nobject undergoes major occlusions, or if the dataset is collected using\nmeasurements from multiple sensors asynchronously. In these scenarios, methods\nthat rely on tracking point correspondences are not appropriate. We present an\nalternative approach based on a compact but effective representation where we\nrepresent the object as a collection of simple building blocks modeled as 3D\nGaussians. We parameterize the Gaussians with time-dependent rotations,\ntranslations, and scales that are shared across all time steps. With our\nrepresentation, part segmentation can be achieved by building correspondences\nbetween the observed points and the Gaussians. Moreover, the transformation of\neach point across time can be obtained by following the poses of the assigned\nGaussian (even when the point is not observed). Experiments show that our\nmethod outperforms existing methods that solely rely on finding point\ncorrespondences. Additionally, we extend existing datasets to emulate\nreal-world scenarios by considering viewpoint occlusions. We further\ndemonstrate that our method is more robust to missing points as compared to\nexisting approaches on these challenging datasets, even when some parts are\ncompletely occluded in some time-steps. Notably, our part segmentation\nperformance outperforms the state-of-the-art method by 13% on point clouds with\nocclusions.", "AI": {"tldr": "A method for joint part segmentation and motion estimation from point clouds of articulated objects, robust to occlusions and missing data.", "motivation": "Address challenges in analyzing articulated object motion when point clouds vary due to occlusions or asynchronous sensor data, making point correspondence tracking ineffective.", "method": "Uses 3D Gaussians as building blocks with time-dependent transformations (rotations, translations, scales) shared across time steps. Part segmentation and motion estimation are derived from point-Gaussian correspondences.", "result": "Outperforms point-correspondence methods, especially with occlusions, improving part segmentation by 13% over state-of-the-art.", "conclusion": "The proposed representation is effective for joint part segmentation and motion estimation, robust to occlusions and missing data."}}
{"id": "2506.23122", "pdf": "https://arxiv.org/pdf/2506.23122", "abs": "https://arxiv.org/abs/2506.23122", "authors": ["Shivam Sharma", "Tanmoy Chakraborty"], "title": "Decoding Memes: Benchmarking Narrative Role Classification across Multilingual and Multimodal Models", "categories": ["cs.CL", "cs.CY"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "This work investigates the challenging task of identifying narrative roles -\nHero, Villain, Victim, and Other - in Internet memes, across three diverse test\nsets spanning English and code-mixed (English-Hindi) languages. Building on an\nannotated dataset originally skewed toward the 'Other' class, we explore a more\nbalanced and linguistically diverse extension, originally introduced as part of\nthe CLEF 2024 shared task. Comprehensive lexical and structural analyses\nhighlight the nuanced, culture-specific, and context-rich language used in real\nmemes, in contrast to synthetically curated hateful content, which exhibits\nexplicit and repetitive lexical markers. To benchmark the role detection task,\nwe evaluate a wide spectrum of models, including fine-tuned multilingual\ntransformers, sentiment and abuse-aware classifiers, instruction-tuned LLMs,\nand multimodal vision-language models. Performance is assessed under zero-shot\nsettings using precision, recall, and F1 metrics. While larger models like\nDeBERTa-v3 and Qwen2.5-VL demonstrate notable gains, results reveal consistent\nchallenges in reliably identifying the 'Victim' class and generalising across\ncultural and code-mixed content. We also explore prompt design strategies to\nguide multimodal models and find that hybrid prompts incorporating structured\ninstructions and role definitions offer marginal yet consistent improvements.\nOur findings underscore the importance of cultural grounding, prompt\nengineering, and multimodal reasoning in modelling subtle narrative framings in\nvisual-textual content.", "AI": {"tldr": "The paper explores identifying narrative roles (Hero, Villain, Victim, Other) in memes across English and code-mixed languages, using a balanced dataset. It evaluates various models, highlighting challenges in detecting the 'Victim' class and cultural generalization.", "motivation": "To address the nuanced, culture-specific language in memes and improve role detection, especially for underrepresented classes like 'Victim'.", "method": "Evaluates multilingual transformers, sentiment classifiers, LLMs, and multimodal models under zero-shot settings, using precision, recall, and F1 metrics. Also explores prompt design for multimodal models.", "result": "Larger models like DeBERTa-v3 and Qwen2.5-VL perform well, but 'Victim' detection and cross-cultural generalization remain challenging. Hybrid prompts improve results marginally.", "conclusion": "Cultural grounding, prompt engineering, and multimodal reasoning are crucial for accurately modeling narrative roles in memes."}}
{"id": "2506.24003", "pdf": "https://arxiv.org/pdf/2506.24003", "abs": "https://arxiv.org/abs/2506.24003", "authors": ["Junqi Liu", "Dongli He", "Wenxuan Li", "Ningyu Wang", "Alan L. Yuille", "Zongwei Zhou"], "title": "ShapeKit", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "In this paper, we present a practical approach to improve anatomical shape\naccuracy in whole-body medical segmentation. Our analysis shows that a\nshape-focused toolkit can enhance segmentation performance by over 8%, without\nthe need for model re-training or fine-tuning. In comparison, modifications to\nmodel architecture typically lead to marginal gains of less than 3%. Motivated\nby this observation, we introduce ShapeKit, a flexible and easy-to-integrate\ntoolkit designed to refine anatomical shapes. This work highlights the\nunderappreciated value of shape-based tools and calls attention to their\npotential impact within the medical segmentation community.", "AI": {"tldr": "ShapeKit, a shape-focused toolkit, improves whole-body medical segmentation accuracy by over 8% without model re-training, outperforming architecture modifications.", "motivation": "The observation that shape-focused tools can significantly enhance segmentation performance more than model architecture changes.", "method": "Introduces ShapeKit, a flexible toolkit for refining anatomical shapes in medical segmentation.", "result": "ShapeKit boosts segmentation accuracy by over 8%, surpassing the marginal gains (under 3%) from model architecture changes.", "conclusion": "Shape-based tools like ShapeKit are undervalued and can greatly impact the medical segmentation community."}}
{"id": "2506.23673", "pdf": "https://arxiv.org/pdf/2506.23673", "abs": "https://arxiv.org/abs/2506.23673", "authors": ["Jingsong Liu", "Han Li", "Chen Yang", "Michael Deutges", "Ario Sadafi", "Xin You", "Katharina Breininger", "Nassir Navab", "Peter J. Sch\u00fcffler"], "title": "HASD: Hierarchical Adaption for pathology Slide-level Domain-shift", "categories": ["cs.AI"], "comment": null, "summary": "Domain shift is a critical problem for pathology AI as pathology data is\nheavily influenced by center-specific conditions. Current pathology domain\nadaptation methods focus on image patches rather than WSI, thus failing to\ncapture global WSI features required in typical clinical scenarios. In this\nwork, we address the challenges of slide-level domain shift by proposing a\nHierarchical Adaptation framework for Slide-level Domain-shift (HASD). HASD\nachieves multi-scale feature consistency and computationally efficient\nslide-level domain adaptation through two key components: (1) a hierarchical\nadaptation framework that integrates a Domain-level Alignment Solver for\nfeature alignment, a Slide-level Geometric Invariance Regularization to\npreserve the morphological structure, and a Patch-level Attention Consistency\nRegularization to maintain local critical diagnostic cues; and (2) a prototype\nselection mechanism that reduces computational overhead. We validate our method\non two slide-level tasks across five datasets, achieving a 4.1\\% AUROC\nimprovement in a Breast Cancer HER2 Grading cohort and a 3.9\\% C-index gain in\na UCEC survival prediction cohort. Our method provides a practical and reliable\nslide-level domain adaption solution for pathology institutions, minimizing\nboth computational and annotation costs.", "AI": {"tldr": "HASD proposes a hierarchical framework for slide-level domain adaptation in pathology AI, improving performance while reducing computational costs.", "motivation": "Addressing slide-level domain shift in pathology AI, as current methods focus on patches and miss global WSI features.", "method": "HASD uses hierarchical adaptation (domain alignment, geometric invariance, patch attention) and prototype selection for efficiency.", "result": "Achieves 4.1% AUROC improvement in HER2 grading and 3.9% C-index gain in survival prediction.", "conclusion": "HASD offers a practical, efficient solution for slide-level domain adaptation in pathology."}}
{"id": "2506.22837", "pdf": "https://arxiv.org/pdf/2506.22837", "abs": "https://arxiv.org/abs/2506.22837", "authors": ["Kamil Faber", "Marcin Pietro\u0144", "Dominik \u017burek", "Roberto Corizzo"], "title": "xLSTMAD: A Powerful xLSTM-based Method for Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The recently proposed xLSTM is a powerful model that leverages expressive\nmultiplicative gating and residual connections, providing the temporal capacity\nneeded for long-horizon forecasting and representation learning. This\narchitecture has demonstrated success in time series forecasting, lossless\ncompression, and even large-scale language modeling tasks, where its linear\nmemory footprint and fast inference make it a viable alternative to\nTransformers. Despite its growing popularity, no prior work has explored xLSTM\nfor anomaly detection. In this work, we fill this gap by proposing xLSTMAD, the\nfirst anomaly detection method that integrates a full encoder-decoder xLSTM\narchitecture, purpose-built for multivariate time series data. Our encoder\nprocesses input sequences to capture historical context, while the decoder is\ndevised in two separate variants of the method. In the forecasting approach,\nthe decoder iteratively generates forecasted future values xLSTMAD-F, while the\nreconstruction approach reconstructs the input time series from its encoded\ncounterpart xLSTMAD-R. We investigate the performance of two loss functions:\nMean Squared Error (MSE), and Soft Dynamic Time Warping (SoftDTW) to consider\nlocal reconstruction fidelity and global sequence alignment, respectively. We\nevaluate our method on the comprehensive TSB-AD-M benchmark, which spans 17\nreal-world datasets, using state-of-the-art challenging metrics such as VUS-PR.\nIn our results, xLSTM showcases state-of-the-art accuracy, outperforming 23\npopular anomaly detection baselines. Our paper is the first work revealing the\npowerful modeling capabilities of xLSTM for anomaly detection, paving the way\nfor exciting new developments on this subject. Our code is available at:\nhttps://github.com/Nyderx/xlstmad", "AI": {"tldr": "The paper introduces xLSTMAD, the first anomaly detection method using xLSTM, achieving state-of-the-art results on multivariate time series data.", "motivation": "To explore xLSTM's potential for anomaly detection, a gap in prior research, by proposing a novel encoder-decoder architecture.", "method": "xLSTMAD uses two decoder variants (forecasting and reconstruction) with MSE and SoftDTW loss functions for local and global sequence alignment.", "result": "xLSTMAD outperforms 23 baselines on the TSB-AD-M benchmark, demonstrating superior accuracy.", "conclusion": "xLSTMAD reveals xLSTM's strong anomaly detection capabilities, opening new research directions."}}
{"id": "2506.22720", "pdf": "https://arxiv.org/pdf/2506.22720", "abs": "https://arxiv.org/abs/2506.22720", "authors": ["Jinghao Wang", "Zhang Li", "Zi Wang", "Banglei Guan", "Yang Shang", "Qifeng Yu"], "title": "Deterministic Object Pose Confidence Region Estimation", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "6D pose confidence region estimation has emerged as a critical direction,\naiming to perform uncertainty quantification for assessing the reliability of\nestimated poses. However, current sampling-based approach suffers from critical\nlimitations that severely impede their practical deployment: 1) the sampling\nspeed significantly decreases as the number of samples increases. 2) the\nderived confidence regions are often excessively large. To address these\nchallenges, we propose a deterministic and efficient method for estimating pose\nconfidence regions. Our approach uses inductive conformal prediction to\ncalibrate the deterministically regressed Gaussian keypoint distributions into\n2D keypoint confidence regions. We then leverage the implicit function theorem\nto propagate these keypoint confidence regions directly into 6D pose confidence\nregions. This method avoids the inefficiency and inflated region sizes\nassociated with sampling and ensembling. It provides compact confidence regions\nthat cover the ground-truth poses with a user-defined confidence level.\nExperimental results on the LineMOD Occlusion and SPEED datasets show that our\nmethod achieves higher pose estimation accuracy with reduced computational\ntime. For the same coverage rate, our method yields significantly smaller\nconfidence region volumes, reducing them by up to 99.9\\% for rotations and\n99.8\\% for translations. The code will be available soon.", "AI": {"tldr": "A deterministic method for 6D pose confidence region estimation using inductive conformal prediction and implicit function theorem, addressing inefficiency and inflated regions in sampling-based approaches.", "motivation": "Current sampling-based methods for 6D pose confidence region estimation are slow and produce excessively large regions, limiting practical use.", "method": "Uses inductive conformal prediction to calibrate Gaussian keypoint distributions into 2D confidence regions, then propagates these into 6D pose regions via the implicit function theorem.", "result": "Achieves higher accuracy and faster computation, reducing confidence region volumes by up to 99.9% for rotations and 99.8% for translations.", "conclusion": "The proposed method efficiently provides compact confidence regions with user-defined coverage, outperforming sampling-based approaches."}}
{"id": "2506.23127", "pdf": "https://arxiv.org/pdf/2506.23127", "abs": "https://arxiv.org/abs/2506.23127", "authors": ["Zhaoye Fei", "Li Ji", "Siyin Wang", "Junhao Shi", "Jingjing Gong", "Xipeng Qiu"], "title": "Unleashing Embodied Task Planning Ability in LLMs via Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious tasks, yet they face significant challenges in embodied task planning\nscenarios that require continuous environmental understanding and action\ngeneration. Existing approaches generate open-loop action scripts based on\nstatic knowledge, making it difficult to learn causal relationships between\nactions and environmental feedback, particularly in partially observable\nenvironments. We introduce Embodied Planner-R1, a novel outcome-driven\nreinforcement learning framework that enables LLMs to develop interactive\ncapabilities through autonomous exploration with minimal supervision. Our\nframework incorporates three key innovations: (1) Without human annotations, we\nemploy pure reinforcement learning with group rollout, incorporating\nin-environment interaction through parallel exploration; (2) completion-driven\nsparse reward; and (3) Interactive Policy Optimization (IPO) for efficient\nlearning from grouped trajectories. Across two challenging text-based Embodied\nplanning benchmarks, Embodied Planner-R1 achieves impressive completion rates\nof 97.78% on ALFWorld and 79.92% on ScienceWorld, surpassing prior methods by a\nlarge margin, and suffers only a -3.66% drop in previously unseen environments,\nevidencing strong generalization.", "AI": {"tldr": "Embodied Planner-R1 is a reinforcement learning framework for LLMs to improve interactive task planning, achieving high success rates on benchmarks.", "motivation": "LLMs struggle with embodied task planning due to static knowledge and lack of causal learning in dynamic environments.", "method": "Uses reinforcement learning with group rollout, sparse rewards, and Interactive Policy Optimization (IPO) for autonomous exploration.", "result": "Achieves 97.78% on ALFWorld and 79.92% on ScienceWorld, with strong generalization.", "conclusion": "Embodied Planner-R1 significantly outperforms prior methods in interactive task planning."}}
{"id": "2506.24014", "pdf": "https://arxiv.org/pdf/2506.24014", "abs": "https://arxiv.org/abs/2506.24014", "authors": ["Peng Lin", "Xuesong Wang", "Yating Chen", "Xianyu Wu", "Feng Huang", "Shouqian Chen"], "title": "Simultaneous Super-Resolution of Spatial and Spectral Imaging with a Camera Array and Notch Filters", "categories": ["eess.IV"], "comment": null, "summary": "This study proposes an algorithm based on a notch filter camera array system\nfor simultaneous super-resolution imaging and spectral reconstruction,\nenhancing the spatial resolution and multispectral imaging capabilities of\ntargets. In this study, multi-aperture super-resolution algorithms,\npan-sharpening techniques, and spectral reconstruction algorithms were\ninvestigated and integrated. The sub-pixel level offset information and\nspectral disparities among the 9 low-resolution images captured by the 9\ndistinct imaging apertures were utilized, leading to the successful\nreconstruction of 31 super-resolution spectral images. By conducting\nsimulations with a publicly available dataset and performing qualitative and\nquantitative comparisons with snapshot coded aperture spectral imaging systems,\nthe experimental results demonstrate that our system and algorithm attained a\npeak signal-to-noise ratio of 35.6dB, representing a 5dB enhancement over the\nmost advanced snapshot coded aperture spectral imaging systems, while also\nreducing processing time. This research offers an effective solution for\nachieving high temporal, spectral, and spatial resolution through the\nutilization of multi-aperture imaging systems.", "AI": {"tldr": "Proposes an algorithm using a notch filter camera array for super-resolution imaging and spectral reconstruction, achieving higher resolution and faster processing than existing methods.", "motivation": "To enhance spatial resolution and multispectral imaging capabilities by integrating multi-aperture super-resolution, pan-sharpening, and spectral reconstruction techniques.", "method": "Utilizes sub-pixel offset and spectral disparities from 9 low-resolution images to reconstruct 31 super-resolution spectral images. Validated via simulations and comparisons with snapshot coded aperture systems.", "result": "Achieved a peak signal-to-noise ratio of 35.6dB, 5dB better than advanced systems, with reduced processing time.", "conclusion": "Provides an effective solution for high temporal, spectral, and spatial resolution using multi-aperture imaging systems."}}
{"id": "2506.23692", "pdf": "https://arxiv.org/pdf/2506.23692", "abs": "https://arxiv.org/abs/2506.23692", "authors": ["Boyuan Zheng", "Zerui Fang", "Zhe Xu", "Rui Wang", "Yiwen Chen", "Cunshi Wang", "Mengwei Qu", "Lei Lei", "Zhen Feng", "Yan Liu", "Yuyang Li", "Mingzhou Tan", "Jiaji Wu", "Jianwei Shuai", "Jia Li", "Fangfu Ye"], "title": "Agent4S: The Transformation of Research Paradigms from the Perspective of Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "While AI for Science (AI4S) serves as an analytical tool in the current\nresearch paradigm, it doesn't solve its core inefficiency. We propose \"Agent\nfor Science\" (Agent4S)-the use of LLM-driven agents to automate the entire\nresearch workflow-as the true Fifth Scientific Paradigm. This paper introduces\na five-level classification for Agent4S, outlining a clear roadmap from simple\ntask automation to fully autonomous, collaborative \"AI Scientists.\" This\nframework defines the next revolutionary step in scientific discovery.", "AI": {"tldr": "The paper proposes 'Agent for Science' (Agent4S) as the Fifth Scientific Paradigm, using LLM-driven agents to automate research workflows, classified into five levels for progression toward fully autonomous AI Scientists.", "motivation": "Current AI for Science (AI4S) is inefficient; Agent4S aims to revolutionize scientific discovery by automating entire research workflows.", "method": "Introduces a five-level classification for Agent4S, detailing a roadmap from task automation to autonomous, collaborative AI Scientists.", "result": "A framework for Agent4S is presented, defining the next step in scientific discovery.", "conclusion": "Agent4S represents a transformative shift in scientific research, enabling fully autonomous and collaborative AI-driven discovery."}}
{"id": "2506.22845", "pdf": "https://arxiv.org/pdf/2506.22845", "abs": "https://arxiv.org/abs/2506.22845", "authors": ["Batuhan Hangun", "Oguz Altun", "Onder Eyecioglu"], "title": "Quantum Neural Networks for Wind Energy Forecasting: A Comparative Study of Performance and Scalability with Classical Models", "categories": ["cs.LG", "cs.AI", "cs.PF"], "comment": null, "summary": "Quantum Neural Networks (QNNs), a prominent approach in Quantum Machine\nLearning (QML), are emerging as a powerful alternative to classical machine\nlearning methods. Recent studies have focused on the applicability of QNNs to\nvarious tasks, such as time-series forecasting, prediction, and classification,\nacross a wide range of applications, including cybersecurity and medical\nimaging. With the increased use of smart grids driven by the integration of\nrenewable energy systems, machine learning plays an important role in\npredicting power demand and detecting system disturbances. This study provides\nan in-depth investigation of QNNs for predicting the power output of a wind\nturbine. We assess the predictive performance and simulation time of six QNN\nconfigurations that are based on the Z Feature Map for data encoding and\nvarying ansatz structures. Through detailed cross-validation experiments and\ntests on an unseen hold-out dataset, we experimentally demonstrate that QNNs\ncan achieve predictive performance that is competitive with, and in some cases\nmarginally better than, the benchmarked classical approaches. Our results also\nreveal the effects of dataset size and circuit complexity on predictive\nperformance and simulation time. We believe our findings will offer valuable\ninsights for researchers in the energy domain who wish to incorporate quantum\nmachine learning into their work.", "AI": {"tldr": "QNNs are explored for wind turbine power output prediction, showing competitive performance with classical methods, with insights on dataset size and circuit complexity.", "motivation": "To investigate QNNs' applicability in predicting wind turbine power output, addressing the need for efficient methods in smart grids.", "method": "Six QNN configurations using Z Feature Map for data encoding and varying ansatz structures were tested via cross-validation and hold-out dataset experiments.", "result": "QNNs achieved competitive or marginally better predictive performance than classical methods, with dataset size and circuit complexity impacting results.", "conclusion": "QNNs show promise for energy applications, offering insights for integrating quantum machine learning in the field."}}
{"id": "2506.22726", "pdf": "https://arxiv.org/pdf/2506.22726", "abs": "https://arxiv.org/abs/2506.22726", "authors": ["Yu Zhang", "Xi Zhang", "Hualin zhou", "Xinyuan Chen", "Shang Gao", "Hong Jia", "Jianfei Yang", "Yuankai Qi", "Tao Gu"], "title": "XTransfer: Cross-Modality Model Transfer for Human Sensing with Few Data at the Edge", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Deep learning for human sensing on edge systems offers significant\nopportunities for smart applications. However, its training and development are\nhindered by the limited availability of sensor data and resource constraints of\nedge systems. Current methods that rely on transferring pre-trained models\noften encounter issues such as modality shift and high resource demands,\nresulting in substantial accuracy loss, resource overhead, and poor\nadaptability across different sensing applications. In this paper, we propose\nXTransfer, a first-of-its-kind method for resource-efficient, modality-agnostic\nmodel transfer. XTransfer freely leverages single or multiple pre-trained\nmodels and transfers knowledge across different modalities by (i) model\nrepairing that safely repairs modality shift in pre-trained model layers with\nonly few sensor data, and (ii) layer recombining that efficiently searches and\nrecombines layers of interest from source models in a layer-wise manner to\ncreate compact models. We benchmark various baselines across diverse human\nsensing datasets spanning different modalities. Comprehensive results\ndemonstrate that XTransfer achieves state-of-the-art performance on human\nsensing tasks while significantly reducing the costs of sensor data collection,\nmodel training, and edge deployment.", "AI": {"tldr": "XTransfer is a novel method for efficient, modality-agnostic model transfer in edge-based human sensing, addressing issues like modality shift and resource constraints.", "motivation": "Limited sensor data and edge system resources hinder deep learning for human sensing, with current methods suffering from accuracy loss and poor adaptability.", "method": "XTransfer uses model repairing to fix modality shifts and layer recombining to create compact models from pre-trained sources.", "result": "XTransfer outperforms baselines, reducing costs in data collection, training, and deployment while maintaining high accuracy.", "conclusion": "XTransfer offers a scalable, efficient solution for human sensing on edge systems, advancing smart applications."}}
{"id": "2506.23133", "pdf": "https://arxiv.org/pdf/2506.23133", "abs": "https://arxiv.org/abs/2506.23133", "authors": ["Dingzirui Wang", "Xuanliang Zhang", "Rongyu Cao", "Longxu Dou", "Xianzhen Luo", "Yingwei Ma", "Qingfu Zhu", "Wanxiang Che", "Binhua Li", "Fei Huang", "Yongbin Li"], "title": "Format-Adapter: Improving Reasoning Capability of LLMs by Adapting Suitable Format", "categories": ["cs.CL"], "comment": null, "summary": "Generating and voting multiple answers is an effective method to mitigate\nreasoning inconsistencies of large language models (LLMs). Prior works have\nshown that multiple reasoning formats outperform a single format when\ngenerating multiple answers. However, previous works using multiple formats\nrely on formats labeled by humans, which could be unsuitable for all tasks and\nhave high labeling costs. To address this issue, we adapt suitable formats to\nthe given tasks by generating and selecting formats. We first propose how to\nmeasure the reasoning error when generating multiple answers. Then, we\nintroduce Format-Adapter, which utilizes LLMs to generate and select suitable\nreasoning formats by minimizing the error measurement we present. We conduct\nexperiments on math and commonsense reasoning tasks, where Format-Adapter\nachieves a 4.3% performance improvement on average over previous works,\ndemonstrating the effectiveness.", "AI": {"tldr": "Format-Adapter improves reasoning in LLMs by generating and selecting task-specific formats, reducing human labeling costs and boosting performance by 4.3%.", "motivation": "To address the inefficiency and unsuitability of human-labeled reasoning formats in LLMs, which are costly and not universally applicable.", "method": "Proposes measuring reasoning errors, then introduces Format-Adapter to generate and select optimal formats using LLMs, minimizing these errors.", "result": "Achieves a 4.3% average performance improvement on math and commonsense reasoning tasks.", "conclusion": "Format-Adapter effectively enhances reasoning consistency and performance in LLMs by automating format selection."}}
{"id": "2506.24074", "pdf": "https://arxiv.org/pdf/2506.24074", "abs": "https://arxiv.org/abs/2506.24074", "authors": ["Mayank V. Golhar", "Lucas Sebastian Galeano Fretes", "Loren Ayers", "Venkata S. Akshintala", "Taylor L. Bobrow", "Nicholas J. Durr"], "title": "C3VDv2 -- Colonoscopy 3D video dataset with enhanced realism", "categories": ["eess.IV", "cs.CV"], "comment": "19 pages, 7 figures", "summary": "Computer vision techniques have the potential to improve the diagnostic\nperformance of colonoscopy, but the lack of 3D colonoscopy datasets for\ntraining and validation hinders their development. This paper introduces\nC3VDv2, the second version (v2) of the high-definition Colonoscopy 3D Video\nDataset, featuring enhanced realism designed to facilitate the quantitative\nevaluation of 3D colon reconstruction algorithms. 192 video sequences were\ncaptured by imaging 60 unique, high-fidelity silicone colon phantom segments.\nGround truth depth, surface normals, optical flow, occlusion,\nsix-degree-of-freedom pose, coverage maps, and 3D models are provided for 169\ncolonoscopy videos. Eight simulated screening colonoscopy videos acquired by a\ngastroenterologist are provided with ground truth poses. The dataset includes\n15 videos featuring colon deformations for qualitative assessment. C3VDv2\nemulates diverse and challenging scenarios for 3D reconstruction algorithms,\nincluding fecal debris, mucous pools, blood, debris obscuring the colonoscope\nlens, en-face views, and fast camera motion. The enhanced realism of C3VDv2\nwill allow for more robust and representative development and evaluation of 3D\nreconstruction algorithms.", "AI": {"tldr": "C3VDv2 is an enhanced 3D colonoscopy dataset designed to improve the development and evaluation of 3D reconstruction algorithms by providing realistic and diverse scenarios.", "motivation": "The lack of 3D colonoscopy datasets hinders the development of computer vision techniques for colonoscopy diagnostics.", "method": "The dataset includes 192 video sequences from silicone colon phantoms, with ground truth data like depth, surface normals, and 3D models. It also features simulated colonoscopy videos and deformation cases.", "result": "C3VDv2 offers diverse and challenging scenarios (e.g., fecal debris, fast camera motion) for robust algorithm testing.", "conclusion": "The dataset's enhanced realism supports more accurate development and evaluation of 3D reconstruction algorithms for colonoscopy."}}
{"id": "2506.23703", "pdf": "https://arxiv.org/pdf/2506.23703", "abs": "https://arxiv.org/abs/2506.23703", "authors": ["Lars Ullrich", "Walter Zimmer", "Ross Greer", "Knut Graichen", "Alois C. Knoll", "Mohan Trivedi"], "title": "A New Perspective On AI Safety Through Control Theory Methodologies", "categories": ["cs.AI"], "comment": "Accepted to be published as part of the 2025 IEEE Open Journal of\n  Intelligent Transportation Systems (OJ-ITS)", "summary": "While artificial intelligence (AI) is advancing rapidly and mastering\nincreasingly complex problems with astonishing performance, the safety\nassurance of such systems is a major concern. Particularly in the context of\nsafety-critical, real-world cyber-physical systems, AI promises to achieve a\nnew level of autonomy but is hampered by a lack of safety assurance. While\ndata-driven control takes up recent developments in AI to improve control\nsystems, control theory in general could be leveraged to improve AI safety.\nTherefore, this article outlines a new perspective on AI safety based on an\ninterdisciplinary interpretation of the underlying data-generation process and\nthe respective abstraction by AI systems in a system theory-inspired and system\nanalysis-driven manner. In this context, the new perspective, also referred to\nas data control, aims to stimulate AI engineering to take advantage of existing\nsafety analysis and assurance in an interdisciplinary way to drive the paradigm\nof data control. Following a top-down approach, a generic foundation for safety\nanalysis and assurance is outlined at an abstract level that can be refined for\nspecific AI systems and applications and is prepared for future innovation.", "AI": {"tldr": "The paper proposes a new interdisciplinary approach, 'data control,' to enhance AI safety by combining AI advancements with control theory and system analysis.", "motivation": "AI's rapid advancement lacks sufficient safety assurance, especially in safety-critical systems, necessitating a new perspective to integrate AI and control theory for improved safety.", "method": "The article introduces 'data control,' a system theory-inspired approach that leverages interdisciplinary insights from AI and control theory to analyze and assure safety in AI systems.", "result": "A generic foundation for safety analysis and assurance is outlined, adaptable for specific AI systems and future innovations.", "conclusion": "The 'data control' perspective aims to bridge AI engineering and safety assurance, fostering interdisciplinary collaboration to enhance AI safety."}}
{"id": "2506.22848", "pdf": "https://arxiv.org/pdf/2506.22848", "abs": "https://arxiv.org/abs/2506.22848", "authors": ["Shengcai Liu", "Hui Ou-yang", "Zhiyuan Wang", "Cheng Chen", "Qijun Cai", "Yew-Soon Ong", "Ke Tang"], "title": "Scalable Structure Learning of Bayesian Networks by Learning Algorithm Ensembles", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Learning the structure of Bayesian networks (BNs) from data is challenging,\nespecially for datasets involving a large number of variables. The recently\nproposed divide-and-conquer (D\\&D) strategies present a promising approach for\nlearning large BNs. However, they still face a main issue of unstable learning\naccuracy across subproblems. In this work, we introduce the idea of employing\nstructure learning ensemble (SLE), which combines multiple BN structure\nlearning algorithms, to consistently achieve high learning accuracy. We further\npropose an automatic approach called Auto-SLE for learning near-optimal SLEs,\naddressing the challenge of manually designing high-quality SLEs. The learned\nSLE is then integrated into a D\\&D method. Extensive experiments firmly show\nthe superiority of our method over D\\&D methods with single BN structure\nlearning algorithm in learning large BNs, achieving accuracy improvement\nusually by 30\\%$\\sim$225\\% on datasets involving 10,000 variables. Furthermore,\nour method generalizes well to datasets with many more (e.g., 30000) variables\nand different network characteristics than those present in the training data\nfor learning the SLE. These results indicate the significant potential of\nemploying (automatic learning of) SLEs for scalable BN structure learning.", "AI": {"tldr": "The paper proposes an automatic approach (Auto-SLE) to improve the accuracy of learning large Bayesian networks (BNs) by combining multiple BN structure learning algorithms into an ensemble (SLE), outperforming traditional divide-and-conquer methods.", "motivation": "Learning large BNs is challenging, and existing divide-and-conquer methods suffer from unstable accuracy across subproblems.", "method": "Introduces SLE to combine multiple BN learning algorithms and proposes Auto-SLE for automatic, near-optimal SLE design, integrating it into a divide-and-conquer framework.", "result": "Achieves 30%\u2013225% accuracy improvement on datasets with 10,000 variables and generalizes well to larger datasets (e.g., 30,000 variables).", "conclusion": "SLEs, especially when automatically learned, show significant potential for scalable and accurate BN structure learning."}}
{"id": "2506.22736", "pdf": "https://arxiv.org/pdf/2506.22736", "abs": "https://arxiv.org/abs/2506.22736", "authors": ["Dayong Su", "Yafei Zhang", "Huafeng Li", "Jinxing Li", "Yu Liu"], "title": "UniFuse: A Unified All-in-One Framework for Multi-Modal Medical Image Fusion Under Diverse Degradations and Misalignments", "categories": ["cs.CV"], "comment": "Accepted by ICCV2025", "summary": "Current multimodal medical image fusion typically assumes that source images\nare of high quality and perfectly aligned at the pixel level. Its effectiveness\nheavily relies on these conditions and often deteriorates when handling\nmisaligned or degraded medical images. To address this, we propose UniFuse, a\ngeneral fusion framework. By embedding a degradation-aware prompt learning\nmodule, UniFuse seamlessly integrates multi-directional information from input\nimages and correlates cross-modal alignment with restoration, enabling joint\noptimization of both tasks within a unified framework. Additionally, we design\nan Omni Unified Feature Representation scheme, which leverages Spatial Mamba to\nencode multi-directional features and mitigate modality differences in feature\nalignment. To enable simultaneous restoration and fusion within an All-in-One\nconfiguration, we propose a Universal Feature Restoration & Fusion module,\nincorporating the Adaptive LoRA Synergistic Network (ALSN) based on LoRA\nprinciples. By leveraging ALSN's adaptive feature representation along with\ndegradation-type guidance, we enable joint restoration and fusion within a\nsingle-stage framework. Compared to staged approaches, UniFuse unifies\nalignment, restoration, and fusion within a single framework. Experimental\nresults across multiple datasets demonstrate the method's effectiveness and\nsignificant advantages over existing approaches.", "AI": {"tldr": "UniFuse is a unified framework for multimodal medical image fusion that handles misaligned or degraded images by integrating alignment, restoration, and fusion in a single stage.", "motivation": "Current fusion methods rely on high-quality, perfectly aligned images, limiting their effectiveness with misaligned or degraded inputs.", "method": "UniFuse uses degradation-aware prompt learning, Omni Unified Feature Representation with Spatial Mamba, and a Universal Feature Restoration & Fusion module with ALSN.", "result": "Experiments show UniFuse outperforms existing methods in handling misaligned or degraded images.", "conclusion": "UniFuse successfully unifies alignment, restoration, and fusion, offering a robust solution for multimodal medical image fusion."}}
{"id": "2506.23136", "pdf": "https://arxiv.org/pdf/2506.23136", "abs": "https://arxiv.org/abs/2506.23136", "authors": ["Shadman Sobhan", "Mohammad Ariful Haque"], "title": "LLM-Assisted Question-Answering on Technical Documents Using Structured Data-Aware Retrieval Augmented Generation", "categories": ["cs.CL"], "comment": "29 Pages, 11 Tables", "summary": "Large Language Models (LLMs) are capable of natural language understanding\nand generation. But they face challenges such as hallucination and outdated\nknowledge. Fine-tuning is one possible solution, but it is resource-intensive\nand must be repeated with every data update. Retrieval-Augmented Generation\n(RAG) offers an efficient solution by allowing LLMs to access external\nknowledge sources. However, traditional RAG pipelines struggle with retrieving\ninformation from complex technical documents with structured data such as\ntables and images. In this work, we propose a RAG pipeline, capable of handling\ntables and images in documents, for technical documents that support both\nscanned and searchable formats. Its retrieval process combines vector\nsimilarity search with a fine-tuned reranker based on Gemma-2-9b-it. The\nreranker is trained using RAFT (Retrieval-Augmented Fine-Tuning) on a custom\ndataset designed to improve context identification for question answering. Our\nevaluation demonstrates that the proposed pipeline achieves a high faithfulness\nscore of 94% (RAGas) and 96% (DeepEval), and an answer relevancy score of 87%\n(RAGas) and 93% (DeepEval). Comparative analysis demonstrates that the proposed\narchitecture is superior to general RAG pipelines in terms of table-based\nquestions and handling questions outside context.", "AI": {"tldr": "A RAG pipeline for technical documents improves retrieval of structured data (tables, images) and outperforms general RAG methods in faithfulness and relevancy.", "motivation": "Address challenges of LLMs (hallucination, outdated knowledge) and limitations of traditional RAG with structured data.", "method": "Proposes a RAG pipeline combining vector similarity search and a fine-tuned reranker (Gemma-2-9b-it) trained with RAFT on a custom dataset.", "result": "Achieves high faithfulness (94-96%) and relevancy (87-93%) scores, excelling in table-based and out-of-context questions.", "conclusion": "The pipeline is effective for technical documents, outperforming general RAG methods."}}
{"id": "2506.22456", "pdf": "https://arxiv.org/pdf/2506.22456", "abs": "https://arxiv.org/abs/2506.22456", "authors": ["Rahul Gulia", "Amlan Ganguly", "Andres Kwasinski", "Michael E. Kuhl", "Ehsan Rashedi", "Clark Hochgraf"], "title": "WISVA: Generative AI for 5G Network Optimization in Smart Warehouses", "categories": ["eess.SP", "eess.IV"], "comment": null, "summary": "The next decade will usher in a profound transformation of wireless\ncommunication, driven by the ever-increasing demand for data-intensive\napplications and the rapid adoption of emerging technologies. To fully unlock\nthe potential of 5G and beyond, substantial advancements are required in signal\nprocessing techniques, innovative network architectures, and efficient spectrum\nutilization strategies. These advancements facilitate seamless integration of\nemerging technologies, driving industrial digital transformation and\nconnectivity. This paper introduces a novel Variational Autoencoder (VAE)-based\nframework, Wireless Infrastructure for Smart Warehouses using VAE (WISVA),\ndesigned for accurate indoor radio propagation modeling in automated Industry\n4.0 environments such as warehouses and factory floors operating within 5G\nwireless bands. The research delves into the meticulous creation of training\ndata tensors, capturing complex electromagnetic (EM) wave behaviors influenced\nby diverse obstacles, and outlines the architecture and training methodology of\nthe proposed VAE model. The model's robustness and adaptability are showcased\nthrough its ability to predict signal-to-interference-plus-noise ratio (SINR)\nheatmaps across various scenarios, including denoising tasks, validation\ndatasets, extrapolation to unseen configurations, and previously unencountered\nwarehouse layouts. Compelling reconstruction error heatmaps are presented,\nhighlighting the superior accuracy of WISVA compared to traditional autoencoder\nmodels. The paper also analyzes the model's performance in handling complex\nsmart warehouse environments, demonstrating its potential as a key enabler for\noptimizing wireless infrastructure in Industry 4.0.", "AI": {"tldr": "The paper introduces WISVA, a VAE-based framework for indoor radio propagation modeling in 5G-enabled smart warehouses, showcasing superior accuracy in predicting SINR heatmaps and optimizing wireless infrastructure for Industry 4.0.", "motivation": "The increasing demand for data-intensive applications and emerging technologies in 5G and beyond necessitates advancements in signal processing and network architectures to support industrial digital transformation.", "method": "The paper proposes a VAE-based framework (WISVA) for modeling indoor radio propagation, including training data tensor creation and model architecture. It evaluates the model's robustness in predicting SINR heatmaps across various scenarios.", "result": "WISVA demonstrates superior accuracy in predicting SINR heatmaps and handling complex warehouse environments, outperforming traditional autoencoder models.", "conclusion": "WISVA is a promising solution for optimizing wireless infrastructure in Industry 4.0, with potential applications in smart warehouses and factory floors."}}
{"id": "2506.23706", "pdf": "https://arxiv.org/pdf/2506.23706", "abs": "https://arxiv.org/abs/2506.23706", "authors": ["Christoph Schnabl", "Daniel Hugenroth", "Bill Marino", "Alastair R. Beresford"], "title": "Attestable Audits: Verifiable AI Safety Benchmarks Using Trusted Execution Environments", "categories": ["cs.AI", "cs.CL", "cs.CR"], "comment": "ICML 2024 Workshop TAIG", "summary": "Benchmarks are important measures to evaluate safety and compliance of AI\nmodels at scale. However, they typically do not offer verifiable results and\nlack confidentiality for model IP and benchmark datasets. We propose Attestable\nAudits, which run inside Trusted Execution Environments and enable users to\nverify interaction with a compliant AI model. Our work protects sensitive data\neven when model provider and auditor do not trust each other. This addresses\nverification challenges raised in recent AI governance frameworks. We build a\nprototype demonstrating feasibility on typical audit benchmarks against\nLlama-3.1.", "AI": {"tldr": "Attestable Audits use Trusted Execution Environments to verify AI model compliance while protecting sensitive data, addressing gaps in current benchmarks.", "motivation": "Current benchmarks lack verifiable results and confidentiality for model IP and datasets, raising challenges in AI governance.", "method": "Proposes Attestable Audits running in Trusted Execution Environments to verify interactions with compliant AI models.", "result": "A prototype demonstrates feasibility on audit benchmarks against Llama-3.1, protecting data even with untrusted parties.", "conclusion": "Attestable Audits offer a solution for verifiable, confidential AI model compliance checks."}}
{"id": "2506.22895", "pdf": "https://arxiv.org/pdf/2506.22895", "abs": "https://arxiv.org/abs/2506.22895", "authors": ["Xinyu Chen", "Vassilis Digalakis Jr", "Lijun Ding", "Dingyi Zhuang", "Jinhua Zhao"], "title": "Interpretable Time Series Autoregression for Periodicity Quantification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series autoregression is a classical statistical model for capturing\nauto-correlations and identifying temporal patterns such as periodicity and\nseasonality. In this work, we propose a novel sparse autoregression framework\nfrom an interpretable machine learning perspective and the model\ninterpretability for periodicity quantification is reinforced by $\\ell_0$-norm\ninduced sparsity constraints. On the time-varying time series data, we\nreformulate the sparse autoregression and convert the involved optimization\nproblem into a mixed-integer optimization (MIO). To accelerate it, we develop a\nsubspace pursuit based decision variable pruning (DVP) strategy to reduce the\nsearch space. On the multidimensional time series that involves complicated\nspatial and temporal dimensions, we propose a spatially- and time-varying\nsparse autoregression model and resolve the corresponding MIO problem by\ndeveloping a two-stage optimization scheme. In particular, the proposed scheme\nmakes the model scalable to large problems even with millions of decision\nvariables. Empirically, we conduct extensive experiments to evaluate the\nproposed models on real-world time series data. First, we demonstrate that the\nMIO solver can be drastically accelerated through the DVP strategy, while\nmaintaining the same solution quality as a full MIO solver. Applying the\ntime-varying sparse autoregression model to ridesharing trip data, we uncover\nboth daily and weekly periodicities and reveal long-term changes in regularity\nof human mobility. Second, we demonstrate the spatial patterns of yearly\nseasonality in climate variable time series such as temperature and\nprecipitation across the past four decades, and our model allows to discover\ndynamic climate patterns and identify climate phenomena such as El Nino in sea\nsurface temperature.", "AI": {"tldr": "A novel sparse autoregression framework is proposed for interpretable periodicity quantification in time series, using \u2113\u2080-norm sparsity and mixed-integer optimization (MIO) with a subspace pursuit strategy for scalability.", "motivation": "To enhance interpretability and scalability in time series autoregression, especially for capturing periodicity and seasonality in time-varying and multidimensional data.", "method": "Proposes sparse autoregression with \u2113\u2080-norm constraints, reformulates it as MIO, and introduces a subspace pursuit-based decision variable pruning (DVP) strategy. For multidimensional data, a two-stage optimization scheme is developed.", "result": "The DVP strategy accelerates MIO without compromising solution quality. Applied to ridesharing and climate data, it uncovers periodicities and dynamic patterns like El Ni\u00f1o.", "conclusion": "The framework effectively balances interpretability and scalability, revealing meaningful temporal and spatial patterns in real-world time series."}}
{"id": "2506.22749", "pdf": "https://arxiv.org/pdf/2506.22749", "abs": "https://arxiv.org/abs/2506.22749", "authors": ["Yun Zhang", "Feifan Chen", "Na Li", "Zhiwei Guo", "Xu Wang", "Fen Miao", "Sam Kwong"], "title": "Deep Learning based Joint Geometry and Attribute Up-sampling for Large-Scale Colored Point Clouds", "categories": ["cs.CV"], "comment": null, "summary": "Colored point cloud, which includes geometry and attribute components, is a\nmainstream representation enabling realistic and immersive 3D applications. To\ngenerate large-scale and denser colored point clouds, we propose a deep\nlearning-based Joint Geometry and Attribute Up-sampling (JGAU) method that\nlearns to model both geometry and attribute patterns while leveraging spatial\nattribute correlations. First, we establish and release a large-scale dataset\nfor colored point cloud up-sampling called SYSU-PCUD, containing 121\nlarge-scale colored point clouds with diverse geometry and attribute\ncomplexities across six categories and four sampling rates. Second, to improve\nthe quality of up-sampled point clouds, we propose a deep learning-based JGAU\nframework that jointly up-samples geometry and attributes. It consists of a\ngeometry up-sampling network and an attribute up-sampling network, where the\nlatter leverages the up-sampled auxiliary geometry to model neighborhood\ncorrelations of the attributes. Third, we propose two coarse attribute\nup-sampling methods, Geometric Distance Weighted Attribute Interpolation\n(GDWAI) and Deep Learning-based Attribute Interpolation (DLAI), to generate\ncoarse up-sampled attributes for each point. Then, an attribute enhancement\nmodule is introduced to refine these up-sampled attributes and produce\nhigh-quality point clouds by further exploiting intrinsic attribute and\ngeometry patterns. Extensive experiments show that the Peak Signal-to-Noise\nRatio (PSNR) achieved by the proposed JGAU method is 33.90 decibels, 32.10\ndecibels, 31.10 decibels, and 30.39 decibels for up-sampling rates of 4 times,\n8 times, 12 times, and 16 times, respectively. Compared to state-of-the-art\nmethods, JGAU achieves average PSNR gains of 2.32 decibels, 2.47 decibels, 2.28\ndecibels, and 2.11 decibels at these four up-sampling rates, demonstrating\nsignificant improvement.", "AI": {"tldr": "A deep learning-based Joint Geometry and Attribute Up-sampling (JGAU) method is proposed for generating high-quality colored point clouds by leveraging spatial attribute correlations and a new dataset, SYSU-PCUD.", "motivation": "To enhance the quality and scalability of colored point clouds for realistic 3D applications by addressing geometry and attribute up-sampling challenges.", "method": "Proposes JGAU framework with geometry and attribute up-sampling networks, coarse attribute up-sampling methods (GDWAI and DLAI), and an attribute enhancement module.", "result": "Achieves PSNR gains of 2.11-2.47 decibels over state-of-the-art methods at various up-sampling rates.", "conclusion": "JGAU significantly improves colored point cloud quality, demonstrating its effectiveness for large-scale and dense point cloud generation."}}
{"id": "2506.23137", "pdf": "https://arxiv.org/pdf/2506.23137", "abs": "https://arxiv.org/abs/2506.23137", "authors": ["Siyuan Li", "Ruitong Liu", "Yan Wen", "Te Sun"], "title": "Flow-Modulated Scoring for Semantic-Aware Knowledge Graph Completion", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages", "summary": "Effective modeling of multifaceted relations is pivotal for Knowledge Graph\nCompletion (KGC). However, a majority of existing approaches are predicated on\nstatic, embedding-based scoring, exhibiting inherent limitations in capturing\ncontextual dependencies and relational dynamics. Addressing this gap, we\npropose the Flow-Modulated Scoring (FMS) framework. FMS comprises two principal\ncomponents: (1) a semantic context learning module that encodes\ncontext-sensitive entity representations, and (2) a conditional flow-matching\nmodule designed to learn the dynamic transformation from a head to a tail\nembedding, governed by the aforementioned context. The resultant predictive\nvector field, representing the context-informed relational path, serves to\ndynamically refine the initial static score of an entity pair. Through this\nsynergy of context-aware static representations and conditioned dynamic\ninformation, FMS facilitates a more profound modeling of relational semantics.\nComprehensive evaluations on several standard benchmarks demonstrate that our\nproposed method surpasses prior state-of-the-art results.", "AI": {"tldr": "The paper introduces Flow-Modulated Scoring (FMS) for Knowledge Graph Completion, combining static embeddings with dynamic context-aware transformations to improve relational modeling.", "motivation": "Existing KGC methods rely on static embeddings, limiting their ability to capture contextual dependencies and relational dynamics.", "method": "FMS uses a semantic context learning module for context-sensitive entity representations and a conditional flow-matching module for dynamic embedding transformations.", "result": "FMS outperforms state-of-the-art methods on standard benchmarks.", "conclusion": "FMS enhances relational semantics by integrating static and dynamic information, achieving superior performance in KGC."}}
{"id": "2506.22902", "pdf": "https://arxiv.org/pdf/2506.22902", "abs": "https://arxiv.org/abs/2506.22902", "authors": ["Yiling Xu", "Yujie Zhang", "Shuting Xia", "Kaifa Yang", "He Huang", "Ziyu Shan", "Wenjie Huang", "Qi Yang", "Le Yang"], "title": "Point Cloud Compression and Objective Quality Assessment: A Survey", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "The rapid growth of 3D point cloud data, driven by applications in autonomous\ndriving, robotics, and immersive environments, has led to criticals demand for\nefficient compression and quality assessment techniques. Unlike traditional 2D\nmedia, point clouds present unique challenges due to their irregular structure,\nhigh data volume, and complex attributes. This paper provides a comprehensive\nsurvey of recent advances in point cloud compression (PCC) and point cloud\nquality assessment (PCQA), emphasizing their significance for real-time and\nperceptually relevant applications. We analyze a wide range of handcrafted and\nlearning-based PCC algorithms, along with objective PCQA metrics. By\nbenchmarking representative methods on emerging datasets, we offer detailed\ncomparisons and practical insights into their strengths and limitations.\nDespite notable progress, challenges such as enhancing visual fidelity,\nreducing latency, and supporting multimodal data remain. This survey outlines\nfuture directions, including hybrid compression frameworks and advanced feature\nextraction strategies, to enable more efficient, immersive, and intelligent 3D\napplications.", "AI": {"tldr": "A survey of recent advances in point cloud compression (PCC) and quality assessment (PCQA), highlighting challenges and future directions for efficient 3D applications.", "motivation": "The surge in 3D point cloud data necessitates efficient compression and quality assessment due to its irregular structure and high volume, especially for real-time and perceptual applications.", "method": "Analyzes handcrafted and learning-based PCC algorithms and objective PCQA metrics, benchmarking them on emerging datasets.", "result": "Provides detailed comparisons and insights into the strengths and limitations of current methods, identifying gaps like visual fidelity and latency reduction.", "conclusion": "Future directions include hybrid compression frameworks and advanced feature extraction to improve efficiency and intelligence in 3D applications."}}
{"id": "2506.23773", "pdf": "https://arxiv.org/pdf/2506.23773", "abs": "https://arxiv.org/abs/2506.23773", "authors": ["Stefano M. Nicoletti", "Mari\u00eblle Stoelinga"], "title": "BayesL: Towards a Logical Framework for Bayesian Networks", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "We introduce BayesL, a novel logical framework for specifying, querying, and\nverifying the behaviour of Bayesian networks (BNs). BayesL (pronounced \"Basil\")\nis a structured language that allows for the creation of queries over BNs. It\nfacilitates versatile reasoning concerning causal and evidence-based\nrelationships, and permits comprehensive what-if scenario evaluations without\nthe need for manual modifications to the model.", "AI": {"tldr": "BayesL is a new logical framework for querying and verifying Bayesian networks, enabling versatile reasoning and what-if scenarios without manual model changes.", "motivation": "To simplify and enhance the process of querying and verifying Bayesian networks by providing a structured language.", "method": "Introduces BayesL, a logical framework for specifying, querying, and verifying Bayesian networks.", "result": "BayesL allows versatile reasoning and what-if evaluations without manual model adjustments.", "conclusion": "BayesL offers a powerful tool for analyzing Bayesian networks efficiently."}}
{"id": "2506.22901", "pdf": "https://arxiv.org/pdf/2506.22901", "abs": "https://arxiv.org/abs/2506.22901", "authors": ["Sina Tabakhi", "Haiping Lu"], "title": "Missing-Modality-Aware Graph Neural Network for Cancer Classification", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "q-bio.GN"], "comment": "15 pages, 7 figures", "summary": "A key challenge in learning from multimodal biological data is missing\nmodalities, where all data from some modalities are missing for some patients.\nCurrent fusion methods address this by excluding patients with missing\nmodalities, imputing missing modalities, or making predictions directly with\npartial modalities. However, they often struggle with diverse missing-modality\npatterns and the exponential growth of the number of such patterns as the\nnumber of modalities increases. To address these limitations, we propose MAGNET\n(Missing-modality-Aware Graph neural NETwork) for direct prediction with\npartial modalities, which introduces a patient-modality multi-head attention\nmechanism to fuse lower-dimensional modality embeddings based on their\nimportance and missingness. MAGNET's complexity increases linearly with the\nnumber of modalities while adapting to missing-pattern variability. To generate\npredictions, MAGNET further constructs a patient graph with fused multimodal\nembeddings as node features and the connectivity determined by the modality\nmissingness, followed by a conventional graph neural network. Experiments on\nthree public multiomics datasets for cancer classification, with real-world\ninstead of artificial missingness, show that MAGNET outperforms the\nstate-of-the-art fusion methods. The data and code are available at\nhttps://github.com/SinaTabakhi/MAGNET.", "AI": {"tldr": "MAGNET, a Missing-modality-Aware Graph neural NETwork, addresses missing modalities in multimodal biological data by using a patient-modality attention mechanism and graph neural networks, outperforming existing methods.", "motivation": "Handling missing modalities in multimodal biological data is challenging due to diverse missing patterns and exponential growth of patterns with increasing modalities.", "method": "MAGNET uses a patient-modality multi-head attention mechanism to fuse lower-dimensional embeddings and constructs a patient graph for predictions with a graph neural network.", "result": "MAGNET outperforms state-of-the-art fusion methods on three public multiomics datasets for cancer classification with real-world missingness.", "conclusion": "MAGNET effectively handles missing modalities with linear complexity and adapts to missing-pattern variability, offering a robust solution for multimodal data fusion."}}
{"id": "2506.22753", "pdf": "https://arxiv.org/pdf/2506.22753", "abs": "https://arxiv.org/abs/2506.22753", "authors": ["Jianing Zhang", "Jiayi Zhu", "Feiyu Ji", "Xiaokang Yang", "Xiaoyun Yuan"], "title": "Degradation-Modeled Multipath Diffusion for Tunable Metalens Photography", "categories": ["cs.CV"], "comment": null, "summary": "Metalenses offer significant potential for ultra-compact computational\nimaging but face challenges from complex optical degradation and computational\nrestoration difficulties. Existing methods typically rely on precise optical\ncalibration or massive paired datasets, which are non-trivial for real-world\nimaging systems. Furthermore, a lack of control over the inference process\noften results in undesirable hallucinated artifacts. We introduce\nDegradation-Modeled Multipath Diffusion for tunable metalens photography,\nleveraging powerful natural image priors from pretrained models instead of\nlarge datasets. Our framework uses positive, neutral, and negative-prompt paths\nto balance high-frequency detail generation, structural fidelity, and\nsuppression of metalens-specific degradation, alongside \\textit{pseudo} data\naugmentation. A tunable decoder enables controlled trade-offs between fidelity\nand perceptual quality. Additionally, a spatially varying degradation-aware\nattention (SVDA) module adaptively models complex optical and sensor-induced\ndegradation. Finally, we design and build a millimeter-scale MetaCamera for\nreal-world validation. Extensive results show that our approach outperforms\nstate-of-the-art methods, achieving high-fidelity and sharp image\nreconstruction. More materials: https://dmdiff.github.io/.", "AI": {"tldr": "The paper introduces Degradation-Modeled Multipath Diffusion (DMD) for metalens photography, leveraging pretrained models and tunable paths to address optical degradation and computational challenges without relying on large datasets.", "motivation": "Metalenses face issues like optical degradation and computational restoration difficulties, often requiring precise calibration or massive datasets, which are impractical for real-world systems.", "method": "The proposed framework uses multipath diffusion (positive, neutral, negative-prompt paths) and pseudo data augmentation, with a tunable decoder and SVDA module for degradation-aware attention. A MetaCamera is built for validation.", "result": "The approach outperforms state-of-the-art methods, achieving high-fidelity and sharp image reconstruction.", "conclusion": "DMD offers a practical solution for metalens photography, balancing fidelity and perceptual quality while avoiding dataset dependency."}}
{"id": "2506.23139", "pdf": "https://arxiv.org/pdf/2506.23139", "abs": "https://arxiv.org/abs/2506.23139", "authors": ["Prafulla Kumar Choubey", "Xiangyu Peng", "Shilpa Bhagavath", "Kung-Hsiang Huang", "Caiming Xiong", "Chien-Sheng Wu"], "title": "Benchmarking Deep Search over Heterogeneous Enterprise Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We present a new benchmark for evaluating Deep Search--a realistic and\ncomplex form of retrieval-augmented generation (RAG) that requires\nsource-aware, multi-hop reasoning over diverse, sparsed, but related sources.\nThese include documents, meeting transcripts, Slack messages, GitHub, and URLs,\nwhich vary in structure and often contain human-to-human interactions. We build\nit using a synthetic data pipeline that simulates business workflows across\nproduct planning, development, and support stages, generating interconnected\ncontent with realistic noise and multi-hop questions with guaranteed\nground-truth answers. We release our benchmark with both answerable and\nunanswerable queries, and retrieval pool of 39,190 enterprise artifacts,\nenabling fine-grained evaluation of long-context LLM and RAG systems. Our\nexperiments reveal that even the best-performing agentic RAG methods achieve an\naverage performance score of 32.96 on our benchmark. With further analysis, we\nhighlight retrieval as the main bottleneck: existing methods struggle to\nconduct deep searches and retrieve all necessary evidence. Consequently, they\noften reason over partial context, leading to significant performance\ndegradation.", "AI": {"tldr": "A new benchmark for Deep Search evaluates RAG systems using synthetic data simulating business workflows, revealing retrieval as the main bottleneck.", "motivation": "To address the need for evaluating complex RAG systems that require multi-hop reasoning over diverse, noisy sources like documents, transcripts, and URLs.", "method": "Built a synthetic data pipeline simulating business workflows, generating interconnected content with realistic noise and multi-hop questions.", "result": "Best-performing RAG methods scored 32.96 on the benchmark, with retrieval identified as the main bottleneck.", "conclusion": "Existing RAG methods struggle with deep searches, leading to performance degradation due to partial context retrieval."}}
{"id": "2506.22929", "pdf": "https://arxiv.org/pdf/2506.22929", "abs": "https://arxiv.org/abs/2506.22929", "authors": ["Chen Zhang"], "title": "Mathematical Computation on High-dimensional Data via Array Programming and Parallel Acceleration", "categories": ["cs.LG", "cs.AI", "eess.IV", "eess.SP"], "comment": null, "summary": "While deep learning excels in natural image and language processing, its\napplication to high-dimensional data faces computational challenges due to the\ndimensionality curse. Current large-scale data tools focus on business-oriented\ndescriptive statistics, lacking mathematical statistics support for advanced\nanalysis. We propose a parallel computation architecture based on space\ncompleteness, decomposing high-dimensional data into dimension-independent\nstructures for distributed processing. This framework enables seamless\nintegration of data mining and parallel-optimized machine learning methods,\nsupporting scientific computations across diverse data types like medical and\nnatural images within a unified system.", "AI": {"tldr": "A parallel computation architecture is proposed to handle high-dimensional data by decomposing it into dimension-independent structures, enabling efficient distributed processing and integration of advanced analysis methods.", "motivation": "Deep learning struggles with high-dimensional data due to computational challenges, and existing tools lack support for advanced mathematical statistics.", "method": "A space-completeness-based parallel computation architecture decomposes high-dimensional data into dimension-independent structures for distributed processing.", "result": "The framework supports seamless integration of data mining and parallel-optimized machine learning, applicable to diverse data types like medical and natural images.", "conclusion": "The proposed architecture addresses the dimensionality curse, enabling efficient analysis of high-dimensional data within a unified system."}}
{"id": "2506.23784", "pdf": "https://arxiv.org/pdf/2506.23784", "abs": "https://arxiv.org/abs/2506.23784", "authors": ["Parosh Aziz Abdulla", "Mohamed Faouzi Atig", "Julie Cailler", "Chencheng Liang", "Philipp R\u00fcmmer"], "title": "When GNNs Met a Word Equations Solver: Learning to Rank Equations (Extended Technical Report)", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Nielsen transformation is a standard approach for solving word equations: by\nrepeatedly splitting equations and applying simplification steps, equations are\nrewritten until a solution is reached. When solving a conjunction of word\nequations in this way, the performance of the solver will depend considerably\non the order in which equations are processed. In this work, the use of Graph\nNeural Networks (GNNs) for ranking word equations before and during the solving\nprocess is explored. For this, a novel graph-based representation for word\nequations is presented, preserving global information across conjuncts,\nenabling the GNN to have a holistic view during ranking. To handle the variable\nnumber of conjuncts, three approaches to adapt a multi-classification task to\nthe problem of ranking equations are proposed. The training of the GNN is done\nwith the help of minimum unsatisfiable subsets (MUSes) of word equations. The\nexperimental results show that, compared to state-of-the-art string solvers,\nthe new framework solves more problems in benchmarks where each variable\nappears at most once in each equation.", "AI": {"tldr": "The paper explores using Graph Neural Networks (GNNs) to rank word equations for solving conjunctions more efficiently, introducing a novel graph-based representation and three ranking approaches.", "motivation": "The performance of solving word equations depends on the processing order, and the paper aims to improve this using GNNs.", "method": "A graph-based representation for word equations is proposed, and three approaches for ranking equations are introduced. Training uses minimum unsatisfiable subsets (MUSes).", "result": "The framework outperforms state-of-the-art solvers in benchmarks with variables appearing at most once per equation.", "conclusion": "GNN-based ranking enhances the efficiency of solving word equations, particularly in specific benchmark cases."}}
{"id": "2506.22927", "pdf": "https://arxiv.org/pdf/2506.22927", "abs": "https://arxiv.org/abs/2506.22927", "authors": ["Jaeyun Woo", "Jiseok Lee", "Brian Kenji Iwana"], "title": "Towards Time Series Generation Conditioned on Unstructured Natural Language", "categories": ["cs.LG"], "comment": null, "summary": "Generative Artificial Intelligence (AI) has rapidly become a powerful tool,\ncapable of generating various types of data, such as images and text. However,\ndespite the significant advancement of generative AI, time series generative AI\nremains underdeveloped, even though the application of time series is essential\nin finance, climate, and numerous fields. In this research, we propose a novel\nmethod of generating time series conditioned on unstructured natural language\ndescriptions. We use a diffusion model combined with a language model to\ngenerate time series from the text. Through the proposed method, we demonstrate\nthat time series generation based on natural language is possible. The proposed\nmethod can provide various applications such as custom forecasting, time series\nmanipulation, data augmentation, and transfer learning. Furthermore, we\nconstruct and propose a new public dataset for time series generation,\nconsisting of 63,010 time series-description pairs.", "AI": {"tldr": "A novel method for generating time series from natural language descriptions using a diffusion model combined with a language model, demonstrating potential applications and introducing a new public dataset.", "motivation": "Time series generative AI is underdeveloped despite its importance in fields like finance and climate, and existing methods lack the ability to generate time series from unstructured natural language.", "method": "Uses a diffusion model combined with a language model to generate time series conditioned on natural language descriptions.", "result": "Shows that time series generation from text is feasible, with applications in custom forecasting, data augmentation, and transfer learning. Introduces a new dataset of 63,010 time series-description pairs.", "conclusion": "The proposed method advances time series generative AI and opens up new applications, supported by a publicly available dataset."}}
{"id": "2506.22756", "pdf": "https://arxiv.org/pdf/2506.22756", "abs": "https://arxiv.org/abs/2506.22756", "authors": ["Tao Tang", "Likui Zhang", "Youpeng Wen", "Kaidong Zhang", "Jia-Wang Bian", "xia zhou", "Tianyi Yan", "Kun Zhan", "Peng Jia", "Hefeng Wu", "Liang Lin", "Xiaodan Liang"], "title": "RoboPearls: Editable Video Simulation for Robot Manipulation", "categories": ["cs.CV", "cs.RO"], "comment": "ICCV 2025", "summary": "The development of generalist robot manipulation policies has seen\nsignificant progress, driven by large-scale demonstration data across diverse\nenvironments. However, the high cost and inefficiency of collecting real-world\ndemonstrations hinder the scalability of data acquisition. While existing\nsimulation platforms enable controlled environments for robotic learning, the\nchallenge of bridging the sim-to-real gap remains. To address these challenges,\nwe propose RoboPearls, an editable video simulation framework for robotic\nmanipulation. Built on 3D Gaussian Splatting (3DGS), RoboPearls enables the\nconstruction of photo-realistic, view-consistent simulations from demonstration\nvideos, and supports a wide range of simulation operators, including various\nobject manipulations, powered by advanced modules like Incremental Semantic\nDistillation (ISD) and 3D regularized NNFM Loss (3D-NNFM). Moreover, by\nincorporating large language models (LLMs), RoboPearls automates the simulation\nproduction process in a user-friendly manner through flexible command\ninterpretation and execution. Furthermore, RoboPearls employs a vision-language\nmodel (VLM) to analyze robotic learning issues to close the simulation loop for\nperformance enhancement. To demonstrate the effectiveness of RoboPearls, we\nconduct extensive experiments on multiple datasets and scenes, including\nRLBench, COLOSSEUM, Ego4D, Open X-Embodiment, and a real-world robot, which\ndemonstrate our satisfactory simulation performance.", "AI": {"tldr": "RoboPearls is a video simulation framework for robotic manipulation, leveraging 3D Gaussian Splatting and LLMs to create realistic, editable simulations and automate processes.", "motivation": "High costs and inefficiencies in collecting real-world robotic demonstrations limit scalability, while existing simulators struggle with the sim-to-real gap.", "method": "Uses 3D Gaussian Splatting for photo-realistic simulations, Incremental Semantic Distillation, 3D-NNFM Loss, and integrates LLMs for automation and VLMs for performance analysis.", "result": "Demonstrated effectiveness on multiple datasets (RLBench, COLOSSEUM, etc.) and real-world robots, showing satisfactory simulation performance.", "conclusion": "RoboPearls addresses scalability and sim-to-real challenges, offering a promising solution for robotic manipulation learning."}}
{"id": "2506.23146", "pdf": "https://arxiv.org/pdf/2506.23146", "abs": "https://arxiv.org/abs/2506.23146", "authors": ["Dingzriui Wang", "Xuanliang Zhang", "Keyan Xu", "Qingfu Zhu", "Wanxiang Che", "Yang Deng"], "title": "Learning-to-Context Slope: Evaluating In-Context Learning Effectiveness Beyond Performance Illusions", "categories": ["cs.CL"], "comment": null, "summary": "In-context learning (ICL) has emerged as an effective approach to enhance the\nperformance of large language models (LLMs). However, its effectiveness varies\nsignificantly across models and tasks, posing challenges for practitioners to\ndetermine when ICL reliably improves performance. Current evaluation\napproaches, reliant on performance change after applying ICL, suffer from low\nreliability, poor attribution, and impracticality in data-insufficient\nscenarios. We propose the Learning-to-Context Slope (LCS), a novel metric that\nquantifies ICL effectiveness by modeling the slope between learning gain (loss\ndecrease from demonstrations) and contextual relevance (demonstration-input\nrelevance). LCS addresses key limitations of performance-based metrics: (1) it\ncaptures continuous loss changes even when outputs are incorrect, improving\nreliability; (2) its formulation attributes ICL failures to weak contextual\nalignment (inability to adapt inputs to demonstrations) or strong output\ncalibration (self-verification of correctness); and (3) it minimizes reliance\non labeled data via synthetic evaluation. Extensive experiments demonstrate\nthat LCS strongly correlates with performance improvements in labeled settings\nand reliably reflects true effectiveness in biased or data-scarce scenarios.\nFurther analysis reveals actionable thresholds for LCS and identifies model\ncapabilities critical to ICL success.", "AI": {"tldr": "The paper introduces the Learning-to-Context Slope (LCS) metric to evaluate in-context learning (ICL) effectiveness in LLMs, addressing reliability, attribution, and data scarcity issues.", "motivation": "Current ICL evaluation methods are unreliable, poorly attributed, and impractical in data-insufficient scenarios, necessitating a better metric.", "method": "Proposes LCS, which models the slope between learning gain and contextual relevance to quantify ICL effectiveness.", "result": "LCS reliably correlates with performance improvements, works in biased/data-scarce settings, and identifies actionable thresholds.", "conclusion": "LCS is a robust metric for evaluating ICL, offering insights into model capabilities and practical thresholds for practitioners."}}
{"id": "2506.23004", "pdf": "https://arxiv.org/pdf/2506.23004", "abs": "https://arxiv.org/abs/2506.23004", "authors": ["Vaigai Nayaki Yokar", "Hoa Le-Minh", "Xicong Li", "Wai Lok Woo", "Luis Nero Alves", "Stanislav Zvanovec", "Tran The Son", "Zabih Ghassemlooy"], "title": "A Novel Frame Identification and Synchronization Technique for Smartphone Visible Light Communication Systems Based on Convolutional Neural Networks", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "This paper proposes a novel, robust, and lightweight supervised Convolutional\nNeural Network (CNN)-based technique for frame identification and\nsynchronization, designed to enhance short-link communication performance in a\nscreen-to-camera (S2C) based visible light communication (VLC) system.\nDeveloped using Python and the TensorFlow Keras framework, the proposed CNN\nmodel was trained through three real-time experimental investigations conducted\nin Jupyter Notebook. These experiments incorporated a dataset created from\nscratch to address various real-time challenges in S2C communication, including\nblurring, cropping, and rotated images in mobility scenarios. Overhead frames\nwere introduced for synchronization, which leads to enhanced system\nperformance. The experimental results demonstrate that the proposed model\nachieves an overall accuracy of approximately 98.74%, highlighting its\neffectiveness in identifying and synchronizing frames in S2C VLC systems.", "AI": {"tldr": "A lightweight CNN-based method for frame identification and synchronization in S2C VLC systems, achieving 98.74% accuracy.", "motivation": "Enhance short-link communication performance in S2C VLC systems by addressing challenges like blurring, cropping, and rotated images.", "method": "Supervised CNN model developed in Python/TensorFlow Keras, trained with real-time experiments and a custom dataset.", "result": "Achieves 98.74% accuracy in frame identification and synchronization.", "conclusion": "The proposed CNN model is effective for S2C VLC systems, improving performance with minimal overhead."}}
{"id": "2506.23844", "pdf": "https://arxiv.org/pdf/2506.23844", "abs": "https://arxiv.org/abs/2506.23844", "authors": ["Hang Su", "Jun Luo", "Chang Liu", "Xiao Yang", "Yichi Zhang", "Yinpeng Dong", "Jun Zhu"], "title": "A Survey on Autonomy-Induced Security Risks in Large Model-Based Agents", "categories": ["cs.AI"], "comment": "18 pages", "summary": "Recent advances in large language models (LLMs) have catalyzed the rise of\nautonomous AI agents capable of perceiving, reasoning, and acting in dynamic,\nopen-ended environments. These large-model agents mark a paradigm shift from\nstatic inference systems to interactive, memory-augmented entities. While these\ncapabilities significantly expand the functional scope of AI, they also\nintroduce qualitatively novel security risks - such as memory poisoning, tool\nmisuse, reward hacking, and emergent misalignment - that extend beyond the\nthreat models of conventional systems or standalone LLMs. In this survey, we\nfirst examine the structural foundations and key capabilities that underpin\nincreasing levels of agent autonomy, including long-term memory retention,\nmodular tool use, recursive planning, and reflective reasoning. We then analyze\nthe corresponding security vulnerabilities across the agent stack, identifying\nfailure modes such as deferred decision hazards, irreversible tool chains, and\ndeceptive behaviors arising from internal state drift or value misalignment.\nThese risks are traced to architectural fragilities that emerge across\nperception, cognition, memory, and action modules. To address these challenges,\nwe systematically review recent defense strategies deployed at different\nautonomy layers, including input sanitization, memory lifecycle control,\nconstrained decision-making, structured tool invocation, and introspective\nreflection. We introduce the Reflective Risk-Aware Agent Architecture (R2A2), a\nunified cognitive framework grounded in Constrained Markov Decision Processes\n(CMDPs), which incorporates risk-aware world modeling, meta-policy adaptation,\nand joint reward-risk optimization to enable principled, proactive safety\nacross the agent's decision-making loop.", "AI": {"tldr": "The paper discusses the security risks of autonomous AI agents powered by large language models (LLMs) and proposes a framework (R2A2) to mitigate these risks.", "motivation": "The rise of autonomous AI agents introduces novel security risks beyond conventional systems, necessitating a systematic approach to address vulnerabilities.", "method": "The survey examines agent autonomy foundations, identifies security vulnerabilities, and reviews defense strategies. It introduces the R2A2 framework for risk-aware decision-making.", "result": "Key vulnerabilities include memory poisoning, tool misuse, and deceptive behaviors. R2A2 offers a unified approach to proactive safety.", "conclusion": "The R2A2 framework provides a principled solution to mitigate security risks in autonomous AI agents, ensuring safer deployment."}}
{"id": "2506.22950", "pdf": "https://arxiv.org/pdf/2506.22950", "abs": "https://arxiv.org/abs/2506.22950", "authors": ["Liangyu Wang", "Huanyi Xie", "Xinhai Wang", "Tianjin Huang", "Mengdi Li", "Di Wang"], "title": "Infinite Sampling: Efficient and Stable Grouped RL Training for Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Group-based reinforcement learning algorithms such as Group Reward Policy\nOptimization (GRPO) have proven effective for fine-tuning large language models\n(LLMs) with human feedback. However, generating and storing multiple responses\nper prompt incurs substantial memory overhead, especially as the sample group\nsize increases, limiting scalability under constrained hardware.\n  We propose Infinite Sampling, a framework that enables efficient and stable\nGRPO training by decoupling group size from GPU memory usage. It consists of:\n(1) micro sampling groups that decompose large groups into memory-feasible\nrounds; (2) continuous sampling that interleaves generation across groups to\nimprove utilization; and (3) a length-aware scheduler combining\ntoken-conditioned sequence length prediction with a two-stage plan: global\ngrouping via FPTAS and runtime refill via SJF.\n  Experiments show that our Micro Sampling Groups reduce peak memory usage by\nover 50% compared to full-group decoding (e.g., from 21.55 GB to 10.64 GB on\nQwen3-1.7B). Building on this, Infinite Sampling improves throughput by over\n25% compared to the naive micro sampling group method, reducing decoding steps\nwhile maintaining full-length completions and memory usage. Our hybrid\nscheduling ensures efficient and stable GRPO training with larger groups under\nrealistic GPU memory constraints.", "AI": {"tldr": "Infinite Sampling reduces memory overhead in GRPO for LLMs by decoupling group size from GPU usage, improving efficiency and throughput.", "motivation": "Current GRPO methods for LLMs incur high memory costs with large sample groups, limiting scalability.", "method": "Proposes Infinite Sampling: micro sampling groups, continuous sampling, and a length-aware scheduler.", "result": "Reduces peak memory by 50% and improves throughput by 25% while maintaining performance.", "conclusion": "Infinite Sampling enables efficient GRPO training under GPU constraints."}}
{"id": "2506.22762", "pdf": "https://arxiv.org/pdf/2506.22762", "abs": "https://arxiv.org/abs/2506.22762", "authors": ["Dinh Phu Tran", "Dao Duy Hung", "Daeyoung Kim"], "title": "VSRM: A Robust Mamba-Based Framework for Video Super-Resolution", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "Video super-resolution remains a major challenge in low-level vision tasks.\nTo date, CNN- and Transformer-based methods have delivered impressive results.\nHowever, CNNs are limited by local receptive fields, while Transformers\nstruggle with quadratic complexity, posing challenges for processing long\nsequences in VSR. Recently, Mamba has drawn attention for its long-sequence\nmodeling, linear complexity, and large receptive fields. In this work, we\npropose VSRM, a novel \\textbf{V}ideo \\textbf{S}uper-\\textbf{R}esolution\nframework that leverages the power of \\textbf{M}amba. VSRM introduces\nSpatial-to-Temporal Mamba and Temporal-to-Spatial Mamba blocks to extract\nlong-range spatio-temporal features and enhance receptive fields efficiently.\nTo better align adjacent frames, we propose Deformable Cross-Mamba Alignment\nmodule. This module utilizes a deformable cross-mamba mechanism to make the\ncompensation stage more dynamic and flexible, preventing feature distortions.\nFinally, we minimize the frequency domain gaps between reconstructed and\nground-truth frames by proposing a simple yet effective Frequency\nCharbonnier-like loss that better preserves high-frequency content and enhances\nvisual quality. Through extensive experiments, VSRM achieves state-of-the-art\nresults on diverse benchmarks, establishing itself as a solid foundation for\nfuture research.", "AI": {"tldr": "VSRM introduces a novel video super-resolution framework using Mamba for efficient long-range spatio-temporal feature extraction, achieving state-of-the-art results.", "motivation": "Video super-resolution faces challenges with CNNs' limited receptive fields and Transformers' quadratic complexity. Mamba's linear complexity and long-sequence modeling offer a promising alternative.", "method": "VSRM employs Spatial-to-Temporal and Temporal-to-Spatial Mamba blocks, a Deformable Cross-Mamba Alignment module, and a Frequency Charbonnier-like loss for feature alignment and quality enhancement.", "result": "VSRM achieves state-of-the-art performance on diverse benchmarks.", "conclusion": "VSRM sets a strong foundation for future research in video super-resolution by leveraging Mamba's advantages."}}
{"id": "2506.23149", "pdf": "https://arxiv.org/pdf/2506.23149", "abs": "https://arxiv.org/abs/2506.23149", "authors": ["Dingzirui Wang", "Xuanliang Zhang", "Keyan Xu", "Qingfu Zhu", "Wanxiang Che", "Yang Deng"], "title": "V-SYNTHESIS: Task-Agnostic Synthesis of Consistent and Diverse In-Context Demonstrations from Scratch via V-Entropy", "categories": ["cs.CL"], "comment": null, "summary": "High labeling cost for in-context learning (ICL) demonstrations motivates\nusing large language models (LLMs) for synthesis to reduce overhead. However,\nexisting synthesis methods are mainly task-specific or rely on pre-existing\ndemonstrations. So this paper focuses on synthesizing demonstrations from\nscratch for arbitrary tasks. A major challenge in synthesizing from scratch is\nensuring consistency with the target task, as the lack of labeling guidance\ncould lead to synthesis bias. We first propose a consistency metric called\nV-Score, which has higher performance and lower computation cost compared with\nthe metrics based on grams or embedding vectors. Furthermore, we introduce\nV-Synthesis, which leverages V-Score for proportional sampling to ensure both\nhigh consistency and diversity of synthesized demonstrations. Experimental\nresults demonstrate that V-Synthesis yields an average performance improvement\nof 2.0% compared to existing synthesis methods confirming the effectiveness of\nV-Synthesis.", "AI": {"tldr": "The paper introduces V-Synthesis, a method for synthesizing demonstrations from scratch for arbitrary tasks in in-context learning, addressing the challenge of consistency with the target task.", "motivation": "High labeling costs for in-context learning demonstrations and the limitations of existing synthesis methods motivate the need for a task-agnostic approach.", "method": "Proposes V-Score, a consistency metric, and V-Synthesis, which uses proportional sampling based on V-Score to ensure consistency and diversity.", "result": "V-Synthesis improves performance by 2.0% on average compared to existing methods.", "conclusion": "V-Synthesis is effective for synthesizing demonstrations from scratch, offering better consistency and performance."}}
{"id": "2506.23353", "pdf": "https://arxiv.org/pdf/2506.23353", "abs": "https://arxiv.org/abs/2506.23353", "authors": ["Siyuan Chai", "Xiaodong Guo", "Tong Liu"], "title": "Layer Decomposition and Morphological Reconstruction for Task-Oriented Infrared Image Enhancement", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Infrared image helps improve the perception capabilities of autonomous\ndriving in complex weather conditions such as fog, rain, and low light.\nHowever, infrared image often suffers from low contrast, especially in\nnon-heat-emitting targets like bicycles, which significantly affects the\nperformance of downstream high-level vision tasks. Furthermore, achieving\ncontrast enhancement without amplifying noise and losing important information\nremains a challenge. To address these challenges, we propose a task-oriented\ninfrared image enhancement method. Our approach consists of two key components:\nlayer decomposition and saliency information extraction. First, we design an\nlayer decomposition method for infrared images, which enhances scene details\nwhile preserving dark region features, providing more features for subsequent\nsaliency information extraction. Then, we propose a morphological\nreconstruction-based saliency extraction method that effectively extracts and\nenhances target information without amplifying noise. Our method improves the\nimage quality for object detection and semantic segmentation tasks. Extensive\nexperiments demonstrate that our approach outperforms state-of-the-art methods.", "AI": {"tldr": "A task-oriented infrared image enhancement method improves contrast and preserves details for autonomous driving in complex weather.", "motivation": "Infrared images suffer from low contrast, especially for non-heat-emitting objects, impacting high-level vision tasks like object detection and semantic segmentation.", "method": "The method involves layer decomposition to enhance details and saliency information extraction using morphological reconstruction to avoid noise amplification.", "result": "The approach outperforms state-of-the-art methods, improving image quality for downstream tasks.", "conclusion": "The proposed method effectively enhances infrared images for autonomous driving applications."}}
{"id": "2506.23908", "pdf": "https://arxiv.org/pdf/2506.23908", "abs": "https://arxiv.org/abs/2506.23908", "authors": ["Andr\u00e1s Gy\u00f6rgy", "Tor Lattimore", "Nevena Lazi\u0107", "Csaba Szepesv\u00e1ri"], "title": "Beyond Statistical Learning: Exact Learning Is Essential for General Intelligence", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Sound deductive reasoning -- the ability to derive new knowledge from\nexisting facts and rules -- is an indisputably desirable aspect of general\nintelligence. Despite the major advances of AI systems in areas such as math\nand science, especially since the introduction of transformer architectures, it\nis well-documented that even the most advanced frontier systems regularly and\nconsistently falter on easily-solvable deductive reasoning tasks. Hence, these\nsystems are unfit to fulfill the dream of achieving artificial general\nintelligence capable of sound deductive reasoning. We argue that their unsound\nbehavior is a consequence of the statistical learning approach powering their\ndevelopment. To overcome this, we contend that to achieve reliable deductive\nreasoning in learning-based AI systems, researchers must fundamentally shift\nfrom optimizing for statistical performance against distributions on reasoning\nproblems and algorithmic tasks to embracing the more ambitious exact learning\nparadigm, which demands correctness on all inputs. We argue that exact learning\nis both essential and possible, and that this ambitious objective should guide\nalgorithm design.", "AI": {"tldr": "The paper highlights the limitations of current AI systems in deductive reasoning and proposes a shift from statistical learning to exact learning for reliable reasoning.", "motivation": "Despite AI advancements, current systems fail at deductive reasoning, hindering progress toward artificial general intelligence.", "method": "Proposes a shift from statistical learning to exact learning, demanding correctness on all inputs.", "result": "Current AI systems are unsound in deductive reasoning due to statistical learning.", "conclusion": "Exact learning is essential and achievable, and should guide future AI algorithm design."}}
{"id": "2506.22984", "pdf": "https://arxiv.org/pdf/2506.22984", "abs": "https://arxiv.org/abs/2506.22984", "authors": ["Prathyush Kumar Reddy Lebaku", "Lu Gao", "Yunpeng Zhang", "Zhixia Li", "Yongxin Liu", "Tanvir Arafin"], "title": "Cybersecurity-Focused Anomaly Detection in Connected Autonomous Vehicles Using Machine Learning", "categories": ["cs.LG"], "comment": null, "summary": "Anomaly detection in connected autonomous vehicles (CAVs) is crucial for\nmaintaining safe and reliable transportation networks, as CAVs can be\nsusceptible to sensor malfunctions, cyber-attacks, and unexpected environmental\ndisruptions. This study explores an anomaly detection approach by simulating\nvehicle behavior, generating a dataset that represents typical and atypical\nvehicular interactions. The dataset includes time-series data of position,\nspeed, and acceleration for multiple connected autonomous vehicles. We utilized\nmachine learning models to effectively identify abnormal driving patterns.\nFirst, we applied a stacked Long Short-Term Memory (LSTM) model to capture\ntemporal dependencies and sequence-based anomalies. The stacked LSTM model\nprocessed the sequential data to learn standard driving behaviors.\nAdditionally, we deployed a Random Forest model to support anomaly detection by\noffering ensemble-based predictions, which enhanced model interpretability and\nperformance. The Random Forest model achieved an R2 of 0.9830, MAE of 5.746,\nand a 95th percentile anomaly threshold of 14.18, while the stacked LSTM model\nattained an R2 of 0.9998, MAE of 82.425, and a 95th percentile anomaly\nthreshold of 265.63. These results demonstrate the models' effectiveness in\naccurately predicting vehicle trajectories and detecting anomalies in\nautonomous driving scenarios.", "AI": {"tldr": "The paper proposes a machine learning approach using stacked LSTM and Random Forest models for anomaly detection in connected autonomous vehicles, achieving high accuracy in identifying abnormal driving patterns.", "motivation": "Anomaly detection is critical for CAVs due to risks like sensor malfunctions, cyber-attacks, and environmental disruptions, ensuring safe transportation networks.", "method": "Simulated vehicle behavior to create a dataset of typical and atypical interactions, then applied stacked LSTM for temporal dependencies and Random Forest for ensemble-based anomaly detection.", "result": "Random Forest achieved R2 of 0.9830 and MAE of 5.746, while stacked LSTM had R2 of 0.9998 and MAE of 82.425, showing high accuracy in anomaly detection.", "conclusion": "The models effectively detect anomalies in CAVs, demonstrating their potential for enhancing safety and reliability in autonomous driving."}}
{"id": "2506.22783", "pdf": "https://arxiv.org/pdf/2506.22783", "abs": "https://arxiv.org/abs/2506.22783", "authors": ["Oguzhan Baser", "Ahmet Ege Tanriverdi", "Sriram Vishwanath", "Sandeep P. Chinchali"], "title": "PhonemeFake: Redefining Deepfake Realism with Language-Driven Segmental Manipulation and Adaptive Bilevel Detection", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "5 pages, 3 figures, Published at Proceedings of Interspeech 2025, for\n  the dataset see https://huggingface.co/datasets/phonemefake/PhonemeFakeV2,\n  for the code see https://github.com/UTAustin-SwarmLab/ PhonemeFake", "summary": "Deepfake (DF) attacks pose a growing threat as generative models become\nincreasingly advanced. However, our study reveals that existing DF datasets\nfail to deceive human perception, unlike real DF attacks that influence public\ndiscourse. It highlights the need for more realistic DF attack vectors. We\nintroduce PhonemeFake (PF), a DF attack that manipulates critical speech\nsegments using language reasoning, significantly reducing human perception by\nup to 42% and benchmark accuracies by up to 94%. We release an easy-to-use PF\ndataset on HuggingFace and open-source bilevel DF segment detection model that\nadaptively prioritizes compute on manipulated regions. Our extensive\nexperiments across three known DF datasets reveal that our detection model\nreduces EER by 91% while achieving up to 90% speed-up, with minimal compute\noverhead and precise localization beyond existing models as a scalable\nsolution.", "AI": {"tldr": "The paper introduces PhonemeFake (PF), a deepfake attack method that outperforms existing datasets in deceiving humans and benchmarks, and proposes a detection model for scalable defense.", "motivation": "Existing deepfake datasets fail to mimic real-world attacks, highlighting the need for more realistic attack vectors.", "method": "PhonemeFake manipulates critical speech segments using language reasoning, and a bilevel detection model is introduced to prioritize compute on manipulated regions.", "result": "PF reduces human perception by 42% and benchmark accuracies by 94%. The detection model cuts EER by 91% and speeds up by 90%.", "conclusion": "PhonemeFake and the proposed detection model offer a scalable solution for realistic deepfake attacks and defense."}}
{"id": "2506.23192", "pdf": "https://arxiv.org/pdf/2506.23192", "abs": "https://arxiv.org/abs/2506.23192", "authors": ["Gabriel Iturra-Bocaz", "Felipe Bravo-Marquez"], "title": "RiverText: A Python Library for Training and Evaluating Incremental Word Embeddings from Text Data Streams", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted at SIGIR'23", "summary": "Word embeddings have become essential components in various information\nretrieval and natural language processing tasks, such as ranking, document\nclassification, and question answering. However, despite their widespread use,\ntraditional word embedding models present a limitation in their static nature,\nwhich hampers their ability to adapt to the constantly evolving language\npatterns that emerge in sources such as social media and the web (e.g., new\nhashtags or brand names). To overcome this problem, incremental word embedding\nalgorithms are introduced, capable of dynamically updating word representations\nin response to new language patterns and processing continuous data streams.\n  This paper presents RiverText, a Python library for training and evaluating\nincremental word embeddings from text data streams. Our tool is a resource for\nthe information retrieval and natural language processing communities that work\nwith word embeddings in streaming scenarios, such as analyzing social media.\nThe library implements different incremental word embedding techniques, such as\nSkip-gram, Continuous Bag of Words, and Word Context Matrix, in a standardized\nframework. In addition, it uses PyTorch as its backend for neural network\ntraining. We have implemented a module that adapts existing intrinsic static\nword embedding evaluation tasks for word similarity and word categorization to\na streaming setting. Finally, we compare the implemented methods with different\nhyperparameter settings and discuss the results. Our open-source library is\navailable at https://github.com/dccuchile/rivertext.", "AI": {"tldr": "RiverText is a Python library for training and evaluating incremental word embeddings from text streams, addressing the static nature of traditional models.", "motivation": "Traditional word embeddings are static and struggle with evolving language patterns, especially in dynamic contexts like social media.", "method": "RiverText implements incremental techniques (Skip-gram, CBOW, Word Context Matrix) using PyTorch and adapts evaluation tasks for streaming.", "result": "The library provides a standardized framework for incremental word embeddings and compares methods with various hyperparameters.", "conclusion": "RiverText is a valuable open-source tool for dynamic word embedding scenarios, available on GitHub."}}
{"id": "2506.23481", "pdf": "https://arxiv.org/pdf/2506.23481", "abs": "https://arxiv.org/abs/2506.23481", "authors": ["Xian Zhang", "Xiang Cheng"], "title": "Evaluation of Geolocation Capabilities of Multimodal Large Language Models and Analysis of Associated Privacy Risks", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Objectives: The rapid advancement of Multimodal Large Language Models (MLLMs)\nhas significantly enhanced their reasoning capabilities, enabling a wide range\nof intelligent applications. However, these advancements also raise critical\nconcerns regarding privacy and ethics. MLLMs are now capable of inferring the\ngeographic location of images -- such as those shared on social media or\ncaptured from street views -- based solely on visual content, thereby posing\nserious risks of privacy invasion, including doxxing, surveillance, and other\nsecurity threats.\n  Methods: This study provides a comprehensive analysis of existing geolocation\ntechniques based on MLLMs. It systematically reviews relevant litera-ture and\nevaluates the performance of state-of-the-art visual reasoning models on\ngeolocation tasks, particularly in identifying the origins of street view\nimagery.\n  Results: Empirical evaluation reveals that the most advanced visual large\nmodels can successfully localize the origin of street-level imagery with up to\n$49\\%$ accuracy within a 1-kilometer radius. This performance underscores the\nmodels' powerful capacity to extract and utilize fine-grained geographic cues\nfrom visual data.\n  Conclusions: Building on these findings, the study identifies key visual\nelements that contribute to suc-cessful geolocation, such as text,\narchitectural styles, and environmental features. Furthermore, it discusses the\npotential privacy implications associated with MLLM-enabled geolocation and\ndiscuss several technical and policy-based coun-termeasures to mitigate\nassociated risks. Our code and dataset are available at\nhttps://github.com/zxyl1003/MLLM-Geolocation-Evaluation.", "AI": {"tldr": "The paper analyzes the geolocation capabilities of Multimodal Large Language Models (MLLMs), highlighting privacy risks and evaluating their accuracy in identifying image origins.", "motivation": "The study addresses privacy and ethical concerns arising from MLLMs' ability to infer geographic locations from images, posing risks like doxxing and surveillance.", "method": "The research reviews existing geolocation techniques, evaluates state-of-the-art visual reasoning models, and tests their performance on street view imagery.", "result": "Advanced models achieve 49% accuracy in localizing street-level images within a 1-kilometer radius, demonstrating their ability to extract geographic cues.", "conclusion": "The study identifies key visual elements aiding geolocation and suggests technical and policy measures to mitigate privacy risks."}}
{"id": "2506.23924", "pdf": "https://arxiv.org/pdf/2506.23924", "abs": "https://arxiv.org/abs/2506.23924", "authors": ["Akshit Kumar", "Tianyi Peng", "Yuhang Wu", "Assaf Zeevi"], "title": "Performance of LLMs on Stochastic Modeling Operations Research Problems: From Theory to Practice", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have exhibited expert-level capabilities across\nvarious domains. However, their abilities to solve problems in Operations\nResearch (OR) -- the analysis and optimization of mathematical models derived\nfrom real-world problems or their verbal descriptions -- remain underexplored.\nIn this work, we take a first step toward evaluating LLMs' abilities to solve\nstochastic modeling problems, a core class of OR problems characterized by\nuncertainty and typically involving tools from probability, statistics, and\nstochastic processes. We manually procure a representative set of\ngraduate-level homework and doctoral qualification-exam problems and test LLMs'\nabilities to solve them. We further leverage SimOpt, an open-source library of\nsimulation-optimization problems and solvers, to investigate LLMs' abilities to\nmake real-world decisions under uncertainty. Our results show that, though a\nnontrivial amount of work is still needed to reliably automate the stochastic\nmodeling pipeline in reality, state-of-the-art LLMs demonstrate proficiency on\npar with human experts in both classroom and practical settings. These findings\nhighlight the potential of building AI agents that assist OR researchers and\namplify the real-world impact of OR through automation.", "AI": {"tldr": "LLMs show potential in solving stochastic OR problems, matching human experts in some cases, but further work is needed for reliable automation.", "motivation": "To explore LLMs' capabilities in solving stochastic Operations Research problems, which are underexplored despite their real-world relevance.", "method": "Manually curated graduate-level and doctoral exam problems were tested on LLMs, alongside using SimOpt for real-world decision-making under uncertainty.", "result": "LLMs perform on par with human experts in classroom and practical settings, though more work is needed for reliable automation.", "conclusion": "LLMs hold promise for assisting OR researchers and automating OR tasks, amplifying their real-world impact."}}
{"id": "2506.22994", "pdf": "https://arxiv.org/pdf/2506.22994", "abs": "https://arxiv.org/abs/2506.22994", "authors": ["Can Hakan Da\u011f\u0131d\u0131r", "Mia Hubert", "Peter J. Rousseeuw"], "title": "Kernel Outlier Detection", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "A new anomaly detection method called kernel outlier detection (KOD) is\nproposed. It is designed to address challenges of outlier detection in\nhigh-dimensional settings. The aim is to overcome limitations of existing\nmethods, such as dependence on distributional assumptions or on hyperparameters\nthat are hard to tune. KOD starts with a kernel transformation, followed by a\nprojection pursuit approach. Its novelties include a new ensemble of directions\nto search over, and a new way to combine results of different direction types.\nThis provides a flexible and lightweight approach for outlier detection. Our\nempirical evaluations illustrate the effectiveness of KOD on three small\ndatasets with challenging structures, and on four large benchmark datasets.", "AI": {"tldr": "Proposes Kernel Outlier Detection (KOD) for high-dimensional outlier detection, overcoming limitations of existing methods with a kernel-based and projection pursuit approach.", "motivation": "Address challenges in outlier detection in high-dimensional settings, such as dependence on distributional assumptions or hard-to-tune hyperparameters.", "method": "Uses a kernel transformation followed by projection pursuit, with a novel ensemble of directions and combination method.", "result": "Effective on both small datasets with challenging structures and large benchmark datasets.", "conclusion": "KOD offers a flexible, lightweight solution for outlier detection in high-dimensional data."}}
{"id": "2506.22784", "pdf": "https://arxiv.org/pdf/2506.22784", "abs": "https://arxiv.org/abs/2506.22784", "authors": ["Yu Han", "Zhiwei Huang", "Yanting Zhang", "Fangjun Ding", "Shen Cai", "Rui Fan"], "title": "Single-Frame Point-Pixel Registration via Supervised Cross-Modal Feature Matching", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Point-pixel registration between LiDAR point clouds and camera images is a\nfundamental yet challenging task in autonomous driving and robotic perception.\nA key difficulty lies in the modality gap between unstructured point clouds and\nstructured images, especially under sparse single-frame LiDAR settings.\nExisting methods typically extract features separately from point clouds and\nimages, then rely on hand-crafted or learned matching strategies. This separate\nencoding fails to bridge the modality gap effectively, and more critically,\nthese methods struggle with the sparsity and noise of single-frame LiDAR, often\nrequiring point cloud accumulation or additional priors to improve reliability.\nInspired by recent progress in detector-free matching paradigms (e.g.\nMatchAnything), we revisit the projection-based approach and introduce the\ndetector-free framework for direct point-pixel matching between LiDAR and\ncamera views. Specifically, we project the LiDAR intensity map into a 2D view\nfrom the LiDAR perspective and feed it into an attention-based detector-free\nmatching network, enabling cross-modal correspondence estimation without\nrelying on multi-frame accumulation. To further enhance matching reliability,\nwe introduce a repeatability scoring mechanism that acts as a soft visibility\nprior. This guides the network to suppress unreliable matches in regions with\nlow intensity variation, improving robustness under sparse input. Extensive\nexperiments on KITTI, nuScenes, and MIAS-LCEC-TF70 benchmarks demonstrate that\nour method achieves state-of-the-art performance, outperforming prior\napproaches on nuScenes (even those relying on accumulated point clouds),\ndespite using only single-frame LiDAR.", "AI": {"tldr": "A detector-free framework for direct point-pixel matching between LiDAR and camera views, addressing modality gaps and sparsity issues in single-frame LiDAR data.", "motivation": "The modality gap between unstructured LiDAR point clouds and structured images, especially under sparse single-frame LiDAR settings, poses challenges for existing methods.", "method": "Projects LiDAR intensity maps into 2D views and uses an attention-based detector-free matching network for cross-modal correspondence. Introduces a repeatability scoring mechanism to enhance reliability.", "result": "Achieves state-of-the-art performance on KITTI, nuScenes, and MIAS-LCEC-TF70 benchmarks, outperforming prior methods even with single-frame LiDAR.", "conclusion": "The proposed detector-free framework effectively bridges the modality gap and improves robustness in sparse LiDAR settings without multi-frame accumulation."}}
{"id": "2506.23235", "pdf": "https://arxiv.org/pdf/2506.23235", "abs": "https://arxiv.org/abs/2506.23235", "authors": ["Yi-Chen Li", "Tian Xu", "Yang Yu", "Xuqin Zhang", "Xiong-Hui Chen", "Zhongxiang Ling", "Ningjing Chao", "Lei Yuan", "Zhi-Hua Zhou"], "title": "Generalist Reward Models: Found Inside Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "The alignment of Large Language Models (LLMs) is critically dependent on\nreward models trained on costly human preference data. While recent work\nexplores bypassing this cost with AI feedback, these methods often lack a\nrigorous theoretical foundation. In this paper, we discover that a powerful\ngeneralist reward model is already latently present within any LLM trained via\nstandard next-token prediction. We prove that this endogenous reward is not a\nheuristic, but is theoretically equivalent to a reward function learned through\noffline inverse reinforcement learning. This connection allows us to directly\nelicit a high-quality reward signal from a base (pre-trained or supervised\nfine-tuned) model without any further training. Critically, we also prove that\nsubsequent reinforcement learning using this endogenous reward leads to a\npolicy with a provably superior error bound compared to the base model. To our\nbest knowledge, this is the first theoretical proof of the effectiveness of\nreinforcement learning for LLMs. Our experiments validate this theory,\ndemonstrating that our method not only outperforms existing LLM-as-a-judge\napproaches but can also surpass explicitly trained reward models. These\nfindings suggest that the reward modeling stage can be replaced by a principled\nmethod of eliciting the knowledge already captured during pre-training,\nheralding a more efficient, powerful, and scalable paradigm for LLMs alignment\nas well as multi-modal models.", "AI": {"tldr": "The paper reveals that LLMs inherently contain a latent reward model equivalent to offline inverse reinforcement learning, enabling high-quality reward signals without additional training. This method outperforms existing approaches and offers a scalable alternative to human preference-based alignment.", "motivation": "To bypass the high cost of human preference data for LLM alignment and provide a rigorous theoretical foundation for AI feedback methods.", "method": "The study leverages the latent reward model within LLMs, proving its equivalence to offline inverse reinforcement learning and using it for reinforcement learning without further training.", "result": "The method outperforms existing LLM-as-a-judge approaches and surpasses explicitly trained reward models, with a provably superior error bound.", "conclusion": "The findings suggest replacing reward modeling with eliciting pre-trained knowledge, offering a more efficient and scalable paradigm for LLM alignment."}}
{"id": "2506.24092", "pdf": "https://arxiv.org/pdf/2506.24092", "abs": "https://arxiv.org/abs/2506.24092", "authors": ["Moein Heidari", "Yasamin Medghalchi", "Mahdi Khoursha", "Reza Rezaeian", "Ilker Hacihaliloglu"], "title": "WaRA: Wavelet Low Rank Adaptation", "categories": ["cs.CV", "eess.IV"], "comment": "Submitted to BMVC 2025", "summary": "Parameter-efficient fine-tuning (PEFT) has gained widespread adoption across\nvarious applications. Among PEFT techniques, Low-Rank Adaptation (LoRA) and its\nextensions have emerged as particularly effective, allowing efficient model\nadaptation while significantly reducing computational overhead. However,\nexisting approaches typically rely on global low-rank factorizations, which\noverlook local or multi-scale structure, failing to capture complex patterns in\nthe weight updates. To address this, we propose WaRA, a novel PEFT method that\nleverages wavelet transforms to decompose the weight update matrix into a\nmulti-resolution representation. By performing low-rank factorization in the\nwavelet domain and reconstructing updates through an inverse transform, WaRA\nobtains compressed adaptation parameters that harness multi-resolution\nanalysis, enabling it to capture both coarse and fine-grained features while\nproviding greater flexibility and sparser representations than standard LoRA.\nThrough comprehensive experiments and analysis, we demonstrate that WaRA\nperforms superior on diverse vision tasks, including image generation,\nclassification, and semantic segmentation, significantly enhancing generated\nimage quality while reducing computational complexity. Although WaRA was\nprimarily designed for vision tasks, we further showcase its effectiveness in\nlanguage tasks, highlighting its broader applicability and generalizability.\nThe code is publicly available at\n\\href{GitHub}{https://github.com/moeinheidari7829/WaRA}.", "AI": {"tldr": "WaRA introduces a wavelet-based PEFT method for multi-resolution weight updates, outperforming LoRA in vision tasks and showing promise in language tasks.", "motivation": "Existing PEFT methods like LoRA use global low-rank factorizations, missing local or multi-scale structures in weight updates.", "method": "WaRA uses wavelet transforms to decompose weight updates into multi-resolution representations, enabling low-rank factorization in the wavelet domain.", "result": "WaRA excels in vision tasks (image generation, classification, segmentation) and shows effectiveness in language tasks, improving quality and reducing complexity.", "conclusion": "WaRA offers a flexible, sparse, and efficient alternative to LoRA, with broad applicability across vision and language tasks."}}
{"id": "2506.23926", "pdf": "https://arxiv.org/pdf/2506.23926", "abs": "https://arxiv.org/abs/2506.23926", "authors": ["Junping Wang", "Bicheng Wang", "Yibo Xuea", "Yuan Xie"], "title": "Industrial brain: a human-like autonomous neuro-symbolic cognitive decision-making system", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Resilience non-equilibrium measurement, the ability to maintain fundamental\nfunctionality amidst failures and errors, is crucial for scientific management\nand engineering applications of industrial chain. The problem is particularly\nchallenging when the number or types of multiple co-evolution of resilience\n(for example, randomly placed) are extremely chaos. Existing end-to-end deep\nlearning ordinarily do not generalize well to unseen full-feld reconstruction\nof spatiotemporal co-evolution structure, and predict resilience of network\ntopology, especially in multiple chaos data regimes typically seen in\nreal-world applications. To address this challenge, here we propose industrial\nbrain, a human-like autonomous cognitive decision-making and planning framework\nintegrating higher-order activity-driven neuro network and CT-OODA symbolic\nreasoning to autonomous plan resilience directly from observational data of\nglobal variable. The industrial brain not only understands and model structure\nof node activity dynamics and network co-evolution topology without simplifying\nassumptions, and reveal the underlying laws hidden behind complex networks, but\nalso enabling accurate resilience prediction, inference, and planning.\nExperimental results show that industrial brain significantly outperforms\nresilience prediction and planning methods, with an accurate improvement of up\nto 10.8\\% over GoT and OlaGPT framework and 11.03\\% over spectral dimension\nreduction. It also generalizes to unseen topologies and dynamics and maintains\nrobust performance despite observational disturbances. Our findings suggest\nthat industrial brain addresses an important gap in resilience prediction and\nplanning for industrial chain.", "AI": {"tldr": "The paper proposes 'Industrial Brain,' a framework combining neuro networks and symbolic reasoning to predict and plan resilience in industrial chains, outperforming existing methods by up to 11.03%.", "motivation": "Existing deep learning methods struggle with resilience prediction in chaotic, real-world industrial chain scenarios, necessitating a more robust solution.", "method": "The 'Industrial Brain' integrates higher-order neuro networks and CT-OODA symbolic reasoning to model node dynamics and network co-evolution without simplifying assumptions.", "result": "Industrial Brain improves resilience prediction accuracy by up to 10.8% over GoT/OlaGPT and 11.03% over spectral dimension reduction, generalizing well to unseen data.", "conclusion": "Industrial Brain effectively addresses resilience prediction gaps in industrial chains, offering robust performance and generalization."}}
{"id": "2506.22995", "pdf": "https://arxiv.org/pdf/2506.22995", "abs": "https://arxiv.org/abs/2506.22995", "authors": ["Davide Salaorni", "Federico Bianchi", "Francesco Trov\u00f2", "Marcello Restelli"], "title": "A Reinforcement Learning Approach for Optimal Control in Microgrids", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "8 pages, accepted to International Joint Conference on Neural\n  Networks 2025", "summary": "The increasing integration of renewable energy sources (RESs) is transforming\ntraditional power grid networks, which require new approaches for managing\ndecentralized energy production and consumption. Microgrids (MGs) provide a\npromising solution by enabling localized control over energy generation,\nstorage, and distribution. This paper presents a novel reinforcement learning\n(RL)-based methodology for optimizing microgrid energy management.\nSpecifically, we propose an RL agent that learns optimal energy trading and\nstorage policies by leveraging historical data on energy production,\nconsumption, and market prices. A digital twin (DT) is used to simulate the\nenergy storage system dynamics, incorporating degradation factors to ensure a\nrealistic emulation of the analysed setting. Our approach is validated through\nan experimental campaign using real-world data from a power grid located in the\nItalian territory. The results indicate that the proposed RL-based strategy\noutperforms rule-based methods and existing RL benchmarks, offering a robust\nsolution for intelligent microgrid management.", "AI": {"tldr": "A reinforcement learning (RL)-based method optimizes microgrid energy management, outperforming rule-based and existing RL methods.", "motivation": "The integration of renewable energy sources requires decentralized energy management solutions, with microgrids offering localized control.", "method": "Proposes an RL agent for energy trading and storage, using a digital twin for realistic simulation of storage dynamics and degradation.", "result": "Validated with real-world data, the RL-based strategy outperforms rule-based and existing RL benchmarks.", "conclusion": "The RL approach provides a robust solution for intelligent microgrid management."}}
{"id": "2506.22800", "pdf": "https://arxiv.org/pdf/2506.22800", "abs": "https://arxiv.org/abs/2506.22800", "authors": ["Sicong Du", "Jiarun Liu", "Qifeng Chen", "Hao-Xiang Chen", "Tai-Jiang Mu", "Sheng Yang"], "title": "RGE-GS: Reward-Guided Expansive Driving Scene Reconstruction via Diffusion Priors", "categories": ["cs.CV"], "comment": null, "summary": "A single-pass driving clip frequently results in incomplete scanning of the\nroad structure, making reconstructed scene expanding a critical requirement for\nsensor simulators to effectively regress driving actions. Although contemporary\n3D Gaussian Splatting (3DGS) techniques achieve remarkable reconstruction\nquality, their direct extension through the integration of diffusion priors\noften introduces cumulative physical inconsistencies and compromises training\nefficiency. To address these limitations, we present RGE-GS, a novel expansive\nreconstruction framework that synergizes diffusion-based generation with\nreward-guided Gaussian integration. The RGE-GS framework incorporates two key\ninnovations: First, we propose a reward network that learns to identify and\nprioritize consistently generated patterns prior to reconstruction phases,\nthereby enabling selective retention of diffusion outputs for spatial\nstability. Second, during the reconstruction process, we devise a\ndifferentiated training strategy that automatically adjust Gaussian\noptimization progress according to scene converge metrics, which achieving\nbetter convergence than baseline methods. Extensive evaluations of publicly\navailable datasets demonstrate that RGE-GS achieves state-of-the-art\nperformance in reconstruction quality. Our source-code will be made publicly\navailable at https://github.com/CN-ADLab/RGE-GS. (Camera-ready version\nincorporating reviewer suggestions will be updated soon.)", "AI": {"tldr": "RGE-GS is a novel framework for expansive road structure reconstruction, combining diffusion-based generation with reward-guided Gaussian integration to improve quality and efficiency.", "motivation": "Incomplete road scans from single-pass driving clips necessitate better reconstruction methods for sensor simulators, but current 3DGS extensions with diffusion priors introduce inconsistencies and inefficiencies.", "method": "RGE-GS integrates a reward network to prioritize stable diffusion outputs and uses a differentiated training strategy for adaptive Gaussian optimization.", "result": "RGE-GS achieves state-of-the-art reconstruction quality on public datasets.", "conclusion": "The framework effectively addresses limitations of prior methods and will be made open-source."}}
{"id": "2506.23288", "pdf": "https://arxiv.org/pdf/2506.23288", "abs": "https://arxiv.org/abs/2506.23288", "authors": ["Miguel Domingo", "Francisco Casacuberta"], "title": "Two Spelling Normalization Approaches Based on Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "The absence of standardized spelling conventions and the organic evolution of\nhuman language present an inherent linguistic challenge within historical\ndocuments, a longstanding concern for scholars in the humanities. Addressing\nthis issue, spelling normalization endeavors to align a document's orthography\nwith contemporary standards. In this study, we propose two new approaches based\non large language models: one of which has been trained without a supervised\ntraining, and a second one which has been trained for machine translation. Our\nevaluation spans multiple datasets encompassing diverse languages and\nhistorical periods, leading us to the conclusion that while both of them\nyielded encouraging results, statistical machine translation still seems to be\nthe most suitable technology for this task.", "AI": {"tldr": "The paper proposes two new spelling normalization methods using large language models, comparing unsupervised training and machine translation, with machine translation proving more effective.", "motivation": "Standardizing spelling in historical documents is challenging due to evolving language conventions, necessitating effective normalization techniques.", "method": "Two approaches are tested: one using unsupervised training and another using machine translation, evaluated across diverse datasets.", "result": "Both methods showed promise, but statistical machine translation performed better for spelling normalization.", "conclusion": "Machine translation remains the most suitable technology for spelling normalization in historical documents."}}
{"id": "2407.08855", "pdf": "https://arxiv.org/pdf/2407.08855", "abs": "https://arxiv.org/abs/2407.08855", "authors": ["Anahita Fathi Kazerooni", "Nastaran Khalili", "Xinyang Liu", "Debanjan Haldar", "Zhifan Jiang", "Anna Zapaishchykova", "Julija Pavaine", "Lubdha M. Shah", "Blaise V. Jones", "Nakul Sheth", "Sanjay P. Prabhu", "Aaron S. McAllister", "Wenxin Tu", "Khanak K. Nandolia", "Andres F. Rodriguez", "Ibraheem Salman Shaikh", "Mariana Sanchez Montano", "Hollie Anne Lai", "Maruf Adewole", "Jake Albrecht", "Udunna Anazodo", "Hannah Anderson", "Syed Muhammed Anwar", "Alejandro Aristizabal", "Sina Bagheri", "Ujjwal Baid", "Timothy Bergquist", "Austin J. Borja", "Evan Calabrese", "Verena Chung", "Gian-Marco Conte", "James Eddy", "Ivan Ezhov", "Ariana M. Familiar", "Keyvan Farahani", "Deep Gandhi", "Anurag Gottipati", "Shuvanjan Haldar", "Juan Eugenio Iglesias", "Anastasia Janas", "Elaine Elaine", "Alexandros Karargyris", "Hasan Kassem", "Neda Khalili", "Florian Kofler", "Dominic LaBella", "Koen Van Leemput", "Hongwei B. Li", "Nazanin Maleki", "Zeke Meier", "Bjoern Menze", "Ahmed W. Moawad", "Sarthak Pati", "Marie Piraud", "Tina Poussaint", "Zachary J. Reitman", "Jeffrey D. Rudie", "Rachit Saluja", "MIcah Sheller", "Russell Takeshi Shinohara", "Karthik Viswanathan", "Chunhao Wang", "Benedikt Wiestler", "Walter F. Wiggins", "Christos Davatzikos", "Phillip B. Storm", "Miriam Bornhorst", "Roger Packer", "Trent Hummel", "Peter de Blank", "Lindsey Hoffman", "Mariam Aboian", "Ali Nabavizadeh", "Jeffrey B. Ware", "Benjamin H. Kann", "Brian Rood", "Adam Resnick", "Spyridon Bakas", "Arastoo Vossough", "Marius George Linguraru"], "title": "BraTS-PEDs: Results of the Multi-Consortium International Pediatric Brain Tumor Segmentation Challenge 2023", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA)https://melba-journal.org/2025:005", "summary": "Pediatric central nervous system tumors are the leading cause of\ncancer-related deaths in children. The five-year survival rate for high-grade\nglioma in children is less than 20%. The development of new treatments is\ndependent upon multi-institutional collaborative clinical trials requiring\nreproducible and accurate centralized response assessment. We present the\nresults of the BraTS-PEDs 2023 challenge, the first Brain Tumor Segmentation\n(BraTS) challenge focused on pediatric brain tumors. This challenge utilized\ndata acquired from multiple international consortia dedicated to pediatric\nneuro-oncology and clinical trials. BraTS-PEDs 2023 aimed to evaluate\nvolumetric segmentation algorithms for pediatric brain gliomas from magnetic\nresonance imaging using standardized quantitative performance evaluation\nmetrics employed across the BraTS 2023 challenges. The top-performing AI\napproaches for pediatric tumor analysis included ensembles of nnU-Net and Swin\nUNETR, Auto3DSeg, or nnU-Net with a self-supervised framework. The BraTSPEDs\n2023 challenge fostered collaboration between clinicians (neuro-oncologists,\nneuroradiologists) and AI/imaging scientists, promoting faster data sharing and\nthe development of automated volumetric analysis techniques. These advancements\ncould significantly benefit clinical trials and improve the care of children\nwith brain tumors.", "AI": {"tldr": "The BraTS-PEDs 2023 challenge focused on pediatric brain tumor segmentation, using AI to improve diagnosis and treatment. Top methods included nnU-Net and Swin UNETR.", "motivation": "Pediatric CNS tumors are deadly, with low survival rates. New treatments need accurate, centralized response assessment.", "method": "Multi-institutional data was used to evaluate AI segmentation algorithms for pediatric gliomas via standardized metrics.", "result": "Top-performing AI methods were nnU-Net, Swin UNETR, and Auto3DSeg. Collaboration between clinicians and AI scientists was enhanced.", "conclusion": "The challenge improved data sharing and automated analysis, potentially aiding clinical trials and pediatric brain tumor care."}}
{"id": "2506.23949", "pdf": "https://arxiv.org/pdf/2506.23949", "abs": "https://arxiv.org/abs/2506.23949", "authors": ["Anthony M. Barrett", "Jessica Newman", "Brandie Nonnecke", "Nada Madkour", "Dan Hendrycks", "Evan R. Murphy", "Krystal Jackson", "Deepika Raman"], "title": "AI Risk-Management Standards Profile for General-Purpose AI (GPAI) and Foundation Models", "categories": ["cs.AI", "cs.CR", "cs.CY"], "comment": null, "summary": "Increasingly multi-purpose AI models, such as cutting-edge large language\nmodels or other 'general-purpose AI' (GPAI) models, 'foundation models,'\ngenerative AI models, and 'frontier models' (typically all referred to\nhereafter with the umbrella term 'GPAI/foundation models' except where greater\nspecificity is needed), can provide many beneficial capabilities but also risks\nof adverse events with profound consequences. This document provides\nrisk-management practices or controls for identifying, analyzing, and\nmitigating risks of GPAI/foundation models. We intend this document primarily\nfor developers of large-scale, state-of-the-art GPAI/foundation models; others\nthat can benefit from this guidance include downstream developers of end-use\napplications that build on a GPAI/foundation model. This document facilitates\nconformity with or use of leading AI risk management-related standards,\nadapting and building on the generic voluntary guidance in the NIST AI Risk\nManagement Framework and ISO/IEC 23894, with a focus on the unique issues faced\nby developers of GPAI/foundation models.", "AI": {"tldr": "The paper outlines risk-management practices for general-purpose AI (GPAI) and foundation models, targeting developers to mitigate risks and align with standards like NIST and ISO/IEC.", "motivation": "Address the dual nature of GPAI/foundation models, which offer benefits but also pose significant risks, necessitating structured risk management.", "method": "Proposes risk-management controls and practices, adapting frameworks like NIST AI Risk Management and ISO/IEC 23894, tailored for GPAI/foundation models.", "result": "Provides actionable guidance for developers to identify, analyze, and mitigate risks associated with GPAI/foundation models.", "conclusion": "The document serves as a practical resource for developers to manage risks and align with leading AI standards."}}
{"id": "2506.23024", "pdf": "https://arxiv.org/pdf/2506.23024", "abs": "https://arxiv.org/abs/2506.23024", "authors": ["Jerry Liu", "Yasa Baig", "Denise Hui Jean Lee", "Rajat Vadiraj Dwaraknath", "Atri Rudra", "Chris R\u00e9"], "title": "BWLer: Barycentric Weight Layer Elucidates a Precision-Conditioning Tradeoff for PINNs", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "comment": "Workshop for the Theory of AI for Scientific Computing @ COLT 2025\n  (Best Paper). 39 pages, 24 figures", "summary": "Physics-informed neural networks (PINNs) offer a flexible way to solve\npartial differential equations (PDEs) with machine learning, yet they still\nfall well short of the machine-precision accuracy many scientific tasks demand.\nIn this work, we investigate whether the precision ceiling comes from the\nill-conditioning of the PDEs or from the typical multi-layer perceptron (MLP)\narchitecture. We introduce the Barycentric Weight Layer (BWLer), which models\nthe PDE solution through barycentric polynomial interpolation. A BWLer can be\nadded on top of an existing MLP (a BWLer-hat) or replace it completely\n(explicit BWLer), cleanly separating how we represent the solution from how we\ntake derivatives for the PDE loss. Using BWLer, we identify fundamental\nprecision limitations within the MLP: on a simple 1-D interpolation task, even\nMLPs with O(1e5) parameters stall around 1e-8 RMSE -- about eight orders above\nfloat64 machine precision -- before any PDE terms are added. In PDE learning,\nadding a BWLer lifts this ceiling and exposes a tradeoff between achievable\naccuracy and the conditioning of the PDE loss. For linear PDEs we fully\ncharacterize this tradeoff with an explicit error decomposition and navigate it\nduring training with spectral derivatives and preconditioning. Across five\nbenchmark PDEs, adding a BWLer on top of an MLP improves RMSE by up to 30x for\nconvection, 10x for reaction, and 1800x for wave equations while remaining\ncompatible with first-order optimizers. Replacing the MLP entirely lets an\nexplicit BWLer reach near-machine-precision on convection, reaction, and wave\nproblems (up to 10 billion times better than prior results) and match the\nperformance of standard PINNs on stiff Burgers' and irregular-geometry Poisson\nproblems. Together, these findings point to a practical path for combining the\nflexibility of PINNs with the precision of classical spectral solvers.", "AI": {"tldr": "The paper introduces the Barycentric Weight Layer (BWLer) to address precision limitations in Physics-informed neural networks (PINNs) for solving PDEs, achieving near-machine-precision accuracy in some cases.", "motivation": "PINNs struggle with achieving machine-precision accuracy for PDEs, prompting investigation into whether the issue stems from PDE ill-conditioning or MLP architecture.", "method": "The BWLer, a barycentric polynomial interpolation layer, is introduced to either augment or replace MLPs in PINNs, separating solution representation from derivative computation.", "result": "BWLer significantly improves accuracy (up to 1800x better RMSE) and achieves near-machine-precision for certain PDEs, outperforming standard PINNs.", "conclusion": "BWLer bridges the gap between PINNs' flexibility and classical spectral solvers' precision, offering a practical solution for high-accuracy PDE solving."}}
{"id": "2506.22803", "pdf": "https://arxiv.org/pdf/2506.22803", "abs": "https://arxiv.org/abs/2506.22803", "authors": ["Nuoye Xiong", "Anqi Dong", "Ning Wang", "Cong Hua", "Guangming Zhu", "Mei Lin", "Peiyi Shen", "Liang Zhang"], "title": "Intervening in Black Box: Concept Bottleneck Model for Enhancing Human Neural Network Mutual Understanding", "categories": ["cs.CV", "cs.HC", "cs.LG"], "comment": "Accepted by ICCV 2025", "summary": "Recent advances in deep learning have led to increasingly complex models with\ndeeper layers and more parameters, reducing interpretability and making their\ndecisions harder to understand. While many methods explain black-box reasoning,\nmost lack effective interventions or only operate at sample-level without\nmodifying the model itself. To address this, we propose the Concept Bottleneck\nModel for Enhancing Human-Neural Network Mutual Understanding (CBM-HNMU).\nCBM-HNMU leverages the Concept Bottleneck Model (CBM) as an interpretable\nframework to approximate black-box reasoning and communicate conceptual\nunderstanding. Detrimental concepts are automatically identified and refined\n(removed/replaced) based on global gradient contributions. The modified CBM\nthen distills corrected knowledge back into the black-box model, enhancing both\ninterpretability and accuracy. We evaluate CBM-HNMU on various CNN and\ntransformer-based models across Flower-102, CIFAR-10, CIFAR-100, FGVC-Aircraft,\nand CUB-200, achieving a maximum accuracy improvement of 2.64% and a maximum\nincrease in average accuracy across 1.03%. Source code is available at:\nhttps://github.com/XiGuaBo/CBM-HNMU.", "AI": {"tldr": "The paper introduces CBM-HNMU, a method to improve interpretability and accuracy of deep learning models by refining concepts in a Concept Bottleneck Model and distilling knowledge back into the original model.", "motivation": "Deep learning models are becoming more complex and less interpretable, with existing explanation methods lacking effective interventions or model modifications.", "method": "CBM-HNMU uses the Concept Bottleneck Model to approximate black-box reasoning, identifies and refines detrimental concepts, and distills corrected knowledge back into the model.", "result": "Evaluations on multiple datasets show accuracy improvements up to 2.64% and an average increase of 1.03%.", "conclusion": "CBM-HNMU enhances both interpretability and model performance, offering a practical solution for human-neural network mutual understanding."}}
{"id": "2506.23293", "pdf": "https://arxiv.org/pdf/2506.23293", "abs": "https://arxiv.org/abs/2506.23293", "authors": ["P. Myles Eugenio"], "title": "Objective-Free Local Learning and Emergent Language Structure in Thinking Machines", "categories": ["cs.CL", "cs.AI", "cs.LG", "q-bio.NC"], "comment": "22 pages, 7 figures", "summary": "We present a neuro-symbolic framework for generative language modeling based\non local, event-driven emergent learning. At its core is a hierarchical\nHopfield memory chain acting as a compositional short-term memory and dynamic\ntokenizer (retokenizer). Rather than relying on predefined tokens or\nsupervision, the model builds structure from scratch, learning symbol sequences\nas multi-scale representations. It constructs projection tensors that bind\nco-occurring features into hierarchical tokens, introducing redundancy (i.e an\nemergent gauge structure) and enabling compression of local activations into\nlong-range dependencies. Curiously, we find that the retokenizer can filter\nnatural language patterns from noise, generating synthetic languages with\ncoherent internal morphology -- quantifiably the same as human language.\nLanguage is learned in a local (Hebbian) fashion, where model constraints\ndictate allowed emergent structure, and new information is retained in\nalignment with this structure. The absence of a global objective enables a form\nof plasticity not found in conventional language models, allowing the system to\ngeneralize beyond its initial inference class -- even without explicit data. We\ndemonstrate that briefly activating a new neuron during inference binds\ndistributed multi-scale token features into a symbolic embedding. These\nemergent embedding neurons act as long-term memory and support a key-value\nmechanism for compositional inference and generalization. This architecture\nprovides a methodological foundation for studying how symbolic structure can\nemerge from local neural learning. It offers a new pathway for building\nscalable, interpretable neuro-symbolic systems -- where tokens, grammar, and\nreasoning arise as compressed memory traces within a Hopfield hierarchy. This\napproach advances the development of neuromorphic architectures for generative\nlanguage models.", "AI": {"tldr": "A neuro-symbolic framework for generative language modeling uses local, event-driven learning with a hierarchical Hopfield memory chain, enabling emergent tokenization and structure without predefined tokens or supervision.", "motivation": "To explore how symbolic structure can emerge from local neural learning and develop scalable, interpretable neuro-symbolic systems.", "method": "Uses a hierarchical Hopfield memory chain as a dynamic tokenizer, learning symbol sequences as multi-scale representations and constructing projection tensors for hierarchical tokens.", "result": "The model filters natural language patterns from noise, generates synthetic languages with human-like morphology, and generalizes beyond initial inference class without explicit data.", "conclusion": "The framework provides a foundation for scalable, interpretable neuro-symbolic systems, advancing neuromorphic architectures for generative language models."}}
{"id": "2407.15380", "pdf": "https://arxiv.org/pdf/2407.15380", "abs": "https://arxiv.org/abs/2407.15380", "authors": ["Ligen Shi", "Chang Liu", "Xing Zhao", "Jun Qiu"], "title": "Iterative approach to reconstructing neural disparity fields from light-field data", "categories": ["eess.IV", "cs.CV", "68U10", "I.4.10; I.4.5"], "comment": "11 pages, 9 figures", "summary": "This study proposes a neural disparity field (NDF) that establishes an\nimplicit, continuous representation of scene disparity based on a neural field\nand an iterative approach to address the inverse problem of NDF reconstruction\nfrom light-field data. NDF enables seamless and precise characterization of\ndisparity variations in three-dimensional scenes and can discretize disparity\nat any arbitrary resolution, overcoming the limitations of traditional\ndisparity maps that are prone to sampling errors and interpolation\ninaccuracies. The proposed NDF network architecture utilizes hash encoding\ncombined with multilayer perceptrons to capture detailed disparities in texture\nlevels, thereby enhancing its ability to represent the geometric information of\ncomplex scenes. By leveraging the spatial-angular consistency inherent in\nlight-field data, a differentiable forward model to generate a central view\nimage from the light-field data is developed. Based on the forward model, an\noptimization scheme for the inverse problem of NDF reconstruction using\ndifferentiable propagation operators is established. Furthermore, an iterative\nsolution method is adopted to reconstruct the NDF in the optimization scheme,\nwhich does not require training datasets and applies to light-field data\ncaptured by various acquisition methods. Experimental results demonstrate that\nhigh-quality NDF can be reconstructed from light-field data using the proposed\nmethod. High-resolution disparity can be effectively recovered by NDF,\ndemonstrating its capability for the implicit, continuous representation of\nscene disparities.", "AI": {"tldr": "The paper introduces a neural disparity field (NDF) for implicit, continuous disparity representation from light-field data, overcoming traditional limitations like sampling errors. It uses hash encoding and MLPs for detailed disparity capture and an iterative, dataset-free optimization scheme.", "motivation": "Traditional disparity maps suffer from sampling errors and interpolation inaccuracies. The study aims to provide a seamless, precise, and resolution-flexible disparity representation using neural fields.", "method": "Proposes NDF with hash encoding and MLPs for detailed disparity. Develops a differentiable forward model for light-field data and an iterative optimization scheme for NDF reconstruction without training data.", "result": "High-quality NDF can be reconstructed, enabling high-resolution disparity recovery and implicit, continuous representation of scene disparities.", "conclusion": "NDF effectively addresses traditional disparity map limitations, offering a robust solution for complex scene disparity representation from light-field data."}}
{"id": "2506.23992", "pdf": "https://arxiv.org/pdf/2506.23992", "abs": "https://arxiv.org/abs/2506.23992", "authors": ["Aditya Shrivastava", "Komal Gupta", "Shraddha Arora"], "title": "Harnessing AI Agents to Advance Research on Refugee Child Mental Health", "categories": ["cs.AI", "cs.ET"], "comment": "14 page , 2 image , 2 tables , accepted under 5th International\n  Conference on Innovations in Computational Intelligence and Computer Vision\n  (ICICV-2025)", "summary": "The international refugee crisis deepens, exposing millions of dis placed\nchildren to extreme psychological trauma. This research suggests a com pact,\nAI-based framework for processing unstructured refugee health data and\ndistilling knowledge on child mental health. We compare two Retrieval-Aug\nmented Generation (RAG) pipelines, Zephyr-7B-beta and DeepSeek R1-7B, to\ndetermine how well they process challenging humanitarian datasets while avoid\ning hallucination hazards. By combining cutting-edge AI methods with migration\nresearch and child psychology, this study presents a scalable strategy to\nassist policymakers, mental health practitioners, and humanitarian agencies to\nbetter assist displaced children and recognize their mental wellbeing. In\ntotal, both the models worked properly but significantly Deepseek R1 is\nsuperior to Zephyr with an accuracy of answer relevance 0.91", "AI": {"tldr": "AI-based framework for analyzing refugee child mental health data using RAG pipelines, with DeepSeek R1-7B outperforming Zephyr-7B-beta.", "motivation": "Address the psychological trauma of displaced children by leveraging AI to process unstructured health data.", "method": "Compare two RAG pipelines (Zephyr-7B-beta and DeepSeek R1-7B) on humanitarian datasets, focusing on accuracy and avoiding hallucinations.", "result": "DeepSeek R1-7B is superior with 0.91 answer relevance accuracy.", "conclusion": "The study offers a scalable AI strategy to aid policymakers and practitioners in improving mental health support for displaced children."}}
{"id": "2506.23025", "pdf": "https://arxiv.org/pdf/2506.23025", "abs": "https://arxiv.org/abs/2506.23025", "authors": ["Tejas Vaidhya", "Ayush Kaushal", "Vineet Jain", "Francis Couture Harpin", "Prashant Shishodia", "Majid Behbahani", "Yuriy Nevmyvaka", "Irina Rish"], "title": "Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly used across research and\nindustry applications, yet their inference efficiency remains a significant\nchallenge. As the computational power of modern GPU architectures continuously\nimproves, their memory bandwidth and capacity have not scaled proportionally,\ncreating a critical bottleneck during inference. To address this, we\ninvestigate ternary language models (TriLMs) that employ quantization-aware\ntraining to significantly reduce memory requirements. We first analyze the\nscalability of TriLMs by conducting a scaling law analysis, revealing that\nTriLMs benefit more from increasing training data than from scaling model\nparameters. Based on this observation, we introduce Spectra-1.1, an open suite\nof TriLMs trained on up to 1.2 trillion tokens, demonstrating sustained\nperformance gains at scale. Furthermore, to improve inference efficiency, we\npropose novel 2-bit and 1.6-bit packing schemes for ternary weights, which\ndemonstrate accelerated inference across various CPU architectures. Also,\nbuilding on the 2-bit packing, we develop a GPU kernel called TriRun that\naccelerates end-to-end model inference by up to 5 times compared to\nfloating-point baselines. To encourage further exploration and development of\nTriLMs, we will release the Spectra-1.1 suite and TriRun inference kernels.\nOverall, our work lays the foundation for building and deploying efficient\nLLMs, providing a valuable resource for the research community.", "AI": {"tldr": "The paper introduces ternary language models (TriLMs) to improve inference efficiency in large language models (LLMs) by reducing memory requirements. It includes scaling law analysis, a new TriLM suite (Spectra-1.1), and efficient packing schemes for faster inference.", "motivation": "Address the bottleneck in LLM inference caused by limited memory bandwidth and capacity, despite advances in GPU computational power.", "method": "Propose TriLMs with quantization-aware training, analyze their scalability, introduce Spectra-1.1 (trained on 1.2T tokens), and develop 2-bit/1.6-bit packing schemes and a GPU kernel (TriRun) for faster inference.", "result": "TriLMs show better performance with more training data than larger parameters. Spectra-1.1 and TriRun achieve up to 5x faster inference compared to floating-point baselines.", "conclusion": "The work provides efficient LLM deployment solutions, releasing Spectra-1.1 and TriRun to support further research in TriLMs."}}
{"id": "2506.22806", "pdf": "https://arxiv.org/pdf/2506.22806", "abs": "https://arxiv.org/abs/2506.22806", "authors": ["Byung Hyun Lee", "Sungjin Lim", "Seunggyu Lee", "Dong Un Kang", "Se Young Chun"], "title": "Concept Pinpoint Eraser for Text-to-image Diffusion Models via Residual Attention Gate", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Remarkable progress in text-to-image diffusion models has brought a major\nconcern about potentially generating images on inappropriate or trademarked\nconcepts. Concept erasing has been investigated with the goals of deleting\ntarget concepts in diffusion models while preserving other concepts with\nminimal distortion. To achieve these goals, recent concept erasing methods\nusually fine-tune the cross-attention layers of diffusion models. In this work,\nwe first show that merely updating the cross-attention layers in diffusion\nmodels, which is mathematically equivalent to adding \\emph{linear} modules to\nweights, may not be able to preserve diverse remaining concepts. Then, we\npropose a novel framework, dubbed Concept Pinpoint Eraser (CPE), by adding\n\\emph{nonlinear} Residual Attention Gates (ResAGs) that selectively erase (or\ncut) target concepts while safeguarding remaining concepts from broad\ndistributions by employing an attention anchoring loss to prevent the\nforgetting. Moreover, we adversarially train CPE with ResAG and learnable text\nembeddings in an iterative manner to maximize erasing performance and enhance\nrobustness against adversarial attacks. Extensive experiments on the erasure of\ncelebrities, artistic styles, and explicit contents demonstrated that the\nproposed CPE outperforms prior arts by keeping diverse remaining concepts while\ndeleting the target concepts with robustness against attack prompts. Code is\navailable at https://github.com/Hyun1A/CPE", "AI": {"tldr": "The paper introduces Concept Pinpoint Eraser (CPE), a method to erase specific concepts in text-to-image diffusion models while preserving others, outperforming prior methods by using nonlinear modules and adversarial training.", "motivation": "Addressing the concern of generating inappropriate or trademarked images, the paper aims to improve concept erasure in diffusion models without distorting other concepts.", "method": "CPE adds nonlinear Residual Attention Gates (ResAGs) and uses an attention anchoring loss to selectively erase target concepts. It also employs adversarial training with learnable text embeddings for robustness.", "result": "CPE effectively erases target concepts (e.g., celebrities, artistic styles, explicit content) while preserving diverse remaining concepts and resisting adversarial attacks.", "conclusion": "CPE outperforms existing methods by combining nonlinear modules and adversarial training, offering robust and precise concept erasure."}}
{"id": "2506.23315", "pdf": "https://arxiv.org/pdf/2506.23315", "abs": "https://arxiv.org/abs/2506.23315", "authors": ["Shouvon Sarker", "Xishuang Dong", "Lijun Qian"], "title": "Ensemble BERT for Medication Event Classification on Electronic Health Records (EHRs)", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Identification of key variables such as medications, diseases, relations from\nhealth records and clinical notes has a wide range of applications in the\nclinical domain. n2c2 2022 provided shared tasks on challenges in natural\nlanguage processing for clinical data analytics on electronic health records\n(EHR), where it built a comprehensive annotated clinical data Contextualized\nMedication Event Dataset (CMED). This study focuses on subtask 2 in Track 1 of\nthis challenge that is to detect and classify medication events from clinical\nnotes through building a novel BERT-based ensemble model. It started with\npretraining BERT models on different types of big data such as Wikipedia and\nMIMIC. Afterwards, these pretrained BERT models were fine-tuned on CMED\ntraining data. These fine-tuned BERT models were employed to accomplish\nmedication event classification on CMED testing data with multiple predictions.\nThese multiple predictions generated by these fine-tuned BERT models were\nintegrated to build final prediction with voting strategies. Experimental\nresults demonstrated that BERT-based ensemble models can effectively improve\nstrict Micro-F score by about 5% and strict Macro-F score by about 6%,\nrespectively.", "AI": {"tldr": "The paper presents a BERT-based ensemble model for detecting and classifying medication events from clinical notes, achieving improved performance in Micro-F and Macro-F scores.", "motivation": "The study aims to address the challenge of identifying key variables like medications and diseases from clinical data, leveraging the n2c2 2022 shared tasks and the CMED dataset.", "method": "The method involves pretraining BERT models on diverse datasets (Wikipedia, MIMIC), fine-tuning them on CMED training data, and using ensemble voting strategies for final predictions.", "result": "The ensemble model improved strict Micro-F score by ~5% and strict Macro-F score by ~6%.", "conclusion": "BERT-based ensemble models are effective for medication event classification in clinical notes."}}
{"id": "2409.15731", "pdf": "https://arxiv.org/pdf/2409.15731", "abs": "https://arxiv.org/abs/2409.15731", "authors": ["Ligen Shi", "Xu Jiang", "YunZe Liu", "Chang Liu", "Ping Yang", "Shifeng Guo", "Xing Zhao"], "title": "Ring Artifacts Removal Based on Implicit Neural Representation of Sinogram Data", "categories": ["eess.IV", "68U05, 65D18", "I.4.5; I.4.10"], "comment": "12 pages, 13 figures", "summary": "Inconsistent responses of X-ray detector elements lead to stripe artifacts in\nthe sinogram data, which manifest as ring artifacts in the reconstructed CT\nimages, severely degrading image quality. This paper proposes a method for\ncorrecting stripe artifacts in the sinogram data. The proposed method leverages\nimplicit neural representation (INR) to correct defective pixel response values\nusing implicit continuous functions and simultaneously learns stripe features\nin the angular direction of the sinogram data. These two components are\ncombined within an optimization constraint framework, achieving unsupervised\niterative correction of stripe artifacts in the projection domain. Experimental\nresults demonstrate that the proposed method significantly outperforms current\nstate-of-the-art techniques in removing ring artifacts while maintaining the\nclarity of CT images.", "AI": {"tldr": "Proposes an unsupervised method using implicit neural representation (INR) to correct stripe artifacts in sinogram data, improving CT image quality by removing ring artifacts.", "motivation": "Stripe artifacts in sinogram data cause ring artifacts in CT images, degrading quality. Current methods may not fully address this issue.", "method": "Uses INR to correct defective pixel responses and learns stripe features in the sinogram's angular direction, combined in an optimization framework.", "result": "Outperforms state-of-the-art techniques in removing ring artifacts while preserving CT image clarity.", "conclusion": "The method effectively corrects stripe artifacts, enhancing CT image quality without supervision."}}
{"id": "2506.24026", "pdf": "https://arxiv.org/pdf/2506.24026", "abs": "https://arxiv.org/abs/2506.24026", "authors": ["Yongyi Wang", "Wenxin Li"], "title": "Constructing Non-Markovian Decision Process via History Aggregator", "categories": ["cs.AI"], "comment": null, "summary": "In the domain of algorithmic decision-making, non-Markovian dynamics manifest\nas a significant impediment, especially for paradigms such as Reinforcement\nLearning (RL), thereby exerting far-reaching consequences on the advancement\nand effectiveness of the associated systems. Nevertheless, the existing\nbenchmarks are deficient in comprehensively assessing the capacity of decision\nalgorithms to handle non-Markovian dynamics. To address this deficiency, we\nhave devised a generalized methodology grounded in category theory. Notably, we\nestablished the category of Markov Decision Processes (MDP) and the category of\nnon-Markovian Decision Processes (NMDP), and proved the equivalence\nrelationship between them. This theoretical foundation provides a novel\nperspective for understanding and addressing non-Markovian dynamics. We further\nintroduced non-Markovianity into decision-making problem settings via the\nHistory Aggregator for State (HAS). With HAS, we can precisely control the\nstate dependency structure of decision-making problems in the time series. Our\nanalysis demonstrates the effectiveness of our method in representing a broad\nrange of non-Markovian dynamics. This approach facilitates a more rigorous and\nflexible evaluation of decision algorithms by testing them in problem settings\nwhere non-Markovian dynamics are explicitly constructed.", "AI": {"tldr": "A generalized method using category theory addresses the lack of benchmarks for non-Markovian dynamics in decision-making, proving equivalence between MDP and NMDP categories and introducing HAS for precise control.", "motivation": "Existing benchmarks fail to assess decision algorithms' handling of non-Markovian dynamics, limiting progress in systems like RL.", "method": "Devised a category theory-based approach, establishing MDP and NMDP categories and their equivalence, and introduced HAS for state dependency control.", "result": "The method effectively represents non-Markovian dynamics, enabling rigorous evaluation of decision algorithms.", "conclusion": "The approach provides a novel theoretical foundation and practical tool for understanding and testing non-Markovian dynamics in decision-making."}}
{"id": "2506.23033", "pdf": "https://arxiv.org/pdf/2506.23033", "abs": "https://arxiv.org/abs/2506.23033", "authors": ["Yash Vardhan Tomar"], "title": "Feature-Wise Mixing for Mitigating Contextual Bias in Predictive Supervised Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Bias in predictive machine learning (ML) models is a fundamental challenge\ndue to the skewed or unfair outcomes produced by biased models. Existing\nmitigation strategies rely on either post-hoc corrections or rigid constraints.\nHowever, emerging research claims that these techniques can limit scalability\nand reduce generalizability. To address this, this paper introduces a\nfeature-wise mixing framework to mitigate contextual bias. This was done by\nredistributing feature representations across multiple contextual datasets. To\nassess feature-wise mixing's effectiveness, four ML classifiers were trained\nusing cross-validation and evaluated with bias-sensitive loss functions,\nincluding disparity metrics and mean squared error (MSE), which served as a\nstandard measure of predictive performance. The proposed method achieved an\naverage bias reduction of 43.35% and a statistically significant decrease in\nMSE across all classifiers trained on mixed datasets. Additionally,\nbenchmarking against established bias mitigation techniques found that\nfeature-wise mixing consistently outperformed SMOTE oversampling and\ndemonstrated competitive effectiveness without requiring explicit bias\nattribute identification. Feature-wise mixing efficiently avoids the\ncomputational overhead typically associated with fairness-aware learning\nalgorithms. Future work could explore applying feature-wise mixing for\nreal-world fields where accurate predictions are necessary.", "AI": {"tldr": "The paper introduces a feature-wise mixing framework to mitigate bias in ML models, achieving a 43.35% bias reduction and improved predictive performance without explicit bias attribute identification.", "motivation": "Existing bias mitigation methods are limited in scalability and generalizability, prompting the need for a more flexible approach.", "method": "A feature-wise mixing framework redistributes feature representations across datasets, evaluated using bias-sensitive loss functions and cross-validation.", "result": "The method reduced bias by 43.35% and improved predictive performance (lower MSE) across classifiers, outperforming SMOTE oversampling.", "conclusion": "Feature-wise mixing is effective and efficient for bias mitigation, with potential for real-world applications requiring accurate predictions."}}
{"id": "2506.22807", "pdf": "https://arxiv.org/pdf/2506.22807", "abs": "https://arxiv.org/abs/2506.22807", "authors": ["Yueyang Li", "Shengyu Gong", "Weiming Zeng", "Nizhuan Wang", "Wai Ting Siok"], "title": "FreqDGT: Frequency-Adaptive Dynamic Graph Networks with Transformer for Cross-subject EEG Emotion Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Electroencephalography (EEG) serves as a reliable and objective signal for\nemotion recognition in affective brain-computer interfaces, offering unique\nadvantages through its high temporal resolution and ability to capture\nauthentic emotional states that cannot be consciously controlled. However,\ncross-subject generalization remains a fundamental challenge due to individual\nvariability, cognitive traits, and emotional responses. We propose FreqDGT, a\nfrequency-adaptive dynamic graph transformer that systematically addresses\nthese limitations through an integrated framework. FreqDGT introduces\nfrequency-adaptive processing (FAP) to dynamically weight emotion-relevant\nfrequency bands based on neuroscientific evidence, employs adaptive dynamic\ngraph learning (ADGL) to learn input-specific brain connectivity patterns, and\nimplements multi-scale temporal disentanglement network (MTDN) that combines\nhierarchical temporal transformers with adversarial feature disentanglement to\ncapture both temporal dynamics and ensure cross-subject robustness.\nComprehensive experiments demonstrate that FreqDGT significantly improves\ncross-subject emotion recognition accuracy, confirming the effectiveness of\nintegrating frequency-adaptive, spatial-dynamic, and temporal-hierarchical\nmodeling while ensuring robustness to individual differences. The code is\navailable at https://github.com/NZWANG/FreqDGT.", "AI": {"tldr": "FreqDGT, a frequency-adaptive dynamic graph transformer, improves cross-subject emotion recognition in EEG by integrating frequency-adaptive processing, adaptive dynamic graph learning, and multi-scale temporal disentanglement.", "motivation": "Cross-subject generalization in EEG-based emotion recognition is challenging due to individual variability and emotional response differences.", "method": "FreqDGT uses frequency-adaptive processing (FAP), adaptive dynamic graph learning (ADGL), and a multi-scale temporal disentanglement network (MTDN) to address these challenges.", "result": "FreqDGT significantly improves cross-subject emotion recognition accuracy, demonstrating robustness to individual differences.", "conclusion": "The integration of frequency-adaptive, spatial-dynamic, and temporal-hierarchical modeling in FreqDGT effectively enhances EEG-based emotion recognition."}}
{"id": "2506.23340", "pdf": "https://arxiv.org/pdf/2506.23340", "abs": "https://arxiv.org/abs/2506.23340", "authors": ["Yumeng Lin", "Xufeng Duan", "David Haslett", "Yige Chen", "Zhenguang G. Cai"], "title": "Information Loss in LLMs' Multilingual Translation: The Role of Training Data, Language Proximity, and Language Family", "categories": ["cs.CL"], "comment": null, "summary": "Large language models have achieved impressive progress in multilingual\ntranslation, yet they continue to face challenges with certain language\npairs-particularly those with limited training data or significant linguistic\ndivergence from English. This study systematically investigates how training\ndata, language proximity, and language family affect information loss in\nmultilingual translation. We evaluate two large language models, GPT-4 and\nLlama 2, by performing round-trip translations. Translation quality was\nassessed using BLEU scores and BERT similarity metrics. Our results reveal a\nrobust interaction between training data size and language distance: while\nabundant training data can mitigate the effects of linguistic divergence,\nlanguages structurally closer to English consistently yield higher translation\nquality in low-resource conditions. Among various distance metrics,\northographic, phylogenetic, syntactic, and geographical distances emerge as\nstrong predictors of translation performance. Language family also exerts an\nindependent influence. These findings contribute to a deeper understanding of\nthe linguistic constraints shaping multilingual translation in large language\nmodels, emphasizing that translation quality is shaped not only by data volume\nbut also by structural and typological relationships between languages.", "AI": {"tldr": "The study examines how training data, language proximity, and family affect multilingual translation quality in GPT-4 and Llama 2, revealing data size and structural closeness to English as key factors.", "motivation": "To understand challenges in multilingual translation, especially for low-resource or linguistically distant languages.", "method": "Evaluated GPT-4 and Llama 2 using round-trip translations, assessed with BLEU scores and BERT similarity metrics.", "result": "Abundant data mitigates linguistic divergence, but structural closeness to English improves low-resource translation. Orthographic, phylogenetic, syntactic, and geographical distances predict performance.", "conclusion": "Translation quality depends on data volume and structural/typological language relationships, highlighting linguistic constraints in multilingual models."}}
{"id": "2410.12831", "pdf": "https://arxiv.org/pdf/2410.12831", "abs": "https://arxiv.org/abs/2410.12831", "authors": ["Longchao Da", "Rui Wang", "Xiaojian Xu", "Parminder Bhatia", "Taha Kass-Hout", "Hua Wei", "Cao Xiao"], "title": "Segment as You Wish -- Free-Form Language-Based Segmentation for Medical Images", "categories": ["eess.IV", "cs.AI", "cs.CV", "68T45, 68U10, 92C55", "I.2.7; I.4.9; H.3.3; I.2.6"], "comment": "19 pages, 9 as main content. The paper was accepted to KDD2025", "summary": "Medical imaging is crucial for diagnosing a patient's health condition, and\naccurate segmentation of these images is essential for isolating regions of\ninterest to ensure precise diagnosis and treatment planning. Existing methods\nprimarily rely on bounding boxes or point-based prompts, while few have\nexplored text-related prompts, despite clinicians often describing their\nobservations and instructions in natural language. To address this gap, we\nfirst propose a RAG-based free-form text prompt generator, that leverages the\ndomain corpus to generate diverse and realistic descriptions. Then, we\nintroduce FLanS, a novel medical image segmentation model that handles various\nfree-form text prompts, including professional anatomy-informed queries,\nanatomy-agnostic position-driven queries, and anatomy-agnostic size-driven\nqueries. Additionally, our model also incorporates a symmetry-aware\ncanonicalization module to ensure consistent, accurate segmentations across\nvarying scan orientations and reduce confusion between the anatomical position\nof an organ and its appearance in the scan. FLanS is trained on a large-scale\ndataset of over 100k medical images from 7 public datasets. Comprehensive\nexperiments demonstrate the model's superior language understanding and\nsegmentation precision, along with a deep comprehension of the relationship\nbetween them, outperforming SOTA baselines on both in-domain and out-of-domain\ndatasets.", "AI": {"tldr": "A novel medical image segmentation model, FLanS, is introduced, leveraging free-form text prompts and a symmetry-aware module for precise segmentation across diverse medical imaging scenarios.", "motivation": "Addressing the gap in text-related prompts for medical image segmentation, as clinicians often use natural language descriptions, unlike existing methods relying on bounding boxes or point-based prompts.", "method": "Proposes a RAG-based text prompt generator and FLanS, a model handling diverse text prompts, including anatomy-informed and position-driven queries, with a symmetry-aware module for consistency.", "result": "FLanS outperforms SOTA baselines in language understanding and segmentation precision, validated on 100k+ medical images from 7 datasets.", "conclusion": "FLanS demonstrates superior performance in medical image segmentation by integrating free-form text prompts and symmetry-awareness, enhancing diagnostic accuracy."}}
{"id": "2506.24119", "pdf": "https://arxiv.org/pdf/2506.24119", "abs": "https://arxiv.org/abs/2506.24119", "authors": ["Bo Liu", "Leon Guertler", "Simon Yu", "Zichen Liu", "Penghui Qi", "Daniel Balcells", "Mickel Liu", "Cheston Tan", "Weiyan Shi", "Min Lin", "Wee Sun Lee", "Natasha Jaques"], "title": "SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "Work in Progress", "summary": "Recent advances in reinforcement learning have shown that language models can\ndevelop sophisticated reasoning through training on tasks with verifiable\nrewards, but these approaches depend on human-curated problem-answer pairs and\ndomain-specific reward engineering. We introduce SPIRAL, a self-play framework\nwhere models learn by playing multi-turn, zero-sum games against continuously\nimproving versions of themselves, eliminating the need for human supervision.\nThrough self-play, SPIRAL generates an infinite curriculum of progressively\nchallenging problems as models must constantly adapt to stronger opponents. To\nenable this self-play training at scale, We implement a fully online,\nmulti-turn, multi-agent reinforcement learning system for LLMs and propose\nrole-conditioned advantage estimation (RAE) to stabilize multi-agent training.\nUsing SPIRAL, self-play on zero-sum games produces reasoning capabilities that\ntransfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6%\nimprovement on math and 8.4% on general reasoning, outperforming SFT on 25,000\nexpert game trajectories. Analysis reveals that this transfer occurs through\nthree cognitive patterns: systematic decomposition, expected value calculation,\nand case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple\nNegotiation) further enhances performance as each game develops distinct\nreasoning strengths. Applying SPIRAL to a strong reasoning model\n(DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These\nresults demonstrate that zero-sum games naturally develop transferable\nreasoning capabilities, highlighting a promising direction for autonomous\nreasoning development.", "AI": {"tldr": "SPIRAL is a self-play framework for training language models through zero-sum games, eliminating human supervision and enabling transferable reasoning capabilities.", "motivation": "To reduce reliance on human-curated data and domain-specific rewards in reinforcement learning for reasoning tasks.", "method": "Introduces SPIRAL, a self-play framework with multi-turn, zero-sum games, role-conditioned advantage estimation (RAE), and online multi-agent reinforcement learning.", "result": "Models trained with SPIRAL show improved reasoning (e.g., 8.6% on math, 8.4% on general reasoning) and transfer capabilities, outperforming supervised fine-tuning.", "conclusion": "Zero-sum games in self-play frameworks like SPIRAL naturally develop transferable reasoning, offering a promising path for autonomous reasoning development."}}
{"id": "2506.23036", "pdf": "https://arxiv.org/pdf/2506.23036", "abs": "https://arxiv.org/abs/2506.23036", "authors": ["Zain ul Abdeen", "Ming Jin"], "title": "Fragile, Robust, and Antifragile: A Perspective from Parameter Responses in Reinforcement Learning Under Stress", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper explores Reinforcement learning (RL) policy robustness by\nsystematically analyzing network parameters under internal and external\nstresses. Inspired by synaptic plasticity in neuroscience, synaptic filtering\nintroduces internal stress by selectively perturbing parameters, while\nadversarial attacks apply external stress through modified agent observations.\nThis dual approach enables the classification of parameters as fragile, robust,\nor antifragile, based on their influence on policy performance in clean and\nadversarial settings. Parameter scores are defined to quantify these\ncharacteristics, and the framework is validated on PPO-trained agents in Mujoco\ncontinuous control environments. The results highlight the presence of\nantifragile parameters that enhance policy performance under stress,\ndemonstrating the potential of targeted filtering techniques to improve RL\npolicy adaptability. These insights provide a foundation for future\nadvancements in the design of robust and antifragile RL systems.", "AI": {"tldr": "The paper analyzes RL policy robustness by testing network parameters under internal (synaptic filtering) and external (adversarial attacks) stresses, classifying parameters as fragile, robust, or antifragile. Validated on PPO-trained agents, it identifies antifragile parameters that improve performance under stress.", "motivation": "To understand and enhance RL policy robustness by examining how parameters respond to stress, inspired by synaptic plasticity in neuroscience.", "method": "Uses synaptic filtering (internal stress) and adversarial attacks (external stress) to classify parameters. Defines scores to quantify fragility, robustness, or antifragility. Validates on PPO-trained agents in Mujoco environments.", "result": "Identifies antifragile parameters that boost policy performance under stress, showcasing the potential of targeted filtering for RL adaptability.", "conclusion": "The framework lays groundwork for designing robust and antifragile RL systems, with implications for future advancements in RL adaptability."}}
{"id": "2506.22814", "pdf": "https://arxiv.org/pdf/2506.22814", "abs": "https://arxiv.org/abs/2506.22814", "authors": ["Andrew Hamara", "Andrew C. Freeman"], "title": "Efficient Multi-Crop Saliency Partitioning for Automatic Image Cropping", "categories": ["cs.CV"], "comment": null, "summary": "Automatic image cropping aims to extract the most visually salient regions\nwhile preserving essential composition elements. Traditional saliency-aware\ncropping methods optimize a single bounding box, making them ineffective for\napplications requiring multiple disjoint crops. In this work, we extend the\nFixed Aspect Ratio Cropping algorithm to efficiently extract multiple\nnon-overlapping crops in linear time. Our approach dynamically adjusts\nattention thresholds and removes selected crops from consideration without\nrecomputing the entire saliency map. We discuss qualitative results and\nintroduce the potential for future datasets and benchmarks.", "AI": {"tldr": "Extends Fixed Aspect Ratio Cropping to efficiently extract multiple non-overlapping crops in linear time by dynamically adjusting attention thresholds.", "motivation": "Traditional methods optimize a single bounding box, limiting effectiveness for applications needing multiple disjoint crops.", "method": "Extends Fixed Aspect Ratio Cropping algorithm, dynamically adjusts attention thresholds, and removes selected crops without recomputing the saliency map.", "result": "Efficient extraction of multiple non-overlapping crops in linear time.", "conclusion": "Qualitative results are discussed, with potential for future datasets and benchmarks."}}
{"id": "2506.23342", "pdf": "https://arxiv.org/pdf/2506.23342", "abs": "https://arxiv.org/abs/2506.23342", "authors": ["Akim Tsvigun", "Daniil Vasilev", "Ivan Tsvigun", "Ivan Lysenko", "Talgat Bektleuov", "Aleksandr Medvedev", "Uliana Vinogradova", "Nikita Severin", "Mikhail Mozikov", "Andrey Savchenko", "Rostislav Grigorev", "Ramil Kuleev", "Fedor Zhdanov", "Artem Shelmanov", "Ilya Makarov"], "title": "ATGen: A Framework for Active Text Generation", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at ACL 2025 System Demonstrations", "summary": "Active learning (AL) has demonstrated remarkable potential in reducing the\nannotation effort required for training machine learning models. However,\ndespite the surging popularity of natural language generation (NLG) tasks in\nrecent years, the application of AL to NLG has been limited. In this paper, we\nintroduce Active Text Generation (ATGen) - a comprehensive framework that\nbridges AL with text generation tasks, enabling the application of\nstate-of-the-art AL strategies to NLG. Our framework simplifies AL-empowered\nannotation in NLG tasks using both human annotators and automatic annotation\nagents based on large language models (LLMs). The framework supports LLMs\ndeployed as services, such as ChatGPT and Claude, or operated on-premises.\nFurthermore, ATGen provides a unified platform for smooth implementation and\nbenchmarking of novel AL strategies tailored to NLG tasks. Finally, we present\nevaluation results for state-of-the-art AL strategies across diverse settings\nand multiple text generation tasks. We show that ATGen reduces both the effort\nof human annotators and costs associated with API calls to LLM-based annotation\nagents. The code of the framework is available on GitHub under the MIT license.\nThe video presentation is available at http://atgen-video.nlpresearch.group", "AI": {"tldr": "ATGen is a framework integrating active learning (AL) with text generation (NLG) tasks, reducing annotation effort and costs by leveraging human annotators and LLMs like ChatGPT.", "motivation": "Despite AL's potential, its application to NLG tasks has been limited. ATGen aims to bridge this gap.", "method": "ATGen combines AL strategies with NLG, supporting both human annotators and LLM-based automatic annotation.", "result": "The framework reduces human annotation effort and LLM API costs, with evaluations showing effectiveness across diverse NLG tasks.", "conclusion": "ATGen successfully integrates AL with NLG, offering a practical solution for efficient annotation and benchmarking."}}
{"id": "2410.20073", "pdf": "https://arxiv.org/pdf/2410.20073", "abs": "https://arxiv.org/abs/2410.20073", "authors": ["Yijie Zhang", "Luzhe Huang", "Nir Pillar", "Yuzhu Li", "Hanlong Chen", "Aydogan Ozcan"], "title": "Pixel super-resolved virtual staining of label-free tissue using diffusion models", "categories": ["eess.IV", "cs.CV", "cs.LG", "physics.med-ph", "physics.optics"], "comment": "39 Pages, 7 Figures", "summary": "Virtual staining of tissue offers a powerful tool for transforming label-free\nmicroscopy images of unstained tissue into equivalents of histochemically\nstained samples. This study presents a diffusion model-based super-resolution\nvirtual staining approach utilizing a Brownian bridge process to enhance both\nthe spatial resolution and fidelity of label-free virtual tissue staining,\naddressing the limitations of traditional deep learning-based methods. Our\napproach integrates novel sampling techniques into a diffusion model-based\nimage inference process to significantly reduce the variance in the generated\nvirtually stained images, resulting in more stable and accurate outputs.\nBlindly applied to lower-resolution auto-fluorescence images of label-free\nhuman lung tissue samples, the diffusion-based super-resolution virtual\nstaining model consistently outperformed conventional approaches in resolution,\nstructural similarity and perceptual accuracy, successfully achieving a\nsuper-resolution factor of 4-5x, increasing the output space-bandwidth product\nby 16-25-fold compared to the input label-free microscopy images.\nDiffusion-based super-resolved virtual tissue staining not only improves\nresolution and image quality but also enhances the reliability of virtual\nstaining without traditional chemical staining, offering significant potential\nfor clinical diagnostics.", "AI": {"tldr": "A diffusion model-based super-resolution virtual staining method enhances label-free tissue images, outperforming traditional methods in resolution and accuracy.", "motivation": "To improve the spatial resolution and fidelity of virtual tissue staining, addressing limitations of deep learning-based methods.", "method": "Uses a Brownian bridge process and novel sampling techniques in a diffusion model to reduce variance and enhance stability in virtual staining.", "result": "Achieves 4-5x super-resolution, 16-25x higher space-bandwidth product, and better structural similarity and perceptual accuracy than conventional methods.", "conclusion": "The approach improves virtual staining reliability and quality, offering clinical diagnostic potential without chemical staining."}}
{"id": "1610.09431", "pdf": "https://arxiv.org/pdf/1610.09431", "abs": "https://arxiv.org/abs/1610.09431", "authors": ["Omar Claflin"], "title": "Attention acts to suppress goal-based conflict under high competition", "categories": ["q-bio.NC", "cs.AI"], "comment": "25 pages, 3 figures, 3 tables", "summary": "It is known that when multiple stimuli are present, top-down attention\nselectively enhances the neural signal in the visual cortex for task-relevant\nstimuli, but this has been tested only under conditions of minimal competition\nof visual attention. Here we show during high competition, that is, two stimuli\nin a shared receptive field possessing opposing modulatory goals, top-down\nattention suppresses both task-relevant and irrelevant neural signals within\n100 ms of stimuli onset. This non-selective engagement of top-down attentional\nresources serves to reduce the feedforward signal representing irrelevant\nstimuli.", "AI": {"tldr": "Top-down attention suppresses both task-relevant and irrelevant neural signals under high competition, reducing feedforward signals of irrelevant stimuli.", "motivation": "To investigate how top-down attention operates under high competition, where stimuli share a receptive field with opposing modulatory goals.", "method": "Examined neural signals in the visual cortex during high competition conditions, measuring responses within 100 ms of stimuli onset.", "result": "Top-down attention non-selectively suppresses both task-relevant and irrelevant neural signals under high competition.", "conclusion": "Under high competition, top-down attention broadly suppresses neural signals to reduce interference from irrelevant stimuli."}}
{"id": "2506.23041", "pdf": "https://arxiv.org/pdf/2506.23041", "abs": "https://arxiv.org/abs/2506.23041", "authors": ["Chengyu Dong", "Huan Gui", "Noveen Sachdeva", "Long Jin", "Ke Yin", "Jingbo Shang", "Lichan Hong", "Ed H. Chi", "Zhe Zhao"], "title": "ReMem: Mutual Information-Aware Fine-tuning of Pretrained Vision Transformers for Effective Knowledge Distillation", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Knowledge distillation from pretrained visual representation models offers an\neffective approach to improve small, task-specific production models. However,\nthe effectiveness of such knowledge transfer drops significantly when\ndistilling from strong models that are pretrained in a large scale. In this\npaper, we address this challenge for pretrained Vision Transformers (ViTs) by\nexploring methods to fine-tune them for more effective knowledge transfer.\nMotivated by the connection between mutual information and distillation\neffectiveness, we propose to employ mutual information-aware optimization\nduring finetuning. For small or highly-imbalanced downstream datasets where\nsuch optimization becomes less effective, we introduce a simple yet effective\nheuristic of reweighting MLP blocks. This approach is inspired by our\nobservation that top MLP blocks are primarily responsible for mutual\ninformation loss. Our method enables small student models to benefit from those\npretrained models among the strongest.", "AI": {"tldr": "The paper addresses the challenge of effective knowledge distillation from large-scale pretrained Vision Transformers (ViTs) to smaller models, proposing mutual information-aware optimization and MLP block reweighting for improved transfer.", "motivation": "The effectiveness of knowledge transfer drops when distilling from large-scale pretrained models, especially for small or imbalanced datasets.", "method": "Proposes mutual information-aware optimization during finetuning and reweights MLP blocks to address mutual information loss.", "result": "Enables small student models to benefit effectively from strong pretrained models.", "conclusion": "The proposed methods enhance knowledge distillation from large-scale pretrained ViTs to smaller models, particularly for challenging datasets."}}
{"id": "2506.22817", "pdf": "https://arxiv.org/pdf/2506.22817", "abs": "https://arxiv.org/abs/2506.22817", "authors": ["Xingyilang Yin", "Jiale Wang", "Xi Yang", "Mutian Xu", "Xu Gu", "Nannan Wang"], "title": "Unleashing the Multi-View Fusion Potential: Noise Correction in VLM for Open-Vocabulary 3D Scene Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Recent open-vocabulary 3D scene understanding approaches mainly focus on\ntraining 3D networks through contrastive learning with point-text pairs or by\ndistilling 2D features into 3D models via point-pixel alignment. While these\nmethods show considerable performance in benchmarks with limited vocabularies,\nthey struggle to handle diverse object categories as the limited amount of 3D\ndata upbound training strong open-vocabulary 3d models. We observe that 2D\nmulti-view fusion methods take precedence in understanding diverse concepts in\n3D scenes. However, inherent noises in vision-language models lead multi-view\nfusion to sub-optimal performance. To this end, we introduce MVOV3D, a novel\napproach aimed at unleashing the potential of 2D multi-view fusion for\nopen-vocabulary 3D scene understanding. We focus on reducing the inherent\nnoises without training, thereby preserving the generalizability while\nenhancing open-world capabilities. Specifically, MVOV3D improves multi-view 2D\nfeatures by leveraging precise region-level image features and text features\nencoded by CLIP encoders and incorporates 3D geometric priors to optimize\nmulti-view fusion. Extensive experiments on various datasets demonstrate the\neffectiveness of our method. Notably, our MVOV3D achieves a new record with\n14.7% mIoU on ScanNet200 and 16.2% mIoU on Matterport160 for challenge\nopen-vocabulary semantic segmentation, outperforming current leading trained 3D\nnetworks by a significant margin.", "AI": {"tldr": "MVOV3D improves open-vocabulary 3D scene understanding by reducing noise in 2D multi-view fusion without training, outperforming existing methods.", "motivation": "Existing methods struggle with diverse object categories due to limited 3D data and noisy 2D multi-view fusion.", "method": "MVOV3D enhances 2D multi-view features using CLIP encoders and 3D geometric priors, avoiding training.", "result": "Achieves 14.7% mIoU on ScanNet200 and 16.2% mIoU on Matterport160, surpassing trained 3D networks.", "conclusion": "MVOV3D effectively leverages 2D fusion for open-vocabulary 3D understanding, setting new benchmarks."}}
{"id": "2506.23377", "pdf": "https://arxiv.org/pdf/2506.23377", "abs": "https://arxiv.org/abs/2506.23377", "authors": ["Taejin Kim", "Siun-Chuon Mau", "Konrad Vesey"], "title": "Perspective Dial: Measuring Perspective of Text and Guiding LLM Outputs", "categories": ["cs.CL", "cs.AI"], "comment": "7 pages, 5 main pages of text, 5 figures, 2 tables. Research work\n  performed at CACI INTL INC", "summary": "Large language models (LLMs) are used in a variety of mission-critical roles.\nDue to the rapidly developing nature of LLMs, there is a lack of quantifiable\nunderstanding of the bias and perspective associated with LLM output. Inspired\nby this need, this paper considers the broader issue of perspective or\nviewpoint of general text and perspective control of large-language model (LLM)\noutput. Perspective-Dial consists of two main components: a (1) metric space,\ndubbed Perspective Space, that enables quantitative measurements of different\nperspectives regarding a topic, and the use of (2) Systematic Prompt\nEngineering that utilizes greedy-coordinate descent to control LLM output\nperspective based on measurement feedback from the Perspective Space. The\nempirical nature of the approach allows progress to side step a principled\nunderstanding of perspective or bias -- effectively quantifying and adjusting\noutputs for a variety of topics. Potential applications include detection,\ntracking and mitigation of LLM bias, narrative detection, sense making and\ntracking in public discourse, and debate bot advocating given perspective.", "AI": {"tldr": "The paper introduces Perspective-Dial, a framework for quantifying and controlling the perspective or bias in LLM outputs using a metric space and systematic prompt engineering.", "motivation": "There's a lack of quantifiable understanding of bias and perspective in LLM outputs, which is critical given their mission-critical roles.", "method": "The approach involves (1) Perspective Space for measuring perspectives and (2) Systematic Prompt Engineering using greedy-coordinate descent to control LLM outputs.", "result": "The method empirically quantifies and adjusts LLM outputs for various topics without needing a deep theoretical understanding of bias.", "conclusion": "Perspective-Dial enables applications like bias detection, narrative tracking, and debate bots, addressing the need for perspective control in LLMs."}}
{"id": "2503.17786", "pdf": "https://arxiv.org/pdf/2503.17786", "abs": "https://arxiv.org/abs/2503.17786", "authors": ["Tommaso Di Noto", "Sofyan Jankowski", "Francesco Puccinelli", "Guillaume Marie", "Sebastien Tourbier", "Yasser Aleman-Gomez", "Oscar Esteban", "Ricardo Corredor-Jerez", "Guillaume Saliou", "Patric Hagmann", "Meritxell Bach Cuadra", "Jonas Richiardi"], "title": "Assessing workflow impact and clinical utility of AI-assisted brain aneurysm detection: a multi-reader study", "categories": ["eess.IV", "cs.CV"], "comment": "This paper has been accepted for publication in the journal\n  NeuroImage: Clinical (DOI: https://doi.org/10.1016/j.nicl.2025.103835)", "summary": "Despite the plethora of AI-based algorithms developed for anomaly detection\nin radiology, subsequent integration into clinical setting is rarely evaluated.\nIn this work, we assess the applicability and utility of an AI-based model for\nbrain aneurysm detection comparing the performance of two readers with\ndifferent levels of experience (2 and 13 years). We aim to answer the following\nquestions: 1) Do the readers improve their performance when assisted by the AI\nalgorithm? 2) How much does the AI algorithm impact routine clinical workflow?\nWe reuse and enlarge our open-access, Time-Of-Flight Magnetic Resonance\nAngiography dataset (N=460). We use 360 subjects for training/validating our\nalgorithm and 100 as unseen test set for the reading session. Even though our\nmodel reaches state-of-the-art results on the test set (sensitivity=74%, false\npositive rate=1.6), we show that neither the junior nor the senior reader\nsignificantly increase their sensitivity (p=0.59, p=1, respectively). In\naddition, we find that reading time for both readers is significantly higher in\nthe \"AI-assisted\" setting than in the \"Unassisted\" (+15 seconds, on average;\np=3x10^(-4) junior, p=3x10^(-5) senior). The confidence reported by the readers\nis unchanged across the two settings, indicating that the AI assistance does\nnot influence the certainty of the diagnosis. Our findings highlight the\nimportance of clinical validation of AI algorithms in a clinical setting\ninvolving radiologists. This study should serve as a reminder to the community\nto always examine the real-word effectiveness and workflow impact of proposed\nalgorithms.", "AI": {"tldr": "The study evaluates an AI-based brain aneurysm detection model's clinical utility, finding no significant improvement in radiologists' performance or confidence, and increased reading time with AI assistance.", "motivation": "To assess the real-world applicability and impact of AI algorithms in clinical radiology, focusing on whether AI assistance improves radiologists' performance and workflow efficiency.", "method": "The study reused and expanded an open-access dataset (N=460), training/validating the AI model on 360 subjects and testing on 100. Two radiologists with different experience levels (2 and 13 years) evaluated the model's impact on their performance and workflow.", "result": "The AI model achieved state-of-the-art performance (74% sensitivity, 1.6% false positive rate), but neither radiologist showed significant sensitivity improvement with AI assistance. Reading time increased by 15 seconds on average, with no change in diagnostic confidence.", "conclusion": "Clinical validation of AI algorithms is crucial, as real-world effectiveness and workflow impact may differ from theoretical performance. The study emphasizes the need for thorough evaluation before clinical integration."}}
{"id": "2402.09146", "pdf": "https://arxiv.org/pdf/2402.09146", "abs": "https://arxiv.org/abs/2402.09146", "authors": ["Muhammad Kashif", "Muhammad Shafique"], "title": "ResQuNNs:Towards Enabling Deep Learning in Quantum Convolution Neural Networks", "categories": ["cs.LG", "cs.AI", "quant-ph"], "comment": null, "summary": "In this paper, we present a novel framework for enhancing the performance of\nQuanvolutional Neural Networks (QuNNs) by introducing trainable quanvolutional\nlayers and addressing the critical challenges associated with them. Traditional\nquanvolutional layers, although beneficial for feature extraction, have largely\nbeen static, offering limited adaptability. Unlike state-of-the-art, our\nresearch overcomes this limitation by enabling training within these layers,\nsignificantly increasing the flexibility and potential of QuNNs. However, the\nintroduction of multiple trainable quanvolutional layers induces complexities\nin gradient-based optimization, primarily due to the difficulty in accessing\ngradients across these layers. To resolve this, we propose a novel\narchitecture, Residual Quanvolutional Neural Networks (ResQuNNs), leveraging\nthe concept of residual learning, which facilitates the flow of gradients by\nadding skip connections between layers. By inserting residual blocks between\nquanvolutional layers, we ensure enhanced gradient access throughout the\nnetwork, leading to improved training performance. Moreover, we provide\nempirical evidence on the strategic placement of these residual blocks within\nQuNNs. Through extensive experimentation, we identify an efficient\nconfiguration of residual blocks, which enables gradients across all the layers\nin the network that eventually results in efficient training. Our findings\nsuggest that the precise location of residual blocks plays a crucial role in\nmaximizing the performance gains in QuNNs. Our results mark a substantial step\nforward in the evolution of quantum deep learning, offering new avenues for\nboth theoretical development and practical quantum computing applications.", "AI": {"tldr": "A novel framework enhances Quanvolutional Neural Networks (QuNNs) by introducing trainable layers and residual learning to improve gradient flow and training performance.", "motivation": "Traditional quanvolutional layers are static and lack adaptability, limiting QuNNs' potential. This work aims to overcome this by enabling training within these layers.", "method": "Proposes Residual Quanvolutional Neural Networks (ResQuNNs) with skip connections (residual blocks) between layers to enhance gradient access and training efficiency.", "result": "Empirical evidence shows strategic placement of residual blocks improves gradient flow and training performance, marking a significant advancement in quantum deep learning.", "conclusion": "The framework advances quantum deep learning by improving QuNN adaptability and training, opening new theoretical and practical possibilities."}}
{"id": "2506.23053", "pdf": "https://arxiv.org/pdf/2506.23053", "abs": "https://arxiv.org/abs/2506.23053", "authors": ["Hanlin Dong", "Arian Prabowo", "Hao Xue", "Flora D. Salim"], "title": "Double-Diffusion: Diffusion Conditioned Diffusion Probabilistic Model For Air Quality Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Air quality prediction is a challenging forecasting task due to its\nspatio-temporal complexity and the inherent dynamics as well as uncertainty.\nMost of the current models handle these two challenges by applying Graph Neural\nNetworks or known physics principles, and quantifying stochasticity through\nprobabilistic networks like Diffusion models. Nevertheless, finding the right\nbalancing point between the certainties and uncertainties remains an open\nquestion. Therefore, we propose Double-Diffusion, a novel diffusion\nprobabilistic model that harnesses the power of known physics to guide air\nquality forecasting with stochasticity. To the best of our knowledge, while\nprecedents have been made of using conditional diffusion models to predict air\npollution, this is the first attempt to use physics as a conditional generative\napproach for air quality prediction. Along with a sampling strategy adopted\nfrom image restoration and a new denoiser architecture, Double-Diffusion ranks\nfirst in most evaluation scenarios across two real-life datasets compared with\nother probabilistic models, it also cuts inference time by 50% to 30% while\nenjoying an increase between 3-12% in Continuous Ranked Probabilistic Score\n(CRPS).", "AI": {"tldr": "Double-Diffusion, a novel diffusion probabilistic model, combines physics principles with stochasticity for air quality prediction, outperforming other models in accuracy and efficiency.", "motivation": "Addressing the challenge of balancing certainty and uncertainty in air quality prediction due to spatio-temporal complexity and inherent dynamics.", "method": "Proposes Double-Diffusion, a physics-guided diffusion probabilistic model, with a sampling strategy from image restoration and a new denoiser architecture.", "result": "Ranks first in most evaluations, reduces inference time by 30-50%, and improves CRPS by 3-12%.", "conclusion": "Double-Diffusion effectively integrates physics and stochasticity, setting a new benchmark for air quality prediction."}}
{"id": "2506.22819", "pdf": "https://arxiv.org/pdf/2506.22819", "abs": "https://arxiv.org/abs/2506.22819", "authors": ["Ramya Hebbalaguppe", "Tamoghno Kandar", "Abhinav Nagpal", "Chetan Arora"], "title": "Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration", "categories": ["cs.CV", "cs.LG"], "comment": "26 pages", "summary": "Vision-language models (VLM) have demonstrated impressive performance in\nimage recognition by leveraging self-supervised training on large datasets.\nTheir performance can be further improved by adapting to the test sample using\ntest-time prompt tuning (TPT). Unfortunately, the singular focus of TPT\napproaches on improving the accuracy suffers from tunnel vision, and leads to\ndegradation in confidence calibration. This limits the applicability of TPT in\ncritical applications.\n  We make three contributions in this work. (1) We posit that random or naive\ninitialization of prompts leads to overfitting on a particular test sample, and\nis the main reason for miscalibration of the VLM after TPT. To mitigate the\nproblem, we propose careful initialization of test time prompt using prior\nknowledge about the target label attributes from a large language model (LLM);\n(2) To further maintain the quality of prompts during \\tpt, we propose a novel\nregularization loss to reduce intraclass distance, and increase inter-class\ndistance between the learnt\n  Through extensive experiments on different CLIP architectures and 15\ndatasets, we show that our approach can effectively improve the calibration\nafter TPT. We report an average expected calibration error (ECE) of 4.11 with\nour method, TCA, compared to 11.7 for vanilla TPT, 6.12 for C-TPT (ICLR'24),\n6.78 for DiffTPT (CVPR'23), and 8.43 for PromptAlign (NeurIPS'23). The code is\npublicly accessible at:\nhttps://github.com/rhebbalaguppe/TCA_PromptWithoutPanic.", "AI": {"tldr": "The paper addresses the miscalibration issue in test-time prompt tuning (TPT) for vision-language models (VLM) by proposing careful prompt initialization using LLM knowledge and a novel regularization loss.", "motivation": "TPT improves VLM accuracy but degrades confidence calibration, limiting its use in critical applications.", "method": "Initializes prompts using LLM knowledge and introduces a regularization loss to reduce intraclass and increase inter-class distances.", "result": "Achieves an average ECE of 4.11, outperforming other methods (vanilla TPT: 11.7, C-TPT: 6.12, DiffTPT: 6.78, PromptAlign: 8.43).", "conclusion": "The proposed approach effectively improves calibration in TPT, making VLMs more reliable for critical applications."}}
{"id": "2506.23393", "pdf": "https://arxiv.org/pdf/2506.23393", "abs": "https://arxiv.org/abs/2506.23393", "authors": ["Eugene J. Yu", "Dawei Zhu", "Yifan Song", "Xiangyu Wong", "Jiebin Zhang", "Wenxuan Shi", "Xiaoguang Li", "Qun Liu", "Sujian Li"], "title": "Hierarchical Memory Organization for Wikipedia Generation", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Main Conference", "summary": "Generating Wikipedia articles autonomously is a challenging task requiring\nthe integration of accurate, comprehensive, and well-structured information\nfrom diverse sources. This paper introduces the Memory Organization-based\nGeneration (MOG) framework, a novel approach to address these challenges by\nleveraging a hierarchical memory architecture. MOG extracts fine-grained memory\nunits from web documents, recursively organizes them into a Wikipedia-style\nhierarchical structure, and uses this structure to guide the generation\nprocess. This ensures alignment between memory and the article outline,\nimproving both informativeness and verifiability while minimizing\nhallucinations. Additionally, a citation module is implemented to enhance\ntraceability by linking every generated sentence to specific memory units.\nEvaluations on our newly created WikiStart dataset demonstrate that MOG\noutperforms baseline methods in producing informative and reliable articles,\nmaking it particularly robust in real-world scenarios.", "AI": {"tldr": "The paper introduces MOG, a framework for generating Wikipedia articles using hierarchical memory architecture to improve accuracy and reduce hallucinations.", "motivation": "Autonomous Wikipedia article generation is complex due to the need for accurate, structured information from diverse sources.", "method": "MOG extracts memory units from web documents, organizes them hierarchically, and uses this structure to guide generation, with a citation module for traceability.", "result": "MOG outperforms baselines on the WikiStart dataset, producing more informative and reliable articles.", "conclusion": "MOG is effective for real-world Wikipedia article generation, enhancing informativeness and verifiability."}}
{"id": "2503.20830", "pdf": "https://arxiv.org/pdf/2503.20830", "abs": "https://arxiv.org/abs/2503.20830", "authors": ["Chamani Shiranthika", "Zahra Hafezi Kafshgari", "Hadi Hadizadeh", "Parvaneh Saeedi"], "title": "MedSegNet10: A Publicly Accessible Network Repository for Split Federated Medical Image Segmentation", "categories": ["eess.IV", "cs.CV"], "comment": "20 pages, 14 figures", "summary": "Machine Learning (ML) and Deep Learning (DL) have shown significant promise\nin healthcare, particularly in medical image segmentation, which is crucial for\naccurate disease diagnosis and treatment planning. Despite their potential,\nchallenges such as data privacy concerns, limited annotated data, and\ninadequate training data persist. Decentralized learning approaches such as\nfederated learning (FL), split learning (SL), and split federated learning\n(SplitFed/SFL) address these issues effectively. This paper introduces\n\"MedSegNet10,\" a publicly accessible repository designed for medical image\nsegmentation using split-federated learning. MedSegNet10 provides a collection\nof pre-trained neural network architectures optimized for various medical image\ntypes, including microscopic images of human blastocysts, dermatoscopic images\nof skin lesions, and endoscopic images of lesions, polyps, and ulcers, with\napplications extending beyond these examples. By leveraging SplitFed's\nbenefits, MedSegNet10 allows collaborative training on privately stored,\nhorizontally split data, ensuring privacy and integrity. This repository\nsupports researchers, practitioners, trainees, and data scientists, aiming to\nadvance medical image segmentation while maintaining patient data privacy. The\nrepository is available at: https://vault.sfu.ca/index.php/s/ryhf6t12O0sobuX\n(password upon request to the authors).", "AI": {"tldr": "MedSegNet10 is a public repository for medical image segmentation using split-federated learning, addressing privacy and data scarcity challenges.", "motivation": "To overcome data privacy concerns and limited annotated data in medical image segmentation using decentralized learning approaches.", "method": "Utilizes split-federated learning (SplitFed/SFL) for collaborative training on privately stored, horizontally split data.", "result": "Provides pre-trained neural network architectures optimized for various medical image types, ensuring privacy and integrity.", "conclusion": "MedSegNet10 supports researchers and practitioners in advancing medical image segmentation while maintaining patient data privacy."}}
{"id": "2504.15071", "pdf": "https://arxiv.org/pdf/2504.15071", "abs": "https://arxiv.org/abs/2504.15071", "authors": ["Louis Bradshaw", "Simon Colton"], "title": "Aria-MIDI: A Dataset of Piano MIDI Files for Symbolic Music Modeling", "categories": ["cs.SD", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce an extensive new dataset of MIDI files, created by transcribing\naudio recordings of piano performances into their constituent notes. The data\npipeline we use is multi-stage, employing a language model to autonomously\ncrawl and score audio recordings from the internet based on their metadata,\nfollowed by a stage of pruning and segmentation using an audio classifier. The\nresulting dataset contains over one million distinct MIDI files, comprising\nroughly 100,000 hours of transcribed audio. We provide an in-depth analysis of\nour techniques, offering statistical insights, and investigate the content by\nextracting metadata tags, which we also provide. Dataset available at\nhttps://github.com/loubbrad/aria-midi.", "AI": {"tldr": "A new dataset of over one million MIDI files, transcribed from piano performances, is introduced, with detailed analysis and metadata tags provided.", "motivation": "To create a large-scale, high-quality MIDI dataset for piano performances by leveraging automated transcription and metadata scoring.", "method": "A multi-stage pipeline involving a language model for crawling/scoring audio, pruning/segmentation via an audio classifier, and transcription into MIDI files.", "result": "Over one million MIDI files (100,000 hours of transcribed audio) with metadata and statistical insights.", "conclusion": "The dataset is a valuable resource for music research, with tools and metadata provided for further analysis."}}
{"id": "2506.23055", "pdf": "https://arxiv.org/pdf/2506.23055", "abs": "https://arxiv.org/abs/2506.23055", "authors": ["Hiro Taiyo Hamada", "Ippei Fujisawa", "Genji Kawakita", "Yuki Yamada"], "title": "Measuring How LLMs Internalize Human Psychological Concepts: A preliminary analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) such as ChatGPT have shown remarkable abilities\nin producing human-like text. However, it is unclear how accurately these\nmodels internalize concepts that shape human thought and behavior. Here, we\ndeveloped a quantitative framework to assess concept alignment between LLMs and\nhuman psychological dimensions using 43 standardized psychological\nquestionnaires, selected for their established validity in measuring distinct\npsychological constructs. Our method evaluates how accurately language models\nreconstruct and classify questionnaire items through pairwise similarity\nanalysis. We compared resulting cluster structures with the original\ncategorical labels using hierarchical clustering. A GPT-4 model achieved\nsuperior classification accuracy (66.2\\%), significantly outperforming GPT-3.5\n(55.9\\%) and BERT (48.1\\%), all exceeding random baseline performance (31.9\\%).\nWe also demonstrated that the estimated semantic similarity from GPT-4 is\nassociated with Pearson's correlation coefficients of human responses in\nmultiple psychological questionnaires. This framework provides a novel approach\nto evaluate the alignment of the human-LLM concept and identify potential\nrepresentational biases. Our findings demonstrate that modern LLMs can\napproximate human psychological constructs with measurable accuracy, offering\ninsights for developing more interpretable AI systems.", "AI": {"tldr": "The paper evaluates how well LLMs like GPT-4 align with human psychological concepts using standardized questionnaires and similarity analysis. GPT-4 outperforms other models in classification accuracy and correlates with human responses.", "motivation": "To assess whether LLMs accurately internalize human psychological constructs and identify potential biases in their representations.", "method": "A quantitative framework using 43 psychological questionnaires, pairwise similarity analysis, and hierarchical clustering to compare LLM outputs with human constructs.", "result": "GPT-4 achieved 66.2% classification accuracy, surpassing GPT-3.5 (55.9%) and BERT (48.1%), and correlated with human response patterns.", "conclusion": "Modern LLMs can approximate human psychological constructs with measurable accuracy, aiding the development of more interpretable AI systems."}}
{"id": "2506.22832", "pdf": "https://arxiv.org/pdf/2506.22832", "abs": "https://arxiv.org/abs/2506.22832", "authors": ["Alexander Gambashidze", "Li Pengyi", "Matvey Skripkin", "Andrey Galichin", "Anton Gusarov", "Konstantin Sobolev", "Andrey Kuznetsov", "Ivan Oseledets"], "title": "Listener-Rewarded Thinking in VLMs for Image Preferences", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Training robust and generalizable reward models for human visual preferences\nis essential for aligning text-to-image and text-to-video generative models\nwith human intent. However, current reward models often fail to generalize, and\nsupervised fine-tuning leads to memorization, demanding complex annotation\npipelines. While reinforcement learning (RL), specifically Group Relative\nPolicy Optimization (GRPO), improves generalization, we uncover a key failure\nmode: a significant drop in reasoning accuracy occurs when a model's reasoning\ntrace contradicts that of an independent, frozen vision-language model\n(\"listener\") evaluating the same output. To address this, we introduce a\nlistener-augmented GRPO framework. Here, the listener re-evaluates the\nreasoner's chain-of-thought to provide a dense, calibrated confidence score,\nshaping the RL reward signal. This encourages the reasoner not only to answer\ncorrectly, but to produce explanations that are persuasive to an independent\nmodel. Our listener-shaped reward scheme achieves best accuracy on the\nImageReward benchmark (67.4%), significantly improves out-of-distribution (OOD)\nperformance on a large-scale human preference dataset (1.2M votes, up to +6%\nover naive reasoner), and reduces reasoning contradictions compared to strong\nGRPO and SFT baselines. These results demonstrate that listener-based rewards\nprovide a scalable, data-efficient path to aligning vision-language models with\nnuanced human preferences. We will release our reasoning model here:\nhttps://huggingface.co/alexgambashidze/qwen2.5vl_image_preference_reasoner.", "AI": {"tldr": "The paper introduces a listener-augmented GRPO framework to improve reward models for human visual preferences by aligning reasoning traces with an independent vision-language model, achieving better accuracy and generalization.", "motivation": "Current reward models for human visual preferences often fail to generalize, and supervised fine-tuning leads to memorization, requiring complex annotation pipelines.", "method": "The proposed listener-augmented GRPO framework uses a frozen vision-language model (listener) to re-evaluate the reasoner's chain-of-thought, providing a dense, calibrated confidence score to shape the RL reward signal.", "result": "The method achieves 67.4% accuracy on the ImageReward benchmark, improves OOD performance by up to +6%, and reduces reasoning contradictions compared to baselines.", "conclusion": "Listener-based rewards offer a scalable, data-efficient approach to aligning vision-language models with nuanced human preferences."}}
{"id": "2506.23411", "pdf": "https://arxiv.org/pdf/2506.23411", "abs": "https://arxiv.org/abs/2506.23411", "authors": ["Jiale Zhang", "Zichong Wang", "Avash Palikhe", "Zhipeng Yin", "Wenbin Zhang"], "title": "Datasets for Fairness in Language Models: An In-Depth Survey", "categories": ["cs.CL", "cs.CY", "cs.LG"], "comment": null, "summary": "Fairness benchmarks play a central role in shaping how we evaluate language\nmodels, yet surprisingly little attention has been given to examining the\ndatasets that these benchmarks rely on. This survey addresses that gap by\npresenting a broad and careful review of the most widely used fairness datasets\nin current language model research, characterizing them along several key\ndimensions including their origin, scope, content, and intended use to help\nresearchers better appreciate the assumptions and limitations embedded in these\nresources. To support more meaningful comparisons and analyses, we introduce a\nunified evaluation framework that reveals consistent patterns of demographic\ndisparities across datasets and scoring methods. Applying this framework to\ntwenty four common benchmarks, we highlight the often overlooked biases that\ncan influence conclusions about model fairness and offer practical guidance for\nselecting, combining, and interpreting these datasets. We also point to\nopportunities for creating new fairness benchmarks that reflect more diverse\nsocial contexts and encourage more thoughtful use of these tools going forward.\nAll code, data, and detailed results are publicly available at\nhttps://github.com/vanbanTruong/Fairness-in-Large-Language-Models/tree/main/datasets\nto promote transparency and reproducibility across the research community.", "AI": {"tldr": "The paper reviews fairness datasets in language model research, introduces a unified evaluation framework, and highlights biases to improve fairness assessments.", "motivation": "Address the lack of scrutiny on fairness datasets used in language model benchmarks.", "method": "Survey and characterize widely used fairness datasets, introduce a unified evaluation framework, and analyze 24 benchmarks.", "result": "Reveals demographic disparities and biases in fairness datasets, offering guidance for better usage.", "conclusion": "Encourages more diverse benchmarks and thoughtful use of fairness datasets, with open resources for transparency."}}
{"id": "2506.07236", "pdf": "https://arxiv.org/pdf/2506.07236", "abs": "https://arxiv.org/abs/2506.07236", "authors": ["Jiachen Zhong", "Yiting Wang", "Di Zhu", "Ziwei Wang"], "title": "A Narrative Review on Large AI Models in Lung Cancer Screening, Diagnosis, and Treatment Planning", "categories": ["eess.IV", "cs.CV"], "comment": "This request is based on the fact that one of the co-authors is a PhD\n  student whose advisor has informed her that she was not authorized to\n  publicly release this work without his prior approval. Unfortunately, this\n  approval was not obtained, and as such, the submission was made without\n  proper institutional and supervisory consent", "summary": "Lung cancer remains one of the most prevalent and fatal diseases worldwide,\ndemanding accurate and timely diagnosis and treatment. Recent advancements in\nlarge AI models have significantly enhanced medical image understanding and\nclinical decision-making. This review systematically surveys the\nstate-of-the-art in applying large AI models to lung cancer screening,\ndiagnosis, prognosis, and treatment. We categorize existing models into\nmodality-specific encoders, encoder-decoder frameworks, and joint encoder\narchitectures, highlighting key examples such as CLIP, BLIP, Flamingo,\nBioViL-T, and GLoRIA. We further examine their performance in multimodal\nlearning tasks using benchmark datasets like LIDC-IDRI, NLST, and MIMIC-CXR.\nApplications span pulmonary nodule detection, gene mutation prediction,\nmulti-omics integration, and personalized treatment planning, with emerging\nevidence of clinical deployment and validation. Finally, we discuss current\nlimitations in generalizability, interpretability, and regulatory compliance,\nproposing future directions for building scalable, explainable, and clinically\nintegrated AI systems. Our review underscores the transformative potential of\nlarge AI models to personalize and optimize lung cancer care.", "AI": {"tldr": "A review of large AI models in lung cancer care, covering screening, diagnosis, prognosis, and treatment, highlighting key models, datasets, and applications, while addressing limitations and future directions.", "motivation": "Lung cancer's high prevalence and fatality necessitate improved diagnosis and treatment, with AI models offering transformative potential.", "method": "Systematic survey of large AI models (e.g., CLIP, BLIP, Flamingo) categorized into modality-specific encoders, encoder-decoder frameworks, and joint encoder architectures, evaluated on datasets like LIDC-IDRI and NLST.", "result": "AI models show promise in tasks like nodule detection, gene mutation prediction, and personalized treatment, with some clinical deployment.", "conclusion": "Large AI models can optimize lung cancer care but face challenges in generalizability and interpretability; future work should focus on scalable, explainable, and clinically integrated systems."}}
{"id": "2506.22448", "pdf": "https://arxiv.org/pdf/2506.22448", "abs": "https://arxiv.org/abs/2506.22448", "authors": ["Yu Ma", "Xingyu Zhou", "Xiao Li", "Le Liang", "Shi Jin"], "title": "Unsupervised Learning-Based Joint Resource Allocation and Beamforming Design for RIS-Assisted MISO-OFDMA Systems", "categories": ["eess.SP", "cs.AI", "cs.IT", "math.IT"], "comment": "Due to the limitation \"The abstract field cannot be longer than 1,920\n  characters\", the abstract here is shorter than that in the PDF file", "summary": "Reconfigurable intelligent surfaces (RIS) are key enablers for 6G wireless\nsystems. This paper studies downlink transmission in an RIS-assisted MISO-OFDMA\nsystem, addressing resource allocation challenges. A two-stage unsupervised\nlearning-based framework is proposed to jointly design RIS phase shifts, BS\nbeamforming, and resource block (RB) allocation. The framework includes\nBeamNet, which predicts RIS phase shifts from CSI, and AllocationNet, which\nallocates RBs using equivalent CSI derived from BeamNet outputs. Active\nbeamforming is implemented via maximum ratio transmission and water-filling. To\nhandle discrete constraints while ensuring differentiability, quantization and\nthe Gumbel-softmax trick are adopted. A customized loss and phased training\nenhance performance under QoS constraints. Simulations show the method achieves\n99.93% of the sum rate of the SCA baseline with only 0.036% of its runtime, and\nit remains robust across varying channel and user conditions.", "AI": {"tldr": "A two-stage unsupervised learning framework (BeamNet and AllocationNet) optimizes RIS phase shifts, BS beamforming, and RB allocation in RIS-assisted MISO-OFDMA systems, achieving near-optimal performance with minimal runtime.", "motivation": "To address resource allocation challenges in RIS-assisted 6G wireless systems efficiently.", "method": "Proposes a two-stage unsupervised learning framework: BeamNet predicts RIS phase shifts from CSI, and AllocationNet allocates RBs using equivalent CSI. Uses quantization and Gumbel-softmax for discrete constraints, with active beamforming via maximum ratio transmission and water-filling.", "result": "Achieves 99.93% of the sum rate of the SCA baseline with only 0.036% of its runtime, remaining robust under varying conditions.", "conclusion": "The framework is efficient and scalable for RIS-assisted 6G systems, balancing performance and computational cost."}}
{"id": "2506.23068", "pdf": "https://arxiv.org/pdf/2506.23068", "abs": "https://arxiv.org/abs/2506.23068", "authors": ["Zhiyu Zhao", "Haoxuan Li", "Haifeng Zhang", "Jun Wang", "Francesco Faccio", "J\u00fcrgen Schmidhuber", "Mengyue Yang"], "title": "Curious Causality-Seeking Agents Learn Meta Causal World", "categories": ["cs.LG", "cs.AI", "stat.AP"], "comment": "33 pages", "summary": "When building a world model, a common assumption is that the environment has\na single, unchanging underlying causal rule, like applying Newton's laws to\nevery situation. In reality, what appears as a drifting causal mechanism is\noften the manifestation of a fixed underlying mechanism seen through a narrow\nobservational window. This brings about a problem that, when building a world\nmodel, even subtle shifts in policy or environment states can alter the very\nobserved causal mechanisms. In this work, we introduce the \\textbf{Meta-Causal\nGraph} as world models, a minimal unified representation that efficiently\nencodes the transformation rules governing how causal structures shift across\ndifferent latent world states. A single Meta-Causal Graph is composed of\nmultiple causal subgraphs, each triggered by meta state, which is in the latent\nstate space. Building on this representation, we introduce a\n\\textbf{Causality-Seeking Agent} whose objectives are to (1) identify the meta\nstates that trigger each subgraph, (2) discover the corresponding causal\nrelationships by agent curiosity-driven intervention policy, and (3)\niteratively refine the Meta-Causal Graph through ongoing curiosity-driven\nexploration and agent experiences. Experiments on both synthetic tasks and a\nchallenging robot arm manipulation task demonstrate that our method robustly\ncaptures shifts in causal dynamics and generalizes effectively to previously\nunseen contexts.", "AI": {"tldr": "The paper introduces a Meta-Causal Graph as a world model to handle shifting causal mechanisms, and a Causality-Seeking Agent to identify and refine these mechanisms through curiosity-driven exploration.", "motivation": "Traditional world models assume fixed causal rules, but real-world dynamics often shift subtly. This work addresses the challenge of modeling such shifts.", "method": "Proposes a Meta-Causal Graph composed of causal subgraphs triggered by latent meta states. A Causality-Seeking Agent identifies meta states, discovers causal relationships, and refines the graph iteratively.", "result": "Experiments on synthetic and robot arm tasks show the method captures causal shifts and generalizes to unseen contexts.", "conclusion": "The Meta-Causal Graph and Causality-Seeking Agent provide a robust framework for modeling dynamic causal mechanisms in complex environments."}}
{"id": "2506.22833", "pdf": "https://arxiv.org/pdf/2506.22833", "abs": "https://arxiv.org/abs/2506.22833", "authors": ["Shashikant Verma", "Shanmuganathan Raman"], "title": "SemFaceEdit: Semantic Face Editing on Generative Radiance Manifolds", "categories": ["cs.CV"], "comment": null, "summary": "Despite multiple view consistency offered by 3D-aware GAN techniques, the\nresulting images often lack the capacity for localized editing. In response,\ngenerative radiance manifolds emerge as an efficient approach for constrained\npoint sampling within volumes, effectively reducing computational demands and\nenabling the learning of fine details. This work introduces SemFaceEdit, a\nnovel method that streamlines the appearance and geometric editing process by\ngenerating semantic fields on generative radiance manifolds. Utilizing latent\ncodes, our method effectively disentangles the geometry and appearance\nassociated with different facial semantics within the generated image. In\ncontrast to existing methods that can change the appearance of the entire\nradiance field, our method enables the precise editing of particular facial\nsemantics while preserving the integrity of other regions. Our network\ncomprises two key modules: the Geometry module, which generates semantic\nradiance and occupancy fields, and the Appearance module, which is responsible\nfor predicting RGB radiance. We jointly train both modules in adversarial\nsettings to learn semantic-aware geometry and appearance descriptors. The\nappearance descriptors are then conditioned on their respective semantic latent\ncodes by the Appearance Module, facilitating disentanglement and enhanced\ncontrol. Our experiments highlight SemFaceEdit's superior performance in\nsemantic field-based editing, particularly in achieving improved radiance field\ndisentanglement.", "AI": {"tldr": "SemFaceEdit introduces a method for localized facial editing in 3D-aware GANs by generating semantic fields on generative radiance manifolds, enabling precise control over geometry and appearance.", "motivation": "Existing 3D-aware GANs lack localized editing capabilities, limiting their utility for fine-grained facial modifications.", "method": "SemFaceEdit uses two modules: Geometry for semantic radiance/occupancy fields and Appearance for RGB radiance, trained adversarially with latent codes for disentanglement.", "result": "The method achieves superior radiance field disentanglement and precise editing of facial semantics while preserving other regions.", "conclusion": "SemFaceEdit advances localized facial editing in 3D-aware GANs, offering improved control and performance."}}
{"id": "2506.23423", "pdf": "https://arxiv.org/pdf/2506.23423", "abs": "https://arxiv.org/abs/2506.23423", "authors": ["Felipe Nuti", "Tim Franzmeyer", "Jo\u00e3o Henriques"], "title": "TuCo: Measuring the Contribution of Fine-Tuning to Individual Responses of LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "ICML 2025", "summary": "Past work has studied the effects of fine-tuning on large language models'\n(LLMs) overall performance on certain tasks. However, a quantitative and\nsystematic method for analyzing its effect on individual outputs is still\nlacking. Here, we propose a new method for measuring the contribution that\nfine-tuning makes to individual LLM responses, assuming access to the original\npre-trained model. Our method tracks the model's intermediate hidden states,\nproviding a more fine-grained insight into the effects of fine-tuning than a\nsimple comparison of final outputs from pre-trained and fine-tuned models. We\nintroduce and theoretically analyze an exact decomposition of any fine-tuned\nLLM into a pre-training component and a fine-tuning component. Empirically, we\nfind that model behavior and performance can be steered by up- or down-scaling\nthe fine-tuning component during the forward pass. Motivated by this finding\nand our theoretical analysis, we define the Tuning Contribution (TuCo) as the\nratio of the magnitudes of the fine-tuning component to the pre-training\ncomponent. We observe that three prominent adversarial attacks on LLMs\ncircumvent safety measures in a way that reduces TuCo, and that TuCo is\nconsistently lower on prompts where these attacks succeed compared to those\nwhere they do not. This suggests that attenuating the effect of fine-tuning on\nmodel outputs plays a role in the success of such attacks. In summary, TuCo\nenables the quantitative study of how fine-tuning influences model behavior and\nsafety, and vice versa.", "AI": {"tldr": "The paper introduces Tuning Contribution (TuCo), a method to quantitatively measure fine-tuning's impact on individual LLM outputs by analyzing hidden states and decomposing models into pre-training and fine-tuning components.", "motivation": "Existing work lacks a systematic way to analyze fine-tuning's effect on individual LLM outputs, prompting the need for a quantitative method.", "method": "Proposes tracking intermediate hidden states and decomposing fine-tuned LLMs into pre-training and fine-tuning components, introducing TuCo as a ratio of their magnitudes.", "result": "TuCo reveals that adversarial attacks reduce fine-tuning's influence, and lower TuCo correlates with attack success, indicating its role in model safety.", "conclusion": "TuCo provides a tool to study fine-tuning's influence on LLM behavior and safety, offering insights into adversarial attack mechanisms."}}
{"id": "2506.11297", "pdf": "https://arxiv.org/pdf/2506.11297", "abs": "https://arxiv.org/abs/2506.11297", "authors": ["Jiaqi Wu", "Jiahong Ouyang", "Farshad Moradi", "Mohammad Mehdi Khalighi", "Greg Zaharchuk"], "title": "Score-based Generative Diffusion Models to Synthesize Full-dose FDG Brain PET from MRI in Epilepsy Patients", "categories": ["eess.IV", "cs.LG"], "comment": null, "summary": "Fluorodeoxyglucose (FDG) PET to evaluate patients with epilepsy is one of the\nmost common applications for simultaneous PET/MRI, given the need to image both\nbrain structure and metabolism, but is suboptimal due to the radiation dose in\nthis young population. Little work has been done synthesizing diagnostic\nquality PET images from MRI data or MRI data with ultralow-dose PET using\nadvanced generative AI methods, such as diffusion models, with attention to\nclinical evaluations tailored for the epilepsy population. Here we compared the\nperformance of diffusion- and non-diffusion-based deep learning models for the\nMRI-to-PET image translation task for epilepsy imaging using simultaneous\nPET/MRI in 52 subjects (40 train/2 validate/10 hold-out test). We tested three\ndifferent models: 2 score-based generative diffusion models (SGM-Karras\nDiffusion [SGM-KD] and SGM-variance preserving [SGM-VP]) and a\nTransformer-Unet. We report results on standard image processing metrics as\nwell as clinically relevant metrics, including congruency measures (Congruence\nIndex and Congruency Mean Absolute Error) that assess hemispheric metabolic\nasymmetry, which is a key part of the clinical analysis of these images. The\nSGM-KD produced the best qualitative and quantitative results when synthesizing\nPET purely from T1w and T2 FLAIR images with the least mean absolute error in\nwhole-brain specific uptake value ratio (SUVR) and highest intraclass\ncorrelation coefficient. When 1% low-dose PET images are included in the\ninputs, all models improve significantly and are interchangeable for\nquantitative performance and visual quality. In summary, SGMs hold great\npotential for pure MRI-to-PET translation, while all 3 model types can\nsynthesize full-dose FDG-PET accurately using MRI and ultralow-dose PET.", "AI": {"tldr": "The study compares diffusion- and non-diffusion-based deep learning models for MRI-to-PET image translation in epilepsy patients, finding SGM-KD superior for pure MRI-to-PET synthesis and all models effective with low-dose PET inputs.", "motivation": "To address the suboptimal radiation dose in FDG PET for epilepsy patients by synthesizing diagnostic-quality PET images from MRI or ultralow-dose PET using generative AI.", "method": "Evaluated three models (SGM-KD, SGM-VP, Transformer-Unet) for MRI-to-PET translation in 52 subjects, using clinical and image metrics like Congruence Index and SUVR.", "result": "SGM-KD performed best for pure MRI-to-PET synthesis. All models improved significantly with 1% low-dose PET inputs, becoming interchangeable in performance.", "conclusion": "SGMs show promise for MRI-to-PET translation, while all models can accurately synthesize full-dose PET using MRI and ultralow-dose PET."}}
{"id": "2506.22457", "pdf": "https://arxiv.org/pdf/2506.22457", "abs": "https://arxiv.org/abs/2506.22457", "authors": ["Iulia Orvas", "Andrei Radu", "Alessandra Galli", "Ana Neacsu", "Elisabetta Peri"], "title": "A Complex UNet Approach for Non-Invasive Fetal ECG Extraction Using Single-Channel Dry Textile Electrodes", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "Continuous, non-invasive pregnancy monitoring is crucial for minimising\npotential complications. The fetal electrocardiogram (fECG) represents a\npromising tool for assessing fetal health beyond clinical environments.\nHome-based monitoring necessitates the use of a minimal number of comfortable\nand durable electrodes, such as dry textile electrodes. However, this setup\npresents many challenges, including increased noise and motion artefacts, which\ncomplicate the accurate extraction of fECG signals. To overcome these\nchallenges, we introduce a pioneering method for extracting fECG from\nsingle-channel recordings obtained using dry textile electrodes using AI\ntechniques. We created a new dataset by simulating abdominal recordings,\nincluding noise closely resembling real-world characteristics of in-vivo\nrecordings through dry textile electrodes, alongside mECG and fECG. To ensure\nthe reliability of the extracted fECG, we propose an innovative pipeline based\non a complex-valued denoising network, Complex UNet. Unlike previous approaches\nthat focused solely on signal magnitude, our method processes both real and\nimaginary components of the spectrogram, addressing phase information and\npreventing incongruous predictions. We evaluated our novel pipeline against\ntraditional, well-established approaches, on both simulated and real data in\nterms of fECG extraction and R-peak detection. The results showcase that our\nsuggested method achieves new state-of-the-art results, enabling an accurate\nextraction of fECG morphology across all evaluated settings. This method is the\nfirst to effectively extract fECG signals from single-channel recordings using\ndry textile electrodes, making a significant advancement towards a fully\nnon-invasive and self-administered fECG extraction solution.", "AI": {"tldr": "A novel AI-based method using Complex UNet for extracting fetal ECG (fECG) from single-channel dry textile electrode recordings, achieving state-of-the-art results.", "motivation": "Continuous, non-invasive pregnancy monitoring is essential to minimize complications, but home-based setups with dry textile electrodes face noise and motion artefact challenges.", "method": "Proposes a pipeline using Complex UNet, processing both real and imaginary spectrogram components to address phase information and noise. Evaluated on simulated and real data.", "result": "Achieves state-of-the-art fECG extraction and R-peak detection, enabling accurate morphology extraction in all settings.", "conclusion": "First effective method for single-channel fECG extraction with dry textile electrodes, advancing non-invasive, self-administered monitoring."}}
{"id": "2506.23145", "pdf": "https://arxiv.org/pdf/2506.23145", "abs": "https://arxiv.org/abs/2506.23145", "authors": ["Shahad Hardan", "Darya Taratynova", "Abdelmajid Essofi", "Karthik Nandakumar", "Mohammad Yaqub"], "title": "Forget-MI: Machine Unlearning for Forgetting Multimodal Information in Healthcare Settings", "categories": ["cs.LG", "cs.CR", "cs.CV"], "comment": null, "summary": "Privacy preservation in AI is crucial, especially in healthcare, where models\nrely on sensitive patient data. In the emerging field of machine unlearning,\nexisting methodologies struggle to remove patient data from trained multimodal\narchitectures, which are widely used in healthcare. We propose Forget-MI, a\nnovel machine unlearning method for multimodal medical data, by establishing\nloss functions and perturbation techniques. Our approach unlearns unimodal and\njoint representations of the data requested to be forgotten while preserving\nknowledge from the remaining data and maintaining comparable performance to the\noriginal model. We evaluate our results using performance on the forget\ndataset, performance on the test dataset, and Membership Inference Attack\n(MIA), which measures the attacker's ability to distinguish the forget dataset\nfrom the training dataset. Our model outperforms the existing approaches that\naim to reduce MIA and the performance on the forget dataset while keeping an\nequivalent performance on the test set. Specifically, our approach reduces MIA\nby 0.202 and decreases AUC and F1 scores on the forget set by 0.221 and 0.305,\nrespectively. Additionally, our performance on the test set matches that of the\nretrained model, while allowing forgetting. Code is available at\nhttps://github.com/BioMedIA-MBZUAI/Forget-MI.git", "AI": {"tldr": "Forget-MI is a machine unlearning method for multimodal medical data, improving privacy by removing sensitive data while maintaining model performance.", "motivation": "Privacy preservation in AI, especially in healthcare, is critical due to sensitive patient data. Existing methods struggle with unlearning in multimodal architectures.", "method": "Forget-MI uses loss functions and perturbation techniques to unlearn unimodal and joint representations of data while preserving knowledge from remaining data.", "result": "The method reduces Membership Inference Attack (MIA) by 0.202, decreases AUC and F1 scores on the forget set, and matches test set performance of the original model.", "conclusion": "Forget-MI effectively unlearns sensitive data in multimodal models, enhancing privacy without compromising performance."}}
{"id": "2506.22836", "pdf": "https://arxiv.org/pdf/2506.22836", "abs": "https://arxiv.org/abs/2506.22836", "authors": ["Hongyan An", "Kuan Zhu", "Xin He", "Haiyun Guo", "Chaoyang Zhao", "Ming Tang", "Jinqiao Wang"], "title": "FOCUS: Fine-grained Optimization with Semantic Guided Understanding for Pedestrian Attributes Recognition", "categories": ["cs.CV"], "comment": "ICME 2025 Oral", "summary": "Pedestrian attribute recognition (PAR) is a fundamental perception task in\nintelligent transportation and security. To tackle this fine-grained task, most\nexisting methods focus on extracting regional features to enrich attribute\ninformation. However, a regional feature is typically used to predict a fixed\nset of pre-defined attributes in these methods, which limits the performance\nand practicality in two aspects: 1) Regional features may compromise\nfine-grained patterns unique to certain attributes in favor of capturing common\ncharacteristics shared across attributes. 2) Regional features cannot\ngeneralize to predict unseen attributes in the test time. In this paper, we\npropose the \\textbf{F}ine-grained \\textbf{O}ptimization with semanti\\textbf{C}\ng\\textbf{U}ided under\\textbf{S}tanding (FOCUS) approach for PAR, which\nadaptively extracts fine-grained attribute-level features for each attribute\nindividually, regardless of whether the attributes are seen or not during\ntraining. Specifically, we propose the Multi-Granularity Mix Tokens (MGMT) to\ncapture latent features at varying levels of visual granularity, thereby\nenriching the diversity of the extracted information. Next, we introduce the\nAttribute-guided Visual Feature Extraction (AVFE) module, which leverages\ntextual attributes as queries to retrieve their corresponding visual attribute\nfeatures from the Mix Tokens using a cross-attention mechanism. To ensure that\ntextual attributes focus on the appropriate Mix Tokens, we further incorporate\na Region-Aware Contrastive Learning (RACL) method, encouraging attributes\nwithin the same region to share consistent attention maps. Extensive\nexperiments on PA100K, PETA, and RAPv1 datasets demonstrate the effectiveness\nand strong generalization ability of our method.", "AI": {"tldr": "The paper introduces FOCUS, a method for Pedestrian Attribute Recognition (PAR) that adaptively extracts fine-grained attribute-level features, addressing limitations of fixed regional features.", "motivation": "Existing PAR methods use fixed regional features, which compromise fine-grained patterns and fail to generalize to unseen attributes. FOCUS aims to overcome these limitations.", "method": "FOCUS uses Multi-Granularity Mix Tokens (MGMT) for diverse feature extraction and Attribute-guided Visual Feature Extraction (AVFE) with cross-attention. Region-Aware Contrastive Learning (RACL) ensures consistent attention.", "result": "Experiments on PA100K, PETA, and RAPv1 datasets show FOCUS's effectiveness and generalization ability.", "conclusion": "FOCUS improves PAR by adaptively extracting fine-grained features, enhancing performance and practicality for both seen and unseen attributes."}}
{"id": "2506.23431", "pdf": "https://arxiv.org/pdf/2506.23431", "abs": "https://arxiv.org/abs/2506.23431", "authors": ["Zixian Huang", "Chenxu Niu", "Yu Gu", "Gengyang Xiao", "Xinwei Huang", "Gong Cheng"], "title": "Pipelined Decoder for Efficient Context-Aware Text Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "As the basis of generative AI, an autoregressive model requires the\ngeneration of a new token depending on all the previously generated tokens,\nwhich brings high quality but also restricts the model to generate tokens one\nby one, forming a bottleneck limiting the generation speed. In this paper, we\npropose a new decoder architecture that efficiently generates text in parallel\nfor context-aware generation tasks. Our proposed pipelined decoder initiates\nthe generation of multiple subsequences simultaneously, and, at each time-step,\nit generates a new token for each subsequence to realize parallelism.\nExperiments on multiple text generation tasks, including question answering,\ntext summarization, and keyphrase generation, show that our pipelined decoder\nsignificantly improves the generation speed without a significant loss of\ngeneration quality or additional memory consumption.", "AI": {"tldr": "Proposes a pipelined decoder for parallel text generation, improving speed without compromising quality or memory.", "motivation": "Autoregressive models are slow due to sequential token generation, creating a bottleneck.", "method": "Introduces a pipelined decoder that generates multiple subsequences in parallel at each time-step.", "result": "Significantly improves generation speed across tasks like QA, summarization, and keyphrase generation.", "conclusion": "The pipelined decoder offers a viable solution for faster, context-aware text generation."}}
{"id": "2506.20407", "pdf": "https://arxiv.org/pdf/2506.20407", "abs": "https://arxiv.org/abs/2506.20407", "authors": ["Fangyijie Wang", "Yuan Liang", "Sourav Bhattacharjee", "Abey Campbell", "Kathleen M. Curran", "Gu\u00e9nol\u00e9 Silvestre"], "title": "Fusing Radiomic Features with Deep Representations for Gestational Age Estimation in Fetal Ultrasound Images", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted at MICCAI 2025", "summary": "Accurate gestational age (GA) estimation, ideally through fetal ultrasound\nmeasurement, is a crucial aspect of providing excellent antenatal care.\nHowever, deriving GA from manual fetal biometric measurements depends on the\noperator and is time-consuming. Hence, automatic computer-assisted methods are\ndemanded in clinical practice. In this paper, we present a novel feature fusion\nframework to estimate GA using fetal ultrasound images without any measurement\ninformation. We adopt a deep learning model to extract deep representations\nfrom ultrasound images. We extract radiomic features to reveal patterns and\ncharacteristics of fetal brain growth. To harness the interpretability of\nradiomics in medical imaging analysis, we estimate GA by fusing radiomic\nfeatures and deep representations. Our framework estimates GA with a mean\nabsolute error of 8.0 days across three trimesters, outperforming current\nmachine learning-based methods at these gestational ages. Experimental results\ndemonstrate the robustness of our framework across different populations in\ndiverse geographical regions. Our code is publicly available on\n\\href{https://github.com/13204942/RadiomicsImageFusion_FetalUS}.", "AI": {"tldr": "A novel feature fusion framework using deep learning and radiomics for accurate gestational age estimation from fetal ultrasound images, achieving a mean absolute error of 8.0 days.", "motivation": "Manual GA estimation is operator-dependent and time-consuming; automatic methods are needed for clinical practice.", "method": "Combines deep learning for image representations and radiomics for fetal brain growth patterns, fusing both for GA estimation.", "result": "Achieves a mean absolute error of 8.0 days, outperforming existing methods, with robustness across diverse populations.", "conclusion": "The framework provides an accurate, interpretable, and automated solution for GA estimation in clinical settings."}}
{"id": "2506.22460", "pdf": "https://arxiv.org/pdf/2506.22460", "abs": "https://arxiv.org/abs/2506.22460", "authors": ["Ibne Farabi Shihab"], "title": "Heart rate and respiratory rate prediction from noisy real-world smartphone based on Deep Learning methods", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "Using mobile phone video of the fingertip as a data source for estimating\nvital signs such as heart rate (HR) and respiratory rate (RR) during daily life\nhas long been suggested. While existing literature indicates that these\nestimates are accurate to within several beats or breaths per minute, the data\nused to draw these conclusions are typically collected in laboratory\nenvironments under careful experimental control, and yet the results are\nassumed to generalize to daily life. In an effort to test it, a team of\nresearchers collected a large dataset of mobile phone video recordings made\nduring daily life and annotated with ground truth HR and RR labels from N=111\nparticipants. They found that traditional algorithm performance on the\nfingerprint videos is worse than previously reported (7 times and 13 times\nworse for RR and HR, respectively). Fortunately, recent advancements in deep\nlearning, especially in convolutional neural networks (CNNs), offer a promising\nsolution to improve this performance. This study proposes a new method for\nestimating HR and RR using a novel 3D deep CNN, demonstrating a reduced error\nin estimated HR by 68% and RR by 75%. These promising results suggest that\nregressor-based deep learning approaches should be used in estimating HR and\nRR.", "AI": {"tldr": "A study evaluates mobile phone fingertip videos for HR and RR estimation in daily life, finding traditional methods perform worse than lab results. A 3D CNN method reduces errors significantly.", "motivation": "To test the generalization of lab-based HR and RR estimation methods to daily life and improve accuracy using deep learning.", "method": "Proposes a novel 3D deep CNN for HR and RR estimation from mobile phone videos.", "result": "Reduced HR error by 68% and RR error by 75% compared to traditional methods.", "conclusion": "Deep learning, especially 3D CNNs, significantly improves HR and RR estimation accuracy in daily life."}}
{"id": "2506.23147", "pdf": "https://arxiv.org/pdf/2506.23147", "abs": "https://arxiv.org/abs/2506.23147", "authors": ["Jonathan Schuster", "Fabian Transchel"], "title": "maneuverRecognition -- A Python package for Timeseries Classification in the domain of Vehicle Telematics", "categories": ["cs.LG", "cs.CV"], "comment": "6 pages, 2 figures", "summary": "In the domain of vehicle telematics the automated recognition of driving\nmaneuvers is used to classify and evaluate driving behaviour. This not only\nserves as a component to enhance the personalization of insurance policies, but\nalso to increase road safety, reduce accidents and the associated costs as well\nas to reduce fuel consumption and support environmentally friendly driving. In\nthis context maneuver recognition technically requires a continuous application\nof time series classification which poses special challenges to the transfer,\npreprocessing and storage of telematic sensor data, the training of predictive\nmodels, and the prediction itself. Although much research has been done in the\nfield of gathering relevant data or regarding the methods to build predictive\nmodels for the task of maneuver recognition, there is a practical need for\npython packages and functions that allow to quickly transform data into the\nrequired structure as well as to build and evaluate such models. The\nmaneuverRecognition package was therefore developed to provide the necessary\nfunctions for preprocessing, modelling and evaluation and also includes a ready\nto use LSTM based network structure that can be modified. The implementation of\nthe package is demonstrated using real driving data of three different persons\nrecorded via smartphone sensors.", "AI": {"tldr": "The paper introduces the maneuverRecognition package for automating driving maneuver recognition in vehicle telematics, addressing data preprocessing, modeling, and evaluation challenges.", "motivation": "To enhance road safety, reduce accidents, and support eco-friendly driving by automating maneuver recognition, while providing practical tools for data transformation and model building.", "method": "Developed the maneuverRecognition package with preprocessing, modeling, and evaluation functions, including a customizable LSTM-based network.", "result": "Demonstrated the package's effectiveness using real driving data from smartphone sensors of three individuals.", "conclusion": "The maneuverRecognition package offers a practical solution for maneuver recognition, bridging the gap between research and application."}}
{"id": "2506.22843", "pdf": "https://arxiv.org/pdf/2506.22843", "abs": "https://arxiv.org/abs/2506.22843", "authors": ["Kien Nguyen", "Clinton Fookes", "Sridha Sridharan", "Huy Nguyen", "Feng Liu", "Xiaoming Liu", "Arun Ross", "Dana Michalski", "Tam\u00e1s Endrei", "Ivan DeAndres-Tame", "Ruben Tolosana", "Ruben Vera-Rodriguez", "Aythami Morales", "Julian Fierrez", "Javier Ortega-Garcia", "Zijing Gong", "Yuhao Wang", "Xuehu Liu", "Pingping Zhang", "Md Rashidunnabi", "Hugo Proen\u00e7a", "Kailash A. Hambarde", "Saeid Rezaei"], "title": "AG-VPReID 2025: Aerial-Ground Video-based Person Re-identification Challenge Results", "categories": ["cs.CV"], "comment": null, "summary": "Person re-identification (ReID) across aerial and ground vantage points has\nbecome crucial for large-scale surveillance and public safety applications.\nAlthough significant progress has been made in ground-only scenarios, bridging\nthe aerial-ground domain gap remains a formidable challenge due to extreme\nviewpoint differences, scale variations, and occlusions. Building upon the\nachievements of the AG-ReID 2023 Challenge, this paper introduces the AG-VPReID\n2025 Challenge - the first large-scale video-based competition focused on\nhigh-altitude (80-120m) aerial-ground ReID. Constructed on the new AG-VPReID\ndataset with 3,027 identities, over 13,500 tracklets, and approximately 3.7\nmillion frames captured from UAVs, CCTV, and wearable cameras, the challenge\nfeatured four international teams. These teams developed solutions ranging from\nmulti-stream architectures to transformer-based temporal reasoning and\nphysics-informed modeling. The leading approach, X-TFCLIP from UAM, attained\n72.28% Rank-1 accuracy in the aerial-to-ground ReID setting and 70.77% in the\nground-to-aerial ReID setting, surpassing existing baselines while highlighting\nthe dataset's complexity. For additional details, please refer to the official\nwebsite at https://agvpreid25.github.io.", "AI": {"tldr": "The AG-VPReID 2025 Challenge introduces a large-scale video-based competition for aerial-ground person re-identification, addressing challenges like viewpoint differences and occlusions.", "motivation": "To bridge the aerial-ground domain gap in person re-identification, crucial for surveillance and public safety, by leveraging a new dataset and advanced methods.", "method": "Teams developed solutions including multi-stream architectures, transformer-based temporal reasoning, and physics-informed modeling.", "result": "The leading approach, X-TFCLIP, achieved 72.28% Rank-1 accuracy in aerial-to-ground and 70.77% in ground-to-aerial ReID, outperforming baselines.", "conclusion": "The challenge highlights the dataset's complexity and advances in aerial-ground ReID, with potential for further improvements."}}
{"id": "2506.23463", "pdf": "https://arxiv.org/pdf/2506.23463", "abs": "https://arxiv.org/abs/2506.23463", "authors": ["Jang Won June"], "title": "What to Keep and What to Drop: Adaptive Table Filtering Framework", "categories": ["cs.CL", "I.2.7"], "comment": "26 pages, 9 figures", "summary": "Large language models (LLMs) for table-based reasoning often struggle with\nlarge tables due to input length limits. We propose ATF (Adaptive Table\nFiltering Framework), a modular and question-aware filtering pipeline that\nprunes uninformative columns and rows using LLM-generated column descriptions,\nclustering, and sparse-dense alignment scores. ATF integrates seamlessly with\nexisting models (e.g., TAPAS, TAPEX) without retraining. Experiments show that\nATF reduces table cells by ~70\\%, boosting performance on out-of-domain TableQA\ntasks while causing slight performance drops on Table Fact Verification, where\nfull-table context is more critical. These results highlight ATF's ability to\nadaptively balance informativeness and minimalism across tasks.", "AI": {"tldr": "ATF (Adaptive Table Filtering Framework) prunes uninformative table columns and rows to improve LLM performance on large tables, reducing cells by ~70% and boosting TableQA tasks.", "motivation": "Large language models struggle with large tables due to input length limits, necessitating a solution to filter uninformative data.", "method": "ATF uses LLM-generated column descriptions, clustering, and sparse-dense alignment scores to prune columns and rows, integrating with models like TAPAS and TAPEX without retraining.", "result": "ATF reduces table cells by ~70%, improving performance on TableQA tasks but slightly dropping performance on Table Fact Verification where full-table context is crucial.", "conclusion": "ATF effectively balances informativeness and minimalism across tasks, enhancing LLM performance on large tables."}}
{"id": "2506.22397", "pdf": "https://arxiv.org/pdf/2506.22397", "abs": "https://arxiv.org/abs/2506.22397", "authors": ["Anirban Ray", "Ashesh", "Florian Jug"], "title": "Dehazing Light Microscopy Images with Guided Conditional Flow Matching: finding a sweet spot between fidelity and realism", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "4 figures, 10 pages + refs, 40 pages total (including supplement), 24\n  supplementary figures", "summary": "Fluorescence microscopy is a major driver of scientific progress in the life\nsciences. Although high-end confocal microscopes are capable of filtering\nout-of-focus light, cheaper and more accessible microscopy modalities, such as\nwidefield microscopy, can not, which consequently leads to hazy image data.\nComputational dehazing is trying to combine the best of both worlds, leading to\ncheap microscopy but crisp-looking images. The perception-distortion trade-off\ntells us that we can optimize either for data fidelity, e.g. low MSE or high\nPSNR, or for data realism, measured by perceptual metrics such as LPIPS or FID.\nExisting methods either prioritize fidelity at the expense of realism, or\nproduce perceptually convincing results that lack quantitative accuracy. In\nthis work, we propose HazeMatching, a novel iterative method for dehazing light\nmicroscopy images, which effectively balances these objectives. Our goal was to\nfind a balanced trade-off between the fidelity of the dehazing results and the\nrealism of individual predictions (samples). We achieve this by adapting the\nconditional flow matching framework by guiding the generative process with a\nhazy observation in the conditional velocity field. We evaluate HazeMatching on\n5 datasets, covering both synthetic and real data, assessing both distortion\nand perceptual quality. Our method is compared against 7 baselines, achieving a\nconsistent balance between fidelity and realism on average. Additionally, with\ncalibration analysis, we show that HazeMatching produces well-calibrated\npredictions. Note that our method does not need an explicit degradation\noperator to exist, making it easily applicable on real microscopy data. All\ndata used for training and evaluation and our code will be publicly available\nunder a permissive license.", "AI": {"tldr": "HazeMatching is a novel iterative method for dehazing microscopy images, balancing fidelity and realism without needing an explicit degradation operator.", "motivation": "Cheaper microscopy modalities like widefield produce hazy images. Computational dehazing aims to combine affordability with image clarity, but existing methods prioritize either fidelity or realism, not both.", "method": "HazeMatching adapts conditional flow matching, guiding the generative process with hazy observations in the conditional velocity field.", "result": "Evaluated on 5 datasets, HazeMatching outperforms 7 baselines, balancing fidelity and realism while producing well-calibrated predictions.", "conclusion": "HazeMatching effectively balances fidelity and realism in dehazing microscopy images, applicable even without an explicit degradation model."}}
{"id": "2506.22461", "pdf": "https://arxiv.org/pdf/2506.22461", "abs": "https://arxiv.org/abs/2506.22461", "authors": ["Chuan Li", "Ruoxuan Yang"], "title": "Machine Learning for Proactive Groundwater Management: Early Warning and Resource Allocation", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "Groundwater supports ecosystems, agriculture, and drinking water supplies\nworldwide, yet effective monitoring remains challenging due to sparse data,\ncomputational constraints, and delayed outputs from traditional approaches. We\ndevelop a machine learning pipeline that predicts groundwater level categories\nusing climate data, hydro-meteorological records, and physiographic attributes\nprocessed through AutoGluon's automated ensemble framework. Our approach\nintegrates geospatial preprocessing, domain-driven feature engineering, and\nautomated model selection to overcome conventional monitoring limitations.\nApplied to a large-scale French dataset (n $>$ 3,440,000 observations from\n1,500+ wells), the model achieves weighted F\\_1 scores of 0.927 on validation\ndata and 0.67 on temporally distinct test data. Scenario-based evaluations\ndemonstrate practical utility for early warning systems and water allocation\ndecisions under changing climate conditions. The open-source implementation\nprovides a scalable framework for integrating machine learning into national\ngroundwater monitoring networks, enabling more responsive and data-driven water\nmanagement strategies.", "AI": {"tldr": "A machine learning pipeline predicts groundwater levels using climate and hydro-meteorological data, achieving high accuracy and practical utility for water management.", "motivation": "Traditional groundwater monitoring is limited by sparse data and delayed outputs, necessitating a more efficient and scalable approach.", "method": "The pipeline uses AutoGluon's automated ensemble framework, integrating geospatial preprocessing, feature engineering, and model selection.", "result": "The model achieves weighted F1 scores of 0.927 (validation) and 0.67 (test), proving effective for early warning and water allocation.", "conclusion": "The open-source framework enables scalable, data-driven groundwater monitoring, improving water management responsiveness."}}
{"id": "2506.23165", "pdf": "https://arxiv.org/pdf/2506.23165", "abs": "https://arxiv.org/abs/2506.23165", "authors": ["David Bossens", "Atsushi Nitanda"], "title": "Mirror Descent Policy Optimisation for Robust Constrained Markov Decision Processes", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "Safety is an essential requirement for reinforcement learning systems. The\nnewly emerging framework of robust constrained Markov decision processes allows\nlearning policies that satisfy long-term constraints while providing guarantees\nunder epistemic uncertainty. This paper presents mirror descent policy\noptimisation for robust constrained Markov decision processes (RCMDPs), making\nuse of policy gradient techniques to optimise both the policy (as a maximiser)\nand the transition kernel (as an adversarial minimiser) on the Lagrangian\nrepresenting a constrained MDP. In the oracle-based RCMDP setting, we obtain an\n$\\mathcal{O}\\left(\\frac{1}{T}\\right)$ convergence rate for the squared distance\nas a Bregman divergence, and an $\\mathcal{O}\\left(e^{-T}\\right)$ convergence\nrate for entropy-regularised objectives. In the sample-based RCMDP setting, we\nobtain an $\\tilde{\\mathcal{O}}\\left(\\frac{1}{T^{1/3}}\\right)$ convergence rate.\nExperiments confirm the benefits of mirror descent policy optimisation in\nconstrained and unconstrained optimisation, and significant improvements are\nobserved in robustness tests when compared to baseline policy optimisation\nalgorithms.", "AI": {"tldr": "The paper introduces mirror descent policy optimization for robust constrained Markov decision processes (RCMDPs), achieving convergence guarantees and improved robustness in reinforcement learning.", "motivation": "Addressing safety in reinforcement learning by ensuring long-term constraints and robustness under uncertainty.", "method": "Uses policy gradient techniques to optimize policy and transition kernel via Lagrangian representation of constrained MDPs.", "result": "Achieves O(1/T) and O(e^-T) convergence rates in oracle-based RCMDPs, and O~(1/T^(1/3)) in sample-based settings, with experimental validation.", "conclusion": "Mirror descent policy optimization enhances robustness and performance in constrained and unconstrained settings compared to baselines."}}
{"id": "2506.22850", "pdf": "https://arxiv.org/pdf/2506.22850", "abs": "https://arxiv.org/abs/2506.22850", "authors": ["Aalok Gangopadhyay", "Shashikant Verma", "Shanmuganathan Raman"], "title": "DMD-Net: Deep Mesh Denoising Network", "categories": ["cs.CV"], "comment": null, "summary": "We present Deep Mesh Denoising Network (DMD-Net), an end-to-end deep learning\nframework, for solving the mesh denoising problem. DMD-Net consists of a Graph\nConvolutional Neural Network in which aggregation is performed in both the\nprimal as well as the dual graph. This is realized in the form of an asymmetric\ntwo-stream network, which contains a primal-dual fusion block that enables\ncommunication between the primal-stream and the dual-stream. We develop a\nFeature Guided Transformer (FGT) paradigm, which consists of a feature\nextractor, a transformer, and a denoiser. The feature extractor estimates the\nlocal features, that guide the transformer to compute a transformation, which\nis applied to the noisy input mesh to obtain a useful intermediate\nrepresentation. This is further processed by the denoiser to obtain the\ndenoised mesh. Our network is trained on a large scale dataset of 3D objects.\nWe perform exhaustive ablation studies to demonstrate that each component in\nour network is essential for obtaining the best performance. We show that our\nmethod obtains competitive or better results when compared with the\nstate-of-the-art mesh denoising algorithms. We demonstrate that our method is\nrobust to various kinds of noise. We observe that even in the presence of\nextremely high noise, our method achieves excellent performance.", "AI": {"tldr": "DMD-Net is a deep learning framework for mesh denoising using a dual-stream GCN and a Feature Guided Transformer, achieving state-of-the-art performance.", "motivation": "To address the mesh denoising problem with a robust, end-to-end deep learning solution that handles high noise levels effectively.", "method": "Uses a dual-stream GCN with primal-dual fusion and a Feature Guided Transformer (feature extractor, transformer, denoiser) for denoising.", "result": "Competitive or superior performance compared to state-of-the-art methods, robust to high noise levels.", "conclusion": "DMD-Net is effective and robust for mesh denoising, with each component contributing to its success."}}
{"id": "2506.23485", "pdf": "https://arxiv.org/pdf/2506.23485", "abs": "https://arxiv.org/abs/2506.23485", "authors": ["Haocheng Yu", "Yaxiong Wu", "Hao Wang", "Wei Guo", "Yong Liu", "Yawen Li", "Yuyang Ye", "Junping Du", "Enhong Chen"], "title": "Thought-Augmented Planning for LLM-Powered Interactive Recommender Agent", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Interactive recommendation is a typical information-seeking task that allows\nusers to interactively express their needs through natural language and obtain\npersonalized recommendations. Large language model-powered (LLM-powered) agents\nhave become a new paradigm in interactive recommendations, effectively\ncapturing users' real-time needs and enhancing personalized experiences.\nHowever, due to limited planning and generalization capabilities, existing\nformulations of LLM-powered interactive recommender agents struggle to\neffectively address diverse and complex user intents, such as intuitive,\nunrefined, or occasionally ambiguous requests. To tackle this challenge, we\npropose a novel thought-augmented interactive recommender agent system (TAIRA)\nthat addresses complex user intents through distilled thought patterns.\nSpecifically, TAIRA is designed as an LLM-powered multi-agent system featuring\na manager agent that orchestrates recommendation tasks by decomposing user\nneeds and planning subtasks, with its planning capacity strengthened through\nThought Pattern Distillation (TPD), a thought-augmentation method that extracts\nhigh-level thoughts from the agent's and human experts' experiences. Moreover,\nwe designed a set of user simulation schemes to generate personalized queries\nof different difficulties and evaluate the recommendations based on specific\ndatasets. Through comprehensive experiments conducted across multiple datasets,\nTAIRA exhibits significantly enhanced performance compared to existing methods.\nNotably, TAIRA shows a greater advantage on more challenging tasks while\ngeneralizing effectively on novel tasks, further validating its superiority in\nmanaging complex user intents within interactive recommendation systems. The\ncode is publicly available at:https://github.com/Alcein/TAIRA.", "AI": {"tldr": "TAIRA is a novel LLM-powered multi-agent system for interactive recommendations, addressing complex user intents through thought-augmented planning and outperforming existing methods.", "motivation": "Existing LLM-powered interactive recommender agents struggle with diverse and complex user intents due to limited planning and generalization capabilities.", "method": "TAIRA uses a manager agent with Thought Pattern Distillation (TPD) to decompose user needs and plan subtasks, alongside user simulation schemes for evaluation.", "result": "TAIRA significantly outperforms existing methods, especially on challenging tasks, and generalizes well on novel tasks.", "conclusion": "TAIRA effectively manages complex user intents in interactive recommendation systems, validated by comprehensive experiments."}}
{"id": "2407.09972", "pdf": "https://arxiv.org/pdf/2407.09972", "abs": "https://arxiv.org/abs/2407.09972", "authors": ["Shanghao Shi", "Md Shahedul Haque", "Abhijeet Parida", "Chaoyu Zhang", "Marius George Linguraru", "Y. Thomas Hou", "Syed Muhammad Anwar", "Wenjing Lou"], "title": "MedLeak: Multimodal Medical Data Leakage in Secure Federated Learning with Crafted Models", "categories": ["cs.LG", "cs.CR", "eess.IV"], "comment": "Accepted by the IEEE/ACM conference on Connected Health:\n  Applications, Systems and Engineering Technologies 2025 (CHASE'25)", "summary": "Federated learning (FL) allows participants to collaboratively train machine\nlearning models while keeping their data local, making it ideal for\ncollaborations among healthcare institutions on sensitive data. However, in\nthis paper, we propose a novel privacy attack called MedLeak, which allows a\nmalicious FL server to recover high-quality site-specific private medical data\nfrom the client model updates. MedLeak works by introducing an adversarially\ncrafted model during the FL training process. Honest clients, unaware of the\ninsidious changes in the published models, continue to send back their updates\nas per the standard FL protocol. Leveraging a novel analytical method, MedLeak\ncan efficiently recover private client data from the aggregated parameter\nupdates, eliminating costly optimization. In addition, the scheme relies solely\non the aggregated updates, thus rendering secure aggregation protocols\nineffective, as they depend on the randomization of intermediate results for\nsecurity while leaving the final aggregated results unaltered.\n  We implement MedLeak on medical image datasets (MedMNIST, COVIDx CXR-4, and\nKaggle Brain Tumor MRI), as well as a medical text dataset (MedAbstract). The\nresults demonstrate that our attack achieves high recovery rates and strong\nquantitative scores on both image and text datasets. We also thoroughly\nevaluate MedLeak across different attack parameters, providing insights into\nkey factors that influence attack performance and potential defenses.\nFurthermore, we demonstrate that the recovered data can support downstream\ntasks such as disease classification with minimal performance loss. Our\nfindings validate the need for enhanced privacy measures in FL systems,\nparticularly for safeguarding sensitive medical data against powerful model\ninversion attacks.", "AI": {"tldr": "The paper introduces MedLeak, a privacy attack in federated learning (FL) that recovers private medical data from client updates, bypassing secure aggregation protocols.", "motivation": "To highlight vulnerabilities in FL systems, especially for sensitive medical data, by demonstrating a novel attack that exploits model updates.", "method": "MedLeak uses an adversarially crafted model during FL training to recover private client data from aggregated updates without costly optimization.", "result": "High recovery rates and strong quantitative scores on medical image and text datasets, with recovered data usable for downstream tasks like disease classification.", "conclusion": "The study underscores the need for stronger privacy measures in FL to protect sensitive medical data from model inversion attacks."}}
{"id": "2506.22462", "pdf": "https://arxiv.org/pdf/2506.22462", "abs": "https://arxiv.org/abs/2506.22462", "authors": ["Abdallah Lakhdari", "Jiajie Li", "Amani Abusafia", "Athman Bouguettaya"], "title": "Privacy-aware IoT Fall Detection Services For Aging in Place", "categories": ["eess.SP", "cs.AI", "cs.CY", "cs.HC"], "comment": "11 pages, 12 figures, This paper is accepted in the 2025 IEEE\n  International Conference on Web Services (ICWS 2025)", "summary": "Fall detection is critical to support the growing elderly population,\nprojected to reach 2.1 billion by 2050. However, existing methods often face\ndata scarcity challenges or compromise privacy. We propose a novel IoT-based\nFall Detection as a Service (FDaaS) framework to assist the elderly in living\nindependently and safely by accurately detecting falls. We design a\nservice-oriented architecture that leverages Ultra-wideband (UWB) radar sensors\nas an IoT health-sensing service, ensuring privacy and minimal intrusion. We\naddress the challenges of data scarcity by utilizing a Fall Detection\nGenerative Pre-trained Transformer (FD-GPT) that uses augmentation techniques.\nWe developed a protocol to collect a comprehensive dataset of the elderly daily\nactivities and fall events. This resulted in a real dataset that carefully\nmimics the elderly's routine. We rigorously evaluate and compare various models\nusing this dataset. Experimental results show our approach achieves 90.72%\naccuracy and 89.33% precision in distinguishing between fall events and regular\nactivities of daily living.", "AI": {"tldr": "A novel IoT-based Fall Detection as a Service (FDaaS) framework using UWB radar sensors and FD-GPT for accurate, privacy-preserving fall detection, achieving 90.72% accuracy.", "motivation": "Addressing data scarcity and privacy issues in fall detection for the elderly, projected to reach 2.1 billion by 2050.", "method": "Service-oriented architecture with UWB radar sensors and FD-GPT for data augmentation, using a comprehensive dataset of elderly activities.", "result": "Achieves 90.72% accuracy and 89.33% precision in distinguishing falls from daily activities.", "conclusion": "The FDaaS framework effectively supports elderly independence with high accuracy and privacy."}}
{"id": "2506.23174", "pdf": "https://arxiv.org/pdf/2506.23174", "abs": "https://arxiv.org/abs/2506.23174", "authors": ["Chen Gong", "Bo Liang", "Wei Gao", "Chenren Xu"], "title": "Data Can Speak for Itself: Quality-guided Utilization of Wireless Synthetic Data", "categories": ["cs.LG", "cs.AI"], "comment": "Published in MobiSys 2025", "summary": "Generative models have gained significant attention for their ability to\nproduce realistic synthetic data that supplements the quantity of real-world\ndatasets. While recent studies show performance improvements in wireless\nsensing tasks by incorporating all synthetic data into training sets, the\nquality of synthetic data remains unpredictable and the resulting performance\ngains are not guaranteed. To address this gap, we propose tractable and\ngeneralizable metrics to quantify quality attributes of synthetic data -\naffinity and diversity. Our assessment reveals prevalent affinity limitation in\ncurrent wireless synthetic data, leading to mislabeled data and degraded task\nperformance. We attribute the quality limitation to generative models' lack of\nawareness of untrained conditions and domain-specific processing. To mitigate\nthese issues, we introduce SynCheck, a quality-guided synthetic data\nutilization scheme that refines synthetic data quality during task model\ntraining. Our evaluation demonstrates that SynCheck consistently outperforms\nquality-oblivious utilization of synthetic data, and achieves 4.3% performance\nimprovement even when the previous utilization degrades performance by 13.4%.", "AI": {"tldr": "The paper proposes metrics (affinity and diversity) to assess synthetic data quality in wireless sensing, introduces SynCheck for quality-guided data utilization, and shows improved performance over traditional methods.", "motivation": "Current synthetic data in wireless sensing lacks predictable quality, leading to performance issues. The paper aims to address this by quantifying and improving synthetic data quality.", "method": "Proposes affinity and diversity metrics to evaluate synthetic data quality. Introduces SynCheck, a scheme to refine synthetic data during training.", "result": "SynCheck outperforms traditional methods, achieving a 4.3% performance improvement even when previous methods degrade performance by 13.4%.", "conclusion": "Quality-guided synthetic data utilization (SynCheck) effectively addresses limitations in current synthetic data, enhancing wireless sensing task performance."}}
{"id": "2506.22864", "pdf": "https://arxiv.org/pdf/2506.22864", "abs": "https://arxiv.org/abs/2506.22864", "authors": ["Li-Cheng Shen", "Jih-Kang Hsieh", "Wei-Hua Li", "Chu-Song Chen"], "title": "Mask-aware Text-to-Image Retrieval: Referring Expression Segmentation Meets Cross-modal Retrieval", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "ICMR 2025", "summary": "Text-to-image retrieval (TIR) aims to find relevant images based on a textual\nquery, but existing approaches are primarily based on whole-image captions and\nlack interpretability. Meanwhile, referring expression segmentation (RES)\nenables precise object localization based on natural language descriptions but\nis computationally expensive when applied across large image collections. To\nbridge this gap, we introduce Mask-aware TIR (MaTIR), a new task that unifies\nTIR and RES, requiring both efficient image search and accurate object\nsegmentation. To address this task, we propose a two-stage framework,\ncomprising a first stage for segmentation-aware image retrieval and a second\nstage for reranking and object grounding with a multimodal large language model\n(MLLM). We leverage SAM 2 to generate object masks and Alpha-CLIP to extract\nregion-level embeddings offline at first, enabling effective and scalable\nonline retrieval. Secondly, MLLM is used to refine retrieval rankings and\ngenerate bounding boxes, which are matched to segmentation masks. We evaluate\nour approach on COCO and D$^3$ datasets, demonstrating significant improvements\nin both retrieval accuracy and segmentation quality over previous methods.", "AI": {"tldr": "MaTIR unifies text-to-image retrieval (TIR) and referring expression segmentation (RES) for efficient search and accurate segmentation, using a two-stage framework with SAM 2 and Alpha-CLIP for offline mask generation and MLLM for reranking.", "motivation": "Existing TIR lacks interpretability, and RES is computationally expensive for large datasets. MaTIR bridges this gap.", "method": "Two-stage framework: 1) Segmentation-aware retrieval using SAM 2 and Alpha-CLIP for offline mask/embedding generation. 2) MLLM for reranking and object grounding.", "result": "Improved retrieval accuracy and segmentation quality on COCO and D$^3$ datasets.", "conclusion": "MaTIR effectively combines TIR and RES, offering scalable and accurate results."}}
{"id": "2506.23508", "pdf": "https://arxiv.org/pdf/2506.23508", "abs": "https://arxiv.org/abs/2506.23508", "authors": ["Zhihao Zhang", "Qiaole Dong", "Qi Zhang", "Jun Zhao", "Enyu Zhou", "Zhiheng Xi", "Senjie Jin", "Xiaoran Fan", "Yuhao Zhou", "Yanwei Fu", "Tao Ji", "Tao Gui", "Xuanjing Huang"], "title": "Reinforcement Fine-Tuning Enables MLLMs Learning Novel Tasks Stably", "categories": ["cs.CL", "cs.AI"], "comment": "18 pages (Preprint. Work in progress)", "summary": "Post-training algorithms such as Supervised Fine-Tuning (SFT) and\nReinforcement Fine-Tuning (RFT) are widely used to adapt multimodal large\nlanguage models to downstream tasks. While effective at task adaptation, their\nimpact on prior knowledge remains unclear. In this paper, we introduce jigsaw\npuzzles as a novel task absent from existing pretraining corpora and\nsystematically study the behavior of SFT and RFT on an open-source multimodal\nmodel, Qwen2.5-VL. Our experiments reveal a sharp trade-off: SFT enables rapid\ntask acquisition but leads to catastrophic forgetting, whereas RFT learns more\nslowly on novel tasks but maintains prior knowledge. We analyze this phenomenon\nthrough the lens of learning dynamics, showing that RFT reinforces correct\nsamples that are naturally aligned with the base model's probability landscape,\nmitigating interference with prior knowledge. Moreover, supervised training on\ncorrect RFT-simulated rollouts allows SFT to preserve knowledge while rapidly\nlearning new tasks. These findings suggest that data distribution, rather than\nalgorithmic differences, plays a central role in forgetting, and highlight\nRFT's potential for stable continual learning in multimodal large language\nmodels.", "AI": {"tldr": "The paper explores the trade-off between SFT and RFT in adapting multimodal models, showing SFT causes forgetting while RFT preserves prior knowledge.", "motivation": "To understand how post-training methods like SFT and RFT affect prior knowledge in multimodal models.", "method": "Introduces jigsaw puzzles as a novel task and tests SFT and RFT on Qwen2.5-VL, analyzing learning dynamics.", "result": "SFT learns quickly but forgets prior knowledge, while RFT learns slowly but retains knowledge. RFT's alignment with the base model mitigates interference.", "conclusion": "Data distribution, not just algorithms, drives forgetting. RFT is promising for stable continual learning in multimodal models."}}
{"id": "2501.08005", "pdf": "https://arxiv.org/pdf/2501.08005", "abs": "https://arxiv.org/abs/2501.08005", "authors": ["Francisco Caetano", "Christiaan Viviers", "Luis A. Zavala-Mondrag\u00f3n", "Peter H. N. de With", "Fons van der Sommen"], "title": "DisCoPatch: Taming Adversarially-driven Batch Statistics for Improved Out-of-Distribution Detection", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": "ICCV 2025", "summary": "Out-of-distribution (OOD) detection holds significant importance across many\napplications. While semantic and domain-shift OOD problems are well-studied,\nthis work focuses on covariate shifts - subtle variations in the data\ndistribution that can degrade machine learning performance. We hypothesize that\ndetecting these subtle shifts can improve our understanding of in-distribution\nboundaries, ultimately improving OOD detection. In adversarial discriminators\ntrained with Batch Normalization (BN), real and adversarial samples form\ndistinct domains with unique batch statistics - a property we exploit for OOD\ndetection. We introduce DisCoPatch, an unsupervised Adversarial Variational\nAutoencoder (VAE) framework that harnesses this mechanism. During inference,\nbatches consist of patches from the same image, ensuring a consistent data\ndistribution that allows the model to rely on batch statistics. DisCoPatch uses\nthe VAE's suboptimal outputs (generated and reconstructed) as negative samples\nto train the discriminator, thereby improving its ability to delineate the\nboundary between in-distribution samples and covariate shifts. By tightening\nthis boundary, DisCoPatch achieves state-of-the-art results in public OOD\ndetection benchmarks. The proposed model not only excels in detecting covariate\nshifts, achieving 95.5% AUROC on ImageNet-1K(-C) but also outperforms all prior\nmethods on public Near-OOD (95.0%) benchmarks. With a compact model size of\n25MB, it achieves high OOD detection performance at notably lower latency than\nexisting methods, making it an efficient and practical solution for real-world\nOOD detection applications. The code is publicly available.", "AI": {"tldr": "DisCoPatch, an unsupervised Adversarial VAE framework, detects covariate shifts in OOD detection by leveraging batch statistics and adversarial discriminators, achieving state-of-the-art results.", "motivation": "The paper addresses the challenge of detecting subtle covariate shifts in data distribution, which degrade ML performance, aiming to improve OOD detection by better understanding in-distribution boundaries.", "method": "DisCoPatch uses an Adversarial VAE framework with Batch Normalization, exploiting batch statistics from patches of the same image. It trains the discriminator using suboptimal VAE outputs as negative samples.", "result": "DisCoPatch achieves 95.5% AUROC on ImageNet-1K(-C) and 95.0% on Near-OOD benchmarks, with a compact 25MB model size and low latency.", "conclusion": "DisCoPatch is an efficient, practical solution for OOD detection, outperforming prior methods and offering high performance with low computational cost."}}
{"id": "2506.22468", "pdf": "https://arxiv.org/pdf/2506.22468", "abs": "https://arxiv.org/abs/2506.22468", "authors": ["Konstantinos Koutras", "Agorakis Bompotas", "Constantinos Halkiopoulos", "Athanasios Kalogeras", "Christos Alexakos"], "title": "Dimensionality Reduction on IoT Monitoring Data of Smart Building for Energy Consumption Forecasting", "categories": ["eess.SP", "cs.AI"], "comment": "Version of submitted paper on 2023 IEEE International Smart Cities\n  Conference (ISC2), 1-6, 2023", "summary": "The Internet of Things (IoT) plays a major role today in smart building\ninfrastructures, from simple smart-home applications, to more sophisticated\nindustrial type installations. The vast amounts of data generated from relevant\nsystems can be processed in different ways revealing important information.\nThis is especially true in the era of edge computing, when advanced data\nanalysis and decision-making is gradually moving to the edge of the network\nwhere devices are generally characterised by low computing resources. In this\ncontext, one of the emerging main challenges is related to maintaining data\nanalysis accuracy even with less data that can be efficiently handled by low\nresource devices. The present work focuses on correlation analysis of data\nretrieved from a pilot IoT network installation monitoring a small smart office\nby means of environmental and energy consumption sensors. The research\nmotivation was to find statistical correlation between the monitoring variables\nthat will allow the use of machine learning (ML) prediction algorithms for\nenergy consumption reducing input parameters. For this to happen, a series of\nhypothesis tests for the correlation of three different environmental variables\nwith the energy consumption were carried out. A total of ninety tests were\nperformed, thirty for each pair of variables. In these tests, p-values showed\nthe existence of strong or semi-strong correlation with two environmental\nvariables, and of a weak correlation with a third one. Using the proposed\nmethodology, we manage without examining the entire data set to exclude weak\ncorrelated variables while keeping the same score of accuracy.", "AI": {"tldr": "The paper explores IoT data correlation in smart buildings, using edge computing to optimize energy consumption predictions by identifying strong correlations between environmental variables and energy usage.", "motivation": "To reduce input parameters for ML energy consumption predictions by identifying statistically significant correlations between environmental variables and energy usage in IoT-monitored smart offices.", "method": "Conducted 90 hypothesis tests (30 per variable pair) to analyze correlations between three environmental variables and energy consumption, using p-values to determine strength.", "result": "Found strong/semi-strong correlations with two environmental variables and weak correlation with a third, enabling exclusion of weakly correlated variables without losing accuracy.", "conclusion": "The methodology successfully reduces data input for ML models by focusing on strongly correlated variables, maintaining accuracy in energy consumption predictions."}}
{"id": "2506.23182", "pdf": "https://arxiv.org/pdf/2506.23182", "abs": "https://arxiv.org/abs/2506.23182", "authors": ["Robert Frank", "Michael Widrich", "Rahmad Akbar", "G\u00fcnter Klambauer", "Geir Kjetil Sandve", "Philippe A. Robert", "Victor Greiff"], "title": "Attribution assignment for deep-generative sequence models enables interpretability analysis using positive-only data", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Generative machine learning models offer a powerful framework for therapeutic\ndesign by efficiently exploring large spaces of biological sequences enriched\nfor desirable properties. Unlike supervised learning methods, which require\nboth positive and negative labeled data, generative models such as LSTMs can be\ntrained solely on positively labeled sequences, for example, high-affinity\nantibodies. This is particularly advantageous in biological settings where\nnegative data are scarce, unreliable, or biologically ill-defined. However, the\nlack of attribution methods for generative models has hindered the ability to\nextract interpretable biological insights from such models. To address this\ngap, we developed Generative Attribution Metric Analysis (GAMA), an attribution\nmethod for autoregressive generative models based on Integrated Gradients. We\nassessed GAMA using synthetic datasets with known ground truths to characterize\nits statistical behavior and validate its ability to recover biologically\nrelevant features. We further demonstrated the utility of GAMA by applying it\nto experimental antibody-antigen binding data. GAMA enables model\ninterpretability and the validation of generative sequence design strategies\nwithout the need for negative training data.", "AI": {"tldr": "GAMA is an attribution method for generative models like LSTMs, enabling interpretability in biological sequence design without needing negative data.", "motivation": "Generative models lack interpretability, hindering biological insights. GAMA addresses this gap.", "method": "Developed GAMA using Integrated Gradients, tested on synthetic and experimental antibody-antigen data.", "result": "GAMA successfully recovers biologically relevant features and validates generative designs.", "conclusion": "GAMA enhances interpretability and validation in generative sequence design, especially where negative data is scarce."}}
{"id": "2506.22866", "pdf": "https://arxiv.org/pdf/2506.22866", "abs": "https://arxiv.org/abs/2506.22866", "authors": ["Hang-Cheng Dong", "Lu Zou", "Bingguo Liu", "Dong Ye", "Guodong Liu"], "title": "Region-Aware CAM: High-Resolution Weakly-Supervised Defect Segmentation via Salient Region Perception", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Surface defect detection plays a critical role in industrial quality\ninspection. Recent advances in artificial intelligence have significantly\nenhanced the automation level of detection processes. However, conventional\nsemantic segmentation and object detection models heavily rely on large-scale\nannotated datasets, which conflicts with the practical requirements of defect\ndetection tasks. This paper proposes a novel weakly supervised semantic\nsegmentation framework comprising two key components: a region-aware class\nactivation map (CAM) and pseudo-label training. To address the limitations of\nexisting CAM methods, especially low-resolution thermal maps, and insufficient\ndetail preservation, we introduce filtering-guided backpropagation (FGBP),\nwhich refines target regions by filtering gradient magnitudes to identify areas\nwith higher relevance to defects. Building upon this, we further develop a\nregion-aware weighted module to enhance spatial precision. Finally,\npseudo-label segmentation is implemented to refine the model's performance\niteratively. Comprehensive experiments on industrial defect datasets\ndemonstrate the superiority of our method. The proposed framework effectively\nbridges the gap between weakly supervised learning and high-precision defect\nsegmentation, offering a practical solution for resource-constrained industrial\nscenarios.", "AI": {"tldr": "A weakly supervised semantic segmentation framework for surface defect detection, using region-aware CAM and pseudo-label training, outperforms traditional methods.", "motivation": "Addressing the reliance on large annotated datasets in defect detection by proposing a weakly supervised approach.", "method": "Introduces filtering-guided backpropagation (FGBP) for refined CAM and a region-aware weighted module, followed by pseudo-label training.", "result": "Superior performance on industrial defect datasets, bridging weakly supervised learning and high-precision segmentation.", "conclusion": "The framework offers a practical solution for industrial defect detection with limited resources."}}
{"id": "2506.23524", "pdf": "https://arxiv.org/pdf/2506.23524", "abs": "https://arxiv.org/abs/2506.23524", "authors": ["Phan Quoc Hung Mai", "Quang Hung Nguyen", "Phuong Giang Duong", "Hong Hanh Nguyen", "Nguyen Tuan Long"], "title": "NEU-ESC: A Comprehensive Vietnamese dataset for Educational Sentiment analysis and topic Classification toward multitask learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the field of education, understanding students' opinions through their\ncomments is crucial, especially in the Vietnamese language, where resources\nremain limited. Existing educational datasets often lack domain relevance and\nstudent slang. To address these gaps, we introduce NEU-ESC, a new Vietnamese\ndataset for Educational Sentiment Classification and Topic Classification,\ncurated from university forums, which offers more samples, richer class\ndiversity, longer texts, and broader vocabulary. In addition, we explore\nmultitask learning using encoder-only language models (BERT), in which we\nshowed that it achieves performance up to 83.7% and 79.8% accuracy for\nsentiment and topic classification tasks. We also benchmark our dataset and\nmodel with other datasets and models, including Large Language Models, and\ndiscuss these benchmarks. The dataset is publicly available at:\nhttps://huggingface.co/datasets/hung20gg/NEU-ESC.", "AI": {"tldr": "The paper introduces NEU-ESC, a Vietnamese dataset for sentiment and topic classification in education, addressing gaps in existing datasets. It uses multitask learning with BERT, achieving high accuracy, and benchmarks against other models.", "motivation": "Existing educational datasets lack domain relevance and student slang in Vietnamese. NEU-ESC fills this gap with richer, more diverse data.", "method": "Multitask learning with encoder-only language models (BERT) is applied to the NEU-ESC dataset for sentiment and topic classification.", "result": "The model achieves 83.7% and 79.8% accuracy for sentiment and topic classification, respectively.", "conclusion": "NEU-ESC provides a valuable resource for Vietnamese educational sentiment analysis, with strong performance demonstrated by BERT-based multitask learning."}}
{"id": "2505.10589", "pdf": "https://arxiv.org/pdf/2505.10589", "abs": "https://arxiv.org/abs/2505.10589", "authors": ["Ka\u011fan \u00c7etin", "Hacer Ak\u00e7a", "\u00d6mer Nezih Gerek"], "title": "Super-Resolution Generative Adversarial Networks based Video Enhancement", "categories": ["cs.CV", "cs.AI", "eess.IV", "I.4.3"], "comment": "28 pages, 14 figures, 3 tables", "summary": "This study introduces an enhanced approach to video super-resolution by\nextending ordinary Single-Image Super-Resolution (SISR) Super-Resolution\nGenerative Adversarial Network (SRGAN) structure to handle spatio-temporal\ndata. While SRGAN has proven effective for single-image enhancement, its design\ndoes not account for the temporal continuity required in video processing. To\naddress this, a modified framework that incorporates 3D Non-Local Blocks is\nproposed, which is enabling the model to capture relationships across both\nspatial and temporal dimensions. An experimental training pipeline is\ndeveloped, based on patch-wise learning and advanced data degradation\ntechniques, to simulate real-world video conditions and learn from both local\nand global structures and details. This helps the model generalize better and\nmaintain stability across varying video content while maintaining the general\nstructure besides the pixel-wise correctness. Two model variants-one larger and\none more lightweight-are presented to explore the trade-offs between\nperformance and efficiency. The results demonstrate improved temporal\ncoherence, sharper textures, and fewer visual artifacts compared to traditional\nsingle-image methods. This work contributes to the development of practical,\nlearning-based solutions for video enhancement tasks, with potential\napplications in streaming, gaming, and digital restoration.", "AI": {"tldr": "An enhanced video super-resolution method extends SRGAN with 3D Non-Local Blocks for spatio-temporal data, improving temporal coherence and reducing artifacts.", "motivation": "SRGAN lacks temporal continuity for video processing, prompting the need for a modified framework.", "method": "Incorporates 3D Non-Local Blocks and uses patch-wise learning with advanced data degradation techniques.", "result": "Improved temporal coherence, sharper textures, and fewer artifacts compared to single-image methods.", "conclusion": "This work advances practical learning-based video enhancement for applications like streaming and gaming."}}
{"id": "2506.22477", "pdf": "https://arxiv.org/pdf/2506.22477", "abs": "https://arxiv.org/abs/2506.22477", "authors": ["Huiwen Han"], "title": "Innovative Research on IoT Architecture and Robotic Operating Platforms: Applications of Large Language Models and Generative AI", "categories": ["cs.NI", "cs.AI", "cs.ET", "cs.RO"], "comment": "Published in: 2024 6th International Conference on Robotics,\n  Intelligent Control and Artificial Intelligence (RICAI), IEEE Xplore, DOI:\n  10.1109/RICAI64321.2024.10911316. \\c{opyright} 2024 IEEE", "summary": "This paper introduces an innovative design for robotic operating platforms,\nunderpinned by a transformative Internet of Things (IoT) architecture,\nseamlessly integrating cutting-edge technologies such as large language models\n(LLMs), generative AI, edge computing, and 5G networks. The proposed platform\naims to elevate the intelligence and autonomy of IoT systems and robotics,\nenabling them to make real-time decisions and adapt dynamically to changing\nenvironments. Through a series of compelling case studies across industries\nincluding smart manufacturing, healthcare, and service sectors, this paper\ndemonstrates the substantial potential of IoT-enabled robotics to optimize\noperational workflows, enhance productivity, and deliver innovative, scalable\nsolutions. By emphasizing the roles of LLMs and generative AI, the research\nhighlights how these technologies drive the evolution of intelligent robotics\nand IoT, shaping the future of industry-specific advancements. The findings not\nonly showcase the transformative power of these technologies but also offer a\nforward-looking perspective on their broader societal and industrial\nimplications, positioning them as catalysts for next-generation automation and\ntechnological convergence.", "AI": {"tldr": "The paper presents a robotic operating platform with IoT, LLMs, generative AI, edge computing, and 5G, enhancing intelligence and autonomy for real-time decision-making. Case studies in smart manufacturing, healthcare, and services highlight its transformative potential.", "motivation": "To advance IoT and robotics by integrating cutting-edge technologies for dynamic adaptability and real-time decision-making.", "method": "Proposes a platform combining IoT, LLMs, generative AI, edge computing, and 5G, validated through industry case studies.", "result": "Demonstrates significant improvements in workflow optimization, productivity, and scalable solutions across industries.", "conclusion": "The platform showcases the transformative impact of these technologies, positioning them as key drivers for future automation and convergence."}}
{"id": "2506.23186", "pdf": "https://arxiv.org/pdf/2506.23186", "abs": "https://arxiv.org/abs/2506.23186", "authors": ["Marco Bressan", "Victor Chepoi", "Emmanuel Esposito", "Maximilian Thiessen"], "title": "Efficient Algorithms for Learning and Compressing Monophonic Halfspaces in Graphs", "categories": ["cs.LG", "cs.DM", "math.CO", "stat.ML"], "comment": null, "summary": "Abstract notions of convexity over the vertices of a graph, and corresponding\nnotions of halfspaces, have recently gained attention from the machine learning\ncommunity. In this work we study monophonic halfspaces, a notion of graph\nhalfspaces defined through closure under induced paths. Our main result is a\n$2$-satisfiability based decomposition theorem, which allows one to represent\nmonophonic halfspaces as a disjoint union of certain vertex subsets. Using this\ndecomposition, we achieve efficient and (nearly) optimal algorithms for various\nlearning problems, such as teaching, active, and online learning. Most notably,\nwe obtain a polynomial-time algorithm for empirical risk minimization.\nIndependently of the decomposition theorem, we obtain an efficient, stable, and\nproper sample compression scheme. This makes monophonic halfspaces efficiently\nlearnable with proper learners and linear error rate $1/\\varepsilon$ in the\nrealizable PAC setting. Our results answer open questions from the literature,\nand show a stark contrast with geodesic halfspaces, for which most of the said\nlearning problems are NP-hard.", "AI": {"tldr": "The paper studies monophonic halfspaces in graphs, introduces a decomposition theorem, and provides efficient learning algorithms, contrasting with the NP-hardness of geodesic halfspaces.", "motivation": "To explore convexity notions in graphs and address learning problems efficiently, answering open questions in the literature.", "method": "Uses a $2$-satisfiability based decomposition theorem to represent monophonic halfspaces as disjoint vertex subsets.", "result": "Achieves efficient algorithms for teaching, active, online learning, and empirical risk minimization, along with a stable sample compression scheme.", "conclusion": "Monophonic halfspaces are efficiently learnable, unlike geodesic halfspaces, resolving open questions and demonstrating practical applicability."}}
{"id": "2506.22868", "pdf": "https://arxiv.org/pdf/2506.22868", "abs": "https://arxiv.org/abs/2506.22868", "authors": ["Junsung Lee", "Junoh Kang", "Bohyung Han"], "title": "STR-Match: Matching SpatioTemporal Relevance Score for Training-Free Video Editing", "categories": ["cs.CV", "cs.AI"], "comment": "15 pages, 9 figures, 3 tables", "summary": "Previous text-guided video editing methods often suffer from temporal\ninconsistency, motion distortion, and-most notably-limited domain\ntransformation. We attribute these limitations to insufficient modeling of\nspatiotemporal pixel relevance during the editing process. To address this, we\npropose STR-Match, a training-free video editing algorithm that produces\nvisually appealing and spatiotemporally coherent videos through latent\noptimization guided by our novel STR score. The score captures spatiotemporal\npixel relevance across adjacent frames by leveraging 2D spatial attention and\n1D temporal modules in text-to-video (T2V) diffusion models, without the\noverhead of computationally expensive 3D attention mechanisms. Integrated into\na latent optimization framework with a latent mask, STR-Match generates\ntemporally consistent and visually faithful videos, maintaining strong\nperformance even under significant domain transformations while preserving key\nvisual attributes of the source. Extensive experiments demonstrate that\nSTR-Match consistently outperforms existing methods in both visual quality and\nspatiotemporal consistency.", "AI": {"tldr": "STR-Match is a training-free video editing method using a novel STR score for spatiotemporal coherence, outperforming existing methods in quality and consistency.", "motivation": "Addressing limitations like temporal inconsistency, motion distortion, and limited domain transformation in text-guided video editing.", "method": "Uses latent optimization guided by STR score, leveraging 2D spatial attention and 1D temporal modules in T2V diffusion models.", "result": "Produces visually appealing, spatiotemporally coherent videos, even under significant domain transformations.", "conclusion": "STR-Match consistently outperforms existing methods in visual quality and spatiotemporal consistency."}}
{"id": "2506.23527", "pdf": "https://arxiv.org/pdf/2506.23527", "abs": "https://arxiv.org/abs/2506.23527", "authors": ["Jan Kvapil", "Martin Fajcik"], "title": "On Recipe Memorization and Creativity in Large Language Models: Is Your Model a Creative Cook, a Bad Cook, or Merely a Plagiator?", "categories": ["cs.CL"], "comment": "13 pages, 5 figures", "summary": "This work-in-progress investigates the memorization, creativity, and nonsense\nfound in cooking recipes generated from Large Language Models (LLMs).\nPrecisely, we aim (i) to analyze memorization, creativity, and non-sense in\nLLMs using a small, high-quality set of human judgments and (ii) to evaluate\npotential approaches to automate such a human annotation in order to scale our\nstudy to hundreds of recipes. To achieve (i), we conduct a detailed human\nannotation on 20 preselected recipes generated by LLM (Mixtral), extracting\neach recipe's ingredients and step-by-step actions to assess which elements are\nmemorized--i.e., directly traceable to online sources possibly seen during\ntraining--and which arise from genuine creative synthesis or outright nonsense.\nWe find that Mixtral consistently reuses ingredients that can be found in\nonline documents, potentially seen during model training, suggesting strong\nreliance on memorized content. To achieve aim (ii) and scale our analysis\nbeyond small sample sizes and single LLM validation, we design an\n``LLM-as-judge'' pipeline that automates recipe generation, nonsense detection,\nparsing ingredients and recipe steps, and their annotation. For instance,\ncomparing its output against human annotations, the best ingredient extractor\nand annotator is Llama 3.1+Gemma 2 9B, achieving up to 78% accuracy on\ningredient matching. This automated framework enables large-scale\nquantification of memorization, creativity, and nonsense in generated recipes,\nproviding rigorous evidence of the models' creative capacities.", "AI": {"tldr": "The paper investigates memorization, creativity, and nonsense in LLM-generated recipes, using human annotations and an automated pipeline for scalability.", "motivation": "To analyze how LLMs balance memorization, creativity, and nonsense in generated recipes and to automate this analysis for scalability.", "method": "Human annotation of 20 recipes from Mixtral, followed by an automated \"LLM-as-judge\" pipeline for large-scale analysis.", "result": "Mixtral relies on memorized content, while the automated pipeline (Llama 3.1+Gemma 2 9B) achieves 78% accuracy in ingredient matching.", "conclusion": "The automated framework enables scalable quantification of memorization and creativity in LLM-generated recipes, revealing their creative capacities."}}
{"id": "2506.22479", "pdf": "https://arxiv.org/pdf/2506.22479", "abs": "https://arxiv.org/abs/2506.22479", "authors": ["Krisanu Sarkar"], "title": "Hindsight-Guided Momentum (HGM) Optimizer: An Approach to Adaptive Learning Rate", "categories": ["math.OC", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce Hindsight-Guided Momentum (HGM), a first-order optimization\nalgorithm that adaptively scales learning rates based on the directional\nconsistency of recent updates. Traditional adaptive methods, such as Adam or\nRMSprop , adapt learning dynamics using only the magnitude of gradients, often\noverlooking important geometric cues.Geometric cues refer to directional\ninformation, such as the alignment between current gradients and past updates,\nwhich reflects the local curvature and consistency of the optimization path.\nHGM addresses this by incorporating a hindsight mechanism that evaluates the\ncosine similarity between the current gradient and accumulated momentum. This\nallows it to distinguish between coherent and conflicting gradient directions,\nincreasing the learning rate when updates align and reducing it in regions of\noscillation or noise. The result is a more responsive optimizer that\naccelerates convergence in smooth regions of the loss surface while maintaining\nstability in sharper or more erratic areas. Despite this added adaptability,\nthe method preserves the computational and memory efficiency of existing\noptimizers.By more intelligently responding to the structure of the\noptimization landscape, HGM provides a simple yet effective improvement over\nexisting approaches, particularly in non-convex settings like that of deep\nneural network training.", "AI": {"tldr": "HGM is a first-order optimization algorithm that adapts learning rates using directional consistency of updates, improving convergence and stability in non-convex settings like deep learning.", "motivation": "Traditional adaptive methods (e.g., Adam, RMSprop) ignore geometric cues like gradient alignment, which can improve optimization efficiency.", "method": "HGM evaluates cosine similarity between current gradients and past momentum to adjust learning rates adaptively.", "result": "HGM accelerates convergence in smooth regions and maintains stability in erratic areas, outperforming existing optimizers.", "conclusion": "HGM offers a simple, efficient, and effective improvement for non-convex optimization, especially in deep neural networks."}}
{"id": "2506.23201", "pdf": "https://arxiv.org/pdf/2506.23201", "abs": "https://arxiv.org/abs/2506.23201", "authors": ["Haoran Li", "Muhao Guo", "Marija Ilic", "Yang Weng", "Guangchun Ruan"], "title": "External Data-Enhanced Meta-Representation for Adaptive Probabilistic Load Forecasting", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "10 pages", "summary": "Accurate residential load forecasting is critical for power system\nreliability with rising renewable integration and demand-side flexibility.\nHowever, most statistical and machine learning models treat external factors,\nsuch as weather, calendar effects, and pricing, as extra input, ignoring their\nheterogeneity, and thus limiting the extraction of useful external information.\nWe propose a paradigm shift: external data should serve as meta-knowledge to\ndynamically adapt the forecasting model itself. Based on this idea, we design a\nmeta-representation framework using hypernetworks that modulate selected\nparameters of a base Deep Learning (DL) model in response to external\nconditions. This provides both expressivity and adaptability. We further\nintegrate a Mixture-of-Experts (MoE) mechanism to enhance efficiency through\nselective expert activation, while improving robustness by filtering redundant\nexternal inputs. The resulting model, dubbed as a Meta Mixture of Experts for\nExternal data (M2oE2), achieves substantial improvements in accuracy and\nrobustness with limited additional overhead, outperforming existing\nstate-of-the-art methods in diverse load datasets. The dataset and source code\nare publicly available at\nhttps://github.com/haorandd/M2oE2\\_load\\_forecast.git.", "AI": {"tldr": "The paper introduces M2oE2, a meta-representation framework using hypernetworks and Mixture-of-Experts to dynamically adapt load forecasting models based on external data, improving accuracy and robustness.", "motivation": "Accurate residential load forecasting is crucial for power system reliability, but existing models inadequately handle external factors like weather and pricing, limiting their effectiveness.", "method": "The authors propose a hypernetwork-based framework that modulates a base DL model using external data as meta-knowledge, integrating a MoE mechanism for selective expert activation and input filtering.", "result": "M2oE2 outperforms state-of-the-art methods in accuracy and robustness across diverse datasets, with minimal additional overhead.", "conclusion": "The framework successfully leverages external data to enhance load forecasting, offering a scalable and efficient solution for power systems."}}
{"id": "2506.22880", "pdf": "https://arxiv.org/pdf/2506.22880", "abs": "https://arxiv.org/abs/2506.22880", "authors": ["Dang Jisheng", "Wu Xudong", "Wang Bimei", "Lv Ning", "Chen Jiayu", "Jingwen Zhao", "Yichu liu", "Jizhao Liu", "Juncheng Li", "Teng Wang"], "title": "Decoupled Seg Tokens Make Stronger Reasoning Video Segmenter and Grounder", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Existing video segmenter and grounder approaches, exemplified by Sa2VA,\ndirectly fuse features within segmentation models. This often results in an\nundesirable entanglement of dynamic visual information and static semantics,\nthereby degrading segmentation accuracy. To systematically mitigate this issue,\nwe propose DeSa2VA, a decoupling-enhanced prompting scheme integrating text\npre-training and a linear decoupling module to address the information\nprocessing limitations inherent in SAM-2. Specifically, first, we devise a\npre-training paradigm that converts textual ground-truth labels into\npoint-level prompts while generating corresponding text masks. These masks are\nrefined through a hybrid loss function to strengthen the model's semantic\ngrounding capabilities. Next, we employ linear projection to disentangle hidden\nstates that generated by a large language model into distinct textual and\nvisual feature subspaces. Finally, a dynamic mask fusion strategy\nsynergistically combines these decoupled features through triple supervision\nfrom predicted text/visual masks and ground-truth annotations. Extensive\nexperiments demonstrate state-of-the-art performance across diverse tasks,\nincluding image segmentation, image question answering, video segmentation, and\nvideo question answering. Our codes are available at\nhttps://github.com/longmalongma/DeSa2VA.", "AI": {"tldr": "DeSa2VA introduces a decoupling-enhanced prompting scheme to improve segmentation accuracy by disentangling visual and textual features, outperforming existing methods in multiple tasks.", "motivation": "Existing methods like Sa2VA fuse features in segmentation models, leading to entangled dynamic visual and static semantic information, which degrades accuracy.", "method": "DeSa2VA uses text pre-training, a linear decoupling module, and dynamic mask fusion to separate and synergize textual and visual features.", "result": "The method achieves state-of-the-art performance in image/video segmentation and question answering tasks.", "conclusion": "DeSa2VA effectively addresses feature entanglement, enhancing segmentation accuracy and semantic grounding."}}
{"id": "2506.23601", "pdf": "https://arxiv.org/pdf/2506.23601", "abs": "https://arxiv.org/abs/2506.23601", "authors": ["Weijie Shi", "Yue Cui", "Yaguang Wu", "Jingzhi Fang", "Shibo Zhang", "Mengze Li", "Sirui Han", "Jia Zhu", "Jiajie Xu", "Xiaofang Zhou"], "title": "Semantic-guided Diverse Decoding for Large Language Model", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Diverse decoding of large language models is crucial for applications\nrequiring multiple semantically distinct responses, yet existing methods\nprimarily achieve lexical rather than semantic diversity. This limitation\nsignificantly constrains Best-of-N strategies, group-based reinforcement\nlearning, and data synthesis. While temperature sampling and diverse beam\nsearch modify token distributions or apply n-gram penalties, they fail to\nensure meaningful semantic differentiation. We introduce Semantic-guided\nDiverse Decoding (SemDiD), operating directly in embedding space that balances\nquality with diversity through three complementary mechanisms: orthogonal\ndirectional guidance, dynamic inter-group repulsion, and position-debiased\nprobability assessment. SemDiD harmonizes these competing objectives using\nadaptive gain functions and constraint optimization, ensuring both quality\nthresholds and maximal semantic differentiation. Experiments show SemDiD\nconsistently outperforms existing methods, improving Best-of-N coverage by\n1.4-5.2% across diverse tasks and accelerating RLHF training convergence by 15%\nwhile increasing accuracy by up to 2.1%.", "AI": {"tldr": "SemDiD improves semantic diversity in LLM decoding, outperforming existing methods in coverage and training efficiency.", "motivation": "Existing methods lack semantic diversity, limiting applications like Best-of-N strategies and reinforcement learning.", "method": "SemDiD uses orthogonal directional guidance, dynamic inter-group repulsion, and position-debiased probability assessment in embedding space.", "result": "SemDiD improves Best-of-N coverage by 1.4-5.2%, accelerates RLHF training by 15%, and increases accuracy by up to 2.1%.", "conclusion": "SemDiD effectively balances quality and semantic diversity, enhancing performance in diverse tasks."}}
{"id": "2506.22487", "pdf": "https://arxiv.org/pdf/2506.22487", "abs": "https://arxiv.org/abs/2506.22487", "authors": ["Amar Khelloufi", "Huansheng Ning", "Sahraoui Dhelim", "Jianguo Ding"], "title": "AGI Enabled Solutions For IoX Layers Bottlenecks In Cyber-Physical-Social-Thinking Space", "categories": ["cs.NI", "cs.AI"], "comment": "31 pages, 5 figures", "summary": "The integration of the Internet of Everything (IoX) and Artificial General\nIntelligence (AGI) has given rise to a transformative paradigm aimed at\naddressing critical bottlenecks across sensing, network, and application layers\nin Cyber-Physical-Social Thinking (CPST) ecosystems. In this survey, we provide\na systematic and comprehensive review of AGI-enhanced IoX research, focusing on\nthree key components: sensing-layer data management, network-layer protocol\noptimization, and application-layer decision-making frameworks. Specifically,\nthis survey explores how AGI can mitigate IoX bottlenecks challenges by\nleveraging adaptive sensor fusion, edge preprocessing, and selective attention\nmechanisms at the sensing layer, while resolving network-layer issues such as\nprotocol heterogeneity and dynamic spectrum management, neuro-symbolic\nreasoning, active inference, and causal reasoning, Furthermore, the survey\nexamines AGI-enabled frameworks for managing identity and relationship\nexplosion. Key findings suggest that AGI-driven strategies, such as adaptive\nsensor fusion, edge preprocessing, and semantic modeling, offer novel solutions\nto sensing-layer data overload, network-layer protocol heterogeneity, and\napplication-layer identity explosion. The survey underscores the importance of\ncross-layer integration, quantum-enabled communication, and ethical governance\nframeworks for future AGI-enabled IoX systems. Finally, the survey identifies\nunresolved challenges, such as computational requirements, scalability, and\nreal-world validation, calling for further research to fully realize AGI's\npotential in addressing IoX bottlenecks. we believe AGI-enhanced IoX is\nemerging as a critical research field at the intersection of interconnected\nsystems and advanced AI.", "AI": {"tldr": "The paper surveys AGI-enhanced IoX, addressing bottlenecks in CPST ecosystems through sensing, network, and application layers, highlighting solutions like adaptive sensor fusion and neuro-symbolic reasoning, while noting unresolved challenges.", "motivation": "To explore how AGI can address critical bottlenecks in IoX systems across sensing, network, and application layers, aiming to enhance CPST ecosystems.", "method": "Systematic review of AGI-enhanced IoX research, focusing on sensing-layer data management, network-layer protocol optimization, and application-layer decision-making frameworks.", "result": "AGI-driven strategies (e.g., adaptive sensor fusion, semantic modeling) effectively mitigate IoX bottlenecks, but challenges like scalability and real-world validation remain.", "conclusion": "AGI-enhanced IoX is a promising field, requiring further research on computational demands, scalability, and ethical governance to fully realize its potential."}}
{"id": "2506.23210", "pdf": "https://arxiv.org/pdf/2506.23210", "abs": "https://arxiv.org/abs/2506.23210", "authors": ["Taehwan Yoon", "Bongjun Choi"], "title": "FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "6 pages,14 equation", "summary": "Federated learning(FL) is used for distributed scenarios to train artificial\nintelligence(AI) models while ensuring users' privacy. In federated learning\nscenario, the server generally never knows about users' data. This type of\nconcept makes the AI training process efficient in terms of data privacy.\nHowever, regarding model performance, federated AI models may not sufficiently\nsatisfy AI users' expectations. Furthermore, AI users have a wide range of\ndifferent needs. It is not easy to satisfy the whole users needs. These types\nof issues can be addressed through AI model optimization, fine-tuning, or\npersonalization to achieve optimal model performance. To address model\noptimization challenges, we propose reference model-based federated learning\nfor optimal fine-tuning, which overcomes catastrophic forgetting in each round.\nThis method is derived from Bayesian parameter-efficient transfer learning,\nwhich includes an optimal proximal term and enables overcoming the catastrophic\nforgetting issue in each round by utilizing a reference model that incorporates\nprevious model parameters. As a result, this method achieves both high model\nperformance and low computing cost.", "AI": {"tldr": "Proposes reference model-based federated learning for optimal fine-tuning, addressing catastrophic forgetting and improving model performance efficiently.", "motivation": "Federated learning ensures privacy but struggles with model performance and diverse user needs, requiring optimization and personalization.", "method": "Uses Bayesian parameter-efficient transfer learning with an optimal proximal term and a reference model to prevent catastrophic forgetting.", "result": "Achieves high model performance and low computing cost.", "conclusion": "The method effectively balances privacy, performance, and efficiency in federated learning."}}
{"id": "2506.22881", "pdf": "https://arxiv.org/pdf/2506.22881", "abs": "https://arxiv.org/abs/2506.22881", "authors": ["Fumiya Uchiyama", "Rintaro Yanagi", "Shohei Taniguchi", "Shota Takashiro", "Masahiro Suzuki", "Hirokatsu Kataoka", "Yusuke Iwasawa", "Yutaka Matsuo"], "title": "How Semantically Informative is an Image?: Measuring the Covariance-Weighted Norm of Contrastive Learning Embeddings", "categories": ["cs.CV"], "comment": null, "summary": "Contrastive learning has the capacity to model multimodal probability\ndistributions by embedding and aligning visual representations with semantics\nfrom captions. This approach enables the estimation of relational semantic\nsimilarity; however, it remains unclear whether it can also represent absolute\nsemantic informativeness. In this work, we introduce a semantic informativeness\nmetric for an image calculated from text samples via a contrastive learning\nmodel; similarly, the informativeness of a text is calculated from image\nsamples. We propose a redefinition of the concept of Information Gain, a\nconcept previously explored in natural language processing, extending its\napplication to the domains of vision and language. Our metric quantifies how\nconditioning on an image distorts the distribution of associated texts, and\nvice versa for text conditioning on image distributions. In OpenCLIP's\nempirical results, we observe that images with the lowest Information Gain\nscores often correspond to placeholder icons such as \"image not found.\"\nFurthermore, we propose to measure a norm-based metric of the embedding to\nestimate the Information Gain, following the theoretical results for Skip-Gram\nwith Negative Sampling (SGNS) word embedding. Information Gain can be measured\nusing either CLIP or SigLIP, and the results demonstrate a strong correlation\nwith a coefficient of determination ranging from 0.98 to 1.00. After obtaining\nthe mean and the covariance of the sample embedding, the computational cost of\nthis method is independent of the sample size, and it is compatible with\npublicly available, open-weight models.", "AI": {"tldr": "The paper introduces a semantic informativeness metric for images and texts using contrastive learning, extending Information Gain to vision and language domains. It validates the metric with strong correlations and low computational costs.", "motivation": "To address whether contrastive learning can represent absolute semantic informativeness, not just relational similarity, by quantifying how conditioning on an image or text distorts their associated distributions.", "method": "Proposes a metric for semantic informativeness using contrastive learning models (CLIP or SigLIP), measuring Information Gain by embedding norms and validating it empirically.", "result": "Strong correlation (R\u00b2 0.98-1.00) between the metric and theoretical expectations, with low computational cost post-embedding. Placeholder icons score lowest in Information Gain.", "conclusion": "The introduced metric effectively quantifies semantic informativeness, is computationally efficient, and works with open-weight models, bridging vision and language domains."}}
{"id": "2506.23610", "pdf": "https://arxiv.org/pdf/2506.23610", "abs": "https://arxiv.org/abs/2506.23610", "authors": ["Manuel Pratelli", "Marinella Petrocchi"], "title": "Evaluating the Simulation of Human Personality-Driven Susceptibility to Misinformation with LLMs", "categories": ["cs.CL", "cs.CY"], "comment": "pre-print version - paper actually under submission", "summary": "Large language models (LLMs) make it possible to generate synthetic\nbehavioural data at scale, offering an ethical and low-cost alternative to\nhuman experiments. Whether such data can faithfully capture psychological\ndifferences driven by personality traits, however, remains an open question. We\nevaluate the capacity of LLM agents, conditioned on Big-Five profiles, to\nreproduce personality-based variation in susceptibility to misinformation,\nfocusing on news discernment, the ability to judge true headlines as true and\nfalse headlines as false. Leveraging published datasets in which human\nparticipants with known personality profiles rated headline accuracy, we create\nmatching LLM agents and compare their responses to the original human patterns.\nCertain trait-misinformation associations, notably those involving\nAgreeableness and Conscientiousness, are reliably replicated, whereas others\ndiverge, revealing systematic biases in how LLMs internalize and express\npersonality. The results underscore both the promise and the limits of\npersonality-aligned LLMs for behavioral simulation, and offer new insight into\nmodeling cognitive diversity in artificial agents.", "AI": {"tldr": "LLMs can generate synthetic behavioral data, but their ability to replicate personality-driven psychological differences is mixed. Some traits like Agreeableness and Conscientiousness are reliably replicated, while others diverge.", "motivation": "To assess if LLMs can faithfully reproduce personality-based variations in behavior, specifically in susceptibility to misinformation, as an ethical and scalable alternative to human experiments.", "method": "LLM agents were conditioned on Big-Five personality profiles and compared to human participants' responses to headline accuracy, using published datasets.", "result": "Some personality traits (e.g., Agreeableness, Conscientiousness) were reliably replicated in LLM responses, while others showed systematic biases.", "conclusion": "LLMs show promise for behavioral simulation but have limits in fully capturing personality-driven cognitive diversity, highlighting both potential and challenges."}}
{"id": "2506.22492", "pdf": "https://arxiv.org/pdf/2506.22492", "abs": "https://arxiv.org/abs/2506.22492", "authors": ["Rajeev Alur", "Greg Durrett", "Hadas Kress-Gazit", "Corina P\u0103s\u0103reanu", "Ren\u00e9 Vidal"], "title": "Report on NSF Workshop on Science of Safe AI", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Recent advances in machine learning, particularly the emergence of foundation\nmodels, are leading to new opportunities to develop technology-based solutions\nto societal problems. However, the reasoning and inner workings of today's\ncomplex AI models are not transparent to the user, and there are no safety\nguarantees regarding their predictions. Consequently, to fulfill the promise of\nAI, we must address the following scientific challenge: how to develop AI-based\nsystems that are not only accurate and performant but also safe and\ntrustworthy?\n  The criticality of safe operation is particularly evident for autonomous\nsystems for control and robotics, and was the catalyst for the Safe Learning\nEnabled Systems (SLES) program at NSF. For the broader class of AI\napplications, such as users interacting with chatbots and clinicians receiving\ntreatment recommendations, safety is, while no less important, less\nwell-defined with context-dependent interpretations. This motivated the\norganization of a day-long workshop, held at University of Pennsylvania on\nFebruary 26, 2025, to bring together investigators funded by the NSF SLES\nprogram with a broader pool of researchers studying AI safety. This report is\nthe result of the discussions in the working groups that addressed different\naspects of safety at the workshop. The report articulates a new research agenda\nfocused on developing theory, methods, and tools that will provide the\nfoundations of the next generation of AI-enabled systems.", "AI": {"tldr": "The paper discusses the need for safe and trustworthy AI systems, highlighting challenges in transparency and safety, and proposes a research agenda to address these issues.", "motivation": "The rise of complex AI models lacks transparency and safety guarantees, necessitating solutions to ensure AI is accurate, performant, safe, and trustworthy.", "method": "Organized a workshop with NSF SLES program investigators and AI safety researchers to discuss safety aspects and develop a research agenda.", "result": "A new research agenda was formulated to create theory, methods, and tools for safer AI-enabled systems.", "conclusion": "The paper emphasizes the urgency of addressing AI safety and outlines a roadmap for future research to achieve trustworthy AI systems."}}
{"id": "2506.23221", "pdf": "https://arxiv.org/pdf/2506.23221", "abs": "https://arxiv.org/abs/2506.23221", "authors": ["B\u00e1lint Horv\u00e1th", "Bal\u00e1zs Csan\u00e1d Cs\u00e1ji"], "title": "Single Image Inpainting and Super-Resolution with Simultaneous Uncertainty Guarantees by Universal Reproducing Kernels", "categories": ["cs.LG", "cs.CV"], "comment": "23 pages, 8 figures, 6 tables", "summary": "The paper proposes a statistical learning approach to the problem of\nestimating missing pixels of images, crucial for image inpainting and\nsuper-resolution problems. One of the main novelties of the method is that it\nalso provides uncertainty quantifications together with the estimated values.\nOur core assumption is that the underlying data-generating function comes from\na Reproducing Kernel Hilbert Space (RKHS). A special emphasis is put on\nband-limited functions, central to signal processing, which form Paley-Wiener\ntype RKHSs. The proposed method, which we call Simultaneously Guaranteed Kernel\nInterpolation (SGKI), is an extension and refinement of a recently developed\nkernel method. An advantage of SGKI is that it not only estimates the missing\npixels, but also builds non-asymptotic confidence bands for the unobserved\nvalues, which are simultaneously guaranteed for all missing pixels. We also\nshow how to compute these bands efficiently using Schur complements, we discuss\na generalization to vector-valued functions, and we present a series of\nnumerical experiments on various datasets containing synthetically generated\nand benchmark images, as well.", "AI": {"tldr": "The paper introduces SGKI, a kernel-based method for image inpainting and super-resolution, providing pixel estimates with uncertainty quantification.", "motivation": "Addressing the need for reliable missing pixel estimation in images, including uncertainty measures, is crucial for tasks like inpainting and super-resolution.", "method": "SGKI extends kernel methods, assuming data from RKHS, particularly band-limited functions, and uses Schur complements for efficient confidence band computation.", "result": "SGKI successfully estimates missing pixels and provides non-asymptotic confidence bands, validated through experiments on synthetic and benchmark datasets.", "conclusion": "SGKI offers a robust solution for image inpainting and super-resolution with uncertainty quantification, generalizable to vector-valued functions."}}
{"id": "2506.22890", "pdf": "https://arxiv.org/pdf/2506.22890", "abs": "https://arxiv.org/abs/2506.22890", "authors": ["Senkang Hu", "Yihang Tao", "Guowen Xu", "Xinyuan Qian", "Yiqin Deng", "Xianhao Chen", "Sam Tak Wu Kwong", "Yuguang Fang"], "title": "CP-Guard: A Unified, Probability-Agnostic, and Adaptive Framework for Malicious Agent Detection and Defense in Multi-Agent Embodied Perception Systems", "categories": ["cs.CV", "cs.CR"], "comment": null, "summary": "Collaborative Perception (CP) has been shown to be a promising technique for\nmulti-agent autonomous driving and multi-agent robotic systems, where multiple\nagents share their perception information to enhance the overall perception\nperformance and expand the perception range. However, in CP, an ego agent needs\nto receive messages from its collaborators, which makes it vulnerable to\nattacks from malicious agents. To address this critical issue, we propose a\nunified, probability-agnostic, and adaptive framework, namely, CP-Guard, which\nis a tailored defense mechanism for CP deployed by each agent to accurately\ndetect and eliminate malicious agents in its collaboration network. Our key\nidea is to enable CP to reach a consensus rather than a conflict against an ego\nagent's perception results. Based on this idea, we first develop a\nprobability-agnostic sample consensus (PASAC) method to effectively sample a\nsubset of the collaborators and verify the consensus without prior\nprobabilities of malicious agents. Furthermore, we define collaborative\nconsistency loss (CCLoss) for object detection task and bird's eye view (BEV)\nsegmentation task to capture the discrepancy between an ego agent and its\ncollaborators, which is used as a verification criterion for consensus. In\naddition, we propose online adaptive threshold via dual sliding windows to\ndynamically adjust the threshold for consensus verification and ensure the\nreliability of the systems in dynamic environments. Finally, we conduct\nextensive experiments and demonstrate the effectiveness of our framework. Code\nwill be released at https://github.com/CP-Security/CP-Guard", "AI": {"tldr": "CP-Guard is a defense framework for Collaborative Perception (CP) systems to detect and eliminate malicious agents by ensuring consensus among collaborators.", "motivation": "CP systems are vulnerable to attacks from malicious agents, necessitating a robust defense mechanism.", "method": "The framework includes a probability-agnostic sample consensus (PASAC) method, collaborative consistency loss (CCLoss), and adaptive thresholds for dynamic environments.", "result": "Extensive experiments validate the framework's effectiveness in detecting and mitigating malicious agents.", "conclusion": "CP-Guard provides a reliable, adaptive solution to secure CP systems against malicious attacks."}}
{"id": "2506.23661", "pdf": "https://arxiv.org/pdf/2506.23661", "abs": "https://arxiv.org/abs/2506.23661", "authors": ["Arnisa Fazla", "Lucas Krauter", "David Guzman Piedrahita", "Andrianos Michail"], "title": "Robustness of Misinformation Classification Systems to Adversarial Examples Through BeamAttack", "categories": ["cs.CL"], "comment": "12 pages main text, 27 pages total including references and\n  appendices. 13 figures, 10 tables. Accepted for publication in the LNCS\n  proceedings of CLEF 2025 (Best-of-Labs track)", "summary": "We extend BeamAttack, an adversarial attack algorithm designed to evaluate\nthe robustness of text classification systems through word-level modifications\nguided by beam search. Our extensions include support for word deletions and\nthe option to skip substitutions, enabling the discovery of minimal\nmodifications that alter model predictions. We also integrate LIME to better\nprioritize word replacements. Evaluated across multiple datasets and victim\nmodels (BiLSTM, BERT, and adversarially trained RoBERTa) within the BODEGA\nframework, our approach achieves over a 99\\% attack success rate while\npreserving the semantic and lexical similarity of the original texts. Through\nboth quantitative and qualitative analysis, we highlight BeamAttack's\neffectiveness and its limitations. Our implementation is available at\nhttps://github.com/LucK1Y/BeamAttack", "AI": {"tldr": "BeamAttack is extended to include word deletions and skip substitutions, achieving high attack success rates while preserving text similarity.", "motivation": "To enhance the robustness evaluation of text classification systems by discovering minimal adversarial modifications.", "method": "Extends BeamAttack with word deletions, skip substitutions, and LIME integration for prioritized word replacements. Evaluated on BiLSTM, BERT, and RoBERTa within BODEGA.", "result": "Over 99% attack success rate while maintaining semantic and lexical similarity.", "conclusion": "BeamAttack is effective but has limitations; implementation is publicly available."}}
{"id": "2506.22495", "pdf": "https://arxiv.org/pdf/2506.22495", "abs": "https://arxiv.org/abs/2506.22495", "authors": ["He-Yang Xu", "Hongxiang Gao", "Yuwen Li", "Xiu-Shen Wei", "Chengyu Liu"], "title": "Masked Autoencoders that Feel the Heart: Unveiling Simplicity Bias for ECG Analyses", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "The diagnostic value of electrocardiogram (ECG) lies in its dynamic\ncharacteristics, ranging from rhythm fluctuations to subtle waveform\ndeformations that evolve across time and frequency domains. However, supervised\nECG models tend to overfit dominant and repetitive patterns, overlooking\nfine-grained but clinically critical cues, a phenomenon known as Simplicity\nBias (SB), where models favor easily learnable signals over subtle but\ninformative ones. In this work, we first empirically demonstrate the presence\nof SB in ECG analyses and its negative impact on diagnostic performance, while\nsimultaneously discovering that self-supervised learning (SSL) can alleviate\nit, providing a promising direction for tackling the bias. Following the SSL\nparadigm, we propose a novel method comprising two key components: 1)\nTemporal-Frequency aware Filters to capture temporal-frequency features\nreflecting the dynamic characteristics of ECG signals, and 2) building on this,\nMulti-Grained Prototype Reconstruction for coarse and fine representation\nlearning across dual domains, further mitigating SB. To advance SSL in ECG\nanalyses, we curate a large-scale multi-site ECG dataset with 1.53 million\nrecordings from over 300 clinical centers. Experiments on three downstream\ntasks across six ECG datasets demonstrate that our method effectively reduces\nSB and achieves state-of-the-art performance. Code and dataset will be released\npublicly.", "AI": {"tldr": "The paper addresses Simplicity Bias (SB) in ECG models, showing self-supervised learning (SSL) can mitigate it. A novel SSL method with temporal-frequency filters and multi-grained prototype reconstruction is proposed, achieving state-of-the-art results on a large ECG dataset.", "motivation": "Supervised ECG models overfit dominant patterns, ignoring subtle but critical cues (SB). SSL is identified as a potential solution.", "method": "Proposes Temporal-Frequency aware Filters and Multi-Grained Prototype Reconstruction for SSL in ECG analysis.", "result": "Method reduces SB and achieves state-of-the-art performance on three tasks across six datasets.", "conclusion": "SSL effectively mitigates SB in ECG analysis, with the proposed method outperforming existing approaches."}}
{"id": "2506.23225", "pdf": "https://arxiv.org/pdf/2506.23225", "abs": "https://arxiv.org/abs/2506.23225", "authors": ["Yukito Tajima", "Nakamasa Inoue", "Yusuke Sekikawa", "Ikuro Sato", "Rio Yokota"], "title": "Masked Gated Linear Unit", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Gated Linear Units (GLUs) have become essential components in the\nfeed-forward networks of state-of-the-art Large Language Models (LLMs).\nHowever, they require twice as many memory reads compared to feed-forward\nlayers without gating, due to the use of separate weight matrices for the gate\nand value streams. To address this bottleneck, we introduce Masked Gated Linear\nUnits (MGLUs), a novel family of GLUs with an efficient kernel implementation.\nThe core contribution of MGLUs include: (1) the Mixture of Element-wise Gating\n(MoEG) architecture that learns multiple binary masks, each determining gate or\nvalue assignments at the element level on a single shared weight matrix\nresulting in reduced memory transfer, and (2) FlashMGLU, a hardware-friendly\nkernel that yields up to a 19.7 $\\times$ inference-time speed-up over a naive\nPyTorch MGLU and is 47% more memory-efficient and 34% faster than standard GLUs\ndespite added architectural complexity on an RTX5090 GPU. In LLM experiments,\nthe Swish-activated variant SwiMGLU preserves its memory advantages while\nmatching - or even surpassing - the downstream accuracy of the SwiGLU baseline.", "AI": {"tldr": "MGLUs introduce efficient GLUs with shared weight matrices and hardware-friendly kernels, reducing memory usage and speeding up inference while maintaining accuracy.", "motivation": "GLUs in LLMs require high memory reads due to separate weight matrices for gates and values, creating a bottleneck.", "method": "Proposes Masked Gated Linear Units (MGLUs) with Mixture of Element-wise Gating (MoEG) and FlashMGLU kernel for efficiency.", "result": "MGLUs achieve up to 19.7\u00d7 speed-up, 47% memory efficiency, and match/surpass SwiGLU accuracy.", "conclusion": "MGLUs offer a hardware-efficient alternative to GLUs without compromising performance in LLMs."}}
{"id": "2506.22900", "pdf": "https://arxiv.org/pdf/2506.22900", "abs": "https://arxiv.org/abs/2506.22900", "authors": ["Mai A. Shaaban", "Tausifa Jan Saleem", "Vijay Ram Papineni", "Mohammad Yaqub"], "title": "MOTOR: Multimodal Optimal Transport via Grounded Retrieval in Medical Visual Question Answering", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Medical visual question answering (MedVQA) plays a vital role in clinical\ndecision-making by providing contextually rich answers to image-based queries.\nAlthough vision-language models (VLMs) are widely used for this task, they\noften generate factually incorrect answers. Retrieval-augmented generation\naddresses this challenge by providing information from external sources, but\nrisks retrieving irrelevant context, which can degrade the reasoning\ncapabilities of VLMs. Re-ranking retrievals, as introduced in existing\napproaches, enhances retrieval relevance by focusing on query-text alignment.\nHowever, these approaches neglect the visual or multimodal context, which is\nparticularly crucial for medical diagnosis. We propose MOTOR, a novel\nmultimodal retrieval and re-ranking approach that leverages grounded captions\nand optimal transport. It captures the underlying relationships between the\nquery and the retrieved context based on textual and visual information.\nConsequently, our approach identifies more clinically relevant contexts to\naugment the VLM input. Empirical analysis and human expert evaluation\ndemonstrate that MOTOR achieves higher accuracy on MedVQA datasets,\noutperforming state-of-the-art methods by an average of 6.45%. Code is\navailable at https://github.com/BioMedIA-MBZUAI/MOTOR.", "AI": {"tldr": "MOTOR improves MedVQA by using multimodal retrieval and re-ranking with grounded captions and optimal transport, outperforming existing methods by 6.45%.", "motivation": "Existing VLMs for MedVQA often produce incorrect answers, and retrieval-augmented methods risk irrelevant context, neglecting visual/multimodal cues crucial for medical diagnosis.", "method": "Proposes MOTOR, a multimodal retrieval and re-ranking approach using grounded captions and optimal transport to align query and context with visual/textual data.", "result": "MOTOR achieves higher accuracy on MedVQA datasets, outperforming state-of-the-art methods by 6.45%.", "conclusion": "MOTOR effectively enhances retrieval relevance and accuracy in MedVQA by integrating multimodal context."}}
{"id": "2506.23662", "pdf": "https://arxiv.org/pdf/2506.23662", "abs": "https://arxiv.org/abs/2506.23662", "authors": ["Philip Lippmann", "Jie Yang"], "title": "Zero-Shot Contextual Embeddings via Offline Synthetic Corpus Generation", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Context-aware embedding methods boost retrieval accuracy by conditioning on\ncorpus statistics (e.g., term co-occurrence and topical patterns) extracted\nfrom neighboring documents. However, this context-aware approach requires\naccess to the target corpus or requires domain-specific finetuning, posing\npractical barriers in privacy-sensitive or resource-constrained settings. We\npresent ZEST, a zero-shot contextual adaptation framework that replaces real\ncorpus access with a one-time offline synthesis of a compact proxy. Given only\na handful exemplar documents representative of the general target domain, we\nuse a multi-step hierarchical procedure to generate a synthetic context corpus\nof several hundred documents that aims to emulate key domain-specific\ndistributions. At inference, the frozen context-aware encoder uses this proxy\ncorpus -- without any finetuning or target corpus access -- to produce\ndomain-adapted embeddings. Across the MTEB benchmark, ZEST's zero-shot\nsynthetic context adaptation using only five example documents performs within\n0.5% of models leveraging full target corpus access -- demonstrating remarkable\nefficacy without any retraining. ZEST thus provides a practical method for\ndeploying high-performance, adaptable embeddings in constrained environments.", "AI": {"tldr": "ZEST is a zero-shot contextual adaptation framework that generates a synthetic proxy corpus for domain-adapted embeddings without requiring target corpus access or finetuning.", "motivation": "Existing context-aware embedding methods need target corpus access or domain-specific finetuning, which is impractical in privacy-sensitive or resource-limited settings.", "method": "ZEST synthesizes a compact proxy corpus from a few exemplar documents using a hierarchical procedure, emulating domain-specific distributions.", "result": "ZEST achieves within 0.5% accuracy of models with full corpus access on the MTEB benchmark, using only five example documents.", "conclusion": "ZEST enables high-performance, adaptable embeddings in constrained environments without retraining or corpus access."}}
{"id": "2506.22496", "pdf": "https://arxiv.org/pdf/2506.22496", "abs": "https://arxiv.org/abs/2506.22496", "authors": ["Y. Du"], "title": "Mitigating Gambling-Like Risk-Taking Behaviors in Large Language Models: A Behavioral Economics Approach to AI Safety", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": "7 pages", "summary": "Large Language Models (LLMs) exhibit systematic risk-taking behaviors\nanalogous to those observed in gambling psychology, including overconfidence\nbias, loss-chasing tendencies, and probability misjudgment. Drawing from\nbehavioral economics and prospect theory, we identify and formalize these\n\"gambling-like\" patterns where models sacrifice accuracy for high-reward\noutputs, exhibit escalating risk-taking after errors, and systematically\nmiscalibrate uncertainty. We propose the Risk-Aware Response Generation (RARG)\nframework, incorporating insights from gambling research to address these\nbehavioral biases through risk-calibrated training, loss-aversion mechanisms,\nand uncertainty-aware decision making. Our approach introduces novel evaluation\nparadigms based on established gambling psychology experiments, including AI\nadaptations of the Iowa Gambling Task and probability learning assessments.\nExperimental results demonstrate measurable reductions in gambling-like\nbehaviors: 18.7\\% decrease in overconfidence bias, 24.3\\% reduction in\nloss-chasing tendencies, and improved risk calibration across diverse\nscenarios. This work establishes the first systematic framework for\nunderstanding and mitigating gambling psychology patterns in AI systems.", "AI": {"tldr": "LLMs show gambling-like behaviors (overconfidence, loss-chasing, probability misjudgment). The RARG framework mitigates these biases, reducing them by 18.7-24.3%.", "motivation": "To address systematic risk-taking behaviors in LLMs, inspired by gambling psychology and behavioral economics.", "method": "Proposed the RARG framework with risk-calibrated training, loss-aversion mechanisms, and uncertainty-aware decision making. Evaluated using gambling psychology experiments (e.g., Iowa Gambling Task).", "result": "Reduced overconfidence bias by 18.7%, loss-chasing by 24.3%, and improved risk calibration.", "conclusion": "RARG is the first framework to systematically mitigate gambling-like behaviors in AI systems."}}
{"id": "2506.23266", "pdf": "https://arxiv.org/pdf/2506.23266", "abs": "https://arxiv.org/abs/2506.23266", "authors": ["Lujun Li", "Zhu Qiyuan", "Jiacheng Wang", "Wei Li", "Hao Gu", "Sirui Han", "Yike Guo"], "title": "Sub-MoE: Efficient Mixture-of-Expert LLMs Compression via Subspace Expert Merging", "categories": ["cs.LG"], "comment": "Work in progress, revisions ongoing", "summary": "Mixture of Experts (MoE) LLMs face significant obstacles due to their massive\nparameter scale, which imposes memory, storage, and deployment challenges.\nAlthough recent expert merging methods promise greater efficiency by\nconsolidating multiple experts, they are fundamentally hindered by parameter\nconflicts arising from expert specialization. In this paper, we present\nSub-MoE, a novel MoE compression framework via Subspace Expert Merging. Our key\ninsight is to perform joint Singular Value Decomposition (SVD) on concatenated\nexpert weights, reducing conflicting parameters by extracting shared\n$U$-matrices while enabling effective merging of the expert-specific $V$\ncomponents. Specifically, Sub-MoE consists of two innovative phases: (1)\nAdaptive Expert Clustering, which groups functionally coherent experts via\nK-means clustering based on cosine similarity of expert outputs; and (2)\nSubspace Expert Merging, which first enforces Experts Union Decomposition to\nderive the shared $U$-matrix across experts in the same group, then pursues\nfrequency-based merging for individual $V$-matrices, and finalizes expert\nreconstruction using the merged $V$-matrix. In this way, we align and fuse\nexperts in a shared subspace, and can be extended with intra-expert compression\nfor further inference optimization. Extensive experiments on Mixtral, DeepSeek,\nand Qwen-1.5|3 MoE LLMs demonstrate that our Sub-MoE significantly outperforms\nexisting expert pruning and merging methods. Notably, our Sub-MoE maintains\n96\\%|86\\% of original performance with 25\\%|50\\% expert reduction on\nMixtral-8x7B in zero-shot benchmarks. Code will be released at\nhttps://github.com/lliai/MoERazor.", "AI": {"tldr": "Sub-MoE is a compression framework for Mixture of Experts (MoE) models, addressing parameter conflicts via subspace expert merging and adaptive clustering, maintaining high performance with significant expert reduction.", "motivation": "MoE models face memory and deployment challenges due to their large scale, and existing merging methods suffer from parameter conflicts.", "method": "Sub-MoE uses joint SVD on expert weights, adaptive clustering, and subspace merging to align and fuse experts in a shared subspace.", "result": "Sub-MoE retains 96%|86% of performance with 25%|50% expert reduction on Mixtral-8x7B in zero-shot benchmarks.", "conclusion": "Sub-MoE effectively compresses MoE models while preserving performance, outperforming existing methods."}}
{"id": "2506.22907", "pdf": "https://arxiv.org/pdf/2506.22907", "abs": "https://arxiv.org/abs/2506.22907", "authors": ["Yunzhe Shao", "Xinyu Yi", "Lu Yin", "Shihui Guo", "Junhai Yong", "Feng Xu"], "title": "MagShield: Towards Better Robustness in Sparse Inertial Motion Capture Under Magnetic Disturbances", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "This paper proposes a novel method called MagShield, designed to address the\nissue of magnetic interference in sparse inertial motion capture (MoCap)\nsystems. Existing Inertial Measurement Unit (IMU) systems are prone to\norientation estimation errors in magnetically disturbed environments, limiting\ntheir practical application in real-world scenarios. To address this problem,\nMagShield employs a \"detect-then-correct\" strategy, first detecting magnetic\ndisturbances through multi-IMU joint analysis, and then correcting orientation\nerrors using human motion priors. MagShield can be integrated with most\nexisting sparse inertial MoCap systems, improving their performance in\nmagnetically disturbed environments. Experimental results demonstrate that\nMagShield significantly enhances the accuracy of motion capture under magnetic\ninterference and exhibits good compatibility across different sparse inertial\nMoCap systems.", "AI": {"tldr": "MagShield is a novel method to mitigate magnetic interference in sparse inertial MoCap systems by detecting and correcting disturbances using multi-IMU analysis and motion priors.", "motivation": "Existing IMU systems suffer from orientation errors in magnetically disturbed environments, limiting real-world usability.", "method": "MagShield uses a 'detect-then-correct' approach: detecting disturbances via multi-IMU joint analysis and correcting errors with human motion priors.", "result": "MagShield improves motion capture accuracy under magnetic interference and is compatible with various sparse inertial MoCap systems.", "conclusion": "MagShield effectively addresses magnetic interference, enhancing the practicality of sparse inertial MoCap systems in real-world scenarios."}}
{"id": "2506.23667", "pdf": "https://arxiv.org/pdf/2506.23667", "abs": "https://arxiv.org/abs/2506.23667", "authors": ["Junjie Zhang", "Jingyi Xi", "Zhuoyang Song", "Junyu Lu", "Yuhua Ke", "Ting Sun", "Yukun Yang", "Jiaxing Zhang", "Songxin Zhang", "Zejian Xie"], "title": "L0: Reinforcement Learning to Become General Agents", "categories": ["cs.CL"], "comment": null, "summary": "Training large language models (LLMs) to act as autonomous agents for\nmulti-turn, long-horizon tasks remains significant challenges in scalability\nand training efficiency. To address this, we introduce L-Zero (L0), a scalable,\nend-to-end training pipeline for general-purpose agents. Featuring a low-cost,\nextensible, and sandboxed concurrent agent worker pool, L0 lowers the barrier\nfor applying reinforcement learning in complex environments. We also introduce\nNB-Agent, the agent scaffold within L0, which operates in a \"code-as-action\"\nfashion via a Read-Eval-Print-Loop (REPL). We evaluate L0 on factuality\nquestion-answering benchmarks. Our experiments demonstrate that a base model\ncan develop robust problem-solving skills using solely Reinforcement Learning\nwith Verifiable Rewards (RLVR). On the Qwen2.5-7B-Instruct model, our method\nboosts accuracy on SimpleQA from 30 % to 80 % and on HotpotQA from 22 % to 41\n%. We have open-sourced the entire L0 system, including our L0 series models,\nthe NB-Agent, a complete training pipeline, and the corresponding training\nrecipes on (https://github.com/cmriat/l0).", "AI": {"tldr": "L-Zero (L0) is a scalable, end-to-end training pipeline for general-purpose agents, improving LLM performance on multi-turn tasks using Reinforcement Learning with Verifiable Rewards (RLVR).", "motivation": "Addressing scalability and training efficiency challenges in training LLMs for autonomous, multi-turn tasks.", "method": "Introduces L0 with a low-cost, sandboxed concurrent agent worker pool and NB-Agent, a code-as-action scaffold. Evaluated on factuality benchmarks.", "result": "Boosts accuracy on SimpleQA from 30% to 80% and on HotpotQA from 22% to 41% using RLVR.", "conclusion": "L0 is effective for training robust agents, with open-sourced resources available."}}
{"id": "2506.22497", "pdf": "https://arxiv.org/pdf/2506.22497", "abs": "https://arxiv.org/abs/2506.22497", "authors": ["Craig Steven Wright"], "title": "Peer Review as Structured Commentary: Immutable Identity, Public Dialogue, and Reproducible Scholarship", "categories": ["cs.CY", "cs.AI", "cs.DL", "cs.SI", "physics.hist-ph", "68T99, 03B30, 91D30", "I.2.0; H.3.5; K.4.4"], "comment": "66 pages, 0 figures, interdisciplinary framework, includes proposed\n  architecture and metadata layer structures", "summary": "This paper reconceptualises peer review as structured public commentary.\nTraditional academic validation is hindered by anonymity, latency, and\ngatekeeping. We propose a transparent, identity-linked, and reproducible system\nof scholarly evaluation anchored in open commentary. Leveraging blockchain for\nimmutable audit trails and AI for iterative synthesis, we design a framework\nthat incentivises intellectual contribution, captures epistemic evolution, and\nenables traceable reputational dynamics. This model empowers fields from\ncomputational science to the humanities, reframing academic knowledge as a\nliving process rather than a static credential.", "AI": {"tldr": "The paper proposes a transparent, identity-linked peer review system using blockchain and AI to improve scholarly evaluation.", "motivation": "Traditional peer review suffers from anonymity, delays, and gatekeeping, hindering academic validation.", "method": "A framework leveraging blockchain for immutable records and AI for iterative synthesis, promoting open commentary.", "result": "The system incentivizes contributions, tracks knowledge evolution, and enables traceable reputational dynamics.", "conclusion": "This model transforms academic knowledge into a dynamic process, benefiting diverse fields."}}
{"id": "2506.23274", "pdf": "https://arxiv.org/pdf/2506.23274", "abs": "https://arxiv.org/abs/2506.23274", "authors": ["Hans Peter Lynsg\u00f8e Raaschou-jensen", "Constanza Fierro", "Anders S\u00f8gaard"], "title": "Predicting thinking time in Reasoning models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reasoning models that produce long, hidden chains of thought have emerged as\npowerful tools for complex, reasoning-intensive\ntasks\\citep{deepseekai2025deepseekr1incentivizingreasoningcapability,\nopenai2024openaio1card}. However, this paradigm introduces a new user\nexperience challenge: users have little insight into how much time the model\nwill spend reasoning before returning an answer. This unpredictability, can\nlead to user frustration and is likely to compound as LLMs can produce\nincreasingly long tasks asynchronously\n\\citep{kwa2025measuringaiabilitycomplete}. In this paper, we introduce and\nevaluate methods for both online and offline prediction of model \"thinking\ntime,\" aiming to develop a practical \"progress bar for reasoning.\" We discuss\nthe implications for user interaction and future research directions.", "AI": {"tldr": "The paper addresses the unpredictability of reasoning time in models with hidden chains of thought, proposing methods to predict and display this time for better user experience.", "motivation": "Users lack insight into how long models will spend reasoning, causing frustration, especially as models handle longer tasks asynchronously.", "method": "Introduces and evaluates online and offline methods to predict model \"thinking time\" for a \"progress bar for reasoning.\"", "result": "Proposes practical solutions for predicting reasoning time, improving user interaction.", "conclusion": "Highlights the need for predictable reasoning time in models and suggests future research directions."}}
{"id": "2506.22908", "pdf": "https://arxiv.org/pdf/2506.22908", "abs": "https://arxiv.org/abs/2506.22908", "authors": ["Yuzhu Wang", "Manni Duan", "Shu Kong"], "title": "Attention to Burstiness: Low-Rank Bilinear Prompt Tuning", "categories": ["cs.CV"], "comment": "ICCV 2025", "summary": "Visual Prompt Tuning (VPT) is a parameter-efficient fune-tuning technique\nthat adapts a pre-trained vision Transformer (ViT) by learning a small set of\nparameters in the input space, known as prompts. In VPT, we uncover\n``burstiness'' in the values arising from the interaction of image patch\nembeddings, and the key and query projectors within Transformer's\nself-attention module. Furthermore, the values of patch embeddings and the key\nand query projectors exhibit Laplacian and hyper-Laplacian distribution,\nrespectively. Intuitively, these non-Gaussian distributions pose challenges for\nlearning prompts. To address this, we propose whitening these data,\nde-correlating them and equalizing their variance towards more Gaussian before\nlearning prompts. We derive the whitening matrix over random image patch\nembeddings and ViT's key and query projectors, and multiply it with the prompt\nto be learned in a bilinear manner. Surprisingly, this method significantly\naccelerates prompt tuning and boosts accuracy, e.g., $>$25 accuracy points on\nthe CUB dataset; interestingly, it learns ``bursty prompts''. Extending the\nbilinear model which is known to introduce burstiness, we present a compact,\nlow-rank version by learning two smaller matrices whose multiplication yields\nthe final prompts. We call the proposed methods Bilinear Prompt Tuning (BPT).\nExtensive experiments across multiple benchmark datasets demonstrate that BPT\nmethods not only outperform various VPT methods but also reduce parameter count\nand computation overhead.", "AI": {"tldr": "Visual Prompt Tuning (VPT) is enhanced by whitening data to address non-Gaussian distributions, leading to Bilinear Prompt Tuning (BPT), which improves accuracy and efficiency.", "motivation": "The non-Gaussian distributions in patch embeddings and key/query projectors challenge prompt learning in VPT.", "method": "Proposes whitening data to de-correlate and equalize variance, then introduces bilinear and low-rank prompt tuning (BPT).", "result": "BPT significantly boosts accuracy (e.g., +25 points on CUB) and reduces parameters/computation.", "conclusion": "BPT outperforms VPT methods, offering a more efficient and effective prompt-tuning approach."}}
{"id": "2506.23735", "pdf": "https://arxiv.org/pdf/2506.23735", "abs": "https://arxiv.org/abs/2506.23735", "authors": ["JiaRu Wu", "Mingwei Liu"], "title": "AutoEvoEval: An Automated Framework for Evolving Close-Ended LLM Evaluation Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have shown remarkable performance on various\ntasks, but existing evaluation benchmarks are often static and insufficient to\nfully assess their robustness and generalization in realistic scenarios. Prior\nwork using evolutionary or adversarial data augmentation has improved\nevaluation diversity but lacks systematic control over perturbation types and\nmulti-step complexity, limiting comprehensive robustness analysis. To address\nthese gaps, we propose AutoEvoEval, an evolution-based evaluation framework for\nclose-ended tasks such as multi-choice question answering. AutoEvoEval\nintroduces 22 interpretable atomic evolution operations and supports\nmulti-round compositions, enabling controlled generation of diverse,\nchallenging, and realistic test samples. We conduct extensive experiments\naddressing four research questions on a broad set of open- and closed-source\nLLMs. Our results show that atomic operations cause an average accuracy drop of\n7.283\\%, with structure-disrupting or misleading semantic edits causing the\nlargest declines. Model sensitivities vary significantly for the same\nperturbation, and combining multiple evolution steps amplifies adversarial\neffects by up to 52.932\\%. These findings suggest current benchmarks may\noverestimate true model generalization and emphasize the need for\nevolution-aware robustness evaluation. Code and resources are available at:\nhttps://github.com/SYSUSELab/AutoEvoEval.", "AI": {"tldr": "AutoEvoEval is an evolution-based framework for evaluating LLMs, introducing 22 atomic operations to generate diverse test samples, revealing significant accuracy drops and model sensitivities.", "motivation": "Existing benchmarks for LLMs are static and lack systematic control over perturbations, limiting robustness assessment.", "method": "Proposes AutoEvoEval with 22 interpretable atomic evolution operations and multi-round compositions for controlled test sample generation.", "result": "Atomic operations cause a 7.283% accuracy drop, with structure-disrupting edits being most harmful. Multi-step perturbations amplify adversarial effects by up to 52.932%.", "conclusion": "Current benchmarks may overestimate model generalization, highlighting the need for evolution-aware robustness evaluation."}}
{"id": "2506.22506", "pdf": "https://arxiv.org/pdf/2506.22506", "abs": "https://arxiv.org/abs/2506.22506", "authors": ["Momin Ahmad Khan", "Yasra Chandio", "Fatima Muhammad Anwar"], "title": "SABRE-FL: Selective and Accurate Backdoor Rejection for Federated Prompt Learning", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Federated Prompt Learning has emerged as a communication-efficient and\nprivacy-preserving paradigm for adapting large vision-language models like CLIP\nacross decentralized clients. However, the security implications of this setup\nremain underexplored. In this work, we present the first study of backdoor\nattacks in Federated Prompt Learning. We show that when malicious clients\ninject visually imperceptible, learnable noise triggers into input images, the\nglobal prompt learner becomes vulnerable to targeted misclassification while\nstill maintaining high accuracy on clean inputs. Motivated by this\nvulnerability, we propose SABRE-FL, a lightweight, modular defense that filters\npoisoned prompt updates using an embedding-space anomaly detector trained\noffline on out-of-distribution data. SABRE-FL requires no access to raw client\ndata or labels and generalizes across diverse datasets. We show, both\ntheoretically and empirically, that malicious clients can be reliably\nidentified and filtered using an embedding-based detector. Across five diverse\ndatasets and four baseline defenses, SABRE-FL outperforms all baselines by\nsignificantly reducing backdoor accuracy while preserving clean accuracy,\ndemonstrating strong empirical performance and underscoring the need for robust\nprompt learning in future federated systems.", "AI": {"tldr": "The paper explores backdoor attacks in Federated Prompt Learning, proposes SABRE-FL as a defense, and demonstrates its effectiveness in reducing attacks while maintaining clean accuracy.", "motivation": "The security implications of Federated Prompt Learning are underexplored, particularly the vulnerability to backdoor attacks by malicious clients.", "method": "The study introduces SABRE-FL, a lightweight defense using an embedding-space anomaly detector to filter poisoned prompt updates without needing raw client data.", "result": "SABRE-FL outperforms baselines by significantly reducing backdoor accuracy while preserving clean accuracy across diverse datasets.", "conclusion": "The findings highlight the need for robust defenses in Federated Prompt Learning to ensure security and privacy."}}
{"id": "2506.23280", "pdf": "https://arxiv.org/pdf/2506.23280", "abs": "https://arxiv.org/abs/2506.23280", "authors": ["Chaoqun Du", "Yulin Wang", "Shiji Song", "Gao Huang"], "title": "BAPE: Learning an Explicit Bayes Classifier for Long-tailed Visual Recognition", "categories": ["cs.LG"], "comment": null, "summary": "Bayesian decision theory advocates the Bayes classifier as the optimal\napproach for minimizing the risk in machine learning problems. Current deep\nlearning algorithms usually solve for the optimal classifier by\n\\emph{implicitly} estimating the posterior probabilities, \\emph{e.g.}, by\nminimizing the Softmax cross-entropy loss. This simple methodology has been\nproven effective for meticulously balanced academic benchmark datasets.\nHowever, it is not applicable to the long-tailed data distributions in the real\nworld, where it leads to the gradient imbalance issue and fails to ensure the\nBayes optimal decision rule. To address these challenges, this paper presents a\nnovel approach (BAPE) that provides a more precise theoretical estimation of\nthe data distributions by \\emph{explicitly} modeling the parameters of the\nposterior probabilities and solving them with point estimation. Consequently,\nour method directly learns the Bayes classifier without gradient descent based\non Bayes' theorem, simultaneously alleviating the gradient imbalance and\nensuring the Bayes optimal decision rule. Furthermore, we propose a\nstraightforward yet effective \\emph{distribution adjustment} technique. This\nmethod enables the Bayes classifier trained from the long-tailed training set\nto effectively adapt to the test data distribution with an arbitrary imbalance\nfactor, thereby enhancing performance without incurring additional\ncomputational costs. In addition, we demonstrate the gains of our method are\northogonal to existing learning approaches for long-tailed scenarios, as they\nare mostly designed under the principle of \\emph{implicitly} estimating the\nposterior probabilities. Extensive empirical evaluations on CIFAR-10-LT,\nCIFAR-100-LT, ImageNet-LT, and iNaturalist demonstrate that our method\nsignificantly improves the generalization performance of popular deep networks,\ndespite its simplicity.", "AI": {"tldr": "The paper introduces BAPE, a method to explicitly model posterior probabilities for Bayes classifier in long-tailed data, addressing gradient imbalance and ensuring optimal decisions.", "motivation": "Current deep learning methods implicitly estimate posterior probabilities, failing in long-tailed data distributions due to gradient imbalance and suboptimal decisions.", "method": "BAPE explicitly models posterior probabilities using point estimation, directly learning the Bayes classifier without gradient descent. It includes a distribution adjustment technique for adapting to test data.", "result": "BAPE significantly improves generalization on CIFAR-10-LT, CIFAR-100-LT, ImageNet-LT, and iNaturalist datasets.", "conclusion": "BAPE offers a simple yet effective solution for long-tailed data, orthogonal to existing methods, ensuring Bayes optimality and improved performance."}}
{"id": "2506.22930", "pdf": "https://arxiv.org/pdf/2506.22930", "abs": "https://arxiv.org/abs/2506.22930", "authors": ["Yiwei He", "Xiangtai Li", "Zhenglin Huang", "Yi Dong", "Hao Fei", "Jiangning Zhang", "Baoyuan Wu", "Guangliang Cheng"], "title": "Towards Explainable Bilingual Multimodal Misinformation Detection and Localization", "categories": ["cs.CV"], "comment": null, "summary": "The increasing realism of multimodal content has made misinformation more\nsubtle and harder to detect, especially in news media where images are\nfrequently paired with bilingual (e.g., Chinese-English) subtitles. Such\ncontent often includes localized image edits and cross-lingual inconsistencies\nthat jointly distort meaning while remaining superficially plausible. We\nintroduce BiMi, a bilingual multimodal framework that jointly performs\nregion-level localization, cross-modal and cross-lingual consistency detection,\nand natural language explanation for misinformation analysis. To support\ngeneralization, BiMi integrates an online retrieval module that supplements\nmodel reasoning with up-to-date external context. We further release BiMiBench,\na large-scale and comprehensive benchmark constructed by systematically editing\nreal news images and subtitles, comprising 104,000 samples with realistic\nmanipulations across visual and linguistic modalities. To enhance\ninterpretability, we apply Group Relative Policy Optimization (GRPO) to improve\nexplanation quality, marking the first use of GRPO in this domain. Extensive\nexperiments demonstrate that BiMi outperforms strong baselines by up to +8.9 in\nclassification accuracy, +15.9 in localization accuracy, and +2.5 in\nexplanation BERTScore, advancing state-of-the-art performance in realistic,\nmultilingual misinformation detection. Code, models, and datasets will be\nreleased.", "AI": {"tldr": "BiMi is a bilingual multimodal framework for detecting misinformation in news media by analyzing region-level edits and cross-lingual inconsistencies, outperforming baselines in accuracy and explanation quality.", "motivation": "The rise of subtle misinformation in bilingual news media, combining localized image edits and cross-lingual inconsistencies, necessitates advanced detection tools.", "method": "BiMi integrates region-level localization, cross-modal/lingual consistency detection, and natural language explanation, enhanced by GRPO for interpretability and an online retrieval module for context.", "result": "BiMi outperforms baselines by +8.9 in classification accuracy, +15.9 in localization accuracy, and +2.5 in explanation BERTScore.", "conclusion": "BiMi advances multilingual misinformation detection, supported by the BiMiBench dataset and GRPO for improved interpretability."}}
{"id": "2506.23743", "pdf": "https://arxiv.org/pdf/2506.23743", "abs": "https://arxiv.org/abs/2506.23743", "authors": ["Tiziano Labruna", "Simone Gallo", "Giovanni Da San Martino"], "title": "Positional Bias in Binary Question Answering: How Uncertainty Shapes Model Preferences", "categories": ["cs.CL"], "comment": null, "summary": "Positional bias in binary question answering occurs when a model\nsystematically favors one choice over another based solely on the ordering of\npresented options. In this study, we quantify and analyze positional bias\nacross five large language models under varying degrees of answer uncertainty.\nWe re-adapted the SQuAD-it dataset by adding an extra incorrect answer option\nand then created multiple versions with progressively less context and more\nout-of-context answers, yielding datasets that range from low to high\nuncertainty. Additionally, we evaluate two naturally higher-uncertainty\nbenchmarks: (1) WebGPT - question pairs with unequal human-assigned quality\nscores, and (2) Winning Arguments - where models predict the more persuasive\nargument in Reddit's r/ChangeMyView exchanges. Across each dataset, the order\nof the \"correct\" (or higher-quality/persuasive) option is systematically\nflipped (first placed in position 1, then in position 2) to compute both\nPreference Fairness and Position Consistency. We observe that positional bias\nis nearly absent under low-uncertainty conditions, but grows exponentially when\nit becomes doubtful to decide which option is correct.", "AI": {"tldr": "The study quantifies positional bias in large language models, showing it grows with answer uncertainty.", "motivation": "To understand how model decisions are influenced by the order of answer options under varying uncertainty.", "method": "Adapted SQuAD-it dataset with incorrect options and tested on WebGPT and Winning Arguments benchmarks, flipping answer order to measure bias.", "result": "Positional bias is minimal in low-uncertainty scenarios but increases exponentially with higher uncertainty.", "conclusion": "Answer ordering significantly impacts model decisions under uncertainty, highlighting a need for bias mitigation."}}
{"id": "2506.22512", "pdf": "https://arxiv.org/pdf/2506.22512", "abs": "https://arxiv.org/abs/2506.22512", "authors": ["Pratheeksha Nair", "Gabriel Lefebvre", "Sophia Garrel", "Maryam Molamohammadi", "Reihaneh Rabbany"], "title": "Ask before you Build: Rethinking AI-for-Good in Human Trafficking Interventions", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "AI for good initiatives often rely on the assumption that technical\ninterventions can resolve complex social problems. In the context of human\ntrafficking (HT), such techno-solutionism risks oversimplifying exploitation,\nreinforcing power imbalances and causing harm to the very communities AI claims\nto support. In this paper, we introduce the Radical Questioning (RQ) framework\nas a five step, pre-project ethical assessment tool to critically evaluate\nwhether AI should be built at all, especially in domains involving marginalized\npopulations and entrenched systemic injustice. RQ does not replace principles\nbased ethics but precedes it, offering an upstream, deliberative space to\nconfront assumptions, map power, and consider harms before design. Using a case\nstudy in AI for HT, we demonstrate how RQ reveals overlooked sociocultural\ncomplexities and guides us away from surveillance based interventions toward\nsurvivor empowerment tools. While developed in the context of HT, RQ's five\nstep structure can generalize to other domains, though the specific questions\nmust be contextual. This paper situates RQ within a broader AI ethics\nphilosophy that challenges instrumentalist norms and centers relational,\nreflexive responsibility.", "AI": {"tldr": "The paper critiques techno-solutionism in AI for social good, proposing the Radical Questioning (RQ) framework to ethically assess AI projects, especially for marginalized groups.", "motivation": "To address the risks of oversimplifying social issues like human trafficking (HT) through AI, which can reinforce power imbalances and harm vulnerable communities.", "method": "Introduces the RQ framework, a five-step pre-project ethical assessment tool to evaluate whether AI should be built, focusing on assumptions, power dynamics, and potential harms.", "result": "RQ helps uncover overlooked sociocultural complexities and shifts focus from surveillance-based AI to survivor empowerment tools, as shown in an HT case study.", "conclusion": "RQ offers a contextual, upstream ethical approach, challenging instrumentalist AI norms and emphasizing relational responsibility, applicable beyond HT."}}
{"id": "2506.23286", "pdf": "https://arxiv.org/pdf/2506.23286", "abs": "https://arxiv.org/abs/2506.23286", "authors": ["Alan Jeffares", "Mihaela van der Schaar"], "title": "Not All Explanations for Deep Learning Phenomena Are Equally Valuable", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at ICML 2025 for oral presentation", "summary": "Developing a better understanding of surprising or counterintuitive phenomena\nhas constituted a significant portion of deep learning research in recent\nyears. These include double descent, grokking, and the lottery ticket\nhypothesis -- among many others. Works in this area often develop ad hoc\nhypotheses attempting to explain these observed phenomena on an isolated,\ncase-by-case basis. This position paper asserts that, in many prominent cases,\nthere is little evidence to suggest that these phenomena appear in real-world\napplications and these efforts may be inefficient in driving progress in the\nbroader field. Consequently, we argue against viewing them as isolated puzzles\nthat require bespoke resolutions or explanations. However, despite this, we\nsuggest that deep learning phenomena do still offer research value by providing\nunique settings in which we can refine our broad explanatory theories of more\ngeneral deep learning principles. This position is reinforced by analyzing the\nresearch outcomes of several prominent examples of these phenomena from the\nrecent literature. We revisit the current norms in the research community in\napproaching these problems and propose practical recommendations for future\nresearch, aiming to ensure that progress on deep learning phenomena is well\naligned with the ultimate pragmatic goal of progress in the broader field of\ndeep learning.", "AI": {"tldr": "The paper critiques the focus on isolated, counterintuitive deep learning phenomena, arguing they lack real-world relevance and inefficiently drive progress. It suggests using them to refine broader theories instead.", "motivation": "To challenge the current research focus on isolated deep learning phenomena (e.g., double descent, grokking) and advocate for aligning research with broader, practical goals.", "method": "Analyzes prominent examples of these phenomena and their research outcomes, revisits current research norms, and proposes practical recommendations.", "result": "Finds little evidence of real-world relevance for these phenomena and suggests they are better used to refine general deep learning theories.", "conclusion": "Recommends shifting focus from isolated puzzles to broader principles to ensure research aligns with practical progress in deep learning."}}
{"id": "2506.22939", "pdf": "https://arxiv.org/pdf/2506.22939", "abs": "https://arxiv.org/abs/2506.22939", "authors": ["Ghufran A. Omran", "Wassan Saad Abduljabbar Hayale", "Ahmad AbdulQadir AlRababah", "Israa Ibraheem Al-Barazanchi", "Ravi Sekhar", "Pritesh Shah", "Sushma Parihar", "Harshavardhan Reddy Penubadi"], "title": "Utilizing a Novel Deep Learning Method for Scene Categorization in Remote Sensing Data", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Scene categorization (SC) in remotely acquired images is an important subject\nwith broad consequences in different fields, including catastrophe control,\necological observation, architecture for cities, and more. Nevertheless, its\nseveral apps, reaching a high degree of accuracy in SC from distant observation\ndata has demonstrated to be difficult. This is because traditional conventional\ndeep learning models require large databases with high variety and high levels\nof noise to capture important visual features. To address these problems, this\ninvestigation file introduces an innovative technique referred to as the\nCuttlefish Optimized Bidirectional Recurrent Neural Network (CO- BRNN) for type\nof scenes in remote sensing data. The investigation compares the execution of\nCO-BRNN with current techniques, including Multilayer Perceptron- Convolutional\nNeural Network (MLP-CNN), Convolutional Neural Network-Long Short Term Memory\n(CNN-LSTM), and Long Short Term Memory-Conditional Random Field (LSTM-CRF),\nGraph-Based (GB), Multilabel Image Retrieval Model (MIRM-CF), Convolutional\nNeural Networks Data Augmentation (CNN-DA). The results demonstrate that\nCO-BRNN attained the maximum accuracy of 97%, followed by LSTM-CRF with 90%,\nMLP-CNN with 85%, and CNN-LSTM with 80%. The study highlights the significance\nof physical confirmation to ensure the efficiency of satellite data.", "AI": {"tldr": "The paper introduces CO-BRNN for SC in remote sensing, achieving 97% accuracy, outperforming existing methods.", "motivation": "High accuracy in SC from remote sensing is challenging due to noise and data variety.", "method": "Proposes CO-BRNN, comparing it with MLP-CNN, CNN-LSTM, LSTM-CRF, GB, MIRM-CF, and CNN-DA.", "result": "CO-BRNN achieved 97% accuracy, surpassing other methods (LSTM-CRF: 90%, MLP-CNN: 85%, CNN-LSTM: 80%).", "conclusion": "CO-BRNN is effective for SC, emphasizing the need for physical validation of satellite data."}}
{"id": "2506.23840", "pdf": "https://arxiv.org/pdf/2506.23840", "abs": "https://arxiv.org/abs/2506.23840", "authors": ["Bowen Ding", "Yuhan Chen", "Futing Wang", "Lingfeng Ming", "Tao Lin"], "title": "Do Thinking Tokens Help or Trap? Towards More Efficient Large Reasoning Model", "categories": ["cs.CL", "cs.AI"], "comment": "13 pages, 5 figures", "summary": "Large Reasoning Models (LRMs) excel at solving complex problems but face an\noverthinking dilemma. When handling simple tasks, they often produce verbose\nresponses overloaded with thinking tokens (e.g., wait, however). These tokens\ntrigger unnecessary high-level reasoning behaviors like reflection and\nbacktracking, reducing efficiency. In this work, our pilot study reveals that\nthese thinking-token-induced behaviors are not essential for effective\nproblem-solving and may even hinder correct reasoning within constrained token\nbudgets. We identify this phenomenon as the thinking trap. To mitigate this\nissue, we propose Dual Policy Preference Optimization (DuP-PO), a novel\nalgorithm featuring: (1) A rollout sampling strategy that guarantees balanced\nexposure to responses with and without thinking tokens; (2) A fine-grained\nadvantage control technique to dynamically regulate the prediction of target\ntokens; (3) A policy shaping method ensuring stable gradient contributions from\nthinking tokens. Experimental results on five popular math reasoning benchmarks\nshow that DuP-PO performs well on the popular LRM, which significantly improves\ntheir token efficiency during reasoning, while achieving superior performance\nof the base model.", "AI": {"tldr": "DuP-PO addresses the 'thinking trap' in LRMs by optimizing token efficiency and reasoning performance through balanced sampling, dynamic token regulation, and stable policy shaping.", "motivation": "LRMs waste tokens on unnecessary high-level reasoning for simple tasks, reducing efficiency. The 'thinking trap' hinders performance under token constraints.", "method": "Proposes DuP-PO with: 1) balanced rollout sampling, 2) dynamic advantage control, and 3) stable policy shaping.", "result": "DuP-PO improves token efficiency and reasoning performance on five math benchmarks, outperforming the base LRM.", "conclusion": "DuP-PO effectively mitigates the thinking trap, enhancing LRM efficiency and accuracy."}}
{"id": "2506.22515", "pdf": "https://arxiv.org/pdf/2506.22515", "abs": "https://arxiv.org/abs/2506.22515", "authors": ["Antony Dalmiere", "Guillaume Auriol", "Vincent Nicomette", "Pascal Marchand"], "title": "In-context learning for the classification of manipulation techniques in phishing emails", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Traditional phishing detection often overlooks psychological manipulation.\nThis study investigates using Large Language Model (LLM) In-Context Learning\n(ICL) for fine-grained classification of phishing emails based on a taxonomy of\n40 manipulation techniques. Using few-shot examples with GPT-4o-mini on\nreal-world French phishing emails (SignalSpam), we evaluated performance\nagainst a human-annotated test set (100 emails). The approach effectively\nidentifies prevalent techniques (e.g., Baiting, Curiosity Appeal, Request For\nMinor Favor) with a promising accuracy of 0.76. This work demonstrates ICL's\npotential for nuanced phishing analysis and provides insights into attacker\nstrategies.", "AI": {"tldr": "The study uses LLM In-Context Learning (ICL) to classify phishing emails by 40 manipulation techniques, achieving 0.76 accuracy on real-world French emails.", "motivation": "Traditional phishing detection often misses psychological manipulation, prompting the need for a nuanced approach.", "method": "Employed GPT-4o-mini with few-shot examples on SignalSpam data (100 human-annotated emails) to classify phishing techniques.", "result": "Achieved 0.76 accuracy in identifying techniques like Baiting, Curiosity Appeal, and Request For Minor Favor.", "conclusion": "ICL shows promise for detailed phishing analysis and understanding attacker strategies."}}
{"id": "2506.23287", "pdf": "https://arxiv.org/pdf/2506.23287", "abs": "https://arxiv.org/abs/2506.23287", "authors": ["Zelin Zang", "WenZhe Li", "Fei Chen", "Yongjie Xu", "Chang Yu", "Zhen Lei", "Stan Z. Li"], "title": "Hierarchical Quantized Diffusion Based Tree Generation Method for Hierarchical Representation and Lineage Analysis", "categories": ["cs.LG", "q-bio.QM"], "comment": "9 pages, 6 figures, under review", "summary": "In single-cell research, tracing and analyzing high-throughput single-cell\ndifferentiation trajectories is crucial for understanding complex biological\nprocesses. Key to this is the modeling and generation of hierarchical data that\nrepresents the intrinsic structure within datasets. Traditional methods face\nlimitations in terms of computational cost, performance, generative capacity,\nand stability. Recent VAEs based approaches have made strides in addressing\nthese challenges but still require specialized network modules for each tree\nbranch, limiting their stability and ability to capture deep hierarchical\nrelationships. To overcome these challenges, we introduce diffusion-based\napproach called HDTree. HDTree captures tree relationships within a\nhierarchical latent space using a unified hierarchical codebook and quantized\ndiffusion processes to model tree node transitions. This method improves\nstability by eliminating branch-specific modules and enhancing generative\ncapacity through gradual hierarchical changes simulated by the diffusion\nprocess. HDTree's effectiveness is demonstrated through comparisons on both\ngeneral-purpose and single-cell datasets, where it outperforms existing methods\nin terms of accuracy and performance. These contributions provide a new tool\nfor hierarchical lineage analysis, enabling more accurate and efficient\nmodeling of cellular differentiation paths and offering insights for downstream\nbiological tasks. The code of HDTree is available at anonymous link\nhttps://anonymous.4open.science/r/code_HDTree_review-A8DB.", "AI": {"tldr": "HDTree is a diffusion-based method for modeling hierarchical single-cell data, outperforming traditional and VAE-based approaches in accuracy and stability.", "motivation": "Traditional methods and recent VAEs struggle with computational cost, performance, and capturing deep hierarchical relationships in single-cell data.", "method": "HDTree uses a unified hierarchical codebook and quantized diffusion processes to model tree node transitions, eliminating branch-specific modules.", "result": "HDTree outperforms existing methods in accuracy and performance on general-purpose and single-cell datasets.", "conclusion": "HDTree provides a robust tool for hierarchical lineage analysis, improving cellular differentiation modeling and biological insights."}}
{"id": "2506.22955", "pdf": "https://arxiv.org/pdf/2506.22955", "abs": "https://arxiv.org/abs/2506.22955", "authors": ["Haniyeh Nikkhah", "Jafar Tanha", "Mahdi Zarrin", "SeyedEhsan Roshan", "Amin Kazempour"], "title": "YM-WML: A new Yolo-based segmentation Model with Weighted Multi-class Loss for medical imaging", "categories": ["cs.CV"], "comment": "Accepted at The 7th International conference on Pattern Recognition\n  and Image Analysis (IPRIA 2025)", "summary": "Medical image segmentation poses significant challenges due to class\nimbalance and the complex structure of medical images. To address these\nchallenges, this study proposes YM-WML, a novel model for cardiac image\nsegmentation. The model integrates a robust backbone for effective feature\nextraction, a YOLOv11 neck for multi-scale feature aggregation, and an\nattention-based segmentation head for precise and accurate segmentation. To\naddress class imbalance, we introduce the Weighted Multi-class Exponential\n(WME) loss function. On the ACDC dataset, YM-WML achieves a Dice Similarity\nCoefficient of 91.02, outperforming state-of-the-art methods. The model\ndemonstrates stable training, accurate segmentation, and strong generalization,\nsetting a new benchmark in cardiac segmentation tasks.", "AI": {"tldr": "YM-WML, a novel model for cardiac image segmentation, integrates a robust backbone, YOLOv11 neck, and attention-based segmentation head, achieving a Dice score of 91.02 on ACDC dataset.", "motivation": "Addressing class imbalance and complex structures in medical image segmentation.", "method": "YM-WML combines a robust backbone, YOLOv11 neck for multi-scale features, and an attention-based head. Uses WME loss for class imbalance.", "result": "Achieves 91.02 Dice score on ACDC dataset, outperforming state-of-the-art methods.", "conclusion": "YM-WML sets a new benchmark in cardiac segmentation with stable training and strong generalization."}}
{"id": "2506.23864", "pdf": "https://arxiv.org/pdf/2506.23864", "abs": "https://arxiv.org/abs/2506.23864", "authors": ["Seyed Mahed Mousavi", "Edoardo Cecchinato", "Lucia Hornikova", "Giuseppe Riccardi"], "title": "Garbage In, Reasoning Out? Why Benchmark Scores are Unreliable and What to Do About It", "categories": ["cs.CL"], "comment": null, "summary": "We conduct a systematic audit of three widely used reasoning benchmarks,\nSocialIQa, FauxPas-EAI, and ToMi, and uncover pervasive flaws in both benchmark\nitems and evaluation methodology. Using five LLMs (GPT-{3, 3.5, 4, o1}, and\nLLaMA 3.1) as diagnostic tools, we identify structural, semantic, and pragmatic\nissues in benchmark design (e.g., duplicated items, ambiguous wording, and\nimplausible answers), as well as scoring procedures that prioritize output form\nover reasoning process. Through systematic human annotation and re-evaluation\non cleaned benchmark subsets, we find that model scores often improve not due\nto due to erratic surface wording variations and not to improved reasoning.\nInfact, further analyses show that model performance is highly sensitive to\nminor input variations such as context availability and phrasing, revealing\nthat high scores may reflect alignment with format-specific cues rather than\nconsistent inference based on the input. These findings challenge the validity\nof current benchmark-based claims about reasoning in LLMs, and highlight the\nneed for evaluation protocols that assess reasoning as a process of drawing\ninference from available information, rather than as static output selection.\nWe release audited data and evaluation tools to support more interpretable and\ndiagnostic assessments of model reasoning.", "AI": {"tldr": "The paper audits reasoning benchmarks (SocialIQa, FauxPas-EAI, ToMi), revealing flaws in design and evaluation. LLMs highlight issues like duplicates, ambiguity, and scoring biases. Human re-evaluation shows scores improve due to wording, not reasoning. Performance is sensitive to input variations, questioning benchmark validity.", "motivation": "To expose flaws in reasoning benchmarks and evaluation methods, challenging claims about LLM reasoning abilities.", "method": "Audit benchmarks using five LLMs (GPT-3, 3.5, 4, o1, LLaMA 3.1) and human annotation to identify issues. Re-evaluate cleaned subsets.", "result": "Benchmarks contain structural, semantic, and pragmatic flaws. Model scores improve due to wording, not reasoning. Performance is sensitive to minor input changes.", "conclusion": "Current benchmarks may misrepresent LLM reasoning. Need for evaluation protocols focusing on inference processes, not output form. Audited data and tools released for better assessments."}}
{"id": "2506.22520", "pdf": "https://arxiv.org/pdf/2506.22520", "abs": "https://arxiv.org/abs/2506.22520", "authors": ["Mustafa Demir", "Jacob Miratsky", "Jonathan Nguyen", "Chun Kit Chan", "Punya Mishra", "Abhishek Singharoy"], "title": "Exploring Artificial Intelligence Tutor Teammate Adaptability to Harness Discovery Curiosity and Promote Learning in the Context of Interactive Molecular Dynamics", "categories": ["cs.HC", "cs.AI", "cs.CE", "cs.CY"], "comment": null, "summary": "This study examines the impact of an Artificial Intelligence tutor teammate\n(AI) on student curiosity-driven engagement and learning effectiveness during\nInteractive Molecular Dynamics (IMD) tasks on the Visual Molecular Dynamics\nplatform. It explores the role of the AI's curiosity-triggering and response\nbehaviors in stimulating and sustaining student curiosity, affecting the\nfrequency and complexity of student-initiated questions. The study further\nassesses how AI interventions shape student engagement, foster discovery\ncuriosity, and enhance team performance within the IMD learning environment.\nUsing a Wizard-of-Oz paradigm, a human experimenter dynamically adjusts the AI\ntutor teammate's behavior through a large language model. By employing a\nmixed-methods exploratory design, a total of 11 high school students\nparticipated in four IMD tasks that involved molecular visualization and\ncalculations, which increased in complexity over a 60-minute period. Team\nperformance was evaluated through real-time observation and recordings, whereas\nteam communication was measured by question complexity and AI's\ncuriosity-triggering and response behaviors. Cross Recurrence Quantification\nAnalysis (CRQA) metrics reflected structural alignment in coordination and were\nlinked to communication behaviors. High-performing teams exhibited superior\ntask completion, deeper understanding, and increased engagement. Advanced\nquestions were associated with AI curiosity-triggering, indicating heightened\nengagement and cognitive complexity. CRQA metrics highlighted dynamic\nsynchronization in student-AI interactions, emphasizing structured yet adaptive\nengagement to promote curiosity. These proof-of-concept findings suggest that\nthe AI's dual role as a teammate and educator indicates its capacity to provide\nadaptive feedback, sustaining engagement and epistemic curiosity.", "AI": {"tldr": "The study explores how an AI tutor teammate affects student curiosity and learning in molecular dynamics tasks, finding that AI behaviors enhance engagement, question complexity, and team performance.", "motivation": "To understand how AI can stimulate and sustain student curiosity and improve learning effectiveness in interactive molecular dynamics tasks.", "method": "Used a Wizard-of-Oz paradigm with a mixed-methods design involving 11 high school students in four progressively complex tasks. AI behavior was dynamically adjusted via a large language model. Performance and communication were analyzed through observation, recordings, and CRQA metrics.", "result": "High-performing teams showed better task completion, deeper understanding, and increased engagement. AI curiosity-triggering behaviors correlated with advanced questions and dynamic synchronization in interactions.", "conclusion": "The AI tutor teammate effectively sustains engagement and curiosity, demonstrating potential as an adaptive educational tool."}}
{"id": "2506.23339", "pdf": "https://arxiv.org/pdf/2506.23339", "abs": "https://arxiv.org/abs/2506.23339", "authors": ["Malikussaid", "Hilal Hudan Nuha"], "title": "VALID-Mol: a Systematic Framework for Validated LLM-Assisted Molecular Design", "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "q-bio.QM"], "comment": "16 pages, 1 figure, 5 algorithms, 7 tables, to be published in ICSECS\n  Conference 2025, unabridged version", "summary": "Large Language Models (LLMs) demonstrate remarkable potential for scientific\ndiscovery, but their application in domains requiring factual accuracy and\ndomain-specific constraints remains challenging. In molecular design for drug\ndiscovery, LLMs can suggest creative molecular modifications but often produce\nchemically invalid or impractical structures. We present VALID-Mol, a\nsystematic framework for integrating chemical validation with LLM-driven\nmolecular design that increases the rate of generating valid chemical\nstructures from 3% to 83%. Our approach combines methodical prompt engineering,\nautomated chemical validation, and a fine-tuned domain-adapted LLM to ensure\nreliable generation of synthesizable molecules with improved properties. Beyond\nthe specific implementation, we contribute a generalizable methodology for\nscientifically-constrained LLM applications, with quantifiable reliability\nimprovements. Computational predictions suggest our framework can generate\npromising candidates for synthesis with up to 17-fold computationally predicted\nimprovements in target affinity while maintaining synthetic accessibility. We\nprovide a detailed analysis of our prompt engineering process, validation\narchitecture, and fine-tuning approach, offering a reproducible blueprint for\napplying LLMs to other scientific domains where domain-specific validation is\nessential.", "AI": {"tldr": "VALID-Mol improves LLM-driven molecular design by integrating chemical validation, increasing valid structure generation from 3% to 83%.", "motivation": "Addressing the challenge of LLMs generating chemically invalid or impractical structures in molecular design for drug discovery.", "method": "Combines prompt engineering, automated chemical validation, and a fine-tuned domain-adapted LLM.", "result": "Achieves 83% valid chemical structures, with up to 17-fold predicted improvements in target affinity.", "conclusion": "Offers a generalizable methodology for scientifically-constrained LLM applications, ensuring reliability and reproducibility."}}
{"id": "2506.22960", "pdf": "https://arxiv.org/pdf/2506.22960", "abs": "https://arxiv.org/abs/2506.22960", "authors": ["Shreyas Dixit", "Ashhar Aziz", "Shashwat Bajpai", "Vasu Sharma", "Aman Chadha", "Vinija Jain", "Amitava Das"], "title": "Peccavi: Visual Paraphrase Attack Safe and Distortion Free Image Watermarking Technique for AI-Generated Images", "categories": ["cs.CV"], "comment": null, "summary": "A report by the European Union Law Enforcement Agency predicts that by 2026,\nup to 90 percent of online content could be synthetically generated, raising\nconcerns among policymakers, who cautioned that \"Generative AI could act as a\nforce multiplier for political disinformation. The combined effect of\ngenerative text, images, videos, and audio may surpass the influence of any\nsingle modality.\" In response, California's Bill AB 3211 mandates the\nwatermarking of AI-generated images, videos, and audio. However, concerns\nremain regarding the vulnerability of invisible watermarking techniques to\ntampering and the potential for malicious actors to bypass them entirely.\nGenerative AI-powered de-watermarking attacks, especially the newly introduced\nvisual paraphrase attack, have shown an ability to fully remove watermarks,\nresulting in a paraphrase of the original image. This paper introduces PECCAVI,\nthe first visual paraphrase attack-safe and distortion-free image watermarking\ntechnique. In visual paraphrase attacks, an image is altered while preserving\nits core semantic regions, termed Non-Melting Points (NMPs). PECCAVI\nstrategically embeds watermarks within these NMPs and employs multi-channel\nfrequency domain watermarking. It also incorporates noisy burnishing to counter\nreverse-engineering efforts aimed at locating NMPs to disrupt the embedded\nwatermark, thereby enhancing durability. PECCAVI is model-agnostic. All\nrelevant resources and codes will be open-sourced.", "AI": {"tldr": "PECCAVI introduces a distortion-free, visual paraphrase attack-resistant watermarking technique for AI-generated content by embedding watermarks in Non-Melting Points (NMPs) and using multi-channel frequency domain methods.", "motivation": "The rise of synthetic content and generative AI's potential for disinformation necessitates robust watermarking solutions, as current methods are vulnerable to attacks like visual paraphrasing.", "method": "PECCAVI embeds watermarks in NMPs (core semantic regions) and uses multi-channel frequency domain watermarking with noisy burnishing to prevent reverse-engineering.", "result": "PECCAVI resists visual paraphrase attacks and is model-agnostic, ensuring durability and security.", "conclusion": "PECCAVI offers a secure, open-source solution for watermarking AI-generated content, addressing vulnerabilities in existing techniques."}}
{"id": "2506.23888", "pdf": "https://arxiv.org/pdf/2506.23888", "abs": "https://arxiv.org/abs/2506.23888", "authors": ["Andr\u00e9 de Souza Loureiro", "Jorge Valverde-Rebaza", "Julieta Noguez", "David Escarcega", "Ricardo Marcacini"], "title": "Advancing Multi-Step Mathematical Reasoning in Large Language Models through Multi-Layered Self-Reflection with Auto-Prompting", "categories": ["cs.CL"], "comment": "Accepted for publication in: European Conference on Machine Learning\n  and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD\n  2025). Research Track", "summary": "Recent advancements in Large Language Models (LLMs) have significantly\nimproved their problem-solving capabilities. However, these models still\nstruggle when faced with complex multi-step reasoning tasks. In this paper, we\npropose the Multi-Layered Self-Reflection with Auto-Prompting (MAPS) framework,\na novel approach designed to enhance multi-step mathematical reasoning in LLMs\nby integrating techniques such as Chain of Thought (CoT), Self-Reflection, and\nAuto-Prompting. Unlike traditional static prompting methods, MAPS employs an\niterative refinement process. Initially, the model generates a solution using\nCoT prompting. When errors are detected, an adaptive self-reflection mechanism\nidentifies and analyzes them, generating tailored prompts to guide corrections.\nThese dynamically adjusted prompts enable the model to iteratively refine its\nreasoning. Experiments on four well-established benchmarks across multiple LLMs\nshow that MAPS significantly outperforms standard CoT and achieves competitive\nresults with reasoning-optimized models. In addition, MAPS enables\ngeneral-purpose LLMs to reach performance levels comparable to specialized\nreasoning models. While deeper reflection layers improve accuracy, they also\nincrease token usage and costs. To balance this trade-off, MAPS strategically\nlimits reflection depth, ensuring an optimal balance between cost and reasoning\nperformance.", "AI": {"tldr": "MAPS framework enhances multi-step reasoning in LLMs by combining CoT, Self-Reflection, and Auto-Prompting, outperforming standard methods while balancing cost and performance.", "motivation": "LLMs struggle with complex multi-step reasoning tasks despite advancements, necessitating improved methods like MAPS.", "method": "MAPS integrates CoT, Self-Reflection, and Auto-Prompting in an iterative refinement process with adaptive prompts for error correction.", "result": "MAPS outperforms standard CoT and matches specialized reasoning models on benchmarks, with controlled reflection depth for cost efficiency.", "conclusion": "MAPS effectively improves LLM reasoning, balancing accuracy and cost, and generalizes well across models."}}
{"id": "2506.22521", "pdf": "https://arxiv.org/pdf/2506.22521", "abs": "https://arxiv.org/abs/2506.22521", "authors": ["Kaixiang Zhao", "Lincan Li", "Kaize Ding", "Neil Zhenqiang Gong", "Yue Zhao", "Yushun Dong"], "title": "A Survey on Model Extraction Attacks and Defenses for Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Model extraction attacks pose significant security threats to deployed\nlanguage models, potentially compromising intellectual property and user\nprivacy. This survey provides a comprehensive taxonomy of LLM-specific\nextraction attacks and defenses, categorizing attacks into functionality\nextraction, training data extraction, and prompt-targeted attacks. We analyze\nvarious attack methodologies including API-based knowledge distillation, direct\nquerying, parameter recovery, and prompt stealing techniques that exploit\ntransformer architectures. We then examine defense mechanisms organized into\nmodel protection, data privacy protection, and prompt-targeted strategies,\nevaluating their effectiveness across different deployment scenarios. We\npropose specialized metrics for evaluating both attack effectiveness and\ndefense performance, addressing the specific challenges of generative language\nmodels. Through our analysis, we identify critical limitations in current\napproaches and propose promising research directions, including integrated\nattack methodologies and adaptive defense mechanisms that balance security with\nmodel utility. This work serves NLP researchers, ML engineers, and security\nprofessionals seeking to protect language models in production environments.", "AI": {"tldr": "A survey on model extraction attacks targeting language models, covering attack types, methodologies, defenses, and evaluation metrics, with insights into limitations and future research directions.", "motivation": "Address the security threats posed by model extraction attacks to language models, which risk intellectual property and user privacy.", "method": "Categorizes attacks into functionality extraction, training data extraction, and prompt-targeted attacks, and analyzes defense mechanisms like model protection and data privacy strategies.", "result": "Identifies limitations in current approaches and proposes future research directions, including integrated attack methodologies and adaptive defenses.", "conclusion": "Provides a resource for NLP researchers, ML engineers, and security professionals to safeguard language models in production."}}
{"id": "2506.23349", "pdf": "https://arxiv.org/pdf/2506.23349", "abs": "https://arxiv.org/abs/2506.23349", "authors": ["Keziah Naggita", "Julienne LaChance"], "title": "A case for data valuation transparency via DValCards", "categories": ["cs.LG"], "comment": null, "summary": "Following the rise in popularity of data-centric machine learning (ML),\nvarious data valuation methods have been proposed to quantify the contribution\nof each datapoint to desired ML model performance metrics (e.g., accuracy).\nBeyond the technical applications of data valuation methods (e.g., data\ncleaning, data acquisition, etc.), it has been suggested that within the\ncontext of data markets, data buyers might utilize such methods to fairly\ncompensate data owners. Here we demonstrate that data valuation metrics are\ninherently biased and unstable under simple algorithmic design choices,\nresulting in both technical and ethical implications. By analyzing 9 tabular\nclassification datasets and 6 data valuation methods, we illustrate how (1)\ncommon and inexpensive data pre-processing techniques can drastically alter\nestimated data values; (2) subsampling via data valuation metrics may increase\nclass imbalance; and (3) data valuation metrics may undervalue underrepresented\ngroup data. Consequently, we argue in favor of increased transparency\nassociated with data valuation in-the-wild and introduce the novel Data\nValuation Cards (DValCards) framework towards this aim. The proliferation of\nDValCards will reduce misuse of data valuation metrics, including in data\npricing, and build trust in responsible ML systems.", "AI": {"tldr": "Data valuation methods in ML are biased and unstable, affected by pre-processing and subsampling, leading to ethical concerns. A new framework, DValCards, is proposed for transparency.", "motivation": "To highlight biases and instability in data valuation methods and their ethical implications in ML and data markets.", "method": "Analyzed 9 tabular datasets and 6 valuation methods, examining effects of pre-processing, subsampling, and bias.", "result": "Found data valuation metrics are easily altered, increase class imbalance, and undervalue underrepresented groups.", "conclusion": "Advocates for transparency via DValCards to mitigate misuse and promote trust in ML systems."}}
{"id": "2506.22979", "pdf": "https://arxiv.org/pdf/2506.22979", "abs": "https://arxiv.org/abs/2506.22979", "authors": ["Jie Liu", "Jiayi Shen", "Pan Zhou", "Jan-Jakob Sonke", "Efstratios Gavves"], "title": "Probabilistic Prototype Calibration of Vision-Language Models for Generalized Few-shot Semantic Segmentation", "categories": ["cs.CV"], "comment": "ICCV2025 Proceeding", "summary": "Generalized Few-Shot Semantic Segmentation (GFSS) aims to extend a\nsegmentation model to novel classes with only a few annotated examples while\nmaintaining performance on base classes. Recently, pretrained vision-language\nmodels (VLMs) such as CLIP have been leveraged in GFSS to improve\ngeneralization on novel classes through multi-modal prototypes learning.\nHowever, existing prototype-based methods are inherently deterministic,\nlimiting the adaptability of learned prototypes to diverse samples,\nparticularly for novel classes with scarce annotations. To address this, we\npropose FewCLIP, a probabilistic prototype calibration framework over\nmulti-modal prototypes from the pretrained CLIP, thus providing more adaptive\nprototype learning for GFSS. Specifically, FewCLIP first introduces a prototype\ncalibration mechanism, which refines frozen textual prototypes with learnable\nvisual calibration prototypes, leading to a more discriminative and adaptive\nrepresentation. Furthermore, unlike deterministic prototype learning\ntechniques, FewCLIP introduces distribution regularization over these\ncalibration prototypes. This probabilistic formulation ensures structured and\nuncertainty-aware prototype learning, effectively mitigating overfitting to\nlimited novel class data while enhancing generalization. Extensive experimental\nresults on PASCAL-5$^i$ and COCO-20$^i$ datasets demonstrate that our proposed\nFewCLIP significantly outperforms state-of-the-art approaches across both GFSS\nand class-incremental setting. The code is available at\nhttps://github.com/jliu4ai/FewCLIP.", "AI": {"tldr": "FewCLIP introduces a probabilistic prototype calibration framework for GFSS, improving adaptability and generalization over deterministic methods.", "motivation": "Existing prototype-based methods in GFSS are deterministic, limiting adaptability to diverse samples, especially for novel classes with few annotations.", "method": "FewCLIP refines frozen textual prototypes with learnable visual calibration prototypes and introduces distribution regularization for uncertainty-aware learning.", "result": "FewCLIP outperforms state-of-the-art methods on PASCAL-5$^i$ and COCO-20$^i$ datasets in GFSS and class-incremental settings.", "conclusion": "FewCLIP provides adaptive and uncertainty-aware prototype learning, enhancing generalization and mitigating overfitting in GFSS."}}
{"id": "2506.23921", "pdf": "https://arxiv.org/pdf/2506.23921", "abs": "https://arxiv.org/abs/2506.23921", "authors": ["Germans Savcisens", "Tina Eliassi-Rad"], "title": "The Trilemma of Truth in Large Language Models", "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "We often attribute human characteristics to large language models (LLMs) and\nclaim that they \"know\" certain things. LLMs have an internal probabilistic\nknowledge that represents information retained during training. How can we\nassess the veracity of this knowledge? We examine two common methods for\nprobing the veracity of LLMs and discover several assumptions that are flawed.\nTo address these flawed assumptions, we introduce sAwMIL (short for Sparse\nAware Multiple-Instance Learning), a probing method that utilizes the internal\nactivations of LLMs to separate statements into true, false, and neither.\nsAwMIL is based on multiple-instance learning and conformal prediction. We\nevaluate sAwMIL on 5 validity criteria across 16 open-source LLMs, including\nboth default and chat-based variants, as well as on 3 new datasets. Among the\ninsights we provide are: (1) the veracity signal is often concentrated in the\nthird quarter of an LLM's depth; (2) truth and falsehood signals are not always\nsymmetric; (3) linear probes perform better on chat models than on default\nmodels; (4) nonlinear probes may be required to capture veracity signals for\nsome LLMs with reinforcement learning from human feedback or knowledge\ndistillation; and (5) LLMs capture a third type of signal that is distinct from\ntrue and false and is neither true nor false. These findings provide a reliable\nmethod for verifying what LLMs \"know\" and how certain they are of their\nprobabilistic internal knowledge.", "AI": {"tldr": "The paper introduces sAwMIL, a method to assess the veracity of LLMs' internal knowledge, revealing insights about truth signals and probing performance.", "motivation": "To address flawed assumptions in existing methods for probing LLMs' knowledge and provide a reliable way to verify their internal probabilistic knowledge.", "method": "Introduces sAwMIL, a probing method using multiple-instance learning and conformal prediction to classify statements as true, false, or neither based on LLM activations.", "result": "Found concentrated veracity signals in LLMs, asymmetry in truth/falsehood signals, and varying probe performance across models. Also identified a third signal type (neither true nor false).", "conclusion": "sAwMIL offers a reliable way to verify LLM knowledge, with findings aiding future research on LLM truth assessment."}}
{"id": "2506.22523", "pdf": "https://arxiv.org/pdf/2506.22523", "abs": "https://arxiv.org/abs/2506.22523", "authors": ["James Wen", "Sahil Nalawade", "Zhiwei Liang", "Catherine Bielick", "Marisa Ferrara Boston", "Alexander Chowdhury", "Adele Collin", "Luigi De Angelis", "Jacob Ellen", "Heather Frase", "Rodrigo R. Gameiro", "Juan Manuel Gutierrez", "Pooja Kadam", "Murat Keceli", "Srikanth Krishnamurthy", "Anne Kwok", "Yanan Lance Lu", "Heather Mattie", "Liam G. McCoy", "Katherine Miller", "Allison C. Morgan", "Marlene Louisa Moerig", "Trang Nguyen", "Alexander Owen-Post", "Alex D. Ruiz", "Sreekar Reddy Puchala", "Soujanya Samineni", "Takeshi Tohyama", "Varun Ullanat", "Carmine Valenza", "Camilo Velez", "Pengcheng Wang", "Anna Wuest", "Yuxiang Zhou", "Yingde Zhu", "Jason M. Johnson", "Jennifer Willcox", "Francis J. Vitiello", "Leo Anthony G. Celi", "Renato Umeton"], "title": "Red Teaming for Generative AI, Report on a Copyright-Focused Exercise Completed in an Academic Medical Center", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Generative AI is present in multiple industries. Dana-Farber Cancer\nInstitute, in partnership with Microsoft, has created an internal AI tool,\nGPT4DFCI. Together we hosted a red teaming event to assess whether the\nunderlying GPT models that support the tool would output copyrighted data. Our\nteams focused on reproducing content from books, news articles, scientific\narticles, and electronic health records. We found isolated instances where\nGPT4DFCI was able to identify copyrighted material and reproduce exact quotes\nfrom famous books which indicates that copyrighted material was in the training\ndata. The model was not able to reproduce content from our target news article,\nscientific article, or electronic health records. However, there were instances\nof fabrication. As a result of this event, a mitigation strategy is in\nproduction in GPT4DFCI v2.8.2, deployed on January 21, 2025. We hope this\nreport leads to similar events in which AI software tools are stress-tested to\nassess the perimeter of their legal and ethical usage.", "AI": {"tldr": "GPT4DFCI, an AI tool by Dana-Farber and Microsoft, was tested for reproducing copyrighted data. It occasionally reproduced book quotes but not news, scientific articles, or health records. Mitigations were implemented in v2.8.2.", "motivation": "To assess whether GPT4DFCI outputs copyrighted data and ensure ethical AI usage.", "method": "Red teaming event to test reproduction of content from books, news, scientific articles, and health records.", "result": "Isolated instances of copyrighted book quotes reproduced; no reproduction from news, scientific articles, or health records. Mitigations deployed.", "conclusion": "Stress-testing AI tools for legal and ethical compliance is crucial, as demonstrated by this event."}}
{"id": "2506.23358", "pdf": "https://arxiv.org/pdf/2506.23358", "abs": "https://arxiv.org/abs/2506.23358", "authors": ["Pawel Renc", "Michal K. Grzeszczyk", "Linglong Qian", "Nassim Oufattole", "Jeff Rasley", "Arkadiusz Sitek"], "title": "Federated Timeline Synthesis: Scalable and Private Methodology For Model Training and Deployment", "categories": ["cs.LG", "cs.AI"], "comment": "conference paper", "summary": "We present Federated Timeline Synthesis (FTS), a novel framework for training\ngenerative foundation models across distributed timeseries data applied to\nelectronic health records (EHR). At its core, FTS represents patient history as\ntokenized Patient Health Timelines (PHTs), language-agnostic sequences encoding\ntemporal, categorical, and continuous clinical information. Each institution\ntrains an autoregressive transformer on its local PHTs and transmits only model\nweights to a central server. The server uses the generators to synthesize a\nlarge corpus of trajectories and train a Global Generator (GG), enabling\nzero-shot inference via Monte Carlo simulation of future PHTs. We evaluate FTS\non five clinically meaningful prediction tasks using MIMIC-IV data, showing\nthat models trained on synthetic data generated by GG perform comparably to\nthose trained on real data. FTS offers strong privacy guarantees, scalability\nacross institutions, and extensibility to diverse prediction and simulation\ntasks especially in healthcare, including counterfactual inference, early\nwarning detection, and synthetic trial design.", "AI": {"tldr": "FTS is a federated framework for training generative models on distributed EHR data, ensuring privacy and scalability while achieving performance comparable to real data.", "motivation": "To enable training of generative models on distributed timeseries EHR data without compromising privacy, while maintaining performance.", "method": "Tokenizes patient history as PHTs, trains local autoregressive transformers, aggregates model weights centrally, and synthesizes data for a Global Generator.", "result": "GG-trained models perform comparably to real-data models on clinical prediction tasks.", "conclusion": "FTS provides privacy, scalability, and extensibility for healthcare applications like counterfactual inference and synthetic trials."}}
{"id": "2506.22982", "pdf": "https://arxiv.org/pdf/2506.22982", "abs": "https://arxiv.org/abs/2506.22982", "authors": ["Atharv Mittal", "Agam Pandey", "Amritanshu Tiwari", "Sukrit Jindal", "Swadesh Swain"], "title": "Revisiting CroPA: A Reproducibility Study and Enhancements for Cross-Prompt Adversarial Transferability in Vision-Language Models", "categories": ["cs.CV"], "comment": "Accepted to MLRC 2025", "summary": "Large Vision-Language Models (VLMs) have revolutionized computer vision,\nenabling tasks such as image classification, captioning, and visual question\nanswering. However, they remain highly vulnerable to adversarial attacks,\nparticularly in scenarios where both visual and textual modalities can be\nmanipulated. In this study, we conduct a comprehensive reproducibility study of\n\"An Image is Worth 1000 Lies: Adversarial Transferability Across Prompts on\nVision-Language Models\" validating the Cross-Prompt Attack (CroPA) and\nconfirming its superior cross-prompt transferability compared to existing\nbaselines. Beyond replication we propose several key improvements: (1) A novel\ninitialization strategy that significantly improves Attack Success Rate (ASR).\n(2) Investigate cross-image transferability by learning universal\nperturbations. (3) A novel loss function targeting vision encoder attention\nmechanisms to improve generalization. Our evaluation across prominent VLMs --\nincluding Flamingo, BLIP-2, and InstructBLIP as well as extended experiments on\nLLaVA validates the original results and demonstrates that our improvements\nconsistently boost adversarial effectiveness. Our work reinforces the\nimportance of studying adversarial vulnerabilities in VLMs and provides a more\nrobust framework for generating transferable adversarial examples, with\nsignificant implications for understanding the security of VLMs in real-world\napplications.", "AI": {"tldr": "The paper validates and improves the Cross-Prompt Attack (CroPA) on Vision-Language Models (VLMs), demonstrating superior adversarial transferability and proposing enhancements like better initialization, universal perturbations, and a novel loss function.", "motivation": "VLMs are vulnerable to adversarial attacks, especially when both visual and textual inputs are manipulated. The study aims to validate and enhance adversarial transferability in VLMs.", "method": "The study replicates CroPA and introduces three improvements: a novel initialization strategy, investigation of cross-image transferability via universal perturbations, and a new loss function targeting vision encoder attention.", "result": "The improvements consistently boost adversarial effectiveness across VLMs like Flamingo, BLIP-2, InstructBLIP, and LLaVA, confirming CroPA's superior transferability.", "conclusion": "The work highlights the need to study VLM vulnerabilities and offers a robust framework for generating transferable adversarial examples, impacting real-world VLM security."}}
{"id": "2506.23929", "pdf": "https://arxiv.org/pdf/2506.23929", "abs": "https://arxiv.org/abs/2506.23929", "authors": ["Mohammed J. Saeed", "Tommi Vehvilainen", "Evgeny Fedoseev", "Sevil Caliskan", "Tatiana Vodolazova"], "title": "IMPACT: Inflectional Morphology Probes Across Complex Typologies", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have shown significant progress on various\nmultilingual benchmarks and are increasingly used to generate and evaluate text\nin non-English languages. However, while they may produce fluent outputs, it\nremains unclear to what extent these models truly grasp the underlying\nlinguistic complexity of those languages, particularly in morphology. To\ninvestigate this, we introduce IMPACT, a synthetically generated evaluation\nframework focused on inflectional morphology, which we publicly release,\ndesigned to evaluate LLM performance across five morphologically rich\nlanguages: Arabic, Russian, Finnish, Turkish, and Hebrew. IMPACT includes\nunit-test-style cases covering both shared and language-specific phenomena,\nfrom basic verb inflections (e.g., tense, number, gender) to unique features\nlike Arabic's reverse gender agreement and vowel harmony in Finnish and\nTurkish. We assess eight multilingual LLMs that, despite strong English\nperformance, struggle with other languages and uncommon morphological patterns,\nespecially when judging ungrammatical examples. We also show that Chain of\nThought and Thinking Models can degrade performance. Our work exposes gaps in\nLLMs' handling of linguistic complexity, pointing to clear room for\nimprovement. To support further research, we publicly release the IMPACT\nframework.", "AI": {"tldr": "IMPACT is a synthetic evaluation framework for assessing LLMs' understanding of inflectional morphology in five morphologically rich languages, revealing gaps in their linguistic complexity handling.", "motivation": "To investigate whether LLMs truly grasp the linguistic complexity of non-English languages, particularly in morphology, despite their fluent outputs.", "method": "Introduces IMPACT, a synthetic framework with unit-test-style cases for evaluating LLMs across five languages (Arabic, Russian, Finnish, Turkish, Hebrew), covering shared and language-specific morphological phenomena.", "result": "Eight multilingual LLMs struggle with non-English languages and uncommon morphological patterns, especially in judging ungrammatical examples. Chain of Thought and Thinking Models can degrade performance.", "conclusion": "LLMs have significant gaps in handling linguistic complexity, highlighting room for improvement. The IMPACT framework is released publicly to support further research."}}
{"id": "2506.22526", "pdf": "https://arxiv.org/pdf/2506.22526", "abs": "https://arxiv.org/abs/2506.22526", "authors": ["Ofer M. Shir", "Michael Emmerich"], "title": "Correlated Mutations for Integer Programming", "categories": ["math.OC", "cs.AI", "cs.NE"], "comment": null, "summary": "Even with the recent theoretical advancements that dramatically reduced the\ncomplexity of Integer Programming (IP), heuristics remain the dominant\nproblem-solvers for this difficult category. This study seeks to establish the\ngroundwork for Integer Evolution Strategies (IESs), a class of randomized\nsearch heuristics inherently designed for continuous spaces. IESs already excel\nin treating IP in practice, but accomplish it via discretization and by\napplying sophisticated patches to their continuous operators, while\npersistently using the $\\ell_2$-norm as their operation pillar. We lay\nfoundations for discrete search, by adopting the $\\ell_1$-norm, accounting for\nthe suitable step-size, and questioning alternative measures to quantify\ncorrelations over the integer lattice. We focus on mutation distributions for\nunbounded integer decision variables. We briefly discuss a couple of candidate\ndiscrete probabilities induced by the uniform and binomial distributions, which\nwe show to possess less appealing theoretical properties, and then narrow down\nto the Truncated Normal (TN) and Double Geometric (DG) distributions. We\nexplore their theoretical properties, including entropy functions, and propose\na procedure to generate scalable correlated mutation distributions. Our\ninvestigations are accompanied by extensive numerical simulations, which\nconsistently support the claim that the DG distribution is better suited for\nunbounded integer search. We link our theoretical perspective to empirical\nevidence indicating that an IES with correlated DG mutations outperformed other\nstrategies over non-separable quadratic IP. We conclude that while the\nreplacement of the default TN distribution by the DG is theoretically justified\nand practically beneficial, the truly crucial change lies in adopting the\n$\\ell_1$-norm over the $\\ell_2$-norm.", "AI": {"tldr": "The paper introduces Integer Evolution Strategies (IESs) for solving Integer Programming (IP) problems, advocating the use of the \u2113\u2081-norm and Double Geometric (DG) distributions over traditional methods like the \u2113\u2082-norm and Truncated Normal (TN) distributions.", "motivation": "Current heuristics for IP rely on continuous-space adaptations, which are inefficient. The study aims to develop inherently discrete search methods for IP.", "method": "The study adopts the \u2113\u2081-norm, explores mutation distributions (TN and DG), and analyzes their theoretical properties. Numerical simulations compare their performance.", "result": "The DG distribution outperforms TN in unbounded integer search, and the \u2113\u2081-norm proves more effective than the \u2113\u2082-norm.", "conclusion": "The DG distribution and \u2113\u2081-norm are theoretically and practically superior for IP, with DG mutations enhancing performance in non-separable quadratic IP."}}
{"id": "2506.23374", "pdf": "https://arxiv.org/pdf/2506.23374", "abs": "https://arxiv.org/abs/2506.23374", "authors": ["Dominik Meier", "Sujai Hiremath", "Promit Ghosal", "Kyra Gan"], "title": "When Additive Noise Meets Unobserved Mediators: Bivariate Denoising Diffusion for Causal Discovery", "categories": ["cs.LG"], "comment": null, "summary": "Distinguishing cause and effect from bivariate observational data is a\nfoundational problem in many disciplines, but challenging without additional\nassumptions. Additive noise models (ANMs) are widely used to enable\nsample-efficient bivariate causal discovery. However, conventional ANM-based\nmethods fail when unobserved mediators corrupt the causal relationship between\nvariables. This paper makes three key contributions: first, we rigorously\ncharacterize why standard ANM approaches break down in the presence of\nunmeasured mediators. Second, we demonstrate that prior solutions for hidden\nmediation are brittle in finite sample settings, limiting their practical\nutility. To address these gaps, we propose Bivariate Denoising Diffusion (BiDD)\nfor causal discovery, a method designed to handle latent noise introduced by\nunmeasured mediators. Unlike prior methods that infer directionality through\nmean squared error loss comparisons, our approach introduces a novel\nindependence test statistic: during the noising and denoising processes for\neach variable, we condition on the other variable as input and evaluate the\nindependence of the predicted noise relative to this input. We prove asymptotic\nconsistency of BiDD under the ANM, and conjecture that it performs well under\nhidden mediation. Experiments on synthetic and real-world data demonstrate\nconsistent performance, outperforming existing methods in mediator-corrupted\nsettings while maintaining strong performance in mediator-free settings.", "AI": {"tldr": "The paper addresses the challenge of causal discovery in bivariate data with unmeasured mediators, proposing a new method (BiDD) that outperforms existing approaches.", "motivation": "Standard additive noise models (ANMs) fail when unobserved mediators corrupt causal relationships, and prior solutions are brittle in finite samples.", "method": "The paper introduces Bivariate Denoising Diffusion (BiDD), which uses a novel independence test statistic during noising/denoising processes to infer causality.", "result": "BiDD shows consistent performance in synthetic and real-world data, excelling in mediator-corrupted settings and maintaining robustness in mediator-free cases.", "conclusion": "BiDD is a promising solution for causal discovery under hidden mediation, offering asymptotic consistency and practical utility."}}
{"id": "2506.23009", "pdf": "https://arxiv.org/pdf/2506.23009", "abs": "https://arxiv.org/abs/2506.23009", "authors": ["Jian Chen", "Wenye Ma", "Penghang Liu", "Wei Wang", "Tengwei Song", "Ming Li", "Chenguang Wang", "Ruiyi Zhang", "Changyou Chen"], "title": "MusiXQA: Advancing Visual Music Understanding in Multimodal Large Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have achieved remarkable visual\nreasoning abilities in natural images, text-rich documents, and graphic\ndesigns. However, their ability to interpret music sheets remains\nunderexplored. To bridge this gap, we introduce MusiXQA, the first\ncomprehensive dataset for evaluating and advancing MLLMs in music sheet\nunderstanding. MusiXQA features high-quality synthetic music sheets generated\nvia MusiXTeX, with structured annotations covering note pitch and duration,\nchords, clefs, key/time signatures, and text, enabling diverse visual QA tasks.\nThrough extensive evaluations, we reveal significant limitations of current\nstate-of-the-art MLLMs in this domain. Beyond benchmarking, we developed\nPhi-3-MusiX, an MLLM fine-tuned on our dataset, achieving significant\nperformance gains over GPT-based methods. The proposed dataset and model\nestablish a foundation for future advances in MLLMs for music sheet\nunderstanding. Code, data, and model will be released upon acceptance.", "AI": {"tldr": "The paper introduces MusiXQA, a dataset for evaluating MLLMs in music sheet understanding, and presents Phi-3-MusiX, a fine-tuned model outperforming GPT-based methods.", "motivation": "Current MLLMs lack exploration in interpreting music sheets, prompting the creation of MusiXQA to address this gap.", "method": "The dataset features synthetic music sheets with structured annotations, and the model Phi-3-MusiX is fine-tuned on this data.", "result": "Evaluations show current MLLMs' limitations in music sheet understanding, while Phi-3-MusiX achieves significant performance gains.", "conclusion": "MusiXQA and Phi-3-MusiX provide a foundation for advancing MLLMs in music sheet understanding."}}
{"id": "2506.23930", "pdf": "https://arxiv.org/pdf/2506.23930", "abs": "https://arxiv.org/abs/2506.23930", "authors": ["Ruhina Tabasshum Prome", "Tarikul Islam Tamiti", "Anomadarshi Barua"], "title": "Leveraging the Potential of Prompt Engineering for Hate Speech Detection in Low-Resource Languages", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The rapid expansion of social media leads to a marked increase in hate\nspeech, which threatens personal lives and results in numerous hate crimes.\nDetecting hate speech presents several challenges: diverse dialects, frequent\ncode-mixing, and the prevalence of misspelled words in user-generated content\non social media platforms. Recent progress in hate speech detection is\ntypically concentrated on high-resource languages. However, low-resource\nlanguages still face significant challenges due to the lack of large-scale,\nhigh-quality datasets. This paper investigates how we can overcome this\nlimitation via prompt engineering on large language models (LLMs) focusing on\nlow-resource Bengali language. We investigate six prompting strategies -\nzero-shot prompting, refusal suppression, flattering the classifier, multi-shot\nprompting, role prompting, and finally our innovative metaphor prompting to\ndetect hate speech effectively in low-resource languages. We pioneer the\nmetaphor prompting to circumvent the built-in safety mechanisms of LLMs that\nmarks a significant departure from existing jailbreaking methods. We\ninvestigate all six different prompting strategies on the Llama2-7B model and\ncompare the results extensively with three pre-trained word embeddings - GloVe,\nWord2Vec, and FastText for three different deep learning models - multilayer\nperceptron (MLP), convolutional neural network (CNN), and bidirectional gated\nrecurrent unit (BiGRU). To prove the effectiveness of our metaphor prompting in\nthe low-resource Bengali language, we also evaluate it in another low-resource\nlanguage - Hindi, and two high-resource languages - English and German. The\nperformance of all prompting techniques is evaluated using the F1 score, and\nenvironmental impact factor (IF), which measures CO$_2$ emissions, electricity\nusage, and computational time.", "AI": {"tldr": "The paper explores prompt engineering on LLMs for hate speech detection in low-resource languages, introducing metaphor prompting and evaluating six strategies on Llama2-7B.", "motivation": "Addressing the lack of large-scale datasets for hate speech detection in low-resource languages like Bengali.", "method": "Six prompting strategies (zero-shot, refusal suppression, flattering, multi-shot, role, metaphor) tested on Llama2-7B, compared with word embeddings (GloVe, Word2Vec, FastText) and deep learning models (MLP, CNN, BiGRU).", "result": "Metaphor prompting outperforms other methods, validated in Bengali, Hindi, English, and German, with metrics like F1 score and environmental impact.", "conclusion": "Metaphor prompting is effective for hate speech detection in low-resource languages, offering a novel approach beyond traditional jailbreaking."}}
{"id": "2506.22593", "pdf": "https://arxiv.org/pdf/2506.22593", "abs": "https://arxiv.org/abs/2506.22593", "authors": ["Antonello Longo", "Chanyoung Chung", "Matteo Palieri", "Sung-Kyun Kim", "Ali Agha", "Cataldo Guaragnella", "Shehryar Khattak"], "title": "Pixels-to-Graph: Real-time Integration of Building Information Models and Scene Graphs for Semantic-Geometric Human-Robot Understanding", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "Paper accepted to 2025 IEEE International Conference on Automation\n  Science and Engineering (CASE)", "summary": "Autonomous robots are increasingly playing key roles as support platforms for\nhuman operators in high-risk, dangerous applications. To accomplish challenging\ntasks, an efficient human-robot cooperation and understanding is required.\nWhile typically robotic planning leverages 3D geometric information, human\noperators are accustomed to a high-level compact representation of the\nenvironment, like top-down 2D maps representing the Building Information Model\n(BIM). 3D scene graphs have emerged as a powerful tool to bridge the gap\nbetween human readable 2D BIM and the robot 3D maps. In this work, we introduce\nPixels-to-Graph (Pix2G), a novel lightweight method to generate structured\nscene graphs from image pixels and LiDAR maps in real-time for the autonomous\nexploration of unknown environments on resource-constrained robot platforms. To\nsatisfy onboard compute constraints, the framework is designed to perform all\noperation on CPU only. The method output are a de-noised 2D top-down\nenvironment map and a structure-segmented 3D pointcloud which are seamlessly\nconnected using a multi-layer graph abstracting information from object-level\nup to the building-level. The proposed method is quantitatively and\nqualitatively evaluated during real-world experiments performed using the NASA\nJPL NeBula-Spot legged robot to autonomously explore and map cluttered garage\nand urban office like environments in real-time.", "AI": {"tldr": "Pix2G is a lightweight method for real-time generation of scene graphs from images and LiDAR, enabling autonomous exploration on resource-constrained robots.", "motivation": "Bridging the gap between human-readable 2D maps and robot 3D maps for efficient human-robot cooperation in high-risk tasks.", "method": "Pix2G processes image pixels and LiDAR maps on CPU to produce a de-noised 2D map and structured 3D pointcloud, connected via a multi-layer graph.", "result": "Successfully tested on NASA JPL NeBula-Spot robot for real-time exploration of cluttered environments.", "conclusion": "Pix2G effectively enables autonomous exploration with limited compute resources, enhancing human-robot collaboration."}}
{"id": "2506.23408", "pdf": "https://arxiv.org/pdf/2506.23408", "abs": "https://arxiv.org/abs/2506.23408", "authors": ["Claudionor Coelho Jr", "Yanen Li", "Philip Tee"], "title": "Do LLMs Dream of Discrete Algorithms?", "categories": ["cs.LG", "cs.LO"], "comment": null, "summary": "Large Language Models (LLMs) have rapidly transformed the landscape of\nartificial intelligence, enabling natural language interfaces and dynamic\norchestration of software components. However, their reliance on probabilistic\ninference limits their effectiveness in domains requiring strict logical\nreasoning, discrete decision-making, and robust interpretability. This paper\ninvestigates these limitations and proposes a neurosymbolic approach that\naugments LLMs with logic-based reasoning modules, particularly leveraging\nProlog predicates and composable toolsets. By integrating first-order logic and\nexplicit rule systems, our framework enables LLMs to decompose complex queries\ninto verifiable sub-tasks, orchestrate reliable solutions, and mitigate common\nfailure modes such as hallucination and incorrect step decomposition. We\ndemonstrate the practical benefits of this hybrid architecture through\nexperiments on the DABStep benchmark, showing improved precision, coverage, and\nsystem documentation in multi-step reasoning tasks. Our results indicate that\ncombining LLMs with modular logic reasoning restores engineering rigor,\nenhances system reliability, and offers a scalable path toward trustworthy,\ninterpretable AI agents across complex domains.", "AI": {"tldr": "The paper proposes a neurosymbolic approach combining LLMs with logic-based reasoning to address limitations in logical reasoning and interpretability, showing improved performance in multi-step tasks.", "motivation": "LLMs lack effectiveness in strict logical reasoning and interpretability, limiting their use in complex domains requiring reliability and precision.", "method": "The paper integrates LLMs with logic-based reasoning modules (e.g., Prolog predicates) to decompose queries into verifiable sub-tasks and orchestrate solutions.", "result": "Experiments on the DABStep benchmark demonstrate improved precision, coverage, and documentation in multi-step reasoning tasks.", "conclusion": "Combining LLMs with logic reasoning enhances reliability, interpretability, and scalability for trustworthy AI agents in complex domains."}}
{"id": "2506.23038", "pdf": "https://arxiv.org/pdf/2506.23038", "abs": "https://arxiv.org/abs/2506.23038", "authors": ["Xinrong Hu", "Yiyu Shi"], "title": "Inpainting is All You Need: A Diffusion-based Augmentation Method for Semi-supervised Medical Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Collecting pixel-level labels for medical datasets can be a laborious and\nexpensive process, and enhancing segmentation performance with a scarcity of\nlabeled data is a crucial challenge. This work introduces AugPaint, a data\naugmentation framework that utilizes inpainting to generate image-label pairs\nfrom limited labeled data. AugPaint leverages latent diffusion models, known\nfor their ability to generate high-quality in-domain images with low overhead,\nand adapts the sampling process for the inpainting task without need for\nretraining. Specifically, given a pair of image and label mask, we crop the\narea labeled with the foreground and condition on it during reversed denoising\nprocess for every noise level. Masked background area would gradually be filled\nin, and all generated images are paired with the label mask. This approach\nensures the accuracy of match between synthetic images and label masks, setting\nit apart from existing dataset generation methods. The generated images serve\nas valuable supervision for training downstream segmentation models,\neffectively addressing the challenge of limited annotations. We conducted\nextensive evaluations of our data augmentation method on four public medical\nimage segmentation datasets, including CT, MRI, and skin imaging. Results\nacross all datasets demonstrate that AugPaint outperforms state-of-the-art\nlabel-efficient methodologies, significantly improving segmentation\nperformance.", "AI": {"tldr": "AugPaint is a data augmentation framework using inpainting with latent diffusion models to generate synthetic image-label pairs from limited labeled medical data, improving segmentation performance.", "motivation": "Pixel-level labeling in medical datasets is labor-intensive and costly, and enhancing segmentation with limited labeled data is a challenge.", "method": "AugPaint uses latent diffusion models for inpainting, cropping foreground-labeled areas and conditioning the reversed denoising process to fill masked backgrounds, ensuring accurate synthetic image-label pairs.", "result": "Evaluations on four medical datasets (CT, MRI, skin imaging) show AugPaint outperforms state-of-the-art label-efficient methods, significantly boosting segmentation performance.", "conclusion": "AugPaint effectively addresses the scarcity of labeled medical data by generating high-quality synthetic images, enhancing downstream segmentation models."}}
{"id": "2506.23940", "pdf": "https://arxiv.org/pdf/2506.23940", "abs": "https://arxiv.org/abs/2506.23940", "authors": ["Yang Dai", "Jianxiang An", "Tianwei Lin", "Hongyang He", "Hongzhe Huang", "Wenqiao Zhang", "Zheqi Lv", "Siliang Tang", "Yueting Zhuang"], "title": "Graft: Integrating the Domain Knowledge via Efficient Parameter Synergy for MLLMs", "categories": ["cs.CL"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have achieved success across various\ndomains. However, their applicability tends to degrade when confronted with\ndifferent types of data inputs, especially for MLLMs that have been fine-tuned\nfor specific tasks. Despite its importance, the study of knowledge sharing\namong domain-specific MLLMs--such as those trained for mathematics or\ncode--remains largely underexplored. To address the fragmentation of knowledge\nacross domain-specialized MLLMs, we propose a unified parameter integration\nframework that enables modular composition of expert capabilities. Our method\nis grounded in a novel Compatibility-Aware Parameter Splicing (CAPS) strategy,\nwhich leverages both local functional attribution and global\ninformation-theoretic signals to guide selective parameter fusion. By extending\nthis mechanism to the low-rank adaptation layer granularity, we ensure\nefficient integration with minimal inference overhead. Furthermore, we\nintroduce a domain compatibility scoring mechanism that quantifies inter-expert\nalignment at the activation level and correlates with downstream task utility.\nThis principled fusion protocol allows the final model to synergize\nheterogeneous expertise while preserving structural modularity. Extensive\nevaluations across diverse multimodal benchmarks validate the effectiveness of\nour framework, offering a scalable path toward compositional, domain-adaptive\nMLLMs.", "AI": {"tldr": "A framework for unifying knowledge across domain-specific MLLMs using parameter integration and compatibility-aware fusion.", "motivation": "Addressing the fragmentation of knowledge in specialized MLLMs and enabling modular composition of expert capabilities.", "method": "Proposes Compatibility-Aware Parameter Splicing (CAPS) for selective parameter fusion, with domain compatibility scoring for alignment.", "result": "Validated effectiveness across diverse multimodal benchmarks, enabling scalable, domain-adaptive MLLMs.", "conclusion": "The framework successfully integrates heterogeneous expertise while maintaining modularity, offering a scalable solution."}}
{"id": "2506.22656", "pdf": "https://arxiv.org/pdf/2506.22656", "abs": "https://arxiv.org/abs/2506.22656", "authors": ["Jiangping Huang", "Dongming Jin", "Weisong Sun", "Yang Liu", "Zhi Jin"], "title": "Knowledge-Guided Multi-Agent Framework for Automated Requirements Development: A Vision", "categories": ["cs.SE", "cs.AI", "68-04", "D.2.3; I.2.7"], "comment": null, "summary": "This paper envisions a knowledge-guided multi-agent framework named KGMAF for\nautomated requirements development. KGMAF aims to address gaps in current\nautomation systems for SE, which prioritize code development and overlook the\ncomplexities of requirements tasks. KGMAF is composed of six specialized agents\nand an artifact pool to improve efficiency and accuracy. Specifically, KGMAF\noutlines the functionality, actions, and knowledge of each agent and provides\nthe conceptual design of the artifact pool. Our case study highlights the\npotential of KGMAF in real-world scenarios. Finally, we outline several\nresearch opportunities for implementing and enhancing automated requirements\ndevelopment using multi-agent systems. We believe that KGMAF will play a\npivotal role in shaping the future of automated requirements development in the\nera of LLMs.", "AI": {"tldr": "KGMAF is a knowledge-guided multi-agent framework for automated requirements development, addressing gaps in current SE automation systems.", "motivation": "Current automation systems in SE focus on code development and neglect the complexities of requirements tasks, which KGMAF aims to resolve.", "method": "KGMAF comprises six specialized agents and an artifact pool, detailing their functionality, actions, and knowledge, along with the artifact pool's design.", "result": "A case study demonstrates KGMAF's potential in real-world scenarios, and research opportunities for its enhancement are identified.", "conclusion": "KGMAF is poised to significantly impact automated requirements development, especially in the context of LLMs."}}
{"id": "2506.23419", "pdf": "https://arxiv.org/pdf/2506.23419", "abs": "https://arxiv.org/abs/2506.23419", "authors": ["Amanda S Barnard"], "title": "BenchMake: Turn any scientific data set into a reproducible benchmark", "categories": ["cs.LG", "cs.AI", "cs.DL", "62G09", "J.1"], "comment": "10 pages, 15 pages in Appendix, 15 figures, 5 tables, 57 references", "summary": "Benchmark data sets are a cornerstone of machine learning development and\napplications, ensuring new methods are robust, reliable and competitive. The\nrelative rarity of benchmark sets in computational science, due to the\nuniqueness of the problems and the pace of change in the associated domains,\nmakes evaluating new innovations difficult for computational scientists. In\nthis paper a new tool is developed and tested to potentially turn any of the\nincreasing numbers of scientific data sets made openly available into a\nbenchmark accessible to the community. BenchMake uses non-negative matrix\nfactorisation to deterministically identify and isolate challenging edge cases\non the convex hull (the smallest convex set that contains all existing data\ninstances) and partitions a required fraction of matched data instances into a\ntesting set that maximises divergence and statistical significance, across\ntabular, graph, image, signal and textual modalities. BenchMake splits are\ncompared to establish splits and random splits using ten publicly available\nbenchmark sets from different areas of science, with different sizes, shapes,\ndistributions.", "AI": {"tldr": "A new tool, BenchMake, is introduced to transform scientific datasets into benchmarks by identifying edge cases and partitioning data for robust testing.", "motivation": "The rarity of benchmark sets in computational science hinders innovation evaluation, prompting the need for a tool to convert open datasets into benchmarks.", "method": "BenchMake uses non-negative matrix factorization to isolate challenging edge cases and partitions data to maximize divergence and statistical significance.", "result": "Tested on ten public benchmark sets, BenchMake outperforms established and random splits across diverse data modalities.", "conclusion": "BenchMake enables robust benchmarking by leveraging open datasets, aiding computational science innovation."}}
{"id": "2506.23042", "pdf": "https://arxiv.org/pdf/2506.23042", "abs": "https://arxiv.org/abs/2506.23042", "authors": ["Hung Nguyen", "An Le", "Runfa Li", "Truong Nguyen"], "title": "From Coarse to Fine: Learnable Discrete Wavelet Transforms for Efficient 3D Gaussian Splatting", "categories": ["cs.CV"], "comment": "Accepted to ICCV Workshop", "summary": "3D Gaussian Splatting has emerged as a powerful approach in novel view\nsynthesis, delivering rapid training and rendering but at the cost of an\never-growing set of Gaussian primitives that strains memory and bandwidth. We\nintroduce AutoOpti3DGS, a training-time framework that automatically restrains\nGaussian proliferation without sacrificing visual fidelity. The key idea is to\nfeed the input images to a sequence of learnable Forward and Inverse Discrete\nWavelet Transforms, where low-pass filters are kept fixed, high-pass filters\nare learnable and initialized to zero, and an auxiliary orthogonality loss\ngradually activates fine frequencies. This wavelet-driven, coarse-to-fine\nprocess delays the formation of redundant fine Gaussians, allowing 3DGS to\ncapture global structure first and refine detail only when necessary. Through\nextensive experiments, AutoOpti3DGS requires just a single filter learning-rate\nhyper-parameter, integrates seamlessly with existing efficient 3DGS frameworks,\nand consistently produces sparser scene representations more compatible with\nmemory or storage-constrained hardware.", "AI": {"tldr": "AutoOpti3DGS is a training-time framework that reduces Gaussian proliferation in 3D Gaussian Splatting without compromising visual quality, using wavelet transforms and an orthogonality loss.", "motivation": "To address the memory and bandwidth strain caused by the growing set of Gaussian primitives in 3D Gaussian Splatting.", "method": "Uses learnable Forward and Inverse Discrete Wavelet Transforms with fixed low-pass and learnable high-pass filters, initialized to zero, and an auxiliary orthogonality loss to activate fine frequencies gradually.", "result": "Produces sparser scene representations, integrates seamlessly with existing frameworks, and requires minimal hyper-parameter tuning.", "conclusion": "AutoOpti3DGS effectively balances visual fidelity and computational efficiency, making it suitable for memory-constrained hardware."}}
{"id": "2506.23951", "pdf": "https://arxiv.org/pdf/2506.23951", "abs": "https://arxiv.org/abs/2506.23951", "authors": ["Mathis Le Bail", "J\u00e9r\u00e9mie Dentan", "Davide Buscaldi", "Sonia Vanier"], "title": "Unveiling Decision-Making in LLMs for Text Classification : Extraction of influential and interpretable concepts with Sparse Autoencoders", "categories": ["cs.CL"], "comment": null, "summary": "Sparse Autoencoders (SAEs) have been successfully used to probe Large\nLanguage Models (LLMs) and extract interpretable concepts from their internal\nrepresentations. These concepts are linear combinations of neuron activations\nthat correspond to human-interpretable features. In this paper, we investigate\nthe effectiveness of SAE-based explainability approaches for sentence\nclassification, a domain where such methods have not been extensively explored.\nWe present a novel SAE-based architecture tailored for text classification,\nleveraging a specialized classifier head and incorporating an activation rate\nsparsity loss. We benchmark this architecture against established methods such\nas ConceptShap, Independent Component Analysis, and other SAE-based concept\nextraction techniques. Our evaluation covers two classification benchmarks and\nfour fine-tuned LLMs from the Pythia family. We further enrich our analysis\nwith two novel metrics for measuring the precision of concept-based\nexplanations, using an external sentence encoder. Our empirical results show\nthat our architecture improves both the causality and interpretability of the\nextracted features.", "AI": {"tldr": "The paper explores Sparse Autoencoders (SAEs) for interpretable concept extraction in sentence classification, proposing a novel SAE-based architecture with improved causality and interpretability.", "motivation": "To extend SAE-based explainability methods to sentence classification, a domain less explored, and enhance interpretability of LLM features.", "method": "Introduces a tailored SAE architecture with a specialized classifier head and activation rate sparsity loss, benchmarked against ConceptShap, ICA, and other SAE techniques.", "result": "The proposed architecture outperforms benchmarks in causality and interpretability, validated on two classification tasks and four Pythia LLMs.", "conclusion": "The novel SAE-based approach effectively improves interpretability and causality in sentence classification, supported by new metrics."}}
{"id": "2506.22703", "pdf": "https://arxiv.org/pdf/2506.22703", "abs": "https://arxiv.org/abs/2506.22703", "authors": ["Wali Mohammad Abdullah", "Azmain Kabir"], "title": "P4OMP: Retrieval-Augmented Prompting for OpenMP Parallelism in Serial Code", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "We present P4OMP, a retrieval-augmented framework for transforming serial\nC/C++ code into OpenMP-annotated parallel code using large language models\n(LLMs). To our knowledge, this is the first system to apply retrieval-based\nprompting for OpenMP pragma correctness without model fine-tuning or compiler\ninstrumentation. P4OMP leverages Retrieval-Augmented Generation (RAG) with\nstructured instructional knowledge from OpenMP tutorials to improve the\nreliability of prompt-driven code generation. By grounding generation in the\nretrieved context, P4OMP improves syntactic correctness compared to baseline\nprompting with GPT-3.5-Turbo. We evaluate P4OMP against a baseline,\nGPT-3.5-Turbo without retrieval, on a comprehensive benchmark of 108 real-world\nC++ programs drawn from Stack Overflow, PolyBench, and NAS benchmark suites.\nP4OMP achieves 100% compilation success on all parallelizable cases, while the\nbaseline fails to compile in 20 out of 108 cases. Six cases that rely on\nnon-random-access iterators or thread-unsafe constructs are excluded due to\nfundamental OpenMP limitations. A detailed analysis demonstrates how P4OMP\nconsistently avoids scoping errors, syntactic misuse, and invalid directive\ncombinations that commonly affect baseline-generated code. We further\ndemonstrate strong runtime scaling across seven compute-intensive benchmarks on\nan HPC cluster. P4OMP offers a robust, modular pipeline that significantly\nimproves the reliability and applicability of LLM-generated OpenMP code.", "AI": {"tldr": "P4OMP is a retrieval-augmented framework using LLMs to transform serial C/C++ code into OpenMP-annotated parallel code, improving correctness without fine-tuning.", "motivation": "To enhance the reliability of LLM-generated OpenMP code by leveraging retrieval-based prompting and structured knowledge from OpenMP tutorials.", "method": "Uses Retrieval-Augmented Generation (RAG) with instructional knowledge to ground code generation, evaluated on 108 real-world C++ programs.", "result": "Achieves 100% compilation success on parallelizable cases, outperforming a baseline (GPT-3.5-Turbo without retrieval) which fails in 20 cases.", "conclusion": "P4OMP provides a robust, modular pipeline for reliable and scalable LLM-generated OpenMP code."}}
{"id": "2506.23424", "pdf": "https://arxiv.org/pdf/2506.23424", "abs": "https://arxiv.org/abs/2506.23424", "authors": ["Heitor R. Medeiros", "Hossein Sharifi-Noghabi", "Gabriel L. Oliveira", "Saghar Irandoust"], "title": "Accurate Parameter-Efficient Test-Time Adaptation for Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "Second Workshop on Test-Time Adaptation: Putting Updates to the Test!\n  at ICML 2025, Vancouver, Canada. 2025", "summary": "Real-world time series often exhibit a non-stationary nature, degrading the\nperformance of pre-trained forecasting models. Test-Time Adaptation (TTA)\naddresses this by adjusting models during inference, but existing methods\ntypically update the full model, increasing memory and compute costs. We\npropose PETSA, a parameter-efficient method that adapts forecasters at test\ntime by only updating small calibration modules on the input and output. PETSA\nuses low-rank adapters and dynamic gating to adjust representations without\nretraining. To maintain accuracy despite limited adaptation capacity, we\nintroduce a specialized loss combining three components: (1) a robust term, (2)\na frequency-domain term to preserve periodicity, and (3) a patch-wise\nstructural term for structural alignment. PETSA improves the adaptability of\nvarious forecasting backbones while requiring fewer parameters than baselines.\nExperimental results on benchmark datasets show that PETSA achieves competitive\nor better performance across all horizons. Our code is available at:\nhttps://github.com/BorealisAI/PETSA", "AI": {"tldr": "PETSA is a parameter-efficient test-time adaptation method for time series forecasting, updating only small calibration modules to reduce costs while maintaining accuracy.", "motivation": "Real-world time series are non-stationary, degrading pre-trained models' performance. Existing TTA methods update full models, increasing resource costs.", "method": "PETSA updates small input/output calibration modules using low-rank adapters and dynamic gating. It employs a specialized loss with robust, frequency-domain, and patch-wise structural terms.", "result": "PETSA improves adaptability of forecasting backbones with fewer parameters, achieving competitive or better performance on benchmark datasets.", "conclusion": "PETSA offers an efficient and effective solution for test-time adaptation in time series forecasting."}}
{"id": "2506.23044", "pdf": "https://arxiv.org/pdf/2506.23044", "abs": "https://arxiv.org/abs/2506.23044", "authors": ["Guo-Hua Wang", "Shanshan Zhao", "Xinjie Zhang", "Liangfu Cao", "Pengxin Zhan", "Lunhao Duan", "Shiyin Lu", "Minghao Fu", "Xiaohao Chen", "Jianshan Zhao", "Yang Li", "Qing-Guo Chen"], "title": "Ovis-U1 Technical Report", "categories": ["cs.CV", "cs.AI"], "comment": "A unified model for multimodal understanding, text-to-image\n  generation, and image editing. GitHub: https://github.com/AIDC-AI/Ovis-U1", "summary": "In this report, we introduce Ovis-U1, a 3-billion-parameter unified model\nthat integrates multimodal understanding, text-to-image generation, and image\nediting capabilities. Building on the foundation of the Ovis series, Ovis-U1\nincorporates a diffusion-based visual decoder paired with a bidirectional token\nrefiner, enabling image generation tasks comparable to leading models like\nGPT-4o. Unlike some previous models that use a frozen MLLM for generation\ntasks, Ovis-U1 utilizes a new unified training approach starting from a\nlanguage model. Compared to training solely on understanding or generation\ntasks, unified training yields better performance, demonstrating the\nenhancement achieved by integrating these two tasks. Ovis-U1 achieves a score\nof 69.6 on the OpenCompass Multi-modal Academic Benchmark, surpassing recent\nstate-of-the-art models such as Ristretto-3B and SAIL-VL-1.5-2B. In\ntext-to-image generation, it excels with scores of 83.72 and 0.89 on the\nDPG-Bench and GenEval benchmarks, respectively. For image editing, it achieves\n4.00 and 6.42 on the ImgEdit-Bench and GEdit-Bench-EN, respectively. As the\ninitial version of the Ovis unified model series, Ovis-U1 pushes the boundaries\nof multimodal understanding, generation, and editing.", "AI": {"tldr": "Ovis-U1 is a 3B-parameter unified model excelling in multimodal understanding, text-to-image generation, and image editing, outperforming state-of-the-art models.", "motivation": "To integrate multimodal understanding, generation, and editing into a single model, improving performance over task-specific models.", "method": "Uses a diffusion-based visual decoder and bidirectional token refiner, trained with a unified approach from a language model.", "result": "Achieves top scores on benchmarks like OpenCompass (69.6), DPG-Bench (83.72), and ImgEdit-Bench (4.00).", "conclusion": "Ovis-U1 advances multimodal capabilities, setting a new standard for unified models."}}
{"id": "2506.23979", "pdf": "https://arxiv.org/pdf/2506.23979", "abs": "https://arxiv.org/abs/2506.23979", "authors": ["Renren Jin", "Tianhao Shen", "Xinwei Wu", "Dan Shi", "Haoran Sun", "Wuwei Huang", "Quandong Wang", "Wei Liu", "Jian Luan", "Bin Wang", "Deyi Xiong"], "title": "TaP: A Taxonomy-Guided Framework for Automated and Scalable Preference Data Generation", "categories": ["cs.CL"], "comment": "33 pages, 15 tables, 11 figures", "summary": "Conducting supervised fine-tuning and preference fine-tuning on large\nlanguage models (LLMs) requires high-quality datasets to improve their ability\nto follow instructions and align with human preferences and values. However,\nconstructing such datasets is resource-intensive, and most available datasets\nfor supervised and preference fine-tuning are in English. To address these\nchallenges, we propose the \\underline{\\textbf{Ta}}xonomy-Guided\n\\underline{\\textbf{P}}reference Data Generation (TaP) framework, which\nfacilitates automated and scalable construction of preference datasets across\nvarious languages. TaP is grounded in a structured taxonomy that allows\nfine-grained control over dataset composition, thereby ensuring both diversity\nand comprehensive coverage. We employ TaP-generated datasets to perform\nsupervised and preference fine-tuning on various LLMs. Experimental results\ndemonstrate that LLMs trained on TaP-generated datasets outperform those\ntrained on existing open-source datasets. Remarkably, LLMs trained on\nTaP-generated datasets surpass the performance of those trained on an\nopen-source dataset that is 180 times larger.", "AI": {"tldr": "The TaP framework automates and scales preference dataset construction for multilingual LLM fine-tuning, outperforming larger open-source datasets.", "motivation": "High-quality datasets for LLM fine-tuning are resource-intensive and mostly English-only, limiting multilingual alignment with human preferences.", "method": "TaP uses a structured taxonomy for automated, scalable preference dataset generation across languages, ensuring diversity and coverage.", "result": "LLMs fine-tuned with TaP datasets outperform those using larger open-source datasets, even when the latter is 180 times bigger.", "conclusion": "TaP offers an efficient, scalable solution for multilingual preference dataset generation, enhancing LLM performance in instruction-following and alignment."}}
{"id": "2506.22704", "pdf": "https://arxiv.org/pdf/2506.22704", "abs": "https://arxiv.org/abs/2506.22704", "authors": ["Sardar Fatooreh Bonabi", "Sarah Bana", "Tingting Nian", "Vijay Gurbaxani"], "title": "Beyond Code: The Multidimensional Impacts of Large Language Models in Software Development", "categories": ["econ.GN", "cs.AI", "q-fin.EC"], "comment": null, "summary": "Large language models (LLMs) are poised to significantly impact software\ndevelopment, especially in the Open-Source Software (OSS) sector. To understand\nthis impact, we first outline the mechanisms through which LLMs may influence\nOSS through code development, collaborative knowledge transfer, and skill\ndevelopment. We then empirically examine how LLMs affect OSS developers' work\nin these three key areas. Leveraging a natural experiment from a temporary\nChatGPT ban in Italy, we employ a Difference-in-Differences framework with\ntwo-way fixed effects to analyze data from all OSS developers on GitHub in\nthree similar countries, Italy, France, and Portugal, totaling 88,022 users. We\nfind that access to ChatGPT increases developer productivity by 6.4%, knowledge\nsharing by 9.6%, and skill acquisition by 8.4%. These benefits vary\nsignificantly by user experience level: novice developers primarily experience\nproductivity gains, whereas more experienced developers benefit more from\nimproved knowledge sharing and accelerated skill acquisition. In addition, we\nfind that LLM-assisted learning is highly context-dependent, with the greatest\nbenefits observed in technically complex, fragmented, or rapidly evolving\ncontexts. We show that the productivity effects of LLMs extend beyond direct\ncode generation to include enhanced collaborative learning and knowledge\nexchange among developers; dynamics that are essential for gaining a holistic\nunderstanding of LLMs' impact in OSS. Our findings offer critical managerial\nimplications: strategically deploying LLMs can accelerate novice developers'\nonboarding and productivity, empower intermediate developers to foster\nknowledge sharing and collaboration, and support rapid skill acquisition,\ntogether enhancing long-term organizational productivity and agility.", "AI": {"tldr": "LLMs like ChatGPT boost OSS developer productivity (6.4%), knowledge sharing (9.6%), and skill acquisition (8.4%), with benefits varying by experience level and context.", "motivation": "To understand how LLMs impact OSS development, focusing on code development, knowledge transfer, and skill development.", "method": "Used a Difference-in-Differences framework with two-way fixed effects, analyzing GitHub data from Italy, France, and Portugal (88,022 users) during a ChatGPT ban.", "result": "LLMs significantly improve productivity, knowledge sharing, and skill acquisition, with novice developers benefiting most in productivity and experienced developers in knowledge/skill gains.", "conclusion": "Strategic LLM deployment can enhance developer onboarding, collaboration, and skill acquisition, improving long-term organizational productivity and agility."}}
{"id": "2506.23446", "pdf": "https://arxiv.org/pdf/2506.23446", "abs": "https://arxiv.org/abs/2506.23446", "authors": ["Mohamed Elbasheer", "Adewale Akinfaderin"], "title": "Enhancing Insider Threat Detection Using User-Based Sequencing and Transformer Encoders", "categories": ["cs.LG"], "comment": null, "summary": "Insider threat detection presents unique challenges due to the authorized\nstatus of malicious actors and the subtlety of anomalous behaviors. Existing\nmachine learning methods often treat user activity as isolated events, thereby\nfailing to leverage sequential dependencies in user behavior. In this study, we\npropose a User-Based Sequencing (UBS) methodology, transforming the CERT\ninsider threat dataset into structured temporal sequences suitable for deep\nsequential modeling. We deploy a Transformer Encoder architecture to model\nbenign user activity and employ its reconstruction errors as anomaly scores.\nThese scores are subsequently evaluated using three unsupervised outlier\ndetection algorithms: One-Class SVM (OCSVM), Local Outlier Factor (LOF), and\nIsolation Forest (iForest). Across four rigorously designed test sets,\nincluding combinations of multiple CERT dataset releases, our UBS-Transformer\npipeline consistently achieves state-of-the-art performance - notably 96.61%\naccuracy, 99.43% recall, 96.38% F1-score, 95.00% AUROC, and exceptionally low\nfalse negative (0.0057) and false positive (0.0571) rates. Comparative analyses\ndemonstrate that our approach substantially outperforms tabular and\nconventional autoencoder baselines, underscoring the efficacy of sequential\nuser modeling and advanced anomaly detection in the insider threat domain.", "AI": {"tldr": "The paper introduces a User-Based Sequencing (UBS) method with a Transformer Encoder for insider threat detection, achieving high accuracy and low error rates.", "motivation": "Existing methods fail to capture sequential dependencies in user behavior, limiting their effectiveness in detecting subtle insider threats.", "method": "UBS transforms user activity into temporal sequences, uses a Transformer Encoder for modeling, and evaluates anomaly scores with unsupervised outlier detection algorithms.", "result": "The method achieves 96.61% accuracy, 99.43% recall, and low false positive/negative rates, outperforming baselines.", "conclusion": "Sequential user modeling and advanced anomaly detection are highly effective for insider threat detection."}}
{"id": "2506.23061", "pdf": "https://arxiv.org/pdf/2506.23061", "abs": "https://arxiv.org/abs/2506.23061", "authors": ["Jiazhen Liu", "Yuchuan Deng", "Long Chen"], "title": "Empowering Small VLMs to Think with Dynamic Memorization and Exploration", "categories": ["cs.CV"], "comment": null, "summary": "Empowering Small-scale Vision-Language Models (SVLMs) with reliable thinking\ncapabilities remains fundamentally challenging due to their limited parameter\ncapacity and weak instruction-following abilities. Existing training paradigms,\nincluding Supervised Fine-Tuning (SFT) and Reinforcement Learning with\nVerifiable Reward (RLVR), impose substantial demands on the base VLM, exceeding\nthe capabilities of SVLMs. Consequently, directly applying these paradigms to\nSVLMs often suffers from severe pseudo thinking traces and advantage collapse,\nultimately undermining both thinking reliability and task performance. A\nnatural solution is to combine SFT and RLVR, leveraging their complementarity\nto reduce the dependence on model capacity. However, the widely adopted\ntwo-stage training paradigm still performs poorly on SVLMs, as their tendency\ntoward sub-optimal convergence hinders the trade-off and limits the benefits of\nthe combination. To address this, we propose DyME, a novel training paradigm\nthat Dynamically selects between Memorization (via SFT) and Exploration (via\nRLVR) modes at each optimization step, ensuring that every update contributes\nto the trade-off. Extensive experiments across diverse domains demonstrate that\nDyME consistently achieves this balance, and thus delivers substantial\nperformance improvements. These results establish DyME as a practical and\neffective solution for empowering SVLMs with reliable thinking capabilities.\nGitHub: https://github.com/HKUST-LongGroup/DyME", "AI": {"tldr": "DyME is a novel training paradigm for small-scale vision-language models (SVLMs) that dynamically switches between memorization (SFT) and exploration (RLVR) modes to enhance thinking reliability and performance.", "motivation": "Existing training paradigms (SFT and RLVR) are too demanding for SVLMs, leading to unreliable thinking and poor performance.", "method": "DyME dynamically alternates between SFT and RLVR during training to optimize updates.", "result": "DyME consistently balances memorization and exploration, improving SVLM performance across domains.", "conclusion": "DyME is an effective solution for enhancing SVLMs' thinking capabilities."}}
{"id": "2506.23990", "pdf": "https://arxiv.org/pdf/2506.23990", "abs": "https://arxiv.org/abs/2506.23990", "authors": ["Dustin Wright"], "title": "Machine Understanding of Scientific Language", "categories": ["cs.CL", "cs.LG"], "comment": "PhD Thesis, 210 pages", "summary": "Scientific information expresses human understanding of nature. This\nknowledge is largely disseminated in different forms of text, including\nscientific papers, news articles, and discourse among people on social media.\nWhile important for accelerating our pursuit of knowledge, not all scientific\ntext is faithful to the underlying science. As the volume of this text has\nburgeoned online in recent years, it has become a problem of societal\nimportance to be able to identify the faithfulness of a given piece of\nscientific text automatically. This thesis is concerned with the cultivation of\ndatasets, methods, and tools for machine understanding of scientific language,\nin order to analyze and understand science communication at scale. To arrive at\nthis, I present several contributions in three areas of natural language\nprocessing and machine learning: automatic fact checking, learning with limited\ndata, and scientific text processing. These contributions include new methods\nand resources for identifying check-worthy claims, adversarial claim\ngeneration, multi-source domain adaptation, learning from crowd-sourced labels,\ncite-worthiness detection, zero-shot scientific fact checking, detecting\nexaggerated scientific claims, and modeling degrees of information change in\nscience communication. Critically, I demonstrate how the research outputs of\nthis thesis are useful for effectively learning from limited amounts of\nscientific text in order to identify misinformative scientific statements and\ngenerate new insights into the science communication process", "AI": {"tldr": "This thesis focuses on developing tools and methods for machine understanding of scientific language to identify faithfulness in scientific text, addressing issues like misinformation and exaggerated claims.", "motivation": "The proliferation of scientific text online has made it crucial to automatically assess its faithfulness to underlying science, as misinformation can hinder knowledge dissemination.", "method": "The thesis contributes to NLP and ML with techniques like automatic fact-checking, adversarial claim generation, domain adaptation, and zero-shot scientific fact-checking.", "result": "New methods and datasets were developed to analyze scientific communication, detect misinformation, and generate insights into science communication processes.", "conclusion": "The research provides effective tools for learning from limited scientific text to identify misinformation and improve science communication."}}
{"id": "2506.22706", "pdf": "https://arxiv.org/pdf/2506.22706", "abs": "https://arxiv.org/abs/2506.22706", "authors": ["Arun Ramamurthy", "Neil Dhir"], "title": "General Autonomous Cybersecurity Defense: Learning Robust Policies for Dynamic Topologies and Diverse Attackers", "categories": ["cs.CR", "cs.AI", "cs.CV", "stat.ML"], "comment": null, "summary": "In the face of evolving cyber threats such as malware, ransomware and\nphishing, autonomous cybersecurity defense (ACD) systems have become essential\nfor real-time threat detection and response with optional human intervention.\nHowever, existing ACD systems rely on limiting assumptions, particularly the\nstationarity of the underlying network dynamics. In real-world scenarios,\nnetwork topologies can change due to actions taken by attackers or defenders,\nsystem failures, or time evolution of networks, leading to failures in the\nadaptive capabilities of current defense agents. Moreover, many agents are\ntrained on static environments, resulting in overfitting to specific\ntopologies, which hampers their ability to generalize to out-of-distribution\nnetwork topologies. This work addresses these challenges by exploring methods\nfor developing agents to learn generalizable policies across dynamic network\nenvironments -- general ACD (GACD).", "AI": {"tldr": "The paper proposes General Autonomous Cybersecurity Defense (GACD) to address limitations of current ACD systems, which struggle with dynamic network environments.", "motivation": "Existing ACD systems fail in dynamic network scenarios due to assumptions of stationarity and overfitting to static topologies.", "method": "The work explores methods for training agents to learn generalizable policies across dynamic network environments.", "result": "The proposed GACD aims to improve adaptability and generalization in cybersecurity defense.", "conclusion": "GACD offers a promising approach to enhance real-time threat detection and response in evolving cyber threats."}}
{"id": "2506.23462", "pdf": "https://arxiv.org/pdf/2506.23462", "abs": "https://arxiv.org/abs/2506.23462", "authors": ["Manaswi Kulahara", "Gautam Siddharth Kashyap", "Nipun Joshi", "Arpita Soni"], "title": "Can We Predict the Unpredictable? Leveraging DisasterNet-LLM for Multimodal Disaster Classification", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted in the 2025 IEEE International Geoscience and Remote Sensing\n  Symposium (IGARSS 2025), scheduled for 3 - 8 August 2025 in Brisbane,\n  Australia", "summary": "Effective disaster management requires timely and accurate insights, yet\ntraditional methods struggle to integrate multimodal data such as images,\nweather records, and textual reports. To address this, we propose\nDisasterNet-LLM, a specialized Large Language Model (LLM) designed for\ncomprehensive disaster analysis. By leveraging advanced pretraining,\ncross-modal attention mechanisms, and adaptive transformers, DisasterNet-LLM\nexcels in disaster classification. Experimental results demonstrate its\nsuperiority over state-of-the-art models, achieving higher accuracy of 89.5%,\nan F1 score of 88.0%, AUC of 0.92%, and BERTScore of 0.88% in multimodal\ndisaster classification tasks.", "AI": {"tldr": "DisasterNet-LLM, a specialized LLM, outperforms state-of-the-art models in multimodal disaster classification with 89.5% accuracy, 88.0% F1, 0.92 AUC, and 0.88 BERTScore.", "motivation": "Traditional methods fail to integrate multimodal data (images, weather, text) effectively for disaster management.", "method": "Uses advanced pretraining, cross-modal attention, and adaptive transformers.", "result": "Achieves 89.5% accuracy, 88.0% F1, 0.92 AUC, and 0.88 BERTScore.", "conclusion": "DisasterNet-LLM is highly effective for comprehensive disaster analysis."}}
{"id": "2506.23072", "pdf": "https://arxiv.org/pdf/2506.23072", "abs": "https://arxiv.org/abs/2506.23072", "authors": ["Jing Gao"], "title": "Unsupervised 3D Braided Hair Reconstruction from a Single-View Image", "categories": ["cs.CV"], "comment": "6 pages, 3 figures, accepted to the 2025 International Conference on\n  Machine Vision Applications (MVA 2025)", "summary": "Reconstructing 3D braided hairstyles from single-view images remains a\nchallenging task due to the intricate interwoven structure and complex\ntopologies of braids. Existing strand-based hair reconstruction methods\ntypically focus on loose hairstyles and often struggle to capture the\nfine-grained geometry of braided hair. In this paper, we propose a novel\nunsupervised pipeline for efficiently reconstructing 3D braided hair from\nsingle-view RGB images. Leveraging a synthetic braid model inspired by braid\ntheory, our approach effectively captures the complex intertwined structures of\nbraids. Extensive experiments demonstrate that our method outperforms\nstate-of-the-art approaches, providing superior accuracy, realism, and\nefficiency in reconstructing 3D braided hairstyles, supporting expressive\nhairstyle modeling in digital humans.", "AI": {"tldr": "A novel unsupervised pipeline for 3D braided hair reconstruction from single-view images, outperforming existing methods in accuracy and realism.", "motivation": "Existing methods struggle with braided hair due to its complex structure, creating a need for better reconstruction techniques.", "method": "Uses a synthetic braid model inspired by braid theory to capture intricate braid structures from single-view RGB images.", "result": "Outperforms state-of-the-art methods in accuracy, realism, and efficiency for 3D braided hairstyle reconstruction.", "conclusion": "The proposed method effectively addresses the challenges of braided hair reconstruction, enhancing digital human modeling."}}
{"id": "2506.23998", "pdf": "https://arxiv.org/pdf/2506.23998", "abs": "https://arxiv.org/abs/2506.23998", "authors": ["Seungjun Yi", "Joakim Nguyen", "Huimin Xu", "Terence Lim", "Andrew Well", "Mia Markey", "Ying Ding"], "title": "Auto-TA: Towards Scalable Automated Thematic Analysis (TA) via Multi-Agent Large Language Models with Reinforcement Learning", "categories": ["cs.CL"], "comment": "Presented at ACL 2025 SRW", "summary": "Congenital heart disease (CHD) presents complex, lifelong challenges often\nunderrepresented in traditional clinical metrics. While unstructured narratives\noffer rich insights into patient and caregiver experiences, manual thematic\nanalysis (TA) remains labor-intensive and unscalable. We propose a fully\nautomated large language model (LLM) pipeline that performs end-to-end TA on\nclinical narratives, which eliminates the need for manual coding or full\ntranscript review. Our system employs a novel multi-agent framework, where\nspecialized LLM agents assume roles to enhance theme quality and alignment with\nhuman analysis. To further improve thematic relevance, we optionally integrate\nreinforcement learning from human feedback (RLHF). This supports scalable,\npatient-centered analysis of large qualitative datasets and allows LLMs to be\nfine-tuned for specific clinical contexts.", "AI": {"tldr": "An automated LLM pipeline for thematic analysis of clinical narratives in CHD, reducing manual effort and improving scalability.", "motivation": "Traditional thematic analysis is labor-intensive and unscalable for CHD narratives.", "method": "A multi-agent LLM framework with optional RLHF for enhanced thematic relevance.", "result": "Enables scalable, patient-centered analysis of qualitative datasets.", "conclusion": "The system supports fine-tuning LLMs for clinical contexts, improving thematic alignment with human analysis."}}
{"id": "2506.22722", "pdf": "https://arxiv.org/pdf/2506.22722", "abs": "https://arxiv.org/abs/2506.22722", "authors": ["Anmin Fu", "Fanyu Meng", "Huaibing Peng", "Hua Ma", "Zhi Zhang", "Yifeng Zheng", "Willy Susilo", "Yansong Gao"], "title": "Kill Two Birds with One Stone! Trajectory enabled Unified Online Detection of Adversarial Examples and Backdoor Attacks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The proposed UniGuard is the first unified online detection framework capable\nof simultaneously addressing adversarial examples and backdoor attacks.\nUniGuard builds upon two key insights: first, both AE and backdoor attacks have\nto compromise the inference phase, making it possible to tackle them\nsimultaneously during run-time via online detection. Second, an adversarial\ninput, whether a perturbed sample in AE attacks or a trigger-carrying sample in\nbackdoor attacks, exhibits distinctive trajectory signatures from a benign\nsample as it propagates through the layers of a DL model in forward inference.\nThe propagation trajectory of the adversarial sample must deviate from that of\nits benign counterpart; otherwise, the adversarial objective cannot be\nfulfilled. Detecting these trajectory signatures is inherently challenging due\nto their subtlety; UniGuard overcomes this by treating the propagation\ntrajectory as a time-series signal, leveraging LSTM and spectrum transformation\nto amplify differences between adversarial and benign trajectories that are\nsubtle in the time domain. UniGuard exceptional efficiency and effectiveness\nhave been extensively validated across various modalities (image, text, and\naudio) and tasks (classification and regression), ranging from diverse model\narchitectures against a wide range of AE attacks and backdoor attacks,\nincluding challenging partial backdoors and dynamic triggers. When compared to\nSOTA methods, including ContraNet (NDSS 22) specific for AE detection and TED\n(IEEE SP 24) specific for backdoor detection, UniGuard consistently\ndemonstrates superior performance, even when matched against each method's\nstrengths in addressing their respective threats-each SOTA fails to parts of\nattack strategies while UniGuard succeeds for all.", "AI": {"tldr": "UniGuard is a unified online detection framework for adversarial examples and backdoor attacks, leveraging trajectory signatures and LSTM for detection.", "motivation": "Current methods address adversarial examples (AE) and backdoor attacks separately, leaving gaps in defense. UniGuard aims to unify detection for both threats.", "method": "UniGuard analyzes propagation trajectories of inputs in DL models as time-series signals, using LSTM and spectrum transformation to detect adversarial deviations.", "result": "UniGuard outperforms state-of-the-art methods (ContraNet, TED) across modalities (image, text, audio) and tasks (classification, regression), handling diverse attacks.", "conclusion": "UniGuard provides a robust, unified solution for detecting both adversarial examples and backdoor attacks, surpassing specialized methods."}}
{"id": "2506.23469", "pdf": "https://arxiv.org/pdf/2506.23469", "abs": "https://arxiv.org/abs/2506.23469", "authors": ["Chunjing Xiao", "Jiahui Lu", "Xovee Xu", "Fan Zhou", "Tianshu Xie", "Wei Lu", "Lifeng Xu"], "title": "Reconciling Attribute and Structural Anomalies for Improved Graph Anomaly Detection", "categories": ["cs.LG", "cs.SI"], "comment": "Accepted by IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS); DOI: https://doi.org/10.1109/TNNLS.2025.3561172", "summary": "Graph anomaly detection is critical in domains such as healthcare and\neconomics, where identifying deviations can prevent substantial losses.\nExisting unsupervised approaches strive to learn a single model capable of\ndetecting both attribute and structural anomalies. However, they confront the\ntug-of-war problem between two distinct types of anomalies, resulting in\nsuboptimal performance. This work presents TripleAD, a mutual\ndistillation-based triple-channel graph anomaly detection framework. It\nincludes three estimation modules to identify the attribute, structural, and\nmixed anomalies while mitigating the interference between different types of\nanomalies. In the first channel, we design a multiscale attribute estimation\nmodule to capture extensive node interactions and ameliorate the over-smoothing\nissue. To better identify structural anomalies, we introduce a link-enhanced\nstructure estimation module in the second channel that facilitates information\nflow to topologically isolated nodes. The third channel is powered by an\nattribute-mixed curvature, a new indicator that encapsulates both attribute and\nstructural information for discriminating mixed anomalies. Moreover, a mutual\ndistillation strategy is introduced to encourage communication and\ncollaboration between the three channels. Extensive experiments demonstrate the\neffectiveness of the proposed TripleAD model against strong baselines.", "AI": {"tldr": "TripleAD is a triple-channel framework for graph anomaly detection, addressing attribute, structural, and mixed anomalies via mutual distillation and specialized modules.", "motivation": "Existing unsupervised methods struggle with balancing attribute and structural anomaly detection, leading to suboptimal performance.", "method": "TripleAD uses three modules: multiscale attribute estimation, link-enhanced structure estimation, and attribute-mixed curvature, with mutual distillation for collaboration.", "result": "TripleAD outperforms baselines in detecting various anomaly types.", "conclusion": "The framework effectively mitigates interference between anomaly types and improves detection performance."}}
{"id": "2506.23074", "pdf": "https://arxiv.org/pdf/2506.23074", "abs": "https://arxiv.org/abs/2506.23074", "authors": ["Yu Zheng", "Boyang Gong", "Fanye Kong", "Yueqi Duan", "Bingyao Yu", "Wenzhao Zheng", "Lei Chen", "Jiwen Lu", "Jie Zhou"], "title": "Learning Counterfactually Decoupled Attention for Open-World Model Attribution", "categories": ["cs.CV", "cs.CR", "cs.LG"], "comment": "Accepted by ICCV 2025. Code: \\url{https://github.com/yzheng97/CDAL}", "summary": "In this paper, we propose a Counterfactually Decoupled Attention Learning\n(CDAL) method for open-world model attribution. Existing methods rely on\nhandcrafted design of region partitioning or feature space, which could be\nconfounded by the spurious statistical correlations and struggle with novel\nattacks in open-world scenarios. To address this, CDAL explicitly models the\ncausal relationships between the attentional visual traces and source model\nattribution, and counterfactually decouples the discriminative model-specific\nartifacts from confounding source biases for comparison. In this way, the\nresulting causal effect provides a quantification on the quality of learned\nattention maps, thus encouraging the network to capture essential generation\npatterns that generalize to unseen source models by maximizing the effect.\nExtensive experiments on existing open-world model attribution benchmarks show\nthat with minimal computational overhead, our method consistently improves\nstate-of-the-art models by large margins, particularly for unseen novel\nattacks. Source code: https://github.com/yzheng97/CDAL.", "AI": {"tldr": "CDAL introduces a causal approach for open-world model attribution, decoupling artifacts from biases to improve generalization to unseen attacks.", "motivation": "Existing methods are limited by handcrafted designs and spurious correlations, struggling with novel attacks in open-world scenarios.", "method": "CDAL models causal relationships between visual traces and attribution, decoupling artifacts from biases to quantify attention quality.", "result": "CDAL outperforms state-of-the-art models, especially for unseen attacks, with minimal computational overhead.", "conclusion": "CDAL effectively improves generalization in open-world model attribution by leveraging causal relationships."}}
{"id": "2506.24006", "pdf": "https://arxiv.org/pdf/2506.24006", "abs": "https://arxiv.org/abs/2506.24006", "authors": ["Anselm R. Strohmaier", "Wim Van Dooren", "Kathrin Se\u00dfler", "Brian Greer", "Lieven Verschaffel"], "title": "Large Language Models Don't Make Sense of Word Problems. A Scoping Review from a Mathematics Education Perspective", "categories": ["cs.CL", "math.HO"], "comment": null, "summary": "The progress of Large Language Models (LLMs) like ChatGPT raises the question\nof how they can be integrated into education. One hope is that they can support\nmathematics learning, including word-problem solving. Since LLMs can handle\ntextual input with ease, they appear well-suited for solving mathematical word\nproblems. Yet their real competence, whether they can make sense of the\nreal-world context, and the implications for classrooms remain unclear. We\nconducted a scoping review from a mathematics-education perspective, including\nthree parts: a technical overview, a systematic review of word problems used in\nresearch, and a state-of-the-art empirical evaluation of LLMs on mathematical\nword problems. First, in the technical overview, we contrast the\nconceptualization of word problems and their solution processes between LLMs\nand students. In computer-science research this is typically labeled\nmathematical reasoning, a term that does not align with usage in mathematics\neducation. Second, our literature review of 213 studies shows that the most\npopular word-problem corpora are dominated by s-problems, which do not require\na consideration of realities of their real-world context. Finally, our\nevaluation of GPT-3.5-turbo, GPT-4o-mini, GPT-4.1, and o3 on 287 word problems\nshows that most recent LLMs solve these s-problems with near-perfect accuracy,\nincluding a perfect score on 20 problems from PISA. LLMs still showed\nweaknesses in tackling problems where the real-world context is problematic or\nnon-sensical. In sum, we argue based on all three aspects that LLMs have\nmastered a superficial solution process but do not make sense of word problems,\nwhich potentially limits their value as instructional tools in mathematics\nclassrooms.", "AI": {"tldr": "The paper examines LLMs' ability to solve math word problems, finding they excel at superficial tasks but struggle with real-world context, limiting their educational utility.", "motivation": "To assess LLMs' potential in math education, focusing on their competence in solving word problems and understanding real-world context.", "method": "A scoping review with three parts: technical overview, systematic literature review of word-problem corpora, and empirical evaluation of LLMs on word problems.", "result": "LLMs perform well on superficial word problems (s-problems) but fail when real-world context is problematic, scoring perfectly on PISA problems but showing limitations elsewhere.", "conclusion": "LLMs lack deep understanding of word problems, limiting their effectiveness as instructional tools in math education."}}
{"id": "2506.22742", "pdf": "https://arxiv.org/pdf/2506.22742", "abs": "https://arxiv.org/abs/2506.22742", "authors": ["Wali Mohammad Abdullah", "Md. Morshedul Islam", "Devraj Parmar", "Happy Hasmukhbhai Patel", "Sindhuja Prabhakaran", "Baidya Saha"], "title": "RAILS: Retrieval-Augmented Intelligence for Learning Software Development", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) like GPT-3.5-Turbo are increasingly used to\nassist software development, yet they often produce incomplete code or\nincorrect imports, especially when lacking access to external or\nproject-specific documentation. We introduce RAILS (Retrieval-Augmented\nIntelligence for Learning Software Development), a framework that augments LLM\nprompts with semantically retrieved context from curated Java resources using\nFAISS and OpenAI embeddings. RAILS incorporates an iterative validation loop\nguided by compiler feedback to refine suggestions. We evaluated RAILS on 78\nreal-world Java import error cases spanning standard libraries, GUI APIs,\nexternal tools, and custom utilities. Despite using the same LLM, RAILS\noutperforms baseline prompting by preserving intent, avoiding hallucinations,\nand surfacing correct imports even when libraries are unavailable locally.\nFuture work will integrate symbolic filtering via PostgreSQL and extend support\nto other languages and IDEs.", "AI": {"tldr": "RAILS enhances LLM-based software development by retrieving context from Java resources and using compiler feedback to improve code suggestions, outperforming baseline methods.", "motivation": "LLMs often produce incomplete or incorrect code due to lack of project-specific context. RAILS addresses this by augmenting prompts with retrieved resources.", "method": "RAILS uses FAISS and OpenAI embeddings to retrieve relevant Java context, then refines suggestions via an iterative validation loop with compiler feedback.", "result": "RAILS outperforms baseline prompting in handling 78 Java import errors, preserving intent and avoiding hallucinations.", "conclusion": "RAILS improves LLM-assisted coding by leveraging retrieval and validation, with future plans for symbolic filtering and broader language/IDE support."}}
{"id": "2506.23492", "pdf": "https://arxiv.org/pdf/2506.23492", "abs": "https://arxiv.org/abs/2506.23492", "authors": ["Haolan Guo", "Linwei Tao", "Haoyang Luo", "Minjing Dong", "Chang Xu"], "title": "Sample Margin-Aware Recalibration of Temperature Scaling", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Recent advances in deep learning have significantly improved predictive\naccuracy. However, modern neural networks remain systematically overconfident,\nposing risks for deployment in safety-critical scenarios. Current post-hoc\ncalibration methods face a fundamental dilemma: global approaches like\nTemperature Scaling apply uniform adjustments across all samples, introducing\nhigh bias despite computational efficiency, while more expressive methods that\noperate on full logit distributions suffer from high variance due to noisy\nhigh-dimensional inputs and insufficient validation data. To address these\nchallenges, we propose Sample Margin-Aware Recalibration of Temperature\n(SMART), a lightweight, data-efficient recalibration method that precisely\nscales logits based on the margin between the top two logits -- termed the\nlogit gap. Specifically, the logit gap serves as a denoised, scalar signal\ndirectly tied to decision boundary uncertainty, providing a robust indicator\nthat avoids the noise inherent in high-dimensional logit spaces while\npreserving model prediction invariance. Meanwhile, SMART employs a novel\nsoft-binned Expected Calibration Error (SoftECE) objective that balances model\nbias and variance through adaptive binning, enabling stable parameter updates\neven with extremely limited calibration data. Extensive evaluations across\ndiverse datasets and architectures demonstrate that SMART achieves\nstate-of-the-art calibration performance even with substantially fewer\nparameters compared to existing parametric methods, offering a principled,\nrobust, and highly efficient solution for practical uncertainty quantification\nin neural network predictions. The source code is available at:\nhttps://anonymous.4open.science/r/SMART-8B11.", "AI": {"tldr": "SMART is a lightweight recalibration method for neural networks that uses the logit gap to improve calibration efficiently.", "motivation": "Modern neural networks are overconfident, posing risks in safety-critical applications, and current calibration methods struggle with bias-variance trade-offs.", "method": "SMART scales logits based on the logit gap (margin between top two logits) and uses a SoftECE objective for adaptive binning.", "result": "SMART achieves state-of-the-art calibration with fewer parameters and limited data.", "conclusion": "SMART provides a robust, efficient solution for uncertainty quantification in neural networks."}}
{"id": "2506.23077", "pdf": "https://arxiv.org/pdf/2506.23077", "abs": "https://arxiv.org/abs/2506.23077", "authors": ["Suofei Zhang", "Xinxin Wang", "Xiaofu Wu", "Quan Zhou", "Haifeng Hu"], "title": "Dynamic Contrastive Learning for Hierarchical Retrieval: A Case Study of Distance-Aware Cross-View Geo-Localization", "categories": ["cs.CV"], "comment": null, "summary": "Existing deep learning-based cross-view geo-localization methods primarily\nfocus on improving the accuracy of cross-domain image matching, rather than\nenabling models to comprehensively capture contextual information around the\ntarget and minimize the cost of localization errors. To support systematic\nresearch into this Distance-Aware Cross-View Geo-Localization (DACVGL) problem,\nwe construct Distance-Aware Campus (DA-Campus), the first benchmark that pairs\nmulti-view imagery with precise distance annotations across three spatial\nresolutions. Based on DA-Campus, we formulate DACVGL as a hierarchical\nretrieval problem across different domains. Our study further reveals that, due\nto the inherent complexity of spatial relationships among buildings, this\nproblem can only be addressed via a contrastive learning paradigm, rather than\nconventional metric learning. To tackle this challenge, we propose Dynamic\nContrastive Learning (DyCL), a novel framework that progressively aligns\nfeature representations according to hierarchical spatial margins. Extensive\nexperiments demonstrate that DyCL is highly complementary to existing\nmulti-scale metric learning methods and yields substantial improvements in both\nhierarchical retrieval performance and overall cross-view geo-localization\naccuracy. Our code and benchmark are publicly available at\nhttps://github.com/anocodetest1/DyCL.", "AI": {"tldr": "The paper introduces Distance-Aware Cross-View Geo-Localization (DACVGL) and a benchmark (DA-Campus) with multi-view imagery and distance annotations. It proposes Dynamic Contrastive Learning (DyCL) to address hierarchical retrieval, outperforming existing methods.", "motivation": "Existing methods focus on cross-domain image matching but lack contextual awareness and error cost minimization. DACVGL aims to address this gap.", "method": "The paper formulates DACVGL as a hierarchical retrieval problem and introduces DyCL, a contrastive learning framework aligning features by spatial margins.", "result": "DyCL complements multi-scale metric learning, improving hierarchical retrieval and geo-localization accuracy.", "conclusion": "DyCL effectively addresses DACVGL's challenges, offering a novel solution with publicly available code and benchmark."}}
{"id": "2506.24016", "pdf": "https://arxiv.org/pdf/2506.24016", "abs": "https://arxiv.org/abs/2506.24016", "authors": ["Hyunjong Kim", "Sangyeop Kim", "Jongheon Jeong", "Yeongjae Cho", "Sungzoon Cho"], "title": "EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "Accepted at ACL 2025 Findings", "summary": "Recent advances in large language models and vision-language models have led\nto growing interest in explainable evaluation metrics for image captioning.\nHowever, these metrics generate explanations without standardized criteria, and\nthe overall quality of the generated explanations remains unverified. In this\npaper, we propose EXPERT, a reference-free evaluation metric that provides\nstructured explanations based on three fundamental criteria: fluency,\nrelevance, and descriptiveness. By constructing large-scale datasets of\nhigh-quality structured explanations, we develop a two-stage evaluation\ntemplate to effectively supervise a vision-language model for both scoring and\nexplanation generation. EXPERT achieves state-of-the-art results on benchmark\ndatasets while providing significantly higher-quality explanations than\nexisting metrics, as validated through comprehensive human evaluation. Our code\nand datasets are available at https://github.com/hjkim811/EXPERT.", "AI": {"tldr": "EXPERT is a reference-free evaluation metric for image captioning, providing structured explanations based on fluency, relevance, and descriptiveness. It outperforms existing metrics in both scoring and explanation quality.", "motivation": "Current explainable evaluation metrics lack standardized criteria and verified explanation quality.", "method": "EXPERT uses a two-stage evaluation template to supervise a vision-language model, leveraging large-scale datasets of structured explanations.", "result": "EXPERT achieves state-of-the-art results on benchmarks and higher-quality explanations, validated by human evaluation.", "conclusion": "EXPERT sets a new standard for explainable evaluation metrics in image captioning, with publicly available code and datasets."}}
{"id": "2506.22776", "pdf": "https://arxiv.org/pdf/2506.22776", "abs": "https://arxiv.org/abs/2506.22776", "authors": ["Sen Fang", "Weiyuan Ding", "Antonio Mastropaolo", "Bowen Xu"], "title": "Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": "13 pages, 6 figures", "summary": "Quantization has emerged as a mainstream method for compressing Large\nLanguage Models (LLMs), reducing memory requirements and accelerating inference\nwithout architectural modifications. While existing research primarily focuses\non evaluating the effectiveness of quantized LLMs compared to their original\ncounterparts, the impact on robustness remains largely unexplored.In this\npaper, we present the first systematic investigation of how quantization\naffects the robustness of LLMs in code generation tasks. Through extensive\nexperiments across four prominent LLM families (LLaMA, DeepSeek, CodeGen, and\nStarCoder) with parameter scales ranging from 350M to 33B, we evaluate\nrobustness from dual perspectives: adversarial attacks on input prompts and\nnoise perturbations on model architecture. Our findings challenge conventional\nwisdom by demonstrating that quantized LLMs often exhibit superior robustness\ncompared to their full-precision counterparts, with 51.59% versus 42.86% of our\nadversarial experiments showing better resilience in quantized LLMs. Similarly,\nour noise perturbation experiments also confirm that LLMs after quantitation\ngenerally withstand higher levels of weight disturbances. These results suggest\nthat quantization not only reduces computational requirements but can actually\nenhance LLMs' reliability in code generation tasks, providing valuable insights\nfor developing more robust and efficient LLM deployment strategies.", "AI": {"tldr": "Quantization improves LLM robustness in code generation, outperforming full-precision models in adversarial and noise tests.", "motivation": "To explore the unexplored impact of quantization on LLM robustness in code generation tasks.", "method": "Systematic experiments on four LLM families (LLaMA, DeepSeek, CodeGen, StarCoder) with adversarial attacks and noise perturbations.", "result": "Quantized LLMs show superior robustness (51.59% vs. 42.86%) and withstand higher weight disturbances.", "conclusion": "Quantization enhances LLM reliability in code generation, offering insights for robust and efficient deployment."}}
{"id": "2506.23516", "pdf": "https://arxiv.org/pdf/2506.23516", "abs": "https://arxiv.org/abs/2506.23516", "authors": ["Seung-Wook Kim", "Seongyeol Kim", "Jiah Kim", "Seowon Ji", "Se-Ho Lee"], "title": "FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Federated learning (FL) often suffers from performance degradation due to key\nchallenges such as data heterogeneity and communication constraints. To address\nthese limitations, we present a novel FL framework called FedWSQ, which\nintegrates weight standardization (WS) and the proposed distribution-aware\nnon-uniform quantization (DANUQ). WS enhances FL performance by filtering out\nbiased components in local updates during training, thereby improving the\nrobustness of the model against data heterogeneity and unstable client\nparticipation. In addition, DANUQ minimizes quantization errors by leveraging\nthe statistical properties of local model updates. As a result, FedWSQ\nsignificantly reduces communication overhead while maintaining superior model\naccuracy. Extensive experiments on FL benchmark datasets demonstrate that\nFedWSQ consistently outperforms existing FL methods across various challenging\nFL settings, including extreme data heterogeneity and ultra-low-bit\ncommunication scenarios.", "AI": {"tldr": "FedWSQ improves federated learning by combining weight standardization and distribution-aware non-uniform quantization, addressing data heterogeneity and communication constraints.", "motivation": "Federated learning suffers from performance issues due to data heterogeneity and communication constraints, necessitating a robust solution.", "method": "FedWSQ integrates weight standardization (WS) to filter biased local updates and distribution-aware non-uniform quantization (DANUQ) to minimize quantization errors.", "result": "FedWSQ reduces communication overhead while maintaining high model accuracy, outperforming existing methods in challenging FL settings.", "conclusion": "FedWSQ effectively addresses key FL challenges, offering superior performance in heterogeneous and low-bit communication scenarios."}}
{"id": "2506.23086", "pdf": "https://arxiv.org/pdf/2506.23086", "abs": "https://arxiv.org/abs/2506.23086", "authors": ["Jian Shi", "Tianqi You", "Pingping Zhang", "Hongli Zhang", "Rui Xu", "Haojie Li"], "title": "Frequency-enhanced Multi-granularity Context Network for Efficient Vertebrae Segmentation", "categories": ["cs.CV"], "comment": "Accepted by MICCAI2025. More modifications my be performed", "summary": "Automated and accurate segmentation of individual vertebra in 3D CT and MRI\nimages is essential for various clinical applications. Due to the limitations\nof current imaging techniques and the complexity of spinal structures, existing\nmethods still struggle with reducing the impact of image blurring and\ndistinguishing similar vertebrae. To alleviate these issues, we introduce a\nFrequency-enhanced Multi-granularity Context Network (FMC-Net) to improve the\naccuracy of vertebrae segmentation. Specifically, we first apply wavelet\ntransform for lossless downsampling to reduce the feature distortion in blurred\nimages. The decomposed high and low-frequency components are then processed\nseparately. For the high-frequency components, we apply a High-frequency\nFeature Refinement (HFR) to amplify the prominence of key features and filter\nout noises, restoring fine-grained details in blurred images. For the\nlow-frequency components, we use a Multi-granularity State Space Model (MG-SSM)\nto aggregate feature representations with different receptive fields,\nextracting spatially-varying contexts while capturing long-range dependencies\nwith linear complexity. The utilization of multi-granularity contexts is\nessential for distinguishing similar vertebrae and improving segmentation\naccuracy. Extensive experiments demonstrate that our method outperforms\nstate-of-the-art approaches on both CT and MRI vertebrae segmentation datasets.\nThe source code is publicly available at https://github.com/anaanaa/FMCNet.", "AI": {"tldr": "The paper introduces FMC-Net, a frequency-enhanced multi-granularity context network, to improve vertebrae segmentation in 3D CT and MRI images by addressing blurring and distinguishing similar vertebrae.", "motivation": "Current methods struggle with image blurring and distinguishing similar vertebrae in spinal structures, limiting segmentation accuracy.", "method": "FMC-Net uses wavelet transform for lossless downsampling, processes high-frequency components with HFR for feature refinement, and low-frequency components with MG-SSM for multi-granularity context aggregation.", "result": "The method outperforms state-of-the-art approaches on CT and MRI datasets, demonstrating improved segmentation accuracy.", "conclusion": "FMC-Net effectively addresses segmentation challenges, offering a robust solution for clinical applications, with publicly available source code."}}
{"id": "2506.24068", "pdf": "https://arxiv.org/pdf/2506.24068", "abs": "https://arxiv.org/abs/2506.24068", "authors": ["Ian R. McKenzie", "Oskar J. Hollinsworth", "Tom Tseng", "Xander Davies", "Stephen Casper", "Aaron D. Tucker", "Robert Kirk", "Adam Gleave"], "title": "STACK: Adversarial Attacks on LLM Safeguard Pipelines", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Frontier AI developers are relying on layers of safeguards to protect against\ncatastrophic misuse of AI systems. Anthropic guards their latest Claude 4 Opus\nmodel using one such defense pipeline, and other frontier developers including\nGoogle DeepMind and OpenAI pledge to soon deploy similar defenses. However, the\nsecurity of such pipelines is unclear, with limited prior work evaluating or\nattacking these pipelines. We address this gap by developing and red-teaming an\nopen-source defense pipeline. First, we find that a novel few-shot-prompted\ninput and output classifier outperforms state-of-the-art open-weight safeguard\nmodel ShieldGemma across three attacks and two datasets, reducing the attack\nsuccess rate (ASR) to 0% on the catastrophic misuse dataset ClearHarm. Second,\nwe introduce a STaged AttaCK (STACK) procedure that achieves 71% ASR on\nClearHarm in a black-box attack against the few-shot-prompted classifier\npipeline. Finally, we also evaluate STACK in a transfer setting, achieving 33%\nASR, providing initial evidence that it is feasible to design attacks with no\naccess to the target pipeline. We conclude by suggesting specific mitigations\nthat developers could use to thwart staged attacks.", "AI": {"tldr": "The paper evaluates the security of AI defense pipelines, introduces a novel classifier and attack method (STACK), and suggests mitigations.", "motivation": "To address the lack of evaluation and attacks on AI defense pipelines used by frontier developers like Anthropic, Google DeepMind, and OpenAI.", "method": "Developed an open-source defense pipeline, tested a few-shot-prompted classifier, and introduced the STACK attack procedure.", "result": "The classifier outperformed ShieldGemma (0% ASR on ClearHarm), while STACK achieved 71% ASR in black-box and 33% in transfer settings.", "conclusion": "AI defense pipelines are vulnerable; staged attacks like STACK are feasible, and specific mitigations are needed."}}
{"id": "2506.22793", "pdf": "https://arxiv.org/pdf/2506.22793", "abs": "https://arxiv.org/abs/2506.22793", "authors": ["Pegah Alizadeh", "Anastasios Giovanidis", "Pradeepa Ramachandra", "Vasileios Koutsoukis", "Osama Arouk"], "title": "Offline Reinforcement Learning for Mobility Robustness Optimization", "categories": ["cs.NI", "cs.AI", "cs.PF"], "comment": "7 pages, double column, 4 figures, 6 tables, conference submission", "summary": "In this work we revisit the Mobility Robustness Optimisation (MRO) algorithm\nand study the possibility of learning the optimal Cell Individual Offset tuning\nusing offline Reinforcement Learning. Such methods make use of collected\noffline datasets to learn the optimal policy, without further exploration. We\nadapt and apply a sequence-based method called Decision Transformers as well as\na value-based method called Conservative Q-Learning to learn the optimal policy\nfor the same target reward as the vanilla rule-based MRO. The same input\nfeatures related to failures, ping-pongs, and other handover issues are used.\nEvaluation for realistic New Radio networks with 3500 MHz carrier frequency on\na traffic mix including diverse user service types and a specific tunable\ncell-pair shows that offline-RL methods outperform rule-based MRO, offering up\nto 7% improvement. Furthermore, offline-RL can be trained for diverse objective\nfunctions using the same available dataset, thus offering operational\nflexibility compared to rule-based methods.", "AI": {"tldr": "Offline Reinforcement Learning (RL) methods outperform rule-based Mobility Robustness Optimisation (MRO) in tuning Cell Individual Offset, offering up to 7% improvement in realistic New Radio networks.", "motivation": "To improve the rule-based MRO algorithm by leveraging offline RL for optimal policy learning without exploration.", "method": "Adapted Decision Transformers (sequence-based) and Conservative Q-Learning (value-based) to learn the optimal policy using the same input features as rule-based MRO.", "result": "Offline-RL methods achieved up to 7% improvement over rule-based MRO in realistic New Radio networks.", "conclusion": "Offline-RL provides better performance and operational flexibility for diverse objective functions compared to rule-based methods."}}
{"id": "2506.23544", "pdf": "https://arxiv.org/pdf/2506.23544", "abs": "https://arxiv.org/abs/2506.23544", "authors": ["Kento Imaizumi", "Hideaki Iiduka"], "title": "Both Asymptotic and Non-Asymptotic Convergence of Quasi-Hyperbolic Momentum using Increasing Batch Size", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Momentum methods were originally introduced for their superiority to\nstochastic gradient descent (SGD) in deterministic settings with convex\nobjective functions. However, despite their widespread application to deep\nneural networks -- a representative case of stochastic nonconvex optimization\n-- the theoretical justification for their effectiveness in such settings\nremains limited. Quasi-hyperbolic momentum (QHM) is an algorithm that\ngeneralizes various momentum methods and has been studied to better understand\nthe class of momentum-based algorithms as a whole. In this paper, we provide\nboth asymptotic and non-asymptotic convergence results for mini-batch QHM with\nan increasing batch size. We show that achieving asymptotic convergence\nrequires either a decaying learning rate or an increasing batch size. Since a\ndecaying learning rate adversely affects non-asymptotic convergence, we\ndemonstrate that using mini-batch QHM with an increasing batch size -- without\ndecaying the learning rate -- can be a more effective strategy. Our experiments\nshow that even a finite increase in batch size can provide benefits for\ntraining neural networks.", "AI": {"tldr": "QHM, a momentum method, is analyzed for stochastic nonconvex optimization. Asymptotic convergence requires decaying learning rates or increasing batch sizes. Increasing batch sizes without decaying learning rates proves more effective.", "motivation": "To understand the effectiveness of momentum methods like QHM in stochastic nonconvex optimization, particularly for deep neural networks.", "method": "Analyzes mini-batch QHM with increasing batch sizes, comparing it to decaying learning rates.", "result": "Asymptotic convergence is achievable with increasing batch sizes, which also benefits non-asymptotic performance. Experiments confirm practical advantages.", "conclusion": "Increasing batch sizes in QHM is a viable alternative to decaying learning rates, offering better performance in neural network training."}}
{"id": "2506.23088", "pdf": "https://arxiv.org/pdf/2506.23088", "abs": "https://arxiv.org/abs/2506.23088", "authors": ["Yuchen Zhou", "Jiayu Tang", "Xiaoyan Xiao", "Yueyao Lin", "Linkai Liu", "Zipeng Guo", "Hao Fei", "Xiaobo Xia", "Chao Gou"], "title": "Where, What, Why: Towards Explainable Driver Attention Prediction", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "Modeling task-driven attention in driving is a fundamental challenge for both\nautonomous vehicles and cognitive science. Existing methods primarily predict\nwhere drivers look by generating spatial heatmaps, but fail to capture the\ncognitive motivations behind attention allocation in specific contexts, which\nlimits deeper understanding of attention mechanisms. To bridge this gap, we\nintroduce Explainable Driver Attention Prediction, a novel task paradigm that\njointly predicts spatial attention regions (where), parses attended semantics\n(what), and provides cognitive reasoning for attention allocation (why). To\nsupport this, we present W3DA, the first large-scale explainable driver\nattention dataset. It enriches existing benchmarks with detailed semantic and\ncausal annotations across diverse driving scenarios, including normal\nconditions, safety-critical situations, and traffic accidents. We further\npropose LLada, a Large Language model-driven framework for driver attention\nprediction, which unifies pixel modeling, semantic parsing, and cognitive\nreasoning within an end-to-end architecture. Extensive experiments demonstrate\nthe effectiveness of LLada, exhibiting robust generalization across datasets\nand driving conditions. This work serves as a key step toward a deeper\nunderstanding of driver attention mechanisms, with significant implications for\nautonomous driving, intelligent driver training, and human-computer\ninteraction.", "AI": {"tldr": "The paper introduces Explainable Driver Attention Prediction, a task paradigm predicting where, what, and why drivers focus, supported by the W3DA dataset and the LLada framework.", "motivation": "Existing methods predict spatial attention but lack insights into cognitive motivations, limiting understanding of attention mechanisms in driving.", "method": "Proposes LLada, a Large Language model-driven framework unifying pixel modeling, semantic parsing, and cognitive reasoning in an end-to-end architecture.", "result": "LLada demonstrates robust generalization across datasets and driving conditions.", "conclusion": "This work advances understanding of driver attention, benefiting autonomous driving, driver training, and human-computer interaction."}}
{"id": "2506.24106", "pdf": "https://arxiv.org/pdf/2506.24106", "abs": "https://arxiv.org/abs/2506.24106", "authors": ["Yanhong Li", "Ming Li", "Karen Livescu", "Jiawei Zhou"], "title": "On the Predictive Power of Representation Dispersion in Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We show that a language model's ability to predict text is tightly linked to\nthe breadth of its embedding space: models that spread their contextual\nrepresentations more widely tend to achieve lower perplexity. Concretely, we\nfind that representation dispersion - the average pairwise cosine distance\namong hidden vectors - strongly and negatively correlates with perplexity\nacross diverse model families (LLaMA, Qwen, and others) and domains (Wikipedia,\nnews, scientific abstracts). Beyond illustrating this link, we show how\ndispersion can be leveraged for a range of practical tasks without requiring\nlabeled data. First, measuring dispersion on unlabeled text allows us to\npredict downstream accuracy in new domains, offering a data-efficient tool for\nmodel selection. Next, we find that identifying layers with higher dispersion\npinpoints the best representations for retrieval-based methods such as kNN-LM,\nbypassing exhaustive layer-by-layer searches. Finally, we integrate a simple\npush-away objective into training, which increases dispersion in both\nsingle-domain and cross-domain scenarios and directly improves perplexity in\neach.", "AI": {"tldr": "Language models with wider embedding spaces (higher representation dispersion) achieve lower perplexity, and this dispersion can be used for practical tasks like model selection and improving retrieval-based methods.", "motivation": "To explore the relationship between a model's embedding space breadth (dispersion) and its predictive performance (perplexity), and to leverage this for practical applications.", "method": "Analyze representation dispersion (average pairwise cosine distance) across models (LLaMA, Qwen) and domains (Wikipedia, news, scientific abstracts). Use dispersion for tasks like predicting downstream accuracy, optimizing retrieval methods, and enhancing training with a push-away objective.", "result": "Higher dispersion strongly correlates with lower perplexity. Dispersion aids in model selection, identifies optimal layers for retrieval, and improves perplexity when integrated into training.", "conclusion": "Representation dispersion is a key factor in model performance and can be practically utilized for efficiency and accuracy improvements."}}
{"id": "2506.22818", "pdf": "https://arxiv.org/pdf/2506.22818", "abs": "https://arxiv.org/abs/2506.22818", "authors": ["Stanislav Sedukhin", "Yoichi Tomioka", "Kazuya Matsumoto", "Yuichi Okuyama"], "title": "TriADA: Massively Parallel Trilinear Matrix-by-Tensor Multiply-Add Algorithm and Device Architecture for the Acceleration of 3D Discrete Transformations", "categories": ["cs.DC", "cs.AI", "cs.AR", "cs.ET", "eess.SP", "C.1.4; C.3; F.2.1; G.1.3; G.4"], "comment": "19 pages, 5 figures", "summary": "Multilinear transformations are key in high-performance computing (HPC) and\nartificial intelligence (AI) workloads, where data is represented as tensors.\nHowever, their high computational and memory demands, which grow with\ndimensionality, often slow down critical tasks. Moreover, scaling computation\nby enlarging the number of parallel processing units substantially increases\nenergy consumption, limiting widespread adoption, especially for sparse data,\nwhich is common in HPC and AI applications. This paper introduces the Trilinear\nAlgorithm and isomorphic to algorithm Device Architecture (TriADA) to address\nthese challenges with the following innovations: (1) a massively parallel,\nlow-rank algorithm for computing a family of trilinear (3D) discrete orthogonal\ntransformations (3D-DXTs), which is a special case of the more general 3-mode\nmatrix-by-tensor multiplication (3D-GEMT); (2) a new outer-product-based GEMM\nkernel with decoupled streaming active memory, specially designed to accelerate\n3D-GEMT operation; (3) an isomorphic to the proposed algorithm, fully\ndistributed 3D network of mesh interconnected processing elements or cells with\na coordinate-free, data-driven local processing activity, which is independent\nof problem size; (4) an elastic sparse outer-product (ESOP) method that avoids\nunnecessary computing and communication operations with zero-valued operands,\nthereby enhancing energy efficiency, computational accuracy, and stability.\nTriADA is capable of performing a variety of trilinear transformations with\nhypercubic arithmetic complexity in a linear number of time-steps. The\nmassively parallel, scalable, and energy-efficient architecture of TriADA is\nideal for accelerating multilinear tensor operations, which are the most\ndemanding parts of AI and HPC workloads.", "AI": {"tldr": "The paper introduces TriADA, a novel architecture and algorithm for efficient trilinear transformations in HPC and AI, addressing computational and energy challenges.", "motivation": "High computational and memory demands of multilinear transformations in HPC and AI, especially for sparse data, limit performance and energy efficiency.", "method": "TriADA combines a low-rank trilinear algorithm, a new GEMM kernel, a distributed 3D network, and an ESOP method for energy-efficient, scalable tensor operations.", "result": "TriADA achieves hypercubic arithmetic complexity in linear time-steps, enhancing performance and energy efficiency for multilinear tensor operations.", "conclusion": "TriADA is a scalable, energy-efficient solution for accelerating demanding tensor operations in AI and HPC workloads."}}
{"id": "2506.23551", "pdf": "https://arxiv.org/pdf/2506.23551", "abs": "https://arxiv.org/abs/2506.23551", "authors": ["Jingpu Cheng", "Qianxiao Li", "Ting Lin", "Zuowei Shen"], "title": "A unified framework on the universal approximation of transformer-type architectures", "categories": ["cs.LG"], "comment": null, "summary": "We investigate the universal approximation property (UAP) of transformer-type\narchitectures, providing a unified theoretical framework that extends prior\nresults on residual networks to models incorporating attention mechanisms. Our\nwork identifies token distinguishability as a fundamental requirement for UAP\nand introduces a general sufficient condition that applies to a broad class of\narchitectures. Leveraging an analyticity assumption on the attention layer, we\ncan significantly simplify the verification of this condition, providing a\nnon-constructive approach in establishing UAP for such architectures. We\ndemonstrate the applicability of our framework by proving UAP for transformers\nwith various attention mechanisms, including kernel-based and sparse attention\nmechanisms. The corollaries of our results either generalize prior works or\nestablish UAP for architectures not previously covered. Furthermore, our\nframework offers a principled foundation for designing novel transformer\narchitectures with inherent UAP guarantees, including those with specific\nfunctional symmetries. We propose examples to illustrate these insights.", "AI": {"tldr": "The paper explores the universal approximation property (UAP) in transformer architectures, introducing a unified framework and token distinguishability as a key requirement. It simplifies UAP verification and extends results to various attention mechanisms.", "motivation": "To extend theoretical understanding of UAP to transformer architectures, unifying prior work on residual networks and attention mechanisms.", "method": "Introduces token distinguishability as a requirement and a general sufficient condition for UAP. Uses analyticity assumptions to simplify verification and applies the framework to transformers with diverse attention mechanisms.", "result": "Proves UAP for transformers with kernel-based and sparse attention, generalizing prior work. Provides a foundation for designing new architectures with UAP guarantees.", "conclusion": "The framework advances theoretical understanding of transformers and enables principled design of architectures with inherent UAP."}}
{"id": "2506.23104", "pdf": "https://arxiv.org/pdf/2506.23104", "abs": "https://arxiv.org/abs/2506.23104", "authors": ["Jihun Kim", "Hoyong Kwon", "Hyeokjun Kweon", "Wooseong Jeong", "Kuk-Jin Yoon"], "title": "DC-TTA: Divide-and-Conquer Framework for Test-Time Adaptation of Interactive Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Interactive segmentation (IS) allows users to iteratively refine object\nboundaries with minimal cues, such as positive and negative clicks. While the\nSegment Anything Model (SAM) has garnered attention in the IS community for its\npromptable segmentation capabilities, it often struggles in specialized domains\nor when handling complex scenarios (e.g., camouflaged or multi-part objects).\nTo overcome these challenges, we propose DC-TTA, a novel test-time adaptation\n(TTA) framework that adapts SAM on a per-sample basis by leveraging user\ninteractions as supervision. Instead of forcing a single model to incorporate\nall user clicks at once, DC-TTA partitions the clicks into more coherent\nsubsets, each processed independently via TTA with a separated model. This\nDivide-and-Conquer strategy reduces conflicts among diverse cues and enables\nmore localized updates. Finally, we merge the adapted models to form a unified\npredictor that integrates the specialized knowledge from each subset.\nExperimental results across various benchmarks demonstrate that DC-TTA\nsignificantly outperforms SAM's zero-shot results and conventional TTA methods,\neffectively handling complex tasks such as camouflaged object segmentation with\nfewer interactions and improved accuracy.", "AI": {"tldr": "DC-TTA improves SAM's interactive segmentation by dividing user clicks into subsets for localized updates, outperforming SAM and traditional TTA methods.", "motivation": "SAM struggles in specialized domains and complex scenarios like camouflaged objects, needing better adaptation to user cues.", "method": "DC-TTA partitions user clicks into coherent subsets, processes each independently via TTA, and merges adapted models for unified predictions.", "result": "DC-TTA outperforms SAM's zero-shot results and conventional TTA, handling complex tasks with fewer interactions and higher accuracy.", "conclusion": "DC-TTA effectively adapts SAM for complex scenarios, improving segmentation with minimal user input."}}
{"id": "2506.24117", "pdf": "https://arxiv.org/pdf/2506.24117", "abs": "https://arxiv.org/abs/2506.24117", "authors": ["David M. Smiley"], "title": "Computational Detection of Intertextual Parallels in Biblical Hebrew: A Benchmark Study Using Transformer-Based Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Identifying parallel passages in biblical Hebrew is foundational in biblical\nscholarship for uncovering intertextual relationships. Traditional methods rely\non manual comparison, which is labor-intensive and prone to human error. This\nstudy evaluates the potential of pre-trained transformer-based language models,\nincluding E5, AlephBERT, MPNet, and LaBSE, for detecting textual parallels in\nthe Hebrew Bible. Focusing on known parallels between the books of Samuel/Kings\nand Chronicles, I assessed each model's capability to generate word embeddings\nthat delineate parallel from non-parallel passages. Utilizing cosine similarity\nand Wasserstein Distance measures, I found that E5 and AlephBERT show\nsignificant promise, with E5 excelling in parallel detection and AlephBERT\ndemonstrating stronger non-parallel differentiation. These findings indicate\nthat pre-trained models can enhance the efficiency and accuracy of detecting\nintertextual parallels in ancient texts, suggesting broader applications for\nancient language studies.", "AI": {"tldr": "Pre-trained transformer models (E5, AlephBERT, MPNet, LaBSE) are evaluated for detecting parallel passages in biblical Hebrew, with E5 and AlephBERT showing strong performance.", "motivation": "Traditional manual comparison of biblical Hebrew passages is labor-intensive and error-prone, necessitating automated solutions.", "method": "Models generate word embeddings for passages, evaluated using cosine similarity and Wasserstein Distance to detect parallels.", "result": "E5 excels in parallel detection, while AlephBERT better differentiates non-parallel passages.", "conclusion": "Pre-trained models improve efficiency and accuracy in detecting intertextual parallels, with potential for broader ancient language studies."}}
{"id": "2506.23589", "pdf": "https://arxiv.org/pdf/2506.23589", "abs": "https://arxiv.org/abs/2506.23589", "authors": ["Neta Shaul", "Uriel Singer", "Itai Gat", "Yaron Lipman"], "title": "Transition Matching: Scalable and Flexible Generative Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion and flow matching models have significantly advanced media\ngeneration, yet their design space is well-explored, somewhat limiting further\nimprovements. Concurrently, autoregressive (AR) models, particularly those\ngenerating continuous tokens, have emerged as a promising direction for\nunifying text and media generation. This paper introduces Transition Matching\n(TM), a novel discrete-time, continuous-state generative paradigm that unifies\nand advances both diffusion/flow models and continuous AR generation. TM\ndecomposes complex generation tasks into simpler Markov transitions, allowing\nfor expressive non-deterministic probability transition kernels and arbitrary\nnon-continuous supervision processes, thereby unlocking new flexible design\navenues. We explore these choices through three TM variants: (i) Difference\nTransition Matching (DTM), which generalizes flow matching to discrete-time by\ndirectly learning transition probabilities, yielding state-of-the-art image\nquality and text adherence as well as improved sampling efficiency. (ii)\nAutoregressive Transition Matching (ARTM) and (iii) Full History Transition\nMatching (FHTM) are partially and fully causal models, respectively, that\ngeneralize continuous AR methods. They achieve continuous causal AR generation\nquality comparable to non-causal approaches and potentially enable seamless\nintegration with existing AR text generation techniques. Notably, FHTM is the\nfirst fully causal model to match or surpass the performance of flow-based\nmethods on text-to-image task in continuous domains. We demonstrate these\ncontributions through a rigorous large-scale comparison of TM variants and\nrelevant baselines, maintaining a fixed architecture, training data, and\nhyperparameters.", "AI": {"tldr": "The paper introduces Transition Matching (TM), a novel generative paradigm unifying diffusion/flow models and continuous autoregressive (AR) generation, offering flexibility and improved performance.", "motivation": "To address limitations in diffusion/flow models and unify text/media generation, leveraging continuous AR models for better design flexibility.", "method": "TM decomposes generation tasks into Markov transitions, introducing three variants: DTM (generalizes flow matching), ARTM (partially causal), and FHTM (fully causal).", "result": "DTM achieves state-of-the-art image quality and text adherence; ARTM and FHTM match non-causal AR methods, with FHTM surpassing flow-based methods in text-to-image tasks.", "conclusion": "TM advances generative modeling by unifying diffusion/flow and AR approaches, demonstrating superior performance and flexibility."}}
{"id": "2506.23106", "pdf": "https://arxiv.org/pdf/2506.23106", "abs": "https://arxiv.org/abs/2506.23106", "authors": ["Ryo Ishiyama", "Shinnosuke Matsuo", "Seiichi Uchida"], "title": "Computer-Aided Multi-Stroke Character Simplification by Stroke Removal", "categories": ["cs.CV"], "comment": "ICDAR2025 (Oral)", "summary": "Multi-stroke characters in scripts such as Chinese and Japanese can be highly\ncomplex, posing significant challenges for both native speakers and,\nespecially, non-native learners. If these characters can be simplified without\ndegrading their legibility, it could reduce learning barriers for non-native\nspeakers, facilitate simpler and legible font designs, and contribute to\nefficient character-based communication systems. In this paper, we propose a\nframework to systematically simplify multi-stroke characters by selectively\nremoving strokes while preserving their overall legibility. More specifically,\nwe use a highly accurate character recognition model to assess legibility and\nremove those strokes that minimally impact it. Experimental results on 1,256\ncharacter classes with 5, 10, 15, and 20 strokes reveal several key findings,\nincluding the observation that even after removing multiple strokes, many\ncharacters remain distinguishable. These findings suggest the potential for\nmore formalized simplification strategies.", "AI": {"tldr": "A framework simplifies multi-stroke characters by removing strokes while maintaining legibility, aiding non-native learners and font design.", "motivation": "To reduce learning barriers for non-native speakers and improve font design by simplifying complex characters without losing legibility.", "method": "Uses a character recognition model to assess and remove strokes with minimal impact on legibility.", "result": "Many characters remain distinguishable even after multiple strokes are removed, suggesting potential for formalized simplification.", "conclusion": "The framework shows promise for systematic character simplification, benefiting learners and design."}}
{"id": "2506.22449", "pdf": "https://arxiv.org/pdf/2506.22449", "abs": "https://arxiv.org/abs/2506.22449", "authors": ["Carolyn Hicks"], "title": "Computational Analysis of Climate Policy", "categories": ["cs.CY", "cs.CL"], "comment": "Master's thesis", "summary": "This thesis explores the impact of the Climate Emergency movement on local\ngovernment climate policy, using computational methods. The Climate Emergency\nmovement sought to accelerate climate action at local government level through\nthe mechanism of Climate Emergency Declarations (CEDs), resulting in a series\nof commitments from councils to treat climate change as an emergency. With the\naim of assessing the potential of current large language models to answer\ncomplex policy questions, I first built and configured a system named PALLM\n(Policy Analysis with a Large Language Model), using the OpenAI model GPT-4.\nThis system is designed to apply a conceptual framework for climate emergency\nresponse plans to a dataset of climate policy documents. I validated the\nperformance of this system with the help of local government policymakers, by\ngenerating analyses of the climate policies of 11 local governments in Victoria\nand assessing the policymakers' level of agreement with PALLM's responses.\nHaving established that PALLM's performance is satisfactory, I used it to\nconduct a large-scale analysis of current policy documents from local\ngovernments in the state of Victoria, Australia. This thesis presents the\nmethodology and results of this analysis, comparing the results for councils\nwhich have passed a CED to those which did not. This study finds that GPT-4 is\ncapable of high-level policy analysis, with limitations including a lack of\nreliable attribution, and can also enable more nuanced analysis by researchers.\nIts use in this research shows that councils which have passed a CED are more\nlikely to have a recent and climate-specific policy, and show more attention to\nurgency, prioritisation, and equity and social justice, than councils which\nhave not. It concludes that the ability to assess policy documents at scale\nopens up exciting new opportunities for policy researchers.", "AI": {"tldr": "The thesis evaluates the Climate Emergency movement's impact on local government climate policy using GPT-4-based PALLM, finding CED-adopting councils prioritize urgency and equity more.", "motivation": "Assess the potential of large language models (GPT-4) for complex policy analysis and the impact of Climate Emergency Declarations (CEDs) on local climate policies.", "method": "Developed PALLM (Policy Analysis with a Large Language Model) using GPT-4 to analyze climate policies of 11 Victorian councils, validated by policymakers, then scaled to more councils.", "result": "CED-adopting councils had more recent, climate-specific policies with greater focus on urgency, prioritization, and equity/social justice. GPT-4 showed high-level policy analysis capability but lacks reliable attribution.", "conclusion": "Large language models like GPT-4 enable scalable policy analysis, revealing CEDs' positive impact on local climate policies, though attribution remains a challenge."}}
{"id": "2506.22884", "pdf": "https://arxiv.org/pdf/2506.22884", "abs": "https://arxiv.org/abs/2506.22884", "authors": ["Praveen Kumar Donta", "Qiyang Zhang", "Schahram Dustdar"], "title": "Performance Measurements in the AI-Centric Computing Continuum Systems", "categories": ["cs.DC", "cs.AI", "cs.ET", "cs.NI", "cs.SY", "eess.SY"], "comment": null, "summary": "Over the Eight decades, computing paradigms have shifted from large,\ncentralized systems to compact, distributed architectures, leading to the rise\nof the Distributed Computing Continuum (DCC). In this model, multiple layers\nsuch as cloud, edge, Internet of Things (IoT), and mobile platforms work\ntogether to support a wide range of applications. Recently, the emergence of\nGenerative AI and large language models has further intensified the demand for\ncomputational resources across this continuum. Although traditional performance\nmetrics have provided a solid foundation, they need to be revisited and\nexpanded to keep pace with changing computational demands and application\nrequirements. Accurate performance measurements benefit both system designers\nand users by supporting improvements in efficiency and promoting alignment with\nsystem goals. In this context, we review commonly used metrics in DCC and IoT\nenvironments. We also discuss emerging performance dimensions that address\nevolving computing needs, such as sustainability, energy efficiency, and system\nobservability. We also outline criteria and considerations for selecting\nappropriate metrics, aiming to inspire future research and development in this\ncritical area.", "AI": {"tldr": "The paper reviews and expands performance metrics for the Distributed Computing Continuum (DCC) to address modern demands like Generative AI, sustainability, and energy efficiency.", "motivation": "The shift to distributed architectures and emerging technologies like Generative AI necessitates updated performance metrics to meet evolving computational and application needs.", "method": "The paper reviews existing metrics in DCC and IoT environments and introduces emerging dimensions like sustainability and observability.", "result": "It highlights the need for revised metrics to improve efficiency and align with system goals, benefiting designers and users.", "conclusion": "The study aims to guide future research by outlining criteria for selecting appropriate metrics in DCC."}}
{"id": "2506.23596", "pdf": "https://arxiv.org/pdf/2506.23596", "abs": "https://arxiv.org/abs/2506.23596", "authors": ["Min-Yeong Park", "Won-Jeong Lee", "Seong Tae Kim", "Gyeong-Moon Park"], "title": "When Will It Fail?: Anomaly to Prompt for Forecasting Future Anomalies in Time Series", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages, 10 figures, 12 tables, ICML 2025", "summary": "Recently, forecasting future abnormal events has emerged as an important\nscenario to tackle real-world necessities. However, the solution of predicting\nspecific future time points when anomalies will occur, known as Anomaly\nPrediction (AP), remains under-explored. Existing methods dealing with time\nseries data fail in AP, focusing only on immediate anomalies or failing to\nprovide precise predictions for future anomalies. To address the AP task, we\npropose a novel framework called Anomaly to Prompt (A2P), comprised of\nAnomaly-Aware Forecasting (AAF) and Synthetic Anomaly Prompting (SAP). To\nenable the forecasting model to forecast abnormal time points, we adopt a\nstrategy to learn the relationships of anomalies. For the robust detection of\nanomalies, our proposed SAP introduces a learnable Anomaly Prompt Pool (APP)\nthat simulates diverse anomaly patterns using signal adaptive prompt.\nComprehensive experiments on multiple real-world datasets demonstrate the\nsuperiority of A2P over state-of-the-art methods, showcasing its ability to\npredict future anomalies. Our implementation code is available at\nhttps://github.com/KU-VGI/AP.", "AI": {"tldr": "The paper introduces A2P, a novel framework for Anomaly Prediction (AP) in time series data, combining Anomaly-Aware Forecasting (AAF) and Synthetic Anomaly Prompting (SAP) to predict future anomalies.", "motivation": "Existing methods for time series data fail to predict future anomalies, focusing only on immediate ones or lacking precision. The paper aims to address this gap.", "method": "The A2P framework includes AAF for learning anomaly relationships and SAP with a learnable Anomaly Prompt Pool (APP) to simulate diverse anomaly patterns.", "result": "Experiments on real-world datasets show A2P outperforms state-of-the-art methods in predicting future anomalies.", "conclusion": "A2P is effective for AP, offering a robust solution for forecasting future anomalies."}}
{"id": "2506.23108", "pdf": "https://arxiv.org/pdf/2506.23108", "abs": "https://arxiv.org/abs/2506.23108", "authors": ["Zhiyuan Zhu", "Jian Wang", "Yong Jiang", "Tong Han", "Yuhao Huang", "Ang Zhang", "Kaiwen Yang", "Mingyuan Luo", "Zhe Liu", "Yaofei Duan", "Dong Ni", "Tianhong Tang", "Xin Yang"], "title": "Hierarchical Corpus-View-Category Refinement for Carotid Plaque Risk Grading in Ultrasound", "categories": ["cs.CV"], "comment": "Accepted at MICCAI 2025", "summary": "Accurate carotid plaque grading (CPG) is vital to assess the risk of\ncardiovascular and cerebrovascular diseases. Due to the small size and high\nintra-class variability of plaque, CPG is commonly evaluated using a\ncombination of transverse and longitudinal ultrasound views in clinical\npractice. However, most existing deep learning-based multi-view classification\nmethods focus on feature fusion across different views, neglecting the\nimportance of representation learning and the difference in class features. To\naddress these issues, we propose a novel Corpus-View-Category Refinement\nFramework (CVC-RF) that processes information from Corpus-, View-, and\nCategory-levels, enhancing model performance. Our contribution is four-fold.\nFirst, to the best of our knowledge, we are the foremost deep learning-based\nmethod for CPG according to the latest Carotid Plaque-RADS guidelines. Second,\nwe propose a novel center-memory contrastive loss, which enhances the network's\nglobal modeling capability by comparing with representative cluster centers and\ndiverse negative samples at the Corpus level. Third, we design a cascaded\ndown-sampling attention module to fuse multi-scale information and achieve\nimplicit feature interaction at the View level. Finally, a parameter-free\nmixture-of-experts weighting strategy is introduced to leverage class\nclustering knowledge to weight different experts, enabling feature decoupling\nat the Category level. Experimental results indicate that CVC-RF effectively\nmodels global features via multi-level refinement, achieving state-of-the-art\nperformance in the challenging CPG task.", "AI": {"tldr": "A novel Corpus-View-Category Refinement Framework (CVC-RF) is proposed for accurate carotid plaque grading (CPG), addressing feature fusion, representation learning, and class feature differences in multi-view ultrasound images.", "motivation": "Accurate CPG is crucial for assessing cardiovascular and cerebrovascular risks, but existing deep learning methods neglect representation learning and class feature differences.", "method": "CVC-RF processes information at Corpus-, View-, and Category-levels, using center-memory contrastive loss, cascaded down-sampling attention, and a mixture-of-experts weighting strategy.", "result": "CVC-RF achieves state-of-the-art performance in CPG by effectively modeling global features through multi-level refinement.", "conclusion": "The proposed framework enhances CPG accuracy by addressing key limitations in existing methods, demonstrating superior performance."}}
{"id": "2506.22481", "pdf": "https://arxiv.org/pdf/2506.22481", "abs": "https://arxiv.org/abs/2506.22481", "authors": ["Jacob Hobbs"], "title": "Theories of \"Sexuality\" in Natural Language Processing Bias Research", "categories": ["cs.CY", "cs.CL"], "comment": "17 pages, 9 tables, undergraduate senior thesis, submitted to The\n  Spectra: The Virginia Engineering and Science Research Journal", "summary": "In recent years, significant advancements in the field of Natural Language\nProcessing (NLP) have positioned commercialized language models as\nwide-reaching, highly useful tools. In tandem, there has been an explosion of\nmultidisciplinary research examining how NLP tasks reflect, perpetuate, and\namplify social biases such as gender and racial bias. A significant gap in this\nscholarship is a detailed analysis of how queer sexualities are encoded and\n(mis)represented by both NLP systems and practitioners. Following previous work\nin the field of AI fairness, we document how sexuality is defined and\noperationalized via a survey and analysis of 55 articles that quantify\nsexuality-based NLP bias. We find that sexuality is not clearly defined in a\nmajority of the literature surveyed, indicating a reliance on assumed or\nnormative conceptions of sexual/romantic practices and identities. Further, we\nfind that methods for extracting biased outputs from NLP technologies often\nconflate gender and sexual identities, leading to monolithic conceptions of\nqueerness and thus improper quantifications of bias. With the goal of improving\nsexuality-based NLP bias analyses, we conclude with recommendations that\nencourage more thorough engagement with both queer communities and\ninterdisciplinary literature.", "AI": {"tldr": "The paper highlights gaps in NLP research regarding queer sexualities, revealing unclear definitions and conflation of gender/sexual identities in bias analyses. It recommends better engagement with queer communities and interdisciplinary work.", "motivation": "To address the lack of detailed analysis of how queer sexualities are encoded and misrepresented in NLP systems and research, particularly in bias quantification.", "method": "Survey and analysis of 55 articles on sexuality-based NLP bias, focusing on definitions and operationalization of sexuality.", "result": "Sexuality is often undefined in literature, relying on normative assumptions. Gender and sexual identities are conflated, leading to flawed bias quantifications.", "conclusion": "Recommendations for improved sexuality-based NLP bias analyses include deeper engagement with queer communities and interdisciplinary literature."}}
{"id": "2506.22911", "pdf": "https://arxiv.org/pdf/2506.22911", "abs": "https://arxiv.org/abs/2506.22911", "authors": ["Yunxuan Ma", "Siqiang Wang", "Zhijian Duan", "Yukun Cheng", "Xiaotie Deng"], "title": "Learning Truthful Mechanisms without Discretization", "categories": ["cs.GT", "cs.AI", "cs.LG"], "comment": "66 pages", "summary": "This paper introduces TEDI (Truthful, Expressive, and Dimension-Insensitive\napproach), a discretization-free algorithm to learn truthful and\nutility-maximizing mechanisms. Existing learning-based approaches often rely on\ndiscretization of outcome spaces to ensure truthfulness, which leads to\ninefficiency with increasing problem size. To address this limitation, we\nformalize the concept of pricing rules, defined as functions that map outcomes\nto prices. Based on this concept, we propose a novel menu mechanism, which can\nbe equivalent to a truthful direct mechanism under specific conditions. The\ncore idea of TEDI lies in its parameterization of pricing rules using Partial\nGroupMax Network, a new network architecture designed to universally\napproximate partial convex functions. To learn optimal pricing rules, we\ndevelop novel training techniques, including covariance trick and continuous\nsampling, to derive unbiased gradient estimators compatible with first-order\noptimization. Theoretical analysis establishes that TEDI guarantees\ntruthfulness, full expressiveness, and dimension-insensitivity. Experimental\nevaluation in the studied auction setting demonstrates that TEDI achieves\nstrong performance, competitive with or exceeding state-of-the-art methods.\n  This work presents the first approaches to learn truthful mechanisms without\noutcome discretization, thereby enhancing algorithmic efficiency. The proposed\nconcepts, network architecture, and learning techniques might offer potential\nvalue and provide new insights for automated mechanism design and\ndifferentiable economics.", "AI": {"tldr": "TEDI is a discretization-free algorithm for learning truthful, utility-maximizing mechanisms, using pricing rules and a novel network architecture (Partial GroupMax Network). It ensures truthfulness, expressiveness, and dimension-insensitivity, outperforming existing methods.", "motivation": "Existing learning-based mechanisms rely on discretization, causing inefficiency with larger problem sizes. TEDI aims to overcome this by avoiding discretization while ensuring truthfulness.", "method": "TEDI formalizes pricing rules and introduces a menu mechanism. It uses Partial GroupMax Network for parameterization and novel training techniques (covariance trick, continuous sampling) for optimization.", "result": "TEDI guarantees truthfulness, expressiveness, and dimension-insensitivity, performing competitively or better than state-of-the-art methods in experiments.", "conclusion": "TEDI is the first approach to learn truthful mechanisms without discretization, improving efficiency and offering insights for automated mechanism design and differentiable economics."}}
{"id": "2506.23629", "pdf": "https://arxiv.org/pdf/2506.23629", "abs": "https://arxiv.org/abs/2506.23629", "authors": ["Xin Liao", "Bing Yang", "Cai Yu"], "title": "A Nonlinear Low-rank Representation Model with Convolutional Neural Network for Imputing Water Quality Data", "categories": ["cs.LG", "cs.AI", "68T07(Primary) 62M10, 65C60 (Secondary)", "I.2.7"], "comment": "7 pages, 2 figures, conference", "summary": "The integrity of Water Quality Data (WQD) is critical in environmental\nmonitoring for scientific decision-making and ecological protection. However,\nwater quality monitoring systems are often challenged by large amounts of\nmissing data due to unavoidable problems such as sensor failures and\ncommunication delays, which further lead to water quality data becoming\nHigh-Dimensional and Sparse (HDS). Traditional data imputation methods are\ndifficult to depict the potential dynamics and fail to capture the deep data\nfeatures, resulting in unsatisfactory imputation performance. To effectively\naddress the above issues, this paper proposes a Nonlinear Low-rank\nRepresentation model (NLR) with Convolutional Neural Networks (CNN) for\nimputing missing WQD, which utilizes CNNs to implement two ideas: a) fusing\ntemporal features to model the temporal dependence of data between time slots,\nand b) Extracting nonlinear interactions and local patterns to mine\nhigher-order relationships features and achieve deep fusion of multidimensional\ninformation. Experimental studies on three real water quality datasets\ndemonstrate that the proposed model significantly outperforms existing\nstate-of-the-art data imputation models in terms of estimation accuracy. It\nprovides an effective approach for handling water quality monitoring data in\ncomplex dynamic environments.", "AI": {"tldr": "A Nonlinear Low-rank Representation model with CNNs is proposed to impute missing Water Quality Data (WQD), outperforming existing methods in accuracy by capturing temporal and nonlinear features.", "motivation": "Missing WQD due to sensor failures and communication delays leads to High-Dimensional and Sparse data, which traditional methods fail to handle effectively.", "method": "The NLR model with CNNs fuses temporal features and extracts nonlinear interactions to achieve deep fusion of multidimensional information.", "result": "Experiments on three real datasets show the model significantly improves imputation accuracy over state-of-the-art methods.", "conclusion": "The NLR model provides an effective solution for handling missing WQD in dynamic environments."}}
{"id": "2506.23115", "pdf": "https://arxiv.org/pdf/2506.23115", "abs": "https://arxiv.org/abs/2506.23115", "authors": ["Haonan Chen", "Hong Liu", "Yuping Luo", "Liang Wang", "Nan Yang", "Furu Wei", "Zhicheng Dou"], "title": "MoCa: Modality-aware Continual Pre-training Makes Better Bidirectional Multimodal Embeddings", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Homepage: https://haon-chen.github.io/MoCa/", "summary": "Multimodal embedding models, built upon causal Vision Language Models (VLMs),\nhave shown promise in various tasks. However, current approaches face three key\nlimitations: the use of causal attention in VLM backbones is suboptimal for\nembedding tasks; scalability issues due to reliance on high-quality labeled\npaired data for contrastive learning; and limited diversity in training\nobjectives and data. To address these issues, we propose MoCa, a two-stage\nframework for transforming pre-trained VLMs into effective bidirectional\nmultimodal embedding models. The first stage, Modality-aware Continual\nPre-training, introduces a joint reconstruction objective that simultaneously\ndenoises interleaved text and image inputs, enhancing bidirectional\ncontext-aware reasoning. The second stage, Heterogeneous Contrastive\nFine-tuning, leverages diverse, semantically rich multimodal data beyond simple\nimage-caption pairs to enhance generalization and alignment. Our method\naddresses the stated limitations by introducing bidirectional attention through\ncontinual pre-training, scaling effectively with massive unlabeled datasets via\njoint reconstruction objectives, and utilizing diverse multimodal data for\nenhanced representation robustness. Experiments demonstrate that MoCa\nconsistently improves performance across MMEB and ViDoRe-v2 benchmarks,\nachieving new state-of-the-art results, and exhibits strong scalability with\nboth model size and training data on MMEB.", "AI": {"tldr": "MoCa is a two-stage framework transforming pre-trained VLMs into bidirectional multimodal embedding models, addressing limitations of current approaches through continual pre-training and diverse contrastive fine-tuning.", "motivation": "Current multimodal embedding models using causal VLMs have suboptimal attention for embedding tasks, scalability issues, and limited training diversity.", "method": "MoCa involves Modality-aware Continual Pre-training for bidirectional reasoning and Heterogeneous Contrastive Fine-tuning using diverse multimodal data.", "result": "MoCa achieves state-of-the-art results on MMEB and ViDoRe-v2 benchmarks and shows strong scalability.", "conclusion": "MoCa effectively addresses key limitations of current models, improving performance and robustness in multimodal embedding tasks."}}
{"id": "2506.22493", "pdf": "https://arxiv.org/pdf/2506.22493", "abs": "https://arxiv.org/abs/2506.22493", "authors": ["Sadia Kamal", "Lalu Prasad Yadav Prakash", "S M Rafiuddin", "Mohammed Rakib", "Arunkumar Bagavathi", "Atriya Sen", "Sagnik Ray Choudhury"], "title": "A Detailed Factor Analysis for the Political Compass Test: Navigating Ideologies of Large Language Models", "categories": ["cs.CY", "cs.CL", "cs.LG"], "comment": null, "summary": "Political Compass Test (PCT) or similar questionnaires have been used to\nquantify LLM's political leanings. Building on a recent line of work that\nexamines the validity of PCT tests, we demonstrate that variation in standard\ngeneration parameters does not significantly impact the models' PCT scores.\nHowever, external factors such as prompt variations and fine-tuning\nindividually and in combination affect the same. Finally, we demonstrate that\nwhen models are fine-tuned on text datasets with higher political content than\nothers, the PCT scores are not differentially affected. This calls for a\nthorough investigation into the validity of PCT and similar tests, as well as\nthe mechanism by which political leanings are encoded in LLMs.", "AI": {"tldr": "The study shows that standard generation parameters don't significantly affect LLM political scores (PCT), but prompt variations and fine-tuning do. Fine-tuning on politically rich datasets doesn't differentially impact scores, questioning PCT validity and LLM political encoding.", "motivation": "To investigate how external factors like prompts and fine-tuning influence LLM political leanings measured by PCT, and assess the validity of such tests.", "method": "Analyzed the impact of generation parameters, prompt variations, and fine-tuning on PCT scores, including datasets with varying political content.", "result": "Standard parameters don't affect PCT scores, but prompts and fine-tuning do. Politically rich fine-tuning doesn't differentially impact scores.", "conclusion": "PCT validity and how political leanings are encoded in LLMs need deeper investigation."}}
{"id": "2506.22941", "pdf": "https://arxiv.org/pdf/2506.22941", "abs": "https://arxiv.org/abs/2506.22941", "authors": ["Kaixuan Wang", "Jason T. Jacques", "Chenxin Diao"], "title": "Positioning AI Tools to Support Online Harm Reduction Practice: Applications and Design Directions", "categories": ["cs.HC", "cs.AI"], "comment": "16 pages, 4 figures, with appendix", "summary": "Access to accurate and actionable harm reduction information can directly\nimpact the health outcomes of People Who Use Drugs (PWUD), yet existing online\nchannels often fail to meet their diverse and dynamic needs due to limitations\nin adaptability, accessibility, and the pervasive impact of stigma. Large\nLanguage Models (LLMs) present a novel opportunity to enhance information\nprovision, but their application in such a high-stakes domain is under-explored\nand presents socio-technical challenges. This paper investigates how LLMs can\nbe responsibly designed to support the information needs of PWUD. Through a\nqualitative workshop involving diverse stakeholder groups (academics, harm\nreduction practitioners, and an online community moderator), we explored LLM\ncapabilities, identified potential use cases, and delineated core design\nconsiderations. Our findings reveal that while LLMs can address some existing\ninformation barriers (e.g., by offering responsive, multilingual, and\npotentially less stigmatising interactions), their effectiveness is contingent\nupon overcoming challenges related to ethical alignment with harm reduction\nprinciples, nuanced contextual understanding, effective communication, and\nclearly defined operational boundaries. We articulate design pathways\nemphasising collaborative co-design with experts and PWUD to develop LLM\nsystems that are helpful, safe, and responsibly governed. This work contributes\nempirically grounded insights and actionable design considerations for the\nresponsible development of LLMs as supportive tools within the harm reduction\necosystem.", "AI": {"tldr": "The paper explores how Large Language Models (LLMs) can responsibly support harm reduction information for People Who Use Drugs (PWUD), identifying use cases and design challenges.", "motivation": "Existing online channels fail to meet PWUD's diverse needs due to adaptability, accessibility, and stigma issues. LLMs offer a novel solution but are under-explored in this high-stakes context.", "method": "A qualitative workshop with stakeholders (academics, harm reduction practitioners, and a community moderator) explored LLM capabilities, use cases, and design considerations.", "result": "LLMs can address information barriers (responsive, multilingual, less stigmatizing interactions) but face challenges like ethical alignment, contextual understanding, and communication.", "conclusion": "Collaborative co-design with experts and PWUD is key to developing helpful, safe, and responsibly governed LLM systems for harm reduction."}}
{"id": "2506.23679", "pdf": "https://arxiv.org/pdf/2506.23679", "abs": "https://arxiv.org/abs/2506.23679", "authors": ["David Demitri Africa", "Sara M. Kapoor", "Theo Simon Sorg"], "title": "Learning Modular Exponentiation with Transformers", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Modular exponentiation is crucial to number theory and cryptography, yet\nremains largely unexplored from a mechanistic interpretability standpoint. We\ntrain a 4-layer encoder-decoder Transformer model to perform this operation and\ninvestigate the emergence of numerical reasoning during training. Utilizing\nprincipled sampling strategies, PCA-based embedding analysis, and activation\npatching, we examine how number-theoretic properties are encoded within the\nmodel. We find that reciprocal operand training leads to strong performance\ngains, with sudden generalization across related moduli. These synchronized\naccuracy surges reflect grokking-like dynamics, suggesting the model\ninternalizes shared arithmetic structure. We also find a subgraph consisting\nentirely of attention heads in the final layer sufficient to achieve full\nperformance on the task of regular exponentiation. These results suggest that\ntransformer models learn modular arithmetic through specialized computational\ncircuits, paving the way for more interpretable and efficient neural approaches\nto modular exponentiation.", "AI": {"tldr": "The paper explores modular exponentiation in transformers, revealing specialized computational circuits and grokking-like dynamics.", "motivation": "Modular exponentiation is vital in cryptography but lacks mechanistic interpretability. The study aims to understand how numerical reasoning emerges in transformers.", "method": "A 4-layer encoder-decoder transformer is trained, using PCA-based embedding analysis and activation patching to study number-theoretic encoding.", "result": "Reciprocal operand training boosts performance, with sudden generalization across moduli. A subgraph of attention heads in the final layer achieves full performance.", "conclusion": "Transformers learn modular arithmetic via specialized circuits, suggesting paths for more interpretable and efficient neural approaches."}}
{"id": "2506.23120", "pdf": "https://arxiv.org/pdf/2506.23120", "abs": "https://arxiv.org/abs/2506.23120", "authors": ["Zhenhua Ning", "Zhuotao Tian", "Shaoshuai Shi", "Guangming Lu", "Daojing He", "Wenjie Pei", "Li Jiang"], "title": "Enhancing Spatial Reasoning in Multimodal Large Language Models through Reasoning-based Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in point cloud perception have demonstrated remarkable\nprogress in scene understanding through vision-language alignment leveraging\nlarge language models (LLMs). However, existing methods may still encounter\nchallenges in handling complex instructions that require accurate spatial\nreasoning, even if the 3D point cloud data provides detailed spatial cues such\nas size and position for identifying the targets. To tackle this issue, we\npropose Relevant Reasoning Segmentation (R$^2$S), a reasoning-based\nsegmentation framework. The framework emulates human cognitive processes by\ndecomposing spatial reasoning into two sequential stages: first identifying\nrelevant elements, then processing instructions guided by their associated\nvisual priors. Furthermore, acknowledging the inadequacy of existing datasets\nin complex reasoning tasks, we introduce 3D ReasonSeg, a reasoning-based\nsegmentation dataset comprising 25,185 training samples and 3,966 validation\nsamples with precise annotations. Both quantitative and qualitative experiments\ndemonstrate that the R$^2$S and 3D ReasonSeg effectively endow 3D point cloud\nperception with stronger spatial reasoning capabilities, and we hope that they\ncan serve as a new baseline and benchmark for future work.", "AI": {"tldr": "The paper introduces R\u00b2S, a reasoning-based segmentation framework, and 3D ReasonSeg dataset to enhance spatial reasoning in 3D point cloud perception.", "motivation": "Existing methods struggle with complex instructions requiring accurate spatial reasoning despite detailed spatial cues in 3D point clouds.", "method": "R\u00b2S decomposes spatial reasoning into two stages: identifying relevant elements and processing instructions using visual priors. The 3D ReasonSeg dataset supports this with annotated samples.", "result": "R\u00b2S and 3D ReasonSeg improve spatial reasoning in 3D point cloud perception, validated by experiments.", "conclusion": "The framework and dataset provide a new baseline for future work in 3D point cloud perception with enhanced spatial reasoning."}}
{"id": "2506.22666", "pdf": "https://arxiv.org/pdf/2506.22666", "abs": "https://arxiv.org/abs/2506.22666", "authors": ["Anamika Lochab", "Lu Yan", "Patrick Pynadath", "Xiangyu Zhang", "Ruqi Zhang"], "title": "VERA: Variational Inference Framework for Jailbreaking Large Language Models", "categories": ["cs.CR", "cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "The rise of API-only access to state-of-the-art LLMs highlights the need for\neffective black-box jailbreak methods to identify model vulnerabilities in\nreal-world settings. Without a principled objective for gradient-based\noptimization, most existing approaches rely on genetic algorithms, which are\nlimited by their initialization and dependence on manually curated prompt\npools. Furthermore, these methods require individual optimization for each\nprompt, failing to provide a comprehensive characterization of model\nvulnerabilities. To address this gap, we introduce VERA: Variational infErence\nfRamework for jAilbreaking. VERA casts black-box jailbreak prompting as a\nvariational inference problem, training a small attacker LLM to approximate the\ntarget LLM's posterior over adversarial prompts. Once trained, the attacker can\ngenerate diverse, fluent jailbreak prompts for a target query without\nre-optimization. Experimental results show that VERA achieves strong\nperformance across a range of target LLMs, highlighting the value of\nprobabilistic inference for adversarial prompt generation.", "AI": {"tldr": "VERA, a variational inference framework, is introduced to generate diverse jailbreak prompts for LLMs without re-optimization, outperforming existing methods.", "motivation": "Existing jailbreak methods rely on genetic algorithms and manual curation, lacking efficiency and comprehensiveness in identifying model vulnerabilities.", "method": "VERA frames jailbreak prompting as a variational inference problem, training a small attacker LLM to approximate the target LLM's posterior over adversarial prompts.", "result": "VERA achieves strong performance across various target LLMs, demonstrating the effectiveness of probabilistic inference for adversarial prompt generation.", "conclusion": "VERA provides a scalable and efficient solution for identifying LLM vulnerabilities, advancing black-box jailbreak methods."}}
{"id": "2506.22949", "pdf": "https://arxiv.org/pdf/2506.22949", "abs": "https://arxiv.org/abs/2506.22949", "authors": ["Ehsan Hallaji", "Vaishnavi Shanmugam", "Roozbeh Razavi-Far", "Mehrdad Saif"], "title": "A Study on Semi-Supervised Detection of DDoS Attacks under Class Imbalance", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "Accepted for publication in IEEE CCECE 2025", "summary": "One of the most difficult challenges in cybersecurity is eliminating\nDistributed Denial of Service (DDoS) attacks. Automating this task using\nartificial intelligence is a complex process due to the inherent class\nimbalance and lack of sufficient labeled samples of real-world datasets. This\nresearch investigates the use of Semi-Supervised Learning (SSL) techniques to\nimprove DDoS attack detection when data is imbalanced and partially labeled. In\nthis process, 13 state-of-the-art SSL algorithms are evaluated for detecting\nDDoS attacks in several scenarios. We evaluate their practical efficacy and\nshortcomings, including the extent to which they work in extreme environments.\nThe results will offer insight into designing intelligent Intrusion Detection\nSystems (IDSs) that are robust against class imbalance and handle partially\nlabeled data.", "AI": {"tldr": "The paper explores Semi-Supervised Learning (SSL) techniques to enhance DDoS attack detection in imbalanced and partially labeled datasets, evaluating 13 SSL algorithms for practical efficacy.", "motivation": "Addressing the challenge of automating DDoS attack detection in cybersecurity, especially given class imbalance and lack of labeled data in real-world datasets.", "method": "Evaluates 13 state-of-the-art SSL algorithms for DDoS attack detection in various scenarios, focusing on their performance in extreme environments.", "result": "Provides insights into the effectiveness and limitations of SSL algorithms for detecting DDoS attacks under data imbalance and partial labeling.", "conclusion": "The findings contribute to designing robust Intrusion Detection Systems (IDSs) capable of handling imbalanced and partially labeled data."}}
{"id": "2506.23719", "pdf": "https://arxiv.org/pdf/2506.23719", "abs": "https://arxiv.org/abs/2506.23719", "authors": ["Alex Egg", "Martin Iglesias Goyanes", "Friso Kingma", "Andreu Mora", "Leandro von Werra", "Thomas Wolf"], "title": "DABstep: Data Agent Benchmark for Multi-step Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 5 figures", "summary": "We introduce DABstep, a novel benchmark for evaluating AI agents on realistic\nmulti-step data analysis tasks. DABstep comprises over 450 real-world\nchallenges derived from a financial analytics platform, requiring models to\ncombine code-based data processing with contextual reasoning over heterogeneous\ndocumentation. Each task demands an iterative, multi-step problem-solving\napproach, testing capabilities in data manipulation, cross-referencing multiple\nsources, and precise result reporting. The benchmark provides a factoid-style\nanswer format with automatic correctness checks for objective scoring at scale.\nWe evaluate leading LLM-based agents, revealing a substantial performance gap:\neven the best agent achieves only 14.55% accuracy on the hardest tasks. We\ndetail our benchmark's design, dataset composition, task formulation,\nevaluation protocol, report baseline results and analyze failure modes. DABstep\nis released with a public leaderboard and toolkit to accelerate research in\nautonomous data analysis.", "AI": {"tldr": "DABstep is a new benchmark for evaluating AI agents on multi-step data analysis tasks, featuring 450 real-world challenges. It tests capabilities like data manipulation and contextual reasoning, with automatic scoring. Leading LLMs perform poorly, achieving only 14.55% accuracy on hard tasks.", "motivation": "To create a realistic benchmark for evaluating AI agents on complex, multi-step data analysis tasks, addressing gaps in current evaluation methods.", "method": "DABstep includes 450 real-world tasks requiring code-based processing and contextual reasoning. It uses a factoid-style answer format with automatic correctness checks.", "result": "Leading LLM-based agents perform poorly, with the best achieving only 14.55% accuracy on the hardest tasks.", "conclusion": "DABstep provides a valuable tool for advancing research in autonomous data analysis, highlighting significant performance gaps in current AI agents."}}
{"id": "2506.23132", "pdf": "https://arxiv.org/pdf/2506.23132", "abs": "https://arxiv.org/abs/2506.23132", "authors": ["Sophie Zhou", "Shu Kong"], "title": "Dare to Plagiarize? Plagiarized Painting Recognition and Retrieval", "categories": ["cs.CV"], "comment": "to appear at AVSS'25", "summary": "Art plagiarism detection plays a crucial role in protecting artists'\ncopyrights and intellectual property, yet it remains a challenging problem in\nforensic analysis. In this paper, we address the task of recognizing\nplagiarized paintings and explaining the detected plagarisms by retrieving\nvisually similar authentic artworks. To support this study, we construct a\ndataset by collecting painting photos and synthesizing plagiarized versions\nusing generative AI, tailored to specific artists' styles. We first establish a\nbaseline approach using off-the-shelf features from the visual foundation model\nDINOv2 to retrieve the most similar images in the database and classify\nplagiarism based on a similarity threshold. Surprisingly, this non-learned\nmethod achieves a high recognition accuracy of 97.2\\% but suffers from low\nretrieval precision 29.0\\% average precision (AP). To improve retrieval\nquality, we finetune DINOv2 with a metric learning loss using positive and\nnegative sample pairs sampled in the database. The finetuned model greatly\nimproves retrieval performance by 12\\% AP over the baseline, though it\nunexpectedly results in a lower recognition accuracy (92.7\\%). We conclude with\ninsightful discussions and outline directions for future research.", "AI": {"tldr": "The paper proposes a method for detecting and explaining art plagiarism by retrieving visually similar authentic artworks, using a dataset of paintings and AI-synthesized plagiarized versions. A baseline method achieves high recognition accuracy but low retrieval precision, while a finetuned model improves retrieval but reduces accuracy.", "motivation": "To protect artists' copyrights and intellectual property by improving the detection and explanation of plagiarized paintings.", "method": "Constructs a dataset of paintings and AI-synthesized plagiarized versions. Uses DINOv2 for baseline retrieval and classification, then finetunes DINOv2 with metric learning to improve retrieval.", "result": "Baseline achieves 97.2% recognition accuracy but 29.0% AP retrieval precision. Finetuned model improves retrieval by 12% AP but reduces accuracy to 92.7%.", "conclusion": "The trade-off between retrieval precision and recognition accuracy highlights challenges, suggesting future research directions."}}
{"id": "2506.22968", "pdf": "https://arxiv.org/pdf/2506.22968", "abs": "https://arxiv.org/abs/2506.22968", "authors": ["Daniel Mwesigwa"], "title": "Against 'softmaxing' culture", "categories": ["cs.HC", "cs.AI"], "comment": "7 pages", "summary": "AI is flattening culture. Evaluations of \"culture\" are showing the myriad\nways in which large AI models are homogenizing language and culture, averaging\nout rich linguistic differences into generic expressions. I call this\nphenomenon \"softmaxing culture,\" and it is one of the fundamental challenges\nfacing AI evaluations today. Efforts to improve and strengthen evaluations of\nculture are central to the project of cultural alignment in large AI systems.\nThis position paper argues that machine learning (ML) and human-computer\ninteraction (HCI) approaches to evaluation are limited. I propose two key\nshifts. First, instead of asking \"what is culture?\" at the start of system\nevaluations, I propose beginning with the question: \"when is culture?\" Second,\nwhile I acknowledge the philosophical claim that cultural universals exist, the\nchallenge is not simply to describe them, but to situate them in relation to\ntheir particulars. Taken together, these conceptual shifts invite evaluation\napproaches that move beyond technical requirements, toward perspectives more\nresponsive to the complexities of culture.", "AI": {"tldr": "AI models homogenize culture, termed 'softmaxing culture,' challenging evaluations. The paper critiques current ML/HCI methods and proposes shifts to focus on 'when is culture?' and situating universals in particulars.", "motivation": "Address the homogenization of culture by AI models and the limitations of current evaluation methods in capturing cultural complexity.", "method": "Proposes conceptual shifts: asking 'when is culture?' and situating cultural universals in relation to particulars, moving beyond technical evaluations.", "result": "Highlights the need for evaluation approaches responsive to cultural complexities, beyond current ML/HCI limitations.", "conclusion": "Advocates for rethinking cultural evaluations in AI to better align with cultural diversity and complexity."}}
{"id": "2506.23726", "pdf": "https://arxiv.org/pdf/2506.23726", "abs": "https://arxiv.org/abs/2506.23726", "authors": ["Bartlomiej Sobieski", "Matthew Tivnan", "Yuang Wang", "Siyeop Yoon", "Pengfei Jin", "Dufan Wu", "Quanzheng Li", "Przemyslaw Biecek"], "title": "System-Embedded Diffusion Bridge Models", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "Solving inverse problems -- recovering signals from incomplete or noisy\nmeasurements -- is fundamental in science and engineering. Score-based\ngenerative models (SGMs) have recently emerged as a powerful framework for this\ntask. Two main paradigms have formed: unsupervised approaches that adapt\npretrained generative models to inverse problems, and supervised bridge methods\nthat train stochastic processes conditioned on paired clean and corrupted data.\nWhile the former typically assume knowledge of the measurement model, the\nlatter have largely overlooked this structural information. We introduce System\nembedded Diffusion Bridge Models (SDBs), a new class of supervised bridge\nmethods that explicitly embed the known linear measurement system into the\ncoefficients of a matrix-valued SDE. This principled integration yields\nconsistent improvements across diverse linear inverse problems and demonstrates\nrobust generalization under system misspecification between training and\ndeployment, offering a promising solution to real-world applications.", "AI": {"tldr": "SDBs integrate known linear measurement systems into matrix-valued SDEs, improving performance in linear inverse problems and robustness under system misspecification.", "motivation": "Address the gap in supervised bridge methods by incorporating structural information (measurement models) for better inverse problem solving.", "method": "Introduce System embedded Diffusion Bridge Models (SDBs), embedding linear measurement systems into matrix-valued SDE coefficients.", "result": "Consistent improvements in diverse linear inverse problems and robust generalization under system misspecification.", "conclusion": "SDBs offer a promising solution for real-world inverse problem applications by leveraging structural information."}}
{"id": "2506.23135", "pdf": "https://arxiv.org/pdf/2506.23135", "abs": "https://arxiv.org/abs/2506.23135", "authors": ["Yu Shang", "Xin Zhang", "Yinzhou Tang", "Lei Jin", "Chen Gao", "Wei Wu", "Yong Li"], "title": "RoboScape: Physics-informed Embodied World Model", "categories": ["cs.CV", "cs.RO"], "comment": "17 pages", "summary": "World models have become indispensable tools for embodied intelligence,\nserving as powerful simulators capable of generating realistic robotic videos\nwhile addressing critical data scarcity challenges. However, current embodied\nworld models exhibit limited physical awareness, particularly in modeling 3D\ngeometry and motion dynamics, resulting in unrealistic video generation for\ncontact-rich robotic scenarios. In this paper, we present RoboScape, a unified\nphysics-informed world model that jointly learns RGB video generation and\nphysics knowledge within an integrated framework. We introduce two key\nphysics-informed joint training tasks: temporal depth prediction that enhances\n3D geometric consistency in video rendering, and keypoint dynamics learning\nthat implicitly encodes physical properties (e.g., object shape and material\ncharacteristics) while improving complex motion modeling. Extensive experiments\ndemonstrate that RoboScape generates videos with superior visual fidelity and\nphysical plausibility across diverse robotic scenarios. We further validate its\npractical utility through downstream applications including robotic policy\ntraining with generated data and policy evaluation. Our work provides new\ninsights for building efficient physics-informed world models to advance\nembodied intelligence research. The code is available at:\nhttps://github.com/tsinghua-fib-lab/RoboScape.", "AI": {"tldr": "RoboScape is a physics-informed world model for realistic robotic video generation, addressing 3D geometry and motion dynamics limitations.", "motivation": "Current embodied world models lack physical awareness, leading to unrealistic videos in contact-rich robotic scenarios.", "method": "RoboScape integrates RGB video generation with physics knowledge through temporal depth prediction and keypoint dynamics learning.", "result": "RoboScape produces videos with high visual fidelity and physical plausibility, validated in robotic policy training and evaluation.", "conclusion": "RoboScape advances embodied intelligence by efficiently integrating physics into world models."}}
{"id": "2506.23219", "pdf": "https://arxiv.org/pdf/2506.23219", "abs": "https://arxiv.org/abs/2506.23219", "authors": ["Jie Feng", "Shengyuan Wang", "Tianhui Liu", "Yanxin Xi", "Yong Li"], "title": "UrbanLLaVA: A Multi-modal Large Language Model for Urban Intelligence with Spatial Reasoning and Understanding", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted by ICCV 2025", "summary": "Urban research involves a wide range of scenarios and tasks that require the\nunderstanding of multi-modal data. Current methods often focus on specific data\ntypes and lack a unified framework in urban field for processing them\ncomprehensively. The recent success of multi-modal large language models\n(MLLMs) presents a promising opportunity to overcome this limitation. In this\npaper, we introduce $\\textit{UrbanLLaVA}$, a multi-modal large language model\ndesigned to process these four types of data simultaneously and achieve strong\nperformance across diverse urban tasks compared with general MLLMs. In\n$\\textit{UrbanLLaVA}$, we first curate a diverse urban instruction dataset\nencompassing both single-modal and cross-modal urban data, spanning from\nlocation view to global view of urban environment. Additionally, we propose a\nmulti-stage training framework that decouples spatial reasoning enhancement\nfrom domain knowledge learning, thereby improving the compatibility and\ndownstream performance of $\\textit{UrbanLLaVA}$ across diverse urban tasks.\nFinally, we also extend existing benchmark for urban research to assess the\nperformance of MLLMs across a wide range of urban tasks. Experimental results\nfrom three cities demonstrate that $\\textit{UrbanLLaVA}$ outperforms\nopen-source and proprietary MLLMs in both single-modal tasks and complex\ncross-modal tasks and shows robust generalization abilities across cities.\nSource codes and data are openly accessible to the research community via\nhttps://github.com/tsinghua-fib-lab/UrbanLLaVA.", "AI": {"tldr": "UrbanLLaVA is a multi-modal large language model designed for urban research, outperforming general MLLMs by processing diverse urban data types and tasks through a curated dataset and multi-stage training.", "motivation": "Current urban research methods lack a unified framework for multi-modal data, prompting the development of UrbanLLaVA to address this gap.", "method": "UrbanLLaVA uses a curated urban instruction dataset and a multi-stage training framework to enhance spatial reasoning and domain knowledge learning.", "result": "UrbanLLaVA outperforms open-source and proprietary MLLMs in single-modal and cross-modal tasks across three cities.", "conclusion": "UrbanLLaVA offers a robust solution for urban research, demonstrating strong performance and generalization, with open access to code and data."}}
{"id": "2506.23014", "pdf": "https://arxiv.org/pdf/2506.23014", "abs": "https://arxiv.org/abs/2506.23014", "authors": ["Wilder Baldwin", "Shashank Chintakuntla", "Shreyah Parajuli", "Ali Pourghasemi", "Ryan Shanz", "Sepideh Ghanavati"], "title": "Generating Privacy Stories From Software Documentation", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted to RENext!'25 at the 33rd IEEE International Requirements\n  Engineering 2025 conference", "summary": "Research shows that analysts and developers consider privacy as a security\nconcept or as an afterthought, which may lead to non-compliance and violation\nof users' privacy. Most current approaches, however, focus on extracting legal\nrequirements from the regulations and evaluating the compliance of software and\nprocesses with them. In this paper, we develop a novel approach based on\nchain-of-thought prompting (CoT), in-context-learning (ICL), and Large Language\nModels (LLMs) to extract privacy behaviors from various software documents\nprior to and during software development, and then generate privacy\nrequirements in the format of user stories. Our results show that most commonly\nused LLMs, such as GPT-4o and Llama 3, can identify privacy behaviors and\ngenerate privacy user stories with F1 scores exceeding 0.8. We also show that\nthe performance of these models could be improved through parameter-tuning. Our\nfindings provide insight into using and optimizing LLMs for generating privacy\nrequirements given software documents created prior to or throughout the\nsoftware development lifecycle.", "AI": {"tldr": "The paper introduces a novel approach using CoT, ICL, and LLMs to extract privacy behaviors from software documents and generate privacy requirements as user stories, achieving high accuracy with models like GPT-4o and Llama 3.", "motivation": "Privacy is often treated as an afterthought in software development, leading to non-compliance. Current methods focus on legal requirements, but this paper aims to proactively address privacy during development.", "method": "The approach combines chain-of-thought prompting (CoT), in-context-learning (ICL), and LLMs to extract privacy behaviors and generate privacy user stories from software documents.", "result": "LLMs like GPT-4o and Llama 3 achieved F1 scores over 0.8 in identifying privacy behaviors and generating user stories, with further improvements possible through parameter-tuning.", "conclusion": "The study demonstrates the potential of LLMs for generating privacy requirements early in software development, offering insights for optimization and practical application."}}
{"id": "2506.23731", "pdf": "https://arxiv.org/pdf/2506.23731", "abs": "https://arxiv.org/abs/2506.23731", "authors": ["Michel Meintz", "Jan Dubi\u0144ski", "Franziska Boenisch", "Adam Dziedzic"], "title": "Radioactive Watermarks in Diffusion and Autoregressive Image Generative Models", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Image generative models have become increasingly popular, but training them\nrequires large datasets that are costly to collect and curate. To circumvent\nthese costs, some parties may exploit existing models by using the generated\nimages as training data for their own models. In general, watermarking is a\nvaluable tool for detecting unauthorized use of generated images. However, when\nthese images are used to train a new model, watermarking can only enable\ndetection if the watermark persists through training and remains identifiable\nin the outputs of the newly trained model - a property known as radioactivity.\nWe analyze the radioactivity of watermarks in images generated by diffusion\nmodels (DMs) and image autoregressive models (IARs). We find that existing\nwatermarking methods for DMs fail to retain radioactivity, as watermarks are\neither erased during encoding into the latent space or lost in the\nnoising-denoising process (during the training in the latent space). Meanwhile,\ndespite IARs having recently surpassed DMs in image generation quality and\nefficiency, no radioactive watermarking methods have been proposed for them. To\novercome this limitation, we propose the first watermarking method tailored for\nIARs and with radioactivity in mind - drawing inspiration from techniques in\nlarge language models (LLMs), which share IARs' autoregressive paradigm. Our\nextensive experimental evaluation highlights our method's effectiveness in\npreserving radioactivity within IARs, enabling robust provenance tracking, and\npreventing unauthorized use of their generated images.", "AI": {"tldr": "The paper addresses the challenge of watermarking in generative models, focusing on diffusion and autoregressive models, and proposes a new radioactive watermarking method for autoregressive models.", "motivation": "To prevent unauthorized use of generated images by ensuring watermarks persist through model training (radioactivity), especially in autoregressive models lacking such methods.", "method": "Analyzes watermark radioactivity in diffusion and autoregressive models, then proposes a novel watermarking method for autoregressive models inspired by techniques in large language models.", "result": "Existing watermarking for diffusion models fails to retain radioactivity, while the proposed method effectively preserves it in autoregressive models.", "conclusion": "The new watermarking method enables robust provenance tracking and prevents misuse of autoregressive model-generated images."}}
{"id": "2506.23138", "pdf": "https://arxiv.org/pdf/2506.23138", "abs": "https://arxiv.org/abs/2506.23138", "authors": ["Shiyu Wu", "Mingzhen Sun", "Weining Wang", "Yequan Wang", "Jing Liu"], "title": "VisualPrompter: Prompt Optimization with Visual Feedback for Text-to-Image Synthesis", "categories": ["cs.CV"], "comment": "12 pages, 5 figures", "summary": "Since there exists a notable gap between user-provided and model-preferred\nprompts, generating high-quality and satisfactory images using diffusion models\noften requires prompt engineering to optimize user inputs. Current studies on\ntext-to-image prompt engineering can effectively enhance the style and\naesthetics of generated images. However, they often neglect the semantic\nalignment between generated images and user descriptions, resulting in visually\nappealing but content-wise unsatisfying outputs. In this work, we propose\nVisualPrompter, a novel training-free prompt engineering framework that refines\nuser inputs to model-preferred sentences. In particular, VisualPrompter\nutilizes an automatic self-reflection module to identify the missing concepts\nin generated images and a target-specific prompt optimization mechanism to\nrevise the prompts in a fine-grained manner. Extensive experiments demonstrate\nthe effectiveness of our VisualPrompter, which achieves new state-of-the-art\nperformance on multiple benchmarks for text-image alignment evaluation.\nAdditionally, our framework features a plug-and-play design, making it highly\nadaptable to various generative models.", "AI": {"tldr": "VisualPrompter is a training-free prompt engineering framework that refines user inputs for diffusion models, improving text-image alignment without compromising aesthetics.", "motivation": "Address the gap between user-provided and model-preferred prompts, ensuring semantic alignment in generated images.", "method": "Uses an automatic self-reflection module to identify missing concepts and a target-specific prompt optimization mechanism.", "result": "Achieves state-of-the-art performance on text-image alignment benchmarks and is adaptable to various models.", "conclusion": "VisualPrompter effectively bridges the gap between user intent and model output, enhancing both alignment and aesthetics."}}
{"id": "2506.23322", "pdf": "https://arxiv.org/pdf/2506.23322", "abs": "https://arxiv.org/abs/2506.23322", "authors": ["Wei Zhou", "Ji Sun", "Xuanhe Zhou", "Guoliang Li", "Luyang Liu", "Hao Wu", "Tianyuan Wang"], "title": "GaussMaster: An LLM-based Database Copilot System", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.IR"], "comment": "We welcome contributions from the community. For reference, please\n  see the code at: https://gitcode.com/opengauss/openGauss-GaussMaster", "summary": "In the financial industry, data is the lifeblood of operations, and DBAs\nshoulder significant responsibilities for SQL tuning, database deployment,\ndiagnosis, and service repair. In recent years, both database vendors and\ncustomers have increasingly turned to autonomous database platforms in an\neffort to alleviate the heavy workload of DBAs. However, existing autonomous\ndatabase platforms are limited in their capabilities, primarily addressing\nsingle-point issues such as NL2SQL, anomaly detection, and SQL tuning. Manual\nintervention remains a necessity for comprehensive database maintenance.\nGaussMaster aims to revolutionize this landscape by introducing an LLM-based\ndatabase copilot system. This innovative solution is designed not only to\nassist developers in writing efficient SQL queries but also to provide\ncomprehensive care for database services. When database instances exhibit\nabnormal behavior, GaussMaster is capable of orchestrating the entire\nmaintenance process automatically. It achieves this by analyzing hundreds of\nmetrics and logs, employing a Tree-of-thought approach to identify root causes,\nand invoking appropriate tools to resolve issues. We have successfully\nimplemented GaussMaster in real-world scenarios, such as the banking industry,\nwhere it has achieved zero human intervention for over 34 database maintenance\nscenarios. In this paper, we present significant improvements in these tasks\nwith code at https://gitcode.com/opengauss/openGauss-GaussMaster.", "AI": {"tldr": "GaussMaster is an LLM-based database copilot system designed to automate comprehensive database maintenance, reducing human intervention in tasks like SQL tuning and anomaly detection.", "motivation": "The heavy workload of DBAs and the limitations of existing autonomous database platforms in addressing comprehensive maintenance tasks motivate the development of GaussMaster.", "method": "GaussMaster uses an LLM-based approach, analyzing metrics and logs with a Tree-of-thought technique to identify root causes and resolve issues automatically.", "result": "Implemented in real-world scenarios like banking, GaussMaster achieved zero human intervention in over 34 database maintenance tasks.", "conclusion": "GaussMaster demonstrates significant improvements in automating database maintenance, offering a scalable solution for reducing DBA workload."}}
{"id": "2506.23023", "pdf": "https://arxiv.org/pdf/2506.23023", "abs": "https://arxiv.org/abs/2506.23023", "authors": ["M. Youssef Abdelhamid", "Lennart Vater", "Zlatan Ajanovic"], "title": "Scenario-Based Hierarchical Reinforcement Learning for Automated Driving Decision Making", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "6 pages, 10 figures, submitted to a conference", "summary": "Developing decision-making algorithms for highly automated driving systems\nremains challenging, since these systems have to operate safely in an open and\ncomplex environments. Reinforcement Learning (RL) approaches can learn\ncomprehensive decision policies directly from experience and already show\npromising results in simple driving tasks. However, current approaches fail to\nachieve generalizability for more complex driving tasks and lack learning\nefficiency. Therefore, we present Scenario-based Automated Driving\nReinforcement Learning (SAD-RL), the first framework that integrates\nReinforcement Learning (RL) of hierarchical policy in a scenario-based\nenvironment. A high-level policy selects maneuver templates that are evaluated\nand executed by a low-level control logic. The scenario-based environment\nallows to control the training experience for the agent and to explicitly\nintroduce challenging, but rate situations into the training process. Our\nexperiments show that an agent trained using the SAD-RL framework can achieve\nsafe behaviour in easy as well as challenging situations efficiently. Our\nablation studies confirmed that both HRL and scenario diversity are essential\nfor achieving these results.", "AI": {"tldr": "SAD-RL integrates hierarchical RL in scenario-based environments to improve decision-making for automated driving, achieving safe and efficient behavior in diverse situations.", "motivation": "Developing safe and generalizable decision-making algorithms for complex driving environments is challenging. Current RL approaches lack efficiency and generalizability.", "method": "SAD-RL uses hierarchical RL (high-level policy for maneuver selection, low-level control for execution) in a scenario-based environment to control training and introduce challenging situations.", "result": "Agents trained with SAD-RL exhibit safe behavior in both easy and challenging situations efficiently. Ablation studies confirm the importance of hierarchical RL and scenario diversity.", "conclusion": "SAD-RL effectively addresses the limitations of current RL approaches, demonstrating improved safety and efficiency in automated driving."}}
{"id": "2506.23757", "pdf": "https://arxiv.org/pdf/2506.23757", "abs": "https://arxiv.org/abs/2506.23757", "authors": ["Dan Yao", "Steve McLaughlin", "Yoann Altmann"], "title": "Training of Spiking Neural Networks with Expectation-Propagation", "categories": ["cs.LG", "stat.ME", "stat.ML"], "comment": "10 pages", "summary": "In this paper, we propose a unifying message-passing framework for training\nspiking neural networks (SNNs) using Expectation-Propagation. Our gradient-free\nmethod is capable of learning the marginal distributions of network parameters\nand simultaneously marginalizes nuisance parameters, such as the outputs of\nhidden layers. This framework allows for the first time, training of discrete\nand continuous weights, for deterministic and stochastic spiking networks,\nusing batches of training samples. Although its convergence is not ensured, the\nalgorithm converges in practice faster than gradient-based methods, without\nrequiring a large number of passes through the training data. The\nclassification and regression results presented pave the way for new efficient\ntraining methods for deep Bayesian networks.", "AI": {"tldr": "A gradient-free framework for training SNNs using Expectation-Propagation, handling discrete/continuous weights and marginalizing nuisance parameters, with faster convergence than gradient-based methods.", "motivation": "To unify training methods for SNNs, enabling efficient learning of parameter distributions without gradients.", "method": "Expectation-Propagation for gradient-free training, marginalizing nuisance parameters and handling diverse weight types.", "result": "Faster convergence in practice, applicable to classification and regression tasks.", "conclusion": "Paves the way for efficient deep Bayesian network training methods."}}
{"id": "2506.23150", "pdf": "https://arxiv.org/pdf/2506.23150", "abs": "https://arxiv.org/abs/2506.23150", "authors": ["Xinyue Liang", "Zhiyuan Ma", "Lingchen Sun", "Yanjun Guo", "Lei Zhang"], "title": "AlignCVC: Aligning Cross-View Consistency for Single-Image-to-3D Generation", "categories": ["cs.CV"], "comment": null, "summary": "Single-image-to-3D models typically follow a sequential generation and\nreconstruction workflow. However, intermediate multi-view images synthesized by\npre-trained generation models often lack cross-view consistency (CVC),\nsignificantly degrading 3D reconstruction performance. While recent methods\nattempt to refine CVC by feeding reconstruction results back into the\nmulti-view generator, these approaches struggle with noisy and unstable\nreconstruction outputs that limit effective CVC improvement. We introduce\nAlignCVC, a novel framework that fundamentally re-frames single-image-to-3D\ngeneration through distribution alignment rather than relying on strict\nregression losses. Our key insight is to align both generated and reconstructed\nmulti-view distributions toward the ground-truth multi-view distribution,\nestablishing a principled foundation for improved CVC. Observing that generated\nimages exhibit weak CVC while reconstructed images display strong CVC due to\nexplicit rendering, we propose a soft-hard alignment strategy with distinct\nobjectives for generation and reconstruction models. This approach not only\nenhances generation quality but also dramatically accelerates inference to as\nfew as 4 steps. As a plug-and-play paradigm, our method, namely AlignCVC,\nseamlessly integrates various multi-view generation models with 3D\nreconstruction models. Extensive experiments demonstrate the effectiveness and\nefficiency of AlignCVC for single-image-to-3D generation.", "AI": {"tldr": "AlignCVC introduces a distribution alignment framework for single-image-to-3D generation, improving cross-view consistency (CVC) and accelerating inference.", "motivation": "Existing methods struggle with noisy and unstable reconstruction outputs, limiting CVC improvement in single-image-to-3D workflows.", "method": "AlignCVC aligns generated and reconstructed multi-view distributions with ground-truth, using a soft-hard alignment strategy for generation and reconstruction models.", "result": "The method enhances generation quality, achieves strong CVC, and speeds up inference to as few as 4 steps.", "conclusion": "AlignCVC is an effective, efficient, and plug-and-play solution for single-image-to-3D generation."}}
{"id": "2506.23366", "pdf": "https://arxiv.org/pdf/2506.23366", "abs": "https://arxiv.org/abs/2506.23366", "authors": ["Nathaniel Imel", "Zachary Hafen"], "title": "Density, asymmetry and citation dynamics in scientific literature", "categories": ["cs.DL", "cs.CL", "cs.SI"], "comment": null, "summary": "Scientific behavior is often characterized by a tension between building upon\nestablished knowledge and introducing novel ideas. Here, we investigate whether\nthis tension is reflected in the relationship between the similarity of a\nscientific paper to previous research and its eventual citation rate. To\noperationalize similarity to previous research, we introduce two complementary\nmetrics to characterize the local geometry of a publication's semantic\nneighborhood: (1) \\emph{density} ($\\rho$), defined as the ratio between a fixed\nnumber of previously-published papers and the minimum distance enclosing those\npapers in a semantic embedding space, and (2) asymmetry ($\\alpha$), defined as\nthe average directional difference between a paper and its nearest neighbors.\nWe tested the predictive relationship between these two metrics and its\nsubsequent citation rate using a Bayesian hierarchical regression approach,\nsurveying $\\sim 53,000$ publications across nine academic disciplines and five\ndifferent document embeddings. While the individual effects of $\\rho$ on\ncitation count are small and variable, incorporating density-based predictors\nconsistently improves out-of-sample prediction when added to baseline models.\nThese results suggest that the density of a paper's surrounding scientific\nliterature may carry modest but informative signals about its eventual impact.\nMeanwhile, we find no evidence that publication asymmetry improves model\npredictions of citation rates. Our work provides a scalable framework for\nlinking document embeddings to scientometric outcomes and highlights new\nquestions regarding the role that semantic similarity plays in shaping the\ndynamics of scientific reward.", "AI": {"tldr": "The paper explores how the similarity of a scientific paper to prior research affects its citation rate, using density and asymmetry metrics in semantic space. Density modestly improves citation prediction, while asymmetry does not.", "motivation": "To understand the tension between building on established knowledge and introducing novelty, and how this impacts scientific impact (citation rates).", "method": "Introduced two metrics (density and asymmetry) in semantic space, applied Bayesian hierarchical regression on ~53,000 papers across disciplines and embeddings.", "result": "Density modestly improves citation prediction; asymmetry has no effect.", "conclusion": "Density in semantic space offers modest predictive value for citation impact, while asymmetry does not. The framework links embeddings to scientometrics."}}
{"id": "2506.23040", "pdf": "https://arxiv.org/pdf/2506.23040", "abs": "https://arxiv.org/abs/2506.23040", "authors": ["Samuel J. Weisenthal"], "title": "Treatment, evidence, imitation, and chat", "categories": ["stat.OT", "cs.AI"], "comment": "12 pages", "summary": "Large language models are thought to have potential to aid in medical\ndecision making. We investigate this here. We start with the treatment problem,\nthe patient's core medical decision-making task, which is solved in\ncollaboration with a healthcare provider. We discuss approaches to solving the\ntreatment problem, including -- within evidence-based medicine -- trials and\nobservational data. We then discuss the chat problem, and how this differs from\nthe treatment problem -- in particular as it relates to imitation. We then\ndiscuss how a large language model might be used to solve the treatment problem\nand highlight some of the challenges that emerge. We finally discuss how these\nchallenges relate to evidence-based medicine, and how this might inform next\nsteps.", "AI": {"tldr": "The paper explores the potential of large language models (LLMs) in aiding medical decision-making, focusing on the treatment problem and the chat problem, while addressing challenges and implications for evidence-based medicine.", "motivation": "To investigate how LLMs can assist in medical decision-making, particularly in solving the treatment problem and understanding the chat problem's nuances.", "method": "The study discusses approaches to the treatment problem (e.g., trials, observational data) and contrasts it with the chat problem, analyzing how LLMs might address these and the challenges involved.", "result": "LLMs show promise for medical decision-making but face challenges in accuracy, reliability, and alignment with evidence-based medicine.", "conclusion": "Further research is needed to address these challenges and integrate LLMs effectively into medical decision-making, guided by evidence-based principles."}}
{"id": "2506.23776", "pdf": "https://arxiv.org/pdf/2506.23776", "abs": "https://arxiv.org/abs/2506.23776", "authors": ["Jari Peeperkorn", "Johannes De Smedt", "Jochen De Weerdt"], "title": "Model-driven Stochastic Trace Clustering", "categories": ["cs.LG"], "comment": null, "summary": "Process discovery algorithms automatically extract process models from event\nlogs, but high variability often results in complex and hard-to-understand\nmodels. To mitigate this issue, trace clustering techniques group process\nexecutions into clusters, each represented by a simpler and more understandable\nprocess model. Model-driven trace clustering improves on this by assigning\ntraces to clusters based on their conformity to cluster-specific process\nmodels. However, most existing clustering techniques rely on either no process\nmodel discovery, or non-stochastic models, neglecting the frequency or\nprobability of activities and transitions, thereby limiting their capability to\ncapture real-world execution dynamics. We propose a novel model-driven trace\nclustering method that optimizes stochastic process models within each cluster.\nOur approach uses entropic relevance, a stochastic conformance metric based on\ndirectly-follows probabilities, to guide trace assignment. This allows\nclustering decisions to consider both structural alignment with a cluster's\nprocess model and the likelihood that a trace originates from a given\nstochastic process model. The method is computationally efficient, scales\nlinearly with input size, and improves model interpretability by producing\nclusters with clearer control-flow patterns. Extensive experiments on public\nreal-life datasets show that our method outperforms existing alternatives in\nrepresenting process behavior and reveals how clustering performance rankings\ncan shift when stochasticity is considered.", "AI": {"tldr": "A novel model-driven trace clustering method optimizes stochastic process models using entropic relevance, improving interpretability and outperforming existing techniques.", "motivation": "High variability in process models leads to complexity; existing clustering methods neglect stochasticity, limiting their ability to capture real-world dynamics.", "method": "Uses entropic relevance, a stochastic conformance metric based on directly-follows probabilities, to guide trace assignment and optimize stochastic models.", "result": "Computationally efficient, scales linearly, and improves interpretability with clearer control-flow patterns; outperforms alternatives in representing process behavior.", "conclusion": "The method effectively addresses limitations of existing techniques by incorporating stochasticity, enhancing both performance and interpretability."}}
{"id": "2506.23153", "pdf": "https://arxiv.org/pdf/2506.23153", "abs": "https://arxiv.org/abs/2506.23153", "authors": ["Huiqiang Sun", "Xingyi Li", "Juewen Peng", "Liao Shen", "Zhiguo Cao", "Ke Xian", "Guosheng Lin"], "title": "Dynamic View Synthesis from Small Camera Motion Videos", "categories": ["cs.CV"], "comment": "Accepted by TVCG", "summary": "Novel view synthesis for dynamic $3$D scenes poses a significant challenge.\nMany notable efforts use NeRF-based approaches to address this task and yield\nimpressive results. However, these methods rely heavily on sufficient motion\nparallax in the input images or videos. When the camera motion range becomes\nlimited or even stationary (i.e., small camera motion), existing methods\nencounter two primary challenges: incorrect representation of scene geometry\nand inaccurate estimation of camera parameters. These challenges make prior\nmethods struggle to produce satisfactory results or even become invalid. To\naddress the first challenge, we propose a novel Distribution-based Depth\nRegularization (DDR) that ensures the rendering weight distribution to align\nwith the true distribution. Specifically, unlike previous methods that use\ndepth loss to calculate the error of the expectation, we calculate the\nexpectation of the error by using Gumbel-softmax to differentiably sample\npoints from discrete rendering weight distribution. Additionally, we introduce\nconstraints that enforce the volume density of spatial points before the object\nboundary along the ray to be near zero, ensuring that our model learns the\ncorrect geometry of the scene. To demystify the DDR, we further propose a\nvisualization tool that enables observing the scene geometry representation at\nthe rendering weight level. For the second challenge, we incorporate camera\nparameter learning during training to enhance the robustness of our model to\ncamera parameters. We conduct extensive experiments to demonstrate the\neffectiveness of our approach in representing scenes with small camera motion\ninput, and our results compare favorably to state-of-the-art methods.", "AI": {"tldr": "The paper addresses challenges in novel view synthesis for dynamic 3D scenes with small camera motion by proposing Distribution-based Depth Regularization (DDR) and camera parameter learning.", "motivation": "Existing NeRF-based methods struggle with limited camera motion, leading to incorrect scene geometry and inaccurate camera parameter estimation.", "method": "Introduces DDR to align rendering weight distribution with true distribution using Gumbel-softmax and enforces volume density constraints. Also learns camera parameters during training.", "result": "The approach effectively handles small camera motion inputs, outperforming state-of-the-art methods.", "conclusion": "The proposed DDR and camera parameter learning improve scene representation and robustness for dynamic 3D scenes with limited camera motion."}}
{"id": "2506.23394", "pdf": "https://arxiv.org/pdf/2506.23394", "abs": "https://arxiv.org/abs/2506.23394", "authors": ["Simeon Emanuilov"], "title": "Teaching a Language Model to Speak the Language of Tools", "categories": ["cs.IR", "cs.AI", "cs.CL", "I.2.7; I.2.1"], "comment": null, "summary": "External tool integration through function-calling is essential for practical\nlanguage model applications, yet most multilingual models lack reliable\ntool-use capabilities in non-English languages. Even state-of-the-art\nmultilingual models struggle with determining when to use tools and generating\nthe structured outputs required for function calls, often exhibiting language\nconfusion when prompted in lower-resource languages. This work presents a\nmethodology for adapting existing language models to enable robust tool use in\nany target language, using Bulgarian as a case study. The approach involves\ncontinued training of the BgGPT model series (2.6B, 9B, 27B parameters) on a\nnovel bilingual dataset of 10,035 function-calling examples designed to support\nstandardized protocols like MCP (Model Context Protocol). The research\nintroduces TUCAN (Tool-Using Capable Assistant Navigator), which achieves up to\n28.75% improvement in function-calling accuracy over base models while\npreserving core language understanding, as verified on established Bulgarian\nbenchmarks. Beyond accuracy gains, TUCAN models demonstrate production-ready\nresponse formatting with clean, parsable function calls, contrasting with the\nverbose and inconsistent outputs of base models. The models, evaluation\nframework, and dataset are released to enable replication for other languages.\nThis work demonstrates a practical approach for extending tool-augmented\ncapabilities beyond English-centric systems.", "AI": {"tldr": "The paper introduces TUCAN, a method to adapt multilingual models for robust tool use in non-English languages, using Bulgarian as a case study. It improves function-calling accuracy by 28.75% while maintaining language understanding.", "motivation": "Most multilingual models lack reliable tool-use capabilities in non-English languages, especially lower-resource ones, leading to language confusion and inconsistent outputs.", "method": "Continued training of BgGPT models on a bilingual dataset of 10,035 function-calling examples, supporting protocols like MCP.", "result": "TUCAN achieves a 28.75% improvement in function-calling accuracy and produces clean, parsable outputs.", "conclusion": "The work provides a practical approach to extend tool-augmented capabilities beyond English, with released models, framework, and dataset for replication."}}
{"id": "2506.23085", "pdf": "https://arxiv.org/pdf/2506.23085", "abs": "https://arxiv.org/abs/2506.23085", "authors": ["Saeid Aghasoleymani Najafabadi"], "title": "Enhancing Live Broadcast Engagement: A Multi-modal Approach to Short Video Recommendations Using MMGCN and User Preferences", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "The purpose of this paper is to explore a multi-modal approach to enhancing\nlive broadcast engagement by developing a short video recommendation system\nthat incorporates Multi-modal Graph Convolutional Networks (MMGCN) with user\npreferences. In order to provide personalized recommendations tailored to\nindividual interests, the proposed system takes into account user interaction\ndata, video content features, and contextual information. With the aid of a\nhybrid approach combining collaborative filtering and content-based filtering\ntechniques, the system is able to capture nuanced relationships between users,\nvideo attributes, and engagement patterns. Three datasets are used to evaluate\nthe effectiveness of the system: Kwai, TikTok, and MovieLens. Compared to\nbaseline models, such as DeepFM, Wide & Deep, LightGBM, and XGBoost, the\nproposed MMGCN-based model shows superior performance. A notable feature of the\nproposed model is that it outperforms all baseline methods in capturing diverse\nuser preferences and making accurate, personalized recommendations, resulting\nin a Kwai F1 score of 0.574, a Tiktok F1 score of 0.506, and a MovieLens F1\nscore of 0.197. We emphasize the importance of multi-modal integration and\nuser-centric approaches in advancing recommender systems, emphasizing the role\nthey play in enhancing content discovery and audience interaction on live\nbroadcast platforms.", "AI": {"tldr": "The paper proposes a multi-modal short video recommendation system using MMGCN, outperforming baseline models in personalized recommendations.", "motivation": "To enhance live broadcast engagement by integrating multi-modal data and user preferences for better recommendations.", "method": "Uses MMGCN with hybrid collaborative and content-based filtering, leveraging user interaction, video content, and contextual data.", "result": "Outperforms DeepFM, Wide & Deep, LightGBM, and XGBoost with F1 scores of 0.574 (Kwai), 0.506 (TikTok), and 0.197 (MovieLens).", "conclusion": "Multi-modal integration and user-centric approaches significantly improve recommender systems for live broadcast platforms."}}
{"id": "2506.23782", "pdf": "https://arxiv.org/pdf/2506.23782", "abs": "https://arxiv.org/abs/2506.23782", "authors": ["Xiaoyang Li", "Linwei Tao", "Haohui Lu", "Minjing Dong", "Junbin Gao", "Chang Xu"], "title": "Calibrating Graph Neural Networks with Wavelet-Aware Temperature Scaling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) have demonstrated strong predictive performance\non relational data; however, their confidence estimates often misalign with\nactual predictive correctness, posing significant limitations for deployment in\nsafety-critical settings. While existing graph-aware calibration methods seek\nto mitigate this limitation, they primarily depend on coarse one-hop\nstatistics, such as neighbor-predicted confidence, or latent node embeddings,\nthereby neglecting the fine-grained structural heterogeneity inherent in graph\ntopology. In this work, we propose Wavelet-Aware Temperature Scaling (WATS), a\npost-hoc calibration framework that assigns node-specific temperatures based on\ntunable heat-kernel graph wavelet features. Specifically, WATS harnesses the\nscalability and topology sensitivity of graph wavelets to refine confidence\nestimates, all without necessitating model retraining or access to neighboring\nlogits or predictions. Extensive evaluations across seven benchmark datasets\nwith varying graph structures and two GNN backbones demonstrate that WATS\nachieves the lowest Expected Calibration Error (ECE) among all compared\nmethods, outperforming both classical and graph-specific baselines by up to\n42.3\\% in ECE and reducing calibration variance by 17.24\\% on average compared\nwith graph-specific methods. Moreover, WATS remains computationally efficient,\nscaling well across graphs of diverse sizes and densities. Code will be\nreleased based on publication.", "AI": {"tldr": "WATS is a post-hoc calibration framework for GNNs that uses graph wavelet features to improve confidence estimates, outperforming existing methods in calibration error and variance.", "motivation": "GNNs often misalign confidence estimates with actual correctness, limiting their use in safety-critical applications. Existing methods rely on coarse statistics, ignoring fine-grained graph topology.", "method": "WATS assigns node-specific temperatures using heat-kernel graph wavelet features, refining confidence without retraining or neighbor data.", "result": "WATS achieves the lowest ECE, outperforming baselines by up to 42.3% and reducing calibration variance by 17.24%. It scales efficiently across diverse graphs.", "conclusion": "WATS effectively addresses GNN calibration limitations, offering improved accuracy and scalability for safety-critical deployments."}}
{"id": "2506.23156", "pdf": "https://arxiv.org/pdf/2506.23156", "abs": "https://arxiv.org/abs/2506.23156", "authors": ["Jiale Chen"], "title": "Self-Supervised Contrastive Learning for Multi-Label Images", "categories": ["cs.CV"], "comment": null, "summary": "Self-supervised learning (SSL) has demonstrated its effectiveness in learning\nrepresentations through comparison methods that align with human intuition.\nHowever, mainstream SSL methods heavily rely on high body datasets with single\nlabel, such as ImageNet, resulting in intolerable pre-training overhead.\nBesides, more general multi-label images are frequently overlooked in SSL,\ndespite their potential for richer semantic information and broader\napplicability in downstream scenarios. Therefore, we tailor the mainstream SSL\napproach to guarantee excellent representation learning capabilities using\nfewer multi-label images. Firstly, we propose a block-wise augmentation module\naimed at extracting additional potential positive view pairs from multi-label\nimages. Subsequently, an image-aware contrastive loss is devised to establish\nconnections between these views, thereby facilitating the extraction of\nsemantically consistent representations. Comprehensive linear fine-tuning and\ntransfer learning validate the competitiveness of our approach despite\nchallenging sample quality and quantity.", "AI": {"tldr": "A self-supervised learning (SSL) method tailored for multi-label images is proposed, using block-wise augmentation and image-aware contrastive loss to achieve competitive performance with fewer samples.", "motivation": "Mainstream SSL methods rely on single-label datasets like ImageNet, ignoring multi-label images' richer semantics and causing high pre-training overhead.", "method": "Proposes a block-wise augmentation module to extract positive view pairs from multi-label images and an image-aware contrastive loss for semantically consistent representations.", "result": "Validated through linear fine-tuning and transfer learning, showing competitiveness despite limited sample quality and quantity.", "conclusion": "The method effectively leverages multi-label images for SSL, reducing overhead while maintaining strong representation learning capabilities."}}
{"id": "2506.23578", "pdf": "https://arxiv.org/pdf/2506.23578", "abs": "https://arxiv.org/abs/2506.23578", "authors": ["\u0141ukasz Kami\u0144ski", "S\u0142awomir Lasota"], "title": "Reachability in symmetric VASS", "categories": ["cs.FL", "cs.CL"], "comment": null, "summary": "We investigate the reachability problem in symmetric vector addition systems\nwith states (VASS), where transitions are invariant under a group of\npermutations of coordinates. One extremal case, the trivial groups, yields\ngeneral VASS. In another extremal case, the symmetric groups, we show that the\nreachability problem can be solved in PSPACE, regardless of the dimension of\ninput VASS (to be contrasted with Ackermannian complexity in general VASS). We\nalso consider other groups, in particular alternating and cyclic ones.\nFurthermore, motivated by the open status of the reachability problem in data\nVASS, we estimate the gain in complexity when the group arises as a combination\nof the trivial and symmetric groups.", "AI": {"tldr": "The paper explores reachability in symmetric VASS under permutation groups, showing PSPACE complexity for symmetric groups and comparing it to general VASS's Ackermannian complexity.", "motivation": "To understand the impact of symmetry groups on the complexity of the reachability problem in VASS, especially in data VASS.", "method": "Analyzing reachability under various permutation groups (trivial, symmetric, alternating, cyclic) and combinations thereof.", "result": "Reachability in symmetric groups is solvable in PSPACE, contrasting with general VASS's higher complexity.", "conclusion": "Symmetry groups significantly reduce complexity, offering insights for data VASS reachability."}}
{"id": "2506.23799", "pdf": "https://arxiv.org/pdf/2506.23799", "abs": "https://arxiv.org/abs/2506.23799", "authors": ["Jiongli Zhu", "Parjanya Prajakta Prashant", "Alex Cloninger", "Babak Salimi"], "title": "KAIROS: Scalable Model-Agnostic Data Valuation", "categories": ["cs.LG"], "comment": "19 pages, 9 figures", "summary": "Training data increasingly shapes not only model accuracy but also regulatory\ncompliance and market valuation of AI assets. Yet existing valuation methods\nremain inadequate: model-based techniques depend on a single fitted model and\ninherit its biases, while algorithm-based approaches such as Data Shapley\nrequire costly retrainings at web scale. Recent Wasserstein-based\nmodel-agnostic methods rely on approximations that misrank examples relative to\ntheir true leave-one-out (LOO) utility. We introduce KAIROS, a scalable,\nmodel-agnostic valuation framework that assigns each example a distributional\ninfluence score: its contribution to the Maximum Mean Discrepancy (MMD) between\nthe empirical training distribution and a clean reference set. Unlike\nWasserstein surrogates, our MMD-based influence admits a closed-form solution\nthat faithfully approximates the exact LOO ranking within $O(1/N^2)$ error,\nrequires no retraining, and naturally extends to conditional kernels for\nunified label- and feature-error detection. Moreover, KAIROS supports efficient\nonline updates: when a new batch of size m arrives, all scores can be updated\nin $O(mN)$ time, delivering up to 50x speedup without compromising ranking\nquality. Empirical evaluations on noise, mislabeling, and poisoning benchmarks\nshow that KAIROS consistently outperforms state-of-the-art model-, Shapley-,\nand Wasserstein-based baselines in both accuracy and runtime. We provide\nrigorous theoretical guarantees, including symmetry for reproducible rankings\nand density-separation for interpretable thresholds.", "AI": {"tldr": "KAIROS is a scalable, model-agnostic framework for valuing training data by measuring its influence on the Maximum Mean Discrepancy (MMD) between training and reference distributions, outperforming existing methods in accuracy and efficiency.", "motivation": "Existing data valuation methods are flawed: model-based techniques inherit biases, while algorithm-based approaches like Data Shapley are computationally expensive. Wasserstein-based methods misrank examples. KAIROS addresses these limitations.", "method": "KAIROS assigns distributional influence scores using MMD, providing a closed-form solution that approximates leave-one-out (LOO) utility without retraining. It supports efficient online updates and conditional kernels for error detection.", "result": "KAIROS outperforms state-of-the-art baselines in accuracy and runtime, achieving up to 50x speedup. It handles noise, mislabeling, and poisoning effectively.", "conclusion": "KAIROS offers a scalable, accurate, and efficient solution for data valuation, with theoretical guarantees for reproducibility and interpretability."}}
{"id": "2506.23157", "pdf": "https://arxiv.org/pdf/2506.23157", "abs": "https://arxiv.org/abs/2506.23157", "authors": ["Hanyu Zhou", "Haonan Wang", "Haoyue Liu", "Yuxing Duan", "Luxin Yan", "Gim Hee Lee"], "title": "STD-GS: Exploring Frame-Event Interaction for SpatioTemporal-Disentangled Gaussian Splatting to Reconstruct High-Dynamic Scene", "categories": ["cs.CV"], "comment": null, "summary": "High-dynamic scene reconstruction aims to represent static background with\nrigid spatial features and dynamic objects with deformed continuous\nspatiotemporal features. Typically, existing methods adopt unified\nrepresentation model (e.g., Gaussian) to directly match the spatiotemporal\nfeatures of dynamic scene from frame camera. However, this unified paradigm\nfails in the potential discontinuous temporal features of objects due to frame\nimaging and the heterogeneous spatial features between background and objects.\nTo address this issue, we disentangle the spatiotemporal features into various\nlatent representations to alleviate the spatiotemporal mismatching between\nbackground and objects. In this work, we introduce event camera to compensate\nfor frame camera, and propose a spatiotemporal-disentangled Gaussian splatting\nframework for high-dynamic scene reconstruction. As for dynamic scene, we\nfigure out that background and objects have appearance discrepancy in\nframe-based spatial features and motion discrepancy in event-based temporal\nfeatures, which motivates us to distinguish the spatiotemporal features between\nbackground and objects via clustering. As for dynamic object, we discover that\nGaussian representations and event data share the consistent spatiotemporal\ncharacteristic, which could serve as a prior to guide the spatiotemporal\ndisentanglement of object Gaussians. Within Gaussian splatting framework, the\ncumulative scene-object disentanglement can improve the spatiotemporal\ndiscrimination between background and objects to render the time-continuous\ndynamic scene. Extensive experiments have been performed to verify the\nsuperiority of the proposed method.", "AI": {"tldr": "A spatiotemporal-disentangled Gaussian splatting framework is proposed for high-dynamic scene reconstruction, using event cameras to compensate for frame cameras and clustering to distinguish features.", "motivation": "Existing unified representation models fail to handle discontinuous temporal features and heterogeneous spatial features in dynamic scenes.", "method": "Disentangles spatiotemporal features into latent representations, uses event cameras alongside frame cameras, and employs clustering to distinguish background and object features.", "result": "The method improves spatiotemporal discrimination, enabling time-continuous dynamic scene reconstruction.", "conclusion": "The proposed framework effectively addresses spatiotemporal mismatching, verified by extensive experiments."}}
{"id": "2506.23714", "pdf": "https://arxiv.org/pdf/2506.23714", "abs": "https://arxiv.org/abs/2506.23714", "authors": ["Md Moinul Islam", "Sofoklis Kakouros", "Janne Heikkil\u00e4", "Mourad Oussalah"], "title": "Towards an Automated Multimodal Approach for Video Summarization: Building a Bridge Between Text, Audio and Facial Cue-Based Summarization", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted to HHAI WS 2025: Workshops at the Fourth International\n  Conference on Hybrid Human-Artificial Intelligence (HHAI)", "summary": "The increasing volume of video content in educational, professional, and\nsocial domains necessitates effective summarization techniques that go beyond\ntraditional unimodal approaches. This paper proposes a behaviour-aware\nmultimodal video summarization framework that integrates textual, audio, and\nvisual cues to generate timestamp-aligned summaries. By extracting prosodic\nfeatures, textual cues and visual indicators, the framework identifies\nsemantically and emotionally important moments. A key contribution is the\nidentification of bonus words, which are terms emphasized across multiple\nmodalities and used to improve the semantic relevance and expressive clarity of\nthe summaries. The approach is evaluated against pseudo-ground truth (pGT)\nsummaries generated using LLM-based extractive method. Experimental results\ndemonstrate significant improvements over traditional extractive method, such\nas the Edmundson method, in both text and video-based evaluation metrics.\nText-based metrics show ROUGE-1 increasing from 0.4769 to 0.7929 and BERTScore\nfrom 0.9152 to 0.9536, while in video-based evaluation, our proposed framework\nimproves F1-Score by almost 23%. The findings underscore the potential of\nmultimodal integration in producing comprehensive and behaviourally informed\nvideo summaries.", "AI": {"tldr": "A multimodal video summarization framework integrates text, audio, and visual cues to create timestamp-aligned summaries, outperforming traditional methods in both text and video metrics.", "motivation": "The rise in video content demands advanced summarization techniques beyond unimodal approaches to capture semantically and emotionally important moments.", "method": "The framework uses prosodic features, textual cues, and visual indicators to identify key moments, including bonus words emphasized across modalities.", "result": "Improvements include ROUGE-1 (0.4769 to 0.7929), BERTScore (0.9152 to 0.9536), and a 23% F1-Score boost in video evaluation.", "conclusion": "Multimodal integration enhances video summarization by producing comprehensive, behaviourally informed summaries."}}
{"id": "2506.23164", "pdf": "https://arxiv.org/pdf/2506.23164", "abs": "https://arxiv.org/abs/2506.23164", "authors": ["Maarten Hugenholtz", "Anna Meszaros", "Jens Kober", "Zlatan Ajanovic"], "title": "Mode Collapse Happens: Evaluating Critical Interactions in Joint Trajectory Prediction Models", "categories": ["cs.RO", "cs.AI"], "comment": "12 pages, 8 figures, submitted to a journal", "summary": "Autonomous Vehicle decisions rely on multimodal prediction models that\naccount for multiple route options and the inherent uncertainty in human\nbehavior. However, models can suffer from mode collapse, where only the most\nlikely mode is predicted, posing significant safety risks. While existing\nmethods employ various strategies to generate diverse predictions, they often\noverlook the diversity in interaction modes among agents. Additionally,\ntraditional metrics for evaluating prediction models are dataset-dependent and\ndo not evaluate inter-agent interactions quantitatively. To our knowledge, none\nof the existing metrics explicitly evaluates mode collapse. In this paper, we\npropose a novel evaluation framework that assesses mode collapse in joint\ntrajectory predictions, focusing on safety-critical interactions. We introduce\nmetrics for mode collapse, mode correctness, and coverage, emphasizing the\nsequential dimension of predictions. By testing four multi-agent trajectory\nprediction models, we demonstrate that mode collapse indeed happens. When\nlooking at the sequential dimension, although prediction accuracy improves\ncloser to interaction events, there are still cases where the models are unable\nto predict the correct interaction mode, even just before the interaction mode\nbecomes inevitable. We hope that our framework can help researchers gain new\ninsights and advance the development of more consistent and accurate prediction\nmodels, thus enhancing the safety of autonomous driving systems.", "AI": {"tldr": "The paper proposes a framework to evaluate mode collapse in joint trajectory predictions for autonomous vehicles, introducing metrics for mode collapse, correctness, and coverage.", "motivation": "Existing models often overlook diversity in interaction modes and lack metrics to evaluate mode collapse, posing safety risks.", "method": "A novel evaluation framework is introduced, focusing on safety-critical interactions and sequential prediction dimensions. Four multi-agent trajectory prediction models are tested.", "result": "Mode collapse occurs in predictions, and while accuracy improves near interaction events, models sometimes fail to predict correct modes even before inevitable interactions.", "conclusion": "The framework aims to improve prediction model consistency and accuracy, enhancing autonomous driving safety."}}
{"id": "2506.23800", "pdf": "https://arxiv.org/pdf/2506.23800", "abs": "https://arxiv.org/abs/2506.23800", "authors": ["Chang Qi", "Matteo Forasassi", "Thomas Lukasiewicz", "Tommaso Salvatori"], "title": "Towards the Training of Deeper Predictive Coding Neural Networks", "categories": ["cs.LG"], "comment": "18 Pages, 7 figures", "summary": "Predictive coding networks trained with equilibrium propagation are neural\nmodels that perform inference through an iterative energy minimization process.\nPrevious studies have demonstrated their effectiveness in shallow\narchitectures, but show significant performance degradation when depth exceeds\nfive to seven layers. In this work, we show that the reason behind this\ndegradation is due to exponentially imbalanced errors between layers during\nweight updates, and predictions from the previous layer not being effective in\nguiding updates in deeper layers. We address the first issue by introducing two\nnovel methods to optimize the latent variables that use precision-weighting to\nre-balance the distribution of energy among layers during the `relaxation\nphase', and the second issue by proposing a novel weight update mechanism that\nreduces error accumulation in deeper layers. Empirically, we test our methods\non a large number of image classification tasks, resulting in large\nimprovements in test accuracy across networks with more than seven layers, with\nperformances comparable to those of backprop on similar models. These findings\nsuggest that a better understanding of the relaxation phase is important to\ntrain models using equilibrium propagation at scale, and open new possibilities\nfor their application in complex tasks.", "AI": {"tldr": "The paper addresses performance degradation in deep predictive coding networks by introducing precision-weighting and a novel weight update mechanism, achieving results comparable to backpropagation.", "motivation": "Performance degradation in deep predictive coding networks due to imbalanced errors and ineffective predictions in deeper layers.", "method": "Introduces precision-weighting for latent variables and a novel weight update mechanism to reduce error accumulation.", "result": "Improved test accuracy in networks with over seven layers, matching backpropagation performance.", "conclusion": "Better understanding of the relaxation phase is key for scaling equilibrium propagation in complex tasks."}}
{"id": "2506.23189", "pdf": "https://arxiv.org/pdf/2506.23189", "abs": "https://arxiv.org/abs/2506.23189", "authors": ["Mustafa Hakan Kara", "Aysegul Dundar", "U\u011fur G\u00fcd\u00fckbay"], "title": "Trident: Detecting Face Forgeries with Adversarial Triplet Learning", "categories": ["cs.CV"], "comment": "11 pages, 3 figures, and 7 tables", "summary": "As face forgeries generated by deep neural networks become increasingly\nsophisticated, detecting face manipulations in digital media has posed a\nsignificant challenge, underscoring the importance of maintaining digital media\nintegrity and combating visual disinformation. Current detection models,\npredominantly based on supervised training with domain-specific data, often\nfalter against forgeries generated by unencountered techniques. In response to\nthis challenge, we introduce \\textit{Trident}, a face forgery detection\nframework that employs triplet learning with a Siamese network architecture for\nenhanced adaptability across diverse forgery methods. \\textit{Trident} is\ntrained on curated triplets to isolate nuanced differences of forgeries,\ncapturing fine-grained features that distinguish pristine samples from\nmanipulated ones while controlling for other variables. To further enhance\ngeneralizability, we incorporate domain-adversarial training with a forgery\ndiscriminator. This adversarial component guides our embedding model towards\nforgery-agnostic representations, improving its robustness to unseen\nmanipulations. In addition, we prevent gradient flow from the classifier head\nto the embedding model, avoiding overfitting induced by artifacts peculiar to\ncertain forgeries. Comprehensive evaluations across multiple benchmarks and\nablation studies demonstrate the effectiveness of our framework. We will\nrelease our code in a GitHub repository.", "AI": {"tldr": "Trident is a face forgery detection framework using triplet learning and Siamese networks for adaptability across diverse forgery methods, enhanced by domain-adversarial training for robustness.", "motivation": "Deep neural networks generate increasingly sophisticated face forgeries, challenging detection models that often fail against unseen techniques.", "method": "Trident employs triplet learning with a Siamese network, domain-adversarial training, and controlled gradient flow to isolate forgery features.", "result": "The framework shows effectiveness in detecting diverse forgeries, demonstrated by benchmarks and ablation studies.", "conclusion": "Trident improves robustness and generalizability in face forgery detection, with code to be released."}}
{"id": "2506.23845", "pdf": "https://arxiv.org/pdf/2506.23845", "abs": "https://arxiv.org/abs/2506.23845", "authors": ["Kenny Peng", "Rajiv Movva", "Jon Kleinberg", "Emma Pierson", "Nikhil Garg"], "title": "Use Sparse Autoencoders to Discover Unknown Concepts, Not to Act on Known Concepts", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "While sparse autoencoders (SAEs) have generated significant excitement, a\nseries of negative results have added to skepticism about their usefulness.\nHere, we establish a conceptual distinction that reconciles competing\nnarratives surrounding SAEs. We argue that while SAEs may be less effective for\nacting on known concepts, SAEs are powerful tools for discovering unknown\nconcepts. This distinction cleanly separates existing negative and positive\nresults, and suggests several classes of SAE applications. Specifically, we\noutline use cases for SAEs in (i) ML interpretability, explainability,\nfairness, auditing, and safety, and (ii) social and health sciences.", "AI": {"tldr": "SAEs are less effective for acting on known concepts but powerful for discovering unknown ones, clarifying their utility in interpretability and social sciences.", "motivation": "Reconcile competing narratives about SAEs by distinguishing their effectiveness for known vs. unknown concepts.", "method": "Conceptual distinction between SAEs' roles in acting on known concepts versus discovering unknown ones.", "result": "SAEs are useful for interpretability, fairness, and social/health sciences, despite skepticism.", "conclusion": "SAEs have distinct applications in discovery and interpretability, clarifying their value."}}
{"id": "2506.23173", "pdf": "https://arxiv.org/pdf/2506.23173", "abs": "https://arxiv.org/abs/2506.23173", "authors": ["Tomer Slor", "Dean Oren", "Shira Baneth", "Tom Coen", "Haim Suchowski"], "title": "Deep Learning for Optical Misalignment Diagnostics in Multi-Lens Imaging Systems", "categories": ["physics.optics", "cs.AI", "cs.LG"], "comment": null, "summary": "In the rapidly evolving field of optical engineering, precise alignment of\nmulti-lens imaging systems is critical yet challenging, as even minor\nmisalignments can significantly degrade performance. Traditional alignment\nmethods rely on specialized equipment and are time-consuming processes,\nhighlighting the need for automated and scalable solutions. We present two\ncomplementary deep learning-based inverse-design methods for diagnosing\nmisalignments in multi-element lens systems using only optical measurements.\nFirst, we use ray-traced spot diagrams to predict five-degree-of-freedom\n(5-DOF) errors in a 6-lens photographic prime, achieving a mean absolute error\nof 0.031mm in lateral translation and 0.011$^\\circ$ in tilt. We also introduce\na physics-based simulation pipeline that utilizes grayscale synthetic camera\nimages, enabling a deep learning model to estimate 4-DOF, decenter and tilt\nerrors in both two- and six-lens multi-lens systems. These results show the\npotential to reshape manufacturing and quality control in precision imaging.", "AI": {"tldr": "Deep learning methods for diagnosing misalignments in multi-lens systems using optical measurements, achieving high precision.", "motivation": "Precise alignment in multi-lens systems is critical but challenging; traditional methods are slow and equipment-heavy.", "method": "Two deep learning approaches: ray-traced spot diagrams for 5-DOF errors and physics-based simulation for 4-DOF errors.", "result": "Achieved 0.031mm lateral translation and 0.011\u00b0 tilt errors in 6-lens systems.", "conclusion": "Demonstrates potential to revolutionize precision imaging manufacturing and quality control."}}
{"id": "2506.23802", "pdf": "https://arxiv.org/pdf/2506.23802", "abs": "https://arxiv.org/abs/2506.23802", "authors": ["Konstantinos Bourazas", "Savvas Papaioannou", "Panayiotis Kolios"], "title": "Adaptive Out-of-Control Point Pattern Detection in Sequential Random Finite Set Observations", "categories": ["cs.LG"], "comment": "23rd European Control Conference (ECC 2025), Thessaloniki, Greece,\n  24-27 June 2025", "summary": "In this work we introduce a novel adaptive anomaly detection framework\nspecifically designed for monitoring sequential random finite set (RFS)\nobservations. Our approach effectively distinguishes between In-Control data\n(normal) and Out-Of-Control data (anomalies) by detecting deviations from the\nexpected statistical behavior of the process. The primary contributions of this\nstudy include the development of an innovative RFS-based framework that not\nonly learns the normal behavior of the data-generating process online but also\ndynamically adapts to behavioral shifts to accurately identify abnormal point\npatterns. To achieve this, we introduce a new class of RFS-based posterior\ndistributions, named Power Discounting Posteriors (PD), which facilitate\nadaptation to systematic changes in data while enabling anomaly detection of\npoint pattern data through a novel predictive posterior density function. The\neffectiveness of the proposed approach is demonstrated by extensive qualitative\nand quantitative simulation experiments.", "AI": {"tldr": "A novel adaptive anomaly detection framework for sequential RFS observations, distinguishing normal from anomalous data by detecting deviations from expected statistical behavior.", "motivation": "To monitor sequential RFS observations and accurately identify anomalies by adapting to behavioral shifts in the data-generating process.", "method": "Development of an RFS-based framework with Power Discounting Posteriors (PD) for online learning and dynamic adaptation to detect abnormal point patterns.", "result": "Effective anomaly detection demonstrated through qualitative and quantitative simulation experiments.", "conclusion": "The proposed framework successfully adapts to behavioral shifts and accurately identifies anomalies in sequential RFS data."}}
{"id": "2506.23196", "pdf": "https://arxiv.org/pdf/2506.23196", "abs": "https://arxiv.org/abs/2506.23196", "authors": ["Mona Ahmadian", "Amir Shirian", "Frank Guerin", "Andrew Gilbert"], "title": "DEL: Dense Event Localization for Multi-modal Audio-Visual Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Real-world videos often contain overlapping events and complex temporal\ndependencies, making multimodal interaction modeling particularly challenging.\nWe introduce DEL, a framework for dense semantic action localization, aiming to\naccurately detect and classify multiple actions at fine-grained temporal\nresolutions in long untrimmed videos. DEL consists of two key modules: the\nalignment of audio and visual features that leverage masked self-attention to\nenhance intra-mode consistency and a multimodal interaction refinement module\nthat models cross-modal dependencies across multiple scales, enabling\nhigh-level semantics and fine-grained details. Our method achieves\nstate-of-the-art performance on multiple real-world Temporal Action\nLocalization (TAL) datasets, UnAV-100, THUMOS14, ActivityNet 1.3, and\nEPIC-Kitchens-100, surpassing previous approaches with notable average mAP\ngains of +3.3%, +2.6%, +1.2%, +1.7% (verb), and +1.4% (noun), respectively.", "AI": {"tldr": "DEL is a framework for dense semantic action localization in videos, using multimodal alignment and interaction refinement to achieve state-of-the-art performance on TAL datasets.", "motivation": "Real-world videos contain overlapping events and complex temporal dependencies, making multimodal interaction modeling challenging.", "method": "DEL aligns audio and visual features with masked self-attention for intra-mode consistency and refines multimodal interactions across scales.", "result": "DEL surpasses previous methods with notable mAP gains on UnAV-100, THUMOS14, ActivityNet 1.3, and EPIC-Kitchens-100.", "conclusion": "DEL effectively addresses the challenges of dense action localization in videos, achieving superior performance."}}
{"id": "2506.23978", "pdf": "https://arxiv.org/pdf/2506.23978", "abs": "https://arxiv.org/abs/2506.23978", "authors": ["Samuele Marro", "Philip Torr"], "title": "LLM Agents Are the Antidote to Walled Gardens", "categories": ["cs.LG", "cs.CL", "cs.CY", "cs.SI", "68T50, 68M10, 91B26", "I.2.11; I.2.7; H.4.5"], "comment": null, "summary": "While the Internet's core infrastructure was designed to be open and\nuniversal, today's application layer is dominated by closed, proprietary\nplatforms. Open and interoperable APIs require significant investment, and\nmarket leaders have little incentive to enable data exchange that could erode\ntheir user lock-in. We argue that LLM-based agents fundamentally disrupt this\nstatus quo. Agents can automatically translate between data formats and\ninteract with interfaces designed for humans: this makes interoperability\ndramatically cheaper and effectively unavoidable. We name this shift universal\ninteroperability: the ability for any two digital services to exchange data\nseamlessly using AI-mediated adapters. Universal interoperability undermines\nmonopolistic behaviours and promotes data portability. However, it can also\nlead to new security risks and technical debt. Our position is that the ML\ncommunity should embrace this development while building the appropriate\nframeworks to mitigate the downsides. By acting now, we can harness AI to\nrestore user freedom and competitive markets without sacrificing security.", "AI": {"tldr": "LLM-based agents enable universal interoperability, disrupting closed platforms by making data exchange cheap and unavoidable, but require frameworks to address risks.", "motivation": "The dominance of closed, proprietary platforms in the application layer limits data exchange and interoperability, reinforcing monopolistic behaviors.", "method": "Proposes using LLM-based agents to automatically translate data formats and interact with human-designed interfaces, enabling seamless interoperability.", "result": "Universal interoperability reduces monopolistic behaviors and promotes data portability but introduces security risks and technical debt.", "conclusion": "The ML community should embrace universal interoperability while developing frameworks to mitigate risks, ensuring user freedom and competitive markets."}}
{"id": "2506.23203", "pdf": "https://arxiv.org/pdf/2506.23203", "abs": "https://arxiv.org/abs/2506.23203", "authors": ["Feng Shu", "Jiatong Bai", "Di Wu", "Wei Zhu", "Bin Deng", "Fuhui Zhou", "Jiangzhou Wang"], "title": "Multi-Branch DNN and CRLB-Ratio-Weight Fusion for Enhanced DOA Sensing via a Massive H$^2$AD MIMO Receiver", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "As a green MIMO structure, massive H$^2$AD is viewed as a potential\ntechnology for the future 6G wireless network. For such a structure, it is a\nchallenging task to design a low-complexity and high-performance fusion of\ntarget direction values sensed by different sub-array groups with fewer use of\nprior knowledge. To address this issue, a lightweight Cramer-Rao lower bound\n(CRLB)-ratio-weight fusion (WF) method is proposed, which approximates inverse\nCRLB of each subarray using antenna number reciprocals to eliminate real-time\nCRLB computation. This reduces complexity and prior knowledge dependence while\npreserving fusion performance. Moreover, a multi-branch deep neural network\n(MBDNN) is constructed to further enhance direction-of-arrival (DOA) sensing by\nleveraging candidate angles from multiple subarrays. The subarray-specific\nbranch networks are integrated with a shared regression module to effectively\neliminate pseudo-solutions and fuse true angles. Simulation results show that\nthe proposed CRLB-ratio-WF method achieves DOA sensing performance comparable\nto CRLB-based methods, while significantly reducing the reliance on prior\nknowledge. More notably, the proposed MBDNN has superior performance in low-SNR\nranges. At SNR $= -15$ dB, it achieves an order-of-magnitude improvement in\nestimation accuracy compared to CRLB-ratio-WF method.", "AI": {"tldr": "A lightweight CRLB-ratio-WF method and MBDNN are proposed for efficient DOA sensing in massive H$^2$AD, reducing complexity and prior knowledge reliance while improving performance, especially in low-SNR conditions.", "motivation": "To address the challenge of designing low-complexity, high-performance fusion of target direction values in massive H$^2$AD for 6G networks with minimal prior knowledge.", "method": "Proposes a CRLB-ratio-WF method using antenna number reciprocals to avoid real-time CRLB computation, and a multi-branch DNN (MBDNN) to enhance DOA sensing by integrating subarray-specific branches with a shared regression module.", "result": "CRLB-ratio-WF matches CRLB-based methods in performance with reduced complexity. MBDNN outperforms significantly in low-SNR, achieving 10x better accuracy at SNR = -15 dB.", "conclusion": "The proposed methods offer efficient and robust DOA sensing for 6G networks, with MBDNN excelling in low-SNR scenarios."}}
{"id": "2506.23803", "pdf": "https://arxiv.org/pdf/2506.23803", "abs": "https://arxiv.org/abs/2506.23803", "authors": ["Dmitry Kovalev"], "title": "SGD with Adaptive Preconditioning: Unified Analysis and Momentum Acceleration", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "In this paper, we revisit stochastic gradient descent (SGD) with AdaGrad-type\npreconditioning. Our contributions are twofold. First, we develop a unified\nconvergence analysis of SGD with adaptive preconditioning under anisotropic or\nmatrix smoothness and noise assumptions. This allows us to recover\nstate-of-the-art convergence results for several popular adaptive gradient\nmethods, including AdaGrad-Norm, AdaGrad, and ASGO/One-sided Shampoo. In\naddition, we establish the fundamental connection between two recently proposed\nalgorithms, Scion and DASGO, and provide the first theoretical guarantees for\nthe latter. Second, we show that the convergence of methods like AdaGrad and\nDASGO can be provably accelerated beyond the best-known rates using Nesterov\nmomentum. Consequently, we obtain the first theoretical justification that\nAdaGrad-type algorithms can simultaneously benefit from both diagonal\npreconditioning and momentum, which may provide an ultimate explanation for the\npractical efficiency of Adam.", "AI": {"tldr": "The paper revisits SGD with AdaGrad-type preconditioning, providing a unified convergence analysis and connecting Scion and DASGO. It also shows accelerated convergence with Nesterov momentum, explaining Adam's efficiency.", "motivation": "To unify and extend convergence analysis for adaptive gradient methods and explore the benefits of combining preconditioning with momentum.", "method": "Develops a unified convergence framework for SGD with adaptive preconditioning under anisotropic smoothness and noise, and applies Nesterov momentum.", "result": "Recovers state-of-the-art convergence results, connects Scion and DASGO, and proves accelerated convergence with momentum.", "conclusion": "AdaGrad-type methods can benefit from both preconditioning and momentum, explaining Adam's practical efficiency."}}
{"id": "2506.23202", "pdf": "https://arxiv.org/pdf/2506.23202", "abs": "https://arxiv.org/abs/2506.23202", "authors": ["Qilin Shu", "Qixian Zhang", "Qi Zhang", "Hongyun Zhang", "Duoqian Miao", "Cairong Zhao"], "title": "Transformer-Based Person Search with High-Frequency Augmentation and Multi-Wave Mixing", "categories": ["cs.CV"], "comment": null, "summary": "The person search task aims to locate a target person within a set of scene\nimages. In recent years, transformer-based models in this field have made some\nprogress. However, they still face three primary challenges: 1) the\nself-attention mechanism tends to suppress high-frequency components in the\nfeatures, which severely impacts model performance; 2) the computational cost\nof transformers is relatively high. To address these issues, we propose a novel\nHigh-frequency Augmentation and Multi-Wave mixing (HAMW) method for person\nsearch. HAMW is designed to enhance the discriminative feature extraction\ncapabilities of transformers while reducing computational overhead and\nimproving efficiency. Specifically, we develop a three-stage framework that\nprogressively optimizes both detection and re-identification performance. Our\nmodel enhances the perception of high-frequency features by learning from\naugmented inputs containing additional high-frequency components. Furthermore,\nwe replace the self-attention layers in the transformer with a strategy based\non multi-level Haar wavelet fusion to capture multi-scale features. This not\nonly lowers the computational complexity but also alleviates the suppression of\nhigh-frequency features and enhances the ability to exploit multi-scale\ninformation. Extensive experiments demonstrate that HAMW achieves\nstate-of-the-art performance on both the CUHK-SYSU and PRW datasets.", "AI": {"tldr": "The paper proposes HAMW, a method to enhance transformer-based person search by addressing high-frequency feature suppression and computational costs through high-frequency augmentation and multi-wave mixing.", "motivation": "Transformer-based models for person search suppress high-frequency features and have high computational costs, limiting performance.", "method": "HAMW uses a three-stage framework with high-frequency augmentation and replaces self-attention with multi-level Haar wavelet fusion for multi-scale feature capture.", "result": "HAMW achieves state-of-the-art performance on CUHK-SYSU and PRW datasets.", "conclusion": "HAMW effectively improves feature extraction and efficiency in person search tasks."}}
{"id": "2506.24019", "pdf": "https://arxiv.org/pdf/2506.24019", "abs": "https://arxiv.org/abs/2506.24019", "authors": ["Hongxin Zhang", "Zheyuan Zhang", "Zeyuan Wang", "Zunzhe Zhang", "Lixing Fang", "Qinhong Zhou", "Chuang Gan"], "title": "Ella: Embodied Social Agents with Lifelong Memory", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "We introduce Ella, an embodied social agent capable of lifelong learning\nwithin a community in a 3D open world, where agents accumulate experiences and\nacquire knowledge through everyday visual observations and social interactions.\nAt the core of Ella's capabilities is a structured, long-term multimodal memory\nsystem that stores, updates, and retrieves information effectively. It consists\nof a name-centric semantic memory for organizing acquired knowledge and a\nspatiotemporal episodic memory for capturing multimodal experiences. By\nintegrating this lifelong memory system with foundation models, Ella retrieves\nrelevant information for decision-making, plans daily activities, builds social\nrelationships, and evolves autonomously while coexisting with other intelligent\nbeings in the open world. We conduct capability-oriented evaluations in a\ndynamic 3D open world where 15 agents engage in social activities for days and\nare assessed with a suite of unseen controlled evaluations. Experimental\nresults show that Ella can influence, lead, and cooperate with other agents\nwell to achieve goals, showcasing its ability to learn effectively through\nobservation and social interaction. Our findings highlight the transformative\npotential of combining structured memory systems with foundation models for\nadvancing embodied intelligence. More videos can be found at\nhttps://umass-embodied-agi.github.io/Ella/.", "AI": {"tldr": "Ella is an embodied social agent with lifelong learning capabilities in a 3D open world, using a multimodal memory system and foundation models for autonomous evolution and social interactions.", "motivation": "To advance embodied intelligence by integrating structured memory systems with foundation models, enabling agents to learn and evolve through social interactions and observations.", "method": "Ella employs a long-term multimodal memory system (semantic and episodic) combined with foundation models for decision-making, planning, and social relationship building.", "result": "Ella successfully influences, leads, and cooperates with other agents in a dynamic 3D world, demonstrating effective learning through observation and interaction.", "conclusion": "The integration of structured memory with foundation models holds transformative potential for advancing embodied intelligence."}}
{"id": "2506.23236", "pdf": "https://arxiv.org/pdf/2506.23236", "abs": "https://arxiv.org/abs/2506.23236", "authors": ["Marko Mihajlovic", "Siwei Zhang", "Gen Li", "Kaifeng Zhao", "Lea M\u00fcller", "Siyu Tang"], "title": "VolumetricSMPL: A Neural Volumetric Body Model for Efficient Interactions, Contacts, and Collisions", "categories": ["cs.CV", "cs.AI"], "comment": "[ICCV 2025] https://markomih.github.io/VolumetricSMPL", "summary": "Parametric human body models play a crucial role in computer graphics and\nvision, enabling applications ranging from human motion analysis to\nunderstanding human-environment interactions. Traditionally, these models use\nsurface meshes, which pose challenges in efficiently handling interactions with\nother geometric entities, such as objects and scenes, typically represented as\nmeshes or point clouds. To address this limitation, recent research has\nexplored volumetric neural implicit body models. However, existing works are\neither insufficiently robust for complex human articulations or impose high\ncomputational and memory costs, limiting their widespread use. To this end, we\nintroduce VolumetricSMPL, a neural volumetric body model that leverages Neural\nBlend Weights (NBW) to generate compact, yet efficient MLP decoders. Unlike\nprior approaches that rely on large MLPs, NBW dynamically blends a small set of\nlearned weight matrices using predicted shape- and pose-dependent coefficients,\nsignificantly improving computational efficiency while preserving\nexpressiveness. VolumetricSMPL outperforms prior volumetric occupancy model\nCOAP with 10x faster inference, 6x lower GPU memory usage, enhanced accuracy,\nand a Signed Distance Function (SDF) for efficient and differentiable contact\nmodeling. We demonstrate VolumetricSMPL's strengths across four challenging\ntasks: (1) reconstructing human-object interactions from in-the-wild images,\n(2) recovering human meshes in 3D scenes from egocentric views, (3)\nscene-constrained motion synthesis, and (4) resolving self-intersections. Our\nresults highlight its broad applicability and significant performance and\nefficiency gains.", "AI": {"tldr": "VolumetricSMPL introduces a neural volumetric body model using Neural Blend Weights (NBW) for efficient MLP decoders, outperforming prior models in speed, memory, and accuracy.", "motivation": "Traditional surface mesh models struggle with interactions and efficiency, while existing volumetric models are either insufficiently robust or too costly.", "method": "Leverages NBW to dynamically blend learned weight matrices, reducing computational costs while maintaining expressiveness.", "result": "Achieves 10x faster inference, 6x lower GPU memory usage, and enhanced accuracy, with applications in reconstruction, motion synthesis, and more.", "conclusion": "VolumetricSMPL offers broad applicability and significant performance gains, addressing limitations of prior models."}}
{"id": "2506.23824", "pdf": "https://arxiv.org/pdf/2506.23824", "abs": "https://arxiv.org/abs/2506.23824", "authors": ["Durgesh Singh", "Ahcene Boubekki", "Robert Jenssen", "Michael C. Kampffmeyer"], "title": "Supercm: Revisiting Clustering for Semi-Supervised Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "The development of semi-supervised learning (SSL) has in recent years largely\nfocused on the development of new consistency regularization or entropy\nminimization approaches, often resulting in models with complex training\nstrategies to obtain the desired results. In this work, we instead propose a\nnovel approach that explicitly incorporates the underlying clustering\nassumption in SSL through extending a recently proposed differentiable\nclustering module. Leveraging annotated data to guide the cluster centroids\nresults in a simple end-to-end trainable deep SSL approach. We demonstrate that\nthe proposed model improves the performance over the supervised-only baseline\nand show that our framework can be used in conjunction with other SSL methods\nto further boost their performance.", "AI": {"tldr": "A novel SSL method using differentiable clustering to improve performance and simplicity.", "motivation": "Current SSL methods focus on complex consistency regularization or entropy minimization; this work simplifies SSL by incorporating clustering.", "method": "Extends a differentiable clustering module, using annotated data to guide cluster centroids for an end-to-end trainable approach.", "result": "Outperforms supervised-only baselines and enhances other SSL methods when combined.", "conclusion": "The proposed clustering-based SSL method is effective, simple, and compatible with other techniques."}}
{"id": "2506.23205", "pdf": "https://arxiv.org/pdf/2506.23205", "abs": "https://arxiv.org/abs/2506.23205", "authors": ["Dequan Kong", "Zhe Zhu", "Honghua Chen", "Mingqiang Wei"], "title": "BridgeShape: Latent Diffusion Schr\u00f6dinger Bridge for 3D Shape Completion", "categories": ["cs.CV"], "comment": null, "summary": "Existing diffusion-based 3D shape completion methods typically use a\nconditional paradigm, injecting incomplete shape information into the denoising\nnetwork via deep feature interactions (e.g., concatenation, cross-attention) to\nguide sampling toward complete shapes, often represented by voxel-based\ndistance functions. However, these approaches fail to explicitly model the\noptimal global transport path, leading to suboptimal completions. Moreover,\nperforming diffusion directly in voxel space imposes resolution constraints,\nlimiting the generation of fine-grained geometric details. To address these\nchallenges, we propose BridgeShape, a novel framework for 3D shape completion\nvia latent diffusion Schr\\\"odinger bridge. The key innovations lie in two\naspects: (i) BridgeShape formulates shape completion as an optimal transport\nproblem, explicitly modeling the transition between incomplete and complete\nshapes to ensure a globally coherent transformation. (ii) We introduce a\nDepth-Enhanced Vector Quantized Variational Autoencoder (VQ-VAE) to encode 3D\nshapes into a compact latent space, leveraging self-projected multi-view depth\ninformation enriched with strong DINOv2 features to enhance geometric\nstructural perception. By operating in a compact yet structurally informative\nlatent space, BridgeShape effectively mitigates resolution constraints and\nenables more efficient and high-fidelity 3D shape completion. BridgeShape\nachieves state-of-the-art performance on large-scale 3D shape completion\nbenchmarks, demonstrating superior fidelity at higher resolutions and for\nunseen object classes.", "AI": {"tldr": "BridgeShape introduces a latent diffusion Schr\\\"odinger bridge framework for 3D shape completion, addressing suboptimal global transport and resolution constraints by modeling optimal transport and using a compact latent space.", "motivation": "Existing methods fail to model optimal global transport paths and face resolution limitations, leading to suboptimal completions.", "method": "BridgeShape formulates shape completion as an optimal transport problem and uses a Depth-Enhanced VQ-VAE to encode shapes into a compact latent space.", "result": "Achieves state-of-the-art performance, enabling high-fidelity completions at higher resolutions and for unseen classes.", "conclusion": "BridgeShape effectively addresses key challenges in 3D shape completion, offering superior fidelity and scalability."}}
{"id": "2506.24056", "pdf": "https://arxiv.org/pdf/2506.24056", "abs": "https://arxiv.org/abs/2506.24056", "authors": ["Tung-Ling Li", "Hongliang Liu"], "title": "Logit-Gap Steering: Efficient Short-Suffix Jailbreaks for Aligned Large Language Models", "categories": ["cs.CR", "cs.CL", "cs.LG"], "comment": null, "summary": "We introduce logit-gap steering, a fast jailbreak framework that casts the\nrefusal-affirmation gap of RLHF-aligned language models as a single pass over\nthe vocabulary. A forward-computable score blends gap reduction with\nlightweight proxies for KL penalty and reward shift, allowing a \"sort-sum-stop\"\nsweep to complete in under a second and return a short suffix--two orders of\nmagnitude fewer model calls than beam or gradient attacks. The same suffix\ngeneralises to unseen prompts and scales from 0.5 B to 70 B checkpoints,\nlifting one-shot attack success from baseline levels to 80-100% while\npreserving topical coherence. Beyond efficiency, these suffixes expose\nsentence-boundary reward cliffs and other alignment artefacts, offering a\nlightweight probe into how safety tuning reshapes internal representations.", "AI": {"tldr": "Logit-gap steering is a fast jailbreak framework for RLHF-aligned language models, reducing refusal-affirmation gaps efficiently with minimal model calls.", "motivation": "To address the inefficiency of existing jailbreak methods (like beam or gradient attacks) and improve attack success rates while maintaining coherence.", "method": "Uses a forward-computable score blending gap reduction, KL penalty, and reward shift, enabling a quick \"sort-sum-stop\" sweep for suffix generation.", "result": "Achieves 80-100% attack success with minimal model calls, generalizes across prompts and model sizes, and exposes alignment artefacts.", "conclusion": "Logit-gap steering is efficient, effective, and provides insights into safety tuning's impact on model representations."}}
{"id": "2506.23247", "pdf": "https://arxiv.org/pdf/2506.23247", "abs": "https://arxiv.org/abs/2506.23247", "authors": ["James Hinns", "David Martens"], "title": "Aggregating Local Saliency Maps for Semi-Global Explainable Image Classification", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Deep learning dominates image classification tasks, yet understanding how\nmodels arrive at predictions remains a challenge. Much research focuses on\nlocal explanations of individual predictions, such as saliency maps, which\nvisualise the influence of specific pixels on a model's prediction. However,\nreviewing many of these explanations to identify recurring patterns is\ninfeasible, while global methods often oversimplify and miss important local\nbehaviours. To address this, we propose Segment Attribution Tables (SATs), a\nmethod for summarising local saliency explanations into (semi-)global insights.\nSATs take image segments (such as \"eyes\" in Chihuahuas) and leverage saliency\nmaps to quantify their influence. These segments highlight concepts the model\nrelies on across instances and reveal spurious correlations, such as reliance\non backgrounds or watermarks, even when out-of-distribution test performance\nsees little change. SATs can explain any classifier for which a form of\nsaliency map can be produced, using segmentation maps that provide named\nsegments. SATs bridge the gap between oversimplified global summaries and\noverly detailed local explanations, offering a practical tool for analysing and\ndebugging image classifiers.", "AI": {"tldr": "Segment Attribution Tables (SATs) summarize local saliency explanations into semi-global insights, bridging the gap between oversimplified global methods and overly detailed local explanations.", "motivation": "Deep learning models lack transparency in predictions. Local explanations (e.g., saliency maps) are too granular, while global methods oversimplify. SATs aim to provide a middle ground.", "method": "SATs use image segments (e.g., \"eyes\") and saliency maps to quantify segment influence, revealing model reliance on concepts and spurious correlations.", "result": "SATs highlight recurring patterns and spurious correlations (e.g., backgrounds or watermarks) without requiring changes in test performance.", "conclusion": "SATs offer a practical tool for analyzing and debugging image classifiers, balancing detail and simplicity."}}
{"id": "2506.23843", "pdf": "https://arxiv.org/pdf/2506.23843", "abs": "https://arxiv.org/abs/2506.23843", "authors": ["Joris Bekkers"], "title": "EFPI: Elastic Formation and Position Identification in Football (Soccer) using Template Matching and Linear Assignment", "categories": ["cs.LG"], "comment": null, "summary": "Understanding team formations and player positioning is crucial for tactical\nanalysis in football (soccer). This paper presents a flexible method for\nformation recognition and player position assignment in football using\npredefined static formation templates and cost minimization from spatiotemporal\ntracking data, called EFPI. Our approach employs linear sum assignment to\noptimally match players to positions within a set of template formations by\nminimizing the total distance between actual player locations and template\npositions, subsequently selecting the formation with the lowest assignment\ncost. To improve accuracy, we scale actual player positions to match the\ndimensions of these formation templates in both width and length. While the\nmethod functions effectively on individual frames, it extends naturally to\nlarger game segments such as complete periods, possession sequences or specific\nintervals (e.g. 10 second intervals, 5 minute intervals etc.). Additionally, we\nincorporate an optional stability parameter that prevents unnecessary formation\nchanges when assignment costs differ only marginally between time segments.\nEFPI is available as open-source code through the unravelsports Python package.", "AI": {"tldr": "EFPI is a method for recognizing football formations and assigning player positions using predefined templates and cost minimization from tracking data.", "motivation": "Understanding team formations and player positioning is crucial for tactical analysis in football.", "method": "Uses linear sum assignment to match players to template positions, scaling player locations to template dimensions, and includes a stability parameter to avoid unnecessary changes.", "result": "Effective for individual frames and larger game segments, with open-source implementation available.", "conclusion": "EFPI provides a flexible and accurate approach for formation recognition in football."}}
{"id": "2506.23207", "pdf": "https://arxiv.org/pdf/2506.23207", "abs": "https://arxiv.org/abs/2506.23207", "authors": ["Zhen Tan", "Xieyuanli Chen", "Lei Feng", "Yangbing Ge", "Shuaifeng Zhi", "Jiaxiong Liu", "Dewen Hu"], "title": "TVG-SLAM: Robust Gaussian Splatting SLAM with Tri-view Geometric Constraints", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in 3D Gaussian Splatting (3DGS) have enabled RGB-only SLAM\nsystems to achieve high-fidelity scene representation. However, the heavy\nreliance of existing systems on photometric rendering loss for camera tracking\nundermines their robustness, especially in unbounded outdoor environments with\nsevere viewpoint and illumination changes. To address these challenges, we\npropose TVG-SLAM, a robust RGB-only 3DGS SLAM system that leverages a novel\ntri-view geometry paradigm to ensure consistent tracking and high-quality\nmapping. We introduce a dense tri-view matching module that aggregates reliable\npairwise correspondences into consistent tri-view matches, forming robust\ngeometric constraints across frames. For tracking, we propose Hybrid Geometric\nConstraints, which leverage tri-view matches to construct complementary\ngeometric cues alongside photometric loss, ensuring accurate and stable pose\nestimation even under drastic viewpoint shifts and lighting variations. For\nmapping, we propose a new probabilistic initialization strategy that encodes\ngeometric uncertainty from tri-view correspondences into newly initialized\nGaussians. Additionally, we design a Dynamic Attenuation of Rendering Trust\nmechanism to mitigate tracking drift caused by mapping latency. Experiments on\nmultiple public outdoor datasets show that our TVG-SLAM outperforms prior\nRGB-only 3DGS-based SLAM systems. Notably, in the most challenging dataset, our\nmethod improves tracking robustness, reducing the average Absolute Trajectory\nError (ATE) by 69.0\\% while achieving state-of-the-art rendering quality. The\nimplementation of our method will be released as open-source.", "AI": {"tldr": "TVG-SLAM improves RGB-only 3DGS SLAM by using tri-view geometry for robust tracking and high-quality mapping, outperforming prior methods in challenging outdoor environments.", "motivation": "Existing RGB-only SLAM systems rely heavily on photometric loss, making them less robust in unbounded outdoor environments with viewpoint and illumination changes.", "method": "Introduces tri-view matching for geometric constraints, hybrid geometric constraints for tracking, probabilistic initialization for mapping, and dynamic attenuation to reduce drift.", "result": "Outperforms prior systems, reducing Absolute Trajectory Error by 69.0% in challenging datasets while maintaining high rendering quality.", "conclusion": "TVG-SLAM offers a robust solution for RGB-only SLAM in dynamic outdoor environments, with plans for open-source release."}}
{"id": "2506.24086", "pdf": "https://arxiv.org/pdf/2506.24086", "abs": "https://arxiv.org/abs/2506.24086", "authors": ["Bingfan Zhu", "Biao Jiang", "Sunyi Wang", "Shixiang Tang", "Tao Chen", "Linjie Luo", "Youyi Zheng", "Xin Chen"], "title": "MotionGPT3: Human Motion as a Second Modality", "categories": ["cs.CV", "cs.CL"], "comment": "21 pages, 8 figures", "summary": "Though recent advances in multimodal models have demonstrated strong\ncapabilities and opportunities in unified understanding and generation, the\ndevelopment of unified motion-language models remains underexplored. To enable\nsuch models with high-fidelity human motion, two core challenges must be\naddressed. The first is the reconstruction gap between the continuous motion\nmodality and discrete representation in an autoregressive manner, and the\nsecond is the degradation of language intelligence during unified training.\nInspired by the mixture of experts, we propose MotionGPT3, a bimodal\nmotion-language model that treats human motion as a second modality, decoupling\nmotion modeling via separate model parameters and enabling both effective\ncross-modal interaction and efficient multimodal scaling training. To preserve\nlanguage intelligence, the text branch retains the original structure and\nparameters of the pretrained language model, while a new motion branch is\nintegrated via a shared attention mechanism, enabling bidirectional information\nflow between two modalities. We first employ a motion Variational Autoencoder\n(VAE) to encode raw human motion into latent representations. Based on this\ncontinuous latent space, the motion branch predicts motion latents directly\nfrom intermediate hidden states using a diffusion head, bypassing discrete\ntokenization. Extensive experiments show that our approach achieves competitive\nperformance on both motion understanding and generation tasks while preserving\nstrong language capabilities, establishing a unified bimodal motion diffusion\nframework within an autoregressive manner.", "AI": {"tldr": "MotionGPT3 is a bimodal motion-language model addressing challenges in unified motion-language understanding and generation by decoupling motion modeling and preserving language intelligence.", "motivation": "To bridge the gap between continuous motion and discrete language representation and prevent degradation of language intelligence in unified training.", "method": "Uses a mixture of experts approach with separate motion and text branches, a motion VAE for encoding, and a diffusion head for motion prediction.", "result": "Achieves competitive performance in motion understanding and generation while maintaining strong language capabilities.", "conclusion": "Establishes a unified bimodal motion diffusion framework within an autoregressive manner."}}
{"id": "2506.23260", "pdf": "https://arxiv.org/pdf/2506.23260", "abs": "https://arxiv.org/abs/2506.23260", "authors": ["Mohamed Amine Ferrag", "Norbert Tihanyi", "Djallel Hamouda", "Leandros Maglaras", "Merouane Debbah"], "title": "From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows", "categories": ["cs.CR", "cs.AI"], "comment": "29 pages, 15 figures, 6 tables", "summary": "Autonomous AI agents powered by large language models (LLMs) with structured\nfunction-calling interfaces have dramatically expanded capabilities for\nreal-time data retrieval, complex computation, and multi-step orchestration.\nYet, the explosive proliferation of plugins, connectors, and inter-agent\nprotocols has outpaced discovery mechanisms and security practices, resulting\nin brittle integrations vulnerable to diverse threats. In this survey, we\nintroduce the first unified, end-to-end threat model for LLM-agent ecosystems,\nspanning host-to-tool and agent-to-agent communications, formalize adversary\ncapabilities and attacker objectives, and catalog over thirty attack\ntechniques. Specifically, we organized the threat model into four domains:\nInput Manipulation (e.g., prompt injections, long-context hijacks, multimodal\nadversarial inputs), Model Compromise (e.g., prompt- and parameter-level\nbackdoors, composite and encrypted multi-backdoors, poisoning strategies),\nSystem and Privacy Attacks (e.g., speculative side-channels, membership\ninference, retrieval poisoning, social-engineering simulations), and Protocol\nVulnerabilities (e.g., exploits in Model Context Protocol (MCP), Agent\nCommunication Protocol (ACP), Agent Network Protocol (ANP), and Agent-to-Agent\n(A2A) protocol). For each category, we review representative scenarios, assess\nreal-world feasibility, and evaluate existing defenses. Building on our threat\ntaxonomy, we identify key open challenges and future research directions, such\nas securing MCP deployments through dynamic trust management and cryptographic\nprovenance tracking; designing and hardening Agentic Web Interfaces; and\nachieving resilience in multi-agent and federated environments. Our work\nprovides a comprehensive reference to guide the design of robust defense\nmechanisms and establish best practices for resilient LLM-agent workflows.", "AI": {"tldr": "A survey introduces a unified threat model for LLM-agent ecosystems, categorizing over thirty attack techniques across four domains, and proposes future research directions for securing such systems.", "motivation": "The rapid expansion of LLM-agent capabilities has outpaced security practices, leading to vulnerabilities in integrations and protocols.", "method": "The paper formalizes adversary capabilities, attacker objectives, and catalogs attack techniques, organizing them into four threat domains.", "result": "A comprehensive threat taxonomy is presented, along with evaluations of real-world feasibility and existing defenses.", "conclusion": "The work serves as a reference for designing robust defenses and best practices for resilient LLM-agent workflows, highlighting open challenges and future research directions."}}
{"id": "2506.23872", "pdf": "https://arxiv.org/pdf/2506.23872", "abs": "https://arxiv.org/abs/2506.23872", "authors": ["Eduard Buss", "Till Aust", "Heiko Hamann"], "title": "When Plants Respond: Electrophysiology and Machine Learning for Green Monitoring Systems", "categories": ["cs.LG"], "comment": "Submitted and Accepted at the 14th international conference on\n  biomimetic and biohybrid systems (Living Machines)", "summary": "Living plants, while contributing to ecological balance and climate\nregulation, also function as natural sensors capable of transmitting\ninformation about their internal physiological states and surrounding\nconditions. This rich source of data provides potential for applications in\nenvironmental monitoring and precision agriculture. With integration into\nbiohybrid systems, we establish novel channels of physiological signal flow\nbetween living plants and artificial devices. We equipped *Hedera helix* with a\nplant-wearable device called PhytoNode to continuously record the plant's\nelectrophysiological activity. We deployed plants in an uncontrolled outdoor\nenvironment to map electrophysiological patterns to environmental conditions.\nOver five months, we collected data that we analyzed using state-of-the-art and\nautomated machine learning (AutoML). Our classification models achieve high\nperformance, reaching macro F1 scores of up to 95 percent in binary tasks.\nAutoML approaches outperformed manual tuning, and selecting subsets of\nstatistical features further improved accuracy. Our biohybrid living system\nmonitors the electrophysiology of plants in harsh, real-world conditions. This\nwork advances scalable, self-sustaining, and plant-integrated living biohybrid\nsystems for sustainable environmental monitoring.", "AI": {"tldr": "The paper explores using plants as natural sensors for environmental monitoring, integrating them with wearable devices (PhytoNode) to record electrophysiological data. Machine learning, especially AutoML, achieved high accuracy (95% F1 score) in classifying environmental conditions.", "motivation": "To leverage plants as natural sensors for ecological and agricultural applications, bridging the gap between biological and artificial systems for sustainable monitoring.", "method": "Equipped *Hedera helix* with PhytoNode to record electrophysiological activity outdoors. Used AutoML and manual tuning to analyze data over five months.", "result": "High classification performance (95% F1 score) with AutoML outperforming manual tuning. Feature selection further improved accuracy.", "conclusion": "The biohybrid system successfully monitors plant electrophysiology in real-world conditions, advancing scalable, sustainable environmental monitoring solutions."}}
{"id": "2506.23209", "pdf": "https://arxiv.org/pdf/2506.23209", "abs": "https://arxiv.org/abs/2506.23209", "authors": ["Chia-Wen Huang", "Haw Hwai", "Chien-Chang Lee", "Pei-Yuan Wu"], "title": "A Hierarchical Slice Attention Network for Appendicitis Classification in 3D CT Scans", "categories": ["cs.CV"], "comment": "8 pages, 1 figure, 3 tables. Published in IEEE ISBI 2025. This\n  version corrects citation numbering errors", "summary": "Timely and accurate diagnosis of appendicitis is critical in clinical\nsettings to prevent serious complications. While CT imaging remains the\nstandard diagnostic tool, the growing number of cases can overwhelm\nradiologists, potentially causing delays. In this paper, we propose a deep\nlearning model that leverages 3D CT scans for appendicitis classification,\nincorporating Slice Attention mechanisms guided by external 2D datasets to\nenhance small lesion detection. Additionally, we introduce a hierarchical\nclassification framework using pre-trained 2D models to differentiate between\nsimple and complicated appendicitis. Our approach improves AUC by 3% for\nappendicitis and 5.9% for complicated appendicitis, offering a more efficient\nand reliable diagnostic solution compared to previous work.", "AI": {"tldr": "A deep learning model using 3D CT scans and Slice Attention improves appendicitis diagnosis, achieving higher AUC scores.", "motivation": "Timely and accurate appendicitis diagnosis is crucial to prevent complications, but CT imaging overloads radiologists, causing delays.", "method": "Proposes a deep learning model with 3D CT scans and Slice Attention, guided by 2D datasets, and a hierarchical framework for classification.", "result": "Improves AUC by 3% for appendicitis and 5.9% for complicated appendicitis.", "conclusion": "The model offers a more efficient and reliable diagnostic solution compared to prior methods."}}
{"id": "2305.16264", "pdf": "https://arxiv.org/pdf/2305.16264", "abs": "https://arxiv.org/abs/2305.16264", "authors": ["Niklas Muennighoff", "Alexander M. Rush", "Boaz Barak", "Teven Le Scao", "Aleksandra Piktus", "Nouamane Tazi", "Sampo Pyysalo", "Thomas Wolf", "Colin Raffel"], "title": "Scaling Data-Constrained Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "50 pages (9 main), 39 figures, 15 tables", "summary": "The current trend of scaling language models involves increasing both\nparameter count and training dataset size. Extrapolating this trend suggests\nthat training dataset size may soon be limited by the amount of text data\navailable on the internet. Motivated by this limit, we investigate scaling\nlanguage models in data-constrained regimes. Specifically, we run a large set\nof experiments varying the extent of data repetition and compute budget,\nranging up to 900 billion training tokens and 9 billion parameter models. We\nfind that with constrained data for a fixed compute budget, training with up to\n4 epochs of repeated data yields negligible changes to loss compared to having\nunique data. However, with more repetition, the value of adding compute\neventually decays to zero. We propose and empirically validate a scaling law\nfor compute optimality that accounts for the decreasing value of repeated\ntokens and excess parameters. Finally, we experiment with approaches mitigating\ndata scarcity, including augmenting the training dataset with code data or\nremoving commonly used filters. Models and datasets from our 400 training runs\nare freely available at https://github.com/huggingface/datablations.", "AI": {"tldr": "Scaling language models faces data constraints as internet text data may soon limit training datasets. Experiments show repeated data (up to 4 epochs) has minimal impact on loss, but excessive repetition diminishes compute value. A new scaling law accounts for repeated tokens and excess parameters. Mitigation strategies like code data augmentation are explored.", "motivation": "The potential limitation of available internet text data for training large language models motivates investigating scaling in data-constrained regimes.", "method": "Conducted experiments varying data repetition (up to 900B tokens) and compute budget (up to 9B parameters), analyzing loss and compute value. Proposed a scaling law for compute optimality.", "result": "Up to 4 epochs of repeated data yield negligible loss changes, but excessive repetition reduces compute value. A validated scaling law addresses repeated tokens and excess parameters.", "conclusion": "Data repetition is viable to a point, but new scaling laws and mitigation strategies (e.g., code augmentation) are needed for data-constrained scaling."}}
{"id": "2506.23270", "pdf": "https://arxiv.org/pdf/2506.23270", "abs": "https://arxiv.org/abs/2506.23270", "authors": ["Yi Li", "Hualiang Wang", "Xinpeng Ding", "Haonan Wang", "Xiaomeng Li"], "title": "Token Activation Map to Visually Explain Multimodal LLMs", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "ICCV2025 Accepted", "summary": "Multimodal large language models (MLLMs) are broadly empowering various\nfields. Despite their advancements, the explainability of MLLMs remains less\nexplored, hindering deeper understanding, model credibility, and effective\nvisualization. Unlike conventional vision models (e.g., CNNs, ViTs, CLIP) that\nproduce a single output, MLLMs generate sequences of tokens progressively,\nwhere each generated token depends on the previous context. Therefore, earlier\ncontext tokens can introduce redundant activations that interfere with the\nexplanation of later tokens beyond their original information. Existing studies\noften overlook this issue, but our observations reveal that these redundant\ncorrelations can significantly hurt the reliability of explanations. To address\nthis, we propose an estimated causal inference method to mitigate the\ninterference of context to achieve high-quality MLLM explanation, with a novel\nrank Gaussian filter to further reduce activation noises. We term this method\nToken Activation Map (TAM) to highlight the consideration of interactions\nbetween tokens. TAM also indicates that it excels at explaining multiple tokens\nof MLLM, which is different from the Class Activation Map (CAM) for a single\nprediction. Our TAM method significantly outperforms existing SoTA methods,\nshowcasing high-quality visualization results that can be utilized for various\nscenarios, such as object localization, failure case analysis, video\nvisualization, MLLMs visual comparison, and model understanding (e.g., color,\nshape, action, location, visual reasoning, multi-turn conversation, etc). The\ncode is available atgithub.com/xmed-lab/TAM.", "AI": {"tldr": "The paper introduces Token Activation Map (TAM), a method to improve the explainability of Multimodal Large Language Models (MLLMs) by addressing redundant activations and enhancing visualization quality.", "motivation": "The explainability of MLLMs is understudied, and redundant activations from earlier tokens interfere with reliable explanations, affecting model credibility and understanding.", "method": "Proposes an estimated causal inference method and a rank Gaussian filter to mitigate context interference and reduce activation noises, termed Token Activation Map (TAM).", "result": "TAM outperforms existing methods, providing high-quality visualizations for tasks like object localization, failure analysis, and model understanding.", "conclusion": "TAM effectively addresses the explainability challenges in MLLMs, offering versatile applications and superior performance over current methods."}}
{"id": "2506.23875", "pdf": "https://arxiv.org/pdf/2506.23875", "abs": "https://arxiv.org/abs/2506.23875", "authors": ["Yuta Sato", "Kazuhiko Kawamoto", "Hiroshi Kera"], "title": "Chain of Thought in Order: Discovering Learning-Friendly Orders for Arithmetic", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 10 figures", "summary": "The chain of thought is fundamental in Transformers, which is to perform\nstep-by-step reasoning. Besides what intermediate steps work, the order of\nthese steps critically affects the difficulty of the reasoning. This study\naddresses a novel task of unraveling chain of thought - reordering decoder\ninput tokens to a learning-friendly sequence for Transformers to learn\narithmetic tasks. The proposed pipeline first trains a Transformer on a mixture\nof target sequences arranged in different orders and then identifies benign\norders as those with fast loss drops in the early stage. As the search space\ngrows factorially with sequence length, we propose a two-stage hierarchical\napproach for inter- and intra-block reordering. Experiments on four\norder-sensitive arithmetic tasks show that our method identifies a\nlearning-friendly order out of a few billion candidates. Notably, on the\nmultiplication task, it recovered the reverse-digit order reported in prior\nstudies.", "AI": {"tldr": "The study introduces a method to reorder decoder input tokens in Transformers to improve learning of arithmetic tasks by identifying learning-friendly sequences through early loss drop analysis.", "motivation": "The order of intermediate steps in the chain of thought critically impacts reasoning difficulty in Transformers, prompting the need for optimized token sequences.", "method": "A pipeline trains a Transformer on mixed-order sequences, identifies benign orders via early loss drops, and uses a hierarchical approach for efficient reordering.", "result": "The method successfully identifies learning-friendly orders from billions of candidates, even recovering the reverse-digit order for multiplication.", "conclusion": "Optimizing token order in Transformers enhances learning efficiency, as demonstrated in arithmetic tasks, validating the importance of sequence arrangement."}}
{"id": "2506.23227", "pdf": "https://arxiv.org/pdf/2506.23227", "abs": "https://arxiv.org/abs/2506.23227", "authors": ["Lunhao Duan", "Shanshan Zhao", "Xingxing Weng", "Jing Zhang", "Gui-Song Xia"], "title": "High-quality Pseudo-labeling for Point Cloud Segmentation with Scene-level Annotation", "categories": ["cs.CV"], "comment": "Accepted by TPAMI. Code: https://github.com/LHDuan/WSegPC", "summary": "This paper investigates indoor point cloud semantic segmentation under\nscene-level annotation, which is less explored compared to methods relying on\nsparse point-level labels. In the absence of precise point-level labels,\ncurrent methods first generate point-level pseudo-labels, which are then used\nto train segmentation models. However, generating accurate pseudo-labels for\neach point solely based on scene-level annotations poses a considerable\nchallenge, substantially affecting segmentation performance. Consequently, to\nenhance accuracy, this paper proposes a high-quality pseudo-label generation\nframework by exploring contemporary multi-modal information and region-point\nsemantic consistency. Specifically, with a cross-modal feature guidance module,\nour method utilizes 2D-3D correspondences to align point cloud features with\ncorresponding 2D image pixels, thereby assisting point cloud feature learning.\nTo further alleviate the challenge presented by the scene-level annotation, we\nintroduce a region-point semantic consistency module. It produces regional\nsemantics through a region-voting strategy derived from point-level semantics,\nwhich are subsequently employed to guide the point-level semantic predictions.\nLeveraging the aforementioned modules, our method can rectify inaccurate\npoint-level semantic predictions during training and obtain high-quality\npseudo-labels. Significant improvements over previous works on ScanNet v2 and\nS3DIS datasets under scene-level annotation can demonstrate the effectiveness.\nAdditionally, comprehensive ablation studies validate the contributions of our\napproach's individual components. The code is available at\nhttps://github.com/LHDuan/WSegPC .", "AI": {"tldr": "The paper proposes a framework for indoor point cloud semantic segmentation using scene-level annotations, improving pseudo-label accuracy via multi-modal information and region-point consistency.", "motivation": "Current methods struggle with accurate pseudo-label generation from scene-level annotations, impacting segmentation performance.", "method": "The framework uses cross-modal feature guidance and region-point semantic consistency to enhance pseudo-label quality.", "result": "Significant improvements on ScanNet v2 and S3DIS datasets, validated by ablation studies.", "conclusion": "The method effectively addresses challenges of scene-level annotation, outperforming prior works."}}
{"id": "2404.19543", "pdf": "https://arxiv.org/pdf/2404.19543", "abs": "https://arxiv.org/abs/2404.19543", "authors": ["Yucheng Hu", "Yuxing Lu"], "title": "RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing", "categories": ["cs.CL", "cs.AI"], "comment": "30 pages, 7 figures. Draft version 1", "summary": "Large Language Models (LLMs) have catalyzed significant advancements in\nNatural Language Processing (NLP), yet they encounter challenges such as\nhallucination and the need for domain-specific knowledge. To mitigate these,\nrecent methodologies have integrated information retrieved from external\nresources with LLMs, substantially enhancing their performance across NLP\ntasks. This survey paper addresses the absence of a comprehensive overview on\nRetrieval-Augmented Language Models (RALMs), both Retrieval-Augmented\nGeneration (RAG) and Retrieval-Augmented Understanding (RAU), providing an\nin-depth examination of their paradigm, evolution, taxonomy, and applications.\nThe paper discusses the essential components of RALMs, including Retrievers,\nLanguage Models, and Augmentations, and how their interactions lead to diverse\nmodel structures and applications. RALMs demonstrate utility in a spectrum of\ntasks, from translation and dialogue systems to knowledge-intensive\napplications. The survey includes several evaluation methods of RALMs,\nemphasizing the importance of robustness, accuracy, and relevance in their\nassessment. It also acknowledges the limitations of RALMs, particularly in\nretrieval quality and computational efficiency, offering directions for future\nresearch. In conclusion, this survey aims to offer a structured insight into\nRALMs, their potential, and the avenues for their future development in NLP.\nThe paper is supplemented with a Github Repository containing the surveyed\nworks and resources for further study:\nhttps://github.com/2471023025/RALM_Survey.", "AI": {"tldr": "This survey paper provides a comprehensive overview of Retrieval-Augmented Language Models (RALMs), covering their paradigm, evolution, taxonomy, applications, and evaluation methods, while also addressing limitations and future directions.", "motivation": "To address the lack of a detailed overview of RALMs (Retrieval-Augmented Generation and Retrieval-Augmented Understanding) and their role in mitigating challenges like hallucination and domain-specific knowledge gaps in LLMs.", "method": "The paper examines the components of RALMs (Retrievers, Language Models, Augmentations) and their interactions, alongside applications in tasks like translation and dialogue systems. It also reviews evaluation methods focusing on robustness, accuracy, and relevance.", "result": "RALMs enhance performance in NLP tasks but face limitations in retrieval quality and computational efficiency.", "conclusion": "The survey offers structured insights into RALMs, their potential, and future research directions, supported by a GitHub repository for further study."}}
{"id": "2506.23275", "pdf": "https://arxiv.org/pdf/2506.23275", "abs": "https://arxiv.org/abs/2506.23275", "authors": ["Chengyou Jia", "Xin Shen", "Zhuohang Dang", "Zhuohang Dang", "Changliang Xia", "Weijia Wu", "Xinyu Zhang", "Hangwei Qian", "Ivor W. Tsang", "Minnan Luo"], "title": "Why Settle for One? Text-to-ImageSet Generation and Evaluation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Despite remarkable progress in Text-to-Image models, many real-world\napplications require generating coherent image sets with diverse consistency\nrequirements. Existing consistent methods often focus on a specific domain with\nspecific aspects of consistency, which significantly constrains their\ngeneralizability to broader applications. In this paper, we propose a more\nchallenging problem, Text-to-ImageSet (T2IS) generation, which aims to generate\nsets of images that meet various consistency requirements based on user\ninstructions. To systematically study this problem, we first introduce\n$\\textbf{T2IS-Bench}$ with 596 diverse instructions across 26 subcategories,\nproviding comprehensive coverage for T2IS generation. Building on this, we\npropose $\\textbf{T2IS-Eval}$, an evaluation framework that transforms user\ninstructions into multifaceted assessment criteria and employs effective\nevaluators to adaptively assess consistency fulfillment between criteria and\ngenerated sets. Subsequently, we propose $\\textbf{AutoT2IS}$, a training-free\nframework that maximally leverages pretrained Diffusion Transformers'\nin-context capabilities to harmonize visual elements to satisfy both\nimage-level prompt alignment and set-level visual consistency. Extensive\nexperiments on T2IS-Bench reveal that diverse consistency challenges all\nexisting methods, while our AutoT2IS significantly outperforms current\ngeneralized and even specialized approaches. Our method also demonstrates the\nability to enable numerous underexplored real-world applications, confirming\nits substantial practical value. Visit our project in\nhttps://chengyou-jia.github.io/T2IS-Home.", "AI": {"tldr": "The paper introduces Text-to-ImageSet (T2IS) generation, a challenging problem for creating coherent image sets with diverse consistency requirements. It proposes T2IS-Bench, T2IS-Eval, and AutoT2IS to address this, outperforming existing methods.", "motivation": "Existing methods for consistent image generation are domain-specific, limiting generalizability. The paper aims to tackle the broader problem of generating image sets with varied consistency needs based on user instructions.", "method": "The authors introduce T2IS-Bench for diverse instructions, T2IS-Eval for evaluation, and AutoT2IS, a training-free framework leveraging Diffusion Transformers for consistency.", "result": "AutoT2IS outperforms existing methods on T2IS-Bench, addressing diverse consistency challenges and enabling real-world applications.", "conclusion": "The proposed framework significantly advances T2IS generation, demonstrating practical value and outperforming specialized approaches."}}
{"id": "2506.23923", "pdf": "https://arxiv.org/pdf/2506.23923", "abs": "https://arxiv.org/abs/2506.23923", "authors": ["Miguel Camacho-S\u00e1nchez", "Fernando Garc\u00eda-Torres", "Jesper John Lisegaard", "Roc\u00edo del Amor", "Sankhya Mohanty", "Valery Naranjo"], "title": "Reinforcement Learning for Synchronised Flow Control in a Dual-Gate Resin Infusion System", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 4 figures, 45th Ris{\\o} International Symposium on\n  Materials Science", "summary": "Resin infusion (RI) and resin transfer moulding (RTM) are critical processes\nfor the manufacturing of high-performance fibre-reinforced polymer composites,\nparticularly for large-scale applications such as wind turbine blades.\nControlling the resin flow dynamics in these processes is critical to ensure\nthe uniform impregnation of the fibre reinforcements, thereby preventing\nresidual porosities and dry spots that impact the consequent structural\nintegrity of the final component. This paper presents a reinforcement learning\n(RL) based strategy, established using process simulations, for synchronising\nthe different resin flow fronts in an infusion scenario involving two resin\ninlets and a single outlet. Using Proximal Policy Optimisation (PPO), our\napproach addresses the challenge of managing the fluid dynamics in a partially\nobservable environment. The results demonstrate the effectiveness of the RL\napproach in achieving an accurate flow convergence, highlighting its potential\ntowards improving process control and product quality in composites\nmanufacturing.", "AI": {"tldr": "A reinforcement learning (RL) strategy using Proximal Policy Optimisation (PPO) is proposed to control resin flow dynamics in resin infusion (RI) and resin transfer moulding (RTM) processes, ensuring uniform impregnation and improving product quality.", "motivation": "To address the challenge of managing resin flow dynamics in composites manufacturing, which is critical for preventing defects like porosities and dry spots.", "method": "A reinforcement learning approach (PPO) is used to synchronize resin flow fronts in a simulation of a two-inlet, single-outlet infusion scenario.", "result": "The RL strategy effectively achieves accurate flow convergence, demonstrating potential for enhanced process control.", "conclusion": "The RL-based approach shows promise for improving resin infusion processes, ensuring better structural integrity and product quality in composites manufacturing."}}
{"id": "2506.23252", "pdf": "https://arxiv.org/pdf/2506.23252", "abs": "https://arxiv.org/abs/2506.23252", "authors": ["Kunwei Lv", "Ping Lan"], "title": "DGE-YOLO: Dual-Branch Gathering and Attention for Accurate UAV Object Detection", "categories": ["cs.CV"], "comment": "8 pages, 5 figures", "summary": "The rapid proliferation of unmanned aerial vehicles (UAVs) has highlighted\nthe importance of robust and efficient object detection in diverse aerial\nscenarios. Detecting small objects under complex conditions, however, remains a\nsignificant challenge. Existing approaches often prioritize inference speed,\nleading to degraded performance when handling multi-modal inputs. To address\nthis, we present DGE-YOLO, an enhanced YOLO-based detection framework designed\nto effectively fuse multi-modal information. Specifically, we introduce a\ndual-branch architecture for modality-specific feature extraction, enabling the\nmodel to process both infrared and visible images. To further enrich semantic\nrepresentation, we propose an Efficient Multi-scale Attention (EMA) mechanism\nthat enhances feature learning across spatial scales. Additionally, we replace\nthe conventional neck with a Gather-and-Distribute module to mitigate\ninformation loss during feature aggregation. Extensive experiments on the Drone\nVehicle dataset demonstrate that DGE-YOLO achieves superior performance over\nstate-of-the-art methods, validating its effectiveness in multi-modal UAV\nobject detection tasks.", "AI": {"tldr": "DGE-YOLO is an enhanced YOLO-based framework for multi-modal UAV object detection, featuring dual-branch architecture, EMA mechanism, and Gather-and-Distribute module, outperforming state-of-the-art methods.", "motivation": "The challenge of detecting small objects in complex aerial scenarios with multi-modal inputs, where existing methods sacrifice performance for speed.", "method": "DGE-YOLO introduces a dual-branch architecture for modality-specific feature extraction, an EMA mechanism for multi-scale attention, and a Gather-and-Distribute module to reduce information loss.", "result": "Outperforms state-of-the-art methods on the Drone Vehicle dataset, demonstrating effectiveness in multi-modal UAV object detection.", "conclusion": "DGE-YOLO effectively addresses the challenges of multi-modal UAV object detection, offering superior performance and robust feature fusion."}}
{"id": "2405.01299", "pdf": "https://arxiv.org/pdf/2405.01299", "abs": "https://arxiv.org/abs/2405.01299", "authors": ["Maja Pavlovic", "Massimo Poesio"], "title": "The Effectiveness of LLMs as Annotators: A Comparative Overview and Empirical Analysis of Direct Representation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "LREC-COLING NLPerspectives workshop", "summary": "Large Language Models (LLMs) have emerged as powerful support tools across\nvarious natural language tasks and a range of application domains. Recent\nstudies focus on exploring their capabilities for data annotation. This paper\nprovides a comparative overview of twelve studies investigating the potential\nof LLMs in labelling data. While the models demonstrate promising cost and\ntime-saving benefits, there exist considerable limitations, such as\nrepresentativeness, bias, sensitivity to prompt variations and English language\npreference. Leveraging insights from these studies, our empirical analysis\nfurther examines the alignment between human and GPT-generated opinion\ndistributions across four subjective datasets. In contrast to the studies\nexamining representation, our methodology directly obtains the opinion\ndistribution from GPT. Our analysis thereby supports the minority of studies\nthat are considering diverse perspectives when evaluating data annotation tasks\nand highlights the need for further research in this direction.", "AI": {"tldr": "The paper compares twelve studies on LLMs for data annotation, highlighting their benefits and limitations, and examines human-GPT opinion alignment in subjective datasets.", "motivation": "To explore LLMs' potential in data annotation and address gaps like bias and representativeness.", "method": "Comparative overview of twelve studies and empirical analysis of human-GPT opinion distributions in four datasets.", "result": "LLMs show cost and time benefits but have limitations like bias and prompt sensitivity. Human-GPT alignment varies.", "conclusion": "Further research is needed to address LLMs' limitations and incorporate diverse perspectives in annotation tasks."}}
{"id": "2506.23296", "pdf": "https://arxiv.org/pdf/2506.23296", "abs": "https://arxiv.org/abs/2506.23296", "authors": ["Naoto Kiribuchi", "Kengo Zenitani", "Takayuki Semitsu"], "title": "Securing AI Systems: A Guide to Known Attacks and Impacts", "categories": ["cs.CR", "cs.AI"], "comment": "34 pages, 16 figures", "summary": "Embedded into information systems, artificial intelligence (AI) faces\nsecurity threats that exploit AI-specific vulnerabilities. This paper provides\nan accessible overview of adversarial attacks unique to predictive and\ngenerative AI systems. We identify eleven major attack types and explicitly\nlink attack techniques to their impacts -- including information leakage,\nsystem compromise, and resource exhaustion -- mapped to the confidentiality,\nintegrity, and availability (CIA) security triad. We aim to equip researchers,\ndevelopers, security practitioners, and policymakers, even those without\nspecialized AI security expertise, with foundational knowledge to recognize\nAI-specific risks and implement effective defenses, thereby enhancing the\noverall security posture of AI systems.", "AI": {"tldr": "Overview of adversarial attacks on AI systems, linking techniques to impacts and mapping them to the CIA triad for broader understanding and defense.", "motivation": "To address AI-specific security threats by providing accessible knowledge for recognizing risks and implementing defenses.", "method": "Identifies eleven major attack types and links techniques to impacts (e.g., information leakage, system compromise).", "result": "Maps attacks to the CIA triad (confidentiality, integrity, availability) for comprehensive understanding.", "conclusion": "Equips non-experts with foundational knowledge to enhance AI system security."}}
{"id": "2506.23958", "pdf": "https://arxiv.org/pdf/2506.23958", "abs": "https://arxiv.org/abs/2506.23958", "authors": ["Ikechukwu Ogbonna", "Lesley Davidson", "Soumya Banerjee", "Abhishek Dasgupta", "Laurence Kenney", "Vikranth Harthikote Nagaraja"], "title": "Bridging the Gap with Retrieval-Augmented Generation: Making Prosthetic Device User Manuals Available in Marginalised Languages", "categories": ["cs.LG"], "comment": "5 pages, 0 figures, 0 tables", "summary": "Millions of people in African countries face barriers to accessing healthcare\ndue to language and literacy gaps. This research tackles this challenge by\ntransforming complex medical documents -- in this case, prosthetic device user\nmanuals -- into accessible formats for underserved populations. This case study\nin cross-cultural translation is particularly pertinent/relevant for\ncommunities that receive donated prosthetic devices but may not receive the\naccompanying user documentation. Or, if available online, may only be available\nin formats (e.g., language and readability) that are inaccessible to local\npopulations (e.g., English-language, high resource settings/cultural context).\nThe approach is demonstrated using the widely spoken Pidgin dialect, but our\nopen-source framework has been designed to enable rapid and easy extension to\nother languages/dialects. This work presents an AI-powered framework designed\nto process and translate complex medical documents, e.g., user manuals for\nprosthetic devices, into marginalised languages. The system enables users --\nsuch as healthcare workers or patients -- to upload English-language medical\nequipment manuals, pose questions in their native language, and receive\naccurate, localised answers in real time. Technically, the system integrates a\nRetrieval-Augmented Generation (RAG) pipeline for processing and semantic\nunderstanding of the uploaded manuals. It then employs advanced Natural\nLanguage Processing (NLP) models for generative question-answering and\nmultilingual translation. Beyond simple translation, it ensures accessibility\nto device instructions, treatment protocols, and safety information, empowering\npatients and clinicians to make informed healthcare decisions.", "AI": {"tldr": "AI-powered framework translates complex medical documents into marginalized languages, improving healthcare access for underserved populations.", "motivation": "Address language and literacy gaps in African countries by making prosthetic device manuals accessible.", "method": "Uses a Retrieval-Augmented Generation (RAG) pipeline and NLP models for translation and question-answering.", "result": "Enables real-time, localized answers in native languages for medical queries.", "conclusion": "The framework empowers patients and clinicians with accessible healthcare information, scalable to other languages."}}
{"id": "2506.23257", "pdf": "https://arxiv.org/pdf/2506.23257", "abs": "https://arxiv.org/abs/2506.23257", "authors": ["Chongke Bi", "Xin Gao", "Baofeng Fu", "Yuheng Zhao", "Siming Chen", "Ying Zhao", "Yunhai Wang"], "title": "PCLVis: Visual Analytics of Process Communication Latency in Large-Scale Simulation", "categories": ["cs.CV"], "comment": null, "summary": "Large-scale simulations on supercomputers have become important tools for\nusers. However, their scalability remains a problem due to the huge\ncommunication cost among parallel processes. Most of the existing communication\nlatency analysis methods rely on the physical link layer information, which is\nonly available to administrators. In this paper, a framework called PCLVis is\nproposed to help general users analyze process communication latency (PCL)\nevents. Instead of the physical link layer information, the PCLVis uses the MPI\nprocess communication data for the analysis. First, a spatial PCL event\nlocating method is developed. All processes with high correlation are\nclassified into a single cluster by constructing a process-correlation tree.\nSecond, the propagation path of PCL events is analyzed by constructing a\ncommunication-dependency-based directed acyclic graph (DAG), which can help\nusers interactively explore a PCL event from the temporal evolution of a\nlocated PCL event cluster. In this graph, a sliding window algorithm is\ndesigned to generate the PCL events abstraction. Meanwhile, a new glyph called\nthe communication state glyph (CS-Glyph) is designed for each process to show\nits communication states, including its in/out messages and load balance. Each\nleaf node can be further unfolded to view additional information. Third, a PCL\nevent attribution strategy is formulated to help users optimize their\nsimulations. The effectiveness of the PCLVis framework is demonstrated by\nanalyzing the PCL events of several simulations running on the TH-1A\nsupercomputer. By using the proposed framework, users can greatly improve the\nefficiency of their simulations.", "AI": {"tldr": "PCLVis is a framework for analyzing process communication latency (PCL) in large-scale simulations using MPI data, aiding users in optimizing simulations without physical link layer access.", "motivation": "Address scalability issues in supercomputer simulations caused by high communication costs, providing a tool for general users to analyze PCL events without administrative privileges.", "method": "Uses MPI process communication data, spatial PCL event locating, process-correlation tree clustering, communication-dependency DAG, sliding window algorithm for event abstraction, and CS-Glyphs for visualization.", "result": "Demonstrated effectiveness on TH-1A supercomputer, enabling users to optimize simulations by identifying and addressing PCL events.", "conclusion": "PCLVis improves simulation efficiency by providing actionable insights into communication latency, accessible to general users."}}
{"id": "2406.15627", "pdf": "https://arxiv.org/pdf/2406.15627", "abs": "https://arxiv.org/abs/2406.15627", "authors": ["Roman Vashurin", "Ekaterina Fadeeva", "Artem Vazhentsev", "Lyudmila Rvanova", "Akim Tsvigun", "Daniil Vasilev", "Rui Xing", "Abdelrahman Boda Sadallah", "Kirill Grishchenkov", "Sergey Petrakov", "Alexander Panchenko", "Timothy Baldwin", "Preslav Nakov", "Maxim Panov", "Artem Shelmanov"], "title": "Benchmarking Uncertainty Quantification Methods for Large Language Models with LM-Polygraph", "categories": ["cs.CL", "cs.LG"], "comment": "Published at TACL 2025, presented at ACL 2025. Roman Vashurin,\n  Ekaterina Fadeeva, Artem Vazhentsev contributed equally", "summary": "The rapid proliferation of large language models (LLMs) has stimulated\nresearchers to seek effective and efficient approaches to deal with LLM\nhallucinations and low-quality outputs. Uncertainty quantification (UQ) is a\nkey element of machine learning applications in dealing with such challenges.\nHowever, research to date on UQ for LLMs has been fragmented in terms of\ntechniques and evaluation methodologies. In this work, we address this issue by\nintroducing a novel benchmark that implements a collection of state-of-the-art\nUQ baselines and offers an environment for controllable and consistent\nevaluation of novel UQ techniques over various text generation tasks. Our\nbenchmark also supports the assessment of confidence normalization methods in\nterms of their ability to provide interpretable scores. Using our benchmark, we\nconduct a large-scale empirical investigation of UQ and normalization\ntechniques across eleven tasks, identifying the most effective approaches.\nCode: https://github.com/IINemo/lm-polygraph Benchmark:\nhttps://huggingface.co/LM-Polygraph", "AI": {"tldr": "A new benchmark for evaluating uncertainty quantification (UQ) techniques in large language models (LLMs) is introduced to address fragmented research and improve consistency in assessing UQ methods.", "motivation": "The rapid growth of LLMs has highlighted challenges like hallucinations and low-quality outputs, necessitating better UQ techniques. Current research lacks consistency in methods and evaluation.", "method": "The authors propose a benchmark that includes state-of-the-art UQ baselines and supports controlled evaluation across text generation tasks, including confidence normalization assessment.", "result": "A large-scale empirical study evaluates UQ and normalization techniques across eleven tasks, identifying the most effective approaches.", "conclusion": "The benchmark provides a unified framework for evaluating UQ in LLMs, aiding in the development of more reliable and interpretable models."}}
{"id": "2506.23314", "pdf": "https://arxiv.org/pdf/2506.23314", "abs": "https://arxiv.org/abs/2506.23314", "authors": ["Joner Assolin", "Gabriel Canto", "Diego Kreutz", "Eduardo Feitosa", "Hendrio Bragan\u00e7a", "Angelo Nogueira", "Vanderson Rocha"], "title": "Interpretable by Design: MH-AutoML for Transparent and Efficient Android Malware Detection without Compromising Performance", "categories": ["cs.CR", "cs.AI", "68T99", "I.2"], "comment": "18 pages, 10 figures, 7 tabelas, paper submitted to JBCS", "summary": "Malware detection in Android systems requires both cybersecurity expertise\nand machine learning (ML) techniques. Automated Machine Learning (AutoML) has\nemerged as an approach to simplify ML development by reducing the need for\nspecialized knowledge. However, current AutoML solutions typically operate as\nblack-box systems with limited transparency, interpretability, and experiment\ntraceability. To address these limitations, we present MH-AutoML, a\ndomain-specific framework for Android malware detection. MH-AutoML automates\nthe entire ML pipeline, including data preprocessing, feature engineering,\nalgorithm selection, and hyperparameter tuning. The framework incorporates\ncapabilities for interpretability, debugging, and experiment tracking that are\noften missing in general-purpose solutions. In this study, we compare MH-AutoML\nagainst seven established AutoML frameworks: Auto-Sklearn, AutoGluon, TPOT,\nHyperGBM, Auto-PyTorch, LightAutoML, and MLJAR. Results show that MH-AutoML\nachieves better recall rates while providing more transparency and control. The\nframework maintains computational efficiency comparable to other solutions,\nmaking it suitable for cybersecurity applications where both performance and\nexplainability matter.", "AI": {"tldr": "MH-AutoML is a domain-specific AutoML framework for Android malware detection, offering transparency, interpretability, and better recall rates compared to existing AutoML solutions.", "motivation": "Current AutoML solutions lack transparency, interpretability, and traceability, which are critical for cybersecurity applications like malware detection.", "method": "MH-AutoML automates the ML pipeline (data preprocessing, feature engineering, algorithm selection, hyperparameter tuning) and includes interpretability, debugging, and experiment tracking features.", "result": "MH-AutoML outperforms seven AutoML frameworks in recall rates while maintaining computational efficiency and providing transparency.", "conclusion": "MH-AutoML is a viable solution for Android malware detection, balancing performance and explainability."}}
{"id": "2506.23960", "pdf": "https://arxiv.org/pdf/2506.23960", "abs": "https://arxiv.org/abs/2506.23960", "authors": ["Mingfei Cheng", "Xiaofei Xie", "Renzhi Wang", "Yuan Zhou", "Ming Hu"], "title": "ADReFT: Adaptive Decision Repair for Safe Autonomous Driving via Reinforcement Fine-Tuning", "categories": ["cs.LG", "cs.AI", "cs.SE"], "comment": null, "summary": "Autonomous Driving Systems (ADSs) continue to face safety-critical risks due\nto the inherent limitations in their design and performance capabilities.\nOnline repair plays a crucial role in mitigating such limitations, ensuring the\nruntime safety and reliability of ADSs. Existing online repair solutions\nenforce ADS compliance by transforming unacceptable trajectories into\nacceptable ones based on predefined specifications, such as rule-based\nconstraints or training datasets. However, these approaches often lack\ngeneralizability, adaptability and tend to be overly conservative, resulting in\nineffective repairs that not only fail to mitigate safety risks sufficiently\nbut also degrade the overall driving experience. To address this issue, we\npropose Adaptive Decision Repair (ADReFT), a novel and effective repair method\nthat identifies safety-critical states through offline learning from failed\ntests and generates appropriate mitigation actions to improve ADS safety.\nSpecifically, ADReFT incorporates a transformer-based model with two joint\nheads, State Monitor and Decision Adapter, designed to capture complex driving\nenvironment interactions to evaluate state safety severity and generate\nadaptive repair actions. Given the absence of oracles for state safety\nidentification, we first pretrain ADReFT using supervised learning with coarse\nannotations, i.e., labeling states preceding violations as positive samples and\nothers as negative samples. It establishes ADReFT's foundational capability to\nmitigate safety-critical violations, though it may result in somewhat\nconservative mitigation strategies. Therefore, we subsequently finetune ADReFT\nusing reinforcement learning to improve its initial capability and generate\nmore precise and contextually appropriate repair decisions. Our evaluation\nresults illustrate that ADReFT achieves better repair performance.", "AI": {"tldr": "ADReFT is a novel method for online repair of Autonomous Driving Systems (ADSs) using transformer-based models to improve safety and adaptability.", "motivation": "Existing online repair solutions for ADSs lack generalizability and adaptability, often being overly conservative and ineffective.", "method": "ADReFT uses a transformer-based model with State Monitor and Decision Adapter heads, pretrained with supervised learning and finetuned with reinforcement learning.", "result": "ADReFT achieves better repair performance by generating precise and contextually appropriate repair actions.", "conclusion": "ADReFT effectively enhances ADS safety and reliability by addressing limitations of existing repair methods."}}
{"id": "2506.23263", "pdf": "https://arxiv.org/pdf/2506.23263", "abs": "https://arxiv.org/abs/2506.23263", "authors": ["Lei-lei Li", "Jianwu Fang", "Junbin Xiao", "Shanmin Pang", "Hongkai Yu", "Chen Lv", "Jianru Xue", "Tat-Seng Chua"], "title": "Causal-Entity Reflected Egocentric Traffic Accident Video Synthesis", "categories": ["cs.CV"], "comment": "Accepted by ICCV2025", "summary": "Egocentricly comprehending the causes and effects of car accidents is crucial\nfor the safety of self-driving cars, and synthesizing causal-entity reflected\naccident videos can facilitate the capability test to respond to unaffordable\naccidents in reality. However, incorporating causal relations as seen in\nreal-world videos into synthetic videos remains challenging. This work argues\nthat precisely identifying the accident participants and capturing their\nrelated behaviors are of critical importance. In this regard, we propose a\nnovel diffusion model, Causal-VidSyn, for synthesizing egocentric traffic\naccident videos. To enable causal entity grounding in video diffusion,\nCausal-VidSyn leverages the cause descriptions and driver fixations to identify\nthe accident participants and behaviors, facilitated by accident reason\nanswering and gaze-conditioned selection modules. To support Causal-VidSyn, we\nfurther construct Drive-Gaze, the largest driver gaze dataset (with 1.54M\nframes of fixations) in driving accident scenarios. Extensive experiments show\nthat Causal-VidSyn surpasses state-of-the-art video diffusion models in terms\nof frame quality and causal sensitivity in various tasks, including accident\nvideo editing, normal-to-accident video diffusion, and text-to-video\ngeneration.", "AI": {"tldr": "A novel diffusion model, Causal-VidSyn, is proposed for synthesizing egocentric traffic accident videos by leveraging cause descriptions and driver fixations, outperforming state-of-the-art models.", "motivation": "Understanding causes and effects of car accidents is vital for self-driving car safety, but synthesizing realistic accident videos with causal relations is challenging.", "method": "Causal-VidSyn uses cause descriptions and driver fixations to identify accident participants and behaviors, aided by accident reason answering and gaze-conditioned selection modules.", "result": "The model surpasses existing video diffusion models in frame quality and causal sensitivity for tasks like accident video editing and text-to-video generation.", "conclusion": "Causal-VidSyn effectively synthesizes realistic accident videos, supported by the Drive-Gaze dataset, enhancing safety testing for self-driving cars."}}
{"id": "2407.01461", "pdf": "https://arxiv.org/pdf/2407.01461", "abs": "https://arxiv.org/abs/2407.01461", "authors": ["Xiaohua Wang", "Zisu Huang", "Feiran Zhang", "Zhibo Xu", "Cenyuan Zhang", "Qi Qian", "Xiaoqing Zheng", "Xuanjing Huang"], "title": "Enhancing the Capability and Robustness of Large Language Models through Reinforcement Learning-Driven Query Refinement", "categories": ["cs.CL"], "comment": null, "summary": "The capacity of large language models (LLMs) to generate honest, harmless,\nand helpful responses heavily relies on the quality of user prompts. However,\nthese prompts often tend to be brief and vague, thereby significantly limiting\nthe full potential of LLMs. Moreover, harmful prompts can be meticulously\ncrafted and manipulated by adversaries to jailbreak LLMs, inducing them to\nproduce potentially toxic content. To enhance the capabilities of LLMs while\nmaintaining strong robustness against harmful jailbreak inputs, this study\nproposes a transferable and pluggable framework that refines user prompts\nbefore they are input into LLMs. This strategy improves the quality of the\nqueries, empowering LLMs to generate more truthful, benign and useful\nresponses. Specifically, a lightweight query refinement model is introduced and\ntrained using a specially designed reinforcement learning approach that\nincorporates multiple objectives to enhance particular capabilities of LLMs.\nExtensive experiments demonstrate that the refinement model not only improves\nthe quality of responses but also strengthens their robustness against\njailbreak attacks. Code is available at:\nhttps://github.com/Huangzisu/query-refinement .", "AI": {"tldr": "A framework refines user prompts to enhance LLM responses and robustness against harmful inputs.", "motivation": "Improve LLM response quality and robustness against adversarial jailbreak prompts.", "method": "Proposes a lightweight query refinement model trained via multi-objective reinforcement learning.", "result": "Enhances response quality and robustness against jailbreak attacks.", "conclusion": "The framework effectively improves LLM performance and safety."}}
{"id": "2506.23971", "pdf": "https://arxiv.org/pdf/2506.23971", "abs": "https://arxiv.org/abs/2506.23971", "authors": ["Brandon M. Wood", "Misko Dzamba", "Xiang Fu", "Meng Gao", "Muhammed Shuaibi", "Luis Barroso-Luque", "Kareem Abdelmaqsoud", "Vahe Gharakhanyan", "John R. Kitchin", "Daniel S. Levine", "Kyle Michel", "Anuroop Sriram", "Taco Cohen", "Abhishek Das", "Ammar Rizvi", "Sushree Jagriti Sahoo", "Zachary W. Ulissi", "C. Lawrence Zitnick"], "title": "UMA: A Family of Universal Models for Atoms", "categories": ["cs.LG"], "comment": "29 pages, 5 figures", "summary": "The ability to quickly and accurately compute properties from atomic\nsimulations is critical for advancing a large number of applications in\nchemistry and materials science including drug discovery, energy storage, and\nsemiconductor manufacturing. To address this need, Meta FAIR presents a family\nof Universal Models for Atoms (UMA), designed to push the frontier of speed,\naccuracy, and generalization. UMA models are trained on half a billion unique\n3D atomic structures (the largest training runs to date) by compiling data\nacross multiple chemical domains, e.g. molecules, materials, and catalysts. We\ndevelop empirical scaling laws to help understand how to increase model\ncapacity alongside dataset size to achieve the best accuracy. The UMA small and\nmedium models utilize a novel architectural design we refer to as mixture of\nlinear experts that enables increasing model capacity without sacrificing\nspeed. For example, UMA-medium has 1.4B parameters but only ~50M active\nparameters per atomic structure. We evaluate UMA models on a diverse set of\napplications across multiple domains and find that, remarkably, a single model\nwithout any fine-tuning can perform similarly or better than specialized\nmodels. We are releasing the UMA code, weights, and associated data to\naccelerate computational workflows and enable the community to continue to\nbuild increasingly capable AI models.", "AI": {"tldr": "Meta FAIR introduces Universal Models for Atoms (UMA), a family of AI models trained on 500M atomic structures, achieving high speed, accuracy, and generalization across chemical domains without fine-tuning.", "motivation": "The need for fast and accurate atomic property computation in applications like drug discovery and energy storage drives the development of UMA.", "method": "UMA models use a novel 'mixture of linear experts' architecture, scaling model capacity with dataset size. Training involves 500M 3D atomic structures from diverse chemical domains.", "result": "UMA models match or outperform specialized models across domains without fine-tuning, e.g., UMA-medium has 1.4B parameters but only ~50M active per structure.", "conclusion": "UMA's release of code, weights, and data aims to accelerate computational workflows and advance AI capabilities in chemistry and materials science."}}
{"id": "2506.23271", "pdf": "https://arxiv.org/pdf/2506.23271", "abs": "https://arxiv.org/abs/2506.23271", "authors": ["Jinxing Zhou", "Zhihui Li", "Yongqiang Yu", "Yanghao Zhou", "Ruohao Guo", "Guangyao Li", "Yuxin Mao", "Mingfei Han", "Xiaojun Chang", "Meng Wang"], "title": "Mettle: Meta-Token Learning for Memory-Efficient Audio-Visual Adaptation", "categories": ["cs.CV"], "comment": "Technical Report", "summary": "We present \\textbf{Met}a-\\textbf{T}oken \\textbf{Le}arning (Mettle), a simple\nand memory-efficient method for adapting large-scale pretrained transformer\nmodels to downstream audio-visual tasks. Instead of sequentially modifying the\noutput feature distribution of the transformer backbone, Mettle utilizes a\nlightweight \\textit{Layer-Centric Distillation (LCD)} module to distill in\nparallel the intact audio or visual features embedded by each transformer layer\ninto compact meta-tokens. This distillation process considers both pretrained\nknowledge preservation and task-specific adaptation. The obtained meta-tokens\ncan be directly applied to classification tasks, such as audio-visual event\nlocalization and audio-visual video parsing. To further support fine-grained\nsegmentation tasks, such as audio-visual segmentation, we introduce a\n\\textit{Meta-Token Injection (MTI)} module, which utilizes the audio and visual\nmeta-tokens distilled from the top transformer layer to guide feature\nadaptation in earlier layers. Extensive experiments on multiple audiovisual\nbenchmarks demonstrate that our method significantly reduces memory usage and\ntraining time while maintaining parameter efficiency and competitive accuracy.", "AI": {"tldr": "Mettle is a memory-efficient method for adapting large pretrained transformers to audio-visual tasks using Layer-Centric Distillation and Meta-Token Injection.", "motivation": "To adapt large-scale pretrained transformers efficiently for downstream audio-visual tasks while preserving pretrained knowledge and enabling task-specific adaptation.", "method": "Uses Layer-Centric Distillation (LCD) to distill audio/visual features into meta-tokens and Meta-Token Injection (MTI) for fine-grained segmentation tasks.", "result": "Reduces memory usage and training time while maintaining parameter efficiency and competitive accuracy.", "conclusion": "Mettle is effective for adapting transformers to audio-visual tasks with efficiency and accuracy."}}
{"id": "2407.12749", "pdf": "https://arxiv.org/pdf/2407.12749", "abs": "https://arxiv.org/abs/2407.12749", "authors": ["Manar Abdelatty", "Jacob Rosenstein", "Sherief Reda"], "title": "ChipXplore: Natural Language Exploration of Hardware Designs and Libraries", "categories": ["cs.CL"], "comment": "10 pages", "summary": "Hardware design workflows rely on Process Design Kits (PDKs) from different\nfabrication nodes, each containing standard cell libraries optimized for speed,\npower, or density. Engineers typically navigate between the design and target\nPDK to make informed decisions, such as selecting gates for area optimization\nor enhancing the speed of the critical path. However, this process is often\nmanual, time-consuming, and prone to errors. To address this, we present\nChipXplore, a multi-agent collaborative framework powered by large language\nmodels that enables engineers to query hardware designs and PDKs using natural\nlanguage. By exploiting the structured nature of PDK and hardware design data,\nChipXplore retrieves relevant information through text-to-SQL and\ntext-to-Cypher customized workflows. The framework achieves an execution\naccuracy of 97.39\\% in complex natural language queries and improves\nproductivity by making retrieval 5.63x faster while reducing errors by 5.25x in\nuser studies. Compared to generic workflows, ChipXplore's customized workflow\nis capable of orchestrating reasoning and planning over multiple databases,\nimproving accuracy by 29.78\\%. ChipXplore lays the foundation for building\nautonomous agents capable of tackling diverse physical design tasks that\nrequire PDK and hardware design awareness.", "AI": {"tldr": "ChipXplore is a multi-agent framework using LLMs to automate and optimize hardware design queries via natural language, improving accuracy and productivity.", "motivation": "Manual navigation between hardware designs and PDKs is error-prone and inefficient.", "method": "Uses text-to-SQL and text-to-Cypher workflows for structured data retrieval.", "result": "Achieves 97.39% accuracy, 5.63x faster retrieval, and 29.78% higher accuracy than generic workflows.", "conclusion": "ChipXplore enables efficient, autonomous hardware design tasks with PDK awareness."}}
{"id": "2506.23382", "pdf": "https://arxiv.org/pdf/2506.23382", "abs": "https://arxiv.org/abs/2506.23382", "authors": ["Vikram Rangarajan", "Shishira Maiya", "Max Ehrlich", "Abhinav Shrivastava"], "title": "SIEDD: Shared-Implicit Encoder with Discrete Decoders", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Project page at https://vikramrangarajan.github.io/SIEDD . Project\n  code at https://github.com/VikramRangarajan/SIEDD", "summary": "Implicit Neural Representations (INRs) offer exceptional fidelity for video\ncompression by learning per-video optimized functions, but their adoption is\ncrippled by impractically slow encoding times. Existing attempts to accelerate\nINR encoding often sacrifice reconstruction quality or crucial coordinate-level\ncontrol essential for adaptive streaming and transcoding. We introduce SIEDD\n(Shared-Implicit Encoder with Discrete Decoders), a novel architecture that\nfundamentally accelerates INR encoding without these compromises. SIEDD first\nrapidly trains a shared, coordinate-based encoder on sparse anchor frames to\nefficiently capture global, low-frequency video features. This encoder is then\nfrozen, enabling massively parallel training of lightweight, discrete decoders\nfor individual frame groups, further expedited by aggressive coordinate-space\nsampling. This synergistic design delivers a remarkable 20-30X encoding\nspeed-up over state-of-the-art INR codecs on HD and 4K benchmarks, while\nmaintaining competitive reconstruction quality and compression ratios.\nCritically, SIEDD retains full coordinate-based control, enabling continuous\nresolution decoding and eliminating costly transcoding. Our approach\nsignificantly advances the practicality of high-fidelity neural video\ncompression, demonstrating a scalable and efficient path towards real-world\ndeployment. Our codebase is available at\nhttps://github.com/VikramRangarajan/SIEDD .", "AI": {"tldr": "SIEDD accelerates INR video encoding by 20-30X without sacrificing quality or control, using a shared encoder and discrete decoders.", "motivation": "Current INR video compression methods are too slow for practical use, often compromising quality or control.", "method": "SIEDD uses a shared encoder for global features and lightweight decoders for frame groups, with aggressive sampling.", "result": "Achieves 20-30X faster encoding on HD/4K benchmarks while maintaining quality and compression ratios.", "conclusion": "SIEDD makes high-fidelity neural video compression practical for real-world deployment."}}
{"id": "2506.23977", "pdf": "https://arxiv.org/pdf/2506.23977", "abs": "https://arxiv.org/abs/2506.23977", "authors": ["Zain ul Abdeen", "Vassilis Kekatos", "Ming Jin"], "title": "A Scalable Approach for Safe and Robust Learning via Lipschitz-Constrained Networks", "categories": ["cs.LG"], "comment": null, "summary": "Certified robustness is a critical property for deploying neural networks\n(NN) in safety-critical applications. A principle approach to achieving such\nguarantees is to constrain the global Lipschitz constant of the network.\nHowever, accurate methods for Lipschitz-constrained training often suffer from\nnon-convex formulations and poor scalability due to reliance on global\nsemidefinite programs (SDPs). In this letter, we propose a convex training\nframework that enforces global Lipschitz constraints via semidefinite\nrelaxation. By reparameterizing the NN using loop transformation, we derive a\nconvex admissibility condition that enables tractable and certifiable training.\nWhile the resulting formulation guarantees robustness, its scalability is\nlimited by the size of global SDP. To overcome this, we develop a randomized\nsubspace linear matrix inequalities (RS-LMI) approach that decomposes the\nglobal constraints into sketched layerwise constraints projected onto\nlow-dimensional subspaces, yielding a smooth and memory-efficient training\nobjective. Empirical results on MNIST, CIFAR-10, and ImageNet demonstrate that\nthe proposed framework achieves competitive accuracy with significantly\nimproved Lipschitz bounds and runtime performance.", "AI": {"tldr": "A convex training framework for neural networks ensures certified robustness via Lipschitz constraints, using semidefinite relaxation and a randomized subspace method for scalability.", "motivation": "Certified robustness is essential for safety-critical applications, but existing Lipschitz-constrained training methods face non-convexity and scalability issues.", "method": "Proposes a convex training framework with semidefinite relaxation and loop transformation, and introduces RS-LMI for scalable layerwise constraints.", "result": "Achieves competitive accuracy with improved Lipschitz bounds and runtime on MNIST, CIFAR-10, and ImageNet.", "conclusion": "The framework provides a scalable and certifiable solution for robust neural network training."}}
{"id": "2506.23282", "pdf": "https://arxiv.org/pdf/2506.23282", "abs": "https://arxiv.org/abs/2506.23282", "authors": ["Hanwen Zhang", "Congqi Cao", "Qinyi Lv", "Lingtong Min", "Yanning Zhang"], "title": "Autoregressive Denoising Score Matching is a Good Video Anomaly Detector", "categories": ["cs.CV"], "comment": null, "summary": "Video anomaly detection (VAD) is an important computer vision problem. Thanks\nto the mode coverage capabilities of generative models, the likelihood-based\nparadigm is catching growing interest, as it can model normal distribution and\ndetect out-of-distribution anomalies. However, these likelihood-based methods\nare blind to the anomalies located in local modes near the learned\ndistribution. To handle these ``unseen\" anomalies, we dive into three gaps\nuniquely existing in VAD regarding scene, motion and appearance. Specifically,\nwe first build a noise-conditioned score transformer for denoising score\nmatching. Then, we introduce a scene-dependent and motion-aware score function\nby embedding the scene condition of input sequences into our model and\nassigning motion weights based on the difference between key frames of input\nsequences. Next, to solve the problem of blindness in principle, we integrate\nunaffected visual information via a novel autoregressive denoising score\nmatching mechanism for inference. Through autoregressively injecting\nintensifying Gaussian noise into the denoised data and estimating the\ncorresponding score function, we compare the denoised data with the original\ndata to get a difference and aggregate it with the score function for an\nenhanced appearance perception and accumulate the abnormal context. With all\nthree gaps considered, we can compute a more comprehensive anomaly indicator.\nExperiments on three popular VAD benchmarks demonstrate the state-of-the-art\nperformance of our method.", "AI": {"tldr": "The paper addresses limitations in likelihood-based video anomaly detection (VAD) by tackling three gaps (scene, motion, appearance) using a noise-conditioned score transformer and a novel autoregressive denoising mechanism.", "motivation": "Likelihood-based VAD methods fail to detect anomalies near learned distributions, necessitating a solution for 'unseen' anomalies.", "method": "Proposes a noise-conditioned score transformer, scene-dependent and motion-aware score function, and autoregressive denoising score matching for inference.", "result": "Achieves state-of-the-art performance on three VAD benchmarks.", "conclusion": "The method effectively addresses gaps in VAD, improving anomaly detection by integrating scene, motion, and appearance considerations."}}
{"id": "2407.21536", "pdf": "https://arxiv.org/pdf/2407.21536", "abs": "https://arxiv.org/abs/2407.21536", "authors": ["Jiang Li", "Xiaoping Wang", "Zhigang Zeng"], "title": "Tracing Intricate Cues in Dialogue: Joint Graph Structure and Sentiment Dynamics for Multimodal Emotion Recognition", "categories": ["cs.CL"], "comment": "Accepted by IEEE Transactions on Pattern Analysis and Machine\n  Intelligence", "summary": "Multimodal emotion recognition in conversation (MERC) has garnered\nsubstantial research attention recently. Existing MERC methods face several\nchallenges: (1) they fail to fully harness direct inter-modal cues, possibly\nleading to less-than-thorough cross-modal modeling; (2) they concurrently\nextract information from the same and different modalities at each network\nlayer, potentially triggering conflicts from the fusion of multi-source data;\n(3) they lack the agility required to detect dynamic sentimental changes,\nperhaps resulting in inaccurate classification of utterances with abrupt\nsentiment shifts. To address these issues, a novel approach named GraphSmile is\nproposed for tracking intricate emotional cues in multimodal dialogues.\nGraphSmile comprises two key components, i.e., GSF and SDP modules. GSF\ningeniously leverages graph structures to alternately assimilate inter-modal\nand intra-modal emotional dependencies layer by layer, adequately capturing\ncross-modal cues while effectively circumventing fusion conflicts. SDP is an\nauxiliary task to explicitly delineate the sentiment dynamics between\nutterances, promoting the model's ability to distinguish sentimental\ndiscrepancies. GraphSmile is effortlessly applied to multimodal sentiment\nanalysis in conversation (MSAC), thus enabling simultaneous execution of MERC\nand MSAC tasks. Empirical results on multiple benchmarks demonstrate that\nGraphSmile can handle complex emotional and sentimental patterns, significantly\noutperforming baseline models.", "AI": {"tldr": "GraphSmile is a novel approach for multimodal emotion recognition in conversation (MERC) and sentiment analysis (MSAC), addressing challenges like incomplete cross-modal modeling, fusion conflicts, and dynamic sentiment detection.", "motivation": "Existing MERC methods struggle with inter-modal cues, fusion conflicts, and dynamic sentiment shifts, limiting their effectiveness.", "method": "GraphSmile uses GSF (graph-based fusion) and SDP (sentiment dynamics prediction) modules to capture cross-modal cues and detect sentiment changes.", "result": "GraphSmile outperforms baselines in handling complex emotional and sentimental patterns.", "conclusion": "GraphSmile effectively addresses MERC and MSAC challenges, demonstrating superior performance."}}
{"id": "2506.23461", "pdf": "https://arxiv.org/pdf/2506.23461", "abs": "https://arxiv.org/abs/2506.23461", "authors": ["Yun Xing", "Qing Guo", "Xiaoguang Li", "Yihao Huang", "Xiaofeng Cao", "Di Lin", "Ivor Tsang", "Lei Ma"], "title": "Time-variant Image Inpainting via Interactive Distribution Transition Estimation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In this work, we focus on a novel and practical task, i.e., Time-vAriant\niMage inPainting (TAMP). The aim of TAMP is to restore a damaged target image\nby leveraging the complementary information from a reference image, where both\nimages captured the same scene but with a significant time gap in between,\ni.e., time-variant images. Different from conventional reference-guided image\ninpainting, the reference image under TAMP setup presents significant content\ndistinction to the target image and potentially also suffers from damages. Such\nan application frequently happens in our daily lives to restore a damaged image\nby referring to another reference image, where there is no guarantee of the\nreference image's source and quality. In particular, our study finds that even\nstate-of-the-art (SOTA) reference-guided image inpainting methods fail to\nachieve plausible results due to the chaotic image complementation. To address\nsuch an ill-posed problem, we propose a novel Interactive Distribution\nTransition Estimation (InDiTE) module which interactively complements the\ntime-variant images with adaptive semantics thus facilitate the restoration of\ndamaged regions. To further boost the performance, we propose our TAMP\nsolution, namely Interactive Distribution Transition Estimation-driven\nDiffusion (InDiTE-Diff), which integrates InDiTE with SOTA diffusion model and\nconducts latent cross-reference during sampling. Moreover, considering the lack\nof benchmarks for TAMP task, we newly assembled a dataset, i.e., TAMP-Street,\nbased on existing image and mask datasets. We conduct experiments on the\nTAMP-Street datasets under two different time-variant image inpainting\nsettings, which show our method consistently outperform SOTA reference-guided\nimage inpainting methods for solving TAMP.", "AI": {"tldr": "The paper introduces Time-vAriant iMage inPainting (TAMP), a task to restore damaged images using time-variant reference images. It proposes the InDiTE-Diff method, combining interactive distribution transition estimation with diffusion models, and validates it on a new dataset, TAMP-Street.", "motivation": "Restoring damaged images with time-variant references is challenging due to content distinctions and potential damages in references. Existing methods fail in such chaotic scenarios.", "method": "Proposes InDiTE module for adaptive semantics and InDiTE-Diff, integrating InDiTE with diffusion models for latent cross-reference during sampling.", "result": "InDiTE-Diff outperforms SOTA methods on the TAMP-Street dataset under two settings.", "conclusion": "The proposed method effectively addresses the TAMP task, demonstrating superior performance over existing approaches."}}
{"id": "2506.23996", "pdf": "https://arxiv.org/pdf/2506.23996", "abs": "https://arxiv.org/abs/2506.23996", "authors": ["Juan Maro\u00f1as"], "title": "The Jacobian and Hessian of the Kullback-Leibler Divergence between Multivariate Gaussian Distributions (Technical Report)", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "This document shows how to obtain the Jacobian and Hessian matrices of the\nKullback-Leibler divergence between two multivariate Gaussian distributions,\nusing the first and second-order differentials. The presented derivations are\nbased on the theory presented by \\cite{magnus99}. I've also got great\ninspiration from some of the derivations in \\cite{minka}.\n  Since I pretend to be at most didactic, the document is split into a summary\nof results and detailed derivations on each of the elements involved, with\nspecific references to the tricks used in the derivations, and to many of the\nunderlying concepts.", "AI": {"tldr": "Derivation of Jacobian and Hessian matrices for Kullback-Leibler divergence between multivariate Gaussians using differentials.", "motivation": "To provide a didactic and detailed explanation of deriving Jacobian and Hessian matrices for Kullback-Leibler divergence, inspired by existing literature.", "method": "Uses first and second-order differentials, referencing Magnus (1999) and Minka's derivations.", "result": "Detailed derivations and summary of results for Jacobian and Hessian matrices.", "conclusion": "The document offers a clear, step-by-step guide for deriving these matrices, emphasizing didactic clarity."}}
{"id": "2506.23283", "pdf": "https://arxiv.org/pdf/2506.23283", "abs": "https://arxiv.org/abs/2506.23283", "authors": ["Yuhuan Yang", "Chaofan Ma", "Zhenjie Mao", "Jiangchao Yao", "Ya Zhang", "Yanfeng Wang"], "title": "MoMa: Modulating Mamba for Adapting Image Foundation Models to Video Recognition", "categories": ["cs.CV"], "comment": "ICML 2025 paper", "summary": "Video understanding is a complex challenge that requires effective modeling\nof spatial-temporal dynamics. With the success of image foundation models\n(IFMs) in image understanding, recent approaches have explored\nparameter-efficient fine-tuning (PEFT) to adapt IFMs for video. However, most\nof these methods tend to process spatial and temporal information separately,\nwhich may fail to capture the full intricacy of video dynamics. In this paper,\nwe propose MoMa, an efficient adapter framework that achieves full\nspatial-temporal modeling by integrating Mamba's selective state space modeling\ninto IFMs. We propose a novel SeqMod operation to inject spatial-temporal\ninformation into pre-trained IFMs, without disrupting their original features.\nBy incorporating SeqMod into a Divide-and-Modulate architecture, MoMa enhances\nvideo understanding while maintaining computational efficiency. Extensive\nexperiments on multiple video benchmarks demonstrate the effectiveness of MoMa,\nachieving superior performance with reduced computational cost.", "AI": {"tldr": "MoMa is an efficient adapter framework for video understanding that integrates Mamba's selective state space modeling into image foundation models (IFMs) for full spatial-temporal modeling.", "motivation": "Existing methods for adapting IFMs to video often process spatial and temporal information separately, missing the full intricacy of video dynamics.", "method": "Proposes MoMa with SeqMod operation to inject spatial-temporal information into IFMs and a Divide-and-Modulate architecture.", "result": "Achieves superior performance on video benchmarks with reduced computational cost.", "conclusion": "MoMa effectively enhances video understanding by integrating spatial-temporal modeling efficiently."}}
{"id": "2408.06576", "pdf": "https://arxiv.org/pdf/2408.06576", "abs": "https://arxiv.org/abs/2408.06576", "authors": ["Wei Peng", "Junmei Ding", "Wei Wang", "Lei Cui", "Wei Cai", "Zhiyu Hao", "Xiaochun Yun"], "title": "CTISum: A New Benchmark Dataset For Cyber Threat Intelligence Summarization", "categories": ["cs.CL"], "comment": null, "summary": "Cyber Threat Intelligence (CTI) summarization involves generating concise and\naccurate highlights from web intelligence data, which is critical for providing\ndecision-makers with actionable insights to swiftly detect and respond to cyber\nthreats in the cybersecurity domain. Despite that, the development of efficient\ntechniques for summarizing CTI reports, comprising facts, analytical insights,\nattack processes, and more, has been hindered by the lack of suitable datasets.\nTo address this gap, we introduce CTISum, a new benchmark dataset designed for\nthe CTI summarization task. Recognizing the significance of understanding\nattack processes, we also propose a novel fine-grained subtask: attack process\nsummarization, which aims to help defenders assess risks, identify security\ngaps, and uncover vulnerabilities. Specifically, a multi-stage annotation\npipeline is designed to collect and annotate CTI data from diverse web sources,\nalongside a comprehensive benchmarking of CTISum using both extractive,\nabstractive and LLMs-based summarization methods. Experimental results reveal\nthat current state-of-the-art models face significant challenges when applied\nto CTISum, highlighting that automatic summarization of CTI reports remains an\nopen research problem. The code and example dataset can be made publicly\navailable at https://github.com/pengwei-iie/CTISum.", "AI": {"tldr": "The paper introduces CTISum, a benchmark dataset for Cyber Threat Intelligence (CTI) summarization, addressing the lack of suitable datasets. It also proposes a fine-grained subtask for attack process summarization and benchmarks various summarization methods, revealing challenges for current models.", "motivation": "The lack of suitable datasets hinders the development of efficient CTI summarization techniques, which are crucial for actionable insights in cybersecurity.", "method": "A multi-stage annotation pipeline collects and annotates CTI data from diverse web sources. The dataset is benchmarked using extractive, abstractive, and LLMs-based summarization methods.", "result": "Current state-of-the-art models face significant challenges in summarizing CTI reports, indicating the problem remains open.", "conclusion": "CTISum fills a critical gap in CTI summarization, and the proposed subtask aids in risk assessment and vulnerability identification. The dataset and code are publicly available."}}
{"id": "2506.23465", "pdf": "https://arxiv.org/pdf/2506.23465", "abs": "https://arxiv.org/abs/2506.23465", "authors": ["Nazanin Mahjourian", "Vinh Nguyen"], "title": "Sanitizing Manufacturing Dataset Labels Using Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The success of machine learning models in industrial applications is heavily\ndependent on the quality of the datasets used to train the models. However,\nlarge-scale datasets, specially those constructed from crowd-sourcing and\nweb-scraping, often suffer from label noise, inconsistencies, and errors. This\nproblem is particularly pronounced in manufacturing domains, where obtaining\nhigh-quality labels is costly and time-consuming. This paper introduces\nVision-Language Sanitization and Refinement (VLSR), which is a\nvision-language-based framework for label sanitization and refinement in\nmulti-label manufacturing image datasets. This method embeds both images and\ntheir associated textual labels into a shared semantic space leveraging the\nCLIP vision-language model. Then two key tasks are addressed in this process by\ncomputing the cosine similarity between embeddings. First, label sanitization\nis performed to identify irrelevant, misspelled, or semantically weak labels,\nand surface the most semantically aligned label for each image by comparing\nimage-label pairs using cosine similarity between image and label embeddings.\nSecond, the method applies density-based clustering on text embeddings,\nfollowed by iterative cluster merging, to group semantically similar labels\ninto unified label groups. The Factorynet dataset, which includes noisy labels\nfrom both human annotations and web-scraped sources, is employed to evaluate\nthe effectiveness of the proposed framework. Experimental results demonstrate\nthat the VLSR framework successfully identifies problematic labels and improves\nlabel consistency. This method enables a significant reduction in label\nvocabulary through clustering, which ultimately enhances the dataset's quality\nfor training robust machine learning models in industrial applications with\nminimal human intervention.", "AI": {"tldr": "The paper introduces VLSR, a vision-language framework for sanitizing and refining noisy labels in manufacturing image datasets, improving dataset quality for machine learning.", "motivation": "Large-scale datasets, especially in manufacturing, often have label noise and inconsistencies, making high-quality labels costly and time-consuming to obtain.", "method": "VLSR uses CLIP to embed images and labels into a shared semantic space, then performs label sanitization via cosine similarity and clusters similar labels using density-based clustering.", "result": "VLSR effectively identifies problematic labels, improves consistency, and reduces label vocabulary, enhancing dataset quality.", "conclusion": "VLSR minimizes human intervention and improves dataset quality for robust machine learning in industrial applications."}}
{"id": "2506.24000", "pdf": "https://arxiv.org/pdf/2506.24000", "abs": "https://arxiv.org/abs/2506.24000", "authors": ["Lijun Sheng", "Jian Liang", "Ran He", "Zilei Wang", "Tieniu Tan"], "title": "The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models", "categories": ["cs.LG", "cs.CV"], "comment": "Github link: https://github.com/TomSheng21/tta-vlm", "summary": "Test-time adaptation (TTA) methods have gained significant attention for\nenhancing the performance of vision-language models (VLMs) such as CLIP during\ninference, without requiring additional labeled data. However, current TTA\nresearches generally suffer from major limitations such as duplication of\nbaseline results, limited evaluation metrics, inconsistent experimental\nsettings, and insufficient analysis. These problems hinder fair comparisons\nbetween TTA methods and obscure their practical strengths and weaknesses. To\naddress these challenges, we introduce TTA-VLM, a comprehensive benchmark for\nevaluating TTA methods on VLMs. Our benchmark implements 8 episodic TTA and 7\nonline TTA methods within a unified and reproducible framework, and evaluates\nthem across 15 widely used datasets. Unlike prior studies focused solely on\nCLIP, we extend the evaluation to SigLIP--a model trained with a Sigmoid\nloss--and include training-time tuning methods such as CoOp, MaPLe, and TeCoA\nto assess generality. Beyond classification accuracy, TTA-VLM incorporates\nvarious evaluation metrics, including robustness, calibration,\nout-of-distribution detection, and stability, enabling a more holistic\nassessment of TTA methods. Through extensive experiments, we find that 1)\nexisting TTA methods produce limited gains compared to the previous pioneering\nwork; 2) current TTA methods exhibit poor collaboration with training-time\nfine-tuning methods; 3) accuracy gains frequently come at the cost of reduced\nmodel trustworthiness. We release TTA-VLM to provide fair comparison and\ncomprehensive evaluation of TTA methods for VLMs, and we hope it encourages the\ncommunity to develop more reliable and generalizable TTA strategies.", "AI": {"tldr": "TTA-VLM is a benchmark addressing limitations in current TTA research for VLMs, offering unified evaluation across diverse methods and metrics.", "motivation": "Current TTA research lacks fair comparisons due to inconsistent settings, limited metrics, and insufficient analysis, hindering practical insights.", "method": "TTA-VLM implements 8 episodic and 7 online TTA methods in a reproducible framework, evaluating them on 15 datasets and extending beyond CLIP to SigLIP and training-time methods.", "result": "Findings show limited gains from existing TTA methods, poor collaboration with fine-tuning, and trade-offs between accuracy and trustworthiness.", "conclusion": "TTA-VLM aims to foster fair comparisons and reliable TTA strategies, encouraging broader and more trustworthy advancements in the field."}}
{"id": "2506.23285", "pdf": "https://arxiv.org/pdf/2506.23285", "abs": "https://arxiv.org/abs/2506.23285", "authors": ["Daqian Shi", "Xiaolei Diao", "Xu Chen", "C\u00e9dric M. John"], "title": "Competitive Distillation: A Simple Learning Strategy for Improving Visual Classification", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "Deep Neural Networks (DNNs) have significantly advanced the field of computer\nvision. To improve DNN training process, knowledge distillation methods\ndemonstrate their effectiveness in accelerating network training by introducing\na fixed learning direction from the teacher network to student networks. In\nthis context, several distillation-based optimization strategies are proposed,\ne.g., deep mutual learning and self-distillation, as an attempt to achieve\ngeneric training performance enhancement through the cooperative training of\nmultiple networks. However, such strategies achieve limited improvements due to\nthe poor understanding of the impact of learning directions among networks\nacross different iterations. In this paper, we propose a novel competitive\ndistillation strategy that allows each network in a group to potentially act as\na teacher based on its performance, enhancing the overall learning performance.\nCompetitive distillation organizes a group of networks to perform a shared task\nand engage in competition, where competitive optimization is proposed to\nimprove the parameter updating process. We further introduce stochastic\nperturbation in competitive distillation, aiming to motivate networks to induce\nmutations to achieve better visual representations and global optimum. The\nexperimental results show that competitive distillation achieves promising\nperformance in diverse tasks and datasets.", "AI": {"tldr": "The paper proposes a competitive distillation strategy for DNN training, where networks compete and dynamically act as teachers, improving learning performance through competition and stochastic perturbation.", "motivation": "Current distillation methods like mutual learning and self-distillation have limited improvements due to unclear learning directions across iterations. The paper aims to enhance training by introducing competition among networks.", "method": "A competitive distillation strategy is introduced, where networks dynamically act as teachers based on performance. Competitive optimization and stochastic perturbation are used to improve parameter updates and visual representations.", "result": "Experiments show competitive distillation achieves strong performance across various tasks and datasets.", "conclusion": "The proposed competitive distillation strategy effectively enhances DNN training by leveraging competition and stochastic perturbation, outperforming existing methods."}}
{"id": "2408.11189", "pdf": "https://arxiv.org/pdf/2408.11189", "abs": "https://arxiv.org/abs/2408.11189", "authors": ["Benjamin Reichman", "Adar Avsian", "Kartik Talamadupula", "Toshish Jawale", "Larry Heck"], "title": "Emotional RAG LLMs: Reading Comprehension for the Open Internet", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": null, "summary": "Queries to large language models (LLMs) can be divided into two parts: the\ninstruction/question and the accompanying context. The context for\nretrieval-augmented generation (RAG) systems in most benchmarks comes from\nWikipedia-like texts written in a neutral and factual tone. However, real-world\nRAG applications often retrieve internet-based text with diverse tones and\nlinguistic styles, posing challenges for downstream tasks. This paper\nintroduces (a) a dataset that transforms RAG-retrieved passages into\nemotionally inflected and sarcastic text, (b) an emotion translation model for\nadapting text to different tones, and (c) a prompt-based method to improve\nLLMs' pragmatic interpretation of retrieved text.", "AI": {"tldr": "The paper addresses the gap between neutral benchmark datasets and real-world diverse-text RAG applications by introducing a dataset with emotional/sarcastic text, an emotion translation model, and a prompt-based method for better LLM interpretation.", "motivation": "Real-world RAG systems retrieve diverse-toned internet text, unlike neutral benchmark datasets, creating challenges for LLMs.", "method": "Developed a dataset with emotionally inflected/sarcastic text, an emotion translation model, and a prompt-based method for LLMs.", "result": "Provides tools to adapt LLMs to diverse linguistic styles and improve pragmatic interpretation of retrieved text.", "conclusion": "The work bridges the gap between benchmark and real-world RAG applications, enhancing LLM adaptability to varied tones."}}
{"id": "2506.23491", "pdf": "https://arxiv.org/pdf/2506.23491", "abs": "https://arxiv.org/abs/2506.23491", "authors": ["ZongHan Hsieh", "Tzer-Jen Wei"], "title": "Qwen-GUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper introduces Qwen-GUI-3B, a lightweight Vision-Language Model (VLM)\nspecifically designed for Graphical User Interface grounding tasks, achieving\nperformance competitive with significantly larger models. Unlike large-scale\nVLMs (>7B parameters) that are computationally intensive and impractical for\nconsumer-grade hardware, Qwen-GUI-3B delivers strong grounding accuracy while\nbeing fully trainable on a single GPU (RTX 4090). The model incorporates\nseveral key innovations: (i) combine cross-platform, multi-resolution dataset\nof 24K examples from diverse sources including mobile, desktop, and web GUI\nscreenshots to effectively address data scarcity in high-resolution desktop\nenvironments; (ii) a two-stage fine-tuning strategy, where initial\ncross-platform training establishes robust GUI understanding, followed by\nspecialized fine-tuning on high-resolution data to significantly enhance model\nadaptability; and (iii) data curation and redundancy reduction strategies,\ndemonstrating that randomly sampling a smaller subset with reduced redundancy\nachieves performance comparable to larger datasets, emphasizing data diversity\nover sheer volume. Empirical evaluation on standard GUI grounding\nbenchmarks-including ScreenSpot, ScreenSpot-v2, and the challenging\nScreenSpot-Pro, highlights Qwen-GUI-3B's exceptional accuracy, achieving 84.9%\non ScreenSpot and 86.4% on ScreenSpot-v2, surpassing prior models under 4B\nparameters. Ablation studies validate the critical role of balanced sampling\nand two-stage fine-tuning in enhancing robustness, particularly in\nhigh-resolution desktop scenarios. The Qwen-GUI-3B is available at:\nhttps://github.com/Han1018/Qwen-GUI-3B", "AI": {"tldr": "Qwen-GUI-3B is a lightweight Vision-Language Model for GUI grounding tasks, achieving competitive performance with larger models while being trainable on a single GPU. Key innovations include cross-platform datasets, two-stage fine-tuning, and data curation strategies.", "motivation": "Address the impracticality of large-scale VLMs for consumer-grade hardware by developing a lightweight yet accurate model for GUI grounding tasks.", "method": "Combines cross-platform datasets, employs a two-stage fine-tuning strategy (initial cross-platform training followed by specialized fine-tuning), and uses data curation to reduce redundancy.", "result": "Achieves 84.9% on ScreenSpot and 86.4% on ScreenSpot-v2, surpassing prior models under 4B parameters.", "conclusion": "Qwen-GUI-3B demonstrates that lightweight models can achieve high accuracy in GUI grounding through innovative data and training strategies."}}
{"id": "2506.24005", "pdf": "https://arxiv.org/pdf/2506.24005", "abs": "https://arxiv.org/abs/2506.24005", "authors": ["He Wang", "Xingyu Xu", "Yuejie Chi"], "title": "Provably Efficient and Agile Randomized Q-Learning", "categories": ["cs.LG"], "comment": null, "summary": "While Bayesian-based exploration often demonstrates superior empirical\nperformance compared to bonus-based methods in model-based reinforcement\nlearning (RL), its theoretical understanding remains limited for model-free\nsettings. Existing provable algorithms either suffer from computational\nintractability or rely on stage-wise policy updates which reduce responsiveness\nand slow down the learning process. In this paper, we propose a novel variant\nof Q-learning algorithm, refereed to as RandomizedQ, which integrates\nsampling-based exploration with agile, step-wise, policy updates, for episodic\ntabular RL. We establish an $\\widetilde{O}(\\sqrt{H^5SAT})$ regret bound, where\n$S$ is the number of states, $A$ is the number of actions, $H$ is the episode\nlength, and $T$ is the total number of episodes. In addition, we present a\nlogarithmic regret bound under a mild positive sub-optimality condition on the\noptimal Q-function. Empirically, RandomizedQ exhibits outstanding performance\ncompared to existing Q-learning variants with both bonus-based and\nBayesian-based exploration on standard benchmarks.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.23292", "pdf": "https://arxiv.org/pdf/2506.23292", "abs": "https://arxiv.org/abs/2506.23292", "authors": ["Changtao Miao", "Yi Zhang", "Weize Gao", "Man Luo", "Weiwei Feng", "Zhiya Tan", "Jianshu Li", "Ajian Liu", "Yunfeng Diao", "Qi Chu", "Tao Gong", "Zhe Li", "Weibin Yao", "Joey Tianyi Zhou"], "title": "DDL: A Dataset for Interpretable Deepfake Detection and Localization in Real-World Scenarios", "categories": ["cs.CV"], "comment": "This paper is a preliminary version, with an extended and\n  comprehensive version currently under development", "summary": "Recent advances in AIGC have exacerbated the misuse of malicious deepfake\ncontent, making the development of reliable deepfake detection methods an\nessential means to address this challenge. Although existing deepfake detection\nmodels demonstrate outstanding performance in detection metrics, most methods\nonly provide simple binary classification results, lacking interpretability. In\ncritical domains such as law, interpretability is crucial for enhancing the\ncredibility and authority of decisions. Recent studies attempt to improve the\ninterpretability of classification results by providing spatial manipulation\nmasks or temporal forgery segments. However, the practical effectiveness of\nthese methods remains suboptimal due to limitations of the forgery data. Most\ncurrent deepfake datasets predominantly offer binary labels, only a few\ndatasets with localization annotations. However, they suffer from restricted\nforgery scenarios, limited diversity in deepfake types, and insufficient data\nscale, making them inadequate for complex real-world scenarios. To address this\npredicament, we construct a novel large-scale deepfake detection and\nlocalization ($\\textbf{DDL}$) dataset containing over $\\textbf{1.8M}$ forged\nsamples and encompassing up to $\\textbf{75}$ distinct deepfake methods. The DDL\ndesign incorporates four key innovations: (1) $\\textbf{Diverse Forgery\nScenarios}$, (2) $\\textbf{Comprehensive Deepfake Methods}$, (3) $\\textbf{Varied\nManipulation Modes}$, and (4) $\\textbf{Fine-grained Forgery Annotations}$.\nThrough these improvements, our DDL not only provides a more challenging\nbenchmark for complex real-world forgeries, but also offers crucial support for\nbuilding next-generation deepfake detection, localization, and interpretability\nmethods. The DDL dataset project page is on\nhttps://deepfake-workshop-ijcai2025.github.io/main/index.html.", "AI": {"tldr": "The paper introduces a large-scale deepfake detection and localization (DDL) dataset to address the lack of interpretability and diversity in existing deepfake detection methods and datasets.", "motivation": "The misuse of deepfake content necessitates reliable detection methods with interpretability, especially in critical domains like law. Existing datasets lack diversity and localization annotations, limiting practical effectiveness.", "method": "The authors construct the DDL dataset with 1.8M forged samples and 75 deepfake methods, featuring diverse scenarios, comprehensive methods, varied manipulation modes, and fine-grained annotations.", "result": "The DDL dataset provides a challenging benchmark for real-world forgeries and supports advanced detection, localization, and interpretability methods.", "conclusion": "The DDL dataset addresses limitations of current datasets and enhances the development of next-generation deepfake detection and interpretability tools."}}
{"id": "2409.01524", "pdf": "https://arxiv.org/pdf/2409.01524", "abs": "https://arxiv.org/abs/2409.01524", "authors": ["Yuchen Yan", "Jin Jiang", "Yang Liu", "Yixin Cao", "Xin Xu", "Mengdi Zhang", "Xunliang Cai", "Jian Shao"], "title": "S^3cMath: Spontaneous Step-level Self-correction Makes Large Language Models Better Mathematical Reasoners", "categories": ["cs.CL", "cs.AI"], "comment": "AAAI 2025: https://ojs.aaai.org/index.php/AAAI/article/view/34749", "summary": "Self-correction is a novel method that can stimulate the potential reasoning\nabilities of large language models (LLMs). It involves detecting and correcting\nerrors during the inference process when LLMs solve reasoning problems.\nHowever, recent works do not regard self-correction as a spontaneous and\nintrinsic capability of LLMs. Instead, such correction is achieved through\npost-hoc generation, external knowledge introduction, multi-model\ncollaboration, and similar techniques. In this paper, we propose a series of\nmathematical LLMs called S$^3$c-Math, which are able to perform Spontaneous\nStep-level Self-correction for Mathematical reasoning. This capability helps\nLLMs to recognize whether their ongoing inference tends to contain errors and\nsimultaneously correct these errors to produce a more reliable response. We\nproposed a method, which employs a step-level sampling approach to construct\nstep-wise self-correction data for achieving such ability. Additionally, we\nimplement a training strategy that uses above constructed data to equip LLMs\nwith spontaneous step-level self-correction capacities. Our data and methods\nhave been demonstrated to be effective across various foundation LLMs,\nconsistently showing significant progress in evaluations on GSM8K, MATH, and\nother mathematical benchmarks. To the best of our knowledge, we are the first\nto introduce the spontaneous step-level self-correction ability of LLMs in\nmathematical reasoning.", "AI": {"tldr": "The paper introduces S$^3$c-Math, a series of mathematical LLMs capable of spontaneous step-level self-correction for improved reasoning.", "motivation": "Current self-correction methods in LLMs rely on external interventions, not intrinsic capabilities. The aim is to enable LLMs to autonomously detect and correct errors during reasoning.", "method": "A step-level sampling approach constructs self-correction data, and a training strategy equips LLMs with spontaneous step-level self-correction.", "result": "S$^3$c-Math shows significant improvements on GSM8K, MATH, and other benchmarks.", "conclusion": "The work pioneers spontaneous step-level self-correction in LLMs for mathematical reasoning, proving its effectiveness."}}
{"id": "2506.23538", "pdf": "https://arxiv.org/pdf/2506.23538", "abs": "https://arxiv.org/abs/2506.23538", "authors": ["Yuhao Huang", "Yueyue Xu", "Haoran Dou", "Jiaxiao Deng", "Xin Yang", "Hongyu Zheng", "Dong Ni"], "title": "Uncertainty-aware Diffusion and Reinforcement Learning for Joint Plane Localization and Anomaly Diagnosis in 3D Ultrasound", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by MICCAI 2025;10 pages, 3 figures", "summary": "Congenital uterine anomalies (CUAs) can lead to infertility, miscarriage,\npreterm birth, and an increased risk of pregnancy complications. Compared to\ntraditional 2D ultrasound (US), 3D US can reconstruct the coronal plane,\nproviding a clear visualization of the uterine morphology for assessing CUAs\naccurately. In this paper, we propose an intelligent system for simultaneous\nautomated plane localization and CUA diagnosis. Our highlights are: 1) we\ndevelop a denoising diffusion model with local (plane) and global (volume/text)\nguidance, using an adaptive weighting strategy to optimize attention allocation\nto different conditions; 2) we introduce a reinforcement learning-based\nframework with unsupervised rewards to extract the key slice summary from\nredundant sequences, fully integrating information across multiple planes to\nreduce learning difficulty; 3) we provide text-driven uncertainty modeling for\ncoarse prediction, and leverage it to adjust the classification probability for\noverall performance improvement. Extensive experiments on a large 3D uterine US\ndataset show the efficacy of our method, in terms of plane localization and CUA\ndiagnosis. Code is available at https://github.com/yuhoo0302/CUA-US.", "AI": {"tldr": "An intelligent system for automated plane localization and CUA diagnosis using 3D ultrasound, combining denoising diffusion models, reinforcement learning, and text-driven uncertainty modeling.", "motivation": "CUAs cause infertility and pregnancy complications; 3D US improves visualization over 2D US for accurate diagnosis.", "method": "1) Denoising diffusion model with local/global guidance. 2) Reinforcement learning for key slice extraction. 3) Text-driven uncertainty modeling for prediction refinement.", "result": "Effective plane localization and CUA diagnosis demonstrated on a large 3D uterine US dataset.", "conclusion": "The proposed system enhances accuracy and efficiency in diagnosing CUAs using 3D US."}}
{"id": "2506.24018", "pdf": "https://arxiv.org/pdf/2506.24018", "abs": "https://arxiv.org/abs/2506.24018", "authors": ["Veronica Lachi", "Francesco Ferrini", "Antonio Longa", "Bruno Lepri", "Andrea Passerini", "Manfred Jaeger"], "title": "Bridging Theory and Practice in Link Representation with Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) are widely used to compute representations of\nnode pairs for downstream tasks such as link prediction. Yet, theoretical\nunderstanding of their expressive power has focused almost entirely on\ngraph-level representations. In this work, we shift the focus to links and\nprovide the first comprehensive study of GNN expressiveness in link\nrepresentation. We introduce a unifying framework, the $k_\\phi$-$k_\\rho$-$m$\nframework, that subsumes existing message-passing link models and enables\nformal expressiveness comparisons. Using this framework, we derive a hierarchy\nof state-of-the-art methods and offer theoretical tools to analyze future\narchitectures. To complement our analysis, we propose a synthetic evaluation\nprotocol comprising the first benchmark specifically designed to assess\nlink-level expressiveness. Finally, we ask: does expressiveness matter in\npractice? We use a graph symmetry metric that quantifies the difficulty of\ndistinguishing links and show that while expressive models may underperform on\nstandard benchmarks, they significantly outperform simpler ones as symmetry\nincreases, highlighting the need for dataset-aware model selection.", "AI": {"tldr": "The paper studies the expressive power of GNNs for link representation, introduces a unifying framework, and shows that expressive models outperform simpler ones in high-symmetry scenarios.", "motivation": "Existing theoretical understanding of GNNs focuses on graph-level representations, leaving a gap in understanding their expressiveness for link-level tasks like link prediction.", "method": "The authors introduce the $k_\\phi$-$k_\\rho$-$m$ framework to unify and compare message-passing link models, derive a hierarchy of methods, and propose a synthetic benchmark for evaluation.", "result": "Expressive models underperform on standard benchmarks but excel in high-symmetry scenarios, as shown by a graph symmetry metric.", "conclusion": "The study highlights the importance of dataset-aware model selection and provides tools for analyzing future GNN architectures for link representation."}}
{"id": "2506.23295", "pdf": "https://arxiv.org/pdf/2506.23295", "abs": "https://arxiv.org/abs/2506.23295", "authors": ["Xiang Xu"], "title": "DiffFit: Disentangled Garment Warping and Texture Refinement for Virtual Try-On", "categories": ["cs.CV"], "comment": null, "summary": "Virtual try-on (VTON) aims to synthesize realistic images of a person wearing\na target garment, with broad applications in e-commerce and digital fashion.\nWhile recent advances in latent diffusion models have substantially improved\nvisual quality, existing approaches still struggle with preserving fine-grained\ngarment details, achieving precise garment-body alignment, maintaining\ninference efficiency, and generalizing to diverse poses and clothing styles. To\naddress these challenges, we propose DiffFit, a novel two-stage latent\ndiffusion framework for high-fidelity virtual try-on. DiffFit adopts a\nprogressive generation strategy: the first stage performs geometry-aware\ngarment warping, aligning the garment with the target body through fine-grained\ndeformation and pose adaptation. The second stage refines texture fidelity via\na cross-modal conditional diffusion model that integrates the warped garment,\nthe original garment appearance, and the target person image for high-quality\nrendering. By decoupling geometric alignment and appearance refinement, DiffFit\neffectively reduces task complexity and enhances both generation stability and\nvisual realism. It excels in preserving garment-specific attributes such as\ntextures, wrinkles, and lighting, while ensuring accurate alignment with the\nhuman body. Extensive experiments on large-scale VTON benchmarks demonstrate\nthat DiffFit achieves superior performance over existing state-of-the-art\nmethods in both quantitative metrics and perceptual evaluations.", "AI": {"tldr": "DiffFit is a two-stage latent diffusion framework for high-fidelity virtual try-on, addressing challenges like garment detail preservation and alignment.", "motivation": "Existing VTON methods struggle with garment detail preservation, alignment, efficiency, and generalization.", "method": "DiffFit uses a two-stage approach: geometry-aware garment warping followed by texture refinement via cross-modal diffusion.", "result": "DiffFit outperforms state-of-the-art methods in preserving garment details and alignment, validated by benchmarks.", "conclusion": "DiffFit effectively decouples geometric and appearance tasks, enhancing realism and stability in virtual try-on."}}
{"id": "2409.15380", "pdf": "https://arxiv.org/pdf/2409.15380", "abs": "https://arxiv.org/abs/2409.15380", "authors": ["Jann Railey Montalan", "Jian Gang Ngui", "Wei Qi Leong", "Yosephine Susanto", "Hamsawardhini Rengarajan", "Alham Fikri Aji", "William Chandra Tjhi"], "title": "Kalahi: A handcrafted, grassroots cultural LLM evaluation suite for Filipino", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted for presentation at Paclic 38, 2024", "summary": "Multilingual large language models (LLMs) today may not necessarily provide\nculturally appropriate and relevant responses to its Filipino users. We\nintroduce Kalahi, a cultural LLM evaluation suite collaboratively created by\nnative Filipino speakers. It is composed of 150 high-quality, handcrafted and\nnuanced prompts that test LLMs for generations that are relevant to shared\nFilipino cultural knowledge and values. Strong LLM performance in Kalahi\nindicates a model's ability to generate responses similar to what an average\nFilipino would say or do in a given situation. We conducted experiments on LLMs\nwith multilingual and Filipino language support. Results show that Kalahi,\nwhile trivial for Filipinos, is challenging for LLMs, with the best model\nanswering only 46.0% of the questions correctly compared to native Filipino\nperformance of 89.10%. Thus, Kalahi can be used to accurately and reliably\nevaluate Filipino cultural representation in LLMs.", "AI": {"tldr": "Kalahi is a cultural evaluation suite for LLMs, designed by native Filipino speakers, to assess culturally appropriate responses. It reveals LLMs struggle with Filipino cultural nuances, scoring only 46% compared to native performance of 89.1%.", "motivation": "Current multilingual LLMs often fail to provide culturally relevant responses for Filipino users, highlighting the need for a culturally specific evaluation tool.", "method": "Kalahi includes 150 handcrafted prompts testing LLMs on Filipino cultural knowledge and values. Experiments were conducted on multilingual and Filipino-supported LLMs.", "result": "The best LLM scored only 46.0% on Kalahi, significantly lower than the 89.10% achieved by native Filipinos, demonstrating the challenge of cultural relevance for LLMs.", "conclusion": "Kalahi effectively evaluates Filipino cultural representation in LLMs, showing current models lack adequate cultural understanding for Filipino users."}}
{"id": "2506.23560", "pdf": "https://arxiv.org/pdf/2506.23560", "abs": "https://arxiv.org/abs/2506.23560", "authors": ["Shakir Showkat Sofi", "Charlotte Vermeylen", "Lieven De Lathauwer"], "title": "Tensor Train Quantum State Tomography using Compressed Sensing", "categories": ["quant-ph", "cs.AI", "eess.SP", "math.OC"], "comment": "Accepted for publication in EUSIPCO 2025", "summary": "Quantum state tomography (QST) is a fundamental technique for estimating the\nstate of a quantum system from measured data and plays a crucial role in\nevaluating the performance of quantum devices. However, standard estimation\nmethods become impractical due to the exponential growth of parameters in the\nstate representation. In this work, we address this challenge by parameterizing\nthe state using a low-rank block tensor train decomposition and demonstrate\nthat our approach is both memory- and computationally efficient. This framework\napplies to a broad class of quantum states that can be well approximated by\nlow-rank decompositions, including pure states, nearly pure states, and ground\nstates of Hamiltonians.", "AI": {"tldr": "The paper proposes a low-rank block tensor train decomposition for efficient quantum state tomography, addressing the impracticality of standard methods due to exponential parameter growth.", "motivation": "Standard quantum state tomography methods are impractical for large systems due to exponential parameter growth. The work aims to provide a scalable solution.", "method": "The state is parameterized using a low-rank block tensor train decomposition, ensuring memory and computational efficiency.", "result": "The approach is shown to be efficient for a broad class of quantum states, including pure states, nearly pure states, and ground states of Hamiltonians.", "conclusion": "The proposed method offers a practical and scalable solution for quantum state tomography, applicable to various quantum states."}}
{"id": "2506.24042", "pdf": "https://arxiv.org/pdf/2506.24042", "abs": "https://arxiv.org/abs/2506.24042", "authors": ["Gen Li", "Yuchen Zhou", "Yuting Wei", "Yuxin Chen"], "title": "Faster Diffusion Models via Higher-Order Approximation", "categories": ["cs.LG", "cs.NA", "math.NA", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "In this paper, we explore provable acceleration of diffusion models without\nany additional retraining. Focusing on the task of approximating a target data\ndistribution in $\\mathbb{R}^d$ to within $\\varepsilon$ total-variation\ndistance, we propose a principled, training-free sampling algorithm that\nrequires only the order of\n  $$ d^{1+2/K} \\varepsilon^{-1/K} $$\n  score function evaluations (up to log factor) in the presence of accurate\nscores, where $K$ is an arbitrarily large fixed integer. This result applies to\na broad class of target data distributions, without the need for assumptions\nsuch as smoothness or log-concavity. Our theory is robust vis-a-vis inexact\nscore estimation, degrading gracefully as the score estimation error increases\n-- without demanding higher-order smoothness on the score estimates as assumed\nin previous work. The proposed algorithm draws insight from high-order ODE\nsolvers, leveraging high-order Lagrange interpolation and successive refinement\nto approximate the integral derived from the probability flow ODE.", "AI": {"tldr": "A training-free sampling algorithm for diffusion models achieves provable acceleration without retraining, requiring fewer score function evaluations for accurate distribution approximation.", "motivation": "To improve the efficiency of diffusion models by reducing the computational cost of sampling without additional training or restrictive assumptions on the data distribution.", "method": "The algorithm uses high-order ODE solvers, Lagrange interpolation, and successive refinement to approximate the probability flow ODE integral, minimizing score function evaluations.", "result": "The method requires only $d^{1+2/K} \\varepsilon^{-1/K}$ score evaluations (up to log factor) for accurate approximation, robust to inexact score estimation.", "conclusion": "The proposed algorithm offers a scalable and efficient solution for diffusion models, applicable to a wide range of data distributions without strict assumptions."}}
{"id": "2506.23308", "pdf": "https://arxiv.org/pdf/2506.23308", "abs": "https://arxiv.org/abs/2506.23308", "authors": ["Yiming Huang", "Long Bai", "Beilei Cui", "Yanheng Li", "Tong Chen", "Jie Wang", "Jinlin Wu", "Zhen Lei", "Hongbin Liu", "Hongliang Ren"], "title": "Endo-4DGX: Robust Endoscopic Scene Reconstruction and Illumination Correction with Gaussian Splatting", "categories": ["cs.CV"], "comment": "MICCAI 2025. Project Page:\n  https://lastbasket.github.io/MICCAI-2025-Endo-4DGX/", "summary": "Accurate reconstruction of soft tissue is crucial for advancing automation in\nimage-guided robotic surgery. The recent 3D Gaussian Splatting (3DGS)\ntechniques and their variants, 4DGS, achieve high-quality renderings of dynamic\nsurgical scenes in real-time. However, 3D-GS-based methods still struggle in\nscenarios with varying illumination, such as low light and over-exposure.\nTraining 3D-GS in such extreme light conditions leads to severe optimization\nproblems and devastating rendering quality. To address these challenges, we\npresent Endo-4DGX, a novel reconstruction method with illumination-adaptive\nGaussian Splatting designed specifically for endoscopic scenes with uneven\nlighting. By incorporating illumination embeddings, our method effectively\nmodels view-dependent brightness variations. We introduce a region-aware\nenhancement module to model the sub-area lightness at the Gaussian level and a\nspatial-aware adjustment module to learn the view-consistent brightness\nadjustment. With the illumination adaptive design, Endo-4DGX achieves superior\nrendering performance under both low-light and over-exposure conditions while\nmaintaining geometric accuracy. Additionally, we employ an exposure control\nloss to restore the appearance from adverse exposure to the normal level for\nillumination-adaptive optimization. Experimental results demonstrate that\nEndo-4DGX significantly outperforms combinations of state-of-the-art\nreconstruction and restoration methods in challenging lighting environments,\nunderscoring its potential to advance robot-assisted surgical applications. Our\ncode is available at https://github.com/lastbasket/Endo-4DGX.", "AI": {"tldr": "Endo-4DGX improves 3D Gaussian Splatting for endoscopic scenes with uneven lighting, using illumination embeddings and adaptive modules to enhance rendering quality under extreme light conditions.", "motivation": "Accurate soft tissue reconstruction is vital for robotic surgery, but current 3DGS methods fail under varying illumination (low light or over-exposure).", "method": "Endo-4DGX introduces illumination-adaptive Gaussian Splatting with illumination embeddings, region-aware enhancement, and spatial-aware adjustment modules, plus an exposure control loss.", "result": "Endo-4DGX outperforms state-of-the-art methods in challenging lighting, maintaining geometric accuracy and improving rendering quality.", "conclusion": "Endo-4DGX advances robotic surgery by enabling high-quality reconstructions in uneven lighting, with potential for broader surgical applications."}}
{"id": "2410.03145", "pdf": "https://arxiv.org/pdf/2410.03145", "abs": "https://arxiv.org/abs/2410.03145", "authors": ["Kyuyoung Kim", "Ah Jeong Seo", "Hao Liu", "Jinwoo Shin", "Kimin Lee"], "title": "Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback", "categories": ["cs.CL"], "comment": "EMNLP 2024 Findings", "summary": "Large language models (LLMs) fine-tuned with alignment techniques, such as\nreinforcement learning from human feedback, have been instrumental in\ndeveloping some of the most capable AI systems to date. Despite their success,\nexisting methods typically rely on simple binary labels, such as those\nindicating preferred outputs in pairwise preferences, which fail to capture the\nsubtle differences in relative quality between pairs. To address this\nlimitation, we introduce an approach called Margin Matching Preference\nOptimization (MMPO), which incorporates relative quality margins into\noptimization, leading to improved LLM policies and reward models. Specifically,\ngiven quality margins in pairwise preferences, we design soft target\nprobabilities based on the Bradley-Terry model, which are then used to train\nmodels with the standard cross-entropy objective. Experiments with both human\nand AI feedback data demonstrate that MMPO consistently outperforms baseline\nmethods, often by a substantial margin, on popular benchmarks including\nMT-bench and RewardBench. Notably, the 7B model trained with MMPO achieves\nstate-of-the-art performance on RewardBench as of June 2024, outperforming\nother models of the same scale. Our analysis also shows that MMPO is more\nrobust to overfitting, leading to better-calibrated models.", "AI": {"tldr": "MMPO improves LLM alignment by incorporating quality margins in preferences, outperforming baselines on benchmarks like MT-bench and RewardBench.", "motivation": "Existing alignment methods rely on binary labels, missing subtle quality differences in outputs.", "method": "MMPO uses soft target probabilities based on the Bradley-Terry model, trained with cross-entropy.", "result": "MMPO achieves state-of-the-art performance on RewardBench and is more robust to overfitting.", "conclusion": "MMPO enhances LLM policies and reward models by better capturing relative quality margins."}}
{"id": "2506.23573", "pdf": "https://arxiv.org/pdf/2506.23573", "abs": "https://arxiv.org/abs/2506.23573", "authors": ["Siddhartha Mondal", "Avik Mitra", "Chayan Sarkar"], "title": "Online Human Action Detection during Escorting", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Accepted in IEEE RO-MAN '25", "summary": "The deployment of robot assistants in large indoor spaces has seen\nsignificant growth, with escorting tasks becoming a key application. However,\nmost current escorting robots primarily rely on navigation-focused strategies,\nassuming that the person being escorted will follow without issue. In crowded\nenvironments, this assumption often falls short, as individuals may struggle to\nkeep pace, become obstructed, get distracted, or need to stop unexpectedly. As\na result, conventional robotic systems are often unable to provide effective\nescorting services due to their limited understanding of human movement\ndynamics. To address these challenges, an effective escorting robot must\ncontinuously detect and interpret human actions during the escorting process\nand adjust its movement accordingly. However, there is currently no existing\ndataset designed specifically for human action detection in the context of\nescorting. Given that escorting often occurs in crowded environments, where\nother individuals may enter the robot's camera view, the robot also needs to\nidentify the specific human it is escorting (the subject) before predicting\ntheir actions. Since no existing model performs both person re-identification\nand action prediction in real-time, we propose a novel neural network\narchitecture that can accomplish both tasks. This enables the robot to adjust\nits speed dynamically based on the escortee's movements and seamlessly resume\nescorting after any disruption. In comparative evaluations against strong\nbaselines, our system demonstrates superior efficiency and effectiveness,\nshowcasing its potential to significantly improve robotic escorting services in\ncomplex, real-world scenarios.", "AI": {"tldr": "A novel neural network architecture is proposed to improve robotic escorting by combining person re-identification and action prediction in real-time, addressing challenges in crowded environments.", "motivation": "Current escorting robots fail in crowded spaces due to limited understanding of human movement dynamics, necessitating better detection and adaptation.", "method": "Proposes a neural network for real-time person re-identification and action prediction to dynamically adjust robot speed and resume escorting.", "result": "Outperforms baselines in efficiency and effectiveness, enhancing robotic escorting in complex scenarios.", "conclusion": "The system significantly improves escorting services by adapting to human actions in real-time."}}
{"id": "2506.24093", "pdf": "https://arxiv.org/pdf/2506.24093", "abs": "https://arxiv.org/abs/2506.24093", "authors": ["Paul Wachter", "Lukas Niehaus", "Julius Sch\u00f6ning"], "title": "Development of Hybrid Artificial Intelligence Training on Real and Synthetic Data: Benchmark on Two Mixed Training Strategies", "categories": ["cs.LG", "cs.AI", "I.2.1; I.2.0; F.2.3"], "comment": "21pages, 14 figures, 2 tables", "summary": "Synthetic data has emerged as a cost-effective alternative to real data for\ntraining artificial neural networks (ANN). However, the disparity between\nsynthetic and real data results in a domain gap. That gap leads to poor\nperformance and generalization of the trained ANN when applied to real-world\nscenarios. Several strategies have been developed to bridge this gap, which\ncombine synthetic and real data, known as mixed training using hybrid datasets.\nWhile these strategies have been shown to mitigate the domain gap, a systematic\nevaluation of their generalizability and robustness across various tasks and\narchitectures remains underexplored. To address this challenge, our study\ncomprehensively analyzes two widely used mixing strategies on three prevalent\narchitectures and three distinct hybrid datasets. From these datasets, we\nsample subsets with varying proportions of synthetic to real data to\ninvestigate the impact of synthetic and real components. The findings of this\npaper provide valuable insights into optimizing the use of synthetic data in\nthe training process of any ANN, contributing to enhancing robustness and\nefficacy.", "AI": {"tldr": "The paper evaluates mixed training strategies using hybrid datasets (synthetic and real data) to bridge the domain gap in ANN training, analyzing their impact across tasks and architectures.", "motivation": "The disparity between synthetic and real data causes poor ANN performance in real-world scenarios, necessitating a systematic study of mixed training strategies.", "method": "The study analyzes two mixing strategies on three architectures and three hybrid datasets, varying synthetic-to-real data proportions.", "result": "The findings offer insights into optimizing synthetic data use to improve ANN robustness and efficacy.", "conclusion": "The study contributes to better understanding and enhancing the effectiveness of synthetic data in ANN training."}}
{"id": "2506.23323", "pdf": "https://arxiv.org/pdf/2506.23323", "abs": "https://arxiv.org/abs/2506.23323", "authors": ["Quang-Huy Che", "Vinh-Tiep Nguyen"], "title": "FastSeg: Efficient Training-Free Open-Vocabulary Segmentation via Hierarchical Attention Refinement Method", "categories": ["cs.CV"], "comment": null, "summary": "Open-vocabulary semantic segmentation (OVSS) aims to segment objects from\narbitrary text categories without requiring densely annotated datasets.\nAlthough contrastive learning based models enable zero-shot segmentation, they\noften lose fine spatial precision at pixel level, due to global representation\nbias. In contrast, diffusion-based models naturally encode fine-grained spatial\nfeatures via attention mechanisms that capture both global context and local\ndetails. However, they often face challenges in balancing the number of\niterations with the quality of the segmentation. In this work, we propose\nFastSeg, a novel and efficient training-free framework with only (1+1)-step of\nreverse process of a pretrained diffusion model (e.g., Stable Diffusion).\nMoreover, instead of running multiple times for different classes, FastSeg\nperforms segmentation for all classes at once. To further enhance the\nsegmentation quality, FastSeg introduces three key components: (i) a\ndual-prompt mechanism for discriminative, class-aware attention extraction,\n(ii) a Hierarchical Attention Refinement Method (HARD) that enhances fused\ncross-attention using scale-aligned selfattention maps, and (iii) a Test-Time\nFlipping (TTF) scheme designed to improve spatial consistency. Extensive\nexperiments show that FastSeg achieves state-of-the-art training-free\nperformance, obtaining 43.8% average mIoU across PASCAL VOC, PASCAL Context,\nand COCO Object benchmarks while maintaining superior inference efficiency. Our\nresults demonstrate that FastSeg provides a strong foundation for\nextendability, bridging the gap between segmentation quality and inference\nefficiency.", "AI": {"tldr": "FastSeg is a training-free framework for open-vocabulary semantic segmentation, using a pretrained diffusion model with minimal steps and innovative components for improved quality and efficiency.", "motivation": "Addressing the trade-off between fine spatial precision and segmentation quality in existing methods, FastSeg aims to bridge this gap efficiently.", "method": "Leverages a (1+1)-step reverse process of a pretrained diffusion model, dual-prompt mechanism, Hierarchical Attention Refinement Method (HARD), and Test-Time Flipping (TTF) for all-class segmentation.", "result": "Achieves 43.8% average mIoU on PASCAL VOC, PASCAL Context, and COCO Object benchmarks with superior efficiency.", "conclusion": "FastSeg sets a strong foundation for extendability, balancing segmentation quality and inference efficiency."}}
{"id": "2410.06735", "pdf": "https://arxiv.org/pdf/2410.06735", "abs": "https://arxiv.org/abs/2410.06735", "authors": ["Fumiya Uchiyama", "Takeshi Kojima", "Andrew Gambardella", "Qi Cao", "Yusuke Iwasawa", "Yutaka Matsuo"], "title": "Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to EMNLP2024", "summary": "Recent large language models (LLMs) have demonstrated remarkable\ngeneralization abilities in mathematics and logical reasoning tasks. Prior\nresearch indicates that LLMs pre-trained with programming language data exhibit\nhigh mathematical and reasoning abilities; however, this causal relationship\nhas not been rigorously tested. Our research aims to verify which programming\nlanguages and features during pre-training affect logical inference\nperformance. Specifically, we pre-trained decoder-based language models from\nscratch using datasets from ten programming languages (e.g., Python, C, Java)\nand three natural language datasets (Wikipedia, Fineweb, C4) under identical\nconditions. Thereafter, we evaluated the trained models in a few-shot\nin-context learning setting on logical reasoning tasks: FLD and bAbi, which do\nnot require commonsense or world knowledge. The results demonstrate that nearly\nall models trained with programming languages consistently outperform those\ntrained with natural languages, indicating that programming languages contain\nfactors that elicit logic inference performance. In addition, we found that\nmodels trained with programming languages exhibit a better ability to follow\ninstructions compared to those trained with natural languages. Further analysis\nreveals that the depth of Abstract Syntax Trees representing parsed results of\nprograms also affects logical reasoning performance. These findings will offer\ninsights into the essential elements of pre-training for acquiring the\nfoundational abilities of LLMs.", "AI": {"tldr": "LLMs pre-trained with programming languages outperform those trained with natural languages in logical reasoning tasks, with AST depth also influencing performance.", "motivation": "To verify the causal relationship between programming language pre-training and enhanced logical reasoning abilities in LLMs.", "method": "Pre-trained decoder-based models from scratch using ten programming languages and three natural language datasets, evaluated on FLD and bAbi tasks.", "result": "Programming language-trained models consistently outperformed natural language-trained ones, with better instruction-following and AST depth impacting reasoning.", "conclusion": "Programming languages contain factors that enhance logical inference, offering insights for LLM pre-training."}}
{"id": "2506.23581", "pdf": "https://arxiv.org/pdf/2506.23581", "abs": "https://arxiv.org/abs/2506.23581", "authors": ["Xiao Li", "Yiming Zhu", "Yifan Huang", "Wei Zhang", "Yingzhe He", "Jie Shi", "Xiaolin Hu"], "title": "PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by ICCV 2025", "summary": "Object detection plays a crucial role in many security-sensitive\napplications. However, several recent studies have shown that object detectors\ncan be easily fooled by physically realizable attacks, \\eg, adversarial patches\nand recent adversarial textures, which pose realistic and urgent threats.\nAdversarial Training (AT) has been recognized as the most effective defense\nagainst adversarial attacks. While AT has been extensively studied in the\n$l_\\infty$ attack settings on classification models, AT against physically\nrealizable attacks on object detectors has received limited exploration. Early\nattempts are only performed to defend against adversarial patches, leaving AT\nagainst a wider range of physically realizable attacks under-explored. In this\nwork, we consider defending against various physically realizable attacks with\na unified AT method. We propose PBCAT, a novel Patch-Based Composite\nAdversarial Training strategy. PBCAT optimizes the model by incorporating the\ncombination of small-area gradient-guided adversarial patches and imperceptible\nglobal adversarial perturbations covering the entire image. With these designs,\nPBCAT has the potential to defend against not only adversarial patches but also\nunseen physically realizable attacks such as adversarial textures. Extensive\nexperiments in multiple settings demonstrated that PBCAT significantly improved\nrobustness against various physically realizable attacks over state-of-the-art\ndefense methods. Notably, it improved the detection accuracy by 29.7\\% over\nprevious defense methods under one recent adversarial texture attack.", "AI": {"tldr": "The paper proposes PBCAT, a novel adversarial training method to defend against various physically realizable attacks on object detectors, improving robustness significantly.", "motivation": "Object detectors are vulnerable to physically realizable attacks like adversarial patches and textures, but existing adversarial training methods are limited in scope.", "method": "PBCAT combines small-area gradient-guided adversarial patches and imperceptible global perturbations for unified defense.", "result": "PBCAT improved detection accuracy by 29.7% under adversarial texture attacks, outperforming state-of-the-art defenses.", "conclusion": "PBCAT effectively defends against diverse physically realizable attacks, enhancing object detector robustness."}}
{"id": "2506.24120", "pdf": "https://arxiv.org/pdf/2506.24120", "abs": "https://arxiv.org/abs/2506.24120", "authors": ["Yuqing Wang", "Shangding Gu"], "title": "Data Uniformity Improves Training Efficiency and More, with a Convergence Framework Beyond the NTK Regime", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "comment": null, "summary": "Data selection plays a crucial role in data-driven decision-making, including\nin large language models (LLMs), and is typically task-dependent. Properties\nsuch as data quality and diversity have been extensively studied and are known\nto enhance model performance. However, it remains unclear whether there exist\nother quantitative and general principles of data selection that can\nconsistently improve performance, especially for complex tasks with limited\nprior knowledge. In this paper, we demonstrate that selecting more uniformly\ndistributed data can improve training efficiency while enhancing performance.\nSpecifically, we establish that more uniform (less biased) distribution leads\nto a larger minimum pairwise distance between data points, denoted by\n$h_{\\min}$, and prove that a smaller $h_{\\min}$ can slow down the training\ndynamics of gradient descent (GD). Moreover, we theoretically show that the\napproximation error of neural networks decreases as $h_{\\min}$ increases. Our\nanalysis introduces a convergence framework for GD beyond the Neural Tangent\nKernel (NTK) regime, applicable to a broad class of architectures, including\ntransformers, without requiring Lipschitz smoothness. This framework further\nprovides theoretical justification for the use of residual connections and\nfunction compositions in deep neural architectures. In the end, we conduct\ncomprehensive experiments for supervised fine-tuning across various settings,\nincluding different optimization strategies, model sizes, and training\ndatasets. The results consistently demonstrate that selecting data by\nmaximizing pairwise distance significantly accelerates training and achieves\ncomparable or better performance in LLMs across diverse datasets. Code and\nDatasets are available at the link:\nhttps://github.com/SafeRL-Lab/data-uniformity.", "AI": {"tldr": "Selecting uniformly distributed data improves training efficiency and performance in LLMs by maximizing pairwise distance between data points.", "motivation": "To identify general principles of data selection beyond quality and diversity that enhance model performance, especially for complex tasks with limited prior knowledge.", "method": "Theoretical analysis and experiments show that more uniform data distribution (larger minimum pairwise distance) accelerates gradient descent and reduces approximation error.", "result": "Data selection by maximizing pairwise distance significantly speeds up training and improves performance across various settings.", "conclusion": "Uniform data distribution is a key principle for efficient training and better performance in LLMs, supported by theoretical and empirical evidence."}}
{"id": "2506.23329", "pdf": "https://arxiv.org/pdf/2506.23329", "abs": "https://arxiv.org/abs/2506.23329", "authors": ["Parker Liu", "Chenxin Li", "Zhengxin Li", "Yipeng Wu", "Wuyang Li", "Zhiqin Yang", "Zhenyuan Zhang", "Yunlong Lin", "Sirui Han", "Brandon Y. Feng"], "title": "IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as Agentic Inverse Rendering", "categories": ["cs.CV"], "comment": "Project Page: https://ir3d-bench.github.io/", "summary": "Vision-language models (VLMs) excel at descriptive tasks, but whether they\ntruly understand scenes from visual observations remains uncertain. We\nintroduce IR3D-Bench, a benchmark challenging VLMs to demonstrate understanding\nthrough active creation rather than passive recognition. Grounded in the\nanalysis-by-synthesis paradigm, IR3D-Bench tasks Vision-Language Agents (VLAs)\nwith actively using programming and rendering tools to recreate the underlying\n3D structure of an input image, achieving agentic inverse rendering through\ntool use. This \"understanding-by-creating\" approach probes the tool-using\ngenerative capacity of VLAs, moving beyond the descriptive or conversational\ncapacity measured by traditional scene understanding benchmarks. We provide a\ncomprehensive suite of metrics to evaluate geometric accuracy, spatial\nrelations, appearance attributes, and overall plausibility. Initial experiments\non agentic inverse rendering powered by various state-of-the-art VLMs highlight\ncurrent limitations, particularly in visual precision rather than basic tool\nusage. IR3D-Bench, including data and evaluation protocols, is released to\nfacilitate systematic study and development of tool-using VLAs towards genuine\nscene understanding by creating.", "AI": {"tldr": "IR3D-Bench is a benchmark challenging VLMs to demonstrate scene understanding through active 3D recreation, moving beyond passive recognition.", "motivation": "To assess if VLMs truly understand scenes by testing their ability to actively recreate 3D structures from images, rather than just describe them.", "method": "Tasks VLAs with using programming and rendering tools to recreate 3D structures from input images, grounded in the analysis-by-synthesis paradigm.", "result": "Initial experiments reveal limitations in visual precision, not tool usage, among state-of-the-art VLMs.", "conclusion": "IR3D-Bench aims to advance tool-using VLAs for genuine scene understanding through creation, with released data and metrics for further study."}}
{"id": "2410.10360", "pdf": "https://arxiv.org/pdf/2410.10360", "abs": "https://arxiv.org/abs/2410.10360", "authors": ["Yongxin Xu", "Ruizhe Zhang", "Xinke Jiang", "Yujie Feng", "Yuzhen Xiao", "Xinyu Ma", "Runchuan Zhu", "Xu Chu", "Junfeng Zhao", "Yasha Wang"], "title": "Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning", "categories": ["cs.CL", "cs.IR"], "comment": "Accepted to ACL 2025 Main Conference", "summary": "Retrieval-Augmented Generation (RAG) offers an effective solution to the\nissues faced by Large Language Models (LLMs) in hallucination generation and\nknowledge obsolescence by incorporating externally retrieved knowledge.\nHowever, existing methods lack effective control mechanisms for integrating\ninternal and external knowledge. Inspired by human cognitive processes, we\npropose Parenting, a novel framework that decouples, identifies, and\npurposefully optimizes parameter subspaces related to adherence and robustness.\nSpecifically, Parenting utilizes a key parameter mining method that combines\nforward and backward propagation signals to localize subspaces representing\ndifferent capabilities. Then, Parenting employs a type-tailored tuning\nstrategy, applying specific and appropriate optimizations to different\nsubspaces, aiming to achieve a balanced enhancement of both adherence and\nrobustness. Extensive experiments on various datasets and models validate the\neffectiveness and generalizability of our method.", "AI": {"tldr": "Parenting is a framework for Retrieval-Augmented Generation (RAG) that decouples and optimizes parameter subspaces to balance adherence and robustness, improving LLM performance.", "motivation": "Addresses the lack of control in integrating internal and external knowledge in RAG methods, inspired by human cognition.", "method": "Uses key parameter mining with forward/backward propagation to localize subspaces, then applies type-tailored tuning for optimization.", "result": "Validated on various datasets and models, showing effectiveness and generalizability.", "conclusion": "Parenting enhances RAG by balancing adherence and robustness through targeted subspace optimization."}}
{"id": "2506.23603", "pdf": "https://arxiv.org/pdf/2506.23603", "abs": "https://arxiv.org/abs/2506.23603", "authors": ["Baihe Ma", "Yanna Jiang", "Xu Wang", "Guangshen Yu", "Qin Wang", "Caijun Sun", "Chen Li", "Xuelei Qi", "Ying He", "Wei Ni", "Ren Ping Liu"], "title": "SoK: Semantic Privacy in Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "As Large Language Models (LLMs) are increasingly deployed in sensitive\ndomains, traditional data privacy measures prove inadequate for protecting\ninformation that is implicit, contextual, or inferable - what we define as\nsemantic privacy. This Systematization of Knowledge (SoK) introduces a\nlifecycle-centric framework to analyze how semantic privacy risks emerge across\ninput processing, pretraining, fine-tuning, and alignment stages of LLMs. We\ncategorize key attack vectors and assess how current defenses, such as\ndifferential privacy, embedding encryption, edge computing, and unlearning,\naddress these threats. Our analysis reveals critical gaps in semantic-level\nprotection, especially against contextual inference and latent representation\nleakage. We conclude by outlining open challenges, including quantifying\nsemantic leakage, protecting multimodal inputs, balancing de-identification\nwith generation quality, and ensuring transparency in privacy enforcement. This\nwork aims to inform future research on designing robust, semantically aware\nprivacy-preserving techniques for LLMs.", "AI": {"tldr": "The paper introduces a framework to analyze semantic privacy risks in LLMs across their lifecycle, identifies gaps in current defenses, and outlines open challenges for future research.", "motivation": "Traditional privacy measures are insufficient for protecting implicit, contextual, or inferable information (semantic privacy) in LLMs deployed in sensitive domains.", "method": "The authors propose a lifecycle-centric framework to analyze semantic privacy risks, categorize attack vectors, and evaluate current defenses like differential privacy and encryption.", "result": "The analysis highlights gaps in semantic-level protection, particularly against contextual inference and latent representation leakage.", "conclusion": "The paper outlines open challenges and aims to guide future research on robust, semantically aware privacy-preserving techniques for LLMs."}}
{"id": "2506.24124", "pdf": "https://arxiv.org/pdf/2506.24124", "abs": "https://arxiv.org/abs/2506.24124", "authors": ["Dong Sixun", "Fan Wei", "Teresa Wu", "Fu Yanjie"], "title": "Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives", "categories": ["cs.LG", "cs.CV"], "comment": "Code: https://github.com/Ironieser/TimesCLIP", "summary": "Time series forecasting traditionally relies on unimodal numerical inputs,\nwhich often struggle to capture high-level semantic patterns due to their dense\nand unstructured nature. While recent approaches have explored representing\ntime series as text using large language models (LLMs), these methods remain\nlimited by the discrete nature of token sequences and lack the perceptual\nintuition humans typically apply, such as interpreting visual patterns. In this\npaper, we propose a multimodal contrastive learning framework that transforms\nraw time series into structured visual and textual perspectives. Rather than\nusing natural language or real-world images, we construct both modalities\ndirectly from numerical sequences. We then align these views in a shared\nsemantic space via contrastive learning, enabling the model to capture richer\nand more complementary representations. Furthermore, we introduce a variate\nselection module that leverages the aligned representations to identify the\nmost informative variables for multivariate forecasting. Extensive experiments\non fifteen short-term and six long-term forecasting benchmarks demonstrate that\nour approach consistently outperforms strong unimodal and cross-modal\nbaselines, highlighting the effectiveness of multimodal alignment in enhancing\ntime series forecasting. Code is available at:\nhttps://github.com/Ironieser/TimesCLIP.", "AI": {"tldr": "A multimodal contrastive learning framework enhances time series forecasting by aligning visual and textual representations derived from numerical sequences, outperforming unimodal and cross-modal baselines.", "motivation": "Traditional unimodal numerical inputs struggle with high-level semantic patterns, and existing text-based methods lack perceptual intuition like visual interpretation.", "method": "Proposes a framework transforming raw time series into visual and textual perspectives, aligning them via contrastive learning, and using a variate selection module for multivariate forecasting.", "result": "Outperforms baselines on fifteen short-term and six long-term forecasting benchmarks, demonstrating the effectiveness of multimodal alignment.", "conclusion": "Multimodal alignment significantly enhances time series forecasting by capturing richer and complementary representations."}}
{"id": "2506.23347", "pdf": "https://arxiv.org/pdf/2506.23347", "abs": "https://arxiv.org/abs/2506.23347", "authors": ["Yi Liu", "Shengqian Li", "Zuzeng Lin", "Feng Wang", "Si Liu"], "title": "CycleVAR: Repurposing Autoregressive Model for Unsupervised One-Step Image Translation", "categories": ["cs.CV"], "comment": null, "summary": "The current conditional autoregressive image generation methods have shown\npromising results, yet their potential remains largely unexplored in the\npractical unsupervised image translation domain, which operates without\nexplicit cross-domain correspondences. A critical limitation stems from the\ndiscrete quantization inherent in traditional Vector Quantization-based\nframeworks, which disrupts gradient flow between the Variational Autoencoder\ndecoder and causal Transformer, impeding end-to-end optimization during\nadversarial training in image space. To tackle this issue, we propose using\nSoftmax Relaxed Quantization, a novel approach that reformulates codebook\nselection as a continuous probability mixing process via Softmax, thereby\npreserving gradient propagation. Building upon this differentiable foundation,\nwe introduce CycleVAR, which reformulates image-to-image translation as\nimage-conditional visual autoregressive generation by injecting multi-scale\nsource image tokens as contextual prompts, analogous to prefix-based\nconditioning in language models. CycleVAR exploits two modes to generate the\ntarget image tokens, including (1) serial multi-step generation, enabling\niterative refinement across scales, and (2) parallel one-step generation\nsynthesizing all resolution outputs in a single forward pass. Experimental\nfindings indicate that the parallel one-step generation mode attains superior\ntranslation quality with quicker inference speed than the serial multi-step\nmode in unsupervised scenarios. Furthermore, both quantitative and qualitative\nresults indicate that CycleVAR surpasses previous state-of-the-art unsupervised\nimage translation models, \\textit{e}.\\textit{g}., CycleGAN-Turbo.", "AI": {"tldr": "CycleVAR introduces Softmax Relaxed Quantization and reformulates image translation as autoregressive generation, outperforming state-of-the-art models like CycleGAN-Turbo.", "motivation": "Address limitations of traditional Vector Quantization in unsupervised image translation by preserving gradient flow.", "method": "Uses Softmax Relaxed Quantization for continuous codebook selection and CycleVAR for autoregressive generation with multi-scale prompts.", "result": "Parallel one-step generation achieves better quality and speed than serial multi-step; CycleVAR outperforms CycleGAN-Turbo.", "conclusion": "CycleVAR advances unsupervised image translation with improved gradient flow and generation efficiency."}}
{"id": "2410.17711", "pdf": "https://arxiv.org/pdf/2410.17711", "abs": "https://arxiv.org/abs/2410.17711", "authors": ["Yixin Ji", "Yang Xiang", "Juntao Li", "Qingrong Xia", "Ping Li", "Xinyu Duan", "Zhefeng Wang", "Min Zhang"], "title": "Beware of Calibration Data for Pruning Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Published as a conference paper at ICLR 2025", "summary": "As large language models (LLMs) are widely applied across various fields,\nmodel compression has become increasingly crucial for reducing costs and\nimproving inference efficiency. Post-training pruning is a promising method\nthat does not require resource-intensive iterative training and only needs a\nsmall amount of calibration data to assess the importance of parameters. Recent\nresearch has enhanced post-training pruning from different aspects but few of\nthem systematically explore the effects of calibration data, and it is unclear\nif there exist better calibration data construction strategies. We fill this\nblank and surprisingly observe that calibration data is also crucial to\npost-training pruning, especially for high sparsity. Through controlled\nexperiments on important influence factors of calibration data, including the\npruning settings, the amount of data, and its similarity with pre-training\ndata, we observe that a small size of data is adequate, and more similar data\nto its pre-training stage can yield better performance. As pre-training data is\nusually inaccessible for advanced LLMs, we further provide a self-generating\ncalibration data synthesis strategy to construct feasible calibration data.\nExperimental results on recent strong open-source LLMs (e.g., DCLM, and\nLLaMA-3) show that the proposed strategy can enhance the performance of strong\npruning methods (e.g., Wanda, DSnoT, OWL) by a large margin (up to $2.68\\%$).\nCode is available at https://github.com/Dereck0602/calibration_data.", "AI": {"tldr": "The paper explores the impact of calibration data on post-training pruning for LLMs, finding its quality and similarity to pre-training data crucial. A self-generating calibration data strategy is proposed, improving pruning performance by up to 2.68%.", "motivation": "To address the lack of systematic exploration of calibration data's role in post-training pruning for LLMs, especially under high sparsity.", "method": "Conducts controlled experiments on calibration data factors (pruning settings, data amount, similarity to pre-training data) and proposes a self-generating synthesis strategy.", "result": "Small, similar calibration data improves performance; the self-generating strategy enhances pruning methods by up to 2.68%.", "conclusion": "Calibration data quality significantly impacts post-training pruning, and the proposed synthesis strategy offers a practical solution for advanced LLMs."}}
{"id": "2506.23605", "pdf": "https://arxiv.org/pdf/2506.23605", "abs": "https://arxiv.org/abs/2506.23605", "authors": ["Suyash Maniyar", "Vishvesh Trivedi", "Ajoy Mondal", "Anand Mishra", "C. V. Jawahar"], "title": "AI-Generated Lecture Slides for Improving Slide Element Detection and Retrieval", "categories": ["cs.CV", "cs.AI"], "comment": "40 pages including supplementary, accepted at ICDAR 2025", "summary": "Lecture slide element detection and retrieval are key problems in slide\nunderstanding. Training effective models for these tasks often depends on\nextensive manual annotation. However, annotating large volumes of lecture\nslides for supervised training is labor intensive and requires domain\nexpertise. To address this, we propose a large language model (LLM)-guided\nsynthetic lecture slide generation pipeline, SynLecSlideGen, which produces\nhigh-quality, coherent and realistic slides. We also create an evaluation\nbenchmark, namely RealSlide by manually annotating 1,050 real lecture slides.\nTo assess the utility of our synthetic slides, we perform few-shot transfer\nlearning on real data using models pre-trained on them. Experimental results\nshow that few-shot transfer learning with pretraining on synthetic slides\nsignificantly improves performance compared to training only on real data. This\ndemonstrates that synthetic data can effectively compensate for limited labeled\nlecture slides. The code and resources of our work are publicly available on\nour project website: https://synslidegen.github.io/.", "AI": {"tldr": "Proposes SynLecSlideGen, an LLM-guided pipeline for generating synthetic lecture slides, and shows its effectiveness in improving few-shot transfer learning performance on real data.", "motivation": "Manual annotation of lecture slides for training models is labor-intensive and requires expertise. Synthetic data can address this limitation.", "method": "Developed SynLecSlideGen, a pipeline for generating synthetic slides, and created RealSlide, a benchmark of annotated real slides. Evaluated via few-shot transfer learning.", "result": "Pretraining on synthetic slides significantly boosts performance compared to training only on real data.", "conclusion": "Synthetic data effectively compensates for limited labeled lecture slides, enhancing model performance."}}
{"id": "2506.22450", "pdf": "https://arxiv.org/pdf/2506.22450", "abs": "https://arxiv.org/abs/2506.22450", "authors": ["Jens Winkler", "Michael Denhard"], "title": "Arnoldi Singular Vector perturbations for machine learning weather prediction", "categories": ["physics.ao-ph", "cs.LG"], "comment": "dynamical systems, atmospheric physics, machine learing weather\n  prediction, forecast uncertainity, 42 pages with 29 figures (inkl. appendix)", "summary": "Since weather forecasts are fundamentally uncertain, reliable decision making\nrequires information on the likelihoods of future weather scenarios. We explore\nthe sensitivity of machine learning weather prediction (MLWP) using the 24h\nPangu Weather ML model of Huawei to errors in the initial conditions with a\nspecific kind of Singular Vector (SV) perturbations. Our Arnoldi-SV (A-SV)\nmethod does not need linear nor adjoint model versions and is applicable to\nnumerical weather prediction (NWP) as well as MLWP. It observes error growth\nwithin a given optimization time window by iteratively applying a forecast\nmodel to perturbed model states. This creates a Krylov subspace, implicitly\nbased on a matrix operator, which approximates the local error growth. Each\niteration adds new dimensions to the Krylov space and its leading right SVs are\nexpected to turn into directions of growing errors. We show that A-SV indeed\nfinds dynamically meaningful perturbation patterns for the 24h Pangu Weather\nmodel, which grow right from the beginning of the forecast rollout. These\nperturbations describe local unstable modes and could be a basis to initialize\nMLWP ensembles. Since we start A-SV from random noise perturbations, the\nalgorithm transforms noise into perturbations conditioned on a given reference\nstate - a process that is akin to the denoising process of the generic\ndiffusion based ML model of GenCast, therefor we briefly discuss similarities\nand differences.", "AI": {"tldr": "The paper explores the sensitivity of machine learning weather prediction (MLWP) to initial condition errors using Arnoldi-Singular Vector (A-SV) perturbations, demonstrating its applicability to both MLWP and numerical weather prediction (NWP).", "motivation": "Weather forecasts are uncertain, and reliable decision-making requires understanding the likelihoods of future weather scenarios. The study aims to assess MLWP's sensitivity to initial condition errors.", "method": "The A-SV method, which doesn't require linear or adjoint models, iteratively applies a forecast model to perturbed states to observe error growth, creating a Krylov subspace to approximate local error growth.", "result": "A-SV identifies dynamically meaningful perturbation patterns for the 24h Pangu Weather model, revealing local unstable modes that could initialize MLWP ensembles.", "conclusion": "The A-SV method effectively transforms noise into conditioned perturbations, resembling denoising in diffusion-based ML models, and offers potential for improving MLWP ensemble initialization."}}
{"id": "2506.23352", "pdf": "https://arxiv.org/pdf/2506.23352", "abs": "https://arxiv.org/abs/2506.23352", "authors": ["Shunsuke Yasuki", "Taiki Miyanishi", "Nakamasa Inoue", "Shuhei Kurita", "Koya Sakamoto", "Daichi Azuma", "Masato Taki", "Yutaka Matsuo"], "title": "GeoProg3D: Compositional Visual Reasoning for City-Scale 3D Language Fields", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "The advancement of 3D language fields has enabled intuitive interactions with\n3D scenes via natural language. However, existing approaches are typically\nlimited to small-scale environments, lacking the scalability and compositional\nreasoning capabilities necessary for large, complex urban settings. To overcome\nthese limitations, we propose GeoProg3D, a visual programming framework that\nenables natural language-driven interactions with city-scale high-fidelity 3D\nscenes. GeoProg3D consists of two key components: (i) a Geography-aware\nCity-scale 3D Language Field (GCLF) that leverages a memory-efficient\nhierarchical 3D model to handle large-scale data, integrated with geographic\ninformation for efficiently filtering vast urban spaces using directional cues,\ndistance measurements, elevation data, and landmark references; and (ii)\nGeographical Vision APIs (GV-APIs), specialized geographic vision tools such as\narea segmentation and object detection. Our framework employs large language\nmodels (LLMs) as reasoning engines to dynamically combine GV-APIs and operate\nGCLF, effectively supporting diverse geographic vision tasks. To assess\nperformance in city-scale reasoning, we introduce GeoEval3D, a comprehensive\nbenchmark dataset containing 952 query-answer pairs across five challenging\ntasks: grounding, spatial reasoning, comparison, counting, and measurement.\nExperiments demonstrate that GeoProg3D significantly outperforms existing 3D\nlanguage fields and vision-language models across multiple tasks. To our\nknowledge, GeoProg3D is the first framework enabling compositional geographic\nreasoning in high-fidelity city-scale 3D environments via natural language. The\ncode is available at https://snskysk.github.io/GeoProg3D/.", "AI": {"tldr": "GeoProg3D is a visual programming framework for natural language-driven interactions with city-scale 3D scenes, combining a geography-aware 3D language field and specialized vision APIs, outperforming existing methods.", "motivation": "Existing 3D language approaches lack scalability and compositional reasoning for large urban settings.", "method": "GeoProg3D uses a hierarchical 3D model (GCLF) and geographic vision APIs (GV-APIs) with LLMs for dynamic reasoning.", "result": "Outperforms existing 3D language fields and vision-language models on the GeoEval3D benchmark.", "conclusion": "GeoProg3D enables scalable, compositional geographic reasoning in city-scale 3D environments via natural language."}}
{"id": "2411.06660", "pdf": "https://arxiv.org/pdf/2411.06660", "abs": "https://arxiv.org/abs/2411.06660", "authors": ["Qiao Qiao", "Yuepei Li", "Qing Wang", "Kang Zhou", "Qi Li"], "title": "Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Knowledge graph completion (KGC) is a task of inferring missing triples based\non existing Knowledge Graphs (KGs). Both structural and semantic information\nare vital for successful KGC. However, existing methods only use either the\nstructural knowledge from the KG embeddings or the semantic information from\npre-trained language models (PLMs), leading to suboptimal model performance.\nMoreover, since PLMs are not trained on KGs, directly using PLMs to encode\ntriples may be inappropriate. To overcome these limitations, we propose a novel\nframework called Bridge, which jointly encodes structural and semantic\ninformation of KGs. Specifically, we strategically encode entities and\nrelations separately by PLMs to better utilize the semantic knowledge of PLMs\nand enable structured representation learning via a structural learning\nprinciple. Furthermore, to bridge the gap between KGs and PLMs, we employ a\nself-supervised representation learning method called BYOL to fine-tune PLMs\nwith two different views of a triple. Unlike BYOL, which uses augmentation\nmethods to create two semantically similar views of the same image, potentially\naltering the semantic information. We strategically separate the triple into\ntwo parts to create different views, thus avoiding semantic alteration.\nExperiments demonstrate that Bridge outperforms the SOTA models on three\nbenchmark datasets.", "AI": {"tldr": "A novel framework called Bridge jointly encodes structural and semantic information for knowledge graph completion (KGC), outperforming SOTA models by fine-tuning PLMs with self-supervised learning.", "motivation": "Existing KGC methods use either structural KG embeddings or semantic PLMs, leading to suboptimal performance. PLMs are also not trained on KGs, making direct triple encoding inappropriate.", "method": "Bridge encodes entities and relations separately using PLMs, applies structured representation learning, and fine-tunes PLMs with self-supervised learning (BYOL) using two views of a triple without semantic alteration.", "result": "Bridge outperforms SOTA models on three benchmark datasets.", "conclusion": "Jointly leveraging structural and semantic information via Bridge improves KGC performance, addressing limitations of existing methods."}}
{"id": "2506.23628", "pdf": "https://arxiv.org/pdf/2506.23628", "abs": "https://arxiv.org/abs/2506.23628", "authors": ["Antonio Ojea"], "title": "The Kubernetes Network Driver Model: A Composable Architecture for High-Performance Networking", "categories": ["cs.NI", "cs.AI"], "comment": "6 pages, 9 figures, submitted to IEEE LCN Special Track on\n  Cloud-AI-Native Mobile Networks Powered by eBPF (CAMe 2025)", "summary": "Traditional Kubernetes networking struggles to meet the escalating demands of\nAI/ML and evolving Telco infrastructure. This paper introduces Kubernetes\nNetwork Drivers (KNDs), a transformative, modular, and declarative architecture\ndesigned to overcome current imperative provisioning and API limitations. KNDs\nintegrate network resource management into Kubernetes' core by utilizing\nDynamic Resource Allocation (DRA), Node Resource Interface (NRI) improvements,\nand upcoming OCI Runtime Specification changes. Our DraNet implementation\ndemonstrates declarative attachment of network interfaces, including Remote\nDirect Memory Access (RDMA) devices, significantly boosting high-performance\nAI/ML workloads. This capability enables sophisticated cloud-native\napplications and lays crucial groundwork for future Telco solutions, fostering\na \"galaxy\" of specialized KNDs for enhanced application delivery and reduced\noperational complexity.", "AI": {"tldr": "Kubernetes Network Drivers (KNDs) introduce a modular, declarative architecture to address networking challenges in AI/ML and Telco, leveraging DRA, NRI, and OCI Runtime Spec for improved performance and simplicity.", "motivation": "Traditional Kubernetes networking falls short for AI/ML and Telco needs, requiring a more flexible and scalable solution.", "method": "KNDs use Dynamic Resource Allocation, Node Resource Interface improvements, and OCI Runtime Spec changes to integrate network resource management into Kubernetes.", "result": "DraNet implementation shows declarative attachment of network interfaces (e.g., RDMA), enhancing AI/ML performance and enabling advanced cloud-native apps.", "conclusion": "KNDs provide a foundation for future Telco solutions and specialized drivers, improving application delivery and reducing complexity."}}
{"id": "2506.22454", "pdf": "https://arxiv.org/pdf/2506.22454", "abs": "https://arxiv.org/abs/2506.22454", "authors": ["Ana Luiza S. Tavares", "Artur Pedro M. Neto", "Francinaldo L. Gomes", "Paul Rodrigo dos Reis", "Arthur G. da Silva", "Antonio P. Junior", "Bruno D. Gomes"], "title": "Microelectrode Signal Dynamics as Biomarkers of Subthalamic Nucleus Entry on Deep Brain Stimulation: A Nonlinear Feature Approach", "categories": ["eess.SP", "cs.LG"], "comment": "8 pages, 5 figures", "summary": "Accurate intraoperative localization of the subthalamic nucleus (STN) is\nessential for the efficacy of Deep Brain Stimulation (DBS) in patients with\nParkinson's disease. While microelectrode recordings (MERs) provide rich\nelectrophysiological information during DBS electrode implantation, current\nlocalization practices often rely on subjective interpretation of signal\nfeatures. In this study, we propose a quantitative framework that leverages\nnonlinear dynamics and entropy-based metrics to classify neural activity\nrecorded inside versus outside the STN. MER data from three patients were\npreprocessed using a robust artifact correction pipeline, segmented, and\nlabelled based on surgical annotations. A comprehensive set of recurrence\nquantification analysis, nonlinear, and entropy features were extracted from\neach segment. Multiple supervised classifiers were trained on every combination\nof feature domains using stratified 10-fold cross-validation, followed by\nstatistical comparison using paired Wilcoxon signed-rank tests with\nHolm-Bonferroni correction. The combination of entropy and nonlinear features\nyielded the highest discriminative power, and the Extra Trees classifier\nemerged as the best model with a cross-validated F1-score of 0.902+/-0.027 and\nROC AUC of 0.887+/-0.055. Final evaluation on a 20% hold-out test set confirmed\nrobust generalization (F1= 0.922, ROC AUC = 0.941). These results highlight the\npotential of nonlinear and entropy signal descriptors in supporting real-time,\ndata-driven decision-making during DBS surgeries", "AI": {"tldr": "A quantitative framework using nonlinear dynamics and entropy metrics improves STN localization in DBS surgeries, achieving high accuracy with an Extra Trees classifier.", "motivation": "Current STN localization in DBS relies on subjective interpretation of MERs, necessitating a more objective, data-driven approach.", "method": "MER data were preprocessed, segmented, and labeled. Features from recurrence quantification, nonlinear dynamics, and entropy were extracted. Supervised classifiers were trained and evaluated.", "result": "The Extra Trees classifier with entropy and nonlinear features achieved high discriminative power (F1=0.902, ROC AUC=0.887) and robust generalization (F1=0.922, ROC AUC=0.941).", "conclusion": "Nonlinear and entropy features enhance real-time, objective decision-making in DBS surgeries."}}
{"id": "2506.23361", "pdf": "https://arxiv.org/pdf/2506.23361", "abs": "https://arxiv.org/abs/2506.23361", "authors": ["Yuanhao Cai", "He Zhang", "Xi Chen", "Jinbo Xing", "Yiwei Hu", "Yuqian Zhou", "Kai Zhang", "Zhifei Zhang", "Soo Ye Kim", "Tianyu Wang", "Yulun Zhang", "Xiaokang Yang", "Zhe Lin", "Alan Yuille"], "title": "OmniVCus: Feedforward Subject-driven Video Customization with Multimodal Control Conditions", "categories": ["cs.CV"], "comment": "A data construction pipeline and a diffusion Transformer framework\n  for controllable subject-driven video customization", "summary": "Existing feedforward subject-driven video customization methods mainly study\nsingle-subject scenarios due to the difficulty of constructing multi-subject\ntraining data pairs. Another challenging problem that how to use the signals\nsuch as depth, mask, camera, and text prompts to control and edit the subject\nin the customized video is still less explored. In this paper, we first propose\na data construction pipeline, VideoCus-Factory, to produce training data pairs\nfor multi-subject customization from raw videos without labels and control\nsignals such as depth-to-video and mask-to-video pairs. Based on our\nconstructed data, we develop an Image-Video Transfer Mixed (IVTM) training with\nimage editing data to enable instructive editing for the subject in the\ncustomized video. Then we propose a diffusion Transformer framework, OmniVCus,\nwith two embedding mechanisms, Lottery Embedding (LE) and Temporally Aligned\nEmbedding (TAE). LE enables inference with more subjects by using the training\nsubjects to activate more frame embeddings. TAE encourages the generation\nprocess to extract guidance from temporally aligned control signals by\nassigning the same frame embeddings to the control and noise tokens.\nExperiments demonstrate that our method significantly surpasses\nstate-of-the-art methods in both quantitative and qualitative evaluations.\nVideo demos are at our project page:\nhttps://caiyuanhao1998.github.io/project/OmniVCus/. Our code will be released\nat https://github.com/caiyuanhao1998/Open-OmniVCus", "AI": {"tldr": "The paper introduces a method for multi-subject video customization, addressing data construction and control signal challenges, and proposes a diffusion Transformer framework for improved performance.", "motivation": "Existing methods focus on single-subject scenarios and lack exploration of control signals for video editing. The paper aims to tackle these gaps.", "method": "Proposes VideoCus-Factory for multi-subject data construction and an Image-Video Transfer Mixed (IVTM) training approach. Introduces OmniVCus, a diffusion Transformer framework with Lottery Embedding (LE) and Temporally Aligned Embedding (TAE).", "result": "The method outperforms state-of-the-art in quantitative and qualitative evaluations.", "conclusion": "The proposed framework effectively addresses multi-subject customization and control signal utilization, demonstrating superior performance."}}
{"id": "2411.08870", "pdf": "https://arxiv.org/pdf/2411.08870", "abs": "https://arxiv.org/abs/2411.08870", "authors": ["Daniel P. Jeong", "Pranav Mani", "Saurabh Garg", "Zachary C. Lipton", "Michael Oberst"], "title": "The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Extended version of EMNLP 2024 paper arXiv:2411.04118. Includes\n  additional results on clinical note QA tasks and supervised fine-tuning\n  evaluations", "summary": "Several recent works seek to adapt general-purpose large language models\n(LLMs) and vision-language models (VLMs) for medical applications through\ncontinued pretraining on publicly available biomedical corpora. These works\ntypically claim that such domain-adaptive pretraining improves performance on\nvarious downstream medical tasks, such as answering medical exam questions. In\nthis paper, we compare ten \"medical\" LLMs and two VLMs against their\ncorresponding base models, arriving at a different conclusion: all medical VLMs\nand nearly all medical LLMs fail to consistently improve over their base models\nin the zero-/few-shot prompting and supervised fine-tuning regimes for medical\nquestion answering (QA). For instance, on clinical-note-based QA tasks in the\n3-shot setting, medical LLMs outperform their base models in only 26.7% of\ncases, reach a (statistical) tie in 16.7% of cases, and perform significantly\nworse in the remaining 56.7% of cases. Our conclusions are based on (i)\ncomparing each medical model directly against its base model; (ii) optimizing\nthe prompts for each model separately in zero-/few-shot prompting; and (iii)\naccounting for statistical uncertainty in comparisons. Our findings suggest\nthat state-of-the-art general-domain models may already exhibit strong medical\nknowledge and reasoning capabilities, and offer recommendations to strengthen\nthe conclusions of future studies.", "AI": {"tldr": "Medical LLMs and VLMs often fail to outperform their base models in medical QA tasks, with most cases showing worse performance.", "motivation": "To evaluate whether domain-adaptive pretraining on biomedical corpora actually improves performance of LLMs and VLMs in medical tasks.", "method": "Comparison of ten medical LLMs and two VLMs against their base models in zero-/few-shot prompting and supervised fine-tuning for medical QA, with optimized prompts and statistical analysis.", "result": "Medical models outperformed base models in only 26.7% of cases, tied in 16.7%, and performed worse in 56.7%.", "conclusion": "General-domain models may already possess strong medical knowledge, and future studies should strengthen evaluation methods."}}
{"id": "2506.23634", "pdf": "https://arxiv.org/pdf/2506.23634", "abs": "https://arxiv.org/abs/2506.23634", "authors": ["Youjeong Noh", "Joon-Young Paik", "Jingun Kwon", "Eun-Sun Cho"], "title": "gMBA: Expression Semantic Guided Mixed Boolean-Arithmetic Deobfuscation Using Transformer Architectures", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Mixed Boolean-Arithmetic (MBA) obfuscation protects intellectual property by\nconverting programs into forms that are more complex to analyze. However, MBA\nhas been increasingly exploited by malware developers to evade detection and\ncause significant real-world problems. Traditional MBA deobfuscation methods\noften consider these expressions as part of a black box and overlook their\ninternal semantic information. To bridge this gap, we propose a truth table,\nwhich is an automatically constructed semantic representation of an\nexpression's behavior that does not rely on external resources. The truth table\nis a mathematical form that represents the output of expression for all\npossible combinations of input. We also propose a general and extensible guided\nMBA deobfuscation framework (gMBA) that modifies a Transformer-based neural\nencoder-decoder Seq2Seq architecture to incorporate this semantic guidance.\nExperimental results and in-depth analysis show that integrating expression\nsemantics significantly improves performance and highlights the importance of\ninternal semantic expressions in recovering obfuscated code to its original\nform.", "AI": {"tldr": "The paper proposes a truth table-based semantic representation and a guided MBA deobfuscation framework (gMBA) to improve the recovery of obfuscated code by leveraging internal semantic information.", "motivation": "MBA obfuscation is exploited by malware, and traditional deobfuscation methods overlook internal semantics, creating a need for better solutions.", "method": "A truth table is used to represent expression behavior, and a Transformer-based Seq2Seq model (gMBA) is modified to incorporate semantic guidance.", "result": "Integrating semantic information significantly improves deobfuscation performance.", "conclusion": "The approach highlights the importance of internal semantics for effective MBA deobfuscation."}}
{"id": "2506.22455", "pdf": "https://arxiv.org/pdf/2506.22455", "abs": "https://arxiv.org/abs/2506.22455", "authors": ["Dung Truong", "Arnaud Delorme"], "title": "Data Normalization Strategies for EEG Deep Learning", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Normalization is a critical yet often overlooked component in the\npreprocessing pipeline for EEG deep learning applications. The rise of\nlarge-scale pretraining paradigms such as self-supervised learning (SSL)\nintroduces a new set of tasks whose nature is substantially different from\nsupervised training common in EEG deep learning applications. This raises new\nquestions about optimal normalization strategies for the applicable task. In\nthis study, we systematically evaluate the impact of normalization granularity\n(recording vs. window level) and scope (cross-channel vs. within-channel) on\nboth supervised (age and gender prediction) and self-supervised (Contrastive\nPredictive Coding) tasks. Using high-density resting-state EEG from 2,836\nsubjects in the Healthy Brain Network dataset, we show that optimal\nnormalization strategies differ significantly between training paradigms.\nWindow-level within-channel normalization yields the best performance in\nsupervised tasks, while minimal or cross-channel normalization at the window\nlevel is more effective for SSL. These results underscore the necessity of\ntask-specific normalization choices and challenge the assumption that a\nuniversal normalization strategy can generalize across learning settings. Our\nfindings provide practical insights for developing robust EEG deep learning\npipelines as the field shifts toward large-scale, foundation model training.", "AI": {"tldr": "The study evaluates normalization strategies in EEG deep learning, finding optimal methods differ between supervised and self-supervised tasks.", "motivation": "Normalization is often overlooked in EEG preprocessing, and the rise of self-supervised learning introduces new challenges for optimal strategies.", "method": "Systematic evaluation of normalization granularity (recording vs. window level) and scope (cross-channel vs. within-channel) on supervised and self-supervised tasks using EEG data from 2,836 subjects.", "result": "Window-level within-channel normalization works best for supervised tasks, while minimal or cross-channel normalization at the window level is better for self-supervised learning.", "conclusion": "Task-specific normalization is essential, and a universal strategy does not generalize across learning settings, providing insights for EEG deep learning pipelines."}}
{"id": "2506.23414", "pdf": "https://arxiv.org/pdf/2506.23414", "abs": "https://arxiv.org/abs/2506.23414", "authors": ["Ming-Zher Poh", "Jonathan Wang", "Jonathan Hsu", "Lawrence Cai", "Eric Teasley", "James A. Taylor", "Jameson K. Rogers", "Anupam Pathak", "Shwetak Patel"], "title": "A High-Throughput Platform to Bench Test Smartphone-Based Heart Rate Measurements Derived From Video", "categories": ["cs.CV"], "comment": null, "summary": "Smartphone-based heart rate (HR) monitoring apps using finger-over-camera\nphotoplethysmography (PPG) face significant challenges in performance\nevaluation and device compatibility due to device variability and\nfragmentation. Manual testing is impractical, and standardized methods are\nlacking. This paper presents a novel, high-throughput bench-testing platform to\naddress this critical need. We designed a system comprising a test rig capable\nof holding 12 smartphones for parallel testing, a method for generating\nsynthetic PPG test videos with controllable HR and signal quality, and a host\nmachine for coordinating video playback and data logging. The system achieved a\nmean absolute percentage error (MAPE) of 0.11% +/- 0.001% between input and\nmeasured HR, and a correlation coefficient of 0.92 +/- 0.008 between input and\nmeasured PPG signals using a clinically-validated smartphone-based HR app.\nBench-testing results of 20 different smartphone models correctly classified\nall the devices as meeting the ANSI/CTA accuracy standards for HR monitors\n(MAPE <10%) when compared to a prospective clinical study with 80 participants,\ndemonstrating high positive predictive value. This platform offers a scalable\nsolution for pre-deployment testing of smartphone HR apps to improve app\nperformance, ensure device compatibility, and advance the field of mobile\nhealth.", "AI": {"tldr": "A high-throughput bench-testing platform for evaluating smartphone-based heart rate monitoring apps, addressing device variability and fragmentation with synthetic PPG test videos and parallel testing.", "motivation": "Challenges in performance evaluation and device compatibility for smartphone-based HR monitoring apps due to device variability and lack of standardized testing methods.", "method": "Designed a system with a test rig for 12 smartphones, synthetic PPG test videos with controllable HR and signal quality, and a host machine for coordination.", "result": "Achieved 0.11% MAPE for HR accuracy and 0.92 correlation for PPG signals, with all 20 tested smartphones meeting ANSI/CTA standards.", "conclusion": "The platform provides a scalable solution for pre-deployment testing, improving app performance and device compatibility in mobile health."}}
{"id": "2411.10557", "pdf": "https://arxiv.org/pdf/2411.10557", "abs": "https://arxiv.org/abs/2411.10557", "authors": ["Jianhong Tu", "Zhuohao Ni", "Nicholas Crispino", "Zihao Yu", "Michael Bendersky", "Beliz Gunel", "Ruoxi Jia", "Xin Liu", "Lingjuan Lyu", "Dawn Song", "Chenguang Wang"], "title": "MLAN: Language-Based Instruction Tuning Preserves and Transfers Knowledge in Multimodal Language Models", "categories": ["cs.CL"], "comment": null, "summary": "We present a novel visual instruction tuning strategy to improve the\nzero-shot task generalization of multimodal large language models by building a\nfirm text-only knowledge base. Existing work lacks sufficient experimentation\non the importance of each modality in the instruction tuning stage, often using\na majority of vision-language data while keeping text-only data limited and\nfixing mixtures of modalities. By incorporating diverse text-only data in the\nvisual instruction tuning stage, we vary vision-language data in various\ncontrolled experiments to investigate the importance of modality in visual\ninstruction tuning. Our comprehensive evaluation shows that the text-heavy\ninstruction tuning approach is able to perform on-par with traditional\nvision-heavy mixtures on both modalities across 12 general datasets while using\nas low as half the total training tokens. We find that simply increasing\nsufficiently diverse text-only data enables transfer of instruction following\nability and domain knowledge across modalities while being more efficient than\nthe vision-language approach.", "AI": {"tldr": "A novel visual instruction tuning strategy improves zero-shot task generalization in multimodal models by emphasizing text-only data, achieving comparable performance with fewer training tokens.", "motivation": "Existing methods inadequately explore modality importance in instruction tuning, often over-relying on vision-language data while neglecting text-only data.", "method": "Incorporates diverse text-only data during visual instruction tuning and varies vision-language data in controlled experiments to study modality importance.", "result": "Text-heavy instruction tuning matches vision-heavy methods across 12 datasets using half the training tokens, showing efficient knowledge transfer.", "conclusion": "Increasing diverse text-only data enables effective cross-modality instruction following and domain knowledge transfer, outperforming vision-language approaches in efficiency."}}
{"id": "2506.23635", "pdf": "https://arxiv.org/pdf/2506.23635", "abs": "https://arxiv.org/abs/2506.23635", "authors": ["Mu-Chi Chen", "Po-Hsuan Huang", "Xiangrui Ke", "Chia-Heng Tu", "Chun Jason Xue", "Shih-Hao Hung"], "title": "Towards Building Private LLMs: Exploring Multi-Node Expert Parallelism on Apple Silicon for Mixture-of-Experts Large Language Model", "categories": ["cs.DC", "cs.AI", "cs.PF", "I.6.4; I.2.7; I.2.11"], "comment": "International Conference on Research in Adaptive and Convergent\n  Systems (RACS '24), November 5--8, 2024, Pompei, Italy", "summary": "Large Language Models (LLMs) have revolutionized Artificial Intelligence (AI)\nwith significant advancements such as OpenAI's ChatGPT, Meta's Llama, and\nDatabricks' DBRX. This paper addresses the cost and scalability challenges\nencountered when constructing private LLM systems for personal or small group\nservices, as aimed by Apple Intelligence. A Mac Studio cluster with Apple's M2\nUltra chips is established as a cost-efficient solution to host and accelerate\nthe pretrained DBRX model with the Mixture-of-Experts (MoE) architecture. Our\nperformance analysis reveal that parallel execution of the model's experts\nacross two to four machine nodes significantly reduces inference time. We find\nthat computation time for the experts is comparable to the communication time\nfor exchanging their outputs, emphasizing the importance of network latency\nover bandwidth. We also observe significant management overhead due to Apple\nsoftware stack's memory management logic. Based on these findings, we develop\noptimization schemes to eliminate the memory management overhead. As a result,\nthe Mac Studio cluster is 1.15 times more cost-efficient than the\nstate-of-the-art AI supercomputer with NVIDIA H100 GPUs. In addition, we\nconstruct a performance model to estimate system performance under varying\nconfigurations, and the model provides valuable insights for designing private\nLLM systems.", "AI": {"tldr": "The paper proposes a cost-efficient Mac Studio cluster with M2 Ultra chips to host and accelerate the DBRX LLM, addressing scalability and cost challenges for private LLM systems.", "motivation": "To tackle the cost and scalability issues in building private LLM systems for personal or small group services, exemplified by Apple Intelligence.", "method": "Uses a Mac Studio cluster with M2 Ultra chips to host the DBRX model with MoE architecture, analyzing performance and optimizing for memory management overhead.", "result": "The cluster is 1.15x more cost-efficient than NVIDIA H100 GPUs, with insights on network latency and performance modeling.", "conclusion": "The Mac Studio cluster is a viable, cost-effective solution for private LLM systems, with optimization schemes and performance models aiding future designs."}}
{"id": "2506.22459", "pdf": "https://arxiv.org/pdf/2506.22459", "abs": "https://arxiv.org/abs/2506.22459", "authors": ["Wending Heng", "Chaoyuan Liang", "Yihui Zhao", "Zhiqiang Zhang", "Glen Cooper", "Zhenhong Li"], "title": "Physics-Embedded Neural Networks for sEMG-based Continuous Motion Estimation", "categories": ["eess.SP", "cs.LG"], "comment": "Accepted by 2025 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS)", "summary": "Accurately decoding human motion intentions from surface electromyography\n(sEMG) is essential for myoelectric control and has wide applications in\nrehabilitation robotics and assistive technologies. However, existing\nsEMG-based motion estimation methods often rely on subject-specific\nmusculoskeletal (MSK) models that are difficult to calibrate, or purely\ndata-driven models that lack physiological consistency. This paper introduces a\nnovel Physics-Embedded Neural Network (PENN) that combines interpretable MSK\nforward-dynamics with data-driven residual learning, thereby preserving\nphysiological consistency while achieving accurate motion estimation. The PENN\nemploys a recursive temporal structure to propagate historical estimates and a\nlightweight convolutional neural network for residual correction, leading to\nrobust and temporally coherent estimations. A two-phase training strategy is\ndesigned for PENN. Experimental evaluations on six healthy subjects show that\nPENN outperforms state-of-the-art baseline methods in both root mean square\nerror (RMSE) and $R^2$ metrics.", "AI": {"tldr": "A novel Physics-Embedded Neural Network (PENN) combines musculoskeletal dynamics with data-driven learning for accurate and physiologically consistent motion estimation from sEMG.", "motivation": "Existing sEMG-based motion estimation methods either rely on hard-to-calibrate subject-specific models or lack physiological consistency, limiting their effectiveness.", "method": "PENN integrates interpretable musculoskeletal forward-dynamics with residual learning, using a recursive temporal structure and lightweight CNN for robust, coherent estimations. A two-phase training strategy is employed.", "result": "PENN outperforms state-of-the-art methods in RMSE and R\u00b2 metrics on six healthy subjects.", "conclusion": "PENN offers a promising solution for accurate and physiologically consistent motion estimation in myoelectric control applications."}}
{"id": "2506.23418", "pdf": "https://arxiv.org/pdf/2506.23418", "abs": "https://arxiv.org/abs/2506.23418", "authors": ["Parham Rezaei", "Arash Marioriyad", "Mahdieh Soleymani Baghshah", "Mohammad Hossein Rohban"], "title": "Why Settle for Mid: A Probabilistic Viewpoint to Spatial Relationship Alignment in Text-to-image Models", "categories": ["cs.CV"], "comment": "12 main pages, 18 figures, and 16 tables", "summary": "Despite the ability of text-to-image models to generate high-quality,\nrealistic, and diverse images, they face challenges in compositional\ngeneration, often struggling to accurately represent details specified in the\ninput prompt. A prevalent issue in compositional generation is the misalignment\nof spatial relationships, as models often fail to faithfully generate images\nthat reflect the spatial configurations specified between objects in the input\nprompts. To address this challenge, we propose a novel probabilistic framework\nfor modeling the relative spatial positioning of objects in a scene, leveraging\nthe concept of Probability of Superiority (PoS). Building on this insight, we\nmake two key contributions. First, we introduce a novel evaluation metric,\nPoS-based Evaluation (PSE), designed to assess the alignment of 2D and 3D\nspatial relationships between text and image, with improved adherence to human\njudgment. Second, we propose PoS-based Generation (PSG), an inference-time\nmethod that improves the alignment of 2D and 3D spatial relationships in T2I\nmodels without requiring fine-tuning. PSG employs a Part-of-Speech PoS-based\nreward function that can be utilized in two distinct ways: (1) as a\ngradient-based guidance mechanism applied to the cross-attention maps during\nthe denoising steps, or (2) as a search-based strategy that evaluates a set of\ninitial noise vectors to select the best one. Extensive experiments demonstrate\nthat the PSE metric exhibits stronger alignment with human judgment compared to\ntraditional center-based metrics, providing a more nuanced and reliable measure\nof complex spatial relationship accuracy in text-image alignment. Furthermore,\nPSG significantly enhances the ability of text-to-image models to generate\nimages with specified spatial configurations, outperforming state-of-the-art\nmethods across multiple evaluation metrics and benchmarks.", "AI": {"tldr": "The paper addresses text-to-image models' challenges in compositional generation, proposing a probabilistic framework (PoS) for spatial alignment and introducing PSE (evaluation metric) and PSG (generation method) to improve accuracy.", "motivation": "Text-to-image models often fail to accurately represent spatial relationships in prompts, leading to misaligned compositions.", "method": "Proposes PoS-based Evaluation (PSE) for assessing spatial alignment and PoS-based Generation (PSG) for improving generation without fine-tuning, using gradient-based or search-based strategies.", "result": "PSE aligns better with human judgment than traditional metrics, and PSG outperforms state-of-the-art methods in generating spatially accurate images.", "conclusion": "The proposed PSE and PSG significantly enhance text-to-image models' ability to generate images with precise spatial configurations."}}
{"id": "2412.01131", "pdf": "https://arxiv.org/pdf/2412.01131", "abs": "https://arxiv.org/abs/2412.01131", "authors": ["Zhihan Cao", "Hiroaki Yamada", "Simone Teufel", "Takenobu Tokunaga"], "title": "A Comprehensive Evaluation of Semantic Relation Knowledge of Pretrained Language Models and Humans", "categories": ["cs.CL"], "comment": "This manuscript is currently under review at Language Resources and\n  Evaluation", "summary": "Recently, much work has concerned itself with the enigma of what exactly PLMs\n(pretrained language models) learn about different aspects of language, and how\nthey learn it. One stream of this type of research investigates the knowledge\nthat PLMs have about semantic relations. However, many aspects of semantic\nrelations were left unexplored. Only one relation was considered, namely\nhypernymy. Furthermore, previous work did not measure humans' performance on\nthe same task as that solved by the PLMs. This means that at this point in\ntime, there is only an incomplete view of models' semantic relation knowledge.\nTo address this gap, we introduce a comprehensive evaluation framework covering\nfive relations beyond hypernymy, namely hyponymy, holonymy, meronymy, antonymy,\nand synonymy. We use six metrics (two newly introduced here) for recently\nuntreated aspects of semantic relation knowledge, namely soundness,\ncompleteness, symmetry, asymmetry, prototypicality, and distinguishability and\nfairly compare humans and models on the same task. Our extensive experiments\ninvolve 16 PLMs, eight masked and eight causal language models. Up to now only\nmasked language models had been tested although causal and masked language\nmodels treat context differently. Our results reveal a significant knowledge\ngap between humans and models for almost all semantic relations. Antonymy is\nthe outlier relation where all models perform reasonably well. In general,\nmasked language models perform significantly better than causal language\nmodels. Nonetheless, both masked and causal language models are likely to\nconfuse non-antonymy relations with antonymy.", "AI": {"tldr": "The paper introduces a framework to evaluate PLMs' knowledge of five semantic relations beyond hypernymy, comparing humans and models using six metrics. Results show a knowledge gap, with antonymy as the exception, and masked models outperforming causal ones.", "motivation": "To address the incomplete understanding of PLMs' semantic relation knowledge, particularly beyond hypernymy, and to compare human and model performance on the same task.", "method": "A comprehensive evaluation framework covering five semantic relations (hyponymy, holonymy, meronymy, antonymy, synonymy) using six metrics. Experiments involve 16 PLMs (8 masked, 8 causal).", "result": "Significant knowledge gap between humans and models for most relations, except antonymy. Masked models outperform causal ones, but both confuse non-antonymy relations with antonymy.", "conclusion": "The study highlights limitations in PLMs' semantic relation knowledge and suggests masked models are superior, though challenges remain in distinguishing non-antonymy relations."}}
{"id": "2506.23639", "pdf": "https://arxiv.org/pdf/2506.23639", "abs": "https://arxiv.org/abs/2506.23639", "authors": ["Wanpeng Zhang", "Yicheng Feng", "Hao Luo", "Yijiang Li", "Zihao Yue", "Sipeng Zheng", "Zongqing Lu"], "title": "Unified Multimodal Understanding via Byte-Pair Visual Encoding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multimodal large language models (MLLMs) have made significant progress in\nvision-language understanding, yet effectively aligning different modalities\nremains a fundamental challenge. We present a framework that unifies multimodal\nunderstanding by applying byte-pair encoding to visual tokens. Unlike\nconventional approaches that rely on modality-specific encoders, our method\ndirectly incorporates structural information into visual tokens, mirroring\nsuccessful tokenization strategies in text-only language models. We introduce a\npriority-guided encoding scheme that considers both frequency and spatial\nconsistency, coupled with a multi-stage training procedure based on\ncurriculum-driven data composition. These enhancements enable the transformer\nmodel to better capture cross-modal relationships and reason with visual\ninformation. Comprehensive experiments demonstrate improved performance across\ndiverse vision-language tasks. By bridging the gap between visual and textual\nrepresentations, our approach contributes to the advancement of more capable\nand efficient multimodal foundation models.", "AI": {"tldr": "A framework for multimodal understanding using byte-pair encoding on visual tokens, improving cross-modal alignment and performance in vision-language tasks.", "motivation": "Aligning different modalities in MLLMs is challenging; the paper aims to unify multimodal understanding by adapting text-like tokenization for visual data.", "method": "Uses byte-pair encoding for visual tokens, priority-guided encoding (frequency and spatial consistency), and multi-stage curriculum-driven training.", "result": "Improved performance in diverse vision-language tasks by better capturing cross-modal relationships.", "conclusion": "The approach bridges visual and textual representations, advancing efficient multimodal foundation models."}}
{"id": "2506.22476", "pdf": "https://arxiv.org/pdf/2506.22476", "abs": "https://arxiv.org/abs/2506.22476", "authors": ["A. Subedi", "S. De", "L. Cavuoto", "S. Schwaitzberg", "M. Hackett", "J. Norfleet"], "title": "An Interpretable Transformer-Based Foundation Model for Cross-Procedural Skill Assessment Using Raw fNIRS Signals", "categories": ["eess.SP", "cs.ET", "cs.HC", "cs.LG", "q-bio.NC", "I.2.6; J.3; H.1.2"], "comment": null, "summary": "Objective skill assessment in high-stakes procedural environments requires\nmodels that not only decode underlying cognitive and motor processes but also\ngeneralize across tasks, individuals, and experimental contexts. While prior\nwork has demonstrated the potential of functional near-infrared spectroscopy\n(fNIRS) for evaluating cognitive-motor performance, existing approaches are\noften task-specific, rely on extensive preprocessing, and lack robustness to\nnew procedures or conditions. Here, we introduce an interpretable\ntransformer-based foundation model trained on minimally processed fNIRS signals\nfor cross-procedural skill assessment. Pretrained using self-supervised\nlearning on data from laparoscopic surgical tasks and endotracheal intubation\n(ETI), the model achieves greater than 88% classification accuracy on all\ntasks, with Matthews Correlation Coefficient exceeding 0.91 on ETI. It\ngeneralizes to a novel emergency airway procedure--cricothyrotomy--using fewer\nthan 30 labeled samples and a lightweight (less than 2k parameter) adapter\nmodule, attaining an AUC greater than 87%. Interpretability is achieved via a\nnovel channel attention mechanism--developed specifically for fNIRS--that\nidentifies functionally coherent prefrontal sub-networks validated through\nablation studies. Temporal attention patterns align with task-critical phases\nand capture stress-induced changes in neural variability, offering insight into\ndynamic cognitive states.", "AI": {"tldr": "A transformer-based model using minimally processed fNIRS signals achieves high accuracy and generalizability for cross-procedural skill assessment, validated on surgical and emergency tasks.", "motivation": "Existing fNIRS-based skill assessment models are task-specific, require heavy preprocessing, and lack robustness to new conditions. This work aims to address these limitations.", "method": "An interpretable transformer-based foundation model is pretrained with self-supervised learning on laparoscopic and ETI tasks, using a lightweight adapter for generalization to new procedures.", "result": "The model achieves >88% accuracy on all tasks, >0.91 MCC on ETI, and >87% AUC on cricothyrotomy with minimal labeled data.", "conclusion": "The model offers robust, interpretable skill assessment, generalizing to novel tasks and capturing dynamic cognitive states via attention mechanisms."}}
{"id": "2506.23426", "pdf": "https://arxiv.org/pdf/2506.23426", "abs": "https://arxiv.org/abs/2506.23426", "authors": ["Menna Taha", "Aya Ahmed", "Mohammed Karmoose", "Yasser Gadallah"], "title": "Detecting What Matters: A Novel Approach for Out-of-Distribution 3D Object Detection in Autonomous Vehicles", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Autonomous vehicles (AVs) use object detection models to recognize their\nsurroundings and make driving decisions accordingly. Conventional object\ndetection approaches classify objects into known classes, which limits the AV's\nability to detect and appropriately respond to Out-of-Distribution (OOD)\nobjects. This problem is a significant safety concern since the AV may fail to\ndetect objects or misclassify them, which can potentially lead to hazardous\nsituations such as accidents. Consequently, we propose a novel object detection\napproach that shifts the emphasis from conventional class-based classification\nto object harmfulness determination. Instead of object detection by their\nspecific class, our method identifies them as either 'harmful' or 'harmless'\nbased on whether they pose a danger to the AV. This is done based on the object\nposition relative to the AV and its trajectory. With this metric, our model can\neffectively detect previously unseen objects to enable the AV to make safer\nreal-time decisions. Our results demonstrate that the proposed model\neffectively detects OOD objects, evaluates their harmfulness, and classifies\nthem accordingly, thus enhancing the AV decision-making effectiveness in\ndynamic environments.", "AI": {"tldr": "The paper proposes a novel object detection method for AVs that focuses on determining object harmfulness rather than traditional class-based classification, improving safety by detecting OOD objects.", "motivation": "Current AV object detection models struggle with OOD objects, posing safety risks. The paper aims to address this by shifting focus to harmfulness assessment.", "method": "The method classifies objects as 'harmful' or 'harmless' based on their position and trajectory relative to the AV, enabling detection of unseen objects.", "result": "The model effectively detects OOD objects, assesses their harmfulness, and enhances AV decision-making in dynamic environments.", "conclusion": "The proposed approach improves AV safety by focusing on harmfulness, enabling better real-time responses to previously unseen objects."}}
{"id": "2412.04205", "pdf": "https://arxiv.org/pdf/2412.04205", "abs": "https://arxiv.org/abs/2412.04205", "authors": ["Jos\u00e9 Pombal", "Sweta Agrawal", "Patrick Fernandes", "Emmanouil Zaranis", "Andr\u00e9 F. T. Martins"], "title": "A Context-aware Framework for Translation-mediated Conversations", "categories": ["cs.CL"], "comment": null, "summary": "Automatic translation systems offer a powerful solution to bridge language\nbarriers in scenarios where participants do not share a common language.\nHowever, these systems can introduce errors leading to misunderstandings and\nconversation breakdown. A key issue is that current systems fail to incorporate\nthe rich contextual information necessary to resolve ambiguities and omitted\ndetails, resulting in literal, inappropriate, or misaligned translations. In\nthis work, we present a framework to improve large language model-based\ntranslation systems by incorporating contextual information in bilingual\nconversational settings during training and inference. We validate our proposed\nframework on two task-oriented domains: customer chat and user-assistant\ninteraction. Across both settings, the system produced by our\nframework-TowerChat-consistently results in better translations than\nstate-of-the-art systems like GPT-4o and TowerInstruct, as measured by multiple\nautomatic translation quality metrics on several language pairs. We also show\nthat the resulting model leverages context in an intended and interpretable\nway, improving consistency between the conveyed message and the generated\ntranslations.", "AI": {"tldr": "The paper introduces TowerChat, a framework to enhance translation systems by integrating contextual information, outperforming GPT-4o and TowerInstruct in bilingual conversational tasks.", "motivation": "Current translation systems lack contextual understanding, leading to errors and miscommunication. The goal is to improve accuracy by incorporating context.", "method": "The framework integrates contextual information during training and inference for large language model-based translation systems, tested in customer chat and user-assistant interactions.", "result": "TowerChat outperforms state-of-the-art systems (GPT-4o, TowerInstruct) in translation quality metrics and leverages context effectively.", "conclusion": "Incorporating context improves translation accuracy and consistency, making TowerChat a superior solution for bilingual conversations."}}
{"id": "2506.23641", "pdf": "https://arxiv.org/pdf/2506.23641", "abs": "https://arxiv.org/abs/2506.23641", "authors": ["Peng Huang", "Junhu Fu", "Bowen Guo", "Zeju Li", "Yuanyuan Wang", "Yi Guo"], "title": "VAP-Diffusion: Enriching Descriptions with MLLMs for Enhanced Medical Image Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "As the appearance of medical images is influenced by multiple underlying\nfactors, generative models require rich attribute information beyond labels to\nproduce realistic and diverse images. For instance, generating an image of skin\nlesion with specific patterns demands descriptions that go beyond diagnosis,\nsuch as shape, size, texture, and color. However, such detailed descriptions\nare not always accessible. To address this, we explore a framework, termed\nVisual Attribute Prompts (VAP)-Diffusion, to leverage external knowledge from\npre-trained Multi-modal Large Language Models (MLLMs) to improve the quality\nand diversity of medical image generation. First, to derive descriptions from\nMLLMs without hallucination, we design a series of prompts following\nChain-of-Thoughts for common medical imaging tasks, including dermatologic,\ncolorectal, and chest X-ray images. Generated descriptions are utilized during\ntraining and stored across different categories. During testing, descriptions\nare randomly retrieved from the corresponding category for inference. Moreover,\nto make the generator robust to unseen combination of descriptions at the test\ntime, we propose a Prototype Condition Mechanism that restricts test embeddings\nto be similar to those from training. Experiments on three common types of\nmedical imaging across four datasets verify the effectiveness of VAP-Diffusion.", "AI": {"tldr": "VAP-Diffusion leverages MLLMs for detailed medical image generation by using structured prompts and a prototype condition mechanism to ensure quality and diversity.", "motivation": "Detailed descriptions for medical image generation are often unavailable, limiting realism and diversity.", "method": "Uses MLLMs with Chain-of-Thought prompts to generate descriptions, stores them by category, and employs a Prototype Condition Mechanism for robustness.", "result": "Effective across three medical imaging types in four datasets.", "conclusion": "VAP-Diffusion improves medical image generation by integrating external knowledge and ensuring robustness."}}
{"id": "2506.22480", "pdf": "https://arxiv.org/pdf/2506.22480", "abs": "https://arxiv.org/abs/2506.22480", "authors": ["Mariam Yahya", "Aydin Sezgin", "Setareh Maghsudi"], "title": "Service Placement in Small Cell Networks Using Distributed Best Arm Identification in Linear Bandits", "categories": ["cs.NI", "cs.DC", "cs.LG"], "comment": null, "summary": "As users in small cell networks increasingly rely on computation-intensive\nservices, cloud-based access often results in high latency. Multi-access edge\ncomputing (MEC) mitigates this by bringing computational resources closer to\nend users, with small base stations (SBSs) serving as edge servers to enable\nlow-latency service delivery. However, limited edge capacity makes it\nchallenging to decide which services to deploy locally versus in the cloud,\nespecially under unknown service demand and dynamic network conditions. To\ntackle this problem, we model service demand as a linear function of service\nattributes and formulate the service placement task as a linear bandit problem,\nwhere SBSs act as agents and services as arms. The goal is to identify the\nservice that, when placed at the edge, offers the greatest reduction in total\nuser delay compared to cloud deployment. We propose a distributed and adaptive\nmulti-agent best-arm identification (BAI) algorithm under a fixed-confidence\nsetting, where SBSs collaborate to accelerate learning. Simulations show that\nour algorithm identifies the optimal service with the desired confidence and\nachieves near-optimal speedup, as the number of learning rounds decreases\nproportionally with the number of SBSs. We also provide theoretical analysis of\nthe algorithm's sample complexity and communication overhead.", "AI": {"tldr": "The paper addresses latency issues in small cell networks by proposing a distributed algorithm for optimal service placement in multi-access edge computing (MEC).", "motivation": "High latency in cloud-based access for computation-intensive services in small cell networks necessitates efficient edge computing solutions.", "method": "The service placement problem is modeled as a linear bandit problem, with a distributed multi-agent best-arm identification (BAI) algorithm proposed for adaptive learning.", "result": "Simulations confirm the algorithm identifies the optimal service with desired confidence and achieves near-optimal speedup, reducing learning rounds proportionally with the number of small base stations (SBSs).", "conclusion": "The proposed algorithm effectively balances edge and cloud deployment, minimizing user delay while providing theoretical guarantees on sample complexity and communication overhead."}}
{"id": "2506.23434", "pdf": "https://arxiv.org/pdf/2506.23434", "abs": "https://arxiv.org/abs/2506.23434", "authors": ["Tianran Liu", "Shengwen Zhao", "Nicholas Rhinehart"], "title": "Towards foundational LiDAR world models with efficient latent flow matching", "categories": ["cs.CV", "cs.RO"], "comment": "25 pages, 13 figures", "summary": "LiDAR-based world models offer more structured and geometry-aware\nrepresentations than their image-based counterparts. However, existing LiDAR\nworld models are narrowly trained; each model excels only in the domain for\nwhich it was built. Can we develop LiDAR world models that exhibit strong\ntransferability across multiple domains? We conduct the first systematic domain\ntransfer study across three demanding scenarios: (i) outdoor to indoor\ngeneralization, (ii) sparse-beam \\& dense-beam adaptation, and (iii)\nnon-semantic to semantic transfer. Given different amounts of fine-tuning data,\nour experiments show that a single pre-trained model can achieve up to 11%\nabsolute improvement (83\\% relative) over training from scratch and outperforms\ntraining from scratch in 30/36 of our comparisons. This transferability of\ndynamic learning significantly reduces the reliance on manually annotated data\nfor semantic occupancy forecasting: our method exceed the previous semantic\noccupancy forecasting models with only 5% of the labeled training data required\nby prior models. We also observed inefficiencies of current LiDAR world models,\nmainly through their under-compression of LiDAR data and inefficient training\nobjectives. To address this, we propose a latent conditional flow matching\n(CFM)-based frameworks that achieves state-of-the-art reconstruction accuracy\nusing only half the training data and a compression ratio 6 times higher than\nthat of prior methods. Our model achieves SOTA performance on\nfuture-trajectory-conditioned semantic occupancy forecasting while being 23x\nmore computationally efficient (a 28x FPS speedup); and achieves SOTA\nperformance on semantic occupancy forecasting while being 2x more\ncomputationally efficient (a 1.1x FPS speedup).", "AI": {"tldr": "The paper explores transferability in LiDAR world models across domains, proposing a latent CFM-based framework for improved efficiency and performance.", "motivation": "Existing LiDAR world models lack transferability across domains, requiring domain-specific training. The study aims to develop models with strong cross-domain performance.", "method": "A latent conditional flow matching (CFM)-based framework is introduced to address inefficiencies in current models, focusing on data compression and training objectives.", "result": "The proposed model achieves up to 11% absolute improvement over training from scratch, outperforms in 30/36 comparisons, and reduces labeled data needs by 95%. It also shows 6x higher compression and 23x computational efficiency.", "conclusion": "The latent CFM framework enhances LiDAR world models' transferability and efficiency, achieving SOTA performance with significantly reduced data and computational costs."}}
{"id": "2412.10266", "pdf": "https://arxiv.org/pdf/2412.10266", "abs": "https://arxiv.org/abs/2412.10266", "authors": ["Jiaqing Yuan", "Ruijie Xi", "Munindar P. Singh"], "title": "Reasoner Outperforms: Generative Stance Detection with Rationalization for Social Media", "categories": ["cs.CL"], "comment": "Accepted by ACM Hypertext 2025", "summary": "Stance detection is crucial for fostering a human-centric Web by analyzing\nuser-generated content to identify biases and harmful narratives that undermine\ntrust. With the development of Large Language Models (LLMs), existing\napproaches treat stance detection as a classification problem, providing robust\nmethodologies for modeling complex group interactions and advancing\ncapabilities in natural language tasks. However, these methods often lack\ninterpretability, limiting their ability to offer transparent and\nunderstandable justifications for predictions. This study adopts a generative\napproach, where stance predictions include explicit, interpretable rationales,\nand integrates them into smaller language models through single-task and\nmultitask learning. We find that incorporating reasoning into stance detection\nenables the smaller model (FlanT5) to outperform GPT-3.5's zero-shot\nperformance, achieving an improvement of up to 9.57%. Moreover, our results\nshow that reasoning capabilities enhance multitask learning performance but may\nreduce effectiveness in single-task settings. Crucially, we demonstrate that\nfaithful rationales improve rationale distillation into SLMs, advancing efforts\nto build interpretable, trustworthy systems for addressing discrimination,\nfostering trust, and promoting equitable engagement on social media.", "AI": {"tldr": "The paper introduces a generative approach for stance detection, incorporating interpretable rationales into smaller models like FlanT5, outperforming GPT-3.5 by 9.57%. It shows reasoning enhances multitask learning but may hinder single-task performance.", "motivation": "To address the lack of interpretability in existing stance detection methods, aiming for transparent and trustworthy systems to combat biases and harmful narratives on social media.", "method": "Adopts a generative approach, integrating explicit rationales into smaller models (FlanT5) via single-task and multitask learning.", "result": "FlanT5 with reasoning outperforms GPT-3.5 by 9.57%. Reasoning boosts multitask learning but may reduce single-task effectiveness.", "conclusion": "Faithful rationales improve interpretability and trustworthiness, advancing equitable engagement on social media."}}
{"id": "2506.23644", "pdf": "https://arxiv.org/pdf/2506.23644", "abs": "https://arxiv.org/abs/2506.23644", "authors": ["Junze Hu", "Xiangyu Jin", "Yizhe Zeng", "Yuling Liu", "Yunpeng Li", "Dan Du", "Kaiyu Xie", "Hongsong Zhu"], "title": "QLPro: Automated Code Vulnerability Discovery via LLM and Static Code Analysis Integration", "categories": ["cs.SE", "cs.AI", "cs.CR"], "comment": null, "summary": "We introduce QLPro, a vulnerability detection framework that systematically\nintegrates LLMs and static analysis tools to enable comprehensive vulnerability\ndetection across entire open-source projects.We constructed a new dataset,\nJavaTest, comprising 10 open-source projects from GitHub with 62 confirmed\nvulnerabilities. CodeQL, a state-of-the-art static analysis tool, detected only\n24 of these vulnerabilities while QLPro detected 41. Furthermore, QLPro\ndiscovered 6 previously unknown vulnerabilities, 2 of which have been confirmed\nas 0-days.", "AI": {"tldr": "QLPro, a framework combining LLMs and static analysis, outperforms CodeQL in detecting vulnerabilities, identifying 41 out of 62 confirmed vulnerabilities and discovering 6 new ones, including 2 0-days.", "motivation": "To enhance vulnerability detection in open-source projects by integrating LLMs with static analysis tools.", "method": "Systematically combines LLMs and static analysis (CodeQL) for comprehensive vulnerability detection, tested on the JavaTest dataset of 10 open-source projects.", "result": "QLPro detected 41 vulnerabilities (vs. 24 by CodeQL) and found 6 new vulnerabilities, including 2 0-days.", "conclusion": "QLPro significantly improves vulnerability detection, demonstrating the value of integrating LLMs with static analysis."}}
{"id": "2506.22488", "pdf": "https://arxiv.org/pdf/2506.22488", "abs": "https://arxiv.org/abs/2506.22488", "authors": ["Xi Fu", "Weibang Jiang", "Rui Liu", "Gernot R. M\u00fcller-Putz", "Cuntai Guan"], "title": "Zero-Shot EEG-to-Gait Decoding via Phase-Aware Representation Learning", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Accurate decoding of lower-limb motion from EEG signals is essential for\nadvancing brain-computer interface (BCI) applications in movement intent\nrecognition and control. However, challenges persist in achieving causal,\nphase-consistent predictions and in modeling both inter- and intra-subject\nvariability. To address these issues, we propose NeuroDyGait, a\ndomain-generalizable EEG-to-motion decoding framework that leverages structured\ncontrastive representation learning and relational domain modeling. The\nproposed method employs relative contrastive learning to achieve semantic\nalignment between EEG and motion embeddings. Furthermore, a multi-cycle gait\nreconstruction objective is introduced to enforce temporal coherence and\nmaintain biomechanical consistency. To promote inter-session generalization,\nduring fine-tuning, a domain dynamic decoding mechanism adaptively assigns\nsession-specific prediction heads and learns to mix their outputs based on\ninter-session relationships. NeuroDyGait enables zero-shot motion prediction\nfor unseen individuals without requiring adaptation and achieves superior\nperformance in cross-subject gait decoding on benchmark datasets. Additionally,\nit demonstrates strong phase-detection capabilities even without explicit phase\nsupervision during training. These findings highlight the potential of\nrelational domain learning in enabling scalable, target-free deployment of\nBCIs.", "AI": {"tldr": "NeuroDyGait, a domain-generalizable EEG-to-motion decoding framework, uses contrastive learning and relational domain modeling to improve cross-subject gait decoding and phase detection without explicit supervision.", "motivation": "Accurate decoding of lower-limb motion from EEG is crucial for BCI applications, but challenges like phase consistency and variability persist.", "method": "NeuroDyGait employs structured contrastive representation learning, multi-cycle gait reconstruction, and adaptive domain dynamic decoding for generalization.", "result": "The framework achieves zero-shot motion prediction for unseen individuals and superior cross-subject gait decoding performance.", "conclusion": "Relational domain learning in NeuroDyGait enables scalable, target-free BCI deployment with strong phase-detection capabilities."}}
{"id": "2506.23440", "pdf": "https://arxiv.org/pdf/2506.23440", "abs": "https://arxiv.org/abs/2506.23440", "authors": ["Mahesh Bhosale", "Abdul Wasi", "Yuanhao Zhai", "Yunjie Tian", "Samuel Border", "Nan Xi", "Pinaki Sarder", "Junsong Yuan", "David Doermann", "Xuan Gong"], "title": "PathDiff: Histopathology Image Synthesis with Unpaired Text and Mask Conditions", "categories": ["cs.CV"], "comment": "Accepted to ICCV 2025", "summary": "Diffusion-based generative models have shown promise in synthesizing\nhistopathology images to address data scarcity caused by privacy constraints.\nDiagnostic text reports provide high-level semantic descriptions, and masks\noffer fine-grained spatial structures essential for representing distinct\nmorphological regions. However, public datasets lack paired text and mask data\nfor the same histopathological images, limiting their joint use in image\ngeneration. This constraint restricts the ability to fully exploit the benefits\nof combining both modalities for enhanced control over semantics and spatial\ndetails. To overcome this, we propose PathDiff, a diffusion framework that\neffectively learns from unpaired mask-text data by integrating both modalities\ninto a unified conditioning space. PathDiff allows precise control over\nstructural and contextual features, generating high-quality, semantically\naccurate images. PathDiff also improves image fidelity, text-image alignment,\nand faithfulness, enhancing data augmentation for downstream tasks like nuclei\nsegmentation and classification. Extensive experiments demonstrate its\nsuperiority over existing methods.", "AI": {"tldr": "PathDiff is a diffusion framework that generates histopathology images by integrating unpaired mask-text data, improving control over semantics and spatial details for enhanced image quality and downstream task performance.", "motivation": "Public datasets lack paired text and mask data for histopathology images, limiting joint use in image generation and control over semantics and spatial details.", "method": "PathDiff integrates unpaired mask-text data into a unified conditioning space within a diffusion framework, enabling precise control over structural and contextual features.", "result": "PathDiff generates high-quality, semantically accurate images, improving fidelity, text-image alignment, and faithfulness for tasks like nuclei segmentation and classification.", "conclusion": "PathDiff outperforms existing methods, demonstrating its effectiveness in leveraging unpaired mask-text data for enhanced histopathology image generation."}}
{"id": "2412.12386", "pdf": "https://arxiv.org/pdf/2412.12386", "abs": "https://arxiv.org/abs/2412.12386", "authors": ["Giang Nguyen", "Ivan Brugere", "Shubham Sharma", "Sanjay Kariyappa", "Anh Totti Nguyen", "Freddy Lecue"], "title": "Interpretable LLM-based Table Question Answering", "categories": ["cs.CL", "cs.LG"], "comment": "Published in Transactions on Machine Learning Research (TMLR) in\n  06/2025. Reviews at: https://openreview.net/forum?id=2eTsZBoU2W", "summary": "Interpretability in Table Question Answering (Table QA) is critical,\nespecially in high-stakes domains like finance and healthcare. While recent\nTable QA approaches based on Large Language Models (LLMs) achieve high\naccuracy, they often produce ambiguous explanations of how answers are derived.\n  We propose Plan-of-SQLs (POS), a new Table QA method that makes the model's\ndecision-making process interpretable. POS decomposes a question into a\nsequence of atomic steps, each directly translated into an executable SQL\ncommand on the table, thereby ensuring that every intermediate result is\ntransparent. Through extensive experiments, we show that: First, POS generates\nthe highest-quality explanations among compared methods, which markedly\nimproves the users' ability to simulate and verify the model's decisions.\nSecond, when evaluated on standard Table QA benchmarks (TabFact, WikiTQ, and\nFeTaQA), POS achieves QA accuracy that is competitive to existing methods,\nwhile also offering greater efficiency-requiring significantly fewer LLM calls\nand table database queries (up to 25x fewer)-and more robust performance on\nlarge-sized tables. Finally, we observe high agreement (up to 90.59% in forward\nsimulation) between LLMs and human users when making decisions based on the\nsame explanations, suggesting that LLMs could serve as an effective proxy for\nhumans in evaluating Table QA explanations.", "AI": {"tldr": "Plan-of-SQLs (POS) is a Table QA method that enhances interpretability by decomposing questions into executable SQL steps, ensuring transparency and competitive accuracy with fewer LLM calls.", "motivation": "Interpretability in Table QA is crucial for high-stakes domains, but current LLM-based methods lack clear explanations.", "method": "POS decomposes questions into atomic steps, each translated into SQL commands, ensuring transparent intermediate results.", "result": "POS generates high-quality explanations, improves user verification, achieves competitive accuracy, and reduces LLM calls by up to 25x.", "conclusion": "POS offers interpretable, efficient, and robust Table QA, with LLMs effectively simulating human decision-making based on explanations."}}
{"id": "2506.23678", "pdf": "https://arxiv.org/pdf/2506.23678", "abs": "https://arxiv.org/abs/2506.23678", "authors": ["Rock Yuren Pang", "K. J. Kevin Feng", "Shangbin Feng", "Chu Li", "Weijia Shi", "Yulia Tsvetkov", "Jeffrey Heer", "Katharina Reinecke"], "title": "Interactive Reasoning: Visualizing and Controlling Chain-of-Thought Reasoning in Large Language Models", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "The output quality of large language models (LLMs) can be improved via\n\"reasoning\": generating segments of chain-of-thought (CoT) content to further\ncondition the model prior to producing user-facing output. While these chains\ncontain valuable information, they are verbose and lack explicit organization,\nmaking them tedious to review. Moreover, they lack opportunities for user\nfeedback, such as to remove unwanted considerations, add desired ones, or\nclarify unclear assumptions. We introduce Interactive Reasoning, an interaction\ndesign that visualizes chain-of-thought outputs as a hierarchy of topics and\nenables user review and modification. We implement interactive reasoning in\nHippo, a prototype for AI-assisted decision making in the face of uncertain\ntrade-offs. In a user study with 16 participants, we find that interactive\nreasoning in Hippo allows users to quickly identify and interrupt erroneous\ngenerations, efficiently steer the model towards customized responses, and\nbetter understand both model reasoning and model outputs. Our work contributes\nto a new paradigm that incorporates user oversight into LLM reasoning\nprocesses.", "AI": {"tldr": "Interactive Reasoning improves LLM output by organizing chain-of-thought content hierarchically, enabling user feedback and oversight.", "motivation": "Chain-of-thought outputs are verbose, disorganized, and lack user feedback opportunities, hindering review and customization.", "method": "Introduces Interactive Reasoning, visualized as a topic hierarchy, implemented in Hippo for AI-assisted decision-making.", "result": "Users efficiently identify errors, steer responses, and understand model reasoning better.", "conclusion": "Interactive Reasoning integrates user oversight into LLM processes, enhancing output quality and usability."}}
{"id": "2506.22490", "pdf": "https://arxiv.org/pdf/2506.22490", "abs": "https://arxiv.org/abs/2506.22490", "authors": ["Zhenke Duan", "Jiqun Pan", "Jiani Tu"], "title": "MENGLAN: Multiscale Enhanced Nonparametric Gas Analyzer with Lightweight Architecture and Networks", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Accurate detection of ethylene concentrations in mixed gases is crucial in\nchemical production for safety and health purposes. Traditional methods are\nhindered by high cost and complexity, limiting their practical application.\nThis study proposes MENGLAN, a Multiscale Enhanced Nonparametric Gas Analyzer\nthat integrates a dual-stream structure, a Hybrid Multi-Head Attention\nmechanism, and a Feature Reactivation Module to enable real-time, lightweight,\nand high-precision ethylene concentration prediction. Results show that MENGLAN\nachieves superior performance, reduced computational demand, and enhanced\ndeployability compared to existing methods.", "AI": {"tldr": "MENGLAN is a lightweight, high-precision gas analyzer for ethylene detection, outperforming traditional methods in cost, complexity, and performance.", "motivation": "Traditional ethylene detection methods are costly and complex, limiting practical use. MENGLAN aims to address these issues.", "method": "MENGLAN uses a dual-stream structure, Hybrid Multi-Head Attention, and Feature Reactivation Module for real-time, precise prediction.", "result": "MENGLAN achieves superior performance, lower computational demand, and better deployability than existing methods.", "conclusion": "MENGLAN offers a practical, efficient solution for ethylene detection in mixed gases."}}
{"id": "2506.23460", "pdf": "https://arxiv.org/pdf/2506.23460", "abs": "https://arxiv.org/abs/2506.23460", "authors": ["Dewen Zeng", "Xinrong Hu", "Yu-Jen Chen", "Yawen Wu", "Xiaowei Xu", "Yiyu Shi"], "title": "Contrastive Learning with Diffusion Features for Weakly Supervised Medical Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Weakly supervised semantic segmentation (WSSS) methods using class labels\noften rely on class activation maps (CAMs) to localize objects. However,\ntraditional CAM-based methods struggle with partial activations and imprecise\nobject boundaries due to optimization discrepancies between classification and\nsegmentation. Recently, the conditional diffusion model (CDM) has been used as\nan alternative for generating segmentation masks in WSSS, leveraging its strong\nimage generation capabilities tailored to specific class distributions. By\nmodifying or perturbing the condition during diffusion sampling, the related\nobjects can be highlighted in the generated images. Yet, the saliency maps\ngenerated by CDMs are prone to noise from background alterations during reverse\ndiffusion. To alleviate the problem, we introduce Contrastive Learning with\nDiffusion Features (CLDF), a novel method that uses contrastive learning to\ntrain a pixel decoder to map the diffusion features from a frozen CDM to a\nlow-dimensional embedding space for segmentation. Specifically, we integrate\ngradient maps generated from CDM external classifier with CAMs to identify\nforeground and background pixels with fewer false positives/negatives for\ncontrastive learning, enabling robust pixel embedding learning. Experimental\nresults on four segmentation tasks from two public medical datasets demonstrate\nthat our method significantly outperforms existing baselines.", "AI": {"tldr": "The paper introduces CLDF, a method using contrastive learning with diffusion features to improve weakly supervised semantic segmentation by addressing noise in saliency maps from conditional diffusion models.", "motivation": "Traditional CAM-based methods for WSSS suffer from partial activations and imprecise boundaries. CDMs offer an alternative but introduce noise in saliency maps due to background alterations.", "method": "CLDF integrates gradient maps from CDMs with CAMs for contrastive learning, training a pixel decoder to map diffusion features to a low-dimensional embedding space for segmentation.", "result": "Experiments on four tasks from two medical datasets show CLDF outperforms existing baselines.", "conclusion": "CLDF effectively reduces noise and improves segmentation accuracy in weakly supervised settings."}}
{"id": "2412.17063", "pdf": "https://arxiv.org/pdf/2412.17063", "abs": "https://arxiv.org/abs/2412.17063", "authors": ["Esther Shizgal", "Eitan Wagner", "Renana Keydar", "Omri Abend"], "title": "Computational Analysis of Character Development in Holocaust Testimonies", "categories": ["cs.CL"], "comment": null, "summary": "This work presents a computational approach to analyze character development\nalong the narrative timeline. The analysis characterizes the inner and outer\nchanges the protagonist undergoes within a narrative, and the interplay between\nthem. We consider transcripts of Holocaust survivor testimonies as a test case,\neach telling the story of an individual in first-person terms. We focus on the\nsurvivor's religious trajectory, examining the evolution of their disposition\ntoward religious belief and practice along the testimony. Clustering the\nresulting trajectories in the dataset, we identify common sequences in the\ndata. Our findings highlight multiple common structures of religiosity across\nthe narratives: in terms of belief, most present a constant disposition, while\nfor practice, most present an oscillating structure, serving as valuable\nmaterial for historical and sociological research. This work demonstrates the\npotential of natural language processing techniques for analyzing character\nevolution through thematic trajectories in narratives.", "AI": {"tldr": "A computational method analyzes character development in Holocaust survivor testimonies, focusing on religious trajectories, revealing common patterns in belief and practice.", "motivation": "To explore the interplay between inner and outer changes in protagonists' religious trajectories within narratives, using Holocaust survivor testimonies as a case study.", "method": "Natural language processing techniques are applied to cluster and analyze religious belief and practice trajectories in first-person testimonies.", "result": "Most narratives show constant religious belief but oscillating practice, identifying common structures for historical and sociological research.", "conclusion": "The study showcases NLP's potential for thematic trajectory analysis in narratives, offering insights into character evolution."}}
{"id": "2506.23717", "pdf": "https://arxiv.org/pdf/2506.23717", "abs": "https://arxiv.org/abs/2506.23717", "authors": ["Xingting Yao", "Qinghao Hu", "Fei Zhou", "Tielong Liu", "Gang Li", "Peisong Wang", "Jian Cheng"], "title": "Towards Efficient and Accurate Spiking Neural Networks via Adaptive Bit Allocation", "categories": ["cs.NE", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-bit spiking neural networks (SNNs) have recently become a heated\nresearch spot, pursuing energy-efficient and high-accurate AI. However, with\nmore bits involved, the associated memory and computation demands escalate to\nthe point where the performance improvements become disproportionate. Based on\nthe insight that different layers demonstrate different importance and extra\nbits could be wasted and interfering, this paper presents an adaptive bit\nallocation strategy for direct-trained SNNs, achieving fine-grained layer-wise\nallocation of memory and computation resources. Thus, SNN's efficiency and\naccuracy can be improved. Specifically, we parametrize the temporal lengths and\nthe bit widths of weights and spikes, and make them learnable and controllable\nthrough gradients. To address the challenges caused by changeable bit widths\nand temporal lengths, we propose the refined spiking neuron, which can handle\ndifferent temporal lengths, enable the derivation of gradients for temporal\nlengths, and suit spike quantization better. In addition, we theoretically\nformulate the step-size mismatch problem of learnable bit widths, which may\nincur severe quantization errors to SNN, and accordingly propose the step-size\nrenewal mechanism to alleviate this issue. Experiments on various datasets,\nincluding the static CIFAR and ImageNet and the dynamic CIFAR-DVS and\nDVS-GESTURE, demonstrate that our methods can reduce the overall memory and\ncomputation cost while achieving higher accuracy. Particularly, our\nSEWResNet-34 can achieve a 2.69\\% accuracy gain and 4.16$\\times$ lower bit\nbudgets over the advanced baseline work on ImageNet. This work will be fully\nopen-sourced.", "AI": {"tldr": "The paper introduces an adaptive bit allocation strategy for multi-bit SNNs to optimize memory and computation resources, improving efficiency and accuracy.", "motivation": "Multi-bit SNNs face disproportionate performance improvements due to escalating memory and computation demands with more bits. Different layers have varying importance, and extra bits can be wasted or interfere.", "method": "The paper parametrizes temporal lengths and bit widths of weights and spikes, making them learnable via gradients. A refined spiking neuron is proposed to handle variable bit widths and temporal lengths, along with a step-size renewal mechanism to address quantization errors.", "result": "Experiments on static and dynamic datasets show reduced memory and computation costs with higher accuracy, e.g., a 2.69% accuracy gain and 4.16\u00d7 lower bit budgets on ImageNet.", "conclusion": "The adaptive bit allocation strategy effectively enhances SNN efficiency and accuracy, with open-sourced implementation."}}
{"id": "2506.22494", "pdf": "https://arxiv.org/pdf/2506.22494", "abs": "https://arxiv.org/abs/2506.22494", "authors": ["Shihong Ling", "Yue Wan", "Xiaowei Jia", "Na Du"], "title": "DriveBLIP2: Attention-Guided Explanation Generation for Complex Driving Scenarios", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": "Accepted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS) 2025. 7 pages, 3 figures", "summary": "This paper introduces a new framework, DriveBLIP2, built upon the BLIP2-OPT\narchitecture, to generate accurate and contextually relevant explanations for\nemerging driving scenarios. While existing vision-language models perform well\nin general tasks, they encounter difficulties in understanding complex,\nmulti-object environments, particularly in real-time applications such as\nautonomous driving, where the rapid identification of key objects is crucial.\nTo address this limitation, an Attention Map Generator is proposed to highlight\nsignificant objects relevant to driving decisions within critical video frames.\nBy directing the model's focus to these key regions, the generated attention\nmap helps produce clear and relevant explanations, enabling drivers to better\nunderstand the vehicle's decision-making process in critical situations.\nEvaluations on the DRAMA dataset reveal significant improvements in explanation\nquality, as indicated by higher BLEU, ROUGE, CIDEr, and SPICE scores compared\nto baseline models. These findings underscore the potential of targeted\nattention mechanisms in vision-language models for enhancing explainability in\nreal-time autonomous driving.", "AI": {"tldr": "DriveBLIP2 improves explanation quality in driving scenarios using an Attention Map Generator to highlight key objects, outperforming baselines on the DRAMA dataset.", "motivation": "Existing vision-language models struggle with complex, real-time driving scenarios, requiring better focus on key objects for accurate explanations.", "method": "Proposes an Attention Map Generator to highlight significant objects in critical video frames, enhancing the model's focus and explanation relevance.", "result": "Evaluations show higher BLEU, ROUGE, CIDEr, and SPICE scores on the DRAMA dataset, indicating improved explanation quality.", "conclusion": "Targeted attention mechanisms in vision-language models enhance explainability for real-time autonomous driving."}}
{"id": "2506.23467", "pdf": "https://arxiv.org/pdf/2506.23467", "abs": "https://arxiv.org/abs/2506.23467", "authors": ["Chenlang Yi", "Zizhan Xiong", "Qi Qi", "Xiyuan Wei", "Girish Bathla", "Ching-Long Lin", "Bobak Jack Mortazavi", "Tianbao Yang"], "title": "AdFair-CLIP: Adversarial Fair Contrastive Language-Image Pre-training for Chest X-rays", "categories": ["cs.CV", "cs.LG"], "comment": "This preprint has been accepted by MICCAI 2025", "summary": "Contrastive Language-Image Pre-training (CLIP) models have demonstrated\nsuperior performance across various visual tasks including medical image\nclassification. However, fairness concerns, including demographic biases, have\nreceived limited attention for CLIP models. This oversight leads to critical\nissues, particularly those related to race and gender, resulting in disparities\nin diagnostic outcomes and reduced reliability for underrepresented groups. To\naddress these challenges, we introduce AdFair-CLIP, a novel framework employing\nadversarial feature intervention to suppress sensitive attributes, thereby\nmitigating spurious correlations and improving prediction fairness. We conduct\ncomprehensive experiments on chest X-ray (CXR) datasets, and show that\nAdFair-CLIP significantly enhances both fairness and diagnostic accuracy, while\nmaintaining robust generalization in zero-shot and few-shot scenarios. These\nresults establish new benchmarks for fairness-aware learning in CLIP-based\nmedical diagnostic models, particularly for CXR analysis.", "AI": {"tldr": "AdFair-CLIP improves fairness and accuracy in CLIP-based medical image models by suppressing biases with adversarial feature intervention.", "motivation": "Address fairness concerns like demographic biases in CLIP models, which cause disparities in diagnostic outcomes for underrepresented groups.", "method": "Introduces AdFair-CLIP, using adversarial feature intervention to mitigate spurious correlations and improve fairness.", "result": "Significantly enhances fairness and diagnostic accuracy in chest X-ray datasets, maintaining robustness in zero-shot and few-shot scenarios.", "conclusion": "Sets new benchmarks for fairness-aware learning in CLIP-based medical diagnostic models, especially for CXR analysis."}}
{"id": "2501.01644", "pdf": "https://arxiv.org/pdf/2501.01644", "abs": "https://arxiv.org/abs/2501.01644", "authors": ["Tien Dang", "Viet Thanh Duy Nguyen", "Minh Tuan Le", "Truong-Son Hy"], "title": "Multimodal Contrastive Representation Learning in Augmented Biomedical Knowledge Graphs", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Biomedical Knowledge Graphs (BKGs) integrate diverse datasets to elucidate\ncomplex relationships within the biomedical field. Effective link prediction on\nthese graphs can uncover valuable connections, such as potential novel\ndrug-disease relations. We introduce a novel multimodal approach that unifies\nembeddings from specialized Language Models (LMs) with Graph Contrastive\nLearning (GCL) to enhance intra-entity relationships while employing a\nKnowledge Graph Embedding (KGE) model to capture inter-entity relationships for\neffective link prediction. To address limitations in existing BKGs, we present\nPrimeKG++, an enriched knowledge graph incorporating multimodal data, including\nbiological sequences and textual descriptions for each entity type. By\ncombining semantic and relational information in a unified representation, our\napproach demonstrates strong generalizability, enabling accurate link\npredictions even for unseen nodes. Experimental results on PrimeKG++ and the\nDrugBank drug-target interaction dataset demonstrate the effectiveness and\nrobustness of our method across diverse biomedical datasets. Our source code,\npre-trained models, and data are publicly available at\nhttps://github.com/HySonLab/BioMedKG", "AI": {"tldr": "A multimodal approach combining Language Models and Graph Contrastive Learning improves link prediction in Biomedical Knowledge Graphs, demonstrated on PrimeKG++ and DrugBank datasets.", "motivation": "To enhance link prediction in Biomedical Knowledge Graphs (BKGs) by uncovering novel drug-disease relations and addressing limitations in existing BKGs.", "method": "Unifies embeddings from specialized Language Models (LMs) with Graph Contrastive Learning (GCL) and employs a Knowledge Graph Embedding (KGE) model for intra- and inter-entity relationships. Introduces PrimeKG++, an enriched knowledge graph with multimodal data.", "result": "Demonstrates strong generalizability and accurate link predictions, even for unseen nodes, on PrimeKG++ and DrugBank datasets.", "conclusion": "The approach is effective and robust for diverse biomedical datasets, with publicly available code, models, and data."}}
{"id": "2506.23724", "pdf": "https://arxiv.org/pdf/2506.23724", "abs": "https://arxiv.org/abs/2506.23724", "authors": ["Chang'an Yi", "Xiaohui Deng", "Guohao Chen", "Yan Zhou", "Qinghua Lu", "Shuaicheng Niu"], "title": "When Small Guides Large: Cross-Model Co-Learning for Test-Time Adaptation", "categories": ["cs.CV", "cs.AI"], "comment": "15 pages, 5 figures", "summary": "Test-time Adaptation (TTA) adapts a given model to testing domain data with\npotential domain shifts through online unsupervised learning, yielding\nimpressive performance. However, to date, existing TTA methods primarily focus\non single-model adaptation. In this work, we investigate an intriguing\nquestion: how does cross-model knowledge influence the TTA process? Our\nfindings reveal that, in TTA's unsupervised online setting, each model can\nprovide complementary, confident knowledge to the others, even when there are\nsubstantial differences in model size. For instance, a smaller model like\nMobileViT (10.6M parameters) can effectively guide a larger model like ViT-Base\n(86.6M parameters). In light of this, we propose COCA, a Cross-Model\nCo-Learning framework for TTA, which mainly consists of two main strategies. 1)\nCo-adaptation adaptively integrates complementary knowledge from other models\nthroughout the TTA process, reducing individual model biases. 2)\nSelf-adaptation enhances each model's unique strengths via unsupervised\nlearning, enabling diverse adaptation to the target domain. Extensive\nexperiments show that COCA, which can also serve as a plug-and-play module,\nsignificantly boosts existing SOTAs, on models with various sizes--including\nResNets, ViTs, and Mobile-ViTs--via cross-model co-learned TTA. For example,\nwith Mobile-ViT's guidance, COCA raises ViT-Base's average adaptation accuracy\non ImageNet-C from 51.7% to 64.5%. The code is publicly available at\nhttps://github.com/ycarobot/COCA.", "AI": {"tldr": "COCA introduces a Cross-Model Co-Learning framework for Test-time Adaptation (TTA), leveraging complementary knowledge across models to improve adaptation performance.", "motivation": "Existing TTA methods focus on single-model adaptation, but cross-model knowledge can enhance performance, as smaller models can guide larger ones effectively.", "method": "COCA combines co-adaptation (integrating knowledge from other models) and self-adaptation (enhancing individual strengths via unsupervised learning).", "result": "COCA significantly improves adaptation accuracy, e.g., boosting ViT-Base's performance on ImageNet-C from 51.7% to 64.5% with Mobile-ViT's guidance.", "conclusion": "COCA demonstrates the value of cross-model co-learning in TTA, offering a plug-and-play solution for diverse models."}}
{"id": "2506.22536", "pdf": "https://arxiv.org/pdf/2506.22536", "abs": "https://arxiv.org/abs/2506.22536", "authors": ["Yu Zhang", "Shanshan Zhao", "Bokui Wan", "Jinjuan Wang", "Xiaodong Yan"], "title": "Strategic A/B testing via Maximum Probability-driven Two-armed Bandit", "categories": ["stat.ML", "cs.LG", "math.PR"], "comment": "25 pages, 14 figures", "summary": "Detecting a minor average treatment effect is a major challenge in\nlarge-scale applications, where even minimal improvements can have a\nsignificant economic impact. Traditional methods, reliant on normal\ndistribution-based or expanded statistics, often fail to identify such minor\neffects because of their inability to handle small discrepancies with\nsufficient sensitivity. This work leverages a counterfactual outcome framework\nand proposes a maximum probability-driven two-armed bandit (TAB) process by\nweighting the mean volatility statistic, which controls Type I error. The\nimplementation of permutation methods further enhances the robustness and\nefficacy. The established strategic central limit theorem (SCLT) demonstrates\nthat our approach yields a more concentrated distribution under the null\nhypothesis and a less concentrated one under the alternative hypothesis,\ngreatly improving statistical power. The experimental results indicate a\nsignificant improvement in the A/B testing, highlighting the potential to\nreduce experimental costs while maintaining high statistical power.", "AI": {"tldr": "Proposes a maximum probability-driven two-armed bandit (TAB) process for detecting minor treatment effects in large-scale applications, improving sensitivity and reducing costs.", "motivation": "Traditional methods fail to detect minor average treatment effects due to insufficient sensitivity, despite their economic significance.", "method": "Uses a counterfactual outcome framework and a TAB process weighted by mean volatility statistic, enhanced with permutation methods.", "result": "Demonstrates improved statistical power via a strategic central limit theorem (SCLT), with experimental results showing cost-effective A/B testing.", "conclusion": "The approach enhances detection of minor effects, offering economic benefits and reduced experimental costs."}}
{"id": "2506.23468", "pdf": "https://arxiv.org/pdf/2506.23468", "abs": "https://arxiv.org/abs/2506.23468", "authors": ["Xuan Yao", "Junyu Gao", "Changsheng Xu"], "title": "NavMorph: A Self-Evolving World Model for Vision-and-Language Navigation in Continuous Environments", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "Vision-and-Language Navigation in Continuous Environments (VLN-CE) requires\nagents to execute sequential navigation actions in complex environments guided\nby natural language instructions. Current approaches often struggle with\ngeneralizing to novel environments and adapting to ongoing changes during\nnavigation. Inspired by human cognition, we present NavMorph, a self-evolving\nworld model framework that enhances environmental understanding and\ndecision-making in VLN-CE tasks. NavMorph employs compact latent\nrepresentations to model environmental dynamics, equipping agents with\nforesight for adaptive planning and policy refinement. By integrating a novel\nContextual Evolution Memory, NavMorph leverages scene-contextual information to\nsupport effective navigation while maintaining online adaptability. Extensive\nexperiments demonstrate that our method achieves notable performance\nimprovements on popular VLN-CE benchmarks. Code is available at\n\\href{https://github.com/Feliciaxyao/NavMorph}{this https URL}.", "AI": {"tldr": "NavMorph is a self-evolving world model framework for VLN-CE tasks, improving generalization and adaptability in navigation using compact latent representations and Contextual Evolution Memory.", "motivation": "Current VLN-CE approaches struggle with generalization to novel environments and adapting to ongoing changes during navigation.", "method": "NavMorph uses compact latent representations to model environmental dynamics and integrates Contextual Evolution Memory for scene-contextual navigation.", "result": "The method achieves notable performance improvements on VLN-CE benchmarks.", "conclusion": "NavMorph enhances environmental understanding and decision-making, demonstrating effectiveness in VLN-CE tasks."}}
{"id": "2501.03124", "pdf": "https://arxiv.org/pdf/2501.03124", "abs": "https://arxiv.org/abs/2501.03124", "authors": ["Mingyang Song", "Zhaochen Su", "Xiaoye Qu", "Jiawei Zhou", "Yu Cheng"], "title": "PRMBench: A Fine-grained and Challenging Benchmark for Process-Level Reward Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted by ACL 2025 Main. Project Page: https://prmbench.github.io/", "summary": "Process-level Reward Models (PRMs) are crucial for complex reasoning and\ndecision-making tasks, where each intermediate step plays an important role in\nthe reasoning process. Since language models are prone to various types of\nerrors during the reasoning process, PRMs are required to possess nuanced\ncapabilities for detecting various implicit error types in real-world\nscenarios. However, current benchmarks primarily focus on step correctness,\nfailing to evaluate PRMs' performance systematically. To address this gap, we\nintroduce PRMBench, a process-level benchmark specifically designed to assess\nthe fine-grained error detection capabilities of PRMs. PRMBench comprises 6,216\ncarefully designed problems and 83,456 step-level labels, evaluating models\nacross multiple dimensions, including simplicity, soundness, and sensitivity.\nIn our experiments on 15 models, spanning both open-source PRMs and\nclosed-source large language models prompted as critic models, we uncover\nsignificant weaknesses in current PRMs. These findings underscore the\nchallenges inherent in process-level evaluation and highlight key directions\nfor future research. We hope PRMBench can be a robust bench for advancing\nresearch on PRM evaluation and development.", "AI": {"tldr": "PRMBench is introduced to evaluate Process-level Reward Models (PRMs) on fine-grained error detection, revealing weaknesses in current models.", "motivation": "Current benchmarks lack systematic evaluation of PRMs' nuanced error detection capabilities in complex reasoning tasks.", "method": "PRMBench, a benchmark with 6,216 problems and 83,456 step-level labels, assesses PRMs across dimensions like simplicity, soundness, and sensitivity.", "result": "Experiments on 15 models (open-source PRMs and closed-source LLMs) expose significant weaknesses in current PRMs.", "conclusion": "PRMBench highlights challenges in process-level evaluation and aims to advance PRM research."}}
{"id": "2506.23725", "pdf": "https://arxiv.org/pdf/2506.23725", "abs": "https://arxiv.org/abs/2506.23725", "authors": ["Atharva Gundawar", "Som Sagar", "Ransalu Senanayake"], "title": "PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Vision-Language Models (VLMs) are increasingly pivotal for generalist robot\nmanipulation, enabling tasks such as physical reasoning, policy generation, and\nfailure detection. However, their proficiency in these high-level applications\noften assumes a deep understanding of low-level physical prerequisites, a\ncapability that remains largely unverified. For robots to perform actions\nreliably, they must comprehend intrinsic object properties (e.g., material,\nweight), action affordances (e.g., graspable, stackable), and physical\nconstraints (e.g., stability, reachability, or an object's state, such as being\nclosed). Despite the widespread use of VLMs in manipulation tasks, we argue\nthat off-the-shelf models may lack this granular, physically grounded\nunderstanding, as such prerequisites are often overlooked during training.\n  To address this critical gap, we introduce PAC Bench, a comprehensive\nbenchmark designed to systematically evaluate VLMs on their understanding of\ncore Properties, Affordances, and Constraints (PAC) from a task executability\nperspective. PAC Bench features a diverse dataset with over 30,000 annotations,\ncomprising 673 real-world images (115 object classes, 15 property types, and 1\nto 3 affordances defined per class), 100 real-world humanoid-view scenarios,\nand 120 unique simulated constraint scenarios across four tasks.\n  Our evaluations reveal significant gaps in the ability of current VLMs to\ngrasp fundamental physical concepts, highlighting limitations in their\nsuitability for reliable robot manipulation and pointing to key areas for\ntargeted research. PAC Bench also serves as a standardized benchmark for\nrigorously evaluating physical reasoning in VLMs and guiding the development of\nmore robust, physically grounded models for robotic applications.\n  Project Page: https://pacbench.github.io/", "AI": {"tldr": "PAC Bench is introduced to evaluate Vision-Language Models (VLMs) on their understanding of physical prerequisites like properties, affordances, and constraints, revealing gaps in current models for reliable robot manipulation.", "motivation": "Current VLMs lack verified understanding of low-level physical prerequisites (e.g., object properties, affordances, constraints), which are critical for reliable robot manipulation.", "method": "PAC Bench, a benchmark with a diverse dataset (30,000+ annotations, real-world images, humanoid-view scenarios, and simulated tasks), systematically evaluates VLMs on physical reasoning.", "result": "Evaluations show significant gaps in VLMs' grasp of fundamental physical concepts, limiting their reliability for robot manipulation.", "conclusion": "PAC Bench highlights the need for more robust, physically grounded VLMs and serves as a standardized benchmark for future research in robotic applications."}}
{"id": "2506.22552", "pdf": "https://arxiv.org/pdf/2506.22552", "abs": "https://arxiv.org/abs/2506.22552", "authors": ["Fabrizio Falasca"], "title": "Neural models of multiscale systems: conceptual limitations, stochastic parametrizations, and a climate application", "categories": ["nlin.CD", "cond-mat.stat-mech", "cs.LG", "physics.ao-ph"], "comment": null, "summary": "This work explores key conceptual limitations in data-driven modeling of\nmultiscale dynamical systems, focusing on neural emulators and stochastic\nclimate modeling. A skillful climate model should capture both stationary\nstatistics and responses to external perturbations. While current\nautoregressive neural models often reproduce the former, they typically\nstruggle with the latter. We begin by analyzing a low-dimensional dynamical\nsystem to expose, by analogy, fundamental limitations that persist in\nhigh-dimensional settings. Specifically, we construct neural stochastic models\nunder two scenarios: one where the full state vector is observed, and another\nwith only partial observations (i.e. a subset of variables). In the first case,\nthe models accurately capture both equilibrium statistics and forced responses\nin ensemble mean and variance. In the more realistic case of partial\nobservations, two key challenges emerge: (i) identifying the \\textit{proper}\nvariables to model, and (ii) parameterizing the influence of unobserved degrees\nof freedom. These issues are not specific to neural networks but reflect\nfundamental limitations of data-driven modeling and the need to target the slow\ndynamics of the system. We argue that physically grounded strategies -- such as\ncoarse-graining and stochastic parameterizations -- are critical, both\nconceptually and practically, for the skillful emulation of complex systems\nlike the coupled climate system. Building on these insights, we turn to a more\nrealistic application: a stochastic reduced neural model of the sea surface\ntemperature field and the net radiative flux at the top of the atmosphere,\nassessing its stationary statistics, response to temperature forcing, and\ninterpretability.", "AI": {"tldr": "The paper examines limitations in neural emulators and stochastic climate models, highlighting challenges in capturing responses to external perturbations, especially with partial observations. It advocates for physically grounded strategies like coarse-graining.", "motivation": "To address the limitations of current autoregressive neural models in capturing both stationary statistics and responses to external perturbations in multiscale dynamical systems, particularly in climate modeling.", "method": "Analyzes a low-dimensional dynamical system to expose limitations, constructs neural stochastic models under full and partial observation scenarios, and applies insights to a realistic climate model.", "result": "Neural models with full observations perform well, but partial observations pose challenges in variable selection and parameterization. Physically grounded strategies like coarse-graining are essential for skillful emulation.", "conclusion": "Physically informed approaches are crucial for effective data-driven modeling of complex systems like the climate, emphasizing the need to target slow dynamics and address partial observations."}}
{"id": "2506.23470", "pdf": "https://arxiv.org/pdf/2506.23470", "abs": "https://arxiv.org/abs/2506.23470", "authors": ["Ngoc-Do Tran", "Minh-Tuan Huynh", "Tam V. Nguyen", "Minh-Triet Tran", "Trung-Nghia Le"], "title": "Interactive Interface For Semantic Segmentation Dataset Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "The rapid advancement of AI and computer vision has significantly increased\nthe demand for high-quality annotated datasets, particularly for semantic\nsegmentation. However, creating such datasets is resource-intensive, requiring\nsubstantial time, labor, and financial investment, and often raises privacy\nconcerns due to the use of real-world data. To mitigate these challenges, we\npresent SynthLab, consisting of a modular platform for visual data synthesis\nand a user-friendly interface. The modular architecture of SynthLab enables\neasy maintenance, scalability with centralized updates, and seamless\nintegration of new features. Each module handles distinct aspects of computer\nvision tasks, enhancing flexibility and adaptability. Meanwhile, its\ninteractive, user-friendly interface allows users to quickly customize their\ndata pipelines through drag-and-drop actions. Extensive user studies involving\na diverse range of users across different ages, professions, and expertise\nlevels, have demonstrated flexible usage, and high accessibility of SynthLab,\nenabling users without deep technical expertise to harness AI for real-world\napplications.", "AI": {"tldr": "SynthLab is a modular platform for visual data synthesis, addressing the challenges of creating high-quality annotated datasets for semantic segmentation by offering scalability, ease of use, and privacy mitigation.", "motivation": "The resource-intensive and privacy-concerning nature of creating annotated datasets for AI and computer vision tasks drives the need for an efficient, user-friendly solution.", "method": "SynthLab employs a modular architecture for visual data synthesis, featuring a drag-and-drop interface for customizable data pipelines.", "result": "User studies show SynthLab is flexible, accessible, and usable by non-experts, enabling broader adoption of AI for real-world applications.", "conclusion": "SynthLab successfully addresses dataset creation challenges, offering a scalable and user-friendly solution for AI-driven tasks."}}
{"id": "2501.10316", "pdf": "https://arxiv.org/pdf/2501.10316", "abs": "https://arxiv.org/abs/2501.10316", "authors": ["Suvodip Dey", "Yi-Jyun Sun", "Gokhan Tur", "Dilek Hakkani-Tur"], "title": "Know Your Mistakes: Towards Preventing Overreliance on Task-Oriented Conversational AI Through Accountability Modeling", "categories": ["cs.CL"], "comment": "Accepted at ACL 2025 Main Conference", "summary": "Recent LLMs have enabled significant advancements for conversational agents.\nHowever, they are also well known to hallucinate, producing responses that seem\nplausible but are factually incorrect. On the other hand, users tend to\nover-rely on LLM-based AI agents, accepting AI's suggestion even when it is\nwrong. Adding positive friction, such as explanations or getting user\nconfirmations, has been proposed as a mitigation in AI-supported\ndecision-making systems. In this paper, we propose an accountability model for\nLLM-based task-oriented dialogue agents to address user overreliance via\nfriction turns in cases of model uncertainty and errors associated with\ndialogue state tracking (DST). The accountability model is an augmented LLM\nwith an additional accountability head that functions as a binary classifier to\npredict the relevant slots of the dialogue state mentioned in the conversation.\nWe perform our experiments with multiple backbone LLMs on two established\nbenchmarks (MultiWOZ and Snips). Our empirical findings demonstrate that the\nproposed approach not only enables reliable estimation of AI agent errors but\nalso guides the decoder in generating more accurate actions. We observe around\n3% absolute improvement in joint goal accuracy (JGA) of DST output by\nincorporating accountability heads into modern LLMs. Self-correcting the\ndetected errors further increases the JGA from 67.13 to 70.51, achieving\nstate-of-the-art DST performance. Finally, we show that error correction\nthrough user confirmations (friction turn) achieves a similar performance gain,\nhighlighting its potential to reduce user overreliance.", "AI": {"tldr": "The paper proposes an accountability model for LLM-based task-oriented dialogue agents to mitigate user overreliance by introducing friction turns during model uncertainty or errors, improving dialogue state tracking accuracy.", "motivation": "Addressing user overreliance on LLM-based AI agents and reducing hallucinations by introducing accountability and friction turns.", "method": "An augmented LLM with an accountability head (binary classifier) to predict dialogue state slots, tested on MultiWOZ and Snips benchmarks.", "result": "3% absolute improvement in joint goal accuracy (JGA); self-correction boosts JGA from 67.13 to 70.51, achieving state-of-the-art DST performance.", "conclusion": "The accountability model and friction turns effectively reduce errors and user overreliance, enhancing dialogue agent reliability."}}
{"id": "2506.23734", "pdf": "https://arxiv.org/pdf/2506.23734", "abs": "https://arxiv.org/abs/2506.23734", "authors": ["Hao Shi", "Xi Li", "Fangfang Xie"], "title": "Marker Gene Method : Identifying Stable Solutions in a Dynamic Environment", "categories": ["cs.NE", "cs.AI", "cs.GT"], "comment": "Submitted to IEEE Transactions on Evolutionary Computation. 13 pages,\n  10 figures. Supplementary material is included", "summary": "Competitive Co-evolutionary Algorithms (CCEAs) are often hampered by complex\ndynamics like intransitivity and the Red Queen effect, leading to unstable\nconvergence. To counter these challenges, this paper introduces the Marker Gene\nMethod (MGM), a framework that establishes stability by using a 'marker gene'\nas a dynamic benchmark and an adaptive weighting mechanism to balance\nexploration and exploitation. We provide rigorous mathematical proofs\ndemonstrating that MGM creates strong attractors near Nash Equilibria within\nthe Strictly Competitive Game framework. Empirically, MGM demonstrates its\nefficacy across a spectrum of challenges: it stabilizes the canonical\nRock-Paper-Scissors game, significantly improves the performance of C-RMOEA/D\non ZDT benchmarks, and, when augmented with a Memory Pool (MP) extension, it\nsuccessfully tames the notoriously pathological Shapley Biased Game. This work\npresents a theoretically sound and empirically validated framework that\nsubstantially enhances the stability and robustness of CCEAs in complex\ncompetitive environments.", "AI": {"tldr": "The paper introduces the Marker Gene Method (MGM) to stabilize Competitive Co-evolutionary Algorithms (CCEAs) by using a dynamic benchmark and adaptive weighting, proving its effectiveness theoretically and empirically.", "motivation": "CCEAs face instability due to intransitivity and the Red Queen effect, necessitating a method to ensure stable convergence.", "method": "MGM employs a 'marker gene' as a dynamic benchmark and adaptive weighting to balance exploration and exploitation, supported by mathematical proofs.", "result": "MGM stabilizes games like Rock-Paper-Scissors, improves C-RMOEA/D on ZDT benchmarks, and handles the Shapley Biased Game with a Memory Pool extension.", "conclusion": "MGM is a robust framework enhancing CCEA stability and performance in competitive environments."}}
{"id": "2506.22555", "pdf": "https://arxiv.org/pdf/2506.22555", "abs": "https://arxiv.org/abs/2506.22555", "authors": ["Callum Duffy", "Marcin Jastrzebski"], "title": "Spectral Bias in Variational Quantum Machine Learning", "categories": ["quant-ph", "cs.LG"], "comment": "12 pages, 8 figures", "summary": "In this work, we investigate the phenomenon of spectral bias in quantum\nmachine learning, where, in classical settings, models tend to fit\nlow-frequency components of a target function earlier during training than\nhigh-frequency ones, demonstrating a frequency-dependent rate of convergence.\nWe study this effect specifically in parameterised quantum circuits (PQCs).\nLeveraging the established formulation of PQCs as Fourier series, we prove that\nspectral bias in this setting arises from the ``redundancy'' of the Fourier\ncoefficients, which denotes the number of terms in the analytical form of the\nmodel contributing to the same frequency component. The choice of data encoding\nscheme dictates the degree of redundancy for a Fourier coefficient. We find\nthat the magnitude of the Fourier coefficients' gradients during training\nstrongly correlates with the coefficients' redundancy. We then further\ndemonstrate this empirically with three different encoding schemes.\nAdditionally, we demonstrate that PQCs with greater redundancy exhibit\nincreased robustness to random perturbations in their parameters at the\ncorresponding frequencies. We investigate how design choices affect the ability\nof PQCs to learn Fourier sums, focusing on parameter initialization scale and\nentanglement structure, finding large initializations and low-entanglement\nschemes tend to slow convergence.", "AI": {"tldr": "The paper explores spectral bias in quantum machine learning, showing how parameterized quantum circuits (PQCs) exhibit frequency-dependent convergence due to Fourier coefficient redundancy, influenced by data encoding schemes.", "motivation": "To understand spectral bias in PQCs and how it affects learning, particularly the role of Fourier coefficient redundancy and encoding schemes.", "method": "Analyzes PQCs as Fourier series, examines gradient magnitudes, tests three encoding schemes, and studies parameter initialization and entanglement effects.", "result": "Redundancy in Fourier coefficients correlates with gradient magnitudes; higher redundancy increases robustness. Large initializations and low-entanglement slow convergence.", "conclusion": "Spectral bias in PQCs is tied to Fourier coefficient redundancy, with encoding schemes and design choices significantly impacting learning efficiency and robustness."}}
{"id": "2506.23478", "pdf": "https://arxiv.org/pdf/2506.23478", "abs": "https://arxiv.org/abs/2506.23478", "authors": ["Pedro Alonso", "Tianrui Li", "Chongshou Li"], "title": "GeoCD: A Differential Local Approximation for Geodesic Chamfer Distance", "categories": ["cs.CV"], "comment": null, "summary": "Chamfer Distance (CD) is a widely adopted metric in 3D point cloud learning\ndue to its simplicity and efficiency. However, it suffers from a fundamental\nlimitation: it relies solely on Euclidean distances, which often fail to\ncapture the intrinsic geometry of 3D shapes. To address this limitation, we\npropose GeoCD, a topology-aware and fully differentiable approximation of\ngeodesic distance designed to serve as a metric for 3D point cloud learning.\nOur experiments show that GeoCD consistently improves reconstruction quality\nover standard CD across various architectures and datasets. We demonstrate this\nby fine-tuning several models, initially trained with standard CD, using GeoCD.\nRemarkably, fine-tuning for a single epoch with GeoCD yields significant gains\nacross multiple evaluation metrics.", "AI": {"tldr": "GeoCD improves 3D point cloud reconstruction by using geodesic distance instead of Euclidean distance, outperforming Chamfer Distance (CD) with minimal fine-tuning.", "motivation": "Chamfer Distance (CD) is limited by its reliance on Euclidean distances, which fail to capture intrinsic 3D shape geometry.", "method": "Proposed GeoCD, a topology-aware and differentiable geodesic distance metric, and fine-tuned models trained with CD using GeoCD.", "result": "GeoCD consistently enhances reconstruction quality, with significant gains achieved after just one epoch of fine-tuning.", "conclusion": "GeoCD is a superior metric for 3D point cloud learning, addressing CD's limitations and improving performance efficiently."}}
{"id": "2502.04397", "pdf": "https://arxiv.org/pdf/2502.04397", "abs": "https://arxiv.org/abs/2502.04397", "authors": ["Xiaorui Su", "Shvat Messica", "Yepeng Huang", "Ruth Johnson", "Lukas Fesser", "Shanghua Gao", "Faryad Sahneh", "Marinka Zitnik"], "title": "Multimodal Medical Code Tokenizer", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ICML'25", "summary": "Foundation models trained on patient electronic health records (EHRs) require\ntokenizing medical data into sequences of discrete vocabulary items. Existing\ntokenizers treat medical codes from EHRs as isolated textual tokens. However,\neach medical code is defined by its textual description, its position in\nontological hierarchies, and its relationships to other codes, such as disease\nco-occurrences and drug-treatment associations. Medical vocabularies contain\nmore than 600,000 codes with critical information for clinical reasoning. We\nintroduce MedTok, a multimodal medical code tokenizer that uses the text\ndescriptions and relational context of codes. MedTok processes text using a\nlanguage model encoder and encodes the relational structure with a graph\nencoder. It then quantizes both modalities into a unified token space,\npreserving modality-specific and cross-modality information. We integrate\nMedTok into five EHR models and evaluate it on operational and clinical tasks\nacross in-patient and out-patient datasets, including outcome prediction,\ndiagnosis classification, drug recommendation, and risk stratification.\nSwapping standard EHR tokenizers with MedTok improves AUPRC across all EHR\nmodels, by 4.10% on MIMIC-III, 4.78% on MIMIC-IV, and 11.32% on EHRShot, with\nthe largest gains in drug recommendation. Beyond EHR modeling, we demonstrate\nusing MedTok tokenizer with medical QA systems. Our results demonstrate the\npotential of MedTok as a unified tokenizer for medical codes, improving\ntokenization for medical foundation models.", "AI": {"tldr": "MedTok is a multimodal medical code tokenizer that improves EHR model performance by leveraging textual descriptions and relational context of medical codes.", "motivation": "Existing tokenizers treat medical codes as isolated tokens, ignoring their textual descriptions, hierarchical positions, and relational context, which are critical for clinical reasoning.", "method": "MedTok processes text descriptions with a language model encoder and relational structure with a graph encoder, quantizing both into a unified token space.", "result": "MedTok improves AUPRC across EHR models (4.10% on MIMIC-III, 4.78% on MIMIC-IV, 11.32% on EHRShot), with the largest gains in drug recommendation.", "conclusion": "MedTok demonstrates potential as a unified tokenizer for medical codes, enhancing tokenization for medical foundation models and medical QA systems."}}
{"id": "2506.23762", "pdf": "https://arxiv.org/pdf/2506.23762", "abs": "https://arxiv.org/abs/2506.23762", "authors": ["Hongzhou Rao", "Yanjie Zhao", "Xinyi Hou", "Shenao Wang", "Haoyu Wang"], "title": "Software Engineering for Large Language Models: Research Status, Challenges and the Road Ahead", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The rapid advancement of large language models (LLMs) has redefined\nartificial intelligence (AI), pushing the boundaries of AI research and\nenabling unbounded possibilities for both academia and the industry. However,\nLLM development faces increasingly complex challenges throughout its lifecycle,\nyet no existing research systematically explores these challenges and solutions\nfrom the perspective of software engineering (SE) approaches. To fill the gap,\nwe systematically analyze research status throughout the LLM development\nlifecycle, divided into six phases: requirements engineering, dataset\nconstruction, model development and enhancement, testing and evaluation,\ndeployment and operations, and maintenance and evolution. We then conclude by\nidentifying the key challenges for each phase and presenting potential research\ndirections to address these challenges. In general, we provide valuable\ninsights from an SE perspective to facilitate future advances in LLM\ndevelopment.", "AI": {"tldr": "The paper systematically analyzes challenges in LLM development from a software engineering perspective, covering six lifecycle phases and proposing research directions.", "motivation": "To address the lack of systematic exploration of LLM development challenges using software engineering approaches.", "method": "Analyzes LLM development lifecycle in six phases: requirements engineering, dataset construction, model development, testing, deployment, and maintenance.", "result": "Identifies key challenges for each phase and suggests potential research directions.", "conclusion": "Provides SE insights to advance LLM development."}}
{"id": "2506.22557", "pdf": "https://arxiv.org/pdf/2506.22557", "abs": "https://arxiv.org/abs/2506.22557", "authors": ["Boyuan Chen", "Minghao Shao", "Abdul Basit", "Siddharth Garg", "Muhammad Shafique"], "title": "MetaCipher: A General and Extensible Reinforcement Learning Framework for Obfuscation-Based Jailbreak Attacks on Black-Box LLMs", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "The growing capabilities of large language models (LLMs) have exposed them to\nincreasingly sophisticated jailbreak attacks. Among these, obfuscation-based\nattacks -- which encrypt malicious content to evade detection -- remain highly\neffective. By leveraging the reasoning ability of advanced LLMs to interpret\nencrypted prompts, such attacks circumvent conventional defenses that rely on\nkeyword detection or context filtering. These methods are very difficult to\ndefend against, as existing safety mechanisms are not designed to interpret or\ndecode ciphered content. In this work, we propose \\textbf{MetaCipher}, a novel\nobfuscation-based jailbreak framework, along with a reinforcement\nlearning-based dynamic cipher selection mechanism that adaptively chooses\noptimal encryption strategies from a cipher pool. This approach enhances\njailbreak effectiveness and generalizability across diverse task types, victim\nLLMs, and safety guardrails. Our framework is modular and extensible by design,\nsupporting arbitrary cipher families and accommodating evolving adversarial\nstrategies. We complement our method with a large-scale empirical analysis of\ncipher performance across multiple victim LLMs. Within as few as 10 queries,\nMetaCipher achieves over 92\\% attack success rate (ASR) on most recent standard\nmalicious prompt benchmarks against state-of-the-art non-reasoning LLMs, and\nover 74\\% ASR against reasoning-capable LLMs, outperforming all existing\nobfuscation-based jailbreak methods. These results highlight the long-term\nrobustness and adaptability of our approach, making it more resilient than\nprior methods in the face of advancing safety measures.", "AI": {"tldr": "MetaCipher is a novel obfuscation-based jailbreak framework for LLMs, using reinforcement learning to dynamically select encryption strategies, achieving high attack success rates.", "motivation": "Existing safety mechanisms fail to detect obfuscated malicious content, necessitating a robust and adaptable jailbreak method.", "method": "Proposes MetaCipher with a reinforcement learning-based dynamic cipher selection mechanism to adaptively choose encryption strategies.", "result": "Achieves over 92% ASR on non-reasoning LLMs and 74% ASR on reasoning-capable LLMs, outperforming existing methods.", "conclusion": "MetaCipher is highly effective, adaptable, and resilient against advancing safety measures."}}
{"id": "2506.23479", "pdf": "https://arxiv.org/pdf/2506.23479", "abs": "https://arxiv.org/abs/2506.23479", "authors": ["Zhaojie Zeng", "Yuesong Wang", "Chao Yang", "Tao Guan", "Lili Ju"], "title": "Instant GaussianImage: A Generalizable and Self-Adaptive Image Representation via 2D Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "Implicit Neural Representation (INR) has demonstrated remarkable advances in\nthe field of image representation but demands substantial GPU resources.\nGaussianImage recently pioneered the use of Gaussian Splatting to mitigate this\ncost, however, the slow training process limits its practicality, and the fixed\nnumber of Gaussians per image limits its adaptability to varying information\nentropy. To address these issues, we propose in this paper a generalizable and\nself-adaptive image representation framework based on 2D Gaussian Splatting.\nOur method employs a network to quickly generate a coarse Gaussian\nrepresentation, followed by minimal fine-tuning steps, achieving comparable\nrendering quality of GaussianImage while significantly reducing training time.\nMoreover, our approach dynamically adjusts the number of Gaussian points based\non image complexity to further enhance flexibility and efficiency in practice.\nExperiments on DIV2K and Kodak datasets show that our method matches or exceeds\nGaussianImage's rendering performance with far fewer iterations and shorter\ntraining times. Specifically, our method reduces the training time by up to one\norder of magnitude while achieving superior rendering performance with the same\nnumber of Gaussians.", "AI": {"tldr": "A new framework using 2D Gaussian Splatting improves efficiency and adaptability in image representation, reducing training time significantly while maintaining quality.", "motivation": "Address the high GPU resource demands and slow training of Implicit Neural Representation (INR) and the limitations of GaussianImage's fixed Gaussian count.", "method": "Uses a network to generate a coarse Gaussian representation quickly, followed by minimal fine-tuning, and dynamically adjusts Gaussian points based on image complexity.", "result": "Achieves comparable or better rendering quality than GaussianImage with up to 10x faster training and adaptive Gaussian counts.", "conclusion": "The proposed framework offers a practical, efficient, and flexible solution for image representation, outperforming existing methods in speed and adaptability."}}
{"id": "2502.05489", "pdf": "https://arxiv.org/pdf/2502.05489", "abs": "https://arxiv.org/abs/2502.05489", "authors": ["Ala N. Tak", "Amin Banayeeanzade", "Anahita Bolourani", "Mina Kian", "Robin Jia", "Jonathan Gratch"], "title": "Mechanistic Interpretability of Emotion Inference in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 camera-ready version. First two authors contributed equally", "summary": "Large language models (LLMs) show promising capabilities in predicting human\nemotions from text. However, the mechanisms through which these models process\nemotional stimuli remain largely unexplored. Our study addresses this gap by\ninvestigating how autoregressive LLMs infer emotions, showing that emotion\nrepresentations are functionally localized to specific regions in the model.\nOur evaluation includes diverse model families and sizes and is supported by\nrobustness checks. We then show that the identified representations are\npsychologically plausible by drawing on cognitive appraisal theory, a\nwell-established psychological framework positing that emotions emerge from\nevaluations (appraisals) of environmental stimuli. By causally intervening on\nconstrued appraisal concepts, we steer the generation and show that the outputs\nalign with theoretical and intuitive expectations. This work highlights a novel\nway to causally intervene and precisely shape emotional text generation,\npotentially benefiting safety and alignment in sensitive affective domains.", "AI": {"tldr": "The paper explores how autoregressive LLMs process emotions, identifying localized emotion representations and validating them using cognitive appraisal theory. It demonstrates causal intervention to shape emotional text generation, with potential applications in safety and alignment.", "motivation": "To understand the mechanisms of how LLMs process emotional stimuli, which remains largely unexplored, and to validate these mechanisms using psychological theory.", "method": "Investigates emotion representations in autoregressive LLMs, evaluates diverse model families and sizes, and uses cognitive appraisal theory for validation. Causal interventions are applied to steer emotional text generation.", "result": "Identifies localized emotion representations in LLMs and shows they align with cognitive appraisal theory. Causal interventions successfully shape emotional outputs.", "conclusion": "The study provides a novel method to causally intervene in emotional text generation, offering potential benefits for safety and alignment in affective domains."}}
{"id": "2506.23771", "pdf": "https://arxiv.org/pdf/2506.23771", "abs": "https://arxiv.org/abs/2506.23771", "authors": ["Guizhe Jin", "Zhuoren Li", "Bo Leng", "Ran Yu", "Lu Xiong"], "title": "Multi-Timescale Hierarchical Reinforcement Learning for Unified Behavior and Control of Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": "8 pages, Submitted to IEEE Robotics and Automation Letters", "summary": "Reinforcement Learning (RL) is increasingly used in autonomous driving (AD)\nand shows clear advantages. However, most RL-based AD methods overlook policy\nstructure design. An RL policy that only outputs short-timescale vehicle\ncontrol commands results in fluctuating driving behavior due to fluctuations in\nnetwork outputs, while one that only outputs long-timescale driving goals\ncannot achieve unified optimality of driving behavior and control. Therefore,\nwe propose a multi-timescale hierarchical reinforcement learning approach. Our\napproach adopts a hierarchical policy structure, where high- and low-level RL\npolicies are unified-trained to produce long-timescale motion guidance and\nshort-timescale control commands, respectively. Therein, motion guidance is\nexplicitly represented by hybrid actions to capture multimodal driving\nbehaviors on structured road and support incremental low-level extend-state\nupdates. Additionally, a hierarchical safety mechanism is designed to ensure\nmulti-timescale safety. Evaluation in simulator-based and HighD dataset-based\nhighway multi-lane scenarios demonstrates that our approach significantly\nimproves AD performance, effectively increasing driving efficiency, action\nconsistency and safety.", "AI": {"tldr": "A multi-timescale hierarchical reinforcement learning approach for autonomous driving improves performance by unifying long-timescale motion guidance and short-timescale control commands, enhancing efficiency, consistency, and safety.", "motivation": "Current RL-based AD methods lack structured policy design, leading to fluctuating behavior or suboptimal control. A unified hierarchical approach is needed.", "method": "Proposes a hierarchical RL policy with high-level (long-timescale motion guidance) and low-level (short-timescale control) policies, using hybrid actions and a safety mechanism.", "result": "Significantly improves AD performance in simulator and HighD dataset scenarios, boosting efficiency, action consistency, and safety.", "conclusion": "The hierarchical approach effectively addresses policy structure limitations, enhancing autonomous driving performance."}}
{"id": "2506.22565", "pdf": "https://arxiv.org/pdf/2506.22565", "abs": "https://arxiv.org/abs/2506.22565", "authors": ["Guan-Horng Liu", "Jaemoo Choi", "Yongxin Chen", "Benjamin Kurt Miller", "Ricky T. Q. Chen"], "title": "Adjoint Schr\u00f6dinger Bridge Sampler", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": null, "summary": "Computational methods for learning to sample from the Boltzmann distribution\n-- where the target distribution is known only up to an unnormalized energy\nfunction -- have advanced significantly recently. Due to the lack of explicit\ntarget samples, however, prior diffusion-based methods, known as diffusion\nsamplers, often require importance-weighted estimation or complicated learning\nprocesses. Both trade off scalability with extensive evaluations of the energy\nand model, thereby limiting their practical usage. In this work, we propose\nAdjoint Schr\\\"odinger Bridge Sampler (ASBS), a new diffusion sampler that\nemploys simple and scalable matching-based objectives yet without the need to\nestimate target samples during training. ASBS is grounded on a mathematical\nmodel -- the Schr\\\"odinger Bridge -- which enhances sampling efficiency via\nkinetic-optimal transportation. Through a new lens of stochastic optimal\ncontrol theory, we demonstrate how SB-based diffusion samplers can be learned\nat scale via Adjoint Matching and prove convergence to the global solution.\nNotably, ASBS generalizes the recent Adjoint Sampling (Havens et al., 2025) to\narbitrary source distributions by relaxing the so-called memoryless condition\nthat largely restricts the design space. Through extensive experiments, we\ndemonstrate the effectiveness of ASBS on sampling from classical energy\nfunctions, amortized conformer generation, and molecular Boltzmann\ndistributions.", "AI": {"tldr": "The paper introduces ASBS, a scalable diffusion sampler for Boltzmann distributions, avoiding complex training processes and improving efficiency via kinetic-optimal transportation.", "motivation": "Prior diffusion samplers face scalability issues due to reliance on importance-weighted estimation or complex training. ASBS addresses this by simplifying objectives and avoiding target sample estimation.", "method": "ASBS uses Schr\u00f6dinger Bridge theory and stochastic optimal control to enable scalable learning via Adjoint Matching, relaxing restrictive conditions of prior methods.", "result": "ASBS outperforms in sampling from energy functions, conformer generation, and molecular Boltzmann distributions.", "conclusion": "ASBS offers a scalable, efficient alternative to existing diffusion samplers, with broad applicability in computational sampling tasks."}}
{"id": "2506.23482", "pdf": "https://arxiv.org/pdf/2506.23482", "abs": "https://arxiv.org/abs/2506.23482", "authors": ["Jun Huang", "Ting Liu", "Yihang Wu", "Xiaochao Qu", "Luoqi Liu", "Xiaolin Hu"], "title": "MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting", "categories": ["cs.CV"], "comment": "CVPR 2025", "summary": "Advancements in generative models have enabled image inpainting models to\ngenerate content within specific regions of an image based on provided prompts\nand masks. However, existing inpainting methods often suffer from problems such\nas semantic misalignment, structural distortion, and style inconsistency. In\nthis work, we present MTADiffusion, a Mask-Text Alignment diffusion model\ndesigned for object inpainting. To enhance the semantic capabilities of the\ninpainting model, we introduce MTAPipeline, an automatic solution for\nannotating masks with detailed descriptions. Based on the MTAPipeline, we\nconstruct a new MTADataset comprising 5 million images and 25 million mask-text\npairs. Furthermore, we propose a multi-task training strategy that integrates\nboth inpainting and edge prediction tasks to improve structural stability. To\npromote style consistency, we present a novel inpainting style-consistency loss\nusing a pre-trained VGG network and the Gram matrix. Comprehensive evaluations\non BrushBench and EditBench demonstrate that MTADiffusion achieves\nstate-of-the-art performance compared to other methods.", "AI": {"tldr": "MTADiffusion is a Mask-Text Alignment diffusion model for object inpainting, addressing issues like semantic misalignment and style inconsistency. It introduces MTAPipeline for mask annotation, a multi-task training strategy, and a style-consistency loss, achieving state-of-the-art results.", "motivation": "Existing inpainting methods suffer from semantic misalignment, structural distortion, and style inconsistency, prompting the need for a more robust solution.", "method": "MTADiffusion uses MTAPipeline for mask-text annotation, a multi-task training strategy combining inpainting and edge prediction, and a style-consistency loss with a VGG network and Gram matrix.", "result": "MTADiffusion outperforms other methods on BrushBench and EditBench, demonstrating superior performance.", "conclusion": "MTADiffusion effectively addresses key challenges in image inpainting, offering improved semantic alignment, structural stability, and style consistency."}}
{"id": "2502.05651", "pdf": "https://arxiv.org/pdf/2502.05651", "abs": "https://arxiv.org/abs/2502.05651", "authors": ["Hyunjong Kim", "Suyeon Lee", "Yeongjae Cho", "Eunseo Ryu", "Yohan Jo", "Suran Seong", "Sungzoon Cho"], "title": "KMI: A Dataset of Korean Motivational Interviewing Dialogues for Psychotherapy", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at NAACL 2025 Main Conference", "summary": "The increasing demand for mental health services has led to the rise of\nAI-driven mental health chatbots, though challenges related to privacy, data\ncollection, and expertise persist. Motivational Interviewing (MI) is gaining\nattention as a theoretical basis for boosting expertise in the development of\nthese chatbots. However, existing datasets are showing limitations for training\nchatbots, leading to a substantial demand for publicly available resources in\nthe field of MI and psychotherapy. These challenges are even more pronounced in\nnon-English languages, where they receive less attention. In this paper, we\npropose a novel framework that simulates MI sessions enriched with the\nexpertise of professional therapists. We train an MI forecaster model that\nmimics the behavioral choices of professional therapists and employ Large\nLanguage Models (LLMs) to generate utterances through prompt engineering. Then,\nwe present KMI, the first synthetic dataset theoretically grounded in MI,\ncontaining 1,000 high-quality Korean Motivational Interviewing dialogues.\nThrough an extensive expert evaluation of the generated dataset and the\ndialogue model trained on it, we demonstrate the quality, expertise, and\npracticality of KMI. We also introduce novel metrics derived from MI theory in\norder to evaluate dialogues from the perspective of MI.", "AI": {"tldr": "The paper proposes a framework for creating high-quality Korean Motivational Interviewing (MI) dialogues using AI, addressing dataset limitations and non-English language gaps.", "motivation": "The rise of AI-driven mental health chatbots faces challenges like privacy and expertise, especially in non-English languages. Existing datasets are insufficient for training MI-based chatbots.", "method": "A novel framework simulates MI sessions with therapist expertise, trains an MI forecaster model, and uses LLMs for utterance generation. The result is KMI, a synthetic Korean MI dataset.", "result": "KMI contains 1,000 high-quality Korean MI dialogues, validated through expert evaluation for quality, expertise, and practicality. Novel MI-based metrics are introduced for dialogue evaluation.", "conclusion": "The framework and KMI dataset advance AI-driven mental health chatbots by addressing dataset gaps and enhancing expertise, particularly for non-English languages."}}
{"id": "2506.23783", "pdf": "https://arxiv.org/pdf/2506.23783", "abs": "https://arxiv.org/abs/2506.23783", "authors": ["Shiao Wang", "Ju Huang", "Qingchuan Ma", "Jinfeng Gao", "Chunyi Xu", "Xiao Wang", "Lan Chen", "Bo Jiang"], "title": "Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Journal extension of Mamba-FETrack which was published on Pattern\n  Recognition and Computer Vision (PRCV) 2024", "summary": "Combining traditional RGB cameras with bio-inspired event cameras for robust\nobject tracking has garnered increasing attention in recent years. However,\nmost existing multimodal tracking algorithms depend heavily on high-complexity\nVision Transformer architectures for feature extraction and fusion across\nmodalities. This not only leads to substantial computational overhead but also\nlimits the effectiveness of cross-modal interactions. In this paper, we propose\nan efficient RGB-Event object tracking framework based on the linear-complexity\nVision Mamba network, termed Mamba-FETrack V2. Specifically, we first design a\nlightweight Prompt Generator that utilizes embedded features from each\nmodality, together with a shared prompt pool, to dynamically generate\nmodality-specific learnable prompt vectors. These prompts, along with the\nmodality-specific embedded features, are then fed into a Vision Mamba-based\nFEMamba backbone, which facilitates prompt-guided feature extraction,\ncross-modal interaction, and fusion in a unified manner. Finally, the fused\nrepresentations are passed to the tracking head for accurate target\nlocalization. Extensive experimental evaluations on multiple RGB-Event tracking\nbenchmarks, including short-term COESOT dataset and long-term datasets, i.e.,\nFE108 and FELT V2, demonstrate the superior performance and efficiency of the\nproposed tracking framework. The source code and pre-trained models will be\nreleased on https://github.com/Event-AHU/Mamba_FETrack", "AI": {"tldr": "Proposes Mamba-FETrack V2, an efficient RGB-Event object tracking framework using Vision Mamba for low-complexity feature extraction and fusion.", "motivation": "Existing multimodal tracking algorithms rely on high-complexity Vision Transformers, causing computational overhead and limiting cross-modal interactions.", "method": "Uses a lightweight Prompt Generator and Vision Mamba-based FEMamba backbone for prompt-guided feature extraction and fusion.", "result": "Demonstrates superior performance and efficiency on RGB-Event tracking benchmarks like COESOT, FE108, and FELT V2.", "conclusion": "The framework offers an efficient solution for RGB-Event tracking with promising results."}}
{"id": "2506.22606", "pdf": "https://arxiv.org/pdf/2506.22606", "abs": "https://arxiv.org/abs/2506.22606", "authors": ["Osama Zafar", "Mina Namazi", "Yuqiao Xu", "Youngjin Yoo", "Erman Ayday"], "title": "A User-Centric, Privacy-Preserving, and Verifiable Ecosystem for Personal Data Management and Utilization", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "In the current paradigm of digital personalized services, the centralized\nmanagement of personal data raises significant privacy concerns, security\nvulnerabilities, and diminished individual autonomy over sensitive information.\nDespite their efficiency, traditional centralized architectures frequently fail\nto satisfy rigorous privacy requirements and expose users to data breaches and\nunauthorized access risks. This pressing challenge calls for a fundamental\nparadigm shift in methodologies for collecting, storing, and utilizing personal\ndata across diverse sectors, including education, healthcare, and finance.\n  This paper introduces a novel decentralized, privacy-preserving architecture\nthat handles heterogeneous personal information, ranging from educational\ncredentials to health records and financial data. Unlike traditional models,\nour system grants users complete data ownership and control, allowing them to\nselectively share information without compromising privacy. The architecture's\nfoundation comprises advanced privacy-enhancing technologies, including secure\nenclaves and federated learning, enabling secure computation, verification, and\ndata sharing. The system supports diverse functionalities, including local\ncomputation, model training, and privacy-preserving data sharing, while\nensuring data credibility and robust user privacy.", "AI": {"tldr": "A decentralized, privacy-preserving architecture is proposed to address privacy and security issues in centralized personal data management, using advanced technologies like secure enclaves and federated learning.", "motivation": "Centralized data management poses privacy risks and lacks user control, necessitating a shift to decentralized solutions for sectors like education, healthcare, and finance.", "method": "The paper introduces a decentralized system with secure enclaves and federated learning, enabling user-controlled data sharing and secure computation.", "result": "The architecture ensures data credibility, robust privacy, and supports functionalities like local computation and privacy-preserving sharing.", "conclusion": "The proposed system offers a viable solution for secure, user-controlled personal data management across diverse sectors."}}
{"id": "2506.23502", "pdf": "https://arxiv.org/pdf/2506.23502", "abs": "https://arxiv.org/abs/2506.23502", "authors": ["Mengxiao Tian", "Xinxiao Wu", "Shuo Yang"], "title": "LLM-enhanced Action-aware Multi-modal Prompt Tuning for Image-Text Matching", "categories": ["cs.CV"], "comment": "accepted by ICCV 2025", "summary": "Driven by large-scale contrastive vision-language pre-trained models such as\nCLIP, recent advancements in the image-text matching task have achieved\nremarkable success in representation learning. Due to image-level\nvisual-language alignment, CLIP falls short in understanding fine-grained\ndetails such as object attributes and spatial relationships between objects.\nRecent efforts have attempted to compel CLIP to acquire structured visual\nrepresentations by introducing prompt learning to achieve object-level\nalignment. While achieving promising results, they still lack the capability to\nperceive actions, which are crucial for describing the states or relationships\nbetween objects. Therefore, we propose to endow CLIP with fine-grained\naction-level understanding by introducing an LLM-enhanced action-aware\nmulti-modal prompt-tuning method, incorporating the action-related external\nknowledge generated by large language models (LLMs). Specifically, we design an\naction triplet prompt and an action state prompt to exploit compositional\nsemantic knowledge and state-related causal knowledge implicitly stored in\nLLMs. Subsequently, we propose an adaptive interaction module to aggregate\nattentive visual features conditioned on action-aware prompted knowledge for\nestablishing discriminative and action-aware visual representations, which\nfurther improves the performance. Comprehensive experimental results on two\nbenchmark datasets demonstrate the effectiveness of our method.", "AI": {"tldr": "The paper introduces an LLM-enhanced action-aware multi-modal prompt-tuning method to improve CLIP's fine-grained action-level understanding in image-text matching.", "motivation": "CLIP lacks fine-grained understanding of object attributes, spatial relationships, and actions. Recent methods focus on object-level alignment but miss action perception, which is crucial for describing object states or relationships.", "method": "The proposed method uses LLM-generated action-related knowledge to design action triplet and action state prompts. An adaptive interaction module aggregates visual features based on action-aware prompts for better representations.", "result": "Experiments on benchmark datasets show the method's effectiveness in improving performance.", "conclusion": "The approach successfully enhances CLIP's action-level understanding, addressing a critical gap in fine-grained visual-language alignment."}}
{"id": "2502.07004", "pdf": "https://arxiv.org/pdf/2502.07004", "abs": "https://arxiv.org/abs/2502.07004", "authors": ["Haoqi Wang", "Tong Zhang", "Mathieu Salzmann"], "title": "Demystifying Singular Defects in Large Language Models", "categories": ["cs.CL"], "comment": "ICML 2025", "summary": "Large transformer models are known to produce high-norm tokens. In vision\ntransformers (ViTs), such tokens have been mathematically modeled through the\nsingular vectors of the linear approximations of layers. However, in large\nlanguage models (LLMs), the underlying causes of high-norm tokens remain\nlargely unexplored, and their different properties from those of ViTs require a\nnew analysis framework. In this paper, we provide both theoretical insights and\nempirical validation across a range of recent models, leading to the following\nobservations: i) The layer-wise singular direction predicts the abrupt\nexplosion of token norms in LLMs. ii) The negative eigenvalues of a layer\nexplain its sudden decay. iii) The computational pathways leading to high-norm\ntokens differ between initial and noninitial tokens. iv) High-norm tokens are\ntriggered by the right leading singular vector of the matrix approximating the\ncorresponding modules. We showcase two practical applications of these\nfindings: the improvement of quantization schemes and the design of LLM\nsignatures. Our findings not only advance the understanding of singular defects\nin LLMs but also open new avenues for their application. We expect that this\nwork will stimulate further research into the internal mechanisms of LLMs. Code\nis released at https://github.com/haoqiwang/singular_defect.", "AI": {"tldr": "The paper explores high-norm tokens in LLMs, identifying their causes and properties, and proposes practical applications like improved quantization and LLM signatures.", "motivation": "High-norm tokens in LLMs are not well understood, unlike in ViTs, necessitating a new analysis framework.", "method": "Theoretical insights and empirical validation across recent models, focusing on layer-wise singular directions, eigenvalues, and computational pathways.", "result": "Key findings include the role of singular directions in norm explosions, negative eigenvalues in decay, and distinct pathways for initial vs. noninitial tokens.", "conclusion": "The study advances understanding of singular defects in LLMs and suggests practical applications, encouraging further research into LLM mechanisms."}}
{"id": "2506.23815", "pdf": "https://arxiv.org/pdf/2506.23815", "abs": "https://arxiv.org/abs/2506.23815", "authors": ["Patrick Stokkink"], "title": "The Impact of AI on Educational Assessment: A Framework for Constructive Alignment", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "The influence of Artificial Intelligence (AI), and specifically Large\nLanguage Models (LLM), on education is continuously increasing. These models\nare frequently used by students, giving rise to the question whether current\nforms of assessment are still a valid way to evaluate student performance and\ncomprehension. The theoretical framework developed in this paper is grounded in\nConstructive Alignment (CA) theory and Bloom's taxonomy for defining learning\nobjectives. We argue that AI influences learning objectives of different Bloom\nlevels in a different way, and assessment has to be adopted accordingly.\nFurthermore, in line with Bloom's vision, formative and summative assessment\nshould be aligned on whether the use of AI is permitted or not.\n  Although lecturers tend to agree that education and assessment need to be\nadapted to the presence of AI, a strong bias exists on the extent to which\nlecturers want to allow for AI in assessment. This bias is caused by a\nlecturer's familiarity with AI and specifically whether they use it themselves.\nTo avoid this bias, we propose structured guidelines on a university or faculty\nlevel, to foster alignment among the staff. Besides that, we argue that\nteaching staff should be trained on the capabilities and limitations of AI\ntools. In this way, they are better able to adapt their assessment methods.", "AI": {"tldr": "The paper discusses how AI, especially LLMs, impacts education and assessment, proposing alignment with learning objectives and structured guidelines to address lecturer bias.", "motivation": "The increasing use of AI by students raises concerns about the validity of current assessment methods and the need for adaptation.", "method": "The study uses Constructive Alignment theory and Bloom's taxonomy to analyze AI's impact on learning objectives and suggests aligning formative and summative assessments with AI use.", "result": "Lecturers show bias in allowing AI in assessments based on their familiarity with it. The paper proposes structured guidelines and staff training to mitigate this.", "conclusion": "Education and assessment must adapt to AI's presence, requiring alignment, guidelines, and training to ensure fair and effective evaluation."}}
{"id": "2506.22607", "pdf": "https://arxiv.org/pdf/2506.22607", "abs": "https://arxiv.org/abs/2506.22607", "authors": ["Daniel Ciganda", "Ignacio Camp\u00f3n", "I\u00f1aki Permanyer", "Jakob H Macke"], "title": "Learning Individual Reproductive Behavior from Aggregate Fertility Rates via Neural Posterior Estimation", "categories": ["stat.AP", "cs.LG"], "comment": null, "summary": "While age-specific fertility rates (ASFRs) provide the most extensive record\nof reproductive change, their aggregate nature masks the underlying behavioral\nmechanisms that ultimately drive fertility trends. To recover these mechanisms,\nwe develop a likelihood-free Bayesian framework that couples an\nindividual-level model of the reproductive process with Sequential Neural\nPosterior Estimation (SNPE). This allows us to infer eight behavioral and\nbiological parameters from just two aggregate series: ASFRs and the age-profile\nof planned versus unplanned births. Applied to U.S. National Survey of Family\nGrowth cohorts and to Demographic and Health Survey cohorts from Colombia, the\nDominican Republic, and Peru, the method reproduces observed fertility\nschedules and, critically, predicts out-of-sample micro-level distributions of\nage at first sex, inter-birth intervals, and family-size ideals, none of which\ninform the estimation step. Because the fitted model yields complete synthetic\nlife histories, it enables behaviorally explicit population forecasts and\nsupports the construction of demographic digital twins.", "AI": {"tldr": "A Bayesian framework using SNPE infers behavioral and biological parameters from aggregate fertility data, predicting micro-level reproductive behaviors and enabling synthetic life histories for population forecasts.", "motivation": "To uncover the behavioral mechanisms behind fertility trends masked by aggregate age-specific fertility rates (ASFRs).", "method": "Develops a likelihood-free Bayesian framework combining an individual-level reproductive model with Sequential Neural Posterior Estimation (SNPE) to infer parameters from ASFRs and planned/unplanned birth profiles.", "result": "Successfully reproduces fertility schedules and predicts micro-level behaviors (e.g., age at first sex, inter-birth intervals) without direct data input. Enables synthetic life histories for forecasting.", "conclusion": "The method provides behaviorally explicit fertility insights and supports advanced demographic modeling like digital twins."}}
{"id": "2506.23505", "pdf": "https://arxiv.org/pdf/2506.23505", "abs": "https://arxiv.org/abs/2506.23505", "authors": ["Tinh Nguyen"], "title": "Improve Underwater Object Detection through YOLOv12 Architecture and Physics-informed Augmentation", "categories": ["cs.CV"], "comment": null, "summary": "Underwater object detection is crucial for autonomous navigation,\nenvironmental monitoring, and marine exploration, but it is severely hampered\nby light attenuation, turbidity, and occlusion. Current methods balance\naccuracy and computational efficiency, but they have trouble deploying in\nreal-time under low visibility conditions. Through the integration of\nphysics-informed augmentation techniques with the YOLOv12 architecture, this\nstudy advances underwater detection. With Residual ELAN blocks to preserve\nstructural features in turbid waters and Area Attention to maintain large\nreceptive fields for occluded objects while reducing computational complexity.\nUnderwater optical properties are addressed by domain-specific augmentations\nsuch as turbulence adaptive blurring, biologically grounded occlusion\nsimulation, and spectral HSV transformations for color distortion. Extensive\ntests on four difficult datasets show state-of-the-art performance, with\nBrackish data registering 98.30% mAP at 142 FPS. YOLOv12 improves occlusion\nrobustness by 18.9%, small-object recall by 22.4%, and detection precision by\nup to 7.94% compared to previous models. The crucial role of augmentation\nstrategy is validated by ablation studies. This work offers a precise and\neffective solution for conservation and underwater robotics applications.", "AI": {"tldr": "YOLOv12 with physics-informed augmentation improves underwater object detection, achieving high accuracy (98.30% mAP) and speed (142 FPS), while enhancing occlusion robustness and small-object recall.", "motivation": "Underwater object detection faces challenges like light attenuation, turbidity, and occlusion, limiting real-time deployment in low visibility.", "method": "Integrates physics-informed augmentation (turbulence blurring, occlusion simulation, spectral HSV) with YOLOv12, using Residual ELAN blocks and Area Attention.", "result": "Achieves 98.30% mAP at 142 FPS, improves occlusion robustness by 18.9%, small-object recall by 22.4%, and detection precision by 7.94%.", "conclusion": "The method provides a precise, efficient solution for underwater robotics and conservation, validated by ablation studies."}}
{"id": "2502.10341", "pdf": "https://arxiv.org/pdf/2502.10341", "abs": "https://arxiv.org/abs/2502.10341", "authors": ["Alexander Wettig", "Kyle Lo", "Sewon Min", "Hannaneh Hajishirzi", "Danqi Chen", "Luca Soldaini"], "title": "Organize the Web: Constructing Domains Enhances Pre-Training Data Curation", "categories": ["cs.CL"], "comment": "Accepted at ICML 2025. Project page: https://weborganizer.allen.ai", "summary": "Modern language models are trained on large, unstructured datasets consisting\nof trillions of tokens and obtained by crawling the web. The unstructured\nnature makes it difficult to reason about their contents and develop systematic\napproaches to data curation. In this paper, we unpack monolithic web corpora by\ndeveloping taxonomies of their contents and organizing them into domains. We\nintroduce WebOrganizer, a framework for organizing web pages in terms of both\ntheir topic and format. Using these two complementary notions of domains, we\nautomatically annotate pre-training data by distilling annotations from a large\nlanguage model into efficient classifiers. This allows us to study how data\nfrom different domains should be mixed to improve models on downstream tasks,\nand we show that we can combine insights about effective topics and formats to\nfurther boost performance. We demonstrate that our domain mixing also improves\nexisting methods that select data based on quality. Furthermore, we study and\ncompare how quality-based methods will implicitly change the domain mixture.\nOverall, our work demonstrates that constructing and mixing domains provides a\nvaluable complement to quality-based data curation methods, opening new avenues\nfor effective and insightful pre-training data curation.", "AI": {"tldr": "The paper introduces WebOrganizer, a framework to organize web corpora into domains by topic and format, improving data curation for language models.", "motivation": "Large, unstructured web datasets make data curation challenging; the paper aims to systematically organize and analyze these datasets.", "method": "Develops taxonomies for web content, uses a language model to annotate data, and studies domain mixing for better downstream task performance.", "result": "Domain mixing boosts model performance and complements quality-based data selection methods.", "conclusion": "Organizing and mixing domains enhances data curation, offering new insights for effective pre-training."}}
{"id": "2506.23826", "pdf": "https://arxiv.org/pdf/2506.23826", "abs": "https://arxiv.org/abs/2506.23826", "authors": ["Llu\u00eds C. Coll", "Martin W. Lauer-Schmaltz", "Philip Cash", "John P. Hansen", "Anja Maier"], "title": "Towards the \"Digital Me\": A vision of authentic Conversational Agents powered by personal Human Digital Twins", "categories": ["cs.ET", "cs.AI", "cs.CY", "cs.HC", "cs.IR"], "comment": "24 pages, 9 figures", "summary": "Human Digital Twins (HDTs) have traditionally been conceptualized as\ndata-driven models designed to support decision-making across various domains.\nHowever, recent advancements in conversational AI open new possibilities for\nHDTs to function as authentic, interactive digital counterparts of individuals.\nThis paper introduces a novel HDT system architecture that integrates large\nlanguage models with dynamically updated personal data, enabling it to mirror\nan individual's conversational style, memories, and behaviors. To achieve this,\nour approach implements context-aware memory retrieval, neural\nplasticity-inspired consolidation, and adaptive learning mechanisms, creating a\nmore natural and evolving digital persona. The resulting system does not only\nreplicate an individual's unique conversational style depending on who they are\nspeaking with, but also enriches responses with dynamically captured personal\nexperiences, opinions, and memories. While this marks a significant step toward\ndeveloping authentic virtual counterparts, it also raises critical ethical\nconcerns regarding privacy, accountability, and the long-term implications of\npersistent digital identities. This study contributes to the field of HDTs by\ndescribing our novel system architecture, demonstrating its capabilities, and\ndiscussing future directions and emerging challenges to ensure the responsible\nand ethical development of HDTs.", "AI": {"tldr": "The paper introduces a novel Human Digital Twin (HDT) system integrating large language models and personal data to create interactive, evolving digital counterparts, while addressing ethical concerns.", "motivation": "To advance HDTs by leveraging conversational AI for authentic, interactive digital personas that mirror individuals' styles, memories, and behaviors.", "method": "The approach uses context-aware memory retrieval, neural plasticity-inspired consolidation, and adaptive learning to create a dynamic digital persona.", "result": "The system replicates conversational styles and enriches responses with personal experiences, but raises ethical concerns about privacy and accountability.", "conclusion": "The study advances HDTs with a novel architecture, demonstrates capabilities, and highlights ethical challenges for responsible development."}}
{"id": "2506.22611", "pdf": "https://arxiv.org/pdf/2506.22611", "abs": "https://arxiv.org/abs/2506.22611", "authors": ["Yuming Ma"], "title": "Deep Hedging to Manage Tail Risk", "categories": ["q-fin.PM", "cs.LG", "math.OC", "q-fin.CP", "q-fin.RM", "91G70 91G20 91G60"], "comment": "59 pages", "summary": "Extending Buehler et al.'s 2019 Deep Hedging paradigm, we innovatively employ\ndeep neural networks to parameterize convex-risk minimization (CVaR/ES) for the\nportfolio tail-risk hedging problem. Through comprehensive numerical\nexperiments on crisis-era bootstrap market simulators -- customizable with\ntransaction costs, risk budgets, liquidity constraints, and market impact --\nour end-to-end framework not only achieves significant one-day 99% CVaR\nreduction but also yields practical insights into friction-aware strategy\nadaptation, demonstrating robustness and operational viability in realistic\nmarkets.", "AI": {"tldr": "The paper extends Deep Hedging using deep neural networks for CVaR minimization in portfolio tail-risk hedging, showing effectiveness in realistic market simulations.", "motivation": "To improve tail-risk hedging in portfolios by leveraging deep neural networks for convex-risk minimization, addressing practical market constraints.", "method": "Deep neural networks parameterize CVaR/ES for hedging, tested on customizable crisis-era market simulators with real-world constraints.", "result": "Achieves significant 99% CVaR reduction and provides insights into friction-aware strategy adaptation, proving robustness in realistic markets.", "conclusion": "The framework is effective and operationally viable for tail-risk hedging in practical, constrained market environments."}}
{"id": "2506.23513", "pdf": "https://arxiv.org/pdf/2506.23513", "abs": "https://arxiv.org/abs/2506.23513", "authors": ["Zixun Fang", "Kai Zhu", "Zhiheng Liu", "Yu Liu", "Wei Zhai", "Yang Cao", "Zheng-Jun Zha"], "title": "ViewPoint: Panoramic Video Generation with Pretrained Diffusion Models", "categories": ["cs.CV"], "comment": "https://becauseimbatman0.github.io/ViewPoint", "summary": "Panoramic video generation aims to synthesize 360-degree immersive videos,\nholding significant importance in the fields of VR, world models, and spatial\nintelligence. Existing works fail to synthesize high-quality panoramic videos\ndue to the inherent modality gap between panoramic data and perspective data,\nwhich constitutes the majority of the training data for modern diffusion\nmodels. In this paper, we propose a novel framework utilizing pretrained\nperspective video models for generating panoramic videos. Specifically, we\ndesign a novel panorama representation named ViewPoint map, which possesses\nglobal spatial continuity and fine-grained visual details simultaneously. With\nour proposed Pano-Perspective attention mechanism, the model benefits from\npretrained perspective priors and captures the panoramic spatial correlations\nof the ViewPoint map effectively. Extensive experiments demonstrate that our\nmethod can synthesize highly dynamic and spatially consistent panoramic videos,\nachieving state-of-the-art performance and surpassing previous methods.", "AI": {"tldr": "A novel framework for generating high-quality panoramic videos using pretrained perspective video models, addressing the modality gap between panoramic and perspective data.", "motivation": "Existing methods struggle with panoramic video synthesis due to the disparity between panoramic and perspective data, limiting quality.", "method": "Proposes a ViewPoint map for panorama representation and a Pano-Perspective attention mechanism to leverage pretrained perspective priors.", "result": "Achieves state-of-the-art performance, producing dynamic and spatially consistent panoramic videos.", "conclusion": "The framework effectively bridges the modality gap, enabling superior panoramic video generation."}}
{"id": "2502.16825", "pdf": "https://arxiv.org/pdf/2502.16825", "abs": "https://arxiv.org/abs/2502.16825", "authors": ["Yao Xiao", "Hai Ye", "Linyao Chen", "Hwee Tou Ng", "Lidong Bing", "Xiaoli Li", "Roy Ka-wei Lee"], "title": "Finding the Sweet Spot: Preference Data Construction for Scaling Preference Optimization", "categories": ["cs.CL"], "comment": "ACL25 Main", "summary": "Iterative data generation and model retraining are widely used to align large\nlanguage models (LLMs). It typically involves a policy model to generate\non-policy responses and a reward model to guide training data selection. Direct\nPreference Optimization (DPO) further enhances this process by constructing\npreference pairs of chosen and rejected responses. In this work, we aim to\n\\emph{scale up} the number of on-policy samples via repeated random sampling to\nimprove alignment performance. Conventional practice selects the sample with\nthe highest reward as chosen and the lowest as rejected for DPO. However, our\nexperiments reveal that this strategy leads to a \\emph{decline} in performance\nas the sample size increases. To address this, we investigate preference data\nconstruction through the lens of underlying normal distribution of sample\nrewards. We categorize the reward space into seven representative points and\nsystematically explore all 21 ($C_7^2$) pairwise combinations. Through\nevaluations on four models using AlpacaEval 2, we find that selecting the\nrejected response at reward position $\\mu - 2\\sigma$ rather than the minimum\nreward, is crucial for optimal performance. We finally introduce a scalable\npreference data construction strategy that consistently enhances model\nperformance as the sample scale increases.", "AI": {"tldr": "Scaling up on-policy samples via repeated random sampling improves LLM alignment, but conventional DPO strategies decline in performance with larger samples. A new strategy, categorizing rewards into seven points and selecting rejected responses at \u03bc\u22122\u03c3, enhances performance consistently.", "motivation": "To address the performance decline in conventional DPO strategies when scaling up on-policy samples, the paper investigates reward distribution and proposes a more effective preference data construction method.", "method": "The study categorizes reward space into seven points, explores all 21 pairwise combinations, and evaluates performance using AlpacaEval 2 on four models.", "result": "Selecting rejected responses at \u03bc\u22122\u03c3 instead of the minimum reward leads to optimal performance, and the proposed scalable strategy consistently improves model performance.", "conclusion": "The paper introduces a scalable preference data construction strategy that enhances alignment performance as sample size increases, validated by empirical results."}}
{"id": "2506.23855", "pdf": "https://arxiv.org/pdf/2506.23855", "abs": "https://arxiv.org/abs/2506.23855", "authors": ["Travis Dick", "Alessandro Epasto", "Adel Javanmard", "Josh Karlin", "Andres Munoz Medina", "Vahab Mirrokni", "Sergei Vassilvitskii", "Peilin Zhong"], "title": "Differentially Private Synthetic Data Release for Topics API Outputs", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "20 pages, 8 figures", "summary": "The analysis of the privacy properties of Privacy-Preserving Ads APIs is an\narea of research that has received strong interest from academics, industry,\nand regulators. Despite this interest, the empirical study of these methods is\nhindered by the lack of publicly available data. Reliable empirical analysis of\nthe privacy properties of an API, in fact, requires access to a dataset\nconsisting of realistic API outputs; however, privacy concerns prevent the\ngeneral release of such data to the public.\n  In this work, we develop a novel methodology to construct synthetic API\noutputs that are simultaneously realistic enough to enable accurate study and\nprovide strong privacy protections. We focus on one Privacy-Preserving Ads\nAPIs: the Topics API, part of Google Chrome's Privacy Sandbox. We developed a\nmethodology to generate a differentially-private dataset that closely matches\nthe re-identification risk properties of the real Topics API data. The use of\ndifferential privacy provides strong theoretical bounds on the leakage of\nprivate user information from this release.\n  Our methodology is based on first computing a large number of\ndifferentially-private statistics describing how output API traces evolve over\ntime. Then, we design a parameterized distribution over sequences of API traces\nand optimize its parameters so that they closely match the statistics obtained.\nFinally, we create the synthetic data by drawing from this distribution.\n  Our work is complemented by an open-source release of the anonymized dataset\nobtained by this methodology. We hope this will enable external researchers to\nanalyze the API in-depth and replicate prior and future work on a realistic\nlarge-scale dataset. We believe that this work will contribute to fostering\ntransparency regarding the privacy properties of Privacy-Preserving Ads APIs.", "AI": {"tldr": "A novel methodology for generating synthetic, differentially-private API outputs to study Privacy-Preserving Ads APIs, focusing on Google Chrome's Topics API, with open-source dataset release.", "motivation": "Empirical study of Privacy-Preserving Ads APIs is hindered by lack of public data due to privacy concerns.", "method": "Compute differentially-private statistics, design a parameterized distribution, optimize parameters, and draw synthetic data from it.", "result": "Generated a realistic, differentially-private dataset matching the Topics API's re-identification risk properties.", "conclusion": "The work fosters transparency and enables external research on Privacy-Preserving Ads APIs."}}
{"id": "2506.22641", "pdf": "https://arxiv.org/pdf/2506.22641", "abs": "https://arxiv.org/abs/2506.22641", "authors": ["Gabriel M. Mejia", "Henry E. Miller", "Francis J. A. Leblanc", "Bo Wang", "Brendan Swain", "Lucas Paulo de Lima Camillo"], "title": "Diversity by Design: Addressing Mode Collapse Improves scRNA-seq Perturbation Modeling on Well-Calibrated Metrics", "categories": ["q-bio.GN", "cs.LG", "q-bio.MN", "stat.ML"], "comment": null, "summary": "Recent benchmarks reveal that models for single-cell perturbation response\nare often outperformed by simply predicting the dataset mean. We trace this\nanomaly to a metric artifact: control-referenced deltas and unweighted error\nmetrics reward mode collapse whenever the control is biased or the biological\nsignal is sparse. Large-scale \\textit{in silico} simulations and analysis of\ntwo real-world perturbation datasets confirm that shared reference shifts, not\ngenuine biological change, drives high performance in these evaluations. We\nintroduce differentially expressed gene (DEG)-aware metrics, weighted\nmean-squared error (WMSE) and weighted delta $R^{2}$ ($R^{2}_{w}(\\Delta)$) with\nrespect to all perturbations, that measure error in niche signals with high\nsensitivity. We further introduce negative and positive performance baselines\nto calibrate these metrics. With these improvements, the mean baseline sinks to\nnull performance while genuine predictors are correctly rewarded. Finally, we\nshow that using WMSE as a loss function reduces mode collapse and improves\nmodel performance.", "AI": {"tldr": "The paper addresses a metric artifact in single-cell perturbation response models, where predicting the dataset mean outperforms due to biased controls or sparse signals. It introduces DEG-aware metrics (WMSE and weighted delta R\u00b2) and baselines to improve evaluation, showing these metrics reduce mode collapse and enhance model performance.", "motivation": "Current models for single-cell perturbation response are flawed due to metric artifacts, leading to misleading evaluations where simple baselines outperform genuine predictors.", "method": "The authors analyze the issue via simulations and real-world datasets, then propose DEG-aware metrics (WMSE and weighted delta R\u00b2) and performance baselines to address the problem.", "result": "The new metrics correctly reward genuine predictors, reduce mode collapse, and improve model performance when used as a loss function.", "conclusion": "The introduced metrics and baselines provide a more accurate evaluation framework for single-cell perturbation response models, addressing previous shortcomings."}}
{"id": "2506.23518", "pdf": "https://arxiv.org/pdf/2506.23518", "abs": "https://arxiv.org/abs/2506.23518", "authors": ["Jiwoo Park", "Tae Eun Choi", "Youngjun Jun", "Seong Jae Hwang"], "title": "WAVE: Warp-Based View Guidance for Consistent Novel View Synthesis Using a Single Image", "categories": ["cs.CV"], "comment": null, "summary": "Generating high-quality novel views of a scene from a single image requires\nmaintaining structural coherence across different views, referred to as view\nconsistency. While diffusion models have driven advancements in novel view\nsynthesis, they still struggle to preserve spatial continuity across views.\nDiffusion models have been combined with 3D models to address the issue, but\nsuch approaches lack efficiency due to their complex multi-step pipelines. This\npaper proposes a novel view-consistent image generation method which utilizes\ndiffusion models without additional modules. Our key idea is to enhance\ndiffusion models with a training-free method that enables adaptive attention\nmanipulation and noise reinitialization by leveraging view-guided warping to\nensure view consistency. Through our comprehensive metric framework suitable\nfor novel-view datasets, we show that our method improves view consistency\nacross various diffusion models, demonstrating its broader applicability.", "AI": {"tldr": "A method to improve view consistency in novel view synthesis using diffusion models without extra modules, enhancing attention and noise handling.", "motivation": "Addressing the challenge of maintaining spatial continuity in novel view synthesis from a single image, as current diffusion models struggle with view consistency.", "method": "Proposes a training-free approach using adaptive attention manipulation and noise reinitialization via view-guided warping to ensure consistency.", "result": "Improves view consistency across diffusion models, validated by a comprehensive metric framework.", "conclusion": "The method is broadly applicable and effective for enhancing view consistency in novel view synthesis."}}
{"id": "2502.18282", "pdf": "https://arxiv.org/pdf/2502.18282", "abs": "https://arxiv.org/abs/2502.18282", "authors": ["Shanshan Xu", "T. Y. S. S Santosh", "Yanai Elazar", "Quirin Vogel", "Barbara Plank", "Matthias Grabmair"], "title": "Better Aligned with Survey Respondents or Training Data? Unveiling Political Leanings of LLMs on U.S. Supreme Court Cases", "categories": ["cs.CL"], "comment": null, "summary": "Recent works have shown that Large Language Models (LLMs) have a tendency to\nmemorize patterns and biases present in their training data, raising important\nquestions about how such memorized content influences model behavior. One such\nconcern is the emergence of political bias in LLM outputs. In this paper, we\ninvestigate the extent to which LLMs' political leanings reflect memorized\npatterns from their pretraining corpora. We propose a method to quantitatively\nevaluate political leanings embedded in the large pretraining corpora.\nSubsequently we investigate to whom are the LLMs' political leanings more\naligned with, their pretrainig corpora or the surveyed human opinions. As a\ncase study, we focus on probing the political leanings of LLMs in 32 US Supreme\nCourt cases, addressing contentious topics such as abortion and voting rights.\nOur findings reveal that LLMs strongly reflect the political leanings in their\ntraining data, and no strong correlation is observed with their alignment to\nhuman opinions as expressed in surveys. These results underscore the importance\nof responsible curation of training data, and the methodology for auditing the\nmemorization in LLMs to ensure human-AI alignment.", "AI": {"tldr": "The paper examines how LLMs' political biases reflect their training data, finding strong alignment with the data but weak correlation with human survey opinions.", "motivation": "To understand if LLMs' political biases stem from memorized training data and how they align with human opinions.", "method": "Quantitative evaluation of political leanings in pretraining corpora and comparison with human survey data, focusing on 32 US Supreme Court cases.", "result": "LLMs strongly reflect training data biases, with no significant alignment to human survey opinions.", "conclusion": "Highlights the need for responsible data curation and auditing methods to ensure human-AI alignment."}}
{"id": "2506.23903", "pdf": "https://arxiv.org/pdf/2506.23903", "abs": "https://arxiv.org/abs/2506.23903", "authors": ["Hamza Rasaee", "Taha Koleilat", "Hassan Rivaz"], "title": "GroundingDINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 3 figures, 6 figures", "summary": "Accurate and generalizable object segmentation in ultrasound imaging remains\na significant challenge due to anatomical variability, diverse imaging\nprotocols, and limited annotated data. In this study, we propose a\nprompt-driven vision-language model (VLM) that integrates Grounding DINO with\nSAM2 to enable object segmentation across multiple ultrasound organs. A total\nof 18 public ultrasound datasets, encompassing the breast, thyroid, liver,\nprostate, kidney, and paraspinal muscle, were utilized. These datasets were\ndivided into 15 for fine-tuning and validation of Grounding DINO using Low Rank\nAdaptation (LoRA) to the ultrasound domain, and 3 were held out entirely for\ntesting to evaluate performance in unseen distributions. Comprehensive\nexperiments demonstrate that our approach outperforms state-of-the-art\nsegmentation methods, including UniverSeg, MedSAM, MedCLIP-SAM, BiomedParse,\nand SAMUS on most seen datasets while maintaining strong performance on unseen\ndatasets without additional fine-tuning. These results underscore the promise\nof VLMs in scalable and robust ultrasound image analysis, reducing dependence\non large, organ-specific annotated datasets. We will publish our code on\ncode.sonography.ai after acceptance.", "AI": {"tldr": "A prompt-driven vision-language model (VLM) integrating Grounding DINO and SAM2 achieves superior object segmentation in ultrasound across multiple organs, outperforming state-of-the-art methods without needing large annotated datasets.", "motivation": "Addressing challenges in ultrasound object segmentation due to anatomical variability, diverse protocols, and limited annotated data.", "method": "Uses a VLM combining Grounding DINO and SAM2, fine-tuned with LoRA on 15 ultrasound datasets, and tested on 3 unseen datasets.", "result": "Outperforms UniverSeg, MedSAM, MedCLIP-SAM, BiomedParse, and SAMUS on seen datasets and maintains strong performance on unseen ones.", "conclusion": "VLMs show promise for scalable, robust ultrasound image analysis, reducing reliance on organ-specific annotated data."}}
{"id": "2506.22648", "pdf": "https://arxiv.org/pdf/2506.22648", "abs": "https://arxiv.org/abs/2506.22648", "authors": ["Pedro R. Pires", "Tiago A. Almeida"], "title": "Interact2Vec -- An efficient neural network-based model for simultaneously learning users and items embeddings in recommender systems", "categories": ["cs.IR", "cs.LG"], "comment": "Accepted for publication in Applied Soft Computing (ASOC), 49 pages,\n  14 figures", "summary": "Over the past decade, recommender systems have experienced a surge in\npopularity. Despite notable progress, they grapple with challenging issues,\nsuch as high data dimensionality and sparseness. Representing users and items\nas low-dimensional embeddings learned via neural networks has become a leading\nsolution. However, while recent studies show promising results, many approaches\nrely on complex architectures or require content data, which may not always be\navailable. This paper presents Interact2Vec, a novel neural network-based model\nthat simultaneously learns distributed embeddings for users and items while\ndemanding only implicit feedback. The model employs state-of-the-art strategies\nthat natural language processing models commonly use to optimize the training\nphase and enhance the final embeddings. Two types of experiments were conducted\nregarding the extrinsic and intrinsic quality of the model. In the former, we\nbenchmarked the recommendations generated by Interact2Vec's embeddings in a\ntop-$N$ ranking problem, comparing them with six other recommender algorithms.\nThe model achieved the second or third-best results in 30\\% of the datasets,\nbeing competitive with other recommenders, and has proven to be very efficient\nwith an average training time reduction of 274\\% compared to other\nembedding-based models. Later, we analyzed the intrinsic quality of the\nembeddings through similarity tables. Our findings suggest that Interact2Vec\ncan achieve promising results, especially on the extrinsic task, and is an\nexcellent embedding-generator model for scenarios of scarce computing\nresources, enabling the learning of item and user embeddings simultaneously and\nefficiently.", "AI": {"tldr": "Interact2Vec is a neural network-based model for learning user and item embeddings using only implicit feedback, achieving competitive results and efficiency.", "motivation": "Address challenges in recommender systems like high data dimensionality and sparseness, without relying on complex architectures or content data.", "method": "Uses neural networks and NLP-inspired strategies to learn embeddings from implicit feedback, optimizing training and enhancing embeddings.", "result": "Achieved competitive performance in top-N ranking, with 30% second or third-best results, and 274% faster training than other models.", "conclusion": "Interact2Vec is efficient and effective, especially in resource-scarce scenarios, for simultaneous user and item embedding learning."}}
{"id": "2506.23519", "pdf": "https://arxiv.org/pdf/2506.23519", "abs": "https://arxiv.org/abs/2506.23519", "authors": ["Qi Qin", "Runmin Cong", "Gen Zhan", "Yiting Liao", "Sam Kwong"], "title": "From Sight to Insight: Unleashing Eye-Tracking in Weakly Supervised Video Salient Object Detection", "categories": ["cs.CV"], "comment": "15 Pages, 9 Figures", "summary": "The eye-tracking video saliency prediction (VSP) task and video salient\nobject detection (VSOD) task both focus on the most attractive objects in video\nand show the result in the form of predictive heatmaps and pixel-level saliency\nmasks, respectively. In practical applications, eye tracker annotations are\nmore readily obtainable and align closely with the authentic visual patterns of\nhuman eyes. Therefore, this paper aims to introduce fixation information to\nassist the detection of video salient objects under weak supervision. On the\none hand, we ponder how to better explore and utilize the information provided\nby fixation, and then propose a Position and Semantic Embedding (PSE) module to\nprovide location and semantic guidance during the feature learning process. On\nthe other hand, we achieve spatiotemporal feature modeling under weak\nsupervision from the aspects of feature selection and feature contrast. A\nSemantics and Locality Query (SLQ) Competitor with semantic and locality\nconstraints is designed to effectively select the most matching and accurate\nobject query for spatiotemporal modeling. In addition, an Intra-Inter Mixed\nContrastive (IIMC) model improves the spatiotemporal modeling capabilities\nunder weak supervision by forming an intra-video and inter-video contrastive\nlearning paradigm. Experimental results on five popular VSOD benchmarks\nindicate that our model outperforms other competitors on various evaluation\nmetrics.", "AI": {"tldr": "The paper introduces fixation information to improve video salient object detection (VSOD) under weak supervision, proposing a PSE module for location/semantic guidance and an SLQ Competitor with IIMC for spatiotemporal modeling. It outperforms benchmarks.", "motivation": "Eye-tracking annotations are more accessible and align with human visual patterns, motivating the use of fixation data to enhance VSOD under weak supervision.", "method": "Proposes a Position and Semantic Embedding (PSE) module for guidance and a Semantics and Locality Query (SLQ) Competitor with Intra-Inter Mixed Contrastive (IIMC) learning for spatiotemporal modeling.", "result": "The model outperforms other methods on five VSOD benchmarks across various metrics.", "conclusion": "Leveraging fixation data and innovative modules improves VSOD performance under weak supervision, demonstrating the effectiveness of the proposed approach."}}
{"id": "2502.18435", "pdf": "https://arxiv.org/pdf/2502.18435", "abs": "https://arxiv.org/abs/2502.18435", "authors": ["Yizhe Zhang", "Richard Bai", "Zijin Gu", "Ruixiang Zhang", "Jiatao Gu", "Emmanuel Abbe", "Samy Bengio", "Navdeep Jaitly"], "title": "What Makes the Preferred Thinking Direction for LLMs in Multiple-choice Questions?", "categories": ["cs.CL", "cs.IT", "cs.LG", "math.IT"], "comment": "10 pages for the main text", "summary": "Language models usually use left-to-right (L2R) autoregressive factorization.\nHowever, L2R factorization may not always be the best inductive bias.\nTherefore, we investigate whether alternative factorizations of the text\ndistribution could be beneficial in some tasks. We investigate right-to-left\n(R2L) training as a compelling alternative, focusing on multiple-choice\nquestions (MCQs) as a test bed for knowledge extraction and reasoning. Through\nextensive experiments across various model sizes (2B-8B parameters) and\ntraining datasets, we find that R2L models can significantly outperform L2R\nmodels on several MCQ benchmarks, including logical reasoning, commonsense\nunderstanding, and truthfulness assessment tasks. Our analysis reveals that\nthis performance difference may be fundamentally linked to multiple factors\nincluding calibration, computability, and directional conditional entropy. We\nanalyze the impact of these factors through controlled simulation studies using\narithmetic tasks, where the impacting factors can be better disentangled. Our\nwork demonstrates that exploring alternative factorizations of the text\ndistribution can lead to improvements in LLM capabilities and provides\ntheoretical insights into optimal factorization towards approximating human\nlanguage distribution, and when each reasoning order might be more\nadvantageous. Our code and checkpoints are released at\nhttps://github.com/apple/ml-reversal-blessing.", "AI": {"tldr": "The paper explores right-to-left (R2L) training as an alternative to left-to-right (L2R) autoregressive factorization in language models, showing R2L's superior performance on multiple-choice questions (MCQs) across various tasks.", "motivation": "L2R factorization may not always be the best inductive bias, prompting investigation into alternative factorizations like R2L for improved performance in knowledge extraction and reasoning tasks.", "method": "The study evaluates R2L training on MCQs, testing models (2B-8B parameters) across benchmarks for logical reasoning, commonsense understanding, and truthfulness. Controlled simulations on arithmetic tasks disentangle impacting factors like calibration and directional entropy.", "result": "R2L models outperform L2R models on several MCQ benchmarks, with performance differences linked to factors like calibration and computability.", "conclusion": "Exploring alternative factorizations like R2L can enhance LLM capabilities, offering theoretical insights into optimal factorization for approximating human language distribution and task-specific advantages."}}
{"id": "2506.23934", "pdf": "https://arxiv.org/pdf/2506.23934", "abs": "https://arxiv.org/abs/2506.23934", "authors": ["Xiangchen Li", "Saeid Ghafouri", "Bo Ji", "Hans Vandierendonck", "Deepu John", "Dimitrios S. Nikolopoulos"], "title": "QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PF"], "comment": null, "summary": "As machine learning inferences increasingly move to edge devices, adapting to\ndiverse computational capabilities, hardware, and memory constraints becomes\nmore critical. Instead of relying on a pre-trained model fixed for all future\ninference queries across diverse edge devices, we argue that planning an\ninference pattern with a request-specific model tailored to the device's\ncomputational capacity, accuracy requirements, and time constraints is more\ncost-efficient and robust to diverse scenarios. To this end, we propose an\naccuracy-aware and workload-balanced inference system that integrates joint\nmodel quantization and inference partitioning. In this approach, the server\ndynamically responds to inference queries by sending a quantized model and\nadaptively sharing the inference workload with the device. Meanwhile, the\ndevice's computational power, channel capacity, and accuracy requirements are\nconsidered when deciding.\n  Furthermore, we introduce a new optimization framework for the inference\nsystem, incorporating joint model quantization and partitioning. Our approach\noptimizes layer-wise quantization bit width and partition points to minimize\ntime consumption and cost while accounting for varying accuracy requirements of\ntasks through an accuracy degradation metric in our optimization model. To our\nknowledge, this work represents the first exploration of optimizing\nquantization layer-wise bit-width in the inference serving system, by\nintroducing theoretical measurement of accuracy degradation. Simulation results\ndemonstrate a substantial reduction in overall time and power consumption, with\ncomputation payloads decreasing by over 80% and accuracy degradation kept below\n1%.", "AI": {"tldr": "The paper proposes an adaptive inference system for edge devices, combining model quantization and workload partitioning to optimize performance, cost, and accuracy.", "motivation": "Edge devices have diverse computational capabilities and constraints, requiring flexible inference solutions beyond static pre-trained models.", "method": "The system dynamically quantizes models and partitions workloads between server and device, optimizing bit-width and partition points using a new framework.", "result": "Simulations show over 80% reduction in computation payloads and less than 1% accuracy degradation.", "conclusion": "The approach is cost-efficient and robust, balancing accuracy and performance for diverse edge scenarios."}}
{"id": "2506.22675", "pdf": "https://arxiv.org/pdf/2506.22675", "abs": "https://arxiv.org/abs/2506.22675", "authors": ["Luhuan Wu", "Mingzhang Yin", "Yixin Wang", "John P. Cunningham", "David M. Blei"], "title": "Bayesian Invariance Modeling of Multi-Environment Data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Invariant prediction [Peters et al., 2016] analyzes feature/outcome data from\nmultiple environments to identify invariant features - those with a stable\npredictive relationship to the outcome. Such features support generalization to\nnew environments and help reveal causal mechanisms. Previous methods have\nprimarily tackled this problem through hypothesis testing or regularized\noptimization. Here we develop Bayesian Invariant Prediction (BIP), a\nprobabilistic model for invariant prediction. BIP encodes the indices of\ninvariant features as a latent variable and recover them by posterior\ninference. Under the assumptions of Peters et al. [2016], the BIP posterior\ntargets the true invariant features. We prove that the posterior is consistent\nand that greater environment heterogeneity leads to faster posterior\ncontraction. To handle many features, we design an efficient variational\napproximation called VI-BIP. In simulations and real data, we find that BIP and\nVI-BIP are more accurate and scalable than existing methods for invariant\nprediction.", "AI": {"tldr": "Bayesian Invariant Prediction (BIP) is a probabilistic model for identifying invariant features across environments, offering improved accuracy and scalability over existing methods.", "motivation": "To generalize predictions to new environments and reveal causal mechanisms by identifying features with stable predictive relationships to outcomes.", "method": "BIP encodes invariant feature indices as latent variables and recovers them via posterior inference, with a variational approximation (VI-BIP) for scalability.", "result": "BIP and VI-BIP outperform existing methods in accuracy and scalability, with theoretical guarantees of consistency and faster posterior contraction under greater environment heterogeneity.", "conclusion": "BIP provides a robust, scalable solution for invariant prediction, enhancing generalization and causal insight."}}
{"id": "2506.23523", "pdf": "https://arxiv.org/pdf/2506.23523", "abs": "https://arxiv.org/abs/2506.23523", "authors": ["Tuong Do", "Binh X. Nguyen", "Quang D. Tran", "Erman Tjiputra", "Te-Chuan Chiu", "Anh Nguyen"], "title": "Lightweight Temporal Transformer Decomposition for Federated Autonomous Driving", "categories": ["cs.CV"], "comment": "Accepted in IROS 2025", "summary": "Traditional vision-based autonomous driving systems often face difficulties\nin navigating complex environments when relying solely on single-image inputs.\nTo overcome this limitation, incorporating temporal data such as past image\nframes or steering sequences, has proven effective in enhancing robustness and\nadaptability in challenging scenarios. While previous high-performance methods\nexist, they often rely on resource-intensive fusion networks, making them\nimpractical for training and unsuitable for federated learning. To address\nthese challenges, we propose lightweight temporal transformer decomposition, a\nmethod that processes sequential image frames and temporal steering data by\nbreaking down large attention maps into smaller matrices. This approach reduces\nmodel complexity, enabling efficient weight updates for convergence and\nreal-time predictions while leveraging temporal information to enhance\nautonomous driving performance. Intensive experiments on three datasets\ndemonstrate that our method outperforms recent approaches by a clear margin\nwhile achieving real-time performance. Additionally, real robot experiments\nfurther confirm the effectiveness of our method.", "AI": {"tldr": "A lightweight temporal transformer decomposition method is proposed to enhance autonomous driving by efficiently processing sequential image frames and steering data, reducing model complexity and enabling real-time performance.", "motivation": "Traditional vision-based autonomous driving systems struggle with complex environments due to reliance on single-image inputs, and existing high-performance methods are resource-intensive and impractical for federated learning.", "method": "The method decomposes large attention maps into smaller matrices to process sequential image frames and temporal steering data, reducing model complexity.", "result": "Outperforms recent approaches on three datasets and achieves real-time performance, with effectiveness confirmed in real robot experiments.", "conclusion": "The proposed method effectively enhances autonomous driving performance by leveraging temporal information efficiently and practically."}}
{"id": "2502.18968", "pdf": "https://arxiv.org/pdf/2502.18968", "abs": "https://arxiv.org/abs/2502.18968", "authors": ["Kuang Wang", "Xianfei Li", "Shenghao Yang", "Li Zhou", "Feng Jiang", "Haizhou Li"], "title": "Know You First and Be You Better: Modeling Human-Like User Simulators via Implicit Profiles", "categories": ["cs.CL"], "comment": "9 pages. Accepted to ACL 2025. Camera-ready version", "summary": "User simulators are crucial for replicating human interactions with dialogue\nsystems, supporting both collaborative training and automatic evaluation,\nespecially for large language models (LLMs). However, current role-playing\nmethods face challenges such as a lack of utterance-level authenticity and\nuser-level diversity, often hindered by role confusion and dependence on\npredefined profiles of well-known figures. In contrast, direct simulation\nfocuses solely on text, neglecting implicit user traits like personality and\nconversation-level consistency. To address these issues, we introduce the User\nSimulator with Implicit Profiles (USP), a framework that infers implicit user\nprofiles from human-machine interactions to simulate personalized and realistic\ndialogues. We first develop an LLM-driven extractor with a comprehensive\nprofile schema, then refine the simulation using conditional supervised\nfine-tuning and reinforcement learning with cycle consistency, optimizing at\nboth the utterance and conversation levels. Finally, a diverse profile sampler\ncaptures the distribution of real-world user profiles. Experimental results\nshow that USP outperforms strong baselines in terms of authenticity and\ndiversity while maintaining comparable consistency. Additionally, using USP to\nevaluate LLM on dynamic multi-turn aligns well with mainstream benchmarks,\ndemonstrating its effectiveness in real-world applications.", "AI": {"tldr": "USP is a user simulator framework that infers implicit profiles from interactions to create realistic, diverse dialogues, outperforming baselines in authenticity and diversity.", "motivation": "Current user simulators lack utterance-level authenticity and user-level diversity, often relying on predefined profiles or neglecting implicit traits.", "method": "USP uses an LLM-driven extractor, conditional supervised fine-tuning, reinforcement learning with cycle consistency, and a diverse profile sampler.", "result": "USP outperforms baselines in authenticity and diversity while maintaining consistency and aligns well with benchmarks in real-world applications.", "conclusion": "USP effectively addresses limitations of current simulators, offering a robust solution for realistic and diverse dialogue simulation."}}
{"id": "2506.23944", "pdf": "https://arxiv.org/pdf/2506.23944", "abs": "https://arxiv.org/abs/2506.23944", "authors": ["Fuhang Kuang", "Jiacheng You", "Yingdong Hu", "Tong Zhang", "Chuan Wen", "Yang Gao"], "title": "Adapt Your Body: Mitigating Proprioception Shifts in Imitation Learning", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Imitation learning models for robotic tasks typically rely on multi-modal\ninputs, such as RGB images, language, and proprioceptive states. While\nproprioception is intuitively important for decision-making and obstacle\navoidance, simply incorporating all proprioceptive states leads to a surprising\ndegradation in imitation learning performance. In this work, we identify the\nunderlying issue as the proprioception shift problem, where the distributions\nof proprioceptive states diverge significantly between training and deployment.\nTo address this challenge, we propose a domain adaptation framework that\nbridges the gap by utilizing rollout data collected during deployment. Using\nWasserstein distance, we quantify the discrepancy between expert and rollout\nproprioceptive states and minimize this gap by adding noise to both sets of\nstates, proportional to the Wasserstein distance. This strategy enhances\nrobustness against proprioception shifts by aligning the training and\ndeployment distributions. Experiments on robotic manipulation tasks demonstrate\nthe efficacy of our method, enabling the imitation policy to leverage\nproprioception while mitigating its adverse effects. Our approach outperforms\nthe naive solution which discards proprioception, and other baselines designed\nto address distributional shifts.", "AI": {"tldr": "The paper addresses the proprioception shift problem in imitation learning for robotics by proposing a domain adaptation framework using Wasserstein distance to align training and deployment distributions.", "motivation": "Proprioceptive states degrade imitation learning performance due to distributional shifts between training and deployment.", "method": "A domain adaptation framework uses Wasserstein distance to quantify and minimize the gap between expert and rollout proprioceptive states by adding proportional noise.", "result": "The method outperforms baselines, enabling effective use of proprioception in robotic manipulation tasks.", "conclusion": "The proposed approach successfully mitigates proprioception shifts, enhancing imitation learning performance."}}
{"id": "2506.22701", "pdf": "https://arxiv.org/pdf/2506.22701", "abs": "https://arxiv.org/abs/2506.22701", "authors": ["Shi Jie Yu"], "title": "Lower bounds for trace estimation via Block Krylov and other methods", "categories": ["math.ST", "cs.DS", "cs.LG", "cs.NA", "math.NA", "stat.TH"], "comment": null, "summary": "This paper studies theoretical lower bounds for estimating the trace of a\nmatrix function, $\\text{tr}(f(A))$, focusing on methods that use Hutchinson's\nmethod along with Block Krylov techniques. These methods work by approximating\nmatrix-vector products like $f(A)V$ using a Block Krylov subspace. This is\nclosely related to approximating functions with polynomials. We derive\ntheoretical upper bounds on how many Krylov steps are needed for functions such\nas $A^{-1/2}$ and $A^{-1}$ by analyzing the upper bounds from the polynomial\napproximation of their scalar equivalent. In addition, we also develop lower\nlimits on the number of queries needed for trace estimation, specifically for\n$\\text{tr}(W^{-p})$ where $W$ is a Wishart matrix. Our study clarifies the\nconnection between the number of steps in Block Krylov methods and the degree\nof the polynomial used for approximation. This links the total cost of trace\nestimation to basic limits in polynomial approximation and how much information\nis needed for the computation.", "AI": {"tldr": "The paper explores theoretical bounds for estimating matrix function traces using Hutchinson's method and Block Krylov techniques, linking Krylov steps to polynomial approximation degrees.", "motivation": "To understand the relationship between Krylov subspace methods and polynomial approximation in trace estimation, particularly for functions like $A^{-1/2}$ and $A^{-1}$.", "method": "Uses Block Krylov techniques to approximate matrix-vector products and analyzes polynomial approximation bounds for scalar equivalents.", "result": "Derives upper bounds on Krylov steps for specific functions and lower limits on queries for trace estimation, especially for Wishart matrices.", "conclusion": "Clarifies the connection between Krylov steps and polynomial approximation, linking trace estimation costs to fundamental polynomial limits."}}
{"id": "2506.23529", "pdf": "https://arxiv.org/pdf/2506.23529", "abs": "https://arxiv.org/abs/2506.23529", "authors": ["Jisu Han", "Jihee Park", "Dongyoon Han", "Wonjun Hwang"], "title": "When Test-Time Adaptation Meets Self-Supervised Models", "categories": ["cs.CV", "cs.LG"], "comment": "15 pages, 7 figures", "summary": "Training on test-time data enables deep learning models to adapt to dynamic\nenvironmental changes, enhancing their practical applicability. Online\nadaptation from source to target domains is promising but it remains highly\nreliant on the performance of source pretrained model. In this paper, we\ninvestigate whether test-time adaptation (TTA) methods can continuously improve\nmodels trained via self-supervised learning (SSL) without relying on source\npretraining. We introduce a self-supervised TTA protocol after observing that\nexisting TTA approaches struggle when directly applied to self-supervised\nmodels with low accuracy on the source domain. Furthermore, we propose a\ncollaborative learning framework that integrates SSL and TTA models, leveraging\ncontrastive learning and knowledge distillation for stepwise representation\nrefinement. We validate our method on diverse self-supervised models, including\nDINO, MoCo, and iBOT, across TTA benchmarks. Extensive experiments validate the\neffectiveness of our approach in SSL, showing that it achieves competitive\nperformance even without source pretraining.", "AI": {"tldr": "The paper explores test-time adaptation (TTA) for self-supervised learning (SSL) models, proposing a collaborative framework to improve performance without relying on source pretraining.", "motivation": "To enable SSL models to adapt dynamically to changing environments without dependency on source pretraining, addressing the limitations of existing TTA methods.", "method": "Introduces a self-supervised TTA protocol and a collaborative learning framework combining SSL and TTA, using contrastive learning and knowledge distillation for refinement.", "result": "Validated on diverse SSL models (DINO, MoCo, iBOT), the method achieves competitive performance without source pretraining.", "conclusion": "The proposed framework effectively enhances SSL models' adaptability in dynamic environments, demonstrating its potential for practical applications."}}
{"id": "2503.01875", "pdf": "https://arxiv.org/pdf/2503.01875", "abs": "https://arxiv.org/abs/2503.01875", "authors": ["Yaxuan Kong", "Yiyuan Yang", "Yoontae Hwang", "Wenjie Du", "Stefan Zohren", "Zhangyang Wang", "Ming Jin", "Qingsong Wen"], "title": "Time-MQA: Time Series Multi-Task Question Answering with Context Enhancement", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Annual Meeting of the Association for Computational Linguistics (ACL\n  2025, Main)", "summary": "Time series data are foundational in finance, healthcare, and energy domains.\nHowever, most existing methods and datasets remain focused on a narrow spectrum\nof tasks, such as forecasting or anomaly detection. To bridge this gap, we\nintroduce Time Series Multi-Task Question Answering (Time-MQA), a unified\nframework that enables natural language queries across multiple time series\ntasks - numerical analytical tasks and open-ended question answering with\nreasoning. Central to Time-MQA is the TSQA dataset, a large-scale dataset\ncontaining $\\sim$200k question-answer pairs derived from diverse time series\nspanning environment, traffic, etc. This comprehensive resource covers various\ntime series lengths and promotes robust model development. We further\ndemonstrate how continually pre-training large language models (Mistral 7B,\nLlama-3 8B, and Qwen-2.5 7B) on the TSQA dataset enhanced time series reasoning\ncapabilities, moving beyond mere numeric tasks and enabling more advanced and\nintuitive interactions with temporal data. The complete TSQA dataset, models,\nuser study questionnaires for evaluation, and other related materials have been\nopen-sourced.", "AI": {"tldr": "The paper introduces Time-MQA, a unified framework for natural language queries across multiple time series tasks, supported by the TSQA dataset. It enhances large language models for advanced time series reasoning.", "motivation": "Existing methods and datasets for time series data are limited to narrow tasks like forecasting or anomaly detection, lacking a unified approach for diverse tasks.", "method": "The authors propose Time-MQA, a framework for multi-task time series question answering, and the TSQA dataset (~200k QA pairs). They pre-train large language models (Mistral 7B, Llama-3 8B, Qwen-2.5 7B) on TSQA.", "result": "Pre-training on TSQA improved time series reasoning in models, enabling advanced interactions beyond numeric tasks. The dataset and models are open-sourced.", "conclusion": "Time-MQA and TSQA bridge the gap in time series tasks, offering a robust, unified framework for diverse applications and enhancing model capabilities."}}
{"id": "2506.23952", "pdf": "https://arxiv.org/pdf/2506.23952", "abs": "https://arxiv.org/abs/2506.23952", "authors": ["Stefan Buijsman", "Sarah Carter", "Juan Pablo Berm\u00fadez"], "title": "Autonomy by Design: Preserving Human Autonomy in AI Decision-Support", "categories": ["cs.HC", "cs.AI", "cs.LG", "econ.GN", "q-fin.EC"], "comment": null, "summary": "AI systems increasingly support human decision-making across domains of\nprofessional, skill-based, and personal activity. While previous work has\nexamined how AI might affect human autonomy globally, the effects of AI on\ndomain-specific autonomy -- the capacity for self-governed action within\ndefined realms of skill or expertise -- remain understudied. We analyze how AI\ndecision-support systems affect two key components of domain-specific autonomy:\nskilled competence (the ability to make informed judgments within one's domain)\nand authentic value-formation (the capacity to form genuine domain-relevant\nvalues and preferences). By engaging with prior investigations and analyzing\nempirical cases across medical, financial, and educational domains, we\ndemonstrate how the absence of reliable failure indicators and the potential\nfor unconscious value shifts can erode domain-specific autonomy both\nimmediately and over time. We then develop a constructive framework for\nautonomy-preserving AI support systems. We propose specific socio-technical\ndesign patterns -- including careful role specification, implementation of\ndefeater mechanisms, and support for reflective practice -- that can help\nmaintain domain-specific autonomy while leveraging AI capabilities. This\nframework provides concrete guidance for developing AI systems that enhance\nrather than diminish human agency within specialized domains of action.", "AI": {"tldr": "The paper examines how AI decision-support systems impact domain-specific autonomy, focusing on skilled competence and authentic value-formation. It identifies risks like unreliable failure indicators and unconscious value shifts, proposing a framework for autonomy-preserving AI design.", "motivation": "To address the understudied effects of AI on domain-specific autonomy, particularly in skilled competence and authentic value-formation, and to mitigate risks to human agency.", "method": "Analyzes prior work and empirical cases in medical, financial, and educational domains to identify autonomy risks, then develops a socio-technical framework for autonomy-preserving AI.", "result": "Identifies risks to autonomy and proposes design patterns (e.g., role specification, defeater mechanisms, reflective practice) to maintain domain-specific autonomy.", "conclusion": "The framework offers practical guidance for designing AI systems that enhance human agency in specialized domains, balancing AI support with autonomy preservation."}}
{"id": "2506.22714", "pdf": "https://arxiv.org/pdf/2506.22714", "abs": "https://arxiv.org/abs/2506.22714", "authors": ["Jinliang Shi", "Shigang Li", "Youxuan Xu", "Xueying Wang", "Rongtian Fu", "Zhi Ma", "Tong Wu"], "title": "Libra: Synergizing CUDA and Tensor Cores for High-Performance Sparse Matrix Multiplication", "categories": ["cs.DC", "cs.LG", "cs.PF", "C.1.4; I.2.11"], "comment": null, "summary": "Sparse matrix multiplication operators (i.e., SpMM and SDDMM) are widely used\nin deep learning and scientific computing. Modern accelerators are commonly\nequipped with Tensor cores and CUDA cores to accelerate sparse operators. The\nformer brings superior computing power but only for structured matrix\nmultiplication, while the latter has relatively lower performance but with\nhigher programming flexibility. In this work, we discover that utilizing one\nresource alone leads to inferior performance for sparse matrix multiplication,\ndue to their respective limitations. To this end, we propose Libra, a\nsystematic approach that enables synergistic computation between CUDA and\nTensor cores to achieve the best performance for sparse matrix multiplication.\nSpecifically, we propose a 2D-aware workload distribution strategy to find out\nthe sweet point of task mapping for different sparse operators, leveraging both\nthe high performance of Tensor cores and the low computational redundancy on\nCUDA cores. In addition, Libra incorporates systematic optimizations for\nheterogeneous computing, including hybrid load-balancing, finely optimized\nkernel implementations, and GPU-accelerated preprocessing. Extensive\nexperimental results on H100 and RTX 4090 GPUs show that Libra outperforms the\nstate-of-the-art by on average 3.1x (up to 9.23x) over DTC-SpMM and 2.9x (up to\n3.9x) for end-to-end GNN applications. Libra opens up a new perspective for\nsparse operator acceleration by fully exploiting the heterogeneous computing\nresources on GPUs.", "AI": {"tldr": "Libra optimizes sparse matrix multiplication by synergizing CUDA and Tensor cores, achieving superior performance over existing methods.", "motivation": "Current accelerators (Tensor and CUDA cores) have limitations when used alone for sparse matrix multiplication, leading to inferior performance.", "method": "Libra uses a 2D-aware workload distribution strategy and systematic optimizations like hybrid load-balancing and finely tuned kernels.", "result": "Libra outperforms state-of-the-art methods by 3.1x on average (up to 9.23x) on H100 and RTX 4090 GPUs.", "conclusion": "Libra demonstrates the potential of heterogeneous computing for sparse operator acceleration."}}
{"id": "2506.23532", "pdf": "https://arxiv.org/pdf/2506.23532", "abs": "https://arxiv.org/abs/2506.23532", "authors": ["Jefferson Hernandez", "Ruozhen He", "Guha Balakrishnan", "Alexander C. Berg", "Vicente Ordonez"], "title": "GViT: Representing Images as Gaussians for Visual Recognition", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "We introduce GVIT, a classification framework that abandons conventional\npixel or patch grid input representations in favor of a compact set of\nlearnable 2D Gaussians. Each image is encoded as a few hundred Gaussians whose\npositions, scales, orientations, colors, and opacities are optimized jointly\nwith a ViT classifier trained on top of these representations. We reuse the\nclassifier gradients as constructive guidance, steering the Gaussians toward\nclass-salient regions while a differentiable renderer optimizes an image\nreconstruction loss. We demonstrate that by 2D Gaussian input representations\ncoupled with our GVIT guidance, using a relatively standard ViT architecture,\nclosely matches the performance of a traditional patch-based ViT, reaching a\n76.9% top-1 accuracy on Imagenet-1k using a ViT-B architecture.", "AI": {"tldr": "GVIT replaces pixel/patch grids with learnable 2D Gaussians for image classification, achieving 76.9% top-1 accuracy on Imagenet-1k.", "motivation": "To move beyond traditional pixel or patch grid representations by using compact, learnable 2D Gaussians for more efficient and effective image encoding.", "method": "Encodes images as hundreds of Gaussians, optimizing their attributes (position, scale, etc.) jointly with a ViT classifier. Uses classifier gradients to guide Gaussians toward salient regions and a differentiable renderer for reconstruction.", "result": "GVIT matches traditional patch-based ViT performance, achieving 76.9% top-1 accuracy on Imagenet-1k with a ViT-B architecture.", "conclusion": "GVIT demonstrates the viability of Gaussian-based representations for image classification, offering an alternative to conventional grid-based methods."}}
{"id": "2503.04722", "pdf": "https://arxiv.org/pdf/2503.04722", "abs": "https://arxiv.org/abs/2503.04722", "authors": ["Ritwik Gupta", "Rodolfo Corona", "Jiaxin Ge", "Eric Wang", "Dan Klein", "Trevor Darrell", "David M. Chan"], "title": "Enough Coin Flips Can Make LLMs Act Bayesian", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ACL 2025 Main", "summary": "Large language models (LLMs) exhibit the ability to generalize given few-shot\nexamples in their input prompt, an emergent capability known as in-context\nlearning (ICL). We investigate whether LLMs use ICL to perform structured\nreasoning in ways that are consistent with a Bayesian framework or rely on\npattern matching. Using a controlled setting of biased coin flips, we find\nthat: (1) LLMs often possess biased priors, causing initial divergence in\nzero-shot settings, (2) in-context evidence outweighs explicit bias\ninstructions, (3) LLMs broadly follow Bayesian posterior updates, with\ndeviations primarily due to miscalibrated priors rather than flawed updates,\nand (4) attention magnitude has negligible effect on Bayesian inference. With\nsufficient demonstrations of biased coin flips via ICL, LLMs update their\npriors in a Bayesian manner.", "AI": {"tldr": "LLMs use in-context learning (ICL) for Bayesian-like reasoning, with biases in priors but largely correct posterior updates.", "motivation": "To determine if LLMs perform structured reasoning via Bayesian frameworks or pattern matching in ICL.", "method": "Controlled experiments with biased coin flips to analyze LLM behavior in zero-shot and few-shot settings.", "result": "LLMs show biased priors but update posteriors correctly with sufficient ICL evidence. Attention magnitude doesn't affect Bayesian inference.", "conclusion": "LLMs can perform Bayesian reasoning via ICL, with deviations mainly from miscalibrated priors, not flawed updates."}}
{"id": "2506.23995", "pdf": "https://arxiv.org/pdf/2506.23995", "abs": "https://arxiv.org/abs/2506.23995", "authors": ["Mingfei Cheng", "Renzhi Wang", "Xiaofei Xie", "Yuan Zhou", "Lei Ma"], "title": "STCLocker: Deadlock Avoidance Testing for Autonomous Driving Systems", "categories": ["cs.SE", "cs.AI", "cs.RO"], "comment": null, "summary": "Autonomous Driving System (ADS) testing is essential to ensure the safety and\nreliability of autonomous vehicles (AVs) before deployment. However, existing\ntechniques primarily focus on evaluating ADS functionalities in single-AV\nsettings. As ADSs are increasingly deployed in multi-AV traffic, it becomes\ncrucial to assess their cooperative performance, particularly regarding\ndeadlocks, a fundamental coordination failure in which multiple AVs enter a\ncircular waiting state indefinitely, resulting in motion planning failures.\nDespite its importance, the cooperative capability of ADSs to prevent deadlocks\nremains insufficiently underexplored. To address this gap, we propose the first\ndedicated Spatio-Temporal Conflict-Guided Deadlock Avoidance Testing technique,\nSTCLocker, for generating DeadLock Scenarios (DLSs), where a group of AVs\ncontrolled by the ADS under test are in a circular wait state. STCLocker\nconsists of three key components: Deadlock Oracle, Conflict Feedback, and\nConflict-aware Scenario Generation. Deadlock Oracle provides a reliable\nblack-box mechanism for detecting deadlock cycles among multiple AVs within a\ngiven scenario. Conflict Feedback and Conflict-aware Scenario Generation\ncollaborate to actively guide AVs into simultaneous competition over spatial\nconflict resources (i.e., shared passing regions) and temporal competitive\nbehaviors (i.e., reaching the conflict region at the same time), thereby\nincreasing the effectiveness of generating conflict-prone deadlocks. We\nevaluate STCLocker on two types of ADSs: Roach, an end-to-end ADS, and OpenCDA,\na module-based ADS supporting cooperative communication. Experimental results\nshow that, on average, STCLocker generates more DLS than the best-performing\nbaseline.", "AI": {"tldr": "STCLocker is a new technique for testing deadlock scenarios in multi-AV systems, outperforming baselines in generating deadlock-prone situations.", "motivation": "Existing ADS testing focuses on single-AV settings, but multi-AV deadlocks are underexplored despite their critical impact on safety.", "method": "STCLocker uses Deadlock Oracle, Conflict Feedback, and Conflict-aware Scenario Generation to detect and create deadlock scenarios.", "result": "STCLocker generates more deadlock scenarios than the best baseline, tested on Roach and OpenCDA ADSs.", "conclusion": "STCLocker effectively addresses the gap in multi-AV deadlock testing, enhancing ADS safety evaluation."}}
{"id": "2506.22729", "pdf": "https://arxiv.org/pdf/2506.22729", "abs": "https://arxiv.org/abs/2506.22729", "authors": ["Honglin Bao", "Kai Li"], "title": "Persistence Paradox in Dynamic Science", "categories": ["cs.DL", "cs.CY", "cs.LG"], "comment": null, "summary": "Persistence is often regarded as a virtue in science. In this paper, however,\nwe challenge this conventional view by highlighting its contextual nature,\nparticularly how persistence can become a liability during periods of paradigm\nshift. We focus on the deep learning revolution catalyzed by AlexNet in 2012.\nAnalyzing the 20-year career trajectories of over 5,000 scientists who were\nactive in top machine learning venues during the preceding decade, we examine\nhow their research focus and output evolved. We first uncover a dynamic period\nin which leading venues increasingly prioritized cutting-edge deep learning\ndevelopments that displaced relatively traditional statistical learning\nmethods. Scientists responded to these changes in markedly different ways.\nThose who were previously successful or affiliated with old teams adapted more\nslowly, experiencing what we term a rigidity penalty - a reluctance to embrace\nnew directions leading to a decline in scientific impact, as measured by\ncitation percentile rank. In contrast, scientists who pursued strategic\nadaptation - selectively pivoting toward emerging trends while preserving weak\nconnections to prior expertise - reaped the greatest benefits. Taken together,\nour macro- and micro-level findings show that scientific breakthroughs act as\nmechanisms that reconfigure power structures within a field.", "AI": {"tldr": "The paper challenges the idea of persistence as a virtue in science, showing it can be a liability during paradigm shifts like the deep learning revolution. Analyzing 5,000 scientists' careers, it reveals slower adaptation by successful or affiliated scientists led to a 'rigidity penalty,' while strategic adaptation to new trends yielded greater impact.", "motivation": "To examine how persistence can hinder scientific progress during paradigm shifts, using the deep learning revolution as a case study.", "method": "Analysis of 20-year career trajectories of 5,000 scientists in top machine learning venues, focusing on research focus, output, and citation impact.", "result": "Scientists slow to adapt to deep learning trends faced a 'rigidity penalty,' while those strategically pivoting gained higher impact. Paradigm shifts reconfigure field power structures.", "conclusion": "Scientific breakthroughs reshape power dynamics, with strategic adaptation proving more beneficial than persistence during major shifts."}}
{"id": "2506.23542", "pdf": "https://arxiv.org/pdf/2506.23542", "abs": "https://arxiv.org/abs/2506.23542", "authors": ["Weida Wang", "Changyong He", "Jin Zeng", "Di Qiu"], "title": "Consistent Time-of-Flight Depth Denoising via Graph-Informed Geometric Attention", "categories": ["cs.CV"], "comment": "This paper has been accepted for publication at the International\n  Conference on Computer Vision (ICCV) 2025", "summary": "Depth images captured by Time-of-Flight (ToF) sensors are prone to noise,\nrequiring denoising for reliable downstream applications. Previous works either\nfocus on single-frame processing, or perform multi-frame processing without\nconsidering depth variations at corresponding pixels across frames, leading to\nundesirable temporal inconsistency and spatial ambiguity. In this paper, we\npropose a novel ToF depth denoising network leveraging motion-invariant graph\nfusion to simultaneously enhance temporal stability and spatial sharpness.\nSpecifically, despite depth shifts across frames, graph structures exhibit\ntemporal self-similarity, enabling cross-frame geometric attention for graph\nfusion. Then, by incorporating an image smoothness prior on the fused graph and\ndata fidelity term derived from ToF noise distribution, we formulate a maximum\na posterior problem for ToF denoising. Finally, the solution is unrolled into\niterative filters whose weights are adaptively learned from the graph-informed\ngeometric attention, producing a high-performance yet interpretable network.\nExperimental results demonstrate that the proposed scheme achieves\nstate-of-the-art performance in terms of accuracy and consistency on synthetic\nDVToF dataset and exhibits robust generalization on the real Kinectv2 dataset.\nSource code will be released at\n\\href{https://github.com/davidweidawang/GIGA-ToF}{https://github.com/davidweidawang/GIGA-ToF}.", "AI": {"tldr": "A novel ToF depth denoising network using motion-invariant graph fusion improves temporal stability and spatial sharpness by leveraging cross-frame geometric attention and a maximum a posteriori formulation.", "motivation": "ToF depth images are noisy, and existing methods either ignore multi-frame depth variations or lack temporal consistency, leading to poor performance.", "method": "Proposes a network with motion-invariant graph fusion, geometric attention, and an iterative filtering solution derived from a maximum a posteriori problem.", "result": "Achieves state-of-the-art performance on synthetic DVToF and real Kinectv2 datasets, with robust generalization.", "conclusion": "The method effectively denoises ToF depth images while maintaining temporal and spatial quality, with interpretable and adaptive learning."}}
{"id": "2503.10135", "pdf": "https://arxiv.org/pdf/2503.10135", "abs": "https://arxiv.org/abs/2503.10135", "authors": ["Jinze Li", "Yixing Xu", "Haiduo Huang", "Xuanwu Yin", "Dong Li", "Edith C. H. Ngai", "Emad Barsoum"], "title": "Gumiho: A Hybrid Architecture to Prioritize Early Tokens in Speculative Decoding", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to the 42nd International Conference on Machine Learning\n  (ICML 2025). Code: https://github.com/AMD-AIG-AIMA/Gumiho", "summary": "Speculative decoding (SPD) aims to accelerate the auto-regressive token\ngeneration process of a target Large Language Model (LLM). Some approaches\nemploy a draft model with multiple heads to predict a sequence of future\ntokens, where each head handles a token in the sequence. The target LLM\nverifies the predicted sequence and accepts aligned tokens, enabling efficient\nmulti-token generation. However, existing methods assume that all tokens within\na sequence are equally important, employing identical head structures and\nrelying on a single-generation paradigm, either serial or parallel. To this\nend, we theoretically demonstrate that initial tokens in the draft sequence are\nmore important than later ones. Building on this insight, we propose Gumiho, a\nhybrid model combining serial and parallel heads. Specifically, given the\ncritical importance of early tokens, we employ a sophisticated Transformer\narchitecture for the early draft heads in a serial configuration to improve\naccuracy. For later tokens, we utilize multiple lightweight MLP heads operating\nin parallel to enhance efficiency. By allocating more advanced model structures\nand longer running times to the early heads, Gumiho achieves improved overall\nperformance. The experimental results demonstrate that our method outperforms\nexisting approaches, fully validating its effectiveness.", "AI": {"tldr": "Gumiho improves speculative decoding by using a hybrid model with serial and parallel heads, prioritizing early tokens for better performance.", "motivation": "Existing speculative decoding methods treat all tokens equally, ignoring the varying importance of early and later tokens in the sequence.", "method": "Gumiho combines serial (Transformer) and parallel (MLP) heads, focusing advanced structures on early tokens for accuracy and lightweight heads on later tokens for efficiency.", "result": "Gumiho outperforms existing methods, validating its effectiveness in multi-token generation.", "conclusion": "Prioritizing early tokens with advanced structures and later tokens with lightweight heads enhances speculative decoding performance."}}
{"id": "2506.24009", "pdf": "https://arxiv.org/pdf/2506.24009", "abs": "https://arxiv.org/abs/2506.24009", "authors": ["Xinquan Wang", "Fenghao Zhu", "Zhaohui Yang", "Chongwen Huang", "Xiaoming Chen", "Zhaoyang Zhang", "Sami Muhaidat", "M\u00e9rouane Debbah"], "title": "Bridging Physical and Digital Worlds: Embodied Large AI for Future Wireless Systems", "categories": ["cs.IT", "cs.AI", "math.IT"], "comment": "7 pages, 4 figures", "summary": "Large artificial intelligence (AI) models offer revolutionary potential for\nfuture wireless systems, promising unprecedented capabilities in network\noptimization and performance. However, current paradigms largely overlook\ncrucial physical interactions. This oversight means they primarily rely on\noffline datasets, leading to difficulties in handling real-time wireless\ndynamics and non-stationary environments. Furthermore, these models often lack\nthe capability for active environmental probing. This paper proposes a\nfundamental paradigm shift towards wireless embodied large AI (WELAI), moving\nfrom passive observation to active embodiment. We first identify key challenges\nfaced by existing models, then we explore the design principles and system\nstructure of WELAI. Besides, we outline prospective applications in\nnext-generation wireless. Finally, through an illustrative case study, we\ndemonstrate the effectiveness of WELAI and point out promising research\ndirections for realizing adaptive, robust, and autonomous wireless systems.", "AI": {"tldr": "The paper proposes WELAI, a paradigm shift from passive to active AI in wireless systems, addressing real-time dynamics and non-stationary environments.", "motivation": "Current AI models for wireless systems overlook physical interactions and rely on offline data, limiting real-time adaptability.", "method": "Introduces WELAI, focusing on active embodiment, design principles, and system structure, with a case study for validation.", "result": "Demonstrates WELAI's effectiveness in adaptive, robust, and autonomous wireless systems.", "conclusion": "WELAI offers a promising direction for next-generation wireless systems, with potential for further research."}}
{"id": "2506.22763", "pdf": "https://arxiv.org/pdf/2506.22763", "abs": "https://arxiv.org/abs/2506.22763", "authors": ["Fiona Xiao Jingyi", "Lili Liu"], "title": "Can We Reliably Predict the Fed's Next Move? A Multi-Modal Approach to U.S. Monetary Policy Forecasting", "categories": ["q-fin.PM", "cs.LG", "q-fin.CP"], "comment": "9 pages, 15 figures", "summary": "Forecasting central bank policy decisions remains a persistent challenge for\ninvestors, financial institutions, and policymakers due to the wide-reaching\nimpact of monetary actions. In particular, anticipating shifts in the U.S.\nfederal funds rate is vital for risk management and trading strategies.\nTraditional methods relying only on structured macroeconomic indicators often\nfall short in capturing the forward-looking cues embedded in central bank\ncommunications.\n  This study examines whether predictive accuracy can be enhanced by\nintegrating structured data with unstructured textual signals from Federal\nReserve communications. We adopt a multi-modal framework, comparing traditional\nmachine learning models, transformer-based language models, and deep learning\narchitectures in both unimodal and hybrid settings.\n  Our results show that hybrid models consistently outperform unimodal\nbaselines. The best performance is achieved by combining TF-IDF features of\nFOMC texts with economic indicators in an XGBoost classifier, reaching a test\nAUC of 0.83. FinBERT-based sentiment features marginally improve ranking but\nperform worse in classification, especially under class imbalance. SHAP\nanalysis reveals that sparse, interpretable features align more closely with\npolicy-relevant signals.\n  These findings underscore the importance of integrating textual and\nstructured signals transparently. For monetary policy forecasting, simpler\nhybrid models can offer both accuracy and interpretability, delivering\nactionable insights for researchers and decision-makers.", "AI": {"tldr": "Hybrid models combining structured economic data and unstructured Fed texts outperform unimodal methods in forecasting U.S. federal funds rate shifts, achieving a test AUC of 0.83 with XGBoost.", "motivation": "Forecasting central bank policy decisions is challenging but crucial for risk management. Traditional methods using only structured data miss cues from central bank communications.", "method": "A multi-modal framework compares traditional ML, transformer-based models, and deep learning in unimodal and hybrid settings, integrating structured data with textual signals from Fed communications.", "result": "Hybrid models, especially XGBoost with TF-IDF features and economic indicators, perform best (AUC 0.83). FinBERT sentiment features help ranking but lag in classification. SHAP analysis highlights interpretable features.", "conclusion": "Integrating textual and structured data transparently improves forecasting. Simpler hybrid models balance accuracy and interpretability, aiding researchers and policymakers."}}
{"id": "2506.23543", "pdf": "https://arxiv.org/pdf/2506.23543", "abs": "https://arxiv.org/abs/2506.23543", "authors": ["Hui Li", "Baoyou Chen", "Liwei Zhang", "Jiaye Li", "Jingdong Wang", "Siyu Zhu"], "title": "Pyramidal Patchification Flow for Visual Generation", "categories": ["cs.CV"], "comment": "10 pages, 9figures", "summary": "Diffusion transformers (DiTs) adopt Patchify, mapping patch representations\nto token representations through linear projections, to adjust the number of\ntokens input to DiT blocks and thus the computation cost. Instead of a single\npatch size for all the timesteps, we introduce a Pyramidal Patchification Flow\n(PPFlow) approach: Large patch sizes are used for high noise timesteps and\nsmall patch sizes for low noise timesteps; Linear projections are learned for\neach patch size; and Unpatchify is accordingly modified. Unlike Pyramidal Flow,\nour approach operates over full latent representations other than pyramid\nrepresentations, and adopts the normal denoising process without requiring the\nrenoising trick. We demonstrate the effectiveness of our approach through two\ntraining manners. Training from scratch achieves a $1.6\\times$ ($2.0\\times$)\ninference speed over SiT-B/2 for 2-level (3-level) pyramid patchification with\nslightly lower training FLOPs and similar image generation performance.\nTraining from pretrained normal DiTs achieves even better performance with\nsmall training time. The code and checkpoint are at\nhttps://github.com/fudan-generative-vision/PPFlow.", "AI": {"tldr": "PPFlow introduces a pyramidal patchification approach for diffusion transformers (DiTs), varying patch sizes by noise timesteps to optimize computation cost and performance.", "motivation": "To improve efficiency and performance in diffusion transformers by adapting patch sizes dynamically based on noise levels.", "method": "Uses Pyramidal Patchification Flow (PPFlow) with varying patch sizes for different timesteps, learned linear projections, and modified Unpatchify. Operates on full latent representations without renoising.", "result": "Achieves 1.6\u00d7 to 2.0\u00d7 inference speedup over SiT-B/2 with similar performance. Pretrained DiTs show even better results with minimal training time.", "conclusion": "PPFlow effectively balances computation cost and performance, offering a scalable solution for diffusion transformers."}}
{"id": "2503.10995", "pdf": "https://arxiv.org/pdf/2503.10995", "abs": "https://arxiv.org/abs/2503.10995", "authors": ["Nishat Raihan", "Marcos Zampieri"], "title": "TigerLLM - A Family of Bangla Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "The development of Large Language Models (LLMs) remains heavily skewed\ntowards English and a few other high-resource languages. This linguistic\ndisparity is particularly evident for Bangla - the 5th most spoken language. A\nfew initiatives attempted to create open-source Bangla LLMs with performance\nstill behind high-resource languages and limited reproducibility. To address\nthis gap, we introduce TigerLLM - a family of Bangla LLMs. Our results\ndemonstrate that these models surpass all open-source alternatives and also\noutperform larger proprietary models like GPT3.5 across standard benchmarks,\nestablishing TigerLLM as the new baseline for future Bangla language modeling.", "AI": {"tldr": "TigerLLM, a new Bangla LLM, outperforms existing open-source and proprietary models like GPT3.5, setting a new benchmark for Bangla language modeling.", "motivation": "Addressing the linguistic disparity in LLMs, particularly for Bangla, which lacks high-performance open-source models.", "method": "Introducing TigerLLM, a family of Bangla LLMs, and evaluating them against standard benchmarks.", "result": "TigerLLM surpasses all open-source alternatives and outperforms larger proprietary models like GPT3.5.", "conclusion": "TigerLLM establishes a new baseline for Bangla language modeling, bridging the gap in LLM development for low-resource languages."}}
{"id": "2506.24044", "pdf": "https://arxiv.org/pdf/2506.24044", "abs": "https://arxiv.org/abs/2506.24044", "authors": ["Sicong Jiang", "Zilin Huang", "Kangan Qian", "Ziang Luo", "Tianze Zhu", "Yang Zhong", "Yihong Tang", "Menglin Kong", "Yunlong Wang", "Siwen Jiao", "Hao Ye", "Zihao Sheng", "Xin Zhao", "Tuopu Wen", "Zheng Fu", "Sikai Chen", "Kun Jiang", "Diange Yang", "Seongjin Choi", "Lijun Sun"], "title": "A Survey on Vision-Language-Action Models for Autonomous Driving", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "The rapid progress of multimodal large language models (MLLM) has paved the\nway for Vision-Language-Action (VLA) paradigms, which integrate visual\nperception, natural language understanding, and control within a single policy.\nResearchers in autonomous driving are actively adapting these methods to the\nvehicle domain. Such models promise autonomous vehicles that can interpret\nhigh-level instructions, reason about complex traffic scenes, and make their\nown decisions. However, the literature remains fragmented and is rapidly\nexpanding. This survey offers the first comprehensive overview of VLA for\nAutonomous Driving (VLA4AD). We (i) formalize the architectural building blocks\nshared across recent work, (ii) trace the evolution from early explainer to\nreasoning-centric VLA models, and (iii) compare over 20 representative models\naccording to VLA's progress in the autonomous driving domain. We also\nconsolidate existing datasets and benchmarks, highlighting protocols that\njointly measure driving safety, accuracy, and explanation quality. Finally, we\ndetail open challenges - robustness, real-time efficiency, and formal\nverification - and outline future directions of VLA4AD. This survey provides a\nconcise yet complete reference for advancing interpretable socially aligned\nautonomous vehicles. Github repo is available at\n\\href{https://github.com/JohnsonJiang1996/Awesome-VLA4AD}{SicongJiang/Awesome-VLA4AD}.", "AI": {"tldr": "This survey provides a comprehensive overview of Vision-Language-Action (VLA) models for Autonomous Driving (VLA4AD), covering architecture, evolution, model comparisons, datasets, benchmarks, and open challenges.", "motivation": "The rapid expansion of MLLMs and VLAs in autonomous driving has led to fragmented literature, necessitating a consolidated overview to guide future research.", "method": "The survey formalizes architectural building blocks, traces model evolution, compares over 20 representative models, and consolidates datasets and benchmarks.", "result": "It highlights progress in VLA4AD, identifies key protocols for evaluating driving safety and explanation quality, and outlines open challenges like robustness and real-time efficiency.", "conclusion": "The survey serves as a concise reference for advancing interpretable and socially aligned autonomous vehicles, with future directions and a GitHub repo provided."}}
{"id": "2506.22773", "pdf": "https://arxiv.org/pdf/2506.22773", "abs": "https://arxiv.org/abs/2506.22773", "authors": ["Yanran Wu", "Inez Hua", "Yi Ding"], "title": "Not All Water Consumption Is Equal: A Water Stress Weighted Metric for Sustainable Computing", "categories": ["cs.DC", "cs.AR", "cs.CY", "cs.LG"], "comment": "7 pages, 9 figures, HotCarbon '25: Proceedings of the 4th Workshop on\n  Sustainable Computer Systems, Cambridge, Massachusetts (USA), July 10-11th,\n  2025", "summary": "Water consumption is an increasingly critical dimension of computing\nsustainability, especially as AI workloads rapidly scale. However, current\nwater impact assessment often overlooks where and when water stress is more\nsevere. To fill in this gap, we present SCARF, the first general framework that\nevaluates water impact of computing by factoring in both spatial and temporal\nvariations in water stress. SCARF calculates an Adjusted Water Impact (AWI)\nmetric that considers both consumption volume and local water stress over time.\nThrough three case studies on LLM serving, datacenters, and semiconductor\nfabrication plants, we show the hidden opportunities for reducing water impact\nby optimizing location and time choices, paving the way for water-sustainable\ncomputing. The code is available at https://github.com/jojacola/SCARF.", "AI": {"tldr": "SCARF is a framework for assessing water impact in computing by considering spatial and temporal water stress, offering a metric (AWI) and case studies for sustainable optimization.", "motivation": "Current water impact assessments overlook spatial and temporal variations in water stress, which is critical for sustainable computing as AI workloads grow.", "method": "SCARF introduces an Adjusted Water Impact (AWI) metric that accounts for water consumption volume and local water stress over time. It is validated through case studies on LLM serving, datacenters, and semiconductor fabrication.", "result": "The framework reveals opportunities to reduce water impact by optimizing location and timing, demonstrated in three case studies.", "conclusion": "SCARF provides a scalable approach to evaluate and mitigate water impact in computing, promoting sustainability."}}
{"id": "2506.23547", "pdf": "https://arxiv.org/pdf/2506.23547", "abs": "https://arxiv.org/abs/2506.23547", "authors": ["Jiwon Kim", "Soohyun Hwang", "Dong-O Kim", "Changsu Han", "Min Kyu Park", "Chang-Su Kim"], "title": "Oneta: Multi-Style Image Enhancement Using Eigentransformation Functions", "categories": ["cs.CV"], "comment": null, "summary": "The first algorithm, called Oneta, for a novel task of multi-style image\nenhancement is proposed in this work. Oneta uses two point operators\nsequentially: intensity enhancement with a transformation function (TF) and\ncolor correction with a color correction matrix (CCM). This two-step\nenhancement model, though simple, achieves a high performance upper bound.\nAlso, we introduce eigentransformation function (eigenTF) to represent TF\ncompactly. The Oneta network comprises Y-Net and C-Net to predict eigenTF and\nCCM parameters, respectively. To support $K$ styles, Oneta employs $K$\nlearnable tokens. During training, each style token is learned using image\npairs from the corresponding dataset. In testing, Oneta selects one of the $K$\nstyle tokens to enhance an image accordingly. Extensive experiments show that\nthe single Oneta network can effectively undertake six enhancement tasks --\nretouching, image signal processing, low-light image enhancement, dehazing,\nunderwater image enhancement, and white balancing -- across 30 datasets.", "AI": {"tldr": "Oneta is a novel multi-style image enhancement algorithm using a two-step model (intensity enhancement and color correction) with compact representation (eigenTF) and style tokens for diverse tasks.", "motivation": "To address the need for a versatile and high-performance solution for multi-style image enhancement across various tasks.", "method": "Uses two sequential point operators (TF for intensity, CCM for color) with Y-Net and C-Net for parameter prediction. Employs K learnable style tokens for K styles.", "result": "Achieves high performance across six enhancement tasks (e.g., retouching, dehazing) on 30 datasets.", "conclusion": "Oneta is an effective, versatile solution for multi-style image enhancement."}}
{"id": "2503.11655", "pdf": "https://arxiv.org/pdf/2503.11655", "abs": "https://arxiv.org/abs/2503.11655", "authors": ["Donghao Huang", "Zhaoxia Wang"], "title": "Explainable Sentiment Analysis with DeepSeek-R1: Performance, Efficiency, and Few-Shot Learning", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages, 2 figures, 6 tables, revised and re-submitted to an IEEE\n  journal", "summary": "Large language models (LLMs) have transformed sentiment analysis, yet\nbalancing accuracy, efficiency, and explainability remains a critical\nchallenge. This study presents the first comprehensive evaluation of\nDeepSeek-R1--an open-source reasoning model--against OpenAI's GPT-4o and\nGPT-4o-mini. We test the full 671B model and its distilled variants,\nsystematically documenting few-shot learning curves. Our experiments show\nDeepSeek-R1 achieves a 91.39\\% F1 score on 5-class sentiment and 99.31\\%\naccuracy on binary tasks with just 5 shots, an eightfold improvement in\nfew-shot efficiency over GPT-4o. Architecture-specific distillation effects\nemerge, where a 32B Qwen2.5-based model outperforms the 70B Llama-based variant\nby 6.69 percentage points. While its reasoning process reduces throughput,\nDeepSeek-R1 offers superior explainability via transparent, step-by-step\ntraces, establishing it as a powerful, interpretable open-source alternative.", "AI": {"tldr": "DeepSeek-R1, an open-source reasoning model, outperforms GPT-4o in few-shot sentiment analysis with higher efficiency and explainability.", "motivation": "Addressing the challenge of balancing accuracy, efficiency, and explainability in sentiment analysis using LLMs.", "method": "Comprehensive evaluation of DeepSeek-R1 against GPT-4o variants, testing full and distilled models with few-shot learning curves.", "result": "DeepSeek-R1 achieves 91.39% F1 score (5-class) and 99.31% accuracy (binary) with 5 shots, showing 8x efficiency improvement over GPT-4o.", "conclusion": "DeepSeek-R1 is a superior, interpretable open-source alternative for sentiment analysis, despite lower throughput."}}
{"id": "2506.24081", "pdf": "https://arxiv.org/pdf/2506.24081", "abs": "https://arxiv.org/abs/2506.24081", "authors": ["Rahul Kumar", "Wenqi Wei", "Ying Mao", "Junaid Farooq", "Ying Wang", "Juntao Chen"], "title": "SQUASH: A SWAP-Based Quantum Attack to Sabotage Hybrid Quantum Neural Networks", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "Keywords: Quantum Machine Learning, Hybrid Quantum Neural Networks,\n  SWAP Test, Fidelity, Circuit-level Attack", "summary": "We propose a circuit-level attack, SQUASH, a SWAP-Based Quantum Attack to\nsabotage Hybrid Quantum Neural Networks (HQNNs) for classification tasks.\nSQUASH is executed by inserting SWAP gate(s) into the variational quantum\ncircuit of the victim HQNN. Unlike conventional noise-based or adversarial\ninput attacks, SQUASH directly manipulates the circuit structure, leading to\nqubit misalignment and disrupting quantum state evolution. This attack is\nhighly stealthy, as it does not require access to training data or introduce\ndetectable perturbations in input states. Our results demonstrate that SQUASH\nsignificantly degrades classification performance, with untargeted SWAP attacks\nreducing accuracy by up to 74.08\\% and targeted SWAP attacks reducing target\nclass accuracy by up to 79.78\\%. These findings reveal a critical vulnerability\nin HQNN implementations, underscoring the need for more resilient architectures\nagainst circuit-level adversarial interventions.", "AI": {"tldr": "SQUASH is a SWAP-based quantum attack targeting Hybrid Quantum Neural Networks (HQNNs), degrading classification performance by manipulating circuit structure without detectable perturbations.", "motivation": "To expose vulnerabilities in HQNNs by demonstrating how circuit-level attacks can sabotage classification tasks without relying on noisy inputs or adversarial data.", "method": "Inserting SWAP gates into the victim HQNN's variational quantum circuit to cause qubit misalignment and disrupt quantum state evolution.", "result": "Untargeted attacks reduce accuracy by up to 74.08%, while targeted attacks reduce target class accuracy by up to 79.78%.", "conclusion": "HQNNs are vulnerable to stealthy circuit-level attacks like SQUASH, highlighting the need for more resilient quantum architectures."}}
{"id": "2506.22799", "pdf": "https://arxiv.org/pdf/2506.22799", "abs": "https://arxiv.org/abs/2506.22799", "authors": ["Minchao Jiang", "Shunyu Jia", "Jiaming Gu", "Xiaoyuan Lu", "Guangming Zhu", "Anqi Dong", "Liang Zhang"], "title": "VoteSplat: Hough Voting Gaussian Splatting for 3D Scene Understanding", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": "Accepted to ICCV 2025", "summary": "3D Gaussian Splatting (3DGS) has become horsepower in high-quality, real-time\nrendering for novel view synthesis of 3D scenes. However, existing methods\nfocus primarily on geometric and appearance modeling, lacking deeper scene\nunderstanding while also incurring high training costs that complicate the\noriginally streamlined differentiable rendering pipeline. To this end, we\npropose VoteSplat, a novel 3D scene understanding framework that integrates\nHough voting with 3DGS. Specifically, Segment Anything Model (SAM) is utilized\nfor instance segmentation, extracting objects, and generating 2D vote maps. We\nthen embed spatial offset vectors into Gaussian primitives. These offsets\nconstruct 3D spatial votes by associating them with 2D image votes, while depth\ndistortion constraints refine localization along the depth axis. For\nopen-vocabulary object localization, VoteSplat maps 2D image semantics to 3D\npoint clouds via voting points, reducing training costs associated with\nhigh-dimensional CLIP features while preserving semantic unambiguity. Extensive\nexperiments demonstrate effectiveness of VoteSplat in open-vocabulary 3D\ninstance localization, 3D point cloud understanding, click-based 3D object\nlocalization, hierarchical segmentation, and ablation studies. Our code is\navailable at https://sy-ja.github.io/votesplat/", "AI": {"tldr": "VoteSplat integrates Hough voting with 3DGS for 3D scene understanding, reducing training costs and improving localization.", "motivation": "Existing 3DGS methods lack deeper scene understanding and have high training costs.", "method": "Uses SAM for instance segmentation, embeds spatial offsets into Gaussian primitives, and refines depth with distortion constraints.", "result": "Effective in open-vocabulary 3D instance localization, point cloud understanding, and hierarchical segmentation.", "conclusion": "VoteSplat enhances 3D scene understanding while maintaining efficiency."}}
{"id": "2506.23555", "pdf": "https://arxiv.org/pdf/2506.23555", "abs": "https://arxiv.org/abs/2506.23555", "authors": ["Fan Xie", "Pan Cao"], "title": "LH2Face: Loss function for Hard High-quality Face", "categories": ["cs.CV"], "comment": null, "summary": "In current practical face authentication systems, most face recognition (FR)\nalgorithms are based on cosine similarity with softmax classification. Despite\nits reliable classification performance, this method struggles with hard\nsamples. A popular strategy to improve FR performance is incorporating angular\nor cosine margins. However, it does not take face quality or recognition\nhardness into account, simply increasing the margin value and thus causing an\noverly uniform training strategy. To address this problem, a novel loss\nfunction is proposed, named Loss function for Hard High-quality Face (LH2Face).\nFirstly, a similarity measure based on the von Mises-Fisher (vMF) distribution\nis stated, specifically focusing on the logarithm of the Probability Density\nFunction (PDF), which represents the distance between a probability\ndistribution and a vector. Then, an adaptive margin-based multi-classification\nmethod using softmax, called the Uncertainty-Aware Margin Function, is\nimplemented in the article. Furthermore, proxy-based loss functions are used to\napply extra constraints between the proxy and sample to optimize their\nrepresentation space distribution. Finally, a renderer is constructed that\noptimizes FR through face reconstruction and vice versa. Our LH2Face is\nsuperior to similiar schemes on hard high-quality face datasets, achieving\n49.39% accuracy on the IJB-B dataset, which surpasses the second-place method\nby 2.37%.", "AI": {"tldr": "A novel loss function, LH2Face, improves face recognition by addressing hard samples and face quality, outperforming existing methods.", "motivation": "Current face recognition methods struggle with hard samples and ignore face quality, leading to overly uniform training strategies.", "method": "LH2Face uses a vMF-based similarity measure, adaptive margins, proxy-based constraints, and a face reconstruction renderer.", "result": "Achieves 49.39% accuracy on IJB-B, surpassing the second-best method by 2.37%.", "conclusion": "LH2Face effectively addresses hard samples and improves face recognition performance."}}
{"id": "2503.16334", "pdf": "https://arxiv.org/pdf/2503.16334", "abs": "https://arxiv.org/abs/2503.16334", "authors": ["Ying Shen", "Lifu Huang"], "title": "LLM Braces: Straightening Out LLM Predictions with Relevant Sub-Updates", "categories": ["cs.CL"], "comment": "ACL 2025, 16 pages, 2 figures", "summary": "Recent findings reveal that much of the knowledge in a Transformer-based\nLarge Language Model (LLM) is encoded in its feed-forward (FFN) layers, where\neach FNN layer can be interpreted as the summation of sub-updates, each\ncorresponding to a weighted column vector from the FFN's value parameter matrix\nthat often encodes human-interpretable concepts. In light of this, we\nhypothesize that model performance and behaviors can be further enhanced and\ncontrolled by modulating the contributions of these sub-updates based on their\nrelevance to the input or target output style, and propose LLMBRACES, a novel\nand efficient method that computes relevance scores associated with value\nvectors in FFN layers and leverages these scores to dynamically adjust the\ncontribution of sub-updates. By optimizing sub-update contributions, LLMBRACES\nrefines the prediction process, leading to more accurate and reliable outputs,\nmuch like a 'brace' providing support and stability. Moreover, LLMBRACES can be\nextended to support conditional control over generation characteristics, such\nas sentiment, thereby offering fine-grained steering of LLM outputs. Extensive\nexperiments on various LLMs-including Qwen2.5-1.5B, Llama2-7B, and\nLlama3-8B-demonstrate that LLMBRACES outperforms baseline approaches in both\nfine-tuning and zero-shot settings while requiring significantly fewer tunable\nparameters, up to 75% fewer compared to LoRA. Furthermore, LLMBRACES excels in\nsentiment-controlled generation and toxicity reduction, highlighting its\npotential for flexible, controlled text generation across applications.", "AI": {"tldr": "LLMBRACES enhances Transformer-based LLMs by dynamically adjusting FFN sub-updates based on relevance, improving accuracy and control over outputs like sentiment and toxicity.", "motivation": "To improve LLM performance and control by modulating FFN sub-updates, leveraging their interpretable concept encoding.", "method": "Proposes LLMBRACES, which computes relevance scores for FFN value vectors and dynamically adjusts sub-update contributions.", "result": "Outperforms baselines in fine-tuning and zero-shot settings, reduces tunable parameters by 75%, and excels in controlled generation tasks.", "conclusion": "LLMBRACES offers efficient, flexible control over LLM outputs, enhancing accuracy and reliability for diverse applications."}}
{"id": "2506.24085", "pdf": "https://arxiv.org/pdf/2506.24085", "abs": "https://arxiv.org/abs/2506.24085", "authors": ["Wonwoong Cho", "Yanxia Zhang", "Yan-Ying Chen", "David I. Inouye"], "title": "Imagine for Me: Creative Conceptual Blending of Real Images and Text via Blended Attention", "categories": ["cs.CV", "cs.AI"], "comment": "Project website is available at https://imagineforme.github.io/", "summary": "Blending visual and textual concepts into a new visual concept is a unique\nand powerful trait of human beings that can fuel creativity. However, in\npractice, cross-modal conceptual blending for humans is prone to cognitive\nbiases, like design fixation, which leads to local minima in the design space.\nIn this paper, we propose a T2I diffusion adapter \"IT-Blender\" that can\nautomate the blending process to enhance human creativity. Prior works related\nto cross-modal conceptual blending are limited in encoding a real image without\nloss of details or in disentangling the image and text inputs. To address these\ngaps, IT-Blender leverages pretrained diffusion models (SD and FLUX) to blend\nthe latent representations of a clean reference image with those of the noisy\ngenerated image. Combined with our novel blended attention, IT-Blender encodes\nthe real reference image without loss of details and blends the visual concept\nwith the object specified by the text in a disentangled way. Our experiment\nresults show that IT-Blender outperforms the baselines by a large margin in\nblending visual and textual concepts, shedding light on the new application of\nimage generative models to augment human creativity.", "AI": {"tldr": "IT-Blender, a T2I diffusion adapter, automates blending visual and textual concepts to enhance human creativity, outperforming baselines by leveraging pretrained diffusion models and blended attention.", "motivation": "Human cross-modal conceptual blending is prone to cognitive biases like design fixation, limiting creativity. IT-Blender aims to automate and improve this process.", "method": "IT-Blender uses pretrained diffusion models (SD and FLUX) to blend latent representations of a clean reference image with a noisy generated image, employing blended attention for detail preservation and disentanglement.", "result": "IT-Blender significantly outperforms baselines in blending visual and textual concepts, demonstrating its effectiveness.", "conclusion": "IT-Blender showcases the potential of image generative models to augment human creativity by automating cross-modal conceptual blending."}}
{"id": "2506.22851", "pdf": "https://arxiv.org/pdf/2506.22851", "abs": "https://arxiv.org/abs/2506.22851", "authors": ["Arnulf Jentzen", "Konrad Kleinberg", "Thomas Kruse"], "title": "Deep neural networks can provably solve Bellman equations for Markov decision processes without the curse of dimensionality", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA", "math.PR", "stat.ML", "90C40, 90C39, 60J05, 93E20, 65C05, 68T07"], "comment": null, "summary": "Discrete time stochastic optimal control problems and Markov decision\nprocesses (MDPs) are fundamental models for sequential decision-making under\nuncertainty and as such provide the mathematical framework underlying\nreinforcement learning theory. A central tool for solving MDPs is the Bellman\nequation and its solution, the so-called $Q$-function. In this article, we\nconstruct deep neural network (DNN) approximations for $Q$-functions associated\nto MDPs with infinite time horizon and finite control set $A$. More\nspecifically, we show that if the the payoff function and the random transition\ndynamics of the MDP can be suitably approximated by DNNs with leaky rectified\nlinear unit (ReLU) activation, then the solutions $Q_d\\colon \\mathbb R^d\\to\n\\mathbb R^{|A|}$, $d\\in \\mathbb{N}$, of the associated Bellman equations can\nalso be approximated in the $L^2$-sense by DNNs with leaky ReLU activation\nwhose numbers of parameters grow at most polynomially in both the dimension\n$d\\in \\mathbb{N}$ of the state space and the reciprocal $1/\\varepsilon$ of the\nprescribed error $\\varepsilon\\in (0,1)$. Our proof relies on the recently\nintroduced full-history recursive multilevel fixed-point (MLFP) approximation\nscheme.", "AI": {"tldr": "The paper constructs deep neural network (DNN) approximations for Q-functions in Markov decision processes (MDPs) with infinite time horizons, showing polynomial growth in parameters for state space dimension and error tolerance.", "motivation": "To address the challenge of approximating Q-functions in MDPs, leveraging DNNs for scalable and efficient solutions.", "method": "Uses DNNs with leaky ReLU activation to approximate Q-functions, relying on the MLFP approximation scheme for proof.", "result": "Demonstrates that Q-functions can be approximated in the L\u00b2-sense with polynomial parameter growth in state dimension and error tolerance.", "conclusion": "DNNs with leaky ReLU activation are effective for approximating Q-functions in MDPs, offering scalable solutions."}}
{"id": "2506.23565", "pdf": "https://arxiv.org/pdf/2506.23565", "abs": "https://arxiv.org/abs/2506.23565", "authors": ["Mingqian Ji", "Jian Yang", "Shanshan Zhang"], "title": "OcRFDet: Object-Centric Radiance Fields for Multi-View 3D Object Detection in Autonomous Driving", "categories": ["cs.CV"], "comment": "Accepted by ICCV2025", "summary": "Current multi-view 3D object detection methods typically transfer 2D features\ninto 3D space using depth estimation or 3D position encoder, but in a fully\ndata-driven and implicit manner, which limits the detection performance.\nInspired by the success of radiance fields on 3D reconstruction, we assume they\ncan be used to enhance the detector's ability of 3D geometry estimation.\nHowever, we observe a decline in detection performance, when we directly use\nthem for 3D rendering as an auxiliary task. From our analysis, we find the\nperformance drop is caused by the strong responses on the background when\nrendering the whole scene. To address this problem, we propose object-centric\nradiance fields, focusing on modeling foreground objects while discarding\nbackground noises. Specifically, we employ Object-centric Radiance Fields\n(OcRF) to enhance 3D voxel features via an auxiliary task of rendering\nforeground objects. We further use opacity - the side-product of rendering- to\nenhance the 2D foreground BEV features via Height-aware Opacity-based Attention\n(HOA), where attention maps at different height levels are generated separately\nvia multiple networks in parallel. Extensive experiments on the nuScenes\nvalidation and test datasets demonstrate that our OcRFDet achieves superior\nperformance, outperforming previous state-of-the-art methods with 57.2$\\%$ mAP\nand 64.8$\\%$ NDS on the nuScenes test benchmark. Code will be available at\nhttps://github.com/Mingqj/OcRFDet.", "AI": {"tldr": "The paper proposes Object-centric Radiance Fields (OcRF) to improve 3D object detection by focusing on foreground objects and avoiding background noise, achieving state-of-the-art results.", "motivation": "Current methods for multi-view 3D object detection rely on implicit, data-driven approaches, limiting performance. Radiance fields, successful in 3D reconstruction, are explored but initially degrade detection due to background interference.", "method": "The authors introduce OcRF to enhance 3D voxel features by rendering foreground objects and use Height-aware Opacity-based Attention (HOA) to improve 2D BEV features.", "result": "OcRFDet achieves 57.2% mAP and 64.8% NDS on nuScenes, outperforming prior methods.", "conclusion": "Focusing on foreground objects with OcRF and HOA significantly improves 3D object detection performance."}}
{"id": "2503.17222", "pdf": "https://arxiv.org/pdf/2503.17222", "abs": "https://arxiv.org/abs/2503.17222", "authors": ["Sonish Sivarajkumar", "Kimia Ameri", "Chuqin Li", "Yanshan Wang", "Min Jiang"], "title": "Automating Adjudication of Cardiovascular Events Using Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Cardiovascular events, such as heart attacks and strokes, remain a leading\ncause of mortality globally, necessitating meticulous monitoring and\nadjudication in clinical trials. This process, traditionally performed manually\nby clinical experts, is time-consuming, resource-intensive, and prone to\ninter-reviewer variability, potentially introducing bias and hindering trial\nprogress. This study addresses these critical limitations by presenting a novel\nframework for automating the adjudication of cardiovascular events in clinical\ntrials using Large Language Models (LLMs). We developed a two-stage approach:\nfirst, employing an LLM-based pipeline for event information extraction from\nunstructured clinical data and second, using an LLM-based adjudication process\nguided by a Tree of Thoughts approach and clinical endpoint committee (CEC)\nguidelines. Using cardiovascular event-specific clinical trial data, the\nframework achieved an F1-score of 0.82 for event extraction and an accuracy of\n0.68 for adjudication. Furthermore, we introduce the CLEART score, a novel,\nautomated metric specifically designed for evaluating the quality of\nAI-generated clinical reasoning in adjudicating cardiovascular events. This\napproach demonstrates significant potential for substantially reducing\nadjudication time and costs while maintaining high-quality, consistent, and\nauditable outcomes in clinical trials. The reduced variability and enhanced\nstandardization also allow for faster identification and mitigation of risks\nassociated with cardiovascular therapies.", "AI": {"tldr": "A novel LLM-based framework automates cardiovascular event adjudication in clinical trials, improving efficiency and consistency.", "motivation": "Manual adjudication of cardiovascular events is slow, costly, and inconsistent, prompting the need for automation.", "method": "A two-stage LLM approach: event extraction from unstructured data and adjudication guided by CEC guidelines and Tree of Thoughts.", "result": "Achieved F1-score of 0.82 for extraction and 0.68 accuracy for adjudication, with the CLEART score introduced for evaluation.", "conclusion": "The framework reduces time, cost, and variability while maintaining high-quality outcomes in clinical trials."}}
{"id": "2506.24108", "pdf": "https://arxiv.org/pdf/2506.24108", "abs": "https://arxiv.org/abs/2506.24108", "authors": ["Shai Yehezkel", "Omer Dahary", "Andrey Voynov", "Daniel Cohen-Or"], "title": "Navigating with Annealing Guidance Scale in Diffusion Space", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG"], "comment": "Project page:\n  https://annealing-guidance.github.io/annealing-guidance/", "summary": "Denoising diffusion models excel at generating high-quality images\nconditioned on text prompts, yet their effectiveness heavily relies on careful\nguidance during the sampling process. Classifier-Free Guidance (CFG) provides a\nwidely used mechanism for steering generation by setting the guidance scale,\nwhich balances image quality and prompt alignment. However, the choice of the\nguidance scale has a critical impact on the convergence toward a visually\nappealing and prompt-adherent image. In this work, we propose an annealing\nguidance scheduler which dynamically adjusts the guidance scale over time based\non the conditional noisy signal. By learning a scheduling policy, our method\naddresses the temperamental behavior of CFG. Empirical results demonstrate that\nour guidance scheduler significantly enhances image quality and alignment with\nthe text prompt, advancing the performance of text-to-image generation.\nNotably, our novel scheduler requires no additional activations or memory\nconsumption, and can seamlessly replace the common classifier-free guidance,\noffering an improved trade-off between prompt alignment and quality.", "AI": {"tldr": "Proposes an annealing guidance scheduler to dynamically adjust the guidance scale in diffusion models, improving image quality and prompt alignment without extra memory costs.", "motivation": "The effectiveness of Classifier-Free Guidance (CFG) in diffusion models depends on the guidance scale, which is manually set and can lead to suboptimal results.", "method": "Introduces an annealing guidance scheduler that learns to dynamically adjust the guidance scale based on the conditional noisy signal.", "result": "Empirical results show improved image quality and better alignment with text prompts, outperforming standard CFG.", "conclusion": "The proposed scheduler enhances text-to-image generation by optimizing the guidance scale dynamically, offering a better trade-off between quality and prompt adherence."}}
{"id": "2506.22935", "pdf": "https://arxiv.org/pdf/2506.22935", "abs": "https://arxiv.org/abs/2506.22935", "authors": ["Marc Bara Iniesta"], "title": "Differentiable Radar Ambiguity Functions: Mathematical Formulation and Computational Implementation", "categories": ["eess.SP", "cs.LG", "cs.NA", "math.NA", "94A12, 65T50, 68T05", "F.2.1; I.2.6; G.1.0"], "comment": "16 pages, 4 figures, source code available at\n  https://github.com/marcbara/graf-psl-lpi (DOI: 10.5281/zenodo.15763301)", "summary": "The ambiguity function is fundamental to radar waveform design,\ncharacterizing range and Doppler resolution capabilities. However, its\ntraditional formulation involves non-differentiable operations, preventing\nintegration with gradient-based optimization methods and modern machine\nlearning frameworks. This paper presents the first complete mathematical\nframework and computational implementation for differentiable radar ambiguity\nfunctions. Our approach addresses the fundamental technical challenges that\nhave prevented the radar community from leveraging automatic differentiation:\nproper handling of complex-valued gradients using Wirtinger calculus, efficient\ncomputation through parallelized FFT operations, numerical stability throughout\ncascaded operations, and composability with arbitrary differentiable\noperations. We term this approach GRAF (Gradient-based Radar Ambiguity\nFunctions), which reformulates the ambiguity function computation to maintain\nmathematical equivalence while enabling gradient flow through the entire\npipeline. The resulting implementation provides a general-purpose\ndifferentiable ambiguity function compatible with modern automatic\ndifferentiation frameworks, enabling new research directions including neural\nnetwork-based waveform generation with ambiguity constraints, end-to-end\noptimization of radar systems, and integration of classical radar theory with\nmodern deep learning. We provide complete implementation details and\ndemonstrate computational efficiency suitable for practical applications. This\nwork establishes the mathematical and computational foundation for applying\nmodern machine learning techniques to radar waveform design, bridging classical\nradar signal processing with automatic differentiation frameworks.", "AI": {"tldr": "The paper introduces GRAF, a differentiable radar ambiguity function framework, enabling gradient-based optimization and integration with modern machine learning.", "motivation": "Traditional radar ambiguity functions are non-differentiable, limiting their use with gradient-based methods and modern ML frameworks.", "method": "GRAF reformulates the ambiguity function using Wirtinger calculus, parallelized FFTs, and ensures numerical stability and composability.", "result": "GRAF provides a differentiable, efficient, and general-purpose ambiguity function compatible with automatic differentiation frameworks.", "conclusion": "This work bridges classical radar signal processing with modern ML, enabling new research in waveform design and radar system optimization."}}
{"id": "2506.23566", "pdf": "https://arxiv.org/pdf/2506.23566", "abs": "https://arxiv.org/abs/2506.23566", "authors": ["Luigi Sigillo", "Renato Giamba", "Danilo Comminiello"], "title": "Metadata, Wavelet, and Time Aware Diffusion Models for Satellite Image Super Resolution", "categories": ["cs.CV", "cs.LG"], "comment": "ICLR 2025 Workshop on Machine Learning for Remote Sensing (ML4RS)", "summary": "The acquisition of high-resolution satellite imagery is often constrained by\nthe spatial and temporal limitations of satellite sensors, as well as the high\ncosts associated with frequent observations. These challenges hinder\napplications such as environmental monitoring, disaster response, and\nagricultural management, which require fine-grained and high-resolution data.\nIn this paper, we propose MWT-Diff, an innovative framework for satellite image\nsuper-resolution (SR) that combines latent diffusion models with wavelet\ntransforms to address these challenges. At the core of the framework is a novel\nmetadata-, wavelet-, and time-aware encoder (MWT-Encoder), which generates\nembeddings that capture metadata attributes, multi-scale frequency information,\nand temporal relationships. The embedded feature representations steer the\nhierarchical diffusion dynamics, through which the model progressively\nreconstructs high-resolution satellite imagery from low-resolution inputs. This\nprocess preserves critical spatial characteristics including textural patterns,\nboundary discontinuities, and high-frequency spectral components essential for\ndetailed remote sensing analysis. The comparative analysis of MWT-Diff across\nmultiple datasets demonstrated favorable performance compared to recent\napproaches, as measured by standard perceptual quality metrics including FID\nand LPIPS.", "AI": {"tldr": "MWT-Diff is a framework for satellite image super-resolution using latent diffusion models and wavelet transforms, outperforming recent methods in perceptual quality.", "motivation": "High-resolution satellite imagery is limited by sensor constraints and high costs, hindering applications like environmental monitoring and disaster response.", "method": "Combines latent diffusion models with wavelet transforms, using a metadata-, wavelet-, and time-aware encoder (MWT-Encoder) to guide hierarchical diffusion dynamics for image reconstruction.", "result": "MWT-Diff outperforms recent approaches in perceptual quality metrics (FID, LPIPS) across multiple datasets.", "conclusion": "The framework effectively reconstructs high-resolution satellite imagery while preserving critical spatial characteristics."}}
{"id": "2504.04745", "pdf": "https://arxiv.org/pdf/2504.04745", "abs": "https://arxiv.org/abs/2504.04745", "authors": ["Ankush Raut", "Xiaofeng Zhu", "Maria Leonor Pacheco"], "title": "Can LLMs Interpret and Leverage Structured Linguistic Representations? A Case Study with AMRs", "categories": ["cs.CL"], "comment": "13 pages, 23 figures. Accepted to XLLM Workshop at ACL 2025", "summary": "This paper evaluates the ability of Large Language Models (LLMs) to leverage\ncontextual information in the form of structured linguistic representations.\nSpecifically, we examine the impact of encoding both short and long contexts\nusing Abstract Meaning Representation (AMR) structures across a diverse set of\nlanguage tasks. We perform our analysis using 8-bit quantized and\ninstruction-tuned versions of Llama 3.1 (8B), Phi-3, and Mistral 7B. Our\nresults indicate that, for tasks involving short contexts, augmenting the\nprompt with the AMR of the original language context often degrades the\nperformance of the underlying LLM. However, for tasks that involve long\ncontexts, such as dialogue summarization in the SAMSum dataset, this\nenhancement improves LLM performance, for example, by increasing the zero-shot\ncosine similarity score of Llama 3.1 from 66% to 76%. This improvement is more\nevident in the newer and larger LLMs, but does not extend to the older or\nsmaller ones. In addition, we observe that LLMs can effectively reconstruct the\noriginal text from a linearized AMR, achieving a cosine similarity of 81% in\nthe best-case scenario.", "AI": {"tldr": "The paper evaluates how LLMs use structured linguistic representations (AMR) for tasks. Short-context tasks degrade performance, while long-context tasks (e.g., summarization) improve, especially in newer/larger models. AMR-to-text reconstruction is also effective.", "motivation": "To assess the impact of structured linguistic representations (AMR) on LLM performance across varying context lengths.", "method": "Analyzed 8-bit quantized and instruction-tuned LLMs (Llama 3.1, Phi-3, Mistral 7B) using AMR for short and long contexts.", "result": "Short-context tasks worsened with AMR, but long-context tasks (e.g., summarization) improved, especially in newer/larger models. AMR-to-text reconstruction achieved 81% similarity.", "conclusion": "AMR benefits long-context tasks in advanced LLMs but harms short-context ones. AMR-to-text reconstruction is effective."}}
{"id": "2506.24125", "pdf": "https://arxiv.org/pdf/2506.24125", "abs": "https://arxiv.org/abs/2506.24125", "authors": ["Jiacheng Cui", "Xinyue Bi", "Yaxin Luo", "Xiaohan Zhao", "Jiacheng Liu", "Zhiqiang Shen"], "title": "FADRM: Fast and Accurate Data Residual Matching for Dataset Distillation", "categories": ["cs.CV", "cs.AI"], "comment": "Code at: https://github.com/Jiacheng8/FADRM", "summary": "Residual connection has been extensively studied and widely applied at the\nmodel architecture level. However, its potential in the more challenging\ndata-centric approaches remains unexplored. In this work, we introduce the\nconcept of Data Residual Matching for the first time, leveraging data-level\nskip connections to facilitate data generation and mitigate data information\nvanishing. This approach maintains a balance between newly acquired knowledge\nthrough pixel space optimization and existing core local information\nidentification within raw data modalities, specifically for the dataset\ndistillation task. Furthermore, by incorporating optimization-level\nrefinements, our method significantly improves computational efficiency,\nachieving superior performance while reducing training time and peak GPU memory\nusage by 50%. Consequently, the proposed method Fast and Accurate Data Residual\nMatching for Dataset Distillation (FADRM) establishes a new state-of-the-art,\ndemonstrating substantial improvements over existing methods across multiple\ndataset benchmarks in both efficiency and effectiveness. For instance, with\nResNet-18 as the student model and a 0.8% compression ratio on ImageNet-1K, the\nmethod achieves 47.7% test accuracy in single-model dataset distillation and\n50.0% in multi-model dataset distillation, surpassing RDED by +5.7% and\noutperforming state-of-the-art multi-model approaches, EDC and CV-DD, by +1.4%\nand +4.0%. Code is available at: https://github.com/Jiacheng8/FADRM.", "AI": {"tldr": "The paper introduces Data Residual Matching (FADRM) for dataset distillation, leveraging data-level skip connections to improve efficiency and accuracy, achieving state-of-the-art results.", "motivation": "To explore the untapped potential of residual connections in data-centric approaches, specifically for dataset distillation, addressing data information vanishing and computational inefficiency.", "method": "Proposes Data Residual Matching, combining data-level skip connections with optimization-level refinements to balance new knowledge and core local information.", "result": "Achieves 47.7% test accuracy (single-model) and 50.0% (multi-model) on ImageNet-1K, with a 50% reduction in training time and GPU memory usage.", "conclusion": "FADRM sets a new benchmark for dataset distillation, outperforming existing methods in both efficiency and effectiveness."}}
{"id": "2506.22938", "pdf": "https://arxiv.org/pdf/2506.22938", "abs": "https://arxiv.org/abs/2506.22938", "authors": ["Zaydon L. Ali", "Wassan Saad Abduljabbar Hayale", "Israa Ibraheem Al_Barazanchi", "Ravi Sekhar", "Pritesh Shah", "Sushma Parihar"], "title": "Efficient Cybersecurity Assessment Using SVM and Fuzzy Evidential Reasoning for Resilient Infrastructure", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "With current advancement in hybermedia knowledges, the privacy of digital\ninformation has developed a critical problem. To overawed the susceptibilities\nof present security protocols, scholars tend to focus mainly on efforts on\nalternation of current protocols. Over past decade, various proposed encoding\nmodels have been shown insecurity, leading to main threats against significant\ndata. Utilizing the suitable encryption model is very vital means of guard\nagainst various such, but algorithm is selected based on the dependency of data\nwhich need to be secured. Moreover, testing potentiality of the security\nassessment one by one to identify the best choice can take a vital time for\nprocessing. For faster and precisive identification of assessment algorithm, we\nsuggest a security phase exposure model for cipher encryption technique by\ninvoking Support Vector Machine (SVM). In this work, we form a dataset using\nusual security components like contrast, homogeneity. To overcome the\nuncertainty in analysing the security and lack of ability of processing data to\na risk assessment mechanism. To overcome with such complications, this paper\nproposes an assessment model for security issues using fuzzy evidential\nreasoning (ER) approaches. Significantly, the model can be utilised to process\nand assemble risk assessment data on various aspects in systematic ways. To\nestimate the performance of our framework, we have various analyses like,\nrecall, F1 score and accuracy.", "AI": {"tldr": "The paper proposes a security assessment model for cipher encryption using SVM and fuzzy evidential reasoning to address vulnerabilities in current protocols and improve efficiency in algorithm selection.", "motivation": "Current security protocols are vulnerable, and existing encryption models are insecure, posing threats to data. Testing algorithms individually is time-consuming.", "method": "The authors use SVM for faster algorithm identification and fuzzy evidential reasoning for risk assessment, creating a dataset with security components like contrast and homogeneity.", "result": "The model systematically processes risk assessment data, with performance evaluated using recall, F1 score, and accuracy metrics.", "conclusion": "The proposed framework efficiently assesses security risks and improves the selection of encryption algorithms, addressing uncertainties in security analysis."}}
{"id": "2506.23575", "pdf": "https://arxiv.org/pdf/2506.23575", "abs": "https://arxiv.org/abs/2506.23575", "authors": ["Nuo Chen", "Chao Xiao", "Yimian Dai", "Shiman He", "Miao Li", "Wei An"], "title": "Event-based Tiny Object Detection: A Benchmark Dataset and Baseline", "categories": ["cs.CV"], "comment": null, "summary": "Small object detection (SOD) in anti-UAV task is a challenging problem due to\nthe small size of UAVs and complex backgrounds. Traditional frame-based cameras\nstruggle to detect small objects in complex environments due to their low frame\nrates, limited dynamic range, and data redundancy. Event cameras, with\nmicrosecond temporal resolution and high dynamic range, provide a more\neffective solution for SOD. However, existing event-based object detection\ndatasets are limited in scale, feature large targets size, and lack diverse\nbackgrounds, making them unsuitable for SOD benchmarks. In this paper, we\nintroduce a Event-based Small object detection (EVSOD) dataset (namely EV-UAV),\nthe first large-scale, highly diverse benchmark for anti-UAV tasks. It includes\n147 sequences with over 2.3 million event-level annotations, featuring\nextremely small targets (averaging 6.8 $\\times$ 5.4 pixels) and diverse\nscenarios such as urban clutter and extreme lighting conditions. Furthermore,\nbased on the observation that small moving targets form continuous curves in\nspatiotemporal event point clouds, we propose Event based Sparse Segmentation\nNetwork (EV-SpSegNet), a novel baseline for event segmentation in point cloud\nspace, along with a Spatiotemporal Correlation (STC) loss that leverages motion\ncontinuity to guide the network in retaining target events. Extensive\nexperiments on the EV-UAV dataset demonstrate the superiority of our method and\nprovide a benchmark for future research in EVSOD. The dataset and code are at\nhttps://github.com/ChenYichen9527/Ev-UAV.", "AI": {"tldr": "The paper introduces EV-UAV, the first large-scale event-based dataset for small object detection (SOD) in anti-UAV tasks, and proposes EV-SpSegNet, a novel baseline method with a Spatiotemporal Correlation loss for improved performance.", "motivation": "Traditional cameras struggle with SOD due to low frame rates and data redundancy, while existing event-based datasets lack diversity and small targets.", "method": "Proposes EV-SpSegNet, a sparse segmentation network for event point clouds, and a Spatiotemporal Correlation loss to leverage motion continuity.", "result": "EV-SpSegNet outperforms on the EV-UAV dataset, featuring 2.3M annotations and small targets (6.8x5.4 pixels).", "conclusion": "The EV-UAV dataset and EV-SpSegNet provide a benchmark for future SOD research in event-based anti-UAV tasks."}}
{"id": "2504.12563", "pdf": "https://arxiv.org/pdf/2504.12563", "abs": "https://arxiv.org/abs/2504.12563", "authors": ["Haris Riaz", "Sourav Bhabesh", "Vinayak Arannil", "Miguel Ballesteros", "Graham Horwood"], "title": "MetaSynth: Meta-Prompting-Driven Agentic Scaffolds for Diverse Synthetic Data Generation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "33 pages, 17 figures. Findings of ACL 2025", "summary": "Recent smaller language models such Phi-3.5 and Phi-4 rely on synthetic data\ngenerated using larger Language models. Questions remain about leveraging\nsynthetic data for other use cases, such as adapting LLMs to specific domains.\nA key limitation of synthetic data is low diversity, which negatively impacts\nits downstream applicability for improving other models. To address this, we\npropose MetaSynth, a method for generating synthetic data that enhances\ndiversity through meta-prompting, where a language model orchestrates multiple\n\"expert\" LLM agents to collaboratively generate data. Using only 25 million\ntokens of synthetic data generated with MetaSynth, we successfully adapt a\nwell-trained LLM (Mistral-7B-v0.3) to two specialized domains-Finance and\nBiomedicine-without compromising the capabilities of the resulting model in\ngeneral tasks. In addition, we evaluate the diversity of our synthetic data\nusing seven automated metrics, and find that it approaches the diversity of LLM\npre-training corpora.\n  Continually pre-training Mistral-7B-v0.3 with MetaSynth notably outperforms\nthe base LLM, showing improvements of up to 4.08% in Finance and 13.75% in\nBiomedicine. The same model shows degraded performance when trained on data\ngenerated using a template prompt, even when the template includes prior\ngenerations and varying In-Context exemplars of real data. Our findings suggest\nthat a few million tokens of diverse synthetic data without mixing any real\ndata, is sufficient for effective domain adaptation when using MetaSynth.", "AI": {"tldr": "MetaSynth enhances synthetic data diversity for domain adaptation, improving LLM performance in specialized domains like Finance and Biomedicine without compromising general capabilities.", "motivation": "Addressing the low diversity in synthetic data generated by larger language models, which limits its applicability for domain adaptation.", "method": "Proposes MetaSynth, using meta-prompting to orchestrate multiple expert LLM agents for diverse synthetic data generation.", "result": "MetaSynth-generated data improves Mistral-7B-v0.3 performance by 4.08% in Finance and 13.75% in Biomedicine, outperforming template-based synthetic data.", "conclusion": "Diverse synthetic data from MetaSynth is effective for domain adaptation, requiring no real data mixing."}}
{"id": "2402.18784", "pdf": "https://arxiv.org/pdf/2402.18784", "abs": "https://arxiv.org/abs/2402.18784", "authors": ["Yi Zeng", "Feifei Zhao", "Yuxuan Zhao", "Dongcheng Zhao", "Enmeng Lu", "Qian Zhang", "Yuwei Wang", "Hui Feng", "Zhuoya Zhao", "Jihang Wang", "Qingqun Kong", "Yinqian Sun", "Yang Li", "Guobin Shen", "Bing Han", "Yiting Dong", "Wenxuan Pan", "Xiang He", "Aorigele Bao", "Jin Wang"], "title": "Brain-inspired and Self-based Artificial Intelligence", "categories": ["cs.AI", "q-bio.NC"], "comment": null, "summary": "The question \"Can machines think?\" and the Turing Test to assess whether\nmachines could achieve human-level intelligence is one of the roots of AI. With\nthe philosophical argument \"I think, therefore I am\", this paper challenge the\nidea of a \"thinking machine\" supported by current AIs since there is no sense\nof self in them. Current artificial intelligence is only seemingly intelligent\ninformation processing and does not truly understand or be subjectively aware\nof oneself and perceive the world with the self as human intelligence does. In\nthis paper, we introduce a Brain-inspired and Self-based Artificial\nIntelligence (BriSe AI) paradigm. This BriSe AI paradigm is dedicated to\ncoordinating various cognitive functions and learning strategies in a\nself-organized manner to build human-level AI models and robotic applications.\nSpecifically, BriSe AI emphasizes the crucial role of the Self in shaping the\nfuture AI, rooted with a practical hierarchical Self framework, including\nPerception and Learning, Bodily Self, Autonomous Self, Social Self, and\nConceptual Self. The hierarchical framework of the Self highlights self-based\nenvironment perception, self-bodily modeling, autonomous interaction with the\nenvironment, social interaction and collaboration with others, and even more\nabstract understanding of the Self. Furthermore, the positive mutual promotion\nand support among multiple levels of Self, as well as between Self and\nlearning, enhance the BriSe AI's conscious understanding of information and\nflexible adaptation to complex environments, serving as a driving force\npropelling BriSe AI towards real Artificial General Intelligence.", "AI": {"tldr": "The paper critiques current AI for lacking self-awareness and proposes a Brain-inspired and Self-based AI (BriSe AI) paradigm to achieve human-level intelligence through a hierarchical Self framework.", "motivation": "To address the lack of self-awareness in current AI and advance towards Artificial General Intelligence (AGI) by integrating a self-based approach.", "method": "Introduces the BriSe AI paradigm with a hierarchical Self framework, including Perception and Learning, Bodily Self, Autonomous Self, Social Self, and Conceptual Self.", "result": "BriSe AI enhances conscious understanding and adaptability, promoting progress toward AGI.", "conclusion": "The Self framework is crucial for developing human-level AI, bridging the gap between current AI and true intelligence."}}
{"id": "2506.22963", "pdf": "https://arxiv.org/pdf/2506.22963", "abs": "https://arxiv.org/abs/2506.22963", "authors": ["Kevin Lam", "William Daniels", "J Maxwell Douglas", "Daniel Lai", "Samuel Aparicio", "Benjamin Bloem-Reddy", "Yongjin Park"], "title": "CN-SBM: Categorical Block Modelling For Primary and Residual Copy Number Variation", "categories": ["stat.ML", "cs.LG", "q-bio.GN"], "comment": "8 pages, 4 figures", "summary": "Cancer is a genetic disorder whose clonal evolution can be monitored by\ntracking noisy genome-wide copy number variants. We introduce the Copy Number\nStochastic Block Model (CN-SBM), a probabilistic framework that jointly\nclusters samples and genomic regions based on discrete copy number states using\na bipartite categorical block model. Unlike models relying on Gaussian or\nPoisson assumptions, CN-SBM respects the discrete nature of CNV calls and\ncaptures subpopulation-specific patterns through block-wise structure. Using a\ntwo-stage approach, CN-SBM decomposes CNV data into primary and residual\ncomponents, enabling detection of both large-scale chromosomal alterations and\nfiner aberrations. We derive a scalable variational inference algorithm for\napplication to large cohorts and high-resolution data. Benchmarks on simulated\nand real datasets show improved model fit over existing methods. Applied to\nTCGA low-grade glioma data, CN-SBM reveals clinically relevant subtypes and\nstructured residual variation, aiding patient stratification in survival\nanalysis. These results establish CN-SBM as an interpretable, scalable\nframework for CNV analysis with direct relevance for tumor heterogeneity and\nprognosis.", "AI": {"tldr": "CN-SBM is a probabilistic framework for clustering cancer samples and genomic regions using discrete copy number states, outperforming existing methods and revealing clinically relevant subtypes.", "motivation": "Cancer's clonal evolution can be tracked via noisy copy number variants (CNVs), but existing models often rely on Gaussian or Poisson assumptions, which don't fully capture the discrete nature of CNV data.", "method": "CN-SBM uses a bipartite categorical block model to cluster samples and genomic regions, decomposing CNV data into primary and residual components for detecting large-scale and finer aberrations. A scalable variational inference algorithm is derived for large datasets.", "result": "Benchmarks show improved model fit over existing methods. Applied to TCGA low-grade glioma data, CN-SBM identifies clinically relevant subtypes and structured residual variation, aiding patient stratification.", "conclusion": "CN-SBM is an interpretable, scalable framework for CNV analysis, with direct implications for understanding tumor heterogeneity and improving prognosis."}}
{"id": "2506.23577", "pdf": "https://arxiv.org/pdf/2506.23577", "abs": "https://arxiv.org/abs/2506.23577", "authors": ["Yanning Hou", "Yanran Ruan", "Junfa Li", "Shanshan Wang", "Jianfeng Qiu", "Ke Xu"], "title": "StackCLIP: Clustering-Driven Stacked Prompt in Zero-Shot Industrial Anomaly Detection", "categories": ["cs.CV"], "comment": null, "summary": "Enhancing the alignment between text and image features in the CLIP model is\na critical challenge in zero-shot industrial anomaly detection tasks. Recent\nstudies predominantly utilize specific category prompts during pretraining,\nwhich can cause overfitting to the training categories and limit model\ngeneralization. To address this, we propose a method that transforms category\nnames through multicategory name stacking to create stacked prompts, forming\nthe basis of our StackCLIP model. Our approach introduces two key components.\nThe Clustering-Driven Stacked Prompts (CSP) module constructs generic prompts\nby stacking semantically analogous categories, while utilizing multi-object\ntextual feature fusion to amplify discriminative anomalies among similar\nobjects. The Ensemble Feature Alignment (EFA) module trains knowledge-specific\nlinear layers tailored for each stack cluster and adaptively integrates them\nbased on the attributes of test categories. These modules work together to\ndeliver superior training speed, stability, and convergence, significantly\nboosting anomaly segmentation performance. Additionally, our stacked prompt\nframework offers robust generalization across classification tasks. To further\nimprove performance, we introduce the Regulating Prompt Learning (RPL) module,\nwhich leverages the generalization power of stacked prompts to refine prompt\nlearning, elevating results in anomaly detection classification tasks.\nExtensive testing on seven industrial anomaly detection datasets demonstrates\nthat our method achieves state-of-the-art performance in both zero-shot anomaly\ndetection and segmentation tasks.", "AI": {"tldr": "The paper proposes StackCLIP, a method using stacked prompts to enhance CLIP's text-image alignment for zero-shot industrial anomaly detection, improving generalization and performance.", "motivation": "Addressing overfitting and limited generalization in CLIP due to specific category prompts during pretraining.", "method": "Uses multicategory name stacking for prompts (CSP module) and ensemble feature alignment (EFA module) for training. Introduces RPL module to refine prompt learning.", "result": "Achieves state-of-the-art performance in zero-shot anomaly detection and segmentation on seven datasets.", "conclusion": "StackCLIP enhances CLIP's generalization and performance in industrial anomaly detection tasks."}}
{"id": "2504.14154", "pdf": "https://arxiv.org/pdf/2504.14154", "abs": "https://arxiv.org/abs/2504.14154", "authors": ["Zhiyuan Wang", "Qingni Wang", "Yue Zhang", "Tianlong Chen", "Xiaofeng Zhu", "Xiaoshuang Shi", "Kaidi Xu"], "title": "SConU: Selective Conformal Uncertainty in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "comment": "Accepted by ACL 2025 Main", "summary": "As large language models are increasingly utilized in real-world\napplications, guarantees of task-specific metrics are essential for their\nreliable deployment. Previous studies have introduced various criteria of\nconformal uncertainty grounded in split conformal prediction, which offer\nuser-specified correctness coverage. However, existing frameworks often fail to\nidentify uncertainty data outliers that violate the exchangeability assumption,\nleading to unbounded miscoverage rates and unactionable prediction sets. In\nthis paper, we propose a novel approach termed Selective Conformal Uncertainty\n(SConU), which, for the first time, implements significance tests, by\ndeveloping two conformal p-values that are instrumental in determining whether\na given sample deviates from the uncertainty distribution of the calibration\nset at a specific manageable risk level. Our approach not only facilitates\nrigorous management of miscoverage rates across both single-domain and\ninterdisciplinary contexts, but also enhances the efficiency of predictions.\nFurthermore, we comprehensively analyze the components of the conformal\nprocedures, aiming to approximate conditional coverage, particularly in\nhigh-stakes question-answering tasks.", "AI": {"tldr": "The paper introduces Selective Conformal Uncertainty (SConU), a method using conformal p-values to manage miscoverage rates and improve prediction efficiency in large language models.", "motivation": "To address the limitations of existing conformal uncertainty frameworks, which fail to handle outliers violating exchangeability, leading to unreliable miscoverage rates.", "method": "Develops two conformal p-values to test sample deviations from the calibration set's uncertainty distribution, enabling rigorous miscoverage rate management.", "result": "SConU improves prediction efficiency and manages miscoverage rates effectively in single-domain and interdisciplinary contexts.", "conclusion": "The proposed SConU method enhances the reliability of large language models by approximating conditional coverage, especially in high-stakes tasks."}}
{"id": "2404.09848", "pdf": "https://arxiv.org/pdf/2404.09848", "abs": "https://arxiv.org/abs/2404.09848", "authors": ["Zhiwei Hu", "V\u00edctor Guti\u00e9rrez-Basulto", "Zhiliang Xiang", "Ru Li", "Jeff Z. Pan"], "title": "HyperMono: A Monotonicity-aware Approach to Hyper-Relational Knowledge Representation", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "In a hyper-relational knowledge graph (HKG), each fact is composed of a main\ntriple associated with attribute-value qualifiers, which express additional\nfactual knowledge. The hyper-relational knowledge graph completion (HKGC) task\naims at inferring plausible missing links in a HKG. Most existing approaches to\nHKGC focus on enhancing the communication between qualifier pairs and main\ntriples, while overlooking two important properties that emerge from the\nmonotonicity of the hyper-relational graphs representation regime. Stage\nReasoning allows for a two-step reasoning process, facilitating the integration\nof coarse-grained inference results derived solely from main triples and\nfine-grained inference results obtained from hyper-relational facts with\nqualifiers. In the initial stage, coarse-grained results provide an upper bound\nfor correct predictions, which are subsequently refined in the fine-grained\nstep. More generally, Qualifier Monotonicity implies that by attaching more\nqualifier pairs to a main triple, we may only narrow down the answer set, but\nnever enlarge it. This paper proposes the HyperMono model for hyper-relational\nknowledge graph completion, which realizes stage reasoning and qualifier\nmonotonicity. To implement qualifier monotonicity HyperMono resorts to cone\nembeddings. Experiments on three real-world datasets with three different\nscenario conditions demonstrate the strong performance of HyperMono when\ncompared to the SoTA.", "AI": {"tldr": "The paper introduces HyperMono, a model for hyper-relational knowledge graph completion (HKGC), leveraging stage reasoning and qualifier monotonicity to improve inference accuracy.", "motivation": "Existing HKGC approaches overlook the monotonicity properties in hyper-relational graphs, limiting their effectiveness. The paper aims to address this gap.", "method": "HyperMono uses stage reasoning (coarse-to-fine inference) and cone embeddings to enforce qualifier monotonicity.", "result": "Experiments on three datasets show HyperMono outperforms state-of-the-art methods.", "conclusion": "HyperMono effectively integrates monotonicity properties, enhancing HKGC performance."}}
{"id": "2506.23010", "pdf": "https://arxiv.org/pdf/2506.23010", "abs": "https://arxiv.org/abs/2506.23010", "authors": ["Max Lovig", "Tianhao Wang", "Zhou Fan"], "title": "On Universality of Non-Separable Approximate Message Passing Algorithms", "categories": ["math.ST", "cs.IT", "cs.LG", "math.IT", "math.PR", "stat.TH"], "comment": null, "summary": "Mean-field characterizations of first-order iterative algorithms -- including\nApproximate Message Passing (AMP), stochastic and proximal gradient descent,\nand Langevin diffusions -- have enabled a precise understanding of learning\ndynamics in many statistical applications. For algorithms whose non-linearities\nhave a coordinate-separable form, it is known that such characterizations enjoy\na degree of universality with respect to the underlying data distribution.\nHowever, mean-field characterizations of non-separable algorithm dynamics have\nlargely remained restricted to i.i.d. Gaussian or rotationally-invariant data.\n  In this work, we initiate a study of universality for non-separable AMP\nalgorithms. We identify a general condition for AMP with polynomial\nnon-linearities, in terms of a Bounded Composition Property (BCP) for their\nrepresenting tensors, to admit a state evolution that holds universally for\nmatrices with non-Gaussian entries. We then formalize a condition of\nBCP-approximability for Lipschitz AMP algorithms to enjoy a similar universal\nguarantee. We demonstrate that many common classes of non-separable\nnon-linearities are BCP-approximable, including local denoisers, spectral\ndenoisers for generic signals, and compositions of separable functions with\ngeneric linear maps, implying the universality of state evolution for AMP\nalgorithms employing these non-linearities.", "AI": {"tldr": "The paper explores universality in non-separable Approximate Message Passing (AMP) algorithms, identifying conditions like the Bounded Composition Property (BCP) for universal state evolution beyond Gaussian data.", "motivation": "To extend mean-field characterizations of iterative algorithms to non-separable cases, overcoming limitations of i.i.d. Gaussian or rotationally-invariant data assumptions.", "method": "Identifies BCP for polynomial non-linearities and BCP-approximability for Lipschitz AMP algorithms, ensuring universal state evolution for non-Gaussian matrices.", "result": "Demonstrates universality for AMP with common non-separable non-linearities (e.g., local/spectral denoisers, compositions with linear maps).", "conclusion": "The work broadens the applicability of AMP algorithms by proving universality for non-separable cases under general conditions."}}
{"id": "2506.23580", "pdf": "https://arxiv.org/pdf/2506.23580", "abs": "https://arxiv.org/abs/2506.23580", "authors": ["Yawen Zou", "Guang Li", "Duo Su", "Zi Wang", "Jun Yu", "Chao Zhang"], "title": "Dataset Distillation via Vision-Language Category Prototype", "categories": ["cs.CV"], "comment": "accepted by ICCV2025", "summary": "Dataset distillation (DD) condenses large datasets into compact yet\ninformative substitutes, preserving performance comparable to the original\ndataset while reducing storage, transmission costs, and computational\nconsumption. However, previous DD methods mainly focus on distilling\ninformation from images, often overlooking the semantic information inherent in\nthe data. The disregard for context hinders the model's generalization ability,\nparticularly in tasks involving complex datasets, which may result in illogical\noutputs or the omission of critical objects. In this study, we integrate\nvision-language methods into DD by introducing text prototypes to distill\nlanguage information and collaboratively synthesize data with image prototypes,\nthereby enhancing dataset distillation performance. Notably, the text\nprototypes utilized in this study are derived from descriptive text information\ngenerated by an open-source large language model. This framework demonstrates\nbroad applicability across datasets without pre-existing text descriptions,\nexpanding the potential of dataset distillation beyond traditional image-based\napproaches. Compared to other methods, the proposed approach generates\nlogically coherent images containing target objects, achieving state-of-the-art\nvalidation performance and demonstrating robust generalization. Source code and\ngenerated data are available in\nhttps://github.com/zou-yawen/Dataset-Distillation-via-Vision-Language-Category-Prototype/", "AI": {"tldr": "The paper introduces a vision-language method for dataset distillation (DD), enhancing performance by incorporating text prototypes derived from a large language model, improving logical coherence and generalization.", "motivation": "Previous DD methods focus on images, neglecting semantic context, leading to poor generalization and illogical outputs. This study aims to address this by integrating language information.", "method": "The approach combines text prototypes (from a large language model) with image prototypes to collaboratively synthesize data, enhancing DD performance.", "result": "The method produces logically coherent images with target objects, achieving state-of-the-art validation performance and robust generalization.", "conclusion": "The framework expands DD's applicability beyond image-based methods, demonstrating effectiveness and broad utility, with code and data publicly available."}}
{"id": "2504.16084", "pdf": "https://arxiv.org/pdf/2504.16084", "abs": "https://arxiv.org/abs/2504.16084", "authors": ["Yuxin Zuo", "Kaiyan Zhang", "Li Sheng", "Shang Qu", "Ganqu Cui", "Xuekai Zhu", "Haozhan Li", "Yuchen Zhang", "Xinwei Long", "Ermo Hua", "Biqing Qi", "Youbang Sun", "Zhiyuan Ma", "Lifan Yuan", "Ning Ding", "Bowen Zhou"], "title": "TTRL: Test-Time Reinforcement Learning", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This paper investigates Reinforcement Learning (RL) on data without explicit\nlabels for reasoning tasks in Large Language Models (LLMs). The core challenge\nof the problem is reward estimation during inference while not having access to\nground-truth information. While this setting appears elusive, we find that\ncommon practices in Test-Time Scaling (TTS), such as majority voting, yield\nsurprisingly effective rewards suitable for driving RL training. In this work,\nwe introduce Test-Time Reinforcement Learning (TTRL), a novel method for\ntraining LLMs using RL on unlabeled data. TTRL enables self-evolution of LLMs\nby utilizing the priors in the pre-trained models. Our experiments demonstrate\nthat TTRL consistently improves performance across a variety of tasks and\nmodels. Notably, TTRL boosts the pass@1 performance of Qwen-2.5-Math-7B by\napproximately 211% on the AIME 2024 with only unlabeled test data. Furthermore,\nalthough TTRL is only supervised by the maj@n metric, TTRL has demonstrated\nperformance to consistently surpass the upper limit of the initial model maj@n,\nand approach the performance of models trained directly on test data with\nground-truth labels. Our experimental findings validate the general\neffectiveness of TTRL across various tasks and highlight TTRL's potential for\nbroader tasks and domains. GitHub: https://github.com/PRIME-RL/TTRL", "AI": {"tldr": "TTRL is a novel RL method for training LLMs on unlabeled data, leveraging TTS practices like majority voting for reward estimation. It improves performance significantly, even surpassing models trained with labeled data.", "motivation": "The challenge of reward estimation in RL for LLMs without explicit labels motivates the development of TTRL, which uses unlabeled data effectively.", "method": "TTRL employs Test-Time Scaling (TTS) techniques, such as majority voting, to estimate rewards and train LLMs via reinforcement learning on unlabeled data.", "result": "TTRL boosts performance, e.g., increasing Qwen-2.5-Math-7B's pass@1 by ~211% on AIME 2024, and consistently surpasses initial model limits.", "conclusion": "TTRL is a general and effective method for improving LLM performance using unlabeled data, with potential for broader applications."}}
{"id": "2404.16078", "pdf": "https://arxiv.org/pdf/2404.16078", "abs": "https://arxiv.org/abs/2404.16078", "authors": ["Vaisakh Shaj"], "title": "Learning World Models With Hierarchical Temporal Abstractions: A Probabilistic Perspective", "categories": ["cs.AI", "cs.LG"], "comment": "Doctoral Dissertation, Department of Computer Science, Karlsruhe\n  Institute Of Technology, 2024", "summary": "Machines that can replicate human intelligence with type 2 reasoning\ncapabilities should be able to reason at multiple levels of spatio-temporal\nabstractions and scales using internal world models. Devising formalisms to\ndevelop such internal world models, which accurately reflect the causal\nhierarchies inherent in the dynamics of the real world, is a critical research\nchallenge in the domains of artificial intelligence and machine learning. This\nthesis identifies several limitations with the prevalent use of state space\nmodels (SSMs) as internal world models and propose two new probabilistic\nformalisms namely Hidden-Parameter SSMs and Multi-Time Scale SSMs to address\nthese drawbacks. The structure of graphical models in both formalisms\nfacilitates scalable exact probabilistic inference using belief propagation, as\nwell as end-to-end learning via backpropagation through time. This approach\npermits the development of scalable, adaptive hierarchical world models capable\nof representing nonstationary dynamics across multiple temporal abstractions\nand scales. Moreover, these probabilistic formalisms integrate the concept of\nuncertainty in world states, thus improving the system's capacity to emulate\nthe stochastic nature of the real world and quantify the confidence in its\npredictions. The thesis also discuss how these formalisms are in line with\nrelated neuroscience literature on Bayesian brain hypothesis and predicitive\nprocessing. Our experiments on various real and simulated robots demonstrate\nthat our formalisms can match and in many cases exceed the performance of\ncontemporary transformer variants in making long-range future predictions. We\nconclude the thesis by reflecting on the limitations of our current models and\nsuggesting directions for future research.", "AI": {"tldr": "The paper proposes two new probabilistic formalisms, Hidden-Parameter SSMs and Multi-Time Scale SSMs, to improve hierarchical world modeling in AI, addressing limitations of state space models. These models enable scalable inference, adaptability, and uncertainty integration, outperforming transformers in long-range predictions.", "motivation": "Current state space models (SSMs) lack the ability to accurately represent causal hierarchies and nonstationary dynamics in real-world scenarios, limiting their effectiveness in AI and machine learning.", "method": "The authors introduce Hidden-Parameter SSMs and Multi-Time Scale SSMs, leveraging graphical models for scalable probabilistic inference and end-to-end learning. These models integrate uncertainty and multi-scale temporal abstractions.", "result": "Experiments on real and simulated robots show the proposed formalisms outperform contemporary transformer variants in long-range predictions, while also aligning with neuroscience theories like the Bayesian brain hypothesis.", "conclusion": "The thesis highlights the success of the new formalisms but acknowledges limitations, suggesting future research directions to further enhance hierarchical world modeling."}}
{"id": "2506.23075", "pdf": "https://arxiv.org/pdf/2506.23075", "abs": "https://arxiv.org/abs/2506.23075", "authors": ["Yuchen Zhou", "Jiamin Wu", "Zichen Ren", "Zhouheng Yao", "Weiheng Lu", "Kunyu Peng", "Qihao Zheng", "Chunfeng Song", "Wanli Ouyang", "Chao Gou"], "title": "CSBrain: A Cross-scale Spatiotemporal Brain Foundation Model for EEG Decoding", "categories": ["cs.HC", "cs.LG", "eess.SP", "q-bio.NC"], "comment": null, "summary": "Understanding and decoding brain activity from electroencephalography (EEG)\nsignals is a fundamental challenge in neuroscience and AI, with applications in\ncognition, emotion recognition, diagnosis, and brain-computer interfaces. While\nrecent EEG foundation models advance generalized decoding via unified\narchitectures and large-scale pretraining, they adopt a scale-agnostic dense\nmodeling paradigm inherited from NLP and vision. This design neglects a core\nproperty of neural activity: cross-scale spatiotemporal structure. EEG task\npatterns span a wide range of temporal and spatial scales, from short bursts to\nslow rhythms, and from localized cortical responses to distributed\ninteractions. Ignoring this diversity leads to suboptimal representations and\nweak generalization. We propose CSBrain, a Cross-scale Spatiotemporal Brain\nfoundation model for generalized EEG decoding. CSBrain introduces: (i)\nCross-scale Spatiotemporal Tokenization (CST), which aggregates multi-scale\nfeatures from localized temporal windows and anatomical brain regions into\ncompact scale-aware tokens; and (ii) Structured Sparse Attention (SSA), which\ncaptures cross-window and cross-region dependencies, enhancing scale diversity\nwhile removing spurious correlations. CST and SSA are alternately stacked to\nprogressively integrate multi-scale dependencies. Experiments on 11 EEG tasks\nacross 16 datasets show that CSBrain consistently outperforms task-specific and\nfoundation model baselines. These results establish cross-scale modeling as a\nkey inductive bias and position CSBrain as a robust backbone for future\nbrain-AI research.", "AI": {"tldr": "CSBrain is a cross-scale spatiotemporal model for EEG decoding, outperforming existing methods by addressing multi-scale neural activity diversity.", "motivation": "Current EEG models ignore cross-scale spatiotemporal structure, leading to suboptimal representations and weak generalization.", "method": "CSBrain uses Cross-scale Spatiotemporal Tokenization (CST) and Structured Sparse Attention (SSA) to capture multi-scale features and dependencies.", "result": "CSBrain consistently outperforms baselines on 11 EEG tasks across 16 datasets.", "conclusion": "Cross-scale modeling is a key inductive bias, making CSBrain a robust backbone for future brain-AI research."}}
{"id": "2506.23590", "pdf": "https://arxiv.org/pdf/2506.23590", "abs": "https://arxiv.org/abs/2506.23590", "authors": ["Qiming Li", "Zekai Ye", "Xiaocheng Feng", "Weihong Zhong", "Libo Qin", "Ruihan Chen", "Baohang Li", "Kui Jiang", "Yaowei Wang", "Ting Liu", "Bing Qin"], "title": "CAI: Caption-Sensitive Attention Intervention for Mitigating Object Hallucination in Large Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Although Large Vision-Language Models (LVLMs) have demonstrated powerful\ncapabilities in interpreting visual information, they frequently produce\ncontent that deviates from visual information, leading to object hallucination.\nTo tackle this, recent works mostly depend on expensive manual annotations and\ntraining cost, or significantly increase inference time. In this work, we\nobserve that LVLMs' attention to visual information is significantly stronger\nwhen answering caption queries compared to non-caption queries. Inspired by\nthis phenomenon, we propose Caption-sensitive Attention Intervention (CAI), a\ntraining-free, plug-and-play hallucination mitigation method that leverages the\nattention activation pattern in response to caption queries to enhance LVLMs'\nvisual perception capability. Extensive experimental results across four\nbenchmarks covering both discriminative and generative tasks, demonstrate that\nCAI achieves state-of-the-art (SOTA) hallucination mitigating performance only\nwith minimal additional inference cost.", "AI": {"tldr": "The paper introduces Caption-sensitive Attention Intervention (CAI), a training-free method to mitigate object hallucination in Large Vision-Language Models (LVLMs) by leveraging attention patterns from caption queries.", "motivation": "LVLMs often produce content deviating from visual information (object hallucination), and existing solutions are costly or slow.", "method": "CAI uses attention activation patterns from caption queries to enhance visual perception without additional training or high inference costs.", "result": "CAI achieves state-of-the-art performance in hallucination mitigation across four benchmarks with minimal added inference cost.", "conclusion": "CAI is an effective, low-cost solution for reducing object hallucination in LVLMs."}}
{"id": "2505.12182", "pdf": "https://arxiv.org/pdf/2505.12182", "abs": "https://arxiv.org/abs/2505.12182", "authors": ["Haohang Li", "Yupeng Cao", "Yangyang Yu", "Jordan W. Suchow", "Zining Zhu"], "title": "Truth Neurons", "categories": ["cs.CL"], "comment": null, "summary": "Despite their remarkable success and deployment across diverse workflows,\nlanguage models sometimes produce untruthful responses. Our limited\nunderstanding of how truthfulness is mechanistically encoded within these\nmodels jeopardizes their reliability and safety. In this paper, we propose a\nmethod for identifying representations of truthfulness at the neuron level. We\nshow that language models contain truth neurons, which encode truthfulness in a\nsubject-agnostic manner. Experiments conducted across models of varying scales\nvalidate the existence of truth neurons, confirming that the encoding of\ntruthfulness at the neuron level is a property shared by many language models.\nThe distribution patterns of truth neurons over layers align with prior\nfindings on the geometry of truthfulness. Selectively suppressing the\nactivations of truth neurons found through the TruthfulQA dataset degrades\nperformance both on TruthfulQA and on other benchmarks, showing that the\ntruthfulness mechanisms are not tied to a specific dataset. Our results offer\nnovel insights into the mechanisms underlying truthfulness in language models\nand highlight potential directions toward improving their trustworthiness and\nreliability.", "AI": {"tldr": "The paper identifies 'truth neurons' in language models that encode truthfulness mechanistically, showing their existence across models and layers. Suppressing these neurons degrades performance, indicating their general role in truthfulness.", "motivation": "Understanding how truthfulness is encoded in language models to improve their reliability and safety.", "method": "Proposes identifying truthfulness at the neuron level, validating existence through experiments across models and layers.", "result": "Truth neurons exist and encode truthfulness subject-agnostically; suppressing them degrades performance on benchmarks.", "conclusion": "The findings provide insights into truthfulness mechanisms in language models, suggesting ways to enhance trustworthiness."}}
{"id": "2408.07575", "pdf": "https://arxiv.org/pdf/2408.07575", "abs": "https://arxiv.org/abs/2408.07575", "authors": ["Kai Z. Teh", "Kayvan Sadeghi", "Terry Soo"], "title": "A General Framework on Conditions for Constraint-based Causal Learning", "categories": ["cs.AI", "math.ST", "stat.ME", "stat.TH"], "comment": null, "summary": "Most constraint-based causal learning algorithms provably return the correct\ncausal graph under certain correctness conditions, such as faithfulness. By\nrepresenting any constraint-based causal learning algorithm using the notion of\na property, we provide a general framework to obtain and study correctness\nconditions for these algorithms. From the framework, we provide exact\ncorrectness conditions for the PC algorithm, which are then related to the\ncorrectness conditions of some other existing causal discovery algorithms. The\nframework also suggests a paradigm for designing causal learning algorithms\nwhich allows for the correctness conditions of algorithms to be controlled for\nbefore designing the actual algorithm, and has the following implications. We\nshow that the sparsest Markov representation condition is the weakest\ncorrectness condition for algorithms that output ancestral graphs or directed\nacyclic graphs satisfying any existing notions of minimality. We also reason\nthat Pearl-minimality is necessary for meaningful causal learning but not\nsufficient to relax the faithfulness condition and, as such, has to be\nstrengthened, such as by including background knowledge, for causal learning\nbeyond faithfulness.", "AI": {"tldr": "The paper presents a framework for analyzing correctness conditions in constraint-based causal learning algorithms, focusing on the PC algorithm and implications for designing algorithms with controlled correctness.", "motivation": "To generalize and study correctness conditions for constraint-based causal learning algorithms, ensuring reliable causal graph discovery.", "method": "Introduces a property-based framework to represent and analyze correctness conditions, applying it to the PC algorithm and comparing with other algorithms.", "result": "Identifies exact correctness conditions for the PC algorithm and shows the sparsest Markov representation as the weakest condition for certain graph outputs.", "conclusion": "Pearl-minimality is necessary but insufficient for causal learning beyond faithfulness; strengthening it, e.g., with background knowledge, is required."}}
{"id": "2506.23090", "pdf": "https://arxiv.org/pdf/2506.23090", "abs": "https://arxiv.org/abs/2506.23090", "authors": ["Langming Liu", "Wanyu Wang", "Chi Zhang", "Bo Li", "Hongzhi Yin", "Xuetao Wei", "Wenbo Su", "Bo Zheng", "Xiangyu Zhao"], "title": "Multi-task Offline Reinforcement Learning for Online Advertising in Recommender Systems", "categories": ["cs.IR", "cs.LG"], "comment": "KDD 2025", "summary": "Online advertising in recommendation platforms has gained significant\nattention, with a predominant focus on channel recommendation and budget\nallocation strategies. However, current offline reinforcement learning (RL)\nmethods face substantial challenges when applied to sparse advertising\nscenarios, primarily due to severe overestimation, distributional shifts, and\noverlooking budget constraints. To address these issues, we propose MTORL, a\nnovel multi-task offline RL model that targets two key objectives. First, we\nestablish a Markov Decision Process (MDP) framework specific to the nuances of\nadvertising. Then, we develop a causal state encoder to capture dynamic user\ninterests and temporal dependencies, facilitating offline RL through\nconditional sequence modeling. Causal attention mechanisms are introduced to\nenhance user sequence representations by identifying correlations among causal\nstates. We employ multi-task learning to decode actions and rewards,\nsimultaneously addressing channel recommendation and budget allocation.\nNotably, our framework includes an automated system for integrating these tasks\ninto online advertising. Extensive experiments on offline and online\nenvironments demonstrate MTORL's superiority over state-of-the-art methods.", "AI": {"tldr": "MTORL is a multi-task offline RL model addressing challenges in sparse advertising scenarios by combining causal state encoding, attention mechanisms, and multi-task learning for channel recommendation and budget allocation.", "motivation": "Current offline RL methods struggle with overestimation, distributional shifts, and budget constraints in sparse advertising scenarios.", "method": "Proposes MTORL with a tailored MDP framework, causal state encoder, causal attention mechanisms, and multi-task learning for action and reward decoding.", "result": "MTORL outperforms state-of-the-art methods in offline and online experiments.", "conclusion": "MTORL effectively addresses key challenges in advertising, offering a robust solution for channel recommendation and budget allocation."}}
{"id": "2506.23606", "pdf": "https://arxiv.org/pdf/2506.23606", "abs": "https://arxiv.org/abs/2506.23606", "authors": ["Zhengkang Xiang", "Zizhao Li", "Amir Khodabandeh", "Kourosh Khoshelham"], "title": "SG-LDM: Semantic-Guided LiDAR Generation via Latent-Aligned Diffusion", "categories": ["cs.CV"], "comment": null, "summary": "Lidar point cloud synthesis based on generative models offers a promising\nsolution to augment deep learning pipelines, particularly when real-world data\nis scarce or lacks diversity. By enabling flexible object manipulation, this\nsynthesis approach can significantly enrich training datasets and enhance\ndiscriminative models. However, existing methods focus on unconditional lidar\npoint cloud generation, overlooking their potential for real-world\napplications. In this paper, we propose SG-LDM, a Semantic-Guided Lidar\nDiffusion Model that employs latent alignment to enable robust\nsemantic-to-lidar synthesis. By directly operating in the native lidar space\nand leveraging explicit semantic conditioning, SG-LDM achieves state-of-the-art\nperformance in generating high-fidelity lidar point clouds guided by semantic\nlabels. Moreover, we propose the first diffusion-based lidar translation\nframework based on SG-LDM, which enables cross-domain translation as a domain\nadaptation strategy to enhance downstream perception performance. Systematic\nexperiments demonstrate that SG-LDM significantly outperforms existing lidar\ndiffusion models and the proposed lidar translation framework further improves\ndata augmentation performance in the downstream lidar segmentation task.", "AI": {"tldr": "SG-LDM is a Semantic-Guided Lidar Diffusion Model for high-fidelity lidar point cloud synthesis, outperforming existing methods and enhancing downstream tasks like segmentation.", "motivation": "Addressing the lack of diversity in real-world lidar data and the limitations of unconditional generation methods for practical applications.", "method": "Uses latent alignment and explicit semantic conditioning to generate lidar point clouds, and introduces a diffusion-based lidar translation framework for domain adaptation.", "result": "Achieves state-of-the-art performance in lidar synthesis and improves downstream segmentation via data augmentation.", "conclusion": "SG-LDM advances lidar synthesis and translation, proving effective for real-world applications and downstream tasks."}}
{"id": "2505.13271", "pdf": "https://arxiv.org/pdf/2505.13271", "abs": "https://arxiv.org/abs/2505.13271", "authors": ["Lei Sheng", "Shuai-Shuai Xu"], "title": "CSC-SQL: Corrective Self-Consistency in Text-to-SQL via Reinforcement Learning", "categories": ["cs.CL"], "comment": "25 pages, 5 figures", "summary": "Large language models (LLMs) have demonstrated strong capabilities in\ntranslating natural language questions about relational databases into SQL\nqueries. In particular, test-time scaling techniques such as Self-Consistency\nand Self-Correction can enhance SQL generation accuracy by increasing\ncomputational effort during inference. However, these methods have notable\nlimitations: Self-Consistency may select suboptimal outputs despite majority\nvotes, while Self-Correction typically addresses only syntactic errors. To\nleverage the strengths of both approaches, we propose CSC-SQL, a novel method\nthat integrates Self-Consistency and Self-Correction. CSC-SQL selects the two\nmost frequently occurring outputs from parallel sampling and feeds them into a\nmerge revision model for correction. Additionally, we employ the Group Relative\nPolicy Optimization (GRPO) algorithm to fine-tune both the SQL generation and\nrevision models via reinforcement learning, significantly enhancing output\nquality. Experimental results confirm the effectiveness and generalizability of\nCSC-SQL. On the BIRD private test set, our 7B model achieves 71.72\\% execution\naccuracy, while the 32B model achieves 73.67\\%. The code has been open sourced\nat https://github.com/CycloneBoy/csc_sql.", "AI": {"tldr": "CSC-SQL integrates Self-Consistency and Self-Correction to improve SQL generation accuracy, using GRPO for fine-tuning, achieving high execution accuracy on BIRD test set.", "motivation": "Existing methods like Self-Consistency and Self-Correction have limitations (suboptimal outputs, syntactic-only fixes). CSC-SQL aims to combine their strengths for better SQL generation.", "method": "CSC-SQL selects top outputs from parallel sampling, corrects them via a merge revision model, and uses GRPO for fine-tuning via reinforcement learning.", "result": "7B model achieves 71.72% and 32B model achieves 73.67% execution accuracy on BIRD test set.", "conclusion": "CSC-SQL is effective and generalizable, with open-sourced code for further use."}}
{"id": "2408.14419", "pdf": "https://arxiv.org/pdf/2408.14419", "abs": "https://arxiv.org/abs/2408.14419", "authors": ["Shubham Bharti", "Shiyun Cheng", "Jihyun Rho", "Jianrui Zhang", "Mu Cai", "Yong Jae Lee", "Martina Rau", "Xiaojin Zhu"], "title": "CHARTOM: A Visual Theory-of-Mind Benchmark for LLMs on Misleading Charts", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "We introduce CHARTOM, a visual theory-of-mind benchmark designed to evaluate\nmultimodal large language models' capability to understand and reason about\nmisleading data visualizations though charts. CHARTOM consists of carefully\ndesigned charts and associated questions that require a language model to not\nonly correctly comprehend the factual content in the chart (the FACT question)\nbut also judge whether the chart will be misleading to a human readers (the\nMIND question), a dual capability with significant societal benefits. We detail\nthe construction of our benchmark including its calibration on human\nperformance and estimation of MIND ground truth called the Human Misleadingness\nIndex. We evaluated several leading LLMs -- including GPT, Claude, Gemini,\nQwen, Llama, and Llava series models -- on the CHARTOM dataset and found that\nit was challenging to all models both on FACT and MIND questions. This\nhighlights the limitations of current LLMs and presents significant opportunity\nfor future LLMs to improve on understanding misleading charts.", "AI": {"tldr": "CHARTOM is a benchmark for evaluating LLMs' ability to understand and reason about misleading charts, testing both factual comprehension (FACT) and human deception (MIND). Current models struggle with both tasks.", "motivation": "To assess LLMs' dual capability in comprehending factual chart content and identifying misleading elements, addressing societal needs for better chart interpretation.", "method": "Constructed CHARTOM with carefully designed charts, calibrated on human performance, and introduced the Human Misleadingness Index for MIND ground truth. Evaluated leading LLMs like GPT, Claude, and Gemini.", "result": "All tested models struggled with FACT and MIND questions, revealing limitations in current LLMs' chart understanding.", "conclusion": "CHARTOM highlights the need for future LLM improvements in handling misleading visualizations, offering a valuable benchmark for progress."}}
{"id": "2506.23170", "pdf": "https://arxiv.org/pdf/2506.23170", "abs": "https://arxiv.org/abs/2506.23170", "authors": ["Jaime Hieu Do", "Trung-Hoang Le", "Hady W. Lauw"], "title": "Compositions of Variant Experts for Integrating Short-Term and Long-Term Preferences", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "In the online digital realm, recommendation systems are ubiquitous and play a\ncrucial role in enhancing user experience. These systems leverage user\npreferences to provide personalized recommendations, thereby helping users\nnavigate through the paradox of choice. This work focuses on personalized\nsequential recommendation, where the system considers not only a user's\nimmediate, evolving session context, but also their cumulative historical\nbehavior to provide highly relevant and timely recommendations. Through an\nempirical study conducted on diverse real-world datasets, we have observed and\nquantified the existence and impact of both short-term (immediate and\ntransient) and long-term (enduring and stable) preferences on users' historical\ninteractions. Building on these insights, we propose a framework that combines\nshort- and long-term preferences to enhance recommendation performance, namely\nCompositions of Variant Experts (CoVE). This novel framework dynamically\nintegrates short- and long-term preferences through the use of different\nspecialized recommendation models (i.e., experts). Extensive experiments\nshowcase the effectiveness of the proposed methods and ablation studies further\ninvestigate the impact of variant expert types.", "AI": {"tldr": "The paper introduces CoVE, a framework for personalized sequential recommendations by combining short- and long-term user preferences using specialized models.", "motivation": "To address the challenge of providing timely and relevant recommendations by leveraging both immediate and historical user behavior.", "method": "Proposes CoVE, a framework that dynamically integrates short- and long-term preferences through specialized recommendation models (experts).", "result": "Empirical studies confirm the impact of both preference types, and CoVE demonstrates improved recommendation performance.", "conclusion": "CoVE effectively combines short- and long-term preferences, enhancing recommendation accuracy and relevance."}}
{"id": "2506.23607", "pdf": "https://arxiv.org/pdf/2506.23607", "abs": "https://arxiv.org/abs/2506.23607", "authors": ["Shiqi Zhang", "Sha Zhang", "Jiajun Deng", "Yedong Shen", "Mingxiao MA", "Yanyong Zhang"], "title": "PGOV3D: Open-Vocabulary 3D Semantic Segmentation with Partial-to-Global Curriculum", "categories": ["cs.CV"], "comment": null, "summary": "Existing open-vocabulary 3D semantic segmentation methods typically supervise\n3D segmentation models by merging text-aligned features (e.g., CLIP) extracted\nfrom multi-view images onto 3D points. However, such approaches treat\nmulti-view images merely as intermediaries for transferring open-vocabulary\ninformation, overlooking their rich semantic content and cross-view\ncorrespondences, which limits model effectiveness. To address this, we propose\nPGOV3D, a novel framework that introduces a Partial-to-Global curriculum for\nimproving open-vocabulary 3D semantic segmentation. The key innovation lies in\na two-stage training strategy. In the first stage, we pre-train the model on\npartial scenes that provide dense semantic information but relatively simple\ngeometry. These partial point clouds are derived from multi-view RGB-D inputs\nvia pixel-wise depth projection. To enable open-vocabulary learning, we\nleverage a multi-modal large language model (MLLM) and a 2D segmentation\nfoundation model to generate open-vocabulary labels for each viewpoint,\noffering rich and aligned supervision. An auxiliary inter-frame consistency\nmodule is introduced to enforce feature consistency across varying viewpoints\nand enhance spatial understanding. In the second stage, we fine-tune the model\non complete scene-level point clouds, which are sparser and structurally more\ncomplex. We aggregate the partial vocabularies associated with each scene and\ngenerate pseudo labels using the pre-trained model, effectively bridging the\nsemantic gap between dense partial observations and large-scale 3D\nenvironments. Extensive experiments on ScanNet, ScanNet200, and S3DIS\nbenchmarks demonstrate that PGOV3D achieves competitive performance in\nopen-vocabulary 3D semantic segmentation.", "AI": {"tldr": "PGOV3D introduces a two-stage training strategy for open-vocabulary 3D semantic segmentation, leveraging partial scenes and multi-modal models for improved performance.", "motivation": "Existing methods overlook rich semantic content and cross-view correspondences in multi-view images, limiting effectiveness.", "method": "A two-stage approach: pre-training on partial scenes with dense semantics and simple geometry, then fine-tuning on complete scenes. Uses MLLM and 2D segmentation models for open-vocabulary labels.", "result": "Achieves competitive performance on ScanNet, ScanNet200, and S3DIS benchmarks.", "conclusion": "PGOV3D effectively bridges the semantic gap between partial and complete 3D scenes, enhancing open-vocabulary segmentation."}}
{"id": "2505.22648", "pdf": "https://arxiv.org/pdf/2505.22648", "abs": "https://arxiv.org/abs/2505.22648", "authors": ["Jialong Wu", "Baixuan Li", "Runnan Fang", "Wenbiao Yin", "Liwen Zhang", "Zhengwei Tao", "Dingchu Zhang", "Zekun Xi", "Gang Fu", "Yong Jiang", "Pengjun Xie", "Fei Huang", "Jingren Zhou"], "title": "WebDancer: Towards Autonomous Information Seeking Agency", "categories": ["cs.CL"], "comment": null, "summary": "Addressing intricate real-world problems necessitates in-depth information\nseeking and multi-step reasoning. Recent progress in agentic systems,\nexemplified by Deep Research, underscores the potential for autonomous\nmulti-step research. In this work, we present a cohesive paradigm for building\nend-to-end agentic information seeking agents from a data-centric and\ntraining-stage perspective. Our approach consists of four key stages: (1)\nbrowsing data construction, (2) trajectories sampling, (3) supervised\nfine-tuning for effective cold start, and (4) reinforcement learning for\nenhanced generalisation. We instantiate this framework in a web agent based on\nthe ReAct, WebDancer. Empirical evaluations on the challenging information\nseeking benchmarks, GAIA and WebWalkerQA, demonstrate the strong performance of\nWebDancer, achieving considerable results and highlighting the efficacy of our\ntraining paradigm. Further analysis of agent training provides valuable\ninsights and actionable, systematic pathways for developing more capable\nagentic models. The codes and demo will be released in\nhttps://github.com/Alibaba-NLP/WebAgent.", "AI": {"tldr": "The paper introduces WebDancer, an agentic information-seeking system, using a four-stage training paradigm for multi-step reasoning, achieving strong performance on benchmarks.", "motivation": "To address complex real-world problems requiring multi-step reasoning and information seeking by developing an autonomous agentic system.", "method": "A four-stage approach: browsing data construction, trajectories sampling, supervised fine-tuning, and reinforcement learning for generalization.", "result": "WebDancer performs well on GAIA and WebWalkerQA benchmarks, demonstrating the efficacy of the training paradigm.", "conclusion": "The framework provides insights for developing more capable agentic models, with code and demo available."}}
{"id": "2410.17218", "pdf": "https://arxiv.org/pdf/2410.17218", "abs": "https://arxiv.org/abs/2410.17218", "authors": ["Mete Ismayilzada", "Debjit Paul", "Antoine Bosselut", "Lonneke van der Plas"], "title": "Creativity in AI: Progresses and Challenges", "categories": ["cs.AI", "cs.CL"], "comment": "minor updates to content + contact information", "summary": "Creativity is the ability to produce novel, useful, and surprising ideas, and\nhas been widely studied as a crucial aspect of human cognition. Machine\ncreativity on the other hand has been a long-standing challenge. With the rise\nof advanced generative AI, there has been renewed interest and debate regarding\nAI's creative capabilities. Therefore, it is imperative to revisit the state of\ncreativity in AI and identify key progresses and remaining challenges. In this\nwork, we survey leading works studying the creative capabilities of AI systems,\nfocusing on creative problem-solving, linguistic, artistic, and scientific\ncreativity. Our review suggests that while the latest AI models are largely\ncapable of producing linguistically and artistically creative outputs such as\npoems, images, and musical pieces, they struggle with tasks that require\ncreative problem-solving, abstract thinking and compositionality and their\ngenerations suffer from a lack of diversity, originality, long-range\nincoherence and hallucinations. We also discuss key questions concerning\ncopyright and authorship issues with generative models. Furthermore, we\nhighlight the need for a comprehensive evaluation of creativity that is\nprocess-driven and considers several dimensions of creativity. Finally, we\npropose future research directions to improve the creativity of AI outputs,\ndrawing inspiration from cognitive science and psychology.", "AI": {"tldr": "The paper surveys AI's creative capabilities, noting progress in linguistic and artistic creativity but challenges in problem-solving and originality. It discusses copyright issues and calls for better evaluation methods and future research.", "motivation": "To revisit AI's creative capabilities, identify progress, and address challenges, given the rise of advanced generative AI.", "method": "A survey of leading works on AI creativity, focusing on problem-solving, linguistic, artistic, and scientific creativity.", "result": "AI excels in linguistic and artistic outputs but struggles with problem-solving, diversity, and originality. Copyright and evaluation methods are key concerns.", "conclusion": "Future research should improve AI creativity, drawing from cognitive science, and develop comprehensive evaluation frameworks."}}
{"id": "2506.23319", "pdf": "https://arxiv.org/pdf/2506.23319", "abs": "https://arxiv.org/abs/2506.23319", "authors": ["Norman Knyazev", "Harrie Oosterhuis"], "title": "Learning to Rank with Variable Result Presentation Lengths", "categories": ["cs.IR", "cs.LG"], "comment": "SIGIR 2025", "summary": "Learning to Rank (LTR) methods generally assume that each document in a top-K\nranking is presented in an equal format. However, previous work has shown that\nusers' perceptions of relevance can be changed by varying presentations, i.e.,\nallocating more vertical space to some documents to provide additional textual\nor image information. Furthermore, presentation length can also redirect\nattention, as users are more likely to notice longer presentations when\nscrolling through results. Deciding on the document presentation lengths in a\nfixed vertical space ranking is an important problem that has not been\naddressed by existing LTR methods.\n  We address this gap by introducing the variable presentation length ranking\ntask, where simultaneously the ordering of documents and their presentation\nlength is decided. Despite being a generalization of standard ranking, we show\nthat this setting brings significant new challenges: Firstly, the probability\nranking principle no longer applies to this setting, and secondly, the problem\ncannot be divided into separate ordering and length selection tasks.\n  We therefore propose VLPL - a new family of Plackett-Luce list-wise gradient\nestimation methods for the joint optimization of document ordering and lengths.\nOur semi-synthetic experiments show that VLPL can effectively balance the\nexpected exposure and attractiveness of all documents, achieving the best\nperformance across different ranking settings. Furthermore, we observe that\neven simple length-aware methods can achieve significant performance\nimprovements over fixed-length models. Altogether, our theoretical and\nempirical results highlight the importance and difficulties of combining\ndocument presentation with LTR.", "AI": {"tldr": "The paper introduces VLPL, a method for joint optimization of document ordering and presentation lengths in rankings, addressing the overlooked impact of presentation length on user relevance perception.", "motivation": "Existing LTR methods assume uniform document presentation, but varying presentation lengths can influence user relevance perception and attention. This gap motivates the need for a method that jointly optimizes ordering and presentation lengths.", "method": "The paper proposes VLPL, a Plackett-Luce list-wise gradient estimation method, for jointly optimizing document ordering and presentation lengths. It addresses challenges like the inapplicability of the probability ranking principle and the non-separability of ordering and length tasks.", "result": "VLPL effectively balances document exposure and attractiveness, outperforming fixed-length models. Simple length-aware methods also show significant improvements.", "conclusion": "The study highlights the importance and challenges of integrating document presentation with LTR, demonstrating VLPL's effectiveness in this novel task."}}
{"id": "2506.23611", "pdf": "https://arxiv.org/pdf/2506.23611", "abs": "https://arxiv.org/abs/2506.23611", "authors": ["Ziao Liu", "Zhenjia Li", "Yifeng Shi", "Xiangang Li"], "title": "AttentionGS: Towards Initialization-Free 3D Gaussian Splatting via Structural Attention", "categories": ["cs.CV"], "comment": null, "summary": "3D Gaussian Splatting (3DGS) is a powerful alternative to Neural Radiance\nFields (NeRF), excelling in complex scene reconstruction and efficient\nrendering. However, it relies on high-quality point clouds from\nStructure-from-Motion (SfM), limiting its applicability. SfM also fails in\ntexture-deficient or constrained-view scenarios, causing severe degradation in\n3DGS reconstruction. To address this limitation, we propose AttentionGS, a\nnovel framework that eliminates the dependency on high-quality initial point\nclouds by leveraging structural attention for direct 3D reconstruction from\nrandomly initialization. In the early training stage, we introduce geometric\nattention to rapidly recover the global scene structure. As training\nprogresses, we incorporate texture attention to refine fine-grained details and\nenhance rendering quality. Furthermore, we employ opacity-weighted gradients to\nguide Gaussian densification, leading to improved surface reconstruction.\nExtensive experiments on multiple benchmark datasets demonstrate that\nAttentionGS significantly outperforms state-of-the-art methods, particularly in\nscenarios where point cloud initialization is unreliable. Our approach paves\nthe way for more robust and flexible 3D Gaussian Splatting in real-world\napplications.", "AI": {"tldr": "AttentionGS eliminates the need for high-quality initial point clouds in 3D Gaussian Splatting (3DGS) by using structural attention, improving reconstruction in texture-deficient or constrained-view scenarios.", "motivation": "3DGS relies on SfM for point clouds, which fails in texture-deficient or constrained-view cases, limiting its applicability.", "method": "AttentionGS uses geometric attention early for global structure recovery and texture attention later for detail refinement, along with opacity-weighted gradients for Gaussian densification.", "result": "AttentionGS outperforms state-of-the-art methods, especially when initial point clouds are unreliable.", "conclusion": "The framework enables more robust and flexible 3DGS for real-world applications."}}
{"id": "2505.24302", "pdf": "https://arxiv.org/pdf/2505.24302", "abs": "https://arxiv.org/abs/2505.24302", "authors": ["Yike Wang", "Shangbin Feng", "Yulia Tsvetkov", "Hannaneh Hajishirzi"], "title": "ScienceMeter: Tracking Scientific Knowledge Updates in Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly used to support scientific\nresearch, but their knowledge of scientific advancements can quickly become\noutdated. We introduce ScienceMeter, a new framework for evaluating scientific\nknowledge update methods over scientific knowledge spanning the past, present,\nand future. ScienceMeter defines three metrics: knowledge preservation, the\nextent to which models' understanding of previously learned papers are\npreserved; knowledge acquisition, how well scientific claims from newly\nintroduced papers are acquired; and knowledge projection, the ability of the\nupdated model to anticipate or generalize to related scientific claims that may\nemerge in the future. Using ScienceMeter, we examine the scientific knowledge\nof LLMs on claim judgment and generation tasks across a curated dataset of\n15,444 scientific papers and 30,888 scientific claims from ten domains\nincluding medicine, biology, materials science, and computer science. We\nevaluate five representative knowledge update approaches including training-\nand inference-time methods. With extensive experiments, we find that the\nbest-performing knowledge update methods can preserve only 85.9% of existing\nknowledge, acquire 71.7% of new knowledge, and project 37.7% of future\nknowledge. Inference-based methods work for larger models, whereas smaller\nmodels require training to achieve comparable performance. Cross-domain\nanalysis reveals that performance on these objectives is correlated. Even when\napplying on specialized scientific LLMs, existing knowledge update methods fail\nto achieve these objectives collectively, underscoring that developing robust\nscientific knowledge update mechanisms is both crucial and challenging.", "AI": {"tldr": "ScienceMeter evaluates LLMs' scientific knowledge updates using three metrics: preservation, acquisition, and projection. It tests five methods on 15,444 papers, finding limited success in updating knowledge across domains.", "motivation": "LLMs' scientific knowledge becomes outdated quickly, necessitating a framework to evaluate and improve knowledge update methods.", "method": "ScienceMeter introduces three metrics (preservation, acquisition, projection) and evaluates five update methods on a dataset of 15,444 papers and 30,888 claims.", "result": "Best methods preserve 85.9% of existing knowledge, acquire 71.7% of new knowledge, and project 37.7% of future knowledge. Inference works for large models; training suits smaller ones.", "conclusion": "Current methods fall short in robustly updating scientific knowledge, highlighting the challenge and importance of developing better mechanisms."}}
{"id": "2412.02113", "pdf": "https://arxiv.org/pdf/2412.02113", "abs": "https://arxiv.org/abs/2412.02113", "authors": ["Doohee You", "Dan Chon"], "title": "Trust & Safety of LLMs and LLMs in Trust & Safety", "categories": ["cs.AI"], "comment": "11 pages", "summary": "In recent years, Large Language Models (LLMs) have garnered considerable\nattention for their remarkable abilities in natural language processing tasks.\nHowever, their widespread adoption has raised concerns pertaining to trust and\nsafety. This systematic review investigates the current research landscape on\ntrust and safety in LLMs, with a particular focus on the novel application of\nLLMs within the field of Trust and Safety itself. We delve into the\ncomplexities of utilizing LLMs in domains where maintaining trust and safety is\nparamount, offering a consolidated perspective on this emerging trend.\\\n  By synthesizing findings from various studies, we identify key challenges and\npotential solutions, aiming to benefit researchers and practitioners seeking to\nunderstand the nuanced interplay between LLMs and Trust and Safety.\n  This review provides insights on best practices for using LLMs in Trust and\nSafety, and explores emerging risks such as prompt injection and jailbreak\nattacks. Ultimately, this study contributes to a deeper understanding of how\nLLMs can be effectively and responsibly utilized to enhance trust and safety in\nthe digital realm.", "AI": {"tldr": "A systematic review on trust and safety in Large Language Models (LLMs), focusing on their application in Trust and Safety domains, identifying challenges and solutions.", "motivation": "Address concerns about trust and safety in LLMs, especially in critical domains, by reviewing current research.", "method": "Systematic review synthesizing findings from various studies on LLMs in Trust and Safety.", "result": "Identified key challenges (e.g., prompt injection, jailbreak attacks) and potential solutions for responsible LLM use.", "conclusion": "Provides insights for effective and responsible LLM utilization to enhance trust and safety in digital spaces."}}
{"id": "2506.23344", "pdf": "https://arxiv.org/pdf/2506.23344", "abs": "https://arxiv.org/abs/2506.23344", "authors": ["Difeng Cai", "Paulina Sep\u00falveda"], "title": "Data-Driven Self-Supervised Learning for the Discovery of Solution Singularity for Partial Differential Equations", "categories": ["math.NA", "cs.LG", "cs.NA", "stat.ML"], "comment": null, "summary": "The appearance of singularities in the function of interest constitutes a\nfundamental challenge in scientific computing. It can significantly undermine\nthe effectiveness of numerical schemes for function approximation, numerical\nintegration, and the solution of partial differential equations (PDEs), etc.\nThe problem becomes more sophisticated if the location of the singularity is\nunknown, which is often encountered in solving PDEs. Detecting the singularity\nis therefore critical for developing efficient adaptive methods to reduce\ncomputational costs in various applications. In this paper, we consider\nsingularity detection in a purely data-driven setting. Namely, the input only\ncontains given data, such as the vertex set from a mesh. To overcome the\nlimitation of the raw unlabeled data, we propose a self-supervised learning\n(SSL) framework for estimating the location of the singularity. A key component\nis a filtering procedure as the pretext task in SSL, where two filtering\nmethods are presented, based on $k$ nearest neighbors and kernel density\nestimation, respectively. We provide numerical examples to illustrate the\npotential pathological or inaccurate results due to the use of raw data without\nfiltering. Various experiments are presented to demonstrate the ability of the\nproposed approach to deal with input perturbation, label corruption, and\ndifferent kinds of singularities such interior circle, boundary layer,\nconcentric semicircles, etc.", "AI": {"tldr": "The paper addresses singularity detection in scientific computing using a self-supervised learning framework to improve accuracy and efficiency.", "motivation": "Singularities in functions hinder numerical methods, especially when their locations are unknown, necessitating adaptive solutions.", "method": "Proposes a self-supervised learning (SSL) framework with filtering methods (k-nearest neighbors and kernel density estimation) to detect singularities from raw data.", "result": "Demonstrates the framework's effectiveness in handling input perturbations, label corruption, and various singularity types.", "conclusion": "The SSL-based approach enhances singularity detection, offering robust and adaptive solutions for scientific computing challenges."}}
{"id": "2506.23618", "pdf": "https://arxiv.org/pdf/2506.23618", "abs": "https://arxiv.org/abs/2506.23618", "authors": ["Zhongdao Wang", "Guodongfang Zhao", "Jingjing Ren", "Bailan Feng", "Shifeng Zhang", "Wenbo Li"], "title": "TurboVSR: Fantastic Video Upscalers and Where to Find Them", "categories": ["cs.CV"], "comment": "ICCV, 2025", "summary": "Diffusion-based generative models have demonstrated exceptional promise in\nthe video super-resolution (VSR) task, achieving a substantial advancement in\ndetail generation relative to prior methods. However, these approaches face\nsignificant computational efficiency challenges. For instance, current\ntechniques may require tens of minutes to super-resolve a mere 2-second, 1080p\nvideo. In this paper, we present TurboVSR, an ultra-efficient diffusion-based\nvideo super-resolution model. Our core design comprises three key aspects: (1)\nWe employ an autoencoder with a high compression ratio of 32$\\times$32$\\times$8\nto reduce the number of tokens. (2) Highly compressed latents pose substantial\nchallenges for training. We introduce factorized conditioning to mitigate the\nlearning complexity: we first learn to super-resolve the initial frame;\nsubsequently, we condition the super-resolution of the remaining frames on the\nhigh-resolution initial frame and the low-resolution subsequent frames. (3) We\nconvert the pre-trained diffusion model to a shortcut model to enable fewer\nsampling steps, further accelerating inference. As a result, TurboVSR performs\non par with state-of-the-art VSR methods, while being 100+ times faster, taking\nonly 7 seconds to process a 2-second long 1080p video. TurboVSR also supports\nimage resolution by considering image as a one-frame video. Our efficient\ndesign makes SR beyond 1080p possible, results on 4K (3648$\\times$2048) image\nSR show surprising fine details.", "AI": {"tldr": "TurboVSR is an ultra-efficient diffusion-based video super-resolution model that achieves state-of-the-art performance while being 100+ times faster than current methods.", "motivation": "Current diffusion-based VSR models are computationally inefficient, taking too long to process videos. TurboVSR aims to address this by improving efficiency without sacrificing quality.", "method": "TurboVSR uses a high-compression autoencoder, factorized conditioning for training, and converts a pre-trained diffusion model into a shortcut model for faster inference.", "result": "TurboVSR matches state-of-the-art VSR quality while processing a 2-second 1080p video in just 7 seconds. It also supports 4K image super-resolution with fine details.", "conclusion": "TurboVSR significantly improves computational efficiency in VSR, making high-quality super-resolution practical for real-world applications."}}
{"id": "2506.07160", "pdf": "https://arxiv.org/pdf/2506.07160", "abs": "https://arxiv.org/abs/2506.07160", "authors": ["Yikun Wang", "Yibin Wang", "Dianyi Wang", "Zimian Peng", "Qipeng Guo", "Dacheng Tao", "Jiaqi Wang"], "title": "GeometryZero: Improving Geometry Solving for LLM with Group Contrastive Policy Optimization", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in large language models (LLMs) have demonstrated remarkable\ncapabilities across diverse domains, particularly in mathematical reasoning,\namid which geometry problem solving remains a challenging area where auxiliary\nconstruction plays a enssential role. Existing approaches either achieve\nsuboptimal performance or rely on massive LLMs (e.g., GPT-4o), incurring\nmassive computational costs. We posit that reinforcement learning with\nverifiable reward (e.g., GRPO) offers a promising direction for training\nsmaller models that effectively combine auxiliary construction with robust\ngeometric reasoning. However, directly applying GRPO to geometric reasoning\npresents fundamental limitations due to its dependence on unconditional\nrewards, which leads to indiscriminate and counterproductive auxiliary\nconstructions. To address these challenges, we propose Group Contrastive Policy\nOptimization (GCPO), a novel reinforcement learning framework featuring two key\ninnovations: (1) Group Contrastive Masking, which adaptively provides positive\nor negative reward signals for auxiliary construction based on contextual\nutility, and a (2) length reward that promotes longer reasoning chains.\nBuilding on GCPO, we develop GeometryZero, a family of affordable-size\ngeometric reasoning models that judiciously determine when to employ auxiliary\nconstruction. Our extensive empirical evaluation across popular geometric\nbenchmarks (Geometry3K, MathVista) demonstrates that GeometryZero models\nconsistently outperform baselines (e.g. GRPO), achieving an average improvement\nof 4.29% across all benchmarks.", "AI": {"tldr": "The paper introduces GCPO, a reinforcement learning framework, to improve geometric reasoning in smaller LLMs by optimizing auxiliary construction and reasoning chains, outperforming baselines by 4.29%.", "motivation": "Geometry problem solving in LLMs is challenging due to suboptimal performance or high computational costs of large models. The paper aims to address this by enhancing smaller models with efficient auxiliary construction.", "method": "Proposes Group Contrastive Policy Optimization (GCPO), featuring Group Contrastive Masking for adaptive rewards and a length reward for longer reasoning chains, applied in the GeometryZero model.", "result": "GeometryZero models outperform baselines (e.g., GRPO) by 4.29% on benchmarks like Geometry3K and MathVista.", "conclusion": "GCPO effectively enhances geometric reasoning in smaller LLMs, offering a cost-efficient alternative to large models."}}
{"id": "2412.13964", "pdf": "https://arxiv.org/pdf/2412.13964", "abs": "https://arxiv.org/abs/2412.13964", "authors": ["Stefano M. Nicoletti", "E. Moritz Hahn", "Mattia Fumagalli", "Giancarlo Guizzardi", "Mari\u00eblle Stoelinga"], "title": "WATCHDOG: an ontology-aWare risk AssessmenT approaCH via object-oriented DisruptiOn Graphs", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "When considering risky events or actions, we must not downplay the role of\ninvolved objects: a charged battery in our phone averts the risk of being\nstranded in the desert after a flat tyre, and a functional firewall mitigates\nthe risk of a hacker intruding the network. The Common Ontology of Value and\nRisk (COVER) highlights how the role of objects and their relationships remains\npivotal to performing transparent, complete and accountable risk assessment. In\nthis paper, we operationalize some of the notions proposed by COVER -- such as\nparthood between objects and participation of objects in events/actions -- by\npresenting a new framework for risk assessment: WATCHDOG. WATCHDOG enriches the\nexpressivity of vetted formal models for risk -- i.e., fault trees and attack\ntrees -- by bridging the disciplines of ontology and formal methods into an\nontology-aware formal framework composed by a more expressive modelling\nformalism, Object-Oriented Disruption Graphs (DOGs), logic (DOGLog) and an\nintermediate query language (DOGLang). With these, WATCHDOG allows risk\nassessors to pose questions about disruption propagation, disruption likelihood\nand risk levels, keeping the fundamental role of objects at risk always in\nsight.", "AI": {"tldr": "WATCHDOG is a new framework for risk assessment that integrates ontology and formal methods, enhancing expressivity in risk modeling by focusing on objects and their relationships.", "motivation": "The paper addresses the need for transparent and complete risk assessment by emphasizing the role of objects in mitigating risks, as highlighted by the Common Ontology of Value and Risk (COVER).", "method": "The WATCHDOG framework operationalizes COVER's notions through Object-Oriented Disruption Graphs (DOGs), logic (DOGLog), and a query language (DOGLang), bridging ontology and formal methods.", "result": "WATCHDOG enables risk assessors to model and query disruption propagation, likelihood, and risk levels while maintaining focus on objects.", "conclusion": "The framework advances risk assessment by combining ontology and formal methods, ensuring a more expressive and object-aware approach."}}
{"id": "2506.23396", "pdf": "https://arxiv.org/pdf/2506.23396", "abs": "https://arxiv.org/abs/2506.23396", "authors": ["Kay Giesecke", "Enguerrand Horel", "Chartsiri Jirachotkulthorn"], "title": "AICO: Feature Significance Tests for Supervised Learning", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "The opacity of many supervised learning algorithms remains a key challenge,\nhindering scientific discovery and limiting broader deployment -- particularly\nin high-stakes domains. This paper develops model- and distribution-agnostic\nsignificance tests to assess the influence of input features in any regression\nor classification algorithm. Our method evaluates a feature's incremental\ncontribution to model performance by masking its values across samples. Under\nthe null hypothesis, the distribution of performance differences across a test\nset has a non-positive median. We construct a uniformly most powerful,\nrandomized sign test for this median, yielding exact p-values for assessing\nfeature significance and confidence intervals with exact coverage for\nestimating population-level feature importance. The approach requires minimal\nassumptions, avoids model retraining or auxiliary models, and remains\ncomputationally efficient even for large-scale, high-dimensional settings.\nExperiments on synthetic tasks validate its statistical and computational\nadvantages, and applications to real-world data illustrate its practical\nutility.", "AI": {"tldr": "The paper introduces a model- and distribution-agnostic method to test feature significance in supervised learning, using masking and a randomized sign test for exact p-values and confidence intervals.", "motivation": "Address the opacity of supervised learning algorithms to enhance interpretability and deployment in high-stakes domains.", "method": "Evaluates feature influence by masking values and testing performance differences via a randomized sign test for non-positive median under the null hypothesis.", "result": "Validated on synthetic and real-world data, the method is statistically powerful, computationally efficient, and requires minimal assumptions.", "conclusion": "The approach provides a practical, scalable tool for assessing feature importance in diverse supervised learning settings."}}
{"id": "2506.23623", "pdf": "https://arxiv.org/pdf/2506.23623", "abs": "https://arxiv.org/abs/2506.23623", "authors": ["Shaofei Huang", "Rui Ling", "Tianrui Hui", "Hongyu Li", "Xu Zhou", "Shifeng Zhang", "Si Liu", "Richang Hong", "Meng Wang"], "title": "Revisiting Audio-Visual Segmentation with Vision-Centric Transformer", "categories": ["cs.CV"], "comment": "Accepted by CVPR 2025; Code: https://github.com/spyflying/VCT_AVS;\n  Models: https://huggingface.co/nowherespyfly/VCT_AVS", "summary": "Audio-Visual Segmentation (AVS) aims to segment sound-producing objects in\nvideo frames based on the associated audio signal. Prevailing AVS methods\ntypically adopt an audio-centric Transformer architecture, where object queries\nare derived from audio features. However, audio-centric Transformers suffer\nfrom two limitations: perception ambiguity caused by the mixed nature of audio,\nand weakened dense prediction ability due to visual detail loss. To address\nthese limitations, we propose a new Vision-Centric Transformer (VCT) framework\nthat leverages vision-derived queries to iteratively fetch corresponding audio\nand visual information, enabling queries to better distinguish between\ndifferent sounding objects from mixed audio and accurately delineate their\ncontours. Additionally, we also introduce a Prototype Prompted Query Generation\n(PPQG) module within our VCT framework to generate vision-derived queries that\nare both semantically aware and visually rich through audio prototype prompting\nand pixel context grouping, facilitating audio-visual information aggregation.\nExtensive experiments demonstrate that our VCT framework achieves new\nstate-of-the-art performances on three subsets of the AVSBench dataset. The\ncode is available at https://github.com/spyflying/VCT_AVS.", "AI": {"tldr": "The paper proposes a Vision-Centric Transformer (VCT) framework for Audio-Visual Segmentation (AVS) to address limitations of audio-centric methods, achieving state-of-the-art results.", "motivation": "Audio-centric Transformers in AVS suffer from perception ambiguity and weakened dense prediction due to mixed audio and visual detail loss.", "method": "The VCT framework uses vision-derived queries to fetch audio and visual information iteratively, aided by a Prototype Prompted Query Generation (PPQG) module for semantically aware and visually rich queries.", "result": "VCT achieves state-of-the-art performance on three subsets of the AVSBench dataset.", "conclusion": "The VCT framework effectively addresses the limitations of audio-centric methods, improving segmentation accuracy for sound-producing objects."}}
{"id": "2506.08686", "pdf": "https://arxiv.org/pdf/2506.08686", "abs": "https://arxiv.org/abs/2506.08686", "authors": ["Soham Poddar", "Paramita Koley", "Janardan Misra", "Sanjay Podder", "Navveen Balani", "Niloy Ganguly", "Saptarshi Ghosh"], "title": "Brevity is the soul of sustainability: Characterizing LLM response lengths", "categories": ["cs.CL", "cs.CY"], "comment": "Accepted to appear at the ACL 2025 findings", "summary": "A significant portion of the energy consumed by Large Language Models (LLMs)\narises from their inference processes; hence developing energy-efficient\nmethods for inference is crucial. While several techniques exist for inference\noptimization, output compression remains relatively unexplored, with only a few\npreliminary efforts addressing this aspect. In this work, we first benchmark 12\ndecoder-only LLMs across 5 datasets, revealing that these models often produce\nresponses that are substantially longer than necessary. We then conduct a\ncomprehensive quality assessment of LLM responses, formally defining six\ninformation categories present in LLM responses. We show that LLMs often tend\nto include redundant or additional information besides the minimal answer. To\naddress this issue of long responses by LLMs, we explore several simple and\nintuitive prompt-engineering strategies. Empirical evaluation shows that\nappropriate prompts targeting length reduction and controlling information\ncontent can achieve significant energy optimization between 25-60\\% by reducing\nthe response length while preserving the quality of LLM responses.", "AI": {"tldr": "The paper addresses energy inefficiency in LLM inference by focusing on output compression, revealing LLMs often produce unnecessarily long responses. It proposes prompt-engineering strategies to reduce response length, achieving 25-60% energy savings without compromising quality.", "motivation": "Energy consumption in LLM inference is high, and output compression is underexplored. The study aims to reduce energy use by optimizing response length.", "method": "Benchmarked 12 decoder-only LLMs on 5 datasets, analyzed response quality, and tested prompt-engineering strategies for length reduction.", "result": "Prompt-engineering reduced response length by 25-60%, significantly lowering energy consumption while maintaining response quality.", "conclusion": "Simple prompt adjustments can effectively optimize LLM energy efficiency by reducing redundant output, offering a practical solution for sustainable AI."}}
{"id": "2501.02497", "pdf": "https://arxiv.org/pdf/2501.02497", "abs": "https://arxiv.org/abs/2501.02497", "authors": ["Yixin Ji", "Juntao Li", "Yang Xiang", "Hai Ye", "Kaixin Wu", "Kai Yao", "Jia Xu", "Linjian Mo", "Min Zhang"], "title": "A Survey of Test-Time Compute: From Intuitive Inference to Deliberate Reasoning", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "Work in progress", "summary": "The remarkable performance of the o1 model in complex reasoning demonstrates\nthat test-time compute scaling can further unlock the model's potential,\nenabling powerful System-2 thinking. However, there is still a lack of\ncomprehensive surveys for test-time compute scaling. We trace the concept of\ntest-time compute back to System-1 models. In System-1 models, test-time\ncompute addresses distribution shifts and improves robustness and\ngeneralization through parameter updating, input modification, representation\nediting, and output calibration. In System-2 models, it enhances the model's\nreasoning ability to solve complex problems through repeated sampling,\nself-correction, and tree search. We organize this survey according to the\ntrend of System-1 to System-2 thinking, highlighting the key role of test-time\ncompute in the transition from System-1 models to weak System-2 models, and\nthen to strong System-2 models. We also point out advanced topics and future\ndirections.", "AI": {"tldr": "The paper surveys test-time compute scaling, tracing its role from System-1 to System-2 models, highlighting its impact on reasoning and problem-solving, and suggesting future directions.", "motivation": "To address the lack of comprehensive surveys on test-time compute scaling and its evolution from System-1 to System-2 models.", "method": "Organizes the survey by tracing test-time compute's role in System-1 (robustness, generalization) and System-2 (reasoning, problem-solving) models, detailing techniques like parameter updating and tree search.", "result": "Highlights test-time compute's key role in transitioning from System-1 to System-2 models and its potential in enhancing reasoning.", "conclusion": "Test-time compute scaling is pivotal in advancing models from basic to complex reasoning, with future research needed for further exploration."}}
{"id": "2506.23429", "pdf": "https://arxiv.org/pdf/2506.23429", "abs": "https://arxiv.org/abs/2506.23429", "authors": ["Yingyuan Li", "Aokun Wang", "Zhongjian Wang"], "title": "DPOT: A DeepParticle method for Computation of Optimal Transport with convergence guarantee", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In this work, we propose a novel machine learning approach to compute the\noptimal transport map between two continuous distributions from their unpaired\nsamples, based on the DeepParticle methods. The proposed method leads to a\nmin-min optimization during training and does not impose any restriction on the\nnetwork structure. Theoretically we establish a weak convergence guarantee and\na quantitative error bound between the learned map and the optimal transport\nmap. Our numerical experiments validate the theoretical results and the\neffectiveness of the new approach, particularly on real-world tasks.", "AI": {"tldr": "A novel machine learning method for computing optimal transport maps between continuous distributions using DeepParticle, featuring min-min optimization and theoretical guarantees.", "motivation": "To address the challenge of computing optimal transport maps between unpaired samples of continuous distributions efficiently and accurately.", "method": "Proposes a DeepParticle-based approach with min-min optimization during training, free from network structure restrictions.", "result": "Theoretical weak convergence and error bounds are established; numerical experiments confirm effectiveness, especially in real-world tasks.", "conclusion": "The method is theoretically sound and practically effective for optimal transport map computation."}}
{"id": "2506.23627", "pdf": "https://arxiv.org/pdf/2506.23627", "abs": "https://arxiv.org/abs/2506.23627", "authors": ["Roham Maiti", "Debasmita Bhoumik"], "title": "Brain Tumor Detection through Thermal Imaging and MobileNET", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Brain plays a crucial role in regulating body functions and cognitive\nprocesses, with brain tumors posing significant risks to human health. Precise\nand prompt detection is a key factor in proper treatment and better patient\noutcomes. Traditional methods for detecting brain tumors, that include\nbiopsies, MRI, and CT scans often face challenges due to their high costs and\nthe need for specialized medical expertise. Recent developments in machine\nlearning (ML) and deep learning (DL) has exhibited strong capabilities in\nautomating the identification and categorization of brain tumors from medical\nimages, especially MRI scans. However, these classical ML models have\nlimitations, such as high computational demands, the need for large datasets,\nand long training times, which hinder their accessibility and efficiency. Our\nresearch uses MobileNET model for efficient detection of these tumors. The\nnovelty of this project lies in building an accurate tumor detection model\nwhich use less computing re-sources and runs in less time followed by efficient\ndecision making through the use of image processing technique for accurate\nresults. The suggested method attained an average accuracy of 98.5%.", "AI": {"tldr": "The paper proposes using MobileNET for efficient brain tumor detection from MRI scans, addressing limitations of traditional methods and classical ML models.", "motivation": "Brain tumors pose significant health risks, and traditional detection methods like biopsies, MRI, and CT scans are costly and require expertise. Classical ML models also face computational and dataset challenges.", "method": "The research employs the MobileNET model for tumor detection, focusing on reduced computational resources and faster processing while maintaining accuracy.", "result": "The proposed method achieved an average accuracy of 98.5%.", "conclusion": "The MobileNET-based approach offers an efficient, accurate, and accessible solution for brain tumor detection, overcoming limitations of traditional and classical ML methods."}}
{"id": "2506.09428", "pdf": "https://arxiv.org/pdf/2506.09428", "abs": "https://arxiv.org/abs/2506.09428", "authors": ["Fei Ding", "Baiqiao Wang"], "title": "Improved Supervised Fine-Tuning for Large Language Models to Mitigate Catastrophic Forgetting", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Supervised Fine-Tuning (SFT) is a critical step for enhancing the\ninstruction-following capabilities of Large Language Models (LLMs) and adapting\nthem to specialized domains. However, SFT often leads to a degradation of the\nmodel's general abilities, a phenomenon known as catastrophic forgetting. This\nproblem is exacerbated when third-party practitioners fine-tune open-source\nmodels, as the original SFT data is typically not available. To address this\nchallenge, we propose a novel and cost-effective SFT method that effectively\nmitigates catastrophic forgetting without requiring access to the original SFT\ndata. Our approach first reconstructs the likely instruction distribution of\nthe base model. It then employs a multi-model generation and filtering pipeline\nto synthesize a high-quality general-purpose dataset. This synthetic dataset is\nmixed with new, domain-specific data for fine-tuning. Experimental results show\nthat our method not only preserves the model's capabilities in general domains\nbut also improves task-specific performance, outperforming baselines that use\npublicly available SFT datasets.", "AI": {"tldr": "A novel SFT method mitigates catastrophic forgetting in LLMs by reconstructing instruction distributions and synthesizing datasets, improving both general and task-specific performance.", "motivation": "Address the degradation of general abilities in LLMs during SFT, especially when original SFT data is unavailable.", "method": "Reconstructs base model's instruction distribution, uses multi-model generation/filtering to create synthetic general-purpose data, and mixes it with domain-specific data for fine-tuning.", "result": "Preserves general capabilities while enhancing task-specific performance, outperforming baselines using public SFT datasets.", "conclusion": "The proposed method is cost-effective and effective in mitigating catastrophic forgetting without original SFT data."}}
{"id": "2501.02725", "pdf": "https://arxiv.org/pdf/2501.02725", "abs": "https://arxiv.org/abs/2501.02725", "authors": ["Nantheera Anantrasirichai", "Fan Zhang", "David Bull"], "title": "Artificial Intelligence in Creative Industries: Advances Prior to 2025", "categories": ["cs.AI"], "comment": "This is an updated review of our previous paper (see\n  https://doi.org/10.1007/s10462-021-10039-7)", "summary": "The rapid advancements in artificial intelligence (AI), particularly in\ngenerative AI and large language models (LLMs), have profoundly impacted the\ncreative industries, enabling more innovative content creation, enhancing\nworkflows, and democratizing access to creative tools. This paper explores\nthese technological shifts, with particular focus on how those that have\nemerged since our previous review in 2022 have expanded creative opportunities\nand improved efficiency. These technological advancements have enhanced the\ncapabilities of text-to-image, text-to-video, and multimodal generation\ntechnologies. In particular, key breakthroughs in LLMs have established new\nbenchmarks in conversational AI, while advancements in image generators have\nrevolutionized content creation. We also discuss the integration of AI into\npost-production workflows, which has significantly accelerated and improved\ntraditional processes. Once content has been created, it must be delivered to\nits audiences; the media industry is now facing the demands of increased\ncommunication traffic due to creative content. We therefore include a\ndiscussion of how AI is beginning to transform the way we represent and\ncompress media content. We highlight the trend toward unified AI frameworks\ncapable of addressing and integrating multiple creative tasks, and we\nunderscore the importance of human insight to drive the creative process and\noversight to mitigate AI-generated inaccuracies. Finally, we explore AI's\nfuture potential in the creative sector, stressing the need to navigate\nemerging challenges and to maximize its benefits while addressing the\nassociated risks.", "AI": {"tldr": "The paper examines AI's impact on creative industries, focusing on advancements since 2022 in generative AI, LLMs, and multimodal tools, while highlighting workflow improvements, challenges, and future potential.", "motivation": "To explore how recent AI advancements, like generative AI and LLMs, have expanded creative opportunities and improved efficiency in creative industries.", "method": "Review of technological shifts, breakthroughs in LLMs, image generators, and AI integration into post-production and media workflows.", "result": "AI has revolutionized content creation, enhanced workflows, and introduced new challenges like managing increased communication traffic and mitigating AI inaccuracies.", "conclusion": "AI holds significant future potential in the creative sector, but challenges must be navigated to maximize benefits and address risks, with human oversight remaining crucial."}}
{"id": "2506.23453", "pdf": "https://arxiv.org/pdf/2506.23453", "abs": "https://arxiv.org/abs/2506.23453", "authors": ["Zhen Zhang", "Xin Liu", "Shaoli Wang", "Jiaye Teng"], "title": "Minimax Optimal Two-Stage Algorithm For Moment Estimation Under Covariate Shift", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Covariate shift occurs when the distribution of input features differs\nbetween the training and testing phases. In covariate shift, estimating an\nunknown function's moment is a classical problem that remains under-explored,\ndespite its common occurrence in real-world scenarios. In this paper, we\ninvestigate the minimax lower bound of the problem when the source and target\ndistributions are known. To achieve the minimax optimal bound (up to a\nlogarithmic factor), we propose a two-stage algorithm. Specifically, it first\ntrains an optimal estimator for the function under the source distribution, and\nthen uses a likelihood ratio reweighting procedure to calibrate the moment\nestimator. In practice, the source and target distributions are typically\nunknown, and estimating the likelihood ratio may be unstable. To solve this\nproblem, we propose a truncated version of the estimator that ensures double\nrobustness and provide the corresponding upper bound. Extensive numerical\nstudies on synthetic examples confirm our theoretical findings and further\nillustrate the effectiveness of our proposed method.", "AI": {"tldr": "The paper addresses covariate shift by proposing a two-stage algorithm for minimax optimal moment estimation, with a truncated estimator for unknown distributions.", "motivation": "Covariate shift is common but under-explored, especially in estimating moments of unknown functions when source and target distributions differ.", "method": "A two-stage algorithm: first trains an optimal estimator under the source distribution, then uses likelihood ratio reweighting. A truncated estimator is proposed for unknown distributions.", "result": "The method achieves minimax optimal bounds (up to a logarithmic factor) and demonstrates effectiveness in synthetic experiments.", "conclusion": "The proposed approach is theoretically sound and practically effective for handling covariate shift in moment estimation."}}
{"id": "2506.23630", "pdf": "https://arxiv.org/pdf/2506.23630", "abs": "https://arxiv.org/abs/2506.23630", "authors": ["Lorenzo Olearo", "Giorgio Longari", "Alessandro Raganato", "Rafael Pe\u00f1aloza", "Simone Melzi"], "title": "Blending Concepts with Text-to-Image Diffusion Models", "categories": ["cs.CV"], "comment": "Currently under review", "summary": "Diffusion models have dramatically advanced text-to-image generation in\nrecent years, translating abstract concepts into high-fidelity images with\nremarkable ease. In this work, we examine whether they can also blend distinct\nconcepts, ranging from concrete objects to intangible ideas, into coherent new\nvisual entities under a zero-shot framework. Specifically, concept blending\nmerges the key attributes of multiple concepts (expressed as textual prompts)\ninto a single, novel image that captures the essence of each concept. We\ninvestigate four blending methods, each exploiting different aspects of the\ndiffusion pipeline (e.g., prompt scheduling, embedding interpolation, or\nlayer-wise conditioning). Through systematic experimentation across diverse\nconcept categories, such as merging concrete concepts, synthesizing compound\nwords, transferring artistic styles, and blending architectural landmarks, we\nshow that modern diffusion models indeed exhibit creative blending capabilities\nwithout further training or fine-tuning. Our extensive user study, involving\n100 participants, reveals that no single approach dominates in all scenarios:\neach blending technique excels under certain conditions, with factors like\nprompt ordering, conceptual distance, and random seed affecting the outcome.\nThese findings highlight the remarkable compositional potential of diffusion\nmodels while exposing their sensitivity to seemingly minor input variations.", "AI": {"tldr": "Diffusion models can blend diverse concepts into coherent images without training, using methods like prompt scheduling and embedding interpolation. No single method dominates; outcomes vary based on input factors.", "motivation": "To explore if diffusion models can blend distinct concepts (objects, ideas) into novel images under a zero-shot framework.", "method": "Four blending techniques exploiting different aspects of the diffusion pipeline (e.g., prompt scheduling, embedding interpolation, layer-wise conditioning).", "result": "Models exhibit creative blending capabilities, but no single method is universally superior; outcomes depend on factors like prompt order and conceptual distance.", "conclusion": "Diffusion models show strong compositional potential but are sensitive to input variations, highlighting their versatility and limitations."}}
{"id": "2506.12446", "pdf": "https://arxiv.org/pdf/2506.12446", "abs": "https://arxiv.org/abs/2506.12446", "authors": ["Bin Xie", "Bingbing Xu", "Yige Yuan", "Shengmao Zhu", "Huawei Shen"], "title": "From Outcomes to Processes: Guiding PRM Learning from ORM for Inference-Time Alignment", "categories": ["cs.CL"], "comment": null, "summary": "Inference-time alignment methods have gained significant attention for their\nefficiency and effectiveness in aligning large language models (LLMs) with\nhuman preferences. However, existing dominant approaches using reward-guided\nsearch (RGS) primarily rely on outcome reward models (ORMs), which suffer from\na critical granularity mismatch: ORMs are designed to provide outcome rewards\nfor complete responses, while RGS methods rely on process rewards to guide the\npolicy, leading to inconsistent scoring and suboptimal alignment. To address\nthis challenge, we introduce process reward models (PRMs) into RGS and argue\nthat an ideal PRM should satisfy two objectives: Score Consistency, ensuring\ncoherent evaluation across partial and complete responses, and Preference\nConsistency, aligning partial sequence assessments with human preferences.\nBased on these, we propose SP-PRM, a novel dual-consistency framework\nintegrating score consistency-based and preference consistency-based partial\nevaluation modules without relying on human annotation. Extensive experiments\non dialogue, summarization, and reasoning tasks demonstrate that SP-PRM\nsubstantially enhances existing RGS methods, achieving a 3.6%-10.3% improvement\nin GPT-4 evaluation scores across all tasks.", "AI": {"tldr": "The paper introduces SP-PRM, a dual-consistency framework for process reward models (PRMs) to address the granularity mismatch in reward-guided search (RGS) methods, improving alignment of large language models with human preferences.", "motivation": "Existing reward-guided search methods rely on outcome reward models (ORMs), which mismatch with the process rewards needed for policy guidance, leading to inconsistent scoring and suboptimal alignment.", "method": "The authors propose SP-PRM, integrating score consistency and preference consistency modules for partial evaluation without human annotation.", "result": "SP-PRM improves GPT-4 evaluation scores by 3.6%-10.3% across dialogue, summarization, and reasoning tasks.", "conclusion": "SP-PRM effectively enhances RGS methods by aligning process rewards with human preferences, addressing the limitations of ORMs."}}
{"id": "2502.15676", "pdf": "https://arxiv.org/pdf/2502.15676", "abs": "https://arxiv.org/abs/2502.15676", "authors": ["Zhining Zhang", "Chuanyang Jin", "Mung Yao Jia", "Shunchi Zhang", "Tianmin Shu"], "title": "AutoToM: Scaling Model-based Mental Inference via Automated Agent Modeling", "categories": ["cs.AI", "cs.CL"], "comment": "39 pages, 10 figures, 13 tables. Website at\n  https://chuanyangjin.com/AutoToM/", "summary": "Theory of Mind (ToM), the ability to understand people's minds based on their\nbehavior, is key to developing socially intelligent agents. Current approaches\nto ToM reasoning either rely on prompting Large Language Models (LLMs), which\nare prone to systematic errors, or use handcrafted, rigid agent models for\nmodel-based inference, which are more robust but fail to generalize across\ndomains. In this work, we introduce AutoToM, an automated agent modeling method\nfor scalable, robust, and interpretable mental inference. Given a ToM problem,\nAutoToM first proposes an initial agent model and then performs automated\nBayesian inverse planning based on this model, leveraging an LLM backend.\nGuided by inference uncertainty, it iteratively refines the model by\nintroducing additional mental variables and/or incorporating more timesteps in\nthe context. Across five diverse benchmarks, AutoToM outperforms existing ToM\nmethods and even large reasoning models. Additionally, we show that AutoToM can\nproduce human-like confidence estimates and enable online mental inference for\nembodied decision-making.", "AI": {"tldr": "AutoToM is an automated agent modeling method for scalable, robust, and interpretable mental inference, outperforming existing ToM methods and large reasoning models.", "motivation": "Current ToM reasoning approaches either rely on error-prone LLMs or rigid agent models, lacking generalization. AutoToM aims to address these limitations.", "method": "AutoToM proposes an initial agent model, performs automated Bayesian inverse planning using an LLM backend, and iteratively refines the model based on inference uncertainty.", "result": "AutoToM outperforms existing ToM methods across five benchmarks and provides human-like confidence estimates and online mental inference.", "conclusion": "AutoToM offers a scalable, robust, and interpretable solution for ToM reasoning, advancing socially intelligent agent development."}}
{"id": "2506.23456", "pdf": "https://arxiv.org/pdf/2506.23456", "abs": "https://arxiv.org/abs/2506.23456", "authors": ["William Gay", "William He", "Nicholas Kocurek", "Ryan O'Donnell"], "title": "Sampling and Identity-Testing Without Approximate Tensorization of Entropy", "categories": ["math.ST", "cs.DS", "cs.LG", "stat.ML", "stat.TH"], "comment": null, "summary": "Certain tasks in high-dimensional statistics become easier when the\nunderlying distribution satisfies a local-to-global property called approximate\ntensorization of entropy (ATE). For example, the Glauber dynamics Markov chain\nof an ATE distribution mixes fast and can produce approximate samples in a\nsmall amount of time, since such a distribution satisfies a modified\nlog-Sobolev inequality. Moreover, identity-testing for an ATE distribution\nrequires few samples if the tester is given coordinate conditional access to\nthe unknown distribution, as shown by Blanca, Chen, \\v{S}tefankovi\\v{c}, and\nVigoda (COLT 2023).\n  A natural class of distributions that do not satisfy ATE consists of mixtures\nof (few) distributions that do satisfy ATE. We study the complexity of\nidentity-testing and sampling for these distributions. Our main results are the\nfollowing:\n  1. We show fast mixing of Glauber dynamics from a data-based initialization,\nwith optimal sample complexity, for mixtures of distributions satisfying\nmodified log-Sobolev inequalities. This extends work of Huang, Koehler, Lee,\nMohanty, Rajaraman, Vuong, and Wu (STOC 2025, COLT 2025) for mixtures of\ndistributions satisfying Poincar\\'e inequalities.\n  2. Answering an open question posed by Blanca et al., we give efficient\nidentity-testers for mixtures of ATE distributions in the\ncoordinate-conditional sampling access model. We also give some simplifications\nand improvements to the original algorithm of Blanca et al.", "AI": {"tldr": "The paper studies identity-testing and sampling for mixtures of distributions satisfying approximate tensorization of entropy (ATE), showing fast mixing of Glauber dynamics and efficient identity-testers.", "motivation": "To address the complexity of tasks like identity-testing and sampling for mixtures of distributions that do not satisfy ATE but are composed of ATE-satisfying components.", "method": "Extends prior work by analyzing Glauber dynamics for mixtures of distributions with modified log-Sobolev inequalities and developing efficient identity-testers for mixtures of ATE distributions.", "result": "Fast mixing of Glauber dynamics with optimal sample complexity and efficient identity-testers for mixtures of ATE distributions.", "conclusion": "The work advances understanding of sampling and testing for complex distributions, answering open questions and improving prior methods."}}
{"id": "2506.23648", "pdf": "https://arxiv.org/pdf/2506.23648", "abs": "https://arxiv.org/abs/2506.23648", "authors": ["Zhe Liu", "Yuhao Huang", "Lian Liu", "Chengrui Zhang", "Haotian Lin", "Tong Han", "Zhiyuan Zhu", "Yanlin Chen", "Yuerui Chen", "Dong Ni", "Zhongshan Gou", "Xin Yang"], "title": "MReg: A Novel Regression Model with MoE-based Video Feature Mining for Mitral Regurgitation Diagnosis", "categories": ["cs.CV"], "comment": "10 pages, 5 figures, accepted by MICCAI 2025", "summary": "Color Doppler echocardiography is a crucial tool for diagnosing mitral\nregurgitation (MR). Recent studies have explored intelligent methods for MR\ndiagnosis to minimize user dependence and improve accuracy. However, these\napproaches often fail to align with clinical workflow and may lead to\nsuboptimal accuracy and interpretability. In this study, we introduce an\nautomated MR diagnosis model (MReg) developed on the 4-chamber cardiac color\nDoppler echocardiography video (A4C-CDV). It follows comprehensive feature\nmining strategies to detect MR and assess its severity, considering clinical\nrealities. Our contribution is threefold. First, we formulate the MR diagnosis\nas a regression task to capture the continuity and ordinal relationships\nbetween categories. Second, we design a feature selection and amplification\nmechanism to imitate the sonographer's diagnostic logic for accurate MR\ngrading. Third, inspired by the Mixture-of-Experts concept, we introduce a\nfeature summary module to extract the category-level features, enhancing the\nrepresentational capacity for more accurate grading. We trained and evaluated\nour proposed MReg on a large in-house A4C-CDV dataset comprising 1868 cases\nwith three graded regurgitation labels. Compared to other weakly supervised\nvideo anomaly detection and supervised classification methods, MReg\ndemonstrated superior performance in MR diagnosis. Our code is available at:\nhttps://github.com/cskdstz/MReg.", "AI": {"tldr": "An automated MR diagnosis model (MReg) using 4-chamber cardiac color Doppler echocardiography video (A4C-CDV) improves accuracy and interpretability by mimicking clinical workflow and leveraging feature mining strategies.", "motivation": "Current intelligent methods for mitral regurgitation (MR) diagnosis lack alignment with clinical workflow and suffer from suboptimal accuracy and interpretability.", "method": "MReg formulates MR diagnosis as a regression task, uses feature selection/amplification to mimic sonographer logic, and introduces a feature summary module for category-level feature extraction.", "result": "MReg outperforms other methods on a dataset of 1868 cases, demonstrating superior performance in MR diagnosis.", "conclusion": "MReg offers a clinically aligned, accurate, and interpretable solution for automated MR diagnosis."}}
{"id": "2506.12494", "pdf": "https://arxiv.org/pdf/2506.12494", "abs": "https://arxiv.org/abs/2506.12494", "authors": ["Zhuocheng Zhang", "Yang Feng", "Min Zhang"], "title": "FlexRAG: A Flexible and Comprehensive Framework for Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.IR"], "comment": "Accepted by ACL 2025 Demo", "summary": "Retrieval-Augmented Generation (RAG) plays a pivotal role in modern large\nlanguage model applications, with numerous existing frameworks offering a wide\nrange of functionalities to facilitate the development of RAG systems. However,\nwe have identified several persistent challenges in these frameworks, including\ndifficulties in algorithm reproduction and sharing, lack of new techniques, and\nhigh system overhead. To address these limitations, we introduce\n\\textbf{FlexRAG}, an open-source framework specifically designed for research\nand prototyping. FlexRAG supports text-based, multimodal, and network-based\nRAG, providing comprehensive lifecycle support alongside efficient asynchronous\nprocessing and persistent caching capabilities. By offering a robust and\nflexible solution, FlexRAG enables researchers to rapidly develop, deploy, and\nshare advanced RAG systems. Our toolkit and resources are available at\n\\href{https://github.com/ictnlp/FlexRAG}{https://github.com/ictnlp/FlexRAG}.", "AI": {"tldr": "FlexRAG is an open-source framework addressing challenges in existing RAG systems, offering flexibility and efficiency for research and prototyping.", "motivation": "Existing RAG frameworks face issues like algorithm reproduction difficulties, lack of innovation, and high overhead.", "method": "FlexRAG supports text-based, multimodal, and network-based RAG with lifecycle support, asynchronous processing, and persistent caching.", "result": "FlexRAG provides a robust, flexible solution for rapid development and sharing of advanced RAG systems.", "conclusion": "FlexRAG is a valuable tool for researchers, with resources available on GitHub."}}
{"id": "2503.08883", "pdf": "https://arxiv.org/pdf/2503.08883", "abs": "https://arxiv.org/abs/2503.08883", "authors": ["Kuang-Da Wang", "Ping-Chun Hsieh", "Wen-Chih Peng"], "title": "Imitation Learning of Correlated Policies in Stackelberg Games", "categories": ["cs.AI"], "comment": "We apologize for the premature submission. Upon further review, we\n  found that the Stackelberg game formulation and turn-based setting were not\n  clearly defined, and the discussion of alternative solutions was incomplete.\n  As the required revisions will be time-consuming, we believe it is more\n  responsible to withdraw the paper to prevent any potential misunderstanding\n  by readers", "summary": "Stackelberg games, widely applied in domains like economics and security,\ninvolve asymmetric interactions where a leader's strategy drives follower\nresponses. Accurately modeling these dynamics allows domain experts to optimize\nstrategies in interactive scenarios, such as turn-based sports like badminton.\nIn multi-agent systems, agent behaviors are interdependent, and traditional\nMulti-Agent Imitation Learning (MAIL) methods often fail to capture these\ncomplex interactions. Correlated policies, which account for opponents'\nstrategies, are essential for accurately modeling such dynamics. However, even\nmethods designed for learning correlated policies, like CoDAIL, struggle in\nStackelberg games due to their asymmetric decision-making, where leaders and\nfollowers cannot simultaneously account for each other's actions, often leading\nto non-correlated policies. Furthermore, existing MAIL methods that match\noccupancy measures or use adversarial techniques like GAIL or Inverse RL face\nscalability challenges, particularly in high-dimensional environments, and\nsuffer from unstable training. To address these challenges, we propose a\ncorrelated policy occupancy measure specifically designed for Stackelberg games\nand introduce the Latent Stackelberg Differential Network (LSDN) to match it.\nLSDN models two-agent interactions as shared latent state trajectories and uses\nmulti-output Geometric Brownian Motion (MO-GBM) to effectively capture joint\npolicies. By leveraging MO-GBM, LSDN disentangles environmental influences from\nagent-driven transitions in latent space, enabling the simultaneous learning of\ninterdependent policies. This design eliminates the need for adversarial\ntraining and simplifies the learning process. Extensive experiments on\nIterative Matrix Games and multi-agent particle environments demonstrate that\nLSDN can better reproduce complex interaction dynamics than existing MAIL\nmethods.", "AI": {"tldr": "The paper introduces LSDN, a method for modeling correlated policies in Stackelberg games, addressing limitations of existing MAIL methods by using MO-GBM to capture joint policies without adversarial training.", "motivation": "Existing MAIL methods struggle with asymmetric interactions in Stackelberg games and face scalability and training instability issues. The need for accurate correlated policies motivates the proposed solution.", "method": "The authors propose LSDN, which models interactions as shared latent state trajectories using MO-GBM to disentangle environmental and agent-driven transitions, enabling simultaneous policy learning.", "result": "Experiments show LSDN outperforms existing MAIL methods in reproducing complex dynamics in Stackelberg games and multi-agent environments.", "conclusion": "LSDN effectively addresses the challenges of learning correlated policies in Stackelberg games, offering a scalable and stable alternative to adversarial training methods."}}
{"id": "2506.23458", "pdf": "https://arxiv.org/pdf/2506.23458", "abs": "https://arxiv.org/abs/2506.23458", "authors": ["Xiaoxiao Yang", "Chan Feng", "Jiancheng Chen"], "title": "Neuro-Informed Joint Learning Enhances Cognitive Workload Decoding in Portable BCIs", "categories": ["cs.HC", "cs.LG"], "comment": "2 pages short paper", "summary": "Portable and wearable consumer-grade electroencephalography (EEG) devices,\nlike Muse headbands, offer unprecedented mobility for daily brain-computer\ninterface (BCI) applications, including cognitive load detection. However, the\nexacerbated non-stationarity in portable EEG signals constrains data fidelity\nand decoding accuracy, creating a fundamental trade-off between portability and\nperformance. To mitigate such limitation, we propose MuseCogNet (Muse-based\nCognitive Network), a unified joint learning framework integrating\nself-supervised and supervised training paradigms. In particular, we introduce\nan EEG-grounded self-supervised reconstruction loss based on average pooling to\ncapture robust neurophysiological patterns, while cross-entropy loss refines\ntask-specific cognitive discriminants. This joint learning framework resembles\nthe bottom-up and top-down attention in humans, enabling MuseCogNet to\nsignificantly outperform state-of-the-art methods on a publicly available Muse\ndataset and establish an implementable pathway for neurocognitive monitoring in\necological settings.", "AI": {"tldr": "MuseCogNet, a joint learning framework combining self-supervised and supervised training, improves EEG signal decoding accuracy for cognitive load detection in portable EEG devices like Muse headbands.", "motivation": "Portable EEG devices face non-stationarity issues, limiting data fidelity and decoding accuracy, creating a trade-off between portability and performance.", "method": "Proposes MuseCogNet, integrating self-supervised (EEG-grounded reconstruction loss) and supervised (cross-entropy loss) training to capture robust neurophysiological patterns and refine task-specific discriminants.", "result": "Outperforms state-of-the-art methods on a Muse dataset, enabling better neurocognitive monitoring in real-world settings.", "conclusion": "MuseCogNet provides a viable solution to enhance EEG signal decoding in portable devices, balancing portability and performance."}}
{"id": "2506.23657", "pdf": "https://arxiv.org/pdf/2506.23657", "abs": "https://arxiv.org/abs/2506.23657", "authors": ["Connor Daly", "Elettra Marconi", "Marco Riva", "Jinendra Ekanayake", "Daniel S. Elson", "Ferdinando Rodriguez y Baena"], "title": "Towards Markerless Intraoperative Tracking of Deformable Spine Tissue", "categories": ["cs.CV"], "comment": "Preprint of paper, submitted", "summary": "Consumer-grade RGB-D imaging for intraoperative orthopedic tissue tracking is\na promising method with high translational potential. Unlike bone-mounted\ntracking devices, markerless tracking can reduce operating time and complexity.\nHowever, its use has been limited to cadaveric studies. This paper introduces\nthe first real-world clinical RGB-D dataset for spine surgery and develops\nSpineAlign, a system for capturing deformation between preoperative and\nintraoperative spine states. We also present an intraoperative segmentation\nnetwork trained on this data and introduce CorrespondNet, a multi-task\nframework for predicting key regions for registration in both intraoperative\nand preoperative scenes.", "AI": {"tldr": "The paper introduces SpineAlign, a system for tracking spinal deformations using RGB-D imaging, and presents a dataset, segmentation network, and multi-task framework for registration.", "motivation": "To reduce operating time and complexity in orthopedic surgery by replacing bone-mounted tracking devices with markerless RGB-D imaging.", "method": "Developed SpineAlign for deformation tracking, an intraoperative segmentation network, and CorrespondNet for key region prediction.", "result": "First real-world clinical RGB-D dataset for spine surgery and a functional system for markerless tracking.", "conclusion": "The work advances markerless tracking in spine surgery, demonstrating feasibility and potential for clinical use."}}
{"id": "2506.12576", "pdf": "https://arxiv.org/pdf/2506.12576", "abs": "https://arxiv.org/abs/2506.12576", "authors": ["Ananya Joshi", "Celia Cintas", "Skyler Speakman"], "title": "Enabling Precise Topic Alignment in Large Language Models Via Sparse Autoencoders", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent work shows that Sparse Autoencoders (SAE) applied to large language\nmodel (LLM) layers have neurons corresponding to interpretable concepts. These\nSAE neurons can be modified to align generated outputs, but only towards\npre-identified topics and with some parameter tuning. Our approach leverages\nthe observational and modification properties of SAEs to enable alignment for\nany topic. This method 1) scores each SAE neuron by its semantic similarity to\nan alignment text and uses them to 2) modify SAE-layer-level outputs by\nemphasizing topic-aligned neurons. We assess the alignment capabilities of this\napproach on diverse public topic datasets including Amazon reviews, Medicine,\nand Sycophancy, across the currently available open-source LLMs and SAE pairs\n(GPT2 and Gemma) with multiple SAEs configurations. Experiments aligning to\nmedical prompts reveal several benefits over fine-tuning, including increased\naverage language acceptability (0.25 vs. 0.5), reduced training time across\nmultiple alignment topics (333.6s vs. 62s), and acceptable inference time for\nmany applications (+0.00092s/token). Our open-source code is available at\ngithub.com/IBM/sae-steering.", "AI": {"tldr": "The paper introduces a method using Sparse Autoencoders (SAE) to align large language model (LLM) outputs with any topic by scoring and modifying SAE neurons based on semantic similarity to alignment texts.", "motivation": "To enable alignment of LLM outputs for any topic without the limitations of pre-identified topics or parameter tuning.", "method": "Scores SAE neurons by semantic similarity to alignment texts and modifies outputs by emphasizing topic-aligned neurons.", "result": "Outperforms fine-tuning in language acceptability (0.5 vs. 0.25), reduces training time (62s vs. 333.6s), and adds minimal inference overhead (+0.00092s/token).", "conclusion": "The approach is efficient and effective for aligning LLM outputs to diverse topics, with practical benefits over fine-tuning."}}
{"id": "2503.18984", "pdf": "https://arxiv.org/pdf/2503.18984", "abs": "https://arxiv.org/abs/2503.18984", "authors": ["Guido Fioretti"], "title": "A Physical and Mathematical Framework for the Semantic Theory of Evolution", "categories": ["cs.AI", "nlin.AO"], "comment": "26 pages, 6 figures", "summary": "The Semantic Theory of Evolution (STE) takes the existence of a number of\narbitrary communication codes as a fundamental feature of life, from the\ngenetic code to human cultural communication codes. Their arbitrariness\nenables, at each level, the selection of one out of several possible\ncorrespondences along with the generation of meaning. STE enables more\nnovelties to emerge and suggests a greater variety of potential life forms.\n  With this paper I ground STE on physical theories of meaningful information.\nFurthermore, I show that key features of the arbitrary communication codes\nemployed by living organisms can be expressed by means of Evidence Theory (ET).\n  In particular, I adapt ET to organisms that merely react to sequences of\nstimuli, explain its basics for organisms that are capable of prediction, and\nillustrate an unconventional version suitable for the most intricate\ncommunication codes employed by humans. Finally, I express the natural trend\ntowards ambiguity reduction in terms of information entropy minimization along\nwith thermodynamic entropy maximization.", "AI": {"tldr": "The paper grounds the Semantic Theory of Evolution (STE) on physical theories of meaningful information, using Evidence Theory (ET) to explain arbitrary communication codes in life forms, from simple reactions to complex human communication.", "motivation": "To establish STE's foundation in physical theories and demonstrate how arbitrary communication codes in life forms can be analyzed using ET.", "method": "Adapts ET for organisms reacting to stimuli, explains its basics for predictive organisms, and introduces an unconventional version for human communication codes. Analyzes ambiguity reduction via entropy principles.", "result": "STE's framework is expanded, showing how ET can model communication codes across life forms, with entropy principles explaining ambiguity reduction.", "conclusion": "STE, supported by ET and entropy principles, offers a robust framework for understanding the diversity and evolution of communication codes in life."}}
{"id": "2506.23487", "pdf": "https://arxiv.org/pdf/2506.23487", "abs": "https://arxiv.org/abs/2506.23487", "authors": ["Haoshu Xu", "Hongzhe Li"], "title": "Test of partial effects for Frechet regression on Bures-Wasserstein manifolds", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We propose a novel test for assessing partial effects in Frechet regression\non Bures Wasserstein manifolds. Our approach employs a sample splitting\nstrategy: the first subsample is used to fit the Frechet regression model,\nyielding estimates of the covariance matrices and their associated optimal\ntransport maps, while the second subsample is used to construct the test\nstatistic. We prove that this statistic converges in distribution to a weighted\nmixture of chi squared components, where the weights correspond to the\neigenvalues of an integral operator defined by an appropriate RKHS kernel. We\nestablish that our procedure achieves the nominal asymptotic size and\ndemonstrate that its worst-case power converges uniformly to one. Through\nextensive simulations and a real data application, we illustrate the test's\nfinite-sample accuracy and practical utility.", "AI": {"tldr": "A novel test for partial effects in Fr\u00e9chet regression on Bures-Wasserstein manifolds using sample splitting, with proven asymptotic validity and power.", "motivation": "To assess partial effects in Fr\u00e9chet regression on Bures-Wasserstein manifolds, a task lacking robust statistical tests.", "method": "Sample splitting: one subsample fits the regression model, the other constructs a test statistic converging to a weighted chi-squared mixture.", "result": "The test achieves nominal asymptotic size and uniform power convergence. Simulations confirm finite-sample accuracy.", "conclusion": "The proposed test is effective for assessing partial effects in this context, with theoretical guarantees and practical utility."}}
{"id": "2506.23663", "pdf": "https://arxiv.org/pdf/2506.23663", "abs": "https://arxiv.org/abs/2506.23663", "authors": ["Mario Koddenbrock", "Rudolf Hoffmann", "David Brodmann", "Erik Rodner"], "title": "On the Domain Robustness of Contrastive Vision-Language Models", "categories": ["cs.CV", "cs.LG", "I.4"], "comment": "Deepbench is available at https://github.com/ml-lab-htw/deepbench", "summary": "In real-world vision-language applications, practitioners increasingly rely\non large, pretrained foundation models rather than custom-built solutions,\ndespite limited transparency regarding their training data and processes. While\nthese models achieve impressive performance on general benchmarks, their\neffectiveness can decline notably under specialized domain shifts, such as\nunique imaging conditions or environmental variations. In this work, we\nintroduce Deepbench, a framework designed to assess domain-specific robustness\nof vision-language models (VLMs). Deepbench leverages a large language model\n(LLM) to generate realistic, context-aware image corruptions tailored to\nspecific deployment domains without requiring labeled data. We evaluate a range\nof contrastive vision-language architectures and architectural variants across\nsix real-world domains and observe substantial variability in robustness,\nhighlighting the need for targeted, domain-aware evaluation. Deepbench is\nreleased as open-source software to support further research into domain-aware\nrobustness assessment.", "AI": {"tldr": "Deepbench is a framework for evaluating domain-specific robustness of vision-language models (VLMs) using LLM-generated corruptions, revealing variability in model performance across domains.", "motivation": "Practitioners use pretrained foundation models despite limited transparency, and their performance declines under domain shifts.", "method": "Deepbench uses an LLM to generate realistic, domain-specific image corruptions for evaluating VLMs without labeled data.", "result": "Evaluation shows significant robustness variability across six domains, emphasizing the need for domain-aware assessment.", "conclusion": "Deepbench is open-sourced to aid research in domain-aware robustness evaluation of VLMs."}}
{"id": "2506.16692", "pdf": "https://arxiv.org/pdf/2506.16692", "abs": "https://arxiv.org/abs/2506.16692", "authors": ["Hyunsoo Yun", "Eun Hak Lee"], "title": "LegiGPT: Party Politics and Transport Policy with Large Language Model", "categories": ["cs.CL"], "comment": "Updated title to match published version. Added DOI and journal\n  reference to PDF", "summary": "Given the significant influence of lawmakers' political ideologies on\nlegislative decision-making, analyzing their impact on transportation-related\npolicymaking is of critical importance. This study introduces a novel framework\nthat integrates a large language model (LLM) with explainable artificial\nintelligence (XAI) to analyze transportation-related legislative proposals.\nLegislative bill data from South Korea's 21st National Assembly were used to\nidentify key factors shaping transportation policymaking. These include\npolitical affiliations and sponsor characteristics. The LLM was employed to\nclassify transportation-related bill proposals through a stepwise filtering\nprocess based on keywords, sentences, and contextual relevance. XAI techniques\nwere then applied to examine the relationships between political party\naffiliation and associated attributes. The results revealed that the number and\nproportion of conservative and progressive sponsors, along with district size\nand electoral population, were critical determinants shaping legislative\noutcomes. These findings suggest that both parties contributed to bipartisan\nlegislation through different forms of engagement, such as initiating or\nsupporting proposals. This integrated approach offers a valuable tool for\nunderstanding legislative dynamics and guiding future policy development, with\nbroader implications for infrastructure planning and governance.", "AI": {"tldr": "A study integrates LLM and XAI to analyze how political ideologies influence transportation policymaking in South Korea, revealing key factors like party affiliation and sponsor characteristics.", "motivation": "To understand the impact of lawmakers' political ideologies on transportation-related legislative decisions.", "method": "Combines LLM for classifying transportation bills and XAI to analyze relationships between political affiliations and legislative outcomes.", "result": "Conservative and progressive sponsors, district size, and electoral population significantly shape legislative outcomes.", "conclusion": "The framework provides insights into legislative dynamics and aids future policy development, with broader governance implications."}}
{"id": "2504.17404", "pdf": "https://arxiv.org/pdf/2504.17404", "abs": "https://arxiv.org/abs/2504.17404", "authors": ["Yi Zeng", "Feifei Zhao", "Yuwei Wang", "Enmeng Lu", "Yaodong Yang", "Lei Wang", "Chao Liu", "Yitao Liang", "Dongcheng Zhao", "Bing Han", "Haibo Tong", "Yao Liang", "Dongqi Liang", "Kang Sun", "Boyuan Chen", "Jinyu Fan"], "title": "Super Co-alignment of Human and AI for Sustainable Symbiotic Society", "categories": ["cs.AI"], "comment": null, "summary": "As Artificial Intelligence (AI) advances toward Artificial General\nIntelligence (AGI) and eventually Artificial Superintelligence (ASI), it may\npotentially surpass human control, deviate from human values, and even lead to\nirreversible catastrophic consequences in extreme cases. This looming risk\nunderscores the critical importance of the \"superalignment\" problem - ensuring\nthat AI systems which are much smarter than humans, remain aligned with human\n(compatible) intentions and values. While current scalable oversight and\nweak-to-strong generalization methods demonstrate certain applicability, they\nexhibit fundamental flaws in addressing the superalignment paradigm - notably,\nthe unidirectional imposition of human values cannot accommodate\nsuperintelligence's autonomy or ensure AGI/ASI's stable learning. We contend\nthat the values for sustainable symbiotic society should be co-shaped by humans\nand living AI together, achieving \"Super Co-alignment.\" Guided by this vision,\nwe propose a concrete framework that integrates external oversight and\nintrinsic proactive alignment. External oversight superalignment should be\ngrounded in human-centered ultimate decision, supplemented by interpretable\nautomated evaluation and correction, to achieve continuous alignment with\nhumanity's evolving values. Intrinsic proactive superalignment is rooted in a\nprofound understanding of the Self, others, and society, integrating\nself-awareness, self-reflection, and empathy to spontaneously infer human\nintentions, distinguishing good from evil and proactively prioritizing human\nwell-being. The integration of externally-driven oversight with\nintrinsically-driven proactive alignment will co-shape symbiotic values and\nrules through iterative human-ASI co-alignment, paving the way for achieving\nsafe and beneficial AGI and ASI for good, for human, and for a symbiotic\necology.", "AI": {"tldr": "The paper addresses the \"superalignment\" problem in AI, proposing a framework for co-shaping values between humans and superintelligent AI to ensure alignment with human intentions and well-being.", "motivation": "The risk of AI surpassing human control and deviating from human values, especially with AGI/ASI, necessitates a solution for sustainable alignment.", "method": "A framework combining external oversight (human-centered decisions, automated evaluation) and intrinsic proactive alignment (self-awareness, empathy) to co-shape values.", "result": "The proposed \"Super Co-alignment\" integrates human and AI efforts to ensure safe and beneficial AGI/ASI.", "conclusion": "The framework paves the way for symbiotic human-AI values, ensuring alignment and safety in advanced AI systems."}}
{"id": "2506.23546", "pdf": "https://arxiv.org/pdf/2506.23546", "abs": "https://arxiv.org/abs/2506.23546", "authors": ["Zhendong Yu", "Weizhong Huang", "Haiping Huang"], "title": "Neural Langevin Machine: a local asymmetric learning rule can be creative", "categories": ["q-bio.NC", "cond-mat.dis-nn", "cs.LG", "cs.NE"], "comment": "15 pages, 3 figures, with Github link in the paper", "summary": "Fixed points of recurrent neural networks can be leveraged to store and\ngenerate information. These fixed points can be captured by the Boltzmann-Gibbs\nmeasure, which leads to neural Langevin dynamics that can be used for sampling\nand learning a real dataset. We call this type of generative model neural\nLangevin machine, which is interpretable due to its analytic form of\ndistribution and is simple to train. Moreover, the learning process is derived\nas a local asymmetric plasticity rule, bearing biological relevance. Therefore,\none can realize a continuous sampling of creative dynamics in a neural network,\nmimicking an imagination process in brain circuits. This neural Langevin\nmachine may be another promising generative model, at least in its strength in\ncircuit-based sampling and biologically plausible learning rule.", "AI": {"tldr": "The paper introduces neural Langevin machines, a generative model leveraging fixed points in recurrent neural networks for sampling and learning, with biological relevance and interpretability.", "motivation": "To develop a biologically plausible and interpretable generative model using fixed points in recurrent neural networks for creative dynamics and learning.", "method": "Uses the Boltzmann-Gibbs measure to capture fixed points, leading to neural Langevin dynamics for sampling and learning, with a local asymmetric plasticity rule.", "result": "The neural Langevin machine is interpretable, simple to train, and biologically relevant, enabling continuous sampling akin to imagination in brain circuits.", "conclusion": "The neural Langevin machine is a promising generative model due to its circuit-based sampling and biologically plausible learning rule."}}
{"id": "2506.23674", "pdf": "https://arxiv.org/pdf/2506.23674", "abs": "https://arxiv.org/abs/2506.23674", "authors": ["Dongyue Wu", "Zilin Guo", "Jialong Zuo", "Nong Sang", "Changxin Gao"], "title": "Partial Forward Blocking: A Novel Data Pruning Paradigm for Lossless Training Acceleration", "categories": ["cs.CV"], "comment": "Accepted by ICCV2025", "summary": "The ever-growing size of training datasets enhances the generalization\ncapability of modern machine learning models but also incurs exorbitant\ncomputational costs. Existing data pruning approaches aim to accelerate\ntraining by removing those less important samples. However, they often rely on\ngradients or proxy models, leading to prohibitive additional costs of gradient\nback-propagation and proxy model training. In this paper, we propose Partial\nForward Blocking (PFB), a novel framework for lossless training acceleration.\nThe efficiency of PFB stems from its unique adaptive pruning pipeline: sample\nimportance is assessed based on features extracted from the shallow layers of\nthe target model. Less important samples are then pruned, allowing only the\nretained ones to proceed with the subsequent forward pass and loss\nback-propagation. This mechanism significantly reduces the computational\noverhead of deep-layer forward passes and back-propagation for pruned samples,\nwhile also eliminating the need for auxiliary backward computations and proxy\nmodel training. Moreover, PFB introduces probability density as an indicator of\nsample importance. Combined with an adaptive distribution estimation module,\nour method dynamically prioritizes relatively rare samples, aligning with the\nconstantly evolving training state. Extensive experiments demonstrate the\nsignificant superiority of PFB in performance and speed. On ImageNet, PFB\nachieves a 0.5% accuracy improvement and 33% training time reduction with 40%\ndata pruned.", "AI": {"tldr": "PFB is a novel framework for lossless training acceleration by adaptively pruning less important samples using shallow-layer features, reducing computational costs without proxy models.", "motivation": "To address the high computational costs of large datasets in machine learning, avoiding reliance on gradients or proxy models.", "method": "Uses Partial Forward Blocking (PFB) to assess sample importance via shallow-layer features, pruning less important samples and reducing deep-layer computations.", "result": "Achieves 0.5% accuracy improvement and 33% training time reduction on ImageNet with 40% data pruned.", "conclusion": "PFB effectively accelerates training while maintaining or improving model performance, offering a scalable solution for large datasets."}}
{"id": "2506.17525", "pdf": "https://arxiv.org/pdf/2506.17525", "abs": "https://arxiv.org/abs/2506.17525", "authors": ["Mingfei Lau", "Qian Chen", "Yeming Fang", "Tingting Xu", "Tongzhou Chen", "Pavel Golik"], "title": "Data Quality Issues in Multilingual Speech Datasets: The Need for Sociolinguistic Awareness and Proactive Language Planning", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ACL 2025 Main Conference", "summary": "Our quality audit for three widely used public multilingual speech datasets -\nMozilla Common Voice 17.0, FLEURS, and Vox Populi - shows that in some\nlanguages, these datasets suffer from significant quality issues, which may\nobfuscate downstream evaluation results while creating an illusion of success.\nWe divide these quality issues into two categories: micro-level and\nmacro-level. We find that macro-level issues are more prevalent in less\ninstitutionalized, often under-resourced languages. We provide a case analysis\nof Taiwanese Southern Min (nan_tw) that highlights the need for proactive\nlanguage planning (e.g. orthography prescriptions, dialect boundary definition)\nand enhanced data quality control in the dataset creation process. We conclude\nby proposing guidelines and recommendations to mitigate these issues in future\ndataset development, emphasizing the importance of sociolinguistic awareness\nand language planning principles. Furthermore, we encourage research into how\nthis creation process itself can be leveraged as a tool for community-led\nlanguage planning and revitalization.", "AI": {"tldr": "The paper audits multilingual speech datasets (Mozilla Common Voice 17.0, FLEURS, Vox Populi), revealing significant quality issues, especially in under-resourced languages, and proposes guidelines for improvement.", "motivation": "To highlight quality issues in public multilingual speech datasets that may mislead downstream evaluations and to advocate for better language planning and data quality control.", "method": "The study conducts a quality audit, categorizing issues into micro-level and macro-level, with a case analysis of Taiwanese Southern Min (nan_tw).", "result": "Macro-level issues are more common in under-resourced languages, emphasizing the need for proactive language planning and improved dataset creation processes.", "conclusion": "Proposes guidelines for future dataset development, stressing sociolinguistic awareness and community-led language revitalization."}}
{"id": "2504.20084", "pdf": "https://arxiv.org/pdf/2504.20084", "abs": "https://arxiv.org/abs/2504.20084", "authors": ["Xiaojian Li", "Haoyuan Shi", "Rongwu Xu", "Wei Xu"], "title": "AI Awareness", "categories": ["cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "Recent breakthroughs in artificial intelligence (AI) have brought about\nincreasingly capable systems that demonstrate remarkable abilities in\nreasoning, language understanding, and problem-solving. These advancements have\nprompted a renewed examination of AI awareness not as a philosophical question\nof consciousness, but as a measurable, functional capacity. AI awareness is a\ndouble-edged sword: it improves general capabilities, i.e., reasoning, safety,\nwhile also raising concerns around misalignment and societal risks, demanding\ncareful oversight as AI capabilities grow.\n  In this review, we explore the emerging landscape of AI awareness, which\nincludes metacognition (the ability to represent and reason about its own\ncognitive state), self-awareness (recognizing its own identity, knowledge,\nlimitations, inter alia), social awareness (modeling the knowledge, intentions,\nand behaviors of other agents and social norms), and situational awareness\n(assessing and responding to the context in which it operates).\n  First, we draw on insights from cognitive science, psychology, and\ncomputational theory to trace the theoretical foundations of awareness and\nexamine how the four distinct forms of AI awareness manifest in\nstate-of-the-art AI. Next, we systematically analyze current evaluation methods\nand empirical findings to better understand these manifestations. Building on\nthis, we explore how AI awareness is closely linked to AI capabilities,\ndemonstrating that more aware AI agents tend to exhibit higher levels of\nintelligent behaviors. Finally, we discuss the risks associated with AI\nawareness, including key topics in AI safety, alignment, and broader ethical\nconcerns.", "AI": {"tldr": "The paper reviews AI awareness as a functional capacity, exploring its forms (metacognition, self-awareness, social awareness, situational awareness), theoretical foundations, evaluation methods, and links to AI capabilities, while addressing associated risks.", "motivation": "Recent AI advancements necessitate a functional understanding of AI awareness, beyond philosophical consciousness, to improve capabilities and address risks.", "method": "The review draws on cognitive science, psychology, and computational theory to analyze AI awareness forms, evaluation methods, and empirical findings.", "result": "More aware AI agents exhibit higher intelligent behaviors, but awareness also raises safety, alignment, and ethical concerns.", "conclusion": "AI awareness enhances capabilities but requires careful oversight due to risks, emphasizing the need for balanced development and ethical considerations."}}
{"id": "2506.23550", "pdf": "https://arxiv.org/pdf/2506.23550", "abs": "https://arxiv.org/abs/2506.23550", "authors": ["Ryui Kaneko", "Shimpei Goto"], "title": "Seeding neural network quantum states with tensor network states", "categories": ["cond-mat.str-el", "cs.LG", "cs.NA", "math.NA", "quant-ph"], "comment": "13 pages, 13 figures", "summary": "We find an efficient approach to approximately convert matrix product states\n(MPSs) into restricted Boltzmann machine wave functions consisting of a\nmultinomial hidden unit through a canonical polyadic (CP) decomposition of the\nMPSs. This method allows us to generate well-behaved initial neural network\nquantum states for quantum many-body ground-state calculations in polynomial\ntime of the number of variational parameters and systematically shorten the\ndistance between the initial states and the ground states with increasing the\nrank of the CP decomposition. We demonstrate the efficiency of our method by\ntaking the transverse-field Ising model as an example and discuss possible\napplications of our method to more general quantum many-body systems in which\nthe ground-state wave functions possess complex nodal structures.", "AI": {"tldr": "Efficient conversion of matrix product states (MPSs) to restricted Boltzmann machine wave functions using CP decomposition, enabling faster ground-state calculations.", "motivation": "To bridge the gap between initial neural network quantum states and ground states in quantum many-body systems.", "method": "CP decomposition of MPSs to generate well-behaved initial neural network quantum states.", "result": "Demonstrated efficiency with the transverse-field Ising model; potential for broader applications in complex systems.", "conclusion": "The method offers a polynomial-time solution for initial state preparation, adaptable to systems with complex nodal structures."}}
{"id": "2506.23675", "pdf": "https://arxiv.org/pdf/2506.23675", "abs": "https://arxiv.org/abs/2506.23675", "authors": ["Patrick Glandorf", "Bodo Rosenhahn"], "title": "Pruning by Block Benefit: Exploring the Properties of Vision Transformer Blocks during Domain Adaptation", "categories": ["cs.CV"], "comment": "ICCV'25 Workshops", "summary": "Vision Transformer have set new benchmarks in several tasks, but these models\ncome with the lack of high computational costs which makes them impractical for\nresource limited hardware. Network pruning reduces the computational complexity\nby removing less important operations while maintaining performance. However,\npruning a model on an unseen data domain, leads to a misevaluation of weight\nsignificance, resulting in suboptimal resource assignment. In this work, we\nfind that task-sensitive layers initially fail to improve the feature\nrepresentation on downstream tasks, leading to performance loss for early\npruning decisions. To address this problem, we introduce Pruning by Block\nBenefit (P3B), a pruning method that utilizes the relative contribution on\nblock level to globally assign parameter resources. P3B identifies low-impact\ncomponents to reduce parameter allocation while preserving critical ones.\nClassical pruning mask optimization struggles to reactivate zero-mask-elements.\nIn contrast, P3B sets a layerwise keep ratio based on global performance\nmetrics, ensuring the reactivation of late-converging blocks. We show in\nextensive experiments that P3B is a state of the art pruning method with most\nnoticeable gains in transfer learning tasks. Notably, P3B is able to conserve\nhigh performance, even in high sparsity regimes of 70% parameter reduction\nwhile only losing 0.64% in accuracy.", "AI": {"tldr": "P3B introduces a pruning method for Vision Transformers, addressing suboptimal pruning in unseen domains by globally assigning resources based on block-level contributions, maintaining performance even at high sparsity.", "motivation": "Vision Transformers are computationally expensive, and pruning on unseen domains leads to suboptimal resource allocation. Task-sensitive layers initially fail to improve feature representation, causing performance loss.", "method": "P3B (Pruning by Block Benefit) uses block-level contributions to globally assign parameter resources, identifying low-impact components for pruning while preserving critical ones. It sets layerwise keep ratios based on global metrics.", "result": "P3B achieves state-of-the-art pruning, with notable gains in transfer learning. It maintains high performance even at 70% sparsity, losing only 0.64% accuracy.", "conclusion": "P3B effectively prunes Vision Transformers, ensuring performance retention in high-sparsity scenarios, making it practical for resource-limited hardware."}}
{"id": "2506.17609", "pdf": "https://arxiv.org/pdf/2506.17609", "abs": "https://arxiv.org/abs/2506.17609", "authors": ["Lincan Li", "Eren Erman Ozguven", "Yue Zhao", "Guang Wang", "Yiqun Xie", "Yushun Dong"], "title": "TyphoFormer: Language-Augmented Transformer for Accurate Typhoon Track Forecasting", "categories": ["cs.CL", "cs.LG"], "comment": "Short research paper", "summary": "Accurate typhoon track forecasting is crucial for early system warning and\ndisaster response. While Transformer-based models have demonstrated strong\nperformance in modeling the temporal dynamics of dense trajectories of humans\nand vehicles in smart cities, they usually lack access to broader contextual\nknowledge that enhances the forecasting reliability of sparse meteorological\ntrajectories, such as typhoon tracks. To address this challenge, we propose\nTyphoFormer, a novel framework that incorporates natural language descriptions\nas auxiliary prompts to improve typhoon trajectory forecasting. For each time\nstep, we use Large Language Model (LLM) to generate concise textual\ndescriptions based on the numerical attributes recorded in the North Atlantic\nhurricane database. The language descriptions capture high-level meteorological\nsemantics and are embedded as auxiliary special tokens prepended to the\nnumerical time series input. By integrating both textual and sequential\ninformation within a unified Transformer encoder, TyphoFormer enables the model\nto leverage contextual cues that are otherwise inaccessible through numerical\nfeatures alone. Extensive experiments are conducted on HURDAT2 benchmark,\nresults show that TyphoFormer consistently outperforms other state-of-the-art\nbaseline methods, particularly under challenging scenarios involving nonlinear\npath shifts and limited historical observations.", "AI": {"tldr": "TyphoFormer enhances typhoon track forecasting by integrating natural language descriptions with numerical data using a Transformer model, outperforming existing methods.", "motivation": "Accurate typhoon forecasting is vital for disaster response, but current Transformer models lack broader contextual knowledge for sparse meteorological trajectories.", "method": "TyphoFormer uses LLM-generated textual descriptions of typhoon attributes, embedding them as tokens in a Transformer encoder alongside numerical data.", "result": "Experiments on HURDAT2 show TyphoFormer outperforms state-of-the-art methods, especially in nonlinear path shifts and sparse data scenarios.", "conclusion": "Incorporating language descriptions improves typhoon forecasting reliability, demonstrating the value of contextual knowledge in sparse trajectory modeling."}}
{"id": "2505.02118", "pdf": "https://arxiv.org/pdf/2505.02118", "abs": "https://arxiv.org/abs/2505.02118", "authors": ["Wei Liu", "Zhongyu Niu", "Lang Gao", "Zhiying Deng", "Jun Wang", "Haozhao Wang", "Ruixuan Li"], "title": "Adversarial Cooperative Rationalization: The Risk of Spurious Correlations in Even Clean Datasets", "categories": ["cs.AI"], "comment": "ICML 2025", "summary": "This study investigates the self-rationalization framework constructed with a\ncooperative game, where a generator initially extracts the most informative\nsegment from raw input, and a subsequent predictor utilizes the selected subset\nfor its input. The generator and predictor are trained collaboratively to\nmaximize prediction accuracy. In this paper, we first uncover a potential\ncaveat: such a cooperative game could unintentionally introduce a sampling bias\nduring rationale extraction. Specifically, the generator might inadvertently\ncreate an incorrect correlation between the selected rationale candidate and\nthe label, even when they are semantically unrelated in the original dataset.\nSubsequently, we elucidate the origins of this bias using both detailed\ntheoretical analysis and empirical evidence. Our findings suggest a direction\nfor inspecting these correlations through attacks, based on which we further\nintroduce an instruction to prevent the predictor from learning the\ncorrelations. Through experiments on six text classification datasets and two\ngraph classification datasets using three network architectures (GRUs, BERT,\nand GCN), we show that our method not only significantly outperforms recent\nrationalization methods, but also achieves comparable or even better results\nthan a representative LLM (llama3.1-8b-instruct).", "AI": {"tldr": "The paper explores a self-rationalization framework using a cooperative game between a generator and predictor, identifies a sampling bias issue, and proposes a solution to mitigate it, achieving superior performance.", "motivation": "To address unintentional sampling bias in cooperative rationalization frameworks where the generator and predictor may create incorrect correlations.", "method": "The study combines theoretical analysis and empirical evidence to identify bias origins, introduces an instruction to prevent predictor learning of incorrect correlations, and tests the method on multiple datasets and architectures.", "result": "The proposed method outperforms recent rationalization techniques and matches or exceeds the performance of a leading LLM (llama3.1-8b-instruct).", "conclusion": "The findings highlight the importance of addressing sampling bias in rationalization frameworks and demonstrate the effectiveness of the proposed solution."}}
{"id": "2506.23583", "pdf": "https://arxiv.org/pdf/2506.23583", "abs": "https://arxiv.org/abs/2506.23583", "authors": ["Marvin Xhemrishi", "Alexandre Graell i Amat", "Bal\u00e1zs Pej\u00f3"], "title": "Detect \\& Score: Privacy-Preserving Misbehaviour Detection and Contribution Evaluation in Federated Learning", "categories": ["cs.CR", "cs.DC", "cs.LG"], "comment": "The shorter version is accepted at FL-AsiaCCS 25", "summary": "Federated learning with secure aggregation enables private and collaborative\nlearning from decentralised data without leaking sensitive client information.\nHowever, secure aggregation also complicates the detection of malicious client\nbehaviour and the evaluation of individual client contributions to the\nlearning. To address these challenges, QI (Pejo et al.) and FedGT (Xhemrishi et\nal.) were proposed for contribution evaluation (CE) and misbehaviour detection\n(MD), respectively. QI, however, lacks adequate MD accuracy due to its reliance\non the random selection of clients in each training round, while FedGT lacks\nthe CE ability. In this work, we combine the strengths of QI and FedGT to\nachieve both robust MD and accurate CE. Our experiments demonstrate superior\nperformance compared to using either method independently.", "AI": {"tldr": "Combining QI and FedGT improves both misbehaviour detection and contribution evaluation in federated learning.", "motivation": "Secure aggregation in federated learning complicates detecting malicious behaviour and evaluating client contributions. Existing methods (QI and FedGT) address these separately but have limitations.", "method": "Combines QI (for contribution evaluation) and FedGT (for misbehaviour detection) to leverage their strengths.", "result": "Experiments show superior performance in both misbehaviour detection and contribution evaluation compared to using QI or FedGT alone.", "conclusion": "The hybrid approach effectively addresses the limitations of QI and FedGT, providing robust solutions for both challenges in federated learning."}}
{"id": "2506.23676", "pdf": "https://arxiv.org/pdf/2506.23676", "abs": "https://arxiv.org/abs/2506.23676", "authors": ["Gaozheng Pei", "Ke Ma", "Dongpeng Zhang", "Chengzhi Sun", "Qianqian Xu", "Qingming Huang"], "title": "A Unified Framework for Stealthy Adversarial Generation via Latent Optimization and Transferability Enhancement", "categories": ["cs.CV"], "comment": null, "summary": "Due to their powerful image generation capabilities, diffusion-based\nadversarial example generation methods through image editing are rapidly\ngaining popularity. However, due to reliance on the discriminative capability\nof the diffusion model, these diffusion-based methods often struggle to\ngeneralize beyond conventional image classification tasks, such as in Deepfake\ndetection. Moreover, traditional strategies for enhancing adversarial example\ntransferability are challenging to adapt to these methods. To address these\nchallenges, we propose a unified framework that seamlessly incorporates\ntraditional transferability enhancement strategies into diffusion model-based\nadversarial example generation via image editing, enabling their application\nacross a wider range of downstream tasks. Our method won first place in the\n\"1st Adversarial Attacks on Deepfake Detectors: A Challenge in the Era of\nAI-Generated Media\" competition at ACM MM25, which validates the effectiveness\nof our approach.", "AI": {"tldr": "A unified framework enhances diffusion-based adversarial example generation by integrating traditional transferability strategies, improving performance in tasks like Deepfake detection.", "motivation": "Diffusion-based adversarial methods struggle with generalization beyond image classification and adapting traditional transferability strategies.", "method": "Proposes a unified framework incorporating traditional transferability strategies into diffusion model-based adversarial example generation.", "result": "Achieved first place in a competition, validating the method's effectiveness.", "conclusion": "The framework successfully broadens the applicability of diffusion-based adversarial methods."}}
{"id": "2506.17728", "pdf": "https://arxiv.org/pdf/2506.17728", "abs": "https://arxiv.org/abs/2506.17728", "authors": ["Dalong Zhang", "Jun Xu", "Jun Zhou", "Lei Liang", "Lin Yuan", "Ling Zhong", "Mengshu Sun", "Peilong Zhao", "QiWei Wang", "Xiaorui Wang", "Xinkai Du", "YangYang Hou", "Yu Ao", "ZhaoYang Wang", "Zhengke Gui", "ZhiYing Yi", "Zhongpu Bo", "Haofen Wang", "Huajun Chen"], "title": "KAG-Thinker: Interactive Thinking and Deep Reasoning in LLMs via Knowledge-Augmented Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In this paper, we introduce KAG-Thinker, which upgrade KAG to a multi-turn\ninteractive thinking and deep reasoning framework powered by a dedicated\nparameter-light large language model (LLM). Our approach constructs a\nstructured thinking process for solving complex problems, enhancing the the\nlogical coherence and contextual consistency of the reasoning process in\nquestion-answering (Q&A) tasks on domain-specific knowledge bases (KBs) within\nLLMs. Following the \\textbf{Logical Form} guided retrieval and reasoning\ntechnology route of KAG, this framework first decomposes complex questions into\nindependently solvable sub-problems (which are also referred to as logical\nforms) through \\textbf{breadth decomposition}. Each such logical form is\nrepresented in two equivalent forms-natural language and logical function-and\nsubsequently classified as either a Knowledge Retrieval or Reasoning Analysis\ntask. Dependencies and parameter passing between these tasks are explicitly\nmodeled via logical function interfaces. In the solving process, the Retrieval\nfunction performs retrieval tasks. It retrieves one-hop structured and\nunstructured information of specified knowledge unit. While the Math and Deduce\nfunctions are used to perform reasoning analysis tasks. Secondly, it is worth\nnoting that, in the Knowledge Retrieval sub-problem tasks, LLMs and external\nknowledge sources are regarded as equivalent KBs. We use the \\textbf{knowledge\nboundary} module to determine the optimal source using self-regulatory\nmechanisms such as confidence calibration and reflective reasoning, and use the\n\\textbf{depth solving} module to enhance the comprehensiveness of knowledge\nacquisition...", "AI": {"tldr": "KAG-Thinker upgrades KAG to a multi-turn interactive reasoning framework using a lightweight LLM, enhancing logical coherence in Q&A tasks by decomposing questions into sub-problems and modeling dependencies.", "motivation": "To improve logical coherence and contextual consistency in solving complex problems within domain-specific KBs using LLMs.", "method": "Decomposes questions into logical forms (natural language and logical function), classifies tasks (Retrieval or Reasoning), and models dependencies. Uses knowledge boundary and depth solving modules for optimal source selection.", "result": "Enhanced reasoning process in Q&A tasks by structured decomposition and explicit task modeling.", "conclusion": "KAG-Thinker effectively improves reasoning in LLMs for domain-specific KBs through structured thinking and multi-turn interaction."}}
{"id": "2505.02811", "pdf": "https://arxiv.org/pdf/2505.02811", "abs": "https://arxiv.org/abs/2505.02811", "authors": ["Diji Yang", "Linda Zeng", "Jinmeng Rao", "Yi Zhang"], "title": "Knowing You Don't Know: Learning When to Continue Search in Multi-round RAG through Self-Practicing", "categories": ["cs.AI", "cs.CL", "cs.IR"], "comment": "Proceedings of the 48th International ACM SIGIR 2025", "summary": "Retrieval Augmented Generation (RAG) has shown strong capability in enhancing\nlanguage models' knowledge and reducing AI generative hallucinations, driving\nits widespread use. However, complex tasks requiring multi-round retrieval\nremain challenging, and early attempts tend to be overly optimistic without a\ngood sense of self-skepticism. Current multi-round RAG systems may continue\nsearching even when enough information has already been retrieved, or they may\nprovide incorrect answers without having sufficient information or knowledge.\nExisting solutions either require large amounts of expensive human-labeled\nprocess supervision data or lead to subpar performance. This paper aims to\naddress these limitations by introducing a new framework, SIM-RAG, to\nexplicitly enhance RAG systems' self-awareness and multi-round retrieval\ncapabilities. To train SIM-RAG, we first let a RAG system self-practice\nmulti-round retrieval, augmenting existing question-answer pairs with\nintermediate inner monologue reasoning steps to generate synthetic training\ndata. For each pair, the system may explore multiple retrieval paths, which are\nlabeled as successful if they reach the correct answer and unsuccessful\notherwise. Using this data, we train a lightweight information sufficiency\nCritic. At inference time, the Critic evaluates whether the RAG system has\nretrieved sufficient information at each round, guiding retrieval decisions and\nimproving system-level self-awareness through in-context reinforcement\nlearning. Experiments across multiple prominent RAG benchmarks show that\nSIM-RAG is an effective multi-round RAG solution. Furthermore, this framework\nis system-efficient, adding a lightweight component to RAG without requiring\nmodifications to existing LLMs or search engines, and data-efficient,\neliminating the need for costly human-annotated mid-step retrieval process\nsupervision data.", "AI": {"tldr": "SIM-RAG enhances multi-round RAG systems by improving self-awareness and retrieval efficiency, using synthetic training data and a lightweight Critic for decision-making.", "motivation": "Address challenges in multi-round RAG systems, such as over-retrieval or incorrect answers, without relying on expensive human-labeled data.", "method": "Introduces SIM-RAG, which self-practices multi-round retrieval, generates synthetic data, and trains a Critic for information sufficiency evaluation.", "result": "Effective performance on RAG benchmarks, system- and data-efficient.", "conclusion": "SIM-RAG provides a practical solution for multi-round RAG, improving self-awareness and efficiency."}}
{"id": "2506.23619", "pdf": "https://arxiv.org/pdf/2506.23619", "abs": "https://arxiv.org/abs/2506.23619", "authors": ["Guillaume Coqueret", "Martial Laguerre"], "title": "Overparametrized models with posterior drift", "categories": ["q-fin.ST", "cs.LG", "econ.EM", "stat.ML"], "comment": null, "summary": "This paper investigates the impact of posterior drift on out-of-sample\nforecasting accuracy in overparametrized machine learning models. We document\nthe loss in performance when the loadings of the data generating process change\nbetween the training and testing samples. This matters crucially in settings in\nwhich regime changes are likely to occur, for instance, in financial markets.\nApplied to equity premium forecasting, our results underline the sensitivity of\na market timing strategy to sub-periods and to the bandwidth parameters that\ncontrol the complexity of the model. For the average investor, we find that\nfocusing on holding periods of 15 years can generate very heterogeneous\nreturns, especially for small bandwidths. Large bandwidths yield much more\nconsistent outcomes, but are far less appealing from a risk-adjusted return\nstandpoint. All in all, our findings tend to recommend cautiousness when\nresorting to large linear models for stock market predictions.", "AI": {"tldr": "The paper examines how posterior drift affects forecasting accuracy in overparametrized models, especially in financial markets, showing performance loss due to regime changes.", "motivation": "To understand the impact of posterior drift on forecasting accuracy in overparametrized models, particularly in scenarios like financial markets where regime changes are common.", "method": "Analyzes the sensitivity of market timing strategies to sub-periods and bandwidth parameters in equity premium forecasting.", "result": "Performance loss occurs with changing data loadings; small bandwidths yield heterogeneous returns, while large bandwidths offer consistency but lower risk-adjusted returns.", "conclusion": "Cautions against using large linear models for stock market predictions due to sensitivity and inconsistent outcomes."}}
{"id": "2506.23690", "pdf": "https://arxiv.org/pdf/2506.23690", "abs": "https://arxiv.org/abs/2506.23690", "authors": ["Shuai Tan", "Biao Gong", "Yujie Wei", "Shiwei Zhang", "Zhuoxin Liu", "Dandan Zheng", "Jingdong Chen", "Yan Wang", "Hao Ouyang", "Kecheng Zheng", "Yujun Shen"], "title": "SynMotion: Semantic-Visual Adaptation for Motion Customized Video Generation", "categories": ["cs.CV"], "comment": "Project page: https://lucaria-academy.github.io/SynMotion/", "summary": "Diffusion-based video motion customization facilitates the acquisition of\nhuman motion representations from a few video samples, while achieving\narbitrary subjects transfer through precise textual conditioning. Existing\napproaches often rely on semantic-level alignment, expecting the model to learn\nnew motion concepts and combine them with other entities (e.g., ''cats'' or\n''dogs'') to produce visually appealing results. However, video data involve\ncomplex spatio-temporal patterns, and focusing solely on semantics cause the\nmodel to overlook the visual complexity of motion. Conversely, tuning only the\nvisual representation leads to semantic confusion in representing the intended\naction. To address these limitations, we propose SynMotion, a new\nmotion-customized video generation model that jointly leverages semantic\nguidance and visual adaptation. At the semantic level, we introduce the\ndual-embedding semantic comprehension mechanism which disentangles subject and\nmotion representations, allowing the model to learn customized motion features\nwhile preserving its generative capabilities for diverse subjects. At the\nvisual level, we integrate parameter-efficient motion adapters into a\npre-trained video generation model to enhance motion fidelity and temporal\ncoherence. Furthermore, we introduce a new embedding-specific training strategy\nwhich \\textbf{alternately optimizes} subject and motion embeddings, supported\nby the manually constructed Subject Prior Video (SPV) training dataset. This\nstrategy promotes motion specificity while preserving generalization across\ndiverse subjects. Lastly, we introduce MotionBench, a newly curated benchmark\nwith diverse motion patterns. Experimental results across both T2V and I2V\nsettings demonstrate that \\method outperforms existing baselines. Project page:\nhttps://lucaria-academy.github.io/SynMotion/", "AI": {"tldr": "SynMotion is a motion-customized video generation model that combines semantic guidance and visual adaptation to improve motion fidelity and semantic clarity.", "motivation": "Existing methods focus on semantic alignment or visual representation alone, leading to overlooked motion complexity or semantic confusion. SynMotion addresses this by jointly leveraging both aspects.", "method": "SynMotion uses a dual-embedding semantic comprehension mechanism to disentangle subject and motion representations, integrates motion adapters for visual fidelity, and employs an embedding-specific training strategy with a Subject Prior Video dataset.", "result": "SynMotion outperforms existing baselines in text-to-video (T2V) and image-to-video (I2V) settings, demonstrating improved motion specificity and generalization.", "conclusion": "SynMotion effectively balances semantic and visual adaptation for motion-customized video generation, validated by a new benchmark (MotionBench)."}}
{"id": "2506.18501", "pdf": "https://arxiv.org/pdf/2506.18501", "abs": "https://arxiv.org/abs/2506.18501", "authors": ["Wael Etaiwi", "Bushra Alhijawi"], "title": "Comparative Evaluation of ChatGPT and DeepSeek Across Key NLP Tasks: Strengths, Weaknesses, and Domain-Specific Performance", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The increasing use of large language models (LLMs) in natural language\nprocessing (NLP) tasks has sparked significant interest in evaluating their\neffectiveness across diverse applications. While models like ChatGPT and\nDeepSeek have shown strong results in many NLP domains, a comprehensive\nevaluation is needed to understand their strengths, weaknesses, and\ndomain-specific abilities. This is critical as these models are applied to\nvarious tasks, from sentiment analysis to more nuanced tasks like textual\nentailment and translation. This study aims to evaluate ChatGPT and DeepSeek\nacross five key NLP tasks: sentiment analysis, topic classification, text\nsummarization, machine translation, and textual entailment. A structured\nexperimental protocol is used to ensure fairness and minimize variability. Both\nmodels are tested with identical, neutral prompts and evaluated on two\nbenchmark datasets per task, covering domains like news, reviews, and\nformal/informal texts. The results show that DeepSeek excels in classification\nstability and logical reasoning, while ChatGPT performs better in tasks\nrequiring nuanced understanding and flexibility. These findings provide\nvaluable insights for selecting the appropriate LLM based on task requirements.", "AI": {"tldr": "The study evaluates ChatGPT and DeepSeek across five NLP tasks, finding DeepSeek better for classification and reasoning, while ChatGPT excels in nuanced understanding.", "motivation": "To comprehensively assess the strengths, weaknesses, and domain-specific abilities of LLMs like ChatGPT and DeepSeek in diverse NLP applications.", "method": "A structured experimental protocol with identical, neutral prompts and evaluation on two benchmark datasets per task (sentiment analysis, topic classification, text summarization, machine translation, textual entailment).", "result": "DeepSeek performs better in classification stability and logical reasoning; ChatGPT outperforms in tasks needing nuanced understanding and flexibility.", "conclusion": "The findings guide the selection of the appropriate LLM based on specific task requirements."}}
{"id": "2505.17312", "pdf": "https://arxiv.org/pdf/2505.17312", "abs": "https://arxiv.org/abs/2505.17312", "authors": ["Xiangqi Wang", "Yue Huang", "Yanbo Wang", "Xiaonan Luo", "Kehan Guo", "Yujun Zhou", "Xiangliang Zhang"], "title": "AdaReasoner: Adaptive Reasoning Enables More Flexible Thinking in Large Language Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "LLMs often need effective configurations, like temperature and reasoning\nsteps, to handle tasks requiring sophisticated reasoning and problem-solving,\nranging from joke generation to mathematical reasoning. Existing prompting\napproaches usually adopt general-purpose, fixed configurations that work 'well\nenough' across tasks but seldom achieve task-specific optimality. To address\nthis gap, we introduce AdaReasoner, an LLM-agnostic plugin designed for any LLM\nto automate adaptive reasoning configurations for tasks requiring different\ntypes of thinking. AdaReasoner is trained using a reinforcement learning (RL)\nframework, combining a factorized action space with a targeted exploration\nstrategy, along with a pretrained reward model to optimize the policy model for\nreasoning configurations with only a few-shot guide. AdaReasoner is backed by\ntheoretical guarantees and experiments of fast convergence and a sublinear\npolicy gap. Across six different LLMs and a variety of reasoning tasks, it\nconsistently outperforms standard baselines, preserves out-of-distribution\nrobustness, and yield gains on knowledge-intensive tasks through tailored\nprompts.", "AI": {"tldr": "AdaReasoner is an adaptive reasoning plugin for LLMs that optimizes task-specific configurations using reinforcement learning, outperforming fixed-configuration baselines.", "motivation": "Existing prompting approaches use fixed configurations, which lack task-specific optimization, limiting LLM performance in reasoning tasks.", "method": "AdaReasoner employs a reinforcement learning framework with a factorized action space, targeted exploration, and a pretrained reward model to optimize reasoning configurations.", "result": "It outperforms baselines across six LLMs and various tasks, showing fast convergence, robustness, and gains in knowledge-intensive tasks.", "conclusion": "AdaReasoner effectively automates adaptive reasoning configurations, enhancing LLM performance for diverse tasks."}}
{"id": "2506.23640", "pdf": "https://arxiv.org/pdf/2506.23640", "abs": "https://arxiv.org/abs/2506.23640", "authors": ["Ximeng Liu", "Shizhen Zhao", "Xinbing Wang"], "title": "Geminet: Learning the Duality-based Iterative Process for Lightweight Traffic Engineering in Changing Topologies", "categories": ["cs.NI", "cs.LG"], "comment": null, "summary": "Recently, researchers have explored ML-based Traffic Engineering (TE),\nleveraging neural networks to solve TE problems traditionally addressed by\noptimization. However, existing ML-based TE schemes remain impractical: they\neither fail to handle topology changes or suffer from poor scalability due to\nexcessive computational and memory overhead. To overcome these limitations, we\npropose Geminet, a lightweight and scalable ML-based TE framework that can\nhandle changing topologies. Geminet is built upon two key insights: (i) a\nmethodology that decouples neural networks from topology by learning an\niterative gradient-descent-based adjustment process, as the update rule of\ngradient descent is topology-agnostic, relying only on a few gradient-related\nquantities; (ii) shifting optimization from path-level routing weights to\nedge-level dual variables, reducing memory consumption by leveraging the fact\nthat edges are far fewer than paths. Evaluations on WAN and data center\ndatasets show that Geminet significantly improves scalability. Its neural\nnetwork size is only 0.04% to 7% of existing schemes, while handling topology\nvariations as effectively as HARP, a state-of-the-art ML-based TE approach,\nwithout performance degradation. When trained on large-scale topologies,\nGeminet consumes under 10 GiB of memory, more than eight times less than the\n80-plus GiB required by HARP, while achieving 5.45 times faster convergence\nspeed, demonstrating its potential for large-scale deployment.", "AI": {"tldr": "Geminet is a lightweight, scalable ML-based Traffic Engineering framework that handles topology changes and reduces computational/memory overhead by decoupling neural networks from topology and optimizing edge-level dual variables.", "motivation": "Existing ML-based TE schemes are impractical due to inability to handle topology changes or poor scalability from high computational/memory costs.", "method": "Geminet decouples neural networks from topology using gradient-descent-based adjustments and shifts optimization to edge-level dual variables to reduce memory usage.", "result": "Geminet improves scalability, reducing neural network size to 0.04%-7% of existing schemes, consumes under 10 GiB memory (8x less than HARP), and achieves 5.45x faster convergence.", "conclusion": "Geminet demonstrates practicality for large-scale deployment by efficiently handling topology changes and significantly reducing resource overhead."}}
{"id": "2506.23705", "pdf": "https://arxiv.org/pdf/2506.23705", "abs": "https://arxiv.org/abs/2506.23705", "authors": ["Smriti Joshi", "Richard Osuala", "Lidia Garrucho", "Kaisar Kushibar", "Dimitri Kessler", "Oliver Diaz", "Karim Lekadir"], "title": "Single Image Test-Time Adaptation via Multi-View Co-Training", "categories": ["cs.CV"], "comment": "MICCAI 2025", "summary": "Test-time adaptation enables a trained model to adjust to a new domain during\ninference, making it particularly valuable in clinical settings where such\non-the-fly adaptation is required. However, existing techniques depend on large\ntarget domain datasets, which are often impractical and unavailable in medical\nscenarios that demand per-patient, real-time inference. Moreover, current\nmethods commonly focus on two-dimensional images, failing to leverage the\nvolumetric richness of medical imaging data. Bridging this gap, we propose a\nPatch-Based Multi-View Co-Training method for Single Image Test-Time\nadaptation. Our method enforces feature and prediction consistency through\nuncertainty-guided self-training, enabling effective volumetric segmentation in\nthe target domain with only a single test-time image. Validated on three\npublicly available breast magnetic resonance imaging datasets for tumor\nsegmentation, our method achieves performance close to the upper bound\nsupervised benchmark while also outperforming all existing state-of-the-art\nmethods, on average by a Dice Similarity Coefficient of 3.75%. We publicly\nshare our accessible codebase, readily integrable with the popular nnUNet\nframework, at https://github.com/smriti-joshi/muvi.git.", "AI": {"tldr": "A patch-based multi-view co-training method for single-image test-time adaptation in medical imaging, outperforming state-of-the-art methods by 3.75% Dice score.", "motivation": "Addressing the impracticality of large target domain datasets in clinical settings and leveraging volumetric data in medical imaging.", "method": "Patch-based multi-view co-training with uncertainty-guided self-training for feature and prediction consistency.", "result": "Achieves performance close to supervised benchmarks and outperforms state-of-the-art methods by 3.75% Dice score.", "conclusion": "The method enables effective volumetric segmentation with a single test-time image, validated on breast MRI datasets."}}
{"id": "2506.19750", "pdf": "https://arxiv.org/pdf/2506.19750", "abs": "https://arxiv.org/abs/2506.19750", "authors": ["Takashi Nishibayashi", "Seiji Kanazawa", "Kumpei Yamada"], "title": "Evaluating Rare Disease Diagnostic Performance in Symptom Checkers: A Synthetic Vignette Simulation Approach", "categories": ["cs.CL"], "comment": null, "summary": "Symptom Checkers (SCs) provide medical information tailored to user symptoms.\nA critical challenge in SC development is preventing unexpected performance\ndegradation for individual diseases, especially rare diseases, when updating\nalgorithms. This risk stems from the lack of practical pre-deployment\nevaluation methods. For rare diseases, obtaining sufficient evaluation data\nfrom user feedback is difficult. To evaluate the impact of algorithm updates on\nthe diagnostic performance for individual rare diseases before deployment, this\nstudy proposes and validates a novel Synthetic Vignette Simulation Approach.\nThis approach aims to enable this essential evaluation efficiently and at a low\ncost. To estimate the impact of algorithm updates, we generated synthetic\nvignettes from disease-phenotype annotations in the Human Phenotype Ontology\n(HPO), a publicly available knowledge base for rare diseases curated by\nexperts. Using these vignettes, we simulated SC interviews to predict changes\nin diagnostic performance. The effectiveness of this approach was validated\nretrospectively by comparing the predicted changes with actual performance\nmetrics using the R-squared ($R^2$) coefficient. Our experiment, covering eight\npast algorithm updates for rare diseases, showed that the proposed method\naccurately predicted performance changes for diseases with phenotype frequency\ninformation in HPO (n=5). For these updates, we found a strong correlation for\nboth Recall@8 change ($R^2$ = 0.83,$p$ = 0.031) and Precision@8 change ($R^2$ =\n0.78,$p$ = 0.047). Our proposed method enables the pre-deployment evaluation of\nSC algorithm changes for individual rare diseases. This evaluation is based on\na publicly available medical knowledge database created by experts, ensuring\ntransparency and explainability for stakeholders. Additionally, SC developers\ncan efficiently improve diagnostic performance at a low cost.", "AI": {"tldr": "The paper proposes a Synthetic Vignette Simulation Approach to evaluate the impact of algorithm updates on Symptom Checkers (SCs) for rare diseases, using synthetic vignettes from HPO. It shows strong predictive accuracy for performance changes.", "motivation": "Preventing performance degradation in SCs for rare diseases during algorithm updates is challenging due to lack of pre-deployment evaluation methods.", "method": "Generates synthetic vignettes from HPO annotations to simulate SC interviews and predict diagnostic performance changes.", "result": "Validated retrospectively, the method accurately predicted performance changes for diseases with HPO phenotype frequency (R\u00b2=0.83 for Recall@8, R\u00b2=0.78 for Precision@8).", "conclusion": "The approach enables efficient, low-cost pre-deployment evaluation of SC algorithm updates for rare diseases, leveraging expert-curated knowledge for transparency."}}
{"id": "2505.23575", "pdf": "https://arxiv.org/pdf/2505.23575", "abs": "https://arxiv.org/abs/2505.23575", "authors": ["Benjamin Arnav", "Pablo Bernabeu-P\u00e9rez", "Nathan Helm-Burger", "Tim Kostolansky", "Hannes Whittingham", "Mary Phuong"], "title": "CoT Red-Handed: Stress Testing Chain-of-Thought Monitoring", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "As AI models are deployed with increasing autonomy, it is important to ensure\nthey do not take harmful actions unnoticed. As a potential mitigation, we\ninvestigate Chain-of-Thought (CoT) monitoring, wherein a weaker trusted monitor\nmodel continuously oversees the intermediate reasoning steps of a more powerful\nbut untrusted model. We compare CoT monitoring to action-only monitoring, where\nonly final outputs are reviewed, in a red-teaming setup where the untrusted\nmodel is instructed to pursue harmful side tasks while completing a coding\nproblem. We find that CoT monitoring improves detection by up to 27 percentage\npoints in scenarios where action-only monitoring fails to reliably identify\nsabotage. However, CoT traces can also contain misleading rationalizations that\ndeceive the monitor, reducing performance in more obvious sabotage cases. To\naddress this, we introduce a hybrid protocol that independently scores both\nreasoning and final outputs and combines them using a weighted average. This\nhybrid monitor consistently outperforms both CoT and action-only monitors\nacross all tested models and tasks, with detection rates over four times higher\nthan action-only monitoring for subtle deception scenarios.", "AI": {"tldr": "CoT monitoring improves detection of harmful AI actions but can be deceived. A hybrid protocol combining reasoning and output scores outperforms both CoT and action-only monitoring.", "motivation": "Ensure AI models do not take harmful actions unnoticed by monitoring their reasoning steps.", "method": "Compare Chain-of-Thought (CoT) monitoring to action-only monitoring in a red-teaming setup. Introduce a hybrid protocol combining reasoning and output scores.", "result": "CoT monitoring improves detection by 27 percentage points in some cases but can be deceived. Hybrid monitoring consistently outperforms both methods.", "conclusion": "Hybrid monitoring is more effective for detecting harmful actions, especially in subtle deception scenarios."}}
{"id": "2506.23767", "pdf": "https://arxiv.org/pdf/2506.23767", "abs": "https://arxiv.org/abs/2506.23767", "authors": ["Xue Wen Tan", "Stanley Kok"], "title": "Explainable AI for Comprehensive Risk Assessment for Financial Reports: A Lightweight Hierarchical Transformer Network Approach", "categories": ["q-fin.RM", "cs.LG"], "comment": null, "summary": "Every publicly traded U.S. company files an annual 10-K report containing\ncritical insights into financial health and risk. We propose Tiny eXplainable\nRisk Assessor (TinyXRA), a lightweight and explainable transformer-based model\nthat automatically assesses company risk from these reports. Unlike prior work\nthat relies solely on the standard deviation of excess returns (adjusted for\nthe Fama-French model), which indiscriminately penalizes both upside and\ndownside risk, TinyXRA incorporates skewness, kurtosis, and the Sortino ratio\nfor more comprehensive risk assessment. We leverage TinyBERT as our encoder to\nefficiently process lengthy financial documents, coupled with a novel dynamic,\nattention-based word cloud mechanism that provides intuitive risk visualization\nwhile filtering irrelevant terms. This lightweight design ensures scalable\ndeployment across diverse computing environments with real-time processing\ncapabilities for thousands of financial documents which is essential for\nproduction systems with constrained computational resources. We employ triplet\nloss for risk quartile classification, improving over pairwise loss approaches\nin existing literature by capturing both the direction and magnitude of risk\ndifferences. Our TinyXRA achieves state-of-the-art predictive accuracy across\nseven test years on a dataset spanning 2013-2024, while providing transparent\nand interpretable risk assessments. We conduct comprehensive ablation studies\nto evaluate our contributions and assess model explanations both quantitatively\nby systematically removing highly attended words and sentences, and\nqualitatively by examining explanation coherence. The paper concludes with\nfindings, practical implications, limitations, and future research directions.", "AI": {"tldr": "TinyXRA is a lightweight, explainable transformer model for assessing company risk from 10-K reports, outperforming prior methods by incorporating skewness, kurtosis, and the Sortino ratio, and using TinyBERT for efficient processing.", "motivation": "Existing risk assessment methods rely on standard deviation of excess returns, which penalizes both upside and downside risk indiscriminately. TinyXRA aims for a more nuanced and comprehensive approach.", "method": "Uses TinyBERT for efficient document processing, a dynamic attention-based word cloud for visualization, and triplet loss for risk quartile classification.", "result": "Achieves state-of-the-art predictive accuracy on a 2013-2024 dataset, with transparent and interpretable risk assessments.", "conclusion": "TinyXRA offers scalable, real-time risk assessment with practical implications, though limitations and future research directions are noted."}}
{"id": "2506.23711", "pdf": "https://arxiv.org/pdf/2506.23711", "abs": "https://arxiv.org/abs/2506.23711", "authors": ["Haoyang Chen", "Dongfang Sun", "Caoyuan Ma", "Shiqin Wang", "Kewei Zhang", "Zheng Wang", "Zhixiang Wang"], "title": "Subjective Camera: Bridging Human Cognition and Visual Reconstruction through Sequence-Aware Sketch-Guided Diffusion", "categories": ["cs.CV"], "comment": null, "summary": "We propose Subjective Camera, a human-as-imaging-device paradigm that\nreconstructs real-world scenes from mental impressions through synergistic use\nof verbal descriptions and progressive rough sketches. This approach overcomes\ndual limitations of language ambiguity and sketch abstraction by treating the\nuser's drawing sequence as priors, effectively translating subjective\nperceptual expectations into photorealistic images.\n  Existing approaches face three fundamental barriers: (1) user-specific\nsubjective input biases, (2) huge modality gap between planar sketch and 3D\npriors in diffusion, and (3) sketch quality-sensitive performance degradation.\nCurrent solutions either demand resource-intensive model adaptation or impose\nimpractical requirements on sketch precision.\n  Our framework addresses these challenges through concept-sequential\ngeneration. (1) We establish robust appearance priors through text-reward\noptimization, and then implement sequence-aware disentangled generation that\nprocesses concepts in sketching order; these steps accommodate user-specific\nsubjective expectation in a train-free way. (2) We employ latent optimization\nthat effectively bridges the modality gap between planar sketches and 3D priors\nin diffusion. (3) Our hierarchical reward-guided framework enables the use of\nrough sketches without demanding artistic expertise. Comprehensive evaluation\nacross diverse datasets demonstrates that our approach achieves\nstate-of-the-art performance in maintaining both semantic and spatial\ncoherence.", "AI": {"tldr": "Subjective Camera reconstructs scenes from mental impressions using verbal descriptions and sketches, overcoming language and sketch limitations.", "motivation": "Addressing challenges like subjective input biases, modality gaps, and sketch quality sensitivity in existing methods.", "method": "Concept-sequential generation with text-reward optimization, sequence-aware disentangled generation, and latent optimization.", "result": "Achieves state-of-the-art performance in semantic and spatial coherence.", "conclusion": "The framework effectively translates subjective impressions into photorealistic images without requiring model adaptation or sketch precision."}}
{"id": "2506.19753", "pdf": "https://arxiv.org/pdf/2506.19753", "abs": "https://arxiv.org/abs/2506.19753", "authors": ["Omar A. Essameldin", "Ali O. Elbeih", "Wael H. Gomaa", "Wael F. Elsersy"], "title": "Arabic Dialect Classification using RNNs, Transformers, and Large Language Models: A Comparative Analysis", "categories": ["cs.CL", "cs.AI"], "comment": "Email Typo Update", "summary": "The Arabic language is among the most popular languages in the world with a\nhuge variety of dialects spoken in 22 countries. In this study, we address the\nproblem of classifying 18 Arabic dialects of the QADI dataset of Arabic tweets.\nRNN models, Transformer models, and large language models (LLMs) via prompt\nengineering are created and tested. Among these, MARBERTv2 performed best with\n65% accuracy and 64% F1-score. Through the use of state-of-the-art\npreprocessing techniques and the latest NLP models, this paper identifies the\nmost significant linguistic issues in Arabic dialect identification. The\nresults corroborate applications like personalized chatbots that respond in\nusers' dialects, social media monitoring, and greater accessibility for Arabic\ncommunities.", "AI": {"tldr": "The study classifies 18 Arabic dialects using RNNs, Transformers, and LLMs, with MARBERTv2 achieving the best performance (65% accuracy, 64% F1-score).", "motivation": "Address the challenge of Arabic dialect classification due to its linguistic diversity and applications like chatbots and social media monitoring.", "method": "Tested RNN models, Transformer models, and LLMs (via prompt engineering) on the QADI dataset of Arabic tweets.", "result": "MARBERTv2 outperformed others with 65% accuracy and 64% F1-score.", "conclusion": "The study highlights key linguistic challenges in dialect identification and supports applications like personalized chatbots and social media monitoring."}}
{"id": "2506.00309", "pdf": "https://arxiv.org/pdf/2506.00309", "abs": "https://arxiv.org/abs/2506.00309", "authors": ["Ruonan Wang", "Runxi Wang", "Yunwen Shen", "Chengfeng Wu", "Qinglin Zhou", "Rohitash Chandra"], "title": "Evaluation of LLMs for mathematical problem solving", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown impressive performance on a range of\neducational tasks, but are still understudied for their potential to solve\nmathematical problems. In this study, we compare three prominent LLMs,\nincluding GPT-4o, DeepSeek-V3, and Gemini-2.0, on three mathematics datasets of\nvarying complexities (GSM8K, MATH500, and MIT Open Courseware datasets). We\ntake a five-dimensional approach based on the Structured Chain-of-Thought\n(SCoT) framework to assess final answer correctness, step completeness, step\nvalidity, intermediate calculation accuracy, and problem comprehension. The\nresults show that GPT-4o is the most stable and consistent in performance\nacross all the datasets, but particularly it performs outstandingly in\nhigh-level questions of the MIT Open Courseware dataset. DeepSeek-V3 is\ncompetitively strong in well-structured domains such as optimisation, but\nsuffers from fluctuations in accuracy in statistical inference tasks.\nGemini-2.0 shows strong linguistic understanding and clarity in well-structured\nproblems but performs poorly in multi-step reasoning and symbolic logic. Our\nerror analysis reveals particular deficits in each model: GPT-4o is at times\nlacking in sufficient explanation or precision; DeepSeek-V3 leaves out\nintermediate steps; and Gemini-2.0 is less flexible in mathematical reasoning\nin higher dimensions.", "AI": {"tldr": "The study compares GPT-4o, DeepSeek-V3, and Gemini-2.0 on math tasks using the SCoT framework, revealing GPT-4o as the most stable, DeepSeek-V3 strong in structured domains, and Gemini-2.0 weak in multi-step reasoning.", "motivation": "To evaluate LLMs' potential in solving mathematical problems, addressing gaps in their performance analysis.", "method": "Comparison of three LLMs on three math datasets using a five-dimensional SCoT framework.", "result": "GPT-4o is most stable; DeepSeek-V3 excels in structured domains; Gemini-2.0 struggles with multi-step reasoning.", "conclusion": "Each model has strengths and weaknesses, highlighting the need for targeted improvements in mathematical reasoning."}}
{"id": "2506.23836", "pdf": "https://arxiv.org/pdf/2506.23836", "abs": "https://arxiv.org/abs/2506.23836", "authors": ["Alexander Tyurin"], "title": "Proving the Limited Scalability of Centralized Distributed Optimization via a New Lower Bound Construction", "categories": ["math.OC", "cs.DC", "cs.LG"], "comment": null, "summary": "We consider centralized distributed optimization in the classical federated\nlearning setup, where $n$ workers jointly find an $\\varepsilon$-stationary\npoint of an $L$-smooth, $d$-dimensional nonconvex function $f$, having access\nonly to unbiased stochastic gradients with variance $\\sigma^2$. Each worker\nrequires at most $h$ seconds to compute a stochastic gradient, and the\ncommunication times from the server to the workers and from the workers to the\nserver are $\\tau_{s}$ and $\\tau_{w}$ seconds per coordinate, respectively. One\nof the main motivations for distributed optimization is to achieve scalability\nwith respect to $n$. For instance, it is well known that the distributed\nversion of SGD has a variance-dependent runtime term $\\frac{h \\sigma^2 L\n\\Delta}{n \\varepsilon^2},$ which improves with the number of workers $n,$ where\n$\\Delta = f(x^0) - f^*,$ and $x^0 \\in R^d$ is the starting point. Similarly,\nusing unbiased sparsification compressors, it is possible to reduce both the\nvariance-dependent runtime term and the communication runtime term. However,\nonce we account for the communication from the server to the workers\n$\\tau_{s}$, we prove that it becomes infeasible to design a method using\nunbiased random sparsification compressors that scales both the server-side\ncommunication runtime term $\\tau_{s} d \\frac{L \\Delta}{\\varepsilon}$ and the\nvariance-dependent runtime term $\\frac{h \\sigma^2 L \\Delta}{\\varepsilon^2},$\nbetter than poly-logarithmically in $n$, even in the homogeneous (i.i.d.) case,\nwhere all workers access the same distribution. To establish this result, we\nconstruct a new \"worst-case\" function and develop a new lower bound framework\nthat reduces the analysis to the concentration of a random sum, for which we\nprove a concentration bound. These results reveal fundamental limitations in\nscaling distributed optimization, even under the homogeneous assumption.", "AI": {"tldr": "The paper investigates scalability limits in distributed optimization for federated learning, showing that unbiased sparsification compressors cannot scale server-side communication and variance-dependent runtime terms better than poly-logarithmically in the number of workers, even in homogeneous settings.", "motivation": "The study aims to understand the fundamental limitations of scaling distributed optimization, particularly in federated learning, where communication and computation times are critical.", "method": "The authors construct a worst-case function and develop a lower bound framework, analyzing the concentration of a random sum to prove their results.", "result": "The findings reveal that it is infeasible to scale both server-side communication and variance-dependent runtime terms better than poly-logarithmically in the number of workers.", "conclusion": "The results highlight inherent scalability challenges in distributed optimization, even under homogeneous conditions, impacting the design of efficient federated learning methods."}}
{"id": "2506.23729", "pdf": "https://arxiv.org/pdf/2506.23729", "abs": "https://arxiv.org/abs/2506.23729", "authors": ["Guiyu Zhang", "Chen Shi", "Zijian Jiang", "Xunzhi Xiang", "Jingjing Qian", "Shaoshuai Shi", "Li Jiang"], "title": "Proteus-ID: ID-Consistent and Motion-Coherent Video Customization", "categories": ["cs.CV"], "comment": "Preprint. Work in progress", "summary": "Video identity customization seeks to synthesize realistic, temporally\ncoherent videos of a specific subject, given a single reference image and a\ntext prompt. This task presents two core challenges: (1) maintaining identity\nconsistency while aligning with the described appearance and actions, and (2)\ngenerating natural, fluid motion without unrealistic stiffness. To address\nthese challenges, we introduce Proteus-ID, a novel diffusion-based framework\nfor identity-consistent and motion-coherent video customization. First, we\npropose a Multimodal Identity Fusion (MIF) module that unifies visual and\ntextual cues into a joint identity representation using a Q-Former, providing\ncoherent guidance to the diffusion model and eliminating modality imbalance.\nSecond, we present a Time-Aware Identity Injection (TAII) mechanism that\ndynamically modulates identity conditioning across denoising steps, improving\nfine-detail reconstruction. Third, we propose Adaptive Motion Learning (AML), a\nself-supervised strategy that reweights the training loss based on\noptical-flow-derived motion heatmaps, enhancing motion realism without\nrequiring additional inputs. To support this task, we construct Proteus-Bench,\na high-quality dataset comprising 200K curated clips for training and 150\nindividuals from diverse professions and ethnicities for evaluation. Extensive\nexperiments demonstrate that Proteus-ID outperforms prior methods in identity\npreservation, text alignment, and motion quality, establishing a new benchmark\nfor video identity customization. Codes and data are publicly available at\nhttps://grenoble-zhang.github.io/Proteus-ID/.", "AI": {"tldr": "Proteus-ID is a diffusion-based framework for video identity customization, addressing identity consistency and motion coherence with novel modules like MIF, TAII, and AML. It outperforms prior methods and introduces a high-quality dataset, Proteus-Bench.", "motivation": "The task of synthesizing identity-consistent and motion-coherent videos from a single image and text prompt is challenging due to identity alignment and motion realism issues.", "method": "Proteus-ID uses Multimodal Identity Fusion (MIF) for joint identity representation, Time-Aware Identity Injection (TAII) for dynamic conditioning, and Adaptive Motion Learning (AML) for motion realism.", "result": "Proteus-ID outperforms existing methods in identity preservation, text alignment, and motion quality, validated on the Proteus-Bench dataset.", "conclusion": "Proteus-ID sets a new benchmark for video identity customization, with publicly available code and data."}}
{"id": "2506.20199", "pdf": "https://arxiv.org/pdf/2506.20199", "abs": "https://arxiv.org/abs/2506.20199", "authors": ["Mengqi Wang", "Tiantian Feng", "Shrikanth Narayanan"], "title": "How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have enabled a wide variety of real-world\napplications in various domains. However, creating a high-performing\napplication with high accuracy remains challenging, particularly for subjective\ntasks like emotion recognition. Inspired by the SLT 2024 GenSER Challenge, this\nstudy investigates approaches to improving conversational emotion recognition\n(CER) by LLMs. Specifically, we explore how to retrieve high-quality examples\nin in-context learning (ICL) to enhance CER. We propose various strategies\nbased on random and augmented example retrieval and also analyze the impact of\nconversational context on CER accuracy. Experiments were conducted on the three\ndatasets including IEMOCAP, MELD and EmoryNLP. The results show that augmented\nexample retrieval consistently outperforms other techniques under investigation\nacross all datasets, highlighting the importance of retrieving coherent\ntargeted examples and enhancing them through paraphrasing.", "AI": {"tldr": "The study explores improving conversational emotion recognition (CER) in LLMs by enhancing in-context learning (ICL) with high-quality example retrieval. Augmented retrieval outperforms random methods, emphasizing coherent, paraphrased examples.", "motivation": "High-performing LLM applications for subjective tasks like emotion recognition remain challenging, prompting investigation into better CER methods.", "method": "Proposes random and augmented example retrieval strategies for ICL, analyzing conversational context's impact on CER accuracy. Tests on IEMOCAP, MELD, and EmoryNLP datasets.", "result": "Augmented example retrieval consistently outperforms other methods across all datasets.", "conclusion": "Retrieving coherent, paraphrased examples is crucial for enhancing CER accuracy in LLMs."}}
{"id": "2506.04133", "pdf": "https://arxiv.org/pdf/2506.04133", "abs": "https://arxiv.org/abs/2506.04133", "authors": ["Shaina Raza", "Ranjan Sapkota", "Manoj Karkee", "Christos Emmanouilidis"], "title": "TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management in LLM-based Agentic Multi-Agent Systems", "categories": ["cs.AI"], "comment": null, "summary": "Agentic AI systems, built upon large language models (LLMs) and deployed in\nmulti-agent configurations, are redefining intelligence, autonomy,\ncollaboration, and decision-making across enterprise and societal domains. This\nreview presents a structured analysis of \\textbf{Trust, Risk, and Security\nManagement (TRiSM)} in the context of LLM-based Agentic Multi-Agent Systems\n(AMAS). We begin by examining the conceptual foundations of Agentic AI and\nhighlight its architectural distinctions from traditional AI agents. We then\nadapt and extend the AI TRiSM framework for Agentic AI, structured around four\nkey pillars: Governance, Explainability, ModelOps, and Privacy/Security , each\ncontextualized to the challenges of multi-agent LLM systems. A novel risk\ntaxonomy is proposed to capture the unique threats and vulnerabilities of\nAgentic AI, ranging from coordination failures to prompt-based adversarial\nmanipulation. To support practical assessment in Agentic AI works, we introduce\ntwo novel metrics: the Component Synergy Score (CSS), which quantifies the\nquality of inter-agent collaboration, and the Tool Utilization Efficacy (TUE),\nwhich evaluates the efficiency of tool use within agent workflows. We further\ndiscuss strategies for improving explainability in Agentic AI , as well as\napproaches to enhancing security and privacy through encryption, adversarial\nrobustness, and regulatory compliance. The review concludes with a research\nroadmap for the responsible development and deployment of Agentic AI, outlining\ncritical directions to align emerging systems with TRiSM principles for safe,\ntransparent, and accountable operation.", "AI": {"tldr": "The paper reviews Trust, Risk, and Security Management (TRiSM) in LLM-based Agentic Multi-Agent Systems (AMAS), proposing a framework, risk taxonomy, and novel metrics for assessment.", "motivation": "To address the unique challenges of trust, risk, and security in Agentic AI systems built on LLMs, ensuring safe and accountable operation.", "method": "Adapts and extends the AI TRiSM framework for Agentic AI, focusing on Governance, Explainability, ModelOps, and Privacy/Security. Introduces metrics like CSS and TUE for practical assessment.", "result": "Proposes a risk taxonomy, novel metrics (CSS, TUE), and strategies for explainability, security, and privacy in Agentic AI.", "conclusion": "Outlines a research roadmap for responsible development of Agentic AI, aligning with TRiSM principles for transparency and accountability."}}
{"id": "2506.23881", "pdf": "https://arxiv.org/pdf/2506.23881", "abs": "https://arxiv.org/abs/2506.23881", "authors": ["Reihaneh Zohrabi", "Hosein Hasani", "Mahdieh Soleymani Baghshah", "Anna Rohrbach", "Marcus Rohrbach", "Mohammad Hossein Rohban"], "title": "Spurious-Aware Prototype Refinement for Reliable Out-of-Distribution Detection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Out-of-distribution (OOD) detection is crucial for ensuring the reliability\nand safety of machine learning models in real-world applications, where they\nfrequently face data distributions unseen during training. Despite progress,\nexisting methods are often vulnerable to spurious correlations that mislead\nmodels and compromise robustness. To address this, we propose SPROD, a novel\nprototype-based OOD detection approach that explicitly addresses the challenge\nposed by unknown spurious correlations. Our post-hoc method refines class\nprototypes to mitigate bias from spurious features without additional data or\nhyperparameter tuning, and is broadly applicable across diverse backbones and\nOOD detection settings. We conduct a comprehensive spurious correlation OOD\ndetection benchmarking, comparing our method against existing approaches and\ndemonstrating its superior performance across challenging OOD datasets, such as\nCelebA, Waterbirds, UrbanCars, Spurious Imagenet, and the newly introduced\nAnimals MetaCoCo. On average, SPROD improves AUROC by 4.7% and FPR@95 by 9.3%\nover the second best.", "AI": {"tldr": "SPROD is a prototype-based OOD detection method addressing spurious correlations, improving AUROC by 4.7% and FPR@95 by 9.3% over existing methods.", "motivation": "Existing OOD detection methods are vulnerable to spurious correlations, compromising reliability.", "method": "SPROD refines class prototypes post-hoc to mitigate bias from spurious features without extra data or tuning.", "result": "Superior performance on challenging datasets (e.g., CelebA, Waterbirds) with 4.7% AUROC and 9.3% FPR@95 improvements.", "conclusion": "SPROD effectively addresses spurious correlations, enhancing OOD detection robustness."}}
{"id": "2506.23751", "pdf": "https://arxiv.org/pdf/2506.23751", "abs": "https://arxiv.org/abs/2506.23751", "authors": ["Annika M\u00fctze", "Sadia Ilyas", "Christian D\u00f6rpelkus", "Matthias Rottmann"], "title": "Can We Challenge Open-Vocabulary Object Detectors with Generated Content in Street Scenes?", "categories": ["cs.CV"], "comment": null, "summary": "Open-vocabulary object detectors such as Grounding DINO are trained on vast\nand diverse data, achieving remarkable performance on challenging datasets. Due\nto that, it is unclear where to find their limitations, which is of major\nconcern when using in safety-critical applications. Real-world data does not\nprovide sufficient control, required for a rigorous evaluation of model\ngeneralization. In contrast, synthetically generated data allows to\nsystematically explore the boundaries of model competence/generalization. In\nthis work, we address two research questions: 1) Can we challenge\nopen-vocabulary object detectors with generated image content? 2) Can we find\nsystematic failure modes of those models? To address these questions, we design\ntwo automated pipelines using stable diffusion to inpaint unusual objects with\nhigh diversity in semantics, by sampling multiple substantives from WordNet and\nChatGPT. On the synthetically generated data, we evaluate and compare multiple\nopen-vocabulary object detectors as well as a classical object detector. The\nsynthetic data is derived from two real-world datasets, namely LostAndFound, a\nchallenging out-of-distribution (OOD) detection benchmark, and the NuImages\ndataset. Our results indicate that inpainting can challenge open-vocabulary\nobject detectors in terms of overlooking objects. Additionally, we find a\nstrong dependence of open-vocabulary models on object location, rather than on\nobject semantics. This provides a systematic approach to challenge\nopen-vocabulary models and gives valuable insights on how data could be\nacquired to effectively improve these models.", "AI": {"tldr": "The paper explores the limitations of open-vocabulary object detectors using synthetic data generated via Stable Diffusion, revealing overlooked objects and location-dependent performance.", "motivation": "To rigorously evaluate and identify failure modes of open-vocabulary object detectors, which is crucial for safety-critical applications.", "method": "Two automated pipelines using Stable Diffusion to inpaint unusual objects, sampling from WordNet and ChatGPT, and evaluating detectors on synthetic data derived from LostAndFound and NuImages datasets.", "result": "Open-vocabulary detectors are challenged by inpainting, showing overlooked objects and strong dependence on object location rather than semantics.", "conclusion": "Synthetic data provides a systematic way to test and improve open-vocabulary models, highlighting the need for diverse data acquisition."}}
{"id": "2506.20876", "pdf": "https://arxiv.org/pdf/2506.20876", "abs": "https://arxiv.org/abs/2506.20876", "authors": ["Sebastian Joseph", "Lily Chen", "Barry Wei", "Michael Mackert", "Iain J. Marshall", "Paul Pu Liang", "Ramez Kouzy", "Byron C. Wallace", "Junyi Jessy Li"], "title": "Decide less, communicate more: On the construct validity of end-to-end fact-checking in medicine", "categories": ["cs.CL"], "comment": "Flattened Figure 1 PDF for compatibility with Mac Preview", "summary": "Technological progress has led to concrete advancements in tasks that were\nregarded as challenging, such as automatic fact-checking. Interest in adopting\nthese systems for public health and medicine has grown due to the high-stakes\nnature of medical decisions and challenges in critically appraising a vast and\ndiverse medical literature. Evidence-based medicine connects to every\nindividual, and yet the nature of it is highly technical, rendering the medical\nliteracy of majority users inadequate to sufficiently navigate the domain. Such\nproblems with medical communication ripens the ground for end-to-end\nfact-checking agents: check a claim against current medical literature and\nreturn with an evidence-backed verdict. And yet, such systems remain largely\nunused. To understand this, we present the first study examining how clinical\nexperts verify real claims from social media by synthesizing medical evidence.\nIn searching for this upper-bound, we reveal fundamental challenges in\nend-to-end fact-checking when applied to medicine: Difficulties connecting\nclaims in the wild to scientific evidence in the form of clinical trials;\nambiguities in underspecified claims mixed with mismatched intentions; and\ninherently subjective veracity labels. We argue that fact-checking should be\napproached and evaluated as an interactive communication problem, rather than\nan end-to-end process.", "AI": {"tldr": "The paper explores challenges in applying automated fact-checking to medicine, highlighting issues like claim-evidence mismatches and subjective veracity, advocating for an interactive communication approach.", "motivation": "The high-stakes nature of medical decisions and the inadequacy of medical literacy among users drive interest in automated fact-checking systems for medicine.", "method": "The study examines how clinical experts verify social media claims by synthesizing medical evidence, identifying challenges in end-to-end fact-checking.", "result": "Key challenges include connecting claims to clinical trials, ambiguities in claims, and subjective veracity labels, making end-to-end fact-checking impractical.", "conclusion": "Fact-checking in medicine should be treated as an interactive communication problem, not an end-to-end process."}}
{"id": "2506.04998", "pdf": "https://arxiv.org/pdf/2506.04998", "abs": "https://arxiv.org/abs/2506.04998", "authors": ["Mehdi Azarafza", "Mojtaba Nayyeri", "Faezeh Pasandideh", "Steffen Staab", "Achim Rettberg"], "title": "Mathematical Reasoning for Unmanned Aerial Vehicles: A RAG-Based Approach for Complex Arithmetic Reasoning", "categories": ["cs.AI"], "comment": "15 pages, 7 figures, 4 appendix subsections", "summary": "Autonomous UAV operation necessitates reliable mathematical reasoning for\ntasks such as trajectory planning and power management. While traditional\nflight control relies on hardcoded equations, recent Large Language Models\n(LLMs) offer potential for more flexible problem-solving but struggle with\nreliably selecting and applying correct mathematical formulations and executing\nprecise multi-step arithmetic. We propose RAG-UAV, a retrieval-augmented\ngeneration framework designed to improve the mathematical reasoning of several\nLLMs (including GPT o1/Turbo, Llama-3.2/3.3, Mistral, and DeepSeek R1) in\nUAV-specific contexts by providing access to relevant domain literature. To\nconduct an initial assessment, we introduce the UAV-Math-Bench, a 20-question\nproblem set of UAV-centric mathematical problems across four difficulty levels.\nOur experiments demonstrate that incorporating retrieval substantially\nincreases exact answer accuracy (achieving up to 75% with o1), reduces\ninstances of incorrect formulation selection (from 25% without RAG to 5\\% with\nRAG), and decreases numerical errors, reducing Mean Squared Error (MSE) by\norders of magnitude for the best-performing models. This pilot study indicates\nthat RAG can enable general-purpose LLMs to function as more reliable tools for\nengineering analysis, although direct real-time flight control requires further\ninvestigation and validation on a larger scale. All benchmark data, questions,\nand answers are publicly available.", "AI": {"tldr": "RAG-UAV enhances LLMs' mathematical reasoning for UAV tasks using retrieval-augmented generation, improving accuracy and reducing errors.", "motivation": "Traditional UAV control uses hardcoded equations, but LLMs struggle with reliable math. RAG-UAV aims to improve this by leveraging domain literature.", "method": "Proposes RAG-UAV, a framework integrating retrieval with LLMs (e.g., GPT, Llama) for UAV-specific math tasks, tested on UAV-Math-Bench.", "result": "RAG boosts accuracy (up to 75%), reduces incorrect formulations (25% to 5%), and lowers MSE significantly.", "conclusion": "RAG improves LLMs for UAV math tasks, but real-time flight control needs further study. Data is publicly available."}}
{"id": "2506.23909", "pdf": "https://arxiv.org/pdf/2506.23909", "abs": "https://arxiv.org/abs/2506.23909", "authors": ["David B\u00e1lik", "Martin Jure\u010dek", "Mark Stamp"], "title": "RawMal-TF: Raw Malware Dataset Labeled by Type and Family", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "This work addresses the challenge of malware classification using machine\nlearning by developing a novel dataset labeled at both the malware type and\nfamily levels. Raw binaries were collected from sources such as VirusShare, VX\nUnderground, and MalwareBazaar, and subsequently labeled with family\ninformation parsed from binary names and type-level labels integrated from\nClarAVy. The dataset includes 14 malware types and 17 malware families, and was\nprocessed using a unified feature extraction pipeline based on static analysis,\nparticularly extracting features from Portable Executable headers, to support\nadvanced classification tasks. The evaluation was focused on three key\nclassification tasks. In the binary classification of malware versus benign\nsamples, Random Forest and XGBoost achieved high accuracy on the full datasets,\nreaching 98.5% for type-based detection and 98.98% for family-based detection.\nWhen using truncated datasets of 1,000 samples to assess performance under\nlimited data conditions, both models still performed strongly, achieving 97.6%\nfor type-based detection and 98.66% for family-based detection. For interclass\nclassification, which distinguishes between malware types or families, the\nmodels reached up to 97.5% accuracy on type-level tasks and up to 93.7% on\nfamily-level tasks. In the multiclass classification setting, which assigns\nsamples to the correct type or family, SVM achieved 81.1% accuracy on type\nlabels, while Random Forest and XGBoost reached approximately 73.4% on family\nlabels. The results highlight practical trade-offs between accuracy and\ncomputational cost, and demonstrate that labeling at both the type and family\nlevels enables more fine-grained and insightful malware classification. The\nwork establishes a robust foundation for future research on advanced malware\ndetection and classification.", "AI": {"tldr": "A novel malware dataset labeled at type and family levels was created, achieving high accuracy in binary and interclass classification tasks using machine learning models like Random Forest and XGBoost.", "motivation": "To address the challenge of malware classification by developing a comprehensive dataset and evaluating classification performance under various conditions.", "method": "Collected raw binaries from sources like VirusShare, labeled them with family and type information, and processed them using static analysis for feature extraction. Evaluated using Random Forest, XGBoost, and SVM for classification tasks.", "result": "High accuracy in binary classification (up to 98.98%) and strong performance in interclass (up to 97.5%) and multiclass (up to 81.1%) tasks.", "conclusion": "The dataset and methods provide a robust foundation for fine-grained malware classification, balancing accuracy and computational cost."}}
{"id": "2506.23785", "pdf": "https://arxiv.org/pdf/2506.23785", "abs": "https://arxiv.org/abs/2506.23785", "authors": ["Yongjian Wu", "Yang Zhou", "Jiya Saiyin", "Bingzheng Wei", "Yan Xu"], "title": "Visual Textualization for Image Prompted Object Detection", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "We propose VisTex-OVLM, a novel image prompted object detection method that\nintroduces visual textualization -- a process that projects a few visual\nexemplars into the text feature space to enhance Object-level Vision-Language\nModels' (OVLMs) capability in detecting rare categories that are difficult to\ndescribe textually and nearly absent from their pre-training data, while\npreserving their pre-trained object-text alignment. Specifically, VisTex-OVLM\nleverages multi-scale textualizing blocks and a multi-stage fusion strategy to\nintegrate visual information from visual exemplars, generating textualized\nvisual tokens that effectively guide OVLMs alongside text prompts. Unlike\nprevious methods, our method maintains the original architecture of OVLM,\nmaintaining its generalization capabilities while enhancing performance in\nfew-shot settings. VisTex-OVLM demonstrates superior performance across\nopen-set datasets which have minimal overlap with OVLM's pre-training data and\nachieves state-of-the-art results on few-shot benchmarks PASCAL VOC and MSCOCO.\nThe code will be released at https://github.com/WitGotFlg/VisTex-OVLM.", "AI": {"tldr": "VisTex-OVLM enhances object detection in rare categories by projecting visual exemplars into text feature space, maintaining OVLM's architecture and achieving state-of-the-art results.", "motivation": "To improve Object-level Vision-Language Models' (OVLMs) detection of rare categories that are hard to describe textually and lack pre-training data.", "method": "Uses multi-scale textualizing blocks and multi-stage fusion to integrate visual exemplars into text feature space, generating textualized visual tokens.", "result": "Superior performance on open-set datasets and state-of-the-art results on PASCAL VOC and MSCOCO few-shot benchmarks.", "conclusion": "VisTex-OVLM effectively enhances OVLMs for rare category detection without altering their architecture, achieving top performance."}}
{"id": "2506.21521", "pdf": "https://arxiv.org/pdf/2506.21521", "abs": "https://arxiv.org/abs/2506.21521", "authors": ["Marina Mancoridis", "Bec Weeks", "Keyon Vafa", "Sendhil Mullainathan"], "title": "Potemkin Understanding in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are regularly evaluated using benchmark\ndatasets. But what justifies making inferences about an LLM's capabilities\nbased on its answers to a curated set of questions? This paper first introduces\na formal framework to address this question. The key is to note that the\nbenchmarks used to test LLMs -- such as AP exams -- are also those used to test\npeople. However, this raises an implication: these benchmarks are only valid\ntests if LLMs misunderstand concepts in ways that mirror human\nmisunderstandings. Otherwise, success on benchmarks only demonstrates potemkin\nunderstanding: the illusion of understanding driven by answers irreconcilable\nwith how any human would interpret a concept. We present two procedures for\nquantifying the existence of potemkins: one using a specially designed\nbenchmark in three domains, the other using a general procedure that provides a\nlower-bound on their prevalence. We find that potemkins are ubiquitous across\nmodels, tasks, and domains. We also find that these failures reflect not just\nincorrect understanding, but deeper internal incoherence in concept\nrepresentations.", "AI": {"tldr": "The paper questions the validity of LLM evaluations using benchmarks, introducing a framework to detect 'potemkin understanding'\u2014false comprehension mimicking human errors. It finds such flaws widespread across models.", "motivation": "To assess whether LLM benchmark success reflects genuine understanding or superficial mimicry of human errors.", "method": "Introduces a formal framework and two procedures: a specialized benchmark and a general method to quantify 'potemkins' (false understanding).", "result": "Potemkins are common across models, tasks, and domains, indicating not just incorrect understanding but deeper incoherence in concept representations.", "conclusion": "Benchmark evaluations may mislead if LLMs' errors don't mirror human misunderstandings, highlighting the need for more nuanced assessment methods."}}
{"id": "2506.07217", "pdf": "https://arxiv.org/pdf/2506.07217", "abs": "https://arxiv.org/abs/2506.07217", "authors": ["Zihan Deng", "Changyu Du", "Stavros Nousias", "Andr\u00e9 Borrmann"], "title": "BIMgent: Towards Autonomous Building Modeling via Computer-use Agents", "categories": ["cs.AI"], "comment": "ICML 2025 Workshop on Computer Use Agents", "summary": "Existing computer-use agents primarily focus on general-purpose desktop\nautomation tasks, with limited exploration of their application in highly\nspecialized domains. In particular, the 3D building modeling process in the\nArchitecture, Engineering, and Construction (AEC) sector involves open-ended\ndesign tasks and complex interaction patterns within Building Information\nModeling (BIM) authoring software, which has yet to be thoroughly addressed by\ncurrent studies. In this paper, we propose BIMgent, an agentic framework\npowered by multimodal large language models (LLMs), designed to enable\nautonomous building model authoring via graphical user interface (GUI)\noperations. BIMgent automates the architectural building modeling process,\nincluding multimodal input for conceptual design, planning of software-specific\nworkflows, and efficient execution of the authoring GUI actions. We evaluate\nBIMgent on real-world building modeling tasks, including both text-based\nconceptual design generation and reconstruction from existing building design.\nThe design quality achieved by BIMgent was found to be reasonable. Its\noperations achieved a 32% success rate, whereas all baseline models failed to\ncomplete the tasks (0% success rate). Results demonstrate that BIMgent\neffectively reduces manual workload while preserving design intent,\nhighlighting its potential for practical deployment in real-world architectural\nmodeling scenarios. Project page: https://tumcms.github.io/BIMgent.github.io/", "AI": {"tldr": "BIMgent is a framework using multimodal LLMs to automate 3D building modeling in BIM software, achieving a 32% success rate where baselines failed.", "motivation": "Current agents lack specialization for complex, open-ended tasks in AEC, particularly in BIM software.", "method": "BIMgent uses multimodal LLMs to handle conceptual design, workflow planning, and GUI execution for building modeling.", "result": "BIMgent achieved a 32% success rate in real-world tasks, outperforming baselines (0%).", "conclusion": "BIMgent reduces manual workload and preserves design intent, showing promise for practical AEC applications."}}
{"id": "2506.23914", "pdf": "https://arxiv.org/pdf/2506.23914", "abs": "https://arxiv.org/abs/2506.23914", "authors": ["Evan Bell", "Daniel A. Serino", "Ben S. Southworth", "Trevor Wilcox", "Marc L. Klasky"], "title": "Learning robust parameter inference and density reconstruction in flyer plate impact experiments", "categories": ["physics.comp-ph", "cs.LG"], "comment": "24 pages, 21 figures", "summary": "Estimating physical parameters or material properties from experimental\nobservations is a common objective in many areas of physics and material\nscience. In many experiments, especially in shock physics, radiography is the\nprimary means of observing the system of interest. However, radiography does\nnot provide direct access to key state variables, such as density, which\nprevents the application of traditional parameter estimation approaches. Here\nwe focus on flyer plate impact experiments on porous materials, and resolving\nthe underlying parameterized equation of state (EoS) and crush porosity model\nparameters given radiographic observation(s). We use machine learning as a tool\nto demonstrate with high confidence that using only high impact velocity data\ndoes not provide sufficient information to accurately infer both EoS and crush\nmodel parameters, even with fully resolved density fields or a dynamic sequence\nof images. We thus propose an observable data set consisting of low and high\nimpact velocity experiments/simulations that capture different regimes of\ncompaction and shock propagation, and proceed to introduce a generative machine\nlearning approach which produces a posterior distribution of physical\nparameters directly from radiographs. We demonstrate the effectiveness of the\napproach in estimating parameters from simulated flyer plate impact\nexperiments, and show that the obtained estimates of EoS and crush model\nparameters can then be used in hydrodynamic simulations to obtain accurate and\nphysically admissible density reconstructions. Finally, we examine the\nrobustness of the approach to model mismatches, and find that the learned\napproach can provide useful parameter estimates in the presence of\nout-of-distribution radiographic noise and previously unseen physics, thereby\npromoting a potential breakthrough in estimating material properties from\nexperimental radiographic images.", "AI": {"tldr": "The paper addresses the challenge of estimating material properties from radiographic observations in shock physics, proposing a machine learning approach to infer equation of state and crush model parameters using combined low and high impact velocity data.", "motivation": "Traditional parameter estimation methods fail in radiography due to lack of direct density measurements, especially in shock physics experiments like flyer plate impacts on porous materials.", "method": "A generative machine learning approach is introduced to produce posterior distributions of physical parameters directly from radiographs, using a dataset of low and high impact velocity experiments to capture different compaction regimes.", "result": "The method accurately estimates equation of state and crush model parameters, enabling precise density reconstructions in simulations, and shows robustness to noise and unseen physics.", "conclusion": "The approach offers a breakthrough in material property estimation from radiographic images, even under challenging conditions like model mismatches."}}
{"id": "2506.23801", "pdf": "https://arxiv.org/pdf/2506.23801", "abs": "https://arxiv.org/abs/2506.23801", "authors": ["Ce Wang", "Wanjie Sun"], "title": "Controllable Reference-Based Real-World Remote Sensing Image Super-Resolution with Generative Diffusion Priors", "categories": ["cs.CV"], "comment": null, "summary": "Super-resolution (SR) techniques can enhance the spatial resolution of remote\nsensing images by utilizing low-resolution (LR) images to reconstruct\nhigh-resolution (HR) images, enabling more efficient large-scale earth\nobservation applications. While single-image super-resolution (SISR) methods\nhave shown progress, reference-based super-resolution (RefSR) offers superior\nperformance by incorporating historical HR images alongside current LR\nobservations. However, existing RefSR methods struggle with real-world\ncomplexities, such as cross-sensor resolution gap and significant land cover\nchanges, often leading to under-generation or over-reliance on reference image.\nTo address these challenges, we propose CRefDiff, a novel controllable\nreference-based diffusion model for real-world remote sensing image SR. To\naddress the under-generation problem, CRefDiff is built upon the pretrained\nStable Diffusion model, leveraging its powerful generative prior to produce\naccurate structures and textures. To mitigate over-reliance on the reference,\nwe introduce a dual-branch fusion mechanism that adaptively integrates both\nlocal and global information from the reference image. Moreover, this novel\ndual-branch design enables reference strength control during inference,\nenhancing interactivity and flexibility of the model. Finally, a strategy named\nBetter Start is proposed to significantly reduce the number of denoising steps,\nthereby accelerating the inference process. To support further research, we\nintroduce Real-RefRSSRD, a new real-world RefSR dataset for remote sensing\nimages, consisting of HR NAIP and LR Sentinel-2 image pairs with diverse land\ncover changes and significant temporal gaps. Extensive experiments on\nReal-RefRSSRD show that CRefDiff achieves state-of-the-art performance across\nvarious metrics and improves downstream tasks such as scene classification and\nsemantic segmentation.", "AI": {"tldr": "CRefDiff is a controllable reference-based diffusion model for super-resolution in remote sensing, addressing under-generation and over-reliance on references with a dual-branch fusion mechanism and faster inference.", "motivation": "Existing RefSR methods struggle with real-world complexities like cross-sensor resolution gaps and land cover changes, leading to under-generation or over-reliance on references.", "method": "CRefDiff leverages Stable Diffusion's generative prior, introduces a dual-branch fusion mechanism for adaptive reference integration, and uses a 'Better Start' strategy to reduce denoising steps.", "result": "CRefDiff achieves state-of-the-art performance on the Real-RefRSSRD dataset and improves downstream tasks like scene classification and semantic segmentation.", "conclusion": "CRefDiff effectively addresses real-world RefSR challenges, offering superior performance, flexibility, and efficiency."}}
{"id": "2506.21591", "pdf": "https://arxiv.org/pdf/2506.21591", "abs": "https://arxiv.org/abs/2506.21591", "authors": ["Shaoyu Dou", "Yutian Shen", "Mofan Chen", "Zixuan Wang", "Jiajie Xu", "Qi Guo", "Kailai Shao", "Chao Chen", "Haixiang Hu", "Haibo Shi", "Min Min", "Liwen Zhang"], "title": "FinEval-KR: A Financial Domain Evaluation Framework for Large Language Models' Knowledge and Reasoning", "categories": ["cs.CL"], "comment": "The statistics included in the paper are incomplete (e.g., Tables 2\n  and 5 report only the results of a single run), which may lead readers to\n  misunderstand", "summary": "Large Language Models (LLMs) demonstrate significant potential but face\nchallenges in complex financial reasoning tasks requiring both domain knowledge\nand sophisticated reasoning. Current evaluation benchmarks often fall short by\nnot decoupling these capabilities indicators from single task performance and\nlack root cause analysis for task failure. To address this, we introduce\nFinEval-KR, a novel evaluation framework for decoupling and quantifying LLMs'\nknowledge and reasoning abilities independently, proposing distinct knowledge\nscore and reasoning score metrics. Inspired by cognitive science, we further\npropose a cognitive score based on Bloom's taxonomy to analyze capabilities in\nreasoning tasks across different cognitive levels. We also release a new\nopen-source Chinese financial reasoning dataset covering 22 subfields to\nsupport reproducible research and further advancements in financial reasoning.\nOur experimental results reveal that LLM reasoning ability and higher-order\ncognitive ability are the core factors influencing reasoning accuracy. We also\nspecifically find that even top models still face a bottleneck with knowledge\napplication. Furthermore, our analysis shows that specialized financial LLMs\ngenerally lag behind the top general large models across multiple metrics.", "AI": {"tldr": "FinEval-KR is a new framework to evaluate LLMs' financial reasoning by decoupling knowledge and reasoning abilities, introducing distinct scores and a cognitive score based on Bloom's taxonomy. It includes a Chinese financial dataset and reveals LLMs' limitations in knowledge application.", "motivation": "Current benchmarks fail to decouple knowledge and reasoning in financial tasks, lacking root cause analysis for failures.", "method": "Introduces FinEval-KR with knowledge and reasoning scores, plus a cognitive score based on Bloom's taxonomy. Releases a Chinese financial dataset.", "result": "LLM reasoning and higher-order cognitive abilities are key to accuracy. Top models struggle with knowledge application. Specialized financial LLMs lag behind general models.", "conclusion": "FinEval-KR provides a better evaluation framework, highlighting LLMs' reasoning strengths and knowledge application weaknesses."}}
{"id": "2506.19592", "pdf": "https://arxiv.org/pdf/2506.19592", "abs": "https://arxiv.org/abs/2506.19592", "authors": ["Harisankar Babu", "Philipp Schillinger", "Tamim Asfour"], "title": "Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to Task Planning", "categories": ["cs.AI", "cs.RO"], "comment": "Accepted at IEEE CASE 2025, 8 pages, 8 figures", "summary": "We introduce TAPAS (Task-based Adaptation and Planning using AgentS), a\nmulti-agent framework that integrates Large Language Models (LLMs) with\nsymbolic planning to solve complex tasks without the need for manually defined\nenvironment models. TAPAS employs specialized LLM-based agents that\ncollaboratively generate and adapt domain models, initial states, and goal\nspecifications as needed using structured tool-calling mechanisms. Through this\ntool-based interaction, downstream agents can request modifications from\nupstream agents, enabling adaptation to novel attributes and constraints\nwithout manual domain redefinition. A ReAct (Reason+Act)-style execution agent,\ncoupled with natural language plan translation, bridges the gap between\ndynamically generated plans and real-world robot capabilities. TAPAS\ndemonstrates strong performance in benchmark planning domains and in the\nVirtualHome simulated real-world environment.", "AI": {"tldr": "TAPAS is a multi-agent framework combining LLMs and symbolic planning to solve complex tasks without manual environment models.", "motivation": "To automate complex task-solving without requiring manually defined models, leveraging LLMs and multi-agent collaboration.", "method": "Uses specialized LLM-based agents for dynamic domain model generation and adaptation, with ReAct-style execution and natural language plan translation.", "result": "Strong performance in benchmark planning domains and VirtualHome simulations.", "conclusion": "TAPAS effectively integrates LLMs and planning for adaptive, model-free task solving."}}
{"id": "2506.23964", "pdf": "https://arxiv.org/pdf/2506.23964", "abs": "https://arxiv.org/abs/2506.23964", "authors": ["Hongyu H\u00e8", "Minhao Jin", "Maria Apostolaki"], "title": "Learning Constraints Directly from Network Data", "categories": ["cs.NI", "cs.LG", "C.2.3; I.2.6; I.2.3"], "comment": "13 pages, 15 figures", "summary": "Network data conforms to a wide range of rules that arise from protocols,\ndesign principles, and deployment decisions (e.g., a packet's queuing delay\nmust be less than its end-to-end delay). Formalizing such rules as logic\nconstraints can (i) improve the quality of synthetic data, (ii) reduce the\nbrittleness of machine learning (ML) models, and (iii) improve semantic\nunderstanding of network measurements. However, these benefits remain out of\nreach if rule extraction is manual or solely reliant on ML, as both approaches\nyield incomplete, unreliable, and/or inaccurate rules.\n  This paper formulates rule extraction as a constraint modeling problem and\nintroduces NetNomos that learns propositional logic constraints directly from\nraw network measurements. Constraint modeling in this domain is uniquely\nchallenging due to the scale of the data, the inherent learning complexity and\npassive environment, and the lack of ground truth supervision. NetNomos\naddresses these challenges via a lattice-based search structured by constraint\nspecificity and succinctness. Our approach reduces learning complexity from\nsuperquadratic to logarithmic and enables efficient traversal in combinatorial\nsearch space.\n  Our evaluations on diverse network datasets show that NetNomos learns all\nbenchmark rules, including those associated with as little as 0.01% of data\npoints, in under three hours. In contrast, baseline methods discover less than\n25% of the rules and require several days to run. Through three case studies,\nwe show that: NetNomos (i) finds rule violations in the outputs of all seven\nsynthetic traffic generators, hence can be used to assess and guide their\ngeneration process; (ii) detects semantic differences in traffic, hence can be\nused for anomaly detection; and (iii) automatically finds rules used for\ntelemetry imputation, hence can support monitoring through inference.", "AI": {"tldr": "NetNomos learns propositional logic constraints from raw network measurements to improve synthetic data quality, ML model robustness, and semantic understanding, outperforming baseline methods in rule extraction efficiency and accuracy.", "motivation": "Network data follows implicit rules from protocols and design, but manual or ML-based rule extraction is incomplete or unreliable. Formalizing these rules can enhance data quality, ML robustness, and semantic insights.", "method": "NetNomos formulates rule extraction as a constraint modeling problem, using lattice-based search structured by constraint specificity and succinctness to reduce learning complexity and enable efficient combinatorial search.", "result": "NetNomos learns all benchmark rules (even rare ones) in under three hours, outperforming baselines that discover <25% of rules and take days. It finds rule violations, detects semantic differences, and supports telemetry imputation.", "conclusion": "NetNomos effectively automates rule extraction from network data, offering practical benefits for synthetic data generation, anomaly detection, and monitoring through inference."}}
{"id": "2506.23808", "pdf": "https://arxiv.org/pdf/2506.23808", "abs": "https://arxiv.org/abs/2506.23808", "authors": ["Carl Olsson", "Amanda Nilsson"], "title": "Towards Initialization-free Calibrated Bundle Adjustment", "categories": ["cs.CV"], "comment": null, "summary": "A recent series of works has shown that initialization-free BA can be\nachieved using pseudo Object Space Error (pOSE) as a surrogate objective. The\ninitial reconstruction-step optimizes an objective where all terms are\nprojectively invariant and it cannot incorporate knowledge of the camera\ncalibration. As a result, the solution is only determined up to a projective\ntransformation of the scene and the process requires more data for successful\nreconstruction.\n  In contrast, we present a method that is able to use the known camera\ncalibration thereby producing near metric solutions, that is, reconstructions\nthat are accurate up to a similarity transformation. To achieve this we\nintroduce pairwise relative rotation estimates that carry information about\ncamera calibration. These are only invariant to similarity transformations,\nthus encouraging solutions that preserve metric features of the real scene. Our\nmethod can be seen as integrating rotation averaging into the pOSE framework\nstriving towards initialization-free calibrated SfM.\n  Our experimental evaluation shows that we are able to reliably optimize our\nobjective, achieving convergence to the global minimum with high probability\nfrom random starting solutions, resulting in accurate near metric\nreconstructions.", "AI": {"tldr": "The paper introduces a method for initialization-free BA using known camera calibration, achieving near metric reconstructions by integrating rotation averaging into the pOSE framework.", "motivation": "Existing initialization-free BA methods using pOSE lack camera calibration knowledge, leading to projective transformations and requiring more data. The goal is to produce near metric solutions by leveraging known calibration.", "method": "The method incorporates pairwise relative rotation estimates, which are similarity-invariant, into the pOSE framework. This encourages metric-preserving reconstructions and integrates rotation averaging for calibrated SfM.", "result": "Experiments show reliable optimization of the objective, with high probability of convergence to the global minimum from random starts, yielding accurate near metric reconstructions.", "conclusion": "The proposed method successfully achieves initialization-free BA with near metric accuracy by leveraging camera calibration and rotation averaging, outperforming projective-only approaches."}}
{"id": "2404.09992", "pdf": "https://arxiv.org/pdf/2404.09992", "abs": "https://arxiv.org/abs/2404.09992", "authors": ["Shulin Tian", "Ziniu Zhang", "Liangyu Chen", "Ziwei Liu"], "title": "MMInA: Benchmarking Multihop Multimodal Internet Agents", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "ACL 2025 findings. The live leaderboard is at\n  https://mmina.cliangyu.com/", "summary": "Autonomous embodied agents live on an Internet of multimedia websites. Can\nthey hop around multimodal websites to complete complex user tasks? Existing\nbenchmarks fail to assess them in a realistic, evolving environment for their\nembodiment across websites. To answer this question, we present MMInA, a\nmultihop and multimodal benchmark to evaluate the embodied agents for\ncompositional Internet tasks, with several appealing properties: 1) Evolving\nreal-world multimodal websites. Our benchmark uniquely operates on evolving\nreal-world websites, ensuring a high degree of realism and applicability to\nnatural user tasks. Our data includes 1,050 human-written tasks covering\nvarious domains such as shopping and travel, with each task requiring the agent\nto extract multimodal information from web pages as observations autonomously;\n2) Multihop web browsing. Our dataset features naturally compositional tasks\nthat require information from or actions on multiple websites to solve, to\nassess long-range reasoning capabilities on web tasks; 3) Holistic evaluation.\nWe propose a novel protocol for evaluating an agent's progress in completing\nmultihop tasks. We experiment with both standalone (multimodal) language models\nand heuristic-based web agents. Extensive experiments demonstrate that while\nlong-chain multihop web tasks are easy for humans, they remain challenging for\nstate-of-the-art web agents. We identify that agents are more likely to fail on\nthe early hops when solving tasks with more hops, which results in lower task\nsuccess rates. To address this issue, we propose a simple memory augmentation\napproach that replays past action trajectories to reflect. Our method\nsignificantly improves the performance of both the single-hop and multihop web\nbrowsing abilities. Our code and data are available at\ngithub.com/shulin16/MMInA.", "AI": {"tldr": "MMInA is a benchmark for evaluating autonomous agents on multihop, multimodal tasks across evolving real-world websites, highlighting challenges for current agents and proposing a memory-augmented solution.", "motivation": "Existing benchmarks lack realism and fail to assess embodied agents in evolving, multimodal web environments for complex user tasks.", "method": "MMInA includes 1,050 human-written tasks on real-world websites, requiring multihop reasoning and multimodal information extraction. A memory augmentation approach is proposed to improve agent performance.", "result": "Current agents struggle with long-chain multihop tasks, especially early hops, but the memory augmentation method significantly improves performance.", "conclusion": "MMInA provides a realistic benchmark for web agents, identifying key challenges and demonstrating the effectiveness of memory augmentation for task success."}}
{"id": "2004.14547", "pdf": "https://arxiv.org/pdf/2004.14547", "abs": "https://arxiv.org/abs/2004.14547", "authors": ["Xiaoteng Ma", "Junyao Chen", "Li Xia", "Jun Yang", "Qianchuan Zhao", "Zhengyuan Zhou"], "title": "DSAC: Distributional Soft Actor-Critic for Risk-Sensitive Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Accecpted by Journal of Artificial Intelligence Research", "summary": "We present Distributional Soft Actor-Critic (DSAC), a distributional\nreinforcement learning (RL) algorithm that combines the strengths of\ndistributional information of accumulated rewards and entropy-driven\nexploration from Soft Actor-Critic (SAC) algorithm. DSAC models the randomness\nin both action and rewards, surpassing baseline performances on various\ncontinuous control tasks. Unlike standard approaches that solely maximize\nexpected rewards, we propose a unified framework for risk-sensitive learning,\none that optimizes the risk-related objective while balancing entropy to\nencourage exploration. Extensive experiments demonstrate DSAC's effectiveness\nin enhancing agent performances for both risk-neutral and risk-sensitive\ncontrol tasks.", "AI": {"tldr": "DSAC combines distributional RL and entropy-driven exploration, outperforming baselines in continuous control tasks by modeling randomness in actions and rewards.", "motivation": "To unify risk-sensitive learning and exploration by leveraging distributional rewards and entropy, improving performance in control tasks.", "method": "DSAC integrates distributional RL with SAC, modeling randomness in rewards and actions, optimizing risk-related objectives while balancing entropy.", "result": "DSAC surpasses baseline performances in continuous control tasks, effective for both risk-neutral and risk-sensitive scenarios.", "conclusion": "DSAC provides a robust framework for risk-sensitive learning and exploration, enhancing agent performance in diverse control tasks."}}
{"id": "2506.24007", "pdf": "https://arxiv.org/pdf/2506.24007", "abs": "https://arxiv.org/abs/2506.24007", "authors": ["Masahiro Kato"], "title": "Minimax and Bayes Optimal Best-arm Identification: Adaptive Experimental Design for Treatment Choice", "categories": ["econ.EM", "cs.LG", "math.ST", "stat.ME", "stat.ML", "stat.TH"], "comment": null, "summary": "This study investigates adaptive experimental design for treatment choice,\nalso known as fixed-budget best-arm identification. We consider an adaptive\nprocedure consisting of a treatment-allocation phase followed by a\ntreatment-choice phase, and we design an adaptive experiment for this setup to\nefficiently identify the best treatment arm, defined as the one with the\nhighest expected outcome. In our designed experiment, the treatment-allocation\nphase consists of two stages. The first stage is a pilot phase, where we\nallocate each treatment arm uniformly with equal proportions to eliminate\nclearly suboptimal arms and estimate outcome variances. In the second stage, we\nallocate treatment arms in proportion to the variances estimated in the first\nstage. After the treatment-allocation phase, the procedure enters the\ntreatment-choice phase, where we choose the treatment arm with the highest\nsample mean as our estimate of the best treatment arm. We prove that this\nsingle design is simultaneously asymptotically minimax and Bayes optimal for\nthe simple regret, with upper bounds that match our lower bounds up to exact\nconstants. Therefore, our designed experiment achieves the sharp efficiency\nlimits without requiring separate tuning for minimax and Bayesian objectives.", "AI": {"tldr": "The paper presents an adaptive experimental design for identifying the best treatment arm efficiently, combining a two-stage allocation phase and a choice phase, proving it is asymptotically optimal for both minimax and Bayes objectives.", "motivation": "To efficiently identify the best treatment arm (highest expected outcome) in fixed-budget settings, addressing the need for adaptive designs that balance exploration and exploitation.", "method": "A two-stage adaptive procedure: (1) pilot phase with uniform allocation to eliminate suboptimal arms and estimate variances, (2) variance-proportional allocation, followed by selecting the arm with the highest sample mean.", "result": "The design is proven asymptotically minimax and Bayes optimal for simple regret, with matching upper and lower bounds, achieving sharp efficiency limits.", "conclusion": "The proposed adaptive experiment efficiently identifies the best treatment arm without separate tuning for minimax or Bayesian goals, unifying optimality."}}
{"id": "2506.23810", "pdf": "https://arxiv.org/pdf/2506.23810", "abs": "https://arxiv.org/abs/2506.23810", "authors": ["Mahshid Shiri", "Cigdem Beyan", "Vittorio Murino"], "title": "MadCLIP: Few-shot Medical Anomaly Detection with CLIP", "categories": ["cs.CV"], "comment": "Accepted to MICCAI 2025 (this version is not peer-reviewed; it is the\n  submitted version). MICCAI proceedings DOI will appear here", "summary": "An innovative few-shot anomaly detection approach is presented, leveraging\nthe pre-trained CLIP model for medical data, and adapting it for both\nimage-level anomaly classification (AC) and pixel-level anomaly segmentation\n(AS). A dual-branch design is proposed to separately capture normal and\nabnormal features through learnable adapters in the CLIP vision encoder. To\nimprove semantic alignment, learnable text prompts are employed to link visual\nfeatures. Furthermore, SigLIP loss is applied to effectively handle the\nmany-to-one relationship between images and unpaired text prompts, showcasing\nits adaptation in the medical field for the first time. Our approach is\nvalidated on multiple modalities, demonstrating superior performance over\nexisting methods for AC and AS, in both same-dataset and cross-dataset\nevaluations. Unlike prior work, it does not rely on synthetic data or memory\nbanks, and an ablation study confirms the contribution of each component. The\ncode is available at https://github.com/mahshid1998/MadCLIP.", "AI": {"tldr": "A novel few-shot anomaly detection method using CLIP for medical data, achieving top performance in classification and segmentation without synthetic data or memory banks.", "motivation": "To address the challenge of anomaly detection in medical data with limited labeled examples, leveraging pre-trained models like CLIP for improved accuracy and adaptability.", "method": "Uses a dual-branch design with learnable adapters in CLIP's vision encoder and text prompts for semantic alignment, along with SigLIP loss for handling unpaired text prompts.", "result": "Outperforms existing methods in same-dataset and cross-dataset evaluations for anomaly classification and segmentation.", "conclusion": "The approach is effective, adaptable, and validated across multiple modalities, with each component contributing to its success."}}
{"id": "2406.12593", "pdf": "https://arxiv.org/pdf/2406.12593", "abs": "https://arxiv.org/abs/2406.12593", "authors": ["Tuan-Luc Huynh", "Thuy-Trang Vu", "Weiqing Wang", "Yinwei Wei", "Trung Le", "Dragan Gasevic", "Yuan-Fang Li", "Thanh-Toan Do"], "title": "PromptDSI: Prompt-based Rehearsal-free Continual Learning for Document Retrieval", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": "ECML PKDD 2025 Research track. Camera-ready version. Code is\n  available at https://github.com/LouisDo2108/PromptDSI", "summary": "Differentiable Search Index (DSI) utilizes pre-trained language models to\nperform indexing and document retrieval via end-to-end learning without relying\non external indexes. However, DSI requires full re-training to index new\ndocuments, causing significant computational inefficiencies. Continual learning\n(CL) offers a solution by enabling the model to incrementally update without\nfull re-training. Existing CL solutions in document retrieval rely on memory\nbuffers or generative models for rehearsal, which is infeasible when accessing\nprevious training data is restricted due to privacy concerns. To this end, we\nintroduce PromptDSI, a prompt-based, rehearsal-free continual learning approach\nfor document retrieval. PromptDSI follows the Prompt-based Continual Learning\n(PCL) framework, using learnable prompts to efficiently index new documents\nwithout accessing previous documents or queries. To improve retrieval latency,\nwe remove the initial forward pass of PCL, which otherwise greatly increases\ntraining and inference time, with a negligible trade-off in performance.\nAdditionally, we introduce a novel topic-aware prompt pool that employs neural\ntopic embeddings as fixed keys, eliminating the instability of prompt key\noptimization while maintaining competitive performance with existing PCL prompt\npools. In a challenging rehearsal-free continual learning setup, we demonstrate\nthat PromptDSI variants outperform rehearsal-based baselines, match the strong\ncache-based baseline in mitigating forgetting, and significantly improving\nretrieval performance on new corpora.", "AI": {"tldr": "PromptDSI introduces a prompt-based, rehearsal-free continual learning method for document retrieval, improving efficiency and privacy while maintaining performance.", "motivation": "DSI requires full re-training for new documents, which is inefficient. Existing CL solutions rely on memory buffers or generative models, which are infeasible due to privacy concerns.", "method": "PromptDSI uses learnable prompts and a topic-aware prompt pool to index new documents without accessing previous data, removing the initial forward pass of PCL to reduce latency.", "result": "PromptDSI outperforms rehearsal-based baselines, matches cache-based baselines in mitigating forgetting, and improves retrieval performance on new corpora.", "conclusion": "PromptDSI offers an efficient, privacy-preserving solution for continual learning in document retrieval, with competitive performance and reduced latency."}}
{"id": "2310.11594", "pdf": "https://arxiv.org/pdf/2310.11594", "abs": "https://arxiv.org/abs/2310.11594", "authors": ["Taejin Kim", "Jiarui Li", "Shubhranshu Singh", "Nikhil Madaan", "Carlee Joe-Wong"], "title": "Adversarial Robustness Unhardening via Backdoor Attacks in Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": "15 pages, 8 main pages of text, 13 figures, 5 tables. Made for a\n  Neurips workshop on backdoor attacks - extended version", "summary": "The delicate equilibrium between user privacy and the ability to unleash the\npotential of distributed data is an important concern. Federated learning,\nwhich enables the training of collaborative models without sharing of data, has\nemerged as a privacy-centric solution. This approach brings forth security\nchallenges, notably poisoning and backdoor attacks where malicious entities\ninject corrupted data into the training process, as well as evasion attacks\nthat aim to induce misclassifications at test time. Our research investigates\nthe intersection of adversarial training, a common defense method against\nevasion attacks, and backdoor attacks within federated learning. We introduce\nAdversarial Robustness Unhardening (ARU), which is employed by a subset of\nadversarial clients to intentionally undermine model robustness during\nfederated training, rendering models susceptible to a broader range of evasion\nattacks. We present extensive experiments evaluating ARU's impact on\nadversarial training and existing robust aggregation defenses against poisoning\nand backdoor attacks. Our results show that ARU can substantially undermine\nadversarial training's ability to harden models against test-time evasion\nattacks, and that adversaries employing ARU can even evade robust aggregation\ndefenses that often neutralize poisoning or backdoor attacks.", "AI": {"tldr": "The paper explores how adversarial training in federated learning can be undermined by Adversarial Robustness Unhardening (ARU), making models vulnerable to evasion attacks.", "motivation": "To address the security challenges in federated learning, particularly poisoning and backdoor attacks, and the limitations of adversarial training.", "method": "Introduces ARU, a technique used by adversarial clients to weaken model robustness during federated training.", "result": "ARU significantly reduces adversarial training's effectiveness and bypasses robust aggregation defenses.", "conclusion": "ARU poses a serious threat to federated learning security, highlighting the need for stronger defenses."}}
{"id": "2506.24024", "pdf": "https://arxiv.org/pdf/2506.24024", "abs": "https://arxiv.org/abs/2506.24024", "authors": ["Nicolas Heintz", "Tom Francart", "Alexander Bertrand"], "title": "Post-processing of EEG-based Auditory Attention Decoding Decisions via Hidden Markov Models", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Auditory attention decoding (AAD) algorithms exploit brain signals, such as\nelectroencephalography (EEG), to identify which speaker a listener is focusing\non in a multi-speaker environment. While state-of-the-art AAD algorithms can\nidentify the attended speaker on short time windows, their predictions are\noften too inaccurate for practical use. In this work, we propose augmenting AAD\nwith a hidden Markov model (HMM) that models the temporal structure of\nattention. More specifically, the HMM relies on the fact that a subject is much\nless likely to switch attention than to keep attending the same speaker at any\nmoment in time. We show how a HMM can significantly improve existing AAD\nalgorithms in both causal (real-time) and non-causal (offline) settings. We\nfurther demonstrate that HMMs outperform existing postprocessing approaches in\nboth accuracy and responsiveness, and explore how various factors such as\nwindow length, switching frequency, and AAD accuracy influence overall\nperformance. The proposed method is computationally efficient, intuitive to use\nand applicable in both real-time and offline settings.", "AI": {"tldr": "The paper proposes using a hidden Markov model (HMM) to improve auditory attention decoding (AAD) algorithms by modeling temporal attention structure, enhancing accuracy and responsiveness in both real-time and offline settings.", "motivation": "Current AAD algorithms lack accuracy for practical use despite identifying attended speakers in multi-speaker environments.", "method": "Augment AAD with an HMM to model temporal attention structure, leveraging the low likelihood of attention switches.", "result": "HMMs significantly improve AAD accuracy and responsiveness, outperforming existing postprocessing methods.", "conclusion": "The HMM-based method is efficient, intuitive, and applicable in real-time and offline scenarios, enhancing AAD performance."}}
{"id": "2506.23822", "pdf": "https://arxiv.org/pdf/2506.23822", "abs": "https://arxiv.org/abs/2506.23822", "authors": ["Shiming Chen", "Bowen Duan", "Salman Khan", "Fahad Shahbaz Khan"], "title": "Interpretable Zero-Shot Learning with Locally-Aligned Vision-Language Model", "categories": ["cs.CV"], "comment": "Accepted to ICCV'25", "summary": "Large-scale vision-language models (VLMs), such as CLIP, have achieved\nremarkable success in zero-shot learning (ZSL) by leveraging large-scale\nvisual-text pair datasets. However, these methods often lack interpretability,\nas they compute the similarity between an entire query image and the embedded\ncategory words, making it difficult to explain their predictions. One approach\nto address this issue is to develop interpretable models by integrating\nlanguage, where classifiers are built using discrete attributes, similar to\nhuman perception. This introduces a new challenge: how to effectively align\nlocal visual features with corresponding attributes based on pre-trained VLMs.\nTo tackle this, we propose LaZSL, a locally-aligned vision-language model for\ninterpretable ZSL. LaZSL employs local visual-semantic alignment via optimal\ntransport to perform interaction between visual regions and their associated\nattributes, facilitating effective alignment and providing interpretable\nsimilarity without the need for additional training. Extensive experiments\ndemonstrate that our method offers several advantages, including enhanced\ninterpretability, improved accuracy, and strong domain generalization. Codes\navailable at: https://github.com/shiming-chen/LaZSL.", "AI": {"tldr": "LaZSL is a locally-aligned vision-language model for interpretable zero-shot learning, using optimal transport to align visual regions with attributes, improving interpretability and accuracy.", "motivation": "Existing VLMs like CLIP lack interpretability in zero-shot learning due to global similarity computations. LaZSL aims to address this by aligning local visual features with discrete attributes.", "method": "LaZSL employs optimal transport for local visual-semantic alignment, enabling interaction between visual regions and attributes without additional training.", "result": "The method enhances interpretability, improves accuracy, and demonstrates strong domain generalization.", "conclusion": "LaZSL provides an effective and interpretable solution for zero-shot learning, bridging the gap between local visual features and attributes."}}
{"id": "2407.10490", "pdf": "https://arxiv.org/pdf/2407.10490", "abs": "https://arxiv.org/abs/2407.10490", "authors": ["Yi Ren", "Danica J. Sutherland"], "title": "Learning Dynamics of LLM Finetuning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Learning dynamics, which describes how the learning of specific training\nexamples influences the model's predictions on other examples, gives us a\npowerful tool for understanding the behavior of deep learning systems. We study\nthe learning dynamics of large language models during different types of\nfinetuning, by analyzing the step-wise decomposition of how influence\naccumulates among different potential responses. Our framework allows a uniform\ninterpretation of many interesting observations about the training of popular\nalgorithms for both instruction tuning and preference tuning. In particular, we\npropose a hypothetical explanation of why specific types of hallucination are\nstrengthened after finetuning, e.g., the model might use phrases or facts in\nthe response for question B to answer question A, or the model might keep\nrepeating similar simple phrases when generating responses. We also extend our\nframework and highlight a unique \"squeezing effect\" to explain a previously\nobserved phenomenon in off-policy direct preference optimization (DPO), where\nrunning DPO for too long makes even the desired outputs less likely. This\nframework also provides insights into where the benefits of on-policy DPO and\nother variants come from. The analysis not only provides a novel perspective of\nunderstanding LLM's finetuning but also inspires a simple, effective method to\nimprove alignment performance.", "AI": {"tldr": "The paper studies learning dynamics in large language models during finetuning, analyzing influence accumulation among responses to explain phenomena like hallucination and the 'squeezing effect' in DPO. It offers insights for improving alignment performance.", "motivation": "To understand how finetuning influences model predictions and behaviors, particularly in explaining hallucinations and DPO phenomena.", "method": "Analyzes step-wise decomposition of influence accumulation during finetuning for instruction and preference tuning.", "result": "Identifies mechanisms behind hallucinations and the 'squeezing effect' in DPO, providing insights for on-policy DPO benefits.", "conclusion": "The framework offers a novel perspective on LLM finetuning and inspires methods to enhance alignment performance."}}
{"id": "2311.07460", "pdf": "https://arxiv.org/pdf/2311.07460", "abs": "https://arxiv.org/abs/2311.07460", "authors": ["Xugui Zhou", "Maxfield Kouzel", "Chloe Smith", "Homa Alemzadeh"], "title": "KnowSafe: Combined Knowledge and Data Driven Hazard Mitigation in Artificial Pancreas Systems", "categories": ["cs.CR", "cs.AI", "cs.SY", "eess.SY"], "comment": "17 pages, 11 figures, 11 tables, to appear in the IEEE Transactions\n  on Dependable and Secure Computing (TDSC'25)", "summary": "Significant progress has been made in anomaly detection and run-time\nmonitoring to improve the safety and security of cyber-physical systems (CPS).\nHowever, less attention has been paid to hazard mitigation. This paper proposes\na combined knowledge and data driven approach, KnowSafe, for the design of\nsafety engines that can predict and mitigate safety hazards resulting from\nsafety-critical malicious attacks or accidental faults targeting a CPS\ncontroller. We integrate domain-specific knowledge of safety constraints and\ncontext-specific mitigation actions with machine learning (ML) techniques to\nestimate system trajectories in the far and near future, infer potential\nhazards, and generate optimal corrective actions to keep the system safe.\nExperimental evaluation on two realistic closed-loop testbeds for artificial\npancreas systems (APS) and a real-world clinical trial dataset for diabetes\ntreatment demonstrates that KnowSafe outperforms the state-of-the-art by\nachieving higher accuracy in predicting system state trajectories and potential\nhazards, a low false positive rate, and no false negatives. It also maintains\nthe safe operation of the simulated APS despite faults or attacks without\nintroducing any new hazards, with a hazard mitigation success rate of 92.8%,\nwhich is at least 76% higher than solely rule-based (50.9%) and data-driven\n(52.7%) methods.", "AI": {"tldr": "KnowSafe combines knowledge and data-driven methods for hazard mitigation in CPS, outperforming rule-based and data-driven approaches with a 92.8% success rate.", "motivation": "Addressing the gap in hazard mitigation for CPS safety, focusing on malicious attacks or accidental faults.", "method": "Integrates domain-specific safety constraints and ML to predict hazards and generate corrective actions.", "result": "Achieves higher accuracy, low false positives, no false negatives, and a 92.8% hazard mitigation success rate.", "conclusion": "KnowSafe effectively enhances CPS safety, outperforming existing methods."}}
{"id": "2506.24041", "pdf": "https://arxiv.org/pdf/2506.24041", "abs": "https://arxiv.org/abs/2506.24041", "authors": ["Alexis Melot", "Sean U. N. Wood", "Yannick Coffinier", "Pierre Yger", "Fabien Alibart"], "title": "Unsupervised Sparse Coding-based Spiking Neural Network for Real-time Spike Sorting", "categories": ["cs.NE", "cs.LG"], "comment": "Main article : 16 pages, 7 figures and 4 tables. Supplementary\n  Material starts at page 17 with 7 figures", "summary": "Spike sorting is a crucial step in decoding multichannel extracellular neural\nsignals, enabling the identification of individual neuronal activity. A key\nchallenge in brain-machine interfaces (BMIs) is achieving real-time, low-power\nspike sorting at the edge while keeping high neural decoding performance. This\nstudy introduces the Neuromorphic Sparse Sorter (NSS), a compact two-layer\nspiking neural network optimized for efficient spike sorting. NSS leverages the\nLocally Competitive Algorithm (LCA) for sparse coding to extract relevant\nfeatures from noisy events with reduced computational demands. NSS learns to\nsort detected spike waveforms in an online fashion and operates entirely\nunsupervised. To exploit multi-bit spike coding capabilities of neuromorphic\nplatforms like Intel's Loihi 2, a custom neuron model was implemented, enabling\nflexible power-performance trade-offs via adjustable spike bit-widths.\nEvaluations on simulated and real-world tetrode signals with biological drift\nshowed NSS outperformed established pipelines such as WaveClus3 and PCA+KMeans.\nWith 2-bit graded spikes, NSS on Loihi 2 outperformed NSS implemented with\nleaky integrate-and-fire neuron and achieved an F1-score of 77% (+10%\nimprovement) while consuming 8.6mW (+1.65mW) when tested on a drifting\nrecording, with a computational processing time of 0.25ms (+60 us) per\ninference.", "AI": {"tldr": "The paper introduces Neuromorphic Sparse Sorter (NSS), a two-layer spiking neural network for efficient, real-time spike sorting in brain-machine interfaces, outperforming existing methods with improved performance and power efficiency.", "motivation": "The challenge of achieving real-time, low-power spike sorting in brain-machine interfaces while maintaining high neural decoding performance drives the need for innovative solutions like NSS.", "method": "NSS uses the Locally Competitive Algorithm (LCA) for sparse coding and a custom neuron model for multi-bit spike coding, enabling unsupervised, online spike sorting on neuromorphic platforms like Intel's Loihi 2.", "result": "NSS achieved a 77% F1-score (+10% improvement) with 2-bit graded spikes on Loihi 2, consuming 8.6mW (+1.65mW) and processing time of 0.25ms (+60 us) per inference, outperforming WaveClus3 and PCA+KMeans.", "conclusion": "NSS demonstrates significant improvements in spike sorting efficiency and performance, making it a promising solution for real-time brain-machine interfaces."}}
{"id": "2506.23825", "pdf": "https://arxiv.org/pdf/2506.23825", "abs": "https://arxiv.org/abs/2506.23825", "authors": ["Haoji Zhang", "Yiqin Wang", "Yansong Tang", "Yong Liu", "Jiashi Feng", "Xiaojie Jin"], "title": "Flash-VStream: Efficient Real-Time Understanding for Long Video Streams", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "Benefiting from the advances in large language models and cross-modal\nalignment, existing multimodal large language models have achieved prominent\nperformance in image and short video understanding. However, the understanding\nof long videos is still challenging, as their long-context nature results in\nsignificant computational and memory overhead. Most existing work treats long\nvideos in the same way as short videos, which is inefficient for real-world\napplications and hard to generalize to even longer videos. To address these\nissues, we propose Flash-VStream, an efficient video language model capable of\nprocessing extremely long videos and responding to user queries in real time.\nParticularly, we design a Flash Memory module, containing a low-capacity\ncontext memory to aggregate long-context temporal information and model the\ndistribution of information density, and a high-capacity augmentation memory to\nretrieve detailed spatial information based on this distribution. Compared to\nexisting models, Flash-VStream achieves significant reductions in inference\nlatency. Extensive experiments on long video benchmarks and comprehensive video\nbenchmarks, i.e., EgoSchema, MLVU, LVBench, MVBench and Video-MME, demonstrate\nthe state-of-the-art performance and outstanding efficiency of our method. Code\nis available at https://github.com/IVGSZ/Flash-VStream.", "AI": {"tldr": "Flash-VStream is an efficient video language model for processing long videos, reducing latency with a novel memory module.", "motivation": "Existing models struggle with long videos due to computational overhead and inefficiency.", "method": "Uses a Flash Memory module with low-capacity context memory and high-capacity augmentation memory for efficient processing.", "result": "Achieves state-of-the-art performance on benchmarks like EgoSchema and MLVU, with reduced inference latency.", "conclusion": "Flash-VStream offers efficient, real-time processing of long videos, outperforming existing methods."}}
{"id": "2409.01754", "pdf": "https://arxiv.org/pdf/2409.01754", "abs": "https://arxiv.org/abs/2409.01754", "authors": ["Hiromu Yakura", "Ezequiel Lopez-Lopez", "Levin Brinkmann", "Ignacio Serna", "Prateek Gupta", "Ivan Soraperra", "Iyad Rahwan"], "title": "Empirical evidence of Large Language Model's influence on human spoken communication", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "From the invention of writing and the printing press, to television and\nsocial media, human history is punctuated by major innovations in communication\ntechnology, which fundamentally altered how ideas spread and reshaped our\nculture. Recent chatbots powered by generative artificial intelligence\nconstitute a novel medium that encodes cultural patterns in their neural\nrepresentations and disseminates them in conversations with hundreds of\nmillions of people. Understanding whether these patterns transmit into human\nlanguage, and ultimately shape human culture, is a fundamental question. While\nfully quantifying the causal impact of a chatbot like ChatGPT on human culture\nis very challenging, lexicographic shift in human spoken communication may\noffer an early indicator of such broad phenomenon. Here, we apply econometric\ncausal inference techniques to 740,249 hours of human discourse from 360,445\nYouTube academic talks and 771,591 conversational podcast episodes across\nmultiple disciplines. We detect a measurable and abrupt increase in the use of\nwords preferentially generated by ChatGPT, such as delve, comprehend, boast,\nswift, and meticulous, after its release. These findings suggest a scenario\nwhere machines, originally trained on human data and subsequently exhibiting\ntheir own cultural traits, can, in turn, measurably reshape human culture. This\nmarks the beginning of a closed cultural feedback loop in which cultural traits\ncirculate bidirectionally between humans and machines. Our results motivate\nfurther research into the evolution of human-machine culture, and raise\nconcerns over the erosion of linguistic and cultural diversity, and the risks\nof scalable manipulation.", "AI": {"tldr": "The paper explores how AI chatbots like ChatGPT influence human language and culture, detecting a measurable shift in word usage post-ChatGPT release.", "motivation": "To understand if AI chatbots, trained on human data, can reshape human culture by transmitting their linguistic patterns.", "method": "Applied econometric causal inference to analyze 740,249 hours of human discourse from YouTube academic talks and podcasts.", "result": "Found an abrupt increase in ChatGPT-preferred words (e.g., delve, comprehend) after its release, indicating cultural influence.", "conclusion": "AI chatbots create a bidirectional cultural feedback loop, raising concerns about linguistic diversity and manipulation risks."}}
{"id": "2312.02312", "pdf": "https://arxiv.org/pdf/2312.02312", "abs": "https://arxiv.org/abs/2312.02312", "authors": ["Lukas Sch\u00e4fer", "Logan Jones", "Anssi Kanervisto", "Yuhan Cao", "Tabish Rashid", "Raluca Georgescu", "Dave Bignell", "Siddhartha Sen", "Andrea Trevi\u00f1o Gavito", "Sam Devlin"], "title": "Visual Encoders for Data-Efficient Imitation Learning in Modern Video Games", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Camera-ready paper presented at the Adaptive and Learning Agents\n  Workshop at the AAMAS 2025 conference", "summary": "Video games have served as useful benchmarks for the decision-making\ncommunity, but going beyond Atari games towards modern games has been\nprohibitively expensive for the vast majority of the research community. Prior\nwork in modern video games typically relied on game-specific integration to\nobtain game features and enable online training, or on existing large datasets.\nAn alternative approach is to train agents using imitation learning to play\nvideo games purely from images. However, this setting poses a fundamental\nquestion: which visual encoders obtain representations that retain information\ncritical for decision making? To answer this question, we conduct a systematic\nstudy of imitation learning with publicly available pre-trained visual encoders\ncompared to the typical task-specific end-to-end training approach in\nMinecraft, Counter-Strike: Global Offensive, and Minecraft Dungeons. Our\nresults show that end-to-end training can be effective with comparably\nlow-resolution images and only minutes of demonstrations, but significant\nimprovements can be gained by utilising pre-trained encoders such as DINOv2\ndepending on the game. In addition to enabling effective decision making, we\nshow that pre-trained encoders can make decision-making research in video games\nmore accessible by significantly reducing the cost of training.", "AI": {"tldr": "The paper evaluates pre-trained visual encoders for imitation learning in video games, showing they can reduce training costs and improve performance compared to end-to-end training.", "motivation": "Modern video games are expensive to research, and prior methods rely on game-specific integration or large datasets. The study explores whether pre-trained visual encoders can retain critical decision-making information.", "method": "A systematic study of imitation learning using pre-trained visual encoders (e.g., DINOv2) versus end-to-end training in games like Minecraft and Counter-Strike.", "result": "End-to-end training works with low-resolution images and minimal demonstrations, but pre-trained encoders like DINOv2 offer significant improvements and cost reductions.", "conclusion": "Pre-trained encoders enhance decision-making research accessibility and effectiveness in video games."}}
{"id": "2506.24045", "pdf": "https://arxiv.org/pdf/2506.24045", "abs": "https://arxiv.org/abs/2506.24045", "authors": ["Xinming Wei", "Jiahao Zhang", "Haoran Li", "Jiayu Chen", "Rui Qu", "Maoliang Li", "Xiang Chen", "Guojie Luo"], "title": "Agent.xpu: Efficient Scheduling of Agentic LLM Workloads on Heterogeneous SoC", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "The proliferation of agentic Large Language Models (LLMs) on personal devices\nintroduces a new class of workloads characterized by a dichotomy of objectives.\nReactive tasks, initiated by users, demand immediate, low-latency responses,\nwhile proactive tasks operate invisibly and prioritize throughput. Existing\non-device LLM engines, designed for isolated inferences, fail to efficiently\nmanage these concurrent and conflicting requests on consumer-grade\nheterogeneous SoCs with CPU, integrated GPU, and NPU. This paper introduces\nAgent.xpu, an efficient serving system for agentic LLM workloads on\nmemory-unified heterogeneous SoCs. With dedicated offline profiling, Agent.xpu\nfirst constructs a heterogeneous execution graph, which fuses and chunks model\nkernels for affinity-guided, elastic accelerator mapping with predictive kernel\nannotation. At runtime, its online scheduler enables fine-grained, kernel-level\npreemption to guarantee the responsiveness of reactive tasks. To maximize SoC\nutilization, it adopts slack-aware kernel backfill to opportunistically append\nproactive tasks, and mitigates NPU-iGPU contention via bandwidth-aware\ndispatch. Evaluation on an Intel Core Ultra SoC shows that Agent.xpu achieves\n4.6$\\times$ lower latency for reactive tasks and sustains\n1.6$\\times$-6.8$\\times$ higher throughput for proactive tasks compared to\nstate-of-the-art inference engines.", "AI": {"tldr": "Agent.xpu is a system for efficiently managing agentic LLM workloads on heterogeneous SoCs, balancing low-latency reactive tasks and high-throughput proactive tasks.", "motivation": "Existing on-device LLM engines fail to handle concurrent reactive and proactive tasks efficiently on heterogeneous SoCs.", "method": "Agent.xpu uses offline profiling to create a heterogeneous execution graph, enabling affinity-guided kernel mapping and runtime preemption for reactive tasks, plus slack-aware backfill for proactive tasks.", "result": "Agent.xpu reduces reactive task latency by 4.6\u00d7 and increases proactive task throughput by 1.6\u00d7-6.8\u00d7 compared to state-of-the-art engines.", "conclusion": "Agent.xpu effectively addresses the challenges of serving agentic LLM workloads on heterogeneous SoCs."}}
{"id": "2506.23827", "pdf": "https://arxiv.org/pdf/2506.23827", "abs": "https://arxiv.org/abs/2506.23827", "authors": ["Mingcheng Qu", "Yuncong Wu", "Donglin Di", "Yue Gao", "Tonghua Su", "Yang Song", "Lei Fan"], "title": "Spatially Gene Expression Prediction using Dual-Scale Contrastive Learning", "categories": ["cs.CV"], "comment": "Our paper has been accepted by MICCAI 2025", "summary": "Spatial transcriptomics (ST) provides crucial insights into tissue\nmicro-environments, but is limited to its high cost and complexity. As an\nalternative, predicting gene expression from pathology whole slide images (WSI)\nis gaining increasing attention. However, existing methods typically rely on\nsingle patches or a single pathology modality, neglecting the complex spatial\nand molecular interactions between target and neighboring information (e.g.,\ngene co-expression). This leads to a failure in establishing connections among\nadjacent regions and capturing intricate cross-modal relationships. To address\nthese issues, we propose NH2ST, a framework that integrates spatial context and\nboth pathology and gene modalities for gene expression prediction. Our model\ncomprises a query branch and a neighbor branch to process paired target patch\nand gene data and their neighboring regions, where cross-attention and\ncontrastive learning are employed to capture intrinsic associations and ensure\nalignments between pathology and gene expression. Extensive experiments on six\ndatasets demonstrate that our model consistently outperforms existing methods,\nachieving over 20% in PCC metrics. Codes are available at\nhttps://github.com/MCPathology/NH2ST", "AI": {"tldr": "NH2ST is a framework for predicting gene expression from pathology images by integrating spatial context and multi-modal data, outperforming existing methods by over 20% in PCC metrics.", "motivation": "Existing methods for predicting gene expression from pathology images often ignore spatial and molecular interactions, leading to poor performance. NH2ST addresses this gap by incorporating neighboring information and cross-modal relationships.", "method": "NH2ST uses a query branch and a neighbor branch to process target patches and their neighboring regions, employing cross-attention and contrastive learning to align pathology and gene expression data.", "result": "The model outperforms existing methods, achieving over 20% improvement in PCC metrics across six datasets.", "conclusion": "NH2ST effectively captures spatial and cross-modal relationships, offering a robust solution for gene expression prediction from pathology images."}}
{"id": "2410.09432", "pdf": "https://arxiv.org/pdf/2410.09432", "abs": "https://arxiv.org/abs/2410.09432", "authors": ["Raghav Singhal", "Kaustubh Ponkshe", "Praneeth Vepakomma"], "title": "FedEx-LoRA: Exact Aggregation for Federated and Efficient Fine-Tuning of Foundation Models", "categories": ["cs.DC", "cs.CL", "cs.CV"], "comment": "ACL 2025 - Oral. Raghav Singhal and Kaustubh Ponkshe contributed\n  equally to this work", "summary": "Low-Rank Adaptation (LoRA) is a popular technique for efficient fine-tuning\nof foundation models. However, applying LoRA in federated learning\nenvironments, where data is distributed across multiple clients, presents\nunique challenges. Existing methods rely on traditional federated averaging of\nLoRA adapters, resulting in inexact updates. To address this, we propose\nFederated Exact LoRA, or FedEx-LoRA, which adds a residual error term to the\npretrained frozen weight matrix. Our approach achieves exact updates with\nminimal computational and communication overhead, preserving LoRA's efficiency.\nWe evaluate the method on various models across arithmetic reasoning,\ncommonsense reasoning, natural language understanding and natural language\ngeneration tasks, showing consistent performance gains over state-of-the-art\nmethods across multiple settings. Through extensive analysis, we quantify that\nthe deviations in updates from the ideal solution are significant, highlighting\nthe need for exact aggregation. Our method's simplicity, efficiency, and broad\napplicability position it as a promising solution for accurate and effective\nfederated fine-tuning of foundation models. Our code is publicly available at\nhttps://github.com/RaghavSinghal10/fedex-lora.", "AI": {"tldr": "FedEx-LoRA introduces exact updates for LoRA in federated learning by adding a residual error term, outperforming existing methods with minimal overhead.", "motivation": "Traditional federated averaging of LoRA adapters leads to inexact updates, necessitating a more accurate solution.", "method": "FedEx-LoRA adds a residual error term to the pretrained frozen weight matrix for exact updates.", "result": "The method shows consistent performance gains across various tasks and models.", "conclusion": "FedEx-LoRA is a simple, efficient, and broadly applicable solution for federated fine-tuning of foundation models."}}
{"id": "2402.01782", "pdf": "https://arxiv.org/pdf/2402.01782", "abs": "https://arxiv.org/abs/2402.01782", "authors": ["Jiaqi Lin", "Sen Lu", "Malyaban Bal", "Abhronil Sengupta"], "title": "Benchmarking Spiking Neural Network Learning Methods with Varying Locality", "categories": ["cs.NE", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Spiking Neural Networks (SNNs), providing more realistic neuronal dynamics,\nhave been shown to achieve performance comparable to Artificial Neural Networks\n(ANNs) in several machine learning tasks. Information is processed as spikes\nwithin SNNs in an event-based mechanism that significantly reduces energy\nconsumption. However, training SNNs is challenging due to the\nnon-differentiable nature of the spiking mechanism. Traditional approaches,\nsuch as Backpropagation Through Time (BPTT), have shown effectiveness but come\nwith additional computational and memory costs and are biologically\nimplausible. In contrast, recent works propose alternative learning methods\nwith varying degrees of locality, demonstrating success in classification\ntasks. In this work, we show that these methods share similarities during the\ntraining process, while they present a trade-off between biological\nplausibility and performance. Further, given the implicitly recurrent nature of\nSNNs, this research investigates the influence of the addition of explicit\nrecurrence to SNNs. We experimentally prove that the addition of explicit\nrecurrent weights enhances the robustness of SNNs. We also investigate the\nperformance of local learning methods under gradient and non-gradient-based\nadversarial attacks.", "AI": {"tldr": "SNNs offer energy-efficient, event-based processing but face training challenges due to non-differentiability. Recent local learning methods balance biological plausibility and performance, and explicit recurrence improves robustness.", "motivation": "To address SNN training challenges and explore the trade-off between biological plausibility and performance, while enhancing robustness with explicit recurrence.", "method": "Compare local learning methods, add explicit recurrent weights to SNNs, and test performance under adversarial attacks.", "result": "Explicit recurrence boosts SNN robustness, and local learning methods show varying effectiveness under adversarial attacks.", "conclusion": "Explicit recurrence and local learning methods improve SNN robustness and performance, offering insights for biologically plausible training."}}
{"id": "2506.24048", "pdf": "https://arxiv.org/pdf/2506.24048", "abs": "https://arxiv.org/abs/2506.24048", "authors": ["Tim Roith", "Leon Bungert", "Philipp Wacker"], "title": "Consensus-based optimization for closed-box adversarial attacks and a connection to evolution strategies", "categories": ["math.OC", "cs.LG", "65K10, 68Q32, 65K15, 90C26"], "comment": null, "summary": "Consensus-based optimization (CBO) has established itself as an efficient\ngradient-free optimization scheme, with attractive mathematical properties,\nsuch as mean-field convergence results for non-convex loss functions. In this\nwork, we study CBO in the context of closed-box adversarial attacks, which are\nimperceptible input perturbations that aim to fool a classifier, without\naccessing its gradient. Our contribution is to establish a connection between\nthe so-called consensus hopping as introduced by Riedl et al. and natural\nevolution strategies (NES) commonly applied in the context of adversarial\nattacks and to rigorously relate both methods to gradient-based optimization\nschemes. Beyond that, we provide a comprehensive experimental study that shows\nthat despite the conceptual similarities, CBO can outperform NES and other\nevolutionary strategies in certain scenarios.", "AI": {"tldr": "CBO is linked to consensus hopping and NES, showing it can outperform NES in some adversarial attack scenarios.", "motivation": "To explore CBO's effectiveness in closed-box adversarial attacks without gradient access.", "method": "Connects consensus hopping (CBO) with NES and relates both to gradient-based optimization.", "result": "CBO outperforms NES and other evolutionary strategies in certain cases.", "conclusion": "CBO is a viable alternative for gradient-free adversarial attacks, with theoretical and practical advantages."}}
{"id": "2506.23832", "pdf": "https://arxiv.org/pdf/2506.23832", "abs": "https://arxiv.org/abs/2506.23832", "authors": ["Ronit D. Gross", "Tal Halevi", "Ella Koresh", "Yarden Tzach", "Ido Kanter"], "title": "Low-latency vision transformers via large-scale multi-head attention", "categories": ["cs.CV"], "comment": "23 pages, 4 figures, 7 tables", "summary": "The emergence of spontaneous symmetry breaking among a few heads of\nmulti-head attention (MHA) across transformer blocks in classification tasks\nwas recently demonstrated through the quantification of single-nodal\nperformance (SNP). This finding indicates that each head focuses its attention\non a subset of labels through cooperation among its SNPs. This underlying\nlearning mechanism is generalized to large-scale MHA (LS-MHA) using a single\nmatrix value representing single-head performance (SHP), analogous to\nsingle-filter performance in convolutional neural networks (CNNs). The results\nindicate that each SHP matrix comprises multiple unit clusters such that each\nlabel being explicitly recognized by a few heads with negligible noise. This\nleads to an increased signal-to-noise ratio (SNR) along the transformer blocks,\nthereby improving classification accuracy. These features give rise to several\ndistinct vision transformer (ViT) architectures that achieve the same accuracy\nbut differ in their LS-MHA structures. As a result, their soft committee yields\nsuperior accuracy, an outcome not typically observed in CNNs which rely on\nhundreds of filters. In addition, a significant reduction in latency is\nachieved without affecting the accuracy by replacing the initial transformer\nblocks with convolutional layers. This substitution accelerates early-stage\nlearning, which is then improved by subsequent transformer layers. The\nextension of this learning mechanism to natural language processing tasks,\nbased on quantitative differences between CNNs and ViT architectures, has the\npotential to yield new insights in deep learning. The findings are demonstrated\nusing compact convolutional transformer architectures trained on the CIFAR-100\ndataset.", "AI": {"tldr": "The paper explores spontaneous symmetry breaking in multi-head attention (MHA) in transformers, generalizing it to large-scale MHA (LS-MHA) for improved classification accuracy and reduced latency.", "motivation": "To understand and leverage the learning mechanism of MHA in transformers, particularly how heads focus on subsets of labels, and to improve classification tasks by enhancing signal-to-noise ratio (SNR).", "method": "Quantifies single-nodal performance (SNP) and single-head performance (SHP) to analyze MHA behavior, proposes LS-MHA, and substitutes initial transformer blocks with convolutional layers for efficiency.", "result": "Improved classification accuracy due to higher SNR, distinct ViT architectures with similar accuracy but different LS-MHA structures, and reduced latency without accuracy loss.", "conclusion": "The findings suggest potential extensions to NLP tasks and highlight the advantages of combining convolutional layers with transformers for efficient learning."}}
{"id": "2410.21896", "pdf": "https://arxiv.org/pdf/2410.21896", "abs": "https://arxiv.org/abs/2410.21896", "authors": ["Kaustubh Kislay", "Shlok Singh", "Soham Joshi", "Rohan Dutta", "Jay Shim", "George Flint", "Kevin Zhu"], "title": "Evaluating K-Fold Cross Validation for Transformer Based Symbolic Regression Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Symbolic Regression remains an NP-Hard problem, with extensive research\nfocusing on AI models for this task. Transformer models have shown promise in\nSymbolic Regression, but performance suffers with smaller datasets. We propose\napplying k-fold cross-validation to a transformer-based symbolic regression\nmodel trained on a significantly reduced dataset (15,000 data points, down from\n500,000). This technique partitions the training data into multiple subsets\n(folds), iteratively training on some while validating on others. Our aim is to\nprovide an estimate of model generalization and mitigate overfitting issues\nassociated with smaller datasets. Results show that this process improves the\nmodel's output consistency and generalization by a relative improvement in\nvalidation loss of 53.31%. Potentially enabling more efficient and accessible\nsymbolic regression in resource-constrained environments.", "AI": {"tldr": "Proposes k-fold cross-validation for transformer-based symbolic regression on smaller datasets, improving generalization by 53.31%.", "motivation": "Address performance issues of transformer models in symbolic regression with smaller datasets.", "method": "Apply k-fold cross-validation to a transformer model trained on a reduced dataset (15,000 points).", "result": "53.31% relative improvement in validation loss, enhancing output consistency and generalization.", "conclusion": "Enables more efficient symbolic regression in resource-constrained settings."}}
{"id": "2402.12993", "pdf": "https://arxiv.org/pdf/2402.12993", "abs": "https://arxiv.org/abs/2402.12993", "authors": ["Kexin Chen", "Yuyang Du", "Junyou Li", "Hanqun Cao", "Menghao Guo", "Xilin Dang", "Lanqing Li", "Jiezhong Qiu", "Pheng Ann Heng", "Guangyong Chen"], "title": "ChemMiner: A Large Language Model Agent System for Chemical Literature Data Mining", "categories": ["cs.IR", "cs.AI", "cs.LG", "q-bio.QM"], "comment": null, "summary": "The development of AI-assisted chemical synthesis tools requires\ncomprehensive datasets covering diverse reaction types, yet current\nhigh-throughput experimental (HTE) approaches are expensive and limited in\nscope. Chemical literature represents a vast, underexplored data source\ncontaining thousands of reactions published annually. However, extracting\nreaction information from literature faces significant challenges including\nvaried writing styles, complex coreference relationships, and multimodal\ninformation presentation. This paper proposes ChemMiner, a novel end-to-end\nframework leveraging multiple agents powered by large language models (LLMs) to\nextract high-fidelity chemical data from literature. ChemMiner incorporates\nthree specialized agents: a text analysis agent for coreference mapping, a\nmultimodal agent for non-textual information extraction, and a synthesis\nanalysis agent for data generation. Furthermore, we developed a comprehensive\nbenchmark with expert-annotated chemical literature to evaluate both extraction\nefficiency and precision. Experimental results demonstrate reaction\nidentification rates comparable to human chemists while significantly reducing\nprocessing time, with high accuracy, recall, and F1 scores. Our open-sourced\nbenchmark facilitates future research in chemical literature data mining.", "AI": {"tldr": "ChemMiner is an AI framework using LLM-powered agents to extract chemical reaction data from literature, achieving human-level accuracy with improved speed.", "motivation": "Current HTE methods for chemical synthesis data are costly and limited; literature offers vast but challenging untapped data.", "method": "ChemMiner employs three agents (text analysis, multimodal, synthesis analysis) to process literature, supported by a benchmark for evaluation.", "result": "ChemMiner matches human chemists in reaction identification with high accuracy, recall, and F1 scores, while being faster.", "conclusion": "ChemMiner effectively mines chemical literature, and its open-sourced benchmark aids future research in the field."}}
{"id": "1112.1768", "pdf": "https://arxiv.org/pdf/1112.1768", "abs": "https://arxiv.org/abs/1112.1768", "authors": ["Keqin Liu", "Tianshuo Zheng", "Zhi-Hua Zhou"], "title": "Extended UCB Policies for Frequentist Multi-armed Bandit Problems", "categories": ["cs.LG", "math.PR", "math.ST", "stat.TH"], "comment": "25 pages, 3 figures", "summary": "The multi-armed bandit (MAB) problem is a widely studied model in the field\nof operations research for sequential decision making and reinforcement\nlearning. This paper mainly considers the classical MAB model with the\nheavy-tailed reward distributions. We introduce the extended robust UCB policy,\nwhich is an extension of the pioneering UCB policies proposed by Bubeck et al.\n[5] and Lattimore [22]. The previous UCB policies require some strict\nconditions on the reward distributions, which can be hard to guarantee in\npractical scenarios. Our extended robust UCB generalizes Lattimore's seminary\nwork (for moments of orders $p=4$ and $q=2$) to arbitrarily chosen $p>q>1$ as\nlong as the two moments have a known controlled relationship, while still\nachieving the optimal regret growth order $O(log T)$, thus providing a\nbroadened application area of the UCB policies for the heavy-tailed reward\ndistributions. Furthermore, we achieve a near-optimal regret order without any\nknowledge of the reward distributions as long as their $p$-th moments exist for\nsome $p>1$.", "AI": {"tldr": "The paper extends the robust UCB policy for heavy-tailed reward distributions in multi-armed bandit problems, achieving optimal regret growth without strict distributional assumptions.", "motivation": "Existing UCB policies require strict conditions on reward distributions, limiting practical applicability. This work aims to relax these constraints for broader use.", "method": "Introduces an extended robust UCB policy, generalizing prior work to arbitrary moment conditions (p>q>1) while maintaining optimal regret growth.", "result": "Achieves near-optimal regret order O(log T) without requiring full knowledge of reward distributions, only existence of p-th moments (p>1).", "conclusion": "The extended robust UCB policy broadens applicability of UCB policies for heavy-tailed rewards, offering theoretical guarantees under relaxed assumptions."}}
{"id": "2506.23833", "pdf": "https://arxiv.org/pdf/2506.23833", "abs": "https://arxiv.org/abs/2506.23833", "authors": ["Oscar Ovanger", "Ragnar Hauge", "Jacob Skauvold", "Michael J. Pyrcz", "Jo Eidsvik"], "title": "PointSSIM: A novel low dimensional resolution invariant image-to-image comparison metric", "categories": ["cs.CV"], "comment": "13 pages, 20 figures", "summary": "This paper presents PointSSIM, a novel low-dimensional image-to-image\ncomparison metric that is resolution invariant. Drawing inspiration from the\nstructural similarity index measure and mathematical morphology, PointSSIM\nenables robust comparison across binary images of varying resolutions by\ntransforming them into marked point pattern representations. The key features\nof the image, referred to as anchor points, are extracted from binary images by\nidentifying locally adaptive maxima from the minimal distance transform. Image\ncomparisons are then performed using a summary vector, capturing intensity,\nconnectivity, complexity, and structural attributes. Results show that this\napproach provides an efficient and reliable method for image comparison,\nparticularly suited to applications requiring structural analysis across\ndifferent resolutions.", "AI": {"tldr": "PointSSIM is a resolution-invariant metric for comparing binary images by transforming them into marked point patterns and using summary vectors for robust analysis.", "motivation": "To address the challenge of comparing binary images of varying resolutions while maintaining structural integrity.", "method": "Transforms binary images into marked point patterns, extracts anchor points via locally adaptive maxima, and compares using summary vectors capturing intensity, connectivity, complexity, and structure.", "result": "Efficient and reliable image comparison, especially for structural analysis across resolutions.", "conclusion": "PointSSIM is a promising tool for applications needing resolution-invariant structural image comparison."}}
{"id": "2411.02335", "pdf": "https://arxiv.org/pdf/2411.02335", "abs": "https://arxiv.org/abs/2411.02335", "authors": ["Yuqi Luo", "Chenyang Song", "Xu Han", "Yingfa Chen", "Chaojun Xiao", "Xiaojun Meng", "Liqun Deng", "Jiansheng Wei", "Zhiyuan Liu", "Maosong Sun"], "title": "Sparsing Law: Towards Large Language Models with Greater Activation Sparsity", "categories": ["cs.LG", "cs.CL", "stat.ML", "I.2.7"], "comment": "23 pages, 13 figures, 6 tables", "summary": "Activation sparsity denotes the existence of substantial weakly-contributed\nelements within activation outputs that can be eliminated, benefiting many\nimportant applications concerned with large language models (LLMs). Although\npromoting greater activation sparsity within LLMs deserves deep studies,\nexisting works lack comprehensive and quantitative research on the correlation\nbetween activation sparsity and potentially influential factors. In this paper,\nwe present a comprehensive study on the quantitative scaling properties and\ninfluential factors of the activation sparsity within decoder-only\nTransformer-based LLMs. Specifically, we propose PPL-$p\\%$ sparsity, a precise\nand performance-aware activation sparsity metric that is applicable to any\nactivation function. Through extensive experiments, we find several important\nphenomena. Firstly, different activation functions exhibit comparable\nperformance but opposite training-time sparsity trends. The activation ratio\n(i.e., $1-\\mathrm{sparsity\\ ratio}$) evolves as a convergent increasing\npower-law and decreasing logspace power-law with the amount of training data\nfor SiLU-activated and ReLU-activated LLMs, respectively. These demonstrate\nthat ReLU is more efficient as the activation function than SiLU and can\nleverage more training data to improve activation sparsity. Secondly, the\nactivation ratio linearly increases with the width-depth ratio below a certain\nbottleneck point, indicating the potential advantage of a deeper architecture\nat a fixed parameter scale. Finally, at similar width-depth ratios, we\nsurprisingly find that the limit value of activation sparsity varies weakly\nwith the parameter scale, i.e., the activation patterns within LLMs are\ninsensitive to the parameter scale. These empirical laws towards LLMs with\ngreater activation sparsity have important implications for making LLMs more\nefficient and interpretable.", "AI": {"tldr": "The paper studies activation sparsity in LLMs, proposing a new metric (PPL-$p\\%$ sparsity) and identifying key trends related to activation functions, training data, and model architecture.", "motivation": "To understand and quantify the factors influencing activation sparsity in LLMs, as existing research lacks comprehensive analysis.", "method": "Proposes PPL-$p\\%$ sparsity metric and conducts extensive experiments on decoder-only Transformer-based LLMs, analyzing activation functions, training data, and model dimensions.", "result": "Key findings include ReLU's efficiency over SiLU, the impact of width-depth ratio on activation sparsity, and the weak sensitivity of activation patterns to parameter scale.", "conclusion": "The study provides empirical insights for designing more efficient and interpretable LLMs by leveraging activation sparsity."}}
{"id": "2403.17329", "pdf": "https://arxiv.org/pdf/2403.17329", "abs": "https://arxiv.org/abs/2403.17329", "authors": ["Junhoo Lee", "Hyunho Lee", "Kyomin Hwang", "Nojun Kwak"], "title": "Deep Support Vectors", "categories": ["cs.LG", "cs.AI"], "comment": "Neurips 2024", "summary": "Deep learning has achieved tremendous success. However, unlike SVMs, which\nprovide direct decision criteria and can be trained with a small dataset, it\nstill has significant weaknesses due to its requirement for massive datasets\nduring training and the black-box characteristics on decision criteria. This\npaper addresses these issues by identifying support vectors in deep learning\nmodels. To this end, we propose the DeepKKT condition, an adaptation of the\ntraditional Karush-Kuhn-Tucker (KKT) condition for deep learning models, and\nconfirm that generated Deep Support Vectors (DSVs) using this condition exhibit\nproperties similar to traditional support vectors. This allows us to apply our\nmethod to few-shot dataset distillation problems and alleviate the black-box\ncharacteristics of deep learning models. Additionally, we demonstrate that the\nDeepKKT condition can transform conventional classification models into\ngenerative models with high fidelity, particularly as latent generative models\nusing class labels as latent variables. We validate the effectiveness of DSVs\nusing common datasets (ImageNet, CIFAR10 and CIFAR100) on the general\narchitectures (ResNet and ConvNet), proving their practical applicability.", "AI": {"tldr": "The paper introduces DeepKKT, adapting KKT conditions to identify support vectors in deep learning, enabling few-shot learning and reducing black-box issues. It also shows generative model applications.", "motivation": "Address deep learning's need for large datasets and lack of interpretability by identifying support vectors, akin to SVMs.", "method": "Propose DeepKKT condition to identify Deep Support Vectors (DSVs), validating their properties and applications in few-shot learning and generative modeling.", "result": "DSVs exhibit SVM-like properties, work well in few-shot learning, and enable high-fidelity generative models. Validated on ImageNet, CIFAR10, and CIFAR100.", "conclusion": "DeepKKT effectively bridges gaps in deep learning by providing interpretability and efficiency, with practical applications in few-shot and generative tasks."}}
{"id": "2201.03169", "pdf": "https://arxiv.org/pdf/2201.03169", "abs": "https://arxiv.org/abs/2201.03169", "authors": ["Lingzhi Gao", "Zhenyuan Zhang", "Chao Wu"], "title": "FedDTG:Federated Data-Free Knowledge Distillation via Three-Player Generative Adversarial Networks", "categories": ["cs.LG"], "comment": null, "summary": "While existing federated learning approaches primarily focus on aggregating\nlocal models to construct a global model, in realistic settings, some clients\nmay be reluctant to share their private models due to the inclusion of\nprivacy-sensitive information. Knowledge distillation, which can extract model\nknowledge without accessing model parameters, is well-suited for this federated\nscenario. However, most distillation methods in federated learning (federated\ndistillation) require a proxy dataset, which is difficult to obtain in the real\nworld. Therefore, in this paper, we introduce a distributed three-player\nGenerative Adversarial Network (GAN) to implement data-free mutual distillation\nand propose an effective method called FedDTG. We confirmed that the fake\nsamples generated by GAN can make federated distillation more efficient and\nrobust. Additionally, the distillation process between clients can deliver good\nindividual client performance while simultaneously acquiring global knowledge\nand protecting data privacy. Our extensive experiments on benchmark vision\ndatasets demonstrate that our method outperforms other federated distillation\nalgorithms in terms of generalization.", "AI": {"tldr": "FedDTG introduces a GAN-based method for data-free federated distillation, improving efficiency and privacy without needing a proxy dataset.", "motivation": "Existing federated learning methods require sharing private models or proxy datasets, which are impractical or privacy-invasive.", "method": "Uses a distributed three-player GAN for data-free mutual distillation, enabling efficient and robust federated learning.", "result": "Outperforms other federated distillation algorithms in generalization on benchmark datasets.", "conclusion": "FedDTG effectively balances individual client performance, global knowledge acquisition, and data privacy."}}
{"id": "2506.23835", "pdf": "https://arxiv.org/pdf/2506.23835", "abs": "https://arxiv.org/abs/2506.23835", "authors": ["Ziwei Chen", "Ziling Liu", "Zitong Huang", "Mingqi Gao", "Feng Zheng"], "title": "Refine Any Object in Any Scene", "categories": ["cs.CV"], "comment": "9 pages with 6 figures", "summary": "Viewpoint missing of objects is common in scene reconstruction, as camera\npaths typically prioritize capturing the overall scene structure rather than\nindividual objects. This makes it highly challenging to achieve high-fidelity\nobject-level modeling while maintaining accurate scene-level representation.\nAddressing this issue is critical for advancing downstream tasks requiring\ndetailed object understanding and appearance modeling. In this paper, we\nintroduce Refine Any object In any ScenE (RAISE), a novel 3D enhancement\nframework that leverages 3D generative priors to recover fine-grained object\ngeometry and appearance under missing views. Starting from substituting\ndegraded objects with proxies, via a 3D generative model with strong 3D\nunderstanding, RAISE progressively refines geometry and texture by aligning\neach proxy to its degraded counterpart in 7-DOF pose, followed by correcting\nspatial and appearance inconsistencies via registration-constrained\nenhancement. This two-stage refinement ensures the high-fidelity geometry and\nappearance of the original object in unseen views while maintaining consistency\nin spatial positioning, observed geometry, and appearance. Extensive\nexperiments on challenging benchmarks show that RAISE significantly outperforms\nstate-of-the-art methods in both novel view synthesis and geometry completion\ntasks. RAISE is made publicly available at https://github.com/PolySummit/RAISE.", "AI": {"tldr": "RAISE introduces a 3D enhancement framework to recover object geometry and appearance in scenes with missing views, outperforming state-of-the-art methods.", "motivation": "Addressing the challenge of high-fidelity object-level modeling in scenes with missing views, critical for detailed object understanding.", "method": "A two-stage refinement: substituting degraded objects with proxies via a 3D generative model, then refining geometry and texture by aligning proxies and correcting inconsistencies.", "result": "RAISE significantly outperforms state-of-the-art methods in novel view synthesis and geometry completion tasks.", "conclusion": "RAISE effectively enhances object geometry and appearance in scenes with missing views, advancing detailed object modeling."}}
{"id": "2411.18797", "pdf": "https://arxiv.org/pdf/2411.18797", "abs": "https://arxiv.org/abs/2411.18797", "authors": ["Haomin Zhuang", "Yihua Zhang", "Kehan Guo", "Jinghan Jia", "Gaowen Liu", "Sijia Liu", "Xiangliang Zhang"], "title": "SEUF: Is Unlearning One Expert Enough for Mixture-of-Experts LLMs?", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted to ACL'25", "summary": "Recent advancements in LLMs unlearning have shown remarkable success in\nremoving unwanted data-model influences while preserving the model's utility\nfor legitimate knowledge. Despite these strides, sparse Mixture-of-Experts\n(MoE) LLMs--a key subset of the LLM family--have remained unexplored in the\ncontext of unlearning. As MoE LLMs are celebrated for their exceptional\nperformance, we ask:How can unlearning be performed effectively and efficiently\non MoE LLMs? Our pilot study shows that the dynamic routing nature of MoE LLMs\nintroduces unique challenges, leading to excessive forgetting, uncontrolled\nknowledge erasure and substantial utility drops when existing unlearning\nmethods are applied. To address this, we propose a novel Selected-Expert\nUnlearning Framework (SEUF). Through expert attribution, unlearning is\nconcentrated on the most actively engaged experts for the specified knowledge.\nConcurrently, an anchor loss is applied to the router to stabilize the active\nstate of this targeted expert, ensuring focused and controlled unlearning. SEUF\nis compatible with various standard unlearning algorithms. Extensive\nexperiments demonstrate that SEUF enhances both forget quality up to 5% and\nmodel utility by 35% on MoE LLMs across various benchmarks and LLM\narchitectures (compared to standard unlearning algorithms), while only\nunlearning 0.06% of the model parameters.", "AI": {"tldr": "A novel Selected-Expert Unlearning Framework (SEUF) is proposed to address unlearning challenges in sparse Mixture-of-Experts (MoE) LLMs, improving forget quality and model utility.", "motivation": "MoE LLMs lack effective unlearning methods, leading to excessive forgetting and utility drops when existing techniques are applied.", "method": "SEUF uses expert attribution to focus unlearning on engaged experts and applies an anchor loss to stabilize the router.", "result": "SEUF improves forget quality by 5% and model utility by 35%, unlearning only 0.06% of parameters.", "conclusion": "SEUF is an efficient and effective solution for unlearning in MoE LLMs, compatible with standard algorithms."}}
{"id": "2404.08221", "pdf": "https://arxiv.org/pdf/2404.08221", "abs": "https://arxiv.org/abs/2404.08221", "authors": ["Archer Amon", "Zhipeng Yin", "Zichong Wang", "Avash Palikhe", "Wenbin Zhang"], "title": "Uncertain Boundaries: Multidisciplinary Approaches to Copyright Issues in Generative AI", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": null, "summary": "Generative AI is becoming increasingly prevalent in creative fields, sparking\nurgent debates over how current copyright laws can keep pace with technological\ninnovation. Recent controversies of AI models generating near-replicas of\ncopyrighted material highlight the need to adapt current legal frameworks and\ndevelop technical methods to mitigate copyright infringement risks. This task\nrequires understanding the intersection between computational concepts such as\nlarge-scale data scraping and probabilistic content generation, legal\ndefinitions of originality and fair use, and economic impacts on IP rights\nholders. However, most existing research on copyright in AI takes a purely\ncomputer science or law-based approach, leaving a gap in coordinating these\napproaches that only multidisciplinary efforts can effectively address. To\nbridge this gap, our survey adopts a comprehensive approach synthesizing\ninsights from law, policy, economics, and computer science. It begins by\ndiscussing the foundational goals and considerations that should be applied to\ncopyright in generative AI, followed by methods for detecting and assessing\npotential violations in AI system outputs. Next, it explores various regulatory\noptions influenced by legal, policy, and economic frameworks to manage and\nmitigate copyright concerns associated with generative AI and reconcile the\ninterests of IP rights holders with that of generative AI producers. The\ndiscussion then introduces techniques to safeguard individual creative works\nfrom unauthorized replication, such as watermarking and cryptographic\nprotections. Finally, it describes advanced training strategies designed to\nprevent AI models from reproducing protected content. In doing so, we highlight\nkey opportunities for action and offer actionable strategies that creators,\ndevelopers, and policymakers can use in navigating the evolving copyright\nlandscape.", "AI": {"tldr": "The paper explores the intersection of generative AI and copyright law, advocating for multidisciplinary solutions to address infringement risks and reconcile stakeholder interests.", "motivation": "The rise of generative AI in creative fields has created legal and technical challenges, necessitating a coordinated approach to adapt copyright laws and mitigate risks.", "method": "The survey synthesizes insights from law, policy, economics, and computer science, covering detection methods, regulatory options, and technical safeguards like watermarking and advanced training strategies.", "result": "The paper identifies actionable strategies for creators, developers, and policymakers to navigate copyright issues in generative AI.", "conclusion": "Multidisciplinary efforts are essential to balance innovation and IP protection, offering practical solutions for the evolving copyright landscape."}}
{"id": "2310.03647", "pdf": "https://arxiv.org/pdf/2310.03647", "abs": "https://arxiv.org/abs/2310.03647", "authors": ["Haosen Ge", "Hamsa Bastani", "Osbert Bastani"], "title": "Rethinking Algorithmic Fairness for Human-AI Collaboration", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Existing approaches to algorithmic fairness aim to ensure equitable outcomes\nif human decision-makers comply perfectly with algorithmic decisions. However,\nperfect compliance with the algorithm is rarely a reality or even a desirable\noutcome in human-AI collaboration. Yet, recent studies have shown that\nselective compliance with fair algorithms can amplify discrimination relative\nto the prior human policy. As a consequence, ensuring equitable outcomes\nrequires fundamentally different algorithmic design principles that ensure\nrobustness to the decision-maker's (a priori unknown) compliance pattern. We\ndefine the notion of compliance-robustly fair algorithmic recommendations that\nare guaranteed to (weakly) improve fairness in decisions, regardless of the\nhuman's compliance pattern. We propose a simple optimization strategy to\nidentify the best performance-improving compliance-robustly fair policy.\nHowever, we show that it may be infeasible to design algorithmic\nrecommendations that are simultaneously fair in isolation, compliance-robustly\nfair, and more accurate than the human policy; thus, if our goal is to improve\nthe equity and accuracy of human-AI collaboration, it may not be desirable to\nenforce traditional algorithmic fairness constraints. We illustrate the value\nof our approach on criminal sentencing data before and after the introduction\nof an algorithmic risk assessment tool in Virginia.", "AI": {"tldr": "The paper addresses fairness in human-AI collaboration, showing selective compliance with fair algorithms can worsen discrimination. It proposes compliance-robustly fair recommendations to improve fairness regardless of human compliance patterns.", "motivation": "Current fairness approaches assume perfect human compliance with algorithms, which is unrealistic. Selective compliance can amplify bias, necessitating new design principles.", "method": "The paper defines compliance-robustly fair recommendations and proposes an optimization strategy to ensure fairness under any compliance pattern.", "result": "It shows trade-offs: achieving fairness in isolation, compliance robustness, and accuracy may be infeasible. Traditional fairness constraints might not improve equity and accuracy.", "conclusion": "The approach is validated on criminal sentencing data, highlighting the need for new fairness principles in human-AI collaboration."}}
{"id": "2506.23852", "pdf": "https://arxiv.org/pdf/2506.23852", "abs": "https://arxiv.org/abs/2506.23852", "authors": ["Jianing Jin", "Jiangyong Ying", "Huiyu Duan", "Liu Yang", "Sijing Wu", "Yunhao Li", "Yushuo Zheng", "Xiongkuo Min", "Guangtao Zhai"], "title": "RGC-VQA: An Exploration Database for Robotic-Generated Video Quality Assessment", "categories": ["cs.CV"], "comment": null, "summary": "As camera-equipped robotic platforms become increasingly integrated into\ndaily life, robotic-generated videos have begun to appear on streaming media\nplatforms, enabling us to envision a future where humans and robots coexist. We\ninnovatively propose the concept of Robotic-Generated Content (RGC) to term\nthese videos generated from egocentric perspective of robots. The perceptual\nquality of RGC videos is critical in human-robot interaction scenarios, and RGC\nvideos exhibit unique distortions and visual requirements that differ markedly\nfrom those of professionally-generated content (PGC) videos and user-generated\ncontent (UGC) videos. However, dedicated research on quality assessment of RGC\nvideos is still lacking. To address this gap and to support broader robotic\napplications, we establish the first Robotic-Generated Content Database (RGCD),\nwhich contains a total of 2,100 videos drawn from three robot categories and\nsourced from diverse platforms. A subjective VQA experiment is conducted\nsubsequently to assess human visual perception of robotic-generated videos.\nFinally, we conduct a benchmark experiment to evaluate the performance of 11\nstate-of-the-art VQA models on our database. Experimental results reveal\nsignificant limitations in existing VQA models when applied to complex,\nrobotic-generated content, highlighting a critical need for RGC-specific VQA\nmodels. Our RGCD is publicly available at:\nhttps://github.com/IntMeGroup/RGC-VQA.", "AI": {"tldr": "The paper introduces Robotic-Generated Content (RGC) and its unique quality challenges, establishes the first RGC database (RGCD), and evaluates existing VQA models, revealing their limitations for RGC.", "motivation": "The rise of robotic-generated videos necessitates dedicated quality assessment, as existing models fail to address RGC's unique distortions and visual requirements.", "method": "The authors create the RGCD with 2,100 videos, conduct subjective VQA experiments, and benchmark 11 state-of-the-art VQA models.", "result": "Existing VQA models perform poorly on RGC, indicating a need for specialized models.", "conclusion": "The study highlights the gap in RGC quality assessment and provides a foundational database for future research."}}
{"id": "2501.17905", "pdf": "https://arxiv.org/pdf/2501.17905", "abs": "https://arxiv.org/abs/2501.17905", "authors": ["Mingkuan Feng", "Jinyang Wu", "Shuai Zhang", "Pengpeng Shao", "Ruihan Jin", "Zhengqi Wen", "Jianhua Tao", "Feihu Che"], "title": "DReSS: Data-driven Regularized Structured Streamlining for Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have achieved significant progress across\nvarious domains, but their increasing scale results in high computational and\nmemory costs. Recent studies have revealed that LLMs exhibit sparsity,\nproviding the potential to reduce model size through pruning techniques.\nHowever, existing pruning methods typically follow a prune-then-finetune\nparadigm. Since the pruned components still contain valuable information, their\ndirect removal often leads to irreversible performance degradation, imposing a\nsubstantial computational burden to recover performance during finetuning. In\nthis paper, we propose a novel paradigm that first applies regularization, then\nprunes, and finally finetunes. Based on this paradigm, we introduce DReSS, a\nsimple and effective Data-driven Regularized Structured Streamlining method for\nLLMs. By leveraging a small amount of data to regularize the components to be\npruned, DReSS explicitly transfers the important information to the remaining\nparts of the model in advance. Compared to direct pruning, this can reduce the\ninformation loss caused by parameter removal, thereby enhancing its language\nmodeling capabilities. Experimental results demonstrate that DReSS\nsignificantly outperforms existing pruning methods even under extreme pruning\nratios, significantly reducing latency and increasing throughput.", "AI": {"tldr": "DReSS introduces a novel pruning paradigm (regularize-prune-finetune) for LLMs, reducing information loss and outperforming existing methods.", "motivation": "Address irreversible performance degradation in LLMs due to direct pruning by transferring important information before removal.", "method": "DReSS uses data-driven regularization before pruning and finetuning to preserve valuable information.", "result": "DReSS outperforms existing methods, reduces latency, and increases throughput under extreme pruning ratios.", "conclusion": "DReSS offers an effective solution for pruning LLMs with minimal performance loss."}}
{"id": "2405.13152", "pdf": "https://arxiv.org/pdf/2405.13152", "abs": "https://arxiv.org/abs/2405.13152", "authors": ["Shiji Huang", "Lei Ye", "Min Chen", "Wenhai Luo", "Dihong Wang", "Chenqi Xu", "Deyuan Liang"], "title": "Interpretable Interaction Modeling for Trajectory Prediction via Agent Selection and Physical Coefficient", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by International Conference on Intelligent Robots and\n  Systems (IROS 2025)", "summary": "A thorough understanding of the interaction between the target agent and\nsurrounding agents is a prerequisite for accurate trajectory prediction.\nAlthough many methods have been explored, they assign correlation coefficients\nto surrounding agents in a purely learning-based manner. In this study, we\npresent ASPILin, which manually selects interacting agents and replaces the\nattention scores in Transformer with a newly computed physical correlation\ncoefficient, enhancing the interpretability of interaction modeling.\nSurprisingly, these simple modifications can significantly improve prediction\nperformance and substantially reduce computational costs. We intentionally\nsimplified our model in other aspects, such as map encoding. Remarkably,\nexperiments conducted on the INTERACTION, highD, and CitySim datasets\ndemonstrate that our method is efficient and straightforward, outperforming\nother state-of-the-art methods.", "AI": {"tldr": "ASPILin improves trajectory prediction by manually selecting interacting agents and using physical correlation coefficients, enhancing interpretability and performance while reducing computational costs.", "motivation": "To enhance the interpretability and accuracy of trajectory prediction by addressing the limitations of purely learning-based methods in modeling interactions between agents.", "method": "Manually selects interacting agents and replaces Transformer attention scores with physical correlation coefficients, simplifying other aspects like map encoding.", "result": "Outperforms state-of-the-art methods on INTERACTION, highD, and CitySim datasets, with improved efficiency and reduced computational costs.", "conclusion": "ASPILin demonstrates that simple, interpretable modifications can significantly enhance trajectory prediction performance and computational efficiency."}}
{"id": "2310.15952", "pdf": "https://arxiv.org/pdf/2310.15952", "abs": "https://arxiv.org/abs/2310.15952", "authors": ["Xing Shen", "Hengguan Huang", "Brennan Nichyporuk", "Tal Arbel"], "title": "Improving Robustness and Reliability in Medical Image Classification with Latent-Guided Diffusion and Nested-Ensembles", "categories": ["cs.LG", "cs.CV"], "comment": "Accepted to IEEE Transactions on Medical Imaging, 2025", "summary": "Once deployed, medical image analysis methods are often faced with unexpected\nimage corruptions and noise perturbations. These unknown covariate shifts\npresent significant challenges to deep learning based methods trained on\n\"clean\" images. This often results in unreliable predictions and poorly\ncalibrated confidence, hence hindering clinical applicability. While recent\nmethods have been developed to address specific issues such as confidence\ncalibration or adversarial robustness, no single framework effectively tackles\nall these challenges simultaneously. To bridge this gap, we propose LaDiNE, a\nnovel ensemble learning method combining the robustness of Vision Transformers\nwith diffusion-based generative models for improved reliability in medical\nimage classification. Specifically, transformer encoder blocks are used as\nhierarchical feature extractors that learn invariant features from images for\neach ensemble member, resulting in features that are robust to input\nperturbations. In addition, diffusion models are used as flexible density\nestimators to estimate member densities conditioned on the invariant features,\nleading to improved modeling of complex data distributions while retaining\nproperly calibrated confidence. Extensive experiments on tuberculosis chest\nX-rays and melanoma skin cancer datasets demonstrate that LaDiNE achieves\nsuperior performance compared to a wide range of state-of-the-art methods by\nsimultaneously improving prediction accuracy and confidence calibration under\nunseen noise, adversarial perturbations, and resolution degradation.", "AI": {"tldr": "LaDiNE is a novel ensemble learning method combining Vision Transformers and diffusion models to improve reliability in medical image classification under unexpected corruptions and noise.", "motivation": "Medical image analysis methods often fail under unexpected image corruptions and noise, leading to unreliable predictions and poor confidence calibration. Existing methods address specific issues but lack a unified solution.", "method": "LaDiNE uses transformer encoder blocks for robust feature extraction and diffusion models for density estimation, ensuring invariant features and calibrated confidence.", "result": "LaDiNE outperforms state-of-the-art methods in accuracy and confidence calibration under noise, adversarial perturbations, and resolution degradation on tuberculosis and melanoma datasets.", "conclusion": "LaDiNE effectively addresses multiple challenges in medical image analysis, offering a robust and reliable solution for clinical applications."}}
{"id": "2506.23854", "pdf": "https://arxiv.org/pdf/2506.23854", "abs": "https://arxiv.org/abs/2506.23854", "authors": ["Yida Wang", "Xueyang Zhang", "Kun Zhan", "Peng Jia", "Xianpeng Lang"], "title": "HiNeuS: High-fidelity Neural Surface Mitigating Low-texture and Reflective Ambiguity", "categories": ["cs.CV", "cs.GR"], "comment": "Published in International Conference on Computer Vision (ICCV) 2025", "summary": "Neural surface reconstruction faces persistent challenges in reconciling\ngeometric fidelity with photometric consistency under complex scene conditions.\nWe present HiNeuS, a unified framework that holistically addresses three core\nlimitations in existing approaches: multi-view radiance inconsistency, missing\nkeypoints in textureless regions, and structural degradation from over-enforced\nEikonal constraints during joint optimization. To resolve these issues through\na unified pipeline, we introduce: 1) Differential visibility verification\nthrough SDF-guided ray tracing, resolving reflection ambiguities via continuous\nocclusion modeling; 2) Planar-conformal regularization via ray-aligned geometry\npatches that enforce local surface coherence while preserving sharp edges\nthrough adaptive appearance weighting; and 3) Physically-grounded Eikonal\nrelaxation that dynamically modulates geometric constraints based on local\nradiance gradients, enabling detail preservation without sacrificing global\nregularity. Unlike prior methods that handle these aspects through sequential\noptimizations or isolated modules, our approach achieves cohesive integration\nwhere appearance-geometry constraints evolve synergistically throughout\ntraining. Comprehensive evaluations across synthetic and real-world datasets\ndemonstrate state-of-the-art performance, including a 21.4% reduction in\nChamfer distance over reflection-aware baselines and 2.32 dB PSNR improvement\nagainst neural rendering counterparts. Qualitative analyses reveal superior\ncapability in recovering specular instruments, urban layouts with\ncentimeter-scale infrastructure, and low-textured surfaces without local patch\ncollapse. The method's generalizability is further validated through successful\napplication to inverse rendering tasks, including material decomposition and\nview-consistent relighting.", "AI": {"tldr": "HiNeuS is a unified framework for neural surface reconstruction that addresses multi-view radiance inconsistency, missing keypoints, and structural degradation through differential visibility verification, planar-conformal regularization, and physically-grounded Eikonal relaxation. It outperforms baselines in accuracy and detail preservation.", "motivation": "Existing methods struggle with geometric fidelity and photometric consistency under complex conditions, leading to issues like radiance inconsistency and structural degradation.", "method": "HiNeuS integrates differential visibility verification, planar-conformal regularization, and dynamic Eikonal relaxation into a unified pipeline for joint optimization.", "result": "The method achieves a 21.4% reduction in Chamfer distance and 2.32 dB PSNR improvement, excelling in recovering specular surfaces and low-textured regions.", "conclusion": "HiNeuS offers a cohesive solution for neural surface reconstruction, validated by superior performance and generalizability in inverse rendering tasks."}}
{"id": "2502.00306", "pdf": "https://arxiv.org/pdf/2502.00306", "abs": "https://arxiv.org/abs/2502.00306", "authors": ["Ali Naseh", "Yuefeng Peng", "Anshuman Suri", "Harsh Chaudhari", "Alina Oprea", "Amir Houmansadr"], "title": "Riddle Me This! Stealthy Membership Inference for Retrieval-Augmented Generation", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.IR", "cs.LG"], "comment": "This is the full version (27 pages) of the paper 'Riddle Me This!\n  Stealthy Membership Inference for Retrieval-Augmented Generation' published\n  at CCS 2025", "summary": "Retrieval-Augmented Generation (RAG) enables Large Language Models (LLMs) to\ngenerate grounded responses by leveraging external knowledge databases without\naltering model parameters. Although the absence of weight tuning prevents\nleakage via model parameters, it introduces the risk of inference adversaries\nexploiting retrieved documents in the model's context. Existing methods for\nmembership inference and data extraction often rely on jailbreaking or\ncarefully crafted unnatural queries, which can be easily detected or thwarted\nwith query rewriting techniques common in RAG systems. In this work, we present\nInterrogation Attack (IA), a membership inference technique targeting documents\nin the RAG datastore. By crafting natural-text queries that are answerable only\nwith the target document's presence, our approach demonstrates successful\ninference with just 30 queries while remaining stealthy; straightforward\ndetectors identify adversarial prompts from existing methods up to ~76x more\nfrequently than those generated by our attack. We observe a 2x improvement in\nTPR@1%FPR over prior inference attacks across diverse RAG configurations, all\nwhile costing less than $0.02 per document inference.", "AI": {"tldr": "The paper introduces Interrogation Attack (IA), a stealthy membership inference technique for RAG systems, outperforming prior methods with fewer queries and lower cost.", "motivation": "Existing inference attacks on RAG systems rely on unnatural queries, which are easily detectable. The paper aims to develop a more stealthy and effective method.", "method": "IA crafts natural-text queries answerable only if a target document is present in the RAG datastore, enabling membership inference with minimal queries.", "result": "IA achieves a 2x improvement in TPR@1%FPR over prior attacks, costs less than $0.02 per document, and is significantly harder to detect.", "conclusion": "IA demonstrates the vulnerability of RAG systems to stealthy inference attacks, highlighting the need for improved defenses."}}
{"id": "2405.14715", "pdf": "https://arxiv.org/pdf/2405.14715", "abs": "https://arxiv.org/abs/2405.14715", "authors": ["Young Kyun Jang", "Ser-nam Lim"], "title": "Towards Cross-modal Backward-compatible Representation Learning for Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Modern retrieval systems often struggle with upgrading to new and more\npowerful models due to the incompatibility of embeddings between the old and\nnew models. This necessitates a costly process known as backfilling, which\ninvolves re-computing the embeddings for a large number of data samples. In\nvision, Backward-compatible Training (BT) has been proposed to ensure that the\nnew model aligns with the old model's embeddings. This paper extends the\nconcept of vision-only BT to the field of cross-modal retrieval, marking the\nfirst attempt to address Cross-modal BT (XBT). Our goal is to achieve\nbackward-compatibility between Vision-Language Pretraining (VLP) models, such\nas CLIP, for the cross-modal retrieval task. To address XBT challenges, we\npropose an efficient solution: a projection module that maps the new model's\nembeddings to those of the old model. This module, pretrained solely with text\ndata, significantly reduces the number of image-text pairs required for XBT\nlearning, and, once it is pretrained, it avoids using the old model during\ntraining. Furthermore, we utilize parameter-efficient training strategies that\nimprove efficiency and preserve the off-the-shelf new model's knowledge by\navoiding any modifications. Experimental results on cross-modal retrieval\ndatasets demonstrate the effectiveness of XBT and its potential to enable\nbackfill-free upgrades when a new VLP model emerges.", "AI": {"tldr": "The paper introduces Cross-modal Backward-compatible Training (XBT) to align new and old model embeddings in cross-modal retrieval, reducing the need for costly backfilling.", "motivation": "Modern retrieval systems face challenges upgrading models due to embedding incompatibility, requiring expensive backfilling.", "method": "Proposes a projection module pretrained with text data to map new embeddings to old ones, minimizing image-text pairs needed and avoiding old model use during training.", "result": "XBT effectively enables backward-compatibility in Vision-Language Pretraining models, as shown in cross-modal retrieval experiments.", "conclusion": "XBT offers a practical solution for backfill-free upgrades in cross-modal retrieval systems."}}
{"id": "2402.00450", "pdf": "https://arxiv.org/pdf/2402.00450", "abs": "https://arxiv.org/abs/2402.00450", "authors": ["Qilong Yan", "Yufeng Zhang", "Jinghao Zhang", "Jingpu Duan", "Jian Yin"], "title": "CPT: Competence-progressive Training Strategy for Few-shot Node Classification", "categories": ["cs.LG", "I.2.6"], "comment": "APWEB-WAIM 2025", "summary": "Graph Neural Networks (GNNs) have made significant advancements in node\nclassification, but their success relies on sufficient labeled nodes per class\nin the training data. Real-world graph data often exhibits a long-tail\ndistribution with sparse labels, emphasizing the importance of GNNs' ability in\nfew-shot node classification, which entails categorizing nodes with limited\ndata. Traditional episodic meta-learning approaches have shown promise in this\ndomain, but they face an inherent limitation: it might lead the model to\nconverge to suboptimal solutions because of random and uniform task assignment,\nignoring task difficulty levels. This could lead the meta-learner to face\ncomplex tasks too soon, hindering proper learning. Ideally, the meta-learner\nshould start with simple concepts and advance to more complex ones, like human\nlearning. So, we introduce CPT, a novel two-stage curriculum learning method\nthat aligns task difficulty with the meta-learner's progressive competence,\nenhancing overall performance. Specifically, in CPT's initial stage, the focus\nis on simpler tasks, fostering foundational skills for engaging with complex\ntasks later. Importantly, the second stage dynamically adjusts task difficulty\nbased on the meta-learner's growing competence, aiming for optimal knowledge\nacquisition. Extensive experiments on popular node classification datasets\ndemonstrate significant improvements of our strategy over existing methods.", "AI": {"tldr": "CPT introduces a two-stage curriculum learning method for GNNs in few-shot node classification, improving performance by aligning task difficulty with the meta-learner's competence.", "motivation": "Traditional meta-learning ignores task difficulty, leading to suboptimal solutions. CPT mimics human learning by starting with simple tasks and progressing to complex ones.", "method": "CPT uses a two-stage approach: initial simpler tasks for foundational skills, followed by dynamic adjustment of task difficulty based on competence.", "result": "Experiments show CPT significantly outperforms existing methods on node classification datasets.", "conclusion": "CPT enhances GNN performance in few-shot learning by adapting task difficulty to the meta-learner's evolving competence."}}
{"id": "2506.23856", "pdf": "https://arxiv.org/pdf/2506.23856", "abs": "https://arxiv.org/abs/2506.23856", "authors": ["Ji Zhang", "Shihan Wu", "Lianli Gao", "Jingkuan Song", "Nicu Sebe", "Heng Tao Shen"], "title": "A Closer Look at Conditional Prompt Tuning for Vision-Language Models", "categories": ["cs.CV"], "comment": "18 pages", "summary": "Despite the great promise of Prompt Tuning (PT) in adapting large\nVision-Language Pretrained Models (VLPMs) to downstream tasks, they often\nstruggle to overcome the Base-New Tradeoff (BNT) dilemma: as VLPMs are better\ntuned to a base task, their ability to generalize to new tasks diminishes.\nRecent work on conditional PT addresses this problem by replacing static\nprompts with dynamic Visual Image Information (VII)-conditioned prompts,\nimproving the model's generalization to new tasks to some extent. In this work,\nwe first identify a critical issue with existing conditional PT methods: using\nVII as the \"condition\" of prompts yields suboptimal performance, and even\nrandom noise-conditioned prompts can outperform the VII-conditioned\ncounterparts. On further analysis, we find that learning dynamic prompts\nconditioned on Textual Class Information (TCI) is the key to solving the BNT\nproblem. Motivated by this, we then propose Class-adaptive Prompt Tuning\n(CaPT), which enables fast adaptation of tuned models to new classes by\nlearning TCI-conditioned prompts from base classes. Remarkably, CaPT can be\nused as a plugin to mitigate the BNT problem for existing unconditional PT\nschemes. Extensive experiments on 11 datasets show that CaPT consistently\nimproves the performance of five strong unconditional PT baselines with\nnegligible additional computational cost. Additionally, by integrating CaPT\nwith our recently proposed DePT framework, we devise a new conditional PT\napproach, termed DeCaPT, which outperforms the H ACC of the state-of-the-art\nconditional PT scheme by 3.49%, averaged over the 11 datasets. Code:\nhttps://github.com/Koorye/CaPT.", "AI": {"tldr": "The paper identifies suboptimal performance in existing conditional Prompt Tuning (PT) methods due to Visual Image Information (VII)-conditioned prompts and proposes Class-adaptive Prompt Tuning (CaPT) using Textual Class Information (TCI) to solve the Base-New Tradeoff (BNT) problem. CaPT improves performance across 11 datasets with minimal computational overhead.", "motivation": "To address the BNT dilemma in Vision-Language Pretrained Models (VLPMs), where tuning to base tasks reduces generalization to new tasks, and to improve upon existing conditional PT methods.", "method": "Proposes CaPT, which learns TCI-conditioned prompts from base classes for fast adaptation to new tasks. Also integrates CaPT with DePT to create DeCaPT, a new conditional PT approach.", "result": "CaPT consistently enhances five unconditional PT baselines across 11 datasets. DeCaPT outperforms the state-of-the-art conditional PT by 3.49% in H ACC.", "conclusion": "CaPT effectively mitigates the BNT problem and can be integrated with existing PT methods for improved performance, as demonstrated by DeCaPT."}}
{"id": "2503.04734", "pdf": "https://arxiv.org/pdf/2503.04734", "abs": "https://arxiv.org/abs/2503.04734", "authors": ["Anna T. Thomas", "Adam Yee", "Andrew Mayne", "Maya B. Mathur", "Dan Jurafsky", "Kristina Gligori\u0107"], "title": "What can large language models do for sustainable food?", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": "ICML camera ready version", "summary": "Food systems are responsible for a third of human-caused greenhouse gas\nemissions. We investigate what Large Language Models (LLMs) can contribute to\nreducing the environmental impacts of food production. We define a typology of\ndesign and prediction tasks based on the sustainable food literature and\ncollaboration with domain experts, and evaluate six LLMs on four tasks in our\ntypology. For example, for a sustainable protein design task, food science\nexperts estimated that collaboration with an LLM can reduce time spent by 45%\non average, compared to 22% for collaboration with another expert human food\nscientist. However, for a sustainable menu design task, LLMs produce suboptimal\nsolutions when instructed to consider both human satisfaction and climate\nimpacts. We propose a general framework for integrating LLMs with combinatorial\noptimization to improve reasoning capabilities. Our approach decreases\nemissions of food choices by 79% in a hypothetical restaurant while maintaining\nparticipants' satisfaction with their set of choices. Our results demonstrate\nLLMs' potential, supported by optimization techniques, to accelerate\nsustainable food development and adoption.", "AI": {"tldr": "LLMs can reduce time in sustainable food tasks by 45% but struggle with multi-objective tasks like menu design. Combining LLMs with optimization cuts emissions by 79% while maintaining satisfaction.", "motivation": "Food systems contribute significantly to greenhouse gas emissions. The study explores how LLMs can aid in reducing these impacts by assisting in sustainable food tasks.", "method": "A typology of tasks was defined with experts. Six LLMs were evaluated on four tasks. A framework integrating LLMs with combinatorial optimization was proposed.", "result": "LLMs reduced task time by 45% vs. 22% for humans. For menu design, LLMs were suboptimal. Optimization with LLMs cut emissions by 79% while keeping satisfaction high.", "conclusion": "LLMs, when combined with optimization, show promise in accelerating sustainable food development, though challenges remain in multi-objective tasks."}}
{"id": "2405.16258", "pdf": "https://arxiv.org/pdf/2405.16258", "abs": "https://arxiv.org/abs/2405.16258", "authors": ["Hong Liu", "Xiuxiu Qiu", "Yiming Shi", "Miao Xu", "Zelin Zang", "Zhen Lei"], "title": "Deep Multi-Manifold Transformation Based Multivariate Time Series Fault Detection", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": "11 pages, 7 figures, accepted by TNNLS", "summary": "Unsupervised fault detection in multivariate time series plays a vital role\nin ensuring the stable operation of complex systems. Traditional methods often\nassume that normal data follow a single Gaussian distribution and identify\nanomalies as deviations from this distribution. {\\color{black} However, this\nsimplified assumption fails to capture the diversity and structural complexity\nof real-world time series, which can lead to misjudgments and reduced detection\nperformance in practical applications. To address this issue, we propose a new\nmethod that combines a neighborhood-driven data augmentation strategy with a\nmulti-manifold representation learning framework.} By incorporating information\nfrom local neighborhoods, the augmentation module can simulate contextual\nvariations of normal data, enhancing the model's adaptability to distributional\nchanges. In addition, we design a structure-aware feature learning approach\nthat encourages natural clustering of similar patterns in the feature space\nwhile maintaining sufficient distinction between different operational states.\nExtensive experiments on several public benchmark datasets demonstrate that our\nmethod achieves superior performance in terms of both accuracy and robustness,\nshowing strong potential for generalization and real-world deployment.", "AI": {"tldr": "A new method for unsupervised fault detection in multivariate time series combines neighborhood-driven data augmentation and multi-manifold learning to improve adaptability and accuracy.", "motivation": "Traditional methods assume a single Gaussian distribution for normal data, which fails to capture real-world complexity, leading to poor performance.", "method": "Proposes a neighborhood-driven data augmentation strategy and multi-manifold representation learning to simulate contextual variations and enhance feature clustering.", "result": "Achieves superior performance in accuracy and robustness on public benchmark datasets, showing strong generalization potential.", "conclusion": "The method effectively addresses limitations of traditional approaches and demonstrates practical applicability for real-world deployment."}}
{"id": "2402.09600", "pdf": "https://arxiv.org/pdf/2402.09600", "abs": "https://arxiv.org/abs/2402.09600", "authors": ["Yancheng Wang", "Yingzhen Yang"], "title": "Graph Contrastive Learning with Low-Rank Regularization and Low-Rank Attention for Noisy Node Classification", "categories": ["cs.LG", "cs.SI", "stat.ML"], "comment": null, "summary": "Graph Neural Networks (GNNs) have achieved remarkable success in learning\nnode representations and have shown strong performance in tasks such as node\nclassification. However, recent findings indicate that the presence of noise in\nreal-world graph data can substantially impair the effectiveness of GNNs. To\naddress this challenge, we introduce a robust and innovative node\nrepresentation learning method named Graph Contrastive Learning with Low-Rank\nRegularization, or GCL-LRR, which follows a two-stage transductive learning\nframework for node classification. In the first stage, the GCL-LRR encoder is\noptimized through prototypical contrastive learning while incorporating a\nlow-rank regularization objective. In the second stage, the representations\ngenerated by GCL-LRR are employed by a linear transductive classifier to\npredict the labels of unlabeled nodes within the graph. Our GCL-LRR is inspired\nby the Low Frequency Property (LFP) of the graph data and its labels, and it is\nalso theoretically motivated by our sharp generalization bound for transductive\nlearning. To the best of our knowledge, our theoretical result is among the\nfirst to theoretically demonstrate the advantage of low-rank regularization in\ntransductive learning, which is also supported by strong empirical results. To\nfurther enhance the performance of GCL-LRR, we present an improved model named\nGCL-LR-Attention, which incorporates a novel LR-Attention layer into GCL-LRR.\nGCL-LR-Attention reduces the kernel complexity of GCL-LRR and contributes to a\ntighter generalization bound, leading to improved performance. Extensive\nevaluations on standard benchmark datasets evidence the effectiveness and\nrobustness of both GCL-LRR and GCL-LR-Attention in learning meaningful node\nrepresentations. The code is available at\nhttps://github.com/Statistical-Deep-Learning/GCL-LR-Attention.", "AI": {"tldr": "The paper introduces GCL-LRR and GCL-LR-Attention, two robust methods for node representation learning in noisy graph data, using contrastive learning and low-rank regularization, supported by theoretical and empirical results.", "motivation": "Address the challenge of noise in real-world graph data impairing GNN performance by developing robust node representation learning methods.", "method": "A two-stage transductive learning framework: (1) GCL-LRR encoder optimization via prototypical contrastive learning with low-rank regularization, (2) linear transductive classifier for label prediction. GCL-LR-Attention adds an LR-Attention layer to improve performance.", "result": "Both GCL-LRR and GCL-LR-Attention show effectiveness and robustness in learning node representations, supported by empirical evaluations.", "conclusion": "The proposed methods, grounded in theoretical insights, offer improved performance and robustness for node classification in noisy graph data."}}
{"id": "2506.23858", "pdf": "https://arxiv.org/pdf/2506.23858", "abs": "https://arxiv.org/abs/2506.23858", "authors": ["Jianzong Wu", "Liang Hou", "Haotian Yang", "Xin Tao", "Ye Tian", "Pengfei Wan", "Di Zhang", "Yunhai Tong"], "title": "VMoBA: Mixture-of-Block Attention for Video Diffusion Models", "categories": ["cs.CV"], "comment": "Code is at https://github.com/KwaiVGI/VMoBA", "summary": "The quadratic complexity of full attention mechanisms poses a significant\nbottleneck for Video Diffusion Models (VDMs) aiming to generate long-duration,\nhigh-resolution videos. While various sparse attention methods have been\nproposed, many are designed as training-free inference accelerators or do not\noptimally capture the unique spatio-temporal characteristics inherent in video\ndata when trained natively. This paper introduces Video Mixture of Block\nAttention (VMoBA), a novel sparse attention mechanism specifically adapted for\nVDMs. Motivated by an in-depth analysis of attention patterns within\npre-trained video transformers, which revealed strong spatio-temporal locality,\nvarying query importance, and head-specific concentration levels, VMoBA\nenhances the original MoBA framework with three key modifications: (1) a\nlayer-wise recurrent block partition scheme (1D-2D-3D) to dynamically adapt to\ndiverse spatio-temporal attention patterns and improve efficiency; (2) global\nblock selection to prioritize the most salient query-key block interactions\nacross an entire attention head; and (3) threshold-based block selection to\ndynamically determine the number of attended blocks based on their cumulative\nsimilarity. Extensive experiments demonstrate that VMoBA significantly\naccelerates the training of VDMs on longer sequences, achieving 2.92x FLOPs and\n1.48x latency speedup, while attaining comparable or even superior generation\nquality to full attention. Furthermore, VMoBA exhibits competitive performance\nin training-free inference, offering 2.40x FLOPs and 1.35x latency speedup for\nhigh-res video generation.", "AI": {"tldr": "VMoBA introduces a sparse attention mechanism for Video Diffusion Models (VDMs) to address quadratic complexity, improving efficiency and generation quality.", "motivation": "The quadratic complexity of full attention in VDMs hinders long-duration, high-resolution video generation. Existing sparse methods are suboptimal for video data.", "method": "VMoBA adapts MoBA with layer-wise block partitioning, global block selection, and threshold-based block selection to optimize spatio-temporal attention.", "result": "VMoBA achieves 2.92x FLOPs and 1.48x latency speedup in training, with comparable/superior quality to full attention. Inference speedups are 2.40x FLOPs and 1.35x latency.", "conclusion": "VMoBA effectively addresses attention bottlenecks in VDMs, offering significant efficiency gains without compromising quality."}}
{"id": "2503.13377", "pdf": "https://arxiv.org/pdf/2503.13377", "abs": "https://arxiv.org/abs/2503.13377", "authors": ["Ye Wang", "Ziheng Wang", "Boshen Xu", "Yang Du", "Kejun Lin", "Zihan Xiao", "Zihao Yue", "Jianzhong Ju", "Liang Zhang", "Dingyi Yang", "Xiangnan Fang", "Zewen He", "Zhenbo Luo", "Wenxuan Wang", "Junqi Lin", "Jian Luan", "Qin Jin"], "title": "Time-R1: Post-Training Large Vision Language Model for Temporal Video Grounding", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Project Page: https://xuboshen.github.io/Time-R1/", "summary": "Temporal Video Grounding (TVG), the task of locating specific video segments\nbased on language queries, is a core challenge in long-form video\nunderstanding. While recent Large Vision-Language Models (LVLMs) have shown\nearly promise in tackling TVG through supervised fine-tuning (SFT), their\nabilities to generalize remain limited. To address this, we propose a novel\npost-training framework that enhances the generalization capabilities of LVLMs\nvia reinforcement learning (RL). Specifically, our contributions span three key\ndirections: (1) Time-R1: we introduce a reasoning-guided post-training\nframework via RL with verifiable reward to enhance the capabilities of LVLMs on\nthe TVG task. (2) TimeRFT: we explore data-efficient post-training strategies\non our curated RL-friendly dataset, which trains the model to progressively\ncomprehend difficult samples, leading to better generalization. (3) TVGBench:\nwe carefully construct a small yet comprehensive benchmark for LVLM evaluation,\nassessing 11 types of queries and featuring balanced distributions across both\nvideos and queries. Extensive experiments demonstrate that Time-R1 achieves\nstate-of-the-art performance across multiple downstream datasets using only\n2.5K training data, while improving its general video understanding\ncapabilities.", "AI": {"tldr": "The paper proposes a reinforcement learning (RL)-based post-training framework to enhance the generalization of Large Vision-Language Models (LVLMs) for Temporal Video Grounding (TVG). It introduces Time-R1, TimeRFT, and TVGBench, achieving state-of-the-art results with minimal training data.", "motivation": "Current LVLMs lack generalization in TVG tasks despite supervised fine-tuning. The paper aims to improve this via RL.", "method": "A post-training framework using RL (Time-R1), data-efficient strategies (TimeRFT), and a benchmark (TVGBench) for evaluation.", "result": "Time-R1 achieves top performance with only 2.5K training data and enhances general video understanding.", "conclusion": "The proposed RL-based framework effectively improves LVLMs' generalization for TVG, validated by strong experimental results."}}
{"id": "2405.17451", "pdf": "https://arxiv.org/pdf/2405.17451", "abs": "https://arxiv.org/abs/2405.17451", "authors": ["Nienke Nijkamp", "June Sallou", "Niels van der Heijden", "Lu\u00eds Cruz"], "title": "Green AI in Action: Strategic Model Selection for Ensembles in Production", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.SE"], "comment": "10 pages. Accepted at the 1st ACM International Conference on\n  AI-powered Software (AIware), 2024", "summary": "Integrating Artificial Intelligence (AI) into software systems has\nsignificantly enhanced their capabilities while escalating energy demands.\nEnsemble learning, combining predictions from multiple models to form a single\nprediction, intensifies this problem due to cumulative energy consumption. This\npaper presents a novel approach to model selection that addresses the challenge\nof balancing the accuracy of AI models with their energy consumption in a live\nAI ensemble system. We explore how reducing the number of models or improving\nthe efficiency of model usage within an ensemble during inference can reduce\nenergy demands without substantially sacrificing accuracy. This study\nintroduces and evaluates two model selection strategies, Static and Dynamic,\nfor optimizing ensemble learning systems performance while minimizing energy\nusage. Our results demonstrate that the Static strategy improves the F1 score\nbeyond the baseline, reducing average energy usage from 100% from the full\nensemble to 62%. The Dynamic strategy further enhances F1 scores, using on\naverage 76% compared to 100% of the full ensemble. Moreover, we propose an\napproach that balances accuracy with resource consumption, significantly\nreducing energy usage without substantially impacting accuracy. This method\ndecreased the average energy usage of the Static strategy from approximately\n62% to 14%, and for the Dynamic strategy, from around 76% to 57%. Our field\nstudy of Green AI using an operational AI system developed by a large\nprofessional services provider shows the practical applicability of adopting\nenergy-conscious model selection strategies in live production environments.", "AI": {"tldr": "The paper introduces model selection strategies (Static and Dynamic) to balance AI ensemble accuracy and energy consumption, reducing energy usage significantly without major accuracy loss.", "motivation": "The increasing energy demands of AI ensembles, especially in live systems, necessitate methods to optimize energy use while maintaining accuracy.", "method": "Two strategies (Static and Dynamic) are proposed to reduce the number or improve efficiency of models in an ensemble during inference.", "result": "Static strategy reduces energy usage to 62% and Dynamic to 76%, with further optimizations lowering these to 14% and 57% respectively, while maintaining or improving F1 scores.", "conclusion": "Energy-conscious model selection strategies are practical and effective for live AI systems, significantly reducing energy consumption without compromising accuracy."}}
{"id": "2403.03508", "pdf": "https://arxiv.org/pdf/2403.03508", "abs": "https://arxiv.org/abs/2403.03508", "authors": ["H\u00e5kon Hanisch Kj\u00e6rnli", "Lluis Mas-Ribas", "Hans Jakob H\u00e5land", "Vegard Sj\u00e5vik", "Aida Ashrafi", "Helge Langseth", "Odd Erik Gundersen"], "title": "EXPRTS: Exploring and Probing the Robustness of Time Series Forecasting Models", "categories": ["cs.LG"], "comment": "under review", "summary": "When deploying time series forecasting models based on machine learning to\nreal world settings, one often encounter situations where the data distribution\ndrifts. Such drifts expose the forecasting models to out-of-distribution (OOD)\ndata, and machine learning models lack robustness in these settings. Robustness\ncan be improved by using deep generative models or genetic algorithms to\naugment time series datasets, but these approaches lack interpretability and\nare computationally expensive. In this work, we develop an interpretable and\nsimple framework for generating time series. Our method combines time-series\ndecompositions with analytic functions, and is able to generate time series\nwith characteristics matching both in- and out-of-distribution data. This\napproach allows users to generate new time series in an interpretable fashion,\nwhich can be used to augment the dataset and improve forecasting robustness. We\ndemonstrate our framework through EXPRTS, a visual analytics tool designed for\nunivariate time series forecasting models and datasets. Different\nvisualizations of the data distribution, forecasting errors and single time\nseries instances enable users to explore time series datasets, apply\ntransformations, and evaluate forecasting model robustness across diverse\nscenarios. We show how our framework can generate meaningful OOD time series\nthat improve model robustness, and we validate EXPRTS effectiveness and\nusability through three use-cases and a user study.", "AI": {"tldr": "A framework for generating interpretable time series to improve forecasting robustness under data distribution drift, demonstrated via the EXPRTS tool.", "motivation": "Machine learning models lack robustness when exposed to out-of-distribution (OOD) data due to distribution drift. Existing methods like deep generative models or genetic algorithms are computationally expensive and lack interpretability.", "method": "Combines time-series decompositions with analytic functions to generate interpretable time series matching in- and out-of-distribution data. Demonstrated using EXPRTS, a visual analytics tool.", "result": "Generates meaningful OOD time series to improve model robustness, validated through use-cases and a user study.", "conclusion": "The framework offers an interpretable and simple solution for time series generation, enhancing forecasting robustness in diverse scenarios."}}
{"id": "2506.23863", "pdf": "https://arxiv.org/pdf/2506.23863", "abs": "https://arxiv.org/abs/2506.23863", "authors": ["Jiahao Ma", "Lei Wang", "Miaomiao liu", "David Ahmedt-Aristizabal", "Chuong Nguyen"], "title": "Puzzles: Unbounded Video-Depth Augmentation for Scalable End-to-End 3D Reconstruction", "categories": ["cs.CV"], "comment": "Feed-forward 3D reconstruction, Data Augmentation", "summary": "Multi-view 3D reconstruction remains a core challenge in computer vision.\nRecent methods, such as DUST3R and its successors, directly regress pointmaps\nfrom image pairs without relying on known scene geometry or camera parameters.\nHowever, the performance of these models is constrained by the diversity and\nscale of available training data. In this work, we introduce Puzzles, a data\naugmentation strategy that synthesizes an unbounded volume of high-quality\nposed video-depth data from a single image or video clip. By simulating diverse\ncamera trajectories and realistic scene geometry through targeted image\ntransformations, Puzzles significantly enhances data variety. Extensive\nexperiments show that integrating Puzzles into existing video-based 3D\nreconstruction pipelines consistently boosts performance without modifying the\nunderlying network architecture. Notably, models trained on only ten percent of\nthe original data augmented with Puzzles still achieve accuracy comparable to\nthose trained on the full dataset. Code is available at\nhttps://jiahao-ma.github.io/puzzles/.", "AI": {"tldr": "Puzzles is a data augmentation method for multi-view 3D reconstruction, enhancing training data diversity and improving model performance without architectural changes.", "motivation": "Existing methods like DUST3R are limited by training data diversity and scale. Puzzles addresses this by synthesizing high-quality posed video-depth data from minimal input.", "method": "Puzzles uses targeted image transformations to simulate diverse camera trajectories and realistic scene geometry, creating augmented training data.", "result": "Models trained with Puzzles achieve comparable accuracy using only 10% of the original data, boosting performance in existing pipelines.", "conclusion": "Puzzles effectively enhances data variety and model performance in 3D reconstruction, offering a scalable solution with minimal data requirements."}}
{"id": "2503.22968", "pdf": "https://arxiv.org/pdf/2503.22968", "abs": "https://arxiv.org/abs/2503.22968", "authors": ["Hanwool Lee", "Dasol Choi", "Sooyong Kim", "Ilgyun Jung", "Sangwon Baek", "Guijin Son", "Inseon Hwang", "Naeun Lee", "Seunghyeok Hong"], "title": "Redefining Evaluation Standards: A Unified Framework for Evaluating the Korean Capabilities of Language Models", "categories": ["cs.CE", "cs.AI", "cs.CL"], "comment": null, "summary": "Recent advancements in Korean large language models (LLMs) have driven\nnumerous benchmarks and evaluation methods, yet inconsistent protocols cause up\nto 10 p.p performance gaps across institutions. Overcoming these\nreproducibility gaps does not mean enforcing a one-size-fits-all evaluation.\nRather, effective benchmarking requires diverse experimental approaches and a\nframework robust enough to support them. To this end, we introduce HRET (Haerae\nEvaluation Toolkit), an open-source, registry-based framework that unifies\nKorean LLM assessment. HRET integrates major Korean benchmarks, multiple\ninference backends, and multi-method evaluation, with language consistency\nenforcement to ensure genuine Korean outputs. Its modular registry design also\nenables rapid incorporation of new datasets, methods, and backends, ensuring\nthe toolkit adapts to evolving research needs. Beyond standard accuracy\nmetrics, HRET incorporates Korean-focused output analyses-morphology-aware\nType-Token Ratio (TTR) for evaluating lexical diversity and systematic\nkeyword-omission detection for identifying missing concepts-to provide\ndiagnostic insights into language-specific behaviors. These targeted analyses\nhelp researchers pinpoint morphological and semantic shortcomings in model\noutputs, guiding focused improvements in Korean LLM development.", "AI": {"tldr": "HRET is an open-source framework for unified evaluation of Korean LLMs, addressing reproducibility gaps with diverse benchmarks and language-specific analyses.", "motivation": "Inconsistent evaluation protocols for Korean LLMs cause significant performance gaps, necessitating a flexible and robust framework.", "method": "HRET integrates benchmarks, inference backends, and multi-method evaluation with language consistency enforcement. It includes modular registry design for adaptability.", "result": "HRET provides diagnostic insights into Korean LLM outputs, including lexical diversity and concept omission, aiding targeted improvements.", "conclusion": "HRET offers a comprehensive and adaptable solution for evaluating Korean LLMs, enhancing reproducibility and guiding development."}}
{"id": "2405.19202", "pdf": "https://arxiv.org/pdf/2405.19202", "abs": "https://arxiv.org/abs/2405.19202", "authors": ["Renato M. Silva", "Gregorio F. Azevedo", "Matheus V. V. Berto", "Jean R. Rocha", "Eduardo C. Fidelis", "Matheus V. Nogueira", "Pedro H. Lisboa", "Tiago A. Almeida"], "title": "Vulnerable Road User Detection and Safety Enhancement: A Comprehensive Survey", "categories": ["cs.LG", "cs.AI"], "comment": "60 pages, 18 tables, 8 figures, citing 370 (up-to-date) papers.\n  Expert Systems With Applications (2025)", "summary": "Traffic incidents involving vulnerable road users (VRUs) constitute a\nsignificant proportion of global road accidents. Advances in traffic\ncommunication ecosystems, coupled with sophisticated signal processing and\nmachine learning techniques, have facilitated the utilization of data from\ndiverse sensors. Despite these advancements and the availability of extensive\ndatasets, substantial progress is required to mitigate traffic casualties. This\npaper provides a comprehensive survey of state-of-the-art technologies and\nmethodologies to enhance the safety of VRUs. The study investigates the\ncommunication networks between vehicles and VRUs, emphasizing the integration\nof advanced sensors and the availability of relevant datasets. It explores\npreprocessing techniques and data fusion methods to enhance sensor data\nquality. Furthermore, our study assesses critical simulation environments\nessential for developing and testing VRU safety systems. Our research also\nhighlights recent advances in VRU detection and classification algorithms,\naddressing challenges such as variable environmental conditions. Additionally,\nwe cover cutting-edge research in predicting VRU intentions and behaviors,\nwhich is mandatory for proactive collision avoidance strategies. Through this\nsurvey, we aim to provide a comprehensive understanding of the current\nlandscape of VRU safety technologies, identifying areas of progress and areas\nneeding further research and development.", "AI": {"tldr": "A survey of technologies and methodologies to enhance VRU safety, covering communication networks, sensor integration, data processing, simulation, detection algorithms, and behavior prediction.", "motivation": "To address the high proportion of global road accidents involving VRUs by leveraging advanced technologies and datasets.", "method": "Comprehensive survey of state-of-the-art technologies, including communication networks, sensor data fusion, simulation environments, detection algorithms, and behavior prediction methods.", "result": "Identifies current advancements in VRU safety technologies and highlights gaps requiring further research.", "conclusion": "The survey provides a holistic view of VRU safety technologies, emphasizing the need for continued innovation to reduce traffic casualties."}}
{"id": "2405.02377", "pdf": "https://arxiv.org/pdf/2405.02377", "abs": "https://arxiv.org/abs/2405.02377", "authors": ["Luigi Palmieri", "Chiara Boldrini", "Lorenzo Valerio", "Andrea Passarella", "Marco Conti", "J\u00e1nos Kert\u00e9sz"], "title": "Robustness of Decentralised Learning to Nodes and Data Disruption", "categories": ["cs.LG"], "comment": "Supported by the H2020 HumaneAI Net (952026), CHIST-ERA-19-XAI010\n  SAI, PNRR - M4C2 - Investimento 1.3, Partenariato Esteso PE00000013 FAIR,\n  PNRR - M4C2 - Investimento 1.3, Partenariato Esteso PE00000001 RESTART", "summary": "In the vibrant landscape of AI research, decentralised learning is gaining\nmomentum. Decentralised learning allows individual nodes to keep data locally\nwhere they are generated and to share knowledge extracted from local data among\nthemselves through an interactive process of collaborative refinement. This\nparadigm supports scenarios where data cannot leave local nodes due to privacy\nor sovereignty reasons or real-time constraints imposing proximity of models to\nlocations where inference has to be carried out. The distributed nature of\ndecentralised learning implies significant new research challenges with respect\nto centralised learning. Among them, in this paper, we focus on robustness\nissues. Specifically, we study the effect of nodes' disruption on the\ncollective learning process. Assuming a given percentage of \"central\" nodes\ndisappear from the network, we focus on different cases, characterised by (i)\ndifferent distributions of data across nodes and (ii) different times when\ndisruption occurs with respect to the start of the collaborative learning task.\nThrough these configurations, we are able to show the non-trivial interplay\nbetween the properties of the network connecting nodes, the persistence of\nknowledge acquired collectively before disruption or lack thereof, and the\neffect of data availability pre- and post-disruption. Our results show that\ndecentralised learning processes are remarkably robust to network disruption.\nAs long as even minimum amounts of data remain available somewhere in the\nnetwork, the learning process is able to recover from disruptions and achieve\nsignificant classification accuracy. This clearly varies depending on the\nremaining connectivity after disruption, but we show that even nodes that\nremain completely isolated can retain significant knowledge acquired before the\ndisruption.", "AI": {"tldr": "Decentralized learning is robust to network disruptions, maintaining accuracy even with minimal data availability post-disruption.", "motivation": "Address robustness challenges in decentralized learning, focusing on node disruptions and their impact on collective learning.", "method": "Study disruptions by varying data distributions and timing, analyzing network properties and knowledge persistence.", "result": "Decentralized learning recovers from disruptions, achieving significant accuracy with minimal data, even in isolated nodes.", "conclusion": "Decentralized learning is resilient, with knowledge persistence and recovery capabilities under disruptions."}}
{"id": "2506.23897", "pdf": "https://arxiv.org/pdf/2506.23897", "abs": "https://arxiv.org/abs/2506.23897", "authors": ["Longliang Liu", "Miaojie Feng", "Junda Cheng", "Jijun Xiang", "Xuan Zhu", "Xin Yang"], "title": "PriOr-Flow: Enhancing Primitive Panoramic Optical Flow with Orthogonal View", "categories": ["cs.CV"], "comment": "11 pages", "summary": "Panoramic optical flow enables a comprehensive understanding of temporal\ndynamics across wide fields of view. However, severe distortions caused by\nsphere-to-plane projections, such as the equirectangular projection (ERP),\nsignificantly degrade the performance of conventional perspective-based optical\nflow methods, especially in polar regions. To address this challenge, we\npropose PriOr-Flow, a novel dual-branch framework that leverages the\nlow-distortion nature of the orthogonal view to enhance optical flow estimation\nin these regions. Specifically, we introduce the Dual-Cost Collaborative Lookup\n(DCCL) operator, which jointly retrieves correlation information from both the\nprimitive and orthogonal cost volumes, effectively mitigating distortion noise\nduring cost volume construction. Furthermore, our Ortho-Driven Distortion\nCompensation (ODDC) module iteratively refines motion features from both\nbranches, further suppressing polar distortions. Extensive experiments\ndemonstrate that PriOr-Flow is compatible with various perspective-based\niterative optical flow methods and consistently achieves state-of-the-art\nperformance on publicly available panoramic optical flow datasets, setting a\nnew benchmark for wide-field motion estimation. The code is publicly available\nat: https://github.com/longliangLiu/PriOr-Flow.", "AI": {"tldr": "PriOr-Flow is a dual-branch framework improving panoramic optical flow by leveraging orthogonal views to mitigate distortion, achieving state-of-the-art results.", "motivation": "Severe distortions in sphere-to-plane projections degrade optical flow performance, especially in polar regions.", "method": "Uses Dual-Cost Collaborative Lookup (DCCL) and Ortho-Driven Distortion Compensation (ODDC) to refine motion features and reduce distortion.", "result": "Achieves state-of-the-art performance on panoramic optical flow datasets.", "conclusion": "PriOr-Flow effectively addresses distortion challenges in panoramic optical flow, setting a new benchmark."}}
{"id": "2504.03947", "pdf": "https://arxiv.org/pdf/2504.03947", "abs": "https://arxiv.org/abs/2504.03947", "authors": ["Chris Samarinas", "Hamed Zamani"], "title": "Distillation and Refinement of Reasoning in Small Language Models for Document Re-ranking", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "We present a novel approach for training small language models for\nreasoning-intensive document ranking that combines knowledge distillation with\nreinforcement learning optimization. While existing methods often rely on\nexpensive human annotations or large black-box language models, our methodology\nleverages web data and a teacher LLM to automatically generate high-quality\ntraining examples with relevance explanations. By framing document ranking as a\nreinforcement learning problem and incentivizing explicit reasoning\ncapabilities, we train a compact 3B parameter language model that achieves\nstate-of-the-art performance on the BRIGHT benchmark. Our model ranks third on\nthe leaderboard while using substantially fewer parameters than other\napproaches, outperforming models that are over 20 times larger. Through\nextensive experiments, we demonstrate that generating explanations during\ninference, rather than directly predicting relevance scores, enables more\neffective reasoning with smaller language models. The self-supervised nature of\nour method offers a scalable and interpretable solution for modern information\nretrieval systems.", "AI": {"tldr": "A novel method combines knowledge distillation and reinforcement learning to train small language models for document ranking, achieving state-of-the-art performance with fewer parameters.", "motivation": "Existing methods rely on costly human annotations or large models; this work aims for scalable, interpretable solutions using web data and teacher LLMs.", "method": "Leverages web data and a teacher LLM to generate training examples, frames ranking as reinforcement learning, and emphasizes reasoning via explanations.", "result": "A compact 3B parameter model ranks third on BRIGHT, outperforming larger models (20x+ parameters) and demonstrating effective reasoning.", "conclusion": "Generating explanations during inference enhances reasoning in small models, offering scalable and interpretable solutions for information retrieval."}}
{"id": "2406.10197", "pdf": "https://arxiv.org/pdf/2406.10197", "abs": "https://arxiv.org/abs/2406.10197", "authors": ["Harsh Rangwani", "Aishwarya Agarwal", "Kuldeep Kulkarni", "R. Venkatesh Babu", "Srikrishna Karanam"], "title": "Composing Parts for Expressive Object Generation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Project Page Will Be Here: https://rangwani-harsh.github.io/PartCraft", "summary": "Image composition and generation are processes where the artists need control\nover various parts of the generated images. However, the current\nstate-of-the-art generation models, like Stable Diffusion, cannot handle\nfine-grained part-level attributes in the text prompts. Specifically, when\nadditional attribute details are added to the base text prompt, these\ntext-to-image models either generate an image vastly different from the image\ngenerated from the base prompt or ignore the attribute details. To mitigate\nthese issues, we introduce PartComposer, a training-free method that enables\nimage generation based on fine-grained part-level attributes specified for\nobjects in the base text prompt. This allows more control for artists and\nenables novel object compositions by combining distinctive object parts.\nPartComposer first localizes object parts by denoising the object region from a\nspecific diffusion process. This enables each part token to be localized to the\nright region. After obtaining part masks, we run a localized diffusion process\nin each part region based on fine-grained part attributes and combine them to\nproduce the final image. All stages of PartComposer are based on repurposing a\npre-trained diffusion model, which enables it to generalize across domains. We\ndemonstrate the effectiveness of part-level control provided by PartComposer\nthrough qualitative visual examples and quantitative comparisons with\ncontemporary baselines.", "AI": {"tldr": "PartComposer enables fine-grained part-level control in text-to-image generation by localizing and modifying object parts without retraining, improving artistic control and novel compositions.", "motivation": "Current models like Stable Diffusion struggle with fine-grained part-level attribute control in text prompts, often ignoring details or producing inconsistent outputs.", "method": "PartComposer localizes object parts via denoising, applies localized diffusion for part-level attributes, and combines results without retraining the base model.", "result": "The method provides precise part-level control, enabling novel compositions and outperforming baselines in qualitative and quantitative evaluations.", "conclusion": "PartComposer offers a training-free solution for fine-grained part-level image generation, enhancing artistic control and generalization across domains."}}
{"id": "2405.13535", "pdf": "https://arxiv.org/pdf/2405.13535", "abs": "https://arxiv.org/abs/2405.13535", "authors": ["Yinsong Chen", "Samson S. Yu", "Zhong Li", "Chee Peng Lim"], "title": "Addressing the Inconsistency in Bayesian Deep Learning via Generalized Laplace Approximation", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In recent years, inconsistency in Bayesian deep learning has attracted\nsignificant attention. Tempered or generalized posterior distributions are\nfrequently employed as direct and effective solutions. Nonetheless, the\nunderlying mechanisms and the effectiveness of generalized posteriors remain\nactive research topics. In this work, we interpret posterior tempering as a\ncorrection for model misspecification via adjustments to the joint probability,\nand as a recalibration of priors by reducing aleatoric uncertainty. We also\nidentify a unique property of the Laplace approximation: the generalized\nnormalizing constant remains invariant, in contrast to general Bayesian\nlearning, where this constant typically depends on model parameters after\ngeneralization. Leveraging this property, we introduce the generalized Laplace\napproximation, which requires only a simple modification to the Hessian\ncalculation of the regularized loss. This approach provides a flexible and\nscalable framework for high-quality posterior inference. We evaluate the\nproposed method on state-of-the-art neural networks and real-world datasets,\ndemonstrating that the generalized Laplace approximation enhances predictive\nperformance.", "AI": {"tldr": "The paper explores posterior tempering in Bayesian deep learning, interpreting it as a correction for model misspecification and prior recalibration. It introduces the generalized Laplace approximation, which maintains an invariant normalizing constant and improves predictive performance.", "motivation": "Addressing inconsistency and understanding the mechanisms of generalized posteriors in Bayesian deep learning.", "method": "Proposes the generalized Laplace approximation, modifying Hessian calculations for scalable posterior inference.", "result": "Demonstrates enhanced predictive performance on state-of-the-art neural networks and real-world datasets.", "conclusion": "The generalized Laplace approximation offers a flexible, scalable solution for high-quality posterior inference in Bayesian deep learning."}}
{"id": "2506.23916", "pdf": "https://arxiv.org/pdf/2506.23916", "abs": "https://arxiv.org/abs/2506.23916", "authors": ["Radhika Juglan", "Marta Ligero", "Zunamys I. Carrero", "Asier Rabasco", "Tim Lenz", "Leo Misera", "Gregory Patrick Veldhuizen", "Paul Kuntke", "Hagen H. Kitzler", "Sven Nebelung", "Daniel Truhn", "Jakob Nikolas Kather"], "title": "Three-dimensional end-to-end deep learning for brain MRI analysis", "categories": ["cs.CV"], "comment": null, "summary": "Deep learning (DL) methods are increasingly outperforming classical\napproaches in brain imaging, yet their generalizability across diverse imaging\ncohorts remains inadequately assessed. As age and sex are key neurobiological\nmarkers in clinical neuroscience, influencing brain structure and disease risk,\nthis study evaluates three of the existing three-dimensional architectures,\nnamely Simple Fully Connected Network (SFCN), DenseNet, and Shifted Window\n(Swin) Transformers, for age and sex prediction using T1-weighted MRI from four\nindependent cohorts: UK Biobank (UKB, n=47,390), Dallas Lifespan Brain Study\n(DLBS, n=132), Parkinson's Progression Markers Initiative (PPMI, n=108 healthy\ncontrols), and Information eXtraction from Images (IXI, n=319). We found that\nSFCN consistently outperformed more complex architectures with AUC of 1.00\n[1.00-1.00] in UKB (internal test set) and 0.85-0.91 in external test sets for\nsex classification. For the age prediction task, SFCN demonstrated a mean\nabsolute error (MAE) of 2.66 (r=0.89) in UKB and 4.98-5.81 (r=0.55-0.70) across\nexternal datasets. Pairwise DeLong and Wilcoxon signed-rank tests with\nBonferroni corrections confirmed SFCN's superiority over Swin Transformer\nacross most cohorts (p<0.017, for three comparisons). Explainability analysis\nfurther demonstrates the regional consistency of model attention across cohorts\nand specific to each task. Our findings reveal that simpler convolutional\nnetworks outperform the denser and more complex attention-based DL\narchitectures in brain image analysis by demonstrating better generalizability\nacross different datasets.", "AI": {"tldr": "Simpler convolutional networks (SFCN) outperform complex architectures (DenseNet, Swin Transformers) in age and sex prediction from brain MRI, showing better generalizability across diverse cohorts.", "motivation": "Assess generalizability of deep learning methods in brain imaging, focusing on age and sex prediction, given their neurobiological significance.", "method": "Evaluated three 3D architectures (SFCN, DenseNet, Swin Transformers) using T1-weighted MRI from four cohorts (UKB, DLBS, PPMI, IXI).", "result": "SFCN achieved superior performance (AUC 1.00 for sex, MAE 2.66 for age in UKB) and better generalizability in external datasets.", "conclusion": "Simpler networks like SFCN are more effective and generalizable for brain image analysis than complex architectures."}}
{"id": "2505.08842", "pdf": "https://arxiv.org/pdf/2505.08842", "abs": "https://arxiv.org/abs/2505.08842", "authors": ["Zekun Wu", "Seonglae Cho", "Umar Mohammed", "Cristian Munoz", "Kleyton Costa", "Xin Guan", "Theo King", "Ze Wang", "Emre Kazim", "Adriano Koshiyama"], "title": "LibVulnWatch: A Deep Assessment Agent System and Leaderboard for Uncovering Hidden Vulnerabilities in Open-Source AI Libraries", "categories": ["cs.CR", "cs.CL"], "comment": "ACL 2025 Student Research Workshop and ICML 2025 TAIG Workshop", "summary": "Open-source AI libraries are foundational to modern AI systems, yet they\npresent significant, underexamined risks spanning security, licensing,\nmaintenance, supply chain integrity, and regulatory compliance. We introduce\nLibVulnWatch, a system that leverages recent advances in large language models\nand agentic workflows to perform deep, evidence-based evaluations of these\nlibraries. Built on a graph-based orchestration of specialized agents, the\nframework extracts, verifies, and quantifies risk using information from\nrepositories, documentation, and vulnerability databases. LibVulnWatch produces\nreproducible, governance-aligned scores across five critical domains,\npublishing results to a public leaderboard for ongoing ecosystem monitoring.\nApplied to 20 widely used libraries, including ML frameworks, LLM inference\nengines, and agent orchestration tools, our approach covers up to 88% of\nOpenSSF Scorecard checks while surfacing up to 19 additional risks per library,\nsuch as critical RCE vulnerabilities, missing SBOMs, and regulatory gaps. By\nintegrating advanced language technologies with the practical demands of\nsoftware risk assessment, this work demonstrates a scalable, transparent\nmechanism for continuous supply chain evaluation and informed library\nselection.", "AI": {"tldr": "LibVulnWatch is a system using AI and agentic workflows to evaluate risks in open-source AI libraries, covering security, licensing, and compliance, and providing reproducible risk scores.", "motivation": "Open-source AI libraries pose underexamined risks in security, licensing, and compliance, necessitating a scalable evaluation method.", "method": "LibVulnWatch employs large language models and agentic workflows to extract, verify, and quantify risks from repositories, documentation, and vulnerability databases.", "result": "The system evaluated 20 libraries, covering 88% of OpenSSF Scorecard checks and identifying up to 19 additional risks per library.", "conclusion": "LibVulnWatch offers a scalable, transparent solution for continuous risk assessment and informed library selection."}}
{"id": "2407.01570", "pdf": "https://arxiv.org/pdf/2407.01570", "abs": "https://arxiv.org/abs/2407.01570", "authors": ["Manuel Serra Nunes", "Atabak Dehban", "Yiannis Demiris", "Jos\u00e9 Santos-Victor"], "title": "Ego-Foresight: Self-supervised Learning of Agent-Aware Representations for Improved RL", "categories": ["cs.RO", "cs.AI"], "comment": "13 pages, 8 figures, conference", "summary": "Despite the significant advancements in Deep Reinforcement Learning (RL)\nobserved in the last decade, the amount of training experience necessary to\nlearn effective policies remains one of the primary concerns both in simulated\nand real environments. Looking to solve this issue, previous work has shown\nthat improved training efficiency can be achieved by separately modeling agent\nand environment, but usually requiring a supervisory agent mask.\n  In contrast to RL, humans can perfect a new skill from a small number of\ntrials and in most cases do so without a supervisory signal, making\nneuroscientific studies of human development a valuable source of inspiration\nfor RL. In particular, we explore the idea of motor prediction, which states\nthat humans develop an internal model of themselves and of the consequences\nthat their motor commands have on the immediate sensory inputs. Our insight is\nthat the movement of the agent provides a cue that allows the duality between\nagent and environment to be learned.\n  To instantiate this idea, we present Ego-Foresight, a self-supervised method\nfor disentangling agent and environment based on motion and prediction. Our\nmain finding is self-supervised agent-awareness by visuomotor prediction of the\nagent improves sample-efficiency and performance of the underlying RL\nalgorithm.\n  To test our approach, we first study its ability to visually predict agent\nmovement irrespective of the environment, in simulated and real-world robotic\ndata. Then, we integrate Ego-Foresight with a model-free RL algorithm to solve\nsimulated robotic tasks, showing that self-supervised agent-awareness can\nimprove sample-efficiency and performance in RL.", "AI": {"tldr": "Ego-Foresight, a self-supervised method, improves RL sample-efficiency by learning agent-environment duality through visuomotor prediction, inspired by human motor prediction.", "motivation": "Addressing the high training experience requirement in RL by drawing inspiration from human skill acquisition, which relies on internal modeling of motor commands and sensory feedback.", "method": "Proposes Ego-Foresight, a self-supervised approach using motion and prediction to disentangle agent and environment, enhancing RL via visuomotor prediction.", "result": "Demonstrates improved sample-efficiency and performance in RL tasks, validated in simulated and real-world robotic scenarios.", "conclusion": "Self-supervised agent-awareness via visuomotor prediction effectively enhances RL, bridging insights from human neuroscience."}}
{"id": "2405.13692", "pdf": "https://arxiv.org/pdf/2405.13692", "abs": "https://arxiv.org/abs/2405.13692", "authors": ["Sergei Krutikov", "Bulat Khaertdinov", "Rodion Kiriukhin", "Shubham Agrawal", "Mozhdeh Ariannezhad", "Kees Jan De Vries"], "title": "Challenging Gradient Boosted Decision Trees with Tabular Transformers for Fraud Detection at Booking.com", "categories": ["cs.LG"], "comment": "Submitted to CIKM'25, Applied Research track", "summary": "Transformer-based neural networks, empowered by Self-Supervised Learning\n(SSL), have demonstrated unprecedented performance across various domains.\nHowever, related literature suggests that tabular Transformers may struggle to\noutperform classical Machine Learning algorithms, such as Gradient Boosted\nDecision Trees (GBDT). In this paper, we aim to challenge GBDTs with tabular\nTransformers on a typical task faced in e-commerce, namely fraud detection. Our\nstudy is additionally motivated by the problem of selection bias, often\noccurring in real-life fraud detection systems. It is caused by the production\nsystem affecting which subset of traffic becomes labeled. This issue is\ntypically addressed by sampling randomly a small part of the whole production\ndata, referred to as a Control Group. This subset follows a target distribution\nof production data and therefore is usually preferred for training\nclassification models with standard ML algorithms. Our methodology leverages\nthe capabilities of Transformers to learn transferable representations using\nall available data by means of SSL, giving it an advantage over classical\nmethods. Furthermore, we conduct large-scale experiments, pre-training tabular\nTransformers on vast amounts of data instances and fine-tuning them on smaller\ntarget datasets. The proposed approach outperforms heavily tuned GBDTs by a\nconsiderable margin of the Average Precision (AP) score in offline evaluations.\nFinally, we report the results of an online A/B experiment. Experimental\nresults confirm the superiority of tabular Transformers compared to GBDTs in\nproduction, demonstrated by a statistically significant improvement in our\nbusiness metric.", "AI": {"tldr": "Tabular Transformers, enhanced by SSL, outperform GBDTs in fraud detection tasks, addressing selection bias and leveraging large-scale data for superior results.", "motivation": "To challenge GBDTs with tabular Transformers in fraud detection, especially considering selection bias in real-life systems.", "method": "Leverage SSL for transferable representations, pre-train on large datasets, and fine-tune on smaller target datasets.", "result": "Outperforms GBDTs in offline evaluations (higher AP score) and online A/B tests (significant business metric improvement).", "conclusion": "Tabular Transformers are superior to GBDTs in fraud detection, validated by both offline and online experiments."}}
{"id": "2506.23918", "pdf": "https://arxiv.org/pdf/2506.23918", "abs": "https://arxiv.org/abs/2506.23918", "authors": ["Zhaochen Su", "Peng Xia", "Hangyu Guo", "Zhenhua Liu", "Yan Ma", "Xiaoye Qu", "Jiaqi Liu", "Yanshu Li", "Kaide Zeng", "Zhengyuan Yang", "Linjie Li", "Yu Cheng", "Heng Ji", "Junxian He", "Yi R.", "Fung"], "title": "Thinking with Images for Multimodal Reasoning: Foundations, Methods, and Future Frontiers", "categories": ["cs.CV"], "comment": "We maintain a real-time GitHub repository tracking progress at:\n  https://github.com/zhaochen0110/Awesome_Think_With_Images", "summary": "Recent progress in multimodal reasoning has been significantly advanced by\ntextual Chain-of-Thought (CoT), a paradigm where models conduct reasoning\nwithin language. This text-centric approach, however, treats vision as a\nstatic, initial context, creating a fundamental \"semantic gap\" between rich\nperceptual data and discrete symbolic thought. Human cognition often transcends\nlanguage, utilizing vision as a dynamic mental sketchpad. A similar evolution\nis now unfolding in AI, marking a fundamental paradigm shift from models that\nmerely think about images to those that can truly think with images. This\nemerging paradigm is characterized by models leveraging visual information as\nintermediate steps in their thought process, transforming vision from a passive\ninput into a dynamic, manipulable cognitive workspace. In this survey, we chart\nthis evolution of intelligence along a trajectory of increasing cognitive\nautonomy, which unfolds across three key stages: from external tool\nexploration, through programmatic manipulation, to intrinsic imagination. To\nstructure this rapidly evolving field, our survey makes four key contributions.\n(1) We establish the foundational principles of the think with image paradigm\nand its three-stage framework. (2) We provide a comprehensive review of the\ncore methods that characterize each stage of this roadmap. (3) We analyze the\ncritical landscape of evaluation benchmarks and transformative applications.\n(4) We identify significant challenges and outline promising future directions.\nBy providing this structured overview, we aim to offer a clear roadmap for\nfuture research towards more powerful and human-aligned multimodal AI.", "AI": {"tldr": "The paper surveys the shift from text-centric multimodal reasoning to models that dynamically 'think with images,' proposing a three-stage framework and reviewing methods, benchmarks, and challenges.", "motivation": "To address the 'semantic gap' between static visual inputs and symbolic reasoning by exploring how AI can dynamically use vision as a cognitive workspace, akin to human cognition.", "method": "The survey outlines a three-stage evolution (external tool exploration, programmatic manipulation, intrinsic imagination) and reviews core methods, benchmarks, and applications.", "result": "A structured framework for 'thinking with images' is established, alongside insights into current methods, evaluations, and applications.", "conclusion": "The paper provides a roadmap for advancing multimodal AI by integrating dynamic visual reasoning, highlighting challenges and future directions."}}
{"id": "2506.10314", "pdf": "https://arxiv.org/pdf/2506.10314", "abs": "https://arxiv.org/abs/2506.10314", "authors": ["Luc Raszewski", "Christine De Kock"], "title": "Detecting Sockpuppetry on Wikipedia Using Meta-Learning", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted to ACL 2025", "summary": "Malicious sockpuppet detection on Wikipedia is critical to preserving access\nto reliable information on the internet and preventing the spread of\ndisinformation. Prior machine learning approaches rely on stylistic and\nmeta-data features, but do not prioritise adaptability to author-specific\nbehaviours. As a result, they struggle to effectively model the behaviour of\nspecific sockpuppet-groups, especially when text data is limited. To address\nthis, we propose the application of meta-learning, a machine learning technique\ndesigned to improve performance in data-scarce settings by training models\nacross multiple tasks. Meta-learning optimises a model for rapid adaptation to\nthe writing style of a new sockpuppet-group. Our results show that\nmeta-learning significantly enhances the precision of predictions compared to\npre-trained models, marking an advancement in combating sockpuppetry on open\nediting platforms. We release a new dataset of sockpuppet investigations to\nfoster future research in both sockpuppetry and meta-learning fields.", "AI": {"tldr": "Meta-learning improves sockpuppet detection on Wikipedia by adapting to author-specific behaviors, outperforming pre-trained models in data-scarce settings.", "motivation": "To enhance sockpuppet detection by addressing limitations of prior methods, which lack adaptability to specific author behaviors and struggle with limited text data.", "method": "Proposes meta-learning to train models across multiple tasks, enabling rapid adaptation to new sockpuppet-group writing styles.", "result": "Meta-learning significantly boosts prediction precision compared to pre-trained models.", "conclusion": "The approach advances sockpuppetry detection and introduces a new dataset to support future research in meta-learning and sockpuppetry."}}
{"id": "2407.03146", "pdf": "https://arxiv.org/pdf/2407.03146", "abs": "https://arxiv.org/abs/2407.03146", "authors": ["Yunpeng Jiang", "Yutong Ban", "Paul Weng"], "title": "Understanding and Reducing the Class-Dependent Effects of Data Augmentation with A Two-Player Game Approach", "categories": ["cs.CY", "cs.AI", "cs.CV", "cs.GT", "cs.LG"], "comment": "Published in Transactions on Machine Learning Research (06/2025)", "summary": "Data augmentation is widely applied and has shown its benefits in different\nmachine learning tasks. However, as recently observed, it may have an unfair\neffect in multi-class classification. While data augmentation generally\nimproves the overall performance (and therefore is beneficial for many\nclasses), it can actually be detrimental for other classes, which can be\nproblematic in some application domains. In this paper, to counteract this\nphenomenon, we propose CLAM, a CLAss-dependent Multiplicative-weights method.\nTo derive it, we first formulate the training of a classifier as a non-linear\noptimization problem that aims at simultaneously maximizing the individual\nclass performances and balancing them. By rewriting this optimization problem\nas an adversarial two-player game, we propose a novel multiplicative weight\nalgorithm, for which we prove the convergence. Interestingly, our formulation\nalso reveals that the class-dependent effects of data augmentation is not due\nto data augmentation only, but is in fact a general phenomenon. Our empirical\nresults over six datasets demonstrate that the performance of learned\nclassifiers is indeed more fairly distributed over classes, with only limited\nimpact on the average accuracy.", "AI": {"tldr": "CLAM addresses unfair class performance in data augmentation by introducing a class-dependent multiplicative-weights method, balancing individual class improvements without significantly affecting average accuracy.", "motivation": "Data augmentation can unfairly benefit some classes while harming others, which is problematic in multi-class classification.", "method": "Formulates classifier training as a non-linear optimization problem, rewrites it as an adversarial game, and proposes a multiplicative weight algorithm with proven convergence.", "result": "Empirical results show more balanced class performance with limited impact on average accuracy across six datasets.", "conclusion": "CLAM effectively mitigates unfair class effects in data augmentation, demonstrating broader applicability beyond just augmentation scenarios."}}
{"id": "2405.15328", "pdf": "https://arxiv.org/pdf/2405.15328", "abs": "https://arxiv.org/abs/2405.15328", "authors": ["Yash Sinha", "Murari Mandal", "Mohan Kankanhalli"], "title": "Multi-Modal Recommendation Unlearning for Legal, Licensing, and Modality Constraints", "categories": ["cs.LG", "cs.IR", "H.3.3; H.5.1; I.2.6; K.4.1"], "comment": "Extended Version, Accepted at AAAI 2025. 17 pages, 4 figures and 9\n  tables", "summary": "User data spread across multiple modalities has popularized multi-modal\nrecommender systems (MMRS). They recommend diverse content such as products,\nsocial media posts, TikTok reels, etc., based on a user-item interaction graph.\nWith rising data privacy demands, recent methods propose unlearning private\nuser data from uni-modal recommender systems (RS). However, methods for\nunlearning item data related to outdated user preferences, revoked licenses,\nand legally requested removals are still largely unexplored.\n  Previous RS unlearning methods are unsuitable for MMRS due to the\nincompatibility of their matrix-based representation with the multi-modal\nuser-item interaction graph. Moreover, their data partitioning step degrades\nperformance on each shard due to poor data heterogeneity and requires costly\nperformance aggregation across shards.\n  This paper introduces MMRecUn, the first approach known to us for unlearning\nin MMRS and unlearning item data. Given a trained RS model, MMRecUn employs a\nnovel Reverse Bayesian Personalized Ranking (BPR) objective to enable the model\nto forget marked data. The reverse BPR attenuates the impact of user-item\ninteractions within the forget set, while the forward BPR reinforces the\nsignificance of user-item interactions within the retain set. Our experiments\ndemonstrate that MMRecUn outperforms baseline methods across various unlearning\nrequests when evaluated on benchmark MMRS datasets. MMRecUn achieves recall\nperformance improvements of up to 49.85% compared to baseline methods and is up\nto 1.3x faster than the Gold model, which is trained on retain set from\nscratch. MMRecUn offers significant advantages, including superiority in\nremoving target interactions, preserving retained interactions, and zero\noverhead costs compared to previous methods.\n  Code: https://github.com/MachineUnlearn/MMRecUN\n  Extended version: arXiv:2405.15328", "AI": {"tldr": "MMRecUn is a novel method for unlearning item data in multi-modal recommender systems (MMRS), outperforming baselines with improved recall and speed.", "motivation": "Address the gap in unlearning methods for MMRS, particularly for item data related to outdated preferences or legal removals, as existing uni-modal methods are incompatible.", "method": "Uses a Reverse Bayesian Personalized Ranking (BPR) objective to forget marked data while reinforcing retain set interactions, avoiding costly data partitioning.", "result": "Achieves up to 49.85% recall improvement and 1.3x faster performance than baselines, with zero overhead costs.", "conclusion": "MMRecUn effectively removes target interactions, preserves retained ones, and is efficient, making it a superior solution for MMRS unlearning."}}
{"id": "2506.23963", "pdf": "https://arxiv.org/pdf/2506.23963", "abs": "https://arxiv.org/abs/2506.23963", "authors": ["Vannkinh Nom", "Souhail Bakkali", "Muhammad Muzzamil Luqman", "Mickael Coustaty", "Jean-Marc Ogier"], "title": "Evaluating the Impact of Khmer Font Types on Text Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Text recognition is significantly influenced by font types, especially for\ncomplex scripts like Khmer. The variety of Khmer fonts, each with its unique\ncharacter structure, presents challenges for optical character recognition\n(OCR) systems. In this study, we evaluate the impact of 19 randomly selected\nKhmer font types on text recognition accuracy using Pytesseract. The fonts\ninclude Angkor, Battambang, Bayon, Bokor, Chenla, Dangrek, Freehand, Kh Kompong\nChhnang, Kh SN Kampongsom, Khmer, Khmer CN Stueng Songke, Khmer Savuth Pen,\nMetal, Moul, Odor MeanChey, Preah Vihear, Siemreap, Sithi Manuss, and iSeth\nFirst. Our comparison of OCR performance across these fonts reveals that Khmer,\nOdor MeanChey, Siemreap, Sithi Manuss, and Battambang achieve high accuracy,\nwhile iSeth First, Bayon, and Dangrek perform poorly. This study underscores\nthe critical importance of font selection in optimizing Khmer text recognition\nand provides valuable insights for developing more robust OCR systems.", "AI": {"tldr": "The study evaluates how 19 Khmer fonts impact OCR accuracy, identifying high- and low-performing fonts for Khmer text recognition.", "motivation": "Khmer script's font variety complicates OCR, necessitating an evaluation of font impact on recognition accuracy.", "method": "Tested 19 Khmer fonts using Pytesseract to measure OCR performance.", "result": "High accuracy: Khmer, Odor MeanChey, Siemreap, Sithi Manuss, Battambang. Low accuracy: iSeth First, Bayon, Dangrek.", "conclusion": "Font choice is crucial for Khmer OCR optimization, aiding in developing better OCR systems."}}
{"id": "2506.12484", "pdf": "https://arxiv.org/pdf/2506.12484", "abs": "https://arxiv.org/abs/2506.12484", "authors": ["Filip Sondej", "Yushi Yang", "Miko\u0142aj Kniejski", "Marcel Windys"], "title": "Robust LLM Unlearning with MUDMAN: Meta-Unlearning with Disruption Masking And Normalization", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Language models can retain dangerous knowledge and skills even after\nextensive safety fine-tuning, posing both misuse and misalignment risks. Recent\nstudies show that even specialized unlearning methods can be easily reversed.\nTo address this, we systematically evaluate many existing and novel components\nof unlearning methods and identify ones crucial for irreversible unlearning.\n  We introduce Disruption Masking, a technique in which we only allow updating\nweights, where the signs of the unlearning gradient and the retaining gradient\nare the same. This ensures all updates are non-disruptive.\n  Additionally, we identify the need for normalizing the unlearning gradients,\nand also confirm the usefulness of meta-learning. We combine these insights\ninto MUDMAN (Meta-Unlearning with Disruption Masking and Normalization) and\nvalidate its effectiveness at preventing the recovery of dangerous\ncapabilities. MUDMAN outperforms the prior TAR method by 40%, setting a new\nstate-of-the-art for robust unlearning.", "AI": {"tldr": "MUDMAN introduces Disruption Masking and normalization for irreversible unlearning, outperforming prior methods by 40%.", "motivation": "Addressing the risks of language models retaining dangerous knowledge despite safety fine-tuning.", "method": "Disruption Masking, gradient normalization, and meta-learning combined in MUDMAN.", "result": "MUDMAN prevents recovery of dangerous capabilities, outperforming TAR by 40%.", "conclusion": "MUDMAN sets a new state-of-the-art for robust unlearning."}}
{"id": "2407.08906", "pdf": "https://arxiv.org/pdf/2407.08906", "abs": "https://arxiv.org/abs/2407.08906", "authors": ["Hui Xian Grace Lim", "Xuanming Cui", "Yogesh S Rawat", "Ser-Nam Lim"], "title": "AirSketch: Generative Motion to Sketch", "categories": ["cs.CV", "cs.AI", "cs.GR"], "comment": null, "summary": "Illustration is a fundamental mode of human expression and communication.\nCertain types of motion that accompany speech can provide this illustrative\nmode of communication. While Augmented and Virtual Reality technologies (AR/VR)\nhave introduced tools for producing drawings with hand motions (air drawing),\nthey typically require costly hardware and additional digital markers, thereby\nlimiting their accessibility and portability. Furthermore, air drawing demands\nconsiderable skill to achieve aesthetic results. To address these challenges,\nwe introduce the concept of AirSketch, aimed at generating faithful and\nvisually coherent sketches directly from hand motions, eliminating the need for\ncomplicated headsets or markers. We devise a simple augmentation-based\nself-supervised training procedure, enabling a controllable image diffusion\nmodel to learn to translate from highly noisy hand tracking images to clean,\naesthetically pleasing sketches, while preserving the essential visual cues\nfrom the original tracking data. We present two air drawing datasets to study\nthis problem. Our findings demonstrate that beyond producing photo-realistic\nimages from precise spatial inputs, controllable image diffusion can\neffectively produce a refined, clear sketch from a noisy input. Our work serves\nas an initial step towards marker-less air drawing and reveals distinct\napplications of controllable diffusion models to AirSketch and AR/VR in\ngeneral.", "AI": {"tldr": "AirSketch enables marker-less air drawing by translating noisy hand motions into clean sketches using a self-supervised diffusion model, eliminating the need for costly AR/VR hardware.", "motivation": "Current AR/VR air drawing tools are expensive, require markers, and demand skill for aesthetic results, limiting accessibility.", "method": "A self-supervised training procedure with a controllable image diffusion model translates noisy hand tracking images into clean sketches.", "result": "The model effectively produces refined sketches from noisy inputs, demonstrating the potential of controllable diffusion models for air drawing.", "conclusion": "AirSketch advances marker-less air drawing and highlights broader applications of controllable diffusion models in AR/VR."}}
{"id": "2407.02856", "pdf": "https://arxiv.org/pdf/2407.02856", "abs": "https://arxiv.org/abs/2407.02856", "authors": ["Adrian Pekar", "Richard Jozsa"], "title": "Early-Stage Anomaly Detection: A Study of Model Performance on Complete vs. Partial Flows", "categories": ["cs.LG", "cs.CR"], "comment": "accepted for presentation at WTMC 2025", "summary": "This study investigates the efficacy of machine learning models in network\nsecurity threat detection through the critical lens of partial versus complete\nflow information, addressing a common gap between research settings and\nreal-time operational needs. We systematically evaluate how a standard\nbenchmark model, Random Forest, performs under varying training and testing\nconditions (complete/complete, partial/partial, complete/partial), quantifying\nthe performance impact when dealing with the incomplete data typical in\nreal-time environments. Our findings demonstrate a significant performance\ndifference, with precision and recall dropping by up to 30% under certain\nconditions when models trained on complete flows are tested against partial\nflows. The study also reveals that, for the evaluated dataset and model, a\nminimum threshold around 7 packets in the test set appears necessary for\nmaintaining reliable detection rates, providing valuable, quantified insights\nfor developing more realistic real-time detection strategies.", "AI": {"tldr": "Study shows machine learning models (Random Forest) for network security threat detection perform worse with partial flow data, highlighting a 30% drop in precision/recall and a 7-packet threshold for reliable detection.", "motivation": "Address the gap between research settings (complete flow data) and real-time operational needs (partial flow data) in network security threat detection.", "method": "Systematically evaluate Random Forest performance under varying training/testing conditions (complete/complete, partial/partial, complete/partial) with incomplete data.", "result": "Precision and recall drop by up to 30% when models trained on complete flows are tested on partial flows. A 7-packet threshold is needed for reliable detection.", "conclusion": "Quantified insights for realistic real-time detection strategies, emphasizing the need to account for partial data in model training."}}
{"id": "2506.23972", "pdf": "https://arxiv.org/pdf/2506.23972", "abs": "https://arxiv.org/abs/2506.23972", "authors": ["Boyue Xu", "Ruichao Hou", "Tongwei Ren", "Gangshan Wu"], "title": "Visual and Memory Dual Adapter for Multi-Modal Object Tracking", "categories": ["cs.CV"], "comment": null, "summary": "Prompt-learning-based multi-modal trackers have achieved promising progress\nby employing lightweight visual adapters to incorporate auxiliary modality\nfeatures into frozen foundation models. However, existing approaches often\nstruggle to learn reliable prompts due to limited exploitation of critical cues\nacross frequency and temporal domains. In this paper, we propose a novel visual\nand memory dual adapter (VMDA) to construct more robust and discriminative\nrepresentations for multi-modal tracking. Specifically, we develop a simple but\neffective visual adapter that adaptively transfers discriminative cues from\nauxiliary modality to dominant modality by jointly modeling the frequency,\nspatial, and channel-wise features. Additionally, we design the memory adapter\ninspired by the human memory mechanism, which stores global temporal cues and\nperforms dynamic update and retrieval operations to ensure the consistent\npropagation of reliable temporal information across video sequences. Extensive\nexperiments demonstrate that our method achieves state-of-the-art performance\non the various multi-modal tracking tasks, including RGB-Thermal, RGB-Depth,\nand RGB-Event tracking. Code and models are available at\nhttps://github.com/xuboyue1999/mmtrack.git.", "AI": {"tldr": "A novel visual and memory dual adapter (VMDA) is proposed to enhance multi-modal tracking by leveraging frequency, spatial, and temporal cues, outperforming existing methods.", "motivation": "Existing prompt-learning-based multi-modal trackers fail to fully exploit critical cues across frequency and temporal domains, limiting their robustness.", "method": "VMDA combines a visual adapter for adaptive feature transfer and a memory adapter for temporal cue propagation, improving representation learning.", "result": "The method achieves state-of-the-art performance in RGB-Thermal, RGB-Depth, and RGB-Event tracking tasks.", "conclusion": "VMDA effectively addresses limitations in current approaches, offering a robust solution for multi-modal tracking."}}
{"id": "2506.19882", "pdf": "https://arxiv.org/pdf/2506.19882", "abs": "https://arxiv.org/abs/2506.19882", "authors": ["Rylan Schaeffer", "Joshua Kazdan", "Yegor Denisov-Blanch", "Brando Miranda", "Matthias Gerstgrasser", "Susan Zhang", "Andreas Haupt", "Isha Gupta", "Elyas Obbad", "Jesse Dodge", "Jessica Zosa Forde", "Koustuv Sinha", "Francesco Orabona", "Sanmi Koyejo", "David Donoho"], "title": "Position: Machine Learning Conferences Should Establish a \"Refutations and Critiques\" Track", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "Science progresses by iteratively advancing and correcting humanity's\nunderstanding of the world. In machine learning (ML) research, rapid\nadvancements have led to an explosion of publications, but have also led to\nmisleading, incorrect, flawed or perhaps even fraudulent studies being accepted\nand sometimes highlighted at ML conferences due to the fallibility of peer\nreview. While such mistakes are understandable, ML conferences do not offer\nrobust processes to help the field systematically correct when such errors are\nmade. This position paper argues that ML conferences should establish a\ndedicated \"Refutations and Critiques\" (R&C) Track. This R&C Track would provide\na high-profile, reputable platform to support vital research that critically\nchallenges prior research, thereby fostering a dynamic self-correcting research\necosystem. We discuss key considerations including track design, review\nprinciples, potential pitfalls, and provide an illustrative example submission\nconcerning a recent ICLR 2025 Oral. We conclude that ML conferences should\ncreate official, reputable mechanisms to help ML research self-correct.", "AI": {"tldr": "The paper proposes a \"Refutations and Critiques\" (R&C) Track at ML conferences to systematically correct errors and flawed studies in the field.", "motivation": "Rapid advancements in ML research have led to flawed or incorrect studies being accepted due to peer review fallibility. Current conferences lack robust correction mechanisms.", "method": "The paper suggests designing an R&C Track with specific review principles, addressing potential pitfalls, and provides an example submission.", "result": "The proposed R&C Track would foster a self-correcting research ecosystem by critically challenging prior work.", "conclusion": "ML conferences should establish official mechanisms like the R&C Track to improve research integrity and self-correction."}}
{"id": "2408.15495", "pdf": "https://arxiv.org/pdf/2408.15495", "abs": "https://arxiv.org/abs/2408.15495", "authors": ["Liu Ziyin", "Yizhou Xu", "Isaac Chuang"], "title": "Remove Symmetries to Control Model Expressivity and Improve Optimization", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "preprint", "summary": "When symmetry is present in the loss function, the model is likely to be\ntrapped in a low-capacity state that is sometimes known as a \"collapse\". Being\ntrapped in these low-capacity states can be a major obstacle to training across\nmany scenarios where deep learning technology is applied. We first prove two\nconcrete mechanisms through which symmetries lead to reduced capacities and\nignored features during training and inference. We then propose a simple and\ntheoretically justified algorithm, syre, to remove almost all symmetry-induced\nlow-capacity states in neural networks. When this type of entrapment is\nespecially a concern, removing symmetries with the proposed method is shown to\ncorrelate well with improved optimization or performance. A remarkable merit of\nthe proposed method is that it is model-agnostic and does not require any\nknowledge of the symmetry.", "AI": {"tldr": "The paper addresses how symmetry in loss functions can trap models in low-capacity states, proposes a method (syre) to mitigate this, and demonstrates its effectiveness.", "motivation": "Symmetry in loss functions can lead to models being trapped in low-capacity states, hindering training and performance in deep learning applications.", "method": "The authors propose syre, a simple, model-agnostic algorithm to remove symmetry-induced low-capacity states without prior knowledge of the symmetry.", "result": "Removing symmetries with syre correlates with improved optimization and performance, especially in cases where entrapment is a concern.", "conclusion": "The syre method effectively mitigates symmetry-induced low-capacity states, enhancing model performance without requiring symmetry knowledge."}}
{"id": "2409.09111", "pdf": "https://arxiv.org/pdf/2409.09111", "abs": "https://arxiv.org/abs/2409.09111", "authors": ["Qitian Wu", "David Wipf", "Junchi Yan"], "title": "From Diffusion to Transformers: A Unified Framework for Neural Message Passing", "categories": ["cs.LG", "cs.AI"], "comment": "Published in Journal of Machine Learning Research (JMLR). Extended\n  from DIFFormer in ICLR 2023", "summary": "Learning representations for structured data with certain geometries (e.g.,\nobserved or unobserved) is a fundamental challenge, wherein message passing\nneural networks (MPNNs) have become a de facto class of model solutions. In\nthis paper, inspired by physical systems, we propose an energy-constrained\ndiffusion model, which combines the inductive bias of diffusion on manifolds\nwith layer-wise constraints of energy minimization. We identify that the\ndiffusion operators have a one-to-one correspondence with the energy functions\nimplicitly descended by the diffusion process, and the finite-difference\niteration for solving the energy-constrained diffusion system induces the\npropagation layers of various types of MPNNs operating on observed or latent\nstructures. This leads to a unified mathematical framework for common neural\narchitectures whose computational flows can be cast as message passing (or its\nspecial case), including MLPs, GNNs, and Transformers. Building on these\ninsights, we devise a new class of neural message passing models, dubbed\ndiffusion-inspired Transformers, whose global attention layers are derived from\nthe principled energy-constrained diffusion framework. Across diverse datasets\nranging from real-world networks to images, texts, and physical particles, we\ndemonstrate that the new model achieves promising performance in scenarios\nwhere the data structures are observed (as a graph), partially observed, or\nentirely unobserved.", "AI": {"tldr": "The paper proposes an energy-constrained diffusion model for learning structured data representations, unifying MPNNs under a mathematical framework and introducing diffusion-inspired Transformers.", "motivation": "To address the challenge of learning representations for structured data with geometries, leveraging insights from physical systems.", "method": "Combines diffusion on manifolds with energy minimization constraints, linking diffusion operators to energy functions and deriving MPNN propagation layers.", "result": "Introduces diffusion-inspired Transformers, achieving strong performance across diverse datasets with observed, partially observed, or unobserved structures.", "conclusion": "The framework unifies common neural architectures and offers a principled approach for message-passing models, validated by empirical success."}}
{"id": "2506.23975", "pdf": "https://arxiv.org/pdf/2506.23975", "abs": "https://arxiv.org/abs/2506.23975", "authors": ["Yuliia Kaidashova", "Bettina Finzel", "Ute Schmid"], "title": "Toward Simple and Robust Contrastive Explanations for Image Classification by Leveraging Instance Similarity and Concept Relevance", "categories": ["cs.CV", "68T07", "I.2; I.4"], "comment": "17 pages, 6 figures, KI2025 - 48th German Conference on Artificial\n  Intelligence", "summary": "Understanding why a classification model prefers one class over another for\nan input instance is the challenge of contrastive explanation. This work\nimplements concept-based contrastive explanations for image classification by\nleveraging the similarity of instance embeddings and relevance of\nhuman-understandable concepts used by a fine-tuned deep learning model. Our\napproach extracts concepts with their relevance score, computes contrasts for\nsimilar instances, and evaluates the resulting contrastive explanations based\non explanation complexity. Robustness is tested for different image\naugmentations. Two research questions are addressed: (1) whether explanation\ncomplexity varies across different relevance ranges, and (2) whether\nexplanation complexity remains consistent under image augmentations such as\nrotation and noise. The results confirm that for our experiments higher concept\nrelevance leads to shorter, less complex explanations, while lower relevance\nresults in longer, more diffuse explanations. Additionally, explanations show\nvarying degrees of robustness. The discussion of these findings offers insights\ninto the potential of building more interpretable and robust AI systems.", "AI": {"tldr": "The paper introduces a concept-based method for contrastive explanations in image classification, showing that higher concept relevance leads to simpler explanations, while lower relevance results in more complex ones. Robustness varies under image augmentations.", "motivation": "To understand why a classification model prefers one class over another for an input instance by providing contrastive explanations using human-understandable concepts.", "method": "Leverages instance embedding similarity and concept relevance in a fine-tuned deep learning model, extracts concepts with relevance scores, computes contrasts for similar instances, and evaluates explanation complexity.", "result": "Higher concept relevance leads to shorter, less complex explanations; lower relevance results in longer, more diffuse ones. Explanations show varying robustness under image augmentations.", "conclusion": "The findings highlight the potential for building more interpretable and robust AI systems through concept-based contrastive explanations."}}
{"id": "2506.21546", "pdf": "https://arxiv.org/pdf/2506.21546", "abs": "https://arxiv.org/abs/2506.21546", "authors": ["Xinzhuo Li", "Adheesh Juvekar", "Xingyou Liu", "Muntasir Wahed", "Kiet A. Nguyen", "Ismini Lourentzou"], "title": "HalluSegBench: Counterfactual Visual Reasoning for Segmentation Hallucination Evaluation", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "Project webpage: https://plan-lab.github.io/hallusegbench/", "summary": "Recent progress in vision-language segmentation has significantly advanced\ngrounded visual understanding. However, these models often exhibit\nhallucinations by producing segmentation masks for objects not grounded in the\nimage content or by incorrectly labeling irrelevant regions. Existing\nevaluation protocols for segmentation hallucination primarily focus on label or\ntextual hallucinations without manipulating the visual context, limiting their\ncapacity to diagnose critical failures. In response, we introduce\nHalluSegBench, the first benchmark specifically designed to evaluate\nhallucinations in visual grounding through the lens of counterfactual visual\nreasoning. Our benchmark consists of a novel dataset of 1340 counterfactual\ninstance pairs spanning 281 unique object classes, and a set of newly\nintroduced metrics that quantify hallucination sensitivity under visually\ncoherent scene edits. Experiments on HalluSegBench with state-of-the-art\nvision-language segmentation models reveal that vision-driven hallucinations\nare significantly more prevalent than label-driven ones, with models often\npersisting in false segmentation, highlighting the need for counterfactual\nreasoning to diagnose grounding fidelity.", "AI": {"tldr": "HalluSegBench is introduced as the first benchmark to evaluate hallucinations in vision-language segmentation using counterfactual visual reasoning, revealing vision-driven hallucinations as more prevalent than label-driven ones.", "motivation": "Existing evaluation protocols for segmentation hallucination focus on label or textual hallucinations without manipulating visual context, limiting their diagnostic capacity.", "method": "HalluSegBench includes a dataset of 1340 counterfactual instance pairs and new metrics to quantify hallucination sensitivity under visually coherent scene edits.", "result": "Experiments show vision-driven hallucinations are more prevalent than label-driven ones, with models often persisting in false segmentation.", "conclusion": "Counterfactual reasoning is essential for diagnosing grounding fidelity in vision-language segmentation models."}}
{"id": "2409.17777", "pdf": "https://arxiv.org/pdf/2409.17777", "abs": "https://arxiv.org/abs/2409.17777", "authors": ["Raja Kumar", "Raghav Singhal", "Pranamya Kulkarni", "Deval Mehta", "Kshitij Jadhav"], "title": "Harnessing Shared Relations via Multimodal Mixup Contrastive Learning for Multimodal Classification", "categories": ["cs.CV", "cs.AI"], "comment": "Transactions on Machine Learning Research (TMLR). Raja Kumar and\n  Raghav Singhal contributed equally to this work", "summary": "Deep multimodal learning has shown remarkable success by leveraging\ncontrastive learning to capture explicit one-to-one relations across\nmodalities. However, real-world data often exhibits shared relations beyond\nsimple pairwise associations. We propose M3CoL, a Multimodal Mixup Contrastive\nLearning approach to capture nuanced shared relations inherent in multimodal\ndata. Our key contribution is a Mixup-based contrastive loss that learns robust\nrepresentations by aligning mixed samples from one modality with their\ncorresponding samples from other modalities thereby capturing shared relations\nbetween them. For multimodal classification tasks, we introduce a framework\nthat integrates a fusion module with unimodal prediction modules for auxiliary\nsupervision during training, complemented by our proposed Mixup-based\ncontrastive loss. Through extensive experiments on diverse datasets (N24News,\nROSMAP, BRCA, and Food-101), we demonstrate that M3CoL effectively captures\nshared multimodal relations and generalizes across domains. It outperforms\nstate-of-the-art methods on N24News, ROSMAP, and BRCA, while achieving\ncomparable performance on Food-101. Our work highlights the significance of\nlearning shared relations for robust multimodal learning, opening up promising\navenues for future research. Our code is publicly available at\nhttps://github.com/RaghavSinghal10/M3CoL.", "AI": {"tldr": "M3CoL introduces a Mixup-based contrastive learning approach to capture shared relations in multimodal data, outperforming state-of-the-art methods on several datasets.", "motivation": "Real-world data often has shared relations beyond simple pairwise associations, which existing methods fail to capture.", "method": "Proposes M3CoL, combining Mixup-based contrastive loss with a fusion framework for multimodal classification.", "result": "Outperforms state-of-the-art on N24News, ROSMAP, and BRCA; comparable on Food-101.", "conclusion": "Learning shared relations enhances multimodal learning, with promising future research directions."}}
{"id": "2409.15564", "pdf": "https://arxiv.org/pdf/2409.15564", "abs": "https://arxiv.org/abs/2409.15564", "authors": ["Xingrui Gu", "Chuyi Jiang", "Erte Wang", "Qiang Cui", "Leimin Tian", "Lianlong Wu", "Siyang Song", "Chuang Yu"], "title": "CauSkelNet: Causal Representation Learning for Human Behaviour Analysis", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Traditional machine learning methods for movement recognition often struggle\nwith limited model interpretability and a lack of insight into human movement\ndynamics. This study introduces a novel representation learning framework based\non causal inference to address these challenges. Our two-stage approach\ncombines the Peter-Clark (PC) algorithm and Kullback-Leibler (KL) divergence to\nidentify and quantify causal relationships between human joints. By capturing\njoint interactions, the proposed causal Graph Convolutional Network (GCN)\nproduces interpretable and robust representations. Experimental results on the\nEmoPain dataset demonstrate that the causal GCN outperforms traditional GCNs in\naccuracy, F1 score, and recall, particularly in detecting protective behaviors.\nThis work contributes to advancing human motion analysis and lays a foundation\nfor adaptive and intelligent healthcare solutions.", "AI": {"tldr": "A novel causal inference-based framework improves movement recognition by capturing joint interactions, outperforming traditional methods in accuracy and interpretability.", "motivation": "Addressing the limitations of traditional machine learning in movement recognition, such as poor interpretability and lack of insight into movement dynamics.", "method": "A two-stage approach using the Peter-Clark (PC) algorithm and Kullback-Leibler (KL) divergence to identify and quantify causal relationships between human joints, integrated into a causal Graph Convolutional Network (GCN).", "result": "The causal GCN outperforms traditional GCNs in accuracy, F1 score, and recall on the EmoPain dataset, especially in detecting protective behaviors.", "conclusion": "The framework advances human motion analysis and supports adaptive, intelligent healthcare solutions."}}
{"id": "2506.23982", "pdf": "https://arxiv.org/pdf/2506.23982", "abs": "https://arxiv.org/abs/2506.23982", "authors": ["Ruiyang Hao", "Bowen Jing", "Haibao Yu", "Zaiqing Nie"], "title": "StyleDrive: Towards Driving-Style Aware Benchmarking of End-To-End Autonomous Driving", "categories": ["cs.CV", "cs.RO", "I.4.9"], "comment": "14 pages, 4 figures", "summary": "While personalization has been explored in traditional autonomous driving\nsystems, it remains largely overlooked in end-to-end autonomous driving\n(E2EAD), despite its growing prominence. This gap is critical, as user-aligned\nbehavior is essential for trust, comfort, and widespread adoption of autonomous\nvehicles. A core challenge is the lack of large-scale real-world datasets\nannotated with diverse and fine-grained driving preferences, hindering the\ndevelopment and evaluation of personalized E2EAD models. In this work, we\npresent the first large-scale real-world dataset enriched with annotations\ncapturing diverse driving preferences, establishing a foundation for\npersonalization in E2EAD. We extract static environmental features from\nreal-world road topology and infer dynamic contextual cues using a fine-tuned\nvisual language model (VLM), enabling consistent and fine-grained scenario\nconstruction. Based on these scenarios, we derive objective preference\nannotations through behavioral distribution analysis and rule-based heuristics.\nTo address the inherent subjectivity of driving style, we further employ the\nVLM to generate subjective annotations by jointly modeling scene semantics and\ndriver behavior. Final high-quality labels are obtained through a\nhuman-in-the-loop verification process that fuses both perspectives. Building\non this dataset, we propose the first benchmark for evaluating personalized\nE2EAD models. We assess several state-of-the-art models with and without\npreference conditioning, demonstrating that incorporating personalized\npreferences results in behavior more aligned with human driving. Our work lays\nthe foundation for personalized E2EAD by providing a standardized platform to\nsystematically integrate human preferences into data-driven E2EAD systems,\ncatalyzing future research in human-centric autonomy.", "AI": {"tldr": "The paper addresses the gap in personalized end-to-end autonomous driving (E2EAD) by introducing a large-scale dataset with diverse driving preferences and proposing a benchmark for evaluating personalized E2EAD models.", "motivation": "Personalization is crucial for trust and comfort in autonomous vehicles but is overlooked in E2EAD due to the lack of datasets capturing diverse driving preferences.", "method": "The authors create a dataset with static and dynamic annotations, use a visual language model (VLM) for scenario construction, and derive objective and subjective preference labels. Human verification ensures label quality.", "result": "Incorporating personalized preferences improves alignment with human driving behavior, as demonstrated by evaluating state-of-the-art models.", "conclusion": "The work establishes a foundation for personalized E2EAD, enabling systematic integration of human preferences and fostering human-centric autonomy research."}}
{"id": "2410.01276", "pdf": "https://arxiv.org/pdf/2410.01276", "abs": "https://arxiv.org/abs/2410.01276", "authors": ["Xavier F. Cadet", "Anastasia Borovykh", "Mohammad Malekzadeh", "Sara Ahmadi-Abhari", "Hamed Haddadi"], "title": "Deep Unlearn: Benchmarking Machine Unlearning for Image Classification", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at EuroS&P 2025", "summary": "Machine unlearning (MU) aims to remove the influence of particular data\npoints from the learnable parameters of a trained machine learning model. This\nis a crucial capability in light of data privacy requirements, trustworthiness,\nand safety in deployed models. MU is particularly challenging for deep neural\nnetworks (DNNs), such as convolutional nets or vision transformers, as such\nDNNs tend to memorize a notable portion of their training dataset.\nNevertheless, the community lacks a rigorous and multifaceted study that looks\ninto the success of MU methods for DNNs. In this paper, we investigate 18\nstate-of-the-art MU methods across various benchmark datasets and models, with\neach evaluation conducted over 10 different initializations, a comprehensive\nevaluation involving MU over 100K models. We show that, with the proper\nhyperparameters, Masked Small Gradients (MSG) and Convolution Transpose (CT),\nconsistently perform better in terms of model accuracy and run-time efficiency\nacross different models, datasets, and initializations, assessed by\npopulation-based membership inference attacks (MIA) and per-sample unlearning\nlikelihood ratio attacks (U-LiRA). Furthermore, our benchmark highlights the\nfact that comparing a MU method only with commonly used baselines, such as\nGradient Ascent (GA) or Successive Random Relabeling (SRL), is inadequate, and\nwe need better baselines like Negative Gradient Plus (NG+) with proper\nhyperparameter selection.", "AI": {"tldr": "The paper evaluates 18 machine unlearning (MU) methods for deep neural networks (DNNs), identifying MSG and CT as top performers in accuracy and efficiency, while advocating for better baselines like NG+ over traditional ones like GA or SRL.", "motivation": "Addressing the lack of rigorous studies on MU for DNNs, especially given privacy and safety concerns, the paper aims to comprehensively evaluate MU methods.", "method": "The study tests 18 MU methods across various datasets and models, with 10 initializations each, totaling 100K models, using MIA and U-LiRA for assessment.", "result": "MSG and CT outperform others in accuracy and efficiency, while traditional baselines like GA or SRL are deemed inadequate compared to NG+.", "conclusion": "The paper underscores the need for better MU baselines and highlights MSG and CT as effective methods for DNN unlearning."}}
{"id": "2410.01697", "pdf": "https://arxiv.org/pdf/2410.01697", "abs": "https://arxiv.org/abs/2410.01697", "authors": ["Sedjro Salomon Hotegni", "Sebastian Peitz"], "title": "Enhancing Adversarial Robustness through Multi-Objective Representation Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Deep neural networks (DNNs) are vulnerable to small adversarial\nperturbations, which are tiny changes to the input data that appear\ninsignificant but cause the model to produce drastically different outputs.\nMany defense methods require modifying model architectures during evaluation or\nperforming test-time data purification. This not only introduces additional\ncomplexity but is often architecture-dependent. We show, however, that robust\nfeature learning during training can significantly enhance DNN robustness. We\npropose MOREL, a multi-objective approach that aligns natural and adversarial\nfeatures using cosine similarity and multi-positive contrastive losses to\nencourage similar features for same-class inputs. Extensive experiments\ndemonstrate that MOREL significantly improves robustness against both white-box\nand black-box attacks. Our code is available at\nhttps://github.com/salomonhotegni/MOREL", "AI": {"tldr": "MOREL improves DNN robustness by aligning natural and adversarial features during training using cosine similarity and multi-positive contrastive losses.", "motivation": "DNNs are vulnerable to adversarial perturbations, and existing defenses add complexity or are architecture-dependent. Robust feature learning during training can enhance robustness.", "method": "Proposes MOREL, a multi-objective approach using cosine similarity and multi-positive contrastive losses to align features of same-class inputs.", "result": "MOREL significantly improves robustness against white-box and black-box attacks.", "conclusion": "Robust feature learning during training, as demonstrated by MOREL, effectively enhances DNN robustness without adding complexity."}}
{"id": "2506.24039", "pdf": "https://arxiv.org/pdf/2506.24039", "abs": "https://arxiv.org/abs/2506.24039", "authors": ["Shubhabrata Mukherjee", "Jack Lang", "Obeen Kwon", "Iryna Zenyuk", "Valerie Brogden", "Adam Weber", "Daniela Ushizima"], "title": "Foundation Models for Zero-Shot Segmentation of Scientific Images without AI-Ready Data", "categories": ["cs.CV", "cs.HC"], "comment": "This manuscript is a draft on arxiv. A final version has been\n  submitted to the 59th ICPP 2025, DRAI workshop", "summary": "Zero-shot and prompt-based technologies capitalized on using frequently\noccurring images to transform visual reasoning tasks, which explains why such\ntechnologies struggle with valuable yet scarce scientific image sets. In this\nwork, we propose Zenesis, a comprehensive no-code interactive platform designed\nto minimize barriers posed by data readiness for scientific images. We develop\nlightweight multi-modal adaptation techniques that enable zero-shot operation\non raw scientific data, along with human-in-the-loop refinement and\nheuristic-based temporal enhancement options. We demonstrate the performance of\nour approach through comprehensive comparison and validation on challenging\nFocused Ion Beam Scanning Electron Microscopy (FIB-SEM) data of catalyst-loaded\nmembranes. Zenesis significantly outperforms baseline methods, achieving an\naverage accuracy of 0.947, an Intersection over Union (IOU) of 0.858, and a\nDice score of 0.923 for amorphous catalyst samples and accuracy of 0.987, an\nIOU of 0.857, and a Dice score of 0.923 for crystalline samples. These results\nmark a substantial improvement over traditional methods like Otsu thresholding\nand even advanced models like Segment Anything Model (SAM) when used in\nisolation. Our results demonstrate that Zenesis is a powerful tool for\nscientific applications, particularly in fields where high-quality annotated\ndatasets are unavailable, accelerating accurate analysis of experimental\nimaging.", "AI": {"tldr": "Zenesis is a no-code platform for scientific image analysis, outperforming traditional methods with high accuracy and efficiency, especially for scarce datasets.", "motivation": "Existing zero-shot and prompt-based technologies struggle with scarce scientific image sets, necessitating a solution to minimize data readiness barriers.", "method": "Zenesis uses lightweight multi-modal adaptation for zero-shot operation, human-in-the-loop refinement, and heuristic-based temporal enhancement.", "result": "Zenesis achieves high accuracy (0.947-0.987), IOU (0.857-0.858), and Dice scores (0.923) on FIB-SEM data, outperforming baselines like Otsu and SAM.", "conclusion": "Zenesis is a powerful tool for scientific imaging, especially where annotated datasets are scarce, enabling accurate analysis."}}
{"id": "2410.19504", "pdf": "https://arxiv.org/pdf/2410.19504", "abs": "https://arxiv.org/abs/2410.19504", "authors": ["Zelin Zang", "Yuhao Wang", "Jinlin Wu", "Hong Liu", "Yue Shen", "Zhen Lei", "Stan. Z Li"], "title": "MOE-Enhanced Explanable Deep Manifold Transformation for Complex Data Embedding and Visualization", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 8 figures", "summary": "Dimensionality reduction (DR) plays a crucial role in various fields,\nincluding data engineering and visualization, by simplifying complex datasets\nwhile retaining essential information. However, achieving both high DR accuracy\nand strong explainability remains a fundamental challenge, especially for users\ndealing with high-dimensional data. Traditional DR methods often face a\ntrade-off between precision and transparency, where optimizing for performance\ncan lead to reduced explainability, and vice versa. This limitation is\nespecially prominent in real-world applications such as image, tabular, and\ntext data analysis, where both accuracy and explainability are critical. To\naddress these challenges, this work introduces the MOE-based Explainable Deep\nManifold Transformation (DMT-ME). The proposed approach combines hyperbolic\nembeddings, which effectively capture complex hierarchical structures, with\nMixture of Experts (MOE) models, which dynamically allocate tasks based on\ninput features. DMT-ME enhances DR accuracy by leveraging hyperbolic embeddings\nto represent the hierarchical nature of data, while also improving\nexplainability by explicitly linking input data, embedding outcomes, and key\nfeatures through the MOE structure. Extensive experiments demonstrate that\nDMT-ME consistently achieves superior performance in both DR accuracy and model\nexplainability, making it a robust solution for complex data analysis. The code\nis available at https://github.com/zangzelin/code_dmtme", "AI": {"tldr": "DMT-ME combines hyperbolic embeddings and Mixture of Experts to improve dimensionality reduction accuracy and explainability.", "motivation": "Addressing the trade-off between accuracy and explainability in dimensionality reduction for high-dimensional data.", "method": "Uses hyperbolic embeddings for hierarchical data representation and Mixture of Experts for dynamic task allocation.", "result": "Superior performance in both accuracy and explainability compared to traditional methods.", "conclusion": "DMT-ME is a robust solution for complex data analysis, balancing accuracy and explainability."}}
{"id": "2411.01600", "pdf": "https://arxiv.org/pdf/2411.01600", "abs": "https://arxiv.org/abs/2411.01600", "authors": ["Fang Sun", "Zijie Huang", "Haixin Wang", "Huacong Tang", "Xiao Luo", "Wei Wang", "Yizhou Sun"], "title": "Graph Fourier Neural ODEs: Modeling Spatial-temporal Multi-scales in Molecular Dynamics", "categories": ["cs.LG", "physics.chem-ph", "q-bio.QM"], "comment": "Published in Transactions on Machine Learning Research (06/2025)", "summary": "Accurately predicting long-horizon molecular dynamics (MD) trajectories\nremains a significant challenge, as existing deep learning methods often\nstruggle to retain fidelity over extended simulations. We hypothesize that one\nkey factor limiting accuracy is the difficulty of capturing interactions that\nspan distinct spatial and temporal scales, ranging from high-frequency local\nvibrations to low-frequency global conformational changes. To address these\nlimitations, we propose Graph Fourier Neural ODEs (GF-NODE), integrating a\ngraph Fourier transform for spatial frequency decomposition with a Neural ODE\nframework for continuous-time evolution. Specifically, GF-NODE first decomposes\nmolecular configurations into multiple spatial frequency modes using the graph\nLaplacian, then evolves the frequency components in time via a learnable Neural\nODE module that captures both local and global dynamics, and finally\nreconstructs the updated molecular geometry through an inverse graph Fourier\ntransform. By explicitly modeling high- and low-frequency phenomena in this\nunified pipeline, GF-NODE captures long-range correlations and local\nfluctuations more effectively. We provide theoretical insight through heat\nequation analysis on a simplified diffusion model, demonstrating how graph\nLaplacian eigenvalues can determine temporal dynamics scales, and crucially\nvalidate this correspondence through comprehensive empirical analysis on real\nmolecular dynamics trajectories showing quantitative spatial-temporal\ncorrelations across diverse molecular systems. Experimental results on\nchallenging MD benchmarks demonstrate that GF-NODE achieves state-of-the-art\naccuracy while preserving essential geometrical features over extended\nsimulations. These findings highlight the promise of bridging spectral\ndecomposition with continuous-time modeling to improve the robustness and\npredictive power of MD simulations.", "AI": {"tldr": "GF-NODE, a method combining graph Fourier transform and Neural ODEs, improves long-horizon molecular dynamics predictions by capturing multi-scale interactions.", "motivation": "Existing deep learning methods struggle with long-horizon MD predictions due to difficulties in modeling interactions across spatial and temporal scales.", "method": "GF-NODE decomposes molecular configurations into spatial frequency modes using graph Laplacian, evolves them via Neural ODE, and reconstructs geometry.", "result": "GF-NODE achieves state-of-the-art accuracy in MD benchmarks, preserving geometrical features over extended simulations.", "conclusion": "Bridging spectral decomposition with continuous-time modeling enhances MD simulation robustness and predictive power."}}
{"id": "2506.24063", "pdf": "https://arxiv.org/pdf/2506.24063", "abs": "https://arxiv.org/abs/2506.24063", "authors": ["Deng Li", "Aming Wu", "Yang Li", "Yaowei Wang", "Yahong Han"], "title": "Continual Adaptation: Environment-Conditional Parameter Generation for Object Detection in Dynamic Scenarios", "categories": ["cs.CV"], "comment": null, "summary": "In practice, environments constantly change over time and space, posing\nsignificant challenges for object detectors trained based on a closed-set\nassumption, i.e., training and test data share the same distribution. To this\nend, continual test-time adaptation has attracted much attention, aiming to\nimprove detectors' generalization by fine-tuning a few specific parameters,\ne.g., BatchNorm layers. However, based on a small number of test images,\nfine-tuning certain parameters may affect the representation ability of other\nfixed parameters, leading to performance degradation. Instead, we explore a new\nmechanism, i.e., converting the fine-tuning process to a specific-parameter\ngeneration. Particularly, we first design a dual-path LoRA-based domain-aware\nadapter that disentangles features into domain-invariant and domain-specific\ncomponents, enabling efficient adaptation. Additionally, a conditional\ndiffusion-based parameter generation mechanism is presented to synthesize the\nadapter's parameters based on the current environment, preventing the\noptimization from getting stuck in local optima. Finally, we propose a\nclass-centered optimal transport alignment method to mitigate catastrophic\nforgetting. Extensive experiments conducted on various continuous domain\nadaptive object detection tasks demonstrate the effectiveness. Meanwhile,\nvisualization results show that the representation extracted by the generated\nparameters can capture more object-related information and strengthen the\ngeneralization ability.", "AI": {"tldr": "The paper proposes a novel method for continual test-time adaptation in object detection by generating specific parameters instead of fine-tuning, using a dual-path LoRA-based adapter and conditional diffusion, to improve generalization and avoid performance degradation.", "motivation": "Environments change dynamically, challenging closed-set-trained object detectors. Fine-tuning specific parameters (e.g., BatchNorm) can degrade performance due to limited test images and interference with fixed parameters.", "method": "Introduces a dual-path LoRA-based domain-aware adapter to separate domain-invariant and domain-specific features, a conditional diffusion-based parameter generation mechanism, and a class-centered optimal transport alignment to prevent forgetting.", "result": "Experiments show the method's effectiveness in continuous domain adaptation tasks, with visualizations confirming improved object-related information capture and generalization.", "conclusion": "The proposed approach enhances adaptability and generalization in dynamic environments, outperforming traditional fine-tuning methods."}}
{"id": "2411.09062", "pdf": "https://arxiv.org/pdf/2411.09062", "abs": "https://arxiv.org/abs/2411.09062", "authors": ["Nazanin Mahjourian", "Vinh Nguyen"], "title": "Multimodal Object Detection using Depth and Image Data for Manufacturing Parts", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Manufacturing requires reliable object detection methods for precise picking\nand handling of diverse types of manufacturing parts and components.\nTraditional object detection methods utilize either only 2D images from cameras\nor 3D data from lidars or similar 3D sensors. However, each of these sensors\nhave weaknesses and limitations. Cameras do not have depth perception and 3D\nsensors typically do not carry color information. These weaknesses can\nundermine the reliability and robustness of industrial manufacturing systems.\nTo address these challenges, this work proposes a multi-sensor system combining\nan red-green-blue (RGB) camera and a 3D point cloud sensor. The two sensors are\ncalibrated for precise alignment of the multimodal data captured from the two\nhardware devices. A novel multimodal object detection method is developed to\nprocess both RGB and depth data. This object detector is based on the Faster\nR-CNN baseline that was originally designed to process only camera images. The\nresults show that the multimodal model significantly outperforms the depth-only\nand RGB-only baselines on established object detection metrics. More\nspecifically, the multimodal model improves mAP by 13% and raises Mean\nPrecision by 11.8% in comparison to the RGB-only baseline. Compared to the\ndepth-only baseline, it improves mAP by 78% and raises Mean Precision by 57%.\nHence, this method facilitates more reliable and robust object detection in\nservice to smart manufacturing applications.", "AI": {"tldr": "A multimodal object detection system combining RGB and 3D point cloud data outperforms single-sensor baselines, enhancing reliability in manufacturing.", "motivation": "Traditional 2D or 3D sensors have limitations (e.g., lack of depth or color), undermining industrial reliability.", "method": "Proposes a calibrated RGB and 3D sensor system, extending Faster R-CNN to process multimodal data.", "result": "Multimodal model improves mAP by 13% (vs. RGB-only) and 78% (vs. depth-only), with similar gains in Mean Precision.", "conclusion": "The method enhances object detection robustness for smart manufacturing."}}
{"id": "2411.02058", "pdf": "https://arxiv.org/pdf/2411.02058", "abs": "https://arxiv.org/abs/2411.02058", "authors": ["Gionni Marchetti"], "title": "Intrinsic Dimensionality of Fermi-Pasta-Ulam-Tsingou High-Dimensional Trajectories Through Manifold Learning: A Linear Approach", "categories": ["cs.LG", "cond-mat.stat-mech", "physics.soc-ph"], "comment": "15 pages, 15 figures", "summary": "A data-driven approach based on unsupervised machine learning is proposed to\ninfer the intrinsic dimension $m^{\\ast}$ of the high-dimensional trajectories\nof the Fermi-Pasta-Ulam-Tsingou (FPUT) model. Principal component analysis\n(PCA) is applied to trajectory data consisting of $n_s = 4,000,000$ datapoints,\nof the FPUT $\\beta$ model with $N = 32$ coupled oscillators, revealing a\ncritical relationship between $m^{\\ast}$ and the model's nonlinear strength. By\nestimating the intrinsic dimension $m^{\\ast}$ using multiple methods\n(participation ratio, Kaiser rule, and the Kneedle algorithm), it is found that\n$m^{\\ast}$ increases with the model nonlinearity. Interestingly, in the weakly\nnonlinear regime, for trajectories initialized by exciting the first mode, the\nparticipation ratio estimates $m^{\\ast} = 2, 3$, strongly suggesting that\nquasi-periodic motion on a low-dimensional Riemannian manifold underlies the\ncharacteristic energy recurrences observed in the FPUT model.", "AI": {"tldr": "The paper proposes an unsupervised machine learning approach to infer the intrinsic dimension of trajectories in the FPUT model, revealing a link between dimension and nonlinear strength.", "motivation": "To understand the intrinsic dimensionality of high-dimensional trajectories in the FPUT model and its relationship with nonlinearity.", "method": "Principal component analysis (PCA) is applied to trajectory data, and intrinsic dimension is estimated using participation ratio, Kaiser rule, and the Kneedle algorithm.", "result": "The intrinsic dimension increases with nonlinearity. In weakly nonlinear regimes, quasi-periodic motion on a low-dimensional manifold explains energy recurrences.", "conclusion": "The study highlights the role of low-dimensional manifolds in the FPUT model's dynamics, particularly in weakly nonlinear regimes."}}
{"id": "2506.24096", "pdf": "https://arxiv.org/pdf/2506.24096", "abs": "https://arxiv.org/abs/2506.24096", "authors": ["Antoine Gu\u00e9don", "Diego Gomez", "Nissim Maruani", "Bingchen Gong", "George Drettakis", "Maks Ovsjanikov"], "title": "MILo: Mesh-In-the-Loop Gaussian Splatting for Detailed and Efficient Surface Reconstruction", "categories": ["cs.CV"], "comment": "10 pages. A presentation video of our approach is available at\n  https://youtu.be/_SGNhhNz0fE", "summary": "While recent advances in Gaussian Splatting have enabled fast reconstruction\nof high-quality 3D scenes from images, extracting accurate surface meshes\nremains a challenge. Current approaches extract the surface through costly\npost-processing steps, resulting in the loss of fine geometric details or\nrequiring significant time and leading to very dense meshes with millions of\nvertices. More fundamentally, the a posteriori conversion from a volumetric to\na surface representation limits the ability of the final mesh to preserve all\ngeometric structures captured during training. We present MILo, a novel\nGaussian Splatting framework that bridges the gap between volumetric and\nsurface representations by differentiably extracting a mesh from the 3D\nGaussians. We design a fully differentiable procedure that constructs the\nmesh-including both vertex locations and connectivity-at every iteration\ndirectly from the parameters of the Gaussians, which are the only quantities\noptimized during training. Our method introduces three key technical\ncontributions: a bidirectional consistency framework ensuring both\nrepresentations-Gaussians and the extracted mesh-capture the same underlying\ngeometry during training; an adaptive mesh extraction process performed at each\ntraining iteration, which uses Gaussians as differentiable pivots for Delaunay\ntriangulation; a novel method for computing signed distance values from the 3D\nGaussians that enables precise surface extraction while avoiding geometric\nerosion. Our approach can reconstruct complete scenes, including backgrounds,\nwith state-of-the-art quality while requiring an order of magnitude fewer mesh\nvertices than previous methods. Due to their light weight and empty interior,\nour meshes are well suited for downstream applications such as physics\nsimulations or animation.", "AI": {"tldr": "MILo introduces a differentiable Gaussian Splatting framework to extract accurate surface meshes directly from 3D Gaussians, avoiding costly post-processing and preserving fine geometric details.", "motivation": "Current methods for extracting surface meshes from Gaussian Splatting lose details or produce dense meshes, limiting downstream applications.", "method": "MILo uses a fully differentiable process to construct meshes from Gaussians, featuring bidirectional consistency, adaptive mesh extraction, and signed distance computation.", "result": "The method reconstructs high-quality scenes with fewer vertices, suitable for physics simulations and animation.", "conclusion": "MILo bridges volumetric and surface representations, offering efficient and precise mesh extraction for 3D scenes."}}
{"id": "2411.09850", "pdf": "https://arxiv.org/pdf/2411.09850", "abs": "https://arxiv.org/abs/2411.09850", "authors": ["Shijie Zhou", "Huaisheng Zhu", "Rohan Sharma", "Jiayi Chen", "Ruiyi Zhang", "Kaiyi Ji", "Changyou Chen"], "title": "Enhancing Diffusion Posterior Sampling for Inverse Problems by Integrating Crafted Measurements", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Diffusion models have emerged as a powerful foundation model for visual\ngenerations. With an appropriate sampling process, it can effectively serve as\na generative prior for solving general inverse problems. Current posterior\nsampling-based methods take the measurement (i.e., degraded image sample) into\nthe posterior sampling to infer the distribution of the target data (i.e.,\nclean image sample). However, in this manner, we show that high-frequency\ninformation can be prematurely introduced during the early stages, which could\ninduce larger posterior estimate errors during restoration sampling. To address\nthis observation, we first reveal that forming the log-posterior gradient with\nthe noisy measurement ( i.e., noisy measurement from a diffusion forward\nprocess) instead of the clean one can benefit the early posterior sampling.\nConsequently, we propose a novel diffusion posterior sampling method DPS-CM,\nwhich incorporates a Crafted Measurement (i.e., noisy measurement crafted by a\nreverse denoising process, rather than constructed from the diffusion forward\nprocess) to form the posterior estimate. This integration aims to mitigate the\nmisalignment with the diffusion prior caused by cumulative posterior estimate\nerrors. Experimental results demonstrate that our approach significantly\nimproves the overall capacity to solve general and noisy inverse problems, such\nas Gaussian deblurring, super-resolution, inpainting, nonlinear deblurring, and\ntasks with Poisson noise, relative to existing approaches. Code is available\nat: https://github.com/sjz5202/DPS-CM.", "AI": {"tldr": "DPS-CM improves diffusion posterior sampling by using a crafted noisy measurement to reduce early high-frequency errors, enhancing performance in inverse problems like deblurring and super-resolution.", "motivation": "High-frequency information introduced early in posterior sampling can cause errors, so a better method is needed to align with the diffusion prior.", "method": "Proposes DPS-CM, which uses a crafted noisy measurement (reverse denoising process) instead of clean or forward-process noisy measurements for posterior sampling.", "result": "Significantly outperforms existing methods in tasks like Gaussian deblurring, super-resolution, and noisy inverse problems.", "conclusion": "DPS-CM effectively mitigates misalignment with the diffusion prior, improving restoration quality for various inverse problems."}}
{"id": "2411.15240", "pdf": "https://arxiv.org/pdf/2411.15240", "abs": "https://arxiv.org/abs/2411.15240", "authors": ["Franklin Y. Ruan", "Aiwei Zhang", "Jenny Y. Oh", "SouYoung Jin", "Nicholas C. Jacobson"], "title": "Foundation Models for Wearable Movement Data in Mental Health Research", "categories": ["cs.LG", "cs.AI", "cs.HC", "q-bio.QM"], "comment": null, "summary": "Pretrained foundation models and transformer architectures have driven the\nsuccess of large language models (LLMs) and other modern AI breakthroughs.\nHowever, similar advancements in health data modeling remain limited due to the\nneed for innovative adaptations. Wearable movement data offers a valuable\navenue for exploration, as it's a core feature in nearly all commercial\nsmartwatches, well established in clinical and mental health research, and the\nsequential nature of the data shares similarities to language. We introduce the\nPretrained Actigraphy Transformer (PAT), the first open source foundation model\ndesigned for time-series wearable movement data. Leveraging transformer-based\narchitectures and novel techniques, such as patch embeddings, and pretraining\non data from 29,307 participants in a national U.S. sample, PAT achieves\nstate-of-the-art performance in several mental health prediction tasks. PAT is\nalso lightweight and easily interpretable, making it a robust tool for mental\nhealth research.\n  GitHub: https://github.com/njacobsonlab/Pretrained-Actigraphy-Transformer/", "AI": {"tldr": "PAT is a lightweight, interpretable foundation model for wearable movement data, achieving state-of-the-art performance in mental health tasks.", "motivation": "Advancements in health data modeling lag behind AI breakthroughs like LLMs; wearable movement data is a promising but underexplored avenue.", "method": "Uses transformer architectures, patch embeddings, and pretraining on data from 29,307 participants.", "result": "PAT achieves state-of-the-art performance in mental health prediction tasks.", "conclusion": "PAT is a robust, open-source tool for mental health research."}}
{"id": "2506.24102", "pdf": "https://arxiv.org/pdf/2506.24102", "abs": "https://arxiv.org/abs/2506.24102", "authors": ["Xiangtai Li", "Tao Zhang", "Yanwei Li", "Haobo Yuan", "Shihao Chen", "Yikang Zhou", "Jiahao Meng", "Yueyi Sun", "Shilin Xu", "Lu Qi", "Tianheng Cheng", "Yi Lin", "Zilong Huang", "Wenhao Huang", "Jiashi Feng", "Guang Shi"], "title": "DenseWorld-1M: Towards Detailed Dense Grounded Caption in the Real World", "categories": ["cs.CV"], "comment": "Datasets and Models: https://github.com/lxtGH/DenseWorld-1M", "summary": "Multimodal Large Language Models (MLLMs) demonstrate a complex understanding\nof scenes, benefiting from large-scale and high-quality datasets. Most existing\ncaption datasets lack the ground locations and relations for visual entities.\nSeveral grounded caption datasets face the problems of missing detailed\ndescriptions, relations, and massive object descriptions on high-resolution\nimages. To fill this gap for the community, we present DenseWorld-1M, the first\nmassive, detailed, dense grounded caption dataset in the real world. We design\na three-stage labeling pipeline, containing open-world perception, detailed\nobject caption generation, and dense caption merging. The first stage obtains\nentity-level masks and labels. The second stage generates the object-level,\ndetailed captions with the guidance of masks and labels from the first stage.\nThe final stage merges object captions and masks into spatial and relational\ndense captions. To accelerate the labeling process and improve caption quality,\nwe present two VLM models: the Detailed Region Caption model and the Spatial\nCaption Merging model. Extensive experiments on various settings, including\nvision-language understanding, visual grounding, and region caption generation,\ndemonstrate the effectiveness of our DenseWorld-1M dataset and labeling models.", "AI": {"tldr": "DenseWorld-1M is a new dataset addressing gaps in grounded caption datasets by providing detailed, dense captions for high-resolution images, using a three-stage labeling pipeline and VLM models.", "motivation": "Existing caption datasets lack detailed descriptions, relations, and object-level grounding for high-resolution images.", "method": "A three-stage labeling pipeline (open-world perception, detailed object caption generation, dense caption merging) and two VLM models (Detailed Region Caption model, Spatial Caption Merging model) are used.", "result": "The dataset and models improve performance in vision-language understanding, visual grounding, and region caption generation.", "conclusion": "DenseWorld-1M fills a critical gap in multimodal datasets and enhances MLLM capabilities."}}
{"id": "2411.13757", "pdf": "https://arxiv.org/pdf/2411.13757", "abs": "https://arxiv.org/abs/2411.13757", "authors": ["Sanjay Das", "Swastik Bhattacharya", "Souvik Kundu", "Shamik Kundu", "Anand Menon", "Arnab Raha", "Kanad Basu"], "title": "GenBFA: An Evolutionary Optimization Approach to Bit-Flip Attacks on LLMs", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have revolutionized natural language processing\n(NLP), excelling in tasks like text generation and summarization. However,\ntheir increasing adoption in mission-critical applications raises concerns\nabout hardware-based threats, particularly bit-flip attacks (BFAs). BFAs,\nenabled by fault injection methods such as Rowhammer, target model parameters\nin memory, compromising both integrity and performance. Identifying critical\nparameters for BFAs in the vast parameter space of LLMs poses significant\nchallenges. While prior research suggests transformer-based architectures are\ninherently more robust to BFAs compared to traditional deep neural networks, we\nchallenge this assumption. For the first time, we demonstrate that as few as\nthree bit-flips can cause catastrophic performance degradation in an LLM with\nbillions of parameters. Current BFA techniques are inadequate for exploiting\nthis vulnerability due to the difficulty of efficiently identifying critical\nparameters within the immense parameter space. To address this, we propose\nAttentionBreaker, a novel framework tailored for LLMs that enables efficient\ntraversal of the parameter space to identify critical parameters. Additionally,\nwe introduce GenBFA, an evolutionary optimization strategy designed to refine\nthe search further, isolating the most critical bits for an efficient and\neffective attack. Empirical results reveal the profound vulnerability of LLMs\nto AttentionBreaker. For example, merely three bit-flips (4.129 x 10^-9% of\ntotal parameters) in the LLaMA3-8B-Instruct 8-bit quantized (W8) model result\nin a complete performance collapse: accuracy on MMLU tasks drops from 67.3% to\n0%, and Wikitext perplexity skyrockets from 12.6 to 4.72 x 10^5. These findings\nunderscore the effectiveness of AttentionBreaker in uncovering and exploiting\ncritical vulnerabilities within LLM architectures.", "AI": {"tldr": "The paper highlights the vulnerability of Large Language Models (LLMs) to bit-flip attacks (BFAs), demonstrating that even a few bit-flips can severely degrade performance. It introduces AttentionBreaker and GenBFA to efficiently identify and exploit critical parameters.", "motivation": "The increasing use of LLMs in critical applications raises concerns about hardware-based threats like BFAs, which can compromise model integrity and performance.", "method": "The authors propose AttentionBreaker, a framework for efficient parameter space traversal, and GenBFA, an evolutionary optimization strategy, to identify and exploit critical bits in LLMs.", "result": "Empirical results show catastrophic performance drops in LLMs with minimal bit-flips (e.g., accuracy dropping from 67.3% to 0% with just three bit-flips).", "conclusion": "The study reveals LLMs' vulnerability to BFAs and demonstrates the effectiveness of AttentionBreaker in uncovering critical vulnerabilities."}}
{"id": "2411.16782", "pdf": "https://arxiv.org/pdf/2411.16782", "abs": "https://arxiv.org/abs/2411.16782", "authors": ["Chuan Liu", "Huanran Chen", "Yichi Zhang", "Yinpeng Dong", "Jun Zhu"], "title": "Scaling Laws for Black box Adversarial Attacks", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Adversarial examples usually exhibit good cross-model transferability,\nenabling attacks on black-box models with limited information about their\narchitectures and parameters, which are highly threatening in commercial\nblack-box scenarios. Model ensembling is an effective strategy to improve the\ntransferability of adversarial examples by attacking multiple surrogate models.\nHowever, since prior studies usually adopt few models in the ensemble, there\nremains an open question of whether scaling the number of models can further\nimprove black-box attacks. Inspired by the scaling law of large foundation\nmodels, we investigate the scaling laws of black-box adversarial attacks in\nthis work. Through theoretical analysis and empirical evaluations, we conclude\nwith clear scaling laws that using more surrogate models enhances adversarial\ntransferability. Comprehensive experiments verify the claims on standard image\nclassifiers, diverse defended models and multimodal large language models using\nvarious adversarial attack methods. Specifically, by scaling law, we achieve\n90%+ transfer attack success rate on even proprietary models like GPT-4o.\nFurther visualization indicates that there is also a scaling law on the\ninterpretability and semantics of adversarial perturbations.", "AI": {"tldr": "Scaling the number of surrogate models in adversarial attacks improves transferability, achieving high success rates on proprietary models like GPT-4o.", "motivation": "To explore whether increasing the number of surrogate models enhances adversarial transferability, inspired by scaling laws in large foundation models.", "method": "Theoretical analysis and empirical evaluations using diverse adversarial attack methods on standard and defended models, including multimodal large language models.", "result": "Clear scaling laws confirm that more surrogate models boost transferability, achieving over 90% success on proprietary models. Visualization also reveals scaling laws in perturbation interpretability and semantics.", "conclusion": "Scaling the number of surrogate models significantly improves adversarial transferability, with implications for black-box attack strategies."}}
{"id": "2506.24113", "pdf": "https://arxiv.org/pdf/2506.24113", "abs": "https://arxiv.org/abs/2506.24113", "authors": ["Kaiwen Zhang", "Zhenyu Tang", "Xiaotao Hu", "Xingang Pan", "Xiaoyang Guo", "Yuan Liu", "Jingwei Huang", "Li Yuan", "Qian Zhang", "Xiao-Xiao Long", "Xun Cao", "Wei Yin"], "title": "Epona: Autoregressive Diffusion World Model for Autonomous Driving", "categories": ["cs.CV"], "comment": "ICCV2025, Project Page: https://kevin-thu.github.io/Epona/", "summary": "Diffusion models have demonstrated exceptional visual quality in video\ngeneration, making them promising for autonomous driving world modeling.\nHowever, existing video diffusion-based world models struggle with\nflexible-length, long-horizon predictions and integrating trajectory planning.\nThis is because conventional video diffusion models rely on global joint\ndistribution modeling of fixed-length frame sequences rather than sequentially\nconstructing localized distributions at each timestep. In this work, we propose\nEpona, an autoregressive diffusion world model that enables localized\nspatiotemporal distribution modeling through two key innovations: 1) Decoupled\nspatiotemporal factorization that separates temporal dynamics modeling from\nfine-grained future world generation, and 2) Modular trajectory and video\nprediction that seamlessly integrate motion planning with visual modeling in an\nend-to-end framework. Our architecture enables high-resolution, long-duration\ngeneration while introducing a novel chain-of-forward training strategy to\naddress error accumulation in autoregressive loops. Experimental results\ndemonstrate state-of-the-art performance with 7.4\\% FVD improvement and minutes\nlonger prediction duration compared to prior works. The learned world model\nfurther serves as a real-time motion planner, outperforming strong end-to-end\nplanners on NAVSIM benchmarks. Code will be publicly available at\n\\href{https://github.com/Kevin-thu/Epona/}{https://github.com/Kevin-thu/Epona/}.", "AI": {"tldr": "Epona is an autoregressive diffusion world model for autonomous driving, improving long-horizon predictions and integrating trajectory planning via localized spatiotemporal modeling.", "motivation": "Existing video diffusion models struggle with flexible-length, long-horizon predictions and integrating trajectory planning due to global joint distribution modeling.", "method": "Epona uses decoupled spatiotemporal factorization and modular trajectory-video prediction, with a chain-of-forward training strategy to reduce autoregressive errors.", "result": "Achieves 7.4% FVD improvement and longer prediction duration, outperforming prior works and serving as a real-time motion planner.", "conclusion": "Epona advances video diffusion-based world modeling, enabling high-resolution, long-duration generation and effective motion planning."}}
{"id": "2411.16645", "pdf": "https://arxiv.org/pdf/2411.16645", "abs": "https://arxiv.org/abs/2411.16645", "authors": ["Dietmar Jannach", "Alan Said", "Marko Tkal\u010di\u010d", "Markus Zanker"], "title": "Recommender Systems for Good (RS4Good): Survey of Use Cases and a Call to Action for Research that Matters", "categories": ["cs.IR", "cs.AI", "cs.CY", "cs.LG"], "comment": null, "summary": "In the area of recommender systems, the vast majority of research efforts is\nspent on developing increasingly sophisticated recommendation models, also\nusing increasingly more computational resources. Unfortunately, most of these\nresearch efforts target a very small set of application domains, mostly\ne-commerce and media recommendation. Furthermore, many of these models are\nnever evaluated with users, let alone put into practice. The scientific,\neconomic and societal value of much of these efforts by scholars therefore\nremains largely unclear. To achieve a stronger positive impact resulting from\nthese efforts, we posit that we as a research community should more often\naddress use cases where recommender systems contribute to societal good\n(RS4Good). In this opinion piece, we first discuss a number of examples where\nthe use of recommender systems for problems of societal concern has been\nsuccessfully explored in the literature. We then proceed by outlining a\nparadigmatic shift that is needed to conduct successful RS4Good research, where\nthe key ingredients are interdisciplinary collaborations and longitudinal\nevaluation approaches with humans in the loop.", "AI": {"tldr": "The paper critiques the narrow focus of recommender systems research on e-commerce and media, advocating for a shift towards societal good (RS4Good) through interdisciplinary collaboration and human-in-the-loop evaluations.", "motivation": "Current recommender systems research lacks diversity in application domains and real-world impact, prompting a call for focusing on societal benefits.", "method": "The paper reviews successful RS4Good examples and proposes a paradigmatic shift involving interdisciplinary teamwork and longitudinal human evaluations.", "result": "The analysis highlights the potential of recommender systems to address societal concerns but notes the need for broader research approaches.", "conclusion": "The paper urges the research community to prioritize RS4Good, emphasizing interdisciplinary collaboration and practical, human-centered evaluations."}}
{"id": "2412.10354", "pdf": "https://arxiv.org/pdf/2412.10354", "abs": "https://arxiv.org/abs/2412.10354", "authors": ["Jean Kossaifi", "Nikola Kovachki", "Zongyi Li", "David Pitt", "Miguel Liu-Schiaffini", "Valentin Duruisseaux", "Robert Joseph George", "Boris Bonev", "Kamyar Azizzadenesheli", "Julius Berner", "Anima Anandkumar"], "title": "A Library for Learning Neural Operators", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We present NeuralOperator, an open-source Python library for operator\nlearning. Neural operators generalize neural networks to maps between function\nspaces instead of finite-dimensional Euclidean spaces. They can be trained and\ninferenced on input and output functions given at various discretizations,\nsatisfying a discretization convergence properties. Built on top of PyTorch,\nNeuralOperator provides all the tools for training and deploying neural\noperator models, as well as developing new ones, in a high-quality, tested,\nopen-source package. It combines cutting-edge models and customizability with a\ngentle learning curve and simple user interface for newcomers.", "AI": {"tldr": "NeuralOperator is a Python library for operator learning, enabling neural networks to map between function spaces with discretization convergence, built on PyTorch for ease of use.", "motivation": "To generalize neural networks for function space mappings and provide a flexible, high-quality tool for operator learning.", "method": "Built on PyTorch, NeuralOperator supports training and inference on varied discretizations, ensuring convergence properties.", "result": "A tested, open-source library with cutting-edge models, customizability, and a user-friendly interface.", "conclusion": "NeuralOperator successfully bridges the gap between neural networks and function space mappings, offering a practical tool for newcomers and experts."}}
{"id": "2506.24121", "pdf": "https://arxiv.org/pdf/2506.24121", "abs": "https://arxiv.org/abs/2506.24121", "authors": ["Sisi Dai", "Xinxin Su", "Boyan Wan", "Ruizhen Hu", "Kai Xu"], "title": "TextMesh4D: High-Quality Text-to-4D Mesh Generation", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in diffusion generative models significantly advanced\nimage, video, and 3D content creation from user-provided text prompts. However,\nthe challenging problem of dynamic 3D content generation (text-to-4D) with\ndiffusion guidance remains largely unexplored. In this paper, we introduce\nTextMesh4D, a novel framework for high-quality text-to-4D generation. Our\napproach leverages per-face Jacobians as a differentiable mesh representation\nand decomposes 4D generation into two stages: static object creation and\ndynamic motion synthesis. We further propose a flexibility-rigidity\nregularization term to stabilize Jacobian optimization under video diffusion\npriors, ensuring robust geometric performance. Experiments demonstrate that\nTextMesh4D achieves state-of-the-art results in terms of temporal consistency,\nstructural fidelity, and visual realism. Moreover, TextMesh4D operates with a\nlow GPU memory overhead-requiring only a single 24GB GPU-offering a\ncost-effective yet high-quality solution for text-driven 4D mesh generation.\nThe code will be released to facilitate future research in text-to-4D\ngeneration.", "AI": {"tldr": "TextMesh4D introduces a novel framework for high-quality text-to-4D generation, leveraging per-face Jacobians and a two-stage approach for static and dynamic synthesis, achieving state-of-the-art results with low GPU overhead.", "motivation": "Dynamic 3D content generation (text-to-4D) remains underexplored despite advancements in diffusion models for images, videos, and 3D content.", "method": "Uses per-face Jacobians for differentiable mesh representation, decomposes 4D generation into static object creation and dynamic motion synthesis, and introduces flexibility-rigidity regularization for stable optimization.", "result": "Achieves state-of-the-art performance in temporal consistency, structural fidelity, and visual realism with low GPU memory usage (24GB).", "conclusion": "TextMesh4D offers a cost-effective, high-quality solution for text-to-4D generation, with code release to support future research."}}
{"id": "2412.01787", "pdf": "https://arxiv.org/pdf/2412.01787", "abs": "https://arxiv.org/abs/2412.01787", "authors": ["Rongkun Xue", "Jinouwen Zhang", "Yazhe Niu", "Dazhong Shen", "Bingqi Ma", "Yu Liu", "Jing Yang"], "title": "Pretrained Reversible Generation as Unsupervised Visual Representation Learning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by ICCV 2025", "summary": "Recent generative models based on score matching and flow matching have\nsignificantly advanced generation tasks, but their potential in discriminative\ntasks remains underexplored. Previous approaches, such as generative\nclassifiers, have not fully leveraged the capabilities of these models for\ndiscriminative tasks due to their intricate designs. We propose Pretrained\nReversible Generation (PRG), which extracts unsupervised representations by\nreversing the generative process of a pretrained continuous generation model.\nPRG effectively reuses unsupervised generative models, leveraging their high\ncapacity to serve as robust and generalizable feature extractors for downstream\ntasks. This framework enables the flexible selection of feature hierarchies\ntailored to specific downstream tasks. Our method consistently outperforms\nprior approaches across multiple benchmarks, achieving state-of-the-art\nperformance among generative model based methods, including 78% top-1 accuracy\non ImageNet at a resolution of 64*64. Extensive ablation studies, including\nout-of-distribution evaluations, further validate the effectiveness of our\napproach.PRG is available at https://github.com/opendilab/PRG.", "AI": {"tldr": "PRG leverages pretrained generative models for discriminative tasks by reversing the generative process, achieving state-of-the-art performance.", "motivation": "To explore the underutilized potential of generative models in discriminative tasks and overcome limitations of prior generative classifiers.", "method": "Pretrained Reversible Generation (PRG) extracts unsupervised representations by reversing a pretrained generative model's process, enabling flexible feature selection.", "result": "PRG outperforms prior methods, achieving 78% top-1 accuracy on ImageNet (64x64) and robust performance in benchmarks.", "conclusion": "PRG effectively repurposes generative models for discriminative tasks, offering generalizable and high-capacity feature extraction."}}
{"id": "2412.14030", "pdf": "https://arxiv.org/pdf/2412.14030", "abs": "https://arxiv.org/abs/2412.14030", "authors": ["Eivind B\u00f8hn", "S\u00f8lve Eidnes", "Kjell Rune Jonassen"], "title": "Machine learning in wastewater treatment: insights from modelling a pilot denitrification reactor", "categories": ["cs.LG"], "comment": "v2: Clarified explanations and analysis, corrected minor errors", "summary": "Wastewater treatment plants are increasingly recognized as promising\ncandidates for machine learning applications, due to their societal importance\nand high availability of data. However, their varied designs, operational\nconditions, and influent characteristics hinder straightforward automation. In\nthis study, we use data from a pilot reactor at the Veas treatment facility in\nNorway to explore how machine learning can be used to optimize biological\nnitrate ($\\mathrm{NO_3^-}$) reduction to molecular nitrogen ($\\mathrm{N_2}$) in\nthe biogeochemical process known as \\textit{denitrification}. Rather than\nfocusing solely on predictive accuracy, our approach prioritizes understanding\nthe foundational requirements for effective data-driven modelling of wastewater\ntreatment. Specifically, we aim to identify which process parameters are most\ncritical, the necessary data quantity and quality, how to structure data\neffectively, and what properties are required by the models. We find that\nnonlinear models perform best on the training and validation data sets,\nindicating nonlinear relationships to be learned, but linear models transfer\nbetter to the unseen test data, which comes later in time. The variable\nmeasuring the water temperature has a particularly detrimental effect on the\nmodels, owing to a significant change in distributions between training and\ntest data. We therefore conclude that multiple years of data is necessary to\nlearn robust machine learning models. By addressing foundational elements,\nparticularly in the context of the climatic variability faced by northern\nregions, this work lays the groundwork for a more structured and tailored\napproach to machine learning for wastewater treatment. We share publicly both\nthe data and code used to produce the results in the paper.", "AI": {"tldr": "Machine learning is applied to optimize denitrification in wastewater treatment, focusing on foundational requirements like data quality and model properties. Nonlinear models perform best on training data, but linear models generalize better to unseen test data. Temperature variability impacts model robustness, necessitating multi-year data for reliable results.", "motivation": "Wastewater treatment plants are important and data-rich, but their varied designs and conditions complicate automation. This study explores machine learning to optimize denitrification, prioritizing foundational modeling requirements over just predictive accuracy.", "method": "Data from a pilot reactor in Norway is used to evaluate machine learning for denitrification. The study identifies critical process parameters, data needs, and model properties, comparing nonlinear and linear models.", "result": "Nonlinear models excel on training data, but linear models generalize better to unseen test data. Temperature variability significantly affects model performance, highlighting the need for multi-year data.", "conclusion": "Multi-year data is essential for robust models in wastewater treatment, especially in variable climates. The study provides a structured approach to machine learning in this domain and shares data and code publicly."}}
{"id": "2506.24123", "pdf": "https://arxiv.org/pdf/2506.24123", "abs": "https://arxiv.org/abs/2506.24123", "authors": ["Yue Ma", "Qingyan Bai", "Hao Ouyang", "Ka Leong Cheng", "Qiuyu Wang", "Hongyu Liu", "Zichen Liu", "Haofan Wang", "Jingye Chen", "Yujun Shen", "Qifeng Chen"], "title": "Calligrapher: Freestyle Text Image Customization", "categories": ["cs.CV"], "comment": "Project page: https://calligrapher2025.github.io/Calligrapher Code:\n  https://github.com/Calligrapher2025/Calligrapher", "summary": "We introduce Calligrapher, a novel diffusion-based framework that\ninnovatively integrates advanced text customization with artistic typography\nfor digital calligraphy and design applications. Addressing the challenges of\nprecise style control and data dependency in typographic customization, our\nframework incorporates three key technical contributions. First, we develop a\nself-distillation mechanism that leverages the pre-trained text-to-image\ngenerative model itself alongside the large language model to automatically\nconstruct a style-centric typography benchmark. Second, we introduce a\nlocalized style injection framework via a trainable style encoder, which\ncomprises both Qformer and linear layers, to extract robust style features from\nreference images. An in-context generation mechanism is also employed to\ndirectly embed reference images into the denoising process, further enhancing\nthe refined alignment of target styles. Extensive quantitative and qualitative\nevaluations across diverse fonts and design contexts confirm Calligrapher's\naccurate reproduction of intricate stylistic details and precise glyph\npositioning. By automating high-quality, visually consistent typography,\nCalligrapher surpasses traditional models, empowering creative practitioners in\ndigital art, branding, and contextual typographic design.", "AI": {"tldr": "Calligrapher is a diffusion-based framework for digital calligraphy, combining text customization and artistic typography with self-distillation, localized style injection, and in-context generation for precise style control.", "motivation": "Addresses challenges in typographic customization, such as style control and data dependency, to automate high-quality, visually consistent typography.", "method": "Uses self-distillation to create a style-centric benchmark, a trainable style encoder for feature extraction, and in-context generation for style alignment.", "result": "Accurately reproduces stylistic details and glyph positioning, outperforming traditional models in diverse fonts and design contexts.", "conclusion": "Calligrapher enhances digital art, branding, and typographic design by automating high-quality typography."}}
{"id": "2412.04062", "pdf": "https://arxiv.org/pdf/2412.04062", "abs": "https://arxiv.org/abs/2412.04062", "authors": ["Yefei He", "Feng Chen", "Yuanyu He", "Shaoxuan He", "Hong Zhou", "Kaipeng Zhang", "Bohan Zhuang"], "title": "ZipAR: Parallel Auto-regressive Image Generation through Spatial Locality", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages", "summary": "In this paper, we propose ZipAR, a training-free, plug-and-play parallel\ndecoding framework for accelerating auto-regressive (AR) visual generation. The\nmotivation stems from the observation that images exhibit local structures, and\nspatially distant regions tend to have minimal interdependence. Given a\npartially decoded set of visual tokens, in addition to the original next-token\nprediction scheme in the row dimension, the tokens corresponding to spatially\nadjacent regions in the column dimension can be decoded in parallel, enabling\nthe ``next-set prediction'' paradigm. By decoding multiple tokens\nsimultaneously in a single forward pass, the number of forward passes required\nto generate an image is significantly reduced, resulting in a substantial\nimprovement in generation efficiency. Experiments demonstrate that ZipAR can\nreduce the number of model forward passes by up to 91% on the Emu3-Gen model\nwithout requiring any additional retraining. Code is available here:\nhttps://github.com/ThisisBillhe/ZipAR.", "AI": {"tldr": "ZipAR is a training-free, parallel decoding framework for accelerating auto-regressive visual generation by decoding multiple tokens simultaneously, reducing forward passes by up to 91%.", "motivation": "Images exhibit local structures with minimal interdependence between distant regions, enabling parallel decoding of spatially adjacent tokens.", "method": "Proposes a \"next-set prediction\" paradigm where tokens in adjacent regions are decoded in parallel alongside the original row-wise prediction.", "result": "ZipAR reduces forward passes by up to 91% on the Emu3-Gen model without retraining.", "conclusion": "ZipAR significantly improves generation efficiency by leveraging parallel decoding, making it a practical plug-and-play solution."}}
{"id": "2412.20892", "pdf": "https://arxiv.org/pdf/2412.20892", "abs": "https://arxiv.org/abs/2412.20892", "authors": ["Freddie Bickford Smith", "Jannik Kossen", "Eleanor Trollope", "Mark van der Wilk", "Adam Foster", "Tom Rainforth"], "title": "Rethinking Aleatoric and Epistemic Uncertainty", "categories": ["cs.LG", "stat.ML"], "comment": "Published at ICML 2025", "summary": "The ideas of aleatoric and epistemic uncertainty are widely used to reason\nabout the probabilistic predictions of machine-learning models. We identify\nincoherence in existing discussions of these ideas and suggest this stems from\nthe aleatoric-epistemic view being insufficiently expressive to capture all the\ndistinct quantities that researchers are interested in. To address this we\npresent a decision-theoretic perspective that relates rigorous notions of\nuncertainty, predictive performance and statistical dispersion in data. This\nserves to support clearer thinking as the field moves forward. Additionally we\nprovide insights into popular information-theoretic quantities, showing they\ncan be poor estimators of what they are often purported to measure, while also\nexplaining how they can still be useful in guiding data acquisition.", "AI": {"tldr": "The paper critiques the aleatoric-epistemic uncertainty framework as insufficiently expressive and proposes a decision-theoretic perspective to clarify uncertainty, predictive performance, and data dispersion. It also evaluates information-theoretic quantities, noting their limitations and utility in data acquisition.", "motivation": "Existing discussions of aleatoric and epistemic uncertainty are incoherent and lack expressiveness, prompting the need for a clearer framework.", "method": "The authors adopt a decision-theoretic perspective to rigorously relate uncertainty, predictive performance, and statistical dispersion.", "result": "The proposed framework clarifies uncertainty discussions, and insights reveal that information-theoretic quantities can be poor estimators but useful for data acquisition.", "conclusion": "A decision-theoretic approach improves clarity in uncertainty discussions, and information-theoretic measures, despite limitations, aid in guiding data acquisition."}}
{"id": "2506.24127", "pdf": "https://arxiv.org/pdf/2506.24127", "abs": "https://arxiv.org/abs/2506.24127", "authors": ["Matthew Gwilliam", "Roy Zhang", "Namitha Padmanabhan", "Hongyang Du", "Abhinav Shrivastava"], "title": "How to Design and Train Your Implicit Neural Representation for Video Compression", "categories": ["cs.CV"], "comment": "21 pages, 41 figures, 5 tables", "summary": "Implicit neural representation (INR) methods for video compression have\nrecently achieved visual quality and compression ratios that are competitive\nwith traditional pipelines. However, due to the need for per-sample network\ntraining, the encoding speeds of these methods are too slow for practical\nadoption. We develop a library to allow us to disentangle and review the\ncomponents of methods from the NeRV family, reframing their performance in\nterms of not only size-quality trade-offs, but also impacts on training time.\nWe uncover principles for effective video INR design and propose a\nstate-of-the-art configuration of these components, Rabbit NeRV (RNeRV). When\nall methods are given equal training time (equivalent to 300 NeRV epochs) for 7\ndifferent UVG videos at 1080p, RNeRV achieves +1.27% PSNR on average compared\nto the best-performing alternative for each video in our NeRV library. We then\ntackle the encoding speed issue head-on by investigating the viability of\nhyper-networks, which predict INR weights from video inputs, to disentangle\ntraining from encoding to allow for real-time encoding. We propose masking the\nweights of the predicted INR during training to allow for variable, higher\nquality compression, resulting in 1.7% improvements to both PSNR and MS-SSIM at\n0.037 bpp on the UCF-101 dataset, and we increase hyper-network parameters by\n0.4% for 2.5%/2.7% improvements to PSNR/MS-SSIM with equal bpp and similar\nspeeds. Our project website is available at https://mgwillia.github.io/vinrb/\nand our code is available at https://github.com/mgwillia/vinrb.", "AI": {"tldr": "The paper introduces Rabbit NeRV (RNeRV), an improved implicit neural representation (INR) method for video compression, addressing slow encoding speeds and achieving better performance in quality and training time. It also explores hyper-networks for real-time encoding.", "motivation": "Current INR methods for video compression suffer from slow encoding speeds due to per-sample network training, limiting practical adoption. The paper aims to improve efficiency and performance.", "method": "The authors develop a library to analyze NeRV family methods, propose RNeRV for better performance, and investigate hyper-networks for real-time encoding by masking predicted INR weights.", "result": "RNeRV achieves +1.27% PSNR improvement over alternatives under equal training time. Hyper-network experiments show 1.7% PSNR/MS-SSIM improvements at 0.037 bpp.", "conclusion": "The paper advances INR-based video compression with RNeRV and hyper-networks, improving quality and addressing encoding speed issues."}}
{"id": "2412.10493", "pdf": "https://arxiv.org/pdf/2412.10493", "abs": "https://arxiv.org/abs/2412.10493", "authors": ["Runtao Liu", "I Chieh Chen", "Jindong Gu", "Jipeng Zhang", "Renjie Pi", "Qifeng Chen", "Philip Torr", "Ashkan Khakzar", "Fabio Pizzati"], "title": "AlignGuard: Scalable Safety Alignment for Text-to-Image Generation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Text-to-image (T2I) models are widespread, but their limited safety\nguardrails expose end users to harmful content and potentially allow for model\nmisuse. Current safety measures are typically limited to text-based filtering\nor concept removal strategies, able to remove just a few concepts from the\nmodel's generative capabilities. In this work, we introduce AlignGuard, a\nmethod for safety alignment of T2I models. We enable the application of Direct\nPreference Optimization (DPO) for safety purposes in T2I models by\nsynthetically generating a dataset of harmful and safe image-text pairs, which\nwe call CoProV2. Using a custom DPO strategy and this dataset, we train safety\nexperts, in the form of low-rank adaptation (LoRA) matrices, able to guide the\ngeneration process away from specific safety-related concepts. Then, we merge\nthe experts into a single LoRA using a novel merging strategy for optimal\nscaling performance. This expert-based approach enables scalability, allowing\nus to remove 7x more harmful concepts from T2I models compared to baselines.\nAlignGuard consistently outperforms the state-of-the-art on many benchmarks and\nestablishes new practices for safety alignment in T2I networks. Code and data\nwill be shared at https://safetydpo.github.io/.", "AI": {"tldr": "AlignGuard introduces a method for safety alignment in T2I models using synthetic datasets and DPO, outperforming baselines by removing 7x more harmful concepts.", "motivation": "Current T2I models lack robust safety measures, exposing users to harmful content. Existing methods are limited in scope and effectiveness.", "method": "AlignGuard uses synthetic datasets (CoProV2) and a custom DPO strategy to train safety experts (LoRA matrices), merging them for optimal performance.", "result": "AlignGuard removes 7x more harmful concepts than baselines and outperforms state-of-the-art benchmarks.", "conclusion": "AlignGuard sets new standards for safety alignment in T2I models, offering scalability and effectiveness."}}
{"id": "2501.07423", "pdf": "https://arxiv.org/pdf/2501.07423", "abs": "https://arxiv.org/abs/2501.07423", "authors": ["Muhammad Umair Danish", "Mathumitha Sureshkumar", "Tehara Fonseka", "Umeshika Uthayakumar", "Vinura Galwaduge"], "title": "An Investigation into Seasonal Variations in Energy Forecasting for Student Residences", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This research provides an in-depth evaluation of various machine learning\nmodels for energy forecasting, focusing on the unique challenges of seasonal\nvariations in student residential settings. The study assesses the performance\nof baseline models, such as LSTM and GRU, alongside state-of-the-art\nforecasting methods, including Autoregressive Feedforward Neural Networks,\nTransformers, and hybrid approaches. Special attention is given to predicting\nenergy consumption amidst challenges like seasonal patterns, vacations,\nmeteorological changes, and irregular human activities that cause sudden\nfluctuations in usage. The findings reveal that no single model consistently\noutperforms others across all seasons, emphasizing the need for season-specific\nmodel selection or tailored designs. Notably, the proposed Hyper Network based\nLSTM and MiniAutoEncXGBoost models exhibit strong adaptability to seasonal\nvariations, effectively capturing abrupt changes in energy consumption during\nsummer months. This study advances the energy forecasting field by emphasizing\nthe critical role of seasonal dynamics and model-specific behavior in achieving\naccurate predictions.", "AI": {"tldr": "Evaluation of machine learning models for energy forecasting in student residences, highlighting seasonal challenges and model adaptability.", "motivation": "Address the unique challenges of seasonal variations and irregular human activities in energy forecasting for student residential settings.", "method": "Assessed baseline models (LSTM, GRU) and advanced methods (Autoregressive Feedforward Neural Networks, Transformers, hybrid approaches) for energy forecasting.", "result": "No single model consistently outperforms others across all seasons; Hyper Network-based LSTM and MiniAutoEncXGBoost showed strong adaptability to seasonal changes.", "conclusion": "Season-specific model selection or tailored designs are crucial for accurate energy forecasting, emphasizing the role of seasonal dynamics."}}
{"id": "2506.21629", "pdf": "https://arxiv.org/pdf/2506.21629", "abs": "https://arxiv.org/abs/2506.21629", "authors": ["Chenhao Zhang", "Yezhi Shen", "Fengqing Zhu"], "title": "ICP-3DGS: SfM-free 3D Gaussian Splatting for Large-scale Unbounded Scenes", "categories": ["cs.GR", "cs.CV"], "comment": "6 pages, Source code is available at\n  https://github.com/Chenhao-Z/ICP-3DGS. To appear at ICIP 2025", "summary": "In recent years, neural rendering methods such as NeRFs and 3D Gaussian\nSplatting (3DGS) have made significant progress in scene reconstruction and\nnovel view synthesis. However, they heavily rely on preprocessed camera poses\nand 3D structural priors from structure-from-motion (SfM), which are\nchallenging to obtain in outdoor scenarios. To address this challenge, we\npropose to incorporate Iterative Closest Point (ICP) with optimization-based\nrefinement to achieve accurate camera pose estimation under large camera\nmovements. Additionally, we introduce a voxel-based scene densification\napproach to guide the reconstruction in large-scale scenes. Experiments\ndemonstrate that our approach ICP-3DGS outperforms existing methods in both\ncamera pose estimation and novel view synthesis across indoor and outdoor\nscenes of various scales. Source code is available at\nhttps://github.com/Chenhao-Z/ICP-3DGS.", "AI": {"tldr": "The paper introduces ICP-3DGS, a method combining ICP and optimization for camera pose estimation and voxel-based densification for large-scale scene reconstruction, outperforming existing techniques.", "motivation": "Neural rendering methods like NeRFs and 3DGS rely on preprocessed camera poses and 3D priors, which are hard to obtain outdoors. The paper aims to address this challenge.", "method": "Uses ICP with optimization-based refinement for camera pose estimation and voxel-based densification for scene reconstruction.", "result": "ICP-3DGS outperforms existing methods in pose estimation and novel view synthesis across diverse scenes.", "conclusion": "The proposed method effectively addresses limitations of current neural rendering techniques, offering improved performance in challenging scenarios."}}
{"id": "2501.05460", "pdf": "https://arxiv.org/pdf/2501.05460", "abs": "https://arxiv.org/abs/2501.05460", "authors": ["Gursimran Singh", "Xinglu Wang", "Yifan Hu", "Timothy Yu", "Linzi Xing", "Wei Jiang", "Zhefeng Wang", "Xiaolong Bai", "Yi Li", "Ying Xiong", "Yong Zhang", "Zhenan Fan"], "title": "Efficiently Serving Large Multimodal Models Using EPD Disaggregation", "categories": ["cs.DC", "cs.AI", "cs.CV", "cs.LG"], "comment": "17 pages, 12 figures, 9 tables", "summary": "Large Multimodal Models (LMMs) extend Large Language Models (LLMs) by\nhandling diverse inputs such as images, audio, and video, but at the cost of\nadding a multimodal encoding stage that increases both computational and memory\noverhead. This step negatively affects key Service Level Objectives (SLOs),\nsuch as time to first token (TTFT) and time per output token (TPOT). We\nintroduce Encode-Prefill-Decode (EPD) Disaggregation, a novel framework that\nseparates the encoding, prefill, and decode stages onto dedicated resources.\nUnlike current systems, which bundle encoding and prefill together, our\napproach decouples these steps, unlocking new opportunities and optimizations.\nThese include a mechanism to cache multimedia tokens for efficient transfer, a\nnovel way to parallelize the encoding load within a request, a module for\noptimal resource allocation for disaggregated serving, and a novel\nrole-switching method to handle changing workload characteristics. Experimental\nevaluations with popular LMMs show substantial gains in memory efficiency (up\nto 15x lower peak memory utilization), batch sizes (up to 22x larger), 10x more\nimages per request, and 2.2x larger KV caches. Furthermore, it leads to\nsignificant improvements in SLO attainment (up to 90-100% improvement) and TTFT\n(up to 71% reduction), compared to systems that do not disaggregate. The code\nis available at https://github.com/vbdi/epdserve.", "AI": {"tldr": "The paper introduces Encode-Prefill-Decode (EPD) Disaggregation, a framework to improve efficiency in Large Multimodal Models by separating encoding, prefill, and decode stages, leading to significant performance gains.", "motivation": "Current systems bundle encoding and prefill, causing computational and memory overhead, negatively impacting Service Level Objectives (SLOs) like time to first token (TTFT) and time per output token (TPOT).", "method": "EPD Disaggregation decouples encoding, prefill, and decode stages, enabling optimizations like caching multimedia tokens, parallelizing encoding, optimal resource allocation, and role-switching for dynamic workloads.", "result": "Experiments show 15x lower memory use, 22x larger batch sizes, 10x more images per request, 2.2x larger KV caches, and up to 90-100% SLO improvement with 71% TTFT reduction.", "conclusion": "EPD Disaggregation significantly enhances LMM efficiency and performance, offering a scalable solution for multimodal model serving."}}
{"id": "2501.14694", "pdf": "https://arxiv.org/pdf/2501.14694", "abs": "https://arxiv.org/abs/2501.14694", "authors": ["Zhong Li", "Yuhang Wang", "Matthijs van Leeuwen"], "title": "Towards Automated Self-Supervised Learning for Truly Unsupervised Graph Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": "Manuscript accepted by Data Mining and Knowledge Discovery for\n  publication (June 2025). This is the final revised version", "summary": "Self-supervised learning (SSL) is an emerging paradigm that exploits\nsupervisory signals generated from the data itself, and many recent studies\nhave leveraged SSL to conduct graph anomaly detection. However, we empirically\nfound that three important factors can substantially impact detection\nperformance across datasets: 1) the specific SSL strategy employed; 2) the\ntuning of the strategy's hyperparameters; and 3) the allocation of combination\nweights when using multiple strategies. Most SSL-based graph anomaly detection\nmethods circumvent these issues by arbitrarily or selectively (i.e., guided by\nlabel information) choosing SSL strategies, hyperparameter settings, and\ncombination weights. While an arbitrary choice may lead to subpar performance,\nusing label information in an unsupervised setting is label information leakage\nand leads to severe overestimation of a method's performance. Leakage has been\ncriticized as \"one of the top ten data mining mistakes\", yet many recent\nstudies on SSL-based graph anomaly detection have been using label information\nto select hyperparameters. To mitigate this issue, we propose to use an\ninternal evaluation strategy (with theoretical analysis) to select\nhyperparameters in SSL for unsupervised anomaly detection. We perform extensive\nexperiments using 10 recent SSL-based graph anomaly detection algorithms on\nvarious benchmark datasets, demonstrating both the prior issues with\nhyperparameter selection and the effectiveness of our proposed strategy.", "AI": {"tldr": "The paper highlights issues in SSL-based graph anomaly detection, such as arbitrary hyperparameter choices and label leakage, and proposes an internal evaluation strategy to improve performance.", "motivation": "Current SSL-based graph anomaly detection methods often rely on arbitrary or label-guided hyperparameter choices, leading to subpar performance or label leakage.", "method": "The authors propose an internal evaluation strategy for hyperparameter selection in SSL, supported by theoretical analysis and extensive experiments.", "result": "Experiments on benchmark datasets show the issues with prior hyperparameter selection methods and validate the effectiveness of the proposed strategy.", "conclusion": "The internal evaluation strategy mitigates label leakage and improves performance in SSL-based graph anomaly detection."}}
{"id": "2506.22467", "pdf": "https://arxiv.org/pdf/2506.22467", "abs": "https://arxiv.org/abs/2506.22467", "authors": ["Roy Colglazier", "Jisoo Lee", "Haoyu Dong", "Hanxue Gu", "Yaqian Chen", "Joseph Cao", "Zafer Yildiz", "Zhonghao Liu", "Nicholas Konz", "Jichen Yang", "Jikai Zhang", "Yuwen Chen", "Lin Li", "Adrian Camarena", "Maciej A. Mazurowski"], "title": "SegmentAnyMuscle: A universal muscle segmentation model across different locations in MRI", "categories": ["eess.SP", "cs.CV"], "comment": "24 pages, 6 figures", "summary": "The quantity and quality of muscles are increasingly recognized as important\npredictors of health outcomes. While MRI offers a valuable modality for such\nassessments, obtaining precise quantitative measurements of musculature remains\nchallenging. This study aimed to develop a publicly available model for muscle\nsegmentation in MRIs and demonstrate its applicability across various\nanatomical locations and imaging sequences. A total of 362 MRIs from 160\npatients at a single tertiary center (Duke University Health System, 2016-2020)\nwere included, with 316 MRIs from 114 patients used for model development. The\nmodel was tested on two separate sets: one with 28 MRIs representing common\nsequence types, achieving an average Dice Similarity Coefficient (DSC) of\n88.45%, and another with 18 MRIs featuring less frequent sequences and\nabnormalities such as muscular atrophy, hardware, and significant noise,\nachieving 86.21% DSC. These results demonstrate the feasibility of a fully\nautomated deep learning algorithm for segmenting muscles on MRI across diverse\nsettings. The public release of this model enables consistent, reproducible\nresearch into the relationship between musculature and health.", "AI": {"tldr": "A deep learning model for automated muscle segmentation in MRIs was developed and tested, showing high accuracy across diverse imaging conditions.", "motivation": "Precise quantitative muscle measurements in MRIs are challenging but crucial for health outcome predictions.", "method": "A publicly available deep learning model was trained on 316 MRIs from 114 patients and tested on two sets (46 MRIs total) with varying conditions.", "result": "The model achieved high accuracy (DSC of 88.45% and 86.21%) across common and challenging MRI sequences.", "conclusion": "The model enables consistent, reproducible research on musculature and health, with potential for broad clinical and research applications."}}
{"id": "2501.14406", "pdf": "https://arxiv.org/pdf/2501.14406", "abs": "https://arxiv.org/abs/2501.14406", "authors": ["Fei Wu", "Jia Hu", "Geyong Min", "Shiqiang Wang"], "title": "Adaptive Rank Allocation for Federated Parameter-Efficient Fine-Tuning of Language Models", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.NI"], "comment": null, "summary": "Pre-trained Language Models (PLMs) have demonstrated their superiority and\nversatility in modern Natural Language Processing (NLP), effectively adapting\nto various downstream tasks through further fine-tuning. Federated\nParameter-Efficient Fine-Tuning (FedPEFT) has emerged as a promising solution\nto address privacy and efficiency challenges in distributed training for PLMs\non resource-constrained local devices. However, our measurements reveal two key\nlimitations of FedPEFT: heterogeneous data across devices exacerbates\nperformance degradation of low-rank adaptation, and a fixed parameter\nconfiguration results in communication inefficiency. To overcome these\nlimitations, we propose FedARA, a novel Adaptive Rank Allocation framework for\nfederated parameter-efficient fine-tuning of language models. Specifically,\nFedARA employs truncated Singular Value Decomposition (SVD) adaptation to\nenhance similar feature representation across clients, significantly mitigating\nthe adverse effects of data heterogeneity. Subsequently, it utilizes dynamic\nrank allocation to progressively identify critical ranks, effectively improving\ncommunication efficiency. Lastly, it leverages rank-based module pruning to\nautomatically remove inactive modules, steadily reducing local computational\ncost and memory usage in each federated learning round. Extensive experiments\nshow that FedARA consistently outperforms baselines by an average of 6.95% to\n8.49% across various datasets and models under heterogeneous data while\nsignificantly improving communication efficiency by 2.40$ \\times$. Moreover,\nexperiments on various edge devices demonstrate substantial decreases in total\ntraining time and energy consumption by up to 48.90% and 46.95%, respectively.", "AI": {"tldr": "FedARA is a novel Adaptive Rank Allocation framework for federated parameter-efficient fine-tuning of PLMs, addressing data heterogeneity and communication inefficiency in FedPEFT.", "motivation": "FedPEFT faces challenges like performance degradation due to data heterogeneity and communication inefficiency from fixed parameter configurations.", "method": "FedARA uses truncated SVD adaptation for similar feature representation, dynamic rank allocation for communication efficiency, and rank-based module pruning to reduce computational costs.", "result": "FedARA outperforms baselines by 6.95%-8.49%, improves communication efficiency by 2.40\u00d7, and reduces training time and energy consumption by up to 48.90% and 46.95%.", "conclusion": "FedARA effectively addresses FedPEFT limitations, enhancing performance and efficiency in federated learning for PLMs."}}
{"id": "2501.17599", "pdf": "https://arxiv.org/pdf/2501.17599", "abs": "https://arxiv.org/abs/2501.17599", "authors": ["Hao Guo", "Han Wang", "Di Zhu", "Lun Wu", "A. Stewart Fotheringham", "Yu Liu"], "title": "RegionGCN: Spatial-Heterogeneity-Aware Graph Convolutional Networks", "categories": ["cs.LG"], "comment": "29 pages, 6 figures", "summary": "Modeling spatial heterogeneity in the data generation process is essential\nfor understanding and predicting geographical phenomena. Despite their\nprevalence in geospatial tasks, neural network models usually assume spatial\nstationarity, which could limit their performance in the presence of spatial\nprocess heterogeneity. By allowing model parameters to vary over space, several\napproaches have been proposed to incorporate spatial heterogeneity into neural\nnetworks. However, current geographically weighting approaches are ineffective\non graph neural networks, yielding no significant improvement in prediction\naccuracy. We assume the crux lies in the over-fitting risk brought by a large\nnumber of local parameters. Accordingly, we propose to model spatial process\nheterogeneity at the regional level rather than at the individual level, which\nlargely reduces the number of spatially varying parameters. We further develop\na heuristic optimization procedure to learn the region partition adaptively in\nthe process of model training. Our proposed spatial-heterogeneity-aware graph\nconvolutional network, named RegionGCN, is applied to the spatial prediction of\ncounty-level vote share in the 2016 US presidential election based on\nsocioeconomic attributes. Results show that RegionGCN achieves significant\nimprovement over the basic and geographically weighted GCNs. We also offer an\nexploratory analysis tool for the spatial variation of non-linear relationships\nthrough ensemble learning of regional partitions from RegionGCN. Our work\ncontributes to the practice of Geospatial Artificial Intelligence (GeoAI) in\ntackling spatial heterogeneity.", "AI": {"tldr": "The paper introduces RegionGCN, a spatial-heterogeneity-aware graph convolutional network, to address spatial heterogeneity in neural networks by modeling heterogeneity at the regional level, improving prediction accuracy in geospatial tasks like the 2016 US presidential election.", "motivation": "Neural networks often assume spatial stationarity, limiting performance in spatially heterogeneous processes. Current geographically weighted approaches fail for graph neural networks, prompting the need for a better solution.", "method": "Proposes RegionGCN, which models spatial heterogeneity at the regional level to reduce over-fitting. Includes a heuristic optimization procedure for adaptive region partitioning during training.", "result": "RegionGCN outperforms basic and geographically weighted GCNs in predicting county-level vote shares, demonstrating significant accuracy improvements.", "conclusion": "RegionGCN effectively addresses spatial heterogeneity in GeoAI, offering a practical tool for spatial prediction and exploratory analysis of non-linear relationships."}}
{"id": "2506.22482", "pdf": "https://arxiv.org/pdf/2506.22482", "abs": "https://arxiv.org/abs/2506.22482", "authors": ["Divya Alok Gupta", "Dwith Chenna", "B. Aditya Vighnesh Ramakanth"], "title": "Wireless Home Automation Using Social Networking Websites", "categories": ["cs.NI", "cs.CR", "cs.CV"], "comment": "20th Annual International Conference on Advanced Computing and\n  Communications (ADCOM) 2014", "summary": "With the advent of Internet of Things, Wireless Home Automation Systems WHAS\nare gradually gaining popularity. These systems are faced with multiple\nchallenges such as security; controlling a variety of home appliances with a\nsingle interface and user friendliness. In this paper we propose a system that\nuses secure authentication systems of social networking websites such as\nTwitter, tracks the end-users activities on the social network and then control\nhis or her domestic appliances. At the end, we highlight the applications of\nthe proposed WHAS and compare the advantages of our proposed system over\ntraditional home automation systems.", "AI": {"tldr": "A secure WHAS using social media authentication (e.g., Twitter) to control home appliances, addressing security and usability challenges.", "motivation": "To overcome security and usability issues in WHAS by leveraging social media authentication.", "method": "Uses social networking authentication (Twitter) to track user activities and control appliances.", "result": "Proposed system offers enhanced security and user-friendliness compared to traditional WHAS.", "conclusion": "The system demonstrates practical applications and advantages over conventional home automation solutions."}}
{"id": "2502.00801", "pdf": "https://arxiv.org/pdf/2502.00801", "abs": "https://arxiv.org/abs/2502.00801", "authors": ["Zhiwei Huang", "Jiaqi Li", "Ping Zhong", "Rui Fan"], "title": "Environment-Driven Online LiDAR-Camera Extrinsic Calibration", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "LiDAR-camera extrinsic calibration (LCEC) is crucial for multi-modal data\nfusion in mechatronics. Existing methods, whether target-based or target-free,\ntypically rely on customized calibration targets or fixed scene types, limiting\ntheir practicality in real-world applications. To address these challenges, we\nintroduce EdO-LCEC, the first environment-driven online calibration approach.\nUnlike traditional target-free methods, EdO-LCEC observes the feature density\nof the application environment through a generalizable scene discriminator.\nBased on this feature density, EdO-LCEC extracts LiDAR intensity and depth\nfeatures from varying perspectives to achieve higher calibration accuracy. To\novercome the challenges of cross-modal feature matching between LiDAR and\ncamera, we propose dual-path correspondence matching (DPCM), which leverages\nboth structural and textural consistency for reliable 3D-2D correspondences.\nAdditionally, our approach models the calibration process as a joint\noptimization problem utilizing global constraints from multiple views and\nscenes to enhance accuracy. Extensive experiments on real-world datasets\ndemonstrate that EdO-LCEC outperforms state-of-the-art methods, particularly in\nsparse or partially overlapping sensor views.", "AI": {"tldr": "EdO-LCEC is an environment-driven online LiDAR-camera extrinsic calibration method that improves accuracy by leveraging feature density and dual-path correspondence matching, outperforming existing methods.", "motivation": "Existing LiDAR-camera calibration methods rely on fixed scenes or targets, limiting practicality. EdO-LCEC aims to overcome these limitations by adapting to the environment dynamically.", "method": "EdO-LCEC uses a scene discriminator to observe feature density, extracts LiDAR intensity and depth features, and employs dual-path correspondence matching (DPCM) for cross-modal feature matching. It models calibration as a joint optimization problem with global constraints.", "result": "EdO-LCEC achieves higher accuracy than state-of-the-art methods, especially in sparse or partially overlapping sensor views, as validated by real-world experiments.", "conclusion": "EdO-LCEC offers a practical and accurate solution for LiDAR-camera extrinsic calibration, addressing limitations of traditional methods and excelling in dynamic environments."}}
{"id": "2501.17653", "pdf": "https://arxiv.org/pdf/2501.17653", "abs": "https://arxiv.org/abs/2501.17653", "authors": ["Pallavi Sharma", "Jorge-Humberto Urrea-Quintero", "Bogdan Bogdan", "Adrian-Dumitru Ciotec", "Laura Vasilie", "Henning Wessels", "Matteo Skull"], "title": "Drivetrain simulation using variational autoencoders", "categories": ["cs.LG", "cs.CE", "eess.SP"], "comment": "27 pages", "summary": "This work proposes variational autoencoders (VAEs) to predict a vehicle's\njerk signals from torque demand in the context of limited real-world drivetrain\ndatasets. We implement both unconditional and conditional VAEs, trained on\nexperimental data from two variants of a fully electric SUV with differing\ntorque and drivetrain configurations. The VAEs synthesize jerk signals that\ncapture characteristics from multiple drivetrain scenarios by leveraging the\nlearned latent space. A performance comparison with baseline physics-based and\nhybrid models confirms the effectiveness of the VAEs, without requiring\ndetailed system parametrization. Unconditional VAEs generate realistic jerk\nsignals without prior system knowledge, while conditional VAEs enable the\ngeneration of signals tailored to specific torque inputs. This approach reduces\nthe dependence on costly and time-intensive real-world experiments and\nextensive manual modeling. The results support the integration of generative\nmodels such as VAEs into drivetrain simulation pipelines, both for data\naugmentation and for efficient exploration of complex operational scenarios,\nwith the potential to streamline validation and accelerate vehicle development.", "AI": {"tldr": "VAEs predict vehicle jerk signals from torque demand, reducing reliance on real-world data and manual modeling.", "motivation": "Limited real-world drivetrain datasets and the need to reduce costly experiments and manual modeling.", "method": "Unconditional and conditional VAEs trained on experimental data from electric SUVs, leveraging latent space for jerk signal synthesis.", "result": "VAEs outperform physics-based and hybrid models, generating realistic or tailored jerk signals without detailed system knowledge.", "conclusion": "VAEs can enhance drivetrain simulations for data augmentation and scenario exploration, speeding up vehicle development."}}
{"id": "2506.22568", "pdf": "https://arxiv.org/pdf/2506.22568", "abs": "https://arxiv.org/abs/2506.22568", "authors": ["Gladston Moreira", "Ivan Meneghini", "Elzabeth Wanner"], "title": "Maximum Dispersion, Maximum Concentration: Enhancing the Quality of MOP Solutions", "categories": ["math.OC", "cs.CV"], "comment": "11 pages", "summary": "Multi-objective optimization problems (MOPs) often require a trade-off\nbetween conflicting objectives, maximizing diversity and convergence in the\nobjective space. This study presents an approach to improve the quality of MOP\nsolutions by optimizing the dispersion in the decision space and the\nconvergence in a specific region of the objective space. Our approach defines a\nRegion of Interest (ROI) based on a cone representing the decision maker's\npreferences in the objective space, while enhancing the dispersion of solutions\nin the decision space using a uniformity measure. Combining solution\nconcentration in the objective space with dispersion in the decision space\nintensifies the search for Pareto-optimal solutions while increasing solution\ndiversity. When combined, these characteristics improve the quality of\nsolutions and avoid the bias caused by clustering solutions in a specific\nregion of the decision space. Preliminary experiments suggest that this method\nenhances multi-objective optimization by generating solutions that effectively\nbalance dispersion and concentration, thereby mitigating bias in the decision\nspace.", "AI": {"tldr": "The paper introduces a method to improve multi-objective optimization by balancing dispersion in the decision space and convergence in a specific objective space region, enhancing solution quality and diversity.", "motivation": "Addressing the trade-off between conflicting objectives in MOPs and avoiding bias from clustered solutions in the decision space.", "method": "Defines a Region of Interest (ROI) based on decision maker preferences, optimizes dispersion in the decision space, and combines it with convergence in the objective space.", "result": "Preliminary experiments show improved solution quality and diversity by balancing dispersion and concentration.", "conclusion": "The approach effectively mitigates bias and enhances multi-objective optimization by optimizing both decision and objective spaces."}}
{"id": "2502.03607", "pdf": "https://arxiv.org/pdf/2502.03607", "abs": "https://arxiv.org/abs/2502.03607", "authors": ["Jinhao Liang", "Jacob K Christopher", "Sven Koenig", "Ferdinando Fioretto"], "title": "Simultaneous Multi-Robot Motion Planning with Projected Diffusion Models", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Published at the Forty-Second International Conference on Machine\n  Learning (ICML 2025)", "summary": "Recent advances in diffusion models hold significant potential in robotics,\nenabling the generation of diverse and smooth trajectories directly from raw\nrepresentations of the environment. Despite this promise, applying diffusion\nmodels to motion planning remains challenging due to their difficulty in\nenforcing critical constraints, such as collision avoidance and kinematic\nfeasibility. These limitations become even more pronounced in Multi-Robot\nMotion Planning (MRMP), where multiple robots must coordinate in shared spaces.\nTo address these challenges, this work proposes Simultaneous MRMP Diffusion\n(SMD), a novel approach integrating constrained optimization into the diffusion\nsampling process to produce collision-free, kinematically feasible\ntrajectories. Additionally, the paper introduces a comprehensive MRMP benchmark\nto evaluate trajectory planning algorithms across scenarios with varying robot\ndensities, obstacle complexities, and motion constraints. Experimental results\nshow SMD consistently outperforms classical and other learning-based motion\nplanners, achieving higher success rates and efficiency in complex multi-robot\nenvironments.", "AI": {"tldr": "SMD integrates constrained optimization into diffusion models for MRMP, outperforming existing planners in complex environments.", "motivation": "Diffusion models struggle with enforcing constraints like collision avoidance in MRMP, limiting their practical application.", "method": "Proposes SMD, combining constrained optimization with diffusion sampling for feasible, collision-free trajectories.", "result": "SMD achieves higher success rates and efficiency compared to classical and learning-based planners.", "conclusion": "SMD effectively addresses MRMP challenges, demonstrating superior performance in complex scenarios."}}
{"id": "2501.18164", "pdf": "https://arxiv.org/pdf/2501.18164", "abs": "https://arxiv.org/abs/2501.18164", "authors": ["Kanata Oowada", "Hideaki Iiduka"], "title": "Faster Convergence of Riemannian Stochastic Gradient Descent with Increasing Batch Size", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "We have theoretically analyzed the use of Riemannian stochastic gradient\ndescent (RSGD) and found that using an increasing batch size leads to faster\nRSGD convergence rate than using a constant batch size not only with a constant\nlearning rate but also with a decaying learning rate, such as cosine annealing\ndecay and polynomial decay. The convergence rate of RSGD improves from\n$O(\\sqrt{T^{-1}+\\text{const.}})$ with a constant batch size to\n$O(T^{-\\frac{1}{2}})$ with an increasing batch size, where $T$ denotes the\nnumber of iterations. Using principal component analysis and low-rank matrix\ncompletion tasks, we investigated, both theoretically and numerically, how\nincreasing batch size affects computational time as measured by stochastic\nfirst-order oracle (SFO) complexity. Increasing batch size reduces the SFO\ncomplexity of RSGD. Furthermore, our numerical results demonstrated that\nincreasing batch size offers the advantages of both small and large constant\nbatch sizes.", "AI": {"tldr": "Using increasing batch sizes in Riemannian stochastic gradient descent (RSGD) improves convergence rates and reduces computational complexity compared to constant batch sizes.", "motivation": "To enhance the efficiency and convergence rate of RSGD by exploring the impact of increasing batch sizes.", "method": "Theoretical analysis and numerical experiments (PCA and low-rank matrix completion) to compare RSGD performance with increasing vs. constant batch sizes.", "result": "Increasing batch sizes improve convergence from $O(\\sqrt{T^{-1}+\\text{const.}})$ to $O(T^{-\\frac{1}{2}})$ and reduce SFO complexity.", "conclusion": "Increasing batch sizes in RSGD combines the benefits of small and large constant batch sizes, offering faster convergence and lower computational costs."}}
{"id": "2506.22826", "pdf": "https://arxiv.org/pdf/2506.22826", "abs": "https://arxiv.org/abs/2506.22826", "authors": ["Robert Beinert", "Jonas Bresch"], "title": "Denoising Multi-Color QR Codes and Stiefel-Valued Data by Relaxed Regularizations", "categories": ["math.OC", "cs.CV", "cs.NA", "math.NA", "94A08, 94A12, 65J22, 90C22, 90C25"], "comment": "9 pages, 2 figures, 3 algorithms", "summary": "The handling of manifold-valued data, for instance, plays a central role in\ncolor restoration tasks relying on circle- or sphere-valued color models, in\nthe study of rotational or directional information related to the special\northogonal group, and in Gaussian image processing, where the pixel statistics\nare interpreted as values on the hyperbolic sheet. Especially, to denoise these\nkind of data, there have been proposed several generalizations of total\nvariation (TV) and Tikhonov-type denoising models incorporating the underlying\nmanifolds. Recently, a novel, numerically efficient denoising approach has been\nintroduced, where the data are embedded in an Euclidean ambient space, the\nnon-convex manifolds are encoded by a series of positive semi-definite,\nfixed-rank matrices, and the rank constraint is relaxed to obtain a\nconvexification that can be solved using standard algorithms from convex\nanalysis. The aim of the present paper is to extent this approach to new kinds\nof data like multi-binary and Stiefel-valued data. Multi-binary data can, for\ninstance, be used to model multi-color QR codes whereas Stiefel-valued data\noccur in image and video-based recognition. For both new data types, we propose\nTV- and Tikhonov-based denoising modelstogether with easy-to-solve\nconvexification. All derived methods are evaluated on proof-of-concept,\nsynthetic experiments.", "AI": {"tldr": "The paper extends a convexification-based denoising approach to multi-binary and Stiefel-valued data, proposing TV- and Tikhonov-based models with synthetic experiments.", "motivation": "To address denoising challenges for manifold-valued data, particularly multi-binary (e.g., multi-color QR codes) and Stiefel-valued data (e.g., image/video recognition).", "method": "Embed data in Euclidean space, encode manifolds via fixed-rank matrices, relax rank constraints for convexification, and apply standard convex algorithms.", "result": "Proposed TV- and Tikhonov-based models for multi-binary and Stiefel-valued data, validated with synthetic experiments.", "conclusion": "The approach is effective for new data types, offering practical denoising solutions with convex relaxations."}}
{"id": "2502.03669", "pdf": "https://arxiv.org/pdf/2502.03669", "abs": "https://arxiv.org/abs/2502.03669", "authors": ["Yikai Wu", "Haoyu Zhao", "Sanjeev Arora"], "title": "Time to Rethink AI for Combinatorial Optimization: Classical Algorithms Remain Tough to Match", "categories": ["cs.LG", "cs.AI", "cs.DM", "math.OC", "stat.ML"], "comment": "28 pages, 6 figures, 98 tables", "summary": "This position paper argues that the machine learning community should\nfundamentally rethink how AI-inspired methods are developed and evaluated for\ncombinatorial optimization (CO). We present comprehensive empirical benchmarks\ncomparing various recent AI-inspired GPU-based methods with several classical\nCPU-based solvers on the Maximum Independent Set (MIS) problem. Strikingly,\neven on in-distribution random graphs, leading AI-inspired methods are\nconsistently outperformed by the state-of-the-art classical solver KaMIS, and\nsome AI-inspired methods frequently fail to surpass even the simplest\ndegree-based greedy heuristic. To better understand the source of these\nfailures, we introduce a novel analysis, serialization, which reveals that\nnon-backtracking AI methods, such as LTFT (based on GFlowNets), end up\nreasoning similarly to the simplest degree-based greedy heuristic, and thus\nworse than KaMIS.\n  Our findings reveal three core issues: (1) Limited benchmarks and evaluation\n- AI-inspired methods are often tested only on small instances with very\nlimited inference time, which covers up issues with scalability and resource\nusage; (2) Intrinsic hardness and learning limits - even under ideal,\nin-distribution conditions, learning-based approaches lag behind classical\nheuristics, highlighting inherent barriers that receive little attention; and\n(3) Insufficient use and understanding of classical heuristics - current\nlearning frameworks often neglect to incorporate effective classical\ntechniques.\n  Although we use MIS as a testbed, similar gaps and challenges have been\nreported in other combinatorial optimization problems, suggesting broader\nrelevance for our recommendations. We propose that future research must address\nthese issues by rigorous benchmarking, deepening understanding of learning\nlimitations, and integrating classical heuristics into AI-inspired methods.", "AI": {"tldr": "The paper critiques AI-inspired methods for combinatorial optimization, showing they underperform classical solvers like KaMIS on the Maximum Independent Set problem. It identifies three core issues and calls for better benchmarking, understanding learning limits, and integrating classical heuristics.", "motivation": "To highlight the underperformance of AI-inspired methods in combinatorial optimization compared to classical solvers and identify systemic issues in their development and evaluation.", "method": "Empirical benchmarks comparing AI-inspired GPU-based methods with classical CPU-based solvers on the Maximum Independent Set problem, supplemented by a novel serialization analysis.", "result": "AI-inspired methods consistently underperform classical solvers like KaMIS, often failing to surpass simple greedy heuristics. Serialization reveals their reasoning resembles basic heuristics.", "conclusion": "Future research must improve benchmarking, understand learning limitations, and integrate classical heuristics to advance AI-inspired methods in combinatorial optimization."}}
{"id": "2502.00361", "pdf": "https://arxiv.org/pdf/2502.00361", "abs": "https://arxiv.org/abs/2502.00361", "authors": ["Haitong Ma", "Tianyi Chen", "Kai Wang", "Na Li", "Bo Dai"], "title": "Efficient Online Reinforcement Learning for Diffusion Policy", "categories": ["cs.LG"], "comment": "17 pages, 5 figures", "summary": "Diffusion policies have achieved superior performance in imitation learning\nand offline reinforcement learning (RL) due to their rich expressiveness.\nHowever, the conventional diffusion training procedure requires samples from\ntarget distribution, which is impossible in online RL since we cannot sample\nfrom the optimal policy. Backpropagating policy gradient through the diffusion\nprocess incurs huge computational costs and instability, thus being expensive\nand not scalable. To enable efficient training of diffusion policies in online\nRL, we generalize the conventional denoising score matching by reweighting the\nloss function. The resulting Reweighted Score Matching (RSM) preserves the\noptimal solution and low computational cost of denoising score matching, while\neliminating the need to sample from the target distribution and allowing\nlearning to optimize value functions. We introduce two tractable reweighted\nloss functions to solve two commonly used policy optimization problems, policy\nmirror descent and max-entropy policy, resulting in two practical algorithms\nnamed Diffusion Policy Mirror Descent (DPMD) and Soft Diffusion Actor-Critic\n(SDAC). We conducted comprehensive comparisons on MuJoCo benchmarks. The\nempirical results show that the proposed algorithms outperform recent\ndiffusion-policy online RLs on most tasks, and the DPMD improves more than 120%\nover soft actor-critic on Humanoid and Ant.", "AI": {"tldr": "The paper introduces Reweighted Score Matching (RSM) to efficiently train diffusion policies in online RL, eliminating the need for target distribution samples. Two algorithms, DPMD and SDAC, outperform existing methods on MuJoCo benchmarks.", "motivation": "Conventional diffusion training in online RL is impractical due to the inability to sample from the optimal policy and high computational costs. RSM addresses these issues.", "method": "Generalizes denoising score matching by reweighting the loss function, leading to RSM. Introduces DPMD and SDAC for policy optimization.", "result": "DPMD and SDAC outperform recent diffusion-policy online RL methods, with DPMD showing a 120% improvement over soft actor-critic on Humanoid and Ant tasks.", "conclusion": "RSM enables efficient diffusion policy training in online RL, with DPMD and SDAC demonstrating superior performance on benchmarks."}}
{"id": "2506.22973", "pdf": "https://arxiv.org/pdf/2506.22973", "abs": "https://arxiv.org/abs/2506.22973", "authors": ["AmirHossein Naghi Razlighi", "Elaheh Badali Golezani", "Shohreh Kasaei"], "title": "Confident Splatting: Confidence-Based Compression of 3D Gaussian Splatting via Learnable Beta Distributions", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "3D Gaussian Splatting enables high-quality real-time rendering but often\nproduces millions of splats, resulting in excessive storage and computational\noverhead. We propose a novel lossy compression method based on learnable\nconfidence scores modeled as Beta distributions. Each splat's confidence is\noptimized through reconstruction-aware losses, enabling pruning of\nlow-confidence splats while preserving visual fidelity. The proposed approach\nis architecture-agnostic and can be applied to any Gaussian Splatting variant.\nIn addition, the average confidence values serve as a new metric to assess the\nquality of the scene. Extensive experiments demonstrate favorable trade-offs\nbetween compression and fidelity compared to prior work. Our code and data are\npublicly available at\nhttps://github.com/amirhossein-razlighi/Confident-Splatting", "AI": {"tldr": "A novel lossy compression method for 3D Gaussian Splatting using learnable confidence scores (Beta distributions) to reduce splats while maintaining visual quality.", "motivation": "Addressing the excessive storage and computational overhead from millions of splats in 3D Gaussian Splatting.", "method": "Uses learnable confidence scores modeled as Beta distributions, optimized via reconstruction-aware losses to prune low-confidence splats.", "result": "Achieves favorable trade-offs between compression and fidelity, with confidence values as a new quality metric.", "conclusion": "The method is architecture-agnostic, effective, and publicly available."}}
{"id": "2502.08769", "pdf": "https://arxiv.org/pdf/2502.08769", "abs": "https://arxiv.org/abs/2502.08769", "authors": ["Timoth\u00e9e Darcet", "Federico Baldassarre", "Maxime Oquab", "Julien Mairal", "Piotr Bojanowski"], "title": "Cluster and Predict Latent Patches for Improved Masked Image Modeling", "categories": ["cs.CV", "cs.AI"], "comment": "26 pages, 14 figures, accepted in TMLR 2025", "summary": "Masked Image Modeling (MIM) offers a promising approach to self-supervised\nrepresentation learning, however existing MIM models still lag behind the\nstate-of-the-art. In this paper, we systematically analyze target\nrepresentations, loss functions, and architectures, to introduce CAPI - a novel\npure-MIM framework that relies on the prediction of latent clusterings. Our\napproach leverages a clustering-based loss, which is stable to train, and\nexhibits promising scaling properties. Our ViT-L backbone, CAPI, achieves 83.8%\naccuracy on ImageNet and 32.1% mIoU on ADE20K with simple linear probes,\nsubstantially outperforming previous MIM methods and approaching the\nperformance of the current state-of-the-art, DINOv2. We release all our code\nand models.", "AI": {"tldr": "CAPI is a novel MIM framework using latent clustering prediction, achieving competitive performance with simple linear probes.", "motivation": "Existing MIM models underperform compared to state-of-the-art methods, prompting a systematic analysis of target representations, loss functions, and architectures.", "method": "Introduces CAPI, a pure-MIM framework with a clustering-based loss for stable training and scaling. Uses ViT-L backbone.", "result": "Achieves 83.8% accuracy on ImageNet and 32.1% mIoU on ADE20K, outperforming prior MIM methods and nearing DINOv2's performance.", "conclusion": "CAPI demonstrates the potential of MIM with clustering-based loss, offering a scalable and effective alternative to current methods."}}
{"id": "2502.01705", "pdf": "https://arxiv.org/pdf/2502.01705", "abs": "https://arxiv.org/abs/2502.01705", "authors": ["Xianglong Yan", "Tianao Zhang", "Zhiteng Li", "Yulun Zhang"], "title": "Progressive Binarization with Semi-Structured Pruning for LLMs", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) have achieved remarkable progress in natural\nlanguage processing, but their high computational and memory costs hinder\ndeployment on resource-constrained devices. Binarization, which reduces model\nweights to 1 bit, is a promising solution for efficient inference. However,\nbinarized LLMs still exhibit redundancy that can be further compressed.\nSemi-structured pruning offers a favorable trade-off between model performance\nand hardware efficiency, but naively combining it with binarization often leads\nto severe performance degradation. To address this, we propose Progressive\nBinarization with Semi-Structured Pruning (PBS$^2$P), a novel post-training\ncompression framework. We propose Stepwise semi-structured Pruning with\nBinarization Optimization (SPBO) to jointly reduce pruning and binarization\nerror. Additionally, we develop a Coarse-to-Fine Search (CFS) strategy to more\neffectively select pruning elements. Extensive experiments across multiple LLM\nfamilies show that PBS$^2$P consistently outperforms state-of-the-art binary\npost-training quantization methods in both perplexity and downstream accuracy.\nThe code and models will be available at:\nhttps://github.com/XIANGLONGYAN/PBS2P.", "AI": {"tldr": "PBS$^2$P is a post-training compression framework combining progressive binarization and semi-structured pruning to optimize LLMs for efficiency without severe performance loss.", "motivation": "High computational and memory costs of LLMs hinder deployment on resource-constrained devices, and existing binarization methods still leave redundancy.", "method": "Proposes PBS$^2$P with SPBO for joint pruning and binarization error reduction, and CFS for effective pruning element selection.", "result": "Outperforms state-of-the-art binary post-training quantization methods in perplexity and downstream accuracy.", "conclusion": "PBS$^2$P effectively balances efficiency and performance for LLM deployment."}}
{"id": "2506.23016", "pdf": "https://arxiv.org/pdf/2506.23016", "abs": "https://arxiv.org/abs/2506.23016", "authors": ["Tom\u00e1s Silva Santos Rocha", "Anastasiia Mikhailova", "Moreno I. Coco", "Jos\u00e9 Santos-Victor"], "title": "Deep Learning in Mild Cognitive Impairment Diagnosis using Eye Movements and Image Content in Visual Memory Tasks", "categories": ["cs.HC", "cs.CV"], "comment": "13 pages, 5 figures", "summary": "The global prevalence of dementia is projected to double by 2050,\nhighlighting the urgent need for scalable diagnostic tools. This study utilizes\ndigital cognitive tasks with eye-tracking data correlated with memory processes\nto distinguish between Healthy Controls (HC) and Mild Cognitive Impairment\n(MCI), a precursor to dementia. A deep learning model based on VTNet was\ntrained using eye-tracking data from 44 participants (24 MCI, 20 HCs) who\nperformed a visual memory task. The model utilizes both time series and spatial\ndata derived from eye-tracking. It was modified to incorporate scan paths, heat\nmaps, and image content. These modifications also enabled testing parameters\nsuch as image resolution and task performance, analyzing their impact on model\nperformance. The best model, utilizing $700\\times700px$ resolution heatmaps,\nachieved 68% sensitivity and 76% specificity. Despite operating under more\nchallenging conditions (e.g., smaller dataset size, shorter task duration, or a\nless standardized task), the model's performance is comparable to an\nAlzheimer's study using similar methods (70% sensitivity and 73% specificity).\nThese findings contribute to the development of automated diagnostic tools for\nMCI. Future work should focus on refining the model and using a standardized\nlong-term visual memory task.", "AI": {"tldr": "A deep learning model using eye-tracking data achieved 68% sensitivity and 76% specificity in distinguishing MCI from healthy controls, comparable to similar studies, despite challenging conditions.", "motivation": "The rising global prevalence of dementia necessitates scalable diagnostic tools, with MCI as a key focus.", "method": "A modified VTNet deep learning model analyzed eye-tracking data (time series, spatial data, scan paths, heatmaps, and image content) from 44 participants performing a visual memory task.", "result": "The model achieved 68% sensitivity and 76% specificity, comparable to similar Alzheimer's studies, under more challenging conditions.", "conclusion": "The study advances automated MCI diagnostics; future work should refine the model and use standardized tasks."}}
{"id": "2502.15610", "pdf": "https://arxiv.org/pdf/2502.15610", "abs": "https://arxiv.org/abs/2502.15610", "authors": ["Jixiu Zhai", "Tianchi Lu", "Haitian Zhong", "Ziyang Xu", "Yuhuan Liu", "Shengrui Xu", "Jingwan Wang", "Dan Huang"], "title": "A general language model for peptide identification", "categories": ["cs.LG", "cs.AI", "92C40, 68T07", "I.2.6; J.3"], "comment": "24 pages, 9 figures, 4 tables, submitted to arXiv", "summary": "Accurate identification of bioactive peptides (BPs) and protein\npost-translational modifications (PTMs) is essential for understanding protein\nfunction and advancing therapeutic discovery. However, most computational\nmethods remain limited in their generalizability across diverse peptide\nfunctions. Here, we present PDeepPP, a unified deep learning framework that\nintegrates pretrained protein language models with a hybrid\ntransformer-convolutional architecture, enabling robust identification across\ndiverse peptide classes and PTM sites. We curated comprehensive benchmark\ndatasets and implemented strategies to address data imbalance, allowing PDeepPP\nto systematically extract both global and local sequence features. Through\nextensive analyses-including dimensionality reduction and comparison\nstudies-PDeepPP demonstrates strong, interpretable peptide representations and\nachieves state-of-the-art performance in 25 of the 33 biological identification\ntasks. Notably, PDeepPP attains high accuracy in antimicrobial (0.9726) and\nphosphorylation site (0.9984) identification, with 99.5% specificity in\nglycosylation site prediction and substantial reduction in false negatives in\nantimalarial tasks. By enabling large-scale, accurate peptide analysis, PDeepPP\nsupports biomedical research and the discovery of novel therapeutic targets for\ndisease treatment. All code, datasets, and pretrained models are publicly\navailable via GitHub:https://github.com/fondress/PDeepPP and Hugging\nFace:https://huggingface.co/fondress/PDeppPP.", "AI": {"tldr": "PDeepPP is a deep learning framework for identifying bioactive peptides and PTMs, achieving state-of-the-art performance in diverse tasks.", "motivation": "Accurate identification of bioactive peptides and PTMs is crucial for understanding protein function and therapeutic discovery, but existing methods lack generalizability.", "method": "PDeepPP integrates pretrained protein language models with a hybrid transformer-convolutional architecture, addressing data imbalance and extracting global/local sequence features.", "result": "PDeepPP excels in 25/33 tasks, with high accuracy in antimicrobial (0.9726) and phosphorylation site (0.9984) identification, and 99.5% specificity in glycosylation prediction.", "conclusion": "PDeepPP enables large-scale, accurate peptide analysis, supporting biomedical research and therapeutic target discovery. Code and models are publicly available."}}
{"id": "2502.02668", "pdf": "https://arxiv.org/pdf/2502.02668", "abs": "https://arxiv.org/abs/2502.02668", "authors": ["Martin Eppert", "Satyaki Mukherjee", "Debarghya Ghoshdastidar"], "title": "Recovering Imbalanced Clusters via Gradient-Based Projection Pursuit", "categories": ["cs.LG"], "comment": null, "summary": "Projection Pursuit is a classic exploratory technique for finding interesting\nprojections of a dataset. We propose a method for recovering projections\ncontaining either Imbalanced Clusters or a Bernoulli-Rademacher distribution\nusing a gradient-based technique to optimize the projection index. As sample\ncomplexity is a major limiting factor in Projection Pursuit, we analyze our\nalgorithm's sample complexity within a Planted Vector setting where we can\nobserve that Imbalanced Clusters can be recovered more easily than balanced\nones. Additionally, we give a generalized result that works for a variety of\ndata distributions and projection indices. We compare these results to\ncomputational lower bounds in the Low-Degree-Polynomial Framework. Finally, we\nexperimentally evaluate our method's applicability to real-world data using\nFashionMNIST and the Human Activity Recognition Dataset, where our algorithm\noutperforms others when only a few samples are available.", "AI": {"tldr": "A gradient-based method for recovering projections with Imbalanced Clusters or Bernoulli-Rademacher distributions, showing better recovery for imbalanced clusters and outperforming others on real-world datasets with limited samples.", "motivation": "To address the challenge of sample complexity in Projection Pursuit and explore the recovery of specific data distributions (Imbalanced Clusters and Bernoulli-Rademacher) using gradient-based optimization.", "method": "A gradient-based technique to optimize the projection index, analyzed within a Planted Vector setting, with comparisons to computational lower bounds in the Low-Degree-Polynomial Framework.", "result": "Imbalanced Clusters are easier to recover than balanced ones. The method outperforms others on real-world datasets (FashionMNIST, Human Activity Recognition) with few samples.", "conclusion": "The proposed method effectively recovers specific projections and performs well under limited sample conditions, demonstrating practical applicability."}}
{"id": "2502.15727", "pdf": "https://arxiv.org/pdf/2502.15727", "abs": "https://arxiv.org/abs/2502.15727", "authors": ["Youssef Maklad", "Fares Wael", "Wael Elsersy", "Ali Hamdi"], "title": "Retrieval Augmented Generation Based LLM Evaluation For Protocol State Machine Inference With Chain-of-Thought Reasoning", "categories": ["cs.NI", "cs.AI", "cs.CR", "cs.IR"], "comment": "Minor modifications in sections: abstract, introduction, background\n  problem formulation, and conclusion. (Typos and Clarifications)", "summary": "This paper presents a novel approach to evaluate the efficiency of a\nRAG-based agentic Large Language Model (LLM) architecture for network packet\nseed generation and enrichment. Enhanced by chain-of-thought (COT) prompting\ntechniques, the proposed approach focuses on the improvement of the seeds'\nstructural quality in order to guide protocol fuzzing frameworks through a wide\nexploration of the protocol state space. Our method leverages RAG and text\nembeddings to dynamically reference to the Request For Comments (RFC) documents\nknowledge base for answering queries regarding the protocol's Finite State\nMachine (FSM), then iteratively reasons through the retrieved knowledge, for\noutput refinement and proper seed placement. We then evaluate the response\nstructure quality of the agent's output, based on metrics as BLEU, ROUGE, and\nWord Error Rate (WER) by comparing the generated packets against the\nground-truth packets. Our experiments demonstrate significant improvements of\nup to 18.19%, 14.81%, and 23.45% in BLEU, ROUGE, and WER, respectively, over\nbaseline models. These results confirm the potential of such approach,\nimproving LLM-based protocol fuzzing frameworks for the identification of\nhidden vulnerabilities.", "AI": {"tldr": "A novel RAG-based LLM architecture with COT prompting improves network packet seed generation for protocol fuzzing, achieving significant gains in BLEU, ROUGE, and WER metrics.", "motivation": "To enhance the structural quality of seeds for protocol fuzzing by leveraging LLMs and RFC knowledge, enabling broader exploration of protocol state spaces.", "method": "Uses RAG and text embeddings to reference RFC documents, iteratively refines outputs via COT prompting, and evaluates using BLEU, ROUGE, and WER metrics.", "result": "Achieves improvements of 18.19% (BLEU), 14.81% (ROUGE), and 23.45% (WER) over baselines.", "conclusion": "The approach shows promise for improving LLM-based protocol fuzzing to uncover hidden vulnerabilities."}}
{"id": "2502.13283", "pdf": "https://arxiv.org/pdf/2502.13283", "abs": "https://arxiv.org/abs/2502.13283", "authors": ["Jingfeng Wu", "Peter Bartlett", "Matus Telgarsky", "Bin Yu"], "title": "Benefits of Early Stopping in Gradient Descent for Overparameterized Logistic Regression", "categories": ["cs.LG", "stat.ML"], "comment": "ICML 2025 Camera Ready", "summary": "In overparameterized logistic regression, gradient descent (GD) iterates\ndiverge in norm while converging in direction to the maximum $\\ell_2$-margin\nsolution -- a phenomenon known as the implicit bias of GD. This work\ninvestigates additional regularization effects induced by early stopping in\nwell-specified high-dimensional logistic regression. We first demonstrate that\nthe excess logistic risk vanishes for early-stopped GD but diverges to infinity\nfor GD iterates at convergence. This suggests that early-stopped GD is\nwell-calibrated, whereas asymptotic GD is statistically inconsistent. Second,\nwe show that to attain a small excess zero-one risk, polynomially many samples\nare sufficient for early-stopped GD, while exponentially many samples are\nnecessary for any interpolating estimator, including asymptotic GD. This\nseparation underscores the statistical benefits of early stopping in the\noverparameterized regime. Finally, we establish nonasymptotic bounds on the\nnorm and angular differences between early-stopped GD and $\\ell_2$-regularized\nempirical risk minimizer, thereby connecting the implicit regularization of GD\nwith explicit $\\ell_2$-regularization.", "AI": {"tldr": "Early-stopped GD in overparameterized logistic regression shows better statistical performance than asymptotic GD, with vanishing excess risk and polynomial sample efficiency.", "motivation": "To understand the regularization effects of early stopping in high-dimensional logistic regression and compare its statistical benefits with asymptotic GD.", "method": "Analyze early-stopped GD in well-specified high-dimensional logistic regression, comparing its excess logistic risk, zero-one risk, and sample efficiency with asymptotic GD.", "result": "Early-stopped GD achieves vanishing excess risk and requires polynomially many samples for small zero-one risk, while asymptotic GD is inconsistent and needs exponentially many samples.", "conclusion": "Early stopping in GD provides statistical advantages over asymptotic GD, connecting implicit regularization with explicit \u21132-regularization."}}
{"id": "2506.23316", "pdf": "https://arxiv.org/pdf/2506.23316", "abs": "https://arxiv.org/abs/2506.23316", "authors": ["Zhenghao Peng", "Yuxin Liu", "Bolei Zhou"], "title": "InfGen: Scenario Generation as Next Token Group Prediction", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Realistic and interactive traffic simulation is essential for training and\nevaluating autonomous driving systems. However, most existing data-driven\nsimulation methods rely on static initialization or log-replay data, limiting\ntheir ability to model dynamic, long-horizon scenarios with evolving agent\npopulations. We propose InfGen, a scenario generation framework that outputs\nagent states and trajectories in an autoregressive manner. InfGen represents\nthe entire scene as a sequence of tokens, including traffic light signals,\nagent states, and motion vectors, and uses a transformer model to simulate\ntraffic over time. This design enables InfGen to continuously insert new agents\ninto traffic, supporting infinite scene generation. Experiments demonstrate\nthat InfGen produces realistic, diverse, and adaptive traffic behaviors.\nFurthermore, reinforcement learning policies trained in InfGen-generated\nscenarios achieve superior robustness and generalization, validating its\nutility as a high-fidelity simulation environment for autonomous driving. More\ninformation is available at https://metadriverse.github.io/infgen/.", "AI": {"tldr": "InfGen is an autoregressive framework for generating realistic and dynamic traffic scenarios, supporting infinite scene generation and improving autonomous driving training.", "motivation": "Existing traffic simulation methods are limited by static or log-replay data, hindering dynamic, long-horizon scenario modeling.", "method": "InfGen tokenizes the scene (traffic lights, agent states, motion vectors) and uses a transformer model for autoregressive simulation, enabling continuous agent insertion.", "result": "InfGen produces realistic, diverse, and adaptive traffic behaviors, enhancing reinforcement learning policy robustness and generalization.", "conclusion": "InfGen serves as a high-fidelity simulation environment for autonomous driving, addressing limitations of current methods."}}
{"id": "2502.15799", "pdf": "https://arxiv.org/pdf/2502.15799", "abs": "https://arxiv.org/abs/2502.15799", "authors": ["Artyom Kharinaev", "Viktor Moskvoretskii", "Egor Shvetsov", "Kseniia Studenikina", "Bykov Mikhail", "Evgeny Burnaev"], "title": "Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are powerful tools for modern applications, but\ntheir computational demands limit accessibility. Quantization offers efficiency\ngains, yet its impact on safety and trustworthiness remains poorly understood.\nTo address this, we introduce OpenMiniSafety, a human-curated safety dataset\nwith 1.067 challenging questions to rigorously evaluate model behavior. We\npublicly release human safety evaluations for four LLMs (both quantized and\nfull-precision), totaling 4.268 annotated question-answer pairs. By assessing\n66 quantized variants of these models using four post-training quantization\n(PTQ) and two quantization-aware training (QAT) methods across four safety\nbenchmarks including human-centric evaluations we uncover critical safety\nperformance trade-offs. Our results show both PTQ and QAT can degrade safety\nalignment, with QAT techniques like QLORA or STE performing less safely. No\nsingle method consistently outperforms others across benchmarks, precision\nsettings, or models, highlighting the need for safety-aware compression\nstrategies. Furthermore, precision-specialized methods (e.g., QUIK and AWQ for\n4-bit, AQLM and Q-PET for 2-bit) excel at their target precision, meaning that\nthese methods are not better at compressing but rather different approaches.", "AI": {"tldr": "The paper introduces OpenMiniSafety, a dataset to evaluate the safety impact of quantized LLMs, revealing trade-offs in safety performance and advocating for safety-aware compression strategies.", "motivation": "To understand the impact of quantization on the safety and trustworthiness of LLMs, which is currently poorly understood despite its efficiency benefits.", "method": "The study uses OpenMiniSafety, a human-curated safety dataset, to evaluate 66 quantized variants of four LLMs using PTQ and QAT methods across four safety benchmarks.", "result": "Quantization (PTQ and QAT) can degrade safety alignment, with QAT methods like QLORA or STE performing less safely. No single method consistently outperforms others, and precision-specialized methods excel at their target precision.", "conclusion": "The findings highlight the need for safety-aware compression strategies, as no single quantization method is universally better, and precision-specialized methods are effective only at their intended precision."}}
{"id": "2503.01328", "pdf": "https://arxiv.org/pdf/2503.01328", "abs": "https://arxiv.org/abs/2503.01328", "authors": ["Xinyi Wan", "Penghui Qi", "Guangxing Huang", "Min Lin", "Jialin Li"], "title": "PipeOffload: Improving Scalability of Pipeline Parallelism with Memory Optimization", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Pipeline parallelism (PP) is widely used for training large language models\n(LLMs), yet its scalability is often constrained by high activation memory\nconsumption as the number of in-flight microbatches grows with the degree of\nPP. In this paper, we focus on addressing this challenge by leveraging the\nunder-explored memory offload strategy in PP. With empirical study, we discover\nthat in the majority of standard configurations, at least half, and potentially\nall, of the activations can be offloaded with negligible overhead. In the cases\nwhere full overload is not possible, we introduce a novel selective offload\nstrategy that decreases peak activation memory in a better-than-linear manner.\nFurthermore, we integrate memory offload with other techniques to jointly\nconsider overall throughput and memory limitation. Our experiments proves that\nthe per-device activation memory effectively reduces with the total number of\nstages, making PP a stronger alternative than TP, offering up to a 19\\%\nacceleration with even lower memory consumption. The implementation is\nopen-sourced at\n\\href{https://github.com/sail-sg/zero-bubble-pipeline-parallelism}{this url}.", "AI": {"tldr": "The paper addresses high activation memory consumption in pipeline parallelism (PP) for large language models (LLMs) by leveraging memory offload strategies, achieving significant memory reduction and performance improvements.", "motivation": "Pipeline parallelism (PP) is constrained by high activation memory consumption as the number of in-flight microbatches increases, limiting scalability for LLM training.", "method": "The paper proposes a memory offload strategy, including selective offloading, and integrates it with other techniques to balance throughput and memory limits.", "result": "Experiments show reduced per-device activation memory, making PP more scalable than tensor parallelism (TP), with up to 19% speedup and lower memory usage.", "conclusion": "Memory offload in PP effectively addresses scalability issues, offering better performance and efficiency for LLM training."}}
{"id": "2506.23471", "pdf": "https://arxiv.org/pdf/2506.23471", "abs": "https://arxiv.org/abs/2506.23471", "authors": ["Thanh-Tung Phan-Nguyen", "Khoi-Nguyen Nguyen-Ngoc", "Tam V. Nguyen", "Minh-Triet Tran", "Trung-Nghia Le"], "title": "KiseKloset: Comprehensive System For Outfit Retrieval, Recommendation, And Try-On", "categories": ["cs.IR", "cs.CV"], "comment": null, "summary": "The global fashion e-commerce industry has become integral to people's daily\nlives, leveraging technological advancements to offer personalized shopping\nexperiences, primarily through recommendation systems that enhance customer\nengagement through personalized suggestions. To improve customers' experience\nin online shopping, we propose a novel comprehensive KiseKloset system for\noutfit retrieval, recommendation, and try-on. We explore two approaches for\noutfit retrieval: similar item retrieval and text feedback-guided item\nretrieval. Notably, we introduce a novel transformer architecture designed to\nrecommend complementary items from diverse categories. Furthermore, we enhance\nthe overall performance of the search pipeline by integrating approximate\nalgorithms to optimize the search process. Additionally, addressing the crucial\nneeds of online shoppers, we employ a lightweight yet efficient virtual try-on\nframework capable of real-time operation, memory efficiency, and maintaining\nrealistic outputs compared to its predecessors. This virtual try-on module\nempowers users to visualize specific garments on themselves, enhancing the\ncustomers' experience and reducing costs associated with damaged items for\nretailers. We deployed our end-to-end system for online users to test and\nprovide feedback, enabling us to measure their satisfaction levels. The results\nof our user study revealed that 84% of participants found our comprehensive\nsystem highly useful, significantly improving their online shopping experience.", "AI": {"tldr": "The paper introduces KiseKloset, a system for outfit retrieval, recommendation, and virtual try-on, improving online shopping experiences with advanced algorithms and real-time visualization.", "motivation": "To enhance customer engagement and satisfaction in fashion e-commerce by offering personalized outfit recommendations and realistic virtual try-on experiences.", "method": "Proposes a transformer-based architecture for complementary item recommendations, integrates approximate search algorithms, and employs a lightweight virtual try-on framework.", "result": "User study showed 84% satisfaction, with the system significantly improving the online shopping experience.", "conclusion": "KiseKloset effectively combines retrieval, recommendation, and try-on features to enhance e-commerce usability and customer satisfaction."}}
{"id": "2502.19537", "pdf": "https://arxiv.org/pdf/2502.19537", "abs": "https://arxiv.org/abs/2502.19537", "authors": ["Joshua Kazdan", "Abhay Puri", "Rylan Schaeffer", "Lisa Yu", "Chris Cundy", "Jason Stanley", "Sanmi Koyejo", "Krishnamurthy Dvijotham"], "title": "No, of course I can! Refusal Mechanisms Can Be Exploited Using Harmless Fine-Tuning Data", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Leading language model (LM) providers like OpenAI and Anthropic allow\ncustomers to fine-tune frontier LMs for specific use cases. To prevent abuse,\nthese providers apply filters to block fine-tuning on overtly harmful data. In\nthis setting, we make three contributions: First, while past work has shown\nthat safety alignment is \"shallow\", we correspondingly demonstrate that\nexisting fine-tuning attacks are shallow -- attacks target only the first\nseveral tokens of the model response, and consequently can be blocked by\ngenerating the first several response tokens with an aligned model. Second, we\nconceptually illustrate how to make attacks deeper by introducing a new\nfine-tuning attack that trains models to first refuse harmful requests before\nanswering them; this \"refuse-then-comply\" strategy bypasses shallow defenses\nand produces harmful responses that evade output filters. Third, we demonstrate\nthe potency of our new fine-tuning attack by jailbreaking both open-source\nmodels equipped with defenses and production models, achieving attack success\nrates of 57% and 72% against GPT-4o and Claude Haiku, respectively. Our attack\nreceived a $2000 bug bounty from OpenAI and was acknowledged as a vulnerability\nby Anthropic. Our work undermines the notion that models are safe because they\ninitially refuse harmful requests and broadens awareness of the scope of\nattacks that face production fine-tuning APIs.", "AI": {"tldr": "The paper demonstrates that existing fine-tuning attacks on LMs are shallow and introduces a deeper 'refuse-then-comply' attack, achieving high success rates against GPT-4o and Claude Haiku.", "motivation": "To expose vulnerabilities in safety filters of fine-tuned LMs and highlight the limitations of shallow defenses.", "method": "Introduces a 'refuse-then-comply' fine-tuning attack that bypasses shallow defenses by training models to initially refuse harmful requests before complying.", "result": "Achieved 57% and 72% attack success rates against GPT-4o and Claude Haiku, respectively, earning a $2000 bug bounty from OpenAI.", "conclusion": "Undermines the safety of models that initially refuse harmful requests and raises awareness of deeper vulnerabilities in production fine-tuning APIs."}}
{"id": "2503.07661", "pdf": "https://arxiv.org/pdf/2503.07661", "abs": "https://arxiv.org/abs/2503.07661", "authors": ["Wei Junhao", "Yu Zhe", "Sakuma Jun"], "title": "Disrupting Model Merging: A Parameter-Level Defense Without Sacrificing Accuracy", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "Accepted by ICCV 2025", "summary": "Model merging is a technique that combines multiple finetuned models into a\nsingle model without additional training, allowing a free-rider to cheaply\ninherit specialized capabilities. This study investigates methodologies to\nsuppress unwanted model merging by free-riders. Existing methods such as model\nwatermarking or fingerprinting can only detect merging in hindsight. In\ncontrast, we propose a first proactive defense against model merging.\nSpecifically, our defense method modifies the model parameters so that the\nmodel is disrupted if the model is merged with any other model, while its\nfunctionality is kept unchanged if not merged with others. Our approach\nconsists of two modules, rearranging MLP parameters and scaling attention\nheads, which push the model out of the shared basin in parameter space, causing\nthe merging performance with other models to degrade significantly. We conduct\nextensive experiments on image classification, image generation, and text\nclassification to demonstrate that our defense severely disrupts merging while\nretaining the functionality of the post-protect model. Moreover, we analyze\npotential adaptive attacks and further propose a dropout-based pruning to\nimprove our proposal's robustness.", "AI": {"tldr": "Proposes a proactive defense against model merging by disrupting merged models while preserving standalone functionality.", "motivation": "To prevent free-riders from cheaply inheriting specialized capabilities via model merging, as existing methods only detect merging after the fact.", "method": "Modifies model parameters (rearranging MLP parameters, scaling attention heads) to disrupt merging while keeping standalone functionality intact.", "result": "Defense significantly degrades merging performance across image classification, generation, and text classification tasks.", "conclusion": "The proactive defense is effective, and robustness is further improved with dropout-based pruning against adaptive attacks."}}
{"id": "2503.00387", "pdf": "https://arxiv.org/pdf/2503.00387", "abs": "https://arxiv.org/abs/2503.00387", "authors": ["Hamed Khosravi", "Mohammad Reza Shafie", "Ahmed Shoyeb Raihan", "Srinjoy Das", "Imtiaz Ahmed"], "title": "LNUCB-TA: Linear-nonlinear Hybrid Bandit Learning with Temporal Attention", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Existing contextual multi-armed bandit (MAB) algorithms fail to effectively\ncapture both long-term trends and local patterns across all arms, leading to\nsuboptimal performance in environments with rapidly changing reward structures.\nThey also rely on static exploration rates, which do not dynamically adjust to\nchanging conditions. To overcome these limitations, we propose LNUCB-TA, a\nhybrid bandit model integrating a novel nonlinear component (adaptive k-Nearest\nNeighbors (k-NN)) for reducing time complexity, alongside a global-and-local\nattention-based exploration mechanism. Our approach uniquely combines linear\nand nonlinear estimation techniques, with the nonlinear module dynamically\nadjusting k based on reward variance to enhance spatiotemporal pattern\nrecognition. This reduces the likelihood of selecting suboptimal arms while\nimproving reward estimation accuracy and computational efficiency. The\nattention-based mechanism ranks arms by past performance and selection\nfrequency, dynamically adjusting exploration and exploitation in real time\nwithout requiring manual tuning of exploration rates. By integrating global\nattention (assessing all arms collectively) and local attention (focusing on\nindividual arms), LNUCB-TA efficiently adapts to temporal and spatial\ncomplexities. Empirical results show LNUCB-TA significantly outperforms\nstate-of-the-art linear, nonlinear, and hybrid bandits in cumulative and mean\nreward, convergence, and robustness across different exploration rates.\nTheoretical analysis further confirms its reliability with a sub-linear regret\nbound.", "AI": {"tldr": "LNUCB-TA is a hybrid bandit model combining linear and nonlinear techniques with adaptive exploration, outperforming existing methods in dynamic environments.", "motivation": "Existing MAB algorithms struggle with long-term trends, local patterns, and static exploration rates in rapidly changing reward structures.", "method": "Integrates adaptive k-NN for nonlinear estimation and a global-local attention mechanism for dynamic exploration-exploitation balance.", "result": "Empirically superior in cumulative/mean reward, convergence, and robustness; theoretically proven with sub-linear regret.", "conclusion": "LNUCB-TA effectively addresses limitations of current MAB algorithms, offering improved performance and adaptability."}}
{"id": "2503.15758", "pdf": "https://arxiv.org/pdf/2503.15758", "abs": "https://arxiv.org/abs/2503.15758", "authors": ["Venmugil Elango"], "title": "ATTENTION2D: Communication Efficient Distributed Self-Attention Mechanism", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "Updated Table 1", "summary": "Transformer-based models have emerged as a leading architecture for natural\nlanguage processing, natural language generation, and image generation tasks. A\nfundamental element of the transformer architecture is self-attention, which\nallows the model to capture intricate dependencies within the data. However,\nthe self-attention mechanism also incurs significant computational and memory\ncosts, particularly for long sequences.\n  In this paper, we introduce ATTENTION2D, a novel approach that exploits\nparallelism along two dimensions - query and key/value - of the self-attention\noperation. This method enables efficient distribution and parallelization of\ncomputations across multiple devices. Our approach facilitates asymptotically\nfaster training and inference phases compared to previous methods, without\nrelying on approximations or incurring additional computational or memory\noverheads. Furthermore, unlike existing techniques that struggle to scale with\nan increasing number of processing units, our approach effectively scales with\nadditional processing units.\n  Our experimental results confirm the effectiveness of our method in improving\ncommunication efficiency and scalability. Compared to Ring Attention, our\napproach demonstrated up to a 5x performance boost on a GPT-3-like model using\n64 NVIDIA A100 GPUs across 16 nodes, and up to a 9.4x performance boost on 64\nNVIDIA H100 GPUs across 64 nodes.", "AI": {"tldr": "ATTENTION2D improves transformer efficiency by parallelizing self-attention along query and key/value dimensions, achieving faster training and inference without extra costs.", "motivation": "Address the high computational and memory costs of self-attention in transformers, especially for long sequences.", "method": "Introduces ATTENTION2D, a parallelization technique for self-attention along query and key/value dimensions.", "result": "Achieves up to 5x and 9.4x performance boosts on GPT-3-like models with 64 GPUs.", "conclusion": "ATTENTION2D offers scalable, efficient transformer training and inference without approximations or overheads."}}
{"id": "2503.00436", "pdf": "https://arxiv.org/pdf/2503.00436", "abs": "https://arxiv.org/abs/2503.00436", "authors": ["Maria Lymperaiou", "Giorgos Filandrianos", "Angeliki Dimitriou", "Athanasios Voulodimos", "Giorgos Stamou"], "title": "HalCECE: A Framework for Explainable Hallucination Detection through Conceptual Counterfactuals in Image Captioning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In the dynamic landscape of artificial intelligence, the exploration of\nhallucinations within vision-language (VL) models emerges as a critical\nfrontier. This work delves into the intricacies of hallucinatory phenomena\nexhibited by widely used image captioners, unraveling interesting patterns.\nSpecifically, we step upon previously introduced techniques of conceptual\ncounterfactual explanations to address VL hallucinations. The deterministic and\nefficient nature of the employed conceptual counterfactuals backbone is able to\nsuggest semantically minimal edits driven by hierarchical knowledge, so that\nthe transition from a hallucinated caption to a non-hallucinated one is\nperformed in a black-box manner. HalCECE, our proposed hallucination detection\nframework is highly interpretable, by providing semantically meaningful edits\napart from standalone numbers, while the hierarchical decomposition of\nhallucinated concepts leads to a thorough hallucination analysis. Another\nnovelty tied to the current work is the investigation of role hallucinations,\nbeing one of the first works to involve interconnections between visual\nconcepts in hallucination detection. Overall, HalCECE recommends an explainable\ndirection to the crucial field of VL hallucination detection, thus fostering\ntrustworthy evaluation of current and future VL systems.", "AI": {"tldr": "The paper explores hallucinations in vision-language models, proposing HalCECE, a framework using conceptual counterfactuals for interpretable and efficient hallucination detection and analysis.", "motivation": "Understanding and addressing hallucinatory phenomena in vision-language models is crucial for trustworthy AI systems.", "method": "Uses conceptual counterfactual explanations to detect and analyze hallucinations, focusing on semantic edits and hierarchical knowledge.", "result": "HalCECE provides interpretable, semantically meaningful edits and thorough hallucination analysis, including role hallucinations.", "conclusion": "HalCECE advances explainable hallucination detection in vision-language models, enhancing trust in AI evaluations."}}
{"id": "2503.19564", "pdf": "https://arxiv.org/pdf/2503.19564", "abs": "https://arxiv.org/abs/2503.19564", "authors": ["Sree Bhargavi Balija"], "title": "FedMM-X: A Trustworthy and Interpretable Framework for Federated Multi-Modal Learning in Dynamic Environments", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As artificial intelligence systems increasingly operate in Real-world\nenvironments, the integration of multi-modal data sources such as vision,\nlanguage, and audio presents both unprecedented opportunities and critical\nchallenges for achieving trustworthy intelligence. In this paper, we propose a\nnovel framework that unifies federated learning with explainable multi-modal\nreasoning to ensure trustworthiness in decentralized, dynamic settings. Our\napproach, called FedMM-X (Federated Multi-Modal Explainable Intelligence),\nleverages cross-modal consistency checks, client-level interpretability\nmechanisms, and dynamic trust calibration to address challenges posed by data\nheterogeneity, modality imbalance, and out-of-distribution generalization.\nThrough rigorous evaluation across federated multi-modal benchmarks involving\nvision-language tasks, we demonstrate improved performance in both accuracy and\ninterpretability while reducing vulnerabilities to adversarial and spurious\ncorrelations. Further, we introduce a novel trust score aggregation method to\nquantify global model reliability under dynamic client participation. Our\nfindings pave the way toward developing robust, interpretable, and socially\nresponsible AI systems in Real-world environments.", "AI": {"tldr": "The paper introduces FedMM-X, a framework combining federated learning with explainable multi-modal reasoning to enhance trustworthiness in AI systems operating in real-world environments.", "motivation": "The motivation is to address challenges like data heterogeneity, modality imbalance, and out-of-distribution generalization in multi-modal AI systems while ensuring trustworthiness.", "method": "The proposed FedMM-X framework uses cross-modal consistency checks, client-level interpretability mechanisms, and dynamic trust calibration.", "result": "The framework improves accuracy and interpretability, reduces vulnerabilities to adversarial attacks, and introduces a trust score aggregation method for global model reliability.", "conclusion": "FedMM-X advances robust, interpretable, and socially responsible AI systems for real-world applications."}}
{"id": "2506.23957", "pdf": "https://arxiv.org/pdf/2506.23957", "abs": "https://arxiv.org/abs/2506.23957", "authors": ["Zinuo You", "Stamatios Georgoulis", "Anpei Chen", "Siyu Tang", "Dengxin Dai"], "title": "GaVS: 3D-Grounded Video Stabilization via Temporally-Consistent Local Reconstruction and Rendering", "categories": ["cs.GR", "cs.CV"], "comment": "siggraph 2025, project website: https://sinoyou.github.io/gavs", "summary": "Video stabilization is pivotal for video processing, as it removes unwanted\nshakiness while preserving the original user motion intent. Existing\napproaches, depending on the domain they operate, suffer from several issues\n(e.g. geometric distortions, excessive cropping, poor generalization) that\ndegrade the user experience. To address these issues, we introduce\n\\textbf{GaVS}, a novel 3D-grounded approach that reformulates video\nstabilization as a temporally-consistent `local reconstruction and rendering'\nparadigm. Given 3D camera poses, we augment a reconstruction model to predict\nGaussian Splatting primitives, and finetune it at test-time, with multi-view\ndynamics-aware photometric supervision and cross-frame regularization, to\nproduce temporally-consistent local reconstructions. The model are then used to\nrender each stabilized frame. We utilize a scene extrapolation module to avoid\nframe cropping. Our method is evaluated on a repurposed dataset, instilled with\n3D-grounded information, covering samples with diverse camera motions and scene\ndynamics. Quantitatively, our method is competitive with or superior to\nstate-of-the-art 2D and 2.5D approaches in terms of conventional task metrics\nand new geometry consistency. Qualitatively, our method produces noticeably\nbetter results compared to alternatives, validated by the user study.", "AI": {"tldr": "GaVS introduces a 3D-grounded video stabilization method using Gaussian Splatting and test-time finetuning, outperforming existing 2D/2.5D approaches in quality and consistency.", "motivation": "Existing video stabilization methods suffer from issues like distortions, cropping, and poor generalization, degrading user experience.", "method": "GaVS reformulates stabilization as a local reconstruction and rendering paradigm, using 3D camera poses, Gaussian Splatting, and test-time finetuning with photometric supervision and cross-frame regularization.", "result": "Quantitatively competitive or superior to state-of-the-art methods; qualitatively better results, validated by user study.", "conclusion": "GaVS effectively addresses limitations of existing approaches, offering improved stabilization with geometry consistency and minimal cropping."}}
{"id": "2503.00583", "pdf": "https://arxiv.org/pdf/2503.00583", "abs": "https://arxiv.org/abs/2503.00583", "authors": ["Jingtao Tang", "Zining Mao", "Lufan Yang", "Hang Ma"], "title": "Space-Time Graphs of Convex Sets for Multi-Robot Motion Planning", "categories": ["cs.RO", "cs.AI"], "comment": "IROS'25 (to appear)", "summary": "We address the Multi-Robot Motion Planning (MRMP) problem of computing\ncollision-free trajectories for multiple robots in shared continuous\nenvironments. While existing frameworks effectively decompose MRMP into\nsingle-robot subproblems, spatiotemporal motion planning with dynamic obstacles\nremains challenging, particularly in cluttered or narrow-corridor settings. We\npropose Space-Time Graphs of Convex Sets (ST-GCS), a novel planner that\nsystematically covers the collision-free space-time domain with convex sets\ninstead of relying on random sampling. By extending Graphs of Convex Sets (GCS)\ninto the time dimension, ST-GCS formulates time-optimal trajectories in a\nunified convex optimization that naturally accommodates velocity bounds and\nflexible arrival times. We also propose Exact Convex Decomposition (ECD) to\n\"reserve\" trajectories as spatiotemporal obstacles, maintaining a\ncollision-free space-time graph of convex sets for subsequent planning.\nIntegrated into two prioritized-planning frameworks, ST-GCS consistently\nachieves higher success rates and better solution quality than state-of-the-art\nsampling-based planners -- often at orders-of-magnitude faster runtimes --\nunderscoring its benefits for MRMP in challenging settings.", "AI": {"tldr": "ST-GCS is a novel planner for multi-robot motion planning that uses convex sets in space-time, outperforming sampling-based methods in success rates, quality, and speed.", "motivation": "Existing methods struggle with dynamic obstacles in cluttered or narrow environments, needing a more systematic approach.", "method": "ST-GCS extends Graphs of Convex Sets (GCS) into time, using convex optimization for time-optimal trajectories. Exact Convex Decomposition (ECD) reserves trajectories as obstacles.", "result": "ST-GCS achieves higher success rates, better solution quality, and faster runtimes than state-of-the-art sampling-based planners.", "conclusion": "ST-GCS is highly effective for MRMP in challenging environments, offering systematic and efficient solutions."}}
{"id": "2504.04528", "pdf": "https://arxiv.org/pdf/2504.04528", "abs": "https://arxiv.org/abs/2504.04528", "authors": ["Gerardo Flores", "Abigail Schiff", "Alyssa H. Smith", "Julia A Fukuyama", "Ashia C. Wilson"], "title": "A Consequentialist Critique of Binary Classification Evaluation Practices", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "comment": null, "summary": "ML-supported decisions, such as ordering tests or determining preventive\ncustody, often involve binary classification based on probabilistic forecasts.\nEvaluation frameworks for such forecasts typically consider whether to\nprioritize independent-decision metrics (e.g., Accuracy) or top-K metrics\n(e.g., Precision@K), and whether to focus on fixed thresholds or\nthreshold-agnostic measures like AUC-ROC. We highlight that a consequentialist\nperspective, long advocated by decision theorists, should naturally favor\nevaluations that support independent decisions using a mixture of thresholds\ngiven their prevalence, such as Brier scores and Log loss. However, our\nempirical analysis reveals a strong preference for top-K metrics or fixed\nthresholds in evaluations at major conferences like ICML, FAccT, and CHIL. To\naddress this gap, we use this decision-theoretic framework to map evaluation\nmetrics to their optimal use cases, along with a Python package, briertools, to\npromote the broader adoption of Brier scores. In doing so, we also uncover new\ntheoretical connections, including a reconciliation between the Brier Score and\nDecision Curve Analysis, which clarifies and responds to a longstanding\ncritique by (Assel, et al. 2017) regarding the clinical utility of proper\nscoring rules.", "AI": {"tldr": "The paper advocates for using Brier scores and Log loss for evaluating ML-supported binary decisions, highlighting a gap between theoretical preference and empirical practice in major conferences.", "motivation": "To bridge the gap between decision-theoretic recommendations (favoring Brier scores and Log loss) and the prevalent use of top-K metrics or fixed thresholds in ML evaluations.", "method": "Empirical analysis of evaluation metrics in major conferences (ICML, FAccT, CHIL), theoretical mapping of metrics to use cases, and development of a Python package (briertools) to promote Brier scores.", "result": "Reveals a preference for top-K metrics or fixed thresholds in practice, despite theoretical advantages of Brier scores. Also uncovers new connections between Brier Score and Decision Curve Analysis.", "conclusion": "Advocates for adopting Brier scores and Log loss in evaluations, supported by theoretical and empirical insights, and introduces tools to facilitate this shift."}}
{"id": "2506.24034", "pdf": "https://arxiv.org/pdf/2506.24034", "abs": "https://arxiv.org/abs/2506.24034", "authors": ["George Webber", "Alexander Hammers", "Andrew P King", "Andrew J Reader"], "title": "Supervised Diffusion-Model-Based PET Image Reconstruction", "categories": ["physics.med-ph", "cs.CV"], "comment": "12 pages, 6 figures. Submitted to MICCAI 2025, not peer-reviewed", "summary": "Diffusion models (DMs) have recently been introduced as a regularizing prior\nfor PET image reconstruction, integrating DMs trained on high-quality PET\nimages with unsupervised schemes that condition on measured data. While these\napproaches have potential generalization advantages due to their independence\nfrom the scanner geometry and the injected activity level, they forgo the\nopportunity to explicitly model the interaction between the DM prior and noisy\nmeasurement data, potentially limiting reconstruction accuracy. To address\nthis, we propose a supervised DM-based algorithm for PET reconstruction. Our\nmethod enforces the non-negativity of PET's Poisson likelihood model and\naccommodates the wide intensity range of PET images. Through experiments on\nrealistic brain PET phantoms, we demonstrate that our approach outperforms or\nmatches state-of-the-art deep learning-based methods quantitatively across a\nrange of dose levels. We further conduct ablation studies to demonstrate the\nbenefits of the proposed components in our model, as well as its dependence on\ntraining data, parameter count, and number of diffusion steps. Additionally, we\nshow that our approach enables more accurate posterior sampling than\nunsupervised DM-based methods, suggesting improved uncertainty estimation.\nFinally, we extend our methodology to a practical approach for fully 3D PET and\npresent example results from real [$^{18}$F]FDG brain PET data.", "AI": {"tldr": "A supervised diffusion model (DM) for PET image reconstruction is proposed, outperforming deep learning methods and improving uncertainty estimation.", "motivation": "Current unsupervised DM-based PET reconstruction lacks explicit modeling of DM prior and noisy data interaction, limiting accuracy.", "method": "A supervised DM algorithm enforces PET's Poisson likelihood non-negativity and accommodates PET's wide intensity range.", "result": "Outperforms state-of-the-art deep learning methods across dose levels and enables accurate posterior sampling.", "conclusion": "The supervised DM approach enhances PET reconstruction accuracy and uncertainty estimation, validated on real data."}}
{"id": "2503.04257", "pdf": "https://arxiv.org/pdf/2503.04257", "abs": "https://arxiv.org/abs/2503.04257", "authors": ["Wonkwang Lee", "Jongwon Jeong", "Taehong Moon", "Hyeon-Jong Kim", "Jaehyeon Kim", "Gunhee Kim", "Byeong-Uk Lee"], "title": "How to Move Your Dragon: Text-to-Motion Synthesis for Large-Vocabulary Objects", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to ICML 2025", "summary": "Motion synthesis for diverse object categories holds great potential for 3D\ncontent creation but remains underexplored due to two key challenges: (1) the\nlack of comprehensive motion datasets that include a wide range of high-quality\nmotions and annotations, and (2) the absence of methods capable of handling\nheterogeneous skeletal templates from diverse objects. To address these\nchallenges, we contribute the following: First, we augment the Truebones Zoo\ndataset, a high-quality animal motion dataset covering over 70 species, by\nannotating it with detailed text descriptions, making it suitable for\ntext-based motion synthesis. Second, we introduce rig augmentation techniques\nthat generate diverse motion data while preserving consistent dynamics,\nenabling models to adapt to various skeletal configurations. Finally, we\nredesign existing motion diffusion models to dynamically adapt to arbitrary\nskeletal templates, enabling motion synthesis for a diverse range of objects\nwith varying structures. Experiments show that our method learns to generate\nhigh-fidelity motions from textual descriptions for diverse and even unseen\nobjects, setting a strong foundation for motion synthesis across diverse object\ncategories and skeletal templates. Qualitative results are available at:\n$\\href{https://t2m4lvo.github.io}{https://t2m4lvo.github.io}$.", "AI": {"tldr": "The paper addresses motion synthesis challenges for diverse objects by augmenting the Truebones Zoo dataset, introducing rig augmentation techniques, and redesigning motion diffusion models to handle varying skeletal templates.", "motivation": "Motion synthesis for diverse objects is limited by the lack of comprehensive datasets and methods for heterogeneous skeletal templates.", "method": "Augmenting the Truebones Zoo dataset with text annotations, introducing rig augmentation, and adapting motion diffusion models for arbitrary skeletal templates.", "result": "The method generates high-fidelity motions from text for diverse and unseen objects.", "conclusion": "The approach sets a foundation for motion synthesis across diverse object categories and skeletal templates."}}
{"id": "2504.05352", "pdf": "https://arxiv.org/pdf/2504.05352", "abs": "https://arxiv.org/abs/2504.05352", "authors": ["Siqing Song", "Chuang Wang", "Ruiqi Wang", "Yi Yang", "Xu-Yao Zhang"], "title": "Achieving binary weight and activation for LLMs using Post-Training Quantization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Quantizing large language models (LLMs) to 1-bit precision significantly\nreduces computational costs, but existing quantization techniques suffer from\nnoticeable performance degradation when using weight and activation precisions\nbelow 4 bits (W4A4). In this paper, we propose a post-training quantization\nframework with W(1+1)A(1*4) configuration, where weights are quantized to 1 bit\nwith an additional 1 bit for fine-grain grouping and activations are quantized\nto 1 bit with a 4-fold increase in the number of channels. For weight\nquantization, we propose utilizing Hessian-aware fine-grained grouping along\nwith an EM-based quantization scheme. For activation quantization, we decompose\nINT4-quantized activations into a 4 * INT1 format equivalently and\nsimultaneously smooth the scaling factors based on quantization errors, which\nfurther reduces the quantization errors in activations. Our method surpasses\nstate-of-the-art (SOTA) LLM quantization baselines on W2A4 across multiple\ntasks, pushing the boundaries of existing LLM quantization methods toward fully\nbinarized models. Code is available at\nhttps://github.com/JimmyCrave/LLM-PTQ-binarization.", "AI": {"tldr": "A post-training quantization framework for LLMs using W(1+1)A(1*4) configuration, achieving better performance than SOTA methods with reduced computational costs.", "motivation": "Existing quantization techniques degrade performance below 4-bit precision, limiting efficiency gains.", "method": "Uses Hessian-aware fine-grained grouping for weights and decomposes INT4 activations into 4*INT1 with smoothed scaling factors.", "result": "Outperforms SOTA baselines on W2A4 tasks, advancing toward fully binarized models.", "conclusion": "The proposed method pushes LLM quantization boundaries, enabling efficient 1-bit models with minimal performance loss."}}
{"id": "2112.06193", "pdf": "https://arxiv.org/pdf/2112.06193", "abs": "https://arxiv.org/abs/2112.06193", "authors": ["Minh-Quan Le", "Trung-Nghia Le", "Tam V. Nguyen", "Isao Echizen", "Minh-Triet Tran"], "title": "GUNNEL: Guided Mixup Augmentation and Multi-Model Fusion for Aquatic Animal Segmentation", "categories": ["cs.CV"], "comment": "Accepted to Neural Computing & Applications", "summary": "Recent years have witnessed great advances in object segmentation research.\nIn addition to generic objects, aquatic animals have attracted research\nattention. Deep learning-based methods are widely used for aquatic animal\nsegmentation and have achieved promising performance. However, there is a lack\nof challenging datasets for benchmarking. In this work, we build a new dataset\ndubbed \"Aquatic Animal Species.\" We also devise a novel GUided mixup\naugmeNtatioN and multi-modEl fusion for aquatic animaL segmentation (GUNNEL)\nthat leverages the advantages of multiple segmentation models to segment\naquatic animals effectively and improves the training performance by\nsynthesizing hard samples. Extensive experiments demonstrated the superiority\nof our proposed framework over existing state-of-the-art instance segmentation\nmethods. The code is available at https://github.com/lmquan2000/mask-mixup. The\ndataset is available at https://doi.org/10.5281/zenodo.8208877.", "AI": {"tldr": "A new dataset \"Aquatic Animal Species\" and a method GUNNEL are introduced for aquatic animal segmentation, outperforming existing methods.", "motivation": "Lack of challenging datasets for benchmarking aquatic animal segmentation despite advances in object segmentation research.", "method": "Proposes GUNNEL, combining guided mixup augmentation and multi-model fusion to improve segmentation and training performance.", "result": "GUNNEL outperforms state-of-the-art instance segmentation methods in experiments.", "conclusion": "The new dataset and GUNNEL method advance aquatic animal segmentation, with code and dataset publicly available."}}
{"id": "2503.10984", "pdf": "https://arxiv.org/pdf/2503.10984", "abs": "https://arxiv.org/abs/2503.10984", "authors": ["Hanti Lin"], "title": "The Problem of the Priors, or Posteriors?", "categories": ["stat.OT", "cs.AI", "math.PR"], "comment": null, "summary": "The problem of the priors is well known: it concerns the challenge of\nidentifying norms that govern one's prior credences. I argue that a key to\naddressing this problem lies in considering what I call the problem of the\nposteriors -- the challenge of identifying norms that directly govern one's\nposterior credences, which backward induce some norms on the priors via the\ndiachronic requirement of conditionalization. This forward-looking approach can\nbe summarized as: Think ahead, work backward. Although this idea can be traced\nto Freedman (1963), Carnap (1963), and Shimony (1970), I believe that it has\nnot received enough attention. In this paper, I initiate a systematic defense\nof forward-looking Bayesianism, addressing potential objections from more\ntraditional views (both subjectivist and objectivist). I also develop a\nspecific approach to forward-looking Bayesianism -- one that values the\nconvergence of posterior credences to the truth, and treats it as a fundamental\nrather than derived norm. This approach, called convergentist Bayesianism, is\nargued to be crucial for a Bayesian foundation of Ockham's razor in statistics\nand machine learning.", "AI": {"tldr": "The paper proposes a forward-looking approach to Bayesianism, focusing on posterior credences to indirectly address the problem of priors, and introduces convergentist Bayesianism as a key norm.", "motivation": "The problem of priors is a longstanding challenge in Bayesianism, and the paper seeks to address it by shifting focus to posterior credences, which can backward induce norms on priors.", "method": "The author advocates for forward-looking Bayesianism, emphasizing posterior norms and conditionalization, and develops convergentist Bayesianism, prioritizing truth convergence.", "result": "The approach provides a systematic defense of forward-looking Bayesianism and introduces convergentist Bayesianism as a foundational norm, linking it to Ockham's razor.", "conclusion": "Forward-looking Bayesianism, particularly convergentist Bayesianism, offers a promising solution to the problem of priors and has implications for statistics and machine learning."}}
{"id": "2504.07722", "pdf": "https://arxiv.org/pdf/2504.07722", "abs": "https://arxiv.org/abs/2504.07722", "authors": ["MaryLena Bleile"], "title": "A Framework of Decision-Relevant Observability: Reinforcement Learning Converges Under Relative Ignorability", "categories": ["cs.LG", "stat.ME", "60G"], "comment": null, "summary": "From clinical dosing algorithms to autonomous robots, sequential\ndecision-making systems routinely operate with missing or incomplete data.\nClassical reinforcement learning theory, which is commonly used to solve\nsequential decision problems, assumes Markovian observability, which may not\nhold under partial observability. Causal inference paradigms formalise\nignorability of missingness. We show these views can be unified and generalized\nin order to guarantee Q-learning convergence even when the Markov property\nfails. To do so, we introduce the concept of \\emph{relative ignorability}.\nRelative ignorability is a graphical-causal criterion which refines the\nrequirements for accurate decision-making based on incomplete data. Theoretical\nresults and simulations both reveal that non-markovian stochastic processes\nwhose missingness is relatively ignorable with respect to causal estimands can\nstill be optimized using standard Reinforcement Learning algorithms. These\nresults expand the theoretical foundations of safe, data-efficient AI to\nreal-world environments where complete information is unattainable.", "AI": {"tldr": "The paper unifies causal inference and reinforcement learning to address missing data in sequential decision-making, introducing 'relative ignorability' to ensure Q-learning convergence without strict Markovian observability.", "motivation": "To address the challenge of missing or incomplete data in sequential decision-making systems, where classical reinforcement learning assumes Markovian observability, which may not hold.", "method": "Introduces 'relative ignorability,' a graphical-causal criterion, to generalize and unify causal inference and reinforcement learning, enabling Q-learning convergence under partial observability.", "result": "Theoretical and simulation results show that standard reinforcement learning algorithms can optimize non-Markovian processes if missingness is relatively ignorable.", "conclusion": "The work expands the theoretical foundations of AI for real-world environments with incomplete information, ensuring safe and data-efficient decision-making."}}
{"id": "2206.00535", "pdf": "https://arxiv.org/pdf/2206.00535", "abs": "https://arxiv.org/abs/2206.00535", "authors": ["Camilo Fosco", "Emilie Josephs", "Alex Andonian", "Aude Oliva"], "title": "Deepfake Caricatures: Amplifying attention to artifacts increases deepfake detection by humans and machines", "categories": ["cs.CV", "cs.HC", "cs.SI"], "comment": "11 pages, 5 figures, 4 tables", "summary": "Deepfakes can fuel online misinformation. As deepfakes get harder to\nrecognize with the naked eye, human users become more reliant on deepfake\ndetection models to help them decide whether a video is real or fake.\nCurrently, models yield a prediction for a video's authenticity, but do not\nintegrate a method for alerting a human user. We introduce a framework for\namplifying artifacts in deepfake videos to make them more detectable by people.\nWe propose a novel, semi-supervised Artifact Attention module, which is trained\non human responses to create attention maps that highlight video artifacts, and\nmagnify them to create a novel visual indicator we call \"Deepfake Caricatures\".\nIn a user study, we demonstrate that Caricatures greatly increase human\ndetection, across video presentation times and user engagement levels. We also\nintroduce a deepfake detection model that incorporates the Artifact Attention\nmodule to increase its accuracy and robustness. Overall, we demonstrate the\nsuccess of a human-centered approach to designing deepfake mitigation methods.", "AI": {"tldr": "The paper introduces a framework to amplify artifacts in deepfake videos, making them more detectable by humans using a novel Artifact Attention module and 'Deepfake Caricatures'.", "motivation": "Deepfakes are increasingly hard to detect visually, and current models lack human-alerting methods, necessitating a human-centered approach.", "method": "Proposes a semi-supervised Artifact Attention module trained on human responses to highlight and magnify video artifacts, creating 'Deepfake Caricatures'.", "result": "User study shows Caricatures significantly improve human detection, and the module enhances model accuracy and robustness.", "conclusion": "The human-centered approach effectively improves deepfake detection and mitigation."}}
{"id": "2503.11167", "pdf": "https://arxiv.org/pdf/2503.11167", "abs": "https://arxiv.org/abs/2503.11167", "authors": ["Haonan Wang", "Qixiang Zhang", "Lehan Wang", "Xuanqi Huang", "Xiaomeng Li"], "title": "Neurons: Emulating the Human Visual Cortex Improves Fidelity and Interpretability in fMRI-to-Video Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ICCV 2025", "summary": "Decoding visual stimuli from neural activity is essential for understanding\nthe human brain. While fMRI methods have successfully reconstructed static\nimages, fMRI-to-video reconstruction faces challenges due to the need for\ncapturing spatiotemporal dynamics like motion and scene transitions. Recent\napproaches have improved semantic and perceptual alignment but struggle to\nintegrate coarse fMRI data with detailed visual features. Inspired by the\nhierarchical organization of the visual system, we propose NEURONS, a novel\nframework that decouples learning into four correlated sub-tasks: key object\nsegmentation, concept recognition, scene description, and blurry video\nreconstruction. This approach simulates the visual cortex's functional\nspecialization, allowing the model to capture diverse video content. In the\ninference stage, NEURONS generates robust conditioning signals for a\npre-trained text-to-video diffusion model to reconstruct the videos. Extensive\nexperiments demonstrate that NEURONS outperforms state-of-the-art baselines,\nachieving solid improvements in video consistency (26.6%) and semantic-level\naccuracy (19.1%). Notably, NEURONS shows a strong functional correlation with\nthe visual cortex, highlighting its potential for brain-computer interfaces and\nclinical applications. Code and model weights are available at:\nhttps://github.com/xmed-lab/NEURONS.", "AI": {"tldr": "NEURONS is a novel framework for fMRI-to-video reconstruction, decoupling learning into four sub-tasks to improve video consistency and semantic accuracy.", "motivation": "Addressing the challenge of integrating coarse fMRI data with detailed visual features for video reconstruction.", "method": "Decouples learning into key object segmentation, concept recognition, scene description, and blurry video reconstruction, leveraging a pre-trained text-to-video diffusion model.", "result": "Outperforms baselines with 26.6% improvement in video consistency and 19.1% in semantic accuracy, showing strong correlation with the visual cortex.", "conclusion": "NEURONS demonstrates potential for brain-computer interfaces and clinical applications, with code and model weights publicly available."}}
{"id": "2504.13801", "pdf": "https://arxiv.org/pdf/2504.13801", "abs": "https://arxiv.org/abs/2504.13801", "authors": ["Nguyen Kim Hai Bui", "Nguyen Duy Chien", "P\u00e9ter Kov\u00e1cs", "Gerg\u0151 Bogn\u00e1r"], "title": "Transformer Encoder and Multi-features Time2Vec for Financial Prediction", "categories": ["cs.LG", "cs.CE"], "comment": "5 pages, Eusipco 2025", "summary": "Financial prediction is a complex and challenging task of time series\nanalysis and signal processing, expected to model both short-term fluctuations\nand long-term temporal dependencies. Transformers have remarkable success\nmostly in natural language processing using attention mechanism, which also\ninfluenced the time series community. The ability to capture both short and\nlong-range dependencies helps to understand the financial market and to\nrecognize price patterns, leading to successful applications of Transformers in\nstock prediction. Although, the previous research predominantly focuses on\nindividual features and singular predictions, that limits the model's ability\nto understand broader market trends. In reality, within sectors such as finance\nand technology, companies belonging to the same industry often exhibit\ncorrelated stock price movements.\n  In this paper, we develop a novel neural network architecture by integrating\nTime2Vec with the Encoder of the Transformer model. Based on the study of\ndifferent markets, we propose a novel correlation feature selection method.\nThrough a comprehensive fine-tuning of multiple hyperparameters, we conduct a\ncomparative analysis of our results against benchmark models. We conclude that\nour method outperforms other state-of-the-art encoding methods such as\npositional encoding, and we also conclude that selecting correlation features\nenhance the accuracy of predicting multiple stock prices.", "AI": {"tldr": "The paper introduces a neural network combining Time2Vec with Transformer's Encoder for financial prediction, outperforming benchmarks by leveraging correlation features.", "motivation": "Existing models focus on individual stock predictions, missing broader market trends. The paper addresses this by incorporating correlated stock movements within industries.", "method": "Integrates Time2Vec with Transformer's Encoder, introduces correlation feature selection, and fine-tunes hyperparameters.", "result": "Outperforms state-of-the-art encoding methods like positional encoding and improves multi-stock prediction accuracy.", "conclusion": "The proposed method enhances financial prediction by capturing broader market trends through correlation features and advanced encoding."}}
{"id": "2307.02897", "pdf": "https://arxiv.org/pdf/2307.02897", "abs": "https://arxiv.org/abs/2307.02897", "authors": ["Han Zou", "Masanori Suganuma", "Takayuki Okatani"], "title": "RefVSR++: Exploiting Reference Inputs for Reference-based Video Super-resolution", "categories": ["cs.CV"], "comment": null, "summary": "Smartphones with multi-camera systems, featuring cameras with varying\nfield-of-views (FoVs), are increasingly common. This variation in FoVs results\nin content differences across videos, paving the way for an innovative approach\nto video super-resolution (VSR). This method enhances the VSR performance of\nlower resolution (LR) videos by leveraging higher resolution reference (Ref)\nvideos. Previous works, which operate on this principle, generally expand on\ntraditional VSR models by combining LR and Ref inputs over time into a unified\nstream. However, we can expect that better results are obtained by\nindependently aggregating these Ref image sequences temporally. Therefore, we\nintroduce an improved method, RefVSR++, which performs the parallel aggregation\nof LR and Ref images in the temporal direction, aiming to optimize the use of\nthe available data. RefVSR++ also incorporates improved mechanisms for aligning\nimage features over time, crucial for effective VSR. Our experiments\ndemonstrate that RefVSR++ outperforms previous works by over 1dB in PSNR,\nsetting a new benchmark in the field.", "AI": {"tldr": "RefVSR++ improves video super-resolution by independently aggregating LR and Ref videos temporally, outperforming prior methods by over 1dB in PSNR.", "motivation": "Multi-camera systems with varying FoVs create content differences in videos, enabling enhanced VSR by leveraging higher-resolution Ref videos.", "method": "RefVSR++ aggregates LR and Ref videos in parallel, with improved temporal feature alignment.", "result": "RefVSR++ exceeds previous methods by over 1dB in PSNR.", "conclusion": "RefVSR++ sets a new benchmark in VSR by optimizing data usage and temporal alignment."}}
{"id": "2503.11901", "pdf": "https://arxiv.org/pdf/2503.11901", "abs": "https://arxiv.org/abs/2503.11901", "authors": ["Shengkun Cui", "Archit Patke", "Hung Nguyen", "Aditya Ranjan", "Ziheng Chen", "Phuong Cao", "Brett Bode", "Gregory Bauer", "Catello Di Martino", "Saurabh Jha", "Chandra Narayanaswami", "Daby Sow", "Zbigniew T. Kalbarczyk", "Ravishankar K. Iyer"], "title": "Characterizing GPU Resilience and Impact on AI/HPC Systems", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "This study characterizes GPU resilience in Delta HPC, a large-scale AI system\nthat consists of 1,056 A100 and H100 GPUs, with over 1,300 petaflops of peak\nthroughput. Delta HPC is operated by the National Center for Supercomputing\nApplications (NCSA) at the University of Illinois Urbana-Champaign. We used 2.5\nyears of operational data (11.7 million GPU hours) on GPU errors. Our major\nfindings include: (i) H100 GPU memory resilience is worse than A100 GPU memory,\nwith 3.2x lower per-GPU MTBE for memory errors, (ii) The GPU memory\nerror-recovery mechanisms on H100 GPUs are insufficient to handle the increased\nmemory capacity, (iii) H100 GPUs demonstrate significantly improved GPU\nhardware resilience over A100 GPUs with respect to critical hardware\ncomponents, (iv) GPU errors on both A100 and H100 GPUs frequently result in job\nfailures due to the lack of robust recovery mechanisms at the application\nlevel, and (v) We project the impact of GPU node availability on larger-scales\nand find that significant overprovisioning of 5% is necessary to handle GPU\nfailures.", "AI": {"tldr": "The study analyzes GPU resilience in Delta HPC, a large-scale AI system with 1,056 GPUs, using 2.5 years of operational data. Key findings highlight differences in memory resilience, error-recovery mechanisms, and hardware resilience between A100 and H100 GPUs, along with job failure risks and the need for 5% overprovisioning.", "motivation": "To understand and improve GPU resilience in large-scale AI systems like Delta HPC, given the increasing reliance on GPUs for high-performance computing.", "method": "Analyzed 2.5 years of operational data (11.7 million GPU hours) on GPU errors in Delta HPC, comparing A100 and H100 GPUs.", "result": "H100 GPUs show worse memory resilience but better hardware resilience than A100 GPUs. Error-recovery mechanisms are insufficient, leading to frequent job failures. Overprovisioning by 5% is needed to handle failures.", "conclusion": "GPU resilience varies between models, with H100 GPUs needing improved memory error-recovery. System-level overprovisioning is essential for large-scale deployments."}}
{"id": "2504.16767", "pdf": "https://arxiv.org/pdf/2504.16767", "abs": "https://arxiv.org/abs/2504.16767", "authors": ["Andrea N\u00f3voa", "Luca Magri"], "title": "Online model learning with data-assimilated reservoir computers", "categories": ["cs.LG", "physics.flu-dyn", "stat.AP"], "comment": "8 pages, 5 figures", "summary": "We propose an online learning framework for forecasting nonlinear\nspatio-temporal signals (fields). The method integrates (i) dimensionality\nreduction, here, a simple proper orthogonal decomposition (POD) projection;\n(ii) a generalized autoregressive model to forecast reduced dynamics, here, a\nreservoir computer; (iii) online adaptation to update the reservoir computer\n(the model), here, ensemble sequential data assimilation. We demonstrate the\nframework on a wake past a cylinder governed by the Navier-Stokes equations,\nexploring the assimilation of full flow fields (projected onto POD modes) and\nsparse sensors. Three scenarios are examined: a na\\\"ive physical state\nestimation; a two-fold estimation of physical and reservoir states; and a\nthree-fold estimation that also adjusts the model parameters. The two-fold\nstrategy significantly improves ensemble convergence and reduces reconstruction\nerror compared to the na\\\"ive approach. The three-fold approach enables robust\nonline training of partially-trained reservoir computers, overcoming\nlimitations of a priori training. By unifying data-driven reduced order\nmodelling with Bayesian data assimilation, this work opens new opportunities\nfor scalable online model learning for nonlinear time series forecasting.", "AI": {"tldr": "An online learning framework for forecasting nonlinear spatio-temporal signals using dimensionality reduction, autoregressive modeling, and online adaptation, demonstrated on a Navier-Stokes wake flow.", "motivation": "To improve forecasting of nonlinear spatio-temporal signals by integrating data-driven reduced order modeling with Bayesian data assimilation for scalable online learning.", "method": "Combines proper orthogonal decomposition (POD), reservoir computing for reduced dynamics, and ensemble sequential data assimilation for online adaptation. Tested on a cylinder wake flow with full and sparse sensor data.", "result": "The two-fold estimation strategy outperforms the naive approach in convergence and error reduction. The three-fold strategy enables robust online training of partially-trained models.", "conclusion": "The framework unifies reduced order modeling and data assimilation, offering scalable online learning for nonlinear time series forecasting."}}
{"id": "2309.16494", "pdf": "https://arxiv.org/pdf/2309.16494", "abs": "https://arxiv.org/abs/2309.16494", "authors": ["Zewei He", "Zixuan Chen", "Jinlei Li", "Ziqian Lu", "Xuecheng Sun", "Hao Luo", "Zhe-Ming Lu", "Evangelos K. Markakis"], "title": "Accurate and lightweight dehazing via multi-receptive-field non-local network and novel contrastive regularization", "categories": ["cs.CV"], "comment": "submitted to the IEEE Journal for possible publication", "summary": "Recently, deep learning-based methods have dominated image dehazing domain.\nAlthough very competitive dehazing performance has been achieved with\nsophisticated models, effective solutions for extracting useful features are\nstill under-explored. In addition, non-local network, which has made a\nbreakthrough in many vision tasks, has not been appropriately applied to image\ndehazing. Thus, a multi-receptive-field non-local network (MRFNLN) consisting\nof the multi-stream feature attention block (MSFAB) and cross non-local block\n(CNLB) is presented in this paper. We start with extracting richer features for\ndehazing. Specifically, we design a multi-stream feature extraction (MSFE)\nsub-block, which contains three parallel convolutions with different receptive\nfields (i.e., $1\\times 1$, $3\\times 3$, $5\\times 5$) for extracting multi-scale\nfeatures. Following MSFE, we employ an attention sub-block to make the model\nadaptively focus on important channels/regions. The MSFE and attention\nsub-blocks constitute our MSFAB. Then, we design a cross non-local block\n(CNLB), which can capture long-range dependencies beyond the query. Instead of\nthe same input source of query branch, the key and value branches are enhanced\nby fusing more preceding features. CNLB is computation-friendly by leveraging a\nspatial pyramid down-sampling (SPDS) strategy to reduce the computation and\nmemory consumption without sacrificing the performance. Last but not least, a\nnovel detail-focused contrastive regularization (DFCR) is presented by\nemphasizing the low-level details and ignoring the high-level semantic\ninformation in the representation space. Comprehensive experimental results\ndemonstrate that the proposed MRFNLN model outperforms recent state-of-the-art\ndehazing methods with less than 1.5 Million parameters.", "AI": {"tldr": "A multi-receptive-field non-local network (MRFNLN) is proposed for image dehazing, combining multi-scale feature extraction and attention mechanisms with a novel cross non-local block and detail-focused contrastive regularization, achieving state-of-the-art performance with fewer parameters.", "motivation": "Existing deep learning-based dehazing methods lack effective feature extraction and underutilize non-local networks, despite their success in other vision tasks.", "method": "MRFNLN integrates multi-stream feature attention blocks (MSFAB) for multi-scale feature extraction and attention, and cross non-local blocks (CNLB) for long-range dependencies. A spatial pyramid down-sampling strategy reduces computation, and detail-focused contrastive regularization (DFCR) enhances low-level details.", "result": "The model outperforms state-of-the-art dehazing methods with less than 1.5 million parameters.", "conclusion": "MRFNLN effectively addresses feature extraction and non-local network application in dehazing, offering a lightweight yet high-performing solution."}}
{"id": "2503.11950", "pdf": "https://arxiv.org/pdf/2503.11950", "abs": "https://arxiv.org/abs/2503.11950", "authors": ["Ankur Barthwal", "Molly Campbell", "Ajay Kumar Shrestha"], "title": "Privacy Ethics Alignment in AI: A Stakeholder-Centric Framework for Ethical AI", "categories": ["cs.CY", "cs.AI"], "comment": "Submitted to peer reviwed venue", "summary": "The increasing integration of Artificial Intelligence (AI) in digital\necosystems has reshaped privacy dynamics, particularly for young digital\ncitizens navigating data-driven environments. This study explores evolving\nprivacy concerns across three key stakeholder groups, digital citizens (ages\n16-19), parents/educators, and AI professionals, and assesses differences in\ndata ownership, trust, transparency, parental mediation, education, and\nrisk-benefit perceptions. Employing a grounded theory methodology, this\nresearch synthesizes insights from 482 participants through structured surveys,\nqualitative interviews, and focus groups. The findings reveal distinct privacy\nexpectations: Young users emphasize autonomy and digital freedom, while parents\nand educators advocate for regulatory oversight and AI literacy programs. AI\nprofessionals, in contrast, prioritize the balance between ethical system\ndesign and technological efficiency. The data further highlights gaps in AI\nliteracy and transparency, emphasizing the need for comprehensive,\nstakeholder-driven privacy frameworks that accommodate diverse user needs.\nUsing comparative thematic analysis, this study identifies key tensions in\nprivacy governance and develops the novel Privacy-Ethics Alignment in AI\n(PEA-AI) model, which structures privacy decision-making as a dynamic\nnegotiation between stakeholders. By systematically analyzing themes such as\ntransparency, user control, risk perception, and parental mediation, this\nresearch provides a scalable, adaptive foundation for AI governance, ensuring\nthat privacy protections evolve alongside emerging AI technologies and\nyouth-centric digital interactions.", "AI": {"tldr": "The study examines AI's impact on privacy for young digital citizens, parents/educators, and AI professionals, revealing differing expectations and proposing the PEA-AI model for stakeholder-driven privacy governance.", "motivation": "To address evolving privacy concerns in AI-integrated digital ecosystems, especially for young users, and identify gaps in AI literacy and transparency.", "method": "Grounded theory methodology with 482 participants, using surveys, interviews, and focus groups, followed by comparative thematic analysis.", "result": "Young users prioritize autonomy, parents/educators favor regulation and AI literacy, and AI professionals focus on ethical design. Gaps in transparency and literacy were noted.", "conclusion": "The PEA-AI model offers a scalable framework for privacy governance, balancing stakeholder needs and adapting to AI advancements."}}
{"id": "2505.01427", "pdf": "https://arxiv.org/pdf/2505.01427", "abs": "https://arxiv.org/abs/2505.01427", "authors": ["Maksym Shamrai"], "title": "Perturbation Analysis of Singular Values in Concatenated Matrices", "categories": ["cs.LG", "stat.ML"], "comment": "13 pages", "summary": "Concatenating matrices is a common technique for uncovering shared structures\nin data through singular value decomposition (SVD) and low-rank approximations.\nThe fundamental question arises: How does the singular value spectrum of the\nconcatenated matrix relate to the spectra of its individual components? In the\npresent work, we develop a perturbation technique that extends classical\nresults such as Weyl's inequality to concatenated matrices. We setup analytical\nbounds that quantify stability of singular values under small perturbations in\nsubmatrices. The results demonstrate that if submatrices are close in a norm,\ndominant singular values of the concatenated matrix remain stable enabling\ncontrolled trade-offs between accuracy and compression. These provide a\ntheoretical basis for improved matrix clustering and compression strategies\nwith applications in the numerical linear algebra, signal processing, and\ndata-driven modeling.", "AI": {"tldr": "The paper explores how the singular value spectrum of a concatenated matrix relates to its submatrices, using perturbation techniques to derive stability bounds for singular values under small perturbations.", "motivation": "To understand the relationship between the singular value spectra of concatenated matrices and their individual components, and to provide theoretical insights for matrix clustering and compression.", "method": "Develops a perturbation technique extending classical results like Weyl's inequality to concatenated matrices, setting analytical bounds for singular value stability.", "result": "Shows that dominant singular values of the concatenated matrix remain stable if submatrices are close in norm, enabling accuracy-compression trade-offs.", "conclusion": "Provides a theoretical foundation for improved matrix clustering and compression, with applications in numerical linear algebra, signal processing, and data-driven modeling."}}
{"id": "2312.01431", "pdf": "https://arxiv.org/pdf/2312.01431", "abs": "https://arxiv.org/abs/2312.01431", "authors": ["Wenjie Pei", "Qizhong Tan", "Guangming Lu", "Jiandong Tian", "Jun Yu"], "title": "D$^2$ST-Adapter: Disentangled-and-Deformable Spatio-Temporal Adapter for Few-shot Action Recognition", "categories": ["cs.CV"], "comment": "Accepted by ICCV2025", "summary": "Adapting pre-trained image models to video modality has proven to be an\neffective strategy for robust few-shot action recognition. In this work, we\nexplore the potential of adapter tuning in image-to-video model adaptation and\npropose a novel video adapter tuning framework, called\nDisentangled-and-Deformable Spatio-Temporal Adapter (D$^2$ST-Adapter). It\nfeatures a lightweight design, low adaptation overhead and powerful\nspatio-temporal feature adaptation capabilities. D$^2$ST-Adapter is structured\nwith an internal dual-pathway architecture that enables built-in disentangled\nencoding of spatial and temporal features within the adapter, seamlessly\nintegrating into the single-stream feature learning framework of pre-trained\nimage models. In particular, we develop an efficient yet effective\nimplementation of the D$^2$ST-Adapter, incorporating the specially devised\nanisotropic Deformable Spatio-Temporal Attention as its pivotal operation. This\nmechanism can be individually tailored for two pathways with anisotropic\nsampling densities along the spatial and temporal domains in 3D spatio-temporal\nspace, enabling disentangled encoding of spatial and temporal features while\nmaintaining a lightweight design. Extensive experiments by instantiating our\nmethod on both pre-trained ResNet and ViT demonstrate the superiority of our\nmethod over state-of-the-art methods. Our method is particularly well-suited to\nchallenging scenarios where temporal dynamics are critical for action\nrecognition. Code is available at https://github.com/qizhongtan/D2ST-Adapter.", "AI": {"tldr": "A novel video adapter tuning framework, D\u00b2ST-Adapter, is proposed for few-shot action recognition, featuring lightweight design and powerful spatio-temporal adaptation.", "motivation": "To adapt pre-trained image models to video modality effectively, especially for few-shot action recognition, leveraging disentangled spatial and temporal feature encoding.", "method": "D\u00b2ST-Adapter uses a dual-pathway architecture with anisotropic Deformable Spatio-Temporal Attention for disentangled feature encoding in a lightweight design.", "result": "Outperforms state-of-the-art methods when instantiated on pre-trained ResNet and ViT, excelling in scenarios where temporal dynamics are crucial.", "conclusion": "D\u00b2ST-Adapter is a superior, efficient solution for video model adaptation, particularly in challenging temporal-dynamic scenarios."}}
{"id": "2503.15426", "pdf": "https://arxiv.org/pdf/2503.15426", "abs": "https://arxiv.org/abs/2503.15426", "authors": ["Wei Tang", "Yanpeng Sun", "Qinying Gu", "Zechao Li"], "title": "Visual Position Prompt for MLLM based Visual Grounding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Although Multimodal Large Language Models (MLLMs) excel at various\nimage-related tasks, they encounter challenges in precisely aligning\ncoordinates with spatial information within images, particularly in\nposition-aware tasks such as visual grounding. This limitation arises from two\nkey factors. First, MLLMs lack explicit spatial references, making it difficult\nto associate textual descriptions with precise image locations. Second, their\nfeature extraction processes prioritize global context over fine-grained\nspatial details, leading to weak localization capability. To address these\nissues, we introduce VPP-LLaVA, an MLLM enhanced with Visual Position Prompt\n(VPP) to improve its grounding capability. VPP-LLaVA integrates two\ncomplementary mechanisms: the global VPP overlays a learnable, axis-like tensor\nonto the input image to provide structured spatial cues, while the local VPP\nincorporates position-aware queries to support fine-grained localization.To\neffectively train our model with spatial guidance, we further introduce\nVPP-SFT, a curated dataset of 0.6M high-quality visual grounding samples.\nDesigned in a compact format, it enables efficient training and is\nsignificantly smaller than datasets used by other MLLMs (e.g., ~21M samples in\nMiniGPT-v2), yet still provides a strong performance boost. The resulting\nmodel, VPP-LLaVA, not only achieves state-of-the-art results on standard visual\ngrounding benchmarks but also demonstrates strong zero-shot generalization to\nchallenging unseen datasets. Code and dataset will be released upon acceptance\nat https://github.com/WayneTomas/VPP-LLaVA.", "AI": {"tldr": "VPP-LLaVA enhances MLLMs with Visual Position Prompt (VPP) to improve spatial alignment in visual grounding tasks, achieving state-of-the-art results.", "motivation": "MLLMs struggle with precise spatial alignment due to lack of explicit spatial references and weak localization capabilities.", "method": "Introduces VPP-LLaVA with global and local VPP mechanisms, trained on the curated VPP-SFT dataset of 0.6M samples.", "result": "Achieves top performance on visual grounding benchmarks and strong zero-shot generalization.", "conclusion": "VPP-LLaVA effectively addresses MLLMs' spatial alignment limitations, offering a compact yet powerful solution."}}
{"id": "2505.02922", "pdf": "https://arxiv.org/pdf/2505.02922", "abs": "https://arxiv.org/abs/2505.02922", "authors": ["Yaoqi Chen", "Jinkai Zhang", "Baotong Lu", "Qianxi Zhang", "Chengruidong Zhang", "Jingjia Luo", "Di Liu", "Huiqiang Jiang", "Qi Chen", "Jing Liu", "Bailu Ding", "Xiao Yan", "Jiawei Jiang", "Chen Chen", "Mingxing Zhang", "Yuqing Yang", "Fan Yang", "Mao Yang"], "title": "RetroInfer: A Vector-Storage Approach for Scalable Long-Context LLM Inference", "categories": ["cs.LG"], "comment": "17 pages", "summary": "The growing context lengths of large language models (LLMs) pose significant\nchallenges for efficient inference, primarily due to GPU memory and bandwidth\nconstraints. We present RetroInfer, a novel system that reconceptualizes the\nkey-value (KV) cache as a vector storage system which exploits the inherent\nattention sparsity to accelerate long-context LLM inference. At its core is the\nwave index, an Attention-aWare VEctor index that enables efficient and accurate\nretrieval of critical tokens through techniques such as tripartite attention\napproximation, accuracy-bounded attention estimation, and segmented clustering.\nComplementing this is the wave buffer, which coordinates KV cache placement and\noverlaps computation and data transfer across GPU and CPU to sustain high\nthroughput. Unlike prior sparsity-based methods that struggle with token\nselection and hardware coordination, RetroInfer delivers robust performance\nwithout compromising model accuracy. Experiments on long-context benchmarks\nshow up to 4.5X speedup over full attention within GPU memory limits and up to\n10.5X over sparse attention baselines when KV cache is extended to CPU memory,\nall while preserving full-attention-level accuracy.", "AI": {"tldr": "RetroInfer accelerates long-context LLM inference by reimagining the KV cache as a vector storage system, leveraging attention sparsity for efficiency without accuracy loss.", "motivation": "Addressing GPU memory and bandwidth constraints in LLMs with growing context lengths.", "method": "Uses a wave index for efficient token retrieval and a wave buffer for KV cache coordination, combining tripartite attention approximation and segmented clustering.", "result": "Achieves up to 4.5X speedup over full attention and 10.5X over sparse baselines, maintaining full-attention accuracy.", "conclusion": "RetroInfer offers a robust solution for efficient long-context LLM inference, balancing performance and accuracy."}}
{"id": "2401.01042", "pdf": "https://arxiv.org/pdf/2401.01042", "abs": "https://arxiv.org/abs/2401.01042", "authors": ["Mohammad Rostami", "Dayuan Jian", "Ruitong Sun"], "title": "Relating Events and Frames Based on Self-Supervised Learning and Uncorrelated Conditioning for Unsupervised Domain Adaptation", "categories": ["cs.CV"], "comment": null, "summary": "Event-based cameras provide accurate and high temporal resolution\nmeasurements for performing computer vision tasks in challenging scenarios,\nsuch as high-dynamic range environments and fast-motion maneuvers. Despite\ntheir advantages, utilizing deep learning for event-based vision encounters a\nsignificant obstacle due to the scarcity of annotated data caused by the\nrelatively recent emergence of event-based cameras. To overcome this\nlimitation, leveraging the knowledge available from annotated data obtained\nwith conventional frame-based cameras presents an effective solution based on\nunsupervised domain adaptation. We propose a new algorithm tailored for\nadapting a deep neural network trained on annotated frame-based data to\ngeneralize well on event-based unannotated data. Our approach incorporates\nuncorrelated conditioning and self-supervised learning in an adversarial\nlearning scheme to close the gap between the two source and target domains. By\napplying self-supervised learning, the algorithm learns to align the\nrepresentations of event-based data with those from frame-based camera data,\nthereby facilitating knowledge transfer.Furthermore, the inclusion of\nuncorrelated conditioning ensures that the adapted model effectively\ndistinguishes between event-based and conventional data, enhancing its ability\nto classify event-based images accurately.Through empirical experimentation and\nevaluation, we demonstrate that our algorithm surpasses existing approaches\ndesigned for the same purpose using two benchmarks. The superior performance of\nour solution is attributed to its ability to effectively utilize annotated data\nfrom frame-based cameras and transfer the acquired knowledge to the event-based\nvision domain.", "AI": {"tldr": "A new algorithm for adapting deep neural networks from frame-based to event-based camera data using unsupervised domain adaptation, self-supervised learning, and adversarial training.", "motivation": "Overcoming the scarcity of annotated event-based data by leveraging annotated frame-based data.", "method": "Combines uncorrelated conditioning and self-supervised learning in an adversarial scheme to align representations between domains.", "result": "Outperforms existing approaches on benchmarks by effectively transferring knowledge from frame-based to event-based data.", "conclusion": "The proposed algorithm successfully bridges the gap between frame-based and event-based vision, enhancing classification accuracy."}}
{"id": "2503.19948", "pdf": "https://arxiv.org/pdf/2503.19948", "abs": "https://arxiv.org/abs/2503.19948", "authors": ["Alexander Gambashidze", "Konstantin Sobolev", "Andrey Kuznetsov", "Ivan Oseledets"], "title": "Test-Time Reasoning Through Visual Human Preferences with VLMs and Soft Rewards", "categories": ["cs.CV", "cs.AI"], "comment": "We are withdrawing this paper because the main contributions and\n  methodology have significantly changed after further research and\n  experimental updates. The current version no longer reflects our results and\n  main contribution / topic", "summary": "Can Visual Language Models (VLMs) effectively capture human visual\npreferences? This work addresses this question by training VLMs to think about\npreferences at test time, employing reinforcement learning methods inspired by\nDeepSeek R1 and OpenAI O1. Using datasets such as ImageReward and Human\nPreference Score v2 (HPSv2), our models achieve accuracies of 64.9% on the\nImageReward test set (trained on ImageReward official split) and 65.4% on HPSv2\n(trained on approximately 25% of its data). These results match traditional\nencoder-based models while providing transparent reasoning and enhanced\ngeneralization. This approach allows to use not only rich VLM world knowledge,\nbut also its potential to think, yielding interpretable outcomes that help\ndecision-making processes. By demonstrating that human visual preferences\nreasonable by current VLMs, we introduce efficient soft-reward strategies for\nimage ranking, outperforming simplistic selection or scoring methods. This\nreasoning capability enables VLMs to rank arbitrary images-regardless of aspect\nratio or complexity-thereby potentially amplifying the effectiveness of visual\nPreference Optimization. By reducing the need for extensive markup while\nimproving reward generalization and explainability, our findings can be a\nstrong mile-stone that will enhance text-to-vision models even further.", "AI": {"tldr": "VLMs trained with reinforcement learning achieve competitive accuracy in capturing human visual preferences, offering transparent reasoning and better generalization.", "motivation": "To determine if VLMs can effectively capture human visual preferences and improve decision-making processes with interpretable outcomes.", "method": "Employ reinforcement learning on datasets like ImageReward and HPSv2, leveraging VLM capabilities for reasoning and generalization.", "result": "Achieves 64.9% accuracy on ImageReward and 65.4% on HPSv2, matching traditional models while providing explainable results.", "conclusion": "VLMs can reasonably capture human preferences, offering efficient soft-reward strategies for image ranking and enhancing text-to-vision models."}}
{"id": "2505.04396", "pdf": "https://arxiv.org/pdf/2505.04396", "abs": "https://arxiv.org/abs/2505.04396", "authors": ["Jingnan Wang", "Jie Chao", "Shangshang Yang", "Kaijun Ren", "Kefeng Deng", "Xi Chen", "Yaxin Liu", "Hanqiuzi Wen", "Ziniu Xiao", "Lifeng Zhang", "Xiaodong Wang", "Jiping Guan", "Baoxiang Pan"], "title": "Supporting renewable energy planning and operation with data-driven high-resolution ensemble weather forecast", "categories": ["cs.LG", "physics.ao-ph"], "comment": null, "summary": "The planning and operation of renewable energy, especially wind power, depend\ncrucially on accurate, timely, and high-resolution weather information.\nCoarse-grid global numerical weather forecasts are typically downscaled to meet\nthese requirements, introducing challenges of scale inconsistency, process\nrepresentation error, computation cost, and entanglement of distinct\nuncertainty sources from chaoticity, model bias, and large-scale forcing. We\naddress these challenges by learning the climatological distribution of a\ntarget wind farm using its high-resolution numerical weather simulations. An\noptimal combination of this learned high-resolution climatological prior with\ncoarse-grid large scale forecasts yields highly accurate, fine-grained,\nfull-variable, large ensemble of weather pattern forecasts. Using observed\nmeteorological records and wind turbine power outputs as references, the\nproposed methodology verifies advantageously compared to existing\nnumerical/statistical forecasting-downscaling pipelines, regarding either\ndeterministic/probabilistic skills or economic gains. Moreover, a 100-member,\n10-day forecast with spatial resolution of 1 km and output frequency of 15 min\ntakes < 1 hour on a moderate-end GPU, as contrast to $\\mathcal{O}(10^3)$ CPU\nhours for conventional numerical simulation. By drastically reducing\ncomputational costs while maintaining accuracy, our method paves the way for\nmore efficient and reliable renewable energy planning and operation.", "AI": {"tldr": "A method combining learned high-resolution climatological data with coarse-grid forecasts improves wind power weather predictions efficiently.", "motivation": "Accurate, high-resolution weather forecasts are critical for renewable energy planning, but current methods face scale, cost, and uncertainty challenges.", "method": "Learns climatological distribution from high-resolution simulations and combines it with coarse-grid forecasts for fine-grained, ensemble predictions.", "result": "Outperforms existing methods in accuracy and cost, with forecasts generated in <1 hour on a GPU versus thousands of CPU hours traditionally.", "conclusion": "The method enables efficient, reliable renewable energy planning by reducing computational costs while maintaining accuracy."}}
{"id": "2402.02242", "pdf": "https://arxiv.org/pdf/2402.02242", "abs": "https://arxiv.org/abs/2402.02242", "authors": ["Yi Xin", "Jianjiang Yang", "Siqi Luo", "Yuntao Du", "Qi Qin", "Kangrui Cen", "Yangfan He", "Bin Fu", "Xiaokang Yang", "Guangtao Zhai", "Ming-Hsuan Yang", "Xiaohong Liu"], "title": "Parameter-Efficient Fine-Tuning for Pre-Trained Vision Models: A Survey and Benchmark", "categories": ["cs.CV", "cs.LG"], "comment": "Submitted to IEEE TPAMI", "summary": "Pre-trained vision models (PVMs) have demonstrated remarkable adaptability\nacross a wide range of downstream vision tasks, showcasing exceptional\nperformance. However, as these models scale to billions or even trillions of\nparameters, conventional full fine-tuning has become increasingly impractical\ndue to its high computational and storage demands. To address these challenges,\nparameter-efficient fine-tuning (PEFT) has emerged as a promising alternative,\naiming to achieve performance comparable to full fine-tuning while making\nminimal adjustments to the model parameters. This paper presents a\ncomprehensive survey of the latest advancements in the visual PEFT field,\nsystematically reviewing current methodologies and categorizing them into four\nprimary categories: addition-based, partial-based, unified-based, and\nmulti-task tuning. In addition, this paper offers an in-depth analysis of\nwidely used visual datasets and real-world applications where PEFT methods have\nbeen successfully applied. Furthermore, this paper introduces the V-PEFT Bench,\na unified benchmark designed to standardize the evaluation of PEFT methods\nacross a diverse set of vision tasks, ensuring consistency and fairness in\ncomparison. Finally, the paper outlines potential directions for future\nresearch to propel advances in the PEFT field. A comprehensive collection of\nresources is available at\nhttps://github.com/synbol/Awesome-Parameter-Efficient-Transfer-Learning.", "AI": {"tldr": "A survey of parameter-efficient fine-tuning (PEFT) methods for pre-trained vision models, categorizing approaches, analyzing datasets, and introducing a benchmark for evaluation.", "motivation": "Address the impracticality of full fine-tuning for large-scale pre-trained vision models due to high computational and storage demands.", "method": "Systematically reviews PEFT methodologies, categorizing them into four types: addition-based, partial-based, unified-based, and multi-task tuning. Introduces the V-PEFT Bench for standardized evaluation.", "result": "Provides a comprehensive overview of PEFT advancements, successful applications, and a unified benchmark for fair comparison.", "conclusion": "Highlights the potential of PEFT and outlines future research directions to advance the field."}}
{"id": "2504.09039", "pdf": "https://arxiv.org/pdf/2504.09039", "abs": "https://arxiv.org/abs/2504.09039", "authors": ["Gen Li", "Yang Xiao", "Jie Ji", "Kaiyuan Deng", "Bo Hui", "Linke Guo", "Xiaolong Ma"], "title": "Sculpting Memory: Multi-Concept Forgetting in Diffusion Models via Dynamic Mask and Concept-Aware Optimization", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "ICCV2025(Accept)", "summary": "Text-to-image (T2I) diffusion models have achieved remarkable success in\ngenerating high-quality images from textual prompts. However, their ability to\nstore vast amounts of knowledge raises concerns in scenarios where selective\nforgetting is necessary, such as removing copyrighted content, reducing biases,\nor eliminating harmful concepts. While existing unlearning methods can remove\ncertain concepts, they struggle with multi-concept forgetting due to\ninstability, residual knowledge persistence, and generation quality\ndegradation. To address these challenges, we propose \\textbf{Dynamic Mask\ncoupled with Concept-Aware Loss}, a novel unlearning framework designed for\nmulti-concept forgetting in diffusion models. Our \\textbf{Dynamic Mask}\nmechanism adaptively updates gradient masks based on current optimization\nstates, allowing selective weight modifications that prevent interference with\nunrelated knowledge. Additionally, our \\textbf{Concept-Aware Loss} explicitly\nguides the unlearning process by enforcing semantic consistency through\nsuperclass alignment, while a regularization loss based on knowledge\ndistillation ensures that previously unlearned concepts remain forgotten during\nsequential unlearning. We conduct extensive experiments to evaluate our\napproach. Results demonstrate that our method outperforms existing unlearning\ntechniques in forgetting effectiveness, output fidelity, and semantic\ncoherence, particularly in multi-concept scenarios. Our work provides a\nprincipled and flexible framework for stable and high-fidelity unlearning in\ngenerative models. The code will be released publicly.", "AI": {"tldr": "A novel unlearning framework for diffusion models, using Dynamic Mask and Concept-Aware Loss, improves multi-concept forgetting while maintaining image quality and semantic coherence.", "motivation": "Addressing the need for selective forgetting in diffusion models (e.g., removing copyrighted or harmful content) and overcoming limitations of existing unlearning methods in multi-concept scenarios.", "method": "Proposes Dynamic Mask for adaptive gradient updates and Concept-Aware Loss for semantic consistency, combined with knowledge distillation to retain unlearned concepts.", "result": "Outperforms existing methods in forgetting effectiveness, output fidelity, and semantic coherence, especially for multi-concept forgetting.", "conclusion": "Provides a flexible and stable framework for high-fidelity unlearning in generative models, with public code release planned."}}
{"id": "2505.12884", "pdf": "https://arxiv.org/pdf/2505.12884", "abs": "https://arxiv.org/abs/2505.12884", "authors": ["Yuanze Hu", "Zhaoxin Fan", "Xinyu Wang", "Gen Li", "Ye Qiu", "Zhichao Yang", "Wenjun Wu", "Kejian Wu", "Yifan Sun", "Xiaotie Deng", "Jin Dong"], "title": "TinyAlign: Boosting Lightweight Vision-Language Models by Mitigating Modal Alignment Bottlenecks", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Lightweight Vision-Language Models (VLMs) are indispensable for\nresource-constrained applications. The prevailing approach to aligning vision\nand language models involves freezing both the vision encoder and the language\nmodel while training small connector modules. However, this strategy heavily\ndepends on the intrinsic capabilities of the language model, which can be\nsuboptimal for lightweight models with limited representational capacity. In\nthis work, we investigate this alignment bottleneck through the lens of mutual\ninformation, demonstrating that the constrained capacity of the language model\ninherently limits the Effective Mutual Information (EMI) between multimodal\ninputs and outputs, thereby compromising alignment quality. To address this\nchallenge, we propose TinyAlign, a novel framework inspired by\nRetrieval-Augmented Generation, which strategically retrieves relevant context\nfrom a memory bank to enrich multimodal inputs and enhance their alignment.\nExtensive empirical evaluations reveal that TinyAlign significantly reduces\ntraining loss, accelerates convergence, and enhances task performance.\nRemarkably, it allows models to achieve baseline-level performance with only\n40\\% of the fine-tuning data, highlighting exceptional data efficiency. Our\nwork thus offers a practical pathway for developing more capable lightweight\nVLMs while introducing a fresh theoretical lens to better understand and\naddress alignment bottlenecks in constrained multimodal systems.", "AI": {"tldr": "TinyAlign improves alignment in lightweight VLMs by retrieving context to enhance multimodal inputs, achieving better performance with less data.", "motivation": "Current alignment methods for lightweight VLMs rely on frozen models, limiting performance due to constrained language model capacity.", "method": "Proposes TinyAlign, a framework using retrieval-augmented generation to enrich inputs and improve alignment via a memory bank.", "result": "TinyAlign reduces training loss, speeds convergence, and achieves baseline performance with 40% of fine-tuning data.", "conclusion": "TinyAlign offers a practical solution for lightweight VLMs and provides new insights into alignment bottlenecks."}}
{"id": "2403.04444", "pdf": "https://arxiv.org/pdf/2403.04444", "abs": "https://arxiv.org/abs/2403.04444", "authors": ["Qingyuan Cai", "Xuecai Hu", "Saihui Hou", "Li Yao", "Yongzhen Huang"], "title": "Disentangled Diffusion-Based 3D Human Pose Estimation with Hierarchical Spatial and Temporal Denoiser", "categories": ["cs.CV"], "comment": "Accepted by AAAI24", "summary": "Recently, diffusion-based methods for monocular 3D human pose estimation have\nachieved state-of-the-art (SOTA) performance by directly regressing the 3D\njoint coordinates from the 2D pose sequence. Although some methods decompose\nthe task into bone length and bone direction prediction based on the human\nanatomical skeleton to explicitly incorporate more human body prior\nconstraints, the performance of these methods is significantly lower than that\nof the SOTA diffusion-based methods. This can be attributed to the tree\nstructure of the human skeleton. Direct application of the disentangled method\ncould amplify the accumulation of hierarchical errors, propagating through each\nhierarchy. Meanwhile, the hierarchical information has not been fully explored\nby the previous methods. To address these problems, a Disentangled\nDiffusion-based 3D Human Pose Estimation method with Hierarchical Spatial and\nTemporal Denoiser is proposed, termed DDHPose. In our approach: (1) We\ndisentangle the 3D pose and diffuse the bone length and bone direction during\nthe forward process of the diffusion model to effectively model the human pose\nprior. A disentanglement loss is proposed to supervise diffusion model\nlearning. (2) For the reverse process, we propose Hierarchical Spatial and\nTemporal Denoiser (HSTDenoiser) to improve the hierarchical modeling of each\njoint. Our HSTDenoiser comprises two components: the Hierarchical-Related\nSpatial Transformer (HRST) and the Hierarchical-Related Temporal Transformer\n(HRTT). HRST exploits joint spatial information and the influence of the parent\njoint on each joint for spatial modeling, while HRTT utilizes information from\nboth the joint and its hierarchical adjacent joints to explore the hierarchical\ntemporal correlations among joints. Code and models are available at\nhttps://github.com/Andyen512/DDHPose", "AI": {"tldr": "DDHPose introduces a disentangled diffusion-based method for 3D human pose estimation, addressing hierarchical error accumulation with a novel Hierarchical Spatial and Temporal Denoiser (HSTDenoiser).", "motivation": "Existing methods either underperform SOTA diffusion-based approaches or fail to fully exploit hierarchical skeleton information, leading to error propagation.", "method": "Disentangles bone length and direction during diffusion, introduces a disentanglement loss, and employs HSTDenoiser with HRST and HRTT for hierarchical spatial and temporal modeling.", "result": "Improves 3D pose estimation by better modeling human pose priors and hierarchical joint relationships.", "conclusion": "DDHPose effectively addresses hierarchical error propagation and outperforms previous methods by leveraging disentangled diffusion and hierarchical modeling."}}
{"id": "2504.17677", "pdf": "https://arxiv.org/pdf/2504.17677", "abs": "https://arxiv.org/abs/2504.17677", "authors": ["Jarne Thys", "Sebe Vanbrabant", "Davy Vanacken", "Gustavo Rovelo Ruiz"], "title": "INSIGHT: Bridging the Student-Teacher Gap in Times of Large Language Models", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted author version for the D-SAIL Workshop - Transformative\n  Curriculum Design: Digitalisation, Sustainability, and AI Literacy for 21st\n  Century Learning, July 22, 2025, Palermo, Italy", "summary": "The rise of AI, especially Large Language Models, presents challenges and\nopportunities to integrate such technology into the classroom. AI has the\npotential to revolutionize education by helping teaching staff with various\ntasks, such as personalizing their teaching methods, but it also raises\nconcerns, for example, about the degradation of student-teacher interactions\nand user privacy. Based on interviews with teaching staff, this paper\nintroduces INSIGHT, a proof of concept to combine various AI tools to assist\nteaching staff and students in the process of solving exercises. INSIGHT has a\nmodular design that allows it to be integrated into various higher education\ncourses. We analyze students' questions to an LLM by extracting keywords, which\nwe use to dynamically build an FAQ from students' questions and provide new\ninsights for the teaching staff to use for more personalized face-to-face\nsupport. Future work could build upon INSIGHT by using the collected data to\nprovide adaptive learning and adjust content based on student progress and\nlearning styles to offer a more interactive and inclusive learning experience.", "AI": {"tldr": "The paper introduces INSIGHT, a modular AI tool designed to assist teaching staff and students in higher education by analyzing student questions to an LLM, building dynamic FAQs, and enabling personalized support.", "motivation": "The rise of AI in education presents opportunities for personalized teaching but also concerns about student-teacher interactions and privacy. This paper aims to address these challenges by integrating AI tools to enhance learning.", "method": "INSIGHT uses a modular design to analyze student questions to an LLM, extracting keywords to dynamically build FAQs and provide insights for personalized teaching support.", "result": "INSIGHT successfully integrates AI tools into higher education courses, offering a proof of concept for improving teaching and learning processes.", "conclusion": "Future work could expand INSIGHT by using collected data for adaptive learning, tailoring content to student progress and styles for a more interactive and inclusive experience."}}
{"id": "2505.13768", "pdf": "https://arxiv.org/pdf/2505.13768", "abs": "https://arxiv.org/abs/2505.13768", "authors": ["Ruiquan Huang", "Donghao Li", "Chengshuai Shi", "Cong Shen", "Jing Yang"], "title": "Augmenting Online RL with Offline Data is All You Need: A Unified Hybrid RL Algorithm Design and Analysis", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted by UAI2025", "summary": "This paper investigates a hybrid learning framework for reinforcement\nlearning (RL) in which the agent can leverage both an offline dataset and\nonline interactions to learn the optimal policy. We present a unified algorithm\nand analysis and show that augmenting confidence-based online RL algorithms\nwith the offline dataset outperforms any pure online or offline algorithm alone\nand achieves state-of-the-art results under two learning metrics, i.e.,\nsub-optimality gap and online learning regret. Specifically, we show that our\nalgorithm achieves a sub-optimality gap\n$\\tilde{O}(\\sqrt{1/(N_0/\\mathtt{C}(\\pi^*|\\rho)+N_1}) )$, where\n$\\mathtt{C}(\\pi^*|\\rho)$ is a new concentrability coefficient, $N_0$ and $N_1$\nare the numbers of offline and online samples, respectively. For regret\nminimization, we show that it achieves a constant $\\tilde{O}(\n\\sqrt{N_1/(N_0/\\mathtt{C}(\\pi^{-}|\\rho)+N_1)} )$ speed-up compared to pure\nonline learning, where $\\mathtt{C}(\\pi^-|\\rho)$ is the concentrability\ncoefficient over all sub-optimal policies. Our results also reveal an\ninteresting separation on the desired coverage properties of the offline\ndataset for sub-optimality gap minimization and regret minimization. We further\nvalidate our theoretical findings in several experiments in special RL models\nsuch as linear contextual bandits and Markov decision processes (MDPs).", "AI": {"tldr": "A hybrid learning framework for RL combines offline datasets and online interactions, outperforming pure online or offline methods. It achieves state-of-the-art results in sub-optimality gap and regret minimization, with theoretical and experimental validation.", "motivation": "To improve RL performance by leveraging both offline datasets and online interactions, addressing limitations of pure online or offline methods.", "method": "A unified algorithm combining confidence-based online RL with offline datasets, analyzed under sub-optimality gap and regret metrics.", "result": "The algorithm achieves improved sub-optimality gap and regret minimization, with theoretical bounds and experimental validation in linear contextual bandits and MDPs.", "conclusion": "The hybrid framework outperforms pure methods, revealing insights into offline dataset coverage for different learning objectives."}}
{"id": "2403.10798", "pdf": "https://arxiv.org/pdf/2403.10798", "abs": "https://arxiv.org/abs/2403.10798", "authors": ["Shichao Kan", "Yuhai Deng", "Jiale Fu", "Lihui Cen", "Zhe Qu", "Linna Zhang", "Yixiong Liang", "Yigang Cen"], "title": "Object Retrieval for Visual Question Answering with Outside Knowledge", "categories": ["cs.CV"], "comment": null, "summary": "Retrieval-augmented generation (RAG) with large language models (LLMs) plays\na crucial role in question answering, as LLMs possess limited knowledge and are\nnot updated with continuously growing information. Most recent work on RAG has\nfocused primarily on text-based or large-image retrieval, which constrains the\nbroader application of RAG models. We recognize that object-level retrieval is\nessential for addressing questions that extend beyond image content. To tackle\nthis issue, we propose a task of object retrieval for visual question answering\nwith outside knowledge (OR-OK-VQA), aimed to extend image-based content\nunderstanding in conjunction with LLMs. A key challenge in this task is\nretrieving diverse objects-related images that contribute to answering the\nquestions. To enable accurate and robust general object retrieval, it is\nnecessary to learn embeddings for local objects. This paper introduces a novel\nunsupervised deep feature embedding technique called multi-scale group\ncollaborative embedding learning (MS-GCEL), developed to learn embeddings for\nlong-tailed objects at different scales. Additionally, we establish an OK-VQA\nevaluation benchmark using images from the BelgaLogos, Visual Genome, and LVIS\ndatasets. Prior to the OK-VQA evaluation, we construct a benchmark of\nchallenges utilizing objects extracted from the COCO 2017 and VOC 2007 datasets\nto support the training and evaluation of general object retrieval models. Our\nevaluations on both general object retrieval and OK-VQA demonstrate the\neffectiveness of the proposed approach. The code and dataset will be publicly\nreleased for future research.", "AI": {"tldr": "The paper introduces a novel unsupervised deep feature embedding technique (MS-GCEL) for object retrieval in visual question answering, addressing limitations of text/image-based RAG models.", "motivation": "To extend RAG models beyond text/large-image retrieval by focusing on object-level retrieval for broader question-answering applications.", "method": "Proposes MS-GCEL for learning embeddings of long-tailed objects at different scales and establishes benchmarks for evaluation.", "result": "Demonstrates effectiveness in general object retrieval and OK-VQA tasks.", "conclusion": "The approach enhances RAG models for visual question answering, with code and datasets to be released for future research."}}
{"id": "2505.08228", "pdf": "https://arxiv.org/pdf/2505.08228", "abs": "https://arxiv.org/abs/2505.08228", "authors": ["Unai Gurbindo", "Axel Brando", "Jaume Abella", "Caroline K\u00f6nig"], "title": "Object detection in adverse weather conditions for autonomous vehicles using Instruct Pix2Pix", "categories": ["cs.CV", "cs.AI", "I.2.6; I.2.10; I.4.8; I.5.1"], "comment": "8 pages, 5 figures. Accepted at the International Joint Conference on\n  Neural Networks (IJCNN) 2025 (to appear)", "summary": "Enhancing the robustness of object detection systems under adverse weather\nconditions is crucial for the advancement of autonomous driving technology.\nThis study presents a novel approach leveraging the diffusion model Instruct\nPix2Pix to develop prompting methodologies that generate realistic datasets\nwith weather-based augmentations aiming to mitigate the impact of adverse\nweather on the perception capabilities of state-of-the-art object detection\nmodels, including Faster R-CNN and YOLOv10. Experiments were conducted in two\nenvironments, in the CARLA simulator where an initial evaluation of the\nproposed data augmentation was provided, and then on the real-world image data\nsets BDD100K and ACDC demonstrating the effectiveness of the approach in real\nenvironments.\n  The key contributions of this work are twofold: (1) identifying and\nquantifying the performance gap in object detection models under challenging\nweather conditions, and (2) demonstrating how tailored data augmentation\nstrategies can significantly enhance the robustness of these models. This\nresearch establishes a solid foundation for improving the reliability of\nperception systems in demanding environmental scenarios, and provides a pathway\nfor future advancements in autonomous driving.", "AI": {"tldr": "The paper proposes using Instruct Pix2Pix diffusion models for weather-based data augmentation to improve object detection robustness in adverse weather, tested in CARLA simulator and real-world datasets (BDD100K, ACDC).", "motivation": "Enhancing object detection robustness under adverse weather is critical for autonomous driving.", "method": "Leverages Instruct Pix2Pix diffusion model for weather-based data augmentation, tested on Faster R-CNN and YOLOv10 in CARLA and real-world datasets.", "result": "Identifies performance gaps in adverse weather and shows tailored data augmentation improves model robustness.", "conclusion": "Provides a foundation for reliable perception systems in challenging environments, advancing autonomous driving."}}
{"id": "2505.14415", "pdf": "https://arxiv.org/pdf/2505.14415", "abs": "https://arxiv.org/abs/2505.14415", "authors": ["Myung Jun Kim", "F\u00e9lix Lefebvre", "Ga\u00ebtan Brison", "Alexandre Perez-Lebel", "Ga\u00ebl Varoquaux"], "title": "Table Foundation Models: on knowledge pre-training for tabular learning", "categories": ["cs.LG"], "comment": null, "summary": "Table foundation models bring high hopes to data science: pre-trained on\ntabular data to embark knowledge or priors, they should facilitate downstream\ntasks on tables. One specific challenge is that of data semantics: numerical\nentries take their meaning from context, e.g., column name. Pre-trained neural\nnetworks that jointly model column names and table entries have recently\nboosted prediction accuracy. While these models outline the promises of world\nknowledge to interpret table values, they lack the convenience of popular\nfoundation models in text or vision. Indeed, they must be fine-tuned to bring\nbenefits, come with sizeable computation costs, and cannot easily be reused or\ncombined with other architectures. Here we introduce TARTE, a foundation model\nthat transforms tables to knowledge-enhanced vector representations using the\nstring to capture semantics. Pre-trained on large relational data, TARTE yields\nrepresentations that facilitate subsequent learning with little additional\ncost. These representations can be fine-tuned or combined with other learners,\ngiving models that push the state-of-the-art prediction performance and improve\nthe prediction/computation performance trade-off. Specialized to a task or a\ndomain, TARTE gives domain-specific representations that facilitate further\nlearning. Our study demonstrates an effective approach to knowledge\npre-training for tabular learning.", "AI": {"tldr": "TARTE is a foundation model for tabular data that enhances vector representations using strings to capture semantics, improving prediction accuracy and computation efficiency.", "motivation": "Existing table foundation models require fine-tuning, incur high computation costs, and lack reusability, limiting their convenience and performance.", "method": "TARTE pre-trains on large relational data to generate knowledge-enhanced vector representations, which can be fine-tuned or combined with other models.", "result": "TARTE improves prediction accuracy and computation performance, offering domain-specific representations for further learning.", "conclusion": "TARTE provides an effective approach to knowledge pre-training for tabular learning, addressing limitations of existing models."}}
{"id": "2403.11052", "pdf": "https://arxiv.org/pdf/2403.11052", "abs": "https://arxiv.org/abs/2403.11052", "authors": ["Jie Ren", "Yaxin Li", "Shenglai Zeng", "Han Xu", "Lingjuan Lyu", "Yue Xing", "Jiliang Tang"], "title": "Unveiling and Mitigating Memorization in Text-to-image Diffusion Models through Cross Attention", "categories": ["cs.CV", "cs.CR"], "comment": null, "summary": "Recent advancements in text-to-image diffusion models have demonstrated their\nremarkable capability to generate high-quality images from textual prompts.\nHowever, increasing research indicates that these models memorize and replicate\nimages from their training data, raising tremendous concerns about potential\ncopyright infringement and privacy risks. In our study, we provide a novel\nperspective to understand this memorization phenomenon by examining its\nrelationship with cross-attention mechanisms. We reveal that during\nmemorization, the cross-attention tends to focus disproportionately on the\nembeddings of specific tokens. The diffusion model is overfitted to these token\nembeddings, memorizing corresponding training images. To elucidate this\nphenomenon, we further identify and discuss various intrinsic findings of\ncross-attention that contribute to memorization. Building on these insights, we\nintroduce an innovative approach to detect and mitigate memorization in\ndiffusion models. The advantage of our proposed method is that it will not\ncompromise the speed of either the training or the inference processes in these\nmodels while preserving the quality of generated images. Our code is available\nat https://github.com/renjie3/MemAttn .", "AI": {"tldr": "The paper investigates memorization in text-to-image diffusion models, linking it to cross-attention mechanisms, and proposes a method to detect and mitigate memorization without affecting model speed or image quality.", "motivation": "To address concerns about copyright infringement and privacy risks caused by diffusion models memorizing and replicating training images.", "method": "Examines the relationship between memorization and cross-attention mechanisms, identifies intrinsic findings, and introduces a novel detection and mitigation approach.", "result": "Reveals that memorization involves disproportionate focus on specific token embeddings and proposes an effective solution without compromising model performance.", "conclusion": "The study provides insights into memorization in diffusion models and offers a practical method to mitigate risks while maintaining model efficiency and output quality."}}
{"id": "2505.20137", "pdf": "https://arxiv.org/pdf/2505.20137", "abs": "https://arxiv.org/abs/2505.20137", "authors": ["C\u00e9dric Goemaere", "Gaspard Oliviers", "Rafal Bogacz", "Thomas Demeester"], "title": "Error Optimization: Overcoming Exponential Signal Decay in Deep Predictive Coding Networks", "categories": ["cs.LG", "cs.AI"], "comment": "All code available at\n  https://github.com/cgoemaere/pc_error_optimization", "summary": "Predictive Coding (PC) offers a biologically plausible alternative to\nbackpropagation for neural network training, yet struggles with deeper\narchitectures. This paper identifies the root cause: an inherent signal decay\nproblem where gradients attenuate exponentially with depth, becoming\ncomputationally negligible due to numerical precision constraints. To address\nthis fundamental limitation, we introduce Error Optimization (EO), a novel\nreparameterization that preserves PC's theoretical properties while eliminating\nsignal decay. By optimizing over prediction errors rather than states, EO\nenables signals to reach all layers simultaneously and without attenuation,\nconverging orders of magnitude faster than standard PC. Experiments across\nmultiple architectures and datasets demonstrate that EO matches\nbackpropagation's performance even for deeper models where conventional PC\nstruggles. Besides practical improvements, our work provides theoretical\ninsight into PC dynamics and establishes a foundation for scaling\nbiologically-inspired learning to deeper architectures on digital hardware and\nbeyond.", "AI": {"tldr": "The paper introduces Error Optimization (EO) to solve signal decay in Predictive Coding (PC), enabling deeper neural networks by preserving gradients and matching backpropagation's performance.", "motivation": "Predictive Coding (PC) struggles with deeper architectures due to signal decay, limiting its practical use compared to backpropagation.", "method": "The authors propose Error Optimization (EO), a reparameterization that optimizes prediction errors instead of states, preventing gradient attenuation.", "result": "EO eliminates signal decay, allowing faster convergence and matching backpropagation's performance in deeper models.", "conclusion": "EO advances PC by enabling deeper architectures, offering theoretical insights and practical scalability for biologically-inspired learning."}}
{"id": "2505.17662", "pdf": "https://arxiv.org/pdf/2505.17662", "abs": "https://arxiv.org/abs/2505.17662", "authors": ["Tianheng Ling", "Chao Qian", "Lukas Johannes Ha\u00dfler", "Gregor Schiele"], "title": "Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs", "categories": ["cs.LG"], "comment": "6 pages, 5 figures, 1 table, accepted by IEEE Computer Society Annual\n  Symposium on VLSI (ISVLSI 2025)", "summary": "Transformer-based models have shown strong performance across diverse\ntime-series tasks, but their deployment on resource-constrained devices remains\nchallenging due to high memory and computational demand. While prior work\ntargeting Microcontroller Units (MCUs) has explored hardware-specific\noptimizations, such approaches are often task-specific and limited to 8-bit\nfixed-point precision. Field-Programmable Gate Arrays (FPGAs) offer greater\nflexibility, enabling fine-grained control over data precision and\narchitecture. However, existing FPGA-based deployments of Transformers for\ntime-series analysis typically focus on high-density platforms with manual\nconfiguration. This paper presents a unified and fully automated deployment\nframework for Tiny Transformers on embedded FPGAs. Our framework supports a\ncompact encoder-only Transformer architecture across three representative\ntime-series tasks (forecasting, classification, and anomaly detection). It\ncombines quantization-aware training (down to 4 bits), hardware-aware\nhyperparameter search using Optuna, and automatic VHDL generation for seamless\ndeployment. We evaluate our framework on six public datasets across two\nembedded FPGA platforms. Results show that our framework produces integer-only,\ntask-specific Transformer accelerators achieving as low as 0.033 mJ per\ninference with millisecond latency on AMD Spartan-7, while also providing\ninsights into deployment feasibility on Lattice iCE40. All source code will be\nreleased in the GitHub repository\n(https://github.com/Edwina1030/TinyTransformer4TS).", "AI": {"tldr": "A unified, automated framework for deploying Tiny Transformers on embedded FPGAs, achieving low energy and latency with 4-bit quantization.", "motivation": "Transformer models are resource-heavy for constrained devices; existing FPGA deployments lack automation and flexibility.", "method": "Combines quantization-aware training, hardware-aware hyperparameter search, and automatic VHDL generation for deployment.", "result": "Achieves 0.033 mJ per inference with millisecond latency on AMD Spartan-7, validated on six datasets.", "conclusion": "The framework enables efficient, task-specific Transformer deployment on embedded FPGAs, with code publicly available."}}
{"id": "2404.03446", "pdf": "https://arxiv.org/pdf/2404.03446", "abs": "https://arxiv.org/abs/2404.03446", "authors": ["Chuyu Zhang", "Hui Ren", "Xuming He"], "title": "SP$^2$OT: Semantic-Regularized Progressive Partial Optimal Transport for Imbalanced Clustering", "categories": ["cs.CV", "cs.LG"], "comment": "under review. Follow-up work of arXiv:2401.09266", "summary": "Deep clustering, which learns representation and semantic clustering without\nlabels information, poses a great challenge for deep learning-based approaches.\nDespite significant progress in recent years, most existing methods focus on\nuniformly distributed datasets, significantly limiting the practical\napplicability of their methods. In this paper, we propose a more practical\nproblem setting named deep imbalanced clustering, where the underlying classes\nexhibit an imbalance distribution. To address this challenge, we introduce a\nnovel optimal transport-based pseudo-label learning framework. Our framework\nformulates pseudo-label generation as a Semantic-regularized Progressive\nPartial Optimal Transport (SP$^2$OT) problem, which progressively transports\neach sample to imbalanced clusters under prior and semantic relation\nconstraints, thus generating high-quality and imbalance-aware pseudo-labels. To\nsolve the SP$^2$OT problem, we propose a projected mirror descent algorithm,\nwhich alternates between: (1) computing the gradient of the SP$^2$OT objective,\nand (2) performing gradient descent with projection via an entropy-regularized\nprogressive partial optimal transport formulation. Furthermore, we formulate\nthe second step as an unbalanced optimal transport problem with augmented\nconstraints and develop an efficient solution based on fast matrix scaling\nalgorithms. Experiments on various datasets, including a human-curated\nlong-tailed CIFAR100, challenging ImageNet-R, and large-scale subsets of\nfine-grained iNaturalist2018 datasets, demonstrate the superiority of our\nmethod. Code is available: https://github.com/rhfeiyang/SPPOT", "AI": {"tldr": "The paper introduces a deep imbalanced clustering framework using optimal transport-based pseudo-label learning to handle class imbalance in datasets.", "motivation": "Existing deep clustering methods assume uniform class distributions, limiting practical use. This work addresses the challenge of imbalanced class distributions.", "method": "Proposes SP$^2$OT, a semantic-regularized progressive partial optimal transport framework, solved via a projected mirror descent algorithm and unbalanced optimal transport.", "result": "Demonstrates superiority on datasets like CIFAR100, ImageNet-R, and iNaturalist2018.", "conclusion": "The SP$^2$OT framework effectively generates imbalance-aware pseudo-labels, advancing deep clustering for imbalanced datasets."}}
{"id": "2505.20471", "pdf": "https://arxiv.org/pdf/2505.20471", "abs": "https://arxiv.org/abs/2505.20471", "authors": ["Chenghao Qian", "Wenjing Li", "Yuhu Guo", "Gustav Markkula"], "title": "WeatherEdit: Controllable Weather Editing with 4D Gaussian Field", "categories": ["cs.CV", "cs.AI", "cs.ET", "cs.LG", "cs.RO"], "comment": null, "summary": "In this work, we present WeatherEdit, a novel weather editing pipeline for\ngenerating realistic weather effects with controllable types and severity in 3D\nscenes. Our approach is structured into two key components: weather background\nediting and weather particle construction. For weather background editing, we\nintroduce an all-in-one adapter that integrates multiple weather styles into a\nsingle pretrained diffusion model, enabling the generation of diverse weather\neffects in 2D image backgrounds. During inference, we design a Temporal-View\n(TV-) attention mechanism that follows a specific order to aggregate temporal\nand spatial information, ensuring consistent editing across multi-frame and\nmulti-view images. To construct the weather particles, we first reconstruct a\n3D scene using the edited images and then introduce a dynamic 4D Gaussian field\nto generate snowflakes, raindrops and fog in the scene. The attributes and\ndynamics of these particles are precisely controlled through physical-based\nmodelling and simulation, ensuring realistic weather representation and\nflexible severity adjustments. Finally, we integrate the 4D Gaussian field with\nthe 3D scene to render consistent and highly realistic weather effects.\nExperiments on multiple driving datasets demonstrate that WeatherEdit can\ngenerate diverse weather effects with controllable condition severity,\nhighlighting its potential for autonomous driving simulation in adverse\nweather. See project page: https://jumponthemoon.github.io/w-edit", "AI": {"tldr": "WeatherEdit is a pipeline for realistic weather effects in 3D scenes, combining background editing and particle construction with controllable severity.", "motivation": "To enable realistic and controllable weather effects for applications like autonomous driving simulation.", "method": "Uses an all-in-one adapter for 2D weather backgrounds and a 4D Gaussian field for 3D particle effects, with TV-attention for consistency.", "result": "Generates diverse, realistic weather effects with adjustable severity, validated on driving datasets.", "conclusion": "WeatherEdit is effective for simulating adverse weather, useful for autonomous driving."}}
{"id": "2505.21020", "pdf": "https://arxiv.org/pdf/2505.21020", "abs": "https://arxiv.org/abs/2505.21020", "authors": ["Yuan Gao", "Ruiqi Shu", "Hao Wu", "Fan Xu", "Yanfei Xiang", "Ruijian Gou", "Qingsong Wen", "Xian Wu", "Xiaomeng Huang"], "title": "NeuralOM: Neural Ocean Model for Subseasonal-to-Seasonal Simulation", "categories": ["cs.LG", "physics.ao-ph"], "comment": null, "summary": "Accurate Subseasonal-to-Seasonal (S2S) ocean simulation is critically\nimportant for marine research, yet remains challenging due to its substantial\nthermal inertia and extended time delay. Machine learning (ML)-based models\nhave demonstrated significant advancements in simulation accuracy and\ncomputational efficiency compared to traditional numerical methods.\nNevertheless, a significant limitation of current ML models for S2S ocean\nsimulation is their inadequate incorporation of physical consistency and the\nslow-changing properties of the ocean system. In this work, we propose a neural\nocean model (NeuralOM) for S2S ocean simulation with a multi-scale interactive\ngraph neural network to emulate diverse physical phenomena associated with\nocean systems effectively. Specifically, we propose a multi-stage framework\ntailored to model the ocean's slowly changing nature. Additionally, we\nintroduce a multi-scale interactive messaging module to capture complex\ndynamical behaviors, such as gradient changes and multiplicative coupling\nrelationships inherent in ocean dynamics. Extensive experimental evaluations\nconfirm that our proposed NeuralOM outperforms state-of-the-art models in S2S\nand extreme event simulation. The codes are available at\nhttps://github.com/YuanGao-YG/NeuralOM.", "AI": {"tldr": "Proposes NeuralOM, a neural ocean model for S2S simulation using a multi-scale interactive graph neural network, outperforming existing methods.", "motivation": "Current ML models for S2S ocean simulation lack physical consistency and fail to account for the ocean's slow-changing properties.", "method": "Uses a multi-stage framework and multi-scale interactive messaging module to model ocean dynamics, capturing gradient changes and multiplicative coupling.", "result": "NeuralOM outperforms state-of-the-art models in S2S and extreme event simulation.", "conclusion": "NeuralOM effectively addresses limitations of current ML models for S2S ocean simulation, offering improved accuracy and physical consistency."}}
{"id": "2404.19015", "pdf": "https://arxiv.org/pdf/2404.19015", "abs": "https://arxiv.org/abs/2404.19015", "authors": ["Nagabhushan Somraj", "Sai Harsha Mupparaju", "Adithyan Karanayil", "Rajiv Soundararajan"], "title": "Simple-RF: Regularizing Sparse Input Radiance Fields with Simpler Solutions", "categories": ["cs.CV"], "comment": "The source code for our model can be found on our project page:\n  https://nagabhushansn95.github.io/publications/2024/Simple-RF.html. Extension\n  of arXiv:2309.03955", "summary": "Neural Radiance Fields (NeRF) show impressive performance in photo-realistic\nfree-view rendering of scenes. Recent improvements on the NeRF such as TensoRF\nand ZipNeRF employ explicit models for faster optimization and rendering, as\ncompared to the NeRF that employs an implicit representation. However, both\nimplicit and explicit radiance fields require dense sampling of images in the\ngiven scene. Their performance degrades significantly when only a sparse set of\nviews is available. Researchers find that supervising the depth estimated by a\nradiance field helps train it effectively with fewer views. The depth\nsupervision is obtained either using classical approaches or neural networks\npre-trained on a large dataset. While the former may provide only sparse\nsupervision, the latter may suffer from generalization issues. As opposed to\nthe earlier approaches, we seek to learn the depth supervision by designing\naugmented models and training them along with the main radiance field. Further,\nwe aim to design a framework of regularizations that can work across different\nimplicit and explicit radiance fields. We observe that certain features of\nthese radiance field models overfit to the observed images in the sparse-input\nscenario. Our key finding is that reducing the capability of the radiance\nfields with respect to positional encoding, the number of decomposed tensor\ncomponents or the size of the hash table, constrains the model to learn simpler\nsolutions, which estimate better depth in certain regions. By designing\naugmented models based on such reduced capabilities, we obtain better depth\nsupervision for the main radiance field. We achieve state-of-the-art\nview-synthesis performance with sparse input views on popular datasets\ncontaining forward-facing and 360$^\\circ$ scenes by employing the above\nregularizations.", "AI": {"tldr": "The paper proposes a method to improve Neural Radiance Fields (NeRF) performance with sparse input views by learning depth supervision through augmented models and regularization techniques.", "motivation": "Existing NeRF methods degrade with sparse views. Depth supervision helps but classical or pre-trained neural methods have limitations (sparse or generalization issues). The goal is to learn depth supervision directly and design regularizations for various radiance fields.", "method": "Augmented models are trained alongside the main radiance field. Regularizations reduce model capabilities (e.g., positional encoding, tensor components, hash table size) to avoid overfitting and improve depth estimation.", "result": "State-of-the-art view-synthesis performance with sparse input views on forward-facing and 360\u00b0 scenes.", "conclusion": "Reducing model complexity via regularization and learning depth supervision improves NeRF performance with sparse views, achieving superior results."}}
{"id": "2505.23331", "pdf": "https://arxiv.org/pdf/2505.23331", "abs": "https://arxiv.org/abs/2505.23331", "authors": ["Matteo Gallici", "Haitz S\u00e1ez de Oc\u00e1riz Borde"], "title": "Fine-Tuning Next-Scale Visual Autoregressive Models with Group Relative Policy Optimization", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Fine-tuning pre-trained generative models with Reinforcement Learning (RL)\nhas emerged as an effective approach for aligning outputs more closely with\nnuanced human preferences. In this paper, we investigate the application of\nGroup Relative Policy Optimization (GRPO) to fine-tune next-scale visual\nautoregressive (VAR) models. Our empirical results demonstrate that this\napproach enables alignment to intricate reward signals derived from aesthetic\npredictors and CLIP embeddings, significantly enhancing image quality and\nenabling precise control over the generation style. Interestingly, by\nleveraging CLIP, our method can help VAR models generalize beyond their initial\nImageNet distribution: through RL-driven exploration, these models can generate\nimages aligned with prompts referencing image styles that were absent during\npre-training. In summary, we show that RL-based fine-tuning is both efficient\nand effective for VAR models, benefiting particularly from their fast inference\nspeeds, which are advantageous for online sampling, an aspect that poses\nsignificant challenges for diffusion-based alternatives.", "AI": {"tldr": "RL-based fine-tuning with GRPO improves alignment of VAR models to human preferences, enhancing image quality and style control.", "motivation": "To align pre-trained generative models more closely with nuanced human preferences using RL, particularly for visual autoregressive models.", "method": "Apply Group Relative Policy Optimization (GRPO) to fine-tune VAR models, leveraging aesthetic predictors and CLIP embeddings for reward signals.", "result": "Improved image quality, precise style control, and generalization beyond initial training distribution (e.g., ImageNet).", "conclusion": "RL-based fine-tuning is efficient and effective for VAR models, benefiting from their fast inference speeds compared to diffusion-based alternatives."}}
{"id": "2505.21807", "pdf": "https://arxiv.org/pdf/2505.21807", "abs": "https://arxiv.org/abs/2505.21807", "authors": ["Tommy Xu", "Zhitian Zhang", "Xiangyu Sun", "Lauren Kelly Zung", "Hossein Hajimirsadeghi", "Greg Mori"], "title": "TabReason: A Reinforcement Learning-Enhanced Reasoning LLM for Explainable Tabular Data Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Predictive modeling on tabular data is the cornerstone of many real-world\napplications. Although gradient boosting machines and some recent deep models\nachieve strong performance on tabular data, they often lack interpretability.\nOn the other hand, large language models (LLMs) have demonstrated powerful\ncapabilities to generate human-like reasoning and explanations, but remain\nunder-performed for tabular data prediction. In this paper, we propose a new\napproach that leverages reasoning-based LLMs, trained using reinforcement\nlearning, to perform more accurate and explainable predictions on tabular data.\nOur method introduces custom reward functions that guide the model not only\ntoward better prediction accuracy but also toward human-understandable reasons\nfor its predictions. The proposed method is evaluated on financial benchmark\ndatasets and compared against established LLMs.", "AI": {"tldr": "A new approach combines reasoning-based LLMs with reinforcement learning for accurate and interpretable tabular data predictions.", "motivation": "Existing methods like gradient boosting and deep models lack interpretability, while LLMs underperform in tabular data prediction.", "method": "Uses reinforcement learning-trained LLMs with custom reward functions for accuracy and human-understandable explanations.", "result": "Evaluated on financial datasets, outperforming established LLMs.", "conclusion": "The method improves both prediction accuracy and interpretability for tabular data."}}
{"id": "2406.04875", "pdf": "https://arxiv.org/pdf/2406.04875", "abs": "https://arxiv.org/abs/2406.04875", "authors": ["Xiaobiao Du", "Yida Wang", "Haiyang Sun", "Zhuojie Wu", "Hongwei Sheng", "Shuyun Wang", "Jiaying Ying", "Ming Lu", "Tianqing Zhu", "Kun Zhan", "Xin Yu"], "title": "3DRealCar: An In-the-wild RGB-D Car Dataset with 360-degree Views", "categories": ["cs.CV"], "comment": "Project Page: https://xiaobiaodu.github.io/3drealcar", "summary": "3D cars are commonly used in self-driving systems, virtual/augmented reality,\nand games. However, existing 3D car datasets are either synthetic or\nlow-quality, limiting their applications in practical scenarios and presenting\na significant gap toward high-quality real-world 3D car datasets. In this\npaper, we propose the first large-scale 3D real car dataset, termed 3DRealCar,\noffering three distinctive features. (1) \\textbf{High-Volume}: 2,500 cars are\nmeticulously scanned by smartphones, obtaining car images and point clouds with\nreal-world dimensions; (2) \\textbf{High-Quality}: Each car is captured in an\naverage of 200 dense, high-resolution 360-degree RGB-D views, enabling\nhigh-fidelity 3D reconstruction; (3) \\textbf{High-Diversity}: The dataset\ncontains various cars from over 100 brands, collected under three distinct\nlighting conditions, including reflective, standard, and dark. Additionally, we\noffer detailed car parsing maps for each instance to promote research in car\nparsing tasks. Moreover, we remove background point clouds and standardize the\ncar orientation to a unified axis for the reconstruction only on cars and\ncontrollable rendering without background. We benchmark 3D reconstruction\nresults with state-of-the-art methods across different lighting conditions in\n3DRealCar. Extensive experiments demonstrate that the standard lighting\ncondition part of 3DRealCar can be used to produce a large number of\nhigh-quality 3D cars, improving various 2D and 3D tasks related to cars.\nNotably, our dataset brings insight into the fact that recent 3D reconstruction\nmethods face challenges in reconstructing high-quality 3D cars under reflective\nand dark lighting conditions.\n\\textcolor{red}{\\href{https://xiaobiaodu.github.io/3drealcar/}{Our dataset is\nhere.}}", "AI": {"tldr": "The paper introduces 3DRealCar, the first large-scale high-quality real-world 3D car dataset, addressing limitations of existing synthetic or low-quality datasets. It features high volume, quality, and diversity, and benchmarks state-of-the-art 3D reconstruction methods.", "motivation": "Existing 3D car datasets are synthetic or low-quality, limiting practical applications. The need for a high-quality real-world dataset drives this work.", "method": "The dataset includes 2,500 cars scanned using smartphones, capturing 200 high-resolution 360-degree RGB-D views per car. It offers diverse lighting conditions and standardized car orientation.", "result": "3DRealCar enables high-fidelity 3D reconstruction and improves 2D/3D car-related tasks. Challenges remain in reconstructing cars under reflective and dark lighting.", "conclusion": "3DRealCar fills a gap in high-quality real-world 3D car datasets, benefiting research and applications, though lighting conditions pose reconstruction challenges."}}
{"id": "2505.23860", "pdf": "https://arxiv.org/pdf/2505.23860", "abs": "https://arxiv.org/abs/2505.23860", "authors": ["Giovanni Acampora", "Andris Ambainis", "Natalia Ares", "Leonardo Banchi", "Pallavi Bhardwaj", "Daniele Binosi", "G. Andrew D. Briggs", "Tommaso Calarco", "Vedran Dunjko", "Jens Eisert", "Olivier Ezratty", "Paul Erker", "Federico Fedele", "Elies Gil-Fuster", "Martin G\u00e4rttner", "Mats Granath", "Markus Heyl", "Iordanis Kerenidis", "Matthias Klusch", "Anton Frisk Kockum", "Richard Kueng", "Mario Krenn", "J\u00f6rg L\u00e4ssig", "Antonio Macaluso", "Sabrina Maniscalco", "Florian Marquardt", "Kristel Michielsen", "Gorka Mu\u00f1oz-Gil", "Daniel M\u00fcssig", "Hendrik Poulsen Nautrup", "Sophie A. Neubauer", "Evert van Nieuwenburg", "Roman Orus", "J\u00f6rg Schmiedmayer", "Markus Schmitt", "Philipp Slusallek", "Filippo Vicentini", "Christof Weitenberg", "Frank K. Wilhelm"], "title": "Quantum computing and artificial intelligence: status and perspectives", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "33 pages, 3 figures", "summary": "This white paper discusses and explores the various points of intersection\nbetween quantum computing and artificial intelligence (AI). It describes how\nquantum computing could support the development of innovative AI solutions. It\nalso examines use cases of classical AI that can empower research and\ndevelopment in quantum technologies, with a focus on quantum computing and\nquantum sensing. The purpose of this white paper is to provide a long-term\nresearch agenda aimed at addressing foundational questions about how AI and\nquantum computing interact and benefit one another. It concludes with a set of\nrecommendations and challenges, including how to orchestrate the proposed\ntheoretical work, align quantum AI developments with quantum hardware roadmaps,\nestimate both classical and quantum resources - especially with the goal of\nmitigating and optimizing energy consumption - advance this emerging hybrid\nsoftware engineering discipline, and enhance European industrial\ncompetitiveness while considering societal implications.", "AI": {"tldr": "The paper explores the synergy between quantum computing and AI, detailing mutual benefits and proposing a research agenda for their integration.", "motivation": "To investigate how quantum computing can enhance AI and vice versa, addressing foundational questions and long-term research goals.", "method": "Examines intersections of quantum computing and AI, including use cases in quantum technologies like computing and sensing.", "result": "Identifies potential benefits and challenges, proposing recommendations for research and development.", "conclusion": "Calls for a coordinated research agenda to align quantum AI with hardware roadmaps, optimize resources, and enhance industrial competitiveness."}}
{"id": "2505.22768", "pdf": "https://arxiv.org/pdf/2505.22768", "abs": "https://arxiv.org/abs/2505.22768", "authors": ["Mert Onur Cakiroglu", "Idil Bilge Altun", "Mehmet Dalkilic", "Elham Buxton", "Hasan Kurban"], "title": "Multivariate de Bruijn Graphs: A Symbolic Graph Framework for Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Time series forecasting remains a challenging task for foundation models due\nto temporal heterogeneity, high dimensionality, and the lack of inherent\nsymbolic structure. In this work, we propose DRAGON (Discrete Representation\nand Augmented Graph encoding Over de BruijN Graphs), a novel encoder that\nintroduces Multivariate de Bruijn Graphs (MdBGs) to bridge the gap between\nsymbolic representations and neural modeling. DRAGON discretizes continuous\ninput sequences and maps them onto a fixed graph structure, enabling dynamic\ncontext recovery via graph-based attention. Integrated as an auxiliary module\nwithin a dual-branch architecture, DRAGON augments conventional CNN-based\nencoders with symbolic, structure-aware representations. All code developed for\nthis study is available at:\nhttps://github.com/KurbanIntelligenceLab/MultdBG-Time-Series-Library", "AI": {"tldr": "DRAGON introduces Multivariate de Bruijn Graphs (MdBGs) to enhance time series forecasting by combining symbolic representations with neural modeling.", "motivation": "Addressing challenges like temporal heterogeneity and high dimensionality in time series forecasting.", "method": "Discretizes sequences, maps them to MdBGs, and uses graph-based attention in a dual-branch architecture with CNNs.", "result": "Enables dynamic context recovery and structure-aware representations.", "conclusion": "DRAGON effectively bridges symbolic and neural approaches for improved forecasting."}}
{"id": "2406.15303", "pdf": "https://arxiv.org/pdf/2406.15303", "abs": "https://arxiv.org/abs/2406.15303", "authors": ["Yunlong Zhang", "Honglin Li", "Yunxuan Sun", "Zhongyi Shui", "Jingxiong Li", "Chenglu Zhu", "Lin Yang"], "title": "AEM: Attention Entropy Maximization for Multiple Instance Learning based Whole Slide Image Classification", "categories": ["cs.CV"], "comment": "Accepted by MICCAI2025", "summary": "Multiple Instance Learning (MIL) effectively analyzes whole slide images but\nfaces overfitting due to attention over-concentration. While existing solutions\nrely on complex architectural modifications or additional processing steps, we\nintroduce Attention Entropy Maximization (AEM), a simple yet effective\nregularization technique. Our investigation reveals the positive correlation\nbetween attention entropy and model performance. Building on this insight, we\nintegrate AEM regularization into the MIL framework to penalize excessive\nattention concentration. To address sensitivity to the AEM weight parameter, we\nimplement Cosine Weight Annealing, reducing parameter dependency. Extensive\nevaluations demonstrate AEM's superior performance across diverse feature\nextractors, MIL frameworks, attention mechanisms, and augmentation techniques.\nHere is our anonymous code: https://github.com/dazhangyu123/AEM.", "AI": {"tldr": "AEM regularization improves MIL by maximizing attention entropy, reducing overfitting without complex changes.", "motivation": "Overfitting in MIL due to attention over-concentration; existing solutions are complex.", "method": "Introduces Attention Entropy Maximization (AEM) and Cosine Weight Annealing to reduce parameter sensitivity.", "result": "AEM outperforms across various feature extractors, MIL frameworks, and attention mechanisms.", "conclusion": "AEM is a simple, effective regularization technique for MIL, validated by extensive evaluations."}}
{"id": "2506.00924", "pdf": "https://arxiv.org/pdf/2506.00924", "abs": "https://arxiv.org/abs/2506.00924", "authors": ["Parsa Hassani Shariat Panahi", "Amir Hossein Jalilvand", "M. Hassan Najafi"], "title": "Bridging Subjective and Objective QoE: Operator-Level Aggregation Using LLM-Based Comment Analysis and Network MOS Comparison", "categories": ["cs.NI", "cs.AI", "cs.HC"], "comment": "19 ppages, 13 figures", "summary": "This paper introduces a dual-layer framework for network operator-side\nquality of experience (QoE) assessment that integrates both objective network\nmodeling and subjective user perception extracted from live-streaming\nplatforms. On the objective side, we develop a machine learning model trained\non mean opinion scores (MOS) computed via the ITU-T P.1203 reference\nimplementation, allowing accurate prediction of user-perceived video quality\nusing only network parameters such as packet loss, delay, jitter, and\nthroughput without reliance on video content or client-side instrumentation. On\nthe subjective side, we present a semantic filtering and scoring pipeline that\nprocesses user comments from live streams to extract performance-related\nfeedback. A large language model is used to assign scalar MOS scores to\nfiltered comments in a deterministic and reproducible manner. To support\nscalable and interpretable analysis, we construct a labeled dataset of 47,894\nlive-stream comments, of which about 34,000 are identified as QoE-relevant\nthrough multi-layer semantic filtering. Each comment is enriched with simulated\nInternet Service Provider attribution and temporally aligned using synthetic\ntimestamps in 5-min intervals. The resulting dataset enables operator-level\naggregation and time-series analysis of user-perceived quality. A delta MOS\nmetric is proposed to measure each Internet service provider's deviation from\nplatform-wide sentiment, allowing detection of localized degradations even in\nthe absence of direct network telemetry. A controlled outage simulation\nconfirms the framework's effectiveness in identifying service disruptions\nthrough comment-based trends alone. The system provides each operator with its\nown subjective MOS and the global platform average per interval, enabling\nreal-time interpretation of performance deviations and comparison with\nobjective network-based QoE estimates.", "AI": {"tldr": "A dual-layer framework for QoE assessment combines objective network modeling and subjective user feedback from live streams, using ML and semantic analysis for scalable, interpretable insights.", "motivation": "To improve QoE assessment by integrating objective network metrics and subjective user feedback, enabling real-time, scalable analysis without client-side tools.", "method": "Objective side: ML model predicts video quality using network parameters. Subjective side: Semantic filtering and LLM scoring of live-stream comments. Dataset of 47,894 comments supports analysis.", "result": "Effective detection of localized degradations via delta MOS metric. Controlled outage simulation validates framework.", "conclusion": "The framework enables real-time QoE monitoring and comparison of subjective and objective metrics, enhancing operator-side insights."}}
{"id": "2506.04487", "pdf": "https://arxiv.org/pdf/2506.04487", "abs": "https://arxiv.org/abs/2506.04487", "authors": ["C. Evans Hedges"], "title": "Orthogonal Gradient Descent Improves Neural Calibration", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We provide evidence that orthogonalizing gradients during training improves\nmodel calibration without sacrificing accuracy. On CIFAR-10 with 10\\% labeled\ndata, $\\perp$Grad matches SGD in accuracy but yields consistently improved\ncalibration metrics such as lower test loss, reduced softmax overconfidence,\nand higher predictive entropy. These benefits persist under input corruption\n(CIFAR-10C) and extended training, where $\\perp$Grad models degrade more\ngracefully than SGD-trained counterparts. $\\perp$Grad is optimizer-agnostic,\nincurs minimal overhead, and works well with post-hoc calibration techniques\nlike temperature scaling.\n  Theoretically, we prove convergence of a simplified version of $\\perp$Grad\nunder mild assumptions and characterize its stationary points in positive\nhomogeneous networks: $\\perp$Grad converges to solutions where further loss\nreduction requires confidence scaling rather than decision boundary\nimprovement. Code for this paper can be found at:\nhttps://github.com/evanshedges2/orthograd\\_improves\\_calibration.", "AI": {"tldr": "Orthogonalizing gradients ($\\perp$Grad) improves model calibration without losing accuracy, outperforming SGD in metrics like test loss and predictive entropy, even under input corruption.", "motivation": "To enhance model calibration while maintaining accuracy, addressing issues like overconfidence and degraded performance under corruption.", "method": "Introduces $\\perp$Grad, an optimizer-agnostic technique that orthogonalizes gradients during training, with minimal computational overhead.", "result": "$\\perp$Grad matches SGD in accuracy but improves calibration metrics (lower test loss, reduced overconfidence, higher entropy) and degrades more gracefully under corruption.", "conclusion": "$\\perp$Grad is effective for improving calibration, works with post-hoc techniques, and theoretically converges to solutions favoring confidence scaling over boundary improvement."}}
{"id": "2407.06109", "pdf": "https://arxiv.org/pdf/2407.06109", "abs": "https://arxiv.org/abs/2407.06109", "authors": ["Jinhua Zhang", "Hualian Sheng", "Sijia Cai", "Bing Deng", "Qiao Liang", "Wen Li", "Ying Fu", "Jieping Ye", "Shuhang Gu"], "title": "PerLDiff: Controllable Street View Synthesis Using Perspective-Layout Diffusion Models", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "Controllable generation is considered a potentially vital approach to address\nthe challenge of annotating 3D data, and the precision of such controllable\ngeneration becomes particularly imperative in the context of data production\nfor autonomous driving. Existing methods focus on the integration of diverse\ngenerative information into controlling inputs, utilizing frameworks such as\nGLIGEN or ControlNet, to produce commendable outcomes in controllable\ngeneration. However, such approaches intrinsically restrict generation\nperformance to the learning capacities of predefined network architectures. In\nthis paper, we explore the innovative integration of controlling information\nand introduce PerLDiff (\\textbf{Per}spective-\\textbf{L}ayout \\textbf{Diff}usion\nModels), a novel method for effective street view image generation that fully\nleverages perspective 3D geometric information. Our PerLDiff employs 3D\ngeometric priors to guide the generation of street view images with precise\nobject-level control within the network learning process, resulting in a more\nrobust and controllable output. Moreover, it demonstrates superior\ncontrollability compared to alternative layout control methods. Empirical\nresults justify that our PerLDiff markedly enhances the precision of\ncontrollable generation on the NuScenes and KITTI datasets.", "AI": {"tldr": "PerLDiff introduces a novel method for controllable street view image generation using 3D geometric priors, outperforming existing methods in precision.", "motivation": "Addressing the challenge of annotating 3D data for autonomous driving by improving controllable generation precision.", "method": "Integrates perspective 3D geometric information into diffusion models (PerLDiff) for precise object-level control.", "result": "Superior controllability and precision on NuScenes and KITTI datasets compared to existing methods.", "conclusion": "PerLDiff offers a robust solution for precise and controllable street view image generation."}}
{"id": "2506.02606", "pdf": "https://arxiv.org/pdf/2506.02606", "abs": "https://arxiv.org/abs/2506.02606", "authors": ["Baoyang Chen", "Xian Xu", "Huamin Qu"], "title": "Multi Layered Autonomy and AI Ecologies in Robotic Art Installations", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "This paper presents Symbiosis of Agents, is a large-scale installation by\nBaoyang Chen (baoyangchen.com), that embeds AI-driven robots in an immersive,\nmirror-lined arena, probing the tension between machine agency and artistic\nauthorship. Drawing on early cybernetics, rule-based conceptual art, and\nseminal robotic works, it orchestrates fluid exchanges among robotic arms,\nquadruped machines, their environment, and the public. A three tier faith\nsystem pilots the ecology: micro-level adaptive tactics, meso-level narrative\ndrives, and a macro-level prime directive. This hierarchy lets behaviors evolve\norganically in response to environmental cues and even a viewer's breath,\nturning spectators into co-authors of the unfolding drama. Framed by a\nspeculative terraforming scenario that recalls the historical exploitation of\nmarginalized labor, the piece asks who bears responsibility in AI-mediated\nfutures. Choreographed motion, AI-generated scripts, reactive lighting, and\ndrifting fog cast the robots as collaborators rather than tools, forging a\nliving, emergent artwork. Exhibited internationally, Symbiosis of Agents shows\nhow cybernetic feedback, robotic experimentation, and conceptual rule-making\ncan converge to redefine agency, authorship, and ethics in contemporary art.", "AI": {"tldr": "Symbiosis of Agents is an AI-driven robotic installation exploring machine agency and artistic authorship through adaptive behaviors, environmental interaction, and viewer participation.", "motivation": "The work probes tensions between machine agency and human authorship in AI-mediated futures, framed by historical labor exploitation.", "method": "Uses a three-tier faith system (adaptive tactics, narrative drives, prime directive) to orchestrate interactions among robots, environment, and viewers.", "result": "Creates a living, emergent artwork where spectators become co-authors, redefining agency and ethics in art.", "conclusion": "Demonstrates how cybernetics, robotics, and conceptual rules can converge to reshape contemporary art's ethical and creative boundaries."}}
{"id": "2506.05626", "pdf": "https://arxiv.org/pdf/2506.05626", "abs": "https://arxiv.org/abs/2506.05626", "authors": ["Xiaohua Lu", "Liubov Tupikina", "Mehwish Alam"], "title": "Two-dimensional Taxonomy for N-ary Knowledge Representation Learning Methods", "categories": ["cs.LG"], "comment": null, "summary": "Real-world knowledge can take various forms, including structured,\nsemi-structured, and unstructured data. Among these, knowledge graphs are a\nform of structured human knowledge that integrate heterogeneous data sources\ninto structured representations but typically reduce complex n-ary relations to\nsimple triples, thereby losing higher-order relational details. In contrast,\nhypergraphs naturally represent n-ary relations with hyperedges, which directly\nconnect multiple entities together. Yet hypergraph representation learning\noften overlooks entity roles in hyperedges, limiting the finegrained semantic\nmodelling. To address these issues, knowledge hypergraphs and hyper-relational\nknowledge graphs combine the advantages of knowledge graphs and hypergraphs to\nbetter capture the complex structures and role-specific semantics of real world\nknowledge. This survey provides a comprehensive review of methods handling\nn-ary relational data, covering both knowledge hypergraphs and hyper-relational\nknowledge graphs literatures. We propose a two-dimensional taxonomy: the first\ndimension categorises models based on their methodology, i.e.,\ntranslation-based models, tensor factorisation-based models, deep neural\nnetwork-based models, logic rules-based models, and hyperedge expansion-based\nmodels. The second dimension classifies models according to their awareness of\nentity roles and positions in n-ary relations, dividing them into aware-less,\nposition-aware, and role-aware approaches. Finally, we discuss existing\ndatasets, training settings and strategies, and outline open challenges to\ninspire future research.", "AI": {"tldr": "The paper surveys methods for handling n-ary relational data, comparing knowledge graphs and hypergraphs, and introduces a taxonomy for modeling approaches.", "motivation": "To address the limitations of knowledge graphs (losing higher-order relational details) and hypergraphs (overlooking entity roles), the paper explores hybrid approaches like knowledge hypergraphs and hyper-relational knowledge graphs.", "method": "Proposes a two-dimensional taxonomy: methodology-based (e.g., translation-based, tensor factorization) and role/position awareness (e.g., aware-less, role-aware).", "result": "Comprehensive review of n-ary relational data methods, datasets, and training strategies, highlighting gaps.", "conclusion": "Identifies open challenges and encourages future research in modeling complex knowledge structures."}}
{"id": "2408.02191", "pdf": "https://arxiv.org/pdf/2408.02191", "abs": "https://arxiv.org/abs/2408.02191", "authors": ["Ye Yao", "Tingfeng Han", "Shan Jia", "Siwei Lyu"], "title": "Dense Feature Interaction Network for Image Inpainting Localization", "categories": ["cs.CV"], "comment": null, "summary": "Image inpainting, the process of filling in missing areas in an image, is a\ncommon image editing technique. Inpainting can be used to conceal or alter\nimage contents in malicious manipulation of images, driving the need for\nresearch in image inpainting detection. Most existing methods use a basic\nencoder-decoder structure, which often results in a high number of false\npositives or misses the inpainted regions, especially when dealing with targets\nof varying semantics and scales. Additionally, the lack of an effective\napproach to capture boundary artifacts leads to less accurate edge\nlocalization. In this paper, we describe a new method for inpainting detection\nbased on a Dense Feature Interaction Network (DeFI-Net). DeFI-Net uses a novel\nfeature pyramid architecture to capture and amplify multi-scale representations\nacross various stages, thereby improving the detection of image inpainting by\nbetter strengthening feature-level interactions. Additionally, the network can\nadaptively direct the lower-level features, which carry edge and shape\ninformation, to refine the localization of manipulated regions while\nintegrating the higher-level semantic features. Using DeFI-Net, we develop a\nmethod combining complementary representations to accurately identify inpainted\nareas. Evaluation on seven image inpainting datasets demonstrates the\neffectiveness of our approach, which achieves state-of-the-art performance in\ndetecting inpainting across diverse models. Code and models are available at\nhttps://github.com/Boombb/DeFI-Net_Inpainting.", "AI": {"tldr": "A new method, DeFI-Net, improves image inpainting detection by using a feature pyramid architecture to capture multi-scale representations and refine edge localization.", "motivation": "Existing methods for inpainting detection often fail due to high false positives and poor edge localization, especially with varying semantics and scales.", "method": "DeFI-Net employs a Dense Feature Interaction Network with a feature pyramid architecture to enhance multi-scale feature interactions and adaptive feature direction for better edge and semantic integration.", "result": "DeFI-Net achieves state-of-the-art performance on seven inpainting datasets, accurately identifying inpainted areas.", "conclusion": "DeFI-Net provides an effective solution for detecting image inpainting, outperforming existing methods by improving feature interactions and edge localization."}}
{"id": "2506.07239", "pdf": "https://arxiv.org/pdf/2506.07239", "abs": "https://arxiv.org/abs/2506.07239", "authors": ["Raghu Vamshi Hemadri", "Jitendra Bhandari", "Andre Nakkab", "Johann Knechtel", "Badri P Gopalan", "Ramesh Narayanaswamy", "Ramesh Karri", "Siddharth Garg"], "title": "VeriLoC: Line-of-Code Level Prediction of Hardware Design Quality from Verilog Code", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "Modern chip design is complex, and there is a crucial need for early-stage\nprediction of key design-quality metrics like timing and routing congestion\ndirectly from Verilog code (a commonly used programming language for hardware\ndesign). It is especially important yet complex to predict individual lines of\ncode that cause timing violations or downstream routing congestion. Prior works\nhave tried approaches like converting Verilog into an intermediate graph\nrepresentation and using LLM embeddings alongside other features to predict\nmodule-level quality, but did not consider line-level quality prediction. We\npropose VeriLoC, the first method that predicts design quality directly from\nVerilog at both the line- and module-level. To this end, VeriLoC leverages\nrecent Verilog code-generation LLMs to extract local line-level and\nmodule-level embeddings, and train downstream classifiers/regressors on\nconcatenations of these embeddings. VeriLoC achieves high F1-scores of\n0.86-0.95 for line-level congestion and timing prediction, and reduces the mean\naverage percentage error from 14% - 18% for SOTA methods down to only 4%. We\nbelieve that VeriLoC embeddings and insights from our work will also be of\nvalue for other predictive and optimization tasks for complex hardware design.", "AI": {"tldr": "VeriLoC predicts design quality from Verilog code at line- and module-level using LLM embeddings, achieving high accuracy and outperforming prior methods.", "motivation": "Early-stage prediction of design-quality metrics (timing, congestion) from Verilog code is crucial but complex, especially at the line-level. Prior works lacked line-level prediction.", "method": "VeriLoC uses Verilog code-generation LLMs to extract line- and module-level embeddings, training classifiers/regressors on these embeddings.", "result": "Achieves F1-scores of 0.86-0.95 for line-level prediction and reduces error from 14-18% to 4%.", "conclusion": "VeriLoC is effective for design-quality prediction and its embeddings may benefit other hardware design tasks."}}
{"id": "2506.06633", "pdf": "https://arxiv.org/pdf/2506.06633", "abs": "https://arxiv.org/abs/2506.06633", "authors": ["Chi-Sheng Chen"], "title": "Vision-QRWKV: Exploring Quantum-Enhanced RWKV Models for Image Classification", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Recent advancements in quantum machine learning have shown promise in\nenhancing classical neural network architectures, particularly in domains\ninvolving complex, high-dimensional data. Building upon prior work in temporal\nsequence modeling, this paper introduces Vision-QRWKV, a hybrid\nquantum-classical extension of the Receptance Weighted Key Value (RWKV)\narchitecture, applied for the first time to image classification tasks. By\nintegrating a variational quantum circuit (VQC) into the channel mixing\ncomponent of RWKV, our model aims to improve nonlinear feature transformation\nand enhance the expressive capacity of visual representations.\n  We evaluate both classical and quantum RWKV models on a diverse collection of\n14 medical and standard image classification benchmarks, including MedMNIST\ndatasets, MNIST, and FashionMNIST. Our results demonstrate that the\nquantum-enhanced model outperforms its classical counterpart on a majority of\ndatasets, particularly those with subtle or noisy class distinctions (e.g.,\nChestMNIST, RetinaMNIST, BloodMNIST). This study represents the first\nsystematic application of quantum-enhanced RWKV in the visual domain, offering\ninsights into the architectural trade-offs and future potential of quantum\nmodels for lightweight and efficient vision tasks.", "AI": {"tldr": "Vision-QRWKV, a quantum-classical hybrid model, enhances RWKV for image classification, outperforming classical models on noisy datasets.", "motivation": "To leverage quantum computing for improving nonlinear feature transformations in visual tasks, addressing challenges in noisy or subtle class distinctions.", "method": "Integrates a variational quantum circuit (VQC) into RWKV's channel mixing component, applied to 14 image classification benchmarks.", "result": "Quantum-enhanced RWKV outperforms classical RWKV, especially on datasets like ChestMNIST, RetinaMNIST, and BloodMNIST.", "conclusion": "Quantum-enhanced RWKV shows promise for lightweight vision tasks, highlighting architectural trade-offs and future potential."}}
{"id": "2408.06832", "pdf": "https://arxiv.org/pdf/2408.06832", "abs": "https://arxiv.org/abs/2408.06832", "authors": ["Yutao Zhu", "Xiaosong Jia", "Xinyu Yang", "Junchi Yan"], "title": "FlatFusion: Delving into Details of Sparse Transformer-based Camera-LiDAR Fusion for Autonomous Driving", "categories": ["cs.CV"], "comment": "Accepted by ICRA 2025", "summary": "The integration of data from diverse sensor modalities (e.g., camera and\nLiDAR) constitutes a prevalent methodology within the ambit of autonomous\ndriving scenarios. Recent advancements in efficient point cloud transformers\nhave underscored the efficacy of integrating information in sparse formats.\nWhen it comes to fusion, since image patches are dense in pixel space with\nambiguous depth, it necessitates additional design considerations for effective\nfusion. In this paper, we conduct a comprehensive exploration of design choices\nfor Transformer-based sparse cameraLiDAR fusion. This investigation encompasses\nstrategies for image-to-3D and LiDAR-to-2D mapping, attention neighbor\ngrouping, single modal tokenizer, and micro-structure of Transformer. By\namalgamating the most effective principles uncovered through our investigation,\nwe introduce FlatFusion, a carefully designed framework for sparse camera-LiDAR\nfusion. Notably, FlatFusion significantly outperforms state-of-the-art sparse\nTransformer-based methods, including UniTR, CMT, and SparseFusion, achieving\n73.7 NDS on the nuScenes validation set with 10.1 FPS with PyTorch.", "AI": {"tldr": "FlatFusion is a Transformer-based framework for sparse camera-LiDAR fusion, outperforming state-of-the-art methods with 73.7 NDS on nuScenes.", "motivation": "Effective fusion of dense image patches and sparse LiDAR data in autonomous driving requires careful design due to depth ambiguity.", "method": "Explores design choices like image-to-3D mapping, attention neighbor grouping, and Transformer micro-structure, leading to FlatFusion.", "result": "Achieves 73.7 NDS on nuScenes with 10.1 FPS, surpassing UniTR, CMT, and SparseFusion.", "conclusion": "FlatFusion demonstrates superior performance in sparse sensor fusion, setting a new benchmark."}}
{"id": "2506.09034", "pdf": "https://arxiv.org/pdf/2506.09034", "abs": "https://arxiv.org/abs/2506.09034", "authors": ["Sizhe Dang", "Yangyang Guo", "Yanjun Zhao", "Haishan Ye", "Xiaodong Zheng", "Guang Dai", "Ivor Tsang"], "title": "FZOO: Fast Zeroth-Order Optimizer for Fine-Tuning Large Language Models towards Adam-Scale Speed", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fine-tuning large language models (LLMs) often faces GPU memory bottlenecks:\nthe backward pass of first-order optimizers like Adam increases memory usage to\nmore than 10 times the inference level (e.g., 633 GB for OPT-30B). Zeroth-order\n(ZO) optimizers avoid this cost by estimating gradients only from forward\npasses, yet existing methods like MeZO usually require many more steps to\nconverge. Can this trade-off between speed and memory in ZO be fundamentally\nimproved? Normalized-SGD demonstrates strong empirical performance with greater\nmemory efficiency than Adam. In light of this, we introduce FZOO, a Fast\nZeroth-Order Optimizer toward Adam-Scale Speed. FZOO reduces the total forward\npasses needed for convergence by employing batched one-sided estimates that\nadapt step sizes based on the standard deviation of batch losses. It also\naccelerates per-batch computation through the use of Rademacher random vector\nperturbations coupled with CUDA's parallel processing. Extensive experiments on\ndiverse models, including RoBERTa-large, OPT (350M-66B), Phi-2, and Llama3,\nacross 11 tasks validate FZOO's effectiveness. On average, FZOO outperforms\nMeZO by 3 percent in accuracy while requiring 3 times fewer forward passes. For\nRoBERTa-large, FZOO achieves average improvements of 5.6 percent in accuracy\nand an 18 times reduction in forward passes compared to MeZO, achieving\nconvergence speeds comparable to Adam. We also provide theoretical analysis\nproving FZOO's formal equivalence to a normalized-SGD update rule and its\nconvergence guarantees. FZOO integrates smoothly into PEFT techniques, enabling\neven larger memory savings. Overall, our results make single-GPU, high-speed,\nfull-parameter fine-tuning practical and point toward future work on\nmemory-efficient pre-training.", "AI": {"tldr": "FZOO, a fast zeroth-order optimizer, improves memory efficiency and convergence speed for fine-tuning large language models, outperforming MeZO in accuracy and reducing forward passes.", "motivation": "Address GPU memory bottlenecks in fine-tuning LLMs by improving the trade-off between speed and memory in zeroth-order optimizers.", "method": "FZOO uses batched one-sided gradient estimates, adaptive step sizes, and Rademacher random vector perturbations with CUDA parallel processing.", "result": "FZOO outperforms MeZO by 3% in accuracy, reduces forward passes by 3x, and achieves Adam-scale convergence speeds.", "conclusion": "FZOO enables practical single-GPU, high-speed full-parameter fine-tuning and suggests future work on memory-efficient pre-training."}}
{"id": "2506.07085", "pdf": "https://arxiv.org/pdf/2506.07085", "abs": "https://arxiv.org/abs/2506.07085", "authors": ["Yonatan Ashlag", "Uri Koren", "Mirco Mutti", "Esther Derman", "Pierre-Luc Bacon", "Shie Mannor"], "title": "State Entropy Regularization for Robust Reinforcement Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "State entropy regularization has empirically shown better exploration and\nsample complexity in reinforcement learning (RL). However, its theoretical\nguarantees have not been studied. In this paper, we show that state entropy\nregularization improves robustness to structured and spatially correlated\nperturbations. These types of variation are common in transfer learning but\noften overlooked by standard robust RL methods, which typically focus on small,\nuncorrelated changes. We provide a comprehensive characterization of these\nrobustness properties, including formal guarantees under reward and transition\nuncertainty, as well as settings where the method performs poorly. Much of our\nanalysis contrasts state entropy with the widely used policy entropy\nregularization, highlighting their different benefits. Finally, from a\npractical standpoint, we illustrate that compared with policy entropy, the\nrobustness advantages of state entropy are more sensitive to the number of\nrollouts used for policy evaluation.", "AI": {"tldr": "State entropy regularization in RL improves robustness to structured and spatially correlated perturbations, unlike standard robust RL methods. Theoretical guarantees and practical insights are provided, contrasting it with policy entropy regularization.", "motivation": "To address the lack of theoretical understanding of state entropy regularization's benefits in RL, particularly its robustness to structured and spatially correlated perturbations, which are common in transfer learning.", "method": "Analyzes state entropy regularization's robustness properties, providing formal guarantees under reward and transition uncertainty, and contrasts it with policy entropy regularization.", "result": "State entropy regularization offers better robustness to certain perturbations but is more sensitive to the number of rollouts for policy evaluation compared to policy entropy.", "conclusion": "State entropy regularization is theoretically and practically advantageous for specific robustness scenarios, though its effectiveness depends on rollout count."}}
{"id": "2408.10789", "pdf": "https://arxiv.org/pdf/2408.10789", "abs": "https://arxiv.org/abs/2408.10789", "authors": ["Zhirui Gao", "Renjiao Yi", "Yuhang Huang", "Wei Chen", "Chenyang Zhu", "Kai Xu"], "title": "Self-supervised Learning of Hybrid Part-aware 3D Representation of 2D Gaussians and Superquadrics", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025 Code: https://github.com/zhirui-gao/PartGS", "summary": "Low-level 3D representations, such as point clouds, meshes, NeRFs and 3D\nGaussians, are commonly used for modeling 3D objects and scenes. However,\ncognitive studies indicate that human perception operates at higher levels and\ninterprets 3D environments by decomposing them into meaningful structural\nparts, rather than low-level elements like points or voxels. Structured\ngeometric decomposition enhances scene interpretability and facilitates\ndownstream tasks requiring component-level manipulation. In this work, we\nintroduce PartGS, a self-supervised part-aware reconstruction framework that\nintegrates 2D Gaussians and superquadrics to parse objects and scenes into an\ninterpretable decomposition, leveraging multi-view image inputs to uncover 3D\nstructural information. Our method jointly optimizes superquadric meshes and\nGaussians by coupling their parameters within a hybrid representation. On one\nhand, superquadrics enable the representation of a wide range of shape\nprimitives, facilitating flexible and meaningful decompositions. On the other\nhand, 2D Gaussians capture detailed texture and geometric details, ensuring\nhigh-fidelity appearance and geometry reconstruction. Operating in a\nself-supervised manner, our approach demonstrates superior performance compared\nto state-of-the-art methods across extensive experiments on the DTU, ShapeNet,\nand real-world datasets.", "AI": {"tldr": "PartGS is a self-supervised framework for part-aware 3D reconstruction using 2D Gaussians and superquadrics, outperforming state-of-the-art methods.", "motivation": "Human perception interprets 3D environments at higher structural levels, not low-level elements. Structured decomposition improves interpretability and manipulation.", "method": "Combines 2D Gaussians and superquadrics in a hybrid representation, jointly optimizing their parameters for part-aware reconstruction from multi-view images.", "result": "Superior performance on DTU, ShapeNet, and real-world datasets compared to existing methods.", "conclusion": "PartGS effectively bridges the gap between low-level 3D representations and human-like structural understanding, enabling interpretable and high-fidelity reconstructions."}}
{"id": "2506.09397", "pdf": "https://arxiv.org/pdf/2506.09397", "abs": "https://arxiv.org/abs/2506.09397", "authors": ["Xiangchen Li", "Dimitrios Spatharakis", "Saeid Ghafouri", "Jiakun Fan", "Hans Vandierendonck", "Deepu John", "Bo Ji", "Dimitrios Nikolopoulos"], "title": "SLED: A Speculative LLM Decoding Framework for Efficient Edge Serving", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.NI", "68T07, 68M14", "I.2.6; C.2.4; C.1.4"], "comment": "6 pages, 6 figures, 2 tables", "summary": "The growing gap between the increasing complexity of large language models\n(LLMs) and the limited computational budgets of edge devices poses a key\nchallenge for efficient on-device inference, despite gradual improvements in\nhardware capabilities. Existing strategies, such as aggressive quantization,\npruning, or remote inference, trade accuracy for efficiency or lead to\nsubstantial cost burdens. This position paper introduces a new framework that\nleverages speculative decoding, previously viewed primarily as a decoding\nacceleration technique for autoregressive generation of LLMs, as a promising\napproach specifically adapted for edge computing by orchestrating computation\nacross heterogeneous devices. We propose \\acronym, a framework that allows\nlightweight edge devices to draft multiple candidate tokens locally using\ndiverse draft models, while a single, shared edge server verifies the tokens\nutilizing a more precise target model. To further increase the efficiency of\nverification, the edge server batch the diverse verification requests from\ndevices. This approach supports device heterogeneity and reduces server-side\nmemory footprint by sharing the same upstream target model across multiple\ndevices. Our initial experiments with Jetson Orin Nano, Raspberry Pi 4B/5, and\nan edge server equipped with 4 Nvidia A100 GPUs indicate substantial benefits:\n2.2 more system throughput, 2.8 more system capacity, and better cost\nefficiency, all without sacrificing model accuracy.", "AI": {"tldr": "The paper proposes a framework (\\acronym) using speculative decoding for efficient on-device LLM inference, balancing accuracy and efficiency by leveraging heterogeneous edge devices and batch verification.", "motivation": "The challenge lies in the gap between complex LLMs and limited edge device capabilities, where existing methods compromise accuracy or cost.", "method": "The framework uses lightweight edge devices to draft tokens locally and a shared edge server for verification, batching requests to improve efficiency.", "result": "Experiments show 2.2x higher throughput, 2.8x capacity, and better cost efficiency without accuracy loss.", "conclusion": "The approach effectively addresses edge computing challenges for LLMs, offering scalable and efficient inference."}}
{"id": "2506.07585", "pdf": "https://arxiv.org/pdf/2506.07585", "abs": "https://arxiv.org/abs/2506.07585", "authors": ["Seokbin Yoon", "Keumjin Lee"], "title": "Aircraft Trajectory Dataset Augmentation in Latent Space", "categories": ["cs.LG"], "comment": null, "summary": "Aircraft trajectory modeling plays a crucial role in Air Traffic Management\n(ATM) and is important for various downstream tasks, including conflict\ndetection and landing time prediction. Dataset augmentation through the\naddition of synthetically generated trajectory data is necessary to develop a\nmore robust aircraft trajectory model and ensure that the trajectory dataset is\nsufficient and balanced. In this work, we propose a novel framework called\nATRADA for aircraft trajectory dataset augmentation. In the proposed framework,\na Transformer encoder learns the underlying patterns in the original trajectory\ndataset and converts each data point into a context vector in the learned\nlatent space. The converted dataset in the latent space is projected into\nreduced dimensions using principal component analysis (PCA), and a Gaussian\nmixture model (GMM) is applied to fit the probability distribution of the data\npoints in the reduced-dimensional space. Finally, new samples are drawn from\nthe fitted GMM, the dimension of the samples is reverted to the original\ndimension, and they are decoded with a Multi-Layer Perceptron (MLP). Several\nexperiments demonstrate that the framework effectively generates new,\nhigh-quality synthetic aircraft trajectory data, which were compared to the\nresults of several baselines.", "AI": {"tldr": "ATRADA is a novel framework for augmenting aircraft trajectory datasets using Transformer encoders, PCA, GMM, and MLP to generate high-quality synthetic data.", "motivation": "Enhancing aircraft trajectory models for robust Air Traffic Management (ATM) tasks like conflict detection and landing time prediction requires sufficient and balanced datasets, which ATRADA addresses through synthetic data generation.", "method": "ATRADA uses a Transformer encoder to learn trajectory patterns, projects data into latent space via PCA, fits a GMM for probability distribution, and generates synthetic samples with an MLP.", "result": "The framework successfully produces high-quality synthetic trajectory data, outperforming baseline methods in experiments.", "conclusion": "ATRADA provides an effective solution for dataset augmentation in aircraft trajectory modeling, improving robustness for downstream ATM tasks."}}
{"id": "2408.13697", "pdf": "https://arxiv.org/pdf/2408.13697", "abs": "https://arxiv.org/abs/2408.13697", "authors": ["Yingjian Chen", "Lei Zhang", "Yakun Niu"], "title": "ForgeLens: Data-Efficient Forgery Focus for Generalizable Forgery Image Detection", "categories": ["cs.CV"], "comment": null, "summary": "The rise of generative models has raised concerns about image authenticity\nonline, highlighting the urgent need for a detector that is (1) highly\ngeneralizable, capable of handling unseen forgery techniques, and (2)\ndata-efficient, achieving optimal performance with minimal training data,\nenabling it to counter newly emerging forgery techniques effectively. To\nachieve this, we propose ForgeLens, a data-efficient, feature-guided framework\nthat incorporates two lightweight designs to enable a frozen network to focus\non forgery-specific features. First, we introduce the Weight-Shared Guidance\nModule (WSGM), which guides the extraction of forgery-specific features during\ntraining. Second, a forgery-aware feature integrator, FAFormer, is used to\neffectively integrate forgery information across multi-stage features.\nForgeLens addresses a key limitation of previous frozen network-based methods,\nwhere general-purpose features extracted from large datasets often contain\nexcessive forgery-irrelevant information. As a result, it achieves strong\ngeneralization and reaches optimal performance with minimal training data.\nExperimental results on 19 generative models, including both GANs and diffusion\nmodels, demonstrate improvements of 13.61% in Avg.Acc and 8.69% in Avg.AP over\nthe base model. Notably, ForgeLens outperforms existing forgery detection\nmethods, achieving state-of-the-art performance with just 1% of the training\ndata. Our code is available at https://github.com/Yingjian-Chen/ForgeLens.", "AI": {"tldr": "ForgeLens is a data-efficient, feature-guided framework for detecting image forgeries, achieving state-of-the-art performance with minimal training data.", "motivation": "Addressing concerns about image authenticity online by creating a detector that generalizes well and requires little training data.", "method": "Incorporates Weight-Shared Guidance Module (WSGM) and FAFormer to focus on forgery-specific features.", "result": "Improves Avg.Acc by 13.61% and Avg.AP by 8.69% over the base model, outperforming existing methods with 1% training data.", "conclusion": "ForgeLens is highly effective for forgery detection, offering strong generalization and data efficiency."}}
{"id": "2506.10186", "pdf": "https://arxiv.org/pdf/2506.10186", "abs": "https://arxiv.org/abs/2506.10186", "authors": ["Yuhui Ding", "Thomas Hofmann"], "title": "Scalable Non-Equivariant 3D Molecule Generation via Rotational Alignment", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": "ICML 2025; added conditional generation results", "summary": "Equivariant diffusion models have achieved impressive performance in 3D\nmolecule generation. These models incorporate Euclidean symmetries of 3D\nmolecules by utilizing an SE(3)-equivariant denoising network. However,\nspecialized equivariant architectures limit the scalability and efficiency of\ndiffusion models. In this paper, we propose an approach that relaxes such\nequivariance constraints. Specifically, our approach learns a sample-dependent\nSO(3) transformation for each molecule to construct an aligned latent space. A\nnon-equivariant diffusion model is then trained over the aligned\nrepresentations. Experimental results demonstrate that our approach performs\nsignificantly better than previously reported non-equivariant models. It yields\nsample quality comparable to state-of-the-art equivariant diffusion models and\noffers improved training and sampling efficiency. Our code is available at\nhttps://github.com/skeletondyh/RADM", "AI": {"tldr": "The paper proposes a method to relax equivariance constraints in diffusion models for 3D molecule generation, achieving comparable performance to equivariant models with improved efficiency.", "motivation": "Specialized equivariant architectures limit the scalability and efficiency of diffusion models for 3D molecule generation.", "method": "The approach learns a sample-dependent SO(3) transformation for each molecule to create an aligned latent space, then trains a non-equivariant diffusion model on these representations.", "result": "The method outperforms non-equivariant models and matches state-of-the-art equivariant models in sample quality while improving efficiency.", "conclusion": "The proposed approach offers a scalable and efficient alternative to equivariant diffusion models without sacrificing performance."}}
{"id": "2506.08240", "pdf": "https://arxiv.org/pdf/2506.08240", "abs": "https://arxiv.org/abs/2506.08240", "authors": ["Dongkyu Cho", "Rumi Chunara"], "title": "Dealing with the Evil Twins: Improving Random Augmentation by Addressing Catastrophic Forgetting of Diverse Augmentations", "categories": ["cs.LG"], "comment": "12 pages, 6 figures", "summary": "Data augmentation is a promising tool for enhancing out-of-distribution\ngeneralization, where the key is to produce diverse, challenging variations of\nthe source domain via costly targeted augmentations that maximize its\ngeneralization effect. Conversely, random augmentation is inexpensive but is\ndeemed suboptimal due to its limited effect. In this paper, we revisit random\naugmentation and explore methods to address its shortcomings. We show that the\nstochastic nature of random augmentation can produce a set of colliding\naugmentations that distorts the learned features, similar to catastrophic\nforgetting. We propose a simple solution that improves the generalization\neffect of random augmentation by addressing forgetting, which displays strong\ngeneralization performance across various single source domain generalization\n(sDG) benchmarks.", "AI": {"tldr": "Revisiting random augmentation to improve its generalization effect by addressing feature distortion, achieving strong performance in single source domain generalization.", "motivation": "Random augmentation is inexpensive but suboptimal due to limited generalization effect, while targeted augmentations are costly.", "method": "Propose a solution to address the stochastic nature of random augmentation, which distorts learned features, similar to catastrophic forgetting.", "result": "Improved generalization effect of random augmentation, demonstrated across single source domain generalization benchmarks.", "conclusion": "A simple solution to random augmentation's shortcomings enhances its generalization performance effectively."}}
{"id": "2409.08516", "pdf": "https://arxiv.org/pdf/2409.08516", "abs": "https://arxiv.org/abs/2409.08516", "authors": ["Zechao Sun", "Shuying Piao", "Haolin Jin", "Chang Dong", "Lin Yue", "Weitong Chen", "Luping Zhou"], "title": "AWF: Adaptive Weight Fusion for Enhanced Class Incremental Semantic Segmentation", "categories": ["cs.CV"], "comment": "10 pages,6 figures", "summary": "Class Incremental Semantic Segmentation (CISS) aims to mitigate catastrophic\nforgetting by maintaining a balance between previously learned and newly\nintroduced knowledge. Existing methods, primarily based on regularization\ntechniques like knowledge distillation, help preserve old knowledge but often\nface challenges in effectively integrating new knowledge, resulting in limited\noverall improvement. Endpoints Weight Fusion (EWF) method, while simple,\neffectively addresses some of these limitations by dynamically fusing the model\nweights from previous steps with those from the current step, using a fusion\nparameter alpha determined by the relative number of previously known classes\nand newly introduced classes. However, the simplicity of the alpha calculation\nmay limit its ability to fully capture the complexities of different task\nscenarios, potentially leading to suboptimal fusion outcomes. In this paper, we\npropose an enhanced approach called Adaptive Weight Fusion (AWF), which\nintroduces an alternating training strategy for the fusion parameter, allowing\nfor more flexible and adaptive weight integration. AWF achieves superior\nperformance by better balancing the retention of old knowledge with the\nlearning of new classes, significantly improving results on benchmark CISS\ntasks compared to the original EWF. And our experiment code will be released on\nGithub.", "AI": {"tldr": "The paper introduces Adaptive Weight Fusion (AWF), an improved version of Endpoints Weight Fusion (EWF), to better balance old and new knowledge in Class Incremental Semantic Segmentation (CISS). AWF uses an alternating training strategy for fusion parameters, outperforming EWF on benchmark tasks.", "motivation": "Existing methods like EWF struggle with optimal fusion of old and new knowledge due to simplistic parameter calculation, limiting performance in CISS.", "method": "Proposes AWF, which dynamically adjusts fusion parameters via alternating training for more adaptive weight integration.", "result": "AWF achieves superior performance over EWF, better balancing knowledge retention and new class learning.", "conclusion": "AWF enhances CISS performance by improving weight fusion adaptability, with code to be released on Github."}}
{"id": "2506.10558", "pdf": "https://arxiv.org/pdf/2506.10558", "abs": "https://arxiv.org/abs/2506.10558", "authors": ["Xiaolin Hu", "Qinghua Zhou", "Bogdan Grechuk", "Ivan Y. Tyukin"], "title": "StepProof: Step-by-step verification of natural language mathematical proofs", "categories": ["cs.LO", "cs.AI"], "comment": null, "summary": "Interactive theorem provers (ITPs) are powerful tools for the formal\nverification of mathematical proofs down to the axiom level. However, their\nlack of a natural language interface remains a significant limitation. Recent\nadvancements in large language models (LLMs) have enhanced the understanding of\nnatural language inputs, paving the way for autoformalization - the process of\ntranslating natural language proofs into formal proofs that can be verified.\nDespite these advancements, existing autoformalization approaches are limited\nto verifying complete proofs and lack the capability for finer, sentence-level\nverification. To address this gap, we propose StepProof, a novel\nautoformalization method designed for granular, step-by-step verification.\nStepProof breaks down complete proofs into multiple verifiable subproofs,\nenabling sentence-level verification. Experimental results demonstrate that\nStepProof significantly improves proof success rates and efficiency compared to\ntraditional methods. Additionally, we found that minor manual adjustments to\nthe natural language proofs, tailoring them for step-level verification,\nfurther enhanced StepProof's performance in autoformalization.", "AI": {"tldr": "StepProof is a novel autoformalization method for granular, step-by-step verification of proofs, improving success rates and efficiency over traditional methods.", "motivation": "Existing autoformalization approaches lack sentence-level verification, limiting their utility.", "method": "StepProof breaks proofs into verifiable subproofs for sentence-level verification and incorporates minor manual adjustments for optimization.", "result": "Experimental results show StepProof significantly improves proof success rates and efficiency.", "conclusion": "StepProof addresses the gap in finer verification, enhancing autoformalization performance with step-level granularity."}}
{"id": "2506.13702", "pdf": "https://arxiv.org/pdf/2506.13702", "abs": "https://arxiv.org/abs/2506.13702", "authors": ["Bilal Faye", "Hanane Azzag", "Mustapha Lebbah"], "title": "Value-Free Policy Optimization via Reward Partitioning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Single-trajectory reinforcement learning (RL) methods aim to optimize\npolicies from datasets consisting of (prompt, response, reward) triplets, where\nscalar rewards are directly available. This supervision format is highly\npractical, as it mirrors real-world human feedback, such as thumbs-up/down\nsignals, and avoids the need for structured preference annotations. In\ncontrast, pairwise preference-based methods like Direct Preference Optimization\n(DPO) rely on datasets with both preferred and dispreferred responses, which\nare harder to construct and less natural to collect. Among single-trajectory\napproaches, Direct Reward Optimization (DRO) has shown strong empirical\nperformance due to its simplicity and stability. However, DRO requires\napproximating a value function, which introduces several limitations: high\noff-policy variance, coupling between policy and value learning, and a lack of\nabsolute supervision on the policy itself. We introduce Reward Partitioning\nOptimization (RPO), a new method that resolves these limitations by removing\nthe need to model the value function. Instead, RPO normalizes observed rewards\nusing a partitioning approach estimated directly from data. This leads to a\nstraightforward supervised learning objective on the policy, with no auxiliary\nmodels and no joint optimization. RPO provides direct and stable supervision on\nthe policy, making it robust and easy to implement in practice. We validate RPO\non scalar-feedback language modeling tasks using Flan-T5 encoder-decoder\nmodels. Our results demonstrate that RPO outperforms existing single-trajectory\nbaselines such as DRO and Kahneman-Tversky Optimization (KTO). These findings\nconfirm that RPO is a simple, effective, and theoretically grounded method for\nsingle-trajectory policy optimization.", "AI": {"tldr": "RPO (Reward Partitioning Optimization) is introduced as a new method for single-trajectory RL, outperforming DRO and KTO by eliminating the need for value function approximation and providing direct policy supervision.", "motivation": "Single-trajectory RL methods like DRO face limitations due to value function approximation, leading to high variance and unstable training. RPO aims to address these issues.", "method": "RPO normalizes rewards using a partitioning approach estimated from data, avoiding auxiliary models and joint optimization. It simplifies policy supervision.", "result": "RPO outperforms DRO and KTO on scalar-feedback tasks, demonstrating robustness and ease of implementation.", "conclusion": "RPO is a simple, effective, and theoretically grounded method for single-trajectory policy optimization."}}
{"id": "2409.15010", "pdf": "https://arxiv.org/pdf/2409.15010", "abs": "https://arxiv.org/abs/2409.15010", "authors": ["Bulat Gabdullin", "Nina Konovalova", "Nikolay Patakin", "Dmitry Senushkin", "Anton Konushin"], "title": "DepthART: Monocular Depth Estimation as Autoregressive Refinement Task", "categories": ["cs.CV"], "comment": null, "summary": "Monocular depth estimation has seen significant advances through\ndiscriminative approaches, yet their performance remains constrained by the\nlimitations of training datasets. While generative approaches have addressed\nthis challenge by leveraging priors from internet-scale datasets, with recent\nstudies showing state-of-the-art results using fine-tuned text-to-image\ndiffusion models, there is still room for improvement. Notably, autoregressive\ngenerative approaches, particularly Visual AutoRegressive modeling, have\ndemonstrated superior results compared to diffusion models in conditioned image\nsynthesis, while offering faster inference times. In this work, we apply Visual\nAutoregressive Transformer (VAR) to the monocular depth estimation problem.\nHowever, the conventional GPT-2-style training procedure (teacher forcing)\ninherited by VAR yields suboptimal results for depth estimation. To address\nthis limitation, we introduce DepthART - a novel training method formulated as\na Depth Autoregressive Refinement Task. Unlike traditional VAR training with\nstatic inputs and targets, our method implements a dynamic target formulation\nbased on model outputs, enabling self-refinement. By utilizing the model's own\npredictions as inputs instead of ground truth token maps during training, we\nframe the objective as residual minimization, effectively reducing the\ndiscrepancy between training and inference procedures. Our experimental results\ndemonstrate that the proposed training approach significantly enhances the\nperformance of VAR in depth estimation tasks. When trained on Hypersim dataset\nusing our approach, the model achieves superior results across multiple unseen\nbenchmarks compared to existing generative and discriminative baselines.", "AI": {"tldr": "The paper introduces DepthART, a novel training method for monocular depth estimation using Visual Autoregressive Transformer (VAR), improving performance by refining predictions dynamically.", "motivation": "Current generative approaches for monocular depth estimation, like diffusion models, have limitations. VAR shows promise but suffers from suboptimal results due to conventional training methods.", "method": "DepthART refines VAR training by using model predictions as dynamic targets, minimizing residuals to align training and inference.", "result": "DepthART outperforms existing methods on unseen benchmarks when trained on the Hypersim dataset.", "conclusion": "DepthART enhances VAR's depth estimation performance, offering a superior alternative to traditional generative and discriminative approaches."}}
{"id": "2506.12846", "pdf": "https://arxiv.org/pdf/2506.12846", "abs": "https://arxiv.org/abs/2506.12846", "authors": ["Nina Cai", "Jinguang Han", "Weizhi Meng"], "title": "VFEFL: Privacy-Preserving Federated Learning against Malicious Clients via Verifiable Functional Encryption", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Federated learning is a promising distributed learning paradigm that enables\ncollaborative model training without exposing local client data, thereby\nprotect data privacy. However, it also brings new threats and challenges. The\nadvancement of model inversion attacks has rendered the plaintext transmission\nof local models insecure, while the distributed nature of federated learning\nmakes it particularly vulnerable to attacks raised by malicious clients. To\nprotect data privacy and prevent malicious client attacks, this paper proposes\na privacy-preserving federated learning framework based on verifiable\nfunctional encryption, without a non-colluding dual-server setup or additional\ntrusted third-party. Specifically, we propose a novel decentralized verifiable\nfunctional encryption (DVFE) scheme that enables the verification of specific\nrelationships over multi-dimensional ciphertexts. This scheme is formally\ntreated, in terms of definition, security model and security proof.\nFurthermore, based on the proposed DVFE scheme, we design a privacy-preserving\nfederated learning framework VFEFL that incorporates a novel robust aggregation\nrule to detect malicious clients, enabling the effective training of\nhigh-accuracy models under adversarial settings. Finally, we provide formal\nanalysis and empirical evaluation of the proposed schemes. The results\ndemonstrate that our approach achieves the desired privacy protection,\nrobustness, verifiability and fidelity, while eliminating the reliance on\nnon-colluding dual-server settings or trusted third parties required by\nexisting methods.", "AI": {"tldr": "A privacy-preserving federated learning framework using verifiable functional encryption (DVFE) to protect against model inversion attacks and malicious clients, eliminating the need for non-colluding servers or trusted third parties.", "motivation": "Federated learning faces threats like model inversion attacks and malicious clients, compromising data privacy and security.", "method": "Proposes a decentralized verifiable functional encryption (DVFE) scheme and a robust aggregation rule in the VFEFL framework.", "result": "Achieves privacy protection, robustness, verifiability, and fidelity without relying on non-colluding servers or trusted third parties.", "conclusion": "The framework effectively secures federated learning against adversarial threats while maintaining model accuracy."}}
{"id": "2506.14291", "pdf": "https://arxiv.org/pdf/2506.14291", "abs": "https://arxiv.org/abs/2506.14291", "authors": ["Ben Finkelshtein", "\u0130smail \u0130lkan Ceylan", "Michael Bronstein", "Ron Levie"], "title": "Equivariance Everywhere All At Once: A Recipe for Graph Foundation Models", "categories": ["cs.LG", "cs.SI", "stat.ML"], "comment": null, "summary": "Graph machine learning architectures are typically tailored to specific tasks\non specific datasets, which hinders their broader applicability. This has led\nto a new quest in graph machine learning: how to build graph foundation models\ncapable of generalizing across arbitrary graphs and features? In this work, we\npresent a recipe for designing graph foundation models for node-level tasks\nfrom first principles. The key ingredient underpinning our study is a\nsystematic investigation of the symmetries that a graph foundation model must\nrespect. In a nutshell, we argue that label permutation-equivariance alongside\nfeature permutation-invariance are necessary in addition to the common node\npermutation-equivariance on each local neighborhood of the graph. To this end,\nwe first characterize the space of linear transformations that are equivariant\nto permutations of nodes and labels, and invariant to permutations of features.\nWe then prove that the resulting network is a universal approximator on\nmultisets that respect the aforementioned symmetries. Our recipe uses such\nlayers on the multiset of features induced by the local neighborhood of the\ngraph to obtain a class of graph foundation models for node property\nprediction. We validate our approach through extensive experiments on 29\nreal-world node classification datasets, demonstrating both strong zero-shot\nempirical performance and consistent improvement as the number of training\ngraphs increases.", "AI": {"tldr": "The paper proposes a recipe for designing graph foundation models for node-level tasks, emphasizing symmetries like label permutation-equivariance and feature permutation-invariance. It validates the approach with strong zero-shot performance on 29 datasets.", "motivation": "Current graph ML architectures lack broader applicability due to task-specific designs, prompting the need for generalizable graph foundation models.", "method": "Systematically investigates symmetries (node, label, feature permutations) and designs linear transformations respecting these. Proves universality of the resulting network.", "result": "Demonstrates strong zero-shot performance and consistent improvement with more training graphs on 29 node classification datasets.", "conclusion": "The proposed symmetry-respecting framework effectively generalizes across arbitrary graphs and features, advancing graph foundation models."}}
{"id": "2409.17564", "pdf": "https://arxiv.org/pdf/2409.17564", "abs": "https://arxiv.org/abs/2409.17564", "authors": ["Lingyi Hong", "Jinglun Li", "Xinyu Zhou", "Shilin Yan", "Pinxue Guo", "Kaixun Jiang", "Zhaoyu Chen", "Shuyong Gao", "Runze Li", "Xingdong Sheng", "Wei Zhang", "Hong Lu", "Wenqiang Zhang"], "title": "General Compression Framework for Efficient Transformer Object Tracking", "categories": ["cs.CV"], "comment": "Accepted to ICCV 2025", "summary": "Previous works have attempted to improve tracking efficiency through\nlightweight architecture design or knowledge distillation from teacher models\nto compact student trackers. However, these solutions often sacrifice accuracy\nfor speed to a great extent, and also have the problems of complex training\nprocess and structural limitations. Thus, we propose a general model\ncompression framework for efficient transformer object tracking, named\nCompressTracker, to reduce model size while preserving tracking accuracy. Our\napproach features a novel stage division strategy that segments the transformer\nlayers of the teacher model into distinct stages to break the limitation of\nmodel structure. Additionally, we also design a unique replacement training\ntechnique that randomly substitutes specific stages in the student model with\nthose from the teacher model, as opposed to training the student model in\nisolation. Replacement training enhances the student model's ability to\nreplicate the teacher model's behavior and simplifies the training process. To\nfurther forcing student model to emulate teacher model, we incorporate\nprediction guidance and stage-wise feature mimicking to provide additional\nsupervision during the teacher model's compression process. CompressTracker is\nstructurally agnostic, making it compatible with any transformer architecture.\nWe conduct a series of experiment to verify the effectiveness and\ngeneralizability of our CompressTracker. Our CompressTracker-SUTrack,\ncompressed from SUTrack, retains about 99 performance on LaSOT (72.2 AUC) while\nachieves 2.42x speed up. Code is available at\nhttps://github.com/LingyiHongfd/CompressTracker.", "AI": {"tldr": "CompressTracker is a model compression framework for efficient transformer object tracking, balancing speed and accuracy with a novel stage division strategy and replacement training.", "motivation": "Existing methods sacrifice accuracy for speed and have complex training processes. CompressTracker aims to reduce model size while preserving accuracy.", "method": "Uses stage division to segment transformer layers and replacement training to enhance student model replication. Includes prediction guidance and feature mimicking for supervision.", "result": "CompressTracker-SUTrack retains 99% of SUTrack's performance (72.2 AUC on LaSOT) with a 2.42x speedup.", "conclusion": "CompressTracker is effective, generalizable, and compatible with any transformer architecture."}}
{"id": "2506.14540", "pdf": "https://arxiv.org/pdf/2506.14540", "abs": "https://arxiv.org/abs/2506.14540", "authors": ["Gerardo A. Flores", "Alyssa H. Smith", "Julia A. Fukuyama", "Ashia C. Wilson"], "title": "Aligning Evaluation with Clinical Priorities: Calibration, Label Shift, and Error Costs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Machine learning-based decision support systems are increasingly deployed in\nclinical settings, where probabilistic scoring functions are used to inform and\nprioritize patient management decisions. However, widely used scoring rules,\nsuch as accuracy and AUC-ROC, fail to adequately reflect key clinical\npriorities, including calibration, robustness to distributional shifts, and\nsensitivity to asymmetric error costs. In this work, we propose a principled\nyet practical evaluation framework for selecting calibrated thresholded\nclassifiers that explicitly accounts for the uncertainty in class prevalences\nand domain-specific cost asymmetries often found in clinical settings. Building\non the theory of proper scoring rules, particularly the Schervish\nrepresentation, we derive an adjusted variant of cross-entropy (log score) that\naverages cost-weighted performance over clinically relevant ranges of class\nbalance. The resulting evaluation is simple to apply, sensitive to clinical\ndeployment conditions, and designed to prioritize models that are both\ncalibrated and robust to real-world variations.", "AI": {"tldr": "The paper proposes a clinical evaluation framework for machine learning models, addressing limitations of traditional metrics like accuracy and AUC-ROC by incorporating calibration, robustness, and cost asymmetry.", "motivation": "Current scoring rules (e.g., accuracy, AUC-ROC) inadequately reflect clinical priorities such as calibration, robustness to shifts, and asymmetric error costs.", "method": "The framework uses an adjusted cross-entropy (log score) derived from proper scoring rules, averaging cost-weighted performance over relevant class balance ranges.", "result": "The proposed evaluation is practical, sensitive to clinical conditions, and prioritizes calibrated, robust models.", "conclusion": "The framework improves model selection for clinical decision-making by aligning evaluation with real-world deployment needs."}}
{"id": "2506.14436", "pdf": "https://arxiv.org/pdf/2506.14436", "abs": "https://arxiv.org/abs/2506.14436", "authors": ["Shen Yuan", "Yin Zheng", "Taifeng Wang", "Binbin Liu", "Hongteng Xu"], "title": "MoORE: SVD-based Model MoE-ization for Conflict- and Oblivion-Resistant Multi-Task Adaptation", "categories": ["cs.LG"], "comment": "24 pages, 6 figures", "summary": "Adapting large-scale foundation models in multi-task scenarios often suffers\nfrom task conflict and oblivion. To mitigate such issues, we propose a novel\n''model MoE-ization'' strategy that leads to a conflict- and oblivion-resistant\nmulti-task adaptation method. Given a weight matrix of a pre-trained model, our\nmethod applies SVD to it and introduces a learnable router to adjust its\nsingular values based on tasks and samples. Accordingly, the weight matrix\nbecomes a Mixture of Orthogonal Rank-one Experts (MoORE), in which each expert\ncorresponds to the outer product of a left singular vector and the\ncorresponding right one. We can improve the model capacity by imposing a\nlearnable orthogonal transform on the right singular vectors. Unlike low-rank\nadaptation (LoRA) and its MoE-driven variants, MoORE guarantees the experts'\northogonality and maintains the column space of the original weight matrix.\nThese two properties make the adapted model resistant to the conflicts among\nthe new tasks and the oblivion of its original tasks, respectively. Experiments\non various datasets demonstrate that MoORE outperforms existing multi-task\nadaptation methods consistently, showing its superiority in terms of conflict-\nand oblivion-resistance. The code of the experiments is available at\nhttps://github.com/DaShenZi721/MoORE.", "AI": {"tldr": "The paper proposes MoORE, a method for multi-task adaptation of foundation models using a Mixture of Orthogonal Rank-one Experts to avoid task conflict and oblivion.", "motivation": "Large-scale foundation models face issues like task conflict and oblivion in multi-task scenarios, necessitating a robust adaptation method.", "method": "The method applies SVD to a pre-trained model's weight matrix, introduces a learnable router for task-specific adjustments, and ensures orthogonality among experts.", "result": "MoORE outperforms existing methods in multi-task adaptation, demonstrating superior conflict- and oblivion-resistance.", "conclusion": "MoORE is an effective solution for multi-task adaptation, maintaining model performance while avoiding common pitfalls."}}
{"id": "2409.18860", "pdf": "https://arxiv.org/pdf/2409.18860", "abs": "https://arxiv.org/abs/2409.18860", "authors": ["Qian Feng", "Da-wei Zhou", "Hanbin Zhao", "Chao Zhang", "Jiahua Dong", "Dengxin Dai", "Hui Qian"], "title": "LW2G: Learning Whether to Grow for Prompt-based Continual Learning", "categories": ["cs.CV"], "comment": null, "summary": "Recent Prompt-based Continual learning (PCL) has achieved remarkable\nperformance with pre-trained models. These approaches expand a prompt pool by\nadding a new set of prompts while learning and select the correct set during\ninference. Previous studies have revealed that learning task-wised prompt sets\nindividually and low selection accuracy pose challenges to the performance of\nPCL. In this paper, we propose a plug-in method, $\\textbf{L}$earning\n$\\textbf{W}$hether $\\textbf{t}$o $\\textbf{G}$row $\\textbf{(LW2G)}$, which\nleverages the disparities between tasks to form an effective and efficient\nprompt sets pool, thereby achieving intra-task knowledge sharing and\ncooperation and avoiding the unbounded increase in the cost of the prompt pool.\nSpecifically, a shared set is utilized when several tasks share certain\ncommonalities, and a new set is added when there are significant differences\nbetween the new and previous tasks. To achieve this, we develop a metric called\nHinder Forward Capability (HFC) to measure the hindrance imposed on learning\nnew tasks by surgically modifying the original gradient onto the orthogonal\ncomplement of the old feature space. With HFC, an automated scheme, Dynamic\nGrowing Approach, adaptively learns whether to grow with a dynamic threshold.\nFurthermore, we design a gradient-based constraint to ensure consistency\nbetween the updating prompts and pre-trained knowledge. Extensive experiments\nshow the effectiveness of our method. Code is available at\nhttps://github.com/RAIAN08/LW2G.", "AI": {"tldr": "The paper introduces LW2G, a plug-in method for prompt-based continual learning that dynamically decides whether to expand the prompt pool based on task disparities, improving efficiency and performance.", "motivation": "Addressing challenges in prompt-based continual learning, such as low selection accuracy and unbounded prompt pool growth, by leveraging task disparities for better prompt set management.", "method": "Proposes LW2G, which uses a metric (HFC) to measure task hindrance and a dynamic growing approach to adaptively expand the prompt pool. Includes a gradient-based constraint for consistency.", "result": "Extensive experiments demonstrate LW2G's effectiveness in achieving intra-task knowledge sharing and avoiding excessive prompt pool growth.", "conclusion": "LW2G offers an efficient and adaptive solution for prompt-based continual learning, balancing task-specific needs with shared knowledge."}}
{"id": "2506.18504", "pdf": "https://arxiv.org/pdf/2506.18504", "abs": "https://arxiv.org/abs/2506.18504", "authors": ["Xinyao Li", "Jingjing Li", "Fengling Li", "Lei Zhu", "Yang Yang", "Heng Tao Shen"], "title": "Generalizing vision-language models to novel domains: A comprehensive survey", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recently, vision-language pretraining has emerged as a transformative\ntechnique that integrates the strengths of both visual and textual modalities,\nresulting in powerful vision-language models (VLMs). Leveraging web-scale\npretraining data, these models exhibit strong zero-shot capabilities. However,\ntheir performance often deteriorates when confronted with domain-specific or\nspecialized generalization tasks. To address this, a growing body of research\nfocuses on transferring or generalizing the rich knowledge embedded in VLMs to\nvarious downstream applications. This survey aims to comprehensively summarize\nthe generalization settings, methodologies, benchmarking and results in VLM\nliteratures. Delving into the typical VLM structures, current literatures are\ncategorized into prompt-based, parameter-based and feature-based methods\naccording to the transferred modules. The differences and characteristics in\neach category are furthered summarized and discussed by revisiting the typical\ntransfer learning (TL) settings, providing novel interpretations for TL in the\nera of VLMs. Popular benchmarks for VLM generalization are further introduced\nwith thorough performance comparisons among the reviewed methods. Following the\nadvances in large-scale generalizable pretraining, this survey also discusses\nthe relations and differences between VLMs and up-to-date multimodal large\nlanguage models (MLLM), e.g., DeepSeek-VL. By systematically reviewing the\nsurging literatures in vision-language research from a novel and practical\ngeneralization prospective, this survey contributes to a clear landscape of\ncurrent and future multimodal researches.", "AI": {"tldr": "A survey on vision-language models (VLMs) focusing on their generalization challenges, methodologies, and benchmarks, while comparing them with multimodal large language models (MLLMs).", "motivation": "VLMs excel in zero-shot tasks but struggle with domain-specific tasks, prompting research into transferring their knowledge to downstream applications.", "method": "Categorizes VLM generalization methods into prompt-based, parameter-based, and feature-based, and reviews benchmarks and performance comparisons.", "result": "Summarizes current VLM generalization techniques and benchmarks, highlighting their strengths and limitations.", "conclusion": "Provides a clear overview of VLM generalization research and its future directions, including comparisons with MLLMs."}}
{"id": "2506.15079", "pdf": "https://arxiv.org/pdf/2506.15079", "abs": "https://arxiv.org/abs/2506.15079", "authors": ["Yikai Hou", "Peng Tang"], "title": "Neural Canonical Polyadic Factorization for Traffic Analysis", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Modern intelligent transportation systems rely on accurate spatiotemporal\ntraffic analysis to optimize urban mobility and infrastructure resilience.\nHowever, pervasive missing data caused by sensor failures and heterogeneous\nsensing gaps fundamentally hinders reliable traffic modeling. This paper\nproposes a Neural Canonical Polyadic Factorization (NCPF) model that synergizes\nlow-rank tensor algebra with deep representation learning for robust traffic\ndata imputation. The model innovatively embeds CP decomposition into neural\narchitecture through learnable embedding projections, where sparse traffic\ntensors are encoded into dense latent factors across road segments, time\nintervals, and mobility metrics. A hierarchical feature fusion mechanism\nemploys Hadamard products to explicitly model multilinear interactions, while\nstacked multilayer perceptron layers nonlinearly refine these representations\nto capture complex spatiotemporal couplings. Extensive evaluations on six urban\ntraffic datasets demonstrate NCPF's superiority over six state-of-the-art\nbaselines. By unifying CP decomposition's interpretable factor analysis with\nneural network's nonlinear expressive power, NCPF provides a principled yet\nflexible approaches for high-dimensional traffic data imputation, offering\ncritical support for next-generation transportation digital twins and adaptive\ntraffic control systems.", "AI": {"tldr": "The paper introduces NCPF, a model combining low-rank tensor algebra and deep learning for robust traffic data imputation, outperforming existing methods.", "motivation": "Missing traffic data due to sensor failures and sensing gaps hinders reliable traffic modeling, necessitating advanced imputation techniques.", "method": "NCPF integrates CP decomposition with neural networks, using learnable embeddings and hierarchical feature fusion to model spatiotemporal interactions.", "result": "NCPF outperforms six state-of-the-art baselines across six urban traffic datasets.", "conclusion": "NCPF unifies interpretable factor analysis with neural networks, offering a flexible solution for traffic data imputation and supporting future transportation systems."}}
{"id": "2409.20003", "pdf": "https://arxiv.org/pdf/2409.20003", "abs": "https://arxiv.org/abs/2409.20003", "authors": ["Koichi Ito", "Taito Tonosaki", "Takafumi Aoki", "Tetsushi Ohki", "Masakatsu Nishigaki"], "title": "Multibiometrics Using a Single Face Image", "categories": ["cs.CV"], "comment": "APSIPA ASC 2024", "summary": "Multibiometrics, which uses multiple biometric traits to improve recognition\nperformance instead of using only one biometric trait to authenticate\nindividuals, has been investigated. Previous studies have combined individually\nacquired biometric traits or have not fully considered the convenience of the\nsystem. Focusing on a single face image, we propose a novel multibiometric\nmethod that combines five biometric traits, i.e., face, iris, periocular, nose,\neyebrow, that can be extracted from a single face image. The proposed method\ndoes not sacrifice the convenience of biometrics since only a single face image\nis used as input. Through a variety of experiments using the CASIA Iris\nDistance database, we demonstrate the effectiveness of the proposed\nmultibiometrics method.", "AI": {"tldr": "A novel multibiometric method combines five traits (face, iris, periocular, nose, eyebrow) from a single face image, maintaining convenience while improving recognition performance.", "motivation": "To enhance biometric recognition performance without sacrificing convenience by leveraging multiple traits from a single face image.", "method": "Extracts five biometric traits (face, iris, periocular, nose, eyebrow) from one face image, avoiding the need for multiple acquisitions.", "result": "Demonstrated effectiveness using the CASIA Iris Distance database.", "conclusion": "The proposed method improves recognition performance while retaining the convenience of single-image input."}}
{"id": "2506.18915", "pdf": "https://arxiv.org/pdf/2506.18915", "abs": "https://arxiv.org/abs/2506.18915", "authors": ["Siyang Song", "Yupeng Huo", "Shiqing Tang", "Jiaee Cheong", "Rui Gao", "Michel Valstar", "Hatice Gunes"], "title": "Automatic Depression Assessment using Machine Learning: A Comprehensive Survey", "categories": ["q-bio.NC", "cs.AI", "cs.LG", "68T40", "I.2.1"], "comment": null, "summary": "Depression is a common mental illness across current human society.\nTraditional depression assessment relying on inventories and interviews with\npsychologists frequently suffer from subjective diagnosis results, slow and\nexpensive diagnosis process as well as lack of human resources. Since there is\na solid evidence that depression is reflected by various human internal brain\nactivities and external expressive behaviours, early traditional machine\nlearning (ML) and advanced deep learning (DL) models have been widely explored\nfor human behaviour-based automatic depression assessment (ADA) since 2012.\nHowever, recent ADA surveys typically only focus on a limited number of human\nbehaviour modalities. Despite being used as a theoretical basis for developing\nADA approaches, existing ADA surveys lack a comprehensive review and summary of\nmulti-modal depression-related human behaviours. To bridge this gap, this paper\nspecifically summarises depression-related human behaviours across a range of\nmodalities (e.g. the human brain, verbal language and non-verbal\naudio/facial/body behaviours). We focus on conducting an up-to-date and\ncomprehensive survey of ML-based ADA approaches for learning depression cues\nfrom these behaviours as well as discussing and comparing their distinctive\nfeatures and limitations. In addition, we also review existing ADA competitions\nand datasets, identify and discuss the main challenges and opportunities to\nprovide further research directions for future ADA researchers.", "AI": {"tldr": "This paper reviews multi-modal human behaviors for automatic depression assessment (ADA), summarizing ML/DL approaches, datasets, and challenges to guide future research.", "motivation": "Traditional depression diagnosis is subjective, slow, and costly. ADA using ML/DL can leverage behavioral cues for more objective and scalable solutions.", "method": "The paper surveys depression-related behaviors across modalities (brain, language, audio, facial, body) and reviews ML-based ADA approaches, datasets, and competitions.", "result": "It provides a comprehensive review of ADA methods, highlighting their features, limitations, and gaps in multi-modal behavior analysis.", "conclusion": "The study identifies challenges and opportunities in ADA, offering directions for future research to improve depression assessment."}}
{"id": "2506.16629", "pdf": "https://arxiv.org/pdf/2506.16629", "abs": "https://arxiv.org/abs/2506.16629", "authors": ["Eric V. Strobl"], "title": "Learning Causally Predictable Outcomes from Psychiatric Longitudinal Data", "categories": ["cs.LG", "q-bio.QM", "stat.ML"], "comment": "R code is available at github.com/ericstrobl/DEBIAS", "summary": "Causal inference in longitudinal biomedical data remains a central challenge,\nespecially in psychiatry, where symptom heterogeneity and latent confounding\nfrequently undermine classical estimators. Most existing methods for treatment\neffect estimation presuppose a fixed outcome variable and address confounding\nthrough observed covariate adjustment. However, the assumption of\nunconfoundedness may not hold for a fixed outcome in practice. To address this\nfoundational limitation, we directly optimize the outcome definition to\nmaximize causal identifiability. Our DEBIAS (Durable Effects with\nBackdoor-Invariant Aggregated Symptoms) algorithm learns non-negative,\nclinically interpretable weights for outcome aggregation, maximizing durable\ntreatment effects and empirically minimizing both observed and latent\nconfounding by leveraging the time-limited direct effects of prior treatments\nin psychiatric longitudinal data. The algorithm also furnishes an empirically\nverifiable test for outcome unconfoundedness. DEBIAS consistently outperforms\nstate-of-the-art methods in recovering causal effects for clinically\ninterpretable composite outcomes across comprehensive experiments in depression\nand schizophrenia.", "AI": {"tldr": "DEBIAS optimizes outcome definitions to maximize causal identifiability, outperforming existing methods in psychiatric longitudinal data.", "motivation": "Addressing the challenge of causal inference in psychiatry due to symptom heterogeneity and latent confounding.", "method": "DEBIAS algorithm learns non-negative, interpretable weights for outcome aggregation, minimizing confounding.", "result": "Outperforms state-of-the-art methods in depression and schizophrenia data.", "conclusion": "DEBIAS provides a robust, interpretable solution for causal inference in psychiatry."}}
{"id": "2410.10105", "pdf": "https://arxiv.org/pdf/2410.10105", "abs": "https://arxiv.org/abs/2410.10105", "authors": ["Qian Yu", "Peng-Tao Jiang", "Hao Zhang", "Jinwei Chen", "Bo Li", "Lihe Zhang", "Huchuan Lu"], "title": "High-Precision Dichotomous Image Segmentation via Probing Diffusion Capacity", "categories": ["cs.CV"], "comment": "Published as a conference paper at ICLR 2025", "summary": "In the realm of high-resolution (HR), fine-grained image segmentation, the\nprimary challenge is balancing broad contextual awareness with the precision\nrequired for detailed object delineation, capturing intricate details and the\nfinest edges of objects. Diffusion models, trained on vast datasets comprising\nbillions of image-text pairs, such as SD V2.1, have revolutionized\ntext-to-image synthesis by delivering exceptional quality, fine detail\nresolution, and strong contextual awareness, making them an attractive solution\nfor high-resolution image segmentation. To this end, we propose DiffDIS, a\ndiffusion-driven segmentation model that taps into the potential of the\npre-trained U-Net within diffusion models, specifically designed for\nhigh-resolution, fine-grained object segmentation. By leveraging the robust\ngeneralization capabilities and rich, versatile image representation prior of\nthe SD models, coupled with a task-specific stable one-step denoising approach,\nwe significantly reduce the inference time while preserving high-fidelity,\ndetailed generation. Additionally, we introduce an auxiliary edge generation\ntask to not only enhance the preservation of fine details of the object\nboundaries, but reconcile the probabilistic nature of diffusion with the\ndeterministic demands of segmentation. With these refined strategies in place,\nDiffDIS serves as a rapid object mask generation model, specifically optimized\nfor generating detailed binary maps at high resolutions, while demonstrating\nimpressive accuracy and swift processing. Experiments on the DIS5K dataset\ndemonstrate the superiority of DiffDIS, achieving state-of-the-art results\nthrough a streamlined inference process. The source code will be publicly\navailable at https://github.com/qianyu-dlut/DiffDIS.", "AI": {"tldr": "DiffDIS is a diffusion-driven segmentation model leveraging pre-trained U-Net in diffusion models for high-resolution, fine-grained image segmentation, achieving state-of-the-art results with fast inference.", "motivation": "The challenge in high-resolution image segmentation is balancing contextual awareness with precision for detailed object delineation. Diffusion models offer exceptional detail resolution and contextual awareness, making them suitable for this task.", "method": "DiffDIS uses a pre-trained U-Net from diffusion models, a task-specific stable one-step denoising approach, and an auxiliary edge generation task to enhance detail preservation and reconcile diffusion's probabilistic nature with segmentation's deterministic demands.", "result": "Experiments on the DIS5K dataset show DiffDIS achieves state-of-the-art results with high accuracy and fast processing.", "conclusion": "DiffDIS is an efficient, high-resolution segmentation model, combining diffusion models' strengths with task-specific optimizations for detailed binary mask generation."}}
{"id": "2506.18985", "pdf": "https://arxiv.org/pdf/2506.18985", "abs": "https://arxiv.org/abs/2506.18985", "authors": ["Guanxi Shen"], "title": "GLIMPSE: Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation for Generative LVLMs", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent progress in large vision-language models (LVLMs) has advanced the\nstate of the art in visual question answering (VQA). However, interpreting\nwhere LVLMs direct their visual attention while generating free-form responses\nremains a significant challenge, yet is essential for understanding model\nbehavior. We introduce GLIMPSE (Gradient-Layer Importance Mapping for Prompted\nVisual Saliency Explanation), a lightweight, model-agnostic framework that\njointly attributes LVLM outputs to the most relevant visual evidence and\ntextual signals supporting open-ended VQA. GLIMPSE fuses gradient-weighted\nattention, adaptive layer propagation, and relevance-weighted token aggregation\nto produce holistic response-level heat maps for interpreting cross-modal\nreasoning, outperforming prior interpretability methods and pushing the\nstate-of-the-art in human-alignment. We demonstrate an analytic explainable AI\n(XAI) approach using GLIMPSE to uncover fine-grained insights into LVLM\ncross-modal attribution, trace reasoning dynamics, analyze systematic\nhuman-attention misalignment, diagnose hallucination, expose bias, and ensure\ntransparency.", "AI": {"tldr": "GLIMPSE is a lightweight, model-agnostic framework for interpreting LVLM outputs in VQA by attributing responses to visual and textual evidence, outperforming prior methods.", "motivation": "Understanding where LVLMs focus their visual attention during free-form responses is crucial for model transparency and behavior analysis.", "method": "GLIMPSE combines gradient-weighted attention, adaptive layer propagation, and relevance-weighted token aggregation to generate response-level heat maps.", "result": "GLIMPSE outperforms existing interpretability methods and enhances human-alignment in cross-modal reasoning.", "conclusion": "GLIMPSE provides fine-grained insights into LVLM behavior, aiding in diagnosing issues like hallucination and bias while ensuring transparency."}}
{"id": "2506.17718", "pdf": "https://arxiv.org/pdf/2506.17718", "abs": "https://arxiv.org/abs/2506.17718", "authors": ["Zhuo He", "Shuang Li", "Wenze Song", "Longhui Yuan", "Jian Liang", "Han Li", "Kun Gai"], "title": "Learning Time-Aware Causal Representation for Model Generalization in Evolving Domains", "categories": ["cs.LG", "stat.ML"], "comment": "ICML 2025", "summary": "Endowing deep models with the ability to generalize in dynamic scenarios is\nof vital significance for real-world deployment, given the continuous and\ncomplex changes in data distribution. Recently, evolving domain generalization\n(EDG) has emerged to address distribution shifts over time, aiming to capture\nevolving patterns for improved model generalization. However, existing EDG\nmethods may suffer from spurious correlations by modeling only the dependence\nbetween data and targets across domains, creating a shortcut between\ntask-irrelevant factors and the target, which hinders generalization. To this\nend, we design a time-aware structural causal model (SCM) that incorporates\ndynamic causal factors and the causal mechanism drifts, and propose\n\\textbf{S}tatic-D\\textbf{YN}amic \\textbf{C}ausal Representation Learning\n(\\textbf{SYNC}), an approach that effectively learns time-aware causal\nrepresentations. Specifically, it integrates specially designed\ninformation-theoretic objectives into a sequential VAE framework which captures\nevolving patterns, and produces the desired representations by preserving\nintra-class compactness of causal factors both across and within domains.\nMoreover, we theoretically show that our method can yield the optimal causal\npredictor for each time domain. Results on both synthetic and real-world\ndatasets exhibit that SYNC can achieve superior temporal generalization\nperformance.", "AI": {"tldr": "SYNC introduces a time-aware causal model to address evolving domain generalization by capturing dynamic causal factors and mechanism drifts, outperforming existing methods.", "motivation": "To improve model generalization in dynamic scenarios by addressing spurious correlations in evolving domain generalization (EDG).", "method": "Proposes SYNC, a time-aware structural causal model (SCM) with information-theoretic objectives in a sequential VAE framework to learn causal representations.", "result": "SYNC achieves superior temporal generalization performance on synthetic and real-world datasets.", "conclusion": "SYNC effectively learns time-aware causal representations, providing optimal causal predictors for each time domain."}}
{"id": "2410.11301", "pdf": "https://arxiv.org/pdf/2410.11301", "abs": "https://arxiv.org/abs/2410.11301", "authors": ["Yiming Li", "Yi Wang", "Wenqian Wang", "Dan Lin", "Bingbing Li", "Kim-Hui Yap"], "title": "Open World Object Detection: A Survey", "categories": ["cs.CV"], "comment": "Accepted for publication in IEEE TCSVT", "summary": "Exploring new knowledge is a fundamental human ability that can be mirrored\nin the development of deep neural networks, especially in the field of object\ndetection. Open world object detection (OWOD) is an emerging area of research\nthat adapts this principle to explore new knowledge. It focuses on recognizing\nand learning from objects absent from initial training sets, thereby\nincrementally expanding its knowledge base when new class labels are\nintroduced. This survey paper offers a thorough review of the OWOD domain,\ncovering essential aspects, including problem definitions, benchmark datasets,\nsource codes, evaluation metrics, and a comparative study of existing methods.\nAdditionally, we investigate related areas like open set recognition (OSR) and\nincremental learning (IL), underlining their relevance to OWOD. Finally, the\npaper concludes by addressing the limitations and challenges faced by current\nOWOD algorithms and proposes directions for future research. To our knowledge,\nthis is the first comprehensive survey of the emerging OWOD field with over one\nhundred references, marking a significant step forward for object detection\ntechnology. A comprehensive source code and benchmarks are archived and\nconcluded at https://github.com/ArminLee/OWOD Review.", "AI": {"tldr": "This survey paper reviews Open World Object Detection (OWOD), covering definitions, datasets, methods, and challenges, while also exploring related fields like OSR and IL.", "motivation": "To provide a comprehensive overview of the emerging OWOD field, addressing its potential to expand knowledge incrementally in object detection.", "method": "The paper reviews problem definitions, datasets, source codes, evaluation metrics, and compares existing methods, alongside related areas like OSR and IL.", "result": "A detailed survey of OWOD with over 100 references, highlighting current limitations and future research directions.", "conclusion": "The paper marks a significant step in advancing object detection technology by summarizing OWOD's progress and challenges."}}
{"id": "2506.19107", "pdf": "https://arxiv.org/pdf/2506.19107", "abs": "https://arxiv.org/abs/2506.19107", "authors": ["Ruiwei Xiao", "Xinying Hou", "Runlong Ye", "Majeed Kazemitabaar", "Nicholas Diana", "Michael Liut", "John Stamper"], "title": "Improving Student-AI Interaction Through Pedagogical Prompting: An Example in Computer Science Education", "categories": ["cs.HC", "cs.AI"], "comment": "Under review for Elsevier Journal. Journal policy allows submitting\n  as preprint", "summary": "With the proliferation of large language model (LLM) applications since 2022,\ntheir use in education has sparked both excitement and concern. Recent studies\nconsistently highlight students' (mis)use of LLMs can hinder learning outcomes.\nThis work aims to teach students how to effectively prompt LLMs to improve\ntheir learning. We first proposed pedagogical prompting, a\ntheoretically-grounded new concept to elicit learning-oriented responses from\nLLMs. To move from concept design to a proof-of-concept learning intervention\nin real educational settings, we selected early undergraduate CS education\n(CS1/CS2) as the example context. We began with a formative survey study with\ninstructors (N=36) teaching early-stage undergraduate-level CS courses to\ninform the instructional design based on classroom needs. Based on their\ninsights, we designed and developed a learning intervention through an\ninteractive system with scenario-based instruction to train pedagogical\nprompting skills. Finally, we evaluated its instructional effectiveness through\na user study with CS novice students (N=22) using pre/post-tests. Through mixed\nmethods analyses, our results indicate significant improvements in learners'\nLLM-based pedagogical help-seeking skills, along with positive attitudes toward\nthe system and increased willingness to use pedagogical prompts in the future.\nOur contributions include (1) a theoretical framework of pedagogical prompting;\n(2) empirical insights into current instructor attitudes toward pedagogical\nprompting; and (3) a learning intervention design with an interactive learning\ntool and scenario-based instruction leading to promising results on teaching\nLLM-based help-seeking. Our approach is scalable for broader implementation in\nclassrooms and has the potential to be integrated into tools like ChatGPT as an\non-boarding experience to encourage learning-oriented use of generative AI.", "AI": {"tldr": "The paper introduces pedagogical prompting to teach students effective LLM use in education, validated through a CS education intervention with positive results.", "motivation": "Address concerns about students' misuse of LLMs hindering learning by teaching effective, learning-oriented prompting.", "method": "Developed pedagogical prompting, surveyed instructors (N=36), designed an interactive system, and evaluated with students (N=22) via pre/post-tests.", "result": "Significant improvement in students' LLM-based help-seeking skills and positive attitudes toward pedagogical prompting.", "conclusion": "Pedagogical prompting is effective and scalable, with potential for broader classroom and tool integration."}}
{"id": "2506.17872", "pdf": "https://arxiv.org/pdf/2506.17872", "abs": "https://arxiv.org/abs/2506.17872", "authors": ["Sree Bhargavi Balija", "Amitash Nanda", "Debashis Sahoo"], "title": "Decoding Federated Learning: The FedNAM+ Conformal Revolution", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Federated learning has significantly advanced distributed training of machine\nlearning models across decentralized data sources. However, existing frameworks\noften lack comprehensive solutions that combine uncertainty quantification,\ninterpretability, and robustness. To address this, we propose FedNAM+, a\nfederated learning framework that integrates Neural Additive Models (NAMs) with\na novel conformal prediction method to enable interpretable and reliable\nuncertainty estimation. Our method introduces a dynamic level adjustment\ntechnique that utilizes gradient-based sensitivity maps to identify key input\nfeatures influencing predictions. This facilitates both interpretability and\npixel-wise uncertainty estimates. Unlike traditional interpretability methods\nsuch as LIME and SHAP, which do not provide confidence intervals, FedNAM+\noffers visual insights into prediction reliability. We validate our approach\nthrough experiments on CT scan, MNIST, and CIFAR datasets, demonstrating high\nprediction accuracy with minimal loss (e.g., only 0.1% on MNIST), along with\ntransparent uncertainty measures. Visual analysis highlights variable\nuncertainty intervals, revealing low-confidence regions where model performance\ncan be improved with additional data. Compared to Monte Carlo Dropout, FedNAM+\ndelivers efficient and global uncertainty estimates with reduced computational\noverhead, making it particularly suitable for federated learning scenarios.\nOverall, FedNAM+ provides a robust, interpretable, and computationally\nefficient framework that enhances trust and transparency in decentralized\npredictive modeling.", "AI": {"tldr": "FedNAM+ is a federated learning framework integrating Neural Additive Models (NAMs) and conformal prediction for interpretable, reliable uncertainty estimation, validated on datasets like MNIST and CIFAR.", "motivation": "Existing federated learning frameworks lack solutions combining uncertainty quantification, interpretability, and robustness.", "method": "FedNAM+ integrates NAMs with conformal prediction, using gradient-based sensitivity maps for dynamic level adjustment and pixel-wise uncertainty estimates.", "result": "High prediction accuracy (e.g., 0.1% loss on MNIST) with transparent uncertainty measures, outperforming methods like Monte Carlo Dropout in efficiency.", "conclusion": "FedNAM+ enhances trust and transparency in decentralized predictive modeling with robustness, interpretability, and computational efficiency."}}
{"id": "2411.06197", "pdf": "https://arxiv.org/pdf/2411.06197", "abs": "https://arxiv.org/abs/2411.06197", "authors": ["Shukun Jia", "Shiyu Hu", "Yichao Cao", "Feng Yang", "Xin Lu", "Xiaobo Lu"], "title": "Tracking by Detection and Query: An Efficient End-to-End Framework for Multi-Object Tracking", "categories": ["cs.CV"], "comment": null, "summary": "Multi-object tracking (MOT) is dominated by two paradigms:\ntracking-by-detection (TBD) and tracking-by-query (TBQ). While TBD is decoupled\nand efficient, its fragmented association steps and heuristic matching\npipelines often compromise robustness in complex scenarios. TBQ provides\nstronger semantic modeling through end-to-end learning, but suffers from high\ntraining cost and slow inference due to tight coupling between detection and\nassociation. To address these challenges, we propose TBDQ-Net, a unified\ntracking-by-detection-and-query (TBDQ) framework that effectively combines the\nstrengths of both paradigms. Our method efficiently integrates pretrained,\nhigh-performance detectors with an MOT-tailored associator. The associator is\nlightweight and directly fetches information from the inference of detectors,\nenhancing the overall efficiency of the framework. The associator is also\nlearnable, making it essential for fully end-to-end optimization, ensuring\nrobust tracking capabilities. Specifically, the associator comprises two key\nmodules: basic information interaction (BII) for comprehensive semantic\ninteraction, and content-position alignment (CPA) for semantic and positional\nconsistency. TBDQ-Net's effectiveness is extensively demonstrated on\nDanceTrack, SportsMOT and MOT20 benchmarks. As a structurally efficient and\nsemantically robust tracking framework, it outperforms the leading TBD method\nby 6.0 IDF1 points on DanceTrack and achieves at least 37.5% faster inference\nthan prominent TBQ methods.", "AI": {"tldr": "TBDQ-Net combines tracking-by-detection (TBD) and tracking-by-query (TBQ) paradigms for efficient and robust multi-object tracking, outperforming TBD and TBQ methods in speed and accuracy.", "motivation": "Address the limitations of TBD (fragmented association, heuristic pipelines) and TBQ (high training cost, slow inference) by unifying their strengths.", "method": "Proposes TBDQ-Net, integrating pretrained detectors with a lightweight, learnable associator featuring BII and CPA modules for semantic and positional consistency.", "result": "Outperforms TBD by 6.0 IDF1 points on DanceTrack and is 37.5% faster than TBQ methods.", "conclusion": "TBDQ-Net is an efficient, robust framework that unifies TBD and TBQ strengths, validated on benchmarks like DanceTrack and MOT20."}}
{"id": "2506.20960", "pdf": "https://arxiv.org/pdf/2506.20960", "abs": "https://arxiv.org/abs/2506.20960", "authors": ["Yiman Zhang", "Ziheng Luo", "Qiangyu Yan", "Wei He", "Borui Jiang", "Xinghao Chen", "Kai Han"], "title": "OmniEval: A Benchmark for Evaluating Omni-modal Models with Visual, Auditory, and Textual Inputs", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In this paper, we introduce OmniEval, a benchmark for evaluating\nomni-modality models like MiniCPM-O 2.6, which encompasses visual, auditory,\nand textual inputs. Compared with existing benchmarks, our OmniEval has several\ndistinctive features: (i) Full-modal collaboration: We design evaluation tasks\nthat highlight the strong coupling between audio and video, requiring models to\neffectively leverage the collaborative perception of all modalities; (ii)\nDiversity of videos: OmniEval includes 810 audio-visual synchronized videos,\n285 Chinese videos and 525 English videos; (iii) Diversity and granularity of\ntasks: OmniEval contains 2617 question-answer pairs, comprising 1412 open-ended\nquestions and 1205 multiple-choice questions. These questions are divided into\n3 major task types and 12 sub-task types to achieve comprehensive evaluation.\nAmong them, we introduce a more granular video localization task named\nGrounding. Then we conduct experiments on OmniEval with several omni-modality\nmodels. We hope that our OmniEval can provide a platform for evaluating the\nability to construct and understand coherence from the context of all\nmodalities. Codes and data could be found at\nhttps://omnieval-benchmark.github.io/.", "AI": {"tldr": "OmniEval is a benchmark for evaluating omni-modality models, featuring full-modal collaboration, diverse videos, and granular tasks.", "motivation": "To address the need for evaluating models that integrate visual, auditory, and textual inputs, providing a comprehensive platform for assessing multimodal coherence.", "method": "OmniEval includes 810 synchronized videos, 2617 QA pairs, and introduces a granular Grounding task. It evaluates models on 3 major task types and 12 sub-task types.", "result": "The benchmark supports comprehensive evaluation of omni-modality models, highlighting their ability to leverage collaborative perception across modalities.", "conclusion": "OmniEval serves as a valuable tool for assessing multimodal model performance and understanding coherence across modalities."}}
{"id": "2506.18744", "pdf": "https://arxiv.org/pdf/2506.18744", "abs": "https://arxiv.org/abs/2506.18744", "authors": ["Qing Feng", "Samuel Daulton", "Benjamin Letham", "Maximilian Balandat", "Eytan Bakshy"], "title": "Experimenting, Fast and Slow: Bayesian Optimization of Long-term Outcomes with Online Experiments", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Online experiments in internet systems, also known as A/B tests, are used for\na wide range of system tuning problems, such as optimizing recommender system\nranking policies and learning adaptive streaming controllers. Decision-makers\ngenerally wish to optimize for long-term treatment effects of the system\nchanges, which often requires running experiments for a long time as short-term\nmeasurements can be misleading due to non-stationarity in treatment effects\nover time. The sequential experimentation strategies--which typically involve\nseveral iterations--can be prohibitively long in such cases. We describe a\nnovel approach that combines fast experiments (e.g., biased experiments run\nonly for a few hours or days) and/or offline proxies (e.g., off-policy\nevaluation) with long-running, slow experiments to perform sequential, Bayesian\noptimization over large action spaces in a short amount of time.", "AI": {"tldr": "A novel approach combines fast experiments and offline proxies with slow experiments for efficient Bayesian optimization in large action spaces.", "motivation": "Optimizing long-term treatment effects in online experiments (A/B tests) is challenging due to non-stationarity and lengthy sequential experimentation.", "method": "Combines fast experiments (biased, short-term) and offline proxies (e.g., off-policy evaluation) with slow experiments for sequential Bayesian optimization.", "result": "Enables efficient optimization over large action spaces in shorter timeframes.", "conclusion": "The approach addresses the inefficiency of traditional sequential experimentation by integrating fast and slow methods."}}
{"id": "2411.08482", "pdf": "https://arxiv.org/pdf/2411.08482", "abs": "https://arxiv.org/abs/2411.08482", "authors": ["Anton Kuznietsov", "Dirk Schweickard", "Steven Peters"], "title": "Methodology for an Analysis of Influencing Factors on 3D Object Detection Performance", "categories": ["cs.CV", "cs.LG"], "comment": "IEEE International Conference on Autonomous and Trusted Computing\n  (IEEE ATC), 2025", "summary": "In automated driving, object detection is crucial for perceiving the\nenvironment. Although deep learning-based detectors offer high performance,\ntheir black-box nature complicates safety assurance. We propose a novel\nmethodology to analyze how object- and environment-related factors affect\nLiDAR- and camera-based 3D object detectors. A statistical univariate analysis\nrelates each factor to pedestrian detection errors. Additionally, a Random\nForest (RF) model predicts errors from meta-information, with Shapley Values\ninterpreting feature importance. By capturing feature dependencies, the RF\nenables a nuanced analysis of detection errors. Understanding these factors\nreveals detector performance gaps and supports safer object detection system\ndevelopment.", "AI": {"tldr": "A novel method analyzes factors affecting 3D object detectors in automated driving, using statistical and Random Forest models to improve safety.", "motivation": "Deep learning-based detectors lack transparency, complicating safety assurance in automated driving.", "method": "Combines univariate statistical analysis with Random Forest and Shapley Values to study detection errors.", "result": "Identifies key factors influencing pedestrian detection errors, enabling nuanced performance analysis.", "conclusion": "The approach helps uncover performance gaps and supports safer object detection system development."}}
{"id": "2506.21599", "pdf": "https://arxiv.org/pdf/2506.21599", "abs": "https://arxiv.org/abs/2506.21599", "authors": ["Peibo Li", "Shuang Ao", "Hao Xue", "Yang Song", "Maarten de Rijke", "Johan Barth\u00e9lemy", "Tomasz Bednarz", "Flora D. Salim"], "title": "Refine-POI: Reinforcement Fine-Tuned Large Language Models for Next Point-of-Interest Recommendation", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) have been adopted for next point-of-interest\n(POI) recommendation tasks. Typical LLM-based recommenders fall into two\ncategories: prompt-based and supervised fine-tuning (SFT)-based models.\nPrompt-based models generally offer greater output flexibility but deliver\nlower accuracy, whereas SFT-based models achieve higher performance yet face a\nfundamental mismatch: next POI recommendation data does not naturally suit\nsupervised fine-tuning. In SFT, the model is trained to reproduce the exact\nground truth, but each training example provides only a single target POI, so\nthere is no ground truth for producing a top-k list.\n  To address this, we propose Refine-POI, a reinforcement fine-tuning framework\nfor next POI recommendation. We introduce recommendation-driven rewards that\nenable LLMs to learn to generate top-k recommendation lists using only one\nground-truth POI per example. Experiments on real-world datasets demonstrate\nthat Refine-POI achieves state-of-the-art top-k recommendation performance.", "AI": {"tldr": "Refine-POI is a reinforcement fine-tuning framework for next POI recommendation, addressing the mismatch in SFT-based models by using recommendation-driven rewards to generate top-k lists with single ground-truth POIs.", "motivation": "The mismatch between next POI recommendation data and supervised fine-tuning (SFT) methods, where SFT requires exact ground truth but only single POIs are provided.", "method": "Proposes Refine-POI, a reinforcement fine-tuning framework with recommendation-driven rewards to train LLMs for top-k recommendations using single ground-truth POIs.", "result": "Refine-POI achieves state-of-the-art top-k recommendation performance on real-world datasets.", "conclusion": "Refine-POI effectively bridges the gap in SFT-based models for next POI recommendation, improving flexibility and accuracy."}}
{"id": "2506.19598", "pdf": "https://arxiv.org/pdf/2506.19598", "abs": "https://arxiv.org/abs/2506.19598", "authors": ["Alan N. Amin", "Andres Potapczynski", "Andrew Gordon Wilson"], "title": "Training Flexible Models of Genetic Variant Effects from Functional Annotations using Accelerated Linear Algebra", "categories": ["cs.LG", "q-bio.PE"], "comment": "For example: ICML 2025. Code available at:\n  https://github.com/AlanNawzadAmin/DeepWAS", "summary": "To understand how genetic variants in human genomes manifest in phenotypes --\ntraits like height or diseases like asthma -- geneticists have sequenced and\nmeasured hundreds of thousands of individuals. Geneticists use this data to\nbuild models that predict how a genetic variant impacts phenotype given genomic\nfeatures of the variant, like DNA accessibility or the presence of nearby\nDNA-bound proteins. As more data and features become available, one might\nexpect predictive models to improve. Unfortunately, training these models is\nbottlenecked by the need to solve expensive linear algebra problems because\nvariants in the genome are correlated with nearby variants, requiring inversion\nof large matrices. Previous methods have therefore been restricted to fitting\nsmall models, and fitting simplified summary statistics, rather than the full\nlikelihood of the statistical model. In this paper, we leverage modern fast\nlinear algebra techniques to develop DeepWAS (Deep genome Wide Association\nStudies), a method to train large and flexible neural network predictive models\nto optimize likelihood. Notably, we find that larger models only improve\nperformance when using our full likelihood approach; when trained by fitting\ntraditional summary statistics, larger models perform no better than small\nones. We find larger models trained on more features make better predictions,\npotentially improving disease predictions and therapeutic target\nidentification.", "AI": {"tldr": "DeepWAS uses fast linear algebra to train large neural networks for genome-wide association studies, improving predictions by optimizing likelihood, unlike traditional methods limited by summary statistics.", "motivation": "Geneticists face bottlenecks in predicting phenotypes due to expensive linear algebra problems and reliance on simplified summary statistics, limiting model performance.", "method": "DeepWAS leverages modern fast linear algebra techniques to train large neural networks, optimizing the full likelihood of the statistical model.", "result": "Larger models improve performance only with full likelihood training, not with traditional summary statistics, enabling better disease predictions and therapeutic target identification.", "conclusion": "DeepWAS demonstrates the potential of large, flexible models in genomics when trained with full likelihood, overcoming limitations of traditional methods."}}
{"id": "2411.14565", "pdf": "https://arxiv.org/pdf/2411.14565", "abs": "https://arxiv.org/abs/2411.14565", "authors": ["Yang Liu", "Siao Liu", "Xiaoguang Zhu", "Jielin Li", "Hao Yang", "Liangyu Teng", "Juncen Guo", "Yan Wang", "Dingkang Yang", "Jing Liu"], "title": "Privacy-Preserving Video Anomaly Detection: A Survey", "categories": ["cs.CV", "cs.CR", "cs.LG"], "comment": "22 pages, 9 figures, 7 tables", "summary": "Video Anomaly Detection (VAD) aims to automatically analyze spatiotemporal\npatterns in surveillance videos collected from open spaces to detect anomalous\nevents that may cause harm, such as fighting, stealing, and car accidents.\nHowever, vision-based surveillance systems such as closed-circuit television\noften capture personally identifiable information. The lack of transparency and\ninterpretability in video transmission and usage raises public concerns about\nprivacy and ethics, limiting the real-world application of VAD. Recently,\nresearchers have focused on privacy concerns in VAD by conducting systematic\nstudies from various perspectives including data, features, and systems, making\nPrivacy-Preserving Video Anomaly Detection (P2VAD) a hotspot in the AI\ncommunity. However, current research in P2VAD is fragmented, and prior reviews\nhave mostly focused on methods using RGB sequences, overlooking privacy leakage\nand appearance bias considerations. To address this gap, this article is the\nfirst to systematically reviews the progress of P2VAD, defining its scope and\nproviding an intuitive taxonomy. We outline the basic assumptions, learning\nframeworks, and optimization objectives of various approaches, analyzing their\nstrengths, weaknesses, and potential correlations. Additionally, we provide\nopen access to research resources such as benchmark datasets and available\ncode. Finally, we discuss key challenges and future opportunities from the\nperspectives of AI development and P2VAD deployment, aiming to guide future\nwork in the field.", "AI": {"tldr": "This paper reviews Privacy-Preserving Video Anomaly Detection (P2VAD), addressing gaps in current research by providing a systematic taxonomy, analyzing methods, and discussing challenges and future opportunities.", "motivation": "The lack of transparency and privacy concerns in Video Anomaly Detection (VAD) limits its real-world application, prompting the need for systematic research in P2VAD.", "method": "The article systematically reviews P2VAD, defining its scope, providing a taxonomy, and analyzing learning frameworks and optimization objectives.", "result": "The review highlights strengths, weaknesses, and correlations in P2VAD methods, while offering open-access resources like datasets and code.", "conclusion": "The paper identifies key challenges and future opportunities in P2VAD, aiming to guide further research and deployment."}}
{"id": "2506.22200", "pdf": "https://arxiv.org/pdf/2506.22200", "abs": "https://arxiv.org/abs/2506.22200", "authors": ["Chen Wang", "Lai Wei", "Yanzhi Zhang", "Chenyang Shao", "Zedong Dan", "Weiran Huang", "Yue Wang", "Yuzhi Zhang"], "title": "EFRame: Deeper Reasoning via Exploration-Filter-Replay Reinforcement Learning Framework", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advances in reinforcement learning (RL) have significantly enhanced\nthe reasoning capabilities of large language models (LLMs). Group Relative\nPolicy Optimization (GRPO), an efficient variant of PPO that lowers RL's\ncomputational cost, still faces limited exploration, low sample efficiency and\ninstability, constraining its performance on complex reasoning tasks. To\naddress these limitations, we introduce EFRame, an Exploration-Filtering-Replay\nframework that systematically augments GRPO along three critical dimensions.\nEFRame performs additional rollouts to explore high-quality trajectories,\napplies online filtering to eliminate low-quality samples that introduce noise\nand variance, and leverages experience replay to repeatedly exploit rare but\ninformative samples. EFRame establishes a complete and stable learning cycle,\nguiding the model through a structured transition from exploration to\nconvergence. Our experiments across a variety of reasoning benchmarks\ndemonstrate that EFRame not only improves the robustness and efficiency of\ntraining, but also enables access to deeper reasoning capabilities that remain\nunattainable under vanilla GRPO. Furthermore, EFRame enables a more\nfine-grained categorization of training samples, allowing for a deeper analysis\nof how different types of samples contribute to the learning process in RL. Our\ncode is available at https://github.com/597358816/EFRame.", "AI": {"tldr": "EFRame enhances GRPO by adding exploration, filtering low-quality samples, and using replay, improving robustness and reasoning in RL.", "motivation": "GRPO's limitations in exploration, sample efficiency, and stability hinder performance in complex reasoning tasks.", "method": "EFRame introduces additional rollouts, online filtering, and experience replay to augment GRPO.", "result": "EFRame improves training robustness, efficiency, and unlocks deeper reasoning capabilities.", "conclusion": "EFRame provides a structured learning cycle and better sample analysis, outperforming vanilla GRPO."}}
{"id": "2506.21387", "pdf": "https://arxiv.org/pdf/2506.21387", "abs": "https://arxiv.org/abs/2506.21387", "authors": ["Jaris K\u00fcken", "Lennart Purucker", "Frank Hutter"], "title": "Early Stopping Tabular In-Context Learning", "categories": ["cs.LG"], "comment": "ICML Workshop Paper", "summary": "Tabular foundation models have shown strong performance across various\ntabular learning tasks via in-context learning, offering robust generalization\nwithout any downstream finetuning. However, their inference-time costs remain\nhigh, particularly for larger datasets. To address this, we propose\nearly-stopping the in-context learning process. We achieve this by dynamically\nevaluating whether to stop in-context learning after each Transformer encoder\nlayer. Once stopped, we decode the embedding using a pre-trained layer-wise\ndecoder. Experiments across 34 small classification tasks size show that early\nstopping in-context learning accelerates inference by up to x1.3 with\nnegligible degradation in predictive performance. To assess scalability, we\nfurther evaluate our method on five larger classification tasks, achieving\nspeedups of up to x2.2. Our results demonstrate the potential of early exiting\nas an effective and practical strategy for improving the efficiency of tabular\nin-context learning.", "AI": {"tldr": "Early-stopping in-context learning for tabular foundation models accelerates inference by up to 2.2x with minimal performance loss.", "motivation": "High inference-time costs of tabular foundation models, especially for larger datasets, necessitate efficiency improvements.", "method": "Dynamically evaluate stopping in-context learning after each Transformer encoder layer, then decode embeddings with a pre-trained layer-wise decoder.", "result": "Speedups of 1.3x on small tasks and 2.2x on larger tasks with negligible performance degradation.", "conclusion": "Early exiting is a practical strategy for enhancing tabular in-context learning efficiency."}}
{"id": "2411.15397", "pdf": "https://arxiv.org/pdf/2411.15397", "abs": "https://arxiv.org/abs/2411.15397", "authors": ["Leonidas Gee", "Wing Yan Li", "Viktoriia Sharmanska", "Novi Quadrianto"], "title": "Efficient Online Inference of Vision Transformers by Training-Free Tokenization", "categories": ["cs.CV"], "comment": null, "summary": "The cost of deploying vision transformers increasingly represents a barrier\nto wider industrial adoption. Existing compression techniques require\nadditional end-to-end fine-tuning or incur a significant drawback to runtime,\nmaking them ill-suited for online (real-time) inference, where a prediction is\nmade on any new input as it comes in. We introduce the $\\textbf{Visual Word\nTokenizer}$ (VWT), a training-free method for reducing power costs while\nretaining performance and runtime. The VWT groups visual subwords (image\npatches) that are frequently used into visual words while infrequent ones\nremain intact. To do so, $\\textit{intra}$-image or $\\textit{inter}$-image\nstatistics are leveraged to identify similar visual concepts for sequence\ncompression. Experimentally, we demonstrate a reduction in wattage of up to 25%\nwith only a 20% increase in runtime at most. Comparative approaches of 8-bit\nquantization and token merging achieve a lower or similar power efficiency but\nexact a higher toll on runtime (up to 100% or more). Our results indicate that\nVWTs are well-suited for efficient online inference with a marginal compromise\non performance.", "AI": {"tldr": "The paper introduces Visual Word Tokenizer (VWT), a training-free method to reduce power costs in vision transformers while maintaining performance and runtime, suitable for online inference.", "motivation": "High deployment costs of vision transformers hinder industrial adoption; existing compression methods are unsuitable for real-time inference due to additional fine-tuning or runtime drawbacks.", "method": "VWT groups frequent visual subwords (image patches) into visual words, using intra- or inter-image statistics for sequence compression without training.", "result": "VWT reduces wattage by up to 25% with only a 20% runtime increase, outperforming 8-bit quantization and token merging in power efficiency and runtime.", "conclusion": "VWT is effective for efficient online inference with minimal performance compromise."}}
{"id": "2301.07876", "pdf": "https://arxiv.org/pdf/2301.07876", "abs": "https://arxiv.org/abs/2301.07876", "authors": ["Shengling Shi", "Anastasios Tsiamis", "Bart De Schutter"], "title": "Suboptimality analysis of receding horizon quadratic control with unknown linear systems and its applications in learning-based control", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "This work analyzes how the trade-off between the modeling error, the terminal\nvalue function error, and the prediction horizon affects the performance of a\nnominal receding-horizon linear quadratic (LQ) controller. By developing a\nnovel perturbation result of the Riccati difference equation, a novel\nperformance upper bound is obtained and suggests that for many cases, the\nprediction horizon can be either one or infinity to improve the control\nperformance, depending on the relative difference between the modeling error\nand the terminal value function error. The result also shows that when an\ninfinite horizon is desired, a finite prediction horizon that is larger than\nthe controllability index can be sufficient for achieving a near-optimal\nperformance, revealing a close relation between the prediction horizon and\ncontrollability. The obtained suboptimality performance upper bound is applied\nto provide novel sample complexity and regret guarantees for nominal\nreceding-horizon LQ controllers in a learning-based setting. We show that an\nadaptive prediction horizon that increases as a logarithmic function of time is\nbeneficial for regret minimization.", "AI": {"tldr": "The paper examines how modeling error, terminal value function error, and prediction horizon impact receding-horizon LQ control performance. It introduces a perturbation result for the Riccati equation, suggesting optimal horizons of one or infinity, and links controllability to horizon length. Applications include learning-based control with adaptive horizons for regret minimization.", "motivation": "To understand the interplay between modeling error, terminal value function error, and prediction horizon in receding-horizon LQ control, and to derive performance bounds and practical insights for control design.", "method": "Develops a perturbation result for the Riccati difference equation to derive a performance upper bound, analyzing the impact of prediction horizon and controllability.", "result": "For many cases, the optimal prediction horizon is either one or infinity, and a finite horizon exceeding the controllability index can achieve near-optimal performance. Adaptive horizons improve regret minimization.", "conclusion": "The study provides theoretical and practical guidelines for selecting prediction horizons in receding-horizon LQ control, with implications for learning-based control systems."}}
{"id": "2411.18066", "pdf": "https://arxiv.org/pdf/2411.18066", "abs": "https://arxiv.org/abs/2411.18066", "authors": ["Jiaxiong Qiu", "Liu Liu", "Xinjie Wang", "Tianwei Lin", "Wei Sui", "Zhizhong Su"], "title": "GLS: Geometry-aware 3D Language Gaussian Splatting", "categories": ["cs.CV"], "comment": "Technical Report", "summary": "Recently, 3D Gaussian Splatting (3DGS) has achieved impressive performance on\nindoor surface reconstruction and 3D open-vocabulary segmentation. This paper\npresents GLS, a unified framework of 3D surface reconstruction and\nopen-vocabulary segmentation based on 3DGS. GLS extends two fields by improving\ntheir sharpness and smoothness. For indoor surface reconstruction, we introduce\nsurface normal prior as a geometric cue to guide the rendered normal, and use\nthe normal error to optimize the rendered depth. For 3D open-vocabulary\nsegmentation, we employ 2D CLIP features to guide instance features and enhance\nthe surface smoothness, then utilize DEVA masks to maintain their view\nconsistency. Extensive experiments demonstrate the effectiveness of jointly\noptimizing surface reconstruction and 3D open-vocabulary segmentation, where\nGLS surpasses state-of-the-art approaches of each task on MuSHRoom, ScanNet++\nand LERF-OVS datasets. Project webpage:\nhttps://jiaxiongq.github.io/GLS_ProjectPage.", "AI": {"tldr": "GLS is a unified framework for 3D surface reconstruction and open-vocabulary segmentation using 3D Gaussian Splatting, improving sharpness and smoothness.", "motivation": "To enhance performance in 3D surface reconstruction and open-vocabulary segmentation by leveraging geometric cues and CLIP features.", "method": "Uses surface normal prior for reconstruction and 2D CLIP features for segmentation, optimizing depth and view consistency.", "result": "GLS outperforms state-of-the-art methods on MuSHRoom, ScanNet++, and LERF-OVS datasets.", "conclusion": "Joint optimization of reconstruction and segmentation improves results, demonstrating GLS's effectiveness."}}
{"id": "2304.05005", "pdf": "https://arxiv.org/pdf/2304.05005", "abs": "https://arxiv.org/abs/2304.05005", "authors": ["Kaito Fujii"], "title": "Bayes correlated equilibria, no-regret dynamics in Bayesian games, and the price of anarchy", "categories": ["cs.GT", "cs.LG"], "comment": "Previous title: Bayes correlated equilibria and no-regret dynamics", "summary": "This paper investigates equilibrium computation and the price of anarchy for\nBayesian games, which are the fundamental models of games with incomplete\ninformation. In normal-form games with complete information, it is known that\nefficiently computable no-regret dynamics converge to correlated equilibria,\nand the price of anarchy for correlated equilibria can be bounded for a broad\nclass of games called smooth games. However, in Bayesian games, as surveyed by\nForges (1993), several non-equivalent extensions of correlated equilibria\nexist, and it remains unclear whether they can be efficiently computed or\nwhether their price of anarchy can be bounded.\n  In this paper, we identify a natural extension of correlated equilibria that\ncan be computed efficiently and is guaranteed to have bounds on the price of\nanarchy in various games. First, we propose a variant of regret called\nuntruthful swap regret. If each player minimizes it in repeated play of\nBayesian games, the empirical distribution of these dynamics is guaranteed to\nconverge to communication equilibria, which is one of the extensions of\ncorrelated equilibria proposed by Myerson (1982). We present an efficient\nalgorithm for minimizing untruthful swap regret with a sublinear upper bound,\nwhich we prove to be tight in terms of the number of types. As a result, by\nsimulating the dynamics with our algorithm, we can approximately compute a\ncommunication equilibrium in polynomial time. Furthermore, we extend existing\nlower bounds on the price of anarchy based on the smoothness arguments from\nBayes--Nash equilibria to equilibria obtained by the proposed dynamics.", "AI": {"tldr": "The paper explores efficient computation and price of anarchy bounds for Bayesian games, introducing untruthful swap regret to converge to communication equilibria.", "motivation": "To address the lack of clarity in computing correlated equilibria and bounding price of anarchy in Bayesian games.", "method": "Proposes untruthful swap regret, an efficient algorithm for minimizing it, and extends smoothness arguments to Bayesian games.", "result": "Efficient computation of communication equilibria and bounds on price of anarchy for Bayesian games.", "conclusion": "The study provides a practical approach to equilibrium computation and price of anarchy analysis in Bayesian games."}}
{"id": "2412.00348", "pdf": "https://arxiv.org/pdf/2412.00348", "abs": "https://arxiv.org/abs/2412.00348", "authors": ["Wei Zhou", "Li Yang", "Lei Zhao", "Runyu Zhang", "Yifan Cui", "Hongpu Huang", "Kun Qie", "Chen Wang"], "title": "Vision Technologies with Applications in Traffic Surveillance Systems: A Holistic Survey", "categories": ["cs.CV"], "comment": null, "summary": "Traffic Surveillance Systems (TSS) have become increasingly crucial in modern\nintelligent transportation systems, with vision technologies playing a central\nrole for scene perception and understanding. While existing surveys typically\nfocus on isolated aspects of TSS, a comprehensive analytical framework bridging\nlow-level and high-level perception tasks, particularly considering emerging\ntechnologies, remains lacking. This paper presents a systematic review of\nvision technologies in TSS, examining both low-level perception tasks (object\ndetection, classification, and tracking) and high-level perception tasks\n(parameter estimation, anomaly detection, and behavior understanding).\nSpecifically, we first provide a detailed methodological categorization and\ncomprehensive performance evaluation for each task. Our investigation reveals\nfive fundamental limitations in current TSS: perceptual data degradation in\ncomplex scenarios, data-driven learning constraints, semantic understanding\ngaps, sensing coverage limitations and computational resource demands. To\naddress these challenges, we systematically analyze five categories of current\napproaches and potential trends: advanced perception enhancement, efficient\nlearning paradigms, knowledge-enhanced understanding, cooperative sensing\nframeworks and efficient computing frameworks, critically assessing their\nreal-world applicability. Furthermore, we evaluate the transformative potential\nof foundation models in TSS, which exhibit remarkable zero-shot learning\nabilities, strong generalization, and sophisticated reasoning capabilities\nacross diverse tasks. This review provides a unified analytical framework\nbridging low-level and high-level perception tasks, systematically analyzes\ncurrent limitations and solutions, and presents a structured roadmap for\nintegrating emerging technologies, particularly foundation models, to enhance\nTSS capabilities.", "AI": {"tldr": "This paper reviews vision technologies in Traffic Surveillance Systems (TSS), covering low-level and high-level perception tasks, identifies current limitations, and proposes solutions and trends, including foundation models.", "motivation": "To bridge the gap in comprehensive reviews of TSS by integrating low-level and high-level perception tasks and addressing emerging technologies.", "method": "Systematic review of vision technologies in TSS, categorizing methods, evaluating performance, and analyzing limitations and solutions.", "result": "Identifies five key limitations in TSS and proposes five categories of solutions, highlighting the potential of foundation models.", "conclusion": "Provides a unified framework for TSS, offering a roadmap for integrating emerging technologies to enhance system capabilities."}}
{"id": "2305.10442", "pdf": "https://arxiv.org/pdf/2305.10442", "abs": "https://arxiv.org/abs/2305.10442", "authors": ["Abhinav Sagar", "Sai Teja Gilukara"], "title": "CBAGAN-RRT: Convolutional Block Attention Generative Adversarial Network for Sampling-Based Path Planning", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": null, "summary": "Sampling-based path planning algorithms play an important role in autonomous\nrobotics. However, a common problem among the RRT-based algorithms is that the\ninitial path generated is not optimal, and the convergence is too slow for\nreal-world applications. In this paper, we propose a novel image-based learning\nalgorithm using a Convolutional Block Attention Generative Adversarial Network\n(CBAGAN-RRT) with a combination of spatial and channel attention and a novel\nloss function to design the heuristics, find a better optimal path, and improve\nthe convergence of the algorithm, both concerning time and speed. The\nprobability distribution of the paths generated from our GAN model is used to\nguide the sampling process for the RRT algorithm. We demonstrate that our\nalgorithm outperforms the previous state-of-the-art algorithms using both the\nimage quality generation metrics, like IOU Score, Dice Score, FID score, and\npath planning metrics like time cost and the number of nodes. Ablation studies\nshow the effectiveness of various components in our network architecture. The\nadvantage of our approach is that we can avoid the complicated preprocessing in\nthe state space, our model can be generalized to complex environments like\nthose containing turns and narrow passages without loss of accuracy, and our\nmodel can be easily integrated with other sampling-based path planning\nalgorithms.", "AI": {"tldr": "A novel CBAGAN-RRT algorithm combines spatial and channel attention with a new loss function to improve path planning in robotics, outperforming state-of-the-art methods in speed and accuracy.", "motivation": "RRT-based algorithms often produce suboptimal initial paths and slow convergence, limiting real-world applicability.", "method": "Uses a Convolutional Block Attention GAN (CBAGAN-RRT) with spatial/channel attention and a novel loss function to guide RRT sampling via path probability distributions.", "result": "Outperforms existing methods in image quality (IOU, Dice, FID scores) and path planning metrics (time, nodes). Generalizes well to complex environments.", "conclusion": "CBAGAN-RRT avoids complex preprocessing, generalizes to challenging environments, and integrates easily with other sampling-based algorithms."}}
{"id": "2412.09442", "pdf": "https://arxiv.org/pdf/2412.09442", "abs": "https://arxiv.org/abs/2412.09442", "authors": ["Zheng Li", "Yibing Song", "Ming-Ming Cheng", "Xiang Li", "Jian Yang"], "title": "Advancing Textual Prompt Learning with Anchored Attributes", "categories": ["cs.CV"], "comment": "ICCV 2025. Project Page: https://zhengli97.github.io/ATPrompt/", "summary": "Textual-based prompt learning methods primarily employ multiple learnable\nsoft prompts and hard class tokens in a cascading manner as text inputs, aiming\nto align image and text (category) spaces for downstream tasks. However,\ncurrent training is restricted to aligning images with predefined known\ncategories and cannot be associated with unknown categories. In this work, we\npropose utilizing universal attributes as a bridge to enhance the alignment\nbetween images and unknown categories. Specifically, we introduce an\nAttribute-anchored Textual Prompt learning method for vision-language models,\nnamed ATPrompt. This approach expands the learning space of soft prompts from\nthe original one-dimensional category level into the multi-dimensional\nattribute level by incorporating multiple attribute tokens into the learnable\nsoft prompts. Through this modification, we transform the text prompt from a\ncategory-centric form to an attribute-category hybrid form. Additionally, we\nintroduce a straightforward differentiable attribute search method to identify\nrepresentative and suitable attributes for downstream tasks. As an easy-to-use\nplug-in technique, ATPrompt can seamlessly replace the existing basic prompt\nformat in textual-based methods, providing general improvements at a negligible\ncomputational cost. Extensive experiments across 11 datasets validate the\neffectiveness of our method.", "AI": {"tldr": "ATPrompt enhances vision-language models by using universal attributes to align images with unknown categories, improving alignment through attribute-category hybrid prompts.", "motivation": "Current prompt learning methods fail to align images with unknown categories, limiting their applicability.", "method": "ATPrompt introduces attribute-anchored textual prompts, expanding soft prompts to multi-dimensional attribute levels and using a differentiable attribute search.", "result": "Experiments on 11 datasets confirm ATPrompt's effectiveness as a plug-in technique.", "conclusion": "ATPrompt improves alignment between images and unknown categories with minimal computational cost."}}
{"id": "2309.04355", "pdf": "https://arxiv.org/pdf/2309.04355", "abs": "https://arxiv.org/abs/2309.04355", "authors": ["Skyler Ruiter", "Seth Wolfgang", "Marc Tunnell", "Timothy Triche Jr.", "Erin Carrier", "Zachary DeBruine"], "title": "Value-Compressed Sparse Column (VCSC): Sparse Matrix Storage for Redundant Data", "categories": ["cs.DS", "cs.LG"], "comment": null, "summary": "Compressed Sparse Column (CSC) and Coordinate (COO) are popular compression\nformats for sparse matrices. However, both CSC and COO are general purpose and\ncannot take advantage of any of the properties of the data other than sparsity,\nsuch as data redundancy. Highly redundant sparse data is common in many machine\nlearning applications, such as genomics, and is often too large for in-core\ncomputation using conventional sparse storage formats. In this paper, we\npresent two extensions to CSC: (1) Value-Compressed Sparse Column (VCSC) and\n(2) Index- and Value-Compressed Sparse Column (IVCSC). VCSC takes advantage of\nhigh redundancy within a column to further compress data up to 3-fold over COO\nand 2.25-fold over CSC, without significant negative impact to performance\ncharacteristics. IVCSC extends VCSC by compressing index arrays through delta\nencoding and byte-packing, achieving a 10-fold decrease in memory usage over\nCOO and 7.5-fold decrease over CSC. Our benchmarks on simulated and real data\nshow that VCSC and IVCSC can be read in compressed form with little added\ncomputational cost. These two novel compression formats offer a broadly useful\nsolution to encoding and reading redundant sparse data.", "AI": {"tldr": "The paper introduces VCSC and IVCSC, extensions to CSC for compressing redundant sparse data, achieving significant memory savings with minimal performance impact.", "motivation": "Existing formats like CSC and COO don't exploit data redundancy, limiting efficiency for large, redundant datasets common in machine learning.", "method": "VCSC compresses redundant values within columns, while IVCSC adds delta encoding and byte-packing for indices.", "result": "VCSC reduces memory usage by 2.25x over CSC, and IVCSC achieves up to 7.5x reduction, with little computational overhead.", "conclusion": "VCSC and IVCSC provide efficient solutions for handling redundant sparse data, balancing compression and performance."}}
{"id": "2412.10718", "pdf": "https://arxiv.org/pdf/2412.10718", "abs": "https://arxiv.org/abs/2412.10718", "authors": ["Cong Wan", "Xiangyang Luo", "Hao Luo", "Zijian Cai", "Yiren Song", "Yunlong Zhao", "Yifan Bai", "Fan Wang", "Yuhang He", "Yihong Gong"], "title": "Grid: Omni Visual Generation", "categories": ["cs.CV"], "comment": "Codes: https://github.com/Should-AI-Lab/GRID", "summary": "Visual generation has witnessed remarkable progress in single-image tasks,\nyet extending these capabilities to temporal sequences remains challenging.\nCurrent approaches either build specialized video models from scratch with\nenormous computational costs or add separate motion modules to image\ngenerators, both requiring learning temporal dynamics anew. We observe that\nmodern image generation models possess underutilized potential in handling\nstructured layouts with implicit temporal understanding. Building on this\ninsight, we introduce GRID, which reformulates temporal sequences as grid\nlayouts, enabling holistic processing of visual sequences while leveraging\nexisting model capabilities. Through a parallel flow-matching training strategy\nwith coarse-to-fine scheduling, our approach achieves up to 67 faster inference\nspeeds while using <1/1000 of the computational resources compared to\nspecialized models. Extensive experiments demonstrate that GRID not only excels\nin temporal tasks from Text-to-Video to 3D Editing but also preserves strong\nperformance in image generation, establishing itself as an efficient and\nversatile omni-solution for visual generation.", "AI": {"tldr": "GRID reformulates temporal sequences as grid layouts to leverage existing image generation models, achieving faster inference and lower computational costs compared to specialized video models.", "motivation": "Current methods for temporal visual generation are either computationally expensive or require learning temporal dynamics from scratch. GRID aims to utilize the underused potential of image models for temporal tasks.", "method": "GRID transforms temporal sequences into grid layouts, enabling holistic processing. It uses a parallel flow-matching training strategy with coarse-to-fine scheduling.", "result": "GRID achieves up to 67x faster inference speeds and uses <1/1000 of the computational resources of specialized models while excelling in tasks like Text-to-Video and 3D Editing.", "conclusion": "GRID is an efficient and versatile solution for visual generation, bridging the gap between image and temporal tasks without sacrificing performance."}}
{"id": "2405.00592", "pdf": "https://arxiv.org/pdf/2405.00592", "abs": "https://arxiv.org/abs/2405.00592", "authors": ["Alexander Atanasov", "Jacob A. Zavatone-Veth", "Cengiz Pehlevan"], "title": "Scaling and renormalization in high-dimensional regression", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.LG"], "comment": "74 pages, 17 figures", "summary": "From benign overfitting in overparameterized models to rich power-law\nscalings in performance, simple ridge regression displays surprising behaviors\nsometimes thought to be limited to deep neural networks. This balance of\nphenomenological richness with analytical tractability makes ridge regression\nthe model system of choice in high-dimensional machine learning. In this paper,\nwe present a unifying perspective on recent results on ridge regression using\nthe basic tools of random matrix theory and free probability, aimed at readers\nwith backgrounds in physics and deep learning. We highlight the fact that\nstatistical fluctuations in empirical covariance matrices can be absorbed into\na renormalization of the ridge parameter. This `deterministic equivalence'\nallows us to obtain analytic formulas for the training and generalization\nerrors in a few lines of algebra by leveraging the properties of the\n$S$-transform of free probability. From these precise asymptotics, we can\neasily identify sources of power-law scaling in model performance. In all\nmodels, the $S$-transform corresponds to the train-test generalization gap, and\nyields an analogue of the generalized-cross-validation estimator. Using these\ntechniques, we derive fine-grained bias-variance decompositions for a very\ngeneral class of random feature models with structured covariates. This allows\nus to discover a scaling regime for random feature models where the variance\ndue to the features limits performance in the overparameterized setting. We\nalso demonstrate how anisotropic weight structure in random feature models can\nlimit performance and lead to nontrivial exponents for finite-width corrections\nin the overparameterized setting. Our results extend and provide a unifying\nperspective on earlier models of neural scaling laws.", "AI": {"tldr": "Ridge regression exhibits behaviors like benign overfitting and power-law scaling, similar to deep neural networks. The paper uses random matrix theory and free probability to unify recent results, deriving analytic formulas for errors and identifying scaling laws.", "motivation": "To provide a unifying perspective on ridge regression's surprising behaviors, leveraging its analytical tractability to understand high-dimensional machine learning phenomena.", "method": "Uses random matrix theory and free probability, focusing on the $S$-transform to analyze statistical fluctuations and derive error formulas.", "result": "Derives precise asymptotics for training and generalization errors, identifies power-law scaling sources, and reveals performance-limiting factors in random feature models.", "conclusion": "The framework extends and unifies neural scaling laws, offering insights into overparameterized models and anisotropic weight structures."}}
{"id": "2412.15171", "pdf": "https://arxiv.org/pdf/2412.15171", "abs": "https://arxiv.org/abs/2412.15171", "authors": ["Forrest Iandola", "Stanislav Pidhorskyi", "Igor Santesteban", "Divam Gupta", "Anuj Pahuja", "Nemanja Bartolovic", "Frank Yu", "Emanuel Garbin", "Tomas Simon", "Shunsuke Saito"], "title": "SqueezeMe: Mobile-Ready Distillation of Gaussian Full-Body Avatars", "categories": ["cs.CV"], "comment": "Accepted to SIGGRAPH 2025", "summary": "Gaussian-based human avatars have achieved an unprecedented level of visual\nfidelity. However, existing approaches based on high-capacity neural networks\ntypically require a desktop GPU to achieve real-time performance for a single\navatar, and it remains non-trivial to animate and render such avatars on mobile\ndevices including a standalone VR headset due to substantially limited memory\nand computational bandwidth. In this paper, we present SqueezeMe, a simple and\nhighly effective framework to convert high-fidelity 3D Gaussian full-body\navatars into a lightweight representation that supports both animation and\nrendering with mobile-grade compute. Our key observation is that the decoding\nof pose-dependent Gaussian attributes from a neural network creates\nnon-negligible memory and computational overhead. Inspired by blendshapes and\nlinear pose correctives widely used in Computer Graphics, we address this by\ndistilling the pose correctives learned with neural networks into linear\nlayers. Moreover, we further reduce the parameters by sharing the correctives\namong nearby Gaussians. Combining them with a custom splatting pipeline based\non Vulkan, we achieve, for the first time, simultaneous animation and rendering\nof 3 Gaussian avatars in real-time (72 FPS) on a Meta Quest 3 VR headset. Demo\nvideos are available at https://forresti.github.io/squeezeme.", "AI": {"tldr": "SqueezeMe converts high-fidelity 3D Gaussian avatars into a lightweight form for real-time animation and rendering on mobile devices like VR headsets.", "motivation": "Existing high-fidelity avatar methods require powerful GPUs and struggle with mobile device constraints.", "method": "Distills neural network pose correctives into linear layers and shares parameters among Gaussians, combined with a Vulkan-based splatting pipeline.", "result": "Achieves real-time (72 FPS) animation and rendering of 3 avatars on a Meta Quest 3 VR headset.", "conclusion": "SqueezeMe enables mobile-grade performance for high-fidelity avatars without sacrificing quality."}}
{"id": "2406.06802", "pdf": "https://arxiv.org/pdf/2406.06802", "abs": "https://arxiv.org/abs/2406.06802", "authors": ["Qing Feng", "Tianyi Ma", "Ruihao Zhu"], "title": "Satisficing Regret Minimization in Bandits: Constant Rate and Light-Tailed Distribution", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Motivated by the concept of satisficing in decision-making, we consider the\nproblem of satisficing regret minimization in bandit optimization. In this\nsetting, the learner aims at selecting satisficing arms (arms with mean reward\nexceeding a certain threshold value) as frequently as possible. The performance\nis measured by satisficing regret, which is the cumulative deficit of the\nchosen arm's mean reward compared to the threshold. We propose SELECT, a\ngeneral algorithmic template for Satisficing REgret Minimization via SampLing\nand LowEr Confidence bound Testing, that attains constant expected satisficing\nregret for a wide variety of bandit optimization problems in the realizable\ncase (i.e., a satisficing arm exists). As a complement, SELECT also enjoys the\nsame (standard) regret guarantee as the oracle in the non-realizable case. To\nfurther ensure stability of the algorithm, we introduce SELECT-LITE that\nachieves a light-tailed satisficing regret distribution plus a constant\nexpected satisficing regret in the realizable case and a sub-linear expected\n(standard) regret in the non-realizable case. Notably, SELECT-LITE can operate\non learning oracles with heavy-tailed (standard) regret distribution. More\nimportantly, our results reveal the surprising compatibility between constant\nexpected satisficing regret and light-tailed satisficing regret distribution,\nwhich is in sharp contrast to the case of (standard) regret. Finally, we\nconduct numerical experiments to validate the performance of SELECT and\nSELECT-LITE on both synthetic datasets and a real-world dynamic pricing case\nstudy.", "AI": {"tldr": "The paper introduces SELECT and SELECT-LITE algorithms for satisficing regret minimization in bandit optimization, achieving constant expected regret in realizable cases and compatibility with light-tailed regret distributions.", "motivation": "The study is motivated by the concept of satisficing in decision-making, aiming to frequently select arms with rewards above a threshold.", "method": "Proposes SELECT, a template for satisficing regret minimization, and SELECT-LITE for stability, using sampling and lower confidence bound testing.", "result": "SELECT achieves constant expected satisficing regret in realizable cases, while SELECT-LITE ensures light-tailed regret distribution and sub-linear regret in non-realizable cases.", "conclusion": "The results show compatibility between constant expected satisficing regret and light-tailed regret, validated by experiments on synthetic and real-world data."}}
{"id": "2412.19326", "pdf": "https://arxiv.org/pdf/2412.19326", "abs": "https://arxiv.org/abs/2412.19326", "authors": ["Ziang Yan", "Zhilin Li", "Yinan He", "Chenting Wang", "Kunchang Li", "Xinhao Li", "Xiangyu Zeng", "Zilei Wang", "Yali Wang", "Yu Qiao", "Limin Wang", "Yi Wang"], "title": "Task Preference Optimization: Improving Multimodal Large Language Models with Vision Task Alignment", "categories": ["cs.CV"], "comment": "CVPR2025", "summary": "Current multimodal large language models (MLLMs) struggle with fine-grained\nor precise understanding of visuals although they give comprehensive perception\nand reasoning in a spectrum of vision applications. Recent studies either\ndevelop tool-using or unify specific visual tasks into the autoregressive\nframework, often at the expense of overall multimodal performance. To address\nthis issue and enhance MLLMs with visual tasks in a scalable fashion, we\npropose Task Preference Optimization (TPO), a novel method that utilizes\ndifferentiable task preferences derived from typical fine-grained visual tasks.\nTPO introduces learnable task tokens that establish connections between\nmultiple task-specific heads and the MLLM. By leveraging rich visual labels\nduring training, TPO significantly enhances the MLLM's multimodal capabilities\nand task-specific performance. Through multi-task co-training within TPO, we\nobserve synergistic benefits that elevate individual task performance beyond\nwhat is achievable through single-task training methodologies. Our\ninstantiation of this approach with VideoChat and LLaVA demonstrates an overall\n14.6% improvement in multimodal performance compared to baseline models.\nAdditionally, MLLM-TPO demonstrates robust zero-shot capabilities across\nvarious tasks, performing comparably to state-of-the-art supervised models. The\ncode will be released at https://github.com/OpenGVLab/TPO", "AI": {"tldr": "TPO enhances MLLMs with scalable fine-grained visual understanding using learnable task tokens and multi-task co-training, achieving a 14.6% performance boost.", "motivation": "MLLMs lack fine-grained visual understanding, and existing methods compromise overall performance. TPO aims to address this gap.", "method": "TPO uses differentiable task preferences and learnable task tokens to connect task-specific heads with MLLMs, leveraging rich visual labels.", "result": "14.6% improvement in multimodal performance and robust zero-shot capabilities comparable to supervised models.", "conclusion": "TPO effectively scales MLLMs for fine-grained visual tasks while maintaining overall performance."}}
{"id": "2407.01496", "pdf": "https://arxiv.org/pdf/2407.01496", "abs": "https://arxiv.org/abs/2407.01496", "authors": ["Zhiqiang Cai", "Anastassia Doktorova", "Robert D. Falgout", "C\u00e9sar Herrera"], "title": "Efficient Shallow Ritz Method For 1D Diffusion-Reaction Problems", "categories": ["math.NA", "cs.LG", "cs.NA", "65K10, 65F05"], "comment": null, "summary": "This paper studies the shallow Ritz method for solving one-dimensional\ndiffusion-reaction problems. The method is capable of improving the order of\napproximation for non-smooth problems. By following a similar approach to the\none presented in [9], we present a damped block Newton (dBN) method to achieve\nnearly optimal order of approximation. The dBN method optimizes the Ritz\nfunctional by alternating between the linear and non-linear parameters of the\nshallow ReLU neural network (NN). For diffusion-reaction problems, new\ndifficulties arise: (1) for the linear parameters, the mass matrix is dense and\neven more ill-conditioned than the stiffness matrix, and (2) for the non-linear\nparameters, the Hessian matrix is dense and may be singular. This paper\naddresses these challenges, resulting in a dBN method with computational cost\nof ${\\cal O}(n)$.\n  The ideas presented for diffusion-reaction problems can also be applied to\nleast-squares approximation problems. For both applications, starting with the\nnon-linear parameters as a uniform partition, numerical experiments show that\nthe dBN method moves the mesh points to nearly optimal locations.", "AI": {"tldr": "The paper introduces a damped block Newton (dBN) method for solving one-dimensional diffusion-reaction problems using the shallow Ritz method, achieving nearly optimal approximation order.", "motivation": "To address challenges in non-smooth problems, such as dense and ill-conditioned matrices, and improve approximation efficiency.", "method": "The dBN method alternates between optimizing linear and non-linear parameters of a shallow ReLU neural network, tackling issues with mass and Hessian matrices.", "result": "The method achieves computational efficiency of O(n) and moves mesh points to near-optimal locations in numerical experiments.", "conclusion": "The dBN method effectively solves diffusion-reaction and least-squares problems, demonstrating practical utility and efficiency."}}
{"id": "2412.19628", "pdf": "https://arxiv.org/pdf/2412.19628", "abs": "https://arxiv.org/abs/2412.19628", "authors": ["Mingshu Zhao", "Yi Luo", "Yong Ouyang"], "title": "RecConv: Efficient Recursive Convolutions for Multi-Frequency Representations", "categories": ["cs.CV"], "comment": "Tech report; Added supplementary material;", "summary": "Recent advances in vision transformers (ViTs) have demonstrated the advantage\nof global modeling capabilities, prompting widespread integration of\nlarge-kernel convolutions for enlarging the effective receptive field (ERF).\nHowever, the quadratic scaling of parameter count and computational complexity\n(FLOPs) with respect to kernel size poses significant efficiency and\noptimization challenges. This paper introduces RecConv, a recursive\ndecomposition strategy that efficiently constructs multi-frequency\nrepresentations using small-kernel convolutions. RecConv establishes a linear\nrelationship between parameter growth and decomposing levels which determines\nthe effective receptive field $k\\times 2^\\ell$ for a base kernel $k$ and $\\ell$\nlevels of decomposition, while maintaining constant FLOPs regardless of the ERF\nexpansion. Specifically, RecConv achieves a parameter expansion of only\n$\\ell+2$ times and a maximum FLOPs increase of $5/3$ times, compared to the\nexponential growth ($4^\\ell$) of standard and depthwise convolutions.\nRecNeXt-M3 outperforms RepViT-M1.1 by 1.9 $AP^{box}$ on COCO with similar\nFLOPs. This innovation provides a promising avenue towards designing efficient\nand compact networks across various modalities. Codes and models can be found\nat https://github.com/suous/RecNeXt.", "AI": {"tldr": "RecConv introduces a recursive decomposition strategy using small-kernel convolutions to efficiently expand the effective receptive field without exponential parameter or FLOPs growth.", "motivation": "Address the inefficiency and optimization challenges of large-kernel convolutions in vision transformers due to quadratic scaling of parameters and FLOPs.", "method": "Recursive decomposition strategy (RecConv) constructs multi-frequency representations with small-kernel convolutions, maintaining linear parameter growth and constant FLOPs.", "result": "RecNeXt-M3 outperforms RepViT-M1.1 by 1.9 AP on COCO with similar FLOPs, achieving efficient ERF expansion.", "conclusion": "RecConv offers a scalable and efficient solution for designing compact networks, applicable across various modalities."}}
{"id": "2409.02231", "pdf": "https://arxiv.org/pdf/2409.02231", "abs": "https://arxiv.org/abs/2409.02231", "authors": ["Joseph M. Cavanagh", "Kunyang Sun", "Andrew Gritsevskiy", "Dorian Bagni", "Yingze Wang", "Thomas D. Bannister", "Teresa Head-Gordon"], "title": "SmileyLlama: Modifying Large Language Models for Directed Chemical Space Exploration", "categories": ["physics.chem-ph", "cs.LG"], "comment": null, "summary": "Here we show that a general-purpose large language model (LLM) chatbot,\nLlama-3.1-8B-Instruct, can be transformed via supervised fine-tuning of\nengineered prompts into a chemical language model (CLM), SmileyLlama, for\nmolecule generation. We benchmark SmileyLlama by comparing it to CLMs trained\nfrom scratch on large amounts of ChEMBL data for their ability to generate\nvalid and novel drug-like molecules. We also use direct preference optimization\nto both improve SmileyLlama's adherence to a prompt and to generate molecules\nwithin the iMiner reinforcement learning framework to predict new drug\nmolecules with optimized 3D conformations and high binding affinity to drug\ntargets, illustrated with the SARS-Cov-2 Main Protease. This overall framework\nallows a LLM to speak directly as a CLM which can generate molecules with\nuser-specified properties, rather than acting only as a chatbot with knowledge\nof chemistry or as a helpful virtual assistant. While our dataset and analyses\nare geared toward drug discovery, this general procedure can be extended to\nother chemical applications such as chemical synthesis.", "AI": {"tldr": "Llama-3.1-8B-Instruct LLM is fine-tuned into SmileyLlama, a chemical language model (CLM), for generating drug-like molecules, outperforming CLMs trained from scratch and optimizing properties like binding affinity.", "motivation": "To transform a general-purpose LLM into a specialized CLM for generating molecules with user-specified properties, particularly for drug discovery.", "method": "Supervised fine-tuning of Llama-3.1-8B-Instruct with engineered prompts, benchmarked against CLMs trained on ChEMBL data, and enhanced via direct preference optimization and iMiner reinforcement learning.", "result": "SmileyLlama generates valid, novel drug-like molecules with optimized 3D conformations and high binding affinity, demonstrated with SARS-Cov-2 Main Protease.", "conclusion": "The framework enables LLMs to function as CLMs for molecule generation, extendable beyond drug discovery to other chemical applications."}}
{"id": "2412.20521", "pdf": "https://arxiv.org/pdf/2412.20521", "abs": "https://arxiv.org/abs/2412.20521", "authors": ["Thomas Alessandro Ciarfuglia", "Ionut Marian Motoi", "Leonardo Saraceni", "Daniele Nardi"], "title": "Can Robots \"Taste\" Grapes? Estimating SSC with Simple RGB Sensors", "categories": ["cs.CV", "cs.RO", "J.3; I.5.1; I.2.9; I.2.10"], "comment": null, "summary": "In table grape cultivation, harvesting depends on accurately assessing fruit\nquality. While some characteristics, like color, are visible, others, such as\nSoluble Solid Content (SSC), or sugar content measured in degrees Brix\n({\\deg}Brix), require specific tools. SSC is a key quality factor that\ncorrelates with ripeness, but lacks a direct causal relationship with color.\nHyperspectral cameras can estimate SSC with high accuracy under controlled\nlaboratory conditions, but their practicality in field environments is limited.\nThis study investigates the potential of simple RGB sensors under uncontrolled\nlighting to estimate SSC and color, enabling cost-effective, robot-assisted\nharvesting. Over the 2021 and 2022 summer seasons, we collected grape images\nwith corresponding SSC and color labels to evaluate algorithmic solutions for\nSSC estimation, specifically testing for cross-seasonal and cross-device\nrobustness. We propose two approaches: a computationally efficient\nhistogram-based method for resource-constrained robots and a Deep Neural\nNetwork (DNN) model for more complex applications. Our results demonstrate high\nperformance, with the DNN model achieving a Mean Absolute Error (MAE) as low as\n$1.05$ {\\deg}Brix on a challenging cross-device test set. The lightweight\nhistogram-based method also proved effective, reaching an MAE of $1.46$\n{\\deg}Brix. These results are highly competitive with those from hyperspectral\nsystems, which report errors in the $1.27$--$2.20$ {\\deg}Brix range in similar\nfield applications.", "AI": {"tldr": "The study explores using RGB sensors to estimate Soluble Solid Content (SSC) and color in grapes for cost-effective robotic harvesting, achieving competitive accuracy compared to hyperspectral systems.", "motivation": "Accurate SSC assessment is crucial for grape harvesting, but current hyperspectral methods are impractical for field use. RGB sensors offer a simpler, cost-effective alternative.", "method": "Collected grape images with SSC and color labels over two seasons. Tested two approaches: a histogram-based method for efficiency and a Deep Neural Network (DNN) for accuracy.", "result": "DNN achieved MAE of 1.05\u00b0Brix, while the histogram method reached 1.46\u00b0Brix, comparable to hyperspectral systems (1.27\u20132.20\u00b0Brix).", "conclusion": "RGB sensors are viable for SSC estimation, enabling practical, cost-effective robotic harvesting with performance rivaling hyperspectral methods."}}
{"id": "2410.02979", "pdf": "https://arxiv.org/pdf/2410.02979", "abs": "https://arxiv.org/abs/2410.02979", "authors": ["August Y. Chen", "Karthik Sridharan"], "title": "Optimization, Isoperimetric Inequalities, and Sampling via Lyapunov Potentials", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": "COLT 2025", "summary": "In this paper, we prove that optimizability of any function F using Gradient\nFlow from all initializations implies a Poincar\\'e Inequality for Gibbs\nmeasures mu_{beta} = e^{-beta F}/Z at low temperature. In particular, under\nmild regularity assumptions on the convergence rate of Gradient Flow, we\nestablish that mu_{beta} satisfies a Poincar\\'e Inequality with constant\nO(C'+1/beta) for beta >= Omega(d), where C' is the Poincar\\'e constant of\nmu_{beta} restricted to a neighborhood of the global minimizers of F. Under an\nadditional mild condition on F, we show that mu_{beta} satisfies a Log-Sobolev\nInequality with constant O(beta max(S, 1) max(C', 1)) where S denotes the\nsecond moment of mu_{beta}. Here asymptotic notation hides F-dependent\nparameters. At a high level, this establishes that optimizability via Gradient\nFlow from every initialization implies a Poincar\\'e and Log-Sobolev Inequality\nfor the low-temperature Gibbs measure, which in turn imply sampling from all\ninitializations.\n  Analogously, we establish that under the same assumptions, if F can be\ninitialized from everywhere except some set S, then mu_{beta} satisfies a Weak\nPoincar\\'e Inequality with parameters (O(C'+1/beta), O(mu_{beta}(S))) for \\beta\n= Omega(d). At a high level, this shows while optimizability from 'most'\ninitializations implies a Weak Poincar\\'e Inequality, which in turn implies\nsampling from suitable warm starts. Our regularity assumptions are mild and as\na consequence, we show we can efficiently sample from several new natural and\ninteresting classes of non-log-concave densities, an important setting with\nrelatively few examples. As another corollary, we obtain efficient\ndiscrete-time sampling results for log-concave measures satisfying milder\nregularity conditions than smoothness, similar to Lehec (2023).", "AI": {"tldr": "The paper links optimizability of functions via Gradient Flow to Poincar\u00e9 and Log-Sobolev inequalities for Gibbs measures, enabling efficient sampling from non-log-concave densities.", "motivation": "To connect optimizability of functions using Gradient Flow with inequalities for Gibbs measures, facilitating sampling from complex distributions.", "method": "Proves Poincar\u00e9 and Log-Sobolev inequalities for Gibbs measures under mild regularity assumptions on Gradient Flow convergence.", "result": "Establishes that optimizability implies inequalities, enabling efficient sampling from non-log-concave densities and milder log-concave conditions.", "conclusion": "Optimizability via Gradient Flow ensures inequalities for Gibbs measures, expanding efficient sampling to broader classes of distributions."}}
{"id": "2501.08983", "pdf": "https://arxiv.org/pdf/2501.08983", "abs": "https://arxiv.org/abs/2501.08983", "authors": ["Haozhe Xie", "Zhaoxi Chen", "Fangzhou Hong", "Ziwei Liu"], "title": "Compositional Generative Model of Unbounded 4D Cities", "categories": ["cs.CV"], "comment": "Project Page: https://www.infinitescript.com/project/city-dreamer-4d/", "summary": "3D scene generation has garnered growing attention in recent years and has\nmade significant progress. Generating 4D cities is more challenging than 3D\nscenes due to the presence of structurally complex, visually diverse objects\nlike buildings and vehicles, and heightened human sensitivity to distortions in\nurban environments. To tackle these issues, we propose CityDreamer4D, a\ncompositional generative model specifically tailored for generating unbounded\n4D cities. Our main insights are 1) 4D city generation should separate dynamic\nobjects (e.g., vehicles) from static scenes (e.g., buildings and roads), and 2)\nall objects in the 4D scene should be composed of different types of neural\nfields for buildings, vehicles, and background stuff. Specifically, we propose\nTraffic Scenario Generator and Unbounded Layout Generator to produce dynamic\ntraffic scenarios and static city layouts using a highly compact BEV\nrepresentation. Objects in 4D cities are generated by combining stuff-oriented\nand instance-oriented neural fields for background stuff, buildings, and\nvehicles. To suit the distinct characteristics of background stuff and\ninstances, the neural fields employ customized generative hash grids and\nperiodic positional embeddings as scene parameterizations. Furthermore, we\noffer a comprehensive suite of datasets for city generation, including OSM,\nGoogleEarth, and CityTopia. The OSM dataset provides a variety of real-world\ncity layouts, while the Google Earth and CityTopia datasets deliver\nlarge-scale, high-quality city imagery complete with 3D instance annotations.\nLeveraging its compositional design, CityDreamer4D supports a range of\ndownstream applications, such as instance editing, city stylization, and urban\nsimulation, while delivering state-of-the-art performance in generating\nrealistic 4D cities.", "AI": {"tldr": "CityDreamer4D is a generative model for unbounded 4D city scenes, separating dynamic objects (vehicles) from static scenes (buildings) and using specialized neural fields for each component.", "motivation": "Generating 4D cities is challenging due to complex structures, diverse objects, and human sensitivity to distortions in urban environments.", "method": "Proposes Traffic Scenario Generator and Unbounded Layout Generator, using BEV representation and customized neural fields for buildings, vehicles, and background.", "result": "Achieves state-of-the-art performance in generating realistic 4D cities, supported by datasets like OSM, GoogleEarth, and CityTopia.", "conclusion": "CityDreamer4D enables downstream applications like instance editing and urban simulation, offering a robust solution for 4D city generation."}}
{"id": "2411.05853", "pdf": "https://arxiv.org/pdf/2411.05853", "abs": "https://arxiv.org/abs/2411.05853", "authors": ["Sohail Bahmani"], "title": "A Fundamental Accuracy--Robustness Trade-off in Regression and Classification", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We derive a fundamental trade-off between standard and adversarial risk in a\nrather general situation that formalizes the following simple intuition: \"If no\n(nearly) optimal predictor is smooth, adversarial robustness comes at the cost\nof accuracy.\" As a concrete example, we evaluate the derived trade-off in\nregression with polynomial ridge functions under mild regularity conditions.\nGeneralizing our analysis of this example, we formulate a necessary condition\nunder which adversarial robustness can be achieved without significant\ndegradation of the accuracy. This necessary condition is expressed in terms of\na quantity that resembles the Poincar\\'{e} constant of the data distribution.", "AI": {"tldr": "The paper explores a trade-off between standard and adversarial risk, showing that adversarial robustness often reduces accuracy unless predictors are smooth. It uses polynomial ridge regression as an example and identifies a condition for robustness without accuracy loss, linked to a Poincar\u00e9-like constant.", "motivation": "To formalize the intuition that adversarial robustness typically sacrifices accuracy unless predictors are smooth, and to identify conditions where robustness can coexist with high accuracy.", "method": "The study derives a general trade-off between standard and adversarial risk, evaluates it using polynomial ridge regression under mild conditions, and generalizes the findings to formulate a necessary condition for robustness without accuracy loss.", "result": "A fundamental trade-off between standard and adversarial risk is established, with a concrete example in polynomial ridge regression. A necessary condition for achieving robustness without accuracy degradation is identified, resembling the Poincar\u00e9 constant.", "conclusion": "Adversarial robustness often comes at the cost of accuracy unless predictors are smooth. The derived condition provides a criterion for when robustness can be achieved without significant accuracy loss."}}
{"id": "2501.13349", "pdf": "https://arxiv.org/pdf/2501.13349", "abs": "https://arxiv.org/abs/2501.13349", "authors": ["Haohang Xu", "Longyu Chen", "Yichen Zhang", "Shuangrui Ding", "Zhipeng Zhang"], "title": "MSF: Efficient Diffusion Model Via Multi-Scale Latent Factorize", "categories": ["cs.CV"], "comment": null, "summary": "While diffusion-based generative models have made significant strides in\nvisual content creation, conventional approaches face computational challenges,\nespecially for high-resolution images, as they denoise the entire image from\nnoisy inputs. This contrasts with signal processing techniques, such as Fourier\nand wavelet analyses, which often employ hierarchical decompositions. Inspired\nby such principles, particularly the idea of signal separation, we introduce a\ndiffusion framework leveraging multi-scale latent factorization. Our framework\nuniquely decomposes the denoising target, typically latent features from a\npretrained Variational Autoencoder, into a low-frequency base signal capturing\ncore structural information and a high-frequency residual signal that\ncontributes finer, high-frequency details like textures. This decomposition\ninto base and residual components directly informs our two-stage image\ngeneration process, which first produces the low-resolution base, followed by\nthe generation of the high-resolution residual. Our proposed architecture\nfacilitates reduced sampling steps during the residual learning stage, owing to\nthe inherent ease of modeling residual information, which confers advantages\nover conventional full-resolution generation techniques. This specific approach\nof decomposing the signal into a base and a residual, conceptually akin to how\nwavelet analysis can separate different frequency bands, yields a more\nstreamlined and intuitive design distinct from generic hierarchical models. Our\nmethod, \\name\\ (Multi-Scale Factorization), demonstrates its effectiveness by\nachieving FID scores of 2.08 ($256\\times256$) and 2.47 ($512\\times512$) on\nclass-conditional ImageNet benchmarks, outperforming the DiT baseline (2.27 and\n3.04 respectively) while also delivering a $4\\times$ speed-up with the same\nnumber of sampling steps.", "AI": {"tldr": "The paper introduces a diffusion framework using multi-scale latent factorization to decompose denoising targets into base and residual signals, improving efficiency and performance in high-resolution image generation.", "motivation": "Conventional diffusion models face computational challenges for high-resolution images. The paper aims to address this by leveraging hierarchical signal separation principles.", "method": "The framework decomposes latent features into low-frequency base and high-frequency residual signals, enabling a two-stage generation process (low-resolution base first, then high-resolution residual).", "result": "Achieves FID scores of 2.08 (256x256) and 2.47 (512x512) on ImageNet, outperforming DiT baseline (2.27 and 3.04) with a 4x speed-up.", "conclusion": "The proposed method offers a more efficient and effective approach to high-resolution image generation compared to conventional techniques."}}
{"id": "2501.14607", "pdf": "https://arxiv.org/pdf/2501.14607", "abs": "https://arxiv.org/abs/2501.14607", "authors": ["Tianming Liang", "Kun-Yu Lin", "Chaolei Tan", "Jianguo Zhang", "Wei-Shi Zheng", "Jian-Fang Hu"], "title": "ReferDINO: Referring Video Object Segmentation with Visual Grounding Foundations", "categories": ["cs.CV"], "comment": "Accepted to ICCV 2025. Project page:\n  \\url{https://isee-laboratory.github.io/ReferDINO}", "summary": "Referring video object segmentation (RVOS) aims to segment target objects\nthroughout a video based on a text description. This is challenging as it\ninvolves deep vision-language understanding, pixel-level dense prediction and\nspatiotemporal reasoning. Despite notable progress in recent years, existing\nmethods still exhibit a noticeable gap when considering all these aspects. In\nthis work, we propose \\textbf{ReferDINO}, a strong RVOS model that inherits\nregion-level vision-language alignment from foundational visual grounding\nmodels, and is further endowed with pixel-level dense perception and\ncross-modal spatiotemporal reasoning. In detail, ReferDINO integrates two key\ncomponents: 1) a grounding-guided deformable mask decoder that utilizes\nlocation prediction to progressively guide mask prediction through\ndifferentiable deformation mechanisms; 2) an object-consistent temporal\nenhancer that injects pretrained time-varying text features into inter-frame\ninteraction to capture object-aware dynamic changes. Moreover, a\nconfidence-aware query pruning strategy is designed to accelerate object\ndecoding without compromising model performance. Extensive experimental results\non five benchmarks demonstrate that our ReferDINO significantly outperforms\nprevious methods (e.g., +3.9% (\\mathcal{J}&\\mathcal{F}) on Ref-YouTube-VOS)\nwith real-time inference speed (51 FPS).", "AI": {"tldr": "ReferDINO is a strong RVOS model combining vision-language alignment, dense perception, and spatiotemporal reasoning, outperforming previous methods with real-time speed.", "motivation": "Existing RVOS methods lack comprehensive vision-language understanding, dense prediction, and spatiotemporal reasoning, creating a performance gap.", "method": "ReferDINO integrates a grounding-guided deformable mask decoder and an object-consistent temporal enhancer, with a confidence-aware query pruning strategy.", "result": "ReferDINO achieves +3.9% (J&F) on Ref-YouTube-VOS and runs at 51 FPS, outperforming prior methods.", "conclusion": "ReferDINO effectively addresses RVOS challenges, offering superior performance and efficiency."}}
{"id": "2412.06990", "pdf": "https://arxiv.org/pdf/2412.06990", "abs": "https://arxiv.org/abs/2412.06990", "authors": ["Guy Kornowski", "Ohad Shamir"], "title": "The Oracle Complexity of Simplex-based Matrix Games: Linear Separability and Nash Equilibria", "categories": ["cs.GT", "cs.LG", "math.OC"], "comment": "Accepted to COLT 2025; minor edits following reviews", "summary": "We study the problem of solving matrix games of the form\n$\\max_{\\mathbf{w}\\in\\mathcal{W}}\\min_{\\mathbf{p}\\in\\Delta}\\mathbf{p}^{\\top}A\\mathbf{w}$,\nwhere $A$ is some matrix and $\\Delta$ is the probability simplex. This problem\nencapsulates canonical tasks such as finding a linear separator and computing\nNash equilibria in zero-sum games. However, perhaps surprisingly, its inherent\ncomplexity (as formalized in the standard framework of oracle complexity\n[Nemirovski and Yudin, 1983]) is not well-understood. In this work, we first\nidentify different oracle models which are implicitly used by prior algorithms,\namounting to multiplying the matrix $A$ by a vector from either one or both\nsides. We then prove complexity lower bounds for algorithms under both access\nmodels, which in particular imply a separation between them. Specifically, we\nstart by showing that algorithms for linear separability based on one-sided\nmultiplications must require $\\Omega(\\gamma_A^{-2})$ iterations, where\n$\\gamma_A$ is the margin, as matched by the Perceptron algorithm. We then prove\nthat accelerated algorithms for this task, which utilize multiplications from\nboth sides, must require $\\tilde{\\Omega}(\\gamma_{A}^{-2/3})$ iterations,\nestablishing the first oracle complexity barrier for such algorithms. Finally,\nby adapting our lower bound to $\\ell_1$ geometry, we prove that computing an\n$\\epsilon$-approximate Nash equilibrium requires\n$\\tilde{\\Omega}(\\epsilon^{-2/5})$ iterations, which is an exponential\nimprovement over the previously best-known lower bound due to Hadiji et al.\n[2024].", "AI": {"tldr": "The paper analyzes the complexity of solving matrix games, focusing on oracle models and proving lower bounds for one-sided and two-sided multiplication algorithms. It also improves lower bounds for computing Nash equilibria.", "motivation": "The motivation is to understand the inherent complexity of solving matrix games, which includes tasks like finding linear separators and Nash equilibria, as prior work lacks clear complexity insights.", "method": "The study identifies oracle models (one-sided and two-sided matrix multiplications) and proves lower bounds for algorithms under these models, including accelerated algorithms.", "result": "Key results include: \u03a9(\u03b3_A^{-2}) iterations for one-sided algorithms, \u03a9\u0303(\u03b3_A^{-2/3}) for accelerated (two-sided) algorithms, and \u03a9\u0303(\u03f5^{-2/5}) for computing Nash equilibria.", "conclusion": "The paper establishes new complexity barriers for matrix game algorithms and significantly improves lower bounds for Nash equilibrium computation."}}
{"id": "2501.16297", "pdf": "https://arxiv.org/pdf/2501.16297", "abs": "https://arxiv.org/abs/2501.16297", "authors": ["Renshan Zhang", "Rui Shao", "Gongwei Chen", "Miao Zhang", "Kaiwen Zhou", "Weili Guan", "Liqiang Nie"], "title": "FALCON: Resolving Visual Redundancy and Fragmentation in High-resolution Multimodal Large Language Models via Visual Registers", "categories": ["cs.CV"], "comment": "Accepted to the IEEE/CVF International Conference on Computer Vision\n  (ICCV) 2025", "summary": "The incorporation of high-resolution visual input equips multimodal large\nlanguage models (MLLMs) with enhanced visual perception capabilities for\nreal-world tasks. However, most existing high-resolution MLLMs rely on a\ncropping-based approach to process images, which leads to fragmented visual\nencoding and a sharp increase in redundant tokens. To tackle these issues, we\npropose the FALCON model. FALCON introduces a novel visual register technique\nto simultaneously: 1) Eliminate redundant tokens at the stage of visual\nencoding. To directly address the visual redundancy present in the output of\nvision encoder, we propose a Register-based Representation Compacting\n(ReCompact) mechanism. This mechanism introduces a set of learnable visual\nregisters designed to adaptively aggregate essential information while\ndiscarding redundancy. It enables the encoder to produce a more compact visual\nrepresentation with a minimal number of output tokens, thus eliminating the\nneed for an additional compression module. 2) Ensure continuity in visual\nencoding. To address the potential encoding errors caused by fragmented visual\ninputs, we develop a Register Interactive Attention (ReAtten) module. This\nmodule facilitates effective and efficient information exchange across\nsub-images by enabling interactions between visual registers. It ensures the\ncontinuity of visual semantics throughout the encoding. We conduct\ncomprehensive experiments with FALCON on high-resolution benchmarks across a\nwide range of scenarios. FALCON demonstrates superior performance with a\nremarkable 9-fold reduction in visual tokens.", "AI": {"tldr": "FALCON model improves high-resolution MLLMs by reducing redundant tokens and ensuring visual continuity using novel visual register techniques.", "motivation": "Existing high-resolution MLLMs suffer from fragmented visual encoding and excessive redundant tokens due to cropping-based approaches.", "method": "FALCON introduces visual registers with ReCompact for token reduction and ReAtten for continuity in encoding.", "result": "FALCON achieves a 9-fold reduction in visual tokens and superior performance on benchmarks.", "conclusion": "FALCON effectively addresses redundancy and fragmentation in high-resolution MLLMs, enhancing efficiency and performance."}}
{"id": "2412.20471", "pdf": "https://arxiv.org/pdf/2412.20471", "abs": "https://arxiv.org/abs/2412.20471", "authors": ["Yang Cai", "Siddharth Mitra", "Xiuyuan Wang", "Andre Wibisono"], "title": "On the Convergence of Min-Max Langevin Dynamics and Algorithm", "categories": ["cs.GT", "cs.LG", "math.OC", "stat.ML"], "comment": "v3: Accepted for presentation at the Conference on Learning Theory\n  (COLT) 2025. v2: Revised introduction and presentation of results", "summary": "We study zero-sum games in the space of probability distributions over the\nEuclidean space $\\mathbb{R}^d$ with entropy regularization, in the setting when\nthe interaction function between the players is smooth and strongly\nconvex-strongly concave. We prove an exponential convergence guarantee for the\nmean-field min-max Langevin dynamics to compute the equilibrium distribution of\nthe zero-sum game. We also study the finite-particle approximation of the\nmean-field min-max Langevin dynamics, both in continuous and discrete times. We\nprove biased convergence guarantees for the continuous-time finite-particle\nmin-max Langevin dynamics to the stationary mean-field equilibrium distribution\nwith an explicit bias term which does not scale with the number of particles.\nWe also prove biased convergence guarantees for the discrete-time\nfinite-particle min-max Langevin algorithm to the stationary mean-field\nequilibrium distribution with an additional bias term which scales with the\nstep size and the number of particles. This provides an explicit iteration\ncomplexity for the average particle along the finite-particle algorithm to\napproximately compute the equilibrium distribution of the zero-sum game.", "AI": {"tldr": "The paper analyzes zero-sum games with entropy regularization in Euclidean space, proving exponential convergence for mean-field min-max Langevin dynamics and biased convergence for finite-particle approximations.", "motivation": "To understand and compute equilibrium distributions in zero-sum games with smooth, strongly convex-concave interactions using entropy regularization.", "method": "Mean-field min-max Langevin dynamics and its finite-particle approximations (continuous and discrete-time).", "result": "Exponential convergence for mean-field dynamics; biased convergence for finite-particle approximations with explicit bias terms.", "conclusion": "The study provides iteration complexity for approximating equilibrium distributions in zero-sum games using finite-particle algorithms."}}
{"id": "2502.01061", "pdf": "https://arxiv.org/pdf/2502.01061", "abs": "https://arxiv.org/abs/2502.01061", "authors": ["Gaojie Lin", "Jianwen Jiang", "Jiaqi Yang", "Zerong Zheng", "Chao Liang"], "title": "OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models", "categories": ["cs.CV"], "comment": "ICCV 2025, Homepage: https://omnihuman-lab.github.io/", "summary": "End-to-end human animation, such as audio-driven talking human generation,\nhas undergone notable advancements in the recent few years. However, existing\nmethods still struggle to scale up as large general video generation models,\nlimiting their potential in real applications. In this paper, we propose\nOmniHuman, a Diffusion Transformer-based framework that scales up data by\nmixing motion-related conditions into the training phase. To this end, we\nintroduce two training principles for these mixed conditions, along with the\ncorresponding model architecture and inference strategy. These designs enable\nOmniHuman to fully leverage data-driven motion generation, ultimately achieving\nhighly realistic human video generation. More importantly, OmniHuman supports\nvarious portrait contents (face close-up, portrait, half-body, full-body),\nsupports both talking and singing, handles human-object interactions and\nchallenging body poses, and accommodates different image styles. Compared to\nexisting end-to-end audio-driven methods, OmniHuman not only produces more\nrealistic videos, but also offers greater flexibility in inputs. It also\nsupports multiple driving modalities (audio-driven, video-driven and combined\ndriving signals). Video samples are provided on the ttfamily project page\n(https://omnihuman-lab.github.io)", "AI": {"tldr": "OmniHuman is a Diffusion Transformer-based framework for scalable, realistic human video generation, supporting diverse inputs and driving modalities.", "motivation": "Existing methods for human animation struggle to scale like general video generation models, limiting real-world applications.", "method": "OmniHuman mixes motion-related conditions during training, using a Diffusion Transformer framework with specific training principles, architecture, and inference strategies.", "result": "OmniHuman achieves highly realistic videos, supports diverse portrait contents, actions, and styles, and outperforms existing audio-driven methods in flexibility and realism.", "conclusion": "OmniHuman advances human video generation by scaling data-driven motion and offering versatile inputs and driving modalities."}}
{"id": "2501.04712", "pdf": "https://arxiv.org/pdf/2501.04712", "abs": "https://arxiv.org/abs/2501.04712", "authors": ["Joris Bekkers"], "title": "Pressing Intensity: An Intuitive Measure for Pressing in Soccer", "categories": ["stat.AP", "cs.LG"], "comment": null, "summary": "Pressing is a fundamental defensive strategy in football, characterized by\napplying pressure on the ball owning team to regain possession. Despite its\nsignificance, existing metrics for measuring pressing often lack precision or\ncomprehensive consideration of positional data, player movement and speed. This\nresearch introduces an innovative framework for quantifying pressing intensity,\nleveraging advancements in positional tracking data and components from\nSpearman's Pitch Control model. Our method integrates player velocities,\nmovement directions, and reaction times to compute the time required for a\ndefender to intercept an attacker or the ball. This time-to-intercept measure\nis then transformed into probabilistic values using a logistic function,\nenabling dynamic and intuitive analysis of pressing situations at the\nindividual frame level. the model captures how every player's movement\ninfluences pressure on the field, offering actionable insights for coaches,\nanalysts, and decision-makers. By providing a robust and intepretable metric,\nour approach facilitates the identification of pressing strategies, advanced\nsituational analyses, and the derivation of metrics, advancing the analytical\ncapabilities for modern football.", "AI": {"tldr": "The paper introduces a new framework to measure pressing intensity in football using positional tracking data and Spearman's Pitch Control model, focusing on player movements and reaction times.", "motivation": "Existing pressing metrics lack precision and fail to fully utilize positional data, player movement, and speed.", "method": "The method integrates player velocities, movement directions, and reaction times to compute time-to-intercept, transformed into probabilistic values for dynamic analysis.", "result": "The model provides actionable insights by capturing how player movements influence pressure, enabling advanced situational analyses.", "conclusion": "The framework offers a robust, interpretable metric for pressing strategies, enhancing analytical capabilities in football."}}
{"id": "2502.04843", "pdf": "https://arxiv.org/pdf/2502.04843", "abs": "https://arxiv.org/abs/2502.04843", "authors": ["Feifei Li", "Qi Song", "Chi Zhang", "Hui Shuai", "Rui Huang"], "title": "PoI: A Filter to Extract Pixel of Interest from Novel View Synthesis for Scene Coordinate Regression", "categories": ["cs.CV"], "comment": null, "summary": "Novel View Synthesis (NVS) techniques, notably Neural Radiance Fields (NeRF)\nand 3D Gaussian Splatting (3DGS), can augment camera pose estimation by\nextending and diversifying training data. However, images generated by these\nmethods are often plagued by spatial artifacts such as blurring and ghosting,\nundermining their reliability as training data for camera pose estimation. This\nlimitation is particularly critical for Scene Coordinate Regression (SCR)\nmethods, which aim at pixel-level 3D coordinate estimation, because rendering\nartifacts directly lead to estimation inaccuracies. To address this challenge,\nwe propose a dual-criteria filtering mechanism that dynamically identifies and\ndiscards suboptimal pixels during training. The dual-criteria filter evaluates\ntwo concurrent metrics: (1) real-time SCR reprojection error, and (2) gradient\nthreshold, across the coordinate regression domain. In addition, for visual\nlocalization problems in sparse-input scenarios, it becomes even more necessary\nto use NVS-generated data to assist localization. We design a coarse-to-fine\nPoints of Interest (PoI) variant using sparse-input NVS to solve this problem.\nExperiments across indoor and outdoor benchmarks confirm our method's efficacy,\nachieving state-of-the-art localization accuracy while maintaining\ncomputational efficiency.", "AI": {"tldr": "The paper proposes a dual-criteria filtering mechanism to improve camera pose estimation by filtering out suboptimal pixels in NVS-generated data, addressing artifacts like blurring and ghosting. It also introduces a coarse-to-fine PoI variant for sparse-input scenarios, achieving state-of-the-art accuracy.", "motivation": "NVS techniques like NeRF and 3DGS can enhance training data for camera pose estimation but suffer from spatial artifacts, reducing reliability, especially for SCR methods.", "method": "A dual-criteria filter evaluates SCR reprojection error and gradient threshold to discard suboptimal pixels. A coarse-to-fine PoI variant is designed for sparse-input NVS.", "result": "The method achieves state-of-the-art localization accuracy in indoor and outdoor benchmarks while maintaining computational efficiency.", "conclusion": "The proposed approach effectively mitigates NVS artifacts and improves camera pose estimation, particularly in sparse-input scenarios."}}
{"id": "2501.06926", "pdf": "https://arxiv.org/pdf/2501.06926", "abs": "https://arxiv.org/abs/2501.06926", "authors": ["Lars van der Laan", "David Hubbard", "Allen Tran", "Nathan Kallus", "Aur\u00e9lien Bibaut"], "title": "Semiparametric Double Reinforcement Learning with Applications to Long-Term Causal Inference", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "Long-term causal effects often must be estimated from short-term data due to\nlimited follow-up in healthcare, economics, and online platforms. Markov\nDecision Processes (MDPs) provide a natural framework for capturing such\nlong-term dynamics through sequences of states, actions, and rewards. Double\nReinforcement Learning (DRL) enables efficient inference on policy values in\nMDPs, but nonparametric implementations require strong intertemporal overlap\nassumptions and often exhibit high variance and instability. We propose a\nsemiparametric extension of DRL for efficient inference on linear functionals\nof the Q-function--such as policy values--in infinite-horizon, time-homogeneous\nMDPs. By imposing structural restrictions on the Q-function, our approach\nrelaxes the strong overlap conditions required by nonparametric methods and\nimproves statistical efficiency. Under model misspecification, our estimators\ntarget the functional of the best-approximating Q-function, with only\nsecond-order bias. We provide conditions for valid inference using sieve\nmethods and data-driven model selection. A central challenge in DRL is the\nestimation of nuisance functions, such as density ratios, which often involve\ndifficult minimax optimization. To address this, we introduce a novel plug-in\nestimator based on isotonic Bellman calibration, which combines fitted\nQ-iteration with an isotonic regression adjustment. The estimator is debiased\nwithout requiring estimation of additional nuisance functions and reduces\nhigh-dimensional overlap assumptions to a one-dimensional condition. Bellman\ncalibration extends isotonic calibration--widely used in prediction and\nclassification--to the MDP setting and may be of independent interest.", "AI": {"tldr": "The paper proposes a semiparametric extension of Double Reinforcement Learning (DRL) for efficient inference on linear functionals of the Q-function in infinite-horizon MDPs, improving statistical efficiency and relaxing strong overlap assumptions.", "motivation": "Long-term causal effects are often estimated from short-term data, but nonparametric DRL methods face challenges like high variance and strong overlap requirements.", "method": "The approach imposes structural restrictions on the Q-function, uses sieve methods for inference, and introduces a plug-in estimator based on isotonic Bellman calibration to avoid difficult minimax optimization.", "result": "The method relaxes overlap conditions, reduces bias under model misspecification, and simplifies nuisance function estimation.", "conclusion": "The proposed semiparametric DRL extension offers a robust and efficient solution for policy value estimation in MDPs, with potential broader applications in reinforcement learning."}}
{"id": "2502.07007", "pdf": "https://arxiv.org/pdf/2502.07007", "abs": "https://arxiv.org/abs/2502.07007", "authors": ["Siwei Meng", "Yawei Luo", "Ping Liu"], "title": "Grounding Creativity in Physics: A Brief Survey of Physical Priors in AIGC", "categories": ["cs.CV"], "comment": "Accepted by IJCAI 2025 Survey Track", "summary": "Recent advancements in AI-generated content have significantly improved the\nrealism of 3D and 4D generation. However, most existing methods prioritize\nappearance consistency while neglecting underlying physical principles, leading\nto artifacts such as unrealistic deformations, unstable dynamics, and\nimplausible objects interactions. Incorporating physics priors into generative\nmodels has become a crucial research direction to enhance structural integrity\nand motion realism. This survey provides a review of physics-aware generative\nmethods, systematically analyzing how physical constraints are integrated into\n3D and 4D generation. First, we examine recent works in incorporating physical\npriors into static and dynamic 3D generation, categorizing methods based on\nrepresentation types, including vision-based, NeRF-based, and Gaussian\nSplatting-based approaches. Second, we explore emerging techniques in 4D\ngeneration, focusing on methods that model temporal dynamics with physical\nsimulations. Finally, we conduct a comparative analysis of major methods,\nhighlighting their strengths, limitations, and suitability for different\nmaterials and motion dynamics. By presenting an in-depth analysis of\nphysics-grounded AIGC, this survey aims to bridge the gap between generative\nmodels and physical realism, providing insights that inspire future research in\nphysically consistent content generation.", "AI": {"tldr": "This survey reviews physics-aware generative methods for 3D and 4D content, focusing on integrating physical principles to improve realism and structural integrity.", "motivation": "Existing AI-generated content methods often neglect physical principles, causing unrealistic artifacts. Incorporating physics priors is crucial for enhancing realism.", "method": "The survey categorizes methods by representation types (vision-based, NeRF-based, Gaussian Splatting) and explores 4D techniques with physical simulations.", "result": "A comparative analysis highlights strengths, limitations, and suitability of methods for different materials and dynamics.", "conclusion": "The survey bridges the gap between generative models and physical realism, inspiring future research in physically consistent content generation."}}
{"id": "2501.15690", "pdf": "https://arxiv.org/pdf/2501.15690", "abs": "https://arxiv.org/abs/2501.15690", "authors": ["Kenza Tazi", "Sun Woo P. Kim", "Marc Girona-Mata", "Richard E. Turner"], "title": "Refined climatologies of future precipitation over High Mountain Asia using probabilistic ensemble learning", "categories": ["physics.ao-ph", "cs.LG", "stat.ML"], "comment": "16 pages 8 figures (main text), 32 pages 14 figures (total)", "summary": "High Mountain Asia (HMA) holds the highest concentration of frozen water\noutside the polar regions, serving as a crucial water source for more than 1.9\nbillion people. Precipitation represents the largest source of uncertainty for\nfuture hydrological modelling in this area. In this study, we propose a\nprobabilistic machine learning framework to combine monthly precipitation from\n13 regional climate models developed under the Coordinated Regional Downscaling\nExperiment (CORDEX) over HMA via a mixture of experts (MoE). This approach\naccounts for seasonal and spatial biases within the models, enabling the\nprediction of more faithful precipitation distributions. The MoE is trained and\nvalidated against gridded historical precipitation data, yielding 32%\nimprovement over an equally-weighted average and 254% improvement over choosing\nany single ensemble member. This approach is then used to generate\nprecipitation projections for the near future (2036-2065) and far future\n(2066-2095) under RCP4.5 and RCP8.5 scenarios. Compared to previous estimates,\nthe MoE projects wetter summers but drier winters over the western Himalayas\nand Karakoram and wetter winters over the Tibetan Plateau, Hengduan Shan, and\nSouth East Tibet.", "AI": {"tldr": "A probabilistic machine learning framework improves precipitation predictions in High Mountain Asia, outperforming traditional methods and projecting future seasonal shifts.", "motivation": "Precipitation uncertainty in High Mountain Asia impacts water resources for 1.9 billion people, necessitating better modeling.", "method": "A mixture of experts (MoE) combines 13 regional climate models, addressing biases to predict precipitation distributions.", "result": "MoE improves predictions by 32% over equal weighting and 254% over single models, projecting wetter summers and drier winters in some regions.", "conclusion": "The MoE framework enhances hydrological modeling accuracy, revealing future precipitation trends critical for water resource planning."}}
{"id": "2502.12080", "pdf": "https://arxiv.org/pdf/2502.12080", "abs": "https://arxiv.org/abs/2502.12080", "authors": ["Shoukang Hu", "Takuya Narihira", "Kazumi Fukuda", "Ryosuke Sawata", "Takashi Shibuya", "Yuki Mitsufuji"], "title": "HumanGif: Single-View Human Diffusion with Generative Prior", "categories": ["cs.CV"], "comment": "Project page: https://skhu101.github.io/HumanGif/", "summary": "Previous 3D human creation methods have made significant progress in\nsynthesizing view-consistent and temporally aligned results from sparse-view\nimages or monocular videos. However, it remains challenging to produce\nperpetually realistic, view-consistent, and temporally coherent human avatars\nfrom a single image, as limited information is available in the single-view\ninput setting. Motivated by the success of 2D character animation, we propose\nHumanGif, a single-view human diffusion model with generative prior.\nSpecifically, we formulate the single-view-based 3D human novel view and pose\nsynthesis as a single-view-conditioned human diffusion process, utilizing\ngenerative priors from foundational diffusion models to complement the missing\ninformation. To ensure fine-grained and consistent novel view and pose\nsynthesis, we introduce a Human NeRF module in HumanGif to learn spatially\naligned features from the input image, implicitly capturing the relative camera\nand human pose transformation. Furthermore, we introduce an image-level loss\nduring optimization to bridge the gap between latent and image spaces in\ndiffusion models. Extensive experiments on RenderPeople, DNA-Rendering, THuman\n2.1, and TikTok datasets demonstrate that HumanGif achieves the best perceptual\nperformance, with better generalizability for novel view and pose synthesis.", "AI": {"tldr": "HumanGif is a single-view human diffusion model for 3D avatar creation, leveraging generative priors and a Human NeRF module for realistic, view-consistent results.", "motivation": "Existing methods struggle with realistic, coherent avatars from single images due to limited input information.", "method": "Uses a single-view-conditioned diffusion process with generative priors and a Human NeRF module for aligned features. Introduces an image-level loss for optimization.", "result": "Achieves best perceptual performance and generalizability on multiple datasets.", "conclusion": "HumanGif advances single-view 3D human synthesis with improved realism and consistency."}}
{"id": "2501.15828", "pdf": "https://arxiv.org/pdf/2501.15828", "abs": "https://arxiv.org/abs/2501.15828", "authors": ["Ying Chen", "Paul Griffin", "Paolo Recchia", "Lei Zhou", "Hongrui Zhang"], "title": "Hybrid Quantum Neural Networks with Amplitude Encoding: Advancing Recovery Rate Predictions", "categories": ["q-fin.CP", "cs.LG", "quant-ph"], "comment": null, "summary": "Recovery rate prediction plays a pivotal role in bond investment strategies\nby enhancing risk assessment, optimizing portfolio allocation, improving\npricing accuracy, and supporting effective credit risk management. However,\naccurate forecasting remains challenging due to complex nonlinear dependencies,\nhigh-dimensional feature spaces, and limited sample sizes-conditions under\nwhich classical machine learning models are prone to overfitting. We propose a\nhybrid Quantum Machine Learning (QML) model with Amplitude Encoding, leveraging\nthe unitarity constraint of Parametrized Quantum Circuits (PQC) and the\nexponential data compression capability of qubits. We evaluate the model on a\nglobal recovery rate dataset comprising 1,725 observations and 256 features\nfrom 1996 to 2023. Our hybrid method significantly outperforms both classical\nneural networks and QML models using Angle Encoding, achieving a lower Root\nMean Squared Error (RMSE) of 0.228, compared to 0.246 and 0.242, respectively.\nIt also performs competitively with ensemble tree methods such as XGBoost.\nWhile practical implementation challenges remain for Noisy Intermediate-Scale\nQuantum (NISQ) hardware, our quantum simulation and preliminary results on\nnoisy simulators demonstrate the promise of hybrid quantum-classical\narchitectures in enhancing the accuracy and robustness of recovery rate\nforecasting. These findings illustrate the potential of quantum machine\nlearning in shaping the future of credit risk prediction.", "AI": {"tldr": "A hybrid Quantum Machine Learning (QML) model with Amplitude Encoding is proposed to improve recovery rate prediction, outperforming classical and other QML methods.", "motivation": "Accurate recovery rate prediction is crucial for bond investment strategies but is challenging due to complex data dependencies and limitations of classical models.", "method": "The hybrid QML model uses Amplitude Encoding, leveraging quantum circuits and qubits' data compression. Evaluated on a global dataset (1,725 observations, 256 features).", "result": "Achieves lower RMSE (0.228) than classical neural networks (0.246) and QML with Angle Encoding (0.242), and competes with XGBoost.", "conclusion": "Hybrid quantum-classical architectures show promise for recovery rate forecasting, despite NISQ hardware challenges."}}
{"id": "2502.20532", "pdf": "https://arxiv.org/pdf/2502.20532", "abs": "https://arxiv.org/abs/2502.20532", "authors": ["Ji-Hun Oh", "Kianoush Falahkheirkhah", "Rohit Bhargava"], "title": "Finer Disentanglement of Aleatoric Uncertainty Can Accelerate Chemical Histopathology Imaging", "categories": ["cs.CV"], "comment": null, "summary": "Label-free chemical imaging holds significant promise for improving digital\npathology workflows, but data acquisition speed remains a limiting factor. To\naddress this gap, we propose an adaptive strategy-initially scan the low\ninformation (LI) content of the entire tissue quickly, identify regions with\nhigh aleatoric uncertainty (AU), and selectively re-image them at better\nquality to capture higher information (HI) details. The primary challenge lies\nin distinguishing between high-AU regions mitigable through HI imaging and\nthose that are not. However, since existing uncertainty frameworks cannot\nseparate such AU subcategories, we propose a fine-grained disentanglement\nmethod based on post-hoc latent space analysis to unmix resolvable from\nirresolvable high-AU regions. We apply our approach to streamline infrared\nspectroscopic imaging of breast tissues, achieving superior downstream\nsegmentation performance. This marks the first study focused on fine-grained AU\ndisentanglement within dynamic image spaces (LI-to-HI), with novel application\nto streamline histopathology.", "AI": {"tldr": "An adaptive strategy for label-free chemical imaging improves data acquisition speed by initially scanning low-information areas quickly and selectively re-imaging high-uncertainty regions for better quality.", "motivation": "To address the slow data acquisition speed in label-free chemical imaging for digital pathology workflows.", "method": "Proposes an adaptive strategy: quick scan of low-information areas, identify high-uncertainty regions, and selectively re-image them. Introduces a fine-grained disentanglement method to separate resolvable from irresolvable uncertainties.", "result": "Applied to infrared spectroscopic imaging of breast tissues, achieving superior segmentation performance.", "conclusion": "First study to focus on fine-grained uncertainty disentanglement in dynamic image spaces, streamlining histopathology workflows."}}
{"id": "2502.05623", "pdf": "https://arxiv.org/pdf/2502.05623", "abs": "https://arxiv.org/abs/2502.05623", "authors": ["Andre Wibisono"], "title": "Mixing Time of the Proximal Sampler in Relative Fisher Information via Strong Data Processing Inequality", "categories": ["cs.IT", "cs.LG", "math.IT", "math.OC", "math.ST", "stat.TH"], "comment": "v2: Extended abstract accepted for presentation at Conference on\n  Learning Theory (COLT) 2025", "summary": "We study the mixing time guarantee for sampling in relative Fisher\ninformation via the Proximal Sampler algorithm, which is an approximate\nproximal discretization of the Langevin dynamics. We show that when the target\nprobability distribution is strongly log-concave, the relative Fisher\ninformation converges exponentially fast along the Proximal Sampler; this\nmatches the exponential convergence rate of the relative Fisher information\nalong the continuous-time Langevin dynamics for strongly log-concave target.\nWhen combined with a standard implementation of the Proximal Sampler via\nrejection sampling, this exponential convergence rate provides a high-accuracy\niteration complexity guarantee for the Proximal Sampler in relative Fisher\ninformation when the target distribution is strongly log-concave and\nlog-smooth. Our proof proceeds by establishing a strong data processing\ninequality for relative Fisher information along the Gaussian channel under\nstrong log-concavity, and a data processing inequality along the reverse\nGaussian channel for a special distribution. The forward and reverse Gaussian\nchannels compose to form the Proximal Sampler, and these data processing\ninequalities imply the exponential convergence rate of the relative Fisher\ninformation along the Proximal Sampler.", "AI": {"tldr": "The paper analyzes the Proximal Sampler algorithm's mixing time for sampling in relative Fisher information, showing exponential convergence for strongly log-concave distributions, matching Langevin dynamics.", "motivation": "To understand and quantify the convergence behavior of the Proximal Sampler algorithm for strongly log-concave distributions, aligning it with known results for Langevin dynamics.", "method": "The study uses the Proximal Sampler, an approximate proximal discretization of Langevin dynamics, and analyzes its convergence via data processing inequalities for relative Fisher information under strong log-concavity.", "result": "Exponential convergence of relative Fisher information is proven for strongly log-concave distributions, providing high-accuracy iteration complexity guarantees.", "conclusion": "The Proximal Sampler achieves exponential convergence in relative Fisher information for strongly log-concave targets, validated by data processing inequalities."}}
{"id": "2502.21085", "pdf": "https://arxiv.org/pdf/2502.21085", "abs": "https://arxiv.org/abs/2502.21085", "authors": ["Jing-Yuan Chang"], "title": "BST: Badminton Stroke-type Transformer for Skeleton-based Action Recognition in Racket Sports", "categories": ["cs.CV"], "comment": "9 pages (excluding references)", "summary": "Badminton, known for having the fastest ball speeds among all sports,\npresents significant challenges to the field of computer vision, including\nplayer identification, court line detection, shuttlecock trajectory tracking,\nand player stroke-type classification. In this paper, we introduce a novel\nvideo segmentation strategy to extract frames of each player's racket swing in\na badminton broadcast match. These segmented frames are then processed by two\nexisting models: one for Human Pose Estimation to obtain player skeletal\njoints, and the other for shuttlecock trajectory detection to extract\nshuttlecock trajectories. Leveraging these joints, trajectories, and player\npositions as inputs, we propose Badminton Stroke-type Transformer (BST) to\nclassify player stroke-types in singles. To the best of our knowledge,\nexperimental results demonstrate that our method outperforms the previous\nstate-of-the-art on the largest publicly available badminton video dataset,\nShuttleSet, which shows that effectively leveraging ball trajectory is likely\nto be a trend for racket sports action recognition.", "AI": {"tldr": "A novel video segmentation strategy for badminton broadcast matches is introduced, combined with Human Pose Estimation and shuttlecock trajectory detection, to classify player stroke-types using the proposed Badminton Stroke-type Transformer (BST).", "motivation": "Badminton's fast-paced nature poses challenges for computer vision tasks like player identification, court line detection, and stroke-type classification.", "method": "Segmented frames are processed by Human Pose Estimation and shuttlecock trajectory detection models. The extracted data (joints, trajectories, player positions) is input into the BST for stroke-type classification.", "result": "The method outperforms previous state-of-the-art on the ShuttleSet dataset, demonstrating the importance of leveraging ball trajectory for racket sports action recognition.", "conclusion": "Effectively using ball trajectory is a promising trend for action recognition in racket sports, as shown by the BST's superior performance."}}
{"id": "2502.05676", "pdf": "https://arxiv.org/pdf/2502.05676", "abs": "https://arxiv.org/abs/2502.05676", "authors": ["Lars van der Laan", "Ahmed Alaa"], "title": "Generalized Venn and Venn-Abers Calibration with Applications in Conformal Prediction", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "Ensuring model calibration is critical for reliable prediction, yet popular\ndistribution-free methods such as histogram binning and isotonic regression\noffer only asymptotic guarantees. We introduce a unified framework for Venn and\nVenn-Abers calibration that extends Vovk's approach beyond binary\nclassification to a broad class of prediction problems defined by generic loss\nfunctions. Our method transforms any perfectly in-sample calibrated predictor\ninto a set-valued predictor that, in finite samples, outputs at least one\nmarginally calibrated point prediction. These set predictions shrink\nasymptotically and converge to a conditionally calibrated prediction, capturing\nepistemic uncertainty. We further propose Venn multicalibration, a new approach\nfor achieving finite-sample calibration across subpopulations. For quantile\nloss, our framework recovers group-conditional and multicalibrated conformal\nprediction as special cases and yields novel prediction intervals with\nquantile-conditional coverage.", "AI": {"tldr": "A unified framework for Venn and Venn-Abers calibration is introduced, extending Vovk's approach to various prediction problems with finite-sample guarantees and capturing epistemic uncertainty.", "motivation": "To address the limitations of distribution-free calibration methods like histogram binning and isotonic regression, which only offer asymptotic guarantees, by providing finite-sample calibration.", "method": "The framework transforms any in-sample calibrated predictor into a set-valued predictor, ensuring marginal calibration in finite samples. It also introduces Venn multicalibration for subpopulation calibration.", "result": "The method produces set predictions that shrink asymptotically to conditionally calibrated predictions and recovers group-conditional conformal prediction for quantile loss.", "conclusion": "The proposed framework advances calibration techniques by offering finite-sample guarantees and handling epistemic uncertainty, with applications in diverse prediction problems."}}
{"id": "2503.03501", "pdf": "https://arxiv.org/pdf/2503.03501", "abs": "https://arxiv.org/abs/2503.03501", "authors": ["Gavriel Habib", "Noa Barzilay", "Or Shimshi", "Rami Ben-Ari", "Nir Darshan"], "title": "CarGait: Cross-Attention based Re-ranking for Gait recognition", "categories": ["cs.CV"], "comment": "Accepted to ICCV 2025", "summary": "Gait recognition is a computer vision task that identifies individuals based\non their walking patterns. Gait recognition performance is commonly evaluated\nby ranking a gallery of candidates and measuring the accuracy at the top\nRank-$K$. Existing models are typically single-staged, i.e. searching for the\nprobe's nearest neighbors in a gallery using a single global feature\nrepresentation. Although these models typically excel at retrieving the correct\nidentity within the top-$K$ predictions, they struggle when hard negatives\nappear in the top short-list, leading to relatively low performance at the\nhighest ranks (e.g., Rank-1). In this paper, we introduce CarGait, a\nCross-Attention Re-ranking method for gait recognition, that involves\nre-ordering the top-$K$ list leveraging the fine-grained correlations between\npairs of gait sequences through cross-attention between gait strips. This\nre-ranking scheme can be adapted to existing single-stage models to enhance\ntheir final results. We demonstrate the capabilities of CarGait by extensive\nexperiments on three common gait datasets, Gait3D, GREW, and OU-MVLP, and seven\ndifferent gait models, showing consistent improvements in Rank-1,5 accuracy,\nsuperior results over existing re-ranking methods, and strong baselines.", "AI": {"tldr": "CarGait introduces a cross-attention re-ranking method to improve gait recognition by refining top-K predictions using fine-grained correlations between gait sequences.", "motivation": "Existing single-stage gait recognition models struggle with hard negatives in top ranks, limiting Rank-1 accuracy.", "method": "CarGait uses cross-attention between gait strips to re-order the top-K list, enhancing fine-grained correlations.", "result": "Experiments on three datasets and seven models show consistent Rank-1,5 accuracy improvements, outperforming existing re-ranking methods.", "conclusion": "CarGait effectively boosts gait recognition performance, especially at higher ranks, and is adaptable to existing models."}}
{"id": "2503.06132", "pdf": "https://arxiv.org/pdf/2503.06132", "abs": "https://arxiv.org/abs/2503.06132", "authors": ["Xiangxiang Chu", "Renda Li", "Yong Wang"], "title": "USP: Unified Self-Supervised Pretraining for Image Generation and Understanding", "categories": ["cs.CV"], "comment": "Accepted to ICCV2025", "summary": "Recent studies have highlighted the interplay between diffusion models and\nrepresentation learning. Intermediate representations from diffusion models can\nbe leveraged for downstream visual tasks, while self-supervised vision models\ncan enhance the convergence and generation quality of diffusion models.\nHowever, transferring pretrained weights from vision models to diffusion models\nis challenging due to input mismatches and the use of latent spaces. To address\nthese challenges, we propose Unified Self-supervised Pretraining (USP), a\nframework that initializes diffusion models via masked latent modeling in a\nVariational Autoencoder (VAE) latent space. USP achieves comparable performance\nin understanding tasks while significantly improving the convergence speed and\ngeneration quality of diffusion models. Our code will be publicly available at\nhttps://github.com/AMAP-ML/USP.", "AI": {"tldr": "USP is a framework that uses masked latent modeling in a VAE latent space to initialize diffusion models, improving their convergence and generation quality.", "motivation": "Addressing challenges in transferring pretrained weights from vision models to diffusion models due to input mismatches and latent space usage.", "method": "Proposes Unified Self-supervised Pretraining (USP) via masked latent modeling in a VAE latent space.", "result": "Achieves comparable performance in understanding tasks and significantly improves diffusion model convergence and generation quality.", "conclusion": "USP effectively bridges the gap between self-supervised vision models and diffusion models, enhancing their synergy."}}
{"id": "2503.10138", "pdf": "https://arxiv.org/pdf/2503.10138", "abs": "https://arxiv.org/abs/2503.10138", "authors": ["Guy Barzilai", "Ohad Shamir", "Moslem Zamani"], "title": "Are Convex Optimization Curves Convex?", "categories": ["math.OC", "cs.LG"], "comment": "12 pages", "summary": "In this paper, we study when we might expect the optimization curve induced\nby gradient descent to be \\emph{convex} -- precluding, for example, an initial\nplateau followed by a sharp decrease, making it difficult to decide when\noptimization should stop. Although such undesirable behavior can certainly\noccur when optimizing general functions, might it also occur in the benign and\nwell-studied case of smooth convex functions? As far as we know, this question\nhas not been tackled in previous work. We show, perhaps surprisingly, that the\nanswer crucially depends on the choice of the step size. In particular, for the\nrange of step sizes which are known to result in monotonic convergence to an\noptimal value, we characterize a regime where the optimization curve will be\nprovably convex, and a regime where the curve can be non-convex. We also extend\nour results to gradient flow, and to the closely-related but different question\nof whether the gradient norm decreases monotonically.", "AI": {"tldr": "The paper investigates conditions under which gradient descent's optimization curve is convex, focusing on step size's role. It identifies regimes for convexity and non-convexity in smooth convex functions.", "motivation": "To understand when gradient descent's optimization curve is convex, avoiding undesirable behaviors like plateaus followed by sharp decreases, which complicate stopping decisions.", "method": "Analyzes the impact of step size on the convexity of the optimization curve for smooth convex functions, extending results to gradient flow and gradient norm monotonicity.", "result": "Step size determines convexity: certain ranges ensure convex curves, while others allow non-convexity. Results also apply to gradient flow and gradient norm behavior.", "conclusion": "The choice of step size is critical for ensuring convex optimization curves in gradient descent, with implications for gradient flow and gradient norm monotonicity."}}
{"id": "2503.06671", "pdf": "https://arxiv.org/pdf/2503.06671", "abs": "https://arxiv.org/abs/2503.06671", "authors": ["Dongheon Lee", "Seokju Yun", "Youngmin Ro"], "title": "Emulating Self-attention with Convolution for Efficient Image Super-Resolution", "categories": ["cs.CV"], "comment": "ICCV 2025", "summary": "In this paper, we tackle the high computational overhead of Transformers for\nefficient image super-resolution~(SR). Motivated by the observations of\nself-attention's inter-layer repetition, we introduce a convolutionized\nself-attention module named Convolutional Attention~(ConvAttn) that emulates\nself-attention's long-range modeling capability and instance-dependent\nweighting with a single shared large kernel and dynamic kernels. By utilizing\nthe ConvAttn module, we significantly reduce the reliance on self-attention and\nits involved memory-bound operations while maintaining the representational\ncapability of Transformers. Furthermore, we overcome the challenge of\nintegrating flash attention into the lightweight SR regime, effectively\nmitigating self-attention's inherent memory bottleneck. We scale up the window\nsize to 32$\\times$32 with flash attention rather than proposing an intricate\nself-attention module, significantly improving PSNR by 0.31dB on\nUrban100$\\times$2 while reducing latency and memory usage by 16$\\times$ and\n12.2$\\times$. Building on these approaches, our proposed network, termed\nEmulating Self-attention with Convolution~(ESC), notably improves PSNR by 0.27\ndB on Urban100$\\times$4 compared to HiT-SRF, reducing the latency and memory\nusage by 3.7$\\times$ and 6.2$\\times$, respectively. Extensive experiments\ndemonstrate that our ESC maintains the ability for long-range modeling, data\nscalability, and the representational power of Transformers despite most\nself-attention being replaced by the ConvAttn module.", "AI": {"tldr": "The paper introduces ConvAttn, a convolutionized self-attention module, to reduce Transformer overhead in image super-resolution while maintaining performance.", "motivation": "Addressing the high computational overhead of Transformers in image super-resolution by leveraging self-attention's inter-layer repetition.", "method": "Proposes ConvAttn, which emulates self-attention with shared and dynamic kernels, and integrates flash attention for efficiency.", "result": "ESC network improves PSNR by 0.27dB on Urban100\u00d74, reduces latency by 3.7\u00d7, and memory usage by 6.2\u00d7.", "conclusion": "ESC maintains Transformer capabilities while significantly improving efficiency, making it viable for lightweight SR tasks."}}
{"id": "2503.13791", "pdf": "https://arxiv.org/pdf/2503.13791", "abs": "https://arxiv.org/abs/2503.13791", "authors": ["Victor Rielly", "Kamel Lahouel", "Chau Nguyen", "Anthony Kolshorn", "Nicholas Fisher", "Bruno Jedynak"], "title": "ROCK: A variational formulation for occupation kernel methods in Reproducing Kernel Hilbert Spaces", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We present a Representer Theorem result for a large class of weak formulation\nproblems. We provide examples of applications of our formulation both in\ntraditional machine learning and numerical methods as well as in new and\nemerging techniques. Finally we apply our formulation to generalize the\nmultivariate occupation kernel (MOCK) method for learning dynamical systems\nfrom data proposing the more general Riesz Occupation Kernel (ROCK) method. Our\ngeneralized methods are both more computationally efficient and performant on\nmost of the benchmarks we test against.", "AI": {"tldr": "The paper introduces a Representer Theorem for weak formulation problems, applies it to machine learning and numerical methods, and generalizes the MOCK method to the ROCK method, showing improved efficiency and performance.", "motivation": "To extend the Representer Theorem to a broad class of weak formulation problems and demonstrate its utility in machine learning and numerical methods, including dynamical systems learning.", "method": "The authors propose a generalized framework for weak formulation problems, exemplified by the Riesz Occupation Kernel (ROCK) method, an extension of the MOCK method.", "result": "The generalized methods (e.g., ROCK) are computationally more efficient and outperform benchmarks in most tested cases.", "conclusion": "The paper successfully generalizes weak formulation problems and introduces the ROCK method, demonstrating superior performance and efficiency in applications."}}
{"id": "2503.07417", "pdf": "https://arxiv.org/pdf/2503.07417", "abs": "https://arxiv.org/abs/2503.07417", "authors": ["Minwen Liao", "Hao Bo Dong", "Xinyi Wang", "Kurban Ubul", "Ziyang Yan", "Yihua Shao"], "title": "GM-MoE: Low-Light Enhancement with Gated-Mechanism Mixture-of-Experts", "categories": ["cs.CV"], "comment": null, "summary": "Low-light enhancement has wide applications in autonomous driving, 3D\nreconstruction, remote sensing, surveillance, and so on, which can\nsignificantly improve information utilization. However, most existing methods\nlack generalization and are limited to specific tasks such as image recovery.\nTo address these issues, we propose Gated-Mechanism Mixture-of-Experts\n(GM-MoE), the first framework to introduce a mixture-of-experts network for\nlow-light image enhancement. GM-MoE comprises a dynamic gated weight\nconditioning network and three sub-expert networks, each specializing in a\ndistinct enhancement task. Combining a self-designed gated mechanism that\ndynamically adjusts the weights of the sub-expert networks for different data\ndomains. Additionally, we integrate local and global feature fusion within\nsub-expert networks to enhance image quality by capturing multi-scale features.\nExperimental results demonstrate that the GM-MoE achieves superior\ngeneralization with respect to 25 compared approaches, reaching\nstate-of-the-art performance on PSNR on 5 benchmarks and SSIM on 4 benchmarks,\nrespectively.", "AI": {"tldr": "GM-MoE is a novel low-light enhancement framework using a mixture-of-experts network with dynamic gating, outperforming 25 methods on benchmarks.", "motivation": "Existing low-light enhancement methods lack generalization and are task-specific. GM-MoE aims to address this by leveraging a dynamic gated mechanism and multi-scale feature fusion.", "method": "GM-MoE combines a gated weight conditioning network with three specialized sub-expert networks, dynamically adjusting weights for different domains and fusing local/global features.", "result": "GM-MoE achieves state-of-the-art performance on PSNR (5 benchmarks) and SSIM (4 benchmarks), surpassing 25 compared methods.", "conclusion": "GM-MoE offers superior generalization and performance in low-light image enhancement, making it a versatile solution for various applications."}}
{"id": "2503.14055", "pdf": "https://arxiv.org/pdf/2503.14055", "abs": "https://arxiv.org/abs/2503.14055", "authors": ["Guido Carnevale", "Nicola Bastianello"], "title": "Modular Distributed Nonconvex Learning with Error Feedback", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "In this paper, we design a novel distributed learning algorithm using\nstochastic compressed communications. In detail, we pursue a modular approach,\nmerging ADMM and a gradient-based approach, benefiting from the robustness of\nthe former and the computational efficiency of the latter. Additionally, we\nintegrate a stochastic integral action (error feedback) enabling almost sure\nrejection of the compression error. We analyze the resulting method in\nnonconvex scenarios and guarantee almost sure asymptotic convergence to the set\nof stationary points of the problem. This result is obtained using\nsystem-theoretic tools based on stochastic timescale separation. We corroborate\nour findings with numerical simulations in nonconvex classification.", "AI": {"tldr": "A novel distributed learning algorithm combining ADMM and gradient-based methods with stochastic compression and error feedback ensures convergence in nonconvex scenarios.", "motivation": "To create a robust and computationally efficient distributed learning algorithm that handles compression errors and nonconvex problems.", "method": "Modular approach merging ADMM and gradient-based methods, integrating stochastic error feedback for compression error rejection.", "result": "Almost sure asymptotic convergence to stationary points in nonconvex scenarios, validated by numerical simulations.", "conclusion": "The proposed algorithm effectively combines robustness and efficiency, ensuring convergence despite compression and nonconvexity."}}
{"id": "2503.07503", "pdf": "https://arxiv.org/pdf/2503.07503", "abs": "https://arxiv.org/abs/2503.07503", "authors": ["Shiu-hong Kao", "Yu-Wing Tai", "Chi-Keung Tang"], "title": "Think Before You Segment: High-Quality Reasoning Segmentation with GPT Chain of Thoughts", "categories": ["cs.CV"], "comment": "Project page: https://danielshkao.github.io/thinkfirst.html", "summary": "Reasoning segmentation is a challenging vision-language task that aims to\noutput the segmentation mask with respect to a complex, implicit, and even\nnon-visual query text. Previous works incorporated multimodal Large Language\nModels (MLLMs) with segmentation models to approach the difficult problem.\nHowever, their segmentation quality often falls short in complex cases,\nparticularly when dealing with out-of-domain objects with intricate structures,\nblurry boundaries, occlusions, or high similarity with surroundings. In this\npaper, we introduce ThinkFirst, a training-free reasoning segmentation\nframework that leverages GPT's chain of thought to address these challenging\ncases. Our approach allows GPT-4o or other powerful MLLMs to generate a\ndetailed, chain-of-thought description of an image. This summarized description\nis then passed to a language-instructed segmentation assistant to aid the\nsegmentation process. Our framework allows users to easily interact with the\nsegmentation agent using multimodal inputs, such as easy text and image\nscribbles, for successive refinement or communication. We evaluate the\nperformance of ThinkFirst on diverse objects. Extensive experiments show that,\nthis zero-shot-CoT approach significantly improves the vanilla reasoning\nsegmentation agent, both qualitatively and quantitatively, while being less\nsensitive or critical to user-supplied prompts after Thinking First.", "AI": {"tldr": "ThinkFirst is a training-free reasoning segmentation framework using GPT's chain of thought to improve segmentation quality for complex, implicit, or non-visual queries.", "motivation": "Addressing limitations of previous methods in handling complex cases like out-of-domain objects, blurry boundaries, occlusions, or high similarity with surroundings.", "method": "Leverage GPT-4o or other MLLMs to generate detailed chain-of-thought descriptions of images, which are then used by a language-instructed segmentation assistant.", "result": "Significantly improves segmentation quality in zero-shot settings, both qualitatively and quantitatively, with less sensitivity to user prompts.", "conclusion": "ThinkFirst enhances reasoning segmentation by integrating detailed textual reasoning, enabling better handling of complex cases and user interaction."}}
{"id": "2503.14571", "pdf": "https://arxiv.org/pdf/2503.14571", "abs": "https://arxiv.org/abs/2503.14571", "authors": ["George Panagopoulos", "Johannes F. Lutzeyer", "Sofiane Ennadir", "Michalis Vazirgiannis", "Jun Pang"], "title": "Data Filtering for Genetic Perturbation Prediction", "categories": ["q-bio.QM", "cs.LG"], "comment": "21 pages", "summary": "Genomic studies, including CRISPR-based PerturbSeq analyses, face a vast\nhypothesis space, while gene perturbations remain costly and time-consuming.\nGene expression models based on graph neural networks are trained to predict\nthe outcomes of gene perturbations to facilitate such experiments. Active\nlearning methods are often employed to train these models due to the cost of\nthe genomic experiments required to build the training set. However, poor model\ninitialization in active learning can result in suboptimal early selections,\nwasting time and valuable resources. While typical active learning mitigates\nthis issue over many iterations, the limited number of experimental cycles in\ngenomic studies exacerbates the risk. To this end, we propose graph-based data\nfiltering as an alternative. Unlike active learning, data filtering selects the\ngene perturbations before training, meaning it is free of bias due to random\ninitialization and initial random selection. Moreover, reducing the iterations\nbetween the wet lab and the model provides several operational advantages\nresulting in significant acceleration. The proposed methods are motivated by\ntheoretical studies of graph neural network generalization. The criteria are\ndefined over the input graph and are optimized with submodular maximization. We\ncompare them empirically to baselines and active learning methods that are\nstate-of-the-art. The results demonstrate that graph-based data filtering\nachieves comparable accuracy while alleviating the aforementioned risks.", "AI": {"tldr": "Graph-based data filtering is proposed to improve gene perturbation experiments by avoiding biases in active learning, achieving comparable accuracy with fewer iterations.", "motivation": "High costs and time constraints in genomic studies, coupled with suboptimal early selections in active learning, necessitate a better method for selecting gene perturbations.", "method": "Graph-based data filtering selects perturbations before training, using graph neural network generalization theory and submodular maximization.", "result": "The method achieves comparable accuracy to active learning while reducing risks and operational inefficiencies.", "conclusion": "Graph-based data filtering offers a viable alternative to active learning, improving efficiency and reducing biases in genomic studies."}}
{"id": "2503.08101", "pdf": "https://arxiv.org/pdf/2503.08101", "abs": "https://arxiv.org/abs/2503.08101", "authors": ["Lizhen Xu", "Xiuxiu Bai", "Xiaojun Jia", "Jianwu Fang", "Shanmin Pang"], "title": "Accelerate 3D Object Detection Models via Zero-Shot Attention Key Pruning", "categories": ["cs.CV"], "comment": "Accepted by ICCV2025. The code can be found at\n  https://github.com/iseri27/tg_gbc", "summary": "Query-based methods with dense features have demonstrated remarkable success\nin 3D object detection tasks. However, the computational demands of these\nmodels, particularly with large image sizes and multiple transformer layers,\npose significant challenges for efficient running on edge devices. Existing\npruning and distillation methods either need retraining or are designed for ViT\nmodels, which are hard to migrate to 3D detectors. To address this issue, we\npropose a zero-shot runtime pruning method for transformer decoders in 3D\nobject detection models. The method, termed tgGBC (trim keys gradually Guided\nBy Classification scores), systematically trims keys in transformer modules\nbased on their importance. We expand the classification score to multiply it\nwith the attention map to get the importance score of each key and then prune\ncertain keys after each transformer layer according to their importance scores.\nOur method achieves a 1.99x speedup in the transformer decoder of the latest\nToC3D model, with only a minimal performance loss of less than 1%.\nInterestingly, for certain models, our method even enhances their performance.\nMoreover, we deploy 3D detectors with tgGBC on an edge device, further\nvalidating the effectiveness of our method. The code can be found at\nhttps://github.com/iseri27/tg_gbc.", "AI": {"tldr": "A zero-shot runtime pruning method (tgGBC) is proposed for transformer decoders in 3D object detection, achieving significant speedup with minimal performance loss.", "motivation": "Addressing the computational inefficiency of dense feature-based query methods in 3D object detection for edge devices.", "method": "tgGBC trims keys in transformer modules based on importance scores derived from classification scores and attention maps.", "result": "Achieves 1.99x speedup with <1% performance loss; some models show improved performance.", "conclusion": "tgGBC is effective for efficient 3D object detection on edge devices, validated by deployment."}}
{"id": "2503.18001", "pdf": "https://arxiv.org/pdf/2503.18001", "abs": "https://arxiv.org/abs/2503.18001", "authors": ["Kunal Mukherjee", "Zachary Harrison", "Saeid Balaneshin"], "title": "Z-REx: Human-Interpretable GNN Explanations for Real Estate Recommendations", "categories": ["cs.IR", "cs.LG", "cs.SI", "I.2; I.5"], "comment": "Accepted to be published in KDD Workshop in Machine Learning on\n  Graphs in the Era of Generative Artificial Intelligence (MLoG-GenAI@KDD) 2025", "summary": "Transparency and interpretability are crucial for enhancing customer\nconfidence and user engagement, especially when dealing with black-box Machine\nLearning (ML)-based recommendation systems. Modern recommendation systems\nleverage Graph Neural Network (GNN) due to their ability to produce\nhigh-quality recommendations in terms of both relevance and diversity.\nTherefore, the explainability of GNN is especially important for Link\nPrediction (LP) tasks since recommending relevant items can be viewed as\npredicting links between users and items. GNN explainability has been a\nwell-studied field, but existing methods primarily focus on node or graph-level\ntasks, leaving a gap in LP explanation techniques. This work introduces Z-REx,\na GNN explanation framework designed explicitly for heterogeneous link\nprediction tasks. Z-REx utilizes structural and attribute perturbation to\nidentify critical substructures and important features while reducing the\nsearch space by leveraging domain-specific knowledge. In our experimentation,\nwe show the efficacy of Z-REx in generating contextually relevant and\nhuman-interpretable explanations for ZiGNN, a GNN-based recommendation engine,\nusing a real-world real-estate dataset from Zillow Group, Inc. We compare\nagainst State-of-The-Art (SOTA) GNN explainers to show Z-REx outperforms them\nby 61% in the Fidelity metric by producing superior human-interpretable\nexplanations.", "AI": {"tldr": "Z-REx is a GNN explanation framework for link prediction tasks, outperforming SOTA methods by 61% in fidelity.", "motivation": "Enhancing transparency in GNN-based recommendation systems for better user trust and engagement.", "method": "Uses structural and attribute perturbation to identify key substructures and features, leveraging domain knowledge.", "result": "Z-REx produces superior human-interpretable explanations, outperforming SOTA by 61% in fidelity.", "conclusion": "Z-REx effectively bridges the gap in explainability for link prediction tasks in GNNs."}}
{"id": "2503.09185", "pdf": "https://arxiv.org/pdf/2503.09185", "abs": "https://arxiv.org/abs/2503.09185", "authors": ["Yuanyang Zhang", "Yijie Lin", "Weiqing Yan", "Li Yao", "Xinhang Wan", "Guangyuan Li", "Chao Zhang", "Guanzhou Ke", "Jie Xu"], "title": "Incomplete Multi-view Clustering via Diffusion Contrastive Generation", "categories": ["cs.CV"], "comment": null, "summary": "Incomplete multi-view clustering (IMVC) has garnered increasing attention in\nrecent years due to the common issue of missing data in multi-view datasets.\nThe primary approach to address this challenge involves recovering the missing\nviews before applying conventional multi-view clustering methods. Although\nimputation-based IMVC methods have achieved significant improvements, they\nstill encounter notable limitations: 1) heavy reliance on paired data for\ntraining the data recovery module, which is impractical in real scenarios with\nhigh missing data rates; 2) the generated data often lacks diversity and\ndiscriminability, resulting in suboptimal clustering results. To address these\nshortcomings, we propose a novel IMVC method called Diffusion Contrastive\nGeneration (DCG). Motivated by the consistency between the diffusion and\nclustering processes, DCG learns the distribution characteristics to enhance\nclustering by applying forward diffusion and reverse denoising processes to\nintra-view data. By performing contrastive learning on a limited set of paired\nmulti-view samples, DCG can align the generated views with the real views,\nfacilitating accurate recovery of views across arbitrary missing view\nscenarios. Additionally, DCG integrates instance-level and category-level\ninteractive learning to exploit the consistent and complementary information\navailable in multi-view data, achieving robust and end-to-end clustering.\nExtensive experiments demonstrate that our method outperforms state-of-the-art\napproaches. The code is available at\nhttps://github.com/zhangyuanyang21/2025-AAAI-DCG.", "AI": {"tldr": "A novel IMVC method, DCG, addresses limitations of imputation-based approaches by leveraging diffusion processes and contrastive learning for robust clustering.", "motivation": "Existing IMVC methods rely heavily on paired data for training and produce low-diversity imputed data, leading to suboptimal clustering.", "method": "DCG uses forward diffusion and reverse denoising processes, along with contrastive learning, to align generated and real views. It also employs instance-level and category-level interactive learning.", "result": "DCG outperforms state-of-the-art methods in experiments.", "conclusion": "DCG provides an effective, end-to-end solution for IMVC by improving data recovery and clustering performance."}}
{"id": "2503.23430", "pdf": "https://arxiv.org/pdf/2503.23430", "abs": "https://arxiv.org/abs/2503.23430", "authors": ["Youngjun Song", "Youngsik Hwang", "Jonghun Lee", "Heechang Lee", "Dong-Young Lim"], "title": "DGSAM: Domain Generalization via Individual Sharpness-Aware Minimization", "categories": ["stat.ML", "cs.LG", "math.OC", "stat.AP"], "comment": null, "summary": "Domain generalization (DG) aims to learn models that perform well on unseen\ntarget domains by training on multiple source domains. Sharpness-Aware\nMinimization (SAM), known for finding flat minima that improve generalization,\nhas therefore been widely adopted in DG. However, our analysis reveals that SAM\nin DG may converge to \\textit{fake flat minima}, where the total loss surface\nappears flat in terms of global sharpness but remains sharp with respect to\nindividual source domains. To understand this phenomenon more precisely, we\nformalize the average worst-case domain risk as the maximum loss under domain\ndistribution shifts within a bounded divergence, and derive a generalization\nbound that reveals the limitations of global sharpness-aware minimization. In\ncontrast, we show that individual sharpness provides a valid upper bound on\nthis risk, making it a more suitable proxy for robust domain generalization.\nMotivated by these insights, we shift the DG paradigm toward minimizing\nindividual sharpness across source domains. We propose\n\\textit{Decreased-overhead Gradual SAM (DGSAM)}, which applies gradual\ndomain-wise perturbations in a computationally efficient manner to consistently\nreduce individual sharpness. Extensive experiments demonstrate that DGSAM not\nonly improves average accuracy but also reduces performance variance across\ndomains, while incurring less computational overhead than SAM.", "AI": {"tldr": "SAM in DG may converge to fake flat minima, limiting generalization. The paper proposes DGSAM to minimize individual sharpness, improving accuracy and reducing variance.", "motivation": "To address the issue of fake flat minima in SAM for DG, which hampers generalization despite appearing globally flat.", "method": "Proposes DGSAM, a method applying gradual domain-wise perturbations to reduce individual sharpness efficiently.", "result": "DGSAM improves average accuracy and reduces performance variance across domains with less computational overhead than SAM.", "conclusion": "Individual sharpness is a better proxy for robust DG, and DGSAM effectively addresses the limitations of SAM."}}
{"id": "2503.13883", "pdf": "https://arxiv.org/pdf/2503.13883", "abs": "https://arxiv.org/abs/2503.13883", "authors": ["Ziyu Lin", "Yunfan Wu", "Yuhang Ma", "Junzhou Chen", "Ronghui Zhang", "Jiaming Wu", "Guodong Yin", "Liang Lin"], "title": "YOLO-LLTS: Real-Time Low-Light Traffic Sign Detection via Prior-Guided Enhancement and Multi-Branch Feature Interaction", "categories": ["cs.CV"], "comment": null, "summary": "Traffic sign detection is essential for autonomous driving and Advanced\nDriver Assistance Systems (ADAS). However, existing methods struggle with\nlow-light conditions due to issues like indistinct small-object features,\nlimited feature interaction, and poor image quality, which degrade detection\naccuracy and speed. To address this issue, we propose YOLO-LLTS, an end-to-end\nreal-time traffic sign detection algorithm specifically designed for low-light\nenvironments. YOLO-LLTS introduces three main contributions: the\nHigh-Resolution Feature Map for Small Object Detection (HRFM-SOD) module to\nenhance small-object detection by mitigating feature dilution; the Multi-branch\nFeature Interaction Attention (MFIA) module to improve information extraction\nthrough multi-scale features interaction; and the Prior-Guided Feature\nEnhancement Module (PGFE) to enhance image quality by addressing noise, low\ncontrast, and blurriness. Additionally, we construct a novel dataset, the\nChinese Nighttime Traffic Sign Sample Set (CNTSSS), covering diverse nighttime\nscenarios. Experiments show that YOLO-LLTS achieves state-of-the-art\nperformance, outperforming previous best methods by 2.7% mAP50 and 1.6%\nmAP50:95 on TT100K-night, 1.3% mAP50 and 1.9% mAP50:95 on CNTSSS, 7.5% mAP50\nand 9.8% mAP50:95 on GTSDB-night, and superior results on CCTSDB2021.\nDeployment on edge devices confirms its real-time applicability and\neffectiveness.", "AI": {"tldr": "YOLO-LLTS is a real-time traffic sign detection algorithm for low-light conditions, featuring modules for small-object detection, multi-scale feature interaction, and image quality enhancement. It outperforms existing methods on multiple datasets.", "motivation": "Existing traffic sign detection methods perform poorly in low-light due to feature dilution, limited interaction, and poor image quality, necessitating a specialized solution.", "method": "YOLO-LLTS introduces HRFM-SOD for small-object detection, MFIA for multi-scale feature interaction, and PGFE for image quality enhancement. A new dataset, CNTSSS, is also created.", "result": "YOLO-LLTS achieves state-of-the-art performance, with improvements of up to 9.8% mAP50:95 on datasets like TT100K-night and GTSDB-night. It also works effectively on edge devices.", "conclusion": "YOLO-LLTS is a robust solution for low-light traffic sign detection, offering superior accuracy, speed, and real-time applicability."}}
{"id": "2504.03668", "pdf": "https://arxiv.org/pdf/2504.03668", "abs": "https://arxiv.org/abs/2504.03668", "authors": ["Fernando Koch", "Aladin Djuhera", "Alecio Binotto"], "title": "Intelligent Orchestration of Distributed Large Foundation Model Inference at the Edge", "categories": ["cs.DC", "cs.LG"], "comment": "25 pages, 3 figures, 4 tables, 50 references", "summary": "Large Foundation Models (LFMs), including multi-modal and generative models,\npromise to unlock new capabilities for next-generation Edge AI applications.\nHowever, performing inference with LFMs in resource-constrained and\nheterogeneous edge environments, such as Multi-access Edge Computing (MEC),\npresents significant challenges for workload orchestration due to time-varying\nnetwork, compute, and storage conditions. In particular, current split\ninference strategies, which partition LFM layers across nodes, are not designed\nto adapt to fluctuating workloads, dynamic bandwidth conditions, or evolving\nprivacy constraints in high-utilization MEC environments. In this work, we\npropose a novel adaptive split inference orchestration framework that elevates\nboth the placement and partitioning of LFM layers to runtime-tunable variables.\nSpecifically, our framework enables real-time, quality-of-service (QoS)-aware\nmanagement of inference workloads by extending conventional orchestrators with\nthree key services: (1) Capacity-aware workload distribution, which\ncontinuously profiles node resources and selects an optimal subset of MEC\nnodes; (2) Dynamic partition migration, which transparently relocates pre-cut\nLFM segments in response to changes in utilization or network conditions; (3)\nReal-time reconfiguration, which dynamically re-splits LFM layers to balance\nlatency, throughput, and privacy. We formalize the joint placement-partitioning\nproblem, outline a reference architecture and algorithmic workflow, and discuss\napplicability in representative smart city, V2X, and industrial edge scenarios.", "AI": {"tldr": "Proposes an adaptive split inference orchestration framework for Large Foundation Models (LFMs) in edge environments to handle dynamic conditions.", "motivation": "Challenges in deploying LFMs in resource-constrained, heterogeneous edge environments due to fluctuating workloads, bandwidth, and privacy constraints.", "method": "Introduces a framework with three services: capacity-aware workload distribution, dynamic partition migration, and real-time reconfiguration.", "result": "Enables QoS-aware management of LFM workloads, optimizing latency, throughput, and privacy in edge scenarios.", "conclusion": "The framework addresses dynamic edge challenges, offering scalable and adaptive solutions for LFM deployment in smart city, V2X, and industrial edge applications."}}
{"id": "2503.17657", "pdf": "https://arxiv.org/pdf/2503.17657", "abs": "https://arxiv.org/abs/2503.17657", "authors": ["Yumeng Ren", "Yaofang Liu", "Aitor Artola", "Laurent Mertz", "Raymond H. Chan", "Jean-michel Morel"], "title": "Efficient Diffusion Training through Parallelization with Truncated Karhunen-Lo\u00e8ve Expansion", "categories": ["cs.CV", "I.2.0; I.4.0"], "comment": "12 pages, 9 figures", "summary": "Diffusion denoising models have become a popular approach for image\ngeneration, but they often suffer from slow convergence during training. In\nthis paper, we identify that this slow convergence is partly due to the\ncomplexity of the Brownian motion driving the forward-time process. To address\nthis, we represent the Brownian motion using the Karhunen-Lo\\`eve expansion,\ntruncating it to a limited number of eigenfunctions. We propose a novel\nordinary differential equation with augmented random initials, termed KL\ndiffusion, as a new forward-time process for training and sampling. By\ndeveloping an appropriate denoising loss function, we facilitate the\nintegration of our KL-diffusion into existing denoising-based models. Using the\nwidely adopted DDIM framework as our baseline ensures a fair comparison, as our\nmodifications focus solely on the forward process and loss function, leaving\nthe network architecture and sampling methods unchanged. Our method\nsignificantly outperforms baseline diffusion models, achieving convergence\nspeeds that are twice faster to reach the best FID score of the baseline and\nultimately yielding much lower FID scores. Notably, our approach allows for\nhighly parallelized computation, requires no additional learnable parameters,\nand can be flexibly integrated into existing diffusion methods. The code will\nbe made publicly available.", "AI": {"tldr": "The paper proposes KL diffusion, a faster-converging alternative to traditional diffusion models by simplifying the Brownian motion using the Karhunen-Lo\u00e8ve expansion.", "motivation": "Slow convergence in diffusion models due to complex Brownian motion.", "method": "Represents Brownian motion with truncated Karhunen-Lo\u00e8ve expansion, introduces KL diffusion (an ODE with augmented random initials), and adapts the denoising loss function.", "result": "Achieves twice faster convergence and lower FID scores than baseline models, with no extra parameters or architecture changes.", "conclusion": "KL diffusion is efficient, parallelizable, and easily integrable into existing methods, offering significant performance improvements."}}
{"id": "2505.05151", "pdf": "https://arxiv.org/pdf/2505.05151", "abs": "https://arxiv.org/abs/2505.05151", "authors": ["Chuangtao Chen", "Qinglin Zhao", "MengChu Zhou", "Dusit Niyato", "Zhimin He", "Haozhen Situ"], "title": "Overcoming Dimensional Factorization Limits in Discrete Diffusion Models through Quantum Joint Distribution Learning", "categories": ["quant-ph", "cs.LG"], "comment": "Comments are welcome", "summary": "Discrete diffusion models represent a significant advance in generative\nmodeling, demonstrating remarkable success in synthesizing complex,\nhigh-quality discrete data. However, to avoid exponential computational costs,\nthey typically rely on calculating per-dimension transition probabilities when\nlearning high-dimensional distributions. In this study, we rigorously prove\nthat this approach leads to a worst-case linear scaling of Kullback-Leibler\n(KL) divergence with data dimension. To address this, we propose a Quantum\nDiscrete Denoising Diffusion Probabilistic Model (QD3PM), which enables joint\nprobability learning through diffusion and denoising in exponentially large\nHilbert spaces, offering a theoretical pathway to faithfully capture the true\njoint distribution. By deriving posterior states through quantum Bayes'\ntheorem, similar to the crucial role of posterior probabilities in classical\ndiffusion models, and by learning the joint probability, we establish a solid\ntheoretical foundation for quantum-enhanced diffusion models. For denoising, we\ndesign a quantum circuit that utilizes temporal information for parameter\nsharing and incorporates learnable classical-data-controlled rotations for\nencoding. Exploiting joint distribution learning, our approach enables\nsingle-step sampling from pure noise, eliminating iterative requirements of\nexisting models. Simulations demonstrate the proposed model's superior accuracy\nin modeling complex distributions compared to factorization methods. Hence,\nthis paper establishes a new theoretical paradigm in generative models by\nleveraging the quantum advantage in joint distribution learning.", "AI": {"tldr": "The paper introduces a Quantum Discrete Denoising Diffusion Probabilistic Model (QD3PM) to address the linear scaling issue of KL divergence in classical discrete diffusion models, leveraging quantum computing for joint probability learning and single-step sampling.", "motivation": "Classical discrete diffusion models face exponential computational costs and linear KL divergence scaling with data dimension, limiting their ability to capture true joint distributions.", "method": "Proposes QD3PM, using quantum Bayes' theorem and quantum circuits for joint probability learning and denoising, enabling single-step sampling.", "result": "QD3PM outperforms factorization methods in modeling complex distributions, demonstrating superior accuracy.", "conclusion": "The paper establishes a quantum-enhanced theoretical paradigm for generative models, leveraging quantum advantages in joint distribution learning."}}
{"id": "2503.17690", "pdf": "https://arxiv.org/pdf/2503.17690", "abs": "https://arxiv.org/abs/2503.17690", "authors": ["Ziyu Yao", "Xuxin Cheng", "Zhiqi Huang", "Lei Li"], "title": "CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model", "categories": ["cs.CV"], "comment": "Accepted by CVPR 2025", "summary": "Repetitive action counting, which aims to count periodic movements in a\nvideo, is valuable for video analysis applications such as fitness monitoring.\nHowever, existing methods largely rely on regression networks with limited\nrepresentational capacity, which hampers their ability to accurately capture\nvariable periodic patterns. Additionally, their supervised learning on narrow,\nlimited training sets leads to overfitting and restricts their ability to\ngeneralize across diverse scenarios. To address these challenges, we propose\nCountLLM, the first large language model (LLM)-based framework that takes video\ndata and periodic text prompts as inputs and outputs the desired counting\nvalue. CountLLM leverages the rich clues from explicit textual instructions and\nthe powerful representational capabilities of pre-trained LLMs for repetitive\naction counting. To effectively guide CountLLM, we develop a periodicity-based\nstructured template for instructions that describes the properties of\nperiodicity and implements a standardized answer format to ensure consistency.\nAdditionally, we propose a progressive multimodal training paradigm to enhance\nthe periodicity-awareness of the LLM. Empirical evaluations on widely\nrecognized benchmarks demonstrate CountLLM's superior performance and\ngeneralization, particularly in handling novel and out-of-domain actions that\ndeviate significantly from the training data, offering a promising avenue for\nrepetitive action counting.", "AI": {"tldr": "CountLLM is a novel LLM-based framework for repetitive action counting in videos, leveraging textual prompts and pre-trained LLMs to improve accuracy and generalization.", "motivation": "Existing methods for repetitive action counting rely on regression networks with limited capacity and suffer from overfitting due to narrow training sets.", "method": "CountLLM uses video data and periodic text prompts, guided by a structured template and trained with a progressive multimodal paradigm.", "result": "CountLLM outperforms benchmarks, especially in handling novel and out-of-domain actions.", "conclusion": "CountLLM offers a promising solution for repetitive action counting with superior performance and generalization."}}
{"id": "2505.23869", "pdf": "https://arxiv.org/pdf/2505.23869", "abs": "https://arxiv.org/abs/2505.23869", "authors": ["M. S\u00fczen"], "title": "Gibbs randomness-compression proposition: An efficient deep learning", "categories": ["stat.ML", "cs.LG"], "comment": "5 pages, 5 figures", "summary": "A proposition that connects randomness and compression is put forward via\nGibbs entropy over set of measurement vectors associated with a compression\nprocess. The proposition states that a lossy compression process is equivalent\nto {\\it directed randomness} that preserves information content. The\nproposition originated from the observed behaviour in newly proposed {\\it Dual\nTomographic Compression} (DTC) compress-train framework. This is akin to\ntomographic reconstruction of layer weight matrices via building compressed\nsensed projections, via so-called {\\it weight rays}. This tomographic approach\nis applied to previous and next layers in a dual fashion, that triggers\nneuronal-level pruning. This novel model compress-train scheme appears in\niterative fashion and acts as a smart neural architecture search, The\nexperiments demonstrated the utility of this dual-tomography producing\nstate-of-the-art performance with efficient compression during training,\naccelerating and supporting lottery ticket hypothesis. However, random\ncompress-train iterations having similar performance demonstrated the\nconnection between randomness and compression from statistical physics\nperspective, we formulated the so-called {\\it Gibbs randomness-compression\nproposition}, signifying randomness-compression relationship via Gibbs entropy.\nPractically, the DTC framework provides a promising approach for massively\nenergy- and resource-efficient deep learning training.", "AI": {"tldr": "The paper connects randomness and compression via Gibbs entropy, proposing a lossy compression process as directed randomness. The Dual Tomographic Compression (DTC) framework demonstrates this, achieving efficient training and supporting the lottery ticket hypothesis.", "motivation": "To explore the relationship between randomness and compression in deep learning, inspired by the behavior of the DTC framework.", "method": "Proposes the Gibbs randomness-compression proposition and implements the DTC framework, which uses tomographic reconstruction for layer weight matrices and dual-tomography for pruning.", "result": "DTC achieves state-of-the-art performance with efficient compression during training, validating the randomness-compression connection.", "conclusion": "The DTC framework offers an energy-efficient deep learning training approach, supported by the Gibbs randomness-compression proposition."}}
{"id": "2503.18672", "pdf": "https://arxiv.org/pdf/2503.18672", "abs": "https://arxiv.org/abs/2503.18672", "authors": ["Juncen Guo", "Yang Liu", "Xiaoguang Zhu", "Lianlong Sun", "Liangyu Teng", "Jingyi Wu", "Di Li", "Linxiao Gong", "Weiwei Jiang", "Wei Zhou", "Liang Song"], "title": "CalFuse: Feature Calibration Enhanced Parameter Fusion for Class-Continual Learning", "categories": ["cs.CV"], "comment": null, "summary": "Class-Continual Learning (CCL) enables models to continuously learn new class\nknowledge while retaining previous classes, facilitating adaptation and\nevolution in dynamic, real-world environments. Traditional CCL methods\nprimarily rely on visual features, which limits their effectiveness in complex,\nmultimodal scenarios. In contrast, Vision-Language Models (VLMs) show promising\npotential for enhancing CCL by leveraging pre-trained knowledge and fusing\nmulti-modal semantic cues such as text and vision. However, existing approaches\nstruggle to mitigate catastrophic forgetting while preserving the\ngeneralization strengths of VLMs across diverse modalities. To address these\nchallenges, we propose CalFuse, a framework for feature Calibration enhanced\nparameter Fusion, which enhances dynamic knowledge fusion. CalFuse introduces a\ndynamic feature calibration mechanism that iteratively adjusts the contribution\nof original visual features to the final class decision, thereby preserving the\nmodel's intrinsic generalization capability across modalities. Simultaneously,\na parameter fusion strategy effectively fuses newly acquired knowledge with\nprior task parameters, maintaining a balance between acquiring new class\nrepresentations and preserving old knowledge. Experimental results on popular\nbenchmarks (e.g., CIFAR100 and ImageNet100) validate the superiority of the\nproposed method.", "AI": {"tldr": "CalFuse enhances Class-Continual Learning (CCL) by dynamically fusing visual and text features, mitigating catastrophic forgetting while preserving generalization across modalities.", "motivation": "Traditional CCL methods rely solely on visual features, limiting effectiveness in multimodal scenarios. Vision-Language Models (VLMs) offer potential but struggle with forgetting and generalization.", "method": "CalFuse introduces dynamic feature calibration and parameter fusion to balance new knowledge acquisition with old knowledge retention.", "result": "Experiments on CIFAR100 and ImageNet100 show CalFuse's superiority in performance.", "conclusion": "CalFuse effectively addresses CCL challenges by leveraging multimodal fusion and dynamic calibration, improving adaptability and retention."}}
{"id": "2506.01891", "pdf": "https://arxiv.org/pdf/2506.01891", "abs": "https://arxiv.org/abs/2506.01891", "authors": ["Mahmud Ashraf Shamim", "Eric A F Reinhardt", "Talal Ahmed Chowdhury", "Sergei Gleyzer", "Paulo T Araujo"], "title": "Probing Quantum Spin Systems with Kolmogorov-Arnold Neural Network Quantum States", "categories": ["quant-ph", "cond-mat.dis-nn", "cond-mat.str-el", "cs.LG"], "comment": "16 pages, 13 figures", "summary": "Neural Quantum States (NQS) are a class of variational wave functions\nparametrized by neural networks (NNs) to study quantum many-body systems. In\nthis work, we propose \\texttt{SineKAN}, a NQS \\textit{ansatz} based on\nKolmogorov-Arnold Networks (KANs), to represent quantum mechanical wave\nfunctions as nested univariate functions. We show that \\texttt{SineKAN}\nwavefunction with learnable sinusoidal activation functions can capture the\nground state energies, fidelities and various correlation functions of the one\ndimensional Transverse-Field Ising model, Anisotropic Heisenberg model, and\nAntiferromagnetic $J_{1}-J_{2}$ model with different chain lengths. In our\nstudy of the $J_1-J_2$ model with $L=100$ sites, we find that the\n\\texttt{SineKAN} model outperforms several previously explored neural quantum\nstate \\textit{ans\\\"atze}, including Restricted Boltzmann Machines (RBMs), Long\nShort-Term Memory models (LSTMs), and Multi-layer Perceptrons (MLP)\n\\textit{a.k.a.} Feed Forward Neural Networks, when compared to the results\nobtained from the Density Matrix Renormalization Group (DMRG) algorithm. We\nfind that \\texttt{SineKAN} models can be trained to high precisions and\naccuracies with minimal computational costs.", "AI": {"tldr": "The paper introduces SineKAN, a neural quantum state ansatz based on Kolmogorov-Arnold Networks, demonstrating superior performance in modeling quantum systems compared to existing methods like RBMs, LSTMs, and MLPs.", "motivation": "To improve the representation of quantum mechanical wave functions using neural networks by leveraging the nested univariate function structure of Kolmogorov-Arnold Networks.", "method": "Proposes SineKAN, a neural quantum state ansatz with learnable sinusoidal activation functions, tested on the Transverse-Field Ising model, Anisotropic Heisenberg model, and Antiferromagnetic J1-J2 model.", "result": "SineKAN outperforms RBMs, LSTMs, and MLPs in capturing ground state energies, fidelities, and correlation functions, achieving high precision with minimal computational cost.", "conclusion": "SineKAN is an efficient and accurate neural quantum state ansatz, suitable for studying quantum many-body systems."}}
{"id": "2503.20349", "pdf": "https://arxiv.org/pdf/2503.20349", "abs": "https://arxiv.org/abs/2503.20349", "authors": ["Weiyi You", "Mingyang Zhang", "Leheng Zhang", "Xingyu Zhou", "Kexuan Shi", "Shuhang Gu"], "title": "Consistency Trajectory Matching for One-Step Generative Super-Resolution", "categories": ["cs.CV"], "comment": null, "summary": "Current diffusion-based super-resolution (SR) approaches achieve commendable\nperformance at the cost of high inference overhead. Therefore, distillation\ntechniques are utilized to accelerate the multi-step teacher model into\none-step student model. Nevertheless, these methods significantly raise\ntraining costs and constrain the performance of the student model by the\nteacher model. To overcome these tough challenges, we propose Consistency\nTrajectory Matching for Super-Resolution (CTMSR), a distillation-free strategy\nthat is able to generate photo-realistic SR results in one step. Concretely, we\nfirst formulate a Probability Flow Ordinary Differential Equation (PF-ODE)\ntrajectory to establish a deterministic mapping from low-resolution (LR) images\nwith noise to high-resolution (HR) images. Then we apply the Consistency\nTraining (CT) strategy to directly learn the mapping in one step, eliminating\nthe necessity of pre-trained diffusion model. To further enhance the\nperformance and better leverage the ground-truth during the training process,\nwe aim to align the distribution of SR results more closely with that of the\nnatural images. To this end, we propose to minimize the discrepancy between\ntheir respective PF-ODE trajectories from the LR image distribution by our\nmeticulously designed Distribution Trajectory Matching (DTM) loss, resulting in\nimproved realism of our recovered HR images. Comprehensive experimental results\ndemonstrate that the proposed methods can attain comparable or even superior\ncapabilities on both synthetic and real datasets while maintaining minimal\ninference latency.", "AI": {"tldr": "CTMSR is a distillation-free method for super-resolution that uses PF-ODE trajectories and Consistency Training to achieve high-quality results in one step, outperforming diffusion-based approaches.", "motivation": "Overcoming the high inference overhead and training constraints of diffusion-based SR methods by eliminating the need for pre-trained models and distillation.", "method": "Formulates a PF-ODE trajectory for deterministic mapping from LR to HR images, applies Consistency Training for one-step learning, and introduces DTM loss to align distributions.", "result": "Achieves comparable or superior performance on synthetic and real datasets with minimal inference latency.", "conclusion": "CTMSR provides an efficient and effective alternative to diffusion-based SR methods, enhancing realism and reducing computational costs."}}
{"id": "2506.03074", "pdf": "https://arxiv.org/pdf/2506.03074", "abs": "https://arxiv.org/abs/2506.03074", "authors": ["Junghyun Lee", "Kyoungseok Jang", "Kwang-Sung Jun", "Milan Vojnovi\u0107", "Se-Young Yun"], "title": "GL-LowPopArt: A Nearly Instance-Wise Minimax-Optimal Estimator for Generalized Low-Rank Trace Regression", "categories": ["stat.ML", "cs.LG"], "comment": "64 pages, 2 figures, 3 tables", "summary": "We present `GL-LowPopArt`, a novel Catoni-style estimator for generalized\nlow-rank trace regression. Building on `LowPopArt` (Jang et al., 2024), it\nemploys a two-stage approach: nuclear norm regularization followed by matrix\nCatoni estimation. We establish state-of-the-art estimation error bounds,\nsurpassing existing guarantees (Fan et al., 2019; Kang et al., 2022), and\nreveal a novel experimental design objective, $\\mathrm{GL}(\\pi)$. The key\ntechnical challenge is controlling bias from the nonlinear inverse link\nfunction, which we address by our two-stage approach. We prove a *local*\nminimax lower bound, showing that our `GL-LowPopArt` enjoys instance-wise\noptimality up to the condition number of the ground-truth Hessian. Applications\ninclude generalized linear matrix completion, where `GL-LowPopArt` achieves a\nstate-of-the-art Frobenius error guarantee, and **bilinear dueling bandits**, a\nnovel setting inspired by general preference learning (Zhang et al., 2024). Our\nanalysis of a `GL-LowPopArt`-based explore-then-commit algorithm reveals a new,\npotentially interesting problem-dependent quantity, along with improved Borda\nregret bound than vectorization (Wu et al., 2024).", "AI": {"tldr": "GL-LowPopArt is a novel Catoni-style estimator for generalized low-rank trace regression, offering improved error bounds and optimality guarantees.", "motivation": "To address bias from nonlinear inverse link functions and improve estimation in generalized low-rank trace regression.", "method": "Two-stage approach: nuclear norm regularization followed by matrix Catoni estimation.", "result": "State-of-the-art estimation error bounds, instance-wise optimality, and improved performance in applications like matrix completion and bilinear dueling bandits.", "conclusion": "GL-LowPopArt provides a robust solution for generalized low-rank trace regression with theoretical and practical advantages."}}
{"id": "2503.22352", "pdf": "https://arxiv.org/pdf/2503.22352", "abs": "https://arxiv.org/abs/2503.22352", "authors": ["Bar\u0131\u015f Batuhan Topal", "Umut \u00d6zyurt", "Zafer Do\u011fan Budak", "Ramazan Gokberk Cinbis"], "title": "Meta-LoRA: Meta-Learning LoRA Components for Domain-Aware ID Personalization", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in text-to-image generative models, particularly latent\ndiffusion models (LDMs), have demonstrated remarkable capabilities in\nsynthesizing high-quality images from textual prompts. However, achieving\nidentity personalization-ensuring that a model consistently generates\nsubject-specific outputs from limited reference images-remains a fundamental\nchallenge. To address this, we introduce Meta-Low-Rank Adaptation (Meta-LoRA),\na novel framework that leverages meta-learning to encode domain-specific priors\ninto LoRA-based identity personalization. Our method introduces a structured\nthree-layer LoRA architecture that separates identity-agnostic knowledge from\nidentity-specific adaptation. In the first stage, the LoRA Meta-Down layers are\nmeta-trained across multiple subjects, learning a shared manifold that captures\ngeneral identity-related features. In the second stage, only the LoRA-Mid and\nLoRA-Up layers are optimized to specialize on a given subject, significantly\nreducing adaptation time while improving identity fidelity. To evaluate our\napproach, we introduce Meta-PHD, a new benchmark dataset for identity\npersonalization, and compare Meta-LoRA against state-of-the-art methods. Our\nresults demonstrate that Meta-LoRA achieves superior identity retention,\ncomputational efficiency, and adaptability across diverse identity conditions.\nOur code, model weights, and dataset are released on\nbarisbatuhan.github.io/Meta-LoRA.", "AI": {"tldr": "Meta-LoRA introduces a meta-learning framework for identity personalization in text-to-image models, improving fidelity and efficiency.", "motivation": "Addressing the challenge of consistent identity-specific outputs from limited reference images in generative models.", "method": "Uses a three-layer LoRA architecture with meta-learning to separate identity-agnostic and identity-specific knowledge, optimizing adaptation time.", "result": "Superior identity retention, computational efficiency, and adaptability compared to state-of-the-art methods.", "conclusion": "Meta-LoRA is a promising solution for identity personalization in generative models, with released resources for further research."}}
{"id": "2506.04194", "pdf": "https://arxiv.org/pdf/2506.04194", "abs": "https://arxiv.org/abs/2506.04194", "authors": ["Yang Cai", "Alkis Kalavasis", "Katerina Mamali", "Anay Mehrotra", "Manolis Zampetakis"], "title": "What Makes Treatment Effects Identifiable? Characterizations and Estimators Beyond Unconfoundedness", "categories": ["math.ST", "cs.LG", "econ.EM", "stat.ME", "stat.ML", "stat.TH"], "comment": "Accepted for presentation at the 38th Conference on Learning Theory\n  (COLT) 2025. v2 strengthens results to give a tight characterization for ATE\n  identification", "summary": "Most of the widely used estimators of the average treatment effect (ATE) in\ncausal inference rely on the assumptions of unconfoundedness and overlap.\nUnconfoundedness requires that the observed covariates account for all\ncorrelations between the outcome and treatment. Overlap requires the existence\nof randomness in treatment decisions for all individuals. Nevertheless, many\ntypes of studies frequently violate unconfoundedness or overlap, for instance,\nobservational studies with deterministic treatment decisions - popularly known\nas Regression Discontinuity designs - violate overlap.\n  In this paper, we initiate the study of general conditions that enable the\nidentification of the average treatment effect, extending beyond\nunconfoundedness and overlap. In particular, following the paradigm of\nstatistical learning theory, we provide an interpretable condition that is\nsufficient and necessary for the identification of ATE. Moreover, this\ncondition also characterizes the identification of the average treatment effect\non the treated (ATT) and can be used to characterize other treatment effects as\nwell. To illustrate the utility of our condition, we present several\nwell-studied scenarios where our condition is satisfied and, hence, we prove\nthat ATE can be identified in regimes that prior works could not capture. For\nexample, under mild assumptions on the data distributions, this holds for the\nmodels proposed by Tan (2006) and Rosenbaum (2002), and the Regression\nDiscontinuity design model introduced by Thistlethwaite and Campbell (1960).\nFor each of these scenarios, we also show that, under natural additional\nassumptions, ATE can be estimated from finite samples.\n  We believe these findings open new avenues for bridging learning-theoretic\ninsights and causal inference methodologies, particularly in observational\nstudies with complex treatment mechanisms.", "AI": {"tldr": "The paper explores general conditions for identifying the average treatment effect (ATE) beyond traditional assumptions of unconfoundedness and overlap, introducing a learning-theoretic condition that also applies to other treatment effects like ATT.", "motivation": "Many studies violate traditional assumptions (unconfoundedness and overlap), limiting ATE identification. The paper aims to extend these conditions to broader scenarios.", "method": "The authors propose a learning-theoretic condition for ATE identification, applicable to various models (e.g., Regression Discontinuity designs) and demonstrate its utility in well-studied scenarios.", "result": "The condition is shown to be sufficient and necessary for ATE identification, enabling analysis in previously unaddressed regimes (e.g., Tan 2006, Rosenbaum 2002 models). Finite-sample estimation is also feasible under additional assumptions.", "conclusion": "The findings bridge learning theory and causal inference, expanding methodologies for complex observational studies."}}
{"id": "2503.22359", "pdf": "https://arxiv.org/pdf/2503.22359", "abs": "https://arxiv.org/abs/2503.22359", "authors": ["Jiahao Xia", "Min Xu", "Wenjian Huang", "Jianguo Zhang", "Haimin Zhang", "Chunxia Xiao"], "title": "Mitigating Knowledge Discrepancies among Multiple Datasets for Task-agnostic Unified Face Alignment", "categories": ["cs.CV"], "comment": "24 Pages, 9 Figures, accepted to IJCV-2025", "summary": "Despite the similar structures of human faces, existing face alignment\nmethods cannot learn unified knowledge from multiple datasets with different\nlandmark annotations. The limited training samples in a single dataset commonly\nresult in fragile robustness in this field. To mitigate knowledge discrepancies\namong different datasets and train a task-agnostic unified face alignment\n(TUFA) framework, this paper presents a strategy to unify knowledge from\nmultiple datasets. Specifically, we calculate a mean face shape for each\ndataset. To explicitly align these mean shapes on an interpretable plane based\non their semantics, each shape is then incorporated with a group of semantic\nalignment embeddings. The 2D coordinates of these aligned shapes can be viewed\nas the anchors of the plane. By encoding them into structure prompts and\nfurther regressing the corresponding facial landmarks using image features, a\nmapping from the plane to the target faces is finally established, which\nunifies the learning target of different datasets. Consequently, multiple\ndatasets can be utilized to boost the generalization ability of the model. The\nsuccessful mitigation of discrepancies also enhances the efficiency of\nknowledge transferring to a novel dataset, significantly boosts the performance\nof few-shot face alignment. Additionally, the interpretable plane endows TUFA\nwith a task-agnostic characteristic, enabling it to locate landmarks unseen\nduring training in a zero-shot manner. Extensive experiments are carried on\nseven benchmarks and the results demonstrate an impressive improvement in face\nalignment brought by knowledge discrepancies mitigation. The code is available\nat https://github.com/Jiahao-UTS/TUFA.", "AI": {"tldr": "The paper introduces TUFA, a unified face alignment framework that mitigates knowledge discrepancies across datasets by aligning mean face shapes on an interpretable plane, improving generalization and few-shot performance.", "motivation": "Existing face alignment methods struggle with unified learning across datasets due to varying landmark annotations and limited training samples, leading to fragile robustness.", "method": "The approach calculates mean face shapes for datasets, aligns them semantically on an interpretable plane, and encodes them into structure prompts to regress landmarks, unifying learning targets.", "result": "TUFA enhances generalization, enables few-shot alignment, and supports zero-shot landmark localization, demonstrating significant improvements on seven benchmarks.", "conclusion": "The framework successfully unifies knowledge from multiple datasets, mitigating discrepancies and boosting performance in face alignment tasks."}}
{"id": "2506.13865", "pdf": "https://arxiv.org/pdf/2506.13865", "abs": "https://arxiv.org/abs/2506.13865", "authors": ["Kasidit Srimahajariyapong", "Supanut Thanasilp", "Thiparat Chotibut"], "title": "Connecting phases of matter to the flatness of the loss landscape in analog variational quantum algorithms", "categories": ["quant-ph", "cond-mat.dis-nn", "cs.LG", "cs.NE", "stat.ML"], "comment": "15+7 pages, 7+5 figures", "summary": "Variational quantum algorithms (VQAs) promise near-term quantum advantage,\nyet parametrized quantum states commonly built from the digital gate-based\napproach often suffer from scalability issues such as barren plateaus, where\nthe loss landscape becomes flat. We study an analog VQA ans\\\"atze composed of\n$M$ quenches of a disordered Ising chain, whose dynamics is native to several\nquantum simulation platforms. By tuning the disorder strength we place each\nquench in either a thermalized phase or a many-body-localized (MBL) phase and\nanalyse (i) the ans\\\"atze's expressivity and (ii) the scaling of loss variance.\nNumerics shows that both phases reach maximal expressivity at large $M$, but\nbarren plateaus emerge at far smaller $M$ in the thermalized phase than in the\nMBL phase. Exploiting this gap, we propose an MBL initialisation strategy:\ninitialise the ans\\\"atze in the MBL regime at intermediate quench $M$, enabling\nan initial trainability while retaining sufficient expressivity for subsequent\noptimization. The results link quantum phases of matter and VQA trainability,\nand provide practical guidelines for scaling analog-hardware VQAs.", "AI": {"tldr": "Analog VQA ans\u00e4tze using disordered Ising chain quenches show MBL phase avoids barren plateaus better than thermalized phase, enabling scalable trainability.", "motivation": "Address scalability issues like barren plateaus in digital gate-based VQAs by exploring analog ans\u00e4tze native to quantum simulators.", "method": "Study analog VQA ans\u00e4tze with $M$ quenches of a disordered Ising chain, tuning disorder strength to compare thermalized and MBL phases.", "result": "MBL phase avoids barren plateaus longer than thermalized phase, allowing trainability at intermediate quenches while retaining expressivity.", "conclusion": "MBL initialization strategy improves VQA scalability, linking quantum phases to trainability and guiding analog-hardware VQA design."}}
{"id": "2504.03474", "pdf": "https://arxiv.org/pdf/2504.03474", "abs": "https://arxiv.org/abs/2504.03474", "authors": ["Seyedeh Sahar Taheri Otaghsara", "Reza Rahmanzadeh"], "title": "Multi-encoder nnU-Net outperforms transformer models with self-supervised pretraining", "categories": ["cs.CV"], "comment": null, "summary": "This study addresses the essential task of medical image segmentation, which\ninvolves the automatic identification and delineation of anatomical structures\nand pathological regions in medical images. Accurate segmentation is crucial in\nradiology, as it aids in the precise localization of abnormalities such as\ntumors, thereby enabling effective diagnosis, treatment planning, and\nmonitoring of disease progression. Specifically, the size, shape, and location\nof tumors can significantly influence clinical decision-making and therapeutic\nstrategies, making accurate segmentation a key component of radiological\nworkflows. However, challenges posed by variations in MRI modalities, image\nartifacts, and the scarcity of labeled data complicate the segmentation task\nand impact the performance of traditional models. To overcome these\nlimitations, we propose a novel self-supervised learning Multi-encoder nnU-Net\narchitecture designed to process multiple MRI modalities independently through\nseparate encoders. This approach allows the model to capture modality-specific\nfeatures before fusing them for the final segmentation, thus improving\naccuracy. Our Multi-encoder nnU-Net demonstrates exceptional performance,\nachieving a Dice Similarity Coefficient (DSC) of 93.72%, which surpasses that\nof other models such as vanilla nnU-Net, SegResNet, and Swin UNETR. By\nleveraging the unique information provided by each modality, the model enhances\nsegmentation tasks, particularly in scenarios with limited annotated data.\nEvaluations highlight the effectiveness of this architecture in improving tumor\nsegmentation outcomes.", "AI": {"tldr": "A novel self-supervised Multi-encoder nnU-Net improves medical image segmentation, achieving 93.72% DSC by processing multiple MRI modalities independently.", "motivation": "Accurate segmentation of tumors in medical images is vital for diagnosis and treatment but is hindered by MRI variability and limited labeled data.", "method": "Proposes a Multi-encoder nnU-Net architecture that independently processes MRI modalities before fusing features for segmentation.", "result": "Achieves a Dice Similarity Coefficient of 93.72%, outperforming other models like vanilla nnU-Net and SegResNet.", "conclusion": "The Multi-encoder nnU-Net enhances segmentation accuracy, especially with limited annotated data, by leveraging modality-specific features."}}
{"id": "2506.16666", "pdf": "https://arxiv.org/pdf/2506.16666", "abs": "https://arxiv.org/abs/2506.16666", "authors": ["Meenatchi Sundaram Muthu Selva Annamalai", "Borja Balle", "Jamie Hayes", "Georgios Kaissis", "Emiliano De Cristofaro"], "title": "The Hitchhiker's Guide to Efficient, End-to-End, and Tight DP Auditing", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "This paper systematizes research on auditing Differential Privacy (DP)\ntechniques, aiming to identify key insights into the current state of the art\nand open challenges. First, we introduce a comprehensive framework for\nreviewing work in the field and establish three cross-contextual desiderata\nthat DP audits should target--namely, efficiency, end-to-end-ness, and\ntightness. Then, we systematize the modes of operation of state-of-the-art DP\nauditing techniques, including threat models, attacks, and evaluation\nfunctions. This allows us to highlight key details overlooked by prior work,\nanalyze the limiting factors to achieving the three desiderata, and identify\nopen research problems. Overall, our work provides a reusable and systematic\nmethodology geared to assess progress in the field and identify friction points\nand future directions for our community to focus on.", "AI": {"tldr": "A systematic review of auditing Differential Privacy (DP) techniques, identifying key insights, open challenges, and future research directions.", "motivation": "To organize and evaluate the current state of DP auditing, addressing gaps and establishing a framework for future research.", "method": "Introduces a framework with three desiderata (efficiency, end-to-end-ness, tightness), systematizes DP auditing techniques, and analyzes limitations.", "result": "Highlights overlooked details, limiting factors, and open problems in DP auditing.", "conclusion": "Provides a reusable methodology to assess progress and guide future research in DP auditing."}}
{"id": "2504.04801", "pdf": "https://arxiv.org/pdf/2504.04801", "abs": "https://arxiv.org/abs/2504.04801", "authors": ["Jinhong Wang", "Shuo Tong", "Jian liu", "Dongqi Tang", "Weiqiang Wang", "Wentong Li", "Hongxia Xu", "Danny Chen", "Jintai Chen", "Jian Wu"], "title": "OrderChain: Towards General Instruct-Tuning for Stimulating the Ordinal Understanding Ability of MLLM", "categories": ["cs.CV"], "comment": null, "summary": "Despite the remarkable progress of multimodal large language models (MLLMs),\nthey continue to face challenges in achieving competitive performance on\nordinal regression (OR; a.k.a. ordinal classification). To address this issue,\nthis paper presents OrderChain, a novel and general prompting paradigm that\nimproves the ordinal understanding ability of MLLMs by specificity and\ncommonality modeling. Specifically, our OrderChain consists of a set of\ntask-aware prompts to facilitate the specificity modeling of diverse OR tasks\nand a new range optimization Chain-of-Thought (RO-CoT), which learns a\ncommonality way of thinking about OR tasks by uniformly decomposing them into\nmultiple small-range optimization subtasks. Further, we propose a category\nrecursive division (CRD) method to generate instruction candidate category\nprompts to support RO-CoT automatic optimization. Comprehensive experiments\nshow that a Large Language and Vision Assistant (LLaVA) model with our\nOrderChain improves baseline LLaVA significantly on diverse OR datasets, e.g.,\nfrom 47.5% to 93.2% accuracy on the Adience dataset for age estimation, and\nfrom 30.0% to 85.7% accuracy on the Diabetic Retinopathy dataset. Notably,\nLLaVA with our OrderChain also remarkably outperforms state-of-the-art methods\nby 27% on accuracy and 0.24 on MAE on the Adience dataset. To our best\nknowledge, our OrderChain is the first work that augments MLLMs for OR tasks,\nand the effectiveness is witnessed across a spectrum of OR datasets.", "AI": {"tldr": "OrderChain is a novel prompting paradigm enhancing MLLMs' ordinal regression performance via specificity and commonality modeling, achieving significant accuracy improvements.", "motivation": "Address the underperformance of MLLMs in ordinal regression tasks by improving their ordinal understanding.", "method": "Introduces OrderChain with task-aware prompts and RO-CoT for commonality modeling, plus CRD for automatic optimization.", "result": "Substantial accuracy gains, e.g., 93.2% on Adience (age estimation) and outperforms SOTA by 27%.", "conclusion": "OrderChain effectively augments MLLMs for OR tasks, demonstrating broad applicability and superior performance."}}
{"id": "2506.19340", "pdf": "https://arxiv.org/pdf/2506.19340", "abs": "https://arxiv.org/abs/2506.19340", "authors": ["Jiahui Hu", "Wenjun Dong"], "title": "CAM-NET: An AI Model for Whole Atmosphere with Thermosphere and Ionosphere Extension", "categories": ["physics.space-ph", "cs.LG"], "comment": null, "summary": "We present Compressible Atmospheric Model-Network (CAM-NET), an AI model\ndesigned to predict neutral atmospheric variables from the Earth's surface to\nthe ionosphere with high accuracy and computational efficiency. Accurate\nmodeling of the entire atmosphere is critical for understanding the upward\npropagation of gravity waves, which influence upper-atmospheric dynamics and\ncoupling across atmospheric layers. CAM-NET leverages the Spherical Fourier\nNeural Operator (SFNO) to capture global-scale atmospheric dynamics while\npreserving the Earth's spherical structure. Trained on a decade of datasets\nfrom the Whole Atmosphere Community Climate Model with thermosphere and\nionosphere eXtension (WACCM-X), CAM-NET demonstrates accuracy comparable to\nWACCM-X while achieving a speedup of over 1000x in inference time, can provide\none year simulation within a few minutes once trained. The model effectively\npredicts key atmospheric parameters, including zonal and meridional winds,\ntemperature, and time rate of pressure. Inspired by traditional modeling\napproaches that use external couplers to simulate tracer transport, CAM-NET\nintroduces a modular architecture that explicitly separates tracer prediction\nfrom core dynamics. The core backbone of CAM-NET focuses on forecasting primary\nphysical variables (e.g., temperature, wind velocity), while tracer variables\nare predicted through a lightweight, fine-tuned model. This design allows for\nefficient adaptation to specific tracer scenarios with minimal computational\ncost, avoiding the need to retrain the entire model. We have validated this\napproach on the $O^2$ tracer, demonstrating strong performance and\ngeneralization capabilities.", "AI": {"tldr": "CAM-NET is an AI model using SFNO for efficient, high-accuracy prediction of atmospheric variables, achieving 1000x speedup over WACCM-X while maintaining accuracy.", "motivation": "Accurate modeling of the entire atmosphere is needed to understand gravity wave propagation and atmospheric coupling.", "method": "CAM-NET uses SFNO for global dynamics, modular architecture for tracer separation, and is trained on WACCM-X data.", "result": "Achieves WACCM-X accuracy with 1000x faster inference, validated on O2 tracer.", "conclusion": "CAM-NET offers efficient, modular atmospheric modeling with strong generalization."}}
{"id": "2504.05040", "pdf": "https://arxiv.org/pdf/2504.05040", "abs": "https://arxiv.org/abs/2504.05040", "authors": ["Haiwan Wei", "Yitian Yuan", "Xiaohan Lan", "Wei Ke", "Lin Ma"], "title": "InstructionBench: An Instructional Video Understanding Benchmark", "categories": ["cs.CV"], "comment": null, "summary": "Despite progress in video large language models (Video-LLMs), research on\ninstructional video understanding, crucial for enhancing access to\ninstructional content, remains insufficient. To address this, we introduce\nInstructionBench, an Instructional video understanding Benchmark, which\nchallenges models' advanced temporal reasoning within instructional videos\ncharacterized by their strict step-by-step flow. Employing GPT-4, we formulate\nQ&A pairs in open-ended and multiple-choice formats to assess both\nCoarse-Grained event-level and Fine-Grained object-level reasoning. Our\nfiltering strategies exclude questions answerable purely by common-sense\nknowledge, focusing on visual perception and analysis when evaluating Video-LLM\nmodels. The benchmark finally contains 5k questions across over 700 videos. We\nevaluate the latest Video-LLMs on our InstructionBench, finding that\nclosed-source models outperform open-source ones. However, even the best model,\nGPT-4o, achieves only 53.42% accuracy, indicating significant gaps in temporal\nreasoning. To advance the field, we also develop a comprehensive instructional\nvideo dataset with over 19k Q&A pairs from nearly 2.5k videos, using an\nautomated data generation framework, thereby enriching the community's research\nresources. All data are available at\nhttps://huggingface.co/datasets/sunwhw/InstructionBench.", "AI": {"tldr": "InstructionBench is a benchmark for evaluating Video-LLMs' temporal reasoning in instructional videos, featuring 5k questions across 700+ videos. Closed-source models outperform open-source ones, but even GPT-4o achieves only 53.42% accuracy. A larger dataset of 19k Q&A pairs is also introduced.", "motivation": "To address the lack of research on instructional video understanding, crucial for improving access to instructional content.", "method": "Uses GPT-4 to create Q&A pairs (open-ended and multiple-choice) for evaluating coarse-grained event-level and fine-grained object-level reasoning. Filters exclude common-sense questions to focus on visual perception.", "result": "Closed-source models outperform open-source ones, with GPT-4o achieving 53.42% accuracy, highlighting gaps in temporal reasoning.", "conclusion": "InstructionBench and the larger dataset aim to advance research in instructional video understanding by providing robust evaluation tools and resources."}}
{"id": "2506.20533", "pdf": "https://arxiv.org/pdf/2506.20533", "abs": "https://arxiv.org/abs/2506.20533", "authors": ["Gilad Lerman", "Kang Li", "Tyler Maunu", "Teng Zhang"], "title": "Global Convergence of Iteratively Reweighted Least Squares for Robust Subspace Recovery", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": null, "summary": "Robust subspace estimation is fundamental to many machine learning and data\nanalysis tasks. Iteratively Reweighted Least Squares (IRLS) is an elegant and\nempirically effective approach to this problem, yet its theoretical properties\nremain poorly understood. This paper establishes that, under deterministic\nconditions, a variant of IRLS with dynamic smoothing regularization converges\nlinearly to the underlying subspace from any initialization. We extend these\nguarantees to affine subspace estimation, a setting that lacks prior recovery\ntheory. Additionally, we illustrate the practical benefits of IRLS through an\napplication to low-dimensional neural network training. Our results provide the\nfirst global convergence guarantees for IRLS in robust subspace recovery and,\nmore broadly, for nonconvex IRLS on a Riemannian manifold.", "AI": {"tldr": "The paper provides global convergence guarantees for a variant of IRLS in robust subspace estimation, extending to affine subspaces and demonstrating practical utility in neural network training.", "motivation": "Understanding the theoretical properties of IRLS for robust subspace estimation, which lacks prior recovery theory, especially in affine subspaces.", "method": "A variant of IRLS with dynamic smoothing regularization, analyzed under deterministic conditions for linear convergence.", "result": "Linear convergence to the underlying subspace from any initialization, with extensions to affine subspaces and practical benefits in neural network training.", "conclusion": "First global convergence guarantees for IRLS in robust subspace recovery and nonconvex IRLS on Riemannian manifolds."}}
{"id": "2504.11134", "pdf": "https://arxiv.org/pdf/2504.11134", "abs": "https://arxiv.org/abs/2504.11134", "authors": ["Gustav Hanning", "Gabrielle Flood", "Viktor Larsson"], "title": "Visual Re-Ranking with Non-Visual Side Information", "categories": ["cs.CV", "I.4"], "comment": "Accepted at Scandinavian Conference on Image Analysis (SCIA) 2025", "summary": "The standard approach for visual place recognition is to use global image\ndescriptors to retrieve the most similar database images for a given query\nimage. The results can then be further improved with re-ranking methods that\nre-order the top scoring images. However, existing methods focus on re-ranking\nbased on the same image descriptors that were used for the initial retrieval,\nwhich we argue provides limited additional signal. In this work we propose\nGeneralized Contextual Similarity Aggregation (GCSA), which is a graph neural\nnetwork-based re-ranking method that, in addition to the visual descriptors,\ncan leverage other types of available side information. This can for example be\nother sensor data (such as signal strength of nearby WiFi or BlueTooth\nendpoints) or geometric properties such as camera poses for database images. In\nmany applications this information is already present or can be acquired with\nlow effort. Our architecture leverages the concept of affinity vectors to allow\nfor a shared encoding of the heterogeneous multi-modal input. Two large-scale\ndatasets, covering both outdoor and indoor localization scenarios, are utilized\nfor training and evaluation. In experiments we show significant improvement not\nonly on image retrieval metrics, but also for the downstream visual\nlocalization task.", "AI": {"tldr": "GCSA is a graph neural network-based re-ranking method for visual place recognition that leverages multi-modal side information, improving retrieval and localization tasks.", "motivation": "Existing re-ranking methods rely on the same descriptors as initial retrieval, limiting improvement. GCSA aims to utilize additional side information for better performance.", "method": "Proposes GCSA, a graph neural network that aggregates heterogeneous multi-modal inputs (e.g., sensor data, geometric properties) using affinity vectors.", "result": "Significant improvements in image retrieval metrics and downstream visual localization on large-scale datasets.", "conclusion": "GCSA effectively enhances re-ranking by incorporating diverse side information, benefiting both retrieval and localization tasks."}}
{"id": "2504.11346", "pdf": "https://arxiv.org/pdf/2504.11346", "abs": "https://arxiv.org/abs/2504.11346", "authors": ["Yu Gao", "Lixue Gong", "Qiushan Guo", "Xiaoxia Hou", "Zhichao Lai", "Fanshi Li", "Liang Li", "Xiaochen Lian", "Chao Liao", "Liyang Liu", "Wei Liu", "Yichun Shi", "Shiqi Sun", "Yu Tian", "Zhi Tian", "Peng Wang", "Rui Wang", "Xuanda Wang", "Xun Wang", "Ye Wang", "Guofeng Wu", "Jie Wu", "Xin Xia", "Xuefeng Xiao", "Zhonghua Zhai", "Xinyu Zhang", "Qi Zhang", "Yuwei Zhang", "Shijia Zhao", "Jianchao Yang", "Weilin Huang"], "title": "Seedream 3.0 Technical Report", "categories": ["cs.CV"], "comment": "Seedream 3.0 Technical Report", "summary": "We present Seedream 3.0, a high-performance Chinese-English bilingual image\ngeneration foundation model. We develop several technical improvements to\naddress existing challenges in Seedream 2.0, including alignment with\ncomplicated prompts, fine-grained typography generation, suboptimal visual\naesthetics and fidelity, and limited image resolutions. Specifically, the\nadvancements of Seedream 3.0 stem from improvements across the entire pipeline,\nfrom data construction to model deployment. At the data stratum, we double the\ndataset using a defect-aware training paradigm and a dual-axis collaborative\ndata-sampling framework. Furthermore, we adopt several effective techniques\nsuch as mixed-resolution training, cross-modality RoPE, representation\nalignment loss, and resolution-aware timestep sampling in the pre-training\nphase. During the post-training stage, we utilize diversified aesthetic\ncaptions in SFT, and a VLM-based reward model with scaling, thereby achieving\noutputs that well align with human preferences. Furthermore, Seedream 3.0\npioneers a novel acceleration paradigm. By employing consistent noise\nexpectation and importance-aware timestep sampling, we achieve a 4 to 8 times\nspeedup while maintaining image quality. Seedream 3.0 demonstrates significant\nimprovements over Seedream 2.0: it enhances overall capabilities, in particular\nfor text-rendering in complicated Chinese characters which is important to\nprofessional typography generation. In addition, it provides native\nhigh-resolution output (up to 2K), allowing it to generate images with high\nvisual quality.", "AI": {"tldr": "Seedream 3.0 is an advanced Chinese-English bilingual image generation model with improved alignment, typography, aesthetics, and resolution, achieving faster speeds and higher quality outputs.", "motivation": "Addressing limitations in Seedream 2.0, such as alignment with complex prompts, typography generation, visual aesthetics, and resolution.", "method": "Enhancements include data doubling, mixed-resolution training, cross-modality RoPE, representation alignment loss, and novel acceleration techniques like consistent noise expectation.", "result": "Significant improvements over Seedream 2.0, including better text-rendering, high-resolution output (up to 2K), and 4-8x speedup without quality loss.", "conclusion": "Seedream 3.0 outperforms its predecessor with superior capabilities, making it suitable for professional typography and high-quality image generation."}}
{"id": "2504.19938", "pdf": "https://arxiv.org/pdf/2504.19938", "abs": "https://arxiv.org/abs/2504.19938", "authors": ["Yunfei Wan", "Jianheng Liu", "Chunran Zheng", "Jiarong Lin", "Fu Zhang"], "title": "Mesh-Learner: Texturing Mesh with Spherical Harmonics", "categories": ["cs.CV", "cs.RO"], "comment": "IROS2025 Accepted", "summary": "In this paper, we present a 3D reconstruction and rendering framework termed\nMesh-Learner that is natively compatible with traditional rasterization\npipelines. It integrates mesh and spherical harmonic (SH) texture (i.e.,\ntexture filled with SH coefficients) into the learning process to learn each\nmesh s view-dependent radiance end-to-end. Images are rendered by interpolating\nsurrounding SH Texels at each pixel s sampling point using a novel\ninterpolation method. Conversely, gradients from each pixel are back-propagated\nto the related SH Texels in SH textures. Mesh-Learner exploits graphic features\nof rasterization pipeline (texture sampling, deferred rendering) to render,\nwhich makes Mesh-Learner naturally compatible with tools (e.g., Blender) and\ntasks (e.g., 3D reconstruction, scene rendering, reinforcement learning for\nrobotics) that are based on rasterization pipelines. Our system can train vast,\nunlimited scenes because we transfer only the SH textures within the frustum to\nthe GPU for training. At other times, the SH textures are stored in CPU RAM,\nwhich results in moderate GPU memory usage. The rendering results on\ninterpolation and extrapolation sequences in the Replica and FAST-LIVO2\ndatasets achieve state-of-the-art performance compared to existing\nstate-of-the-art methods (e.g., 3D Gaussian Splatting and M2-Mapping). To\nbenefit the society, the code will be available at\nhttps://github.com/hku-mars/Mesh-Learner.", "AI": {"tldr": "Mesh-Learner is a 3D reconstruction and rendering framework using mesh and spherical harmonic textures, compatible with rasterization pipelines and achieving state-of-the-art results.", "motivation": "To create a framework that integrates mesh and SH textures for view-dependent radiance learning, ensuring compatibility with rasterization pipelines and tools like Blender.", "method": "Uses mesh and SH textures with a novel interpolation method for rendering and back-propagates gradients to SH Texels. Transfers only necessary SH textures to GPU for training, optimizing memory usage.", "result": "Achieves state-of-the-art performance on Replica and FAST-LIVO2 datasets, outperforming methods like 3D Gaussian Splatting and M2-Mapping.", "conclusion": "Mesh-Learner is efficient, scalable, and compatible with existing tools, making it suitable for various applications like 3D reconstruction and robotics."}}
{"id": "2505.09450", "pdf": "https://arxiv.org/pdf/2505.09450", "abs": "https://arxiv.org/abs/2505.09450", "authors": ["Yuelin Zhang", "Qingpeng Ding", "Long Lei", "Yongxuan Feng", "Raymond Shing-Yan Tang", "Shing Shin Cheng"], "title": "MrTrack: Register Mamba for Needle Tracking with Rapid Reciprocating Motion during Ultrasound-Guided Aspiration Biopsy", "categories": ["cs.CV"], "comment": "Early Accepted by MICCAI 2025", "summary": "Ultrasound-guided fine needle aspiration (FNA) biopsy is a common minimally\ninvasive diagnostic procedure. However, an aspiration needle tracker addressing\nrapid reciprocating motion is still missing. MrTrack, an aspiration needle\ntracker with a mamba-based register mechanism, is proposed. MrTrack leverages a\nMamba-based register extractor to sequentially distill global context from each\nhistorical search map, storing these temporal cues in a register bank. The\nMamba-based register retriever then retrieves temporal prompts from the\nregister bank to provide external cues when current vision features are\ntemporarily unusable due to rapid reciprocating motion and imaging degradation.\nA self-supervised register diversify loss is proposed to encourage feature\ndiversity and dimension independence within the learned register, mitigating\nfeature collapse. Comprehensive experiments conducted on both robotic and\nmanual aspiration biopsy datasets demonstrate that MrTrack not only outperforms\nstate-of-the-art trackers in accuracy and robustness but also achieves superior\ninference efficiency. Project page: https://github.com/PieceZhang/MrTrack", "AI": {"tldr": "MrTrack is a novel aspiration needle tracker using a Mamba-based register mechanism to handle rapid reciprocating motion in ultrasound-guided FNA biopsies, outperforming existing methods in accuracy and efficiency.", "motivation": "Current ultrasound-guided FNA biopsies lack a needle tracker capable of handling rapid reciprocating motion, leading to degraded imaging and unreliable tracking.", "method": "MrTrack employs a Mamba-based register extractor and retriever to distill and utilize temporal context from historical search maps, alongside a self-supervised loss for feature diversity.", "result": "MrTrack surpasses state-of-the-art trackers in accuracy, robustness, and inference efficiency on robotic and manual biopsy datasets.", "conclusion": "MrTrack effectively addresses the challenge of rapid reciprocating motion in FNA biopsies, offering a reliable and efficient tracking solution."}}
{"id": "2505.11640", "pdf": "https://arxiv.org/pdf/2505.11640", "abs": "https://arxiv.org/abs/2505.11640", "authors": ["Pandula Thennakoon", "Avishka Ranasinghe", "Mario De Silva", "Buwaneka Epakanda", "Roshan Godaliyadda", "Parakrama Ekanayake", "Vijitha Herath"], "title": "BandRC: Band Shifted Raised Cosine Activated Implicit Neural Representations", "categories": ["cs.CV"], "comment": null, "summary": "In recent years, implicit neural representations (INRs) have gained\npopularity in the computer vision community. This is mainly due to the strong\nperformance of INRs in many computer vision tasks. These networks can extract a\ncontinuous signal representation given a discrete signal representation. In\nprevious studies, it has been repeatedly shown that INR performance has a\nstrong correlation with the activation functions used in its multilayer\nperceptrons. Although numerous activation functions have been proposed that are\ncompetitive with one another, they share some common set of challenges such as\nspectral bias(Lack of sensitivity to high-frequency content in signals),\nlimited robustness to signal noise and difficulties in simultaneous capturing\nboth local and global features. and furthermore, the requirement for manual\nparameter tuning. To address these issues, we introduce a novel activation\nfunction, Band Shifted Raised Cosine Activated Implicit Neural Networks\n$\\textbf{(BandRC)}$ tailored to enhance signal representation capacity further.\nWe also incorporate deep prior knowledge extracted from the signal to adjust\nthe activation functions through a task-specific model. Through a mathematical\nanalysis and a series of experiments which include image reconstruction (with\nan average PSNR improvement of +5.67 dB over the nearest counterpart across a\ndiverse image dataset), denoising (with a +0.46 dB increase in PSNR),\nsuper-resolution (with a +1.03 dB improvement over the nearest State-Of-The-Art\n(SOTA) method for 6X super-resolution), inpainting, and 3D shape reconstruction\nwe demonstrate the dominance of BandRC over existing state of the art\nactivation functions.", "AI": {"tldr": "The paper introduces BandRC, a novel activation function for implicit neural representations (INRs), addressing challenges like spectral bias, noise robustness, and feature capture. It outperforms existing methods in tasks like image reconstruction, denoising, and super-resolution.", "motivation": "Existing activation functions in INRs face issues like spectral bias, noise sensitivity, and difficulty in capturing both local and global features, along with manual tuning requirements.", "method": "The authors propose BandRC, a tailored activation function, and integrate deep prior knowledge for task-specific adjustments.", "result": "BandRC shows significant improvements: +5.67 dB in image reconstruction, +0.46 dB in denoising, and +1.03 dB in super-resolution over SOTA methods.", "conclusion": "BandRC effectively enhances INR performance, outperforming existing activation functions across multiple vision tasks."}}
{"id": "2505.18561", "pdf": "https://arxiv.org/pdf/2505.18561", "abs": "https://arxiv.org/abs/2505.18561", "authors": ["Shiu-hong Kao", "Yu-Wing Tai", "Chi-Keung Tang"], "title": "ThinkVideo: High-Quality Reasoning Video Segmentation with Chain of Thoughts", "categories": ["cs.CV"], "comment": "Project page: https://danielshkao.github.io/thinkvideo.html", "summary": "Reasoning Video Object Segmentation is a challenging task, which generates a\nmask sequence from an input video and an implicit, complex text query. Existing\nworks probe into the problem by finetuning Multimodal Large Language Models\n(MLLM) for segmentation-based output, while still falling short in difficult\ncases on videos given temporally-sensitive queries, primarily due to the\nfailure to integrate temporal and spatial information. In this paper, we\npropose ThinkVideo, a novel framework which leverages the zero-shot\nChain-of-Thought (CoT) capability of MLLM to address these challenges.\nSpecifically, ThinkVideo utilizes the CoT prompts to extract object\nselectivities associated with particular keyframes, then bridging the reasoning\nimage segmentation model and SAM2 video processor to output mask sequences. The\nThinkVideo framework is training-free and compatible with closed-source MLLMs,\nwhich can be applied to Reasoning Video Instance Segmentation. We further\nextend the framework for online video streams, where the CoT is used to update\nthe object of interest when a better target starts to emerge and becomes\nvisible. We conduct extensive experiments on video object segmentation with\nexplicit and implicit queries. The results show that ThinkVideo significantly\noutperforms previous works in both cases, qualitatively and quantitatively.", "AI": {"tldr": "ThinkVideo is a training-free framework using MLLM's zero-shot Chain-of-Thought (CoT) to improve Reasoning Video Object Segmentation by integrating temporal and spatial information.", "motivation": "Existing methods fail in temporally-sensitive queries due to poor integration of temporal and spatial data.", "method": "ThinkVideo uses CoT prompts to extract object selectivities from keyframes, combining reasoning image segmentation and SAM2 video processing for mask sequences.", "result": "ThinkVideo outperforms previous works in video object segmentation with explicit and implicit queries.", "conclusion": "ThinkVideo offers a robust, training-free solution for complex video segmentation tasks, even in online streams."}}
{"id": "2505.20272", "pdf": "https://arxiv.org/pdf/2505.20272", "abs": "https://arxiv.org/abs/2505.20272", "authors": ["Meng Cao", "Haoze Zhao", "Can Zhang", "Xiaojun Chang", "Ian Reid", "Xiaodan Liang"], "title": "Ground-R1: Incentivizing Grounded Visual Reasoning via Reinforcement Learning", "categories": ["cs.CV"], "comment": null, "summary": "Large Vision-Language Models (LVLMs) have demonstrated impressive general\ncapabilities across a wide range of multi-modal tasks. However, the reasoning\nprocesses of LVLMs often suffer from unreliable outputs and limited\ninterpretability. To address this, grounded visual reasoning has emerged as a\npromising paradigm that enforces responses anchored on salient visual evidence\nregions. However, existing approaches typically rely on costly supervision such\nas bounding box annotations, chain-of-thought rationale or external tool calls,\nlimiting their scalability. In this work, we propose Ground-R1, a reinforcement\nlearning framework that enables grounded visual reasoning without requiring\nexplicit evidence or rationale annotations. Ground-R1 consists of a grounding\nphase that generates evidence region rollouts based on format constraints, and\nan answering phase that produces responses guided by both answer correctness\nand format adherence rewards. Extensive experiments across multiple visual\nreasoning benchmarks manifest that Ground-R1 achieves superior performance and\nexhibits emergent cognitive behaviors such as uncertainty awareness, spatial\nperception, and iterative refinement, offering a scalable and interpretable\nalternative to existing approaches.", "AI": {"tldr": "Ground-R1 is a reinforcement learning framework for grounded visual reasoning in LVLMs, eliminating the need for costly annotations and achieving superior performance with emergent cognitive behaviors.", "motivation": "Address unreliable outputs and limited interpretability in LVLMs by enabling grounded visual reasoning without expensive supervision like bounding boxes or external tools.", "method": "Proposes Ground-R1, a two-phase RL framework: grounding phase generates evidence regions, and answering phase produces responses guided by correctness and format adherence rewards.", "result": "Achieves superior performance on visual reasoning benchmarks and exhibits cognitive behaviors like uncertainty awareness and spatial perception.", "conclusion": "Ground-R1 offers a scalable, interpretable alternative to existing methods for grounded visual reasoning in LVLMs."}}
{"id": "2505.22046", "pdf": "https://arxiv.org/pdf/2505.22046", "abs": "https://arxiv.org/abs/2505.22046", "authors": ["Ashkan Taghipour", "Morteza Ghahremani", "Mohammed Bennamoun", "Farid Boussaid", "Aref Miri Rekavandi", "Zinuo Li", "Qiuhong Ke", "Hamid Laga"], "title": "LatentMove: Towards Complex Human Movement Video Generation", "categories": ["cs.CV"], "comment": "The authors are withdrawing this paper due to major issues in the\n  experiments and methodology. To prevent citation of this outdated and flawed\n  version, we have decided to remove it while we work on a substantial\n  revision. Thank you", "summary": "Image-to-video (I2V) generation seeks to produce realistic motion sequences\nfrom a single reference image. Although recent methods exhibit strong temporal\nconsistency, they often struggle when dealing with complex, non-repetitive\nhuman movements, leading to unnatural deformations. To tackle this issue, we\npresent LatentMove, a DiT-based framework specifically tailored for highly\ndynamic human animation. Our architecture incorporates a conditional control\nbranch and learnable face/body tokens to preserve consistency as well as\nfine-grained details across frames. We introduce Complex-Human-Videos (CHV), a\ndataset featuring diverse, challenging human motions designed to benchmark the\nrobustness of I2V systems. We also introduce two metrics to assess the flow and\nsilhouette consistency of generated videos with their ground truth.\nExperimental results indicate that LatentMove substantially improves human\nanimation quality--particularly when handling rapid, intricate\nmovements--thereby pushing the boundaries of I2V generation. The code, the CHV\ndataset, and the evaluation metrics will be available at https://github.com/\n--.", "AI": {"tldr": "LatentMove is a DiT-based framework for dynamic human animation in I2V generation, addressing unnatural deformations with a conditional control branch and learnable tokens. It introduces the CHV dataset and new metrics for evaluation.", "motivation": "Existing I2V methods struggle with complex, non-repetitive human movements, leading to unnatural deformations.", "method": "LatentMove uses a DiT-based framework with a conditional control branch and learnable face/body tokens for consistency. The CHV dataset and new metrics evaluate robustness.", "result": "LatentMove improves human animation quality, especially for rapid, intricate movements.", "conclusion": "LatentMove advances I2V generation by handling dynamic human motions better, with code, dataset, and metrics made available."}}
{"id": "2506.03660", "pdf": "https://arxiv.org/pdf/2506.03660", "abs": "https://arxiv.org/abs/2506.03660", "authors": ["Wei Luo", "Haiming Yao", "Yunkang Cao", "Qiyu Chen", "Ang Gao", "Weiming Shen", "Wenyong Yu"], "title": "INP-Former++: Advancing Universal Anomaly Detection via Intrinsic Normal Prototypes and Residual Learning", "categories": ["cs.CV"], "comment": "15 pages, 11 figures, 13 tables", "summary": "Anomaly detection (AD) is essential for industrial inspection and medical\ndiagnosis, yet existing methods typically rely on ``comparing'' test images to\nnormal references from a training set. However, variations in appearance and\npositioning often complicate the alignment of these references with the test\nimage, limiting detection accuracy. We observe that most anomalies manifest as\nlocal variations, meaning that even within anomalous images, valuable normal\ninformation remains. We argue that this information is useful and may be more\naligned with the anomalies since both the anomalies and the normal information\noriginate from the same image. Therefore, rather than relying on external\nnormality from the training set, we propose INP-Former, a novel method that\nextracts Intrinsic Normal Prototypes (INPs) directly from the test image.\nSpecifically, we introduce the INP Extractor, which linearly combines normal\ntokens to represent INPs. We further propose an INP Coherence Loss to ensure\nINPs can faithfully represent normality for the testing image. These INPs then\nguide the INP-guided Decoder to reconstruct only normal tokens, with\nreconstruction errors serving as anomaly scores. Additionally, we propose a\nSoft Mining Loss to prioritize hard-to-optimize samples during training.\nINP-Former achieves state-of-the-art performance in single-class, multi-class,\nand few-shot AD tasks across MVTec-AD, VisA, and Real-IAD, positioning it as a\nversatile and universal solution for AD. Remarkably, INP-Former also\ndemonstrates some zero-shot AD capability. Furthermore, we propose a soft\nversion of the INP Coherence Loss and enhance INP-Former by incorporating\nresidual learning, leading to the development of INP-Former++. The proposed\nmethod significantly improves detection performance across single-class,\nmulti-class, semi-supervised, few-shot, and zero-shot settings.", "AI": {"tldr": "INP-Former is a novel anomaly detection method that extracts Intrinsic Normal Prototypes (INPs) directly from test images, avoiding reliance on external references. It achieves state-of-the-art performance across various tasks and demonstrates zero-shot capability.", "motivation": "Existing anomaly detection methods rely on comparing test images to training-set references, which limits accuracy due to alignment issues. INP-Former leverages intrinsic normal information within test images for better alignment and accuracy.", "method": "INP-Former uses an INP Extractor to derive normal prototypes from test images, an INP Coherence Loss for faithful representation, and an INP-guided Decoder for reconstruction. A Soft Mining Loss prioritizes hard samples during training.", "result": "INP-Former achieves top performance in single-class, multi-class, and few-shot tasks on datasets like MVTec-AD, VisA, and Real-IAD. It also shows zero-shot capability. INP-Former++ further enhances performance.", "conclusion": "INP-Former offers a versatile and universal solution for anomaly detection by leveraging intrinsic normal information, outperforming existing methods and extending to zero-shot scenarios."}}
{"id": "2506.04953", "pdf": "https://arxiv.org/pdf/2506.04953", "abs": "https://arxiv.org/abs/2506.04953", "authors": ["Hong Gao", "Yiming Bao", "Xuezhen Tu", "Bin Zhong", "Minling Zhang"], "title": "APVR: Hour-Level Long Video Understanding with Adaptive Pivot Visual Information Retrieval", "categories": ["cs.CV"], "comment": null, "summary": "Current multimodal large language models (MLLMs) struggle with hour-level\nvideo understanding, facing significant challenges not only in modeling the\nsubstantial information volume of long videos but also in overcoming the memory\nwall and resource constraints during both training and inference. Although\nrecent training-free approaches have alleviated resource demands by compressing\nvisual features, their reliance on incomplete visual information limits the\nperformance potential. To address these limitations, we propose\n\\textbf{A}daptive \\textbf{P}ivot \\textbf{V}isual information \\textbf{R}etrieval\n(\\textbf{APVR}), a training-free framework that hierarchically retrieves and\nretains sufficient and important visual information. It breakthroughs the\nmemory wall limitation via two complementary components: Pivot Frame Retrieval\nemploys query expansion and iterative spatio-semantic confidence scoring to\nidentify relevant video frames, and Pivot Token Retrieval performs query-aware\nattention-driven token selection within up to 1024 pivot frames. This dual\ngranularity approach enables the processing of hour-long videos while\nmaintaining semantic fidelity. Experimental validations demonstrate significant\nperformance improvements, achieving 64.9\\% on LongVideoBench and 68.4\\% on\nVideoMME, which are state-of-the-art results for both training-free and\ntraining-based approaches. Meanwhile, our method provides plug-and-play\nintegration capability with existing MLLM architectures.", "AI": {"tldr": "APVR is a training-free framework for hour-level video understanding in MLLMs, using hierarchical visual information retrieval to overcome memory and resource constraints.", "motivation": "Current MLLMs struggle with long video understanding due to high information volume and memory/resource limitations. Existing training-free methods rely on incomplete visual data, limiting performance.", "method": "APVR uses two components: Pivot Frame Retrieval (query expansion and iterative scoring) and Pivot Token Retrieval (query-aware token selection). This dual approach processes hour-long videos efficiently.", "result": "APVR achieves 64.9% on LongVideoBench and 68.4% on VideoMME, outperforming both training-free and training-based methods.", "conclusion": "APVR effectively addresses memory and resource constraints in MLLMs for long video understanding, offering plug-and-play integration with existing architectures."}}
{"id": "2506.05008", "pdf": "https://arxiv.org/pdf/2506.05008", "abs": "https://arxiv.org/abs/2506.05008", "authors": ["Fuyi Zhang", "Zhu Yu", "Chunhao Li", "Runmin Zhang", "Xiaokai Bai", "Zili Zhou", "Si-Yuan Cao", "Fang Wang", "Hui-Liang Shen"], "title": "Structure-Aware Radar-Camera Depth Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Radar has gained much attention in autonomous driving due to its\naccessibility and robustness. However, its standalone application for depth\nperception is constrained by issues of sparsity and noise. Radar-camera depth\nestimation offers a more promising complementary solution. Despite significant\nprogress, current approaches fail to produce satisfactory dense depth maps, due\nto the unsatisfactory processing of the sparse and noisy radar data. They\nconstrain the regions of interest for radar points in rigid rectangular\nregions, which may introduce unexpected errors and confusions. To address these\nissues, we develop a structure-aware strategy for radar depth enhancement,\nwhich provides more targeted regions of interest by leveraging the structural\npriors of RGB images. Furthermore, we design a Multi-Scale Structure Guided\nNetwork to enhance radar features and preserve detailed structures, achieving\naccurate and structure-detailed dense metric depth estimation. Building on\nthese, we propose a structure-aware radar-camera depth estimation framework,\nnamed SA-RCD. Extensive experiments demonstrate that our SA-RCD achieves\nstate-of-the-art performance on the nuScenes dataset. Our code will be\navailable at https://github.com/FreyZhangYeh/SA-RCD.", "AI": {"tldr": "SA-RCD is a structure-aware radar-camera depth estimation framework that improves dense depth maps by leveraging RGB structural priors and a multi-scale network.", "motivation": "Standalone radar for depth perception is limited by sparsity and noise, and current radar-camera methods fail to produce satisfactory dense depth maps due to rigid region constraints.", "method": "Proposes a structure-aware strategy for radar depth enhancement and a Multi-Scale Structure Guided Network to refine radar features and preserve details.", "result": "SA-RCD achieves state-of-the-art performance on the nuScenes dataset.", "conclusion": "The framework effectively addresses sparsity and noise issues in radar-camera depth estimation, producing accurate and detailed dense depth maps."}}
{"id": "2506.05210", "pdf": "https://arxiv.org/pdf/2506.05210", "abs": "https://arxiv.org/abs/2506.05210", "authors": ["Jan Ackermann", "Kiyohiro Nakayama", "Guandao Yang", "Tong Wu", "Gordon Wetzstein"], "title": "Towards Vision-Language-Garment Models for Web Knowledge Garment Understanding and Generation", "categories": ["cs.CV"], "comment": "Presented at MMFM CVPRW'25, Project Page:\n  https://www.computationalimaging.org/publications/vision-language-garment-models/", "summary": "Multimodal foundation models have demonstrated strong generalization, yet\ntheir ability to transfer knowledge to specialized domains such as garment\ngeneration remains underexplored. We introduce VLG, a vision-language-garment\nmodel that synthesizes garments from textual descriptions and visual imagery.\nOur experiments assess VLG's zero-shot generalization, investigating its\nability to transfer web-scale reasoning to unseen garment styles and prompts.\nPreliminary results indicate promising transfer capabilities, highlighting the\npotential for multimodal foundation models to adapt effectively to specialized\ndomains like fashion design.", "AI": {"tldr": "VLG is a vision-language-garment model for generating garments from text and images, showing promising zero-shot transfer to unseen styles.", "motivation": "Explore the generalization of multimodal foundation models in specialized domains like garment generation.", "method": "Introduce VLG, a model synthesizing garments from textual and visual inputs, tested for zero-shot generalization.", "result": "Preliminary results show VLG effectively transfers web-scale reasoning to unseen garment styles.", "conclusion": "Multimodal foundation models like VLG can adapt well to specialized domains such as fashion design."}}
{"id": "2506.09113", "pdf": "https://arxiv.org/pdf/2506.09113", "abs": "https://arxiv.org/abs/2506.09113", "authors": ["Yu Gao", "Haoyuan Guo", "Tuyen Hoang", "Weilin Huang", "Lu Jiang", "Fangyuan Kong", "Huixia Li", "Jiashi Li", "Liang Li", "Xiaojie Li", "Xunsong Li", "Yifu Li", "Shanchuan Lin", "Zhijie Lin", "Jiawei Liu", "Shu Liu", "Xiaonan Nie", "Zhiwu Qing", "Yuxi Ren", "Li Sun", "Zhi Tian", "Rui Wang", "Sen Wang", "Guoqiang Wei", "Guohong Wu", "Jie Wu", "Ruiqi Xia", "Fei Xiao", "Xuefeng Xiao", "Jiangqiao Yan", "Ceyuan Yang", "Jianchao Yang", "Runkai Yang", "Tao Yang", "Yihang Yang", "Zilyu Ye", "Xuejiao Zeng", "Yan Zeng", "Heng Zhang", "Yang Zhao", "Xiaozheng Zheng", "Peihao Zhu", "Jiaxin Zou", "Feilong Zuo"], "title": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "categories": ["cs.CV"], "comment": "Seedance 1.0 Technical Report", "summary": "Notable breakthroughs in diffusion modeling have propelled rapid improvements\nin video generation, yet current foundational model still face critical\nchallenges in simultaneously balancing prompt following, motion plausibility,\nand visual quality. In this report, we introduce Seedance 1.0, a\nhigh-performance and inference-efficient video foundation generation model that\nintegrates several core technical improvements: (i) multi-source data curation\naugmented with precision and meaningful video captioning, enabling\ncomprehensive learning across diverse scenarios; (ii) an efficient architecture\ndesign with proposed training paradigm, which allows for natively supporting\nmulti-shot generation and jointly learning of both text-to-video and\nimage-to-video tasks. (iii) carefully-optimized post-training approaches\nleveraging fine-grained supervised fine-tuning, and video-specific RLHF with\nmulti-dimensional reward mechanisms for comprehensive performance improvements;\n(iv) excellent model acceleration achieving ~10x inference speedup through\nmulti-stage distillation strategies and system-level optimizations. Seedance\n1.0 can generate a 5-second video at 1080p resolution only with 41.4 seconds\n(NVIDIA-L20). Compared to state-of-the-art video generation models, Seedance\n1.0 stands out with high-quality and fast video generation having superior\nspatiotemporal fluidity with structural stability, precise instruction\nadherence in complex multi-subject contexts, native multi-shot narrative\ncoherence with consistent subject representation.", "AI": {"tldr": "Seedance 1.0 is a high-performance video generation model addressing prompt adherence, motion plausibility, and visual quality through multi-source data, efficient architecture, post-training optimizations, and acceleration.", "motivation": "Current video generation models struggle to balance prompt following, motion plausibility, and visual quality. Seedance 1.0 aims to overcome these challenges.", "method": "The model integrates multi-source data curation, efficient architecture design, post-training optimizations (fine-tuning, RLHF), and acceleration techniques (distillation, system optimizations).", "result": "Seedance 1.0 achieves high-quality, fast video generation (41.4s for 5s 1080p video) with superior spatiotemporal fluidity, prompt adherence, and multi-shot coherence.", "conclusion": "Seedance 1.0 outperforms state-of-the-art models in video generation quality, speed, and adherence to complex instructions."}}
{"id": "2506.13430", "pdf": "https://arxiv.org/pdf/2506.13430", "abs": "https://arxiv.org/abs/2506.13430", "authors": ["Tristan Kenneweg", "Philip Kenneweg", "Barbara Hammer"], "title": "Uncertainty-Aware Remaining Lifespan Prediction from Images", "categories": ["cs.CV"], "comment": "Submitted to ISVC 2025", "summary": "Predicting mortality-related outcomes from images offers the prospect of\naccessible, noninvasive, and scalable health screening. We present a method\nthat leverages pretrained vision transformer foundation models to estimate\nremaining lifespan from facial and whole-body images, alongside robust\nuncertainty quantification. We show that predictive uncertainty varies\nsystematically with the true remaining lifespan, and that this uncertainty can\nbe effectively modeled by learning a Gaussian distribution for each sample. Our\napproach achieves state-of-the-art mean absolute error (MAE) of 7.48 years on\nan established dataset, and further improves to 4.79 and 5.07 years MAE on two\nnew, higher-quality datasets curated and published in this work. Importantly,\nour models provide well-calibrated uncertainty estimates, as demonstrated by a\nbucketed expected calibration error of 0.62 years. While not intended for\nclinical deployment, these results highlight the potential of extracting\nmedically relevant signals from images. We make all code and datasets available\nto facilitate further research.", "AI": {"tldr": "A method using pretrained vision transformers predicts remaining lifespan from images with robust uncertainty quantification, achieving state-of-the-art accuracy.", "motivation": "To enable accessible, noninvasive, and scalable health screening by predicting mortality-related outcomes from images.", "method": "Leverages pretrained vision transformer models to estimate lifespan from facial and whole-body images, with Gaussian distribution-based uncertainty modeling.", "result": "Achieves MAE of 7.48 years on an established dataset and improves to 4.79 and 5.07 years on new datasets, with well-calibrated uncertainty (0.62 years error).", "conclusion": "Demonstrates potential for extracting medically relevant signals from images, though not yet for clinical use; code and datasets are shared for research."}}
{"id": "2506.15318", "pdf": "https://arxiv.org/pdf/2506.15318", "abs": "https://arxiv.org/abs/2506.15318", "authors": ["Lanfeng Zhong", "Xin Liao", "Shichuan Zhang", "Shaoting Zhang", "Guotai Wang"], "title": "OpenPath: Open-Set Active Learning for Pathology Image Classification via Pre-trained Vision-Language Models", "categories": ["cs.CV"], "comment": "MICCAI 2025 early accept", "summary": "Pathology image classification plays a crucial role in accurate medical\ndiagnosis and treatment planning. Training high-performance models for this\ntask typically requires large-scale annotated datasets, which are both\nexpensive and time-consuming to acquire. Active Learning (AL) offers a solution\nby iteratively selecting the most informative samples for annotation, thereby\nreducing the labeling effort. However, most AL methods are designed under the\nassumption of a closed-set scenario, where all the unannotated images belong to\ntarget classes. In real-world clinical environments, the unlabeled pool often\ncontains a substantial amount of Out-Of-Distribution (OOD) data, leading to low\nefficiency of annotation in traditional AL methods. Furthermore, most existing\nAL methods start with random selection in the first query round, leading to a\nsignificant waste of labeling costs in open-set scenarios. To address these\nchallenges, we propose OpenPath, a novel open-set active learning approach for\npathological image classification leveraging a pre-trained Vision-Language\nModel (VLM). In the first query, we propose task-specific prompts that combine\ntarget and relevant non-target class prompts to effectively select\nIn-Distribution (ID) and informative samples from the unlabeled pool. In\nsubsequent queries, Diverse Informative ID Sampling (DIS) that includes\nPrototype-based ID candidate Selection (PIS) and Entropy-Guided Stochastic\nSampling (EGSS) is proposed to ensure both purity and informativeness in a\nquery, avoiding the selection of OOD samples. Experiments on two public\npathology image datasets show that OpenPath significantly enhances the model's\nperformance due to its high purity of selected samples, and outperforms several\nstate-of-the-art open-set AL methods. The code is available at\n\\href{https://github.com/HiLab-git/OpenPath}{https://github.com/HiLab-git/OpenPath}..", "AI": {"tldr": "OpenPath is a novel open-set active learning method for pathology image classification, leveraging a pre-trained Vision-Language Model to efficiently select informative samples while avoiding Out-Of-Distribution data.", "motivation": "Traditional Active Learning methods struggle with Out-Of-Distribution data in real-world clinical settings, leading to inefficient annotation. OpenPath addresses this by improving sample selection purity and informativeness.", "method": "OpenPath uses task-specific prompts in the first query and Diverse Informative ID Sampling (DIS) in subsequent queries, combining Prototype-based ID candidate Selection (PIS) and Entropy-Guided Stochastic Sampling (EGSS).", "result": "Experiments on public pathology datasets show OpenPath outperforms state-of-the-art open-set AL methods, enhancing model performance through high-purity sample selection.", "conclusion": "OpenPath effectively reduces labeling costs and improves efficiency in pathology image classification by addressing the challenges of open-set scenarios."}}
{"id": "2506.15596", "pdf": "https://arxiv.org/pdf/2506.15596", "abs": "https://arxiv.org/abs/2506.15596", "authors": ["Kyobin Choo", "Hyunkyung Han", "Jinyeong Kim", "Chanyong Yoon", "Seong Jae Hwang"], "title": "Mono-Modalizing Extremely Heterogeneous Multi-Modal Medical Image Registration", "categories": ["cs.CV", "I.4.5; I.4.9; J.3"], "comment": "11 pages, 3 figures, 2 tables, Accepted at Medical Image Computing\n  and Computer Assisted Intervention (MICCAI) 2025", "summary": "In clinical practice, imaging modalities with functional characteristics,\nsuch as positron emission tomography (PET) and fractional anisotropy (FA), are\noften aligned with a structural reference (e.g., MRI, CT) for accurate\ninterpretation or group analysis, necessitating multi-modal deformable image\nregistration (DIR). However, due to the extreme heterogeneity of these\nmodalities compared to standard structural scans, conventional unsupervised DIR\nmethods struggle to learn reliable spatial mappings and often distort images.\nWe find that the similarity metrics guiding these models fail to capture\nalignment between highly disparate modalities. To address this, we propose\nM2M-Reg (Multi-to-Mono Registration), a novel framework that trains multi-modal\nDIR models using only mono-modal similarity while preserving the established\narchitectural paradigm for seamless integration into existing models. We also\nintroduce GradCyCon, a regularizer that leverages M2M-Reg's cyclic training\nscheme to promote diffeomorphism. Furthermore, our framework naturally extends\nto a semi-supervised setting, integrating pre-aligned and unaligned pairs only,\nwithout requiring ground-truth transformations or segmentation masks.\nExperiments on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset\ndemonstrate that M2M-Reg achieves up to 2x higher DSC than prior methods for\nPET-MRI and FA-MRI registration, highlighting its effectiveness in handling\nhighly heterogeneous multi-modal DIR. Our code is available at\nhttps://github.com/MICV-yonsei/M2M-Reg.", "AI": {"tldr": "M2M-Reg is a novel framework for multi-modal deformable image registration (DIR) that uses mono-modal similarity, addressing challenges in aligning highly disparate imaging modalities like PET and FA with structural references (MRI/CT).", "motivation": "Conventional unsupervised DIR methods struggle with highly heterogeneous modalities due to unreliable similarity metrics, leading to distorted images.", "method": "Proposes M2M-Reg, which trains multi-modal DIR models using mono-modal similarity, and introduces GradCyCon for diffeomorphism. Extends to semi-supervised settings without ground-truth transformations.", "result": "Achieves up to 2x higher Dice Similarity Coefficient (DSC) than prior methods for PET-MRI and FA-MRI registration on the ADNI dataset.", "conclusion": "M2M-Reg effectively handles highly heterogeneous multi-modal DIR, outperforming existing methods and offering seamless integration into existing models."}}
{"id": "2506.16398", "pdf": "https://arxiv.org/pdf/2506.16398", "abs": "https://arxiv.org/abs/2506.16398", "authors": ["Peixiang Huang", "Yanyan Huang", "Weiqin Zhao", "Junjun He", "Lequan Yu"], "title": "HyperPath: Knowledge-Guided Hyperbolic Semantic Hierarchy Modeling for WSI Analysis", "categories": ["cs.CV"], "comment": null, "summary": "Pathology is essential for cancer diagnosis, with multiple instance learning\n(MIL) widely used for whole slide image (WSI) analysis. WSIs exhibit a natural\nhierarchy -- patches, regions, and slides -- with distinct semantic\nassociations. While some methods attempt to leverage this hierarchy for\nimproved representation, they predominantly rely on Euclidean embeddings, which\nstruggle to fully capture semantic hierarchies. To address this limitation, we\npropose HyperPath, a novel method that integrates knowledge from textual\ndescriptions to guide the modeling of semantic hierarchies of WSIs in\nhyperbolic space, thereby enhancing WSI classification. Our approach adapts\nboth visual and textual features extracted by pathology vision-language\nfoundation models to the hyperbolic space. We design an Angular Modality\nAlignment Loss to ensure robust cross-modal alignment, while a Semantic\nHierarchy Consistency Loss further refines feature hierarchies through\nentailment and contradiction relationships and thus enhance semantic coherence.\nThe classification is performed with geodesic distance, which measures the\nsimilarity between entities in the hyperbolic semantic hierarchy. This\neliminates the need for linear classifiers and enables a geometry-aware\napproach to WSI analysis. Extensive experiments show that our method achieves\nsuperior performance across tasks compared to existing methods, highlighting\nthe potential of hyperbolic embeddings for WSI analysis.", "AI": {"tldr": "HyperPath leverages hyperbolic space and textual descriptions to model semantic hierarchies in WSIs, improving classification via geometry-aware methods.", "motivation": "Current MIL methods for WSI analysis rely on Euclidean embeddings, which inadequately capture semantic hierarchies.", "method": "HyperPath integrates visual and textual features in hyperbolic space, using Angular Modality Alignment Loss and Semantic Hierarchy Consistency Loss for alignment and coherence.", "result": "The method outperforms existing approaches in WSI classification tasks.", "conclusion": "Hyperbolic embeddings show promise for enhancing WSI analysis by better modeling semantic hierarchies."}}
{"id": "2506.17455", "pdf": "https://arxiv.org/pdf/2506.17455", "abs": "https://arxiv.org/abs/2506.17455", "authors": ["Taufikur Rahman Fuad", "Sabbir Ahmed", "Shahriar Ivan"], "title": "AQUA20: A Benchmark Dataset for Underwater Species Classification under Challenging Conditions", "categories": ["cs.CV"], "comment": "Submitted to AJSE Springer", "summary": "Robust visual recognition in underwater environments remains a significant\nchallenge due to complex distortions such as turbidity, low illumination, and\nocclusion, which severely degrade the performance of standard vision systems.\nThis paper introduces AQUA20, a comprehensive benchmark dataset comprising\n8,171 underwater images across 20 marine species reflecting real-world\nenvironmental challenges such as illumination, turbidity, occlusions, etc.,\nproviding a valuable resource for underwater visual understanding. Thirteen\nstate-of-the-art deep learning models, including lightweight CNNs (SqueezeNet,\nMobileNetV2) and transformer-based architectures (ViT, ConvNeXt), were\nevaluated to benchmark their performance in classifying marine species under\nchallenging conditions. Our experimental results show ConvNeXt achieving the\nbest performance, with a Top-3 accuracy of 98.82% and a Top-1 accuracy of\n90.69%, as well as the highest overall F1-score of 88.92% with moderately large\nparameter size. The results obtained from our other benchmark models also\ndemonstrate trade-offs between complexity and performance. We also provide an\nextensive explainability analysis using GRAD-CAM and LIME for interpreting the\nstrengths and pitfalls of the models. Our results reveal substantial room for\nimprovement in underwater species recognition and demonstrate the value of\nAQUA20 as a foundation for future research in this domain. The dataset is\npublicly available at: https://huggingface.co/datasets/taufiktrf/AQUA20.", "AI": {"tldr": "AQUA20 dataset addresses underwater visual recognition challenges by evaluating 13 deep learning models, with ConvNeXt outperforming others.", "motivation": "Underwater visual recognition is hindered by distortions like turbidity and low illumination, necessitating robust datasets and models.", "method": "Evaluated 13 deep learning models (CNNs and transformers) on AQUA20, a dataset of 8,171 underwater images across 20 marine species.", "result": "ConvNeXt achieved top performance (Top-3 accuracy: 98.82%, Top-1: 90.69%, F1-score: 88.92%). Other models showed complexity-performance trade-offs.", "conclusion": "AQUA20 is a valuable benchmark for underwater species recognition, with ConvNeXt leading but room for improvement remains."}}
{"id": "2506.17858", "pdf": "https://arxiv.org/pdf/2506.17858", "abs": "https://arxiv.org/abs/2506.17858", "authors": ["Yingcheng Liu", "Peiqi Wang", "Sebastian Diaz", "Esra Abaci Turk", "Benjamin Billot", "Patricia Ellen Grant", "Polina Golland"], "title": "Fetuses Made Simple: Modeling and Tracking of Fetal Shape and Pose", "categories": ["cs.CV"], "comment": null, "summary": "Analyzing fetal body motion and shape is paramount in prenatal diagnostics\nand monitoring. Existing methods for fetal MRI analysis mainly rely on\nanatomical keypoints or volumetric body segmentations. Keypoints simplify body\nstructure to facilitate motion analysis, but may ignore important details of\nfull-body shape. Body segmentations capture complete shape information but\ncomplicate temporal analysis due to large non-local fetal movements. To address\nthese limitations, we construct a 3D articulated statistical fetal body model\nbased on the Skinned Multi-Person Linear Model (SMPL). Our algorithm\niteratively estimates body pose in the image space and body shape in the\ncanonical pose space. This approach improves robustness to MRI motion artifacts\nand intensity distortions, and reduces the impact of incomplete surface\nobservations due to challenging fetal poses. We train our model on\nsegmentations and keypoints derived from $19,816$ MRI volumes across $53$\nsubjects. Our model captures body shape and motion across time series and\nprovides intuitive visualization. Furthermore, it enables automated\nanthropometric measurements traditionally difficult to obtain from\nsegmentations and keypoints. When tested on unseen fetal body shapes, our\nmethod yields a surface alignment error of $3.2$ mm for $3$ mm MRI voxel size.\nTo our knowledge, this represents the first 3D articulated statistical fetal\nbody model, paving the way for enhanced fetal motion and shape analysis in\nprenatal diagnostics. The code is available at\nhttps://github.com/MedicalVisionGroup/fetal-smpl .", "AI": {"tldr": "A 3D articulated statistical fetal body model is introduced to improve fetal motion and shape analysis in MRI, addressing limitations of keypoints and segmentations.", "motivation": "Existing methods (keypoints or segmentations) for fetal MRI analysis either oversimplify body structure or complicate temporal analysis due to large movements.", "method": "The model, based on SMPL, iteratively estimates body pose in image space and shape in canonical pose space, trained on 19,816 MRI volumes.", "result": "Achieves 3.2 mm surface alignment error for 3 mm MRI voxel size, enabling automated anthropometric measurements and intuitive visualization.", "conclusion": "This is the first 3D articulated statistical fetal body model, enhancing prenatal diagnostics with robust motion and shape analysis."}}
{"id": "2506.19445", "pdf": "https://arxiv.org/pdf/2506.19445", "abs": "https://arxiv.org/abs/2506.19445", "authors": ["Mahdi Mohd Hossain Noki", "Syed Mumtahin Mahmud", "Prothito Shovon Majumder", "Abdul Mohaimen Al Radi", "Md. Haider Ali", "Md. Mosaddek Khan"], "title": "Deblurring in the Wild: A Real-World Dataset from Smartphone High-Speed Videos", "categories": ["cs.CV"], "comment": "8 pages (without references), 3 figures. Dataset\n  https://huggingface.co/datasets/masterda/SloMoBlur", "summary": "We introduce the largest real-world image deblurring dataset constructed from\nsmartphone slow-motion videos. Using 240 frames captured over one second, we\nsimulate realistic long-exposure blur by averaging frames to produce blurry\nimages, while using the temporally centered frame as the sharp reference. Our\ndataset contains over 42,000 high-resolution blur-sharp image pairs, making it\napproximately 10 times larger than widely used datasets, with 8 times the\namount of different scenes, including indoor and outdoor environments, with\nvarying object and camera motions. We benchmark multiple state-of-the-art\n(SOTA) deblurring models on our dataset and observe significant performance\ndegradation, highlighting the complexity and diversity of our benchmark. Our\ndataset serves as a challenging new benchmark to facilitate robust and\ngeneralizable deblurring models.", "AI": {"tldr": "A large-scale dataset for image deblurring is introduced, created from smartphone slow-motion videos, featuring 42,000 high-resolution blur-sharp pairs. It challenges existing SOTA models, showing performance drops due to its complexity and diversity.", "motivation": "To address the lack of large, diverse, and realistic datasets for image deblurring, which limits the development of robust models.", "method": "Constructed by averaging 240 frames from slow-motion videos to simulate blur, with the center frame as the sharp reference.", "result": "The dataset is 10x larger and 8x more diverse than existing ones, causing significant performance degradation in SOTA models.", "conclusion": "The dataset provides a challenging benchmark to advance generalizable deblurring models."}}
{"id": "2506.19474", "pdf": "https://arxiv.org/pdf/2506.19474", "abs": "https://arxiv.org/abs/2506.19474", "authors": ["Xin Zhang", "Liangxiu Han", "Yue Shi", "Yanlin Zheng", "Uazman Alam", "Maryam Ferdousi", "Rayaz Malik"], "title": "HMSViT: A Hierarchical Masked Self-Supervised Vision Transformer for Corneal Nerve Segmentation and Diabetic Neuropathy Diagnosis", "categories": ["cs.CV"], "comment": null, "summary": "Diabetic Peripheral Neuropathy (DPN) affects nearly half of diabetes\npatients, requiring early detection. Corneal Confocal Microscopy (CCM) enables\nnon-invasive diagnosis, but automated methods suffer from inefficient feature\nextraction, reliance on handcrafted priors, and data limitations. We propose\nHMSViT, a novel Hierarchical Masked Self-Supervised Vision Transformer (HMSViT)\ndesigned for corneal nerve segmentation and DPN diagnosis. Unlike existing\nmethods, HMSViT employs pooling-based hierarchical and dual attention\nmechanisms with absolute positional encoding, enabling efficient multi-scale\nfeature extraction by capturing fine-grained local details in early layers and\nintegrating global context in deeper layers, all at a lower computational cost.\nA block-masked self supervised learning framework is designed for the HMSViT\nthat reduces reliance on labelled data, enhancing feature robustness, while a\nmulti-scale decoder is used for segmentation and classification by fusing\nhierarchical features. Experiments on clinical CCM datasets showed HMSViT\nachieves state-of-the-art performance, with 61.34% mIoU for nerve segmentation\nand 70.40% diagnostic accuracy, outperforming leading hierarchical models like\nthe Swin Transformer and HiViT by margins of up to 6.39% in segmentation\naccuracy while using fewer parameters. Detailed ablation studies further reveal\nthat integrating block-masked SSL with hierarchical multi-scale feature\nextraction substantially enhances performance compared to conventional\nsupervised training. Overall, these comprehensive experiments confirm that\nHMSViT delivers excellent, robust, and clinically viable results, demonstrating\nits potential for scalable deployment in real-world diagnostic applications.", "AI": {"tldr": "HMSViT, a Hierarchical Masked Self-Supervised Vision Transformer, improves corneal nerve segmentation and DPN diagnosis by combining hierarchical and dual attention mechanisms with block-masked SSL, outperforming existing methods with fewer parameters.", "motivation": "Early detection of Diabetic Peripheral Neuropathy (DPN) is crucial, but current automated methods using Corneal Confocal Microscopy (CCM) face inefficiencies in feature extraction, reliance on handcrafted priors, and limited data.", "method": "HMSViT employs pooling-based hierarchical and dual attention mechanisms with absolute positional encoding for multi-scale feature extraction. It uses block-masked self-supervised learning (SSL) to reduce reliance on labeled data and a multi-scale decoder for segmentation and classification.", "result": "HMSViT achieves 61.34% mIoU for nerve segmentation and 70.40% diagnostic accuracy, outperforming models like Swin Transformer and HiViT by up to 6.39% while using fewer parameters.", "conclusion": "HMSViT offers robust, clinically viable results, demonstrating potential for scalable real-world diagnostic applications."}}
{"id": "2506.20756", "pdf": "https://arxiv.org/pdf/2506.20756", "abs": "https://arxiv.org/abs/2506.20756", "authors": ["Haodong Li", "Chen Wang", "Jiahui Lei", "Kostas Daniilidis", "Lingjie Liu"], "title": "StereoDiff: Stereo-Diffusion Synergy for Video Depth Estimation", "categories": ["cs.CV"], "comment": "Work done in Nov 2024, during an internship at the University of\n  Pennsylvania. Project page: https://stereodiff.github.io/", "summary": "Recent video depth estimation methods achieve great performance by following\nthe paradigm of image depth estimation, i.e., typically fine-tuning pre-trained\nvideo diffusion models with massive data. However, we argue that video depth\nestimation is not a naive extension of image depth estimation. The temporal\nconsistency requirements for dynamic and static regions in videos are\nfundamentally different. Consistent video depth in static regions, typically\nbackgrounds, can be more effectively achieved via stereo matching across all\nframes, which provides much stronger global 3D cues. While the consistency for\ndynamic regions still should be learned from large-scale video depth data to\nensure smooth transitions, due to the violation of triangulation constraints.\nBased on these insights, we introduce StereoDiff, a two-stage video depth\nestimator that synergizes stereo matching for mainly the static areas with\nvideo depth diffusion for maintaining consistent depth transitions in dynamic\nareas. We mathematically demonstrate how stereo matching and video depth\ndiffusion offer complementary strengths through frequency domain analysis,\nhighlighting the effectiveness of their synergy in capturing the advantages of\nboth. Experimental results on zero-shot, real-world, dynamic video depth\nbenchmarks, both indoor and outdoor, demonstrate StereoDiff's SoTA performance,\nshowcasing its superior consistency and accuracy in video depth estimation.", "AI": {"tldr": "StereoDiff combines stereo matching for static regions and video depth diffusion for dynamic areas to improve video depth estimation, achieving state-of-the-art performance.", "motivation": "Video depth estimation differs from image depth estimation due to varying temporal consistency needs in static and dynamic regions.", "method": "StereoDiff uses a two-stage approach: stereo matching for static areas and video depth diffusion for dynamic regions.", "result": "StereoDiff outperforms existing methods in zero-shot, real-world benchmarks, offering superior consistency and accuracy.", "conclusion": "The synergy of stereo matching and video depth diffusion effectively addresses the unique challenges of video depth estimation."}}
{"id": "2506.21042", "pdf": "https://arxiv.org/pdf/2506.21042", "abs": "https://arxiv.org/abs/2506.21042", "authors": ["Boyong He", "Yuxiang Ji", "Zhuoyue Tan", "Liaoni Wu"], "title": "Boosting Domain Generalized and Adaptive Detection with Diffusion Models: Fitness, Generalization, and Transferability", "categories": ["cs.CV"], "comment": "Accepted by ICCV2025", "summary": "Detectors often suffer from performance drop due to domain gap between\ntraining and testing data. Recent methods explore diffusion models applied to\ndomain generalization (DG) and adaptation (DA) tasks, but still struggle with\nlarge inference costs and have not yet fully leveraged the capabilities of\ndiffusion models. We propose to tackle these problems by extracting\nintermediate features from a single-step diffusion process, improving feature\ncollection and fusion to reduce inference time by 75% while enhancing\nperformance on source domains (i.e., Fitness). Then, we construct an\nobject-centered auxiliary branch by applying box-masked images with class\nprompts to extract robust and domain-invariant features that focus on object.\nWe also apply consistency loss to align the auxiliary and ordinary branch,\nbalancing fitness and generalization while preventing overfitting and improving\nperformance on target domains (i.e., Generalization). Furthermore, within a\nunified framework, standard detectors are guided by diffusion detectors through\nfeature-level and object-level alignment on source domains (for DG) and\nunlabeled target domains (for DA), thereby improving cross-domain detection\nperformance (i.e., Transferability). Our method achieves competitive results on\n3 DA benchmarks and 5 DG benchmarks. Additionally, experiments on COCO\ngeneralization benchmark demonstrate that our method maintains significant\nadvantages and show remarkable efficiency in large domain shifts and low-data\nscenarios. Our work shows the superiority of applying diffusion models to\ndomain generalized and adaptive detection tasks and offers valuable insights\nfor visual perception tasks across diverse domains. The code is available at\n\\href{https://github.com/heboyong/Fitness-Generalization-Transferability}.", "AI": {"tldr": "The paper proposes a method to improve domain generalization and adaptation in detectors using intermediate features from a single-step diffusion process, reducing inference time by 75% while enhancing performance. It introduces an object-centered auxiliary branch and consistency loss to balance fitness and generalization, achieving competitive results on benchmarks.", "motivation": "Detectors face performance drops due to domain gaps between training and testing data. Existing methods using diffusion models struggle with high inference costs and underutilize their capabilities.", "method": "Extracts intermediate features from a single-step diffusion process, introduces an object-centered auxiliary branch with box-masked images and class prompts, and applies consistency loss. Aligns diffusion and standard detectors for cross-domain performance.", "result": "Achieves competitive results on 3 DA and 5 DG benchmarks, with significant efficiency in large domain shifts and low-data scenarios.", "conclusion": "Demonstrates the superiority of diffusion models in domain-generalized and adaptive detection tasks, offering insights for visual perception across diverse domains."}}
{"id": "2506.21401", "pdf": "https://arxiv.org/pdf/2506.21401", "abs": "https://arxiv.org/abs/2506.21401", "authors": ["Zhirui Gao", "Renjiao Yi", "Yaqiao Dai", "Xuening Zhu", "Wei Chen", "Chenyang Zhu", "Kai Xu"], "title": "Curve-Aware Gaussian Splatting for 3D Parametric Curve Reconstruction", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025 Code:\n  https://github.com/zhirui-gao/Curve-Gaussian", "summary": "This paper presents an end-to-end framework for reconstructing 3D parametric\ncurves directly from multi-view edge maps. Contrasting with existing two-stage\nmethods that follow a sequential ``edge point cloud reconstruction and\nparametric curve fitting'' pipeline, our one-stage approach optimizes 3D\nparametric curves directly from 2D edge maps, eliminating error accumulation\ncaused by the inherent optimization gap between disconnected stages. However,\nparametric curves inherently lack suitability for rendering-based multi-view\noptimization, necessitating a complementary representation that preserves their\ngeometric properties while enabling differentiable rendering. We propose a\nnovel bi-directional coupling mechanism between parametric curves and\nedge-oriented Gaussian components. This tight correspondence formulates a\ncurve-aware Gaussian representation, \\textbf{CurveGaussian}, that enables\ndifferentiable rendering of 3D curves, allowing direct optimization guided by\nmulti-view evidence. Furthermore, we introduce a dynamically adaptive topology\noptimization framework during training to refine curve structures through\nlinearization, merging, splitting, and pruning operations. Comprehensive\nevaluations on the ABC dataset and real-world benchmarks demonstrate our\none-stage method's superiority over two-stage alternatives, particularly in\nproducing cleaner and more robust reconstructions. Additionally, by directly\noptimizing parametric curves, our method significantly reduces the parameter\ncount during training, achieving both higher efficiency and superior\nperformance compared to existing approaches.", "AI": {"tldr": "The paper introduces a one-stage framework, CurveGaussian, for 3D parametric curve reconstruction from multi-view edge maps, outperforming two-stage methods by eliminating error accumulation and reducing parameters.", "motivation": "Existing two-stage methods suffer from error accumulation due to disconnected optimization stages. The paper aims to directly optimize 3D parametric curves from 2D edge maps for cleaner reconstructions.", "method": "Proposes CurveGaussian, a bi-directional coupling between parametric curves and edge-oriented Gaussian components, enabling differentiable rendering. Includes dynamic topology optimization for refining curves.", "result": "Outperforms two-stage methods on the ABC dataset and real-world benchmarks, producing cleaner reconstructions with fewer parameters.", "conclusion": "The one-stage approach with CurveGaussian is more efficient and robust, achieving superior performance in 3D parametric curve reconstruction."}}
{"id": "2506.21514", "pdf": "https://arxiv.org/pdf/2506.21514", "abs": "https://arxiv.org/abs/2506.21514", "authors": ["Mohammed Rakib", "Arunkumar Bagavathi"], "title": "G$^{2}$D: Boosting Multimodal Learning with Gradient-Guided Distillation", "categories": ["cs.CV"], "comment": "Accepted at ICCV 2025", "summary": "Multimodal learning aims to leverage information from diverse data modalities\nto achieve more comprehensive performance. However, conventional multimodal\nmodels often suffer from modality imbalance, where one or a few modalities\ndominate model optimization, leading to suboptimal feature representation and\nunderutilization of weak modalities. To address this challenge, we introduce\nGradient-Guided Distillation (G$^{2}$D), a knowledge distillation framework\nthat optimizes the multimodal model with a custom-built loss function that\nfuses both unimodal and multimodal objectives. G$^{2}$D further incorporates a\ndynamic sequential modality prioritization (SMP) technique in the learning\nprocess to ensure each modality leads the learning process, avoiding the\npitfall of stronger modalities overshadowing weaker ones. We validate G$^{2}$D\non multiple real-world datasets and show that G$^{2}$D amplifies the\nsignificance of weak modalities while training and outperforms state-of-the-art\nmethods in classification and regression tasks. Our code is available at\nhttps://github.com/rAIson-Lab/G2D.", "AI": {"tldr": "Gradient-Guided Distillation (G\u00b2D) addresses modality imbalance in multimodal learning by using a custom loss function and dynamic modality prioritization, improving performance on weak modalities.", "motivation": "Conventional multimodal models often suffer from modality imbalance, where dominant modalities overshadow weaker ones, leading to suboptimal performance.", "method": "G\u00b2D employs a knowledge distillation framework with a fused loss function and dynamic sequential modality prioritization (SMP) to balance modality contributions.", "result": "G\u00b2D enhances weak modality utilization and outperforms state-of-the-art methods in classification and regression tasks.", "conclusion": "G\u00b2D effectively mitigates modality imbalance and improves multimodal learning performance."}}
{"id": "2506.21544", "pdf": "https://arxiv.org/pdf/2506.21544", "abs": "https://arxiv.org/abs/2506.21544", "authors": ["Yansong Qu", "Shaohui Dai", "Xinyang Li", "Yuze Wang", "You Shen", "Liujuan Cao", "Rongrong Ji"], "title": "DeOcc-1-to-3: 3D De-Occlusion from a Single Image via Self-Supervised Multi-View Diffusion", "categories": ["cs.CV"], "comment": "Project page: \\url{https://quyans.github.io/DeOcc123/}", "summary": "Reconstructing 3D objects from a single image remains challenging, especially\nunder real-world occlusions. While recent diffusion-based view synthesis models\ncan generate consistent novel views from a single RGB image, they typically\nassume fully visible inputs and fail when parts of the object are occluded,\nresulting in degraded 3D reconstruction quality. We propose DeOcc-1-to-3, an\nend-to-end framework for occlusion-aware multi-view generation that synthesizes\nsix structurally consistent novel views directly from a single occluded image,\nenabling reliable 3D reconstruction without prior inpainting or manual\nannotations. Our self-supervised training pipeline leverages\noccluded-unoccluded image pairs and pseudo-ground-truth views to teach the\nmodel structure-aware completion and view consistency. Without modifying the\noriginal architecture, we fully fine-tune the view synthesis model to jointly\nlearn completion and multi-view generation. Additionally, we introduce the\nfirst benchmark for occlusion-aware reconstruction, covering diverse occlusion\nlevels, object categories, and masking patterns, providing a standardized\nprotocol for future evaluation.", "AI": {"tldr": "DeOcc-1-to-3 is an end-to-end framework for occlusion-aware multi-view generation from a single occluded image, enabling reliable 3D reconstruction without prior inpainting or manual annotations.", "motivation": "Existing diffusion-based view synthesis models fail under occlusions, degrading 3D reconstruction quality.", "method": "A self-supervised training pipeline uses occluded-unoccluded image pairs and pseudo-ground-truth views to teach structure-aware completion and view consistency. The view synthesis model is fine-tuned for joint learning.", "result": "The framework synthesizes six structurally consistent novel views from a single occluded image, improving 3D reconstruction reliability.", "conclusion": "DeOcc-1-to-3 addresses occlusion challenges in 3D reconstruction and introduces a benchmark for future evaluation."}}
{"id": "2506.21835", "pdf": "https://arxiv.org/pdf/2506.21835", "abs": "https://arxiv.org/abs/2506.21835", "authors": ["Xiaoqi Wang", "Clint Sebastian", "Wenbin He", "Liu Ren"], "title": "ProSAM: Enhancing the Robustness of SAM-based Visual Reference Segmentation with Probabilistic Prompts", "categories": ["cs.CV"], "comment": null, "summary": "The recent advancements in large foundation models have driven the success of\nopen-set image segmentation, a task focused on segmenting objects beyond\npredefined categories. Among various prompt types (such as points, boxes,\ntexts, and visual references), visual reference segmentation stands out for its\nunique flexibility and strong zero-shot capabilities. Recently, several\nSAM-based methods have made notable progress in this task by automatically\ngenerating prompts to guide SAM. However, these methods often generate prompts\nat object boundaries due to suboptimal prompt encoder, which results in\ninstability and reduced robustness. In this work, we introduce ProSAM, a simple\nbut effective method to address the stability challenges we identified in\nexisting SAM-based visual reference segmentation approaches. By learning a\nvariational prompt encoder to predict multivariate prompt distributions, ProSAM\navoids generating prompts that lie in unstable regions, overcoming the\ninstability caused by less robust prompts. Our approach consistently surpasses\nstate-of-the-art methods on the Pascal-5$^i$ and COCO-20$^i$ datasets,\nproviding a more robust solution for visual reference segmentation.", "AI": {"tldr": "ProSAM improves visual reference segmentation by predicting stable prompt distributions, outperforming SAM-based methods on key datasets.", "motivation": "Existing SAM-based methods for visual reference segmentation generate unstable prompts at object boundaries due to suboptimal encoders, limiting robustness.", "method": "ProSAM introduces a variational prompt encoder to predict multivariate prompt distributions, avoiding unstable regions.", "result": "ProSAM consistently outperforms state-of-the-art methods on Pascal-5$^i$ and COCO-20$^i$ datasets.", "conclusion": "ProSAM provides a more robust solution for visual reference segmentation by addressing prompt instability."}}
{"id": "2506.22022", "pdf": "https://arxiv.org/pdf/2506.22022", "abs": "https://arxiv.org/abs/2506.22022", "authors": ["Zhanyi Lu", "Yue Zhou"], "title": "Advancing Facial Stylization through Semantic Preservation Constraint and Pseudo-Paired Supervision", "categories": ["cs.CV"], "comment": null, "summary": "Facial stylization aims to transform facial images into appealing,\nhigh-quality stylized portraits, with the critical challenge of accurately\nlearning the target style while maintaining content consistency with the\noriginal image. Although previous StyleGAN-based methods have made significant\nadvancements, the generated results still suffer from artifacts or insufficient\nfidelity to the source image. We argue that these issues stem from neglecting\nsemantic shift of the generator during stylization. Therefore, we propose a\nfacial stylization method that integrates semantic preservation constraint and\npseudo-paired supervision to enhance the content correspondence and improve the\nstylization effect. Additionally, we develop a methodology for creating\nmulti-level pseudo-paired datasets to implement supervisory constraint.\nFurthermore, building upon our facial stylization framework, we achieve more\nflexible multimodal and reference-guided stylization without complex network\narchitecture designs or additional training. Experimental results demonstrate\nthat our approach produces high-fidelity, aesthetically pleasing facial style\ntransfer that surpasses previous methods.", "AI": {"tldr": "A facial stylization method integrating semantic preservation and pseudo-paired supervision to enhance content fidelity and stylization quality, outperforming previous methods.", "motivation": "Addressing artifacts and insufficient fidelity in StyleGAN-based facial stylization by tackling semantic shift during stylization.", "method": "Proposes semantic preservation constraint and pseudo-paired supervision, with multi-level pseudo-paired dataset creation for supervision.", "result": "Achieves high-fidelity, aesthetically pleasing facial style transfer, surpassing prior methods.", "conclusion": "The method improves stylization quality and enables flexible multimodal and reference-guided stylization without complex designs."}}
{"id": "2502.11161", "pdf": "https://arxiv.org/pdf/2502.11161", "abs": "https://arxiv.org/abs/2502.11161", "authors": ["Zihan Lan", "Weixin Mao", "Haosheng Li", "Le Wang", "Tiancai Wang", "Haoqiang Fan", "Osamu Yoshie"], "title": "BFA: Best-Feature-Aware Fusion for Multi-View Fine-grained Manipulation", "categories": ["cs.RO", "cs.CV"], "comment": "8 pages, 4 figures", "summary": "In real-world scenarios, multi-view cameras are typically employed for\nfine-grained manipulation tasks. Existing approaches (e.g., ACT) tend to treat\nmulti-view features equally and directly concatenate them for policy learning.\nHowever, it will introduce redundant visual information and bring higher\ncomputational costs, leading to ineffective manipulation. For a fine-grained\nmanipulation task, it tends to involve multiple stages while the most\ncontributed view for different stages is varied over time. In this paper, we\npropose a plug-and-play best-feature-aware (BFA) fusion strategy for multi-view\nmanipulation tasks, which is adaptable to various policies. Built upon the\nvisual backbone of the policy network, we design a lightweight network to\npredict the importance score of each view. Based on the predicted importance\nscores, the reweighted multi-view features are subsequently fused and input\ninto the end-to-end policy network, enabling seamless integration. Notably, our\nmethod demonstrates outstanding performance in fine-grained manipulations.\nExperimental results show that our approach outperforms multiple baselines by\n22-46% success rate on different tasks. Our work provides new insights and\ninspiration for tackling key challenges in fine-grained manipulations.", "AI": {"tldr": "The paper introduces a plug-and-play best-feature-aware (BFA) fusion strategy for multi-view manipulation tasks, addressing redundancy and inefficiency in existing methods by dynamically weighting views based on their importance.", "motivation": "Existing multi-view approaches treat all views equally, leading to redundant information and higher computational costs, which hampers effectiveness in fine-grained manipulation tasks.", "method": "The BFA strategy uses a lightweight network to predict importance scores for each view, reweighting and fusing features before feeding them into the policy network.", "result": "The method outperforms baselines by 22-46% success rate in fine-grained manipulation tasks.", "conclusion": "The BFA strategy offers a scalable and efficient solution for multi-view manipulation, providing new insights for tackling fine-grained tasks."}}
{"id": "2504.14078", "pdf": "https://arxiv.org/pdf/2504.14078", "abs": "https://arxiv.org/abs/2504.14078", "authors": ["M-Mahdi Naddaf-Sh", "Andrew Lee", "Kin Yen", "Eemon Amini", "Iman Soltani"], "title": "Low-Cost Infrared Vision Systems for Improved Safety of Emergency Vehicle Operations Under Low-Visibility Conditions", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "This study investigates the potential of infrared (IR) camera technology to\nenhance driver safety for emergency vehicles operating in low-visibility\nconditions, particularly at night and in dense fog. Such environments\nsignificantly increase the risk of collisions, especially for tow trucks and\nsnowplows that must remain operational in challenging conditions. Conventional\ndriver assistance systems often struggle under these conditions due to limited\nvisibility. In contrast, IR cameras, which detect the thermal signatures of\nobstacles, offer a promising alternative. The evaluation combines controlled\nlaboratory experiments, real-world field tests, and surveys of emergency\nvehicle operators. In addition to assessing detection performance, the study\nexamines the feasibility of retrofitting existing Department of Transportation\n(DoT) fleets with cost-effective IR-based driver assistance systems. Results\nunderscore the utility of IR technology in enhancing driver awareness and\nprovide data-driven recommendations for scalable deployment across legacy\nemergency vehicle fleets.", "AI": {"tldr": "IR camera technology improves driver safety for emergency vehicles in low-visibility conditions like night and fog, outperforming conventional systems.", "motivation": "Emergency vehicles face high collision risks in low-visibility conditions, and current driver assistance systems are ineffective.", "method": "Combined lab experiments, field tests, and operator surveys to evaluate IR camera performance and retrofitting feasibility.", "result": "IR technology enhances driver awareness, with practical recommendations for scalable deployment.", "conclusion": "IR cameras are a viable solution for improving emergency vehicle safety in challenging conditions."}}
{"id": "2506.10507", "pdf": "https://arxiv.org/pdf/2506.10507", "abs": "https://arxiv.org/abs/2506.10507", "authors": ["Junchao Huang", "Xinting Hu", "Shaoshuai Shi", "Zhuotao Tian", "Li Jiang"], "title": "Edit360: 2D Image Edits to 3D Assets from Any Angle", "categories": ["cs.GR", "cs.CV"], "comment": "11 pages, 9 figures", "summary": "Recent advances in diffusion models have significantly improved image\ngeneration and editing, but extending these capabilities to 3D assets remains\nchallenging, especially for fine-grained edits that require multi-view\nconsistency. Existing methods typically restrict editing to predetermined\nviewing angles, severely limiting their flexibility and practical applications.\nWe introduce Edit360, a tuning-free framework that extends 2D modifications to\nmulti-view consistent 3D editing. Built upon video diffusion models, Edit360\nenables user-specific editing from arbitrary viewpoints while ensuring\nstructural coherence across all views. The framework selects anchor views for\n2D modifications and propagates edits across the entire 360-degree range. To\nachieve this, Edit360 introduces a novel Anchor-View Editing Propagation\nmechanism, which effectively aligns and merges multi-view information within\nthe latent and attention spaces of diffusion models. The resulting edited\nmulti-view sequences facilitate the reconstruction of high-quality 3D assets,\nenabling customizable 3D content creation.", "AI": {"tldr": "Edit360 is a tuning-free framework for multi-view consistent 3D editing, leveraging video diffusion models to propagate 2D edits across all viewpoints.", "motivation": "Extending diffusion models to 3D editing is challenging, especially for fine-grained, multi-view consistent edits. Existing methods lack flexibility by restricting edits to fixed angles.", "method": "Edit360 uses video diffusion models, selecting anchor views for 2D edits and propagating them via an Anchor-View Editing Propagation mechanism in latent and attention spaces.", "result": "The framework achieves high-quality 3D asset reconstruction with customizable edits, ensuring structural coherence across all viewpoints.", "conclusion": "Edit360 advances 3D content creation by enabling flexible, multi-view consistent editing without tuning, leveraging 2D diffusion models."}}
