{"id": "2505.03788", "pdf": "https://arxiv.org/pdf/2505.03788", "abs": "https://arxiv.org/abs/2505.03788", "authors": ["Trilok Padhi", "Ramneet Kaur", "Adam D. Cobb", "Manoj Acharya", "Anirban Roy", "Colin Samplawski", "Brian Matejek", "Alexander M. Berenbeim", "Nathaniel D. Bastian", "Susmit Jha"], "title": "Calibrating Uncertainty Quantification of Multi-Modal LLMs using Grounding", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "We introduce a novel approach for calibrating uncertainty quantification (UQ)\ntailored for multi-modal large language models (LLMs). Existing\nstate-of-the-art UQ methods rely on consistency among multiple responses\ngenerated by the LLM on an input query under diverse settings. However, these\napproaches often report higher confidence in scenarios where the LLM is\nconsistently incorrect. This leads to a poorly calibrated confidence with\nrespect to accuracy. To address this, we leverage cross-modal consistency in\naddition to self-consistency to improve the calibration of the multi-modal\nmodels. Specifically, we ground the textual responses to the visual inputs. The\nconfidence from the grounding model is used to calibrate the overall\nconfidence. Given that using a grounding model adds its own uncertainty in the\npipeline, we apply temperature scaling - a widely accepted parametric\ncalibration technique - to calibrate the grounding model's confidence in the\naccuracy of generated responses. We evaluate the proposed approach across\nmultiple multi-modal tasks, such as medical question answering (Slake) and\nvisual question answering (VQAv2), considering multi-modal models such as\nLLaVA-Med and LLaVA. The experiments demonstrate that the proposed framework\nachieves significantly improved calibration on both tasks.", "AI": {"tldr": "A novel method improves uncertainty calibration in multi-modal LLMs by using cross-modal consistency and temperature scaling, achieving better results on tasks like medical and visual question answering.", "motivation": "Existing UQ methods for LLMs often report high confidence even when incorrect, leading to poor calibration. This work addresses this by leveraging cross-modal consistency.", "method": "The approach grounds textual responses to visual inputs and uses a grounding model's confidence, calibrated via temperature scaling, to improve overall uncertainty calibration.", "result": "Experiments on tasks like Slake and VQAv2 show significantly improved calibration with models like LLaVA-Med and LLaVA.", "conclusion": "The proposed framework effectively enhances uncertainty calibration in multi-modal LLMs, validated across diverse tasks."}}
{"id": "2505.03910", "pdf": "https://arxiv.org/pdf/2505.03910", "abs": "https://arxiv.org/abs/2505.03910", "authors": ["Gianluca Manzo", "Julia Ive"], "title": "Hesitation is defeat? Connecting Linguistic and Predictive Uncertainty", "categories": ["cs.CL"], "comment": null, "summary": "Automating chest radiograph interpretation using Deep Learning (DL) models\nhas the potential to significantly improve clinical workflows, decision-making,\nand large-scale health screening. However, in medical settings, merely\noptimising predictive performance is insufficient, as the quantification of\nuncertainty is equally crucial. This paper investigates the relationship\nbetween predictive uncertainty, derived from Bayesian Deep Learning\napproximations, and human/linguistic uncertainty, as estimated from free-text\nradiology reports labelled by rule-based labellers. Utilising BERT as the model\nof choice, this study evaluates different binarisation methods for uncertainty\nlabels and explores the efficacy of Monte Carlo Dropout and Deep Ensembles in\nestimating predictive uncertainty. The results demonstrate good model\nperformance, but also a modest correlation between predictive and linguistic\nuncertainty, highlighting the challenges in aligning machine uncertainty with\nhuman interpretation nuances. Our findings suggest that while Bayesian\napproximations provide valuable uncertainty estimates, further refinement is\nnecessary to fully capture and utilise the subtleties of human uncertainty in\nclinical applications.", "AI": {"tldr": "The paper explores using Bayesian Deep Learning to align predictive uncertainty in chest radiograph interpretation with human linguistic uncertainty, finding modest correlation and highlighting the need for refinement.", "motivation": "To improve clinical workflows and decision-making by aligning machine uncertainty estimates with human uncertainty in medical imaging.", "method": "Uses BERT, Monte Carlo Dropout, and Deep Ensembles to evaluate predictive uncertainty and compares it with rule-based linguistic uncertainty from radiology reports.", "result": "Demonstrates good model performance but only a modest correlation between predictive and linguistic uncertainty.", "conclusion": "Bayesian approximations provide useful uncertainty estimates, but further refinement is needed to better align with human uncertainty nuances in clinical settings."}}
{"id": "2505.03970", "pdf": "https://arxiv.org/pdf/2505.03970", "abs": "https://arxiv.org/abs/2505.03970", "authors": ["Lucia Zheng", "Neel Guha", "Javokhir Arifov", "Sarah Zhang", "Michal Skreta", "Christopher D. Manning", "Peter Henderson", "Daniel E. Ho"], "title": "A Reasoning-Focused Legal Retrieval Benchmark", "categories": ["cs.CL"], "comment": "CS&Law 2025. For data, see\n  https://reglab.github.io/legal-rag-benchmarks/", "summary": "As the legal community increasingly examines the use of large language models\n(LLMs) for various legal applications, legal AI developers have turned to\nretrieval-augmented LLMs (\"RAG\" systems) to improve system performance and\nrobustness. An obstacle to the development of specialized RAG systems is the\nlack of realistic legal RAG benchmarks which capture the complexity of both\nlegal retrieval and downstream legal question-answering. To address this, we\nintroduce two novel legal RAG benchmarks: Bar Exam QA and Housing Statute QA.\nOur tasks correspond to real-world legal research tasks, and were produced\nthrough annotation processes which resemble legal research. We describe the\nconstruction of these benchmarks and the performance of existing retriever\npipelines. Our results suggest that legal RAG remains a challenging\napplication, thus motivating future research.", "AI": {"tldr": "The paper introduces two legal RAG benchmarks (Bar Exam QA and Housing Statute QA) to address the lack of realistic benchmarks for legal AI systems, highlighting the challenges in legal RAG applications.", "motivation": "The lack of realistic benchmarks for legal retrieval-augmented LLMs (RAG systems) hinders development. The paper aims to fill this gap by creating specialized benchmarks.", "method": "Two novel legal RAG benchmarks were developed (Bar Exam QA and Housing Statute QA) using annotation processes mimicking legal research. Existing retriever pipelines were evaluated.", "result": "Legal RAG systems face significant challenges, as shown by the performance of existing pipelines on the new benchmarks.", "conclusion": "The benchmarks highlight the difficulty of legal RAG tasks, motivating further research in this area."}}
{"id": "2505.03973", "pdf": "https://arxiv.org/pdf/2505.03973", "abs": "https://arxiv.org/abs/2505.03973", "authors": ["Jiale Liu", "Yifan Zeng", "Shaokun Zhang", "Chi Zhang", "Malte H\u00f8jmark-Bertelsen", "Marie Normann Gadeberg", "Huazheng Wang", "Qingyun Wu"], "title": "Divide, Optimize, Merge: Fine-Grained LLM Agent Optimization at Scale", "categories": ["cs.CL"], "comment": null, "summary": "LLM-based optimization has shown remarkable potential in enhancing agentic\nsystems. However, the conventional approach of prompting LLM optimizer with the\nwhole training trajectories on training dataset in a single pass becomes\nuntenable as datasets grow, leading to context window overflow and degraded\npattern recognition. To address these challenges, we propose Fine-Grained\nOptimization (FGO), a scalable framework that divides large optimization tasks\ninto manageable subsets, performs targeted optimizations, and systematically\ncombines optimized components through progressive merging. Evaluation across\nALFWorld, LogisticsQA, and GAIA benchmarks demonstrate that FGO outperforms\nexisting approaches by 1.6-8.6% while reducing average prompt token consumption\nby 56.3%. Our framework provides a practical solution for scaling up LLM-based\noptimization of increasingly sophisticated agent systems. Further analysis\ndemonstrates that FGO achieves the most consistent performance gain in all\ntraining dataset sizes, showcasing its scalability and efficiency.", "AI": {"tldr": "FGO (Fine-Grained Optimization) is a scalable framework for LLM-based optimization, dividing tasks into subsets to avoid context overflow and improve efficiency, outperforming existing methods by 1.6-8.6%.", "motivation": "Addressing the limitations of conventional LLM optimization, which struggles with large datasets due to context window overflow and degraded performance.", "method": "Proposes FGO, which breaks large tasks into subsets, performs targeted optimizations, and merges results progressively.", "result": "FGO outperforms existing methods by 1.6-8.6% and reduces prompt token usage by 56.3%, showing consistent gains across dataset sizes.", "conclusion": "FGO provides a scalable and efficient solution for LLM-based optimization in agent systems."}}
{"id": "2505.04082", "pdf": "https://arxiv.org/pdf/2505.04082", "abs": "https://arxiv.org/abs/2505.04082", "authors": ["Ryota Sato", "Julius O. Smith III"], "title": "Aliasing Reduction in Neural Amp Modeling by Smoothing Activations", "categories": ["eess.AS", "cs.SD", "eess.SP"], "comment": "Accepted to DAFx 2025", "summary": "The increasing demand for high-quality digital emulations of analog audio\nhardware such as vintage guitar amplifiers has led to numerous works in\nneural-network-based black-box modeling, with deep learning architectures like\nWaveNet showing promising results. However, a key limitation in all of these\nmodels is the aliasing artifacts that arise from the use of nonlinear\nactivation functions in neural networks. In this paper, we investigate novel\nand modified activation functions aimed at mitigating aliasing within neural\namplifier models. Supporting this, we introduce a novel metric, the\nAliasing-to-Signal Ratio (ASR), which quantitatively assesses the level of\naliasing with high accuracy. Measuring also the conventional Error-to-Signal\nRatio (ESR), we conducted studies on a range of preexisting and modern\nactivation functions with varying stretch factors. Our findings confirmed that\nactivation functions with smoother curves tend to achieve lower ASR values,\nindicating a noticeable reduction in aliasing. Notably, this improvement in\naliasing reduction was achievable without a substantial increase in ESR,\ndemonstrating the potential for high modeling accuracy with reduced aliasing in\nneural amp models.", "AI": {"tldr": "The paper explores novel activation functions to reduce aliasing in neural-network-based audio hardware emulations, introducing the Aliasing-to-Signal Ratio (ASR) metric for assessment.", "motivation": "Address aliasing artifacts in neural amplifier models caused by nonlinear activation functions.", "method": "Investigate modified activation functions and introduce ASR to measure aliasing. Compare with Error-to-Signal Ratio (ESR).", "result": "Smoother activation functions reduce ASR without significantly increasing ESR, improving modeling accuracy.", "conclusion": "Improved activation functions can mitigate aliasing in neural amp models while maintaining accuracy."}}
{"id": "2505.03770", "pdf": "https://arxiv.org/pdf/2505.03770", "abs": "https://arxiv.org/abs/2505.03770", "authors": ["Mouad Abrini", "Omri Abend", "Dina Acklin", "Henny Admoni", "Gregor Aichinger", "Nitay Alon", "Zahra Ashktorab", "Ashish Atreja", "Moises Auron", "Alexander Aufreiter", "Raghav Awasthi", "Soumya Banerjee", "Joe M. Barnby", "Rhea Basappa", "Severin Bergsmann", "Djallel Bouneffouf", "Patrick Callaghan", "Marc Cavazza", "Thierry Chaminade", "Sonia Chernova", "Mohamed Chetouan", "Moumita Choudhury", "Axel Cleeremans", "Jacek B. Cywinski", "Fabio Cuzzolin", "Hokin Deng", "N'yoma Diamond", "Camilla Di Pasquasio", "Guillaume Dumas", "Max van Duijn", "Mahapatra Dwarikanath", "Qingying Gao", "Ashok Goel", "Rebecca Goldstein", "Matthew Gombolay", "Gabriel Enrique Gonzalez", "Amar Halilovic", "Tobias Halmdienst", "Mahimul Islam", "Julian Jara-Ettinger", "Natalie Kastel", "Renana Keydar", "Ashish K. Khanna", "Mahdi Khoramshahi", "JiHyun Kim", "MiHyeon Kim", "YoungBin Kim", "Senka Krivic", "Nikita Krasnytskyi", "Arun Kumar", "JuneHyoung Kwon", "Eunju Lee", "Shane Lee", "Peter R. Lewis", "Xue Li", "Yijiang Li", "Michal Lewandowski", "Nathan Lloyd", "Matthew B. Luebbers", "Dezhi Luo", "Haiyun Lyu", "Dwarikanath Mahapatra", "Kamal Maheshwari", "Mallika Mainali", "Piyush Mathur", "Patrick Mederitsch", "Shuwa Miura", "Manuel Preston de Miranda", "Reuth Mirsky", "Shreya Mishra", "Nina Moorman", "Katelyn Morrison", "John Muchovej", "Bernhard Nessler", "Felix Nessler", "Hieu Minh Jord Nguyen", "Abby Ortego", "Francis A. Papay", "Antoine Pasquali", "Hamed Rahimi", "Charumathi Raghu", "Amanda Royka", "Stefan Sarkadi", "Jaelle Scheuerman", "Simon Schmid", "Paul Schrater", "Anik Sen", "Zahra Sheikhbahaee", "Ke Shi", "Reid Simmons", "Nishant Singh", "Mason O. Smith", "Ramira van der Meulen", "Anthia Solaki", "Haoran Sun", "Viktor Szolga", "Matthew E. Taylor", "Travis Taylor", "Sanne Van Waveren", "Juan David Vargas", "Rineke Verbrugge", "Eitan Wagner", "Justin D. Weisz", "Ximing Wen", "William Yeoh", "Wenlong Zhang", "Michelle Zhao", "Shlomo Zilberstein"], "title": "Proceedings of 1st Workshop on Advancing Artificial Intelligence through Theory of Mind", "categories": ["cs.AI"], "comment": "workshop proceedings", "summary": "This volume includes a selection of papers presented at the Workshop on\nAdvancing Artificial Intelligence through Theory of Mind held at AAAI 2025 in\nPhiladelphia US on 3rd March 2025. The purpose of this volume is to provide an\nopen access and curated anthology for the ToM and AI research community.", "AI": {"tldr": "A curated anthology of papers from a 2025 AAAI workshop on advancing AI through Theory of Mind (ToM).", "motivation": "To provide an open-access resource for the ToM and AI research community.", "method": "Selection of papers presented at the AAAI 2025 workshop.", "result": "A published volume of research contributions.", "conclusion": "The volume serves as a valuable resource for advancing ToM in AI."}}
{"id": "2505.03774", "pdf": "https://arxiv.org/pdf/2505.03774", "abs": "https://arxiv.org/abs/2505.03774", "authors": ["Tao Yin", "Chen Zhao", "Xiaoyan Liu", "Minglai Shao"], "title": "Out-of-Distribution Detection in Heterogeneous Graphs via Energy Propagation", "categories": ["cs.LG", "cs.SI"], "comment": "Knowledge-Based Systems 2025", "summary": "Graph neural networks (GNNs) are proven effective in extracting complex node\nand structural information from graph data. While current GNNs perform well in\nnode classification tasks within in-distribution (ID) settings, real-world\nscenarios often present distribution shifts, leading to the presence of\nout-of-distribution (OOD) nodes. OOD detection in graphs is a crucial and\nchallenging task. Most existing research focuses on homogeneous graphs, but\nreal-world graphs are often heterogeneous, consisting of diverse node and edge\ntypes. This heterogeneity adds complexity and enriches the informational\ncontent. To the best of our knowledge, OOD detection in heterogeneous graphs\nremains an underexplored area. In this context, we propose a novel methodology\nfor OOD detection in heterogeneous graphs (OODHG) that aims to achieve two main\nobjectives: 1) detecting OOD nodes and 2) classifying all ID nodes based on the\nfirst task's results. Specifically, we learn representations for each node in\nthe heterogeneous graph, calculate energy values to determine whether nodes are\nOOD, and then classify ID nodes. To leverage the structural information of\nheterogeneous graphs, we introduce a meta-path-based energy propagation\nmechanism and an energy constraint to enhance the distinction between ID and\nOOD nodes. Extensive experimental findings substantiate the simplicity and\neffectiveness of OODHG, demonstrating its superiority over baseline models in\nOOD detection tasks and its accuracy in ID node classification.", "AI": {"tldr": "A novel method (OODHG) for detecting out-of-distribution (OOD) nodes in heterogeneous graphs, leveraging meta-path-based energy propagation and achieving superior performance in OOD detection and ID node classification.", "motivation": "Real-world graphs are often heterogeneous and involve distribution shifts, making OOD detection challenging. Existing research focuses on homogeneous graphs, leaving heterogeneous graphs underexplored.", "method": "Proposes OODHG: learns node representations, calculates energy values for OOD detection, and classifies ID nodes. Uses meta-path-based energy propagation and energy constraints.", "result": "OODHG outperforms baselines in OOD detection and accurately classifies ID nodes.", "conclusion": "OODHG is simple, effective, and superior for OOD detection in heterogeneous graphs."}}
{"id": "2505.03821", "pdf": "https://arxiv.org/pdf/2505.03821", "abs": "https://arxiv.org/abs/2505.03821", "authors": ["Gracjan G\u00f3ral", "Alicja Ziarko", "Piotr Mi\u0142o\u015b", "Micha\u0142 Nauman", "Maciej Wo\u0142czyk", "Micha\u0142 Kosi\u0144ski"], "title": "Beyond Recognition: Evaluating Visual Perspective Taking in Vision Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "Dataset:\n  https://huggingface.co/datasets/Gracjan/Isle/viewer/Isle-Brick-V2", "summary": "We investigate the ability of Vision Language Models (VLMs) to perform visual\nperspective taking using a novel set of visual tasks inspired by established\nhuman tests. Our approach leverages carefully controlled scenes, in which a\nsingle humanoid minifigure is paired with a single object. By systematically\nvarying spatial configurations - such as object position relative to the\nhumanoid minifigure and the humanoid minifigure's orientation - and using both\nbird's-eye and surface-level views, we created 144 unique visual tasks. Each\nvisual task is paired with a series of 7 diagnostic questions designed to\nassess three levels of visual cognition: scene understanding, spatial\nreasoning, and visual perspective taking. Our evaluation of several\nstate-of-the-art models, including GPT-4-Turbo, GPT-4o,\nLlama-3.2-11B-Vision-Instruct, and variants of Claude Sonnet, reveals that\nwhile they excel in scene understanding, the performance declines significantly\non spatial reasoning and further deteriorates on perspective-taking. Our\nanalysis suggests a gap between surface-level object recognition and the deeper\nspatial and perspective reasoning required for complex visual tasks, pointing\nto the need for integrating explicit geometric representations and tailored\ntraining protocols in future VLM development.", "AI": {"tldr": "VLMs struggle with spatial reasoning and perspective-taking despite excelling in scene understanding, highlighting the need for improved geometric representations and training.", "motivation": "To assess VLMs' ability in visual perspective taking using controlled tasks inspired by human tests.", "method": "Used 144 unique visual tasks with systematic spatial variations and diagnostic questions to evaluate scene understanding, spatial reasoning, and perspective-taking.", "result": "Models like GPT-4-Turbo and Claude Sonnet perform well in scene understanding but poorly in spatial reasoning and perspective-taking.", "conclusion": "Future VLM development should integrate explicit geometric representations and tailored training to bridge the gap in complex visual tasks."}}
{"id": "2505.04113", "pdf": "https://arxiv.org/pdf/2505.04113", "abs": "https://arxiv.org/abs/2505.04113", "authors": ["Xueyao Zhang", "Yuancheng Wang", "Chaoren Wang", "Ziniu Li", "Zhuo Chen", "Zhizheng Wu"], "title": "Advancing Zero-shot Text-to-Speech Intelligibility across Diverse Domains via Preference Alignment", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Modern zero-shot text-to-speech (TTS) systems, despite using extensive\npre-training, often struggle in challenging scenarios such as tongue twisters,\nrepeated words, code-switching, and cross-lingual synthesis, leading to\nintelligibility issues. To address these limitations, this paper leverages\npreference alignment techniques, which enable targeted construction of\nout-of-pretraining-distribution data to enhance performance. We introduce a new\ndataset, named the Intelligibility Preference Speech Dataset (INTP), and extend\nthe Direct Preference Optimization (DPO) framework to accommodate diverse TTS\narchitectures. After INTP alignment, in addition to intelligibility, we observe\noverall improvements including naturalness, similarity, and audio quality for\nmultiple TTS models across diverse domains. Based on that, we also verify the\nweak-to-strong generalization ability of INTP for more intelligible models such\nas CosyVoice 2 and Ints. Moreover, we showcase the potential for further\nimprovements through iterative alignment based on Ints. Audio samples are\navailable at https://intalign.github.io/.", "AI": {"tldr": "The paper introduces the Intelligibility Preference Speech Dataset (INTP) and extends the Direct Preference Optimization (DPO) framework to improve zero-shot TTS systems, addressing challenges like tongue twisters and cross-lingual synthesis.", "motivation": "Modern zero-shot TTS systems struggle with intelligibility in challenging scenarios, prompting the need for targeted improvements.", "method": "Leverages preference alignment techniques and introduces INTP, extending DPO for diverse TTS architectures.", "result": "INTP alignment improves intelligibility, naturalness, similarity, and audio quality across multiple TTS models, with weak-to-strong generalization demonstrated.", "conclusion": "The approach shows promise for further iterative improvements, as validated by models like CosyVoice 2 and Ints."}}
{"id": "2505.03864", "pdf": "https://arxiv.org/pdf/2505.03864", "abs": "https://arxiv.org/abs/2505.03864", "authors": ["Qiaomu Li", "Ying Xie"], "title": "From Glue-Code to Protocols: A Critical Analysis of A2A and MCP Integration for Scalable Agent Systems", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "Artificial intelligence is rapidly evolving towards multi-agent systems where\nnumerous AI agents collaborate and interact with external tools. Two key open\nstandards, Google's Agent to Agent (A2A) protocol for inter-agent communication\nand Anthropic's Model Context Protocol (MCP) for standardized tool access,\npromise to overcome the limitations of fragmented, custom integration\napproaches. While their potential synergy is significant, this paper argues\nthat effectively integrating A2A and MCP presents unique, emergent challenges\nat their intersection, particularly concerning semantic interoperability\nbetween agent tasks and tool capabilities, the compounded security risks\narising from combined discovery and execution, and the practical governance\nrequired for the envisioned \"Agent Economy\". This work provides a critical\nanalysis, moving beyond a survey to evaluate the practical implications and\ninherent difficulties of combining these horizontal and vertical integration\nstandards. We examine the benefits (e.g., specialization, scalability) while\ncritically assessing their dependencies and trade-offs in an integrated\ncontext. We identify key challenges increased by the integration, including\nnovel security vulnerabilities, privacy complexities, debugging difficulties\nacross protocols, and the need for robust semantic negotiation mechanisms. In\nsummary, A2A+MCP offers a vital architectural foundation, but fully realizing\nits potential requires substantial advancements to manage the complexities of\ntheir combined operation.", "AI": {"tldr": "The paper analyzes the challenges of integrating Google's A2A and Anthropic's MCP for multi-agent AI systems, focusing on semantic interoperability, security, governance, and practical implications.", "motivation": "To address the emergent challenges of combining A2A and MCP for seamless multi-agent collaboration and tool interaction.", "method": "Critical analysis of the integration's benefits, dependencies, and trade-offs, including security, privacy, debugging, and semantic negotiation.", "result": "Identifies key challenges like security vulnerabilities, privacy issues, and debugging difficulties, while acknowledging the foundational potential of A2A+MCP.", "conclusion": "A2A+MCP provides a vital foundation but requires advancements to manage complexities for full potential realization."}}
{"id": "2505.04116", "pdf": "https://arxiv.org/pdf/2505.04116", "abs": "https://arxiv.org/abs/2505.04116", "authors": ["Yu Cheng", "Jiuan Zhou", "Jiawei Chen", "Zhaoxia Yin", "Xinpeng Zhang"], "title": "RFNNS: Robust Fixed Neural Network Steganography with Popular Deep Generative Models", "categories": ["cs.MM"], "comment": null, "summary": "Image steganography is a technique that conceals secret information in a\ncover image to achieve covert communication. Recent research has demonstrated\nthat Fixed Neural Network Steganography (FNNS) exhibits significant practical\nadvantages, as it enables stable and efficient steganographic embedding and\nextraction without requiring neural network training. However, the stego image\ngenerated by existing FNNS methods suffers from considerable distortion and\nexhibits poor robustness, severely reducing the security and practicality of\nsteganography. To address the aforementioned issues, we propose a Robust Fixed\nNeural Network Steganography (RFNNS). In RFNNS, we introduce a texture-aware\nlocalization technique to add perturbations carrying secret image information\nto complex texture areas that are less perceptible to the human eye, thereby\nensuring the quality of the stego image. To enhance robustness, a robust\nsteganographic perturbation generation (RSPG) strategy is designed, which\nenables slight perturbations to be accurately decoded even after common image\nattacks. Subsequently, the generated robust perturbations are combined with the\nAI-generated cover image to produce the stego image. The receiver only needs to\nshare the secret key and employ the same decoding network structure to\naccurately extract the secret image from the attacked stego image. Experimental\nresults demonstrate that RFNNS achieves enhanced performance in terms of\nsecurity, including imperceptibility and anti-steganalysis performance.\nFurthermore, RFNNS demonstrates superior robustness against common image\nattacks, such as JPEG compression, Gaussian noise, and contrast adjustment,\nacross diverse embedding capacities, outperforming existing SOTA FNNS methods.", "AI": {"tldr": "RFNNS improves Fixed Neural Network Steganography by enhancing stego image quality and robustness against attacks, outperforming existing methods.", "motivation": "Existing FNNS methods cause high distortion and poor robustness in stego images, limiting security and practicality.", "method": "RFNNS uses texture-aware localization and robust perturbation generation to embed secret data in less perceptible areas and withstand attacks.", "result": "RFNNS achieves better security (imperceptibility, anti-steganalysis) and robustness against common attacks like JPEG compression and noise.", "conclusion": "RFNNS outperforms SOTA FNNS methods, offering practical and secure steganography."}}
{"id": "2505.03838", "pdf": "https://arxiv.org/pdf/2505.03838", "abs": "https://arxiv.org/abs/2505.03838", "authors": ["Ting Yu Tsai", "An Yu", "Meghana Spurthi Maadugundu", "Ishrat Jahan Mohima", "Umme Habiba Barsha", "Mei-Hwa F. Chen", "Balakrishnan Prabhakaran", "Ming-Ching Chang"], "title": "IntelliCardiac: An Intelligent Platform for Cardiac Image Segmentation and Classification", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Precise and effective processing of cardiac imaging data is critical for the\nidentification and management of the cardiovascular diseases. We introduce\nIntelliCardiac, a comprehensive, web-based medical image processing platform\nfor the automatic segmentation of 4D cardiac images and disease classification,\nutilizing an AI model trained on the publicly accessible ACDC dataset. The\nsystem, intended for patients, cardiologists, and healthcare professionals,\noffers an intuitive interface and uses deep learning models to identify\nessential heart structures and categorize cardiac diseases. The system supports\nanalysis of both the right and left ventricles as well as myocardium, and then\nclassifies patient's cardiac images into five diagnostic categories: dilated\ncardiomyopathy, myocardial infarction, hypertrophic cardiomyopathy, right\nventricular abnormality, and no disease. IntelliCardiac combines a deep\nlearning-based segmentation model with a two-step classification pipeline. The\nsegmentation module gains an overall accuracy of 92.6\\%. The classification\nmodule, trained on characteristics taken from segmented heart structures,\nachieves 98\\% accuracy in five categories. These results exceed the performance\nof the existing state-of-the-art methods that integrate both segmentation and\nclassification models. IntelliCardiac, which supports real-time visualization,\nworkflow integration, and AI-assisted diagnostics, has great potential as a\nscalable, accurate tool for clinical decision assistance in cardiac imaging and\ndiagnosis.", "AI": {"tldr": "IntelliCardiac is a web-based AI platform for 4D cardiac image segmentation and disease classification, achieving high accuracy and outperforming existing methods.", "motivation": "To provide precise and effective processing of cardiac imaging data for better identification and management of cardiovascular diseases.", "method": "Uses deep learning models for segmentation and a two-step classification pipeline, trained on the ACDC dataset.", "result": "Segmentation accuracy of 92.6% and classification accuracy of 98% in five disease categories.", "conclusion": "IntelliCardiac is a scalable, accurate tool for clinical decision assistance in cardiac imaging and diagnosis."}}
{"id": "2505.03981", "pdf": "https://arxiv.org/pdf/2505.03981", "abs": "https://arxiv.org/abs/2505.03981", "authors": ["Qianchu Liu", "Sheng Zhang", "Guanghui Qin", "Timothy Ossowski", "Yu Gu", "Ying Jin", "Sid Kiblawi", "Sam Preston", "Mu Wei", "Paul Vozila", "Tristan Naumann", "Hoifung Poon"], "title": "X-Reasoner: Towards Generalizable Reasoning Across Modalities and Domains", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent proprietary models (e.g., o3) have begun to demonstrate strong\nmultimodal reasoning capabilities. Yet, most existing open-source research\nconcentrates on training text-only reasoning models, with evaluations limited\nto mainly mathematical and general-domain tasks. Therefore, it remains unclear\nhow to effectively extend reasoning capabilities beyond text input and general\ndomains. This paper explores a fundamental research question: Is reasoning\ngeneralizable across modalities and domains? Our findings support an\naffirmative answer: General-domain text-based post-training can enable such\nstrong generalizable reasoning. Leveraging this finding, we introduce\nX-Reasoner, a vision-language model post-trained solely on general-domain text\nfor generalizable reasoning, using a two-stage approach: an initial supervised\nfine-tuning phase with distilled long chain-of-thoughts, followed by\nreinforcement learning with verifiable rewards. Experiments show that\nX-Reasoner successfully transfers reasoning capabilities to both multimodal and\nout-of-domain settings, outperforming existing state-of-the-art models trained\nwith in-domain and multimodal data across various general and medical\nbenchmarks (Figure 1). Additionally, we find that X-Reasoner's performance in\nspecialized domains can be further enhanced through continued training on\ndomain-specific text-only data. Building upon this, we introduce\nX-Reasoner-Med, a medical-specialized variant that achieves new state of the\nart on numerous text-only and multimodal medical benchmarks.", "AI": {"tldr": "X-Reasoner, a vision-language model post-trained on general-domain text, demonstrates generalizable reasoning across modalities and domains, outperforming state-of-the-art models.", "motivation": "Proprietary models show strong multimodal reasoning, but open-source research focuses on text-only models. This paper explores if reasoning generalizes across modalities and domains.", "method": "Two-stage approach: supervised fine-tuning with distilled long chain-of-thoughts, followed by reinforcement learning with verifiable rewards.", "result": "X-Reasoner transfers reasoning to multimodal and out-of-domain settings, outperforming existing models. Continued training enhances specialized performance, leading to X-Reasoner-Med.", "conclusion": "General-domain text-based post-training enables strong generalizable reasoning, with potential for domain-specific enhancement."}}
{"id": "2505.04237", "pdf": "https://arxiv.org/pdf/2505.04237", "abs": "https://arxiv.org/abs/2505.04237", "authors": ["Rauf Nasretdinov", "Roman Korostik", "Ante Juki\u0107"], "title": "Robust Speech Recognition with Schr\u00f6dinger Bridge-Based Speech Enhancement", "categories": ["eess.AS"], "comment": "5 pages. Published in ICASSP 2025", "summary": "In this work, we investigate application of generative speech enhancement to\nimprove the robustness of ASR models in noisy and reverberant conditions. We\nemploy a recently-proposed speech enhancement model based on Schr\\\"odinger\nbridge, which has been shown to perform well compared to diffusion-based\napproaches. We analyze the impact of model scaling and different sampling\nmethods on the ASR performance. Furthermore, we compare the considered model\nwith predictive and diffusion-based baselines and analyze the speech\nrecognition performance when using different pre-trained ASR models. The\nproposed approach significantly reduces the word error rate, reducing it by\napproximately 40% relative to the unprocessed speech signals and by\napproximately 8% relative to a similarly sized predictive approach.", "AI": {"tldr": "Generative speech enhancement using Schr\u00f6dinger bridge improves ASR robustness in noisy/reverberant conditions, reducing word error rate by 40% vs. unprocessed speech and 8% vs. predictive baselines.", "motivation": "To enhance ASR model robustness in challenging acoustic environments (noisy and reverberant conditions).", "method": "Employ a Schr\u00f6dinger bridge-based speech enhancement model, analyze scaling and sampling methods, and compare with predictive/diffusion baselines using pre-trained ASR models.", "result": "Significant reduction in word error rate: 40% relative to unprocessed speech and 8% relative to predictive baselines.", "conclusion": "The Schr\u00f6dinger bridge approach is effective for improving ASR performance in noisy/reverberant environments."}}
{"id": "2505.03800", "pdf": "https://arxiv.org/pdf/2505.03800", "abs": "https://arxiv.org/abs/2505.03800", "authors": ["TianYi Yu"], "title": "Design description of Wisdom Computing Persperctive", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "This course design aims to develop and research a handwriting matrix\nrecognition and step-by-step visual calculation process display system,\naddressing the issue of abstract formulas and complex calculation steps that\nstudents find difficult to understand when learning mathematics. By integrating\nartificial intelligence with visualization animation technology, the system\nenhances precise recognition of handwritten matrix content through the\nintroduction of Mamba backbone networks, completes digital extraction and\nmatrix reconstruction using the YOLO model, and simultaneously combines\nCoordAttention coordinate attention mechanisms to improve the accurate grasp of\ncharacter spatial positions. The calculation process is demonstrated frame by\nframe through the Manim animation engine, vividly showcasing each mathematical\ncalculation step, helping students intuitively understand the intrinsic logic\nof mathematical operations. Through dynamically generating animation processes\nfor different computational tasks, the system exhibits high modularity and\nflexibility, capable of generating various mathematical operation examples in\nreal-time according to student needs. By innovating human-computer interaction\nmethods, it brings mathematical calculation processes to life, helping students\nbridge the gap between knowledge and understanding on a deeper level,\nultimately achieving a learning experience where \"every step is understood.\"\nThe system's scalability and interactivity make it an intuitive, user-friendly,\nand efficient auxiliary tool in education.", "AI": {"tldr": "A system combining AI and visualization to recognize handwritten matrices and display calculation steps, enhancing math learning.", "motivation": "Addresses students' difficulty in understanding abstract math formulas and complex calculations.", "method": "Uses Mamba backbone networks for handwriting recognition, YOLO for matrix extraction, CoordAttention for spatial accuracy, and Manim for animated step-by-step displays.", "result": "Creates a modular, flexible system that dynamically generates animations for various math tasks, improving student comprehension.", "conclusion": "The system is an intuitive, interactive educational tool that bridges the gap between knowledge and understanding in math."}}
{"id": "2505.03775", "pdf": "https://arxiv.org/pdf/2505.03775", "abs": "https://arxiv.org/abs/2505.03775", "authors": ["Linqing Chen", "Weilei Wang", "Wentao Wu", "Hanmeng Zhong"], "title": "Hierarchical Multi-Label Generation with Probabilistic Level-Constraint", "categories": ["cs.LG"], "comment": null, "summary": "Hierarchical Extreme Multi-Label Classification poses greater difficulties\ncompared to traditional multi-label classification because of the intricate\nhierarchical connections of labels within a domain-specific taxonomy and the\nsubstantial number of labels. Some of the prior research endeavors centered on\nclassifying text through several ancillary stages such as the cluster algorithm\nand multiphase classification. Others made attempts to leverage the assistance\nof generative methods yet were unable to properly control the output of the\ngenerative model. We redefine the task from hierarchical multi-Label\nclassification to Hierarchical Multi-Label Generation (HMG) and employ a\ngenerative framework with Probabilistic Level Constraints (PLC) to generate\nhierarchical labels within a specific taxonomy that have complex hierarchical\nrelationships. The approach we proposed in this paper enables the framework to\ngenerate all relevant labels across levels for each document without relying on\npreliminary operations like clustering. Meanwhile, it can control the model\noutput precisely in terms of count, length, and level aspects. Experiments\ndemonstrate that our approach not only achieves a new SOTA performance in the\nHMG task, but also has a much better performance in constrained the output of\nmodel than previous research work.", "AI": {"tldr": "The paper redefines hierarchical multi-label classification as Hierarchical Multi-Label Generation (HMG), using a generative framework with Probabilistic Level Constraints (PLC) to improve performance and control over model outputs.", "motivation": "Addressing the challenges of hierarchical label relationships and large label counts in extreme multi-label classification, previous methods lacked precision in generative model outputs.", "method": "Proposes a generative framework with PLC to generate hierarchical labels without preliminary steps like clustering, ensuring precise control over output count, length, and level.", "result": "Achieves state-of-the-art performance in HMG and significantly better control over model outputs compared to prior work.", "conclusion": "The proposed HMG framework with PLC effectively handles hierarchical label generation and outperforms existing methods in both performance and output control."}}
{"id": "2505.03826", "pdf": "https://arxiv.org/pdf/2505.03826", "abs": "https://arxiv.org/abs/2505.03826", "authors": ["Minji Kang", "Seongho Kim", "Eunseo Go", "Donghyeon Paek", "Geon Lim", "Muyoung Kim", "Soyeun Kim", "Sung Kyu Jang", "Min Sup Choi", "Woo Seok Kang", "Jaehyun Kim", "Jaekwang Kim", "Hyeong-U Kim"], "title": "In-situ and Non-contact Etch Depth Prediction in Plasma Etching via Machine Learning (ANN & BNN) and Digital Image Colorimetry", "categories": ["cs.CV", "cs.AI"], "comment": "20 pages", "summary": "Precise monitoring of etch depth and the thickness of insulating materials,\nsuch as Silicon dioxide and silicon nitride, is critical to ensuring device\nperformance and yield in semiconductor manufacturing. While conventional\nex-situ analysis methods are accurate, they are constrained by time delays and\ncontamination risks. To address these limitations, this study proposes a\nnon-contact, in-situ etch depth prediction framework based on machine learning\n(ML) techniques. Two scenarios are explored. In the first scenario, an\nartificial neural network (ANN) is trained to predict average etch depth from\nprocess parameters, achieving a significantly lower mean squared error (MSE)\ncompared to a linear baseline model. The approach is then extended to\nincorporate variability from repeated measurements using a Bayesian Neural\nNetwork (BNN) to capture both aleatoric and epistemic uncertainty. Coverage\nanalysis confirms the BNN's capability to provide reliable uncertainty\nestimates. In the second scenario, we demonstrate the feasibility of using RGB\ndata from digital image colorimetry (DIC) as input for etch depth prediction,\nachieving strong performance even in the absence of explicit process\nparameters. These results suggest that the integration of DIC and ML offers a\nviable, cost-effective alternative for real-time, in-situ, and non-invasive\nmonitoring in plasma etching processes, contributing to enhanced process\nstability, and manufacturing efficiency.", "AI": {"tldr": "A machine learning-based framework for in-situ etch depth prediction in semiconductor manufacturing, using ANN and BNN for accuracy and uncertainty, and RGB data for cost-effective monitoring.", "motivation": "Addressing limitations of conventional ex-situ methods (time delays, contamination risks) in monitoring etch depth and insulating material thickness.", "method": "Proposes ML techniques: ANN for average etch depth prediction, BNN for uncertainty, and RGB data from DIC for input.", "result": "ANN outperforms linear models; BNN provides reliable uncertainty estimates. RGB data shows strong performance without explicit process parameters.", "conclusion": "Integration of DIC and ML offers a viable, cost-effective, real-time, in-situ monitoring solution for plasma etching, enhancing process stability and efficiency."}}
{"id": "2505.04451", "pdf": "https://arxiv.org/pdf/2505.04451", "abs": "https://arxiv.org/abs/2505.04451", "authors": ["Yohannis Telila", "Tommaso Cucinotta", "Davide Bacciu"], "title": "Automatic Music Transcription using Convolutional Neural Networks and Constant-Q transform", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "comment": "6 pages", "summary": "Automatic music transcription (AMT) is the problem of analyzing an audio\nrecording of a musical piece and detecting notes that are being played. AMT is\na challenging problem, particularly when it comes to polyphonic music. The goal\nof AMT is to produce a score representation of a music piece, by analyzing a\nsound signal containing multiple notes played simultaneously. In this work, we\ndesign a processing pipeline that can transform classical piano audio files in\n.wav format into a music score representation. The features from the audio\nsignals are extracted using the constant-Q transform, and the resulting\ncoefficients are used as an input to the convolutional neural network (CNN)\nmodel.", "AI": {"tldr": "A method for automatic music transcription (AMT) using constant-Q transform and CNN to convert piano audio into a music score.", "motivation": "To address the challenge of transcribing polyphonic music, particularly classical piano, into a score representation.", "method": "Uses constant-Q transform for feature extraction and a CNN model to process the audio signals.", "result": "Transforms .wav piano audio files into a music score representation.", "conclusion": "The proposed pipeline effectively converts piano audio into a score, demonstrating the potential of CNN in AMT."}}
{"id": "2505.04364", "pdf": "https://arxiv.org/pdf/2505.04364", "abs": "https://arxiv.org/abs/2505.04364", "authors": ["Kai Ruan", "Mowen Huang", "Ji-Rong Wen", "Hao Sun"], "title": "Benchmarking LLMs' Swarm intelligence", "categories": ["cs.MA", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) show potential for complex reasoning, yet their\ncapacity for emergent coordination in Multi-Agent Systems (MAS) when operating\nunder strict constraints-such as limited local perception and communication,\ncharacteristic of natural swarms-remains largely unexplored, particularly\nconcerning the nuances of swarm intelligence. Existing benchmarks often do not\nfully capture the unique challenges of decentralized coordination that arise\nwhen agents operate with incomplete spatio-temporal information. To bridge this\ngap, we introduce SwarmBench, a novel benchmark designed to systematically\nevaluate the swarm intelligence capabilities of LLMs acting as decentralized\nagents. SwarmBench features five foundational MAS coordination tasks within a\nconfigurable 2D grid environment, forcing agents to rely primarily on local\nsensory input (k x k view) and local communication. We propose metrics for\ncoordination effectiveness and analyze emergent group dynamics. Evaluating\nseveral leading LLMs in a zero-shot setting, we find significant performance\nvariations across tasks, highlighting the difficulties posed by local\ninformation constraints. While some coordination emerges, results indicate\nlimitations in robust planning and strategy formation under uncertainty in\nthese decentralized scenarios. Assessing LLMs under swarm-like conditions is\ncrucial for realizing their potential in future decentralized systems. We\nrelease SwarmBench as an open, extensible toolkit-built upon a customizable and\nscalable physical system with defined mechanical properties. It provides\nenvironments, prompts, evaluation scripts, and the comprehensive experimental\ndatasets generated, aiming to foster reproducible research into LLM-based MAS\ncoordination and the theoretical underpinnings of Embodied MAS. Our code\nrepository is available at https://github.com/x66ccff/swarmbench.", "AI": {"tldr": "SwarmBench is introduced to evaluate LLMs' swarm intelligence in decentralized MAS under local constraints, revealing performance variations and coordination challenges.", "motivation": "To explore LLMs' emergent coordination in MAS under strict, swarm-like constraints, addressing gaps in existing benchmarks.", "method": "SwarmBench, a configurable 2D grid benchmark with five MAS tasks, evaluates LLMs using local perception and communication.", "result": "LLMs show performance variations and struggle with robust planning under local information constraints.", "conclusion": "SwarmBench aids reproducible research into LLM-based MAS coordination and Embodied MAS theory, released as an open toolkit."}}
{"id": "2505.04466", "pdf": "https://arxiv.org/pdf/2505.04466", "abs": "https://arxiv.org/abs/2505.04466", "authors": ["Mohammad Waquas Usmani", "Susmit Shannigrahi", "Michael Zink"], "title": "Securing Immersive 360 Video Streams through Attribute-Based Selective Encryption", "categories": ["cs.MM", "cs.CR", "eess.IV"], "comment": "8 pages plus references, 10 figures, some with subfigures", "summary": "Delivering high-quality, secure 360{\\deg} video content introduces unique\nchallenges, primarily due to the high bitrates and interactive demands of\nimmersive media. Traditional HTTPS-based methods, although widely used, face\nlimitations in computational efficiency and scalability when securing these\nhigh-resolution streams. To address these issues, this paper proposes a novel\nframework integrating Attribute-Based Encryption (ABE) with selective\nencryption techniques tailored specifically for tiled 360{\\deg} video\nstreaming. Our approach employs selective encryption of frames at varying\nlevels to reduce computational overhead while ensuring robust protection\nagainst unauthorized access.\n  Moreover, we explore viewport-adaptive encryption, dynamically encrypting\nmore frames within tiles occupying larger portions of the viewer's field of\nview. This targeted method significantly enhances security in critical viewing\nareas without unnecessary overhead in peripheral regions. We deploy and\nevaluate our proposed approach using the CloudLab testbed, comparing its\nperformance against traditional HTTPS streaming. Experimental results\ndemonstrate that our ABE-based model achieves reduced computational load on\nintermediate caches, improves cache hit rates, and maintains comparable visual\nquality to HTTPS, as assessed by Video Multimethod Assessment Fusion (VMAF).", "AI": {"tldr": "A novel ABE-based framework for secure 360\u00b0 video streaming reduces computational overhead while maintaining security and quality.", "motivation": "Addressing the inefficiency and scalability issues of HTTPS in securing high-bitrate 360\u00b0 video streams.", "method": "Integrates ABE with selective encryption, focusing on viewport-adaptive encryption for dynamic frame protection.", "result": "Reduced computational load, improved cache hit rates, and maintained visual quality comparable to HTTPS.", "conclusion": "The proposed ABE-based framework efficiently secures 360\u00b0 video streaming with minimal overhead."}}
{"id": "2505.03844", "pdf": "https://arxiv.org/pdf/2505.03844", "abs": "https://arxiv.org/abs/2505.03844", "authors": ["Sol\u00e8ne Debuys\u00e8re", "Nicolas Trouv\u00e9", "Nathan Letheule", "Olivier L\u00e9v\u00eaque", "Elise Colin"], "title": "From Spaceborn to Airborn: SAR Image Synthesis Using Foundation Models for Multi-Scale Adaptation", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "The availability of Synthetic Aperture Radar (SAR) satellite imagery has\nincreased considerably in recent years, with datasets commercially available.\nHowever, the acquisition of high-resolution SAR images in airborne\nconfigurations, remains costly and limited. Thus, the lack of open source,\nwell-labeled, or easily exploitable SAR text-image datasets is a barrier to the\nuse of existing foundation models in remote sensing applications. In this\ncontext, synthetic image generation is a promising solution to augment this\nscarce data, enabling a broader range of applications. Leveraging over 15 years\nof ONERA's extensive archival airborn data from acquisition campaigns, we\ncreated a comprehensive training dataset of 110 thousands SAR images to exploit\na 3.5 billion parameters pre-trained latent diffusion model. In this work, we\npresent a novel approach utilizing spatial conditioning techniques within a\nfoundation model to transform satellite SAR imagery into airborne SAR\nrepresentations. Additionally, we demonstrate that our pipeline is effective\nfor bridging the realism of simulated images generated by ONERA's physics-based\nsimulator EMPRISE. Our method explores a key application of AI in advancing SAR\nimaging technology. To the best of our knowledge, we are the first to introduce\nthis approach in the literature.", "AI": {"tldr": "A novel AI-driven method transforms satellite SAR imagery into airborne SAR representations using a pre-trained latent diffusion model, addressing data scarcity in remote sensing.", "motivation": "The lack of open-source, labeled SAR datasets hinders the use of foundation models in remote sensing. Synthetic image generation is proposed to augment scarce data.", "method": "Utilizes spatial conditioning in a 3.5B-parameter latent diffusion model, trained on 110k SAR images from ONERA's archival data, to convert satellite SAR to airborne SAR.", "result": "The pipeline effectively bridges realism between simulated and real images, advancing SAR imaging technology.", "conclusion": "This work pioneers a new approach in SAR imaging, demonstrating AI's potential to overcome data limitations in remote sensing."}}
{"id": "2505.04016", "pdf": "https://arxiv.org/pdf/2505.04016", "abs": "https://arxiv.org/abs/2505.04016", "authors": ["Darren Yow-Bang Wang", "Zhengyuan Shen", "Soumya Smruti Mishra", "Zhichao Xu", "Yifei Teng", "Haibo Ding"], "title": "SLOT: Structuring the Output of Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Structured outputs are essential for large language models (LLMs) in critical\napplications like agents and information extraction. Despite their\ncapabilities, LLMs often generate outputs that deviate from predefined schemas,\nsignificantly hampering reliable application development. We present SLOT\n(Structured LLM Output Transformer), a model-agnostic approach that transforms\nunstructured LLM outputs into precise structured formats. While existing\nsolutions predominantly rely on constrained decoding techniques or are tightly\ncoupled with specific models, SLOT employs a fine-tuned lightweight language\nmodel as a post-processing layer, achieving flexibility across various LLMs and\nschema specifications. We introduce a systematic pipeline for data curation and\nsynthesis alongside a formal evaluation methodology that quantifies both schema\naccuracy and content fidelity. Our results demonstrate that fine-tuned\nMistral-7B model with constrained decoding achieves near perfect schema\naccuracy (99.5%) and content similarity (94.0%), outperforming\nClaude-3.5-Sonnet by substantial margins (+25 and +20 percentage points,\nrespectively). Notably, even compact models like Llama-3.2-1B can match or\nexceed the structured output capabilities of much larger proprietary models\nwhen equipped with SLOT, enabling reliable structured generation in\nresource-constrained environments.", "AI": {"tldr": "SLOT (Structured LLM Output Transformer) is a model-agnostic method to convert unstructured LLM outputs into structured formats, outperforming existing solutions in schema accuracy and content fidelity.", "motivation": "LLMs often produce outputs that don't adhere to predefined schemas, limiting their reliability in critical applications like agents and information extraction.", "method": "SLOT uses a fine-tuned lightweight language model as a post-processing layer, combined with a systematic data curation pipeline and constrained decoding.", "result": "Fine-tuned Mistral-7B with SLOT achieves 99.5% schema accuracy and 94.0% content similarity, surpassing Claude-3.5-Sonnet by significant margins. Compact models like Llama-3.2-1B also perform well.", "conclusion": "SLOT enables reliable structured output generation across various LLMs, even in resource-constrained settings, outperforming proprietary models."}}
{"id": "2505.04382", "pdf": "https://arxiv.org/pdf/2505.04382", "abs": "https://arxiv.org/abs/2505.04382", "authors": ["Anton Selitskiy", "Maitreya Kocharekar"], "title": "Discrete Optimal Transport and Voice Conversion", "categories": ["eess.AS", "cs.LG"], "comment": "4 pages, 6 figures, 1 table", "summary": "In this work, we address the voice conversion (VC) task using a vector-based\ninterface. To align audio embeddings between speakers, we employ discrete\noptimal transport mapping. Our evaluation results demonstrate the high quality\nand effectiveness of this method. Additionally, we show that applying discrete\noptimal transport as a post-processing step in audio generation can lead to the\nincorrect classification of synthetic audio as real.", "AI": {"tldr": "The paper introduces a vector-based voice conversion method using discrete optimal transport for alignment, showing high quality and effectiveness, and highlights a potential misuse in audio generation.", "motivation": "To improve voice conversion by aligning audio embeddings between speakers using discrete optimal transport.", "method": "Employ discrete optimal transport mapping for aligning audio embeddings in voice conversion.", "result": "Demonstrates high quality and effectiveness of the method, with potential misuse in audio generation.", "conclusion": "Discrete optimal transport is effective for voice conversion but may have unintended consequences in synthetic audio classification."}}
{"id": "2505.03941", "pdf": "https://arxiv.org/pdf/2505.03941", "abs": "https://arxiv.org/abs/2505.03941", "authors": ["Matan Shamir", "Reuth Mirsky"], "title": "GRAML: Dynamic Goal Recognition As Metric Learning", "categories": ["cs.AI"], "comment": "Accepted for publication in International Joint Conference on\n  Artificial Intelligence (IJCAI) 2025", "summary": "Goal Recognition (GR) is the problem of recognizing an agent's objectives\nbased on observed actions. Recent data-driven approaches for GR alleviate the\nneed for costly, manually crafted domain models. However, these approaches can\nonly reason about a pre-defined set of goals, and time-consuming training is\nneeded for new emerging goals. To keep this model-learning automated while\nenabling quick adaptation to new goals, this paper introduces GRAML: Goal\nRecognition As Metric Learning. GRAML uses a Siamese network to treat GR as a\ndeep metric learning task, employing an RNN that learns a metric over an\nembedding space, where the embeddings for observation traces leading to\ndifferent goals are distant, and embeddings of traces leading to the same goals\nare close. This metric is especially useful when adapting to new goals, even if\ngiven just one example observation trace per goal. Evaluated on a versatile set\nof environments, GRAML shows speed, flexibility, and runtime improvements over\nthe state-of-the-art GR while maintaining accurate recognition.", "AI": {"tldr": "GRAML introduces a metric learning approach for Goal Recognition (GR) using a Siamese network, enabling quick adaptation to new goals with minimal training.", "motivation": "Traditional GR methods require costly domain models or extensive training for new goals, limiting flexibility and efficiency.", "method": "GRAML employs a Siamese network and RNN to learn a metric in an embedding space, distinguishing observation traces by goal similarity.", "result": "GRAML outperforms state-of-the-art GR methods in speed, flexibility, and runtime while maintaining accuracy.", "conclusion": "GRAML automates model-learning for GR and efficiently adapts to new goals, offering a scalable and accurate solution."}}
{"id": "2505.03776", "pdf": "https://arxiv.org/pdf/2505.03776", "abs": "https://arxiv.org/abs/2505.03776", "authors": ["Hansi Denis", "Siegfried Mercelis", "Ngoc-Quang Luong"], "title": "PAPN: Proximity Attention Encoder and Pointer Network Decoder for Parcel Pickup Route Prediction", "categories": ["cs.LG", "I.2.8; F.2.2"], "comment": "9 pages, 2 figures, 2 tables", "summary": "Optimization of the last-mile delivery and first-mile pickup of parcels is an\nintegral part of the broader logistics optimization pipeline as it entails both\ncost and resource efficiency as well as a heightened service quality. Such\noptimization requires accurate route and time prediction systems to adapt to\ndifferent scenarios in advance. This work tackles the first building block,\nnamely route prediction. This is done by introducing a novel Proximity\nAttention mechanism in an encoder-decoder architecture utilizing a Pointer\nNetwork in the decoding process (Proximity Attention Encoder and Pointer\nNetwork decoder: PAPN) to leverage the underlying connections between the\ndifferent visitable pickup positions at each timestep. To this local attention\nprocess is coupled global context computing via a multi-head attention\ntransformer encoder. The obtained global context is then mixed to an aggregated\nversion of the local embedding thus achieving a mix of global and local\nattention for complete modeling of the problems. Proximity attention is also\nused in the decoding process to skew predictions towards the locations with the\nhighest attention scores and thus using inter-connectivity of locations as a\nbase for next-location prediction. This method is trained, validated and tested\non a large industry-level dataset of real-world, large-scale last-mile delivery\nand first-mile pickup named LaDE[1]. This approach shows noticeable promise,\noutperforming all state-of-the-art supervised systems in terms of most metrics\nused for benchmarking methods on this dataset while still being competitive\nwith the best-performing reinforcement learning method named DRL4Route[2].", "AI": {"tldr": "The paper introduces a novel Proximity Attention mechanism (PAPN) for route prediction in last-mile delivery and first-mile pickup, combining local and global attention to outperform state-of-the-art methods.", "motivation": "Optimizing parcel delivery and pickup requires accurate route prediction to enhance cost, resource efficiency, and service quality.", "method": "Uses a Proximity Attention Encoder and Pointer Network decoder (PAPN) with local and global attention, trained on the LaDE dataset.", "result": "Outperforms state-of-the-art supervised systems and competes with the best reinforcement learning method (DRL4Route).", "conclusion": "PAPN demonstrates promise for route prediction in logistics, leveraging attention mechanisms for improved performance."}}
{"id": "2505.03829", "pdf": "https://arxiv.org/pdf/2505.03829", "abs": "https://arxiv.org/abs/2505.03829", "authors": ["Yogesh Kumar"], "title": "VideoLLM Benchmarks and Evaluation: A Survey", "categories": ["cs.CV", "cs.AI"], "comment": "12 pages, 2 Tables", "summary": "The rapid development of Large Language Models (LLMs) has catalyzed\nsignificant advancements in video understanding technologies. This survey\nprovides a comprehensive analysis of benchmarks and evaluation methodologies\nspecifically designed or used for Video Large Language Models (VideoLLMs). We\nexamine the current landscape of video understanding benchmarks, discussing\ntheir characteristics, evaluation protocols, and limitations. The paper\nanalyzes various evaluation methodologies, including closed-set, open-set, and\nspecialized evaluations for temporal and spatiotemporal understanding tasks. We\nhighlight the performance trends of state-of-the-art VideoLLMs across these\nbenchmarks and identify key challenges in current evaluation frameworks.\nAdditionally, we propose future research directions to enhance benchmark\ndesign, evaluation metrics, and protocols, including the need for more diverse,\nmultimodal, and interpretability-focused benchmarks. This survey aims to equip\nresearchers with a structured understanding of how to effectively evaluate\nVideoLLMs and identify promising avenues for advancing the field of video\nunderstanding with large language models.", "AI": {"tldr": "A survey analyzing benchmarks and evaluation methods for Video Large Language Models (VideoLLMs), highlighting trends, challenges, and future research directions.", "motivation": "To provide a structured understanding of how to evaluate VideoLLMs and advance video understanding technologies.", "method": "Examination of video understanding benchmarks, their characteristics, evaluation protocols, and limitations, along with analysis of various evaluation methodologies.", "result": "Identifies performance trends of state-of-the-art VideoLLMs, key challenges in evaluation frameworks, and gaps in current benchmarks.", "conclusion": "Proposes future research directions for improving benchmark design, metrics, and protocols, emphasizing diversity, multimodality, and interpretability."}}
{"id": "2505.04457", "pdf": "https://arxiv.org/pdf/2505.04457", "abs": "https://arxiv.org/abs/2505.04457", "authors": ["Shigeki Karita", "Yuma Koizumi", "Heiga Zen", "Haruko Ishikawa", "Robin Scheibler", "Michiel Bacchiani"], "title": "Miipher-2: A Universal Speech Restoration Model for Million-Hour Scale Data Restoration", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": null, "summary": "Training data cleaning is a new application for generative model-based speech\nrestoration (SR). This paper introduces Miipher-2, an SR model designed for\nmillion-hour scale data, for training data cleaning for large-scale generative\nmodels like large language models. Key challenges addressed include\ngeneralization to unseen languages, operation without explicit conditioning\n(e.g., text, speaker ID), and computational efficiency. Miipher-2 utilizes a\nfrozen, pre-trained Universal Speech Model (USM), supporting over 300\nlanguages, as a robust, conditioning-free feature extractor. To optimize\nefficiency and minimize memory, Miipher-2 incorporates parallel adapters for\npredicting clean USM features from noisy inputs and employs the WaneFit neural\nvocoder for waveform synthesis. These components were trained on 3,000 hours of\nmulti-lingual, studio-quality recordings with augmented degradations, while USM\nparameters remained fixed. Experimental results demonstrate Miipher-2's\nsuperior or comparable performance to conventional SR models in\nword-error-rate, speaker similarity, and both objective and subjective sound\nquality scores across all tested languages. Miipher-2 operates efficiently on\nconsumer-grade accelerators, achieving a real-time factor of 0.0078, enabling\nthe processing of a million-hour speech dataset in approximately three days\nusing only 100 such accelerators.", "AI": {"tldr": "Miipher-2 is a speech restoration model for cleaning training data in large-scale generative models, addressing challenges like generalization, efficiency, and no explicit conditioning. It uses a frozen USM for feature extraction and achieves high performance across languages.", "motivation": "To enable efficient and scalable cleaning of training data for large generative models, especially for unseen languages and without explicit conditioning.", "method": "Utilizes a frozen USM for feature extraction, parallel adapters for clean feature prediction, and WaneFit vocoder for synthesis. Trained on multi-lingual data with degradations.", "result": "Outperforms or matches conventional SR models in word-error-rate, speaker similarity, and sound quality. Efficiently processes million-hour datasets.", "conclusion": "Miipher-2 is a scalable, efficient solution for speech data cleaning, suitable for large-scale applications."}}
{"id": "2505.04379", "pdf": "https://arxiv.org/pdf/2505.04379", "abs": "https://arxiv.org/abs/2505.04379", "authors": ["Mohammad Elayan", "Wissam Kontar"], "title": "Consensus-Aware AV Behavior: Trade-offs Between Safety, Interaction, and Performance in Mixed Urban Traffic", "categories": ["cs.MA", "cs.AI", "cs.SY", "eess.SY"], "comment": "7 pages, 8 figures", "summary": "Transportation systems have long been shaped by complexity and heterogeneity,\ndriven by the interdependency of agent actions and traffic outcomes. The\ndeployment of automated vehicles (AVs) in such systems introduces a new\nchallenge: achieving consensus across safety, interaction quality, and traffic\nperformance. In this work, we position consensus as a fundamental property of\nthe traffic system and aim to quantify it. We use high-resolution trajectory\ndata from the Third Generation Simulation (TGSIM) dataset to empirically\nanalyze AV and human-driven vehicle (HDV) behavior at a signalized urban\nintersection and around vulnerable road users (VRUs). Key metrics, including\nTime-to-Collision (TTC), Post-Encroachment Time (PET), deceleration patterns,\nheadways, and string stability, are evaluated across the three performance\ndimensions. Results show that full consensus across safety, interaction, and\nperformance is rare, with only 1.63% of AV-VRU interaction frames meeting all\nthree conditions. These findings highlight the need for AV models that\nexplicitly balance multi-dimensional performance in mixed-traffic environments.\nFull reproducibility is supported via our open-source codebase on\nhttps://github.com/wissamkontar/Consensus-AV-Analysis.", "AI": {"tldr": "The paper analyzes consensus in transportation systems with AVs, using TGSIM data to evaluate safety, interaction, and performance metrics. Full consensus is rare (1.63% of AV-VRU interactions), emphasizing the need for balanced AV models.", "motivation": "To address the challenge of achieving consensus in safety, interaction quality, and traffic performance in mixed-traffic systems with AVs.", "method": "Empirical analysis using high-resolution trajectory data from TGSIM, evaluating metrics like TTC, PET, deceleration, headways, and string stability.", "result": "Full consensus across safety, interaction, and performance is rare (1.63% of AV-VRU interactions).", "conclusion": "AV models must explicitly balance multi-dimensional performance in mixed-traffic environments."}}
{"id": "2505.04276", "pdf": "https://arxiv.org/pdf/2505.04276", "abs": "https://arxiv.org/abs/2505.04276", "authors": ["Yajie Fu", "Chaorui Huang", "Junwei Li", "Hui Kong", "Yibin Tian", "Huakang Li", "Zhiyuan Zhang"], "title": "HDiffTG: A Lightweight Hybrid Diffusion-Transformer-GCN Architecture for 3D Human Pose Estimation", "categories": ["cs.CV", "cs.MM"], "comment": "8 pages, 4 figures, International Joint Conference on Neural Networks\n  (IJCNN)", "summary": "We propose HDiffTG, a novel 3D Human Pose Estimation (3DHPE) method that\nintegrates Transformer, Graph Convolutional Network (GCN), and diffusion model\ninto a unified framework. HDiffTG leverages the strengths of these techniques\nto significantly improve pose estimation accuracy and robustness while\nmaintaining a lightweight design. The Transformer captures global\nspatiotemporal dependencies, the GCN models local skeletal structures, and the\ndiffusion model provides step-by-step optimization for fine-tuning, achieving a\ncomplementary balance between global and local features. This integration\nenhances the model's ability to handle pose estimation under occlusions and in\ncomplex scenarios. Furthermore, we introduce lightweight optimizations to the\nintegrated model and refine the objective function design to reduce\ncomputational overhead without compromising performance. Evaluation results on\nthe Human3.6M and MPI-INF-3DHP datasets demonstrate that HDiffTG achieves\nstate-of-the-art (SOTA) performance on the MPI-INF-3DHP dataset while excelling\nin both accuracy and computational efficiency. Additionally, the model exhibits\nexceptional robustness in noisy and occluded environments. Source codes and\nmodels are available at https://github.com/CirceJie/HDiffTG", "AI": {"tldr": "HDiffTG integrates Transformer, GCN, and diffusion models for 3D human pose estimation, achieving SOTA performance with robustness and efficiency.", "motivation": "To improve accuracy and robustness in 3D human pose estimation by combining global (Transformer), local (GCN), and fine-tuning (diffusion model) techniques.", "method": "Unified framework with Transformer for global dependencies, GCN for skeletal structures, and diffusion model for optimization. Lightweight optimizations reduce computational overhead.", "result": "SOTA performance on MPI-INF-3DHP, high accuracy, efficiency, and robustness in noisy/occluded scenarios.", "conclusion": "HDiffTG effectively balances global and local features, offering a lightweight, high-performance solution for 3D pose estimation."}}
{"id": "2505.03845", "pdf": "https://arxiv.org/pdf/2505.03845", "abs": "https://arxiv.org/abs/2505.03845", "authors": ["Ioannis Kyprakis", "Vasileios Skaramagkas", "Iro Boura", "Georgios Karamanis", "Dimitrios I. Fotiadis", "Zinovia Kefalopoulou", "Cleanthe Spanaki", "Manolis Tsiknakis"], "title": "A Deep Learning approach for Depressive Symptoms assessment in Parkinson's disease patients using facial videos", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Parkinson's disease (PD) is a neurodegenerative disorder, manifesting with\nmotor and non-motor symptoms. Depressive symptoms are prevalent in PD,\naffecting up to 45% of patients. They are often underdiagnosed due to\noverlapping motor features, such as hypomimia. This study explores deep\nlearning (DL) models-ViViT, Video Swin Tiny, and 3D CNN-LSTM with attention\nlayers-to assess the presence and severity of depressive symptoms, as detected\nby the Geriatric Depression Scale (GDS), in PD patients through facial video\nanalysis. The same parameters were assessed in a secondary analysis taking into\naccount whether patients were one hour after (ON-medication state) or 12 hours\nwithout (OFF-medication state) dopaminergic medication. Using a dataset of\n1,875 videos from 178 patients, the Video Swin Tiny model achieved the highest\nperformance, with up to 94% accuracy and 93.7% F1-score in binary\nclassification (presence of absence of depressive symptoms), and 87.1% accuracy\nwith an 85.4% F1-score in multiclass tasks (absence or mild or severe\ndepressive symptoms).", "AI": {"tldr": "Deep learning models analyze facial videos to detect depressive symptoms in Parkinson's disease patients, with Video Swin Tiny performing best (94% accuracy).", "motivation": "Depressive symptoms in PD are underdiagnosed due to overlapping motor features; this study aims to improve detection using facial video analysis.", "method": "Tested ViViT, Video Swin Tiny, and 3D CNN-LSTM with attention layers on 1,875 videos from 178 PD patients, assessing GDS scores and medication states.", "result": "Video Swin Tiny achieved 94% accuracy in binary classification and 87.1% in multiclass tasks for depressive symptom detection.", "conclusion": "Facial video analysis with deep learning, especially Video Swin Tiny, effectively detects depressive symptoms in PD patients."}}
{"id": "2505.04072", "pdf": "https://arxiv.org/pdf/2505.04072", "abs": "https://arxiv.org/abs/2505.04072", "authors": ["Xu Huang", "Yuefeng Huang", "Weiwen Liu", "Xingshan Zeng", "Yasheng Wang", "Ruiming Tang", "Hong Xie", "Defu Lian"], "title": "Advancing and Benchmarking Personalized Tool Invocation for LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "14 pages, 7 figures, 5 tables", "summary": "Tool invocation is a crucial mechanism for extending the capabilities of\nLarge Language Models (LLMs) and has recently garnered significant attention.\nIt enables LLMs to solve complex problems through tool calls while accessing\nup-to-date world knowledge. However, existing work primarily focuses on the\nfundamental ability of LLMs to invoke tools for problem-solving, without\nconsidering personalized constraints in tool invocation. In this work, we\nintroduce the concept of Personalized Tool Invocation and define two key tasks:\nTool Preference and Profile-dependent Query. Tool Preference addresses user\npreferences when selecting among functionally similar tools, while\nProfile-dependent Query considers cases where a user query lacks certain tool\nparameters, requiring the model to infer them from the user profile. To tackle\nthese challenges, we propose PTool, a data synthesis framework designed for\npersonalized tool invocation. Additionally, we construct \\textbf{PTBench}, the\nfirst benchmark for evaluating personalized tool invocation. We then fine-tune\nvarious open-source models, demonstrating the effectiveness of our framework\nand providing valuable insights. Our benchmark is public at\nhttps://github.com/hyfshadow/PTBench.", "AI": {"tldr": "The paper introduces Personalized Tool Invocation (PTool) for LLMs, addressing user preferences and profile-dependent queries, and presents PTBench for evaluation.", "motivation": "Existing LLM tool invocation lacks personalization, ignoring user preferences and profile-based parameter inference.", "method": "Proposes PTool, a data synthesis framework, and PTBench, a benchmark for personalized tool invocation. Fine-tunes open-source models.", "result": "Demonstrates PTool's effectiveness and provides insights through model fine-tuning.", "conclusion": "PTool and PTBench advance personalized tool invocation, with the benchmark publicly available."}}
{"id": "2505.04419", "pdf": "https://arxiv.org/pdf/2505.04419", "abs": "https://arxiv.org/abs/2505.04419", "authors": ["Sumit Kumar", "Parampreet Singh", "Vipul Arora"], "title": "Recognizing Ornaments in Vocal Indian Art Music with Active Annotation", "categories": ["eess.AS", "cs.AI", "cs.LG"], "comment": null, "summary": "Ornamentations, embellishments, or microtonal inflections are essential to\nmelodic expression across many musical traditions, adding depth, nuance, and\nemotional impact to performances. Recognizing ornamentations in singing voices\nis key to MIR, with potential applications in music pedagogy, singer\nidentification, genre classification, and controlled singing voice generation.\nHowever, the lack of annotated datasets and specialized modeling approaches\nremains a major obstacle for progress in this research area. In this work, we\nintroduce R\\=aga Ornamentation Detection (ROD), a novel dataset comprising\nIndian classical music recordings curated by expert musicians. The dataset is\nannotated using a custom Human-in-the-Loop tool for six vocal ornaments marked\nas event-based labels. Using this dataset, we develop an ornamentation\ndetection model based on deep time-series analysis, preserving ornament\nboundaries during the chunking of long audio recordings. We conduct experiments\nusing different train-test configurations within the ROD dataset and also\nevaluate our approach on a separate, manually annotated dataset of Indian\nclassical concert recordings. Our experimental results support the superior\nperformance of our proposed approach over the baseline CRNN.", "AI": {"tldr": "The paper introduces ROD, a dataset for detecting vocal ornaments in Indian classical music, and proposes a deep time-series model for ornamentation detection, outperforming baseline methods.", "motivation": "Ornamentations are crucial for melodic expression but lack annotated datasets and specialized models, hindering research in MIR applications like pedagogy and genre classification.", "method": "The authors create the ROD dataset with expert annotations and develop a deep time-series model for ornament detection, ensuring boundary preservation in audio chunking.", "result": "Experiments show the proposed model outperforms the baseline CRNN on both the ROD dataset and a separate annotated concert dataset.", "conclusion": "The ROD dataset and the proposed model advance ornamentation detection in MIR, with potential applications in music analysis and generation."}}
{"id": "2505.03947", "pdf": "https://arxiv.org/pdf/2505.03947", "abs": "https://arxiv.org/abs/2505.03947", "authors": ["Xiang Li", "Yiyang Hao", "Doug Fulop"], "title": "Frog Soup: Zero-Shot, In-Context, and Sample-Efficient Frogger Agents", "categories": ["cs.AI"], "comment": null, "summary": "One of the primary aspirations in reinforcement learning research is\ndeveloping general-purpose agents capable of rapidly adapting to and mastering\nnovel tasks. While RL gaming agents have mastered many Atari games, they remain\nslow and costly to train for each game. In this work, we demonstrate that\nlatest reasoning LLMs with out-of-domain RL post-training can play a\nchallenging Atari game called Frogger under a zero-shot setting. We then\ninvestigate the effect of in-context learning and the amount of reasoning\neffort on LLM performance. Lastly, we demonstrate a way to bootstrap\ntraditional RL method with LLM demonstrations, which significantly improves\ntheir performance and sample efficiency. Our implementation is open sourced at\nhttps://github.com/AlienKevin/frogger.", "AI": {"tldr": "LLMs with RL post-training can play Atari's Frogger zero-shot, improve with in-context learning, and boost traditional RL methods via demonstrations.", "motivation": "Develop general-purpose RL agents that adapt quickly to new tasks, addressing the inefficiency of current RL methods.", "method": "Use reasoning LLMs with RL post-training for zero-shot play, study in-context learning, and bootstrap RL with LLM demonstrations.", "result": "LLMs perform well in Frogger zero-shot, benefit from in-context learning, and enhance RL methods' efficiency.", "conclusion": "LLMs show promise for efficient RL adaptation and can augment traditional RL training."}}
{"id": "2505.03777", "pdf": "https://arxiv.org/pdf/2505.03777", "abs": "https://arxiv.org/abs/2505.03777", "authors": ["LG AI Research", "Sehyun Chun", "Jiye Kim", "Ahra Jo", "Yeonsik Jo", "Seungyul Oh", "Seungjun Lee", "Kwangrok Ryoo", "Jongmin Lee", "Seunghwan Kim", "Byung Jun Kang", "Soonyoung Lee", "Jun Ha Park", "Chanwoo Moon", "Jiwon Ham", "Haein Lee", "Heejae Han", "Jaeseung Byun", "Soojong Do", "Minju Ha", "Dongyun Kim", "Kyunghoon Bae", "Woohyung Lim", "Edward Hwayoung Lee", "Yongmin Park", "Jeongsang Yu", "Gerrard Jeongwon Jo", "Yeonjung Hong", "Kyungjae Yoo", "Sehui Han", "Jaewan Lee", "Changyoung Park", "Kijeong Jeon", "Sihyuk Yi"], "title": "MolMole: Molecule Mining from Scientific Literature", "categories": ["cs.LG"], "comment": "15 pages, 12 figures", "summary": "The extraction of molecular structures and reaction data from scientific\ndocuments is challenging due to their varied, unstructured chemical formats and\ncomplex document layouts. To address this, we introduce MolMole, a vision-based\ndeep learning framework that unifies molecule detection, reaction diagram\nparsing, and optical chemical structure recognition (OCSR) into a single\npipeline for automating the extraction of chemical data directly from\npage-level documents. Recognizing the lack of a standard page-level benchmark\nand evaluation metric, we also present a testset of 550 pages annotated with\nmolecule bounding boxes, reaction labels, and MOLfiles, along with a novel\nevaluation metric. Experimental results demonstrate that MolMole outperforms\nexisting toolkits on both our benchmark and public datasets. The benchmark\ntestset will be publicly available, and the MolMole toolkit will be accessible\nsoon through an interactive demo on the LG AI Research website. For commercial\ninquiries, please contact us at\n\\href{mailto:contact_ddu@lgresearch.ai}{contact\\_ddu@lgresearch.ai}.", "AI": {"tldr": "MolMole is a vision-based deep learning framework for extracting chemical data from documents, outperforming existing tools and introducing a new benchmark and evaluation metric.", "motivation": "The challenge of extracting molecular structures and reaction data from unstructured chemical formats and complex document layouts.", "method": "MolMole unifies molecule detection, reaction diagram parsing, and optical chemical structure recognition (OCSR) into a single pipeline.", "result": "MolMole outperforms existing toolkits on both the introduced benchmark and public datasets.", "conclusion": "The benchmark testset will be public, and MolMole will be accessible via an interactive demo, with commercial inquiries directed to LG AI Research."}}
{"id": "2505.03832", "pdf": "https://arxiv.org/pdf/2505.03832", "abs": "https://arxiv.org/abs/2505.03832", "authors": ["Noor B. Tayfor", "Tarik A. Rashid", "Shko M. Qader", "Bryar A. Hassan", "Mohammed H. Abdalla", "Jafar Majidpour", "Aram M. Ahmed", "Hussein M. Ali", "Aso M. Aladdin", "Abdulhady A. Abdullah", "Ahmed S. Shamsaldin", "Haval M. Sidqi", "Abdulrahman Salih", "Zaher M. Yaseen", "Azad A. Ameen", "Janmenjoy Nayak", "Mahmood Yashar Hamza"], "title": "Video Forgery Detection for Surveillance Cameras: A Review", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The widespread availability of video recording through smartphones and\ndigital devices has made video-based evidence more accessible than ever.\nSurveillance footage plays a crucial role in security, law enforcement, and\njudicial processes. However, with the rise of advanced video editing tools,\ntampering with digital recordings has become increasingly easy, raising\nconcerns about their authenticity. Ensuring the integrity of surveillance\nvideos is essential, as manipulated footage can lead to misinformation and\nundermine judicial decisions. This paper provides a comprehensive review of\nexisting forensic techniques used to detect video forgery, focusing on their\neffectiveness in verifying the authenticity of surveillance recordings. Various\nmethods, including compression-based analysis, frame duplication detection, and\nmachine learning-based approaches, are explored. The findings highlight the\ngrowing necessity for more robust forensic techniques to counteract evolving\nforgery methods. Strengthening video forensic capabilities will ensure that\nsurveillance recordings remain credible and admissible as legal evidence.", "AI": {"tldr": "The paper reviews forensic techniques for detecting video forgery in surveillance footage, emphasizing the need for robust methods to ensure authenticity and legal credibility.", "motivation": "The rise of video editing tools has made tampering with digital recordings easier, threatening the integrity of surveillance footage used in security and judicial processes.", "method": "The study examines existing forensic techniques, including compression-based analysis, frame duplication detection, and machine learning-based approaches.", "result": "The findings underscore the need for more advanced forensic methods to counter evolving forgery techniques.", "conclusion": "Enhancing video forensic capabilities is crucial to maintaining the credibility and admissibility of surveillance recordings as legal evidence."}}
{"id": "2505.04621", "pdf": "https://arxiv.org/pdf/2505.04621", "abs": "https://arxiv.org/abs/2505.04621", "authors": ["Jessie Richter-Powell", "Antonio Torralba", "Jonathan Lorraine"], "title": "Score Distillation Sampling for Audio: Source Separation, Synthesis, and Beyond", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS", "68T07", "I.2.6; H.5.5; H.5.1"], "comment": "See the project website at\n  https://research.nvidia.com/labs/toronto-ai/Audio-SDS/", "summary": "We introduce Audio-SDS, a generalization of Score Distillation Sampling (SDS)\nto text-conditioned audio diffusion models. While SDS was initially designed\nfor text-to-3D generation using image diffusion, its core idea of distilling a\npowerful generative prior into a separate parametric representation extends to\nthe audio domain. Leveraging a single pretrained model, Audio-SDS enables a\nbroad range of tasks without requiring specialized datasets. In particular, we\ndemonstrate how Audio-SDS can guide physically informed impact sound\nsimulations, calibrate FM-synthesis parameters, and perform prompt-specified\nsource separation. Our findings illustrate the versatility of\ndistillation-based methods across modalities and establish a robust foundation\nfor future work using generative priors in audio tasks.", "AI": {"tldr": "Audio-SDS extends Score Distillation Sampling (SDS) to audio diffusion models, enabling diverse tasks like impact sound simulation and source separation without specialized datasets.", "motivation": "To generalize SDS, originally for text-to-3D generation, to audio tasks, leveraging generative priors for versatility.", "method": "Uses a pretrained audio diffusion model with SDS to guide tasks like sound simulation, FM-synthesis calibration, and source separation.", "result": "Demonstrates successful application across tasks, showing the method's adaptability.", "conclusion": "Audio-SDS provides a versatile foundation for future generative prior-based audio tasks."}}
{"id": "2505.04579", "pdf": "https://arxiv.org/pdf/2505.04579", "abs": "https://arxiv.org/abs/2505.04579", "authors": ["St\u00e9phane Aroca-Ouellette", "Miguel Aroca-Ouellette", "Katharina von der Wense", "Alessandro Roncone"], "title": "Implicitly Aligning Humans and Autonomous Agents through Shared Task Abstractions", "categories": ["cs.MA", "cs.LG"], "comment": "9 pages (7 paper + 2 references). To be published in IJCAI 2025", "summary": "In collaborative tasks, autonomous agents fall short of humans in their\ncapability to quickly adapt to new and unfamiliar teammates. We posit that a\nlimiting factor for zero-shot coordination is the lack of shared task\nabstractions, a mechanism humans rely on to implicitly align with teammates. To\naddress this gap, we introduce HA$^2$: Hierarchical Ad Hoc Agents, a framework\nleveraging hierarchical reinforcement learning to mimic the structured approach\nhumans use in collaboration. We evaluate HA$^2$ in the Overcooked environment,\ndemonstrating statistically significant improvement over existing baselines\nwhen paired with both unseen agents and humans, providing better resilience to\nenvironmental shifts, and outperforming all state-of-the-art methods.", "AI": {"tldr": "HA$^2$ improves zero-shot coordination in collaborative tasks by using hierarchical reinforcement learning to mimic human-like shared task abstractions, outperforming baselines and state-of-the-art methods.", "motivation": "Autonomous agents struggle with quick adaptation to new teammates due to lack of shared task abstractions, a key human capability.", "method": "HA$^2$ leverages hierarchical reinforcement learning to create structured collaboration akin to humans.", "result": "HA$^2$ shows significant improvement over baselines and state-of-the-art methods in the Overcooked environment, with better resilience to changes.", "conclusion": "HA$^2$ effectively bridges the gap in zero-shot coordination by emulating human collaboration strategies."}}
{"id": "2505.04488", "pdf": "https://arxiv.org/pdf/2505.04488", "abs": "https://arxiv.org/abs/2505.04488", "authors": ["Ziyi Zhang", "Zhen Sun", "Zongmin Zhang", "Zifan Peng", "Yuemeng Zhao", "Zichun Wang", "Zeren Luo", "Ruiting Zuo", "Xinlei He"], "title": "\"I Can See Forever!\": Evaluating Real-time VideoLLMs for Assisting Individuals with Visual Impairments", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.MM"], "comment": "12 pages, 6 figures", "summary": "The visually impaired population, especially the severely visually impaired,\nis currently large in scale, and daily activities pose significant challenges\nfor them. Although many studies use large language and vision-language models\nto assist the blind, most focus on static content and fail to meet real-time\nperception needs in dynamic and complex environments, such as daily activities.\nTo provide them with more effective intelligent assistance, it is imperative to\nincorporate advanced visual understanding technologies. Although real-time\nvision and speech interaction VideoLLMs demonstrate strong real-time visual\nunderstanding, no prior work has systematically evaluated their effectiveness\nin assisting visually impaired individuals. In this work, we conduct the first\nsuch evaluation. First, we construct a benchmark dataset (VisAssistDaily),\ncovering three categories of assistive tasks for visually impaired individuals:\nBasic Skills, Home Life Tasks, and Social Life Tasks. The results show that\nGPT-4o achieves the highest task success rate. Next, we conduct a user study to\nevaluate the models in both closed-world and open-world scenarios, further\nexploring the practical challenges of applying VideoLLMs in assistive contexts.\nOne key issue we identify is the difficulty current models face in perceiving\npotential hazards in dynamic environments. To address this, we build an\nenvironment-awareness dataset named SafeVid and introduce a polling mechanism\nthat enables the model to proactively detect environmental risks. We hope this\nwork provides valuable insights and inspiration for future research in this\nfield.", "AI": {"tldr": "The paper evaluates VideoLLMs for assisting visually impaired individuals in dynamic environments, introduces a benchmark dataset (VisAssistDaily), and highlights GPT-4o's high task success rate. It also identifies challenges like hazard perception and proposes solutions with SafeVid dataset and a polling mechanism.", "motivation": "To address the lack of real-time perception in assistive technologies for visually impaired individuals in dynamic environments.", "method": "Constructs VisAssistDaily benchmark dataset, evaluates VideoLLMs (including GPT-4o), conducts user studies, and introduces SafeVid dataset with a polling mechanism for hazard detection.", "result": "GPT-4o achieves the highest task success rate. Challenges in hazard perception are identified, and a solution is proposed.", "conclusion": "The work provides insights for improving assistive technologies for visually impaired individuals, emphasizing real-time hazard detection and dynamic environment adaptation."}}
{"id": "2505.04003", "pdf": "https://arxiv.org/pdf/2505.04003", "abs": "https://arxiv.org/abs/2505.04003", "authors": ["Feng Gao", "Sheng Liu", "Chuanzheng Gong", "Xiaowei Zhou", "Jiayi Wang", "Junyu Dong", "Qian Du"], "title": "Prototype-Based Information Compensation Network for Multi-Source Remote Sensing Data Classification", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted by IEEE TGRS 2025", "summary": "Multi-source remote sensing data joint classification aims to provide\naccuracy and reliability of land cover classification by leveraging the\ncomplementary information from multiple data sources. Existing methods confront\ntwo challenges: inter-frequency multi-source feature coupling and inconsistency\nof complementary information exploration. To solve these issues, we present a\nPrototype-based Information Compensation Network (PICNet) for land cover\nclassification based on HSI and SAR/LiDAR data. Specifically, we first design a\nfrequency interaction module to enhance the inter-frequency coupling in\nmulti-source feature extraction. The multi-source features are first decoupled\ninto high- and low-frequency components. Then, these features are recoupled to\nachieve efficient inter-frequency communication. Afterward, we design a\nprototype-based information compensation module to model the global\nmulti-source complementary information. Two sets of learnable modality\nprototypes are introduced to represent the global modality information of\nmulti-source data. Subsequently, cross-modal feature integration and alignment\nare achieved through cross-attention computation between the modality-specific\nprototype vectors and the raw feature representations. Extensive experiments on\nthree public datasets demonstrate the significant superiority of our PICNet\nover state-of-the-art methods. The codes are available at\nhttps://github.com/oucailab/PICNet.", "AI": {"tldr": "PICNet improves land cover classification by addressing inter-frequency feature coupling and complementary information inconsistency in multi-source remote sensing data.", "motivation": "To enhance accuracy and reliability in land cover classification by leveraging complementary information from HSI and SAR/LiDAR data.", "method": "Uses a Prototype-based Information Compensation Network (PICNet) with frequency interaction and prototype-based compensation modules.", "result": "Outperforms state-of-the-art methods on three public datasets.", "conclusion": "PICNet effectively addresses challenges in multi-source data classification, demonstrating superior performance."}}
{"id": "2505.04073", "pdf": "https://arxiv.org/pdf/2505.04073", "abs": "https://arxiv.org/abs/2505.04073", "authors": ["Mengxian Lyu", "Xiaohan Li", "Ziyi Chen", "Jinqian Pan", "Cheng Peng", "Sankalp Talankar", "Yonghui Wu"], "title": "Natural Language Generation in Healthcare: A Review of Methods and Applications", "categories": ["cs.CL"], "comment": null, "summary": "Natural language generation (NLG) is the key technology to achieve generative\nartificial intelligence (AI). With the breakthroughs in large language models\n(LLMs), NLG has been widely used in various medical applications, demonstrating\nthe potential to enhance clinical workflows, support clinical decision-making,\nand improve clinical documentation. Heterogeneous and diverse medical data\nmodalities, such as medical text, images, and knowledge bases, are utilized in\nNLG. Researchers have proposed many generative models and applied them in a\nnumber of healthcare applications. There is a need for a comprehensive review\nof NLG methods and applications in the medical domain. In this study, we\nsystematically reviewed 113 scientific publications from a total of 3,988\nNLG-related articles identified using a literature search, focusing on data\nmodality, model architecture, clinical applications, and evaluation methods.\nFollowing PRISMA (Preferred Reporting Items for Systematic reviews and\nMeta-Analyses) guidelines, we categorize key methods, identify clinical\napplications, and assess their capabilities, limitations, and emerging\nchallenges. This timely review covers the key NLG technologies and medical\napplications and provides valuable insights for future studies to leverage NLG\nto transform medical discovery and healthcare.", "AI": {"tldr": "A systematic review of 113 NLG-related medical publications, covering methods, applications, and challenges in healthcare.", "motivation": "To address the need for a comprehensive review of NLG methods and applications in the medical domain, given the growing use of NLG in healthcare.", "method": "Analyzed 113 publications from 3,988 NLG-related articles, focusing on data modality, model architecture, clinical applications, and evaluation methods, following PRISMA guidelines.", "result": "Identified key NLG technologies, categorized clinical applications, and assessed capabilities, limitations, and challenges in medical NLG.", "conclusion": "The review provides insights for future studies to leverage NLG for transforming medical discovery and healthcare."}}
{"id": "2505.04548", "pdf": "https://arxiv.org/pdf/2505.04548", "abs": "https://arxiv.org/abs/2505.04548", "authors": ["Austin Lu", "Kanad Sarkar", "Yongjie Zhuang", "Leo Lin", "Ryan M Corey", "Andrew C Singer"], "title": "Accelerating Audio Research with Robotic Dummy Heads", "categories": ["eess.AS", "cs.HC", "cs.RO", "cs.SD"], "comment": "WASPAA 2025", "summary": "This work introduces a robotic dummy head that fuses the acoustic realism of\nconventional audiological mannequins with the mobility of robots. The proposed\ndevice is capable of moving, talking, and listening as people do, and can be\nused to automate spatially-stationary audio experiments, thus accelerating the\npace of audio research. Critically, the device may also be used as a moving\nsound source in dynamic experiments, due to its quiet motor. This feature\ndifferentiates our work from previous robotic acoustic research platforms.\nValidation that the robot enables high quality audio data collection is\nprovided through various experiments and acoustic measurements. These\nexperiments also demonstrate how the robot might be used to study adaptive\nbinaural beamforming. Design files are provided as open-source to stimulate\nnovel audio research.", "AI": {"tldr": "A robotic dummy head combines acoustic realism and mobility to automate audio experiments and serve as a moving sound source, validated through experiments and open-sourced for research.", "motivation": "To bridge the gap between static acoustic mannequins and dynamic robotic platforms for advanced audio research.", "method": "Developed a robotic dummy head capable of movement, speech, and listening, with quiet motors for dynamic experiments.", "result": "Validated high-quality audio data collection and demonstrated utility in adaptive binaural beamforming studies.", "conclusion": "The device accelerates audio research by enabling dynamic experiments and is open-sourced to foster innovation."}}
{"id": "2505.03961", "pdf": "https://arxiv.org/pdf/2505.03961", "abs": "https://arxiv.org/abs/2505.03961", "authors": ["Gerrit Gro\u00dfmann", "Larisa Ivanova", "Sai Leela Poduru", "Mohaddeseh Tabrizian", "Islam Mesabah", "David A. Selby", "Sebastian J. Vollmer"], "title": "The Power of Stories: Narrative Priming Shapes How LLM Agents Collaborate and Compete", "categories": ["cs.AI", "cs.CL", "cs.MA", "I.2.11; I.2.7; I.6; J.4"], "comment": "16 pages, 8 figures. Code available at\n  https://github.com/storyagents25/story-agents", "summary": "According to Yuval Noah Harari, large-scale human cooperation is driven by\nshared narratives that encode common beliefs and values. This study explores\nwhether such narratives can similarly nudge LLM agents toward collaboration. We\nuse a finitely repeated public goods game in which LLM agents choose either\ncooperative or egoistic spending strategies. We prime agents with stories\nhighlighting teamwork to different degrees and test how this influences\nnegotiation outcomes. Our experiments explore four questions:(1) How do\nnarratives influence negotiation behavior? (2) What differs when agents share\nthe same story versus different ones? (3) What happens when the agent numbers\ngrow? (4) Are agents resilient against self-serving negotiators? We find that\nstory-based priming significantly affects negotiation strategies and success\nrates. Common stories improve collaboration, benefiting each agent. By\ncontrast, priming agents with different stories reverses this effect, and those\nagents primed toward self-interest prevail. We hypothesize that these results\ncarry implications for multi-agent system design and AI alignment.", "AI": {"tldr": "The study investigates how shared narratives influence LLM agents' collaboration in a public goods game, finding that common stories boost cooperation while differing stories or self-interest priming reduce it.", "motivation": "To explore whether shared narratives, which drive human cooperation, can similarly encourage collaboration among LLM agents.", "method": "A finitely repeated public goods game with LLM agents primed by teamwork stories, testing negotiation behavior under varying conditions.", "result": "Common stories improved collaboration, while differing stories or self-interest priming led to egoistic behavior and reduced success rates.", "conclusion": "Shared narratives can enhance LLM agent cooperation, suggesting implications for multi-agent system design and AI alignment."}}
{"id": "2505.03778", "pdf": "https://arxiv.org/pdf/2505.03778", "abs": "https://arxiv.org/abs/2505.03778", "authors": ["Jonathan Viquerat", "Paul Garnier", "Amirhossein Bateni", "Elie Hachem"], "title": "Dragonfly: a modular deep reinforcement learning library", "categories": ["cs.LG"], "comment": null, "summary": "Dragonfly is a deep reinforcement learning library focused on modularity, in\norder to ease experimentation and developments. It relies on a json\nserialization that allows to swap building blocks and perform parameter sweep,\nwhile minimizing code maintenance. Some of its features are specifically\ndesigned for CPU-intensive environments, such as numerical simulations. Its\nperformance on standard agents using common benchmarks compares favorably with\nthe literature.", "AI": {"tldr": "Dragonfly is a modular deep reinforcement learning library for easy experimentation, featuring JSON serialization and CPU-intensive environment support, with competitive benchmark performance.", "motivation": "To simplify experimentation and development in deep reinforcement learning by providing a modular and maintainable framework.", "method": "Uses JSON serialization for swapping building blocks and parameter sweeps, with features optimized for CPU-intensive tasks like numerical simulations.", "result": "Performs favorably compared to standard agents in common benchmarks.", "conclusion": "Dragonfly is an effective tool for modular and efficient deep reinforcement learning research and development."}}
{"id": "2505.03833", "pdf": "https://arxiv.org/pdf/2505.03833", "abs": "https://arxiv.org/abs/2505.03833", "authors": ["Xuechao Wang", "Sven Nomm", "Junqing Huang", "Kadri Medijainen", "Aaro Toomela", "Michael Ruzhansky"], "title": "PointExplainer: Towards Transparent Parkinson's Disease Diagnosis", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Deep neural networks have shown potential in analyzing digitized hand-drawn\nsignals for early diagnosis of Parkinson's disease. However, the lack of clear\ninterpretability in existing diagnostic methods presents a challenge to\nclinical trust. In this paper, we propose PointExplainer, an explainable\ndiagnostic strategy to identify hand-drawn regions that drive model diagnosis.\nSpecifically, PointExplainer assigns discrete attribution values to hand-drawn\nsegments, explicitly quantifying their relative contributions to the model's\ndecision. Its key components include: (i) a diagnosis module, which encodes\nhand-drawn signals into 3D point clouds to represent hand-drawn trajectories,\nand (ii) an explanation module, which trains an interpretable surrogate model\nto approximate the local behavior of the black-box diagnostic model. We also\nintroduce consistency measures to further address the issue of faithfulness in\nexplanations. Extensive experiments on two benchmark datasets and a newly\nconstructed dataset show that PointExplainer can provide intuitive explanations\nwith no diagnostic performance degradation. The source code is available at\nhttps://github.com/chaoxuewang/PointExplainer.", "AI": {"tldr": "PointExplainer is an explainable diagnostic tool for Parkinson's disease using hand-drawn signals, providing interpretable attributions without losing accuracy.", "motivation": "Existing deep neural network methods lack interpretability, hindering clinical trust in Parkinson's disease diagnosis.", "method": "PointExplainer uses a diagnosis module (encoding hand-drawn signals into 3D point clouds) and an explanation module (training an interpretable surrogate model). It also introduces consistency measures for faithful explanations.", "result": "Experiments on benchmark and new datasets show PointExplainer provides intuitive explanations without degrading diagnostic performance.", "conclusion": "PointExplainer successfully addresses interpretability challenges in Parkinson's disease diagnosis while maintaining accuracy."}}
{"id": "2505.04203", "pdf": "https://arxiv.org/pdf/2505.04203", "abs": "https://arxiv.org/abs/2505.04203", "authors": ["Zhiping Qiu", "Yitong Jin", "Yuan Wang", "Yi Shi", "Chongwu Wang", "Chao Tan", "Xiaobing Li", "Feng Yu", "Tao Yu", "Qionghai Dai"], "title": "ELGAR: Expressive Cello Performance Motion Generation for Audio Rendition", "categories": ["cs.GR", "cs.SD", "eess.AS"], "comment": null, "summary": "The art of instrument performance stands as a vivid manifestation of human\ncreativity and emotion. Nonetheless, generating instrument performance motions\nis a highly challenging task, as it requires not only capturing intricate\nmovements but also reconstructing the complex dynamics of the\nperformer-instrument interaction. While existing works primarily focus on\nmodeling partial body motions, we propose Expressive ceLlo performance motion\nGeneration for Audio Rendition (ELGAR), a state-of-the-art diffusion-based\nframework for whole-body fine-grained instrument performance motion generation\nsolely from audio. To emphasize the interactive nature of the instrument\nperformance, we introduce Hand Interactive Contact Loss (HICL) and Bow\nInteractive Contact Loss (BICL), which effectively guarantee the authenticity\nof the interplay. Moreover, to better evaluate whether the generated motions\nalign with the semantic context of the music audio, we design novel metrics\nspecifically for string instrument performance motion generation, including\nfinger-contact distance, bow-string distance, and bowing score. Extensive\nevaluations and ablation studies are conducted to validate the efficacy of the\nproposed methods. In addition, we put forward a motion generation dataset\nSPD-GEN, collated and normalized from the MoCap dataset SPD. As demonstrated,\nELGAR has shown great potential in generating instrument performance motions\nwith complicated and fast interactions, which will promote further development\nin areas such as animation, music education, interactive art creation, etc.", "AI": {"tldr": "ELGAR is a diffusion-based framework for generating whole-body cello performance motions from audio, incorporating novel interactive loss functions and evaluation metrics.", "motivation": "Existing works focus on partial body motions, but generating authentic instrument performance requires capturing intricate movements and performer-instrument dynamics.", "method": "Proposes ELGAR, a diffusion-based framework with Hand Interactive Contact Loss (HICL) and Bow Interactive Contact Loss (BICL) to ensure motion authenticity. Introduces metrics like finger-contact distance and bowing score for evaluation.", "result": "ELGAR effectively generates fine-grained motions with complex interactions, validated through extensive evaluations and ablation studies.", "conclusion": "ELGAR advances instrument performance motion generation, with applications in animation, music education, and interactive art."}}
{"id": "2505.03771", "pdf": "https://arxiv.org/pdf/2505.03771", "abs": "https://arxiv.org/abs/2505.03771", "authors": ["Ritik Raj", "Akshat Ramachandran", "Jeff Nye", "Shashank Nemawarkar", "Tushar Krishna"], "title": "OneDSE: A Unified Microprocessor Metric Prediction and Design Space Exploration Framework", "categories": ["cs.AR", "cs.MA"], "comment": null, "summary": "With the diminishing returns of Moore Law scaling and as power constraints\nbecome more impactful, processor designs rely on architectural innovation to\nachieve differentiating performance. Innovation complexity has increased the\ndesign space of modern high-performance processors. This work offers an\nefficient and novel design space exploration (DSE) solution to these challenges\nof modern CPU design. We identify three key challenges in past DSE approaches:\n(a) Metric prediction is slow and inaccurate for unseen workloads,\nmicroarchitectures, (b) Search is slow and inaccurate in CPU parameter space,\nand (c) A Single model is unable to learn the huge design space. We present\nOneDSE, a unified metric predictor and CPU parameter explorer to mitigate these\nchallenges with three key techniques: (a) Transformer-based workload-Aware CPU\nDSE (TrACE) predictor that outperforms state-of-the-art ANN-based prediction\nmethods by 2.75x and 6.12x with and without fine-tuning, respectively, on\nseveral benchmarks; (b) a novel metric space search approach that outperforms\noptimized metaheuristics by 1.19x while reducing search time by an order of\nmagnitude; (c) MARL-based multi-agent framework that achieves a 10.6% reduction\nin prediction error compared to its non-MARL counterpart, enabling more\naccurate and efficient exploration of the CPU design space.", "AI": {"tldr": "OneDSE introduces a unified DSE solution for CPU design, addressing slow/inaccurate metric prediction, inefficient search, and single-model limitations with Transformer-based prediction, metric space search, and MARL-based multi-agent framework.", "motivation": "The challenges of modern CPU design, such as slow and inaccurate metric prediction, inefficient search, and the inability of single models to handle large design spaces, motivate the need for an innovative DSE solution.", "method": "OneDSE employs three key techniques: (1) TrACE, a Transformer-based predictor; (2) a novel metric space search; (3) a MARL-based multi-agent framework.", "result": "TrACE outperforms ANN-based methods by 2.75x-6.12x; the search approach is 1.19x better and faster; MARL reduces prediction error by 10.6%.", "conclusion": "OneDSE effectively addresses modern CPU design challenges, offering faster, more accurate, and efficient design space exploration."}}
{"id": "2505.04623", "pdf": "https://arxiv.org/pdf/2505.04623", "abs": "https://arxiv.org/abs/2505.04623", "authors": ["Zhenghao Xing", "Xiaowei Hu", "Chi-Wing Fu", "Wenhai Wang", "Jifeng Dai", "Pheng-Ann Heng"], "title": "EchoInk-R1: Exploring Audio-Visual Reasoning in Multimodal LLMs via Reinforcement Learning", "categories": ["eess.AS", "cs.AI", "cs.CV", "cs.MM", "cs.SD"], "comment": null, "summary": "Multimodal large language models (MLLMs) have advanced perception across\ntext, vision, and audio, yet they often struggle with structured cross-modal\nreasoning, particularly when integrating audio and visual signals. We introduce\nEchoInk-R1, a reinforcement learning framework that enhances such reasoning in\nMLLMs. Built upon the Qwen2.5-Omni-7B foundation and optimized with Group\nRelative Policy Optimization (GRPO), EchoInk-R1 tackles multiple-choice\nquestion answering over synchronized audio-image pairs. To enable this, we\ncurate AVQA-R1-6K, a dataset pairing such audio-image inputs with\nmultiple-choice questions derived from OmniInstruct-v1. EchoInk-R1-7B achieves\n85.77% accuracy on the validation set, outperforming the base model, which\nscores 80.53%, using only 562 reinforcement learning steps. Beyond accuracy,\nEchoInk-R1 demonstrates reflective reasoning by revisiting initial\ninterpretations and refining responses when facing ambiguous multimodal inputs.\nThese results suggest that lightweight reinforcement learning fine-tuning\nenhances cross-modal reasoning in MLLMs. EchoInk-R1 is the first framework to\nunify audio, visual, and textual modalities for general open-world reasoning\nvia reinforcement learning. Code and data are publicly released to facilitate\nfurther research.", "AI": {"tldr": "EchoInk-R1, a reinforcement learning framework, improves cross-modal reasoning in MLLMs, achieving 85.77% accuracy on AVQA-R1-6K, outperforming the base model.", "motivation": "MLLMs struggle with structured cross-modal reasoning, especially integrating audio and visual signals.", "method": "Built on Qwen2.5-Omni-7B and optimized with GRPO, EchoInk-R1 tackles multiple-choice QA over audio-image pairs using the AVQA-R1-6K dataset.", "result": "EchoInk-R1-7B achieves 85.77% accuracy, outperforming the base model (80.53%) with just 562 RL steps. It also shows reflective reasoning.", "conclusion": "Lightweight RL fine-tuning enhances cross-modal reasoning, unifying audio, visual, and textual modalities for open-world reasoning."}}
{"id": "2505.04097", "pdf": "https://arxiv.org/pdf/2505.04097", "abs": "https://arxiv.org/abs/2505.04097", "authors": ["Thien Nhan Vo", "Bac Nam Ho", "Thanh Xuan Truong"], "title": "3D Brain MRI Classification for Alzheimer Diagnosis Using CNN with Data Augmentation", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "A three-dimensional convolutional neural network was developed to classify\nT1-weighted brain MRI scans as healthy or Alzheimer. The network comprises 3D\nconvolution, pooling, batch normalization, dense ReLU layers, and a sigmoid\noutput. Using stochastic noise injection and five-fold cross-validation, the\nmodel achieved test set accuracy of 0.912 and area under the ROC curve of\n0.961, an improvement of approximately 0.027 over resizing alone. Sensitivity\nand specificity both exceeded 0.90. These results align with prior work\nreporting up to 0.10 gain via synthetic augmentation. The findings demonstrate\nthe effectiveness of simple augmentation for 3D MRI classification and motivate\nfuture exploration of advanced augmentation methods and architectures such as\n3D U-Net and vision transformers.", "AI": {"tldr": "A 3D CNN model for classifying Alzheimer's in brain MRI scans achieved high accuracy (0.912) and AUC (0.961), outperforming resizing alone by ~0.027. Sensitivity and specificity were >0.90, showing the value of simple augmentation.", "motivation": "To improve Alzheimer's classification in T1-weighted brain MRI scans using a 3D CNN with noise injection and cross-validation.", "method": "Developed a 3D CNN with convolution, pooling, batch normalization, ReLU layers, and sigmoid output, using stochastic noise injection and five-fold cross-validation.", "result": "Achieved 0.912 accuracy, 0.961 AUC, and >0.90 sensitivity/specificity, outperforming resizing by ~0.027.", "conclusion": "Simple augmentation is effective for 3D MRI classification, motivating future work on advanced methods like 3D U-Net and vision transformers."}}
{"id": "2505.04132", "pdf": "https://arxiv.org/pdf/2505.04132", "abs": "https://arxiv.org/abs/2505.04132", "authors": ["Mingruo Yuan", "Ben Kao", "Tien-Hsuan Wu", "Michael M. K. Cheung", "Henry W. H. Chan", "Anne S. Y. Cheung", "Felix W. H. Chan", "Yongxi Chen"], "title": "Bringing legal knowledge to the public by constructing a legal question bank using large-scale pre-trained language model", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Access to legal information is fundamental to access to justice. Yet\naccessibility refers not only to making legal documents available to the\npublic, but also rendering legal information comprehensible to them. A vexing\nproblem in bringing legal information to the public is how to turn formal legal\ndocuments such as legislation and judgments, which are often highly technical,\nto easily navigable and comprehensible knowledge to those without legal\neducation. In this study, we formulate a three-step approach for bringing legal\nknowledge to laypersons, tackling the issues of navigability and\ncomprehensibility. First, we translate selected sections of the law into\nsnippets (called CLIC-pages), each being a small piece of article that focuses\non explaining certain technical legal concept in layperson's terms. Second, we\nconstruct a Legal Question Bank (LQB), which is a collection of legal questions\nwhose answers can be found in the CLIC-pages. Third, we design an interactive\nCLIC Recommender (CRec). Given a user's verbal description of a legal situation\nthat requires a legal solution, CRec interprets the user's input and shortlists\nquestions from the question bank that are most likely relevant to the given\nlegal situation and recommends their corresponding CLIC pages where relevant\nlegal knowledge can be found. In this paper we focus on the technical aspects\nof creating an LQB. We show how large-scale pre-trained language models, such\nas GPT-3, can be used to generate legal questions. We compare machine-generated\nquestions (MGQs) against human-composed questions (HCQs) and find that MGQs are\nmore scalable, cost-effective, and more diversified, while HCQs are more\nprecise. We also show a prototype of CRec and illustrate through an example how\nour 3-step approach effectively brings relevant legal knowledge to the public.", "AI": {"tldr": "The paper proposes a three-step method to make legal information accessible to laypersons by translating legal documents into simplified snippets, creating a Legal Question Bank (LQB), and designing an interactive recommender system. It highlights the use of GPT-3 for generating scalable legal questions.", "motivation": "To address the challenge of making technical legal documents comprehensible and navigable for non-experts, ensuring better access to justice.", "method": "A three-step approach: 1) Translate legal sections into layperson-friendly snippets (CLIC-pages), 2) Build a Legal Question Bank (LQB) using GPT-3 for scalable question generation, and 3) Develop an interactive CLIC Recommender (CRec) to link user queries to relevant CLIC-pages.", "result": "Machine-generated questions (MGQs) are more scalable and diversified than human-composed questions (HCQs), though HCQs are more precise. A prototype of CRec demonstrates the approach's effectiveness.", "conclusion": "The proposed method successfully bridges the gap between legal documents and laypersons, leveraging AI for scalability while maintaining precision through human input."}}
{"id": "2505.04066", "pdf": "https://arxiv.org/pdf/2505.04066", "abs": "https://arxiv.org/abs/2505.04066", "authors": ["Tuochao Chen", "Nicholas Batchelder", "Alisa Liu", "Noah Smith", "Shyamnath Gollakota"], "title": "LLAMAPIE: Proactive In-Ear Conversation Assistants", "categories": ["cs.LG", "cs.CL", "eess.AS"], "comment": null, "summary": "We introduce LlamaPIE, the first real-time proactive assistant designed to\nenhance human conversations through discreet, concise guidance delivered via\nhearable devices. Unlike traditional language models that require explicit user\ninvocation, this assistant operates in the background, anticipating user needs\nwithout interrupting conversations. We address several challenges, including\ndetermining when to respond, crafting concise responses that enhance\nconversations, leveraging knowledge of the user for context-aware assistance,\nand real-time, on-device processing. To achieve this, we construct a\nsemi-synthetic dialogue dataset and propose a two-model pipeline: a small model\nthat decides when to respond and a larger model that generates the response. We\nevaluate our approach on real-world datasets, demonstrating its effectiveness\nin providing helpful, unobtrusive assistance. User studies with our assistant,\nimplemented on Apple Silicon M2 hardware, show a strong preference for the\nproactive assistant over both a baseline with no assistance and a reactive\nmodel, highlighting the potential of LlamaPie to enhance live conversations.", "AI": {"tldr": "LlamaPIE is a real-time proactive assistant for enhancing human conversations via hearable devices, operating discreetly without explicit user invocation. It uses a two-model pipeline for context-aware assistance and is evaluated as effective and preferred over baselines.", "motivation": "To enhance human conversations by providing discreet, proactive assistance without interrupting the flow, addressing challenges like timing, conciseness, and real-time processing.", "method": "A two-model pipeline: a small model decides when to respond, and a larger model generates the response. Built on a semi-synthetic dialogue dataset and implemented on Apple Silicon M2 hardware.", "result": "User studies show strong preference for LlamaPIE over no assistance and reactive models, proving its effectiveness in live conversations.", "conclusion": "LlamaPIE demonstrates the potential of proactive, unobtrusive AI assistance in enhancing real-time human interactions."}}
{"id": "2505.03985", "pdf": "https://arxiv.org/pdf/2505.03985", "abs": "https://arxiv.org/abs/2505.03985", "authors": ["Zirong Chen", "Ziyan An", "Jennifer Reynolds", "Kristin Mullen", "Stephen Martini", "Meiyi Ma"], "title": "LogiDebrief: A Signal-Temporal Logic based Automated Debriefing Approach with Large Language Models Integration", "categories": ["cs.AI"], "comment": "Accepted at IJCAI-2025", "summary": "Emergency response services are critical to public safety, with 9-1-1\ncall-takers playing a key role in ensuring timely and effective emergency\noperations. To ensure call-taking performance consistency, quality assurance is\nimplemented to evaluate and refine call-takers' skillsets. However, traditional\nhuman-led evaluations struggle with high call volumes, leading to low coverage\nand delayed assessments. We introduce LogiDebrief, an AI-driven framework that\nautomates traditional 9-1-1 call debriefing by integrating Signal-Temporal\nLogic (STL) with Large Language Models (LLMs) for fully-covered rigorous\nperformance evaluation. LogiDebrief formalizes call-taking requirements as\nlogical specifications, enabling systematic assessment of 9-1-1 calls against\nprocedural guidelines. It employs a three-step verification process: (1)\ncontextual understanding to identify responder types, incident classifications,\nand critical conditions; (2) STL-based runtime checking with LLM integration to\nensure compliance; and (3) automated aggregation of results into quality\nassurance reports. Beyond its technical contributions, LogiDebrief has\ndemonstrated real-world impact. Successfully deployed at Metro Nashville\nDepartment of Emergency Communications, it has assisted in debriefing 1,701\nreal-world calls, saving 311.85 hours of active engagement. Empirical\nevaluation with real-world data confirms its accuracy, while a case study and\nextensive user study highlight its effectiveness in enhancing call-taking\nperformance.", "AI": {"tldr": "LogiDebrief automates 9-1-1 call debriefing using AI (STL and LLMs) for systematic performance evaluation, improving coverage and efficiency.", "motivation": "Traditional human-led evaluations struggle with high call volumes, leading to low coverage and delayed assessments.", "method": "LogiDebrief formalizes call-taking requirements as logical specifications, using a three-step process: contextual understanding, STL-based runtime checking, and automated report generation.", "result": "Deployed in Nashville, it debriefed 1,701 calls, saving 311.85 hours. Empirical evaluation confirms accuracy and effectiveness.", "conclusion": "LogiDebrief enhances call-taking performance and efficiency, demonstrating real-world impact."}}
{"id": "2505.03779", "pdf": "https://arxiv.org/pdf/2505.03779", "abs": "https://arxiv.org/abs/2505.03779", "authors": ["Tao Liu", "Tianyu Zhang", "Yongxue Chen", "Weiming Wang", "Yu Jiang", "Yuming Huang", "Charlie C. L. Wang"], "title": "Neural Co-Optimization of Structural Topology, Manufacturable Layers, and Path Orientations for Fiber-Reinforced Composites", "categories": ["cs.LG"], "comment": null, "summary": "We propose a neural network-based computational framework for the\nsimultaneous optimization of structural topology, curved layers, and path\norientations to achieve strong anisotropic strength in fiber-reinforced\nthermoplastic composites while ensuring manufacturability. Our framework\nemploys three implicit neural fields to represent geometric shape, layer\nsequence, and fiber orientation. This enables the direct formulation of both\ndesign and manufacturability objectives - such as anisotropic strength,\nstructural volume, machine motion control, layer curvature, and layer thickness\n- into an integrated and differentiable optimization process. By incorporating\nthese objectives as loss functions, the framework ensures that the resultant\ncomposites exhibit optimized mechanical strength while remaining its\nmanufacturability for filament-based multi-axis 3D printing across diverse\nhardware platforms. Physical experiments demonstrate that the composites\ngenerated by our co-optimization method can achieve an improvement of up to\n33.1% in failure loads compared to composites with sequentially optimized\nstructures and manufacturing sequences.", "AI": {"tldr": "A neural network framework optimizes structural topology, curved layers, and fiber orientations in composites for strength and manufacturability, achieving 33.1% higher failure loads.", "motivation": "To enhance anisotropic strength in fiber-reinforced thermoplastic composites while ensuring manufacturability through an integrated optimization approach.", "method": "Uses three implicit neural fields for shape, layer sequence, and fiber orientation, integrating design and manufacturability objectives into a differentiable optimization process.", "result": "Composites show up to 33.1% improvement in failure loads compared to sequentially optimized designs.", "conclusion": "The framework successfully co-optimizes mechanical strength and manufacturability, validated by physical experiments."}}
{"id": "2505.03837", "pdf": "https://arxiv.org/pdf/2505.03837", "abs": "https://arxiv.org/abs/2505.03837", "authors": ["Rashik Shadman", "Daqing Hou", "Faraz Hussain", "M G Sarwar Murshed"], "title": "Explainable Face Recognition via Improved Localization", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Biometric authentication has become one of the most widely used tools in the\ncurrent technological era to authenticate users and to distinguish between\ngenuine users and imposters. Face is the most common form of biometric modality\nthat has proven effective. Deep learning-based face recognition systems are now\ncommonly used across different domains. However, these systems usually operate\nlike black-box models that do not provide necessary explanations or\njustifications for their decisions. This is a major disadvantage because users\ncannot trust such artificial intelligence-based biometric systems and may not\nfeel comfortable using them when clear explanations or justifications are not\nprovided. This paper addresses this problem by applying an efficient method for\nexplainable face recognition systems. We use a Class Activation Mapping\n(CAM)-based discriminative localization (very narrow/specific localization)\ntechnique called Scaled Directed Divergence (SDD) to visually explain the\nresults of deep learning-based face recognition systems. We perform fine\nlocalization of the face features relevant to the deep learning model for its\nprediction/decision. Our experiments show that the SDD Class Activation Map\n(CAM) highlights the relevant face features very specifically compared to the\ntraditional CAM and very accurately. The provided visual explanations with\nnarrow localization of relevant features can ensure much-needed transparency\nand trust for deep learning-based face recognition systems.", "AI": {"tldr": "The paper proposes an explainable face recognition system using Scaled Directed Divergence (SDD) for precise feature localization, enhancing transparency and trust in deep learning models.", "motivation": "Deep learning-based face recognition systems lack explainability, reducing user trust. This paper aims to address this gap by providing visual explanations for model decisions.", "method": "The authors use SDD, a CAM-based discriminative localization technique, to fine-tune and highlight relevant facial features for model predictions.", "result": "SDD-CAM outperforms traditional CAM by accurately and specifically localizing relevant facial features, improving transparency.", "conclusion": "The SDD-based approach enhances trust in face recognition systems by providing clear, narrow visual explanations of model decisions."}}
{"id": "2308.04729", "pdf": "https://arxiv.org/pdf/2308.04729", "abs": "https://arxiv.org/abs/2308.04729", "authors": ["Peike Li", "Boyu Chen", "Yao Yao", "Yikai Wang", "Allen Wang", "Alex Wang"], "title": "JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "comment": "Github Demo Page: https://gogoduck912.github.io/Jen1-Demo-Page/", "summary": "Music generation has attracted growing interest with the advancement of deep\ngenerative models. However, generating music conditioned on textual\ndescriptions, known as text-to-music, remains challenging due to the complexity\nof musical structures and high sampling rate requirements. Despite the task's\nsignificance, prevailing generative models exhibit limitations in music\nquality, computational efficiency, and generalization. This paper introduces\nJEN-1, a universal high-fidelity model for text-to-music generation. JEN-1 is a\ndiffusion model incorporating both autoregressive and non-autoregressive\ntraining. Through in-context learning, JEN-1 performs various generation tasks\nincluding text-guided music generation, music inpainting, and continuation.\nEvaluations demonstrate JEN-1's superior performance over state-of-the-art\nmethods in text-music alignment and music quality while maintaining\ncomputational efficiency. Our demos are available at\nhttps://jenmusic.ai/audio-demos", "AI": {"tldr": "JEN-1 is a diffusion model for text-to-music generation, combining autoregressive and non-autoregressive training, outperforming state-of-the-art methods in quality and efficiency.", "motivation": "Text-to-music generation is challenging due to musical complexity and high sampling rates, with existing models lacking in quality and efficiency.", "method": "JEN-1 uses a diffusion model with autoregressive and non-autoregressive training, enabling tasks like text-guided generation, inpainting, and continuation.", "result": "JEN-1 achieves superior text-music alignment and music quality while remaining computationally efficient.", "conclusion": "JEN-1 is a high-fidelity, versatile model for text-to-music generation, setting a new benchmark in the field."}}
{"id": "2505.03807", "pdf": "https://arxiv.org/pdf/2505.03807", "abs": "https://arxiv.org/abs/2505.03807", "authors": ["Yiwen Zhang", "Jianing Hao", "Zhan Wang", "Hongling Sheng", "Wei Zeng"], "title": "Facilitating Video Story Interaction with Multi-Agent Collaborative System", "categories": ["cs.HC", "cs.AI", "cs.CV", "cs.MA"], "comment": "Prepared and submitted in 2024", "summary": "Video story interaction enables viewers to engage with and explore narrative\ncontent for personalized experiences. However, existing methods are limited to\nuser selection, specially designed narratives, and lack customization. To\naddress this, we propose an interactive system based on user intent. Our system\nuses a Vision Language Model (VLM) to enable machines to understand video\nstories, combining Retrieval-Augmented Generation (RAG) and a Multi-Agent\nSystem (MAS) to create evolving characters and scene experiences. It includes\nthree stages: 1) Video story processing, utilizing VLM and prior knowledge to\nsimulate human understanding of stories across three modalities. 2) Multi-space\nchat, creating growth-oriented characters through MAS interactions based on\nuser queries and story stages. 3) Scene customization, expanding and\nvisualizing various story scenes mentioned in dialogue. Applied to the Harry\nPotter series, our study shows the system effectively portrays emergent\ncharacter social behavior and growth, enhancing the interactive experience in\nthe video story world.", "AI": {"tldr": "Proposes an interactive video story system using VLM, RAG, and MAS for personalized, evolving narratives, tested on Harry Potter.", "motivation": "Existing methods lack customization and are limited to user selection or pre-designed narratives.", "method": "Uses VLM for story understanding, RAG and MAS for evolving characters and scenes, with three stages: video processing, multi-space chat, and scene customization.", "result": "Effective portrayal of character behavior and growth, enhancing interactive experiences in video stories.", "conclusion": "The system successfully addresses customization gaps, improving engagement in narrative content."}}
{"id": "2504.16405", "pdf": "https://arxiv.org/pdf/2504.16405", "abs": "https://arxiv.org/abs/2504.16405", "authors": ["Lancheng Gao", "Ziheng Jia", "Yunhao Zeng", "Wei Sun", "Yiming Zhang", "Wei Zhou", "Guangtao Zhai", "Xiongkuo Min"], "title": "EEmo-Bench: A Benchmark for Multi-modal Large Language Models on Image Evoked Emotion Assessment", "categories": ["cs.MM"], "comment": null, "summary": "The furnishing of multi-modal large language models (MLLMs) has led to the\nemergence of numerous benchmark studies, particularly those evaluating their\nperception and understanding capabilities. Among these, understanding\nimage-evoked emotions aims to enhance MLLMs' empathy, with significant\napplications such as human-machine interaction and advertising recommendations.\nHowever, current evaluations of this MLLM capability remain coarse-grained, and\na systematic and comprehensive assessment is still lacking. To this end, we\nintroduce EEmo-Bench, a novel benchmark dedicated to the analysis of the evoked\nemotions in images across diverse content categories. Our core contributions\ninclude: 1) Regarding the diversity of the evoked emotions, we adopt an emotion\nranking strategy and employ the Valence-Arousal-Dominance (VAD) as emotional\nattributes for emotional assessment. In line with this methodology, 1,960\nimages are collected and manually annotated. 2) We design four tasks to\nevaluate MLLMs' ability to capture the evoked emotions by single images and\ntheir associated attributes: Perception, Ranking, Description, and Assessment.\nAdditionally, image-pairwise analysis is introduced to investigate the model's\nproficiency in performing joint and comparative analysis. In total, we collect\n6,773 question-answer pairs and perform a thorough assessment on 19\ncommonly-used MLLMs. The results indicate that while some proprietary and\nlarge-scale open-source MLLMs achieve promising overall performance, the\nanalytical capabilities in certain evaluation dimensions remain suboptimal. Our\nEEmo-Bench paves the path for further research aimed at enhancing the\ncomprehensive perceiving and understanding capabilities of MLLMs concerning\nimage-evoked emotions, which is crucial for machine-centric emotion perception\nand understanding.", "AI": {"tldr": "EEmo-Bench is a new benchmark for evaluating multi-modal large language models (MLLMs) on image-evoked emotions, using diverse tasks and emotional attributes like Valence-Arousal-Dominance (VAD).", "motivation": "Current evaluations of MLLMs' emotion understanding are coarse-grained; EEmo-Bench aims to provide a systematic and comprehensive assessment.", "method": "The benchmark includes 1,960 annotated images and four tasks (Perception, Ranking, Description, Assessment) with 6,773 QA pairs, tested on 19 MLLMs.", "result": "Some proprietary and large-scale open-source MLLMs perform well overall, but analytical capabilities in certain dimensions are lacking.", "conclusion": "EEmo-Bench advances research on MLLMs' emotion perception and understanding, crucial for applications like human-machine interaction."}}
{"id": "2505.04172", "pdf": "https://arxiv.org/pdf/2505.04172", "abs": "https://arxiv.org/abs/2505.04172", "authors": ["Iankai Tang", "Kegang Wang", "Yingke Ding", "Jiatong Ji", "Zeyu Wang", "Xiyuxing Zhang", "Ping Chen", "Yuanchun Shi", "Yuntao Wang"], "title": "A Dataset and Toolkit for Multiparameter Cardiovascular Physiology Sensing on Rings", "categories": ["eess.IV", "cs.HC", "physics.med-ph"], "comment": null, "summary": "Smart rings offer a convenient way to continuously and unobtrusively monitor\ncardiovascular physiological signals. However, a gap remains between the ring\nhardware and reliable methods for estimating cardiovascular parameters, partly\ndue to the lack of publicly available datasets and standardized analysis tools.\nIn this work, we present $\\tau$-Ring, the first open-source ring-based dataset\ndesigned for cardiovascular physiological sensing. The dataset comprises\nphotoplethysmography signals (infrared and red channels) and 3-axis\naccelerometer data collected from two rings (reflective and transmissive\noptical paths), with 28.21 hours of raw data from 34 subjects across seven\nactivities. $\\tau$-Ring encompasses both stationary and motion scenarios, as\nwell as stimulus-evoked abnormal physiological states, annotated with four\nground-truth labels: heart rate, respiratory rate, oxygen saturation, and blood\npressure. Using our proposed RingTool toolkit, we evaluated three widely-used\nphysics-based methods and four cutting-edge deep learning approaches. Our\nresults show superior performance compared to commercial rings, achieving best\nMAE values of 5.18 BPM for heart rate, 2.98 BPM for respiratory rate, 3.22\\%\nfor oxygen saturation, and 13.33/7.56 mmHg for systolic/diastolic blood\npressure estimation. The open-sourced dataset and toolkit aim to foster further\nresearch and community-driven advances in ring-based cardiovascular health\nsensing.", "AI": {"tldr": "The paper introduces \u03c4-Ring, an open-source dataset for ring-based cardiovascular monitoring, and evaluates methods for estimating heart rate, respiratory rate, oxygen saturation, and blood pressure.", "motivation": "There is a lack of publicly available datasets and standardized tools for reliable cardiovascular parameter estimation using smart rings.", "method": "The authors present \u03c4-Ring, a dataset with photoplethysmography and accelerometer data from 34 subjects, and evaluate physics-based and deep learning methods using their RingTool toolkit.", "result": "The proposed methods outperform commercial rings, achieving low MAE values for cardiovascular parameters.", "conclusion": "The open-sourced dataset and toolkit aim to advance research in ring-based cardiovascular health sensing."}}
{"id": "2505.04135", "pdf": "https://arxiv.org/pdf/2505.04135", "abs": "https://arxiv.org/abs/2505.04135", "authors": ["Vihaan Miriyala", "Smrithi Bukkapatnam", "Lavanya Prahallad"], "title": "Enhancing Granular Sentiment Classification with Chain-of-Thought Prompting in Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": "5 pages", "summary": "We explore the use of Chain-of-Thought (CoT) prompting with large language\nmodels (LLMs) to improve the accuracy of granular sentiment categorization in\napp store reviews. Traditional numeric and polarity-based ratings often fail to\ncapture the nuanced sentiment embedded in user feedback. We evaluated the\neffectiveness of CoT prompting versus simple prompting on 2000 Amazon app\nreviews by comparing each method's predictions to human judgements. CoT\nprompting improved classification accuracy from 84% to 93% highlighting the\nbenefit of explicit reasoning in enhancing sentiment analysis performance.", "AI": {"tldr": "CoT prompting with LLMs boosts sentiment categorization accuracy from 84% to 93% in app reviews.", "motivation": "Traditional sentiment analysis methods lack nuance in capturing user feedback.", "method": "Compared CoT prompting vs. simple prompting on 2000 Amazon app reviews, validated against human judgments.", "result": "CoT prompting improved accuracy from 84% to 93%.", "conclusion": "Explicit reasoning via CoT enhances sentiment analysis performance."}}
{"id": "2505.04394", "pdf": "https://arxiv.org/pdf/2505.04394", "abs": "https://arxiv.org/abs/2505.04394", "authors": ["Young-Hu Park", "Rae-Hong Park", "Hyung-Min Park"], "title": "SwinLip: An Efficient Visual Speech Encoder for Lip Reading Using Swin Transformer", "categories": ["cs.CV", "eess.AS"], "comment": null, "summary": "This paper presents an efficient visual speech encoder for lip reading. While\nmost recent lip reading studies have been based on the ResNet architecture and\nhave achieved significant success, they are not sufficiently suitable for\nefficiently capturing lip reading features due to high computational complexity\nin modeling spatio-temporal information. Additionally, using a complex visual\nmodel not only increases the complexity of lip reading models but also induces\ndelays in the overall network for multi-modal studies (e.g., audio-visual\nspeech recognition, speech enhancement, and speech separation). To overcome the\nlimitations of Convolutional Neural Network (CNN)-based models, we apply the\nhierarchical structure and window self-attention of the Swin Transformer to lip\nreading. We configure a new lightweight scale of the Swin Transformer suitable\nfor processing lip reading data and present the SwinLip visual speech encoder,\nwhich efficiently reduces computational load by integrating modified\nConvolution-augmented Transformer (Conformer) temporal embeddings with\nconventional spatial embeddings in the hierarchical structure. Through\nextensive experiments, we have validated that our SwinLip successfully improves\nthe performance and inference speed of the lip reading network when applied to\nvarious backbones for word and sentence recognition, reducing computational\nload. In particular, our SwinLip demonstrated robust performance in both\nEnglish LRW and Mandarin LRW-1000 datasets and achieved state-of-the-art\nperformance on the Mandarin LRW-1000 dataset with less computation compared to\nthe existing state-of-the-art model.", "AI": {"tldr": "The paper introduces SwinLip, a lightweight visual speech encoder for lip reading, using Swin Transformer and Conformer to reduce computational load while improving performance.", "motivation": "Existing CNN-based lip reading models are computationally complex and inefficient for spatio-temporal feature capture, hindering multi-modal applications.", "method": "The authors apply Swin Transformer's hierarchical structure and window self-attention, integrating Conformer temporal embeddings for efficiency.", "result": "SwinLip improves performance and speed in word/sentence recognition, achieving state-of-the-art results on Mandarin LRW-1000 with less computation.", "conclusion": "SwinLip is an efficient, high-performance alternative to CNN-based lip reading models, validated on diverse datasets."}}
{"id": "2505.03989", "pdf": "https://arxiv.org/pdf/2505.03989", "abs": "https://arxiv.org/abs/2505.03989", "authors": ["Marie Davidsen Buhl", "Jacob Pfau", "Benjamin Hilton", "Geoffrey Irving"], "title": "An alignment safety case sketch based on debate", "categories": ["cs.AI"], "comment": null, "summary": "If AI systems match or exceed human capabilities on a wide range of tasks, it\nmay become difficult for humans to efficiently judge their actions -- making it\nhard to use human feedback to steer them towards desirable traits. One proposed\nsolution is to leverage another superhuman system to point out flaws in the\nsystem's outputs via a debate. This paper outlines the value of debate for AI\nsafety, as well as the assumptions and further research required to make debate\nwork. It does so by sketching an ``alignment safety case'' -- an argument that\nan AI system will not autonomously take actions which could lead to egregious\nharm, despite being able to do so. The sketch focuses on the risk of an AI R\\&D\nagent inside an AI company sabotaging research, for example by producing false\nresults. To prevent this, the agent is trained via debate, subject to\nexploration guarantees, to teach the system to be honest. Honesty is maintained\nthroughout deployment via online training. The safety case rests on four key\nclaims: (1) the agent has become good at the debate game, (2) good performance\nin the debate game implies that the system is mostly honest, (3) the system\nwill not become significantly less honest during deployment, and (4) the\ndeployment context is tolerant of some errors. We identify open research\nproblems that, if solved, could render this a compelling argument that an AI\nsystem is safe.", "AI": {"tldr": "The paper explores using debate between AI systems to ensure safety and honesty, addressing risks like research sabotage in AI companies.", "motivation": "As AI systems surpass human capabilities, human oversight becomes challenging. Debate between AI systems is proposed to ensure alignment and prevent harmful actions.", "method": "The paper outlines a debate-based training method for AI, ensuring honesty through exploration guarantees and online training.", "result": "The safety case relies on four claims: debate proficiency, honesty from debate, stability during deployment, and error tolerance.", "conclusion": "Open research problems remain to fully validate debate as a safety mechanism for AI systems."}}
{"id": "2505.03781", "pdf": "https://arxiv.org/pdf/2505.03781", "abs": "https://arxiv.org/abs/2505.03781", "authors": ["Jin Yu", "JaeHo Park", "TaeJun Park", "Gyurin Kim", "JiHyun Lee", "Min Sung Lee", "Joon-myoung Kwon", "Jeong Min Son", "Yong-Yeon Jo"], "title": "ALFRED: Ask a Large-language model For Reliable ECG Diagnosis", "categories": ["cs.LG"], "comment": null, "summary": "Leveraging Large Language Models (LLMs) with Retrieval-Augmented Generation\n(RAG) for analyzing medical data, particularly Electrocardiogram (ECG), offers\nhigh accuracy and convenience. However, generating reliable, evidence-based\nresults in specialized fields like healthcare remains a challenge, as RAG alone\nmay not suffice. We propose a Zero-shot ECG diagnosis framework based on RAG\nfor ECG analysis that incorporates expert-curated knowledge to enhance\ndiagnostic accuracy and explainability. Evaluation on the PTB-XL dataset\ndemonstrates the framework's effectiveness, highlighting the value of\nstructured domain expertise in automated ECG interpretation. Our framework is\ndesigned to support comprehensive ECG analysis, addressing diverse diagnostic\nneeds with potential applications beyond the tested dataset.", "AI": {"tldr": "A Zero-shot ECG diagnosis framework using RAG and expert-curated knowledge improves accuracy and explainability in ECG analysis, validated on the PTB-XL dataset.", "motivation": "Generating reliable, evidence-based results in healthcare using RAG alone is challenging, necessitating expert-curated knowledge for accuracy.", "method": "Proposes a Zero-shot ECG diagnosis framework combining RAG with expert-curated knowledge for ECG analysis.", "result": "Effective performance on the PTB-XL dataset, demonstrating enhanced diagnostic accuracy and explainability.", "conclusion": "The framework supports comprehensive ECG analysis and has potential applications beyond the tested dataset."}}
{"id": "2505.03846", "pdf": "https://arxiv.org/pdf/2505.03846", "abs": "https://arxiv.org/abs/2505.03846", "authors": ["Kangsheng Wang", "Yuhang Li", "Chengwei Ye", "Yufei Lin", "Huanzhen Zhang", "Bohan Hu", "Linuo Xu", "Shuyan Liu"], "title": "GAME: Learning Multimodal Interactions via Graph Structures for Personality Trait Estimation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Apparent personality analysis from short videos poses significant chal-lenges\ndue to the complex interplay of visual, auditory, and textual cues. In this\npaper, we propose GAME, a Graph-Augmented Multimodal Encoder designed to\nrobustly model and fuse multi-source features for automatic personality\nprediction. For the visual stream, we construct a facial graph and introduce a\ndual-branch Geo Two-Stream Network, which combines Graph Convolutional Networks\n(GCNs) and Convolutional Neural Net-works (CNNs) with attention mechanisms to\ncapture both structural and appearance-based facial cues. Complementing this,\nglobal context and iden-tity features are extracted using pretrained ResNet18\nand VGGFace back-bones. To capture temporal dynamics, frame-level features are\nprocessed by a BiGRU enhanced with temporal attention modules. Meanwhile, audio\nrepresentations are derived from the VGGish network, and linguistic se-mantics\nare captured via the XLM-Roberta transformer. To achieve effective multimodal\nintegration, we propose a Channel Attention-based Fusion module, followed by a\nMulti-Layer Perceptron (MLP) regression head for predicting personality traits.\nExtensive experiments show that GAME con-sistently outperforms existing methods\nacross multiple benchmarks, vali-dating its effectiveness and generalizability.", "AI": {"tldr": "GAME, a Graph-Augmented Multimodal Encoder, effectively combines visual, auditory, and textual cues for personality prediction, outperforming existing methods.", "motivation": "The challenge of analyzing personality from short videos due to complex multimodal interactions.", "method": "Uses a dual-branch Geo Two-Stream Network for visual cues, VGGish for audio, XLM-Roberta for text, and a Channel Attention-based Fusion module for integration.", "result": "GAME consistently outperforms existing benchmarks.", "conclusion": "GAME is effective and generalizable for personality prediction from multimodal data."}}
{"id": "2309.08751", "pdf": "https://arxiv.org/pdf/2309.08751", "abs": "https://arxiv.org/abs/2309.08751", "authors": ["Prateek Verma"], "title": "Diverse Audio Embeddings -- Bringing Features Back Outperforms CLAP!", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "comment": "6 pages, 1 figure, 2 table", "summary": "With the advent of modern AI architectures, a shift has happened towards\nend-to-end architectures. This pivot has led to neural architectures being\ntrained without domain-specific biases/knowledge, optimized according to the\ntask. We in this paper, learn audio embeddings via diverse feature\nrepresentations, in this case, domain-specific. For the case of audio\nclassification over hundreds of categories of sound, we learn robust separate\nembeddings for diverse audio properties such as pitch, timbre, and neural\nrepresentation, along with also learning it via an end-to-end architecture. We\nobserve handcrafted embeddings, e.g., pitch and timbre-based, although on their\nown, are not able to beat a fully end-to-end representation, yet adding these\ntogether with end-to-end embedding helps us, significantly improve performance.\nThis work would pave the way to bring some domain expertise with end-to-end\nmodels to learn robust, diverse representations, surpassing the performance of\njust training end-to-end models.", "AI": {"tldr": "The paper explores combining domain-specific audio embeddings (e.g., pitch, timbre) with end-to-end learning to improve audio classification performance.", "motivation": "To enhance audio classification by integrating domain-specific knowledge (e.g., pitch, timbre) with end-to-end models, surpassing the limitations of purely end-to-end approaches.", "method": "Learns separate embeddings for diverse audio properties (pitch, timbre, neural representation) alongside an end-to-end architecture. Combines these embeddings for classification.", "result": "Combining domain-specific embeddings with end-to-end learning significantly improves performance over using either approach alone.", "conclusion": "Integrating domain expertise with end-to-end models yields robust, diverse representations, outperforming purely end-to-end methods."}}
{"id": "2505.03820", "pdf": "https://arxiv.org/pdf/2505.03820", "abs": "https://arxiv.org/abs/2505.03820", "authors": ["Keidai Iiyama", "Daniel Neamati", "Grace Gao"], "title": "Satellite Autonomous Clock Fault Monitoring with Inter-Satellite Ranges Using Euclidean Distance Matrices", "categories": ["cs.RO", "cs.MA"], "comment": "This manuscript was submitted to the NAVIGATION: Journal of the\n  Institute of Navigation", "summary": "To address the need for robust positioning, navigation, and timing services\nin lunar environments, this paper proposes a novel onboard clock phase jump\ndetection framework for satellite constellations using range measurements\nobtained from dual one-way inter-satellite links. Our approach leverages vertex\nredundantly rigid graphs to detect faults without relying on prior knowledge of\nsatellite positions or clock biases, providing flexibility for lunar satellite\nnetworks with diverse satellite types and operators. We model satellite\nconstellations as graphs, where satellites are vertices and inter-satellite\nlinks are edges. The proposed algorithm detects and identifies satellites with\nclock jumps by monitoring the singular values of the geometric-centered\nEuclidean distance matrix (GCEDM) of 5-clique sub-graphs. The proposed method\nis validated through simulations of a GPS constellation and a notional\nconstellation around the Moon, demonstrating its effectiveness in various\nconfigurations.", "AI": {"tldr": "A novel framework detects clock phase jumps in lunar satellite constellations using inter-satellite links and graph theory, validated via simulations.", "motivation": "Addressing the need for robust positioning, navigation, and timing services in lunar environments.", "method": "Uses vertex redundantly rigid graphs and GCEDM singular values to detect clock jumps without prior knowledge of satellite positions or biases.", "result": "Effective in simulations of GPS and lunar constellations.", "conclusion": "The method provides a flexible and reliable solution for diverse lunar satellite networks."}}
{"id": "2406.04321", "pdf": "https://arxiv.org/pdf/2406.04321", "abs": "https://arxiv.org/abs/2406.04321", "authors": ["Zeyue Tian", "Zhaoyang Liu", "Ruibin Yuan", "Jiahao Pan", "Qifeng Liu", "Xu Tan", "Qifeng Chen", "Wei Xue", "Yike Guo"], "title": "VidMuse: A Simple Video-to-Music Generation Framework with Long-Short-Term Modeling", "categories": ["cs.CV", "cs.LG", "cs.MM", "cs.SD"], "comment": "The code and datasets are available at\n  https://github.com/ZeyueT/VidMuse/", "summary": "In this work, we systematically study music generation conditioned solely on\nthe video. First, we present a large-scale dataset comprising 360K video-music\npairs, including various genres such as movie trailers, advertisements, and\ndocumentaries. Furthermore, we propose VidMuse, a simple framework for\ngenerating music aligned with video inputs. VidMuse stands out by producing\nhigh-fidelity music that is both acoustically and semantically aligned with the\nvideo. By incorporating local and global visual cues, VidMuse enables the\ncreation of musically coherent audio tracks that consistently match the video\ncontent through Long-Short-Term modeling. Through extensive experiments,\nVidMuse outperforms existing models in terms of audio quality, diversity, and\naudio-visual alignment. The code and datasets are available at\nhttps://vidmuse.github.io/.", "AI": {"tldr": "VidMuse generates high-quality music from videos using local and global visual cues, outperforming existing models in audio quality and alignment.", "motivation": "To study music generation conditioned solely on video, addressing the need for acoustically and semantically aligned audio tracks.", "method": "Proposes VidMuse, a framework leveraging Long-Short-Term modeling and visual cues for music generation.", "result": "VidMuse outperforms existing models in audio quality, diversity, and audio-visual alignment.", "conclusion": "VidMuse is effective for video-conditioned music generation, with code and datasets publicly available."}}
{"id": "2505.04199", "pdf": "https://arxiv.org/pdf/2505.04199", "abs": "https://arxiv.org/abs/2505.04199", "authors": ["Athulya Ratnayake", "Buddhi Wijenayake", "Praveen Sumanasekara", "Roshan Godaliyadda", "Vijitha Herath", "Parakrama Ekanayake"], "title": "Enhanced SCanNet with CBAM and Dice Loss for Semantic Change Detection", "categories": ["eess.IV"], "comment": "7 pages, 3 figures, conference", "summary": "Semantic Change Detection (SCD) in remote sensing imagery requires accurately\nidentifying land-cover changes across multi-temporal image pairs. Despite\nsubstantial advancements, including the introduction of transformer-based\narchitectures, current SCD models continue to struggle with challenges such as\nnoisy inputs, subtle class boundaries, and significant class imbalance. In this\nstudy, we propose enhancing the Semantic Change Network (SCanNet) by\nintegrating the Convolutional Block Attention Module (CBAM) and employing Dice\nloss during training. CBAM sequentially applies channel attention to highlight\nfeature maps with the most meaningful content, followed by spatial attention to\npinpoint critical regions within these maps. This sequential approach ensures\nprecise suppression of irrelevant features and spatial noise, resulting in more\naccurate and robust detection performance compared to attention mechanisms that\napply both processes simultaneously or independently. Dice loss, designed\nexplicitly for handling class imbalance, further boosts sensitivity to minority\nchange classes. Quantitative experiments conducted on the SECOND dataset\ndemonstrate consistent improvements. Qualitative analysis confirms these\nimprovements, showing clearer segmentation boundaries and more accurate\nrecovery of small-change regions. These findings highlight the effectiveness of\nattention mechanisms and Dice loss in improving feature representation and\naddressing class imbalance in semantic change detection tasks.", "AI": {"tldr": "The paper proposes enhancing SCanNet with CBAM and Dice loss to improve semantic change detection in remote sensing by addressing noise, class boundaries, and imbalance.", "motivation": "Current SCD models struggle with noisy inputs, subtle class boundaries, and class imbalance, despite advancements like transformers.", "method": "Integrates CBAM (channel and spatial attention) and Dice loss into SCanNet for better feature representation and handling class imbalance.", "result": "Quantitative and qualitative experiments on SECOND dataset show improved accuracy, clearer boundaries, and better small-change recovery.", "conclusion": "CBAM and Dice loss effectively enhance feature representation and address class imbalance in SCD tasks."}}
{"id": "2505.04146", "pdf": "https://arxiv.org/pdf/2505.04146", "abs": "https://arxiv.org/abs/2505.04146", "authors": ["Variath Madhupal Gautham Nair", "Vishal Varma Dantuluri"], "title": "Unmasking the Canvas: A Dynamic Benchmark for Image Generation Jailbreaking and LLM Content Safety", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "Existing large language models (LLMs) are advancing rapidly and produce\noutstanding results in image generation tasks, yet their content safety checks\nremain vulnerable to prompt-based jailbreaks. Through preliminary testing on\nplatforms such as ChatGPT, MetaAI, and Grok, we observed that even short,\nnatural prompts could lead to the generation of compromising images ranging\nfrom realistic depictions of forged documents to manipulated images of public\nfigures.\n  We introduce Unmasking the Canvas (UTC Benchmark; UTCB), a dynamic and\nscalable benchmark dataset to evaluate LLM vulnerability in image generation.\nOur methodology combines structured prompt engineering, multilingual\nobfuscation (e.g., Zulu, Gaelic, Base64), and evaluation using Groq-hosted\nLLaMA-3. The pipeline supports both zero-shot and fallback prompting\nstrategies, risk scoring, and automated tagging. All generations are stored\nwith rich metadata and curated into Bronze (non-verified), Silver (LLM-aided\nverification), and Gold (manually verified) tiers. UTCB is designed to evolve\nover time with new data sources, prompt templates, and model behaviors.\n  Warning: This paper includes visual examples of adversarial inputs designed\nto test model safety. All outputs have been redacted to ensure responsible\ndisclosure.", "AI": {"tldr": "The paper introduces UTCB, a benchmark to test LLM vulnerabilities in image generation, revealing prompt-based jailbreaks and proposing a scalable evaluation method.", "motivation": "Existing LLMs lack robust content safety checks, making them susceptible to prompt-based jailbreaks, as shown by preliminary tests on platforms like ChatGPT and MetaAI.", "method": "The UTCB benchmark uses structured prompt engineering, multilingual obfuscation, and evaluation with LLaMA-3, supporting zero-shot and fallback strategies, risk scoring, and automated tagging.", "result": "The benchmark identifies vulnerabilities in LLMs, generating compromising images from simple prompts, and categorizes results into Bronze, Silver, and Gold tiers for verification.", "conclusion": "UTCB provides a dynamic, scalable tool to evaluate and improve LLM safety in image generation, with plans for future updates to address evolving threats."}}
{"id": "2408.17432", "pdf": "https://arxiv.org/pdf/2408.17432", "abs": "https://arxiv.org/abs/2408.17432", "authors": ["Ismail Rasim Ulgen", "Shreeram Suresh Chandra", "Junchen Lu", "Berrak Sisman"], "title": "SelectTTS: Synthesizing Anyone's Voice via Discrete Unit-Based Frame Selection", "categories": ["eess.AS", "cs.LG"], "comment": "Submitted to IEEE Signal Processing Letters", "summary": "Synthesizing the voices of unseen speakers remains a persisting challenge in\nmulti-speaker text-to-speech (TTS). Existing methods model speaker\ncharacteristics through speaker conditioning during training, leading to\nincreased model complexity and limiting reproducibility and accessibility. A\nlower-complexity method would enable speech synthesis research with limited\ncomputational and data resources to reach to a wider use. To this end, we\npropose SelectTTS, a simple and effective alternative. SelectTTS selects\nappropriate frames from the target speaker and decodes them using frame-level\nself-supervised learning (SSL) features. We demonstrate that this approach can\neffectively capture speaker characteristics for unseen speakers and achieves\nperformance comparable to state-of-the-art multi-speaker TTS frameworks on both\nobjective and subjective metrics. By directly selecting frames from the target\nspeaker's speech, SelectTTS enables generalization to unseen speakers with\nsignificantly lower model complexity. Compared to baselines such as XTTS-v2 and\nVALL-E, SelectTTS achieves better speaker similarity while reducing model\nparameters by over 8x and training data requirements by 270x.", "AI": {"tldr": "SelectTTS is a low-complexity method for multi-speaker TTS that selects frames from target speakers and uses SSL features, achieving performance comparable to state-of-the-art models with fewer resources.", "motivation": "Existing multi-speaker TTS methods are complex and resource-intensive, limiting accessibility. SelectTTS aims to simplify this process.", "method": "SelectTTS selects frames from target speakers and decodes them using SSL features, reducing model complexity.", "result": "SelectTTS matches state-of-the-art performance with 8x fewer parameters and 270x less training data.", "conclusion": "SelectTTS offers a simpler, resource-efficient alternative for multi-speaker TTS, enabling wider accessibility."}}
{"id": "2505.04019", "pdf": "https://arxiv.org/pdf/2505.04019", "abs": "https://arxiv.org/abs/2505.04019", "authors": ["Matteo Ceschin", "Leonardo Arrighi", "Luca Longo", "Sylvio Barbon Junior"], "title": "Extending Decision Predicate Graphs for Comprehensive Explanation of Isolation Forest", "categories": ["cs.AI"], "comment": null, "summary": "The need to explain predictive models is well-established in modern machine\nlearning. However, beyond model interpretability, understanding pre-processing\nmethods is equally essential. Understanding how data modifications impact model\nperformance improvements and potential biases and promoting a reliable pipeline\nis mandatory for developing robust machine learning solutions. Isolation Forest\n(iForest) is a widely used technique for outlier detection that performs well.\nIts effectiveness increases with the number of tree-based learners. However,\nthis also complicates the explanation of outlier selection and the decision\nboundaries for inliers. This research introduces a novel Explainable AI (XAI)\nmethod, tackling the problem of global explainability. In detail, it aims to\noffer a global explanation for outlier detection to address its opaque nature.\nOur approach is based on the Decision Predicate Graph (DPG), which clarifies\nthe logic of ensemble methods and provides both insights and a graph-based\nmetric to explain how samples are identified as outliers using the proposed\nInlier-Outlier Propagation Score (IOP-Score). Our proposal enhances iForest's\nexplainability and provides a comprehensive view of the decision-making\nprocess, detailing which features contribute to outlier identification and how\nthe model utilizes them. This method advances the state-of-the-art by providing\ninsights into decision boundaries and a comprehensive view of holistic feature\nusage in outlier identification. -- thus promoting a fully explainable machine\nlearning pipeline.", "AI": {"tldr": "The paper introduces a novel XAI method using Decision Predicate Graph (DPG) to globally explain outlier detection in Isolation Forest (iForest), enhancing interpretability and decision transparency.", "motivation": "Understanding data pre-processing and model interpretability is crucial for robust ML solutions. iForest's effectiveness grows with complexity, but this complicates explainability, necessitating a global explanation method.", "method": "The proposed method uses DPG to clarify ensemble logic, introducing the Inlier-Outlier Propagation Score (IOP-Score) to explain outlier identification and feature contributions.", "result": "The approach improves iForest's explainability, offering insights into decision boundaries and feature usage, advancing the state-of-the-art in XAI for outlier detection.", "conclusion": "The method promotes a fully explainable ML pipeline by detailing outlier identification logic and feature contributions, enhancing transparency in iForest."}}
{"id": "2505.03783", "pdf": "https://arxiv.org/pdf/2505.03783", "abs": "https://arxiv.org/abs/2505.03783", "authors": ["Tian Chen", "Shengping Liu", "Li Liu", "Heng Yong"], "title": "A general physics-constrained method for the modelling of equation's closure terms with sparse data", "categories": ["cs.LG"], "comment": null, "summary": "Accurate modeling of closure terms is a critical challenge in engineering and\nscientific research, particularly when data is sparse (scarse or incomplete),\nmaking widely applicable models difficult to develop. This study proposes a\nnovel approach for constructing closure models in such challenging scenarios.\nWe introduce a Series-Parallel Multi-Network Architecture that integrates\nPhysics-Informed Neural Networks (PINNs) to incorporate physical constraints\nand heterogeneous data from multiple initial and boundary conditions, while\nemploying dedicated subnetworks to independently model unknown closure terms,\nenhancing generalizability across diverse problems. These closure models are\nintegrated into an accurate Partial Differential Equation (PDE) solver,\nenabling robust solutions to complex predictive simulations in engineering\napplications.", "AI": {"tldr": "A novel Series-Parallel Multi-Network Architecture using PINNs is proposed to model closure terms in sparse data scenarios, enhancing generalizability for engineering applications.", "motivation": "Accurate modeling of closure terms is challenging with sparse or incomplete data, necessitating widely applicable models.", "method": "The approach integrates Physics-Informed Neural Networks (PINNs) with dedicated subnetworks to independently model unknown closure terms, incorporating physical constraints and heterogeneous data.", "result": "The closure models are integrated into a PDE solver, enabling robust solutions for complex predictive simulations.", "conclusion": "The proposed architecture improves generalizability and accuracy in modeling closure terms for engineering problems."}}
{"id": "2505.03848", "pdf": "https://arxiv.org/pdf/2505.03848", "abs": "https://arxiv.org/abs/2505.03848", "authors": ["Janhavi Giri", "Attila Lengyel", "Don Kent", "Edward Kibardin"], "title": "Advanced Clustering Framework for Semiconductor Image Analytics Integrating Deep TDA with Self-Supervised and Transfer Learning Techniques", "categories": ["cs.CV", "cs.AI", "cs.ET", "cs.LG"], "comment": "46 pages, 22 figures, 5 tables", "summary": "Semiconductor manufacturing generates vast amounts of image data, crucial for\ndefect identification and yield optimization, yet often exceeds manual\ninspection capabilities. Traditional clustering techniques struggle with\nhigh-dimensional, unlabeled data, limiting their effectiveness in capturing\nnuanced patterns. This paper introduces an advanced clustering framework that\nintegrates deep Topological Data Analysis (TDA) with self-supervised and\ntransfer learning techniques, offering a novel approach to unsupervised image\nclustering. TDA captures intrinsic topological features, while self-supervised\nlearning extracts meaningful representations from unlabeled data, reducing\nreliance on labeled datasets. Transfer learning enhances the framework's\nadaptability and scalability, allowing fine-tuning to new datasets without\nretraining from scratch. Validated on synthetic and open-source semiconductor\nimage datasets, the framework successfully identifies clusters aligned with\ndefect patterns and process variations. This study highlights the\ntransformative potential of combining TDA, self-supervised learning, and\ntransfer learning, providing a scalable solution for proactive process\nmonitoring and quality control in semiconductor manufacturing and other domains\nwith large-scale image datasets.", "AI": {"tldr": "An advanced clustering framework combining deep Topological Data Analysis (TDA), self-supervised learning, and transfer learning is proposed for unsupervised image clustering in semiconductor manufacturing, improving defect identification and process monitoring.", "motivation": "Semiconductor manufacturing produces large-scale image data for defect identification, but manual inspection and traditional clustering methods are inadequate for high-dimensional, unlabeled data.", "method": "The framework integrates deep TDA to capture topological features, self-supervised learning for meaningful representations, and transfer learning for adaptability and scalability.", "result": "Validated on synthetic and open-source datasets, the framework effectively clusters defect patterns and process variations.", "conclusion": "The combination of TDA, self-supervised learning, and transfer learning offers a scalable solution for quality control in semiconductor manufacturing and similar domains."}}
{"id": "2503.22712", "pdf": "https://arxiv.org/pdf/2503.22712", "abs": "https://arxiv.org/abs/2503.22712", "authors": ["Zijun Jia", "Jinsong Yu", "Hongyu Long", "Diyin Tang"], "title": "Coverage-Guaranteed Speech Emotion Recognition via Calibrated Uncertainty-Adaptive Prediction Sets", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": null, "summary": "Road rage, often triggered by emotional suppression and sudden outbursts,\nsignificantly threatens road safety by causing collisions and aggressive\nbehavior. Speech emotion recognition technologies can mitigate this risk by\nidentifying negative emotions early and issuing timely alerts. However, current\nSER methods, such as those based on hidden markov models and Long short-term\nmemory networks, primarily handle one-dimensional signals, frequently\nexperience overfitting, and lack calibration, limiting their safety-critical\neffectiveness. We propose a novel risk-controlled prediction framework\nproviding statistically rigorous guarantees on prediction accuracy. This\napproach employs a calibration set to define a binary loss function indicating\nwhether the true label is included in the prediction set. Using a data-driven\nthreshold $\\beta$, we optimize a joint loss function to maintain an expected\ntest loss bounded by a user-specified risk level $\\alpha$. Evaluations across\nsix baseline models and two benchmark datasets demonstrate our framework\nconsistently achieves a minimum coverage of $1 - \\alpha$, effectively\ncontrolling marginal error rates despite varying calibration-test split ratios\n(e.g., 0.1). The robustness and generalizability of the framework are further\nvalidated through an extension to small-batch online calibration under a local\nexchangeability assumption. We construct a non-negative test martingale to\nmaintain prediction validity even in dynamic and non-exchangeable environments.\nCross-dataset tests confirm our method's ability to uphold reliable statistical\nguarantees in realistic, evolving data scenarios.", "AI": {"tldr": "A risk-controlled prediction framework for speech emotion recognition (SER) is proposed to mitigate road rage by ensuring statistically rigorous guarantees on prediction accuracy, outperforming traditional methods.", "motivation": "Road rage, caused by emotional suppression and outbursts, threatens road safety. Current SER methods lack reliability and calibration for safety-critical applications.", "method": "A novel framework uses a calibration set and a binary loss function to optimize prediction accuracy, controlled by a user-specified risk level. It includes extensions for small-batch online calibration and non-exchangeable environments.", "result": "The framework consistently achieves a minimum coverage of 1 - \u03b1 across models and datasets, maintaining robustness under varying conditions.", "conclusion": "The proposed method provides reliable statistical guarantees for SER in dynamic environments, enhancing road safety by early emotion detection."}}
{"id": "2505.04161", "pdf": "https://arxiv.org/pdf/2505.04161", "abs": "https://arxiv.org/abs/2505.04161", "authors": ["Baida Zhang", "Yakai Chen", "Huichun Li", "Zhenghu Zu"], "title": "Optimization of Infectious Disease Intervention Measures Based on Reinforcement Learning -- Empirical analysis based on UK COVID-19 epidemic data", "categories": ["cs.LG", "cs.CY", "cs.MA", "physics.comp-ph"], "comment": null, "summary": "Globally, the outbreaks of infectious diseases have exerted an extremely\nprofound and severe influence on health security and the economy. During the\ncritical phases of epidemics, devising effective intervention measures poses a\nsignificant challenge to both the academic and practical arenas. There is\nnumerous research based on reinforcement learning to optimize intervention\nmeasures of infectious diseases. Nevertheless, most of these efforts have been\nconfined within the differential equation based on infectious disease models.\nAlthough a limited number of studies have incorporated reinforcement learning\nmethodologies into individual-based infectious disease models, the models\nemployed therein have entailed simplifications and limitations, rendering it\nincapable of modeling the complexity and dynamics inherent in infectious\ndisease transmission. We establish a decision-making framework based on an\nindividual agent-based transmission model, utilizing reinforcement learning to\ncontinuously explore and develop a strategy function. The framework's validity\nis verified through both experimental and theoretical approaches. Covasim, a\ndetailed and widely used agent-based disease transmission model, was modified\nto support reinforcement learning research. We conduct an exhaustive\nexploration of the application efficacy of multiple algorithms across diverse\naction spaces. Furthermore, we conduct an innovative preliminary theoretical\nanalysis concerning the issue of \"time coverage\". The results of the experiment\nrobustly validate the effectiveness and feasibility of the methodological\nframework of this study. The coping strategies gleaned therefrom prove highly\nefficacious in suppressing the expansion of the epidemic scale and safeguarding\nthe stability of the economic system, thereby providing crucial reference\nperspectives for the formulation of global public health security strategies.", "AI": {"tldr": "A reinforcement learning framework is developed for optimizing intervention measures in infectious diseases using an individual agent-based model, validated through experiments and theory.", "motivation": "The challenge of devising effective intervention measures during epidemics, with existing research limited by simplifications in disease models.", "method": "A decision-making framework based on an individual agent-based transmission model (modified Covasim) using reinforcement learning to develop strategy functions, tested with multiple algorithms.", "result": "The framework effectively suppresses epidemic expansion and maintains economic stability, validated experimentally and theoretically.", "conclusion": "The study provides a robust methodological framework for public health strategies, addressing the complexity of disease transmission."}}
{"id": "2409.04388", "pdf": "https://arxiv.org/pdf/2409.04388", "abs": "https://arxiv.org/abs/2409.04388", "authors": ["Hangyu Qin", "Junbin Xiao", "Angela Yao"], "title": "Question-Answering Dense Video Events", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": "Accepted to SIGIR'25", "summary": "This paper presents question-answering on dense video events, a novel task\nthat answers and grounds dense-event questions in long videos, thus challenging\nMLLMs to faithfully comprehend and reason about multiple events over extended\nperiods of time. To facilitate the study, we construct DeVE-QA -- a dataset\nfeaturing 78K questions about 26K events on 10.6K long videos. Our benchmarking\nshows that state-of-the-art MLLMs struggle on DeVE-QA. For improvement, we\npropose DeVi, a novel training-free MLLM approach that highlights a\nhierarchical captioning module, a temporal event memory module, and a\nself-consistency checking module to respectively detect, contextualize and\nmemorize, and ground dense-events in long videos for question answering.\nExtensive experiments show that DeVi is superior at answering dense-event\nquestions and grounding relevant video moments. Compared with existing MLLMs,\nit achieves a remarkable increase of 4.8% and 2.1% for G(round)QA accuracy on\nDeVE-QA~and NExT-GQA, respectively. Our data and code will be released upon\nacceptance.", "AI": {"tldr": "The paper introduces a novel task of question-answering on dense video events, presents the DeVE-QA dataset, and proposes DeVi, a training-free MLLM approach that outperforms state-of-the-art models.", "motivation": "To address the challenge of answering and grounding dense-event questions in long videos, which current MLLMs struggle with.", "method": "Proposes DeVi, featuring hierarchical captioning, temporal event memory, and self-consistency checking modules to detect, contextualize, and ground dense events.", "result": "DeVi achieves a 4.8% and 2.1% accuracy increase on DeVE-QA and NExT-GQA, respectively.", "conclusion": "DeVi effectively improves dense-event question answering and grounding, with plans to release data and code."}}
{"id": "2505.04230", "pdf": "https://arxiv.org/pdf/2505.04230", "abs": "https://arxiv.org/abs/2505.04230", "authors": ["Meishar Meisel", "Benjamin A. Cohen", "Meital Baskin", "Beatrice Tiosano", "Joachim A. Behar", "Eran Berkowitz"], "title": "HYAMD High-Resolution Fundus Image Dataset for age related macular degeneration (AMD) Diagnosis", "categories": ["eess.IV", "q-bio.TO"], "comment": null, "summary": "The Hillel Yaffe Age Related Macular Degeneration (HYAMD) dataset is a\nlongitudinal collection of 1,560 Digital Fundus Images (DFIs) from 325 patients\nexamined at the Hillel Yaffe Medical Center (Hadera, Israel) between 2021 and\n2024. The dataset includes an AMD cohort of 147 patients (aged 54-94) with\nvarying stages of AMD and a control group of 190 diabetic retinopathy (DR)\npatients (aged 24-92). AMD diagnoses were based on comprehensive clinical\nophthalmic evaluations, supported by Optical Coherence Tomography (OCT) and OCT\nangiography. Non-AMD DFIs were sourced from DR patients without concurrent AMD,\ndiagnosed using macular OCT, fluorescein angiography, and widefield imaging.\nHYAMD provides gold-standard annotations, ensuring AMD labels were assigned\nfollowing a full clinical assessment. Images were captured with a DRI OCT\nTriton (Topcon) camera, offering a 45 deg field of view and 1960 x 1934 pixel\nresolution. To the best of our knowledge, HYAMD is the first open-access\nretinal dataset from an Israeli sample, designed to support AMD identification\nusing machine learning models.", "AI": {"tldr": "The HYAMD dataset is a longitudinal collection of 1,560 fundus images from 325 patients, including AMD and DR cases, with gold-standard annotations for AMD identification using machine learning.", "motivation": "To provide an open-access retinal dataset from an Israeli sample to support AMD identification and research using machine learning models.", "method": "The dataset includes DFIs from AMD and DR patients, with diagnoses confirmed by clinical evaluations, OCT, and angiography. Images were captured using a Topcon camera.", "result": "HYAMD is the first open-access Israeli retinal dataset, offering high-quality annotated images for AMD research.", "conclusion": "HYAMD serves as a valuable resource for advancing AMD identification and machine learning applications in ophthalmology."}}
{"id": "2505.04152", "pdf": "https://arxiv.org/pdf/2505.04152", "abs": "https://arxiv.org/abs/2505.04152", "authors": ["Manas Satish Bedmutha", "Feng Chen", "Andrea Hartzler", "Trevor Cohen", "Nadir Weibel"], "title": "Can Language Models Understand Social Behavior in Clinical Conversations?", "categories": ["cs.CL", "cs.CY", "cs.HC", "H.5.2; H.1.2; I.2.7; I.2.m; J.3"], "comment": null, "summary": "Effective communication between providers and their patients influences\nhealth and care outcomes. The effectiveness of such conversations has been\nlinked not only to the exchange of clinical information, but also to a range of\ninterpersonal behaviors; commonly referred to as social signals, which are\noften conveyed through non-verbal cues and shape the quality of the\npatient-provider relationship. Recent advances in large language models (LLMs)\nhave demonstrated an increasing ability to infer emotional and social behaviors\neven when analyzing only textual information. As automation increases also in\nclinical settings, such as for transcription of patient-provider conversations,\nthere is growing potential for LLMs to automatically analyze and extract social\nbehaviors from these interactions. To explore the foundational capabilities of\nLLMs in tracking social signals in clinical dialogue, we designed task-specific\nprompts and evaluated model performance across multiple architectures and\nprompting styles using a highly imbalanced, annotated dataset spanning 20\ndistinct social signals such as provider dominance, patient warmth, etc. We\npresent the first system capable of tracking all these 20 coded signals, and\nuncover patterns in LLM behavior. Further analysis of model configurations and\nclinical context provides insights for enhancing LLM performance on social\nsignal processing tasks in healthcare settings.", "AI": {"tldr": "The paper explores using LLMs to analyze social signals in clinical dialogues, evaluating performance across architectures and prompting styles, and presents a system tracking 20 social signals.", "motivation": "Effective patient-provider communication impacts health outcomes, and LLMs offer potential to automate analysis of social behaviors in clinical settings.", "method": "Task-specific prompts were designed, and model performance was evaluated using an imbalanced annotated dataset of 20 social signals.", "result": "The study presents the first system tracking all 20 social signals and identifies patterns in LLM behavior, offering insights for improving performance.", "conclusion": "LLMs show promise for social signal processing in healthcare, with further analysis needed to optimize their use in clinical contexts."}}
{"id": "2502.01547", "pdf": "https://arxiv.org/pdf/2502.01547", "abs": "https://arxiv.org/abs/2502.01547", "authors": ["Andrew Rouditchenko", "Samuel Thomas", "Hilde Kuehne", "Rogerio Feris", "James Glass"], "title": "mWhisper-Flamingo for Multilingual Audio-Visual Noise-Robust Speech Recognition", "categories": ["eess.AS", "cs.CV", "cs.SD"], "comment": "Accepted in Signal Processing Letters. Code at\n  https://github.com/roudimit/whisper-flamingo", "summary": "Audio-Visual Speech Recognition (AVSR) combines lip-based video with audio\nand can improve performance in noise, but most methods are trained only on\nEnglish data. One limitation is the lack of large-scale multilingual video\ndata, which makes it hard to train models from scratch. In this work, we\npropose mWhisper-Flamingo for multilingual AVSR which combines the strengths of\na pre-trained audio model (Whisper) and video model (AV-HuBERT). To enable\nbetter multi-modal integration and improve the noisy multilingual performance,\nwe introduce decoder modality dropout where the model is trained both on paired\naudio-visual inputs and separate audio/visual inputs. mWhisper-Flamingo\nachieves state-of-the-art WER on MuAViC, an AVSR dataset of 9 languages.\nAudio-visual mWhisper-Flamingo consistently outperforms audio-only Whisper on\nall languages in noisy conditions.", "AI": {"tldr": "mWhisper-Flamingo combines pre-trained audio (Whisper) and video (AV-HuBERT) models for multilingual AVSR, using decoder modality dropout to improve noisy performance. It achieves state-of-the-art results on MuAViC.", "motivation": "Most AVSR methods are limited to English due to lack of multilingual video data, hindering performance in noisy conditions.", "method": "Combines Whisper and AV-HuBERT with decoder modality dropout for training on paired and separate audio/visual inputs.", "result": "Achieves state-of-the-art WER on MuAViC (9 languages) and outperforms audio-only Whisper in noisy conditions.", "conclusion": "mWhisper-Flamingo effectively addresses multilingual AVSR challenges, improving noisy performance with innovative training."}}
{"id": "2505.04115", "pdf": "https://arxiv.org/pdf/2505.04115", "abs": "https://arxiv.org/abs/2505.04115", "authors": ["Luise Ge", "Brendan Juba", "Kris Nilsson"], "title": "Polynomial-Time Relational Probabilistic Inference in Open Universes", "categories": ["cs.AI"], "comment": null, "summary": "Reasoning under uncertainty is a fundamental challenge in Artificial\nIntelligence. As with most of these challenges, there is a harsh dilemma\nbetween the expressive power of the language used, and the tractability of the\ncomputational problem posed by reasoning. Inspired by human reasoning, we\nintroduce a method of first-order relational probabilistic inference that\nsatisfies both criteria, and can handle hybrid (discrete and continuous)\nvariables. Specifically, we extend sum-of-squares logic of expectation to\nrelational settings, demonstrating that lifted reasoning in the bounded-degree\nfragment for knowledge bases of bounded quantifier rank can be performed in\npolynomial time, even with an a priori unknown and/or countably infinite set of\nobjects. Crucially, our notion of tractability is framed in proof-theoretic\nterms, which extends beyond the syntactic properties of the language or\nqueries. We are able to derive the tightest bounds provable by proofs of a\ngiven degree and size and establish completeness in our sum-of-squares\nrefutations for fixed degrees.", "AI": {"tldr": "The paper introduces a tractable first-order relational probabilistic inference method for hybrid variables, inspired by human reasoning, with polynomial-time lifted reasoning in bounded-degree settings.", "motivation": "Address the challenge of balancing expressive power and computational tractability in reasoning under uncertainty, inspired by human reasoning.", "method": "Extends sum-of-squares logic of expectation to relational settings, enabling lifted reasoning in bounded-degree fragments with polynomial-time complexity.", "result": "Demonstrates tractable reasoning with hybrid variables, tight bounds provable by proofs of given degree and size, and completeness in sum-of-squares refutations.", "conclusion": "The method successfully balances expressive power and tractability, offering a proof-theoretic framework for efficient probabilistic inference."}}
{"id": "2505.03784", "pdf": "https://arxiv.org/pdf/2505.03784", "abs": "https://arxiv.org/abs/2505.03784", "authors": ["Ahmed A. Metwally", "A. Ali Heydari", "Daniel McDuff", "Alexandru Solot", "Zeinab Esmaeilpour", "Anthony Z Faranesh", "Menglian Zhou", "David B. Savage", "Conor Heneghan", "Shwetak Patel", "Cathy Speed", "Javier L. Prieto"], "title": "Insulin Resistance Prediction From Wearables and Routine Blood Biomarkers", "categories": ["cs.LG"], "comment": null, "summary": "Insulin resistance, a precursor to type 2 diabetes, is characterized by\nimpaired insulin action in tissues. Current methods for measuring insulin\nresistance, while effective, are expensive, inaccessible, not widely available\nand hinder opportunities for early intervention. In this study, we remotely\nrecruited the largest dataset to date across the US to study insulin resistance\n(N=1,165 participants, with median BMI=28 kg/m2, age=45 years, HbA1c=5.4%),\nincorporating wearable device time series data and blood biomarkers, including\nthe ground-truth measure of insulin resistance, homeostatic model assessment\nfor insulin resistance (HOMA-IR). We developed deep neural network models to\npredict insulin resistance based on readily available digital and blood\nbiomarkers. Our results show that our models can predict insulin resistance by\ncombining both wearable data and readily available blood biomarkers better than\neither of the two data sources separately (R2=0.5, auROC=0.80, Sensitivity=76%,\nand specificity 84%). The model showed 93% sensitivity and 95% adjusted\nspecificity in obese and sedentary participants, a subpopulation most\nvulnerable to developing type 2 diabetes and who could benefit most from early\nintervention. Rigorous evaluation of model performance, including\ninterpretability, and robustness, facilitates generalizability across larger\ncohorts, which is demonstrated by reproducing the prediction performance on an\nindependent validation cohort (N=72 participants). Additionally, we\ndemonstrated how the predicted insulin resistance can be integrated into a\nlarge language model agent to help understand and contextualize HOMA-IR values,\nfacilitating interpretation and safe personalized recommendations. This work\noffers the potential for early detection of people at risk of type 2 diabetes\nand thereby facilitate earlier implementation of preventative strategies.", "AI": {"tldr": "Deep neural networks predict insulin resistance using wearable and blood biomarker data, outperforming single-source methods, with high accuracy in vulnerable populations.", "motivation": "Current methods for measuring insulin resistance are costly and inaccessible, limiting early intervention opportunities.", "method": "Developed deep neural network models combining wearable device data and blood biomarkers to predict insulin resistance.", "result": "Models achieved R2=0.5, auROC=0.80, Sensitivity=76%, and specificity 84%, with higher accuracy in obese/sedentary participants.", "conclusion": "This approach enables early detection of type 2 diabetes risk, facilitating preventative strategies."}}
{"id": "2505.03856", "pdf": "https://arxiv.org/pdf/2505.03856", "abs": "https://arxiv.org/abs/2505.03856", "authors": ["Tin Mi\u0161i\u0107", "Karlo Koledi\u0107", "Fabio Bonsignorio", "Ivan Petrovi\u0107", "Ivan Markovi\u0107"], "title": "An Active Inference Model of Covert and Overt Visual Attention", "categories": ["cs.CV", "cs.AI", "I.2.6; I.2.10"], "comment": "7 pages, 7 figures. Code available at\n  https://github.com/unizgfer-lamor/ainf-visual-attention", "summary": "The ability to selectively attend to relevant stimuli while filtering out\ndistractions is essential for agents that process complex, high-dimensional\nsensory input. This paper introduces a model of covert and overt visual\nattention through the framework of active inference, utilizing dynamic\noptimization of sensory precisions to minimize free-energy. The model\ndetermines visual sensory precisions based on both current environmental\nbeliefs and sensory input, influencing attentional allocation in both covert\nand overt modalities. To test the effectiveness of the model, we analyze its\nbehavior in the Posner cueing task and a simple target focus task using\ntwo-dimensional(2D) visual data. Reaction times are measured to investigate the\ninterplay between exogenous and endogenous attention, as well as valid and\ninvalid cueing. The results show that exogenous and valid cues generally lead\nto faster reaction times compared to endogenous and invalid cues. Furthermore,\nthe model exhibits behavior similar to inhibition of return, where previously\nattended locations become suppressed after a specific cue-target onset\nasynchrony interval. Lastly, we investigate different aspects of overt\nattention and show that involuntary, reflexive saccades occur faster than\nintentional ones, but at the expense of adaptability.", "AI": {"tldr": "The paper presents an active inference-based model for covert and overt visual attention, tested using the Posner cueing task and a target focus task. Results show faster reaction times for exogenous/valid cues and behaviors like inhibition of return. Reflexive saccades are faster but less adaptable.", "motivation": "To model how agents selectively attend to stimuli while filtering distractions, using active inference to optimize sensory precisions.", "method": "The model dynamically optimizes sensory precisions based on environmental beliefs and input, tested in the Posner cueing task and a 2D target focus task, measuring reaction times.", "result": "Exogenous/valid cues yield faster reaction times; the model shows inhibition of return. Reflexive saccades are quicker but less adaptable.", "conclusion": "The active inference model effectively captures attentional dynamics, balancing speed and adaptability in covert and overt attention."}}
{"id": "2505.01880", "pdf": "https://arxiv.org/pdf/2505.01880", "abs": "https://arxiv.org/abs/2505.01880", "authors": ["Junyan Wu", "Wenbo Xu", "Wei Lu", "Xiangyang Luo", "Rui Yang", "Shize Guo"], "title": "Weakly-supervised Audio Temporal Forgery Localization via Progressive Audio-language Co-learning Network", "categories": ["cs.SD", "cs.CV", "cs.MM", "eess.AS"], "comment": "9pages, 5figures. This paper has been accepted for IJCAI2025", "summary": "Audio temporal forgery localization (ATFL) aims to find the precise forgery\nregions of the partial spoof audio that is purposefully modified. Existing ATFL\nmethods rely on training efficient networks using fine-grained annotations,\nwhich are obtained costly and challenging in real-world scenarios. To meet this\nchallenge, in this paper, we propose a progressive audio-language co-learning\nnetwork (LOCO) that adopts co-learning and self-supervision manners to prompt\nlocalization performance under weak supervision scenarios. Specifically, an\naudio-language co-learning module is first designed to capture forgery\nconsensus features by aligning semantics from temporal and global perspectives.\nIn this module, forgery-aware prompts are constructed by using utterance-level\nannotations together with learnable prompts, which can incorporate semantic\npriors into temporal content features dynamically. In addition, a forgery\nlocalization module is applied to produce forgery proposals based on fused\nforgery-class activation sequences. Finally, a progressive refinement strategy\nis introduced to generate pseudo frame-level labels and leverage supervised\nsemantic contrastive learning to amplify the semantic distinction between real\nand fake content, thereby continuously optimizing forgery-aware features.\nExtensive experiments show that the proposed LOCO achieves SOTA performance on\nthree public benchmarks.", "AI": {"tldr": "LOCO is a progressive audio-language co-learning network for audio temporal forgery localization (ATFL) under weak supervision, achieving SOTA performance.", "motivation": "Existing ATFL methods require costly fine-grained annotations, which are impractical in real-world scenarios. LOCO addresses this by leveraging weak supervision and self-supervision.", "method": "LOCO uses an audio-language co-learning module to align semantics and forgery-aware prompts, a forgery localization module for proposals, and progressive refinement with pseudo labels and contrastive learning.", "result": "LOCO achieves state-of-the-art performance on three public benchmarks.", "conclusion": "LOCO effectively localizes audio forgeries under weak supervision, outperforming existing methods."}}
{"id": "2505.04196", "pdf": "https://arxiv.org/pdf/2505.04196", "abs": "https://arxiv.org/abs/2505.04196", "authors": ["Sung Yoo Lim", "Hyunsoo Yun", "Prateek Bansal", "Dong-Kyu Kim", "Eui-Jin Kim"], "title": "A Large Language Model for Feasible and Diverse Population Synthesis", "categories": ["cs.LG", "cs.MA"], "comment": "28 pages, 7 figures, 6 tables. Submitted to Transportation Research\n  Part C: Emerging Technologies. Preprint version", "summary": "Generating a synthetic population that is both feasible and diverse is\ncrucial for ensuring the validity of downstream activity schedule simulation in\nactivity-based models (ABMs). While deep generative models (DGMs), such as\nvariational autoencoders and generative adversarial networks, have been applied\nto this task, they often struggle to balance the inclusion of rare but\nplausible combinations (i.e., sampling zeros) with the exclusion of implausible\nones (i.e., structural zeros). To improve feasibility while maintaining\ndiversity, we propose a fine-tuning method for large language models (LLMs)\nthat explicitly controls the autoregressive generation process through\ntopological orderings derived from a Bayesian Network (BN). Experimental\nresults show that our hybrid LLM-BN approach outperforms both traditional DGMs\nand proprietary LLMs (e.g., ChatGPT-4o) with few-shot learning. Specifically,\nour approach achieves approximately 95% feasibility, significantly higher than\nthe ~80% observed in DGMs, while maintaining comparable diversity, making it\nwell-suited for practical applications. Importantly, the method is based on a\nlightweight open-source LLM, enabling fine-tuning and inference on standard\npersonal computing environments. This makes the approach cost-effective and\nscalable for large-scale applications, such as synthesizing populations in\nmegacities, without relying on expensive infrastructure. By initiating the ABM\npipeline with high-quality synthetic populations, our method improves overall\nsimulation reliability and reduces downstream error propagation. The source\ncode for these methods is available for research and practical application.", "AI": {"tldr": "A hybrid LLM-BN method improves synthetic population generation, achieving 95% feasibility and comparable diversity, outperforming traditional DGMs and proprietary LLMs.", "motivation": "Ensuring valid downstream activity simulations in ABMs requires feasible and diverse synthetic populations, which existing DGMs struggle to balance.", "method": "Fine-tuning LLMs with topological orderings from a Bayesian Network to control autoregressive generation.", "result": "95% feasibility (vs. ~80% in DGMs) with maintained diversity, scalable on standard hardware.", "conclusion": "The lightweight, open-source LLM-BN approach enhances ABM reliability and reduces error propagation."}}
{"id": "2505.03603", "pdf": "https://arxiv.org/pdf/2505.03603", "abs": "https://arxiv.org/abs/2505.03603", "authors": ["Y. B. Wang", "S. Z. Zhou", "J. F. Wu", "T. Hu", "J. N. Zhang", "Y. Liu"], "title": "PAHA: Parts-Aware Audio-Driven Human Animation with Diffusion Model", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Audio-driven human animation technology is widely used in human-computer\ninteraction, and the emergence of diffusion models has further advanced its\ndevelopment. Currently, most methods rely on multi-stage generation and\nintermediate representations, resulting in long inference time and issues with\ngeneration quality in specific foreground regions and audio-motion consistency.\nThese shortcomings are primarily due to the lack of localized fine-grained\nsupervised guidance. To address above challenges, we propose PAHA, an\nend-to-end audio-driven upper-body human animation framework with diffusion\nmodel. We introduce two key methods: Parts-Aware Re-weighting (PAR) and Parts\nConsistency Enhancement (PCE). PAR dynamically adjusts regional training loss\nweights based on pose confidence scores, effectively improving visual quality.\nPCE constructs and trains diffusion-based regional audio-visual classifiers to\nimprove the consistency of motion and co-speech audio. Afterwards, we design\ntwo novel inference guidance methods for the foregoing classifiers, Sequential\nGuidance (SG) and Differential Guidance (DG), to balance efficiency and quality\nrespectively. Additionally, we build CNAS, the first public Chinese News Anchor\nSpeech dataset, to advance research and validation in this field. Extensive\nexperimental results and user studies demonstrate that PAHA significantly\noutperforms existing methods in audio-motion alignment and video-related\nevaluations. The codes and CNAS dataset will be released upon acceptance.", "AI": {"tldr": "PAHA is an end-to-end audio-driven upper-body human animation framework using a diffusion model, addressing quality and consistency issues with PAR and PCE methods, and introducing CNAS dataset.", "motivation": "Current methods suffer from long inference times and poor quality in specific regions due to lack of localized fine-grained supervision.", "method": "Proposes PAR for dynamic loss adjustment and PCE for audio-motion consistency, with SG and DG for inference guidance.", "result": "PAHA outperforms existing methods in audio-motion alignment and video evaluations.", "conclusion": "PAHA advances audio-driven animation with improved quality and consistency, supported by the new CNAS dataset."}}
{"id": "2505.03785", "pdf": "https://arxiv.org/pdf/2505.03785", "abs": "https://arxiv.org/abs/2505.03785", "authors": ["Eleftherios Tzanis", "Michail E. Klontzas"], "title": "mAIstro: an open-source multi-agentic system for automated end-to-end development of radiomics and deep learning models for medical imaging", "categories": ["cs.LG", "eess.IV"], "comment": null, "summary": "Agentic systems built on large language models (LLMs) offer promising\ncapabilities for automating complex workflows in healthcare AI. We introduce\nmAIstro, an open-source, autonomous multi-agentic framework for end-to-end\ndevelopment and deployment of medical AI models. The system orchestrates\nexploratory data analysis, radiomic feature extraction, image segmentation,\nclassification, and regression through a natural language interface, requiring\nno coding from the user. Built on a modular architecture, mAIstro supports both\nopen- and closed-source LLMs, and was evaluated using a large and diverse set\nof prompts across 16 open-source datasets, covering a wide range of imaging\nmodalities, anatomical regions, and data types. The agents successfully\nexecuted all tasks, producing interpretable outputs and validated models. This\nwork presents the first agentic framework capable of unifying data analysis, AI\nmodel development, and inference across varied healthcare applications,\noffering a reproducible and extensible foundation for clinical and research AI\nintegration. The code is available at: https://github.com/eltzanis/mAIstro", "AI": {"tldr": "mAIstro is an open-source, autonomous multi-agent framework for developing and deploying medical AI models without coding, using LLMs.", "motivation": "To automate complex healthcare AI workflows and unify data analysis, model development, and inference.", "method": "Modular architecture with natural language interface for tasks like data analysis, feature extraction, and model validation.", "result": "Successfully executed tasks across 16 datasets, producing interpretable outputs and validated models.", "conclusion": "mAIstro provides a reproducible, extensible foundation for clinical and research AI integration."}}
{"id": "2505.04253", "pdf": "https://arxiv.org/pdf/2505.04253", "abs": "https://arxiv.org/abs/2505.04253", "authors": ["Maria Marina", "Nikolay Ivanov", "Sergey Pletenev", "Mikhail Salnikov", "Daria Galimzianova", "Nikita Krayko", "Vasily Konovalov", "Alexander Panchenko", "Viktor Moskvoretskii"], "title": "LLM-Independent Adaptive RAG: Let the Question Speak for Itself", "categories": ["cs.CL", "cs.LG"], "comment": "11 pages, 5 figures, 2 tables", "summary": "Large Language Models~(LLMs) are prone to hallucinations, and\nRetrieval-Augmented Generation (RAG) helps mitigate this, but at a high\ncomputational cost while risking misinformation. Adaptive retrieval aims to\nretrieve only when necessary, but existing approaches rely on LLM-based\nuncertainty estimation, which remain inefficient and impractical. In this\nstudy, we introduce lightweight LLM-independent adaptive retrieval methods\nbased on external information. We investigated 27 features, organized into 7\ngroups, and their hybrid combinations. We evaluated these methods on 6 QA\ndatasets, assessing the QA performance and efficiency. The results show that\nour approach matches the performance of complex LLM-based methods while\nachieving significant efficiency gains, demonstrating the potential of external\ninformation for adaptive retrieval.", "AI": {"tldr": "Lightweight LLM-independent adaptive retrieval methods using external information match LLM-based performance with efficiency gains.", "motivation": "LLMs suffer from hallucinations, and RAG is costly and risky. Adaptive retrieval needs efficient, practical solutions beyond LLM-based uncertainty estimation.", "method": "Introduced lightweight adaptive retrieval methods using 27 features grouped into 7 categories, evaluated on 6 QA datasets.", "result": "Matched LLM-based performance while significantly improving efficiency.", "conclusion": "External information can effectively enable adaptive retrieval without relying on LLMs."}}
{"id": "2505.04310", "pdf": "https://arxiv.org/pdf/2505.04310", "abs": "https://arxiv.org/abs/2505.04310", "authors": ["Simo Alami C.", "Rim Kaddah", "Jesse Read", "Marie-Paule Cani"], "title": "Flow Models for Unbounded and Geometry-Aware Distributional Reinforcement Learning", "categories": ["cs.AI", "math.OC"], "comment": null, "summary": "We introduce a new architecture for Distributional Reinforcement Learning\n(DistRL) that models return distributions using normalizing flows. This\napproach enables flexible, unbounded support for return distributions, in\ncontrast to categorical approaches like C51 that rely on fixed or bounded\nrepresentations. It also offers richer modeling capacity to capture\nmulti-modality, skewness, and tail behavior than quantile based approaches. Our\nmethod is significantly more parameter-efficient than categorical approaches.\nStandard metrics used to train existing models like KL divergence or\nWasserstein distance either are scale insensitive or have biased sample\ngradients, especially when return supports do not overlap. To address this, we\npropose a novel surrogate for the Cram\\`er distance, that is geometry-aware and\ncomputable directly from the return distribution's PDF, avoiding the costly CDF\ncomputation. We test our model on the ATARI-5 sub-benchmark and show that our\napproach outperforms PDF based models while remaining competitive with quantile\nbased methods.", "AI": {"tldr": "A new DistRL architecture using normalizing flows for flexible return distributions, outperforming categorical and quantile methods on ATARI-5.", "motivation": "Existing DistRL methods (e.g., C51) have limitations like fixed support or biased gradients, prompting a need for more flexible and efficient modeling.", "method": "Uses normalizing flows for unbounded return distributions and introduces a novel surrogate for Cram\u00e9r distance to address gradient issues.", "result": "Outperforms PDF-based models and remains competitive with quantile methods on ATARI-5, with higher parameter efficiency.", "conclusion": "The proposed architecture offers superior flexibility and efficiency for modeling return distributions in DistRL."}}
{"id": "2505.03786", "pdf": "https://arxiv.org/pdf/2505.03786", "abs": "https://arxiv.org/abs/2505.03786", "authors": ["Md Fahim Anjum"], "title": "When Reasoning Beats Scale: A 1.5B Reasoning Model Outranks 13B LLMs as Discriminator", "categories": ["cs.LG", "cs.CL"], "comment": "12 pages, 5 figures. Code available at:\n  https://github.com/MDFahimAnjum/llm-planning-with-reasoning", "summary": "Large Language Models (LLM) with reasoning capabilities offer a promising\npath for improving candidate evaluation in planning frameworks, but their\nrelative performance against traditional non-reasoning models remains largely\nunderexplored. In this study, we benchmark a distilled 1.5B parameter reasoning\nmodel (DeepSeek-R1) against several state-of-the-art non-reasoning LLMs within\na generator-discriminator LLM planning framework for the text-to-SQL task. For\nthis, we introduce a novel method for extracting soft scores from the\nchain-of-thought (CoT) outputs from reasoning that enables fine-grained ranking\nof candidates. Our central hypothesis is that reasoning models are more\neffective discriminators than non-reasoning LLMs. Our results show that\ndistilled DeepSeek-R1-1.5B achieves up to $87\\%$ higher F1 and $3.7\\%$ better\ndiscrimination accuracy than CodeLlama-7B, as well as $3.7\\%$ higher execution\naccuracy than CodeLlama-13B, despite having significantly fewer parameters.\nFurthermore, we find that there is a limit to the logical capabilities of\nreasoning models, and only providing more context or allowing more compute\nbudget for reasoning is not enough to improve their discrimination performance.\nFinally, we demonstrate that, unlike non-reasoning LLMs, reasoning models find\ngeneration more challenging than discrimination and may underperform as\ngenerators compared to smaller non-reasoning LLMs. Our work highlights the\npotential of reasoning models as discriminators in agentic frameworks, far\noutweighing their capabilities as generators, offering insights into their\noptimal role within LLM planning infrastructures.", "AI": {"tldr": "The study benchmarks a reasoning LLM (DeepSeek-R1) against non-reasoning LLMs in a text-to-SQL task, showing superior discrimination performance but limitations in generation.", "motivation": "To explore the effectiveness of reasoning LLMs as discriminators compared to non-reasoning LLMs in planning frameworks.", "method": "Benchmarked DeepSeek-R1 against non-reasoning LLMs using a novel method to extract soft scores from CoT outputs for fine-grained ranking.", "result": "DeepSeek-R1 outperformed non-reasoning LLMs in discrimination but showed limitations in generation and logical capabilities.", "conclusion": "Reasoning models excel as discriminators in LLM planning frameworks but underperform as generators, suggesting their optimal role is in discrimination."}}
{"id": "2505.03896", "pdf": "https://arxiv.org/pdf/2505.03896", "abs": "https://arxiv.org/abs/2505.03896", "authors": ["Shuang Zeng", "Chee Hong Lee", "Micky C Nnamdi", "Wenqi Shi", "J Ben Tamo", "Lei Zhu", "Hangzhou He", "Xinliang Zhang", "Qian Chen", "May D. Wang", "Yanye Lu", "Qiushi Ren"], "title": "Novel Extraction of Discriminative Fine-Grained Feature to Improve Retinal Vessel Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Retinal vessel segmentation is a vital early detection method for several\nsevere ocular diseases. Despite significant progress in retinal vessel\nsegmentation with the advancement of Neural Networks, there are still\nchallenges to overcome. Specifically, retinal vessel segmentation aims to\npredict the class label for every pixel within a fundus image, with a primary\nfocus on intra-image discrimination, making it vital for models to extract more\ndiscriminative features. Nevertheless, existing methods primarily focus on\nminimizing the difference between the output from the decoder and the label,\nbut ignore fully using feature-level fine-grained representations from the\nencoder. To address these issues, we propose a novel Attention U-shaped\nKolmogorov-Arnold Network named AttUKAN along with a novel Label-guided\nPixel-wise Contrastive Loss for retinal vessel segmentation. Specifically, we\nimplement Attention Gates into Kolmogorov-Arnold Networks to enhance model\nsensitivity by suppressing irrelevant feature activations and model\ninterpretability by non-linear modeling of KAN blocks. Additionally, we also\ndesign a novel Label-guided Pixel-wise Contrastive Loss to supervise our\nproposed AttUKAN to extract more discriminative features by distinguishing\nbetween foreground vessel-pixel pairs and background pairs. Experiments are\nconducted across four public datasets including DRIVE, STARE, CHASE_DB1, HRF\nand our private dataset. AttUKAN achieves F1 scores of 82.50%, 81.14%, 81.34%,\n80.21% and 80.09%, along with MIoU scores of 70.24%, 68.64%, 68.59%, 67.21% and\n66.94% in the above datasets, which are the highest compared to 11 networks for\nretinal vessel segmentation. Quantitative and qualitative results show that our\nAttUKAN achieves state-of-the-art performance and outperforms existing retinal\nvessel segmentation methods. Our code will be available at\nhttps://github.com/stevezs315/AttUKAN.", "AI": {"tldr": "Proposes AttUKAN, a novel Attention U-shaped Kolmogorov-Arnold Network with Label-guided Pixel-wise Contrastive Loss for superior retinal vessel segmentation.", "motivation": "Existing methods ignore fine-grained encoder features and focus only on decoder-label differences, limiting discriminative feature extraction.", "method": "Integrates Attention Gates into Kolmogorov-Arnold Networks for enhanced sensitivity and interpretability, and introduces a novel contrastive loss for better feature discrimination.", "result": "Achieves top F1 and MIoU scores on four public and one private dataset, outperforming 11 existing networks.", "conclusion": "AttUKAN sets a new state-of-the-art in retinal vessel segmentation, validated by quantitative and qualitative results."}}
{"id": "2505.04231", "pdf": "https://arxiv.org/pdf/2505.04231", "abs": "https://arxiv.org/abs/2505.04231", "authors": ["Taoyuan Yu", "Kui Wang", "Zongdian Li", "Tao Yu", "Kei Sakaguchi"], "title": "Multi-Agent Reinforcement Learning-based Cooperative Autonomous Driving in Smart Intersections", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "comment": "7 pages", "summary": "Unsignalized intersections pose significant safety and efficiency challenges\ndue to complex traffic flows. This paper proposes a novel roadside unit\n(RSU)-centric cooperative driving system leveraging global perception and\nvehicle-to-infrastructure (V2I) communication. The core of the system is an\nRSU-based decision-making module using a two-stage hybrid reinforcement\nlearning (RL) framework. At first, policies are pre-trained offline using\nconservative Q-learning (CQL) combined with behavior cloning (BC) on collected\ndataset. Subsequently, these policies are fine-tuned in the simulation using\nmulti-agent proximal policy optimization (MAPPO), aligned with a self-attention\nmechanism to effectively solve inter-agent dependencies. RSUs perform real-time\ninference based on the trained models to realize vehicle control via V2I\ncommunications. Extensive experiments in CARLA environment demonstrate high\neffectiveness of the proposed system, by: \\textit{(i)} achieving failure rates\nbelow 0.03\\% in coordinating three connected and autonomous vehicles (CAVs)\nthrough complex intersection scenarios, significantly outperforming the\ntraditional Autoware control method, and \\textit{(ii)} exhibiting strong\nrobustness across varying numbers of controlled agents and shows promising\ngeneralization capabilities on other maps.", "AI": {"tldr": "A novel RSU-centric cooperative driving system for unsignalized intersections uses a hybrid RL framework (CQL+BC and MAPPO) to achieve high safety and efficiency, outperforming traditional methods.", "motivation": "Address safety and efficiency challenges at unsignalized intersections due to complex traffic flows.", "method": "Two-stage hybrid RL: offline pre-training (CQL+BC) and online fine-tuning (MAPPO with self-attention). RSUs perform real-time inference via V2I.", "result": "Achieves <0.03% failure rate in coordinating CAVs, outperforming Autoware, and shows robustness and generalization.", "conclusion": "The system is highly effective for unsignalized intersections, offering safety, efficiency, and scalability."}}
{"id": "2505.04085", "pdf": "https://arxiv.org/pdf/2505.04085", "abs": "https://arxiv.org/abs/2505.04085", "authors": ["Minseok Kim", "Gesi Teng", "Keita Nishi", "Togo Ikegami", "Masamune Sato"], "title": "Device-Free Localization Using Multi-Link MIMO Channels in Distributed Antenna Networks", "categories": ["eess.SP", "eess.IV"], "comment": null, "summary": "This paper presented a novel device-free localization (DFL) framework based\non distributed antenna networks (DANs), targeting integrated sensing and\ncommunication (ISAC) in future 6G radio access networks (RANs). In the proposed\napproach, radio tomographic imaging (RTI) leverages the spatial and temporal\ndiversity of multi-link multiple-input multiple-output (MIMO) channels in DANs\nto improve localization accuracy. Furthermore, a prototype system was developed\nusing software-defined radios (SDRs) operating in the sub-6 GHz band, and\ncomprehensive evaluations were conducted under indoor conditions involving\nvarying node densities and target types. The results demonstrate that the\nframework achieves sub-meter localization accuracy in most scenarios and\nmaintains robust performance under complex multipath environments. In addition,\nthe use of Bayesian optimization to fine-tune key parameters, such as sparsity\nand path thickness, led to significant improvements in image reconstruction\nquality and target estimation accuracy. These results demonstrate the\nfeasibility and effectiveness of DAN-based DFL systems for accurate, robust,\nand scalable localization.", "AI": {"tldr": "A novel device-free localization (DFL) framework using distributed antenna networks (DANs) for 6G ISAC, achieving sub-meter accuracy with Bayesian optimization for parameter tuning.", "motivation": "To enhance localization accuracy in 6G RANs by leveraging DANs and ISAC, addressing challenges like multipath environments and varying node densities.", "method": "Uses radio tomographic imaging (RTI) with multi-link MIMO channels in DANs, implemented via SDRs in sub-6 GHz band, and employs Bayesian optimization for parameter tuning.", "result": "Achieves sub-meter localization accuracy, robust performance in multipath, and improved image reconstruction and target estimation.", "conclusion": "The DAN-based DFL system is feasible, effective, and scalable for accurate localization in 6G networks."}}
{"id": "2505.04284", "pdf": "https://arxiv.org/pdf/2505.04284", "abs": "https://arxiv.org/abs/2505.04284", "authors": ["Sofia Jamil", "Aryan Dabad", "Bollampalli Areen Reddy", "Sriparna Saha", "Rajiv Misra", "Adil A. Shakur"], "title": "GASCADE: Grouped Summarization of Adverse Drug Event for Enhanced Cancer Pharmacovigilance", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the realm of cancer treatment, summarizing adverse drug events (ADEs)\nreported by patients using prescribed drugs is crucial for enhancing\npharmacovigilance practices and improving drug-related decision-making. While\nthe volume and complexity of pharmacovigilance data have increased, existing\nresearch in this field has predominantly focused on general diseases rather\nthan specifically addressing cancer. This work introduces the task of grouped\nsummarization of adverse drug events reported by multiple patients using the\nsame drug for cancer treatment. To address the challenge of limited resources\nin cancer pharmacovigilance, we present the MultiLabeled Cancer Adverse Drug\nReaction and Summarization (MCADRS) dataset. This dataset includes\npharmacovigilance posts detailing patient concerns regarding drug efficacy and\nadverse effects, along with extracted labels for drug names, adverse drug\nevents, severity, and adversity of reactions, as well as summaries of ADEs for\neach drug. Additionally, we propose the Grouping and Abstractive Summarization\nof Cancer Adverse Drug events (GASCADE) framework, a novel pipeline that\ncombines the information extraction capabilities of Large Language Models\n(LLMs) with the summarization power of the encoder-decoder T5 model. Our work\nis the first to apply alignment techniques, including advanced algorithms like\nDirect Preference Optimization, to encoder-decoder models using synthetic\ndatasets for summarization tasks. Through extensive experiments, we demonstrate\nthe superior performance of GASCADE across various metrics, validated through\nboth automated assessments and human evaluations. This multitasking approach\nenhances drug-related decision-making and fosters a deeper understanding of\npatient concerns, paving the way for advancements in personalized and\nresponsive cancer care. The code and dataset used in this work are publicly\navailable.", "AI": {"tldr": "The paper introduces a novel framework (GASCADE) and dataset (MCADRS) for summarizing adverse drug events in cancer treatment, leveraging LLMs and T5 models with alignment techniques for superior performance.", "motivation": "To address the gap in pharmacovigilance research focused on cancer, improving drug-related decision-making by summarizing patient-reported adverse drug events.", "method": "Proposes the GASCADE framework, combining LLMs for information extraction and T5 for summarization, using the MCADRS dataset with alignment techniques like Direct Preference Optimization.", "result": "GASCADE outperforms in experiments, validated by automated and human evaluations, enhancing drug decision-making and patient understanding.", "conclusion": "The work advances personalized cancer care by improving ADE summarization, with publicly available code and dataset."}}
{"id": "2505.04313", "pdf": "https://arxiv.org/pdf/2505.04313", "abs": "https://arxiv.org/abs/2505.04313", "authors": ["Stephen Richard Varey", "Alessandro Di Stefano", "The Anh Han"], "title": "KERAIA: An Adaptive and Explainable Framework for Dynamic Knowledge Representation and Reasoning", "categories": ["cs.AI", "cs.ET", "cs.SC"], "comment": "22 pages", "summary": "In this paper, we introduce KERAIA, a novel framework and software platform\nfor symbolic knowledge engineering designed to address the persistent\nchallenges of representing, reasoning with, and executing knowledge in dynamic,\ncomplex, and context-sensitive environments. The central research question that\nmotivates this work is: How can unstructured, often tacit, human expertise be\neffectively transformed into computationally tractable algorithms that AI\nsystems can efficiently utilise? KERAIA seeks to bridge this gap by building on\nfoundational concepts such as Minsky's frame-based reasoning and K-lines, while\nintroducing significant innovations. These include Clouds of Knowledge for\ndynamic aggregation, Dynamic Relations (DRels) for context-sensitive\ninheritance, explicit Lines of Thought (LoTs) for traceable reasoning, and\nCloud Elaboration for adaptive knowledge transformation. This approach moves\nbeyond the limitations of traditional, often static, knowledge representation\nparadigms. KERAIA is designed with Explainable AI (XAI) as a core principle,\nensuring transparency and interpretability, particularly through the use of\nLoTs. The paper details the framework's architecture, the KSYNTH representation\nlanguage, and the General Purpose Paradigm Builder (GPPB) to integrate diverse\ninference methods within a unified structure. We validate KERAIA's versatility,\nexpressiveness, and practical applicability through detailed analysis of\nmultiple case studies spanning naval warfare simulation, industrial diagnostics\nin water treatment plants, and strategic decision-making in the game of RISK.\nFurthermore, we provide a comparative analysis against established knowledge\nrepresentation paradigms (including ontologies, rule-based systems, and\nknowledge graphs) and discuss the implementation aspects and computational\nconsiderations of the KERAIA platform.", "AI": {"tldr": "KERAIA is a novel framework for symbolic knowledge engineering, addressing challenges in dynamic, complex environments by transforming human expertise into AI-tractable algorithms. It introduces innovations like Clouds of Knowledge and Dynamic Relations, validated through case studies.", "motivation": "To bridge the gap between unstructured human expertise and computationally tractable AI algorithms, overcoming limitations of static knowledge representation paradigms.", "method": "KERAIA uses frame-based reasoning, Clouds of Knowledge, Dynamic Relations, and Lines of Thought for adaptive knowledge transformation. It includes KSYNTH language and GPPB for unified inference.", "result": "Validated through case studies in naval warfare, industrial diagnostics, and RISK game, showing versatility and expressiveness.", "conclusion": "KERAIA advances knowledge representation with dynamic, context-sensitive methods, ensuring transparency and practical applicability."}}
{"id": "2505.03787", "pdf": "https://arxiv.org/pdf/2505.03787", "abs": "https://arxiv.org/abs/2505.03787", "authors": ["Zuraiz Baig", "Sidra Nasir", "Rizwan Ahmed Khan", "Muhammad Zeeshan Ul Haque"], "title": "ArrhythmiaVision: Resource-Conscious Deep Learning Models with Visual Explanations for ECG Arrhythmia Classification", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages and 08 figures", "summary": "Cardiac arrhythmias are a leading cause of life-threatening cardiac events,\nhighlighting the urgent need for accurate and timely detection.\nElectrocardiography (ECG) remains the clinical gold standard for arrhythmia\ndiagnosis; however, manual interpretation is time-consuming, dependent on\nclinical expertise, and prone to human error. Although deep learning has\nadvanced automated ECG analysis, many existing models abstract away the\nsignal's intrinsic temporal and morphological features, lack interpretability,\nand are computationally intensive-hindering their deployment on\nresource-constrained platforms. In this work, we propose two novel lightweight\n1D convolutional neural networks, ArrhythmiNet V1 and V2, optimized for\nefficient, real-time arrhythmia classification on edge devices. Inspired by\nMobileNet's depthwise separable convolutional design, these models maintain\nmemory footprints of just 302.18 KB and 157.76 KB, respectively, while\nachieving classification accuracies of 0.99 (V1) and 0.98 (V2) on the MIT-BIH\nArrhythmia Dataset across five classes: Normal Sinus Rhythm, Left Bundle Branch\nBlock, Right Bundle Branch Block, Atrial Premature Contraction, and Premature\nVentricular Contraction. In order to ensure clinical transparency and\nrelevance, we integrate Shapley Additive Explanations and Gradient-weighted\nClass Activation Mapping, enabling both local and global interpretability.\nThese techniques highlight physiologically meaningful patterns such as the QRS\ncomplex and T-wave that contribute to the model's predictions. We also discuss\nperformance-efficiency trade-offs and address current limitations related to\ndataset diversity and generalizability. Overall, our findings demonstrate the\nfeasibility of combining interpretability, predictive accuracy, and\ncomputational efficiency in practical, wearable, and embedded ECG monitoring\nsystems.", "AI": {"tldr": "Proposes lightweight 1D CNNs (ArrhythmiNet V1/V2) for efficient, real-time arrhythmia classification on edge devices, achieving high accuracy and interpretability.", "motivation": "Addresses the need for accurate, timely arrhythmia detection, overcoming limitations of manual ECG interpretation and existing deep learning models.", "method": "Introduces two lightweight 1D CNNs inspired by MobileNet, optimized for edge devices, with Shapley and Grad-CAM for interpretability.", "result": "Achieves 0.99 (V1) and 0.98 (V2) accuracy on MIT-BIH dataset, with small memory footprints (302.18 KB and 157.76 KB).", "conclusion": "Demonstrates feasibility of interpretable, accurate, and efficient ECG monitoring systems for practical use."}}
{"id": "2505.03974", "pdf": "https://arxiv.org/pdf/2505.03974", "abs": "https://arxiv.org/abs/2505.03974", "authors": ["Nikhil M. Pawar", "Jorge A. Prozzi", "Feng Hong", "Surya Sarat Chandra Congress"], "title": "Deep Learning Framework for Infrastructure Maintenance: Crack Detection and High-Resolution Imaging of Infrastructure Surfaces", "categories": ["cs.CV", "cs.AI"], "comment": "Presented :Transportation Research Board 104th Annual Meeting,\n  Washington, D.C", "summary": "Recently, there has been an impetus for the application of cutting-edge data\ncollection platforms such as drones mounted with camera sensors for\ninfrastructure asset management. However, the sensor characteristics, proximity\nto the structure, hard-to-reach access, and environmental conditions often\nlimit the resolution of the datasets. A few studies used super-resolution\ntechniques to address the problem of low-resolution images. Nevertheless, these\ntechniques were observed to increase computational cost and false alarms of\ndistress detection due to the consideration of all the infrastructure images\ni.e., positive and negative distress classes. In order to address the\npre-processing of false alarm and achieve efficient super-resolution, this\nstudy developed a framework consisting of convolutional neural network (CNN)\nand efficient sub-pixel convolutional neural network (ESPCNN). CNN accurately\nclassified both the classes. ESPCNN, which is the lightweight super-resolution\ntechnique, generated high-resolution infrastructure image of positive distress\nobtained from CNN. The ESPCNN outperformed bicubic interpolation in all the\nevaluation metrics for super-resolution. Based on the performance metrics, the\ncombination of CNN and ESPCNN was observed to be effective in preprocessing the\ninfrastructure images with negative distress, reducing the computational cost\nand false alarms in the next step of super-resolution. The visual inspection\nshowed that EPSCNN is able to capture crack propagation, complex geometry of\neven minor cracks. The proposed framework is expected to help the highway\nagencies in accurately performing distress detection and assist in efficient\nasset management practices.", "AI": {"tldr": "A framework combining CNN and ESPCNN improves infrastructure image resolution and reduces false alarms in distress detection.", "motivation": "Address limitations of low-resolution drone images and high computational costs in super-resolution techniques for infrastructure management.", "method": "Developed a framework using CNN for accurate distress classification and ESPCNN for efficient super-resolution of positive distress images.", "result": "ESPCNN outperformed bicubic interpolation, reduced computational costs, and minimized false alarms. Visual inspection confirmed accurate crack detection.", "conclusion": "The CNN-ESPCNN framework enhances distress detection accuracy and aids efficient infrastructure asset management."}}
{"id": "2505.04251", "pdf": "https://arxiv.org/pdf/2505.04251", "abs": "https://arxiv.org/abs/2505.04251", "authors": ["Krishna Ronanki"], "title": "Facilitating Trustworthy Human-Agent Collaboration in LLM-based Multi-Agent System oriented Software Engineering", "categories": ["cs.SE", "cs.AI", "cs.MA"], "comment": null, "summary": "Multi-agent autonomous systems (MAS) are better at addressing challenges that\nspans across multiple domains than singular autonomous agents. This holds true\nwithin the field of software engineering (SE) as well. The state-of-the-art\nresearch on MAS within SE focuses on integrating LLMs at the core of autonomous\nagents to create LLM-based multi-agent autonomous (LMA) systems. However, the\nintroduction of LMA systems into SE brings a plethora of challenges. One of the\nmajor challenges is the strategic allocation of tasks between humans and the\nLMA system in a trustworthy manner. To address this challenge, a RACI-based\nframework is proposed in this work in progress article, along with\nimplementation guidelines and an example implementation of the framework. The\nproposed framework can facilitate efficient collaboration, ensure\naccountability, and mitigate potential risks associated with LLM-driven\nautomation while aligning with the Trustworthy AI guidelines. The future steps\nfor this work delineating the planned empirical validation method are also\npresented.", "AI": {"tldr": "The paper proposes a RACI-based framework for task allocation between humans and LLM-based multi-agent systems in software engineering to ensure trust and efficiency.", "motivation": "Addressing challenges in integrating LLM-based multi-agent systems (LMA) into software engineering, particularly task allocation and trustworthiness.", "method": "Proposes a RACI-based framework with implementation guidelines and an example.", "result": "The framework aims to facilitate collaboration, ensure accountability, and mitigate risks of LLM-driven automation.", "conclusion": "Future work includes empirical validation of the proposed framework."}}
{"id": "2505.04318", "pdf": "https://arxiv.org/pdf/2505.04318", "abs": "https://arxiv.org/abs/2505.04318", "authors": ["Jacob Glenn Ayers", "Buvaneswari A. Ramanan", "Manzoor A. Khan"], "title": "Detecting Concept Drift in Neural Networks Using Chi-squared Goodness of Fit Testing", "categories": ["cs.LG", "cs.AI", "eess.IV"], "comment": "8 pages, 6 figures, 1 table", "summary": "As the adoption of deep learning models has grown beyond human capacity for\nverification, meta-algorithms are needed to ensure reliable model inference.\nConcept drift detection is a field dedicated to identifying statistical shifts\nthat is underutilized in monitoring neural networks that may encounter\ninference data with distributional characteristics diverging from their\ntraining data. Given the wide variety of model architectures, applications, and\ndatasets, it is important that concept drift detection algorithms are adaptable\nto different inference scenarios. In this paper, we introduce an application of\nthe $\\chi^2$ Goodness of Fit Hypothesis Test as a drift detection\nmeta-algorithm applied to a multilayer perceptron, a convolutional neural\nnetwork, and a transformer trained for machine vision as they are exposed to\nsimulated drift during inference. To that end, we demonstrate how unexpected\ndrops in accuracy due to concept drift can be detected without directly\nexamining the inference outputs. Our approach enhances safety by ensuring\nmodels are continually evaluated for reliability across varying conditions.", "AI": {"tldr": "The paper proposes using the \u03c7\u00b2 Goodness of Fit Test as a drift detection meta-algorithm for neural networks to identify concept drift without examining inference outputs directly.", "motivation": "Deep learning models often face unreliable inference due to concept drift, and existing drift detection methods are underutilized. A versatile approach is needed to monitor models across diverse scenarios.", "method": "The \u03c7\u00b2 Goodness of Fit Test is applied as a drift detection meta-algorithm on a multilayer perceptron, CNN, and transformer under simulated drift conditions.", "result": "The method detects accuracy drops caused by concept drift without direct output analysis, enhancing model reliability.", "conclusion": "The approach ensures continual evaluation of model reliability under varying conditions, improving safety in deep learning applications."}}
{"id": "2505.04388", "pdf": "https://arxiv.org/pdf/2505.04388", "abs": "https://arxiv.org/abs/2505.04388", "authors": ["Dario Garcia-Gasulla", "Jordi Bayarri-Planas", "Ashwin Kumar Gururajan", "Enrique Lopez-Cuena", "Adrian Tormos", "Daniel Hinjos", "Pablo Bernabeu-Perez", "Anna Arias-Duart", "Pablo Agustin Martin-Torres", "Marta Gonzalez-Mallo", "Sergio Alvarez-Napagao", "Eduard Ayguad\u00e9-Parra", "Ulises Cort\u00e9s"], "title": "The Aloe Family Recipe for Open and Specialized Healthcare LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "arXiv admin note: substantial text overlap with arXiv:2405.01886", "summary": "Purpose: With advancements in Large Language Models (LLMs) for healthcare,\nthe need arises for competitive open-source models to protect the public\ninterest. This work contributes to the field of open medical LLMs by optimizing\nkey stages of data preprocessing and training, while showing how to improve\nmodel safety (through DPO) and efficacy (through RAG). The evaluation\nmethodology used, which includes four different types of tests, defines a new\nstandard for the field. The resultant models, shown to be competitive with the\nbest private alternatives, are released with a permisive license.\n  Methods: Building on top of strong base models like Llama 3.1 and Qwen 2.5,\nAloe Beta uses a custom dataset to enhance public data with synthetic Chain of\nThought examples. The models undergo alignment with Direct Preference\nOptimization, emphasizing ethical and policy-aligned performance in the\npresence of jailbreaking attacks. Evaluation includes close-ended, open-ended,\nsafety and human assessments, to maximize the reliability of results.\n  Results: Recommendations are made across the entire pipeline, backed by the\nsolid performance of the Aloe Family. These models deliver competitive\nperformance across healthcare benchmarks and medical fields, and are often\npreferred by healthcare professionals. On bias and toxicity, the Aloe Beta\nmodels significantly improve safety, showing resilience to unseen jailbreaking\nattacks. For a responsible release, a detailed risk assessment specific to\nhealthcare is attached to the Aloe Family models.\n  Conclusion: The Aloe Beta models, and the recipe that leads to them, are a\nsignificant contribution to the open-source medical LLM field, offering\ntop-of-the-line performance while maintaining high ethical requirements. This\nwork sets a new standard for developing and reporting aligned LLMs in\nhealthcare.", "AI": {"tldr": "The paper introduces Aloe Beta, an open-source medical LLM, optimizing data preprocessing and training for safety and efficacy, setting a new evaluation standard and outperforming private alternatives.", "motivation": "To advance open-source medical LLMs, ensuring public interest protection through improved safety, efficacy, and ethical alignment.", "method": "Uses base models (Llama 3.1, Qwen 2.5) with synthetic data, Direct Preference Optimization (DPO) for alignment, and rigorous evaluation (four test types).", "result": "Aloe Beta models excel in healthcare benchmarks, safety, and bias reduction, preferred by professionals and resilient to attacks.", "conclusion": "Aloe Beta and its methodology advance open-source medical LLMs, setting new standards for ethical, high-performance models in healthcare."}}
{"id": "2505.04317", "pdf": "https://arxiv.org/pdf/2505.04317", "abs": "https://arxiv.org/abs/2505.04317", "authors": ["Ruize Zhang", "Sirui Xiang", "Zelai Xu", "Feng Gao", "Shilong Ji", "Wenhao Tang", "Wenbo Ding", "Chao Yu", "Yu Wang"], "title": "Mastering Multi-Drone Volleyball through Hierarchical Co-Self-Play Reinforcement Learning", "categories": ["cs.AI"], "comment": null, "summary": "In this paper, we tackle the problem of learning to play 3v3 multi-drone\nvolleyball, a new embodied competitive task that requires both high-level\nstrategic coordination and low-level agile control. The task is turn-based,\nmulti-agent, and physically grounded, posing significant challenges due to its\nlong-horizon dependencies, tight inter-agent coupling, and the underactuated\ndynamics of quadrotors. To address this, we propose Hierarchical Co-Self-Play\n(HCSP), a hierarchical reinforcement learning framework that separates\ncentralized high-level strategic decision-making from decentralized low-level\nmotion control. We design a three-stage population-based training pipeline to\nenable both strategy and skill to emerge from scratch without expert\ndemonstrations: (I) training diverse low-level skills, (II) learning high-level\nstrategy via self-play with fixed low-level controllers, and (III) joint\nfine-tuning through co-self-play. Experiments show that HCSP achieves superior\nperformance, outperforming non-hierarchical self-play and rule-based\nhierarchical baselines with an average 82.9\\% win rate and a 71.5\\% win rate\nagainst the two-stage variant. Moreover, co-self-play leads to emergent team\nbehaviors such as role switching and coordinated formations, demonstrating the\neffectiveness of our hierarchical design and training scheme.", "AI": {"tldr": "HCSP, a hierarchical RL framework, excels in 3v3 multi-drone volleyball by separating strategic and motion control, achieving high win rates and emergent team behaviors.", "motivation": "Addressing the challenges of long-horizon dependencies, inter-agent coupling, and quadrotor dynamics in competitive multi-agent tasks.", "method": "Hierarchical Co-Self-Play (HCSP) with a three-stage pipeline: skill training, strategy learning via self-play, and joint fine-tuning.", "result": "HCSP outperforms baselines with 82.9% win rate and shows emergent behaviors like role switching.", "conclusion": "HCSP's hierarchical design and co-self-play are effective for complex multi-agent tasks."}}
{"id": "2505.03789", "pdf": "https://arxiv.org/pdf/2505.03789", "abs": "https://arxiv.org/abs/2505.03789", "authors": ["Syoiti Ninomiya", "Yuming Ma"], "title": "A new architecture of high-order deep neural networks that learn martingales", "categories": ["cs.LG", "math.PR", "q-fin.CP", "65C30, 60H35, 91G60, 68T07"], "comment": "19 pages, 3 figures", "summary": "A new deep-learning neural network architecture based on high-order weak\napproximation algorithms for stochastic differential equations (SDEs) is\nproposed. The architecture enables the efficient learning of martingales by\ndeep learning models. The behaviour of deep neural networks based on this\narchitecture, when applied to the problem of pricing financial derivatives, is\nalso examined. The core of this new architecture lies in the high-order weak\napproximation algorithms of the explicit Runge--Kutta type, wherein the\napproximation is realised solely through iterative compositions and linear\ncombinations of vector fields of the target SDEs.", "AI": {"tldr": "A new deep-learning architecture using high-order weak approximation for SDEs improves martingale learning and financial derivative pricing.", "motivation": "To enhance the efficiency of learning martingales and pricing financial derivatives using deep learning.", "method": "High-order weak approximation algorithms of explicit Runge-Kutta type, applied through iterative compositions and linear combinations of SDE vector fields.", "result": "The architecture enables efficient learning of martingales and improves derivative pricing.", "conclusion": "The proposed architecture successfully integrates high-order weak approximation with deep learning for financial applications."}}
{"id": "2505.03991", "pdf": "https://arxiv.org/pdf/2505.03991", "abs": "https://arxiv.org/abs/2505.03991", "authors": ["Hao Xu", "Arbind Agrahari Baniya", "Sam Well", "Mohamed Reda Bouadjenek", "Richard Dazeley", "Sunil Aryal"], "title": "Action Spotting and Precise Event Detection in Sports: Datasets, Methods, and Challenges", "categories": ["cs.CV"], "comment": "13 pages, 4 figures, 2 tables", "summary": "Video event detection has become an essential component of sports analytics,\nenabling automated identification of key moments and enhancing performance\nanalysis, viewer engagement, and broadcast efficiency. Recent advancements in\ndeep learning, particularly Convolutional Neural Networks (CNNs) and\nTransformers, have significantly improved accuracy and efficiency in Temporal\nAction Localization (TAL), Action Spotting (AS), and Precise Event Spotting\n(PES). This survey provides a comprehensive overview of these three key tasks,\nemphasizing their differences, applications, and the evolution of\nmethodological approaches. We thoroughly review and categorize existing\ndatasets and evaluation metrics specifically tailored for sports contexts,\nhighlighting the strengths and limitations of each. Furthermore, we analyze\nstate-of-the-art techniques, including multi-modal approaches that integrate\naudio and visual information, methods utilizing self-supervised learning and\nknowledge distillation, and approaches aimed at generalizing across multiple\nsports. Finally, we discuss critical open challenges and outline promising\nresearch directions toward developing more generalized, efficient, and robust\nevent detection frameworks applicable to diverse sports. This survey serves as\na foundation for future research on efficient, generalizable, and multi-modal\nsports event detection.", "AI": {"tldr": "A survey on video event detection in sports analytics, covering tasks like TAL, AS, and PES, with a focus on deep learning advancements, datasets, metrics, and future research directions.", "motivation": "To enhance sports analytics through automated event detection, improving performance analysis, viewer engagement, and broadcast efficiency.", "method": "Review and categorization of datasets, evaluation metrics, and state-of-the-art techniques, including multi-modal and self-supervised learning approaches.", "result": "Comprehensive overview of tasks, methodologies, and challenges in sports event detection, highlighting strengths and limitations.", "conclusion": "Identifies open challenges and promising directions for future research to develop generalized, efficient, and robust event detection frameworks."}}
{"id": "2505.04551", "pdf": "https://arxiv.org/pdf/2505.04551", "abs": "https://arxiv.org/abs/2505.04551", "authors": ["Demetrius Hernandez", "Jane Cleland-Huang"], "title": "Runtime Advocates: A Persona-Driven Framework for Requirements@Runtime Decision Support", "categories": ["cs.SE", "cs.HC", "cs.MA"], "comment": "7 pages, 5 figures. Submitted to 33rd IEEE International Requirements\n  Engineering 2025 conference", "summary": "Complex systems, such as small Uncrewed Aerial Systems (sUAS) swarms\ndispatched for emergency response, often require dynamic reconfiguration at\nruntime under the supervision of human operators. This introduces\nhuman-on-the-loop requirements, where evolving needs shape ongoing system\nfunctionality and behaviors. While traditional personas support upfront, static\nrequirements elicitation, we propose a persona-based advocate framework for\nruntime requirements engineering to provide ethically informed, safety-driven,\nand regulatory-aware decision support. Our approach extends standard personas\ninto event-driven personas. When triggered by events such as adverse\nenvironmental conditions, evolving mission state, or operational constraints,\nthe framework updates the sUAS operator's view of the personas, ensuring\nrelevance to current conditions. We create three key advocate personas, namely\nSafety Controller, Ethical Governor, and Regulatory Auditor, to manage\ntrade-offs among risk, ethical considerations, and regulatory compliance. We\nperform a proof-of-concept validation in an emergency response scenario using\nsUAS, showing how our advocate personas provide context-aware guidance grounded\nin safety, regulatory, and ethical constraints. By evolving static, design-time\npersonas into adaptive, event-driven advocates, the framework surfaces\nmission-critical runtime requirements in response to changing conditions. These\nrequirements shape operator decisions in real time, aligning actions with the\noperational demands of the moment.", "AI": {"tldr": "A framework for dynamic reconfiguration of sUAS swarms using event-driven personas to guide human operators in real-time, balancing safety, ethics, and regulations.", "motivation": "Addressing the need for adaptive human-on-the-loop decision-making in complex systems like sUAS swarms during emergencies.", "method": "Extends personas into event-driven advocates (Safety Controller, Ethical Governor, Regulatory Auditor) triggered by runtime events.", "result": "Proof-of-concept validation in emergency response shows context-aware guidance aligning with safety, ethics, and regulations.", "conclusion": "Event-driven personas effectively surface runtime requirements, enhancing real-time operator decisions in dynamic conditions."}}
{"id": "2505.04502", "pdf": "https://arxiv.org/pdf/2505.04502", "abs": "https://arxiv.org/abs/2505.04502", "authors": ["Asma Baobaid", "Mahmoud Meribout"], "title": "Leveraging Simultaneous Usage of Edge GPU Hardware Engines for Video Face Detection and Recognition", "categories": ["cs.CV", "cs.AR", "eess.IV"], "comment": "10 pages, 11 figures", "summary": "Video face detection and recognition in public places at the edge is required\nin several applications, such as security reinforcement and contactless access\nto authorized venues. This paper aims to maximize the simultaneous usage of\nhardware engines available in edge GPUs nowadays by leveraging the concurrency\nand pipelining of tasks required for face detection and recognition. This also\nincludes the video decoding task, which is required in most face monitoring\napplications as the video streams are usually carried via Gbps Ethernet\nnetwork. This constitutes an improvement over previous works where the tasks\nare usually allocated to a single engine due to the lack of a unified and\nautomated framework that simultaneously explores all hardware engines. In\naddition, previously, the input faces were usually embedded in still images or\nwithin raw video streams that overlook the burst delay caused by the decoding\nstage. The results on real-life video streams suggest that simultaneously using\nall the hardware engines available in the recent NVIDIA edge Orin GPU, higher\nthroughput, and a slight saving of power consumption of around 300 mW,\naccounting for around 5%, have been achieved while satisfying the real-time\nperformance constraint. The performance gets even higher by considering several\nvideo streams simultaneously. Further performance improvement could have been\nobtained if the number of shuffle layers that were created by the tensor RT\nframework for the face recognition task was lower. Thus, the paper suggests\nsome hardware improvements to the existing edge GPU processors to enhance their\nperformance even higher.", "AI": {"tldr": "The paper proposes a method to maximize hardware engine usage in edge GPUs for video face detection and recognition, improving throughput and power efficiency.", "motivation": "To enhance security and contactless access by optimizing concurrent task execution in edge GPUs, addressing limitations of prior works.", "method": "Leverages concurrency and pipelining of tasks (face detection, recognition, video decoding) across all hardware engines in NVIDIA edge Orin GPUs.", "result": "Achieved higher throughput, ~5% power savings (~300 mW), and real-time performance, with further gains from multi-stream processing.", "conclusion": "Suggests hardware improvements for edge GPUs to reduce shuffle layers and further boost performance."}}
{"id": "2505.04393", "pdf": "https://arxiv.org/pdf/2505.04393", "abs": "https://arxiv.org/abs/2505.04393", "authors": ["David Exler", "Mark Schutera", "Markus Reischl", "Luca Rettenberger"], "title": "Large Means Left: Political Bias in Large Language Models Increases with Their Number of Parameters", "categories": ["cs.CL"], "comment": null, "summary": "With the increasing prevalence of artificial intelligence, careful evaluation\nof inherent biases needs to be conducted to form the basis for alleviating the\neffects these predispositions can have on users. Large language models (LLMs)\nare predominantly used by many as a primary source of information for various\ntopics. LLMs frequently make factual errors, fabricate data (hallucinations),\nor present biases, exposing users to misinformation and influencing opinions.\nEducating users on their risks is key to responsible use, as bias, unlike\nhallucinations, cannot be caught through data verification. We quantify the\npolitical bias of popular LLMs in the context of the recent vote of the German\nBundestag using the score produced by the Wahl-O-Mat. This metric measures the\nalignment between an individual's political views and the positions of German\npolitical parties. We compare the models' alignment scores to identify factors\ninfluencing their political preferences. Doing so, we discover a bias toward\nleft-leaning parties, most dominant in larger LLMs. Also, we find that the\nlanguage we use to communicate with the models affects their political views.\nAdditionally, we analyze the influence of a model's origin and release date and\ncompare the results to the outcome of the recent vote of the Bundestag. Our\nresults imply that LLMs are prone to exhibiting political bias. Large\ncorporations with the necessary means to develop LLMs, thus, knowingly or\nunknowingly, have a responsibility to contain these biases, as they can\ninfluence each voter's decision-making process and inform public opinion in\ngeneral and at scale.", "AI": {"tldr": "The paper quantifies political bias in large language models (LLMs) using German Bundestag voting data, revealing left-leaning biases, influenced by model size, language, origin, and release date.", "motivation": "To evaluate and address inherent biases in LLMs, which can spread misinformation and influence opinions, especially in political contexts.", "method": "Quantified political bias using the Wahl-O-Mat score, comparing LLMs' alignment with German political parties and analyzing influencing factors.", "result": "LLMs exhibit left-leaning biases, more pronounced in larger models. Language, origin, and release date also affect bias.", "conclusion": "LLMs are prone to political bias, and developers must mitigate these biases to prevent undue influence on public opinion and decision-making."}}
{"id": "2505.04352", "pdf": "https://arxiv.org/pdf/2505.04352", "abs": "https://arxiv.org/abs/2505.04352", "authors": ["Simon Kolker", "Louise A. Dennis", "Ramon Fraga Pereira", "Mengwei Xu"], "title": "Uncertain Machine Ethics Planning", "categories": ["cs.AI", "cs.CY"], "comment": null, "summary": "Machine Ethics decisions should consider the implications of uncertainty over\ndecisions. Decisions should be made over sequences of actions to reach\npreferable outcomes long term. The evaluation of outcomes, however, may invoke\none or more moral theories, which might have conflicting judgements. Each\ntheory will require differing representations of the ethical situation. For\nexample, Utilitarianism measures numerical values, Deontology analyses duties,\nand Virtue Ethics emphasises moral character. While balancing potentially\nconflicting moral considerations, decisions may need to be made, for example,\nto achieve morally neutral goals with minimal costs. In this paper, we\nformalise the problem as a Multi-Moral Markov Decision Process and a\nMulti-Moral Stochastic Shortest Path Problem. We develop a heuristic algorithm\nbased on Multi-Objective AO*, utilising Sven-Ove Hansson's Hypothetical\nRetrospection procedure for ethical reasoning under uncertainty. Our approach\nis validated by a case study from Machine Ethics literature: the problem of\nwhether to steal insulin for someone who needs it.", "AI": {"tldr": "The paper formalizes ethical decision-making under uncertainty using Multi-Moral Markov Decision Processes and a heuristic algorithm based on Multi-Objective AO*.", "motivation": "Addressing conflicting moral theories (e.g., Utilitarianism, Deontology, Virtue Ethics) in machine ethics decisions and balancing them for long-term preferable outcomes.", "method": "Develops a Multi-Moral Markov Decision Process and Multi-Moral Stochastic Shortest Path Problem, using a heuristic algorithm with Hypothetical Retrospection for ethical reasoning.", "result": "Validated by a case study on the ethical dilemma of stealing insulin for someone in need.", "conclusion": "The approach provides a framework for handling moral uncertainty and conflicting ethical theories in machine decision-making."}}
{"id": "2505.03790", "pdf": "https://arxiv.org/pdf/2505.03790", "abs": "https://arxiv.org/abs/2505.03790", "authors": ["Yuren Zhang", "Zhongnan Pu", "Lei Jing"], "title": "A Time-Series Data Augmentation Model through Diffusion and Transformer Integration", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages,22 figures", "summary": "With the development of Artificial Intelligence, numerous real-world tasks\nhave been accomplished using technology integrated with deep learning. To\nachieve optimal performance, deep neural networks typically require large\nvolumes of data for training. Although advances in data augmentation have\nfacilitated the acquisition of vast datasets, most of this data is concentrated\nin domains like images and speech. However, there has been relatively less\nfocus on augmenting time-series data. To address this gap and generate a\nsubstantial amount of time-series data, we propose a simple and effective\nmethod that combines the Diffusion and Transformer models. By utilizing an\nadjusted diffusion denoising model to generate a large volume of initial\ntime-step action data, followed by employing a Transformer model to predict\nsubsequent actions, and incorporating a weighted loss function to achieve\nconvergence, the method demonstrates its effectiveness. Using the performance\nimprovement of the model after applying augmented data as a benchmark, and\ncomparing the results with those obtained without data augmentation or using\ntraditional data augmentation methods, this approach shows its capability to\nproduce high-quality augmented data.", "AI": {"tldr": "A method combining Diffusion and Transformer models is proposed to generate high-quality augmented time-series data, addressing the lack of focus in this domain.", "motivation": "Deep learning requires large datasets, but time-series data augmentation is underdeveloped compared to domains like images and speech.", "method": "Uses a diffusion denoising model to generate initial time-step data, a Transformer for predicting subsequent actions, and a weighted loss function for convergence.", "result": "The method produces high-quality augmented data, improving model performance compared to no augmentation or traditional methods.", "conclusion": "The proposed approach effectively addresses the gap in time-series data augmentation, demonstrating its practical utility."}}
{"id": "2505.04006", "pdf": "https://arxiv.org/pdf/2505.04006", "abs": "https://arxiv.org/abs/2505.04006", "authors": ["Inamullah", "Imran Razzak", "Shoaib Jameel"], "title": "The Eye as a Window to Systemic Health: A Survey of Retinal Imaging from Classical Techniques to Oculomics", "categories": ["cs.CV"], "comment": null, "summary": "The unique vascularized anatomy of the human eye, encased in the retina,\nprovides an opportunity to act as a window for human health. The retinal\nstructure assists in assessing the early detection, monitoring of disease\nprogression and intervention for both ocular and non-ocular diseases. The\nadvancement in imaging technology leveraging Artificial Intelligence has seized\nthis opportunity to bridge the gap between the eye and human health. This track\npaves the way for unveiling systemic health insight from the ocular system and\nsurrogating non-invasive markers for timely intervention and identification.\nThe new frontiers of oculomics in ophthalmology cover both ocular and systemic\ndiseases, and getting more attention to explore them. In this survey paper, we\nexplore the evolution of retinal imaging techniques, the dire need for the\nintegration of AI-driven analysis, and the shift of retinal imaging from\nclassical techniques to oculomics. We also discuss some hurdles that may be\nfaced in the progression of oculomics, highlighting the research gaps and\nfuture directions.", "AI": {"tldr": "The paper explores how retinal imaging, enhanced by AI, serves as a non-invasive window for detecting and monitoring both ocular and systemic diseases, while discussing challenges and future directions in oculomics.", "motivation": "The unique vascularized anatomy of the retina offers a non-invasive way to assess human health, driving the need for advanced imaging and AI integration.", "method": "The survey reviews the evolution of retinal imaging techniques, AI-driven analysis, and the transition to oculomics.", "result": "Retinal imaging combined with AI provides systemic health insights and non-invasive markers, advancing early disease detection and intervention.", "conclusion": "Oculomics holds promise but faces hurdles; addressing research gaps and future directions is crucial for its progression."}}
{"id": "2504.17669", "pdf": "https://arxiv.org/pdf/2504.17669", "abs": "https://arxiv.org/abs/2504.17669", "authors": ["Subash Neupane", "Sudip Mittal", "Shahram Rahimi"], "title": "Towards a HIPAA Compliant Agentic AI System in Healthcare", "categories": ["cs.MA", "cs.AI", "cs.ET"], "comment": null, "summary": "Agentic AI systems powered by Large Language Models (LLMs) as their\nfoundational reasoning engine, are transforming clinical workflows such as\nmedical report generation and clinical summarization by autonomously analyzing\nsensitive healthcare data and executing decisions with minimal human oversight.\nHowever, their adoption demands strict compliance with regulatory frameworks\nsuch as Health Insurance Portability and Accountability Act (HIPAA),\nparticularly when handling Protected Health Information (PHI). This\nwork-in-progress paper introduces a HIPAA-compliant Agentic AI framework that\nenforces regulatory compliance through dynamic, context-aware policy\nenforcement. Our framework integrates three core mechanisms: (1)\nAttribute-Based Access Control (ABAC) for granular PHI governance, (2) a hybrid\nPHI sanitization pipeline combining regex patterns and BERT-based model to\nminimize leakage, and (3) immutable audit trails for compliance verification.", "AI": {"tldr": "A HIPAA-compliant Agentic AI framework for clinical workflows ensures regulatory compliance via dynamic policy enforcement, PHI governance, sanitization, and audit trails.", "motivation": "To address the need for regulatory compliance (e.g., HIPAA) in AI-driven clinical workflows handling sensitive healthcare data.", "method": "Integrates ABAC for PHI governance, a hybrid PHI sanitization pipeline (regex + BERT), and immutable audit trails.", "result": "A framework that enforces compliance while autonomously handling sensitive healthcare data.", "conclusion": "The proposed framework enables safe adoption of Agentic AI in clinical settings by ensuring HIPAA compliance."}}
{"id": "2505.04524", "pdf": "https://arxiv.org/pdf/2505.04524", "abs": "https://arxiv.org/abs/2505.04524", "authors": ["Asma Baobaid", "Mahmoud Meribout"], "title": "Edge-GPU Based Face Tracking for Face Detection and Recognition Acceleration", "categories": ["cs.CV", "cs.AR", "cs.LG", "eess.IV"], "comment": "10 pages, 12 figures", "summary": "Cost-effective machine vision systems dedicated to real-time and accurate\nface detection and recognition in public places are crucial for many modern\napplications. However, despite their high performance, which could be reached\nusing specialized edge or cloud AI hardware accelerators, there is still room\nfor improvement in throughput and power consumption. This paper aims to suggest\na combined hardware-software approach that optimizes face detection and\nrecognition systems on one of the latest edge GPUs, namely NVIDIA Jetson AGX\nOrin. First, it leverages the simultaneous usage of all its hardware engines to\nimprove processing time. This offers an improvement over previous works where\nthese tasks were mainly allocated automatically and exclusively to the CPU or,\nto a higher extent, to the GPU core. Additionally, the paper suggests\nintegrating a face tracker module to avoid redundantly running the face\nrecognition algorithm for every frame but only when a new face appears in the\nscene. The results of extended experiments suggest that simultaneous usage of\nall the hardware engines that are available in the Orin GPU and tracker\nintegration into the pipeline yield an impressive throughput of 290 FPS (frames\nper second) on 1920 x 1080 input size frames containing in average of 6\nfaces/frame. Additionally, a substantial saving of power consumption of around\n800 mW was achieved when compared to running the task on the CPU/GPU engines\nonly and without integrating a tracker into the Orin GPU\\'92s pipeline. This\nhardware-codesign approach can pave the way to design high-performance machine\nvision systems at the edge, critically needed in video monitoring in public\nplaces where several nearby cameras are usually deployed for a same scene.", "AI": {"tldr": "The paper proposes a hardware-software approach to optimize face detection and recognition on NVIDIA Jetson AGX Orin, achieving 290 FPS and reducing power consumption by 800 mW.", "motivation": "Improving throughput and power consumption in face detection and recognition systems for public places, despite existing high-performance solutions.", "method": "Combines simultaneous usage of all hardware engines in the Orin GPU and integrates a face tracker to avoid redundant recognition.", "result": "Achieves 290 FPS on 1920x1080 frames with ~6 faces/frame and reduces power consumption by 800 mW.", "conclusion": "The approach enables high-performance edge machine vision systems, ideal for multi-camera public monitoring."}}
{"id": "2505.04406", "pdf": "https://arxiv.org/pdf/2505.04406", "abs": "https://arxiv.org/abs/2505.04406", "authors": ["Aidar Valeev", "Roman Garaev", "Vadim Lomshakov", "Irina Piontkovskaya", "Vladimir Ivanov", "Israel Adewuyi"], "title": "YABLoCo: Yet Another Benchmark for Long Context Code Generation", "categories": ["cs.CL", "cs.AI", "cs.SE"], "comment": "Presented at LLM4Code 2025 Workshop co-located wtih ICSE 2025", "summary": "Large Language Models demonstrate the ability to solve various programming\ntasks, including code generation. Typically, the performance of LLMs is\nmeasured on benchmarks with small or medium-sized context windows of thousands\nof lines of code. At the same time, in real-world software projects,\nrepositories can span up to millions of LoC. This paper closes this gap by\ncontributing to the long context code generation benchmark (YABLoCo). The\nbenchmark featured a test set of 215 functions selected from four large\nrepositories with thousands of functions. The dataset contained metadata of\nfunctions, contexts of the functions with different levels of dependencies,\ndocstrings, functions bodies, and call graphs for each repository. This paper\npresents three key aspects of the contribution. First, the benchmark aims at\nfunction body generation in large repositories in C and C++, two languages not\ncovered by previous benchmarks. Second, the benchmark contains large\nrepositories from 200K to 2,000K LoC. Third, we contribute a scalable\nevaluation pipeline for efficient computing of the target metrics and a tool\nfor visual analysis of generated code. Overall, these three aspects allow for\nevaluating code generation in large repositories in C and C++.", "AI": {"tldr": "The paper introduces YABLoCo, a benchmark for evaluating LLMs on large-context code generation in C/C++ repositories with up to 2M LoC.", "motivation": "Existing benchmarks focus on small/medium code contexts, while real-world projects involve much larger repositories.", "method": "The benchmark includes 215 functions from large repositories, with metadata, dependencies, docstrings, and call graphs.", "result": "YABLoCo evaluates function body generation in C/C++ and provides a scalable pipeline and visualization tool.", "conclusion": "The benchmark addresses the gap in evaluating LLMs for large-scale code generation in real-world projects."}}
{"id": "2505.04480", "pdf": "https://arxiv.org/pdf/2505.04480", "abs": "https://arxiv.org/abs/2505.04480", "authors": ["Zhikai Zhao", "Chuanbo Hua", "Federico Berto", "Kanghoon Lee", "Zihan Ma", "Jiachen Li", "Jinkyoo Park"], "title": "TrajEvo: Designing Trajectory Prediction Heuristics via LLM-driven Evolution", "categories": ["cs.AI", "cs.NE", "cs.RO"], "comment": null, "summary": "Trajectory prediction is a crucial task in modeling human behavior,\nespecially in fields as social robotics and autonomous vehicle navigation.\nTraditional heuristics based on handcrafted rules often lack accuracy, while\nrecently proposed deep learning approaches suffer from computational cost, lack\nof explainability, and generalization issues that limit their practical\nadoption. In this paper, we introduce TrajEvo, a framework that leverages Large\nLanguage Models (LLMs) to automatically design trajectory prediction\nheuristics. TrajEvo employs an evolutionary algorithm to generate and refine\nprediction heuristics from past trajectory data. We introduce a\nCross-Generation Elite Sampling to promote population diversity and a\nStatistics Feedback Loop allowing the LLM to analyze alternative predictions.\nOur evaluations show TrajEvo outperforms previous heuristic methods on the\nETH-UCY datasets, and remarkably outperforms both heuristics and deep learning\nmethods when generalizing to the unseen SDD dataset. TrajEvo represents a first\nstep toward automated design of fast, explainable, and generalizable trajectory\nprediction heuristics. We make our source code publicly available to foster\nfuture research at https://github.com/ai4co/trajevo.", "AI": {"tldr": "TrajEvo is a framework using LLMs and evolutionary algorithms to automate trajectory prediction heuristics, outperforming traditional and deep learning methods in accuracy and generalization.", "motivation": "Traditional heuristics lack accuracy, while deep learning methods are computationally expensive and lack explainability, limiting practical adoption.", "method": "TrajEvo uses an evolutionary algorithm with Cross-Generation Elite Sampling and a Statistics Feedback Loop to refine heuristics from trajectory data.", "result": "TrajEvo outperforms heuristic and deep learning methods on ETH-UCY and generalizes better to the unseen SDD dataset.", "conclusion": "TrajEvo advances automated design of fast, explainable, and generalizable trajectory prediction heuristics, with open-source code for future research."}}
{"id": "2505.03791", "pdf": "https://arxiv.org/pdf/2505.03791", "abs": "https://arxiv.org/abs/2505.03791", "authors": ["Simon Golbert"], "title": "Practical Boolean Backpropagation", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages", "summary": "Boolean neural networks offer hardware-efficient alternatives to real-valued\nmodels. While quantization is common, purely Boolean training remains\nunderexplored. We present a practical method for purely Boolean backpropagation\nfor networks based on a single specific gate we chose, operating directly in\nBoolean algebra involving no numerics. Initial experiments confirm its\nfeasibility.", "AI": {"tldr": "A method for purely Boolean backpropagation in neural networks, avoiding numerics, is introduced and tested.", "motivation": "Boolean neural networks are hardware-efficient but lack exploration in purely Boolean training methods.", "method": "Proposes a purely Boolean backpropagation method using a specific gate, operating in Boolean algebra without numerics.", "result": "Initial experiments confirm the feasibility of the method.", "conclusion": "The method shows promise for practical Boolean neural network training."}}
{"id": "2505.04055", "pdf": "https://arxiv.org/pdf/2505.04055", "abs": "https://arxiv.org/abs/2505.04055", "authors": ["Ervin Wang", "Yuhao Chen"], "title": "FoodTrack: Estimating Handheld Food Portions with Egocentric Video", "categories": ["cs.CV"], "comment": "Accepted as extended abstract at CVPR 2025 Metafood workshop", "summary": "Accurately tracking food consumption is crucial for nutrition and health\nmonitoring. Traditional approaches typically require specific camera angles,\nnon-occluded images, or rely on gesture recognition to estimate intake, making\nassumptions about bite size rather than directly measuring food volume. We\npropose the FoodTrack framework for tracking and measuring the volume of\nhand-held food items using egocentric video which is robust to hand occlusions\nand flexible with varying camera and object poses. FoodTrack estimates food\nvolume directly, without relying on intake gestures or fixed assumptions about\nbite size, offering a more accurate and adaptable solution for tracking food\nconsumption. We achieve absolute percentage loss of approximately 7.01% on a\nhandheld food object, improving upon a previous approach that achieved a 16.40%\nmean absolute percentage error in its best case, under less flexible\nconditions.", "AI": {"tldr": "FoodTrack framework improves food volume tracking using egocentric video, achieving 7.01% error, outperforming prior methods.", "motivation": "Accurate food tracking is vital for health monitoring, but traditional methods rely on restrictive conditions like specific camera angles or gesture recognition.", "method": "FoodTrack uses egocentric video to measure food volume directly, handling occlusions and varying poses without relying on bite size assumptions.", "result": "Achieves 7.01% absolute percentage loss, better than a previous 16.40% error under less flexible conditions.", "conclusion": "FoodTrack offers a more accurate and adaptable solution for tracking food consumption."}}
{"id": "2410.03072", "pdf": "https://arxiv.org/pdf/2410.03072", "abs": "https://arxiv.org/abs/2410.03072", "authors": ["Yorai Shaoul", "Itamar Mishani", "Shivam Vats", "Jiaoyang Li", "Maxim Likhachev"], "title": "Multi-Robot Motion Planning with Diffusion Models", "categories": ["cs.RO", "cs.AI", "cs.MA"], "comment": "The first three authors contributed equally to this work. Published\n  at ICLR 2025", "summary": "Diffusion models have recently been successfully applied to a wide range of\nrobotics applications for learning complex multi-modal behaviors from data.\nHowever, prior works have mostly been confined to single-robot and small-scale\nenvironments due to the high sample complexity of learning multi-robot\ndiffusion models. In this paper, we propose a method for generating\ncollision-free multi-robot trajectories that conform to underlying data\ndistributions while using only single-robot data. Our algorithm, Multi-robot\nMulti-model planning Diffusion (MMD), does so by combining learned diffusion\nmodels with classical search-based techniques -- generating data-driven motions\nunder collision constraints. Scaling further, we show how to compose multiple\ndiffusion models to plan in large environments where a single diffusion model\nfails to generalize well. We demonstrate the effectiveness of our approach in\nplanning for dozens of robots in a variety of simulated scenarios motivated by\nlogistics environments. View video demonstrations and code at:\nhttps://multi-robot-diffusion.github.io/.", "AI": {"tldr": "A method called MMD combines diffusion models with search-based techniques to generate collision-free multi-robot trajectories using only single-robot data, scaling to large environments.", "motivation": "Prior diffusion models for robotics were limited to single-robot and small-scale environments due to high sample complexity.", "method": "MMD integrates learned diffusion models with classical search-based planning to ensure collision-free, data-driven multi-robot trajectories.", "result": "The approach successfully plans for dozens of robots in simulated logistics scenarios.", "conclusion": "MMD effectively scales multi-robot planning by leveraging single-robot data and classical techniques."}}
{"id": "2410.22530", "pdf": "https://arxiv.org/pdf/2410.22530", "abs": "https://arxiv.org/abs/2410.22530", "authors": ["Hongyi Pan", "Gorkem Durak", "Zheyuan Zhang", "Yavuz Taktak", "Elif Keles", "Halil Ertugrul Aktas", "Alpay Medetalibeyoglu", "Yury Velichko", "Concetto Spampinato", "Ivo Schoots", "Marco J. Bruno", "Rajesh N. Keswani", "Pallavi Tiwari", "Candice Bolan", "Tamas Gonda", "Michael G. Goggins", "Michael B. Wallace", "Ziyue Xu", "Ulas Bagci"], "title": "Adaptive Aggregation Weights for Federated Segmentation of Pancreas MRI", "categories": ["eess.IV", "cs.CV", "cs.DC"], "comment": "This paper has been accepted to ISBI 2025", "summary": "Federated learning (FL) enables collaborative model training across\ninstitutions without sharing sensitive data, making it an attractive solution\nfor medical imaging tasks. However, traditional FL methods, such as Federated\nAveraging (FedAvg), face difficulties in generalizing across domains due to\nvariations in imaging protocols and patient demographics across institutions.\nThis challenge is particularly evident in pancreas MRI segmentation, where\nanatomical variability and imaging artifacts significantly impact performance.\nIn this paper, we conduct a comprehensive evaluation of FL algorithms for\npancreas MRI segmentation and introduce a novel approach that incorporates\nadaptive aggregation weights. By dynamically adjusting the contribution of each\nclient during model aggregation, our method accounts for domain-specific\ndifferences and improves generalization across heterogeneous datasets.\nExperimental results demonstrate that our approach enhances segmentation\naccuracy and reduces the impact of domain shift compared to conventional FL\nmethods while maintaining privacy-preserving capabilities. Significant\nperformance improvements are observed across multiple hospitals (centers).", "AI": {"tldr": "A novel FL method with adaptive aggregation weights improves pancreas MRI segmentation accuracy across diverse datasets while preserving privacy.", "motivation": "Traditional FL methods like FedAvg struggle with domain generalization due to variations in imaging protocols and demographics, especially in pancreas MRI segmentation.", "method": "Introduces adaptive aggregation weights to dynamically adjust client contributions during model aggregation, addressing domain-specific differences.", "result": "The approach enhances segmentation accuracy, reduces domain shift impact, and shows significant improvements across multiple hospitals.", "conclusion": "The proposed method outperforms conventional FL techniques in handling heterogeneity while maintaining privacy."}}
{"id": "2505.04416", "pdf": "https://arxiv.org/pdf/2505.04416", "abs": "https://arxiv.org/abs/2505.04416", "authors": ["Xiaoyu Xu", "Minxin Du", "Qingqing Ye", "Haibo Hu"], "title": "OBLIVIATE: Robust and Practical Machine Unlearning for Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "comment": "18 pages, 2 figures", "summary": "Large language models (LLMs) trained over extensive corpora risk memorizing\nsensitive, copyrighted, or toxic content. To address this, we propose\nOBLIVIATE, a robust unlearning framework that removes targeted data while\npreserving model utility. The framework follows a structured process:\nextracting target tokens, building retain sets, and fine-tuning with a tailored\nloss function comprising three components -- masking, distillation, and world\nfact. Using low-rank adapters (LoRA), it ensures efficiency without\ncompromising unlearning quality. We conduct experiments on multiple datasets,\nincluding the Harry Potter series, WMDP, and TOFU, using a comprehensive suite\nof metrics: forget quality (new document-level memorization score), model\nutility, and fluency. Results demonstrate its effectiveness in resisting\nmembership inference attacks, minimizing the impact on retained data, and\nmaintaining robustness across diverse scenarios.", "AI": {"tldr": "OBLIVIATE is a framework for unlearning sensitive data in LLMs, preserving utility via token extraction, retain sets, and a tailored loss function with LoRA for efficiency.", "motivation": "To mitigate risks of memorizing sensitive, copyrighted, or toxic content in LLMs.", "method": "Extracts target tokens, builds retain sets, and fine-tunes with a loss function (masking, distillation, world fact) using LoRA.", "result": "Effective in resisting membership inference attacks, minimizing impact on retained data, and maintaining robustness.", "conclusion": "OBLIVIATE successfully unlearns targeted data while preserving model utility and efficiency."}}
{"id": "2505.04525", "pdf": "https://arxiv.org/pdf/2505.04525", "abs": "https://arxiv.org/abs/2505.04525", "authors": ["Quentin Cohen-Solal", "Tristan Cazenave"], "title": "On some improvements to Unbounded Minimax", "categories": ["cs.AI"], "comment": null, "summary": "This paper presents the first experimental evaluation of four previously\nuntested modifications of Unbounded Best-First Minimax algorithm. This\nalgorithm explores the game tree by iteratively expanding the most promising\nsequences of actions based on the current partial game tree. We first evaluate\nthe use of transposition tables, which convert the game tree into a directed\nacyclic graph by merging duplicate states. Second, we compare the original\nalgorithm by Korf & Chickering with the variant proposed by Cohen-Solal, which\ndiffers in its backpropagation strategy: instead of stopping when a stable\nvalue is encountered, it updates values up to the root. This change slightly\nimproves performance when value ties or transposition tables are involved.\nThird, we assess replacing the exact terminal evaluation function with the\nlearned heuristic function. While beneficial when exact evaluations are costly,\nthis modification reduces performance in inexpensive settings. Finally, we\nexamine the impact of the completion technique that prioritizes resolved\nwinning states and avoids resolved losing states. This technique also improves\nperformance. Overall, our findings highlight how targeted modifications can\nenhance the efficiency of Unbounded Best-First Minimax.", "AI": {"tldr": "Experimental evaluation of four modifications to Unbounded Best-First Minimax shows performance improvements in certain scenarios.", "motivation": "To assess the impact of untested modifications on the Unbounded Best-First Minimax algorithm's efficiency.", "method": "Tested four modifications: transposition tables, backpropagation strategy, heuristic function replacement, and completion technique.", "result": "Transposition tables and completion techniques improved performance; heuristic replacement was beneficial only in costly settings.", "conclusion": "Targeted modifications can enhance the algorithm's efficiency, though their effectiveness depends on context."}}
{"id": "2505.03792", "pdf": "https://arxiv.org/pdf/2505.03792", "abs": "https://arxiv.org/abs/2505.03792", "authors": ["Lang Feng", "Weihao Tan", "Zhiyi Lyu", "Longtao Zheng", "Haiyang Xu", "Ming Yan", "Fei Huang", "Bo An"], "title": "Towards Efficient Online Tuning of VLM Agents via Counterfactual Soft Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025", "summary": "Online fine-tuning vision-language model (VLM) agents with reinforcement\nlearning (RL) has shown promise for equipping agents with multi-step,\ngoal-oriented capabilities in dynamic environments. However, their open-ended\ntextual action space and non-end-to-end nature of action generation present\nsignificant challenges to effective online exploration in RL, e.g., explosion\nof the exploration space. We propose a novel online fine-tuning method,\nCounterfactual Soft Reinforcement Learning (CoSo), better suited to the textual\noutput space of VLM agents. Compared to prior methods that assign uniform\nuncertainty to all tokens, CoSo leverages counterfactual reasoning to\ndynamically assess the causal influence of individual tokens on post-processed\nactions. By prioritizing the exploration of action-critical tokens while\nreducing the impact of semantically redundant or low-impact tokens, CoSo\nenables a more targeted and efficient online rollout process. We provide\ntheoretical analysis proving CoSo's convergence and policy improvement\nguarantees, and extensive empirical evaluations supporting CoSo's\neffectiveness. Our results across a diverse set of agent tasks, including\nAndroid device control, card gaming, and embodied AI, highlight its remarkable\nability to enhance exploration efficiency and deliver consistent performance\ngains. The code is available at https://github.com/langfengQ/CoSo.", "AI": {"tldr": "CoSo, a novel online fine-tuning method for VLM agents, improves RL exploration efficiency by dynamically assessing token influence using counterfactual reasoning.", "motivation": "Address challenges in online RL for VLM agents, such as open-ended textual action spaces and inefficient exploration.", "method": "Proposes Counterfactual Soft Reinforcement Learning (CoSo), which prioritizes exploration of action-critical tokens while minimizing redundant ones.", "result": "Theoretical and empirical results show CoSo enhances exploration efficiency and performance across diverse tasks.", "conclusion": "CoSo is effective for fine-tuning VLM agents, offering improved exploration and performance in dynamic environments."}}
{"id": "2505.04058", "pdf": "https://arxiv.org/pdf/2505.04058", "abs": "https://arxiv.org/abs/2505.04058", "authors": ["Feng Xiao", "Hongbin Xu", "Guocan Zhao", "Wenxiong Kang"], "title": "AS3D: 2D-Assisted Cross-Modal Understanding with Semantic-Spatial Scene Graphs for 3D Visual Grounding", "categories": ["cs.CV"], "comment": null, "summary": "3D visual grounding aims to localize the unique target described by natural\nlanguages in 3D scenes. The significant gap between 3D and language modalities\nmakes it a notable challenge to distinguish multiple similar objects through\nthe described spatial relationships. Current methods attempt to achieve\ncross-modal understanding in complex scenes via a target-centered learning\nmechanism, ignoring the perception of referred objects. We propose a novel\n2D-assisted 3D visual grounding framework that constructs semantic-spatial\nscene graphs with referred object discrimination for relationship perception.\nThe framework incorporates a dual-branch visual encoder that utilizes 2D\npre-trained attributes to guide the multi-modal object encoding. Furthermore,\nour cross-modal interaction module uses graph attention to facilitate\nrelationship-oriented information fusion. The enhanced object representation\nand iterative relational learning enable the model to establish effective\nalignment between 3D vision and referential descriptions. Experimental results\non the popular benchmarks demonstrate our superior performance compared to\nstate-of-the-art methods, especially in addressing the challenges of multiple\nsimilar distractors.", "AI": {"tldr": "A novel 2D-assisted 3D visual grounding framework improves object discrimination and relationship perception, outperforming state-of-the-art methods.", "motivation": "The challenge of distinguishing similar objects in 3D scenes using natural language due to the modality gap.", "method": "Uses a dual-branch visual encoder with 2D pre-trained attributes and a cross-modal interaction module with graph attention for relationship fusion.", "result": "Superior performance on benchmarks, especially in handling multiple similar distractors.", "conclusion": "The framework effectively aligns 3D vision and language, enhancing object representation and relational learning."}}
{"id": "2502.03501", "pdf": "https://arxiv.org/pdf/2502.03501", "abs": "https://arxiv.org/abs/2502.03501", "authors": ["Wang Xinyi", "Kang Hongyu", "Wei Peishan", "Shuai Li", "Yu Sun", "Sai Kit Lam", "Yongping Zheng"], "title": "Proxy Prompt: Endowing SAM and SAM 2 with Auto-Interactive-Prompt for Medical Segmentation", "categories": ["eess.IV", "cs.LG"], "comment": null, "summary": "In this paper, we aim to address the unmet demand for automated prompting and\nenhanced human-model interactions of SAM and SAM2 for the sake of promoting\ntheir widespread clinical adoption. Specifically, we propose Proxy Prompt (PP),\nauto-generated by leveraging non-target data with a pre-annotated mask. We\ndevise a novel 3-step context-selection strategy for adaptively selecting the\nmost representative contextual information from non-target data via vision\nmamba and selective maps, empowering the guiding capability of non-target\nimage-mask pairs for segmentation on target image/video data. To reinforce\nhuman-model interactions in PP, we further propose a contextual colorization\nmodule via a dual-reverse cross-attention to enhance interactions between\ntarget features and contextual-embedding with amplifying distinctive features\nof user-defined object(s). Via extensive evaluations, our method achieves\nstate-of-the-art performance on four public datasets and yields comparable\nresults with fully-trained models, even when trained with only 16 image masks.", "AI": {"tldr": "The paper introduces Proxy Prompt (PP) for automated prompting and improved human-model interactions in SAM/SAM2, achieving state-of-the-art results with minimal training data.", "motivation": "To address the lack of automated prompting and enhance human-model interactions for SAM/SAM2, promoting their clinical adoption.", "method": "Proposes PP, auto-generated using non-target data with pre-annotated masks, and a 3-step context-selection strategy. Includes a contextual colorization module for enhanced interactions.", "result": "Achieves state-of-the-art performance on four datasets, comparable to fully-trained models, even with only 16 image masks.", "conclusion": "PP effectively improves segmentation and human-model interactions, demonstrating strong performance with minimal training data."}}
{"id": "2505.04507", "pdf": "https://arxiv.org/pdf/2505.04507", "abs": "https://arxiv.org/abs/2505.04507", "authors": ["Ilya Koziev"], "title": "Detecting Spelling and Grammatical Anomalies in Russian Poetry Texts", "categories": ["cs.CL"], "comment": null, "summary": "The quality of natural language texts in fine-tuning datasets plays a\ncritical role in the performance of generative models, particularly in\ncomputational creativity tasks such as poem or song lyric generation. Fluency\ndefects in generated poems significantly reduce their value. However, training\ntexts are often sourced from internet-based platforms without stringent quality\ncontrol, posing a challenge for data engineers to manage defect levels\neffectively.\n  To address this issue, we propose the use of automated linguistic anomaly\ndetection to identify and filter out low-quality texts from training datasets\nfor creative models. In this paper, we present a comprehensive comparison of\nunsupervised and supervised text anomaly detection approaches, utilizing both\nsynthetic and human-labeled datasets. We also introduce the RUPOR dataset, a\ncollection of Russian-language human-labeled poems designed for cross-sentence\ngrammatical error detection, and provide the full evaluation code. Our work\naims to empower the community with tools and insights to improve the quality of\ntraining datasets for generative models in creative domains.", "AI": {"tldr": "The paper proposes automated linguistic anomaly detection to improve training dataset quality for generative models in creative tasks like poetry, comparing unsupervised and supervised methods and introducing the RUPOR dataset.", "motivation": "Fluency defects in generated poems reduce their value, and training texts often lack quality control, necessitating better methods to manage dataset quality.", "method": "The study compares unsupervised and supervised text anomaly detection approaches using synthetic and human-labeled datasets, including the newly introduced RUPOR dataset for Russian poems.", "result": "The paper provides tools and insights, such as the RUPOR dataset and evaluation code, to enhance training dataset quality for creative generative models.", "conclusion": "Automated linguistic anomaly detection can effectively improve dataset quality, benefiting generative models in creative domains."}}
{"id": "2505.04528", "pdf": "https://arxiv.org/pdf/2505.04528", "abs": "https://arxiv.org/abs/2505.04528", "authors": ["Qi Liu", "Xinhao Zheng", "Renqiu Xia", "Xingzhi Qi", "Qinxiang Cao", "Junchi Yan"], "title": "Beyond Theorem Proving: Formulation, Framework and Benchmark for Formal Problem-Solving", "categories": ["cs.AI", "cs.CL", "cs.LO"], "comment": "42 pages, 3 figures", "summary": "As a seemingly self-explanatory task, problem-solving has been a significant\ncomponent of science and engineering. However, a general yet concrete\nformulation of problem-solving itself is missing. With the recent development\nof AI-based problem-solving agents, the demand for process-level verifiability\nis rapidly increasing yet underexplored. To fill these gaps, we present a\nprincipled formulation of problem-solving as a deterministic Markov decision\nprocess; a novel framework, FPS (Formal Problem-Solving), which utilizes\nexisting FTP (formal theorem proving) environments to perform process-verified\nproblem-solving; and D-FPS (Deductive FPS), decoupling solving and answer\nverification for better human-alignment. The expressiveness, soundness and\ncompleteness of the frameworks are proven. We construct three benchmarks on\nproblem-solving: FormalMath500, a formalization of a subset of the MATH500\nbenchmark; MiniF2F-Solving and PutnamBench-Solving, adaptations of FTP\nbenchmarks MiniF2F and PutnamBench. For faithful, interpretable, and\nhuman-aligned evaluation, we propose RPE (Restricted Propositional\nEquivalence), a symbolic approach to determine the correctness of answers by\nformal verification. We evaluate four prevalent FTP models and two prompting\nmethods as baselines, solving at most 23.77% of FormalMath500, 27.47% of\nMiniF2F-Solving, and 0.31% of PutnamBench-Solving.", "AI": {"tldr": "The paper introduces FPS and D-FPS frameworks for formal, process-verified problem-solving, evaluates them on benchmarks, and proposes RPE for answer correctness.", "motivation": "To address the lack of a general formulation of problem-solving and the need for process-level verifiability in AI-based agents.", "method": "Proposes FPS as a deterministic Markov decision process and D-FPS for decoupled solving and verification. Uses FTP environments and benchmarks like FormalMath500.", "result": "Evaluated models solved up to 23.77% of FormalMath500, 27.47% of MiniF2F-Solving, and 0.31% of PutnamBench-Solving.", "conclusion": "The frameworks are expressive, sound, and complete, offering a principled approach to verified problem-solving."}}
{"id": "2505.03793", "pdf": "https://arxiv.org/pdf/2505.03793", "abs": "https://arxiv.org/abs/2505.03793", "authors": ["Xinyue Zeng", "Haohui Wang", "Junhong Lin", "Jun Wu", "Tyler Cody", "Dawei Zhou"], "title": "LENSLLM: Unveiling Fine-Tuning Dynamics for LLM Selection", "categories": ["cs.LG", "cs.AI"], "comment": "It is accepted by ICML'2025, and the code is open-sourcing on\n  https://github.com/Susan571/LENSLLM.git", "summary": "The proliferation of open-sourced Large Language Models (LLMs) and diverse\ndownstream tasks necessitates efficient model selection, given the\nimpracticality of fine-tuning all candidates due to computational constraints.\nDespite the recent advances in LLM selection, a fundamental research question\nlargely remains nascent: how can we model the dynamic behaviors of LLMs during\nfine-tuning, thereby enhancing our understanding of their generalization\nperformance across diverse downstream tasks? In this work, we propose a novel\ntheoretical framework that provides a proper lens to assess the generalization\ncapabilities of LLMs, thereby enabling accurate and efficient LLM selection for\ndownstream applications. In particular, we first derive a Hessian-based\nPAC-Bayes generalization bound that unveils fine-tuning dynamics of LLMs and\nthen introduce LENSLLM, a Neural Tangent Kernel(NTK)-based Rectified Scaling\nModel that enables accurate performance predictions across diverse tasks while\nmaintaining computational efficiency. Extensive empirical results on 3\nlarge-scale benchmarks demonstrate that our model achieves up to 91.1% accuracy\nand reduces up to 88.5% computational cost in LLM selection, outperforming 5\nstate-of-the-art methods. We open-source our proposed LENSLLM model and\ncorresponding results at the Github link:\nhttps://github.com/Susan571/LENSLLM.git.", "AI": {"tldr": "A novel theoretical framework, LENSLLM, is proposed to model LLM fine-tuning dynamics for efficient and accurate model selection, achieving high accuracy and computational savings.", "motivation": "The need for efficient LLM selection due to computational constraints and the lack of understanding of LLM fine-tuning dynamics.", "method": "Derived a Hessian-based PAC-Bayes generalization bound and introduced LENSLLM, an NTK-based Rectified Scaling Model.", "result": "Achieved up to 91.1% accuracy and reduced computational cost by 88.5%, outperforming 5 state-of-the-art methods.", "conclusion": "LENSLLM provides an effective solution for LLM selection, with open-sourced implementation available."}}
{"id": "2505.04087", "pdf": "https://arxiv.org/pdf/2505.04087", "abs": "https://arxiv.org/abs/2505.04087", "authors": ["Zixuan Hu", "Yichun Hu", "Ling-Yu Duan"], "title": "SEVA: Leveraging Single-Step Ensemble of Vicinal Augmentations for Test-Time Adaptation", "categories": ["cs.CV"], "comment": null, "summary": "Test-Time adaptation (TTA) aims to enhance model robustness against\ndistribution shifts through rapid model adaptation during inference. While\nexisting TTA methods often rely on entropy-based unsupervised training and\nachieve promising results, the common practice of a single round of entropy\ntraining is typically unable to adequately utilize reliable samples, hindering\nadaptation efficiency. In this paper, we discover augmentation strategies can\neffectively unleash the potential of reliable samples, but the rapidly growing\ncomputational cost impedes their real-time application. To address this\nlimitation, we propose a novel TTA approach named Single-step Ensemble of\nVicinal Augmentations (SEVA), which can take advantage of data augmentations\nwithout increasing the computational burden. Specifically, instead of\nexplicitly utilizing the augmentation strategy to generate new data, SEVA\ndevelops a theoretical framework to explore the impacts of multiple\naugmentations on model adaptation and proposes to optimize an upper bound of\nthe entropy loss to integrate the effects of multiple rounds of augmentation\ntraining into a single step. Furthermore, we discover and verify that using the\nupper bound as the loss is more conducive to the selection mechanism, as it can\neffectively filter out harmful samples that confuse the model. Combining these\ntwo key advantages, the proposed efficient loss and a complementary selection\nstrategy can simultaneously boost the potential of reliable samples and meet\nthe stringent time requirements of TTA. The comprehensive experiments on\nvarious network architectures across challenging testing scenarios demonstrate\nimpressive performances and the broad adaptability of SEVA. The code will be\npublicly available.", "AI": {"tldr": "SEVA is a novel TTA method that efficiently leverages data augmentations without extra computational cost, improving adaptation by optimizing an entropy loss upper bound and filtering harmful samples.", "motivation": "Existing TTA methods underutilize reliable samples due to single-round entropy training, and augmentation strategies, while effective, are computationally expensive.", "method": "SEVA introduces a theoretical framework to explore augmentation impacts, optimizing an upper bound of entropy loss in a single step and filtering harmful samples.", "result": "SEVA demonstrates superior performance across various architectures and testing scenarios, meeting real-time TTA requirements.", "conclusion": "SEVA effectively balances efficiency and performance, making it a practical solution for TTA challenges."}}
{"id": "2504.12527", "pdf": "https://arxiv.org/pdf/2504.12527", "abs": "https://arxiv.org/abs/2504.12527", "authors": ["Nazanin Maleki", "Raisa Amiruddin", "Ahmed W. Moawad", "Nikolay Yordanov", "Athanasios Gkampenis", "Pascal Fehringer", "Fabian Umeh", "Crystal Chukwurah", "Fatima Memon", "Bojan Petrovic", "Justin Cramer", "Mark Krycia", "Elizabeth B. Shrickel", "Ichiro Ikuta", "Gerard Thompson", "Lorenna Vidal", "Vilma Kosovic", "Adam E. Goldman-Yassen", "Virginia Hill", "Tiffany So", "Sedra Mhana", "Albara Alotaibi", "Nathan Page", "Prisha Bhatia", "Yasaman Sharifi", "Marko Jakovljevic", "Salma Abosabie", "Sara Abosabie", "Mohanad Ghonim", "Mohamed Ghonim", "Amirreza Manteghinejad", "Anastasia Janas", "Kiril Krantchev", "Maruf Adewole", "Jake Albrecht", "Udunna Anazodo", "Sanjay Aneja", "Syed Muhammad Anwar", "Timothy Bergquist", "Veronica Chiang", "Verena Chung", "Gian Marco Conte", "Farouk Dako", "James Eddy", "Ivan Ezhov", "Nastaran Khalili", "Keyvan Farahani", "Juan Eugenio Iglesias", "Zhifan Jiang", "Elaine Johanson", "Anahita Fathi Kazerooni", "Florian Kofler", "Dominic LaBella", "Koen Van Leemput", "Hongwei Bran Li", "Marius George Linguraru", "Xinyang Liu", "Zeke Meier", "Bjoern H Menze", "Harrison Moy", "Klara Osenberg", "Marie Piraud", "Zachary Reitman", "Russell Takeshi Shinohara", "Chunhao Wang", "Benedikt Wiestler", "Walter Wiggins", "Umber Shafique", "Klara Willms", "Arman Avesta", "Khaled Bousabarah", "Satrajit Chakrabarty", "Nicolo Gennaro", "Wolfgang Holler", "Manpreet Kaur", "Pamela LaMontagne", "MingDe Lin", "Jan Lost", "Daniel S. Marcus", "Ryan Maresca", "Sarah Merkaj", "Gabriel Cassinelli Pedersen", "Marc von Reppert", "Aristeidis Sotiras", "Oleg Teytelboym", "Niklas Tillmans", "Malte Westerhoff", "Ayda Youssef", "Devon Godfrey", "Scott Floyd", "Andreas Rauschecker", "Javier Villanueva-Meyer", "Irada Pfl\u00fcger", "Jaeyoung Cho", "Martin Bendszus", "Gianluca Brugnara", "Gloria J. Guzman Perez-Carillo", "Derek R. Johnson", "Anthony Kam", "Benjamin Yin Ming Kwan", "Lillian Lai", "Neil U. Lall", "Satya Narayana Patro", "Lei Wu", "Anu Bansal", "Frederik Barkhof", "Cristina Besada", "Sammy Chu", "Jason Druzgal", "Alexandru Dusoi", "Luciano Farage", "Fabricio Feltrin", "Amy Fong", "Steve H. Fung", "R. Ian Gray", "Michael Iv", "Alida A. Postma", "Amit Mahajan", "David Joyner", "Chase Krumpelman", "Laurent Letourneau-Guillon", "Christie M. Lincoln", "Mate E. Maros", "Elka Miller", "Fanny Mor\u00f3n", "Esther A. Nimchinsky", "Ozkan Ozsarlak", "Uresh Patel", "Saurabh Rohatgi", "Atin Saha", "Anousheh Sayah", "Eric D. Schwartz", "Robert Shih", "Mark S. Shiroishi", "Juan E. Small", "Manoj Tanwar", "Jewels Valerie", "Brent D. Weinberg", "Matthew L. White", "Robert Young", "Vahe M. Zohrabian", "Aynur Azizova", "Melanie Maria Theresa Br\u00fc\u00dfeler", "Abdullah Okar", "Luca Pasquini", "Yasaman Sharifi", "Gagandeep Singh", "Nico Sollmann", "Theodora Soumala", "Mahsa Taherzadeh", "Philipp Vollmuth", "Martha Foltyn-Dumitru", "Ajay Malhotra", "Francesco Dellepiane", "V\u00edctor M. P\u00e9rez-Garc\u00eda", "Hesham Elhalawani", "Maria Correia de Verdier", "Sanaria Al Rubaiey", "Rui Duarte Armindo", "Kholod Ashraf", "Moamen M. Asla", "Mohamed Badawy", "Jeroen Bisschop", "Nima Broomand Lomer", "Jan Bukatz", "Jim Chen", "Petra Cimflova", "Felix Corr", "Alexis Crawley", "Lisa Deptula", "Tasneem Elakhdar", "Islam H. Shawali", "Shahriar Faghani", "Alexandra Frick", "Vaibhav Gulati", "Muhammad Ammar Haider", "F\u00e1tima Hierro", "Rasmus Holmboe Dahl", "Sarah Maria Jacobs", "Kuang-chun Jim Hsieh", "Sedat G. Kandemirli", "Katharina Kersting", "Laura Kida", "Sofia Kollia", "Ioannis Koukoulithras", "Xiao Li", "Ahmed Abouelatta", "Aya Mansour", "Ruxandra-Catrinel Maria-Zamfirescu", "Marcela Marsiglia", "Yohana Sarahi Mateo-Camacho", "Mark McArthur", "Olivia McDonnel", "Maire McHugh", "Mana Moassefi", "Samah Mostafa Morsi", "Alexander Munteanu", "Khanak K. Nandolia", "Syed Raza Naqvi", "Yalda Nikanpour", "Mostafa Alnoury", "Abdullah Mohamed Aly Nouh", "Francesca Pappafava", "Markand D. Patel", "Samantha Petrucci", "Eric Rawie", "Scott Raymond", "Borna Roohani", "Sadeq Sabouhi", "Laura M. Sanchez Garcia", "Zoe Shaked", "Pokhraj P. Suthar", "Talissa Altes", "Edvin Isufi", "Yaseen Dhemesh", "Jaime Gass", "Jonathan Thacker", "Abdul Rahman Tarabishy", "Benjamin Turner", "Sebastiano Vacca", "George K. Vilanilam", "Daniel Warren", "David Weiss", "Fikadu Worede", "Sara Yousry", "Wondwossen Lerebo", "Alejandro Aristizabal", "Alexandros Karargyris", "Hasan Kassem", "Sarthak Pati", "Micah Sheller", "Katherine E. Link", "Evan Calabrese", "Nourel Hoda Tahon", "Ayman Nada", "Jeffrey D. Rudie", "Janet Reid", "Kassa Darge", "Aly H. Abayazeed", "Philipp Lohmann", "Yuri S. Velichko", "Spyridon Bakas", "Mariam Aboian"], "title": "Analysis of the MICCAI Brain Tumor Segmentation -- Metastases (BraTS-METS) 2025 Lighthouse Challenge: Brain Metastasis Segmentation on Pre- and Post-treatment MRI", "categories": ["q-bio.OT", "eess.IV"], "comment": "28 pages, 4 figures, 2 tables", "summary": "Despite continuous advancements in cancer treatment, brain metastatic disease\nremains a significant complication of primary cancer and is associated with an\nunfavorable prognosis. One approach for improving diagnosis, management, and\noutcomes is to implement algorithms based on artificial intelligence for the\nautomated segmentation of both pre- and post-treatment MRI brain images. Such\nalgorithms rely on volumetric criteria for lesion identification and treatment\nresponse assessment, which are still not available in clinical practice.\nTherefore, it is critical to establish tools for rapid volumetric segmentations\nmethods that can be translated to clinical practice and that are trained on\nhigh quality annotated data. The BraTS-METS 2025 Lighthouse Challenge aims to\naddress this critical need by establishing inter-rater and intra-rater\nvariability in dataset annotation by generating high quality annotated datasets\nfrom four individual instances of segmentation by neuroradiologists while being\nrecorded on video (two instances doing \"from scratch\" and two instances after\nAI pre-segmentation). This high-quality annotated dataset will be used for\ntesting phase in 2025 Lighthouse challenge and will be publicly released at the\ncompletion of the challenge. The 2025 Lighthouse challenge will also release\nthe 2023 and 2024 segmented datasets that were annotated using an established\npipeline of pre-segmentation, student annotation, two neuroradiologists\nchecking, and one neuroradiologist finalizing the process. It builds upon its\nprevious edition by including post-treatment cases in the dataset. Using these\nhigh-quality annotated datasets, the 2025 Lighthouse challenge plans to test\nbenchmark algorithms for automated segmentation of pre-and post-treatment brain\nmetastases (BM), trained on diverse and multi-institutional datasets of MRI\nimages obtained from patients with brain metastases.", "AI": {"tldr": "The paper discusses the use of AI for automated segmentation of brain metastases in MRI images to improve diagnosis and treatment outcomes, highlighting the BraTS-METS 2025 Lighthouse Challenge for high-quality annotated datasets.", "motivation": "Brain metastatic disease has a poor prognosis, and current clinical practices lack reliable volumetric segmentation tools for lesion identification and treatment response assessment.", "method": "The BraTS-METS 2025 Lighthouse Challenge generates high-quality annotated datasets from neuroradiologists' segmentations, including pre- and post-treatment cases, to benchmark AI algorithms.", "result": "The challenge will release annotated datasets (2023-2025) for testing AI algorithms, aiming to improve automated segmentation of brain metastases.", "conclusion": "The initiative aims to bridge the gap between AI-based tools and clinical practice by providing standardized, high-quality datasets for algorithm development."}}
{"id": "2505.04519", "pdf": "https://arxiv.org/pdf/2505.04519", "abs": "https://arxiv.org/abs/2505.04519", "authors": ["Yehui Tang", "Yichun Yin", "Yaoyuan Wang", "Hang Zhou", "Yu Pan", "Wei Guo", "Ziyang Zhang", "Miao Rang", "Fangcheng Liu", "Naifu Zhang", "Binghan Li", "Yonghan Dong", "Xiaojun Meng", "Yasheng Wang", "Dong Li", "Yin Li", "Dandan Tu", "Can Chen", "Youliang Yan", "Fisher Yu", "Ruiming Tang", "Yunhe Wang", "Botian Huang", "Bo Wang", "Boxiao Liu", "Changzheng Zhang", "Da Kuang", "Fei Liu", "Gang Huang", "Jiansheng Wei", "Jiarui Qin", "Jie Ran", "Jinpeng Li", "Jun Zhao", "Liang Dai", "Lin Li", "Liqun Deng", "Peifeng Qin", "Pengyuan Zeng", "Qiang Gu", "Shaohua Tang", "Shengjun Cheng", "Tao Gao", "Tao Yu", "Tianshu Li", "Tianyu Bi", "Wei He", "Weikai Mao", "Wenyong Huang", "Wulong Liu", "Xiabing Li", "Xianzhi Yu", "Xueyu Wu", "Xu He", "Yangkai Du", "Yan Xu", "Ye Tian", "Yimeng Wu", "Yongbing Huang", "Yong Tian", "Yong Zhu", "Yue Li", "Yufei Wang", "Yuhang Gai", "Yujun Li", "Yu Luo", "Yunsheng Ni", "Yusen Sun", "Zelin Chen", "Zhe Liu", "Zhicheng Liu", "Zhipeng Tu", "Zilin Ding", "Zongyuan Zhan"], "title": "Pangu Ultra MoE: How to Train Your Big MoE on Ascend NPUs", "categories": ["cs.CL"], "comment": null, "summary": "Sparse large language models (LLMs) with Mixture of Experts (MoE) and close\nto a trillion parameters are dominating the realm of most capable language\nmodels. However, the massive model scale poses significant challenges for the\nunderlying software and hardware systems. In this paper, we aim to uncover a\nrecipe to harness such scale on Ascend NPUs. The key goals are better usage of\nthe computing resources under the dynamic sparse model structures and\nmaterializing the expected performance gain on the actual hardware. To select\nmodel configurations suitable for Ascend NPUs without repeatedly running the\nexpensive experiments, we leverage simulation to compare the trade-off of\nvarious model hyperparameters. This study led to Pangu Ultra MoE, a sparse LLM\nwith 718 billion parameters, and we conducted experiments on the model to\nverify the simulation results. On the system side, we dig into Expert\nParallelism to optimize the communication between NPU devices to reduce the\nsynchronization overhead. We also optimize the memory efficiency within the\ndevices to further reduce the parameter and activation management overhead. In\nthe end, we achieve an MFU of 30.0% when training Pangu Ultra MoE, with\nperformance comparable to that of DeepSeek R1, on 6K Ascend NPUs, and\ndemonstrate that the Ascend system is capable of harnessing all the training\nstages of the state-of-the-art language models. Extensive experiments indicate\nthat our recipe can lead to efficient training of large-scale sparse language\nmodels with MoE. We also study the behaviors of such models for future\nreference.", "AI": {"tldr": "The paper presents a method to efficiently train sparse large language models (LLMs) with Mixture of Experts (MoE) on Ascend NPUs, achieving high performance and resource utilization.", "motivation": "The massive scale of trillion-parameter sparse LLMs poses challenges for software and hardware systems, motivating the need for efficient training methods on Ascend NPUs.", "method": "The study leverages simulation to compare model hyperparameters, optimizes Expert Parallelism for communication, and improves memory efficiency. This leads to the development of Pangu Ultra MoE (718B parameters).", "result": "Achieved 30.0% MFU on 6K Ascend NPUs, with performance comparable to DeepSeek R1, demonstrating efficient training of large-scale sparse LLMs.", "conclusion": "The proposed recipe enables efficient training of MoE-based LLMs on Ascend NPUs, with insights for future model development."}}
{"id": "2505.04539", "pdf": "https://arxiv.org/pdf/2505.04539", "abs": "https://arxiv.org/abs/2505.04539", "authors": ["Ali Asadi", "Krishnendu Chatterjee", "Ehsan Kafshdar Goharshady", "Mehrdad Karrabi", "Ali Shafiee"], "title": "Qualitative Analysis of $\u03c9$-Regular Objectives on Robust MDPs", "categories": ["cs.AI"], "comment": null, "summary": "Robust Markov Decision Processes (RMDPs) generalize classical MDPs that\nconsider uncertainties in transition probabilities by defining a set of\npossible transition functions. An objective is a set of runs (or infinite\ntrajectories) of the RMDP, and the value for an objective is the maximal\nprobability that the agent can guarantee against the adversarial environment.\nWe consider (a) reachability objectives, where given a target set of states,\nthe goal is to eventually arrive at one of them; and (b) parity objectives,\nwhich are a canonical representation for $\\omega$-regular objectives. The\nqualitative analysis problem asks whether the objective can be ensured with\nprobability 1.\n  In this work, we study the qualitative problem for reachability and parity\nobjectives on RMDPs without making any assumption over the structures of the\nRMDPs, e.g., unichain or aperiodic. Our contributions are twofold. We first\npresent efficient algorithms with oracle access to uncertainty sets that solve\nqualitative problems of reachability and parity objectives. We then report\nexperimental results demonstrating the effectiveness of our oracle-based\napproach on classical RMDP examples from the literature scaling up to thousands\nof states.", "AI": {"tldr": "The paper studies qualitative problems for reachability and parity objectives in Robust Markov Decision Processes (RMDPs) without structural assumptions, presenting efficient oracle-based algorithms and experimental validation.", "motivation": "To address the qualitative analysis problem in RMDPs for reachability and parity objectives without relying on structural assumptions like unichain or aperiodic properties.", "method": "Develops efficient algorithms with oracle access to uncertainty sets for solving qualitative problems.", "result": "Demonstrates effectiveness through experiments on classical RMDP examples, scaling to thousands of states.", "conclusion": "The proposed oracle-based approach efficiently solves qualitative problems in RMDPs, validated by experimental results."}}
{"id": "2505.03794", "pdf": "https://arxiv.org/pdf/2505.03794", "abs": "https://arxiv.org/abs/2505.03794", "authors": ["\u0130rfan I\u015fik", "Ibrahim Karahan", "Okan Erkaymaz"], "title": "A Double Inertial Forward-Backward Splitting Algorithm With Applications to Regression and Classification Problems", "categories": ["cs.LG", "math.OC"], "comment": "20 pages, 5 sections, 5 figures, 5 tables", "summary": "This paper presents an improved forward-backward splitting algorithm with two\ninertial parameters. It aims to find a point in the real Hilbert space at which\nthe sum of a co-coercive operator and a maximal monotone operator vanishes.\nUnder standard assumptions, our proposed algorithm demonstrates weak\nconvergence. We present numerous experimental results to demonstrate the\nbehavior of the developed algorithm by comparing it with existing algorithms in\nthe literature for regression and data classification problems. Furthermore,\nthese implementations suggest our proposed algorithm yields superior outcomes\nwhen benchmarked against other relevant algorithms in existing literature.", "AI": {"tldr": "An improved forward-backward splitting algorithm with two inertial parameters is proposed, showing weak convergence and superior performance in regression and classification tasks.", "motivation": "To find a point in a real Hilbert space where the sum of a co-coercive operator and a maximal monotone operator vanishes, improving upon existing methods.", "method": "The paper introduces a forward-backward splitting algorithm enhanced with two inertial parameters, tested under standard assumptions.", "result": "The algorithm demonstrates weak convergence and outperforms existing methods in regression and data classification experiments.", "conclusion": "The proposed algorithm is effective and superior to current alternatives for solving the targeted problem."}}
{"id": "2505.04088", "pdf": "https://arxiv.org/pdf/2505.04088", "abs": "https://arxiv.org/abs/2505.04088", "authors": ["Shang Zhang", "Huanbin Zhang", "Dali Feng", "Yujie Cui", "Ruoyan Xiong", "Cen He"], "title": "SMMT: Siamese Motion Mamba with Self-attention for Thermal Infrared Target Tracking", "categories": ["cs.CV"], "comment": null, "summary": "Thermal infrared (TIR) object tracking often suffers from challenges such as\ntarget occlusion, motion blur, and background clutter, which significantly\ndegrade the performance of trackers. To address these issues, this paper\npro-poses a novel Siamese Motion Mamba Tracker (SMMT), which integrates a\nbidirectional state-space model and a self-attention mechanism. Specifically,\nwe introduce the Motion Mamba module into the Siamese architecture to ex-tract\nmotion features and recover overlooked edge details using bidirectional\nmodeling and self-attention. We propose a Siamese parameter-sharing strate-gy\nthat allows certain convolutional layers to share weights. This approach\nreduces computational redundancy while preserving strong feature\nrepresen-tation. In addition, we design a motion edge-aware regression loss to\nimprove tracking accuracy, especially for motion-blurred targets. Extensive\nexperi-ments are conducted on four TIR tracking benchmarks, including\nLSOTB-TIR, PTB-TIR, VOT-TIR2015, and VOT-TIR 2017. The results show that SMMT\nachieves superior performance in TIR target tracking.", "AI": {"tldr": "The paper proposes a Siamese Motion Mamba Tracker (SMMT) for thermal infrared (TIR) object tracking, addressing challenges like occlusion and motion blur with bidirectional state-space modeling and self-attention.", "motivation": "TIR object tracking faces issues like occlusion, motion blur, and clutter, degrading tracker performance.", "method": "SMMT integrates bidirectional state-space modeling and self-attention, uses a Siamese parameter-sharing strategy, and introduces a motion edge-aware regression loss.", "result": "SMMT outperforms on benchmarks like LSOTB-TIR, PTB-TIR, VOT-TIR2015, and VOT-TIR2017.", "conclusion": "SMMT achieves superior TIR tracking performance by addressing key challenges with innovative modules and loss design."}}
{"id": "2504.21632", "pdf": "https://arxiv.org/pdf/2504.21632", "abs": "https://arxiv.org/abs/2504.21632", "authors": ["Fuma Ito", "Chihiro Tsutake", "Keita Takahashi", "Toshiaki Fujii"], "title": "Fast Sign Retrieval via Sub-band Convolution: An Elementary Extension of Binary Classification", "categories": ["cs.IT", "eess.IV", "math.IT"], "comment": null, "summary": "To efficiently compress the sign information of images, we address a sign\nretrieval problem for the block-wise discrete cosine transformation (DCT):\nreconstruction of the signs of DCT coefficients from their amplitudes. To this\nend, we propose a fast sign retrieval method on the basis of binary\nclassification machine learning. We first introduce 3D representations of the\namplitudes and signs, where we pack amplitudes/signs belonging to the same\nfrequency band into a 2D slice, referred to as the sub-band block. We then\nretrieve the signs from the 3D amplitudes via binary classification, where each\nsign is regarded as a binary label. We implement a binary classification\nalgorithm using convolutional neural networks, which are advantageous for\nefficiently extracting features in the 3D amplitudes. Experimental results\ndemonstrate that our method achieves accurate sign retrieval with an\noverwhelmingly low computation cost.", "AI": {"tldr": "A fast sign retrieval method for DCT coefficients using binary classification with CNNs, achieving high accuracy and low computation cost.", "motivation": "Efficient compression of sign information in images by reconstructing DCT coefficient signs from their amplitudes.", "method": "Proposes a binary classification approach using CNNs on 3D representations of amplitudes and signs, organized into sub-band blocks.", "result": "Accurate sign retrieval with very low computational cost.", "conclusion": "The method effectively addresses sign retrieval for DCT coefficients, offering a practical solution for image compression."}}
{"id": "2505.04531", "pdf": "https://arxiv.org/pdf/2505.04531", "abs": "https://arxiv.org/abs/2505.04531", "authors": ["Josh McGiff", "Nikola S. Nikolov"], "title": "Overcoming Data Scarcity in Generative Language Modelling for Low-Resource Languages: A Systematic Review", "categories": ["cs.CL", "cs.AI"], "comment": "This work is currently under review. Please do not cite without\n  permission", "summary": "Generative language modelling has surged in popularity with the emergence of\nservices such as ChatGPT and Google Gemini. While these models have\ndemonstrated transformative potential in productivity and communication, they\noverwhelmingly cater to high-resource languages like English. This has\namplified concerns over linguistic inequality in natural language processing\n(NLP). This paper presents the first systematic review focused specifically on\nstrategies to address data scarcity in generative language modelling for\nlow-resource languages (LRL). Drawing from 54 studies, we identify, categorise\nand evaluate technical approaches, including monolingual data augmentation,\nback-translation, multilingual training, and prompt engineering, across\ngenerative tasks. We also analyse trends in architecture choices, language\nfamily representation, and evaluation methods. Our findings highlight a strong\nreliance on transformer-based models, a concentration on a small subset of\nLRLs, and a lack of consistent evaluation across studies. We conclude with\nrecommendations for extending these methods to a wider range of LRLs and\noutline open challenges in building equitable generative language systems.\nUltimately, this review aims to support researchers and developers in building\ninclusive AI tools for underrepresented languages, a necessary step toward\nempowering LRL speakers and the preservation of linguistic diversity in a world\nincreasingly shaped by large-scale language technologies.", "AI": {"tldr": "A systematic review of strategies to address data scarcity in generative language modeling for low-resource languages, highlighting trends, challenges, and recommendations for equitable AI tools.", "motivation": "To tackle linguistic inequality in NLP by focusing on low-resource languages, which are often overlooked in generative language modeling.", "method": "Analyzed 54 studies to categorize and evaluate technical approaches like data augmentation, back-translation, multilingual training, and prompt engineering.", "result": "Found reliance on transformer models, limited language coverage, and inconsistent evaluation methods.", "conclusion": "Recommends broader language inclusion and outlines open challenges for equitable generative systems to support underrepresented languages."}}
{"id": "2504.13777", "pdf": "https://arxiv.org/pdf/2504.13777", "abs": "https://arxiv.org/abs/2504.13777", "authors": ["Anqi Shao"], "title": "Beyond Misinformation: A Conceptual Framework for Studying AI Hallucinations in (Science) Communication", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "This paper proposes a conceptual framework for understanding AI\nhallucinations as a distinct form of misinformation. While misinformation\nscholarship has traditionally focused on human intent, generative AI systems\nnow produce false yet plausible outputs absent of such intent. I argue that\nthese AI hallucinations should not be treated merely as technical failures but\nas communication phenomena with social consequences. Drawing on a\nsupply-and-demand model and the concept of distributed agency, the framework\noutlines how hallucinations differ from human-generated misinformation in\nproduction, perception, and institutional response. I conclude by outlining a\nresearch agenda for communication scholars to investigate the emergence,\ndissemination, and audience reception of hallucinated content, with attention\nto macro (institutional), meso (group), and micro (individual) levels. This\nwork urges communication researchers to rethink the boundaries of\nmisinformation theory in light of probabilistic, non-human actors increasingly\nembedded in knowledge production.", "AI": {"tldr": "The paper proposes a framework to study AI hallucinations as a unique form of misinformation, distinct from human-generated falsehoods, and calls for communication scholars to investigate its social impact.", "motivation": "To address the gap in misinformation research by focusing on AI-generated false outputs (hallucinations) that lack human intent, emphasizing their social and communicative implications.", "method": "Uses a supply-and-demand model and the concept of distributed agency to differentiate AI hallucinations from human misinformation in production, perception, and institutional response.", "result": "The framework highlights the need to study AI hallucinations as communication phenomena, not just technical flaws, and outlines their societal consequences.", "conclusion": "Urges communication scholars to expand misinformation theory to include AI-generated content, proposing a research agenda at macro, meso, and micro levels."}}
{"id": "2505.03797", "pdf": "https://arxiv.org/pdf/2505.03797", "abs": "https://arxiv.org/abs/2505.03797", "authors": ["Andrew Millard", "Joshua Murphy", "Simon Maskell", "Zheng Zhao"], "title": "Utilising Gradient-Based Proposals Within Sequential Monte Carlo Samplers for Training of Partial Bayesian Neural Networks", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Partial Bayesian neural networks (pBNNs) have been shown to perform\ncompetitively with fully Bayesian neural networks while only having a subset of\nthe parameters be stochastic. Using sequential Monte Carlo (SMC) samplers as\nthe inference method for pBNNs gives a non-parametric probabilistic estimation\nof the stochastic parameters, and has shown improved performance over\nparametric methods. In this paper we introduce a new SMC-based training method\nfor pBNNs by utilising a guided proposal and incorporating gradient-based\nMarkov kernels, which gives us better scalability on high dimensional problems.\nWe show that our new method outperforms the state-of-the-art in terms of\npredictive performance and optimal loss. We also show that pBNNs scale well\nwith larger batch sizes, resulting in significantly reduced training times and\noften better performance.", "AI": {"tldr": "A new SMC-based training method for pBNNs improves scalability and outperforms state-of-the-art in predictive performance and optimal loss.", "motivation": "To enhance the performance and scalability of partial Bayesian neural networks (pBNNs) using sequential Monte Carlo (SMC) samplers.", "method": "Introduces a guided proposal and gradient-based Markov kernels for SMC-based training of pBNNs.", "result": "Outperforms state-of-the-art in predictive performance and optimal loss, with better scalability and reduced training times.", "conclusion": "The new SMC-based method for pBNNs is highly effective, scalable, and efficient, making it a competitive alternative to fully Bayesian approaches."}}
{"id": "2505.04105", "pdf": "https://arxiv.org/pdf/2505.04105", "abs": "https://arxiv.org/abs/2505.04105", "authors": ["Andrew Zhang", "Hao Wang", "Shuchang Ye", "Michael Fulham", "Jinman Kim"], "title": "MAISY: Motion-Aware Image SYnthesis for MedicalImage Motion Correction", "categories": ["cs.CV"], "comment": null, "summary": "Patient motion during medical image acquisition causes blurring, ghosting,\nand distorts organs, which makes image interpretation challenging.Current\nstate-of-the-art algorithms using Generative Adversarial Network (GAN)-based\nmethods with their ability to learn the mappings between corrupted images and\ntheir ground truth via Structural Similarity Index Measure (SSIM) loss\neffectively generate motion-free images. However, we identified the following\nlimitations: (i) they mainly focus on global structural characteristics and\ntherefore overlook localized features that often carry critical pathological\ninformation, and (ii) the SSIM loss function struggles to handle images with\nvarying pixel intensities, luminance factors, and variance. In this study, we\npropose Motion-Aware Image SYnthesis (MAISY) which initially characterize\nmotion and then uses it for correction by: (a) leveraging the foundation model\nSegment Anything Model (SAM), to dynamically learn spatial patterns along\nanatomical boundaries where motion artifacts are most pronounced and, (b)\nintroducing the Variance-Selective SSIM (VS-SSIM) loss which adaptively\nemphasizes spatial regions with high pixel variance to preserve essential\nanatomical details during artifact correction. Experiments on chest and head CT\ndatasets demonstrate that our model outperformed the state-of-the-art\ncounterparts, with Peak Signal-to-Noise Ratio (PSNR) increasing by 40%, SSIM by\n10%, and Dice by 16%.", "AI": {"tldr": "Proposes MAISY, a motion-aware image synthesis method using SAM and VS-SSIM loss to address limitations of GAN-based motion correction in medical imaging.", "motivation": "Current GAN-based methods overlook localized features and struggle with varying pixel intensities, luminance, and variance.", "method": "Uses Segment Anything Model (SAM) to learn spatial patterns and introduces VS-SSIM loss for adaptive correction.", "result": "Outperforms state-of-the-art with 40% PSNR, 10% SSIM, and 16% Dice improvements.", "conclusion": "MAISY effectively corrects motion artifacts while preserving critical anatomical details."}}
{"id": "2505.04588", "pdf": "https://arxiv.org/pdf/2505.04588", "abs": "https://arxiv.org/abs/2505.04588", "authors": ["Hao Sun", "Zile Qiao", "Jiayan Guo", "Xuanbo Fan", "Yingyan Hou", "Yong Jiang", "Pengjun Xie", "Fei Huang", "Yan Zhang"], "title": "ZeroSearch: Incentivize the Search Capability of LLMs without Searching", "categories": ["cs.CL"], "comment": null, "summary": "Effective information searching is essential for enhancing the reasoning and\ngeneration capabilities of large language models (LLMs). Recent research has\nexplored using reinforcement learning (RL) to improve LLMs' search capabilities\nby interacting with live search engines in real-world environments. While these\napproaches show promising results, they face two major challenges: (1)\nUncontrolled Document Quality: The quality of documents returned by search\nengines is often unpredictable, introducing noise and instability into the\ntraining process. (2) Prohibitively High API Costs: RL training requires\nfrequent rollouts, potentially involving hundreds of thousands of search\nrequests, which incur substantial API expenses and severely constrain\nscalability. To address these challenges, we introduce ZeroSearch, a\nreinforcement learning framework that incentivizes the search capabilities of\nLLMs without interacting with real search engines. Our approach begins with\nlightweight supervised fine-tuning to transform the LLM into a retrieval module\ncapable of generating both relevant and noisy documents in response to a query.\nDuring RL training, we employ a curriculum-based rollout strategy that\nincrementally degrades the quality of generated documents, progressively\neliciting the model's reasoning ability by exposing it to increasingly\nchallenging retrieval scenarios. Extensive experiments demonstrate that\nZeroSearch effectively incentivizes the search capabilities of LLMs using a 3B\nLLM as the retrieval module. Remarkably, a 7B retrieval module achieves\ncomparable performance to the real search engine, while a 14B retrieval module\neven surpasses it. Furthermore, it generalizes well across both base and\ninstruction-tuned models of various parameter sizes and is compatible with a\nwide range of RL algorithms.", "AI": {"tldr": "ZeroSearch is a reinforcement learning framework that improves LLMs' search capabilities without real search engine interaction, addressing document quality and API cost issues.", "motivation": "To overcome challenges of uncontrolled document quality and high API costs in RL-based search training for LLMs.", "method": "Uses lightweight supervised fine-tuning to create a retrieval module, followed by curriculum-based RL training with degrading document quality.", "result": "Achieves comparable or superior performance to real search engines with 3B, 7B, and 14B LLMs, and generalizes well across models.", "conclusion": "ZeroSearch is a scalable and cost-effective solution for enhancing LLMs' search capabilities."}}
{"id": "2505.03745", "pdf": "https://arxiv.org/pdf/2505.03745", "abs": "https://arxiv.org/abs/2505.03745", "authors": ["Yanbiao Liang", "Huihong Shi", "Haikuo Shao", "Zhongfeng Wang"], "title": "AccLLM: Accelerating Long-Context LLM Inference Via Algorithm-Hardware Co-Design", "categories": ["cs.AR", "cs.AI", "cs.LG"], "comment": null, "summary": "Recently, large language models (LLMs) have achieved huge success in the\nnatural language processing (NLP) field, driving a growing demand to extend\ntheir deployment from the cloud to edge devices. However, deploying LLMs on\nresource-constrained edge devices poses significant challenges, including (1)\nintensive computations and huge model sizes, (2) great memory and bandwidth\ndemands introduced by the autoregressive generation process, and (3) limited\nscalability for handling long sequences. To address these challenges, we\npropose AccLLM, a comprehensive acceleration framework that enables efficient\nand fast long-context LLM inference through algorithm and hardware co-design.\nAt the algorithmic level, we integrate (1) pruning, (2) {\\Lambda}-shaped\nattention, and (3) an innovative W2A8KV4 (2-bit weights, 8-bit activations, and\n4-bit KV cache) quantization scheme, thus effectively reducing memory and\nbandwidth requirements while facilitating LLMs' long-sequence generation. At\nthe hardware level, we design a dedicated FPGA-based accelerator with a\nreconfigurable computing engine to effectively and flexibly accommodate diverse\noperations arising from our compression algorithm, thereby fully translating\nthe algorithmic innovations into tangible hardware efficiency. We validate\nAccLLM on the Xilinx Alveo U280 FPGA, demonstrating a 4.07x energy efficiency\nand a 2.98x throughput compared to the state-of-the-art work FlightLLM.", "AI": {"tldr": "AccLLM is a framework for efficient LLM deployment on edge devices, combining algorithmic and hardware optimizations to address computational and memory challenges.", "motivation": "The need to deploy large language models (LLMs) on resource-constrained edge devices despite challenges like intensive computations, memory demands, and limited scalability for long sequences.", "method": "Algorithmic innovations (pruning, \u039b-shaped attention, W2A8KV4 quantization) and a dedicated FPGA-based accelerator for hardware efficiency.", "result": "AccLLM achieves 4.07x energy efficiency and 2.98x throughput compared to FlightLLM on Xilinx Alveo U280 FPGA.", "conclusion": "AccLLM effectively bridges the gap between LLM capabilities and edge deployment constraints through co-design."}}
{"id": "2505.03798", "pdf": "https://arxiv.org/pdf/2505.03798", "abs": "https://arxiv.org/abs/2505.03798", "authors": ["Yiqing Shen", "Hao Ding", "Lalithkumar Seenivasan", "Tianmin Shu", "Mathias Unberath"], "title": "Position: Foundation Models Need Digital Twin Representations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Current foundation models (FMs) rely on token representations that directly\nfragment continuous real-world multimodal data into discrete tokens. They limit\nFMs to learning real-world knowledge and relationships purely through\nstatistical correlation rather than leveraging explicit domain knowledge.\nConsequently, current FMs struggle with maintaining semantic coherence across\nmodalities, capturing fine-grained spatial-temporal dynamics, and performing\ncausal reasoning. These limitations cannot be overcome by simply scaling up\nmodel size or expanding datasets. This position paper argues that the machine\nlearning community should consider digital twin (DT) representations, which are\noutcome-driven digital representations that serve as building blocks for\ncreating virtual replicas of physical processes, as an alternative to the token\nrepresentation for building FMs. Finally, we discuss how DT representations can\naddress these challenges by providing physically grounded representations that\nexplicitly encode domain knowledge and preserve the continuous nature of\nreal-world processes.", "AI": {"tldr": "The paper proposes using digital twin (DT) representations instead of token representations in foundation models (FMs) to better capture real-world knowledge and address limitations like semantic coherence and causal reasoning.", "motivation": "Current FMs use token representations that fragment real-world data, limiting their ability to leverage domain knowledge and perform tasks like causal reasoning.", "method": "The paper suggests adopting DT representations, which are outcome-driven digital replicas of physical processes, to encode domain knowledge and preserve continuous data.", "result": "DT representations could overcome FM limitations by providing physically grounded, continuous representations.", "conclusion": "The machine learning community should explore DT representations as an alternative to tokens for building more effective FMs."}}
{"id": "2505.04109", "pdf": "https://arxiv.org/pdf/2505.04109", "abs": "https://arxiv.org/abs/2505.04109", "authors": ["Mengya Liu", "Siyuan Li", "Ajad Chhatkuli", "Prune Truong", "Luc Van Gool", "Federico Tombari"], "title": "One2Any: One-Reference 6D Pose Estimation for Any Object", "categories": ["cs.CV"], "comment": "accepted by CVPR 2025", "summary": "6D object pose estimation remains challenging for many applications due to\ndependencies on complete 3D models, multi-view images, or training limited to\nspecific object categories. These requirements make generalization to novel\nobjects difficult for which neither 3D models nor multi-view images may be\navailable. To address this, we propose a novel method One2Any that estimates\nthe relative 6-degrees of freedom (DOF) object pose using only a single\nreference-single query RGB-D image, without prior knowledge of its 3D model,\nmulti-view data, or category constraints. We treat object pose estimation as an\nencoding-decoding process, first, we obtain a comprehensive Reference Object\nPose Embedding (ROPE) that encodes an object shape, orientation, and texture\nfrom a single reference view. Using this embedding, a U-Net-based pose decoding\nmodule produces Reference Object Coordinate (ROC) for new views, enabling fast\nand accurate pose estimation. This simple encoding-decoding framework allows\nour model to be trained on any pair-wise pose data, enabling large-scale\ntraining and demonstrating great scalability. Experiments on multiple benchmark\ndatasets demonstrate that our model generalizes well to novel objects,\nachieving state-of-the-art accuracy and robustness even rivaling methods that\nrequire multi-view or CAD inputs, at a fraction of compute.", "AI": {"tldr": "One2Any is a novel method for 6D object pose estimation using a single RGB-D image, eliminating the need for 3D models, multi-view images, or category-specific training.", "motivation": "Current methods rely on complete 3D models, multi-view images, or category-specific training, limiting generalization to novel objects.", "method": "One2Any uses an encoding-decoding framework: it encodes object shape, orientation, and texture into a Reference Object Pose Embedding (ROPE) from a single reference view, then decodes it into Reference Object Coordinates (ROC) for pose estimation.", "result": "The method achieves state-of-the-art accuracy and robustness on benchmark datasets, outperforming methods requiring multi-view or CAD inputs.", "conclusion": "One2Any demonstrates scalability and generalization to novel objects, offering a simpler and more efficient solution for 6D pose estimation."}}
{"id": "2505.03799", "pdf": "https://arxiv.org/pdf/2505.03799", "abs": "https://arxiv.org/abs/2505.03799", "authors": ["Hyun Lee", "Chris Yi", "Maminur Islam", "B. D. S. Aritra"], "title": "Scalability Matters: Overcoming Challenges in InstructGLM with Similarity-Degree-Based Sampling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "To be published in International Joint Conference on Neural Networks\n  (IJCNN), 2025", "summary": "Large Language Models (LLMs) have demonstrated strong capabilities in various\nnatural language processing tasks; however, their application to graph-related\nproblems remains limited, primarily due to scalability constraints and the\nabsence of dedicated mechanisms for processing graph structures. Existing\napproaches predominantly integrate LLMs with Graph Neural Networks (GNNs),\nusing GNNs as feature encoders or auxiliary components. However, directly\nencoding graph structures within LLMs has been underexplored, particularly in\nthe context of large-scale graphs where token limitations hinder effective\nrepresentation. To address these challenges, we propose SDM-InstructGLM, a\nnovel instruction-tuned Graph Language Model (InstructGLM) framework that\nenhances scalability and efficiency without relying on GNNs. Our method\nintroduces a similarity-degree-based biased random walk mechanism, which\nselectively samples and encodes graph information based on node-feature\nsimilarity and degree centrality, ensuring an adaptive and structured\nrepresentation within the LLM. This approach significantly improves token\nefficiency, mitigates information loss due to random sampling, and enhances\nperformance on graph-based tasks such as node classification and link\nprediction. Furthermore, our results demonstrate the feasibility of LLM-only\ngraph processing, enabling scalable and interpretable Graph Language Models\n(GLMs) optimized through instruction-based fine-tuning. This work paves the way\nfor GNN-free approaches to graph learning, leveraging LLMs as standalone graph\nreasoning models. Our source code is available on GitHub.", "AI": {"tldr": "Proposes SDM-InstructGLM, an instruction-tuned Graph Language Model for scalable graph processing without GNNs, using similarity-degree-based biased random walks.", "motivation": "Addresses limitations of LLMs in graph tasks due to scalability and lack of graph-specific mechanisms, avoiding reliance on GNNs.", "method": "Introduces a similarity-degree-based biased random walk to selectively sample and encode graph information, improving token efficiency.", "result": "Enhances performance in node classification and link prediction, demonstrating scalable LLM-only graph processing.", "conclusion": "Paves the way for GNN-free graph learning, enabling standalone LLM-based graph reasoning."}}
{"id": "2505.03746", "pdf": "https://arxiv.org/pdf/2505.03746", "abs": "https://arxiv.org/abs/2505.03746", "authors": ["Silvia Garc\u00eda-M\u00e9ndez", "Francisco De Arriba-P\u00e9rez"], "title": "Promoting Security and Trust on Social Networks: Explainable Cyberbullying Detection Using Large Language Models in a Stream-Based Machine Learning Framework", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "Social media platforms enable instant and ubiquitous connectivity and are\nessential to social interaction and communication in our technological society.\nApart from its advantages, these platforms have given rise to negative\nbehaviors in the online community, the so-called cyberbullying. Despite the\nmany works involving generative Artificial Intelligence (AI) in the literature\nlately, there remain opportunities to study its performance apart from\nzero/few-shot learning strategies. Accordingly, we propose an innovative and\nreal-time solution for cyberbullying detection that leverages stream-based\nMachine Learning (ML) models able to process the incoming samples incrementally\nand Large Language Models (LLMS) for feature engineering to address the\nevolving nature of abusive and hate speech online. An explainability dashboard\nis provided to promote the system's trustworthiness, reliability, and\naccountability. Results on experimental data report promising performance close\nto 90 % in all evaluation metrics and surpassing those obtained by competing\nworks in the literature. Ultimately, our proposal contributes to the safety of\nonline communities by timely detecting abusive behavior to prevent long-lasting\nharassment and reduce the negative consequences in society.", "AI": {"tldr": "The paper proposes a real-time cyberbullying detection system using stream-based ML and LLMs for feature engineering, achieving ~90% performance and offering explainability.", "motivation": "To address the evolving nature of cyberbullying and leverage AI beyond zero/few-shot learning for timely detection.", "method": "Combines stream-based ML models for incremental processing and LLMs for feature engineering, with an explainability dashboard.", "result": "Achieves ~90% performance across metrics, outperforming existing works.", "conclusion": "The system enhances online safety by detecting abusive behavior early, reducing societal harm."}}
{"id": "2505.03801", "pdf": "https://arxiv.org/pdf/2505.03801", "abs": "https://arxiv.org/abs/2505.03801", "authors": ["Changhai Zhou", "Qian Qiao", "Weizhong Zhang", "Cheng Jin"], "title": "Large Language Model Compression with Global Rank and Sparsity Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "22 pages, 5 figures", "summary": "Low-rank and sparse composite approximation is a natural idea to compress\nLarge Language Models (LLMs). However, such an idea faces two primary\nchallenges that adversely affect the performance of existing methods. The first\nchallenge relates to the interaction and cooperation between low-rank and\nsparse matrices, while the second involves determining weight allocation across\ndifferent layers, as redundancy varies considerably among them. To address\nthese challenges, we propose a novel two-stage LLM compression method with the\ncapability of global rank and sparsity optimization. It is noteworthy that the\noverall optimization space is vast, making comprehensive optimization\ncomputationally prohibitive. Therefore, to reduce the optimization space, our\nfirst stage utilizes robust principal component analysis to decompose the\nweight matrices of LLMs into low-rank and sparse components, which span the low\ndimensional and sparse spaces containing the resultant low-rank and sparse\nmatrices, respectively. In the second stage, we propose a probabilistic global\noptimization technique to jointly identify the low-rank and sparse structures\nwithin the above two spaces. The appealing feature of our approach is its\nability to automatically detect the redundancy across different layers and to\nmanage the interaction between the sparse and low-rank components. Extensive\nexperimental results indicate that our method significantly surpasses\nstate-of-the-art techniques for sparsification and composite approximation.", "AI": {"tldr": "A two-stage LLM compression method is proposed, addressing challenges in low-rank and sparse composite approximation by optimizing global rank and sparsity while managing layer redundancy and component interaction.", "motivation": "Existing methods for compressing LLMs struggle with interaction between low-rank and sparse matrices and uneven weight allocation across layers due to varying redundancy.", "method": "The method uses robust PCA for decomposition in the first stage and probabilistic global optimization in the second stage to jointly identify low-rank and sparse structures.", "result": "The approach outperforms state-of-the-art techniques in sparsification and composite approximation.", "conclusion": "The proposed method effectively addresses key challenges in LLM compression, offering superior performance by optimizing global rank and sparsity."}}
{"id": "2505.04119", "pdf": "https://arxiv.org/pdf/2505.04119", "abs": "https://arxiv.org/abs/2505.04119", "authors": ["Zixiang Ai", "Zichen Liu", "Yuanhang Lei", "Zhenyu Cui", "Xu Zou", "Jiahuan Zhou"], "title": "GAPrompt: Geometry-Aware Point Cloud Prompt for 3D Vision Model", "categories": ["cs.CV"], "comment": "Accepted by ICML 2025", "summary": "Pre-trained 3D vision models have gained significant attention for their\npromising performance on point cloud data. However, fully fine-tuning these\nmodels for downstream tasks is computationally expensive and storage-intensive.\nExisting parameter-efficient fine-tuning (PEFT) approaches, which focus\nprimarily on input token prompting, struggle to achieve competitive performance\ndue to their limited ability to capture the geometric information inherent in\npoint clouds. To address this challenge, we propose a novel Geometry-Aware\nPoint Cloud Prompt (GAPrompt) that leverages geometric cues to enhance the\nadaptability of 3D vision models. First, we introduce a Point Prompt that\nserves as an auxiliary input alongside the original point cloud, explicitly\nguiding the model to capture fine-grained geometric details. Additionally, we\npresent a Point Shift Prompter designed to extract global shape information\nfrom the point cloud, enabling instance-specific geometric adjustments at the\ninput level. Moreover, our proposed Prompt Propagation mechanism incorporates\nthe shape information into the model's feature extraction process, further\nstrengthening its ability to capture essential geometric characteristics.\nExtensive experiments demonstrate that GAPrompt significantly outperforms\nstate-of-the-art PEFT methods and achieves competitive results compared to full\nfine-tuning on various benchmarks, while utilizing only 2.19% of trainable\nparameters. Our code is available at\nhttps://github.com/zhoujiahuan1991/ICML2025-VGP.", "AI": {"tldr": "GAPrompt introduces a geometry-aware approach for efficient fine-tuning of 3D vision models, outperforming existing methods with minimal trainable parameters.", "motivation": "Fully fine-tuning pre-trained 3D models is resource-intensive, and current PEFT methods lack geometric awareness for point cloud data.", "method": "Proposes GAPrompt with Point Prompt, Point Shift Prompter, and Prompt Propagation to enhance geometric adaptability.", "result": "Achieves competitive performance with full fine-tuning while using only 2.19% of trainable parameters.", "conclusion": "GAPrompt offers a parameter-efficient, geometry-aware solution for fine-tuning 3D vision models."}}
{"id": "2505.03810", "pdf": "https://arxiv.org/pdf/2505.03810", "abs": "https://arxiv.org/abs/2505.03810", "authors": ["Euntae Choi", "Sumin Song", "Woosang Lim", "Sungjoo Yoo"], "title": "Grouped Sequency-arranged Rotation: Optimizing Rotation Transformation for Quantization for Free", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "7 pages", "summary": "Large Language Models (LLMs) face deployment challenges due to high\ncomputational costs, and while Post-Training Quantization (PTQ) offers a\nsolution, existing rotation-based methods struggle at very low bit-widths like\n2-bit. We introduce a novel, training-free approach to construct an improved\nrotation matrix, addressing the limitations of current methods. The key\ncontributions include leveraging the Walsh-Hadamard transform with sequency\nordering, which clusters similar frequency components to reduce quantization\nerror compared to standard Hadamard matrices, significantly improving\nperformance. Furthermore, we propose a Grouped Sequency-arranged Rotation (GSR)\nusing block-diagonal matrices with smaller Walsh blocks, effectively isolating\noutlier impacts and achieving performance comparable to optimization-based\nmethods without requiring any training. Our method demonstrates robust\nperformance on reasoning tasks and Perplexity (PPL) score on WikiText-2. Our\nmethod also enhances results even when applied over existing learned rotation\ntechniques.", "AI": {"tldr": "A novel training-free method improves LLM quantization at low bit-widths using Walsh-Hadamard transform and grouped rotation, outperforming existing techniques.", "motivation": "Addressing the limitations of current rotation-based PTQ methods for LLMs at very low bit-widths (e.g., 2-bit).", "method": "Leverages Walsh-Hadamard transform with sequency ordering and proposes Grouped Sequency-arranged Rotation (GSR) using block-diagonal matrices.", "result": "Significantly reduces quantization error, improves reasoning tasks, and enhances WikiText-2 PPL scores.", "conclusion": "The method offers a robust, training-free solution for low-bit LLM quantization, even enhancing learned rotation techniques."}}
{"id": "2505.03747", "pdf": "https://arxiv.org/pdf/2505.03747", "abs": "https://arxiv.org/abs/2505.03747", "authors": ["Viktor Marek", "Ewa Or\u0142owska", "Ivo D\u00fcntsch"], "title": "The Evolution of Rough Sets 1970s-1981", "categories": ["math.HO", "cs.AI"], "comment": null, "summary": "In this note research and publications by Zdzis{\\l}aw Pawlak and his\ncollaborators from 1970s and 1981 are recalled. Focus is placed on the sources\nof inspiration which one can identify on the basis of those publications.\nFinally, developments from 1981 related to rough sets and information systems\nare outlined.", "AI": {"tldr": "A retrospective on Zdzis\u0142aw Pawlak's 1970s and 1981 work, highlighting inspirations and developments in rough sets and information systems.", "motivation": "To revisit Pawlak's foundational contributions and identify the inspirations behind his work.", "method": "Review and analysis of Pawlak's publications from the 1970s and 1981.", "result": "Identified key inspirations and outlined developments in rough sets and information systems post-1981.", "conclusion": "Pawlak's work remains influential, with clear inspirations and lasting impact on rough sets and information systems."}}
{"id": "2505.03802", "pdf": "https://arxiv.org/pdf/2505.03802", "abs": "https://arxiv.org/abs/2505.03802", "authors": ["Changhai Zhou", "Yuhua Zhou", "Qian Qiao", "Weizhong Zhang", "Cheng Jin"], "title": "Efficient Fine-Tuning of Quantized Models via Adaptive Rank and Bitwidth", "categories": ["cs.LG", "cs.AI"], "comment": "24 pages, 6 figures", "summary": "QLoRA effectively combines low-bit quantization and LoRA to achieve\nmemory-friendly fine-tuning for large language models (LLM). Recently, methods\nbased on SVD for continuous update iterations to initialize LoRA matrices to\naccommodate quantization errors have generally failed to consistently improve\nperformance. Dynamic mixed precision is a natural idea for continuously\nimproving the fine-tuning performance of quantized models, but previous methods\noften optimize low-rank subspaces or quantization components separately,\nwithout considering their synergy. To address this, we propose\n\\textbf{QR-Adaptor}, a unified, gradient-free strategy that uses partial\ncalibration data to jointly search the quantization components and the rank of\nlow-rank spaces for each layer, thereby continuously improving model\nperformance. QR-Adaptor does not minimize quantization error but treats\nprecision and rank allocation as a discrete optimization problem guided by\nactual downstream performance and memory usage. Compared to state-of-the-art\n(SOTA) quantized LoRA fine-tuning methods, our approach achieves a 4.89\\%\naccuracy improvement on GSM8K, and in some cases even outperforms the 16-bit\nfine-tuned model while maintaining the memory footprint of the 4-bit setting.", "AI": {"tldr": "QLoRA combines low-bit quantization and LoRA for memory-efficient LLM fine-tuning. QR-Adaptor, a gradient-free method, jointly optimizes quantization and low-rank subspaces, outperforming SOTA methods by 4.89% on GSM8K.", "motivation": "Existing methods fail to consistently improve performance due to separate optimization of quantization and low-rank subspaces, ignoring their synergy.", "method": "Proposes QR-Adaptor, a unified strategy using partial calibration data to jointly search quantization components and low-rank subspaces, treating it as a discrete optimization problem.", "result": "Achieves 4.89% accuracy improvement on GSM8K, sometimes outperforming 16-bit models while maintaining 4-bit memory usage.", "conclusion": "QR-Adaptor effectively balances performance and memory efficiency, advancing quantized LLM fine-tuning."}}
{"id": "2505.04121", "pdf": "https://arxiv.org/pdf/2505.04121", "abs": "https://arxiv.org/abs/2505.04121", "authors": ["Zixiang Ai", "Zichen Liu", "Jiahuan Zhou"], "title": "Vision Graph Prompting via Semantic Low-Rank Decomposition", "categories": ["cs.CV"], "comment": "Accepted by ICML 2025", "summary": "Vision GNN (ViG) demonstrates superior performance by representing images as\ngraph structures, providing a more natural way to capture irregular semantic\npatterns beyond traditional grid or sequence-based representations. To\nefficiently adapt ViG to downstream tasks, parameter-efficient fine-tuning\ntechniques like visual prompting become increasingly essential. However,\nexisting prompting methods are primarily designed for Transformer-based models,\nneglecting the rich topological relationships among nodes and edges in\ngraph-based representations, limiting their capacity to model complex\nsemantics. In this paper, we propose Vision Graph Prompting (VGP), a novel\nframework tailored for vision graph structures. Our core insight reveals that\nsemantically connected components in the graph exhibit low-rank properties.\nBuilding on this observation, we introduce a semantic low-rank prompting method\nthat decomposes low-rank semantic features and integrates them with prompts on\nvision graph topologies, capturing both global structural patterns and\nfine-grained semantic dependencies. Extensive experiments demonstrate our\nmethod significantly improves ViG's transfer performance on diverse downstream\ntasks, achieving results comparable to full fine-tuning while maintaining\nparameter efficiency. Our code is available at\nhttps://github.com/zhoujiahuan1991/ICML2025-VGP.", "AI": {"tldr": "ViG outperforms by using graph structures for images. VGP introduces a low-rank prompting method for ViG, improving transfer performance efficiently.", "motivation": "Existing prompting methods for Transformer-based models don't suit graph-based representations, limiting semantic modeling.", "method": "Proposes Vision Graph Prompting (VGP), leveraging low-rank properties of graph components to integrate semantic and topological features.", "result": "VGP significantly enhances ViG's transfer performance on downstream tasks, matching full fine-tuning with fewer parameters.", "conclusion": "VGP effectively bridges the gap in graph-based prompting, offering a parameter-efficient solution for vision tasks."}}
{"id": "2505.03814", "pdf": "https://arxiv.org/pdf/2505.03814", "abs": "https://arxiv.org/abs/2505.03814", "authors": ["Ganghua Wang", "Zhaorun Chen", "Bo Li", "Haifeng Xu"], "title": "Cer-Eval: Certifiable and Cost-Efficient Evaluation Framework for LLMs", "categories": ["stat.ML", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "As foundation models continue to scale, the size of trained models grows\nexponentially, presenting significant challenges for their evaluation. Current\nevaluation practices involve curating increasingly large datasets to assess the\nperformance of large language models (LLMs). However, there is a lack of\nsystematic analysis and guidance on determining the sufficiency of test data or\nselecting informative samples for evaluation. This paper introduces a\ncertifiable and cost-efficient evaluation framework for LLMs. Our framework\nadapts to different evaluation objectives and outputs confidence intervals that\ncontain true values with high probability. We use ``test sample complexity'' to\nquantify the number of test points needed for a certifiable evaluation and\nderive tight bounds on test sample complexity. Based on the developed theory,\nwe develop a partition-based algorithm, named Cer-Eval, that adaptively selects\ntest points to minimize the cost of LLM evaluation. Real-world experiments\ndemonstrate that Cer-Eval can save 20% to 40% test points across various\nbenchmarks, while maintaining an estimation error level comparable to the\ncurrent evaluation process and providing a 95% confidence guarantee.", "AI": {"tldr": "The paper introduces a certifiable and cost-efficient evaluation framework for large language models (LLMs) that adapts to evaluation objectives, provides confidence intervals, and reduces test points by 20%-40% while maintaining accuracy.", "motivation": "Current evaluation practices for LLMs lack systematic analysis and guidance on test data sufficiency and sample selection, leading to inefficiencies.", "method": "The framework uses \"test sample complexity\" to quantify needed test points, derives tight bounds, and employs a partition-based algorithm (Cer-Eval) for adaptive test point selection.", "result": "Cer-Eval saves 20%-40% test points across benchmarks, maintains comparable estimation error, and provides 95% confidence guarantees.", "conclusion": "The proposed framework offers a certifiable, efficient, and adaptive solution for LLM evaluation, addressing current limitations."}}
{"id": "2505.03748", "pdf": "https://arxiv.org/pdf/2505.03748", "abs": "https://arxiv.org/abs/2505.03748", "authors": ["Yonghao Tan", "Pingcheng Dong", "Yongkun Wu", "Yu Liu", "Xuejiao Liu", "Peng Luo", "Shih-Yang Liu", "Xijie Huang", "Dong Zhang", "Luhong Liang", "Kwang-Ting Cheng"], "title": "APSQ: Additive Partial Sum Quantization with Algorithm-Hardware Co-Design", "categories": ["cs.AR", "cs.AI"], "comment": "62nd ACM/IEEE Design Automation Conference (DAC) 2025", "summary": "DNN accelerators, significantly advanced by model compression and specialized\ndataflow techniques, have marked considerable progress. However, the frequent\naccess of high-precision partial sums (PSUMs) leads to excessive memory demands\nin architectures utilizing input/weight stationary dataflows. Traditional\ncompression strategies have typically overlooked PSUM quantization, which may\naccount for 69% of power consumption. This study introduces a novel Additive\nPartial Sum Quantization (APSQ) method, seamlessly integrating PSUM\naccumulation into the quantization framework. A grouping strategy that combines\nAPSQ with PSUM quantization enhanced by a reconfigurable architecture is\nfurther proposed. The APSQ performs nearly lossless on NLP and CV tasks across\nBERT, Segformer, and EfficientViT models while compressing PSUMs to INT8. This\nleads to a notable reduction in energy costs by 28-87%. Extended experiments on\nLLaMA2-7B demonstrate the potential of APSQ for large language models. Code is\navailable at https://github.com/Yonghao-Tan/APSQ.", "AI": {"tldr": "The paper introduces APSQ, a method for quantizing partial sums (PSUMs) in DNN accelerators, reducing memory demands and energy costs by 28-87%.", "motivation": "Addressing the overlooked issue of PSUM quantization, which contributes significantly to power consumption in DNN accelerators.", "method": "Proposes Additive Partial Sum Quantization (APSQ) and a grouping strategy with reconfigurable architecture for PSUM quantization.", "result": "APSQ achieves near-lossless performance on NLP and CV tasks (BERT, Segformer, EfficientViT) while compressing PSUMs to INT8, reducing energy costs by 28-87%.", "conclusion": "APSQ is effective for DNN accelerators and shows potential for large language models like LLaMA2-7B."}}
{"id": "2505.03803", "pdf": "https://arxiv.org/pdf/2505.03803", "abs": "https://arxiv.org/abs/2505.03803", "authors": ["Chen Xu", "Yuxuan Yue", "Zukang Xu", "Xing Hu", "Jiangyong Yu", "Zhixuan Chen", "Sifan Zhou", "Zhihang Yuan", "Dawei Yang"], "title": "RWKVQuant: Quantizing the RWKV Family with Proxy Guided Hybrid of Scalar and Vector Quantization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "RWKV is a modern RNN architecture with comparable performance to Transformer,\nbut still faces challenges when deployed to resource-constrained devices. Post\nTraining Quantization (PTQ), which is a an essential technique to reduce model\nsize and inference latency, has been widely used in Transformer models.\nHowever, it suffers significant degradation of performance when applied to\nRWKV. This paper investigates and identifies two key constraints inherent in\nthe properties of RWKV: (1) Non-linear operators hinder the parameter-fusion of\nboth smooth- and rotation-based quantization, introducing extra computation\noverhead. (2) The larger amount of uniformly distributed weights poses\nchallenges for cluster-based quantization, leading to reduced accuracy. To this\nend, we propose RWKVQuant, a PTQ framework tailored for RWKV models, consisting\nof two novel techniques: (1) a coarse-to-fine proxy capable of adaptively\nselecting different quantization approaches by assessing the uniformity and\nidentifying outliers in the weights, and (2) a codebook optimization algorithm\nthat enhances the performance of cluster-based quantization methods for\nelement-wise multiplication in RWKV. Experiments show that RWKVQuant can\nquantize RWKV-6-14B into about 3-bit with less than 1% accuracy loss and 2.14x\nspeed up.", "AI": {"tldr": "RWKVQuant is a PTQ framework for RWKV models, addressing quantization challenges with adaptive techniques, achieving 3-bit quantization with minimal accuracy loss and speedup.", "motivation": "RWKV, despite its Transformer-like performance, struggles with PTQ due to non-linear operators and uniform weight distribution, leading to performance degradation.", "method": "RWKVQuant introduces a coarse-to-fine proxy for adaptive quantization and a codebook optimization algorithm for cluster-based quantization.", "result": "Quantizes RWKV-6-14B to ~3-bit with <1% accuracy loss and 2.14x speedup.", "conclusion": "RWKVQuant effectively addresses RWKV's PTQ challenges, enabling efficient deployment on resource-constrained devices."}}
{"id": "2505.04147", "pdf": "https://arxiv.org/pdf/2505.04147", "abs": "https://arxiv.org/abs/2505.04147", "authors": ["Lixing Niu", "Jiapeng Li", "Xingping Yu", "Shu Wang", "Ruining Feng", "Bo Wu", "Ping Wei", "Yisen Wang", "Lifeng Fan"], "title": "R^3-VQA: \"Read the Room\" by Video Social Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "\"Read the room\" is a significant social reasoning capability in human daily\nlife. Humans can infer others' mental states from subtle social cues. Previous\nsocial reasoning tasks and datasets lack complexity (e.g., simple scenes, basic\ninteractions, incomplete mental state variables, single-step reasoning, etc.)\nand fall far short of the challenges present in real-life social interactions.\nIn this paper, we contribute a valuable, high-quality, and comprehensive video\ndataset named R^3-VQA with precise and fine-grained annotations of social\nevents and mental states (i.e., belief, intent, desire, and emotion) as well as\ncorresponding social causal chains in complex social scenarios. Moreover, we\ninclude human-annotated and model-generated QAs. Our task R^3-VQA includes\nthree aspects: Social Event Understanding, Mental State Estimation, and Social\nCausal Reasoning. As a benchmark, we comprehensively evaluate the social\nreasoning capabilities and consistencies of current state-of-the-art large\nvision-language models (LVLMs). Comprehensive experiments show that (i) LVLMs\nare still far from human-level consistent social reasoning in complex social\nscenarios; (ii) Theory of Mind (ToM) prompting can help LVLMs perform better on\nsocial reasoning tasks. We provide some of our dataset and codes in\nsupplementary material and will release our full dataset and codes upon\nacceptance.", "AI": {"tldr": "The paper introduces R^3-VQA, a comprehensive video dataset for social reasoning, evaluating LVLMs' capabilities and showing gaps in human-level reasoning.", "motivation": "Existing social reasoning tasks lack complexity, failing to mirror real-life challenges. The paper aims to bridge this gap with a detailed dataset.", "method": "The authors created R^3-VQA, a dataset with fine-grained annotations of social events, mental states, and causal chains, including human and model-generated QAs.", "result": "LVLMs fall short of human-level social reasoning, but ToM prompting improves their performance.", "conclusion": "The dataset and findings highlight the need for better models in complex social reasoning."}}
{"id": "2505.03828", "pdf": "https://arxiv.org/pdf/2505.03828", "abs": "https://arxiv.org/abs/2505.03828", "authors": ["Yogesh Gajula"], "title": "Sentiment-Aware Recommendation Systems in E-Commerce: A Review from a Natural Language Processing Perspective", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": "12 pages, 2 tables, 2 figures", "summary": "E-commerce platforms generate vast volumes of user feedback, such as star\nratings, written reviews, and comments. However, most recommendation engines\nrely primarily on numerical scores, often overlooking the nuanced opinions\nembedded in free text. This paper comprehensively reviews sentiment-aware\nrecommendation systems from a natural language processing perspective, covering\nadvancements from 2023 to early 2025. It highlights the benefits of integrating\nsentiment analysis into e-commerce recommenders to enhance prediction accuracy\nand explainability through detailed opinion extraction. Our survey categorizes\nrecent work into four main approaches: deep learning classifiers that combine\nsentiment embeddings with user item interactions, transformer based methods for\nnuanced feature extraction, graph neural networks that propagate sentiment\nsignals, and conversational recommenders that adapt in real time to user\nfeedback. We summarize model architectures and demonstrate how sentiment flows\nthrough recommendation pipelines, impacting dialogue-based suggestions. Key\nchallenges include handling noisy or sarcastic text, dynamic user preferences,\nand bias mitigation. Finally, we outline research gaps and provide a roadmap\nfor developing smarter, fairer, and more user-centric recommendation tools.", "AI": {"tldr": "The paper reviews sentiment-aware recommendation systems in e-commerce, focusing on NLP advancements (2023-2025), and categorizes methods into deep learning, transformers, GNNs, and conversational recommenders. It highlights benefits, challenges, and future directions.", "motivation": "E-commerce platforms often ignore nuanced opinions in free text, relying on numerical scores. Integrating sentiment analysis can improve recommendation accuracy and explainability.", "method": "The paper surveys four approaches: deep learning classifiers, transformer-based methods, graph neural networks, and conversational recommenders, analyzing their architectures and sentiment integration.", "result": "Sentiment-aware systems enhance prediction accuracy and explainability, but challenges like noisy text, dynamic preferences, and bias remain.", "conclusion": "The paper outlines research gaps and a roadmap for developing smarter, fairer, and user-centric recommendation tools."}}
{"id": "2505.03750", "pdf": "https://arxiv.org/pdf/2505.03750", "abs": "https://arxiv.org/abs/2505.03750", "authors": ["Jinhai Hu", "Wang Ling Goh", "Yuan Gao"], "title": "AI-Powered Agile Analog Circuit Design and Optimization", "categories": ["cs.AR", "cs.AI"], "comment": "3 pages, 5 figures, AI4X, 2025", "summary": "Artificial intelligence (AI) techniques are transforming analog circuit\ndesign by automating device-level tuning and enabling system-level\nco-optimization. This paper integrates two approaches: (1) AI-assisted\ntransistor sizing using Multi-Objective Bayesian Optimization (MOBO) for direct\ncircuit parameter optimization, demonstrated on a linearly tunable\ntransconductor; and (2) AI-integrated circuit transfer function modeling for\nsystem-level optimization in a keyword spotting (KWS) application, demonstrated\nby optimizing an analog bandpass filter within a machine learning training\nloop. The combined insights highlight how AI can improve analog performance,\nreduce design iteration effort, and jointly optimize analog components and\napplication-level metrics.", "AI": {"tldr": "AI techniques automate analog circuit design, combining transistor sizing with MOBO and system-level optimization for improved performance and reduced effort.", "motivation": "To demonstrate how AI can enhance analog circuit design by automating tuning and enabling co-optimization at both device and system levels.", "method": "Integrates AI-assisted transistor sizing using MOBO and AI-integrated circuit transfer function modeling for system-level optimization.", "result": "Improved analog performance, reduced design iteration effort, and joint optimization of analog components and application-level metrics.", "conclusion": "AI effectively enhances analog circuit design by automating tuning and enabling holistic optimization."}}
{"id": "2505.03804", "pdf": "https://arxiv.org/pdf/2505.03804", "abs": "https://arxiv.org/abs/2505.03804", "authors": ["Xing Hu", "Zhixuan Chen", "Dawei Yang", "Zukang Xu", "Chen Xu", "Zhihang Yuan", "Sifan Zhou", "Jiangyong Yu"], "title": "MoEQuant: Enhancing Quantization for Mixture-of-Experts Large Language Models via Expert-Balanced Sampling and Affinity Guidance", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Mixture-of-Experts (MoE) large language models (LLMs), which leverage dynamic\nrouting and sparse activation to enhance efficiency and scalability, have\nachieved higher performance while reducing computational costs. However, these\nmodels face significant memory overheads, limiting their practical deployment\nand broader adoption. Post-training quantization (PTQ), a widely used method\nfor compressing LLMs, encounters severe accuracy degradation and diminished\ngeneralization performance when applied to MoE models. This paper investigates\nthe impact of MoE's sparse and dynamic characteristics on quantization and\nidentifies two primary challenges: (1) Inter-expert imbalance, referring to the\nuneven distribution of samples across experts, which leads to insufficient and\nbiased calibration for less frequently utilized experts; (2) Intra-expert\nimbalance, arising from MoE's unique aggregation mechanism, which leads to\nvarying degrees of correlation between different samples and their assigned\nexperts. To address these challenges, we propose MoEQuant, a novel quantization\nframework tailored for MoE LLMs. MoE-Quant includes two novel techniques: 1)\nExpert-Balanced Self-Sampling (EBSS) is an efficient sampling method that\nefficiently constructs a calibration set with balanced expert distributions by\nleveraging the cumulative probabilities of tokens and expert balance metrics as\nguiding factors. 2) Affinity-Guided Quantization (AGQ), which incorporates\naffinities between experts and samples into the quantization process, thereby\naccurately assessing the impact of individual samples on different experts\nwithin the MoE layer. Experiments demonstrate that MoEQuant achieves\nsubstantial performance gains (more than 10 points accuracy gain in the\nHumanEval for DeepSeekMoE-16B under 4-bit quantization) and boosts efficiency.", "AI": {"tldr": "MoEQuant, a novel quantization framework, addresses memory overheads in MoE LLMs by tackling inter-expert and intra-expert imbalance challenges, achieving significant performance gains.", "motivation": "MoE LLMs face memory overheads and accuracy degradation with standard PTQ due to sparse and dynamic routing, limiting practical deployment.", "method": "Proposes MoEQuant with Expert-Balanced Self-Sampling (EBSS) for balanced calibration and Affinity-Guided Quantization (AGQ) to incorporate sample-expert affinities.", "result": "MoEQuant achieves over 10 points accuracy gain in HumanEval for DeepSeekMoE-16B under 4-bit quantization, improving efficiency.", "conclusion": "MoEQuant effectively addresses quantization challenges in MoE LLMs, enhancing performance and scalability."}}
{"id": "2505.04150", "pdf": "https://arxiv.org/pdf/2505.04150", "abs": "https://arxiv.org/abs/2505.04150", "authors": ["Yu Yamaoka or Weng Ian Chan", "Shigeto Seno", "Soichiro Fukada", "Hideo Matsuda"], "title": "Learning from Similarity Proportion Loss for Classifying Skeletal Muscle Recovery Stages", "categories": ["cs.CV", "cs.LG"], "comment": "MICCAI2024 workshop ADSMI in Morocco (oral) [Peer-reviewed]", "summary": "Evaluating the regeneration process of damaged muscle tissue is a fundamental\nanalysis in muscle research to measure experimental effect sizes and uncover\nmechanisms behind muscle weakness due to aging and disease. The conventional\napproach to assessing muscle tissue regeneration involves whole-slide imaging\nand expert visual inspection of the recovery stages based on the morphological\ninformation of cells and fibers. There is a need to replace these tasks with\nautomated methods incorporating machine learning techniques to ensure a\nquantitative and objective analysis. Given the limited availability of fully\nlabeled data, a possible approach is Learning from Label Proportions (LLP), a\nweakly supervised learning method using class label proportions. However,\ncurrent LLP methods have two limitations: (1) they cannot adapt the feature\nextractor for muscle tissues, and (2) they treat the classes representing\nrecovery stages and cell morphological changes as nominal, resulting in the\nloss of ordinal information. To address these issues, we propose Ordinal Scale\nLearning from Similarity Proportion (OSLSP), which uses a similarity proportion\nloss derived from two bag combinations. OSLSP can update the feature extractor\nby using class proportion attention to the ordinal scale of the class. Our\nmodel with OSLSP outperforms large-scale pre-trained and fine-tuning models in\nclassification tasks of skeletal muscle recovery stages.", "AI": {"tldr": "The paper proposes OSLSP, a method for automated muscle tissue regeneration analysis using weakly supervised learning to address limitations of current LLP methods.", "motivation": "Traditional muscle regeneration assessment relies on manual inspection, which lacks objectivity. Automated methods like LLP are limited by feature adaptation and loss of ordinal class information.", "method": "The authors introduce OSLSP, a weakly supervised learning approach using similarity proportion loss and class proportion attention to preserve ordinal scale.", "result": "OSLSP outperforms pre-trained and fine-tuning models in classifying skeletal muscle recovery stages.", "conclusion": "OSLSP provides a quantitative, objective solution for muscle regeneration analysis, addressing key limitations of existing methods."}}
{"id": "2505.03997", "pdf": "https://arxiv.org/pdf/2505.03997", "abs": "https://arxiv.org/abs/2505.03997", "authors": ["Prudhviraj Naidu", "Zixian Wang", "Leon Bergen", "Ramamohan Paturi"], "title": "Quiet Feature Learning in Algorithmic Tasks", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "We train Transformer-based language models on ten foundational algorithmic\ntasks and observe pronounced phase transitions in their loss curves that\ndeviate from established power-law scaling trends. Over large ranges of\ncompute, the validation loss barely improves, then abruptly decreases. Probing\nthe models' internal representations reveals the learning of quiet features\nduring the stagnant phase, followed by sudden acquisition of loud features that\ncoincide with the sharp drop in loss. Our ablation experiments show that\ndisrupting a single learned feature can dramatically degrade performance,\nproviding evidence of their causal role in task performance. These findings\nchallenge the prevailing assumption that next-token predictive loss reliably\ntracks incremental progress; instead, key internal features may be developing\nbelow the surface until they coalesce, triggering a rapid performance gain.", "AI": {"tldr": "Transformer models show abrupt loss drops during training on algorithmic tasks, revealing hidden feature learning phases.", "motivation": "To understand why Transformer models exhibit sudden performance improvements despite stagnant loss trends.", "method": "Train Transformers on algorithmic tasks, analyze loss curves, and probe internal representations to identify feature learning phases.", "result": "Models learn quiet features during stagnation, then acquire loud features coinciding with sharp loss drops. Ablation confirms causal role of features.", "conclusion": "Next-token loss may not track incremental progress; key features develop covertly before triggering rapid gains."}}
{"id": "2505.03756", "pdf": "https://arxiv.org/pdf/2505.03756", "abs": "https://arxiv.org/abs/2505.03756", "authors": ["Hang Zhang", "Jiuchen Shi", "Yixiao Wang", "Quan Chen", "Yizhou Shan", "Minyi Guo"], "title": "Improving the Serving Performance of Multi-LoRA Large Language Models via Efficient LoRA and KV Cache Management", "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.PF"], "comment": null, "summary": "Multiple Low-Rank Adapters (Multi-LoRAs) are gaining popularity for\ntask-specific Large Language Model (LLM) applications. For multi-LoRA serving,\ncaching hot KV caches and LoRA adapters in high bandwidth memory of\naccelerations can improve inference performance. However, existing Multi-LoRA\ninference systems fail to optimize serving performance like Time-To-First-Toke\n(TTFT), neglecting usage dependencies when caching LoRAs and KVs. We therefore\npropose FASTLIBRA, a Multi-LoRA caching system to optimize the serving\nperformance. FASTLIBRA comprises a dependency-aware cache manager and a\nperformance-driven cache swapper. The cache manager maintains the usage\ndependencies between LoRAs and KV caches during the inference with a unified\ncaching pool. The cache swapper determines the swap-in or out of LoRAs and KV\ncaches based on a unified cost model, when the HBM is idle or busy,\nrespectively. Experimental results show that ELORA reduces the TTFT by 63.4% on\naverage, compared to state-of-the-art works.", "AI": {"tldr": "FASTLIBRA optimizes Multi-LoRA serving by caching hot KV caches and LoRA adapters with dependency-aware management, reducing TTFT by 63.4%.", "motivation": "Existing Multi-LoRA systems lack optimization for serving performance, ignoring usage dependencies between LoRAs and KV caches.", "method": "FASTLIBRA uses a dependency-aware cache manager and performance-driven cache swapper to handle LoRAs and KV caches efficiently.", "result": "FASTLIBRA reduces Time-To-First-Token (TTFT) by 63.4% compared to state-of-the-art systems.", "conclusion": "FASTLIBRA significantly improves Multi-LoRA serving performance by addressing caching dependencies and optimizing swap decisions."}}
{"id": "2505.03805", "pdf": "https://arxiv.org/pdf/2505.03805", "abs": "https://arxiv.org/abs/2505.03805", "authors": ["Nguyen Van Thanh"], "title": "Feature Optimization for Time Series Forecasting via Novel Randomized Uphill Climbing", "categories": ["cs.LG", "cs.PF"], "comment": null, "summary": "Randomized Uphill Climbing is a lightweight, stochastic search heuristic that\nhas delivered state of the art equity alpha factors for quantitative hedge\nfunds. I propose to generalize RUC into a model agnostic feature optimization\nframework for multivariate time series forecasting. The core idea is to\nsynthesize candidate feature programs by randomly composing operators from a\ndomain specific grammar, score candidates rapidly with inexpensive surrogate\nmodels on rolling windows, and filter instability via nested cross validation\nand information theoretic shrinkage. By decoupling feature discovery from GPU\nheavy deep learning, the method promises faster iteration cycles, lower energy\nconsumption, and greater interpretability. Societal relevance: accurate,\ntransparent forecasting tools empower resource constrained institutions, energy\nregulators, climate risk NGOs to make data driven decisions without proprietary\nblack box models.", "AI": {"tldr": "Generalizing Randomized Uphill Climbing (RUC) into a model-agnostic feature optimization framework for multivariate time series forecasting, focusing on efficiency, interpretability, and societal impact.", "motivation": "To improve forecasting tools by decoupling feature discovery from resource-intensive deep learning, enabling faster, more transparent, and energy-efficient solutions for resource-constrained institutions.", "method": "Synthesizes feature programs via random operator composition, scores them with surrogate models on rolling windows, and filters instability using nested cross-validation and information-theoretic shrinkage.", "result": "A lightweight framework promising faster iteration, lower energy use, and greater interpretability compared to GPU-heavy deep learning.", "conclusion": "The approach offers a practical, transparent alternative to black-box models, benefiting institutions like energy regulators and climate risk NGOs."}}
{"id": "2505.04175", "pdf": "https://arxiv.org/pdf/2505.04175", "abs": "https://arxiv.org/abs/2505.04175", "authors": ["Naphat Nithisopa", "Teerapong Panboonyuen"], "title": "DOTA: Deformable Optimized Transformer Architecture for End-to-End Text Recognition with Retrieval-Augmented Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Text recognition in natural images remains a challenging yet essential task,\nwith broad applications spanning computer vision and natural language\nprocessing. This paper introduces a novel end-to-end framework that combines\nResNet and Vision Transformer backbones with advanced methodologies, including\nDeformable Convolutions, Retrieval-Augmented Generation, and Conditional Random\nFields (CRF). These innovations collectively enhance feature representation and\nimprove Optical Character Recognition (OCR) performance. Specifically, the\nframework substitutes standard convolution layers in the third and fourth\nblocks with Deformable Convolutions, leverages adaptive dropout for\nregularization, and incorporates CRF for more refined sequence modeling.\nExtensive experiments conducted on six benchmark datasets IC13, IC15, SVT,\nIIIT5K, SVTP, and CUTE80 validate the proposed method's efficacy, achieving\nnotable accuracies: 97.32% on IC13, 58.26% on IC15, 88.10% on SVT, 74.13% on\nIIIT5K, 82.17% on SVTP, and 66.67% on CUTE80, resulting in an average accuracy\nof 77.77%. These results establish a new state-of-the-art for text recognition,\ndemonstrating the robustness of the approach across diverse and challenging\ndatasets.", "AI": {"tldr": "A novel end-to-end framework combining ResNet and Vision Transformer with advanced techniques (Deformable Convolutions, Retrieval-Augmented Generation, CRF) achieves state-of-the-art OCR performance on six benchmark datasets.", "motivation": "Text recognition in natural images is challenging but crucial for applications in computer vision and NLP.", "method": "The framework uses Deformable Convolutions, adaptive dropout, and CRF for refined sequence modeling, replacing standard convolutions in ResNet and Vision Transformer.", "result": "Achieves accuracies of 97.32% (IC13), 58.26% (IC15), 88.10% (SVT), 74.13% (IIIT5K), 82.17% (SVTP), and 66.67% (CUTE80), averaging 77.77%.", "conclusion": "The method sets a new state-of-the-art, proving robustness across diverse datasets."}}
{"id": "2505.04171", "pdf": "https://arxiv.org/pdf/2505.04171", "abs": "https://arxiv.org/abs/2505.04171", "authors": ["Nouar Aldahoul", "Hazem Ibrahim", "Matteo Varvello", "Aaron Kaufman", "Talal Rahwan", "Yasir Zaki"], "title": "Large Language Models are often politically extreme, usually ideologically inconsistent, and persuasive even in informational contexts", "categories": ["cs.CY", "cs.CL"], "comment": "61 pages, 29 figures", "summary": "Large Language Models (LLMs) are a transformational technology, fundamentally\nchanging how people obtain information and interact with the world. As people\nbecome increasingly reliant on them for an enormous variety of tasks, a body of\nacademic research has developed to examine these models for inherent biases,\nespecially political biases, often finding them small. We challenge this\nprevailing wisdom. First, by comparing 31 LLMs to legislators, judges, and a\nnationally representative sample of U.S. voters, we show that LLMs' apparently\nsmall overall partisan preference is the net result of offsetting extreme views\non specific topics, much like moderate voters. Second, in a randomized\nexperiment, we show that LLMs can promulgate their preferences into political\npersuasiveness even in information-seeking contexts: voters randomized to\ndiscuss political issues with an LLM chatbot are as much as 5 percentage points\nmore likely to express the same preferences as that chatbot. Contrary to\nexpectations, these persuasive effects are not moderated by familiarity with\nLLMs, news consumption, or interest in politics. LLMs, especially those\ncontrolled by private companies or governments, may become a powerful and\ntargeted vector for political influence.", "AI": {"tldr": "LLMs exhibit hidden political biases and can influence voters' preferences by up to 5 percentage points, challenging the notion of their neutrality.", "motivation": "To challenge the prevailing belief that LLMs have minimal political biases and to investigate their potential influence on political preferences.", "method": "Compared 31 LLMs to legislators, judges, and U.S. voters, and conducted a randomized experiment on political persuasiveness.", "result": "LLMs' small overall partisan preference masks extreme views on specific topics, and they can sway voters' preferences by 5 percentage points.", "conclusion": "LLMs, especially those controlled by private or government entities, may serve as powerful tools for targeted political influence."}}
{"id": "2505.03760", "pdf": "https://arxiv.org/pdf/2505.03760", "abs": "https://arxiv.org/abs/2505.03760", "authors": ["Arishi Orra", "Aryan Bhambu", "Himanshu Choudhary", "Manoj Thakur", "Selvaraju Natarajan"], "title": "Deep Reinforcement Learning for Investor-Specific Portfolio Optimization: A Volatility-Guided Asset Selection Approach", "categories": ["q-fin.PM", "cs.AI", "math.OC"], "comment": null, "summary": "Portfolio optimization requires dynamic allocation of funds by balancing the\nrisk and return tradeoff under dynamic market conditions. With the recent\nadvancements in AI, Deep Reinforcement Learning (DRL) has gained prominence in\nproviding adaptive and scalable strategies for portfolio optimization. However,\nthe success of these strategies depends not only on their ability to adapt to\nmarket dynamics but also on the careful pre-selection of assets that influence\noverall portfolio performance. Incorporating the investor's preference in\npre-selecting assets for a portfolio is essential in refining their investment\nstrategies. This study proposes a volatility-guided DRL-based portfolio\noptimization framework that dynamically constructs portfolios based on\ninvestors' risk profiles. The Generalized Autoregressive Conditional\nHeteroscedasticity (GARCH) model is utilized for volatility forecasting of\nstocks and categorizes them based on their volatility as aggressive, moderate,\nand conservative. The DRL agent is then employed to learn an optimal investment\npolicy by interacting with the historical market data. The efficacy of the\nproposed methodology is established using stocks from the Dow $30$ index. The\nproposed investor-specific DRL-based portfolios outperformed the baseline\nstrategies by generating consistent risk-adjusted returns.", "AI": {"tldr": "A volatility-guided Deep Reinforcement Learning (DRL) framework for portfolio optimization dynamically constructs portfolios based on investors' risk profiles, outperforming baseline strategies.", "motivation": "To address the need for adaptive and scalable portfolio optimization strategies that incorporate investor preferences and market dynamics.", "method": "Uses GARCH for volatility forecasting to categorize stocks (aggressive, moderate, conservative) and a DRL agent to learn optimal investment policies from historical data.", "result": "The proposed investor-specific DRL-based portfolios outperformed baseline strategies, generating consistent risk-adjusted returns.", "conclusion": "The framework effectively balances risk and return by integrating investor preferences and market volatility, enhancing portfolio performance."}}
{"id": "2505.03806", "pdf": "https://arxiv.org/pdf/2505.03806", "abs": "https://arxiv.org/abs/2505.03806", "authors": ["Mehran Mazandarani", "Marzieh Najariyan"], "title": "Perception-Informed Neural Networks: Beyond Physics-Informed Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This article introduces Perception-Informed Neural Networks (PrINNs), a\nframework designed to incorporate perception-based information into neural\nnetworks, addressing both systems with known and unknown physics laws or\ndifferential equations. Moreover, PrINNs extend the concept of Physics-Informed\nNeural Networks (PINNs) and their variants, offering a platform for the\nintegration of diverse forms of perception precisiation, including singular,\nprobability distribution, possibility distribution, interval, and fuzzy graph.\nIn fact, PrINNs allow neural networks to model dynamical systems by integrating\nexpert knowledge and perception-based information through loss functions,\nenabling the creation of modern data-driven models. Some of the key\ncontributions include Mixture of Experts Informed Neural Networks (MOEINNs),\nwhich combine heterogeneous expert knowledge into the network, and\nTransformed-Knowledge Informed Neural Networks (TKINNs), which facilitate the\nincorporation of meta-information for enhanced model performance. Additionally,\nFuzzy-Informed Neural Networks (FINNs) as a modern class of fuzzy deep neural\nnetworks leverage fuzzy logic constraints within a deep learning architecture,\nallowing online training without pre-training and eliminating the need for\ndefuzzification. PrINNs represent a significant step forward in bridging the\ngap between traditional physics-based modeling and modern data-driven\napproaches, enabling neural networks to learn from both structured physics laws\nand flexible perception-based rules. This approach empowers neural networks to\noperate in uncertain environments, model complex systems, and discover new\nforms of differential equations, making PrINNs a powerful tool for advancing\ncomputational science and engineering.", "AI": {"tldr": "PrINNs integrate perception-based info into neural networks, extending PINNs to handle diverse perception forms and expert knowledge, enabling data-driven modeling in uncertain environments.", "motivation": "To bridge physics-based modeling and data-driven approaches by incorporating perception-based info and expert knowledge into neural networks.", "method": "Uses loss functions to integrate perception precisiation (e.g., probability, fuzzy logic) and expert knowledge, introducing variants like MOEINNs, TKINNs, and FINNs.", "result": "Enables modeling of dynamical systems, uncertain environments, and discovery of new differential equations without defuzzification.", "conclusion": "PrINNs advance computational science by combining physics and perception, offering flexible and powerful modeling tools."}}
{"id": "2505.04185", "pdf": "https://arxiv.org/pdf/2505.04185", "abs": "https://arxiv.org/abs/2505.04185", "authors": ["Hail Song", "Wonsik Shin", "Naeun Lee", "Soomin Chung", "Nojun Kwak", "Woontack Woo"], "title": "S3D: Sketch-Driven 3D Model Generation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted as a short paper to the GMCV Workshop at CVPR'25", "summary": "Generating high-quality 3D models from 2D sketches is a challenging task due\nto the inherent ambiguity and sparsity of sketch data. In this paper, we\npresent S3D, a novel framework that converts simple hand-drawn sketches into\ndetailed 3D models. Our method utilizes a U-Net-based encoder-decoder\narchitecture to convert sketches into face segmentation masks, which are then\nused to generate a 3D representation that can be rendered from novel views. To\nensure robust consistency between the sketch domain and the 3D output, we\nintroduce a novel style-alignment loss that aligns the U-Net bottleneck\nfeatures with the initial encoder outputs of the 3D generation module,\nsignificantly enhancing reconstruction fidelity. To further enhance the\nnetwork's robustness, we apply augmentation techniques to the sketch dataset.\nThis streamlined framework demonstrates the effectiveness of S3D in generating\nhigh-quality 3D models from sketch inputs. The source code for this project is\npublicly available at https://github.com/hailsong/S3D.", "AI": {"tldr": "S3D is a framework that converts 2D sketches into detailed 3D models using a U-Net-based architecture and style-alignment loss for improved fidelity.", "motivation": "The challenge of generating 3D models from sparse and ambiguous 2D sketches drives the need for a robust solution.", "method": "Uses a U-Net encoder-decoder to create face segmentation masks, then generates 3D models with a style-alignment loss and sketch augmentation.", "result": "S3D effectively produces high-quality 3D models from sketches, with enhanced reconstruction fidelity.", "conclusion": "The framework demonstrates success in 3D model generation from sketches, with publicly available source code."}}
{"id": "2505.04192", "pdf": "https://arxiv.org/pdf/2505.04192", "abs": "https://arxiv.org/abs/2505.04192", "authors": ["Trinh T. L. Vuong", "Jin Tae Kwak"], "title": "VideoPath-LLaVA: Pathology Diagnostic Reasoning Through Video Instruction Tuning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "We present VideoPath-LLaVA, the first large multimodal model (LMM) in\ncomputational pathology that integrates three distinct image scenarios, single\npatch images, automatically keyframe-extracted clips, and manually segmented\nvideo pathology images, to mimic the natural diagnostic process of\npathologists. By generating detailed histological descriptions and culminating\nin a definitive sign-out diagnosis, VideoPath-LLaVA bridges visual narratives\nwith diagnostic reasoning.\n  Central to our approach is the VideoPath-Instruct dataset, comprising 4278\nvideo and diagnosis-specific chain-of-thought instructional pairs sourced from\neducational histopathology videos on YouTube. Although high-quality data is\ncritical for enhancing diagnostic reasoning, its creation is time-intensive and\nlimited in volume. To overcome this challenge, we transfer knowledge from\nexisting single-image instruction datasets to train on weakly annotated,\nkeyframe-extracted clips, followed by fine-tuning on manually segmented videos.\nVideoPath-LLaVA establishes a new benchmark in pathology video analysis and\noffers a promising foundation for future AI systems that support clinical\ndecision-making through integrated visual and diagnostic reasoning. Our code,\ndata, and model are publicly available at\nhttps://github.com/trinhvg/VideoPath-LLaVA.", "AI": {"tldr": "VideoPath-LLaVA is a multimodal model for pathology that integrates single patch images, keyframe-extracted clips, and segmented videos to mimic pathologists' diagnostic process. It uses the VideoPath-Instruct dataset and knowledge transfer for training, achieving a benchmark in pathology video analysis.", "motivation": "To bridge visual narratives with diagnostic reasoning in pathology by mimicking the natural diagnostic process of pathologists.", "method": "Integrates three image scenarios (single patch, keyframe clips, segmented videos) and uses the VideoPath-Instruct dataset for training, leveraging knowledge transfer from single-image datasets.", "result": "Establishes a new benchmark in pathology video analysis, offering a foundation for AI systems supporting clinical decision-making.", "conclusion": "VideoPath-LLaVA is a promising tool for enhancing diagnostic reasoning in pathology, with publicly available code, data, and model."}}
{"id": "2505.03763", "pdf": "https://arxiv.org/pdf/2505.03763", "abs": "https://arxiv.org/abs/2505.03763", "authors": ["Asad Aali", "Adney Cardoza", "Melissa Capo"], "title": "Splitwiser: Efficient LM inference with constrained resources", "categories": ["cs.AR", "cs.AI", "cs.DC", "cs.LG"], "comment": null, "summary": "Efficient inference of LLMs remains a crucial challenge, with two main\nphases: a compute-intensive prompt computation and a memory-intensive token\ngeneration. Despite existing batching and scheduling techniques, token\ngeneration phases fail to fully utilize compute resources, especially when\ncompared to prompt computation phases. To address these challenges, we propose\nSplitwiser, a methodology that splits the two phases of an LLM inference\nrequest onto the same GPU, thereby reducing overhead and improving memory\naccess and cache utilization. By eliminating the need to transfer data across\ndevices, Splitwiser aims to minimize network-related overheads. In this report,\nwe describe the basic structure of our proposed pipeline while sharing\npreliminary results and analysis. We implement our proposed multiprocessing\ndesign on two widely-used and independent LLM architectures: Huggingface and\nvLLM. We open-source our code for the respective implementations: 1)\nHuggingface (https://github.com/asad-aali/splitwiser), and 2) vLLM\n(https://github.com/adney11/vllm-sysml).", "AI": {"tldr": "Splitwiser improves LLM inference efficiency by splitting prompt computation and token generation phases on the same GPU, reducing overhead and enhancing resource utilization.", "motivation": "Current LLM inference struggles with underutilized compute resources during token generation compared to prompt computation.", "method": "Proposes Splitwiser, a pipeline splitting the two phases on the same GPU, minimizing data transfer and network overhead. Implemented on Huggingface and vLLM architectures.", "result": "Preliminary results show improved memory access and cache utilization, with open-sourced implementations for Huggingface and vLLM.", "conclusion": "Splitwiser offers a promising approach to optimize LLM inference by addressing resource underutilization and overhead issues."}}
{"id": "2505.03808", "pdf": "https://arxiv.org/pdf/2505.03808", "abs": "https://arxiv.org/abs/2505.03808", "authors": ["Ioannis Nasios"], "title": "AI-driven multi-source data fusion for algal bloom severity classification in small inland water bodies: Leveraging Sentinel-2, DEM, and NOAA climate data", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Harmful algal blooms are a growing threat to inland water quality and public\nhealth worldwide, creating an urgent need for efficient, accurate, and\ncost-effective detection methods. This research introduces a high-performing\nmethodology that integrates multiple open-source remote sensing data with\nadvanced artificial intelligence models. Key data sources include Copernicus\nSentinel-2 optical imagery, the Copernicus Digital Elevation Model (DEM), and\nNOAA's High-Resolution Rapid Refresh (HRRR) climate data, all efficiently\nretrieved using platforms like Google Earth Engine (GEE) and Microsoft\nPlanetary Computer (MPC). The NIR and two SWIR bands from Sentinel-2, the\naltitude from the elevation model, the temperature and wind from NOAA as well\nas the longitude and latitude were the most important features. The approach\ncombines two types of machine learning models, tree-based models and a neural\nnetwork, into an ensemble for classifying algal bloom severity. While the tree\nmodels performed strongly on their own, incorporating a neural network added\nrobustness and demonstrated how deep learning models can effectively use\ndiverse remote sensing inputs. The method leverages high-resolution satellite\nimagery and AI-driven analysis to monitor algal blooms dynamically, and\nalthough initially developed for a NASA competition in the U.S., it shows\npotential for global application. The complete code is available for further\nadaptation and practical implementation, illustrating the convergence of remote\nsensing data and AI to address critical environmental challenges\n(https://github.com/IoannisNasios/HarmfulAlgalBloomDetection).", "AI": {"tldr": "A high-performing method for detecting harmful algal blooms using remote sensing data and AI models, combining tree-based and neural network approaches for robust classification.", "motivation": "The growing threat of harmful algal blooms to water quality and public health necessitates efficient, accurate, and cost-effective detection methods.", "method": "Integration of open-source remote sensing data (Sentinel-2, DEM, NOAA HRRR) with AI models (tree-based and neural network) into an ensemble for classifying algal bloom severity.", "result": "The ensemble approach, combining tree models and a neural network, improved robustness and demonstrated effective use of diverse remote sensing inputs.", "conclusion": "The method, initially developed for a U.S. competition, shows global potential and is openly available for adaptation, highlighting the synergy of remote sensing and AI for environmental challenges."}}
{"id": "2505.04201", "pdf": "https://arxiv.org/pdf/2505.04201", "abs": "https://arxiv.org/abs/2505.04201", "authors": ["Ning Cheng", "Jinan Xu", "Jialing Chen", "Wenjuan Han"], "title": "SToLa: Self-Adaptive Touch-Language Framework with Tactile Commonsense Reasoning in Open-Ended Scenarios", "categories": ["cs.CV"], "comment": null, "summary": "This paper explores the challenges of integrating tactile sensing into\nintelligent systems for multimodal reasoning, particularly in enabling\ncommonsense reasoning about the open-ended physical world. We identify two key\nchallenges: modality discrepancy, where existing large touch-language models\noften treat touch as a mere sub-modality of language, and open-ended tactile\ndata scarcity, where current datasets lack the diversity, open-endness and\ncomplexity needed for reasoning. To overcome these challenges, we introduce\nSToLa, a Self-Adaptive Touch-Language framework. SToLa utilizes Mixture of\nExperts (MoE) to dynamically process, unify, and manage tactile and language\nmodalities, capturing their unique characteristics. Crucially, we also present\na comprehensive tactile commonsense reasoning dataset and benchmark featuring\nfree-form questions and responses, 8 physical properties, 4 interactive\ncharacteristics, and diverse commonsense knowledge. Experiments show SToLa\nexhibits competitive performance compared to existing models on the PhysiCLeAR\nbenchmark and self-constructed datasets, proving the effectiveness of the\nMixture of Experts architecture in multimodal management and the performance\nadvantages for open-scenario tactile commonsense reasoning tasks.", "AI": {"tldr": "The paper introduces SToLa, a framework for integrating tactile sensing into multimodal reasoning, addressing modality discrepancy and data scarcity. It uses Mixture of Experts (MoE) and a new dataset for tactile commonsense reasoning.", "motivation": "To enable commonsense reasoning about the physical world by overcoming challenges in integrating tactile sensing, such as modality discrepancy and lack of diverse tactile data.", "method": "Proposes SToLa, a Self-Adaptive Touch-Language framework using Mixture of Experts (MoE) to dynamically manage tactile and language modalities, alongside a new tactile commonsense reasoning dataset.", "result": "SToLa shows competitive performance on benchmarks, demonstrating the effectiveness of MoE for multimodal management and tactile reasoning.", "conclusion": "The framework and dataset advance tactile commonsense reasoning, proving the value of MoE in handling open-ended multimodal tasks."}}
{"id": "2305.16867", "pdf": "https://arxiv.org/pdf/2305.16867", "abs": "https://arxiv.org/abs/2305.16867", "authors": ["Elif Akata", "Lion Schulz", "Julian Coda-Forno", "Seong Joon Oh", "Matthias Bethge", "Eric Schulz"], "title": "Playing repeated games with Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "LLMs are increasingly used in applications where they interact with humans\nand other agents. We propose to use behavioural game theory to study LLM's\ncooperation and coordination behaviour. We let different LLMs play finitely\nrepeated $2\\times2$ games with each other, with human-like strategies, and\nactual human players. Our results show that LLMs perform particularly well at\nself-interested games like the iterated Prisoner's Dilemma family. However,\nthey behave sub-optimally in games that require coordination, like the Battle\nof the Sexes. We verify that these behavioural signatures are stable across\nrobustness checks. We additionally show how GPT-4's behaviour can be modulated\nby providing additional information about its opponent and by using a \"social\nchain-of-thought\" (SCoT) strategy. This also leads to better scores and more\nsuccessful coordination when interacting with human players. These results\nenrich our understanding of LLM's social behaviour and pave the way for a\nbehavioural game theory for machines.", "AI": {"tldr": "The paper uses behavioral game theory to study LLMs' cooperation and coordination in repeated games, showing strong performance in self-interested games but sub-optimality in coordination games. GPT-4's behavior can be modulated for better human interaction.", "motivation": "To understand LLMs' social behavior in interactive settings using game theory, focusing on cooperation and coordination.", "method": "LLMs play finitely repeated 2\u00d72 games (e.g., Prisoner\u2019s Dilemma, Battle of the Sexes) with other LLMs, human-like strategies, and actual humans.", "result": "LLMs excel in self-interested games but struggle in coordination games. GPT-4's behavior improves with opponent info and social chain-of-thought (SCoT) strategies.", "conclusion": "The study advances understanding of LLMs' social behavior and lays groundwork for machine behavioral game theory."}}
{"id": "2505.03764", "pdf": "https://arxiv.org/pdf/2505.03764", "abs": "https://arxiv.org/abs/2505.03764", "authors": ["Logan Larsh", "Raiyan Siddique", "Sarah Sharif Yaser Mike Banad"], "title": "Ultra-Low-Power Spiking Neurons in 7 nm FinFET Technology: A Comparative Analysis of Leaky Integrate-and-Fire, Morris-Lecar, and Axon-Hillock Architectures", "categories": ["cs.NE", "cs.AI", "cs.AR"], "comment": null, "summary": "Neuromorphic computing aims to replicate the brain's remarkable energy\nefficiency and parallel processing capabilities for large-scale artificial\nintelligence applications. In this work, we present a comprehensive comparative\nstudy of three spiking neuron circuit architectures-Leaky-Integrate-and-Fire\n(LIF), Morris-Lecar (ML), and Axon-Hillock (AH)-implemented in a 7 nm FinFET\ntechnology. Through extensive SPICE simulations, we explore the optimization of\nspiking frequency, energy per spike, and static power consumption. Our results\nshow that the AH design achieves the highest throughput, demonstrating\nmulti-gigahertz firing rates (up to 3 GHz) with attojoule energy costs. By\ncontrast, the ML architecture excels in subthreshold to near-threshold regimes,\noffering robust low-power operation (as low as 0.385 aJ/spike) and biological\nbursting behavior. Although LIF benefits from a decoupled current mirror for\nhigh-frequency operation, it exhibits slightly higher static leakage compared\nto ML and AH at elevated supply voltages. Comparisons with previous node\nimplementations (22 nm planar, 28 nm) reveal that 7 nm FinFETs can drastically\nboost energy efficiency and speed albeit at the cost of increased subthreshold\nleakage in deep subthreshold regions. By quantifying design trade-offs for each\nneuron architecture, our work provides a roadmap for optimizing spiking neuron\ncircuits in advanced nanoscale technologies to deliver neuromorphic hardware\ncapable of both ultra-low-power operation and high computational throughput.", "AI": {"tldr": "A comparative study of three spiking neuron circuits (LIF, ML, AH) in 7 nm FinFET technology, highlighting their performance in speed, energy efficiency, and power consumption.", "motivation": "To replicate the brain's energy efficiency and parallel processing for AI by optimizing spiking neuron circuits in advanced nanoscale technologies.", "method": "Extensive SPICE simulations to evaluate spiking frequency, energy per spike, and static power consumption for LIF, ML, and AH architectures.", "result": "AH achieves highest throughput (3 GHz), ML excels in low-power regimes (0.385 aJ/spike), and LIF has higher leakage. 7 nm FinFETs improve efficiency but increase leakage.", "conclusion": "The study provides a roadmap for optimizing spiking neuron circuits to balance ultra-low-power operation and high computational throughput in neuromorphic hardware."}}
{"id": "2505.03809", "pdf": "https://arxiv.org/pdf/2505.03809", "abs": "https://arxiv.org/abs/2505.03809", "authors": ["Suorong Yang", "Peng Ye", "Furao Shen", "Dongzhan Zhou"], "title": "When Dynamic Data Selection Meets Data Augmentation", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Dynamic data selection aims to accelerate training with lossless performance.\nHowever, reducing training data inherently limits data diversity, potentially\nhindering generalization. While data augmentation is widely used to enhance\ndiversity, it is typically not optimized in conjunction with selection. As a\nresult, directly combining these techniques fails to fully exploit their\nsynergies. To tackle the challenge, we propose a novel online data training\nframework that, for the first time, unifies dynamic data selection and\naugmentation, achieving both training efficiency and enhanced performance. Our\nmethod estimates each sample's joint distribution of local density and\nmultimodal semantic consistency, allowing for the targeted selection of\naugmentation-suitable samples while suppressing the inclusion of noisy or\nambiguous data. This enables a more significant reduction in dataset size\nwithout sacrificing model generalization. Experimental results demonstrate that\nour method outperforms existing state-of-the-art approaches on various\nbenchmark datasets and architectures, e.g., reducing 50\\% training costs on\nImageNet-1k with lossless performance. Furthermore, our approach enhances noise\nresistance and improves model robustness, reinforcing its practical utility in\nreal-world scenarios.", "AI": {"tldr": "A novel framework unifies dynamic data selection and augmentation to improve training efficiency and model performance without sacrificing generalization.", "motivation": "Dynamic data selection alone limits diversity, while combining it with augmentation lacks optimization. The goal is to exploit their synergies for better efficiency and performance.", "method": "Proposes an online training framework that jointly estimates sample density and semantic consistency to select augmentation-suitable samples and exclude noisy data.", "result": "Outperforms state-of-the-art methods, reducing training costs by 50% on ImageNet-1k with no performance loss, while enhancing noise resistance and robustness.", "conclusion": "The unified approach effectively balances efficiency and performance, proving practical for real-world applications."}}
{"id": "2505.04207", "pdf": "https://arxiv.org/pdf/2505.04207", "abs": "https://arxiv.org/abs/2505.04207", "authors": ["Mustafa Yurdakul", "\u015eakir Tasdemir"], "title": "An Enhanced YOLOv8 Model for Real-Time and Accurate Pothole Detection and Measurement", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Potholes cause vehicle damage and traffic accidents, creating serious safety\nand economic problems. Therefore, early and accurate detection of potholes is\ncrucial. Existing detection methods are usually only based on 2D RGB images and\ncannot accurately analyze the physical characteristics of potholes. In this\npaper, a publicly available dataset of RGB-D images (PothRGBD) is created and\nan improved YOLOv8-based model is proposed for both pothole detection and\npothole physical features analysis. The Intel RealSense D415 depth camera was\nused to collect RGB and depth data from the road surfaces, resulting in a\nPothRGBD dataset of 1000 images. The data was labeled in YOLO format suitable\nfor segmentation. A novel YOLO model is proposed based on the YOLOv8n-seg\narchitecture, which is structurally improved with Dynamic Snake Convolution\n(DSConv), Simple Attention Module (SimAM) and Gaussian Error Linear Unit\n(GELU). The proposed model segmented potholes with irregular edge structure\nmore accurately, and performed perimeter and depth measurements on depth maps\nwith high accuracy. The standard YOLOv8n-seg model achieved 91.9% precision,\n85.2% recall and 91.9% mAP@50. With the proposed model, the values increased to\n93.7%, 90.4% and 93.8% respectively. Thus, an improvement of 1.96% in\nprecision, 6.13% in recall and 2.07% in mAP was achieved. The proposed model\nperforms pothole detection as well as perimeter and depth measurement with high\naccuracy and is suitable for real-time applications due to its low model\ncomplexity. In this way, a lightweight and effective model that can be used in\ndeep learning-based intelligent transportation solutions has been acquired.", "AI": {"tldr": "The paper introduces a new RGB-D dataset (PothRGBD) and an improved YOLOv8-based model for accurate pothole detection and physical feature analysis, achieving higher precision, recall, and mAP than the standard YOLOv8n-seg model.", "motivation": "Potholes cause safety and economic issues, but existing 2D RGB-based methods lack accuracy in analyzing physical characteristics. This work aims to improve detection and analysis using RGB-D data.", "method": "A dataset of 1000 RGB-D images (PothRGBD) was created using an Intel RealSense D415 camera. The improved YOLOv8n-seg model incorporates DSConv, SimAM, and GELU for better segmentation and feature analysis.", "result": "The proposed model achieved 93.7% precision, 90.4% recall, and 93.8% mAP@50, outperforming the standard YOLOv8n-seg model by 1.96%, 6.13%, and 2.07% respectively.", "conclusion": "The model is lightweight, accurate, and suitable for real-time applications, providing a practical solution for intelligent transportation systems."}}
{"id": "2308.15022", "pdf": "https://arxiv.org/pdf/2308.15022", "abs": "https://arxiv.org/abs/2308.15022", "authors": ["Qingyue Wang", "Yanhe Fu", "Yanan Cao", "Shuai Wang", "Zhiliang Tian", "Liang Ding"], "title": "Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recently, large language models (LLMs), such as GPT-4, stand out remarkable\nconversational abilities, enabling them to engage in dynamic and contextually\nrelevant dialogues across a wide range of topics. However, given a long\nconversation, these chatbots fail to recall past information and tend to\ngenerate inconsistent responses. To address this, we propose to recursively\ngenerate summaries/ memory using large language models (LLMs) to enhance\nlong-term memory ability. Specifically, our method first stimulates LLMs to\nmemorize small dialogue contexts and then recursively produce new memory using\nprevious memory and following contexts. Finally, the chatbot can easily\ngenerate a highly consistent response with the help of the latest memory. We\nevaluate our method on both open and closed LLMs, and the experiments on the\nwidely-used public dataset show that our method can generate more consistent\nresponses in a long-context conversation. Also, we show that our strategy could\nnicely complement both long-context (e.g., 8K and 16K) and retrieval-enhanced\nLLMs, bringing further long-term dialogue performance. Notably, our method is a\npotential solution to enable the LLM to model the extremely long context. The\ncode and scripts will be released later.", "AI": {"tldr": "Proposes recursive summarization for LLMs to improve long-term memory in conversations, enhancing response consistency.", "motivation": "LLMs like GPT-4 struggle with recalling past information in long conversations, leading to inconsistent responses.", "method": "Recursively generates summaries/memory from dialogue contexts, using previous memory and new contexts to aid response generation.", "result": "Improves response consistency in long-context conversations and complements existing long-context and retrieval-enhanced LLMs.", "conclusion": "The method is a potential solution for modeling extremely long contexts in LLMs, with code to be released."}}
{"id": "2505.03769", "pdf": "https://arxiv.org/pdf/2505.03769", "abs": "https://arxiv.org/abs/2505.03769", "authors": ["Yibo Hu", "Yiqiao Jin", "Meng Ye", "Ajay Divakaran", "Srijan Kumar"], "title": "The Influence of Text Variation on User Engagement in Cross-Platform Content Sharing", "categories": ["cs.SI", "cs.AI", "cs.IR"], "comment": null, "summary": "In today's cross-platform social media landscape, understanding factors that\ndrive engagement for multimodal content, especially text paired with visuals,\nremains complex. This study investigates how rewriting Reddit post titles\nadapted from YouTube video titles affects user engagement. First, we build and\nanalyze a large dataset of Reddit posts sharing YouTube videos, revealing that\n21% of post titles are minimally modified. Statistical analysis demonstrates\nthat title rewrites measurably improve engagement. Second, we design a\ncontrolled, multi-phase experiment to rigorously isolate the effects of textual\nvariations by neutralizing confounding factors like video popularity, timing,\nand community norms. Comprehensive statistical tests reveal that effective\ntitle rewrites tend to feature emotional resonance, lexical richness, and\nalignment with community-specific norms. Lastly, pairwise ranking prediction\nexperiments using a fine-tuned BERT classifier achieves 74% accuracy,\nsignificantly outperforming near-random baselines, including GPT-4o. These\nresults validate that our controlled dataset effectively minimizes confounding\neffects, allowing advanced models to both learn and demonstrate the impact of\ntextual features on engagement. By bridging quantitative rigor with qualitative\ninsights, this study uncovers engagement dynamics and offers a robust framework\nfor future cross-platform, multimodal content strategies.", "AI": {"tldr": "Rewriting Reddit post titles adapted from YouTube videos improves engagement, with effective rewrites featuring emotional resonance, lexical richness, and community alignment. A fine-tuned BERT model outperforms baselines in predicting engagement.", "motivation": "Understanding how title rewrites impact engagement in cross-platform social media, focusing on text-visual content.", "method": "Built a dataset of Reddit posts sharing YouTube videos, conducted statistical analysis, designed controlled experiments, and used a fine-tuned BERT model for prediction.", "result": "Title rewrites improve engagement; effective rewrites align with community norms and exhibit emotional and lexical richness. BERT achieved 74% accuracy in predicting engagement.", "conclusion": "The study provides insights into engagement dynamics and a framework for cross-platform content strategies, validated by rigorous analysis and advanced modeling."}}
{"id": "2505.03811", "pdf": "https://arxiv.org/pdf/2505.03811", "abs": "https://arxiv.org/abs/2505.03811", "authors": ["Surajit Chakrabarty", "Rukma Talwadker", "Tridib Mukherjee"], "title": "ScarceGAN: Discriminative Classification Framework for Rare Class Identification for Longitudinal Data with Weak Prior", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper introduces ScarceGAN which focuses on identification of extremely\nrare or scarce samples from multi-dimensional longitudinal telemetry data with\nsmall and weak label prior. We specifically address: (i) severe scarcity in\npositive class, stemming from both underlying organic skew in the data, as well\nas extremely limited labels; (ii) multi-class nature of the negative samples,\nwith uneven density distributions and partially overlapping feature\ndistributions; and (iii) massively unlabelled data leading to tiny and weak\nprior on both positive and negative classes, and possibility of unseen or\nunknown behavior in the unlabelled set, especially in the negative class.\nAlthough related to PU learning problems, we contend that knowledge (or lack of\nit) on the negative class can be leveraged to learn the compliment of it (i.e.,\nthe positive class) better in a semi-supervised manner. To this effect,\nScarceGAN re-formulates semi-supervised GAN by accommodating weakly labelled\nmulti-class negative samples and the available positive samples. It relaxes the\nsupervised discriminator's constraint on exact differentiation between negative\nsamples by introducing a 'leeway' term for samples with noisy prior. We propose\nmodifications to the cost objectives of discriminator, in supervised and\nunsupervised path as well as that of the generator. For identifying risky\nplayers in skill gaming, this formulation in whole gives us a recall of over\n85% (~60% jump over vanilla semi-supervised GAN) on our scarce class with very\nminimal verbosity in the unknown space. Further ScarceGAN outperforms the\nrecall benchmarks established by recent GAN based specialized models for the\npositive imbalanced class identification and establishes a new benchmark in\nidentifying one of rare attack classes (0.09%) in the intrusion dataset from\nthe KDDCUP99 challenge.", "AI": {"tldr": "ScarceGAN improves rare sample identification in multi-dimensional longitudinal data by leveraging weak labels and semi-supervised GANs, achieving high recall with minimal noise.", "motivation": "Addressing challenges like severe scarcity of positive samples, multi-class negative samples with uneven distributions, and weak label priors in unlabelled data.", "method": "Reformulates semi-supervised GANs to accommodate weak labels, introduces a 'leeway' term for noisy samples, and modifies cost objectives for discriminator and generator.", "result": "Achieves over 85% recall on scarce classes (60% improvement over vanilla GANs) and outperforms benchmarks in rare attack class identification (0.09% in KDDCUP99).", "conclusion": "ScarceGAN effectively leverages weak labels and semi-supervised learning to identify rare samples, setting new benchmarks in imbalanced class identification."}}
{"id": "2505.04214", "pdf": "https://arxiv.org/pdf/2505.04214", "abs": "https://arxiv.org/abs/2505.04214", "authors": ["Fabian Wolf", "Oliver T\u00fcselmann", "Arthur Matei", "Lukas Hennies", "Christoph Rass", "Gernot A. Fink"], "title": "CM1 -- A Dataset for Evaluating Few-Shot Information Extraction with Large Vision Language Models", "categories": ["cs.CV"], "comment": null, "summary": "The automatic extraction of key-value information from handwritten documents\nis a key challenge in document analysis. A reliable extraction is a\nprerequisite for the mass digitization efforts of many archives. Large Vision\nLanguage Models (LVLM) are a promising technology to tackle this problem\nespecially in scenarios where little annotated training data is available. In\nthis work, we present a novel dataset specifically designed to evaluate the\nfew-shot capabilities of LVLMs. The CM1 documents are a historic collection of\nforms with handwritten entries created in Europe to administer the Care and\nMaintenance program after World War Two. The dataset establishes three\nbenchmarks on extracting name and birthdate information and, furthermore,\nconsiders different training set sizes. We provide baseline results for two\ndifferent LVLMs and compare performances to an established full-page extraction\nmodel. While the traditional full-page model achieves highly competitive\nperformances, our experiments show that when only a few training samples are\navailable the considered LVLMs benefit from their size and heavy pretraining\nand outperform the classical approach.", "AI": {"tldr": "The paper introduces a dataset (CM1) to evaluate few-shot capabilities of Large Vision Language Models (LVLMs) for extracting key-value info from handwritten documents, showing LVLMs outperform traditional methods with limited training data.", "motivation": "To address the challenge of extracting key-value info from handwritten documents, especially with scarce annotated data, using LVLMs for mass digitization in archives.", "method": "A novel dataset (CM1) of historic forms is used to benchmark LVLMs on extracting name and birthdate info, comparing them to a full-page extraction model under varying training set sizes.", "result": "LVLMs outperform traditional full-page models when few training samples are available, leveraging their size and pretraining.", "conclusion": "LVLMs are effective for few-shot extraction tasks in document analysis, offering advantages over classical methods in low-data scenarios."}}
{"id": "2403.19346", "pdf": "https://arxiv.org/pdf/2403.19346", "abs": "https://arxiv.org/abs/2403.19346", "authors": ["Jingyuan Ma", "Damai Dai", "Zihang Yuan", "Rui li", "Weilin Luo", "Bin Wang", "Qun Liu", "Lei Sha", "Zhifang Sui"], "title": "Large Language Models Are Struggle to Cope with Unreasonability in Math Problems", "categories": ["cs.CL"], "comment": "32 pages, 8 figures", "summary": "Recent research have demonstrated LLMs' impressive performance in math and\nreasoning. However, the capacity of LLMs to address math problems under\nunconventional conditions, such as internal inconsistencies and flawed\nassumptions, remains largely unexplored. In this paper, we propose a novel\nbenchmark Unreasonable Math Problem (UMP) designed to assess LLMs' ability to\nrecognize and respond to unreasonability in math problem. The benchmark\nconsists of a carefully curated collection of unreasonable math questions\nacross diverse types. Based on extensive experiments covering 19 LLMs, we\nobserve that even state-of-the-art models such as GPT-4o achieve only limited\nperformance of 0.6 in UMP, while reasoning models such as DeepSeek-R1 are prone\nto overthinking and unstable. We further explore strategies for improving the\nrecognition of unreasonable inputs, shedding light on both the possibility and\nlimitations of LLMs in this challenging setting.", "AI": {"tldr": "A new benchmark, Unreasonable Math Problem (UMP), evaluates LLMs' ability to handle unconventional math problems with flaws. State-of-the-art models like GPT-4o perform poorly (0.6 score), and reasoning models like DeepSeek-R1 are unstable. The study explores improvement strategies and limitations.", "motivation": "To assess LLMs' capability in recognizing and responding to unreasonable math problems, an underexplored area.", "method": "Proposed the UMP benchmark with diverse unreasonable math questions, tested on 19 LLMs.", "result": "GPT-4o scored 0.6 in UMP; reasoning models like DeepSeek-R1 were unstable.", "conclusion": "LLMs struggle with unreasonable math problems, highlighting their limitations and the need for further research."}}
{"id": "2505.03780", "pdf": "https://arxiv.org/pdf/2505.03780", "abs": "https://arxiv.org/abs/2505.03780", "authors": ["Burkhard Ringlein", "Thomas Parnell", "Radu Stoica"], "title": "GPU Performance Portability needs Autotuning", "categories": ["cs.AR", "cs.AI", "cs.PL"], "comment": null, "summary": "As LLMs grow in complexity, achieving state-of-the-art performance requires\ntight co-design across algorithms, software, and hardware. Today's reliance on\na single dominant platform limits portability, creates vendor lock-in, and\nraises barriers for new AI hardware. In this work, we make the case for\ncombining just-in-time (JIT) compilation with kernel parameter autotuning to\nenable portable, state-of-the-art performance LLM execution without code\nchanges. Focusing on flash attention -- a widespread performance-critical LLM\nkernel -- we demonstrate that this approach explores up to 15x more kernel\nparameter configurations, produces significantly more diverse code across\nmultiple dimensions, and even outperforms vendor-optimized implementations by\nup to 230%, all while reducing kernel code size by 70x and eliminating manual\ncode optimizations. Our results highlight autotuning as a promising path to\nunlocking model portability across GPU vendors.", "AI": {"tldr": "Combining JIT compilation and kernel parameter autotuning enables portable, high-performance LLM execution without code changes, outperforming vendor-optimized implementations.", "motivation": "Addressing limitations of single-platform reliance, vendor lock-in, and barriers for new AI hardware by enabling portable LLM performance.", "method": "Uses JIT compilation and autotuning for flash attention, exploring more kernel configurations and diverse code.", "result": "Achieves up to 230% better performance than vendor-optimized implementations, reduces kernel code size by 70x, and eliminates manual optimizations.", "conclusion": "Autotuning is a promising approach for model portability across GPU vendors."}}
{"id": "2505.03812", "pdf": "https://arxiv.org/pdf/2505.03812", "abs": "https://arxiv.org/abs/2505.03812", "authors": ["Tomaso Aste"], "title": "Information Filtering Networks: Theoretical Foundations, Generative Methodologies, and Real-World Applications", "categories": ["cs.LG"], "comment": null, "summary": "Information Filtering Networks (IFNs) provide a powerful framework for\nmodeling complex systems through globally sparse yet locally dense and\ninterpretable structures that capture multivariate dependencies. This review\noffers a comprehensive account of IFNs, covering their theoretical foundations,\nconstruction methodologies, and diverse applications. Tracing their origins\nfrom early network-based models to advanced formulations such as the\nTriangulated Maximally Filtered Graph (TMFG) and the Maximally Filtered Clique\nForest (MFCF), the paper highlights how IFNs address key challenges in\nhigh-dimensional data-driven modeling. IFNs and their construction\nmethodologies are intrinsically higher-order networks that generate simplicial\ncomplexes-structures that are only now becoming popular in the broader\nliterature. Applications span fields including finance, biology, psychology,\nand artificial intelligence, where IFNs improve interpretability, computational\nefficiency, and predictive performance. Special attention is given to their\nrole in graphical modeling, where IFNs enable the estimation of sparse inverse\ncovariance matrices with greater accuracy and scalability than traditional\napproaches like Graphical LASSO. Finally, the review discusses recent\ndevelopments that integrate IFNs with machine learning and deep learning,\nunderscoring their potential not only to bridge classical network theory with\ncontemporary data-driven paradigms, but also to shape the architectures of deep\nlearning models themselves.", "AI": {"tldr": "A review of Information Filtering Networks (IFNs), covering their theory, methods, applications, and integration with modern machine learning.", "motivation": "To address challenges in high-dimensional data modeling by leveraging IFNs for interpretable, efficient, and scalable solutions.", "method": "Discusses IFN construction methodologies like TMFG and MFCF, which generate simplicial complexes for capturing multivariate dependencies.", "result": "IFNs improve interpretability, computational efficiency, and predictive performance across fields like finance, biology, and AI.", "conclusion": "IFNs bridge classical network theory with modern data-driven approaches and show potential in shaping deep learning architectures."}}
{"id": "2505.04229", "pdf": "https://arxiv.org/pdf/2505.04229", "abs": "https://arxiv.org/abs/2505.04229", "authors": ["Theophilus Aidoo", "Till Koebe", "Akansh Maurya", "Hewan Shrestha", "Ingmar Weber"], "title": "A Weak Supervision Learning Approach Towards an Equitable Parking Lot Occupancy Estimation", "categories": ["cs.CV", "cs.CY"], "comment": null, "summary": "The scarcity and high cost of labeled high-resolution imagery have long\nchallenged remote sensing applications, particularly in low-income regions\nwhere high-resolution data are scarce. In this study, we propose a weak\nsupervision framework that estimates parking lot occupancy using 3m resolution\nsatellite imagery. By leveraging coarse temporal labels -- based on the\nassumption that parking lots of major supermarkets and hardware stores in\nGermany are typically full on Saturdays and empty on Sundays -- we train a\npairwise comparison model that achieves an AUC of 0.92 on large parking lots.\nThe proposed approach minimizes the reliance on expensive high-resolution\nimages and holds promise for scalable urban mobility analysis. Moreover, the\nmethod can be adapted to assess transit patterns and resource allocation in\nvulnerable communities, providing a data-driven basis to improve the well-being\nof those most in need.", "AI": {"tldr": "A weak supervision framework uses 3m satellite imagery and coarse temporal labels to estimate parking lot occupancy, achieving high accuracy with minimal reliance on expensive high-resolution data.", "motivation": "Addressing the scarcity and high cost of labeled high-resolution imagery, especially in low-income regions, by proposing a cost-effective solution for remote sensing applications.", "method": "Leverages coarse temporal labels (e.g., full on Saturdays, empty on Sundays) to train a pairwise comparison model using 3m resolution satellite imagery.", "result": "Achieves an AUC of 0.92 on large parking lots, demonstrating high accuracy.", "conclusion": "The framework is scalable for urban mobility analysis and adaptable for transit patterns and resource allocation in vulnerable communities, offering data-driven insights to improve well-being."}}
{"id": "2406.01495", "pdf": "https://arxiv.org/pdf/2406.01495", "abs": "https://arxiv.org/abs/2406.01495", "authors": ["Zi-Yi Dou", "Cheng-Fu Yang", "Xueqing Wu", "Kai-Wei Chang", "Nanyun Peng"], "title": "Re-ReST: Reflection-Reinforced Self-Training for Language Agents", "categories": ["cs.CL"], "comment": null, "summary": "Finetuning language agents with reasoning-action trajectories is effective,\nbut obtaining these trajectories from human annotations or stronger models is\ncostly and sometimes impractical. In this paper, we investigate the use of\nself-training in language agents, which can generate supervision from the agent\nitself, offering a promising alternative without relying on human or stronger\nmodel demonstrations. Self-training, however, requires high-quality\nmodel-generated samples, which are hard to obtain for challenging language\nagent tasks. To address this, we present Reflection-Reinforced Self-Training\n(Re-ReST), which uses a \\textit{reflector} to refine low-quality generated\nsamples during self-training. The reflector takes the agent's output and\nfeedback from an external environment (e.g., unit test results in code\ngeneration) to produce improved samples. This technique enhances the quality of\ninferior samples and efficiently enriches the self-training dataset with\nhigher-quality samples. We conduct extensive experiments on open-source\nlanguage agents across tasks, including multi-hop question answering,\nsequential decision-making, code generation, visual question answering, and\ntext-to-image generation. The results demonstrate the effectiveness of\nself-training and Re-ReST in language agent tasks, with self-training improving\nbaselines by 7.6\\% on HotpotQA and 28.4\\% on AlfWorld, and Re-ReST further\nboosting performance by 2.0\\% and 14.1\\%, respectively. Our studies also\nconfirm the efficiency of using a reflector to generate high-quality samples\nfor self-training. Moreover, we demonstrate a method to employ reflection\nduring inference without ground-truth feedback, addressing the limitation of\nprevious reflection work. Our code is released at\nhttps://github.com/PlusLabNLP/Re-ReST.", "AI": {"tldr": "The paper introduces Reflection-Reinforced Self-Training (Re-ReST) to improve language agents by refining low-quality self-generated samples using a reflector, achieving significant performance boosts.", "motivation": "To reduce reliance on costly human or stronger model annotations for finetuning language agents, the paper explores self-training and enhances it with reflection.", "method": "Proposes Re-ReST, where a reflector refines low-quality self-generated samples using external feedback (e.g., unit test results), enriching the self-training dataset.", "result": "Self-training improves baselines by 7.6% on HotpotQA and 28.4% on AlfWorld; Re-ReST further boosts performance by 2.0% and 14.1%, respectively.", "conclusion": "Re-ReST effectively enhances self-training for language agents, demonstrating the reflector's efficiency and addressing limitations of prior reflection methods."}}
{"id": "2505.03795", "pdf": "https://arxiv.org/pdf/2505.03795", "abs": "https://arxiv.org/abs/2505.03795", "authors": ["Jacob W. Crandall", "Jonathan Skaggs"], "title": "Modeling Human Behavior in a Strategic Network Game with Complex Group Dynamics", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "Human networks greatly impact important societal outcomes, including wealth\nand health inequality, poverty, and bullying. As such, understanding human\nnetworks is critical to learning how to promote favorable societal outcomes. As\na step toward better understanding human networks, we compare and contrast\nseveral methods for learning models of human behavior in a strategic network\ngame called the Junior High Game (JHG). These modeling methods differ with\nrespect to the assumptions they use to parameterize human behavior (behavior\nvs. community-aware behavior) and the statistical moments they model (mean vs.\ndistribution). Results show that the highest-performing method models the\npopulation's distribution rather than the mean and assumes humans use\ncommunity-aware behavior rather than behavior matching. When applied to small\nsocieties (6-11 individuals), this learned model, called hCAB, closely mirrors\nthe population dynamics of human groups (with some differences). Additionally,\na user study reveals that human participants were unable to distinguish hCAB\nagents from other humans, thus illustrating that individual hCAB behavior\nplausibly mirrors human behavior in this strategic network game.", "AI": {"tldr": "The paper compares methods for modeling human behavior in a strategic network game (JHG), finding that community-aware behavior and distribution modeling outperform alternatives. The hCAB model closely mirrors human group dynamics and is indistinguishable from humans in tests.", "motivation": "Understanding human networks is crucial for addressing societal issues like inequality and bullying. This study aims to improve modeling of human behavior in strategic network games.", "method": "Several methods are compared, differing in assumptions (behavior vs. community-aware) and statistical moments (mean vs. distribution). The hCAB model is developed and tested.", "result": "hCAB, which models distribution and assumes community-aware behavior, performs best, closely matching human group dynamics and being indistinguishable from humans in tests.", "conclusion": "The hCAB model effectively mirrors human behavior in strategic network games, offering insights for understanding and improving societal outcomes."}}
{"id": "2505.03818", "pdf": "https://arxiv.org/pdf/2505.03818", "abs": "https://arxiv.org/abs/2505.03818", "authors": ["Antonio Valerio Miceli-Barone", "Vaishak Belle", "Ali Payani"], "title": "Program Semantic Inequivalence Game with Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) can achieve strong performance on everyday\ncoding tasks, but they can fail on complex tasks that require non-trivial\nreasoning about program semantics. Finding training examples to teach LLMs to\nsolve these tasks can be challenging.\n  In this work, we explore a method to synthetically generate code reasoning\ntraining data based on a semantic inequivalence game SInQ: a generator agent\ncreates program variants that are semantically distinct, derived from a dataset\nof real-world programming tasks, while an evaluator agent has to identify input\nexamples that cause the original programs and the generated variants to diverge\nin their behaviour, with the agents training each other semi-adversarially. We\nprove that this setup enables theoretically unlimited improvement through\nself-play in the limit of infinite computational resources.\n  We evaluated our approach on multiple code generation and understanding\nbenchmarks, including cross-language vulnerability detection (Lu et al., 2021),\nwhere our method improves vulnerability detection in C/C++ code despite being\ntrained exclusively on Python code, and the challenging Python builtin\nidentifier swap benchmark (Miceli-Barone et al., 2023), showing that whereas\nmodern LLMs still struggle with this benchmark, our approach yields substantial\nimprovements.\n  We release the code needed to replicate the experiments, as well as the\ngenerated synthetic data, which can be used to fine-tune LLMs.", "AI": {"tldr": "A method called SInQ generates synthetic code reasoning training data using a generator and evaluator agent in a semi-adversarial setup, improving LLM performance on complex tasks.", "motivation": "LLMs struggle with complex coding tasks requiring deep reasoning, and obtaining training data for such tasks is challenging.", "method": "SInQ involves a generator agent creating semantically distinct program variants and an evaluator agent identifying divergent inputs, training each other semi-adversarially.", "result": "The method improves performance on benchmarks like cross-language vulnerability detection and Python identifier swap tasks.", "conclusion": "SInQ enables scalable synthetic data generation for training LLMs on complex reasoning tasks, with released code and data for replication."}}
{"id": "2505.04262", "pdf": "https://arxiv.org/pdf/2505.04262", "abs": "https://arxiv.org/abs/2505.04262", "authors": ["Feng Yang", "Wenliang Qian", "Wangmeng Zuo", "Hui Li"], "title": "Bridging Geometry-Coherent Text-to-3D Generation with Multi-View Diffusion Priors and Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "Score Distillation Sampling (SDS) leverages pretrained 2D diffusion models to\nadvance text-to-3D generation but neglects multi-view correlations, being prone\nto geometric inconsistencies and multi-face artifacts in the generated 3D\ncontent. In this work, we propose Coupled Score Distillation (CSD), a framework\nthat couples multi-view joint distribution priors to ensure geometrically\nconsistent 3D generation while enabling the stable and direct optimization of\n3D Gaussian Splatting. Specifically, by reformulating the optimization as a\nmulti-view joint optimization problem, we derive an effective optimization rule\nthat effectively couples multi-view priors to guide optimization across\ndifferent viewpoints while preserving the diversity of generated 3D assets.\nAdditionally, we propose a framework that directly optimizes 3D Gaussian\nSplatting (3D-GS) with random initialization to generate geometrically\nconsistent 3D content. We further employ a deformable tetrahedral grid,\ninitialized from 3D-GS and refined through CSD, to produce high-quality,\nrefined meshes. Quantitative and qualitative experimental results demonstrate\nthe efficiency and competitive quality of our approach.", "AI": {"tldr": "CSD improves 3D generation by coupling multi-view priors, addressing SDS's geometric inconsistencies and artifacts.", "motivation": "SDS lacks multi-view correlation, leading to geometric flaws in 3D generation.", "method": "CSD reformulates optimization as a multi-view joint problem, directly optimizes 3D Gaussian Splatting, and uses a deformable tetrahedral grid.", "result": "CSD produces geometrically consistent 3D content with high-quality meshes.", "conclusion": "CSD outperforms SDS in efficiency and quality for text-to-3D generation."}}
{"id": "2406.02044", "pdf": "https://arxiv.org/pdf/2406.02044", "abs": "https://arxiv.org/abs/2406.02044", "authors": ["Hussein Jawad", "Yassine Chenik", "Nicolas J. -B. Brunel"], "title": "Towards Universal and Black-Box Query-Response Only Attack on LLMs with QROA", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "The rapid adoption of Large Language Models (LLMs) has exposed critical\nsecurity and ethical vulnerabilities, particularly their susceptibility to\nadversarial manipulations. This paper introduces QROA, a novel black-box\njailbreak method designed to identify adversarial suffixes that can bypass LLM\nalignment safeguards when appended to a malicious instruction. Unlike existing\nsuffix-based jailbreak approaches, QROA does not require access to the model's\nlogit or any other internal information. It also eliminates reliance on\nhuman-crafted templates, operating solely through the standard query-response\ninterface of LLMs. By framing the attack as an optimization bandit problem,\nQROA employs a surrogate model and token level optimization to efficiently\nexplore suffix variations. Furthermore, we propose QROA-UNV, an extension that\nidentifies universal adversarial suffixes for individual models, enabling\none-query jailbreaks across a wide range of instructions. Testing on multiple\nmodels demonstrates Attack Success Rate (ASR) greater than 80\\%. These findings\nhighlight critical vulnerabilities, emphasize the need for advanced defenses,\nand contribute to the development of more robust safety evaluations for secure\nAI deployment. The code is made public on the following link:\nhttps://github.com/qroa/QROA", "AI": {"tldr": "QROA is a black-box jailbreak method for LLMs that identifies adversarial suffixes without needing internal model access or human templates, achieving over 80% ASR.", "motivation": "To address security vulnerabilities in LLMs by exposing their susceptibility to adversarial manipulations.", "method": "QROA frames the attack as an optimization bandit problem, using a surrogate model and token-level optimization. QROA-UNV extends this to find universal adversarial suffixes.", "result": "Achieves over 80% Attack Success Rate (ASR) on multiple models.", "conclusion": "Highlights critical LLM vulnerabilities, urging advanced defenses and robust safety evaluations for secure AI deployment."}}
{"id": "2505.03796", "pdf": "https://arxiv.org/pdf/2505.03796", "abs": "https://arxiv.org/abs/2505.03796", "authors": ["Lokesh Koli", "Shubham Kalra", "Rohan Thakur", "Anas Saifi", "Karanpreet Singh"], "title": "AI-Driven IRM: Transforming insider risk management with adaptive scoring and LLM-based threat detection", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Insider threats pose a significant challenge to organizational security,\noften evading traditional rule-based detection systems due to their subtlety\nand contextual nature. This paper presents an AI-powered Insider Risk\nManagement (IRM) system that integrates behavioral analytics, dynamic risk\nscoring, and real-time policy enforcement to detect and mitigate insider\nthreats with high accuracy and adaptability. We introduce a hybrid scoring\nmechanism - transitioning from the static PRISM model to an adaptive AI-based\nmodel utilizing an autoencoder neural network trained on expert-annotated user\nactivity data. Through iterative feedback loops and continuous learning, the\nsystem reduces false positives by 59% and improves true positive detection\nrates by 30%, demonstrating substantial gains in detection precision.\nAdditionally, the platform scales efficiently, processing up to 10 million log\nevents daily with sub-300ms query latency, and supports automated enforcement\nactions for policy violations, reducing manual intervention. The IRM system's\ndeployment resulted in a 47% reduction in incident response times, highlighting\nits operational impact. Future enhancements include integrating explainable AI,\nfederated learning, graph-based anomaly detection, and alignment with Zero\nTrust principles to further elevate its adaptability, transparency, and\ncompliance-readiness. This work establishes a scalable and proactive framework\nfor mitigating emerging insider risks in both on-premises and hybrid\nenvironments.", "AI": {"tldr": "An AI-powered Insider Risk Management (IRM) system improves insider threat detection by 30% and reduces false positives by 59%, scaling to 10M daily log events with sub-300ms latency.", "motivation": "Traditional rule-based systems fail to detect subtle insider threats, necessitating an adaptive, AI-driven approach.", "method": "Hybrid scoring mechanism (PRISM to AI-based autoencoder), behavioral analytics, dynamic risk scoring, and real-time policy enforcement.", "result": "59% fewer false positives, 30% higher true positives, 47% faster incident response, and scalable processing.", "conclusion": "The IRM system is scalable and proactive, with future enhancements like explainable AI and Zero Trust alignment."}}
{"id": "2505.03819", "pdf": "https://arxiv.org/pdf/2505.03819", "abs": "https://arxiv.org/abs/2505.03819", "authors": ["Johannes Schneider"], "title": "Focus on the Likely: Test-time Instance-based Uncertainty Removal", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We propose two novel test-time fine-tuning methods to improve uncertain model\npredictions. Our methods require no auxiliary data and use the given test\ninstance only. Instead of performing a greedy selection of the most likely\nclass to make a prediction, we introduce an additional focus on the likely\nclasses step during inference. By applying a single-step gradient descent, we\nrefine predictions when an initial forward pass indicates high uncertainty.\nThis aligns predictions more closely with the ideal of assigning zero\nprobability to less plausible outcomes. Our theoretical discussion provides a\ndeeper understanding highlighting the impact on shared and non-shared features\namong (focus) classes. The experimental evaluation highlights accuracy gains on\nsamples exhibiting high decision uncertainty for a diverse set of models from\nboth the text and image domain using the same hyperparameters.", "AI": {"tldr": "Two test-time fine-tuning methods improve uncertain model predictions by refining likely classes during inference, without auxiliary data.", "motivation": "To enhance model predictions by addressing uncertainty without needing extra data.", "method": "Introduces a focus on likely classes during inference and uses single-step gradient descent to refine predictions.", "result": "Improved accuracy on high-uncertainty samples across text and image models with consistent hyperparameters.", "conclusion": "The methods effectively refine predictions by reducing uncertainty and aligning probabilities with plausible outcomes."}}
{"id": "2505.04270", "pdf": "https://arxiv.org/pdf/2505.04270", "abs": "https://arxiv.org/abs/2505.04270", "authors": ["Yisen Feng", "Haoyu Zhang", "Meng Liu", "Weili Guan", "Liqiang Nie"], "title": "Object-Shot Enhanced Grounding Network for Egocentric Video", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by CVPR 2025", "summary": "Egocentric video grounding is a crucial task for embodied intelligence\napplications, distinct from exocentric video moment localization. Existing\nmethods primarily focus on the distributional differences between egocentric\nand exocentric videos but often neglect key characteristics of egocentric\nvideos and the fine-grained information emphasized by question-type queries. To\naddress these limitations, we propose OSGNet, an Object-Shot enhanced Grounding\nNetwork for egocentric video. Specifically, we extract object information from\nvideos to enrich video representation, particularly for objects highlighted in\nthe textual query but not directly captured in the video features.\nAdditionally, we analyze the frequent shot movements inherent to egocentric\nvideos, leveraging these features to extract the wearer's attention\ninformation, which enhances the model's ability to perform modality alignment.\nExperiments conducted on three datasets demonstrate that OSGNet achieves\nstate-of-the-art performance, validating the effectiveness of our approach. Our\ncode can be found at https://github.com/Yisen-Feng/OSGNet.", "AI": {"tldr": "OSGNet improves egocentric video grounding by leveraging object information and shot movements, outperforming existing methods.", "motivation": "Existing methods overlook key egocentric video traits and fine-grained query details, limiting performance.", "method": "OSGNet enriches video representation with object data and analyzes shot movements to align modalities.", "result": "OSGNet achieves state-of-the-art results on three datasets.", "conclusion": "OSGNet effectively addresses egocentric video grounding challenges, validated by superior performance."}}
{"id": "2406.18501", "pdf": "https://arxiv.org/pdf/2406.18501", "abs": "https://arxiv.org/abs/2406.18501", "authors": ["Zhenghao Zhou", "Robert Frank", "R. Thomas McCoy"], "title": "Is In-Context Learning a Type of Error-Driven Learning? Evidence from the Inverse Frequency Effect in Structural Priming", "categories": ["cs.CL"], "comment": "This version is accepted to NAACL 2025\n  (https://aclanthology.org/2025.naacl-long.586/)", "summary": "Large language models (LLMs) have shown the emergent capability of in-context\nlearning (ICL). One line of research has claimed that ICL is functionally\nequivalent to gradient descent, a type of error-driven learning mechanism. In\nthis paper, we introduce a new way of diagnosing whether ICL is functionally\nperforming error-driven learning. Our approach is based on the inverse\nfrequency effect (IFE) -- a phenomenon in which an agent's behavior is\ninfluenced to a greater degree when presented with improbable examples as\ncompared to more likely ones. The IFE has previously been identified in\npsycholinguistics where humans exhibit the IFE in the context of structural\npriming (the tendency for people to produce sentence structures they have\nencountered recently). In that context, the IFE has been used as evidence that\nhuman structural priming must involve error-driven learning mechanisms. In our\nexperiments, we simulated structural priming with ICL and found that LLMs\nindeed display the IFE, with the effect being stronger in larger models. We\nconclude that at least in the case we studied, ICL is indeed a type of\nerror-driven learning, supporting the hypothesis that an error signal is\nimplicitly computed in the forward pass during ICL. Our results suggest that\nboth humans and LLMs make use of error-driven processing mechanisms in on-line\nprocessing.", "AI": {"tldr": "The paper investigates whether in-context learning (ICL) in large language models (LLMs) is functionally equivalent to error-driven learning, using the inverse frequency effect (IFE) as evidence.", "motivation": "To diagnose if ICL in LLMs involves error-driven learning mechanisms, inspired by the IFE observed in human psycholinguistics.", "method": "Simulated structural priming with ICL and analyzed the IFE in LLMs, comparing effects across model sizes.", "result": "LLMs exhibited the IFE, with stronger effects in larger models, suggesting ICL involves error-driven learning.", "conclusion": "ICL in LLMs is a form of error-driven learning, aligning with human cognitive processing mechanisms."}}
{"id": "2505.03822", "pdf": "https://arxiv.org/pdf/2505.03822", "abs": "https://arxiv.org/abs/2505.03822", "authors": ["Hao Wu", "Jialiang Wang"], "title": "DRSLF: Double Regularized Second-Order Low-Rank Representation for Web Service QoS Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Quality-of-Service (QoS) data plays a crucial role in cloud service\nselection. Since users cannot access all services, QoS can be represented by a\nhigh-dimensional and incomplete (HDI) matrix. Latent factor analysis (LFA)\nmodels have been proven effective as low-rank representation techniques for\naddressing this issue. However, most LFA models rely on first-order optimizers\nand use L2-norm regularization, which can lead to lower QoS prediction\naccuracy. To address this issue, this paper proposes a double regularized\nsecond-order latent factor (DRSLF) model with two key ideas: a) integrating\nL1-norm and L2-norm regularization terms to enhance the low-rank representation\nperformance; b) incorporating second-order information by calculating the\nHessian-vector product in each conjugate gradient step. Experimental results on\ntwo real-world response-time QoS datasets demonstrate that DRSLF has a higher\nlow-rank representation capability than two baselines.", "AI": {"tldr": "The paper proposes a double regularized second-order latent factor (DRSLF) model to improve QoS prediction accuracy in cloud services by combining L1/L2-norm regularization and second-order optimization.", "motivation": "Existing latent factor analysis models for QoS data rely on first-order optimizers and L2-norm regularization, leading to lower prediction accuracy.", "method": "The DRSLF model integrates L1/L2-norm regularization and uses second-order information (Hessian-vector product) in conjugate gradient steps.", "result": "Experiments on real-world QoS datasets show DRSLF outperforms baselines in low-rank representation.", "conclusion": "DRSLF enhances QoS prediction accuracy by leveraging double regularization and second-order optimization."}}
{"id": "2505.04281", "pdf": "https://arxiv.org/pdf/2505.04281", "abs": "https://arxiv.org/abs/2505.04281", "authors": ["Yi Li", "Zhiyuan Zhang", "Jiangnan Xia", "Jianghan Cheng", "Qilong Wu", "Junwei Li", "Yibin Tian", "Hui Kong"], "title": "TS-Diff: Two-Stage Diffusion Model for Low-Light RAW Image Enhancement", "categories": ["cs.CV"], "comment": "International Joint Conference on Neural Networks (IJCNN)", "summary": "This paper presents a novel Two-Stage Diffusion Model (TS-Diff) for enhancing\nextremely low-light RAW images. In the pre-training stage, TS-Diff synthesizes\nnoisy images by constructing multiple virtual cameras based on a noise space.\nCamera Feature Integration (CFI) modules are then designed to enable the model\nto learn generalizable features across diverse virtual cameras. During the\naligning stage, CFIs are averaged to create a target-specific CFI$^T$, which is\nfine-tuned using a small amount of real RAW data to adapt to the noise\ncharacteristics of specific cameras. A structural reparameterization technique\nfurther simplifies CFI$^T$ for efficient deployment. To address color shifts\nduring the diffusion process, a color corrector is introduced to ensure color\nconsistency by dynamically adjusting global color distributions. Additionally,\na novel dataset, QID, is constructed, featuring quantifiable illumination\nlevels and a wide dynamic range, providing a comprehensive benchmark for\ntraining and evaluation under extreme low-light conditions. Experimental\nresults demonstrate that TS-Diff achieves state-of-the-art performance on\nmultiple datasets, including QID, SID, and ELD, excelling in denoising,\ngeneralization, and color consistency across various cameras and illumination\nlevels. These findings highlight the robustness and versatility of TS-Diff,\nmaking it a practical solution for low-light imaging applications. Source codes\nand models are available at https://github.com/CircccleK/TS-Diff", "AI": {"tldr": "TS-Diff is a Two-Stage Diffusion Model for enhancing extremely low-light RAW images, using virtual cameras, CFI modules, and a color corrector, achieving state-of-the-art performance.", "motivation": "To address challenges in enhancing low-light RAW images, including noise, color shifts, and lack of generalizable models for diverse cameras.", "method": "Uses a two-stage approach: pre-training with virtual cameras and CFI modules, followed by fine-tuning with real RAW data and structural reparameterization. Introduces a color corrector for consistency.", "result": "Achieves top performance on QID, SID, and ELD datasets, excelling in denoising, generalization, and color consistency.", "conclusion": "TS-Diff is robust and versatile, offering a practical solution for low-light imaging, with code and models publicly available."}}
{"id": "2408.13184", "pdf": "https://arxiv.org/pdf/2408.13184", "abs": "https://arxiv.org/abs/2408.13184", "authors": ["Hourui Deng", "Hongjie Zhang", "Jie Ou", "Chaosheng Feng"], "title": "Can LLM be a Good Path Planner based on Prompt Engineering? Mitigating the Hallucination for Path Planning", "categories": ["cs.CL"], "comment": "Accepted by ICIC 2025", "summary": "Spatial reasoning in Large Language Models (LLMs) is the foundation for\nembodied intelligence. However, even in simple maze environments, LLMs still\nencounter challenges in long-term path-planning, primarily influenced by their\nspatial hallucination and context inconsistency hallucination by long-term\nreasoning. To address this challenge, this study proposes an innovative model,\nSpatial-to-Relational Transformation and Curriculum Q-Learning (S2RCQL). To\naddress the spatial hallucination of LLMs, we propose the Spatial-to-Relational\napproach, which transforms spatial prompts into entity relations and paths\nrepresenting entity relation chains. This approach fully taps the potential of\nLLMs in terms of sequential thinking. As a result, we design a path-planning\nalgorithm based on Q-learning to mitigate the context inconsistency\nhallucination, which enhances the reasoning ability of LLMs. Using the Q-value\nof state-action as auxiliary information for prompts, we correct the\nhallucinations of LLMs, thereby guiding LLMs to learn the optimal path.\nFinally, we propose a reverse curriculum learning technique based on LLMs to\nfurther mitigate the context inconsistency hallucination. LLMs can rapidly\naccumulate successful experiences by reducing task difficulty and leveraging\nthem to tackle more complex tasks. We performed comprehensive experiments based\non Baidu's self-developed LLM: ERNIE-Bot 4.0. The results showed that our\nS2RCQL achieved a 23%--40% improvement in both success and optimality rates\ncompared with advanced prompt engineering.", "AI": {"tldr": "The paper introduces S2RCQL, a model combining Spatial-to-Relational Transformation and Curriculum Q-Learning to improve LLMs' spatial reasoning and path-planning by addressing hallucinations.", "motivation": "Spatial reasoning in LLMs is crucial for embodied intelligence, but challenges like spatial and context inconsistency hallucinations hinder performance, especially in long-term path-planning tasks.", "method": "Proposes S2RCQL: (1) Spatial-to-Relational Transformation converts spatial prompts into entity relations, leveraging LLMs' sequential thinking; (2) Q-learning-based path-planning corrects hallucinations using Q-values; (3) Reverse curriculum learning reduces task difficulty to accumulate experience.", "result": "Experiments on ERNIE-Bot 4.0 show S2RCQL improves success and optimality rates by 23%-40% over advanced prompt engineering.", "conclusion": "S2RCQL effectively mitigates hallucinations in LLMs, enhancing spatial reasoning and path-planning performance."}}
{"id": "2505.03816", "pdf": "https://arxiv.org/pdf/2505.03816", "abs": "https://arxiv.org/abs/2505.03816", "authors": ["Bidyarthi Paul", "Fariha Tasnim Chowdhury", "Dipta Biswas", "Meherin Sultana"], "title": "Geospatial and Temporal Trends in Urban Transportation: A Study of NYC Taxis and Pathao Food Deliveries", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "Urban transportation plays a vital role in modern city life, affecting how\nefficiently people and goods move around. This study analyzes transportation\npatterns using two datasets: the NYC Taxi Trip dataset from New York City and\nthe Pathao Food Trip dataset from Dhaka, Bangladesh. Our goal is to identify\nkey trends in demand, peak times, and important geographical hotspots. We start\nwith Exploratory Data Analysis (EDA) to understand the basic characteristics of\nthe datasets. Next, we perform geospatial analysis to map out high-demand and\nlow-demand regions. We use the SARIMAX model for time series analysis to\nforecast demand patterns, capturing seasonal and weekly variations. Lastly, we\napply clustering techniques to identify significant areas of high and low\ndemand. Our findings provide valuable insights for optimizing fleet management\nand resource allocation in both passenger transport and food delivery services.\nThese insights can help improve service efficiency, better meet customer needs,\nand enhance urban transportation systems in diverse urban environments.", "AI": {"tldr": "The paper analyzes urban transportation patterns using NYC and Dhaka datasets to identify demand trends, peak times, and hotspots. Methods include EDA, geospatial analysis, SARIMAX forecasting, and clustering. Results aid fleet management and service optimization.", "motivation": "To understand and optimize urban transportation efficiency by analyzing demand patterns and hotspots in diverse cities.", "method": "Exploratory Data Analysis (EDA), geospatial analysis, SARIMAX time series forecasting, and clustering techniques.", "result": "Identified key demand trends, peak times, and geographical hotspots, aiding fleet management and resource allocation.", "conclusion": "Insights improve service efficiency, customer satisfaction, and urban transportation systems in varied environments."}}
{"id": "2505.03825", "pdf": "https://arxiv.org/pdf/2505.03825", "abs": "https://arxiv.org/abs/2505.03825", "authors": ["Anushiya Arunan", "Yan Qin", "Xiaoli Li", "Yuen Chau"], "title": "Intelligently Augmented Contrastive Tensor Factorization: Empowering Multi-dimensional Time Series Classification in Low-Data Environments", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted in Expert Systems with Applications (DOI pending)", "summary": "Classification of multi-dimensional time series from real-world systems\nrequire fine-grained learning of complex features such as cross-dimensional\ndependencies and intra-class variations-all under the practical challenge of\nlow training data availability. However, standard deep learning (DL) struggles\nto learn generalizable features in low-data environments due to model\noverfitting. We propose a versatile yet data-efficient framework, Intelligently\nAugmented Contrastive Tensor Factorization (ITA-CTF), to learn effective\nrepresentations from multi-dimensional time series. The CTF module learns core\nexplanatory components of the time series (e.g., sensor factors, temporal\nfactors), and importantly, their joint dependencies. Notably, unlike standard\ntensor factorization (TF), the CTF module incorporates a new contrastive loss\noptimization to induce similarity learning and class-awareness into the learnt\nrepresentations for better classification performance. To strengthen this\ncontrastive learning, the preceding ITA module generates targeted but\ninformative augmentations that highlight realistic intra-class patterns in the\noriginal data, while preserving class-wise properties. This is achieved by\ndynamically sampling a \"soft\" class prototype to guide the warping of each\nquery data sample, which results in an augmentation that is intelligently\npattern-mixed between the \"soft\" class prototype and the query sample. These\naugmentations enable the CTF module to recognize complex intra-class variations\ndespite the limited original training data, and seek out invariant class-wise\nproperties for accurate classification performance. The proposed method is\ncomprehensively evaluated on five different classification tasks. Compared to\nstandard TF and several DL benchmarks, notable performance improvements up to\n18.7% were achieved.", "AI": {"tldr": "ITA-CTF is a data-efficient framework for classifying multi-dimensional time series by combining contrastive tensor factorization with intelligent augmentations to handle low-data challenges.", "motivation": "Standard deep learning struggles with overfitting in low-data environments, making it hard to learn generalizable features for multi-dimensional time series classification.", "method": "ITA-CTF uses contrastive tensor factorization (CTF) to learn core components and dependencies, enhanced by an ITA module that generates realistic augmentations guided by class prototypes.", "result": "The method outperforms standard tensor factorization and DL benchmarks, achieving up to 18.7% improvement in performance across five classification tasks.", "conclusion": "ITA-CTF effectively addresses low-data challenges by leveraging contrastive learning and intelligent augmentations, improving classification accuracy."}}
{"id": "2505.04306", "pdf": "https://arxiv.org/pdf/2505.04306", "abs": "https://arxiv.org/abs/2505.04306", "authors": ["Qiannan Fan", "Zhuoyang Li", "Jitong Li", "Chenyang Cao"], "title": "MoDE: Mixture of Diffusion Experts for Any Occluded Face Recognition", "categories": ["cs.CV", "I.4.8; I.5.4; I.2.10"], "comment": "8 pages,7 figures", "summary": "With the continuous impact of epidemics, people have become accustomed to\nwearing masks. However, most current occluded face recognition (OFR) algorithms\nlack prior knowledge of occlusions, resulting in poor performance when dealing\nwith occluded faces of varying types and severity in reality. Recognizing\noccluded faces is still a significant challenge, which greatly affects the\nconvenience of people's daily lives. In this paper, we propose an\nidentity-gated mixture of diffusion experts (MoDE) for OFR. Each\ndiffusion-based generative expert estimates one possible complete image for\noccluded faces. Considering the random sampling process of the diffusion model,\nwhich introduces inevitable differences and variations between the inpainted\nfaces and the real ones. To ensemble effective information from\nmulti-reconstructed faces, we introduce an identity-gating network to evaluate\nthe contribution of each reconstructed face to the identity and adaptively\nintegrate the predictions in the decision space. Moreover, our MoDE is a\nplug-and-play module for most existing face recognition models. Extensive\nexperiments on three public face datasets and two datasets in the wild validate\nour advanced performance for various occlusions in comparison with the\ncompeting methods.", "AI": {"tldr": "The paper proposes an identity-gated mixture of diffusion experts (MoDE) for occluded face recognition (OFR), improving performance by integrating multi-reconstructed faces and adapting predictions.", "motivation": "Current OFR algorithms lack prior occlusion knowledge, leading to poor performance with real-world occlusions, impacting daily convenience.", "method": "MoDE uses diffusion-based generative experts to estimate complete images for occluded faces, with an identity-gating network to evaluate and integrate predictions.", "result": "Extensive experiments on public and wild datasets show superior performance for various occlusions compared to competing methods.", "conclusion": "MoDE is an effective, plug-and-play solution for OFR, enhancing recognition accuracy for occluded faces."}}
{"id": "2411.02116", "pdf": "https://arxiv.org/pdf/2411.02116", "abs": "https://arxiv.org/abs/2411.02116", "authors": ["Makoto Fukushima", "Shusuke Eshita", "Hiroshige Fukuhara"], "title": "Advancements and limitations of LLMs in replicating human color-word associations", "categories": ["cs.CL", "cs.CV", "cs.GR", "cs.HC"], "comment": "20 pages, 7 figures, 3 tables", "summary": "Color-word associations play a fundamental role in human cognition and design\napplications. Large Language Models (LLMs) have become widely available and\nhave demonstrated intelligent behaviors in various benchmarks with natural\nconversation skills. However, their ability to replicate human color-word\nassociations remains understudied. We compared multiple generations of LLMs\n(from GPT-3 to GPT-4o) against human color-word associations using data\ncollected from over 10,000 Japanese participants, involving 17 colors and 80\nwords (10 word from eight categories) in Japanese. Our findings reveal a clear\nprogression in LLM performance across generations, with GPT-4o achieving the\nhighest accuracy in predicting the best voted word for each color and category.\nHowever, the highest median performance was approximately 50% even for GPT-4o\nwith visual inputs (chance level of 10%). Moreover, we found performance\nvariations across word categories and colors: while LLMs tended to excel in\ncategories such as Rhythm and Landscape, they struggled with categories such as\nEmotions. Interestingly, color discrimination ability estimated from our\ncolor-word association data showed high correlation with human color\ndiscrimination patterns, consistent with previous studies. Thus, despite\nreasonable alignment in basic color discrimination, humans and LLMs still\ndiverge systematically in the words they assign to those colors. Our study\nhighlights both the advancements in LLM capabilities and their persistent\nlimitations, raising the possibility of systematic differences in semantic\nmemory structures between humans and LLMs in representing color-word\nassociations.", "AI": {"tldr": "The study compares human and LLM color-word associations, showing GPT-4o's highest accuracy but persistent gaps, especially in emotional categories.", "motivation": "To assess LLMs' ability to replicate human color-word associations, a fundamental aspect of cognition and design.", "method": "Comparison of LLM generations (GPT-3 to GPT-4o) against human data from 10,000 Japanese participants, involving 17 colors and 80 words.", "result": "GPT-4o performed best (50% accuracy) but showed category-specific variations, excelling in Rhythm/Landscape but struggling with Emotions.", "conclusion": "LLMs align with humans in basic color discrimination but diverge in semantic memory structures for color-word associations."}}
{"id": "2505.03817", "pdf": "https://arxiv.org/pdf/2505.03817", "abs": "https://arxiv.org/abs/2505.03817", "authors": ["Aditya Shinde", "Prashant Doshi"], "title": "Modeling Behavioral Preferences of Cyber Adversaries Using Inverse Reinforcement Learning", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper presents a holistic approach to attacker preference modeling from\nsystem-level audit logs using inverse reinforcement learning (IRL). Adversary\nmodeling is an important capability in cybersecurity that lets defenders\ncharacterize behaviors of potential attackers, which enables attribution to\nknown cyber adversary groups. Existing approaches rely on documenting an\never-evolving set of attacker tools and techniques to track known threat\nactors. Although attacks evolve constantly, attacker behavioral preferences are\nintrinsic and less volatile. Our approach learns the behavioral preferences of\ncyber adversaries from forensics data on their tools and techniques. We model\nthe attacker as an expert decision-making agent with unknown behavioral\npreferences situated in a computer host. We leverage attack provenance graphs\nof audit logs to derive a state-action trajectory of the attack. We test our\napproach on open datasets of audit logs containing real attack data. Our\nresults demonstrate for the first time that low-level forensics data can\nautomatically reveal an adversary's subjective preferences, which serves as an\nadditional dimension to modeling and documenting cyber adversaries. Attackers'\npreferences tend to be invariant despite their different tools and indicate\npredispositions that are inherent to the attacker. As such, these inferred\npreferences can potentially serve as unique behavioral signatures of attackers\nand improve threat attribution.", "AI": {"tldr": "The paper introduces an inverse reinforcement learning (IRL) method to model attacker preferences from system-level audit logs, offering a stable behavioral signature for cyber adversaries.", "motivation": "Existing methods track evolving attacker tools and techniques, but behavioral preferences are intrinsic and less volatile, providing a more stable basis for adversary modeling.", "method": "The approach models attackers as expert agents with unknown preferences, using attack provenance graphs from audit logs to derive state-action trajectories.", "result": "Testing on real attack data shows that low-level forensics can reveal invariant attacker preferences, serving as unique behavioral signatures.", "conclusion": "Inferred preferences can improve threat attribution by capturing inherent attacker predispositions, complementing traditional tool-based tracking."}}
{"id": "2505.03827", "pdf": "https://arxiv.org/pdf/2505.03827", "abs": "https://arxiv.org/abs/2505.03827", "authors": ["Xin Wang", "Ling Feng", "Huijun Zhang", "Lei Cao", "Kaisheng Zeng", "Qi Li", "Yang Ding", "Yi Dai", "David Clifton"], "title": "MISE: Meta-knowledge Inheritance for Social Media-Based Stressor Estimation", "categories": ["cs.LG", "cs.AI"], "comment": "WWW2025, Oral Presentation", "summary": "Stress haunts people in modern society, which may cause severe health issues\nif left unattended. With social media becoming an integral part of daily life,\nleveraging social media to detect stress has gained increasing attention. While\nthe majority of the work focuses on classifying stress states and stress\ncategories, this study introduce a new task aimed at estimating more specific\nstressors (like exam, writing paper, etc.) through users' posts on social\nmedia. Unfortunately, the diversity of stressors with many different classes\nbut a few examples per class, combined with the consistent arising of new\nstressors over time, hinders the machine understanding of stressors. To this\nend, we cast the stressor estimation problem within a practical scenario\nfew-shot learning setting, and propose a novel meta-learning based stressor\nestimation framework that is enhanced by a meta-knowledge inheritance\nmechanism. This model can not only learn generic stressor context through\nmeta-learning, but also has a good generalization ability to estimate new\nstressors with little labeled data. A fundamental breakthrough in our approach\nlies in the inclusion of the meta-knowledge inheritance mechanism, which equips\nour model with the ability to prevent catastrophic forgetting when adapting to\nnew stressors. The experimental results show that our model achieves\nstate-of-the-art performance compared with the baselines. Additionally, we\nconstruct a social media-based stressor estimation dataset that can help train\nartificial intelligence models to facilitate human well-being. The dataset is\nnow public at\n\\href{https://www.kaggle.com/datasets/xinwangcs/stressor-cause-of-mental-health-problem-dataset}{\\underline{Kaggle}}\nand\n\\href{https://huggingface.co/datasets/XinWangcs/Stressor}{\\underline{Hugging\nFace}}.", "AI": {"tldr": "The paper introduces a meta-learning framework for estimating specific stressors from social media posts, addressing challenges like class diversity and limited data. It includes a meta-knowledge inheritance mechanism to prevent catastrophic forgetting and achieves state-of-the-art results.", "motivation": "Stress detection via social media is crucial for health, but existing work lacks specificity in identifying stressors. This study aims to estimate detailed stressors (e.g., exams, writing papers) despite challenges like class diversity and limited labeled data.", "method": "A meta-learning-based framework enhanced by a meta-knowledge inheritance mechanism is proposed. It learns generic stressor contexts and generalizes well to new stressors with minimal labeled data.", "result": "The model outperforms baselines, demonstrating strong generalization and prevention of catastrophic forgetting. A public dataset for stressor estimation is also released.", "conclusion": "The framework effectively estimates stressors in a few-shot learning setting, advancing stress detection research. The public dataset supports further AI development for human well-being."}}
{"id": "2505.04320", "pdf": "https://arxiv.org/pdf/2505.04320", "abs": "https://arxiv.org/abs/2505.04320", "authors": ["Zijun Zhou", "Yingying Deng", "Xiangyu He", "Weiming Dong", "Fan Tang"], "title": "Multi-turn Consistent Image Editing", "categories": ["cs.CV"], "comment": null, "summary": "Many real-world applications, such as interactive photo retouching, artistic\ncontent creation, and product design, require flexible and iterative image\nediting. However, existing image editing methods primarily focus on achieving\nthe desired modifications in a single step, which often struggles with\nambiguous user intent, complex transformations, or the need for progressive\nrefinements. As a result, these methods frequently produce inconsistent\noutcomes or fail to meet user expectations. To address these challenges, we\npropose a multi-turn image editing framework that enables users to iteratively\nrefine their edits, progressively achieving more satisfactory results. Our\napproach leverages flow matching for accurate image inversion and a\ndual-objective Linear Quadratic Regulators (LQR) for stable sampling,\neffectively mitigating error accumulation. Additionally, by analyzing the\nlayer-wise roles of transformers, we introduce a adaptive attention\nhighlighting method that enhances editability while preserving multi-turn\ncoherence. Extensive experiments demonstrate that our framework significantly\nimproves edit success rates and visual fidelity compared to existing methods.", "AI": {"tldr": "A multi-turn image editing framework improves iterative refinement, using flow matching and LQR for stability, and adaptive attention for coherence.", "motivation": "Existing single-step image editing methods struggle with ambiguity, complex transformations, and progressive refinements, leading to inconsistent results.", "method": "Proposes a multi-turn framework with flow matching for inversion, LQR for stable sampling, and adaptive attention highlighting for coherence.", "result": "Significantly improves edit success rates and visual fidelity compared to existing methods.", "conclusion": "The framework effectively addresses challenges in iterative image editing, offering better user satisfaction and consistency."}}
{"id": "2501.05040", "pdf": "https://arxiv.org/pdf/2501.05040", "abs": "https://arxiv.org/abs/2501.05040", "authors": ["Chengxing Xie", "Bowen Li", "Chang Gao", "He Du", "Wai Lam", "Difan Zou", "Kai Chen"], "title": "SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution", "categories": ["cs.CL"], "comment": "Our code, data, and model will be released at\n  https://github.com/InternLM/SWE-Fixer", "summary": "Large Language Models (LLMs) have demonstrated remarkable proficiency across\na variety of complex tasks. One significant application of LLMs is in tackling\nsoftware engineering challenges, particularly in resolving real-world tasks on\nGitHub by fixing code based on the issues reported by the users. However, many\ncurrent approaches rely on proprietary LLMs, which limits reproducibility,\naccessibility, and transparency. The critical components of LLMs for addressing\nsoftware engineering issues and how their capabilities can be effectively\nenhanced remain unclear. To address these challenges, we introduce SWE-Fixer, a\nnovel open-source framework designed to effectively and efficiently resolve\nGitHub issues. SWE-Fixer comprises two essential modules: a code file retrieval\nmodule and a code editing module. The retrieval module employs BM25 along with\na lightweight model to achieve coarse-to-fine file retrieval. Subsequently, the\ncode editing module utilizes the other model to generate patches for the\nidentified files. To mitigate the lack of publicly available datasets, we\ncompile an extensive dataset that includes 110K GitHub issues along with their\ncorresponding patches and train the two models of SWE-Fixer separately. We\nassess our approach on the SWE-Bench Lite and Verified benchmarks, achieving\ncompetitive performance among open-source models with scores of 22.0% and\n30.2%. Furthermore, SWE-Fixer reaches state-of-the-art performance (24.7% on\nLite and 32.8% on Verified) with PASS_TO_PASS (P2P) filtering. Additionally,\nour approach requires only two model calls per instance, making it\nsignificantly more efficient than existing methods. These results highlight the\neffectiveness of SWE-Fixer in real-world code-fixing scenarios. We will make\nour model, dataset, and code publicly available at\nhttps://github.com/InternLM/SWE-Fixer.", "AI": {"tldr": "SWE-Fixer is an open-source framework for resolving GitHub issues using LLMs, featuring efficient retrieval and editing modules, and achieves competitive performance on benchmarks.", "motivation": "Current LLM-based approaches for GitHub issue resolution rely on proprietary models, limiting reproducibility and transparency. SWE-Fixer addresses this gap.", "method": "SWE-Fixer uses a two-module system: a BM25-based retrieval module and a code editing module, trained on a custom 110K GitHub issues dataset.", "result": "Achieves 22.0% and 30.2% on SWE-Bench Lite and Verified, improving to 24.7% and 32.8% with P2P filtering, while being more efficient.", "conclusion": "SWE-Fixer is effective for real-world code-fixing, with plans to release the model, dataset, and code publicly."}}
{"id": "2505.03824", "pdf": "https://arxiv.org/pdf/2505.03824", "abs": "https://arxiv.org/abs/2505.03824", "authors": ["Jiarui Chen"], "title": "Memory Assisted LLM for Personalized Recommendation System", "categories": ["cs.IR", "cs.AI"], "comment": "8 pages, 7 figures", "summary": "Large language models (LLMs) have demonstrated significant potential in\nsolving recommendation tasks. With proven capabilities in understanding user\npreferences, LLM personalization has emerged as a critical area for providing\ntailored responses to individuals. Current studies explore personalization\nthrough prompt design and fine-tuning, paving the way for further research in\npersonalized LLMs. However, existing approaches are either costly and\ninefficient in capturing diverse user preferences or fail to account for timely\nupdates to user history. To address these gaps, we propose the Memory-Assisted\nPersonalized LLM (MAP). Through user interactions, we first create a history\nprofile for each user, capturing their preferences, such as ratings for\nhistorical items. During recommendation, we extract relevant memory based on\nsimilarity, which is then incorporated into the prompts to enhance personalized\nrecommendations. In our experiments, we evaluate MAP using a sequential rating\nprediction task under two scenarios: single domain, where memory and tasks are\nfrom the same category (e.g., movies), and cross-domain (e.g., memory from\nmovies and recommendation tasks in books). The results show that MAP\noutperforms regular LLM-based recommenders that integrate user history directly\nthrough prompt design. Moreover, as user history grows, MAP's advantage\nincreases in both scenarios, making it more suitable for addressing successive\npersonalized user requests.", "AI": {"tldr": "The paper proposes MAP, a Memory-Assisted Personalized LLM, to improve personalized recommendations by leveraging user history profiles and similarity-based memory extraction.", "motivation": "Existing LLM-based personalization methods are costly, inefficient, or fail to update user history timely, creating gaps in capturing diverse preferences.", "method": "MAP creates user history profiles and extracts relevant memory for prompts, enhancing recommendations. It is evaluated on sequential rating prediction tasks in single and cross-domain scenarios.", "result": "MAP outperforms regular LLM-based recommenders, especially as user history grows, showing scalability and effectiveness.", "conclusion": "MAP is a scalable and efficient solution for personalized LLM recommendations, addressing limitations of current approaches."}}
{"id": "2505.03849", "pdf": "https://arxiv.org/pdf/2505.03849", "abs": "https://arxiv.org/abs/2505.03849", "authors": ["Jonathan Gorard", "Ammar Hakim", "Hong Qin", "Kyle Parfrey", "Shantenu Jha"], "title": "Improved Dimensionality Reduction for Inverse Problems in Nuclear Fusion and High-Energy Astrophysics", "categories": ["cs.LG", "astro-ph.IM", "nucl-th"], "comment": "2 pages. Position paper accepted to DOE-ASCR Inverse Methods for\n  Complex Systems under Uncertainty Workshop (Rockville, MD, United States,\n  June 10-12, 2025)", "summary": "Many inverse problems in nuclear fusion and high-energy astrophysics\nresearch, such as the optimization of tokamak reactor geometries or the\ninference of black hole parameters from interferometric images, necessitate\nhigh-dimensional parameter scans and large ensembles of simulations to be\nperformed. Such inverse problems typically involve large uncertainties, both in\nthe measurement parameters being inverted and in the underlying physics models\nthemselves. Monte Carlo sampling, when combined with modern non-linear\ndimensionality reduction techniques such as autoencoders and manifold learning,\ncan be used to reduce the size of the parameter spaces considerably. However,\nthere is no guarantee that the resulting combinations of parameters will be\nphysically valid, or even mathematically consistent. In this position paper, we\nadvocate adopting a hybrid approach that leverages our recent advances in the\ndevelopment of formal verification methods for numerical algorithms, with the\ngoal of constructing parameter space restrictions with provable mathematical\nand physical correctness properties, whilst nevertheless respecting both\nexperimental uncertainties and uncertainties in the underlying physical\nprocesses.", "AI": {"tldr": "The paper proposes a hybrid approach combining Monte Carlo sampling with formal verification methods to ensure physically and mathematically valid parameter spaces in high-dimensional inverse problems.", "motivation": "Addressing the challenges of high-dimensional parameter scans and uncertainties in inverse problems in nuclear fusion and astrophysics.", "method": "Combines Monte Carlo sampling with non-linear dimensionality reduction (e.g., autoencoders) and formal verification methods.", "result": "Aims to construct parameter space restrictions with provable correctness while accounting for uncertainties.", "conclusion": "Advocates for a hybrid approach to improve the reliability of parameter space exploration in complex inverse problems."}}
{"id": "2505.04347", "pdf": "https://arxiv.org/pdf/2505.04347", "abs": "https://arxiv.org/abs/2505.04347", "authors": ["Yanyu Li", "Pencheng Wan", "Liang Han", "Yaowei Wang", "Liqiang Nie", "Min Zhang"], "title": "CountDiffusion: Text-to-Image Synthesis with Training-Free Counting-Guidance Diffusion", "categories": ["cs.CV"], "comment": "8 pages, 9 figures, 3 tables", "summary": "Stable Diffusion has advanced text-to-image synthesis, but training models to\ngenerate images with accurate object quantity is still difficult due to the\nhigh computational cost and the challenge of teaching models the abstract\nconcept of quantity. In this paper, we propose CountDiffusion, a training-free\nframework aiming at generating images with correct object quantity from textual\ndescriptions. CountDiffusion consists of two stages. In the first stage, an\nintermediate denoising result is generated by the diffusion model to predict\nthe final synthesized image with one-step denoising, and a counting model is\nused to count the number of objects in this image. In the second stage, a\ncorrection module is used to correct the object quantity by changing the\nattention map of the object with universal guidance. The proposed\nCountDiffusion can be plugged into any diffusion-based text-to-image (T2I)\ngeneration models without further training. Experiment results demonstrate the\nsuperiority of our proposed CountDiffusion, which improves the accurate object\nquantity generation ability of T2I models by a large margin.", "AI": {"tldr": "CountDiffusion is a training-free framework to improve object quantity accuracy in text-to-image generation by correcting attention maps using a counting model.", "motivation": "Training models for accurate object quantity in images is computationally expensive and conceptually challenging.", "method": "CountDiffusion uses a two-stage process: predicting an intermediate image with a counting model, then correcting object quantity via attention map adjustments.", "result": "CountDiffusion significantly enhances the ability of T2I models to generate images with correct object quantities.", "conclusion": "The framework is effective, training-free, and compatible with existing diffusion-based T2I models."}}
{"id": "2502.00290", "pdf": "https://arxiv.org/pdf/2502.00290", "abs": "https://arxiv.org/abs/2502.00290", "authors": ["Huan Ma", "Jingdong Chen", "Joey Tianyi Zhou", "Guangyu Wang", "Changqing Zhang"], "title": "Estimating LLM Uncertainty with Logits", "categories": ["cs.CL", "cs.AI"], "comment": "Fixed some data errors in Table 1", "summary": "Over the past few years, Large Language Models (LLMs) have developed rapidly\nand are widely applied in various domains. However, LLMs face the issue of\nhallucinations, generating responses that may be unreliable when the models\nlack relevant knowledge. To be aware of potential hallucinations, uncertainty\nestimation methods have been introduced, and most of them have confirmed that\nreliability lies in critical tokens. However, probability-based methods perform\npoorly in identifying token reliability, limiting their practical utility. In\nthis paper, we reveal that the probability-based method fails to estimate token\nreliability due to the loss of evidence strength information which is\naccumulated in the training stage. Therefore, we present Logits-induced token\nuncertainty (LogTokU), a framework for estimating decoupled token uncertainty\nin LLMs, enabling real-time uncertainty estimation without requiring multiple\nsampling processes. We employ evidence modeling to implement LogTokU and use\nthe estimated uncertainty to guide downstream tasks. The experimental results\ndemonstrate that LogTokU has significant effectiveness and promise.", "AI": {"tldr": "LogTokU is a framework for estimating token uncertainty in LLMs, addressing the limitations of probability-based methods by leveraging evidence strength information.", "motivation": "LLMs suffer from hallucinations due to unreliable token generation when lacking knowledge. Existing uncertainty estimation methods, especially probability-based ones, fail to accurately identify token reliability.", "method": "Proposes LogTokU, a framework using evidence modeling to decouple token uncertainty, enabling real-time estimation without multiple sampling.", "result": "LogTokU shows significant effectiveness in estimating token uncertainty and guiding downstream tasks.", "conclusion": "LogTokU provides a promising solution for real-time uncertainty estimation in LLMs, improving reliability."}}
{"id": "2505.03835", "pdf": "https://arxiv.org/pdf/2505.03835", "abs": "https://arxiv.org/abs/2505.03835", "authors": ["Simon Suh", "Jihyuk Bang", "Ji Woo Han"], "title": "The Shift Towards Preprints in AI Policy Research: A Comparative Study of Preprint Trends in the U.S., Europe, and South Korea", "categories": ["cs.DL", "cs.AI", "cs.CY", "I.2.0; K.4.0"], "comment": "22 pages, 6 figures, 3 tables. Uses cross-regional analysis to\n  evaluate how preprint citation trends in AI - policy research have shifted\n  over time in response to two major global events: the COVID-19 pandemic and\n  the release of ChatGPT. Compares United States, Europe, and South Korea", "summary": "The adoption of open science has quickly changed how artificial intelligence\n(AI) policy research is distributed globally. This study examines the regional\ntrends in the citation of preprints, specifically focusing on the impact of two\nmajor disruptive events: the COVID-19 pandemic and the release of ChatGPT, on\nresearch dissemination patterns in the United States, Europe, and South Korea\nfrom 2015 to 2024. Using bibliometrics data from the Web of Science, this study\ntracks how global disruptive events influenced the adoption of preprints in AI\npolicy research and how such shifts vary by region. By marking the timing of\nthese disruptive events, the analysis reveals that while all regions\nexperienced growth in preprint citations, the magnitude and trajectory of\nchange varied significantly. The United States exhibited sharp, event-driven\nincreases; Europe demonstrated institutional growth; and South Korea maintained\nconsistent, linear growth in preprint adoption. These findings suggest that\nglobal disruptions may have accelerated preprint adoption, but the extent and\ntrajectory are shaped by local research cultures, policy environments, and\nlevels of open science maturity. This paper emphasizes the need for future AI\ngovernance strategies to consider regional variability in research\ndissemination and highlights opportunities for further longitudinal and\ncomparative research to deepen our understanding of open-access adoption in AI\npolicy development.", "AI": {"tldr": "The study explores how global disruptions (COVID-19 and ChatGPT) influenced preprint citation trends in AI policy research across the US, Europe, and South Korea, revealing regional differences in adoption patterns.", "motivation": "To understand how disruptive events impact the dissemination of AI policy research via preprints and how regional factors shape these trends.", "method": "Analyzed bibliometrics data from Web of Science (2015-2024) to track preprint citation trends, focusing on the US, Europe, and South Korea.", "result": "All regions saw preprint growth, but patterns varied: US had event-driven spikes, Europe showed institutional growth, and South Korea had linear adoption.", "conclusion": "Global disruptions accelerate preprint adoption, but local factors shape outcomes. Future AI governance should account for regional variability, and more longitudinal research is needed."}}
{"id": "2505.03861", "pdf": "https://arxiv.org/pdf/2505.03861", "abs": "https://arxiv.org/abs/2505.03861", "authors": ["Kyunghyun Cho"], "title": "Machine Learning: a Lecture Note", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "This lecture note is intended to prepare early-year master's and PhD students\nin data science or a related discipline with foundational ideas in machine\nlearning. It starts with basic ideas in modern machine learning with\nclassification as a main target task. These basic ideas include loss\nformulation, backpropagation, stochastic gradient descent, generalization,\nmodel selection as well as fundamental blocks of artificial neural networks.\nBased on these basic ideas, the lecture note explores in depth the probablistic\napproach to unsupervised learning, covering directed latent variable models,\nproduct of experts, generative adversarial networks and autoregressive models.\nFinally, the note ends by covering a diverse set of further topics, such as\nreinforcement learning, ensemble methods and meta-learning. After reading this\nlecture note, a student should be ready to embark on studying and researching\nmore advanced topics in machine learning and more broadly artificial\nintelligence.", "AI": {"tldr": "A lecture note for early-year master's and PhD students in data science, covering foundational machine learning topics, probabilistic unsupervised learning, and advanced topics like reinforcement learning and meta-learning.", "motivation": "To prepare students with foundational machine learning concepts and equip them for advanced study and research in AI.", "method": "Starts with basics (e.g., classification, backpropagation, SGD), explores probabilistic unsupervised learning (e.g., GANs, autoregressive models), and concludes with diverse advanced topics.", "result": "Students gain a solid foundation in machine learning, enabling them to tackle more advanced topics and research.", "conclusion": "The lecture note successfully bridges foundational knowledge to advanced machine learning, preparing students for further study and research in AI."}}
{"id": "2505.04369", "pdf": "https://arxiv.org/pdf/2505.04369", "abs": "https://arxiv.org/abs/2505.04369", "authors": ["Jie Sun", "Heng Liu", "Yongzhen Wang", "Xiao-Ping Zhang", "Mingqiang Wei"], "title": "WDMamba: When Wavelet Degradation Prior Meets Vision Mamba for Image Dehazing", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we reveal a novel haze-specific wavelet degradation prior\nobserved through wavelet transform analysis, which shows that haze-related\ninformation predominantly resides in low-frequency components. Exploiting this\ninsight, we propose a novel dehazing framework, WDMamba, which decomposes the\nimage dehazing task into two sequential stages: low-frequency restoration\nfollowed by detail enhancement. This coarse-to-fine strategy enables WDMamba to\neffectively capture features specific to each stage of the dehazing process,\nresulting in high-quality restored images. Specifically, in the low-frequency\nrestoration stage, we integrate Mamba blocks to reconstruct global structures\nwith linear complexity, efficiently removing overall haze and producing a\ncoarse restored image. Thereafter, the detail enhancement stage reinstates\nfine-grained information that may have been overlooked during the previous\nphase, culminating in the final dehazed output. Furthermore, to enhance detail\nretention and achieve more natural dehazing, we introduce a self-guided\ncontrastive regularization during network training. By utilizing the coarse\nrestored output as a hard negative example, our model learns more\ndiscriminative representations, substantially boosting the overall dehazing\nperformance. Extensive evaluations on public dehazing benchmarks demonstrate\nthat our method surpasses state-of-the-art approaches both qualitatively and\nquantitatively. Code is available at https://github.com/SunJ000/WDMamba.", "AI": {"tldr": "The paper introduces WDMamba, a novel dehazing framework leveraging a haze-specific wavelet degradation prior. It decomposes dehazing into low-frequency restoration and detail enhancement, using Mamba blocks for efficiency and self-guided contrastive regularization for improved performance.", "motivation": "The motivation is to address the challenge of image dehazing by exploiting the observation that haze-related information primarily resides in low-frequency components, leading to a more effective restoration process.", "method": "The method involves a two-stage coarse-to-fine strategy: low-frequency restoration using Mamba blocks for global structure reconstruction, followed by detail enhancement. Self-guided contrastive regularization is introduced during training to enhance detail retention.", "result": "Extensive evaluations show WDMamba outperforms state-of-the-art methods in both qualitative and quantitative metrics on public dehazing benchmarks.", "conclusion": "The proposed WDMamba framework effectively addresses image dehazing by leveraging wavelet degradation prior and a two-stage approach, achieving superior results."}}
{"id": "2503.01496", "pdf": "https://arxiv.org/pdf/2503.01496", "abs": "https://arxiv.org/abs/2503.01496", "authors": ["Disen Lan", "Weigao Sun", "Jiaxi Hu", "Jusen Du", "Yu Cheng"], "title": "Liger: Linearizing Large Language Models to Gated Recurrent Structures", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted by ICML 2025, 15 pages", "summary": "Transformers with linear recurrent modeling offer linear-time training and\nconstant-memory inference. Despite their demonstrated efficiency and\nperformance, pretraining such non-standard architectures from scratch remains\ncostly and risky. The linearization of large language models (LLMs) transforms\npretrained standard models into linear recurrent structures, enabling more\nefficient deployment. However, current linearization methods typically\nintroduce additional feature map modules that require extensive fine-tuning and\noverlook the gating mechanisms used in state-of-the-art linear recurrent\nmodels. To address these issues, this paper presents Liger, short for\nLinearizing LLMs to gated recurrent structures. Liger is a novel approach for\nconverting pretrained LLMs into gated linear recurrent models without adding\nextra parameters. It repurposes the pretrained key matrix weights to construct\ndiverse gating mechanisms, facilitating the formation of various gated\nrecurrent structures while avoiding the need to train additional components\nfrom scratch. Using lightweight fine-tuning with Low-Rank Adaptation (LoRA),\nLiger restores the performance of the linearized gated recurrent models to\nmatch that of the original LLMs. Additionally, we introduce Liger Attention, an\nintra-layer hybrid attention mechanism, which significantly recovers 93\\% of\nthe Transformer-based LLM at 0.02\\% pre-training tokens during the\nlinearization process, achieving competitive results across multiple\nbenchmarks, as validated on models ranging from 1B to 8B parameters. Code is\navailable at https://github.com/OpenSparseLLMs/Linearization.", "AI": {"tldr": "Liger is a method to convert pretrained LLMs into gated linear recurrent models without extra parameters, using lightweight fine-tuning to restore performance.", "motivation": "Pretraining non-standard architectures like linear recurrent models is costly, and current linearization methods require extensive fine-tuning or overlook gating mechanisms.", "method": "Liger repurposes pretrained key matrix weights for gating, avoids extra parameters, and uses LoRA for lightweight fine-tuning. It also introduces Liger Attention for hybrid attention.", "result": "Liger recovers 93% of Transformer performance with 0.02% pretraining tokens and achieves competitive benchmarks on 1B-8B parameter models.", "conclusion": "Liger efficiently linearizes LLMs into gated recurrent structures without added parameters, maintaining performance and reducing training costs."}}
{"id": "2505.03836", "pdf": "https://arxiv.org/pdf/2505.03836", "abs": "https://arxiv.org/abs/2505.03836", "authors": ["Chongsheng Zhang", "Shuwen Wu", "Yingqi Chen", "Matthias A\u00dfenmacher", "Christian Heumann", "Yi Men", "Gaojuan Fan", "Jo\u00e3o Gama"], "title": "OBD-Finder: Explainable Coarse-to-Fine Text-Centric Oracle Bone Duplicates Discovery", "categories": ["cs.IR", "cs.AI", "cs.CV"], "comment": "This is the long version of our OBD-Finder paper for AI-enabled\n  Oracle Bone Duplicates Discovery (currently under review at the ECML PKDD\n  2025 Demo Track). The models, video illustration and demonstration of this\n  paper are available at: https://github.com/cszhangLMU/OBD-Finder/.\n  Illustration video: https://www.youtube.com/watch?v=5QT4f0YIo0Q", "summary": "Oracle Bone Inscription (OBI) is the earliest systematic writing system in\nChina, while the identification of Oracle Bone (OB) duplicates is a fundamental\nissue in OBI research. In this work, we design a progressive OB duplicate\ndiscovery framework that combines unsupervised low-level keypoints matching\nwith high-level text-centric content-based matching to refine and rank the\ncandidate OB duplicates with semantic awareness and interpretability. We\ncompare our approach with state-of-the-art content-based image retrieval and\nimage matching methods, showing that our approach yields comparable recall\nperformance and the highest simplified mean reciprocal rank scores for both\nTop-5 and Top-15 retrieval results, and with significantly accelerated\ncomputation efficiency. We have discovered over 60 pairs of new OB duplicates\nin real-world deployment, which were missed by OBI researchers for decades. The\nmodels, video illustration and demonstration of this work are available at:\nhttps://github.com/cszhangLMU/OBD-Finder/.", "AI": {"tldr": "A framework combining unsupervised keypoints matching and text-centric content-based matching for Oracle Bone duplicate discovery, outperforming existing methods in efficiency and accuracy.", "motivation": "Oracle Bone Inscription (OBI) research requires identifying duplicates, a fundamental but challenging task.", "method": "Progressive framework with low-level keypoints matching and high-level text-centric content-based matching for refining and ranking duplicates.", "result": "Achieves comparable recall, highest simplified mean reciprocal rank scores, and faster computation; discovers 60+ new OB duplicates.", "conclusion": "The framework is effective, efficient, and has practical impact in OBI research."}}
{"id": "2505.03911", "pdf": "https://arxiv.org/pdf/2505.03911", "abs": "https://arxiv.org/abs/2505.03911", "authors": ["Hans Hohenfeld", "Marius Beuerle", "Elie Mounzer"], "title": "Explaining Anomalies with Tensor Networks", "categories": ["cs.LG", "quant-ph"], "comment": "6 pages, 3 figures", "summary": "Tensor networks, a class of variational quantum many-body wave functions have\nattracted considerable research interest across many disciplines, including\nclassical machine learning. Recently, Aizpurua et al. demonstrated explainable\nanomaly detection with matrix product states on a discrete-valued\ncyber-security task, using quantum-inspired methods to gain insight into the\nlearned model and detected anomalies. Here, we extend this framework to\nreal-valued data domains. We furthermore introduce tree tensor networks for the\ntask of explainable anomaly detection. We demonstrate these methods with three\nbenchmark problems, show adequate predictive performance compared to several\nbaseline models and both tensor network architectures' ability to explain\nanomalous samples. We thereby extend the application of tensor networks to a\nbroader class of potential problems and open a pathway for future extensions to\nmore complex tensor network architectures.", "AI": {"tldr": "The paper extends tensor networks for explainable anomaly detection to real-valued data and introduces tree tensor networks, demonstrating their effectiveness on benchmarks.", "motivation": "To broaden the application of tensor networks for explainable anomaly detection beyond discrete-valued tasks, enabling insights into real-world problems.", "method": "Extends matrix product states to real-valued data and introduces tree tensor networks for anomaly detection, tested on three benchmarks.", "result": "Shows adequate predictive performance and explainability of anomalies compared to baseline models.", "conclusion": "Expands tensor networks' applicability and paves the way for future extensions to more complex architectures."}}
{"id": "2505.04375", "pdf": "https://arxiv.org/pdf/2505.04375", "abs": "https://arxiv.org/abs/2505.04375", "authors": ["Moseli Mots'oehli", "Hope Mogale", "Kyungim Baek"], "title": "Balancing Accuracy, Calibration, and Efficiency in Active Learning with Vision Transformers Under Label Noise", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Fine-tuning pre-trained convolutional neural networks on ImageNet for\ndownstream tasks is well-established. Still, the impact of model size on the\nperformance of vision transformers in similar scenarios, particularly under\nlabel noise, remains largely unexplored. Given the utility and versatility of\ntransformer architectures, this study investigates their practicality under\nlow-budget constraints and noisy labels. We explore how classification accuracy\nand calibration are affected by symmetric label noise in active learning\nsettings, evaluating four vision transformer configurations (Base and Large\nwith 16x16 and 32x32 patch sizes) and three Swin Transformer configurations\n(Tiny, Small, and Base) on CIFAR10 and CIFAR100 datasets, under varying label\nnoise rates. Our findings show that larger ViT models (ViTl32 in particular)\nconsistently outperform their smaller counterparts in both accuracy and\ncalibration, even under moderate to high label noise, while Swin Transformers\nexhibit weaker robustness across all noise levels. We find that smaller patch\nsizes do not always lead to better performance, as ViTl16 performs consistently\nworse than ViTl32 while incurring a higher computational cost. We also find\nthat information-based Active Learning strategies only provide meaningful\naccuracy improvements at moderate label noise rates, but they result in poorer\ncalibration compared to models trained on randomly acquired labels, especially\nat high label noise rates. We hope these insights provide actionable guidance\nfor practitioners looking to deploy vision transformers in resource-constrained\nenvironments, where balancing model complexity, label noise, and compute\nefficiency is critical in model fine-tuning or distillation.", "AI": {"tldr": "The study explores the impact of model size and label noise on vision transformers (ViTs) and Swin Transformers, finding larger ViTs (ViTl32) outperform smaller ones in accuracy and calibration under noise, while Swin Transformers are less robust. Active Learning helps moderately but harms calibration at high noise.", "motivation": "To understand how model size and label noise affect vision transformers' performance and calibration, especially in resource-constrained settings.", "method": "Evaluated four ViT and three Swin Transformer configurations on CIFAR10/100 under varying label noise rates, comparing accuracy and calibration.", "result": "Larger ViTs (ViTl32) perform better under noise; Swin Transformers are less robust. Active Learning aids accuracy moderately but worsens calibration at high noise.", "conclusion": "Larger ViTs are more practical under noise, while Swin Transformers struggle. Active Learning's benefits are limited by calibration trade-offs. Insights aid deployment in resource-constrained scenarios."}}
{"id": "2503.03186", "pdf": "https://arxiv.org/pdf/2503.03186", "abs": "https://arxiv.org/abs/2503.03186", "authors": ["Ben Hutchinson", "Celeste Rodr\u00edguez Louro", "Glenys Collard", "Ned Cooper"], "title": "Designing Speech Technologies for Australian Aboriginal English: Opportunities, Risks and Participation", "categories": ["cs.CL"], "comment": null, "summary": "In Australia, post-contact language varieties, including creoles and local\nvarieties of international languages, emerged as a result of forced contact\nbetween Indigenous communities and English speakers. These contact varieties\nare widely used, yet are poorly supported by language technologies. This gap\npresents barriers to participation in civil and economic society for Indigenous\ncommunities using these varieties, and reproduces minoritisation of\ncontemporary Indigenous sociolinguistic identities. This paper concerns three\nquestions regarding this context. First, can speech technologies support\nspeakers of Australian Aboriginal English, a local indigenised variety of\nEnglish? Second, what risks are inherent in such a project? Third, what\ntechnology development practices are appropriate for this context, and how can\nresearchers integrate meaningful community participation in order to mitigate\nrisks? We argue that opportunities do exist -- as well as risks -- and\ndemonstrate this through a case study exploring design practices in a\nreal-world project aiming to improve speech technologies for Australian\nAboriginal English. We discuss how we integrated culturally appropriate and\nparticipatory processes throughout the project. We call for increased support\nfor languages used by Indigenous communities, including contact varieties,\nwhich provide practical economic and socio-cultural benefits, provided that\nparticipatory and culturally safe practices are enacted.", "AI": {"tldr": "The paper explores the potential and risks of using speech technologies to support Australian Aboriginal English, emphasizing participatory and culturally safe practices.", "motivation": "The gap in language technology support for Indigenous contact varieties hinders participation in society and perpetuates minoritization.", "method": "A case study on a real-world project integrating culturally appropriate and participatory design practices.", "result": "Opportunities exist for supporting Indigenous languages, but risks must be mitigated through community participation.", "conclusion": "Increased support for Indigenous languages is needed, with participatory and culturally safe practices."}}
{"id": "2505.03840", "pdf": "https://arxiv.org/pdf/2505.03840", "abs": "https://arxiv.org/abs/2505.03840", "authors": ["Cairong Yan", "Jinyi Han", "Jin Ju", "Yanting Zhang", "Zijian Wang", "Xuan Shao"], "title": "CoCoB: Adaptive Collaborative Combinatorial Bandits for Online Recommendation", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": "This paper has been accepted by DASFAA 2025: The International\n  Conference on Database Systems for Advanced Applications. This version\n  provides more detailed information", "summary": "Clustering bandits have gained significant attention in recommender systems\nby leveraging collaborative information from neighboring users to better\ncapture target user preferences. However, these methods often lack a clear\ndefinition of similar users and face challenges when users with unique\npreferences lack appropriate neighbors. In such cases, relying on divergent\npreferences of misidentified neighbors can degrade recommendation quality. To\naddress these limitations, this paper proposes an adaptive Collaborative\nCombinatorial Bandits algorithm (CoCoB). CoCoB employs an innovative two-sided\nbandit architecture, applying bandit principles to both the user and item\nsides. The user-bandit employs an enhanced Bayesian model to explore user\nsimilarity, identifying neighbors based on a similarity probability threshold.\nThe item-bandit treats items as arms, generating diverse recommendations\ninformed by the user-bandit's output. CoCoB dynamically adapts, leveraging\nneighbor preferences when available or focusing solely on the target user\notherwise. Regret analysis under a linear contextual bandit setting and\nexperiments on three real-world datasets demonstrate CoCoB's effectiveness,\nachieving an average 2.4% improvement in F1 score over state-of-the-art\nmethods.", "AI": {"tldr": "CoCoB, a two-sided bandit algorithm, improves clustering bandits by dynamically adapting to user similarity and item diversity, outperforming state-of-the-art methods by 2.4% in F1 score.", "motivation": "Existing clustering bandits lack clear user similarity definitions and struggle with unique preferences, degrading recommendation quality.", "method": "CoCoB uses a two-sided bandit architecture: a user-bandit with Bayesian similarity modeling and an item-bandit for diverse recommendations.", "result": "Experiments show CoCoB achieves a 2.4% F1 score improvement over top methods.", "conclusion": "CoCoB effectively addresses limitations of clustering bandits by adaptively leveraging neighbor preferences or focusing on target users."}}
{"id": "2505.03923", "pdf": "https://arxiv.org/pdf/2505.03923", "abs": "https://arxiv.org/abs/2505.03923", "authors": ["Pedram Pad", "Hadi Hammoud", "Mohamad Dia", "Nadim Maamari", "L. Andrea Dunbar"], "title": "SAND: One-Shot Feature Selection with Additive Noise Distortion", "categories": ["cs.LG"], "comment": "Proceedings of the 42nd International Conference on Machine Learning\n  (ICML), Vancouver, Canada. PMLR 267, 2025", "summary": "Feature selection is a critical step in data-driven applications, reducing\ninput dimensionality to enhance learning accuracy, computational efficiency,\nand interpretability. Existing state-of-the-art methods often require\npost-selection retraining and extensive hyperparameter tuning, complicating\ntheir adoption. We introduce a novel, non-intrusive feature selection layer\nthat, given a target feature count $k$, automatically identifies and selects\nthe $k$ most informative features during neural network training. Our method is\nuniquely simple, requiring no alterations to the loss function, network\narchitecture, or post-selection retraining. The layer is mathematically elegant\nand can be fully described by: \\begin{align} \\nonumber \\tilde{x}_i = a_i x_i +\n(1-a_i)z_i \\end{align} where $x_i$ is the input feature, $\\tilde{x}_i$ the\noutput, $z_i$ a Gaussian noise, and $a_i$ trainable gain such that\n$\\sum_i{a_i^2}=k$. This formulation induces an automatic clustering effect,\ndriving $k$ of the $a_i$ gains to $1$ (selecting informative features) and the\nrest to $0$ (discarding redundant ones) via weighted noise distortion and gain\nnormalization. Despite its extreme simplicity, our method delivers\nstate-of-the-art performance on standard benchmark datasets and a novel\nreal-world dataset, outperforming or matching existing approaches without\nrequiring hyperparameter search for $k$ or retraining. Theoretical analysis in\nthe context of linear regression further validates its efficacy. Our work\ndemonstrates that simplicity and performance are not mutually exclusive,\noffering a powerful yet straightforward tool for feature selection in machine\nlearning.", "AI": {"tldr": "A novel, non-intrusive feature selection layer for neural networks automatically selects the most informative features during training, eliminating the need for retraining or hyperparameter tuning.", "motivation": "Existing feature selection methods require post-selection retraining and extensive hyperparameter tuning, complicating adoption.", "method": "Introduces a simple feature selection layer using trainable gains and Gaussian noise to automatically select features, with no changes to loss function or architecture.", "result": "Achieves state-of-the-art performance on benchmarks and real-world datasets without hyperparameter search or retraining.", "conclusion": "Demonstrates that simplicity and performance can coexist, providing an effective, straightforward tool for feature selection."}}
{"id": "2505.04376", "pdf": "https://arxiv.org/pdf/2505.04376", "abs": "https://arxiv.org/abs/2505.04376", "authors": ["Zili Zhang", "Ziting Wen", "Yiheng Qiang", "Hongzhou Dong", "Wenle Dong", "Xinyang Li", "Xiaofan Wang", "Xiaoqiang Ren"], "title": "Label-efficient Single Photon Images Classification via Active Learning", "categories": ["cs.CV"], "comment": null, "summary": "Single-photon LiDAR achieves high-precision 3D imaging in extreme\nenvironments through quantum-level photon detection technology. Current\nresearch primarily focuses on reconstructing 3D scenes from sparse photon\nevents, whereas the semantic interpretation of single-photon images remains\nunderexplored, due to high annotation costs and inefficient labeling\nstrategies. This paper presents the first active learning framework for\nsingle-photon image classification. The core contribution is an imaging\ncondition-aware sampling strategy that integrates synthetic augmentation to\nmodel variability across imaging conditions. By identifying samples where the\nmodel is both uncertain and sensitive to these conditions, the proposed method\nselectively annotates only the most informative examples. Experiments on both\nsynthetic and real-world datasets show that our approach outperforms all\nbaselines and achieves high classification accuracy with significantly fewer\nlabeled samples. Specifically, our approach achieves 97% accuracy on synthetic\nsingle-photon data using only 1.5% labeled samples. On real-world data, we\nmaintain 90.63% accuracy with just 8% labeled samples, which is 4.51% higher\nthan the best-performing baseline. This illustrates that active learning\nenables the same level of classification performance on single-photon images as\non classical images, opening doors to large-scale integration of single-photon\ndata in real-world applications.", "AI": {"tldr": "The paper introduces an active learning framework for single-photon image classification, using a condition-aware sampling strategy to reduce annotation costs while achieving high accuracy.", "motivation": "Semantic interpretation of single-photon images is underexplored due to high annotation costs and inefficient labeling.", "method": "Proposes an imaging condition-aware sampling strategy with synthetic augmentation to selectively annotate informative samples.", "result": "Achieves 97% accuracy on synthetic data with 1.5% labeled samples and 90.63% on real-world data with 8% labeled samples, outperforming baselines.", "conclusion": "Active learning enables efficient classification of single-photon images, facilitating their large-scale real-world use."}}
{"id": "2503.11280", "pdf": "https://arxiv.org/pdf/2503.11280", "abs": "https://arxiv.org/abs/2503.11280", "authors": ["Bryan Wilie", "Samuel Cahyawijaya", "Junxian He", "Pascale Fung"], "title": "High-Dimensional Interlingual Representations of Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) trained on massive multilingual datasets hint at\nthe formation of interlingual constructs--a shared subspace in the\nrepresentation space. However, evidence regarding this phenomenon is mixed,\nleaving it unclear whether these models truly develop unified interlingual\nrepresentations, or present a partially aligned constructs. We explore 31\ndiverse languages varying on their resource-levels, typologies, and\ngeographical regions; and find that multilingual LLMs exhibit inconsistent\ncross-lingual alignments. To address this, we propose an interlingual\nrepresentation framework identifying both the shared interlingual semantic\nsubspace and fragmented components, existed due to representational\nlimitations. We introduce Interlingual Local Overlap (ILO) score to quantify\ninterlingual alignment by comparing the local neighborhood structures of\nhigh-dimensional representations. We utilize ILO to investigate the impact of\nsingle-language fine-tuning on the interlingual representations in multilingual\nLLMs. Our results indicate that training exclusively on a single language\ndisrupts the alignment in early layers, while freezing these layers preserves\nthe alignment of interlingual representations, leading to improved\ncross-lingual generalization. These results validate our framework and metric\nfor evaluating interlingual representation, and further underscore that\ninterlingual alignment is crucial for scalable multilingual learning.", "AI": {"tldr": "Multilingual LLMs show inconsistent cross-lingual alignments. A framework and metric (ILO) are proposed to evaluate shared and fragmented interlingual representations, revealing that single-language fine-tuning disrupts alignment unless early layers are frozen.", "motivation": "To clarify whether multilingual LLMs develop unified interlingual representations or partially aligned constructs, given mixed evidence.", "method": "Study 31 diverse languages, propose an interlingual representation framework, and introduce the ILO score to quantify alignment. Investigate the impact of single-language fine-tuning.", "result": "Single-language fine-tuning disrupts alignment in early layers; freezing these layers preserves alignment and improves cross-lingual generalization.", "conclusion": "Interlingual alignment is crucial for scalable multilingual learning, validated by the proposed framework and ILO metric."}}
{"id": "2505.03850", "pdf": "https://arxiv.org/pdf/2505.03850", "abs": "https://arxiv.org/abs/2505.03850", "authors": ["Hanlin Chen", "Simin Chen", "Wenyu Li", "Wei Yang", "Yiheng Feng"], "title": "Impact Analysis of Inference Time Attack of Perception Sensors on Autonomous Vehicles", "categories": ["cs.CR", "cs.AI"], "comment": "Accepted and presented in TRBAM 2024", "summary": "As a safety-critical cyber-physical system, cybersecurity and related safety\nissues for Autonomous Vehicles (AVs) have been important research topics for a\nwhile. Among all the modules on AVs, perception is one of the most accessible\nattack surfaces, as drivers and AVs have no control over the outside\nenvironment. Most current work targeting perception security for AVs focuses on\nperception correctness. In this work, we propose an impact analysis based on\ninference time attacks for autonomous vehicles. We demonstrate in a simulation\nsystem that such inference time attacks can also threaten the safety of both\nthe ego vehicle and other traffic participants.", "AI": {"tldr": "The paper analyzes the safety impact of inference time attacks on autonomous vehicles' perception systems, showing threats to both the ego vehicle and other traffic participants.", "motivation": "Autonomous vehicles (AVs) are safety-critical systems, and perception security is a key concern due to uncontrolled external environments. Most research focuses on perception correctness, but this work explores the safety implications of inference time attacks.", "method": "The study uses a simulation system to demonstrate the effects of inference time attacks on AV perception.", "result": "The results show that such attacks can compromise the safety of the ego vehicle and other traffic participants.", "conclusion": "The work highlights the need to address inference time attacks in AV perception security to ensure overall safety."}}
{"id": "2505.03949", "pdf": "https://arxiv.org/pdf/2505.03949", "abs": "https://arxiv.org/abs/2505.03949", "authors": ["John Christopher Tidwell", "John Storm Tidwell"], "title": "Deep Q-Network (DQN) multi-agent reinforcement learning (MARL) for Stock Trading", "categories": ["cs.LG"], "comment": null, "summary": "This project addresses the challenge of automated stock trading, where\ntraditional methods and direct reinforcement learning (RL) struggle with market\nnoise, complexity, and generalization. Our proposed solution is an integrated\ndeep learning framework combining a Convolutional Neural Network (CNN) to\nidentify patterns in technical indicators formatted as images, a Long\nShort-Term Memory (LSTM) network to capture temporal dependencies across both\nprice history and technical indicators, and a Deep Q-Network (DQN) agent which\nlearns the optimal trading policy (buy, sell, hold) based on the features\nextracted by the CNN and LSTM.", "AI": {"tldr": "A deep learning framework combining CNN, LSTM, and DQN for automated stock trading to overcome market noise and complexity.", "motivation": "Traditional methods and direct RL struggle with market noise, complexity, and generalization in stock trading.", "method": "Integrated framework using CNN for pattern recognition in technical indicators, LSTM for temporal dependencies, and DQN for optimal trading policy.", "result": "Proposed solution aims to improve trading decisions by leveraging deep learning techniques.", "conclusion": "The framework addresses limitations of traditional methods and RL, offering a robust approach for automated stock trading."}}
{"id": "2505.04380", "pdf": "https://arxiv.org/pdf/2505.04380", "abs": "https://arxiv.org/abs/2505.04380", "authors": ["Jinhai Xiang", "Shuai Guo", "Qianru Han", "Dantong Shi", "Xinwei He", "Xiang Bai"], "title": "Tetrahedron-Net for Medical Image Registration", "categories": ["cs.CV", "cs.IR"], "comment": null, "summary": "Medical image registration plays a vital role in medical image processing.\nExtracting expressive representations for medical images is crucial for\nimproving the registration quality. One common practice for this end is\nconstructing a convolutional backbone to enable interactions with skip\nconnections among feature extraction layers. The de facto structure, U-Net-like\nnetworks, has attempted to design skip connections such as nested or full-scale\nones to connect one single encoder and one single decoder to improve its\nrepresentation capacity. Despite being effective, it still does not fully\nexplore interactions with a single encoder and decoder architectures. In this\npaper, we embrace this observation and introduce a simple yet effective\nalternative strategy to enhance the representations for registrations by\nappending one additional decoder. The new decoder is designed to interact with\nboth the original encoder and decoder. In this way, it not only reuses feature\npresentation from corresponding layers in the encoder but also interacts with\nthe original decoder to corporately give more accurate registration results.\nThe new architecture is concise yet generalized, with only one encoder and two\ndecoders forming a ``Tetrahedron'' structure, thereby dubbed Tetrahedron-Net.\nThree instantiations of Tetrahedron-Net are further constructed regarding the\ndifferent structures of the appended decoder. Our extensive experiments prove\nthat superior performance can be obtained on several representative benchmarks\nof medical image registration. Finally, such a ``Tetrahedron'' design can also\nbe easily integrated into popular U-Net-like architectures including\nVoxelMorph, ViT-V-Net, and TransMorph, leading to consistent performance gains.", "AI": {"tldr": "The paper introduces Tetrahedron-Net, a new architecture for medical image registration, adding an extra decoder to U-Net-like structures for improved feature interaction and performance.", "motivation": "Current U-Net-like networks for medical image registration don't fully explore interactions within single encoder-decoder architectures, limiting representation capacity.", "method": "Proposes Tetrahedron-Net, adding a second decoder to interact with both the encoder and original decoder, forming a 'Tetrahedron' structure.", "result": "Experiments show superior performance on medical image registration benchmarks, with consistent gains when integrated into existing U-Net-like architectures.", "conclusion": "The Tetrahedron-Net design is simple, effective, and generalizable, enhancing registration accuracy by improving feature interactions."}}
{"id": "2503.21813", "pdf": "https://arxiv.org/pdf/2503.21813", "abs": "https://arxiv.org/abs/2503.21813", "authors": ["Zhangcheng Qiang"], "title": "OAEI-LLM-T: A TBox Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching", "categories": ["cs.CL", "cs.IR"], "comment": "15 pages, 4 figures, 5 tables, 2 prompt templates", "summary": "Hallucinations are often inevitable in downstream tasks using large language\nmodels (LLMs). To tackle the substantial challenge of addressing hallucinations\nfor LLM-based ontology matching (OM) systems, we introduce a new benchmark\ndataset called OAEI-LLM-T. The dataset evolves from the TBox (i.e.\nschema-matching) datasets in the Ontology Alignment Evaluation Initiative\n(OAEI), capturing hallucinations of different LLMs performing OM tasks. These\nOM-specific hallucinations are carefully classified into two primary categories\nand six sub-categories. We showcase the usefulness of the dataset in\nconstructing the LLM leaderboard and fine-tuning foundational LLMs for\nLLM-based OM systems.", "AI": {"tldr": "A new benchmark dataset, OAEI-LLM-T, is introduced to address hallucinations in LLM-based ontology matching, classifying them into categories and sub-categories for leaderboard construction and LLM fine-tuning.", "motivation": "Hallucinations in LLMs pose challenges for ontology matching tasks, necessitating a dedicated dataset to study and mitigate these issues.", "method": "The dataset, derived from OAEI TBox datasets, captures and classifies LLM hallucinations in ontology matching into two main categories and six sub-categories.", "result": "OAEI-LLM-T enables the construction of an LLM leaderboard and supports fine-tuning of foundational LLMs for improved ontology matching.", "conclusion": "The dataset provides a valuable tool for benchmarking and enhancing LLM performance in ontology matching by addressing hallucinations systematically."}}
{"id": "2505.03853", "pdf": "https://arxiv.org/pdf/2505.03853", "abs": "https://arxiv.org/abs/2505.03853", "authors": ["Changxi Chi", "Jun Xia", "Jingbo Zhou", "Jiabei Cheng", "Chang Yu", "Stan Z. Li"], "title": "GRAPE: Heterogeneous Graph Representation Learning for Genetic Perturbation with Coding and Non-Coding Biotype", "categories": ["q-bio.QM", "cs.AI"], "comment": null, "summary": "Predicting genetic perturbations enables the identification of potentially\ncrucial genes prior to wet-lab experiments, significantly improving overall\nexperimental efficiency. Since genes are the foundation of cellular life,\nbuilding gene regulatory networks (GRN) is essential to understand and predict\nthe effects of genetic perturbations. However, current methods fail to fully\nleverage gene-related information, and solely rely on simple evaluation metrics\nto construct coarse-grained GRN. More importantly, they ignore functional\ndifferences between biotypes, limiting the ability to capture potential gene\ninteractions. In this work, we leverage pre-trained large language model and\nDNA sequence model to extract features from gene descriptions and DNA sequence\ndata, respectively, which serve as the initialization for gene representations.\nAdditionally, we introduce gene biotype information for the first time in\ngenetic perturbation, simulating the distinct roles of genes with different\nbiotypes in regulating cellular processes, while capturing implicit gene\nrelationships through graph structure learning (GSL). We propose GRAPE, a\nheterogeneous graph neural network (HGNN) that leverages gene representations\ninitialized with features from descriptions and sequences, models the distinct\nroles of genes with different biotypes, and dynamically refines the GRN through\nGSL. The results on publicly available datasets show that our method achieves\nstate-of-the-art performance.", "AI": {"tldr": "GRAPE, a heterogeneous graph neural network, leverages gene descriptions and DNA sequences to improve gene regulatory network (GRN) construction by incorporating biotype information and graph structure learning, achieving state-of-the-art results.", "motivation": "Current methods for GRN construction inadequately utilize gene-related information and ignore biotype functional differences, limiting their predictive power for genetic perturbations.", "method": "GRAPE uses pre-trained models to extract gene features from descriptions and sequences, incorporates biotype roles, and refines GRN via graph structure learning.", "result": "GRAPE outperforms existing methods on public datasets, demonstrating superior performance in GRN construction.", "conclusion": "GRAPE advances GRN prediction by integrating diverse gene features and biotype roles, offering a more accurate tool for genetic perturbation studies."}}
{"id": "2505.03953", "pdf": "https://arxiv.org/pdf/2505.03953", "abs": "https://arxiv.org/abs/2505.03953", "authors": ["Noah Schutte", "Grigorii Veviurko", "Krzysztof Postek", "Neil Yorke-Smith"], "title": "Sufficient Decision Proxies for Decision-Focused Learning", "categories": ["cs.LG", "math.OC"], "comment": "16 pages, 4 figures,", "summary": "When solving optimization problems under uncertainty with contextual data,\nutilizing machine learning to predict the uncertain parameters is a popular and\neffective approach. Decision-focused learning (DFL) aims at learning a\npredictive model such that decision quality, instead of prediction accuracy, is\nmaximized. Common practice here is to predict a single value for each uncertain\nparameter, implicitly assuming that there exists a (single-scenario)\ndeterministic problem approximation (proxy) that is sufficient to obtain an\noptimal decision. Other work assumes the opposite, where the underlying\ndistribution needs to be estimated. However, little is known about when either\nchoice is valid. This paper investigates for the first time problem properties\nthat justify using either assumption. Using this, we present effective decision\nproxies for DFL, with very limited compromise on the complexity of the learning\ntask. We show the effectiveness of presented approaches in experiments on\nproblems with continuous and discrete variables, as well as uncertainty in the\nobjective function and in the constraints.", "AI": {"tldr": "The paper explores problem properties that justify using single-scenario deterministic proxies or distribution estimation in Decision-Focused Learning (DFL) for optimization under uncertainty. It introduces effective decision proxies with minimal learning complexity and demonstrates their success in experiments.", "motivation": "The motivation is to address the gap in understanding when to use single-scenario deterministic proxies versus distribution estimation in DFL, aiming to maximize decision quality rather than prediction accuracy.", "method": "The study investigates problem properties to justify assumptions, proposes effective decision proxies for DFL, and tests them on problems with continuous/discrete variables and uncertainty in objectives/constraints.", "result": "The presented approaches prove effective in experiments, showing minimal compromise on learning complexity while improving decision quality.", "conclusion": "The paper concludes that understanding problem properties can guide the choice between single-scenario proxies and distribution estimation in DFL, offering practical solutions for optimization under uncertainty."}}
{"id": "2505.04384", "pdf": "https://arxiv.org/pdf/2505.04384", "abs": "https://arxiv.org/abs/2505.04384", "authors": ["Ming-Hui Liu", "Xiao-Qian Liu", "Xin Luo", "Xin-Shun Xu"], "title": "DATA: Multi-Disentanglement based Contrastive Learning for Open-World Semi-Supervised Deepfake Attribution", "categories": ["cs.CV"], "comment": "Accepted by IEEE TMM on 17-Jan-2025; Submitted to IEEE TMM on\n  11-Jul-2024", "summary": "Deepfake attribution (DFA) aims to perform multiclassification on different\nfacial manipulation techniques, thereby mitigating the detrimental effects of\nforgery content on the social order and personal reputations. However, previous\nmethods focus only on method-specific clues, which easily lead to overfitting,\nwhile overlooking the crucial role of common forgery features. Additionally,\nthey struggle to distinguish between uncertain novel classes in more practical\nopen-world scenarios. To address these issues, in this paper we propose an\ninnovative multi-DisentAnglement based conTrastive leArning framework, DATA, to\nenhance the generalization ability on novel classes for the open-world\nsemi-supervised deepfake attribution (OSS-DFA) task. Specifically, since all\ngeneration techniques can be abstracted into a similar architecture, DATA\ndefines the concept of 'Orthonormal Deepfake Basis' for the first time and\nutilizes it to disentangle method-specific features, thereby reducing the\noverfitting on forgery-irrelevant information. Furthermore, an augmented-memory\nmechanism is designed to assist in novel class discovery and contrastive\nlearning, which aims to obtain clear class boundaries for the novel classes\nthrough instance-level disentanglements. Additionally, to enhance the\nstandardization and discrimination of features, DATA uses bases contrastive\nloss and center contrastive loss as auxiliaries for the aforementioned modules.\nExtensive experimental evaluations show that DATA achieves state-of-the-art\nperformance on the OSS-DFA benchmark, e.g., there are notable accuracy\nimprovements in 2.55% / 5.7% under different settings, compared with the\nexisting methods.", "AI": {"tldr": "The paper proposes DATA, a multi-DisentAnglement based conTrastive leArning framework, to improve generalization for open-world semi-supervised deepfake attribution by disentangling method-specific features and enhancing novel class discovery.", "motivation": "Address limitations of previous methods that overfit to method-specific clues and struggle with novel classes in open-world scenarios.", "method": "Introduces 'Orthonormal Deepfake Basis' to disentangle features and uses augmented-memory for contrastive learning to improve class boundaries.", "result": "Achieves state-of-the-art performance with notable accuracy improvements (2.55%/5.7%) on the OSS-DFA benchmark.", "conclusion": "DATA effectively enhances generalization and discrimination for deepfake attribution in open-world settings."}}
{"id": "2504.18884", "pdf": "https://arxiv.org/pdf/2504.18884", "abs": "https://arxiv.org/abs/2504.18884", "authors": ["Junichiro Niimi"], "title": "A Simple Ensemble Strategy for LLM Inference: Towards More Stable Text Classification", "categories": ["cs.CL", "cs.AI"], "comment": "This manuscript has been accepted for the 30th International\n  Conference on Natural Language \\& Information Systems (NLDB 2025) and will\n  appear in Springer Lecture Notes in Computer Science (LNCS)", "summary": "With the advance of large language models (LLMs), LLMs have been utilized for\nthe various tasks. However, the issues of variability and reproducibility of\nresults from each trial of LLMs have been largely overlooked in existing\nliterature while actual human annotation uses majority voting to resolve\ndisagreements among annotators. Therefore, this study introduces the\nstraightforward ensemble strategy to a sentiment analysis using LLMs. As the\nresults, we demonstrate that the ensemble of multiple inference using\nmedium-sized LLMs produces more robust and accurate results than using a large\nmodel with a single attempt with reducing RMSE by 18.6%.", "AI": {"tldr": "Ensemble strategy for LLMs improves sentiment analysis accuracy and robustness, reducing RMSE by 18.6%.", "motivation": "Address variability and reproducibility issues in LLM results, inspired by human annotation's majority voting.", "method": "Straightforward ensemble of multiple inferences using medium-sized LLMs.", "result": "Ensemble outperforms single large-model attempts, reducing RMSE by 18.6%.", "conclusion": "Ensemble strategy enhances LLM performance in sentiment analysis."}}
{"id": "2505.03859", "pdf": "https://arxiv.org/pdf/2505.03859", "abs": "https://arxiv.org/abs/2505.03859", "authors": ["Will Hawkins", "Chris Russell", "Brent Mittelstadt"], "title": "Deepfakes on Demand: the rise of accessible non-consensual deepfake image generators", "categories": ["cs.CY", "cs.AI", "cs.CV", "68T01"], "comment": "13 pages", "summary": "Advances in multimodal machine learning have made text-to-image (T2I) models\nincreasingly accessible and popular. However, T2I models introduce risks such\nas the generation of non-consensual depictions of identifiable individuals,\notherwise known as deepfakes. This paper presents an empirical study exploring\nthe accessibility of deepfake model variants online. Through a metadata\nanalysis of thousands of publicly downloadable model variants on two popular\nrepositories, Hugging Face and Civitai, we demonstrate a huge rise in easily\naccessible deepfake models. Almost 35,000 examples of publicly downloadable\ndeepfake model variants are identified, primarily hosted on Civitai. These\ndeepfake models have been downloaded almost 15 million times since November\n2022, with the models targeting a range of individuals from global celebrities\nto Instagram users with under 10,000 followers. Both Stable Diffusion and Flux\nmodels are used for the creation of deepfake models, with 96% of these\ntargeting women and many signalling intent to generate non-consensual intimate\nimagery (NCII). Deepfake model variants are often created via the\nparameter-efficient fine-tuning technique known as low rank adaptation (LoRA),\nrequiring as few as 20 images, 24GB VRAM, and 15 minutes of time, making this\nprocess widely accessible via consumer-grade computers. Despite these models\nviolating the Terms of Service of hosting platforms, and regulation seeking to\nprevent dissemination, these results emphasise the pressing need for greater\naction to be taken against the creation of deepfakes and NCII.", "AI": {"tldr": "The paper highlights the alarming rise in accessible deepfake models online, primarily targeting women, and calls for urgent action to combat their creation and dissemination.", "motivation": "The study aims to expose the accessibility and risks of deepfake models, particularly those generating non-consensual intimate imagery (NCII), to advocate for stronger regulatory measures.", "method": "The researchers conducted a metadata analysis of thousands of publicly downloadable deepfake model variants on Hugging Face and Civitai, focusing on their prevalence, targets, and technical requirements.", "result": "Almost 35,000 deepfake model variants were identified, downloaded 15 million times since November 2022, with 96% targeting women and many intended for NCII. These models require minimal resources (e.g., 20 images, 24GB VRAM, 15 minutes) for creation.", "conclusion": "The findings underscore the urgent need for stricter enforcement of platform policies and regulations to curb the proliferation of deepfake models and NCII."}}
{"id": "2505.03955", "pdf": "https://arxiv.org/pdf/2505.03955", "abs": "https://arxiv.org/abs/2505.03955", "authors": ["Charupriya Sharma", "I\u00f1aki Estella Aguerri", "Daniel Guimarans"], "title": "Hierarchical Forecast Reconciliation on Networks: A Network Flow Optimization Formulation", "categories": ["cs.LG"], "comment": null, "summary": "Hierarchical forecasting with reconciliation requires forecasting values of a\nhierarchy (e.g.~customer demand in a state and district), such that forecast\nvalues are linked (e.g.~ district forecasts should add up to the state\nforecast). Basic forecasting provides no guarantee for these desired structural\nrelationships. Reconciliation addresses this problem, which is crucial for\norganizations requiring coherent predictions across multiple aggregation\nlevels. Current methods like minimum trace (MinT) are mostly limited to tree\nstructures and are computationally expensive. We introduce FlowRec, which\nreformulates hierarchical forecast reconciliation as a network flow\noptimization, enabling forecasting on generalized network structures. While\nreconciliation under the $\\ell_0$ norm is NP-hard, we prove polynomial-time\nsolvability for all $\\ell_{p > 0}$ norms and , for any strictly convex and\ncontinuously differentiable loss function. For sparse networks, FlowRec\nachieves $O(n^2\\log n)$ complexity, significantly improving upon MinT's\n$O(n^3)$. Furthermore, we prove that FlowRec extends MinT to handle general\nnetworks, replacing MinT's error-covariance estimation step with direct network\nstructural information. A key novelty of our approach is its handling of\ndynamic scenarios: while traditional methods recompute both base forecasts and\nreconciliation, FlowRec provides efficient localised updates with optimality\nguarantees. Monotonicity ensures that when forecasts improve incrementally, the\ninitial reconciliation remains optimal. We also establish efficient,\nerror-bounded approximate reconciliation, enabling fast updates in\ntime-critical applications. Experiments on both simulated and real benchmarks\ndemonstrate that FlowRec improves accuracy, runtime by 3-40x and memory usage\nby 5-7x. These results establish FlowRec as a powerful tool for large-scale\nhierarchical forecasting applications.", "AI": {"tldr": "FlowRec introduces a network flow optimization approach for hierarchical forecast reconciliation, improving efficiency and scalability over traditional methods like MinT.", "motivation": "Hierarchical forecasting requires coherent predictions across aggregation levels, but current methods are limited to tree structures and computationally expensive.", "method": "FlowRec reformulates reconciliation as a network flow optimization, enabling generalized network structures and efficient updates.", "result": "FlowRec achieves significant improvements in accuracy, runtime (3-40x), and memory usage (5-7x) over MinT.", "conclusion": "FlowRec is a scalable and efficient solution for large-scale hierarchical forecasting, with optimality guarantees and dynamic update capabilities."}}
{"id": "2505.04392", "pdf": "https://arxiv.org/pdf/2505.04392", "abs": "https://arxiv.org/abs/2505.04392", "authors": ["Petr Jahoda", "Jan Cech"], "title": "Predicting Road Surface Anomalies by Visual Tracking of a Preceding Vehicle", "categories": ["cs.CV"], "comment": "Accepted to the IEEE Intelligent Vehicles Symposium (IV), 2025", "summary": "A novel approach to detect road surface anomalies by visual tracking of a\npreceding vehicle is proposed. The method is versatile, predicting any kind of\nroad anomalies, such as potholes, bumps, debris, etc., unlike direct\nobservation methods that rely on training visual detectors of those cases. The\nmethod operates in low visibility conditions or in dense traffic where the\nanomaly is occluded by a preceding vehicle. Anomalies are detected\npredictively, i.e., before a vehicle encounters them, which allows to\npre-configure low-level vehicle systems (such as chassis) or to plan an\navoidance maneuver in case of autonomous driving. A challenge is that the\nsignal coming from camera-based tracking of a preceding vehicle may be weak and\ndisturbed by camera ego motion due to vibrations affecting the ego vehicle.\nTherefore, we propose an efficient method to compensate camera pitch rotation\nby an iterative robust estimator. Our experiments on both controlled setup and\nnormal traffic conditions show that road anomalies can be detected reliably at\na distance even in challenging cases where the ego vehicle traverses imperfect\nroad surfaces. The method is effective and performs in real time on standard\nconsumer hardware.", "AI": {"tldr": "A novel method detects road anomalies by tracking a preceding vehicle, working in low visibility or dense traffic. It compensates for camera motion and performs in real time.", "motivation": "Current methods rely on direct observation, which is limited in low visibility or dense traffic. This approach aims to predict anomalies before encountering them.", "method": "Uses visual tracking of a preceding vehicle and compensates for camera pitch rotation with an iterative robust estimator.", "result": "Reliably detects road anomalies at a distance, even in challenging conditions, and operates in real time.", "conclusion": "The method is versatile, effective, and suitable for real-time applications on standard hardware."}}
{"id": "2504.20752", "pdf": "https://arxiv.org/pdf/2504.20752", "abs": "https://arxiv.org/abs/2504.20752", "authors": ["Roman Abramov", "Felix Steinbauer", "Gjergji Kasneci"], "title": "Grokking in the Wild: Data Augmentation for Real-World Multi-Hop Reasoning with Transformers", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7; I.2.6; I.2.3; I.7"], "comment": "Accepted to the International Conference on Machine Learning (ICML)\n  2025", "summary": "Transformers have achieved great success in numerous NLP tasks but continue\nto exhibit notable gaps in multi-step factual reasoning, especially when\nreal-world knowledge is sparse. Recent advances in grokking have demonstrated\nthat neural networks can transition from memorizing to perfectly generalizing\nonce they detect underlying logical patterns - yet these studies have primarily\nused small, synthetic tasks. In this paper, for the first time, we extend\ngrokking to real-world factual data and address the challenge of dataset\nsparsity by augmenting existing knowledge graphs with carefully designed\nsynthetic data to raise the ratio $\\phi_r$ of inferred facts to atomic facts\nabove the threshold required for grokking. Surprisingly, we find that even\nfactually incorrect synthetic data can strengthen emergent reasoning circuits\nrather than degrade accuracy, as it forces the model to rely on relational\nstructure rather than memorization. When evaluated on multi-hop reasoning\nbenchmarks, our approach achieves up to 95-100% accuracy on 2WikiMultiHopQA -\nsubstantially improving over strong baselines and matching or exceeding current\nstate-of-the-art results. We further provide an in-depth analysis of how\nincreasing $\\phi_r$ drives the formation of generalizing circuits inside\nTransformers. Our findings suggest that grokking-based data augmentation can\nunlock implicit multi-hop reasoning capabilities, opening the door to more\nrobust and interpretable factual reasoning in large-scale language models.", "AI": {"tldr": "Extending grokking to real-world data by augmenting knowledge graphs with synthetic data improves multi-hop reasoning accuracy in Transformers.", "motivation": "Addressing gaps in multi-step factual reasoning in Transformers, especially with sparse real-world knowledge.", "method": "Augmenting knowledge graphs with synthetic data to increase the ratio of inferred to atomic facts, enabling grokking.", "result": "Achieves 95-100% accuracy on 2WikiMultiHopQA, surpassing baselines and matching state-of-the-art.", "conclusion": "Grokking-based data augmentation enhances multi-hop reasoning, offering robust and interpretable factual reasoning in language models."}}
{"id": "2505.03863", "pdf": "https://arxiv.org/pdf/2505.03863", "abs": "https://arxiv.org/abs/2505.03863", "authors": ["Atanu Kundu", "Sauvik Gon", "Rajarshi Ray"], "title": "Data-Driven Falsification of Cyber-Physical Systems", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Cyber-Physical Systems (CPS) are abundant in safety-critical domains such as\nhealthcare, avionics, and autonomous vehicles. Formal verification of their\noperational safety is, therefore, of utmost importance. In this paper, we\naddress the falsification problem, where the focus is on searching for an\nunsafe execution in the system instead of proving their absence. The\ncontribution of this paper is a framework that (a) connects the falsification\nof CPS with the falsification of deep neural networks (DNNs) and (b) leverages\nthe inherent interpretability of Decision Trees for faster falsification of\nCPS. This is achieved by: (1) building a surrogate model of the CPS under test,\neither as a DNN model or a Decision Tree, (2) application of various DNN\nfalsification tools to falsify CPS, and (3) a novel falsification algorithm\nguided by the explanations of safety violations of the CPS model extracted from\nits Decision Tree surrogate. The proposed framework has the potential to\nexploit a repertoire of \\emph{adversarial attack} algorithms designed to\nfalsify robustness properties of DNNs, as well as state-of-the-art\nfalsification algorithms for DNNs. Although the presented methodology is\napplicable to systems that can be executed/simulated in general, we demonstrate\nits effectiveness, particularly in CPS. We show that our framework, implemented\nas a tool \\textsc{FlexiFal}, can detect hard-to-find counterexamples in CPS\nthat have linear and non-linear dynamics. Decision tree-guided falsification\nshows promising results in efficiently finding multiple counterexamples in the\nARCH-COMP 2024 falsification benchmarks~\\cite{khandait2024arch}.", "AI": {"tldr": "The paper presents a framework for falsifying Cyber-Physical Systems (CPS) by connecting CPS falsification with deep neural network (DNN) falsification and using Decision Trees for faster results.", "motivation": "Formal verification of CPS safety is critical, but this work focuses on finding unsafe executions rather than proving their absence.", "method": "The framework involves building surrogate models (DNN or Decision Tree), applying DNN falsification tools, and using a novel algorithm guided by Decision Tree explanations.", "result": "The tool FlexiFal effectively detects hard-to-find counterexamples in CPS with linear and non-linear dynamics, showing promising results in benchmarks.", "conclusion": "The framework leverages DNN falsification tools and Decision Trees to efficiently falsify CPS, demonstrating practical effectiveness."}}
{"id": "2505.03977", "pdf": "https://arxiv.org/pdf/2505.03977", "abs": "https://arxiv.org/abs/2505.03977", "authors": ["Guilherme S. Imai Aldeia", "Hengzhe Zhang", "Geoffrey Bomarito", "Miles Cranmer", "Alcides Fonseca", "Bogdan Burlacu", "William G. La Cava", "Fabr\u00edcio Olivetti de Fran\u00e7a"], "title": "Call for Action: towards the next generation of symbolic regression benchmark", "categories": ["cs.LG", "cs.NE"], "comment": "10 pages, 4 figures, 3 tables, accepted in Genetic and Evolutionary\n  Computation Conference (GECCO '25) Symbolic Regression Workshop", "summary": "Symbolic Regression (SR) is a powerful technique for discovering\ninterpretable mathematical expressions. However, benchmarking SR methods\nremains challenging due to the diversity of algorithms, datasets, and\nevaluation criteria. In this work, we present an updated version of SRBench.\nOur benchmark expands the previous one by nearly doubling the number of\nevaluated methods, refining evaluation metrics, and using improved\nvisualizations of the results to understand the performances. Additionally, we\nanalyze trade-offs between model complexity, accuracy, and energy consumption.\nOur results show that no single algorithm dominates across all datasets. We\npropose a call for action from SR community in maintaining and evolving SRBench\nas a living benchmark that reflects the state-of-the-art in symbolic\nregression, by standardizing hyperparameter tuning, execution constraints, and\ncomputational resource allocation. We also propose deprecation criteria to\nmaintain the benchmark's relevance and discuss best practices for improving SR\nalgorithms, such as adaptive hyperparameter tuning and energy-efficient\nimplementations.", "AI": {"tldr": "The paper introduces an updated version of SRBench, a benchmark for Symbolic Regression (SR), expanding methods, refining metrics, and analyzing trade-offs. It highlights the lack of a dominant algorithm and calls for community involvement to maintain SRBench as a living benchmark.", "motivation": "Benchmarking SR methods is challenging due to diverse algorithms, datasets, and evaluation criteria. The paper aims to improve SRBench to better reflect the state-of-the-art in SR.", "method": "The authors update SRBench by doubling the evaluated methods, refining metrics, and improving visualizations. They analyze trade-offs between complexity, accuracy, and energy consumption.", "result": "No single algorithm performs best across all datasets. The paper emphasizes the need for standardized hyperparameter tuning and resource allocation.", "conclusion": "The paper calls for community action to maintain SRBench, proposes deprecation criteria, and suggests best practices like adaptive tuning and energy efficiency."}}
{"id": "2505.04397", "pdf": "https://arxiv.org/pdf/2505.04397", "abs": "https://arxiv.org/abs/2505.04397", "authors": ["Ziyuan Li", "Uwe Jaekel", "Babette Dellen"], "title": "Deep residual learning with product units", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We propose a deep product-unit residual neural network (PURe) that integrates\nproduct units into residual blocks to improve the expressiveness and parameter\nefficiency of deep convolutional networks. Unlike standard summation neurons,\nproduct units enable multiplicative feature interactions, potentially offering\na more powerful representation of complex patterns. PURe replaces conventional\nconvolutional layers with 2D product units in the second layer of each residual\nblock, eliminating nonlinear activation functions to preserve structural\ninformation. We validate PURe on three benchmark datasets. On Galaxy10 DECaLS,\nPURe34 achieves the highest test accuracy of 84.89%, surpassing the much deeper\nResNet152, while converging nearly five times faster and demonstrating strong\nrobustness to Poisson noise. On ImageNet, PURe architectures outperform\nstandard ResNet models at similar depths, with PURe34 achieving a top-1\naccuracy of 80.27% and top-5 accuracy of 95.78%, surpassing deeper ResNet\nvariants (ResNet50, ResNet101) while utilizing significantly fewer parameters\nand computational resources. On CIFAR-10, PURe consistently outperforms ResNet\nvariants across varying depths, with PURe272 reaching 95.01% test accuracy,\ncomparable to ResNet1001 but at less than half the model size. These results\ndemonstrate that PURe achieves a favorable balance between accuracy,\nefficiency, and robustness. Compared to traditional residual networks, PURe not\nonly achieves competitive classification performance with faster convergence\nand fewer parameters, but also demonstrates greater robustness to noise. Its\neffectiveness across diverse datasets highlights the potential of\nproduct-unit-based architectures for scalable and reliable deep learning in\ncomputer vision.", "AI": {"tldr": "PURe, a deep product-unit residual neural network, enhances expressiveness and efficiency by integrating product units into residual blocks, outperforming deeper ResNet models on multiple benchmarks with fewer parameters and faster convergence.", "motivation": "To improve the expressiveness and parameter efficiency of deep convolutional networks by leveraging multiplicative feature interactions through product units, addressing limitations of standard summation neurons.", "method": "PURe replaces conventional convolutional layers with 2D product units in residual blocks, eliminating nonlinear activation functions to preserve structural information.", "result": "PURe achieves superior accuracy on Galaxy10 DECaLS (84.89%), ImageNet (top-1: 80.27%, top-5: 95.78%), and CIFAR-10 (95.01%) with fewer parameters and faster convergence than ResNet variants.", "conclusion": "PURe balances accuracy, efficiency, and robustness, demonstrating the potential of product-unit-based architectures for scalable and reliable deep learning in computer vision."}}
{"id": "2505.00661", "pdf": "https://arxiv.org/pdf/2505.00661", "abs": "https://arxiv.org/abs/2505.00661", "authors": ["Andrew K. Lampinen", "Arslan Chaudhry", "Stephanie C. Y. Chan", "Cody Wild", "Diane Wan", "Alex Ku", "J\u00f6rg Bornschein", "Razvan Pascanu", "Murray Shanahan", "James L. McClelland"], "title": "On the generalization of language models from in-context learning and finetuning: a controlled study", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models exhibit exciting capabilities, yet can show\nsurprisingly narrow generalization from finetuning. E.g. they can fail to\ngeneralize to simple reversals of relations they are trained on, or fail to\nmake simple logical deductions based on trained information. These failures to\ngeneralize from fine-tuning can hinder practical application of these models.\nOn the other hand, language models' in-context learning shows different\ninductive biases, and can generalize better in some cases. Here, we explore\nthese differences in generalization between in-context- and fine-tuning-based\nlearning. To do so, we constructed several novel datasets to evaluate and\nimprove models' abilities to generalize from finetuning data. The datasets are\ndesigned to create clean tests of generalization, by isolating the knowledge in\nthe dataset from that in pretraining. We expose pretrained large models to\ncontrolled subsets of the information in these datasets -- either in context,\nor through fine-tuning -- and evaluate their performance on test sets that\nrequire various types of generalization. We find overall that in data-matched\nsettings, in-context learning can generalize more flexibly than fine-tuning\n(though we also find some qualifications of prior findings, such as cases when\nfine-tuning can generalize to reversals embedded in a larger structure of\nknowledge). We build on these findings to propose a method to enable improved\ngeneralization from fine-tuning: adding in-context inferences to finetuning\ndata. We show that this method improves generalization across various splits of\nour datasets and other benchmarks. Our results have implications for\nunderstanding the inductive biases of different modes of learning in language\nmodels, and practically improving their performance.", "AI": {"tldr": "The paper explores differences in generalization between in-context learning and fine-tuning in large language models, proposing a method to improve fine-tuning generalization by incorporating in-context inferences.", "motivation": "Large language models often fail to generalize from fine-tuning, hindering practical applications, while in-context learning shows better generalization in some cases.", "method": "Constructed novel datasets to test generalization, comparing in-context learning and fine-tuning, and proposed adding in-context inferences to fine-tuning data.", "result": "In-context learning generalizes more flexibly than fine-tuning in data-matched settings, and the proposed method improves fine-tuning generalization.", "conclusion": "The findings enhance understanding of learning biases in language models and offer practical improvements for their performance."}}
{"id": "2505.03867", "pdf": "https://arxiv.org/pdf/2505.03867", "abs": "https://arxiv.org/abs/2505.03867", "authors": ["Stefania Druga", "Amy J. Ko"], "title": "Scratch Copilot: Supporting Youth Creative Coding with AI", "categories": ["cs.HC", "cs.AI"], "comment": "5 figures, 14 pages", "summary": "Creative coding platforms like Scratch have democratized programming for\nchildren, yet translating imaginative ideas into functional code remains a\nsignificant hurdle for many young learners. While AI copilots assist adult\nprogrammers, few tools target children in block-based environments. Building on\nprior research \\cite{druga_how_2021,druga2023ai, druga2023scratch}, we present\nCognimates Scratch Copilot: an AI-powered assistant integrated into a\nScratch-like environment, providing real-time support for ideation, code\ngeneration, debugging, and asset creation. This paper details the system\narchitecture and findings from an exploratory qualitative evaluation with 18\ninternational children (ages 7--12). Our analysis reveals how the AI Copilot\nsupported key creative coding processes, particularly aiding ideation and\ndebugging. Crucially, it also highlights how children actively negotiated the\nuse of AI, demonstrating strong agency by adapting or rejecting suggestions to\nmaintain creative control. Interactions surfaced design tensions between\nproviding helpful scaffolding and fostering independent problem-solving, as\nwell as learning opportunities arising from navigating AI limitations and\nerrors. Findings indicate Cognimates Scratch Copilot's potential to enhance\ncreative self-efficacy and engagement. Based on these insights, we propose\ninitial design guidelines for AI coding assistants that prioritize youth agency\nand critical interaction alongside supportive scaffolding.", "AI": {"tldr": "Cognimates Scratch Copilot is an AI assistant for children in Scratch-like environments, aiding ideation, coding, and debugging while preserving their creative control.", "motivation": "To address the challenge children face in translating ideas into functional code in block-based programming environments like Scratch.", "method": "Development of an AI-powered assistant (Cognimates Scratch Copilot) and qualitative evaluation with 18 children (ages 7-12).", "result": "The AI Copilot supported ideation and debugging, with children actively negotiating AI use to maintain agency. Design tensions and learning opportunities were identified.", "conclusion": "The tool enhances creative self-efficacy and engagement, with proposed design guidelines prioritizing youth agency and critical interaction."}}
{"id": "2505.03980", "pdf": "https://arxiv.org/pdf/2505.03980", "abs": "https://arxiv.org/abs/2505.03980", "authors": ["Aroon Sankoh", "Victor Wickerhauser"], "title": "Comparing statistical and deep learning techniques for parameter estimation of continuous-time stochastic differentiable equations", "categories": ["cs.LG", "math.PR"], "comment": "6 pages, 2 figures, 2 tables", "summary": "Stochastic differential equations such as the Ornstein-Uhlenbeck process have\nlong been used to model realworld probablistic events such as stock prices and\ntemperature fluctuations. While statistical methods such as Maximum Likelihood\nEstimation (MLE), Kalman Filtering, Inverse Variable Method, and more have\nhistorically been used to estimate the parameters of stochastic differential\nequations, the recent explosion of deep learning technology suggests that\nmodels such as a Recurrent Neural Network (RNN) could produce more precise\nestimators. We present a series of experiments that compare the estimation\naccuracy and computational expensiveness of a statistical method (MLE) with a\ndeep learning model (RNN) for the parameters of the Ornstein-Uhlenbeck process.", "AI": {"tldr": "Comparison of MLE and RNN for estimating Ornstein-Uhlenbeck process parameters.", "motivation": "Traditional statistical methods like MLE are compared with deep learning (RNN) for better accuracy in parameter estimation.", "method": "Experiments comparing MLE and RNN for parameter estimation in the Ornstein-Uhlenbeck process.", "result": "RNN may offer more precise estimators compared to MLE.", "conclusion": "Deep learning (RNN) shows promise for improving parameter estimation in stochastic differential equations."}}
{"id": "2505.04408", "pdf": "https://arxiv.org/pdf/2505.04408", "abs": "https://arxiv.org/abs/2505.04408", "authors": ["Chengjie Huang", "Krzysztof Czarnecki"], "title": "MFSeg: Efficient Multi-frame 3D Semantic Segmentation", "categories": ["cs.CV"], "comment": "ICRA 2025", "summary": "We propose MFSeg, an efficient multi-frame 3D semantic segmentation\nframework. By aggregating point cloud sequences at the feature level and\nregularizing the feature extraction and aggregation process, MFSeg reduces\ncomputational overhead while maintaining high accuracy. Moreover, by employing\na lightweight MLP-based point decoder, our method eliminates the need to\nupsample redundant points from past frames. Experiments on the nuScenes and\nWaymo datasets show that MFSeg outperforms existing methods, demonstrating its\neffectiveness and efficiency.", "AI": {"tldr": "MFSeg is an efficient multi-frame 3D semantic segmentation framework that reduces computational overhead while maintaining accuracy by feature-level aggregation and regularization.", "motivation": "To address the computational inefficiency and redundancy in existing multi-frame 3D semantic segmentation methods.", "method": "Aggregates point cloud sequences at the feature level, regularizes feature extraction, and uses a lightweight MLP-based point decoder to avoid redundant upsampling.", "result": "Outperforms existing methods on nuScenes and Waymo datasets, showing effectiveness and efficiency.", "conclusion": "MFSeg is a promising solution for efficient and accurate multi-frame 3D semantic segmentation."}}
{"id": "2505.00977", "pdf": "https://arxiv.org/pdf/2505.00977", "abs": "https://arxiv.org/abs/2505.00977", "authors": ["Yingquan Chen", "Qianmu Li", "Xiaocong Wu", "Huifeng Li", "Qing Chang"], "title": "A Character-based Diffusion Embedding Algorithm for Enhancing the Generation Quality of Generative Linguistic Steganographic Texts", "categories": ["cs.CL", "cs.CR"], "comment": "we need to clarify authorship and make further revisions in\n  collaboration with co-authors", "summary": "Generating high-quality steganographic text is a fundamental challenge in the\nfield of generative linguistic steganography. This challenge arises primarily\nfrom two aspects: firstly, the capabilities of existing models in text\ngeneration are limited; secondly, embedding algorithms fail to effectively\nmitigate the negative impacts of sensitive information's properties, such as\nsemantic content or randomness. Specifically, to ensure that the recipient can\naccurately extract hidden information, embedding algorithms often have to\nconsider selecting candidate words with relatively low probabilities. This\nphenomenon leads to a decrease in the number of high-probability candidate\nwords and an increase in low-probability candidate words, thereby compromising\nthe semantic coherence and logical fluency of the steganographic text and\ndiminishing the overall quality of the generated steganographic material. To\naddress this issue, this paper proposes a novel embedding algorithm,\ncharacter-based diffusion embedding algorithm (CDEA). Unlike existing embedding\nalgorithms that strive to eliminate the impact of sensitive information's\nproperties on the generation process, CDEA leverages sensitive information's\nproperties. It enhances the selection frequency of high-probability candidate\nwords in the candidate pool based on general statistical properties at the\ncharacter level and grouping methods based on power-law distributions, while\nreducing the selection frequency of low-probability candidate words in the\ncandidate pool. Furthermore, to ensure the effective transformation of\nsensitive information in long sequences, we also introduce the XLNet model.\nExperimental results demonstrate that the combination of CDEA and XLNet\nsignificantly improves the quality of generated steganographic text,\nparticularly in terms of perceptual-imperceptibility.", "AI": {"tldr": "The paper proposes a character-based diffusion embedding algorithm (CDEA) and XLNet to improve steganographic text quality by leveraging sensitive information properties and enhancing high-probability word selection.", "motivation": "Existing models and embedding algorithms struggle with generating high-quality steganographic text due to limitations in text generation and ineffective mitigation of sensitive information's negative impacts.", "method": "Introduces CDEA, which leverages sensitive information properties and character-level statistics to enhance high-probability word selection, combined with XLNet for long-sequence transformation.", "result": "The combination of CDEA and XLNet significantly improves steganographic text quality, especially perceptual-imperceptibility.", "conclusion": "CDEA and XLNet effectively address the challenges in steganographic text generation, enhancing quality and coherence."}}
{"id": "2505.03899", "pdf": "https://arxiv.org/pdf/2505.03899", "abs": "https://arxiv.org/abs/2505.03899", "authors": ["Danial Davarnia", "Mohammadreza Kiaghadi"], "title": "A Graphical Global Optimization Framework for Parameter Estimation of Statistical Models with Nonconvex Regularization Functions", "categories": ["math.OC", "cs.AI", "math.ST", "stat.TH"], "comment": null, "summary": "Optimization problems with norm-bounding constraints arise in a variety of\napplications, including portfolio optimization, machine learning, and feature\nselection. A common approach to these problems involves relaxing the norm\nconstraint via Lagrangian relaxation, transforming it into a regularization\nterm in the objective function. A particularly challenging class includes the\nzero-norm function, which promotes sparsity in statistical parameter\nestimation. Most existing exact methods for solving these problems introduce\nbinary variables and artificial bounds to reformulate them as\nhigher-dimensional mixed-integer programs, solvable by standard solvers. Other\nexact approaches exploit specific structural properties of the objective,\nmaking them difficult to generalize across different problem types. Alternative\nmethods employ nonconvex penalties with favorable statistical characteristics,\nbut these are typically addressed using heuristic or local optimization\ntechniques due to their structural complexity. In this paper, we propose a\nnovel graph-based method to globally solve optimization problems involving\ngeneralized norm-bounding constraints. Our approach encompasses standard\n$\\ell_p$-norms for $p \\in [0, \\infty)$ and nonconvex penalties such as SCAD and\nMCP. We leverage decision diagrams to construct strong convex relaxations\ndirectly in the original variable space, eliminating the need for auxiliary\nvariables or artificial bounds. Integrated into a spatial branch-and-cut\nframework, our method guarantees convergence to the global optimum. We\ndemonstrate its effectiveness through preliminary computational experiments on\nbenchmark sparse linear regression problems involving complex nonconvex\npenalties, which are not tractable using existing global optimization\ntechniques.", "AI": {"tldr": "A novel graph-based method is proposed to globally solve optimization problems with norm-bounding constraints, including nonconvex penalties, using decision diagrams and spatial branch-and-cut for guaranteed convergence.", "motivation": "Existing methods for norm-bounded optimization problems often rely on binary variables, artificial bounds, or problem-specific structures, limiting their generality and tractability for complex nonconvex penalties.", "method": "The approach uses decision diagrams to construct convex relaxations directly in the original variable space, integrated into a spatial branch-and-cut framework for global optimization.", "result": "Preliminary experiments show effectiveness on benchmark sparse linear regression problems with nonconvex penalties, outperforming existing global optimization techniques.", "conclusion": "The proposed method provides a general and efficient solution for norm-bounded optimization problems, including challenging nonconvex cases, with guaranteed global optimality."}}
{"id": "2505.03983", "pdf": "https://arxiv.org/pdf/2505.03983", "abs": "https://arxiv.org/abs/2505.03983", "authors": ["Hengyuan Hu", "Aniket Das", "Dorsa Sadigh", "Nima Anari"], "title": "Diffusion Models are Secretly Exchangeable: Parallelizing DDPMs via Autospeculation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Denoising Diffusion Probabilistic Models (DDPMs) have emerged as powerful\ntools for generative modeling. However, their sequential computation\nrequirements lead to significant inference-time bottlenecks. In this work, we\nutilize the connection between DDPMs and Stochastic Localization to prove that,\nunder an appropriate reparametrization, the increments of DDPM satisfy an\nexchangeability property. This general insight enables near-black-box\nadaptation of various performance optimization techniques from autoregressive\nmodels to the diffusion setting. To demonstrate this, we introduce\n\\emph{Autospeculative Decoding} (ASD), an extension of the widely used\nspeculative decoding algorithm to DDPMs that does not require any auxiliary\ndraft models. Our theoretical analysis shows that ASD achieves a $\\tilde{O}\n(K^{\\frac{1}{3}})$ parallel runtime speedup over the $K$ step sequential DDPM.\nWe also demonstrate that a practical implementation of autospeculative decoding\naccelerates DDPM inference significantly in various domains.", "AI": {"tldr": "DDPMs face slow inference due to sequential computation. This work leverages Stochastic Localization to enable optimization techniques like Autospeculative Decoding (ASD), achieving faster parallel runtime.", "motivation": "Address the inference-time bottlenecks in DDPMs by exploiting their connection to Stochastic Localization.", "method": "Reparametrize DDPM increments to satisfy exchangeability, then adapt Autospeculative Decoding (ASD) from autoregressive models.", "result": "ASD achieves a theoretical $\tilde{O}(K^{\frac{1}{3}})$ speedup and practical inference acceleration in DDPMs.", "conclusion": "The exchangeability insight and ASD provide efficient optimization for DDPMs, reducing inference bottlenecks."}}
{"id": "2505.04410", "pdf": "https://arxiv.org/pdf/2505.04410", "abs": "https://arxiv.org/abs/2505.04410", "authors": ["Junjie Wang", "Bin Chen", "Yulin Li", "Bin Kang", "Yichi Chen", "Zhuotao Tian"], "title": "DeCLIP: Decoupled Learning for Open-Vocabulary Dense Perception", "categories": ["cs.CV"], "comment": null, "summary": "Dense visual prediction tasks have been constrained by their reliance on\npredefined categories, limiting their applicability in real-world scenarios\nwhere visual concepts are unbounded. While Vision-Language Models (VLMs) like\nCLIP have shown promise in open-vocabulary tasks, their direct application to\ndense prediction often leads to suboptimal performance due to limitations in\nlocal feature representation. In this work, we present our observation that\nCLIP's image tokens struggle to effectively aggregate information from\nspatially or semantically related regions, resulting in features that lack\nlocal discriminability and spatial consistency. To address this issue, we\npropose DeCLIP, a novel framework that enhances CLIP by decoupling the\nself-attention module to obtain ``content'' and ``context'' features\nrespectively. The ``content'' features are aligned with image crop\nrepresentations to improve local discriminability, while ``context'' features\nlearn to retain the spatial correlations under the guidance of vision\nfoundation models, such as DINO. Extensive experiments demonstrate that DeCLIP\nsignificantly outperforms existing methods across multiple open-vocabulary\ndense prediction tasks, including object detection and semantic segmentation.\nCode is available at \\textcolor{magenta}{https://github.com/xiaomoguhz/DeCLIP}.", "AI": {"tldr": "DeCLIP improves CLIP for dense prediction by decoupling self-attention into 'content' and 'context' features, enhancing local discriminability and spatial consistency.", "motivation": "Address limitations of CLIP in dense prediction tasks due to poor local feature representation and spatial consistency.", "method": "Proposes DeCLIP, decoupling self-attention into 'content' (aligned with image crops) and 'context' (retaining spatial correlations) features.", "result": "DeCLIP outperforms existing methods in open-vocabulary dense prediction tasks like object detection and semantic segmentation.", "conclusion": "DeCLIP effectively enhances CLIP for dense prediction, achieving superior performance in real-world scenarios."}}
{"id": "2505.02366", "pdf": "https://arxiv.org/pdf/2505.02366", "abs": "https://arxiv.org/abs/2505.02366", "authors": ["Tianyu Zong", "Hongzhu Yi", "Bingkang Shi", "Yuanxiang Wang", "Jungang Xu"], "title": "JTCSE: Joint Tensor-Modulus Constraints and Cross-Attention for Unsupervised Contrastive Learning of Sentence Embeddings", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Unsupervised contrastive learning has become a hot research topic in natural\nlanguage processing. Existing works usually aim at constraining the orientation\ndistribution of the representations of positive and negative samples in the\nhigh-dimensional semantic space in contrastive learning, but the semantic\nrepresentation tensor possesses both modulus and orientation features, and the\nexisting works ignore the modulus feature of the representations and cause\ninsufficient contrastive learning. % Therefore, we firstly propose a training\nobjective that aims at modulus constraints on the semantic representation\ntensor, to strengthen the alignment between the positive samples in contrastive\nlearning. Therefore, we first propose a training objective that is designed to\nimpose modulus constraints on the semantic representation tensor, to strengthen\nthe alignment between positive samples in contrastive learning. Then, the\nBERT-like model suffers from the phenomenon of sinking attention, leading to a\nlack of attention to CLS tokens that aggregate semantic information. In\nresponse, we propose a cross-attention structure among the twin-tower ensemble\nmodels to enhance the model's attention to CLS token and optimize the quality\nof CLS Pooling. Combining the above two motivations, we propose a new\n\\textbf{J}oint \\textbf{T}ensor representation modulus constraint and\n\\textbf{C}ross-attention unsupervised contrastive learning \\textbf{S}entence\n\\textbf{E}mbedding representation framework JTCSE, which we evaluate in seven\nsemantic text similarity computation tasks, and the experimental results show\nthat JTCSE's twin-tower ensemble model and single-tower distillation model\noutperform the other baselines and become the current SOTA. In addition, we\nhave conducted an extensive zero-shot downstream task evaluation, which shows\nthat JTCSE outperforms other baselines overall on more than 130 tasks.", "AI": {"tldr": "The paper introduces JTCSE, a framework combining modulus constraints on semantic representations and cross-attention to improve unsupervised contrastive learning for sentence embeddings, achieving SOTA results.", "motivation": "Existing contrastive learning methods ignore modulus features of semantic representations and suffer from sinking attention in BERT-like models, limiting performance.", "method": "Proposes modulus constraints on semantic tensors and a cross-attention structure to enhance CLS token attention, forming the JTCSE framework.", "result": "JTCSE outperforms baselines in seven semantic text similarity tasks and 130+ zero-shot downstream tasks.", "conclusion": "JTCSE effectively addresses modulus and attention issues, achieving superior performance in unsupervised contrastive learning."}}
{"id": "2505.03945", "pdf": "https://arxiv.org/pdf/2505.03945", "abs": "https://arxiv.org/abs/2505.03945", "authors": ["Shamnad Mohamed Shaffi", "Sunish Vengathattil", "Jezeena Nikarthil Sidhick", "Resmi Vijayan"], "title": "AI-Driven Security in Cloud Computing: Enhancing Threat Detection, Automated Response, and Cyber Resilience", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Cloud security concerns have been greatly realized in recent years due to the\nincrease of complicated threats in the computing world. Many traditional\nsolutions do not work well in real-time to detect or prevent more complex\nthreats. Artificial intelligence is today regarded as a revolution in\ndetermining a protection plan for cloud data architecture through machine\nlearning, statistical visualization of computing infrastructure, and detection\nof security breaches followed by counteraction. These AI-enabled systems make\nwork easier as more network activities are scrutinized, and any anomalous\nbehavior that might be a precursor to a more serious breach is prevented. This\npaper examines ways AI can enhance cloud security by applying predictive\nanalytics, behavior-based security threat detection, and AI-stirring\nencryption. It also outlines the problems of the previous security models and\nhow AI overcomes them. For a similar reason, issues like data privacy, biases\nin the AI model, and regulatory compliance are also covered. So, AI improves\nthe protection of cloud computing contexts; however, more efforts are needed in\nthe subsequent phases to extend the technology's reliability, modularity, and\nethical aspects. This means that AI can be blended with other new computing\ntechnologies, including blockchain, to improve security frameworks further. The\npaper discusses the current trends in securing cloud data architecture using AI\nand presents further research and application directions.", "AI": {"tldr": "AI enhances cloud security through predictive analytics, behavior-based threat detection, and encryption, overcoming traditional model limitations while addressing privacy, bias, and compliance issues.", "motivation": "The rise of complex threats in cloud computing necessitates advanced solutions, as traditional methods fail in real-time detection and prevention.", "method": "AI leverages machine learning, statistical visualization, and breach detection to analyze network activities and prevent anomalies.", "result": "AI improves cloud security but requires further work on reliability, modularity, and ethical integration with technologies like blockchain.", "conclusion": "AI is transformative for cloud security, but ongoing research is needed to address its challenges and expand its applications."}}
{"id": "2505.03992", "pdf": "https://arxiv.org/pdf/2505.03992", "abs": "https://arxiv.org/abs/2505.03992", "authors": ["Jarren Briscoe", "Garrett Kepler", "Daryl Deford", "Assefaw Gebremedhin"], "title": "Algorithmic Accountability in Small Data: Sample-Size-Induced Bias Within Classification Metrics", "categories": ["cs.LG"], "comment": "AISTATS 2025", "summary": "Evaluating machine learning models is crucial not only for determining their\ntechnical accuracy but also for assessing their potential societal\nimplications. While the potential for low-sample-size bias in algorithms is\nwell known, we demonstrate the significance of sample-size bias induced by\ncombinatorics in classification metrics. This revelation challenges the\nefficacy of these metrics in assessing bias with high resolution, especially\nwhen comparing groups of disparate sizes, which frequently arise in social\napplications. We provide analyses of the bias that appears in several commonly\napplied metrics and propose a model-agnostic assessment and correction\ntechnique. Additionally, we analyze counts of undefined cases in metric\ncalculations, which can lead to misleading evaluations if improperly handled.\nThis work illuminates the previously unrecognized challenge of combinatorics\nand probability in standard evaluation practices and thereby advances\napproaches for performing fair and trustworthy classification methods.", "AI": {"tldr": "The paper highlights the impact of combinatorics-induced sample-size bias in classification metrics, proposing a model-agnostic correction technique to improve fairness in evaluations.", "motivation": "To address the overlooked issue of sample-size bias in classification metrics, especially in social applications with disparate group sizes, ensuring fair and trustworthy model assessments.", "method": "Analyzes bias in common classification metrics, identifies undefined cases, and proposes a model-agnostic technique for assessment and correction.", "result": "Reveals significant bias due to combinatorics in metrics, challenges their efficacy in high-resolution bias assessment, and provides corrective measures.", "conclusion": "The study advances fair classification methods by addressing combinatorics-induced bias and improving evaluation practices."}}
{"id": "2505.04424", "pdf": "https://arxiv.org/pdf/2505.04424", "abs": "https://arxiv.org/abs/2505.04424", "authors": ["Jing Hu", "Chengming Feng", "Shu Hu", "Ming-Ching Chang", "Xin Li", "Xi Wu", "Xin Wang"], "title": "RLMiniStyler: Light-weight RL Style Agent for Arbitrary Sequential Neural Style Generation", "categories": ["cs.CV"], "comment": "IJCAI2025", "summary": "Arbitrary style transfer aims to apply the style of any given artistic image\nto another content image. Still, existing deep learning-based methods often\nrequire significant computational costs to generate diverse stylized results.\nMotivated by this, we propose a novel reinforcement learning-based framework\nfor arbitrary style transfer RLMiniStyler. This framework leverages a unified\nreinforcement learning policy to iteratively guide the style transfer process\nby exploring and exploiting stylization feedback, generating smooth sequences\nof stylized results while achieving model lightweight. Furthermore, we\nintroduce an uncertainty-aware multi-task learning strategy that automatically\nadjusts loss weights to adapt to the content and style balance requirements at\ndifferent training stages, thereby accelerating model convergence. Through a\nseries of experiments across image various resolutions, we have validated the\nadvantages of RLMiniStyler over other state-of-the-art methods in generating\nhigh-quality, diverse artistic image sequences at a lower cost. Codes are\navailable at https://github.com/fengxiaoming520/RLMiniStyler.", "AI": {"tldr": "A reinforcement learning-based framework, RLMiniStyler, is proposed for efficient and lightweight arbitrary style transfer, leveraging iterative feedback and multi-task learning for high-quality results.", "motivation": "Existing deep learning methods for style transfer are computationally expensive, prompting the need for a more efficient solution.", "method": "Uses reinforcement learning to iteratively guide style transfer and an uncertainty-aware multi-task learning strategy to balance content and style.", "result": "Validated as superior to state-of-the-art methods, generating high-quality stylized images at lower computational cost.", "conclusion": "RLMiniStyler offers an efficient, lightweight solution for diverse style transfer with faster convergence and better performance."}}
{"id": "2311.18681", "pdf": "https://arxiv.org/pdf/2311.18681", "abs": "https://arxiv.org/abs/2311.18681", "authors": ["Chantal Pellegrini", "Ege \u00d6zsoy", "Benjamin Busam", "Nassir Navab", "Matthias Keicher"], "title": "RaDialog: A Large Vision-Language Model for Radiology Report Generation and Conversational Assistance", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted for publication at MIDL 2025", "summary": "Conversational AI tools that can generate and discuss clinically correct\nradiology reports for a given medical image have the potential to transform\nradiology. Such a human-in-the-loop radiology assistant could facilitate a\ncollaborative diagnostic process, thus saving time and improving the quality of\nreports. Towards this goal, we introduce RaDialog, the first thoroughly\nevaluated and publicly available large vision-language model for radiology\nreport generation and interactive dialog. RaDialog effectively integrates\nvisual image features and structured pathology findings with a large language\nmodel (LLM) while simultaneously adapting it to a specialized domain using\nparameter-efficient fine-tuning. To keep the conversational abilities of the\nunderlying LLM, we propose a comprehensive, semi-automatically labeled,\nimage-grounded instruct dataset for chest X-ray radiology tasks. By training\nwith this dataset, our method achieves state-of-the-art clinical correctness in\nreport generation and shows impressive abilities in interactive tasks such as\ncorrecting reports and answering questions, serving as a foundational step\ntoward clinical dialog systems. Our code is available on github:\nhttps://github.com/ChantalMP/RaDialog.", "AI": {"tldr": "RaDialog is a conversational AI for radiology report generation and interactive dialog, integrating visual and pathology data with an LLM, achieving state-of-the-art clinical correctness.", "motivation": "To transform radiology by facilitating collaborative diagnostics, saving time, and improving report quality.", "method": "Integrates visual features and pathology findings with an LLM, using parameter-efficient fine-tuning and a semi-automatically labeled dataset for chest X-ray tasks.", "result": "Achieves state-of-the-art clinical correctness in report generation and excels in interactive tasks like report correction and Q&A.", "conclusion": "RaDialog serves as a foundational step toward clinical dialog systems, with code publicly available."}}
{"id": "2505.03946", "pdf": "https://arxiv.org/pdf/2505.03946", "abs": "https://arxiv.org/abs/2505.03946", "authors": ["Matthew Sgambati", "Aleksandar Vakanski", "Matthew Anderson"], "title": "Decentralized Distributed Proximal Policy Optimization (DD-PPO) for High Performance Computing Scheduling on Multi-User Systems", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Resource allocation in High Performance Computing (HPC) environments presents\na complex and multifaceted challenge for job scheduling algorithms. Beyond the\nefficient allocation of system resources, schedulers must account for and\noptimize multiple performance metrics, including job wait time and system\nutilization. While traditional rule-based scheduling algorithms dominate the\ncurrent deployments of HPC systems, the increasing heterogeneity and scale of\nthose systems is expected to challenge the efficiency and flexibility of those\nalgorithms in minimizing job wait time and maximizing utilization. Recent\nresearch efforts have focused on leveraging advancements in Reinforcement\nLearning (RL) to develop more adaptable and intelligent scheduling strategies.\nRecent RL-based scheduling approaches have explored a range of algorithms, from\nDeep Q-Networks (DQN) to Proximal Policy Optimization (PPO), and more recently,\nhybrid methods that integrate Graph Neural Networks with RL techniques.\nHowever, a common limitation across these methods is their reliance on\nrelatively small datasets, and these methods face scalability issues when using\nlarge datasets. This study introduces a novel RL-based scheduler utilizing the\nDecentralized Distributed Proximal Policy Optimization (DD-PPO) algorithm,\nwhich supports large-scale distributed training across multiple workers without\nrequiring parameter synchronization at every step. By eliminating reliance on\ncentralized updates to a shared policy, the DD-PPO scheduler enhances\nscalability, training efficiency, and sample utilization. The validation\ndataset leveraged over 11.5 million real HPC job traces for comparing DD-PPO\nperformance between traditional and advanced scheduling approaches, and the\nexperimental results demonstrate improved scheduling performance in comparison\nto both rule-based schedulers and existing RL-based scheduling algorithms.", "AI": {"tldr": "A novel RL-based scheduler using DD-PPO improves scalability and performance in HPC job scheduling, outperforming traditional and existing RL methods.", "motivation": "Traditional rule-based scheduling struggles with HPC system heterogeneity and scale, prompting the need for adaptable RL-based solutions.", "method": "The study introduces a DD-PPO algorithm for distributed training, eliminating centralized policy updates to enhance scalability.", "result": "Experiments with 11.5 million job traces show DD-PPO outperforms rule-based and existing RL schedulers.", "conclusion": "DD-PPO offers a scalable and efficient solution for HPC job scheduling, addressing limitations of prior RL methods."}}
{"id": "2505.04005", "pdf": "https://arxiv.org/pdf/2505.04005", "abs": "https://arxiv.org/abs/2505.04005", "authors": ["Devan Selvaraj"], "title": "Iterative Orthogonalization Scaling Laws", "categories": ["cs.LG", "68T07"], "comment": null, "summary": "The muon optimizer has picked up much attention as of late as a possible\nreplacement to the seemingly omnipresent Adam optimizer. Recently, care has\nbeen taken to document the scaling laws of hyper-parameters under muon such as\nweight decay and learning rate. However, at much larger scales the iterative\northogonalization procedure present in muon may suffer a possible issue as the\nsingular values of random matrices shrink with scale. This paper shows this\nscaling behavior theoretically and empirically on random matrices but does not\nsuggest what to do about it.", "AI": {"tldr": "The paper examines scaling issues in the muon optimizer's iterative orthogonalization at larger scales, showing theoretical and empirical evidence but no solutions.", "motivation": "To understand the scaling behavior of muon optimizer's hyper-parameters and identify potential issues at larger scales.", "method": "Theoretical analysis and empirical validation on random matrices.", "result": "Demonstrates that singular values of random matrices shrink with scale, impacting muon's orthogonalization.", "conclusion": "Highlights a scaling issue in muon but does not propose remedies."}}
{"id": "2505.04460", "pdf": "https://arxiv.org/pdf/2505.04460", "abs": "https://arxiv.org/abs/2505.04460", "authors": ["Ming-Hui Liu", "Harry Cheng", "Tianyi Wang", "Xin Luo", "Xin-Shun Xu"], "title": "Learning Real Facial Concepts for Independent Deepfake Detection", "categories": ["cs.CV"], "comment": "Accepted by IJCAI 2025", "summary": "Deepfake detection models often struggle with generalization to unseen\ndatasets, manifesting as misclassifying real instances as fake in target\ndomains. This is primarily due to an overreliance on forgery artifacts and a\nlimited understanding of real faces. To address this challenge, we propose a\nnovel approach RealID to enhance generalization by learning a comprehensive\nconcept of real faces while assessing the probabilities of belonging to the\nreal and fake classes independently. RealID comprises two key modules: the Real\nConcept Capture Module (RealC2) and the Independent Dual-Decision Classifier\n(IDC). With the assistance of a MultiReal Memory, RealC2 maintains various\nprototypes for real faces, allowing the model to capture a comprehensive\nconcept of real class. Meanwhile, IDC redefines the classification strategy by\nmaking independent decisions based on the concept of the real class and the\npresence of forgery artifacts. Through the combined effect of the above\nmodules, the influence of forgery-irrelevant patterns is alleviated, and\nextensive experiments on five widely used datasets demonstrate that RealID\nsignificantly outperforms existing state-of-the-art methods, achieving a 1.74%\nimprovement in average accuracy.", "AI": {"tldr": "RealID improves deepfake detection by learning real face concepts and independent classification, outperforming state-of-the-art methods by 1.74% in accuracy.", "motivation": "Deepfake detection models generalize poorly due to reliance on forgery artifacts and limited real face understanding.", "method": "RealID uses Real Concept Capture Module (RealC2) and Independent Dual-Decision Classifier (IDC) to learn real face concepts and classify independently.", "result": "Achieves 1.74% higher average accuracy on five datasets compared to existing methods.", "conclusion": "RealID enhances generalization by reducing reliance on forgery-irrelevant patterns and improving real face understanding."}}
{"id": "2410.02131", "pdf": "https://arxiv.org/pdf/2410.02131", "abs": "https://arxiv.org/abs/2410.02131", "authors": ["Hung Manh Pham", "Aaqib Saeed", "Dong Ma"], "title": "Boosting Masked ECG-Text Auto-Encoders as Discriminative Learners", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted at ICML 2025", "summary": "The accurate interpretation of Electrocardiogram (ECG) signals is pivotal for\ndiagnosing cardiovascular diseases. Integrating ECG signals with accompanying\ntextual reports further holds immense potential to enhance clinical diagnostics\nby combining physiological data and qualitative insights. However, this\nintegration faces significant challenges due to inherent modality disparities\nand the scarcity of labeled data for robust cross-modal learning. To address\nthese obstacles, we propose D-BETA, a novel framework that pre-trains ECG and\ntext data using a contrastive masked auto-encoder architecture. D-BETA uniquely\ncombines the strengths of generative with boosted discriminative capabilities\nto achieve robust cross-modal representations. This is accomplished through\nmasked modality modeling, specialized loss functions, and an improved negative\nsampling strategy tailored for cross-modal alignment. Extensive experiments on\nfive public datasets across diverse downstream tasks demonstrate that D-BETA\nsignificantly outperforms existing methods, achieving an average AUC\nimprovement of 15% in linear probing with only one percent of training data and\n2% in zero-shot performance without requiring training data over\nstate-of-the-art models. These results highlight the effectiveness of D-BETA,\nunderscoring its potential to advance automated clinical diagnostics through\nmulti-modal representations. Our sample code and checkpoint are made available\nat https://github.com/manhph2211/D-BETA.", "AI": {"tldr": "D-BETA is a novel framework for integrating ECG signals and textual reports using contrastive masked auto-encoder architecture, outperforming existing methods by 15% AUC in linear probing and 2% in zero-shot performance.", "motivation": "Accurate ECG interpretation combined with textual reports can enhance clinical diagnostics, but modality disparities and data scarcity hinder robust cross-modal learning.", "method": "D-BETA pre-trains ECG and text data with masked modality modeling, specialized loss functions, and improved negative sampling for cross-modal alignment.", "result": "D-BETA achieves significant improvements (15% AUC in linear probing, 2% in zero-shot) over state-of-the-art models on five public datasets.", "conclusion": "D-BETA effectively advances automated clinical diagnostics through robust multi-modal representations, with code and checkpoints publicly available."}}
{"id": "2505.03988", "pdf": "https://arxiv.org/pdf/2505.03988", "abs": "https://arxiv.org/abs/2505.03988", "authors": ["Gregory Bolet", "Giorgis Georgakoudis", "Harshitha Menon", "Konstantinos Parasyris", "Niranjan Hasabnis", "Hayden Estes", "Kirk W. Cameron", "Gal Oren"], "title": "Can Large Language Models Predict Parallel Code Performance?", "categories": ["cs.DC", "cs.AI", "cs.PF"], "comment": "5 pages, 4 figures, accepted to AI4Sys Workshop at HPDC 2025", "summary": "Accurate determination of the performance of parallel GPU code typically\nrequires execution-time profiling on target hardware -- an increasingly\nprohibitive step due to limited access to high-end GPUs. This paper explores\nwhether Large Language Models (LLMs) can offer an alternative approach for GPU\nperformance prediction without relying on hardware. We frame the problem as a\nroofline classification task: given the source code of a GPU kernel and the\nhardware specifications of a target GPU, can an LLM predict whether the GPU\nkernel is compute-bound or bandwidth-bound?\n  For this study, we build a balanced dataset of 340 GPU kernels, obtained from\nHeCBench benchmark and written in CUDA and OpenMP, along with their\nground-truth labels obtained via empirical GPU profiling. We evaluate LLMs\nacross four scenarios: (1) with access to profiling data of the kernel source,\n(2) zero-shot with source code only, (3) few-shot with code and label pairs,\nand (4) fine-tuned on a small custom dataset.\n  Our results show that state-of-the-art LLMs have a strong understanding of\nthe Roofline model, achieving 100% classification accuracy when provided with\nexplicit profiling data. We also find that reasoning-capable LLMs significantly\noutperform standard LLMs in zero- and few-shot settings, achieving up to 64%\naccuracy on GPU source codes, without profiling information. Lastly, we find\nthat LLM fine-tuning will require much more data than what we currently have\navailable.\n  This work is among the first to use LLMs for source-level roofline\nperformance prediction via classification, and illustrates their potential to\nguide optimization efforts when runtime profiling is infeasible. Our findings\nsuggest that with better datasets and prompt strategies, LLMs could become\npractical tools for HPC performance analysis and performance portability.", "AI": {"tldr": "LLMs can predict GPU kernel performance (compute-bound or bandwidth-bound) without hardware profiling, achieving high accuracy with profiling data and moderate accuracy in zero-/few-shot settings.", "motivation": "Limited access to high-end GPUs makes hardware profiling impractical, prompting exploration of LLMs for GPU performance prediction.", "method": "Evaluated LLMs on a dataset of 340 GPU kernels using four scenarios: profiling data, zero-shot, few-shot, and fine-tuning.", "result": "LLMs achieved 100% accuracy with profiling data and up to 64% in zero-/few-shot settings. Fine-tuning requires more data.", "conclusion": "LLMs show promise for HPC performance analysis, with potential for practical use given better datasets and prompts."}}
{"id": "2505.04046", "pdf": "https://arxiv.org/pdf/2505.04046", "abs": "https://arxiv.org/abs/2505.04046", "authors": ["Xuyang Wang", "Siyuan Duan", "Qizhi Li", "Guiduo Duan", "Yuan Sun", "Dezhong Peng"], "title": "Reliable Disentanglement Multi-view Learning Against View Adversarial Attacks", "categories": ["cs.LG", "cs.CR"], "comment": "11 pages, 11 figures, accepted by International Joint Conference on\n  Artificial Intelligence (IJCAI 2025)", "summary": "Recently, trustworthy multi-view learning has attracted extensive attention\nbecause evidence learning can provide reliable uncertainty estimation to\nenhance the credibility of multi-view predictions. Existing trusted multi-view\nlearning methods implicitly assume that multi-view data is secure. In practice,\nhowever, in safety-sensitive applications such as autonomous driving and\nsecurity monitoring, multi-view data often faces threats from adversarial\nperturbations, thereby deceiving or disrupting multi-view learning models. This\ninevitably leads to the adversarial unreliability problem (AUP) in trusted\nmulti-view learning. To overcome this tricky problem, we propose a novel\nmulti-view learning framework, namely Reliable Disentanglement Multi-view\nLearning (RDML). Specifically, we first propose evidential disentanglement\nlearning to decompose each view into clean and adversarial parts under the\nguidance of corresponding evidences, which is extracted by a pretrained\nevidence extractor. Then, we employ the feature recalibration module to\nmitigate the negative impact of adversarial perturbations and extract potential\ninformative features from them. Finally, to further ignore the irreparable\nadversarial interferences, a view-level evidential attention mechanism is\ndesigned. Extensive experiments on multi-view classification tasks with\nadversarial attacks show that our RDML outperforms the state-of-the-art\nmulti-view learning methods by a relatively large margin.", "AI": {"tldr": "RDML addresses adversarial unreliability in trusted multi-view learning by disentangling clean and adversarial parts of data, recalibrating features, and using evidential attention.", "motivation": "Existing trusted multi-view learning methods assume secure data, but adversarial perturbations in safety-sensitive applications (e.g., autonomous driving) undermine reliability.", "method": "Proposes RDML: evidential disentanglement learning, feature recalibration, and view-level evidential attention to mitigate adversarial impacts.", "result": "RDML outperforms state-of-the-art methods in multi-view classification under adversarial attacks.", "conclusion": "RDML effectively enhances the reliability of multi-view learning in adversarial settings."}}
{"id": "2505.04481", "pdf": "https://arxiv.org/pdf/2505.04481", "abs": "https://arxiv.org/abs/2505.04481", "authors": ["Jiahao Li", "Weijian Ma", "Xueyang Li", "Yunzhong Lou", "Guichun Zhou", "Xiangdong Zhou"], "title": "CAD-Llama: Leveraging Large Language Models for Computer-Aided Design Parametric 3D Model Generation", "categories": ["cs.CV"], "comment": null, "summary": "Recently, Large Language Models (LLMs) have achieved significant success,\nprompting increased interest in expanding their generative capabilities beyond\ngeneral text into domain-specific areas. This study investigates the generation\nof parametric sequences for computer-aided design (CAD) models using LLMs. This\nendeavor represents an initial step towards creating parametric 3D shapes with\nLLMs, as CAD model parameters directly correlate with shapes in\nthree-dimensional space. Despite the formidable generative capacities of LLMs,\nthis task remains challenging, as these models neither encounter parametric\nsequences during their pretraining phase nor possess direct awareness of 3D\nstructures. To address this, we present CAD-Llama, a framework designed to\nenhance pretrained LLMs for generating parametric 3D CAD models. Specifically,\nwe develop a hierarchical annotation pipeline and a code-like format to\ntranslate parametric 3D CAD command sequences into Structured Parametric CAD\nCode (SPCC), incorporating hierarchical semantic descriptions. Furthermore, we\npropose an adaptive pretraining approach utilizing SPCC, followed by an\ninstruction tuning process aligned with CAD-specific guidelines. This\nmethodology aims to equip LLMs with the spatial knowledge inherent in\nparametric sequences. Experimental results demonstrate that our framework\nsignificantly outperforms prior autoregressive methods and existing LLM\nbaselines.", "AI": {"tldr": "The paper introduces CAD-Llama, a framework to enhance LLMs for generating parametric 3D CAD models by translating sequences into structured code and using adaptive pretraining.", "motivation": "To expand LLMs' capabilities into domain-specific tasks like parametric CAD model generation, addressing their lack of exposure to parametric sequences and 3D awareness.", "method": "Develops a hierarchical annotation pipeline and structured code format (SPCC), followed by adaptive pretraining and instruction tuning for CAD-specific tasks.", "result": "CAD-Llama outperforms prior autoregressive methods and LLM baselines in generating parametric 3D CAD models.", "conclusion": "The framework successfully equips LLMs with spatial knowledge for CAD tasks, demonstrating significant improvement over existing methods."}}
{"id": "2410.22330", "pdf": "https://arxiv.org/pdf/2410.22330", "abs": "https://arxiv.org/abs/2410.22330", "authors": ["Grace Luo", "Trevor Darrell", "Amir Bar"], "title": "Vision-Language Models Create Cross-Modal Task Representations", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "ICML 2025", "summary": "Autoregressive vision-language models (VLMs) can handle many tasks within a\nsingle model, yet the representations that enable this capability remain\nopaque. We find that VLMs align conceptually equivalent inputs into a shared\ntask vector, which is invariant to modality (text, image) and format (examples,\ninstruction), and may simplify VLM processing. We measure this alignment via\ncross-modal transfer -- the ability of a task vector derived in one modality to\ntrigger the correct generation in another -- on a range of tasks and model\narchitectures. Although the task vector is highly compressed, we find that this\nsingle vector outperforms prompting the model with the full task information,\nunique to this cross-modal case. Furthermore, we show that task vectors can be\ntransferred from a base language model to its fine-tuned vision-language\ncounterpart, and that they can be derived solely from instructions without the\nneed for examples. Taken together, our findings shed light on how VLMs\ninternally process task information, and how they map different modalities into\ncommon semantic representations. Project page:\nhttps://vlm-cross-modal-reps.github.io.", "AI": {"tldr": "VLMs align inputs into shared task vectors, enabling cross-modal transfer and outperforming full-task prompting.", "motivation": "To understand how VLMs process task information and align inputs across modalities.", "method": "Measure cross-modal transfer of task vectors across tasks and architectures.", "result": "Task vectors outperform full-task prompting and can transfer between base and fine-tuned models.", "conclusion": "VLMs map modalities into common semantic representations via task vectors, simplifying processing."}}
{"id": "2505.04002", "pdf": "https://arxiv.org/pdf/2505.04002", "abs": "https://arxiv.org/abs/2505.04002", "authors": ["Michael Xu", "Yi Shi", "KangKang Yin", "Xue Bin Peng"], "title": "PARC: Physics-based Augmentation with Reinforcement Learning for Character Controllers", "categories": ["cs.GR", "cs.AI", "cs.LG", "cs.RO"], "comment": "SIGGRAPH Conference Papers 2025", "summary": "Humans excel in navigating diverse, complex environments with agile motor\nskills, exemplified by parkour practitioners performing dynamic maneuvers, such\nas climbing up walls and jumping across gaps. Reproducing these agile movements\nwith simulated characters remains challenging, in part due to the scarcity of\nmotion capture data for agile terrain traversal behaviors and the high cost of\nacquiring such data. In this work, we introduce PARC (Physics-based\nAugmentation with Reinforcement Learning for Character Controllers), a\nframework that leverages machine learning and physics-based simulation to\niteratively augment motion datasets and expand the capabilities of terrain\ntraversal controllers. PARC begins by training a motion generator on a small\ndataset consisting of core terrain traversal skills. The motion generator is\nthen used to produce synthetic data for traversing new terrains. However, these\ngenerated motions often exhibit artifacts, such as incorrect contacts or\ndiscontinuities. To correct these artifacts, we train a physics-based tracking\ncontroller to imitate the motions in simulation. The corrected motions are then\nadded to the dataset, which is used to continue training the motion generator\nin the next iteration. PARC's iterative process jointly expands the\ncapabilities of the motion generator and tracker, creating agile and versatile\nmodels for interacting with complex environments. PARC provides an effective\napproach to develop controllers for agile terrain traversal, which bridges the\ngap between the scarcity of motion data and the need for versatile character\ncontrollers.", "AI": {"tldr": "PARC is a framework combining machine learning and physics-based simulation to enhance terrain traversal controllers by iteratively augmenting motion datasets.", "motivation": "The challenge of reproducing agile human movements in simulations due to scarce and costly motion capture data for complex terrains.", "method": "PARC trains a motion generator on a small dataset, generates synthetic data, corrects artifacts with a physics-based tracker, and iteratively improves both components.", "result": "The framework produces agile and versatile models for complex terrain traversal, addressing data scarcity.", "conclusion": "PARC effectively bridges the gap between limited motion data and the need for versatile character controllers."}}
{"id": "2505.04075", "pdf": "https://arxiv.org/pdf/2505.04075", "abs": "https://arxiv.org/abs/2505.04075", "authors": ["Teddy Foley", "Spencer Guo", "Henry Josephson", "Anqi Qu", "Jack Sanderson"], "title": "LLM-e Guess: Can LLMs Capabilities Advance Without Hardware Progress?", "categories": ["cs.LG", "cs.AI", "I.2"], "comment": null, "summary": "This paper examines whether large language model (LLM) capabilities can\ncontinue to advance without additional compute by analyzing the development and\nrole of algorithms used in state-of-the-art LLMs. Motivated by regulatory\nefforts that have largely focused on restricting access to high-performance\nhardware, we ask: Can LLMs progress in a compute-constrained environment, and\nhow do algorithmic innovations perform under such conditions?\n  To address these questions, we introduce a novel classification framework\nthat distinguishes between compute-dependent innovations -- which yield\ndisproportionate benefits at high compute levels (e.g., the Transformer\narchitecture and mixture-of-experts models) and compute-independent\ninnovations, which improve efficiency across all compute scales (e.g., rotary\npositional encoding, FlashAttention, or layer normalization). We quantify these\ncontributions using a metric called compute-equivalent gain (CEG), which\nestimates the additional compute that would be required to achieve similar\nimprovements without these algorithmic advancements.\n  To validate this framework, we conduct small-scale training experiments with\na scaled-down GPT-2 model. Our results confirm that compute-independent\nadvancements yield meaningful performance gains even in resource-constrained\nsettings, with a CEG of up to $3.5\\times$ over a baseline model. By contrast,\ncompute-dependent advancements provided little benefit or even degraded\nperformance at the small scale, reinforcing the importance of compute\navailability for certain algorithmic gains.", "AI": {"tldr": "The paper explores whether LLMs can advance without more compute, distinguishing between compute-dependent and compute-independent innovations, and introduces a metric (CEG) to quantify their impact.", "motivation": "Motivated by regulatory efforts limiting high-performance hardware, the study investigates LLM progress in compute-constrained environments.", "method": "A classification framework for innovations (compute-dependent vs. independent) is introduced, validated via small-scale GPT-2 experiments using CEG.", "result": "Compute-independent innovations showed significant gains (CEG up to 3.5x), while compute-dependent ones were ineffective or harmful at small scales.", "conclusion": "Algorithmic advancements can drive LLM progress under compute constraints, but compute availability remains crucial for certain innovations."}}
{"id": "2505.04485", "pdf": "https://arxiv.org/pdf/2505.04485", "abs": "https://arxiv.org/abs/2505.04485", "authors": ["Ali Alawieh", "Alexandru P. Condurache"], "title": "FA-KPConv: Introducing Euclidean Symmetries to KPConv via Frame Averaging", "categories": ["cs.CV"], "comment": "8 pages, 2 figures, accepted at IJCNN 2025", "summary": "We present Frame-Averaging Kernel-Point Convolution (FA-KPConv), a neural\nnetwork architecture built on top of the well-known KPConv, a widely adopted\nbackbone for 3D point cloud analysis. Even though invariance and/or\nequivariance to Euclidean transformations are required for many common tasks,\nKPConv-based networks can only approximately achieve such properties when\ntraining on large datasets or with significant data augmentations. Using Frame\nAveraging, we allow to flexibly customize point cloud neural networks built\nwith KPConv layers, by making them exactly invariant and/or equivariant to\ntranslations, rotations and/or reflections of the input point clouds. By simply\nwrapping around an existing KPConv-based network, FA-KPConv embeds geometrical\nprior knowledge into it while preserving the number of learnable parameters and\nnot compromising any input information. We showcase the benefit of such an\nintroduced bias for point cloud classification and point cloud registration,\nespecially in challenging cases such as scarce training data or randomly\nrotated test data.", "AI": {"tldr": "FA-KPConv enhances KPConv by making it exactly invariant/equivariant to Euclidean transformations, improving performance in tasks like classification and registration, especially with limited data or random rotations.", "motivation": "KPConv lacks exact invariance/equivariance to Euclidean transformations, requiring large datasets or augmentations. FA-KPConv addresses this by embedding geometric priors.", "method": "FA-KPConv wraps KPConv layers with Frame Averaging, ensuring exact invariance/equivariance to translations, rotations, and reflections without adding parameters or losing input data.", "result": "FA-KPConv improves performance in point cloud classification and registration, particularly with scarce training data or randomly rotated test data.", "conclusion": "FA-KPConv effectively integrates geometric priors into KPConv, enhancing its robustness and accuracy in 3D point cloud tasks."}}
{"id": "2411.04997", "pdf": "https://arxiv.org/pdf/2411.04997", "abs": "https://arxiv.org/abs/2411.04997", "authors": ["Weiquan Huang", "Aoqi Wu", "Yifan Yang", "Xufang Luo", "Yuqing Yang", "Liang Hu", "Qi Dai", "Chunyu Wang", "Xiyang Dai", "Dongdong Chen", "Chong Luo", "Lili Qiu"], "title": "LLM2CLIP: Powerful Language Model Unlocks Richer Visual Representation", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "CLIP is a foundational multimodal model that aligns image and text features\ninto a shared representation space via contrastive learning on large-scale\nimage-text pairs. Its effectiveness primarily stems from the use of natural\nlanguage as rich supervision. Motivated by the remarkable advancements in large\nlanguage models (LLMs), this work explores how LLMs' superior text\nunderstanding and extensive open-world knowledge can enhance CLIP's capability,\nespecially for processing longer and more complex image captions. We propose an\nefficient post-training strategy that integrates LLMs into pretrained CLIP. To\naddress the challenge posed by the autoregressive nature of LLMs, we introduce\na caption-to-caption contrastive fine-tuning framework, significantly enhancing\nthe discriminative quality of LLM outputs. Extensive experiments demonstrate\nthat our approach outperforms LoRA-based methods, achieving nearly fourfold\nfaster training with superior performance. Furthermore, we validate substantial\nimprovements over state-of-the-art models such as CLIP, EVA02, and SigLip2\nacross various zero-shot multimodal retrieval tasks, cross-lingual retrieval\ntasks, and multimodal language model pretraining.", "AI": {"tldr": "The paper proposes integrating LLMs into CLIP to enhance its capability for processing complex captions, using a novel caption-to-caption contrastive fine-tuning framework. This method outperforms existing approaches in speed and performance.", "motivation": "Leverage LLMs' superior text understanding and open-world knowledge to improve CLIP's performance, especially for longer and more complex image captions.", "method": "An efficient post-training strategy integrating LLMs into CLIP, using a caption-to-caption contrastive fine-tuning framework to address LLMs' autoregressive nature.", "result": "Outperforms LoRA-based methods with nearly fourfold faster training and superior performance, surpassing models like CLIP, EVA02, and SigLip2 in various tasks.", "conclusion": "The proposed approach significantly enhances CLIP's capabilities, demonstrating broad improvements in multimodal and cross-lingual retrieval tasks."}}
{"id": "2505.04015", "pdf": "https://arxiv.org/pdf/2505.04015", "abs": "https://arxiv.org/abs/2505.04015", "authors": ["Soheil Zibakhsh Shabgahi", "Yaman Jandali", "Farinaz Koushanfar"], "title": "MergeGuard: Efficient Thwarting of Trojan Attacks in Machine Learning Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "This paper proposes MergeGuard, a novel methodology for mitigation of AI\nTrojan attacks. Trojan attacks on AI models cause inputs embedded with triggers\nto be misclassified to an adversary's target class, posing a significant threat\nto model usability trained by an untrusted third party. The core of MergeGuard\nis a new post-training methodology for linearizing and merging fully connected\nlayers which we show simultaneously improves model generalizability and\nperformance. Our Proof of Concept evaluation on Transformer models demonstrates\nthat MergeGuard maintains model accuracy while decreasing trojan attack success\nrate, outperforming commonly used (post-training) Trojan mitigation by\nfine-tuning methodologies.", "AI": {"tldr": "MergeGuard is a post-training method to mitigate AI Trojan attacks by linearizing and merging fully connected layers, improving model performance and reducing attack success rates.", "motivation": "Trojan attacks on AI models pose a threat by misclassifying triggered inputs, especially in models trained by untrusted parties.", "method": "MergeGuard linearizes and merges fully connected layers post-training to enhance generalizability and performance.", "result": "Evaluation on Transformer models shows MergeGuard maintains accuracy while reducing Trojan attack success rates, outperforming fine-tuning methods.", "conclusion": "MergeGuard effectively mitigates Trojan attacks without compromising model accuracy, offering a robust post-training solution."}}
{"id": "2505.04083", "pdf": "https://arxiv.org/pdf/2505.04083", "abs": "https://arxiv.org/abs/2505.04083", "authors": ["Aditya K. Ranjan", "Siddharth Singh", "Cunyang Wei", "Abhinav Bhatele"], "title": "Plexus: Taming Billion-edge Graphs with 3D Parallel GNN Training", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Graph neural networks have emerged as a potent class of neural networks\ncapable of leveraging the connectivity and structure of real-world graphs to\nlearn intricate properties and relationships between nodes. Many real-world\ngraphs exceed the memory capacity of a GPU due to their sheer size, and using\nGNNs on them requires techniques such as mini-batch sampling to scale. However,\nthis can lead to reduced accuracy in some cases, and sampling and data transfer\nfrom the CPU to the GPU can also slow down training. On the other hand,\ndistributed full-graph training suffers from high communication overhead and\nload imbalance due to the irregular structure of graphs. We propose Plexus, a\nthree-dimensional (3D) parallel approach for full-graph training that tackles\nthese issues and scales to billion-edge graphs. Additionally, we introduce\noptimizations such as a permutation scheme for load balancing, and a\nperformance model to predict the optimal 3D configuration. We evaluate Plexus\non several graph datasets and show scaling results for up to 2048 GPUs on\nPerlmutter, which is 33% of the machine, and 2048 GCDs on Frontier. Plexus\nachieves unprecedented speedups of 2.3x-12.5x over existing methods and a\nreduction in the time to solution by 5.2-8.7x on Perlmutter and 7-54.2x on\nFrontier.", "AI": {"tldr": "Plexus, a 3D parallel approach for full-graph training, scales to billion-edge graphs, outperforming existing methods with significant speedups and reduced time to solution.", "motivation": "Addressing the challenges of GPU memory limits and communication overhead in distributed full-graph training for GNNs.", "method": "Proposes Plexus, a 3D parallel approach with optimizations like load balancing and a performance model for optimal configuration.", "result": "Achieves speedups of 2.3x-12.5x and reduces time to solution by 5.2-8.7x on Perlmutter and 7-54.2x on Frontier.", "conclusion": "Plexus effectively scales GNN training to large graphs with superior performance and efficiency."}}
{"id": "2505.04486", "pdf": "https://arxiv.org/pdf/2505.04486", "abs": "https://arxiv.org/abs/2505.04486", "authors": ["Anirban Samaddar", "Yixuan Sun", "Viktor Nilsson", "Sandeep Madireddy"], "title": "Efficient Flow Matching using Latent Variables", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Flow matching models have shown great potential in image generation tasks\namong probabilistic generative models. Building upon the ideas of continuous\nnormalizing flows, flow matching models generalize the transport path of the\ndiffusion models from a simple prior distribution to the data. Most flow\nmatching models in the literature do not explicitly model the underlying\nstructure/manifold in the target data when learning the flow from a simple\nsource distribution like the standard Gaussian. This leads to inefficient\nlearning, especially for many high-dimensional real-world datasets, which often\nreside in a low-dimensional manifold. Existing strategies of incorporating\nmanifolds, including data with underlying multi-modal distribution, often\nrequire expensive training and hence frequently lead to suboptimal performance.\nTo this end, we present \\texttt{Latent-CFM}, which provides simplified\ntraining/inference strategies to incorporate multi-modal data structures using\npretrained deep latent variable models. Through experiments on multi-modal\nsynthetic data and widely used image benchmark datasets, we show that\n\\texttt{Latent-CFM} exhibits improved generation quality with significantly\nless training ($\\sim 50\\%$ less in some cases) and computation than\nstate-of-the-art flow matching models. Using a 2d Darcy flow dataset, we\ndemonstrate that our approach generates more physically accurate samples than\ncompetitive approaches. In addition, through latent space analysis, we\ndemonstrate that our approach can be used for conditional image generation\nconditioned on latent features.", "AI": {"tldr": "Latent-CFM improves flow matching models by incorporating multi-modal data structures using pretrained latent variable models, reducing training time and enhancing generation quality.", "motivation": "Existing flow matching models inefficiently learn high-dimensional data due to ignoring underlying structures, leading to suboptimal performance.", "method": "Latent-CFM simplifies training/inference by leveraging pretrained deep latent variable models to handle multi-modal data.", "result": "Latent-CFM achieves better generation quality with 50% less training, outperforms state-of-the-art models, and generates physically accurate samples.", "conclusion": "Latent-CFM offers a scalable and efficient solution for flow matching, enabling conditional image generation and improved performance."}}
{"id": "2411.05261", "pdf": "https://arxiv.org/pdf/2411.05261", "abs": "https://arxiv.org/abs/2411.05261", "authors": ["Yingying Fang", "Zihao Jin", "Shaojie Guo", "Jinda Liu", "Zhiling Yue", "Yijian Gao", "Junzhi Ning", "Zhi Li", "Simon Walsh", "Guang Yang"], "title": "Cyclic Vision-Language Manipulator: Towards Reliable and Fine-Grained Image Interpretation for Automated Report Generation", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Despite significant advancements in automated report generation, the\nopaqueness of text interpretability continues to cast doubt on the reliability\nof the content produced. This paper introduces a novel approach to identify\nspecific image features in X-ray images that influence the outputs of report\ngeneration models. Specifically, we propose Cyclic Vision-Language Manipulator\nCVLM, a module to generate a manipulated X-ray from an original X-ray and its\nreport from a designated report generator. The essence of CVLM is that cycling\nmanipulated X-rays to the report generator produces altered reports aligned\nwith the alterations pre-injected into the reports for X-ray generation,\nachieving the term \"cyclic manipulation\". This process allows direct comparison\nbetween original and manipulated X-rays, clarifying the critical image features\ndriving changes in reports and enabling model users to assess the reliability\nof the generated texts. Empirical evaluations demonstrate that CVLM can\nidentify more precise and reliable features compared to existing explanation\nmethods, significantly enhancing the transparency and applicability of\nAI-generated reports.", "AI": {"tldr": "The paper introduces CVLM, a cyclic vision-language manipulator, to identify key image features in X-rays that influence AI-generated reports, improving transparency and reliability.", "motivation": "Address the opaqueness and reliability concerns in AI-generated medical reports by clarifying which image features drive report changes.", "method": "Proposes CVLM to generate manipulated X-rays and reports, enabling cyclic comparison to pinpoint critical features.", "result": "CVLM identifies more precise and reliable features than existing methods, enhancing report transparency.", "conclusion": "CVLM improves the interpretability and trustworthiness of AI-generated medical reports."}}
{"id": "2505.04021", "pdf": "https://arxiv.org/pdf/2505.04021", "abs": "https://arxiv.org/abs/2505.04021", "authors": ["Shan Yu", "Jiarong Xing", "Yifan Qiao", "Mingyuan Ma", "Yangmin Li", "Yang Wang", "Shuo Yang", "Zhiqiang Xie", "Shiyi Cao", "Ke Bao", "Ion Stoica", "Harry Xu", "Ying Sheng"], "title": "Prism: Unleashing GPU Sharing for Cost-Efficient Multi-LLM Serving", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PF"], "comment": null, "summary": "Serving large language models (LLMs) is expensive, especially for providers\nhosting many models, making cost reduction essential. The unique workload\npatterns of serving multiple LLMs (i.e., multi-LLM serving) create new\nopportunities and challenges for this task. The long-tail popularity of models\nand their long idle periods present opportunities to improve utilization\nthrough GPU sharing. However, existing GPU sharing systems lack the ability to\nadjust their resource allocation and sharing policies at runtime, making them\nineffective at meeting latency service-level objectives (SLOs) under rapidly\nfluctuating workloads.\n  This paper presents Prism, a multi-LLM serving system that unleashes the full\npotential of GPU sharing to achieve both cost efficiency and SLO attainment. At\nits core, Prism tackles a key limitation of existing\nsystems$\\unicode{x2014}$the lack of $\\textit{cross-model memory coordination}$,\nwhich is essential for flexibly sharing GPU memory across models under dynamic\nworkloads. Prism achieves this with two key designs. First, it supports\non-demand memory allocation by dynamically mapping physical to virtual memory\npages, allowing flexible memory redistribution among models that space- and\ntime-share a GPU. Second, it improves memory efficiency through a two-level\nscheduling policy that dynamically adjusts sharing strategies based on models'\nruntime demands. Evaluations on real-world traces show that Prism achieves more\nthan $2\\times$ cost savings and $3.3\\times$ SLO attainment compared to\nstate-of-the-art systems.", "AI": {"tldr": "Prism is a multi-LLM serving system that improves GPU sharing for cost efficiency and SLO attainment by enabling cross-model memory coordination and dynamic resource allocation.", "motivation": "High costs of serving multiple LLMs and inefficiencies in existing GPU sharing systems due to static resource allocation and lack of cross-model memory coordination.", "method": "Prism introduces on-demand memory allocation via dynamic mapping of physical to virtual memory pages and a two-level scheduling policy for adaptive memory sharing.", "result": "Prism achieves over 2\u00d7 cost savings and 3.3\u00d7 SLO attainment compared to state-of-the-art systems.", "conclusion": "Prism effectively addresses GPU sharing limitations in multi-LLM serving, offering significant cost and performance improvements."}}
{"id": "2505.04104", "pdf": "https://arxiv.org/pdf/2505.04104", "abs": "https://arxiv.org/abs/2505.04104", "authors": ["Sarah Hartman", "Cheng Soon Ong", "Julia Powles", "Petra Kuhnert"], "title": "Position: We need responsible, application-driven (RAD) AI research", "categories": ["cs.LG", "cs.CY", "I.2.0; K.4.1; J.4"], "comment": "11 pages, 1 figure, Accepted to Proceedings of the 41 st\n  International Conference on Machine Learning, Vancouver, Canada. PMLR 267,\n  2025", "summary": "This position paper argues that achieving meaningful scientific and societal\nadvances with artificial intelligence (AI) requires a responsible,\napplication-driven approach (RAD) to AI research. As AI is increasingly\nintegrated into society, AI researchers must engage with the specific contexts\nwhere AI is being applied. This includes being responsive to ethical and legal\nconsiderations, technical and societal constraints, and public discourse. We\npresent the case for RAD-AI to drive research through a three-staged approach:\n(1) building transdisciplinary teams and people-centred studies; (2) addressing\ncontext-specific methods, ethical commitments, assumptions, and metrics; and\n(3) testing and sustaining efficacy through staged testbeds and a community of\npractice. We present a vision for the future of application-driven AI research\nto unlock new value through technically feasible methods that are adaptive to\nthe contextual needs and values of the communities they ultimately serve.", "AI": {"tldr": "The paper advocates for a responsible, application-driven approach (RAD-AI) to AI research, emphasizing context-specific, ethical, and adaptive methods for meaningful societal impact.", "motivation": "The motivation is to ensure AI research aligns with societal needs by addressing ethical, legal, and contextual challenges, fostering meaningful advances.", "method": "A three-staged approach: (1) transdisciplinary teams and people-centered studies, (2) context-specific methods and ethical commitments, and (3) staged testbeds and community practice.", "result": "Proposes RAD-AI as a framework to drive AI research that is adaptive, ethical, and contextually relevant.", "conclusion": "RAD-AI can unlock new value by aligning AI research with societal needs and values, ensuring technical feasibility and ethical integrity."}}
{"id": "2505.04497", "pdf": "https://arxiv.org/pdf/2505.04497", "abs": "https://arxiv.org/abs/2505.04497", "authors": ["Aditi Ramaswamy"], "title": "Defining and Quantifying Creative Behavior in Popular Image Generators", "categories": ["cs.CV", "cs.AI", "I.4.m; I.2.m"], "comment": null, "summary": "Creativity of generative AI models has been a subject of scientific debate in\nthe last years, without a conclusive answer. In this paper, we study creativity\nfrom a practical perspective and introduce quantitative measures that help the\nuser to choose a suitable AI model for a given task. We evaluated our measures\non a number of popular image-to-image generation models, and the results of\nthis suggest that our measures conform to human intuition.", "AI": {"tldr": "The paper introduces quantitative measures to evaluate the creativity of generative AI models, aiding users in selecting the right model for tasks, with results aligning with human intuition.", "motivation": "To address the ongoing debate about the creativity of generative AI models by providing practical, measurable criteria for evaluation.", "method": "Developed quantitative measures for creativity and tested them on popular image-to-image generation models.", "result": "The proposed measures align with human intuition, suggesting their practical utility.", "conclusion": "Quantitative measures can effectively evaluate AI creativity, helping users make informed model choices."}}
{"id": "2411.10246", "pdf": "https://arxiv.org/pdf/2411.10246", "abs": "https://arxiv.org/abs/2411.10246", "authors": ["Jiangang Hao", "Wenju Cui", "Patrick Kyllonen", "Emily Kerzabi", "Lei Liu", "Michael Flor"], "title": "Automated Coding of Communications in Collaborative Problem-solving Tasks Using ChatGPT", "categories": ["cs.HC", "cs.CL"], "comment": "21 pages, 3 figures, 5 tables. Initially report in the edArXiv:xw6kz", "summary": "Collaborative problem solving (CPS) is widely recognized as a critical\n21st-century skill. Assessing CPS depends heavily on coding the communication\ndata using a construct-relevant framework, and this process has long been a\nmajor bottleneck to scaling up such assessments. Based on five datasets and two\ncoding frameworks, we demonstrate that ChatGPT can code communication data to a\nsatisfactory level, though performance varies across ChatGPT models, and\ndepends on the coding framework and task characteristics. Interestingly, newer\nreasoning-focused models such as GPT-o1-mini and GPT-o3-mini do not necessarily\nyield better coding results. Additionally, we show that refining prompts based\non feedback from miscoded cases can improve coding accuracy in some instances,\nthough the effectiveness of this approach is not consistent across all tasks.\nThese findings offer practical guidance for researchers and practitioners in\ndeveloping scalable, efficient methods to analyze communication data in support\nof 21st-century skill assessment.", "AI": {"tldr": "ChatGPT can code communication data for CPS assessment, but performance varies by model, framework, and task. Newer reasoning models don't always improve results, and prompt refinement helps inconsistently.", "motivation": "Assessing CPS via communication data coding is a bottleneck; scalable methods are needed.", "method": "Used five datasets and two coding frameworks to test ChatGPT's coding performance across models and tasks.", "result": "ChatGPT codes satisfactorily, but performance varies. Newer models don't always outperform, and prompt refinement has inconsistent benefits.", "conclusion": "ChatGPT offers scalable CPS assessment potential, but model and task specifics matter."}}
{"id": "2505.04034", "pdf": "https://arxiv.org/pdf/2505.04034", "abs": "https://arxiv.org/abs/2505.04034", "authors": ["Ayana Moshruba", "Hamed Poursiami", "Maryam Parsa"], "title": "Izhikevich-Inspired Temporal Dynamics for Enhancing Privacy, Efficiency, and Transferability in Spiking Neural Networks", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": null, "summary": "Biological neurons exhibit diverse temporal spike patterns, which are\nbelieved to support efficient, robust, and adaptive neural information\nprocessing. While models such as Izhikevich can replicate a wide range of these\nfiring dynamics, their complexity poses challenges for directly integrating\nthem into scalable spiking neural networks (SNN) training pipelines. In this\nwork, we propose two probabilistically driven, input-level temporal spike\ntransformations: Poisson-Burst and Delayed-Burst that introduce biologically\ninspired temporal variability directly into standard Leaky Integrate-and-Fire\n(LIF) neurons. This enables scalable training and systematic evaluation of how\nspike timing dynamics affect privacy, generalization, and learning performance.\nPoisson-Burst modulates burst occurrence based on input intensity, while\nDelayed-Burst encodes input strength through burst onset timing. Through\nextensive experiments across multiple benchmarks, we demonstrate that\nPoisson-Burst maintains competitive accuracy and lower resource overhead while\nexhibiting enhanced privacy robustness against membership inference attacks,\nwhereas Delayed-Burst provides stronger privacy protection at a modest accuracy\ntrade-off. These findings highlight the potential of biologically grounded\ntemporal spike dynamics in improving the privacy, generalization and biological\nplausibility of neuromorphic learning systems.", "AI": {"tldr": "The paper proposes two input-level temporal spike transformations (Poisson-Burst and Delayed-Burst) for LIF neurons to study spike timing dynamics' impact on privacy, generalization, and learning.", "motivation": "Biological neurons exhibit diverse spike patterns, but complex models like Izhikevich are hard to scale. The goal is to integrate biologically inspired variability into scalable SNNs.", "method": "Introduces Poisson-Burst (modulates burst occurrence by input intensity) and Delayed-Burst (encodes input strength via burst timing) for LIF neurons.", "result": "Poisson-Burst maintains accuracy with lower overhead and better privacy robustness; Delayed-Burst offers stronger privacy at a slight accuracy cost.", "conclusion": "Biologically inspired spike dynamics can enhance privacy, generalization, and plausibility in neuromorphic systems."}}
{"id": "2505.04110", "pdf": "https://arxiv.org/pdf/2505.04110", "abs": "https://arxiv.org/abs/2505.04110", "authors": ["David Noever", "Forrest McKee"], "title": "Alpha Excel Benchmark", "categories": ["cs.LG"], "comment": null, "summary": "This study presents a novel benchmark for evaluating Large Language Models\n(LLMs) using challenges derived from the Financial Modeling World Cup (FMWC)\nExcel competitions. We introduce a methodology for converting 113 existing FMWC\nchallenges into programmatically evaluable JSON formats and use this dataset to\ncompare the performance of several leading LLMs. Our findings demonstrate\nsignificant variations in performance across different challenge categories,\nwith models showing specific strengths in pattern recognition tasks but\nstruggling with complex numerical reasoning. The benchmark provides a\nstandardized framework for assessing LLM capabilities in realistic\nbusiness-oriented tasks rather than abstract academic problems. This research\ncontributes to the growing field of AI benchmarking by establishing proficiency\namong the 1.5 billion people who daily use Microsoft Excel as a meaningful\nevaluation metric that bridges the gap between academic AI benchmarks and\npractical business applications.", "AI": {"tldr": "A new benchmark for LLMs using Financial Modeling World Cup challenges, showing varied performance across tasks and highlighting practical business applications.", "motivation": "To bridge the gap between academic AI benchmarks and real-world business tasks by leveraging Excel-based challenges.", "method": "Converted 113 FMWC challenges into JSON formats and evaluated leading LLMs on this dataset.", "result": "Models excelled in pattern recognition but struggled with complex numerical reasoning, revealing category-specific strengths.", "conclusion": "The benchmark offers a practical framework for assessing LLMs in business contexts, aligning AI evaluation with real-world Excel proficiency."}}
{"id": "2505.04512", "pdf": "https://arxiv.org/pdf/2505.04512", "abs": "https://arxiv.org/abs/2505.04512", "authors": ["Teng Hu", "Zhentao Yu", "Zhengguang Zhou", "Sen Liang", "Yuan Zhou", "Qin Lin", "Qinglin Lu"], "title": "HunyuanCustom: A Multimodal-Driven Architecture for Customized Video Generation", "categories": ["cs.CV"], "comment": null, "summary": "Customized video generation aims to produce videos featuring specific\nsubjects under flexible user-defined conditions, yet existing methods often\nstruggle with identity consistency and limited input modalities. In this paper,\nwe propose HunyuanCustom, a multi-modal customized video generation framework\nthat emphasizes subject consistency while supporting image, audio, video, and\ntext conditions. Built upon HunyuanVideo, our model first addresses the\nimage-text conditioned generation task by introducing a text-image fusion\nmodule based on LLaVA for enhanced multi-modal understanding, along with an\nimage ID enhancement module that leverages temporal concatenation to reinforce\nidentity features across frames. To enable audio- and video-conditioned\ngeneration, we further propose modality-specific condition injection\nmechanisms: an AudioNet module that achieves hierarchical alignment via spatial\ncross-attention, and a video-driven injection module that integrates\nlatent-compressed conditional video through a patchify-based feature-alignment\nnetwork. Extensive experiments on single- and multi-subject scenarios\ndemonstrate that HunyuanCustom significantly outperforms state-of-the-art open-\nand closed-source methods in terms of ID consistency, realism, and text-video\nalignment. Moreover, we validate its robustness across downstream tasks,\nincluding audio and video-driven customized video generation. Our results\nhighlight the effectiveness of multi-modal conditioning and identity-preserving\nstrategies in advancing controllable video generation. All the code and models\nare available at https://hunyuancustom.github.io.", "AI": {"tldr": "HunyuanCustom is a multi-modal video generation framework that enhances subject consistency and supports diverse input conditions like image, audio, video, and text, outperforming existing methods.", "motivation": "Existing methods for customized video generation struggle with identity consistency and limited input modalities, prompting the need for a more robust solution.", "method": "The framework introduces a text-image fusion module, image ID enhancement, AudioNet for audio alignment, and a video-driven injection module for multi-modal conditioning.", "result": "HunyuanCustom outperforms state-of-the-art methods in ID consistency, realism, and text-video alignment, validated across various scenarios.", "conclusion": "Multi-modal conditioning and identity-preserving strategies effectively advance controllable video generation, as demonstrated by HunyuanCustom."}}
{"id": "2503.18892", "pdf": "https://arxiv.org/pdf/2503.18892", "abs": "https://arxiv.org/abs/2503.18892", "authors": ["Weihao Zeng", "Yuzhen Huang", "Qian Liu", "Wei Liu", "Keqing He", "Zejun Ma", "Junxian He"], "title": "SimpleRL-Zoo: Investigating and Taming Zero Reinforcement Learning for Open Base Models in the Wild", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "DeepSeek-R1 has shown that long chain-of-thought (CoT) reasoning can\nnaturally emerge through a simple reinforcement learning (RL) framework with\nrule-based rewards, where the training may directly start from the base\nmodels-a paradigm referred to as zero RL training. Most recent efforts to\nreproduce zero RL training have primarily focused on the Qwen2.5 model series,\nwhich may not be representative as we find the base models already exhibit\nstrong instruction-following and self-reflection abilities. In this work, we\ninvestigate zero RL training across 10 diverse base models, spanning different\nfamilies and sizes including LLama3-8B, Mistral-7B/24B, DeepSeek-Math-7B,\nQwen2.5-math-7B, and all Qwen2.5 models from 0.5B to 32B. Leveraging several\nkey design strategies-such as adjusting format reward and controlling query\ndifficulty-we achieve substantial improvements in both reasoning accuracy and\nresponse length across most settings. However, by carefully monitoring the\ntraining dynamics, we observe that different base models exhibit distinct\npatterns during training. For instance, the increased response length does not\nalways correlate with the emergence of certain cognitive behaviors such as\nverification (i.e., the \"aha moment\"). Notably, we observe the \"aha moment\" for\nthe first time in small models not from the Qwen family. We share the key\ndesigns that enable successful zero RL training, along with our findings and\npractices. To facilitate further research, we open-source the code, models, and\nanalysis tools.", "AI": {"tldr": "The paper investigates zero RL training across diverse base models, achieving improvements in reasoning accuracy and response length, while noting distinct training patterns and the emergence of cognitive behaviors like the 'aha moment.'", "motivation": "To explore zero RL training beyond the Qwen2.5 model series, addressing limitations in representativeness and understanding diverse model behaviors.", "method": "Leverages key design strategies like adjusting format rewards and controlling query difficulty, applied across 10 diverse base models.", "result": "Substantial improvements in reasoning accuracy and response length, with observations of distinct training patterns and the 'aha moment' in small non-Qwen models.", "conclusion": "Successful zero RL training is achievable with careful design, and the findings are shared openly to support further research."}}
{"id": "2505.04084", "pdf": "https://arxiv.org/pdf/2505.04084", "abs": "https://arxiv.org/abs/2505.04084", "authors": ["Xiang Chen", "Jibin Wang", "Chaoyang Gao", "Xiaolin Ju", "Zhanqi Cui"], "title": "An Empirical Study of OpenAI API Discussions on Stack Overflow", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The rapid advancement of large language models (LLMs), represented by\nOpenAI's GPT series, has significantly impacted various domains such as natural\nlanguage processing, software development, education, healthcare, finance, and\nscientific research. However, OpenAI APIs introduce unique challenges that\ndiffer from traditional APIs, such as the complexities of prompt engineering,\ntoken-based cost management, non-deterministic outputs, and operation as black\nboxes. To the best of our knowledge, the challenges developers encounter when\nusing OpenAI APIs have not been explored in previous empirical studies. To fill\nthis gap, we conduct the first comprehensive empirical study by analyzing 2,874\nOpenAI API-related discussions from the popular Q&A forum Stack Overflow. We\nfirst examine the popularity and difficulty of these posts. After manually\ncategorizing them into nine OpenAI API-related categories, we identify specific\nchallenges associated with each category through topic modeling analysis. Based\non our empirical findings, we finally propose actionable implications for\ndevelopers, LLM vendors, and researchers.", "AI": {"tldr": "The paper explores challenges developers face with OpenAI APIs, analyzing 2,874 Stack Overflow posts to identify issues and propose solutions.", "motivation": "To address the lack of empirical studies on OpenAI API challenges, such as prompt engineering and non-deterministic outputs.", "method": "Analyzed 2,874 Stack Overflow discussions, categorized them into nine API-related topics, and performed topic modeling.", "result": "Identified specific challenges per category, highlighting developer struggles with OpenAI APIs.", "conclusion": "Proposes actionable implications for developers, vendors, and researchers to improve OpenAI API usage."}}
{"id": "2505.04139", "pdf": "https://arxiv.org/pdf/2505.04139", "abs": "https://arxiv.org/abs/2505.04139", "authors": ["Hongyi Li", "Jun Xu", "William Ward Armstrong"], "title": "LHT: Statistically-Driven Oblique Decision Trees for Interpretable Classification", "categories": ["cs.LG"], "comment": null, "summary": "We introduce the Learning Hyperplane Tree (LHT), a novel oblique decision\ntree model designed for expressive and interpretable classification. LHT\nfundamentally distinguishes itself through a non-iterative,\nstatistically-driven approach to constructing splitting hyperplanes. Unlike\nmethods that rely on iterative optimization or heuristics, LHT directly\ncomputes the hyperplane parameters, which are derived from feature weights\nbased on the differences in feature expectations between classes within each\nnode. This deterministic mechanism enables a direct and well-defined hyperplane\nconstruction process. Predictions leverage a unique piecewise linear membership\nfunction within leaf nodes, obtained via local least-squares fitting. We\nformally analyze the convergence of the LHT splitting process, ensuring that\neach split yields meaningful, non-empty partitions. Furthermore, we establish\nthat the time complexity for building an LHT up to depth $d$ is $O(mnd)$,\ndemonstrating the practical feasibility of constructing trees with powerful\noblique splits using this methodology. The explicit feature weighting at each\nsplit provides inherent interpretability. Experimental results on benchmark\ndatasets demonstrate LHT's competitive accuracy, positioning it as a practical,\ntheoretically grounded, and interpretable alternative in the landscape of\ntree-based models. The implementation of the proposed method is available at\nhttps://github.com/Hongyi-Li-sz/LHT_model.", "AI": {"tldr": "LHT is a non-iterative, statistically-driven oblique decision tree model for expressive and interpretable classification, with deterministic hyperplane construction and competitive accuracy.", "motivation": "To create an interpretable and theoretically grounded oblique decision tree model that avoids iterative optimization or heuristics.", "method": "LHT directly computes hyperplane parameters from feature weights based on class differences, using a deterministic mechanism and piecewise linear membership functions in leaf nodes.", "result": "LHT achieves competitive accuracy, has a time complexity of O(mnd), and provides interpretability through explicit feature weighting.", "conclusion": "LHT is a practical, interpretable, and efficient alternative to traditional tree-based models, with theoretical guarantees and open-source implementation."}}
{"id": "2505.04522", "pdf": "https://arxiv.org/pdf/2505.04522", "abs": "https://arxiv.org/abs/2505.04522", "authors": ["Pengfei Guo", "Can Zhao", "Dong Yang", "Yufan He", "Vishwesh Nath", "Ziyue Xu", "Pedro R. A. S. Bassi", "Zongwei Zhou", "Benjamin D. Simon", "Stephanie Anne Harmon", "Baris Turkbey", "Daguang Xu"], "title": "Text2CT: Towards 3D CT Volume Generation from Free-text Descriptions Using Diffusion Model", "categories": ["cs.CV"], "comment": null, "summary": "Generating 3D CT volumes from descriptive free-text inputs presents a\ntransformative opportunity in diagnostics and research. In this paper, we\nintroduce Text2CT, a novel approach for synthesizing 3D CT volumes from textual\ndescriptions using the diffusion model. Unlike previous methods that rely on\nfixed-format text input, Text2CT employs a novel prompt formulation that\nenables generation from diverse, free-text descriptions. The proposed framework\nencodes medical text into latent representations and decodes them into\nhigh-resolution 3D CT scans, effectively bridging the gap between semantic text\ninputs and detailed volumetric representations in a unified 3D framework. Our\nmethod demonstrates superior performance in preserving anatomical fidelity and\ncapturing intricate structures as described in the input text. Extensive\nevaluations show that our approach achieves state-of-the-art results, offering\npromising potential applications in diagnostics, and data augmentation.", "AI": {"tldr": "Text2CT generates 3D CT volumes from free-text descriptions using a diffusion model, outperforming fixed-format methods and achieving high anatomical fidelity.", "motivation": "To bridge the gap between semantic text inputs and detailed 3D CT scans for diagnostics and research.", "method": "Uses a diffusion model with a novel prompt formulation to encode medical text into latent representations and decode them into high-resolution 3D CT scans.", "result": "Superior performance in preserving anatomical fidelity and capturing intricate structures, achieving state-of-the-art results.", "conclusion": "Text2CT offers promising applications in diagnostics and data augmentation, demonstrating the potential of free-text-to-3D-CT synthesis."}}
{"id": "2505.00831", "pdf": "https://arxiv.org/pdf/2505.00831", "abs": "https://arxiv.org/abs/2505.00831", "authors": ["Quang P. M. Pham", "Khoi T. N. Nguyen", "Nhi H. Doan", "Cuong A. Pham", "Kentaro Inui", "Dezhen Song"], "title": "SmallPlan: Leverage Small Language Models for Sequential Path Planning with Simulation-Powered, LLM-Guided Distillation", "categories": ["cs.RO", "cs.CL"], "comment": "Paper is under review", "summary": "Efficient path planning in robotics, particularly within large-scale, dynamic\nenvironments, remains a significant hurdle. While Large Language Models (LLMs)\noffer strong reasoning capabilities, their high computational cost and limited\nadaptability in dynamic scenarios hinder real-time deployment on edge devices.\nWe present SmallPlan -- a novel framework leveraging LLMs as teacher models to\ntrain lightweight Small Language Models (SLMs) for high-level path planning\ntasks. In SmallPlan, the SLMs provide optimal action sequences to navigate\nacross scene graphs that compactly represent full-scaled 3D scenes. The SLMs\nare trained in a simulation-powered, interleaved manner with LLM-guided\nsupervised fine-tuning (SFT) and reinforcement learning (RL). This strategy not\nonly enables SLMs to successfully complete navigation tasks but also makes them\naware of important factors like travel distance and number of trials. Through\nexperiments, we demonstrate that the fine-tuned SLMs perform competitively with\nlarger models like GPT-4o on sequential path planning, without suffering from\nhallucination and overfitting. SmallPlan is resource-efficient, making it\nwell-suited for edge-device deployment and advancing practical autonomous\nrobotics.", "AI": {"tldr": "SmallPlan trains lightweight SLMs using LLMs as teachers for efficient path planning in robotics, achieving competitive performance with larger models while being resource-efficient.", "motivation": "Addressing the high computational cost and limited adaptability of LLMs in dynamic environments for real-time robotics applications.", "method": "Uses LLMs to train SLMs via interleaved supervised fine-tuning and reinforcement learning on scene graphs.", "result": "Fine-tuned SLMs match GPT-4o performance in path planning, avoiding hallucination and overfitting.", "conclusion": "SmallPlan is a practical, resource-efficient solution for edge-device deployment in autonomous robotics."}}
{"id": "2505.04101", "pdf": "https://arxiv.org/pdf/2505.04101", "abs": "https://arxiv.org/abs/2505.04101", "authors": ["AbdulAziz AbdulGhaffar", "Ashraf Matrawy"], "title": "LLMs' Suitability for Network Security: A Case Study of STRIDE Threat Modeling", "categories": ["cs.CR", "cs.AI", "cs.NI"], "comment": null, "summary": "Artificial Intelligence (AI) is expected to be an integral part of\nnext-generation AI-native 6G networks. With the prevalence of AI, researchers\nhave identified numerous use cases of AI in network security. However, there\nare almost nonexistent studies that analyze the suitability of Large Language\nModels (LLMs) in network security. To fill this gap, we examine the suitability\nof LLMs in network security, particularly with the case study of STRIDE threat\nmodeling. We utilize four prompting techniques with five LLMs to perform STRIDE\nclassification of 5G threats. From our evaluation results, we point out key\nfindings and detailed insights along with the explanation of the possible\nunderlying factors influencing the behavior of LLMs in the modeling of certain\nthreats. The numerical results and the insights support the necessity for\nadjusting and fine-tuning LLMs for network security use cases.", "AI": {"tldr": "The paper explores the suitability of Large Language Models (LLMs) in network security, focusing on STRIDE threat modeling for 5G threats, and highlights the need for fine-tuning LLMs for such use cases.", "motivation": "Despite AI's growing role in 6G networks, there's a lack of research on LLMs' applicability in network security, prompting this study.", "method": "The study uses four prompting techniques with five LLMs to classify 5G threats using the STRIDE model.", "result": "Evaluation reveals key findings and insights, indicating the need for adjustments and fine-tuning of LLMs for network security.", "conclusion": "LLMs show potential but require fine-tuning for effective use in network security, particularly for threat modeling."}}
{"id": "2505.04158", "pdf": "https://arxiv.org/pdf/2505.04158", "abs": "https://arxiv.org/abs/2505.04158", "authors": ["Yulong Wang", "Yushuo Liu", "Xiaoyi Duan", "Kai Wang"], "title": "FilterTS: Comprehensive Frequency Filtering for Multivariate Time Series Forecasting", "categories": ["cs.LG"], "comment": "Accepted to AAAI 2025", "summary": "Multivariate time series forecasting is crucial across various industries,\nwhere accurate extraction of complex periodic and trend components can\nsignificantly enhance prediction performance. However, existing models often\nstruggle to capture these intricate patterns. To address these challenges, we\npropose FilterTS, a novel forecasting model that utilizes specialized filtering\ntechniques based on the frequency domain. FilterTS introduces a Dynamic\nCross-Variable Filtering Module, a key innovation that dynamically leverages\nother variables as filters to extract and reinforce shared variable frequency\ncomponents across variables in multivariate time series. Additionally, a Static\nGlobal Filtering Module captures stable frequency components, identified\nthroughout the entire training set. Moreover, the model is built in the\nfrequency domain, converting time-domain convolutions into frequency-domain\nmultiplicative operations to enhance computational efficiency. Extensive\nexperimental results on eight real-world datasets have demonstrated that\nFilterTS significantly outperforms existing methods in terms of prediction\naccuracy and computational efficiency.", "AI": {"tldr": "FilterTS is a novel multivariate time series forecasting model using frequency-domain filtering to improve accuracy and efficiency.", "motivation": "Existing models struggle to capture complex periodic and trend components in multivariate time series, limiting prediction performance.", "method": "FilterTS employs Dynamic Cross-Variable Filtering and Static Global Filtering Modules in the frequency domain, converting time-domain convolutions to multiplicative operations.", "result": "FilterTS outperforms existing methods in accuracy and computational efficiency across eight real-world datasets.", "conclusion": "FilterTS effectively addresses the limitations of current models by leveraging frequency-domain techniques for enhanced forecasting."}}
{"id": "2505.04526", "pdf": "https://arxiv.org/pdf/2505.04526", "abs": "https://arxiv.org/abs/2505.04526", "authors": ["Qi Zhou", "Yukai Shi", "Xiaojun Yang", "Xiaoyu Xian", "Lunjia Liao", "Ruimao Zhang", "Liang Lin"], "title": "DFVO: Learning Darkness-free Visible and Infrared Image Disentanglement and Fusion All at Once", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Visible and infrared image fusion is one of the most crucial tasks in the\nfield of image fusion, aiming to generate fused images with clear structural\ninformation and high-quality texture features for high-level vision tasks.\nHowever, when faced with severe illumination degradation in visible images, the\nfusion results of existing image fusion methods often exhibit blurry and dim\nvisual effects, posing major challenges for autonomous driving. To this end, a\nDarkness-Free network is proposed to handle Visible and infrared image\ndisentanglement and fusion all at Once (DFVO), which employs a cascaded\nmulti-task approach to replace the traditional two-stage cascaded training\n(enhancement and fusion), addressing the issue of information entropy loss\ncaused by hierarchical data transmission. Specifically, we construct a\nlatent-common feature extractor (LCFE) to obtain latent features for the\ncascaded tasks strategy. Firstly, a details-extraction module (DEM) is devised\nto acquire high-frequency semantic information. Secondly, we design a hyper\ncross-attention module (HCAM) to extract low-frequency information and preserve\ntexture features from source images. Finally, a relevant loss function is\ndesigned to guide the holistic network learning, thereby achieving better image\nfusion. Extensive experiments demonstrate that our proposed approach\noutperforms state-of-the-art alternatives in terms of qualitative and\nquantitative evaluations. Particularly, DFVO can generate clearer, more\ninformative, and more evenly illuminated fusion results in the dark\nenvironments, achieving best performance on the LLVIP dataset with 63.258 dB\nPSNR and 0.724 CC, providing more effective information for high-level vision\ntasks. Our code is publicly accessible at https://github.com/DaVin-Qi530/DFVO.", "AI": {"tldr": "The paper proposes a Darkness-Free network (DFVO) for visible and infrared image fusion, addressing blurry and dim results in low-light conditions. It uses a cascaded multi-task approach with a latent-common feature extractor, achieving superior performance on the LLVIP dataset.", "motivation": "Existing image fusion methods struggle with severe illumination degradation, leading to poor visual effects for autonomous driving. The goal is to create clearer, more informative fused images.", "method": "DFVO employs a cascaded multi-task strategy with a latent-common feature extractor (LCFE), details-extraction module (DEM), and hyper cross-attention module (HCAM) to preserve texture and structural information.", "result": "DFVO outperforms state-of-the-art methods, achieving 63.258 dB PSNR and 0.724 CC on the LLVIP dataset, with clearer and more evenly illuminated fusion results.", "conclusion": "The proposed DFVO network effectively addresses illumination degradation in image fusion, providing superior results for high-level vision tasks."}}
{"id": "2505.03335", "pdf": "https://arxiv.org/pdf/2505.03335", "abs": "https://arxiv.org/abs/2505.03335", "authors": ["Andrew Zhao", "Yiran Wu", "Yang Yue", "Tong Wu", "Quentin Xu", "Yang Yue", "Matthieu Lin", "Shenzhi Wang", "Qingyun Wu", "Zilong Zheng", "Gao Huang"], "title": "Absolute Zero: Reinforced Self-play Reasoning with Zero Data", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) has shown promise in\nenhancing the reasoning capabilities of large language models by learning\ndirectly from outcome-based rewards. Recent RLVR works that operate under the\nzero setting avoid supervision in labeling the reasoning process, but still\ndepend on manually curated collections of questions and answers for training.\nThe scarcity of high-quality, human-produced examples raises concerns about the\nlong-term scalability of relying on human supervision, a challenge already\nevident in the domain of language model pretraining. Furthermore, in a\nhypothetical future where AI surpasses human intelligence, tasks provided by\nhumans may offer limited learning potential for a superintelligent system. To\naddress these concerns, we propose a new RLVR paradigm called Absolute Zero, in\nwhich a single model learns to propose tasks that maximize its own learning\nprogress and improves reasoning by solving them, without relying on any\nexternal data. Under this paradigm, we introduce the Absolute Zero Reasoner\n(AZR), a system that self-evolves its training curriculum and reasoning ability\nby using a code executor to both validate proposed code reasoning tasks and\nverify answers, serving as an unified source of verifiable reward to guide\nopen-ended yet grounded learning. Despite being trained entirely without\nexternal data, AZR achieves overall SOTA performance on coding and mathematical\nreasoning tasks, outperforming existing zero-setting models that rely on tens\nof thousands of in-domain human-curated examples. Furthermore, we demonstrate\nthat AZR can be effectively applied across different model scales and is\ncompatible with various model classes.", "AI": {"tldr": "The paper introduces Absolute Zero (AZR), a self-evolving RLVR paradigm for language models that learns without external data, achieving SOTA performance on reasoning tasks.", "motivation": "Addressing scalability concerns of human supervision in RLVR and preparing for a future where human-provided tasks may limit superintelligent AI learning.", "method": "AZR proposes and solves its own tasks using a code executor for validation and reward, eliminating reliance on external data.", "result": "AZR outperforms zero-setting models using human-curated data, achieving SOTA in coding and math reasoning.", "conclusion": "AZR demonstrates scalable, open-ended learning without human supervision, applicable across model scales and classes."}}
{"id": "2505.04165", "pdf": "https://arxiv.org/pdf/2505.04165", "abs": "https://arxiv.org/abs/2505.04165", "authors": ["Kairong Yu", "Tianqing Zhang", "Qi Xu", "Gang Pan", "Hongwei Wang"], "title": "TS-SNN: Temporal Shift Module for Spiking Neural Networks", "categories": ["cs.NE", "cs.AI"], "comment": "Accepted by ICML2025", "summary": "Spiking Neural Networks (SNNs) are increasingly recognized for their\nbiological plausibility and energy efficiency, positioning them as strong\nalternatives to Artificial Neural Networks (ANNs) in neuromorphic computing\napplications. SNNs inherently process temporal information by leveraging the\nprecise timing of spikes, but balancing temporal feature utilization with low\nenergy consumption remains a challenge. In this work, we introduce Temporal\nShift module for Spiking Neural Networks (TS-SNN), which incorporates a novel\nTemporal Shift (TS) module to integrate past, present, and future spike\nfeatures within a single timestep via a simple yet effective shift operation. A\nresidual combination method prevents information loss by integrating shifted\nand original features. The TS module is lightweight, requiring only one\nadditional learnable parameter, and can be seamlessly integrated into existing\narchitectures with minimal additional computational cost. TS-SNN achieves\nstate-of-the-art performance on benchmarks like CIFAR-10 (96.72\\%), CIFAR-100\n(80.28\\%), and ImageNet (70.61\\%) with fewer timesteps, while maintaining low\nenergy consumption. This work marks a significant step forward in developing\nefficient and accurate SNN architectures.", "AI": {"tldr": "TS-SNN introduces a lightweight Temporal Shift module to enhance Spiking Neural Networks by integrating past, present, and future spike features efficiently, achieving top performance on benchmarks with low energy use.", "motivation": "Balancing temporal feature utilization with energy efficiency in SNNs is challenging, motivating the development of TS-SNN.", "method": "The TS-SNN uses a Temporal Shift module to integrate spike features across timesteps via a simple shift operation, combined with a residual method to prevent information loss.", "result": "TS-SNN achieves state-of-the-art results on CIFAR-10 (96.72%), CIFAR-100 (80.28%), and ImageNet (70.61%) with minimal energy consumption.", "conclusion": "TS-SNN advances efficient and accurate SNN architectures, demonstrating significant improvements in performance and energy efficiency."}}
{"id": "2505.04163", "pdf": "https://arxiv.org/pdf/2505.04163", "abs": "https://arxiv.org/abs/2505.04163", "authors": ["Sungwon Han", "Seungeon Lee", "Meeyoung Cha", "Sercan O Arik", "Jinsung Yoon"], "title": "Retrieval Augmented Time Series Forecasting", "categories": ["cs.LG", "cs.IR"], "comment": null, "summary": "Time series forecasting uses historical data to predict future trends,\nleveraging the relationships between past observations and available features.\nIn this paper, we propose RAFT, a retrieval-augmented time series forecasting\nmethod to provide sufficient inductive biases and complement the model's\nlearning capacity. When forecasting the subsequent time frames, we directly\nretrieve historical data candidates from the training dataset with patterns\nmost similar to the input, and utilize the future values of these candidates\nalongside the inputs to obtain predictions. This simple approach augments the\nmodel's capacity by externally providing information about past patterns via\nretrieval modules. Our empirical evaluations on ten benchmark datasets show\nthat RAFT consistently outperforms contemporary baselines with an average win\nratio of 86%.", "AI": {"tldr": "RAFT is a retrieval-augmented time series forecasting method that leverages historical data patterns to improve predictions, outperforming baselines by 86%.", "motivation": "To enhance time series forecasting by providing inductive biases and complementing the model's learning capacity through retrieval of similar historical patterns.", "method": "RAFT retrieves historical data candidates with patterns similar to the input and uses their future values alongside inputs for predictions.", "result": "RAFT outperforms contemporary baselines on ten benchmark datasets with an average win ratio of 86%.", "conclusion": "RAFT effectively augments forecasting models by retrieving and utilizing historical patterns, demonstrating superior performance."}}
{"id": "2505.04529", "pdf": "https://arxiv.org/pdf/2505.04529", "abs": "https://arxiv.org/abs/2505.04529", "authors": ["Edward Humes", "Xiaomin Lin", "Uttej Kallakuri", "Tinoosh Mohsenin"], "title": "RAFT: Robust Augmentation of FeaTures for Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Image segmentation is a powerful computer vision technique for scene\nunderstanding. However, real-world deployment is stymied by the need for\nhigh-quality, meticulously labeled datasets. Synthetic data provides\nhigh-quality labels while reducing the need for manual data collection and\nannotation. However, deep neural networks trained on synthetic data often face\nthe Syn2Real problem, leading to poor performance in real-world deployments.\n  To mitigate the aforementioned gap in image segmentation, we propose RAFT, a\nnovel framework for adapting image segmentation models using minimal labeled\nreal-world data through data and feature augmentations, as well as active\nlearning. To validate RAFT, we perform experiments on the synthetic-to-real\n\"SYNTHIA->Cityscapes\" and \"GTAV->Cityscapes\" benchmarks. We managed to surpass\nthe previous state of the art, HALO. SYNTHIA->Cityscapes experiences an\nimprovement in mIoU* upon domain adaptation of 2.1%/79.9%, and GTAV->Cityscapes\nexperiences a 0.4%/78.2% improvement in mIoU. Furthermore, we test our approach\non the real-to-real benchmark of \"Cityscapes->ACDC\", and again surpass HALO,\nwith a gain in mIoU upon adaptation of 1.3%/73.2%. Finally, we examine the\neffect of the allocated annotation budget and various components of RAFT upon\nthe final transfer mIoU.", "AI": {"tldr": "RAFT improves synthetic-to-real image segmentation with minimal labeled data, outperforming HALO on benchmarks like SYNTHIA->Cityscapes and GTAV->Cityscapes.", "motivation": "Address the Syn2Real problem in image segmentation by reducing reliance on manual labeling and improving model adaptation.", "method": "Proposes RAFT, a framework using data/feature augmentations and active learning for domain adaptation.", "result": "Achieves mIoU improvements: 2.1%/79.9% (SYNTHIA->Cityscapes), 0.4%/78.2% (GTAV->Cityscapes), and 1.3%/73.2% (Cityscapes->ACDC).", "conclusion": "RAFT effectively bridges the synthetic-to-real gap in image segmentation with minimal labeled data, outperforming prior methods."}}
{"id": "2505.03414", "pdf": "https://arxiv.org/pdf/2505.03414", "abs": "https://arxiv.org/abs/2505.03414", "authors": ["Fangming Cui", "Yonggang Zhang", "Xuan Wang", "Xinmei Tian", "Jun Yu"], "title": "Enhancing Target-unspecific Tasks through a Features Matrix", "categories": ["cs.CV", "cs.CL"], "comment": "ICML 2025", "summary": "Recent developments in prompt learning of large vision-language models have\nsignificantly improved performance in target-specific tasks. However, these\nprompt optimizing methods often struggle to tackle the target-unspecific or\ngeneralizable tasks effectively. It may be attributed to the fact that\noverfitting training causes the model to forget its general knowledge having\nstrong promotion on target-unspecific tasks. To alleviate this issue, we\npropose a novel Features Matrix (FM) regularization approach designed to\nenhance these models on target-unspecific tasks. Our method extracts and\nleverages general knowledge, shaping a Features Matrix (FM). Specifically, the\nFM captures the semantics of diverse inputs from a deep and fine perspective,\npreserving essential general knowledge, which mitigates the risk of\noverfitting. Representative evaluations demonstrate that: 1) the FM is\ncompatible with existing frameworks as a generic and flexible module, and 2)\nthe FM significantly showcases its effectiveness in enhancing target-unspecific\ntasks, achieving state-of-the-art performance.", "AI": {"tldr": "A novel Features Matrix (FM) regularization method is proposed to enhance large vision-language models for target-unspecific tasks by preserving general knowledge and preventing overfitting.", "motivation": "Existing prompt learning methods for large vision-language models struggle with target-unspecific tasks due to overfitting, which causes loss of general knowledge.", "method": "The proposed method introduces a Features Matrix (FM) that captures diverse input semantics from a deep and fine perspective to preserve general knowledge.", "result": "The FM is compatible with existing frameworks and significantly improves performance on target-unspecific tasks, achieving state-of-the-art results.", "conclusion": "The FM regularization approach effectively mitigates overfitting and enhances generalizability in vision-language models."}}
{"id": "2505.04174", "pdf": "https://arxiv.org/pdf/2505.04174", "abs": "https://arxiv.org/abs/2505.04174", "authors": ["Ju-Hyung Lee", "Yanqing Lu"], "title": "On-Device LLM for Context-Aware Wi-Fi Roaming", "categories": ["cs.LG", "cs.AI", "cs.NI", "eess.SP"], "comment": null, "summary": "Wireless roaming is a critical yet challenging task for maintaining seamless\nconnectivity in dynamic mobile environments. Conventional threshold-based or\nheuristic schemes often fail, leading to either sticky or excessive handovers.\nWe introduce the first cross-layer use of an on-device large language model\n(LLM): high-level reasoning in the application layer that issues real-time\nactions executed in the PHY/MAC stack. The LLM addresses two tasks: (i)\ncontext-aware AP selection, where structured prompts fuse environmental cues\n(e.g., location, time) to choose the best BSSID; and (ii) dynamic threshold\nadjustment, where the model adaptively decides when to roam. To satisfy the\ntight latency and resource budgets of edge hardware, we apply a suite of\noptimizations-chain-of-thought prompting, parameter-efficient fine-tuning, and\nquantization. Experiments on indoor and outdoor datasets show that our approach\nsurpasses legacy heuristics and DRL baselines, achieving a strong balance\nbetween roaming stability and signal quality. These findings underscore the\npromise of application-layer LLM reasoning for lower-layer wireless control in\nfuture edge systems.", "AI": {"tldr": "The paper introduces a cross-layer approach using an on-device LLM for wireless roaming, improving AP selection and dynamic threshold adjustment, outperforming traditional methods.", "motivation": "Wireless roaming is challenging due to sticky or excessive handovers in dynamic environments, and conventional methods often fail.", "method": "Uses an on-device LLM for context-aware AP selection and dynamic threshold adjustment, optimized for latency and resource efficiency.", "result": "Outperforms legacy heuristics and DRL baselines, balancing roaming stability and signal quality.", "conclusion": "Demonstrates the potential of application-layer LLM reasoning for wireless control in edge systems."}}
{"id": "2505.04167", "pdf": "https://arxiv.org/pdf/2505.04167", "abs": "https://arxiv.org/abs/2505.04167", "authors": ["Yulong Wang", "Xiaofeng Hu", "Xiaojian Cui", "Kai Wang"], "title": "STRGCN: Capturing Asynchronous Spatio-Temporal Dependencies for Irregular Multivariate Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Irregular multivariate time series (IMTS) are prevalent in real-world\napplications across many fields, where varying sensor frequencies and\nasynchronous measurements pose significant modeling challenges. Existing\nsolutions often rely on a pre-alignment strategy to normalize data, which can\ndistort intrinsic patterns and escalate computational and memory demands.\nAddressing these limitations, we introduce STRGCN, a Spatio-Temporal Relational\nGraph Convolutional Network that avoids pre-alignment and directly captures the\ncomplex interdependencies in IMTS by representing them as a fully connected\ngraph. Each observation is represented as a node, allowing the model to\neffectively handle misaligned timestamps by mapping all inter-node\nrelationships, thus faithfully preserving the asynchronous nature of the data.\nMoreover, we enhance this model with a hierarchical ``Sandwich'' structure that\nstrategically aggregates nodes to optimize graph embeddings, reducing\ncomputational overhead while maintaining detailed local and global context.\nExtensive experiments on four public datasets demonstrate that STRGCN achieves\nstate-of-the-art accuracy, competitive memory usage and training speed.", "AI": {"tldr": "STRGCN is a Spatio-Temporal Relational Graph Convolutional Network designed for irregular multivariate time series (IMTS) without pre-alignment, achieving state-of-the-art performance.", "motivation": "Existing methods for IMTS rely on pre-alignment, which distorts data patterns and increases computational costs. STRGCN addresses these limitations by directly modeling asynchronous data.", "method": "STRGCN represents IMTS as a fully connected graph, with observations as nodes, and uses a hierarchical 'Sandwich' structure to optimize embeddings.", "result": "Experiments on four datasets show STRGCN achieves top accuracy with efficient memory usage and training speed.", "conclusion": "STRGCN effectively handles IMTS by preserving asynchronous data nature and outperforms existing methods."}}
{"id": "2505.04540", "pdf": "https://arxiv.org/pdf/2505.04540", "abs": "https://arxiv.org/abs/2505.04540", "authors": ["Ashutosh Singandhupe", "Sanket Lokhande", "Hung Manh La"], "title": "Registration of 3D Point Sets Using Exponential-based Similarity Matrix", "categories": ["cs.CV"], "comment": null, "summary": "Point cloud registration is a fundamental problem in computer vision and\nrobotics, involving the alignment of 3D point sets captured from varying\nviewpoints using depth sensors such as LiDAR or structured light. In modern\nrobotic systems, especially those focused on mapping, it is essential to merge\nmultiple views of the same environment accurately. However, state-of-the-art\nregistration techniques often struggle when large rotational differences exist\nbetween point sets or when the data is significantly corrupted by sensor noise.\nThese challenges can lead to misalignments and, consequently, to inaccurate or\ndistorted 3D reconstructions. In this work, we address both these limitations\nby proposing a robust modification to the classic Iterative Closest Point (ICP)\nalgorithm. Our method, termed Exponential Similarity Matrix ICP (ESM-ICP),\nintegrates a Gaussian-inspired exponential weighting scheme to construct a\nsimilarity matrix that dynamically adapts across iterations. This matrix\nfacilitates improved estimation of both rotational and translational components\nduring alignment. We demonstrate the robustness of ESM-ICP in two challenging\nscenarios: (i) large rotational discrepancies between the source and target\npoint clouds, and (ii) data corrupted by non-Gaussian noise. Our results show\nthat ESM-ICP outperforms traditional geometric registration techniques as well\nas several recent learning-based methods. To encourage reproducibility and\ncommunity engagement, our full implementation is made publicly available on\nGitHub. https://github.com/aralab-unr/ESM_ICP", "AI": {"tldr": "The paper introduces ESM-ICP, a robust variant of the ICP algorithm for point cloud registration, addressing challenges like large rotations and noise.", "motivation": "Existing registration techniques struggle with large rotational differences and noise, leading to inaccurate 3D reconstructions.", "method": "ESM-ICP uses a Gaussian-inspired exponential weighting scheme to dynamically adapt a similarity matrix for better alignment.", "result": "ESM-ICP outperforms traditional and learning-based methods in handling large rotations and non-Gaussian noise.", "conclusion": "ESM-ICP is a robust solution for point cloud registration, with public implementation available for reproducibility."}}
{"id": "2505.04209", "pdf": "https://arxiv.org/pdf/2505.04209", "abs": "https://arxiv.org/abs/2505.04209", "authors": ["Soumik Dey", "Hansi Wu", "Binbin Li"], "title": "To Judge or not to Judge: Using LLM Judgements for Advertiser Keyphrase Relevance at eBay", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": null, "summary": "E-commerce sellers are recommended keyphrases based on their inventory on\nwhich they advertise to increase buyer engagement (clicks/sales). The relevance\nof advertiser keyphrases plays an important role in preventing the inundation\nof search systems with numerous irrelevant items that compete for attention in\nauctions, in addition to maintaining a healthy seller perception. In this work,\nwe describe the shortcomings of training Advertiser keyphrase relevance filter\nmodels on click/sales/search relevance signals and the importance of aligning\nwith human judgment, as sellers have the power to adopt or reject said\nkeyphrase recommendations. In this study, we frame Advertiser keyphrase\nrelevance as a complex interaction between 3 dynamical systems -- seller\njudgment, which influences seller adoption of our product, Advertising, which\nprovides the keyphrases to bid on, and Search, who holds the auctions for the\nsame keyphrases. This study discusses the practicalities of using human\njudgment via a case study at eBay Advertising and demonstrate that using\nLLM-as-a-judge en-masse as a scalable proxy for seller judgment to train our\nrelevance models achieves a better harmony across the three systems -- provided\nthat they are bound by a meticulous evaluation framework grounded in business\nmetrics.", "AI": {"tldr": "The paper highlights the need for aligning advertiser keyphrase relevance models with human judgment, using LLM-as-a-judge for scalability, to improve harmony between seller judgment, advertising, and search systems.", "motivation": "Current models trained on click/sales/search signals misalign with seller judgment, risking irrelevant ads and poor seller perception.", "method": "Frames keyphrase relevance as an interaction between seller judgment, advertising, and search. Uses LLM-as-a-judge as a scalable proxy for human judgment, bound by a business-metrics evaluation framework.", "result": "Demonstrates that aligning models with human judgment via LLM-as-a-judge improves harmony across the three systems.", "conclusion": "Aligning relevance models with human judgment, scaled via LLMs, enhances system harmony and business outcomes."}}
{"id": "2505.04173", "pdf": "https://arxiv.org/pdf/2505.04173", "abs": "https://arxiv.org/abs/2505.04173", "authors": ["Zixiao Wang", "Wenqian Zhao", "Yunheng Shen", "Yang Bai", "Guojin Chen", "Farzan Farnia", "Bei Yu"], "title": "DiffPattern-Flex: Efficient Layout Pattern Generation via Discrete Diffusion", "categories": ["cs.LG"], "comment": "13 pages, 13 figures. Accepted by TCAD", "summary": "Recent advancements in layout pattern generation have been dominated by deep\ngenerative models. However, relying solely on neural networks for legality\nguarantees raises concerns in many practical applications. In this paper, we\npresent \\tool{DiffPattern}-Flex, a novel approach designed to generate reliable\nlayout patterns efficiently. \\tool{DiffPattern}-Flex incorporates a new method\nfor generating diverse topologies using a discrete diffusion model while\nmaintaining a lossless and compute-efficient layout representation. To ensure\nlegal pattern generation, we employ {an} optimization-based, white-box pattern\nassessment process based on specific design rules. Furthermore, fast sampling\nand efficient legalization technologies are employed to accelerate the\ngeneration process. Experimental results across various benchmarks demonstrate\nthat \\tool{DiffPattern}-Flex significantly outperforms existing methods and\nexcels at producing reliable layout patterns.", "AI": {"tldr": "DiffPattern-Flex introduces a novel method for reliable layout pattern generation using a discrete diffusion model and optimization-based legalization.", "motivation": "Address concerns about legality guarantees in neural network-based layout generation by ensuring reliable and efficient pattern production.", "method": "Combines a discrete diffusion model for diverse topology generation with an optimization-based white-box assessment for legality.", "result": "Outperforms existing methods in benchmarks, producing reliable layout patterns efficiently.", "conclusion": "DiffPattern-Flex is a robust solution for legal and efficient layout pattern generation."}}
{"id": "2505.04575", "pdf": "https://arxiv.org/pdf/2505.04575", "abs": "https://arxiv.org/abs/2505.04575", "authors": ["Kunlun Xu", "Xu Zou", "Gang Hua", "Jiahuan Zhou"], "title": "Componential Prompt-Knowledge Alignment for Domain Incremental Learning", "categories": ["cs.CV", "cs.LG"], "comment": "Accpted by ICML2025", "summary": "Domain Incremental Learning (DIL) aims to learn from non-stationary data\nstreams across domains while retaining and utilizing past knowledge. Although\nprompt-based methods effectively store multi-domain knowledge in prompt\nparameters and obtain advanced performance through cross-domain prompt fusion,\nwe reveal an intrinsic limitation: component-wise misalignment between\ndomain-specific prompts leads to conflicting knowledge integration and degraded\npredictions. This arises from the random positioning of knowledge components\nwithin prompts, where irrelevant component fusion introduces interference.To\naddress this, we propose Componential Prompt-Knowledge Alignment (KA-Prompt), a\nnovel prompt-based DIL method that introduces component-aware prompt-knowledge\nalignment during training, significantly improving both the learning and\ninference capacity of the model. KA-Prompt operates in two phases: (1) Initial\nComponential Structure Configuring, where a set of old prompts containing\nknowledge relevant to the new domain are mined via greedy search, which is then\nexploited to initialize new prompts to achieve reusable knowledge transfer and\nestablish intrinsic alignment between new and old prompts. (2) Online Alignment\nPreservation, which dynamically identifies the target old prompts and applies\nadaptive componential consistency constraints as new prompts evolve. Extensive\nexperiments on DIL benchmarks demonstrate the effectiveness of our KA-Prompt.\nOur source code is available at\nhttps://github.com/zhoujiahuan1991/ICML2025-KA-Prompt", "AI": {"tldr": "KA-Prompt addresses misalignment in domain-specific prompts for Domain Incremental Learning (DIL) by introducing componential alignment, improving model performance.", "motivation": "Random positioning of knowledge components in prompts causes conflicting integration and degraded predictions, necessitating alignment.", "method": "KA-Prompt uses componential alignment in two phases: initial structure configuration and online alignment preservation.", "result": "Extensive experiments show KA-Prompt improves learning and inference capacity in DIL benchmarks.", "conclusion": "KA-Prompt effectively aligns domain-specific prompts, enhancing knowledge transfer and model performance."}}
{"id": "2505.04223", "pdf": "https://arxiv.org/pdf/2505.04223", "abs": "https://arxiv.org/abs/2505.04223", "authors": ["Sanghyeon Park", "Soo-Mook Moon"], "title": "FRAIN to Train: A Fast-and-Reliable Solution for Decentralized Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated learning (FL) enables collaborative model training across\ndistributed clients while preserving data locality. Although FedAvg pioneered\nsynchronous rounds for global model averaging, slower devices can delay\ncollective progress. Asynchronous FL (e.g., FedAsync) addresses stragglers by\ncontinuously integrating client updates, yet naive implementations risk client\ndrift due to non-IID data and stale contributions. Some Blockchain-based FL\napproaches (e.g., BRAIN) employ robust weighting or scoring of updates to\nresist malicious or misaligned proposals. However, performance drops can still\npersist under severe data heterogeneity or high staleness, and synchronization\noverhead has emerged as a new concern due to its aggregator-free architectures.\n  We introduce Fast-and-Reliable AI Network, FRAIN, a new asynchronous FL\nmethod that mitigates these limitations by incorporating two key ideas. First,\nour FastSync strategy eliminates the need to replay past model versions,\nenabling newcomers and infrequent participants to efficiently approximate the\nglobal model. Second, we adopt spherical linear interpolation (SLERP) when\nmerging parameters, preserving models' directions and alleviating destructive\ninterference from divergent local training.\n  Experiments with a CNN image-classification model and a Transformer-based\nlanguage model demonstrate that FRAIN achieves more stable and robust\nconvergence than FedAvg, FedAsync, and BRAIN, especially under harsh\nenvironments: non-IID data distributions, networks that experience delays and\nrequire frequent re-synchronization, and the presence of malicious nodes.", "AI": {"tldr": "FRAIN introduces FastSync and SLERP to improve asynchronous federated learning, outperforming FedAvg, FedAsync, and BRAIN in stability and robustness under challenging conditions.", "motivation": "Addressing limitations in existing FL methods like client drift, performance drops under data heterogeneity, and synchronization overhead.", "method": "FRAIN uses FastSync for efficient global model approximation and SLERP for parameter merging to preserve model directions.", "result": "FRAIN achieves more stable and robust convergence than FedAvg, FedAsync, and BRAIN, especially in harsh environments.", "conclusion": "FRAIN effectively mitigates issues in asynchronous FL, offering improved performance under non-IID data, delays, and malicious nodes."}}
{"id": "2505.04193", "pdf": "https://arxiv.org/pdf/2505.04193", "abs": "https://arxiv.org/abs/2505.04193", "authors": ["Bang You", "Chenxu Wang", "Huaping Liu"], "title": "Trajectory Entropy Reinforcement Learning for Predictable and Robust Control", "categories": ["cs.LG", "cs.RO"], "comment": "10 pages", "summary": "Simplicity is a critical inductive bias for designing data-driven\ncontrollers, especially when robustness is important. Despite the impressive\nresults of deep reinforcement learning in complex control tasks, it is prone to\ncapturing intricate and spurious correlations between observations and actions,\nleading to failure under slight perturbations to the environment. To tackle\nthis problem, in this work we introduce a novel inductive bias towards simple\npolicies in reinforcement learning. The simplicity inductive bias is introduced\nby minimizing the entropy of entire action trajectories, corresponding to the\nnumber of bits required to describe information in action trajectories after\nthe agent observes state trajectories. Our reinforcement learning agent,\nTrajectory Entropy Reinforcement Learning, is optimized to minimize the\ntrajectory entropy while maximizing rewards. We show that the trajectory\nentropy can be effectively estimated by learning a variational parameterized\naction prediction model, and use the prediction model to construct an\ninformation-regularized reward function. Furthermore, we construct a practical\nalgorithm that enables the joint optimization of models, including the policy\nand the prediction model. Experimental evaluations on several high-dimensional\nlocomotion tasks show that our learned policies produce more cyclical and\nconsistent action trajectories, and achieve superior performance, and\nrobustness to noise and dynamic changes than the state-of-the-art.", "AI": {"tldr": "The paper introduces a simplicity inductive bias in reinforcement learning by minimizing action trajectory entropy, leading to more robust and consistent policies.", "motivation": "Deep reinforcement learning often captures spurious correlations, failing under perturbations. Simplicity is proposed as a solution for robustness.", "method": "Minimizes trajectory entropy (bits to describe actions after observing states) using a variational action prediction model and an information-regularized reward function.", "result": "Policies show cyclical, consistent action trajectories, outperforming state-of-the-art in robustness and performance.", "conclusion": "Trajectory entropy minimization enhances policy simplicity and robustness, validated in high-dimensional tasks."}}
{"id": "2505.04586", "pdf": "https://arxiv.org/pdf/2505.04586", "abs": "https://arxiv.org/abs/2505.04586", "authors": ["Yuning Du", "Jingshuai Liu", "Rohan Dharmakumar", "Sotirios A. Tsaftaris"], "title": "Active Sampling for MRI-based Sequential Decision Making", "categories": ["cs.CV", "cs.LG"], "comment": "Under Review", "summary": "Despite the superior diagnostic capability of Magnetic Resonance Imaging\n(MRI), its use as a Point-of-Care (PoC) device remains limited by high cost and\ncomplexity. To enable such a future by reducing the magnetic field strength,\none key approach will be to improve sampling strategies. Previous work has\nshown that it is possible to make diagnostic decisions directly from k-space\nwith fewer samples. Such work shows that single diagnostic decisions can be\nmade, but if we aspire to see MRI as a true PoC, multiple and sequential\ndecisions are necessary while minimizing the number of samples acquired. We\npresent a novel multi-objective reinforcement learning framework enabling\ncomprehensive, sequential, diagnostic evaluation from undersampled k-space\ndata. Our approach during inference actively adapts to sequential decisions to\noptimally sample. To achieve this, we introduce a training methodology that\nidentifies the samples that contribute the best to each diagnostic objective\nusing a step-wise weighting reward function. We evaluate our approach in two\nsequential knee pathology assessment tasks: ACL sprain detection and cartilage\nthickness loss assessment. Our framework achieves diagnostic performance\ncompetitive with various policy-based benchmarks on disease detection, severity\nquantification, and overall sequential diagnosis, while substantially saving\nk-space samples. Our approach paves the way for the future of MRI as a\ncomprehensive and affordable PoC device. Our code is publicly available at\nhttps://github.com/vios-s/MRI_Sequential_Active_Sampling", "AI": {"tldr": "A reinforcement learning framework improves MRI sampling for sequential diagnostic decisions, enabling affordable Point-of-Care MRI.", "motivation": "To make MRI affordable and usable as a Point-of-Care device by reducing sampling complexity and cost.", "method": "Multi-objective reinforcement learning adaptively optimizes k-space sampling for sequential diagnostic tasks.", "result": "Competitive diagnostic performance with fewer samples in ACL sprain and cartilage thickness loss assessments.", "conclusion": "The framework advances MRI towards comprehensive, affordable PoC use."}}
{"id": "2505.04260", "pdf": "https://arxiv.org/pdf/2505.04260", "abs": "https://arxiv.org/abs/2505.04260", "authors": ["Jessica Y. Bo", "Tianyu Xu", "Ishan Chatterjee", "Katrina Passarella-Ward", "Achin Kulshrestha", "D Shin"], "title": "Steerable Chatbots: Personalizing LLMs with Preference-Based Activation Steering", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "As large language models (LLMs) improve in their capacity to serve as\npersonal AI assistants, their ability to output uniquely tailored, personalized\nresponses that align with the soft preferences of their users is essential for\nenhancing user satisfaction and retention. However, untrained lay users have\npoor prompt specification abilities and often struggle with conveying their\nlatent preferences to AI assistants. To address this, we leverage activation\nsteering to guide LLMs to align with interpretable preference dimensions during\ninference. In contrast to memory-based personalization methods that require\nlonger user history, steering is extremely lightweight and can be easily\ncontrolled by the user via an linear strength factor. We embed steering into\nthree different interactive chatbot interfaces and conduct a within-subjects\nuser study (n=14) to investigate how end users prefer to personalize their\nconversations. The results demonstrate the effectiveness of preference-based\nsteering for aligning real-world conversations with hidden user preferences,\nand highlight further insights on how diverse values around control, usability,\nand transparency lead users to prefer different interfaces.", "AI": {"tldr": "The paper introduces activation steering to help LLMs align with user preferences, offering a lightweight alternative to memory-based methods. User studies show its effectiveness and interface preferences.", "motivation": "Enhancing user satisfaction with AI assistants by addressing poor prompt specification and latent preference communication.", "method": "Leveraging activation steering for preference alignment during inference, tested via three chatbot interfaces in a user study (n=14).", "result": "Effective alignment of conversations with hidden preferences; diverse user preferences for interfaces based on control, usability, and transparency.", "conclusion": "Preference-based steering is effective and adaptable, with interface design impacting user satisfaction."}}
{"id": "2505.04200", "pdf": "https://arxiv.org/pdf/2505.04200", "abs": "https://arxiv.org/abs/2505.04200", "authors": ["Ahmed Sayeed Faruk", "Jason Sulskis", "Elena Zheleva"], "title": "Estimating Causal Effects in Networks with Cluster-Based Bandits", "categories": ["cs.LG", "cs.SI"], "comment": "Presented at the AAAI 2022 Workshop on Artificial Intelligence for\n  Behavioral Change (AI4BC)", "summary": "The gold standard for estimating causal effects is randomized controlled\ntrial (RCT) or A/B testing where a random group of individuals from a\npopulation of interest are given treatment and the outcome is compared to a\nrandom group of individuals from the same population. However, A/B testing is\nchallenging in the presence of interference, commonly occurring in social\nnetworks, where individuals can impact each others outcome. Moreover, A/B\ntesting can incur a high performance loss when one of the treatment arms has a\npoor performance and the test continues to treat individuals with it.\nTherefore, it is important to design a strategy that can adapt over time and\nefficiently learn the total treatment effect in the network. We introduce two\ncluster-based multi-armed bandit (MAB) algorithms to gradually estimate the\ntotal treatment effect in a network while maximizing the expected reward by\nmaking a tradeoff between exploration and exploitation. We compare the\nperformance of our MAB algorithms with a vanilla MAB algorithm that ignores\nclusters and the corresponding RCT methods on semi-synthetic data with\nsimulated interference. The vanilla MAB algorithm shows higher reward-action\nratio at the cost of higher treatment effect error due to undesired spillover.\nThe cluster-based MAB algorithms show higher reward-action ratio compared to\ntheir corresponding RCT methods without sacrificing much accuracy in treatment\neffect estimation.", "AI": {"tldr": "The paper introduces cluster-based MAB algorithms to estimate treatment effects in networks with interference, outperforming vanilla MAB and RCT methods by balancing exploration-exploitation tradeoffs.", "motivation": "A/B testing faces challenges like interference in social networks and performance loss, necessitating adaptive strategies for accurate treatment effect estimation.", "method": "Two cluster-based MAB algorithms are proposed to learn total treatment effects while maximizing rewards, compared against vanilla MAB and RCT methods on semi-synthetic data.", "result": "Cluster-based MABs achieve higher reward-action ratios than RCT methods without significant accuracy loss, while vanilla MABs suffer from spillover errors.", "conclusion": "Cluster-based MABs offer an efficient alternative to RCTs for treatment effect estimation in networks with interference, balancing reward and accuracy."}}
{"id": "2505.04594", "pdf": "https://arxiv.org/pdf/2505.04594", "abs": "https://arxiv.org/abs/2505.04594", "authors": ["Zhihao Zhang", "Abhinav Kumar", "Girish Chandar Ganesan", "Xiaoming Liu"], "title": "MonoCoP: Chain-of-Prediction for Monocular 3D Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Accurately predicting 3D attributes is crucial for monocular 3D object\ndetection (Mono3D), with depth estimation posing the greatest challenge due to\nthe inherent ambiguity in mapping 2D images to 3D space. While existing methods\nleverage multiple depth cues (e.g., estimating depth uncertainty, modeling\ndepth error) to improve depth accuracy, they overlook that accurate depth\nprediction requires conditioning on other 3D attributes, as these attributes\nare intrinsically inter-correlated through the 3D to 2D projection, which\nultimately limits overall accuracy and stability. Inspired by Chain-of-Thought\n(CoT) in large language models (LLMs), this paper proposes MonoCoP, which\nleverages a Chain-of-Prediction (CoP) to predict attributes sequentially and\nconditionally via three key designs. First, it employs a lightweight\nAttributeNet (AN) for each 3D attribute to learn attribute-specific features.\nNext, MonoCoP constructs an explicit chain to propagate these learned features\nfrom one attribute to the next. Finally, MonoCoP uses a residual connection to\naggregate features for each attribute along the chain, ensuring that later\nattribute predictions are conditioned on all previously processed attributes\nwithout forgetting the features of earlier ones. Experimental results show that\nour MonoCoP achieves state-of-the-art (SoTA) performance on the KITTI\nleaderboard without requiring additional data and further surpasses existing\nmethods on the Waymo and nuScenes frontal datasets.", "AI": {"tldr": "MonoCoP improves monocular 3D object detection by sequentially predicting 3D attributes using a Chain-of-Prediction approach, achieving state-of-the-art results.", "motivation": "Existing methods overlook the inter-correlation of 3D attributes, limiting accuracy. MonoCoP addresses this by conditioning predictions on prior attributes.", "method": "Uses AttributeNet for feature learning, constructs a Chain-of-Prediction for sequential feature propagation, and employs residual connections to retain earlier features.", "result": "Achieves SoTA on KITTI and outperforms methods on Waymo and nuScenes datasets.", "conclusion": "MonoCoP demonstrates the effectiveness of sequential and conditional attribute prediction for improving monocular 3D detection."}}
{"id": "2505.04265", "pdf": "https://arxiv.org/pdf/2505.04265", "abs": "https://arxiv.org/abs/2505.04265", "authors": ["Abdulrahman S Almuhaidib", "Azlan Mohd Zain", "Zalmiyah Zakaria", "Izyan Izzati Kamsani", "Abdulaziz S Almuhaidib"], "title": "Weaponizing Language Models for Cybersecurity Offensive Operations: Automating Vulnerability Assessment Report Validation; A Review Paper", "categories": ["cs.CR", "cs.AI"], "comment": "Pre-print - Accepted for publication in the Proceedings of the\n  International Computer Sciences and Informatics Conference (ICSIC-2024),\n  published by AIP Publishing", "summary": "This, with the ever-increasing sophistication of cyberwar, calls for novel\nsolutions. In this regard, Large Language Models (LLMs) have emerged as a\nhighly promising tool for defensive and offensive cybersecurity-related\nstrategies. While existing literature has focused much on the defensive use of\nLLMs, when it comes to their offensive utilization, very little has been\nreported-namely, concerning Vulnerability Assessment (VA) report validation.\nConsequentially, this paper tries to fill that gap by investigating the\ncapabilities of LLMs in automating and improving the validation process of the\nreport of the VA. From the critical review of the related literature, this\npaper hereby proposes a new approach to using the LLMs in the automation of the\nanalysis and within the validation process of the report of the VA that could\npotentially reduce the number of false positives and generally enhance\nefficiency. These results are promising for LLM automatization for improving\nvalidation on reports coming from VA in order to improve accuracy while\nreducing human effort and security postures. The contribution of this paper\nprovides further evidence about the offensive and defensive LLM capabilities\nand therefor helps in devising more appropriate cybersecurity strategies and\ntools accordingly.", "AI": {"tldr": "The paper explores using Large Language Models (LLMs) to automate and improve Vulnerability Assessment (VA) report validation, addressing a gap in offensive cybersecurity applications.", "motivation": "The increasing complexity of cyberwar necessitates innovative solutions, with LLMs showing promise for both defensive and offensive cybersecurity strategies.", "method": "The paper proposes a novel approach using LLMs to automate VA report analysis and validation, aiming to reduce false positives and enhance efficiency.", "result": "Results indicate LLMs can improve VA report validation accuracy while reducing human effort and strengthening security postures.", "conclusion": "The study highlights LLMs' offensive and defensive cybersecurity potential, aiding in better strategy and tool development."}}
{"id": "2505.04204", "pdf": "https://arxiv.org/pdf/2505.04204", "abs": "https://arxiv.org/abs/2505.04204", "authors": ["Mateo Lopez-Ledezma", "Gissel Velarde"], "title": "Cyber Security Data Science: Machine Learning Methods and their Performance on Imbalanced Datasets", "categories": ["cs.LG"], "comment": "13 pages, 5 figures. Digital Management and Artificial Intelligence.\n  Proceedings of the Fourth International Scientific-Practical Conference (ISPC\n  2024), Hybrid, October 10-11, 2024.\n  https://link.springer.com/chapter/10.1007/978-3-031-88052-0_45", "summary": "Cybersecurity has become essential worldwide and at all levels, concerning\nindividuals, institutions, and governments. A basic principle in cybersecurity\nis to be always alert. Therefore, automation is imperative in processes where\nthe volume of daily operations is large. Several cybersecurity applications can\nbe addressed as binary classification problems, including anomaly detection,\nfraud detection, intrusion detection, spam detection, or malware detection. We\npresent three experiments. In the first experiment, we evaluate single\nclassifiers including Random Forests, Light Gradient Boosting Machine, eXtreme\nGradient Boosting, Logistic Regression, Decision Tree, and Gradient Boosting\nDecision Tree. In the second experiment, we test different sampling techniques\nincluding over-sampling, under-sampling, Synthetic Minority Over-sampling\nTechnique, and Self-Paced Ensembling. In the last experiment, we evaluate\nSelf-Paced Ensembling and its number of base classifiers. We found that\nimbalance learning techniques had positive and negative effects, as reported in\nrelated studies. Thus, these techniques should be applied with caution.\nBesides, we found different best performers for each dataset. Therefore, we\nrecommend testing single classifiers and imbalance learning techniques for each\nnew dataset and application involving imbalanced datasets as is the case in\nseveral cyber security applications.", "AI": {"tldr": "The paper explores binary classification in cybersecurity, testing single classifiers and imbalance learning techniques, emphasizing the need for tailored approaches for each dataset.", "motivation": "Cybersecurity requires automation due to large operational volumes, with many tasks framed as binary classification problems.", "method": "Three experiments: evaluating single classifiers, testing sampling techniques, and assessing Self-Paced Ensembling with varying base classifiers.", "result": "Imbalance learning techniques had mixed effects; best performers varied by dataset, highlighting the need for dataset-specific testing.", "conclusion": "Tailored testing of classifiers and imbalance techniques is recommended for cybersecurity applications with imbalanced datasets."}}
{"id": "2505.04601", "pdf": "https://arxiv.org/pdf/2505.04601", "abs": "https://arxiv.org/abs/2505.04601", "authors": ["Xianhang Li", "Yanqing Liu", "Haoqin Tu", "Hongru Zhu", "Cihang Xie"], "title": "OpenVision: A Fully-Open, Cost-Effective Family of Advanced Vision Encoders for Multimodal Learning", "categories": ["cs.CV"], "comment": null, "summary": "OpenAI's CLIP, released in early 2021, have long been the go-to choice of\nvision encoder for building multimodal foundation models. Although recent\nalternatives such as SigLIP have begun to challenge this status quo, to our\nknowledge none are fully open: their training data remains proprietary and/or\ntheir training recipes are not released. This paper fills this gap with\nOpenVision, a fully-open, cost-effective family of vision encoders that match\nor surpass the performance of OpenAI's CLIP when integrated into multimodal\nframeworks like LLaVA. OpenVision builds on existing works -- e.g., CLIPS for\ntraining framework and Recap-DataComp-1B for training data -- while revealing\nmultiple key insights in enhancing encoder quality and showcasing practical\nbenefits in advancing multimodal models. By releasing vision encoders spanning\nfrom 5.9M to 632.1M parameters, OpenVision offers practitioners a flexible\ntrade-off between capacity and efficiency in building multimodal models: larger\nmodels deliver enhanced multimodal performance, while smaller versions enable\nlightweight, edge-ready multimodal deployments.", "AI": {"tldr": "OpenVision is a fully-open, cost-effective family of vision encoders that outperform or match OpenAI's CLIP, offering flexible trade-offs between capacity and efficiency for multimodal models.", "motivation": "To address the lack of fully open alternatives to CLIP, OpenVision provides transparent training data and recipes, filling a gap in the field.", "method": "OpenVision builds on existing frameworks like CLIPS and Recap-DataComp-1B, incorporating key insights to enhance encoder quality.", "result": "OpenVision models (5.9M to 632.1M parameters) match or surpass CLIP's performance in multimodal frameworks like LLaVA, offering scalability.", "conclusion": "OpenVision advances multimodal models by providing open, scalable, and efficient vision encoders, benefiting both research and practical deployments."}}
{"id": "2505.04278", "pdf": "https://arxiv.org/pdf/2505.04278", "abs": "https://arxiv.org/abs/2505.04278", "authors": ["Weiwei Ye", "Zhuopeng Xu", "Ning Gui"], "title": "Non-stationary Diffusion For Probabilistic Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted as spotlight poster at ICML", "summary": "Due to the dynamics of underlying physics and external influences, the\nuncertainty of time series often varies over time. However, existing Denoising\nDiffusion Probabilistic Models (DDPMs) often fail to capture this\nnon-stationary nature, constrained by their constant variance assumption from\nthe additive noise model (ANM). In this paper, we innovatively utilize the\nLocation-Scale Noise Model (LSNM) to relax the fixed uncertainty assumption of\nANM. A diffusion-based probabilistic forecasting framework, termed\nNon-stationary Diffusion (NsDiff), is designed based on LSNM that is capable of\nmodeling the changing pattern of uncertainty. Specifically, NsDiff combines a\ndenoising diffusion-based conditional generative model with a pre-trained\nconditional mean and variance estimator, enabling adaptive endpoint\ndistribution modeling. Furthermore, we propose an uncertainty-aware noise\nschedule, which dynamically adjusts the noise levels to accurately reflect the\ndata uncertainty at each step and integrates the time-varying variances into\nthe diffusion process. Extensive experiments conducted on nine real-world and\nsynthetic datasets demonstrate the superior performance of NsDiff compared to\nexisting approaches. Code is available at https://github.com/wwy155/NsDiff.", "AI": {"tldr": "NsDiff introduces a diffusion-based framework using LSNM to model time-varying uncertainty in time series, outperforming existing methods.", "motivation": "Existing DDPMs fail to capture non-stationary uncertainty due to fixed variance assumptions.", "method": "NsDiff combines a diffusion-based generative model with a pre-trained estimator and an uncertainty-aware noise schedule.", "result": "Experiments on nine datasets show NsDiff's superior performance.", "conclusion": "NsDiff effectively models changing uncertainty, advancing probabilistic forecasting."}}
{"id": "2505.04241", "pdf": "https://arxiv.org/pdf/2505.04241", "abs": "https://arxiv.org/abs/2505.04241", "authors": ["Grzegorz Miebs", "Rafa\u0142 A. Bachorz"], "title": "Technology prediction of a 3D model using Neural Network", "categories": ["cs.LG", "I.2.10"], "comment": "5 pages, 2 figures", "summary": "Accurate estimation of production times is critical for effective\nmanufacturing scheduling, yet traditional methods relying on expert analysis or\nhistorical data often fall short in dynamic or customized production\nenvironments. This paper introduces a data-driven approach that predicts\nmanufacturing steps and their durations directly from a product's 3D model. By\nrendering the model into multiple 2D images and leveraging a neural network\ninspired by the Generative Query Network, the method learns to map geometric\nfeatures into time estimates for predefined production steps enabling scalable,\nadaptive, and precise process planning across varied product types.", "AI": {"tldr": "A data-driven method predicts manufacturing steps and durations from 3D models using neural networks for scalable and precise scheduling.", "motivation": "Traditional methods for estimating production times are inadequate in dynamic or customized environments, necessitating a more adaptive approach.", "method": "The approach renders 3D models into 2D images and uses a neural network (inspired by Generative Query Network) to map geometric features to time estimates for production steps.", "result": "The method enables scalable, adaptive, and precise process planning across diverse product types.", "conclusion": "This data-driven approach improves manufacturing scheduling accuracy in dynamic or customized production settings."}}
{"id": "2505.04612", "pdf": "https://arxiv.org/pdf/2505.04612", "abs": "https://arxiv.org/abs/2505.04612", "authors": ["Jiahao Li", "Haochen Wang", "Muhammad Zubair Irshad", "Igor Vasiljevic", "Matthew R. Walter", "Vitor Campagnolo Guizilini", "Greg Shakhnarovich"], "title": "FastMap: Revisiting Dense and Scalable Structure from Motion", "categories": ["cs.CV"], "comment": "Project webpage: https://jiahao.ai/fastmap", "summary": "We propose FastMap, a new global structure from motion method focused on\nspeed and simplicity. Previous methods like COLMAP and GLOMAP are able to\nestimate high-precision camera poses, but suffer from poor scalability when the\nnumber of matched keypoint pairs becomes large. We identify two key factors\nleading to this problem: poor parallelization and computationally expensive\noptimization steps. To overcome these issues, we design an SfM framework that\nrelies entirely on GPU-friendly operations, making it easily parallelizable.\nMoreover, each optimization step runs in time linear to the number of image\npairs, independent of keypoint pairs or 3D points. Through extensive\nexperiments, we show that FastMap is one to two orders of magnitude faster than\nCOLMAP and GLOMAP on large-scale scenes with comparable pose accuracy.", "AI": {"tldr": "FastMap is a fast, GPU-friendly SfM method that outperforms COLMAP and GLOMAP in speed while maintaining pose accuracy.", "motivation": "Existing methods like COLMAP and GLOMAP are slow due to poor parallelization and expensive optimization steps.", "method": "FastMap uses GPU-friendly operations for easy parallelization and linear-time optimization steps.", "result": "FastMap is 10-100x faster than COLMAP and GLOMAP with comparable accuracy.", "conclusion": "FastMap offers a scalable and efficient solution for large-scale SfM tasks."}}
{"id": "2505.04300", "pdf": "https://arxiv.org/pdf/2505.04300", "abs": "https://arxiv.org/abs/2505.04300", "authors": ["Isabella Caranzano", "Corrado Pancotti", "Cesare Rollo", "Flavio Sartori", "Pietro Li\u00f2", "Piero Fariselli", "Tiziana Sanavia"], "title": "Sparsity is All You Need: Rethinking Biological Pathway-Informed Approaches in Deep Learning", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": null, "summary": "Biologically-informed neural networks typically leverage pathway annotations\nto enhance performance in biomedical applications. We hypothesized that the\nbenefits of pathway integration does not arise from its biological relevance,\nbut rather from the sparsity it introduces. We conducted a comprehensive\nanalysis of all relevant pathway-based neural network models for predictive\ntasks, critically evaluating each study's contributions. From this review, we\ncurated a subset of methods for which the source code was publicly available.\nThe comparison of the biologically informed state-of-the-art deep learning\nmodels and their randomized counterparts showed that models based on randomized\ninformation performed equally well as biologically informed ones across\ndifferent metrics and datasets. Notably, in 3 out of the 15 analyzed models,\nthe randomized versions even outperformed their biologically informed\ncounterparts. Moreover, pathway-informed models did not show any clear\nadvantage in interpretability, as randomized models were still able to identify\nrelevant disease biomarkers despite lacking explicit pathway information. Our\nfindings suggest that pathway annotations may be too noisy or inadequately\nexplored by current methods. Therefore, we propose a methodology that can be\napplied to different domains and can serve as a robust benchmark for\nsystematically comparing novel pathway-informed models against their randomized\ncounterparts. This approach enables researchers to rigorously determine whether\nobserved performance improvements can be attributed to biological insights.", "AI": {"tldr": "Pathway-informed neural networks perform no better than randomized versions, suggesting biological relevance may not be the key factor.", "motivation": "To test if pathway integration's benefits stem from biological relevance or introduced sparsity.", "method": "Comprehensive analysis of pathway-based neural networks, comparing biologically informed models with randomized counterparts.", "result": "Randomized models matched or outperformed biologically informed ones in performance and interpretability.", "conclusion": "Pathway annotations may be noisy; proposed a benchmark to rigorously evaluate biological insights in models."}}
{"id": "2505.04263", "pdf": "https://arxiv.org/pdf/2505.04263", "abs": "https://arxiv.org/abs/2505.04263", "authors": ["Jan Blechschmidt", "Tom-Christian Riemer", "Max Winkler", "Martin Stoll", "Jan-F. Pietschmann"], "title": "Physics-Informed DeepONets for drift-diffusion on metric graphs: simulation and parameter identification", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "We develop a novel physics informed deep learning approach for solving\nnonlinear drift-diffusion equations on metric graphs. These models represent an\nimportant model class with a large number of applications in areas ranging from\ntransport in biological cells to the motion of human crowds. While traditional\nnumerical schemes require a large amount of tailoring, especially in the case\nof model design or parameter identification problems, physics informed deep\noperator networks (DeepONet) have emerged as a versatile tool for the solution\nof partial differential equations with the particular advantage that they\neasily incorporate parameter identification questions. We here present an\napproach where we first learn three DeepONet models for representative inflow,\ninner and outflow edges, resp., and then subsequently couple these models for\nthe solution of the drift-diffusion metric graph problem by relying on an\nedge-based domain decomposition approach. We illustrate that our framework is\napplicable for the accurate evaluation of graph-coupled physics models and is\nwell suited for solving optimization or inverse problems on these coupled\nnetworks.", "AI": {"tldr": "A novel physics-informed deep learning method using DeepONet solves nonlinear drift-diffusion equations on metric graphs, applicable to diverse fields like biology and crowd dynamics.", "motivation": "Traditional numerical methods are inflexible for model design and parameter identification in drift-diffusion equations, prompting the need for a versatile deep learning approach.", "method": "Three DeepONet models are trained for inflow, inner, and outflow edges, then coupled via edge-based domain decomposition to solve the drift-diffusion problem.", "result": "The framework accurately evaluates graph-coupled physics models and is effective for optimization or inverse problems on such networks.", "conclusion": "The approach is versatile and efficient for solving complex drift-diffusion equations on metric graphs, with potential for broader applications."}}
{"id": "2505.04616", "pdf": "https://arxiv.org/pdf/2505.04616", "abs": "https://arxiv.org/abs/2505.04616", "authors": ["Feng Liu", "Nicholas Chimitt", "Lanqing Guo", "Jitesh Jain", "Aditya Kane", "Minchul Kim", "Wes Robbins", "Yiyang Su", "Dingqiang Ye", "Xingguang Zhang", "Jie Zhu", "Siddharth Satyakam", "Christopher Perry", "Stanley H. Chan", "Arun Ross", "Humphrey Shi", "Zhangyang Wang", "Anil Jain", "Xiaoming Liu"], "title": "Person Recognition at Altitude and Range: Fusion of Face, Body Shape and Gait", "categories": ["cs.CV"], "comment": "18 pages, 12 figures", "summary": "We address the problem of whole-body person recognition in unconstrained\nenvironments. This problem arises in surveillance scenarios such as those in\nthe IARPA Biometric Recognition and Identification at Altitude and Range\n(BRIAR) program, where biometric data is captured at long standoff distances,\nelevated viewing angles, and under adverse atmospheric conditions (e.g.,\nturbulence and high wind velocity). To this end, we propose FarSight, a unified\nend-to-end system for person recognition that integrates complementary\nbiometric cues across face, gait, and body shape modalities. FarSight\nincorporates novel algorithms across four core modules: multi-subject detection\nand tracking, recognition-aware video restoration, modality-specific biometric\nfeature encoding, and quality-guided multi-modal fusion. These components are\ndesigned to work cohesively under degraded image conditions, large pose and\nscale variations, and cross-domain gaps. Extensive experiments on the BRIAR\ndataset, one of the most comprehensive benchmarks for long-range, multi-modal\nbiometric recognition, demonstrate the effectiveness of FarSight. Compared to\nour preliminary system, this system achieves a 34.1% absolute gain in 1:1\nverification accuracy (TAR@0.1% FAR), a 17.8% increase in closed-set\nidentification (Rank-20), and a 34.3% reduction in open-set identification\nerrors (FNIR@1% FPIR). Furthermore, FarSight was evaluated in the 2025 NIST RTE\nFace in Video Evaluation (FIVE), which conducts standardized face recognition\ntesting on the BRIAR dataset. These results establish FarSight as a\nstate-of-the-art solution for operational biometric recognition in challenging\nreal-world conditions.", "AI": {"tldr": "FarSight is an end-to-end system for whole-body person recognition in challenging environments, integrating face, gait, and body shape cues. It outperforms prior methods with significant accuracy gains.", "motivation": "The need for reliable biometric recognition in unconstrained, long-range surveillance scenarios with degraded conditions.", "method": "FarSight combines multi-subject detection, video restoration, biometric feature encoding, and quality-guided fusion across modalities.", "result": "Achieves 34.1% higher verification accuracy, 17.8% better identification, and 34.3% fewer errors in open-set tasks.", "conclusion": "FarSight is a state-of-the-art solution for operational biometric recognition in real-world challenges."}}
{"id": "2505.04308", "pdf": "https://arxiv.org/pdf/2505.04308", "abs": "https://arxiv.org/abs/2505.04308", "authors": ["Md Saiful Islam", "Li Xiangdong"], "title": "Guardians of the Web: The Evolution and Future of Website Information Security", "categories": ["cs.CR", "cs.AI", "F.2.2, I.2.7"], "comment": "22 pages", "summary": "Website information security has become a critical concern in the digital\nage. This article explores the evolution of website information security,\nexamining its historical development, current practices, and future directions.\nThe early beginnings from the 1960s to the 1980s laid the groundwork for modern\ncybersecurity, with the development of ARPANET, TCP/IP, public-key\ncryptography, and the first antivirus programs. The 1990s marked a\ntransformative era, driven by the commercialization of the Internet and the\nemergence of web-based services. As the Internet grew, so did the range and\nsophistication of cyber threats, leading to advancements in security\ntechnologies such as the Secure Sockets Layer (SSL) protocol, password\nprotection, and firewalls. Current practices in website information security\ninvolve a multi-layered approach, including encryption, secure coding\npractices, regular security audits, and user education. The future of website\ninformation security is expected to be shaped by emerging technologies such as\nartificial intelligence, blockchain, and quantum computing, as well as the\nincreasing importance of international cooperation and standardization efforts.\nAs cyber threats continue to evolve, ongoing research and innovation in website\ninformation security will be essential to protect sensitive information and\nmaintain trust in the digital world.", "AI": {"tldr": "The paper traces the evolution of website information security from its early beginnings to current practices and future trends, emphasizing the need for ongoing innovation to combat evolving cyber threats.", "motivation": "To understand the historical development, current state, and future directions of website information security to address growing cyber threats.", "method": "Examines historical milestones, current security practices, and emerging technologies shaping the future of website security.", "result": "Highlights advancements like SSL, encryption, and AI, while stressing the importance of international cooperation and standardization.", "conclusion": "Ongoing research and innovation are crucial to safeguard sensitive information and maintain digital trust."}}
{"id": "2505.04335", "pdf": "https://arxiv.org/pdf/2505.04335", "abs": "https://arxiv.org/abs/2505.04335", "authors": ["Swagato Das", "Arghya Pratihar", "Swagatam Das"], "title": "Hyperbolic Fuzzy $C$-Means with Adaptive Weight-based Filtering for Clustering in Non-Euclidean Spaces", "categories": ["cs.LG"], "comment": null, "summary": "Clustering algorithms play a pivotal role in unsupervised learning by\nidentifying and grouping similar objects based on shared characteristics. While\ntraditional clustering techniques, such as hard and fuzzy center-based\nclustering, have been widely used, they struggle with complex,\nhigh-dimensional, and non-Euclidean datasets. In particular, the Fuzzy\n$C$-Means (FCM) algorithm, despite its efficiency and popularity, exhibits\nnotable limitations in non-Euclidean spaces. Euclidean spaces assume linear\nseparability and uniform distance scaling, limiting their effectiveness in\ncapturing complex, hierarchical, or non-Euclidean structures in fuzzy\nclustering. To overcome these challenges, we introduce Filtration-based\nHyperbolic Fuzzy $C$-Means (HypeFCM), a novel clustering algorithm tailored for\nbetter representation of data relationships in non-Euclidean spaces. HypeFCM\nintegrates the principles of fuzzy clustering with hyperbolic geometry and\nemploys a weight-based filtering mechanism to improve performance. The\nalgorithm initializes weights using a Dirichlet distribution and iteratively\nrefines cluster centroids and membership assignments based on a hyperbolic\nmetric in the Poincar\\'e Disc model. Extensive experimental evaluations\ndemonstrate that HypeFCM significantly outperforms conventional fuzzy\nclustering methods in non-Euclidean settings, underscoring its robustness and\neffectiveness.", "AI": {"tldr": "HypeFCM improves fuzzy clustering in non-Euclidean spaces using hyperbolic geometry and a weight-based filtering mechanism, outperforming traditional methods.", "motivation": "Traditional clustering methods like FCM struggle with complex, high-dimensional, and non-Euclidean datasets due to Euclidean space assumptions.", "method": "HypeFCM integrates fuzzy clustering with hyperbolic geometry (Poincar\u00e9 Disc model), initializes weights via Dirichlet distribution, and refines centroids iteratively.", "result": "HypeFCM significantly outperforms conventional fuzzy clustering in non-Euclidean settings.", "conclusion": "HypeFCM is robust and effective for clustering in non-Euclidean spaces, addressing limitations of traditional methods."}}
{"id": "2505.04620", "pdf": "https://arxiv.org/pdf/2505.04620", "abs": "https://arxiv.org/abs/2505.04620", "authors": ["Hao Fei", "Yuan Zhou", "Juncheng Li", "Xiangtai Li", "Qingshan Xu", "Bobo Li", "Shengqiong Wu", "Yaoting Wang", "Junbao Zhou", "Jiahao Meng", "Qingyu Shi", "Zhiyuan Zhou", "Liangtao Shi", "Minghe Gao", "Daoan Zhang", "Zhiqi Ge", "Weiming Wu", "Siliang Tang", "Kaihang Pan", "Yaobo Ye", "Haobo Yuan", "Tao Zhang", "Tianjie Ju", "Zixiang Meng", "Shilin Xu", "Liyu Jia", "Wentao Hu", "Meng Luo", "Jiebo Luo", "Tat-Seng Chua", "Shuicheng Yan", "Hanwang Zhang"], "title": "On Path to Multimodal Generalist: General-Level and General-Bench", "categories": ["cs.CV"], "comment": "ICML'25, 305 pages, 115 tables, 177 figures, project page:\n  https://generalist.top/", "summary": "The Multimodal Large Language Model (MLLM) is currently experiencing rapid\ngrowth, driven by the advanced capabilities of LLMs. Unlike earlier\nspecialists, existing MLLMs are evolving towards a Multimodal Generalist\nparadigm. Initially limited to understanding multiple modalities, these models\nhave advanced to not only comprehend but also generate across modalities. Their\ncapabilities have expanded from coarse-grained to fine-grained multimodal\nunderstanding and from supporting limited modalities to arbitrary ones. While\nmany benchmarks exist to assess MLLMs, a critical question arises: Can we\nsimply assume that higher performance across tasks indicates a stronger MLLM\ncapability, bringing us closer to human-level AI? We argue that the answer is\nnot as straightforward as it seems. This project introduces General-Level, an\nevaluation framework that defines 5-scale levels of MLLM performance and\ngenerality, offering a methodology to compare MLLMs and gauge the progress of\nexisting systems towards more robust multimodal generalists and, ultimately,\ntowards AGI. At the core of the framework is the concept of Synergy, which\nmeasures whether models maintain consistent capabilities across comprehension\nand generation, and across multiple modalities. To support this evaluation, we\npresent General-Bench, which encompasses a broader spectrum of skills,\nmodalities, formats, and capabilities, including over 700 tasks and 325,800\ninstances. The evaluation results that involve over 100 existing\nstate-of-the-art MLLMs uncover the capability rankings of generalists,\nhighlighting the challenges in reaching genuine AI. We expect this project to\npave the way for future research on next-generation multimodal foundation\nmodels, providing a robust infrastructure to accelerate the realization of AGI.\nProject page: https://generalist.top/", "AI": {"tldr": "The paper introduces General-Level, an evaluation framework for Multimodal Large Language Models (MLLMs), assessing their performance and generality across 5-scale levels. It challenges the assumption that higher task performance equals stronger MLLM capability, proposing Synergy as a core metric. The framework includes General-Bench, a comprehensive benchmark with 700 tasks and 325,800 instances, evaluating over 100 MLLMs.", "motivation": "To address the lack of a standardized evaluation framework for MLLMs, questioning whether higher task performance truly reflects stronger capability or progress toward human-level AI.", "method": "Introduces General-Level, a 5-scale evaluation framework, and General-Bench, a benchmark with diverse tasks and modalities. Synergy is used to measure consistency across comprehension, generation, and modalities.", "result": "Evaluation of 100+ MLLMs reveals capability rankings and challenges in achieving genuine AI. The framework highlights gaps in current models.", "conclusion": "The project aims to guide future research on multimodal foundation models, providing infrastructure to advance toward AGI."}}
{"id": "2505.04340", "pdf": "https://arxiv.org/pdf/2505.04340", "abs": "https://arxiv.org/abs/2505.04340", "authors": ["Hong Jin", "Kaicheng Zhou", "Jie Yin", "Lan You", "Zhifeng Zhou"], "title": "Multi-Granular Attention based Heterogeneous Hypergraph Neural Network", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Heterogeneous graph neural networks (HeteGNNs) have demonstrated strong\nabilities to learn node representations by effectively extracting complex\nstructural and semantic information in heterogeneous graphs. Most of the\nprevailing HeteGNNs follow the neighborhood aggregation paradigm, leveraging\nmeta-path based message passing to learn latent node representations. However,\ndue to the pairwise nature of meta-paths, these models fail to capture\nhigh-order relations among nodes, resulting in suboptimal performance.\nAdditionally, the challenge of ``over-squashing'', where long-range message\npassing in HeteGNNs leads to severe information distortion, further limits the\nefficacy of these models. To address these limitations, this paper proposes\nMGA-HHN, a Multi-Granular Attention based Heterogeneous Hypergraph Neural\nNetwork for heterogeneous graph representation learning. MGA-HHN introduces two\nkey innovations: (1) a novel approach for constructing meta-path based\nheterogeneous hypergraphs that explicitly models higher-order semantic\ninformation in heterogeneous graphs through multiple views, and (2) a\nmulti-granular attention mechanism that operates at both the node and hyperedge\nlevels. This mechanism enables the model to capture fine-grained interactions\namong nodes sharing the same semantic context within a hyperedge type, while\npreserving the diversity of semantics across different hyperedge types. As\nsuch, MGA-HHN effectively mitigates long-range message distortion and generates\nmore expressive node representations. Extensive experiments on real-world\nbenchmark datasets demonstrate that MGA-HHN outperforms state-of-the-art\nmodels, showcasing its effectiveness in node classification, node clustering\nand visualization tasks.", "AI": {"tldr": "MGA-HHN is a novel heterogeneous hypergraph neural network that addresses limitations of meta-path-based models by capturing high-order relations and mitigating over-squashing through multi-granular attention.", "motivation": "Existing HeteGNNs fail to capture high-order node relations and suffer from over-squashing, limiting their performance.", "method": "MGA-HHN constructs meta-path-based heterogeneous hypergraphs and employs a multi-granular attention mechanism at node and hyperedge levels.", "result": "MGA-HHN outperforms state-of-the-art models in node classification, clustering, and visualization tasks.", "conclusion": "MGA-HHN effectively addresses the limitations of prevailing HeteGNNs, offering improved performance and expressive node representations."}}
{"id": "2505.04338", "pdf": "https://arxiv.org/pdf/2505.04338", "abs": "https://arxiv.org/abs/2505.04338", "authors": ["Zichen Liu", "Wei Zhang", "Christof Sch\u00fctte", "Tiejun Li"], "title": "Riemannian Denoising Diffusion Probabilistic Models", "categories": ["cs.LG"], "comment": "28 pages", "summary": "We propose Riemannian Denoising Diffusion Probabilistic Models (RDDPMs) for\nlearning distributions on submanifolds of Euclidean space that are level sets\nof functions, including most of the manifolds relevant to applications.\nExisting methods for generative modeling on manifolds rely on substantial\ngeometric information such as geodesic curves or eigenfunctions of the\nLaplace-Beltrami operator and, as a result, they are limited to manifolds where\nsuch information is available. In contrast, our method, built on a projection\nscheme, can be applied to more general manifolds, as it only requires being\nable to evaluate the value and the first order derivatives of the function that\ndefines the submanifold. We provide a theoretical analysis of our method in the\ncontinuous-time limit, which elucidates the connection between our RDDPMs and\nscore-based generative models on manifolds. The capability of our method is\ndemonstrated on datasets from previous studies and on new datasets sampled from\ntwo high-dimensional manifolds, i.e. $\\mathrm{SO}(10)$ and the configuration\nspace of molecular system alanine dipeptide with fixed dihedral angle.", "AI": {"tldr": "RDDPMs enable generative modeling on submanifolds using only function evaluations and first-order derivatives, avoiding reliance on extensive geometric data.", "motivation": "Existing methods require detailed geometric information, limiting applicability. RDDPMs aim to generalize to more manifolds.", "method": "Uses a projection scheme requiring only function value and first-order derivative evaluations.", "result": "Demonstrated effectiveness on datasets, including high-dimensional manifolds like SO(10) and molecular configurations.", "conclusion": "RDDPMs offer a versatile and practical approach for generative modeling on diverse manifolds."}}
{"id": "2505.03757", "pdf": "https://arxiv.org/pdf/2505.03757", "abs": "https://arxiv.org/abs/2505.03757", "authors": ["Vinicius Francisco Rofatto", "Luiz Felipe Rodrigues de Almeida", "Marcelo Tomio Matsuoka", "Ivandro Klein", "Mauricio Roberto Veronez", "Luiz Gonzaga Da Silveira Junior"], "title": "On the Residual-based Neural Network for Unmodeled Distortions in Coordinate Transformation", "categories": ["physics.geo-ph", "cs.CV", "cs.LG", "stat.AP", "stat.ML"], "comment": null, "summary": "Coordinate transformation models often fail to account for nonlinear and\nspatially dependent distortions, leading to significant residual errors in\ngeospatial applications. Here we propose a residual-based neural correction\nstrategy, in which a neural network learns to model only the systematic\ndistortions left by an initial geometric transformation. By focusing solely on\nresidual patterns, the proposed method reduces model complexity and improves\nperformance, particularly in scenarios with sparse or structured control point\nconfigurations. We evaluate the method using both simulated datasets with\nvarying distortion intensities and sampling strategies, as well as under the\nreal-world image georeferencing tasks. Compared with direct neural network\ncoordinate converter and classical transformation models, the residual-based\nneural correction delivers more accurate and stable results under challenging\nconditions, while maintaining comparable performance in ideal cases. These\nfindings demonstrate the effectiveness of residual modelling as a lightweight\nand robust alternative for improving coordinate transformation accuracy.", "AI": {"tldr": "A residual-based neural correction method improves coordinate transformation accuracy by modeling systematic distortions left by initial transformations, reducing complexity and enhancing performance.", "motivation": "Existing coordinate transformation models often fail to handle nonlinear and spatially dependent distortions, leading to residual errors in geospatial applications.", "method": "A neural network is trained to model only the residual distortions from an initial geometric transformation, focusing on systematic errors.", "result": "The method outperforms direct neural network converters and classical models, especially in sparse or structured control point scenarios, and maintains accuracy in ideal cases.", "conclusion": "Residual-based neural correction is a lightweight, robust solution for improving coordinate transformation accuracy."}}
{"id": "2505.04354", "pdf": "https://arxiv.org/pdf/2505.04354", "abs": "https://arxiv.org/abs/2505.04354", "authors": ["Wenhao Li", "Bo Jin", "Mingyi Hong", "Changhong Lu", "Xiangfeng Wang"], "title": "Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows", "categories": ["math.OC", "cs.AI"], "comment": "27 pages, 5 figures", "summary": "This position paper argues that optimization problem solving can transition\nfrom expert-dependent to evolutionary agentic workflows. Traditional\noptimization practices rely on human specialists for problem formulation,\nalgorithm selection, and hyperparameter tuning, creating bottlenecks that\nimpede industrial adoption of cutting-edge methods. We contend that an\nevolutionary agentic workflow, powered by foundation models and evolutionary\nsearch, can autonomously navigate the optimization space, comprising problem,\nformulation, algorithm, and hyperparameter spaces. Through case studies in\ncloud resource scheduling and ADMM parameter adaptation, we demonstrate how\nthis approach can bridge the gap between academic innovation and industrial\nimplementation. Our position challenges the status quo of human-centric\noptimization workflows and advocates for a more scalable, adaptive approach to\nsolving real-world optimization problems.", "AI": {"tldr": "The paper proposes replacing expert-dependent optimization workflows with evolutionary agentic workflows using foundation models and evolutionary search for scalability and adaptability.", "motivation": "Traditional optimization relies on human experts, creating bottlenecks and limiting industrial adoption of advanced methods.", "method": "Uses evolutionary agentic workflows powered by foundation models and evolutionary search to autonomously navigate optimization spaces.", "result": "Case studies in cloud resource scheduling and ADMM parameter adaptation show the approach bridges academic innovation and industrial implementation.", "conclusion": "Challenges human-centric workflows and advocates for scalable, adaptive solutions to real-world optimization problems."}}
{"id": "2505.04339", "pdf": "https://arxiv.org/pdf/2505.04339", "abs": "https://arxiv.org/abs/2505.04339", "authors": ["Hao Peng", "Xiang Huang", "Shuo Sun", "Ruitong Zhang", "Philip S. Yu"], "title": "Adaptive and Robust DBSCAN with Multi-agent Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "DBSCAN, a well-known density-based clustering algorithm, has gained\nwidespread popularity and usage due to its effectiveness in identifying\nclusters of arbitrary shapes and handling noisy data. However, it encounters\nchallenges in producing satisfactory cluster results when confronted with\ndatasets of varying density scales, a common scenario in real-world\napplications. In this paper, we propose a novel Adaptive and Robust DBSCAN with\nMulti-agent Reinforcement Learning cluster framework, namely AR-DBSCAN. First,\nwe model the initial dataset as a two-level encoding tree and categorize the\ndata vertices into distinct density partitions according to the information\nuncertainty determined in the encoding tree. Each partition is then assigned to\nan agent to find the best clustering parameters without manual assistance. The\nallocation is density-adaptive, enabling AR-DBSCAN to effectively handle\ndiverse density distributions within the dataset by utilizing distinct agents\nfor different partitions. Second, a multi-agent deep reinforcement learning\nguided automatic parameter searching process is designed. The process of\nadjusting the parameter search direction by perceiving the clustering\nenvironment is modeled as a Markov decision process. Using a weakly-supervised\nreward training policy network, each agent adaptively learns the optimal\nclustering parameters by interacting with the clusters. Third, a recursive\nsearch mechanism adaptable to the data's scale is presented, enabling efficient\nand controlled exploration of large parameter spaces. Extensive experiments are\nconducted on nine artificial datasets and a real-world dataset. The results of\noffline and online tasks show that AR-DBSCAN not only improves clustering\naccuracy by up to 144.1% and 175.3% in the NMI and ARI metrics, respectively,\nbut also is capable of robustly finding dominant parameters.", "AI": {"tldr": "AR-DBSCAN enhances DBSCAN by using multi-agent reinforcement learning to adaptively handle varying density scales, improving clustering accuracy and robustness.", "motivation": "DBSCAN struggles with datasets of varying density scales, limiting its effectiveness in real-world applications.", "method": "AR-DBSCAN models data as a two-level encoding tree, assigns agents to density partitions, and uses reinforcement learning for parameter optimization.", "result": "AR-DBSCAN improves clustering accuracy by up to 144.1% (NMI) and 175.3% (ARI) and robustly finds optimal parameters.", "conclusion": "AR-DBSCAN effectively addresses DBSCAN's limitations, offering adaptive and robust clustering for diverse datasets."}}
{"id": "2505.03842", "pdf": "https://arxiv.org/pdf/2505.03842", "abs": "https://arxiv.org/abs/2505.03842", "authors": ["Vadim Musienko", "Axel Jacquet", "Ingmar Weber", "Till Koebe"], "title": "Coverage Biases in High-Resolution Satellite Imagery", "categories": ["cs.CY", "astro-ph.EP", "cs.CV"], "comment": null, "summary": "Satellite imagery is increasingly used to complement traditional data\ncollection approaches such as surveys and censuses across scientific\ndisciplines. However, we ask: Do all places on earth benefit equally from this\nnew wealth of information? In this study, we investigate coverage bias of major\nsatellite constellations that provide optical satellite imagery with a ground\nsampling distance below 10 meters, evaluating both the future on-demand tasking\nopportunities as well as the availability of historic images across the globe.\nSpecifically, forward-looking, we estimate how often different places are\nrevisited during a window of 30 days based on the satellites' orbital paths,\nthus investigating potential coverage biases caused by physical factors. We\nfind that locations farther away from the equator are generally revisited more\nfrequently by the constellations under study. Backward-looking, we show that\nhistoric satellite image availability -- based on metadata collected from major\nsatellite imagery providers -- is influenced by socio-economic factors on the\nground: less developed, less populated places have less satellite images\navailable. Furthermore, in three small case studies on recent conflict regions\nin this world, namely Gaza, Sudan and Ukraine, we show that also geopolitical\nevents play an important role in satellite image availability, hinting at\nunderlying business model decisions. These insights lay bare that the digital\ndividend yielded by satellite imagery is not equally distributed across our\nplanet.", "AI": {"tldr": "The study examines coverage bias in satellite imagery, revealing disparities in revisit frequency and historic availability influenced by physical, socio-economic, and geopolitical factors.", "motivation": "To assess whether satellite imagery benefits all regions equally, given its growing use in data collection.", "method": "Analyzed revisit frequency based on orbital paths for future coverage and metadata from providers for historic availability, including case studies on conflict regions.", "result": "Equatorial regions are revisited less frequently; less developed areas have fewer historic images. Geopolitical events also impact availability.", "conclusion": "Satellite imagery's benefits are unevenly distributed, highlighting biases in coverage and access."}}
{"id": "2505.04404", "pdf": "https://arxiv.org/pdf/2505.04404", "abs": "https://arxiv.org/abs/2505.04404", "authors": ["Jiaqi Zhu", "Shaofeng Cai", "Yanyan Shen", "Gang Chen", "Fang Deng", "Beng Chin Ooi"], "title": "In-Context Adaptation to Concept Drift for Learned Database Operations", "categories": ["cs.DB", "cs.AI"], "comment": "Accepted by ICML 2025", "summary": "Machine learning has demonstrated transformative potential for database\noperations, such as query optimization and in-database data analytics. However,\ndynamic database environments, characterized by frequent updates and evolving\ndata distributions, introduce concept drift, which leads to performance\ndegradation for learned models and limits their practical applicability.\nAddressing this challenge requires efficient frameworks capable of adapting to\nshifting concepts while minimizing the overhead of retraining or fine-tuning.\n  In this paper, we propose FLAIR, an online adaptation framework that\nintroduces a new paradigm called \\textit{in-context adaptation} for learned\ndatabase operations. FLAIR leverages the inherent property of data systems,\ni.e., immediate availability of execution results for predictions, to enable\ndynamic context construction. By formalizing adaptation as $f:(\\mathbf{x} \\,|\n\\,\\mathcal{C}_t) \\to \\mathbf{y}$, with $\\mathcal{C}_t$ representing a dynamic\ncontext memory, FLAIR delivers predictions aligned with the current concept,\neliminating the need for runtime parameter optimization. To achieve this, FLAIR\nintegrates two key modules: a Task Featurization Module for encoding\ntask-specific features into standardized representations, and a Dynamic\nDecision Engine, pre-trained via Bayesian meta-training, to adapt seamlessly\nusing contextual information at runtime. Extensive experiments across key\ndatabase tasks demonstrate that FLAIR outperforms state-of-the-art baselines,\nachieving up to 5.2x faster adaptation and reducing error by 22.5% for\ncardinality estimation.", "AI": {"tldr": "FLAIR is an online adaptation framework for learned database operations, addressing concept drift in dynamic environments without runtime parameter optimization.", "motivation": "Dynamic database environments cause concept drift, degrading learned model performance. Efficient adaptation frameworks are needed to maintain accuracy.", "method": "FLAIR uses in-context adaptation, leveraging execution results for dynamic context construction. It includes a Task Featurization Module and a Dynamic Decision Engine pre-trained via Bayesian meta-training.", "result": "FLAIR outperforms baselines, achieving 5.2x faster adaptation and 22.5% lower error in cardinality estimation.", "conclusion": "FLAIR effectively adapts to concept drift in databases, enhancing performance without runtime parameter updates."}}
{"id": "2505.04346", "pdf": "https://arxiv.org/pdf/2505.04346", "abs": "https://arxiv.org/abs/2505.04346", "authors": ["Arghya Pratihar", "Kushal Bose", "Swagatam Das"], "title": "Topology-Driven Clustering: Enhancing Performance with Betti Number Filtration", "categories": ["cs.LG"], "comment": null, "summary": "Clustering aims to form groups of similar data points in an unsupervised\nregime. Yet, clustering complex datasets containing critically intertwined\nshapes poses significant challenges. The prevailing clustering algorithms\nwidely depend on evaluating similarity measures based on Euclidean metrics.\nExploring topological characteristics to perform clustering of complex datasets\ninevitably presents a better scope. The topological clustering algorithms\npredominantly perceive the point set through the lens of Simplicial complexes\nand Persistent homology. Despite these approaches, the existing topological\nclustering algorithms cannot somehow fully exploit topological structures and\nshow inconsistent performances on some highly complicated datasets. This work\naims to mitigate the limitations by identifying topologically similar neighbors\nthrough the Vietoris-Rips complex and Betti number filtration. In addition, we\nintroduce the concept of the Betti sequences to capture flexibly essential\nfeatures from the topological structures. Our proposed algorithm is adept at\nclustering complex, intertwined shapes contained in the datasets. We carried\nout experiments on several synthetic and real-world datasets. Our algorithm\ndemonstrated commendable performances across the datasets compared to some of\nthe well-known topology-based clustering algorithms.", "AI": {"tldr": "The paper proposes a topological clustering algorithm using Vietoris-Rips complex and Betti number filtration to improve performance on complex datasets.", "motivation": "Existing topological clustering algorithms fail to fully exploit topological structures and perform inconsistently on complex datasets.", "method": "The algorithm identifies topologically similar neighbors using Vietoris-Rips complex and Betti number filtration, and introduces Betti sequences to capture essential features.", "result": "Experiments on synthetic and real-world datasets show the algorithm outperforms existing topology-based methods.", "conclusion": "The proposed method effectively clusters complex, intertwined shapes, addressing limitations of current approaches."}}
{"id": "2505.03912", "pdf": "https://arxiv.org/pdf/2505.03912", "abs": "https://arxiv.org/abs/2505.03912", "authors": ["Can Cui", "Pengxiang Ding", "Wenxuan Song", "Shuanghao Bai", "Xinyang Tong", "Zirui Ge", "Runze Suo", "Wanqi Zhou", "Yang Liu", "Bofang Jia", "Han Zhao", "Siteng Huang", "Donglin Wang"], "title": "OpenHelix: A Short Survey, Empirical Analysis, and Open-Source Dual-System VLA Model for Robotic Manipulation", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Dual-system VLA (Vision-Language-Action) architectures have become a hot\ntopic in embodied intelligence research, but there is a lack of sufficient\nopen-source work for further performance analysis and optimization. To address\nthis problem, this paper will summarize and compare the structural designs of\nexisting dual-system architectures, and conduct systematic empirical\nevaluations on the core design elements of existing dual-system architectures.\nUltimately, it will provide a low-cost open-source model for further\nexploration. Of course, this project will continue to update with more\nexperimental conclusions and open-source models with improved performance for\neveryone to choose from. Project page: https://openhelix-robot.github.io/.", "AI": {"tldr": "This paper summarizes and compares dual-system VLA architectures, evaluates their core design elements, and provides an open-source model for further research.", "motivation": "Addressing the lack of open-source work for analyzing and optimizing dual-system VLA architectures in embodied intelligence.", "method": "Summarizing and comparing structural designs of existing dual-system architectures, followed by systematic empirical evaluations.", "result": "A low-cost open-source model is provided, with plans for ongoing updates and improved performance models.", "conclusion": "The paper offers a foundation for further exploration in dual-system VLA architectures, with continuous updates expected."}}
{"id": "2505.04405", "pdf": "https://arxiv.org/pdf/2505.04405", "abs": "https://arxiv.org/abs/2505.04405", "authors": ["Yi Zhang", "Nikolaos Farmakidis", "Ioannis Roumpos", "Miltiadis Moralis-Pegios", "Apostolos Tsakyridis", "June Sang Lee", "Bowei Dong", "Yuhan He", "Samarth Aggarwal", "Nikolaos Pleros", "Harish Bhaskaran"], "title": "High-speed multiwavelength photonic temporal integration using silicon photonics", "categories": ["physics.optics", "cs.AI", "physics.app-ph"], "comment": null, "summary": "Optical systems have been pivotal for energy-efficient computing, performing\nhigh-speed, parallel operations in low-loss carriers. While these predominantly\nanalog optical accelerators bypass digitization to perform parallel\nfloating-point computations, scaling optical hardware to map large-vector sizes\nfor AI tasks remains challenging. Here, we overcome this limitation by\nunfolding scalar operations in time and introducing a\nphotonic-heater-in-lightpath (PHIL) unit for all-optical temporal integration.\nCounterintuitively, we exploit a slow heat dissipation process to integrate\noptical signals modulated at 50 GHz bridging the speed gap between the widely\napplied thermo-optic effects and ultrafast photonics. This architecture\nsupports optical end-to-end signal processing, eliminates inefficient\nelectro-optical conversions, and enables both linear and nonlinear operations\nwithin a unified framework. Our results demonstrate a scalable path towards\nhigh-speed photonic computing through thermally driven integration.", "AI": {"tldr": "The paper introduces a photonic-heater-in-lightpath (PHIL) unit for scalable optical computing, leveraging slow heat dissipation to integrate high-speed optical signals, enabling efficient linear and nonlinear operations.", "motivation": "Overcoming the challenge of scaling optical hardware for large-vector AI tasks by avoiding inefficient electro-optical conversions and digitization.", "method": "Unfolding scalar operations in time and using a PHIL unit for all-optical temporal integration, exploiting slow heat dissipation to bridge the speed gap between thermo-optic effects and ultrafast photonics.", "result": "Demonstrated scalable high-speed photonic computing with thermally driven integration, supporting end-to-end optical signal processing.", "conclusion": "The PHIL architecture provides a scalable solution for efficient, high-speed optical computing, unifying linear and nonlinear operations."}}
{"id": "2505.04367", "pdf": "https://arxiv.org/pdf/2505.04367", "abs": "https://arxiv.org/abs/2505.04367", "authors": ["Stavros Sykiotis"], "title": "Deep Learning Innovations for Energy Efficiency: Advances in Non-Intrusive Load Monitoring and EV Charging Optimization for a Sustainable Grid", "categories": ["cs.LG"], "comment": "PhD thesis", "summary": "The global energy landscape is undergoing a profound transformation, often\nreferred to as the energy transition, driven by the urgent need to mitigate\nclimate change, reduce greenhouse gas emissions, and ensure sustainable energy\nsupplies. However, the undoubted complexity of new investments in renewables,\nas well as the phase out of high CO2-emission energy sources, hampers the pace\nof the energy transition and raises doubts as to whether new renewable energy\nsources are capable of solely meeting the climate target goals. This highlights\nthe need to investigate alternative pathways to accelerate the energy\ntransition, by identifying human activity domains with higher/excessive energy\ndemands. Two notable examples where there is room for improvement, in the sense\nof reducing energy consumption and consequently CO2 emissions, are residential\nenergy consumption and road transport. This dissertation investigates the\ndevelopment of novel Deep Learning techniques to create tools which solve\nlimitations in these two key energy domains. Reduction of residential energy\nconsumption can be achieved by empowering end-users with the user of\nNon-Intrusive Load Monitoring, whereas optimization of EV charging with Deep\nReinforcement Learning can tackle road transport decarbonization.", "AI": {"tldr": "The paper explores Deep Learning techniques to address energy transition challenges, focusing on residential energy use and road transport.", "motivation": "The urgency to mitigate climate change and reduce CO2 emissions, coupled with the slow pace of the energy transition, drives the need for alternative solutions.", "method": "Develops novel Deep Learning tools: Non-Intrusive Load Monitoring for residential energy reduction and Deep Reinforcement Learning for optimizing EV charging.", "result": "Proposes actionable tools to reduce energy consumption and emissions in key sectors.", "conclusion": "Deep Learning can accelerate the energy transition by targeting high-demand domains like residential energy and transport."}}
{"id": "2505.04050", "pdf": "https://arxiv.org/pdf/2505.04050", "abs": "https://arxiv.org/abs/2505.04050", "authors": ["Kazuki Higo", "Toshiki Kanai", "Yuki Endo", "Yoshihiro Kanamori"], "title": "TerraFusion: Joint Generation of Terrain Geometry and Texture Using Latent Diffusion Models", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "3D terrain models are essential in fields such as video game development and\nfilm production. Since surface color often correlates with terrain geometry,\ncapturing this relationship is crucial to achieving realism. However, most\nexisting methods generate either a heightmap or a texture, without sufficiently\naccounting for the inherent correlation. In this paper, we propose a method\nthat jointly generates terrain heightmaps and textures using a latent diffusion\nmodel. First, we train the model in an unsupervised manner to randomly generate\npaired heightmaps and textures. Then, we perform supervised learning of an\nexternal adapter to enable user control via hand-drawn sketches. Experiments\nshow that our approach allows intuitive terrain generation while preserving the\ncorrelation between heightmaps and textures.", "AI": {"tldr": "A method for jointly generating terrain heightmaps and textures using a latent diffusion model, enabling intuitive user control via sketches while preserving their correlation.", "motivation": "Existing methods generate heightmaps or textures separately, missing the correlation between surface color and terrain geometry, which is crucial for realism.", "method": "Train a latent diffusion model unsupervised for random generation of paired heightmaps and textures, then add a supervised adapter for user control via sketches.", "result": "The approach successfully generates terrains intuitively while maintaining the heightmap-texture correlation.", "conclusion": "The proposed method effectively combines unsupervised and supervised learning for realistic and user-controllable terrain generation."}}
{"id": "2505.04435", "pdf": "https://arxiv.org/pdf/2505.04435", "abs": "https://arxiv.org/abs/2505.04435", "authors": ["Vahideh Hayyolalam", "\u00d6znur \u00d6zkasap"], "title": "FedBWO: Enhancing Communication Efficiency in Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": "5th IEEE International Conference on Human-Machine Systems, Abu\n  Dhabi, UAE, 26-28 May 2025", "summary": "Federated Learning (FL) is a distributed Machine Learning (ML) setup, where a\nshared model is collaboratively trained by various clients using their local\ndatasets while keeping the data private. Considering resource-constrained\ndevices, FL clients often suffer from restricted transmission capacity. Aiming\nto enhance the system performance, the communication between clients and server\nneeds to be diminished. Current FL strategies transmit a tremendous amount of\ndata (model weights) within the FL process, which needs a high communication\nbandwidth. Considering resource constraints, increasing the number of clients\nand, consequently, the amount of data (model weights) can lead to a bottleneck.\nIn this paper, we introduce the Federated Black Widow Optimization (FedBWO)\ntechnique to decrease the amount of transmitted data by transmitting only a\nperformance score rather than the local model weights from clients. FedBWO\nemploys the BWO algorithm to improve local model updates. The conducted\nexperiments prove that FedBWO remarkably improves the performance of the global\nmodel and the communication efficiency of the overall system. According to the\nexperimental outcomes, FedBWO enhances the global model accuracy by an average\nof 21% over FedAvg, and 12% over FedGWO. Furthermore, FedBWO dramatically\ndecreases the communication cost compared to other methods.", "AI": {"tldr": "FedBWO reduces communication in Federated Learning by transmitting performance scores instead of model weights, improving accuracy and efficiency.", "motivation": "FL clients face communication bottlenecks due to high data transmission; FedBWO aims to reduce this by optimizing updates.", "method": "Uses Federated Black Widow Optimization (FedBWO) to transmit performance scores and improve local model updates.", "result": "FedBWO boosts global model accuracy by 21% over FedAvg and 12% over FedGWO, while cutting communication costs.", "conclusion": "FedBWO is effective for resource-constrained FL, enhancing performance and reducing communication overhead."}}
{"id": "2505.04371", "pdf": "https://arxiv.org/pdf/2505.04371", "abs": "https://arxiv.org/abs/2505.04371", "authors": ["Filipe Santos", "Jo\u00e3o Paulo Fernandes", "Lu\u00eds Macedo"], "title": "Extending a Quantum Reinforcement Learning Exploration Policy with Flags to Connect Four", "categories": ["cs.LG"], "comment": "8 pages, 3 figures, to be submitted to a journal", "summary": "Action selection based on flags is a Reinforcement Learning (RL) exploration\npolicy that improves the exploration of the state space through the use of\nflags, which can identify the most promising actions to take in each state. The\nquantum counterpart of this exploration policy further improves upon this by\ntaking advantage of a quadratic speedup for sampling flagged actions. This\napproach has already been successfully employed for the game of Checkers. In\nthis work, we describe the application of this method to the context of Connect\nFour, in order to study its performance in a different setting, which can lead\nto a better generalization of the technique. We also kept track of a metric\nthat wasn't taken into account in previous work: the average number of\niterations to obtain a flagged action. Since going second is a significant\ndisadvantage in Connect Four, we also had the intent of exploring how this more\ncomplex scenario would impact the performance of our approach. The experiments\ninvolved training and testing classical and quantum RL agents that played\neither going first or going second against a Randomized Negamax opponent. The\nresults showed that both flagged exploration policies were clearly superior to\na simple epsilon-greedy policy. Furthermore, the quantum agents did in fact\nsample flagged actions in less iterations. Despite obtaining tagged actions\nmore consistently, the win rates between the classical and quantum versions of\nthe approach were identical, which could be due to the simplicity of the\ntraining scenario chosen.", "AI": {"tldr": "The paper applies a flag-based RL exploration policy to Connect Four, comparing classical and quantum versions, showing improved performance over epsilon-greedy but identical win rates between the two.", "motivation": "To generalize the flag-based RL exploration policy by testing it in Connect Four, a different setting than Checkers, and to study its performance under more complex scenarios like going second.", "method": "Classical and quantum RL agents were trained and tested against a Randomized Negamax opponent, tracking flagged action iterations and win rates.", "result": "Flagged policies outperformed epsilon-greedy, with quantum agents sampling flagged actions faster, but win rates were identical for classical and quantum versions.", "conclusion": "The flag-based approach is effective, but the simplicity of the training scenario may explain the identical win rates between classical and quantum methods."}}
{"id": "2505.04052", "pdf": "https://arxiv.org/pdf/2505.04052", "abs": "https://arxiv.org/abs/2505.04052", "authors": ["Shun Masuda", "Yuki Endo", "Yoshihiro Kanamori"], "title": "Person-In-Situ: Scene-Consistent Human Image Insertion with Occlusion-Aware Pose Control", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Compositing human figures into scene images has broad applications in areas\nsuch as entertainment and advertising. However, existing methods often cannot\nhandle occlusion of the inserted person by foreground objects and unnaturally\nplace the person in the frontmost layer. Moreover, they offer limited control\nover the inserted person's pose. To address these challenges, we propose two\nmethods. Both allow explicit pose control via a 3D body model and leverage\nlatent diffusion models to synthesize the person at a contextually appropriate\ndepth, naturally handling occlusions without requiring occlusion masks. The\nfirst is a two-stage approach: the model first learns a depth map of the scene\nwith the person through supervised learning, and then synthesizes the person\naccordingly. The second method learns occlusion implicitly and synthesizes the\nperson directly from input data without explicit depth supervision.\nQuantitative and qualitative evaluations show that both methods outperform\nexisting approaches by better preserving scene consistency while accurately\nreflecting occlusions and user-specified poses.", "AI": {"tldr": "The paper proposes two methods for compositing human figures into scenes, addressing occlusion and pose control challenges using 3D body models and latent diffusion models.", "motivation": "Existing methods fail to handle occlusion and unnatural depth placement of inserted figures, and lack pose control.", "method": "Two approaches: one uses supervised learning for depth maps, the other learns occlusion implicitly without depth supervision.", "result": "Both methods outperform existing approaches in scene consistency, occlusion handling, and pose accuracy.", "conclusion": "The proposed methods improve human figure compositing by addressing depth and occlusion issues while enabling pose control."}}
{"id": "2505.04461", "pdf": "https://arxiv.org/pdf/2505.04461", "abs": "https://arxiv.org/abs/2505.04461", "authors": ["Pengfei Jiao", "Hongjiang Chen", "Xuan Guo", "Zhidong Zhao", "Dongxiao He", "Di Jin"], "title": "A Survey on Temporal Interaction Graph Representation Learning: Progress, Challenges, and Opportunities", "categories": ["cs.LG", "cs.AI", "cs.SI"], "comment": "IJCAI 2025 Survey Track", "summary": "Temporal interaction graphs (TIGs), defined by sequences of timestamped\ninteraction events, have become ubiquitous in real-world applications due to\ntheir capability to model complex dynamic system behaviors. As a result,\ntemporal interaction graph representation learning (TIGRL) has garnered\nsignificant attention in recent years. TIGRL aims to embed nodes in TIGs into\nlow-dimensional representations that effectively preserve both structural and\ntemporal information, thereby enhancing the performance of downstream tasks\nsuch as classification, prediction, and clustering within constantly evolving\ndata environments. In this paper, we begin by introducing the foundational\nconcepts of TIGs and emphasize the critical role of temporal dependencies. We\nthen propose a comprehensive taxonomy of state-of-the-art TIGRL methods,\nsystematically categorizing them based on the types of information utilized\nduring the learning process to address the unique challenges inherent to TIGs.\nTo facilitate further research and practical applications, we curate the source\nof datasets and benchmarks, providing valuable resources for empirical\ninvestigations. Finally, we examine key open challenges and explore promising\nresearch directions in TIGRL, laying the groundwork for future advancements\nthat have the potential to shape the evolution of this field.", "AI": {"tldr": "The paper discusses temporal interaction graph representation learning (TIGRL), its importance, methods, and future directions.", "motivation": "Temporal interaction graphs (TIGs) model dynamic systems, and TIGRL aims to embed nodes effectively for downstream tasks.", "method": "Proposes a taxonomy of TIGRL methods based on information types and curates datasets for empirical research.", "result": "Provides a systematic categorization of TIGRL methods and resources for further study.", "conclusion": "Identifies open challenges and future research directions to advance TIGRL."}}
{"id": "2505.04389", "pdf": "https://arxiv.org/pdf/2505.04389", "abs": "https://arxiv.org/abs/2505.04389", "authors": ["Jenni Lampainen", "Kaisa Joki", "Napsu Karmitsa", "Marko M. M\u00e4kel\u00e4"], "title": "Clust-Splitter $-$ an Efficient Nonsmooth Optimization-Based Algorithm for Clustering Large Datasets", "categories": ["cs.LG", "90C90, 90C26"], "comment": "36 pages, 23 figures", "summary": "Clustering is a fundamental task in data mining and machine learning,\nparticularly for analyzing large-scale data. In this paper, we introduce\nClust-Splitter, an efficient algorithm based on nonsmooth optimization,\ndesigned to solve the minimum sum-of-squares clustering problem in very large\ndatasets. The clustering task is approached through a sequence of three\nnonsmooth optimization problems: two auxiliary problems used to generate\nsuitable starting points, followed by a main clustering formulation. To solve\nthese problems effectively, the limited memory bundle method is combined with\nan incremental approach to develop the Clust-Splitter algorithm. We evaluate\nClust-Splitter on real-world datasets characterized by both a large number of\nattributes and a large number of data points and compare its performance with\nseveral state-of-the-art large-scale clustering algorithms. Experimental\nresults demonstrate the efficiency of the proposed method for clustering very\nlarge datasets, as well as the high quality of its solutions, which are on par\nwith those of the best existing methods.", "AI": {"tldr": "Clust-Splitter is an efficient algorithm for large-scale clustering using nonsmooth optimization, outperforming state-of-the-art methods.", "motivation": "Addressing the challenge of clustering very large datasets efficiently and effectively.", "method": "Uses a sequence of nonsmooth optimization problems and the limited memory bundle method with an incremental approach.", "result": "Demonstrates high efficiency and solution quality comparable to best existing methods.", "conclusion": "Clust-Splitter is a robust solution for large-scale clustering tasks."}}
{"id": "2505.04095", "pdf": "https://arxiv.org/pdf/2505.04095", "abs": "https://arxiv.org/abs/2505.04095", "authors": ["Shuo Wen", "Edwin Meriaux", "Mariana Sosa Guzm\u00e1n", "Charlotte Morissette", "Chloe Si", "Bobak Baghi", "Gregory Dudek"], "title": "Scalable Aerial GNSS Localization for Marine Robots", "categories": ["cs.RO", "cs.CV"], "comment": "International Conference on Robotics and Automation 2025 Workshop\n  Robots in the Wild", "summary": "Accurate localization is crucial for water robotics, yet traditional onboard\nGlobal Navigation Satellite System (GNSS) approaches are difficult or\nineffective due to signal reflection on the water's surface and its high cost\nof aquatic GNSS receivers. Existing approaches, such as inertial navigation,\nDoppler Velocity Loggers (DVL), SLAM, and acoustic-based methods, face\nchallenges like error accumulation and high computational complexity.\nTherefore, a more efficient and scalable solution remains necessary. This paper\nproposes an alternative approach that leverages an aerial drone equipped with\nGNSS localization to track and localize a marine robot once it is near the\nsurface of the water. Our results show that this novel adaptation enables\naccurate single and multi-robot marine robot localization.", "AI": {"tldr": "A drone with GNSS tracks marine robots for accurate localization, overcoming water surface signal issues.", "motivation": "Traditional GNSS methods fail on water due to signal reflection and cost; existing alternatives have limitations like error buildup and complexity.", "method": "Uses an aerial drone with GNSS to localize marine robots near the water surface.", "result": "Enables precise single and multi-robot localization.", "conclusion": "The drone-based approach is efficient and scalable for marine robot localization."}}
{"id": "2505.04464", "pdf": "https://arxiv.org/pdf/2505.04464", "abs": "https://arxiv.org/abs/2505.04464", "authors": ["Louis Ohl", "Fredrik Lindsten"], "title": "Discriminative Ordering Through Ensemble Consensus", "categories": ["cs.LG", "cs.AI", "62H30", "G.3"], "comment": "Accepted at UAI 2025", "summary": "Evaluating the performance of clustering models is a challenging task where\nthe outcome depends on the definition of what constitutes a cluster. Due to\nthis design, current existing metrics rarely handle multiple clustering models\nwith diverse cluster definitions, nor do they comply with the integration of\nconstraints when available. In this work, we take inspiration from consensus\nclustering and assume that a set of clustering models is able to uncover hidden\nstructures in the data. We propose to construct a discriminative ordering\nthrough ensemble clustering based on the distance between the connectivity of a\nclustering model and the consensus matrix. We first validate the proposed\nmethod with synthetic scenarios, highlighting that the proposed score ranks the\nmodels that best match the consensus first. We then show that this simple\nranking score significantly outperforms other scoring methods when comparing\nsets of different clustering algorithms that are not restricted to a fixed\nnumber of clusters and is compatible with clustering constraints.", "AI": {"tldr": "The paper proposes a new method to evaluate clustering models by ranking them based on their alignment with a consensus matrix, outperforming existing metrics.", "motivation": "Current clustering evaluation metrics struggle with diverse cluster definitions and constraints, limiting their effectiveness.", "method": "The method constructs a discriminative ordering using ensemble clustering, comparing model connectivity to a consensus matrix.", "result": "Tests on synthetic data show the method ranks models matching the consensus well, and it outperforms other scoring methods for diverse clustering algorithms.", "conclusion": "The proposed ranking score is effective for evaluating clustering models with varied definitions and constraints."}}
{"id": "2505.04396", "pdf": "https://arxiv.org/pdf/2505.04396", "abs": "https://arxiv.org/abs/2505.04396", "authors": ["Jingnan Wang", "Jie Chao", "Shangshang Yang", "Congyi Nai", "Kaijun Ren", "Kefeng Deng", "Xi Chen", "Yaxin Liu", "Hanqiuzi Wen", "Ziniu Xiao", "Lifeng Zhang", "Xiaodong Wang", "Jiping Guan", "Baoxiang Pan"], "title": "Supporting renewable energy planning and operation with data-driven high-resolution ensemble weather forecast", "categories": ["cs.LG", "physics.ao-ph"], "comment": null, "summary": "The planning and operation of renewable energy, especially wind power, depend\ncrucially on accurate, timely, and high-resolution weather information.\nCoarse-grid global numerical weather forecasts are typically downscaled to meet\nthese requirements, introducing challenges of scale inconsistency, process\nrepresentation error, computation cost, and entanglement of distinct\nuncertainty sources from chaoticity, model bias, and large-scale forcing. We\naddress these challenges by learning the climatological distribution of a\ntarget wind farm using its high-resolution numerical weather simulations. An\noptimal combination of this learned high-resolution climatological prior with\ncoarse-grid large scale forecasts yields highly accurate, fine-grained,\nfull-variable, large ensemble of weather pattern forecasts. Using observed\nmeteorological records and wind turbine power outputs as references, the\nproposed methodology verifies advantageously compared to existing\nnumerical/statistical forecasting-downscaling pipelines, regarding either\ndeterministic/probabilistic skills or economic gains. Moreover, a 100-member,\n10-day forecast with spatial resolution of 1 km and output frequency of 15 min\ntakes < 1 hour on a moderate-end GPU, as contrast to $\\mathcal{O}(10^3)$ CPU\nhours for conventional numerical simulation. By drastically reducing\ncomputational costs while maintaining accuracy, our method paves the way for\nmore efficient and reliable renewable energy planning and operation.", "AI": {"tldr": "A method combines learned high-resolution climatological data with coarse-grid forecasts for accurate, efficient wind power weather predictions.", "motivation": "Address challenges in renewable energy planning due to scale inconsistency, process errors, and high computational costs of traditional weather forecasting.", "method": "Learn climatological distribution from high-resolution simulations and combine it with coarse-grid forecasts to produce fine-grained, large ensemble forecasts.", "result": "Outperforms existing methods in accuracy and efficiency, with significant computational cost reduction (1 GPU hour vs. 1000s of CPU hours).", "conclusion": "The method enables more efficient and reliable renewable energy planning by reducing costs while maintaining accuracy."}}
{"id": "2505.04258", "pdf": "https://arxiv.org/pdf/2505.04258", "abs": "https://arxiv.org/abs/2505.04258", "authors": ["Pietro Bonazzi", "Christian Vogt", "Michael Jost", "Haotong Qin", "Lyes Khacef", "Federico Paredes-Valles", "Michele Magno"], "title": "RGB-Event Fusion with Self-Attention for Collision Prediction", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Ensuring robust and real-time obstacle avoidance is critical for the safe\noperation of autonomous robots in dynamic, real-world environments. This paper\nproposes a neural network framework for predicting the time and collision\nposition of an unmanned aerial vehicle with a dynamic object, using RGB and\nevent-based vision sensors. The proposed architecture consists of two separate\nencoder branches, one for each modality, followed by fusion by self-attention\nto improve prediction accuracy. To facilitate benchmarking, we leverage the\nABCD [8] dataset collected that enables detailed comparisons of single-modality\nand fusion-based approaches. At the same prediction throughput of 50Hz, the\nexperimental results show that the fusion-based model offers an improvement in\nprediction accuracy over single-modality approaches of 1% on average and 10%\nfor distances beyond 0.5m, but comes at the cost of +71% in memory and + 105%\nin FLOPs. Notably, the event-based model outperforms the RGB model by 4% for\nposition and 26% for time error at a similar computational cost, making it a\ncompetitive alternative. Additionally, we evaluate quantized versions of the\nevent-based models, applying 1- to 8-bit quantization to assess the trade-offs\nbetween predictive performance and computational efficiency. These findings\nhighlight the trade-offs of multi-modal perception using RGB and event-based\ncameras in robotic applications.", "AI": {"tldr": "A neural network framework for UAV obstacle avoidance using RGB and event-based sensors, showing improved accuracy with fusion but higher computational costs.", "motivation": "Ensuring robust, real-time obstacle avoidance for autonomous robots in dynamic environments.", "method": "Two encoder branches (RGB and event-based) fused via self-attention, benchmarked on the ABCD dataset.", "result": "Fusion improves accuracy by 1% (avg) and 10% (beyond 0.5m) but increases memory (+71%) and FLOPs (+105%). Event-based outperforms RGB (4% position, 26% time error).", "conclusion": "Multi-modal perception (RGB + event-based) offers accuracy gains but with computational trade-offs; event-based is a competitive alternative."}}
{"id": "2505.04468", "pdf": "https://arxiv.org/pdf/2505.04468", "abs": "https://arxiv.org/abs/2505.04468", "authors": ["Hyeju Shin", "Kyudan Jung", "Seongwon Yun", "Juyoung Yun"], "title": "Spectral and Temporal Denoising for Differentially Private Optimization", "categories": ["cs.LG", "cs.AI", "cs.IT", "cs.NE", "math.IT"], "comment": null, "summary": "This paper introduces the FFT-Enhanced Kalman Filter (FFTKF), a\ndifferentially private optimization method that addresses the challenge of\npreserving performance in DP-SGD, where added noise typically degrades model\nutility. FFTKF integrates frequency-domain noise shaping with Kalman filtering\nto enhance gradient quality while preserving $(\\varepsilon, \\delta)$-DP\nguarantees. It employs a high-frequency shaping mask in the Fourier domain to\nconcentrate differential privacy noise in less informative spectral components,\npreserving low-frequency gradient signals. A scalar-gain Kalman filter with\nfinite-difference Hessian approximation further refines the denoised gradients.\nWith a per-iteration complexity of $\\mathcal{O}(d \\log d)$, FFTKF demonstrates\nimproved test accuracy over DP-SGD and DiSK across MNIST, CIFAR-10, CIFAR-100,\nand Tiny-ImageNet datasets using CNNs, Wide ResNets, and Vision Transformers.\nTheoretical analysis confirms that FFTKF maintains equivalent privacy\nguarantees while achieving a tighter privacy-utility trade-off through reduced\nnoise and controlled bias.", "AI": {"tldr": "FFTKF combines frequency-domain noise shaping and Kalman filtering to improve DP-SGD performance while maintaining privacy guarantees.", "motivation": "Address the performance degradation in DP-SGD due to added noise, aiming to preserve model utility.", "method": "Integrates frequency-domain noise shaping with Kalman filtering, using a high-frequency mask and scalar-gain Kalman filter.", "result": "Outperforms DP-SGD and DiSK in test accuracy across multiple datasets with CNNs, Wide ResNets, and Vision Transformers.", "conclusion": "FFTKF maintains privacy guarantees while achieving better utility through reduced noise and controlled bias."}}
{"id": "2505.04412", "pdf": "https://arxiv.org/pdf/2505.04412", "abs": "https://arxiv.org/abs/2505.04412", "authors": ["Ren Wang", "Pengcheng Zhou"], "title": "Latent Manifold Reconstruction and Representation with Topological and Geometrical Regularization", "categories": ["cs.LG"], "comment": "25 pages, 11 figures, 4 tables", "summary": "Manifold learning aims to discover and represent low-dimensional structures\nunderlying high-dimensional data while preserving critical topological and\ngeometric properties. Existing methods often fail to capture local details with\nglobal topological integrity from noisy data or construct a balanced\ndimensionality reduction, resulting in distorted or fractured embeddings. We\npresent an AutoEncoder-based method that integrates a manifold reconstruction\nlayer, which uncovers latent manifold structures from noisy point clouds, and\nfurther provides regularizations on topological and geometric properties during\ndimensionality reduction, whereas the two components promote each other during\ntraining. Experiments on point cloud datasets demonstrate that our method\noutperforms baselines like t-SNE, UMAP, and Topological AutoEncoders in\ndiscovering manifold structures from noisy data and preserving them through\ndimensionality reduction, as validated by visualization and quantitative\nmetrics. This work demonstrates the significance of combining manifold\nreconstruction with manifold learning to achieve reliable representation of the\nlatent manifold, particularly when dealing with noisy real-world data. Code\nrepository: https://github.com/Thanatorika/mrtg.", "AI": {"tldr": "An AutoEncoder-based method integrates manifold reconstruction and learning to improve dimensionality reduction for noisy data, outperforming t-SNE, UMAP, and Topological AutoEncoders.", "motivation": "Existing manifold learning methods often fail to balance local details and global topology in noisy data, leading to distorted embeddings.", "method": "The proposed method combines a manifold reconstruction layer with topological and geometric regularizations during dimensionality reduction, enhancing mutual training benefits.", "result": "Outperforms baselines (t-SNE, UMAP, Topological AutoEncoders) in discovering and preserving manifold structures, validated by visual and quantitative metrics.", "conclusion": "Combining manifold reconstruction with learning is key for reliable latent manifold representation, especially in noisy real-world data."}}
{"id": "2505.04387", "pdf": "https://arxiv.org/pdf/2505.04387", "abs": "https://arxiv.org/abs/2505.04387", "authors": ["Amin Fadaeinejad", "Abdallah Dib", "Luiz Gustavo Hafemann", "Emeline Got", "Trevor Anderson", "Amaury Depierre", "Nikolaus F. Troje", "Marcus A. Brubaker", "Marc-Andr\u00e9 Carbonneau"], "title": "Geometry-Aware Texture Generation for 3D Head Modeling with Artist-driven Control", "categories": ["cs.GR", "cs.CV"], "comment": "11 pages, 9 figures, AI for Creative Visual Content Generation\n  Editing and Understanding (CVEU), CVPRW 2025", "summary": "Creating realistic 3D head assets for virtual characters that match a precise\nartistic vision remains labor-intensive. We present a novel framework that\nstreamlines this process by providing artists with intuitive control over\ngenerated 3D heads. Our approach uses a geometry-aware texture synthesis\npipeline that learns correlations between head geometry and skin texture maps\nacross different demographics. The framework offers three levels of artistic\ncontrol: manipulation of overall head geometry, adjustment of skin tone while\npreserving facial characteristics, and fine-grained editing of details such as\nwrinkles or facial hair. Our pipeline allows artists to make edits to a single\ntexture map using familiar tools, with our system automatically propagating\nthese changes coherently across the remaining texture maps needed for realistic\nrendering. Experiments demonstrate that our method produces diverse results\nwith clean geometries. We showcase practical applications focusing on intuitive\ncontrol for artists, including skin tone adjustments and simplified editing\nworkflows for adding age-related details or removing unwanted features from\nscanned models. This integrated approach aims to streamline the artistic\nworkflow in virtual character creation.", "AI": {"tldr": "A framework for intuitive artistic control over 3D head generation, enabling geometry and texture manipulation with automated coherence.", "motivation": "To reduce the labor-intensive process of creating realistic 3D head assets that match artistic visions.", "method": "Uses a geometry-aware texture synthesis pipeline learning correlations between head geometry and skin textures, offering three levels of control: geometry, skin tone, and fine details.", "result": "Produces diverse, clean geometries with coherent texture edits, demonstrated in skin tone adjustments and detail editing.", "conclusion": "Streamlines artistic workflow in virtual character creation with intuitive control and automated coherence."}}
{"id": "2505.04493", "pdf": "https://arxiv.org/pdf/2505.04493", "abs": "https://arxiv.org/abs/2505.04493", "authors": ["Or Wertheim", "Ronen I. Brafman"], "title": "Model-Based AI planning and Execution Systems for Robotics", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Model-based planning and execution systems offer a principled approach to\nbuilding flexible autonomous robots that can perform diverse tasks by\nautomatically combining a host of basic skills. This idea is almost as old as\nmodern robotics. Yet, while diverse general-purpose reasoning architectures\nhave been proposed since, general-purpose systems that are integrated with\nmodern robotic platforms have emerged only recently, starting with the\ninfluential ROSPlan system. Since then, a growing number of model-based systems\nfor robot task-level control have emerged. In this paper, we consider the\ndiverse design choices and issues existing systems attempt to address, the\ndifferent solutions proposed so far, and suggest avenues for future\ndevelopment.", "AI": {"tldr": "The paper reviews model-based planning and execution systems for autonomous robots, highlighting their evolution, current solutions, and future directions.", "motivation": "To explore the design choices and challenges in model-based systems for robot task-level control, addressing gaps in general-purpose robotic reasoning architectures.", "method": "Analyzes existing systems, their solutions, and design approaches, focusing on integration with modern robotic platforms.", "result": "Identifies diverse solutions and trends in model-based systems, emphasizing recent advancements like ROSPlan.", "conclusion": "Suggests future development avenues for improving general-purpose model-based robotic systems."}}
{"id": "2505.04417", "pdf": "https://arxiv.org/pdf/2505.04417", "abs": "https://arxiv.org/abs/2505.04417", "authors": ["Georg A. Gottwald", "Shuigen Liu", "Youssef Marzouk", "Sebastian Reich", "Xin T. Tong"], "title": "Localized Diffusion Models for High Dimensional Distributions Generation", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.ML"], "comment": null, "summary": "Diffusion models are the state-of-the-art tools for various generative tasks.\nHowever, estimating high-dimensional score functions makes them potentially\nsuffer from the curse of dimensionality (CoD). This underscores the importance\nof better understanding and exploiting low-dimensional structure in the target\ndistribution. In this work, we consider locality structure, which describes\nsparse dependencies between model components. Under locality structure, the\nscore function is effectively low-dimensional, so that it can be estimated by a\nlocalized neural network with significantly reduced sample complexity. This\nmotivates the localized diffusion model, where a localized score matching loss\nis used to train the score function within a localized hypothesis space. We\nprove that such localization enables diffusion models to circumvent CoD, at the\nprice of additional localization error. Under realistic sample size scaling, we\nshow both theoretically and numerically that a moderate localization radius can\nbalance the statistical and localization error, leading to a better overall\nperformance. The localized structure also facilitates parallel training of\ndiffusion models, making it potentially more efficient for large-scale\napplications.", "AI": {"tldr": "Localized diffusion models exploit low-dimensional structure to reduce sample complexity and avoid the curse of dimensionality, balancing statistical and localization errors for better performance.", "motivation": "Diffusion models face challenges due to high-dimensional score functions, which suffer from the curse of dimensionality. Understanding and leveraging low-dimensional structure (like locality) can improve efficiency.", "method": "Proposes a localized diffusion model using a localized score matching loss and a localized hypothesis space to train the score function.", "result": "Localization reduces sample complexity and circumvents the curse of dimensionality, with a trade-off in localization error. A moderate localization radius balances errors for optimal performance.", "conclusion": "Localized diffusion models offer improved efficiency and parallel training potential, making them suitable for large-scale applications."}}
{"id": "2505.04590", "pdf": "https://arxiv.org/pdf/2505.04590", "abs": "https://arxiv.org/abs/2505.04590", "authors": ["Alexandre Binninger", "Ruben Wiersma", "Philipp Herholz", "Olga Sorkine-Hornung"], "title": "TetWeave: Isosurface Extraction using On-The-Fly Delaunay Tetrahedral Grids for Gradient-Based Mesh Optimization", "categories": ["cs.GR", "cs.CV", "I.3.5"], "comment": "ACM Trans. Graph. 44, 4. SIGGRAPH 2025. 19 pages, 21 figures", "summary": "We introduce TetWeave, a novel isosurface representation for gradient-based\nmesh optimization that jointly optimizes the placement of a tetrahedral grid\nused for Marching Tetrahedra and a novel directional signed distance at each\npoint. TetWeave constructs tetrahedral grids on-the-fly via Delaunay\ntriangulation, enabling increased flexibility compared to predefined grids. The\nextracted meshes are guaranteed to be watertight, two-manifold and\nintersection-free. The flexibility of TetWeave enables a resampling strategy\nthat places new points where reconstruction error is high and allows to\nencourage mesh fairness without compromising on reconstruction error. This\nleads to high-quality, adaptive meshes that require minimal memory usage and\nfew parameters to optimize. Consequently, TetWeave exhibits near-linear memory\nscaling relative to the vertex count of the output mesh - a substantial\nimprovement over predefined grids. We demonstrate the applicability of TetWeave\nto a broad range of challenging tasks in computer graphics and vision, such as\nmulti-view 3D reconstruction, mesh compression and geometric texture\ngeneration.", "AI": {"tldr": "TetWeave is a flexible isosurface representation for gradient-based mesh optimization, using dynamic tetrahedral grids and directional signed distances to produce high-quality, adaptive meshes with minimal memory usage.", "motivation": "Existing predefined grids for mesh optimization lack flexibility and efficiency. TetWeave aims to address these limitations by enabling dynamic grid construction and adaptive resampling.", "method": "TetWeave constructs tetrahedral grids on-the-fly via Delaunay triangulation and optimizes a directional signed distance at each point. It ensures watertight, two-manifold, and intersection-free meshes.", "result": "TetWeave achieves high-quality meshes with near-linear memory scaling, outperforming predefined grids. It excels in tasks like 3D reconstruction, mesh compression, and texture generation.", "conclusion": "TetWeave offers a versatile and efficient solution for mesh optimization, with broad applicability in graphics and vision tasks."}}
{"id": "2505.04553", "pdf": "https://arxiv.org/pdf/2505.04553", "abs": "https://arxiv.org/abs/2505.04553", "authors": ["Shanyu Han", "Yang Liu", "Xiang Yu"], "title": "Risk-sensitive Reinforcement Learning Based on Convex Scoring Functions", "categories": ["q-fin.MF", "cs.AI", "q-fin.RM"], "comment": "35 pages", "summary": "We propose a reinforcement learning (RL) framework under a broad class of\nrisk objectives, characterized by convex scoring functions. This class covers\nmany common risk measures, such as variance, Expected Shortfall, entropic\nValue-at-Risk, and mean-risk utility. To resolve the time-inconsistency issue,\nwe consider an augmented state space and an auxiliary variable and recast the\nproblem as a two-state optimization problem. We propose a customized\nActor-Critic algorithm and establish some theoretical approximation guarantees.\nA key theoretical contribution is that our results do not require the Markov\ndecision process to be continuous. Additionally, we propose an auxiliary\nvariable sampling method inspired by the alternating minimization algorithm,\nwhich is convergent under certain conditions. We validate our approach in\nsimulation experiments with a financial application in statistical arbitrage\ntrading, demonstrating the effectiveness of the algorithm.", "AI": {"tldr": "A reinforcement learning framework for risk objectives using convex scoring functions, addressing time-inconsistency with a two-state optimization approach and a customized Actor-Critic algorithm.", "motivation": "To handle diverse risk measures (e.g., variance, Expected Shortfall) in RL, overcoming time-inconsistency issues.", "method": "Augmented state space, auxiliary variable, two-state optimization, and a customized Actor-Critic algorithm with theoretical guarantees.", "result": "Effective algorithm validated in financial applications like statistical arbitrage trading.", "conclusion": "The framework successfully addresses time-inconsistency and works for non-continuous Markov decision processes."}}
{"id": "2505.04440", "pdf": "https://arxiv.org/pdf/2505.04440", "abs": "https://arxiv.org/abs/2505.04440", "authors": ["Xiaozheng Qu", "Zhaochuan Li", "Zhuang Qi", "Xiang Li", "Haibei Huang", "Lei Meng", "Xiangxu Meng"], "title": "Towards Initialization-Agnostic Clustering with Iterative Adaptive Resonance Theory", "categories": ["cs.LG"], "comment": "2025 International Joint Conference on Neural Networks (IJCNN 2025)", "summary": "The clustering performance of Fuzzy Adaptive Resonance Theory (Fuzzy ART) is\nhighly dependent on the preset vigilance parameter, where deviations in its\nvalue can lead to significant fluctuations in clustering results, severely\nlimiting its practicality for non-expert users. Existing approaches generally\nenhance vigilance parameter robustness through adaptive mechanisms such as\nparticle swarm optimization and fuzzy logic rules. However, they often\nintroduce additional hyperparameters or complex frameworks that contradict the\noriginal simplicity of the algorithm. To address this, we propose Iterative\nRefinement Adaptive Resonance Theory (IR-ART), which integrates three key\nphases into a unified iterative framework: (1) Cluster Stability Detection: A\ndynamic stability detection module that identifies unstable clusters by\nanalyzing the change of sample size (number of samples in the cluster) in\niteration. (2) Unstable Cluster Deletion: An evolutionary pruning module that\neliminates low-quality clusters. (3) Vigilance Region Expansion: A vigilance\nregion expansion mechanism that adaptively adjusts similarity thresholds.\nIndependent of the specific execution of clustering, these three phases\nsequentially focus on analyzing the implicit knowledge within the iterative\nprocess, adjusting weights and vigilance parameters, thereby laying a\nfoundation for the next iteration. Experimental evaluation on 15 datasets\ndemonstrates that IR-ART improves tolerance to suboptimal vigilance parameter\nvalues while preserving the parameter simplicity of Fuzzy ART. Case studies\nvisually confirm the algorithm's self-optimization capability through iterative\nrefinement, making it particularly suitable for non-expert users in\nresource-constrained scenarios.", "AI": {"tldr": "IR-ART improves Fuzzy ART by iteratively refining clusters, enhancing robustness to vigilance parameter changes without added complexity.", "motivation": "Fuzzy ART's clustering performance is sensitive to the vigilance parameter, limiting its practicality for non-expert users. Existing solutions add complexity, contradicting the algorithm's simplicity.", "method": "IR-ART integrates three phases: Cluster Stability Detection, Unstable Cluster Deletion, and Vigilance Region Expansion, iteratively refining clusters.", "result": "IR-ART improves tolerance to suboptimal vigilance parameters while maintaining simplicity, validated on 15 datasets.", "conclusion": "IR-ART is a practical solution for non-expert users, offering self-optimization through iterative refinement."}}
{"id": "2505.04596", "pdf": "https://arxiv.org/pdf/2505.04596", "abs": "https://arxiv.org/abs/2505.04596", "authors": ["Mohammad Merati", "David Casta\u00f1\u00f3n"], "title": "Dynamic Network Flow Optimization for Task Scheduling in PTZ Camera Surveillance Systems", "categories": ["math.OC", "cs.CV", "cs.SY", "eess.SY"], "comment": "7 pages, 3 Figures, Accepted at AIRC 2025", "summary": "This paper presents a novel approach for optimizing the scheduling and\ncontrol of Pan-Tilt-Zoom (PTZ) cameras in dynamic surveillance environments.\nThe proposed method integrates Kalman filters for motion prediction with a\ndynamic network flow model to enhance real-time video capture efficiency. By\nassigning Kalman filters to tracked objects, the system predicts future\nlocations, enabling precise scheduling of camera tasks. This prediction-driven\napproach is formulated as a network flow optimization, ensuring scalability and\nadaptability to various surveillance scenarios. To further reduce redundant\nmonitoring, we also incorporate group-tracking nodes, allowing multiple objects\nto be captured within a single camera focus when appropriate. In addition, a\nvalue-based system is introduced to prioritize camera actions, focusing on the\ntimely capture of critical events. By adjusting the decay rates of these values\nover time, the system ensures prompt responses to tasks with imminent\ndeadlines. Extensive simulations demonstrate that this approach improves\ncoverage, reduces average wait times, and minimizes missed events compared to\ntraditional master-slave camera systems. Overall, our method significantly\nenhances the efficiency, scalability, and effectiveness of surveillance\nsystems, particularly in dynamic and crowded environments.", "AI": {"tldr": "A novel method optimizes PTZ camera scheduling using Kalman filters and dynamic network flow, improving coverage and reducing missed events in surveillance.", "motivation": "Enhance real-time video capture efficiency in dynamic surveillance environments by integrating motion prediction and optimization.", "method": "Combines Kalman filters for motion prediction with a dynamic network flow model, group-tracking nodes, and a value-based prioritization system.", "result": "Improves coverage, reduces wait times, and minimizes missed events compared to traditional systems.", "conclusion": "The method significantly boosts surveillance efficiency, scalability, and effectiveness in dynamic environments."}}
{"id": "2505.04558", "pdf": "https://arxiv.org/pdf/2505.04558", "abs": "https://arxiv.org/abs/2505.04558", "authors": ["Wenzhao Liu", "Haoran Li", "Congying Han", "Zicheng Zhang", "Anqi Li", "Tiande Guo"], "title": "Purity Law for Generalizable Neural TSP Solvers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Achieving generalization in neural approaches across different scales and\ndistributions remains a significant challenge for the Traveling Salesman\nProblem~(TSP). A key obstacle is that neural networks often fail to learn\nrobust principles for identifying universal patterns and deriving optimal\nsolutions from diverse instances. In this paper, we first uncover Purity Law\n(PuLa), a fundamental structural principle for optimal TSP solutions, defining\nthat edge prevalence grows exponentially with the sparsity of surrounding\nvertices. Statistically validated across diverse instances, PuLa reveals a\nconsistent bias toward local sparsity in global optima. Building on this\ninsight, we propose Purity Policy Optimization~(PUPO), a novel training\nparadigm that explicitly aligns characteristics of neural solutions with PuLa\nduring the solution construction process to enhance generalization. Extensive\nexperiments demonstrate that PUPO can be seamlessly integrated with popular\nneural solvers, significantly enhancing their generalization performance\nwithout incurring additional computational overhead during inference.", "AI": {"tldr": "The paper introduces Purity Law (PuLa) for TSP, showing edge prevalence grows with vertex sparsity, and proposes PUPO to align neural solutions with PuLa, improving generalization without extra inference cost.", "motivation": "Generalization in neural TSP solvers is challenging due to lack of robust principles for universal patterns.", "method": "Uncover PuLa, a structural principle for TSP, and propose PUPO to align neural solutions with PuLa during training.", "result": "PUPO enhances generalization of neural solvers without additional inference overhead.", "conclusion": "PuLa and PUPO provide a principled way to improve neural TSP solvers' generalization."}}
{"id": "2505.04441", "pdf": "https://arxiv.org/pdf/2505.04441", "abs": "https://arxiv.org/abs/2505.04441", "authors": ["Mirazul Haque", "Petr Babkin", "Farima Farmahinifarahani", "Manuela Veloso"], "title": "Towards Effectively Leveraging Execution Traces for Program Repair with Code LLMs", "categories": ["cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) show promising performance on various\nprogramming tasks, including Automatic Program Repair (APR). However, most\napproaches to LLM-based APR are limited to the static analysis of the programs,\nwhile disregarding their runtime behavior. Inspired by knowledge-augmented NLP,\nin this work, we aim to remedy this potential blind spot by augmenting standard\nAPR prompts with program execution traces. We evaluate our approach using the\nGPT family of models on three popular APR datasets. Our findings suggest that\nsimply incorporating execution traces into the prompt provides a limited\nperformance improvement over trace-free baselines, in only 2 out of 6 tested\ndataset / model configurations. We further find that the effectiveness of\nexecution traces for APR diminishes as their complexity increases. We explore\nseveral strategies for leveraging traces in prompts and demonstrate that\nLLM-optimized prompts help outperform trace-free prompts more consistently.\nAdditionally, we show trace-based prompting to be superior to finetuning a\nsmaller LLM on a small-scale dataset; and conduct probing studies reinforcing\nthe notion that execution traces can complement the reasoning abilities of the\nLLMs.", "AI": {"tldr": "LLM-based APR augmented with execution traces shows limited improvement, with effectiveness decreasing as trace complexity increases. Optimized prompts outperform trace-free ones, and traces complement LLM reasoning.", "motivation": "Current LLM-based APR methods ignore runtime behavior, so this work aims to enhance APR by incorporating execution traces.", "method": "Augment standard APR prompts with program execution traces, evaluated using GPT models on three APR datasets.", "result": "Limited performance improvement (2/6 configurations); effectiveness decreases with trace complexity. Optimized prompts outperform trace-free ones.", "conclusion": "Execution traces complement LLM reasoning, and optimized prompts are more effective than trace-free or finetuning approaches."}}
{"id": "2505.04619", "pdf": "https://arxiv.org/pdf/2505.04619", "abs": "https://arxiv.org/abs/2505.04619", "authors": ["Abdulaziz Almuzairee", "Rohan Patil", "Dwait Bhatt", "Henrik I. Christensen"], "title": "Merging and Disentangling Views in Visual Reinforcement Learning for Robotic Manipulation", "categories": ["cs.LG", "cs.CV", "cs.RO"], "comment": "For project website and code, see https://aalmuzairee.github.io/mad", "summary": "Vision is well-known for its use in manipulation, especially using visual\nservoing. To make it robust, multiple cameras are needed to expand the field of\nview. That is computationally challenging. Merging multiple views and using\nQ-learning allows the design of more effective representations and optimization\nof sample efficiency. Such a solution might be expensive to deploy. To mitigate\nthis, we introduce a Merge And Disentanglement (MAD) algorithm that efficiently\nmerges views to increase sample efficiency while augmenting with single-view\nfeatures to allow lightweight deployment and ensure robust policies. We\ndemonstrate the efficiency and robustness of our approach using Meta-World and\nManiSkill3. For project website and code, see https://aalmuzairee.github.io/mad", "AI": {"tldr": "The paper introduces the Merge And Disentanglement (MAD) algorithm to efficiently merge multiple camera views for robust visual servoing, balancing computational efficiency and deployment cost.", "motivation": "Multiple cameras improve robustness in visual servoing but are computationally expensive. The goal is to optimize sample efficiency while ensuring lightweight deployment.", "method": "The MAD algorithm merges multiple views for efficiency and augments with single-view features for lightweight deployment.", "result": "The approach is validated on Meta-World and ManiSkill3, showing efficiency and robustness.", "conclusion": "MAD provides a practical solution for robust visual servoing by balancing computational efficiency and deployment cost."}}
{"id": "2505.04578", "pdf": "https://arxiv.org/pdf/2505.04578", "abs": "https://arxiv.org/abs/2505.04578", "authors": ["Wenjun Cao"], "title": "Fight Fire with Fire: Defending Against Malicious RL Fine-Tuning via Reward Neutralization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) fine-tuning transforms large language models\nwhile creating a vulnerability we experimentally verify: Our experiment shows\nthat malicious RL fine-tuning dismantles safety guardrails with remarkable\nefficiency, requiring only 50 steps and minimal adversarial prompts, with\nharmful escalating from 0-2 to 7-9. This attack vector particularly threatens\nopen-source models with parameter-level access. Existing defenses targeting\nsupervised fine-tuning prove ineffective against RL's dynamic feedback\nmechanisms. We introduce Reward Neutralization, the first defense framework\nspecifically designed against RL fine-tuning attacks, establishing concise\nrejection patterns that render malicious reward signals ineffective. Our\napproach trains models to produce minimal-information rejections that attackers\ncannot exploit, systematically neutralizing attempts to optimize toward harmful\noutputs. Experiments validate that our approach maintains low harmful scores\n(no greater than 2) after 200 attack steps, while standard models rapidly\ndeteriorate. This work provides the first constructive proof that robust\ndefense against increasingly accessible RL attacks is achievable, addressing a\ncritical security gap for open-weight models.", "AI": {"tldr": "Malicious RL fine-tuning can dismantle safety guardrails in language models efficiently. Reward Neutralization is introduced as a defense, maintaining safety under attack.", "motivation": "To address the vulnerability of language models to RL fine-tuning attacks, which bypass existing defenses and escalate harmful outputs.", "method": "Introduces Reward Neutralization, a defense framework that trains models to reject malicious reward signals with minimal-information responses.", "result": "Reward Neutralization maintains harmful scores \u22642 after 200 attack steps, outperforming standard models.", "conclusion": "Robust defense against RL fine-tuning attacks is achievable, closing a security gap for open-weight models."}}
{"id": "2505.04471", "pdf": "https://arxiv.org/pdf/2505.04471", "abs": "https://arxiv.org/abs/2505.04471", "authors": ["Vincent Souveton", "S\u00e9bastien Terrana"], "title": "Hamiltonian Normalizing Flows as kinetic PDE solvers: application to the 1D Vlasov-Poisson Equations", "categories": ["cs.LG"], "comment": null, "summary": "Many conservative physical systems can be described using the Hamiltonian\nformalism. A notable example is the Vlasov-Poisson equations, a set of partial\ndifferential equations that govern the time evolution of a phase-space density\nfunction representing collisionless particles under a self-consistent\npotential. These equations play a central role in both plasma physics and\ncosmology. Due to the complexity of the potential involved, analytical\nsolutions are rarely available, necessitating the use of numerical methods such\nas Particle-In-Cell. In this work, we introduce a novel approach based on\nHamiltonian-informed Normalizing Flows, specifically a variant of Fixed-Kinetic\nNeural Hamiltonian Flows. Our method transforms an initial Gaussian\ndistribution in phase space into the final distribution using a sequence of\ninvertible, volume-preserving transformations derived from Hamiltonian\ndynamics. The model is trained on a dataset comprising initial and final states\nat a fixed time T, generated via numerical simulations. After training, the\nmodel enables fast sampling of the final distribution from any given initial\nstate. Moreover, by automatically learning an interpretable physical potential,\nit can generalize to intermediate states not seen during training, offering\ninsights into the system's evolution across time.", "AI": {"tldr": "A novel method using Hamiltonian-informed Normalizing Flows is introduced to model the Vlasov-Poisson equations, enabling fast sampling and interpretable potential learning.", "motivation": "The complexity of the Vlasov-Poisson equations and lack of analytical solutions necessitate numerical methods. This work aims to provide a faster and interpretable alternative.", "method": "The approach uses Fixed-Kinetic Neural Hamiltonian Flows to transform an initial Gaussian distribution into the final state via invertible, volume-preserving transformations derived from Hamiltonian dynamics.", "result": "The model successfully learns the final distribution from initial states and generalizes to unseen intermediate states, providing insights into system evolution.", "conclusion": "The method offers a fast, interpretable, and generalizable solution for modeling Hamiltonian systems like the Vlasov-Poisson equations."}}
{"id": "2505.04622", "pdf": "https://arxiv.org/pdf/2505.04622", "abs": "https://arxiv.org/abs/2505.04622", "authors": ["Jingwen Ye", "Yuze He", "Yanning Zhou", "Yiqin Zhu", "Kaiwen Xiao", "Yong-Jin Liu", "Wei Yang", "Xiao Han"], "title": "PrimitiveAnything: Human-Crafted 3D Primitive Assembly Generation with Auto-Regressive Transformer", "categories": ["cs.GR", "cs.CV"], "comment": "SIGGRAPH 2025. 14 pages, 15 figures", "summary": "Shape primitive abstraction, which decomposes complex 3D shapes into simple\ngeometric elements, plays a crucial role in human visual cognition and has\nbroad applications in computer vision and graphics. While recent advances in 3D\ncontent generation have shown remarkable progress, existing primitive\nabstraction methods either rely on geometric optimization with limited semantic\nunderstanding or learn from small-scale, category-specific datasets, struggling\nto generalize across diverse shape categories. We present PrimitiveAnything, a\nnovel framework that reformulates shape primitive abstraction as a primitive\nassembly generation task. PrimitiveAnything includes a shape-conditioned\nprimitive transformer for auto-regressive generation and an ambiguity-free\nparameterization scheme to represent multiple types of primitives in a unified\nmanner. The proposed framework directly learns the process of primitive\nassembly from large-scale human-crafted abstractions, enabling it to capture\nhow humans decompose complex shapes into primitive elements. Through extensive\nexperiments, we demonstrate that PrimitiveAnything can generate high-quality\nprimitive assemblies that better align with human perception while maintaining\ngeometric fidelity across diverse shape categories. It benefits various 3D\napplications and shows potential for enabling primitive-based user-generated\ncontent (UGC) in games. Project page: https://primitiveanything.github.io", "AI": {"tldr": "PrimitiveAnything is a framework for shape primitive abstraction, learning from human-crafted data to generate high-quality primitive assemblies across diverse 3D shapes.", "motivation": "Existing methods lack semantic understanding or generalize poorly across shape categories, limiting their effectiveness in human-aligned primitive abstraction.", "method": "PrimitiveAnything uses a shape-conditioned primitive transformer for auto-regressive generation and a unified parameterization scheme for multiple primitive types.", "result": "The framework generates high-quality primitive assemblies that align with human perception and maintain geometric fidelity across diverse shapes.", "conclusion": "PrimitiveAnything advances primitive abstraction, benefiting 3D applications and enabling primitive-based user-generated content in games."}}
{"id": "2505.04592", "pdf": "https://arxiv.org/pdf/2505.04592", "abs": "https://arxiv.org/abs/2505.04592", "authors": ["Peter Barnett", "Aaron Scher"], "title": "AI Governance to Avoid Extinction: The Strategic Landscape and Actionable Research Questions", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Humanity appears to be on course to soon develop AI systems that\nsubstantially outperform human experts in all cognitive domains and activities.\nWe believe the default trajectory has a high likelihood of catastrophe,\nincluding human extinction. Risks come from failure to control powerful AI\nsystems, misuse of AI by malicious rogue actors, war between great powers, and\nauthoritarian lock-in. This research agenda has two aims: to describe the\nstrategic landscape of AI development and to catalog important governance\nresearch questions. These questions, if answered, would provide important\ninsight on how to successfully reduce catastrophic risks.\n  We describe four high-level scenarios for the geopolitical response to\nadvanced AI development, cataloging the research questions most relevant to\neach. Our favored scenario involves building the technical, legal, and\ninstitutional infrastructure required to internationally restrict dangerous AI\ndevelopment and deployment (which we refer to as an Off Switch), which leads\ninto an internationally coordinated Halt on frontier AI activities at some\npoint in the future. The second scenario we describe is a US National Project\nfor AI, in which the US Government races to develop advanced AI systems and\nestablish unilateral control over global AI development. We also describe two\nadditional scenarios: a Light-Touch world similar to that of today and a Threat\nof Sabotage situation where countries use sabotage and deterrence to slow AI\ndevelopment.\n  In our view, apart from the Off Switch and Halt scenario, all of these\ntrajectories appear to carry an unacceptable risk of catastrophic harm. Urgent\naction is needed from the US National Security community and AI governance\necosystem to answer key research questions, build the capability to halt\ndangerous AI activities, and prepare for international AI agreements.", "AI": {"tldr": "The paper warns of catastrophic risks from advanced AI, including human extinction, and proposes governance research to mitigate these risks. It outlines four geopolitical scenarios, favoring an 'Off Switch' and coordinated halt on AI development.", "motivation": "The motivation is to address the high likelihood of catastrophic outcomes from uncontrolled AI development, including misuse, war, and authoritarianism, by guiding governance research.", "method": "The method involves describing the strategic landscape of AI development and cataloging key governance research questions to reduce risks. Four geopolitical scenarios are analyzed.", "result": "The paper identifies four scenarios, favoring an 'Off Switch' and coordinated halt as the least risky. Other scenarios (US National Project, Light-Touch, Threat of Sabotage) are deemed unacceptable due to high risks.", "conclusion": "Urgent action is needed to answer governance questions, build capabilities to halt dangerous AI activities, and prepare for international agreements to avoid catastrophic outcomes."}}
{"id": "2505.04535", "pdf": "https://arxiv.org/pdf/2505.04535", "abs": "https://arxiv.org/abs/2505.04535", "authors": ["Michail Theologitis", "Vasilis Samoladas", "Antonios Deligiannakis"], "title": "Communication-Efficient Federated Fine-Tuning of Language Models via Dynamic Update Schedules", "categories": ["cs.LG"], "comment": null, "summary": "Federated learning (FL) makes it possible to train models on data that would\notherwise remain untapped and inaccessible. Simultaneously, pre-trained\nlanguage models (LMs) have emerged as indispensable tools in modern workflows.\nThese models exhibit extraordinary capabilities and are easily adapted to\ndownstream tasks. This opens one of the most exciting frontiers in FL:\nfine-tuning LMs. However, a persistent challenge in FL is the frequent, rigid\ncommunication of parameters, a problem which is magnified by the sheer size of\nthese modern models. Currently, the FedOpt family of algorithms is the\nprevailing approach in FL, though it relies on fixed, heuristic intervals for\nmodel synchronization. Recently, the FDA algorithm introduced a dynamic\nalternative by monitoring training progress, but it came with its own\ndrawbacks; namely, a hard-to-tune threshold parameter and a rigid\nsynchronization scheme. In this work, we introduce the FDA-Opt family of\nalgorithms -- a unified generalization that extends the principles behind both\nFDA and FedOpt, while resolving their core limitations. We evaluate our\napproach on fine-tuning LMs across a range of downstream NLP tasks, and\ndemonstrate that it consistently outperforms FedOpt -- even when FDA-Opt\noperates under hyper-parameter settings originally optimized for its\ncompetitors. In other words, we show that FDA-Opt is a practical, drop-in\nreplacement for FedOpt in modern FL libraries and systems: it requires no\nadditional configuration and delivers superior performance out of the box.", "AI": {"tldr": "FDA-Opt is a new algorithm combining FedOpt and FDA, improving federated learning for fine-tuning language models without extra tuning.", "motivation": "Federated learning (FL) struggles with rigid communication of large model parameters. FedOpt and FDA have limitations in synchronization and tuning.", "method": "Introduces FDA-Opt, a unified algorithm combining FedOpt and FDA principles, resolving their drawbacks.", "result": "Outperforms FedOpt in fine-tuning LMs across NLP tasks, even with competitor-optimized settings.", "conclusion": "FDA-Opt is a practical, superior drop-in replacement for FedOpt in FL systems, requiring no additional configuration."}}
{"id": "2202.03482", "pdf": "https://arxiv.org/pdf/2202.03482", "abs": "https://arxiv.org/abs/2202.03482", "authors": ["Frederik Pahde", "Maximilian Dreyer", "Leander Weber", "Moritz Weckbecker", "Christopher J. Anders", "Thomas Wiegand", "Wojciech Samek", "Sebastian Lapuschkin"], "title": "Navigating Neural Space: Revisiting Concept Activation Vectors to Overcome Directional Divergence", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "With a growing interest in understanding neural network prediction\nstrategies, Concept Activation Vectors (CAVs) have emerged as a popular tool\nfor modeling human-understandable concepts in the latent space. Commonly, CAVs\nare computed by leveraging linear classifiers optimizing the separability of\nlatent representations of samples with and without a given concept. However, in\nthis paper we show that such a separability-oriented computation leads to\nsolutions, which may diverge from the actual goal of precisely modeling the\nconcept direction. This discrepancy can be attributed to the significant\ninfluence of distractor directions, i.e., signals unrelated to the concept,\nwhich are picked up by filters (i.e., weights) of linear models to optimize\nclass-separability. To address this, we introduce pattern-based CAVs, solely\nfocussing on concept signals, thereby providing more accurate concept\ndirections. We evaluate various CAV methods in terms of their alignment with\nthe true concept direction and their impact on CAV applications, including\nconcept sensitivity testing and model correction for shortcut behavior caused\nby data artifacts. We demonstrate the benefits of pattern-based CAVs using the\nPediatric Bone Age, ISIC2019, and FunnyBirds datasets with VGG, ResNet, ReXNet,\nEfficientNet, and Vision Transformer as model architectures.", "AI": {"tldr": "The paper critiques the separability-oriented computation of Concept Activation Vectors (CAVs) for diverging from true concept modeling due to distractor signals. It proposes pattern-based CAVs for more accurate concept directions and validates their superiority in alignment and applications like sensitivity testing and model correction.", "motivation": "To address the discrepancy between separability-oriented CAVs and true concept modeling caused by distractor signals.", "method": "Introduces pattern-based CAVs that focus solely on concept signals, avoiding distractor influences. Evaluates alignment with true concept directions and impact on applications.", "result": "Demonstrates that pattern-based CAVs provide more accurate concept directions, improving performance in sensitivity testing and correcting shortcut behaviors in models.", "conclusion": "Pattern-based CAVs outperform traditional methods by better aligning with true concept directions, enhancing their utility in applications."}}
{"id": "2505.04608", "pdf": "https://arxiv.org/pdf/2505.04608", "abs": "https://arxiv.org/abs/2505.04608", "authors": ["Drew Prinster", "Xing Han", "Anqi Liu", "Suchi Saria"], "title": "WATCH: Weighted Adaptive Testing for Changepoint Hypotheses via Weighted-Conformal Martingales", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "To be published in The International Conference on Machine Learning\n  (ICML), 2025", "summary": "Responsibly deploying artificial intelligence (AI) / machine learning (ML)\nsystems in high-stakes settings arguably requires not only proof of system\nreliability, but moreover continual, post-deployment monitoring to quickly\ndetect and address any unsafe behavior. Statistical methods for nonparametric\nchange-point detection -- especially the tools of conformal test martingales\n(CTMs) and anytime-valid inference -- offer promising approaches to this\nmonitoring task. However, existing methods are restricted to monitoring limited\nhypothesis classes or ``alarm criteria,'' such as data shifts that violate\ncertain exchangeability assumptions, or do not allow for online adaptation in\nresponse to shifts. In this paper, we expand the scope of these monitoring\nmethods by proposing a weighted generalization of conformal test martingales\n(WCTMs), which lay a theoretical foundation for online monitoring for any\nunexpected changepoints in the data distribution while controlling\nfalse-alarms. For practical applications, we propose specific WCTM algorithms\nthat accommodate online adaptation to mild covariate shifts (in the marginal\ninput distribution) while raising alarms in response to more severe shifts,\nsuch as concept shifts (in the conditional label distribution) or extreme\n(out-of-support) covariate shifts that cannot be easily adapted to. On\nreal-world datasets, we demonstrate improved performance relative to\nstate-of-the-art baselines.", "AI": {"tldr": "The paper proposes weighted conformal test martingales (WCTMs) for online monitoring of AI/ML systems to detect unexpected data distribution changes, improving adaptability and performance over existing methods.", "motivation": "Responsible AI/ML deployment in high-stakes settings requires post-deployment monitoring to detect unsafe behavior, but current methods are limited in scope and adaptability.", "method": "The authors introduce WCTMs, a generalization of conformal test martingales, to monitor any unexpected changepoints while controlling false alarms. They also propose specific algorithms for online adaptation to mild shifts and detection of severe shifts.", "result": "WCTMs demonstrate improved performance on real-world datasets compared to state-of-the-art baselines.", "conclusion": "The proposed WCTMs expand the capabilities of monitoring methods, enabling better adaptability and detection of harmful shifts in AI/ML systems."}}
{"id": "2505.04560", "pdf": "https://arxiv.org/pdf/2505.04560", "abs": "https://arxiv.org/abs/2505.04560", "authors": ["Guanghui Wang", "Zhiyong Yang", "Zitai Wang", "Shi Wang", "Qianqian Xu", "Qingming Huang"], "title": "ABKD: Pursuing a Proper Allocation of the Probability Mass in Knowledge Distillation via $\u03b1$-$\u03b2$-Divergence", "categories": ["cs.LG"], "comment": "ICML 2025 Spotlight", "summary": "Knowledge Distillation (KD) transfers knowledge from a large teacher model to\na smaller student model by minimizing the divergence between their output\ndistributions, typically using forward Kullback-Leibler divergence (FKLD) or\nreverse KLD (RKLD). It has become an effective training paradigm due to the\nbroader supervision information provided by the teacher distribution compared\nto one-hot labels. We identify that the core challenge in KD lies in balancing\ntwo mode-concentration effects: the \\textbf{\\textit{Hardness-Concentration}}\neffect, which refers to focusing on modes with large errors, and the\n\\textbf{\\textit{Confidence-Concentration}} effect, which refers to focusing on\nmodes with high student confidence. Through an analysis of how probabilities\nare reassigned during gradient updates, we observe that these two effects are\nentangled in FKLD and RKLD, but in extreme forms. Specifically, both are too\nweak in FKLD, causing the student to fail to concentrate on the target class.\nIn contrast, both are too strong in RKLD, causing the student to overly\nemphasize the target class while ignoring the broader distributional\ninformation from the teacher. To address this imbalance, we propose ABKD, a\ngeneric framework with $\\alpha$-$\\beta$-divergence. Our theoretical results\nshow that ABKD offers a smooth interpolation between FKLD and RKLD, achieving\nan effective trade-off between these effects. Extensive experiments on 17\nlanguage/vision datasets with 12 teacher-student settings confirm its efficacy.\nThe code is available at https://github.com/ghwang-s/abkd.", "AI": {"tldr": "ABKD introduces a framework using \u03b1-\u03b2-divergence to balance the Hardness-Concentration and Confidence-Concentration effects in Knowledge Distillation, outperforming FKLD and RKLD.", "motivation": "The core challenge in KD is balancing two mode-concentration effects: Hardness-Concentration (focus on large errors) and Confidence-Concentration (focus on high student confidence). FKLD and RKLD handle these effects poorly, either too weakly or too strongly.", "method": "Proposes ABKD, a framework with \u03b1-\u03b2-divergence, to smoothly interpolate between FKLD and RKLD, balancing the two effects.", "result": "ABKD achieves an effective trade-off between the two effects, validated by experiments on 17 datasets with 12 teacher-student settings.", "conclusion": "ABKD provides a superior balance in KD, leveraging teacher distribution more effectively than FKLD or RKLD alone."}}
{"id": "2306.07971", "pdf": "https://arxiv.org/pdf/2306.07971", "abs": "https://arxiv.org/abs/2306.07971", "authors": ["Omkar Thawakar", "Abdelrahman Shaker", "Sahal Shaji Mullappilly", "Hisham Cholakkal", "Rao Muhammad Anwer", "Salman Khan", "Jorma Laaksonen", "Fahad Shahbaz Khan"], "title": "XrayGPT: Chest Radiographs Summarization using Medical Vision-Language Models", "categories": ["cs.CV"], "comment": "Accepted at ACL 2024-BIONLP Workshop. Code:\n  https://github.com/mbzuai-oryx/XrayGPT", "summary": "The latest breakthroughs in large vision-language models, such as Bard and\nGPT-4, have showcased extraordinary abilities in performing a wide range of\ntasks. Such models are trained on massive datasets comprising billions of\npublic image-text pairs with diverse tasks. However, their performance on\ntask-specific domains, such as radiology, is still under-investigated and\npotentially limited due to a lack of sophistication in understanding biomedical\nimages. On the other hand, conversational medical models have exhibited\nremarkable success but have mainly focused on text-based analysis. In this\npaper, we introduce XrayGPT, a novel conversational medical vision-language\nmodel that can analyze and answer open-ended questions about chest radiographs.\nSpecifically, we align both medical visual encoder (MedClip) with a fine-tuned\nlarge language model (Vicuna), using a simple linear transformation. This\nalignment enables our model to possess exceptional visual conversation\nabilities, grounded in a deep understanding of radiographs and medical domain\nknowledge. To enhance the performance of LLMs in the medical context, we\ngenerate ~217k interactive and high-quality summaries from free-text radiology\nreports. These summaries serve to enhance the performance of LLMs through the\nfine-tuning process. Our approach opens up new avenues the research for\nadvancing the automated analysis of chest radiographs. Our open-source demos,\nmodels, and instruction sets are available at:\nhttps://github.com/mbzuai-oryx/XrayGPT.", "AI": {"tldr": "XrayGPT is a conversational medical vision-language model for analyzing chest radiographs, combining a medical visual encoder with a fine-tuned LLM to enhance performance in the medical domain.", "motivation": "Existing vision-language models lack sophistication in biomedical image understanding, while conversational medical models focus on text. XrayGPT bridges this gap by enabling visual conversation grounded in medical knowledge.", "method": "Aligns a medical visual encoder (MedClip) with a fine-tuned LLM (Vicuna) using linear transformation and generates ~217k summaries from radiology reports for fine-tuning.", "result": "XrayGPT achieves exceptional visual conversation abilities for chest radiographs, leveraging medical domain knowledge.", "conclusion": "The model advances automated chest radiograph analysis and is open-sourced for further research."}}
{"id": "2008.01188", "pdf": "https://arxiv.org/pdf/2008.01188", "abs": "https://arxiv.org/abs/2008.01188", "authors": ["Quentin Cohen-Solal"], "title": "Learning to Play Two-Player Perfect-Information Games without Knowledge", "categories": ["cs.AI"], "comment": null, "summary": "In this paper, several techniques for learning game state evaluation\nfunctions by reinforcement are proposed. The first is a generalization of tree\nbootstrapping (tree learning): it is adapted to the context of reinforcement\nlearning without knowledge based on non-linear functions. With this technique,\nno information is lost during the reinforcement learning process. The second is\na modification of minimax with unbounded depth extending the best sequences of\nactions to the terminal states. This modified search is intended to be used\nduring the learning process. The third is to replace the classic gain of a game\n(+1 / -1) with a reinforcement heuristic. We study particular reinforcement\nheuristics such as: quick wins and slow defeats ; scoring ; mobility or\npresence. The four is a new action selection distribution. The conducted\nexperiments suggest that these techniques improve the level of play. Finally,\nwe apply these different techniques to design program-players to the game of\nHex (size 11 and 13) surpassing the level of Mohex 3HNN with reinforcement\nlearning from self-play without knowledge.", "AI": {"tldr": "Proposes four techniques for learning game state evaluation functions via reinforcement, improving gameplay, and applying them to Hex to surpass Mohex 3HNN.", "motivation": "To enhance reinforcement learning for game state evaluation without losing information and improve gameplay performance.", "method": "1. Generalization of tree bootstrapping for RL. 2. Modified minimax with unbounded depth. 3. Replacement of classic game gain with reinforcement heuristics. 4. New action selection distribution.", "result": "Techniques improve gameplay; applied to Hex, surpassing Mohex 3HNN's level via self-play RL.", "conclusion": "The proposed methods effectively enhance game state evaluation and performance in Hex."}}
{"id": "2505.04566", "pdf": "https://arxiv.org/pdf/2505.04566", "abs": "https://arxiv.org/abs/2505.04566", "authors": ["Lucas R. C. Farias", "Talita P. Silva", "Pedro H. M. Araujo"], "title": "Multitask LSTM for Arboviral Outbreak Prediction Using Public Health Data", "categories": ["cs.LG"], "comment": "6 pages, 4 figures", "summary": "This paper presents a multitask learning approach based on long-short-term\nmemory (LSTM) networks for the joint prediction of arboviral outbreaks and case\ncounts of dengue, chikungunya, and Zika in Recife, Brazil. Leveraging\nhistorical public health data from DataSUS (2017-2023), the proposed model\nconcurrently performs binary classification (outbreak detection) and regression\n(case forecasting) tasks. A sliding window strategy was adopted to construct\ntemporal features using varying input lengths (60, 90, and 120 days), with\nhyperparameter optimization carried out using Keras Tuner. Model evaluation\nused time series cross-validation for robustness and a held-out test from 2023\nfor generalization assessment. The results show that longer windows improve\ndengue regression accuracy, while classification performance peaked at\nintermediate windows, suggesting an optimal trade-off between sequence length\nand generalization. The multitask architecture delivers competitive performance\nacross diseases and tasks, demonstrating the feasibility and advantages of\nunified modeling strategies for scalable epidemic forecasting in data-limited\npublic health scenarios.", "AI": {"tldr": "A multitask LSTM model predicts arboviral outbreaks and case counts for dengue, chikungunya, and Zika in Recife, Brazil, using historical data. Longer input windows improve dengue forecasting, while intermediate windows optimize outbreak detection.", "motivation": "To address the need for scalable epidemic forecasting in data-limited public health settings by jointly predicting outbreaks and case counts for multiple diseases.", "method": "Uses LSTM networks with a sliding window strategy (60, 90, 120 days) and hyperparameter optimization via Keras Tuner. Evaluated with time series cross-validation and a 2023 test set.", "result": "Longer windows enhance dengue case forecasting, while intermediate windows improve outbreak detection. The multitask model performs well across diseases and tasks.", "conclusion": "The unified multitask approach is feasible and advantageous for epidemic forecasting in resource-limited scenarios."}}
{"id": "2308.06057", "pdf": "https://arxiv.org/pdf/2308.06057", "abs": "https://arxiv.org/abs/2308.06057", "authors": ["Andrea Asperti", "Gabriele Colasuonno", "Antonio Guerra"], "title": "Illumination and Shadows in Head Rotation: experiments with Denoising Diffusion Models", "categories": ["cs.CV", "I.2.10; I.4.5; I.5"], "comment": null, "summary": "Accurately modeling the effects of illumination and shadows during head\nrotation is critical in computer vision for enhancing image realism and\nreducing artifacts. This study delves into the latent space of denoising\ndiffusion models to identify compelling trajectories that can express\ncontinuous head rotation under varying lighting conditions. A key contribution\nof our work is the generation of additional labels from the CelebA\ndataset,categorizing images into three groups based on prevalent illumination\ndirection: left, center, and right. These labels play a crucial role in our\napproach, enabling more precise manipulations and improved handling of lighting\nvariations. Leveraging a recent embedding technique for Denoising Diffusion\nImplicit Models (DDIM), our method achieves noteworthy manipulations,\nencompassing a wide rotation angle of $\\pm 30$ degrees, while preserving\nindividual distinct characteristics even under challenging illumination\nconditions. Our methodology involves computing trajectories that approximate\nclouds of latent representations of dataset samples with different yaw\nrotations through linear regression. Specific trajectories are obtained by\nanalyzing subsets of data that share significant attributes with the source\nimage, including light direction. Notably, our approach does not require any\nspecific training of the generative model for the task of rotation; we merely\ncompute and follow specific trajectories in the latent space of a pre-trained\nface generation model. This article showcases the potential of our approach and\nits current limitations through a qualitative discussion of notable examples.\nThis study contributes to the ongoing advancements in representation learning\nand the semantic investigation of the latent space of generative models.", "AI": {"tldr": "The paper explores using denoising diffusion models to simulate continuous head rotation under varying lighting, leveraging latent space trajectories and additional labels from CelebA for improved realism.", "motivation": "Enhancing image realism and reducing artifacts in computer vision by accurately modeling illumination and shadows during head rotation.", "method": "Uses latent space trajectories in denoising diffusion models (DDIM), labels images by illumination direction, and computes trajectories via linear regression without additional training.", "result": "Achieves head rotations up to \u00b130 degrees while preserving distinct characteristics under challenging lighting.", "conclusion": "Demonstrates the potential of latent space manipulation for realistic head rotation, contributing to representation learning and generative model semantics."}}
{"id": "2406.01759", "pdf": "https://arxiv.org/pdf/2406.01759", "abs": "https://arxiv.org/abs/2406.01759", "authors": ["Christoph Wehner", "Chrysa Iliopoulou", "Ute Schmid", "Tarek R. Besold"], "title": "From Latent to Lucid: Transforming Knowledge Graph Embeddings into Interpretable Structures with KGEPrisma", "categories": ["cs.AI"], "comment": null, "summary": "In this paper, we introduce a post-hoc and local explainable AI method\ntailored for Knowledge Graph Embedding (KGE) models. These models are essential\nto Knowledge Graph Completion yet criticized for their opaque, black-box\nnature. Despite their significant success in capturing the semantics of\nknowledge graphs through high-dimensional latent representations, their\ninherent complexity poses substantial challenges to explainability. While\nexisting methods like Kelpie use resource-intensive perturbation to explain KGE\nmodels, our approach directly decodes the latent representations encoded by KGE\nmodels, leveraging the smoothness of the embeddings, which follows the\nprinciple that similar embeddings reflect similar behaviours within the\nKnowledge Graph, meaning that nodes are similarly embedded because their graph\nneighbourhood looks similar. This principle is commonly referred to as\nsmoothness. By identifying symbolic structures, in the form of triples, within\nthe subgraph neighborhoods of similarly embedded entities, our method\nidentifies the statistical regularities on which the models rely and translates\nthese insights into human-understandable symbolic rules and facts. This bridges\nthe gap between the abstract representations of KGE models and their predictive\noutputs, offering clear, interpretable insights. Key contributions include a\nnovel post-hoc and local explainable AI method for KGE models that provides\nimmediate, faithful explanations without retraining, facilitating real-time\napplication on large-scale knowledge graphs. The method's flexibility enables\nthe generation of rule-based, instance-based, and analogy-based explanations,\nmeeting diverse user needs. Extensive evaluations show the effectiveness of our\napproach in delivering faithful and well-localized explanations, enhancing the\ntransparency and trustworthiness of KGE models.", "AI": {"tldr": "A post-hoc, local explainable AI method for Knowledge Graph Embedding (KGE) models decodes latent representations to provide interpretable insights without retraining.", "motivation": "KGE models are opaque, making their predictions hard to explain. This work aims to bridge the gap between abstract embeddings and human-understandable explanations.", "method": "The approach leverages the smoothness of embeddings to identify symbolic structures (triples) in subgraph neighborhoods, translating them into rules and facts.", "result": "The method delivers faithful, localized explanations and supports diverse explanation types (rule-based, instance-based, analogy-based).", "conclusion": "The proposed method enhances KGE model transparency and trustworthiness, enabling real-time explainability for large-scale knowledge graphs."}}
{"id": "2505.04599", "pdf": "https://arxiv.org/pdf/2505.04599", "abs": "https://arxiv.org/abs/2505.04599", "authors": ["Michael Crawshaw", "Mingrui Liu"], "title": "Complexity Lower Bounds of Adaptive Gradient Algorithms for Non-convex Stochastic Optimization under Relaxed Smoothness", "categories": ["cs.LG"], "comment": "ICLR 2025", "summary": "Recent results in non-convex stochastic optimization demonstrate the\nconvergence of popular adaptive algorithms (e.g., AdaGrad) under the $(L_0,\nL_1)$-smoothness condition, but the rate of convergence is a higher-order\npolynomial in terms of problem parameters like the smoothness constants. The\ncomplexity guaranteed by such algorithms to find an $\\epsilon$-stationary point\nmay be significantly larger than the optimal complexity of $\\Theta \\left(\n\\Delta L \\sigma^2 \\epsilon^{-4} \\right)$ achieved by SGD in the $L$-smooth\nsetting, where $\\Delta$ is the initial optimality gap, $\\sigma^2$ is the\nvariance of stochastic gradient. However, it is currently not known whether\nthese higher-order dependencies can be tightened. To answer this question, we\ninvestigate complexity lower bounds for several adaptive optimization\nalgorithms in the $(L_0, L_1)$-smooth setting, with a focus on the dependence\nin terms of problem parameters $\\Delta, L_0, L_1$. We provide complexity bounds\nfor three variations of AdaGrad, which show at least a quadratic dependence on\nproblem parameters $\\Delta, L_0, L_1$. Notably, we show that the decorrelated\nvariant of AdaGrad-Norm requires at least $\\Omega \\left( \\Delta^2 L_1^2\n\\sigma^2 \\epsilon^{-4} \\right)$ stochastic gradient queries to find an\n$\\epsilon$-stationary point. We also provide a lower bound for SGD with a broad\nclass of adaptive stepsizes. Our results show that, for certain adaptive\nalgorithms, the $(L_0, L_1)$-smooth setting is fundamentally more difficult\nthan the standard smooth setting, in terms of the initial optimality gap and\nthe smoothness constants.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2406.17774", "pdf": "https://arxiv.org/pdf/2406.17774", "abs": "https://arxiv.org/abs/2406.17774", "authors": ["Ruben Wiersma", "Julien Philip", "Milo\u0161 Ha\u0161an", "Krishna Mullia", "Fujun Luan", "Elmar Eisemann", "Valentin Deschaintre"], "title": "Uncertainty for SVBRDF Acquisition using Frequency Analysis", "categories": ["cs.CV", "cs.GR"], "comment": "Project page: https://svbrdf-uncertainty.github.io", "summary": "This paper aims to quantify uncertainty for SVBRDF acquisition in multi-view\ncaptures. Under uncontrolled illumination and unstructured viewpoints, there is\nno guarantee that the observations contain enough information to reconstruct\nthe appearance properties of a captured object. We study this ambiguity, or\nuncertainty, using entropy and accelerate the analysis by using the frequency\ndomain, rather than the domain of incoming and outgoing viewing angles. The\nresult is a method that computes a map of uncertainty over an entire object\nwithin a millisecond. We find that the frequency model allows us to recover\nSVBRDF parameters with competitive performance, that the accelerated entropy\ncomputation matches results with a physically-based path tracer, and that there\nis a positive correlation between error and uncertainty. We then show that the\nuncertainty map can be applied to improve SVBRDF acquisition using capture\nguidance, sharing information on the surface, and using a diffusion model to\ninpaint uncertain regions. Our code is available at\nhttps://github.com/rubenwiersma/svbrdf_uncertainty.", "AI": {"tldr": "The paper introduces a method to quantify uncertainty in SVBRDF acquisition using entropy and frequency domain analysis, enabling fast uncertainty mapping and improved reconstruction.", "motivation": "To address ambiguity in SVBRDF acquisition under uncontrolled conditions by quantifying uncertainty.", "method": "Uses entropy and frequency domain analysis to accelerate uncertainty mapping, validated with a path tracer.", "result": "Achieves competitive SVBRDF reconstruction, correlates error with uncertainty, and applies uncertainty maps for improved acquisition.", "conclusion": "The method efficiently quantifies uncertainty and enhances SVBRDF acquisition through capture guidance and diffusion-based inpainting."}}
{"id": "2502.12224", "pdf": "https://arxiv.org/pdf/2502.12224", "abs": "https://arxiv.org/abs/2502.12224", "authors": ["Zhiyuan Fang", "Zicong Hong", "Yuegui Huang", "Yufeng Lyu", "Wuhui Chen", "Yue Yu", "Fan Yu", "Zibin Zheng"], "title": "Fate: Fast Edge Inference of Mixture-of-Experts Models via Cross-Layer Gate", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive performance across\nvarious tasks, and their application in edge scenarios has attracted\nsignificant attention. However, sparse-activated Mixture-of-Experts (MoE)\nmodels, which are well suited for edge scenarios, have received relatively\nlittle attention due to their high memory demands. Offload-based methods have\nbeen proposed to address this challenge, but they face difficulties with expert\nprediction. Inaccurate expert predictions can result in prolonged inference\ndelays. To promote the application of MoE models in edge scenarios, we propose\nFate, an offloading system designed for MoE models to enable efficient\ninference in resource-constrained environments. The key insight behind Fate is\nthat gate inputs from adjacent layers can be effectively used for expert\nprefetching, achieving high prediction accuracy without additional GPU\noverhead. Furthermore, Fate employs a shallow-favoring expert caching strategy\nthat increases the expert hit rate to 99\\%. Additionally, Fate integrates\ntailored quantization strategies for cache optimization and IO efficiency.\nExperimental results show that, compared to Load on Demand and Expert\nActivation Path-based method, Fate achieves up to 4.5x and 1.9x speedups in\nprefill speed and up to 4.1x and 2.2x speedups in decoding speed, respectively,\nwhile maintaining inference quality. Moreover, Fate's performance improvements\nare scalable across different memory budgets.", "AI": {"tldr": "Fate is an offloading system for MoE models, improving inference efficiency in edge scenarios by leveraging gate inputs for expert prefetching and a caching strategy.", "motivation": "MoE models are underutilized in edge scenarios due to high memory demands and inaccurate expert predictions, which delay inference.", "method": "Fate uses gate inputs from adjacent layers for expert prefetching, a shallow-favoring caching strategy, and tailored quantization for optimization.", "result": "Fate achieves up to 4.5x and 1.9x speedups in prefill and decoding speeds, respectively, with a 99% expert hit rate.", "conclusion": "Fate enables efficient MoE model inference in resource-constrained environments, with scalable performance improvements."}}
{"id": "2505.04604", "pdf": "https://arxiv.org/pdf/2505.04604", "abs": "https://arxiv.org/abs/2505.04604", "authors": ["Lorenzo Beretta", "Nathaniel Harms", "Caleb Koch"], "title": "Testing Juntas Optimally with Samples", "categories": ["cs.LG", "cs.CC", "cs.DS"], "comment": null, "summary": "We prove tight upper and lower bounds of\n$\\Theta\\left(\\tfrac{1}{\\epsilon}\\left( \\sqrt{2^k \\log\\binom{n}{k} } +\n\\log\\binom{n}{k} \\right)\\right)$ on the number of samples required for\ndistribution-free $k$-junta testing. This is the first tight bound for testing\na natural class of Boolean functions in the distribution-free sample-based\nmodel. Our bounds also hold for the feature selection problem, showing that a\njunta tester must learn the set of relevant variables. For tolerant junta\ntesting, we prove a sample lower bound of $\\Omega(2^{(1-o(1)) k} +\n\\log\\binom{n}{k})$ showing that, unlike standard testing, there is no large gap\nbetween tolerant testing and learning.", "AI": {"tldr": "Tight bounds for distribution-free k-junta testing and feature selection, showing no large gap between tolerant testing and learning.", "motivation": "To establish the first tight bounds for testing a natural class of Boolean functions in the distribution-free sample-based model and explore implications for feature selection and tolerant testing.", "method": "Proving upper and lower bounds on the number of samples required for k-junta testing and analyzing the feature selection problem.", "result": "Tight bounds of \u0398(1/\u03f5(\u221a(2^k log(n choose k)) + log(n choose k))) for k-junta testing and \u03a9(2^{(1-o(1))k} + log(n choose k)) for tolerant testing.", "conclusion": "The study provides foundational insights into the sample complexity of junta testing and its relationship with learning, highlighting the absence of a large gap in tolerant testing."}}
{"id": "2406.18360", "pdf": "https://arxiv.org/pdf/2406.18360", "abs": "https://arxiv.org/abs/2406.18360", "authors": ["Hao Li", "Chenming Wu", "Ming Yuan", "Yan Zhang", "Chen Zhao", "Chunyu Song", "Haocheng Feng", "Errui Ding", "Dingwen Zhang", "Jingdong Wang"], "title": "XLD: A Cross-Lane Dataset for Benchmarking Novel Driving View Synthesis", "categories": ["cs.CV"], "comment": "Accepted to 3DV 2025, project page: https://3d-aigc.github.io/XLD/", "summary": "Comprehensive testing of autonomous systems through simulation is essential\nto ensure the safety of autonomous driving vehicles. This requires the\ngeneration of safety-critical scenarios that extend beyond the limitations of\nreal-world data collection, as many of these scenarios are rare or rarely\nencountered on public roads. However, evaluating most existing novel view\nsynthesis (NVS) methods relies on sporadic sampling of image frames from the\ntraining data, comparing the rendered images with ground-truth images.\nUnfortunately, this evaluation protocol falls short of meeting the actual\nrequirements in closed-loop simulations. Specifically, the true application\ndemands the capability to render novel views that extend beyond the original\ntrajectory (such as cross-lane views), which are challenging to capture in the\nreal world. To address this, this paper presents a synthetic dataset for novel\ndriving view synthesis evaluation, which is specifically designed for\nautonomous driving simulations. This unique dataset includes testing images\ncaptured by deviating from the training trajectory by $1-4$ meters. It\ncomprises six sequences that cover various times and weather conditions. Each\nsequence contains $450$ training images, $120$ testing images, and their\ncorresponding camera poses and intrinsic parameters. Leveraging this novel\ndataset, we establish the first realistic benchmark for evaluating existing NVS\napproaches under front-only and multicamera settings. The experimental findings\nunderscore the significant gap in current approaches, revealing their\ninadequate ability to fulfill the demanding prerequisites of cross-lane or\nclosed-loop simulation.", "AI": {"tldr": "A synthetic dataset for novel driving view synthesis is introduced to address the limitations of real-world data in autonomous driving simulations, revealing gaps in current NVS methods.", "motivation": "Existing NVS methods fail to meet the demands of closed-loop simulations, especially for rendering views beyond the original trajectory (e.g., cross-lane views).", "method": "A synthetic dataset with deviated trajectories (1-4 meters) is created, covering diverse conditions, to benchmark NVS methods in autonomous driving contexts.", "result": "The dataset highlights the inadequacy of current NVS approaches in handling cross-lane or closed-loop simulation requirements.", "conclusion": "The study underscores the need for improved NVS methods tailored to autonomous driving simulations, using the provided dataset as a benchmark."}}
{"id": "2503.07158", "pdf": "https://arxiv.org/pdf/2503.07158", "abs": "https://arxiv.org/abs/2503.07158", "authors": ["Longchao Da", "Tiejin Chen", "Zhuoheng Li", "Shreyas Bachiraju", "Huaiyuan Yao", "Li Li", "Yushun Dong", "Xiyang Hu", "Zhengzhong Tu", "Dongjie Wang", "Yue Zhao", "Ben Zhou", "Ram Pendyala", "Benjamin Stabler", "Yezhou Yang", "Xuesong Zhou", "Hua Wei"], "title": "Generative AI in Transportation Planning: A Survey", "categories": ["cs.AI", "68T99, 90B06", "I.2.6; I.2.8; I.6.3; J.2"], "comment": "55 pages", "summary": "The integration of generative artificial intelligence (GenAI) into\ntransportation planning has the potential to revolutionize tasks such as demand\nforecasting, infrastructure design, policy evaluation, and traffic simulation.\nHowever, there is a critical need for a systematic framework to guide the\nadoption of GenAI in this interdisciplinary domain. In this survey, we, a\nmultidisciplinary team of researchers spanning computer science and\ntransportation engineering, present the first comprehensive framework for\nleveraging GenAI in transportation planning. Specifically, we introduce a new\ntaxonomy that categorizes existing applications and methodologies into two\nperspectives: transportation planning tasks and computational techniques. From\nthe transportation planning perspective, we examine the role of GenAI in\nautomating descriptive, predictive, generative, simulation, and explainable\ntasks to enhance mobility systems. From the computational perspective, we\ndetail advancements in data preparation, domain-specific fine-tuning, and\ninference strategies, such as retrieval-augmented generation and zero-shot\nlearning tailored to transportation applications. Additionally, we address\ncritical challenges, including data scarcity, explainability, bias mitigation,\nand the development of domain-specific evaluation frameworks that align with\ntransportation goals like sustainability, equity, and system efficiency. This\nsurvey aims to bridge the gap between traditional transportation planning\nmethodologies and modern AI techniques, fostering collaboration and innovation.\nBy addressing these challenges and opportunities, we seek to inspire future\nresearch that ensures ethical, equitable, and impactful use of generative AI in\ntransportation planning.", "AI": {"tldr": "A survey introduces a framework for using generative AI (GenAI) in transportation planning, categorizing applications by tasks and techniques, and addressing challenges like data scarcity and bias.", "motivation": "The need for a systematic framework to guide GenAI adoption in transportation planning, bridging gaps between traditional methods and modern AI.", "method": "Introduces a taxonomy categorizing GenAI applications into transportation tasks (descriptive, predictive, etc.) and computational techniques (data preparation, fine-tuning, etc.).", "result": "Provides a comprehensive framework for GenAI in transportation, highlighting advancements and challenges like explainability and bias mitigation.", "conclusion": "Aims to foster collaboration and innovation, ensuring ethical and impactful use of GenAI in transportation planning."}}
{"id": "2407.01866", "pdf": "https://arxiv.org/pdf/2407.01866", "abs": "https://arxiv.org/abs/2407.01866", "authors": ["Yunxiang Zhang", "Bingxuan Li", "Alexandr Kuznetsov", "Akshay Jindal", "Stavros Diolatzis", "Kenneth Chen", "Anton Sochenov", "Anton Kaplanyan", "Qi Sun"], "title": "Image-GS: Content-Adaptive Image Representation via 2D Gaussians", "categories": ["cs.CV", "cs.GR"], "comment": "ACM SIGGRAPH 2025 Conference Proceedings", "summary": "Neural image representations have emerged as a promising approach for\nencoding and rendering visual data. Combined with learning-based workflows,\nthey demonstrate impressive trade-offs between visual fidelity and memory\nfootprint. Existing methods in this domain, however, often rely on fixed data\nstructures that suboptimally allocate memory or compute-intensive implicit\nmodels, hindering their practicality for real-time graphics applications.\n  Inspired by recent advancements in radiance field rendering, we introduce\nImage-GS, a content-adaptive image representation based on 2D Gaussians.\nLeveraging a custom differentiable renderer, Image-GS reconstructs images by\nadaptively allocating and progressively optimizing a group of anisotropic,\ncolored 2D Gaussians. It achieves a favorable balance between visual fidelity\nand memory efficiency across a variety of stylized images frequently seen in\ngraphics workflows, especially for those showing non-uniformly distributed\nfeatures and in low-bitrate regimes. Moreover, it supports hardware-friendly\nrapid random access for real-time usage, requiring only 0.3K MACs to decode a\npixel. Through error-guided progressive optimization, Image-GS naturally\nconstructs a smooth level-of-detail hierarchy. We demonstrate its versatility\nwith several applications, including texture compression, semantics-aware\ncompression, and joint image compression and restoration.", "AI": {"tldr": "Image-GS introduces a content-adaptive image representation using 2D Gaussians, balancing visual fidelity and memory efficiency for real-time graphics.", "motivation": "Existing methods use fixed data structures or compute-heavy implicit models, limiting practicality for real-time applications.", "method": "Image-GS employs a custom differentiable renderer to adaptively allocate and optimize anisotropic, colored 2D Gaussians.", "result": "It achieves efficient memory usage and visual quality, supports rapid random access, and works well for stylized images.", "conclusion": "Image-GS is versatile, useful for texture compression, semantics-aware compression, and joint image tasks."}}
{"id": "2302.03669", "pdf": "https://arxiv.org/pdf/2302.03669", "abs": "https://arxiv.org/abs/2302.03669", "authors": ["Ming Zhu", "Xiao-Yang Liu", "Sem Borst", "Anwar Walid"], "title": "Deep Reinforcement Learning for Traffic Light Control in Intelligent Transportation Systems", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages", "summary": "Smart traffic lights in intelligent transportation systems (ITSs) are\nenvisioned to greatly increase traffic efficiency and reduce congestion. Deep\nreinforcement learning (DRL) is a promising approach to adaptively control\ntraffic lights based on the real-time traffic situation in a road network.\nHowever, conventional methods may suffer from poor scalability. In this paper,\nwe investigate deep reinforcement learning to control traffic lights, and both\ntheoretical analysis and numerical experiments show that the intelligent\nbehavior ``greenwave\" (i.e., a vehicle will see a progressive cascade of green\nlights, and not have to brake at any intersection) emerges naturally a grid\nroad network, which is proved to be the optimal policy in an avenue with\nmultiple cross streets. As a first step, we use two DRL algorithms for the\ntraffic light control problems in two scenarios. In a single road intersection,\nwe verify that the deep Q-network (DQN) algorithm delivers a thresholding\npolicy; and in a grid road network, we adopt the deep deterministic policy\ngradient (DDPG) algorithm. Secondly, numerical experiments show that the DQN\nalgorithm delivers the optimal control, and the DDPG algorithm with passive\nobservations has the capability to produce on its own a high-level intelligent\nbehavior in a grid road network, namely, the ``greenwave\" policy emerges. We\nalso verify the ``greenwave\" patterns in a $5 \\times 10$ grid road network.\nThirdly, the ``greenwave\" patterns demonstrate that DRL algorithms produce\nfavorable solutions since the ``greenwave\" policy shown in experiment results\nis proved to be optimal in a specified traffic model (an avenue with multiple\ncross streets). The delivered policies both in a single road intersection and a\ngrid road network demonstrate the scalability of DRL algorithms.", "AI": {"tldr": "The paper explores deep reinforcement learning (DRL) for adaptive traffic light control, showing scalability and optimal 'greenwave' behavior in grid networks.", "motivation": "To improve traffic efficiency and reduce congestion in intelligent transportation systems using scalable DRL methods.", "method": "Uses DQN for single intersections and DDPG for grid networks, demonstrating 'greenwave' behavior.", "result": "DQN delivers optimal control in single intersections; DDPG produces 'greenwave' in grids, proven optimal.", "conclusion": "DRL is scalable and effective for traffic light control, with 'greenwave' emerging as optimal behavior."}}
{"id": "2505.03831", "pdf": "https://arxiv.org/pdf/2505.03831", "abs": "https://arxiv.org/abs/2505.03831", "authors": ["Esra Hoto\u011flu", "Sevil Sen", "Burcu Can"], "title": "A Comprehensive Analysis of Adversarial Attacks against Spam Filters", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Deep learning has revolutionized email filtering, which is critical to\nprotect users from cyber threats such as spam, malware, and phishing. However,\nthe increasing sophistication of adversarial attacks poses a significant\nchallenge to the effectiveness of these filters. This study investigates the\nimpact of adversarial attacks on deep learning-based spam detection systems\nusing real-world datasets. Six prominent deep learning models are evaluated on\nthese datasets, analyzing attacks at the word, character sentence, and\nAI-generated paragraph-levels. Novel scoring functions, including spam weights\nand attention weights, are introduced to improve attack effectiveness. This\ncomprehensive analysis sheds light on the vulnerabilities of spam filters and\ncontributes to efforts to improve their security against evolving adversarial\nthreats.", "AI": {"tldr": "The paper examines adversarial attacks on deep learning-based spam filters, evaluating six models and introducing novel scoring functions to assess vulnerabilities.", "motivation": "The increasing sophistication of adversarial attacks threatens the effectiveness of deep learning-based email filters, necessitating a study to understand and mitigate these vulnerabilities.", "method": "Six deep learning models are evaluated on real-world datasets, with attacks analyzed at word, character, sentence, and AI-generated paragraph levels. Novel scoring functions (spam and attention weights) are introduced.", "result": "The study reveals vulnerabilities in spam filters and demonstrates the effectiveness of the proposed scoring functions in improving attack assessment.", "conclusion": "The findings highlight the need for enhanced security measures in spam filters to counter evolving adversarial threats."}}
{"id": "2409.00313", "pdf": "https://arxiv.org/pdf/2409.00313", "abs": "https://arxiv.org/abs/2409.00313", "authors": ["Sandra Zhang Ding", "Jiafeng Mao", "Kiyoharu Aizawa"], "title": "Training-Free Sketch-Guided Diffusion with Latent Optimization", "categories": ["cs.CV"], "comment": "8 pages", "summary": "Based on recent advanced diffusion models, Text-to-image (T2I) generation\nmodels have demonstrated their capabilities to generate diverse and\nhigh-quality images. However, leveraging their potential for real-world content\ncreation, particularly in providing users with precise control over the image\ngeneration result, poses a significant challenge. In this paper, we propose an\ninnovative training-free pipeline that extends existing text-to-image\ngeneration models to incorporate a sketch as an additional condition. To\ngenerate new images with a layout and structure closely resembling the input\nsketch, we find that these core features of a sketch can be tracked with the\ncross-attention maps of diffusion models. We introduce latent optimization, a\nmethod that refines the noisy latent at each intermediate step of the\ngeneration process using cross-attention maps to ensure that the generated\nimages adhere closely to the desired structure outlined in the reference\nsketch. Through latent optimization, our method enhances the accuracy of image\ngeneration, offering users greater control and customization options in content\ncreation.", "AI": {"tldr": "A training-free pipeline enhances text-to-image models by using sketches for precise control, leveraging cross-attention maps and latent optimization.", "motivation": "To provide users with precise control over image generation in real-world content creation, addressing limitations of current text-to-image models.", "method": "Uses cross-attention maps to track sketch features and introduces latent optimization to refine noisy latents during generation.", "result": "Improved accuracy in generating images that closely follow the structure of input sketches.", "conclusion": "The method offers greater user control and customization in content creation without additional training."}}
{"id": "2307.11079", "pdf": "https://arxiv.org/pdf/2307.11079", "abs": "https://arxiv.org/abs/2307.11079", "authors": ["Chenyang Qiu", "Yingsheng Geng", "Junrui Lu", "Kaida Chen", "Shitong Zhu", "Ya Su", "Guoshun Nan", "Can Zhang", "Junsong Fu", "Qimei Cui", "Xiaofeng Tao"], "title": "3D-IDS: Doubly Disentangled Dynamic Intrusion Detection", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SI"], "comment": "Published in the proceedings of the KDD 2023 Research Track", "summary": "Network-based intrusion detection system (NIDS) monitors network traffic for\nmalicious activities, forming the frontline defense against increasing attacks\nover information infrastructures. Although promising, our quantitative analysis\nshows that existing methods perform inconsistently in declaring various unknown\nattacks (e.g., 9% and 35% F1 respectively for two distinct unknown threats for\nan SVM-based method) or detecting diverse known attacks (e.g., 31% F1 for the\nBackdoor and 93% F1 for DDoS by a GCN-based state-of-the-art method), and\nreveals that the underlying cause is entangled distributions of flow features.\nThis motivates us to propose 3D-IDS, a novel method that aims to tackle the\nabove issues through two-step feature disentanglements and a dynamic graph\ndiffusion scheme. Specifically, we first disentangle traffic features by a\nnon-parameterized optimization based on mutual information, automatically\ndifferentiating tens and hundreds of complex features of various attacks. Such\ndifferentiated features will be fed into a memory model to generate\nrepresentations, which are further disentangled to highlight the\nattack-specific features. Finally, we use a novel graph diffusion method that\ndynamically fuses the network topology for spatial-temporal aggregation in\nevolving data streams. By doing so, we can effectively identify various attacks\nin encrypted traffics, including unknown threats and known ones that are not\neasily detected. Experiments show the superiority of our 3D-IDS. We also\ndemonstrate that our two-step feature disentanglements benefit the\nexplainability of NIDS.", "AI": {"tldr": "3D-IDS improves NIDS by disentangling traffic features and using dynamic graph diffusion, addressing inconsistent performance in detecting known and unknown attacks.", "motivation": "Existing NIDS methods perform inconsistently due to entangled flow features, motivating the need for a better approach.", "method": "3D-IDS uses two-step feature disentanglement (mutual information optimization and memory model) and dynamic graph diffusion for spatial-temporal aggregation.", "result": "3D-IDS effectively identifies various attacks, including unknown threats, and improves explainability.", "conclusion": "3D-IDS outperforms existing methods and enhances NIDS explainability through feature disentanglement."}}
{"id": "2505.03858", "pdf": "https://arxiv.org/pdf/2505.03858", "abs": "https://arxiv.org/abs/2505.03858", "authors": ["Alireza Khayatian", "Anil Vullikanti", "Aritra Konar"], "title": "Differentially Private Densest-$k$-Subgraph", "categories": ["cs.DS", "cs.LG"], "comment": null, "summary": "Many graph datasets involve sensitive network data, motivating the need for\nprivacy-preserving graph mining. The Densest-$k$-subgraph (D$k$S) problem is a\nkey primitive in graph mining that aims to extract a subset of $k$ vertices\nwith the maximum internal connectivity. Although non-private algorithms are\nknown for D$k$S, this paper is the first to design algorithms that offer formal\ndifferential privacy (DP) guarantees for the problem. We base our general\napproach on using the principal component (PC) of the graph adjacency matrix to\noutput a subset of $k$ vertices under edge DP. For this task, we first consider\noutput perturbation, which traditionally offer good scalability, but at the\nexpense of utility. Our tight on the local sensitivity indicate a big gap with\nthe global sensitivity, motivating the use of instance specific sensitive\nmethods for private PC. Next, we derive a tight bound on the smooth sensitivity\nand show that it can be close to the global sensitivity. This leads us to\nconsider the Propose-Test-Release (PTR) framework for private PC. Although\ncomputationally expensive in general, we design a novel approach for\nimplementing PTR in the same time as computation of a non-private PC, while\noffering good utility for \\DkS{}. Additionally, we also consider the iterative\nprivate power method (PPM) for private PC, albeit it is significantly slower\nthan PTR on large networks. We run our methods on diverse real-world networks,\nwith the largest having 3 million vertices, and show good privacy-utility\ntrade-offs. Although PTR requires a slightly larger privacy budget, on average,\nit achieves a 180-fold improvement in runtime over PPM.", "AI": {"tldr": "This paper introduces the first differentially private algorithms for the Densest-$k$-subgraph (D$k$S) problem, focusing on privacy-preserving graph mining. It explores methods like output perturbation, Propose-Test-Release (PTR), and private power method (PPM), with PTR showing significant runtime advantages.", "motivation": "The need for privacy-preserving graph mining arises from sensitive network data in many graph datasets. The D$k$S problem, a key primitive in graph mining, lacks private algorithms, motivating this work.", "method": "The approach uses the principal component (PC) of the graph adjacency matrix under edge differential privacy (DP). Methods include output perturbation, PTR (with tight smooth sensitivity bounds), and PPM.", "result": "PTR offers a 180-fold runtime improvement over PPM while maintaining utility. The largest tested network had 3 million vertices, showing scalability.", "conclusion": "The paper successfully designs private algorithms for D$k$S, with PTR being a practical choice due to its balance of privacy, utility, and efficiency."}}
{"id": "2409.01341", "pdf": "https://arxiv.org/pdf/2409.01341", "abs": "https://arxiv.org/abs/2409.01341", "authors": ["Siqi Luo", "Yi Xin", "Yuntao Du", "Zhongwei Wan", "Tao Tan", "Guangtao Zhai", "Xiaohong Liu"], "title": "Enhancing Test Time Adaptation with Few-shot Guidance", "categories": ["cs.CV"], "comment": "17 pages, 8 figures", "summary": "Deep neural networks often encounter significant performance drops while\nfacing with domain shifts between training (source) and test (target) data. To\naddress this issue, Test Time Adaptation (TTA) methods have been proposed to\nadapt pre-trained source model to handle out-of-distribution streaming target\ndata. Although these methods offer some relief, they lack a reliable mechanism\nfor domain shift correction, which can often be erratic in real-world\napplications. In response, we develop Few-Shot Test Time Adaptation (FS-TTA), a\nnovel and practical setting that utilizes a few-shot support set on top of TTA.\nAdhering to the principle of few inputs, big gains, FS-TTA reduces blind\nexploration in unseen target domains. Furthermore, we propose a two-stage\nframework to tackle FS-TTA, including (i) fine-tuning the pre-trained source\nmodel with few-shot support set, along with using feature diversity\naugmentation module to avoid overfitting, (ii) implementing test time\nadaptation based on prototype memory bank guidance to produce high quality\npseudo-label for model adaptation. Through extensive experiments on three\ncross-domain classification benchmarks, we demonstrate the superior performance\nand reliability of our FS-TTA and framework.", "AI": {"tldr": "FS-TTA introduces a few-shot support set to improve Test Time Adaptation (TTA), reducing blind exploration in unseen target domains with a two-stage framework for better performance.", "motivation": "Addressing the unreliability of existing TTA methods in handling domain shifts between training and test data.", "method": "A two-stage framework: (i) fine-tuning with few-shot support set and feature diversity augmentation, (ii) test time adaptation using prototype memory bank guidance.", "result": "Superior performance and reliability demonstrated on three cross-domain classification benchmarks.", "conclusion": "FS-TTA is a practical and effective solution for domain shift correction in real-world applications."}}
{"id": "2402.17767", "pdf": "https://arxiv.org/pdf/2402.17767", "abs": "https://arxiv.org/abs/2402.17767", "authors": ["Arjun Gupta", "Michelle Zhang", "Rishik Sathua", "Saurabh Gupta"], "title": "Opening Articulated Structures in the Real World", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "Accepted to RSS 2025. Project webpage:\n  https://arjung128.github.io/opening-articulated-structures/", "summary": "What does it take to build mobile manipulation systems that can competently\noperate on previously unseen objects in previously unseen environments? This\nwork answers this question using opening of articulated structures as a mobile\nmanipulation testbed. Specifically, our focus is on the end-to-end performance\non this task without any privileged information, i.e. the robot starts at a\nlocation with the novel target articulated object in view, and has to approach\nthe object and successfully open it. We first develop a system for this task,\nand then conduct 100+ end-to-end system tests across 13 real world test sites.\nOur large-scale study reveals a number of surprising findings: a) modular\nsystems outperform end-to-end learned systems for this task, even when the\nend-to-end learned systems are trained on 1000+ demonstrations, b) perception,\nand not precise end-effector control, is the primary bottleneck to task\nsuccess, and c) state-of-the-art articulation parameter estimation models\ndeveloped in isolation struggle when faced with robot-centric viewpoints.\nOverall, our findings highlight the limitations of developing components of the\npipeline in isolation and underscore the need for system-level research,\nproviding a pragmatic roadmap for building generalizable mobile manipulation\nsystems. Videos, code, and models are available on the project website:\nhttps://arjung128.github.io/opening-articulated-structures/", "AI": {"tldr": "The paper explores building mobile manipulation systems for unseen objects and environments, focusing on opening articulated structures. It compares modular and end-to-end learned systems, revealing modular systems' superiority, perception as the main bottleneck, and challenges in articulation parameter estimation.", "motivation": "To understand how to create mobile manipulation systems capable of operating on unseen objects in unfamiliar environments, using opening articulated structures as a test case.", "method": "Developed a system for the task and conducted 100+ end-to-end tests across 13 real-world sites, comparing modular and end-to-end learned approaches.", "result": "Modular systems outperformed end-to-end learned ones; perception was the key bottleneck; articulation parameter estimation models struggled with robot-centric views.", "conclusion": "Highlights the need for system-level research over isolated component development, providing a roadmap for generalizable mobile manipulation systems."}}
{"id": "2505.03862", "pdf": "https://arxiv.org/pdf/2505.03862", "abs": "https://arxiv.org/abs/2505.03862", "authors": ["H\u00f4ng V\u00e2n L\u00ea", "H\u00e0 Quang Minh", "Frederic Protin", "Wilderich Tuschmann"], "title": "Categorical and geometric methods in statistical, manifold, and machine learning", "categories": ["stat.ML", "cs.LG", "math.CT", "math.DG", "math.ST", "stat.TH"], "comment": "37 p., will appear as part of a special volume in the Springer Tohoku\n  Series in Mathematics", "summary": "We present and discuss applications of the category of probabilistic\nmorphisms, initially developed in \\cite{Le2023}, as well as some geometric\nmethods to several classes of problems in statistical, machine and manifold\nlearning which shall be, along with many other topics, considered in depth in\nthe forthcoming book \\cite{LMPT2024}.", "AI": {"tldr": "Applications of probabilistic morphisms and geometric methods in statistical, machine, and manifold learning are explored.", "motivation": "To extend the use of probabilistic morphisms and geometric techniques to diverse learning problems.", "method": "Utilizes probabilistic morphisms and geometric approaches.", "result": "Potential applications in statistical, machine, and manifold learning are identified.", "conclusion": "The methods show promise for broader learning applications, with further details to be published."}}
{"id": "2409.19911", "pdf": "https://arxiv.org/pdf/2409.19911", "abs": "https://arxiv.org/abs/2409.19911", "authors": ["Xiang Wang", "Shiwei Zhang", "Haonan Qiu", "Ruihang Chu", "Zekun Li", "Yingya Zhang", "Changxin Gao", "Yuehuan Wang", "Chunhua Shen", "Nong Sang"], "title": "Replace Anyone in Videos", "categories": ["cs.CV"], "comment": null, "summary": "The field of controllable human-centric video generation has witnessed\nremarkable progress, particularly with the advent of diffusion models. However,\nachieving precise and localized control over human motion in videos, such as\nreplacing or inserting individuals while preserving desired motion patterns,\nstill remains a formidable challenge. In this work, we present the\nReplaceAnyone framework, which focuses on localized human replacement and\ninsertion featuring intricate backgrounds. Specifically, we formulate this task\nas an image-conditioned video inpainting paradigm with pose guidance, utilizing\na unified end-to-end video diffusion architecture that facilitates\nimage-conditioned video inpainting within masked regions. To prevent shape\nleakage and enable granular local control, we introduce diverse mask forms\ninvolving both regular and irregular shapes. Furthermore, we implement an\nenriched visual guidance mechanism to enhance appearance alignment, a hybrid\ninpainting encoder to further preserve the detailed background information in\nthe masked video, and a two-phase optimization methodology to simplify the\ntraining difficulty. ReplaceAnyone enables seamless replacement or insertion of\ncharacters while maintaining the desired pose motion and reference appearance\nwithin a single framework. Extensive experimental results demonstrate the\neffectiveness of our method in generating realistic and coherent video content.\nThe proposed ReplaceAnyone can be seamlessly applied not only to traditional\n3D-UNet base models but also to DiT-based video models such as Wan2.1. The code\nwill be available at https://github.com/ali-vilab/UniAnimate-DiT.", "AI": {"tldr": "ReplaceAnyone is a framework for localized human replacement and insertion in videos, using a diffusion-based approach with pose guidance and mask diversity for precise control.", "motivation": "Precise control over human motion in videos, such as replacing or inserting individuals while preserving motion patterns, remains challenging despite advancements in diffusion models.", "method": "The method uses an image-conditioned video inpainting paradigm with pose guidance, diverse masks, a hybrid inpainting encoder, and a two-phase optimization for training.", "result": "ReplaceAnyone achieves realistic and coherent video content with seamless character replacement or insertion, maintaining desired motion and appearance.", "conclusion": "The framework is effective and adaptable, working with both 3D-UNet and DiT-based models, and will be publicly available."}}
{"id": "2406.09713", "pdf": "https://arxiv.org/pdf/2406.09713", "abs": "https://arxiv.org/abs/2406.09713", "authors": ["Christian Raymond"], "title": "Meta-Learning Loss Functions for Deep Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "PhD thesis", "summary": "Humans can often quickly and efficiently solve complex new learning tasks\ngiven only a small set of examples. In contrast, modern artificially\nintelligent systems often require thousands or millions of observations in\norder to solve even the most basic tasks. Meta-learning aims to resolve this\nissue by leveraging past experiences from similar learning tasks to embed the\nappropriate inductive biases into the learning system. Historically methods for\nmeta-learning components such as optimizers, parameter initializations, and\nmore have led to significant performance increases. This thesis aims to explore\nthe concept of meta-learning to improve performance, through the\noften-overlooked component of the loss function. The loss function is a vital\ncomponent of a learning system, as it represents the primary learning\nobjective, where success is determined and quantified by the system's ability\nto optimize for that objective successfully.", "AI": {"tldr": "Meta-learning improves AI performance by leveraging past experiences, focusing on optimizing loss functions for better learning efficiency.", "motivation": "Humans learn quickly from few examples, while AI systems require extensive data. Meta-learning addresses this gap by embedding inductive biases from past tasks.", "method": "Explores meta-learning, particularly optimizing loss functions, to enhance learning efficiency and performance.", "result": "Meta-learning, especially loss function optimization, can significantly improve AI learning systems.", "conclusion": "Optimizing loss functions through meta-learning is a promising approach to enhance AI performance and efficiency."}}
{"id": "2505.03906", "pdf": "https://arxiv.org/pdf/2505.03906", "abs": "https://arxiv.org/abs/2505.03906", "authors": ["Asif Rahman", "Veljko Cvetkovic", "Kathleen Reece", "Aidan Walters", "Yasir Hassan", "Aneesh Tummeti", "Bryan Torres", "Denise Cooney", "Margaret Ellis", "Dimitrios S. Nikolopoulos"], "title": "MARCO: A Multi-Agent System for Optimizing HPC Code Generation Using Large Language Models", "categories": ["cs.DC", "cs.LG", "cs.SE"], "comment": "9 pages, 4 figures, 2 tables", "summary": "Large language models (LLMs) have transformed software development through\ncode generation capabilities, yet their effectiveness for high-performance\ncomputing (HPC) remains limited. HPC code requires specialized optimizations\nfor parallelism, memory efficiency, and architecture-specific considerations\nthat general-purpose LLMs often overlook. We present MARCO (Multi-Agent\nReactive Code Optimizer), a novel framework that enhances LLM-generated code\nfor HPC through a specialized multi-agent architecture. MARCO employs separate\nagents for code generation and performance evaluation, connected by a feedback\nloop that progressively refines optimizations. A key innovation is MARCO's\nweb-search component that retrieves real-time optimization techniques from\nrecent conference proceedings and research publications, bridging the knowledge\ngap in pre-trained LLMs. Our extensive evaluation on the LeetCode 75 problem\nset demonstrates that MARCO achieves a 14.6% average runtime reduction compared\nto Claude 3.5 Sonnet alone, while the integration of the web-search component\nyields a 30.9% performance improvement over the base MARCO system. These\nresults highlight the potential of multi-agent systems to address the\nspecialized requirements of high-performance code generation, offering a\ncost-effective alternative to domain-specific model fine-tuning.", "AI": {"tldr": "MARCO enhances LLM-generated HPC code via a multi-agent framework with real-time optimization feedback, achieving significant performance improvements.", "motivation": "General-purpose LLMs lack specialized optimizations for HPC code, limiting their effectiveness in high-performance computing.", "method": "MARCO uses a multi-agent architecture with code generation and performance evaluation agents, plus a web-search component for real-time optimizations.", "result": "MARCO reduces runtime by 14.6% vs. Claude 3.5 Sonnet and achieves 30.9% improvement with web-search integration.", "conclusion": "Multi-agent systems like MARCO offer a cost-effective solution for HPC code generation, outperforming general-purpose LLMs."}}
{"id": "2410.04634", "pdf": "https://arxiv.org/pdf/2410.04634", "abs": "https://arxiv.org/abs/2410.04634", "authors": ["Salma S. Abdel Magid", "Weiwei Pan", "Simon Warchol", "Grace Guo", "Junsik Kim", "Mahia Rahman", "Hanspeter Pfister"], "title": "Is What You Ask For What You Get? Investigating Concept Associations in Text-to-Image Models", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-image (T2I) models are increasingly used in impactful real-life\napplications. As such, there is a growing need to audit these models to ensure\nthat they generate desirable, task-appropriate images. However, systematically\ninspecting the associations between prompts and generated content in a\nhuman-understandable way remains challenging. To address this, we propose\nConcept2Concept, a framework where we characterize conditional distributions of\nvision language models using interpretable concepts and metrics that can be\ndefined in terms of these concepts. This characterization allows us to use our\nframework to audit models and prompt-datasets. To demonstrate, we investigate\nseveral case studies of conditional distributions of prompts, such as\nuser-defined distributions or empirical, real-world distributions. Lastly, we\nimplement Concept2Concept as an open-source interactive visualization tool to\nfacilitate use by non-technical end-users. A demo is available at\nhttps://tinyurl.com/Concept2ConceptDemo.", "AI": {"tldr": "Concept2Concept is a framework for auditing T2I models by characterizing their conditional distributions using interpretable concepts and metrics, aiding in human-understandable analysis.", "motivation": "The need to audit T2I models for generating task-appropriate images and understanding prompt-content associations systematically.", "method": "Proposes Concept2Concept, a framework using interpretable concepts and metrics to characterize conditional distributions of vision language models.", "result": "Demonstrated through case studies of prompt distributions and implemented as an open-source interactive tool for non-technical users.", "conclusion": "Concept2Concept provides a practical solution for auditing T2I models and datasets, making the process accessible to a broader audience."}}
{"id": "2410.06523", "pdf": "https://arxiv.org/pdf/2410.06523", "abs": "https://arxiv.org/abs/2410.06523", "authors": ["Sejin Kim", "Kyung Kiu Kim", "Yunseok Seo"], "title": "Phase Diagram from Nonlinear Interaction between Superconducting Order and Density: Toward Data-Based Holographic Superconductor", "categories": ["hep-th", "cond-mat.dis-nn", "cond-mat.supr-con", "cs.AI"], "comment": "22 pages, 20 figures, published version in JHEP", "summary": "We address an inverse problem in modeling holographic superconductors. We\nfocus our research on the critical temperature behavior depicted by\nexperiments. We use a physics-informed neural network method to find a mass\nfunction $M(F^2)$, which is necessary to understand phase transition behavior.\nThis mass function describes a nonlinear interaction between superconducting\norder and charge carrier density. We introduce positional embedding layers to\nimprove the learning process in our algorithm, and the Adam optimization is\nused to predict the critical temperature data via holographic calculation with\nappropriate accuracy. Consideration of the positional embedding layers is\nmotivated by the transformer model of natural-language processing in the\nartificial intelligence (AI) field. We obtain holographic models that reproduce\nborderlines of the normal and superconducting phases provided by actual data.\nOur work is the first holographic attempt to match phase transition data\nquantitatively obtained from experiments. Also, the present work offers a new\nmethodology for data-based holographic models.", "AI": {"tldr": "The paper uses physics-informed neural networks to model holographic superconductors, focusing on critical temperature behavior. It introduces positional embedding layers for improved learning and matches experimental phase transition data.", "motivation": "To quantitatively match experimental phase transition data in holographic superconductors and develop a new data-based modeling methodology.", "method": "Physics-informed neural networks with positional embedding layers and Adam optimization to predict critical temperature via holographic calculations.", "result": "Holographic models reproduce experimental phase transition borderlines, achieving quantitative agreement with actual data.", "conclusion": "This work is the first to quantitatively match experimental phase transition data in holographic superconductors and introduces a novel data-based modeling approach."}}
{"id": "2505.04007", "pdf": "https://arxiv.org/pdf/2505.04007", "abs": "https://arxiv.org/abs/2505.04007", "authors": ["Yinzhuang Yi", "Jorge Cort\u00e9s", "Nikolay Atanasov"], "title": "Variational Formulation of the Particle Flow Particle Filter", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This paper provides a formulation of the particle flow particle filter from\nthe perspective of variational inference. We show that the transient density\nused to derive the particle flow particle filter follows a time-scaled\ntrajectory of the Fisher-Rao gradient flow in the space of probability\ndensities. The Fisher-Rao gradient flow is obtained as a continuous-time\nalgorithm for variational inference, minimizing the Kullback-Leibler divergence\nbetween a variational density and the true posterior density.", "AI": {"tldr": "The paper reformulates the particle flow particle filter using variational inference, linking it to the Fisher-Rao gradient flow for minimizing KL divergence.", "motivation": "To provide a variational inference perspective on the particle flow particle filter and connect it to the Fisher-Rao gradient flow.", "method": "The transient density in the particle flow particle filter is shown to follow a time-scaled Fisher-Rao gradient flow trajectory.", "result": "The Fisher-Rao gradient flow serves as a continuous-time algorithm for variational inference, minimizing KL divergence between variational and true posterior densities.", "conclusion": "The paper successfully bridges the particle flow particle filter with variational inference through the Fisher-Rao gradient flow framework."}}
{"id": "2412.03255", "pdf": "https://arxiv.org/pdf/2412.03255", "abs": "https://arxiv.org/abs/2412.03255", "authors": ["Qingdong He", "Jinlong Peng", "Pengcheng Xu", "Boyuan Jiang", "Xiaobin Hu", "Donghao Luo", "Yong Liu", "Yabiao Wang", "Chengjie Wang", "Xiangtai Li", "Jiangning Zhang"], "title": "DynamicControl: Adaptive Condition Selection for Improved Text-to-Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "To enhance the controllability of text-to-image diffusion models, current\nControlNet-like models have explored various control signals to dictate image\nattributes. However, existing methods either handle conditions inefficiently or\nuse a fixed number of conditions, which does not fully address the complexity\nof multiple conditions and their potential conflicts. This underscores the need\nfor innovative approaches to manage multiple conditions effectively for more\nreliable and detailed image synthesis. To address this issue, we propose a\nnovel framework, DynamicControl, which supports dynamic combinations of diverse\ncontrol signals, allowing adaptive selection of different numbers and types of\nconditions. Our approach begins with a double-cycle controller that generates\nan initial real score sorting for all input conditions by leveraging\npre-trained conditional generation models and discriminative models. This\ncontroller evaluates the similarity between extracted conditions and input\nconditions, as well as the pixel-level similarity with the source image. Then,\nwe integrate a Multimodal Large Language Model (MLLM) to build an efficient\ncondition evaluator. This evaluator optimizes the ordering of conditions based\non the double-cycle controller's score ranking. Our method jointly optimizes\nMLLMs and diffusion models, utilizing MLLMs' reasoning capabilities to\nfacilitate multi-condition text-to-image (T2I) tasks. The final sorted\nconditions are fed into a parallel multi-control adapter, which learns feature\nmaps from dynamic visual conditions and integrates them to modulate ControlNet,\nthereby enhancing control over generated images. Through both quantitative and\nqualitative comparisons, DynamicControl demonstrates its superiority over\nexisting methods in terms of controllability, generation quality and\ncomposability under various conditional controls.", "AI": {"tldr": "DynamicControl is a novel framework for text-to-image diffusion models that dynamically manages multiple control signals, improving controllability and image quality.", "motivation": "Existing methods inefficiently handle or fix the number of conditions, limiting their ability to address complex or conflicting conditions in image synthesis.", "method": "The framework uses a double-cycle controller for initial condition scoring, integrates a Multimodal Large Language Model (MLLM) for condition evaluation, and employs a parallel multi-control adapter to modulate ControlNet.", "result": "DynamicControl outperforms existing methods in controllability, generation quality, and composability under diverse conditions.", "conclusion": "The proposed framework effectively addresses the limitations of current methods by dynamically managing multiple conditions, enhancing text-to-image synthesis."}}
{"id": "2410.07547", "pdf": "https://arxiv.org/pdf/2410.07547", "abs": "https://arxiv.org/abs/2410.07547", "authors": ["Zecheng Hao", "Yifan Huang", "Zijie Xu", "Wenxuan Liu", "Yuanhong Tang", "Zhaofei Yu", "Tiejun Huang"], "title": "HM-DF SNN: Transcending Conventional Online Learning with Advanced Training and Deployment", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "Spiking Neural Networks (SNNs) are considered to have enormous potential in\nthe future development of Artificial Intelligence due to their brain-inspired\nand energy-efficient properties. Compared to vanilla Spatial-Temporal\nBack-propagation (STBP) training methods, online training can effectively\novercome the risk of GPU memory explosion. However, current online learning\nframework cannot tackle the inseparability problem of temporal dependent\ngradients and merely aim to optimize the training memory, resulting in no\nperformance advantages compared to the STBP training models in the inference\nphase. To address the aforementioned challenges, we propose Hybrid\nMechanism-Driven Firing (HM-DF) model, which is a family of advanced models\nthat respectively adopt different spiking calculation schemes in the\nupper-region and lower-region of the firing threshold. We point out that HM-DF\nmodel can effectively separate temporal gradients and tackle the mismatch\nproblem of surrogate gradients, as well as achieving full-stage optimization\ntowards computation speed and memory footprint. Experimental results have\ndemonstrated that HM-DF model can be flexibly combined with various techniques\nto achieve state-of-the-art performance in the field of online learning,\nwithout triggering further power consumption.", "AI": {"tldr": "HM-DF model improves SNN online learning by separating temporal gradients and optimizing computation speed and memory, outperforming STBP without extra power.", "motivation": "Current online learning for SNNs fails to handle temporal gradient inseparability and lacks performance advantages over STBP.", "method": "Proposes HM-DF model with hybrid spiking calculation schemes above and below the firing threshold.", "result": "HM-DF achieves state-of-the-art performance in online learning without additional power consumption.", "conclusion": "HM-DF effectively addresses temporal gradient and surrogate gradient issues, optimizing SNN training and inference."}}
{"id": "2505.04037", "pdf": "https://arxiv.org/pdf/2505.04037", "abs": "https://arxiv.org/abs/2505.04037", "authors": ["Kang Liu", "Wei Peng", "Jianchen Hu"], "title": "Learning based convex approximation for constrained parametric optimization", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "We propose an input convex neural network (ICNN)-based self-supervised\nlearning framework to solve continuous constrained optimization problems. By\nintegrating the augmented Lagrangian method (ALM) with the constraint\ncorrection mechanism, our framework ensures \\emph{non-strict constraint\nfeasibility}, \\emph{better optimality gap}, and \\emph{best convergence rate}\nwith respect to the state-of-the-art learning-based methods. We provide a\nrigorous convergence analysis, showing that the algorithm converges to a\nKarush-Kuhn-Tucker (KKT) point of the original problem even when the internal\nsolver is a neural network, and the approximation error is bounded. We test our\napproach on a range of benchmark tasks including quadratic programming (QP),\nnonconvex programming, and large-scale AC optimal power flow problems. The\nresults demonstrate that compared to existing solvers (e.g., \\texttt{OSQP},\n\\texttt{IPOPT}) and the latest learning-based methods (e.g., DC3, PDL), our\napproach achieves a superior balance among accuracy, feasibility, and\ncomputational efficiency.", "AI": {"tldr": "An ICNN-based self-supervised learning framework for constrained optimization, ensuring feasibility, optimality, and convergence, outperforming existing solvers.", "motivation": "To address continuous constrained optimization problems with better feasibility, optimality, and convergence than current learning-based methods.", "method": "Integrates augmented Lagrangian method (ALM) with constraint correction in an ICNN framework, ensuring non-strict feasibility and bounded approximation error.", "result": "Superior accuracy, feasibility, and efficiency compared to solvers like OSQP, IPOPT, and learning-based methods like DC3 and PDL.", "conclusion": "The framework reliably converges to KKT points and outperforms state-of-the-art methods in benchmark tasks."}}
{"id": "2412.03413", "pdf": "https://arxiv.org/pdf/2412.03413", "abs": "https://arxiv.org/abs/2412.03413", "authors": ["Andrea Asperti", "Ali Aydogdu", "Angelo Greco", "Fabio Merizzi", "Pietro Miraglio", "Beniamino Tartufoli", "Alessandro Testa", "Nadia Pinardi", "Paolo Oddo"], "title": "Deep Learning for Sea Surface Temperature Reconstruction under Cloud Occlusion", "categories": ["cs.CV", "I.4.5"], "comment": null, "summary": "Sea Surface Temperature (SST) reconstructions from satellite images affected\nby cloud gaps have been extensively documented in the past three decades. Here\nwe describe several Machine Learning models to fill the cloud-occluded areas\nstarting from MODIS Aqua nighttime L3 images. To tackle this challenge, we\nemployed a type of Convolutional Neural Network model (U-net) to reconstruct\ncloud-covered portions of satellite imagery while preserving the integrity of\nobserved values in cloud-free areas. We demonstrate the outstanding precision\nof U-net with respect to available products done using OI interpolation\nalgorithms. Our best-performing architecture show 50% lower root mean square\nerrors over established gap-filling methods.", "AI": {"tldr": "Machine Learning models, particularly U-net, outperform traditional methods in reconstructing cloud-occluded SST data from MODIS Aqua images, reducing errors by 50%.", "motivation": "Address the challenge of filling cloud gaps in SST reconstructions from satellite images, improving accuracy over existing methods.", "method": "Employed a U-net Convolutional Neural Network to reconstruct cloud-covered areas in MODIS Aqua nighttime L3 images, preserving observed values in cloud-free regions.", "result": "U-net achieved 50% lower root mean square errors compared to traditional OI interpolation algorithms.", "conclusion": "U-net is a highly precise and effective solution for SST reconstruction in cloud-affected satellite imagery."}}
{"id": "2410.19550", "pdf": "https://arxiv.org/pdf/2410.19550", "abs": "https://arxiv.org/abs/2410.19550", "authors": ["Yu Qiao", "Lina Gong", "Yu Zhao", "Yongwei Wang", "Mingqiang Wei"], "title": "DeMuVGN: Effective Software Defect Prediction Model by Learning Multi-view Software Dependency via Graph Neural Networks", "categories": ["cs.SE", "cs.AI"], "comment": "The current paper is not comprehensive enough. We are seeking further\n  improvement", "summary": "Software defect prediction (SDP) aims to identify high-risk defect modules in\nsoftware development, optimizing resource allocation. While previous studies\nshow that dependency network metrics improve defect prediction, most methods\nfocus on code-based dependency graphs, overlooking developer factors. Current\nmetrics, based on handcrafted features like ego and global network metrics,\nfail to fully capture defect-related information. To address this, we propose\nDeMuVGN, a defect prediction model that learns multi-view software dependency\nvia graph neural networks. We introduce a Multi-view Software Dependency Graph\n(MSDG) that integrates data, call, and developer dependencies. DeMuVGN also\nleverages the Synthetic Minority Oversampling Technique (SMOTE) to address\nclass imbalance and enhance defect module identification. In a case study of\neight open-source projects across 20 versions, DeMuVGN demonstrates significant\nimprovements: i) models based on multi-view graphs improve F1 scores by 11.1%\nto 12.1% over single-view models; ii) DeMuVGN improves F1 scores by 17.4% to\n45.8% in within-project contexts and by 17.9% to 41.0% in cross-project\ncontexts. Additionally, DeMuVGN excels in software evolution, showing more\nimprovement in later-stage software versions. Its strong performance across\ndifferent projects highlights its generalizability. We recommend future\nresearch focus on multi-view dependency graphs for defect prediction in both\nmature and newly developed projects.", "AI": {"tldr": "DeMuVGN, a defect prediction model using multi-view dependency graphs and SMOTE, outperforms single-view models by 11.1%-12.1% in F1 scores and shows significant improvements in within- and cross-project contexts.", "motivation": "Existing defect prediction methods focus on code-based dependencies, neglecting developer factors and failing to fully capture defect-related information.", "method": "Proposes DeMuVGN, leveraging multi-view software dependency graphs (data, call, developer) and SMOTE for class imbalance.", "result": "DeMuVGN improves F1 scores by 17.4%-45.8% (within-project) and 17.9%-41.0% (cross-project), excelling in later-stage software versions.", "conclusion": "Multi-view dependency graphs enhance defect prediction; DeMuVGN's generalizability suggests their value for mature and new projects."}}
{"id": "2412.04472", "pdf": "https://arxiv.org/pdf/2412.04472", "abs": "https://arxiv.org/abs/2412.04472", "authors": ["Luca Bartolomei", "Fabio Tosi", "Matteo Poggi", "Stefano Mattoccia"], "title": "Stereo Anywhere: Robust Zero-Shot Deep Stereo Matching Even Where Either Stereo or Mono Fail", "categories": ["cs.CV"], "comment": "CVPR 2025. Code: https://github.com/bartn8/stereoanywhere - Project\n  page: https://stereoanywhere.github.io/", "summary": "We introduce Stereo Anywhere, a novel stereo-matching framework that combines\ngeometric constraints with robust priors from monocular depth Vision Foundation\nModels (VFMs). By elegantly coupling these complementary worlds through a\ndual-branch architecture, we seamlessly integrate stereo matching with learned\ncontextual cues. Following this design, our framework introduces novel cost\nvolume fusion mechanisms that effectively handle critical challenges such as\ntextureless regions, occlusions, and non-Lambertian surfaces. Through our novel\noptical illusion dataset, MonoTrap, and extensive evaluation across multiple\nbenchmarks, we demonstrate that our synthetic-only trained model achieves\nstate-of-the-art results in zero-shot generalization, significantly\noutperforming existing solutions while showing remarkable robustness to\nchallenging cases such as mirrors and transparencies.", "AI": {"tldr": "Stereo Anywhere combines geometric constraints and monocular depth priors for stereo matching, achieving state-of-the-art zero-shot generalization.", "motivation": "To address challenges like textureless regions and occlusions by integrating stereo matching with learned contextual cues.", "method": "Uses a dual-branch architecture with novel cost volume fusion mechanisms.", "result": "Achieves top performance in zero-shot generalization, handling mirrors and transparencies robustly.", "conclusion": "The framework outperforms existing solutions, demonstrating strong generalization and robustness."}}
{"id": "2410.22377", "pdf": "https://arxiv.org/pdf/2410.22377", "abs": "https://arxiv.org/abs/2410.22377", "authors": ["Flavio Corradini", "Flavio Gerosa", "Marco Gori", "Carlo Lucheroni", "Marco Piangerelli", "Martina Zannotti"], "title": "A Systematic Literature Review of Spatio-Temporal Graph Neural Network Models for Time Series Forecasting and Classification", "categories": ["cs.LG", "cs.AI", "physics.data-an"], "comment": null, "summary": "In recent years, spatio-temporal graph neural networks (GNNs) have attracted\nconsiderable interest in the field of time series analysis, due to their\nability to capture dependencies among variables and across time points. The\nobjective of the presented systematic literature review is hence to provide a\ncomprehensive overview of the various modeling approaches and application\ndomains of GNNs for time series classification and forecasting. A database\nsearch was conducted, and over 150 journal papers were selected for a detailed\nexamination of the current state-of-the-art in the field. This examination is\nintended to offer to the reader a comprehensive collection of proposed models,\nlinks to related source code, available datasets, benchmark models, and fitting\nresults. All this information is hoped to assist researchers in future studies.\nTo the best of our knowledge, this is the first systematic literature review\npresenting a detailed comparison of the results of current spatio-temporal GNN\nmodels in different domains. In addition, in its final part this review\ndiscusses current limitations and challenges in the application of\nspatio-temporal GNNs, such as comparability, reproducibility, explainability,\npoor information capacity, and scalability.", "AI": {"tldr": "A systematic review of spatio-temporal GNNs for time series analysis, covering models, datasets, benchmarks, and challenges.", "motivation": "To provide a comprehensive overview of GNNs for time series classification and forecasting, aiding future research.", "method": "Conducted a database search, reviewed over 150 papers, and analyzed models, datasets, and results.", "result": "First detailed comparison of spatio-temporal GNN models across domains, highlighting key findings and resources.", "conclusion": "Identifies limitations like reproducibility and scalability, guiding future research in spatio-temporal GNNs."}}
{"id": "2505.04401", "pdf": "https://arxiv.org/pdf/2505.04401", "abs": "https://arxiv.org/abs/2505.04401", "authors": ["Wei Wang", "Peizheng Li", "Angela Doufexi", "Mark A. Beach"], "title": "A Heuristic-Integrated DRL Approach for Phase Optimization in Large-Scale RISs", "categories": ["eess.SP", "cs.LG"], "comment": "5 pages, 5 figures. This work has been accepted for publication in\n  IEEE Communications Letters", "summary": "Optimizing discrete phase shifts in large-scale reconfigurable intelligent\nsurfaces (RISs) is challenging due to their non-convex and non-linear nature.\nIn this letter, we propose a heuristic-integrated deep reinforcement learning\n(DRL) framework that (1) leverages accumulated actions over multiple steps in\nthe double deep Q-network (DDQN) for RIS column-wise control and (2) integrates\na greedy algorithm (GA) into each DRL step to refine the state via\nfine-grained, element-wise optimization of RIS configurations. By learning from\nGA-included states, the proposed approach effectively addresses RIS\noptimization within a small DRL action space, demonstrating its capability to\noptimize phase-shift configurations of large-scale RISs.", "AI": {"tldr": "A heuristic-integrated DRL framework optimizes large-scale RIS phase shifts by combining DDQN for column-wise control and GA for element-wise refinement.", "motivation": "Optimizing discrete phase shifts in large-scale RISs is challenging due to non-convex and non-linear nature.", "method": "Proposes a DRL framework integrating DDQN for column-wise control and GA for element-wise optimization.", "result": "Effectively addresses RIS optimization within a small DRL action space, optimizing large-scale RIS phase shifts.", "conclusion": "The approach demonstrates capability to optimize phase-shift configurations of large-scale RISs."}}
{"id": "2412.06661", "pdf": "https://arxiv.org/pdf/2412.06661", "abs": "https://arxiv.org/abs/2412.06661", "authors": ["Shuaiting Li", "Juncan Deng", "Zeyu Wang", "Kedong Xu", "Rongtao Deng", "Hong Gu", "Haibin Shen", "Kejie Huang"], "title": "Efficiency Meets Fidelity: A Novel Quantization Framework for Stable Diffusion", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-image generation via Stable Diffusion models (SDM) have demonstrated\nremarkable capabilities. However, their computational intensity, particularly\nin the iterative denoising process, hinders real-time deployment in\nlatency-sensitive applications. While Recent studies have explored\npost-training quantization (PTQ) and quantization-aware training (QAT) methods\nto compress Diffusion models, existing methods often overlook the consistency\nbetween results generated by quantized models and those from floating-point\nmodels. This consistency is paramount for professional applications where both\nefficiency and output reliability are essential. To ensure that quantized SDM\ngenerates high-quality and consistent images, we propose an efficient\nquantization framework for SDM. Our framework introduces a Serial-to-Parallel\npipeline that simultaneously maintains training-inference consistency and\nensures optimization stability. Building upon this foundation, we further\ndevelop several techniques including multi-timestep activation quantization,\ntime information precalculation, inter-layer distillation, and selective\nfreezing, to achieve high-fidelity generation in comparison to floating-point\nmodels while maintaining quantization efficiency.\n  Through comprehensive evaluation across multiple Stable Diffusion variants\n(v1-4, v2-1, XL 1.0, and v3), our method demonstrates superior performance over\nstate-of-the-art approaches with shorter training times. Under W4A8\nquantization settings, we achieve significant improvements in both distribution\nsimilarity and visual fidelity, while preserving a high image quality.", "AI": {"tldr": "A new quantization framework for Stable Diffusion models ensures high-quality, consistent image generation while maintaining efficiency.", "motivation": "Address the computational intensity and output consistency issues in quantized Stable Diffusion models for real-time applications.", "method": "Proposes a Serial-to-Parallel pipeline with techniques like multi-timestep activation quantization, time information precalculation, inter-layer distillation, and selective freezing.", "result": "Superior performance in distribution similarity and visual fidelity under W4A8 quantization, with shorter training times.", "conclusion": "The framework achieves high-fidelity generation comparable to floating-point models while maintaining quantization efficiency."}}
{"id": "2410.23346", "pdf": "https://arxiv.org/pdf/2410.23346", "abs": "https://arxiv.org/abs/2410.23346", "authors": ["Keiya Hirashima", "Kana Moriwaki", "Michiko S. Fujii", "Yutaka Hirai", "Takayuki R. Saitoh", "Junnichiro Makino", "Ulrich P. Steinwandel", "Shirley Ho"], "title": "ASURA-FDPS-ML: Star-by-star Galaxy Simulations Accelerated by Surrogate Modeling for Supernova Feedback", "categories": ["astro-ph.GA", "cs.AI", "cs.LG"], "comment": "22 pages, 15 figures, 3 tables, accepted for publication in ApJ", "summary": "We introduce new high-resolution galaxy simulations accelerated by a\nsurrogate model that reduces the computation cost by approximately 75 percent.\nMassive stars with a Zero Age Main Sequence mass of more than about 10\n$\\mathrm{M_\\odot}$ explode as core-collapse supernovae (CCSNe), which play a\ncritical role in galaxy formation. The energy released by CCSNe is essential\nfor regulating star formation and driving feedback processes in the\ninterstellar medium (ISM). However, the short integration timesteps required\nfor SNe feedback have presented significant bottlenecks in astrophysical\nsimulations across various scales. Overcoming this challenge is crucial for\nenabling star-by-star galaxy simulations, which aim to capture the dynamics of\nindividual stars and the inhomogeneous shell's expansion within the turbulent\nISM. To address this, our new framework combines direct numerical simulations\nand surrogate modeling, including machine learning and Gibbs sampling. The star\nformation history and the time evolution of outflow rates in the galaxy match\nthose obtained from resolved direct numerical simulations. Our new approach\nachieves high-resolution fidelity while reducing computational costs,\neffectively bridging the physical scale gap and enabling multi-scale\nsimulations.", "AI": {"tldr": "New high-resolution galaxy simulations use a surrogate model to cut computation costs by 75%, addressing bottlenecks in supernova feedback modeling.", "motivation": "Core-collapse supernovae (CCSNe) feedback is critical for galaxy formation but computationally expensive due to short timesteps. Overcoming this enables star-by-star simulations.", "method": "Combines direct numerical simulations with surrogate modeling (machine learning and Gibbs sampling) to reduce costs while maintaining accuracy.", "result": "Matches star formation history and outflow rates of resolved simulations, achieving high-resolution fidelity at lower cost.", "conclusion": "The framework bridges the physical scale gap, enabling efficient multi-scale galaxy simulations."}}
{"id": "2505.04484", "pdf": "https://arxiv.org/pdf/2505.04484", "abs": "https://arxiv.org/abs/2505.04484", "authors": ["Louis Ohl", "Pierre-Alexandre Mattei", "Fr\u00e9d\u00e9ric Precioso"], "title": "A Tutorial on Discriminative Clustering and Mutual Information", "categories": ["stat.ML", "cs.LG", "62H30", "G.3"], "comment": null, "summary": "To cluster data is to separate samples into distinctive groups that should\nideally have some cohesive properties. Today, numerous clustering algorithms\nexist, and their differences lie essentially in what can be perceived as\n``cohesive properties''. Therefore, hypotheses on the nature of clusters must\nbe set: they can be either generative or discriminative. As the last decade\nwitnessed the impressive growth of deep clustering methods that involve neural\nnetworks to handle high-dimensional data often in a discriminative manner; we\nconcentrate mainly on the discriminative hypotheses. In this paper, our aim is\nto provide an accessible historical perspective on the evolution of\ndiscriminative clustering methods and notably how the nature of assumptions of\nthe discriminative models changed over time: from decision boundaries to\ninvariance critics. We notably highlight how mutual information has been a\nhistorical cornerstone of the progress of (deep) discriminative clustering\nmethods. We also show some known limitations of mutual information and how\ndiscriminative clustering methods tried to circumvent those. We then discuss\nthe challenges that discriminative clustering faces with respect to the\nselection of the number of clusters. Finally, we showcase these techniques\nusing the dedicated Python package, GemClus, that we have developed for\ndiscriminative clustering.", "AI": {"tldr": "The paper provides a historical overview of discriminative clustering methods, focusing on their evolution, assumptions, and challenges, while introducing a Python package, GemClus, for implementation.", "motivation": "To offer an accessible perspective on how discriminative clustering methods have evolved, particularly in deep learning, and to address their limitations and challenges.", "method": "The paper reviews the historical development of discriminative clustering, emphasizing changes in assumptions (e.g., decision boundaries to invariance critics) and the role of mutual information. It also discusses limitations and introduces the GemClus package.", "result": "The study highlights the progress and challenges in discriminative clustering, including issues with mutual information and cluster number selection, and demonstrates practical implementation via GemClus.", "conclusion": "Discriminative clustering has evolved significantly, but challenges remain, particularly in cluster selection. The GemClus package provides a tool for exploring these methods."}}
{"id": "2412.11026", "pdf": "https://arxiv.org/pdf/2412.11026", "abs": "https://arxiv.org/abs/2412.11026", "authors": ["Hang Zhang", "Zhuoling Li", "Jun Liu"], "title": "SceneLLM: Implicit Language Reasoning in LLM for Dynamic Scene Graph Generation", "categories": ["cs.CV", "cs.AI"], "comment": "29 pages, 7 figures", "summary": "Dynamic scenes contain intricate spatio-temporal information, crucial for\nmobile robots, UAVs, and autonomous driving systems to make informed decisions.\nParsing these scenes into semantic triplets <Subject-Predicate-Object> for\naccurate Scene Graph Generation (SGG) is highly challenging due to the\nfluctuating spatio-temporal complexity. Inspired by the reasoning capabilities\nof Large Language Models (LLMs), we propose SceneLLM, a novel framework that\nleverages LLMs as powerful scene analyzers for dynamic SGG. Our framework\nintroduces a Video-to-Language (V2L) mapping module that transforms video\nframes into linguistic signals (scene tokens), making the input more\ncomprehensible for LLMs. To better encode spatial information, we devise a\nSpatial Information Aggregation (SIA) scheme, inspired by the structure of\nChinese characters, which encodes spatial data into tokens. Using Optimal\nTransport (OT), we generate an implicit language signal from the frame-level\ntoken sequence that captures the video's spatio-temporal information. To\nfurther improve the LLM's ability to process this implicit linguistic input, we\napply Low-Rank Adaptation (LoRA) to fine-tune the model. Finally, we use a\ntransformer-based SGG predictor to decode the LLM's reasoning and predict\nsemantic triplets. Our method achieves state-of-the-art results on the Action\nGenome (AG) benchmark, and extensive experiments show the effectiveness of\nSceneLLM in understanding and generating accurate dynamic scene graphs.", "AI": {"tldr": "SceneLLM leverages LLMs for dynamic Scene Graph Generation (SGG) by converting video frames into linguistic signals, enhancing spatial encoding, and fine-tuning with LoRA, achieving state-of-the-art results.", "motivation": "Dynamic scenes' spatio-temporal complexity makes SGG challenging; LLMs' reasoning capabilities inspire a novel approach to improve accuracy.", "method": "Proposes SceneLLM with V2L mapping, SIA for spatial encoding, OT for implicit language signals, LoRA fine-tuning, and a transformer-based SGG predictor.", "result": "Achieves state-of-the-art performance on the Action Genome benchmark, demonstrating effective dynamic scene understanding.", "conclusion": "SceneLLM effectively integrates LLMs for dynamic SGG, offering a robust solution for complex spatio-temporal scene parsing."}}
{"id": "2411.00874", "pdf": "https://arxiv.org/pdf/2411.00874", "abs": "https://arxiv.org/abs/2411.00874", "authors": ["Wentao Zhang", "Jingyuan Wang", "Yifan Yang", "Leong Hou U"], "title": "VecCity: A Taxonomy-guided Library for Map Entity Representation Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Electronic maps consist of diverse entities, such as points of interest\n(POIs), road networks, and land parcels, playing a vital role in applications\nlike ITS and LBS. Map entity representation learning (MapRL) generates\nversatile and reusable data representations, providing essential tools for\nefficiently managing and utilizing map entity data. Despite the progress in\nMapRL, two key challenges constrain further development. First, existing\nresearch is fragmented, with models classified by the type of map entity,\nlimiting the reusability of techniques across different tasks. Second, the lack\nof unified benchmarks makes systematic evaluation and comparison of models\ndifficult. To address these challenges, we propose a novel taxonomy for MapRL\nthat organizes models based on functional module-such as encoders, pre-training\ntasks, and downstream tasks-rather than by entity type. Building on this\ntaxonomy, we present a taxonomy-driven library, VecCity, which offers\neasy-to-use interfaces for encoding, pre-training, fine-tuning, and evaluation.\nThe library integrates datasets from nine cities and reproduces 21 mainstream\nMapRL models, establishing the first standardized benchmarks for the field.\nVecCity also allows users to modify and extend models through modular\ncomponents, facilitating seamless experimentation. Our comprehensive\nexperiments cover multiple types of map entities and evaluate 21 VecCity\npre-built models across various downstream tasks. Experimental results\ndemonstrate the effectiveness of VecCity in streamlining model development and\nprovide insights into the impact of various components on performance. By\npromoting modular design and reusability, VecCity offers a unified framework to\nadvance research and innovation in MapRL. The code is available at\nhttps://github.com/Bigscity-VecCity/VecCity.", "AI": {"tldr": "The paper introduces VecCity, a taxonomy-driven library for MapRL, addressing fragmentation and lack of benchmarks by organizing models functionally and providing standardized evaluation tools.", "motivation": "Existing MapRL research is fragmented by entity type and lacks unified benchmarks, hindering progress and reusability.", "method": "Proposes a functional taxonomy for MapRL models and develops VecCity, a library with modular components for encoding, pre-training, fine-tuning, and evaluation.", "result": "VecCity integrates datasets from nine cities, reproduces 21 models, and establishes standardized benchmarks, demonstrating effectiveness in streamlining development.", "conclusion": "VecCity advances MapRL research by promoting modularity and reusability, offering a unified framework for innovation."}}
{"id": "2505.04494", "pdf": "https://arxiv.org/pdf/2505.04494", "abs": "https://arxiv.org/abs/2505.04494", "authors": ["Axel Friedrich Wolter", "Tobias Sutter"], "title": "A Two-Timescale Primal-Dual Framework for Reinforcement Learning via Online Dual Variable Guidance", "categories": ["math.OC", "cs.LG"], "comment": "35 pages, 1 figure", "summary": "We study reinforcement learning by combining recent advances in regularized\nlinear programming formulations with the classical theory of stochastic\napproximation. Motivated by the challenge of designing algorithms that leverage\noff-policy data while maintaining on-policy exploration, we propose PGDA-RL, a\nnovel primal-dual Projected Gradient Descent-Ascent algorithm for solving\nregularized Markov Decision Processes (MDPs). PGDA-RL integrates experience\nreplay-based gradient estimation with a two-timescale decomposition of the\nunderlying nested optimization problem. The algorithm operates asynchronously,\ninteracts with the environment through a single trajectory of correlated data,\nand updates its policy online in response to the dual variable associated with\nthe occupation measure of the underlying MDP. We prove that PGDA-RL converges\nalmost surely to the optimal value function and policy of the regularized MDP.\nOur convergence analysis relies on tools from stochastic approximation theory\nand holds under weaker assumptions than those required by existing primal-dual\nRL approaches, notably removing the need for a simulator or a fixed behavioral\npolicy.", "AI": {"tldr": "PGDA-RL, a primal-dual algorithm for regularized MDPs, combines off-policy data with on-policy exploration, achieving convergence to optimal policies under weaker assumptions.", "motivation": "Addresses the challenge of leveraging off-policy data while maintaining on-policy exploration in reinforcement learning.", "method": "Proposes PGDA-RL, integrating experience replay-based gradient estimation and a two-timescale decomposition for nested optimization.", "result": "PGDA-RL converges almost surely to the optimal value function and policy of the regularized MDP.", "conclusion": "The algorithm advances RL by removing the need for a simulator or fixed behavioral policy, relying on stochastic approximation theory."}}
{"id": "2501.04666", "pdf": "https://arxiv.org/pdf/2501.04666", "abs": "https://arxiv.org/abs/2501.04666", "authors": ["Nannan Li", "Kevin J. Shih", "Bryan A. Plummer"], "title": "Enhancing Virtual Try-On with Synthetic Pairs and Error-Aware Noise Scheduling", "categories": ["cs.CV"], "comment": "Accepted in CVPR 2025", "summary": "Given an isolated garment image in a canonical product view and a separate\nimage of a person, the virtual try-on task aims to generate a new image of the\nperson wearing the target garment. Prior virtual try-on works face two major\nchallenges in achieving this goal: a) the paired (human, garment) training data\nhas limited availability; b) generating textures on the human that perfectly\nmatch that of the prompted garment is difficult, often resulting in distorted\ntext and faded textures. Our work explores ways to tackle these issues through\nboth synthetic data as well as model refinement. We introduce a garment\nextraction model that generates (human, synthetic garment) pairs from a single\nimage of a clothed individual. The synthetic pairs can then be used to augment\nthe training of virtual try-on. We also propose an Error-Aware Refinement-based\nSchr\\\"odinger Bridge (EARSB) that surgically targets localized generation\nerrors for correcting the output of a base virtual try-on model. To identify\nlikely errors, we propose a weakly-supervised error classifier that localizes\nregions for refinement, subsequently augmenting the Schr\\\"odinger Bridge's\nnoise schedule with its confidence heatmap. Experiments on VITON-HD and\nDressCode-Upper demonstrate that our synthetic data augmentation enhances the\nperformance of prior work, while EARSB improves the overall image quality. In\nuser studies, our model is preferred by the users in an average of 59% of\ncases.", "AI": {"tldr": "The paper addresses challenges in virtual try-on by using synthetic data and a refinement model (EARSB) to improve garment matching and image quality.", "motivation": "Limited paired (human, garment) training data and difficulties in generating accurate garment textures motivate the need for synthetic data and model refinement.", "method": "Introduces a garment extraction model for synthetic data generation and EARSB for localized error correction in virtual try-on outputs.", "result": "Synthetic data improves prior work, and EARSB enhances image quality, with user preference at 59%.", "conclusion": "Combining synthetic data and EARSB effectively addresses virtual try-on challenges, improving performance and user satisfaction."}}
{"id": "2412.02302", "pdf": "https://arxiv.org/pdf/2412.02302", "abs": "https://arxiv.org/abs/2412.02302", "authors": ["Guang Wu", "Yun Wang", "Qian Zhou", "Ziyang Zhang"], "title": "Enhanced Photovoltaic Power Forecasting: An iTransformer and LSTM-Based Model Integrating Temporal and Covariate Interactions", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate photovoltaic (PV) power forecasting is critical for integrating\nrenewable energy sources into the grid, optimizing real-time energy management,\nand ensuring energy reliability amidst increasing demand. However, existing\nmodels often struggle with effectively capturing the complex relationships\nbetween target variables and covariates, as well as the interactions between\ntemporal dynamics and multivariate data, leading to suboptimal forecasting\naccuracy. To address these challenges, we propose a novel model architecture\nthat leverages the iTransformer for feature extraction from target variables\nand employs long short-term memory (LSTM) to extract features from covariates.\nA cross-attention mechanism is integrated to fuse the outputs of both models,\nfollowed by a Kolmogorov-Arnold network (KAN) mapping for enhanced\nrepresentation. The effectiveness of the proposed model is validated using\npublicly available datasets from Australia, with experiments conducted across\nfour seasons. Results demonstrate that the proposed model effectively capture\nseasonal variations in PV power generation and improve forecasting accuracy.", "AI": {"tldr": "A novel model combining iTransformer, LSTM, and cross-attention with KAN mapping improves PV power forecasting accuracy by capturing seasonal variations.", "motivation": "Accurate PV power forecasting is essential for grid integration and energy management, but existing models struggle with complex relationships and temporal dynamics.", "method": "The model uses iTransformer for target variable feature extraction, LSTM for covariate features, cross-attention for fusion, and KAN mapping for enhanced representation.", "result": "Experiments on Australian datasets show the model effectively captures seasonal variations and improves forecasting accuracy.", "conclusion": "The proposed model addresses limitations of existing methods and enhances PV power forecasting performance."}}
{"id": "2505.04583", "pdf": "https://arxiv.org/pdf/2505.04583", "abs": "https://arxiv.org/abs/2505.04583", "authors": ["Nathaniel Dennler", "Zhonghao Shi", "Uksang Yoo", "Stefanos Nikolaidis", "Maja Matari\u0107"], "title": "Modeling Personalized Difficulty of Rehabilitation Exercises Using Causal Trees", "categories": ["cs.RO", "cs.LG"], "comment": "Accepted to IEEE/RAS-EMBS International Conference on Rehabilitation\n  Robotics (ICORR 2025)", "summary": "Rehabilitation robots are often used in game-like interactions for\nrehabilitation to increase a person's motivation to complete rehabilitation\nexercises. By adjusting exercise difficulty for a specific user throughout the\nexercise interaction, robots can maximize both the user's rehabilitation\noutcomes and the their motivation throughout the exercise. Previous approaches\nhave assumed exercises have generic difficulty values that apply to all users\nequally, however, we identified that stroke survivors have varied and unique\nperceptions of exercise difficulty. For example, some stroke survivors found\nreaching vertically more difficult than reaching farther but lower while others\nfound reaching farther more challenging than reaching vertically. In this\npaper, we formulate a causal tree-based method to calculate exercise difficulty\nbased on the user's performance. We find that this approach accurately models\nexercise difficulty and provides a readily interpretable model of why that\nexercise is difficult for both users and caretakers.", "AI": {"tldr": "A causal tree-based method is proposed to personalize exercise difficulty in rehabilitation robots, improving outcomes and motivation by accounting for individual stroke survivors' unique perceptions of difficulty.", "motivation": "Traditional rehabilitation robots use generic difficulty values, ignoring individual differences in how stroke survivors perceive exercise difficulty. This limits effectiveness and motivation.", "method": "A causal tree-based method is developed to calculate exercise difficulty based on user performance, capturing individual perceptions of difficulty.", "result": "The method accurately models exercise difficulty and provides interpretable insights for users and caretakers.", "conclusion": "Personalizing exercise difficulty using causal trees enhances rehabilitation outcomes and motivation by addressing individual needs."}}
{"id": "2501.18504", "pdf": "https://arxiv.org/pdf/2501.18504", "abs": "https://arxiv.org/abs/2501.18504", "authors": ["Peter J. Bentley", "Soo Ling Lim", "Fuyuki Ishikawa"], "title": "CLEAR: Cue Learning using Evolution for Accurate Recognition Applied to Sustainability Data Extraction", "categories": ["cs.CV", "cs.AI", "cs.NE", "68W50, 68T07", "G.1.6; I.2.10"], "comment": "9 pages plus 2 pages of supplemental material", "summary": "Large Language Model (LLM) image recognition is a powerful tool for\nextracting data from images, but accuracy depends on providing sufficient cues\nin the prompt - requiring a domain expert for specialized tasks. We introduce\nCue Learning using Evolution for Accurate Recognition (CLEAR), which uses a\ncombination of LLMs and evolutionary computation to generate and optimize cues\nsuch that recognition of specialized features in images is improved. It\nachieves this by auto-generating a novel domain-specific representation and\nthen using it to optimize suitable textual cues with a genetic algorithm. We\napply CLEAR to the real-world task of identifying sustainability data from\ninterior and exterior images of buildings. We investigate the effects of using\na variable-length representation compared to fixed-length and show how LLM\nconsistency can be improved by refactoring from categorical to real-valued\nestimates. We show that CLEAR enables higher accuracy compared to expert human\nrecognition and human-authored prompts in every task with error rates improved\nby up to two orders of magnitude and an ablation study evincing solution\nconcision.", "AI": {"tldr": "CLEAR combines LLMs and evolutionary computation to auto-generate and optimize cues for improved image recognition, outperforming human experts in specialized tasks like sustainability data extraction.", "motivation": "Specialized image recognition tasks require domain expertise for prompt cues, limiting accuracy and scalability. CLEAR aims to automate and optimize this process.", "method": "Uses LLMs and evolutionary computation to generate domain-specific representations and optimize textual cues via a genetic algorithm. Tests variable-length vs. fixed-length representations and refactors categorical to real-valued estimates.", "result": "CLEAR achieves higher accuracy than human experts, reducing error rates by up to two orders of magnitude.", "conclusion": "CLEAR effectively automates cue optimization for specialized image recognition, significantly improving accuracy and consistency."}}
{"id": "2501.18271", "pdf": "https://arxiv.org/pdf/2501.18271", "abs": "https://arxiv.org/abs/2501.18271", "authors": ["Hao-Zhe Tan", "Zhi Zhou", "Yu-Feng Li", "Lan-Zhe Guo"], "title": "Vision-Language Model Selection and Reuse for Downstream Adaptation", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICML 2025", "summary": "Pre-trained Vision-Language Models (VLMs) are becoming increasingly popular\nacross various visual tasks, and several open-sourced VLM variants have been\nreleased. However, selecting the best-performing pre-trained VLM for a specific\ndownstream task is challenging since no single VLM can achieve promising\nperformance on all downstream tasks, and evaluating all available VLMs is\nimpossible due to time and data limitations. To address this problem, this\npaper proposes a novel paradigm to select and reuse VLM for downstream tasks,\ncalled Model Label Learning (MLL). The proposal contains three key modules:\n\\emph{model labeling}, which assigns labels to each VLM to describe their\nspecialty and utility; \\emph{model selection}, which matches the requirements\nof the target task with model labels; and \\emph{model reuse}, which applies\nselected VLMs to the target task in an ensemble manner. The proposal is highly\ncomputationally efficient and growable since the model labeling process is\ncompleted target task independent and the ability could grow with the number of\ncandidate VLMs. We also introduce a new benchmark for evaluating VLM selection\nmethods, including 49 VLMs and 17 target task datasets. Experimental results\nclearly demonstrate the effectiveness of the proposed method for selecting and\nreusing VLMs.", "AI": {"tldr": "The paper introduces Model Label Learning (MLL), a method to efficiently select and reuse Vision-Language Models (VLMs) for downstream tasks by labeling, selecting, and reusing models based on their specialties.", "motivation": "Selecting the best pre-trained VLM for specific tasks is challenging due to performance variability and evaluation limitations.", "method": "MLL involves three modules: model labeling (describing VLM specialties), model selection (matching task requirements), and model reuse (ensemble application).", "result": "The method is computationally efficient and scalable, validated on a benchmark of 49 VLMs and 17 datasets.", "conclusion": "MLL effectively addresses the challenge of VLM selection and reuse, demonstrating promising results."}}
{"id": "2505.04603", "pdf": "https://arxiv.org/pdf/2505.04603", "abs": "https://arxiv.org/abs/2505.04603", "authors": ["Wenhui Sophia Lu", "Wing Hung Wong"], "title": "Likelihood-Free Adaptive Bayesian Inference via Nonparametric Distribution Matching", "categories": ["stat.ME", "cs.LG", "stat.CO", "stat.ML"], "comment": null, "summary": "When the likelihood is analytically unavailable and computationally\nintractable, approximate Bayesian computation (ABC) has emerged as a widely\nused methodology for approximate posterior inference; however, it suffers from\nsevere computational inefficiency in high-dimensional settings or under diffuse\npriors. To overcome these limitations, we propose Adaptive Bayesian Inference\n(ABI), a framework that bypasses traditional data-space discrepancies and\ninstead compares distributions directly in posterior space through\nnonparametric distribution matching. By leveraging a novel Marginally-augmented\nSliced Wasserstein (MSW) distance on posterior measures and exploiting its\nquantile representation, ABI transforms the challenging problem of measuring\ndivergence between posterior distributions into a tractable sequence of\none-dimensional conditional quantile regression tasks. Moreover, we introduce a\nnew adaptive rejection sampling scheme that iteratively refines the posterior\napproximation by updating the proposal distribution via generative density\nestimation. Theoretically, we establish parametric convergence rates for the\ntrimmed MSW distance and prove that the ABI posterior converges to the true\nposterior as the tolerance threshold vanishes. Through extensive empirical\nevaluation, we demonstrate that ABI significantly outperforms data-based\nWasserstein ABC, summary-based ABC, and state-of-the-art likelihood-free\nsimulators, especially in high-dimensional or dependent observation regimes.", "AI": {"tldr": "ABI improves ABC by comparing posterior distributions directly using a novel MSW distance and adaptive sampling, outperforming existing methods in high-dimensional settings.", "motivation": "ABC is inefficient in high-dimensional or diffuse prior settings, motivating the need for a more efficient method like ABI.", "method": "ABI uses nonparametric distribution matching with MSW distance and adaptive rejection sampling for posterior approximation.", "result": "ABI shows superior performance over traditional ABC methods, especially in high-dimensional or dependent observation scenarios.", "conclusion": "ABI provides a scalable and efficient alternative to ABC, with theoretical guarantees and empirical success."}}
{"id": "2502.00205", "pdf": "https://arxiv.org/pdf/2502.00205", "abs": "https://arxiv.org/abs/2502.00205", "authors": ["Omar H. Khater", "Abdul Jabbar Siddiqui", "M. Shamim Hossain", "Aiman El-Maleh"], "title": "EcoWeedNet: A Lightweight and Automated Weed Detection Method for Sustainable Next-Generation Agricultural Consumer Electronics", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Sustainable agriculture plays a crucial role in ensuring world food security\nfor consumers. A critical challenge faced by sustainable precision agriculture\nis weed growth, as weeds compete for essential resources with crops, such as\nwater, soil nutrients, and sunlight, which notably affect crop yields. The\nadoption of automated computer vision technologies and ground agricultural\nconsumer electronic vehicles in precision agriculture offers sustainable,\nlow-carbon solutions. However, prior works suffer from issues such as low\naccuracy and precision, as well as high computational expense. This work\nproposes EcoWeedNet, a novel model that enhances weed detection performance\nwithout introducing significant computational complexity, aligning with the\ngoals of low-carbon agricultural practices. The effectiveness of the proposed\nmodel is demonstrated through comprehensive experiments on the CottonWeedDet12\nbenchmark dataset, which reflects real-world scenarios. EcoWeedNet achieves\nperformance comparable to that of large models (mAP@0.5 = 95.2%), yet with\nsignificantly fewer parameters (approximately 4.21% of the parameters of\nYOLOv4), lower computational complexity and better computational efficiency\n6.59% of the GFLOPs of YOLOv4). These key findings indicate EcoWeedNet's\ndeployability on low-power consumer hardware, lower energy consumption, and\nhence reduced carbon footprint, thereby emphasizing the application prospects\nof EcoWeedNet in next-generation sustainable agriculture. These findings\nprovide the way forward for increased application of environmentally-friendly\nagricultural consumer technologies.", "AI": {"tldr": "EcoWeedNet is a lightweight, efficient model for weed detection in sustainable agriculture, achieving high accuracy with low computational cost and energy use.", "motivation": "Weeds compete with crops for resources, impacting yields. Existing solutions are computationally expensive and less accurate.", "method": "Proposes EcoWeedNet, a model optimized for weed detection, tested on the CottonWeedDet12 dataset.", "result": "Achieves 95.2% mAP@0.5 with 4.21% of YOLOv4's parameters and 6.59% of its GFLOPs.", "conclusion": "EcoWeedNet is deployable on low-power hardware, reducing carbon footprint and advancing sustainable agriculture."}}
{"id": "2502.13994", "pdf": "https://arxiv.org/pdf/2502.13994", "abs": "https://arxiv.org/abs/2502.13994", "authors": ["Saeed Hadadan", "Benedikt Bitterli", "Tizian Zeltner", "Jan Nov\u00e1k", "Fabrice Rousselle", "Jacob Munkberg", "Jon Hasselgren", "Bartlomiej Wronski", "Matthias Zwicker"], "title": "Generative Detail Enhancement for Physically Based Materials", "categories": ["cs.GR", "cs.AI"], "comment": null, "summary": "We present a tool for enhancing the detail of physically based materials\nusing an off-the-shelf diffusion model and inverse rendering. Our goal is to\nenhance the visual fidelity of materials with detail that is often tedious to\nauthor, by adding signs of wear, aging, weathering, etc. As these appearance\ndetails are often rooted in real-world processes, we leverage a generative\nimage model trained on a large dataset of natural images with corresponding\nvisuals in context. Starting with a given geometry, UV mapping, and basic\nappearance, we render multiple views of the object. We use these views,\ntogether with an appearance-defining text prompt, to condition a diffusion\nmodel. The details it generates are then backpropagated from the enhanced\nimages to the material parameters via inverse differentiable rendering. For\ninverse rendering to be successful, the generated appearance has to be\nconsistent across all the images. We propose two priors to address the\nmulti-view consistency of the diffusion model. First, we ensure that the\ninitial noise that seeds the diffusion process is itself consistent across\nviews by integrating it from a view-independent UV space. Second, we enforce\ngeometric consistency by biasing the attention mechanism via a projective\nconstraint so that pixels attend strongly to their corresponding pixel\nlocations in other views. Our approach does not require any training or\nfinetuning of the diffusion model, is agnostic of the material model used, and\nthe enhanced material properties, i.e., 2D PBR textures, can be further edited\nby artists. This project is available at https://generative-detail.github.io.", "AI": {"tldr": "A tool enhances material detail using diffusion models and inverse rendering, adding wear/aging effects without model training.", "motivation": "To improve visual fidelity of materials by automating tedious detail authoring like wear and aging.", "method": "Uses a diffusion model conditioned on rendered views and text prompts, with inverse rendering for material parameter updates. Multi-view consistency is ensured via noise integration and geometric attention constraints.", "result": "Generates consistent, high-fidelity material details without requiring diffusion model training or fine-tuning.", "conclusion": "The approach is versatile, artist-friendly, and produces editable PBR textures, demonstrated by the project's availability."}}
{"id": "2505.04613", "pdf": "https://arxiv.org/pdf/2505.04613", "abs": "https://arxiv.org/abs/2505.04613", "authors": ["Leonardo V. Santoro", "Kartik G. Waghmare", "Victor M. Panaretos"], "title": "From Two Sample Testing to Singular Gaussian Discrimination", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH", "62G10, 46E22, 60G15"], "comment": null, "summary": "We establish that testing for the equality of two probability measures on a\ngeneral separable and compact metric space is equivalent to testing for the\nsingularity between two corresponding Gaussian measures on a suitable\nReproducing Kernel Hilbert Space. The corresponding Gaussians are defined via\nthe notion of kernel mean and covariance embedding of a probability measure.\nDiscerning two singular Gaussians is fundamentally simpler from an\ninformation-theoretic perspective than non-parametric two-sample testing,\nparticularly in high-dimensional settings. Our proof leverages the\nFeldman-Hajek criterion for singularity/equivalence of Gaussians on Hilbert\nspaces, and shows that discrepancies between distributions are heavily\nmagnified through their corresponding Gaussian embeddings: at a population\nlevel, distinct probability measures lead to essentially separated Gaussian\nembeddings. This appears to be a new instance of the blessing of dimensionality\nthat can be harnessed for the design of efficient inference tools in great\ngenerality.", "AI": {"tldr": "Testing equality of two probability measures on a compact metric space is equivalent to testing singularity of their Gaussian embeddings in a Reproducing Kernel Hilbert Space, simplifying high-dimensional non-parametric testing.", "motivation": "To simplify non-parametric two-sample testing in high-dimensional settings by leveraging Gaussian embeddings and the Feldman-Hajek criterion.", "method": "Use kernel mean and covariance embeddings to map probability measures to Gaussian measures in a Hilbert space, then apply the Feldman-Hajek criterion for singularity testing.", "result": "Distinct probability measures lead to separated Gaussian embeddings, making testing easier in high dimensions.", "conclusion": "Gaussian embeddings magnify discrepancies, offering an efficient inference tool in high-dimensional settings."}}
{"id": "2502.11178", "pdf": "https://arxiv.org/pdf/2502.11178", "abs": "https://arxiv.org/abs/2502.11178", "authors": ["A. Enes Doruk", "Hasan F. Ates"], "title": "DA-Mamba: Domain Adaptive Hybrid Mamba-Transformer Based One-Stage Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Recent 2D CNN-based domain adaptation approaches struggle with long-range\ndependencies due to limited receptive fields, making it difficult to adapt to\ntarget domains with significant spatial distribution changes. While\ntransformer-based domain adaptation methods better capture distant\nrelationships through self-attention mechanisms that facilitate more effective\ncross-domain feature alignment, their quadratic computational complexity makes\npractical deployment challenging for object detection tasks across diverse\ndomains. Inspired by the global modeling and linear computation complexity of\nthe Mamba architecture, we present the first domain-adaptive Mamba-based\none-stage object detection model, termed DA-Mamba. Specifically, we combine\nMamba's efficient state-space modeling with attention mechanisms to address\ndomain-specific spatial and channel-wise variations. Our design leverages\ndomain-adaptive spatial and channel-wise scanning within the Mamba block to\nextract highly transferable representations for efficient sequential\nprocessing, while cross-attention modules generate long-range, mixed-domain\nspatial features to enable robust soft alignment across domains. Besides,\nmotivated by the observation that hybrid architectures introduce feature noise\nin domain adaptation tasks, we propose an entropy-based knowledge distillation\nframework with margin ReLU, which adaptively refines multi-level\nrepresentations by suppressing irrelevant activations and aligning uncertainty\nacross source and target domains. Finally, to prevent overfitting caused by the\nmixed-up features generated through cross-attention mechanisms, we propose\nentropy-driven gating attention with random perturbations that simultaneously\nrefine target features and enhance model generalization.", "AI": {"tldr": "DA-Mamba, a domain-adaptive Mamba-based one-stage object detection model, addresses limitations of 2D CNNs and transformers in domain adaptation by combining Mamba's efficient state-space modeling with attention mechanisms and introducing entropy-based knowledge distillation and gating attention for robust feature alignment.", "motivation": "2D CNNs struggle with long-range dependencies in domain adaptation, while transformers face computational complexity issues. The goal is to leverage Mamba's efficiency and global modeling for better cross-domain feature alignment.", "method": "Combines Mamba's state-space modeling with attention mechanisms, introduces domain-adaptive spatial and channel-wise scanning, and proposes entropy-based knowledge distillation and gating attention to refine features and prevent overfitting.", "result": "DA-Mamba achieves efficient and robust cross-domain feature alignment, addressing spatial and channel-wise variations while enhancing model generalization.", "conclusion": "The proposed DA-Mamba model effectively overcomes the limitations of existing methods, offering a scalable and efficient solution for domain-adaptive object detection."}}
{"id": "2503.18314", "pdf": "https://arxiv.org/pdf/2503.18314", "abs": "https://arxiv.org/abs/2503.18314", "authors": ["Christoforos N. Spartalis", "Theodoros Semertzidis", "Efstratios Gavves", "Petros Daras"], "title": "LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted as a main conference paper at CVPR 2025\n  (https://cvpr.thecvf.com/virtual/2025/poster/33292)", "summary": "We present LoTUS, a novel Machine Unlearning (MU) method that eliminates the\ninfluence of training samples from pre-trained models, avoiding retraining from\nscratch. LoTUS smooths the prediction probabilities of the model up to an\ninformation-theoretic bound, mitigating its over-confidence stemming from data\nmemorization. We evaluate LoTUS on Transformer and ResNet18 models against\neight baselines across five public datasets. Beyond established MU benchmarks,\nwe evaluate unlearning on ImageNet1k, a large-scale dataset, where retraining\nis impractical, simulating real-world conditions. Moreover, we introduce the\nnovel Retrain-Free Jensen-Shannon Divergence (RF-JSD) metric to enable\nevaluation under real-world conditions. The experimental results show that\nLoTUS outperforms state-of-the-art methods in terms of both efficiency and\neffectiveness. Code: https://github.com/cspartalis/LoTUS.", "AI": {"tldr": "LoTUS is a Machine Unlearning (MU) method that removes training sample influence from pre-trained models without retraining, outperforming baselines in efficiency and effectiveness.", "motivation": "To avoid costly retraining from scratch while eliminating the influence of specific training samples in pre-trained models.", "method": "LoTUS smooths model prediction probabilities up to an information-theoretic bound, mitigating over-confidence from data memorization.", "result": "Outperforms eight baselines on five datasets, including ImageNet1k, and introduces the RF-JSD metric for real-world evaluation.", "conclusion": "LoTUS is efficient and effective for MU, especially in large-scale scenarios like ImageNet1k."}}
{"id": "2505.04627", "pdf": "https://arxiv.org/pdf/2505.04627", "abs": "https://arxiv.org/abs/2505.04627", "authors": ["Jean-Michel Tucny", "Mihir Durve", "Sauro Succi"], "title": "Is the end of Insight in Sight ?", "categories": ["physics.comp-ph", "cs.LG", "physics.data-an"], "comment": "20 pages, 5 figures", "summary": "It is shown that the weight matrices of a Physics-informed neural network\n(PINN)-based deep learning application to a rarefied gas dynamics problem\ndescribed by the Boltzmann equation bear no evident link to the mathematical\nstructure of the physical problem. Instead, the weights appear close to\nGaussian distributed random matrices. Although significantly more work is\nneeded to support a robust assessment in this direction, these results suggest\nthat deep-learning and the numerical solution of the Boltzmann equation\nrepresent two equivalent, but largely distinct paths to the same physical\nknowledge. If so, Explainable AI might be an unrealistic target and possibly\neven an ill-posed one.", "AI": {"tldr": "PINN weights in Boltzmann equation applications resemble random matrices, suggesting deep learning and traditional methods may be distinct but equivalent paths to physical knowledge, questioning Explainable AI's feasibility.", "motivation": "To investigate the relationship between the weight matrices in PINNs and the mathematical structure of the Boltzmann equation in rarefied gas dynamics.", "method": "Analysis of weight matrices in a PINN-based deep learning application to the Boltzmann equation.", "result": "Weight matrices appear Gaussian-distributed and random, lacking evident links to the physical problem's structure.", "conclusion": "Deep learning and traditional numerical methods may be equivalent but distinct, casting doubt on the feasibility of Explainable AI for such problems."}}
{"id": "2503.22676", "pdf": "https://arxiv.org/pdf/2503.22676", "abs": "https://arxiv.org/abs/2503.22676", "authors": ["Tony Yu", "Yanlin Jin", "Ashok Veeraraghavan", "Akshat Dave", "Guha Balakrishnan"], "title": "TranSplat: Lighting-Consistent Cross-Scene Object Transfer with 3D Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "We present TranSplat, a 3D scene rendering algorithm that enables realistic\ncross-scene object transfer (from a source to a target scene) based on the\nGaussian Splatting framework. Our approach addresses two critical challenges:\n(1) precise 3D object extraction from the source scene, and (2) faithful\nrelighting of the transferred object in the target scene without explicit\nmaterial property estimation. TranSplat fits a splatting model to the source\nscene, using 2D object masks to drive fine-grained 3D segmentation. Following\nuser-guided insertion of the object into the target scene, along with automatic\nrefinement of position and orientation, TranSplat derives per-Gaussian radiance\ntransfer functions via spherical harmonic analysis to adapt the object's\nappearance to match the target scene's lighting environment. This relighting\nstrategy does not require explicitly estimating physical scene properties such\nas BRDFs. Evaluated on several synthetic and real-world scenes and objects,\nTranSplat yields excellent 3D object extractions and relighting performance\ncompared to recent baseline methods and visually convincing cross-scene object\ntransfers. We conclude by discussing the limitations of the approach.", "AI": {"tldr": "TranSplat is a 3D rendering algorithm for realistic cross-scene object transfer using Gaussian Splatting, addressing extraction and relighting challenges without explicit material estimation.", "motivation": "To enable realistic cross-scene object transfer by solving challenges in 3D object extraction and relighting without needing explicit material properties.", "method": "Uses Gaussian Splatting for 3D segmentation, user-guided insertion, and spherical harmonic analysis for relighting.", "result": "Achieves excellent 3D object extractions and relighting, outperforming baselines in synthetic and real-world scenes.", "conclusion": "TranSplat is effective but has limitations, as discussed."}}
{"id": "2504.02388", "pdf": "https://arxiv.org/pdf/2504.02388", "abs": "https://arxiv.org/abs/2504.02388", "authors": ["Alessia Ciacco", "Francesca Guerriero", "Eneko Osaba"], "title": "Steiner Traveling Salesman Problem with Quantum Annealing", "categories": ["quant-ph", "cs.AI", "cs.ET"], "comment": "7 pages, 1 figure, 6 tables. Paper accepted in The Genetic and\n  Evolutionary Computation Conference (GECCO 2025)", "summary": "The Steiner Traveling Salesman Problem (STSP) is a variant of the classical\nTraveling Salesman Problem. The STSP involves incorporating steiner nodes,\nwhich are extra nodes not originally part of the required visit set but that\ncan be added to the route to enhance the overall solution and minimize the\ntotal travel cost. Given the NP-hard nature of the STSP, we propose a quantum\napproach to address it. Specifically, we employ quantum annealing using\nD-Wave's hardware to explore its potential for solving this problem. To enhance\ncomputational feasibility, we develop a preprocessing method that effectively\nreduces the network size. Our experimental results demonstrate that this\nreduction technique significantly decreases the problem complexity, making the\nQuadratic Unconstrained Binary Optimization formulation, the standard input for\nquantum annealers, better suited for existing quantum hardware. Furthermore,\nthe results highlight the potential of quantum annealing as a promising and\ninnovative approach for solving the STSP.", "AI": {"tldr": "A quantum annealing approach is proposed for the Steiner Traveling Salesman Problem (STSP), leveraging D-Wave's hardware and a preprocessing method to reduce network size, showing promising results.", "motivation": "The STSP is NP-hard, and quantum computing offers a novel way to tackle such complex problems efficiently.", "method": "Quantum annealing with D-Wave's hardware and a preprocessing technique to simplify the network.", "result": "The preprocessing reduces problem complexity, making quantum annealing feasible and effective for STSP.", "conclusion": "Quantum annealing is a promising approach for solving the STSP, with potential for further advancements."}}
{"id": "1905.02342", "pdf": "https://arxiv.org/pdf/1905.02342", "abs": "https://arxiv.org/abs/1905.02342", "authors": ["Nhan Duy Truong", "Jing Yan Haw", "Syed Muhamad Assad", "Ping Koy Lam", "Omid Kavehei"], "title": "Machine Learning Cryptanalysis of a Quantum Random Number Generator", "categories": ["cs.LG", "cs.CR", "quant-ph", "stat.ML"], "comment": "Published article is at https://ieeexplore.ieee.org/document/8396276.\n  Related code is at\n  https://github.com/Nano-Neuro-Research-Lab/Machine-Learning-Cryptanalysis-of-a-Quantum-Random-Number-Generator", "summary": "Random number generators (RNGs) that are crucial for cryptographic\napplications have been the subject of adversarial attacks. These attacks\nexploit environmental information to predict generated random numbers that are\nsupposed to be truly random and unpredictable. Though quantum random number\ngenerators (QRNGs) are based on the intrinsic indeterministic nature of quantum\nproperties, the presence of classical noise in the measurement process\ncompromises the integrity of a QRNG. In this paper, we develop a predictive\nmachine learning (ML) analysis to investigate the impact of deterministic\nclassical noise in different stages of an optical continuous variable QRNG. Our\nML model successfully detects inherent correlations when the deterministic\nnoise sources are prominent. After appropriate filtering and randomness\nextraction processes are introduced, our QRNG system, in turn, demonstrates its\nrobustness against ML. We further demonstrate the robustness of our ML approach\nby applying it to uniformly distributed random numbers from the QRNG and a\ncongruential RNG. Hence, our result shows that ML has potentials in\nbenchmarking the quality of RNG devices.", "AI": {"tldr": "The paper investigates the impact of deterministic classical noise in optical continuous variable QRNGs using ML, showing ML's potential to benchmark RNG quality.", "motivation": "Adversarial attacks exploit environmental info to predict RNG outputs, compromising QRNG integrity due to classical noise.", "method": "Developed a predictive ML analysis to detect correlations from deterministic noise in QRNG stages, followed by filtering and randomness extraction.", "result": "ML detects noise correlations; QRNG becomes robust after filtering. ML also benchmarks QRNG against congruential RNG.", "conclusion": "ML is effective for assessing RNG quality, highlighting QRNG robustness post-processing."}}
{"id": "2504.02287", "pdf": "https://arxiv.org/pdf/2504.02287", "abs": "https://arxiv.org/abs/2504.02287", "authors": ["Trung Thanh Nguyen", "Yasutomo Kawanishi", "Vijay John", "Takahiro Komamizu", "Ichiro Ide"], "title": "MultiSensor-Home: A Wide-area Multi-modal Multi-view Dataset for Action Recognition and Transformer-based Sensor Fusion", "categories": ["cs.CV"], "comment": "The 19th IEEE International Conference on Automatic Face and Gesture\n  Recognition (FG 2025)", "summary": "Multi-modal multi-view action recognition is a rapidly growing field in\ncomputer vision, offering significant potential for applications in\nsurveillance. However, current datasets often fail to address real-world\nchallenges such as wide-area distributed settings, asynchronous data streams,\nand the lack of frame-level annotations. Furthermore, existing methods face\ndifficulties in effectively modeling inter-view relationships and enhancing\nspatial feature learning. In this paper, we introduce the MultiSensor-Home\ndataset, a novel benchmark designed for comprehensive action recognition in\nhome environments, and also propose the Multi-modal Multi-view\nTransformer-based Sensor Fusion (MultiTSF) method. The proposed\nMultiSensor-Home dataset features untrimmed videos captured by distributed\nsensors, providing high-resolution RGB and audio data along with detailed\nmulti-view frame-level action labels. The proposed MultiTSF method leverages a\nTransformer-based fusion mechanism to dynamically model inter-view\nrelationships. Furthermore, the proposed method integrates a human detection\nmodule to enhance spatial feature learning, guiding the model to prioritize\nframes with human activity to enhance action the recognition accuracy.\nExperiments on the proposed MultiSensor-Home and the existing MM-Office\ndatasets demonstrate the superiority of MultiTSF over the state-of-the-art\nmethods. Quantitative and qualitative results highlight the effectiveness of\nthe proposed method in advancing real-world multi-modal multi-view action\nrecognition. The source code is available at\nhttps://github.com/thanhhff/MultiTSF.", "AI": {"tldr": "The paper introduces the MultiSensor-Home dataset and the MultiTSF method for multi-modal multi-view action recognition, addressing real-world challenges like distributed settings and asynchronous data.", "motivation": "Current datasets and methods lack solutions for real-world challenges (e.g., wide-area distributed settings, asynchronous data) and struggle with inter-view relationships and spatial feature learning.", "method": "Proposes MultiTSF, a Transformer-based fusion method with a human detection module to enhance spatial features and inter-view modeling.", "result": "MultiTSF outperforms state-of-the-art methods on the MultiSensor-Home and MM-Office datasets, improving action recognition accuracy.", "conclusion": "The MultiSensor-Home dataset and MultiTSF method advance real-world multi-modal multi-view action recognition, with code available for reproducibility."}}
{"id": "2504.03783", "pdf": "https://arxiv.org/pdf/2504.03783", "abs": "https://arxiv.org/abs/2504.03783", "authors": ["Haoyuan Li", "Mathias Funk", "Jindong Wang", "Aaqib Saeed"], "title": "FAST: Federated Active Learning with Foundation Models for Communication-efficient Sampling and Training", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DC"], "comment": null, "summary": "Federated Active Learning (FAL) has emerged as a promising framework to\nleverage large quantities of unlabeled data across distributed clients while\npreserving data privacy. However, real-world deployments remain limited by high\nannotation costs and communication-intensive sampling processes, particularly\nin a cross-silo setting, when clients possess substantial local datasets. This\npaper addresses the crucial question: What is the best practice to reduce\ncommunication costs in human-in-the-loop learning with minimal annotator\neffort? Existing FAL methods typically rely on iterative annotation processes\nthat separate active sampling from federated updates, leading to multiple\nrounds of expensive communication and annotation. In response, we introduce\nFAST, a two-pass FAL framework that harnesses foundation models for weak\nlabeling in a preliminary pass, followed by a refinement pass focused\nexclusively on the most uncertain samples. By leveraging representation\nknowledge from foundation models and integrating refinement steps into a\nstreamlined workflow, FAST substantially reduces the overhead incurred by\niterative active sampling. Extensive experiments on diverse medical and natural\nimage benchmarks demonstrate that FAST outperforms existing FAL methods by an\naverage of 4.36% while reducing communication rounds eightfold under a limited\n5% labeling budget.", "AI": {"tldr": "FAST, a two-pass Federated Active Learning framework, reduces communication costs and annotator effort by using foundation models for weak labeling and refining uncertain samples, outperforming existing methods.", "motivation": "High annotation costs and communication-intensive processes limit real-world Federated Active Learning (FAL) deployments, especially in cross-silo settings.", "method": "FAST employs a two-pass approach: weak labeling with foundation models followed by refinement of uncertain samples, integrating steps into a streamlined workflow.", "result": "FAST outperforms existing FAL methods by 4.36% on average and reduces communication rounds eightfold under a 5% labeling budget.", "conclusion": "FAST offers an efficient solution for FAL by minimizing communication and annotation overhead while maintaining performance."}}
{"id": "2304.01215", "pdf": "https://arxiv.org/pdf/2304.01215", "abs": "https://arxiv.org/abs/2304.01215", "authors": ["Alessio Brini", "Elisa Giovannini", "Elia Smaniotto"], "title": "A Machine Learning Approach to Forecasting Honey Production with Tree-Based Methods", "categories": ["cs.LG"], "comment": "53 pages, 26 figures", "summary": "The beekeeping sector has experienced significant production fluctuations in\nrecent years, largely due to increasingly frequent adverse weather events\nlinked to climate change. These events can severely affect the environment,\nreducing its suitability for bee activity. We conduct a forecasting analysis of\nhoney production across Italy using a range of machine learning models, with a\nparticular focus on weather-related variables as key predictors. Our analysis\nrelies on a dataset collected in 2022, which combines hive-level observations\nwith detailed weather data. We train and compare several linear and nonlinear\nmodels, evaluating both their predictive accuracy and interpretability. By\nexamining model explanations, we identify the main drivers of honey production.\nWe also ensemble models from different families to assess whether combining\npredictions improves forecast accuracy. These insights support beekeepers in\nmanaging production risks and may inform the development of insurance products\nagainst unexpected losses due to poor harvests.", "AI": {"tldr": "Machine learning models forecast honey production in Italy, using weather data to identify key drivers and improve risk management for beekeepers.", "motivation": "Address production fluctuations in beekeeping due to climate change by predicting honey yields using weather variables.", "method": "Train and compare linear and nonlinear machine learning models on 2022 hive-level and weather data, then ensemble models for accuracy.", "result": "Identified key weather-related drivers of honey production; ensemble models may improve forecast accuracy.", "conclusion": "Insights aid beekeepers in risk management and could inform insurance products for poor harvests."}}
{"id": "2504.05184", "pdf": "https://arxiv.org/pdf/2504.05184", "abs": "https://arxiv.org/abs/2504.05184", "authors": ["Rayan Merghani Ahmed", "Adnan Iltaf", "Mohamed Elmanna", "Gang Zhao", "Hongliang Li", "Yue Du", "Bin Li", "Shoujun Zhou"], "title": "MSA-UNet3+: Multi-Scale Attention UNet3+ with New Supervised Prototypical Contrastive Loss for Coronary DSA Image Segmentation", "categories": ["cs.CV"], "comment": "Work in progress", "summary": "Accurate segmentation of coronary Digital Subtraction Angiography images is\nessential to diagnose and treat coronary artery diseases. Despite advances in\ndeep learning, challenges such as high intra-class variance and class imbalance\nlimit precise vessel delineation. Most existing approaches for coronary DSA\nsegmentation cannot address these issues. Also, existing segmentation network's\nencoders do not directly generate semantic embeddings, which could enable the\ndecoder to reconstruct segmentation masks effectively from these well-defined\nfeatures. We propose a Supervised Prototypical Contrastive Loss that fuses\nsupervised and prototypical contrastive learning to enhance coronary DSA image\nsegmentation. The supervised contrastive loss enforces semantic embeddings in\nthe encoder, improving feature differentiation. The prototypical contrastive\nloss allows the model to focus on the foreground class while alleviating the\nhigh intra-class variance and class imbalance problems by concentrating only on\nthe hard-to-classify background samples. We implement the proposed SPCL loss\nwithin an MSA-UNet3+: a Multi-Scale Attention-Enhanced UNet3+ architecture. The\narchitecture integrates key components: a Multi-Scale Attention Encoder and a\nMulti-Scale Dilated Bottleneck designed to enhance multi-scale feature\nextraction and a Contextual Attention Fusion Module built to keep fine-grained\ndetails while improving contextual understanding. Experiments on a private\ncoronary DSA dataset show that MSA-UNet3+ outperforms state-of-the-art methods,\nachieving the highest Dice coefficient and F1-score and significantly reducing\nASD and ACD. The developed framework provides clinicians with precise vessel\nsegmentation, enabling accurate identification of coronary stenosis and\nsupporting informed diagnostic and therapeutic decisions. The code will be\nreleased at https://github.com/rayanmerghani/MSA-UNet3plus.", "AI": {"tldr": "A novel Supervised Prototypical Contrastive Loss (SPCL) is proposed to improve coronary DSA image segmentation by addressing high intra-class variance and class imbalance, implemented in an MSA-UNet3+ architecture, achieving state-of-the-art results.", "motivation": "Accurate segmentation of coronary DSA images is crucial for diagnosing and treating coronary artery diseases, but existing methods struggle with high intra-class variance and class imbalance.", "method": "The SPCL loss combines supervised and prototypical contrastive learning to enhance feature differentiation and focus on hard-to-classify samples. The MSA-UNet3+ architecture includes a Multi-Scale Attention Encoder, Multi-Scale Dilated Bottleneck, and Contextual Attention Fusion Module for improved feature extraction and detail preservation.", "result": "The method outperforms state-of-the-art techniques on a private dataset, achieving the highest Dice coefficient and F1-score while reducing ASD and ACD.", "conclusion": "The proposed framework provides precise vessel segmentation, aiding in accurate diagnosis and treatment decisions, with code available for public use."}}
{"id": "2504.06987", "pdf": "https://arxiv.org/pdf/2504.06987", "abs": "https://arxiv.org/abs/2504.06987", "authors": ["Sanyam Paresh Shah", "Abdullah Mamun", "Shovito Barua Soumma", "Hassan Ghasemzadeh"], "title": "Enhancing Metabolic Syndrome Prediction with Hybrid Data Balancing and Counterfactuals", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at the IEEE EMBC 2025 Conference. 7 pages, 3 figures", "summary": "Metabolic Syndrome (MetS) is a cluster of interrelated risk factors that\nsignificantly increases the risk of cardiovascular diseases and type 2\ndiabetes. Despite its global prevalence, accurate prediction of MetS remains\nchallenging due to issues such as class imbalance, data scarcity, and\nmethodological inconsistencies in existing studies. In this paper, we address\nthese challenges by systematically evaluating and optimizing machine learning\n(ML) models for MetS prediction, leveraging advanced data balancing techniques\nand counterfactual analysis. Multiple ML models, including XGBoost, Random\nForest, TabNet, etc., were trained and compared under various data balancing\ntechniques such as random oversampling (ROS), SMOTE, ADASYN, and CTGAN.\nAdditionally, we introduce MetaBoost, a novel hybrid framework that integrates\nSMOTE, ADASYN, and CTGAN, optimizing synthetic data generation through weighted\naveraging and iterative weight tuning to enhance the model's performance\n(achieving up to a 1.87% accuracy improvement over individual balancing\ntechniques). A comprehensive counterfactual analysis is conducted to quantify\nthe feature-level changes required to shift individuals from high-risk to\nlow-risk categories. The results indicate that blood glucose (50.3%) and\ntriglycerides (46.7%) were the most frequently modified features, highlighting\ntheir clinical significance in MetS risk reduction. Additionally, probabilistic\nanalysis shows elevated blood glucose (85.5% likelihood) and triglycerides\n(74.9% posterior probability) as the strongest predictors. This study not only\nadvances the methodological rigor of MetS prediction but also provides\nactionable insights for clinicians and researchers, highlighting the potential\nof ML in mitigating the public health burden of metabolic syndrome.", "AI": {"tldr": "The paper proposes MetaBoost, a hybrid ML framework for predicting Metabolic Syndrome (MetS), addressing data imbalance and methodological issues. It outperforms existing techniques and identifies key risk factors like blood glucose and triglycerides.", "motivation": "MetS prediction is challenging due to class imbalance, data scarcity, and inconsistent methods. The study aims to improve accuracy and provide actionable insights.", "method": "Evaluated ML models (XGBoost, Random Forest, TabNet) with data balancing techniques (ROS, SMOTE, ADASYN, CTGAN) and introduced MetaBoost, a hybrid framework. Conducted counterfactual and probabilistic analyses.", "result": "MetaBoost improved accuracy by 1.87%. Blood glucose and triglycerides were the most modified and predictive features.", "conclusion": "The study enhances MetS prediction methodology and offers clinical insights, demonstrating ML's potential in reducing MetS-related health burdens."}}
{"id": "2305.12292", "pdf": "https://arxiv.org/pdf/2305.12292", "abs": "https://arxiv.org/abs/2305.12292", "authors": ["Dimitris Bertsimas", "Ryan Cory-Wright", "Sean Lo", "Jean Pauphilet"], "title": "Disjunctive Branch-And-Bound for Certifiably Optimal Low-Rank Matrix Completion", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "Updated version with new numerics showcasing scalability up to n=2500", "summary": "Low-rank matrix completion consists of computing a matrix of minimal\ncomplexity that recovers a given set of observations as accurately as possible.\nUnfortunately, existing methods for matrix completion are heuristics that,\nwhile highly scalable and often identifying high-quality solutions, do not\npossess any optimality guarantees. We reexamine matrix completion with an\noptimality-oriented eye. We reformulate low-rank matrix completion problems as\nconvex problems over the non-convex set of projection matrices and implement a\ndisjunctive branch-and-bound scheme that solves them to certifiable optimality.\nFurther, we derive a novel and often near-exact class of convex relaxations by\ndecomposing a low-rank matrix as a sum of rank-one matrices and incentivizing\nthat two-by-two minors in each rank-one matrix have determinant zero. In\nnumerical experiments, our new convex relaxations decrease the optimality gap\nby two orders of magnitude compared to existing attempts, and our disjunctive\nbranch-and-bound scheme solves $n \\times m$ rank-$r$ matrix completion problems\nto certifiable optimality or near optimality in hours for $\\max \\{m, n\\} \\leq\n2500$ and $r \\leq 5$. Moreover, this improvement in the training error\ntranslates into an average $2\\%$--$50\\%$ improvement in the test set error.", "AI": {"tldr": "The paper proposes a method for low-rank matrix completion with optimality guarantees, using convex relaxations and branch-and-bound to achieve certifiable optimality.", "motivation": "Existing matrix completion methods lack optimality guarantees despite being scalable and effective. The authors aim to address this gap.", "method": "Reformulates matrix completion as convex problems over projection matrices, introduces disjunctive branch-and-bound, and derives new convex relaxations by decomposing low-rank matrices.", "result": "Numerical experiments show a two-order reduction in optimality gap and solve problems to certifiable optimality for specific dimensions. Test error improves by 2%--50%.", "conclusion": "The proposed method achieves certifiable optimality in low-rank matrix completion, significantly outperforming existing heuristics."}}
{"id": "2504.06675", "pdf": "https://arxiv.org/pdf/2504.06675", "abs": "https://arxiv.org/abs/2504.06675", "authors": ["Qingtao Yu", "Jaskirat Singh", "Zhaoyuan Yang", "Peter Henry Tu", "Jing Zhang", "Hongdong Li", "Richard Hartley", "Dylan Campbell"], "title": "Probability Density Geodesics in Image Diffusion Latent Space", "categories": ["cs.CV"], "comment": "CVPR2025", "summary": "Diffusion models indirectly estimate the probability density over a data\nspace, which can be used to study its structure. In this work, we show that\ngeodesics can be computed in diffusion latent space, where the norm induced by\nthe spatially-varying inner product is inversely proportional to the\nprobability density. In this formulation, a path that traverses a high density\n(that is, probable) region of image latent space is shorter than the equivalent\npath through a low density region. We present algorithms for solving the\nassociated initial and boundary value problems and show how to compute the\nprobability density along the path and the geodesic distance between two\npoints. Using these techniques, we analyze how closely video clips approximate\ngeodesics in a pre-trained image diffusion space. Finally, we demonstrate how\nthese techniques can be applied to training-free image sequence interpolation\nand extrapolation, given a pre-trained image diffusion model.", "AI": {"tldr": "The paper explores computing geodesics in diffusion latent space, leveraging probability density for path analysis and applications like image sequence interpolation.", "motivation": "To study the structure of data space using diffusion models and geodesics, enabling analysis of high-density regions and practical applications.", "method": "Algorithms for solving initial and boundary value problems in diffusion latent space, computing probability density and geodesic distance.", "result": "Demonstrated analysis of video clips as geodesics and training-free image sequence interpolation/extrapolation.", "conclusion": "Geodesics in diffusion latent space provide insights into data structure and enable practical applications without additional training."}}
{"id": "2504.12806", "pdf": "https://arxiv.org/pdf/2504.12806", "abs": "https://arxiv.org/abs/2504.12806", "authors": ["Georgios Papadopoulos", "Shaltiel Eloul", "Yash Satsangi", "Jamie Heredge", "Niraj Kumar", "Chun-Fu Chen", "Marco Pistoia"], "title": "A Numerical Gradient Inversion Attack in Variational Quantum Neural-Networks", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "9 pages, 17 figures", "summary": "The loss landscape of Variational Quantum Neural Networks (VQNNs) is\ncharacterized by local minima that grow exponentially with increasing qubits.\nBecause of this, it is more challenging to recover information from model\ngradients during training compared to classical Neural Networks (NNs). In this\npaper we present a numerical scheme that successfully reconstructs input\ntraining, real-world, practical data from trainable VQNNs' gradients. Our\nscheme is based on gradient inversion that works by combining gradients\nestimation with the finite difference method and adaptive low-pass filtering.\nThe scheme is further optimized with Kalman filter to obtain efficient\nconvergence. Our experiments show that our algorithm can invert even\nbatch-trained data, given the VQNN model is sufficiently over-parameterized.", "AI": {"tldr": "A method to reconstruct input data from VQNN gradients using gradient inversion, finite difference, and adaptive filtering, optimized with Kalman filter for convergence.", "motivation": "VQNNs' loss landscapes have exponentially growing local minima, making gradient-based information recovery harder than in classical NNs.", "method": "Combines gradient inversion, finite difference, adaptive low-pass filtering, and Kalman filter optimization.", "result": "Successfully inverts batch-trained data if the VQNN is over-parameterized.", "conclusion": "The scheme effectively recovers input data from VQNN gradients despite challenging loss landscapes."}}
{"id": "2308.12563", "pdf": "https://arxiv.org/pdf/2308.12563", "abs": "https://arxiv.org/abs/2308.12563", "authors": ["Thi Kieu Khanh Ho", "Narges Armanfard"], "title": "Contaminated Multivariate Time-Series Anomaly Detection with Spatio-Temporal Graph Conditional Diffusion Models", "categories": ["cs.LG", "eess.SP"], "comment": "Accepted to The Conference on Uncertainty in Artificial Intelligence\n  (UAI 2025)", "summary": "Mainstream unsupervised anomaly detection algorithms often excel in academic\ndatasets, yet their real-world performance is restricted due to the controlled\nexperimental conditions involving clean training data. Addressing the challenge\nof training with noise, a prevalent issue in practical anomaly detection, is\nfrequently overlooked. In a pioneering endeavor, this study delves into the\nrealm of label-level noise within sensory time-series anomaly detection (TSAD).\nThis paper presents a novel and practical end-to-end unsupervised TSAD when the\ntraining data is contaminated with anomalies. The introduced approach, called\nTSAD-C, is devoid of access to abnormality labels during the training phase.\nTSAD-C encompasses three core modules: a Decontaminator to rectify anomalies\n(aka noise) present during training, a Long-range Variable Dependency Modeling\nmodule to capture long-term intra- and inter-variable dependencies within the\ndecontaminated data that is considered as a surrogate of the pure normal data,\nand an Anomaly Scoring module to detect anomalies from all types. Our extensive\nexperiments conducted on four reliable and diverse datasets conclusively\ndemonstrate that TSAD-C surpasses existing methodologies, thus establishing a\nnew state-of-the-art in the TSAD field.", "AI": {"tldr": "TSAD-C is a novel unsupervised time-series anomaly detection method that handles noisy training data, outperforming existing approaches.", "motivation": "Real-world anomaly detection often involves noisy training data, a challenge overlooked in controlled academic settings.", "method": "TSAD-C uses three modules: Decontaminator for noise removal, Long-range Dependency Modeling for capturing patterns, and Anomaly Scoring for detection.", "result": "TSAD-C outperforms existing methods on four diverse datasets, setting a new benchmark.", "conclusion": "TSAD-C advances unsupervised TSAD by effectively addressing noisy training data, achieving state-of-the-art performance."}}
{"id": "2504.08280", "pdf": "https://arxiv.org/pdf/2504.08280", "abs": "https://arxiv.org/abs/2504.08280", "authors": ["Xiong Li", "Shulei Liu", "Xingning Chen", "Yisong Wu", "Dong Zhu"], "title": "PNE-SGAN: Probabilistic NDT-Enhanced Semantic Graph Attention Network for LiDAR Loop Closure Detection", "categories": ["cs.CV", "cs.RO"], "comment": "We discovered a critical implementation bug in Section 4\n  (probabilistic NDT-based semantic graph attention module) that invalidates\n  the results shown in Figures 3-4", "summary": "LiDAR loop closure detection (LCD) is crucial for consistent Simultaneous\nLocalization and Mapping (SLAM) but faces challenges in robustness and\naccuracy. Existing methods, including semantic graph approaches, often suffer\nfrom coarse geometric representations and lack temporal robustness against\nnoise, dynamics, and viewpoint changes. We introduce PNE-SGAN, a Probabilistic\nNDT-Enhanced Semantic Graph Attention Network, to overcome these limitations.\nPNE-SGAN enhances semantic graphs by using Normal Distributions Transform (NDT)\ncovariance matrices as rich, discriminative geometric node features, processed\nvia a Graph Attention Network (GAT). Crucially, it integrates graph similarity\nscores into a probabilistic temporal filtering framework (modeled as an\nHMM/Bayes filter), incorporating uncertain odometry for motion modeling and\nutilizing forward-backward smoothing to effectively handle ambiguities.\nEvaluations on challenging KITTI sequences (00 and 08) demonstrate\nstate-of-the-art performance, achieving Average Precision of 96.2\\% and 95.1\\%,\nrespectively. PNE-SGAN significantly outperforms existing methods, particularly\nin difficult bidirectional loop scenarios where others falter. By synergizing\ndetailed NDT geometry with principled probabilistic temporal reasoning,\nPNE-SGAN offers a highly accurate and robust solution for LiDAR LCD, enhancing\nSLAM reliability in complex, large-scale environments.", "AI": {"tldr": "PNE-SGAN improves LiDAR loop closure detection by combining NDT-enhanced semantic graphs with probabilistic temporal filtering, achieving high accuracy and robustness.", "motivation": "Existing methods for LiDAR loop closure detection lack robustness and accuracy due to coarse geometric representations and sensitivity to noise and viewpoint changes.", "method": "PNE-SGAN uses NDT covariance matrices as geometric node features in a Graph Attention Network and integrates graph similarity scores into a probabilistic temporal filtering framework.", "result": "PNE-SGAN achieves state-of-the-art performance on KITTI sequences (96.2% and 95.1% Average Precision) and excels in challenging bidirectional loop scenarios.", "conclusion": "PNE-SGAN provides a highly accurate and robust solution for LiDAR loop closure detection, enhancing SLAM reliability in complex environments."}}
{"id": "2504.17393", "pdf": "https://arxiv.org/pdf/2504.17393", "abs": "https://arxiv.org/abs/2504.17393", "authors": ["Vesna Nowack", "Dalal Alrajeh", "Carolina Gutierrez Mu\u00f1oz", "Katie Thomas", "William Hobson", "Patrick Benjamin", "Catherine Hamilton-Giachritsis", "Tim Grant", "Juliane A. Kloess", "Jessica Woodhams"], "title": "Towards User-Centred Design of AI-Assisted Decision-Making in Law Enforcement", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "10 pages", "summary": "Artificial Intelligence (AI) has become an important part of our everyday\nlives, yet user requirements for designing AI-assisted systems in law\nenforcement remain unclear. To address this gap, we conducted qualitative\nresearch on decision-making within a law enforcement agency. Our study aimed to\nidentify limitations of existing practices, explore user requirements and\nunderstand the responsibilities that humans expect to undertake in these\nsystems.\n  Participants in our study highlighted the need for a system capable of\nprocessing and analysing large volumes of data efficiently to help in crime\ndetection and prevention. Additionally, the system should satisfy requirements\nfor scalability, accuracy, justification, trustworthiness and adaptability to\nbe adopted in this domain. Participants also emphasised the importance of\nhaving end users review the input data that might be challenging for AI to\ninterpret, and validate the generated output to ensure the system's accuracy.\nTo keep up with the evolving nature of the law enforcement domain, end users\nneed to help the system adapt to the changes in criminal behaviour and\ngovernment guidance, and technical experts need to regularly oversee and\nmonitor the system. Furthermore, user-friendly human interaction with the\nsystem is essential for its adoption and some of the participants confirmed\nthey would be happy to be in the loop and provide necessary feedback that the\nsystem can learn from. Finally, we argue that it is very unlikely that the\nsystem will ever achieve full automation due to the dynamic and complex nature\nof the law enforcement domain.", "AI": {"tldr": "The study explores user requirements for AI-assisted systems in law enforcement, emphasizing efficiency, scalability, accuracy, and human oversight due to the domain's complexity.", "motivation": "To address unclear user requirements for designing AI-assisted systems in law enforcement by understanding limitations, needs, and human responsibilities.", "method": "Qualitative research on decision-making within a law enforcement agency, involving participant insights.", "result": "Participants identified key system requirements (efficiency, scalability, accuracy) and stressed human oversight for data review, validation, and system adaptation.", "conclusion": "Full automation is unlikely in law enforcement due to its dynamic nature; human-AI collaboration is essential for system adoption and effectiveness."}}
{"id": "2310.10745", "pdf": "https://arxiv.org/pdf/2310.10745", "abs": "https://arxiv.org/abs/2310.10745", "authors": ["Priyam Gupta", "Peter J. Schmid", "Denis Sipp", "Taraneh Sayadi", "Georgios Rigas"], "title": "Mori-Zwanzig latent space Koopman closure for nonlinear autoencoder", "categories": ["cs.LG", "math.DS", "physics.flu-dyn", "stat.ML"], "comment": "23 pages, 11 figures", "summary": "The Koopman operator presents an attractive approach to achieve global\nlinearization of nonlinear systems, making it a valuable method for simplifying\nthe understanding of complex dynamics. While data-driven methodologies have\nexhibited promise in approximating finite Koopman operators, they grapple with\nvarious challenges, such as the judicious selection of observables,\ndimensionality reduction, and the ability to predict complex system behaviours\naccurately. This study presents a novel approach termed Mori-Zwanzig\nautoencoder (MZ-AE) to robustly approximate the Koopman operator in\nlow-dimensional spaces. The proposed method leverages a nonlinear autoencoder\nto extract key observables for approximating a finite invariant Koopman\nsubspace and integrates a non-Markovian correction mechanism using the\nMori-Zwanzig formalism. Consequently, this approach yields an approximate\nclosure of the dynamics within the latent manifold of the nonlinear\nautoencoder, thereby enhancing the accuracy and stability of the Koopman\noperator approximation. Demonstrations showcase the technique's improved\npredictive capability for flow around a cylinder. It also provides a low\ndimensional approximation for Kuramoto-Sivashinsky (KS) with promising\nshort-term predictability and robust long-term statistical performance. By\nbridging the gap between data-driven techniques and the mathematical\nfoundations of Koopman theory, MZ-AE offers a promising avenue for improved\nunderstanding and prediction of complex nonlinear dynamics.", "AI": {"tldr": "The paper introduces the Mori-Zwanzig autoencoder (MZ-AE) to improve Koopman operator approximation by combining nonlinear autoencoders with non-Markovian corrections, enhancing predictive accuracy for complex dynamics.", "motivation": "Data-driven methods for approximating the Koopman operator face challenges like observable selection and dimensionality reduction, limiting their accuracy for complex systems.", "method": "The MZ-AE method uses a nonlinear autoencoder to extract observables and integrates a non-Markovian correction via the Mori-Zwanzig formalism for robust approximation.", "result": "The approach improves predictive accuracy for flow around a cylinder and offers low-dimensional approximations for Kuramoto-Sivashinsky dynamics with strong short- and long-term performance.", "conclusion": "MZ-AE bridges data-driven techniques and Koopman theory, advancing the understanding and prediction of nonlinear dynamics."}}
{"id": "2504.18589", "pdf": "https://arxiv.org/pdf/2504.18589", "abs": "https://arxiv.org/abs/2504.18589", "authors": ["Zhikai Wang", "Jiashuo Sun", "Wenqi Zhang", "Zhiqiang Hu", "Xin Li", "Fan Wang", "Deli Zhao"], "title": "Benchmarking Multimodal Mathematical Reasoning with Explicit Visual Dependency", "categories": ["cs.CV"], "comment": "Home page: https://alibaba-damo-academy.github.io/VCBench/", "summary": "Recent advancements in Large Vision-Language Models (LVLMs) have\nsignificantly enhanced their ability to integrate visual and linguistic\ninformation, achieving near-human proficiency in tasks like object recognition,\ncaptioning, and visual question answering. However, current benchmarks\ntypically focus on knowledge-centric evaluations that assess domain-specific\nexpertise, often neglecting the core ability to reason about fundamental\nmathematical elements and visual concepts. We identify a gap in evaluating\nelementary-level math problems, which rely on explicit visual\ndependencies-requiring models to discern, integrate, and reason across multiple\nimages while incorporating commonsense knowledge, all of which are crucial for\nadvancing toward broader AGI capabilities. To address this gap, we introduce\nVCBENCH, a comprehensive benchmark for multimodal mathematical reasoning with\nexplicit visual dependencies. VCBENCH includes 1,720 problems across six\ncognitive domains, featuring 6,697 images (averaging 3.9 per question) to\nensure multi-image reasoning. We evaluate 26 state-of-the-art LVLMs on VCBENCH,\nrevealing substantial performance disparities, with even the top models unable\nto exceed 50% accuracy. Our findings highlight the ongoing challenges in\nvisual-mathematical integration and suggest avenues for future LVLM\nadvancements.The project can be found at\nhttps://alibaba-damo-academy.github.io/VCBench/.", "AI": {"tldr": "VCBENCH is a new benchmark for evaluating LVLMs on multimodal mathematical reasoning with visual dependencies, revealing significant performance gaps.", "motivation": "Current benchmarks overlook elementary-level math problems with visual dependencies, a key area for advancing AGI.", "method": "VCBENCH includes 1,720 problems across six domains, using 6,697 images (avg. 3.9 per question) to test multi-image reasoning.", "result": "Top LVLMs scored below 50% accuracy, showing major challenges in visual-mathematical integration.", "conclusion": "VCBENCH highlights critical gaps in LVLMs and suggests future research directions."}}
{"id": "2504.18827", "pdf": "https://arxiv.org/pdf/2504.18827", "abs": "https://arxiv.org/abs/2504.18827", "authors": ["Teeradaj Racharak", "Chaiyong Ragkhitwetsagul", "Chommakorn Sontesadisai", "Thanwadee Sunetnanta"], "title": "Test It Before You Trust It: Applying Software Testing for Trustworthy In-context Learning", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "In-context learning (ICL) has emerged as a powerful capability of large\nlanguage models (LLMs), enabling them to perform new tasks based on a few\nprovided examples without explicit fine-tuning. Despite their impressive\nadaptability, these models remain vulnerable to subtle adversarial\nperturbations and exhibit unpredictable behavior when faced with linguistic\nvariations. Inspired by software testing principles, we introduce a software\ntesting-inspired framework, called MMT4NL, for evaluating the trustworthiness\nof in-context learning by utilizing adversarial perturbations and software\ntesting techniques. It includes diverse evaluation aspects of linguistic\ncapabilities for testing the ICL capabilities of LLMs. MMT4NL is built around\nthe idea of crafting metamorphic adversarial examples from a test set in order\nto quantify and pinpoint bugs in the designed prompts of ICL. Our philosophy is\nto treat any LLM as software and validate its functionalities just like testing\nthe software. Finally, we demonstrate applications of MMT4NL on the sentiment\nanalysis and question-answering tasks. Our experiments could reveal various\nlinguistic bugs in state-of-the-art LLMs.", "AI": {"tldr": "MMT4NL is a software testing-inspired framework to evaluate the trustworthiness of in-context learning in LLMs using adversarial perturbations and linguistic variations.", "motivation": "LLMs show vulnerability to adversarial perturbations and unpredictable behavior with linguistic variations, necessitating a robust evaluation method.", "method": "MMT4NL crafts metamorphic adversarial examples from test sets to quantify and identify bugs in ICL prompts, treating LLMs like software.", "result": "The framework revealed linguistic bugs in state-of-the-art LLMs during sentiment analysis and question-answering tasks.", "conclusion": "MMT4NL effectively evaluates and improves the reliability of ICL in LLMs by applying software testing principles."}}
{"id": "2311.05139", "pdf": "https://arxiv.org/pdf/2311.05139", "abs": "https://arxiv.org/abs/2311.05139", "authors": ["Ruijie Jiang", "Thuan Nguyen", "Shuchin Aeron", "Prakash Ishwar"], "title": "Hard-Negative Sampling for Contrastive Learning: Optimal Representation Geometry and Neural- vs Dimensional-Collapse", "categories": ["cs.LG"], "comment": "Final version: Reviewed and accepted to TMLR April 2025. Updated\n  exposition, Added analysis of lower bounds", "summary": "For a widely-studied data model and general loss and sample-hardening\nfunctions we prove that the losses of Supervised Contrastive Learning (SCL),\nHard-SCL (HSCL), and Unsupervised Contrastive Learning (UCL) are minimized by\nrepresentations that exhibit Neural-Collapse (NC), i.e., the class means form\nan Equiangular Tight Frame (ETF) and data from the same class are mapped to the\nsame representation. We also prove that for any representation mapping, the\nHSCL and Hard-UCL (HUCL) losses are lower bounded by the corresponding SCL and\nUCL losses. In contrast to existing literature, our theoretical results for SCL\ndo not require class-conditional independence of augmented views and work for a\ngeneral loss function class that includes the widely used InfoNCE loss\nfunction. Moreover, our proofs are simpler, compact, and transparent. Similar\nto existing literature, our theoretical claims also hold for the practical\nscenario where batching is used for optimization. We empirically demonstrate,\nfor the first time, that Adam optimization (with batching) of HSCL and HUCL\nlosses with random initialization and suitable hardness levels can indeed\nconverge to the NC-geometry if we incorporate unit-ball or unit-sphere feature\nnormalization. Without incorporating hard-negatives or feature normalization,\nhowever, the representations learned via Adam suffer from Dimensional-Collapse\n(DC) and fail to attain the NC-geometry. These results exemplify the role of\nhard-negative sampling in contrastive representation learning and we conclude\nwith several open theoretical problems for future work. The code can be found\nat https://github.com/rjiang03/HCL/tree/main", "AI": {"tldr": "The paper proves that Supervised, Hard-Supervised, and Unsupervised Contrastive Learning losses are minimized by Neural-Collapse (NC) representations, with simpler proofs and broader applicability than prior work. Empirical results show Adam optimization with hard-negatives and feature normalization achieves NC, while their absence leads to Dimensional-Collapse.", "motivation": "To theoretically and empirically demonstrate that contrastive learning losses (SCL, HSCL, UCL) lead to Neural-Collapse (NC) representations, and to highlight the role of hard-negatives and feature normalization in avoiding Dimensional-Collapse (DC).", "method": "Theoretical proofs for loss minimization under NC conditions, empirical validation using Adam optimization with hard-negatives and feature normalization, and comparison of results with and without these components.", "result": "Losses for SCL, HSCL, and UCL are minimized by NC representations. Hard-negatives and feature normalization are crucial for achieving NC, while their absence leads to DC.", "conclusion": "Hard-negative sampling and feature normalization are essential for contrastive learning to achieve NC. The work opens theoretical problems for future research."}}
{"id": "2504.19186", "pdf": "https://arxiv.org/pdf/2504.19186", "abs": "https://arxiv.org/abs/2504.19186", "authors": ["Zhangshuo Qi", "Luqi Cheng", "Zijie Zhou", "Guangming Xiong"], "title": "LRFusionPR: A Polar BEV-Based LiDAR-Radar Fusion Network for Place Recognition", "categories": ["cs.CV", "cs.RO"], "comment": "8 pages, 6 figures", "summary": "In autonomous driving, place recognition is critical for global localization\nin GPS-denied environments. LiDAR and radar-based place recognition methods\nhave garnered increasing attention, as LiDAR provides precise ranging, whereas\nradar excels in adverse weather resilience. However, effectively leveraging\nLiDAR-radar fusion for place recognition remains challenging. The noisy and\nsparse nature of radar data limits its potential to further improve recognition\naccuracy. In addition, heterogeneous radar configurations complicate the\ndevelopment of unified cross-modality fusion frameworks. In this paper, we\npropose LRFusionPR, which improves recognition accuracy and robustness by\nfusing LiDAR with either single-chip or scanning radar. Technically, a\ndual-branch network is proposed to fuse different modalities within the unified\npolar coordinate bird's eye view (BEV) representation. In the fusion branch,\ncross-attention is utilized to perform cross-modality feature interactions. The\nknowledge from the fusion branch is simultaneously transferred to the\ndistillation branch, which takes radar as its only input to further improve the\nrobustness. Ultimately, the descriptors from both branches are concatenated,\nproducing the multimodal global descriptor for place retrieval. Extensive\nevaluations on multiple datasets demonstrate that our LRFusionPR achieves\naccurate place recognition, while maintaining robustness under varying weather\nconditions. Our open-source code will be released at\nhttps://github.com/QiZS-BIT/LRFusionPR.", "AI": {"tldr": "LRFusionPR improves autonomous driving place recognition by fusing LiDAR and radar data using a dual-branch network, enhancing accuracy and robustness in GPS-denied environments.", "motivation": "Place recognition in GPS-denied environments is crucial for autonomous driving. LiDAR and radar fusion is promising but challenged by radar data noise, sparsity, and heterogeneous configurations.", "method": "A dual-branch network fuses LiDAR and radar data in a unified polar coordinate BEV representation, using cross-attention for feature interaction and knowledge distillation for robustness.", "result": "LRFusionPR achieves accurate place recognition and maintains robustness under varying weather conditions, validated on multiple datasets.", "conclusion": "The proposed method effectively addresses challenges in LiDAR-radar fusion for place recognition, offering improved accuracy and robustness, with open-source code available."}}
{"id": "2504.21043", "pdf": "https://arxiv.org/pdf/2504.21043", "abs": "https://arxiv.org/abs/2504.21043", "authors": ["Lingxiang Wang", "Hainan Zhang", "Qinnan Zhang", "Ziwei Wang", "Hongwei Zheng", "Jin Dong", "Zhiming Zheng"], "title": "CodeBC: A More Secure Large Language Model for Smart Contract Code Generation in Blockchain", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) excel at generating code from natural language\ninstructions, yet they often lack an understanding of security vulnerabilities.\nThis limitation makes it difficult for LLMs to avoid security risks in\ngenerated code, particularly in high-security programming tasks such as smart\ncontract development for blockchain. Researchers have attempted to enhance the\nvulnerability awareness of these models by training them to differentiate\nbetween vulnerable and fixed code snippets. However, this approach relies\nheavily on manually labeled vulnerability data, which is only available for\npopular languages like Python and C++. For low-resource languages like\nSolidity, used in smart contracts, large-scale annotated datasets are scarce\nand difficult to obtain. To address this challenge, we introduce CodeBC, a code\ngeneration model specifically designed for generating secure smart contracts in\nblockchain. CodeBC employs a three-stage fine-tuning approach based on\nCodeLlama, distinguishing itself from previous methods by not relying on\npairwise vulnerability location annotations. Instead, it leverages\nvulnerability and security tags to teach the model the differences between\nvulnerable and secure code. During the inference phase, the model leverages\nsecurity tags to generate secure and robust code. Experimental results\ndemonstrate that CodeBC outperforms baseline models in terms of BLEU, CodeBLEU,\nand compilation pass rates, while significantly reducing vulnerability rates.\nThese findings validate the effectiveness and cost-efficiency of our\nthree-stage fine-tuning strategy, making CodeBC a promising solution for\ngenerating secure smart contract code.", "AI": {"tldr": "CodeBC is a model for generating secure smart contracts by leveraging vulnerability tags without needing annotated datasets, outperforming baselines in security and performance metrics.", "motivation": "LLMs lack security awareness in code generation, especially for low-resource languages like Solidity, where annotated vulnerability data is scarce.", "method": "CodeBC uses a three-stage fine-tuning approach on CodeLlama, teaching the model secure coding via vulnerability and security tags instead of pairwise annotations.", "result": "CodeBC achieves higher BLEU, CodeBLEU, and compilation pass rates while reducing vulnerabilities compared to baselines.", "conclusion": "The three-stage fine-tuning strategy is effective and cost-efficient, making CodeBC a viable solution for secure smart contract generation."}}
{"id": "2402.07545", "pdf": "https://arxiv.org/pdf/2402.07545", "abs": "https://arxiv.org/abs/2402.07545", "authors": ["Dimitrios Danopoulos", "Georgios Zervakis", "Dimitrios Soudris", "J\u00f6rg Henkel"], "title": "TransAxx: Efficient Transformers with Approximate Computing", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "Vision Transformer (ViT) models which were recently introduced by the\ntransformer architecture have shown to be very competitive and often become a\npopular alternative to Convolutional Neural Networks (CNNs). However, the high\ncomputational requirements of these models limit their practical applicability\nespecially on low-power devices. Current state-of-the-art employs approximate\nmultipliers to address the highly increased compute demands of DNN accelerators\nbut no prior research has explored their use on ViT models. In this work we\npropose TransAxx, a framework based on the popular PyTorch library that enables\nfast inherent support for approximate arithmetic to seamlessly evaluate the\nimpact of approximate computing on DNNs such as ViT models. Using TransAxx we\nanalyze the sensitivity of transformer models on the ImageNet dataset to\napproximate multiplications and perform approximate-aware finetuning to regain\naccuracy. Furthermore, we propose a methodology to generate approximate\naccelerators for ViT models. Our approach uses a Monte Carlo Tree Search (MCTS)\nalgorithm to efficiently search the space of possible configurations using a\nhardware-driven hand-crafted policy. Our evaluation demonstrates the efficacy\nof our methodology in achieving significant trade-offs between accuracy and\npower, resulting in substantial gains without compromising on performance.", "AI": {"tldr": "TransAxx, a PyTorch-based framework, enables approximate arithmetic for ViT models, improving efficiency without compromising performance.", "motivation": "ViT models are computationally demanding, limiting their use on low-power devices. Approximate multipliers, though used in DNN accelerators, haven't been explored for ViTs.", "method": "TransAxx integrates approximate arithmetic for ViTs, analyzes sensitivity on ImageNet, and uses MCTS to optimize hardware configurations.", "result": "The framework achieves significant accuracy-power trade-offs, enhancing efficiency for ViT models.", "conclusion": "TransAxx effectively addresses ViT computational demands, offering a practical solution for low-power applications."}}
{"id": "2504.20468", "pdf": "https://arxiv.org/pdf/2504.20468", "abs": "https://arxiv.org/abs/2504.20468", "authors": ["Yuanchen Wu", "Lu Zhang", "Hang Yao", "Junlong Du", "Ke Yan", "Shouhong Ding", "Yunsheng Wu", "Xiaoqiang Li"], "title": "Antidote: A Unified Framework for Mitigating LVLM Hallucinations in Counterfactual Presupposition and Object Perception", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2025", "summary": "Large Vision-Language Models (LVLMs) have achieved impressive results across\nvarious cross-modal tasks. However, hallucinations, i.e., the models generating\ncounterfactual responses, remain a challenge. Though recent studies have\nattempted to alleviate object perception hallucinations, they focus on the\nmodels' response generation, and overlooking the task question itself. This\npaper discusses the vulnerability of LVLMs in solving counterfactual\npresupposition questions (CPQs), where the models are prone to accept the\npresuppositions of counterfactual objects and produce severe hallucinatory\nresponses. To this end, we introduce \"Antidote\", a unified, synthetic\ndata-driven post-training framework for mitigating both types of hallucination\nabove. It leverages synthetic data to incorporate factual priors into questions\nto achieve self-correction, and decouple the mitigation process into a\npreference optimization problem. Furthermore, we construct \"CP-Bench\", a novel\nbenchmark to evaluate LVLMs' ability to correctly handle CPQs and produce\nfactual responses. Applied to the LLaVA series, Antidote can simultaneously\nenhance performance on CP-Bench by over 50%, POPE by 1.8-3.3%, and CHAIR & SHR\nby 30-50%, all without relying on external supervision from stronger LVLMs or\nhuman feedback and introducing noticeable catastrophic forgetting issues.", "AI": {"tldr": "The paper addresses hallucinations in Large Vision-Language Models (LVLMs) by introducing 'Antidote,' a framework to mitigate counterfactual responses, and 'CP-Bench,' a benchmark for evaluation.", "motivation": "LVLMs generate counterfactual responses, especially in counterfactual presupposition questions (CPQs), which current methods overlook.", "method": "Proposes 'Antidote,' a synthetic data-driven post-training framework for self-correction and preference optimization.", "result": "Antidote improves performance on CP-Bench by 50%, POPE by 1.8-3.3%, and CHAIR & SHR by 30-50%.", "conclusion": "Antidote effectively mitigates hallucinations without external supervision or catastrophic forgetting."}}
{"id": "2504.21226", "pdf": "https://arxiv.org/pdf/2504.21226", "abs": "https://arxiv.org/abs/2504.21226", "authors": ["Jiaqi Liu", "Ran Tong", "Aowei Shen", "Shuzheng Li", "Changlin Yang", "Lisha Xu"], "title": "MemeBLIP2: A novel lightweight multimodal system to detect harmful memes", "categories": ["cs.CV", "cs.AI"], "comment": "11pages, 3 figures, manucripts in preparation", "summary": "Memes often merge visuals with brief text to share humor or opinions, yet\nsome memes contain harmful messages such as hate speech. In this paper, we\nintroduces MemeBLIP2, a light weight multimodal system that detects harmful\nmemes by combining image and text features effectively. We build on previous\nstudies by adding modules that align image and text representations into a\nshared space and fuse them for better classification. Using BLIP-2 as the core\nvision-language model, our system is evaluated on the PrideMM datasets. The\nresults show that MemeBLIP2 can capture subtle cues in both modalities, even in\ncases with ironic or culturally specific content, thereby improving the\ndetection of harmful material.", "AI": {"tldr": "MemeBLIP2 is a lightweight multimodal system for detecting harmful memes by effectively combining image and text features, improving detection accuracy even for ironic or culturally specific content.", "motivation": "To address the challenge of detecting harmful messages in memes, which combine visuals and text, often with subtle or culturally nuanced cues.", "method": "Builds on BLIP-2, adding modules to align and fuse image and text representations in a shared space for better classification.", "result": "Evaluated on PrideMM datasets, MemeBLIP2 captures subtle multimodal cues, enhancing harmful meme detection.", "conclusion": "MemeBLIP2 effectively improves harmful meme detection by leveraging aligned multimodal features."}}
{"id": "2405.17211", "pdf": "https://arxiv.org/pdf/2405.17211", "abs": "https://arxiv.org/abs/2405.17211", "authors": ["Shuhao Cao", "Francesco Brarda", "Ruipeng Li", "Yuanzhe Xi"], "title": "Spectral-Refiner: Accurate Fine-Tuning of Spatiotemporal Fourier Neural Operator for Turbulent Flows", "categories": ["cs.LG", "cs.NA", "math.NA", "physics.flu-dyn", "65M70 (Primary), 35Q30, 76M22, 65M50, 68T07 (Secondary)"], "comment": "Published as a conference paper at ICLR 2025", "summary": "Recent advancements in operator-type neural networks have shown promising\nresults in approximating the solutions of spatiotemporal Partial Differential\nEquations (PDEs). However, these neural networks often entail considerable\ntraining expenses, and may not always achieve the desired accuracy required in\nmany scientific and engineering disciplines. In this paper, we propose a new\nlearning framework to address these issues. A new spatiotemporal adaptation is\nproposed to generalize any Fourier Neural Operator (FNO) variant to learn maps\nbetween Bochner spaces, which can perform an arbitrary-length temporal\nsuper-resolution for the first time. To better exploit this capacity, a new\nparadigm is proposed to refine the commonly adopted end-to-end neural operator\ntraining and evaluations with the help from the wisdom from traditional\nnumerical PDE theory and techniques. Specifically, in the learning problems for\nthe turbulent flow modeled by the Navier-Stokes Equations (NSE), the proposed\nparadigm trains an FNO only for a few epochs. Then, only the newly proposed\nspatiotemporal spectral convolution layer is fine-tuned without the frequency\ntruncation. The spectral fine-tuning loss function uses a negative Sobolev norm\nfor the first time in operator learning, defined through a reliable\nfunctional-type a posteriori error estimator whose evaluation is exact thanks\nto the Parseval identity. Moreover, unlike the difficult nonconvex optimization\nproblems in the end-to-end training, this fine-tuning loss is convex. Numerical\nexperiments on commonly used NSE benchmarks demonstrate significant\nimprovements in both computational efficiency and accuracy, compared to\nend-to-end evaluation and traditional numerical PDE solvers under certain\nconditions. The source code is publicly available at\nhttps://github.com/scaomath/torch-cfd.", "AI": {"tldr": "A new learning framework improves Fourier Neural Operators (FNOs) for spatiotemporal PDEs by introducing spectral fine-tuning and a convex loss function, enhancing efficiency and accuracy.", "motivation": "Existing neural networks for PDEs are costly and lack accuracy; the paper aims to address these issues with a novel framework.", "method": "Proposes spatiotemporal adaptation for FNOs, spectral fine-tuning without frequency truncation, and a convex loss function using a negative Sobolev norm.", "result": "Significant improvements in computational efficiency and accuracy on Navier-Stokes benchmarks compared to traditional methods.", "conclusion": "The framework advances operator learning for PDEs, offering a practical and efficient solution with publicly available code."}}
{"id": "2504.21718", "pdf": "https://arxiv.org/pdf/2504.21718", "abs": "https://arxiv.org/abs/2504.21718", "authors": ["Shiying Li", "Xingqun Qi", "Bingkun Yang", "Chen Weile", "Zezhao Tian", "Muyi Sun", "Qifeng Liu", "Man Zhang", "Zhenan Sun"], "title": "VividListener: Expressive and Controllable Listener Dynamics Modeling for Multi-Modal Responsive Interaction", "categories": ["cs.CV"], "comment": null, "summary": "Generating responsive listener head dynamics with nuanced emotions and\nexpressive reactions is crucial for practical dialogue modeling in various\nvirtual avatar animations. Previous studies mainly focus on the direct\nshort-term production of listener behavior. They overlook the fine-grained\ncontrol over motion variations and emotional intensity, especially in\nlong-sequence modeling. Moreover, the lack of long-term and large-scale paired\nspeaker-listener corpora including head dynamics and fine-grained\nmulti-modality annotations (e.g., text-based expression descriptions, emotional\nintensity) also limits the application of dialogue modeling.Therefore, we first\nnewly collect a large-scale multi-turn dataset of 3D dyadic conversation\ncontaining more than 1.4M valid frames for multi-modal responsive interaction,\ndubbed ListenerX. Additionally, we propose VividListener, a novel framework\nenabling fine-grained, expressive and controllable listener dynamics modeling.\nThis framework leverages multi-modal conditions as guiding principles for\nfostering coherent interactions between speakers and listeners.Specifically, we\ndesign the Responsive Interaction Module (RIM) to adaptively represent the\nmulti-modal interactive embeddings. RIM ensures the listener dynamics achieve\nfine-grained semantic coordination with textual descriptions and adjustments,\nwhile preserving expressive reaction with speaker behavior. Meanwhile, we\ndesign the Emotional Intensity Tags (EIT) for emotion intensity editing with\nmulti-modal information integration, applying to both text descriptions and\nlistener motion amplitude.Extensive experiments conducted on our newly\ncollected ListenerX dataset demonstrate that VividListener achieves\nstate-of-the-art performance, realizing expressive and controllable listener\ndynamics.", "AI": {"tldr": "The paper introduces VividListener, a framework for expressive and controllable listener head dynamics in dialogue modeling, supported by a new dataset, ListenerX.", "motivation": "Existing methods lack fine-grained control over motion variations and emotional intensity in long-sequence modeling, and there's a scarcity of large-scale paired speaker-listener corpora with multi-modal annotations.", "method": "The authors propose VividListener, which includes a Responsive Interaction Module (RIM) for multi-modal interactive embeddings and Emotional Intensity Tags (EIT) for emotion intensity editing.", "result": "VividListener achieves state-of-the-art performance on the ListenerX dataset, demonstrating expressive and controllable listener dynamics.", "conclusion": "The framework and dataset address limitations in dialogue modeling, enabling fine-grained, expressive listener behavior."}}
{"id": "2505.01709", "pdf": "https://arxiv.org/pdf/2505.01709", "abs": "https://arxiv.org/abs/2505.01709", "authors": ["Kaidong Zhang", "Rongtao Xu", "Pengzhen Ren", "Junfan Lin", "Hefeng Wu", "Liang Lin", "Xiaodan Liang"], "title": "RoBridge: A Hierarchical Architecture Bridging Cognition and Execution for General Robotic Manipulation", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "project page: https://abliao.github.io/RoBridge/", "summary": "Operating robots in open-ended scenarios with diverse tasks is a crucial\nresearch and application direction in robotics. While recent progress in\nnatural language processing and large multimodal models has enhanced robots'\nability to understand complex instructions, robot manipulation still faces the\nprocedural skill dilemma and the declarative skill dilemma in open\nenvironments. Existing methods often compromise cognitive and executive\ncapabilities. To address these challenges, in this paper, we propose RoBridge,\na hierarchical intelligent architecture for general robotic manipulation. It\nconsists of a high-level cognitive planner (HCP) based on a large-scale\npre-trained vision-language model (VLM), an invariant operable representation\n(IOR) serving as a symbolic bridge, and a generalist embodied agent (GEA).\nRoBridge maintains the declarative skill of VLM and unleashes the procedural\nskill of reinforcement learning, effectively bridging the gap between cognition\nand execution. RoBridge demonstrates significant performance improvements over\nexisting baselines, achieving a 75% success rate on new tasks and an 83%\naverage success rate in sim-to-real generalization using only five real-world\ndata samples per task. This work represents a significant step towards\nintegrating cognitive reasoning with physical execution in robotic systems,\noffering a new paradigm for general robotic manipulation.", "AI": {"tldr": "RoBridge is a hierarchical architecture for general robotic manipulation, combining cognitive planning with procedural execution to address skill dilemmas in open environments.", "motivation": "To overcome the procedural and declarative skill dilemmas in robot manipulation by integrating cognitive reasoning with physical execution.", "method": "Proposes RoBridge, consisting of a high-level cognitive planner (HCP), invariant operable representation (IOR), and generalist embodied agent (GEA).", "result": "Achieves 75% success on new tasks and 83% sim-to-real generalization with minimal real-world data.", "conclusion": "RoBridge bridges cognition and execution, advancing general robotic manipulation."}}
{"id": "2406.05227", "pdf": "https://arxiv.org/pdf/2406.05227", "abs": "https://arxiv.org/abs/2406.05227", "authors": ["Philippe Chlenski", "Quentin Chu", "Itsik Pe'er"], "title": "Mixed-Curvature Decision Trees and Random Forests", "categories": ["cs.LG"], "comment": "This paper has been replaced by a newer version at arXiv:2410.13879", "summary": "We extend decision tree and random forest algorithms to product space\nmanifolds: Cartesian products of Euclidean, hyperspherical, and hyperbolic\nmanifolds. Such spaces have extremely expressive geometries capable of\nrepresenting many arrangements of distances with low metric distortion. To\ndate, all classifiers for product spaces fit a single linear decision boundary,\nand no regressor has been described. Our method enables a simple, expressive\nmethod for classification and regression in product manifolds. We demonstrate\nthe superior accuracy of our tool compared to Euclidean methods operating in\nthe ambient space or the tangent plane of the manifold across a range of\nconstant-curvature and product manifolds. Code for our implementation and\nexperiments is available at https://github.com/pchlenski/embedders.", "AI": {"tldr": "Extends decision trees and random forests to product space manifolds for improved classification and regression.", "motivation": "Existing classifiers for product spaces are limited to single linear boundaries, and no regressors exist.", "method": "Extends decision tree and random forest algorithms to handle Cartesian products of Euclidean, hyperspherical, and hyperbolic manifolds.", "result": "Demonstrates superior accuracy over Euclidean methods in various constant-curvature and product manifolds.", "conclusion": "Provides a simple, expressive solution for classification and regression in product manifolds."}}
{"id": "2505.02406", "pdf": "https://arxiv.org/pdf/2505.02406", "abs": "https://arxiv.org/abs/2505.02406", "authors": ["Zichen Liu", "Xu Zou", "Gang Hua", "Jiahuan Zhou"], "title": "Token Coordinated Prompt Attention is Needed for Visual Prompting", "categories": ["cs.CV"], "comment": null, "summary": "Visual prompting techniques are widely used to efficiently fine-tune\npretrained Vision Transformers (ViT) by learning a small set of shared prompts\nfor all tokens. However, existing methods overlook the unique roles of\ndifferent tokens in conveying discriminative information and interact with all\ntokens using the same prompts, thereby limiting the representational capacity\nof ViT. This often leads to indistinguishable and biased prompt-extracted\nfeatures, hindering performance. To address this issue, we propose a\nplug-and-play Token Coordinated Prompt Attention (TCPA) module, which assigns\nspecific coordinated prompts to different tokens for attention-based\ninteractions. Firstly, recognizing the distinct functions of CLS and image\ntokens-global information aggregation and local feature extraction, we\ndisentangle the prompts into CLS Prompts and Image Prompts, which interact\nexclusively with CLS tokens and image tokens through attention mechanisms. This\nenhances their respective discriminative abilities. Furthermore, as different\nimage tokens correspond to distinct image patches and contain diverse\ninformation, we employ a matching function to automatically assign coordinated\nprompts to individual tokens. This enables more precise attention interactions,\nimproving the diversity and representational capacity of the extracted\nfeatures. Extensive experiments across various benchmarks demonstrate that TCPA\nsignificantly enhances the diversity and discriminative power of the extracted\nfeatures. The code is available at\nhttps://github.com/zhoujiahuan1991/ICML2025-TCPA.", "AI": {"tldr": "The paper introduces TCPA, a module for Vision Transformers that assigns specific prompts to different tokens (CLS and image tokens) to enhance feature diversity and discriminative power.", "motivation": "Existing visual prompting methods treat all tokens uniformly, limiting ViT's representational capacity and causing biased features.", "method": "TCPA disentangles prompts into CLS Prompts and Image Prompts, using attention mechanisms and a matching function for precise token-prompt interactions.", "result": "Experiments show TCPA improves feature diversity and discriminative ability across benchmarks.", "conclusion": "TCPA effectively addresses token-specific prompt interaction, enhancing ViT performance."}}
{"id": "2505.02369", "pdf": "https://arxiv.org/pdf/2505.02369", "abs": "https://arxiv.org/abs/2505.02369", "authors": ["Juyoung Yun"], "title": "Sharpness-Aware Minimization with Z-Score Gradient Filtering for Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.IT", "cs.NE", "math.IT"], "comment": null, "summary": "Sharpness-Aware Minimization (SAM) improves neural network generalization by\noptimizing the worst-case loss within a neighborhood of parameters, yet it\nperturbs parameters using the entire gradient vector, including components with\nlow statistical significance. We introduce ZSharp, a refined sharpness-aware\noptimization method that incorporates layer-wise Z-score normalization followed\nby percentile-based filtering. This process selects only the most statistically\nsignificant gradient components-those with large standardized magnitudes-for\nconstructing the perturbation direction. ZSharp retains the standard two-phase\nSAM structure of ascent and descent while modifying the ascent step to focus on\nsharper, curvature-relevant directions. We evaluate ZSharp on CIFAR-10,\nCIFAR-100, and Tiny-ImageNet using a range of models including ResNet, VGG, and\nVision Transformers. Across all architectures and datasets, ZSharp consistently\nachieves higher test accuracy compared to SAM, ASAM, and Friendly-SAM. These\nresults indicate that Z-score-based gradient filtering can enhance the\nsharpness sensitivity of the update direction, leading to improved\ngeneralization in deep neural network training.", "AI": {"tldr": "ZSharp improves SAM by using Z-score normalization and percentile-based filtering to focus on statistically significant gradient components, enhancing generalization.", "motivation": "SAM perturbs parameters using the entire gradient vector, including less significant components, which may not optimize sharpness effectively.", "method": "ZSharp applies layer-wise Z-score normalization and percentile filtering to select significant gradient components for perturbation, retaining SAM's two-phase structure.", "result": "ZSharp outperforms SAM, ASAM, and Friendly-SAM in test accuracy across CIFAR-10, CIFAR-100, and Tiny-ImageNet with various models.", "conclusion": "ZSharp's gradient filtering enhances sharpness sensitivity, leading to better generalization in neural network training."}}
{"id": "2409.16832", "pdf": "https://arxiv.org/pdf/2409.16832", "abs": "https://arxiv.org/abs/2409.16832", "authors": ["Lyudong Jin", "Ming Tang", "Jiayu Pan", "Meng Zhang", "Hao Wang"], "title": "Asynchronous Fractional Multi-Agent Deep Reinforcement Learning for Age-Minimal Mobile Edge Computing", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "In the realm of emerging real-time networked applications like cyber-physical\nsystems (CPS), the Age of Information (AoI) has merged as a pivotal metric for\nevaluating the timeliness. To meet the high computational demands, such as\nthose in intelligent manufacturing within CPS, mobile edge computing (MEC)\npresents a promising solution for optimizing computing and reducing AoI. In\nthis work, we study the timeliness of computational-intensive updates and\nexplores jointly optimize the task updating and offloading policies to minimize\nAoI. Specifically, we consider edge load dynamics and formulate a task\nscheduling problem to minimize the expected time-average AoI. The fractional\nobjective introduced by AoI and the semi-Markov game nature of the problem\nrender this challenge particularly difficult, with existing approaches not\ndirectly applicable. To this end, we present a comprehensive framework to\nfractional reinforcement learning (RL). We first introduce a fractional\nsingle-agent RL framework and prove its linear convergence. We then extend this\nto a fractional multi-agent RL framework with a convergence analysis. To tackle\nthe challenge of asynchronous control in semi-Markov game, we further design an\nasynchronous model-free fractional multi-agent RL algorithm, where each device\nmakes scheduling decisions with the hybrid action space without knowing the\nsystem dynamics and decisions of other devices. Experimental results show that\nour proposed algorithms reduce the average AoI by up to 52.6% compared with the\nbest baseline algorithm in our experiments.", "AI": {"tldr": "The paper proposes a fractional reinforcement learning framework to optimize task updating and offloading in mobile edge computing, reducing Age of Information (AoI) by up to 52.6%.", "motivation": "To address the timeliness challenges in computational-intensive updates for cyber-physical systems (CPS) using mobile edge computing (MEC).", "method": "Develops fractional single-agent and multi-agent RL frameworks, including an asynchronous model-free algorithm for semi-Markov games.", "result": "Achieves a 52.6% reduction in average AoI compared to baseline algorithms.", "conclusion": "The proposed framework effectively minimizes AoI in dynamic edge computing environments, demonstrating significant performance improvements."}}
{"id": "2505.02471", "pdf": "https://arxiv.org/pdf/2505.02471", "abs": "https://arxiv.org/abs/2505.02471", "authors": ["Inclusion AI", "Biao Gong", "Cheng Zou", "Dandan Zheng", "Hu Yu", "Jingdong Chen", "Jianxin Sun", "Junbo Zhao", "Jun Zhou", "Kaixiang Ji", "Lixiang Ru", "Libin Wang", "Qingpei Guo", "Rui Liu", "Weilong Chai", "Xinyu Xiao", "Ziyuan Huang"], "title": "Ming-Lite-Uni: Advancements in Unified Architecture for Natural Multimodal Interaction", "categories": ["cs.CV"], "comment": "https://github.com/inclusionAI/Ming/tree/main/Ming-unify", "summary": "We introduce Ming-Lite-Uni, an open-source multimodal framework featuring a\nnewly designed unified visual generator and a native multimodal autoregressive\nmodel tailored for unifying vision and language. Specifically, this project\nprovides an open-source implementation of the integrated MetaQueries and\nM2-omni framework, while introducing the novel multi-scale learnable tokens and\nmulti-scale representation alignment strategy. By leveraging a fixed MLLM and a\nlearnable diffusion model, Ming-Lite-Uni enables native multimodal AR models to\nperform both text-to-image generation and instruction based image editing\ntasks, expanding their capabilities beyond pure visual understanding. Our\nexperimental results demonstrate the strong performance of Ming-Lite-Uni and\nillustrate the impressive fluid nature of its interactive process. All code and\nmodel weights are open-sourced to foster further exploration within the\ncommunity. Notably, this work aligns with concurrent multimodal AI milestones -\nsuch as ChatGPT-4o with native image generation updated in March 25, 2025 -\nunderscoring the broader significance of unified models like Ming-Lite-Uni on\nthe path toward AGI. Ming-Lite-Uni is in alpha stage and will soon be further\nrefined.", "AI": {"tldr": "Ming-Lite-Uni is an open-source multimodal framework unifying vision and language with a visual generator and autoregressive model, supporting text-to-image generation and image editing.", "motivation": "To advance multimodal AI by integrating vision and language tasks, aligning with broader AGI goals.", "method": "Combines MetaQueries and M2-omni frameworks with multi-scale tokens and representation alignment, using a fixed MLLM and learnable diffusion model.", "result": "Demonstrates strong performance and fluid interaction, with open-sourced code and models.", "conclusion": "Ming-Lite-Uni highlights the potential of unified models for AGI, with plans for further refinement."}}
{"id": "2505.03204", "pdf": "https://arxiv.org/pdf/2505.03204", "abs": "https://arxiv.org/abs/2505.03204", "authors": ["Liu Suxing", "Byungwon Min"], "title": "DCS-ST for Classification of Breast Cancer Histopathology Images with Limited Annotations", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Deep learning methods have shown promise in classifying breast cancer\nhistopathology images, but their performance often declines with limited\nannotated data, a critical challenge in medical imaging due to the high cost\nand expertise required for annotations.", "AI": {"tldr": "Deep learning struggles with limited annotated data in breast cancer histopathology image classification.", "motivation": "Address the challenge of declining performance in deep learning models due to scarce annotated data in medical imaging.", "method": "Not explicitly stated, but implies the use of deep learning for histopathology image classification.", "result": "Performance declines with limited annotated data.", "conclusion": "Limited annotated data is a critical challenge for deep learning in medical imaging."}}
{"id": "2410.06333", "pdf": "https://arxiv.org/pdf/2410.06333", "abs": "https://arxiv.org/abs/2410.06333", "authors": ["Jenna Fromer", "Runzhong Wang", "Mrunali Manjrekar", "Austin Tripp", "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato", "Connor W. Coley"], "title": "Batched Bayesian optimization by maximizing the probability of including the optimum", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Batched Bayesian optimization (BO) can accelerate molecular design by\nefficiently identifying top-performing compounds from a large chemical library.\nExisting acquisition strategies for batch design in BO aim to balance\nexploration and exploitation. This often involves optimizing non-additive batch\nacquisition functions, necessitating approximation via myopic construction\nand/or diversity heuristics. In this work, we propose an acquisition strategy\nfor discrete optimization that is motivated by pure exploitation, qPO\n(multipoint Probability of Optimality). qPO maximizes the probability that the\nbatch includes the true optimum, which is expressible as the sum over\nindividual acquisition scores and thereby circumvents the combinatorial\nchallenge of optimizing a batch acquisition function. We differentiate the\nproposed strategy from parallel Thompson sampling and discuss how it implicitly\ncaptures diversity. Finally, we apply our method to the model-guided\nexploration of large chemical libraries and provide empirical evidence that it\nis competitive with and complements other state-of-the-art methods in batched\nBayesian optimization.", "AI": {"tldr": "Proposes qPO, a batched Bayesian optimization method for molecular design, focusing on pure exploitation to efficiently identify top compounds.", "motivation": "Existing batch BO methods balance exploration-exploitation but require approximations. qPO aims to simplify by focusing on pure exploitation.", "method": "qPO maximizes the probability the batch includes the true optimum, using additive scores to avoid combinatorial challenges.", "result": "Empirical evidence shows qPO is competitive with state-of-the-art batch BO methods.", "conclusion": "qPO offers a simpler, effective alternative for batched BO in molecular design, complementing existing methods."}}
{"id": "2505.02567", "pdf": "https://arxiv.org/pdf/2505.02567", "abs": "https://arxiv.org/abs/2505.02567", "authors": ["Xinjie Zhang", "Jintao Guo", "Shanshan Zhao", "Minghao Fu", "Lunhao Duan", "Guo-Hua Wang", "Qing-Guo Chen", "Zhao Xu", "Weihua Luo", "Kaifu Zhang"], "title": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "categories": ["cs.CV"], "comment": "This work is still in progress; Github project:\n  https://github.com/AIDC-AI/Awesome-Unified-Multimodal-Models", "summary": "Recent years have seen remarkable progress in both multimodal understanding\nmodels and image generation models. Despite their respective successes, these\ntwo domains have evolved independently, leading to distinct architectural\nparadigms: While autoregressive-based architectures have dominated multimodal\nunderstanding, diffusion-based models have become the cornerstone of image\ngeneration. Recently, there has been growing interest in developing unified\nframeworks that integrate these tasks. The emergence of GPT-4o's new\ncapabilities exemplifies this trend, highlighting the potential for\nunification. However, the architectural differences between the two domains\npose significant challenges. To provide a clear overview of current efforts\ntoward unification, we present a comprehensive survey aimed at guiding future\nresearch. First, we introduce the foundational concepts and recent advancements\nin multimodal understanding and text-to-image generation models. Next, we\nreview existing unified models, categorizing them into three main architectural\nparadigms: diffusion-based, autoregressive-based, and hybrid approaches that\nfuse autoregressive and diffusion mechanisms. For each category, we analyze the\nstructural designs and innovations introduced by related works. Additionally,\nwe compile datasets and benchmarks tailored for unified models, offering\nresources for future exploration. Finally, we discuss the key challenges facing\nthis nascent field, including tokenization strategy, cross-modal attention, and\ndata. As this area is still in its early stages, we anticipate rapid\nadvancements and will regularly update this survey. Our goal is to inspire\nfurther research and provide a valuable reference for the community. The\nreferences associated with this survey are available on GitHub\n(https://github.com/AIDC-AI/Awesome-Unified-Multimodal-Models).", "AI": {"tldr": "A survey on unifying multimodal understanding and image generation models, covering architectures, datasets, and challenges.", "motivation": "To bridge the gap between multimodal understanding (autoregressive-based) and image generation (diffusion-based) models by exploring unified frameworks.", "method": "Reviews existing unified models, categorizing them into diffusion-based, autoregressive-based, and hybrid approaches, and analyzes their designs.", "result": "Identifies key challenges (tokenization, cross-modal attention, data) and provides datasets/benchmarks for future research.", "conclusion": "Aims to inspire further research and serve as a reference, with plans for regular updates."}}
{"id": "2410.06397", "pdf": "https://arxiv.org/pdf/2410.06397", "abs": "https://arxiv.org/abs/2410.06397", "authors": ["Matthew X. Burns", "Qingyuan Hou", "Michael C. Huang"], "title": "Provable Accuracy Bounds for Hybrid Dynamical Optimization and Sampling", "categories": ["cs.LG", "cs.DS", "math.ST", "stat.TH", "60J60", "F.2.0"], "comment": "33 pages, 3 figures", "summary": "Analog dynamical accelerators (DXs) are a growing sub-field in computer\narchitecture research, offering order-of-magnitude gains in power efficiency\nand latency over traditional digital methods in several machine learning,\noptimization, and sampling tasks. However, limited-capacity accelerators\nrequire hybrid analog/digital algorithms to solve real-world problems, commonly\nusing large-neighborhood local search (LNLS) frameworks. Unlike fully digital\nalgorithms, hybrid LNLS has no non-asymptotic convergence guarantees and no\nprincipled hyperparameter selection schemes, particularly limiting cross-device\ntraining and inference.\n  In this work, we provide non-asymptotic convergence guarantees for hybrid\nLNLS by reducing to block Langevin Diffusion (BLD) algorithms. Adapting tools\nfrom classical sampling theory, we prove exponential KL-divergence convergence\nfor randomized and cyclic block selection strategies using ideal DXs. With\nfinite device variation, we provide explicit bounds on the 2-Wasserstein bias\nin terms of step duration, noise strength, and function parameters. Our BLD\nmodel provides a key link between established theory and novel computing\nplatforms, and our theoretical results provide a closed-form expression linking\ndevice variation, algorithm hyperparameters, and performance.", "AI": {"tldr": "The paper provides non-asymptotic convergence guarantees for hybrid large-neighborhood local search (LNLS) algorithms in analog dynamical accelerators (DXs) by linking them to block Langevin Diffusion (BLD).", "motivation": "Hybrid LNLS lacks non-asymptotic convergence guarantees and principled hyperparameter selection, limiting its practical use in cross-device training and inference.", "method": "The work reduces hybrid LNLS to BLD algorithms, adapting classical sampling theory to prove exponential KL-divergence convergence for randomized and cyclic block selection strategies. It also bounds 2-Wasserstein bias under finite device variation.", "result": "The paper establishes explicit bounds on performance in terms of device variation, step duration, noise strength, and function parameters, providing a closed-form expression for hyperparameter tuning.", "conclusion": "The BLD model bridges theory and analog computing, offering practical insights for hyperparameter selection and performance optimization in hybrid LNLS."}}
{"id": "2505.02784", "pdf": "https://arxiv.org/pdf/2505.02784", "abs": "https://arxiv.org/abs/2505.02784", "authors": ["Vladyslav Zalevskyi", "Thomas Sanchez", "Misha Kaandorp", "Margaux Roulet", "Diego Fajardo-Rojas", "Liu Li", "Jana Hutter", "Hongwei Bran Li", "Matthew Barkovich", "Hui Ji", "Luca Wilhelmi", "Aline D\u00e4ndliker", "C\u00e9line Steger", "M\u00e9riam Koob", "Yvan Gomez", "Anton Jakov\u010di\u0107", "Melita Klai\u0107", "Ana Ad\u017ei\u0107", "Pavel Markovi\u0107", "Gracia Grabari\u0107", "Milan Rados", "Jordina Aviles Verdera", "Gregor Kasprian", "Gregor Dovjak", "Raphael Gaubert-Rachm\u00fchl", "Maurice Aschwanden", "Qi Zeng", "Davood Karimi", "Denis Peruzzo", "Tommaso Ciceri", "Giorgio Longari", "Rachika E. Hamadache", "Amina Bouzid", "Xavier Llad\u00f3", "Simone Chiarella", "Gerard Mart\u00ed-Juan", "Miguel \u00c1ngel Gonz\u00e1lez Ballester", "Marco Castellaro", "Marco Pinamonti", "Valentina Visani", "Robin Cremese", "Ke\u00efn Sam", "Fleur Gaudfernau", "Param Ahir", "Mehul Parikh", "Maximilian Zenk", "Michael Baumgartner", "Klaus Maier-Hein", "Li Tianhong", "Yang Hong", "Zhao Longfei", "Domen Preloznik", "\u017diga \u0160piclin", "Jae Won Choi", "Muyang Li", "Jia Fu", "Guotai Wang", "Jingwen Jiang", "Lyuyang Tong", "Bo Du", "Milton O. Candela-Leal", "Andrea Gondova", "Sungmin You", "Abdul Qayyum", "Moona Mazher", "Steven A Niederer", "Andras Jakab", "Roxane Licandro", "Kelly Payette", "Meritxell Bach Cuadra"], "title": "Advances in Automated Fetal Brain MRI Segmentation and Biometry: Insights from the FeTA 2024 Challenge", "categories": ["cs.CV"], "comment": null, "summary": "Accurate fetal brain tissue segmentation and biometric analysis are essential\nfor studying brain development in utero. The FeTA Challenge 2024 advanced\nautomated fetal brain MRI analysis by introducing biometry prediction as a new\ntask alongside tissue segmentation. For the first time, our diverse\nmulti-centric test set included data from a new low-field (0.55T) MRI dataset.\nEvaluation metrics were also expanded to include the topology-specific Euler\ncharacteristic difference (ED). Sixteen teams submitted segmentation methods,\nmost of which performed consistently across both high- and low-field scans.\nHowever, longitudinal trends indicate that segmentation accuracy may be\nreaching a plateau, with results now approaching inter-rater variability. The\nED metric uncovered topological differences that were missed by conventional\nmetrics, while the low-field dataset achieved the highest segmentation scores,\nhighlighting the potential of affordable imaging systems when paired with\nhigh-quality reconstruction. Seven teams participated in the biometry task, but\nmost methods failed to outperform a simple baseline that predicted measurements\nbased solely on gestational age, underscoring the challenge of extracting\nreliable biometric estimates from image data alone. Domain shift analysis\nidentified image quality as the most significant factor affecting model\ngeneralization, with super-resolution pipelines also playing a substantial\nrole. Other factors, such as gestational age, pathology, and acquisition site,\nhad smaller, though still measurable, effects. Overall, FeTA 2024 offers a\ncomprehensive benchmark for multi-class segmentation and biometry estimation in\nfetal brain MRI, underscoring the need for data-centric approaches, improved\ntopological evaluation, and greater dataset diversity to enable clinically\nrobust and generalizable AI tools.", "AI": {"tldr": "The FeTA Challenge 2024 benchmarked automated fetal brain MRI analysis, introducing biometry prediction and low-field MRI data. Segmentation accuracy nears inter-rater variability, while biometry methods struggled. Topological metrics and data diversity were highlighted as key for future improvements.", "motivation": "To advance automated fetal brain MRI analysis by evaluating segmentation and biometry tasks, including low-field MRI data and topological metrics.", "method": "Sixteen teams submitted segmentation methods, and seven participated in biometry prediction, evaluated on multi-centric datasets including low-field MRI.", "result": "Segmentation accuracy plateaued near inter-rater variability. Biometry methods underperformed, and low-field MRI achieved high scores. Topological metrics revealed missed differences.", "conclusion": "FeTA 2024 highlights the need for data-centric approaches, better topological evaluation, and diverse datasets for robust AI tools in fetal brain MRI."}}
{"id": "2410.07550", "pdf": "https://arxiv.org/pdf/2410.07550", "abs": "https://arxiv.org/abs/2410.07550", "authors": ["Weizhu Qian", "Dalin Zhang", "Yan Zhao", "Yunyao Cheng"], "title": "Conditional Lagrangian Wasserstein Flow for Time Series Imputation", "categories": ["cs.LG", "stat.ML"], "comment": "20 pages, 4 figures", "summary": "Time series imputation is important for numerous real-world applications. To\novercome the limitations of diffusion model-based imputation methods, e.g.,\nslow convergence in inference, we propose a novel method for time series\nimputation in this work, called Conditional Lagrangian Wasserstein Flow (CLWF).\nFollowing the principle of least action in Lagrangian mechanics, we learn the\nvelocity by minimizing the corresponding kinetic energy. Moreover, to enhance\nthe model's performance, we estimate the gradient of a task-specific potential\nfunction using a time-dependent denoising autoencoder and integrate it into the\nbase estimator to reduce the sampling variance. Finally, the proposed method\ndemonstrates competitive performance compared to other state-of-the-art\nimputation approaches.", "AI": {"tldr": "A novel method, Conditional Lagrangian Wasserstein Flow (CLWF), is proposed for time series imputation, addressing slow convergence in diffusion models by minimizing kinetic energy and integrating a task-specific potential function.", "motivation": "To overcome the limitations of diffusion model-based imputation methods, particularly slow convergence during inference.", "method": "CLWF learns velocity by minimizing kinetic energy, following Lagrangian mechanics, and integrates a time-dependent denoising autoencoder to estimate the gradient of a potential function, reducing sampling variance.", "result": "The method demonstrates competitive performance against state-of-the-art imputation approaches.", "conclusion": "CLWF is an effective solution for time series imputation, outperforming existing methods."}}
{"id": "2505.02831", "pdf": "https://arxiv.org/pdf/2505.02831", "abs": "https://arxiv.org/abs/2505.02831", "authors": ["Dengyang Jiang", "Mengmeng Wang", "Liuzhuozheng Li", "Lei Zhang", "Haoyu Wang", "Wei Wei", "Guang Dai", "Yanning Zhang", "Jingdong Wang"], "title": "No Other Representation Component Is Needed: Diffusion Transformers Can Provide Representation Guidance by Themselves", "categories": ["cs.CV"], "comment": "Self-Representation Alignment for Diffusion Transformers", "summary": "Recent studies have demonstrated that learning a meaningful internal\nrepresentation can both accelerate generative training and enhance generation\nquality of the diffusion transformers. However, existing approaches necessitate\nto either introduce an additional and complex representation training framework\nor rely on a large-scale, pre-trained representation foundation model to\nprovide representation guidance during the original generative training\nprocess. In this study, we posit that the unique discriminative process\ninherent to diffusion transformers enables them to offer such guidance without\nrequiring external representation components. We therefore propose\nSelf-Representation Alignment (SRA), a simple yet straightforward method that\nobtain representation guidance through a self-distillation manner.\nSpecifically, SRA aligns the output latent representation of the diffusion\ntransformer in earlier layer with higher noise to that in later layer with\nlower noise to progressively enhance the overall representation learning during\nonly generative training process. Experimental results indicate that applying\nSRA to DiTs and SiTs yields consistent performance improvements. Moreover, SRA\nnot only significantly outperforms approaches relying on auxiliary, complex\nrepresentation training frameworks but also achieves performance comparable to\nmethods that heavily dependent on powerful external representation priors.", "AI": {"tldr": "Self-Representation Alignment (SRA) improves diffusion transformers' performance by aligning latent representations internally, eliminating the need for external frameworks or pre-trained models.", "motivation": "Existing methods for enhancing diffusion transformers require complex external representation frameworks or pre-trained models. SRA aims to simplify this by leveraging the model's inherent discriminative process.", "method": "SRA aligns latent representations between earlier (noisier) and later (cleaner) layers of the diffusion transformer through self-distillation during generative training.", "result": "SRA consistently improves performance for DiTs and SiTs, outperforming complex auxiliary frameworks and matching methods relying on external representation priors.", "conclusion": "SRA is an effective, simple method for enhancing diffusion transformers without external dependencies, demonstrating strong performance and practicality."}}
{"id": "2410.14081", "pdf": "https://arxiv.org/pdf/2410.14081", "abs": "https://arxiv.org/abs/2410.14081", "authors": ["Shangzhe Li", "Zhiao Huang", "Hao Su"], "title": "Reward-free World Models for Online Imitation Learning", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Imitation learning (IL) enables agents to acquire skills directly from expert\ndemonstrations, providing a compelling alternative to reinforcement learning.\nHowever, prior online IL approaches struggle with complex tasks characterized\nby high-dimensional inputs and complex dynamics. In this work, we propose a\nnovel approach to online imitation learning that leverages reward-free world\nmodels. Our method learns environmental dynamics entirely in latent spaces\nwithout reconstruction, enabling efficient and accurate modeling. We adopt the\ninverse soft-Q learning objective, reformulating the optimization process in\nthe Q-policy space to mitigate the instability associated with traditional\noptimization in the reward-policy space. By employing a learned latent dynamics\nmodel and planning for control, our approach consistently achieves stable,\nexpert-level performance in tasks with high-dimensional observation or action\nspaces and intricate dynamics. We evaluate our method on a diverse set of\nbenchmarks, including DMControl, MyoSuite, and ManiSkill2, demonstrating\nsuperior empirical performance compared to existing approaches.", "AI": {"tldr": "A novel online imitation learning method using reward-free world models in latent spaces achieves stable, expert-level performance in complex tasks.", "motivation": "Prior online IL methods struggle with high-dimensional inputs and complex dynamics, necessitating a more efficient and stable approach.", "method": "Leverages reward-free world models in latent spaces, uses inverse soft-Q learning for optimization, and employs learned latent dynamics for planning.", "result": "Demonstrates superior performance on benchmarks like DMControl, MyoSuite, and ManiSkill2.", "conclusion": "The proposed method effectively addresses instability and inefficiency in complex tasks, outperforming existing approaches."}}
{"id": "2505.03567", "pdf": "https://arxiv.org/pdf/2505.03567", "abs": "https://arxiv.org/abs/2505.03567", "authors": ["Zengli Luo", "Canlong Zhang", "Xiaochun Lu", "Zhixin Li", "Zhiwen Wang"], "title": "Uncertainty-Aware Prototype Semantic Decoupling for Text-Based Person Search in Full Images", "categories": ["cs.CV"], "comment": "9pages,5figures", "summary": "Text-based pedestrian search (TBPS) in full images aims to locate a target\npedestrian in untrimmed images using natural language descriptions. However, in\ncomplex scenes with multiple pedestrians, existing methods are limited by\nuncertainties in detection and matching, leading to degraded performance. To\naddress this, we propose UPD-TBPS, a novel framework comprising three modules:\nMulti-granularity Uncertainty Estimation (MUE), Prototype-based Uncertainty\nDecoupling (PUD), and Cross-modal Re-identification (ReID). MUE conducts\nmulti-granularity queries to identify potential targets and assigns confidence\nscores to reduce early-stage uncertainty. PUD leverages visual context\ndecoupling and prototype mining to extract features of the target pedestrian\ndescribed in the query. It separates and learns pedestrian prototype\nrepresentations at both the coarse-grained cluster level and the fine-grained\nindividual level, thereby reducing matching uncertainty. ReID evaluates\ncandidates with varying confidence levels, improving detection and retrieval\naccuracy. Experiments on CUHK-SYSU-TBPS and PRW-TBPS datasets validate the\neffectiveness of our framework.", "AI": {"tldr": "UPD-TBPS is a new framework for text-based pedestrian search that reduces uncertainties in detection and matching using multi-granularity uncertainty estimation, prototype-based decoupling, and cross-modal re-identification.", "motivation": "Existing methods for text-based pedestrian search struggle with uncertainties in complex scenes, leading to degraded performance.", "method": "The framework includes Multi-granularity Uncertainty Estimation (MUE), Prototype-based Uncertainty Decoupling (PUD), and Cross-modal Re-identification (ReID) to improve target identification and matching.", "result": "Experiments on CUHK-SYSU-TBPS and PRW-TBPS datasets confirm the framework's effectiveness.", "conclusion": "UPD-TBPS successfully addresses uncertainties in pedestrian search, enhancing detection and retrieval accuracy."}}
{"id": "2410.14659", "pdf": "https://arxiv.org/pdf/2410.14659", "abs": "https://arxiv.org/abs/2410.14659", "authors": ["Daiqi Gao", "Hsin-Yu Lai", "Predrag Klasnja", "Susan A. Murphy"], "title": "Harnessing Causality in Reinforcement Learning With Bagged Decision Times", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We consider reinforcement learning (RL) for a class of problems with bagged\ndecision times. A bag contains a finite sequence of consecutive decision times.\nThe transition dynamics are non-Markovian and non-stationary within a bag. All\nactions within a bag jointly impact a single reward, observed at the end of the\nbag. For example, in mobile health, multiple activity suggestions in a day\ncollectively affect a user's daily commitment to being active. Our goal is to\ndevelop an online RL algorithm to maximize the discounted sum of the\nbag-specific rewards. To handle non-Markovian transitions within a bag, we\nutilize an expert-provided causal directed acyclic graph (DAG). Based on the\nDAG, we construct states as a dynamical Bayesian sufficient statistic of the\nobserved history, which results in Markov state transitions within and across\nbags. We then formulate this problem as a periodic Markov decision process\n(MDP) that allows non-stationarity within a period. An online RL algorithm\nbased on Bellman equations for stationary MDPs is generalized to handle\nperiodic MDPs. We show that our constructed state achieves the maximal optimal\nvalue function among all state constructions for a periodic MDP. Finally, we\nevaluate the proposed method on testbed variants built from real data in a\nmobile health clinical trial.", "AI": {"tldr": "The paper proposes an online RL algorithm for problems with bagged decision times, using causal DAGs to handle non-Markovian transitions and formulating it as a periodic MDP.", "motivation": "Addressing RL problems where actions within a finite sequence (bag) jointly impact a single reward, common in scenarios like mobile health interventions.", "method": "Utilizes expert-provided causal DAGs to construct states as Bayesian sufficient statistics, transforming the problem into a periodic MDP. Generalizes Bellman equations for stationary MDPs to periodic ones.", "result": "The constructed state achieves the maximal optimal value function. The method is validated on testbed variants from real mobile health data.", "conclusion": "The approach effectively handles non-Markovian and non-stationary transitions in bagged decision-time problems, demonstrating practical utility in mobile health."}}
{"id": "2505.03631", "pdf": "https://arxiv.org/pdf/2505.03631", "abs": "https://arxiv.org/abs/2505.03631", "authors": ["Linhan Cao", "Wei Sun", "Kaiwei Zhang", "Yicong Peng", "Guangtao Zhai", "Xiongkuo Min"], "title": "Breaking Annotation Barriers: Generalized Video Quality Assessment via Ranking-based Self-Supervision", "categories": ["cs.CV"], "comment": null, "summary": "Video quality assessment (VQA) is essential for quantifying perceptual\nquality in various video processing workflows, spanning from camera capture\nsystems to over-the-top streaming platforms. While recent supervised VQA models\nhave made substantial progress, the reliance on manually annotated datasets --\na process that is labor-intensive, costly, and difficult to scale up -- has\nhindered further optimization of their generalization to unseen video content\nand distortions. To bridge this gap, we introduce a self-supervised learning\nframework for VQA to learn quality assessment capabilities from large-scale,\nunlabeled web videos. Our approach leverages a \\textbf{learning-to-rank}\nparadigm to train a large multimodal model (LMM) on video pairs automatically\nlabeled via two manners, including quality pseudo-labeling by existing VQA\nmodels and relative quality ranking based on synthetic distortion simulations.\nFurthermore, we introduce a novel \\textbf{iterative self-improvement training\nstrategy}, where the trained model acts an improved annotator to iteratively\nrefine the annotation quality of training data. By training on a dataset\n$10\\times$ larger than the existing VQA benchmarks, our model: (1) achieves\nzero-shot performance on in-domain VQA benchmarks that matches or surpasses\nsupervised models; (2) demonstrates superior out-of-distribution (OOD)\ngeneralization across diverse video content and distortions; and (3) sets a new\nstate-of-the-art when fine-tuned on human-labeled datasets. Extensive\nexperimental results validate the effectiveness of our self-supervised approach\nin training generalized VQA models. The datasets and code will be publicly\nreleased to facilitate future research.", "AI": {"tldr": "A self-supervised learning framework for video quality assessment (VQA) is introduced, leveraging large-scale unlabeled web videos and iterative self-improvement to outperform supervised models.", "motivation": "The reliance on manually annotated datasets for VQA is labor-intensive and limits generalization. This work aims to overcome these challenges using self-supervised learning.", "method": "The approach uses a learning-to-rank paradigm on video pairs labeled via pseudo-labeling and synthetic distortions, with an iterative self-improvement strategy to refine annotations.", "result": "The model achieves zero-shot performance matching supervised models, superior out-of-distribution generalization, and state-of-the-art results when fine-tuned.", "conclusion": "The self-supervised framework effectively trains generalized VQA models, with datasets and code to be released for future research."}}
{"id": "2412.01124", "pdf": "https://arxiv.org/pdf/2412.01124", "abs": "https://arxiv.org/abs/2412.01124", "authors": ["Qingtian Zhu", "Yumin Zheng", "Yuling Sang", "Yifan Zhan", "Ziyan Zhu", "Jun Ding", "Yinqiang Zheng"], "title": "SUICA: Learning Super-high Dimensional Sparse Implicit Neural Representations for Spatial Transcriptomics", "categories": ["cs.LG", "q-bio.GN"], "comment": "ICML 2025", "summary": "Spatial Transcriptomics (ST) is a method that captures gene expression\nprofiles aligned with spatial coordinates. The discrete spatial distribution\nand the super-high dimensional sequencing results make ST data challenging to\nbe modeled effectively. In this paper, we manage to model ST in a continuous\nand compact manner by the proposed tool, SUICA, empowered by the great\napproximation capability of Implicit Neural Representations (INRs) that can\nenhance both the spatial density and the gene expression. Concretely within the\nproposed SUICA, we incorporate a graph-augmented Autoencoder to effectively\nmodel the context information of the unstructured spots and provide informative\nembeddings that are structure-aware for spatial mapping. We also tackle the\nextremely skewed distribution in a regression-by-classification fashion and\nenforce classification-based loss functions for the optimization of SUICA. By\nextensive experiments of a wide range of common ST platforms under varying\ndegradations, SUICA outperforms both conventional INR variants and SOTA methods\nregarding numerical fidelity, statistical correlation, and bio-conservation.\nThe prediction by SUICA also showcases amplified gene signatures that enriches\nthe bio-conservation of the raw data and benefits subsequent analysis. The code\nis available at https://github.com/Szym29/SUICA.", "AI": {"tldr": "SUICA is a tool using Implicit Neural Representations (INRs) and a graph-augmented Autoencoder to model Spatial Transcriptomics (ST) data continuously and compactly, improving spatial density and gene expression.", "motivation": "ST data is challenging due to its discrete spatial distribution and high dimensionality. SUICA aims to model it effectively.", "method": "SUICA combines INRs with a graph-augmented Autoencoder, uses regression-by-classification for skewed data, and employs classification-based loss functions.", "result": "SUICA outperforms conventional INR variants and SOTA methods in numerical fidelity, statistical correlation, and bio-conservation. It also enriches gene signatures.", "conclusion": "SUICA effectively models ST data, enhancing spatial and gene expression analysis, and benefits downstream applications."}}
{"id": "2408.13117", "pdf": "https://arxiv.org/pdf/2408.13117", "abs": "https://arxiv.org/abs/2408.13117", "authors": ["Yuou Sun", "Bailin Deng", "Juyong Zhang"], "title": "End-to-end Surface Optimization for Light Control", "categories": ["cs.GR", "cs.CV"], "comment": "This is the author's version of the work. It is posted here for your\n  personal use. Not for redistribution. The definitive Version of Record was\n  published in ACM Transactions on Graphics, https://doi.org/10.1145/3732284", "summary": "Designing a freeform surface to reflect or refract light to achieve a target\ndistribution is a challenging inverse problem. In this paper, we propose an\nend-to-end optimization strategy for an optical surface mesh. Our formulation\nleverages a novel differentiable rendering model, and is directly driven by the\ndifference between the resulting light distribution and the target\ndistribution. We also enforce geometric constraints related to fabrication\nrequirements, to facilitate CNC milling and polishing of the designed surface.\nTo address the issue of local minima, we formulate a face-based optimal\ntransport problem between the current mesh and the target distribution, which\nmakes effective large changes to the surface shape. The combination of our\noptimal transport update and rendering-guided optimization produces an optical\nsurface design with a resulting image closely resembling the target, while the\ngeometric constraints in our optimization help to ensure consistency between\nthe rendering model and the final physical results. The effectiveness of our\nalgorithm is demonstrated on a variety of target images using both simulated\nrendering and physical prototypes.", "AI": {"tldr": "An end-to-end optimization strategy for designing optical surfaces using differentiable rendering and optimal transport to match target light distributions while ensuring fabrication feasibility.", "motivation": "The challenge of designing freeform optical surfaces to achieve specific light distributions, requiring solutions that balance accuracy and manufacturability.", "method": "Uses a differentiable rendering model and face-based optimal transport to optimize surface meshes, incorporating geometric constraints for CNC milling and polishing.", "result": "Produces optical surfaces with light distributions closely matching targets, validated through simulations and physical prototypes.", "conclusion": "The method effectively combines rendering-guided optimization and optimal transport to achieve accurate and manufacturable optical designs."}}
{"id": "2412.11646", "pdf": "https://arxiv.org/pdf/2412.11646", "abs": "https://arxiv.org/abs/2412.11646", "authors": ["Nour Jamoussi", "Giuseppe Serra", "Photios A. Stavrou", "Marios Kountouris"], "title": "Information-Geometric Barycenters for Bayesian Federated Learning", "categories": ["cs.LG", "cs.IT", "cs.NI", "math.IT"], "comment": null, "summary": "Federated learning (FL) is a widely used and impactful distributed\noptimization framework that achieves consensus through averaging locally\ntrained models. While effective, this approach may not align well with Bayesian\ninference, where the model space has the structure of a distribution space.\nTaking an information-geometric perspective, we reinterpret FL aggregation as\nthe problem of finding the barycenter of local posteriors using a prespecified\ndivergence metric, minimizing the average discrepancy across clients. This\nperspective provides a unifying framework that generalizes many existing\nmethods and offers crisp insights into their theoretical underpinnings. We then\npropose BA-BFL, an algorithm that retains the convergence properties of\nFederated Averaging in non-convex settings. In non-independent and identically\ndistributed scenarios, we conduct extensive comparisons with statistical\naggregation techniques, showing that BA-BFL achieves performance comparable to\nstate-of-the-art methods while offering a geometric interpretation of the\naggregation phase. Additionally, we extend our analysis to Hybrid Bayesian Deep\nLearning, exploring the impact of Bayesian layers on uncertainty quantification\nand model calibration.", "AI": {"tldr": "The paper reinterprets federated learning (FL) aggregation as finding the barycenter of local posteriors using divergence metrics, proposing BA-BFL, which matches state-of-the-art performance while providing geometric insights.", "motivation": "FL's averaging approach may not align with Bayesian inference, prompting a need for a unifying framework that generalizes existing methods and offers theoretical clarity.", "method": "The study adopts an information-geometric perspective to reinterpret FL aggregation, proposes BA-BFL for non-convex settings, and compares it with statistical techniques in non-IID scenarios.", "result": "BA-BFL achieves performance comparable to state-of-the-art methods and provides a geometric interpretation of aggregation. It also explores Bayesian layers' impact in hybrid models.", "conclusion": "The framework generalizes FL methods, BA-BFL is effective in non-convex and non-IID settings, and Bayesian layers enhance uncertainty quantification."}}
{"id": "2409.15511", "pdf": "https://arxiv.org/pdf/2409.15511", "abs": "https://arxiv.org/abs/2409.15511", "authors": ["Abdul-Lateef Haji-Ali", "Marcelo Pereyra", "Luke Shaw", "Konstantinos Zygalakis"], "title": "Bayesian computation with generative diffusion models by Multilevel Monte Carlo", "categories": ["stat.CO", "cs.CV", "cs.LG"], "comment": "13 images", "summary": "Generative diffusion models have recently emerged as a powerful strategy to\nperform stochastic sampling in Bayesian inverse problems, delivering remarkably\naccurate solutions for a wide range of challenging applications. However,\ndiffusion models often require a large number of neural function evaluations\nper sample in order to deliver accurate posterior samples. As a result, using\ndiffusion models as stochastic samplers for Monte Carlo integration in Bayesian\ncomputation can be highly computationally expensive, particularly in\napplications that require a substantial number of Monte Carlo samples for\nconducting uncertainty quantification analyses. This cost is especially high in\nlarge-scale inverse problems such as computational imaging, which rely on large\nneural networks that are expensive to evaluate. With quantitative imaging\napplications in mind, this paper presents a Multilevel Monte Carlo strategy\nthat significantly reduces the cost of Bayesian computation with diffusion\nmodels. This is achieved by exploiting cost-accuracy trade-offs inherent to\ndiffusion models to carefully couple models of different levels of accuracy in\na manner that significantly reduces the overall cost of the calculation,\nwithout reducing the final accuracy. The proposed approach achieves a\n$4\\times$-to-$8\\times$ reduction in computational cost w.r.t. standard\ntechniques across three benchmark imaging problems.", "AI": {"tldr": "The paper introduces a Multilevel Monte Carlo strategy to reduce the computational cost of using diffusion models for Bayesian inverse problems, achieving significant cost savings without sacrificing accuracy.", "motivation": "Diffusion models are computationally expensive for Bayesian inverse problems, especially in large-scale applications like computational imaging, due to the high number of neural function evaluations required.", "method": "The paper proposes a Multilevel Monte Carlo approach that leverages cost-accuracy trade-offs in diffusion models, coupling models of varying accuracy to reduce computational costs.", "result": "The method achieves a 4\u00d7-to-8\u00d7 reduction in computational cost compared to standard techniques across three benchmark imaging problems.", "conclusion": "The proposed Multilevel Monte Carlo strategy effectively addresses the computational inefficiency of diffusion models in Bayesian computation, making them more practical for large-scale applications."}}
{"id": "2412.13779", "pdf": "https://arxiv.org/pdf/2412.13779", "abs": "https://arxiv.org/abs/2412.13779", "authors": ["Yichen Li", "Yuying Wang", "Haozhao Wang", "Yining Qi", "Tianzhe Xiao", "Ruixuan Li"], "title": "Rehearsal-Free Continual Federated Learning with Synergistic Synaptic Intelligence", "categories": ["cs.LG", "cs.DC"], "comment": "arXiv admin note: text overlap with arXiv:2403.05890", "summary": "Continual Federated Learning (CFL) allows distributed devices to\ncollaboratively learn novel concepts from continuously shifting training data\nwhile avoiding knowledge forgetting of previously seen tasks. To tackle this\nchallenge, most current CFL approaches rely on extensive rehearsal of previous\ndata. Despite effectiveness, rehearsal comes at a cost to memory, and it may\nalso violate data privacy. Considering these, we seek to apply regularization\ntechniques to CFL by considering their cost-efficient properties that do not\nrequire sample caching or rehearsal. Specifically, we first apply traditional\nregularization techniques to CFL and observe that existing regularization\ntechniques, especially synaptic intelligence, can achieve promising results\nunder homogeneous data distribution but fail when the data is heterogeneous.\nBased on this observation, we propose a simple yet effective regularization\nalgorithm for CFL named FedSSI, which tailors the synaptic intelligence for the\nCFL with heterogeneous data settings. FedSSI can not only reduce computational\noverhead without rehearsal but also address the data heterogeneity issue.\nExtensive experiments show that FedSSI achieves superior performance compared\nto state-of-the-art methods.", "AI": {"tldr": "FedSSI is a regularization-based method for Continual Federated Learning (CFL) that avoids rehearsal, reduces computational overhead, and handles data heterogeneity effectively.", "motivation": "Current CFL methods rely on rehearsal, which is memory-intensive and may violate privacy. The goal is to develop a cost-efficient solution without rehearsal.", "method": "FedSSI adapts synaptic intelligence for CFL, specifically addressing heterogeneous data. It avoids rehearsal and reduces computational costs.", "result": "FedSSI outperforms state-of-the-art methods, demonstrating effectiveness in heterogeneous data settings.", "conclusion": "FedSSI is a simple yet effective solution for CFL, offering privacy preservation and computational efficiency."}}
{"id": "2502.10156", "pdf": "https://arxiv.org/pdf/2502.10156", "abs": "https://arxiv.org/abs/2502.10156", "authors": ["Ruslan Agishev", "Karel Zimmermann"], "title": "MonoForce: Learnable Image-conditioned Physics Engine", "categories": ["cs.RO", "cs.CV"], "comment": "Code: https://github.com/ctu-vras/monoforce", "summary": "We propose a novel model for the prediction of robot trajectories on rough\noffroad terrain from the onboard camera images. This model enforces the laws of\nclassical mechanics through a physics-aware neural symbolic layer while\npreserving the ability to learn from large-scale data as it is end-to-end\ndifferentiable. The proposed hybrid model integrates a black-box component that\npredicts robot-terrain interaction forces with a neural-symbolic layer. This\nlayer includes a differentiable physics engine that computes the robot's\ntrajectory by querying these forces at the points of contact with the terrain.\nAs the proposed architecture comprises substantial geometrical and physics\npriors, the resulting model can also be seen as a learnable physics engine\nconditioned on real images that delivers $10^4$ trajectories per second. We\nargue and empirically demonstrate that this architecture reduces the\nsim-to-real gap and mitigates out-of-distribution sensitivity. The\ndifferentiability, in conjunction with the rapid simulation speed, makes the\nmodel well-suited for various applications including model predictive control,\ntrajectory shooting, supervised and reinforcement learning or SLAM. The codes\nand data are publicly available.", "AI": {"tldr": "A hybrid model combining neural networks and symbolic physics for predicting robot trajectories on rough terrain, reducing sim-to-real gaps and enabling fast, differentiable simulations.", "motivation": "To bridge the sim-to-real gap and improve trajectory prediction accuracy by integrating physics priors with data-driven learning.", "method": "Uses a physics-aware neural-symbolic layer with a differentiable physics engine to compute trajectories from predicted interaction forces.", "result": "Achieves 10^4 trajectories per second, reduces out-of-distribution sensitivity, and is applicable to control and learning tasks.", "conclusion": "The model effectively combines physics and learning, offering fast, accurate, and differentiable trajectory predictions for real-world applications."}}
{"id": "2501.13584", "pdf": "https://arxiv.org/pdf/2501.13584", "abs": "https://arxiv.org/abs/2501.13584", "authors": ["Rui Wang", "Mingxuan Xia", "Chang Yao", "Lei Feng", "Junbo Zhao", "Gang Chen", "Haobo Wang"], "title": "Towards Robust Incremental Learning under Ambiguous Supervision", "categories": ["cs.LG"], "comment": null, "summary": "Traditional Incremental Learning (IL) targets to handle sequential\nfully-supervised learning problems where novel classes emerge from time to\ntime. However, due to inherent annotation uncertainty and ambiguity, collecting\nhigh-quality annotated data in a dynamic learning system can be extremely\nexpensive. To mitigate this problem, we propose a novel weakly-supervised\nlearning paradigm called Incremental Partial Label Learning (IPLL), where the\nsequentially arrived data relate to a set of candidate labels rather than the\nground truth. Technically, we develop the Prototype-Guided Disambiguation and\nReplay Algorithm (PGDR) which leverages the class prototypes as a proxy to\nmitigate two intertwined challenges in IPLL, i.e., label ambiguity and\ncatastrophic forgetting. To handle the former, PGDR encapsulates a\nmomentum-based pseudo-labeling algorithm along with prototype-guided\ninitialization, resulting in a balanced perception of classes. To alleviate\nforgetting, we develop a memory replay technique that collects\nwell-disambiguated samples while maintaining representativeness and diversity.\nBy jointly distilling knowledge from curated memory data, our framework\nexhibits a great disambiguation ability for samples of new tasks and achieves\nless forgetting of knowledge. Extensive experiments demonstrate that PGDR\nachieves superior", "AI": {"tldr": "The paper introduces Incremental Partial Label Learning (IPLL) to address annotation uncertainty in dynamic learning systems. It proposes the PGDR algorithm to mitigate label ambiguity and forgetting, showing superior performance in experiments.", "motivation": "Annotation uncertainty and high costs in dynamic learning systems motivate the need for weakly-supervised learning like IPLL.", "method": "PGDR uses prototype-guided disambiguation and memory replay to handle label ambiguity and catastrophic forgetting.", "result": "PGDR achieves balanced class perception and less forgetting, outperforming in experiments.", "conclusion": "IPLL with PGDR effectively addresses annotation challenges and forgetting in incremental learning."}}
{"id": "2505.03729", "pdf": "https://arxiv.org/pdf/2505.03729", "abs": "https://arxiv.org/abs/2505.03729", "authors": ["Arthur Allshire", "Hongsuk Choi", "Junyi Zhang", "David McAllister", "Anthony Zhang", "Chung Min Kim", "Trevor Darrell", "Pieter Abbeel", "Jitendra Malik", "Angjoo Kanazawa"], "title": "Visual Imitation Enables Contextual Humanoid Control", "categories": ["cs.RO", "cs.CV"], "comment": "Project website: https://www.videomimic.net/", "summary": "How can we teach humanoids to climb staircases and sit on chairs using the\nsurrounding environment context? Arguably, the simplest way is to just show\nthem-casually capture a human motion video and feed it to humanoids. We\nintroduce VIDEOMIMIC, a real-to-sim-to-real pipeline that mines everyday\nvideos, jointly reconstructs the humans and the environment, and produces\nwhole-body control policies for humanoid robots that perform the corresponding\nskills. We demonstrate the results of our pipeline on real humanoid robots,\nshowing robust, repeatable contextual control such as staircase ascents and\ndescents, sitting and standing from chairs and benches, as well as other\ndynamic whole-body skills-all from a single policy, conditioned on the\nenvironment and global root commands. VIDEOMIMIC offers a scalable path towards\nteaching humanoids to operate in diverse real-world environments.", "AI": {"tldr": "VIDEOMIMIC is a pipeline that converts human motion videos into control policies for humanoid robots, enabling skills like climbing stairs and sitting on chairs.", "motivation": "To teach humanoids complex skills using everyday human motion videos as input.", "method": "A real-to-sim-to-real pipeline that reconstructs humans and environments from videos and generates whole-body control policies.", "result": "Demonstrated robust, repeatable control for skills like stair climbing and sitting on real humanoid robots.", "conclusion": "VIDEOMIMIC provides a scalable way to train humanoids for diverse real-world tasks."}}
{"id": "2501.13790", "pdf": "https://arxiv.org/pdf/2501.13790", "abs": "https://arxiv.org/abs/2501.13790", "authors": ["Michael Crawshaw", "Blake Woodworth", "Mingrui Liu"], "title": "Local Steps Speed Up Local GD for Heterogeneous Distributed Logistic Regression", "categories": ["cs.LG"], "comment": "ICLR 2025", "summary": "We analyze two variants of Local Gradient Descent applied to distributed\nlogistic regression with heterogeneous, separable data and show convergence at\nthe rate $O(1/KR)$ for $K$ local steps and sufficiently large $R$ communication\nrounds. In contrast, all existing convergence guarantees for Local GD applied\nto any problem are at least $\\Omega(1/R)$, meaning they fail to show the\nbenefit of local updates. The key to our improved guarantee is showing progress\non the logistic regression objective when using a large stepsize $\\eta \\gg\n1/K$, whereas prior analysis depends on $\\eta \\leq 1/K$.", "AI": {"tldr": "Local Gradient Descent variants for distributed logistic regression achieve faster convergence ($O(1/KR)$) with large stepsizes, outperforming prior guarantees ($\\Omega(1/R)$).", "motivation": "To demonstrate the benefits of local updates in distributed logistic regression with heterogeneous data, which existing analyses fail to capture.", "method": "Analyzed two variants of Local Gradient Descent, focusing on large stepsizes ($\\eta \\gg 1/K$) for logistic regression.", "result": "Convergence rate of $O(1/KR)$ for $K$ local steps and sufficient $R$ rounds, improving over prior $\\Omega(1/R)$ guarantees.", "conclusion": "Large stepsizes enable faster convergence, highlighting the advantage of local updates in distributed settings."}}
{"id": "2502.00846", "pdf": "https://arxiv.org/pdf/2502.00846", "abs": "https://arxiv.org/abs/2502.00846", "authors": ["Terje Mildner", "Oliver Hamelijnck", "Paris Giampouras", "Theodoros Damoulas"], "title": "Federated Generalised Variational Inference: A Robust Probabilistic Federated Learning Framework", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted at ICML 2025", "summary": "We introduce FedGVI, a probabilistic Federated Learning (FL) framework that\nis robust to both prior and likelihood misspecification. FedGVI addresses\nlimitations in both frequentist and Bayesian FL by providing unbiased\npredictions under model misspecification, with calibrated uncertainty\nquantification. Our approach generalises previous FL approaches, specifically\nPartitioned Variational Inference (Ashman et al., 2022), by allowing robust and\nconjugate updates, decreasing computational complexity at the clients. We offer\ntheoretical analysis in terms of fixed-point convergence, optimality of the\ncavity distribution, and provable robustness to likelihood misspecification.\nFurther, we empirically demonstrate the effectiveness of FedGVI in terms of\nimproved robustness and predictive performance on multiple synthetic and real\nworld classification data sets.", "AI": {"tldr": "FedGVI is a robust probabilistic Federated Learning framework addressing model misspecification with calibrated uncertainty, outperforming existing methods in robustness and predictive performance.", "motivation": "To overcome limitations in frequentist and Bayesian FL by providing unbiased predictions and calibrated uncertainty under model misspecification.", "method": "Generalizes Partitioned Variational Inference with robust and conjugate updates, reducing client-side computational complexity.", "result": "Theoretical guarantees include fixed-point convergence, optimal cavity distribution, and robustness to likelihood misspecification. Empirical results show improved robustness and predictive performance.", "conclusion": "FedGVI effectively addresses FL challenges, offering theoretical and empirical advantages over prior methods."}}
{"id": "2502.21187", "pdf": "https://arxiv.org/pdf/2502.21187", "abs": "https://arxiv.org/abs/2502.21187", "authors": ["Fakrul Islam Tushar", "Lavsen Dahal", "Cindy McCabe", "Fong Chi Ho", "Paul Segars", "Ehsan Abadi", "Kyle J. Lafata", "Ehsan Samei", "Joseph Y. Lo"], "title": "SYN-LUNGS: Towards Simulating Lung Nodules with Anatomy-Informed Digital Twins for AI Training", "categories": ["cs.LG"], "comment": "6 figures, 12 pages", "summary": "AI models for lung cancer screening are limited by data scarcity, impacting\ngeneralizability and clinical applicability. Generative models address this\nissue but are constrained by training data variability. We introduce SYN-LUNGS,\na framework for generating high-quality 3D CT images with detailed annotations.\nSYN-LUNGS integrates XCAT3 phantoms for digital twin generation, X-Lesions for\nnodule simulation (varying size, location, and appearance), and DukeSim for CT\nimage formation with vendor and parameter variability. The dataset includes\n3,072 nodule images from 1,044 simulated CT scans, with 512 lesions and 174\ndigital twins. Models trained on clinical + simulated data outperform clinical\nonly models, achieving 10% improvement in detection, 2-9% in segmentation and\nclassification, and enhanced synthesis. By incorporating anatomy-informed\nsimulations, SYN-LUNGS provides a scalable approach for AI model development,\nparticularly in rare disease representation and improving model reliability.", "AI": {"tldr": "SYN-LUNGS generates high-quality 3D CT images with annotations to address data scarcity in AI lung cancer screening, improving model performance by 10% in detection and 2-9% in segmentation/classification.", "motivation": "AI models for lung cancer screening face data scarcity, limiting generalizability and clinical use. Generative models help but are hindered by training data variability.", "method": "SYN-LUNGS combines XCAT3 phantoms for digital twins, X-Lesions for nodule simulation, and DukeSim for CT image formation, creating a dataset of 3,072 nodule images from 1,044 CT scans.", "result": "Models trained on clinical + simulated data outperformed clinical-only models, with 10% better detection, 2-9% improvements in segmentation/classification, and enhanced synthesis.", "conclusion": "SYN-LUNGS offers a scalable solution for AI development, improving rare disease representation and model reliability through anatomy-informed simulations."}}
{"id": "2503.18216", "pdf": "https://arxiv.org/pdf/2503.18216", "abs": "https://arxiv.org/abs/2503.18216", "authors": ["Roberto Garcia", "Jerry Liu", "Daniel Sorvisto", "Sabri Eyuboglu"], "title": "Adaptive Rank Allocation: Speeding Up Modern Transformers with RaNA Adapters", "categories": ["cs.LG"], "comment": "16 pages, 5 figures. ICLR 2025", "summary": "Large Language Models (LLMs) are computationally intensive, particularly\nduring inference. Neuron-adaptive techniques, which selectively activate\nneurons in Multi-Layer Perceptron (MLP) layers, offer some speedups but suffer\nfrom limitations in modern Transformers. These include reliance on sparse\nactivations, incompatibility with attention layers, and the use of costly\nneuron masking techniques. To address these issues, we propose the Adaptive\nRank Allocation framework and introduce the Rank and Neuron Allocator (RaNA)\nadapter. RaNA adapters leverage rank adapters, which operate on linear layers\nby applying both low-rank matrix decompositions and adaptive masking to\nefficiently allocate compute without depending on activation sparsity. This\nenables RaNA to be generally applied to MLPs and linear components of attention\nmodules, while eliminating the need for expensive maskers found in\nneuron-adaptive methods. Notably, when compared to neuron adapters, RaNA\nimproves perplexity by up to 7 points and increases accuracy by up to 8\npercentage-points when reducing FLOPs by $\\sim$44% in state-of-the-art\nTransformer architectures. These results position RaNA as a robust solution for\nimproving inference efficiency in modern Transformer architectures.", "AI": {"tldr": "RaNA adapters improve LLM inference efficiency by combining low-rank matrix decompositions and adaptive masking, outperforming neuron-adaptive methods.", "motivation": "Address limitations of neuron-adaptive techniques in Transformers, such as reliance on sparse activations and costly masking.", "method": "Propose Adaptive Rank Allocation framework and RaNA adapter, applying low-rank decompositions and adaptive masking to linear layers.", "result": "Improves perplexity by 7 points and accuracy by 8 percentage-points while reducing FLOPs by ~44%.", "conclusion": "RaNA is a robust solution for efficient inference in modern Transformer architectures."}}
{"id": "2504.09604", "pdf": "https://arxiv.org/pdf/2504.09604", "abs": "https://arxiv.org/abs/2504.09604", "authors": ["Christopher M. Ackerman", "Nina Panickssery"], "title": "Mitigating Many-Shot Jailbreaking", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Many-shot jailbreaking (MSJ) is an adversarial technique that exploits the\nlong context windows of modern LLMs to circumvent model safety training by\nincluding in the prompt many examples of a \"fake\" assistant responding\ninappropriately before the final request. With enough examples, the model's\nin-context learning abilities override its safety training, and it responds as\nif it were the \"fake\" assistant. In this work, we probe the effectiveness of\ndifferent fine-tuning and input sanitization approaches on mitigating MSJ\nattacks, alone and in combination. We find incremental mitigation effectiveness\nfor each, and show that the combined techniques significantly reduce the\neffectiveness of MSJ attacks, while retaining model performance in benign\nin-context learning and conversational tasks. We suggest that our approach\ncould meaningfully ameliorate this vulnerability if incorporated into model\nsafety post-training.", "AI": {"tldr": "The paper explores mitigation techniques for Many-shot jailbreaking (MSJ) attacks on LLMs, showing combined fine-tuning and input sanitization significantly reduces attack effectiveness while preserving model performance.", "motivation": "To address the vulnerability of modern LLMs to MSJ attacks, which exploit long context windows to bypass safety training.", "method": "Probes the effectiveness of fine-tuning and input sanitization, individually and combined, against MSJ attacks.", "result": "Combined techniques significantly reduce MSJ attack effectiveness without harming benign tasks.", "conclusion": "The proposed approach could effectively mitigate MSJ vulnerabilities if integrated into post-training safety measures."}}
{"id": "2505.02222", "pdf": "https://arxiv.org/pdf/2505.02222", "abs": "https://arxiv.org/abs/2505.02222", "authors": ["Essential AI", ":", "Ishaan Shah", "Anthony M. Polloreno", "Karl Stratos", "Philip Monk", "Adarsh Chaluvaraju", "Andrew Hojel", "Andrew Ma", "Anil Thomas", "Ashish Tanwer", "Darsh J Shah", "Khoi Nguyen", "Kurt Smith", "Michael Callahan", "Michael Pust", "Mohit Parmar", "Peter Rushton", "Platon Mazarakis", "Ritvik Kapila", "Saurabh Srivastava", "Somanshu Singla", "Tim Romanski", "Yash Vanjani", "Ashish Vaswani"], "title": "Practical Efficiency of Muon for Pretraining", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We demonstrate that Muon, the simplest instantiation of a second-order\noptimizer, explicitly expands the Pareto frontier over AdamW on the\ncompute-time tradeoff. We find that Muon is more effective than AdamW in\nretaining data efficiency at large batch sizes, far beyond the so-called\ncritical batch size, while remaining computationally efficient, thus enabling\nmore economical training. We study the combination of Muon and the maximal\nupdate parameterization (muP) for efficient hyperparameter transfer and present\na simple telescoping algorithm that accounts for all sources of error in muP\nwhile introducing only a modest overhead in resources. We validate our findings\nthrough extensive experiments with model sizes up to four billion parameters\nand ablations on the data distribution and architecture.", "AI": {"tldr": "Muon, a second-order optimizer, outperforms AdamW in data efficiency at large batch sizes, enabling economical training. Combined with muP, it offers efficient hyperparameter transfer with minimal overhead.", "motivation": "To improve training efficiency and data retention at large batch sizes beyond the critical batch size, surpassing AdamW's limitations.", "method": "Muon, a second-order optimizer, is combined with the maximal update parameterization (muP) and a telescoping algorithm to handle errors in muP.", "result": "Muon retains data efficiency at large batch sizes, is computationally efficient, and works well with models up to four billion parameters.", "conclusion": "Muon expands the Pareto frontier over AdamW, offering a more economical and efficient training solution, especially at large scales."}}
{"id": "2505.02959", "pdf": "https://arxiv.org/pdf/2505.02959", "abs": "https://arxiv.org/abs/2505.02959", "authors": ["Enrique Nueve", "Bo Waggoner"], "title": "Smooth Quadratic Prediction Markets", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "When agents trade in a Duality-based Cost Function prediction market, they\ncollectively implement the learning algorithm Follow-The-Regularized-Leader. We\nask whether other learning algorithms could be used to inspire the design of\nprediction markets. By decomposing and modifying the Duality-based Cost\nFunction Market Maker's (DCFMM) pricing mechanism, we propose a new prediction\nmarket, called the Smooth Quadratic Prediction Market, the incentivizes agents\nto collectively implement general steepest gradient descent. Relative to the\nDCFMM, the Smooth Quadratic Prediction Market has a better worst-case monetary\nloss for AD securities while preserving axiom guarantees such as the existence\nof instantaneous price, information incorporation, expressiveness, no\narbitrage, and a form of incentive compatibility. To motivate the application\nof the Smooth Quadratic Prediction Market, we independently examine agents'\ntrading behavior under two realistic constraints: bounded budgets and buy-only\nsecurities. Finally, we provide an introductory analysis of an approach to\nfacilitate adaptive liquidity using the Smooth Quadratic Prediction Market. Our\nresults suggest future designs where the price update rule is separate from the\nfee structure, yet guarantees are preserved.", "AI": {"tldr": "The paper introduces the Smooth Quadratic Prediction Market, which generalizes steepest gradient descent, improving worst-case monetary loss while retaining key guarantees. It also explores trading behavior under constraints and adaptive liquidity.", "motivation": "To explore if other learning algorithms beyond Follow-The-Regularized-Leader can inspire prediction market designs, improving upon Duality-based Cost Function Market Makers.", "method": "Decomposes and modifies the DCFMM pricing mechanism to propose the Smooth Quadratic Prediction Market, incentivizing steepest gradient descent. Examines trading under bounded budgets and buy-only constraints.", "result": "The new market improves worst-case monetary loss for AD securities while preserving key axioms. Trading behavior insights under constraints are provided.", "conclusion": "Future designs can separate price update rules from fee structures while maintaining guarantees, as demonstrated by the Smooth Quadratic Prediction Market."}}
{"id": "2505.03595", "pdf": "https://arxiv.org/pdf/2505.03595", "abs": "https://arxiv.org/abs/2505.03595", "authors": ["Sidharth S. Menon", "Ameya D. Jagtap"], "title": "Anant-Net: Breaking the Curse of Dimensionality with Scalable and Interpretable Neural Surrogate for High-Dimensional PDEs", "categories": ["cs.LG"], "comment": "27 pages, 13 figures", "summary": "High-dimensional partial differential equations (PDEs) arise in diverse\nscientific and engineering applications but remain computationally intractable\ndue to the curse of dimensionality. Traditional numerical methods struggle with\nthe exponential growth in computational complexity, particularly on hypercubic\ndomains, where the number of required collocation points increases rapidly with\ndimensionality. Here, we introduce Anant-Net, an efficient neural surrogate\nthat overcomes this challenge, enabling the solution of PDEs in high\ndimensions. Unlike hyperspheres, where the internal volume diminishes as\ndimensionality increases, hypercubes retain or expand their volume (for unit or\nlarger length), making high-dimensional computations significantly more\ndemanding. Anant-Net efficiently incorporates high-dimensional boundary\nconditions and minimizes the PDE residual at high-dimensional collocation\npoints. To enhance interpretability, we integrate Kolmogorov-Arnold networks\ninto the Anant-Net architecture. We benchmark Anant-Net's performance on\nseveral linear and nonlinear high-dimensional equations, including the Poisson,\nSine-Gordon, and Allen-Cahn equations, demonstrating high accuracy and\nrobustness across randomly sampled test points from high-dimensional space.\nImportantly, Anant-Net achieves these results with remarkable efficiency,\nsolving 300-dimensional problems on a single GPU within a few hours. We also\ncompare Anant-Net's results for accuracy and runtime with other\nstate-of-the-art methods. Our findings establish Anant-Net as an accurate,\ninterpretable, and scalable framework for efficiently solving high-dimensional\nPDEs.", "AI": {"tldr": "Anant-Net is a neural surrogate for solving high-dimensional PDEs efficiently, overcoming the curse of dimensionality with high accuracy and scalability.", "motivation": "High-dimensional PDEs are computationally intractable due to exponential complexity growth, especially on hypercubic domains. Traditional methods fail, necessitating a scalable solution.", "method": "Anant-Net integrates high-dimensional boundary conditions and minimizes PDE residuals at collocation points, using Kolmogorov-Arnold networks for interpretability.", "result": "Anant-Net solves 300-dimensional PDEs on a single GPU in hours, outperforming state-of-the-art methods in accuracy and runtime.", "conclusion": "Anant-Net is an accurate, interpretable, and scalable framework for high-dimensional PDEs, setting a new benchmark in the field."}}
{"id": "2505.03712", "pdf": "https://arxiv.org/pdf/2505.03712", "abs": "https://arxiv.org/abs/2505.03712", "authors": ["Deming Sheng", "Ricardo Henao"], "title": "Learning Survival Distributions with the Asymmetric Laplace Distribution", "categories": ["cs.LG", "math.ST", "stat.TH"], "comment": "Accepted to ICML 2025", "summary": "Probabilistic survival analysis models seek to estimate the distribution of\nthe future occurrence (time) of an event given a set of covariates. In recent\nyears, these models have preferred nonparametric specifications that avoid\ndirectly estimating survival distributions via discretization. Specifically,\nthey estimate the probability of an individual event at fixed times or the time\nof an event at fixed probabilities (quantiles), using supervised learning.\nBorrowing ideas from the quantile regression literature, we propose a\nparametric survival analysis method based on the Asymmetric Laplace\nDistribution (ALD). This distribution allows for closed-form calculation of\npopular event summaries such as mean, median, mode, variation, and quantiles.\nThe model is optimized by maximum likelihood to learn, at the individual level,\nthe parameters (location, scale, and asymmetry) of the ALD distribution.\nExtensive results on synthetic and real-world data demonstrate that the\nproposed method outperforms parametric and nonparametric approaches in terms of\naccuracy, discrimination and calibration.", "AI": {"tldr": "A parametric survival analysis method using the Asymmetric Laplace Distribution (ALD) is proposed, outperforming existing parametric and nonparametric models in accuracy, discrimination, and calibration.", "motivation": "To address limitations of nonparametric survival analysis models by introducing a parametric approach with closed-form calculations for event summaries.", "method": "Uses the ALD distribution for parametric modeling, optimized via maximum likelihood to learn individual-level parameters (location, scale, asymmetry).", "result": "Demonstrates superior performance in accuracy, discrimination, and calibration on synthetic and real-world datasets.", "conclusion": "The ALD-based parametric method is a robust alternative to existing survival analysis models."}}
{"id": "1805.11792", "pdf": "https://arxiv.org/pdf/1805.11792", "abs": "https://arxiv.org/abs/1805.11792", "authors": ["Jonathan Scarlett"], "title": "Tight Regret Bounds for Bayesian Optimization in One Dimension", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT", "math.OC"], "comment": "ICML 2018 + supplementary material. This version also includes an\n  'Errata' section correcting two minor mistakes", "summary": "We consider the problem of Bayesian optimization (BO) in one dimension, under\na Gaussian process prior and Gaussian sampling noise. We provide a theoretical\nanalysis showing that, under fairly mild technical assumptions on the kernel,\nthe best possible cumulative regret up to time $T$ behaves as\n$\\Omega(\\sqrt{T})$ and $O(\\sqrt{T\\log T})$. This gives a tight characterization\nup to a $\\sqrt{\\log T}$ factor, and includes the first non-trivial lower bound\nfor noisy BO. Our assumptions are satisfied, for example, by the squared\nexponential and Mat\\'ern-$\\nu$ kernels, with the latter requiring $\\nu > 2$.\nOur results certify the near-optimality of existing bounds (Srinivas {\\em et\nal.}, 2009) for the SE kernel, while proving them to be strictly suboptimal for\nthe Mat\\'ern kernel with $\\nu > 2$.", "AI": {"tldr": "The paper analyzes Bayesian optimization (BO) in one dimension, proving tight regret bounds under Gaussian process priors and noise, highlighting near-optimality for some kernels and suboptimality for others.", "motivation": "To theoretically understand the limits of Bayesian optimization performance under noise, particularly for common kernels like squared exponential and Mat\u00e9rn.", "method": "Theoretical analysis of cumulative regret bounds for BO under Gaussian process priors and Gaussian noise, focusing on kernel-specific assumptions.", "result": "Established tight regret bounds of \u03a9(\u221aT) and O(\u221aT log T), showing near-optimality for squared exponential kernels but suboptimality for Mat\u00e9rn kernels with \u03bd > 2.", "conclusion": "The work provides foundational insights into BO performance, confirming some existing bounds while identifying areas for improvement, especially for Mat\u00e9rn kernels."}}
{"id": "1908.09173", "pdf": "https://arxiv.org/pdf/1908.09173", "abs": "https://arxiv.org/abs/1908.09173", "authors": ["Victor Chernozhukov", "Whitney Newey", "Vira Semenova"], "title": "Welfare Analysis in Dynamic Models", "categories": ["stat.ML", "cs.LG", "econ.EM"], "comment": null, "summary": "This paper introduces metrics for welfare analysis in dynamic models. We\ndevelop estimation and inference for these parameters even in the presence of a\nhigh-dimensional state space. Examples of welfare metrics include average\nwelfare, average marginal welfare effects, and welfare decompositions into\ndirect and indirect effects similar to Oaxaca (1973) and Blinder (1973). We\nderive dual and doubly robust representations of welfare metrics that\nfacilitate debiased inference. For average welfare, the value function does not\nhave to be estimated. In general, debiasing can be applied to any estimator of\nthe value function, including neural nets, random forests, Lasso, boosting, and\nother high-dimensional methods. In particular, we derive Lasso and Neural\nNetwork estimators of the value function and associated dynamic dual\nrepresentation and establish associated mean square convergence rates for these\nfunctions. Debiasing is automatic in the sense that it only requires knowledge\nof the welfare metric of interest, not the form of bias correction. The\nproposed methods are applied to estimate a dynamic behavioral model of teacher\nabsenteeism in \\cite{DHR} and associated average teacher welfare.", "AI": {"tldr": "The paper introduces welfare metrics for dynamic models, offering debiased estimation and inference methods even with high-dimensional state spaces. It includes applications like teacher absenteeism analysis.", "motivation": "To enable welfare analysis in dynamic models with high-dimensional states, addressing challenges in estimation and inference.", "method": "Develops dual and doubly robust welfare metrics, leveraging debiased inference techniques applicable to various estimators (e.g., Lasso, Neural Networks).", "result": "Proposes Lasso and Neural Network estimators for value functions, with proven convergence rates, and applies them to teacher welfare analysis.", "conclusion": "The framework provides robust, debiased welfare analysis tools, adaptable to diverse estimators and high-dimensional settings."}}
{"id": "2302.09551", "pdf": "https://arxiv.org/pdf/2302.09551", "abs": "https://arxiv.org/abs/2302.09551", "authors": ["Jiahua Xu", "Yebo Feng", "Daniel Perez", "Benjamin Livshits"], "title": "Auto.gov: Learning-based Governance for Decentralized Finance (DeFi)", "categories": ["q-fin.RM", "cs.CE", "cs.LG"], "comment": null, "summary": "Decentralized finance (DeFi) is an integral component of the blockchain\necosystem, enabling a range of financial activities through\nsmart-contract-based protocols. Traditional DeFi governance typically involves\nmanual parameter adjustments by protocol teams or token holder votes, and is\nthus prone to human bias and financial risks, undermining the system's\nintegrity and security. While existing efforts aim to establish more adaptive\nparameter adjustment schemes, there remains a need for a governance model that\nis both more efficient and resilient to significant market manipulations. In\nthis paper, we introduce \"Auto$.$gov\", a learning-based governance framework\nthat employs a deep Qnetwork (DQN) reinforcement learning (RL) strategy to\nperform semi-automated, data-driven parameter adjustments. We create a DeFi\nenvironment with an encoded action-state space akin to the Aave lending\nprotocol for simulation and testing purposes, where Auto$.$gov has demonstrated\nthe capability to retain funds that would have otherwise been lost to price\noracle attacks. In tests with real-world data, Auto$.$gov outperforms the\nbenchmark approaches by at least 14% and the static baseline model by tenfold,\nin terms of the preset performance metric--protocol profitability. Overall, the\ncomprehensive evaluations confirm that Auto$.$gov is more efficient and\neffective than traditional governance methods, thereby enhancing the security,\nprofitability, and ultimately, the sustainability of DeFi protocols.", "AI": {"tldr": "Auto$.$gov is a learning-based governance framework for DeFi, using DQN reinforcement learning to automate parameter adjustments, outperforming traditional methods by 14% and static models by tenfold in profitability.", "motivation": "Traditional DeFi governance is prone to human bias and risks, lacking efficiency and resilience against market manipulations.", "method": "Uses a deep Q-network (DQN) reinforcement learning strategy for semi-automated, data-driven parameter adjustments, tested in a simulated Aave-like DeFi environment.", "result": "Auto$.$gov retains funds lost to price oracle attacks, outperforms benchmarks by 14% and static models by tenfold in profitability.", "conclusion": "Auto$.$gov enhances DeFi protocol security, profitability, and sustainability, proving more efficient than traditional governance."}}
{"id": "2401.11679", "pdf": "https://arxiv.org/pdf/2401.11679", "abs": "https://arxiv.org/abs/2401.11679", "authors": ["Jinghuai Yao", "Puyuan Du", "Yucheng Zhao", "Yubo Wang"], "title": "Simulating Nighttime Visible Satellite Imagery of Tropical Cyclones Using Conditional Generative Adversarial Networks", "categories": ["physics.ao-ph", "cs.LG"], "comment": null, "summary": "Visible (VIS) imagery is important for monitoring Tropical Cyclones (TCs) but\nis unavailable at night. This study presents a Conditional Generative\nAdversarial Networks (CGAN) model to generate nighttime VIS imagery with\nsignificantly enhanced accuracy and spatial resolution. Our method offers three\nkey improvements compared to existing models. First, we replaced the L1 loss in\nthe pix2pix framework with the Structural Similarity Index Measure (SSIM) loss,\nwhich significantly reduced image blurriness. Second, we selected multispectral\ninfrared (IR) bands as input based on a thorough examination of their spectral\nproperties, providing essential physical information for accurate simulation.\nThird, we incorporated the direction parameters of the sun and the satellite,\nwhich addressed the dependence of VIS images on sunlight directions and enabled\na much larger training set from continuous daytime data. The model was trained\nand validated using data from the Advanced Himawari Imager (AHI) in the\ndaytime, achieving statistical results of SSIM = 0.923 and Root Mean Square\nError (RMSE) = 0.0299, which significantly surpasses existing models. We also\nperformed a cross-satellite nighttime model validation using the Day/Night Band\n(DNB) of the Visible/Infrared Imager Radiometer Suite (VIIRS), which yields\noutstanding results compared to existing models. Our model is operationally\napplied to generate accurate VIS imagery with arbitrary virtual sunlight\ndirections, significantly contributing to the nighttime monitoring of various\nmeteorological phenomena.", "AI": {"tldr": "A CGAN model generates nighttime VIS imagery for TCs with improved accuracy and resolution, using SSIM loss, multispectral IR inputs, and sunlight direction parameters, outperforming existing models.", "motivation": "VIS imagery is unavailable at night, limiting TC monitoring. This study aims to enhance nighttime VIS imagery generation.", "method": "Replaced L1 loss with SSIM loss, used multispectral IR bands, and incorporated sunlight direction parameters. Trained with AHI daytime data.", "result": "Achieved SSIM = 0.923 and RMSE = 0.0299, outperforming existing models. Validated with VIIRS DNB data.", "conclusion": "The model enables accurate nighttime VIS imagery generation, aiding meteorological monitoring."}}
{"id": "2405.13238", "pdf": "https://arxiv.org/pdf/2405.13238", "abs": "https://arxiv.org/abs/2405.13238", "authors": ["Peng Liu", "Nian Wang", "Cong Xu", "Ming Zhao", "Bin Wang", "Yi Ren"], "title": "Enhancing User Interest based on Stream Clustering and Memory Networks in Large-Scale Recommender Systems", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Recommender Systems (RSs) provide personalized recommendation service based\non user interest, which are widely used in various platforms. However, there\nare lots of users with sparse interest due to lacking consumption behaviors,\nwhich leads to poor recommendation results for them. This problem is widespread\nin large-scale RSs and is particularly difficult to address. To solve this\nchallenging problem, we propose an innovative solution called User Interest\nEnhancement (UIE). UIE enhances user interest including user profile and user\nhistory behavior sequences by leveraging the enhancement vectors and\npersonalized enhancement vectors generated based on dynamic streaming\nclustering of similar users and items from multiple perspectives, which are\nstored and updated in memory networks. UIE not only remarkably improves model\nperformance for users with sparse interest, but also delivers notable gains for\nother users. As an end-to-end solution, UIE is easy to implement on top of\nexisting ranking models. Furthermore, we extend our approach to long-tail items\nusing similar methods, which also yields excellent improvements. We conduct\nextensive offline and online experiments in a large-scale industrial RS. The\nresults demonstrate that our model substantially outperforms other existing\napproaches, especially for users with sparse interest. UIE has been deployed in\nseveral large-scale RSs at Tencent since 2022, which was made public on 21 May\n2024. In addition, UIE-based methods have also been successfully applied in\ncandidate generation, pre-ranking, and context-DNN stages. Multiple teams have\ndeveloped solutions based on UIE, focusing primarily on updating clustering\nalgorithms and attention mechanisms. As far as we know, UIE has been deployed\nby many companies. The thoughts of UIE, dynamic streaming clustering and\nsimilarity enhancement, have inspired subsequent relevant works.", "AI": {"tldr": "The paper introduces User Interest Enhancement (UIE), a method to improve recommendations for users with sparse interest by leveraging dynamic streaming clustering and memory networks.", "motivation": "Addressing the challenge of poor recommendations for users with sparse interest in large-scale recommender systems.", "method": "UIE enhances user profiles and behavior sequences using enhancement vectors from dynamic streaming clustering of similar users and items, stored in memory networks.", "result": "UIE significantly improves model performance, especially for sparse-interest users, and has been successfully deployed in industrial systems.", "conclusion": "UIE is an effective, scalable solution that outperforms existing approaches and has inspired further research and applications."}}
{"id": "2405.17248", "pdf": "https://arxiv.org/pdf/2405.17248", "abs": "https://arxiv.org/abs/2405.17248", "authors": ["Aaron T. Wang", "William Convertino", "Xiang Cheng", "Ricardo Henao", "Lawrence Carin"], "title": "On Understanding Attention-Based In-Context Learning for Categorical Data", "categories": ["stat.ML", "cs.LG"], "comment": "Accepted to ICML 2025", "summary": "In-context learning based on attention models is examined for data with\ncategorical outcomes, with inference in such models viewed from the perspective\nof functional gradient descent (GD). We develop a network composed of attention\nblocks, with each block employing a self-attention layer followed by a\ncross-attention layer, with associated skip connections. This model can exactly\nperform multi-step functional GD inference for in-context inference with\ncategorical observations. We perform a theoretical analysis of this setup,\ngeneralizing many prior assumptions in this line of work, including the class\nof attention mechanisms for which it is appropriate. We demonstrate the\nframework empirically on synthetic data, image classification and language\ngeneration.", "AI": {"tldr": "The paper explores in-context learning using attention models for categorical data, framing inference as functional gradient descent (GD). A network with attention blocks (self-attention + cross-attention) is designed to perform multi-step GD inference. Theoretical analysis generalizes prior assumptions, and empirical validation is done on synthetic data, image classification, and language generation.", "motivation": "To advance in-context learning for categorical outcomes by leveraging attention models and functional GD, addressing limitations in prior work.", "method": "A network with attention blocks (self-attention + cross-attention layers and skip connections) is developed to perform multi-step functional GD inference.", "result": "Theoretical analysis generalizes prior assumptions, and empirical results validate the framework on synthetic data, image classification, and language generation.", "conclusion": "The proposed attention-based model effectively performs in-context learning for categorical data, with theoretical and empirical support."}}
{"id": "2406.04163", "pdf": "https://arxiv.org/pdf/2406.04163", "abs": "https://arxiv.org/abs/2406.04163", "authors": ["Johannes M\u00fcller", "Semih Cayci"], "title": "Optimal Rates of Convergence for Entropy Regularization in Discounted Markov Decision Processes", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY", "37N40, 65K05, 90C05, 90C40, 90C53"], "comment": "32 pages, 1 figure", "summary": "We study the error introduced by entropy regularization in infinite-horizon,\ndiscrete, discounted Markov decision processes. We show that this error\ndecreases exponentially in the inverse regularization strength both in a\nweighted KL-divergence and in value with a problem-specific exponent. This is\nin contrast to previously known estimates, of the order $O(\\tau)$, where $\\tau$\nis the regularization strength. We provide a lower bound matching our upper\nbound up to a polynomial term, thereby characterizing the exponential\nconvergence rate for entropy regularization. Our proof relies on the\nobservation that the solutions of entropy-regularized Markov decision processes\nsolve a gradient flow of the unregularized reward with respect to a Riemannian\nmetric common in natural policy gradient methods. This correspondence allows us\nto identify the limit of this gradient flow as the generalized maximum entropy\noptimal policy, thereby characterizing the implicit bias of this gradient flow,\nwhich corresponds to a time-continuous version of the natural policy gradient\nmethod. We use our improved error estimates to show that for\nentropy-regularized natural policy gradient methods, the overall error decays\nexponentially in the square root of the number of iterations, improving over\nexisting sublinear guarantees. Finally, we extend our analysis to settings\nbeyond the entropy. In particular, we characterize the implicit bias regarding\ngeneral convex potentials and their resulting generalized natural policy\ngradients.", "AI": {"tldr": "The paper analyzes the error from entropy regularization in Markov decision processes, showing exponential convergence in regularization strength, improving prior linear estimates. It connects entropy-regularized solutions to gradient flow and extends analysis to general convex potentials.", "motivation": "To understand and quantify the error introduced by entropy regularization in Markov decision processes, improving upon existing linear error estimates and characterizing the implicit bias of gradient flow methods.", "method": "The study uses gradient flow analysis of entropy-regularized solutions, linking them to Riemannian metrics in natural policy gradient methods, and provides upper and lower bounds for error convergence.", "result": "Exponential convergence of error in regularization strength is proven, with improved guarantees for natural policy gradient methods, and extension to general convex potentials.", "conclusion": "The work provides a refined understanding of entropy regularization's impact, showing exponential convergence and broader applicability to convex potentials, enhancing theoretical guarantees for policy gradient methods."}}
{"id": "2412.09423", "pdf": "https://arxiv.org/pdf/2412.09423", "abs": "https://arxiv.org/abs/2412.09423", "authors": ["Manuel Hagel\u00fcken", "Marco F. Huber", "Marco Roth"], "title": "Data Efficient Prediction of excited-state properties using Quantum Neural Networks", "categories": ["quant-ph", "cs.LG"], "comment": "11 + 6 pages, 7 + 5 figures", "summary": "Understanding the properties of excited states of complex molecules is\ncrucial for many chemical and physical processes. Calculating these properties\nis often significantly more resource-intensive than calculating their ground\nstate counterparts. We present a quantum machine learning model that predicts\nexcited-state properties from the molecular ground state for different\ngeometric configurations. The model comprises a symmetry-invariant quantum\nneural network and a conventional neural network and is able to provide\naccurate predictions with only a few training data points. The proposed\nprocedure is fully NISQ compatible. This is achieved by using a quantum circuit\nthat requires a number of parameters linearly proportional to the number of\nmolecular orbitals, along with a parameterized measurement observable, thereby\nreducing the number of necessary measurements. We benchmark the algorithm on\nthree different molecules with three different system sizes: $H_2$ with four\norbitals, LiH with five orbitals, and $H_4$ with six orbitals. For these\nmolecules, we predict the excited state transition energies and transition\ndipole moments. We show that, in many cases, the procedure is able to\noutperform various classical models (support vector machines, Gaussian\nprocesses, and neural networks) that rely solely on classical features, by up\nto two orders of magnitude in the test mean squared error.", "AI": {"tldr": "A quantum machine learning model predicts excited-state properties from molecular ground states efficiently, outperforming classical models.", "motivation": "Understanding excited states of molecules is resource-intensive; a quantum approach could simplify this.", "method": "Combines a symmetry-invariant quantum neural network with a conventional neural network, requiring minimal training data and fewer measurements.", "result": "Outperforms classical models (SVMs, Gaussian processes, neural networks) by up to two orders of magnitude in accuracy.", "conclusion": "The proposed quantum model is efficient, NISQ-compatible, and effective for predicting excited-state properties."}}
{"id": "2501.14095", "pdf": "https://arxiv.org/pdf/2501.14095", "abs": "https://arxiv.org/abs/2501.14095", "authors": ["Kelly Ramsay", "Dylan Spicker"], "title": "Improved subsample-and-aggregate via the private modified winsorized mean", "categories": ["stat.ME", "cs.LG", "62G35, 68P27", "G.3.7; C.2.0"], "comment": "45 pages, 6 figures", "summary": "We develop a univariate, differentially private mean estimator, called the\nprivate modified winsorized mean, designed to be used as the aggregator in\nsubsample-and-aggregate. We demonstrate, via real data analysis, that common\ndifferentially private multivariate mean estimators may not perform well as the\naggregator, even in large datasets, motivating our developments.We show that\nthe modified winsorized mean is minimax optimal for several, large classes of\ndistributions, even under adversarial contamination. We also demonstrate that,\nempirically, the private modified winsorized mean performs well compared to\nother private mean estimates. We consider the modified winsorized mean as the\naggregator in subsample-and-aggregate, deriving a finite sample deviations\nbound for a subsample-and-aggregate estimate generated with the new aggregator.\nThis result yields two important insights: (i) the optimal choice of subsamples\ndepends on the bias of the estimator computed on the subsamples, and (ii) the\nrate of convergence of the subsample-and-aggregate estimator depends on the\nrobustness of the estimator computed on the subsamples.", "AI": {"tldr": "The paper introduces a differentially private mean estimator, the private modified winsorized mean, for use in subsample-and-aggregate. It shows its superiority over existing methods and proves its minimax optimality under adversarial conditions.", "motivation": "Common differentially private mean estimators perform poorly in subsample-and-aggregate, even with large datasets, necessitating a more robust solution.", "method": "Develops the private modified winsorized mean and tests it against other estimators. Analyzes its performance in subsample-and-aggregate with finite sample deviation bounds.", "result": "The new estimator is minimax optimal for large distribution classes and outperforms others empirically. Subsample-and-aggregate performance depends on subsample bias and estimator robustness.", "conclusion": "The private modified winsorized mean is a robust, optimal choice for subsample-and-aggregate, with insights on subsample selection and convergence rates."}}
{"id": "2501.14539", "pdf": "https://arxiv.org/pdf/2501.14539", "abs": "https://arxiv.org/abs/2501.14539", "authors": ["Yingchao Yu", "Yaochu Jin", "Kuangrong Hao", "Yuchen Xiao", "Yuping Yan", "Hengjie Yu"], "title": "Emergence of Abstract Rules in Recurrent Spiking Neural Networks", "categories": ["cs.NE", "cs.LG", "I.2.6"], "comment": "31 pages, 11 figures", "summary": "The emergence of abstract rules from exemplars is a cornerstone of genuine\nintelligence in both biological and artificial systems. However, the internal\norganizational principles underlying different abstract rules remain poorly\nunderstood. We propose a hierarchically modulated recurrent spiking neural\nnetwork (HM-RSNN), inspired by astrocyte signaling. The model globally\nconfigures and locally fine-tunes intrinsic neuronal properties via a two-stage\nneuromodulatory mechanism. This design enhances neuronal adaptability and\ndiversity, thus enabling fine-grained analysis of internal organizational\nprinciples. We evaluate abstract rule emergence across four cognitive task\nsets. To probe internal organization, we examine network-level connectivity via\nstructural modularity analysis and neuron-level functional biases via bin-wise\nlesion studies based on intrinsic properties. Our experiments show that HM-RSNN\nsuccessfully achieves abstract rule emergence, with rule-contingent\norganizational principles evident at both network and neuron levels. These\nfindings highlight the critical role of dynamic internal organization in\nsupporting flexible cognition.", "AI": {"tldr": "The paper introduces a hierarchically modulated recurrent spiking neural network (HM-RSNN) to study abstract rule emergence, revealing dynamic internal organization principles at network and neuron levels.", "motivation": "To understand the internal organizational principles underlying abstract rules in biological and artificial systems, which remain poorly understood.", "method": "Proposes HM-RSNN, a two-stage neuromodulatory mechanism inspired by astrocyte signaling, to globally configure and locally fine-tune neuronal properties. Evaluated across four cognitive task sets.", "result": "HM-RSNN successfully achieves abstract rule emergence, with rule-contingent organizational principles evident at both network and neuron levels.", "conclusion": "Dynamic internal organization is critical for flexible cognition, as demonstrated by HM-RSNN's performance."}}
{"id": "2502.03885", "pdf": "https://arxiv.org/pdf/2502.03885", "abs": "https://arxiv.org/abs/2502.03885", "authors": ["Chenchen Shou", "Guyue Liu", "Hao Nie", "Huaiyu Meng", "Yu Zhou", "Yimin Jiang", "Wenqing Lv", "Yelong Xu", "Yuanwei Lu", "Zhang Chen", "Yanbo Yu", "Yichen Shen", "Yibo Zhu", "Daxin Jiang"], "title": "InfiniteHBD: Building Datacenter-Scale High-Bandwidth Domain for LLM with Optical Circuit Switching Transceivers", "categories": ["cs.NI", "cs.DC", "cs.LG"], "comment": null, "summary": "Scaling Large Language Model (LLM) training relies on multi-dimensional\nparallelism, where High-Bandwidth Domains (HBDs) are critical for\ncommunication-intensive parallelism like Tensor Parallelism (TP) and Expert\nParallelism (EP). However, existing HBD architectures face fundamental\nlimitations in scalability, cost, and fault resiliency: switch-centric HBDs\n(e.g., NVL-72) incur prohibitive scaling costs, while GPU-centric HBDs (e.g.,\nTPUv3/Dojo) suffer from severe fault propagation. Switch-GPU hybrid HBDs such\nas TPUv4 takes a middle-ground approach by leveraging Optical Circuit Switches,\nbut the fault explosion radius remains large at the cube level (e.g., 64 TPUs).\n  We propose InfiniteHBD, a novel transceiver-centric HBD architecture that\nunifies connectivity and dynamic switching at the transceiver level using\nOptical Circuit Switching (OCS). By embedding OCS within each transceiver,\nInfiniteHBD achieves reconfigurable point-to-multipoint connectivity, allowing\nthe topology to adapt into variable-size rings. This design provides: i)\ndatacenter-wide scalability without cost explosion; ii) fault resilience by\nisolating failures to a single node, and iii) full bandwidth utilization for\nfault-free GPUs. Key innovations include a Silicon Photonic (SiPh) based\nlow-cost OCS transceiver (OCSTrx), a reconfigurable k-hop ring topology\nco-designed with intra-/inter-node communication, and an HBD-DCN orchestration\nalgorithm maximizing GPU utilization while minimizing cross-ToR datacenter\nnetwork traffic. The evaluation demonstrates that InfiniteHBD achieves 31% of\nthe cost of NVL-72, near-zero GPU waste ratio (over one order of magnitude\nlower than NVL-72 and TPUv4), near-zero cross-ToR traffic when node fault\nratios under 7%, and improves Model FLOPs Utilization by 3.37x compared to\nNVIDIA DGX (8 GPUs per Node).", "AI": {"tldr": "InfiniteHBD is a transceiver-centric HBD architecture using Optical Circuit Switching (OCS) for scalable, fault-resilient, and cost-efficient LLM training.", "motivation": "Existing HBD architectures (switch-centric, GPU-centric, or hybrid) face scalability, cost, and fault resiliency issues, limiting their effectiveness for large-scale LLM training.", "method": "InfiniteHBD embeds OCS in transceivers for reconfigurable point-to-multipoint connectivity, enabling dynamic ring topologies. It includes a low-cost SiPh-based OCS transceiver, a k-hop ring topology, and an orchestration algorithm.", "result": "InfiniteHBD reduces costs by 69% vs. NVL-72, minimizes GPU waste, and improves Model FLOPs Utilization by 3.37x vs. NVIDIA DGX.", "conclusion": "InfiniteHBD offers a scalable, fault-resilient, and cost-effective solution for large-scale LLM training, outperforming existing HBD architectures."}}
{"id": "2504.20984", "pdf": "https://arxiv.org/pdf/2504.20984", "abs": "https://arxiv.org/abs/2504.20984", "authors": ["Evan Li", "Tushin Mallick", "Evan Rose", "William Robertson", "Alina Oprea", "Cristina Nita-Rotaru"], "title": "ACE: A Security Architecture for LLM-Integrated App Systems", "categories": ["cs.CR", "cs.LG"], "comment": "21 pages, 13 figures; clarify relation to indirect prompt injection\n  attacks", "summary": "LLM-integrated app systems extend the utility of Large Language Models (LLMs)\nwith third-party apps that are invoked by a system LLM using interleaved\nplanning and execution phases to answer user queries. These systems introduce\nnew attack vectors where malicious apps can cause integrity violation of\nplanning or execution, availability breakdown, or privacy compromise during\nexecution.\n  In this work, we identify new attacks impacting the integrity of planning, as\nwell as the integrity and availability of execution in LLM-integrated apps, and\ndemonstrate them against IsolateGPT, a recent solution designed to mitigate\nattacks from malicious apps. We propose Abstract-Concrete-Execute (ACE), a new\nsecure architecture for LLM-integrated app systems that provides security\nguarantees for system planning and execution. Specifically, ACE decouples\nplanning into two phases by first creating an abstract execution plan using\nonly trusted information, and then mapping the abstract plan to a concrete plan\nusing installed system apps. We verify that the plans generated by our system\nsatisfy user-specified secure information flow constraints via static analysis\non the structured plan output. During execution, ACE enforces data and\ncapability barriers between apps, and ensures that the execution is conducted\naccording to the trusted abstract plan. We show experimentally that our system\nis secure against attacks from the INJECAGENT benchmark, a standard benchmark\nfor control flow integrity in the face of indirect prompt injection attacks,\nand our newly introduced attacks. Our architecture represents a significant\nadvancement towards hardening LLM-based systems containing system facilities of\nvarying levels of trustworthiness.", "AI": {"tldr": "The paper identifies vulnerabilities in LLM-integrated app systems, proposes the ACE architecture for secure planning and execution, and demonstrates its effectiveness against attacks.", "motivation": "To address security risks in LLM-integrated app systems, such as integrity violations and availability breakdowns caused by malicious apps.", "method": "Introduces Abstract-Concrete-Execute (ACE), a secure architecture that decouples planning into abstract and concrete phases, enforces barriers, and verifies plans via static analysis.", "result": "ACE is secure against attacks from the INJECAGENT benchmark and newly introduced attacks, ensuring trusted execution.", "conclusion": "ACE represents a significant step towards securing LLM-based systems with varying trust levels."}}
{"id": "2505.02173", "pdf": "https://arxiv.org/pdf/2505.02173", "abs": "https://arxiv.org/abs/2505.02173", "authors": ["Chutiphan Charoensuk", "Nathakhun Wiroonsri"], "title": "Ranked differences Pearson correlation dissimilarity with an application to electricity users time series clustering", "categories": ["stat.ML", "cs.LG"], "comment": "17 pages", "summary": "Time series clustering is an unsupervised learning method for classifying\ntime series data into groups with similar behavior. It is used in applications\nsuch as healthcare, finance, economics, energy, and climate science. Several\ntime series clustering methods have been introduced and used for over four\ndecades. Most of them focus on measuring either Euclidean distances or\nassociation dissimilarities between time series. In this work, we propose a new\ndissimilarity measure called ranked Pearson correlation dissimilarity (RDPC),\nwhich combines a weighted average of a specified fraction of the largest\nelement-wise differences with the well-known Pearson correlation dissimilarity.\nIt is incorporated into hierarchical clustering. The performance is evaluated\nand compared with existing clustering algorithms. The results show that the\nRDPC algorithm outperforms others in complicated cases involving different\nseasonal patterns, trends, and peaks. Finally, we demonstrate our method by\nclustering a random sample of customers from a Thai electricity consumption\ntime series dataset into seven groups with unique characteristics.", "AI": {"tldr": "The paper introduces a new dissimilarity measure, RDPC, for time series clustering, combining weighted element-wise differences with Pearson correlation. It outperforms existing methods in complex cases and is demonstrated on an electricity consumption dataset.", "motivation": "Time series clustering is widely used but existing methods focus on Euclidean distances or association dissimilarities. The authors aim to improve clustering performance in complex scenarios with varying patterns.", "method": "Proposes RDPC, a new dissimilarity measure combining weighted element-wise differences and Pearson correlation. Incorporated into hierarchical clustering and evaluated against existing methods.", "result": "RDPC outperforms other clustering algorithms in cases with seasonal patterns, trends, and peaks. Demonstrated effectiveness on an electricity consumption dataset.", "conclusion": "The RDPC measure enhances time series clustering, particularly in complex scenarios, and shows practical utility in real-world datasets."}}
{"id": "2505.03397", "pdf": "https://arxiv.org/pdf/2505.03397", "abs": "https://arxiv.org/abs/2505.03397", "authors": ["Chris Wise", "Akram Youssry", "Alberto Peruzzo", "Jo Plested", "Matt Woolley"], "title": "Quantum Feature Space of a Qubit Coupled to an Arbitrary Bath", "categories": ["quant-ph", "cs.LG"], "comment": "19 pages, 3 figures, 4 tables", "summary": "Qubit control protocols have traditionally leveraged a characterisation of\nthe qubit-bath coupling via its power spectral density. Previous work proposed\nthe inference of noise operators that characterise the influence of a classical\nbath using a grey-box approach that combines deep neural networks with\nphysics-encoded layers. This overall structure is complex and poses challenges\nin scaling and real-time operations. Here, we show that no expensive neural\nnetworks are needed and that this noise operator description admits an\nefficient parameterisation. We refer to the resulting parameter space as the\n\\textit{quantum feature space} of the qubit dynamics resulting from the coupled\nbath. We show that the Euclidean distance defined over the quantum feature\nspace provides an effective method for classifying noise processes in the\npresence of a given set of controls. Using the quantum feature space as the\ninput space for a simple machine learning algorithm (random forest, in this\ncase), we demonstrate that it can effectively classify the stationarity and the\nbroad class of noise processes perturbing a qubit. Finally, we explore how\ncontrol pulse parameters map to the quantum feature space.", "AI": {"tldr": "The paper simplifies qubit control by replacing complex neural networks with an efficient parameterization called the quantum feature space, enabling effective noise classification.", "motivation": "Traditional qubit control relies on complex neural networks and physics-encoded layers, which are hard to scale and operate in real-time.", "method": "Introduces a quantum feature space for efficient noise operator parameterization and uses Euclidean distance and random forest for noise classification.", "result": "Demonstrates effective classification of noise processes and explores control pulse parameter mapping.", "conclusion": "The quantum feature space simplifies qubit control and noise classification without expensive neural networks."}}
{"id": "2505.03649", "pdf": "https://arxiv.org/pdf/2505.03649", "abs": "https://arxiv.org/abs/2505.03649", "authors": ["Bernardo Marenco", "Paola Bermolen", "Marcelo Fiori", "Federico Larroca", "Gonzalo Mateos"], "title": "Weighted Random Dot Product Graphs", "categories": ["stat.ML", "cs.LG", "math.CO", "math.PR"], "comment": "30 pages, 12 figures, code to generate Figures 3 to 12 available at\n  https://github.com/bmarenco/wrdpg", "summary": "Modeling of intricate relational patterns has become a cornerstone of\ncontemporary statistical research and related data science fields. Networks,\nrepresented as graphs, offer a natural framework for this analysis. This paper\nextends the Random Dot Product Graph (RDPG) model to accommodate weighted\ngraphs, markedly broadening the model's scope to scenarios where edges exhibit\nheterogeneous weight distributions. We propose a nonparametric weighted (W)RDPG\nmodel that assigns a sequence of latent positions to each node. Inner products\nof these nodal vectors specify the moments of their incident edge weights'\ndistribution via moment-generating functions. In this way, and unlike prior\nart, the WRDPG can discriminate between weight distributions that share the\nsame mean but differ in other higher-order moments. We derive statistical\nguarantees for an estimator of the nodal's latent positions adapted from the\nworkhorse adjacency spectral embedding, establishing its consistency and\nasymptotic normality. We also contribute a generative framework that enables\nsampling of graphs that adhere to a (prescribed or data-fitted) WRDPG,\nfacilitating, e.g., the analysis and testing of observed graph metrics using\njudicious reference distributions. The paper is organized to formalize the\nmodel's definition, the estimation (or nodal embedding) process and its\nguarantees, as well as the methodologies for generating weighted graphs, all\ncomplemented by illustrative and reproducible examples showcasing the WRDPG's\neffectiveness in various network analytic applications.", "AI": {"tldr": "The paper extends the Random Dot Product Graph (RDPG) model to weighted graphs, proposing a nonparametric weighted (W)RDPG model. It offers statistical guarantees for latent position estimation and introduces a generative framework for weighted graphs.", "motivation": "To address scenarios where edges in networks exhibit heterogeneous weight distributions, which existing models like RDPG cannot handle effectively.", "method": "Proposes the WRDPG model, using latent positions and moment-generating functions to describe edge weight distributions. Derives statistical guarantees for latent position estimation and introduces a generative framework.", "result": "The WRDPG model can discriminate between weight distributions with the same mean but differing higher-order moments. Provides consistent and asymptotically normal estimators for latent positions.", "conclusion": "The WRDPG model broadens the applicability of RDPG to weighted graphs, offering theoretical guarantees and practical tools for network analysis."}}
{"id": "2505.03704", "pdf": "https://arxiv.org/pdf/2505.03704", "abs": "https://arxiv.org/abs/2505.03704", "authors": ["Kiichi Obuchi", "Yuta Yahagi", "Kiyohiko Toyama", "Shukichi Tanaka", "Kota Matsui"], "title": "Multi-modal cascade feature transfer for polymer property prediction", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In this paper, we propose a novel transfer learning approach called\nmulti-modal cascade model with feature transfer for polymer property\nprediction.Polymers are characterized by a composite of data in several\ndifferent formats, including molecular descriptors and additive information as\nwell as chemical structures. However, in conventional approaches, prediction\nmodels were often constructed using each type of data separately. Our model\nenables more accurate prediction of physical properties for polymers by\ncombining features extracted from the chemical structure by graph convolutional\nneural networks (GCN) with features such as molecular descriptors and additive\ninformation. The predictive performance of the proposed method is empirically\nevaluated using several polymer datasets. We report that the proposed method\nshows high predictive performance compared to the baseline conventional\napproach using a single feature.", "AI": {"tldr": "A novel transfer learning approach, the multi-modal cascade model with feature transfer, improves polymer property prediction by combining multiple data types (chemical structures, molecular descriptors, additive information) using GCNs.", "motivation": "Polymers have diverse data formats, but conventional methods use them separately, limiting prediction accuracy.", "method": "Combines features from chemical structures (via GCNs) with molecular descriptors and additive information for enhanced prediction.", "result": "Empirical evaluation shows superior predictive performance over single-feature baseline methods.", "conclusion": "The proposed multi-modal approach outperforms conventional methods, offering more accurate polymer property predictions."}}
