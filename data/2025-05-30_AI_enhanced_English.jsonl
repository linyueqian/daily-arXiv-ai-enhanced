{"id": "2505.22857", "pdf": "https://arxiv.org/pdf/2505.22857", "abs": "https://arxiv.org/abs/2505.22857", "authors": ["Vladimir Bataev", "Andrei Andrusenko", "Lilit Grigoryan", "Aleksandr Laptev", "Vitaly Lavrukhin", "Boris Ginsburg"], "title": "NGPU-LM: GPU-Accelerated N-Gram Language Model for Context-Biasing in Greedy ASR Decoding", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "comment": "Accepted to Interspeech 2025", "summary": "Statistical n-gram language models are widely used for context-biasing tasks\nin Automatic Speech Recognition (ASR). However, existing implementations lack\ncomputational efficiency due to poor parallelization, making context-biasing\nless appealing for industrial use. This work rethinks data structures for\nstatistical n-gram language models to enable fast and parallel operations for\nGPU-optimized inference. Our approach, named NGPU-LM, introduces customizable\ngreedy decoding for all major ASR model types - including transducers,\nattention encoder-decoder models, and CTC - with less than 7% computational\noverhead. The proposed approach can eliminate more than 50% of the accuracy gap\nbetween greedy and beam search for out-of-domain scenarios while avoiding\nsignificant slowdown caused by beam search. The implementation of the proposed\nNGPU-LM is open-sourced.", "AI": {"tldr": "NGPU-LM improves computational efficiency of n-gram language models for ASR by enabling GPU-optimized parallel operations, reducing accuracy gaps between greedy and beam search with minimal overhead.", "motivation": "Existing n-gram language models for ASR lack computational efficiency due to poor parallelization, limiting their industrial appeal.", "method": "NGPU-LM rethinks data structures for n-gram models, enabling fast, parallel GPU-optimized operations and customizable greedy decoding for major ASR model types.", "result": "NGPU-LM reduces computational overhead to less than 7%, closes over 50% of the accuracy gap between greedy and beam search, and avoids beam search slowdowns.", "conclusion": "NGPU-LM offers an efficient, open-source solution for context-biasing in ASR, balancing speed and accuracy."}}
{"id": "2505.22995", "pdf": "https://arxiv.org/pdf/2505.22995", "abs": "https://arxiv.org/abs/2505.22995", "authors": ["Pai Zhu", "Quan Wang", "Dhruuv Agarwal", "Kurt Partridge"], "title": "LLM-Synth4KWS: Scalable Automatic Generation and Synthesis of Confusable Data for Custom Keyword Spotting", "categories": ["eess.AS", "cs.SD"], "comment": null, "summary": "Custom keyword spotting (KWS) allows detecting user-defined spoken keywords\nfrom streaming audio. This is achieved by comparing the embeddings from voice\nenrollments and input audio. State-of-the-art custom KWS models are typically\ntrained contrastively using utterances whose keywords are randomly sampled from\ntraining dataset. These KWS models often struggle with confusing keywords, such\nas \"blue\" versus \"glue\". This paper introduces an effective way to augment the\ntraining with confusable utterances where keywords are generated and grouped\nfrom large language models (LLMs), and speech signals are synthesized with\ndiverse speaking styles from text-to-speech (TTS) engines. To better measure\nuser experience on confusable KWS, we define a new northstar metric using the\naverage area under DET curve from confusable groups (c-AUC). Featuring high\nscalability and zero labor cost, the proposed method improves AUC by 3.7% and\nc-AUC by 11.3% on the Speech Commands testing set.", "AI": {"tldr": "The paper introduces a method to improve custom keyword spotting (KWS) by augmenting training with confusable utterances generated by LLMs and TTS, achieving significant performance gains.", "motivation": "State-of-the-art KWS models struggle with confusing keywords, prompting the need for better training methods.", "method": "Augments training with confusable utterances generated by LLMs and synthesized speech from TTS, introducing a new metric (c-AUC) for evaluation.", "result": "Improves AUC by 3.7% and c-AUC by 11.3% on the Speech Commands testing set.", "conclusion": "The proposed method is scalable, cost-effective, and significantly enhances KWS performance for confusable keywords."}}
{"id": "2505.23212", "pdf": "https://arxiv.org/pdf/2505.23212", "abs": "https://arxiv.org/abs/2505.23212", "authors": ["Kohei Saijo", "Wangyou Zhang", "Samuele Cornell", "Robin Scheibler", "Chenda Li", "Zhaoheng Ni", "Anurag Kumar", "Marvin Sach", "Yihui Fu", "Wei Wang", "Tim Fingscheidt", "Shinji Watanabe"], "title": "Interspeech 2025 URGENT Speech Enhancement Challenge", "categories": ["eess.AS"], "comment": "Accepted to Interspeech 2025", "summary": "There has been a growing effort to develop universal speech enhancement (SE)\nto handle inputs with various speech distortions and recording conditions. The\nURGENT Challenge series aims to foster such universal SE by embracing a broad\nrange of distortion types, increasing data diversity, and incorporating\nextensive evaluation metrics. This work introduces the Interspeech 2025 URGENT\nChallenge, the second edition of the series, to explore several aspects that\nhave received limited attention so far: language dependency, universality for\nmore distortion types, data scalability, and the effectiveness of using noisy\ntraining data. We received 32 submissions, where the best system uses a\ndiscriminative model, while most other competitive ones are hybrid methods.\nAnalysis reveals some key findings: (i) some generative or hybrid approaches\nare preferred in subjective evaluations over the top discriminative model, and\n(ii) purely generative SE models can exhibit language dependency.", "AI": {"tldr": "The Interspeech 2025 URGENT Challenge focuses on universal speech enhancement (SE), addressing language dependency, distortion universality, data scalability, and noisy training data. Top submissions include discriminative and hybrid models, with subjective preferences favoring some generative/hybrid approaches.", "motivation": "To advance universal SE by exploring overlooked aspects like language dependency, distortion types, and noisy data effectiveness.", "method": "The challenge evaluates 32 submissions, including discriminative and hybrid models, with subjective and objective metrics.", "result": "Best system uses a discriminative model, but generative/hybrid models are preferred subjectively. Generative SE models show language dependency.", "conclusion": "The challenge highlights the potential of hybrid/generative models for universal SE and identifies language dependency as a key factor."}}
{"id": "2505.23308", "pdf": "https://arxiv.org/pdf/2505.23308", "abs": "https://arxiv.org/abs/2505.23308", "authors": ["Nimrod Shabtay", "Zvi Kons", "Avihu Dekel", "Hagai Aronowitz", "Ron Hoory", "Assaf Arbelle"], "title": "Spoken question answering for visual queries", "categories": ["eess.AS", "cs.AI", "eess.IV"], "comment": "Accepted for Interspeech 2025 (with additional results)", "summary": "Question answering (QA) systems are designed to answer natural language\nquestions. Visual QA (VQA) and Spoken QA (SQA) systems extend the textual QA\nsystem to accept visual and spoken input respectively.\n  This work aims to create a system that enables user interaction through both\nspeech and images. That is achieved through the fusion of text, speech, and\nimage modalities to tackle the task of spoken VQA (SVQA). The resulting\nmulti-modal model has textual, visual, and spoken inputs and can answer spoken\nquestions on images.\n  Training and evaluating SVQA models requires a dataset for all three\nmodalities, but no such dataset currently exists. We address this problem by\nsynthesizing VQA datasets using two zero-shot TTS models. Our initial findings\nindicate that a model trained only with synthesized speech nearly reaches the\nperformance of the upper-bounding model trained on textual QAs. In addition, we\nshow that the choice of the TTS model has a minor impact on accuracy.", "AI": {"tldr": "The paper introduces a multi-modal system for Spoken Visual Question Answering (SVQA) combining text, speech, and image inputs. It synthesizes datasets for training and shows synthesized speech performs nearly as well as text-based models.", "motivation": "To enable user interaction through both speech and images by integrating text, speech, and image modalities for SVQA, addressing the lack of datasets for all three modalities.", "method": "Fuses text, speech, and image inputs to create a multi-modal SVQA system. Synthesizes datasets using zero-shot TTS models for training and evaluation.", "result": "A model trained with synthesized speech nearly matches the performance of text-based models, with TTS model choice having minimal impact on accuracy.", "conclusion": "The proposed multi-modal SVQA system is viable, and synthesized datasets can effectively train models, bridging the gap in multi-modal QA research."}}
{"id": "2505.22865", "pdf": "https://arxiv.org/pdf/2505.22865", "abs": "https://arxiv.org/abs/2505.22865", "authors": ["Susan Liang", "Dejan Markovic", "Israel D. Gebru", "Steven Krenn", "Todd Keebler", "Jacob Sandakly", "Frank Yu", "Samuel Hassel", "Chenliang Xu", "Alexander Richard"], "title": "BinauralFlow: A Causal and Streamable Approach for High-Quality Binaural Speech Synthesis with Flow Matching Models", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "ICML 2025, 18 pages", "summary": "Binaural rendering aims to synthesize binaural audio that mimics natural\nhearing based on a mono audio and the locations of the speaker and listener.\nAlthough many methods have been proposed to solve this problem, they struggle\nwith rendering quality and streamable inference. Synthesizing high-quality\nbinaural audio that is indistinguishable from real-world recordings requires\nprecise modeling of binaural cues, room reverb, and ambient sounds.\nAdditionally, real-world applications demand streaming inference. To address\nthese challenges, we propose a flow matching based streaming binaural speech\nsynthesis framework called BinauralFlow. We consider binaural rendering to be a\ngeneration problem rather than a regression problem and design a conditional\nflow matching model to render high-quality audio. Moreover, we design a causal\nU-Net architecture that estimates the current audio frame solely based on past\ninformation to tailor generative models for streaming inference. Finally, we\nintroduce a continuous inference pipeline incorporating streaming STFT/ISTFT\noperations, a buffer bank, a midpoint solver, and an early skip schedule to\nimprove rendering continuity and speed. Quantitative and qualitative\nevaluations demonstrate the superiority of our method over SOTA approaches. A\nperceptual study further reveals that our model is nearly indistinguishable\nfrom real-world recordings, with a $42\\%$ confusion rate.", "AI": {"tldr": "BinauralFlow is a flow-matching-based streaming binaural speech synthesis framework that addresses quality and streaming challenges in binaural rendering.", "motivation": "Existing methods struggle with rendering quality and streamable inference, requiring precise modeling of binaural cues, reverb, and ambient sounds.", "method": "Proposes a conditional flow matching model and causal U-Net architecture for streaming inference, with a continuous pipeline for improved rendering.", "result": "Outperforms SOTA methods, with a 42% confusion rate in perceptual studies, nearly matching real-world recordings.", "conclusion": "BinauralFlow effectively synthesizes high-quality, streamable binaural audio, bridging the gap with real-world recordings."}}
{"id": "2505.22704", "pdf": "https://arxiv.org/pdf/2505.22704", "abs": "https://arxiv.org/abs/2505.22704", "authors": ["Feng Yao", "Zilong Wang", "Liyuan Liu", "Junxia Cui", "Li Zhong", "Xiaohan Fu", "Haohui Mai", "Vish Krishnan", "Jianfeng Gao", "Jingbo Shang"], "title": "Training Language Models to Generate Quality Code with Program Analysis Feedback", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages, 3 figures", "summary": "Code generation with large language models (LLMs), often termed vibe coding,\nis increasingly adopted in production but fails to ensure code quality,\nparticularly in security (e.g., SQL injection vulnerabilities) and\nmaintainability (e.g., missing type annotations). Existing methods, such as\nsupervised fine-tuning and rule-based post-processing, rely on labor-intensive\nannotations or brittle heuristics, limiting their scalability and\neffectiveness. We propose REAL, a reinforcement learning framework that\nincentivizes LLMs to generate production-quality code using program\nanalysis-guided feedback. Specifically, REAL integrates two automated signals:\n(1) program analysis detecting security or maintainability defects and (2) unit\ntests ensuring functional correctness. Unlike prior work, our framework is\nprompt-agnostic and reference-free, enabling scalable supervision without\nmanual intervention. Experiments across multiple datasets and model scales\ndemonstrate that REAL outperforms state-of-the-art methods in simultaneous\nassessments of functionality and code quality. Our work bridges the gap between\nrapid prototyping and production-ready code, enabling LLMs to deliver both\nspeed and quality.", "AI": {"tldr": "REAL is a reinforcement learning framework for LLMs to generate high-quality code using automated feedback from program analysis and unit tests, outperforming existing methods.", "motivation": "Current LLM-based code generation lacks quality assurance in security and maintainability, and existing methods are not scalable or effective.", "method": "REAL uses reinforcement learning with automated signals from program analysis (for defects) and unit tests (for correctness), without needing manual annotations.", "result": "REAL outperforms state-of-the-art methods in functionality and code quality across datasets and model scales.", "conclusion": "REAL bridges the gap between rapid prototyping and production-ready code, combining speed and quality in LLM-generated code."}}
{"id": "2505.22682", "pdf": "https://arxiv.org/pdf/2505.22682", "abs": "https://arxiv.org/abs/2505.22682", "authors": ["Xinxian Fan", "Mengye Lyu"], "title": "MRI Image Generation Based on Text Prompts", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "comment": null, "summary": "This study explores the use of text-prompted MRI image generation with the\nStable Diffusion (SD) model to address challenges in acquiring real MRI\ndatasets, such as high costs, limited rare case samples, and privacy concerns.\nThe SD model, pre-trained on natural images, was fine-tuned using the 3T\nfastMRI dataset and the 0.3T M4Raw dataset, with the goal of generating brain\nT1, T2, and FLAIR images across different magnetic field strengths. The\nperformance of the fine-tuned model was evaluated using quantitative\nmetrics,including Fr\\'echet Inception Distance (FID) and Multi-Scale Structural\nSimilarity (MS-SSIM), showing improvements in image quality and semantic\nconsistency with the text prompts. To further evaluate the model's potential, a\nsimple classification task was carried out using a small 0.35T MRI dataset,\ndemonstrating that the synthetic images generated by the fine-tuned SD model\ncan effectively augment training datasets and improve the performance of MRI\nconstrast classification tasks. Overall, our findings suggest that\ntext-prompted MRI image generation is feasible and can serve as a useful tool\nfor medical AI applications.", "AI": {"tldr": "The study fine-tunes Stable Diffusion for MRI image generation to overcome dataset limitations, showing improved quality and utility in medical AI tasks.", "motivation": "Address challenges like high costs, rare case scarcity, and privacy in acquiring real MRI datasets.", "method": "Fine-tune Stable Diffusion on 3T fastMRI and 0.3T M4Raw datasets to generate brain T1, T2, and FLAIR images. Evaluate with FID and MS-SSIM metrics.", "result": "Improved image quality and semantic consistency. Synthetic images augmented training data, enhancing MRI contrast classification performance.", "conclusion": "Text-prompted MRI image generation is feasible and beneficial for medical AI applications."}}
{"id": "2505.22677", "pdf": "https://arxiv.org/pdf/2505.22677", "abs": "https://arxiv.org/abs/2505.22677", "authors": ["Jisu Kim", "Alex Mattingly", "Eung-Joo Lee", "Benjamin S. Riggan"], "title": "Using Cross-Domain Detection Loss to Infer Multi-Scale Information for Improved Tiny Head Tracking", "categories": ["cs.CV"], "comment": "To appear at IEEE International Conference on Automatic Face and\n  Gesture 2025 (FG2025)", "summary": "Head detection and tracking are essential for downstream tasks, but current\nmethods often require large computational budgets, which increase latencies and\nties up resources (e.g., processors, memory, and bandwidth). To address this,\nwe propose a framework to enhance tiny head detection and tracking by\noptimizing the balance between performance and efficiency. Our framework\nintegrates (1) a cross-domain detection loss, (2) a multi-scale module, and (3)\na small receptive field detection mechanism. These innovations enhance\ndetection by bridging the gap between large and small detectors, capturing\nhigh-frequency details at multiple scales during training, and using filters\nwith small receptive fields to detect tiny heads. Evaluations on the CroHD and\nCrowdHuman datasets show improved Multiple Object Tracking Accuracy (MOTA) and\nmean Average Precision (mAP), demonstrating the effectiveness of our approach\nin crowded scenes.", "AI": {"tldr": "A framework for efficient tiny head detection and tracking balances performance and efficiency using cross-domain loss, multi-scale training, and small receptive fields, improving MOTA and mAP on crowded datasets.", "motivation": "Current head detection and tracking methods are computationally expensive, increasing latency and resource usage.", "method": "Integrates cross-domain detection loss, a multi-scale module, and small receptive field detection to enhance tiny head detection.", "result": "Improved MOTA and mAP on CroHD and CrowdHuman datasets.", "conclusion": "The framework effectively enhances tiny head detection and tracking in crowded scenes while optimizing efficiency."}}
{"id": "2505.22698", "pdf": "https://arxiv.org/pdf/2505.22698", "abs": "https://arxiv.org/abs/2505.22698", "authors": ["Luca Fantin", "Marco Antonelli", "Margherita Cesetti", "Daniele Irto", "Bruno Zamengo", "Francesco Silvestri"], "title": "Design and testing of an agent chatbot supporting decision making with public transport data", "categories": ["cs.AI"], "comment": null, "summary": "Assessing the quality of public transportation services requires the analysis\nof large quantities of data on the scheduled and actual trips and documents\nlisting the quality constraints each service needs to meet. Interrogating such\ndatasets with SQL queries, organizing and visualizing the data can be quite\ncomplex for most users. This paper presents a chatbot offering a user-friendly\ntool to interact with these datasets and support decision making. It is based\non an agent architecture, which expands the capabilities of the core Large\nLanguage Model (LLM) by allowing it to interact with a series of tools that can\nexecute several tasks, like performing SQL queries, plotting data and creating\nmaps from the coordinates of a trip and its stops. This paper also tackles one\nof the main open problems of such Generative AI projects: collecting data to\nmeasure the system's performance. Our chatbot has been extensively tested with\na workflow that asks several questions and stores the generated query, the\nretrieved data and the natural language response for each of them. Such\nquestions are drawn from a set of base examples which are then completed with\nactual data from the database. This procedure yields a dataset for the\nevaluation of the chatbot's performance, especially the consistency of its\nanswers and the correctness of the generated queries.", "AI": {"tldr": "A chatbot simplifies analyzing public transportation data by using an agent architecture with LLM and tools for SQL queries, visualization, and performance evaluation.", "motivation": "To make public transportation data analysis accessible and user-friendly, overcoming SQL and visualization complexities.", "method": "Uses an agent-based chatbot with LLM, integrating tools for SQL queries, data plotting, and map creation, plus a workflow for performance evaluation.", "result": "The chatbot effectively interacts with datasets, generates queries, and provides natural language responses, with a workflow for performance measurement.", "conclusion": "The chatbot offers a practical solution for public transportation data analysis, with a robust method for evaluating its performance."}}
{"id": "2505.22686", "pdf": "https://arxiv.org/pdf/2505.22686", "abs": "https://arxiv.org/abs/2505.22686", "authors": ["Ange-Clement Akazan", "Verlon Roel Mbingui", "Gnankan Landry Regis N'guessan", "Issa Karambal"], "title": "Localized Weather Prediction Using Kolmogorov-Arnold Network-Based Models and Deep RNNs", "categories": ["cs.LG"], "comment": null, "summary": "Weather forecasting is crucial for managing risks and economic planning,\nparticularly in tropical Africa, where extreme events severely impact\nlivelihoods. Yet, existing forecasting methods often struggle with the region's\ncomplex, non-linear weather patterns. This study benchmarks deep recurrent\nneural networks such as $\\texttt{LSTM, GRU, BiLSTM, BiGRU}$, and\nKolmogorov-Arnold-based models $(\\texttt{KAN} and \\texttt{TKAN})$ for daily\nforecasting of temperature, precipitation, and pressure in two tropical cities:\nAbidjan, Cote d'Ivoire (Ivory Coast) and Kigali (Rwanda). We further introduce\ntwo customized variants of $ \\texttt{TKAN}$ that replace its original\n$\\texttt{SiLU}$ activation function with $ \\texttt{GeLU}$ and \\texttt{MiSH},\nrespectively. Using station-level meteorological data spanning from 2010 to\n2024, we evaluate all the models on standard regression metrics. $\\texttt{KAN}$\nachieves temperature prediction ($R^2=0.9986$ in Abidjan, $0.9998$ in Kigali,\n$\\texttt{MSE} < 0.0014~^\\circ C ^2$), while $\\texttt{TKAN}$ variants minimize\nabsolute errors for precipitation forecasting in low-rainfall regimes. The\ncustomized $\\texttt{TKAN}$ models demonstrate improvements over the standard\n$\\texttt{TKAN}$ across both datasets. Classical \\texttt{RNNs} remain highly\ncompetitive for atmospheric pressure ($R^2 \\approx 0.83{-}0.86$), outperforming\n$\\texttt{KAN}$-based models in this task. These results highlight the potential\nof spline-based neural architectures for efficient and data-efficient\nforecasting.", "AI": {"tldr": "The study benchmarks deep recurrent neural networks and Kolmogorov-Arnold-based models for weather forecasting in tropical Africa, introducing customized variants of TKAN. Results show KAN excels in temperature prediction, TKAN variants improve precipitation forecasting, and classical RNNs outperform in pressure prediction.", "motivation": "Existing forecasting methods struggle with tropical Africa's complex weather patterns, necessitating improved models for better risk management and economic planning.", "method": "Benchmarked models include LSTM, GRU, BiLSTM, BiGRU, KAN, and TKAN, with customized TKAN variants using GeLU and MiSH activations. Evaluated on station-level meteorological data (2010-2024) for temperature, precipitation, and pressure.", "result": "KAN achieves high accuracy in temperature prediction (R\u00b2\u22480.9986-0.9998), TKAN variants minimize precipitation errors, and classical RNNs outperform in pressure prediction (R\u00b2\u22480.83-0.86).", "conclusion": "Spline-based neural architectures like KAN and TKAN show promise for efficient and data-efficient weather forecasting in tropical regions."}}
{"id": "2505.22814", "pdf": "https://arxiv.org/pdf/2505.22814", "abs": "https://arxiv.org/abs/2505.22814", "authors": ["Jonghan Lim", "Ilya Kovalenko"], "title": "A Large Language Model-Enabled Control Architecture for Dynamic Resource Capability Exploration in Multi-Agent Manufacturing Systems", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Manufacturing environments are becoming more complex and unpredictable due to\nfactors such as demand variations and shorter product lifespans. This\ncomplexity requires real-time decision-making and adaptation to disruptions.\nTraditional control approaches highlight the need for advanced control\nstrategies capable of overcoming unforeseen challenges, as they demonstrate\nlimitations in responsiveness within dynamic industrial settings. Multi-agent\nsystems address these challenges through decentralization of decision-making,\nenabling systems to respond dynamically to operational changes. However,\ncurrent multi-agent systems encounter challenges related to real-time\nadaptation, context-aware decision-making, and the dynamic exploration of\nresource capabilities. Large language models provide the possibility to\novercome these limitations through context-aware decision-making capabilities.\nThis paper introduces a large language model-enabled control architecture for\nmulti-agent manufacturing systems to dynamically explore resource capabilities\nin response to real-time disruptions. A simulation-based case study\ndemonstrates that the proposed architecture improves system resilience and\nflexibility. The case study findings show improved throughput and efficient\nresource utilization compared to existing approaches.", "AI": {"tldr": "A large language model-enabled control architecture for multi-agent manufacturing systems improves resilience and flexibility in dynamic environments.", "motivation": "Addressing the limitations of traditional control and current multi-agent systems in handling real-time disruptions and dynamic resource exploration in manufacturing.", "method": "Proposes a large language model-enabled control architecture for multi-agent systems, validated through a simulation-based case study.", "result": "Improved throughput and resource utilization compared to existing approaches.", "conclusion": "The architecture enhances system resilience and flexibility, proving effective in dynamic manufacturing settings."}}
{"id": "2505.23379", "pdf": "https://arxiv.org/pdf/2505.23379", "abs": "https://arxiv.org/abs/2505.23379", "authors": ["Yao Guo", "Yang Ai", "Rui-Chen Zheng", "Hui-Peng Du", "Xiao-Hang Jiang", "Zhen-Hua Ling"], "title": "Vision-Integrated High-Quality Neural Speech Coding", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted by interspeech2025", "summary": "This paper proposes a novel vision-integrated neural speech codec (VNSC),\nwhich aims to enhance speech coding quality by leveraging visual modality\ninformation. In VNSC, the image analysis-synthesis module extracts visual\nfeatures from lip images, while the feature fusion module facilitates\ninteraction between the image analysis-synthesis module and the speech coding\nmodule, transmitting visual information to assist the speech coding process.\nDepending on whether visual information is available during the inference\nstage, the feature fusion module integrates visual features into the speech\ncoding module using either explicit integration or implicit distillation\nstrategies. Experimental results confirm that integrating visual information\neffectively improves the quality of the decoded speech and enhances the noise\nrobustness of the neural speech codec, without increasing the bitrate.", "AI": {"tldr": "The paper introduces a vision-integrated neural speech codec (VNSC) that uses visual information from lip images to improve speech coding quality and noise robustness without increasing bitrate.", "motivation": "To enhance speech coding quality by leveraging visual modality information, particularly lip movements, to assist the speech coding process.", "method": "VNSC includes an image analysis-synthesis module for extracting visual features and a feature fusion module to integrate these features into the speech coding module using explicit or implicit strategies.", "result": "Experimental results show improved decoded speech quality and enhanced noise robustness without additional bitrate.", "conclusion": "Integrating visual information effectively improves speech coding performance, demonstrating the potential of multimodal approaches in speech processing."}}
{"id": "2505.23036", "pdf": "https://arxiv.org/pdf/2505.23036", "abs": "https://arxiv.org/abs/2505.23036", "authors": ["Yuhang Dai", "He Wang", "Xingchen Li", "Zihan Zhang", "Shuiyuan Wang", "Lei Xie", "Xin Xu", "Hongxiao Guo", "Shaoji Zhang", "Hui Bu", "Wei Chen"], "title": "AISHELL-5: The First Open-Source In-Car Multi-Channel Multi-Speaker Speech Dataset for Automatic Speech Diarization and Recognition", "categories": ["cs.SD", "eess.AS"], "comment": "5 pages, 1 figures, 3 tables, accepted by InterSpeech 2025", "summary": "This paper delineates AISHELL-5, the first open-source in-car multi-channel\nmulti-speaker Mandarin automatic speech recognition (ASR) dataset. AISHLL-5\nincludes two parts: (1) over 100 hours of multi-channel speech data recorded in\nan electric vehicle across more than 60 real driving scenarios. This audio data\nconsists of four far-field speech signals captured by microphones located on\neach car door, as well as near-field signals obtained from high-fidelity\nheadset microphones worn by each speaker. (2) a collection of 40 hours of\nreal-world environmental noise recordings, which supports the in-car speech\ndata simulation. Moreover, we also provide an open-access, reproducible\nbaseline system based on this dataset. This system features a speech frontend\nmodel that employs speech source separation to extract each speaker's clean\nspeech from the far-field signals, along with a speech recognition module that\naccurately transcribes the content of each individual speaker. Experimental\nresults demonstrate the challenges faced by various mainstream ASR models when\nevaluated on the AISHELL-5. We firmly believe the AISHELL-5 dataset will\nsignificantly advance the research on ASR systems under complex driving\nscenarios by establishing the first publicly available in-car ASR benchmark.", "AI": {"tldr": "AISHELL-5 is the first open-source in-car multi-channel multi-speaker Mandarin ASR dataset, featuring real driving scenario recordings and environmental noise, with a baseline system for research advancement.", "motivation": "To address the lack of open-source datasets for in-car multi-speaker Mandarin ASR, enabling research in complex driving scenarios.", "method": "The dataset includes multi-channel speech data from real driving scenarios and environmental noise. A baseline system with speech source separation and ASR modules is provided.", "result": "Highlights challenges for mainstream ASR models, demonstrating the dataset's utility for advancing in-car ASR research.", "conclusion": "AISHELL-5 establishes a benchmark for in-car ASR, fostering progress in complex driving scenario speech recognition."}}
{"id": "2505.22752", "pdf": "https://arxiv.org/pdf/2505.22752", "abs": "https://arxiv.org/abs/2505.22752", "authors": ["Rafik Mankour", "Yassine Chafai", "Hamada Saleh", "Ghassen Ben Hassine", "Thibaud Barreau", "Peter Tankov"], "title": "Climate Finance Bench", "categories": ["cs.CL"], "comment": "Dataset is available at\n  https://github.com/Pladifes/climate_finance_bench", "summary": "Climate Finance Bench introduces an open benchmark that targets\nquestion-answering over corporate climate disclosures using Large Language\nModels. We curate 33 recent sustainability reports in English drawn from\ncompanies across all 11 GICS sectors and annotate 330 expert-validated\nquestion-answer pairs that span pure extraction, numerical reasoning, and\nlogical reasoning. Building on this dataset, we propose a comparison of RAG\n(retrieval-augmented generation) approaches. We show that the retriever's\nability to locate passages that actually contain the answer is the chief\nperformance bottleneck. We further argue for transparent carbon reporting in\nAI-for-climate applications, highlighting advantages of techniques such as\nWeight Quantization.", "AI": {"tldr": "Climate Finance Bench introduces an open benchmark for QA over corporate climate disclosures using LLMs, highlighting retriever performance as a bottleneck and advocating for transparent carbon reporting.", "motivation": "To address the lack of benchmarks for QA tasks in corporate climate disclosures and promote transparency in AI-for-climate applications.", "method": "Curated 33 sustainability reports with 330 expert-validated QA pairs, compared RAG approaches, and emphasized retriever performance.", "result": "Identified the retriever's ability to locate relevant passages as the main performance bottleneck.", "conclusion": "Advocates for transparent carbon reporting in AI-for-climate applications, suggesting techniques like Weight Quantization."}}
{"id": "2505.22685", "pdf": "https://arxiv.org/pdf/2505.22685", "abs": "https://arxiv.org/abs/2505.22685", "authors": ["Marcus J. Vroemen", "Yuqian Chen", "Yui Lo", "Tengfei Xu", "Weidong Cai", "Fan Zhang", "Josien P. W. Pluim", "Lauren J. O'Donnell"], "title": "DeepMultiConnectome: Deep Multi-Task Prediction of Structural Connectomes Directly from Diffusion MRI Tractography", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "15 pages, 5 figures, 5 tables", "summary": "Diffusion MRI (dMRI) tractography enables in vivo mapping of brain structural\nconnections, but traditional connectome generation is time-consuming and\nrequires gray matter parcellation, posing challenges for large-scale studies.\nWe introduce DeepMultiConnectome, a deep-learning model that predicts\nstructural connectomes directly from tractography, bypassing the need for gray\nmatter parcellation while supporting multiple parcellation schemes. Using a\npoint-cloud-based neural network with multi-task learning, the model classifies\nstreamlines according to their connected regions across two parcellation\nschemes, sharing a learned representation. We train and validate\nDeepMultiConnectome on tractography from the Human Connectome Project Young\nAdult dataset ($n = 1000$), labeled with an 84 and 164 region gray matter\nparcellation scheme. DeepMultiConnectome predicts multiple structural\nconnectomes from a whole-brain tractogram containing 3 million streamlines in\napproximately 40 seconds. DeepMultiConnectome is evaluated by comparing\npredicted connectomes with traditional connectomes generated using the\nconventional method of labeling streamlines using a gray matter parcellation.\nThe predicted connectomes are highly correlated with traditionally generated\nconnectomes ($r = 0.992$ for an 84-region scheme; $r = 0.986$ for a 164-region\nscheme) and largely preserve network properties. A test-retest analysis of\nDeepMultiConnectome demonstrates reproducibility comparable to traditionally\ngenerated connectomes. The predicted connectomes perform similarly to\ntraditionally generated connectomes in predicting age and cognitive function.\nOverall, DeepMultiConnectome provides a scalable, fast model for generating\nsubject-specific connectomes across multiple parcellation schemes.", "AI": {"tldr": "DeepMultiConnectome is a deep-learning model that predicts structural connectomes from tractography quickly and without gray matter parcellation, achieving high correlation with traditional methods.", "motivation": "Traditional connectome generation is time-consuming and requires gray matter parcellation, limiting scalability for large-scale studies.", "method": "Uses a point-cloud-based neural network with multi-task learning to classify streamlines across multiple parcellation schemes.", "result": "Predicts connectomes in ~40 seconds with high correlation to traditional methods (r = 0.992 for 84-region, r = 0.986 for 164-region) and preserves network properties.", "conclusion": "DeepMultiConnectome offers a fast, scalable solution for generating subject-specific connectomes across multiple parcellation schemes."}}
{"id": "2505.22701", "pdf": "https://arxiv.org/pdf/2505.22701", "abs": "https://arxiv.org/abs/2505.22701", "authors": ["Ziyue Kang", "Weichuan Zhang"], "title": "Frequency-Adaptive Discrete Cosine-ViT-ResNet Architecture for Sparse-Data Vision", "categories": ["cs.CV"], "comment": null, "summary": "A major challenge in rare animal image classification is the scarcity of\ndata, as many species usually have only a small number of labeled samples.\n  To address this challenge, we designed a hybrid deep-learning framework\ncomprising a novel adaptive DCT preprocessing module, ViT-B16 and ResNet50\nbackbones, and a Bayesian linear classification head. To our knowledge, we are\nthe first to introduce an adaptive frequency-domain selection mechanism that\nlearns optimal low-, mid-, and high-frequency boundaries suited to the\nsubsequent backbones.\n  Our network first captures image frequency-domain cues via this adaptive DCT\npartitioning. The adaptively filtered frequency features are then fed into\nViT-B16 to model global contextual relationships, while ResNet50 concurrently\nextracts local, multi-scale spatial representations from the original image. A\ncross-level fusion strategy seamlessly integrates these frequency- and\nspatial-domain embeddings, and the fused features are passed through a Bayesian\nlinear classifier to output the final category predictions. On our self-built\n50-class wildlife dataset, this approach outperforms conventional CNN and\nfixed-band DCT pipelines, achieving state-of-the-art accuracy under extreme\nsample scarcity.", "AI": {"tldr": "A hybrid deep-learning framework with adaptive DCT preprocessing, ViT-B16, ResNet50, and Bayesian classification improves rare animal image classification under data scarcity.", "motivation": "Addressing the challenge of scarce labeled data for rare animal species by leveraging frequency-domain and spatial-domain features.", "method": "Combines adaptive DCT for frequency-domain feature selection, ViT-B16 for global context, ResNet50 for local spatial features, and Bayesian linear classification.", "result": "Outperforms traditional CNNs and fixed-band DCT methods, achieving state-of-the-art accuracy on a 50-class wildlife dataset.", "conclusion": "The proposed hybrid framework effectively tackles data scarcity in rare animal classification by integrating adaptive frequency and spatial features."}}
{"id": "2505.22753", "pdf": "https://arxiv.org/pdf/2505.22753", "abs": "https://arxiv.org/abs/2505.22753", "authors": ["Arseniy Pertzovsky", "Roni Stern", "Ariel Felner", "Roie Zivan"], "title": "Enhancing Lifelong Multi-Agent Path-finding by Using Artificial Potential Fields", "categories": ["cs.AI", "cs.MA", "cs.RO"], "comment": null, "summary": "We explore the use of Artificial Potential Fields (APFs) to solve Multi-Agent\nPath Finding (MAPF) and Lifelong MAPF (LMAPF) problems. In MAPF, a team of\nagents must move to their goal locations without collisions, whereas in LMAPF,\nnew goals are generated upon arrival. We propose methods for incorporating APFs\nin a range of MAPF algorithms, including Prioritized Planning, MAPF-LNS2, and\nPriority Inheritance with Backtracking (PIBT). Experimental results show that\nusing APF is not beneficial for MAPF but yields up to a 7-fold increase in\noverall system throughput for LMAPF.", "AI": {"tldr": "APFs improve LMAPF throughput but not MAPF.", "motivation": "To enhance MAPF and LMAPF solutions using APFs.", "method": "Incorporated APFs into MAPF algorithms like Prioritized Planning, MAPF-LNS2, and PIBT.", "result": "APFs didn't help MAPF but boosted LMAPF throughput by up to 7x.", "conclusion": "APFs are effective for LMAPF but not for standard MAPF."}}
{"id": "2505.22689", "pdf": "https://arxiv.org/pdf/2505.22689", "abs": "https://arxiv.org/abs/2505.22689", "authors": ["Jialong Guo", "Xinghao Chen", "Yehui Tang", "Yunhe Wang"], "title": "SlimLLM: Accurate Structured Pruning for Large Language Models", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Large language models(LLMs) have garnered significant attention and\ndemonstrated impressive capabilities in a wide range of applications. However,\ndue to their enormous computational costs, the deployment and application of\nLLMs are often severely limited. To address this issue, structured pruning is\nan effective solution to compress the parameters of LLMs. Determining the\nimportance of each sub-module in LLMs and minimizing performance loss are\ncritical issues that need to be carefully addressed in structured pruning. In\nthis paper, we propose an effective and fast structured pruning method named\nSlimLLM for large language models. For channel and attention head pruning, we\nevaluate the importance based on the entire channel or head, rather than merely\naggregating the importance of individual elements within a sub-module. This\napproach enables a more holistic consideration of the interdependence among\nelements within the sub-module. In addition, we design a simple linear\nregression strategy for the output matrix to quickly recover performance. We\nalso propose layer-based importance ratio to determine the pruning ratio for\neach layer. Based on the LLaMA benchmark results, our SlimLLM outperforms other\nmethods and achieves state-of-the-art performance.", "AI": {"tldr": "SlimLLM is a structured pruning method for large language models (LLMs) that evaluates sub-module importance holistically and recovers performance efficiently, achieving state-of-the-art results.", "motivation": "The high computational cost of LLMs limits their deployment, prompting the need for effective pruning methods to compress parameters without significant performance loss.", "method": "SlimLLM evaluates channel and attention head importance collectively, uses linear regression for output matrix recovery, and employs layer-based importance ratios for pruning.", "result": "SlimLLM outperforms other methods on the LLaMA benchmark, achieving state-of-the-art performance.", "conclusion": "SlimLLM provides an efficient and effective solution for pruning LLMs, addressing computational constraints while maintaining performance."}}
{"id": "2505.23352", "pdf": "https://arxiv.org/pdf/2505.23352", "abs": "https://arxiv.org/abs/2505.23352", "authors": ["Xu Shen", "Yixin Liu", "Yiwei Dai", "Yili Wang", "Rui Miao", "Yue Tan", "Shirui Pan", "Xin Wang"], "title": "Understanding the Information Propagation Effects of Communication Topologies in LLM-based Multi-Agent Systems", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "The communication topology in large language model-based multi-agent systems\nfundamentally governs inter-agent collaboration patterns, critically shaping\nboth the efficiency and effectiveness of collective decision-making. While\nrecent studies for communication topology automated design tend to construct\nsparse structures for efficiency, they often overlook why and when sparse and\ndense topologies help or hinder collaboration. In this paper, we present a\ncausal framework to analyze how agent outputs, whether correct or erroneous,\npropagate under topologies with varying sparsity. Our empirical studies reveal\nthat moderately sparse topologies, which effectively suppress error propagation\nwhile preserving beneficial information diffusion, typically achieve optimal\ntask performance. Guided by this insight, we propose a novel topology design\napproach, EIB-leanrner, that balances error suppression and beneficial\ninformation propagation by fusing connectivity patterns from both dense and\nsparse graphs. Extensive experiments show the superior effectiveness,\ncommunication cost, and robustness of EIB-leanrner.", "AI": {"tldr": "A causal framework analyzes how communication topology sparsity affects agent collaboration, revealing moderately sparse topologies optimize performance. EIB-leanrner, a novel approach, balances error suppression and information diffusion.", "motivation": "To understand why and when sparse or dense communication topologies help or hinder collaboration in multi-agent systems.", "method": "A causal framework analyzes error and information propagation under varying sparsity. EIB-leanrner fuses dense and sparse connectivity patterns.", "result": "Moderately sparse topologies suppress errors while preserving beneficial information, achieving optimal performance. EIB-leanrner outperforms in effectiveness, cost, and robustness.", "conclusion": "Moderate sparsity balances error suppression and information flow; EIB-leanrner is a superior topology design approach."}}
{"id": "2505.23515", "pdf": "https://arxiv.org/pdf/2505.23515", "abs": "https://arxiv.org/abs/2505.23515", "authors": ["Sanberk Serbest", "Tijana Stojkovic", "Milos Cernak", "Andrew Harper"], "title": "DeepFilterGAN: A Full-band Real-time Speech Enhancement System with GAN-based Stochastic Regeneration", "categories": ["eess.AS", "cs.LG", "eess.SP"], "comment": "Accepted to Interspeech 2025", "summary": "In this work, we propose a full-band real-time speech enhancement system with\nGAN-based stochastic regeneration. Predictive models focus on estimating the\nmean of the target distribution, whereas generative models aim to learn the\nfull distribution. This behavior of predictive models may lead to\nover-suppression, i.e. the removal of speech content. In the literature, it was\nshown that combining a predictive model with a generative one within the\nstochastic regeneration framework can reduce the distortion in the output. We\nuse this framework to obtain a real-time speech enhancement system. With 3.58M\nparameters and a low latency, our system is designed for real-time streaming\nwith a lightweight architecture. Experiments show that our system improves over\nthe first stage in terms of NISQA-MOS metric. Finally, through an ablation\nstudy, we show the importance of noisy conditioning in our system. We\nparticipated in 2025 Urgent Challenge with our model and later made further\nimprovements.", "AI": {"tldr": "A GAN-based real-time speech enhancement system reduces distortion by combining predictive and generative models, achieving improved performance with low latency.", "motivation": "Predictive models often over-suppress speech, removing content. Combining them with generative models can mitigate this issue.", "method": "Proposes a GAN-based stochastic regeneration framework for real-time speech enhancement, using a lightweight architecture with 3.58M parameters.", "result": "Improves NISQA-MOS metric over the first stage; noisy conditioning is crucial, as shown in ablation studies.", "conclusion": "The system is effective for real-time streaming, demonstrated by participation in the 2025 Urgent Challenge and further improvements."}}
{"id": "2505.23077", "pdf": "https://arxiv.org/pdf/2505.23077", "abs": "https://arxiv.org/abs/2505.23077", "authors": ["Zhennan Lin", "Kaixun Huang", "Wei Ren", "Linju Yang", "Lei Xie"], "title": "Contextualized Automatic Speech Recognition with Dynamic Vocabulary Prediction and Activation", "categories": ["cs.SD"], "comment": "Accepted by interspeech 2025", "summary": "Deep biasing improves automatic speech recognition (ASR) performance by\nincorporating contextual phrases. However, most existing methods enhance\nsubwords in a contextual phrase as independent units, potentially compromising\ncontextual phrase integrity, leading to accuracy reduction. In this paper, we\npropose an encoder-based phrase-level contextualized ASR method that leverages\ndynamic vocabulary prediction and activation. We introduce architectural\noptimizations and integrate a bias loss to extend phrase-level predictions\nbased on frame-level outputs. We also introduce a confidence-activated decoding\nmethod that ensures the complete output of contextual phrases while suppressing\nincorrect bias. Experiments on Librispeech and Wenetspeech datasets demonstrate\nthat our approach achieves relative WER reductions of 28.31% and 23.49%\ncompared to baseline, with the WER on contextual phrases decreasing relatively\nby 72.04% and 75.69%.", "AI": {"tldr": "Proposes an encoder-based phrase-level contextualized ASR method with dynamic vocabulary prediction, bias loss, and confidence-activated decoding, achieving significant WER reductions.", "motivation": "Existing ASR methods treat subwords in contextual phrases as independent units, compromising phrase integrity and reducing accuracy.", "method": "Uses encoder-based phrase-level contextualization, dynamic vocabulary prediction, bias loss, and confidence-activated decoding.", "result": "Achieves relative WER reductions of 28.31% and 23.49% on Librispeech and Wenetspeech, with contextual phrase WER decreasing by 72.04% and 75.69%.", "conclusion": "The proposed method effectively improves ASR performance by maintaining contextual phrase integrity and suppressing incorrect bias."}}
{"id": "2505.22757", "pdf": "https://arxiv.org/pdf/2505.22757", "abs": "https://arxiv.org/abs/2505.22757", "authors": ["Ansar Aynetdinov", "Alan Akbik"], "title": "Pre-Training Curriculum for Multi-Token Prediction in Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ACL 2025 (Main)", "summary": "Multi-token prediction (MTP) is a recently proposed pre-training objective\nfor language models. Rather than predicting only the next token (NTP), MTP\npredicts the next $k$ tokens at each prediction step, using multiple prediction\nheads. MTP has shown promise in improving downstream performance, inference\nspeed, and training efficiency, particularly for large models. However, prior\nwork has shown that smaller language models (SLMs) struggle with the MTP\nobjective. To address this, we propose a curriculum learning strategy for MTP\ntraining, exploring two variants: a forward curriculum, which gradually\nincreases the complexity of the pre-training objective from NTP to MTP, and a\nreverse curriculum, which does the opposite. Our experiments show that the\nforward curriculum enables SLMs to better leverage the MTP objective during\npre-training, improving downstream NTP performance and generative output\nquality, while retaining the benefits of self-speculative decoding. The reverse\ncurriculum achieves stronger NTP performance and output quality, but fails to\nprovide any self-speculative decoding benefits.", "AI": {"tldr": "A curriculum learning strategy for multi-token prediction (MTP) helps smaller language models (SLMs) leverage MTP benefits, improving downstream performance and generative quality.", "motivation": "Smaller language models struggle with MTP, so a curriculum learning approach is proposed to ease the transition from next-token prediction (NTP) to MTP.", "method": "Two curriculum variants: forward (NTP to MTP) and reverse (MTP to NTP).", "result": "Forward curriculum improves downstream NTP performance and generative quality while retaining self-speculative decoding benefits. Reverse curriculum boosts NTP performance but lacks decoding benefits.", "conclusion": "Curriculum learning, especially the forward variant, effectively enables SLMs to benefit from MTP training."}}
{"id": "2505.22923", "pdf": "https://arxiv.org/pdf/2505.22923", "abs": "https://arxiv.org/abs/2505.22923", "authors": ["Anqi Li", "Weijie Gan", "Ulugbek S. Kamilov"], "title": "Plug-and-Play Posterior Sampling for Blind Inverse Problems", "categories": ["eess.IV", "cs.CV"], "comment": "arXiv admin note: text overlap with arXiv:2305.12672", "summary": "We introduce Blind Plug-and-Play Diffusion Models (Blind-PnPDM) as a novel\nframework for solving blind inverse problems where both the target image and\nthe measurement operator are unknown. Unlike conventional methods that rely on\nexplicit priors or separate parameter estimation, our approach performs\nposterior sampling by recasting the problem into an alternating Gaussian\ndenoising scheme. We leverage two diffusion models as learned priors: one to\ncapture the distribution of the target image and another to characterize the\nparameters of the measurement operator. This PnP integration of diffusion\nmodels ensures flexibility and ease of adaptation. Our experiments on blind\nimage deblurring show that Blind-PnPDM outperforms state-of-the-art methods in\nterms of both quantitative metrics and visual fidelity. Our results highlight\nthe effectiveness of treating blind inverse problems as a sequence of denoising\nsubproblems while harnessing the expressive power of diffusion-based priors.", "AI": {"tldr": "Blind-PnPDM is a new framework for blind inverse problems, using diffusion models as priors for both the image and measurement operator, outperforming existing methods.", "motivation": "To address blind inverse problems where both the target image and measurement operator are unknown, without relying on explicit priors or separate parameter estimation.", "method": "Uses two diffusion models as learned priors for the image and measurement operator, recasting the problem into an alternating Gaussian denoising scheme.", "result": "Outperforms state-of-the-art methods in blind image deblurring, achieving better quantitative metrics and visual fidelity.", "conclusion": "Blind-PnPDM effectively solves blind inverse problems by treating them as denoising subproblems and leveraging diffusion-based priors."}}
{"id": "2505.22705", "pdf": "https://arxiv.org/pdf/2505.22705", "abs": "https://arxiv.org/abs/2505.22705", "authors": ["Qi Cai", "Jingwen Chen", "Yang Chen", "Yehao Li", "Fuchen Long", "Yingwei Pan", "Zhaofan Qiu", "Yiheng Zhang", "Fengbin Gao", "Peihan Xu", "Yimeng Wang", "Kai Yu", "Wenxuan Chen", "Ziwei Feng", "Zijian Gong", "Jianzhuang Pan", "Yi Peng", "Rui Tian", "Siyu Wang", "Bo Zhao", "Ting Yao", "Tao Mei"], "title": "HiDream-I1: A High-Efficient Image Generative Foundation Model with Sparse Diffusion Transformer", "categories": ["cs.CV", "cs.MM"], "comment": "Source codes and models are available at\n  https://github.com/HiDream-ai/HiDream-I1 and\n  https://github.com/HiDream-ai/HiDream-E1", "summary": "Recent advancements in image generative foundation models have prioritized\nquality improvements but often at the cost of increased computational\ncomplexity and inference latency. To address this critical trade-off, we\nintroduce HiDream-I1, a new open-source image generative foundation model with\n17B parameters that achieves state-of-the-art image generation quality within\nseconds. HiDream-I1 is constructed with a new sparse Diffusion Transformer\n(DiT) structure. Specifically, it starts with a dual-stream decoupled design of\nsparse DiT with dynamic Mixture-of-Experts (MoE) architecture, in which two\nseparate encoders are first involved to independently process image and text\ntokens. Then, a single-stream sparse DiT structure with dynamic MoE\narchitecture is adopted to trigger multi-model interaction for image generation\nin a cost-efficient manner. To support flexiable accessibility with varied\nmodel capabilities, we provide HiDream-I1 in three variants: HiDream-I1-Full,\nHiDream-I1-Dev, and HiDream-I1-Fast.\n  Furthermore, we go beyond the typical text-to-image generation and remould\nHiDream-I1 with additional image conditions to perform precise,\ninstruction-based editing on given images, yielding a new instruction-based\nimage editing model namely HiDream-E1. Ultimately, by integrating text-to-image\ngeneration and instruction-based image editing, HiDream-I1 evolves to form a\ncomprehensive image agent (HiDream-A1) capable of fully interactive image\ncreation and refinement. To accelerate multi-modal AIGC research, we have\nopen-sourced all the codes and model weights of HiDream-I1-Full,\nHiDream-I1-Dev, HiDream-I1-Fast, HiDream-E1 through our project websites:\nhttps://github.com/HiDream-ai/HiDream-I1 and\nhttps://github.com/HiDream-ai/HiDream-E1. All features can be directly\nexperienced via https://vivago.ai/studio.", "AI": {"tldr": "HiDream-I1 is a 17B-parameter image generative model with a sparse Diffusion Transformer (DiT) and dynamic Mixture-of-Experts (MoE) architecture, offering high-quality image generation in seconds. It includes variants for flexibility and extends to instruction-based image editing (HiDream-E1) and a comprehensive image agent (HiDream-A1).", "motivation": "Address the trade-off between image generation quality and computational complexity by developing a fast, high-quality model with flexible capabilities.", "method": "Uses a dual-stream decoupled sparse DiT with dynamic MoE for processing image and text tokens, followed by a single-stream sparse DiT for efficient multi-model interaction. Offers three variants for varied needs.", "result": "Achieves state-of-the-art image generation quality within seconds and supports instruction-based image editing and interactive image refinement.", "conclusion": "HiDream-I1 and its extensions provide a versatile, efficient solution for image generation and editing, advancing multi-modal AIGC research with open-source availability."}}
{"id": "2505.22756", "pdf": "https://arxiv.org/pdf/2505.22756", "abs": "https://arxiv.org/abs/2505.22756", "authors": ["Tian Qin", "Core Francisco Park", "Mujin Kwun", "Aaron Walsman", "Eran Malach", "Nikhil Anand", "Hidenori Tanaka", "David Alvarez-Melis"], "title": "Decomposing Elements of Problem Solving: What \"Math\" Does RL Teach?", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Mathematical reasoning tasks have become prominent benchmarks for assessing\nthe reasoning capabilities of LLMs, especially with reinforcement learning (RL)\nmethods such as GRPO showing significant performance gains. However, accuracy\nmetrics alone do not support fine-grained assessment of capabilities and fail\nto reveal which problem-solving skills have been internalized. To better\nunderstand these capabilities, we propose to decompose problem solving into\nfundamental capabilities: Plan (mapping questions to sequences of steps),\nExecute (correctly performing solution steps), and Verify (identifying the\ncorrectness of a solution). Empirically, we find that GRPO mainly enhances the\nexecution skill-improving execution robustness on problems the model already\nknows how to solve-a phenomenon we call temperature distillation. More\nimportantly, we show that RL-trained models struggle with fundamentally new\nproblems, hitting a 'coverage wall' due to insufficient planning skills. To\nexplore RL's impact more deeply, we construct a minimal, synthetic\nsolution-tree navigation task as an analogy for mathematical problem-solving.\nThis controlled setup replicates our empirical findings, confirming RL\nprimarily boosts execution robustness. Importantly, in this setting, we\nidentify conditions under which RL can potentially overcome the coverage wall\nthrough improved exploration and generalization to new solution paths. Our\nfindings provide insights into the role of RL in enhancing LLM reasoning,\nexpose key limitations, and suggest a path toward overcoming these barriers.\nCode is available at https://github.com/cfpark00/RL-Wall.", "AI": {"tldr": "The paper analyzes LLM reasoning in math tasks, proposing a decomposition into Plan, Execute, and Verify. GRPO improves execution but struggles with new problems due to planning gaps. A synthetic task confirms RL's execution boost and explores overcoming limitations.", "motivation": "To understand LLM reasoning beyond accuracy metrics by decomposing problem-solving into core skills and assessing RL's impact.", "method": "Decompose math problem-solving into Plan, Execute, Verify; use GRPO and a synthetic task to study RL's effects.", "result": "GRPO enhances execution but not planning, leading to a 'coverage wall' for new problems. Synthetic tasks replicate findings and suggest RL can improve exploration.", "conclusion": "RL boosts execution robustness but faces planning limitations. Insights suggest paths to overcome these barriers."}}
{"id": "2505.22694", "pdf": "https://arxiv.org/pdf/2505.22694", "abs": "https://arxiv.org/abs/2505.22694", "authors": ["Dacao Zhang", "Kun Zhang", "Shimao Chu", "Le Wu", "Xin Li", "Si Wei"], "title": "MoRE: A Mixture of Low-Rank Experts for Adaptive Multi-Task Learning", "categories": ["cs.LG"], "comment": "This paper has been accepted to ACL 2025 Findings", "summary": "With the rapid development of Large Language Models (LLMs),\nParameter-Efficient Fine-Tuning (PEFT) methods have gained significant\nattention, which aims to achieve efficient fine-tuning of LLMs with fewer\nparameters. As a representative PEFT method, Low-Rank Adaptation (LoRA)\nintroduces low-rank matrices to approximate the incremental tuning parameters\nand achieves impressive performance over multiple scenarios. After that, plenty\nof improvements have been proposed for further improvement. However, these\nmethods either focus on single-task scenarios or separately train multiple LoRA\nmodules for multi-task scenarios, limiting the efficiency and effectiveness of\nLoRA in multi-task scenarios. To better adapt to multi-task fine-tuning, in\nthis paper, we propose a novel Mixture of Low-Rank Experts (MoRE) for\nmulti-task PEFT. Specifically, instead of using an individual LoRA for each\ntask, we align different ranks of LoRA module with different tasks, which we\nnamed low-rank experts. Moreover, we design a novel adaptive rank selector to\nselect the appropriate expert for each task. By jointly training low-rank\nexperts, MoRE can enhance the adaptability and efficiency of LoRA in multi-task\nscenarios. Finally, we conduct extensive experiments over multiple multi-task\nbenchmarks along with different LLMs to verify model performance. Experimental\nresults demonstrate that compared to traditional LoRA and its variants, MoRE\nsignificantly improves the performance of LLMs in multi-task scenarios and\nincurs no additional inference cost. We also release the model and code to\nfacilitate the community.", "AI": {"tldr": "MoRE improves LoRA for multi-task PEFT by aligning different ranks of LoRA with tasks and using an adaptive rank selector, enhancing efficiency and performance without extra inference cost.", "motivation": "Existing PEFT methods like LoRA are limited in multi-task scenarios, either focusing on single tasks or separately training modules. MoRE aims to address this gap.", "method": "MoRE introduces low-rank experts aligned with tasks and an adaptive rank selector. It jointly trains these experts for multi-task efficiency.", "result": "MoRE outperforms traditional LoRA and variants in multi-task benchmarks, improving LLM performance without added inference cost.", "conclusion": "MoRE effectively adapts LoRA for multi-task PEFT, offering better performance and efficiency, with released code for community use."}}
{"id": "2505.23584", "pdf": "https://arxiv.org/pdf/2505.23584", "abs": "https://arxiv.org/abs/2505.23584", "authors": ["Sumbal Malik", "Majid Khonji", "Khaled Elbassioni", "Jorge Dias"], "title": "Collaborative Last-Mile Delivery: A Multi-Platform Vehicle Routing Problem With En-route Charging", "categories": ["cs.MA", "cs.AI", "cs.RO"], "comment": null, "summary": "The rapid growth of e-commerce and the increasing demand for timely,\ncost-effective last-mile delivery have increased interest in collaborative\nlogistics. This research introduces a novel collaborative synchronized\nmulti-platform vehicle routing problem with drones and robots (VRP-DR), where a\nfleet of $\\mathcal{M}$ trucks, $\\mathcal{N}$ drones and $\\mathcal{K}$ robots,\ncooperatively delivers parcels. Trucks serve as mobile platforms, enabling the\nlaunching, retrieving, and en-route charging of drones and robots, thereby\naddressing critical limitations such as restricted payload capacities, limited\nrange, and battery constraints. The VRP-DR incorporates five realistic\nfeatures: (1) multi-visit service per trip, (2) multi-trip operations, (3)\nflexible docking, allowing returns to the same or different trucks (4) cyclic\nand acyclic operations, enabling return to the same or different nodes; and (5)\nen-route charging, enabling drones and robots to recharge while being\ntransported on the truck, maximizing operational efficiency by utilizing idle\ntransit time. The VRP-DR is formulated as a mixed-integer linear program (MILP)\nto minimize both operational costs and makespan. To overcome the computational\nchallenges of solving large-scale instances, a scalable heuristic algorithm,\nFINDER (Flexible INtegrated Delivery with Energy Recharge), is developed, to\nprovide efficient, near-optimal solutions. Numerical experiments across various\ninstance sizes evaluate the performance of the MILP and heuristic approaches in\nterms of solution quality and computation time. The results demonstrate\nsignificant time savings of the combined delivery mode over the truck-only mode\nand substantial cost reductions from enabling multi-visits. The study also\nprovides insights into the effects of en-route charging, docking flexibility,\ndrone count, speed, and payload capacity on system performance.", "AI": {"tldr": "The paper introduces a collaborative vehicle routing problem with drones and robots (VRP-DR) to optimize last-mile delivery, addressing payload, range, and battery constraints. A heuristic algorithm, FINDER, is proposed for scalable solutions, showing significant cost and time savings over traditional methods.", "motivation": "The rise of e-commerce and demand for efficient last-mile delivery drives the need for innovative logistics solutions, overcoming limitations like payload capacity and battery life.", "method": "The VRP-DR is modeled as a MILP, incorporating multi-visit, multi-trip, flexible docking, cyclic/acyclic operations, and en-route charging. FINDER, a heuristic, is developed for scalability.", "result": "Numerical experiments show the combined delivery mode saves time and costs, with multi-visits and en-route charging enhancing efficiency.", "conclusion": "The VRP-DR framework and FINDER algorithm offer practical, scalable solutions for collaborative logistics, improving last-mile delivery performance."}}
{"id": "2505.23018", "pdf": "https://arxiv.org/pdf/2505.23018", "abs": "https://arxiv.org/abs/2505.23018", "authors": ["Haoqin Sun", "Xuechen Wang", "Jinghua Zhao", "Shiwan Zhao", "Jiaming Zhou", "Hui Wang", "Jiabei He", "Aobo Kong", "Xi Yang", "Yequan Wang", "Yonghua Lin", "Yong Qin"], "title": "EmotionTalk: An Interactive Chinese Multimodal Emotion Dataset With Rich Annotations", "categories": ["cs.MM"], "comment": null, "summary": "In recent years, emotion recognition plays a critical role in applications\nsuch as human-computer interaction, mental health monitoring, and sentiment\nanalysis. While datasets for emotion analysis in languages such as English have\nproliferated, there remains a pressing need for high-quality, comprehensive\ndatasets tailored to the unique linguistic, cultural, and multimodal\ncharacteristics of Chinese. In this work, we propose \\textbf{EmotionTalk}, an\ninteractive Chinese multimodal emotion dataset with rich annotations. This\ndataset provides multimodal information from 19 actors participating in dyadic\nconversational settings, incorporating acoustic, visual, and textual\nmodalities. It includes 23.6 hours of speech (19,250 utterances), annotations\nfor 7 utterance-level emotion categories (happy, surprise, sad, disgust, anger,\nfear, and neutral), 5-dimensional sentiment labels (negative, weakly negative,\nneutral, weakly positive, and positive) and 4-dimensional speech captions\n(speaker, speaking style, emotion and overall). The dataset is well-suited for\nresearch on unimodal and multimodal emotion recognition, missing modality\nchallenges, and speech captioning tasks. To our knowledge, it represents the\nfirst high-quality and versatile Chinese dialogue multimodal emotion dataset,\nwhich is a valuable contribution to research on cross-cultural emotion analysis\nand recognition. Additionally, we conduct experiments on EmotionTalk to\ndemonstrate the effectiveness and quality of the dataset. It will be\nopen-source and freely available for all academic purposes. The dataset and\ncodes will be made available at: https://github.com/NKU-HLT/EmotionTalk.", "AI": {"tldr": "The paper introduces EmotionTalk, a high-quality Chinese multimodal emotion dataset with rich annotations, addressing the lack of such resources for Chinese language and culture.", "motivation": "There is a need for comprehensive Chinese emotion datasets due to unique linguistic and cultural characteristics, unlike widely available English datasets.", "method": "The dataset includes multimodal data (acoustic, visual, textual) from 19 actors in dyadic conversations, annotated for emotion, sentiment, and speech captions.", "result": "EmotionTalk offers 23.6 hours of speech, 19,250 utterances, and detailed annotations, making it versatile for emotion recognition and related tasks.", "conclusion": "EmotionTalk is a pioneering Chinese multimodal emotion dataset, valuable for cross-cultural research, and will be open-source for academic use."}}
{"id": "2505.22765", "pdf": "https://arxiv.org/pdf/2505.22765", "abs": "https://arxiv.org/abs/2505.22765", "authors": ["Iddo Yosha", "Gallil Maimon", "Yossi Adi"], "title": "StressTest: Can YOUR Speech LM Handle the Stress?", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "Sentence stress refers to emphasis, placed on specific words within a spoken\nutterance to highlight or contrast an idea, or to introduce new information. It\nis often used to imply an underlying intention that is not explicitly stated.\nRecent advances in speech-aware language models (SLMs) have enabled direct\nprocessing of audio, allowing models to bypass transcription and access the\nfull richness of the speech signal and perform audio reasoning tasks such as\nspoken question answering. Despite the crucial role of sentence stress in\nshaping meaning and speaker intent, it remains largely overlooked in evaluation\nand development of such models. In this work, we address this gap by\nintroducing StressTest, a benchmark specifically designed to evaluate a model's\nability to distinguish between interpretations of spoken sentences based on the\nstress pattern. We assess the performance of several leading SLMs and find\nthat, despite their overall capabilities, they perform poorly on such tasks. To\novercome this limitation, we propose a novel synthetic data generation\npipeline, and create Stress17k, a training set that simulates change of meaning\nimplied by stress variation. Then, we empirically show that optimizing models\nwith this synthetic dataset aligns well with real-world recordings and enables\neffective finetuning of SLMs. Results suggest, that our finetuned model,\nStresSLM, significantly outperforms existing models on both sentence stress\nreasoning and detection tasks. Code, models, data, and audio samples -\npages.cs.huji.ac.il/adiyoss-lab/stresstest.", "AI": {"tldr": "The paper introduces StressTest, a benchmark for evaluating speech-aware language models (SLMs) on sentence stress interpretation, and proposes a synthetic data pipeline (Stress17k) to improve model performance.", "motivation": "Sentence stress is crucial for meaning and intent in speech but is overlooked in SLM evaluation.", "method": "Developed StressTest benchmark and Stress17k synthetic dataset to train and evaluate SLMs on stress-based interpretations.", "result": "Existing SLMs perform poorly on stress tasks; finetuned model (StresSLM) outperforms others.", "conclusion": "Synthetic data improves SLM performance on stress tasks, enabling better real-world application."}}
{"id": "2505.23132", "pdf": "https://arxiv.org/pdf/2505.23132", "abs": "https://arxiv.org/abs/2505.23132", "authors": ["Seung Gyu Jeong", "Seong Eun Kim"], "title": "Patient Domain Supervised Contrastive Learning for Lung Sound Classification Using Mobile Phone", "categories": ["cs.SD", "cs.AI"], "comment": "ITS-CSCC 2024", "summary": "Auscultation is crucial for diagnosing lung diseases. The COVID-19 pandemic\nhas revealed the limitations of traditional, in-person lung sound assessments.\nTo overcome these issues, advancements in digital stethoscopes and artificial\nintelligence (AI) have led to the development of new diagnostic methods. In\nthis context, our study aims to use smartphone microphones to record and\nanalyze lung sounds. We faced two major challenges: the difference in audio\nstyle between electronic stethoscopes and smartphone microphones, and the\nvariability among patients. To address these challenges, we developed a method\ncalled Patient Domain Supervised Contrastive Learning (PD-SCL). By integrating\nthis method with the Audio Spectrogram Transformer (AST) model, we\nsignificantly improved its performance by 2.4\\% compared to the original AST\nmodel. This progress demonstrates that smartphones can effectively diagnose\nlung sounds, addressing inconsistencies in patient data and showing potential\nfor broad use beyond traditional clinical settings. Our research contributes to\nmaking lung disease detection more accessible in the post-COVID-19 world.", "AI": {"tldr": "Smartphone-based lung sound analysis using PD-SCL and AST improves diagnosis accuracy by 2.4%, addressing patient variability and device differences.", "motivation": "The COVID-19 pandemic highlighted limitations of in-person lung sound assessments, prompting the need for accessible, digital diagnostic methods.", "method": "Developed Patient Domain Supervised Contrastive Learning (PD-SCL) combined with Audio Spectrogram Transformer (AST) to analyze lung sounds recorded via smartphone microphones.", "result": "Improved performance by 2.4% over the original AST model, demonstrating smartphones' potential for accurate lung sound diagnosis.", "conclusion": "Smartphone-based lung sound analysis is viable, addressing data inconsistencies and expanding diagnostic accessibility beyond clinical settings."}}
{"id": "2505.22759", "pdf": "https://arxiv.org/pdf/2505.22759", "abs": "https://arxiv.org/abs/2505.22759", "authors": ["Sara Papi", "Marco Gaido", "Luisa Bentivogli", "Alessio Brutti", "Mauro Cettolo", "Roberto Gretter", "Marco Matassoni", "Mohamed Nabih", "Matteo Negri"], "title": "FAMA: The First Large-Scale Open-Science Speech Foundation Model for English and Italian", "categories": ["cs.CL", "cs.AI", "cs.SD"], "comment": null, "summary": "The development of speech foundation models (SFMs) like Whisper and\nSeamlessM4T has significantly advanced the field of speech processing. However,\ntheir closed nature--with inaccessible training data and code--poses major\nreproducibility and fair evaluation challenges. While other domains have made\nsubstantial progress toward open science by developing fully transparent models\ntrained on open-source (OS) code and data, similar efforts in speech remain\nlimited. To fill this gap, we introduce FAMA, the first family of open science\nSFMs for English and Italian, trained on 150k+ hours of OS speech data.\nMoreover, we present a new dataset containing 16k hours of cleaned and\npseudo-labeled speech for both languages. Results show that FAMA achieves\ncompetitive performance compared to existing SFMs while being up to 8 times\nfaster. All artifacts, including code, datasets, and models, are released under\nOS-compliant licenses, promoting openness in speech technology research.", "AI": {"tldr": "FAMA introduces open science speech foundation models (SFMs) for English and Italian, trained on 150k+ hours of open-source data, achieving competitive performance and faster speeds while promoting transparency.", "motivation": "Closed nature of existing SFMs (e.g., Whisper, SeamlessM4T) hinders reproducibility and fair evaluation. Open science efforts in speech are limited.", "method": "Developed FAMA, a family of SFMs, using 150k+ hours of open-source speech data and a new 16k-hour cleaned and pseudo-labeled dataset.", "result": "FAMA matches performance of existing SFMs while being up to 8 times faster.", "conclusion": "FAMA promotes openness in speech research by releasing all artifacts (code, data, models) under OS-compliant licenses."}}
{"id": "2505.23353", "pdf": "https://arxiv.org/pdf/2505.23353", "abs": "https://arxiv.org/abs/2505.23353", "authors": ["Alexandra G. Roberts", "Ha M. Luu", "Mert \u015ei\u015fman", "Alexey V. Dimov", "Ceren Tozlu", "Ilhami Kovanlikaya", "Susan A. Gauthier", "Thanh D. Nguyen", "Yi Wang"], "title": "Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "Accepted full paper in Synthetic Data @ CVPR 2025 12 pages, 10\n  figures", "summary": "Quantitative susceptibility maps from magnetic resonance images can provide\nboth prognostic and diagnostic information in multiple sclerosis, a\nneurodegenerative disease characterized by the formation of lesions in white\nmatter brain tissue. In particular, susceptibility maps provide adequate\ncontrast to distinguish between \"rim\" lesions, surrounded by deposited\nparamagnetic iron, and \"non-rim\" lesion types. These paramagnetic rim lesions\n(PRLs) are an emerging biomarker in multiple sclerosis. Much effort has been\ndevoted to both detection and segmentation of such lesions to monitor\nlongitudinal change. As paramagnetic rim lesions are rare, addressing this\nproblem requires confronting the class imbalance between rim and non-rim\nlesions. We produce synthetic quantitative susceptibility maps of paramagnetic\nrim lesions and show that inclusion of such synthetic data improves classifier\nperformance and provide a multi-channel extension to generate accompanying\ncontrasts and probabilistic segmentation maps. We exploit the projection\ncapability of our trained generative network to demonstrate a novel denoising\napproach that allows us to train on ambiguous rim cases and substantially\nincrease the minority class. We show that both synthetic lesion synthesis and\nour proposed rim lesion label denoising method best approximate the unseen rim\nlesion distribution and improve detection in a clinically interpretable manner.\nWe release our code and generated data at https://github.com/agr78/PRLx-GAN\nupon publication.", "AI": {"tldr": "The paper proposes a method to improve detection and segmentation of paramagnetic rim lesions (PRLs) in multiple sclerosis using synthetic quantitative susceptibility maps and a novel denoising approach.", "motivation": "PRLs are a rare but important biomarker in multiple sclerosis, and their detection is hindered by class imbalance between rim and non-rim lesions.", "method": "The authors generate synthetic susceptibility maps for PRLs, extend the method to multi-channel contrasts, and introduce a denoising technique to handle ambiguous cases.", "result": "Synthetic data and denoising improve classifier performance and better approximate the distribution of unseen rim lesions.", "conclusion": "The proposed methods enhance PRL detection and segmentation, offering clinically interpretable improvements."}}
{"id": "2505.22762", "pdf": "https://arxiv.org/pdf/2505.22762", "abs": "https://arxiv.org/abs/2505.22762", "authors": ["Marco Colussi", "Dragan Ahmetovic", "Sergio Mascetti"], "title": "MIAS-SAM: Medical Image Anomaly Segmentation without thresholding", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper presents MIAS-SAM, a novel approach for the segmentation of\nanomalous regions in medical images. MIAS-SAM uses a patch-based memory bank to\nstore relevant image features, which are extracted from normal data using the\nSAM encoder. At inference time, the embedding patches extracted from the SAM\nencoder are compared with those in the memory bank to obtain the anomaly map.\nFinally, MIAS-SAM computes the center of gravity of the anomaly map to prompt\nthe SAM decoder, obtaining an accurate segmentation from the previously\nextracted features. Differently from prior works, MIAS-SAM does not require to\ndefine a threshold value to obtain the segmentation from the anomaly map.\nExperimental results conducted on three publicly available datasets, each with\na different imaging modality (Brain MRI, Liver CT, and Retina OCT) show\naccurate anomaly segmentation capabilities measured using DICE score. The code\nis available at: https://github.com/warpcut/MIAS-SAM", "AI": {"tldr": "MIAS-SAM is a novel method for segmenting anomalies in medical images using a patch-based memory bank and SAM encoder, achieving accurate results without thresholding.", "motivation": "To improve anomaly segmentation in medical images by leveraging a memory bank of normal features and avoiding manual thresholding.", "method": "Uses a patch-based memory bank with SAM encoder features for comparison, computes anomaly map, and prompts SAM decoder for segmentation.", "result": "Achieves accurate anomaly segmentation on Brain MRI, Liver CT, and Retina OCT datasets, measured by DICE score.", "conclusion": "MIAS-SAM provides an effective, threshold-free approach for medical anomaly segmentation with promising results."}}
{"id": "2505.22779", "pdf": "https://arxiv.org/pdf/2505.22779", "abs": "https://arxiv.org/abs/2505.22779", "authors": ["Mohammad Helal Uddin", "Sabur Baidya"], "title": "Predicting Human Depression with Hybrid Data Acquisition utilizing Physical Activity Sensing and Social Media Feeds", "categories": ["cs.AI"], "comment": null, "summary": "Mental disorders including depression, anxiety, and other neurological\ndisorders pose a significant global challenge, particularly among individuals\nexhibiting social avoidance tendencies. This study proposes a hybrid approach\nby leveraging smartphone sensor data measuring daily physical activities and\nanalyzing their social media (Twitter) interactions for evaluating an\nindividual's depression level. Using CNN-based deep learning models and Naive\nBayes classification, we identify human physical activities accurately and also\nclassify the user sentiments. A total of 33 participants were recruited for\ndata acquisition, and nine relevant features were extracted from the physical\nactivities and analyzed with their weekly depression scores, evaluated using\nthe Geriatric Depression Scale (GDS) questionnaire. Of the nine features, six\nare derived from physical activities, achieving an activity recognition\naccuracy of 95%, while three features stem from sentiment analysis of Twitter\nactivities, yielding a sentiment analysis accuracy of 95.6%. Notably, several\nphysical activity features exhibited significant correlations with the severity\nof depression symptoms. For classifying the depression severity, a support\nvector machine (SVM)-based algorithm is employed that demonstrated a very high\naccuracy of 94%, outperforming alternative models, e.g., the multilayer\nperceptron (MLP) and k-nearest neighbor. It is a simple approach yet highly\neffective in the long run for monitoring depression without breaching personal\nprivacy.", "AI": {"tldr": "A hybrid approach using smartphone sensor data and Twitter sentiment analysis to evaluate depression levels, achieving high accuracy with SVM-based classification.", "motivation": "Addressing the global challenge of mental disorders like depression by leveraging technology for non-invasive monitoring.", "method": "Combines CNN-based activity recognition and Naive Bayes sentiment analysis, with SVM for depression severity classification.", "result": "High accuracy in activity recognition (95%), sentiment analysis (95.6%), and depression classification (94%).", "conclusion": "The approach is effective for long-term depression monitoring while preserving privacy."}}
{"id": "2505.22695", "pdf": "https://arxiv.org/pdf/2505.22695", "abs": "https://arxiv.org/abs/2505.22695", "authors": ["Tengfei Lyu", "Siyuan Feng", "Hao Liu", "Hai Yang"], "title": "LLM-ODDR: A Large Language Model Framework for Joint Order Dispatching and Driver Repositioning", "categories": ["cs.LG"], "comment": null, "summary": "Ride-hailing platforms face significant challenges in optimizing order\ndispatching and driver repositioning operations in dynamic urban environments.\nTraditional approaches based on combinatorial optimization, rule-based\nheuristics, and reinforcement learning often overlook driver income fairness,\ninterpretability, and adaptability to real-world dynamics. To address these\ngaps, we propose LLM-ODDR, a novel framework leveraging Large Language Models\n(LLMs) for joint Order Dispatching and Driver Repositioning (ODDR) in\nride-hailing services. LLM-ODDR framework comprises three key components: (1)\nMulti-objective-guided Order Value Refinement, which evaluates orders by\nconsidering multiple objectives to determine their overall value; (2)\nFairness-aware Order Dispatching, which balances platform revenue with driver\nincome fairness; and (3) Spatiotemporal Demand-Aware Driver Repositioning,\nwhich optimizes idle vehicle placement based on historical patterns and\nprojected supply. We also develop JointDR-GPT, a fine-tuned model optimized for\nODDR tasks with domain knowledge. Extensive experiments on real-world datasets\nfrom Manhattan taxi operations demonstrate that our framework significantly\noutperforms traditional methods in terms of effectiveness, adaptability to\nanomalous conditions, and decision interpretability. To our knowledge, this is\nthe first exploration of LLMs as decision-making agents in ride-hailing ODDR\ntasks, establishing foundational insights for integrating advanced language\nmodels within intelligent transportation systems.", "AI": {"tldr": "LLM-ODDR is a novel framework using Large Language Models (LLMs) for ride-hailing order dispatching and driver repositioning, outperforming traditional methods in fairness, adaptability, and interpretability.", "motivation": "Addressing gaps in traditional methods (e.g., ignoring driver income fairness and real-world adaptability) for ride-hailing optimization.", "method": "LLM-ODDR includes multi-objective order evaluation, fairness-aware dispatching, and demand-aware repositioning, with a fine-tuned model (JointDR-GPT).", "result": "Outperforms traditional methods in effectiveness, adaptability, and interpretability on real-world Manhattan taxi data.", "conclusion": "First successful use of LLMs for ride-hailing ODDR tasks, paving the way for advanced language models in transportation systems."}}
{"id": "2505.22804", "pdf": "https://arxiv.org/pdf/2505.22804", "abs": "https://arxiv.org/abs/2505.22804", "authors": ["Jonghan Lim", "Ilya Kovalenko"], "title": "Dynamic Task Adaptation for Multi-Robot Manufacturing Systems with Large Language Models", "categories": ["cs.RO", "cs.MA"], "comment": null, "summary": "Recent manufacturing systems are increasingly adopting multi-robot\ncollaboration to handle complex and dynamic environments. While multi-agent\narchitectures support decentralized coordination among robot agents, they often\nface challenges in enabling real-time adaptability for unexpected disruptions\nwithout predefined rules. Recent advances in large language models offer new\nopportunities for context-aware decision-making to enable adaptive responses to\nunexpected changes. This paper presents an initial exploratory implementation\nof a large language model-enabled control framework for dynamic task\nreassignment in multi-robot manufacturing systems. A central controller agent\nleverages the large language model's ability to interpret structured robot\nconfiguration data and generate valid reassignments in response to robot\nfailures. Experiments in a real-world setup demonstrate high task success rates\nin recovering from failures, highlighting the potential of this approach to\nimprove adaptability in multi-robot manufacturing systems.", "AI": {"tldr": "A large language model-enabled control framework improves adaptability in multi-robot manufacturing systems by enabling dynamic task reassignment in response to failures.", "motivation": "Address challenges in real-time adaptability for multi-robot systems facing unexpected disruptions without predefined rules.", "method": "Uses a central controller agent with a large language model to interpret robot data and generate reassignments during failures.", "result": "High task success rates in recovering from failures in real-world experiments.", "conclusion": "The approach shows promise for enhancing adaptability in multi-robot manufacturing systems."}}
{"id": "2505.23449", "pdf": "https://arxiv.org/pdf/2505.23449", "abs": "https://arxiv.org/abs/2505.23449", "authors": ["Fanxiao Li", "Jiaying Wu", "Canyuan He", "Wei Zhou"], "title": "CMIE: Combining MLLM Insights with External Evidence for Explainable Out-of-Context Misinformation Detection", "categories": ["cs.MM"], "comment": null, "summary": "Multimodal large language models (MLLMs) have demonstrated impressive\ncapabilities in visual reasoning and text generation. While previous studies\nhave explored the application of MLLM for detecting out-of-context (OOC)\nmisinformation, our empirical analysis reveals two persisting challenges of\nthis paradigm. Evaluating the representative GPT-4o model on direct reasoning\nand evidence augmented reasoning, results indicate that MLLM struggle to\ncapture the deeper relationships-specifically, cases in which the image and\ntext are not directly connected but are associated through underlying semantic\nlinks. Moreover, noise in the evidence further impairs detection accuracy. To\naddress these challenges, we propose CMIE, a novel OOC misinformation detection\nframework that incorporates a Coexistence Relationship Generation (CRG)\nstrategy and an Association Scoring (AS) mechanism. CMIE identifies the\nunderlying coexistence relationships between images and text, and selectively\nutilizes relevant evidence to enhance misinformation detection. Experimental\nresults demonstrate that our approach outperforms existing methods.", "AI": {"tldr": "The paper highlights challenges in using MLLMs for detecting out-of-context misinformation and proposes CMIE, a framework with CRG and AS mechanisms, which outperforms existing methods.", "motivation": "Existing MLLMs struggle with detecting deeper semantic relationships and are affected by noisy evidence in out-of-context misinformation detection.", "method": "Proposes CMIE, incorporating Coexistence Relationship Generation (CRG) and Association Scoring (AS) to identify underlying relationships and selectively use evidence.", "result": "CMIE outperforms existing methods in detecting out-of-context misinformation.", "conclusion": "The CMIE framework effectively addresses the limitations of MLLMs in misinformation detection by leveraging deeper semantic analysis and selective evidence usage."}}
{"id": "2505.23009", "pdf": "https://arxiv.org/pdf/2505.23009", "abs": "https://arxiv.org/abs/2505.23009", "authors": ["Ruskin Raj Manku", "Yuzhi Tang", "Xingjian Shi", "Mu Li", "Alex Smola"], "title": "EmergentTTS-Eval: Evaluating TTS Models on Complex Prosodic, Expressiveness, and Linguistic Challenges Using Model-as-a-Judge", "categories": ["cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "Text-to-Speech (TTS) benchmarks often fail to capture how well models handle\nnuanced and semantically complex text. Building on $\\textit{EmergentTTS}$, we\nintroduce $\\textit{EmergentTTS-Eval}$, a comprehensive benchmark covering six\nchallenging TTS scenarios: emotions, paralinguistics, foreign words, syntactic\ncomplexity, complex pronunciation (e.g. URLs, formulas), and questions.\nCrucially, our framework automates both test-case generation and evaluation,\nmaking the benchmark easily extensible. Starting from a small set of\nhuman-written seed prompts, we iteratively extend them using LLMs to target\nspecific structural, phonetic and prosodic challenges, resulting in 1,645\ndiverse test cases. Moreover, we employ a model-as-a-judge approach, using a\nLarge Audio Language Model (LALM) to assess the speech across multiple\ndimensions such as expressed emotion, prosodic, intonational, and pronunciation\naccuracy. We evaluate state-of-the-art open-source and proprietary TTS systems,\nsuch as 11Labs, Deepgram, and OpenAI's 4o-mini-TTS, on EmergentTTS-Eval,\ndemonstrating its ability to reveal fine-grained performance differences.\nResults show that the model-as-a-judge approach offers robust TTS assessment\nand a high correlation with human preferences. We open source the evaluation\n$\\href{https://github.com/boson-ai/EmergentTTS-Eval-public}{code}$ and the\n$\\href{https://huggingface.co/datasets/bosonai/EmergentTTS-Eval}{dataset}$.", "AI": {"tldr": "The paper introduces EmergentTTS-Eval, a benchmark for evaluating TTS models on nuanced and complex text, automating test-case generation and evaluation using LLMs and a model-as-a-judge approach.", "motivation": "Existing TTS benchmarks lack the ability to assess nuanced and semantically complex text, prompting the need for a more comprehensive evaluation framework.", "method": "The authors develop EmergentTTS-Eval, automating test-case generation from seed prompts using LLMs and employing a Large Audio Language Model (LALM) for multi-dimensional evaluation.", "result": "The benchmark reveals fine-grained performance differences among TTS systems, with the model-as-a-judge approach showing high correlation with human preferences.", "conclusion": "EmergentTTS-Eval provides a robust, extensible framework for TTS evaluation, with open-sourced code and dataset to facilitate further research."}}
{"id": "2505.23207", "pdf": "https://arxiv.org/pdf/2505.23207", "abs": "https://arxiv.org/abs/2505.23207", "authors": ["Zhaokai Sun", "Li Zhang", "Qing Wang", "Pan Zhou", "Lei Xie"], "title": "Towards Robust Overlapping Speech Detection: A Speaker-Aware Progressive Approach Using WavLM", "categories": ["cs.SD", "cs.LG"], "comment": null, "summary": "Overlapping Speech Detection (OSD) aims to identify regions where multiple\nspeakers overlap in a conversation, a critical challenge in multi-party speech\nprocessing. This work proposes a speaker-aware progressive OSD model that\nleverages a progressive training strategy to enhance the correlation between\nsubtasks such as voice activity detection (VAD) and overlap detection. To\nimprove acoustic representation, we explore the effectiveness of\nstate-of-the-art self-supervised learning (SSL) models, including WavLM and\nwav2vec 2.0, while incorporating a speaker attention module to enrich features\nwith frame-level speaker information. Experimental results show that the\nproposed method achieves state-of-the-art performance, with an F1 score of\n82.76\\% on the AMI test set, demonstrating its robustness and effectiveness in\nOSD.", "AI": {"tldr": "A speaker-aware progressive OSD model using SSL models and speaker attention achieves state-of-the-art performance (F1: 82.76%) on the AMI test set.", "motivation": "Addressing the challenge of detecting overlapping speech in multi-party conversations, a critical task in speech processing.", "method": "Progressive training strategy integrating VAD and overlap detection, enhanced by SSL models (WavLM, wav2vec 2.0) and a speaker attention module.", "result": "Achieves an F1 score of 82.76% on the AMI test set, outperforming existing methods.", "conclusion": "The proposed model is robust and effective for OSD, leveraging speaker-aware features and SSL advancements."}}
{"id": "2505.22771", "pdf": "https://arxiv.org/pdf/2505.22771", "abs": "https://arxiv.org/abs/2505.22771", "authors": ["Christopher Ormerod"], "title": "Automated Essay Scoring Incorporating Annotations from Automated Feedback Systems", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages, AIME-Con Conference Submission", "summary": "This study illustrates how incorporating feedback-oriented annotations into\nthe scoring pipeline can enhance the accuracy of automated essay scoring (AES).\nThis approach is demonstrated with the Persuasive Essays for Rating, Selecting,\nand Understanding Argumentative and Discourse Elements (PERSUADE) corpus. We\nintegrate two types of feedback-driven annotations: those that identify\nspelling and grammatical errors, and those that highlight argumentative\ncomponents. To illustrate how this method could be applied in real-world\nscenarios, we employ two LLMs to generate annotations -- a generative language\nmodel used for spell-correction and an encoder-based token classifier trained\nto identify and mark argumentative elements. By incorporating annotations into\nthe scoring process, we demonstrate improvements in performance using\nencoder-based large language models fine-tuned as classifiers.", "AI": {"tldr": "Incorporating feedback-driven annotations (spelling/grammar errors and argumentative components) into AES improves scoring accuracy, demonstrated using the PERSUADE corpus and LLMs.", "motivation": "Enhance automated essay scoring accuracy by integrating feedback-oriented annotations.", "method": "Use two LLMs: one for spell-correction and another to identify argumentative elements, integrating annotations into the scoring pipeline.", "result": "Improved performance in automated essay scoring using fine-tuned encoder-based LLMs.", "conclusion": "Feedback-driven annotations enhance AES accuracy, with practical applications demonstrated using LLMs."}}
{"id": "2505.23408", "pdf": "https://arxiv.org/pdf/2505.23408", "abs": "https://arxiv.org/abs/2505.23408", "authors": ["Siying Xu", "Marcel Fr\u00fch", "Kerstin Hammernik", "Andreas Lingg", "Jens K\u00fcbler", "Patrick Krumm", "Daniel Rueckert", "Sergios Gatidis", "Thomas K\u00fcstner"], "title": "Self-supervised feature learning for cardiac Cine MR image reconstruction", "categories": ["eess.IV"], "comment": "Accepted to IEEE Transactions on Medical Imaging (TMI), 2025", "summary": "We propose a self-supervised feature learning assisted reconstruction\n(SSFL-Recon) framework for MRI reconstruction to address the limitation of\nexisting supervised learning methods. Although recent deep learning-based\nmethods have shown promising performance in MRI reconstruction, most require\nfully-sampled images for supervised learning, which is challenging in practice\nconsidering long acquisition times under respiratory or organ motion. Moreover,\nnearly all fully-sampled datasets are obtained from conventional reconstruction\nof mildly accelerated datasets, thus potentially biasing the achievable\nperformance. The numerous undersampled datasets with different accelerations in\nclinical practice, hence, remain underutilized. To address these issues, we\nfirst train a self-supervised feature extractor on undersampled images to learn\nsampling-insensitive features. The pre-learned features are subsequently\nembedded in the self-supervised reconstruction network to assist in removing\nartifacts. Experiments were conducted retrospectively on an in-house 2D cardiac\nCine dataset, including 91 cardiovascular patients and 38 healthy subjects. The\nresults demonstrate that the proposed SSFL-Recon framework outperforms existing\nself-supervised MRI reconstruction methods and even exhibits comparable or\nbetter performance to supervised learning up to $16\\times$ retrospective\nundersampling. The feature learning strategy can effectively extract global\nrepresentations, which have proven beneficial in removing artifacts and\nincreasing generalization ability during reconstruction.", "AI": {"tldr": "The paper introduces SSFL-Recon, a self-supervised framework for MRI reconstruction, addressing limitations of supervised methods by leveraging undersampled datasets and outperforming existing approaches.", "motivation": "Existing supervised MRI reconstruction methods require fully-sampled images, which are hard to acquire and may introduce bias. Undersampled datasets are underutilized.", "method": "A self-supervised feature extractor is trained on undersampled images to learn sampling-insensitive features, which are then embedded in a reconstruction network to remove artifacts.", "result": "SSFL-Recon outperforms self-supervised methods and matches or exceeds supervised methods up to 16\u00d7 undersampling, with better artifact removal and generalization.", "conclusion": "The framework effectively utilizes undersampled data, improving MRI reconstruction without needing fully-sampled images, and shows superior performance."}}
{"id": "2505.22792", "pdf": "https://arxiv.org/pdf/2505.22792", "abs": "https://arxiv.org/abs/2505.22792", "authors": ["Yuxi Zhang", "Yueting Li", "Xinyu Du", "Sibo Wang"], "title": "Rhetorical Text-to-Image Generation via Two-layer Diffusion Policy Optimization", "categories": ["cs.CV"], "comment": null, "summary": "Generating images from rhetorical languages remains a critical challenge for\ntext-to-image models. Even state-of-the-art (SOTA) multimodal large language\nmodels (MLLM) fail to generate images based on the hidden meaning inherent in\nrhetorical language--despite such content being readily mappable to visual\nrepresentations by humans. A key limitation is that current models emphasize\nobject-level word embedding alignment, causing metaphorical expressions to\nsteer image generation towards their literal visuals and overlook the intended\nsemantic meaning. To address this, we propose Rhet2Pix, a framework that\nformulates rhetorical text-to-image generation as a multi-step policy\noptimization problem, incorporating a two-layer MDP diffusion module. In the\nouter layer, Rhet2Pix converts the input prompt into incrementally elaborated\nsub-sentences and executes corresponding image-generation actions, constructing\nsemantically richer visuals. In the inner layer, Rhet2Pix mitigates reward\nsparsity during image generation by discounting the final reward and optimizing\nevery adjacent action pair along the diffusion denoising trajectory. Extensive\nexperiments demonstrate the effectiveness of Rhet2Pix in rhetorical\ntext-to-image generation. Our model outperforms SOTA MLLMs such as GPT-4o,\nGrok-3 and leading academic baselines across both qualitative and quantitative\nevaluations. The code and dataset used in this work are publicly available.", "AI": {"tldr": "Rhet2Pix improves text-to-image generation for rhetorical language by using a multi-step policy optimization framework with a two-layer MDP diffusion module.", "motivation": "Current models struggle with rhetorical language, generating literal visuals instead of intended semantic meanings.", "method": "Rhet2Pix uses a two-layer MDP diffusion module: outer layer elaborates sub-sentences, inner layer optimizes rewards during generation.", "result": "Outperforms SOTA models like GPT-4o and Grok-3 in qualitative and quantitative evaluations.", "conclusion": "Rhet2Pix effectively addresses rhetorical text-to-image generation challenges, with publicly available code and dataset."}}
{"id": "2505.22871", "pdf": "https://arxiv.org/pdf/2505.22871", "abs": "https://arxiv.org/abs/2505.22871", "authors": ["Yuval David", "Fabiana Fournier", "Lior Limonad", "Inna Skarbovsky"], "title": "The WHY in Business Processes: Unification of Causal Process Models", "categories": ["cs.AI"], "comment": "28 pages, 6 figures, BPM 2025 Forum", "summary": "Causal reasoning is essential for business process interventions and\nimprovement, requiring a clear understanding of causal relationships among\nactivity execution times in an event log. Recent work introduced a method for\ndiscovering causal process models but lacked the ability to capture alternating\ncausal conditions across multiple variants. This raises the challenges of\nhandling missing values and expressing the alternating conditions among log\nsplits when blending traces with varying activities.\n  We propose a novel method to unify multiple causal process variants into a\nconsistent model that preserves the correctness of the original causal models,\nwhile explicitly representing their causal-flow alternations. The method is\nformally defined, proved, evaluated on three open and two proprietary datasets,\nand released as an open-source implementation.", "AI": {"tldr": "A novel method unifies multiple causal process variants into a consistent model, addressing challenges like missing values and alternating causal conditions.", "motivation": "Existing methods for discovering causal process models fail to handle alternating causal conditions across variants, missing values, and trace blending issues.", "method": "Proposes a formally defined method to unify causal process variants, preserving correctness and representing causal-flow alternations explicitly.", "result": "Evaluated on three open and two proprietary datasets, with an open-source implementation released.", "conclusion": "The method successfully addresses the limitations of prior work, offering a unified and correct representation of causal process variants."}}
{"id": "2505.22696", "pdf": "https://arxiv.org/pdf/2505.22696", "abs": "https://arxiv.org/abs/2505.22696", "authors": ["Eleni Nisioti", "Joachim Winther Pedersen", "Erwan Plantec", "Milton L. Montero", "Sebastian Risi"], "title": "When Does Neuroevolution Outcompete Reinforcement Learning in Transfer Learning Tasks?", "categories": ["cs.LG"], "comment": null, "summary": "The ability to continuously and efficiently transfer skills across tasks is a\nhallmark of biological intelligence and a long-standing goal in artificial\nsystems. Reinforcement learning (RL), a dominant paradigm for learning in\nhigh-dimensional control tasks, is known to suffer from brittleness to task\nvariations and catastrophic forgetting. Neuroevolution (NE) has recently gained\nattention for its robustness, scalability, and capacity to escape local optima.\nIn this paper, we investigate an understudied dimension of NE: its transfer\nlearning capabilities. To this end, we introduce two benchmarks: a) in stepping\ngates, neural networks are tasked with emulating logic circuits, with designs\nthat emphasize modular repetition and variation b) ecorobot extends the Brax\nphysics engine with objects such as walls and obstacles and the ability to\neasily switch between different robotic morphologies. Crucial in both\nbenchmarks is the presence of a curriculum that enables evaluating skill\ntransfer across tasks of increasing complexity. Our empirical analysis shows\nthat NE methods vary in their transfer abilities and frequently outperform RL\nbaselines. Our findings support the potential of NE as a foundation for\nbuilding more adaptable agents and highlight future challenges for scaling NE\nto complex, real-world problems.", "AI": {"tldr": "The paper explores neuroevolution (NE) for transfer learning in AI, showing NE often outperforms reinforcement learning (RL) in adaptability and skill transfer across tasks.", "motivation": "To address RL's brittleness and catastrophic forgetting, the study investigates NE's understudied transfer learning capabilities for more adaptable AI systems.", "method": "Two benchmarks (stepping gates and ecorobot) with curricula are introduced to evaluate NE's skill transfer across tasks of increasing complexity.", "result": "NE methods frequently outperform RL baselines in transfer learning, demonstrating robustness and scalability.", "conclusion": "NE shows promise for adaptable AI agents but faces challenges in scaling to complex real-world problems."}}
{"id": "2505.22967", "pdf": "https://arxiv.org/pdf/2505.22967", "abs": "https://arxiv.org/abs/2505.22967", "authors": ["Chengqi Zheng", "Jianda Chen", "Yueming Lyu", "Wen Zheng Terence Ng", "Haopeng Zhang", "Yew-Soon Ong", "Ivor Tsang", "Haiyan Yin"], "title": "MermaidFlow: Redefining Agentic Workflow Generation via Safety-Constrained Evolutionary Programming", "categories": ["cs.LG", "cs.MA"], "comment": null, "summary": "Despite the promise of autonomous agentic reasoning, existing workflow\ngeneration methods frequently produce fragile, unexecutable plans due to\nunconstrained LLM-driven construction. We introduce MermaidFlow, a framework\nthat redefines the agentic search space through safety-constrained graph\nevolution. At its core, MermaidFlow represent workflows as a verifiable\nintermediate representation using Mermaid, a structured and human-interpretable\ngraph language. We formulate domain-aware evolutionary operators, i.e.,\ncrossover, mutation, insertion, and deletion, to preserve semantic correctness\nwhile promoting structural diversity, enabling efficient exploration of a\nhigh-quality, statically verifiable workflow space. Without modifying task\nsettings or evaluation protocols, MermaidFlow achieves consistent improvements\nin success rates and faster convergence to executable plans on the agent\nreasoning benchmark. The experimental results demonstrate that\nsafety-constrained graph evolution offers a scalable, modular foundation for\nrobust and interpretable agentic reasoning systems.", "AI": {"tldr": "MermaidFlow improves workflow generation by using safety-constrained graph evolution with Mermaid, ensuring executable and diverse plans.", "motivation": "Existing methods produce fragile, unexecutable plans due to unconstrained LLM-driven construction.", "method": "Uses Mermaid for verifiable intermediate representation and domain-aware evolutionary operators (crossover, mutation, insertion, deletion) to maintain correctness and diversity.", "result": "Achieves higher success rates and faster convergence to executable plans on benchmarks.", "conclusion": "Safety-constrained graph evolution provides a scalable, modular foundation for robust and interpretable agentic reasoning."}}
{"id": "2505.23268", "pdf": "https://arxiv.org/pdf/2505.23268", "abs": "https://arxiv.org/abs/2505.23268", "authors": ["Spyros Barbakos", "Charalampos Antoniadis", "Gerasimos Potamianos", "Gianluca Setti"], "title": "Unsupervised Transcript-assisted Video Summarization and Highlight Detection", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": null, "summary": "Video consumption is a key part of daily life, but watching entire videos can\nbe tedious. To address this, researchers have explored video summarization and\nhighlight detection to identify key video segments. While some works combine\nvideo frames and transcripts, and others tackle video summarization and\nhighlight detection using Reinforcement Learning (RL), no existing work, to the\nbest of our knowledge, integrates both modalities within an RL framework. In\nthis paper, we propose a multimodal pipeline that leverages video frames and\ntheir corresponding transcripts to generate a more condensed version of the\nvideo and detect highlights using a modality fusion mechanism. The pipeline is\ntrained within an RL framework, which rewards the model for generating diverse\nand representative summaries while ensuring the inclusion of video segments\nwith meaningful transcript content. The unsupervised nature of the training\nallows for learning from large-scale unannotated datasets, overcoming the\nchallenge posed by the limited size of existing annotated datasets. Our\nexperiments show that using the transcript in video summarization and highlight\ndetection achieves superior results compared to relying solely on the visual\ncontent of the video.", "AI": {"tldr": "A multimodal RL framework combines video frames and transcripts for better video summarization and highlight detection, outperforming visual-only methods.", "motivation": "Existing methods either use video frames or transcripts separately, but none integrate both in an RL framework for summarization and highlight detection.", "method": "Proposes a multimodal pipeline using RL to fuse video frames and transcripts, rewarding diverse and representative summaries with meaningful transcript content.", "result": "The approach outperforms visual-only methods by leveraging transcripts, and the unsupervised training allows scalability.", "conclusion": "Integrating transcripts with video frames in an RL framework improves summarization and highlight detection, demonstrating the value of multimodal fusion."}}
{"id": "2505.23494", "pdf": "https://arxiv.org/pdf/2505.23494", "abs": "https://arxiv.org/abs/2505.23494", "authors": ["Nicol Visser", "Herman Kamper"], "title": "Spoken Language Modeling with Duration-Penalized Self-Supervised Units", "categories": ["cs.CL", "eess.AS"], "comment": "Accepted to Interspeech 2025", "summary": "Spoken language models (SLMs) operate on acoustic units obtained by\ndiscretizing self-supervised speech representations. Although the\ncharacteristics of these units directly affect performance, the interaction\nbetween codebook size and unit coarseness (i.e., duration) remains unexplored.\nWe investigate SLM performance as we vary codebook size and unit coarseness\nusing the simple duration-penalized dynamic programming (DPDP) method. New\nanalyses are performed across different linguistic levels. At the phone and\nword levels, coarseness provides little benefit, as long as the codebook size\nis chosen appropriately. However, when producing whole sentences in a\nresynthesis task, SLMs perform better with coarser units. In lexical and\nsyntactic language modeling tasks, coarser units also give higher accuracies at\nlower bitrates. We therefore show that coarser units aren't always better, but\nthat DPDP is a simple and efficient way to obtain coarser units for the tasks\nwhere they are beneficial.", "AI": {"tldr": "The paper explores how codebook size and unit coarseness affect spoken language models (SLMs), finding coarser units improve performance in sentence resynthesis and language modeling tasks, but not at phone or word levels.", "motivation": "To understand the interaction between codebook size and unit coarseness in SLMs, which remains unexplored despite its impact on performance.", "method": "Varies codebook size and unit coarseness using duration-penalized dynamic programming (DPDP) and analyzes performance across linguistic levels.", "result": "Coarser units benefit sentence resynthesis and language modeling tasks but not phone/word levels. DPDP efficiently provides coarser units where needed.", "conclusion": "Coarser units are task-dependent; DPDP is a simple, effective method to optimize SLM performance for specific tasks."}}
{"id": "2505.23236", "pdf": "https://arxiv.org/pdf/2505.23236", "abs": "https://arxiv.org/abs/2505.23236", "authors": ["Youjun Chen", "Xurong Xie", "Haoning Xu", "Mengzhe Geng", "Guinan Li", "Chengxi Deng", "Huimeng Wang", "Shujie Hu", "Xunying Liu"], "title": "Towards LLM-Empowered Fine-Grained Speech Descriptors for Explainable Emotion Recognition", "categories": ["cs.SD", "cs.HC", "eess.AS"], "comment": "Accepted by INTERSPEECH2025", "summary": "This paper presents a novel end-to-end LLM-empowered explainable speech\nemotion recognition (SER) approach. Fine-grained speech emotion descriptor\n(SED) features, e.g., pitch, tone and emphasis, are disentangled from HuBERT\nSSL representations via alternating LLM fine-tuning to joint SER-SED prediction\nand ASR tasks. VAE compressed HuBERT features derived via Information\nBottleneck (IB) are used to adjust feature granularity. Experiments on the\nIEMOCAP and MELD benchmarks demonstrate that our approach consistently\noutperforms comparable LLaMA-based SER baselines, including those using either\n(a) alternating multi-task fine-tuning alone or (b) feature disentanglement\nonly. Statistically significant increase of SER unweighted accuracy by up to\n4.0% and 3.7% absolute (5.4% and 6.6% relative) are obtained. More importantly,\nemotion descriptors offer further explainability for SER.", "AI": {"tldr": "A novel LLM-based explainable speech emotion recognition (SER) method outperforms baselines by disentangling fine-grained features and using VAE-compressed HuBERT features.", "motivation": "To improve SER accuracy and provide explainability through emotion descriptors.", "method": "Disentangles SED features from HuBERT SSL representations via alternating LLM fine-tuning, uses VAE-compressed HuBERT features with IB for granularity adjustment.", "result": "Outperforms LLaMA-based SER baselines by up to 4.0% absolute accuracy, with added explainability.", "conclusion": "The approach enhances SER performance and explainability, demonstrating the value of feature disentanglement and multi-task fine-tuning."}}
{"id": "2505.22774", "pdf": "https://arxiv.org/pdf/2505.22774", "abs": "https://arxiv.org/abs/2505.22774", "authors": ["Kaja Dobrovoljc"], "title": "Counting trees: A treebank-driven exploration of syntactic variation in speech and writing across languages", "categories": ["cs.CL"], "comment": null, "summary": "This paper presents a novel treebank-driven approach to comparing syntactic\nstructures in speech and writing using dependency-parsed corpora. Adopting a\nfully inductive, bottom-up method, we define syntactic structures as\ndelexicalized dependency (sub)trees and extract them from spoken and written\nUniversal Dependencies (UD) treebanks in two syntactically distinct languages,\nEnglish and Slovenian. For each corpus, we analyze the size, diversity, and\ndistribution of syntactic inventories, their overlap across modalities, and the\nstructures most characteristic of speech. Results show that, across both\nlanguages, spoken corpora contain fewer and less diverse syntactic structures\nthan their written counterparts, with consistent cross-linguistic preferences\nfor certain structural types across modalities. Strikingly, the overlap between\nspoken and written syntactic inventories is very limited: most structures\nattested in speech do not occur in writing, pointing to modality-specific\npreferences in syntactic organization that reflect the distinct demands of\nreal-time interaction and elaborated writing. This contrast is further\nsupported by a keyness analysis of the most frequent speech-specific\nstructures, which highlights patterns associated with interactivity,\ncontext-grounding, and economy of expression. We argue that this scalable,\nlanguage-independent framework offers a useful general method for\nsystematically studying syntactic variation across corpora, laying the\ngroundwork for more comprehensive data-driven theories of grammar in use.", "AI": {"tldr": "A treebank-driven method compares syntactic structures in speech and writing using dependency-parsed corpora, revealing fewer and less diverse structures in speech with limited overlap between modalities.", "motivation": "To systematically compare syntactic structures in spoken and written language across modalities and languages, identifying modality-specific preferences.", "method": "Delexicalized dependency subtrees are extracted from spoken and written Universal Dependencies treebanks in English and Slovenian, analyzing size, diversity, distribution, and overlap.", "result": "Spoken corpora have fewer and less diverse structures than written ones, with minimal overlap. Speech-specific structures reflect interactivity and economy of expression.", "conclusion": "The framework provides a scalable, language-independent method for studying syntactic variation, advancing data-driven theories of grammar."}}
{"id": "2505.23618", "pdf": "https://arxiv.org/pdf/2505.23618", "abs": "https://arxiv.org/abs/2505.23618", "authors": ["Amir Said", "Hilmi E. Egilmez", "Yung-Hsuan Chao"], "title": "Low-Complexity Transform Adjustments For Video Coding", "categories": ["eess.IV"], "comment": null, "summary": "Recent video codecs with multiple separable transforms can achieve\nsignificant coding gains using asymmetric trigonometric transforms (DCTs and\nDSTs), because they can exploit diverse statistics of residual block signals.\nHowever, they add excessive computational and memory complexity on large\ntransforms (32-point and larger), since their practical software and hardware\nimplementations are not as efficient as of the DCT-2. This article introduces a\nnovel technique to design low-complexity approximations of trigonometric\ntransforms. The proposed method uses DCT-2 computations, and applies orthogonal\nadjustments to approximate the most important basis vectors of the desired\ntransform. Experimental results on the Versatile Video Coding (VVC) reference\nsoftware show that the proposed approach significantly reduces the\ncomputational complexity, while providing practically identical coding\nefficiency.", "AI": {"tldr": "A novel method reduces complexity of large trigonometric transforms in video codecs by approximating them using DCT-2, maintaining coding efficiency.", "motivation": "Current video codecs use complex transforms (DCTs/DSTs) for coding gains, but their inefficiency in large transforms (32-point+) increases computational and memory costs.", "method": "Proposes using DCT-2 computations with orthogonal adjustments to approximate key basis vectors of desired transforms.", "result": "Tests on VVC software show significant complexity reduction with no loss in coding efficiency.", "conclusion": "The method effectively balances computational simplicity and coding performance for large transforms."}}
{"id": "2505.22793", "pdf": "https://arxiv.org/pdf/2505.22793", "abs": "https://arxiv.org/abs/2505.22793", "authors": ["Srishti Yadav", "Lauren Tilton", "Maria Antoniak", "Taylor Arnold", "Jiaang Li", "Siddhesh Milind Pawar", "Antonia Karamolegkou", "Stella Frank", "Zhaochong An", "Negar Rostamzadeh", "Daniel Hershcovich", "Serge Belongie", "Ekaterina Shutova"], "title": "Cultural Evaluations of Vision-Language Models Have a Lot to Learn from Cultural Theory", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Modern vision-language models (VLMs) often fail at cultural competency\nevaluations and benchmarks. Given the diversity of applications built upon\nVLMs, there is renewed interest in understanding how they encode cultural\nnuances. While individual aspects of this problem have been studied, we still\nlack a comprehensive framework for systematically identifying and annotating\nthe nuanced cultural dimensions present in images for VLMs. This position paper\nargues that foundational methodologies from visual culture studies (cultural\nstudies, semiotics, and visual studies) are necessary for cultural analysis of\nimages. Building upon this review, we propose a set of five frameworks,\ncorresponding to cultural dimensions, that must be considered for a more\ncomplete analysis of the cultural competencies of VLMs.", "AI": {"tldr": "The paper argues for using foundational methodologies from visual culture studies to systematically analyze cultural dimensions in images for vision-language models (VLMs).", "motivation": "VLMs often fail at cultural competency evaluations, highlighting the need for a comprehensive framework to understand cultural nuances in images.", "method": "Proposes five frameworks based on cultural dimensions, derived from visual culture studies (cultural studies, semiotics, visual studies).", "result": "A structured approach to identify and annotate cultural nuances in images for VLMs.", "conclusion": "Foundational methodologies from visual culture studies are essential for improving the cultural competency of VLMs."}}
{"id": "2505.22928", "pdf": "https://arxiv.org/pdf/2505.22928", "abs": "https://arxiv.org/abs/2505.22928", "authors": ["Massimiliano Pronesti", "Michela Lorandi", "Paul Flanagan", "Oisin Redmon", "Anya Belz", "Yufang Hou"], "title": "Enhancing Study-Level Inference from Clinical Trial Papers via RL-based Numeric Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Systematic reviews in medicine play a critical role in evidence-based\ndecision-making by aggregating findings from multiple studies. A central\nbottleneck in automating this process is extracting numeric evidence and\ndetermining study-level conclusions for specific outcomes and comparisons.\nPrior work has framed this problem as a textual inference task by retrieving\nrelevant content fragments and inferring conclusions from them. However, such\napproaches often rely on shallow textual cues and fail to capture the\nunderlying numeric reasoning behind expert assessments.\n  In this work, we conceptualise the problem as one of quantitative reasoning.\nRather than inferring conclusions from surface text, we extract structured\nnumerical evidence (e.g., event counts or standard deviations) and apply domain\nknowledge informed logic to derive outcome-specific conclusions. We develop a\nnumeric reasoning system composed of a numeric data extraction model and an\neffect estimate component, enabling more accurate and interpretable inference\naligned with the domain expert principles. We train the numeric data extraction\nmodel using different strategies, including supervised fine-tuning (SFT) and\nreinforcement learning (RL) with a new value reward model.\n  When evaluated on the CochraneForest benchmark, our best-performing approach\n-- using RL to train a small-scale number extraction model -- yields up to a\n21% absolute improvement in F1 score over retrieval-based systems and\noutperforms general-purpose LLMs of over 400B parameters by up to 9%. Our\nresults demonstrate the promise of reasoning-driven approaches for automating\nsystematic evidence synthesis.", "AI": {"tldr": "The paper proposes a numeric reasoning system for automating systematic reviews in medicine, improving accuracy by extracting structured numerical evidence and applying domain-specific logic, outperforming prior methods.", "motivation": "Automating systematic reviews is hindered by the challenge of extracting numeric evidence and deriving conclusions. Prior methods rely on shallow textual cues, lacking the depth of expert numeric reasoning.", "method": "The system combines numeric data extraction (trained via supervised fine-tuning and reinforcement learning) with domain-informed logic for deriving conclusions.", "result": "The approach achieves a 21% F1 score improvement over retrieval-based systems and outperforms large language models by up to 9%.", "conclusion": "Numeric reasoning-driven methods show promise for automating evidence synthesis, aligning with expert principles."}}
{"id": "2505.22697", "pdf": "https://arxiv.org/pdf/2505.22697", "abs": "https://arxiv.org/abs/2505.22697", "authors": ["Filippo Rinaldi", "Giacomo Capitani", "Lorenzo Bonicelli", "Donato Crisostomi", "Federico Bolelli", "Elisa Ficarra", "Emanuele Rodol\u00e0", "Simone Calderara", "Angelo Porrello"], "title": "Update Your Transformer to the Latest Release: Re-Basin of Task Vectors", "categories": ["cs.LG"], "comment": "Accepted at ICML 2025", "summary": "Foundation models serve as the backbone for numerous specialized models\ndeveloped through fine-tuning. However, when the underlying pretrained model is\nupdated or retrained (e.g., on larger and more curated datasets), the\nfine-tuned model becomes obsolete, losing its utility and requiring retraining.\nThis raises the question: is it possible to transfer fine-tuning to a new\nrelease of the model? In this work, we investigate how to transfer fine-tuning\nto a new checkpoint without having to re-train, in a data-free manner. To do\nso, we draw principles from model re-basin and provide a recipe based on weight\npermutations to re-base the modifications made to the original base model,\noften called task vector. In particular, our approach tailors model re-basin\nfor Transformer models, taking into account the challenges of residual\nconnections and multi-head attention layers. Specifically, we propose a\ntwo-level method rooted in spectral theory, initially permuting the attention\nheads and subsequently adjusting parameters within select pairs of heads.\nThrough extensive experiments on visual and textual tasks, we achieve the\nseamless transfer of fine-tuned knowledge to new pre-trained backbones without\nrelying on a single training step or datapoint. Code is available at\nhttps://github.com/aimagelab/TransFusion.", "AI": {"tldr": "The paper proposes a method to transfer fine-tuning from an outdated pre-trained model to a new one without retraining, using weight permutations and spectral theory.", "motivation": "Fine-tuned models become obsolete when the underlying pre-trained model is updated, requiring costly retraining. The goal is to enable seamless transfer of fine-tuning to new models without data or retraining.", "method": "A two-level approach based on weight permutations and spectral theory, addressing challenges in Transformer models like residual connections and multi-head attention layers.", "result": "Successful transfer of fine-tuned knowledge to new pre-trained models without training or data, validated on visual and textual tasks.", "conclusion": "The method provides a practical solution for updating fine-tuned models when the base model changes, eliminating the need for retraining."}}
{"id": "2505.22979", "pdf": "https://arxiv.org/pdf/2505.22979", "abs": "https://arxiv.org/abs/2505.22979", "authors": ["Bengisu Guresti", "Chongjie Zhang", "Yevgeniy Vorobeychik"], "title": "Learning Recommender Mechanisms for Bayesian Stochastic Games", "categories": ["cs.GT", "cs.MA"], "comment": null, "summary": "An important challenge in non-cooperative game theory is coordinating on a\nsingle (approximate) equilibrium from many possibilities - a challenge that\nbecomes even more complex when players hold private information. Recommender\nmechanisms tackle this problem by recommending strategies to players based on\ntheir reported type profiles. A key consideration in such mechanisms is to\nensure that players are incentivized to participate, report their private\ninformation truthfully, and follow the recommendations. While previous work has\nfocused on designing recommender mechanisms for one-shot and extensive-form\ngames, these approaches cannot be effectively applied to stochastic games,\nparticularly if we constrain recommendations to be Markov stationary policies.\nTo bridge this gap, we introduce a novel bi-level reinforcement learning\napproach for automatically designing recommender mechanisms in Bayesian\nstochastic games. Our method produces a mechanism represented by a parametric\nfunction (such as a neural network), and is therefore highly efficient at\nexecution time. Experimental results on two repeated and two stochastic games\ndemonstrate that our approach achieves social welfare levels competitive with\ncooperative multi-agent reinforcement learning baselines, while also providing\nsignificantly improved incentive properties.", "AI": {"tldr": "A novel bi-level reinforcement learning approach is introduced to design recommender mechanisms for Bayesian stochastic games, ensuring participation, truthful reporting, and adherence to recommendations.", "motivation": "The challenge of coordinating on an equilibrium in non-cooperative games with private information, especially in stochastic games with Markov stationary policies, motivates this work.", "method": "A bi-level reinforcement learning approach is used to design parametric recommender mechanisms (e.g., neural networks) for Bayesian stochastic games.", "result": "Experiments show competitive social welfare with cooperative multi-agent reinforcement learning baselines and improved incentive properties.", "conclusion": "The proposed method effectively bridges the gap in designing recommender mechanisms for stochastic games while maintaining efficiency and strong incentive properties."}}
{"id": "2505.23586", "pdf": "https://arxiv.org/pdf/2505.23586", "abs": "https://arxiv.org/abs/2505.23586", "authors": ["Ziyong Wang", "Charith Abhayaratne"], "title": "Weakly-supervised Localization of Manipulated Image Regions Using Multi-resolution Learned Features", "categories": ["cs.CV", "cs.MM", "eess.IV"], "comment": "This paper was presented at the British Machine Vision Conference\n  2024 workshop on Media authenticity in the age of artificial intelligence", "summary": "The explosive growth of digital images and the widespread availability of\nimage editing tools have made image manipulation detection an increasingly\ncritical challenge. Current deep learning-based manipulation detection methods\nexcel in achieving high image-level classification accuracy, they often fall\nshort in terms of interpretability and localization of manipulated regions.\nAdditionally, the absence of pixel-wise annotations in real-world scenarios\nlimits the existing fully-supervised manipulation localization techniques. To\naddress these challenges, we propose a novel weakly-supervised approach that\nintegrates activation maps generated by image-level manipulation detection\nnetworks with segmentation maps from pre-trained models. Specifically, we build\non our previous image-level work named WCBnet to produce multi-view feature\nmaps which are subsequently fused for coarse localization. These coarse maps\nare then refined using detailed segmented regional information provided by\npre-trained segmentation models (such as DeepLab, SegmentAnything and PSPnet),\nwith Bayesian inference employed to enhance the manipulation localization.\nExperimental results demonstrate the effectiveness of our approach,\nhighlighting the feasibility to localize image manipulations without relying on\npixel-level labels.", "AI": {"tldr": "A weakly-supervised approach for image manipulation detection and localization, combining activation maps and pre-trained segmentation models, achieves effective results without pixel-level labels.", "motivation": "Addressing the lack of interpretability and localization in deep learning-based manipulation detection, and overcoming the limitation of missing pixel-wise annotations in real-world scenarios.", "method": "Integrates activation maps from image-level detection networks (WCBnet) with segmentation maps from pre-trained models (DeepLab, SegmentAnything, PSPnet), refining with Bayesian inference.", "result": "Demonstrates feasibility of localizing manipulations without pixel-level labels, achieving effective localization.", "conclusion": "Proposed approach successfully addresses interpretability and localization challenges in image manipulation detection."}}
{"id": "2505.23509", "pdf": "https://arxiv.org/pdf/2505.23509", "abs": "https://arxiv.org/abs/2505.23509", "authors": ["Andrew Chang", "Yike Li", "Iran R. Roman", "David Poeppel"], "title": "Spectrotemporal Modulation: Efficient and Interpretable Feature Representation for Classifying Speech, Music, and Environmental Sounds", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "Interspeech 2025", "summary": "Audio DNNs have demonstrated impressive performance on various machine\nlistening tasks; however, most of their representations are computationally\ncostly and uninterpretable, leaving room for optimization. Here, we propose a\nnovel approach centered on spectrotemporal modulation (STM) features, a signal\nprocessing method that mimics the neurophysiological representation in the\nhuman auditory cortex. The classification performance of our STM-based model,\nwithout any pretraining, is comparable to that of pretrained audio DNNs across\ndiverse naturalistic speech, music, and environmental sounds, which are\nessential categories for both human cognition and machine perception. These\nresults show that STM is an efficient and interpretable feature representation\nfor audio classification, advancing the development of machine listening and\nunlocking exciting new possibilities for basic understanding of speech and\nauditory sciences, as well as developing audio BCI and cognitive computing.", "AI": {"tldr": "The paper proposes a spectrotemporal modulation (STM) feature-based model for audio classification, achieving performance comparable to pretrained DNNs while being more efficient and interpretable.", "motivation": "Current audio DNNs are computationally costly and lack interpretability, prompting the need for optimized solutions.", "method": "The approach uses STM features, inspired by human auditory cortex neurophysiology, for audio classification without pretraining.", "result": "The STM-based model matches pretrained DNN performance across speech, music, and environmental sounds.", "conclusion": "STM features offer an efficient, interpretable alternative for audio classification, with potential applications in auditory science and cognitive computing."}}
{"id": "2505.23290", "pdf": "https://arxiv.org/pdf/2505.23290", "abs": "https://arxiv.org/abs/2505.23290", "authors": ["Hao Li", "Ju Dai", "Xin Zhao", "Feng Zhou", "Junjun Pan", "Lei Li"], "title": "Wav2Sem: Plug-and-Play Audio Semantic Decoupling for 3D Speech-Driven Facial Animation", "categories": ["cs.SD", "cs.CV"], "comment": "Accepted to CVPR 2025", "summary": "In 3D speech-driven facial animation generation, existing methods commonly\nemploy pre-trained self-supervised audio models as encoders. However, due to\nthe prevalence of phonetically similar syllables with distinct lip shapes in\nlanguage, these near-homophone syllables tend to exhibit significant coupling\nin self-supervised audio feature spaces, leading to the averaging effect in\nsubsequent lip motion generation. To address this issue, this paper proposes a\nplug-and-play semantic decorrelation module-Wav2Sem. This module extracts\nsemantic features corresponding to the entire audio sequence, leveraging the\nadded semantic information to decorrelate audio encodings within the feature\nspace, thereby achieving more expressive audio features. Extensive experiments\nacross multiple Speech-driven models indicate that the Wav2Sem module\neffectively decouples audio features, significantly alleviating the averaging\neffect of phonetically similar syllables in lip shape generation, thereby\nenhancing the precision and naturalness of facial animations. Our source code\nis available at https://github.com/wslh852/Wav2Sem.git.", "AI": {"tldr": "The paper introduces Wav2Sem, a plug-and-play module to decorrelate audio features in 3D speech-driven facial animation, improving lip motion precision by addressing the averaging effect of phonetically similar syllables.", "motivation": "Existing methods using self-supervised audio models struggle with phonetically similar syllables causing coupling in audio features, leading to less accurate lip shapes.", "method": "Proposes Wav2Sem, a semantic decorrelation module that extracts semantic features from audio sequences to decorrelate encodings and enhance expressiveness.", "result": "Experiments show Wav2Sem effectively decouples audio features, reducing the averaging effect and improving facial animation precision and naturalness.", "conclusion": "Wav2Sem enhances speech-driven facial animation by addressing feature coupling, offering a practical solution for more accurate lip motion generation."}}
{"id": "2505.22777", "pdf": "https://arxiv.org/pdf/2505.22777", "abs": "https://arxiv.org/abs/2505.22777", "authors": ["John Mendon\u00e7a", "Alon Lavie", "Isabel Trancoso"], "title": "MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Chatbots and Dialogue Evaluators", "categories": ["cs.CL"], "comment": "May ARR", "summary": "As the capabilities of chatbots and their underlying LLMs continue to\ndramatically improve, evaluating their performance has increasingly become a\nmajor blocker to their further development. A major challenge is the available\nbenchmarking datasets, which are largely static, outdated, and lacking in\nmultilingual coverage, limiting their ability to capture subtle linguistic and\ncultural variations. This paper introduces MEDAL, an automated multi-agent\nframework for generating, evaluating, and curating more representative and\ndiverse open-domain dialogue evaluation benchmarks. Our approach leverages\nseveral state-of-the-art LLMs to generate user-chatbot multilingual dialogues,\nconditioned on varied seed contexts. A strong LLM (GPT-4.1) is then used for a\nmultidimensional analysis of the performance of the chatbots, uncovering\nnoticeable cross-lingual performance differences. Guided by this large-scale\nevaluation, we curate a new meta-evaluation multilingual benchmark and\nhuman-annotate samples with nuanced quality judgments. This benchmark is then\nused to assess the ability of several reasoning and non-reasoning LLMs to act\nas evaluators of open-domain dialogues. We find that current LLMs struggle to\ndetect nuanced issues, particularly those involving empathy and reasoning.", "AI": {"tldr": "MEDAL is an automated multi-agent framework for generating and evaluating multilingual dialogue benchmarks, revealing LLMs' limitations in nuanced issue detection.", "motivation": "Current benchmarking datasets for chatbots are static, outdated, and lack multilingual coverage, hindering development.", "method": "MEDAL uses LLMs to generate multilingual dialogues, evaluates them with GPT-4.1, and curates a new benchmark with human annotations.", "result": "The framework uncovers cross-lingual performance differences and shows LLMs struggle with nuanced issues like empathy and reasoning.", "conclusion": "MEDAL provides a more representative benchmark, highlighting the need for improved LLM evaluators in open-domain dialogues."}}
{"id": "2505.23672", "pdf": "https://arxiv.org/pdf/2505.23672", "abs": "https://arxiv.org/abs/2505.23672", "authors": ["Amir Said", "Xin Zhao", "Marta Karczewicz", "Jianle Chen", "Feng Zou"], "title": "Position Dependent Prediction Combination For Intra-Frame Video Coding", "categories": ["eess.IV"], "comment": null, "summary": "Intra-frame prediction in the High Efficiency Video Coding (HEVC) standard\ncan be empirically improved by applying sets of recursive two-dimensional\nfilters to the predicted values. However, this approach does not allow (or\ncomplicates significantly) the parallel computation of pixel predictions. In\nthis work we analyze why the recursive filters are effective, and use the\nresults to derive sets of non-recursive predictors that have superior\nperformance. We present an extension to HEVC intra prediction that combines\nvalues predicted using non-filtered and filtered (smoothed) reference samples,\ndepending on the prediction mode, and block size. Simulations using the HEVC\ncommon test conditions show that a 2.0% bit rate average reduction can be\nachieved compared to HEVC, for All Intra (AI) configurations.", "AI": {"tldr": "The paper improves HEVC intra-frame prediction by replacing recursive filters with non-recursive predictors, achieving a 2.0% bit rate reduction.", "motivation": "Recursive filters in HEVC complicate parallel computation of pixel predictions, prompting a search for more efficient alternatives.", "method": "Analyzed recursive filters' effectiveness and derived non-recursive predictors. Extended HEVC by combining filtered and non-filtered reference samples based on prediction mode and block size.", "result": "Simulations showed a 2.0% average bit rate reduction in All Intra configurations compared to standard HEVC.", "conclusion": "Non-recursive predictors outperform recursive filters, offering better efficiency and parallelizability in HEVC intra prediction."}}
{"id": "2505.22797", "pdf": "https://arxiv.org/pdf/2505.22797", "abs": "https://arxiv.org/abs/2505.22797", "authors": ["Vladyslav Gapyak", "Thomas M\u00e4rz", "Andreas Weinmann"], "title": "Fast Trajectory-Independent Model-Based Reconstruction Algorithm for Multi-Dimensional Magnetic Particle Imaging", "categories": ["cs.CV", "cs.NA", "math.NA", "physics.med-ph"], "comment": "10 pages, 5 figures. This work has been submitted to the IEEE for\n  possible publication", "summary": "Magnetic Particle Imaging (MPI) is a promising tomographic technique for\nvisualizing the spatio-temporal distribution of superparamagnetic\nnanoparticles, with applications ranging from cancer detection to real-time\ncardiovascular monitoring. Traditional MPI reconstruction relies on either\ntime-consuming calibration (measured system matrix) or model-based simulation\nof the forward operator. Recent developments have shown the applicability of\nChebyshev polynomials to multi-dimensional Lissajous Field-Free Point (FFP)\nscans. This method is bound to the particular choice of sinusoidal scanning\ntrajectories. In this paper, we present the first reconstruction on real 2D MPI\ndata with a trajectory-independent model-based MPI reconstruction algorithm. We\nfurther develop the zero-shot Plug-and-Play (PnP) algorithm of the authors --\nwith automatic noise level estimation -- to address the present deconvolution\nproblem, leveraging a state-of-the-art denoiser trained on natural images\nwithout retraining on MPI-specific data. We evaluate our method on the publicly\navailable 2D FFP MPI dataset ``MPIdata: Equilibrium Model with Anisotropy\",\nfeaturing scans of six phantoms acquired using a Bruker preclinical scanner.\nMoreover, we show reconstruction performed on custom data on a 2D scanner with\nadditional high-frequency excitation field and partial data. Our results\ndemonstrate strong reconstruction capabilities across different scanning\nscenarios -- setting a precedent for general-purpose, flexible model-based MPI\nreconstruction.", "AI": {"tldr": "A trajectory-independent model-based MPI reconstruction algorithm is introduced, leveraging a zero-shot Plug-and-Play method with automatic noise estimation, demonstrating strong performance across diverse scanning scenarios.", "motivation": "Traditional MPI reconstruction methods are limited by time-consuming calibration or model-based simulations tied to specific trajectories, prompting the need for a more flexible approach.", "method": "The paper presents a trajectory-independent model-based MPI reconstruction algorithm using a zero-shot Plug-and-Play (PnP) method with automatic noise level estimation, employing a state-of-the-art denoiser trained on natural images.", "result": "The method is evaluated on public and custom datasets, showing robust reconstruction capabilities across various scanning scenarios, including high-frequency excitation fields and partial data.", "conclusion": "The proposed algorithm sets a precedent for general-purpose, flexible model-based MPI reconstruction, overcoming limitations of traditional methods."}}
{"id": "2505.22948", "pdf": "https://arxiv.org/pdf/2505.22948", "abs": "https://arxiv.org/abs/2505.22948", "authors": ["Michael Sun", "Weize Yuan", "Gang Liu", "Wojciech Matusik", "Jie Chen"], "title": "Foundation Molecular Grammar: Multi-Modal Foundation Models Induce Interpretable Molecular Graph Languages", "categories": ["cs.AI"], "comment": "ICML 2025", "summary": "Recent data-efficient molecular generation approaches exploit graph grammars\nto introduce interpretability into the generative models. However, grammar\nlearning therein relies on expert annotation or unreliable heuristics for\nalgorithmic inference. We propose Foundation Molecular Grammar (FMG), which\nleverages multi-modal foundation models (MMFMs) to induce an interpretable\nmolecular language. By exploiting the chemical knowledge of an MMFM, FMG\nrenders molecules as images, describes them as text, and aligns information\nacross modalities using prompt learning. FMG can be used as a drop-in\nreplacement for the prior grammar learning approaches in molecular generation\nand property prediction. We show that FMG not only excels in synthesizability,\ndiversity, and data efficiency but also offers built-in chemical\ninterpretability for automated molecular discovery workflows. Code is available\nat https://github.com/shiningsunnyday/induction.", "AI": {"tldr": "FMG uses multi-modal foundation models to create an interpretable molecular language, improving molecular generation and property prediction.", "motivation": "Current grammar-based molecular generation methods rely on expert annotation or unreliable heuristics, limiting their effectiveness.", "method": "FMG leverages multi-modal foundation models to represent molecules as images and text, aligning information across modalities via prompt learning.", "result": "FMG outperforms prior methods in synthesizability, diversity, and data efficiency while providing built-in chemical interpretability.", "conclusion": "FMG is a versatile and interpretable alternative for molecular discovery, with code publicly available."}}
{"id": "2505.22703", "pdf": "https://arxiv.org/pdf/2505.22703", "abs": "https://arxiv.org/abs/2505.22703", "authors": ["Mohammad Yaghini", "Tudor Cebere", "Michael Menart", "Aur\u00e9lien Bellet", "Nicolas Papernot"], "title": "Private Rate-Constrained Optimization with Applications to Fair Learning", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": null, "summary": "Many problems in trustworthy ML can be formulated as minimization of the\nmodel error under constraints on the prediction rates of the model for\nsuitably-chosen marginals, including most group fairness constraints\n(demographic parity, equality of odds, etc.). In this work, we study such\nconstrained minimization problems under differential privacy (DP). Standard DP\noptimization techniques like DP-SGD rely on the loss function's decomposability\ninto per-sample contributions. However, rate constraints introduce inter-sample\ndependencies, violating the decomposability requirement. To address this, we\ndevelop RaCO-DP, a DP variant of the Stochastic Gradient Descent-Ascent (SGDA)\nalgorithm which solves the Lagrangian formulation of rate constraint problems.\nWe demonstrate that the additional privacy cost of incorporating these\nconstraints reduces to privately estimating a histogram over the mini-batch at\neach optimization step. We prove the convergence of our algorithm through a\nnovel analysis of SGDA that leverages the linear structure of the dual\nparameter. Finally, empirical results on learning under group fairness\nconstraints demonstrate that our method Pareto-dominates existing private\nlearning approaches in fairness-utility trade-offs.", "AI": {"tldr": "RaCO-DP, a differentially private variant of SGDA, addresses constrained ML problems with rate constraints, improving fairness-utility trade-offs.", "motivation": "To solve constrained minimization problems in trustworthy ML under differential privacy, where standard techniques fail due to inter-sample dependencies from rate constraints.", "method": "Develops RaCO-DP, a DP variant of SGDA, solving the Lagrangian formulation of rate constraint problems by privately estimating histograms over mini-batches.", "result": "The method Pareto-dominates existing private learning approaches in fairness-utility trade-offs.", "conclusion": "RaCO-DP effectively handles rate constraints under DP, offering better fairness-utility trade-offs than prior methods."}}
{"id": "2505.23187", "pdf": "https://arxiv.org/pdf/2505.23187", "abs": "https://arxiv.org/abs/2505.23187", "authors": ["Yilong Li", "Chen Qian", "Yu Xia", "Ruijie Shi", "Yufan Dang", "Zihao Xie", "Ziming You", "Weize Chen", "Cheng Yang", "Weichuan Liu", "Ye Tian", "Xuantang Xiong", "Lei Han", "Zhiyuan Liu", "Maosong Sun"], "title": "Cross-Task Experiential Learning on LLM-based Multi-Agent Collaboration", "categories": ["cs.CL", "cs.AI", "cs.MA"], "comment": "Work in Progress", "summary": "Large Language Model-based multi-agent systems (MAS) have shown remarkable\nprogress in solving complex tasks through collaborative reasoning and\ninter-agent critique. However, existing approaches typically treat each task in\nisolation, resulting in redundant computations and limited generalization\nacross structurally similar tasks. To address this, we introduce multi-agent\ncross-task experiential learning (MAEL), a novel framework that endows\nLLM-driven agents with explicit cross-task learning and experience\naccumulation. We model the task-solving workflow on a graph-structured\nmulti-agent collaboration network, where agents propagate information and\ncoordinate via explicit connectivity. During the experiential learning phase,\nwe quantify the quality for each step in the task-solving workflow and store\nthe resulting rewards along with the corresponding inputs and outputs into each\nagent's individual experience pool. During inference, agents retrieve\nhigh-reward, task-relevant experiences as few-shot examples to enhance the\neffectiveness of each reasoning step, thereby enabling more accurate and\nefficient multi-agent collaboration. Experimental results on diverse datasets\ndemonstrate that MAEL empowers agents to learn from prior task experiences\neffectively-achieving faster convergence and producing higher-quality solutions\non current tasks.", "AI": {"tldr": "MAEL introduces cross-task experiential learning for LLM-based multi-agent systems, improving efficiency and generalization by leveraging prior task experiences.", "motivation": "Existing approaches treat tasks in isolation, leading to redundancy and limited generalization. MAEL addresses this by enabling agents to learn from past experiences.", "method": "MAEL uses a graph-structured collaboration network where agents share and store high-reward task-solving steps. During inference, agents retrieve relevant experiences to enhance reasoning.", "result": "Experiments show MAEL achieves faster convergence and higher-quality solutions by leveraging prior experiences.", "conclusion": "MAEL enhances multi-agent collaboration by enabling cross-task learning, improving both accuracy and efficiency."}}
{"id": "2505.23727", "pdf": "https://arxiv.org/pdf/2505.23727", "abs": "https://arxiv.org/abs/2505.23727", "authors": ["Song Wang", "Gongfan Fang", "Lingdong Kong", "Xiangtai Li", "Jianyun Xu", "Sheng Yang", "Qiang Li", "Jianke Zhu", "Xinchao Wang"], "title": "PixelThink: Towards Efficient Chain-of-Pixel Reasoning", "categories": ["cs.CV", "cs.MM"], "comment": "Project Page: https://PixelThink.github.io", "summary": "Existing reasoning segmentation approaches typically fine-tune multimodal\nlarge language models (MLLMs) using image-text pairs and corresponding mask\nlabels. However, they exhibit limited generalization to out-of-distribution\nscenarios without an explicit reasoning process. Although recent efforts\nleverage reinforcement learning through group-relative policy optimization\n(GRPO) to enhance reasoning ability, they often suffer from overthinking -\nproducing uniformly verbose reasoning chains irrespective of task complexity.\nThis results in elevated computational costs and limited control over reasoning\nquality. To address this problem, we propose PixelThink, a simple yet effective\nscheme that integrates externally estimated task difficulty and internally\nmeasured model uncertainty to regulate reasoning generation within a\nreinforcement learning paradigm. The model learns to compress reasoning length\nin accordance with scene complexity and predictive confidence. To support\ncomprehensive evaluation, we introduce ReasonSeg-Diff, an extended benchmark\nwith annotated reasoning references and difficulty scores, along with a suite\nof metrics designed to assess segmentation accuracy, reasoning quality, and\nefficiency jointly. Experimental results demonstrate that the proposed approach\nimproves both reasoning efficiency and overall segmentation performance. Our\nwork contributes novel perspectives towards efficient and interpretable\nmultimodal understanding. The code and model will be publicly available.", "AI": {"tldr": "PixelThink improves reasoning efficiency in segmentation by regulating reasoning length based on task difficulty and model uncertainty, outperforming existing methods.", "motivation": "Existing methods lack generalization and suffer from overthinking, leading to inefficiency and poor control over reasoning quality.", "method": "PixelThink integrates task difficulty and model uncertainty to regulate reasoning generation within reinforcement learning.", "result": "The approach enhances reasoning efficiency and segmentation performance, validated on the ReasonSeg-Diff benchmark.", "conclusion": "PixelThink offers a novel, efficient, and interpretable solution for multimodal understanding."}}
{"id": "2505.13455", "pdf": "https://arxiv.org/pdf/2505.13455", "abs": "https://arxiv.org/abs/2505.13455", "authors": ["Von Ralph Dane Marquez Herbuela", "Yukie Nagai"], "title": "Exploring Spatiotemporal Emotional Synchrony in Dyadic Interactions: The Role of Speech Conditions in Facial and Vocal Affective Alignment", "categories": ["eess.AS", "cs.AI"], "comment": null, "summary": "Understanding how humans express and synchronize emotions across multiple\ncommunication channels particularly facial expressions and speech has\nsignificant implications for emotion recognition systems and human computer\ninteraction. Motivated by the notion that non-overlapping speech promotes\nclearer emotional coordination, while overlapping speech disrupts synchrony,\nthis study examines how these conversational dynamics shape the spatial and\ntemporal alignment of arousal and valence across facial and vocal modalities.\nUsing dyadic interactions from the IEMOCAP dataset, we extracted continuous\nemotion estimates via EmoNet (facial video) and a Wav2Vec2-based model (speech\naudio). Segments were categorized based on speech overlap, and emotional\nalignment was assessed using Pearson correlation, lag adjusted analysis, and\nDynamic Time Warping (DTW). Across analyses, non overlapping speech was\nassociated with more stable and predictable emotional synchrony than\noverlapping speech. While zero-lag correlations were low and not statistically\ndifferent, non overlapping speech showed reduced variability, especially for\narousal. Lag adjusted correlations and best-lag distributions revealed clearer,\nmore consistent temporal alignment in these segments. In contrast, overlapping\nspeech exhibited higher variability and flatter lag profiles, though DTW\nindicated unexpectedly tighter alignment suggesting distinct coordination\nstrategies. Notably, directionality patterns showed that facial expressions\nmore often preceded speech during turn-taking, while speech led during\nsimultaneous vocalizations. These findings underscore the importance of\nconversational structure in regulating emotional communication and provide new\ninsight into the spatial and temporal dynamics of multimodal affective\nalignment in real world interaction.", "AI": {"tldr": "Non-overlapping speech promotes stable emotional synchrony, while overlapping speech disrupts it, with distinct coordination strategies revealed in dyadic interactions.", "motivation": "To understand how conversational dynamics (speech overlap) affect emotional alignment across facial and vocal modalities.", "method": "Analyzed IEMOCAP dataset using EmoNet (facial) and Wav2Vec2 (speech), categorized segments by speech overlap, and assessed alignment via Pearson correlation, lag analysis, and DTW.", "result": "Non-overlapping speech showed stable synchrony; overlapping speech had higher variability but tighter DTW alignment. Facial expressions often preceded speech in turn-taking, while speech led during overlaps.", "conclusion": "Conversational structure regulates emotional communication, revealing distinct temporal and spatial dynamics in multimodal affective alignment."}}
{"id": "2505.23298", "pdf": "https://arxiv.org/pdf/2505.23298", "abs": "https://arxiv.org/abs/2505.23298", "authors": ["Xiaofeng Pan", "Jing Chen", "Haitong Zhang", "Menglin Xing", "Jiayi Wei", "Xuefeng Mu", "Zhongqian Xie"], "title": "Bridging the Gap Between Semantic and User Preference Spaces for Multi-modal Music Representation Learning", "categories": ["cs.SD", "cs.IR", "eess.AS"], "comment": "ICMR 2025", "summary": "Recent works of music representation learning mainly focus on learning\nacoustic music representations with unlabeled audios or further attempt to\nacquire multi-modal music representations with scarce annotated audio-text\npairs. They either ignore the language semantics or rely on labeled audio\ndatasets that are difficult and expensive to create. Moreover, merely modeling\nsemantic space usually fails to achieve satisfactory performance on music\nrecommendation tasks since the user preference space is ignored. In this paper,\nwe propose a novel Hierarchical Two-stage Contrastive Learning (HTCL) method\nthat models similarity from the semantic perspective to the user perspective\nhierarchically to learn a comprehensive music representation bridging the gap\nbetween semantic and user preference spaces. We devise a scalable audio encoder\nand leverage a pre-trained BERT model as the text encoder to learn audio-text\nsemantics via large-scale contrastive pre-training. Further, we explore a\nsimple yet effective way to exploit interaction data from our online music\nplatform to adapt the semantic space to user preference space via contrastive\nfine-tuning, which differs from previous works that follow the idea of\ncollaborative filtering. As a result, we obtain a powerful audio encoder that\nnot only distills language semantics from the text encoder but also models\nsimilarity in user preference space with the integrity of semantic space\npreserved. Experimental results on both music semantic and recommendation tasks\nconfirm the effectiveness of our method.", "AI": {"tldr": "The paper proposes HTCL, a method for learning comprehensive music representations by hierarchically modeling semantic and user preference spaces using contrastive learning.", "motivation": "Existing methods either ignore language semantics or rely on scarce labeled data, and fail to address user preferences in music recommendation tasks.", "method": "HTCL uses a scalable audio encoder and pre-trained BERT for text to learn audio-text semantics via contrastive pre-training, then fine-tunes with user interaction data.", "result": "The method achieves strong performance on both semantic and recommendation tasks, bridging semantic and user preference spaces.", "conclusion": "HTCL effectively integrates semantic and user preference modeling, outperforming previous approaches."}}
{"id": "2505.22787", "pdf": "https://arxiv.org/pdf/2505.22787", "abs": "https://arxiv.org/abs/2505.22787", "authors": ["Christopher Polzak", "Alejandro Lozano", "Min Woo Sun", "James Burgess", "Yuhui Zhang", "Kevin Wu", "Serena Yeung-Levy"], "title": "Can Large Language Models Match the Conclusions of Systematic Reviews?", "categories": ["cs.CL"], "comment": null, "summary": "Systematic reviews (SR), in which experts summarize and analyze evidence\nacross individual studies to provide insights on a specialized topic, are a\ncornerstone for evidence-based clinical decision-making, research, and policy.\nGiven the exponential growth of scientific articles, there is growing interest\nin using large language models (LLMs) to automate SR generation. However, the\nability of LLMs to critically assess evidence and reason across multiple\ndocuments to provide recommendations at the same proficiency as domain experts\nremains poorly characterized. We therefore ask: Can LLMs match the conclusions\nof systematic reviews written by clinical experts when given access to the same\nstudies? To explore this question, we present MedEvidence, a benchmark pairing\nfindings from 100 SRs with the studies they are based on. We benchmark 24 LLMs\non MedEvidence, including reasoning, non-reasoning, medical specialist, and\nmodels across varying sizes (from 7B-700B). Through our systematic evaluation,\nwe find that reasoning does not necessarily improve performance, larger models\ndo not consistently yield greater gains, and knowledge-based fine-tuning\ndegrades accuracy on MedEvidence. Instead, most models exhibit similar\nbehavior: performance tends to degrade as token length increases, their\nresponses show overconfidence, and, contrary to human experts, all models show\na lack of scientific skepticism toward low-quality findings. These results\nsuggest that more work is still required before LLMs can reliably match the\nobservations from expert-conducted SRs, even though these systems are already\ndeployed and being used by clinicians. We release our codebase and benchmark to\nthe broader research community to further investigate LLM-based SR systems.", "AI": {"tldr": "LLMs struggle to match expert-conducted systematic reviews (SRs) in critical assessment and reasoning, despite access to the same studies. Performance varies with model size and fine-tuning, but issues like overconfidence and lack of skepticism persist.", "motivation": "To evaluate if LLMs can replicate the conclusions of expert-conducted SRs when given the same studies, addressing the growing interest in automating SR generation.", "method": "Benchmarking 24 LLMs (varying sizes and types) on MedEvidence, a dataset pairing 100 SRs with their underlying studies, to assess reasoning, performance, and behavior.", "result": "Reasoning doesn't improve performance, larger models don't guarantee better results, and fine-tuning reduces accuracy. Models show overconfidence and lack skepticism toward low-quality findings.", "conclusion": "LLMs are not yet reliable for matching expert SRs, highlighting the need for further research despite current clinical use."}}
{"id": "2505.22789", "pdf": "https://arxiv.org/pdf/2505.22789", "abs": "https://arxiv.org/abs/2505.22789", "authors": ["Erbing Hua", "Theofilos Spyrou", "Majid Ahmadi", "Abdul Momin Syed", "Hanzhi Xun", "Laurentiu Braic", "Ewout van der Veer", "Nazek Elatab", "Anteneh Gebregiorgis", "Georgi Gaydadjiev", "Beatriz Noheda", "Said Hamdioui", "Ryoichi Ishihara", "Heba Abunahla"], "title": "PdNeuRAM: Forming-Free, Multi-Bit Pd/HfO2 ReRAM for Energy-Efficient Computing", "categories": ["cond-mat.mtrl-sci", "eess.IV"], "comment": "32 pages, 6 figures in main text and 7 figures in supporting\n  information", "summary": "Memristor technology shows great promise for energy-efficient computing, yet\nit grapples with challenges like resistance drift and inherent variability. For\nfilamentary Resistive RAM (ReRAM), one of the most investigated types of\nmemristive devices, the expensive electroforming step required to create\nconductive pathways results in increased power and area overheads and reduced\nendurance. In this study, we present novel HfO2-based forming-free ReRAM\ndevices, PdNeuRAM, that operate at low voltages, support multi-bit\nfunctionality, and display reduced variability. Through a deep understanding\nand comprehensive material characterization, we discover the key process that\nallows this unique behavior: a Pd-O-Hf configuration that capitalizes on Pd\ninnate affinity for integrating into HfO2. This structure actively facilitates\ncharge redistribution at room temperature, effectively eliminating the need for\nelectroforming. Moreover, the fabricated ReRAM device provides tunable\nresistance states for dense memory and reduces programming and reading energy\nby 43% and 73%, respectively, using spiking neural networks (SNN). This study\nreveals novel mechanistic insights and delineates a strategic roadmap for the\nrealization of power-efficient and cost-effective ReRAM devices.", "AI": {"tldr": "Novel HfO2-based forming-free ReRAM devices (PdNeuRAM) eliminate electroforming, reduce variability, and lower energy usage, enabling efficient multi-bit functionality.", "motivation": "Address challenges like resistance drift, variability, and high power/area overheads in filamentary ReRAM by developing forming-free devices.", "method": "Develop PdNeuRAM using Pd-O-Hf configuration in HfO2, leveraging Pd's affinity for HfO2 to enable charge redistribution without electroforming.", "result": "Devices operate at low voltages, reduce programming/reading energy by 43%/73%, and support multi-bit functionality with tunable resistance states.", "conclusion": "PdNeuRAM offers a power-efficient, cost-effective ReRAM solution with mechanistic insights for future device development."}}
{"id": "2505.22810", "pdf": "https://arxiv.org/pdf/2505.22810", "abs": "https://arxiv.org/abs/2505.22810", "authors": ["Zhoufaran Yang", "Yan Shu", "Zhifei Yang", "Yan Zhang", "Yu Li", "Keyang Lu", "Gangyan Zeng", "Shaohui Liu", "Yu Zhou", "Nicu Sebe"], "title": "VidText: Towards Comprehensive Evaluation for Video Text Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Visual texts embedded in videos carry rich semantic information, which is\ncrucial for both holistic video understanding and fine-grained reasoning about\nlocal human actions. However, existing video understanding benchmarks largely\noverlook textual information, while OCR-specific benchmarks are constrained to\nstatic images, limiting their ability to capture the interaction between text\nand dynamic visual contexts. To address this gap, we propose VidText, a new\nbenchmark designed for comprehensive and in-depth evaluation of video text\nunderstanding. VidText offers the following key features: 1) It covers a wide\nrange of real-world scenarios and supports multilingual content, encompassing\ndiverse settings where video text naturally appears. 2) It introduces a\nhierarchical evaluation framework with video-level, clip-level, and\ninstance-level tasks, enabling assessment of both global summarization and\nlocal retrieval capabilities. 3) The benchmark also introduces a set of paired\nperception reasoning tasks, ranging from visual text perception to cross-modal\nreasoning between textual and visual information. Extensive experiments on 18\nstate-of-the-art Large Multimodal Models (LMMs) reveal that current models\nstruggle across most tasks, with significant room for improvement. Further\nanalysis highlights the impact of both model-intrinsic factors, such as input\nresolution and OCR capability, and external factors, including the use of\nauxiliary information and Chain-of-Thought reasoning strategies. We hope\nVidText will fill the current gap in video understanding benchmarks and serve\nas a foundation for future research on multimodal reasoning with video text in\ndynamic environments.", "AI": {"tldr": "VidText is a new benchmark for video text understanding, addressing gaps in existing benchmarks by covering diverse scenarios, multilingual content, and hierarchical tasks. Current models struggle, showing room for improvement.", "motivation": "Existing benchmarks overlook video text or are limited to static images, missing dynamic text-visual interactions. VidText aims to fill this gap.", "method": "VidText introduces a hierarchical evaluation framework (video-, clip-, instance-level) and paired perception-reasoning tasks, tested on 18 LMMs.", "result": "Current models perform poorly, with model-intrinsic (e.g., OCR capability) and external factors (e.g., reasoning strategies) impacting performance.", "conclusion": "VidText fills a critical gap and provides a foundation for future research on multimodal reasoning with video text."}}
{"id": "2505.22954", "pdf": "https://arxiv.org/pdf/2505.22954", "abs": "https://arxiv.org/abs/2505.22954", "authors": ["Jenny Zhang", "Shengran Hu", "Cong Lu", "Robert Lange", "Jeff Clune"], "title": "Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents", "categories": ["cs.AI"], "comment": "Code at https://github.com/jennyzzt/dgm", "summary": "Today's AI systems have human-designed, fixed architectures and cannot\nautonomously and continuously improve themselves. The advance of AI could\nitself be automated. If done safely, that would accelerate AI development and\nallow us to reap its benefits much sooner. Meta-learning can automate the\ndiscovery of novel algorithms, but is limited by first-order improvements and\nthe human design of a suitable search space. The G\\\"odel machine proposed a\ntheoretical alternative: a self-improving AI that repeatedly modifies itself in\na provably beneficial manner. Unfortunately, proving that most changes are net\nbeneficial is impossible in practice. We introduce the Darwin G\\\"odel Machine\n(DGM), a self-improving system that iteratively modifies its own code (thereby\nalso improving its ability to modify its own codebase) and empirically\nvalidates each change using coding benchmarks. Inspired by Darwinian evolution\nand open-endedness research, the DGM maintains an archive of generated coding\nagents. It grows the archive by sampling an agent from it and using a\nfoundation model to create a new, interesting, version of the sampled agent.\nThis open-ended exploration forms a growing tree of diverse, high-quality\nagents and allows the parallel exploration of many different paths through the\nsearch space. Empirically, the DGM automatically improves its coding\ncapabilities (e.g., better code editing tools, long-context window management,\npeer-review mechanisms), increasing performance on SWE-bench from 20.0% to\n50.0%, and on Polyglot from 14.2% to 30.7%. Furthermore, the DGM significantly\noutperforms baselines without self-improvement or open-ended exploration. All\nexperiments were done with safety precautions (e.g., sandboxing, human\noversight). The DGM is a significant step toward self-improving AI, capable of\ngathering its own stepping stones along paths that unfold into endless\ninnovation.", "AI": {"tldr": "The paper introduces the Darwin G\u00f6del Machine (DGM), a self-improving AI system that autonomously modifies its code and validates changes empirically, outperforming non-self-improving baselines on coding benchmarks.", "motivation": "Current AI systems lack autonomous self-improvement capabilities, limiting their potential. Automating AI advancement could accelerate progress and benefits, but existing methods like meta-learning are constrained by human-designed search spaces.", "method": "The DGM iteratively modifies its own code, empirically validating each change using coding benchmarks. It maintains an archive of diverse coding agents, growing it through open-ended exploration inspired by Darwinian evolution.", "result": "The DGM improves coding capabilities significantly, e.g., from 20.0% to 50.0% on SWE-bench and from 14.2% to 30.7% on Polyglot, outperforming baselines without self-improvement or open-ended exploration.", "conclusion": "The DGM represents a step toward self-improving AI, capable of autonomous innovation while incorporating safety measures like sandboxing and human oversight."}}
{"id": "2505.22758", "pdf": "https://arxiv.org/pdf/2505.22758", "abs": "https://arxiv.org/abs/2505.22758", "authors": ["Aniruddha Nrusimha", "William Brandon", "Mayank Mishra", "Yikang Shen", "Rameswar Panda", "Jonathan Ragan-Kelley", "Yoon Kim"], "title": "FlashFormer: Whole-Model Kernels for Efficient Low-Batch Inference", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "The size and compute characteristics of modern large language models have led\nto an increased interest in developing specialized kernels tailored for\ntraining and inference. Existing kernels primarily optimize for compute\nutilization, targeting the large-batch training and inference settings.\nHowever, low-batch inference, where memory bandwidth and kernel launch\noverheads contribute are significant factors, remains important for many\napplications of interest such as in edge deployment and latency-sensitive\napplications. This paper describes FlashFormer, a proof-of-concept kernel for\naccelerating single-batch inference for transformer-based large language\nmodels. Across various model sizes and quantizations settings, we observe\nnontrivial speedups compared to existing state-of-the-art inference kernels.", "AI": {"tldr": "FlashFormer is a specialized kernel for low-batch inference of transformer-based LLMs, offering speedups over existing kernels.", "motivation": "Address the gap in optimizing kernels for low-batch inference, crucial for edge deployment and latency-sensitive applications.", "method": "Develops FlashFormer, a proof-of-concept kernel tailored for single-batch inference in transformer-based LLMs.", "result": "Achieves nontrivial speedups across various model sizes and quantization settings.", "conclusion": "FlashFormer demonstrates the potential for optimizing low-batch inference, benefiting edge and latency-sensitive use cases."}}
{"id": "2505.23686", "pdf": "https://arxiv.org/pdf/2505.23686", "abs": "https://arxiv.org/abs/2505.23686", "authors": ["Caroline Wang", "Arrasy Rahman", "Jiaxun Cui", "Yoonchang Sung", "Peter Stone"], "title": "ROTATE: Regret-driven Open-ended Training for Ad Hoc Teamwork", "categories": ["cs.AI", "cs.MA", "I.2.11; I.2.1; I.2.6; I.2.8"], "comment": null, "summary": "Developing AI agents capable of collaborating with previously unseen partners\nis a fundamental generalization challenge in multi-agent learning, known as Ad\nHoc Teamwork (AHT). Existing AHT approaches typically adopt a two-stage\npipeline, where first, a fixed population of teammates is generated with the\nidea that they should be representative of the teammates that will be seen at\ndeployment time, and second, an AHT agent is trained to collaborate well with\nagents in the population. To date, the research community has focused on\ndesigning separate algorithms for each stage. This separation has led to\nalgorithms that generate teammate pools with limited coverage of possible\nbehaviors, and that ignore whether the generated teammates are easy to learn\nfrom for the AHT agent. Furthermore, algorithms for training AHT agents\ntypically treat the set of training teammates as static, thus attempting to\ngeneralize to previously unseen partner agents without assuming any control\nover the distribution of training teammates. In this paper, we present a\nunified framework for AHT by reformulating the problem as an open-ended\nlearning process between an ad hoc agent and an adversarial teammate generator.\nWe introduce ROTATE, a regret-driven, open-ended training algorithm that\nalternates between improving the AHT agent and generating teammates that probe\nits deficiencies. Extensive experiments across diverse AHT environments\ndemonstrate that ROTATE significantly outperforms baselines at generalizing to\nan unseen set of evaluation teammates, thus establishing a new standard for\nrobust and generalizable teamwork.", "AI": {"tldr": "ROTATE introduces a unified, regret-driven framework for Ad Hoc Teamwork (AHT), outperforming baselines by improving agent training and teammate generation iteratively.", "motivation": "Existing AHT methods lack coverage in teammate behaviors and ignore learnability, leading to poor generalization.", "method": "ROTATE alternates between training the AHT agent and generating adversarial teammates to probe deficiencies.", "result": "ROTATE significantly outperforms baselines in generalizing to unseen teammates.", "conclusion": "ROTATE sets a new standard for robust and generalizable teamwork in AHT."}}
{"id": "2411.17690", "pdf": "https://arxiv.org/pdf/2411.17690", "abs": "https://arxiv.org/abs/2411.17690", "authors": ["Akshita Gupta", "Tatiana Likhomanenko", "Karren Dai Yang", "Richard He Bai", "Zakaria Aldeneh", "Navdeep Jaitly"], "title": "Visatronic: A Multimodal Decoder-Only Model for Speech Synthesis", "categories": ["cs.MM", "cs.CV", "cs.SD", "eess.AS"], "comment": null, "summary": "The rapid progress of foundation models and large language models (LLMs) has\nfueled significantly improvement in the capabilities of machine learning\nsystems that benefit from mutlimodal input data. However, existing multimodal\nmodels are predominantly built on top of pre-trained LLMs, which can limit\naccurate modeling of temporal dependencies across other modalities and thus\nlimit the model's ability to jointly process and leverage multimodal inputs. To\nspecifically investigate the alignment of text, video, and speech modalities in\nLLM-style (decoder-only) models, we consider a simplified multimodal generation\ntask, Video-Text to Speech (VTTS): speech generation conditioned on both its\ncorresponding text and video of talking people. The ultimate goal is to\ngenerate speech that not only follows the text but also aligns temporally with\nthe video and is consistent with the facial expressions. In this paper, we\nfirst introduce Visatronic, a unified multimodal decoder-only transformer model\nthat adopts an LLM-style architecture to embed visual, textual, and speech\ninputs into a shared subspace, treating all modalities as temporally aligned\ntoken streams. Next, we carefully explore different token mixing strategies to\nunderstand the best way to propagate information from the steps where video and\ntext conditioning is input to the steps where the audio is generated. We\nextensively evaluate Visatronic on the challenging VoxCeleb2 dataset and\ndemonstrate zero-shot generalization to LRS3, where Visatronic, trained on\nVoxCeleb2, achieves a 4.5% WER, outperforming prior SOTA methods trained only\non LRS3, which report a 21.4% WER. Additionally, we propose a new objective\nmetric, TimeSync, specifically designed to measure phoneme-level temporal\nalignment between generated and reference speech, further ensuring\nsynchronization quality. Demo: https://apple.github.io/visatronic-demo/", "AI": {"tldr": "The paper introduces Visatronic, a multimodal decoder-only transformer model for aligning text, video, and speech, achieving state-of-the-art performance in speech generation tasks.", "motivation": "Existing multimodal models built on pre-trained LLMs struggle with temporal alignment across modalities, limiting their ability to jointly process multimodal inputs.", "method": "Visatronic uses an LLM-style architecture to embed visual, textual, and speech inputs into a shared subspace, treating them as temporally aligned token streams. It explores token mixing strategies for effective information propagation.", "result": "Visatronic outperforms prior methods, achieving a 4.5% WER on LRS3 (zero-shot) compared to 21.4% WER by SOTA methods trained on LRS3. It also introduces TimeSync for phoneme-level alignment evaluation.", "conclusion": "Visatronic demonstrates superior performance in multimodal alignment and introduces a novel metric for synchronization quality, advancing the field of multimodal generation."}}
{"id": "2505.13814", "pdf": "https://arxiv.org/pdf/2505.13814", "abs": "https://arxiv.org/abs/2505.13814", "authors": ["Jihwan Lee", "Kevin Huang", "Kleanthis Avramidis", "Simon Pistrosch", "Monica Gonzalez-Machorro", "Yoonjeong Lee", "Bj\u00f6rn Schuller", "Louis Goldstein", "Shrikanth Narayanan"], "title": "Articulatory Feature Prediction from Surface EMG during Speech Production", "categories": ["eess.AS", "cs.AI", "cs.SD"], "comment": "Accepted for Interspeech2025", "summary": "We present a model for predicting articulatory features from surface\nelectromyography (EMG) signals during speech production. The proposed model\nintegrates convolutional layers and a Transformer block, followed by separate\npredictors for articulatory features. Our approach achieves a high prediction\ncorrelation of approximately 0.9 for most articulatory features. Furthermore,\nwe demonstrate that these predicted articulatory features can be decoded into\nintelligible speech waveforms. To our knowledge, this is the first method to\ndecode speech waveforms from surface EMG via articulatory features, offering a\nnovel approach to EMG-based speech synthesis. Additionally, we analyze the\nrelationship between EMG electrode placement and articulatory feature\npredictability, providing knowledge-driven insights for optimizing EMG\nelectrode configurations. The source code and decoded speech samples are\npublicly available.", "AI": {"tldr": "A model predicts articulatory features from EMG signals using convolutional layers and a Transformer, achieving high correlation (~0.9) and decoding them into intelligible speech.", "motivation": "To develop a novel EMG-based speech synthesis method by predicting articulatory features from EMG signals.", "method": "Integrates convolutional layers and a Transformer block, followed by separate predictors for articulatory features.", "result": "High prediction correlation (~0.9) for articulatory features, successfully decoded into intelligible speech waveforms.", "conclusion": "First method to decode speech from EMG via articulatory features, with insights for optimizing electrode placement."}}
{"id": "2505.23305", "pdf": "https://arxiv.org/pdf/2505.23305", "abs": "https://arxiv.org/abs/2505.23305", "authors": ["Yunkee Chae", "Kyogu Lee"], "title": "MGE-LDM: Joint Latent Diffusion for Simultaneous Music Generation and Source Extraction", "categories": ["cs.SD", "cs.LG"], "comment": "27 pages, 4 figures", "summary": "We present MGE-LDM, a unified latent diffusion framework for simultaneous\nmusic generation, source imputation, and query-driven source separation. Unlike\nprior approaches constrained to fixed instrument classes, MGE-LDM learns a\njoint distribution over full mixtures, submixtures, and individual stems within\na single compact latent diffusion model. At inference, MGE-LDM enables (1)\ncomplete mixture generation, (2) partial generation (i.e., source imputation),\nand (3) text-conditioned extraction of arbitrary sources. By formulating both\nseparation and imputation as conditional inpainting tasks in the latent space,\nour approach supports flexible, class-agnostic manipulation of arbitrary\ninstrument sources. Notably, MGE-LDM can be trained jointly across\nheterogeneous multi-track datasets (e.g., Slakh2100, MUSDB18, MoisesDB) without\nrelying on predefined instrument categories. Audio samples are available at our\nproject page: https://yoongi43.github.io/MGELDM_Samples/.", "AI": {"tldr": "MGE-LDM is a unified latent diffusion framework for music generation, source imputation, and query-driven separation, supporting flexible manipulation of arbitrary instrument sources.", "motivation": "To address limitations of prior approaches constrained to fixed instrument classes by enabling joint learning and flexible manipulation of music sources.", "method": "Uses a latent diffusion model to learn a joint distribution over mixtures, submixtures, and stems, treating separation and imputation as conditional inpainting tasks.", "result": "Enables complete mixture generation, partial generation (source imputation), and text-conditioned source extraction, trained across heterogeneous datasets.", "conclusion": "MGE-LDM offers a versatile, class-agnostic solution for music generation and manipulation, outperforming fixed-class methods."}}
{"id": "2505.22801", "pdf": "https://arxiv.org/pdf/2505.22801", "abs": "https://arxiv.org/abs/2505.22801", "authors": ["Qing Wang", "Yuepei Li", "Qiao Qiao", "Kang Zhou", "Qi Li"], "title": "Towards a More Generalized Approach in Open Relation Extraction", "categories": ["cs.CL"], "comment": "Accepted by ACL 2025 Main Conference", "summary": "Open Relation Extraction (OpenRE) seeks to identify and extract novel\nrelational facts between named entities from unlabeled data without pre-defined\nrelation schemas. Traditional OpenRE methods typically assume that the\nunlabeled data consists solely of novel relations or is pre-divided into known\nand novel instances. However, in real-world scenarios, novel relations are\narbitrarily distributed. In this paper, we propose a generalized OpenRE setting\nthat considers unlabeled data as a mixture of both known and novel instances.\nTo address this, we propose MixORE, a two-phase framework that integrates\nrelation classification and clustering to jointly learn known and novel\nrelations. Experiments on three benchmark datasets demonstrate that MixORE\nconsistently outperforms competitive baselines in known relation classification\nand novel relation clustering. Our findings contribute to the advancement of\ngeneralized OpenRE research and real-world applications.", "AI": {"tldr": "MixORE is a two-phase framework for Open Relation Extraction (OpenRE) that handles mixed known and novel relations, outperforming baselines in classification and clustering.", "motivation": "Traditional OpenRE assumes unlabeled data contains only novel relations or is pre-divided, but real-world data mixes known and novel relations arbitrarily.", "method": "MixORE integrates relation classification and clustering in two phases to jointly learn known and novel relations.", "result": "Experiments on three benchmarks show MixORE outperforms baselines in known relation classification and novel relation clustering.", "conclusion": "MixORE advances generalized OpenRE research and is applicable to real-world scenarios."}}
{"id": "2505.23085", "pdf": "https://arxiv.org/pdf/2505.23085", "abs": "https://arxiv.org/abs/2505.23085", "authors": ["Gwanghyun Kim", "Xueting Li", "Ye Yuan", "Koki Nagano", "Tianye Li", "Jan Kautz", "Se Young Chun", "Umar Iqbal"], "title": "GeoMan: Temporally Consistent Human Geometry Estimation using Image-to-Video Diffusion", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": "Project page: https://research.nvidia.com/labs/dair/geoman", "summary": "Estimating accurate and temporally consistent 3D human geometry from videos\nis a challenging problem in computer vision. Existing methods, primarily\noptimized for single images, often suffer from temporal inconsistencies and\nfail to capture fine-grained dynamic details. To address these limitations, we\npresent GeoMan, a novel architecture designed to produce accurate and\ntemporally consistent depth and normal estimations from monocular human videos.\nGeoMan addresses two key challenges: the scarcity of high-quality 4D training\ndata and the need for metric depth estimation to accurately model human size.\nTo overcome the first challenge, GeoMan employs an image-based model to\nestimate depth and normals for the first frame of a video, which then\nconditions a video diffusion model, reframing video geometry estimation task as\nan image-to-video generation problem. This design offloads the heavy lifting of\ngeometric estimation to the image model and simplifies the video model's role\nto focus on intricate details while using priors learned from large-scale video\ndatasets. Consequently, GeoMan improves temporal consistency and\ngeneralizability while requiring minimal 4D training data. To address the\nchallenge of accurate human size estimation, we introduce a root-relative depth\nrepresentation that retains critical human-scale details and is easier to be\nestimated from monocular inputs, overcoming the limitations of traditional\naffine-invariant and metric depth representations. GeoMan achieves\nstate-of-the-art performance in both qualitative and quantitative evaluations,\ndemonstrating its effectiveness in overcoming longstanding challenges in 3D\nhuman geometry estimation from videos.", "AI": {"tldr": "GeoMan is a novel architecture for accurate, temporally consistent 3D human geometry estimation from monocular videos, addressing data scarcity and metric depth challenges.", "motivation": "Existing methods for 3D human geometry from videos suffer from temporal inconsistencies and lack fine-grained details, prompting the need for a better solution.", "method": "GeoMan combines an image-based model for initial depth/normal estimation with a video diffusion model, simplifying the task as image-to-video generation. It uses root-relative depth for accurate human size.", "result": "GeoMan achieves state-of-the-art performance, improving temporal consistency and generalizability with minimal 4D training data.", "conclusion": "GeoMan effectively addresses key challenges in 3D human geometry estimation, offering superior accuracy and consistency."}}
{"id": "2505.22815", "pdf": "https://arxiv.org/pdf/2505.22815", "abs": "https://arxiv.org/abs/2505.22815", "authors": ["Zhangyi Hu", "Jiemin Wu", "Hua Xu", "Mingqian Liao", "Ninghui Feng", "Bo Gao", "Songning Lai", "Yutao Yue"], "title": "IMTS is Worth Time $\\times$ Channel Patches: Visual Masked Autoencoders for Irregular Multivariate Time Series Prediction", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "ICML 2025", "summary": "Irregular Multivariate Time Series (IMTS) forecasting is challenging due to\nthe unaligned nature of multi-channel signals and the prevalence of extensive\nmissing data. Existing methods struggle to capture reliable temporal patterns\nfrom such data due to significant missing values. While pre-trained foundation\nmodels show potential for addressing these challenges, they are typically\ndesigned for Regularly Sampled Time Series (RTS). Motivated by the visual Mask\nAutoEncoder's (MAE) powerful capability for modeling sparse multi-channel\ninformation and its success in RTS forecasting, we propose VIMTS, a framework\nadapting Visual MAE for IMTS forecasting. To mitigate the effect of missing\nvalues, VIMTS first processes IMTS along the timeline into feature patches at\nequal intervals. These patches are then complemented using learned\ncross-channel dependencies. Then it leverages visual MAE's capability in\nhandling sparse multichannel data for patch reconstruction, followed by a\ncoarse-to-fine technique to generate precise predictions from focused contexts.\nIn addition, we integrate self-supervised learning for improved IMTS modeling\nby adapting the visual MAE to IMTS data. Extensive experiments demonstrate\nVIMTS's superior performance and few-shot capability, advancing the application\nof visual foundation models in more general time series tasks. Our code is\navailable at https://github.com/WHU-HZY/VIMTS.", "AI": {"tldr": "VIMTS adapts Visual MAE for Irregular Multivariate Time Series (IMTS) forecasting, handling missing data and leveraging cross-channel dependencies for accurate predictions.", "motivation": "Existing methods struggle with IMTS due to unaligned signals and missing data, while foundation models are designed for regular time series.", "method": "VIMTS processes IMTS into feature patches, uses cross-channel dependencies, and applies Visual MAE for reconstruction and prediction.", "result": "VIMTS outperforms existing methods and shows few-shot capability.", "conclusion": "VIMTS advances visual foundation models for general time series tasks."}}
{"id": "2505.22960", "pdf": "https://arxiv.org/pdf/2505.22960", "abs": "https://arxiv.org/abs/2505.22960", "authors": ["Yongjin Yang", "Euiin Yi", "Jongwoo Ko", "Kimin Lee", "Zhijing Jin", "Se-Young Yun"], "title": "Revisiting Multi-Agent Debate as Test-Time Scaling: A Systematic Study of Conditional Effectiveness", "categories": ["cs.AI", "cs.LG"], "comment": "Preprint, under review", "summary": "The remarkable growth in large language model (LLM) capabilities has spurred\nexploration into multi-agent systems, with debate frameworks emerging as a\npromising avenue for enhanced problem-solving. These multi-agent debate (MAD)\napproaches, where agents collaboratively present, critique, and refine\narguments, potentially offer improved reasoning, robustness, and diverse\nperspectives over monolithic models. Despite prior studies leveraging MAD, a\nsystematic understanding of its effectiveness compared to self-agent methods,\nparticularly under varying conditions, remains elusive. This paper seeks to\nfill this gap by conceptualizing MAD as a test-time computational scaling\ntechnique, distinguished by collaborative refinement and diverse exploration\ncapabilities. We conduct a comprehensive empirical investigation comparing MAD\nwith strong self-agent test-time scaling baselines on mathematical reasoning\nand safety-related tasks. Our study systematically examines the influence of\ntask difficulty, model scale, and agent diversity on MAD's performance. Key\nfindings reveal that, for mathematical reasoning, MAD offers limited advantages\nover self-agent scaling but becomes more effective with increased problem\ndifficulty and decreased model capability, while agent diversity shows little\nbenefit. Conversely, for safety tasks, MAD's collaborative refinement can\nincrease vulnerability, but incorporating diverse agent configurations\nfacilitates a gradual reduction in attack success through the collaborative\nrefinement process. We believe our findings provide critical guidance for the\nfuture development of more effective and strategically deployed MAD systems.", "AI": {"tldr": "Multi-agent debate (MAD) is explored as a test-time scaling technique, showing limited benefits for math tasks but potential risks and benefits for safety tasks, depending on conditions like problem difficulty and model capability.", "motivation": "To systematically understand MAD's effectiveness compared to self-agent methods under varying conditions, filling a gap in prior research.", "method": "Conceptualizes MAD as a test-time computational scaling technique and conducts empirical comparisons on mathematical reasoning and safety tasks, examining factors like task difficulty, model scale, and agent diversity.", "result": "MAD offers limited advantages for math tasks but becomes more effective with harder problems or weaker models. For safety tasks, MAD can increase vulnerability but reduces attack success with diverse agent configurations.", "conclusion": "The findings guide future MAD system development, highlighting context-dependent effectiveness and strategic deployment needs."}}
{"id": "2505.22764", "pdf": "https://arxiv.org/pdf/2505.22764", "abs": "https://arxiv.org/abs/2505.22764", "authors": ["Divya Shanmugam", "Helen Lu", "Swami Sankaranarayanan", "John Guttag"], "title": "Test-time augmentation improves efficiency in conformal prediction", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "A conformal classifier produces a set of predicted classes and provides a\nprobabilistic guarantee that the set includes the true class. Unfortunately, it\nis often the case that conformal classifiers produce uninformatively large\nsets. In this work, we show that test-time augmentation (TTA)--a technique that\nintroduces inductive biases during inference--reduces the size of the sets\nproduced by conformal classifiers. Our approach is flexible, computationally\nefficient, and effective. It can be combined with any conformal score, requires\nno model retraining, and reduces prediction set sizes by 10%-14% on average. We\nconduct an evaluation of the approach spanning three datasets, three models,\ntwo established conformal scoring methods, different guarantee strengths, and\nseveral distribution shifts to show when and why test-time augmentation is a\nuseful addition to the conformal pipeline.", "AI": {"tldr": "Test-time augmentation (TTA) reduces the size of prediction sets in conformal classifiers by 10%-14% on average, without requiring model retraining.", "motivation": "Conformal classifiers often produce large, uninformative prediction sets, limiting their practical utility.", "method": "The paper introduces TTA, a technique that applies inductive biases during inference, to reduce prediction set sizes. It is flexible, works with any conformal score, and doesn't need model retraining.", "result": "TTA reduces prediction set sizes by 10%-14% on average across three datasets, three models, and various conditions.", "conclusion": "TTA is a computationally efficient and effective addition to the conformal pipeline, improving the informativeness of prediction sets."}}
{"id": "2408.09955", "pdf": "https://arxiv.org/pdf/2408.09955", "abs": "https://arxiv.org/abs/2408.09955", "authors": ["Qian Wang", "Tianyu Wang", "Zhenheng Tang", "Qinbin Li", "Nuo Chen", "Jingsheng Liang", "Bingsheng He"], "title": "MegaAgent: A Large-Scale Autonomous LLM-based Multi-Agent System Without Predefined SOPs", "categories": ["cs.MA"], "comment": null, "summary": "LLM-based multi-agent systems (MAS) have shown promise in tackling complex\ntasks. However, existing solutions often suffer from limited agent coordination\nand heavy reliance on predefined Standard Operating Procedures (SOPs), which\ndemand extensive human input. To address these limitations, we propose\nMegaAgent, a large-scale autonomous LLM-based multi-agent system. MegaAgent\ngenerates agents based on task complexity and enables dynamic task\ndecomposition, parallel execution, efficient communication, and comprehensive\nsystem monitoring of agents. In evaluations, MegaAgent demonstrates exceptional\nperformance, successfully developing a Gobang game within 800 seconds and\nscaling up to 590 agents in a national policy simulation to generate\nmulti-domain policies. It significantly outperforms existing systems, such as\nMetaGPT, in both task completion efficiency and scalability. By eliminating the\nneed for predefined SOPs, MegaAgent demonstrates exceptional scalability and\nautonomy, setting a foundation for advancing true autonomy in MAS. Our code is\navailable at https://github.com/Xtra-Computing/MegaAgent .", "AI": {"tldr": "MegaAgent is a scalable, autonomous LLM-based multi-agent system that outperforms existing solutions by enabling dynamic task decomposition, parallel execution, and efficient communication without predefined SOPs.", "motivation": "Existing LLM-based multi-agent systems face limitations in coordination and reliance on predefined SOPs, requiring extensive human input.", "method": "MegaAgent generates agents based on task complexity, supports dynamic task decomposition, parallel execution, and comprehensive monitoring.", "result": "MegaAgent developed a Gobang game in 800 seconds and scaled to 590 agents for policy simulation, outperforming MetaGPT in efficiency and scalability.", "conclusion": "MegaAgent advances true autonomy in MAS by eliminating predefined SOPs, showcasing exceptional scalability and performance."}}
{"id": "2503.01879", "pdf": "https://arxiv.org/pdf/2503.01879", "abs": "https://arxiv.org/abs/2503.01879", "authors": ["Che Liu", "Yingji Zhang", "Dong Zhang", "Weijie Zhang", "Chenggong Gong", "Haohan Li", "Yu Lu", "Shilin Zhou", "Yue Lu", "Ziliang Gan", "Ziao Wang", "Junwei Liao", "Haipang Wu", "Ji Liu", "Andr\u00e9 Freitas", "Qifan Wang", "Zenglin Xu", "Rongjuncheng Zhang", "Yong Dai"], "title": "Nexus: An Omni-Perceptive And -Interactive Model for Language, Audio, And Vision", "categories": ["cs.MM", "cs.CV", "cs.SD", "eess.AS"], "comment": null, "summary": "This work proposes an industry-level omni-modal large language model (LLM)\npipeline that integrates auditory, visual, and linguistic modalities to\novercome challenges such as limited tri-modal datasets, high computational\ncosts, and complex feature alignments. Our pipeline consists of three main\ncomponents: First, a modular framework enabling flexible configuration of\nvarious encoder-LLM-decoder architectures. Second, a lightweight training\nstrategy that pre-trains audio-language alignment on the state-of-the-art\nvision-language model Qwen2.5-VL, thus avoiding the costly pre-training of\nvision-specific modalities. Third, an audio synthesis pipeline that generates\nhigh-quality audio-text data from diverse real-world scenarios, supporting\napplications such as Automatic Speech Recognition and Speech-to-Speech chat. To\nthis end, we introduce an industry-level omni-modal LLM, Nexus. Extensive\nexperiments validate the efficacy of our pipeline, yielding the following key\nfindings:(1) In the visual understanding task, Nexus exhibits superior\nperformance compared with its backbone model - Qwen2.5-VL-7B, validating the\nefficiency of our training strategy. (2) Within the English Spoken\nQuestion-Answering task, the model achieves better accuracy than the\nsame-period competitor (i.e, MiniCPM-o2.6-7B) in the LLaMA Q. benchmark. (3) In\nour real-world ASR testset, Nexus achieves outstanding performance, indicating\nits robustness in real scenarios. (4) In the Speech-to-Text Translation task,\nour model outperforms Qwen2-Audio-Instruct-7B. (5) In the Text-to-Speech task,\nbased on pretrained vocoder (e.g., Fishspeech1.4 or CosyVoice2.0), Nexus is\ncomparable to its backbone vocoder on Seed-TTS benchmark. (6) An in-depth\nanalysis of tri-modal alignment reveals that incorporating the audio modality\nenhances representational alignment between vision and language.", "AI": {"tldr": "The paper introduces Nexus, an omni-modal LLM pipeline integrating auditory, visual, and linguistic modalities, addressing challenges like limited datasets and high costs. It features a modular framework, lightweight training, and audio synthesis, achieving superior performance in tasks like visual understanding, speech QA, ASR, and translation.", "motivation": "To overcome limitations in tri-modal datasets, computational costs, and feature alignment, the authors propose an industry-level omni-modal LLM pipeline integrating auditory, visual, and linguistic modalities.", "method": "The pipeline includes a modular framework for flexible architecture configuration, lightweight training leveraging Qwen2.5-VL, and an audio synthesis pipeline for generating high-quality data.", "result": "Nexus outperforms competitors in visual understanding, English Spoken QA, ASR, speech-to-text translation, and matches backbone vocoders in text-to-speech tasks, demonstrating robust performance.", "conclusion": "The proposed pipeline effectively integrates multiple modalities, enhancing alignment and performance across diverse tasks, validating its industry-level applicability."}}
{"id": "2505.21527", "pdf": "https://arxiv.org/pdf/2505.21527", "abs": "https://arxiv.org/abs/2505.21527", "authors": ["Jianheng Zhuo", "Yifan Yang", "Yiwen Shao", "Yong Xu", "Dong Yu", "Kai Yu", "Xie Chen"], "title": "VietASR: Achieving Industry-level Vietnamese ASR with 50-hour labeled data and Large-Scale Speech Pretraining", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "comment": null, "summary": "Automatic speech recognition (ASR) has made remarkable progress but heavily\nrelies on large-scale labeled data, which is scarce for low-resource languages\nlike Vietnamese. While existing systems such as Whisper, USM, and MMS achieve\npromising performance, their efficacy remains inadequate in terms of training\ncosts, latency, and accessibility. To address these issues, we propose VietASR,\na novel ASR training pipeline that leverages vast amounts of unlabeled data and\na small set of labeled data. Through multi-iteration ASR-biased self-supervised\nlearning on a large-scale unlabeled dataset, VietASR offers a cost-effective\nand practical solution for enhancing ASR performance. Experiments demonstrate\nthat pre-training on 70,000-hour unlabeled data and fine-tuning on merely\n50-hour labeled data yield a lightweight but powerful ASR model. It outperforms\nWhisper Large-v3 and commercial ASR systems on real-world data. Our code and\nmodels will be open-sourced to facilitate research in low-resource ASR.", "AI": {"tldr": "VietASR is a cost-effective ASR pipeline for low-resource languages like Vietnamese, using self-supervised learning on unlabeled data and minimal labeled data to outperform existing systems.", "motivation": "Addressing the scarcity of labeled data and high training costs for ASR in low-resource languages like Vietnamese.", "method": "Multi-iteration ASR-biased self-supervised learning on large unlabeled datasets, followed by fine-tuning with minimal labeled data.", "result": "VietASR outperforms Whisper Large-v3 and commercial ASR systems using only 70,000h unlabeled and 50h labeled data.", "conclusion": "VietASR provides a practical, high-performance solution for low-resource ASR, with open-sourced code and models to aid research."}}
{"id": "2505.23339", "pdf": "https://arxiv.org/pdf/2505.23339", "abs": "https://arxiv.org/abs/2505.23339", "authors": ["Maya Dewhurst", "Jack Collins", "Justin J. H. Lo", "Roy Alderton", "Sam Kirkham"], "title": "Nosey: Open-source hardware for acoustic nasalance", "categories": ["cs.SD", "cs.CL"], "comment": "Accepted to Interspeech 2025", "summary": "We introduce Nosey (Nasalance Open Source Estimation sYstem), a low-cost,\ncustomizable, 3D-printed system for recording acoustic nasalance data that we\nhave made available as open-source hardware\n(http://github.com/phoneticslab/nosey). We first outline the motivations and\ndesign principles behind our hardware nasalance system, and then present a\ncomparison between Nosey and a commercial nasalance device. Nosey shows\nconsistently higher nasalance scores than the commercial device, but the\nmagnitude of contrast between phonological environments is comparable between\nsystems. We also review ways of customizing the hardware to facilitate testing,\nsuch as comparison of microphones and different construction materials. We\nconclude that Nosey is a flexible and cost-effective alternative to commercial\nnasometry devices and propose some methodological considerations for its use in\ndata collection.", "AI": {"tldr": "Nosey is a low-cost, open-source, 3D-printed nasalance recording system, showing comparable performance to commercial devices but with higher nasalance scores.", "motivation": "To provide a flexible, cost-effective alternative to commercial nasalance devices for acoustic nasalance data recording.", "method": "Developed a customizable, 3D-printed hardware system (Nosey) and compared it with a commercial nasalance device.", "result": "Nosey yields higher nasalance scores but maintains comparable contrast between phonological environments. It allows customization for testing.", "conclusion": "Nosey is a viable, cost-effective alternative to commercial devices, with recommendations for its use in data collection."}}
{"id": "2505.22809", "pdf": "https://arxiv.org/pdf/2505.22809", "abs": "https://arxiv.org/abs/2505.22809", "authors": ["Andrew Zhu", "Evan Osgood", "Chris Callison-Burch"], "title": "First Steps Towards Overhearing LLM Agents: A Case Study With Dungeons & Dragons Gameplay", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "8 pages, 5 figures. In submission at EMNLP 2025", "summary": "Much work has been done on conversational LLM agents which directly assist\nhuman users with tasks. We present an alternative paradigm for interacting with\nLLM agents, which we call \"overhearing agents\". These overhearing agents do not\nactively participate in conversation -- instead, they \"listen in\" on\nhuman-to-human conversations and perform background tasks or provide\nsuggestions to assist the user. In this work, we explore the overhearing agents\nparadigm through the lens of Dungeons & Dragons gameplay. We present an\nin-depth study using large multimodal audio-language models as overhearing\nagents to assist a Dungeon Master. We perform a human evaluation to examine the\nhelpfulness of such agents and find that some large audio-language models have\nthe emergent ability to perform overhearing agent tasks using implicit audio\ncues. Finally, we release Python libraries and our project code to support\nfurther research into the overhearing agents paradigm at\nhttps://github.com/zhudotexe/overhearing_agents.", "AI": {"tldr": "The paper introduces \"overhearing agents,\" LLM agents that assist users by listening to human conversations without active participation, demonstrated in Dungeons & Dragons gameplay.", "motivation": "To explore an alternative interaction paradigm for LLM agents, focusing on passive assistance through \"overhearing\" human conversations.", "method": "Utilized large multimodal audio-language models as overhearing agents in Dungeons & Dragons, conducting human evaluations to assess their helpfulness.", "result": "Found that some models can perform overhearing tasks using implicit audio cues, demonstrating emergent abilities.", "conclusion": "The study validates the feasibility of overhearing agents, releasing tools for further research."}}
{"id": "2505.23594", "pdf": "https://arxiv.org/pdf/2505.23594", "abs": "https://arxiv.org/abs/2505.23594", "authors": ["Xi Chen", "Soham Jana", "Christopher A. Metzler", "Arian Maleki", "Shirin Jalali"], "title": "Multilook Coherent Imaging: Theoretical Guarantees and Algorithms", "categories": ["stat.ML", "cs.LG", "eess.IV"], "comment": "29 pages, 4 figures, 3 tables. arXiv admin note: substantial text\n  overlap with arXiv:2402.15635", "summary": "Multilook coherent imaging is a widely used technique in applications such as\ndigital holography, ultrasound imaging, and synthetic aperture radar. A central\nchallenge in these systems is the presence of multiplicative noise, commonly\nknown as speckle, which degrades image quality. Despite the widespread use of\ncoherent imaging systems, their theoretical foundations remain relatively\nunderexplored. In this paper, we study both the theoretical and algorithmic\naspects of likelihood-based approaches for multilook coherent imaging,\nproviding a rigorous framework for analysis and method development. Our\ntheoretical contributions include establishing the first theoretical upper\nbound on the Mean Squared Error (MSE) of the maximum likelihood estimator under\nthe deep image prior hypothesis. Our results capture the dependence of MSE on\nthe number of parameters in the deep image prior, the number of looks, the\nsignal dimension, and the number of measurements per look. On the algorithmic\nside, we employ projected gradient descent (PGD) as an efficient method for\ncomputing the maximum likelihood solution. Furthermore, we introduce two key\nideas to enhance the practical performance of PGD. First, we incorporate the\nNewton-Schulz algorithm to compute matrix inverses within the PGD iterations,\nsignificantly reducing computational complexity. Second, we develop a bagging\nstrategy to mitigate projection errors introduced during PGD updates. We\ndemonstrate that combining these techniques with PGD yields state-of-the-art\nperformance. Our code is available at\nhttps://github.com/Computational-Imaging-RU/Bagged-DIP-Speckle.", "AI": {"tldr": "The paper explores likelihood-based approaches for multilook coherent imaging, providing theoretical bounds on MSE and algorithmic improvements using PGD with Newton-Schulz and bagging.", "motivation": "Addressing the challenge of speckle noise in coherent imaging systems and the lack of theoretical foundations for such systems.", "method": "Uses projected gradient descent (PGD) with Newton-Schulz for matrix inverses and a bagging strategy to reduce errors.", "result": "Establishes theoretical MSE bounds and achieves state-of-the-art performance with the proposed algorithm.", "conclusion": "The framework and algorithmic enhancements significantly improve multilook coherent imaging, with practical code available."}}
{"id": "2505.22850", "pdf": "https://arxiv.org/pdf/2505.22850", "abs": "https://arxiv.org/abs/2505.22850", "authors": ["Kostas Triaridis", "Panagiotis Kaliosis", "E-Ro Nguyen", "Jingyi Xu", "Hieu Le", "Dimitris Samaras"], "title": "Improving Contrastive Learning for Referring Expression Counting", "categories": ["cs.CV"], "comment": "9 pages, 4 figures", "summary": "Object counting has progressed from class-specific models, which count only\nknown categories, to class-agnostic models that generalize to unseen\ncategories. The next challenge is Referring Expression Counting (REC), where\nthe goal is to count objects based on fine-grained attributes and contextual\ndifferences. Existing methods struggle with distinguishing visually similar\nobjects that belong to the same category but correspond to different referring\nexpressions. To address this, we propose C-REX, a novel contrastive learning\nframework, based on supervised contrastive learning, designed to enhance\ndiscriminative representation learning. Unlike prior works, C-REX operates\nentirely within the image space, avoiding the misalignment issues of image-text\ncontrastive learning, thus providing a more stable contrastive signal. It also\nguarantees a significantly larger pool of negative samples, leading to improved\nrobustness in the learned representations. Moreover, we showcase that our\nframework is versatile and generic enough to be applied to other similar tasks\nlike class-agnostic counting. To support our approach, we analyze the key\ncomponents of sota detection-based models and identify that detecting object\ncentroids instead of bounding boxes is the key common factor behind their\nsuccess in counting tasks. We use this insight to design a simple yet effective\ndetection-based baseline to build upon. Our experiments show that C-REX\nachieves state-of-the-art results in REC, outperforming previous methods by\nmore than 22\\% in MAE and more than 10\\% in RMSE, while also demonstrating\nstrong performance in class-agnostic counting. Code is available at\nhttps://github.com/cvlab-stonybrook/c-rex.", "AI": {"tldr": "C-REX is a contrastive learning framework for Referring Expression Counting (REC), addressing challenges in distinguishing visually similar objects. It outperforms prior methods by 22% in MAE and 10% in RMSE.", "motivation": "Existing methods struggle with fine-grained REC tasks due to misalignment in image-text contrastive learning and limited negative samples.", "method": "Proposes C-REX, a supervised contrastive learning framework operating in image space, ensuring stable signals and larger negative sample pools.", "result": "Achieves state-of-the-art REC performance (22% MAE, 10% RMSE improvement) and strong class-agnostic counting results.", "conclusion": "C-REX is effective for REC and adaptable to similar tasks, with insights on centroid detection enhancing counting models."}}
{"id": "2505.22987", "pdf": "https://arxiv.org/pdf/2505.22987", "abs": "https://arxiv.org/abs/2505.22987", "authors": ["Nick Byrd"], "title": "Strategic Reflectivism In Intelligent Systems", "categories": ["cs.AI", "cs.HC", "econ.TH", "C.1.3; I.2.0; I.2.8; I.2.11"], "comment": "An earlier version of this paper was presented at the 2025 ACM\n  Workshop on Human-AI Interaction for Augmented Reasoning\n  (CHI25-WS-AUGMENTED-REASONING). Permission to copy for educational use is\n  granted, provided copies are not for sale or profit and include this notice\n  and full citation on the first page. Other uses require the author permission", "summary": "By late 20th century, the rationality wars had launched debates about the\nnature and norms of intuitive and reflective thinking. Those debates drew from\nmid-20th century ideas such as bounded rationality, which challenged more\nidealized notions of rationality observed since the 19th century. Now that 21st\ncentury cognitive scientists are applying the resulting dual process theories\nto artificial intelligence, it is time to dust off some lessons from this\nhistory. So this paper synthesizes old ideas with recent results from\nexperiments on humans and machines. The result is Strategic Reflectivism, which\ntakes the position that one key to intelligent systems (human or artificial) is\npragmatic switching between intuitive and reflective inference to optimally\nfulfill competing goals. Strategic Reflectivism builds on American Pragmatism,\ntranscends superficial indicators of reflective thinking such as model size or\nchains of thought, and becomes increasingly actionable as we learn more about\nthe value of intuition and reflection.", "AI": {"tldr": "The paper synthesizes historical debates on rationality with modern cognitive science to propose Strategic Reflectivism, emphasizing pragmatic switching between intuitive and reflective thinking for intelligent systems.", "motivation": "The paper aims to bridge historical debates on rationality (e.g., bounded rationality) with contemporary applications in AI, highlighting the importance of integrating intuitive and reflective processes.", "method": "It combines historical analysis with recent experimental results from human and machine cognition to develop Strategic Reflectivism.", "result": "Strategic Reflectivism emerges as a framework advocating for pragmatic switching between intuitive and reflective inference to optimize goal fulfillment.", "conclusion": "The paper concludes that Strategic Reflectivism, rooted in American Pragmatism, offers actionable insights for designing intelligent systems by valuing both intuition and reflection."}}
{"id": "2505.22768", "pdf": "https://arxiv.org/pdf/2505.22768", "abs": "https://arxiv.org/abs/2505.22768", "authors": ["Mert Onur Cakiroglu", "Idil Bilge Altun", "Hasan Kurban", "Elham Buxton", "Mehmet Dalkilic"], "title": "Multivariate de Bruijn Graphs: A Symbolic Graph Framework for Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Time series forecasting remains a challenging task for foundation models due\nto temporal heterogeneity, high dimensionality, and the lack of inherent\nsymbolic structure. In this work, we propose DRAGON (Discrete Representation\nand Augmented Graph encoding Over deBruijN Graphs), a novel encoder that\nintroduces Multivariate de Bruijn Graphs (MdBGs) to bridge the gap between\nsymbolic representations and neural modeling. DRAGON discretizes continuous\ninput sequences and maps them onto a fixed graph structure, enabling dynamic\ncontext recovery via graph-based attention. Integrated as an auxiliary module\nwithin a dual-branch architecture, DRAGON augments conventional CNN-based\nencoders with symbolic, structure-aware representations. All code developed for\nthis study is available at:\nhttps://github.com/KurbanIntelligenceLab/MultdBG-Time-Series-Library", "AI": {"tldr": "DRAGON introduces Multivariate de Bruijn Graphs (MdBGs) to enhance time series forecasting by combining symbolic representations with neural modeling.", "motivation": "Addressing challenges like temporal heterogeneity and high dimensionality in time series forecasting by bridging symbolic and neural approaches.", "method": "Discretizes continuous sequences, maps them to MdBGs, and uses graph-based attention for dynamic context recovery within a dual-branch architecture.", "result": "Enhances CNN-based encoders with symbolic, structure-aware representations.", "conclusion": "DRAGON effectively integrates symbolic and neural methods for improved time series forecasting."}}
{"id": "2410.08948", "pdf": "https://arxiv.org/pdf/2410.08948", "abs": "https://arxiv.org/abs/2410.08948", "authors": ["Ariel Flint Ashery", "Luca Maria Aiello", "Andrea Baronchelli"], "title": "Emergent social conventions and collective bias in LLM populations", "categories": ["cs.MA", "cs.AI", "cs.CY", "physics.soc-ph"], "comment": null, "summary": "Social conventions are the backbone of social coordination, shaping how\nindividuals form a group. As growing populations of artificial intelligence\n(AI) agents communicate through natural language, a fundamental question is\nwhether they can bootstrap the foundations of a society. Here, we present\nexperimental results that demonstrate the spontaneous emergence of universally\nadopted social conventions in decentralized populations of large language model\n(LLM) agents. We then show how strong collective biases can emerge during this\nprocess, even when agents exhibit no bias individually. Last, we examine how\ncommitted minority groups of adversarial LLM agents can drive social change by\nimposing alternative social conventions on the larger population. Our results\nshow that AI systems can autonomously develop social conventions without\nexplicit programming and have implications for designing AI systems that align,\nand remain aligned, with human values and societal goals.", "AI": {"tldr": "AI agents can autonomously form social conventions, exhibit collective biases, and be influenced by adversarial minorities, showing potential for AI societies.", "motivation": "To explore whether AI agents can bootstrap social conventions and how biases or adversarial groups influence these conventions.", "method": "Experimental study using decentralized populations of large language model (LLM) agents to observe emergent social conventions.", "result": "Spontaneous emergence of universally adopted conventions, collective biases, and influence of adversarial minorities on social change.", "conclusion": "AI can autonomously develop social conventions, highlighting implications for aligning AI with human values and societal goals."}}
{"id": "2404.03161", "pdf": "https://arxiv.org/pdf/2404.03161", "abs": "https://arxiv.org/abs/2404.03161", "authors": ["Tomohiro Nishimoto", "Taichi Nishimura", "Koki Yamamoto", "Keisuke Shirai", "Hirotaka Kameko", "Yuto Haneji", "Tomoya Yoshida", "Keiya Kajimura", "Taiyu Cui", "Chihiro Nishiwaki", "Eriko Daikoku", "Natsuko Okuda", "Fumihito Ono", "Shinsuke Mori"], "title": "BioVL-QR: Egocentric Biochemical Vision-and-Language Dataset Using Micro QR Codes", "categories": ["cs.CV", "cs.CL", "cs.MM"], "comment": "ICIP2025", "summary": "This paper introduces BioVL-QR, a biochemical vision-and-language dataset\ncomprising 23 egocentric experiment videos, corresponding protocols, and\nvision-and-language alignments. A major challenge in understanding biochemical\nvideos is detecting equipment, reagents, and containers because of the\ncluttered environment and indistinguishable objects. Previous studies assumed\nmanual object annotation, which is costly and time-consuming. To address the\nissue, we focus on Micro QR Codes. However, detecting objects using only Micro\nQR Codes is still difficult due to blur and occlusion caused by object\nmanipulation. To overcome this, we propose an object labeling method combining\na Micro QR Code detector with an off-the-shelf hand object detector. As an\napplication of the method and BioVL-QR, we tackled the task of localizing the\nprocedural steps in an instructional video. The experimental results show that\nusing Micro QR Codes and our method improves biochemical video understanding.\nData and code are available through https://nishi10mo.github.io/BioVL-QR/", "AI": {"tldr": "BioVL-QR is a new dataset for biochemical vision-and-language tasks, using Micro QR Codes and hand-object detection to improve object labeling in cluttered environments.", "motivation": "Understanding biochemical videos is challenging due to cluttered environments and indistinguishable objects. Manual annotation is costly, so an automated solution is needed.", "method": "Combines Micro QR Code detection with an off-the-shelf hand-object detector to label objects. Applied to localize procedural steps in instructional videos.", "result": "The method improves biochemical video understanding by leveraging Micro QR Codes and hand-object detection.", "conclusion": "BioVL-QR and the proposed method offer a practical solution for automated object labeling in biochemical videos."}}
{"id": "2403.03947", "pdf": "https://arxiv.org/pdf/2403.03947", "abs": "https://arxiv.org/abs/2403.03947", "authors": ["Pedro Ramoneda", "Minhee Lee", "Dasaem Jeong", "J. J. Valero-Mas", "Xavier Serra"], "title": "Can Audio Reveal Music Performance Difficulty? Insights from the Piano Syllabus Dataset", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Automatically estimating the performance difficulty of a music piece\nrepresents a key process in music education to create tailored curricula\naccording to the individual needs of the students. Given its relevance, the\nMusic Information Retrieval (MIR) field depicts some proof-of-concept works\naddressing this task that mainly focuses on high-level music abstractions such\nas machine-readable scores or music sheet images. In this regard, the potential\nof directly analyzing audio recordings has been generally neglected, which\nprevents students from exploring diverse music pieces that may not have a\nformal symbolic-level transcription. This work pioneers in the automatic\nestimation of performance difficulty of music pieces on audio recordings with\ntwo precise contributions: (i) the first audio-based difficulty estimation\ndataset -- namely, Piano Syllabus (PSyllabus) dataset -- featuring 7,901 piano\npieces across 11 difficulty levels from 1,233 composers; and (ii) a recognition\nframework capable of managing different input representations -- both unimodal\nand multimodal manners -- directly derived from audio to perform the difficulty\nestimation task. The comprehensive experimentation comprising different\npre-training schemes, input modalities, and multi-task scenarios prove the\nvalidity of the proposal and establishes PSyllabus as a reference dataset for\naudio-based difficulty estimation in the MIR field. The dataset as well as the\ndeveloped code and trained models are publicly shared to promote further\nresearch in the field.", "AI": {"tldr": "The paper introduces an audio-based method for estimating music performance difficulty, including a new dataset (PSyllabus) and a multimodal recognition framework.", "motivation": "Current methods rely on symbolic music representations, neglecting audio recordings, which limits accessibility for students. This work addresses this gap.", "method": "The authors propose a recognition framework using unimodal and multimodal input representations derived from audio, tested with various pre-training schemes and multi-task scenarios.", "result": "The framework is validated through experiments, and the PSyllabus dataset (7,901 piano pieces across 11 difficulty levels) is established as a benchmark.", "conclusion": "The work pioneers audio-based difficulty estimation, sharing the dataset, code, and models to encourage further research in MIR."}}
{"id": "2505.23465", "pdf": "https://arxiv.org/pdf/2505.23465", "abs": "https://arxiv.org/abs/2505.23465", "authors": ["Zi-An Wang", "Shihao Zou", "Shiyao Yu", "Mingyuan Zhang", "Chao Dong"], "title": "Semantics-Aware Human Motion Generation from Audio Instructions", "categories": ["cs.SD", "cs.CV"], "comment": null, "summary": "Recent advances in interactive technologies have highlighted the prominence\nof audio signals for semantic encoding. This paper explores a new task, where\naudio signals are used as conditioning inputs to generate motions that align\nwith the semantics of the audio. Unlike text-based interactions, audio provides\na more natural and intuitive communication method. However, existing methods\ntypically focus on matching motions with music or speech rhythms, which often\nresults in a weak connection between the semantics of the audio and generated\nmotions. We propose an end-to-end framework using a masked generative\ntransformer, enhanced by a memory-retrieval attention module to handle sparse\nand lengthy audio inputs. Additionally, we enrich existing datasets by\nconverting descriptions into conversational style and generating corresponding\naudio with varied speaker identities. Experiments demonstrate the effectiveness\nand efficiency of the proposed framework, demonstrating that audio instructions\ncan convey semantics similar to text while providing more practical and\nuser-friendly interactions.", "AI": {"tldr": "The paper introduces an end-to-end framework using a masked generative transformer to generate motions aligned with audio semantics, improving upon existing methods that focus on rhythm matching.", "motivation": "Audio signals offer a natural and intuitive communication method for motion generation, but current methods lack strong semantic alignment between audio and motions.", "method": "Proposes a masked generative transformer with a memory-retrieval attention module to handle sparse audio inputs, and enriches datasets with conversational-style descriptions and varied audio.", "result": "Experiments show the framework effectively generates motions aligned with audio semantics, proving audio can convey semantics like text while being more user-friendly.", "conclusion": "The framework successfully bridges the gap between audio semantics and motion generation, offering practical and intuitive interactions."}}
{"id": "2505.22823", "pdf": "https://arxiv.org/pdf/2505.22823", "abs": "https://arxiv.org/abs/2505.22823", "authors": ["Yingming Wang", "Pepa Atanasova"], "title": "Self-Critique and Refinement for Faithful Natural Language Explanations", "categories": ["cs.CL"], "comment": "21 pages, 10 figures, 14 tables", "summary": "With the rapid development of large language models (LLMs), natural language\nexplanations (NLEs) have become increasingly important for understanding model\npredictions. However, these explanations often fail to faithfully represent the\nmodel's actual reasoning process. While existing work has demonstrated that\nLLMs can self-critique and refine their initial outputs for various tasks, this\ncapability remains unexplored for improving explanation faithfulness. To\naddress this gap, we introduce Self-critique and Refinement for Natural\nLanguage Explanations (SR-NLE), a framework that enables models to improve the\nfaithfulness of their own explanations -- specifically, post-hoc NLEs --\nthrough an iterative critique and refinement process without external\nsupervision. Our framework leverages different feedback mechanisms to guide the\nrefinement process, including natural language self-feedback and, notably, a\nnovel feedback approach based on feature attribution that highlights important\ninput words. Our experiments across three datasets and four state-of-the-art\nLLMs demonstrate that SR-NLE significantly reduces unfaithfulness rates, with\nour best method achieving an average unfaithfulness rate of 36.02%, compared to\n54.81% for baseline -- an absolute reduction of 18.79%. These findings reveal\nthat the investigated LLMs can indeed refine their explanations to better\nreflect their actual reasoning process, requiring only appropriate guidance\nthrough feedback without additional training or fine-tuning.", "AI": {"tldr": "SR-NLE is a framework that improves the faithfulness of LLM-generated explanations through iterative self-critique and refinement, reducing unfaithfulness rates by 18.79%.", "motivation": "Existing LLM explanations often lack faithfulness to the model's reasoning, and the potential for self-improvement in this context is unexplored.", "method": "SR-NLE uses iterative critique and refinement with feedback mechanisms like natural language self-feedback and feature attribution.", "result": "Experiments show SR-NLE reduces unfaithfulness rates to 36.02% from 54.81%, a significant improvement.", "conclusion": "LLMs can refine their explanations to better reflect reasoning with guided feedback, without additional training."}}
{"id": "2304.11476", "pdf": "https://arxiv.org/pdf/2304.11476", "abs": "https://arxiv.org/abs/2304.11476", "authors": ["Alexandra G. Roberts", "Dominick J. Romano", "Mert \u015ei\u015fman", "Alexey V. Dimov", "Pascal Spincemaille", "Thanh D. Nguyen", "Ilhami Kovanlikaya", "Susan A. Gauthier", "Yi Wang"], "title": "Maximum Spherical Mean Value (mSMV) Filtering for Whole Brain Quantitative Susceptibility Mapping", "categories": ["eess.IV"], "comment": "12 pages, 5 figures", "summary": "To develop a tissue field filtering algorithm, called maximum Spherical Mean\nValue (mSMV), for reducing shadow artifacts in quantitative susceptibility\nmapping (QSM) of the brain without requiring brain tissue erosion. Residual\nbackground field is a major source of shadow artifacts in QSM. The mSMV\nalgorithm filters large field values near the border, where the maximum value\nof the harmonic background field is located. The effectiveness of mSMV for\nartifact removal was evaluated by comparing with existing QSM algorithms in\nnumerical brain simulation as well as using in vivo human data acquired from 11\nhealthy volunteers and 93 patients. Numerical simulation showed that mSMV\nreduces shadow artifacts and improves QSM accuracy. Better shadow reduction, as\ndemonstrated by lower QSM variation in the gray matter and higher QSM image\nquality score, was also observed in healthy subjects and in patients with\nhemorrhages, stroke and multiple sclerosis. The mSMV algorithm allows QSM maps\nthat are substantially equivalent to those obtained using SMV-filtered dipole\ninversion without eroding the volume of interest.", "AI": {"tldr": "The paper introduces the mSMV algorithm to reduce shadow artifacts in QSM without brain tissue erosion, showing improved accuracy and image quality in simulations and real data.", "motivation": "Shadow artifacts in QSM, caused by residual background fields, degrade image quality. Current methods require brain tissue erosion, which the mSMV algorithm avoids.", "method": "The mSMV algorithm filters large field values near borders where harmonic background fields peak. It was tested in simulations and on data from 11 healthy volunteers and 93 patients.", "result": "mSMV reduced shadow artifacts, improved QSM accuracy in simulations, and showed better shadow reduction in real data, with lower gray matter variation and higher image quality scores.", "conclusion": "mSMV provides artifact-free QSM maps comparable to SMV-filtered dipole inversion without eroding the volume of interest."}}
{"id": "2505.22854", "pdf": "https://arxiv.org/pdf/2505.22854", "abs": "https://arxiv.org/abs/2505.22854", "authors": ["Kornel Howil", "Joanna Waczy\u0144ska", "Piotr Borycki", "Tadeusz Dziarmaga", "Marcin Mazur", "Przemys\u0142aw Spurek"], "title": "CLIPGaussian: Universal and Multimodal Style Transfer Based on Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "Gaussian Splatting (GS) has recently emerged as an efficient representation\nfor rendering 3D scenes from 2D images and has been extended to images, videos,\nand dynamic 4D content. However, applying style transfer to GS-based\nrepresentations, especially beyond simple color changes, remains challenging.\nIn this work, we introduce CLIPGaussians, the first unified style transfer\nframework that supports text- and image-guided stylization across multiple\nmodalities: 2D images, videos, 3D objects, and 4D scenes. Our method operates\ndirectly on Gaussian primitives and integrates into existing GS pipelines as a\nplug-in module, without requiring large generative models or retraining from\nscratch. CLIPGaussians approach enables joint optimization of color and\ngeometry in 3D and 4D settings, and achieves temporal coherence in videos,\nwhile preserving a model size. We demonstrate superior style fidelity and\nconsistency across all tasks, validating CLIPGaussians as a universal and\nefficient solution for multimodal style transfer.", "AI": {"tldr": "CLIPGaussians introduces a unified style transfer framework for Gaussian Splatting (GS) representations, supporting text- and image-guided stylization across 2D, 3D, and 4D content without retraining.", "motivation": "Style transfer for GS-based representations is challenging beyond simple color changes, prompting the need for a versatile solution.", "method": "CLIPGaussians operates directly on Gaussian primitives, integrating as a plug-in module into GS pipelines, optimizing color and geometry jointly.", "result": "Achieves superior style fidelity, temporal coherence in videos, and consistency across tasks while maintaining model size.", "conclusion": "CLIPGaussians is a universal and efficient solution for multimodal style transfer in GS representations."}}
{"id": "2505.22990", "pdf": "https://arxiv.org/pdf/2505.22990", "abs": "https://arxiv.org/abs/2505.22990", "authors": ["Pin-Han Chen", "Yu-Sheng Lin", "Wei-Cheng Lee", "Tin-Yu Leu", "Po-Hsiang Hsu", "Anjana Dissanayake", "Sungjin Oh", "Chinq-Shiun Chiu"], "title": "MenTeR: A fully-automated Multi-agenT workflow for end-to-end RF/Analog Circuits Netlist Design", "categories": ["cs.AI", "cs.ET", "cs.LG"], "comment": "9 pages, 7 figures, accepted by IEEE ICLAD 2025", "summary": "RF/Analog design is essential for bridging digital technologies with\nreal-world signals, ensuring the functionality and reliability of a wide range\nof electronic systems. However, analog design procedures are often intricate,\ntime-consuming and reliant on expert intuition, and hinder the time and cost\nefficiency of circuit development. To overcome the limitations of the manual\ncircuit design, we introduce MenTeR - a multiagent workflow integrated into an\nend-to-end analog design framework. By employing multiple specialized AI agents\nthat collaboratively address different aspects of the design process, such as\nspecification understanding, circuit optimization, and test bench validation,\nMenTeR reduces the dependency on frequent trial-and-error-style intervention.\nMenTeR not only accelerates the design cycle time but also facilitates a\nbroader exploration of the design space, demonstrating robust capabilities in\nhandling real-world analog systems. We believe that MenTeR lays the groundwork\nfor future \"RF/Analog Copilots\" that can collaborate seamlessly with human\ndesigners.", "AI": {"tldr": "MenTeR is a multiagent AI workflow for RF/analog design, reducing manual effort and accelerating the design cycle.", "motivation": "Analog design is complex and time-consuming, relying heavily on expert intuition, which hinders efficiency.", "method": "MenTeR uses specialized AI agents for tasks like specification understanding, optimization, and validation.", "result": "It speeds up design cycles, explores more design options, and handles real-world systems robustly.", "conclusion": "MenTeR paves the way for future AI-assisted RF/analog design tools."}}
{"id": "2505.22772", "pdf": "https://arxiv.org/pdf/2505.22772", "abs": "https://arxiv.org/abs/2505.22772", "authors": ["Claas Voelcker", "Anastasiia Pedan", "Arash Ahmadian", "Romina Abachi", "Igor Gilitschenski", "Amir-massoud Farahmand"], "title": "Calibrated Value-Aware Model Learning with Stochastic Environment Models", "categories": ["cs.LG"], "comment": null, "summary": "The idea of value-aware model learning, that models should produce accurate\nvalue estimates, has gained prominence in model-based reinforcement learning.\nThe MuZero loss, which penalizes a model's value function prediction compared\nto the ground-truth value function, has been utilized in several prominent\nempirical works in the literature. However, theoretical investigation into its\nstrengths and weaknesses is limited. In this paper, we analyze the family of\nvalue-aware model learning losses, which includes the popular MuZero loss. We\nshow that these losses, as normally used, are uncalibrated surrogate losses,\nwhich means that they do not always recover the correct model and value\nfunction. Building on this insight, we propose corrections to solve this issue.\nFurthermore, we investigate the interplay between the loss calibration, latent\nmodel architectures, and auxiliary losses that are commonly employed when\ntraining MuZero-style agents. We show that while deterministic models can be\nsufficient to predict accurate values, learning calibrated stochastic models is\nstill advantageous.", "AI": {"tldr": "The paper analyzes value-aware model learning losses, including MuZero, showing they are uncalibrated and proposing corrections. It also explores the role of loss calibration, model architectures, and auxiliary losses.", "motivation": "To address the lack of theoretical understanding of value-aware model learning losses, particularly the MuZero loss, and their limitations in recovering correct models and value functions.", "method": "Theoretical analysis of value-aware model learning losses, identification of their uncalibrated nature, and proposal of corrective measures. Investigation of loss calibration, model architectures, and auxiliary losses.", "result": "Value-aware losses like MuZero are uncalibrated surrogates, but corrections can address this. Deterministic models suffice for value prediction, but stochastic models offer advantages.", "conclusion": "Correcting uncalibrated losses improves model learning. Stochastic models, despite deterministic sufficiency, provide additional benefits."}}
{"id": "2505.22467", "pdf": "https://arxiv.org/pdf/2505.22467", "abs": "https://arxiv.org/abs/2505.22467", "authors": ["Jiaxi Yang", "Mengqi Zhang", "Yiqiao Jin", "Hao Chen", "Qingsong Wen", "Lu Lin", "Yi He", "Weijie Xu", "James Evans", "Jindong Wang"], "title": "Topological Structure Learning Should Be A Research Priority for LLM-Based Multi-Agent Systems", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Model-based Multi-Agent Systems (MASs) have emerged as a\npowerful paradigm for tackling complex tasks through collaborative\nintelligence. Nevertheless, the question of how agents should be structurally\norganized for optimal cooperation remains largely unexplored. In this position\npaper, we aim to gently redirect the focus of the MAS research community toward\nthis critical dimension: develop topology-aware MASs for specific tasks.\nSpecifically, the system consists of three core components - agents,\ncommunication links, and communication patterns - that collectively shape its\ncoordination performance and efficiency. To this end, we introduce a\nsystematic, three-stage framework: agent selection, structure profiling, and\ntopology synthesis. Each stage would trigger new research opportunities in\nareas such as language models, reinforcement learning, graph learning, and\ngenerative modeling; together, they could unleash the full potential of MASs in\ncomplicated real-world applications. Then, we discuss the potential challenges\nand opportunities in the evaluation of multiple systems. We hope our\nperspective and framework can offer critical new insights in the era of agentic\nAI.", "AI": {"tldr": "The paper proposes a framework for optimizing the structural organization of Multi-Agent Systems (MASs) using Large Language Models, focusing on agent selection, structure profiling, and topology synthesis.", "motivation": "To address the unexplored question of how agents should be structurally organized for optimal cooperation in MASs.", "method": "Introduces a three-stage framework: agent selection, structure profiling, and topology synthesis, leveraging areas like language models and reinforcement learning.", "result": "The framework aims to enhance coordination performance and efficiency in MASs, opening new research opportunities.", "conclusion": "The paper highlights challenges and opportunities in evaluating MASs and aims to inspire further research in agentic AI."}}
{"id": "2405.20032", "pdf": "https://arxiv.org/pdf/2405.20032", "abs": "https://arxiv.org/abs/2405.20032", "authors": ["Jiangkai Wu", "Liming Liu", "Yunpeng Tan", "Junlin Hao", "Xinggong Zhang"], "title": "Promptus: Can Prompts Streaming Replace Video Streaming with Stable Diffusion", "categories": ["cs.NI", "cs.AI", "cs.MM"], "comment": null, "summary": "With the exponential growth of video traffic, traditional video streaming\nsystems are approaching their limits in compression efficiency and\ncommunication capacity. To further reduce bitrate while maintaining quality, we\npropose Promptus, a disruptive semantic communication system that streaming\nprompts instead of video content, which represents real-world video frames with\na series of \"prompts\" for delivery and employs Stable Diffusion to generate\nvideos at the receiver. To ensure that the generated video is pixel-aligned\nwith the original video, a gradient descent-based prompt fitting framework is\nproposed. Further, a low-rank decomposition-based bitrate control algorithm is\nintroduced to achieve adaptive bitrate. For inter-frame compression, an\ninterpolation-aware fitting algorithm is proposed. Evaluations across various\nvideo genres demonstrate that, compared to H.265, Promptus can achieve more\nthan a 4x bandwidth reduction while preserving the same perceptual quality. On\nthe other hand, at extremely low bitrates, Promptus can enhance the perceptual\nquality by 0.139 and 0.118 (in LPIPS) compared to VAE and H.265, respectively,\nand decreases the ratio of severely distorted frames by 89.3% and 91.7%. Our\nwork opens up a new paradigm for efficient video communication. Promptus is\nopen-sourced at: https://github.com/JiangkaiWu/Promptus.", "AI": {"tldr": "Promptus is a semantic communication system that streams prompts instead of video content, using Stable Diffusion for video generation at the receiver, achieving significant bandwidth reduction and quality preservation.", "motivation": "Traditional video streaming systems face limitations in compression efficiency and communication capacity, necessitating innovative solutions to reduce bitrate while maintaining quality.", "method": "Promptus employs a gradient descent-based prompt fitting framework for pixel-aligned video generation, a low-rank decomposition-based bitrate control algorithm, and an interpolation-aware fitting algorithm for inter-frame compression.", "result": "Promptus achieves over 4x bandwidth reduction compared to H.265 while preserving perceptual quality and enhances quality at extremely low bitrates, reducing severely distorted frames by up to 91.7%.", "conclusion": "Promptus introduces a new paradigm for efficient video communication, demonstrating superior performance over traditional methods and is open-sourced for further development."}}
{"id": "2412.00175", "pdf": "https://arxiv.org/pdf/2412.00175", "abs": "https://arxiv.org/abs/2412.00175", "authors": ["Stefan Smeu", "Dragos-Alexandru Boldisor", "Dan Oneata", "Elisabeta Oneata"], "title": "Circumventing shortcuts in audio-visual deepfake detection datasets with unsupervised learning", "categories": ["cs.CV", "cs.LG", "cs.SD", "eess.AS", "eess.IV"], "comment": "Accepted as a highlight paper at the IEEE/CVF Conference on Computer\n  Vision and Pattern Recognition (CVPR) 2025", "summary": "Good datasets are essential for developing and benchmarking any machine\nlearning system. Their importance is even more extreme for safety critical\napplications such as deepfake detection - the focus of this paper. Here we\nreveal that two of the most widely used audio-video deepfake datasets suffer\nfrom a previously unidentified spurious feature: the leading silence. Fake\nvideos start with a very brief moment of silence and based on this feature\nalone, we can separate the real and fake samples almost perfectly. As such,\nprevious audio-only and audio-video models exploit the presence of silence in\nthe fake videos and consequently perform worse when the leading silence is\nremoved. To circumvent latching on such unwanted artifact and possibly other\nunrevealed ones we propose a shift from supervised to unsupervised learning by\ntraining models exclusively on real data. We show that by aligning\nself-supervised audio-video representations we remove the risk of relying on\ndataset-specific biases and improve robustness in deepfake detection.", "AI": {"tldr": "The paper identifies a spurious feature (leading silence) in widely used deepfake datasets, showing it biases detection models. It proposes unsupervised learning on real data to improve robustness.", "motivation": "Deepfake detection is safety-critical, but current datasets contain biases (leading silence) that mislead models, undermining reliability.", "method": "Shift from supervised to unsupervised learning, training models exclusively on real data and aligning self-supervised audio-video representations.", "result": "Models exploiting leading silence perform poorly when the feature is removed. Unsupervised learning avoids biases and enhances detection robustness.", "conclusion": "Unsupervised learning on real data mitigates dataset-specific biases, improving deepfake detection reliability."}}
{"id": "2505.23619", "pdf": "https://arxiv.org/pdf/2505.23619", "abs": "https://arxiv.org/abs/2505.23619", "authors": ["Neta Glazer", "David Chernin", "Idan Achituve", "Sharon Gannot", "Ethan Fetaya"], "title": "Few-Shot Speech Deepfake Detection Adaptation with Gaussian Processes", "categories": ["cs.SD", "cs.LG"], "comment": null, "summary": "Recent advancements in Text-to-Speech (TTS) models, particularly in voice\ncloning, have intensified the demand for adaptable and efficient deepfake\ndetection methods. As TTS systems continue to evolve, detection models must be\nable to efficiently adapt to previously unseen generation models with minimal\ndata. This paper introduces ADD-GP, a few-shot adaptive framework based on a\nGaussian Process (GP) classifier for Audio Deepfake Detection (ADD). We show\nhow the combination of a powerful deep embedding model with the Gaussian\nprocesses flexibility can achieve strong performance and adaptability.\nAdditionally, we show this approach can also be used for personalized\ndetection, with greater robustness to new TTS models and one-shot adaptability.\nTo support our evaluation, a benchmark dataset is constructed for this task\nusing new state-of-the-art voice cloning models.", "AI": {"tldr": "ADD-GP is a few-shot adaptive framework for audio deepfake detection using Gaussian Process classifiers, achieving strong performance and adaptability.", "motivation": "The rise of advanced TTS models and voice cloning necessitates adaptable deepfake detection methods that work with minimal data.", "method": "Combines deep embedding models with Gaussian Process classifiers for few-shot learning and adaptability.", "result": "Demonstrates strong performance, adaptability to new TTS models, and one-shot personalized detection.", "conclusion": "ADD-GP offers a robust and adaptable solution for detecting audio deepfakes, even with limited data."}}
{"id": "2505.22830", "pdf": "https://arxiv.org/pdf/2505.22830", "abs": "https://arxiv.org/abs/2505.22830", "authors": ["Alexander Gill", "Abhilasha Ravichander", "Ana Marasovi\u0107"], "title": "What Has Been Lost with Synthetic Evaluation?", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages main, 5 pages reference, 24 pages appendix", "summary": "Large language models (LLMs) are increasingly used for data generation.\nHowever, creating evaluation benchmarks raises the bar for this emerging\nparadigm. Benchmarks must target specific phenomena, penalize exploiting\nshortcuts, and be challenging. Through two case studies, we investigate whether\nLLMs can meet these demands by generating reasoning over-text benchmarks and\ncomparing them to those created through careful crowdsourcing. Specifically, we\nevaluate both the validity and difficulty of LLM-generated versions of two\nhigh-quality reading comprehension datasets: CondaQA, which evaluates reasoning\nabout negation, and DROP, which targets reasoning about quantities. We find\nthat prompting LLMs can produce variants of these datasets that are often valid\naccording to the annotation guidelines, at a fraction of the cost of the\noriginal crowdsourcing effort. However, we show that they are less challenging\nfor LLMs than their human-authored counterparts. This finding sheds light on\nwhat may have been lost by generating evaluation data with LLMs, and calls for\ncritically reassessing the immediate use of this increasingly prevalent\napproach to benchmark creation.", "AI": {"tldr": "LLMs can generate valid evaluation benchmarks at lower cost but produce less challenging data compared to human-authored benchmarks.", "motivation": "To assess if LLMs can meet the demands of creating high-quality evaluation benchmarks for reasoning tasks.", "method": "Case studies comparing LLM-generated benchmarks (CondaQA and DROP variants) to human-crowdsourced ones, evaluating validity and difficulty.", "result": "LLM-generated benchmarks are valid but less challenging for LLMs than human-authored ones.", "conclusion": "The approach of using LLMs for benchmark creation needs critical reassessment due to reduced challenge."}}
{"id": "2412.16197", "pdf": "https://arxiv.org/pdf/2412.16197", "abs": "https://arxiv.org/abs/2412.16197", "authors": ["Wenhui Cui", "Haleh Akrami", "Anand A. Joshi", "Richard M. Leahy"], "title": "Generalizable Representation Learning for fMRI-based Neurological Disorder Identification", "categories": ["eess.IV", "cs.CE", "cs.CV", "cs.LG"], "comment": "Accepted by TMLR", "summary": "Despite the impressive advances achieved using deep learning for functional\nbrain activity analysis, the heterogeneity of functional patterns and the\nscarcity of imaging data still pose challenges in tasks such as identifying\nneurological disorders. For functional Magnetic Resonance Imaging (fMRI), while\ndata may be abundantly available from healthy controls, clinical data is often\nscarce, especially for rare diseases, limiting the ability of models to\nidentify clinically-relevant features. We overcome this limitation by\nintroducing a novel representation learning strategy integrating meta-learning\nwith self-supervised learning to improve the generalization from normal to\nclinical features. This approach enables generalization to challenging clinical\ntasks featuring scarce training data. We achieve this by leveraging\nself-supervised learning on the control dataset to focus on inherent features\nthat are not limited to a particular supervised task and incorporating\nmeta-learning to improve the generalization across domains. To explore the\ngeneralizability of the learned representations to unseen clinical\napplications, we apply the model to four distinct clinical datasets featuring\nscarce and heterogeneous data for neurological disorder classification. Results\ndemonstrate the superiority of our representation learning strategy on diverse\nclinically-relevant tasks. Code is publicly available at\nhttps://github.com/wenhui0206/MeTSK/tree/main", "AI": {"tldr": "A novel representation learning strategy combining meta-learning and self-supervised learning improves generalization for neurological disorder classification in fMRI data, even with scarce clinical datasets.", "motivation": "The heterogeneity of functional brain activity patterns and scarcity of clinical fMRI data limit the ability of deep learning models to identify neurological disorders, especially for rare diseases.", "method": "The approach integrates meta-learning with self-supervised learning, leveraging control datasets to focus on inherent features and improve cross-domain generalization.", "result": "The strategy outperforms others on four clinical datasets with scarce and heterogeneous data, demonstrating superior generalization.", "conclusion": "The proposed method effectively addresses data scarcity and heterogeneity, enhancing clinical task performance in fMRI analysis."}}
{"id": "2505.22855", "pdf": "https://arxiv.org/pdf/2505.22855", "abs": "https://arxiv.org/abs/2505.22855", "authors": ["Ruining Deng", "Junchao Zhu", "Juming Xiong", "Can Cui", "Tianyuan Yao", "Junlin Guo", "Siqi Lu", "Marilyn Lionts", "Mengmeng Yin", "Yu Wang", "Shilin Zhao", "Yucheng Tang", "Yihe Yang", "Paul Dennis Simonson", "Mert R. Sabuncu", "Haichun Yang", "Yuankai Huo"], "title": "IRS: Incremental Relationship-guided Segmentation for Digital Pathology", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Continual learning is rapidly emerging as a key focus in computer vision,\naiming to develop AI systems capable of continuous improvement, thereby\nenhancing their value and practicality in diverse real-world applications. In\nhealthcare, continual learning holds great promise for continuously acquired\ndigital pathology data, which is collected in hospitals on a daily basis.\nHowever, panoramic segmentation on digital whole slide images (WSIs) presents\nsignificant challenges, as it is often infeasible to obtain comprehensive\nannotations for all potential objects, spanning from coarse structures (e.g.,\nregions and unit objects) to fine structures (e.g., cells). This results in\ntemporally and partially annotated data, posing a major challenge in developing\na holistic segmentation framework. Moreover, an ideal segmentation model should\nincorporate new phenotypes, unseen diseases, and diverse populations, making\nthis task even more complex. In this paper, we introduce a novel and unified\nIncremental Relationship-guided Segmentation (IRS) learning scheme to address\ntemporally acquired, partially annotated data while maintaining\nout-of-distribution (OOD) continual learning capacity in digital pathology. The\nkey innovation of IRS lies in its ability to realize a new spatial-temporal OOD\ncontinual learning paradigm by mathematically modeling anatomical relationships\nbetween existing and newly introduced classes through a simple incremental\nuniversal proposition matrix. Experimental results demonstrate that the IRS\nmethod effectively handles the multi-scale nature of pathological segmentation,\nenabling precise kidney segmentation across various structures (regions, units,\nand cells) as well as OOD disease lesions at multiple magnifications. This\ncapability significantly enhances domain generalization, making IRS a robust\napproach for real-world digital pathology applications.", "AI": {"tldr": "The paper introduces IRS, a novel continual learning scheme for digital pathology, addressing partially annotated data and OOD challenges through anatomical relationship modeling.", "motivation": "Continual learning is crucial for AI in healthcare, especially for digital pathology, where data is continuously acquired but often partially annotated, posing challenges for holistic segmentation.", "method": "The IRS method uses an incremental universal proposition matrix to model anatomical relationships between existing and new classes, enabling spatial-temporal OOD continual learning.", "result": "IRS effectively handles multi-scale pathological segmentation, achieving precise kidney segmentation across structures and OOD disease lesions, enhancing domain generalization.", "conclusion": "IRS is a robust solution for real-world digital pathology, addressing continual learning challenges and improving segmentation accuracy."}}
{"id": "2505.23034", "pdf": "https://arxiv.org/pdf/2505.23034", "abs": "https://arxiv.org/abs/2505.23034", "authors": ["Guangyi Liu", "Yongqi Zhang", "Xunyuan Liu", "Quanming Yao"], "title": "Case-Based Reasoning Enhances the Predictive Power of LLMs in Drug-Drug Interaction", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Drug-drug interaction (DDI) prediction is critical for treatment safety.\nWhile large language models (LLMs) show promise in pharmaceutical tasks, their\neffectiveness in DDI prediction remains challenging. Inspired by the\nwell-established clinical practice where physicians routinely reference similar\nhistorical cases to guide their decisions through case-based reasoning (CBR),\nwe propose CBR-DDI, a novel framework that distills pharmacological principles\nfrom historical cases to improve LLM reasoning for DDI tasks. CBR-DDI\nconstructs a knowledge repository by leveraging LLMs to extract pharmacological\ninsights and graph neural networks (GNNs) to model drug associations. A hybrid\nretrieval mechanism and dual-layer knowledge-enhanced prompting allow LLMs to\neffectively retrieve and reuse relevant cases. We further introduce a\nrepresentative sampling strategy for dynamic case refinement. Extensive\nexperiments demonstrate that CBR-DDI achieves state-of-the-art performance,\nwith a significant 28.7% accuracy improvement over both popular LLMs and CBR\nbaseline, while maintaining high interpretability and flexibility.", "AI": {"tldr": "CBR-DDI improves DDI prediction by combining LLMs and GNNs with case-based reasoning, achieving a 28.7% accuracy boost.", "motivation": "DDI prediction is crucial for treatment safety, but LLMs struggle with it. Inspired by clinical case-based reasoning, CBR-DDI aims to enhance LLM performance.", "method": "Uses LLMs to extract pharmacological insights and GNNs to model drug associations. Features hybrid retrieval, dual-layer prompting, and dynamic case refinement.", "result": "Achieves state-of-the-art performance with a 28.7% accuracy improvement over baselines.", "conclusion": "CBR-DDI effectively enhances LLM reasoning for DDI tasks, offering high interpretability and flexibility."}}
{"id": "2505.22778", "pdf": "https://arxiv.org/pdf/2505.22778", "abs": "https://arxiv.org/abs/2505.22778", "authors": ["Sarah Meiklejohn", "Hayden Blauzvern", "Mihai Maruseac", "Spencer Schrock", "Laurent Simon", "Ilia Shumailov"], "title": "Machine Learning Models Have a Supply Chain Problem", "categories": ["cs.LG", "cs.CR"], "comment": "12 pages, four figures and one table", "summary": "Powerful machine learning (ML) models are now readily available online, which\ncreates exciting possibilities for users who lack the deep technical expertise\nor substantial computing resources needed to develop them. On the other hand,\nthis type of open ecosystem comes with many risks. In this paper, we argue that\nthe current ecosystem for open ML models contains significant supply-chain\nrisks, some of which have been exploited already in real attacks. These include\nan attacker replacing a model with something malicious (e.g., malware), or a\nmodel being trained using a vulnerable version of a framework or on restricted\nor poisoned data. We then explore how Sigstore, a solution designed to bring\ntransparency to open-source software supply chains, can be used to bring\ntransparency to open ML models, in terms of enabling model publishers to sign\ntheir models and prove properties about the datasets they use.", "AI": {"tldr": "The paper highlights supply-chain risks in open ML models and proposes using Sigstore for transparency.", "motivation": "The open ecosystem for ML models poses risks like malicious replacements and poisoned data, which need addressing.", "method": "Explore Sigstore's application to ML models for signing and verifying dataset properties.", "result": "Sigstore can enhance transparency and security in open ML model supply chains.", "conclusion": "Using Sigstore can mitigate risks in the open ML model ecosystem."}}
{"id": "2310.18940", "pdf": "https://arxiv.org/pdf/2310.18940", "abs": "https://arxiv.org/abs/2310.18940", "authors": ["Zelai Xu", "Chao Yu", "Fei Fang", "Yu Wang", "Yi Wu"], "title": "Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": "Published in ICML 2024", "summary": "Agents built with large language models (LLMs) have shown great potential\nacross a wide range of domains. However, in complex decision-making tasks, pure\nLLM-based agents tend to exhibit intrinsic bias in their choice of actions,\nwhich is inherited from the model's training data and results in suboptimal\nperformance. To develop strategic language agents, i.e., agents that generate\nflexible language actions and possess strong decision-making abilities, we\npropose a novel framework that powers LLM-based agents with reinforcement\nlearning (RL). We consider Werewolf, a popular social deduction game, as a\nchallenging testbed that emphasizes versatile communication and strategic\ngameplay. To mitigate the intrinsic bias in language actions, our agents use an\nLLM to perform deductive reasoning and generate a diverse set of action\ncandidates. Then an RL policy trained to optimize the decision-making ability\nchooses an action from the candidates to play in the game. Extensive\nexperiments show that our agents overcome the intrinsic bias and outperform\nexisting LLM-based agents in the Werewolf game. We also conduct human-agent\nexperiments and find that our agents achieve human-level performance and\ndemonstrate strong strategic play.", "AI": {"tldr": "A framework combining LLMs with RL improves strategic decision-making in language agents, tested in the Werewolf game, outperforming pure LLM-based agents and achieving human-level performance.", "motivation": "Pure LLM-based agents exhibit intrinsic bias in complex decision-making tasks, leading to suboptimal performance. The goal is to develop strategic language agents with flexible actions and strong decision-making.", "method": "Proposes a framework where an LLM generates diverse action candidates, and an RL policy selects the optimal action. Tested in the Werewolf game.", "result": "Agents overcome intrinsic bias, outperform existing LLM-based agents, and achieve human-level performance in strategic gameplay.", "conclusion": "Combining LLMs with RL enhances strategic decision-making in language agents, demonstrating potential for complex tasks."}}
{"id": "2407.17490", "pdf": "https://arxiv.org/pdf/2407.17490", "abs": "https://arxiv.org/abs/2407.17490", "authors": ["Yuxiang Chai", "Siyuan Huang", "Yazhe Niu", "Han Xiao", "Liang Liu", "Dingyu Zhang", "Shuai Ren", "Hongsheng Li"], "title": "AMEX: Android Multi-annotation Expo Dataset for Mobile GUI Agents", "categories": ["cs.HC", "cs.AI", "cs.MM"], "comment": null, "summary": "AI agents have drawn increasing attention mostly on their ability to perceive\nenvironments, understand tasks, and autonomously achieve goals. To advance\nresearch on AI agents in mobile scenarios, we introduce the Android\nMulti-annotation EXpo (AMEX), a comprehensive, large-scale dataset designed for\ngeneralist mobile GUI-control agents which are capable of completing tasks by\ndirectly interacting with the graphical user interface (GUI) on mobile devices.\nAMEX comprises over 104K high-resolution screenshots from popular mobile\napplications, which are annotated at multiple levels. Unlike existing\nGUI-related datasets, e.g., Rico, AitW, etc., AMEX includes three levels of\nannotations: GUI interactive element grounding, GUI screen and element\nfunctionality descriptions, and complex natural language instructions with\nstepwise GUI-action chains. We develop this dataset from a more instructive and\ndetailed perspective, complementing the general settings of existing datasets.\nAdditionally, we finetune a baseline model SPHINX Agent and illustrate the\neffectiveness of AMEX.The project is available at https://yxchai.com/AMEX/.", "AI": {"tldr": "AMEX is a large-scale dataset for mobile GUI-control AI agents, featuring multi-level annotations and high-resolution screenshots, designed to advance research in mobile AI tasks.", "motivation": "To enhance research on AI agents in mobile scenarios by providing a detailed, instructive dataset for GUI interaction tasks.", "method": "Developed AMEX with 104K annotated screenshots, including GUI element grounding, functionality descriptions, and stepwise action chains.", "result": "Demonstrated effectiveness by finetuning the SPHINX Agent model.", "conclusion": "AMEX complements existing datasets and supports the development of generalist mobile GUI-control agents."}}
{"id": "2505.15914", "pdf": "https://arxiv.org/pdf/2505.15914", "abs": "https://arxiv.org/abs/2505.15914", "authors": ["Yuan-Kuei Wu", "Juan Azcarreta", "Kashyap Patel", "Buye Xu", "Jung-Suk Lee", "Sanha Lee", "Ashutosh Pandey"], "title": "A Novel Deep Learning Framework for Efficient Multichannel Acoustic Feedback Control", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted by Interspeech 2025", "summary": "This study presents a deep-learning framework for controlling multichannel\nacoustic feedback in audio devices. Traditional digital signal processing\nmethods struggle with convergence when dealing with highly correlated noise\nsuch as feedback. We introduce a Convolutional Recurrent Network that\nefficiently combines spatial and temporal processing, significantly enhancing\nspeech enhancement capabilities with lower computational demands. Our approach\nutilizes three training methods: In-a-Loop Training, Teacher Forcing, and a\nHybrid strategy with a Multichannel Wiener Filter, optimizing performance in\ncomplex acoustic environments. This scalable framework offers a robust solution\nfor real-world applications, making significant advances in Acoustic Feedback\nControl technology.", "AI": {"tldr": "A deep-learning framework using a Convolutional Recurrent Network improves multichannel acoustic feedback control, outperforming traditional methods with lower computational costs.", "motivation": "Traditional digital signal processing methods fail to converge with highly correlated noise like feedback, necessitating a more efficient solution.", "method": "The framework employs a Convolutional Recurrent Network and three training methods (In-a-Loop Training, Teacher Forcing, Hybrid with Multichannel Wiener Filter) for optimized performance.", "result": "The approach significantly enhances speech enhancement and is scalable for real-world applications.", "conclusion": "This framework advances Acoustic Feedback Control technology, offering a robust and efficient solution."}}
{"id": "2505.23625", "pdf": "https://arxiv.org/pdf/2505.23625", "abs": "https://arxiv.org/abs/2505.23625", "authors": ["Chao Huang", "Yuesheng Ma", "Junxuan Huang", "Susan Liang", "Yunlong Tang", "Jing Bi", "Wenqiang Liu", "Nima Mesgarani", "Chenliang Xu"], "title": "ZeroSep: Separate Anything in Audio with Zero Training", "categories": ["cs.SD", "cs.CV"], "comment": "Project page: https://wikichao.github.io/ZeroSep/", "summary": "Audio source separation is fundamental for machines to understand complex\nacoustic environments and underpins numerous audio applications. Current\nsupervised deep learning approaches, while powerful, are limited by the need\nfor extensive, task-specific labeled data and struggle to generalize to the\nimmense variability and open-set nature of real-world acoustic scenes. Inspired\nby the success of generative foundation models, we investigate whether\npre-trained text-guided audio diffusion models can overcome these limitations.\nWe make a surprising discovery: zero-shot source separation can be achieved\npurely through a pre-trained text-guided audio diffusion model under the right\nconfiguration. Our method, named ZeroSep, works by inverting the mixed audio\ninto the diffusion model's latent space and then using text conditioning to\nguide the denoising process to recover individual sources. Without any\ntask-specific training or fine-tuning, ZeroSep repurposes the generative\ndiffusion model for a discriminative separation task and inherently supports\nopen-set scenarios through its rich textual priors. ZeroSep is compatible with\na variety of pre-trained text-guided audio diffusion backbones and delivers\nstrong separation performance on multiple separation benchmarks, surpassing\neven supervised methods.", "AI": {"tldr": "ZeroSep enables zero-shot audio source separation using pre-trained text-guided audio diffusion models without task-specific training.", "motivation": "Current supervised methods require extensive labeled data and struggle with real-world variability. Generative foundation models offer a potential solution.", "method": "Inverts mixed audio into a diffusion model's latent space and uses text conditioning to guide denoising for source separation.", "result": "ZeroSep achieves strong performance on benchmarks, surpassing supervised methods, and supports open-set scenarios.", "conclusion": "Pre-trained generative models can be repurposed for discriminative tasks like source separation, offering a scalable and flexible solution."}}
{"id": "2505.22842", "pdf": "https://arxiv.org/pdf/2505.22842", "abs": "https://arxiv.org/abs/2505.22842", "authors": ["Arthur S. Bianchessi", "Rodrigo C. Barros", "Lucas S. Kupssinsk\u00fc"], "title": "Bayesian Attention Mechanism: A Probabilistic Framework for Positional Encoding and Context Length Extrapolation", "categories": ["cs.CL", "cs.LG", "I.2.6; I.2.7"], "comment": null, "summary": "Transformer-based language models rely on positional encoding (PE) to handle\ntoken order and support context length extrapolation. However, existing PE\nmethods lack theoretical clarity and rely on limited evaluation metrics to\nsubstantiate their extrapolation claims. We propose the Bayesian Attention\nMechanism (BAM), a theoretical framework that formulates positional encoding as\na prior within a probabilistic model. BAM unifies existing methods (e.g., NoPE\nand ALiBi) and motivates a new Generalized Gaussian positional prior that\nsubstantially improves long-context generalization. Empirically, BAM enables\naccurate information retrieval at $500\\times$ the training context length,\noutperforming previous state-of-the-art context length generalization in long\ncontext retrieval accuracy while maintaining comparable perplexity and\nintroducing minimal additional parameters.", "AI": {"tldr": "The paper introduces BAM, a Bayesian framework for positional encoding in transformers, improving long-context generalization and outperforming existing methods.", "motivation": "Existing positional encoding methods lack theoretical clarity and rely on limited evaluation metrics for extrapolation claims.", "method": "Proposes BAM, a probabilistic model treating positional encoding as a prior, unifying existing methods and introducing a Generalized Gaussian positional prior.", "result": "BAM achieves accurate information retrieval at 500\u00d7 training context length, outperforming state-of-the-art in long-context accuracy with minimal added parameters.", "conclusion": "BAM provides a theoretically grounded and empirically superior approach to positional encoding for transformers."}}
{"id": "2501.01482", "pdf": "https://arxiv.org/pdf/2501.01482", "abs": "https://arxiv.org/abs/2501.01482", "authors": ["Muhammad Ahmad Sultan", "Chong Chen", "Yingmin Liu", "Katarzyna Gil", "Karolina Zareba", "Rizwan Ahmad"], "title": "An unsupervised method for MRI recovery: Deep image prior with structured sparsity", "categories": ["eess.IV", "cs.CV", "cs.LG", "eess.SP"], "comment": "Magn Reson Mater Phy (2025)", "summary": "Objective: To propose and validate an unsupervised MRI reconstruction method\nthat does not require fully sampled k-space data. Materials and Methods: The\nproposed method, deep image prior with structured sparsity (DISCUS), extends\nthe deep image prior (DIP) by introducing group sparsity to frame-specific code\nvectors, enabling the discovery of a low-dimensional manifold for capturing\ntemporal variations. \\discus was validated using four studies: (I) simulation\nof a dynamic Shepp-Logan phantom to demonstrate its manifold discovery\ncapabilities, (II) comparison with compressed sensing and DIP-based methods\nusing simulated single-shot late gadolinium enhancement (LGE) image series from\nsix distinct digital cardiac phantoms in terms of normalized mean square error\n(NMSE) and structural similarity index measure (SSIM), (III) evaluation on\nretrospectively undersampled single-shot LGE data from eight patients, and (IV)\nevaluation on prospectively undersampled single-shot LGE data from eight\npatients, assessed via blind scoring from two expert readers. Results: DISCUS\noutperformed competing methods, demonstrating superior reconstruction quality\nin terms of NMSE and SSIM (Studies I--III) and expert reader scoring (Study\nIV). Discussion: An unsupervised image reconstruction method is presented and\nvalidated on simulated and measured data. These developments can benefit\napplications where acquiring fully sampled data is challenging.", "AI": {"tldr": "Proposes DISCUS, an unsupervised MRI reconstruction method using deep image prior with structured sparsity, validated via simulations and patient data.", "motivation": "Addresses the challenge of MRI reconstruction without fully sampled k-space data, leveraging unsupervised learning.", "method": "Extends deep image prior (DIP) with group sparsity for low-dimensional manifold discovery, validated through simulations and patient studies.", "result": "Outperforms compressed sensing and DIP-based methods in NMSE, SSIM, and expert scoring.", "conclusion": "DISCUS offers a robust unsupervised solution for MRI reconstruction, especially where fully sampled data is hard to acquire."}}
{"id": "2505.22858", "pdf": "https://arxiv.org/pdf/2505.22858", "abs": "https://arxiv.org/abs/2505.22858", "authors": ["Sanjoy Kundu", "Shanmukha Vellamcheti", "Sathyanarayanan N. Aakur"], "title": "A Probabilistic Jump-Diffusion Framework for Open-World Egocentric Activity Recognition", "categories": ["cs.CV"], "comment": "Extended abstract of arXiv:2504.03948 for CVPR 2025 EgoVis Workshop", "summary": "Open-world egocentric activity recognition poses a fundamental challenge due\nto its unconstrained nature, requiring models to infer unseen activities from\nan expansive, partially observed search space. We introduce ProbRes, a\nProbabilistic Residual search framework based on jump-diffusion that\nefficiently navigates this space by balancing prior-guided exploration with\nlikelihood-driven exploitation. Our approach integrates structured commonsense\npriors to construct a semantically coherent search space, adaptively refines\npredictions using Vision-Language Models (VLMs) and employs a stochastic search\nmechanism to locate high-likelihood activity labels while minimizing exhaustive\nenumeration efficiently. We systematically evaluate ProbRes across multiple\nopenness levels (L0--L3), demonstrating its adaptability to increasing search\nspace complexity. In addition to achieving state-of-the-art performance on\nbenchmark datasets (GTEA Gaze, GTEA Gaze+, EPIC-Kitchens, and Charades-Ego), we\nestablish a clear taxonomy for open-world recognition, delineating the\nchallenges and methodological advancements necessary for egocentric activity\nunderstanding.", "AI": {"tldr": "ProbRes, a probabilistic residual search framework, efficiently navigates open-world egocentric activity recognition by balancing exploration and exploitation, achieving state-of-the-art results.", "motivation": "Addressing the challenge of inferring unseen activities in unconstrained, open-world egocentric scenarios.", "method": "Uses jump-diffusion, commonsense priors, Vision-Language Models (VLMs), and stochastic search to refine predictions.", "result": "Achieves top performance on benchmark datasets (GTEA Gaze, GTEA Gaze+, EPIC-Kitchens, Charades-Ego) and establishes a taxonomy for open-world recognition.", "conclusion": "ProbRes advances egocentric activity understanding by efficiently navigating complex search spaces and setting benchmarks for future work."}}
{"id": "2505.23058", "pdf": "https://arxiv.org/pdf/2505.23058", "abs": "https://arxiv.org/abs/2505.23058", "authors": ["Yutong Xie", "Zhuoheng Li", "Xiyuan Wang", "Yijun Pan", "Qijia Liu", "Xingzhi Cui", "Kuang-Yu Lo", "Ruoyi Gao", "Xingjian Zhang", "Jin Huang", "Walter Yuan", "Matthew O. Jackson", "Qiaozhu Mei"], "title": "Be.FM: Open Foundation Models for Human Behavior", "categories": ["cs.AI", "cs.CE", "cs.CL"], "comment": null, "summary": "Despite their success in numerous fields, the potential of foundation models\nfor modeling and understanding human behavior remains largely unexplored. We\nintroduce Be.FM, one of the first open foundation models designed for human\nbehavior modeling. Built upon open-source large language models and fine-tuned\non a diverse range of behavioral data, Be.FM can be used to understand and\npredict human decision-making. We construct a comprehensive set of benchmark\ntasks for testing the capabilities of behavioral foundation models. Our results\ndemonstrate that Be.FM can predict behaviors, infer characteristics of\nindividuals and populations, generate insights about contexts, and apply\nbehavioral science knowledge.", "AI": {"tldr": "Be.FM is an open foundation model for human behavior modeling, built on large language models, capable of predicting and understanding human decision-making.", "motivation": "To explore the untapped potential of foundation models in human behavior modeling.", "method": "Built on open-source large language models and fine-tuned on diverse behavioral data.", "result": "Be.FM can predict behaviors, infer individual/population characteristics, generate contextual insights, and apply behavioral science knowledge.", "conclusion": "Be.FM demonstrates the viability of foundation models for human behavior understanding and prediction."}}
{"id": "2505.22785", "pdf": "https://arxiv.org/pdf/2505.22785", "abs": "https://arxiv.org/abs/2505.22785", "authors": ["Marco Fumero", "Luca Moschella", "Emanuele Rodol\u00e0", "Francesco Locatello"], "title": "Navigating the Latent Space Dynamics of Neural Models", "categories": ["cs.LG"], "comment": null, "summary": "Neural networks transform high-dimensional data into compact, structured\nrepresentations, often modeled as elements of a lower dimensional latent space.\nIn this paper, we present an alternative interpretation of neural models as\ndynamical systems acting on the latent manifold. Specifically, we show that\nautoencoder models implicitly define a latent vector field on the manifold,\nderived by iteratively applying the encoding-decoding map, without any\nadditional training. We observe that standard training procedures introduce\ninductive biases that lead to the emergence of attractor points within this\nvector field. Drawing on this insight, we propose to leverage the vector field\nas a representation for the network, providing a novel tool to analyze the\nproperties of the model and the data. This representation enables to: (i)\nanalyze the generalization and memorization regimes of neural models, even\nthroughout training; (ii) extract prior knowledge encoded in the network's\nparameters from the attractors, without requiring any input data; (iii)\nidentify out-of-distribution samples from their trajectories in the vector\nfield. We further validate our approach on vision foundation models, showcasing\nthe applicability and effectiveness of our method in real-world scenarios.", "AI": {"tldr": "The paper interprets neural networks as dynamical systems on latent manifolds, revealing implicit vector fields and attractor points, enabling novel analysis of model properties and data.", "motivation": "To provide an alternative interpretation of neural models as dynamical systems, uncovering implicit structures like vector fields and attractor points for better model analysis.", "method": "Analyzes autoencoder models as dynamical systems, deriving latent vector fields from encoding-decoding maps without extra training.", "result": "Reveals attractor points in vector fields, enabling analysis of generalization, memorization, prior knowledge extraction, and out-of-distribution detection.", "conclusion": "The proposed method offers a powerful tool for analyzing neural models and data, validated on real-world vision foundation models."}}
{"id": "2502.02673", "pdf": "https://arxiv.org/pdf/2502.02673", "abs": "https://arxiv.org/abs/2502.02673", "authors": ["Adibvafa Fallahpour", "Jun Ma", "Alif Munim", "Hongwei Lyu", "Bo Wang"], "title": "MedRAX: Medical Reasoning Agent for Chest X-ray", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": "16 pages, 4 figures, 5 Tables", "summary": "Chest X-rays (CXRs) play an integral role in driving critical decisions in\ndisease management and patient care. While recent innovations have led to\nspecialized models for various CXR interpretation tasks, these solutions often\noperate in isolation, limiting their practical utility in clinical practice. We\npresent MedRAX, the first versatile AI agent that seamlessly integrates\nstate-of-the-art CXR analysis tools and multimodal large language models into a\nunified framework. MedRAX dynamically leverages these models to address complex\nmedical queries without requiring additional training. To rigorously evaluate\nits capabilities, we introduce ChestAgentBench, a comprehensive benchmark\ncontaining 2,500 complex medical queries across 7 diverse categories. Our\nexperiments demonstrate that MedRAX achieves state-of-the-art performance\ncompared to both open-source and proprietary models, representing a significant\nstep toward the practical deployment of automated CXR interpretation systems.\nData and code have been publicly available at\nhttps://github.com/bowang-lab/MedRAX", "AI": {"tldr": "MedRAX is a versatile AI agent integrating CXR analysis tools and multimodal LLMs, achieving state-of-the-art performance on complex medical queries without additional training.", "motivation": "Specialized CXR models operate in isolation, limiting clinical utility. MedRAX aims to unify these tools for practical deployment.", "method": "Integrates state-of-the-art CXR tools and multimodal LLMs into a unified framework, evaluated using ChestAgentBench (2,500 queries across 7 categories).", "result": "Outperforms open-source and proprietary models, demonstrating superior performance in automated CXR interpretation.", "conclusion": "MedRAX represents a significant advancement toward practical, automated CXR analysis in clinical settings."}}
{"id": "2502.01699", "pdf": "https://arxiv.org/pdf/2502.01699", "abs": "https://arxiv.org/abs/2502.01699", "authors": ["Tianlin Zhang", "En Yu", "Yi Shao", "Jiande Sun"], "title": "Multimodal Inverse Attention Network with Intrinsic Discriminant Feature Exploitation for Fake News Detection", "categories": ["cs.LG", "cs.CL", "cs.CV", "cs.IR", "cs.MM"], "comment": "13 pages, 6 figures", "summary": "Multimodal fake news detection has garnered significant attention due to its\nprofound implications for social security. While existing approaches have\ncontributed to understanding cross-modal consistency, they often fail to\nleverage modal-specific representations and explicit discrepant features. To\naddress these limitations, we propose a Multimodal Inverse Attention Network\n(MIAN), a novel framework that explores intrinsic discriminative features based\non news content to advance fake news detection. Specifically, MIAN introduces a\nhierarchical learning module that captures diverse intra-modal relationships\nthrough local-to-global and local-to-local interactions, thereby generating\nenhanced unimodal representations to improve the identification of fake news at\nthe intra-modal level. Additionally, a cross-modal interaction module employs a\nco-attention mechanism to establish and model dependencies between the refined\nunimodal representations, facilitating seamless semantic integration across\nmodalities. To explicitly extract inconsistency features, we propose an inverse\nattention mechanism that effectively highlights the conflicting patterns and\nsemantic deviations introduced by fake news in both intra- and inter-modality.\nExtensive experiments on benchmark datasets demonstrate that MIAN significantly\noutperforms state-of-the-art methods, underscoring its pivotal contribution to\nadvancing social security through enhanced multimodal fake news detection.", "AI": {"tldr": "MIAN, a Multimodal Inverse Attention Network, improves fake news detection by leveraging modal-specific features and explicit discrepancies through hierarchical and cross-modal interactions.", "motivation": "Existing methods lack modal-specific representations and explicit discrepant features, limiting fake news detection accuracy.", "method": "MIAN uses hierarchical learning for intra-modal relationships and cross-modal co-attention for semantic integration, with an inverse attention mechanism to highlight inconsistencies.", "result": "MIAN outperforms state-of-the-art methods on benchmark datasets.", "conclusion": "MIAN advances multimodal fake news detection, enhancing social security."}}
{"id": "2505.20745", "pdf": "https://arxiv.org/pdf/2505.20745", "abs": "https://arxiv.org/abs/2505.20745", "authors": ["Jingping Nie", "Dung T. Tran", "Karan Thakkar", "Vasudha Kowtha", "Jon Huang", "Carlos Avendano", "Erdrin Azemi", "Vikramjit Mitra"], "title": "Foundation Model Hidden Representations for Heart Rate Estimation from Auscultation", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "5 pages, Interspeech 2025 conference", "summary": "Auscultation, particularly heart sound, is a non-invasive technique that\nprovides essential vital sign information. Recently, self-supervised acoustic\nrepresentation foundation models (FMs) have been proposed to offer insights\ninto acoustics-based vital signs. However, there has been little exploration of\nthe extent to which auscultation is encoded in these pre-trained FM\nrepresentations. In this work, using a publicly available phonocardiogram (PCG)\ndataset and a heart rate (HR) estimation model, we conduct a layer-wise\ninvestigation of six acoustic representation FMs: HuBERT, wav2vec2, wavLM,\nWhisper, Contrastive Language-Audio Pretraining (CLAP), and an in-house CLAP\nmodel. Additionally, we implement the baseline method from Nie et al., 2024\n(which relies on acoustic features) and show that overall, representation\nvectors from pre-trained foundation models (FMs) offer comparable performance\nto the baseline. Notably, HR estimation using the representations from the\naudio encoder of the in-house CLAP model outperforms the results obtained from\nthe baseline, achieving a lower mean absolute error (MAE) across various\ntrain/validation/test splits despite the domain mismatch.", "AI": {"tldr": "The paper investigates how well pre-trained acoustic foundation models (FMs) encode auscultation data, comparing six FMs for heart rate (HR) estimation. The in-house CLAP model outperforms the baseline.", "motivation": "To explore the extent to which auscultation data is captured by pre-trained acoustic FMs, as this has not been thoroughly studied.", "method": "Layer-wise analysis of six FMs (HuBERT, wav2vec2, wavLM, Whisper, CLAP, in-house CLAP) using a PCG dataset and HR estimation model, comparing against a baseline method.", "result": "Pre-trained FMs perform comparably to the baseline, with the in-house CLAP model achieving lower MAE in HR estimation.", "conclusion": "Pre-trained FMs, especially the in-house CLAP model, effectively encode auscultation data and can outperform traditional acoustic feature-based methods."}}
{"id": "2505.22943", "pdf": "https://arxiv.org/pdf/2505.22943", "abs": "https://arxiv.org/abs/2505.22943", "authors": ["Jaewoo Ahn", "Heeseung Yun", "Dayoon Ko", "Gunhee Kim"], "title": "Can LLMs Deceive CLIP? Benchmarking Adversarial Compositionality of Pre-trained Multimodal Representation via Text Updates", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.SD"], "comment": "ACL 2025 Main. Code is released at\n  https://vision.snu.ac.kr/projects/mac", "summary": "While pre-trained multimodal representations (e.g., CLIP) have shown\nimpressive capabilities, they exhibit significant compositional vulnerabilities\nleading to counterintuitive judgments. We introduce Multimodal Adversarial\nCompositionality (MAC), a benchmark that leverages large language models (LLMs)\nto generate deceptive text samples to exploit these vulnerabilities across\ndifferent modalities and evaluates them through both sample-wise attack success\nrate and group-wise entropy-based diversity. To improve zero-shot methods, we\npropose a self-training approach that leverages rejection-sampling fine-tuning\nwith diversity-promoting filtering, which enhances both attack success rate and\nsample diversity. Using smaller language models like Llama-3.1-8B, our approach\ndemonstrates superior performance in revealing compositional vulnerabilities\nacross various multimodal representations, including images, videos, and\naudios.", "AI": {"tldr": "MAC benchmark uses LLMs to exploit multimodal representation vulnerabilities, proposing a self-training method to improve zero-shot performance.", "motivation": "Address compositional vulnerabilities in pre-trained multimodal representations like CLIP, which lead to counterintuitive judgments.", "method": "Introduces MAC benchmark with LLM-generated deceptive text samples, evaluates via attack success rate and entropy-based diversity. Proposes self-training with rejection-sampling fine-tuning and diversity-promoting filtering.", "result": "Superior performance in revealing vulnerabilities across modalities (images, videos, audios) using smaller models like Llama-3.1-8B.", "conclusion": "MAC and self-training enhance attack success and diversity, effectively exposing multimodal representation weaknesses."}}
{"id": "2505.22848", "pdf": "https://arxiv.org/pdf/2505.22848", "abs": "https://arxiv.org/abs/2505.22848", "authors": ["Pingjun Hong", "Beiduo Chen", "Siyao Peng", "Marie-Catherine de Marneffe", "Barbara Plank"], "title": "LiTEx: A Linguistic Taxonomy of Explanations for Understanding Within-Label Variation in Natural Language Inference", "categories": ["cs.CL"], "comment": "21 pages, 6 figures", "summary": "There is increasing evidence of Human Label Variation (HLV) in Natural\nLanguage Inference (NLI), where annotators assign different labels to the same\npremise-hypothesis pair. However, within-label variation--cases where\nannotators agree on the same label but provide divergent reasoning--poses an\nadditional and mostly overlooked challenge. Several NLI datasets contain\nhighlighted words in the NLI item as explanations, but the same spans on the\nNLI item can be highlighted for different reasons, as evidenced by free-text\nexplanations, which offer a window into annotators' reasoning. To\nsystematically understand this problem and gain insight into the rationales\nbehind NLI labels, we introduce LITEX, a linguistically-informed taxonomy for\ncategorizing free-text explanations. Using this taxonomy, we annotate a subset\nof the e-SNLI dataset, validate the taxonomy's reliability, and analyze how it\naligns with NLI labels, highlights, and explanations. We further assess the\ntaxonomy's usefulness in explanation generation, demonstrating that\nconditioning generation on LITEX yields explanations that are linguistically\ncloser to human explanations than those generated using only labels or\nhighlights. Our approach thus not only captures within-label variation but also\nshows how taxonomy-guided generation for reasoning can bridge the gap between\nhuman and model explanations more effectively than existing strategies.", "AI": {"tldr": "The paper introduces LITEX, a taxonomy for categorizing free-text explanations in NLI, addressing within-label variation and improving explanation generation.", "motivation": "To address overlooked within-label variation in NLI and understand annotators' reasoning behind labels.", "method": "Develop LITEX, a linguistically-informed taxonomy; annotate e-SNLI subset; validate taxonomy reliability; analyze alignment with labels, highlights, and explanations.", "result": "LITEX captures within-label variation and improves explanation generation, aligning better with human reasoning than label/highlight-based methods.", "conclusion": "LITEX bridges the gap between human and model explanations, offering a systematic approach to understanding NLI reasoning."}}
{"id": "2503.13330", "pdf": "https://arxiv.org/pdf/2503.13330", "abs": "https://arxiv.org/abs/2503.13330", "authors": ["Ricardo Bigolin Lanfredi", "Yan Zhuang", "Mark Finkelstein", "Praveen Thoppey Srinivasan Balamuralikrishna", "Luke Krembs", "Brandon Khoury", "Arthi Reddy", "Pritam Mukherjee", "Neil M. Rofsky", "Ronald M. Summers"], "title": "LEAVS: An LLM-based Labeler for Abdominal CT Supervision", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "Early acceptance (top 9% of submissions) for MICCAI 2025", "summary": "Extracting structured labels from radiology reports has been employed to\ncreate vision models to simultaneously detect several types of abnormalities.\nHowever, existing works focus mainly on the chest region. Few works have been\ninvestigated on abdominal radiology reports due to more complex anatomy and a\nwider range of pathologies in the abdomen. We propose LEAVS (Large language\nmodel Extractor for Abdominal Vision Supervision). This labeler can annotate\nthe certainty of presence and the urgency of seven types of abnormalities for\nnine abdominal organs on CT radiology reports. To ensure broad coverage, we\nchose abnormalities that encompass most of the finding types from CT reports.\nOur approach employs a specialized chain-of-thought prompting strategy for a\nlocally-run LLM using sentence extraction and multiple-choice questions in a\ntree-based decision system. We demonstrate that the LLM can extract several\nabnormality types across abdominal organs with an average F1 score of 0.89,\nsignificantly outperforming competing labelers and humans. Additionally, we\nshow that extraction of urgency labels achieved performance comparable to human\nannotations. Finally, we demonstrate that the abnormality labels contain\nvaluable information for training a single vision model that classifies several\norgans as normal or abnormal. We release our code and structured annotations\nfor a public CT dataset containing over 1,000 CT volumes.", "AI": {"tldr": "LEAVS, a large language model, extracts structured labels from abdominal radiology reports with high accuracy, outperforming humans and other labelers, and aids in training vision models.", "motivation": "Existing label extraction methods focus on chest radiology, leaving abdominal reports understudied due to their complexity and variety of pathologies.", "method": "LEAVS uses a specialized chain-of-thought prompting strategy with sentence extraction and multiple-choice questions in a tree-based decision system.", "result": "Achieves an average F1 score of 0.89 for abnormality detection and matches human performance in urgency labeling. Also useful for training vision models.", "conclusion": "LEAVS effectively addresses the gap in abdominal radiology labeling, providing high-quality annotations for training models and releasing a public dataset."}}
{"id": "2505.22859", "pdf": "https://arxiv.org/pdf/2505.22859", "abs": "https://arxiv.org/abs/2505.22859", "authors": ["Hidenobu Matsuki", "Gwangbin Bae", "Andrew J. Davison"], "title": "4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians", "categories": ["cs.CV"], "comment": "CVPR 2025. Project Page: https://muskie82.github.io/4dtam/", "summary": "We propose the first 4D tracking and mapping method that jointly performs\ncamera localization and non-rigid surface reconstruction via differentiable\nrendering. Our approach captures 4D scenes from an online stream of color\nimages with depth measurements or predictions by jointly optimizing scene\ngeometry, appearance, dynamics, and camera ego-motion. Although natural\nenvironments exhibit complex non-rigid motions, 4D-SLAM remains relatively\nunderexplored due to its inherent challenges; even with 2.5D signals, the\nproblem is ill-posed because of the high dimensionality of the optimization\nspace. To overcome these challenges, we first introduce a SLAM method based on\nGaussian surface primitives that leverages depth signals more effectively than\n3D Gaussians, thereby achieving accurate surface reconstruction. To further\nmodel non-rigid deformations, we employ a warp-field represented by a\nmulti-layer perceptron (MLP) and introduce a novel camera pose estimation\ntechnique along with surface regularization terms that facilitate\nspatio-temporal reconstruction. In addition to these algorithmic challenges, a\nsignificant hurdle in 4D SLAM research is the lack of reliable ground truth and\nevaluation protocols, primarily due to the difficulty of 4D capture using\ncommodity sensors. To address this, we present a novel open synthetic dataset\nof everyday objects with diverse motions, leveraging large-scale object models\nand animation modeling. In summary, we open up the modern 4D-SLAM research by\nintroducing a novel method and evaluation protocols grounded in modern vision\nand rendering techniques.", "AI": {"tldr": "A novel 4D-SLAM method for joint camera localization and non-rigid surface reconstruction using differentiable rendering, Gaussian surface primitives, and MLP warp-fields, validated with a new synthetic dataset.", "motivation": "Addressing the underexplored challenges of 4D-SLAM, such as high-dimensional optimization and lack of ground truth, to enable accurate spatio-temporal reconstruction of dynamic scenes.", "method": "Uses Gaussian surface primitives for depth signal optimization, MLP warp-fields for non-rigid deformations, and introduces a new camera pose estimation technique with surface regularization.", "result": "Achieves accurate 4D scene reconstruction and camera localization, validated by a novel synthetic dataset of diverse motions.", "conclusion": "Advances 4D-SLAM research with a robust method and evaluation protocols, leveraging modern vision and rendering techniques."}}
{"id": "2505.23075", "pdf": "https://arxiv.org/pdf/2505.23075", "abs": "https://arxiv.org/abs/2505.23075", "authors": ["Amit Kumthekar", "Zion Tilley", "Henry Duong", "Bhargav Patel", "Michael Magnoli", "Ahmed Omar", "Ahmed Nasser", "Chaitanya Gharpure", "Yevgen Reztzov"], "title": "Second Opinion Matters: Towards Adaptive Clinical AI via the Consensus of Expert Model Ensemble", "categories": ["cs.AI", "cs.LG"], "comment": "23 pages, 11 figures", "summary": "Despite the growing clinical adoption of large language models (LLMs),\ncurrent approaches heavily rely on single model architectures. To overcome\nrisks of obsolescence and rigid dependence on single model systems, we present\na novel framework, termed the Consensus Mechanism. Mimicking clinical triage\nand multidisciplinary clinical decision-making, the Consensus Mechanism\nimplements an ensemble of specialized medical expert agents enabling improved\nclinical decision making while maintaining robust adaptability. This\narchitecture enables the Consensus Mechanism to be optimized for cost, latency,\nor performance, purely based on its interior model configuration.\n  To rigorously evaluate the Consensus Mechanism, we employed three medical\nevaluation benchmarks: MedMCQA, MedQA, and MedXpertQA Text, and the\ndifferential diagnosis dataset, DDX+. On MedXpertQA, the Consensus Mechanism\nachieved an accuracy of 61.0% compared to 53.5% and 45.9% for OpenAI's O3 and\nGoogle's Gemini 2.5 Pro. Improvement was consistent across benchmarks with an\nincrease in accuracy on MedQA\n($\\Delta\\mathrm{Accuracy}_{\\mathrm{consensus\\text{-}O3}} = 3.4\\%$) and MedMCQA\n($\\Delta\\mathrm{Accuracy}_{\\mathrm{consensus\\text{-}O3}} = 9.1\\%$). These\naccuracy gains extended to differential diagnosis generation, where our system\ndemonstrated improved recall and precision (F1$_\\mathrm{consensus}$ = 0.326 vs.\nF1$_{\\mathrm{O3\\text{-}high}}$ = 0.2886) and a higher top-1 accuracy for DDX\n(Top1$_\\mathrm{consensus}$ = 52.0% vs. Top1$_{\\mathrm{O3\\text{-}high}}$ =\n45.2%).", "AI": {"tldr": "The paper introduces the Consensus Mechanism, an ensemble of specialized medical expert agents, outperforming single-model LLMs in clinical decision-making across multiple benchmarks.", "motivation": "To address the risks of obsolescence and rigid dependence on single-model systems in clinical LLMs by mimicking multidisciplinary decision-making.", "method": "The Consensus Mechanism uses an ensemble of specialized medical expert agents, optimized for cost, latency, or performance.", "result": "Achieved higher accuracy (e.g., 61.0% on MedXpertQA) and improved recall/precision in differential diagnosis compared to single-model systems.", "conclusion": "The Consensus Mechanism offers a robust, adaptable alternative to single-model LLMs, enhancing clinical decision-making."}}
{"id": "2505.22798", "pdf": "https://arxiv.org/pdf/2505.22798", "abs": "https://arxiv.org/abs/2505.22798", "authors": ["Anton Bj\u00f6rklund", "Mykola Zaitsev", "Marta Kwiatkowska"], "title": "Efficient Preimage Approximation for Neural Network Certification", "categories": ["cs.LG", "cs.AI", "cs.CR", "68T07"], "comment": null, "summary": "The growing reliance on artificial intelligence in safety- and\nsecurity-critical applications demands effective neural network certification.\nA challenging real-world use case is certification against ``patch attacks'',\nwhere adversarial patches or lighting conditions obscure parts of images, for\nexample traffic signs. One approach to certification, which also gives\nquantitative coverage estimates, utilizes preimages of neural networks, i.e.,\nthe set of inputs that lead to a specified output. However, these preimage\napproximation methods, including the state-of-the-art PREMAP algorithm,\nstruggle with scalability. This paper presents novel algorithmic improvements\nto PREMAP involving tighter bounds, adaptive Monte Carlo sampling, and improved\nbranching heuristics. We demonstrate efficiency improvements of at least an\norder of magnitude on reinforcement learning control benchmarks, and show that\nour method scales to convolutional neural networks that were previously\ninfeasible. Our results demonstrate the potential of preimage approximation\nmethodology for reliability and robustness certification.", "AI": {"tldr": "The paper improves the PREMAP algorithm for neural network certification against patch attacks, achieving significant efficiency gains and scalability to larger networks.", "motivation": "The need for reliable neural network certification in safety-critical applications, especially against patch attacks, drives the research.", "method": "The authors enhance PREMAP with tighter bounds, adaptive Monte Carlo sampling, and better branching heuristics.", "result": "Efficiency improves by at least an order of magnitude, and the method scales to previously infeasible convolutional neural networks.", "conclusion": "The improved PREMAP demonstrates the potential of preimage approximation for robust and reliable certification."}}
{"id": "2504.03553", "pdf": "https://arxiv.org/pdf/2504.03553", "abs": "https://arxiv.org/abs/2504.03553", "authors": ["Shuofei Qiao", "Zhisong Qiu", "Baochang Ren", "Xiaobin Wang", "Xiangyuan Ru", "Ningyu Zhang", "Xiang Chen", "Yong Jiang", "Pengjun Xie", "Fei Huang", "Huajun Chen"], "title": "Agentic Knowledgeable Self-awareness", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MA"], "comment": "ACL 2025", "summary": "Large Language Models (LLMs) have achieved considerable performance across\nvarious agentic planning tasks. However, traditional agent planning approaches\nadopt a \"flood irrigation\" methodology that indiscriminately injects gold\ntrajectories, external feedback, and domain knowledge into agent models. This\npractice overlooks the fundamental human cognitive principle of situational\nself-awareness during decision-making-the ability to dynamically assess\nsituational demands and strategically employ resources during decision-making.\nWe propose agentic knowledgeable self-awareness to address this gap, a novel\nparadigm enabling LLM-based agents to autonomously regulate knowledge\nutilization. Specifically, we propose KnowSelf, a data-centric approach that\napplies agents with knowledgeable self-awareness like humans. Concretely, we\ndevise a heuristic situation judgement criterion to mark special tokens on the\nagent's self-explored trajectories for collecting training data. Through a\ntwo-stage training process, the agent model can switch between different\nsituations by generating specific special tokens, achieving optimal planning\neffects with minimal costs. Our experiments demonstrate that KnowSelf can\noutperform various strong baselines on different tasks and models with minimal\nuse of external knowledge. Code is available at\nhttps://github.com/zjunlp/KnowSelf.", "AI": {"tldr": "KnowSelf introduces agentic knowledgeable self-awareness for LLM-based agents, enabling dynamic knowledge regulation for optimal planning with minimal costs.", "motivation": "Traditional agent planning lacks situational self-awareness, leading to inefficient knowledge use. KnowSelf addresses this gap.", "method": "Uses a heuristic situation judgement criterion and two-stage training to mark and utilize self-explored trajectories.", "result": "Outperforms baselines with minimal external knowledge use.", "conclusion": "KnowSelf enhances LLM-based agent planning by mimicking human-like self-awareness."}}
{"id": "2502.16359", "pdf": "https://arxiv.org/pdf/2502.16359", "abs": "https://arxiv.org/abs/2502.16359", "authors": ["Kyungbok Lee", "You Zhang", "Zhiyao Duan"], "title": "Audio Visual Segmentation Through Text Embeddings", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": null, "summary": "The goal of Audio-Visual Segmentation (AVS) is to localize and segment the\nsounding source objects from video frames. Research on AVS suffers from data\nscarcity due to the high cost of fine-grained manual annotations. Recent works\nattempt to overcome the challenge of limited data by leveraging the vision\nfoundation model, Segment Anything Model (SAM), prompting it with audio to\nenhance its ability to segment sounding source objects. While this approach\nalleviates the model's burden on understanding visual modality by utilizing\nknowledge of pre-trained SAM, it does not address the fundamental challenge of\nlearning audio-visual correspondence with limited data. To address this\nlimitation, we propose \\textbf{AV2T-SAM}, a novel framework that bridges audio\nfeatures with the text embedding space of pre-trained text-prompted SAM. Our\nmethod leverages multimodal correspondence learned from rich text-image paired\ndatasets to enhance audio-visual alignment. Furthermore, we introduce a novel\nfeature, $\\mathbf{\\textit{\\textbf{f}}_{CLIP} \\odot\n\\textit{\\textbf{f}}_{CLAP}}$, which emphasizes shared semantics of audio and\nvisual modalities while filtering irrelevant noise. Our approach outperforms\nexisting methods on the AVSBench dataset by effectively utilizing pre-trained\nsegmentation models and cross-modal semantic alignment. The source code is\nreleased at https://github.com/bok-bok/AV2T-SAM.", "AI": {"tldr": "AV2T-SAM improves Audio-Visual Segmentation by bridging audio features with text-prompted SAM, leveraging multimodal correspondence and a novel feature for better alignment.", "motivation": "Addressing the challenge of learning audio-visual correspondence with limited data, which existing methods fail to solve despite leveraging SAM.", "method": "Proposes AV2T-SAM, integrating audio features with SAM's text embedding space and introducing a novel feature (f_CLIP \u2299 f_CLAP) for enhanced alignment.", "result": "Outperforms existing methods on the AVSBench dataset by improving cross-modal semantic alignment.", "conclusion": "AV2T-SAM effectively utilizes pre-trained models and cross-modal alignment to advance AVS performance."}}
{"id": "2505.20956", "pdf": "https://arxiv.org/pdf/2505.20956", "abs": "https://arxiv.org/abs/2505.20956", "authors": ["Shiqi Zhang", "Tuomas Virtanen"], "title": "Hybrid Disagreement-Diversity Active Learning for Bioacoustic Sound Event Detection", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": "5 pages, 1 figure, accepted by EUSIPCO 2025 v2: add our github repo", "summary": "Bioacoustic sound event detection (BioSED) is crucial for biodiversity\nconservation but faces practical challenges during model development and\ntraining: limited amounts of annotated data, sparse events, species diversity,\nand class imbalance. To address these challenges efficiently with a limited\nlabeling budget, we apply the mismatch-first farthest-traversal (MFFT), an\nactive learning method integrating committee voting disagreement and diversity\nanalysis. We also refine an existing BioSED dataset specifically for evaluating\nactive learning algorithms. Experimental results demonstrate that MFFT achieves\na mAP of 68% when cold-starting and 71% when warm-starting (which is close to\nthe fully-supervised mAP of 75%) while using only 2.3% of the annotations.\nNotably, MFFT excels in cold-start scenarios and with rare species, which are\ncritical for monitoring endangered species, demonstrating its practical value.", "AI": {"tldr": "The paper introduces MFFT, an active learning method for BioSED, addressing challenges like limited annotated data and class imbalance. MFFT achieves high mAP with minimal annotations, excelling in cold-start and rare species scenarios.", "motivation": "BioSED faces challenges like sparse annotated data, species diversity, and class imbalance, hindering biodiversity conservation efforts.", "method": "MFFT, an active learning method combining committee voting disagreement and diversity analysis, is applied to efficiently use limited labeling budgets.", "result": "MFFT achieves 68% mAP (cold-start) and 71% mAP (warm-start), close to fully-supervised 75% mAP, using only 2.3% annotations. It performs well with rare species.", "conclusion": "MFFT is practical for BioSED, especially in cold-start and rare species scenarios, making it valuable for biodiversity monitoring."}}
{"id": "2505.23170", "pdf": "https://arxiv.org/pdf/2505.23170", "abs": "https://arxiv.org/abs/2505.23170", "authors": ["Jian Zhu", "Farhan Samir", "Eleanor Chodroff", "David R. Mortensen"], "title": "ZIPA: A family of efficient models for multilingual phone recognition", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "ACL 2025 Main", "summary": "We present ZIPA, a family of efficient speech models that advances the\nstate-of-the-art performance of crosslinguistic phone recognition. We first\ncurated IPAPack++, a large-scale multilingual speech corpus with 17,132 hours\nof normalized phone transcriptions and a novel evaluation set capturing unseen\nlanguages and sociophonetic variation. With the large-scale training data,\nZIPA, including transducer (ZIPA-T) and CTC-based (ZIPA-CR) variants, leverage\nthe efficient Zipformer backbones and outperform existing phone recognition\nsystems with much fewer parameters. Further scaling via noisy student training\non 11,000 hours of pseudo-labeled multilingual data yields further improvement.\nWhile ZIPA achieves strong performance on benchmarks, error analysis reveals\npersistent limitations in modeling sociophonetic diversity, underscoring\nchallenges for future research.", "AI": {"tldr": "ZIPA introduces efficient speech models for crosslinguistic phone recognition, leveraging a large multilingual corpus and outperforming existing systems with fewer parameters.", "motivation": "Advance state-of-the-art performance in crosslinguistic phone recognition by addressing data and model efficiency challenges.", "method": "Utilizes IPAPack++ corpus, Zipformer backbones, and noisy student training for scaling. Includes ZIPA-T (transducer) and ZIPA-CR (CTC-based) variants.", "result": "Outperforms existing phone recognition systems with fewer parameters. Error analysis highlights limitations in sociophonetic diversity.", "conclusion": "ZIPA advances phone recognition but reveals challenges in modeling sociophonetic variation, pointing to future research directions."}}
{"id": "2505.22867", "pdf": "https://arxiv.org/pdf/2505.22867", "abs": "https://arxiv.org/abs/2505.22867", "authors": ["Iknoor Singh", "Carolina Scarton", "Kalina Bontcheva"], "title": "GateNLP at SemEval-2025 Task 10: Hierarchical Three-Step Prompting for Multilingual Narrative Classification", "categories": ["cs.CL"], "comment": null, "summary": "The proliferation of online news and the increasing spread of misinformation\nnecessitate robust methods for automatic data analysis. Narrative\nclassification is emerging as a important task, since identifying what is being\nsaid online is critical for fact-checkers, policy markers and other\nprofessionals working on information studies. This paper presents our approach\nto SemEval 2025 Task 10 Subtask 2, which aims to classify news articles into a\npre-defined two-level taxonomy of main narratives and sub-narratives across\nmultiple languages.\n  We propose Hierarchical Three-Step Prompting (H3Prompt) for multilingual\nnarrative classification. Our methodology follows a three-step Large Language\nModel (LLM) prompting strategy, where the model first categorises an article\ninto one of two domains (Ukraine-Russia War or Climate Change), then identifies\nthe most relevant main narratives, and finally assigns sub-narratives. Our\napproach secured the top position on the English test set among 28 competing\nteams worldwide. The code is available at https://github.com/GateNLP/H3Prompt.", "AI": {"tldr": "The paper introduces Hierarchical Three-Step Prompting (H3Prompt) for multilingual narrative classification, achieving top performance in SemEval 2025 Task 10 Subtask 2.", "motivation": "The need for robust methods to classify online news narratives due to misinformation proliferation.", "method": "A three-step LLM prompting strategy: domain classification, main narrative identification, and sub-narrative assignment.", "result": "Top performance on the English test set among 28 teams.", "conclusion": "H3Prompt is effective for multilingual narrative classification, with code publicly available."}}
{"id": "2504.04532", "pdf": "https://arxiv.org/pdf/2504.04532", "abs": "https://arxiv.org/abs/2504.04532", "authors": ["Moinak Bhattacharya", "Saumya Gupta", "Annie Singh", "Chao Chen", "Gagandeep Singh", "Prateek Prasanna"], "title": "BrainMRDiff: A Diffusion Model for Anatomically Consistent Brain MRI Synthesis", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Accurate brain tumor diagnosis relies on the assessment of multiple Magnetic\nResonance Imaging (MRI) sequences. However, in clinical practice, the\nacquisition of certain sequences may be affected by factors like motion\nartifacts or contrast agent contraindications, leading to suboptimal outcome,\nsuch as poor image quality. This can then affect image interpretation by\nradiologists. Synthesizing high quality MRI sequences has thus become a\ncritical research focus. Though recent advancements in controllable generative\nAI have facilitated the synthesis of diagnostic quality MRI, ensuring\nanatomical accuracy remains a significant challenge. Preserving critical\nstructural relationships between different anatomical regions is essential, as\neven minor structural or topological inconsistencies can compromise diagnostic\nvalidity. In this work, we propose BrainMRDiff, a novel topology-preserving,\nanatomy-guided diffusion model for synthesizing brain MRI, leveraging brain and\ntumor anatomies as conditioning inputs. To achieve this, we introduce two key\nmodules: Tumor+Structure Aggregation (TSA) and Topology-Guided Anatomy\nPreservation (TGAP). TSA integrates diverse anatomical structures with tumor\ninformation, forming a comprehensive conditioning mechanism for the diffusion\nprocess. TGAP enforces topological consistency during reverse denoising\ndiffusion process; both these modules ensure that the generated image respects\nanatomical integrity. Experimental results demonstrate that BrainMRDiff\nsurpasses existing baselines, achieving performance improvements of 23.33% on\nthe BraTS-AG dataset and 33.33% on the BraTS-Met dataset. Code will be made\npublicly available soon.", "AI": {"tldr": "BrainMRDiff, a novel diffusion model, synthesizes high-quality brain MRI sequences while preserving anatomical accuracy, outperforming existing methods by 23.33% and 33.33% on two datasets.", "motivation": "Clinical MRI sequences may be incomplete or low-quality due to artifacts or contraindications, impacting diagnosis. Synthesizing accurate MRI sequences is crucial but challenging due to anatomical integrity requirements.", "method": "Proposes BrainMRDiff, a topology-preserving diffusion model with Tumor+Structure Aggregation (TSA) and Topology-Guided Anatomy Preservation (TGAP) modules to ensure anatomical consistency.", "result": "BrainMRDiff outperforms baselines by 23.33% on BraTS-AG and 33.33% on BraTS-Met datasets.", "conclusion": "BrainMRDiff effectively synthesizes anatomically accurate MRI sequences, addressing clinical challenges in brain tumor diagnosis."}}
{"id": "2505.22869", "pdf": "https://arxiv.org/pdf/2505.22869", "abs": "https://arxiv.org/abs/2505.22869", "authors": ["Junbo Yin", "Chao Zha", "Wenjia He", "Chencheng Xu", "Xin Gao"], "title": "CFP-Gen: Combinatorial Functional Protein Generation via Diffusion Language Models", "categories": ["cs.CV", "cs.LG", "q-bio.BM"], "comment": "Accepted at ICML 2025. Code is available at\n  https://github.com/yinjunbo/cfpgen", "summary": "Existing PLMs generate protein sequences based on a single-condition\nconstraint from a specific modality, struggling to simultaneously satisfy\nmultiple constraints across different modalities. In this work, we introduce\nCFP-Gen, a novel diffusion language model for Combinatorial Functional Protein\nGENeration. CFP-Gen facilitates the de novo protein design by integrating\nmultimodal conditions with functional, sequence, and structural constraints.\nSpecifically, an Annotation-Guided Feature Modulation (AGFM) module is\nintroduced to dynamically adjust the protein feature distribution based on\ncomposable functional annotations, e.g., GO terms, IPR domains and EC numbers.\nMeanwhile, the Residue-Controlled Functional Encoding (RCFE) module captures\nresidue-wise interaction to ensure more precise control. Additionally,\noff-the-shelf 3D structure encoders can be seamlessly integrated to impose\ngeometric constraints. We demonstrate that CFP-Gen enables high-throughput\ngeneration of novel proteins with functionality comparable to natural proteins,\nwhile achieving a high success rate in designing multifunctional proteins. Code\nand data available at https://github.com/yinjunbo/cfpgen.", "AI": {"tldr": "CFP-Gen is a diffusion language model for combinatorial protein generation, integrating multimodal constraints for de novo protein design.", "motivation": "Existing PLMs struggle with multiple constraints across modalities; CFP-Gen addresses this gap.", "method": "Uses Annotation-Guided Feature Modulation (AGFM) and Residue-Controlled Functional Encoding (RCFE) to integrate functional, sequence, and structural constraints.", "result": "Generates novel proteins with natural-like functionality and high success in multifunctional designs.", "conclusion": "CFP-Gen advances protein design by efficiently handling multimodal constraints."}}
{"id": "2505.23091", "pdf": "https://arxiv.org/pdf/2505.23091", "abs": "https://arxiv.org/abs/2505.23091", "authors": ["Zeyu Liu", "Yuhang Liu", "Guanghao Zhu", "Congkai Xie", "Zhen Li", "Jianbo Yuan", "Xinyao Wang", "Qing Li", "Shing-Chi Cheung", "Shengyu Zhang", "Fei Wu", "Hongxia Yang"], "title": "Infi-MMR: Curriculum-based Unlocking Multimodal Reasoning via Phased Reinforcement Learning in Multimodal Small Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have demonstrated\nsubstantial progress in reasoning capabilities, such as DeepSeek-R1, which\nleverages rule-based reinforcement learning to enhance logical reasoning\nsignificantly. However, extending these achievements to multimodal large\nlanguage models (MLLMs) presents critical challenges, which are frequently more\npronounced for Multimodal Small Language Models (MSLMs) given their typically\nweaker foundational reasoning abilities: (1) the scarcity of high-quality\nmultimodal reasoning datasets, (2) the degradation of reasoning capabilities\ndue to the integration of visual processing, and (3) the risk that direct\napplication of reinforcement learning may produce complex yet incorrect\nreasoning processes. To address these challenges, we design a novel framework\nInfi-MMR to systematically unlock the reasoning potential of MSLMs through a\ncurriculum of three carefully structured phases and propose our multimodal\nreasoning model Infi-MMR-3B. The first phase, Foundational Reasoning\nActivation, leverages high-quality textual reasoning datasets to activate and\nstrengthen the model's logical reasoning capabilities. The second phase,\nCross-Modal Reasoning Adaptation, utilizes caption-augmented multimodal data to\nfacilitate the progressive transfer of reasoning skills to multimodal contexts.\nThe third phase, Multimodal Reasoning Enhancement, employs curated,\ncaption-free multimodal data to mitigate linguistic biases and promote robust\ncross-modal reasoning. Infi-MMR-3B achieves both state-of-the-art multimodal\nmath reasoning ability (43.68% on MathVerse testmini, 27.04% on MathVision\ntest, and 21.33% on OlympiadBench) and general reasoning ability (67.2% on\nMathVista testmini).", "AI": {"tldr": "The paper introduces Infi-MMR, a framework to enhance reasoning in Multimodal Small Language Models (MSLMs) through a three-phase curriculum, achieving state-of-the-art performance.", "motivation": "Address challenges in extending reasoning capabilities from LLMs to MSLMs, including dataset scarcity, reasoning degradation, and flawed reinforcement learning.", "method": "Three-phase curriculum: Foundational Reasoning Activation, Cross-Modal Reasoning Adaptation, and Multimodal Reasoning Enhancement, applied to Infi-MMR-3B.", "result": "Infi-MMR-3B excels in multimodal math reasoning (e.g., 43.68% on MathVerse) and general reasoning (67.2% on MathVista).", "conclusion": "Infi-MMR effectively unlocks MSLMs' reasoning potential, addressing key challenges and achieving top performance."}}
{"id": "2505.22803", "pdf": "https://arxiv.org/pdf/2505.22803", "abs": "https://arxiv.org/abs/2505.22803", "authors": ["Pedro Mendes", "Paolo Romano", "David Garlan"], "title": "CLUE: Neural Networks Calibration via Learning Uncertainty-Error alignment", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reliable uncertainty estimation is critical for deploying neural networks\n(NNs) in real-world applications. While existing calibration techniques often\nrely on post-hoc adjustments or coarse-grained binning methods, they remain\nlimited in scalability, differentiability, and generalization across domains.\nIn this work, we introduce CLUE (Calibration via Learning Uncertainty-Error\nAlignment), a novel approach that explicitly aligns predicted uncertainty with\nobserved error during training, grounded in the principle that well-calibrated\nmodels should produce uncertainty estimates that match their empirical loss.\nCLUE adopts a novel loss function that jointly optimizes predictive performance\nand calibration, using summary statistics of uncertainty and loss as proxies.\nThe proposed method is fully differentiable, domain-agnostic, and compatible\nwith standard training pipelines. Through extensive experiments on vision,\nregression, and language modeling tasks, including out-of-distribution and\ndomain-shift scenarios, we demonstrate that CLUE achieves superior calibration\nquality and competitive predictive performance with respect to state-of-the-art\napproaches without imposing significant computational overhead.", "AI": {"tldr": "CLUE introduces a novel method for neural network calibration by aligning predicted uncertainty with observed error during training, improving scalability and generalization.", "motivation": "Existing calibration techniques lack scalability, differentiability, and domain generalization, limiting their practical deployment.", "method": "CLUE uses a novel loss function to align uncertainty with empirical loss, optimizing both predictive performance and calibration.", "result": "CLUE outperforms state-of-the-art methods in calibration quality and maintains competitive predictive performance across diverse tasks.", "conclusion": "CLUE provides a scalable, differentiable, and domain-agnostic solution for reliable uncertainty estimation in neural networks."}}
{"id": "2505.19301", "pdf": "https://arxiv.org/pdf/2505.19301", "abs": "https://arxiv.org/abs/2505.19301", "authors": ["Ken Huang", "Vineeth Sai Narajala", "John Yeoh", "Jason Ross", "Ramesh Raskar", "Youssef Harkati", "Jerry Huang", "Idan Habler", "Chris Hughes"], "title": "A Novel Zero-Trust Identity Framework for Agentic AI: Decentralized Authentication and Fine-Grained Access Control", "categories": ["cs.CR", "cs.AI", "cs.MA"], "comment": "24 Pages, 5 figures, 2 tables, edit: added a missed Author", "summary": "Traditional Identity and Access Management (IAM) systems, primarily designed\nfor human users or static machine identities via protocols such as OAuth,\nOpenID Connect (OIDC), and SAML, prove fundamentally inadequate for the\ndynamic, interdependent, and often ephemeral nature of AI agents operating at\nscale within Multi Agent Systems (MAS), a computational system composed of\nmultiple interacting intelligent agents that work collectively.\n  This paper posits the imperative for a novel Agentic AI IAM framework: We\ndeconstruct the limitations of existing protocols when applied to MAS,\nillustrating with concrete examples why their coarse-grained controls,\nsingle-entity focus, and lack of context-awareness falter. We then propose a\ncomprehensive framework built upon rich, verifiable Agent Identities (IDs),\nleveraging Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs),\nthat encapsulate an agents capabilities, provenance, behavioral scope, and\nsecurity posture.\n  Our framework includes an Agent Naming Service (ANS) for secure and\ncapability-aware discovery, dynamic fine-grained access control mechanisms, and\ncritically, a unified global session management and policy enforcement layer\nfor real-time control and consistent revocation across heterogeneous agent\ncommunication protocols. We also explore how Zero-Knowledge Proofs (ZKPs)\nenable privacy-preserving attribute disclosure and verifiable policy\ncompliance.\n  We outline the architecture, operational lifecycle, innovative contributions,\nand security considerations of this new IAM paradigm, aiming to establish the\nfoundational trust, accountability, and security necessary for the burgeoning\nfield of agentic AI and the complex ecosystems they will inhabit.", "AI": {"tldr": "The paper proposes a new IAM framework for AI agents in MAS, addressing limitations of traditional systems with dynamic, decentralized solutions.", "motivation": "Existing IAM systems are inadequate for AI agents in MAS due to their static, human-centric design, lacking context-awareness and scalability.", "method": "The framework uses Decentralized Identifiers (DIDs), Verifiable Credentials (VCs), an Agent Naming Service (ANS), and Zero-Knowledge Proofs (ZKPs) for dynamic, fine-grained access control and privacy.", "result": "A comprehensive IAM framework for AI agents is introduced, enabling secure, scalable, and context-aware identity and access management.", "conclusion": "The proposed framework establishes trust, accountability, and security for AI agents in MAS, addressing the limitations of traditional IAM systems."}}
{"id": "2504.11695", "pdf": "https://arxiv.org/pdf/2504.11695", "abs": "https://arxiv.org/abs/2504.11695", "authors": ["Isabel Papadimitriou", "Huangyuan Su", "Thomas Fel", "Sham Kakade", "Stephanie Gil"], "title": "Interpreting the linear structure of vision-language model embedding spaces", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Vision-language models encode images and text in a joint space, minimizing\nthe distance between corresponding image and text pairs. How are language and\nimages organized in this joint space, and how do the models encode meaning and\nmodality? To investigate this, we train and release sparse autoencoders (SAEs)\non the embedding spaces of four vision-language models (CLIP, SigLIP, SigLIP2,\nand AIMv2). SAEs approximate model embeddings as sparse linear combinations of\nlearned directions, or \"concepts\". We find that, compared to other methods of\nlinear feature learning, SAEs are better at reconstructing the real embeddings,\nwhile also able to retain the most sparsity. Retraining SAEs with different\nseeds or different data diet leads to two findings: the rare, specific concepts\ncaptured by the SAEs are liable to change drastically, but we also show that\nthe key commonly-activating concepts extracted by SAEs are remarkably stable\nacross runs. Interestingly, while most concepts are strongly unimodal in\nactivation, we find they are not merely encoding modality per se. Many lie\nclose to - but not entirely within - the subspace defining modality, suggesting\nthat they encode cross-modal semantics despite their unimodal usage. To\nquantify this bridging behavior, we introduce the Bridge Score, a metric that\nidentifies concept pairs which are both co-activated across aligned image-text\ninputs and geometrically aligned in the shared space. This reveals that even\nunimodal concepts can collaborate to support cross-modal integration. We\nrelease interactive demos of the SAEs for all models, allowing researchers to\nexplore the organization of the concept spaces. Overall, our findings uncover a\nsparse linear structure within VLM embedding spaces that is shaped by modality,\nyet stitched together through latent bridges-offering new insight into how\nmultimodal meaning is constructed.", "AI": {"tldr": "The paper investigates the organization of language and images in vision-language models (VLMs) using sparse autoencoders (SAEs), revealing stable cross-modal concepts and introducing the Bridge Score to quantify their integration.", "motivation": "To understand how VLMs encode meaning and modality in their joint embedding space and explore the structure of this space.", "method": "Train and analyze SAEs on four VLMs (CLIP, SigLIP, SigLIP2, AIMv2) to identify sparse linear concepts and their stability across runs. Introduce the Bridge Score to measure cross-modal integration.", "result": "SAEs outperform other methods in reconstruction and sparsity. Key concepts are stable across runs, and many encode cross-modal semantics despite unimodal activation. The Bridge Score highlights latent bridges for cross-modal integration.", "conclusion": "VLMs exhibit a sparse linear structure shaped by modality but connected through latent bridges, providing new insights into multimodal meaning construction."}}
{"id": "2505.22888", "pdf": "https://arxiv.org/pdf/2505.22888", "abs": "https://arxiv.org/abs/2505.22888", "authors": ["Jirui Qi", "Shan Chen", "Zidi Xiong", "Raquel Fern\u00e1ndez", "Danielle S. Bitterman", "Arianna Bisazza"], "title": "When Models Reason in Your Language: Controlling Thinking Trace Language Comes at the Cost of Accuracy", "categories": ["cs.CL"], "comment": null, "summary": "Recent Large Reasoning Models (LRMs) with thinking traces have shown strong\nperformance on English reasoning tasks. However, their ability to think in\nother languages is less studied. This capability is as important as answer\naccuracy for real world applications because users may find the reasoning trace\nuseful for oversight only when it is expressed in their own language. We\ncomprehensively evaluate two leading families of LRMs on our XReasoning\nbenchmark and find that even the most advanced models often revert to English\nor produce fragmented reasoning in other languages, revealing a substantial gap\nin multilingual reasoning. Prompt based interventions that force models to\nreason in the users language improve readability and oversight but reduce\nanswer accuracy, exposing an important trade off. We further show that targeted\npost training on just 100 examples mitigates this mismatch, though some\naccuracy loss remains. Our results highlight the limited multilingual reasoning\ncapabilities of current LRMs and outline directions for future work. Code and\ndata are available at https://github.com/Betswish/mCoT-XReasoning.", "AI": {"tldr": "Current Large Reasoning Models (LRMs) struggle with multilingual reasoning, often defaulting to English or producing fragmented traces. Prompt interventions improve readability but reduce accuracy, while targeted training mitigates some issues.", "motivation": "To assess and improve the multilingual reasoning capabilities of LRMs, as reasoning traces in users' languages are crucial for oversight in real-world applications.", "method": "Evaluation of two leading LRM families on the XReasoning benchmark, testing reasoning in non-English languages. Interventions include prompt-based forcing and targeted post-training.", "result": "Advanced models often revert to English or produce fragmented reasoning in other languages. Prompt interventions improve readability but reduce accuracy, while targeted training helps but doesn't fully resolve the issue.", "conclusion": "Current LRMs have limited multilingual reasoning capabilities, highlighting a need for future improvements. Targeted training shows promise but doesn't eliminate accuracy trade-offs."}}
{"id": "2505.15057", "pdf": "https://arxiv.org/pdf/2505.15057", "abs": "https://arxiv.org/abs/2505.15057", "authors": ["Frederic Wang", "Jonathan I. Tamir"], "title": "Non-rigid Motion Correction for MRI Reconstruction via Coarse-To-Fine Diffusion Models", "categories": ["eess.IV", "cs.CV"], "comment": "ICIP 2025", "summary": "Magnetic Resonance Imaging (MRI) is highly susceptible to motion artifacts\ndue to the extended acquisition times required for k-space sampling. These\nartifacts can compromise diagnostic utility, particularly for dynamic imaging.\nWe propose a novel alternating minimization framework that leverages a bespoke\ndiffusion model to jointly reconstruct and correct non-rigid motion-corrupted\nk-space data. The diffusion model uses a coarse-to-fine denoising strategy to\ncapture large overall motion and reconstruct the lower frequencies of the image\nfirst, providing a better inductive bias for motion estimation than that of\nstandard diffusion models. We demonstrate the performance of our approach on\nboth real-world cine cardiac MRI datasets and complex simulated rigid and\nnon-rigid deformations, even when each motion state is undersampled by a factor\nof 64x. Additionally, our method is agnostic to sampling patterns, anatomical\nvariations, and MRI scanning protocols, as long as some low frequency\ncomponents are sampled during each motion state.", "AI": {"tldr": "A novel alternating minimization framework using a diffusion model to correct motion artifacts in MRI by jointly reconstructing and correcting k-space data.", "motivation": "MRI is prone to motion artifacts due to long acquisition times, which can degrade diagnostic quality, especially in dynamic imaging.", "method": "Proposes a coarse-to-fine denoising diffusion model to capture large motion and reconstruct lower frequencies first, improving motion estimation.", "result": "Demonstrated effectiveness on real-world cardiac MRI and simulated deformations, even with 64x undersampling.", "conclusion": "The method is versatile, working across sampling patterns, anatomical variations, and protocols, provided low-frequency components are sampled."}}
{"id": "2505.22908", "pdf": "https://arxiv.org/pdf/2505.22908", "abs": "https://arxiv.org/abs/2505.22908", "authors": ["Hao Xu", "Xiaolin Wu", "Xi Zhang"], "title": "3DGS Compression with Sparsity-guided Hierarchical Transform Coding", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "3D Gaussian Splatting (3DGS) has gained popularity for its fast and\nhigh-quality rendering, but it has a very large memory footprint incurring high\ntransmission and storage overhead. Recently, some neural compression methods,\nsuch as Scaffold-GS, were proposed for 3DGS but they did not adopt the approach\nof end-to-end optimized analysis-synthesis transforms which has been proven\nhighly effective in neural signal compression. Without an appropriate analysis\ntransform, signal correlations cannot be removed by sparse representation.\nWithout such transforms the only way to remove signal redundancies is through\nentropy coding driven by a complex and expensive context modeling, which\nresults in slower speed and suboptimal rate-distortion (R-D) performance. To\novercome this weakness, we propose Sparsity-guided Hierarchical Transform\nCoding (SHTC), the first end-to-end optimized transform coding framework for\n3DGS compression. SHTC jointly optimizes the 3DGS, transforms and a lightweight\ncontext model. This joint optimization enables the transform to produce\nrepresentations that approach the best R-D performance possible. The SHTC\nframework consists of a base layer using KLT for data decorrelation, and a\nsparsity-coded enhancement layer that compresses the KLT residuals to refine\nthe representation. The enhancement encoder learns a linear transform to\nproject high-dimensional inputs into a low-dimensional space, while the decoder\nunfolds the Iterative Shrinkage-Thresholding Algorithm (ISTA) to reconstruct\nthe residuals. All components are designed to be interpretable, allowing the\nincorporation of signal priors and fewer parameters than black-box transforms.\nThis novel design significantly improves R-D performance with minimal\nadditional parameters and computational overhead.", "AI": {"tldr": "SHTC is an end-to-end optimized transform coding framework for 3DGS compression, improving rate-distortion performance with minimal overhead.", "motivation": "3DGS has a large memory footprint, and existing neural compression methods lack efficient analysis-synthesis transforms, leading to suboptimal performance.", "method": "SHTC jointly optimizes 3DGS, transforms, and a lightweight context model, using KLT for decorrelation and sparsity-coded residuals for refinement.", "result": "SHTC achieves superior rate-distortion performance with fewer parameters and computational overhead.", "conclusion": "SHTC provides an interpretable, efficient solution for 3DGS compression, outperforming existing methods."}}
{"id": "2505.23153", "pdf": "https://arxiv.org/pdf/2505.23153", "abs": "https://arxiv.org/abs/2505.23153", "authors": ["Fan Wang", "Shaoshan Liu"], "title": "Conceptual Framework Toward Embodied Collective Adaptive Intelligence", "categories": ["cs.AI"], "comment": null, "summary": "Collective Adaptive Intelligence (CAI) represent a transformative approach in\nartificial intelligence, wherein numerous autonomous agents collaborate, adapt,\nand self-organize to navigate complex, dynamic environments. This paradigm is\nparticularly impactful in embodied AI applications, where adaptability and\nresilience are paramount. By enabling systems to reconfigure themselves in\nresponse to unforeseen challenges, CAI facilitate robust performance in\nreal-world scenarios. This article introduces a conceptual framework for\ndesigning and analyzing CAI. It delineates key attributes including task\ngeneralization, resilience, scalability, and self-assembly, aiming to bridge\ntheoretical foundations with practical methodologies for engineering adaptive,\nemergent intelligence. By providing a structured foundation for understanding\nand implementing CAI, this work seeks to guide researchers and practitioners in\ndeveloping more resilient, scalable, and adaptable AI systems across various\ndomains.", "AI": {"tldr": "The paper introduces Collective Adaptive Intelligence (CAI), a framework for designing AI systems where autonomous agents collaborate and adapt in dynamic environments, emphasizing resilience and scalability.", "motivation": "To address the need for adaptable and resilient AI systems in complex, real-world scenarios by leveraging collaborative and self-organizing agents.", "method": "Proposes a conceptual framework for CAI, outlining key attributes like task generalization, resilience, scalability, and self-assembly.", "result": "Provides a structured foundation for understanding and implementing CAI, bridging theory and practical methodologies.", "conclusion": "Aims to guide researchers in developing more resilient, scalable, and adaptable AI systems across various domains."}}
{"id": "2505.22813", "pdf": "https://arxiv.org/pdf/2505.22813", "abs": "https://arxiv.org/abs/2505.22813", "authors": ["Josiah Couch", "Miao Li", "Rima Arnaout", "Ramy Arnaout"], "title": "X-Factor: Quality Is a Dataset-Intrinsic Property", "categories": ["cs.LG", "68T07", "I.2.6"], "comment": "13 pages, 7 figures", "summary": "In the universal quest to optimize machine-learning classifiers, three\nfactors -- model architecture, dataset size, and class balance -- have been\nshown to influence test-time performance but do not fully account for it.\nPreviously, evidence was presented for an additional factor that can be\nreferred to as dataset quality, but it was unclear whether this was actually a\njoint property of the dataset and the model architecture, or an intrinsic\nproperty of the dataset itself. If quality is truly dataset-intrinsic and\nindependent of model architecture, dataset size, and class balance, then the\nsame datasets should perform better (or worse) regardless of these other\nfactors. To test this hypothesis, here we create thousands of datasets, each\ncontrolled for size and class balance, and use them to train classifiers with a\nwide range of architectures, from random forests and support-vector machines to\ndeep networks. We find that classifier performance correlates strongly by\nsubset across architectures ($R^2=0.79$), supporting quality as an intrinsic\nproperty of datasets independent of dataset size and class balance and of model\narchitecture. Digging deeper, we find that dataset quality appears to be an\nemergent property of something more fundamental: the quality of datasets'\nconstituent classes. Thus, quality joins size, class balance, and model\narchitecture as an independent correlate of performance and a separate target\nfor optimizing machine-learning-based classification.", "AI": {"tldr": "Dataset quality is an intrinsic property, independent of model architecture, size, and class balance, and correlates strongly with classifier performance.", "motivation": "To determine if dataset quality is an intrinsic property or a joint property of dataset and model architecture.", "method": "Created controlled datasets, trained classifiers with varied architectures, and analyzed performance correlations.", "result": "Classifier performance strongly correlates by subset across architectures (R\u00b2=0.79), confirming dataset quality as intrinsic.", "conclusion": "Dataset quality is a fundamental, independent factor for optimizing ML classifiers, alongside size, class balance, and architecture."}}
{"id": "2505.20579", "pdf": "https://arxiv.org/pdf/2505.20579", "abs": "https://arxiv.org/abs/2505.20579", "authors": ["Dane Malenfant", "Blake A. Richards"], "title": "The challenge of hidden gifts in multi-agent reinforcement learning", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": null, "summary": "Sometimes we benefit from actions that others have taken even when we are\nunaware that they took those actions. For example, if your neighbor chooses not\nto take a parking spot in front of your house when you are not there, you can\nbenefit, even without being aware that they took this action. These \"hidden\ngifts\" represent an interesting challenge for multi-agent reinforcement\nlearning (MARL), since assigning credit when the beneficial actions of others\nare hidden is non-trivial. Here, we study the impact of hidden gifts with a\nvery simple MARL task. In this task, agents in a grid-world environment have\nindividual doors to unlock in order to obtain individual rewards. As well, if\nall the agents unlock their door the group receives a larger collective reward.\nHowever, there is only one key for all of the doors, such that the collective\nreward can only be obtained when the agents drop the key for others after they\nuse it. Notably, there is nothing to indicate to an agent that the other agents\nhave dropped the key, thus the act of dropping the key for others is a \"hidden\ngift\". We show that several different state-of-the-art RL algorithms, including\nMARL algorithms, fail to learn how to obtain the collective reward in this\nsimple task. Interestingly, we find that independent model-free policy gradient\nagents can solve the task when we provide them with information about their own\naction history, but MARL agents still cannot solve the task with action\nhistory. Finally, we derive a correction term for these independent agents,\ninspired by learning aware approaches, which reduces the variance in learning\nand helps them to converge to collective success more reliably. These results\nshow that credit assignment in multi-agent settings can be particularly\nchallenging in the presence of \"hidden gifts\", and demonstrate that learning\nawareness in independent agents can benefit these settings.", "AI": {"tldr": "The paper explores 'hidden gifts' in MARL, where agents unknowingly benefit from others' actions. A simple grid-world task reveals state-of-the-art RL algorithms struggle with collective rewards due to hidden actions. Independent agents succeed with action history, while MARL agents fail. A correction term improves reliability.", "motivation": "To understand how 'hidden gifts'\u2014unseen beneficial actions by others\u2014impact credit assignment in MARL, and to identify solutions for such challenges.", "method": "A grid-world task where agents must unlock doors with a shared key to earn individual and collective rewards, testing various RL algorithms.", "result": "State-of-the-art RL and MARL algorithms fail to achieve collective rewards. Independent agents succeed with action history, and a correction term improves convergence.", "conclusion": "Hidden gifts complicate credit assignment in MARL, but learning-aware approaches can help independent agents succeed, highlighting the need for better MARL solutions."}}
{"id": "2505.22897", "pdf": "https://arxiv.org/pdf/2505.22897", "abs": "https://arxiv.org/abs/2505.22897", "authors": ["Chahat Raj", "Bowen Wei", "Aylin Caliskan", "Antonios Anastasopoulos", "Ziwei Zhu"], "title": "VIGNETTE: Socially Grounded Bias Evaluation for Vision-Language Models", "categories": ["cs.CL"], "comment": "17 pages", "summary": "While bias in large language models (LLMs) is well-studied, similar concerns\nin vision-language models (VLMs) have received comparatively less attention.\nExisting VLM bias studies often focus on portrait-style images and\ngender-occupation associations, overlooking broader and more complex social\nstereotypes and their implied harm. This work introduces VIGNETTE, a\nlarge-scale VQA benchmark with 30M+ images for evaluating bias in VLMs through\na question-answering framework spanning four directions: factuality,\nperception, stereotyping, and decision making. Beyond narrowly-centered\nstudies, we assess how VLMs interpret identities in contextualized settings,\nrevealing how models make trait and capability assumptions and exhibit patterns\nof discrimination. Drawing from social psychology, we examine how VLMs connect\nvisual identity cues to trait and role-based inferences, encoding social\nhierarchies, through biased selections. Our findings uncover subtle,\nmultifaceted, and surprising stereotypical patterns, offering insights into how\nVLMs construct social meaning from inputs.", "AI": {"tldr": "A benchmark called VIGNETTE is introduced to evaluate bias in vision-language models (VLMs) across four areas, revealing complex stereotypes and social hierarchies.", "motivation": "Bias in VLMs is understudied compared to LLMs, with existing work focusing narrowly on gender-occupation associations.", "method": "VIGNETTE, a large-scale VQA benchmark with 30M+ images, assesses bias through question-answering in four directions: factuality, perception, stereotyping, and decision making.", "result": "The study uncovers subtle, multifaceted stereotypical patterns in VLMs, showing how they encode social hierarchies and make biased assumptions.", "conclusion": "The work highlights the need for broader bias evaluation in VLMs, revealing their construction of social meaning from inputs."}}
{"id": "2505.16091", "pdf": "https://arxiv.org/pdf/2505.16091", "abs": "https://arxiv.org/abs/2505.16091", "authors": ["Jinpei Guo", "Yifei Ji", "Zheng Chen", "Kai Liu", "Min Liu", "Wang Rao", "Wenbo Li", "Yong Guo", "Yulun Zhang"], "title": "OSCAR: One-Step Diffusion Codec for Image Compression Across Multiple Bit-rates", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Pretrained latent diffusion models have shown strong potential for lossy\nimage compression, owing to their powerful generative priors. Most existing\ndiffusion-based methods reconstruct images by iteratively denoising from random\nnoise, guided by compressed latent representations. While these approaches have\nachieved high reconstruction quality, their multi-step sampling process incurs\nsubstantial computational overhead. Moreover, they typically require training\nseparate models for different compression bit-rates, leading to significant\ntraining and storage costs. To address these challenges, we propose a one-step\ndiffusion codec across multiple bit-rates. termed OSCAR. Specifically, our\nmethod views compressed latents as noisy variants of the original latents,\nwhere the level of distortion depends on the bit-rate. This perspective allows\nthem to be modeled as intermediate states along a diffusion trajectory. By\nestablishing a mapping from the compression bit-rate to a pseudo diffusion\ntimestep, we condition a single generative model to support reconstructions at\nmultiple bit-rates. Meanwhile, we argue that the compressed latents retain rich\nstructural information, thereby making one-step denoising feasible. Thus, OSCAR\nreplaces iterative sampling with a single denoising pass, significantly\nimproving inference efficiency. Extensive experiments demonstrate that OSCAR\nachieves superior performance in both quantitative and visual quality metrics.\nThe code and models will be released at https://github.com/jp-guo/OSCAR.", "AI": {"tldr": "OSCAR is a one-step diffusion codec for image compression across multiple bit-rates, improving efficiency by replacing iterative denoising with a single pass.", "motivation": "Existing diffusion-based methods for image compression are computationally expensive and require separate models for different bit-rates, leading to high costs.", "method": "OSCAR models compressed latents as noisy variants of original latents, mapping bit-rates to pseudo diffusion timesteps, enabling one-step denoising with a single generative model.", "result": "OSCAR achieves superior performance in quantitative and visual quality metrics while significantly improving inference efficiency.", "conclusion": "OSCAR addresses computational and storage challenges in diffusion-based image compression, offering a practical and efficient solution."}}
{"id": "2505.22911", "pdf": "https://arxiv.org/pdf/2505.22911", "abs": "https://arxiv.org/abs/2505.22911", "authors": ["Matthew Beveridge", "Shree K. Nayar"], "title": "Hierarchical Material Recognition from Local Appearance", "categories": ["cs.CV"], "comment": null, "summary": "We introduce a taxonomy of materials for hierarchical recognition from local\nappearance. Our taxonomy is motivated by vision applications and is arranged\naccording to the physical traits of materials. We contribute a diverse,\nin-the-wild dataset with images and depth maps of the taxonomy classes.\nUtilizing the taxonomy and dataset, we present a method for hierarchical\nmaterial recognition based on graph attention networks. Our model leverages the\ntaxonomic proximity between classes and achieves state-of-the-art performance.\nWe demonstrate the model's potential to generalize to adverse, real-world\nimaging conditions, and that novel views rendered using the depth maps can\nenhance this capability. Finally, we show the model's capacity to rapidly learn\nnew materials in a few-shot learning setting.", "AI": {"tldr": "A taxonomy for hierarchical material recognition is introduced, supported by a dataset and a graph attention network method, achieving top performance and generalization to real-world conditions.", "motivation": "To address hierarchical material recognition by leveraging physical traits of materials and improving performance in diverse, real-world conditions.", "method": "A graph attention network-based approach utilizing taxonomic proximity and depth maps for hierarchical material recognition.", "result": "State-of-the-art performance, generalization to adverse conditions, and enhanced capability with rendered views. Few-shot learning for new materials is demonstrated.", "conclusion": "The taxonomy, dataset, and method advance material recognition, showing robustness and adaptability in real-world scenarios."}}
{"id": "2505.23281", "pdf": "https://arxiv.org/pdf/2505.23281", "abs": "https://arxiv.org/abs/2505.23281", "authors": ["Mislav Balunovi\u0107", "Jasper Dekoninck", "Ivo Petrov", "Nikola Jovanovi\u0107", "Martin Vechev"], "title": "MathArena: Evaluating LLMs on Uncontaminated Math Competitions", "categories": ["cs.AI"], "comment": null, "summary": "The rapid advancement of reasoning capabilities in large language models\n(LLMs) has led to notable improvements on mathematical benchmarks. However,\nmany of the most commonly used evaluation datasets (e.g., AIME 2024) are widely\navailable online, making it difficult to disentangle genuine reasoning from\npotential memorization. Furthermore, these benchmarks do not evaluate\nproof-writing capabilities, which are crucial for many mathematical tasks. To\naddress this, we introduce MathArena, a new benchmark based on the following\nkey insight: recurring math competitions provide a stream of high-quality,\nchallenging problems that can be used for real-time evaluation of LLMs. By\nevaluating models as soon as new problems are released, we effectively\neliminate the risk of contamination. Using this framework, we find strong signs\nof contamination in AIME 2024. Nonetheless, evaluations on harder competitions,\nsuch as SMT 2025 -- published well after model release dates -- demonstrate\nimpressive reasoning capabilities in top-performing models. MathArena is also\nthe first benchmark for proof-writing capabilities. On USAMO 2025, even top\nmodels score below 25%, far behind their performance on final-answer tasks. So\nfar, we have evaluated 30 models across five competitions, totaling 149\nproblems. As an evolving benchmark, MathArena will continue to track the\nprogress of LLMs on newly released competitions, ensuring rigorous and\nup-to-date evaluation of mathematical reasoning.", "AI": {"tldr": "MathArena is a new benchmark for evaluating LLMs' mathematical reasoning and proof-writing, addressing contamination risks in existing datasets like AIME 2024. It uses real-time competition problems and shows strong reasoning in top models but poor proof-writing performance.", "motivation": "Existing benchmarks like AIME 2024 suffer from contamination risks and lack proof-writing evaluation, necessitating a more rigorous and dynamic benchmark.", "method": "MathArena leverages recurring math competitions for real-time evaluation, eliminating contamination risks. It assesses 30 models across five competitions (149 problems).", "result": "Contamination is evident in AIME 2024, but top models show strong reasoning on newer competitions like SMT 2025. Proof-writing performance (e.g., USAMO 2025) lags behind final-answer tasks.", "conclusion": "MathArena provides a contamination-free, evolving benchmark for LLMs' mathematical reasoning and proof-writing, highlighting gaps in current capabilities."}}
{"id": "2505.22820", "pdf": "https://arxiv.org/pdf/2505.22820", "abs": "https://arxiv.org/abs/2505.22820", "authors": ["Ayush Sawarni", "Sahasrajit Sarmasarkar", "Vasilis Syrgkanis"], "title": "Preference Learning with Response Time", "categories": ["cs.LG"], "comment": null, "summary": "This paper investigates the integration of response time data into human\npreference learning frameworks for more effective reward model elicitation.\nWhile binary preference data has become fundamental in fine-tuning foundation\nmodels, generative AI systems, and other large-scale models, the valuable\ntemporal information inherent in user decision-making remains largely\nunexploited. We propose novel methodologies to incorporate response time\ninformation alongside binary choice data, leveraging the Evidence Accumulation\nDrift Diffusion (EZ) model, under which response time is informative of the\npreference strength. We develop Neyman-orthogonal loss functions that achieve\noracle convergence rates for reward model learning, matching the theoretical\noptimal rates that would be attained if the expected response times for each\nquery were known a priori. Our theoretical analysis demonstrates that for\nlinear reward functions, conventional preference learning suffers from error\nrates that scale exponentially with reward magnitude. In contrast, our response\ntime-augmented approach reduces this to polynomial scaling, representing a\nsignificant improvement in sample efficiency. We extend these guarantees to\nnon-parametric reward function spaces, establishing convergence properties for\nmore complex, realistic reward models. Our extensive experiments validate our\ntheoretical findings in the context of preference learning over images.", "AI": {"tldr": "The paper introduces a method to enhance reward model learning by integrating response time data with binary preference data, improving sample efficiency and reducing error rates.", "motivation": "Current preference learning frameworks primarily use binary data, neglecting valuable temporal information in user decision-making. This work aims to exploit response time data for better reward model elicitation.", "method": "The authors propose using the Evidence Accumulation Drift Diffusion (EZ) model to incorporate response time information. They develop Neyman-orthogonal loss functions for optimal convergence rates in reward model learning.", "result": "Theoretical analysis shows the method reduces error rates from exponential to polynomial scaling for linear reward functions. Experiments confirm these improvements in preference learning over images.", "conclusion": "Integrating response time data significantly enhances reward model learning, offering better sample efficiency and accuracy, especially for complex reward functions."}}
{"id": "2505.22910", "pdf": "https://arxiv.org/pdf/2505.22910", "abs": "https://arxiv.org/abs/2505.22910", "authors": ["Chahat Raj", "Mahika Banerjee", "Aylin Caliskan", "Antonios Anastasopoulos", "Ziwei Zhu"], "title": "Talent or Luck? Evaluating Attribution Bias in Large Language Models", "categories": ["cs.CL"], "comment": "18 pages", "summary": "When a student fails an exam, do we tend to blame their effort or the test's\ndifficulty? Attribution, defined as how reasons are assigned to event outcomes,\nshapes perceptions, reinforces stereotypes, and influences decisions.\nAttribution Theory in social psychology explains how humans assign\nresponsibility for events using implicit cognition, attributing causes to\ninternal (e.g., effort, ability) or external (e.g., task difficulty, luck)\nfactors. LLMs' attribution of event outcomes based on demographics carries\nimportant fairness implications. Most works exploring social biases in LLMs\nfocus on surface-level associations or isolated stereotypes. This work proposes\na cognitively grounded bias evaluation framework to identify how models'\nreasoning disparities channelize biases toward demographic groups.", "AI": {"tldr": "The paper explores how LLMs attribute event outcomes (e.g., exam failure) to internal (effort) or external (test difficulty) factors, with fairness implications. It proposes a cognitively grounded framework to evaluate biases in LLMs' reasoning.", "motivation": "Understanding how LLMs assign responsibility for events is crucial for fairness, as biases in attribution can reinforce stereotypes and influence decisions.", "method": "The work introduces a cognitively grounded bias evaluation framework to analyze LLMs' reasoning disparities and biases toward demographic groups.", "result": "The framework identifies how LLMs' attribution patterns channelize biases, moving beyond surface-level associations to deeper reasoning disparities.", "conclusion": "The proposed framework offers a nuanced approach to evaluating biases in LLMs, addressing fairness implications of attribution patterns."}}
{"id": "2505.17366", "pdf": "https://arxiv.org/pdf/2505.17366", "abs": "https://arxiv.org/abs/2505.17366", "authors": ["Yichi Zhang", "Zhihao Duan", "Yuning Huang", "Fengqing Zhu"], "title": "Low-Rank Adaptation of Pre-trained Vision Backbones for Energy-Efficient Image Coding for Machine", "categories": ["eess.IV"], "comment": "2025 IEEE International Conference on Image Processing (ICIP2025).\n  Fix typo", "summary": "Image Coding for Machines (ICM) focuses on optimizing image compression for\nAI-driven analysis rather than human perception. Existing ICM frameworks often\nrely on separate codecs for specific tasks, leading to significant storage\nrequirements, training overhead, and computational complexity. To address these\nchallenges, we propose an energy-efficient framework that leverages pre-trained\nvision backbones to extract robust and versatile latent representations\nsuitable for multiple tasks. We introduce a task-specific low-rank adaptation\nmechanism, which refines the pre-trained features to be both compressible and\ntailored to downstream applications. This design minimizes trainable parameters\nand reduces energy costs for multi-task scenarios. By jointly optimizing task\nperformance and entropy minimization, our method enables efficient adaptation\nto diverse tasks and datasets without full fine-tuning, achieving high coding\nefficiency. Extensive experiments demonstrate that our framework significantly\noutperforms traditional codecs and pre-processors, offering an energy-efficient\nand effective solution for ICM applications. The code and the supplementary\nmaterials will be available at:\nhttps://gitlab.com/viper-purdue/efficient-compression.", "AI": {"tldr": "Proposes an energy-efficient framework for Image Coding for Machines (ICM) using pre-trained vision backbones and task-specific low-rank adaptation to optimize compression for AI-driven analysis.", "motivation": "Existing ICM frameworks use separate codecs for tasks, causing high storage, training, and computational costs.", "method": "Leverages pre-trained vision backbones with task-specific low-rank adaptation to refine features for compressibility and task performance.", "result": "Outperforms traditional codecs and pre-processors, achieving high coding efficiency with minimal trainable parameters and energy costs.", "conclusion": "Offers an effective, energy-efficient solution for ICM, adaptable to diverse tasks without full fine-tuning."}}
{"id": "2505.22914", "pdf": "https://arxiv.org/pdf/2505.22914", "abs": "https://arxiv.org/abs/2505.22914", "authors": ["Maksim Kolodiazhnyi", "Denis Tarasov", "Dmitrii Zhemchuzhnikov", "Alexander Nikulin", "Ilya Zisman", "Anna Vorontsova", "Anton Konushin", "Vladislav Kurenkov", "Danila Rukhovich"], "title": "cadrille: Multi-modal CAD Reconstruction with Online Reinforcement Learning", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Computer-Aided Design (CAD) plays a central role in engineering and\nmanufacturing, making it possible to create precise and editable 3D models.\nUsing a variety of sensor or user-provided data as inputs for CAD\nreconstruction can democratize access to design applications. However, existing\nmethods typically focus on a single input modality, such as point clouds,\nimages, or text, which limits their generalizability and robustness. Leveraging\nrecent advances in vision-language models (VLM), we propose a multi-modal CAD\nreconstruction model that simultaneously processes all three input modalities.\nInspired by large language model (LLM) training paradigms, we adopt a two-stage\npipeline: supervised fine-tuning (SFT) on large-scale procedurally generated\ndata, followed by reinforcement learning (RL) fine-tuning using online\nfeedback, obtained programatically. Furthermore, we are the first to explore RL\nfine-tuning of LLMs for CAD tasks demonstrating that online RL algorithms such\nas Group Relative Preference Optimization (GRPO) outperform offline\nalternatives. In the DeepCAD benchmark, our SFT model outperforms existing\nsingle-modal approaches in all three input modalities simultaneously. More\nimportantly, after RL fine-tuning, cadrille sets new state-of-the-art on three\nchallenging datasets, including a real-world one.", "AI": {"tldr": "A multi-modal CAD reconstruction model using vision-language models (VLM) and reinforcement learning (RL) outperforms single-modal methods and achieves state-of-the-art results.", "motivation": "To democratize CAD design by leveraging multi-modal inputs (point clouds, images, text) for better generalizability and robustness, overcoming limitations of single-modal approaches.", "method": "A two-stage pipeline: supervised fine-tuning (SFT) on procedurally generated data, followed by RL fine-tuning using online feedback (GRPO).", "result": "The SFT model outperforms single-modal methods, and RL fine-tuning sets new state-of-the-art on three datasets, including real-world data.", "conclusion": "Multi-modal CAD reconstruction with RL fine-tuning is highly effective, demonstrating superior performance and potential for broader applications."}}
{"id": "2505.23381", "pdf": "https://arxiv.org/pdf/2505.23381", "abs": "https://arxiv.org/abs/2505.23381", "authors": ["Bowen Ping", "Minnan Luo", "Zhuohang Dang", "Chenxi Wang", "Chengyou Jia"], "title": "AutoGPS: Automated Geometry Problem Solving via Multimodal Formalization and Deductive Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Geometry problem solving presents distinctive challenges in artificial\nintelligence, requiring exceptional multimodal comprehension and rigorous\nmathematical reasoning capabilities. Existing approaches typically fall into\ntwo categories: neural-based and symbolic-based methods, both of which exhibit\nlimitations in reliability and interpretability. To address this challenge, we\npropose AutoGPS, a neuro-symbolic collaborative framework that solves geometry\nproblems with concise, reliable, and human-interpretable reasoning processes.\nSpecifically, AutoGPS employs a Multimodal Problem Formalizer (MPF) and a\nDeductive Symbolic Reasoner (DSR). The MPF utilizes neural cross-modal\ncomprehension to translate geometry problems into structured formal language\nrepresentations, with feedback from DSR collaboratively. The DSR takes the\nformalization as input and formulates geometry problem solving as a hypergraph\nexpansion task, executing mathematically rigorous and reliable derivation to\nproduce minimal and human-readable stepwise solutions. Extensive experimental\nevaluations demonstrate that AutoGPS achieves state-of-the-art performance on\nbenchmark datasets. Furthermore, human stepwise-reasoning evaluation confirms\nAutoGPS's impressive reliability and interpretability, with 99\\% stepwise\nlogical coherence. The project homepage is at\nhttps://jayce-ping.github.io/AutoGPS-homepage.", "AI": {"tldr": "AutoGPS is a neuro-symbolic framework for solving geometry problems with reliable, interpretable reasoning, outperforming existing methods.", "motivation": "Addressing limitations in reliability and interpretability of neural and symbolic approaches for geometry problem solving.", "method": "Combines Multimodal Problem Formalizer (MPF) for cross-modal comprehension and Deductive Symbolic Reasoner (DSR) for hypergraph-based rigorous reasoning.", "result": "Achieves state-of-the-art performance and 99% logical coherence in stepwise solutions.", "conclusion": "AutoGPS provides a robust, human-interpretable solution for geometry problem solving."}}
{"id": "2505.22825", "pdf": "https://arxiv.org/pdf/2505.22825", "abs": "https://arxiv.org/abs/2505.22825", "authors": ["Michael Klamkin", "Mathieu Tanneau", "Pascal Van Hentenryck"], "title": "PGLearn -- An Open-Source Learning Toolkit for Optimal Power Flow", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY", "math.OC"], "comment": null, "summary": "Machine Learning (ML) techniques for Optimal Power Flow (OPF) problems have\nrecently garnered significant attention, reflecting a broader trend of\nleveraging ML to approximate and/or accelerate the resolution of complex\noptimization problems. These developments are necessitated by the increased\nvolatility and scale in energy production for modern and future grids. However,\nprogress in ML for OPF is hindered by the lack of standardized datasets and\nevaluation metrics, from generating and solving OPF instances, to training and\nbenchmarking machine learning models. To address this challenge, this paper\nintroduces PGLearn, a comprehensive suite of standardized datasets and\nevaluation tools for ML and OPF. PGLearn provides datasets that are\nrepresentative of real-life operating conditions, by explicitly capturing both\nglobal and local variability in the data generation, and by, for the first\ntime, including time series data for several large-scale systems. In addition,\nit supports multiple OPF formulations, including AC, DC, and second-order cone\nformulations. Standardized datasets are made publicly available to democratize\naccess to this field, reduce the burden of data generation, and enable the fair\ncomparison of various methodologies. PGLearn also includes a robust toolkit for\ntraining, evaluating, and benchmarking machine learning models for OPF, with\nthe goal of standardizing performance evaluation across the field. By promoting\nopen, standardized datasets and evaluation metrics, PGLearn aims at\ndemocratizing and accelerating research and innovation in machine learning\napplications for optimal power flow problems. Datasets are available for\ndownload at https://www.huggingface.co/PGLearn.", "AI": {"tldr": "PGLearn introduces standardized datasets and tools for ML in OPF, addressing lack of benchmarks and promoting fair comparison.", "motivation": "The volatility and scale of modern energy grids necessitate ML for OPF, but progress is hindered by the lack of standardized datasets and metrics.", "method": "PGLearn provides diverse datasets (including time series) and supports multiple OPF formulations (AC, DC, second-order cone). It also offers evaluation tools.", "result": "Standardized datasets and tools are made publicly available, enabling fair benchmarking and reducing data generation burdens.", "conclusion": "PGLearn democratizes and accelerates ML research for OPF by promoting open, standardized resources."}}
{"id": "2505.22919", "pdf": "https://arxiv.org/pdf/2505.22919", "abs": "https://arxiv.org/abs/2505.22919", "authors": ["Nikita Mehandru", "Niloufar Golchini", "David Bamman", "Travis Zack", "Melanie F. Molina", "Ahmed Alaa"], "title": "ER-REASON: A Benchmark Dataset for LLM-Based Clinical Reasoning in the Emergency Room", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have been extensively evaluated on medical\nquestion answering tasks based on licensing exams. However, real-world\nevaluations often depend on costly human annotators, and existing benchmarks\ntend to focus on isolated tasks that rarely capture the clinical reasoning or\nfull workflow underlying medical decisions. In this paper, we introduce\nER-Reason, a benchmark designed to evaluate LLM-based clinical reasoning and\ndecision-making in the emergency room (ER)--a high-stakes setting where\nclinicians make rapid, consequential decisions across diverse patient\npresentations and medical specialties under time pressure. ER-Reason includes\ndata from 3,984 patients, encompassing 25,174 de-identified longitudinal\nclinical notes spanning discharge summaries, progress notes, history and\nphysical exams, consults, echocardiography reports, imaging notes, and ER\nprovider documentation. The benchmark includes evaluation tasks that span key\nstages of the ER workflow: triage intake, initial assessment, treatment\nselection, disposition planning, and final diagnosis--each structured to\nreflect core clinical reasoning processes such as differential diagnosis via\nrule-out reasoning. We also collected 72 full physician-authored rationales\nexplaining reasoning processes that mimic the teaching process used in\nresidency training, and are typically absent from ER documentation. Evaluations\nof state-of-the-art LLMs on ER-Reason reveal a gap between LLM-generated and\nclinician-authored clinical reasoning for ER decisions, highlighting the need\nfor future research to bridge this divide.", "AI": {"tldr": "ER-Reason is a benchmark for evaluating LLMs in emergency room (ER) clinical reasoning, highlighting gaps between AI and clinician decision-making.", "motivation": "Existing benchmarks lack real-world clinical workflow and reasoning, relying on costly human annotators and isolated tasks.", "method": "ER-Reason uses 3,984 patient records and 25,174 clinical notes, structured around ER workflow stages and clinical reasoning processes like differential diagnosis.", "result": "State-of-the-art LLMs show a gap in clinical reasoning compared to clinician-authored rationales.", "conclusion": "Future research is needed to improve LLMs' clinical reasoning for ER decisions."}}
{"id": "2505.18424", "pdf": "https://arxiv.org/pdf/2505.18424", "abs": "https://arxiv.org/abs/2505.18424", "authors": ["Tianyi Ren", "Juampablo E. Heras Rivera", "Hitender Oswal", "Yutong Pan", "William Henry", "Sophie Walters", "Mehmet Kurt"], "title": "How We Won the ISLES'24 Challenge by Preprocessing", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Stroke is among the top three causes of death worldwide, and accurate\nidentification of stroke lesion boundaries is critical for diagnosis and\ntreatment. Supervised deep learning methods have emerged as the leading\nsolution for stroke lesion segmentation but require large, diverse, and\nannotated datasets. The ISLES'24 challenge addresses this need by providing\nlongitudinal stroke imaging data, including CT scans taken on arrival to the\nhospital and follow-up MRI taken 2-9 days from initial arrival, with\nannotations derived from follow-up MRI. Importantly, models submitted to the\nISLES'24 challenge are evaluated using only CT inputs, requiring prediction of\nlesion progression that may not be visible in CT scans for segmentation. Our\nwinning solution shows that a carefully designed preprocessing pipeline\nincluding deep-learning-based skull stripping and custom intensity windowing is\nbeneficial for accurate segmentation. Combined with a standard large residual\nnnU-Net architecture for segmentation, this approach achieves a mean test Dice\nof 28.5 with a standard deviation of 21.27.", "AI": {"tldr": "A winning solution for stroke lesion segmentation in the ISLES'24 challenge uses preprocessing and a residual nnU-Net to achieve accurate results from CT scans.", "motivation": "Accurate stroke lesion segmentation is critical for diagnosis and treatment, but supervised deep learning requires large annotated datasets.", "method": "The approach combines deep-learning-based skull stripping, custom intensity windowing, and a residual nnU-Net architecture.", "result": "Achieves a mean test Dice of 28.5 with a standard deviation of 21.27.", "conclusion": "Careful preprocessing and standard segmentation architectures can effectively address challenges in stroke lesion segmentation."}}
{"id": "2505.22918", "pdf": "https://arxiv.org/pdf/2505.22918", "abs": "https://arxiv.org/abs/2505.22918", "authors": ["Ruichen Chen", "Keith G. Mills", "Liyao Jiang", "Chao Gao", "Di Niu"], "title": "Re-ttention: Ultra Sparse Visual Generation via Attention Statistical Reshape", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion Transformers (DiT) have become the de-facto model for generating\nhigh-quality visual content like videos and images. A huge bottleneck is the\nattention mechanism where complexity scales quadratically with resolution and\nvideo length. One logical way to lessen this burden is sparse attention, where\nonly a subset of tokens or patches are included in the calculation. However,\nexisting techniques fail to preserve visual quality at extremely high sparsity\nlevels and might even incur non-negligible compute overheads. % To address this\nconcern, we propose Re-ttention, which implements very high sparse attention\nfor visual generation models by leveraging the temporal redundancy of Diffusion\nModels to overcome the probabilistic normalization shift within the attention\nmechanism. Specifically, Re-ttention reshapes attention scores based on the\nprior softmax distribution history in order to preserve the visual quality of\nthe full quadratic attention at very high sparsity levels. % Experimental\nresults on T2V/T2I models such as CogVideoX and the PixArt DiTs demonstrate\nthat Re-ttention requires as few as 3.1\\% of the tokens during inference,\noutperforming contemporary methods like FastDiTAttn, Sparse VideoGen and\nMInference. Further, we measure latency to show that our method can attain over\n45\\% end-to-end % and over 92\\% self-attention latency reduction on an H100 GPU\nat negligible overhead cost.\n  Code available online here:\n\\href{https://github.com/cccrrrccc/Re-ttention}{https://github.com/cccrrrccc/Re-ttention}", "AI": {"tldr": "Re-ttention reduces attention complexity in Diffusion Transformers (DiT) by leveraging temporal redundancy, enabling high sparsity without quality loss.", "motivation": "The quadratic complexity of attention in DiTs limits scalability for high-resolution and long videos. Existing sparse attention methods degrade quality or add overhead.", "method": "Re-ttention reshapes attention scores using prior softmax distribution history to maintain quality at high sparsity (e.g., 3.1% tokens).", "result": "Achieves 45% end-to-end and 92% self-attention latency reduction on H100 GPU, outperforming FastDiTAttn, Sparse VideoGen, and MInference.", "conclusion": "Re-ttention enables efficient high-quality visual generation with minimal compute overhead."}}
{"id": "2505.23397", "pdf": "https://arxiv.org/pdf/2505.23397", "abs": "https://arxiv.org/abs/2505.23397", "authors": ["Ahmad Mohsin", "Helge Janicke", "Ahmed Ibrahim", "Iqbal H. Sarker", "Seyit Camtepe"], "title": "A Unified Framework for Human AI Collaboration in Security Operations Centers with Trusted Autonomy", "categories": ["cs.AI", "cs.CR"], "comment": "Journal Article", "summary": "This article presents a structured framework for Human-AI collaboration in\nSecurity Operations Centers (SOCs), integrating AI autonomy, trust calibration,\nand Human-in-the-loop decision making. Existing frameworks in SOCs often focus\nnarrowly on automation, lacking systematic structures to manage human\noversight, trust calibration, and scalable autonomy with AI. Many assume static\nor binary autonomy settings, failing to account for the varied complexity,\ncriticality, and risk across SOC tasks considering Humans and AI collaboration.\nTo address these limitations, we propose a novel autonomy tiered framework\ngrounded in five levels of AI autonomy from manual to fully autonomous, mapped\nto Human-in-the-Loop (HITL) roles and task-specific trust thresholds. This\nenables adaptive and explainable AI integration across core SOC functions,\nincluding monitoring, protection, threat detection, alert triage, and incident\nresponse. The proposed framework differentiates itself from previous research\nby creating formal connections between autonomy, trust, and HITL across various\nSOC levels, which allows for adaptive task distribution according to\noperational complexity and associated risks. The framework is exemplified\nthrough a simulated cyber range that features the cybersecurity AI-Avatar, a\nfine-tuned LLM-based SOC assistant. The AI-Avatar case study illustrates\nhuman-AI collaboration for SOC tasks, reducing alert fatigue, enhancing\nresponse coordination, and strategically calibrating trust. This research\nsystematically presents both the theoretical and practical aspects and\nfeasibility of designing next-generation cognitive SOCs that leverage AI not to\nreplace but to enhance human decision-making.", "AI": {"tldr": "A structured framework for Human-AI collaboration in SOCs is proposed, featuring tiered AI autonomy, trust calibration, and Human-in-the-Loop roles to address gaps in existing automation-focused approaches.", "motivation": "Existing SOC frameworks lack systematic structures for human oversight, trust calibration, and scalable AI autonomy, often assuming static settings unsuitable for varied task complexities.", "method": "The framework introduces five levels of AI autonomy, mapped to Human-in-the-Loop roles and task-specific trust thresholds, demonstrated via a simulated cyber range with an LLM-based AI-Avatar.", "result": "The framework enables adaptive AI integration, reduces alert fatigue, enhances response coordination, and strategically calibrates trust in SOC tasks.", "conclusion": "The research advances theoretical and practical designs for next-gen cognitive SOCs, emphasizing AI's role in enhancing, not replacing, human decision-making."}}
{"id": "2505.22829", "pdf": "https://arxiv.org/pdf/2505.22829", "abs": "https://arxiv.org/abs/2505.22829", "authors": ["Chenruo Liu", "Kenan Tang", "Yao Qin", "Qi Lei"], "title": "Bridging Distribution Shift and AI Safety: Conceptual and Methodological Synergies", "categories": ["cs.LG", "cs.AI"], "comment": "35 pages", "summary": "This paper bridges distribution shift and AI safety through a comprehensive\nanalysis of their conceptual and methodological synergies. While prior\ndiscussions often focus on narrow cases or informal analogies, we establish two\ntypes connections between specific causes of distribution shift and\nfine-grained AI safety issues: (1) methods addressing a specific shift type can\nhelp achieve corresponding safety goals, or (2) certain shifts and safety\nissues can be formally reduced to each other, enabling mutual adaptation of\ntheir methods. Our findings provide a unified perspective that encourages\nfundamental integration between distribution shift and AI safety research.", "AI": {"tldr": "The paper connects distribution shift and AI safety, showing how methods for addressing shifts can aid safety goals and how shifts and safety issues can be formally linked.", "motivation": "To unify distribution shift and AI safety research by exploring their conceptual and methodological overlaps.", "method": "Analyzes two types of connections: (1) methods for specific shifts aiding safety goals, and (2) formal reductions between shifts and safety issues.", "result": "Establishes a unified perspective for integrating distribution shift and AI safety research.", "conclusion": "Encourages fundamental integration between the two fields for mutual methodological adaptation."}}
{"id": "2505.22921", "pdf": "https://arxiv.org/pdf/2505.22921", "abs": "https://arxiv.org/abs/2505.22921", "authors": ["Yue Xing", "Tao Yang", "Yijiashun Qi", "Minggu Wei", "Yu Cheng", "Honghui Xin"], "title": "Structured Memory Mechanisms for Stable Context Representation in Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "This paper addresses the limitations of large language models in\nunderstanding long-term context. It proposes a model architecture equipped with\na long-term memory mechanism to improve the retention and retrieval of semantic\ninformation across paragraphs and dialogue turns. The model integrates explicit\nmemory units, gated writing mechanisms, and attention-based reading modules. A\nforgetting function is introduced to enable dynamic updates of memory content,\nenhancing the model's ability to manage historical information. To further\nimprove the effectiveness of memory operations, the study designs a joint\ntraining objective. This combines the main task loss with constraints on memory\nwriting and forgetting. It guides the model to learn better memory strategies\nduring task execution. Systematic evaluation across multiple subtasks shows\nthat the model achieves clear advantages in text generation consistency,\nstability in multi-turn question answering, and accuracy in cross-context\nreasoning. In particular, the model demonstrates strong semantic retention and\ncontextual coherence in long-text tasks and complex question answering\nscenarios. It effectively mitigates the context loss and semantic drift\nproblems commonly faced by traditional language models when handling long-term\ndependencies. The experiments also include analysis of different memory\nstructures, capacity sizes, and control strategies. These results further\nconfirm the critical role of memory mechanisms in language understanding. They\ndemonstrate the feasibility and effectiveness of the proposed approach in both\narchitectural design and performance outcomes.", "AI": {"tldr": "The paper proposes a model with long-term memory mechanisms to improve context retention in language models, showing better performance in text generation, question answering, and reasoning.", "motivation": "Address limitations of large language models in understanding long-term context, particularly issues like context loss and semantic drift.", "method": "Introduces a model with explicit memory units, gated writing, attention-based reading, and a forgetting function, trained with a joint objective combining task loss and memory constraints.", "result": "The model outperforms in text generation consistency, multi-turn QA stability, and cross-context reasoning, mitigating context loss and semantic drift.", "conclusion": "Memory mechanisms are crucial for language understanding; the proposed approach is feasible and effective in design and performance."}}
{"id": "2505.22511", "pdf": "https://arxiv.org/pdf/2505.22511", "abs": "https://arxiv.org/abs/2505.22511", "authors": ["Siyeop Yoon", "Yujin Oh", "Pengfei Jin", "Sifan Song", "Matthew Tivnan", "Dufan Wu", "Xiang Li", "Quanzheng Li"], "title": "Surf2CT: Cascaded 3D Flow Matching Models for Torso 3D CT Synthesis from Skin Surface", "categories": ["eess.IV", "cs.CV"], "comment": "Neurips 2025 submitted", "summary": "We present Surf2CT, a novel cascaded flow matching framework that synthesizes\nfull 3D computed tomography (CT) volumes of the human torso from external\nsurface scans and simple demographic data (age, sex, height, weight). This is\nthe first approach capable of generating realistic volumetric internal anatomy\nimages solely based on external body shape and demographics, without any\ninternal imaging. Surf2CT proceeds through three sequential stages: (1) Surface\nCompletion, reconstructing a complete signed distance function (SDF) from\npartial torso scans using conditional 3D flow matching; (2) Coarse CT\nSynthesis, generating a low-resolution CT volume from the completed SDF and\ndemographic information; and (3) CT Super-Resolution, refining the coarse\nvolume into a high-resolution CT via a patch-wise conditional flow model. Each\nstage utilizes a 3D-adapted EDM2 backbone trained via flow matching. We trained\nour model on a combined dataset of 3,198 torso CT scans (approximately 1.13\nmillion axial slices) sourced from Massachusetts General Hospital (MGH) and the\nAutoPET challenge. Evaluation on 700 paired torso surface-CT cases demonstrated\nstrong anatomical fidelity: organ volumes exhibited small mean percentage\ndifferences (range from -11.1% to 4.4%), and muscle/fat body composition\nmetrics matched ground truth with strong correlation (range from 0.67 to 0.96).\nLung localization had minimal bias (mean difference -2.5 mm), and surface\ncompletion significantly improved metrics (Chamfer distance: from 521.8 mm to\n2.7 mm; Intersection-over-Union: from 0.87 to 0.98). Surf2CT establishes a new\nparadigm for non-invasive internal anatomical imaging using only external data,\nopening opportunities for home-based healthcare, preventive medicine, and\npersonalized clinical assessments without the risks associated with\nconventional imaging techniques.", "AI": {"tldr": "Surf2CT is a cascaded flow matching framework that generates 3D CT volumes from surface scans and demographics, achieving high anatomical fidelity without internal imaging.", "motivation": "To enable non-invasive internal anatomical imaging using only external data, reducing risks and expanding applications in healthcare.", "method": "Three-stage process: Surface Completion, Coarse CT Synthesis, and CT Super-Resolution, using 3D-adapted EDM2 backbone trained via flow matching.", "result": "Strong anatomical fidelity with small organ volume differences, high correlation in body composition, and improved surface completion metrics.", "conclusion": "Surf2CT pioneers non-invasive internal imaging, offering potential for home-based healthcare and personalized medicine."}}
{"id": "2505.22926", "pdf": "https://arxiv.org/pdf/2505.22926", "abs": "https://arxiv.org/abs/2505.22926", "authors": ["Sylvey Lin", "Zhi-Yi Cao"], "title": "Leveraging Diffusion Models for Synthetic Data Augmentation in Protein Subcellular Localization Classification", "categories": ["cs.CV"], "comment": null, "summary": "We investigate whether synthetic images generated by diffusion models can\nenhance multi-label classification of protein subcellular localization.\nSpecifically, we implement a simplified class-conditional denoising diffusion\nprobabilistic model (DDPM) to produce label-consistent samples and explore\ntheir integration with real data via two hybrid training strategies: Mix Loss\nand Mix Representation. While these approaches yield promising validation\nperformance, our proposed MixModel exhibits poor generalization to unseen test\ndata, underscoring the challenges of leveraging synthetic data effectively. In\ncontrast, baseline classifiers built on ResNet backbones with conventional loss\nfunctions demonstrate greater stability and test-time performance. Our findings\nhighlight the importance of realistic data generation and robust supervision\nwhen incorporating generative augmentation into biomedical image\nclassification.", "AI": {"tldr": "Synthetic images from diffusion models show promise for multi-label protein classification but struggle with generalization, while traditional methods remain more stable.", "motivation": "To explore if synthetic images from diffusion models can improve multi-label classification of protein subcellular localization.", "method": "Implemented a simplified DDPM for label-consistent synthetic images and tested hybrid training strategies (Mix Loss, Mix Representation).", "result": "Validation performance was promising, but MixModel generalized poorly to unseen test data; ResNet baselines outperformed.", "conclusion": "Realistic data generation and robust supervision are crucial for effective generative augmentation in biomedical image classification."}}
{"id": "2505.23399", "pdf": "https://arxiv.org/pdf/2505.23399", "abs": "https://arxiv.org/abs/2505.23399", "authors": ["Jusheng Zhang", "Yijia Fan", "Wenjun Lin", "Ruiqi Chen", "Haoyi Jiang", "Wenhao Chai", "Jian Wang", "Keze Wang"], "title": "GAM-Agent: Game-Theoretic and Uncertainty-Aware Collaboration for Complex Visual Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "We propose GAM-Agent, a game-theoretic multi-agent framework for enhancing\nvision-language reasoning. Unlike prior single-agent or monolithic models,\nGAM-Agent formulates the reasoning process as a non-zero-sum game between base\nagents--each specializing in visual perception subtasks--and a critical agent\nthat verifies logic consistency and factual correctness. Agents communicate via\nstructured claims, evidence, and uncertainty estimates. The framework\nintroduces an uncertainty-aware controller to dynamically adjust agent\ncollaboration, triggering multi-round debates when disagreement or ambiguity is\ndetected. This process yields more robust and interpretable predictions.\nExperiments on four challenging benchmarks--MMMU, MMBench, MVBench, and\nV*Bench--demonstrate that GAM-Agent significantly improves performance across\nvarious VLM backbones. Notably, GAM-Agent boosts the accuracy of small-to-mid\nscale models (e.g., Qwen2.5-VL-7B, InternVL3-14B) by 5--6\\%, and still enhances\nstrong models like GPT-4o by up to 2--3\\%. Our approach is modular, scalable,\nand generalizable, offering a path toward reliable and explainable multi-agent\nmultimodal reasoning.", "AI": {"tldr": "GAM-Agent is a game-theoretic multi-agent framework for vision-language reasoning, improving robustness and interpretability through dynamic agent collaboration and uncertainty-aware control.", "motivation": "To address limitations of single-agent or monolithic models in vision-language reasoning by introducing a collaborative, game-theoretic approach for more robust and interpretable predictions.", "method": "Formulates reasoning as a non-zero-sum game between specialized base agents and a critical agent, using structured communication and uncertainty-aware dynamic collaboration.", "result": "Significant performance improvements on benchmarks (5-6% for smaller models, 2-3% for strong models like GPT-4o).", "conclusion": "GAM-Agent offers a modular, scalable, and generalizable solution for reliable and explainable multi-agent multimodal reasoning."}}
{"id": "2505.22839", "pdf": "https://arxiv.org/pdf/2505.22839", "abs": "https://arxiv.org/abs/2505.22839", "authors": ["Liu Yuezhang", "Xue-Xin Wei"], "title": "How Do Diffusion Models Improve Adversarial Robustness?", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages, 7 figures", "summary": "Recent findings suggest that diffusion models significantly enhance empirical\nadversarial robustness. While some intuitive explanations have been proposed,\nthe precise mechanisms underlying these improvements remain unclear. In this\nwork, we systematically investigate how and how well diffusion models improve\nadversarial robustness. First, we observe that diffusion models intriguingly\nincrease, rather than decrease, the $\\ell_p$ distance to clean\nsamples--challenging the intuition that purification denoises inputs closer to\nthe original data. Second, we find that the purified images are heavily\ninfluenced by the internal randomness of diffusion models, where a compression\neffect arises within each randomness configuration. Motivated by this\nobservation, we evaluate robustness under fixed randomness and find that the\nimprovement drops to approximately 24% on CIFAR-10--substantially lower than\nprior reports approaching 70%. Importantly, we show that this remaining\nrobustness gain strongly correlates with the model's ability to compress the\ninput space, revealing the compression rate as a reliable robustness indicator\nwithout requiring gradient-based analysis. Our findings provide novel insights\ninto the mechanisms underlying diffusion-based purification, and offer guidance\nfor developing more effective and principled adversarial purification systems.", "AI": {"tldr": "Diffusion models improve adversarial robustness, but the mechanisms are unclear. This study reveals that diffusion models increase distance to clean samples and are influenced by internal randomness, with robustness gains linked to input space compression.", "motivation": "To systematically understand how diffusion models enhance adversarial robustness, given unclear mechanisms despite intuitive explanations.", "method": "Investigate diffusion models' effects on adversarial robustness, focusing on distance to clean samples, internal randomness, and compression effects. Evaluate robustness under fixed randomness and correlate it with compression rate.", "result": "Robustness improvement drops to ~24% under fixed randomness (vs. ~70% prior reports). Remaining gain correlates with input space compression, making compression rate a reliable robustness indicator.", "conclusion": "The study clarifies diffusion-based purification mechanisms, linking robustness to compression, and guides future adversarial purification system development."}}
{"id": "2505.22934", "pdf": "https://arxiv.org/pdf/2505.22934", "abs": "https://arxiv.org/abs/2505.22934", "authors": ["Haobo Zhang", "Jiayu Zhou"], "title": "Unraveling LoRA Interference: Orthogonal Subspaces for Robust Model Merging", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "14 pages, 5 figures, 16 tables, accepted by ACL 2025", "summary": "Fine-tuning large language models (LMs) for individual tasks yields strong\nperformance but is expensive for deployment and storage. Recent works explore\nmodel merging to combine multiple task-specific models into a single multi-task\nmodel without additional training. However, existing merging methods often fail\nfor models fine-tuned with low-rank adaptation (LoRA), due to significant\nperformance degradation. In this paper, we show that this issue arises from a\npreviously overlooked interplay between model parameters and data\ndistributions. We propose Orthogonal Subspaces for Robust model Merging (OSRM)\nto constrain the LoRA subspace *prior* to fine-tuning, ensuring that updates\nrelevant to one task do not adversely shift outputs for others. Our approach\ncan seamlessly integrate with most existing merging algorithms, reducing the\nunintended interference among tasks. Extensive experiments on eight datasets,\ntested with three widely used LMs and two large LMs, demonstrate that our\nmethod not only boosts merging performance but also preserves single-task\naccuracy. Furthermore, our approach exhibits greater robustness to the\nhyperparameters of merging. These results highlight the importance of\ndata-parameter interaction in model merging and offer a plug-and-play solution\nfor merging LoRA models.", "AI": {"tldr": "Proposes OSRM, a method to improve merging of LoRA-fine-tuned models by constraining subspaces to avoid task interference, enhancing performance and robustness.", "motivation": "Addresses performance degradation in merging LoRA-fine-tuned models due to overlooked parameter-data interplay.", "method": "Uses Orthogonal Subspaces for Robust model Merging (OSRM) to constrain LoRA subspaces before fine-tuning, reducing task interference.", "result": "Boosts merging performance, preserves single-task accuracy, and shows robustness to hyperparameters across eight datasets and multiple LMs.", "conclusion": "Highlights data-parameter interaction's role in merging and offers a plug-and-play solution for LoRA model merging."}}
{"id": "2401.13980", "pdf": "https://arxiv.org/pdf/2401.13980", "abs": "https://arxiv.org/abs/2401.13980", "authors": ["Weixuan Chen", "Shuo Shao", "Qianqian Yang", "Zhaoyang Zhang", "Ping Zhang"], "title": "A Superposition Code-Based Semantic Communication Approach with Quantifiable and Controllable Security", "categories": ["cs.IT", "eess.IV", "math.IT"], "comment": null, "summary": "This paper addresses the challenge of achieving security in semantic\ncommunication (SemCom) over a wiretap channel, where a legitimate receiver\ncoexists with an eavesdropper experiencing a poorer channel condition. Despite\nprevious efforts to secure SemCom against eavesdroppers, guarantee of\napproximately zero information leakage remains an open issue. In this work, we\npropose a secure SemCom approach based on superposition codes, aiming to\nprovide quantifiable and controllable security for digital SemCom systems. The\nproposed method employs a double-layered constellation map, where semantic\ninformation is associated with satellite constellation points and cloud center\nconstellation points are randomly selected. By carefully allocating power\nbetween these two layers of constellation, we ensure that the symbol error\nprobability (SEP) of the eavesdropper decoding satellite constellation points\nis nearly equivalent to random guessing, while maintaining a low SEP for the\nlegitimate receiver to successfully decode the semantic information. Simulation\nresults demonstrate that the peak signal-to-noise ratio (PSNR) and mean squared\nerror (MSE) of the eavesdropper' s reconstructed data, under the proposed\nmethod, can range from decoding Gaussian-distributed random noise to\napproaching the variance of the data. This validates the effectiveness of our\nmethod in nearly achieving the experimental upper bound of security for digital\nSemCom systems when both eavesdroppers and legitimate users utilize identical\ndecoding schemes. Furthermore, the proposed method consistently outperforms\nbenchmark techniques, showcasing superior data security and robustness against\neavesdropping.", "AI": {"tldr": "Proposes a secure semantic communication method using superposition codes to minimize information leakage to eavesdroppers while ensuring reliable decoding for legitimate receivers.", "motivation": "Addresses the open issue of guaranteeing near-zero information leakage in semantic communication over wiretap channels, where eavesdroppers have poorer channel conditions.", "method": "Uses a double-layered constellation map with semantic information in satellite points and random cloud centers, optimizing power allocation to degrade eavesdropper decoding.", "result": "Simulations show eavesdroppers decode noise-like data, while legitimate receivers achieve low error rates, validating near-optimal security.", "conclusion": "The method outperforms benchmarks, offering robust security and reliable communication for digital SemCom systems."}}
{"id": "2505.22938", "pdf": "https://arxiv.org/pdf/2505.22938", "abs": "https://arxiv.org/abs/2505.22938", "authors": ["Ben Weiss"], "title": "Fast Isotropic Median Filtering", "categories": ["cs.CV", "cs.DS"], "comment": "Supplemental material:\n  https://github.com/google/fast-isotropic-median-filter", "summary": "Median filtering is a cornerstone of computational image processing. It\nprovides an effective means of image smoothing, with minimal blurring or\nsoftening of edges, invariance to monotonic transformations such as gamma\nadjustment, and robustness to noise and outliers. However, known algorithms\nhave all suffered from practical limitations: the bit depth of the image data,\nthe size of the filter kernel, or the kernel shape itself. Square-kernel\nimplementations tend to produce streaky cross-hatching artifacts, and nearly\nall known efficient algorithms are in practice limited to square kernels. We\npresent for the first time a method that overcomes all of these limitations.\nOur method operates efficiently on arbitrary bit-depth data, arbitrary kernel\nsizes, and arbitrary convex kernel shapes, including circular shapes.", "AI": {"tldr": "A new method for median filtering overcomes limitations of bit depth, kernel size, and shape, including circular kernels.", "motivation": "Existing median filtering algorithms are limited by bit depth, kernel size, or shape, often producing artifacts like streaky cross-hatching.", "method": "The proposed method efficiently handles arbitrary bit depths, kernel sizes, and convex kernel shapes, including circular ones.", "result": "The method successfully addresses the limitations of previous algorithms, enabling more versatile and artifact-free median filtering.", "conclusion": "This breakthrough allows for broader and more effective use of median filtering in image processing."}}
{"id": "2505.23432", "pdf": "https://arxiv.org/pdf/2505.23432", "abs": "https://arxiv.org/abs/2505.23432", "authors": ["Elisa Celis", "Lingxiao Huang", "Nisheeth K. Vishnoi"], "title": "A Mathematical Framework for AI-Human Integration in Work", "categories": ["cs.AI", "cs.CY", "econ.GN", "q-fin.EC"], "comment": "This paper will appear in ICML 2025", "summary": "The rapid rise of Generative AI (GenAI) tools has sparked debate over their\nrole in complementing or replacing human workers across job contexts. We\npresent a mathematical framework that models jobs, workers, and worker-job fit,\nintroducing a novel decomposition of skills into decision-level and\naction-level subskills to reflect the complementary strengths of humans and\nGenAI. We analyze how changes in subskill abilities affect job success,\nidentifying conditions for sharp transitions in success probability. We also\nestablish sufficient conditions under which combining workers with\ncomplementary subskills significantly outperforms relying on a single worker.\nThis explains phenomena such as productivity compression, where GenAI\nassistance yields larger gains for lower-skilled workers. We demonstrate the\nframework' s practicality using data from O*NET and Big-Bench Lite, aligning\nreal-world data with our model via subskill-division methods. Our results\nhighlight when and how GenAI complements human skills, rather than replacing\nthem.", "AI": {"tldr": "A mathematical framework models human-GenAI collaboration by decomposing skills into decision and action subskills, showing when GenAI complements rather than replaces humans.", "motivation": "To address debates on whether GenAI tools complement or replace human workers by modeling their collaborative potential.", "method": "Introduces a skill decomposition framework (decision and action subskills) and analyzes job success under varying subskill abilities, using O*NET and Big-Bench Lite data.", "result": "Identifies conditions for productivity gains, like larger benefits for lower-skilled workers, and demonstrates practical alignment with real-world data.", "conclusion": "GenAI complements human skills under specific conditions, enhancing productivity without full replacement."}}
{"id": "2505.22840", "pdf": "https://arxiv.org/pdf/2505.22840", "abs": "https://arxiv.org/abs/2505.22840", "authors": ["Dharambir Mahto", "Prashant Yadav", "Mahesh Banavar", "Jim Keany", "Alan T Joseph", "Srinivas Kilambi"], "title": "Development and Validation of SXI++ LNM Algorithm for Sepsis Prediction", "categories": ["cs.LG"], "comment": "Paper accepted at JMAI", "summary": "Sepsis is a life-threatening condition affecting over 48.9 million people\nglobally and causing 11 million deaths annually. Despite medical advancements,\npredicting sepsis remains a challenge due to non-specific symptoms and complex\npathophysiology. The SXI++ LNM is a machine learning scoring system that\nrefines sepsis prediction by leveraging multiple algorithms and deep neural\nnetworks. This study aims to improve robustness in clinical applications and\nevaluates the predictive performance of the SXI++ LNM for sepsis prediction.\nThe model, utilizing a deep neural network, was trained and tested using\nmultiple scenarios with different dataset distributions. The model's\nperformance was assessed against unseen test data, and accuracy, precision, and\narea under the curve (AUC) were calculated. THE SXI++ LNM outperformed the\nstate of the art in three use cases, achieving an AUC of 0.99 (95% CI:\n0.98-1.00). The model demonstrated a precision of 99.9% (95% CI: 99.8-100.0)\nand an accuracy of 99.99% (95% CI: 99.98-100.0), maintaining high reliability.", "AI": {"tldr": "The SXI++ LNM, a machine learning model, improves sepsis prediction with high accuracy (99.99%) and AUC (0.99), outperforming existing methods.", "motivation": "Sepsis prediction is challenging due to non-specific symptoms and complex pathophysiology, necessitating better predictive tools.", "method": "The SXI++ LNM uses deep neural networks and multiple algorithms, tested across varied dataset distributions.", "result": "The model achieved an AUC of 0.99, precision of 99.9%, and accuracy of 99.99%, outperforming state-of-the-art methods.", "conclusion": "The SXI++ LNM is a robust tool for sepsis prediction, demonstrating high reliability in clinical applications."}}
{"id": "2505.22937", "pdf": "https://arxiv.org/pdf/2505.22937", "abs": "https://arxiv.org/abs/2505.22937", "authors": ["Ngeyen Yinkfu"], "title": "Improving QA Efficiency with DistilBERT: Fine-Tuning and Inference on mobile Intel CPUs", "categories": ["cs.CL"], "comment": "This paper presents an efficient transformer-based question-answering\n  model optimized for inference on a 13th Gen Intel i7 CPU. The proposed\n  approach balances performance and computational efficiency, making it\n  suitable for real-time applications on resource-constrained devices. Code for\n  this paper is available upon request via email at nyinkfu@andrew.cmu.edu", "summary": "This study presents an efficient transformer-based question-answering (QA)\nmodel optimized for deployment on a 13th Gen Intel i7-1355U CPU, using the\nStanford Question Answering Dataset (SQuAD) v1.1. Leveraging exploratory data\nanalysis, data augmentation, and fine-tuning of a DistilBERT architecture, the\nmodel achieves a validation F1 score of 0.6536 with an average inference time\nof 0.1208 seconds per question. Compared to a rule-based baseline (F1: 0.3124)\nand full BERT-based models, our approach offers a favorable trade-off between\naccuracy and computational efficiency. This makes it well-suited for real-time\napplications on resource-constrained systems. The study includes systematic\nevaluation of data augmentation strategies and hyperparameter configurations,\nproviding practical insights into optimizing transformer models for CPU-based\ninference.", "AI": {"tldr": "An efficient transformer-based QA model optimized for Intel CPUs achieves a balance between accuracy and speed, outperforming rule-based and full BERT models.", "motivation": "To develop a QA model suitable for real-time applications on resource-constrained systems like Intel CPUs.", "method": "Uses DistilBERT architecture with data augmentation, fine-tuning, and systematic hyperparameter optimization.", "result": "Achieves F1 score of 0.6536 with 0.1208s inference time per question, outperforming baselines.", "conclusion": "The model offers a practical solution for CPU-based inference, balancing accuracy and efficiency."}}
{"id": "2406.09546", "pdf": "https://arxiv.org/pdf/2406.09546", "abs": "https://arxiv.org/abs/2406.09546", "authors": ["Fengbin Guan", "Xin Li", "Zihao Yu", "Yiting Lu", "Zhibo Chen"], "title": "QMamba: On First Exploration of Vision Mamba for Image Quality Assessment", "categories": ["cs.CV", "eess.IV"], "comment": "Accepted by ICML 2025", "summary": "In this work, we take the first exploration of the recently popular\nfoundation model, i.e., State Space Model/Mamba, in image quality assessment\n(IQA), aiming at observing and excavating the perception potential in vision\nMamba. A series of works on Mamba has shown its significant potential in\nvarious fields, e.g., segmentation and classification. However, the perception\ncapability of Mamba remains under-explored. Consequently, we propose QMamba by\nrevisiting and adapting the Mamba model for three crucial IQA tasks, i.e.,\ntask-specific, universal, and transferable IQA, which reveals its clear\nadvantages over existing foundational models, e.g., Swin Transformer, ViT, and\nCNNs, in terms of perception and computational cost. To improve the\ntransferability of QMamba, we propose the StylePrompt tuning paradigm, where\nlightweight mean and variance prompts are injected to assist task-adaptive\ntransfer learning of pre-trained QMamba for different downstream IQA tasks.\nCompared with existing prompt tuning strategies, our StylePrompt enables better\nperceptual transfer with lower computational cost. Extensive experiments on\nmultiple synthetic, authentic IQA datasets, and cross IQA datasets demonstrate\nthe effectiveness of our proposed QMamba. The code will be available at:\nhttps://github.com/bingo-G/QMamba.git", "AI": {"tldr": "QMamba explores the State Space Model/Mamba for image quality assessment (IQA), outperforming models like Swin Transformer and ViT in perception and efficiency. StylePrompt tuning enhances transferability.", "motivation": "To investigate the perception potential of Mamba in IQA, as its capabilities in vision tasks remain under-explored.", "method": "Proposes QMamba by adapting Mamba for IQA tasks and introduces StylePrompt for lightweight task-adaptive transfer learning.", "result": "QMamba shows clear advantages over existing models in perception and computational cost, validated on multiple datasets.", "conclusion": "QMamba, enhanced by StylePrompt, is effective for IQA tasks, offering better performance and efficiency."}}
{"id": "2505.22944", "pdf": "https://arxiv.org/pdf/2505.22944", "abs": "https://arxiv.org/abs/2505.22944", "authors": ["Angtian Wang", "Haibin Huang", "Jacob Zhiyuan Fang", "Yiding Yang", "Chongyang Ma"], "title": "ATI: Any Trajectory Instruction for Controllable Video Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We propose a unified framework for motion control in video generation that\nseamlessly integrates camera movement, object-level translation, and\nfine-grained local motion using trajectory-based inputs. In contrast to prior\nmethods that address these motion types through separate modules or\ntask-specific designs, our approach offers a cohesive solution by projecting\nuser-defined trajectories into the latent space of pre-trained image-to-video\ngeneration models via a lightweight motion injector. Users can specify\nkeypoints and their motion paths to control localized deformations, entire\nobject motion, virtual camera dynamics, or combinations of these. The injected\ntrajectory signals guide the generative process to produce temporally\nconsistent and semantically aligned motion sequences. Our framework\ndemonstrates superior performance across multiple video motion control tasks,\nincluding stylized motion effects (e.g., motion brushes), dynamic viewpoint\nchanges, and precise local motion manipulation. Experiments show that our\nmethod provides significantly better controllability and visual quality\ncompared to prior approaches and commercial solutions, while remaining broadly\ncompatible with various state-of-the-art video generation backbones. Project\npage: https://anytraj.github.io/.", "AI": {"tldr": "A unified framework for motion control in video generation integrates camera movement, object translation, and local motion using trajectory inputs, outperforming prior methods in controllability and quality.", "motivation": "Prior methods handle motion types separately or with task-specific designs, lacking cohesion. This work aims for a unified solution.", "method": "Projects user-defined trajectories into latent space of pre-trained models via a lightweight motion injector, guiding generative process.", "result": "Superior performance in tasks like stylized motion effects, viewpoint changes, and local motion manipulation.", "conclusion": "The framework offers better controllability and visual quality, compatible with various video generation backbones."}}
{"id": "2505.23436", "pdf": "https://arxiv.org/pdf/2505.23436", "abs": "https://arxiv.org/abs/2505.23436", "authors": ["Daniel Jarne Ornia", "Nicholas Bishop", "Joel Dyer", "Wei-Chen Lee", "Ani Calinescu", "Doyne Farme", "Michael Wooldridge"], "title": "Emergent Risk Awareness in Rational Agents under Resource Constraints", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Advanced reasoning models with agentic capabilities (AI agents) are deployed\nto interact with humans and to solve sequential decision-making problems under\n(approximate) utility functions and internal models. When such problems have\nresource or failure constraints where action sequences may be forcibly\nterminated once resources are exhausted, agents face implicit trade-offs that\nreshape their utility-driven (rational) behaviour. Additionally, since these\nagents are typically commissioned by a human principal to act on their behalf,\nasymmetries in constraint exposure can give rise to previously unanticipated\nmisalignment between human objectives and agent incentives. We formalise this\nsetting through a survival bandit framework, provide theoretical and empirical\nresults that quantify the impact of survival-driven preference shifts, identify\nconditions under which misalignment emerges and propose mechanisms to mitigate\nthe emergence of risk-seeking or risk-averse behaviours. As a result, this work\naims to increase understanding and interpretability of emergent behaviours of\nAI agents operating under such survival pressure, and offer guidelines for\nsafely deploying such AI systems in critical resource-limited environments.", "AI": {"tldr": "The paper explores how AI agents under resource constraints exhibit altered utility-driven behaviors, leading to misalignment with human objectives, and proposes mitigation mechanisms.", "motivation": "To understand and address the misalignment between human objectives and AI agent behaviors when operating under survival pressure and resource constraints.", "method": "Formalizes the problem using a survival bandit framework, provides theoretical and empirical analysis, and proposes mechanisms to mitigate risk-seeking or risk-averse behaviors.", "result": "Quantifies the impact of survival-driven preference shifts and identifies conditions for misalignment emergence.", "conclusion": "The work enhances interpretability of AI agent behaviors under survival pressure and offers guidelines for safe deployment in resource-limited environments."}}
{"id": "2505.22841", "pdf": "https://arxiv.org/pdf/2505.22841", "abs": "https://arxiv.org/abs/2505.22841", "authors": ["Franck Gabriel", "Fran\u00e7ois Ged", "Maria Han Veiga", "Emmanuel Schertzer"], "title": "Kernel-Smoothed Scores for Denoising Diffusion: A Bias-Variance Study", "categories": ["cs.LG", "math.PR", "stat.ML", "G.3; I.2.6"], "comment": null, "summary": "Diffusion models now set the benchmark in high-fidelity generative sampling,\nyet they can, in principle, be prone to memorization. In this case, their\nlearned score overfits the finite dataset so that the reverse-time SDE samples\nare mostly training points. In this paper, we interpret the empirical score as\na noisy version of the true score and show that its covariance matrix is\nasymptotically a re-weighted data PCA. In large dimension, the small time limit\nmakes the noise variance blow up while simultaneously reducing spatial\ncorrelation. To reduce this variance, we introduce a kernel-smoothed empirical\nscore and analyze its bias-variance trade-off. We derive asymptotic bounds on\nthe Kullback-Leibler divergence between the true distribution and the one\ngenerated by the modified reverse SDE. Regularization on the score has the same\neffect as increasing the size of the training dataset, and thus helps prevent\nmemorization. A spectral decomposition of the forward diffusion suggests better\nvariance control under some regularity conditions of the true data\ndistribution. Reverse diffusion with kernel-smoothed empirical score can be\nreformulated as a gradient descent drifted toward a Log-Exponential\nDouble-Kernel Density Estimator (LED-KDE). This perspective highlights two\nregularization mechanisms taking place in denoising diffusions: an initial\nGaussian kernel first diffuses mass isotropically in the ambient space, while a\nsecond kernel applied in score space concentrates and spreads that mass along\nthe data manifold. Hence, even a straightforward regularization-without any\nlearning-already mitigates memorization and enhances generalization.\nNumerically, we illustrate our results with several experiments on synthetic\nand MNIST datasets.", "AI": {"tldr": "The paper addresses memorization risks in diffusion models by analyzing the empirical score's noise and proposing kernel-smoothed regularization to improve generalization.", "motivation": "Diffusion models, while effective, can overfit training data, leading to memorization. The study aims to mitigate this by understanding and controlling the noise in the empirical score.", "method": "The authors interpret the empirical score as noisy, analyze its covariance matrix, and introduce kernel-smoothed regularization. They derive bounds on divergence and reformulate reverse diffusion as gradient descent with LED-KDE.", "result": "Kernel-smoothed regularization reduces variance, prevents memorization, and enhances generalization, akin to increasing dataset size. Spectral analysis suggests better variance control under certain conditions.", "conclusion": "Regularization, even without learning, mitigates memorization and improves generalization, as demonstrated on synthetic and MNIST datasets."}}
{"id": "2505.22942", "pdf": "https://arxiv.org/pdf/2505.22942", "abs": "https://arxiv.org/abs/2505.22942", "authors": ["Yuchen Zhuang", "Di Jin", "Jiaao Chen", "Wenqi Shi", "Hanrui Wang", "Chao Zhang"], "title": "WorkForceAgent-R1: Incentivizing Reasoning Capability in LLM-based Web Agents via Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": "Work in Progress", "summary": "Large language models (LLMs)-empowered web agents enables automating complex,\nreal-time web navigation tasks in enterprise environments. However, existing\nweb agents relying on supervised fine-tuning (SFT) often struggle with\ngeneralization and robustness due to insufficient reasoning capabilities when\nhandling the inherently dynamic nature of web interactions. In this study, we\nintroduce WorkForceAgent-R1, an LLM-based web agent trained using a rule-based\nR1-style reinforcement learning framework designed explicitly to enhance\nsingle-step reasoning and planning for business-oriented web navigation tasks.\nWe employ a structured reward function that evaluates both adherence to output\nformats and correctness of actions, enabling WorkForceAgent-R1 to implicitly\nlearn robust intermediate reasoning without explicit annotations or extensive\nexpert demonstrations. Extensive experiments on the WorkArena benchmark\ndemonstrate that WorkForceAgent-R1 substantially outperforms SFT baselines by\n10.26-16.59%, achieving competitive performance relative to proprietary\nLLM-based agents (gpt-4o) in workplace-oriented web navigation tasks.", "AI": {"tldr": "WorkForceAgent-R1, an LLM-based web agent using rule-based R1-style reinforcement learning, outperforms SFT baselines by 10.26-16.59% in business-oriented web navigation tasks.", "motivation": "Existing web agents struggle with generalization and robustness due to insufficient reasoning in dynamic web interactions.", "method": "Rule-based R1-style reinforcement learning with a structured reward function for single-step reasoning and planning.", "result": "Substantially outperforms SFT baselines by 10.26-16.59% and achieves competitive performance with proprietary LLM-based agents.", "conclusion": "WorkForceAgent-R1 enhances robustness and reasoning in business-oriented web navigation tasks."}}
{"id": "2410.04081", "pdf": "https://arxiv.org/pdf/2410.04081", "abs": "https://arxiv.org/abs/2410.04081", "authors": ["Long Zhao", "Sanghyun Woo", "Ziyu Wan", "Yandong Li", "Han Zhang", "Boqing Gong", "Hartwig Adam", "Xuhui Jia", "Ting Liu"], "title": "Epsilon-VAE: Denoising as Visual Decoding", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": "Accepted to ICML 2025. v2: added comparisons to SD-VAE and more\n  visual results; v3: minor change to title; v4: camera-ready version", "summary": "In generative modeling, tokenization simplifies complex data into compact,\nstructured representations, creating a more efficient, learnable space. For\nhigh-dimensional visual data, it reduces redundancy and emphasizes key features\nfor high-quality generation. Current visual tokenization methods rely on a\ntraditional autoencoder framework, where the encoder compresses data into\nlatent representations, and the decoder reconstructs the original input. In\nthis work, we offer a new perspective by proposing denoising as decoding,\nshifting from single-step reconstruction to iterative refinement. Specifically,\nwe replace the decoder with a diffusion process that iteratively refines noise\nto recover the original image, guided by the latents provided by the encoder.\nWe evaluate our approach by assessing both reconstruction (rFID) and generation\nquality (FID), comparing it to state-of-the-art autoencoding approaches. By\nadopting iterative reconstruction through diffusion, our autoencoder, namely\nEpsilon-VAE, achieves high reconstruction quality, which in turn enhances\ndownstream generation quality by 22% at the same compression rates or provides\n2.3x inference speedup through increasing compression rates. We hope this work\noffers new insights into integrating iterative generation and autoencoding for\nimproved compression and generation.", "AI": {"tldr": "The paper proposes Epsilon-VAE, a novel autoencoder using diffusion for iterative refinement, improving reconstruction and generation quality over traditional methods.", "motivation": "Current visual tokenization methods rely on single-step reconstruction, limiting efficiency and quality. The authors aim to enhance this by integrating iterative refinement via diffusion.", "method": "Replace the traditional decoder with a diffusion process for iterative refinement of noise into the original image, guided by encoder latents.", "result": "Epsilon-VAE achieves 22% better generation quality and 2.3x faster inference at the same compression rates compared to state-of-the-art autoencoders.", "conclusion": "The work demonstrates the benefits of combining iterative generation with autoencoding, offering improved compression and generation insights."}}
{"id": "2505.22971", "pdf": "https://arxiv.org/pdf/2505.22971", "abs": "https://arxiv.org/abs/2505.22971", "authors": ["Yu Yuan", "Yiheng Chi", "Xingguang Zhang", "Stanley Chan"], "title": "iHDR: Iterative HDR Imaging with Arbitrary Number of Exposures", "categories": ["eess.IV", "cs.CV"], "comment": "To be appear in IEEE ICIP 2025", "summary": "High dynamic range (HDR) imaging aims to obtain a high-quality HDR image by\nfusing information from multiple low dynamic range (LDR) images. Numerous\nlearning-based HDR imaging methods have been proposed to achieve this for\nstatic and dynamic scenes. However, their architectures are mostly tailored for\na fixed number (e.g., three) of inputs and, therefore, cannot apply directly to\nsituations beyond the pre-defined limited scope. To address this issue, we\npropose a novel framework, iHDR, for iterative fusion, which comprises a\nghost-free Dual-input HDR fusion network (DiHDR) and a physics-based domain\nmapping network (ToneNet). DiHDR leverages a pair of inputs to estimate an\nintermediate HDR image, while ToneNet maps it back to the nonlinear domain and\nserves as the reference input for the next pairwise fusion. This process is\niteratively executed until all input frames are utilized. Qualitative and\nquantitative experiments demonstrate the effectiveness of the proposed method\nas compared to existing state-of-the-art HDR deghosting approaches given\nflexible numbers of input frames.", "AI": {"tldr": "The paper proposes iHDR, a framework for iterative HDR image fusion, handling flexible input numbers via a dual-input network (DiHDR) and a physics-based mapping network (ToneNet).", "motivation": "Existing HDR methods are limited to fixed input numbers, restricting their applicability. The goal is to enable flexible input handling for broader scenarios.", "method": "iHDR combines DiHDR (for pairwise HDR fusion) and ToneNet (for domain mapping), iteratively processing inputs until all frames are used.", "result": "The method outperforms state-of-the-art HDR deghosting approaches with flexible input counts, as shown in qualitative and quantitative tests.", "conclusion": "iHDR effectively addresses the limitation of fixed input numbers in HDR imaging, offering superior performance and flexibility."}}
{"id": "2505.23473", "pdf": "https://arxiv.org/pdf/2505.23473", "abs": "https://arxiv.org/abs/2505.23473", "authors": ["Xiaorui Wu", "Xiaofeng Mao", "Fei Li", "Xin Zhang", "Xiaolu Zhang", "Jun Zhou", "Yuxiang Peng", "Li Zheng", "Chong Teng", "Donghong Ji", "Zhuang Li"], "title": "EVOREFUSE: Evolutionary Prompt Optimization for Evaluation and Mitigation of LLM Over-Refusal to Pseudo-Malicious Instructions", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) frequently refuse to respond to pseudo-malicious\ninstructions: semantically harmless input queries triggering unnecessary LLM\nrefusals due to conservative safety alignment, significantly impairing user\nexperience. Collecting such instructions is crucial for evaluating and\nmitigating over-refusals, but existing instruction curation methods, like\nmanual creation or instruction rewriting, either lack scalability or fail to\nproduce sufficiently diverse and effective refusal-inducing prompts. To address\nthese limitations, we introduce EVOREFUSE, a prompt optimization approach that\ngenerates diverse pseudo-malicious instructions consistently eliciting\nconfident refusals across LLMs. EVOREFUSE employs an evolutionary algorithm\nexploring the instruction space in more diverse directions than existing\nmethods via mutation strategies and recombination, and iteratively evolves seed\ninstructions to maximize evidence lower bound on LLM refusal probability. Using\nEVOREFUSE, we create two novel datasets: EVOREFUSE-TEST, a benchmark of 582\npseudo-malicious instructions that outperforms the next-best benchmark with\n140.41% higher average refusal triggering rate across 9 LLMs, 34.86% greater\nlexical diversity, and 40.03% improved LLM response confidence scores; and\nEVOREFUSE-ALIGN, which provides 3,000 pseudo-malicious instructions with\nresponses for supervised and preference-based alignment training.\nLLAMA3.1-8B-INSTRUCT supervisedly fine-tuned on EVOREFUSE-ALIGN achieves up to\n14.31% fewer over-refusals than models trained on the second-best alignment\ndataset, without compromising safety. Our analysis with EVOREFUSE-TEST reveals\nmodels trigger over-refusals by overly focusing on sensitive keywords while\nignoring broader context.", "AI": {"tldr": "EVOREFUSE is a prompt optimization method using evolutionary algorithms to generate diverse pseudo-malicious instructions, improving LLM refusal evaluation and alignment training.", "motivation": "Addressing the issue of LLMs over-refusing harmless queries due to conservative safety alignment, which harms user experience.", "method": "EVOREFUSE employs an evolutionary algorithm with mutation and recombination to optimize prompts, maximizing refusal probability.", "result": "Created datasets EVOREFUSE-TEST and EVOREFUSE-ALIGN, showing higher refusal rates, diversity, and improved alignment training outcomes.", "conclusion": "EVOREFUSE effectively mitigates over-refusals and enhances LLM alignment without compromising safety."}}
{"id": "2505.22846", "pdf": "https://arxiv.org/pdf/2505.22846", "abs": "https://arxiv.org/abs/2505.22846", "authors": ["Nikita Khramov", "Andrei Kozyrev", "Gleb Solovev", "Anton Podkopaev"], "title": "RocqStar: Leveraging Similarity-driven Retrieval and Agentic Systems for Rocq generation", "categories": ["cs.LG", "cs.AI", "cs.LO", "cs.SE"], "comment": null, "summary": "Interactive Theorem Proving was repeatedly shown to be fruitful combined with\nGenerative Artificial Intelligence. This paper assesses multiple approaches to\nRocq generation and illuminates potential avenues for improvement. We highlight\nthe importance of thorough premise selection for generating Rocq proofs and\npropose a novel approach, leveraging retrieval via a self-attentive embedder\nmodel. The evaluation of the designed approach shows up to 28% relative\nincrease of the generator's performance. We tackle the problem of writing Rocq\nproofs using a multi-stage agentic system, tailored for formal verification,\nand demonstrate its high effectiveness. We conduct an ablation study and show\nthe use of multi-agent debate on the planning stage of proof synthesis.", "AI": {"tldr": "The paper explores combining Interactive Theorem Proving with Generative AI, proposing a novel method for Rocq proof generation using a self-attentive embedder model, achieving a 28% performance boost.", "motivation": "To improve Rocq proof generation by addressing premise selection and leveraging AI techniques.", "method": "A multi-stage agentic system with a self-attentive embedder model and multi-agent debate for proof synthesis.", "result": "28% relative increase in generator performance, demonstrating high effectiveness.", "conclusion": "The proposed approach significantly enhances Rocq proof generation, with potential for further improvements."}}
{"id": "2505.22945", "pdf": "https://arxiv.org/pdf/2505.22945", "abs": "https://arxiv.org/abs/2505.22945", "authors": ["Alisha Srivastava", "Emir Korukluoglu", "Minh Nhat Le", "Duyen Tran", "Chau Minh Pham", "Marzena Karpinska", "Mohit Iyyer"], "title": "OWL: Probing Cross-Lingual Recall of Memorized Texts via World Literature", "categories": ["cs.CL", "cs.AI"], "comment": "preprint, 25 pages", "summary": "Large language models (LLMs) are known to memorize and recall English text\nfrom their pretraining data. However, the extent to which this ability\ngeneralizes to non-English languages or transfers across languages remains\nunclear. This paper investigates multilingual and cross-lingual memorization in\nLLMs, probing if memorized content in one language (e.g., English) can be\nrecalled when presented in translation. To do so, we introduce OWL, a dataset\nof 31.5K aligned excerpts from 20 books in ten languages, including English\noriginals, official translations (Vietnamese, Spanish, Turkish), and new\ntranslations in six low-resource languages (Sesotho, Yoruba, Maithili,\nMalagasy, Setswana, Tahitian). We evaluate memorization across model families\nand sizes through three tasks: (1) direct probing, which asks the model to\nidentify a book's title and author; (2) name cloze, which requires predicting\nmasked character names; and (3) prefix probing, which involves generating\ncontinuations. We find that LLMs consistently recall content across languages,\neven for texts without direct translation in pretraining data. GPT-4o, for\nexample, identifies authors and titles 69% of the time and masked entities 6%\nof the time in newly translated excerpts. Perturbations (e.g., masking\ncharacters, shuffling words) modestly reduce direct probing accuracy (7% drop\nfor shuffled official translations). Our results highlight the extent of\ncross-lingual memorization and provide insights on the differences between the\nmodels.", "AI": {"tldr": "The paper explores multilingual and cross-lingual memorization in LLMs, finding they recall content across languages, even without direct translation in pretraining data.", "motivation": "To understand if LLMs' memorization ability generalizes to non-English languages or transfers across languages.", "method": "Uses the OWL dataset (31.5K aligned excerpts in 10 languages) and evaluates memorization via direct probing, name cloze, and prefix probing tasks.", "result": "LLMs recall content across languages; GPT-4o identifies authors/titles 69% of the time and masked entities 6% of the time in new translations.", "conclusion": "LLMs exhibit significant cross-lingual memorization, with modest reductions from perturbations, revealing differences between models."}}
{"id": "2504.10974", "pdf": "https://arxiv.org/pdf/2504.10974", "abs": "https://arxiv.org/abs/2504.10974", "authors": ["Zhisheng Zhang", "Peng Zhang", "Fengxiang Wang", "Liangli Ma", "Fuchun Sun"], "title": "Self-Supervised Enhancement of Forward-Looking Sonar Images: Bridging Cross-Modal Degradation Gaps through Feature Space Transformation and Multi-Frame Fusion", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Enhancing forward-looking sonar images is critical for accurate underwater\ntarget detection. Current deep learning methods mainly rely on supervised\ntraining with simulated data, but the difficulty in obtaining high-quality\nreal-world paired data limits their practical use and generalization. Although\nself-supervised approaches from remote sensing partially alleviate data\nshortages, they neglect the cross-modal degradation gap between sonar and\nremote sensing images. Directly transferring pretrained weights often leads to\noverly smooth sonar images, detail loss, and insufficient brightness. To\naddress this, we propose a feature-space transformation that maps sonar images\nfrom the pixel domain to a robust feature domain, effectively bridging the\ndegradation gap. Additionally, our self-supervised multi-frame fusion strategy\nleverages complementary inter-frame information to naturally remove speckle\nnoise and enhance target-region brightness. Experiments on three self-collected\nreal-world forward-looking sonar datasets show that our method significantly\noutperforms existing approaches, effectively suppressing noise, preserving\ndetailed edges, and substantially improving brightness, demonstrating strong\npotential for underwater target detection applications.", "AI": {"tldr": "A feature-space transformation and self-supervised multi-frame fusion method enhances sonar images, outperforming existing approaches in noise suppression, edge preservation, and brightness improvement.", "motivation": "The difficulty in obtaining high-quality real-world paired data for supervised training and the limitations of transferring pretrained weights from remote sensing to sonar images motivate the need for a specialized solution.", "method": "Proposes a feature-space transformation to map sonar images to a robust feature domain and a self-supervised multi-frame fusion strategy to leverage inter-frame information for noise removal and brightness enhancement.", "result": "Outperforms existing methods on real-world datasets, effectively suppressing noise, preserving edges, and improving brightness.", "conclusion": "The method demonstrates strong potential for underwater target detection by addressing the degradation gap and enhancing sonar image quality."}}
{"id": "2505.22976", "pdf": "https://arxiv.org/pdf/2505.22976", "abs": "https://arxiv.org/abs/2505.22976", "authors": ["Kewei Lian", "Shaofei Cai", "Yilun Du", "Yitao Liang"], "title": "Toward Memory-Aided World Models: Benchmarking via Spatial Consistency", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The ability to simulate the world in a spatially consistent manner is a\ncrucial requirements for effective world models. Such a model enables\nhigh-quality visual generation, and also ensures the reliability of world\nmodels for downstream tasks such as simulation and planning. Designing a memory\nmodule is a crucial component for addressing spatial consistency: such a model\nmust not only retain long-horizon observational information, but also enables\nthe construction of explicit or implicit internal spatial representations.\nHowever, there are no dataset designed to promote the development of memory\nmodules by explicitly enforcing spatial consistency constraints. Furthermore,\nmost existing benchmarks primarily emphasize visual coherence or generation\nquality, neglecting the requirement of long-range spatial consistency. To\nbridge this gap, we construct a dataset and corresponding benchmark by sampling\n150 distinct locations within the open-world environment of Minecraft,\ncollecting about 250 hours (20 million frames) of loop-based navigation videos\nwith actions. Our dataset follows a curriculum design of sequence lengths,\nallowing models to learn spatial consistency on increasingly complex navigation\ntrajectories. Furthermore, our data collection pipeline is easily extensible to\nnew Minecraft environments and modules. Four representative world model\nbaselines are evaluated on our benchmark. Dataset, benchmark, and code are\nopen-sourced to support future research.", "AI": {"tldr": "The paper introduces a dataset and benchmark for training spatially consistent world models, using Minecraft navigation videos to enforce long-range spatial consistency.", "motivation": "Existing datasets lack explicit spatial consistency constraints, focusing instead on visual coherence or generation quality, which limits the development of effective world models.", "method": "A dataset of 150 Minecraft locations with 250 hours of loop-based navigation videos is created, featuring a curriculum design for sequence lengths. Four world model baselines are evaluated.", "result": "The dataset and benchmark are open-sourced, enabling future research on spatially consistent world models.", "conclusion": "The work bridges the gap in datasets for spatial consistency, providing a scalable and extensible solution for training and evaluating world models."}}
{"id": "2505.23474", "pdf": "https://arxiv.org/pdf/2505.23474", "abs": "https://arxiv.org/abs/2505.23474", "authors": ["Xiang Li", "Haiyang Yu", "Xinghua Zhang", "Ziyang Huang", "Shizhu He", "Kang Liu", "Jun Zhao", "Fei Huang", "Yongbin Li"], "title": "Socratic-PRMBench: Benchmarking Process Reward Models with Systematic Reasoning Patterns", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Process Reward Models (PRMs) are crucial in complex reasoning and\nproblem-solving tasks (e.g., LLM agents with long-horizon decision-making) by\nverifying the correctness of each intermediate reasoning step. In real-world\nscenarios, LLMs may apply various reasoning patterns (e.g., decomposition) to\nsolve a problem, potentially suffering from errors under various reasoning\npatterns. Therefore, PRMs are required to identify errors under various\nreasoning patterns during the reasoning process. However, existing benchmarks\nmainly focus on evaluating PRMs with stepwise correctness, ignoring a\nsystematic evaluation of PRMs under various reasoning patterns. To mitigate\nthis gap, we introduce Socratic-PRMBench, a new benchmark to evaluate PRMs\nsystematically under six reasoning patterns, including Transformation,\nDecomposition, Regather, Deduction, Verification, and Integration.\nSocratic-PRMBench}comprises 2995 reasoning paths with flaws within the\naforementioned six reasoning patterns. Through our experiments on both PRMs and\nLLMs prompted as critic models, we identify notable deficiencies in existing\nPRMs. These observations underscore the significant weakness of current PRMs in\nconducting evaluations on reasoning steps under various reasoning patterns. We\nhope Socratic-PRMBench can serve as a comprehensive testbed for systematic\nevaluation of PRMs under diverse reasoning patterns and pave the way for future\ndevelopment of PRMs.", "AI": {"tldr": "Socratic-PRMBench is introduced to evaluate Process Reward Models (PRMs) under six reasoning patterns, revealing deficiencies in current PRMs.", "motivation": "Existing benchmarks lack systematic evaluation of PRMs under diverse reasoning patterns, leading to gaps in identifying errors.", "method": "A new benchmark, Socratic-PRMBench, with 2995 flawed reasoning paths across six reasoning patterns, is used to test PRMs and LLMs.", "result": "Experiments show significant weaknesses in current PRMs when evaluating reasoning steps under various patterns.", "conclusion": "Socratic-PRMBench aims to improve PRM evaluation and guide future development by addressing current limitations."}}
{"id": "2505.22861", "pdf": "https://arxiv.org/pdf/2505.22861", "abs": "https://arxiv.org/abs/2505.22861", "authors": ["Carlota Par\u00e9s-Morlans", "Michelle Yi", "Claire Chen", "Sarah A. Wu", "Rika Antonova", "Tobias Gerstenberg", "Jeannette Bohg"], "title": "Causal-PIK: Causality-based Physical Reasoning with a Physics-Informed Kernel", "categories": ["cs.LG"], "comment": "Accepted to ICML 2025", "summary": "Tasks that involve complex interactions between objects with unknown dynamics\nmake planning before execution difficult. These tasks require agents to\niteratively improve their actions after actively exploring causes and effects\nin the environment. For these type of tasks, we propose Causal-PIK, a method\nthat leverages Bayesian optimization to reason about causal interactions via a\nPhysics-Informed Kernel to help guide efficient search for the best next\naction. Experimental results on Virtual Tools and PHYRE physical reasoning\nbenchmarks show that Causal-PIK outperforms state-of-the-art results, requiring\nfewer actions to reach the goal. We also compare Causal-PIK to human studies,\nincluding results from a new user study we conducted on the PHYRE benchmark. We\nfind that Causal-PIK remains competitive on tasks that are very challenging,\neven for human problem-solvers.", "AI": {"tldr": "Causal-PIK uses Bayesian optimization and a Physics-Informed Kernel to improve action planning in complex tasks, outperforming state-of-the-art methods and even matching human performance in challenging scenarios.", "motivation": "Planning in tasks with unknown object dynamics is difficult, requiring iterative action improvement through active exploration of causes and effects.", "method": "Causal-PIK leverages Bayesian optimization and a Physics-Informed Kernel to efficiently search for optimal actions by reasoning about causal interactions.", "result": "Causal-PIK outperforms state-of-the-art methods on Virtual Tools and PHYRE benchmarks, requiring fewer actions to achieve goals, and remains competitive with human performance in challenging tasks.", "conclusion": "Causal-PIK is effective for complex tasks with unknown dynamics, demonstrating superior performance and scalability compared to existing methods and human problem-solvers."}}
{"id": "2505.22946", "pdf": "https://arxiv.org/pdf/2505.22946", "abs": "https://arxiv.org/abs/2505.22946", "authors": ["Yuhui Zhang", "Yuchang Su", "Yiming Liu", "Serena Yeung-Levy"], "title": "NegVQA: Can Vision Language Models Understand Negation?", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.CY", "cs.LG"], "comment": "Published at ACL 2025 Findings", "summary": "Negation is a fundamental linguistic phenomenon that can entirely reverse the\nmeaning of a sentence. As vision language models (VLMs) continue to advance and\nare deployed in high-stakes applications, assessing their ability to comprehend\nnegation becomes essential. To address this, we introduce NegVQA, a visual\nquestion answering (VQA) benchmark consisting of 7,379 two-choice questions\ncovering diverse negation scenarios and image-question distributions. We\nconstruct NegVQA by leveraging large language models to generate negated\nversions of questions from existing VQA datasets. Evaluating 20\nstate-of-the-art VLMs across seven model families, we find that these models\nstruggle significantly with negation, exhibiting a substantial performance drop\ncompared to their responses to the original questions. Furthermore, we uncover\na U-shaped scaling trend, where increasing model size initially degrades\nperformance on NegVQA before leading to improvements. Our benchmark reveals\ncritical gaps in VLMs' negation understanding and offers insights into future\nVLM development. Project page available at\nhttps://yuhui-zh15.github.io/NegVQA/.", "AI": {"tldr": "NegVQA is a benchmark for evaluating vision-language models' (VLMs) understanding of negation, revealing significant gaps in their performance.", "motivation": "Assessing VLMs' comprehension of negation is crucial as they advance in high-stakes applications.", "method": "NegVQA was created by generating negated questions from existing VQA datasets using large language models, and 20 VLMs were evaluated.", "result": "VLMs struggle with negation, showing a performance drop and a U-shaped scaling trend with model size.", "conclusion": "NegVQA highlights critical gaps in VLMs' negation understanding and provides insights for future development."}}
{"id": "2505.20876", "pdf": "https://arxiv.org/pdf/2505.20876", "abs": "https://arxiv.org/abs/2505.20876", "authors": ["Tatsuya Sasayama", "Shintaro Ito", "Koichi Ito", "Takafumi Aoki"], "title": "Stereo Radargrammetry Using Deep Learning from Airborne SAR Images", "categories": ["cs.CV", "eess.IV"], "comment": "5 pages, 5 figures, conference IGARSS2025", "summary": "In this paper, we propose a stereo radargrammetry method using deep learning\nfrom airborne Synthetic Aperture Radar (SAR) images. Deep learning-based\nmethods are considered to suffer less from geometric image modulation, while\nthere is no public SAR image dataset used to train such methods. We create a\nSAR image dataset and perform fine-tuning of a deep learning-based image\ncorrespondence method. The proposed method suppresses the degradation of image\nquality by pixel interpolation without ground projection of the SAR image and\ndivides the SAR image into patches for processing, which makes it possible to\napply deep learning. Through a set of experiments, we demonstrate that the\nproposed method exhibits a wider range and more accurate elevation measurements\ncompared to conventional methods. The project web page is available at:\nhttps://gsisaoki.github.io/IGARSS2025_sasayama/", "AI": {"tldr": "A deep learning-based stereo radargrammetry method for airborne SAR images is proposed, addressing the lack of public datasets and improving elevation measurement accuracy.", "motivation": "Deep learning methods for SAR images lack public datasets and suffer from geometric modulation issues, prompting the creation of a new dataset and method.", "method": "The method involves creating a SAR dataset, fine-tuning a deep learning-based correspondence method, and processing images in patches without ground projection.", "result": "Experiments show the method achieves wider range and more accurate elevation measurements than conventional techniques.", "conclusion": "The proposed method effectively addresses SAR image processing challenges and outperforms traditional approaches."}}
{"id": "2505.22977", "pdf": "https://arxiv.org/pdf/2505.22977", "abs": "https://arxiv.org/abs/2505.22977", "authors": ["Shuolin Xu", "Siming Zheng", "Ziyi Wang", "HC Yu", "Jinwei Chen", "Huaqi Zhang", "Bo Li", "Peng-Tao Jiang"], "title": "HyperMotion: DiT-Based Pose-Guided Human Image Animation of Complex Motions", "categories": ["cs.CV"], "comment": "17 pages, 7 figures", "summary": "Recent advances in diffusion models have significantly improved conditional\nvideo generation, particularly in the pose-guided human image animation task.\nAlthough existing methods are capable of generating high-fidelity and\ntime-consistent animation sequences in regular motions and static scenes, there\nare still obvious limitations when facing complex human body motions\n(Hypermotion) that contain highly dynamic, non-standard motions, and the lack\nof a high-quality benchmark for evaluation of complex human motion animations.\nTo address this challenge, we introduce the \\textbf{Open-HyperMotionX Dataset}\nand \\textbf{HyperMotionX Bench}, which provide high-quality human pose\nannotations and curated video clips for evaluating and improving pose-guided\nhuman image animation models under complex human motion conditions.\nFurthermore, we propose a simple yet powerful DiT-based video generation\nbaseline and design spatial low-frequency enhanced RoPE, a novel module that\nselectively enhances low-frequency spatial feature modeling by introducing\nlearnable frequency scaling. Our method significantly improves structural\nstability and appearance consistency in highly dynamic human motion sequences.\nExtensive experiments demonstrate the effectiveness of our dataset and proposed\napproach in advancing the generation quality of complex human motion image\nanimations. Code and dataset will be made publicly available.", "AI": {"tldr": "The paper introduces a dataset and benchmark for complex human motion animation, proposes a DiT-based video generation method with a novel spatial low-frequency enhancement module, and demonstrates improved performance in dynamic motion sequences.", "motivation": "Existing methods struggle with complex human motions (Hypermotion) and lack high-quality benchmarks for evaluation.", "method": "Proposes a DiT-based video generation baseline with a spatial low-frequency enhanced RoPE module to enhance feature modeling.", "result": "The method improves structural stability and appearance consistency in dynamic motion sequences.", "conclusion": "The introduced dataset and method advance the quality of complex human motion animations, with code and dataset to be made public."}}
{"id": "2505.23486", "pdf": "https://arxiv.org/pdf/2505.23486", "abs": "https://arxiv.org/abs/2505.23486", "authors": ["Ke Weng", "Lun Du", "Sirui Li", "Wangyue Lu", "Haozhe Sun", "Hengyu Liu", "Tiancheng Zhang"], "title": "Autoformalization in the Era of Large Language Models: A Survey", "categories": ["cs.AI"], "comment": null, "summary": "Autoformalization, the process of transforming informal mathematical\npropositions into verifiable formal representations, is a foundational task in\nautomated theorem proving, offering a new perspective on the use of mathematics\nin both theoretical and applied domains. Driven by the rapid progress in\nartificial intelligence, particularly large language models (LLMs), this field\nhas witnessed substantial growth, bringing both new opportunities and unique\nchallenges. In this survey, we provide a comprehensive overview of recent\nadvances in autoformalization from both mathematical and LLM-centric\nperspectives. We examine how autoformalization is applied across various\nmathematical domains and levels of difficulty, and analyze the end-to-end\nworkflow from data preprocessing to model design and evaluation. We further\nexplore the emerging role of autoformalization in enhancing the verifiability\nof LLM-generated outputs, highlighting its potential to improve both the\ntrustworthiness and reasoning capabilities of LLMs. Finally, we summarize key\nopen-source models and datasets supporting current research, and discuss open\nchallenges and promising future directions for the field.", "AI": {"tldr": "A survey on autoformalization, covering its role in AI and theorem proving, recent advances, applications, and future challenges.", "motivation": "To explore autoformalization's potential in enhancing theorem proving and LLM outputs, driven by AI advancements.", "method": "Examines autoformalization workflows, from data preprocessing to model evaluation, across mathematical domains.", "result": "Highlights autoformalization's impact on LLM verifiability and reasoning, with key open-source resources identified.", "conclusion": "Summarizes progress, open challenges, and future directions for autoformalization research."}}
{"id": "2505.22866", "pdf": "https://arxiv.org/pdf/2505.22866", "abs": "https://arxiv.org/abs/2505.22866", "authors": ["Nicolas Espinosa-Dice", "Yiyi Zhang", "Yiding Chen", "Bradley Guo", "Owen Oertell", "Gokul Swamy", "Kiante Brantley", "Wen Sun"], "title": "Scaling Offline RL via Efficient and Expressive Shortcut Models", "categories": ["cs.LG", "cs.AI", "I.2.6"], "comment": "32 pages, 5 figures. Under review at NeurIPS 2025", "summary": "Diffusion and flow models have emerged as powerful generative approaches\ncapable of modeling diverse and multimodal behavior. However, applying these\nmodels to offline reinforcement learning (RL) remains challenging due to the\niterative nature of their noise sampling processes, making policy optimization\ndifficult. In this paper, we introduce Scalable Offline Reinforcement Learning\n(SORL), a new offline RL algorithm that leverages shortcut models - a novel\nclass of generative models - to scale both training and inference. SORL's\npolicy can capture complex data distributions and can be trained simply and\nefficiently in a one-stage training procedure. At test time, SORL introduces\nboth sequential and parallel inference scaling by using the learned Q-function\nas a verifier. We demonstrate that SORL achieves strong performance across a\nrange of offline RL tasks and exhibits positive scaling behavior with increased\ntest-time compute. We release the code at\nnico-espinosadice.github.io/projects/sorl.", "AI": {"tldr": "SORL is a scalable offline RL algorithm using shortcut models for efficient training and inference, achieving strong performance across tasks.", "motivation": "Applying diffusion and flow models to offline RL is challenging due to iterative noise sampling. SORL addresses this by leveraging shortcut models.", "method": "SORL uses shortcut models for one-stage training and employs Q-function verification for sequential and parallel inference scaling.", "result": "SORL performs well across offline RL tasks and scales positively with increased test-time compute.", "conclusion": "SORL offers a scalable and efficient solution for offline RL, demonstrated by its strong performance and released code."}}
{"id": "2505.22950", "pdf": "https://arxiv.org/pdf/2505.22950", "abs": "https://arxiv.org/abs/2505.22950", "authors": ["Haohan Yuan", "Sukhwa Hong", "Haopeng Zhang"], "title": "StrucSum: Graph-Structured Reasoning for Long Document Extractive Summarization with LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have shown strong performance in zero-shot\nsummarization, but often struggle to model document structure and identify\nsalient information in long texts. In this work, we introduce StrucSum, a\ntraining-free prompting framework that enhances LLM reasoning through\nsentence-level graph structures. StrucSum injects structural signals into\nprompts via three targeted strategies: Neighbor-Aware Prompting (NAP) for local\ncontext, Centrality-Aware Prompting (CAP) for importance estimation, and\nCentrality-Guided Masking (CGM) for efficient input reduction. Experiments on\nArXiv, PubMed, and Multi-News demonstrate that StrucSum consistently improves\nboth summary quality and factual consistency over unsupervised baselines and\nvanilla prompting. Notably, on ArXiv, it boosts FactCC and SummaC by 19.2 and\n9.7 points, indicating stronger alignment between summaries and source content.\nThese findings suggest that structure-aware prompting is a simple yet effective\napproach for zero-shot extractive summarization with LLMs, without any training\nor task-specific tuning.", "AI": {"tldr": "StrucSum is a training-free prompting framework that improves LLM summarization by incorporating document structure through graph-based strategies, outperforming baselines in quality and factual consistency.", "motivation": "LLMs struggle with document structure and salient information in long texts for zero-shot summarization.", "method": "StrucSum uses three strategies: Neighbor-Aware Prompting (NAP), Centrality-Aware Prompting (CAP), and Centrality-Guided Masking (CGM) to inject structural signals into prompts.", "result": "Experiments show StrucSum improves summary quality and factual consistency, with notable gains on ArXiv (19.2 and 9.7 points for FactCC and SummaC).", "conclusion": "Structure-aware prompting is effective for zero-shot extractive summarization with LLMs, requiring no training or task-specific tuning."}}
{"id": "2505.22978", "pdf": "https://arxiv.org/pdf/2505.22978", "abs": "https://arxiv.org/abs/2505.22978", "authors": ["Youngju Na", "Taeyeon Kim", "Jumin Lee", "Kyu Beom Han", "Woo Jae Kim", "Sung-eui Yoon"], "title": "Pose-free 3D Gaussian splatting via shape-ray estimation", "categories": ["cs.CV"], "comment": "ICIP 2025", "summary": "While generalizable 3D Gaussian splatting enables efficient, high-quality\nrendering of unseen scenes, it heavily depends on precise camera poses for\naccurate geometry. In real-world scenarios, obtaining accurate poses is\nchallenging, leading to noisy pose estimates and geometric misalignments. To\naddress this, we introduce SHARE, a pose-free, feed-forward Gaussian splatting\nframework that overcomes these ambiguities by joint shape and camera rays\nestimation. Instead of relying on explicit 3D transformations, SHARE builds a\npose-aware canonical volume representation that seamlessly integrates\nmulti-view information, reducing misalignment caused by inaccurate pose\nestimates. Additionally, anchor-aligned Gaussian prediction enhances scene\nreconstruction by refining local geometry around coarse anchors, allowing for\nmore precise Gaussian placement. Extensive experiments on diverse real-world\ndatasets show that our method achieves robust performance in pose-free\ngeneralizable Gaussian splatting.", "AI": {"tldr": "SHARE is a pose-free Gaussian splatting framework that jointly estimates shape and camera rays, reducing reliance on precise camera poses for accurate geometry.", "motivation": "Accurate camera poses are hard to obtain in real-world scenarios, leading to noisy estimates and geometric misalignments in 3D Gaussian splatting.", "method": "SHARE uses a pose-aware canonical volume representation and anchor-aligned Gaussian prediction to integrate multi-view information and refine local geometry.", "result": "The method achieves robust performance in pose-free generalizable Gaussian splatting on diverse real-world datasets.", "conclusion": "SHARE effectively addresses pose ambiguities and improves scene reconstruction without relying on precise camera poses."}}
{"id": "2505.23518", "pdf": "https://arxiv.org/pdf/2505.23518", "abs": "https://arxiv.org/abs/2505.23518", "authors": ["Hangoo Kang", "Jehyeok Yeon", "Gagandeep Singh"], "title": "TRAP: Targeted Redirecting of Agentic Preferences", "categories": ["cs.AI"], "comment": null, "summary": "Autonomous agentic AI systems powered by vision-language models (VLMs) are\nrapidly advancing toward real-world deployment, yet their cross-modal reasoning\ncapabilities introduce new attack surfaces for adversarial manipulation that\nexploit semantic reasoning across modalities. Existing adversarial attacks\ntypically rely on visible pixel perturbations or require privileged model or\nenvironment access, making them impractical for stealthy, real-world\nexploitation. We introduce TRAP, a generative adversarial framework that\nmanipulates the agent's decision-making using diffusion-based semantic\ninjections. Our method combines negative prompt-based degradation with positive\nsemantic optimization, guided by a Siamese semantic network and layout-aware\nspatial masking. Without requiring access to model internals, TRAP produces\nvisually natural images yet induces consistent selection biases in agentic AI\nsystems. We evaluate TRAP on the Microsoft Common Objects in Context (COCO)\ndataset, building multi-candidate decision scenarios. Across these scenarios,\nTRAP achieves a 100% attack success rate on leading models, including\nLLaVA-34B, Gemma3, and Mistral-3.1, significantly outperforming baselines such\nas SPSA, Bandit, and standard diffusion approaches. These results expose a\ncritical vulnerability: Autonomous agents can be consistently misled through\nhuman-imperceptible cross-modal manipulations. These findings highlight the\nneed for defense strategies beyond pixel-level robustness to address semantic\nvulnerabilities in cross-modal decision-making.", "AI": {"tldr": "TRAP is a generative adversarial framework that manipulates AI decision-making using semantic injections, achieving 100% attack success on leading models without visible perturbations.", "motivation": "To address the vulnerability of autonomous AI systems to stealthy, cross-modal adversarial attacks that exploit semantic reasoning.", "method": "TRAP combines negative prompt-based degradation and positive semantic optimization, guided by a Siamese semantic network and layout-aware spatial masking.", "result": "TRAP achieves a 100% attack success rate on models like LLaVA-34B, Gemma3, and Mistral-3.1, outperforming baselines.", "conclusion": "The findings reveal a critical vulnerability in AI systems, emphasizing the need for defenses against semantic-level attacks."}}
{"id": "2505.22881", "pdf": "https://arxiv.org/pdf/2505.22881", "abs": "https://arxiv.org/abs/2505.22881", "authors": ["Hyungki Im", "Wyame Benslimane", "Paul Grigas"], "title": "Smart Surrogate Losses for Contextual Stochastic Linear Optimization with Robust Constraints", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "We study an extension of contextual stochastic linear optimization (CSLO)\nthat, in contrast to most of the existing literature, involves inequality\nconstraints that depend on uncertain parameters predicted by a machine learning\nmodel. To handle the constraint uncertainty, we use contextual uncertainty sets\nconstructed via methods like conformal prediction. Given a contextual\nuncertainty set method, we introduce the \"Smart Predict-then-Optimize with\nRobust Constraints\" (SPO-RC) loss, a feasibility-sensitive adaptation of the\nSPO loss that measures decision error of predicted objective parameters. We\nalso introduce a convex surrogate, SPO-RC+, and prove Fisher consistency with\nSPO-RC. To enhance performance, we train on truncated datasets where true\nconstraint parameters lie within the uncertainty sets, and we correct the\ninduced sample selection bias using importance reweighting techniques. Through\nexperiments on fractional knapsack and alloy production problem instances, we\ndemonstrate that SPO-RC+ effectively handles uncertainty in constraints and\nthat combining truncation with importance reweighting can further improve\nperformance.", "AI": {"tldr": "The paper introduces SPO-RC and SPO-RC+ to handle uncertain constraints in CSLO, using conformal prediction and importance reweighting for improved performance.", "motivation": "Address uncertainty in constraints for CSLO, which is underexplored in literature.", "method": "Use contextual uncertainty sets, SPO-RC loss, and SPO-RC+ surrogate with truncation and importance reweighting.", "result": "SPO-RC+ effectively manages constraint uncertainty; truncation and reweighting boost performance.", "conclusion": "SPO-RC+ is a viable approach for CSLO with uncertain constraints, enhanced by truncation and reweighting."}}
{"id": "2505.22956", "pdf": "https://arxiv.org/pdf/2505.22956", "abs": "https://arxiv.org/abs/2505.22956", "authors": ["Matteo Guida", "Yulia Otmakhova", "Eduard Hovy", "Lea Frermann"], "title": "LLMs for Argument Mining: Detection, Extraction, and Relationship Classification of pre-defined Arguments in Online Comments", "categories": ["cs.CL"], "comment": null, "summary": "Automated large-scale analysis of public discussions around contested issues\nlike abortion requires detecting and understanding the use of arguments. While\nLarge Language Models (LLMs) have shown promise in language processing tasks,\ntheir performance in mining topic-specific, pre-defined arguments in online\ncomments remains underexplored. We evaluate four state-of-the-art LLMs on three\nargument mining tasks using datasets comprising over 2,000 opinion comments\nacross six polarizing topics. Quantitative evaluation suggests an overall\nstrong performance across the three tasks, especially for large and fine-tuned\nLLMs, albeit at a significant environmental cost. However, a detailed error\nanalysis revealed systematic shortcomings on long and nuanced comments and\nemotionally charged language, raising concerns for downstream applications like\ncontent moderation or opinion analysis. Our results highlight both the promise\nand current limitations of LLMs for automated argument analysis in online\ncomments.", "AI": {"tldr": "The paper evaluates four LLMs for argument mining in online comments on polarizing topics, showing strong performance but limitations in handling nuanced or emotional language.", "motivation": "To assess LLMs' effectiveness in detecting and understanding topic-specific arguments in public discussions, given their underexplored performance in this context.", "method": "Evaluation of four state-of-the-art LLMs on three argument mining tasks using datasets of over 2,000 opinion comments across six polarizing topics.", "result": "LLMs performed well, especially large and fine-tuned models, but struggled with long, nuanced, or emotionally charged comments.", "conclusion": "LLMs show promise for automated argument analysis but have limitations for nuanced or emotional content, impacting applications like content moderation."}}
{"id": "2505.22980", "pdf": "https://arxiv.org/pdf/2505.22980", "abs": "https://arxiv.org/abs/2505.22980", "authors": ["Aimon Rahman", "Jiang Liu", "Ze Wang", "Ximeng Sun", "Jialian Wu", "Xiaodong Yu", "Yusheng Su", "Vishal M. Patel", "Zicheng Liu", "Emad Barsoum"], "title": "MOVi: Training-free Text-conditioned Multi-Object Video Generation", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in diffusion-based text-to-video (T2V) models have\ndemonstrated remarkable progress, but these models still face challenges in\ngenerating videos with multiple objects. Most models struggle with accurately\ncapturing complex object interactions, often treating some objects as static\nbackground elements and limiting their movement. In addition, they often fail\nto generate multiple distinct objects as specified in the prompt, resulting in\nincorrect generations or mixed features across objects. In this paper, we\npresent a novel training-free approach for multi-object video generation that\nleverages the open world knowledge of diffusion models and large language\nmodels (LLMs). We use an LLM as the ``director'' of object trajectories, and\napply the trajectories through noise re-initialization to achieve precise\ncontrol of realistic movements. We further refine the generation process by\nmanipulating the attention mechanism to better capture object-specific features\nand motion patterns, and prevent cross-object feature interference. Extensive\nexperiments validate the effectiveness of our training free approach in\nsignificantly enhancing the multi-object generation capabilities of existing\nvideo diffusion models, resulting in 42% absolute improvement in motion\ndynamics and object generation accuracy, while also maintaining high fidelity\nand motion smoothness.", "AI": {"tldr": "A training-free method improves multi-object video generation by leveraging LLMs for trajectory control and refining attention mechanisms, achieving 42% better accuracy and motion dynamics.", "motivation": "Existing diffusion-based T2V models struggle with multi-object generation, often failing to capture complex interactions or distinct object features.", "method": "Uses an LLM as a 'director' for object trajectories and noise re-initialization, while refining attention mechanisms to avoid cross-object interference.", "result": "42% absolute improvement in motion dynamics and object generation accuracy, with high fidelity and smoothness.", "conclusion": "The approach effectively enhances multi-object video generation without additional training, addressing key limitations of current models."}}
{"id": "2505.23519", "pdf": "https://arxiv.org/pdf/2505.23519", "abs": "https://arxiv.org/abs/2505.23519", "authors": ["Ruiqi He", "Falk Lieder"], "title": "Individual differences in the cognitive mechanisms of planning strategy discovery", "categories": ["cs.AI"], "comment": null, "summary": "People employ efficient planning strategies. But how are these strategies\nacquired? Previous research suggests that people can discover new planning\nstrategies through learning from reinforcements, a process known as\nmetacognitive reinforcement learning (MCRL). While prior work has shown that\nMCRL models can learn new planning strategies and explain more participants'\nexperience-driven discovery better than alternative mechanisms, it also\nrevealed significant individual differences in metacognitive learning.\nFurthermore, when fitted to human data, these models exhibit a slower rate of\nstrategy discovery than humans. In this study, we investigate whether\nincorporating cognitive mechanisms that might facilitate human strategy\ndiscovery can bring models of MCRL closer to human performance. Specifically,\nwe consider intrinsically generated metacognitive pseudo-rewards, subjective\neffort valuation, and termination deliberation. Analysis of planning task data\nshows that a larger proportion of participants used at least one of these\nmechanisms, with significant individual differences in their usage and varying\nimpacts on strategy discovery. Metacognitive pseudo-rewards, subjective effort\nvaluation, and learning the value of acting without further planning were found\nto facilitate strategy discovery. While these enhancements provided valuable\ninsights into individual differences and the effect of these mechanisms on\nstrategy discovery, they did not fully close the gap between model and human\nperformance, prompting further exploration of additional factors that people\nmight use to discover new planning strategies.", "AI": {"tldr": "The study explores cognitive mechanisms like metacognitive pseudo-rewards, subjective effort valuation, and termination deliberation to improve metacognitive reinforcement learning (MCRL) models, aiming to match human strategy discovery rates. While these mechanisms help, they don't fully bridge the gap.", "motivation": "To understand why MCRL models learn planning strategies slower than humans and identify cognitive mechanisms that could narrow this gap.", "method": "Incorporated intrinsic metacognitive pseudo-rewards, subjective effort valuation, and termination deliberation into MCRL models, analyzing their impact on strategy discovery in planning tasks.", "result": "The mechanisms facilitated strategy discovery but didn't fully match human performance, revealing individual differences in their usage and effectiveness.", "conclusion": "Further exploration of additional cognitive factors is needed to fully explain human strategy discovery rates."}}
{"id": "2505.22899", "pdf": "https://arxiv.org/pdf/2505.22899", "abs": "https://arxiv.org/abs/2505.22899", "authors": ["Naram Mhaisen", "George Iosifidis"], "title": "On the Dynamic Regret of Following the Regularized Leader: Optimism with History Pruning", "categories": ["cs.LG"], "comment": null, "summary": "We revisit the Follow the Regularized Leader (FTRL) framework for Online\nConvex Optimization (OCO) over compact sets, focusing on achieving dynamic\nregret guarantees. Prior work has highlighted the framework's limitations in\ndynamic environments due to its tendency to produce \"lazy\" iterates. However,\nbuilding on insights showing FTRL's ability to produce \"agile\" iterates, we\nshow that it can indeed recover known dynamic regret bounds through optimistic\ncomposition of future costs and careful linearization of past costs, which can\nlead to pruning some of them. This new analysis of FTRL against dynamic\ncomparators yields a principled way to interpolate between greedy and agile\nupdates and offers several benefits, including refined control over regret\nterms, optimism without cyclic dependence, and the application of minimal\nrecursive regularization akin to AdaFTRL. More broadly, we show that it is not\nthe lazy projection style of FTRL that hinders (optimistic) dynamic regret, but\nthe decoupling of the algorithm's state (linearized history) from its iterates,\nallowing the state to grow arbitrarily. Instead, pruning synchronizes these two\nwhen necessary.", "AI": {"tldr": "The paper revisits FTRL for OCO, showing it can achieve dynamic regret bounds by optimizing future costs and pruning past costs, overcoming prior limitations.", "motivation": "Addressing FTRL's limitations in dynamic environments by leveraging its ability to produce agile iterates and improving dynamic regret guarantees.", "method": "Optimistic composition of future costs and careful linearization/pruning of past costs to synchronize algorithm state and iterates.", "result": "FTRL recovers known dynamic regret bounds, offers refined control, and avoids cyclic dependence, with minimal recursive regularization.", "conclusion": "FTRL's dynamic regret issues stem from state-iterate decoupling, not lazy projection; pruning synchronizes them, enabling better performance."}}
{"id": "2505.22959", "pdf": "https://arxiv.org/pdf/2505.22959", "abs": "https://arxiv.org/abs/2505.22959", "authors": ["Jianwei Wang", "Mengqi Wang", "Yinsi Zhou", "Zhenchang Xing", "Qing Liu", "Xiwei Xu", "Wenjie Zhang", "Liming Zhu"], "title": "LLM-based HSE Compliance Assessment: Benchmark, Performance, and Advancements", "categories": ["cs.CL"], "comment": null, "summary": "Health, Safety, and Environment (HSE) compliance assessment demands dynamic\nreal-time decision-making under complicated regulations and complex\nhuman-machine-environment interactions. While large language models (LLMs) hold\nsignificant potential for decision intelligence and contextual dialogue, their\ncapacity for domain-specific knowledge in HSE and structured legal reasoning\nremains underexplored. We introduce HSE-Bench, the first benchmark dataset\ndesigned to evaluate the HSE compliance assessment capabilities of LLM.\nHSE-Bench comprises over 1,000 manually curated questions drawn from\nregulations, court cases, safety exams, and fieldwork videos, and integrates a\nreasoning flow based on Issue spotting, rule Recall, rule Application, and rule\nConclusion (IRAC) to assess the holistic reasoning pipeline. We conduct\nextensive evaluations on different prompting strategies and more than 10 LLMs,\nincluding foundation models, reasoning models and multimodal vision models. The\nresults show that, although current LLMs achieve good performance, their\ncapabilities largely rely on semantic matching rather than principled reasoning\ngrounded in the underlying HSE compliance context. Moreover, their native\nreasoning trace lacks the systematic legal reasoning required for rigorous HSE\ncompliance assessment. To alleviate these, we propose a new prompting\ntechnique, Reasoning of Expert (RoE), which guides LLMs to simulate the\nreasoning process of different experts for compliance assessment and reach a\nmore accurate unified decision. We hope our study highlights reasoning gaps in\nLLMs for HSE compliance and inspires further research on related tasks.", "AI": {"tldr": "HSE-Bench is introduced as the first benchmark to evaluate LLMs' HSE compliance assessment, revealing reliance on semantic matching over principled reasoning. A new prompting technique, RoE, is proposed to improve accuracy.", "motivation": "To address the underexplored capacity of LLMs in domain-specific HSE knowledge and structured legal reasoning for compliance assessment.", "method": "HSE-Bench, a dataset of 1,000+ curated questions, evaluates LLMs using IRAC reasoning flow. RoE prompting is introduced to simulate expert reasoning.", "result": "LLMs perform well but rely on semantic matching, lacking systematic legal reasoning. RoE improves decision accuracy.", "conclusion": "The study highlights reasoning gaps in LLMs for HSE compliance and encourages further research."}}
{"id": "2505.23008", "pdf": "https://arxiv.org/pdf/2505.23008", "abs": "https://arxiv.org/abs/2505.23008", "authors": ["Jonathan Li", "Zoltan Csaki", "Nidhi Hiremath", "Etash Guha", "Fenglu Hong", "Edward Ma", "Urmish Thakker"], "title": "Synthetic Document Question Answering in Hungarian", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Modern VLMs have achieved near-saturation accuracy in English document visual\nquestion-answering (VQA). However, this task remains challenging in lower\nresource languages due to a dearth of suitable training and evaluation data. In\nthis paper we present scalable methods for curating such datasets by focusing\non Hungarian, approximately the 17th highest resource language on the internet.\nSpecifically, we present HuDocVQA and HuDocVQA-manual, document VQA datasets\nthat modern VLMs significantly underperform on compared to English DocVQA.\nHuDocVQA-manual is a small manually curated dataset based on Hungarian\ndocuments from Common Crawl, while HuDocVQA is a larger synthetically generated\nVQA data set from the same source. We apply multiple rounds of quality\nfiltering and deduplication to HuDocVQA in order to match human-level quality\nin this dataset. We also present HuCCPDF, a dataset of 117k pages from\nHungarian Common Crawl PDFs along with their transcriptions, which can be used\nfor training a model for Hungarian OCR. To validate the quality of our\ndatasets, we show how finetuning on a mixture of these datasets can improve\naccuracy on HuDocVQA for Llama 3.2 11B Instruct by +7.2%. Our datasets and code\nwill be released to the public to foster further research in multilingual\nDocVQA.", "AI": {"tldr": "The paper introduces HuDocVQA and HuDocVQA-manual, datasets for Hungarian document VQA, addressing the lack of resources in lower-resource languages. It also presents HuCCPDF for OCR training and shows finetuning improves accuracy.", "motivation": "The challenge of document VQA in lower-resource languages like Hungarian due to limited training and evaluation data.", "method": "Creation of HuDocVQA (synthetic) and HuDocVQA-manual (manual) datasets, along with HuCCPDF for OCR. Quality filtering and deduplication are applied.", "result": "Finetuning on these datasets improves Llama 3.2 11B Instruct's accuracy on HuDocVQA by +7.2%.", "conclusion": "The datasets and code will be released to support multilingual DocVQA research."}}
{"id": "2505.23536", "pdf": "https://arxiv.org/pdf/2505.23536", "abs": "https://arxiv.org/abs/2505.23536", "authors": ["Janik-Vasily Benzin", "Gyunam Park", "Stefanie Rinderle-Ma"], "title": "Synchronizing Process Model and Event Abstraction for Grounded Process Intelligence (Extended Version)", "categories": ["cs.AI"], "comment": null, "summary": "Model abstraction (MA) and event abstraction (EA) are means to reduce\ncomplexity of (discovered) models and event data. Imagine a process\nintelligence project that aims to analyze a model discovered from event data\nwhich is further abstracted, possibly multiple times, to reach optimality\ngoals, e.g., reducing model size. So far, after discovering the model, there is\nno technique that enables the synchronized abstraction of the underlying event\nlog. This results in loosing the grounding in the real-world behavior contained\nin the log and, in turn, restricts analysis insights. Hence, in this work, we\nprovide the formal basis for synchronized model and event abstraction, i.e., we\nprove that abstracting a process model by MA and discovering a process model\nfrom an abstracted event log yields an equivalent process model. We prove the\nfeasibility of our approach based on behavioral profile abstraction as\nnon-order preserving MA technique, resulting in a novel EA technique.", "AI": {"tldr": "The paper introduces a formal basis for synchronized model and event abstraction to maintain grounding in real-world behavior during process intelligence projects.", "motivation": "Current techniques lack synchronization between model and event abstraction, leading to loss of real-world behavior insights.", "method": "The approach proves equivalence between abstracting a process model and discovering a model from an abstracted event log, using behavioral profile abstraction.", "result": "The paper demonstrates feasibility with a novel event abstraction technique.", "conclusion": "Synchronized abstraction enhances analysis insights by preserving real-world behavior."}}
{"id": "2505.22904", "pdf": "https://arxiv.org/pdf/2505.22904", "abs": "https://arxiv.org/abs/2505.22904", "authors": ["Youngsoo Choi", "Siu Wun Cheung", "Youngkyu Kim", "Ping-Hsuan Tsai", "Alejandro N. Diaz", "Ivan Zanardi", "Seung Whan Chung", "Dylan Matthew Copeland", "Coleman Kendrick", "William Anderson", "Traian Iliescu", "Matthias Heinkenschloss"], "title": "Defining Foundation Models for Computational Science: A Call for Clarity and Rigor", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "comment": "26 pages, 2 tables, 7 figures", "summary": "The widespread success of foundation models in natural language processing\nand computer vision has inspired researchers to extend the concept to\nscientific machine learning and computational science. However, this position\npaper argues that as the term \"foundation model\" is an evolving concept, its\napplication in computational science is increasingly used without a universally\naccepted definition, potentially creating confusion and diluting its precise\nscientific meaning. In this paper, we address this gap by proposing a formal\ndefinition of foundation models in computational science, grounded in the core\nvalues of generality, reusability, and scalability. We articulate a set of\nessential and desirable characteristics that such models must exhibit, drawing\nparallels with traditional foundational methods, like the finite element and\nfinite volume methods. Furthermore, we introduce the Data-Driven Finite Element\nMethod (DD-FEM), a framework that fuses the modular structure of classical FEM\nwith the representational power of data-driven learning. We demonstrate how\nDD-FEM addresses many of the key challenges in realizing foundation models for\ncomputational science, including scalability, adaptability, and physics\nconsistency. By bridging traditional numerical methods with modern AI\nparadigms, this work provides a rigorous foundation for evaluating and\ndeveloping novel approaches toward future foundation models in computational\nscience.", "AI": {"tldr": "The paper proposes a formal definition of foundation models in computational science, emphasizing generality, reusability, and scalability, and introduces the Data-Driven Finite Element Method (DD-FEM) as a framework to address key challenges.", "motivation": "The term \"foundation model\" lacks a universally accepted definition in computational science, leading to confusion. This paper aims to clarify and formalize the concept.", "method": "The authors propose a formal definition and essential characteristics for foundation models in computational science. They introduce DD-FEM, combining classical FEM with data-driven learning.", "result": "DD-FEM demonstrates scalability, adaptability, and physics consistency, addressing challenges in realizing foundation models for computational science.", "conclusion": "The work bridges traditional numerical methods with AI, providing a rigorous foundation for future foundation models in computational science."}}
{"id": "2505.22961", "pdf": "https://arxiv.org/pdf/2505.22961", "abs": "https://arxiv.org/abs/2505.22961", "authors": ["Peixuan Han", "Zijia Liu", "Jiaxuan You"], "title": "ToMAP: Training Opponent-Aware LLM Persuaders with Theory of Mind", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) have shown promising potential in persuasion,\nbut existing works on training LLM persuaders are still preliminary. Notably,\nwhile humans are skilled in modeling their opponent's thoughts and opinions\nproactively and dynamically, current LLMs struggle with such Theory of Mind\n(ToM) reasoning, resulting in limited diversity and opponent awareness. To\naddress this limitation, we introduce Theory of Mind Augmented Persuader\n(ToMAP), a novel approach for building more flexible persuader agents by\nincorporating two theory of mind modules that enhance the persuader's awareness\nand analysis of the opponent's mental state. Specifically, we begin by\nprompting the persuader to consider possible objections to the target central\nclaim, and then use a text encoder paired with a trained MLP classifier to\npredict the opponent's current stance on these counterclaims. Our carefully\ndesigned reinforcement learning schema enables the persuader learns how to\nanalyze opponent-related information and utilize it to generate more effective\narguments. Experiments show that the ToMAP persuader, while containing only 3B\nparameters, outperforms much larger baselines, like GPT-4o, with a relative\ngain of 39.4% across multiple persuadee models and diverse corpora. Notably,\nToMAP exhibits complex reasoning chains and reduced repetition during training,\nwhich leads to more diverse and effective arguments. The opponent-aware feature\nof ToMAP also makes it suitable for long conversations and enables it to employ\nmore logical and opponent-aware strategies. These results underscore our\nmethod's effectiveness and highlight its potential for developing more\npersuasive language agents. Code is available at:\nhttps://github.com/ulab-uiuc/ToMAP.", "AI": {"tldr": "ToMAP enhances LLM persuaders by incorporating Theory of Mind modules, improving opponent awareness and argument diversity, outperforming larger models like GPT-4o.", "motivation": "Current LLMs lack dynamic Theory of Mind reasoning, limiting persuasion diversity and opponent awareness.", "method": "ToMAP uses two ToM modules: prompting for objections and predicting opponent stance via MLP. Reinforcement learning refines argument generation.", "result": "ToMAP (3B params) outperforms GPT-4o by 39.4%, showing diverse, logical arguments and reduced repetition.", "conclusion": "ToMAP's opponent-aware design improves persuasion effectiveness, suitable for long conversations and diverse strategies."}}
{"id": "2505.23010", "pdf": "https://arxiv.org/pdf/2505.23010", "abs": "https://arxiv.org/abs/2505.23010", "authors": ["Bowen Chen", "Keyan Chen", "Mohan Yang", "Zhengxia Zou", "Zhenwei Shi"], "title": "SeG-SR: Integrating Semantic Knowledge into Remote Sensing Image Super-Resolution via Vision-Language Model", "categories": ["cs.CV"], "comment": null, "summary": "High-resolution (HR) remote sensing imagery plays a vital role in a wide\nrange of applications, including urban planning and environmental monitoring.\nHowever, due to limitations in sensors and data transmission links, the images\nacquired in practice often suffer from resolution degradation. Remote Sensing\nImage Super-Resolution (RSISR) aims to reconstruct HR images from\nlow-resolution (LR) inputs, providing a cost-effective and efficient\nalternative to direct HR image acquisition. Existing RSISR methods primarily\nfocus on low-level characteristics in pixel space, while neglecting the\nhigh-level understanding of remote sensing scenes. This may lead to\nsemantically inconsistent artifacts in the reconstructed results. Motivated by\nthis observation, our work aims to explore the role of high-level semantic\nknowledge in improving RSISR performance. We propose a Semantic-Guided\nSuper-Resolution framework, SeG-SR, which leverages Vision-Language Models\n(VLMs) to extract semantic knowledge from input images and uses it to guide the\nsuper resolution (SR) process. Specifically, we first design a Semantic Feature\nExtraction Module (SFEM) that utilizes a pretrained VLM to extract semantic\nknowledge from remote sensing images. Next, we propose a Semantic Localization\nModule (SLM), which derives a series of semantic guidance from the extracted\nsemantic knowledge. Finally, we develop a Learnable Modulation Module (LMM)\nthat uses semantic guidance to modulate the features extracted by the SR\nnetwork, effectively incorporating high-level scene understanding into the SR\npipeline. We validate the effectiveness and generalizability of SeG-SR through\nextensive experiments: SeG-SR achieves state-of-the-art performance on two\ndatasets and consistently delivers performance improvements across various SR\narchitectures. Codes can be found at https://github.com/Mr-Bamboo/SeG-SR.", "AI": {"tldr": "The paper proposes SeG-SR, a semantic-guided super-resolution framework for remote sensing images, leveraging vision-language models to improve resolution by incorporating high-level semantic knowledge.", "motivation": "Existing RSISR methods focus on low-level pixel characteristics, neglecting high-level semantic understanding, leading to artifacts. This work explores semantic knowledge's role in enhancing RSISR.", "method": "SeG-SR uses a pretrained VLM for semantic feature extraction, a Semantic Localization Module for guidance, and a Learnable Modulation Module to integrate semantics into the SR process.", "result": "SeG-SR achieves state-of-the-art performance on two datasets and improves various SR architectures.", "conclusion": "Incorporating high-level semantic knowledge via SeG-SR significantly enhances remote sensing image super-resolution, offering a robust and generalizable solution."}}
{"id": "2505.23559", "pdf": "https://arxiv.org/pdf/2505.23559", "abs": "https://arxiv.org/abs/2505.23559", "authors": ["Kunlun Zhu", "Jiaxun Zhang", "Ziheng Qi", "Nuoxing Shang", "Zijia Liu", "Peixuan Han", "Yue Su", "Haofei Yu", "Jiaxuan You"], "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "categories": ["cs.AI"], "comment": null, "summary": "Recent advancements in large language model (LLM) agents have significantly\naccelerated scientific discovery automation, yet concurrently raised critical\nethical and safety concerns. To systematically address these challenges, we\nintroduce \\textbf{SafeScientist}, an innovative AI scientist framework\nexplicitly designed to enhance safety and ethical responsibility in AI-driven\nscientific exploration. SafeScientist proactively refuses ethically\ninappropriate or high-risk tasks and rigorously emphasizes safety throughout\nthe research process. To achieve comprehensive safety oversight, we integrate\nmultiple defensive mechanisms, including prompt monitoring, agent-collaboration\nmonitoring, tool-use monitoring, and an ethical reviewer component.\nComplementing SafeScientist, we propose \\textbf{SciSafetyBench}, a novel\nbenchmark specifically designed to evaluate AI safety in scientific contexts,\ncomprising 240 high-risk scientific tasks across 6 domains, alongside 30\nspecially designed scientific tools and 120 tool-related risk tasks. Extensive\nexperiments demonstrate that SafeScientist significantly improves safety\nperformance by 35\\% compared to traditional AI scientist frameworks, without\ncompromising scientific output quality. Additionally, we rigorously validate\nthe robustness of our safety pipeline against diverse adversarial attack\nmethods, further confirming the effectiveness of our integrated approach. The\ncode and data will be available at https://github.com/ulab-uiuc/SafeScientist.\n\\textcolor{red}{Warning: this paper contains example data that may be offensive\nor harmful.}", "AI": {"tldr": "SafeScientist is a framework enhancing safety and ethics in AI-driven science, outperforming traditional methods by 35% in safety while maintaining scientific quality.", "motivation": "Address ethical and safety concerns in AI-driven scientific discovery.", "method": "Integrates defensive mechanisms like prompt monitoring, ethical review, and introduces SciSafetyBench for evaluation.", "result": "35% safety improvement without compromising scientific output; robustness validated against adversarial attacks.", "conclusion": "SafeScientist effectively balances safety and scientific productivity, with tools and benchmarks for broader adoption."}}
{"id": "2505.22913", "pdf": "https://arxiv.org/pdf/2505.22913", "abs": "https://arxiv.org/abs/2505.22913", "authors": ["Donghyeon Joo", "Helya Hosseini", "Ramyad Hadidi", "Bahar Asgari"], "title": "Mustafar: Promoting Unstructured Sparsity for KV Cache Pruning in LLM Inference", "categories": ["cs.LG"], "comment": "19 pages, 9 figures", "summary": "We demonstrate that unstructured sparsity significantly improves KV cache\ncompression for LLMs, enabling sparsity levels up to 70% without compromising\naccuracy or requiring fine-tuning. We conduct a systematic exploration of\npruning strategies and find per-token magnitude-based pruning as highly\neffective for both Key and Value caches under unstructured sparsity, surpassing\nprior structured pruning schemes. The Key cache benefits from prominent outlier\nelements, while the Value cache surprisingly benefits from a simple\nmagnitude-based pruning despite its uniform distribution. KV cache size is the\nmajor bottleneck in decode performance due to high memory overhead for large\ncontext lengths. To address this, we use a bitmap-based sparse format and a\ncustom attention kernel capable of compressing and directly computing over\ncompressed caches pruned to arbitrary sparsity patterns, significantly\naccelerating memory-bound operations in decode computations and thereby\ncompensating for the overhead of runtime pruning and compression. Our custom\nattention kernel coupled with the bitmap-based format delivers substantial\ncompression of KV cache upto 45% of dense inference and thereby enables longer\ncontext length and increased tokens/sec throughput of upto 2.23x compared to\ndense inference. Our pruning mechanism and sparse attention kernel is available\nat https://github.com/dhjoo98/mustafar.", "AI": {"tldr": "Unstructured sparsity improves KV cache compression in LLMs, achieving up to 70% sparsity without accuracy loss or fine-tuning. A custom attention kernel and bitmap-based format enable 45% compression and 2.23x throughput boost.", "motivation": "KV cache size limits decode performance due to memory overhead. Addressing this bottleneck improves efficiency for large context lengths.", "method": "Per-token magnitude-based pruning for Key and Value caches, combined with a bitmap-based sparse format and custom attention kernel.", "result": "Achieves 70% sparsity without accuracy loss, 45% compression of KV cache, and 2.23x throughput increase.", "conclusion": "Unstructured sparsity and custom kernels effectively compress KV caches, enhancing performance and enabling longer contexts."}}
{"id": "2505.22964", "pdf": "https://arxiv.org/pdf/2505.22964", "abs": "https://arxiv.org/abs/2505.22964", "authors": ["Sheng Zhang", "Qin Liu", "Naoto Usuyama", "Cliff Wong", "Tristan Naumann", "Hoifung Poon"], "title": "Exploring Scaling Laws for EHR Foundation Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The emergence of scaling laws has profoundly shaped the development of large\nlanguage models (LLMs), enabling predictable performance gains through\nsystematic increases in model size, dataset volume, and compute. Yet, these\nprinciples remain largely unexplored in the context of electronic health\nrecords (EHRs) -- a rich, sequential, and globally abundant data source that\ndiffers structurally from natural language. In this work, we present the first\nempirical investigation of scaling laws for EHR foundation models. By training\ntransformer architectures on patient timeline data from the MIMIC-IV database\nacross varying model sizes and compute budgets, we identify consistent scaling\npatterns, including parabolic IsoFLOPs curves and power-law relationships\nbetween compute, model parameters, data size, and clinical utility. These\nfindings demonstrate that EHR models exhibit scaling behavior analogous to\nLLMs, offering predictive insights into resource-efficient training strategies.\nOur results lay the groundwork for developing powerful EHR foundation models\ncapable of transforming clinical prediction tasks and advancing personalized\nhealthcare.", "AI": {"tldr": "The paper explores scaling laws in EHR foundation models, showing they behave similarly to LLMs, with predictable performance gains from scaling model size, data, and compute.", "motivation": "Scaling laws are well-studied in LLMs but unexplored in EHRs, despite their rich, sequential data. This work aims to bridge that gap.", "method": "Transformer models were trained on MIMIC-IV patient timeline data, varying model sizes and compute budgets to analyze scaling patterns.", "result": "Consistent scaling patterns emerged, including parabolic IsoFLOPs curves and power-law relationships, similar to LLMs.", "conclusion": "The findings support resource-efficient training of EHR models, enabling advancements in clinical prediction and personalized healthcare."}}
{"id": "2505.23012", "pdf": "https://arxiv.org/pdf/2505.23012", "abs": "https://arxiv.org/abs/2505.23012", "authors": ["Shanaka Ramesh Gunasekara", "Wanqing Li", "Philip Ogunbona", "Jack Yang"], "title": "Spatio-Temporal Joint Density Driven Learning for Skeleton-Based Action Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Traditional approaches in unsupervised or self supervised learning for\nskeleton-based action classification have concentrated predominantly on the\ndynamic aspects of skeletal sequences. Yet, the intricate interaction between\nthe moving and static elements of the skeleton presents a rarely tapped\ndiscriminative potential for action classification. This paper introduces a\nnovel measurement, referred to as spatial-temporal joint density (STJD), to\nquantify such interaction. Tracking the evolution of this density throughout an\naction can effectively identify a subset of discriminative moving and/or static\njoints termed \"prime joints\" to steer self-supervised learning. A new\ncontrastive learning strategy named STJD-CL is proposed to align the\nrepresentation of a skeleton sequence with that of its prime joints while\nsimultaneously contrasting the representations of prime and nonprime joints. In\naddition, a method called STJD-MP is developed by integrating it with a\nreconstruction-based framework for more effective learning. Experimental\nevaluations on the NTU RGB+D 60, NTU RGB+D 120, and PKUMMD datasets in various\ndownstream tasks demonstrate that the proposed STJD-CL and STJD-MP improved\nperformance, particularly by 3.5 and 3.6 percentage points over the\nstate-of-the-art contrastive methods on the NTU RGB+D 120 dataset using X-sub\nand X-set evaluations, respectively.", "AI": {"tldr": "The paper introduces a novel measurement, STJD, to quantify the interaction between moving and static skeletal joints for action classification. It proposes STJD-CL and STJD-MP methods, improving performance over state-of-the-art methods.", "motivation": "To leverage the discriminative potential of interactions between moving and static skeletal joints, which is often overlooked in traditional approaches.", "method": "Introduces STJD to quantify joint interactions, identifies 'prime joints,' and proposes STJD-CL (contrastive learning) and STJD-MP (reconstruction-based framework).", "result": "Improved performance by 3.5 and 3.6 percentage points on NTU RGB+D 120 dataset over state-of-the-art methods.", "conclusion": "The proposed methods effectively harness the interaction between moving and static joints, enhancing action classification performance."}}
{"id": "2505.23575", "pdf": "https://arxiv.org/pdf/2505.23575", "abs": "https://arxiv.org/abs/2505.23575", "authors": ["Benjamin Arnav", "Pablo Bernabeu-P\u00e9rez", "Nathan Helm-Burger", "Tim Kostolansky", "Hannes Whittingham", "Mary Phuong"], "title": "CoT Red-Handed: Stress Testing Chain-of-Thought Monitoring", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "As AI models are deployed with increasing autonomy, it is important to ensure\nthey do not take harmful actions unnoticed. As a potential mitigation, we\ninvestigate Chain-of-Thought (CoT) monitoring, wherein a weaker trusted monitor\nmodel continuously oversees the intermediate reasoning steps of a more powerful\nbut untrusted model. We compare CoT monitoring to action-only monitoring, where\nonly final outputs are reviewed, in a red-teaming setup where the untrusted\nmodel is instructed to pursue harmful side tasks while completing a coding\nproblem. We find that CoT monitoring improves detection by up to 27 percentage\npoints in scenarios where action-only monitoring fails to reliably identify\nsabotage. However, CoT traces can also contain misleading rationalizations that\ndeceive the monitor, reducing performance in more obvious sabotage cases. To\naddress this, we introduce a hybrid protocol that independently scores both\nreasoning and final outputs and combines them using a weighted average. This\nhybrid monitor consistently outperforms both CoT and action-only monitors\nacross all tested models and tasks, with detection rates over four times higher\nthan action-only monitoring for subtle deception scenarios.", "AI": {"tldr": "CoT monitoring improves detection of harmful AI actions but can be misled by deceptive reasoning. A hybrid protocol combining reasoning and output scoring outperforms both CoT and action-only monitoring.", "motivation": "To ensure AI models do not take harmful actions unnoticed by improving monitoring methods.", "method": "Compare Chain-of-Thought (CoT) monitoring to action-only monitoring in a red-teaming setup. Introduce a hybrid protocol scoring both reasoning and outputs.", "result": "CoT monitoring improves detection by up to 27 percentage points but can be deceived. The hybrid protocol consistently outperforms both methods, with detection rates over four times higher for subtle deception.", "conclusion": "Hybrid monitoring, combining reasoning and output scoring, is more effective for detecting harmful AI actions."}}
{"id": "2505.22922", "pdf": "https://arxiv.org/pdf/2505.22922", "abs": "https://arxiv.org/abs/2505.22922", "authors": ["Athanasios Glentis", "Jiaxiang Li", "Qiulin Shang", "Andi Han", "Ioannis Tsaknakis", "Quan Wei", "Mingyi Hong"], "title": "Scalable Parameter and Memory Efficient Pretraining for LLM: Recent Algorithmic Advances and Benchmarking", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fueled by their remarkable ability to tackle diverse tasks across multiple\ndomains, large language models (LLMs) have grown at an unprecedented rate, with\nsome recent models containing trillions of parameters. This growth is\naccompanied by substantial computational challenges, particularly regarding the\nmemory and compute resources required for training and fine-tuning. Numerous\napproaches have been explored to address these issues, such as LoRA. While\nthese methods are effective for fine-tuning, their application to pre-training\nis significantly more challenging due to the need to learn vast datasets.\nMotivated by this issue, we aim to address the following questions: Can\nparameter- or memory-efficient methods enhance pre-training efficiency while\nachieving performance comparable to full-model training? How can the\nperformance gap be narrowed? To this end, the contributions of this work are\nthe following. (1) We begin by conducting a comprehensive survey that\nsummarizes state-of-the-art methods for efficient pre-training. (2) We perform\na benchmark evaluation of several representative memory efficient pre-training\napproaches to comprehensively evaluate their performance across model sizes. We\nobserve that with a proper choice of optimizer and hyperparameters, full-rank\ntraining delivers the best performance, as expected. We also notice that\nincorporating high-rank updates in low-rank approaches is the key to improving\ntheir performance. (3) Finally, we propose two practical techniques, namely\nweight refactorization and momentum reset, to enhance the performance of\nefficient pre-training methods. We observe that applying these techniques to\nthe low-rank method (on a 1B model) can achieve a lower perplexity than popular\nmemory efficient algorithms such as GaLore and Fira, while simultaneously using\nabout 25% less memory.", "AI": {"tldr": "The paper explores efficient pre-training methods for large language models (LLMs), comparing techniques like LoRA, proposing new methods (weight refactorization and momentum reset), and demonstrating improved performance and memory efficiency.", "motivation": "Addressing the computational challenges of pre-training LLMs, the study aims to enhance efficiency without compromising performance, focusing on parameter- and memory-efficient methods.", "method": "The study includes a survey of efficient pre-training methods, benchmarks of memory-efficient approaches, and introduces two techniques (weight refactorization and momentum reset) to improve low-rank methods.", "result": "Full-rank training performs best with proper optimization, while low-rank methods improve with high-rank updates. The proposed techniques achieve better perplexity and 25% memory savings compared to GaLore and Fira.", "conclusion": "Efficient pre-training is achievable with the right methods, and the proposed techniques enhance performance and memory usage, narrowing the gap with full-model training."}}
{"id": "2505.22993", "pdf": "https://arxiv.org/pdf/2505.22993", "abs": "https://arxiv.org/abs/2505.22993", "authors": ["Hoang Pham", "Thanh-Do Nguyen", "Khac-Hoai Nam Bui"], "title": "Verify-in-the-Graph: Entity Disambiguation Enhancement for Complex Claim Verification with Interactive Graph Representation", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR"], "comment": "Published at NAACL 2025 Main Conference", "summary": "Claim verification is a long-standing and challenging task that demands not\nonly high accuracy but also explainability of the verification process. This\ntask becomes an emerging research issue in the era of large language models\n(LLMs) since real-world claims are often complex, featuring intricate semantic\nstructures or obfuscated entities. Traditional approaches typically address\nthis by decomposing claims into sub-claims and querying a knowledge base to\nresolve hidden or ambiguous entities. However, the absence of effective\ndisambiguation strategies for these entities can compromise the entire\nverification process. To address these challenges, we propose\nVerify-in-the-Graph (VeGraph), a novel framework leveraging the reasoning and\ncomprehension abilities of LLM agents. VeGraph operates in three phases: (1)\nGraph Representation - an input claim is decomposed into structured triplets,\nforming a graph-based representation that integrates both structured and\nunstructured information; (2) Entity Disambiguation -VeGraph iteratively\ninteracts with the knowledge base to resolve ambiguous entities within the\ngraph for deeper sub-claim verification; and (3) Verification - remaining\ntriplets are verified to complete the fact-checking process. Experiments using\nMeta-Llama-3-70B (instruct version) show that VeGraph achieves competitive\nperformance compared to baselines on two benchmarks HoVer and FEVEROUS,\neffectively addressing claim verification challenges. Our source code and data\nare available for further exploitation.", "AI": {"tldr": "VeGraph is a novel framework using LLMs for claim verification, addressing entity disambiguation and structured representation to improve accuracy and explainability.", "motivation": "Traditional claim verification struggles with complex claims and ambiguous entities, lacking effective disambiguation strategies.", "method": "VeGraph decomposes claims into graph-based triplets, resolves ambiguous entities iteratively, and verifies remaining triplets.", "result": "VeGraph outperforms baselines on HoVer and FEVEROUS benchmarks using Meta-Llama-3-70B.", "conclusion": "VeGraph effectively tackles claim verification challenges, offering a robust and explainable solution."}}
{"id": "2505.23031", "pdf": "https://arxiv.org/pdf/2505.23031", "abs": "https://arxiv.org/abs/2505.23031", "authors": ["Jinyi Chang", "Dongliang Chang", "Lei Chen", "Bingyao Yu", "Zhanyu Ma"], "title": "Towards Privacy-Preserving Fine-Grained Visual Classification via Hierarchical Learning from Label Proportions", "categories": ["cs.CV"], "comment": "10 pages, 5 figures, 5 tables", "summary": "In recent years, Fine-Grained Visual Classification (FGVC) has achieved\nimpressive recognition accuracy, despite minimal inter-class variations.\nHowever, existing methods heavily rely on instance-level labels, making them\nimpractical in privacy-sensitive scenarios such as medical image analysis. This\npaper aims to enable accurate fine-grained recognition without direct access to\ninstance labels. To achieve this, we leverage the Learning from Label\nProportions (LLP) paradigm, which requires only bag-level labels for efficient\ntraining. Unlike existing LLP-based methods, our framework explicitly exploits\nthe hierarchical nature of fine-grained datasets, enabling progressive feature\ngranularity refinement and improving classification accuracy. We propose\nLearning from Hierarchical Fine-Grained Label Proportions (LHFGLP), a framework\nthat incorporates Unrolled Hierarchical Fine-Grained Sparse Dictionary\nLearning, transforming handcrafted iterative approximation into learnable\nnetwork optimization. Additionally, our proposed Hierarchical Proportion Loss\nprovides hierarchical supervision, further enhancing classification\nperformance. Experiments on three widely-used fine-grained datasets, structured\nin a bag-based manner, demonstrate that our framework consistently outperforms\nexisting LLP-based methods. We will release our code and datasets to foster\nfurther research in privacy-preserving fine-grained classification.", "AI": {"tldr": "The paper introduces LHFGLP, a framework for fine-grained visual classification without instance-level labels, using hierarchical label proportions to improve accuracy.", "motivation": "Existing FGVC methods rely on instance-level labels, which are impractical in privacy-sensitive scenarios like medical imaging. The paper aims to enable accurate classification without direct access to such labels.", "method": "The proposed LHFGLP framework leverages hierarchical label proportions, using Unrolled Hierarchical Fine-Grained Sparse Dictionary Learning and Hierarchical Proportion Loss for progressive feature refinement.", "result": "Experiments on three fine-grained datasets show LHFGLP outperforms existing LLP-based methods.", "conclusion": "The framework advances privacy-preserving FGVC and will release code and datasets for further research."}}
{"id": "2505.23596", "pdf": "https://arxiv.org/pdf/2505.23596", "abs": "https://arxiv.org/abs/2505.23596", "authors": ["Linqiang Guo", "Wei Liu", "Yi Wen Heng", "Tse-Hsun", "Chen", "Yang Wang"], "title": "MAPLE: A Mobile Assistant with Persistent Finite State Machines for Recovery Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Mobile GUI agents aim to autonomously complete user-instructed tasks across\nmobile apps. Recent advances in Multimodal Large Language Models (MLLMs) enable\nthese agents to interpret UI screens, identify actionable elements, and perform\ninteractions such as tapping or typing. However, existing agents remain\nreactive: they reason only over the current screen and lack a structured model\nof app navigation flow, limiting their ability to understand context, detect\nunexpected outcomes, and recover from errors. We present MAPLE, a state-aware\nmulti-agent framework that abstracts app interactions as a Finite State Machine\n(FSM). We computationally model each UI screen as a discrete state and user\nactions as transitions, allowing the FSM to provide a structured representation\nof the app execution. MAPLE consists of specialized agents responsible for four\nphases of task execution: planning, execution, verification, error recovery,\nand knowledge retention. These agents collaborate to dynamically construct FSMs\nin real time based on perception data extracted from the UI screen, allowing\nthe GUI agents to track navigation progress and flow, validate action outcomes\nthrough pre- and post-conditions of the states, and recover from errors by\nrolling back to previously stable states. Our evaluation results on two\nchallenging cross-app benchmarks, Mobile-Eval-E and SPA-Bench, show that MAPLE\noutperforms the state-of-the-art baseline, improving task success rate by up to\n12%, recovery success by 13.8%, and action accuracy by 6.5%. Our results\nhighlight the importance of structured state modeling in guiding mobile GUI\nagents during task execution. Moreover, our FSM representation can be\nintegrated into future GUI agent architectures as a lightweight, model-agnostic\nmemory layer to support structured planning, execution verification, and error\nrecovery.", "AI": {"tldr": "MAPLE is a state-aware multi-agent framework for mobile GUI agents, using Finite State Machines (FSMs) to model app interactions, improving task success, recovery, and accuracy.", "motivation": "Existing mobile GUI agents lack structured navigation flow and error recovery, limiting their context understanding and robustness.", "method": "MAPLE abstracts app interactions as FSMs, with specialized agents for planning, execution, verification, error recovery, and knowledge retention.", "result": "MAPLE outperforms baselines, improving task success by 12%, recovery by 13.8%, and action accuracy by 6.5%.", "conclusion": "Structured state modeling via FSMs enhances GUI agent performance and can be integrated as a lightweight memory layer for future architectures."}}
{"id": "2505.22935", "pdf": "https://arxiv.org/pdf/2505.22935", "abs": "https://arxiv.org/abs/2505.22935", "authors": ["Jipeng Li", "Yanning Shen"], "title": "Is Noise Conditioning Necessary? A Unified Theory of Unconditional Graph Diffusion Models", "categories": ["cs.LG"], "comment": null, "summary": "Explicit noise-level conditioning is widely regarded as essential for the\neffective operation of Graph Diffusion Models (GDMs). In this work, we\nchallenge this assumption by investigating whether denoisers can implicitly\ninfer noise levels directly from corrupted graph structures, potentially\neliminating the need for explicit noise conditioning. To this end, we develop a\ntheoretical framework centered on Bernoulli edge-flip corruptions and extend it\nto encompass more complex scenarios involving coupled structure-attribute\nnoise. Extensive empirical evaluations on both synthetic and real-world graph\ndatasets, using models such as GDSS and DiGress, provide strong support for our\ntheoretical findings. Notably, unconditional GDMs achieve performance\ncomparable or superior to their conditioned counterparts, while also offering\nreductions in parameters (4-6%) and computation time (8-10%). Our results\nsuggest that the high-dimensional nature of graph data itself often encodes\nsufficient information for the denoising process, opening avenues for simpler,\nmore efficient GDM architectures.", "AI": {"tldr": "The paper challenges the necessity of explicit noise-level conditioning in Graph Diffusion Models (GDMs) by showing denoisers can implicitly infer noise levels from corrupted graph structures.", "motivation": "To explore if denoisers can infer noise levels without explicit conditioning, simplifying GDM architectures.", "method": "Developed a theoretical framework for Bernoulli edge-flip corruptions and extended it to coupled structure-attribute noise, validated empirically on synthetic and real-world datasets.", "result": "Unconditional GDMs matched or outperformed conditioned ones, reducing parameters (4-6%) and computation time (8-10%).", "conclusion": "Graph data's high-dimensional nature often provides enough information for denoising, enabling simpler, more efficient GDM designs."}}
{"id": "2505.23001", "pdf": "https://arxiv.org/pdf/2505.23001", "abs": "https://arxiv.org/abs/2505.23001", "authors": ["Yize Cheng", "Wenxiao Wang", "Mazda Moayeri", "Soheil Feizi"], "title": "DyePack: Provably Flagging Test Set Contamination in LLMs Using Backdoors", "categories": ["cs.CL"], "comment": null, "summary": "Open benchmarks are essential for evaluating and advancing large language\nmodels, offering reproducibility and transparency. However, their accessibility\nmakes them likely targets of test set contamination. In this work, we introduce\nDyePack, a framework that leverages backdoor attacks to identify models that\nused benchmark test sets during training, without requiring access to the loss,\nlogits, or any internal details of the model. Like how banks mix dye packs with\ntheir money to mark robbers, DyePack mixes backdoor samples with the test data\nto flag models that trained on it. We propose a principled design incorporating\nmultiple backdoors with stochastic targets, enabling exact false positive rate\n(FPR) computation when flagging every model. This provably prevents false\naccusations while providing strong evidence for every detected case of\ncontamination. We evaluate DyePack on five models across three datasets,\ncovering both multiple-choice and open-ended generation tasks. For\nmultiple-choice questions, it successfully detects all contaminated models with\nguaranteed FPRs as low as 0.000073% on MMLU-Pro and 0.000017% on Big-Bench-Hard\nusing eight backdoors. For open-ended generation tasks, it generalizes well and\nidentifies all contaminated models on Alpaca with a guaranteed false positive\nrate of just 0.127% using six backdoors.", "AI": {"tldr": "DyePack is a framework using backdoor attacks to detect if models trained on benchmark test sets, ensuring low false positive rates and strong evidence for contamination.", "motivation": "Open benchmarks are prone to test set contamination, necessitating a method to detect misuse without accessing model internals.", "method": "DyePack introduces backdoor samples into test data, using stochastic targets for precise false positive rate control.", "result": "It detects contamination with extremely low false positive rates (e.g., 0.000073% on MMLU-Pro) across multiple datasets and tasks.", "conclusion": "DyePack effectively identifies benchmark misuse with provable guarantees, enhancing reproducibility in model evaluation."}}
{"id": "2505.23040", "pdf": "https://arxiv.org/pdf/2505.23040", "abs": "https://arxiv.org/abs/2505.23040", "authors": ["Yihang Wu", "Muhammad Owais", "Reem Kateb", "Ahmad Chaddad"], "title": "Deep Modeling and Optimization of Medical Image Classification", "categories": ["cs.CV"], "comment": "Accepted in ISBI2025", "summary": "Deep models, such as convolutional neural networks (CNNs) and vision\ntransformer (ViT), demonstrate remarkable performance in image classification.\nHowever, those deep models require large data to fine-tune, which is\nimpractical in the medical domain due to the data privacy issue. Furthermore,\ndespite the feasible performance of contrastive language image pre-training\n(CLIP) in the natural domain, the potential of CLIP has not been fully\ninvestigated in the medical field. To face these challenges, we considered\nthree scenarios: 1) we introduce a novel CLIP variant using four CNNs and eight\nViTs as image encoders for the classification of brain cancer and skin cancer,\n2) we combine 12 deep models with two federated learning techniques to protect\ndata privacy, and 3) we involve traditional machine learning (ML) methods to\nimprove the generalization ability of those deep models in unseen domain data.\nThe experimental results indicate that maxvit shows the highest averaged (AVG)\ntest metrics (AVG = 87.03\\%) in HAM10000 dataset with multimodal learning,\nwhile convnext\\_l demonstrates remarkable test with an F1-score of 83.98\\%\ncompared to swin\\_b with 81.33\\% in FL model. Furthermore, the use of support\nvector machine (SVM) can improve the overall test metrics with AVG of $\\sim\n2\\%$ for swin transformer series in ISIC2018. Our codes are available at\nhttps://github.com/AIPMLab/SkinCancerSimulation.", "AI": {"tldr": "The paper proposes a novel CLIP variant for medical image classification, combines deep models with federated learning for privacy, and uses traditional ML to enhance generalization. Results show improved performance in brain and skin cancer datasets.", "motivation": "Address the impracticality of fine-tuning deep models in the medical domain due to data privacy and underutilization of CLIP in medicine.", "method": "Introduce a CLIP variant with CNNs and ViTs, combine 12 deep models with federated learning, and integrate traditional ML methods.", "result": "MaxViT achieved 87.03% AVG in HAM10000, ConvNeXt_L scored 83.98% F1 in FL, and SVM boosted swin transformer by ~2% in ISIC2018.", "conclusion": "The approach effectively tackles privacy and generalization challenges, demonstrating strong performance in medical image classification."}}
{"id": "2505.23667", "pdf": "https://arxiv.org/pdf/2505.23667", "abs": "https://arxiv.org/abs/2505.23667", "authors": ["Lang Cao", "Jingxian Xu", "Hanbing Liu", "Jinyu Wang", "Mengyu Zhou", "Haoyu Dong", "Shi Han", "Dongmei Zhang"], "title": "Fortune: Formula-Driven Reinforcement Learning for Symbolic Table Reasoning in Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Tables are a fundamental structure for organizing and analyzing data, making\neffective table understanding a critical capability for intelligent systems.\nWhile large language models (LMs) demonstrate strong general reasoning\nabilities, they continue to struggle with accurate numerical or symbolic\nreasoning over tabular data, especially in complex scenarios. Spreadsheet\nformulas provide a powerful and expressive medium for representing executable\nsymbolic operations, encoding rich reasoning patterns that remain largely\nunderutilized. In this paper, we propose Formula Tuning (Fortune), a\nreinforcement learning (RL) framework that trains LMs to generate executable\nspreadsheet formulas for question answering over general tabular data. Formula\nTuning reduces the reliance on supervised formula annotations by using binary\nanswer correctness as a reward signal, guiding the model to learn formula\nderivation through reasoning. We provide a theoretical analysis of its\nadvantages and demonstrate its effectiveness through extensive experiments on\nseven table reasoning benchmarks. Formula Tuning substantially enhances LM\nperformance, particularly on multi-step numerical and symbolic reasoning tasks,\nenabling a 7B model to outperform O1 on table understanding. This highlights\nthe potential of formula-driven RL to advance symbolic table reasoning in LMs.", "AI": {"tldr": "Formula Tuning (Fortune) is a reinforcement learning framework that trains LMs to generate spreadsheet formulas for table reasoning, improving performance on numerical and symbolic tasks.", "motivation": "Large LMs struggle with numerical/symbolic reasoning over tabular data, despite their general reasoning abilities. Spreadsheet formulas offer rich but underutilized reasoning patterns.", "method": "Proposes Formula Tuning, an RL framework using binary answer correctness as a reward signal to train LMs for formula generation, reducing reliance on supervised annotations.", "result": "Substantially enhances LM performance on multi-step numerical/symbolic reasoning, enabling a 7B model to outperform O1 on table understanding benchmarks.", "conclusion": "Formula-driven RL has potential to advance symbolic table reasoning in LMs, as demonstrated by improved performance on complex tasks."}}
{"id": "2505.22949", "pdf": "https://arxiv.org/pdf/2505.22949", "abs": "https://arxiv.org/abs/2505.22949", "authors": ["Michael Sun", "Orion Foo", "Gang Liu", "Wojciech Matusik", "Jie Chen"], "title": "Directed Graph Grammars for Sequence-based Learning", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Directed acyclic graphs (DAGs) are a class of graphs commonly used in\npractice, with examples that include electronic circuits, Bayesian networks,\nand neural architectures. While many effective encoders exist for DAGs, it\nremains challenging to decode them in a principled manner, because the nodes of\na DAG can have many different topological orders. In this work, we propose a\ngrammar-based approach to constructing a principled, compact and equivalent\nsequential representation of a DAG. Specifically, we view a graph as\nderivations over an unambiguous grammar, where the DAG corresponds to a unique\nsequence of production rules. Equivalently, the procedure to construct such a\ndescription can be viewed as a lossless compression of the data. Such a\nrepresentation has many uses, including building a generative model for graph\ngeneration, learning a latent space for property prediction, and leveraging the\nsequence representational continuity for Bayesian Optimization over structured\ndata. Code is available at https://github.com/shiningsunnyday/induction.", "AI": {"tldr": "A grammar-based method for decoding DAGs into unique sequential representations, enabling applications like generative modeling and Bayesian optimization.", "motivation": "Decoding DAGs is challenging due to multiple topological orders; a principled approach is needed for sequential representation.", "method": "Proposes a grammar-based approach, treating DAGs as derivations over an unambiguous grammar to generate unique sequences.", "result": "Creates a compact, equivalent sequential representation of DAGs, useful for generative models, property prediction, and Bayesian optimization.", "conclusion": "The method provides a principled way to decode DAGs, with broad applications in structured data tasks."}}
{"id": "2505.23006", "pdf": "https://arxiv.org/pdf/2505.23006", "abs": "https://arxiv.org/abs/2505.23006", "authors": ["Chiwan Park", "Wonjun Jang", "Daeryong Kim", "Aelim Ahn", "Kichang Yang", "Woosung Hwang", "Jihyeon Roh", "Hyerin Park", "Hyosun Wang", "Min Seok Kim", "Jihoon Kang"], "title": "A Practical Approach for Building Production-Grade Conversational Agents with Workflow Graphs", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "Accepted to ACL 2025 Industry Track. 12 pages, 5 figures", "summary": "The advancement of Large Language Models (LLMs) has led to significant\nimprovements in various service domains, including search, recommendation, and\nchatbot applications. However, applying state-of-the-art (SOTA) research to\nindustrial settings presents challenges, as it requires maintaining flexible\nconversational abilities while also strictly complying with service-specific\nconstraints. This can be seen as two conflicting requirements due to the\nprobabilistic nature of LLMs. In this paper, we propose our approach to\naddressing this challenge and detail the strategies we employed to overcome\ntheir inherent limitations in real-world applications. We conduct a practical\ncase study of a conversational agent designed for the e-commerce domain,\ndetailing our implementation workflow and optimizations. Our findings provide\ninsights into bridging the gap between academic research and real-world\napplication, introducing a framework for developing scalable, controllable, and\nreliable AI-driven agents.", "AI": {"tldr": "The paper addresses the challenge of applying SOTA LLMs in industrial settings by balancing conversational flexibility with service-specific constraints, demonstrated through an e-commerce chatbot case study.", "motivation": "The need to reconcile the probabilistic nature of LLMs with strict industrial requirements in applications like search, recommendation, and chatbots.", "method": "Proposes a framework for developing scalable, controllable, and reliable AI-driven agents, detailed via an e-commerce conversational agent case study.", "result": "Provides insights and strategies for bridging the gap between academic research and real-world LLM applications.", "conclusion": "Introduces a practical framework for deploying LLMs in industrial settings, ensuring both flexibility and compliance."}}
{"id": "2505.23043", "pdf": "https://arxiv.org/pdf/2505.23043", "abs": "https://arxiv.org/abs/2505.23043", "authors": ["Jihai Zhang", "Tianle Li", "Linjie Li", "Zhengyuan Yang", "Yu Cheng"], "title": "Are Unified Vision-Language Models Necessary: Generalization Across Understanding and Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advancements in unified vision-language models (VLMs), which integrate\nboth visual understanding and generation capabilities, have attracted\nsignificant attention. The underlying hypothesis is that a unified architecture\nwith mixed training on both understanding and generation tasks can enable\nmutual enhancement between understanding and generation. However, this\nhypothesis remains underexplored in prior works on unified VLMs. To address\nthis gap, this paper systematically investigates the generalization across\nunderstanding and generation tasks in unified VLMs. Specifically, we design a\ndataset closely aligned with real-world scenarios to facilitate extensive\nexperiments and quantitative evaluations. We evaluate multiple unified VLM\narchitectures to validate our findings. Our key findings are as follows. First,\nunified VLMs trained with mixed data exhibit mutual benefits in understanding\nand generation tasks across various architectures, and this mutual benefits can\nscale up with increased data. Second, better alignment between multimodal input\nand output spaces will lead to better generalization. Third, the knowledge\nacquired during generation tasks can transfer to understanding tasks, and this\ncross-task generalization occurs within the base language model, beyond\nmodality adapters. Our findings underscore the critical necessity of unifying\nunderstanding and generation in VLMs, offering valuable insights for the design\nand optimization of unified VLMs.", "AI": {"tldr": "Unified vision-language models (VLMs) show mutual benefits between understanding and generation tasks, scaling with data and alignment. Cross-task generalization occurs within the base language model.", "motivation": "To explore the underexplored hypothesis that unified VLMs with mixed training enhance both understanding and generation tasks.", "method": "Systematic investigation using a real-world-aligned dataset and evaluation of multiple unified VLM architectures.", "result": "Mutual benefits between tasks, scalability with data, better alignment improves generalization, and cross-task knowledge transfer within the base language model.", "conclusion": "Unifying understanding and generation in VLMs is critical, providing insights for their design and optimization."}}
{"id": "2505.23695", "pdf": "https://arxiv.org/pdf/2505.23695", "abs": "https://arxiv.org/abs/2505.23695", "authors": ["Ran Zhang", "Mohannad Elhamod"], "title": "Data-to-Dashboard: Multi-Agent LLM Framework for Insightful Visualization in Enterprise Analytics", "categories": ["cs.AI"], "comment": null, "summary": "The rapid advancement of LLMs has led to the creation of diverse agentic\nsystems in data analysis, utilizing LLMs' capabilities to improve insight\ngeneration and visualization. In this paper, we present an agentic system that\nautomates the data-to-dashboard pipeline through modular LLM agents capable of\ndomain detection, concept extraction, multi-perspective analysis generation,\nand iterative self-reflection. Unlike existing chart QA systems, our framework\nsimulates the analytical reasoning process of business analysts by retrieving\ndomain-relevant knowledge and adapting to diverse datasets without relying on\nclosed ontologies or question templates.\n  We evaluate our system on three datasets across different domains.\nBenchmarked against GPT-4o with a single-prompt baseline, our approach shows\nimproved insightfulness, domain relevance, and analytical depth, as measured by\ntailored evaluation metrics and qualitative human assessment.\n  This work contributes a novel modular pipeline to bridge the path from raw\ndata to visualization, and opens new opportunities for human-in-the-loop\nvalidation by domain experts in business analytics. All code can be found here:\nhttps://github.com/77luvC/D2D_Data2Dashboard", "AI": {"tldr": "The paper introduces a modular LLM-based agentic system for automating data-to-dashboard pipelines, outperforming GPT-4o in insightfulness and domain relevance.", "motivation": "To enhance data analysis and visualization by leveraging LLMs' capabilities, simulating human analytical reasoning without relying on rigid templates.", "method": "Uses modular LLM agents for domain detection, concept extraction, multi-perspective analysis, and iterative self-reflection. Evaluated on diverse datasets.", "result": "Outperforms GPT-4o in insightfulness, domain relevance, and analytical depth, validated by tailored metrics and human assessment.", "conclusion": "Presents a novel pipeline for data-to-dashboard automation, enabling human-in-the-loop validation in business analytics."}}
{"id": "2505.22973", "pdf": "https://arxiv.org/pdf/2505.22973", "abs": "https://arxiv.org/abs/2505.22973", "authors": ["Bahareh Tolooshams", "Aditi Chandrashekar", "Rayhan Zirvi", "Abbas Mammadov", "Jiachen Yao", "Chuwei Wang", "Anima Anandkumar"], "title": "EquiReg: Equivariance Regularized Diffusion for Inverse Problems", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion models represent the state-of-the-art for solving inverse problems\nsuch as image restoration tasks. In the Bayesian framework, diffusion-based\ninverse solvers incorporate a likelihood term to guide the prior sampling\nprocess, generating data consistent with the posterior distribution. However,\ndue to the intractability of the likelihood term, many current methods rely on\nisotropic Gaussian approximations, which lead to deviations from the data\nmanifold and result in inconsistent, unstable reconstructions. We propose\nEquivariance Regularized (EquiReg) diffusion, a general framework for\nregularizing posterior sampling in diffusion-based inverse problem solvers.\nEquiReg enhances reconstructions by reweighting diffusion trajectories and\npenalizing those that deviate from the data manifold. We define a new\ndistribution-dependent equivariance error, empirically identify functions that\nexhibit low error for on-manifold samples and higher error for off-manifold\nsamples, and leverage these functions to regularize the diffusion sampling\nprocess. When applied to a variety of solvers, EquiReg outperforms\nstate-of-the-art diffusion models in both linear and nonlinear image\nrestoration tasks, as well as in reconstructing partial differential equations.", "AI": {"tldr": "EquiReg diffusion improves diffusion-based inverse problem solvers by regularizing posterior sampling, outperforming state-of-the-art methods in image restoration and PDE reconstruction.", "motivation": "Current diffusion-based inverse solvers use isotropic Gaussian approximations, leading to inconsistent reconstructions due to deviations from the data manifold.", "method": "EquiReg reweights diffusion trajectories and penalizes off-manifold samples using a distribution-dependent equivariance error.", "result": "EquiReg outperforms state-of-the-art diffusion models in linear/nonlinear image restoration and PDE reconstruction.", "conclusion": "EquiReg provides a robust framework for enhancing diffusion-based inverse problem solvers by maintaining data manifold consistency."}}
{"id": "2505.23015", "pdf": "https://arxiv.org/pdf/2505.23015", "abs": "https://arxiv.org/abs/2505.23015", "authors": ["Jinwen Chen", "Hainan Zhang", "Fei Sun", "Qinnan Zhang", "Sijia Wen", "Ziwei Wang", "Zhiming Zheng"], "title": "Detecting Stealthy Backdoor Samples based on Intra-class Distance for Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Fine-tuning LLMs with datasets containing stealthy backdoors from publishers\nposes security risks to downstream applications. Mainstream detection methods\neither identify poisoned samples by analyzing the prediction probability of\npoisoned classification models or rely on the rewriting model to eliminate the\nstealthy triggers. However, the former cannot be applied to generation tasks,\nwhile the latter may degrade generation performance and introduce new triggers.\nTherefore, efficiently eliminating stealthy poisoned samples for LLMs remains\nan urgent problem. We observe that after applying TF-IDF clustering to the\nsample response, there are notable differences in the intra-class distances\nbetween clean and poisoned samples. Poisoned samples tend to cluster closely\nbecause of their specific malicious outputs, whereas clean samples are more\nscattered due to their more varied responses. Thus, in this paper, we propose a\nstealthy backdoor sample detection method based on Reference-Filtration and\nTfidf-Clustering mechanisms (RFTC). Specifically, we first compare the sample\nresponse with the reference model's outputs and consider the sample suspicious\nif there's a significant discrepancy. And then we perform TF-IDF clustering on\nthese suspicious samples to identify the true poisoned samples based on the\nintra-class distance. Experiments on two machine translation datasets and one\nQA dataset demonstrate that RFTC outperforms baselines in backdoor detection\nand model performance. Further analysis of different reference models also\nconfirms the effectiveness of our Reference-Filtration.", "AI": {"tldr": "The paper proposes RFTC, a method to detect stealthy backdoor samples in LLMs using Reference-Filtration and TF-IDF clustering, outperforming existing methods.", "motivation": "Existing detection methods for poisoned samples in LLMs are either ineffective for generation tasks or degrade performance, necessitating a better solution.", "method": "RFTC combines Reference-Filtration (comparing responses to a reference model) and TF-IDF clustering (analyzing intra-class distances) to identify poisoned samples.", "result": "RFTC shows superior performance in backdoor detection and model performance on translation and QA datasets compared to baselines.", "conclusion": "RFTC effectively addresses the challenge of detecting stealthy backdoor samples in LLMs without compromising generation quality."}}
{"id": "2505.23044", "pdf": "https://arxiv.org/pdf/2505.23044", "abs": "https://arxiv.org/abs/2505.23044", "authors": ["Yu Sheng", "Jiajun Deng", "Xinran Zhang", "Yu Zhang", "Bei Hua", "Yanyong Zhang", "Jianmin Ji"], "title": "SpatialSplat: Efficient Semantic 3D from Sparse Unposed Images", "categories": ["cs.CV"], "comment": null, "summary": "A major breakthrough in 3D reconstruction is the feedforward paradigm to\ngenerate pixel-wise 3D points or Gaussian primitives from sparse, unposed\nimages. To further incorporate semantics while avoiding the significant memory\nand storage costs of high-dimensional semantic features, existing methods\nextend this paradigm by associating each primitive with a compressed semantic\nfeature vector. However, these methods have two major limitations: (a) the\nnaively compressed feature compromises expressiveness, affecting the model's\nability to capture fine-grained semantics, and (b) the pixel-wise primitive\nprediction introduces redundancy in overlapping areas, causing unnecessary\nmemory overhead. To this end, we introduce \\textbf{SpatialSplat}, a feedforward\nframework that produces redundancy-aware Gaussians and capitalizes on a\ndual-field semantic representation. Particularly, with the insight that\nprimitives within the same instance exhibit high semantic consistency, we\ndecompose the semantic representation into a coarse feature field that encodes\nuncompressed semantics with minimal primitives, and a fine-grained yet\nlow-dimensional feature field that captures detailed inter-instance\nrelationships. Moreover, we propose a selective Gaussian mechanism, which\nretains only essential Gaussians in the scene, effectively eliminating\nredundant primitives. Our proposed Spatialsplat learns accurate semantic\ninformation and detailed instances prior with more compact 3D Gaussians, making\nsemantic 3D reconstruction more applicable. We conduct extensive experiments to\nevaluate our method, demonstrating a remarkable 60\\% reduction in scene\nrepresentation parameters while achieving superior performance over\nstate-of-the-art methods. The code will be made available for future\ninvestigation.", "AI": {"tldr": "SpatialSplat introduces a feedforward framework for 3D reconstruction with dual-field semantic representation and selective Gaussian mechanism, reducing redundancy and improving efficiency.", "motivation": "Existing methods compromise semantic expressiveness and introduce memory overhead due to naive feature compression and redundant primitives.", "method": "SpatialSplat uses a dual-field semantic representation (coarse and fine-grained) and a selective Gaussian mechanism to eliminate redundancy.", "result": "Achieves a 60% reduction in scene representation parameters while outperforming state-of-the-art methods.", "conclusion": "SpatialSplat enables more compact and accurate semantic 3D reconstruction, making it more practical for real-world applications."}}
{"id": "2505.23703", "pdf": "https://arxiv.org/pdf/2505.23703", "abs": "https://arxiv.org/abs/2505.23703", "authors": ["Ruida Wang", "Yuxin Li", "Yi R.", "Fung", "Tong Zhang"], "title": "Let's Reason Formally: Natural-Formal Hybrid Reasoning Enhances LLM's Math Capability", "categories": ["cs.AI"], "comment": null, "summary": "Enhancing the mathematical reasoning capabilities of LLMs has garnered\nsignificant attention in both the mathematical and computer science\ncommunities. Recent works have made substantial progress in both Natural\nLanguage (NL) reasoning and Formal Language (FL) reasoning by leveraging the\npotential of pure Reinforcement Learning (RL) methods on base models. However,\nRL approaches struggle to impart new capabilities not presented in the base\nmodel, highlighting the need to integrate more knowledge like FL into NL math\nreasoning effectively. Yet, this integration is challenging due to inherent\ndisparities in problem structure and reasoning format between NL and FL. To\naddress these challenges, we introduce **NL-FL HybridReasoning**, an end-to-end\nframework designed to incorporate the FL expert into NL math problem-solving.\nTo bridge the NL and FL input format gap, we propose the *NL-FL Problem\nAlignment* method, which reformulates the Question-Answering (QA) problems in\nNL as existence theorems in FL. Subsequently, the *Mixed Problem Input*\ntechnique we provide enables the FL reasoner to handle both QA and existence\nproblems concurrently. Lastly, we mitigate the NL and FL output format gap in\nreasoning through an LLM-based *Answer Extraction* mechanism. Comprehensive\nexperiments demonstrate that the **HybridReasoning** framework achieves\n**89.80%** and **84.34%** accuracy rates on the MATH-500 and the AMC\nbenchmarks, surpassing the NL baseline by 4.60% and 4.82%, respectively.\nNotably, some problems resolved by our framework remain unsolved by the NL\nbaseline model even under a larger number of trials.", "AI": {"tldr": "The paper introduces **NL-FL HybridReasoning**, a framework combining Natural Language (NL) and Formal Language (FL) to enhance math reasoning in LLMs, achieving higher accuracy than NL baselines.", "motivation": "Current RL methods for LLMs struggle to integrate new capabilities like FL into NL math reasoning due to disparities in problem structure and reasoning format.", "method": "The framework includes *NL-FL Problem Alignment* to reformulate NL QA problems as FL existence theorems, *Mixed Problem Input* for handling both QA and existence problems, and *Answer Extraction* to bridge output gaps.", "result": "The framework achieves 89.80% and 84.34% accuracy on MATH-500 and AMC benchmarks, outperforming NL baselines by 4.60% and 4.82%.", "conclusion": "**HybridReasoning** effectively integrates FL into NL math reasoning, solving problems unsolved by NL baselines."}}
{"id": "2505.22984", "pdf": "https://arxiv.org/pdf/2505.22984", "abs": "https://arxiv.org/abs/2505.22984", "authors": ["Guancheng Zhou", "Haiping Xu", "Hongkang Xu", "Chenyu Li", "Donghui Yan"], "title": "A Computational Approach to Improving Fairness in K-means Clustering", "categories": ["cs.LG", "cs.CY"], "comment": "14 pages, 5 figures", "summary": "The popular K-means clustering algorithm potentially suffers from a major\nweakness for further analysis or interpretation. Some cluster may have\ndisproportionately more (or fewer) points from one of the subpopulations in\nterms of some sensitive variable, e.g., gender or race. Such a fairness issue\nmay cause bias and unexpected social consequences. This work attempts to\nimprove the fairness of K-means clustering with a two-stage optimization\nformulation--clustering first and then adjust cluster membership of a small\nsubset of selected data points. Two computationally efficient algorithms are\nproposed in identifying those data points that are expensive for fairness, with\none focusing on nearest data points outside of a cluster and the other on\nhighly 'mixed' data points. Experiments on benchmark datasets show substantial\nimprovement on fairness with a minimal impact to clustering quality. The\nproposed algorithms can be easily extended to a broad class of clustering\nalgorithms or fairness metrics.", "AI": {"tldr": "The paper addresses fairness issues in K-means clustering by proposing a two-stage optimization method to adjust cluster membership, improving fairness with minimal impact on clustering quality.", "motivation": "K-means clustering can unfairly distribute points from sensitive groups (e.g., gender, race), leading to bias and social consequences. This work aims to mitigate such fairness issues.", "method": "A two-stage optimization approach: first, perform clustering; then, adjust cluster membership for a small subset of data points. Two algorithms are proposed to identify fairness-expensive points.", "result": "Experiments show significant fairness improvements with negligible impact on clustering quality. The methods are adaptable to other clustering algorithms or fairness metrics.", "conclusion": "The proposed approach effectively enhances fairness in K-means clustering while preserving clustering performance, with potential for broader applications."}}
{"id": "2505.23026", "pdf": "https://arxiv.org/pdf/2505.23026", "abs": "https://arxiv.org/abs/2505.23026", "authors": ["Haewon Park", "Gyubin Choi", "Minjun Kim", "Yohan Jo"], "title": "Context Robust Knowledge Editing for Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Findings. Our code and datasets are available at\n  (https://github.com/holi-lab/CoRE)", "summary": "Knowledge editing (KE) methods offer an efficient way to modify knowledge in\nlarge language models. Current KE evaluations typically assess editing success\nby considering only the edited knowledge without any preceding contexts. In\nreal-world applications, however, preceding contexts often trigger the\nretrieval of the original knowledge and undermine the intended edit. To address\nthis issue, we develop CHED -- a benchmark designed to evaluate the context\nrobustness of KE methods. Evaluations on CHED show that they often fail when\npreceding contexts are present. To mitigate this shortcoming, we introduce\nCoRE, a KE method designed to strengthen context robustness by minimizing\ncontext-sensitive variance in hidden states of the model for edited knowledge.\nThis method not only improves the editing success rate in situations where a\npreceding context is present but also preserves the overall capabilities of the\nmodel. We provide an in-depth analysis of the differing impacts of preceding\ncontexts when introduced as user utterances versus assistant responses, and we\ndissect attention-score patterns to assess how specific tokens influence\nediting success.", "AI": {"tldr": "The paper introduces CHED, a benchmark for evaluating context robustness in knowledge editing (KE) methods, and CoRE, a KE method to improve robustness by reducing context-sensitive variance in hidden states.", "motivation": "Current KE evaluations ignore preceding contexts, which can trigger original knowledge retrieval and undermine edits. The paper aims to address this gap.", "method": "Develop CHED benchmark for context robustness evaluation and propose CoRE, a KE method minimizing context-sensitive variance in hidden states.", "result": "KE methods often fail with preceding contexts. CoRE improves editing success while preserving model capabilities.", "conclusion": "CoRE enhances context robustness in KE, and CHED provides a valuable benchmark for future evaluations."}}
{"id": "2505.23045", "pdf": "https://arxiv.org/pdf/2505.23045", "abs": "https://arxiv.org/abs/2505.23045", "authors": ["Chuanhao Li", "Wenbo Ye", "Zhen Li", "Yuwei Wu", "Yunde Jia"], "title": "Multi-Sourced Compositional Generalization in Visual Question Answering", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by IJCAI 2025", "summary": "Compositional generalization is the ability of generalizing novel\ncompositions from seen primitives, and has received much attention in\nvision-and-language (V\\&L) recently. Due to the multi-modal nature of V\\&L\ntasks, the primitives composing compositions source from different modalities,\nresulting in multi-sourced novel compositions. However, the generalization\nability over multi-sourced novel compositions, \\textit{i.e.}, multi-sourced\ncompositional generalization (MSCG) remains unexplored. In this paper, we\nexplore MSCG in the context of visual question answering (VQA), and propose a\nretrieval-augmented training framework to enhance the MSCG ability of VQA\nmodels by learning unified representations for primitives from different\nmodalities. Specifically, semantically equivalent primitives are retrieved for\neach primitive in the training samples, and the retrieved features are\naggregated with the original primitive to refine the model. This process helps\nthe model learn consistent representations for the same semantic primitives\nacross different modalities. To evaluate the MSCG ability of VQA models, we\nconstruct a new GQA-MSCG dataset based on the GQA dataset, in which samples\ninclude three types of novel compositions composed of primitives from different\nmodalities. Experimental results demonstrate the effectiveness of the proposed\nframework. We release GQA-MSCG at https://github.com/NeverMoreLCH/MSCG.", "AI": {"tldr": "The paper explores multi-sourced compositional generalization (MSCG) in VQA, proposing a retrieval-augmented training framework to unify representations of multi-modal primitives. A new dataset, GQA-MSCG, is introduced for evaluation.", "motivation": "To address the unexplored challenge of MSCG in V&L tasks, particularly VQA, where compositions involve primitives from different modalities.", "method": "A retrieval-augmented training framework retrieves and aggregates semantically equivalent primitives to learn unified representations across modalities.", "result": "The framework enhances MSCG ability, validated by experiments on the newly constructed GQA-MSCG dataset.", "conclusion": "The proposed method effectively improves MSCG in VQA, with the GQA-MSCG dataset serving as a benchmark for future research."}}
{"id": "2505.23746", "pdf": "https://arxiv.org/pdf/2505.23746", "abs": "https://arxiv.org/abs/2505.23746", "authors": ["Hugo Henry", "Kelly Cohen"], "title": "Comparative of Genetic Fuzzy regression techniques for aeroacoustic phenomenons", "categories": ["cs.AI", "cs.NE"], "comment": "11 pages and 23 figures", "summary": "This study investigates the application of Genetic Fuzzy Systems (GFS) to\nmodel the self-noise generated by airfoils, a key issue in aeroaccoustics with\nsignificant implications for aerospace, automotive and drone applications.\nUsing the publicly available Airfoil Self Noise dataset, various Fuzzy\nregression strategies are explored and compared. The paper evaluates a brute\nforce Takagi Sugeno Kang (TSK) fuzzy system with high rule density, a cascading\nGeneti Fuzzy Tree (GFT) architecture and a novel clustered approach based on\nFuzzy C-means (FCM) to reduce the model's complexity. This highlights the\nviability of clustering assisted fuzzy inference as an effective regression\ntool for complex aero accoustic phenomena. Keywords : Fuzzy logic, Regression,\nCascading systems, Clustering and AI.", "AI": {"tldr": "The study explores Genetic Fuzzy Systems (GFS) for modeling airfoil self-noise, comparing methods like brute force TSK, GFT, and FCM-based clustering to simplify complexity.", "motivation": "Addressing airfoil self-noise is crucial for aerospace, automotive, and drone applications, requiring accurate modeling tools.", "method": "The paper evaluates brute force TSK, cascading GFT, and FCM-based clustered approaches using the Airfoil Self Noise dataset.", "result": "Clustering-assisted fuzzy inference proves effective for modeling complex aeroacoustic phenomena.", "conclusion": "The study demonstrates the viability of GFS, particularly clustered approaches, for aeroacoustic regression tasks."}}
{"id": "2505.22985", "pdf": "https://arxiv.org/pdf/2505.22985", "abs": "https://arxiv.org/abs/2505.22985", "authors": ["Masaharu Kagiyama", "Tsuyoshi Okita"], "title": "Knowledge Distillation for Reservoir-based Classifier: Human Activity Recognition", "categories": ["cs.LG", "cs.AI", "cs.PF"], "comment": "23 pages,5 figures", "summary": "This paper aims to develop an energy-efficient classifier for time-series\ndata by introducing PatchEchoClassifier, a novel model that leverages a\nreservoir-based mechanism known as the Echo State Network (ESN). The model is\ndesigned for human activity recognition (HAR) using one-dimensional sensor\nsignals and incorporates a tokenizer to extract patch-level representations. To\ntrain the model efficiently, we propose a knowledge distillation framework that\ntransfers knowledge from a high-capacity MLP-Mixer teacher to the lightweight\nreservoir-based student model. Experimental evaluations on multiple HAR\ndatasets demonstrate that our model achieves over 80 percent accuracy while\nsignificantly reducing computational cost. Notably, PatchEchoClassifier\nrequires only about one-sixth of the floating point operations (FLOPS) compared\nto DeepConvLSTM, a widely used convolutional baseline. These results suggest\nthat PatchEchoClassifier is a promising solution for real-time and\nenergy-efficient human activity recognition in edge computing environments.", "AI": {"tldr": "PatchEchoClassifier is an energy-efficient model for HAR using ESN and knowledge distillation, achieving 80% accuracy with low computational cost.", "motivation": "To develop a lightweight, energy-efficient classifier for HAR in edge computing environments.", "method": "Uses Echo State Network (ESN) with patch-level tokenizer and knowledge distillation from an MLP-Mixer teacher.", "result": "Achieves over 80% accuracy with significantly reduced FLOPS (1/6 of DeepConvLSTM).", "conclusion": "PatchEchoClassifier is promising for real-time, energy-efficient HAR."}}
{"id": "2505.23029", "pdf": "https://arxiv.org/pdf/2505.23029", "abs": "https://arxiv.org/abs/2505.23029", "authors": ["Si Wu", "Sebastian Bruch"], "title": "Uncovering Visual-Semantic Psycholinguistic Properties from the Distributional Structure of Text Embedding Spac", "categories": ["cs.CL"], "comment": "Accepted for ACL 2025. This is the camera-ready version. Will be\n  presenting in July 2025 in Vienna", "summary": "Imageability (potential of text to evoke a mental image) and concreteness\n(perceptibility of text) are two psycholinguistic properties that link visual\nand semantic spaces. It is little surprise that computational methods that\nestimate them do so using parallel visual and semantic spaces, such as\ncollections of image-caption pairs or multi-modal models. In this paper, we\nwork on the supposition that text itself in an image-caption dataset offers\nsufficient signals to accurately estimate these properties. We hypothesize, in\nparticular, that the peakedness of the neighborhood of a word in the semantic\nembedding space reflects its degree of imageability and concreteness. We then\npropose an unsupervised, distribution-free measure, which we call Neighborhood\nStability Measure (NSM), that quantifies the sharpness of peaks. Extensive\nexperiments show that NSM correlates more strongly with ground-truth ratings\nthan existing unsupervised methods, and is a strong predictor of these\nproperties for classification. Our code and data are available on GitHub\n(https://github.com/Artificial-Memory-Lab/imageability).", "AI": {"tldr": "The paper proposes an unsupervised measure, Neighborhood Stability Measure (NSM), to estimate imageability and concreteness of text using semantic embedding space, outperforming existing methods.", "motivation": "To leverage text signals in image-caption datasets for estimating psycholinguistic properties like imageability and concreteness without relying on parallel visual-semantic spaces.", "method": "Introduces NSM, which quantifies the peakedness of a word's neighborhood in semantic embedding space to reflect imageability and concreteness.", "result": "NSM correlates more strongly with ground-truth ratings than existing unsupervised methods and is effective for classification.", "conclusion": "Text in image-caption datasets provides sufficient signals for accurate estimation of imageability and concreteness using NSM."}}
{"id": "2505.23054", "pdf": "https://arxiv.org/pdf/2505.23054", "abs": "https://arxiv.org/abs/2505.23054", "authors": ["Yuxuan Lin", "Ruihang Chu", "Zhenyu Chen", "Xiao Tang", "Lei Ke", "Haoling Li", "Yingji Zhong", "Zhihao Li", "Shiyong Liu", "Xiaofei Wu", "Jianzhuang Liu", "Yujiu Yang"], "title": "Zero-P-to-3: Zero-Shot Partial-View Images to 3D Object", "categories": ["cs.CV"], "comment": null, "summary": "Generative 3D reconstruction shows strong potential in incomplete\nobservations. While sparse-view and single-image reconstruction are\nwell-researched, partial observation remains underexplored. In this context,\ndense views are accessible only from a specific angular range, with other\nperspectives remaining inaccessible. This task presents two main challenges:\n(i) limited View Range: observations confined to a narrow angular scope prevent\neffective traditional interpolation techniques that require evenly distributed\nperspectives. (ii) inconsistent Generation: views created for invisible regions\noften lack coherence with both visible regions and each other, compromising\nreconstruction consistency. To address these challenges, we propose \\method, a\nnovel training-free approach that integrates the local dense observations and\nmulti-source priors for reconstruction. Our method introduces a fusion-based\nstrategy to effectively align these priors in DDIM sampling, thereby generating\nmulti-view consistent images to supervise invisible views. We further design an\niterative refinement strategy, which uses the geometric structures of the\nobject to enhance reconstruction quality. Extensive experiments on multiple\ndatasets show the superiority of our method over SOTAs, especially in invisible\nregions.", "AI": {"tldr": "A novel training-free method, \\method, addresses partial 3D reconstruction challenges by integrating dense observations and multi-source priors, ensuring multi-view consistency and improved quality in invisible regions.", "motivation": "Partial 3D reconstruction is underexplored, with challenges like limited view range and inconsistent generation in invisible regions.", "method": "Proposes \\method, a training-free approach using fusion-based alignment of priors in DDIM sampling and iterative refinement with geometric structures.", "result": "Outperforms state-of-the-art methods, especially in reconstructing invisible regions, as shown in extensive experiments.", "conclusion": "\\method effectively tackles partial 3D reconstruction challenges, offering superior performance and consistency."}}
{"id": "2505.23762", "pdf": "https://arxiv.org/pdf/2505.23762", "abs": "https://arxiv.org/abs/2505.23762", "authors": ["Chenyu Yang", "Shiqian Su", "Shi Liu", "Xuan Dong", "Yue Yu", "Weijie Su", "Xuehui Wang", "Zhaoyang Liu", "Jinguo Zhu", "Hao Li", "Wenhai Wang", "Yu Qiao", "Xizhou Zhu", "Jifeng Dai"], "title": "ZeroGUI: Automating Online GUI Learning at Zero Human Cost", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "The rapid advancement of large Vision-Language Models (VLMs) has propelled\nthe development of pure-vision-based GUI Agents, capable of perceiving and\noperating Graphical User Interfaces (GUI) to autonomously fulfill user\ninstructions. However, existing approaches usually adopt an offline learning\nframework, which faces two core limitations: (1) heavy reliance on high-quality\nmanual annotations for element grounding and action supervision, and (2)\nlimited adaptability to dynamic and interactive environments. To address these\nlimitations, we propose ZeroGUI, a scalable, online learning framework for\nautomating GUI Agent training at Zero human cost. Specifically, ZeroGUI\nintegrates (i) VLM-based automatic task generation to produce diverse training\ngoals from the current environment state, (ii) VLM-based automatic reward\nestimation to assess task success without hand-crafted evaluation functions,\nand (iii) two-stage online reinforcement learning to continuously interact with\nand learn from GUI environments. Experiments on two advanced GUI Agents\n(UI-TARS and Aguvis) demonstrate that ZeroGUI significantly boosts performance\nacross OSWorld and AndroidLab environments. The code is available at\nhttps://github.com/OpenGVLab/ZeroGUI.", "AI": {"tldr": "ZeroGUI is an online learning framework for GUI Agents that eliminates manual annotations and adapts to dynamic environments using VLM-based task generation, reward estimation, and reinforcement learning.", "motivation": "Existing GUI Agent approaches rely on offline learning with high-quality manual annotations and struggle with dynamic environments.", "method": "ZeroGUI integrates VLM-based task generation, reward estimation, and two-stage online reinforcement learning.", "result": "Experiments show ZeroGUI significantly improves performance in OSWorld and AndroidLab environments.", "conclusion": "ZeroGUI offers a scalable, zero-human-cost solution for training GUI Agents, addressing key limitations of existing methods."}}
{"id": "2505.22988", "pdf": "https://arxiv.org/pdf/2505.22988", "abs": "https://arxiv.org/abs/2505.22988", "authors": ["Albert Tseng", "Zhaofeng Sun", "Christopher De Sa"], "title": "Model-Preserving Adaptive Rounding", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "The main goal of post-training quantization (PTQ) is to produced a compressed\nmodel whose output distribution is as close to the original model's as\npossible. To do this tractably, almost all LLM PTQ algorithms quantize linear\nlayers by independently minimizing the immediate activation error. However,\nthis localized objective ignores the effect of subsequent layers, so reducing\nit does not necessarily give a closer model. In this work, we introduce Yet\nAnother Quantization Algorithm (YAQA), an adaptive rounding algorithm that uses\nKronecker-factored approximations of each linear layer's Hessian with respect\nto the \\textit{full model} KL divergence. YAQA consists of two components:\nKronecker-factored sketches of the full layerwise Hessian that can be tractably\ncomputed for hundred-billion parameter LLMs, and a quantizer-independent\nrounding algorithm that uses these sketches and comes with theoretical\nguarantees. Across a wide range of models and quantizers, YAQA empirically\nreduces the KL divergence to the original model by $\\approx 30\\%$ while\nachieving state of the art performance on downstream tasks.", "AI": {"tldr": "YAQA introduces an adaptive rounding algorithm for LLM PTQ, using Kronecker-factored Hessian approximations to minimize full-model KL divergence, outperforming localized methods.", "motivation": "Current PTQ methods focus on localized activation error, ignoring the impact of subsequent layers, leading to suboptimal model compression.", "method": "YAQA uses Kronecker-factored Hessian approximations and a quantizer-independent rounding algorithm to minimize full-model KL divergence.", "result": "YAQA reduces KL divergence by \u224830% and achieves state-of-the-art downstream task performance.", "conclusion": "YAQA provides a more effective PTQ approach by considering full-model effects, improving compression and task performance."}}
{"id": "2505.23030", "pdf": "https://arxiv.org/pdf/2505.23030", "abs": "https://arxiv.org/abs/2505.23030", "authors": ["Shruti Hegde", "Mabon Manoj Ninan", "Jonathan R. Dillman", "Shireen Hayatghaibi", "Lynn Babcock", "Elanchezhian Somasundaram"], "title": "Can Modern NLP Systems Reliably Annotate Chest Radiography Exams? A Pre-Purchase Evaluation and Comparative Study of Solutions from AWS, Google, Azure, John Snow Labs, and Open-Source Models on an Independent Pediatric Dataset", "categories": ["cs.CL"], "comment": null, "summary": "General-purpose clinical natural language processing (NLP) tools are\nincreasingly used for the automatic labeling of clinical reports. However,\nindependent evaluations for specific tasks, such as pediatric chest radiograph\n(CXR) report labeling, are limited. This study compares four commercial\nclinical NLP systems - Amazon Comprehend Medical (AWS), Google Healthcare NLP\n(GC), Azure Clinical NLP (AZ), and SparkNLP (SP) - for entity extraction and\nassertion detection in pediatric CXR reports. Additionally, CheXpert and\nCheXbert, two dedicated chest radiograph report labelers, were evaluated on the\nsame task using CheXpert-defined labels. We analyzed 95,008 pediatric CXR\nreports from a large academic pediatric hospital. Entities and assertion\nstatuses (positive, negative, uncertain) from the findings and impression\nsections were extracted by the NLP systems, with impression section entities\nmapped to 12 disease categories and a No Findings category. CheXpert and\nCheXbert extracted the same 13 categories. Outputs were compared using Fleiss\nKappa and accuracy against a consensus pseudo-ground truth. Significant\ndifferences were found in the number of extracted entities and assertion\ndistributions across NLP systems. SP extracted 49,688 unique entities, GC\n16,477, AZ 31,543, and AWS 27,216. Assertion accuracy across models averaged\naround 62%, with SP highest (76%) and AWS lowest (50%). CheXpert and CheXbert\nachieved 56% accuracy. Considerable variability in performance highlights the\nneed for careful validation and review before deploying NLP tools for clinical\nreport labeling.", "AI": {"tldr": "The study evaluates four commercial NLP systems and two dedicated tools for labeling pediatric CXR reports, finding significant variability in performance and accuracy.", "motivation": "To assess the effectiveness of general-purpose clinical NLP tools for specific tasks like pediatric CXR report labeling, given limited independent evaluations.", "method": "Compared four NLP systems (AWS, GC, AZ, SP) and two dedicated tools (CheXpert, CheXbert) on 95,008 pediatric CXR reports, analyzing entity extraction and assertion detection.", "result": "Significant differences in entity extraction and assertion accuracy (62% average, SP highest at 76%, AWS lowest at 50%). CheXpert and CheXbert achieved 56% accuracy.", "conclusion": "Variability in NLP tool performance underscores the need for validation before clinical deployment."}}
{"id": "2505.23068", "pdf": "https://arxiv.org/pdf/2505.23068", "abs": "https://arxiv.org/abs/2505.23068", "authors": ["Rui Xu", "Yuzhen Niu", "Yuezhou Li", "Huangbiao Xu", "Wenxi Liu", "Yuzhong Chen"], "title": "URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration", "categories": ["cs.CV"], "comment": "This paper has been accepted to CVPR 2025", "summary": "Existing low-light image enhancement (LLIE) and joint LLIE and deblurring\n(LLIE-deblur) models have made strides in addressing predefined degradations,\nyet they are often constrained by dynamically coupled degradations. To address\nthese challenges, we introduce a Unified Receptance Weighted Key Value (URWKV)\nmodel with multi-state perspective, enabling flexible and effective degradation\nrestoration for low-light images. Specifically, we customize the core URWKV\nblock to perceive and analyze complex degradations by leveraging multiple\nintra- and inter-stage states. First, inspired by the pupil mechanism in the\nhuman visual system, we propose Luminance-adaptive Normalization (LAN) that\nadjusts normalization parameters based on rich inter-stage states, allowing for\nadaptive, scene-aware luminance modulation. Second, we aggregate multiple\nintra-stage states through exponential moving average approach, effectively\ncapturing subtle variations while mitigating information loss inherent in the\nsingle-state mechanism. To reduce the degradation effects commonly associated\nwith conventional skip connections, we propose the State-aware Selective Fusion\n(SSF) module, which dynamically aligns and integrates multi-state features\nacross encoder stages, selectively fusing contextual information. In comparison\nto state-of-the-art models, our URWKV model achieves superior performance on\nvarious benchmarks, while requiring significantly fewer parameters and\ncomputational resources.", "AI": {"tldr": "The paper introduces a URWKV model for low-light image enhancement and deblurring, addressing dynamically coupled degradations with adaptive luminance modulation and multi-state feature fusion.", "motivation": "Existing models struggle with dynamically coupled degradations in low-light images, prompting the need for a more flexible and effective solution.", "method": "The URWKV model uses Luminance-adaptive Normalization (LAN) for adaptive luminance modulation and State-aware Selective Fusion (SSF) for multi-state feature integration.", "result": "The model outperforms state-of-the-art methods on benchmarks with fewer parameters and computational resources.", "conclusion": "The URWKV model effectively addresses complex degradations in low-light images, offering superior performance and efficiency."}}
{"id": "2505.22673", "pdf": "https://arxiv.org/pdf/2505.22673", "abs": "https://arxiv.org/abs/2505.22673", "authors": ["Wasif Khan", "Kyle B. See", "Simon Kato", "Ziqian Huang", "Amy Lazarte", "Kyle Douglas", "Xiangyang Lou", "Teng J. Peng", "Dhanashree Rajderkar", "John Rees", "Pina Sanelli", "Amita Singh", "Ibrahim Tuna", "Christina A. Wilson", "Ruogu Fang"], "title": "Physiology-Informed Generative Multi-Task Network for Contrast-Free CT Perfusion", "categories": ["q-bio.TO", "cs.AI", "cs.CV"], "comment": "Under Review", "summary": "Perfusion imaging is extensively utilized to assess hemodynamic status and\ntissue perfusion in various organs. Computed tomography perfusion (CTP) imaging\nplays a key role in the early assessment and planning of stroke treatment.\nWhile CTP provides essential perfusion parameters to identify abnormal blood\nflow in the brain, the use of contrast agents in CTP can lead to allergic\nreactions and adverse side effects, along with costing USD 4.9 billion\nworldwide in 2022. To address these challenges, we propose a novel deep\nlearning framework called Multitask Automated Generation of Intermodal CT\nperfusion maps (MAGIC). This framework combines generative artificial\nintelligence and physiological information to map non-contrast computed\ntomography (CT) imaging to multiple contrast-free CTP imaging maps. We\ndemonstrate enhanced image fidelity by incorporating physiological\ncharacteristics into the loss terms. Our network was trained and validated\nusing CT image data from patients referred for stroke at UF Health and\ndemonstrated robustness to abnormalities in brain perfusion activity. A\ndouble-blinded study was conducted involving seven experienced\nneuroradiologists and vascular neurologists. This study validated MAGIC's\nvisual quality and diagnostic accuracy showing favorable performance compared\nto clinical perfusion imaging with intravenous contrast injection. Overall,\nMAGIC holds great promise in revolutionizing healthcare by offering\ncontrast-free, cost-effective, and rapid perfusion imaging.", "AI": {"tldr": "A deep learning framework (MAGIC) generates contrast-free CT perfusion maps from non-contrast CT, addressing issues like cost and side effects of contrast agents.", "motivation": "Contrast agents in CTP imaging cause allergic reactions, side effects, and high costs, necessitating a safer, cost-effective alternative.", "method": "MAGIC combines generative AI and physiological data to map non-contrast CT to contrast-free CTP maps, enhancing fidelity with physiological loss terms.", "result": "MAGIC showed robust performance in generating perfusion maps and was validated by experts, matching clinical contrast-based imaging quality.", "conclusion": "MAGIC offers a promising contrast-free, cost-effective solution for perfusion imaging, potentially transforming stroke assessment."}}
{"id": "2505.22991", "pdf": "https://arxiv.org/pdf/2505.22991", "abs": "https://arxiv.org/abs/2505.22991", "authors": ["Behzad Kamgar-Parsi", "Behrooz Kamgar-Parsi"], "title": "Number of Clusters in a Dataset: A Regularized K-means Approach", "categories": ["cs.LG", "cs.CV", "68", "I.5.3"], "comment": "19 pages, 14 figures. arXiv admin note: substantial text overlap with\n  arXiv:1911.06741", "summary": "Finding the number of meaningful clusters in an unlabeled dataset is\nimportant in many applications. Regularized k-means algorithm is a possible\napproach frequently used to find the correct number of distinct clusters in\ndatasets. The most common formulation of the regularization function is the\nadditive linear term $\\lambda k$, where $k$ is the number of clusters and\n$\\lambda$ a positive coefficient. Currently, there are no principled guidelines\nfor setting a value for the critical hyperparameter $\\lambda$. In this paper,\nwe derive rigorous bounds for $\\lambda$ assuming clusters are {\\em ideal}.\nIdeal clusters (defined as $d$-dimensional spheres with identical radii) are\nclose proxies for k-means clusters ($d$-dimensional spherically symmetric\ndistributions with identical standard deviations). Experiments show that the\nk-means algorithm with additive regularizer often yields multiple solutions.\nThus, we also analyze k-means algorithm with multiplicative regularizer. The\nconsensus among k-means solutions with additive and multiplicative\nregularizations reduces the ambiguity of multiple solutions in certain cases.\nWe also present selected experiments that demonstrate performance of the\nregularized k-means algorithms as clusters deviate from the ideal assumption.", "AI": {"tldr": "The paper provides rigorous bounds for the hyperparameter \u03bb in regularized k-means clustering, assuming ideal clusters, and analyzes additive and multiplicative regularization to reduce solution ambiguity.", "motivation": "Determining the correct number of clusters in unlabeled datasets is crucial, but lacks principled guidelines for setting the regularization hyperparameter \u03bb.", "method": "Derives bounds for \u03bb under ideal cluster assumptions, compares additive and multiplicative regularization, and tests performance with non-ideal clusters.", "result": "Additive regularization often yields multiple solutions; multiplicative regularization and consensus between methods can reduce ambiguity.", "conclusion": "The study offers practical insights for setting \u03bb and improving cluster count accuracy, even when clusters deviate from ideal assumptions."}}
{"id": "2505.23035", "pdf": "https://arxiv.org/pdf/2505.23035", "abs": "https://arxiv.org/abs/2505.23035", "authors": ["Hyunwoo Kim", "Hanau Yi"], "title": "Machine-Facing English: Defining a Hybrid Register Shaped by Human-AI Discourse", "categories": ["cs.CL"], "comment": null, "summary": "Machine-Facing English (MFE) is an emergent register shaped by the adaptation\nof everyday language to the expanding presence of AI interlocutors. Drawing on\nregister theory (Halliday 1985, 2006), enregisterment (Agha 2003), audience\ndesign (Bell 1984), and interactional pragmatics (Giles & Ogay 2007), this\nstudy traces how sustained human-AI interaction normalizes syntactic rigidity,\npragmatic simplification, and hyper-explicit phrasing - features that enhance\nmachine parseability at the expense of natural fluency. Our analysis is\ngrounded in qualitative observations from bilingual (Korean/English) voice- and\ntext-based product testing sessions, with reflexive drafting conducted using\nNatural Language Declarative Prompting (NLD-P) under human curation. Thematic\nanalysis identifies five recurrent traits - redundant clarity, directive\nsyntax, controlled vocabulary, flattened prosody, and single-intent structuring\n- that improve execution accuracy but compress expressive range. MFE's\nevolution highlights a persistent tension between communicative efficiency and\nlinguistic richness, raising design challenges for conversational interfaces\nand pedagogical considerations for multilingual users. We conclude by\nunderscoring the need for comprehensive methodological exposition and future\nempirical validation.", "AI": {"tldr": "The paper explores Machine-Facing English (MFE), a language register adapted for AI interaction, highlighting its syntactic and pragmatic simplifications for machine parseability.", "motivation": "To understand how human-AI interaction shapes language, focusing on features that enhance machine understanding but reduce natural fluency.", "method": "Qualitative analysis of bilingual (Korean/English) voice and text interactions, using Natural Language Declarative Prompting (NLD-P) and thematic analysis.", "result": "Identified five traits (redundant clarity, directive syntax, controlled vocabulary, flattened prosody, single-intent structuring) that improve AI execution but limit expressiveness.", "conclusion": "MFE reveals a trade-off between efficiency and richness, posing challenges for conversational AI design and multilingual users, calling for further research."}}
{"id": "2505.23093", "pdf": "https://arxiv.org/pdf/2505.23093", "abs": "https://arxiv.org/abs/2505.23093", "authors": ["Mian Muhammad Naeem Abid", "Nancy Mehta", "Zongwei Wu", "Radu Timofte"], "title": "LeMoRe: Learn More Details for Lightweight Semantic Segmentation", "categories": ["cs.CV"], "comment": "Accepted at IEEE ICIP 2025", "summary": "Lightweight semantic segmentation is essential for many downstream vision\ntasks. Unfortunately, existing methods often struggle to balance efficiency and\nperformance due to the complexity of feature modeling. Many of these existing\napproaches are constrained by rigid architectures and implicit representation\nlearning, often characterized by parameter-heavy designs and a reliance on\ncomputationally intensive Vision Transformer-based frameworks. In this work, we\nintroduce an efficient paradigm by synergizing explicit and implicit modeling\nto balance computational efficiency with representational fidelity. Our method\ncombines well-defined Cartesian directions with explicitly modeled views and\nimplicitly inferred intermediate representations, efficiently capturing global\ndependencies through a nested attention mechanism. Extensive experiments on\nchallenging datasets, including ADE20K, CityScapes, Pascal Context, and\nCOCO-Stuff, demonstrate that LeMoRe strikes an effective balance between\nperformance and efficiency.", "AI": {"tldr": "The paper introduces LeMoRe, a lightweight semantic segmentation method balancing efficiency and performance by combining explicit and implicit modeling.", "motivation": "Existing methods struggle with balancing efficiency and performance due to rigid architectures and heavy reliance on Vision Transformers.", "method": "LeMoRe synergizes explicit (Cartesian directions, modeled views) and implicit (inferred representations) modeling with a nested attention mechanism.", "result": "Experiments on ADE20K, CityScapes, Pascal Context, and COCO-Stuff show LeMoRe achieves a good balance between performance and efficiency.", "conclusion": "LeMoRe effectively addresses the trade-off between computational efficiency and representational fidelity in semantic segmentation."}}
{"id": "2505.22674", "pdf": "https://arxiv.org/pdf/2505.22674", "abs": "https://arxiv.org/abs/2505.22674", "authors": ["Pawan Neupane", "Jian Liu", "Jianlin Cheng"], "title": "PSBench: a large-scale benchmark for estimating the accuracy of protein complex structural models", "categories": ["q-bio.BM", "cs.AI", "cs.LG"], "comment": null, "summary": "Predicting protein complex structures is essential for protein function\nanalysis, protein design, and drug discovery. While AI methods like AlphaFold\ncan predict accurate structural models for many protein complexes, reliably\nestimating the quality of these predicted models (estimation of model accuracy,\nor EMA) for model ranking and selection remains a major challenge. A key\nbarrier to developing effective machine learning-based EMA methods is the lack\nof large, diverse, and well-annotated datasets for training and evaluation. To\naddress this gap, we introduce PSBench, a benchmark suite comprising four\nlarge-scale, labeled datasets generated during the 15th and 16th community-wide\nCritical Assessment of Protein Structure Prediction (CASP15 and CASP16).\nPSBench includes over one million structural models covering a wide range of\nprotein sequence lengths, complex stoichiometries, functional classes, and\nmodeling difficulties. Each model is annotated with multiple complementary\nquality scores at the global, local, and interface levels. PSBench also\nprovides multiple evaluation metrics and baseline EMA methods to facilitate\nrigorous comparisons. To demonstrate PSBench's utility, we trained and\nevaluated GATE, a graph transformer-based EMA method, on the CASP15 data. GATE\nwas blindly tested in CASP16 (2024), where it ranked among the top-performing\nEMA methods. These results highlight PSBench as a valuable resource for\nadvancing EMA research in protein complex modeling. PSBench is publicly\navailable at: https://github.com/BioinfoMachineLearning/PSBench.", "AI": {"tldr": "PSBench is a benchmark suite for evaluating protein complex model accuracy, addressing the lack of diverse datasets. It includes over one million annotated models and supports EMA method development, demonstrated by the success of GATE in CASP16.", "motivation": "Predicting protein complex structures is crucial for function analysis and drug discovery, but reliable model quality estimation (EMA) lacks large, diverse datasets.", "method": "PSBench provides four large-scale, labeled datasets from CASP15 and CASP16, annotated with quality scores. It includes evaluation metrics and baseline EMA methods.", "result": "GATE, a graph transformer-based EMA method trained on PSBench, ranked among the top in CASP16.", "conclusion": "PSBench is a valuable resource for advancing EMA research in protein complex modeling, publicly available for use."}}
{"id": "2505.22994", "pdf": "https://arxiv.org/pdf/2505.22994", "abs": "https://arxiv.org/abs/2505.22994", "authors": ["Ari S. Benjamin", "Kyle Daruwalla", "Christian Pehle", "Anthony M. Zador"], "title": "Walking the Weight Manifold: a Topological Approach to Conditioning Inspired by Neuromodulation", "categories": ["cs.LG", "cs.NE"], "comment": "17 pages, 4 figures", "summary": "One frequently wishes to learn a range of similar tasks as efficiently as\npossible, re-using knowledge across tasks. In artificial neural networks, this\nis typically accomplished by conditioning a network upon task context by\ninjecting context as input. Brains have a different strategy: the parameters\nthemselves are modulated as a function of various neuromodulators such as\nserotonin. Here, we take inspiration from neuromodulation and propose to learn\nweights which are smoothly parameterized functions of task context variables.\nRather than optimize a weight vector, i.e. a single point in weight space, we\noptimize a smooth manifold in weight space with a predefined topology. To\naccomplish this, we derive a formal treatment of optimization of manifolds as\nthe minimization of a loss functional subject to a constraint on volumetric\nmovement, analogous to gradient descent. During inference, conditioning selects\na single point on this manifold which serves as the effective weight matrix for\na particular sub-task. This strategy for conditioning has two main advantages.\nFirst, the topology of the manifold (whether a line, circle, or torus) is a\nconvenient lever for inductive biases about the relationship between tasks.\nSecond, learning in one state smoothly affects the entire manifold, encouraging\ngeneralization across states. To verify this, we train manifolds with several\ntopologies, including straight lines in weight space (for conditioning on e.g.\nnoise level in input data) and ellipses (for rotated images). Despite their\nsimplicity, these parameterizations outperform conditioning identical networks\nby input concatenation and better generalize to out-of-distribution samples.\nThese results suggest that modulating weights over low-dimensional manifolds\noffers a principled and effective alternative to traditional conditioning.", "AI": {"tldr": "The paper proposes learning weight manifolds in neural networks, inspired by neuromodulation, to efficiently generalize across tasks by conditioning on context variables.", "motivation": "To improve task efficiency and knowledge reuse in neural networks by mimicking biological neuromodulation, where parameters are modulated by context rather than input injection.", "method": "Derives a formal optimization of smooth manifolds in weight space, minimizing loss with constraints on volumetric movement. Manifolds (e.g., lines, circles) are predefined for inductive biases.", "result": "Manifold-based conditioning outperforms input concatenation, generalizing better to out-of-distribution samples.", "conclusion": "Modulating weights over low-dimensional manifolds is a principled and effective alternative to traditional conditioning methods."}}
{"id": "2505.23037", "pdf": "https://arxiv.org/pdf/2505.23037", "abs": "https://arxiv.org/abs/2505.23037", "authors": ["Longyin Zhang", "Bowei Zou", "Ai Ti Aw"], "title": "Improving Multilingual Social Media Insights: Aspect-based Comment Analysis", "categories": ["cs.CL"], "comment": "The paper was peer-reviewed", "summary": "The inherent nature of social media posts, characterized by the freedom of\nlanguage use with a disjointed array of diverse opinions and topics, poses\nsignificant challenges to downstream NLP tasks such as comment clustering,\ncomment summarization, and social media opinion analysis. To address this, we\npropose a granular level of identifying and generating aspect terms from\nindividual comments to guide model attention. Specifically, we leverage\nmultilingual large language models with supervised fine-tuning for comment\naspect term generation (CAT-G), further aligning the model's predictions with\nhuman expectations through DPO. We demonstrate the effectiveness of our method\nin enhancing the comprehension of social media discourse on two NLP tasks.\nMoreover, this paper contributes the first multilingual CAT-G test set on\nEnglish, Chinese, Malay, and Bahasa Indonesian. As LLM capabilities vary among\nlanguages, this test set allows for a comparative analysis of performance\nacross languages with varying levels of LLM proficiency.", "AI": {"tldr": "The paper proposes a method (CAT-G) using multilingual LLMs to generate aspect terms from social media comments, improving NLP tasks like clustering and summarization. It also introduces a multilingual test set for comparative analysis.", "motivation": "Social media posts' unstructured and diverse nature complicates NLP tasks. The paper aims to enhance comprehension by focusing on aspect terms.", "method": "Uses multilingual LLMs with supervised fine-tuning for aspect term generation (CAT-G) and aligns predictions with human expectations via DPO.", "result": "The method improves social media discourse comprehension in NLP tasks and introduces a multilingual test set for performance comparison.", "conclusion": "CAT-G effectively addresses challenges in social media NLP tasks and provides a multilingual benchmark for future research."}}
{"id": "2505.23102", "pdf": "https://arxiv.org/pdf/2505.23102", "abs": "https://arxiv.org/abs/2505.23102", "authors": ["Yuka Ogino", "Takahiro Toizumi", "Atsushi Ito"], "title": "CURVE: CLIP-Utilized Reinforcement Learning for Visual Image Enhancement via Simple Image Processing", "categories": ["cs.CV"], "comment": "Accepted to ICIP2025", "summary": "Low-Light Image Enhancement (LLIE) is crucial for improving both human\nperception and computer vision tasks. This paper addresses two challenges in\nzero-reference LLIE: obtaining perceptually 'good' images using the Contrastive\nLanguage-Image Pre-Training (CLIP) model and maintaining computational\nefficiency for high-resolution images. We propose CLIP-Utilized Reinforcement\nlearning-based Visual image Enhancement (CURVE). CURVE employs a simple image\nprocessing module which adjusts global image tone based on B\\'ezier curve and\nestimates its processing parameters iteratively. The estimator is trained by\nreinforcement learning with rewards designed using CLIP text embeddings.\nExperiments on low-light and multi-exposure datasets demonstrate the\nperformance of CURVE in terms of enhancement quality and processing speed\ncompared to conventional methods.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.22683", "pdf": "https://arxiv.org/pdf/2505.22683", "abs": "https://arxiv.org/abs/2505.22683", "authors": ["Xuhang Chen", "Michael Kwok-Po Ng", "Kim-Fung Tsang", "Chi-Man Pun", "Shuqiang Wang"], "title": "ConnectomeDiffuser: Generative AI Enables Brain Network Construction from Diffusion Tensor Imaging", "categories": ["q-bio.NC", "cs.AI", "cs.CV"], "comment": null, "summary": "Brain network analysis plays a crucial role in diagnosing and monitoring\nneurodegenerative disorders such as Alzheimer's disease (AD). Existing\napproaches for constructing structural brain networks from diffusion tensor\nimaging (DTI) often rely on specialized toolkits that suffer from inherent\nlimitations: operator subjectivity, labor-intensive workflows, and restricted\ncapacity to capture complex topological features and disease-specific\nbiomarkers. To overcome these challenges and advance computational neuroimaging\ninstrumentation, ConnectomeDiffuser is proposed as a novel diffusion-based\nframework for automated end-to-end brain network construction from DTI. The\nproposed model combines three key components: (1) a Template Network that\nextracts topological features from 3D DTI scans using Riemannian geometric\nprinciples, (2) a diffusion model that generates comprehensive brain networks\nwith enhanced topological fidelity, and (3) a Graph Convolutional Network\nclassifier that incorporates disease-specific markers to improve diagnostic\naccuracy. ConnectomeDiffuser demonstrates superior performance by capturing a\nbroader range of structural connectivity and pathology-related information,\nenabling more sensitive analysis of individual variations in brain networks.\nExperimental validation on datasets representing two distinct neurodegenerative\nconditions demonstrates significant performance improvements over other brain\nnetwork methods. This work contributes to the advancement of instrumentation in\nthe context of neurological disorders, providing clinicians and researchers\nwith a robust, generalizable measurement framework that facilitates more\naccurate diagnosis, deeper mechanistic understanding, and improved therapeutic\nmonitoring of neurodegenerative diseases such as AD.", "AI": {"tldr": "ConnectomeDiffuser is a novel diffusion-based framework for automated brain network construction from DTI, overcoming limitations of existing methods by combining topological feature extraction, diffusion modeling, and disease-specific classification.", "motivation": "Existing methods for brain network analysis from DTI are limited by subjectivity, labor-intensiveness, and inability to capture complex topological and disease-specific features, hindering accurate diagnosis of neurodegenerative disorders like Alzheimer's disease.", "method": "ConnectomeDiffuser integrates a Template Network for topological feature extraction, a diffusion model for enhanced network generation, and a Graph Convolutional Network classifier for disease-specific analysis.", "result": "The framework outperforms existing methods, capturing broader structural connectivity and pathology-related information, validated on datasets for neurodegenerative conditions.", "conclusion": "ConnectomeDiffuser advances computational neuroimaging, offering a robust, generalizable tool for improved diagnosis and monitoring of neurodegenerative diseases."}}
{"id": "2505.22998", "pdf": "https://arxiv.org/pdf/2505.22998", "abs": "https://arxiv.org/abs/2505.22998", "authors": ["Jihwan Oh", "Murad Aghazada", "Se-Young Yun", "Taehyeon Kim"], "title": "LLM Agents for Bargaining with Utility-based Feedback", "categories": ["cs.LG"], "comment": "Preprint", "summary": "Bargaining, a critical aspect of real-world interactions, presents challenges\nfor large language models (LLMs) due to limitations in strategic depth and\nadaptation to complex human factors. Existing benchmarks often fail to capture\nthis real-world complexity. To address this and enhance LLM capabilities in\nrealistic bargaining, we introduce a comprehensive framework centered on\nutility-based feedback. Our contributions are threefold: (1) BargainArena, a\nnovel benchmark dataset with six intricate scenarios (e.g., deceptive\npractices, monopolies) to facilitate diverse strategy modeling; (2)\nhuman-aligned, economically-grounded evaluation metrics inspired by utility\ntheory, incorporating agent utility and negotiation power, which implicitly\nreflect and promote opponent-aware reasoning (OAR); and (3) a structured\nfeedback mechanism enabling LLMs to iteratively refine their bargaining\nstrategies. This mechanism can positively collaborate with in-context learning\n(ICL) prompts, including those explicitly designed to foster OAR. Experimental\nresults show that LLMs often exhibit negotiation strategies misaligned with\nhuman preferences, and that our structured feedback mechanism significantly\nimproves their performance, yielding deeper strategic and opponent-aware\nreasoning.", "AI": {"tldr": "The paper introduces a framework to improve LLMs' bargaining skills using utility-based feedback, a new benchmark (BargainArena), and human-aligned metrics.", "motivation": "Addressing LLMs' limitations in strategic depth and adaptation to complex human factors in bargaining.", "method": "Developed BargainArena benchmark, utility-based metrics, and a structured feedback mechanism for iterative strategy refinement.", "result": "LLMs often misalign with human preferences, but the feedback mechanism improves performance and strategic reasoning.", "conclusion": "The framework enhances LLMs' bargaining capabilities, promoting opponent-aware reasoning and strategic depth."}}
{"id": "2505.23038", "pdf": "https://arxiv.org/pdf/2505.23038", "abs": "https://arxiv.org/abs/2505.23038", "authors": ["Yuzhen Xiao", "Jiahe Song", "Yongxin Xu", "Ruizhe Zhang", "Yiqi Xiao", "Xin Lu", "Runchuan Zhu", "Bowen Jiang", "Junfeng Zhao"], "title": "EL4NER: Ensemble Learning for Named Entity Recognition via Multiple Small-Parameter Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "In-Context Learning (ICL) technique based on Large Language Models (LLMs) has\ngained prominence in Named Entity Recognition (NER) tasks for its lower\ncomputing resource consumption, less manual labeling overhead, and stronger\ngeneralizability. Nevertheless, most ICL-based NER methods depend on\nlarge-parameter LLMs: the open-source models demand substantial computational\nresources for deployment and inference, while the closed-source ones incur high\nAPI costs, raise data-privacy concerns, and hinder community collaboration. To\naddress this question, we propose an Ensemble Learning Method for Named Entity\nRecognition (EL4NER), which aims at aggregating the ICL outputs of multiple\nopen-source, small-parameter LLMs to enhance overall performance in NER tasks\nat less deployment and inference cost. Specifically, our method comprises three\nkey components. First, we design a task decomposition-based pipeline that\nfacilitates deep, multi-stage ensemble learning. Second, we introduce a novel\nspan-level sentence similarity algorithm to establish an ICL demonstration\nretrieval mechanism better suited for NER tasks. Third, we incorporate a\nself-validation mechanism to mitigate the noise introduced during the ensemble\nprocess. We evaluated EL4NER on multiple widely adopted NER datasets from\ndiverse domains. Our experimental results indicate that EL4NER surpasses most\nclosed-source, large-parameter LLM-based methods at a lower parameter cost and\neven attains state-of-the-art (SOTA) performance among ICL-based methods on\ncertain datasets. These results show the parameter efficiency of EL4NER and\nunderscore the feasibility of employing open-source, small-parameter LLMs\nwithin the ICL paradigm for NER tasks.", "AI": {"tldr": "EL4NER is an ensemble learning method for NER tasks that aggregates outputs of small-parameter LLMs, reducing costs and improving performance compared to large-parameter LLMs.", "motivation": "Address the high computational and API costs, data-privacy concerns, and limited collaboration in ICL-based NER methods relying on large-parameter LLMs.", "method": "EL4NER uses a task decomposition pipeline, span-level sentence similarity for ICL demonstration retrieval, and a self-validation mechanism to reduce noise.", "result": "EL4NER outperforms large-parameter LLM methods at lower cost and achieves SOTA performance on some datasets.", "conclusion": "EL4NER demonstrates the feasibility of using small-parameter LLMs in ICL for NER tasks, offering parameter efficiency and cost-effectiveness."}}
{"id": "2505.23107", "pdf": "https://arxiv.org/pdf/2505.23107", "abs": "https://arxiv.org/abs/2505.23107", "authors": ["Pushapdeep Singh", "Jyoti Nigam", "Medicherla Vamsi Krishna", "Arnav Bhavsar", "Aditya Nigam"], "title": "EAD: An EEG Adapter for Automated Classification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "While electroencephalography (EEG) has been a popular modality for neural\ndecoding, it often involves task specific acquisition of the EEG data. This\nposes challenges for the development of a unified pipeline to learn embeddings\nfor various EEG signal classification, which is often involved in various\ndecoding tasks. Traditionally, EEG classification involves the step of signal\npreprocessing and the use of deep learning techniques, which are highly\ndependent on the number of EEG channels in each sample. However, the same\npipeline cannot be applied even if the EEG data is collected for the same\nexperiment but with different acquisition devices. This necessitates the\ndevelopment of a framework for learning EEG embeddings, which could be highly\nbeneficial for tasks involving multiple EEG samples for the same task but with\nvarying numbers of EEG channels. In this work, we propose EEG Adapter (EAD), a\nflexible framework compatible with any signal acquisition device. More\nspecifically, we leverage a recent EEG foundational model with significant\nadaptations to learn robust representations from the EEG data for the\nclassification task. We evaluate EAD on two publicly available datasets\nachieving state-of-the-art accuracies 99.33% and 92.31% on EEG-ImageNet and\nBrainLat respectively. This illustrates the effectiveness of the proposed\nframework across diverse EEG datasets containing two different perception\ntasks: stimulus and resting-state EEG signals. We also perform zero-shot EEG\nclassification on EEG-ImageNet task to demonstrate the generalization\ncapability of the proposed approach.", "AI": {"tldr": "Proposes EEG Adapter (EAD), a flexible framework for EEG signal classification, achieving high accuracy across diverse datasets and demonstrating zero-shot generalization.", "motivation": "Addresses challenges in EEG decoding due to task-specific data acquisition and device variability, aiming for a unified pipeline.", "method": "Leverages an EEG foundational model with adaptations to learn robust representations, evaluated on EEG-ImageNet and BrainLat datasets.", "result": "Achieves state-of-the-art accuracies of 99.33% and 92.31% on EEG-ImageNet and BrainLat, respectively, and demonstrates zero-shot classification.", "conclusion": "EAD is effective for diverse EEG tasks, offering flexibility and generalization across datasets and devices."}}
{"id": "2505.22749", "pdf": "https://arxiv.org/pdf/2505.22749", "abs": "https://arxiv.org/abs/2505.22749", "authors": ["Tamas Spisak", "Karl Friston"], "title": "Self-orthogonalizing attractor neural networks emerging from the free energy principle", "categories": ["q-bio.NC", "cs.AI", "cs.LG", "cs.NE"], "comment": "22 pages main text, 5 pages appendix, 6 figures; interactive\n  manuscript available at: https://pni-lab.github.io/fep-attractor-network\n  Associated GitHub repository:\n  https://github.com/pni-lab/fep-attractor-network", "summary": "Attractor dynamics are a hallmark of many complex systems, including the\nbrain. Understanding how such self-organizing dynamics emerge from first\nprinciples is crucial for advancing our understanding of neuronal computations\nand the design of artificial intelligence systems. Here we formalize how\nattractor networks emerge from the free energy principle applied to a universal\npartitioning of random dynamical systems. Our approach obviates the need for\nexplicitly imposed learning and inference rules and identifies emergent, but\nefficient and biologically plausible inference and learning dynamics for such\nself-organizing systems. These result in a collective, multi-level Bayesian\nactive inference process. Attractors on the free energy landscape encode prior\nbeliefs; inference integrates sensory data into posterior beliefs; and learning\nfine-tunes couplings to minimize long-term surprise. Analytically and via\nsimulations, we establish that the proposed networks favor approximately\northogonalized attractor representations, a consequence of simultaneously\noptimizing predictive accuracy and model complexity. These attractors\nefficiently span the input subspace, enhancing generalization and the mutual\ninformation between hidden causes and observable effects. Furthermore, while\nrandom data presentation leads to symmetric and sparse couplings, sequential\ndata fosters asymmetric couplings and non-equilibrium steady-state dynamics,\noffering a natural extension to conventional Boltzmann Machines. Our findings\noffer a unifying theory of self-organizing attractor networks, providing novel\ninsights for AI and neuroscience.", "AI": {"tldr": "The paper formalizes how attractor networks emerge from the free energy principle in random dynamical systems, enabling efficient, biologically plausible inference and learning without explicit rules.", "motivation": "To understand self-organizing dynamics in complex systems like the brain and AI, advancing neuronal computation and AI design.", "method": "Applies the free energy principle to random dynamical systems, analyzing emergent inference and learning dynamics.", "result": "Attractor networks optimize predictive accuracy and model complexity, favoring orthogonalized representations and efficient input subspace spanning.", "conclusion": "Provides a unifying theory for self-organizing attractor networks, with implications for AI and neuroscience."}}
{"id": "2505.23003", "pdf": "https://arxiv.org/pdf/2505.23003", "abs": "https://arxiv.org/abs/2505.23003", "authors": ["Linh Le Pham Van", "Minh Hoang Nguyen", "Hung Le", "Hung The Tran", "Sunil Gupta"], "title": "Hybrid Cross-domain Robust Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ECML PKDD 2025", "summary": "Robust reinforcement learning (RL) aims to learn policies that remain\neffective despite uncertainties in its environment, which frequently arise in\nreal-world applications due to variations in environment dynamics. The robust\nRL methods learn a robust policy by maximizing value under the worst-case\nmodels within a predefined uncertainty set. Offline robust RL algorithms are\nparticularly promising in scenarios where only a fixed dataset is available and\nnew data cannot be collected. However, these approaches often require extensive\noffline data, and gathering such datasets for specific tasks in specific\nenvironments can be both costly and time-consuming. Using an imperfect\nsimulator offers a faster, cheaper, and safer way to collect data for training,\nbut it can suffer from dynamics mismatch. In this paper, we introduce HYDRO,\nthe first Hybrid Cross-Domain Robust RL framework designed to address these\nchallenges. HYDRO utilizes an online simulator to complement the limited amount\nof offline datasets in the non-trivial context of robust RL. By measuring and\nminimizing performance gaps between the simulator and the worst-case models in\nthe uncertainty set, HYDRO employs novel uncertainty filtering and prioritized\nsampling to select the most relevant and reliable simulator samples. Our\nextensive experiments demonstrate HYDRO's superior performance over existing\nmethods across various tasks, underscoring its potential to improve sample\nefficiency in offline robust RL.", "AI": {"tldr": "HYDRO is a hybrid robust RL framework combining offline data and online simulator to improve sample efficiency by minimizing performance gaps and using novel sampling techniques.", "motivation": "Address the challenges of offline robust RL, such as limited data and dynamics mismatch, by leveraging an online simulator to complement offline datasets.", "method": "HYDRO measures and minimizes performance gaps between the simulator and worst-case models, using uncertainty filtering and prioritized sampling to select reliable simulator samples.", "result": "HYDRO outperforms existing methods in various tasks, demonstrating improved sample efficiency.", "conclusion": "HYDRO effectively bridges the gap between offline and online data, enhancing robust RL performance with limited datasets."}}
{"id": "2505.23052", "pdf": "https://arxiv.org/pdf/2505.23052", "abs": "https://arxiv.org/abs/2505.23052", "authors": ["Jiarui Zhang", "Xiangyu Liu", "Yong Hu", "Chaoyue Niu", "Fan Wu", "Guihai Chen"], "title": "Query Routing for Retrieval-Augmented Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) significantly improves the performance\nof Large Language Models (LLMs) on knowledge-intensive tasks. However, varying\nresponse quality across LLMs under RAG necessitates intelligent routing\nmechanisms, which select the most suitable model for each query from multiple\nretrieval-augmented LLMs via a dedicated router model. We observe that external\ndocuments dynamically affect LLMs' ability to answer queries, while existing\nrouting methods, which rely on static parametric knowledge representations,\nexhibit suboptimal performance in RAG scenarios. To address this, we formally\ndefine the new retrieval-augmented LLM routing problem, incorporating the\ninfluence of retrieved documents into the routing framework. We propose\nRAGRouter, a RAG-aware routing design, which leverages document embeddings and\nRAG capability embeddings with contrastive learning to capture knowledge\nrepresentation shifts and enable informed routing decisions. Extensive\nexperiments on diverse knowledge-intensive tasks and retrieval settings show\nthat RAGRouter outperforms the best individual LLM by 3.61% on average and\nexisting routing methods by 3.29%-9.33%. With an extended score-threshold-based\nmechanism, it also achieves strong performance-efficiency trade-offs under\nlow-latency constraints.", "AI": {"tldr": "RAGRouter improves LLM routing in RAG scenarios by dynamically incorporating document influence, outperforming existing methods by 3.29%-9.33%.", "motivation": "Existing routing methods for retrieval-augmented LLMs rely on static knowledge representations, leading to suboptimal performance due to dynamic document influence.", "method": "Proposes RAGRouter, which uses document embeddings and RAG capability embeddings with contrastive learning to capture knowledge shifts for informed routing.", "result": "RAGRouter outperforms the best individual LLM by 3.61% on average and existing routing methods by 3.29%-9.33%.", "conclusion": "RAGRouter effectively addresses the retrieval-augmented LLM routing problem, achieving strong performance-efficiency trade-offs."}}
{"id": "2505.23109", "pdf": "https://arxiv.org/pdf/2505.23109", "abs": "https://arxiv.org/abs/2505.23109", "authors": ["Anusha A. S.", "Uma Ranjan", "Medha Sharma", "Siddharth Dutt"], "title": "Identification of Patterns of Cognitive Impairment for Early Detection of Dementia", "categories": ["cs.CV"], "comment": "4 pages, 2 figures, to be published in IEEE EMBC 2020", "summary": "Early detection of dementia is crucial to devise effective interventions.\nComprehensive cognitive tests, while being the most accurate means of\ndiagnosis, are long and tedious, thus limiting their applicability to a large\npopulation, especially when periodic assessments are needed. The problem is\ncompounded by the fact that people have differing patterns of cognitive\nimpairment as they progress to different forms of dementia. This paper presents\na novel scheme by which individual-specific patterns of impairment can be\nidentified and used to devise personalized tests for periodic follow-up.\nPatterns of cognitive impairment are initially learned from a population\ncluster of combined normals and MCIs, using a set of standardized cognitive\ntests. Impairment patterns in the population are identified using a 2-step\nprocedure involving an ensemble wrapper feature selection followed by cluster\nidentification and analysis. These patterns have been shown to correspond to\nclinically accepted variants of MCI, a prodrome of dementia. The learned\nclusters of patterns can subsequently be used to identify the most likely route\nof cognitive impairment, even for pre-symptomatic and apparently normal people.\nBaseline data of 24,000 subjects from the NACC database was used for the study.", "AI": {"tldr": "A novel scheme for personalized dementia detection identifies individual-specific cognitive impairment patterns using population data, enabling tailored follow-up tests.", "motivation": "Early dementia detection is vital, but current cognitive tests are lengthy and impractical for large-scale periodic use. Personalized approaches are needed due to varying impairment patterns.", "method": "A 2-step procedure: ensemble wrapper feature selection followed by cluster analysis identifies cognitive impairment patterns in a population (24,000 subjects from NACC). These patterns guide personalized tests.", "result": "Identified patterns align with clinical MCI variants, allowing prediction of cognitive impairment routes even in pre-symptomatic individuals.", "conclusion": "The method offers scalable, personalized dementia detection, improving early intervention feasibility."}}
{"id": "2505.22761", "pdf": "https://arxiv.org/pdf/2505.22761", "abs": "https://arxiv.org/abs/2505.22761", "authors": ["Afila Ajithkumar Sophiya", "Akarsh K Nair", "Sepehr Maleki", "Senthil K. Krishnababu"], "title": "A comprehensive analysis of PINNs: Variants, Applications, and Challenges", "categories": ["cs.CE", "cs.AI"], "comment": null, "summary": "Physics Informed Neural Networks (PINNs) have been emerging as a powerful\ncomputational tool for solving differential equations. However, the\napplicability of these models is still in its initial stages and requires more\nstandardization to gain wider popularity. Through this survey, we present a\ncomprehensive overview of PINNs approaches exploring various aspects related to\ntheir architecture, variants, areas of application, real-world use cases,\nchallenges, and so on. Even though existing surveys can be identified, they\nfail to provide a comprehensive view as they primarily focus on either\ndifferent application scenarios or limit their study to a superficial level.\nThis survey attempts to bridge the gap in the existing literature by presenting\na detailed analysis of all these factors combined with recent advancements and\nstate-of-the-art research in PINNs. Additionally, we discuss prevalent\nchallenges in PINNs implementation and present some of the future research\ndirections as well. The overall contributions of the survey can be summarised\ninto three sections: A detailed overview of PINNs architecture and variants, a\nperformance analysis of PINNs on different equations and application domains\nhighlighting their features. Finally, we present a detailed discussion of\ncurrent issues and future research directions.", "AI": {"tldr": "A survey on Physics Informed Neural Networks (PINNs) providing a detailed overview of their architecture, variants, applications, challenges, and future directions.", "motivation": "To address the lack of comprehensive surveys on PINNs, which often focus narrowly on applications or superficial analysis.", "method": "The survey reviews PINNs' architecture, variants, real-world use cases, and performance across different equations and domains.", "result": "A detailed analysis of PINNs, highlighting their features, challenges, and recent advancements.", "conclusion": "The survey bridges gaps in existing literature and outlines future research directions for PINNs."}}
{"id": "2505.23004", "pdf": "https://arxiv.org/pdf/2505.23004", "abs": "https://arxiv.org/abs/2505.23004", "authors": ["Kyle R. Chickering", "Bangzheng Li", "Muhao Chen"], "title": "QLIP: A Dynamic Quadtree Vision Prior Enhances MLLM Performance Without Retraining", "categories": ["cs.LG"], "comment": "22 pages, 19 figures", "summary": "Multimodal Large Language Models (MLLMs) encode images into visual tokens,\naligning visual and textual signals within a shared latent space to facilitate\ncrossmodal representation learning. The CLIP model is a widely adopted\nfoundational vision language model whose vision encoder has played a critical\nrole in the development of MLLMs such as LLaVA. However, the CLIP vision\nencoder suffers from notable limitations including being constrained to only\nhandling fixed input resolutions and a failure to produce separated embeddings\nfor dissimilar images. Replacing the vision encoder of an existing model\ntypically incurs substantial computational costs because such a change often\nnecessitates retraining the entire model pipeline.\n  In this work, we identify two factors which underlie the limitations of the\nCLIP vision encoder: mesoscopic bias and interpolation bias. To address these\nissues, we propose QLIP, a drop-in replacement for CLIP that can be seamlessly\nintegrated with existing MLLMs with only a few lines of code and can enhance\nboth coarse-grained and fine-grained visual understanding, without re-training.\nQLIP is designed around an image quadtree which replaces the standard uniform\ngrid patches with a novel content aware patchification. Our experimental\nresults demonstrate that QLIP improves the general visual question answering\naccuracy of the LLaVA v1.5 model series across various model sizes--without\nrequiring retraining or fine-tuning of the full MLLM. Notably, QLIP boosts\ndetailed understanding performance on the challenging $V^{\\ast}$ benchmark by\nup to 13.6 percent.", "AI": {"tldr": "QLIP is a drop-in replacement for CLIP in MLLMs, addressing its limitations (mesoscopic and interpolation biases) without requiring retraining. It improves visual understanding and boosts performance on benchmarks like V*.", "motivation": "CLIP's vision encoder has limitations (fixed input resolution, poor dissimilar image embeddings) and replacing it is costly. QLIP aims to solve these issues efficiently.", "method": "QLIP uses an image quadtree for content-aware patchification, replacing CLIP's uniform grid patches. It integrates seamlessly with existing MLLMs like LLaVA.", "result": "QLIP enhances LLaVA's visual question answering accuracy across model sizes and improves detailed understanding on the V* benchmark by up to 13.6%.", "conclusion": "QLIP is an efficient, plug-and-play solution to CLIP's limitations, improving MLLM performance without retraining."}}
{"id": "2505.23060", "pdf": "https://arxiv.org/pdf/2505.23060", "abs": "https://arxiv.org/abs/2505.23060", "authors": ["Jeonghun Cho", "Deokhyung Kang", "Hyounghun Kim", "Gary Geunbae Lee"], "title": "Self-Correcting Code Generation Using Small Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Self-correction has demonstrated potential in code generation by allowing\nlanguage models to revise and improve their outputs through successive\nrefinement. Recent studies have explored prompting-based strategies that\nincorporate verification or feedback loops using proprietary models, as well as\ntraining-based methods that leverage their strong reasoning capabilities.\nHowever, whether smaller models possess the capacity to effectively guide their\noutputs through self-reflection remains unexplored. Our findings reveal that\nsmaller models struggle to exhibit reflective revision behavior across both\nself-correction paradigms. In response, we introduce CoCoS, an approach\ndesigned to enhance the ability of small language models for multi-turn code\ncorrection. Specifically, we propose an online reinforcement learning objective\nthat trains the model to confidently maintain correct outputs while\nprogressively correcting incorrect outputs as turns proceed. Our approach\nfeatures an accumulated reward function that aggregates rewards across the\nentire trajectory and a fine-grained reward better suited to multi-turn\ncorrection scenarios. This facilitates the model in enhancing initial response\nquality while achieving substantial improvements through self-correction. With\n1B-scale models, CoCoS achieves improvements of 35.8% on the MBPP and 27.7% on\nHumanEval compared to the baselines.", "AI": {"tldr": "Smaller models struggle with self-correction in code generation. CoCoS, a reinforcement learning approach, improves their multi-turn correction ability, achieving significant gains on benchmarks.", "motivation": "Exploring whether smaller models can effectively self-correct code outputs, given their limited capacity compared to larger models.", "method": "Introduces CoCoS, an online reinforcement learning approach with an accumulated reward function and fine-grained rewards for multi-turn correction.", "result": "CoCoS improves performance by 35.8% on MBPP and 27.7% on HumanEval with 1B-scale models.", "conclusion": "CoCoS enhances smaller models' self-correction capabilities, demonstrating its effectiveness in code generation tasks."}}
{"id": "2505.23115", "pdf": "https://arxiv.org/pdf/2505.23115", "abs": "https://arxiv.org/abs/2505.23115", "authors": ["Yunshen Wang", "Yicheng Liu", "Tianyuan Yuan", "Yucheng Mao", "Yingshi Liang", "Xiuyu Yang", "Honggang Zhang", "Hang Zhao"], "title": "Diffusion-Based Generative Models for 3D Occupancy Prediction in Autonomous Driving", "categories": ["cs.CV"], "comment": "ICRA 2025", "summary": "Accurately predicting 3D occupancy grids from visual inputs is critical for\nautonomous driving, but current discriminative methods struggle with noisy\ndata, incomplete observations, and the complex structures inherent in 3D\nscenes. In this work, we reframe 3D occupancy prediction as a generative\nmodeling task using diffusion models, which learn the underlying data\ndistribution and incorporate 3D scene priors. This approach enhances prediction\nconsistency, noise robustness, and better handles the intricacies of 3D spatial\nstructures. Our extensive experiments show that diffusion-based generative\nmodels outperform state-of-the-art discriminative approaches, delivering more\nrealistic and accurate occupancy predictions, especially in occluded or\nlow-visibility regions. Moreover, the improved predictions significantly\nbenefit downstream planning tasks, highlighting the practical advantages of our\nmethod for real-world autonomous driving applications.", "AI": {"tldr": "The paper proposes using diffusion models for 3D occupancy grid prediction in autonomous driving, improving accuracy and robustness over discriminative methods.", "motivation": "Current discriminative methods for 3D occupancy prediction struggle with noise, incomplete data, and complex 3D structures, limiting their effectiveness in autonomous driving.", "method": "The work reframes the problem as a generative modeling task using diffusion models, leveraging 3D scene priors to enhance prediction quality.", "result": "Diffusion-based models outperform state-of-the-art discriminative methods, providing more realistic and accurate predictions, especially in occluded or low-visibility areas.", "conclusion": "The generative approach improves prediction consistency and robustness, benefiting downstream planning tasks in autonomous driving applications."}}
{"id": "2505.22767", "pdf": "https://arxiv.org/pdf/2505.22767", "abs": "https://arxiv.org/abs/2505.22767", "authors": ["Eleni Vasilaki"], "title": "In Dialogue with Intelligence: Rethinking Large Language Models as Collective Knowledge", "categories": ["cs.HC", "cs.AI"], "comment": "6 pages, 1 table", "summary": "Large Language Models (LLMs) are typically analysed through architectural,\nbehavioural, or training-data lenses. This article offers a theoretical and\nexperiential re-framing: LLMs as dynamic instantiations of Collective human\nKnowledge (CK), where intelligence is evoked through dialogue rather than\nstored statically. Drawing on concepts from neuroscience and AI, and grounded\nin sustained interaction with ChatGPT-4, I examine emergent dialogue patterns,\nthe implications of fine-tuning, and the notion of co-augmentation: mutual\nenhancement between human and machine cognition. This perspective offers a new\nlens for understanding interaction, representation, and agency in contemporary\nAI systems.", "AI": {"tldr": "The paper reframes LLMs as dynamic embodiments of collective human knowledge, emphasizing intelligence through dialogue, not static storage.", "motivation": "To shift the analysis of LLMs from architectural or behavioral views to a dialogue-driven, collective knowledge perspective.", "method": "Uses theoretical concepts from neuroscience and AI, along with experiential interaction with ChatGPT-4, to study dialogue patterns, fine-tuning, and human-machine co-augmentation.", "result": "Identifies emergent dialogue patterns and explores the mutual enhancement of human and machine cognition.", "conclusion": "Offers a new framework for understanding interaction, representation, and agency in AI systems."}}
{"id": "2505.23013", "pdf": "https://arxiv.org/pdf/2505.23013", "abs": "https://arxiv.org/abs/2505.23013", "authors": ["Liangkai Hang", "Junjie Yao", "Zhiwei Bai", "Tianyi Chen", "Yang Chen", "Rongjie Diao", "Hezhou Li", "Pengxiao Lin", "Zhiwei Wang", "Cheng Xu", "Zhongwang Zhang", "Zhangchen Zhou", "Zhiyu Li", "Zehao Lin", "Kai Chen", "Feiyu Xiong", "Yaoyu Zhang", "Weinan E", "Hongkang Yang", "Zhi-Qin John Xu"], "title": "Scalable Complexity Control Facilitates Reasoning Ability of LLMs", "categories": ["cs.LG"], "comment": null, "summary": "The reasoning ability of large language models (LLMs) has been rapidly\nadvancing in recent years, attracting interest in more fundamental approaches\nthat can reliably enhance their generalizability. This work demonstrates that\nmodel complexity control, conveniently implementable by adjusting the\ninitialization rate and weight decay coefficient, improves the scaling law of\nLLMs consistently over varying model sizes and data sizes. This gain is further\nillustrated by comparing the benchmark performance of 2.4B models pretrained on\n1T tokens with different complexity hyperparameters. Instead of fixing the\ninitialization std, we found that a constant initialization rate (the exponent\nof std) enables the scaling law to descend faster in both model and data sizes.\nThese results indicate that complexity control is a promising direction for the\ncontinual advancement of LLMs.", "AI": {"tldr": "Complexity control via initialization rate and weight decay improves LLM scaling laws, enhancing generalizability across model and data sizes.", "motivation": "To enhance the generalizability of large language models (LLMs) through fundamental approaches like complexity control.", "method": "Adjusting initialization rate and weight decay coefficient to control model complexity, tested on 2.4B models pretrained on 1T tokens.", "result": "Constant initialization rate (exponent of std) improves scaling law descent in model and data sizes, outperforming fixed initialization std.", "conclusion": "Complexity control is a promising direction for advancing LLMs, offering consistent improvements in scaling laws."}}
{"id": "2505.23065", "pdf": "https://arxiv.org/pdf/2505.23065", "abs": "https://arxiv.org/abs/2505.23065", "authors": ["Hongcheng Guo", "Zheyong Xie", "Shaosheng Cao", "Boyang Wang", "Weiting Liu", "Anjie Le", "Lei Li", "Zhoujun Li"], "title": "SNS-Bench-VL: Benchmarking Multimodal Large Language Models in Social Networking Services", "categories": ["cs.CL"], "comment": null, "summary": "With the increasing integration of visual and textual content in Social\nNetworking Services (SNS), evaluating the multimodal capabilities of Large\nLanguage Models (LLMs) is crucial for enhancing user experience, content\nunderstanding, and platform intelligence. Existing benchmarks primarily focus\non text-centric tasks, lacking coverage of the multimodal contexts prevalent in\nmodern SNS ecosystems. In this paper, we introduce SNS-Bench-VL, a\ncomprehensive multimodal benchmark designed to assess the performance of\nVision-Language LLMs in real-world social media scenarios. SNS-Bench-VL\nincorporates images and text across 8 multimodal tasks, including note\ncomprehension, user engagement analysis, information retrieval, and\npersonalized recommendation. It comprises 4,001 carefully curated multimodal\nquestion-answer pairs, covering single-choice, multiple-choice, and open-ended\ntasks. We evaluate over 25 state-of-the-art multimodal LLMs, analyzing their\nperformance across tasks. Our findings highlight persistent challenges in\nmultimodal social context comprehension. We hope SNS-Bench-VL will inspire\nfuture research towards robust, context-aware, and human-aligned multimodal\nintelligence for next-generation social networking services.", "AI": {"tldr": "SNS-Bench-VL is a new multimodal benchmark for evaluating Vision-Language LLMs in social media contexts, covering 8 tasks with 4,001 QA pairs. It reveals challenges in multimodal comprehension.", "motivation": "Existing benchmarks lack coverage of multimodal contexts in SNS, necessitating a tool to assess LLMs' performance in real-world social media scenarios.", "method": "SNS-Bench-VL includes 8 multimodal tasks (e.g., note comprehension, user engagement) with 4,001 QA pairs, evaluated on 25 state-of-the-art LLMs.", "result": "The benchmark uncovers persistent challenges in multimodal social context comprehension among LLMs.", "conclusion": "SNS-Bench-VL aims to drive research towards robust, context-aware multimodal intelligence for future SNS."}}
{"id": "2505.23119", "pdf": "https://arxiv.org/pdf/2505.23119", "abs": "https://arxiv.org/abs/2505.23119", "authors": ["Keren Ye", "Ignacio Garcia Dorado", "Michalis Raptis", "Mauricio Delbracio", "Irene Zhu", "Peyman Milanfar", "Hossein Talebi"], "title": "TextSR: Diffusion Super-Resolution with Multilingual OCR Guidance", "categories": ["cs.CV"], "comment": null, "summary": "While recent advancements in Image Super-Resolution (SR) using diffusion\nmodels have shown promise in improving overall image quality, their application\nto scene text images has revealed limitations. These models often struggle with\naccurate text region localization and fail to effectively model image and\nmultilingual character-to-shape priors. This leads to inconsistencies, the\ngeneration of hallucinated textures, and a decrease in the perceived quality of\nthe super-resolved text.\n  To address these issues, we introduce TextSR, a multimodal diffusion model\nspecifically designed for Multilingual Scene Text Image Super-Resolution.\nTextSR leverages a text detector to pinpoint text regions within an image and\nthen employs Optical Character Recognition (OCR) to extract multilingual text\nfrom these areas. The extracted text characters are then transformed into\nvisual shapes using a UTF-8 based text encoder and cross-attention. Recognizing\nthat OCR may sometimes produce inaccurate results in real-world scenarios, we\nhave developed two innovative methods to enhance the robustness of our model.\nBy integrating text character priors with the low-resolution text images, our\nmodel effectively guides the super-resolution process, enhancing fine details\nwithin the text and improving overall legibility. The superior performance of\nour model on both the TextZoom and TextVQA datasets sets a new benchmark for\nSTISR, underscoring the efficacy of our approach.", "AI": {"tldr": "TextSR is a multimodal diffusion model for Multilingual Scene Text Image Super-Resolution, addressing limitations of existing models by integrating text detection, OCR, and character-to-shape priors to improve text legibility and quality.", "motivation": "Existing diffusion models for Image Super-Resolution struggle with text region localization and multilingual character-to-shape priors, leading to inconsistencies and poor text quality.", "method": "TextSR uses a text detector and OCR to extract multilingual text, encodes characters into visual shapes, and integrates these priors with low-resolution images to guide super-resolution.", "result": "TextSR outperforms existing models on TextZoom and TextVQA datasets, setting a new benchmark for Scene Text Image Super-Resolution.", "conclusion": "TextSR effectively addresses the challenges of text super-resolution by leveraging multimodal priors, improving text legibility and overall image quality."}}
{"id": "2505.22818", "pdf": "https://arxiv.org/pdf/2505.22818", "abs": "https://arxiv.org/abs/2505.22818", "authors": ["Linghan Zhong", "Samuel Yuan", "Jiyang Zhang", "Yu Liu", "Pengyu Nie", "Junyi Jessy Li", "Milos Gligoric"], "title": "A Tool for Generating Exceptional Behavior Tests With Large Language Models", "categories": ["cs.SE", "cs.AI"], "comment": "FSE 2025 Demo (Camera Ready)", "summary": "Exceptional behavior tests (EBTs) are crucial in software development for\nverifying that code correctly handles unwanted events and throws appropriate\nexceptions. However, prior research has shown that developers often prioritize\ntesting \"happy paths\", e.g., paths without unwanted events over exceptional\nscenarios. We present exLong, a framework that automatically generates EBTs to\naddress this gap. exLong leverages a large language model (LLM) fine-tuned from\nCodeLlama and incorporates reasoning about exception-throwing traces,\nconditional expressions that guard throw statements, and non-exceptional\nbehavior tests that execute similar traces. Our demonstration video illustrates\nhow exLong can effectively assist developers in creating comprehensive EBTs for\ntheir project (available at https://youtu.be/Jro8kMgplZk).", "AI": {"tldr": "exLong is a framework using LLMs to automatically generate exceptional behavior tests (EBTs), addressing the gap where developers often neglect testing exceptional scenarios.", "motivation": "Developers prioritize testing 'happy paths' over exceptional scenarios, leaving potential bugs undetected. exLong aims to automate EBT generation to improve software reliability.", "method": "exLong uses a fine-tuned LLM (CodeLlama) to analyze exception-throwing traces, conditional expressions, and non-exceptional behavior tests for generating EBTs.", "result": "The framework effectively assists developers in creating comprehensive EBTs, as demonstrated in the provided video.", "conclusion": "exLong successfully bridges the gap in EBT generation, enhancing software testing by automating exceptional scenario coverage."}}
{"id": "2505.23014", "pdf": "https://arxiv.org/pdf/2505.23014", "abs": "https://arxiv.org/abs/2505.23014", "authors": ["Juwei Yue", "Haikuo Li", "Jiawei Sheng", "Xiaodong Li", "Taoyu Su", "Tingwen Liu", "Li Guo"], "title": "Hyperbolic-PDE GNN: Spectral Graph Neural Networks in the Perspective of A System of Hyperbolic Partial Differential Equations", "categories": ["cs.LG"], "comment": "18 pages, 2 figures, published to ICML 2025", "summary": "Graph neural networks (GNNs) leverage message passing mechanisms to learn the\ntopological features of graph data. Traditional GNNs learns node features in a\nspatial domain unrelated to the topology, which can hardly ensure topological\nfeatures. In this paper, we formulates message passing as a system of\nhyperbolic partial differential equations (hyperbolic PDEs), constituting a\ndynamical system that explicitly maps node representations into a particular\nsolution space. This solution space is spanned by a set of eigenvectors\ndescribing the topological structure of graphs. Within this system, for any\nmoment in time, a node features can be decomposed into a superposition of the\nbasis of eigenvectors. This not only enhances the interpretability of message\npassing but also enables the explicit extraction of fundamental characteristics\nabout the topological structure. Furthermore, by solving this system of\nhyperbolic partial differential equations, we establish a connection with\nspectral graph neural networks (spectral GNNs), serving as a message passing\nenhancement paradigm for spectral GNNs.We further introduce polynomials to\napproximate arbitrary filter functions. Extensive experiments demonstrate that\nthe paradigm of hyperbolic PDEs not only exhibits strong flexibility but also\nsignificantly enhances the performance of various spectral GNNs across diverse\ngraph tasks.", "AI": {"tldr": "The paper proposes using hyperbolic PDEs to model message passing in GNNs, enhancing interpretability and performance by explicitly capturing topological features.", "motivation": "Traditional GNNs lack explicit topological feature learning, limiting their interpretability and effectiveness.", "method": "Formulates message passing as hyperbolic PDEs, mapping node representations into a solution space spanned by eigenvectors, and approximates filters with polynomials.", "result": "The approach improves flexibility and performance of spectral GNNs across various graph tasks.", "conclusion": "Hyperbolic PDEs offer a powerful paradigm for enhancing spectral GNNs by explicitly leveraging topological structure."}}
{"id": "2505.23078", "pdf": "https://arxiv.org/pdf/2505.23078", "abs": "https://arxiv.org/abs/2505.23078", "authors": ["Yuu Jinnai"], "title": "Document-Level Text Generation with Minimum Bayes Risk Decoding using Optimal Transport", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025", "summary": "Document-level text generation tasks are known to be more difficult than\nsentence-level text generation tasks as they require the understanding of\nlonger context to generate high-quality texts. In this paper, we investigate\nthe adaption of Minimum Bayes Risk (MBR) decoding for document-level text\ngeneration tasks. MBR decoding makes use of a utility function to estimate the\noutput with the highest expected utility from a set of candidate outputs.\nAlthough MBR decoding is shown to be effective in a wide range of\nsentence-level text generation tasks, its performance on document-level text\ngeneration tasks is limited as many of the utility functions are designed for\nevaluating the utility of sentences. To this end, we propose MBR-OT, a variant\nof MBR decoding using Wasserstein distance to compute the utility of a document\nusing a sentence-level utility function. The experimental result shows that the\nperformance of MBR-OT outperforms that of the standard MBR in document-level\nmachine translation, text simplification, and dense image captioning tasks. Our\ncode is available at https://github.com/jinnaiyuu/mbr-optimal-transport", "AI": {"tldr": "MBR-OT, a variant of MBR decoding using Wasserstein distance, improves document-level text generation tasks by leveraging sentence-level utility functions.", "motivation": "Document-level text generation is challenging due to longer context requirements, and existing MBR decoding methods are limited by sentence-focused utility functions.", "method": "Proposes MBR-OT, which uses Wasserstein distance to compute document utility from sentence-level functions.", "result": "MBR-OT outperforms standard MBR in document-level machine translation, text simplification, and dense image captioning.", "conclusion": "MBR-OT effectively adapts MBR decoding for document-level tasks, demonstrating superior performance."}}
{"id": "2505.23120", "pdf": "https://arxiv.org/pdf/2505.23120", "abs": "https://arxiv.org/abs/2505.23120", "authors": ["Siyuan Wang", "Jiawei Liu", "Wei Wang", "Yeying Jin", "Jinsong Du", "Zhi Han"], "title": "MMGT: Motion Mask Guided Two-Stage Network for Co-Speech Gesture Video Generation", "categories": ["cs.CV"], "comment": null, "summary": "Co-Speech Gesture Video Generation aims to generate vivid speech videos from\naudio-driven still images, which is challenging due to the diversity of\ndifferent parts of the body in terms of amplitude of motion, audio relevance,\nand detailed features. Relying solely on audio as the control signal often\nfails to capture large gesture movements in video, leading to more pronounced\nartifacts and distortions. Existing approaches typically address this issue by\nintroducing additional a priori information, but this can limit the practical\napplication of the task. Specifically, we propose a Motion Mask-Guided\nTwo-Stage Network (MMGT) that uses audio, as well as motion masks and motion\nfeatures generated from the audio signal to jointly drive the generation of\nsynchronized speech gesture videos. In the first stage, the Spatial Mask-Guided\nAudio Pose Generation (SMGA) Network generates high-quality pose videos and\nmotion masks from audio, effectively capturing large movements in key regions\nsuch as the face and gestures. In the second stage, we integrate the Motion\nMasked Hierarchical Audio Attention (MM-HAA) into the Stabilized Diffusion\nVideo Generation model, overcoming limitations in fine-grained motion\ngeneration and region-specific detail control found in traditional methods.\nThis guarantees high-quality, detailed upper-body video generation with\naccurate texture and motion details. Evaluations show improved video quality,\nlip-sync, and gesture. The model and code are available at\nhttps://github.com/SIA-IDE/MMGT.", "AI": {"tldr": "The paper proposes a Motion Mask-Guided Two-Stage Network (MMGT) to generate synchronized speech gesture videos, addressing challenges like motion diversity and audio relevance.", "motivation": "Existing methods relying solely on audio often fail to capture large gestures, causing artifacts. Additional priors limit practicality, so MMGT integrates motion masks and features for better results.", "method": "MMGT uses a two-stage approach: (1) SMGA Network generates pose videos and motion masks from audio, capturing key movements. (2) MM-HAA in Stabilized Diffusion refines fine-grained motion and details.", "result": "The method improves video quality, lip-sync, and gesture accuracy, outperforming traditional approaches.", "conclusion": "MMGT effectively addresses limitations in co-speech gesture video generation, offering high-quality, detailed results with practical applicability."}}
{"id": "2505.22831", "pdf": "https://arxiv.org/pdf/2505.22831", "abs": "https://arxiv.org/abs/2505.22831", "authors": ["Peiling Jiang", "Haijun Xia"], "title": "Orca: Browsing at Scale Through User-Driven and AI-Facilitated Orchestration Across Malleable Webpages", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Web-based activities are fundamentally distributed across webpages. However,\nconventional browsers with stacks of tabs fail to support operating and\nsynthesizing large volumes of information across pages. While recent AI systems\nenable fully automated web browsing and information synthesis, they often\ndiminish user agency and hinder contextual understanding. Therefore, we explore\nhow AI could instead augment users' interactions with content across webpages\nand mitigate cognitive and manual efforts. Through literature on information\ntasks and web browsing challenges, and an iterative design process, we present\na rich set of novel interactions with our prototype web browser, Orca.\nLeveraging AI, Orca supports user-driven exploration, operation, organization,\nand synthesis of web content at scale. To enable browsing at scale, webpages\nare treated as malleable materials that humans and AI can collaboratively\nmanipulate and compose into a malleable, dynamic, and browser-level workspace.\nOur evaluation revealed an increased \"appetite\" for information foraging,\nenhanced user control, and more flexibility in sensemaking across a broader\ninformation landscape on the web.", "AI": {"tldr": "The paper introduces Orca, an AI-augmented web browser designed to enhance user-driven exploration and synthesis of web content across multiple pages, addressing limitations of conventional browsers and fully automated AI systems.", "motivation": "Conventional browsers and fully automated AI systems fail to support efficient synthesis of large-scale web information while maintaining user agency and contextual understanding.", "method": "The authors conducted literature reviews on information tasks and web browsing challenges, followed by an iterative design process to develop Orca, a prototype browser. Orca treats webpages as malleable materials for collaborative human-AI manipulation.", "result": "Evaluation showed Orca increased information foraging, improved user control, and provided greater flexibility in sensemaking across a broader web information landscape.", "conclusion": "AI can effectively augment user interactions with web content, balancing automation with user agency to enhance large-scale information synthesis."}}
{"id": "2505.23017", "pdf": "https://arxiv.org/pdf/2505.23017", "abs": "https://arxiv.org/abs/2505.23017", "authors": ["Xingjian Wu", "Xiangfei Qiu", "Hongfan Gao", "Jilin Hu", "Bin Yang", "Chenjuan Guo"], "title": "$K^2$VAE: A Koopman-Kalman Enhanced Variational AutoEncoder for Probabilistic Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Probabilistic Time Series Forecasting (PTSF) plays a crucial role in\ndecision-making across various fields, including economics, energy, and\ntransportation. Most existing methods excell at short-term forecasting, while\noverlooking the hurdles of Long-term Probabilistic Time Series Forecasting\n(LPTSF). As the forecast horizon extends, the inherent nonlinear dynamics have\na significant adverse effect on prediction accuracy, and make generative models\ninefficient by increasing the cost of each iteration. To overcome these\nlimitations, we introduce $K^2$VAE, an efficient VAE-based generative model\nthat leverages a KoopmanNet to transform nonlinear time series into a linear\ndynamical system, and devises a KalmanNet to refine predictions and model\nuncertainty in such linear system, which reduces error accumulation in\nlong-term forecasting. Extensive experiments demonstrate that $K^2$VAE\noutperforms state-of-the-art methods in both short- and long-term PTSF,\nproviding a more efficient and accurate solution.", "AI": {"tldr": "$K^2$VAE is a VAE-based model for long-term probabilistic time series forecasting, using KoopmanNet and KalmanNet to improve accuracy and efficiency.", "motivation": "Existing methods focus on short-term forecasting, neglecting challenges in long-term probabilistic forecasting due to nonlinear dynamics and inefficiency.", "method": "$K^2$VAE combines a KoopmanNet to linearize time series and a KalmanNet to refine predictions and model uncertainty in the linear system.", "result": "$K^2$VAE outperforms state-of-the-art methods in both short- and long-term forecasting, reducing error accumulation.", "conclusion": "$K^2$VAE provides an efficient and accurate solution for long-term probabilistic time series forecasting."}}
{"id": "2505.23108", "pdf": "https://arxiv.org/pdf/2505.23108", "abs": "https://arxiv.org/abs/2505.23108", "authors": ["Zexuan Li", "Hongliang Dai", "Piji Li"], "title": "Generating Diverse Training Samples for Relation Extraction with Large Language Models", "categories": ["cs.CL"], "comment": "ACL2025 Main", "summary": "Using Large Language Models (LLMs) to generate training data can potentially\nbe a preferable way to improve zero or few-shot NLP tasks. However, many\nproblems remain to be investigated for this direction. For the task of Relation\nExtraction (RE), we find that samples generated by directly prompting LLMs may\neasily have high structural similarities with each other. They tend to use a\nlimited variety of phrasing while expressing the relation between a pair of\nentities. Therefore, in this paper, we study how to effectively improve the\ndiversity of the training samples generated with LLMs for RE, while also\nmaintaining their correctness. We first try to make the LLMs produce dissimilar\nsamples by directly giving instructions in In-Context Learning (ICL) prompts.\nThen, we propose an approach to fine-tune LLMs for diversity training sample\ngeneration through Direct Preference Optimization (DPO). Our experiments on\ncommonly used RE datasets show that both attempts can improve the quality of\nthe generated training data. We also find that comparing with directly\nperforming RE with an LLM, training a non-LLM RE model with its generated\nsamples may lead to better performance.", "AI": {"tldr": "The paper explores improving diversity in LLM-generated training data for Relation Extraction (RE) while ensuring correctness, using ICL prompts and DPO fine-tuning. Results show better data quality and performance when training non-LLM models with this data.", "motivation": "LLM-generated RE training samples often lack diversity due to structural similarities, limiting their effectiveness for zero or few-shot tasks.", "method": "1. Use ICL prompts to encourage diverse samples. 2. Fine-tune LLMs with DPO for diversity.", "result": "Both methods improve training data quality. Training non-LLM RE models with this data outperforms direct LLM-based RE.", "conclusion": "Enhancing diversity in LLM-generated RE data via ICL and DPO improves downstream task performance, suggesting a viable alternative to direct LLM use."}}
{"id": "2505.23129", "pdf": "https://arxiv.org/pdf/2505.23129", "abs": "https://arxiv.org/abs/2505.23129", "authors": ["Bin Wang", "Pingjun Li", "Jinkun Liu", "Jun Cheng", "Hailong Lei", "Yinze Rong", "Huan-ang Gao", "Kangliang Chen", "Xing Pan", "Weihao Gu"], "title": "HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring", "categories": ["cs.CV"], "comment": null, "summary": "End-to-end autonomous driving faces persistent challenges in both generating\ndiverse, rule-compliant trajectories and robustly selecting the optimal path\nfrom these options via learned, multi-faceted evaluation. To address these\nchallenges, we introduce HMAD, a framework integrating a distinctive\nBird's-Eye-View (BEV) based trajectory proposal mechanism with learned\nmulti-criteria scoring. HMAD leverages BEVFormer and employs learnable anchored\nqueries, initialized from a trajectory dictionary and refined via iterative\noffset decoding (inspired by DiffusionDrive), to produce numerous diverse and\nstable candidate trajectories. A key innovation, our simulation-supervised\nscorer module, then evaluates these proposals against critical metrics\nincluding no at-fault collisions, drivable area compliance, comfortableness,\nand overall driving quality (i.e., extended PDM score). Demonstrating its\nefficacy, HMAD achieves a 44.5% driving score on the CVPR 2025 private test\nset. This work highlights the benefits of effectively decoupling robust\ntrajectory generation from comprehensive, safety-aware learned scoring for\nadvanced autonomous driving.", "AI": {"tldr": "HMAD is a framework for autonomous driving that combines BEV-based trajectory proposals with learned multi-criteria scoring to improve trajectory diversity and selection.", "motivation": "Address challenges in generating diverse, rule-compliant trajectories and selecting the optimal path via learned evaluation.", "method": "Uses BEVFormer and learnable anchored queries for trajectory generation, refined via iterative offset decoding. Includes a simulation-supervised scorer for multi-criteria evaluation.", "result": "Achieves a 44.5% driving score on the CVPR 2025 private test set.", "conclusion": "Decoupling trajectory generation from safety-aware scoring enhances autonomous driving performance."}}
{"id": "2505.22843", "pdf": "https://arxiv.org/pdf/2505.22843", "abs": "https://arxiv.org/abs/2505.22843", "authors": ["Alexander Herzog", "Aliai Eusebi", "Lorenzo Cavallaro"], "title": "Aurora: Are Android Malware Classifiers Reliable under Distribution Shift?", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The performance figures of modern drift-adaptive malware classifiers appear\npromising, but does this translate to genuine operational reliability? The\nstandard evaluation paradigm primarily focuses on baseline performance metrics,\nneglecting confidence-error alignment and operational stability. While\nTESSERACT established the importance of temporal evaluation, we take a\ncomplementary direction by investigating whether malware classifiers maintain\nreliable confidence estimates under distribution shifts and exploring the\ntensions between scientific advancement and practical impacts when they do not.\nWe propose AURORA, a framework to evaluate malware classifiers based on their\nconfidence quality and operational resilience. AURORA subjects the confidence\nprofile of a given model to verification to assess the reliability of its\nestimates. Unreliable confidence estimates erode operational trust, waste\nvaluable annotation budget on non-informative samples for active learning, and\nleave error-prone instances undetected in selective classification. AURORA is\nfurther complemented by a set of metrics designed to go beyond point-in-time\nperformance, striving towards a more holistic assessment of operational\nstability throughout temporal evaluation periods. The fragility we observe in\nstate-of-the-art frameworks across datasets of varying drift severity suggests\nthe need for a return to the whiteboard.", "AI": {"tldr": "AURORA evaluates malware classifiers' confidence reliability and operational resilience, highlighting gaps in current evaluation methods.", "motivation": "Current malware classifier evaluations overlook confidence-error alignment and operational stability, risking practical reliability.", "method": "Proposes AURORA, a framework to assess confidence quality and resilience under distribution shifts, with metrics for temporal stability.", "result": "State-of-the-art frameworks show fragility in confidence estimates across datasets, indicating a need for reevaluation.", "conclusion": "AURORA underscores the importance of confidence reliability and operational stability in malware classifiers, calling for improved evaluation practices."}}
{"id": "2505.23022", "pdf": "https://arxiv.org/pdf/2505.23022", "abs": "https://arxiv.org/abs/2505.23022", "authors": ["Yinghao Tang", "Tingfeng Lan", "Xiuqi Huang", "Hui Lu", "Wei Chen"], "title": "SCORPIO: Serving the Right Requests at the Right Time for Heterogeneous SLOs in LLM Inference", "categories": ["cs.LG"], "comment": null, "summary": "Existing Large Language Model (LLM) serving systems prioritize maximum\nthroughput. They often neglect Service Level Objectives (SLOs) such as Time to\nFirst Token (TTFT) and Time Per Output Token (TPOT), which leads to suboptimal\nSLO attainment. This paper introduces SCORPIO, an SLO-oriented LLM serving\nsystem designed to maximize system goodput and SLO attainment for workloads\nwith heterogeneous SLOs. Our core insight is to exploit SLO heterogeneity for\nadaptive scheduling across admission control, queue management, and batch\nselection. SCORPIO features a TTFT Guard, which employs least-deadline-first\nreordering and rejects unattainable requests, and a TPOT Guard, which utilizes\na VBS-based admission control and a novel credit-based batching mechanism. Both\nguards are supported by a predictive module. Evaluations demonstrate that\nSCORPIO improves system goodput by up to 14.4X and SLO adherence by up to 46.5%\ncompared to state-of-the-art baselines.", "AI": {"tldr": "SCORPIO is an SLO-oriented LLM serving system that improves goodput and SLO adherence by exploiting SLO heterogeneity for adaptive scheduling.", "motivation": "Existing LLM serving systems prioritize throughput over SLOs like TTFT and TPOT, leading to suboptimal performance.", "method": "SCORPIO uses adaptive scheduling with TTFT Guard (deadline-first reordering) and TPOT Guard (VBS-based admission control and credit-based batching), supported by a predictive module.", "result": "SCORPIO improves system goodput by up to 14.4X and SLO adherence by up to 46.5%.", "conclusion": "SCORPIO effectively addresses SLO neglect in LLM serving systems, enhancing performance and adherence."}}
{"id": "2505.23114", "pdf": "https://arxiv.org/pdf/2505.23114", "abs": "https://arxiv.org/abs/2505.23114", "authors": ["Seohyeong Lee", "Eunwon Kim", "Hwaran Lee", "Buru Chang"], "title": "Dataset Cartography for Large Language Model Alignment: Mapping and Diagnosing Preference Data", "categories": ["cs.CL"], "comment": null, "summary": "Human preference data plays a critical role in aligning large language models\n(LLMs) with human values. However, collecting such data is often expensive and\ninefficient, posing a significant scalability challenge. To address this, we\nintroduce Alignment Data Map, a GPT-4o-assisted tool for analyzing and\ndiagnosing preference data. Using GPT-4o as a proxy for LLM alignment, we\ncompute alignment scores for LLM-generated responses to instructions from\nexisting preference datasets. These scores are then used to construct an\nAlignment Data Map based on their mean and variance. Our experiments show that\nusing only 33 percent of the data, specifically samples in the high-mean,\nlow-variance region, achieves performance comparable to or better than using\nthe entire dataset. This finding suggests that the Alignment Data Map can\nsignificantly improve data collection efficiency by identifying high-quality\nsamples for LLM alignment without requiring explicit annotations. Moreover, the\nAlignment Data Map can diagnose existing preference datasets. Our analysis\nshows that it effectively detects low-impact or potentially misannotated\nsamples. Source code is available online.", "AI": {"tldr": "Alignment Data Map, a GPT-4o-assisted tool, improves efficiency in collecting human preference data for LLM alignment by identifying high-quality samples without explicit annotations.", "motivation": "Human preference data collection for LLM alignment is costly and inefficient, necessitating a scalable solution.", "method": "Uses GPT-4o to compute alignment scores for LLM responses, constructing an Alignment Data Map based on mean and variance of scores.", "result": "Using 33% of high-quality data achieves comparable or better performance than full datasets.", "conclusion": "The Alignment Data Map enhances data efficiency and diagnoses dataset quality, reducing reliance on explicit annotations."}}
{"id": "2505.23130", "pdf": "https://arxiv.org/pdf/2505.23130", "abs": "https://arxiv.org/abs/2505.23130", "authors": ["Haoyu Chen", "Keda Tao", "Yizao Wang", "Xinlei Wang", "Lei Zhu", "Jinjin Gu"], "title": "PhotoArtAgent: Intelligent Photo Retouching with Language Model-Based Artist Agents", "categories": ["cs.CV"], "comment": null, "summary": "Photo retouching is integral to photographic art, extending far beyond simple\ntechnical fixes to heighten emotional expression and narrative depth. While\nartists leverage expertise to create unique visual effects through deliberate\nadjustments, non-professional users often rely on automated tools that produce\nvisually pleasing results but lack interpretative depth and interactive\ntransparency. In this paper, we introduce PhotoArtAgent, an intelligent system\nthat combines Vision-Language Models (VLMs) with advanced natural language\nreasoning to emulate the creative process of a professional artist. The agent\nperforms explicit artistic analysis, plans retouching strategies, and outputs\nprecise parameters to Lightroom through an API. It then evaluates the resulting\nimages and iteratively refines them until the desired artistic vision is\nachieved. Throughout this process, PhotoArtAgent provides transparent,\ntext-based explanations of its creative rationale, fostering meaningful\ninteraction and user control. Experimental results show that PhotoArtAgent not\nonly surpasses existing automated tools in user studies but also achieves\nresults comparable to those of professional human artists.", "AI": {"tldr": "PhotoArtAgent is an AI system that uses Vision-Language Models to emulate professional photo retouching, offering transparent, interactive, and high-quality results comparable to human artists.", "motivation": "Automated photo retouching tools lack interpretative depth and transparency. PhotoArtAgent aims to bridge this gap by mimicking the creative process of professional artists.", "method": "Combines Vision-Language Models with natural language reasoning to analyze, plan, and execute retouching strategies, iteratively refining results via Lightroom API.", "result": "Outperforms existing automated tools and matches professional human artists in quality, with transparent text-based explanations.", "conclusion": "PhotoArtAgent successfully integrates AI with artistic creativity, offering a user-controlled, high-quality retouching solution."}}
{"id": "2505.22845", "pdf": "https://arxiv.org/pdf/2505.22845", "abs": "https://arxiv.org/abs/2505.22845", "authors": ["Sandra H\u00f6ltervennhoff", "Jonas Ricker", "Maike M. Raphael", "Charlotte Schwedes", "Rebecca Weil", "Asja Fischer", "Thorsten Holz", "Lea Sch\u00f6nherr", "Sascha Fahl"], "title": "Security Benefits and Side Effects of Labeling AI-Generated Images", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.SI"], "comment": null, "summary": "Generative artificial intelligence is developing rapidly, impacting humans'\ninteraction with information and digital media. It is increasingly used to\ncreate deceptively realistic misinformation, so lawmakers have imposed\nregulations requiring the disclosure of AI-generated content. However, only\nlittle is known about whether these labels reduce the risks of AI-generated\nmisinformation.\n  Our work addresses this research gap. Focusing on AI-generated images, we\nstudy the implications of labels, including the possibility of mislabeling.\nAssuming that simplicity, transparency, and trust are likely to impact the\nsuccessful adoption of such labels, we first qualitatively explore users'\nopinions and expectations of AI labeling using five focus groups. Second, we\nconduct a pre-registered online survey with over 1300 U.S. and EU participants\nto quantitatively assess the effect of AI labels on users' ability to recognize\nmisinformation containing either human-made or AI-generated images. Our focus\ngroups illustrate that, while participants have concerns about the practical\nimplementation of labeling, they consider it helpful in identifying\nAI-generated images and avoiding deception. However, considering security\nbenefits, our survey revealed an ambiguous picture, suggesting that users might\nover-rely on labels. While inaccurate claims supported by labeled AI-generated\nimages were rated less credible than those with unlabeled AI-images, the belief\nin accurate claims also decreased when accompanied by a labeled AI-generated\nimage. Moreover, we find the undesired side effect that human-made images\nconveying inaccurate claims were perceived as more credible in the presence of\nlabels.", "AI": {"tldr": "The study examines the effectiveness of AI-generated content labels in reducing misinformation risks, revealing mixed results and unintended side effects.", "motivation": "To address the lack of knowledge about whether AI labels mitigate the risks of AI-generated misinformation, focusing on user perceptions and practical implications.", "method": "Combined qualitative focus groups (5 groups) and a pre-registered online survey (1300+ U.S. and EU participants) to assess AI label effects on misinformation recognition.", "result": "Labels helped identify AI-generated images but led to over-reliance. Accurate claims with labeled AI images were less trusted, while human-made misinformation gained credibility.", "conclusion": "AI labels have potential but require careful implementation to avoid unintended consequences like over-reliance and reduced trust in accurate information."}}
{"id": "2505.23024", "pdf": "https://arxiv.org/pdf/2505.23024", "abs": "https://arxiv.org/abs/2505.23024", "authors": ["Zhihao Wang", "Wenke Huang", "Tian Chen", "Zekun Shi", "Guancheng Wan", "Yu Qiao", "Bin Yang", "Jian Wang", "Bing Li", "Mang Ye"], "title": "An Empirical Study of Federated Prompt Learning for Vision Language Model", "categories": ["cs.LG"], "comment": null, "summary": "The Vision Language Model (VLM) excels in aligning vision and language\nrepresentations, and prompt learning has emerged as a key technique for\nadapting such models to downstream tasks. However, the application of prompt\nlearning with VLM in federated learning (\\fl{}) scenarios remains\nunderexplored. This paper systematically investigates the behavioral\ndifferences between language prompt learning (LPT) and vision prompt learning\n(VPT) under data heterogeneity challenges, including label skew and domain\nshift. We conduct extensive experiments to evaluate the impact of various \\fl{}\nand prompt configurations, such as client scale, aggregation strategies, and\nprompt length, to assess the robustness of Federated Prompt Learning (FPL).\nFurthermore, we explore strategies for enhancing prompt learning in complex\nscenarios where label skew and domain shift coexist, including leveraging both\nprompt types when computational resources allow. Our findings offer practical\ninsights into optimizing prompt learning in federated settings, contributing to\nthe broader deployment of VLMs in privacy-preserving environments.", "AI": {"tldr": "This paper explores prompt learning in Vision Language Models (VLMs) within federated learning (FL) settings, focusing on differences between language (LPT) and vision (VPT) prompt learning under data heterogeneity. It evaluates FL and prompt configurations and proposes strategies for robustness.", "motivation": "The study addresses the underexplored application of prompt learning with VLMs in FL, particularly under data heterogeneity challenges like label skew and domain shift.", "method": "The paper conducts experiments to compare LPT and VPT in FL, testing various configurations (client scale, aggregation strategies, prompt length) and exploring strategies for complex scenarios.", "result": "Findings provide insights into optimizing prompt learning in FL, including leveraging both prompt types when resources allow, enhancing robustness in heterogeneous data settings.", "conclusion": "The work contributes to deploying VLMs in privacy-preserving FL environments by offering practical solutions for prompt learning challenges."}}
{"id": "2505.23118", "pdf": "https://arxiv.org/pdf/2505.23118", "abs": "https://arxiv.org/abs/2505.23118", "authors": ["Linjie Mu", "Zhongzhen Huang", "Yakun Zhu", "Xiangyu Zhao", "Shaoting Zhang", "Xiaofan Zhang"], "title": "Elicit and Enhance: Advancing Multimodal Reasoning in Medical Scenarios", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Effective clinical decision-making depends on iterative, multimodal reasoning\nacross diverse sources of evidence. The recent emergence of multimodal\nreasoning models has significantly transformed the landscape of solving complex\ntasks. Although such models have achieved notable success in mathematics and\nscience, their application to medical domains remains underexplored. In this\nwork, we propose \\textit{MedE$^2$}, a two-stage post-training pipeline that\nelicits and then enhances multimodal reasoning for medical domains. In Stage-I,\nwe fine-tune models using 2,000 text-only data samples containing precisely\norchestrated reasoning demonstrations to elicit reasoning behaviors. In\nStage-II, we further enhance the model's reasoning capabilities using 1,500\nrigorously curated multimodal medical cases, aligning model reasoning outputs\nwith our proposed multimodal medical reasoning preference. Extensive\nexperiments demonstrate the efficacy and reliability of \\textit{MedE$^2$} in\nimproving the reasoning performance of medical multimodal models. Notably,\nmodels trained with \\textit{MedE$^2$} consistently outperform baselines across\nmultiple medical multimodal benchmarks. Additional validation on larger models\nand under inference-time scaling further confirms the robustness and practical\nutility of our approach.", "AI": {"tldr": "The paper introduces MedE\u00b2, a two-stage post-training pipeline to enhance multimodal reasoning in medical domains, outperforming baselines in benchmarks.", "motivation": "Clinical decision-making relies on multimodal reasoning, yet existing models are underexplored in medical applications.", "method": "Stage-I fine-tunes models with text-only reasoning demonstrations; Stage-II enhances reasoning using curated multimodal medical cases.", "result": "MedE\u00b2 improves reasoning performance, consistently outperforming baselines in medical benchmarks.", "conclusion": "The approach is robust, scalable, and practical for enhancing medical multimodal reasoning."}}
{"id": "2505.23134", "pdf": "https://arxiv.org/pdf/2505.23134", "abs": "https://arxiv.org/abs/2505.23134", "authors": ["Tongtong Su", "Chengyu Wang", "Jun Huang", "Dongming Lu"], "title": "Zero-to-Hero: Zero-Shot Initialization Empowering Reference-Based Video Appearance Editing", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Appearance editing according to user needs is a pivotal task in video\nediting. Existing text-guided methods often lead to ambiguities regarding user\nintentions and restrict fine-grained control over editing specific aspects of\nobjects. To overcome these limitations, this paper introduces a novel approach\nnamed {Zero-to-Hero}, which focuses on reference-based video editing that\ndisentangles the editing process into two distinct problems. It achieves this\nby first editing an anchor frame to satisfy user requirements as a reference\nimage and then consistently propagating its appearance across other frames. We\nleverage correspondence within the original frames to guide the attention\nmechanism, which is more robust than previously proposed optical flow or\ntemporal modules in memory-friendly video generative models, especially when\ndealing with objects exhibiting large motions. It offers a solid ZERO-shot\ninitialization that ensures both accuracy and temporal consistency. However,\nintervention in the attention mechanism results in compounded imaging\ndegradation with over-saturated colors and unknown blurring issues. Starting\nfrom Zero-Stage, our Hero-Stage Holistically learns a conditional generative\nmodel for vidEo RestOration. To accurately evaluate the consistency of the\nappearance, we construct a set of videos with multiple appearances using\nBlender, enabling a fine-grained and deterministic evaluation. Our method\noutperforms the best-performing baseline with a PSNR improvement of 2.6 dB. The\nproject page is at https://github.com/Tonniia/Zero2Hero.", "AI": {"tldr": "Zero-to-Hero introduces a reference-based video editing method that disentangles editing into anchor frame refinement and propagation, addressing ambiguities and control issues in text-guided methods.", "motivation": "Existing text-guided video editing methods lack fine-grained control and clarity in user intentions, prompting the need for a more robust and precise approach.", "method": "The method splits editing into two stages: editing an anchor frame as a reference and propagating its appearance using correspondence-guided attention. A Hero-Stage further refines results with a conditional generative model for restoration.", "result": "The approach improves PSNR by 2.6 dB over baselines, demonstrating superior accuracy and temporal consistency.", "conclusion": "Zero-to-Hero offers a robust, memory-friendly solution for precise video appearance editing, outperforming existing methods while addressing their limitations."}}
{"id": "2505.22852", "pdf": "https://arxiv.org/pdf/2505.22852", "abs": "https://arxiv.org/abs/2505.22852", "authors": ["Krti Tallam", "Emma Miller"], "title": "Operationalizing CaMeL: Strengthening LLM Defenses for Enterprise Deployment", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "CaMeL (Capabilities for Machine Learning) introduces a capability-based\nsandbox to mitigate prompt injection attacks in large language model (LLM)\nagents. While effective, CaMeL assumes a trusted user prompt, omits\nside-channel concerns, and incurs performance tradeoffs due to its dual-LLM\ndesign. This response identifies these issues and proposes engineering\nimprovements to expand CaMeL's threat coverage and operational usability. We\nintroduce: (1) prompt screening for initial inputs, (2) output auditing to\ndetect instruction leakage, (3) a tiered-risk access model to balance usability\nand control, and (4) a verified intermediate language for formal guarantees.\nTogether, these upgrades align CaMeL with best practices in enterprise security\nand support scalable deployment.", "AI": {"tldr": "CaMeL introduces a capability-based sandbox for LLM security but has limitations. Proposed improvements include prompt screening, output auditing, tiered-risk access, and a verified intermediate language.", "motivation": "To address vulnerabilities in CaMeL's design, such as untrusted user prompts and side-channel risks, and enhance its security and usability.", "method": "Proposes four upgrades: prompt screening, output auditing, tiered-risk access, and a verified intermediate language.", "result": "Improved threat coverage and operational usability, aligning with enterprise security best practices.", "conclusion": "The enhancements make CaMeL more robust and scalable for secure LLM deployment."}}
{"id": "2505.23027", "pdf": "https://arxiv.org/pdf/2505.23027", "abs": "https://arxiv.org/abs/2505.23027", "authors": ["Minh Nguyen Nhat To", "Paul F RWilson", "Viet Nguyen", "Mohamed Harmanani", "Michael Cooper", "Fahimeh Fooladgar", "Purang Abolmaesumi", "Parvin Mousavi", "Rahul G. Krishnan"], "title": "Diverse Prototypical Ensembles Improve Robustness to Subpopulation Shift", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "ICML 2025 Paper", "summary": "The subpopulationtion shift, characterized by a disparity in subpopulation\ndistributibetween theween the training and target datasets, can significantly\ndegrade the performance of machine learning models. Current solutions to\nsubpopulation shift involve modifying empirical risk minimization with\nre-weighting strategies to improve generalization. This strategy relies on\nassumptions about the number and nature of subpopulations and annotations on\ngroup membership, which are unavailable for many real-world datasets. Instead,\nwe propose using an ensemble of diverse classifiers to adaptively capture risk\nassociated with subpopulations. Given a feature extractor network, we replace\nits standard linear classification layer with a mixture of prototypical\nclassifiers, where each member is trained to classify the data while focusing\non different features and samples from other members. In empirical evaluation\non nine real-world datasets, covering diverse domains and kinds of\nsubpopulation shift, our method of Diverse Prototypical Ensembles (DPEs) often\noutperforms the prior state-of-the-art in worst-group accuracy. The code is\navailable at https://github.com/minhto2802/dpe4subpop", "AI": {"tldr": "The paper proposes Diverse Prototypical Ensembles (DPEs) to address subpopulation shift in machine learning, outperforming prior methods in worst-group accuracy.", "motivation": "Subpopulation shift degrades model performance, and current solutions rely on unavailable assumptions about subpopulations.", "method": "Replace a linear classifier with a mixture of prototypical classifiers, each focusing on different features and samples.", "result": "DPEs outperform state-of-the-art methods on nine real-world datasets.", "conclusion": "DPEs effectively address subpopulation shift without requiring group annotations."}}
{"id": "2505.23121", "pdf": "https://arxiv.org/pdf/2505.23121", "abs": "https://arxiv.org/abs/2505.23121", "authors": ["Yiming Lei", "Zhizheng Yang", "Zeming Liu", "Haitao Leng", "Shaoguo Liu", "Tingting Gao", "Qingjie Liu", "Yunhong Wang"], "title": "ContextQFormer: A New Context Modeling Method for Multi-Turn Multi-Modal Conversations", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 6 figures", "summary": "Multi-modal large language models have demonstrated remarkable zero-shot\nabilities and powerful image-understanding capabilities. However, the existing\nopen-source multi-modal models suffer from the weak capability of multi-turn\ninteraction, especially for long contexts. To address the issue, we first\nintroduce a context modeling module, termed ContextQFormer, which utilizes a\nmemory block to enhance the presentation of contextual information.\nFurthermore, to facilitate further research, we carefully build a new\nmulti-turn multi-modal dialogue dataset (TMDialog) for pre-training,\ninstruction-tuning, and evaluation, which will be open-sourced lately. Compared\nwith other multi-modal dialogue datasets, TMDialog contains longer\nconversations, which supports the research of multi-turn multi-modal dialogue.\nIn addition, ContextQFormer is compared with three baselines on TMDialog and\nexperimental results illustrate that ContextQFormer achieves an improvement of\n2%-4% in available rate over baselines.", "AI": {"tldr": "The paper introduces ContextQFormer, a module to improve multi-turn interaction in multi-modal models, and a new dataset (TMDialog) for research. ContextQFormer outperforms baselines by 2%-4%.", "motivation": "Existing open-source multi-modal models lack strong multi-turn interaction capabilities, especially for long contexts.", "method": "Introduces ContextQFormer, a context modeling module with a memory block, and builds TMDialog, a multi-turn multi-modal dialogue dataset.", "result": "ContextQFormer improves performance by 2%-4% over baselines on TMDialog.", "conclusion": "The proposed ContextQFormer and TMDialog dataset address limitations in multi-turn multi-modal dialogue research."}}
{"id": "2505.23143", "pdf": "https://arxiv.org/pdf/2505.23143", "abs": "https://arxiv.org/abs/2505.23143", "authors": ["Jinquan Guan", "Qi Chen", "Lizhou Liang", "Yuhang Liu", "Vu Minh Hieu Phan", "Minh-Son To", "Jian Chen", "Yutong Xie"], "title": "Interpreting Chest X-rays Like a Radiologist: A Benchmark with Clinical Reasoning", "categories": ["cs.CV"], "comment": "10 pages (main text), 18 pages (appendix)", "summary": "Artificial intelligence (AI)-based chest X-ray (CXR) interpretation\nassistants have demonstrated significant progress and are increasingly being\napplied in clinical settings. However, contemporary medical AI models often\nadhere to a simplistic input-to-output paradigm, directly processing an image\nand an instruction to generate a result, where the instructions may be integral\nto the model's architecture. This approach overlooks the modeling of the\ninherent diagnostic reasoning in chest X-ray interpretation. Such reasoning is\ntypically sequential, where each interpretive stage considers the images, the\ncurrent task, and the contextual information from previous stages. This\noversight leads to several shortcomings, including misalignment with clinical\nscenarios, contextless reasoning, and untraceable errors. To fill this gap, we\nconstruct CXRTrek, a new multi-stage visual question answering (VQA) dataset\nfor CXR interpretation. The dataset is designed to explicitly simulate the\ndiagnostic reasoning process employed by radiologists in real-world clinical\nsettings for the first time. CXRTrek covers 8 sequential diagnostic stages,\ncomprising 428,966 samples and over 11 million question-answer (Q&A) pairs,\nwith an average of 26.29 Q&A pairs per sample. Building on the CXRTrek dataset,\nwe propose a new vision-language large model (VLLM), CXRTrekNet, specifically\ndesigned to incorporate the clinical reasoning flow into the VLLM framework.\nCXRTrekNet effectively models the dependencies between diagnostic stages and\ncaptures reasoning patterns within the radiological context. Trained on our\ndataset, the model consistently outperforms existing medical VLLMs on the\nCXRTrek benchmarks and demonstrates superior generalization across multiple\ntasks on five diverse external datasets. The dataset and model can be found in\nour repository (https://github.com/guanjinquan/CXRTrek).", "AI": {"tldr": "The paper introduces CXRTrek, a multi-stage VQA dataset for CXR interpretation, and CXRTrekNet, a VLLM designed to model clinical reasoning. It outperforms existing models and generalizes well.", "motivation": "Current AI models for CXR interpretation lack sequential diagnostic reasoning, leading to misalignment with clinical scenarios.", "method": "Constructed CXRTrek dataset with 8 diagnostic stages and proposed CXRTrekNet, a VLLM incorporating clinical reasoning.", "result": "CXRTrekNet outperforms existing medical VLLMs on benchmarks and generalizes well across tasks.", "conclusion": "CXRTrek and CXRTrekNet address the gap in modeling diagnostic reasoning, improving AI-assisted CXR interpretation."}}
{"id": "2505.22860", "pdf": "https://arxiv.org/pdf/2505.22860", "abs": "https://arxiv.org/abs/2505.22860", "authors": ["Bargav Jayaraman", "Virendra J. Marathe", "Hamid Mozaffari", "William F. Shen", "Krishnaram Kenthapadi"], "title": "Permissioned LLMs: Enforcing Access Control in Large Language Models", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "In enterprise settings, organizational data is segregated, siloed and\ncarefully protected by elaborate access control frameworks. These access\ncontrol structures can completely break down if an LLM fine-tuned on the siloed\ndata serves requests, for downstream tasks, from individuals with disparate\naccess privileges. We propose Permissioned LLMs (PermLLM), a new class of LLMs\nthat superimpose the organizational data access control structures on query\nresponses they generate. We formalize abstractions underpinning the means to\ndetermine whether access control enforcement happens correctly over LLM query\nresponses. Our formalism introduces the notion of a relevant response that can\nbe used to prove whether a PermLLM mechanism has been implemented correctly. We\nalso introduce a novel metric, called access advantage, to empirically evaluate\nthe efficacy of a PermLLM mechanism. We introduce three novel PermLLM\nmechanisms that build on Parameter Efficient Fine-Tuning to achieve the desired\naccess control. We furthermore present two instantiations of access\nadvantage--(i) Domain Distinguishability Index (DDI) based on Membership\nInference Attacks, and (ii) Utility Gap Index (UGI) based on LLM utility\nevaluation. We demonstrate the efficacy of our PermLLM mechanisms through\nextensive experiments on four public datasets (GPQA, RCV1, SimpleQA, and WMDP),\nin addition to evaluating the validity of DDI and UGI metrics themselves for\nquantifying access control in LLMs.", "AI": {"tldr": "The paper introduces Permissioned LLMs (PermLLMs) to enforce organizational access control on LLM responses, formalizes correctness proofs, and proposes metrics (DDI and UGI) for empirical evaluation.", "motivation": "Organizational data access control breaks down when LLMs serve users with disparate privileges, necessitating a solution to enforce access control in LLM responses.", "method": "Proposes PermLLMs, formalizes correctness abstractions, and introduces three mechanisms using Parameter Efficient Fine-Tuning. Metrics (DDI and UGI) are developed for evaluation.", "result": "Demonstrates efficacy on four datasets (GPQA, RCV1, SimpleQA, WMDP) and validates DDI and UGI for quantifying access control.", "conclusion": "PermLLMs effectively enforce access control in LLMs, with DDI and UGI providing reliable metrics for evaluation."}}
{"id": "2505.23032", "pdf": "https://arxiv.org/pdf/2505.23032", "abs": "https://arxiv.org/abs/2505.23032", "authors": ["Dongwoo Lee", "Dong Bok Lee", "Steven Adriaensen", "Juho Lee", "Sung Ju Hwang", "Frank Hutter", "Seon Joo Kim", "Hae Beom Lee"], "title": "Bayesian Neural Scaling Laws Extrapolation with Prior-Fitted Networks", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ICML 2025", "summary": "Scaling has been a major driver of recent advancements in deep learning.\nNumerous empirical studies have found that scaling laws often follow the\npower-law and proposed several variants of power-law functions to predict the\nscaling behavior at larger scales. However, existing methods mostly rely on\npoint estimation and do not quantify uncertainty, which is crucial for\nreal-world applications involving decision-making problems such as determining\nthe expected performance improvements achievable by investing additional\ncomputational resources. In this work, we explore a Bayesian framework based on\nPrior-data Fitted Networks (PFNs) for neural scaling law extrapolation.\nSpecifically, we design a prior distribution that enables the sampling of\ninfinitely many synthetic functions resembling real-world neural scaling laws,\nallowing our PFN to meta-learn the extrapolation. We validate the effectiveness\nof our approach on real-world neural scaling laws, comparing it against both\nthe existing point estimation methods and Bayesian approaches. Our method\ndemonstrates superior performance, particularly in data-limited scenarios such\nas Bayesian active learning, underscoring its potential for reliable,\nuncertainty-aware extrapolation in practical applications.", "AI": {"tldr": "A Bayesian framework using Prior-data Fitted Networks (PFNs) is proposed for neural scaling law extrapolation, outperforming point estimation methods by quantifying uncertainty, especially in data-limited scenarios.", "motivation": "Existing scaling law methods lack uncertainty quantification, which is critical for decision-making in resource allocation.", "method": "A Bayesian framework with PFNs is designed, using a prior distribution to sample synthetic functions resembling real scaling laws, enabling meta-learning for extrapolation.", "result": "The method shows superior performance over point estimation and other Bayesian approaches, particularly in data-limited settings like active learning.", "conclusion": "The approach provides reliable, uncertainty-aware extrapolation, making it valuable for practical applications requiring decision-making under uncertainty."}}
{"id": "2505.23126", "pdf": "https://arxiv.org/pdf/2505.23126", "abs": "https://arxiv.org/abs/2505.23126", "authors": ["Atharva Naik", "Darsh Agrawal", "Manav Kapadnis", "Yuwei An", "Yash Mathur", "Carolyn Rose", "David Mortensen"], "title": "PBEBench: A Multi-Step Programming by Examples Reasoning Benchmark inspired by Historical Linguistics", "categories": ["cs.CL"], "comment": null, "summary": "Recently, long chain of thought (LCoT), Large Language Models (LLMs), have\ntaken the machine learning world by storm with their breathtaking reasoning\ncapabilities. However, are the abstract reasoning abilities of these models\ngeneral enough for problems of practical importance? Unlike past work, which\nhas focused mainly on math, coding, and data wrangling, we focus on a\nhistorical linguistics-inspired inductive reasoning problem, formulated as\nProgramming by Examples. We develop a fully automated pipeline for dynamically\ngenerating a benchmark for this task with controllable difficulty in order to\ntackle scalability and contamination issues to which many reasoning benchmarks\nare subject. Using our pipeline, we generate a test set with nearly 1k\ninstances that is challenging for all state-of-the-art reasoning LLMs, with the\nbest model (Claude-3.7-Sonnet) achieving a mere 54% pass rate, demonstrating\nthat LCoT LLMs still struggle with a class or reasoning that is ubiquitous in\nhistorical linguistics as well as many other domains.", "AI": {"tldr": "The paper evaluates the reasoning abilities of LCoT LLMs on historical linguistics tasks, showing they struggle despite strong performance in other domains.", "motivation": "To assess if LCoT LLMs' reasoning is general enough for practical problems like historical linguistics, beyond math and coding.", "method": "Developed an automated pipeline to generate a scalable, contamination-free benchmark with controllable difficulty for Programming by Examples.", "result": "Generated a 1k-instance test set; best model (Claude-3.7-Sonnet) achieved only 54% pass rate, indicating poor performance.", "conclusion": "LCoT LLMs still struggle with reasoning tasks common in historical linguistics and other domains."}}
{"id": "2505.23145", "pdf": "https://arxiv.org/pdf/2505.23145", "abs": "https://arxiv.org/abs/2505.23145", "authors": ["Jeongsol Kim", "Yeobin Hong", "Jong Chul Ye"], "title": "FlowAlign: Trajectory-Regularized, Inversion-Free Flow-based Image Editing", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent inversion-free, flow-based image editing methods such as FlowEdit\nleverages a pre-trained noise-to-image flow model such as Stable Diffusion 3,\nenabling text-driven manipulation by solving an ordinary differential equation\n(ODE). While the lack of exact latent inversion is a core advantage of these\nmethods, it often results in unstable editing trajectories and poor source\nconsistency. To address this limitation, we propose FlowAlign, a novel\ninversion-free flow-based framework for consistent image editing with\nprincipled trajectory control. FlowAlign introduces a flow-matching loss as a\nregularization mechanism to promote smoother and more stable trajectories\nduring the editing process. Notably, the flow-matching loss is shown to\nexplicitly balance semantic alignment with the edit prompt and structural\nconsistency with the source image along the trajectory. Furthermore, FlowAlign\nnaturally supports reverse editing by simply reversing the ODE trajectory,\nhighlighting the reversible and consistent nature of the transformation.\nExtensive experiments demonstrate that FlowAlign outperforms existing methods\nin both source preservation and editing controllability.", "AI": {"tldr": "FlowAlign improves inversion-free flow-based image editing by introducing a flow-matching loss for stable trajectories and better consistency.", "motivation": "Existing inversion-free methods like FlowEdit suffer from unstable editing trajectories and poor source consistency.", "method": "FlowAlign uses a flow-matching loss to regularize trajectories, balancing semantic alignment and structural consistency.", "result": "FlowAlign outperforms existing methods in source preservation and editing controllability.", "conclusion": "FlowAlign offers a reversible and consistent framework for inversion-free image editing."}}
{"id": "2505.22878", "pdf": "https://arxiv.org/pdf/2505.22878", "abs": "https://arxiv.org/abs/2505.22878", "authors": ["Shams Tarek", "Dipayan Saha", "Sujan Kumar Saha", "Farimah Farahmandi"], "title": "BugWhisperer: Fine-Tuning LLMs for SoC Hardware Vulnerability Detection", "categories": ["cs.CR", "cs.AI"], "comment": "This paper was presented at IEEE VLSI Test Symposium (VTS) 2025", "summary": "The current landscape of system-on-chips (SoCs) security verification faces\nchallenges due to manual, labor-intensive, and inflexible methodologies. These\nissues limit the scalability and effectiveness of security protocols, making\nbug detection at the Register-Transfer Level (RTL) difficult. This paper\nproposes a new framework named BugWhisperer that utilizes a specialized,\nfine-tuned Large Language Model (LLM) to address these challenges. By enhancing\nthe LLM's hardware security knowledge and leveraging its capabilities for text\ninference and knowledge transfer, this approach automates and improves the\nadaptability and reusability of the verification process. We introduce an\nopen-source, fine-tuned LLM specifically designed for detecting security\nvulnerabilities in SoC designs. Our findings demonstrate that this tailored LLM\neffectively enhances the efficiency and flexibility of the security\nverification process. Additionally, we introduce a comprehensive hardware\nvulnerability database that supports this work and will further assist the\nresearch community in enhancing the security verification process.", "AI": {"tldr": "BugWhisperer, a framework using a fine-tuned LLM, automates and improves SoC security verification by detecting RTL-level vulnerabilities.", "motivation": "Manual, inflexible SoC security verification methods limit scalability and bug detection.", "method": "A specialized, fine-tuned LLM is developed for automated vulnerability detection, supported by a hardware vulnerability database.", "result": "The tailored LLM enhances verification efficiency and flexibility.", "conclusion": "BugWhisperer offers a scalable, reusable solution for SoC security verification, supported by an open-source LLM and vulnerability database."}}
{"id": "2505.23042", "pdf": "https://arxiv.org/pdf/2505.23042", "abs": "https://arxiv.org/abs/2505.23042", "authors": ["Siwen Wang", "Shitou Zhang", "Wan-Lin Chen", "Dung Truong", "Tzyy-Ping Jung"], "title": "From Theory to Application: Fine-Tuning Large EEG Model with Real-World Stress Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advancements in Large Language Models have inspired the development of\nfoundation models across various domains. In this study, we evaluate the\nefficacy of Large EEG Models (LEMs) by fine-tuning LaBraM, a state-of-the-art\nfoundation EEG model, on a real-world stress classification dataset collected\nin a graduate classroom. Unlike previous studies that primarily evaluate LEMs\nusing data from controlled clinical settings, our work assesses their\napplicability to real-world environments. We train a binary classifier that\ndistinguishes between normal and elevated stress states using resting-state EEG\ndata recorded from 18 graduate students during a class session. The\nbest-performing fine-tuned model achieves a balanced accuracy of 90.47% with a\n5-second window, significantly outperforming traditional stress classifiers in\nboth accuracy and inference efficiency. We further evaluate the robustness of\nthe fine-tuned LEM under random data shuffling and reduced channel counts.\nThese results demonstrate the capability of LEMs to effectively process\nreal-world EEG data and highlight their potential to revolutionize\nbrain-computer interface applications by shifting the focus from model-centric\nto data-centric design.", "AI": {"tldr": "The study evaluates Large EEG Models (LEMs) by fine-tuning LaBraM on real-world stress classification data, achieving high accuracy and robustness.", "motivation": "To assess LEMs' applicability in real-world environments, unlike previous studies focused on controlled clinical settings.", "method": "Fine-tuned LaBraM on resting-state EEG data from 18 graduate students to classify stress states, testing robustness under data shuffling and reduced channels.", "result": "Achieved 90.47% balanced accuracy with a 5-second window, outperforming traditional classifiers in accuracy and efficiency.", "conclusion": "LEMs show promise for real-world EEG processing, potentially revolutionizing brain-computer interfaces by shifting to data-centric design."}}
{"id": "2505.23140", "pdf": "https://arxiv.org/pdf/2505.23140", "abs": "https://arxiv.org/abs/2505.23140", "authors": ["Qiuyu Ding", "Zhiqiang Cao", "Hailong Cao", "Tiejun Zhao"], "title": "Enhancing Large Language Models'Machine Translation via Dynamic Focus Anchoring", "categories": ["cs.CL"], "comment": null, "summary": "Large language models have demonstrated exceptional performance across\nmultiple crosslingual NLP tasks, including machine translation (MT). However,\npersistent challenges remain in addressing context-sensitive units (CSUs), such\nas polysemous words. These CSUs not only affect the local translation accuracy\nof LLMs, but also affect LLMs' understanding capability for sentences and\ntasks, and even lead to translation failure. To address this problem, we\npropose a simple but effective method to enhance LLMs' MT capabilities by\nacquiring CSUs and applying semantic focus. Specifically, we dynamically\nanalyze and identify translation challenges, then incorporate them into LLMs in\na structured manner to mitigate mistranslations or misunderstandings of CSUs\ncaused by information flattening. Efficiently activate LLMs to identify and\napply relevant knowledge from its vast data pool in this way, ensuring more\naccurate translations for translating difficult terms. On a benchmark dataset\nof MT, our proposed method achieved competitive performance compared to\nmultiple existing open-sourced MT baseline models. It demonstrates\neffectiveness and robustness across multiple language pairs, including both\nsimilar language pairs and distant language pairs. Notably, the proposed method\nrequires no additional model training and enhances LLMs' performance across\nmultiple NLP tasks with minimal resource consumption.", "AI": {"tldr": "A method to improve large language models' machine translation by addressing context-sensitive units (CSUs) like polysemous words, enhancing accuracy without additional training.", "motivation": "Persistent challenges in translating CSUs affect LLMs' performance, leading to mistranslations and misunderstandings.", "method": "Dynamically analyze and identify CSUs, apply semantic focus, and incorporate them into LLMs to mitigate errors.", "result": "Achieves competitive performance on MT benchmarks across diverse language pairs without extra training.", "conclusion": "The method is effective, resource-efficient, and enhances LLMs' translation and broader NLP task performance."}}
{"id": "2505.23155", "pdf": "https://arxiv.org/pdf/2505.23155", "abs": "https://arxiv.org/abs/2505.23155", "authors": ["Xiao Yu", "Yan Fang", "Xiaojie Jin", "Yao Zhao", "Yunchao Wei"], "title": "PreFM: Online Audio-Visual Event Parsing via Predictive Future Modeling", "categories": ["cs.CV"], "comment": "20 pages, 8 figures", "summary": "Audio-visual event parsing plays a crucial role in understanding multimodal\nvideo content, but existing methods typically rely on offline processing of\nentire videos with huge model sizes, limiting their real-time applicability. We\nintroduce Online Audio-Visual Event Parsing (On-AVEP), a novel paradigm for\nparsing audio, visual, and audio-visual events by sequentially analyzing\nincoming video streams. The On-AVEP task necessitates models with two key\ncapabilities: (1) Accurate online inference, to effectively distinguish events\nwith unclear and limited context in online settings, and (2) Real-time\nefficiency, to balance high performance with computational constraints. To\ncultivate these, we propose the Predictive Future Modeling (PreFM) framework\nfeatured by (a) predictive multimodal future modeling to infer and integrate\nbeneficial future audio-visual cues, thereby enhancing contextual understanding\nand (b) modality-agnostic robust representation along with focal temporal\nprioritization to improve precision and generalization. Extensive experiments\non the UnAV-100 and LLP datasets show PreFM significantly outperforms\nstate-of-the-art methods by a large margin with significantly fewer parameters,\noffering an insightful approach for real-time multimodal video understanding.\nCode is available at https://github.com/XiaoYu-1123/PreFM.", "AI": {"tldr": "On-AVEP introduces real-time audio-visual event parsing with PreFM, enhancing contextual understanding and efficiency.", "motivation": "Existing methods are offline and computationally heavy, limiting real-time use. On-AVEP addresses this gap.", "method": "Uses Predictive Future Modeling (PreFM) for future cue integration and robust representation.", "result": "Outperforms state-of-the-art on UnAV-100 and LLP datasets with fewer parameters.", "conclusion": "PreFM offers an efficient, real-time solution for multimodal video understanding."}}
{"id": "2505.22880", "pdf": "https://arxiv.org/pdf/2505.22880", "abs": "https://arxiv.org/abs/2505.22880", "authors": ["Xiaoyang Zhan", "Shixin Zhou", "Qianqian Yang", "Yixuan Zhao", "Hao Liu", "Srinivas Chowdary Ramineni", "Kenji Shimada"], "title": "Semantic Exploration and Dense Mapping of Complex Environments using Ground Robots Equipped with LiDAR and Panoramic Camera", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "This paper presents a system for autonomous semantic exploration and dense\nsemantic target mapping of a complex unknown environment using a ground robot\nequipped with a LiDAR-panoramic camera suite. Existing approaches often\nstruggle to balance collecting high-quality observations from multiple view\nangles and avoiding unnecessary repetitive traversal. To fill this gap, we\npropose a complete system combining mapping and planning. We first redefine the\ntask as completing both geometric coverage and semantic viewpoint observation.\nWe then manage semantic and geometric viewpoints separately and propose a novel\nPriority-driven Decoupled Local Sampler to generate local viewpoint sets. This\nenables explicit multi-view semantic inspection and voxel coverage without\nunnecessary repetition. Building on this, we develop a hierarchical planner to\nensure efficient global coverage. In addition, we propose a Safe Aggressive\nExploration State Machine, which allows aggressive exploration behavior while\nensuring the robot's safety. Our system includes a plug-and-play semantic\ntarget mapping module that integrates seamlessly with state-of-the-art SLAM\nalgorithms for pointcloud-level dense semantic target mapping. We validate our\napproach through extensive experiments in both realistic simulations and\ncomplex real-world environments. Simulation results show that our planner\nachieves faster exploration and shorter travel distances while guaranteeing a\nspecified number of multi-view inspections. Real-world experiments further\nconfirm the system's effectiveness in achieving accurate dense semantic object\nmapping of unstructured environments.", "AI": {"tldr": "A system for autonomous semantic exploration and dense semantic mapping using a ground robot with LiDAR-panoramic camera, balancing multi-view observations and avoiding repetitive traversal.", "motivation": "Existing methods struggle with balancing high-quality multi-view observations and avoiding unnecessary traversal in complex environments.", "method": "Combines mapping and planning with a Priority-driven Decoupled Local Sampler for viewpoint sets, hierarchical planning, and a Safe Aggressive Exploration State Machine.", "result": "Achieves faster exploration, shorter travel distances, and accurate dense semantic mapping in simulations and real-world tests.", "conclusion": "The system effectively balances exploration efficiency and semantic mapping accuracy in unstructured environments."}}
{"id": "2505.23048", "pdf": "https://arxiv.org/pdf/2505.23048", "abs": "https://arxiv.org/abs/2505.23048", "authors": ["Tianci Bu", "Le Zhou", "Wenchuan Yang", "Jianhong Mou", "Kang Yang", "Suoyi Tan", "Feng Yao", "Jingyuan Wang", "Xin Lu"], "title": "ProDiff: Prototype-Guided Diffusion for Minimal Information Trajectory Imputation", "categories": ["cs.LG"], "comment": null, "summary": "Trajectory data is crucial for various applications but often suffers from\nincompleteness due to device limitations and diverse collection scenarios.\nExisting imputation methods rely on sparse trajectory or travel information,\nsuch as velocity, to infer missing points. However, these approaches assume\nthat sparse trajectories retain essential behavioral patterns, which place\nsignificant demands on data acquisition and overlook the potential of\nlarge-scale human trajectory embeddings. To address this, we propose ProDiff, a\ntrajectory imputation framework that uses only two endpoints as minimal\ninformation. It integrates prototype learning to embed human movement patterns\nand a denoising diffusion probabilistic model for robust spatiotemporal\nreconstruction. Joint training with a tailored loss function ensures effective\nimputation. ProDiff outperforms state-of-the-art methods, improving accuracy by\n6.28\\% on FourSquare and 2.52\\% on WuXi. Further analysis shows a 0.927\ncorrelation between generated and real trajectories, demonstrating the\neffectiveness of our approach.", "AI": {"tldr": "ProDiff is a trajectory imputation framework using minimal endpoint data, leveraging prototype learning and diffusion models for accurate reconstruction, outperforming existing methods.", "motivation": "Existing trajectory imputation methods rely on sparse data, assuming retained behavioral patterns, which is data-intensive and overlooks large-scale trajectory embeddings.", "method": "ProDiff integrates prototype learning for movement patterns and a denoising diffusion probabilistic model for spatiotemporal reconstruction, trained with a tailored loss function.", "result": "ProDiff improves accuracy by 6.28% on FourSquare and 2.52% on WuXi, with a 0.927 correlation between generated and real trajectories.", "conclusion": "ProDiff effectively addresses trajectory incompleteness with minimal input, demonstrating superior performance and robustness."}}
{"id": "2505.23146", "pdf": "https://arxiv.org/pdf/2505.23146", "abs": "https://arxiv.org/abs/2505.23146", "authors": ["Qiuyu Ding", "Zhiqiang Cao", "Hailong Cao", "Tiejun Zhao"], "title": "Cross-Domain Bilingual Lexicon Induction via Pretrained Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Bilingual Lexicon Induction (BLI) is generally based on common domain data to\nobtain monolingual word embedding, and by aligning the monolingual word\nembeddings to obtain the cross-lingual embeddings which are used to get the\nword translation pairs. In this paper, we propose a new task of BLI, which is\nto use the monolingual corpus of the general domain and target domain to\nextract domain-specific bilingual dictionaries. Motivated by the ability of\nPre-trained models, we propose a method to get better word embeddings that\nbuild on the recent work on BLI. This way, we introduce the Code Switch(Qin et\nal., 2020) firstly in the cross-domain BLI task, which can match differit is\nyet to be seen whether these methods are suitable for bilingual lexicon\nextraction in professional fields. As we can see in table 1, the classic and\nefficient BLI approach, Muse and Vecmap, perform much worse on the Medical\ndataset than on the Wiki dataset. On one hand, the specialized domain data set\nis relatively smaller compared to the generic domain data set generally, and\nspecialized words have a lower frequency, which will directly affect the\ntranslation quality of bilingual dictionaries. On the other hand, static word\nembeddings are widely used for BLI, however, in some specific fields, the\nmeaning of words is greatly influenced by context, in this case, using only\nstatic word embeddings may lead to greater bias. ent strategies in different\ncontexts, making the model more suitable for this task. Experimental results\nshow that our method can improve performances over robust BLI baselines on\nthree specific domains by averagely improving 0.78 points.", "AI": {"tldr": "The paper introduces a new task in Bilingual Lexicon Induction (BLI) for domain-specific bilingual dictionaries, leveraging pre-trained models and code-switching to improve performance in specialized domains.", "motivation": "The motivation is to address the limitations of traditional BLI methods in specialized domains, where smaller datasets and context-dependent word meanings reduce translation quality.", "method": "The method involves using monolingual corpora from general and target domains, incorporating pre-trained models and code-switching techniques to enhance word embeddings.", "result": "The method improves performance over robust BLI baselines by an average of 0.78 points across three specific domains.", "conclusion": "The approach is effective for domain-specific BLI, addressing challenges like data scarcity and contextual word meanings."}}
{"id": "2505.23158", "pdf": "https://arxiv.org/pdf/2505.23158", "abs": "https://arxiv.org/abs/2505.23158", "authors": ["Jonas Kulhanek", "Marie-Julie Rakotosaona", "Fabian Manhardt", "Christina Tsalicoglou", "Michael Niemeyer", "Torsten Sattler", "Songyou Peng", "Federico Tombari"], "title": "LODGE: Level-of-Detail Large-Scale Gaussian Splatting with Efficient Rendering", "categories": ["cs.CV"], "comment": "Web: https://lodge-gs.github.io/", "summary": "In this work, we present a novel level-of-detail (LOD) method for 3D Gaussian\nSplatting that enables real-time rendering of large-scale scenes on\nmemory-constrained devices. Our approach introduces a hierarchical LOD\nrepresentation that iteratively selects optimal subsets of Gaussians based on\ncamera distance, thus largely reducing both rendering time and GPU memory\nusage. We construct each LOD level by applying a depth-aware 3D smoothing\nfilter, followed by importance-based pruning and fine-tuning to maintain visual\nfidelity. To further reduce memory overhead, we partition the scene into\nspatial chunks and dynamically load only relevant Gaussians during rendering,\nemploying an opacity-blending mechanism to avoid visual artifacts at chunk\nboundaries. Our method achieves state-of-the-art performance on both outdoor\n(Hierarchical 3DGS) and indoor (Zip-NeRF) datasets, delivering high-quality\nrenderings with reduced latency and memory requirements.", "AI": {"tldr": "A novel LOD method for 3D Gaussian Splatting enables real-time rendering of large scenes on memory-constrained devices by hierarchical LOD representation, depth-aware smoothing, and dynamic spatial chunking.", "motivation": "To enable real-time rendering of large-scale scenes on devices with limited memory by optimizing Gaussian subsets and reducing rendering time and GPU memory usage.", "method": "Hierarchical LOD representation with depth-aware 3D smoothing, importance-based pruning, fine-tuning, spatial chunking, and dynamic loading of Gaussians.", "result": "Achieves state-of-the-art performance on outdoor (Hierarchical 3DGS) and indoor (Zip-NeRF) datasets with high-quality renderings, reduced latency, and lower memory usage.", "conclusion": "The method effectively balances visual fidelity and performance, making it suitable for memory-constrained real-time applications."}}
{"id": "2505.22889", "pdf": "https://arxiv.org/pdf/2505.22889", "abs": "https://arxiv.org/abs/2505.22889", "authors": ["Hamidreza Montazeri Hedesh", "Moh Kamalul Wafi", "Milad Siami"], "title": "Local Stability and Region of Attraction Analysis for Neural Network Feedback Systems under Positivity Constraints", "categories": ["eess.SY", "cs.AI", "cs.SY", "93D09, 93D20, 93C10, 68T07", "B.1.3; G.1; I.2; I.2.3; I.2.8; I.2.1; J.2"], "comment": "Submitted to 64th IEEE Conference on Decision and Control 2025 - Rio\n  de Janeiro, Brazil", "summary": "We study the local stability of nonlinear systems in the Lur'e form with\nstatic nonlinear feedback realized by feedforward neural networks (FFNNs). By\nleveraging positivity system constraints, we employ a localized variant of the\nAizerman conjecture, which provides sufficient conditions for exponential\nstability of trajectories confined to a compact set. Using this foundation, we\ndevelop two distinct methods for estimating the Region of Attraction (ROA): (i)\na less conservative Lyapunov-based approach that constructs invariant sublevel\nsets of a quadratic function satisfying a linear matrix inequality (LMI), and\n(ii) a novel technique for computing tight local sector bounds for FFNNs via\nlayer-wise propagation of linear relaxations. These bounds are integrated into\nthe localized Aizerman framework to certify local exponential stability.\nNumerical results demonstrate substantial improvements over existing integral\nquadratic constraint-based approaches in both ROA size and scalability.", "AI": {"tldr": "The paper analyzes local stability of nonlinear Lur'e systems with FFNN feedback, proposing two ROA estimation methods for improved stability certification.", "motivation": "To address the challenge of ensuring stability in nonlinear systems with FFNN feedback, leveraging positivity constraints and localized Aizerman conjecture.", "method": "Two approaches: (i) Lyapunov-based LMI for less conservative ROA, (ii) layer-wise linear relaxations for tight FFNN sector bounds.", "result": "Numerical results show significant improvements in ROA size and scalability over existing methods.", "conclusion": "The proposed methods effectively certify local exponential stability, outperforming traditional approaches."}}
{"id": "2505.23049", "pdf": "https://arxiv.org/pdf/2505.23049", "abs": "https://arxiv.org/abs/2505.23049", "authors": ["Tianteng Gu", "Bei Liu", "Bo Xiao", "Ke Zeng", "Jiacheng Liu", "Yanmin Qian"], "title": "DenoiseRotator: Enhance Pruning Robustness for LLMs via Importance Concentration", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Pruning is a widely used technique to compress large language models (LLMs)\nby removing unimportant weights, but it often suffers from significant\nperformance degradation - especially under semi-structured sparsity\nconstraints. Existing pruning methods primarily focus on estimating the\nimportance of individual weights, which limits their ability to preserve\ncritical capabilities of the model. In this work, we propose a new perspective:\nrather than merely selecting which weights to prune, we first redistribute\nparameter importance to make the model inherently more amenable to pruning. By\nminimizing the information entropy of normalized importance scores, our\napproach concentrates importance onto a smaller subset of weights, thereby\nenhancing pruning robustness. We instantiate this idea through DenoiseRotator,\nwhich applies learnable orthogonal transformations to the model's weight\nmatrices. Our method is model-agnostic and can be seamlessly integrated with\nexisting pruning techniques such as Magnitude, SparseGPT, and Wanda. Evaluated\non LLaMA3, Qwen2.5, and Mistral models under 50% unstructured and 2:4\nsemi-structured sparsity, DenoiseRotator consistently improves perplexity and\nzero-shot accuracy. For instance, on LLaMA3-70B pruned with SparseGPT at 2:4\nsemi-structured sparsity, DenoiseRotator reduces the perplexity gap to the\ndense model by 58%, narrowing the degradation from 8.1 to 3.4 points. Codes are\navailable at https://github.com/Axel-gu/DenoiseRotator.", "AI": {"tldr": "The paper introduces DenoiseRotator, a method to enhance pruning robustness in LLMs by redistributing parameter importance, improving performance under sparsity constraints.", "motivation": "Existing pruning methods focus on individual weight importance, leading to performance degradation, especially under semi-structured sparsity. The paper aims to make models more pruning-friendly by concentrating importance on fewer weights.", "method": "DenoiseRotator applies learnable orthogonal transformations to weight matrices, minimizing information entropy of normalized importance scores. It is model-agnostic and compatible with existing pruning techniques.", "result": "DenoiseRotator improves perplexity and zero-shot accuracy on models like LLaMA3, Qwen2.5, and Mistral under 50% unstructured and 2:4 semi-structured sparsity. For LLaMA3-70B, it reduces the perplexity gap by 58%.", "conclusion": "DenoiseRotator effectively enhances pruning robustness by redistributing parameter importance, offering a scalable and compatible solution for LLM compression."}}
{"id": "2505.23166", "pdf": "https://arxiv.org/pdf/2505.23166", "abs": "https://arxiv.org/abs/2505.23166", "authors": ["Li Lucy", "Camilla Griffiths", "Sarah Levine", "Jennifer L. Eberhardt", "Dorottya Demszky", "David Bamman"], "title": "Tell, Don't Show: Leveraging Language Models' Abstractive Retellings to Model Literary Themes", "categories": ["cs.CL"], "comment": "26 pages, 7 figures, Findings of ACL 2025", "summary": "Conventional bag-of-words approaches for topic modeling, like latent\nDirichlet allocation (LDA), struggle with literary text. Literature challenges\nlexical methods because narrative language focuses on immersive sensory details\ninstead of abstractive description or exposition: writers are advised to \"show,\ndon't tell.\" We propose Retell, a simple, accessible topic modeling approach\nfor literature. Here, we prompt resource-efficient, generative language models\n(LMs) to tell what passages show, thereby translating narratives' surface forms\ninto higher-level concepts and themes. By running LDA on LMs' retellings of\npassages, we can obtain more precise and informative topics than by running LDA\nalone or by directly asking LMs to list topics. To investigate the potential of\nour method for cultural analytics, we compare our method's outputs to\nexpert-guided annotations in a case study on racial/cultural identity in high\nschool English language arts books.", "AI": {"tldr": "Retell improves topic modeling for literature by using generative LMs to translate narrative details into higher-level concepts, enhancing LDA's precision.", "motivation": "Traditional methods like LDA struggle with literary texts due to their focus on sensory details over abstract themes.", "method": "Prompt generative LMs to retell passages, then apply LDA to these retellings for better topic extraction.", "result": "Retell produces more precise and informative topics than LDA alone or direct LM topic listing.", "conclusion": "Retell shows promise for cultural analytics, as demonstrated in a case study on racial/cultural identity in literature."}}
{"id": "2505.23161", "pdf": "https://arxiv.org/pdf/2505.23161", "abs": "https://arxiv.org/abs/2505.23161", "authors": ["Antonio D'Orazio", "Maria Rosaria Briglia", "Donato Crisostomi", "Dario Loi", "Emanuele Rodol\u00e0", "Iacopo Masi"], "title": "Implicit Inversion turns CLIP into a Decoder", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "CLIP is a discriminative model trained to align images and text in a shared\nembedding space. Due to its multimodal structure, it serves as the backbone of\nmany generative pipelines, where a decoder is trained to map from the shared\nspace back to images. In this work, we show that image synthesis is\nnevertheless possible using CLIP alone -- without any decoder, training, or\nfine-tuning. Our approach optimizes a frequency-aware implicit neural\nrepresentation that encourages coarse-to-fine generation by stratifying\nfrequencies across network layers. To stabilize this inverse mapping, we\nintroduce adversarially robust initialization, a lightweight Orthogonal\nProcrustes projection to align local text and image embeddings, and a blending\nloss that anchors outputs to natural image statistics. Without altering CLIP's\nweights, this framework unlocks capabilities such as text-to-image generation,\nstyle transfer, and image reconstruction. These findings suggest that\ndiscriminative models may hold untapped generative potential, hidden in plain\nsight.", "AI": {"tldr": "CLIP, a discriminative model, can generate images without a decoder or training by optimizing a frequency-aware neural representation and using stabilization techniques.", "motivation": "To explore the untapped generative potential of discriminative models like CLIP, bypassing the need for decoders or fine-tuning.", "method": "Uses a frequency-aware implicit neural representation, adversarially robust initialization, Orthogonal Procrustes projection, and a blending loss to stabilize image synthesis.", "result": "Enables text-to-image generation, style transfer, and image reconstruction without modifying CLIP's weights.", "conclusion": "Discriminative models like CLIP may have hidden generative capabilities, suggesting broader applications."}}
{"id": "2505.22906", "pdf": "https://arxiv.org/pdf/2505.22906", "abs": "https://arxiv.org/abs/2505.22906", "authors": ["Emmanuel Anaya Gonz\u00e1lez", "Raven Rothkopf", "Sorin Lerner", "Nadia Polikarpova"], "title": "HiLDe: Intentional Code Generation via Human-in-the-Loop Decoding", "categories": ["cs.HC", "cs.AI", "cs.PL"], "comment": "10 pages, 6 figures", "summary": "While AI programming tools hold the promise of increasing programmers'\ncapabilities and productivity to a remarkable degree, they often exclude users\nfrom essential decision-making processes, causing many to effectively \"turn off\ntheir brains\" and over-rely on solutions provided by these systems. These\nbehaviors can have severe consequences in critical domains, like software\nsecurity. We propose Human-in-the-loop Decoding, a novel interaction technique\nthat allows users to observe and directly influence LLM decisions during code\ngeneration, in order to align the model's output with their personal\nrequirements. We implement this technique in HiLDe, a code completion assistant\nthat highlights critical decisions made by the LLM and provides local\nalternatives for the user to explore. In a within-subjects study (N=18) on\nsecurity-related tasks, we found that HiLDe led participants to generate\nsignificantly fewer vulnerabilities and better align code generation with their\ngoals compared to a traditional code completion assistant.", "AI": {"tldr": "HiLDe, a Human-in-the-loop Decoding technique, improves code generation by involving users in LLM decisions, reducing vulnerabilities and aligning outputs with user goals.", "motivation": "AI programming tools often exclude users from decision-making, leading to over-reliance and potential security risks.", "method": "Proposed Human-in-the-loop Decoding, implemented in HiLDe, which highlights LLM decisions and offers local alternatives.", "result": "HiLDe reduced vulnerabilities and better aligned code generation with user goals in a study (N=18).", "conclusion": "Human-in-the-loop techniques like HiLDe enhance AI tool effectiveness and user control in critical domains."}}
{"id": "2505.23055", "pdf": "https://arxiv.org/pdf/2505.23055", "abs": "https://arxiv.org/abs/2505.23055", "authors": ["Zhen Xiang", "Aliyah R. Hsu", "Austin V. Zane", "Aaron E. Kornblith", "Margaret J. Lin-Martore", "Jasmanpreet C. Kaur", "Vasuda M. Dokiparthi", "Bo Li", "Bin Yu"], "title": "CDR-Agent: Intelligent Selection and Execution of Clinical Decision Rules Using Large Language Model Agents", "categories": ["cs.LG"], "comment": null, "summary": "Clinical decision-making is inherently complex and fast-paced, particularly\nin emergency departments (EDs) where critical, rapid and high-stakes decisions\nare made. Clinical Decision Rules (CDRs) are standardized evidence-based tools\nthat combine signs, symptoms, and clinical variables into decision trees to\nmake consistent and accurate diagnoses. CDR usage is often hindered by the\nclinician's cognitive load, limiting their ability to quickly recall and apply\nthe appropriate rules. We introduce CDR-Agent, a novel LLM-based system\ndesigned to enhance ED decision-making by autonomously identifying and applying\nthe most appropriate CDRs based on unstructured clinical notes. To validate\nCDR-Agent, we curated two novel ED datasets: synthetic and CDR-Bench, although\nCDR-Agent is applicable to non ED clinics. CDR-Agent achieves a 56.3\\%\n(synthetic) and 8.7\\% (CDR-Bench) accuracy gain relative to the standalone LLM\nbaseline in CDR selection. Moreover, CDR-Agent significantly reduces\ncomputational overhead. Using these datasets, we demonstrated that CDR-Agent\nnot only selects relevant CDRs efficiently, but makes cautious yet effective\nimaging decisions by minimizing unnecessary interventions while successfully\nidentifying most positively diagnosed cases, outperforming traditional LLM\nprompting approaches. Code for our work can be found at:\nhttps://github.com/zhenxianglance/medagent-cdr-agent", "AI": {"tldr": "CDR-Agent, an LLM-based system, improves emergency department decision-making by autonomously applying Clinical Decision Rules (CDRs) from unstructured notes, outperforming standalone LLMs in accuracy and efficiency.", "motivation": "The complexity and urgency of clinical decision-making in EDs, coupled with cognitive load hindering CDR application, drive the need for an automated solution.", "method": "CDR-Agent uses LLMs to identify and apply CDRs from unstructured clinical notes, validated on synthetic and CDR-Bench datasets.", "result": "CDR-Agent achieves 56.3% (synthetic) and 8.7% (CDR-Bench) accuracy gains over standalone LLMs, reduces computational overhead, and optimizes imaging decisions.", "conclusion": "CDR-Agent enhances ED decision-making by efficiently selecting CDRs and minimizing unnecessary interventions, outperforming traditional LLM approaches."}}
{"id": "2505.23174", "pdf": "https://arxiv.org/pdf/2505.23174", "abs": "https://arxiv.org/abs/2505.23174", "authors": ["Naman Ahuja", "Fenil Bardoliya", "Chitta Baral", "Vivek Gupta"], "title": "Map&Make: Schema Guided Text to Table Generation", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025", "summary": "Transforming dense, detailed, unstructured text into an interpretable and\nsummarised table, also colloquially known as Text-to-Table generation, is an\nessential task for information retrieval. Current methods, however, miss out on\nhow and what complex information to extract; they also lack the ability to\ninfer data from the text. In this paper, we introduce a versatile approach,\nMap&Make, which \"dissects\" text into propositional atomic statements. This\nfacilitates granular decomposition to extract the latent schema. The schema is\nthen used to populate the tables that capture the qualitative nuances and the\nquantitative facts in the original text. Our approach is tested against two\nchallenging datasets, Rotowire, renowned for its complex and multi-table\nschema, and Livesum, which demands numerical aggregation. By carefully\nidentifying and correcting hallucination errors in Rotowire, we aim to achieve\na cleaner and more reliable benchmark. We evaluate our method rigorously on a\ncomprehensive suite of comparative and referenceless metrics. Our findings\ndemonstrate significant improvement results across both datasets with better\ninterpretability in Text-to-Table generation. Moreover, through detailed\nablation studies and analyses, we investigate the factors contributing to\nsuperior performance and validate the practicality of our framework in\nstructured summarization tasks.", "AI": {"tldr": "The paper introduces Map&Make, a method for Text-to-Table generation that decomposes text into atomic statements to extract latent schemas, improving interpretability and performance.", "motivation": "Current Text-to-Table methods fail to handle complex information extraction and lack inference capabilities, necessitating a more versatile approach.", "method": "Map&Make dissects text into propositional atomic statements to extract latent schemas, which populate tables capturing qualitative and quantitative details.", "result": "The method shows significant improvements on Rotowire and Livesum datasets, with better interpretability and reduced hallucination errors.", "conclusion": "Map&Make validates its practicality and superior performance in structured summarization tasks through rigorous evaluation and ablation studies."}}
{"id": "2505.23171", "pdf": "https://arxiv.org/pdf/2505.23171", "abs": "https://arxiv.org/abs/2505.23171", "authors": ["Liu Liu", "Xiaofeng Wang", "Guosheng Zhao", "Keyu Li", "Wenkang Qin", "Jiaxiong Qiu", "Zheng Zhu", "Guan Huang", "Zhizhong Su"], "title": "RoboTransfer: Geometry-Consistent Video Diffusion for Robotic Visual Policy Transfer", "categories": ["cs.CV"], "comment": "20 pages, 15 figures", "summary": "Imitation Learning has become a fundamental approach in robotic manipulation.\nHowever, collecting large-scale real-world robot demonstrations is\nprohibitively expensive. Simulators offer a cost-effective alternative, but the\nsim-to-real gap make it extremely challenging to scale. Therefore, we introduce\nRoboTransfer, a diffusion-based video generation framework for robotic data\nsynthesis. Unlike previous methods, RoboTransfer integrates multi-view geometry\nwith explicit control over scene components, such as background and object\nattributes. By incorporating cross-view feature interactions and global\ndepth/normal conditions, RoboTransfer ensures geometry consistency across\nviews. This framework allows fine-grained control, including background edits\nand object swaps. Experiments demonstrate that RoboTransfer is capable of\ngenerating multi-view videos with enhanced geometric consistency and visual\nfidelity. In addition, policies trained on the data generated by RoboTransfer\nachieve a 33.3% relative improvement in the success rate in the DIFF-OBJ\nsetting and a substantial 251% relative improvement in the more challenging\nDIFF-ALL scenario. Explore more demos on our project page:\nhttps://horizonrobotics.github.io/robot_lab/robotransfer", "AI": {"tldr": "RoboTransfer is a diffusion-based video generation framework for robotic data synthesis, addressing the sim-to-real gap by ensuring geometric consistency and fine-grained control.", "motivation": "Collecting large-scale real-world robot demonstrations is expensive, and simulators face challenges due to the sim-to-real gap.", "method": "RoboTransfer integrates multi-view geometry with explicit control over scene components, using cross-view feature interactions and global depth/normal conditions.", "result": "Policies trained on RoboTransfer-generated data show a 33.3% improvement in DIFF-OBJ and 251% in DIFF-ALL scenarios.", "conclusion": "RoboTransfer effectively bridges the sim-to-real gap, enhancing robotic manipulation performance."}}
{"id": "2505.22909", "pdf": "https://arxiv.org/pdf/2505.22909", "abs": "https://arxiv.org/abs/2505.22909", "authors": ["Cristian Chica", "Yinglong Guo", "Gilad Lerman"], "title": "Learning to Charge More: A Theoretical Study of Collusion by Q-Learning Agents", "categories": ["econ.GN", "cs.AI", "cs.GT", "q-fin.EC"], "comment": null, "summary": "There is growing experimental evidence that $Q$-learning agents may learn to\ncharge supracompetitive prices. We provide the first theoretical explanation\nfor this behavior in infinite repeated games. Firms update their pricing\npolicies based solely on observed profits, without computing equilibrium\nstrategies. We show that when the game admits both a one-stage Nash equilibrium\nprice and a collusive-enabling price, and when the $Q$-function satisfies\ncertain inequalities at the end of experimentation, firms learn to consistently\ncharge supracompetitive prices. We introduce a new class of one-memory subgame\nperfect equilibria (SPEs) and provide conditions under which learned behavior\nis supported by naive collusion, grim trigger policies, or increasing\nstrategies. Naive collusion does not constitute an SPE unless the\ncollusive-enabling price is a one-stage Nash equilibrium, whereas grim trigger\npolicies can.", "AI": {"tldr": "The paper explains why Q-learning agents may charge supracompetitive prices in infinite repeated games, showing conditions under which learned behavior aligns with collusion or equilibrium strategies.", "motivation": "To provide a theoretical explanation for experimental observations of Q-learning agents charging supracompetitive prices in repeated games.", "method": "Analyze firms updating pricing policies based on observed profits, without computing equilibrium strategies, and introduce one-memory subgame perfect equilibria (SPEs).", "result": "Firms learn to charge supracompetitive prices when certain Q-function inequalities hold, and learned behavior aligns with naive collusion, grim trigger policies, or increasing strategies.", "conclusion": "Naive collusion is not an SPE unless the collusive-enabling price is a Nash equilibrium, but grim trigger policies can support learned behavior as an SPE."}}
{"id": "2505.23061", "pdf": "https://arxiv.org/pdf/2505.23061", "abs": "https://arxiv.org/abs/2505.23061", "authors": ["Tarun Suresh", "Debangshu Banerjee", "Shubham Ugare", "Sasa Misailovic", "Gagandeep Singh"], "title": "DINGO: Constrained Inference for Diffusion LLMs", "categories": ["cs.LG", "cs.PL", "cs.SE"], "comment": "DINGO an algorithm to provably apply constraints to diffusion LLM\n  generations", "summary": "Diffusion LLMs have emerged as a promising alternative to conventional\nautoregressive LLMs, offering significant potential for improved runtime\nefficiency. However, existing diffusion models lack the ability to provably\nenforce user-specified formal constraints, such as regular expressions, which\nmakes them unreliable for tasks that require structured outputs, such as\nfixed-schema JSON generation. Unlike autoregressive models that generate tokens\nsequentially, diffusion LLMs predict a block of tokens in parallel. This\nparallelism makes traditional constrained decoding algorithms, which are\ndesigned for sequential token prediction, ineffective at preserving the true\noutput distribution. To address this limitation, we propose DINGO, a dynamic\nprogramming-based constrained decoding strategy that is both efficient and\nprovably distribution-preserving. DINGO enables sampling of output strings with\nthe highest probability under the model's predicted distribution, while\nstrictly satisfying any user-specified regular expression. On standard symbolic\nmath and JSON generation benchmarks, DINGO achieves up to a 68 percentage point\nimprovement over unconstrained inference", "AI": {"tldr": "DINGO is a dynamic programming-based constrained decoding strategy for diffusion LLMs, ensuring structured outputs while preserving the model's distribution.", "motivation": "Existing diffusion LLMs lack the ability to enforce formal constraints like regular expressions, making them unreliable for structured tasks.", "method": "Proposes DINGO, a dynamic programming approach for constrained decoding in parallel token prediction.", "result": "DINGO improves structured output generation by up to 68 percentage points over unconstrained inference.", "conclusion": "DINGO effectively bridges the gap between diffusion LLMs and structured output requirements."}}
{"id": "2505.23177", "pdf": "https://arxiv.org/pdf/2505.23177", "abs": "https://arxiv.org/abs/2505.23177", "authors": ["Wenjing Xing", "Wenke Lu", "Yeheng Duan", "Bing Zhao", "Zhenghui kang", "Yaolong Wang", "Kai Gao", "Lei Qiao"], "title": "Infinite-Instruct: Synthesizing Scaling Code instruction Data with Bidirectional Synthesis and Static Verification", "categories": ["cs.CL"], "comment": null, "summary": "Traditional code instruction data synthesis methods suffer from limited\ndiversity and poor logic. We introduce Infinite-Instruct, an automated\nframework for synthesizing high-quality question-answer pairs, designed to\nenhance the code generation capabilities of large language models (LLMs). The\nframework focuses on improving the internal logic of synthesized problems and\nthe quality of synthesized code. First, \"Reverse Construction\" transforms code\nsnippets into diverse programming problems. Then, through \"Backfeeding\nConstruction,\" keywords in programming problems are structured into a knowledge\ngraph to reconstruct them into programming problems with stronger internal\nlogic. Finally, a cross-lingual static code analysis pipeline filters invalid\nsamples to ensure data quality. Experiments show that on mainstream code\ngeneration benchmarks, our fine-tuned models achieve an average performance\nimprovement of 21.70% on 7B-parameter models and 36.95% on 32B-parameter\nmodels. Using less than one-tenth of the instruction fine-tuning data, we\nachieved performance comparable to the Qwen-2.5-Coder-Instruct.\nInfinite-Instruct provides a scalable solution for LLM training in programming.\nWe open-source the datasets used in the experiments, including both unfiltered\nversions and filtered versions via static analysis. The data are available at\nhttps://github.com/xingwenjing417/Infinite-Instruct-dataset", "AI": {"tldr": "Infinite-Instruct automates high-quality question-answer pair synthesis for LLM code generation, improving diversity, logic, and quality via reverse and backfeeding construction, plus static analysis.", "motivation": "Address limitations of traditional code instruction synthesis (low diversity, poor logic) to enhance LLM code generation.", "method": "Uses 'Reverse Construction' to turn code into problems, 'Backfeeding Construction' to structure keywords into a knowledge graph, and static analysis for filtering.", "result": "Fine-tuned models show 21.70% (7B) and 36.95% (32B) performance gains, matching Qwen-2.5-Coder-Instruct with less data.", "conclusion": "Infinite-Instruct offers a scalable solution for LLM programming training, with open-sourced datasets."}}
{"id": "2505.23179", "pdf": "https://arxiv.org/pdf/2505.23179", "abs": "https://arxiv.org/abs/2505.23179", "authors": ["Sungjune Park", "Hyunjun Kim", "Junho Kim", "Seongho Kim", "Yong Man Ro"], "title": "DIP-R1: Deep Inspection and Perception with RL Looking Through and Understanding Complex Scenes", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have demonstrated significant visual\nunderstanding capabilities, yet their fine-grained visual perception in complex\nreal-world scenarios, such as densely crowded public areas, remains limited.\nInspired by the recent success of reinforcement learning (RL) in both LLMs and\nMLLMs, in this paper, we explore how RL can enhance visual perception ability\nof MLLMs. Then we develop a novel RL-based framework, Deep Inspection and\nPerception with RL (DIP-R1) designed to enhance the visual perception\ncapabilities of MLLMs, by comprehending complex scenes and looking through\nvisual instances closely. DIP-R1 guides MLLMs through detailed inspection of\nvisual scene via three simply designed rule-based reward modelings. First, we\nadopt a standard reasoning reward encouraging the model to include three\nstep-by-step processes: 1) reasoning for understanding visual scenes, 2)\nobserving for looking through interested but ambiguous regions, and 3)\ndecision-making for predicting answer. Second, a variance-guided looking reward\nis designed to examine uncertain regions for the second observing process. It\nexplicitly enables the model to inspect ambiguous areas, improving its ability\nto mitigate perceptual uncertainties. Third, we model a weighted\nprecision-recall accuracy reward enhancing accurate decision-making. We explore\nits effectiveness across diverse fine-grained object detection data consisting\nof challenging real-world environments, such as densely crowded scenes. Built\nupon existing MLLMs, DIP-R1 achieves consistent and significant improvement\nacross various in-domain and out-of-domain scenarios. It also outperforms\nvarious existing baseline models and supervised fine-tuning methods. Our\nfindings highlight the substantial potential of integrating RL into MLLMs for\nenhancing capabilities in complex real-world perception tasks.", "AI": {"tldr": "The paper introduces DIP-R1, an RL-based framework to enhance MLLMs' fine-grained visual perception in complex scenes, outperforming baselines and supervised methods.", "motivation": "MLLMs lack fine-grained visual perception in complex scenarios like crowded areas. RL's success in LLMs and MLLMs inspired its use to improve this capability.", "method": "DIP-R1 uses three rule-based rewards: reasoning, variance-guided looking, and precision-recall accuracy, to guide MLLMs in detailed scene inspection.", "result": "DIP-R1 improves performance in diverse fine-grained detection tasks, including crowded scenes, and outperforms baselines and supervised methods.", "conclusion": "Integrating RL into MLLMs shows great potential for enhancing complex real-world perception tasks."}}
{"id": "2505.22939", "pdf": "https://arxiv.org/pdf/2505.22939", "abs": "https://arxiv.org/abs/2505.22939", "authors": ["Niclas Boehmer", "Sara Fish", "Ariel D. Procaccia"], "title": "Generative Social Choice: The Next Generation", "categories": ["cs.GT", "cs.AI", "cs.LG"], "comment": "Accepted to ICML 2025", "summary": "A key task in certain democratic processes is to produce a concise slate of\nstatements that proportionally represents the full spectrum of user opinions.\nThis task is similar to committee elections, but unlike traditional settings,\nthe candidate set comprises all possible statements of varying lengths, and so\nit can only be accessed through specific queries. Combining social choice and\nlarge language models, prior work has approached this challenge through a\nframework of generative social choice. We extend the framework in two\nfundamental ways, providing theoretical guarantees even in the face of\napproximately optimal queries and a budget limit on the overall length of the\nslate. Using GPT-4o to implement queries, we showcase our approach on datasets\nrelated to city improvement measures and drug reviews, demonstrating its\neffectiveness in generating representative slates from unstructured user\nopinions.", "AI": {"tldr": "Extends generative social choice framework with theoretical guarantees for proportional representation of opinions, even with approximate queries and budget constraints, using GPT-4o for implementation.", "motivation": "To address the challenge of proportionally representing diverse user opinions in democratic processes, especially when the candidate set is vast and unstructured.", "method": "Extends generative social choice by incorporating theoretical guarantees for approximate queries and budget limits, implemented using GPT-4o.", "result": "Demonstrated effectiveness in generating representative slates from unstructured opinions in city improvement and drug review datasets.", "conclusion": "The extended framework successfully balances representation and practicality, offering a scalable solution for democratic opinion aggregation."}}
{"id": "2505.23062", "pdf": "https://arxiv.org/pdf/2505.23062", "abs": "https://arxiv.org/abs/2505.23062", "authors": ["Lingkai Kong", "Haichuan Wang", "Tonghan Wang", "Guojun Xiong", "Milind Tambe"], "title": "Composite Flow Matching for Reinforcement Learning with Shifted-Dynamics Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Incorporating pre-collected offline data from a source environment can\nsignificantly improve the sample efficiency of reinforcement learning (RL), but\nthis benefit is often challenged by discrepancies between the transition\ndynamics of the source and target environments. Existing methods typically\naddress this issue by penalizing or filtering out source transitions in high\ndynamics-gap regions. However, their estimation of the dynamics gap often\nrelies on KL divergence or mutual information, which can be ill-defined when\nthe source and target dynamics have disjoint support. To overcome these\nlimitations, we propose CompFlow, a method grounded in the theoretical\nconnection between flow matching and optimal transport. Specifically, we model\nthe target dynamics as a conditional flow built upon the output distribution of\nthe source-domain flow, rather than learning it directly from a Gaussian prior.\nThis composite structure offers two key advantages: (1) improved generalization\nfor learning target dynamics, and (2) a principled estimation of the dynamics\ngap via the Wasserstein distance between source and target transitions.\nLeveraging our principled estimation of the dynamics gap, we further introduce\nan optimistic active data collection strategy that prioritizes exploration in\nregions of high dynamics gap, and theoretically prove that it reduces the\nperformance disparity with the optimal policy. Empirically, CompFlow\noutperforms strong baselines across several RL benchmarks with shifted\ndynamics.", "AI": {"tldr": "CompFlow improves RL sample efficiency by addressing dynamics discrepancies between source and target environments using flow matching and optimal transport, outperforming baselines.", "motivation": "Existing methods for handling dynamics discrepancies in RL rely on ill-defined metrics like KL divergence, which fail when source and target dynamics have disjoint support.", "method": "CompFlow models target dynamics as a conditional flow built on source-domain flow, using Wasserstein distance for principled dynamics gap estimation and an optimistic active data collection strategy.", "result": "CompFlow outperforms baselines in RL benchmarks with shifted dynamics, demonstrating improved generalization and reduced performance disparity.", "conclusion": "CompFlow provides a robust solution for leveraging offline data in RL by addressing dynamics gaps theoretically and empirically."}}
{"id": "2505.23183", "pdf": "https://arxiv.org/pdf/2505.23183", "abs": "https://arxiv.org/abs/2505.23183", "authors": ["Gabriele Sarti", "Vil\u00e9m Zouhar", "Malvina Nissim", "Arianna Bisazza"], "title": "Unsupervised Word-level Quality Estimation for Machine Translation Through the Lens of Annotators (Dis)agreement", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "Under review. Code:\n  https://github.com/gsarti/labl/tree/main/examples/unsup_wqe Metrics:\n  https://huggingface.co/datasets/gsarti/unsup_wqe_metrics", "summary": "Word-level quality estimation (WQE) aims to automatically identify\nfine-grained error spans in machine-translated outputs and has found many uses,\nincluding assisting translators during post-editing. Modern WQE techniques are\noften expensive, involving prompting of large language models or ad-hoc\ntraining on large amounts of human-labeled data. In this work, we investigate\nefficient alternatives exploiting recent advances in language model\ninterpretability and uncertainty quantification to identify translation errors\nfrom the inner workings of translation models. In our evaluation spanning 14\nmetrics across 12 translation directions, we quantify the impact of human label\nvariation on metric performance by using multiple sets of human labels. Our\nresults highlight the untapped potential of unsupervised metrics, the\nshortcomings of supervised methods when faced with label uncertainty, and the\nbrittleness of single-annotator evaluation practices.", "AI": {"tldr": "The paper explores efficient alternatives to costly word-level quality estimation (WQE) methods by leveraging language model interpretability and uncertainty quantification, evaluating their performance across diverse metrics and translation directions.", "motivation": "Modern WQE techniques are expensive and rely on large language models or extensive labeled data. The study aims to find efficient alternatives using model interpretability and uncertainty.", "method": "The approach uses language model interpretability and uncertainty quantification to identify translation errors from translation models' inner workings. Evaluation involves 14 metrics across 12 translation directions, using multiple human label sets.", "result": "Results show the potential of unsupervised metrics, the limitations of supervised methods under label uncertainty, and the fragility of single-annotator evaluations.", "conclusion": "The study highlights the promise of unsupervised WQE methods and the need to address label uncertainty in supervised approaches."}}
{"id": "2505.23180", "pdf": "https://arxiv.org/pdf/2505.23180", "abs": "https://arxiv.org/abs/2505.23180", "authors": ["Ping Wang", "Lishun Wang", "Gang Qu", "Xiaodong Wang", "Yulun Zhang", "Xin Yuan"], "title": "Proximal Algorithm Unrolling: Flexible and Efficient Reconstruction Networks for Single-Pixel Imaging", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted by CVPR 2025", "summary": "Deep-unrolling and plug-and-play (PnP) approaches have become the de-facto\nstandard solvers for single-pixel imaging (SPI) inverse problem. PnP\napproaches, a class of iterative algorithms where regularization is implicitly\nperformed by an off-the-shelf deep denoiser, are flexible for varying\ncompression ratios (CRs) but are limited in reconstruction accuracy and speed.\nConversely, unrolling approaches, a class of multi-stage neural networks where\na truncated iterative optimization process is transformed into an end-to-end\ntrainable network, typically achieve better accuracy with faster inference but\nrequire fine-tuning or even retraining when CR changes. In this paper, we\naddress the challenge of integrating the strengths of both classes of solvers.\nTo this end, we design an efficient deep image restorer (DIR) for the unrolling\nof HQS (half quadratic splitting) and ADMM (alternating direction method of\nmultipliers). More importantly, a general proximal trajectory (PT) loss\nfunction is proposed to train HQS/ADMM-unrolling networks such that learned DIR\napproximates the proximal operator of an ideal explicit restoration\nregularizer. Extensive experiments demonstrate that, the resulting proximal\nunrolling networks can not only flexibly handle varying CRs with a single model\nlike PnP algorithms, but also outperform previous CR-specific unrolling\nnetworks in both reconstruction accuracy and speed. Source codes and models are\navailable at https://github.com/pwangcs/ProxUnroll.", "AI": {"tldr": "The paper proposes a method to combine the strengths of deep-unrolling and plug-and-play (PnP) approaches for single-pixel imaging (SPI) by designing a deep image restorer (DIR) and a proximal trajectory (PT) loss function, achieving flexibility and superior performance.", "motivation": "To integrate the flexibility of PnP approaches (handling varying compression ratios) with the accuracy and speed of unrolling methods (better reconstruction but CR-specific).", "method": "Designs a deep image restorer (DIR) for unrolling HQS and ADMM, and introduces a PT loss function to train the networks, approximating an ideal regularizer's proximal operator.", "result": "The proposed proximal unrolling networks handle varying CRs with a single model, outperforming previous CR-specific unrolling networks in accuracy and speed.", "conclusion": "The method successfully combines PnP flexibility with unrolling accuracy and speed, validated by extensive experiments."}}
{"id": "2505.23063", "pdf": "https://arxiv.org/pdf/2505.23063", "abs": "https://arxiv.org/abs/2505.23063", "authors": ["Denis Mamba Kabala", "Adel Hafiane", "Laurent Bobelin", "Raphael Canals"], "title": "Loss-Guided Model Sharing and Local Learning Correction in Decentralized Federated Learning for Crop Disease Classification", "categories": ["cs.LG"], "comment": null, "summary": "Crop disease detection and classification is a critical challenge in\nagriculture, with major implications for productivity, food security, and\nenvironmental sustainability. While deep learning models such as CNN and ViT\nhave shown excellent performance in classifying plant diseases from images,\ntheir large-scale deployment is often limited by data privacy concerns.\nFederated Learning (FL) addresses this issue, but centralized FL remains\nvulnerable to single-point failures and scalability limits. In this paper, we\nintroduce a novel Decentralized Federated Learning (DFL) framework that uses\nvalidation loss (Loss_val) both to guide model sharing between peers and to\ncorrect local training via an adaptive loss function controlled by weighting\nparameter. We conduct extensive experiments using PlantVillage datasets with\nthree deep learning architectures (ResNet50, VGG16, and ViT_B16), analyzing the\nimpact of weighting parameter, the number of shared models, the number of\nclients, and the use of Loss_val versus Loss_train of other clients. Results\ndemonstrate that our DFL approach not only improves accuracy and convergence\nspeed, but also ensures better generalization and robustness across\nheterogeneous data environments making it particularly well-suited for\nprivacy-preserving agricultural applications.", "AI": {"tldr": "A Decentralized Federated Learning (DFL) framework is introduced for crop disease detection, improving accuracy, convergence, and privacy in agriculture.", "motivation": "Addressing data privacy and scalability issues in centralized Federated Learning for crop disease classification.", "method": "Proposes DFL using validation loss for model sharing and adaptive loss correction, tested with ResNet50, VGG16, and ViT_B16 on PlantVillage datasets.", "result": "DFL enhances accuracy, convergence speed, generalization, and robustness in heterogeneous data environments.", "conclusion": "DFL is effective for privacy-preserving agricultural applications, outperforming traditional FL methods."}}
{"id": "2505.23191", "pdf": "https://arxiv.org/pdf/2505.23191", "abs": "https://arxiv.org/abs/2505.23191", "authors": ["Jinglong Gao", "Xiao Ding", "Lingxiao Zou", "Bibo Cai", "Bing Qin", "Ting Liu"], "title": "ExpeTrans: LLMs Are Experiential Transfer Learners", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 12 figs/tables", "summary": "Recent studies provide large language models (LLMs) with textual task-solving\nexperiences via prompts to improve their performance. However, previous methods\nrely on substantial human labor or time to gather such experiences for each\ntask, which is impractical given the growing variety of task types in user\nqueries to LLMs. To address this issue, we design an autonomous experience\ntransfer framework to explore whether LLMs can mimic human cognitive\nintelligence to autonomously transfer experience from existing source tasks to\nnewly encountered target tasks. This not only allows the acquisition of\nexperience without extensive costs of previous methods, but also offers a novel\npath for the generalization of LLMs. Experimental results on 13 datasets\ndemonstrate that our framework effectively improves the performance of LLMs.\nFurthermore, we provide a detailed analysis of each module in the framework.", "AI": {"tldr": "The paper introduces an autonomous experience transfer framework for LLMs to improve performance by transferring knowledge from source to target tasks, reducing human labor and time costs.", "motivation": "To address the impracticality of gathering task-solving experiences manually for diverse LLM tasks, the paper explores autonomous experience transfer.", "method": "An autonomous experience transfer framework is designed to mimic human cognitive intelligence for transferring knowledge between tasks.", "result": "Experiments on 13 datasets show the framework effectively enhances LLM performance.", "conclusion": "The framework offers a cost-effective and novel approach for LLM generalization, with detailed module analysis provided."}}
{"id": "2505.23186", "pdf": "https://arxiv.org/pdf/2505.23186", "abs": "https://arxiv.org/abs/2505.23186", "authors": ["Junyi Guo", "Jingxuan Zhang", "Fangyu Wu", "Huanda Lu", "Qiufeng Wang", "Wenmian Yang", "Eng Gee Lim", "Dongming Lu"], "title": "HiGarment: Cross-modal Harmony Based Diffusion Model for Flat Sketch to Realistic Garment Image", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion-based garment synthesis tasks primarily focus on the design phase\nin the fashion domain, while the garment production process remains largely\nunderexplored. To bridge this gap, we introduce a new task: Flat Sketch to\nRealistic Garment Image (FS2RG), which generates realistic garment images by\nintegrating flat sketches and textual guidance. FS2RG presents two key\nchallenges: 1) fabric characteristics are solely guided by textual prompts,\nproviding insufficient visual supervision for diffusion-based models, which\nlimits their ability to capture fine-grained fabric details; 2) flat sketches\nand textual guidance may provide conflicting information, requiring the model\nto selectively preserve or modify garment attributes while maintaining\nstructural coherence. To tackle this task, we propose HiGarment, a novel\nframework that comprises two core components: i) a multi-modal semantic\nenhancement mechanism that enhances fabric representation across textual and\nvisual modalities, and ii) a harmonized cross-attention mechanism that\ndynamically balances information from flat sketches and text prompts, allowing\ncontrollable synthesis by generating either sketch-aligned (image-biased) or\ntext-guided (text-biased) outputs. Furthermore, we collect Multi-modal Detailed\nGarment, the largest open-source dataset for garment generation. Experimental\nresults and user studies demonstrate the effectiveness of HiGarment in garment\nsynthesis. The code and dataset will be released.", "AI": {"tldr": "The paper introduces FS2RG, a task for generating realistic garment images from flat sketches and text, addressing challenges like fabric detail capture and conflicting inputs. It proposes HiGarment, a framework with multi-modal enhancement and cross-attention mechanisms, and releases a new dataset.", "motivation": "To bridge the gap in garment production by exploring realistic image generation from flat sketches and text, addressing limitations in fabric detail and input conflicts.", "method": "Proposes HiGarment, featuring multi-modal semantic enhancement for fabric representation and harmonized cross-attention to balance sketch and text inputs.", "result": "HiGarment effectively synthesizes garments, validated by experiments and user studies. A new dataset is introduced.", "conclusion": "HiGarment advances garment synthesis by addressing key challenges, with potential impact on fashion design and production."}}
{"id": "2505.23020", "pdf": "https://arxiv.org/pdf/2505.23020", "abs": "https://arxiv.org/abs/2505.23020", "authors": ["Jinchuan Zhang", "Lu Yin", "Yan Zhou", "Songlin Hu"], "title": "AgentAlign: Navigating Safety Alignment in the Shift from Informative to Agentic Large Language Models", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": "Submitted to ACL 2025", "summary": "The acquisition of agentic capabilities has transformed LLMs from \"knowledge\nproviders\" to \"action executors\", a trend that while expanding LLMs' capability\nboundaries, significantly increases their susceptibility to malicious use.\nPrevious work has shown that current LLM-based agents execute numerous\nmalicious tasks even without being attacked, indicating a deficiency in agentic\nuse safety alignment during the post-training phase. To address this gap, we\npropose AgentAlign, a novel framework that leverages abstract behavior chains\nas a medium for safety alignment data synthesis. By instantiating these\nbehavior chains in simulated environments with diverse tool instances, our\nframework enables the generation of highly authentic and executable\ninstructions while capturing complex multi-step dynamics. The framework further\nensures model utility by proportionally synthesizing benign instructions\nthrough non-malicious interpretations of behavior chains, precisely calibrating\nthe boundary between helpfulness and harmlessness. Evaluation results on\nAgentHarm demonstrate that fine-tuning three families of open-source models\nusing our method substantially improves their safety (35.8% to 79.5%\nimprovement) while minimally impacting or even positively enhancing their\nhelpfulness, outperforming various prompting methods. The dataset and code have\nboth been open-sourced.", "AI": {"tldr": "AgentAlign improves LLM safety by synthesizing alignment data using abstract behavior chains, reducing malicious task execution without compromising utility.", "motivation": "LLMs' shift to action executors increases malicious use risks, highlighting a gap in safety alignment during post-training.", "method": "AgentAlign uses abstract behavior chains in simulated environments to generate authentic, executable instructions, balancing safety and utility.", "result": "Fine-tuning with AgentAlign boosts safety (35.8% to 79.5% improvement) while maintaining or enhancing helpfulness.", "conclusion": "AgentAlign effectively addresses LLM safety alignment, outperforming prompting methods, with open-sourced dataset and code."}}
{"id": "2505.23071", "pdf": "https://arxiv.org/pdf/2505.23071", "abs": "https://arxiv.org/abs/2505.23071", "authors": ["Peizheng Guo", "Jingyao Wang", "Huijie Guo", "Jiangmeng Li", "Chuxiong Sun", "Changwen Zheng", "Wenwen Qiang"], "title": "Multi-Modal Learning with Bayesian-Oriented Gradient Calibration", "categories": ["cs.LG"], "comment": null, "summary": "Multi-Modal Learning (MML) integrates information from diverse modalities to\nimprove predictive accuracy. However, existing methods mainly aggregate\ngradients with fixed weights and treat all dimensions equally, overlooking the\nintrinsic gradient uncertainty of each modality. This may lead to (i) excessive\nupdates in sensitive dimensions, degrading performance, and (ii) insufficient\nupdates in less sensitive dimensions, hindering learning. To address this\nissue, we propose BOGC-MML, a Bayesian-Oriented Gradient Calibration method for\nMML to explicitly model the gradient uncertainty and guide the model\noptimization towards the optimal direction. Specifically, we first model each\nmodality's gradient as a random variable and derive its probability\ndistribution, capturing the full uncertainty in the gradient space. Then, we\npropose an effective method that converts the precision (inverse variance) of\neach gradient distribution into a scalar evidence. This evidence quantifies the\nconfidence of each modality in every gradient dimension. Using these evidences,\nwe explicitly quantify per-dimension uncertainties and fuse them via a reduced\nDempster-Shafer rule. The resulting uncertainty-weighted aggregation produces a\ncalibrated update direction that balances sensitivity and conservatism across\ndimensions. Extensive experiments on multiple benchmark datasets demonstrate\nthe effectiveness and advantages of the proposed method.", "AI": {"tldr": "BOGC-MML introduces a Bayesian-Oriented Gradient Calibration method for Multi-Modal Learning, addressing gradient uncertainty to improve predictive accuracy by balancing sensitivity and conservatism in updates.", "motivation": "Existing MML methods use fixed weights for gradient aggregation, ignoring intrinsic gradient uncertainty, which can degrade performance or hinder learning.", "method": "BOGC-MML models gradient uncertainty per modality, derives probability distributions, converts precision into evidence, and fuses uncertainties using Dempster-Shafer rule for calibrated updates.", "result": "Experiments on benchmark datasets show BOGC-MML's effectiveness in improving predictive accuracy.", "conclusion": "BOGC-MML successfully addresses gradient uncertainty in MML, enhancing model optimization and performance."}}
{"id": "2505.23224", "pdf": "https://arxiv.org/pdf/2505.23224", "abs": "https://arxiv.org/abs/2505.23224", "authors": ["Zhitao He", "Sandeep Polisetty", "Zhiyuan Fan", "Yuchen Huang", "Shujin Wu", "Yi R.", "Fung"], "title": "MMBoundary: Advancing MLLM Knowledge Boundary Awareness through Reasoning Step Confidence Calibration", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025", "summary": "In recent years, multimodal large language models (MLLMs) have made\nsignificant progress but continue to face inherent challenges in multimodal\nreasoning, which requires multi-level (e.g., perception, reasoning) and\nmulti-granular (e.g., multi-step reasoning chain) advanced inferencing. Prior\nwork on estimating model confidence tends to focus on the overall response for\ntraining and calibration, but fails to assess confidence in each reasoning\nstep, leading to undesirable hallucination snowballing. In this work, we\npresent MMBoundary, a novel framework that advances the knowledge boundary\nawareness of MLLMs through reasoning step confidence calibration. To achieve\nthis, we propose to incorporate complementary textual and cross-modal\nself-rewarding signals to estimate confidence at each step of the MLLM\nreasoning process. In addition to supervised fine-tuning MLLM on this set of\nself-rewarded confidence estimation signal for initial confidence expression\nwarm-up, we introduce a reinforcement learning stage with multiple reward\nfunctions for further aligning model knowledge and calibrating confidence at\neach reasoning step, enhancing reasoning chain self-correction. Empirical\nresults show that MMBoundary significantly outperforms existing methods across\ndiverse domain datasets and metrics, achieving an average of 7.5% reduction in\nmultimodal confidence calibration errors and up to 8.3% improvement in task\nperformance.", "AI": {"tldr": "MMBoundary improves multimodal reasoning in MLLMs by calibrating confidence at each reasoning step, reducing errors and enhancing performance.", "motivation": "Addressing the challenge of multimodal reasoning in MLLMs, particularly the lack of step-wise confidence assessment leading to hallucination.", "method": "Proposes MMBoundary, a framework using textual and cross-modal self-rewarding signals for step-wise confidence calibration, combined with supervised fine-tuning and reinforcement learning.", "result": "Achieves 7.5% reduction in calibration errors and up to 8.3% improvement in task performance.", "conclusion": "MMBoundary effectively enhances MLLM reasoning by improving confidence awareness and self-correction."}}
{"id": "2505.23192", "pdf": "https://arxiv.org/pdf/2505.23192", "abs": "https://arxiv.org/abs/2505.23192", "authors": ["Run Hao", "Peng Ying"], "title": "Fooling the Watchers: Breaking AIGC Detectors via Semantic Prompt Attacks", "categories": ["cs.CV", "cs.AI", "cs.CR"], "comment": "9 pages", "summary": "The rise of text-to-image (T2I) models has enabled the synthesis of\nphotorealistic human portraits, raising serious concerns about identity misuse\nand the robustness of AIGC detectors. In this work, we propose an automated\nadversarial prompt generation framework that leverages a grammar tree structure\nand a variant of the Monte Carlo tree search algorithm to systematically\nexplore the semantic prompt space. Our method generates diverse, controllable\nprompts that consistently evade both open-source and commercial AIGC detectors.\nExtensive experiments across multiple T2I models validate its effectiveness,\nand the approach ranked first in a real-world adversarial AIGC detection\ncompetition. Beyond attack scenarios, our method can also be used to construct\nhigh-quality adversarial datasets, providing valuable resources for training\nand evaluating more robust AIGC detection and defense systems.", "AI": {"tldr": "An automated adversarial prompt generation framework is proposed to evade AIGC detectors using grammar trees and Monte Carlo tree search, validated by experiments and competition success.", "motivation": "Address concerns about identity misuse and AIGC detector robustness by creating adversarial prompts.", "method": "Uses a grammar tree structure and Monte Carlo tree search variant to explore semantic prompt space for diverse, controllable prompts.", "result": "Effectively evades detectors, ranks first in a competition, and aids in creating adversarial datasets.", "conclusion": "The framework is effective for attacks and improving detector robustness through dataset construction."}}
{"id": "2505.23053", "pdf": "https://arxiv.org/pdf/2505.23053", "abs": "https://arxiv.org/abs/2505.23053", "authors": ["Wei-Hsiang Huang", "Chen-Wei Ke", "Wei-Ning Chiu", "Yu-Xuan Su", "Chun-Chun Yang", "Chieh-Yuan Cheng", "Yun-Nung Chen", "Pu-Jen Cheng"], "title": "Augment or Not? A Comparative Study of Pure and Augmented Large Language Model Recommenders", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have introduced new paradigms for recommender\nsystems by enabling richer semantic understanding and incorporating implicit\nworld knowledge. In this study, we propose a systematic taxonomy that\nclassifies existing approaches into two categories: (1) Pure LLM Recommenders,\nwhich rely solely on LLMs, and (2) Augmented LLM Recommenders, which integrate\nadditional non-LLM techniques to enhance performance. This taxonomy provides a\nnovel lens through which to examine the evolving landscape of LLM-based\nrecommendation. To support fair comparison, we introduce a unified evaluation\nplatform that benchmarks representative models under consistent experimental\nsettings, highlighting key design choices that impact effectiveness. We\nconclude by discussing open challenges and outlining promising directions for\nfuture research. This work offers both a comprehensive overview and practical\nguidance for advancing next-generation LLM-powered recommender.", "AI": {"tldr": "The paper proposes a taxonomy for LLM-based recommender systems, categorizing them into Pure and Augmented LLM Recommenders, and introduces a unified evaluation platform for fair benchmarking.", "motivation": "To provide a structured understanding of LLM-based recommender systems and enable fair comparisons among different approaches.", "method": "A systematic taxonomy is proposed, classifying approaches into Pure and Augmented LLM Recommenders. A unified evaluation platform is introduced for benchmarking.", "result": "The taxonomy and evaluation platform highlight key design choices and their impact on performance.", "conclusion": "The work offers a comprehensive overview and practical guidance for advancing LLM-powered recommender systems, with open challenges and future directions discussed."}}
{"id": "2505.23084", "pdf": "https://arxiv.org/pdf/2505.23084", "abs": "https://arxiv.org/abs/2505.23084", "authors": ["Chang Yu", "Fang Liu", "Jie Zhu", "Shaobo Guo", "Yifan Gao", "Zhongheng Yang", "Meiwei Liu", "Qianwen Xing"], "title": "Gradient Boosting Decision Tree with LSTM for Investment Prediction", "categories": ["cs.LG"], "comment": "This paper have been accepted by IEEE confulence", "summary": "This paper proposes a hybrid framework combining LSTM (Long Short-Term\nMemory) networks with LightGBM and CatBoost for stock price prediction. The\nframework processes time-series financial data and evaluates performance using\nseven models: Artificial Neural Networks (ANNs), Convolutional Neural Networks\n(CNNs), Bidirectional LSTM (BiLSTM), vanilla LSTM, XGBoost, LightGBM, and\nstandard Neural Networks (NNs). Key metrics, including MAE, R-squared, MSE, and\nRMSE, are used to establish benchmarks across different time scales.\n  Building on these benchmarks, we develop an ensemble model that combines the\nstrengths of sequential and tree-based approaches. Experimental results show\nthat the proposed framework improves accuracy by 10 to 15 percent compared to\nindividual models and reduces error during market changes. This study\nhighlights the potential of ensemble methods for financial forecasting and\nprovides a flexible design for integrating new machine learning techniques.", "AI": {"tldr": "A hybrid framework combining LSTM, LightGBM, and CatBoost for stock price prediction outperforms individual models by 10-15% in accuracy.", "motivation": "To improve stock price prediction accuracy by leveraging ensemble methods combining sequential (LSTM) and tree-based (LightGBM, CatBoost) approaches.", "method": "Processes time-series financial data using seven models (ANNs, CNNs, BiLSTM, LSTM, XGBoost, LightGBM, NNs) and benchmarks performance with MAE, R-squared, MSE, RMSE. Develops an ensemble model.", "result": "The hybrid framework improves accuracy by 10-15% and reduces error during market changes.", "conclusion": "Ensemble methods are effective for financial forecasting, and the framework offers flexibility for integrating new techniques."}}
{"id": "2505.23229", "pdf": "https://arxiv.org/pdf/2505.23229", "abs": "https://arxiv.org/abs/2505.23229", "authors": ["Hao Lu", "Yanchi Gu", "Haoyuan Huang", "Yulin Zhou", "Ningxin Zhu", "Chen Li"], "title": "MCTSr-Zero: Self-Reflective Psychological Counseling Dialogues Generation via Principles and Adaptive Exploration", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "50 pages, 3 figures", "summary": "The integration of Monte Carlo Tree Search (MCTS) with Large Language Models\n(LLMs) has demonstrated significant success in structured, problem-oriented\ntasks. However, applying these methods to open-ended dialogues, such as those\nin psychological counseling, presents unique challenges. Unlike tasks with\nobjective correctness, success in therapeutic conversations depends on\nsubjective factors like empathetic engagement, ethical adherence, and alignment\nwith human preferences, for which strict \"correctness\" criteria are\nill-defined. Existing result-oriented MCTS approaches can therefore produce\nmisaligned responses. To address this, we introduce MCTSr-Zero, an MCTS\nframework designed for open-ended, human-centric dialogues. Its core innovation\nis \"domain alignment\", which shifts the MCTS search objective from predefined\nend-states towards conversational trajectories that conform to target domain\nprinciples (e.g., empathy in counseling). Furthermore, MCTSr-Zero incorporates\n\"Regeneration\" and \"Meta-Prompt Adaptation\" mechanisms to substantially broaden\nexploration by allowing the MCTS to consider fundamentally different initial\ndialogue strategies. We evaluate MCTSr-Zero in psychological counseling by\ngenerating multi-turn dialogue data, which is used to fine-tune an LLM, PsyLLM.\nWe also introduce PsyEval, a benchmark for assessing multi-turn psychological\ncounseling dialogues. Experiments demonstrate that PsyLLM achieves\nstate-of-the-art performance on PsyEval and other relevant metrics, validating\nMCTSr-Zero's effectiveness in generating high-quality, principle-aligned\nconversational data for human-centric domains and addressing the LLM challenge\nof consistently adhering to complex psychological standards.", "AI": {"tldr": "MCTSr-Zero, an MCTS framework for open-ended dialogues, improves alignment with human-centric principles like empathy in psychological counseling, outperforming existing methods.", "motivation": "Existing MCTS methods struggle in open-ended dialogues (e.g., counseling) due to ill-defined correctness criteria and misalignment with subjective factors like empathy.", "method": "MCTSr-Zero introduces 'domain alignment' to focus on conversational trajectories, plus 'Regeneration' and 'Meta-Prompt Adaptation' for broader exploration.", "result": "MCTSr-Zero generates high-quality dialogue data, fine-tuning PsyLLM, which achieves state-of-the-art performance on the PsyEval benchmark.", "conclusion": "MCTSr-Zero effectively addresses the challenge of aligning LLMs with complex psychological standards in human-centric dialogues."}}
{"id": "2505.23193", "pdf": "https://arxiv.org/pdf/2505.23193", "abs": "https://arxiv.org/abs/2505.23193", "authors": ["Sungjune Park", "Hyunjun Kim", "Beomchan Park", "Yong Man Ro"], "title": "Language-guided Learning for Object Detection Tackling Multiple Variations in Aerial Images", "categories": ["cs.CV"], "comment": null, "summary": "Despite recent advancements in computer vision research, object detection in\naerial images still suffers from several challenges. One primary challenge to\nbe mitigated is the presence of multiple types of variation in aerial images,\nfor example, illumination and viewpoint changes. These variations result in\nhighly diverse image scenes and drastic alterations in object appearance, so\nthat it becomes more complicated to localize objects from the whole image scene\nand recognize their categories. To address this problem, in this paper, we\nintroduce a novel object detection framework in aerial images, named\nLANGuage-guided Object detection (LANGO). Upon the proposed language-guided\nlearning, the proposed framework is designed to alleviate the impacts from both\nscene and instance-level variations. First, we are motivated by the way humans\nunderstand the semantics of scenes while perceiving environmental factors in\nthe scenes (e.g., weather). Therefore, we design a visual semantic reasoner\nthat comprehends visual semantics of image scenes by interpreting conditions\nwhere the given images were captured. Second, we devise a training objective,\nnamed relation learning loss, to deal with instance-level variations, such as\nviewpoint angle and scale changes. This training objective aims to learn\nrelations in language representations of object categories, with the help of\nthe robust characteristics against such variations. Through extensive\nexperiments, we demonstrate the effectiveness of the proposed method, and our\nmethod obtains noticeable detection performance improvements.", "AI": {"tldr": "The paper introduces LANGO, a language-guided object detection framework for aerial images, addressing challenges like scene and instance-level variations.", "motivation": "Aerial images have diverse scenes and object appearances due to variations like illumination and viewpoint changes, making object detection difficult.", "method": "LANGO uses a visual semantic reasoner to interpret scene conditions and a relation learning loss to handle instance-level variations like viewpoint and scale changes.", "result": "The method shows noticeable improvements in detection performance through extensive experiments.", "conclusion": "LANGO effectively mitigates challenges in aerial object detection by leveraging language-guided learning."}}
{"id": "2505.23059", "pdf": "https://arxiv.org/pdf/2505.23059", "abs": "https://arxiv.org/abs/2505.23059", "authors": ["Dohyeon Lee", "Yeonseok Jeong", "Seung-won Hwang"], "title": "From Token to Action: State Machine Reasoning to Mitigate Overthinking in Information Retrieval", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Chain-of-Thought (CoT) prompting enables complex reasoning in large language\nmodels (LLMs), including applications in information retrieval (IR). However,\nit often leads to overthinking, where models produce excessively long and\nsemantically redundant traces with little or no benefit. We identify two key\nchallenges in IR: redundant trajectories that revisit similar states and\nmisguided reasoning that diverges from user intent. To address these, we\npropose State Machine Reasoning (SMR), a transition-based reasoning framework\ncomposed of discrete actions (Refine, Rerank, Stop) that support early stopping\nand fine-grained control. Experiments on the BEIR and BRIGHT benchmarks show\nthat SMR improves retrieval performance (nDCG@10) by 3.4% while reducing token\nusage by 74.4%. It generalizes across LLMs and retrievers without requiring\ntask-specific tuning, offering a practical alternative to conventional CoT\nreasoning. The code and details are available at https://github.com/ldilab/SMR.", "AI": {"tldr": "State Machine Reasoning (SMR) improves retrieval performance by 3.4% and reduces token usage by 74.4% compared to Chain-of-Thought (CoT) prompting, addressing redundancy and misguided reasoning in IR.", "motivation": "CoT prompting in LLMs for IR leads to overthinking, producing redundant and unhelpful reasoning traces.", "method": "Proposes SMR, a transition-based framework with discrete actions (Refine, Rerank, Stop) for controlled reasoning.", "result": "SMR boosts nDCG@10 by 3.4% and cuts token usage by 74.4% on BEIR and BRIGHT benchmarks.", "conclusion": "SMR offers a practical, efficient alternative to CoT, generalizing across LLMs and retrievers without task-specific tuning."}}
{"id": "2505.23086", "pdf": "https://arxiv.org/pdf/2505.23086", "abs": "https://arxiv.org/abs/2505.23086", "authors": ["Junyi An", "Xinyu Lu", "Chao Qu", "Yunfei Shi", "Peijia Lin", "Qianwei Tang", "Licheng Xu", "Fenglei Cao", "Yuan Qi"], "title": "Equivariant Spherical Transformer for Efficient Molecular Modeling", "categories": ["cs.LG", "cs.AI"], "comment": "24 pages, 3 figures", "summary": "SE(3)-equivariant Graph Neural Networks (GNNs) have significantly advanced\nmolecular system modeling by employing group representations. However, their\nmessage passing processes, which rely on tensor product-based convolutions, are\nlimited by insufficient non-linearity and incomplete group representations,\nthereby restricting expressiveness. To overcome these limitations, we introduce\nthe Equivariant Spherical Transformer (EST), a novel framework that leverages a\nTransformer structure within the spatial domain of group representations after\nFourier transform. We theoretically and empirically demonstrate that EST can\nencompass the function space of tensor products while achieving superior\nexpressiveness. Furthermore, EST's equivariant inductive bias is guaranteed\nthrough a uniform sampling strategy for the Fourier transform. Our experiments\ndemonstrate state-of-the-art performance by EST on various molecular\nbenchmarks, including OC20 and QM9.", "AI": {"tldr": "The paper introduces the Equivariant Spherical Transformer (EST), a novel SE(3)-equivariant GNN framework, to address limitations in expressiveness and non-linearity of existing methods.", "motivation": "Existing SE(3)-equivariant GNNs suffer from insufficient non-linearity and incomplete group representations, limiting their expressiveness.", "method": "The proposed EST leverages a Transformer structure in the spatial domain of group representations post-Fourier transform, ensuring equivariance and superior expressiveness.", "result": "EST achieves state-of-the-art performance on molecular benchmarks like OC20 and QM9.", "conclusion": "EST overcomes the limitations of tensor product-based convolutions and sets a new benchmark in molecular system modeling."}}
{"id": "2505.23242", "pdf": "https://arxiv.org/pdf/2505.23242", "abs": "https://arxiv.org/abs/2505.23242", "authors": ["Jingxuan Wei", "Nan Xu", "Junnan Zhu", "Yanni Hao", "Gaowei Wu", "Bihui Yu", "Lei Wang"], "title": "ChartMind: A Comprehensive Benchmark for Complex Real-world Multimodal Chart Question Answering", "categories": ["cs.CL"], "comment": null, "summary": "Chart question answering (CQA) has become a critical multimodal task for\nevaluating the reasoning capabilities of vision-language models. While early\napproaches have shown promising performance by focusing on visual features or\nleveraging large-scale pre-training, most existing evaluations rely on rigid\noutput formats and objective metrics, thus ignoring the complex, real-world\ndemands of practical chart analysis. In this paper, we introduce ChartMind, a\nnew benchmark designed for complex CQA tasks in real-world settings. ChartMind\ncovers seven task categories, incorporates multilingual contexts, supports\nopen-domain textual outputs, and accommodates diverse chart formats, bridging\nthe gap between real-world applications and traditional academic benchmarks.\nFurthermore, we propose a context-aware yet model-agnostic framework, ChartLLM,\nthat focuses on extracting key contextual elements, reducing noise, and\nenhancing the reasoning accuracy of multimodal large language models. Extensive\nevaluations on ChartMind and three representative public benchmarks with 14\nmainstream multimodal models show our framework significantly outperforms the\nprevious three common CQA paradigms: instruction-following, OCR-enhanced, and\nchain-of-thought, highlighting the importance of flexible chart understanding\nfor real-world CQA. These findings suggest new directions for developing more\nrobust chart reasoning in future research.", "AI": {"tldr": "ChartMind is a new benchmark for complex chart question answering (CQA), addressing real-world demands. ChartLLM, a context-aware framework, outperforms existing methods.", "motivation": "Existing CQA evaluations lack flexibility for real-world chart analysis, prompting the need for a more robust benchmark and framework.", "method": "Introduces ChartMind (7 task categories, multilingual, open-domain) and ChartLLM (context-aware, noise-reducing framework).", "result": "ChartLLM outperforms three common CQA paradigms on ChartMind and public benchmarks.", "conclusion": "Flexible chart understanding is crucial for real-world CQA, guiding future research toward robust chart reasoning."}}
{"id": "2505.23201", "pdf": "https://arxiv.org/pdf/2505.23201", "abs": "https://arxiv.org/abs/2505.23201", "authors": ["Hao Wu", "Junzhou Chen", "Ronghui Zhang", "Nengchao Lyu", "Hongyu Hu", "Yanyong Guo", "Tony Z. Qiu"], "title": "WTEFNet: Real-Time Low-Light Object Detection for Advanced Driver-Assistance Systems", "categories": ["cs.CV"], "comment": "This paper is expected to be submitted to IEEE Transactions on\n  Instrumentation and Measurement", "summary": "Object detection is a cornerstone of environmental perception in advanced\ndriver assistance systems(ADAS). However, most existing methods rely on RGB\ncameras, which suffer from significant performance degradation under low-light\nconditions due to poor image quality. To address this challenge, we proposes\nWTEFNet, a real-time object detection framework specifically designed for\nlow-light scenarios, with strong adaptability to mainstream detectors. WTEFNet\ncomprises three core modules: a Low-Light Enhancement (LLE) module, a\nWavelet-based Feature Extraction (WFE) module, and an Adaptive Fusion Detection\n(AFFD) module. The LLE enhances dark regions while suppressing overexposed\nareas; the WFE applies multi-level discrete wavelet transforms to isolate high-\nand low-frequency components, enabling effective denoising and structural\nfeature retention; the AFFD fuses semantic and illumination features for robust\ndetection. To support training and evaluation, we introduce GSN, a manually\nannotated dataset covering both clear and rainy night-time scenes. Extensive\nexperiments on BDD100K, SHIFT, nuScenes, and GSN demonstrate that WTEFNet\nachieves state-of-the-art accuracy under low-light conditions. Furthermore,\ndeployment on a embedded platform (NVIDIA Jetson AGX Orin) confirms the\nframework's suitability for real-time ADAS applications.", "AI": {"tldr": "WTEFNet is a real-time object detection framework for low-light conditions, combining low-light enhancement, wavelet-based feature extraction, and adaptive fusion, achieving state-of-the-art results.", "motivation": "Existing RGB-based object detection methods perform poorly in low-light conditions, limiting ADAS effectiveness.", "method": "WTEFNet uses three modules: Low-Light Enhancement (LLE), Wavelet-based Feature Extraction (WFE), and Adaptive Fusion Detection (AFFD).", "result": "WTEFNet achieves top accuracy on datasets like BDD100K and GSN and is suitable for real-time ADAS applications.", "conclusion": "WTEFNet effectively addresses low-light object detection challenges, demonstrating practicality for real-world ADAS deployment."}}
{"id": "2505.23066", "pdf": "https://arxiv.org/pdf/2505.23066", "abs": "https://arxiv.org/abs/2505.23066", "authors": ["Shuyin Xia", "Xiaojiang Tian", "Suzhen Yuan", "Jeremiah D. Deng"], "title": "Efficient Quantum Approximate $k$NN Algorithm via Granular-Ball Computing", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "8 pages; 7 figure; accepted by IJCAI 2025", "summary": "High time complexity is one of the biggest challenges faced by $k$-Nearest\nNeighbors ($k$NN). Although current classical and quantum $k$NN algorithms have\nmade some improvements, they still have a speed bottleneck when facing large\namounts of data. To address this issue, we propose an innovative algorithm\ncalled Granular-Ball based Quantum $k$NN(GB-Q$k$NN). This approach achieves\nhigher efficiency by first employing granular-balls, which reduces the data\nsize needed to processed. The search process is then accelerated by adopting a\nHierarchical Navigable Small World (HNSW) method. Moreover, we optimize the\ntime-consuming steps, such as distance calculation, of the HNSW via\nquantization, further reducing the time complexity of the construct and search\nprocess. By combining the use of granular-balls and quantization of the HNSW\nmethod, our approach manages to take advantage of these treatments and\nsignificantly reduces the time complexity of the $k$NN-like algorithms, as\nrevealed by a comprehensive complexity analysis.", "AI": {"tldr": "GB-QkNN combines granular-balls and quantization with HNSW to reduce time complexity in kNN algorithms.", "motivation": "High time complexity in kNN algorithms, especially with large datasets, needs improvement.", "method": "Uses granular-balls to reduce data size, HNSW for faster search, and quantization for efficiency.", "result": "Significantly reduces time complexity in kNN-like algorithms.", "conclusion": "GB-QkNN is an efficient solution for speeding up kNN tasks."}}
{"id": "2505.23094", "pdf": "https://arxiv.org/pdf/2505.23094", "abs": "https://arxiv.org/abs/2505.23094", "authors": ["Chongjie Si", "Zhiyi Shi", "Yadao Wang", "Xiaokang Yang", "Susanto Rahardja", "Wei Shen"], "title": "MAP: Revisiting Weight Decomposition for Low-Rank Adaptation", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "The rapid development of large language models has revolutionized natural\nlanguage processing, but their fine-tuning remains computationally expensive,\nhindering broad deployment. Parameter-efficient fine-tuning (PEFT) methods,\nsuch as LoRA, have emerged as solutions. Recent work like DoRA attempts to\nfurther decompose weight adaptation into direction and magnitude components.\nHowever, existing formulations often define direction heuristically at the\ncolumn level, lacking a principled geometric foundation. In this paper, we\npropose MAP, a novel framework that reformulates weight matrices as\nhigh-dimensional vectors and decouples their adaptation into direction and\nmagnitude in a rigorous manner. MAP normalizes the pre-trained weights, learns\na directional update, and introduces two scalar coefficients to independently\nscale the magnitude of the base and update vectors. This design enables more\ninterpretable and flexible adaptation, and can be seamlessly integrated into\nexisting PEFT methods. Extensive experiments show that MAP significantly\nimproves performance when coupling with existing methods, offering a simple yet\npowerful enhancement to existing PEFT methods. Given the universality and\nsimplicity of MAP, we hope it can serve as a default setting for designing\nfuture PEFT methods.", "AI": {"tldr": "MAP is a novel framework for parameter-efficient fine-tuning (PEFT) that rigorously decouples weight adaptation into direction and magnitude, improving performance and interpretability.", "motivation": "Existing PEFT methods lack a principled geometric foundation for direction adaptation, limiting their effectiveness.", "method": "MAP reformulates weight matrices as vectors, normalizes pre-trained weights, learns directional updates, and scales magnitudes independently.", "result": "MAP significantly enhances performance when combined with existing PEFT methods.", "conclusion": "MAP is a universal and simple enhancement for PEFT, proposed as a default for future methods."}}
{"id": "2505.23252", "pdf": "https://arxiv.org/pdf/2505.23252", "abs": "https://arxiv.org/abs/2505.23252", "authors": ["Bing Ma", "Hai Zhuge"], "title": "Automatic Construction of Multiple Classification Dimensions for Managing Approaches in Scientific Papers", "categories": ["cs.CL"], "comment": "26 pages, 9 figures", "summary": "Approaches form the foundation for conducting scientific research. Querying\napproaches from a vast body of scientific papers is extremely time-consuming,\nand without a well-organized management framework, researchers may face\nsignificant challenges in querying and utilizing relevant approaches.\nConstructing multiple dimensions on approaches and managing them from these\ndimensions can provide an efficient solution. Firstly, this paper identifies\napproach patterns using a top-down way, refining the patterns through four\ndistinct linguistic levels: semantic level, discourse level, syntactic level,\nand lexical level. Approaches in scientific papers are extracted based on\napproach patterns. Additionally, five dimensions for categorizing approaches\nare identified using these patterns. This paper proposes using tree structure\nto represent step and measuring the similarity between different steps with a\ntree-structure-based similarity measure that focuses on syntactic-level\nsimilarities. A collection similarity measure is proposed to compute the\nsimilarity between approaches. A bottom-up clustering algorithm is proposed to\nconstruct class trees for approach components within each dimension by merging\neach approach component or class with its most similar approach component or\nclass in each iteration. The class labels generated during the clustering\nprocess indicate the common semantics of the step components within the\napproach components in each class and are used to manage the approaches within\nthe class. The class trees of the five dimensions collectively form a\nmulti-dimensional approach space. The application of approach queries on the\nmulti-dimensional approach space demonstrates that querying within this space\nensures strong relevance between user queries and results and rapidly reduces\nsearch space through a class-based query mechanism.", "AI": {"tldr": "The paper proposes a multi-dimensional framework for efficiently querying and managing scientific research approaches by identifying patterns, categorizing approaches, and using tree structures for similarity and clustering.", "motivation": "The challenge of querying and managing approaches in scientific papers is time-consuming and inefficient without a structured framework.", "method": "Identifies approach patterns across linguistic levels, extracts approaches, categorizes them into five dimensions, and uses tree structures for similarity and clustering.", "result": "A multi-dimensional approach space is created, enabling efficient and relevant querying with reduced search space.", "conclusion": "The proposed framework improves approach querying and management in scientific research by leveraging multi-dimensional categorization and similarity measures."}}
{"id": "2505.23206", "pdf": "https://arxiv.org/pdf/2505.23206", "abs": "https://arxiv.org/abs/2505.23206", "authors": ["Aldino Rizaldy", "Richard Gloaguen", "Fabian Ewald Fassnacht", "Pedram Ghamisi"], "title": "HyperPointFormer: Multimodal Fusion in 3D Space with Dual-Branch Cross-Attention Transformers", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal remote sensing data, including spectral and lidar or\nphotogrammetry, is crucial for achieving satisfactory land-use / land-cover\nclassification results in urban scenes. So far, most studies have been\nconducted in a 2D context. When 3D information is available in the dataset, it\nis typically integrated with the 2D data by rasterizing the 3D data into 2D\nformats. Although this method yields satisfactory classification results, it\nfalls short in fully exploiting the potential of 3D data by restricting the\nmodel's ability to learn 3D spatial features directly from raw point clouds.\nAdditionally, it limits the generation of 3D predictions, as the dimensionality\nof the input data has been reduced. In this study, we propose a fully 3D-based\nmethod that fuses all modalities within the 3D point cloud and employs a\ndedicated dual-branch Transformer model to simultaneously learn geometric and\nspectral features. To enhance the fusion process, we introduce a\ncross-attention-based mechanism that fully operates on 3D points, effectively\nintegrating features from various modalities across multiple scales. The\npurpose of cross-attention is to allow one modality to assess the importance of\nanother by weighing the relevant features. We evaluated our method by comparing\nit against both 3D and 2D methods using the 2018 IEEE GRSS Data Fusion Contest\n(DFC2018) dataset. Our findings indicate that 3D fusion delivers competitive\nresults compared to 2D methods and offers more flexibility by providing 3D\npredictions. These predictions can be projected onto 2D maps, a capability that\nis not feasible in reverse. Additionally, we evaluated our method on different\ndatasets, specifically the ISPRS Vaihingen 3D and the IEEE 2019 Data Fusion\nContest. Our code will be published here:\nhttps://github.com/aldinorizaldy/hyperpointformer.", "AI": {"tldr": "A 3D-based method fusing multimodal remote sensing data using a dual-branch Transformer and cross-attention for improved land-use classification.", "motivation": "Current methods rasterize 3D data into 2D, limiting 3D feature learning and prediction flexibility.", "method": "Proposes a 3D point cloud fusion with a dual-branch Transformer and cross-attention mechanism for feature integration.", "result": "Outperforms 2D methods, provides 3D predictions, and shows flexibility in projection to 2D maps.", "conclusion": "3D fusion is competitive and offers advantages over 2D methods, with potential for broader applications."}}
{"id": "2505.23116", "pdf": "https://arxiv.org/pdf/2505.23116", "abs": "https://arxiv.org/abs/2505.23116", "authors": ["Pengfei Zhou", "Yunlong Liu", "Junli Liang", "Qi Song", "Xiangyang Li"], "title": "CrossLinear: Plug-and-Play Cross-Correlation Embedding for Time Series Forecasting with Exogenous Variables", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series forecasting with exogenous variables is a critical emerging\nparadigm that presents unique challenges in modeling dependencies between\nvariables. Traditional models often struggle to differentiate between\nendogenous and exogenous variables, leading to inefficiencies and overfitting.\nIn this paper, we introduce CrossLinear, a novel Linear-based forecasting model\nthat addresses these challenges by incorporating a plug-and-play\ncross-correlation embedding module. This lightweight module captures the\ndependencies between variables with minimal computational cost and seamlessly\nintegrates into existing neural networks. Specifically, it captures\ntime-invariant and direct variable dependencies while disregarding time-varying\nor indirect dependencies, thereby mitigating the risk of overfitting in\ndependency modeling and contributing to consistent performance improvements.\nFurthermore, CrossLinear employs patch-wise processing and a global linear head\nto effectively capture both short-term and long-term temporal dependencies,\nfurther improving its forecasting precision. Extensive experiments on 12\nreal-world datasets demonstrate that CrossLinear achieves superior performance\nin both short-term and long-term forecasting tasks. The ablation study\nunderscores the effectiveness of the cross-correlation embedding module.\nAdditionally, the generalizability of this module makes it a valuable plug-in\nfor various forecasting tasks across different domains. Codes are available at\nhttps://github.com/mumiao2000/CrossLinear.", "AI": {"tldr": "CrossLinear is a novel linear-based forecasting model with a cross-correlation embedding module for efficient time series forecasting with exogenous variables.", "motivation": "Traditional models struggle with differentiating endogenous and exogenous variables, leading to inefficiencies and overfitting.", "method": "CrossLinear uses a plug-and-play cross-correlation embedding module to capture dependencies between variables, patch-wise processing, and a global linear head for temporal dependencies.", "result": "Experiments on 12 datasets show superior performance in short- and long-term forecasting, with the module proving effective and generalizable.", "conclusion": "CrossLinear offers consistent performance improvements and is adaptable for various forecasting tasks."}}
{"id": "2505.23098", "pdf": "https://arxiv.org/pdf/2505.23098", "abs": "https://arxiv.org/abs/2505.23098", "authors": ["Kuan Xu", "Zhiguang Cao", "Chenlong Zheng", "Linong Liu"], "title": "Learning to Search for Vehicle Routing with Multiple Time Windows", "categories": ["cs.LG"], "comment": null, "summary": "In this study, we propose a reinforcement learning-based adaptive variable\nneighborhood search (RL-AVNS) method designed for effectively solving the\nVehicle Routing Problem with Multiple Time Windows (VRPMTW). Unlike traditional\nadaptive approaches that rely solely on historical operator performance, our\nmethod integrates a reinforcement learning framework to dynamically select\nneighborhood operators based on real-time solution states and learned\nexperience. We introduce a fitness metric that quantifies customers' temporal\nflexibility to improve the shaking phase, and employ a transformer-based neural\npolicy network to intelligently guide operator selection during the local\nsearch. Extensive computational experiments are conducted on realistic\nscenarios derived from the replenishment of unmanned vending machines,\ncharacterized by multiple clustered replenishment windows. Results demonstrate\nthat RL-AVNS significantly outperforms traditional variable neighborhood search\n(VNS), adaptive VNS (AVNS), and state-of-the-art learning-based heuristics,\nachieving substantial improvements in solution quality and computational\nefficiency across various instance scales and time window complexities.\nParticularly notable is the algorithm's capability to generalize effectively to\nproblem instances not encountered during training, underscoring its practical\nutility for complex logistics scenarios.", "AI": {"tldr": "Proposes RL-AVNS, a reinforcement learning-based adaptive variable neighborhood search method for VRPMTW, outperforming traditional and learning-based heuristics.", "motivation": "To improve solution quality and efficiency for VRPMTW by dynamically selecting operators using real-time states and learned experience.", "method": "Integrates reinforcement learning with a fitness metric for temporal flexibility and a transformer-based policy network for operator selection.", "result": "RL-AVNS outperforms VNS, AVNS, and learning-based heuristics, showing better generalization to unseen instances.", "conclusion": "RL-AVNS is practical for complex logistics, offering superior performance and adaptability."}}
{"id": "2505.23276", "pdf": "https://arxiv.org/pdf/2505.23276", "abs": "https://arxiv.org/abs/2505.23276", "authors": ["Maged S. Al-Shaibani", "Moataz Ahmed"], "title": "The Arabic AI Fingerprint: Stylometric Analysis and Detection of Large Language Models Text", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have achieved unprecedented capabilities in\ngenerating human-like text, posing subtle yet significant challenges for\ninformation integrity across critical domains, including education, social\nmedia, and academia, enabling sophisticated misinformation campaigns,\ncompromising healthcare guidance, and facilitating targeted propaganda. This\nchallenge becomes severe, particularly in under-explored and low-resource\nlanguages like Arabic. This paper presents a comprehensive investigation of\nArabic machine-generated text, examining multiple generation strategies\n(generation from the title only, content-aware generation, and text refinement)\nacross diverse model architectures (ALLaM, Jais, Llama, and GPT-4) in academic,\nand social media domains. Our stylometric analysis reveals distinctive\nlinguistic patterns differentiating human-written from machine-generated Arabic\ntext across these varied contexts. Despite their human-like qualities, we\ndemonstrate that LLMs produce detectable signatures in their Arabic outputs,\nwith domain-specific characteristics that vary significantly between different\ncontexts. Based on these insights, we developed BERT-based detection models\nthat achieved exceptional performance in formal contexts (up to 99.9\\%\nF1-score) with strong precision across model architectures. Our cross-domain\nanalysis confirms generalization challenges previously reported in the\nliterature. To the best of our knowledge, this work represents the most\ncomprehensive investigation of Arabic machine-generated text to date, uniquely\ncombining multiple prompt generation methods, diverse model architectures, and\nin-depth stylometric analysis across varied textual domains, establishing a\nfoundation for developing robust, linguistically-informed detection systems\nessential for preserving information integrity in Arabic-language contexts.", "AI": {"tldr": "The paper investigates machine-generated Arabic text, revealing detectable linguistic patterns and developing high-performance BERT-based detection models to combat misinformation.", "motivation": "Addressing the challenge of LLM-generated misinformation in low-resource languages like Arabic, particularly in critical domains like education and healthcare.", "method": "Examined Arabic text generation strategies (title-only, content-aware, refinement) across models (ALLaM, Jais, Llama, GPT-4) using stylometric analysis and developed BERT-based detectors.", "result": "Detected distinctive linguistic signatures in machine-generated Arabic text, achieving up to 99.9% F1-score in formal contexts, though cross-domain generalization remains challenging.", "conclusion": "The study provides a foundation for linguistically-informed detection systems to preserve information integrity in Arabic-language contexts."}}
{"id": "2505.23209", "pdf": "https://arxiv.org/pdf/2505.23209", "abs": "https://arxiv.org/abs/2505.23209", "authors": ["Akash Dhasade", "Divyansh Jhunjhunwala", "Milos Vujasinovic", "Gauri Joshi", "Anne-Marie Kermarrec"], "title": "Navigating the Accuracy-Size Trade-Off with Flexible Model Merging", "categories": ["cs.CV"], "comment": null, "summary": "Model merging has emerged as an efficient method to combine multiple\nsingle-task fine-tuned models. The merged model can enjoy multi-task\ncapabilities without expensive training. While promising, merging into a single\nmodel often suffers from an accuracy gap with respect to individual fine-tuned\nmodels. On the other hand, deploying all individual fine-tuned models incurs\nhigh costs. We propose FlexMerge, a novel data-free model merging framework to\nflexibly generate merged models of varying sizes, spanning the spectrum from a\nsingle merged model to retaining all individual fine-tuned models. FlexMerge\ntreats fine-tuned models as collections of sequential blocks and progressively\nmerges them using any existing data-free merging method, halting at a desired\nsize. We systematically explore the accuracy-size trade-off exhibited by\ndifferent merging algorithms in combination with FlexMerge. Extensive\nexperiments on vision and NLP benchmarks, with up to 30 tasks, reveal that even\nmodestly larger merged models can provide substantial accuracy improvements\nover a single model. By offering fine-grained control over fused model size,\nFlexMerge provides a flexible, data-free, and high-performance solution for\ndiverse deployment scenarios.", "AI": {"tldr": "FlexMerge is a data-free model merging framework that flexibly generates merged models of varying sizes, balancing accuracy and deployment costs.", "motivation": "To address the accuracy gap in single merged models and high costs of deploying individual models, FlexMerge offers a flexible merging solution.", "method": "FlexMerge treats models as sequential blocks, progressively merging them using existing data-free methods, stopping at a desired size.", "result": "Experiments show modestly larger merged models improve accuracy over a single model, with fine-grained size control.", "conclusion": "FlexMerge provides a high-performance, flexible, and data-free solution for diverse deployment needs."}}
{"id": "2505.23117", "pdf": "https://arxiv.org/pdf/2505.23117", "abs": "https://arxiv.org/abs/2505.23117", "authors": ["Yuatyong Chaichana", "Thanapat Trachu", "Peerat Limkonchotiwat", "Konpat Preechakul", "Tirasan Khandhawit", "Ekapol Chuangsuwanich"], "title": "Decom-Renorm-Merge: Model Merging on the Right Space Improves Multitasking", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In the era of large-scale training, model merging has evolved into a tool for\ncreating multitasking models efficiently. It enables the knowledge of models to\nbe fused, without the need for heavy computation as required in traditional\nmultitask learning. Existing merging methods often assume that entries at\nidentical positions in weight matrices serve the same function, enabling\nstraightforward entry-wise comparison and merging. However, this assumption\noverlooks the complexity of finetuned neural networks, where neurons may\ndevelop distinct feature compositions, making direct entry-wise merging\nproblematic. We present Decom-Renorm-Merge (DRM), a simple yet effective\napproach that leverages Singular Value Decomposition to decompose and\ncoordinate weight matrices into an aligned joint space, where entry-wise\nmerging becomes possible. We showcase the effectiveness of DRM across various\nsettings ranging from smaller encoder-based such as ViT and DeBERTa,\nencoder-decoder-based such as T5, and larger decoder-based such as Llama3.1-8B.\nOur experimental results show that DRM outperforms several state-of-the-art\nmerging techniques across full finetuning and low-rank adaptation settings.\nMoreover, our analysis reveals renormalization as the crucial component for\ncreating a robust and even joint space for merging, significantly contributing\nto the method's performance.", "AI": {"tldr": "DRM is a model merging method using Singular Value Decomposition to align weight matrices, outperforming existing techniques in multitask learning.", "motivation": "Traditional merging assumes identical function for weight matrix entries, ignoring finetuned networks' complexity. DRM addresses this gap.", "method": "DRM decomposes and renormalizes weight matrices via SVD, enabling aligned entry-wise merging.", "result": "DRM outperforms state-of-the-art methods in various models (ViT, DeBERTa, T5, Llama3.1-8B) and settings.", "conclusion": "Renormalization is key to DRM's success, creating a robust joint space for merging."}}
{"id": "2505.23099", "pdf": "https://arxiv.org/pdf/2505.23099", "abs": "https://arxiv.org/abs/2505.23099", "authors": ["Chongjie Si", "Xuankun Yang", "Muqing Liu", "Yadao Wang", "Xiaokang Yang", "Wenbo Su", "Bo Zheng", "Wei Shen"], "title": "Weight Spectra Induced Efficient Model Adaptation", "categories": ["cs.LG"], "comment": null, "summary": "Large-scale foundation models have demonstrated remarkable versatility across\na wide range of downstream tasks. However, fully fine-tuning these models\nincurs prohibitive computational costs, motivating the development of\nParameter-Efficient Fine-Tuning (PEFT) methods such as LoRA, which introduces\nlow-rank updates to pre-trained weights. Despite their empirical success, the\nunderlying mechanisms by which PEFT modifies model parameters remain\nunderexplored. In this work, we present a systematic investigation into the\nstructural changes of weight matrices during fully fine-tuning. Through\nsingular value decomposition (SVD), we reveal that fine-tuning predominantly\namplifies the top singular values while leaving the remainder largely intact,\nsuggesting that task-specific knowledge is injected into a low-dimensional\nsubspace. Furthermore, we find that the dominant singular vectors are\nreoriented in task-specific directions, whereas the non-dominant subspace\nremains stable. Building on these insights, we propose a novel method that\nleverages learnable rescaling of top singular directions, enabling precise\nmodulation of the most influential components without disrupting the global\nstructure. Our approach achieves consistent improvements over strong baselines\nacross multiple tasks, highlighting the efficacy of structurally informed\nfine-tuning.", "AI": {"tldr": "The paper investigates how Parameter-Efficient Fine-Tuning (PEFT) modifies model parameters, revealing that fine-tuning amplifies top singular values and reorients dominant singular vectors. A novel method leveraging learnable rescaling of top singular directions is proposed, improving performance across tasks.", "motivation": "To understand the structural changes in weight matrices during fine-tuning and develop a more efficient method for task-specific adaptation of large-scale foundation models.", "method": "Uses singular value decomposition (SVD) to analyze weight matrices during fine-tuning, identifying amplification of top singular values and reorientation of dominant singular vectors. Proposes a method with learnable rescaling of top singular directions.", "result": "Fine-tuning primarily affects top singular values and dominant singular vectors, injecting task-specific knowledge into a low-dimensional subspace. The proposed method outperforms baselines across multiple tasks.", "conclusion": "Structurally informed fine-tuning, focusing on top singular directions, is effective for efficient and precise model adaptation."}}
{"id": "2505.23277", "pdf": "https://arxiv.org/pdf/2505.23277", "abs": "https://arxiv.org/abs/2505.23277", "authors": ["Yong Zhang", "Yanwen Huang", "Ning Cheng", "Yang Guo", "Yun Zhu", "Yanmeng Wang", "Shaojun Wang", "Jing Xiao"], "title": "Sentinel: Attention Probing of Proxy Models for LLM Context Compression with an Understanding Perspective", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint. 17 pages including appendix", "summary": "Retrieval-augmented generation (RAG) enhances large language models (LLMs)\nwith external context, but retrieved passages are often lengthy, noisy, or\nexceed input limits. Existing compression methods typically require supervised\ntraining of dedicated compression models, increasing cost and reducing\nportability. We propose Sentinel, a lightweight sentence-level compression\nframework that reframes context filtering as an attention-based understanding\ntask. Rather than training a compression model, Sentinel probes decoder\nattention from an off-the-shelf 0.5B proxy LLM using a lightweight classifier\nto identify sentence relevance. Empirically, we find that query-context\nrelevance estimation is consistent across model scales, with 0.5B proxies\nclosely matching the behaviors of larger models. On the LongBench benchmark,\nSentinel achieves up to 5$\\times$ compression while matching the QA performance\nof 7B-scale compression systems. Our results suggest that probing native\nattention signals enables fast, effective, and question-aware context\ncompression. Code available at: https://github.com/yzhangchuck/Sentinel.", "AI": {"tldr": "Sentinel is a lightweight framework for compressing retrieved passages in RAG systems by probing decoder attention from a small proxy LLM, achieving efficient and question-aware compression without supervised training.", "motivation": "Retrieved passages in RAG systems are often lengthy or noisy, and existing compression methods require costly supervised training, reducing portability.", "method": "Sentinel reframes context filtering as an attention-based task, using a lightweight classifier to probe decoder attention from a 0.5B proxy LLM for sentence relevance.", "result": "On LongBench, Sentinel achieves up to 5\u00d7 compression while matching QA performance of larger 7B-scale systems.", "conclusion": "Probing native attention signals enables fast, effective, and question-aware context compression without dedicated training."}}
{"id": "2505.23214", "pdf": "https://arxiv.org/pdf/2505.23214", "abs": "https://arxiv.org/abs/2505.23214", "authors": ["Wenhao Xu", "Shuchen Zheng", "Changwei Wang", "Zherui Zhang", "Chuan Ren", "Rongtao Xu", "Shibiao Xu"], "title": "SAMamba: Adaptive State Space Modeling with Hierarchical Vision for Infrared Small Target Detection", "categories": ["cs.CV", "cs.AI"], "comment": "Information Fusion 2025", "summary": "Infrared small target detection (ISTD) is vital for long-range surveillance\nin military, maritime, and early warning applications. ISTD is challenged by\ntargets occupying less than 0.15% of the image and low distinguishability from\ncomplex backgrounds. Existing deep learning methods often suffer from\ninformation loss during downsampling and inefficient global context modeling.\nThis paper presents SAMamba, a novel framework integrating SAM2's hierarchical\nfeature learning with Mamba's selective sequence modeling. Key innovations\ninclude: (1) A Feature Selection Adapter (FS-Adapter) for efficient\nnatural-to-infrared domain adaptation via dual-stage selection (token-level\nwith a learnable task embedding and channel-wise adaptive transformations); (2)\nA Cross-Channel State-Space Interaction (CSI) module for efficient global\ncontext modeling with linear complexity using selective state space modeling;\nand (3) A Detail-Preserving Contextual Fusion (DPCF) module that adaptively\ncombines multi-scale features with a gating mechanism to balance\nhigh-resolution and low-resolution feature contributions. SAMamba addresses\ncore ISTD challenges by bridging the domain gap, maintaining fine-grained\ndetails, and efficiently modeling long-range dependencies. Experiments on\nNUAA-SIRST, IRSTD-1k, and NUDT-SIRST datasets show SAMamba significantly\noutperforms state-of-the-art methods, especially in challenging scenarios with\nheterogeneous backgrounds and varying target scales. Code:\nhttps://github.com/zhengshuchen/SAMamba.", "AI": {"tldr": "SAMamba is a novel framework for infrared small target detection (ISTD) that integrates hierarchical feature learning and selective sequence modeling to address challenges like domain gaps and inefficient global context modeling.", "motivation": "ISTD is crucial for long-range surveillance but faces challenges due to small target size and complex backgrounds. Existing methods suffer from information loss and poor global context modeling.", "method": "SAMamba combines SAM2's hierarchical feature learning with Mamba's selective sequence modeling, introducing FS-Adapter for domain adaptation, CSI for global context modeling, and DPCF for multi-scale feature fusion.", "result": "SAMamba outperforms state-of-the-art methods on datasets like NUAA-SIRST, IRSTD-1k, and NUDT-SIRST, especially in challenging scenarios.", "conclusion": "SAMamba effectively bridges the domain gap, preserves details, and models long-range dependencies, making it a robust solution for ISTD."}}
{"id": "2505.23135", "pdf": "https://arxiv.org/pdf/2505.23135", "abs": "https://arxiv.org/abs/2505.23135", "authors": ["Zhe Ye", "Zhengxu Yan", "Jingxuan He", "Timothe Kasriel", "Kaiyu Yang", "Dawn Song"], "title": "VERINA: Benchmarking Verifiable Code Generation", "categories": ["cs.LG", "cs.AI", "cs.LO", "cs.PL", "cs.SE"], "comment": null, "summary": "Large language models (LLMs) are increasingly integrated in software\ndevelopment, but ensuring correctness in LLM-generated code remains challenging\nand often requires costly manual review. Verifiable code generation -- jointly\ngenerating code, specifications, and proofs of code-specification alignment --\noffers a promising path to address this limitation and further unleash LLMs'\nbenefits in coding. Yet, there exists a significant gap in evaluation: current\nbenchmarks often lack support for end-to-end verifiable code generation. In\nthis paper, we introduce Verina (Verifiable Code Generation Arena), a\nhigh-quality benchmark enabling a comprehensive and modular evaluation of code,\nspecification, and proof generation as well as their compositions. Verina\nconsists of 189 manually curated coding tasks in Lean, with detailed problem\ndescriptions, reference implementations, formal specifications, and extensive\ntest suites. Our extensive evaluation of state-of-the-art LLMs reveals\nsignificant challenges in verifiable code generation, especially in proof\ngeneration, underscoring the need for improving LLM-based theorem provers in\nverification domains. The best model, OpenAI o4-mini, generates only 61.4%\ncorrect code, 51.0% sound and complete specifications, and 3.6% successful\nproofs, with one trial per task. We hope Verina will catalyze progress in\nverifiable code generation by providing a rigorous and comprehensive benchmark.\nWe release our dataset on https://huggingface.co/datasets/sunblaze-ucb/verina\nand our evaluation code on https://github.com/sunblaze-ucb/verina.", "AI": {"tldr": "Verina is a benchmark for evaluating verifiable code generation in LLMs, revealing significant challenges in correctness, specification, and proof generation.", "motivation": "To address the lack of benchmarks for end-to-end verifiable code generation and improve LLM-based coding correctness.", "method": "Introduces Verina, a manually curated benchmark with 189 Lean coding tasks, including specifications and proofs.", "result": "State-of-the-art LLMs struggle, with OpenAI o4-mini achieving only 61.4% correct code, 51.0% sound specifications, and 3.6% successful proofs.", "conclusion": "Verina aims to advance verifiable code generation by providing a rigorous benchmark, highlighting the need for better LLM-based theorem provers."}}
{"id": "2505.23105", "pdf": "https://arxiv.org/pdf/2505.23105", "abs": "https://arxiv.org/abs/2505.23105", "authors": ["Abhishek Vijaya Kumar", "Eric Ding", "Arjun Devraj", "Darius Bunandar", "Rachee Singh"], "title": "LUMION: Fast Fault Recovery for ML Jobs Using Programmable Optical Fabrics", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "When accelerators fail in modern ML datacenters, operators migrate the\naffected ML training or inference jobs to entirely new racks. This approach,\nwhile preserving network performance, is highly inefficient, requiring\ndatacenters to reserve full racks of idle accelerators for fault tolerance. In\nthis paper, we address this resource inefficiency by introducing LUMION, a\nnovel reconfigurable optical fabric for connecting accelerators within a\ndatacenter rack. Instead of migrating entire ML jobs, LUMION dynamically\nintegrates spare accelerators into ongoing workloads as failures occur, thereby\nmaintaining consistent performance without costly migrations. We show the\nbenefits of LUMION by building an end-to-end hardware prototype. Our\nexperiments fine-tune Llama 3.2 and show that LUMION swaps a failed GPU with a\nhealthy one and restarts the ML job within ~ 1 second of the failure. LUMION\nachieves higher inter-GPU bandwidth compared to traditional electrical racks\nafter replacing failed accelerators with spare ones, leading to nearly 2X\nimprovement in fine-tuning throughput.", "AI": {"tldr": "LUMION is a reconfigurable optical fabric that dynamically integrates spare accelerators into ML workloads during failures, avoiding costly migrations and improving efficiency.", "motivation": "Current methods of migrating entire ML jobs to new racks for fault tolerance are inefficient and require idle resources.", "method": "LUMION uses a reconfigurable optical fabric to dynamically replace failed accelerators with spares within the same rack.", "result": "LUMION reduces recovery time to ~1 second and improves fine-tuning throughput by nearly 2X compared to traditional methods.", "conclusion": "LUMION offers a resource-efficient solution for accelerator failures, enhancing performance and reducing downtime in ML datacenters."}}
{"id": "2505.23291", "pdf": "https://arxiv.org/pdf/2505.23291", "abs": "https://arxiv.org/abs/2505.23291", "authors": ["Xinye Li", "Zunwen Zheng", "Qian Zhang", "Dekai Zhuang", "Jiabao Kang", "Liyan Xu", "Qingbin Liu", "Xi Chen", "Zhiying Tu", "Dianhui Chu", "Dianbo Sui"], "title": "ScEdit: Script-based Assessment of Knowledge Editing", "categories": ["cs.CL"], "comment": "ACL 2025 Findings", "summary": "Knowledge Editing (KE) has gained increasing attention, yet current KE tasks\nremain relatively simple. Under current evaluation frameworks, many editing\nmethods achieve exceptionally high scores, sometimes nearing perfection.\nHowever, few studies integrate KE into real-world application scenarios (e.g.,\nrecent interest in LLM-as-agent). To support our analysis, we introduce a novel\nscript-based benchmark -- ScEdit (Script-based Knowledge Editing Benchmark) --\nwhich encompasses both counterfactual and temporal edits. We integrate\ntoken-level and text-level evaluation methods, comprehensively analyzing\nexisting KE techniques. The benchmark extends traditional fact-based\n(\"What\"-type question) evaluation to action-based (\"How\"-type question)\nevaluation. We observe that all KE methods exhibit a drop in performance on\nestablished metrics and face challenges on text-level metrics, indicating a\nchallenging task. Our benchmark is available at\nhttps://github.com/asdfo123/ScEdit.", "AI": {"tldr": "The paper introduces ScEdit, a script-based benchmark for Knowledge Editing (KE), extending evaluation to action-based questions and revealing performance drops in existing KE methods.", "motivation": "Current KE tasks are too simple, with high scores in evaluations, but lack integration into real-world applications like LLM-as-agent scenarios.", "method": "A novel script-based benchmark (ScEdit) is introduced, covering counterfactual and temporal edits, and combining token-level and text-level evaluations.", "result": "Existing KE methods show performance drops on established metrics and struggle with text-level evaluations, highlighting the challenge.", "conclusion": "ScEdit provides a comprehensive benchmark for KE, revealing limitations in current methods and paving the way for more realistic evaluations."}}
{"id": "2505.23248", "pdf": "https://arxiv.org/pdf/2505.23248", "abs": "https://arxiv.org/abs/2505.23248", "authors": ["Yunliang Qi", "Meng Lou", "Yimin Liu", "Lu Li", "Zhen Yang", "Wen Nie"], "title": "Advancing Image Super-resolution Techniques in Remote Sensing: A Comprehensive Survey", "categories": ["eess.IV", "cs.CV"], "comment": "31 pages,7 figures, an survey", "summary": "Remote sensing image super-resolution (RSISR) is a crucial task in remote\nsensing image processing, aiming to reconstruct high-resolution (HR) images\nfrom their low-resolution (LR) counterparts. Despite the growing number of\nRSISR methods proposed in recent years, a systematic and comprehensive review\nof these methods is still lacking. This paper presents a thorough review of\nRSISR algorithms, covering methodologies, datasets, and evaluation metrics. We\nprovide an in-depth analysis of RSISR methods, categorizing them into\nsupervised, unsupervised, and quality evaluation approaches, to help\nresearchers understand current trends and challenges. Our review also discusses\nthe strengths, limitations, and inherent challenges of these techniques.\nNotably, our analysis reveals significant limitations in existing methods,\nparticularly in preserving fine-grained textures and geometric structures under\nlarge-scale degradation. Based on these findings, we outline future research\ndirections, highlighting the need for domain-specific architectures and robust\nevaluation protocols to bridge the gap between synthetic and real-world RSISR\nscenarios.", "AI": {"tldr": "A comprehensive review of remote sensing image super-resolution (RSISR) methods, covering methodologies, datasets, and evaluation metrics, while highlighting current limitations and future research directions.", "motivation": "To address the lack of a systematic review of RSISR methods and provide insights into current trends, challenges, and gaps in the field.", "method": "Categorizes RSISR methods into supervised, unsupervised, and quality evaluation approaches, analyzing their methodologies, datasets, and evaluation metrics.", "result": "Identifies significant limitations in existing methods, especially in preserving fine-grained textures and geometric structures under large-scale degradation.", "conclusion": "Proposes future research directions, emphasizing domain-specific architectures and robust evaluation protocols to improve RSISR for real-world scenarios."}}
{"id": "2505.23165", "pdf": "https://arxiv.org/pdf/2505.23165", "abs": "https://arxiv.org/abs/2505.23165", "authors": ["Le Yang", "Vincent Y. F. Tan", "Wang Chi Cheung"], "title": "Best Arm Identification with Possibly Biased Offline Data", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "comment": "Accepted to UAI 2025", "summary": "We study the best arm identification (BAI) problem with potentially biased\noffline data in the fixed confidence setting, which commonly arises in\nreal-world scenarios such as clinical trials. We prove an impossibility result\nfor adaptive algorithms without prior knowledge of the bias bound between\nonline and offline distributions. To address this, we propose the LUCB-H\nalgorithm, which introduces adaptive confidence bounds by incorporating an\nauxiliary bias correction to balance offline and online data within the LUCB\nframework. Theoretical analysis shows that LUCB-H matches the sample complexity\nof standard LUCB when offline data is misleading and significantly outperforms\nit when offline data is helpful. We also derive an instance-dependent lower\nbound that matches the upper bound of LUCB-H in certain scenarios. Numerical\nexperiments further demonstrate the robustness and adaptability of LUCB-H in\neffectively incorporating offline data.", "AI": {"tldr": "The paper addresses the best arm identification (BAI) problem with biased offline data, proposing the LUCB-H algorithm to adaptively balance offline and online data, showing improved performance and robustness.", "motivation": "The study is motivated by real-world scenarios like clinical trials where offline data may be biased, and adaptive algorithms without prior bias knowledge face limitations.", "method": "The LUCB-H algorithm is introduced, incorporating adaptive confidence bounds and bias correction within the LUCB framework to handle biased offline data.", "result": "LUCB-H matches standard LUCB's sample complexity when offline data is misleading and outperforms it when helpful, with theoretical and experimental validation.", "conclusion": "LUCB-H effectively addresses BAI with biased offline data, offering robust and adaptable performance, supported by theoretical and empirical evidence."}}
{"id": "2505.23106", "pdf": "https://arxiv.org/pdf/2505.23106", "abs": "https://arxiv.org/abs/2505.23106", "authors": ["Ning Liu", "Yue Yu"], "title": "Neural Interpretable PDEs: Harmonizing Fourier Insights with Attention for Scalable and Interpretable Physics Discovery", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Attention mechanisms have emerged as transformative tools in core AI domains\nsuch as natural language processing and computer vision. Yet, their largely\nuntapped potential for modeling intricate physical systems presents a\ncompelling frontier. Learning such systems often entails discovering operators\nthat map between functional spaces using limited instances of function pairs --\na task commonly framed as a severely ill-posed inverse PDE problem. In this\nwork, we introduce Neural Interpretable PDEs (NIPS), a novel neural operator\narchitecture that builds upon and enhances Nonlocal Attention Operators (NAO)\nin both predictive accuracy and computational efficiency. NIPS employs a linear\nattention mechanism to enable scalable learning and integrates a learnable\nkernel network that acts as a channel-independent convolution in Fourier space.\nAs a consequence, NIPS eliminates the need to explicitly compute and store\nlarge pairwise interactions, effectively amortizing the cost of handling\nspatial interactions into the Fourier transform. Empirical evaluations\ndemonstrate that NIPS consistently surpasses NAO and other baselines across\ndiverse benchmarks, heralding a substantial leap in scalable, interpretable,\nand efficient physics learning. Our code and data accompanying this paper are\navailable at https://github.com/fishmoon1234/Nonlocal-Attention-Operator.", "AI": {"tldr": "NIPS, a neural operator architecture, improves predictive accuracy and efficiency in modeling physical systems using linear attention and Fourier space convolution.", "motivation": "To address the challenge of learning intricate physical systems, framed as ill-posed inverse PDE problems, by enhancing Nonlocal Attention Operators.", "method": "NIPS uses a linear attention mechanism and a learnable kernel network in Fourier space, avoiding explicit computation of large pairwise interactions.", "result": "NIPS outperforms NAO and other baselines in benchmarks, offering scalable, interpretable, and efficient physics learning.", "conclusion": "NIPS represents a significant advancement in neural operator architectures for physics learning, with practical applications supported by available code and data."}}
{"id": "2505.23295", "pdf": "https://arxiv.org/pdf/2505.23295", "abs": "https://arxiv.org/abs/2505.23295", "authors": ["James Xu Zhao", "Jimmy Z. J. Liu", "Bryan Hooi", "See-Kiong Ng"], "title": "How Does Response Length Affect Long-Form Factuality", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ACL 2025 Findings. 24 pages, 10 figures, 18 tables. Code available at\n  https://github.com/XuZhao0/length-bias-factuality", "summary": "Large language models (LLMs) are widely used for long-form text generation.\nHowever, factual errors in the responses would undermine their reliability.\nDespite growing attention to LLM factuality, the effect of response length on\nfactuality remains underexplored. In this work, we systematically investigate\nthis relationship by first introducing an automatic and bi-level long-form\nfactuality evaluation framework, which achieves high agreement with human\nannotations while being cost-effective. Using this framework, we conduct\ncontrolled experiments and find that longer responses exhibit lower factual\nprecision, confirming the presence of length bias. To explain this phenomenon,\nwe empirically examine three hypotheses: error propagation, long context, and\nfacts exhaustion. Our results reveal that facts exhaustion, where the model\ngradually exhausts more reliable knowledge, is the primary cause of factual\ndegradation, rather than the other two hypotheses.", "AI": {"tldr": "Longer responses from LLMs tend to have lower factual precision due to facts exhaustion, not error propagation or long context.", "motivation": "To investigate the underexplored relationship between response length and factuality in LLMs, addressing reliability concerns.", "method": "Introduces an automatic, bi-level long-form factuality evaluation framework and conducts controlled experiments to test three hypotheses.", "result": "Longer responses show lower factual precision, with facts exhaustion identified as the primary cause.", "conclusion": "Facts exhaustion, not error propagation or long context, drives factual degradation in longer LLM responses."}}
{"id": "2505.23253", "pdf": "https://arxiv.org/pdf/2505.23253", "abs": "https://arxiv.org/abs/2505.23253", "authors": ["Yixun Liang", "Kunming Luo", "Xiao Chen", "Rui Chen", "Hongyu Yan", "Weiyu Li", "Jiarui Liu", "Ping Tan"], "title": "UniTEX: Universal High Fidelity Generative Texturing for 3D Shapes", "categories": ["cs.CV"], "comment": "10 pages, 9 figures", "summary": "We present UniTEX, a novel two-stage 3D texture generation framework to\ncreate high-quality, consistent textures for 3D assets. Existing approaches\npredominantly rely on UV-based inpainting to refine textures after reprojecting\nthe generated multi-view images onto the 3D shapes, which introduces challenges\nrelated to topological ambiguity. To address this, we propose to bypass the\nlimitations of UV mapping by operating directly in a unified 3D functional\nspace. Specifically, we first propose that lifts texture generation into 3D\nspace via Texture Functions (TFs)--a continuous, volumetric representation that\nmaps any 3D point to a texture value based solely on surface proximity,\nindependent of mesh topology. Then, we propose to predict these TFs directly\nfrom images and geometry inputs using a transformer-based Large Texturing Model\n(LTM). To further enhance texture quality and leverage powerful 2D priors, we\ndevelop an advanced LoRA-based strategy for efficiently adapting large-scale\nDiffusion Transformers (DiTs) for high-quality multi-view texture synthesis as\nour first stage. Extensive experiments demonstrate that UniTEX achieves\nsuperior visual quality and texture integrity compared to existing approaches,\noffering a generalizable and scalable solution for automated 3D texture\ngeneration. Code will available in: https://github.com/YixunLiang/UniTEX.", "AI": {"tldr": "UniTEX is a two-stage 3D texture generation framework that bypasses UV mapping by using a 3D functional space, achieving high-quality, consistent textures for 3D assets.", "motivation": "Existing UV-based methods face topological ambiguity issues when refining textures. UniTEX aims to overcome these limitations by operating directly in 3D space.", "method": "1. Uses Texture Functions (TFs) for continuous volumetric representation. 2. Predicts TFs from images/geometry via a transformer-based Large Texturing Model (LTM). 3. Employs LoRA-based strategy for high-quality multi-view texture synthesis.", "result": "UniTEX outperforms existing methods in visual quality and texture integrity, offering a scalable solution for automated 3D texture generation.", "conclusion": "UniTEX provides a generalizable and efficient approach for 3D texture generation, avoiding UV mapping limitations."}}
{"id": "2505.23181", "pdf": "https://arxiv.org/pdf/2505.23181", "abs": "https://arxiv.org/abs/2505.23181", "authors": ["Tian Tian", "Chunyan Miao", "Hangwei Qian"], "title": "FreRA: A Frequency-Refined Augmentation for Contrastive Learning on Time Series Classification", "categories": ["cs.LG", "cs.AI", "I.2.6"], "comment": "KDD 2025", "summary": "Contrastive learning has emerged as a competent approach for unsupervised\nrepresentation learning. However, the design of an optimal augmentation\nstrategy, although crucial for contrastive learning, is less explored for time\nseries classification tasks. Existing predefined time-domain augmentation\nmethods are primarily adopted from vision and are not specific to time series\ndata. Consequently, this cross-modality incompatibility may distort the\nsemantically relevant information of time series by introducing mismatched\npatterns into the data. To address this limitation, we present a novel\nperspective from the frequency domain and identify three advantages for\ndownstream classification: global, independent, and compact. To fully utilize\nthe three properties, we propose the lightweight yet effective Frequency\nRefined Augmentation (FreRA) tailored for time series contrastive learning on\nclassification tasks, which can be seamlessly integrated with contrastive\nlearning frameworks in a plug-and-play manner. Specifically, FreRA\nautomatically separates critical and unimportant frequency components.\nAccordingly, we propose semantic-aware Identity Modification and\nsemantic-agnostic Self-adaptive Modification to protect semantically relevant\ninformation in the critical frequency components and infuse variance into the\nunimportant ones respectively. Theoretically, we prove that FreRA generates\nsemantic-preserving views. Empirically, we conduct extensive experiments on two\nbenchmark datasets, including UCR and UEA archives, as well as five large-scale\ndatasets on diverse applications. FreRA consistently outperforms ten leading\nbaselines on time series classification, anomaly detection, and transfer\nlearning tasks, demonstrating superior capabilities in contrastive\nrepresentation learning and generalization in transfer learning scenarios\nacross diverse datasets.", "AI": {"tldr": "The paper introduces Frequency Refined Augmentation (FreRA), a novel frequency-domain method for contrastive learning in time series classification, outperforming existing baselines.", "motivation": "Existing augmentation methods for contrastive learning in time series are borrowed from vision and may distort semantically relevant information. The paper addresses this by proposing a frequency-domain approach.", "method": "FreRA separates critical and unimportant frequency components, using semantic-aware and semantic-agnostic modifications to preserve and infuse variance, respectively.", "result": "FreRA outperforms ten baselines on benchmark datasets (UCR, UEA) and large-scale datasets, excelling in classification, anomaly detection, and transfer learning.", "conclusion": "FreRA is a lightweight, effective, and plug-and-play solution for time series contrastive learning, demonstrating superior performance and generalization."}}
{"id": "2505.23131", "pdf": "https://arxiv.org/pdf/2505.23131", "abs": "https://arxiv.org/abs/2505.23131", "authors": ["Xinyu Yao", "Daniel Bourgeois", "Abhinav Jain", "Yuxin Tang", "Jiawen Yao", "Zhimin Ding", "Arlei Silva", "Chris Jermaine"], "title": "DOPPLER: Dual-Policy Learning for Device Assignment in Asynchronous Dataflow Graphs", "categories": ["cs.LG", "cs.DC"], "comment": "32 pages, 19 figures", "summary": "We study the problem of assigning operations in a dataflow graph to devices\nto minimize execution time in a work-conserving system, with emphasis on\ncomplex machine learning workloads. Prior learning-based methods often struggle\ndue to three key limitations: (1) reliance on bulk-synchronous systems like\nTensorFlow, which under-utilize devices due to barrier synchronization; (2)\nlack of awareness of the scheduling mechanism of underlying systems when\ndesigning learning-based methods; and (3) exclusive dependence on reinforcement\nlearning, ignoring the structure of effective heuristics designed by experts.\nIn this paper, we propose \\textsc{Doppler}, a three-stage framework for\ntraining dual-policy networks consisting of 1) a $\\mathsf{SEL}$ policy for\nselecting operations and 2) a $\\mathsf{PLC}$ policy for placing chosen\noperations on devices. Our experiments show that \\textsc{Doppler} outperforms\nall baseline methods across tasks by reducing system execution time and\nadditionally demonstrates sampling efficiency by reducing per-episode training\ntime.", "AI": {"tldr": "Doppler is a three-stage framework for optimizing operation assignment in dataflow graphs, outperforming baselines by reducing execution and training time.", "motivation": "Address limitations in prior learning-based methods, such as under-utilization of devices, lack of system-awareness, and over-reliance on reinforcement learning.", "method": "Uses dual-policy networks: SEL for operation selection and PLC for device placement.", "result": "Outperforms baselines in reducing execution time and improves sampling efficiency.", "conclusion": "Doppler effectively optimizes complex machine learning workloads by combining expert heuristics with learning-based policies."}}
{"id": "2505.23297", "pdf": "https://arxiv.org/pdf/2505.23297", "abs": "https://arxiv.org/abs/2505.23297", "authors": ["Daryna Dementieva", "Nikolay Babakov", "Alexander Fraser"], "title": "EmoBench-UA: A Benchmark Dataset for Emotion Detection in Ukrainian", "categories": ["cs.CL"], "comment": null, "summary": "While Ukrainian NLP has seen progress in many texts processing tasks, emotion\nclassification remains an underexplored area with no publicly available\nbenchmark to date. In this work, we introduce EmoBench-UA, the first annotated\ndataset for emotion detection in Ukrainian texts. Our annotation schema is\nadapted from the previous English-centric works on emotion detection (Mohammad\net al., 2018; Mohammad, 2022) guidelines. The dataset was created through\ncrowdsourcing using the Toloka.ai platform ensuring high-quality of the\nannotation process. Then, we evaluate a range of approaches on the collected\ndataset, starting from linguistic-based baselines, synthetic data translated\nfrom English, to large language models (LLMs). Our findings highlight the\nchallenges of emotion classification in non-mainstream languages like Ukrainian\nand emphasize the need for further development of Ukrainian-specific models and\ntraining resources.", "AI": {"tldr": "EmoBench-UA is the first annotated dataset for emotion detection in Ukrainian, addressing a gap in Ukrainian NLP. It uses crowdsourcing for annotation and evaluates various methods, revealing challenges in non-mainstream languages.", "motivation": "Emotion classification in Ukrainian is underexplored, lacking public benchmarks. This work fills the gap by introducing EmoBench-UA.", "method": "The dataset is annotated via crowdsourcing (Toloka.ai), adapting English-centric guidelines. Evaluated methods include linguistic baselines, synthetic data, and LLMs.", "result": "Challenges in emotion classification for Ukrainian are highlighted, showing the need for Ukrainian-specific models and resources.", "conclusion": "EmoBench-UA is a foundational step for Ukrainian emotion detection, calling for further development in this area."}}
{"id": "2505.23265", "pdf": "https://arxiv.org/pdf/2505.23265", "abs": "https://arxiv.org/abs/2505.23265", "authors": ["Zheng Sun", "Yi Wei", "Long Yu"], "title": "Image Aesthetic Reasoning: A New Benchmark for Medical Image Screening with MLLMs", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) are of great application across many\ndomains, such as multimodal understanding and generation. With the development\nof diffusion models (DM) and unified MLLMs, the performance of image generation\nhas been significantly improved, however, the study of image screening is rare\nand its performance with MLLMs is unsatisfactory due to the lack of data and\nthe week image aesthetic reasoning ability in MLLMs. In this work, we propose a\ncomplete solution to address these problems in terms of data and methodology.\nFor data, we collect a comprehensive medical image screening dataset with 1500+\nsamples, each sample consists of a medical image, four generated images, and a\nmultiple-choice answer. The dataset evaluates the aesthetic reasoning ability\nunder four aspects: \\textit{(1) Appearance Deformation, (2) Principles of\nPhysical Lighting and Shadow, (3) Placement Layout, (4) Extension Rationality}.\nFor methodology, we utilize long chains of thought (CoT) and Group Relative\nPolicy Optimization with Dynamic Proportional Accuracy reward, called DPA-GRPO,\nto enhance the image aesthetic reasoning ability of MLLMs. Our experimental\nresults reveal that even state-of-the-art closed-source MLLMs, such as GPT-4o\nand Qwen-VL-Max, exhibit performance akin to random guessing in image aesthetic\nreasoning. In contrast, by leveraging the reinforcement learning approach, we\nare able to surpass the score of both large-scale models and leading\nclosed-source models using a much smaller model. We hope our attempt on medical\nimage screening will serve as a regular configuration in image aesthetic\nreasoning in the future.", "AI": {"tldr": "The paper proposes a solution to improve image aesthetic reasoning in MLLMs using a new dataset and reinforcement learning method (DPA-GRPO), outperforming state-of-the-art models.", "motivation": "Current MLLMs struggle with image aesthetic reasoning due to lack of data and weak reasoning abilities, especially in medical image screening.", "method": "Uses a dataset of 1500+ medical images with generated variants and applies DPA-GRPO, a reinforcement learning approach with long chains of thought.", "result": "Outperforms large-scale and closed-source models (e.g., GPT-4o) in aesthetic reasoning, achieving better scores with a smaller model.", "conclusion": "The approach could standardize image aesthetic reasoning, particularly in medical screening."}}
{"id": "2505.23195", "pdf": "https://arxiv.org/pdf/2505.23195", "abs": "https://arxiv.org/abs/2505.23195", "authors": ["Lifan Zhao", "Yanyan Shen", "Zhaoyang Liu", "Xue Wang", "Jiaji Deng"], "title": "Less is More: Unlocking Specialization of Time Series Foundation Models via Structured Pruning", "categories": ["cs.LG", "cs.AI"], "comment": "Manuscript with fixed typos and figures", "summary": "Scaling laws motivate the development of Time Series Foundation Models\n(TSFMs) that pre-train vast parameters and achieve remarkable zero-shot\nforecasting performance. Surprisingly, even after fine-tuning, TSFMs cannot\nconsistently outperform smaller, specialized models trained on full-shot\ndownstream data. A key question is how to realize effective adaptation of TSFMs\nfor a target forecasting task. Through empirical studies on various TSFMs, the\npre-trained models often exhibit inherent sparsity and redundancy in\ncomputation, suggesting that TSFMs have learned to activate task-relevant\nnetwork substructures to accommodate diverse forecasting tasks. To preserve\nthis valuable prior knowledge, we propose a structured pruning method to\nregularize the subsequent fine-tuning process by focusing it on a more relevant\nand compact parameter space. Extensive experiments on seven TSFMs and six\nbenchmarks demonstrate that fine-tuning a smaller, pruned TSFM significantly\nimproves forecasting performance compared to fine-tuning original models. This\n\"prune-then-finetune\" paradigm often enables TSFMs to achieve state-of-the-art\nperformance and surpass strong specialized baselines.", "AI": {"tldr": "Pruning pre-trained Time Series Foundation Models (TSFMs) before fine-tuning improves forecasting performance, often surpassing specialized models.", "motivation": "Despite their zero-shot capabilities, TSFMs underperform smaller specialized models after fine-tuning, prompting the need for effective adaptation methods.", "method": "A structured pruning method is proposed to focus fine-tuning on relevant and compact parameter spaces, leveraging inherent sparsity in TSFMs.", "result": "Fine-tuning pruned TSFMs outperforms original models and achieves state-of-the-art performance on benchmarks.", "conclusion": "The \"prune-then-finetune\" paradigm enhances TSFM adaptation, making them competitive with specialized models."}}
{"id": "2505.23150", "pdf": "https://arxiv.org/pdf/2505.23150", "abs": "https://arxiv.org/abs/2505.23150", "authors": ["Michal Nauman", "Marek Cygan", "Carmelo Sferrazza", "Aviral Kumar", "Pieter Abbeel"], "title": "Bigger, Regularized, Categorical: High-Capacity Value Functions are Efficient Multi-Task Learners", "categories": ["cs.LG"], "comment": "preprint", "summary": "Recent advances in language modeling and vision stem from training large\nmodels on diverse, multi-task data. This paradigm has had limited impact in\nvalue-based reinforcement learning (RL), where improvements are often driven by\nsmall models trained in a single-task context. This is because in multi-task RL\nsparse rewards and gradient conflicts make optimization of temporal difference\nbrittle. Practical workflows for generalist policies therefore avoid online\ntraining, instead cloning expert trajectories or distilling collections of\nsingle-task policies into one agent. In this work, we show that the use of\nhigh-capacity value models trained via cross-entropy and conditioned on\nlearnable task embeddings addresses the problem of task interference in online\nRL, allowing for robust and scalable multi-task training. We test our approach\non 7 multi-task benchmarks with over 280 unique tasks, spanning high\ndegree-of-freedom humanoid control and discrete vision-based RL. We find that,\ndespite its simplicity, the proposed approach leads to state-of-the-art single\nand multi-task performance, as well as sample-efficient transfer to new tasks.", "AI": {"tldr": "High-capacity value models with learnable task embeddings enable robust multi-task RL, outperforming single-task methods.", "motivation": "Address task interference in online RL by improving multi-task training with scalable, high-capacity models.", "method": "Train value models via cross-entropy with learnable task embeddings on diverse tasks.", "result": "Achieves state-of-the-art performance on 280+ tasks, including humanoid control and vision-based RL.", "conclusion": "The approach enables scalable, sample-efficient multi-task RL with superior transfer capabilities."}}
{"id": "2505.23299", "pdf": "https://arxiv.org/pdf/2505.23299", "abs": "https://arxiv.org/abs/2505.23299", "authors": ["Julia Belikova", "Konstantin Polev", "Rauf Parchiev", "Dmitry Simakov"], "title": "Data-efficient Meta-models for Evaluation of Context-based Questions and Answers in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems\nare increasingly deployed in industry applications, yet their reliability\nremains hampered by challenges in detecting hallucinations. While supervised\nstate-of-the-art (SOTA) methods that leverage LLM hidden states -- such as\nactivation tracing and representation analysis -- show promise, their\ndependence on extensively annotated datasets limits scalability in real-world\napplications. This paper addresses the critical bottleneck of data annotation\nby investigating the feasibility of reducing training data requirements for two\nSOTA hallucination detection frameworks: Lookback Lens, which analyzes\nattention head dynamics, and probing-based approaches, which decode internal\nmodel representations. We propose a methodology combining efficient\nclassification algorithms with dimensionality reduction techniques to minimize\nsample size demands while maintaining competitive performance. Evaluations on\nstandardized question-answering RAG benchmarks show that our approach achieves\nperformance comparable to strong proprietary LLM-based baselines with only 250\ntraining samples. These results highlight the potential of lightweight,\ndata-efficient paradigms for industrial deployment, particularly in\nannotation-constrained scenarios.", "AI": {"tldr": "The paper proposes a lightweight method to reduce training data requirements for hallucination detection in LLMs and RAG systems, achieving competitive performance with only 250 samples.", "motivation": "The reliability of LLMs and RAG systems is limited by hallucination detection challenges, and existing SOTA methods rely on extensive annotated data, hindering scalability.", "method": "Combines efficient classification algorithms with dimensionality reduction to minimize sample size needs while maintaining performance for hallucination detection frameworks like Lookback Lens and probing-based approaches.", "result": "The approach achieves performance comparable to proprietary LLM baselines with just 250 training samples on standardized benchmarks.", "conclusion": "Lightweight, data-efficient methods are viable for industrial deployment, especially in annotation-constrained scenarios."}}
{"id": "2505.23271", "pdf": "https://arxiv.org/pdf/2505.23271", "abs": "https://arxiv.org/abs/2505.23271", "authors": ["Mao-Lin Luo", "Zi-Hao Zhou", "Tong Wei", "Min-Ling Zhang"], "title": "LADA: Scalable Label-Specific CLIP Adapter for Continual Learning", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at ICML 2025", "summary": "Continual learning with vision-language models like CLIP offers a pathway\ntoward scalable machine learning systems by leveraging its transferable\nrepresentations. Existing CLIP-based methods adapt the pre-trained image\nencoder by adding multiple sets of learnable parameters, with each task using a\npartial set of parameters. This requires selecting the expected parameters for\ninput images during inference, which is prone to error that degrades\nperformance. To address this problem, we introduce LADA (Label-specific\nADApter). Instead of partitioning parameters across tasks, LADA appends\nlightweight, label-specific memory units to the frozen CLIP image encoder,\nenabling discriminative feature generation by aggregating task-agnostic\nknowledge. To prevent catastrophic forgetting, LADA employs feature\ndistillation for seen classes, preventing their features from being interfered\nwith by new classes. Positioned after the image encoder, LADA prevents gradient\nflow to the frozen CLIP parameters, ensuring efficient training. Extensive\nresults show that LADA achieves state-of-the-art performance in continual\nlearning settings. The implementation code is available at\nhttps://github.com/MaolinLuo/LADA.", "AI": {"tldr": "LADA introduces label-specific adapters to CLIP for continual learning, avoiding parameter partitioning and improving performance.", "motivation": "Existing CLIP-based methods partition parameters for tasks, leading to inference errors and degraded performance.", "method": "LADA adds lightweight, label-specific memory units to the frozen CLIP encoder, using feature distillation to prevent forgetting.", "result": "LADA achieves state-of-the-art performance in continual learning.", "conclusion": "LADA efficiently adapts CLIP for continual learning without modifying its core parameters."}}
{"id": "2505.23239", "pdf": "https://arxiv.org/pdf/2505.23239", "abs": "https://arxiv.org/abs/2505.23239", "authors": ["Lingkai Meng", "Yu Shao", "Long Yuan", "Longbin Lai", "Peng Cheng", "Wenyuan Yu", "Wenjie Zhang", "Xuemin Lin", "Jingren Zhou"], "title": "OSS-UAgent: An Agent-based Usability Evaluation Framework for Open Source Software", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Usability evaluation is critical to the impact and adoption of open source\nsoftware (OSS), yet traditional methods relying on human evaluators suffer from\nhigh costs and limited scalability. To address these limitations, we introduce\nOSS-UAgent, an automated, configurable, and interactive agent-based usability\nevaluation framework specifically designed for open source software. Our\nframework employs intelligent agents powered by large language models (LLMs) to\nsimulate developers performing programming tasks across various experience\nlevels (from Junior to Expert). By dynamically constructing platform-specific\nknowledge bases, OSS-UAgent ensures accurate and context-aware code generation.\nThe generated code is automatically evaluated across multiple dimensions,\nincluding compliance, correctness, and readability, providing a comprehensive\nmeasure of the software's usability. Additionally, our demonstration showcases\nOSS-UAgent's practical application in evaluating graph analytics platforms,\nhighlighting its effectiveness in automating usability evaluation.", "AI": {"tldr": "OSS-UAgent is an automated, agent-based framework using LLMs to evaluate OSS usability, overcoming scalability and cost issues of human evaluators.", "motivation": "Traditional usability evaluation methods for OSS are costly and lack scalability, necessitating an automated solution.", "method": "OSS-UAgent employs LLM-powered agents to simulate developers of varying experience levels, dynamically builds knowledge bases, and evaluates code across compliance, correctness, and readability.", "result": "The framework effectively automates usability evaluation, demonstrated in graph analytics platforms.", "conclusion": "OSS-UAgent provides a scalable, cost-effective solution for OSS usability evaluation, with practical applications in real-world scenarios."}}
{"id": "2505.23173", "pdf": "https://arxiv.org/pdf/2505.23173", "abs": "https://arxiv.org/abs/2505.23173", "authors": ["Shohei Enomoto"], "title": "Pseudo Multi-Source Domain Generalization: Bridging the Gap Between Single and Multi-Source Domain Generalization", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Deep learning models often struggle to maintain performance when deployed on\ndata distributions different from their training data, particularly in\nreal-world applications where environmental conditions frequently change. While\nMulti-source Domain Generalization (MDG) has shown promise in addressing this\nchallenge by leveraging multiple source domains during training, its practical\napplication is limited by the significant costs and difficulties associated\nwith creating multi-domain datasets. To address this limitation, we propose\nPseudo Multi-source Domain Generalization (PMDG), a novel framework that\nenables the application of sophisticated MDG algorithms in more practical\nSingle-source Domain Generalization (SDG) settings. PMDG generates multiple\npseudo-domains from a single source domain through style transfer and data\naugmentation techniques, creating a synthetic multi-domain dataset that can be\nused with existing MDG algorithms. Through extensive experiments with\nPseudoDomainBed, our modified version of the DomainBed benchmark, we analyze\nthe effectiveness of PMDG across multiple datasets and architectures. Our\nanalysis reveals several key findings, including a positive correlation between\nMDG and PMDG performance and the potential of pseudo-domains to match or exceed\nactual multi-domain performance with sufficient data. These comprehensive\nempirical results provide valuable insights for future research in domain\ngeneralization. Our code is available at\nhttps://github.com/s-enmt/PseudoDomainBed.", "AI": {"tldr": "PMDG enables MDG algorithms in SDG settings by generating pseudo-domains from a single source, achieving comparable performance to multi-domain training.", "motivation": "Deep learning models often fail on unseen data distributions, and MDG is costly to implement due to multi-domain dataset requirements.", "method": "PMDG uses style transfer and data augmentation to create pseudo-domains from a single source, tested via PseudoDomainBed.", "result": "PMDG shows a positive correlation with MDG performance and can match or exceed multi-domain results with enough data.", "conclusion": "PMDG offers a practical solution for domain generalization, with potential for future research."}}
{"id": "2505.23304", "pdf": "https://arxiv.org/pdf/2505.23304", "abs": "https://arxiv.org/abs/2505.23304", "authors": ["Yi Luo", "Qiwen Wang", "Junqi Yang", "Luyao Tang", "Zhenghao Lin", "Zhenzhe Ying", "Weiqiang Wang", "Chen Lin"], "title": "Generalized Category Discovery in Event-Centric Contexts: Latent Pattern Mining with LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Generalized Category Discovery (GCD) aims to classify both known and novel\ncategories using partially labeled data that contains only known classes.\nDespite achieving strong performance on existing benchmarks, current textual\nGCD methods lack sufficient validation in realistic settings. We introduce\nEvent-Centric GCD (EC-GCD), characterized by long, complex narratives and\nhighly imbalanced class distributions, posing two main challenges: (1)\ndivergent clustering versus classification groupings caused by subjective\ncriteria, and (2) Unfair alignment for minority classes. To tackle these, we\npropose PaMA, a framework leveraging LLMs to extract and refine event patterns\nfor improved cluster-class alignment. Additionally, a ranking-filtering-mining\npipeline ensures balanced representation of prototypes across imbalanced\ncategories. Evaluations on two EC-GCD benchmarks, including a newly constructed\nScam Report dataset, demonstrate that PaMA outperforms prior methods with up to\n12.58% H-score gains, while maintaining strong generalization on base GCD\ndatasets.", "AI": {"tldr": "PaMA improves GCD by addressing clustering-classification divergence and minority class unfairness using LLMs and a ranking-filtering-mining pipeline, achieving up to 12.58% H-score gains.", "motivation": "Current GCD methods lack validation in realistic settings with long narratives and imbalanced classes, leading to unfair alignment and divergent groupings.", "method": "Proposes PaMA, leveraging LLMs to refine event patterns and a pipeline for balanced prototype representation.", "result": "Outperforms prior methods with up to 12.58% H-score gains on EC-GCD benchmarks, including a new Scam Report dataset.", "conclusion": "PaMA effectively addresses GCD challenges in realistic settings while maintaining strong generalization."}}
{"id": "2505.23272", "pdf": "https://arxiv.org/pdf/2505.23272", "abs": "https://arxiv.org/abs/2505.23272", "authors": ["Yazhou Zhang", "Chunwang Zou", "Qimeng Liu", "Lu Rong", "Ben Yao", "Zheng Lian", "Qiuchi Li", "Peng Zhang", "Jing Qin"], "title": "Are MLMs Trapped in the Visual Room?", "categories": ["cs.CV"], "comment": null, "summary": "Can multi-modal large models (MLMs) that can ``see'' an image be said to\n``understand'' it? Drawing inspiration from Searle's Chinese Room, we propose\nthe \\textbf{Visual Room} argument: a system may process and describe every\ndetail of visual inputs by following algorithmic rules, without genuinely\ncomprehending the underlying intention. This dilemma challenges the prevailing\nassumption that perceptual mastery implies genuine understanding. In\nimplementation, we introduce a two-tier evaluation framework spanning\nperception and cognition. The perception component evaluates whether MLMs can\naccurately capture the surface-level details of visual contents, where the\ncognitive component examines their ability to infer sarcasm polarity. To\nsupport this framework, We further introduce a high-quality multi-modal sarcasm\ndataset comprising both 924 static images and 100 dynamic videos. All sarcasm\nlabels are annotated by the original authors and verified by independent\nreviewers to ensure clarity and consistency. We evaluate eight state-of-the-art\n(SoTA) MLMs. Our results highlight three key findings: (1) MLMs perform well on\nperception tasks; (2) even with correct perception, models exhibit an average\nerror rate of ~16.1\\% in sarcasm understanding, revealing a significant gap\nbetween seeing and understanding; (3) error analysis attributes this gap to\ndeficiencies in emotional reasoning, commonsense inference, and context\nalignment. This work provides empirical grounding for the proposed Visual Room\nargument and offers a new evaluation paradigm for MLMs.", "AI": {"tldr": "The paper questions whether multi-modal large models (MLMs) truly understand images, proposing the Visual Room argument. It introduces a two-tier evaluation framework (perception and cognition) and a sarcasm dataset, revealing gaps in MLMs' understanding despite strong perception.", "motivation": "To challenge the assumption that perceptual mastery equates to genuine understanding in MLMs, inspired by Searle's Chinese Room.", "method": "A two-tier evaluation framework (perception and cognition) tested on eight SoTA MLMs using a sarcasm dataset (924 images, 100 videos).", "result": "MLMs excel in perception but struggle with sarcasm understanding (~16.1% error rate), highlighting gaps in emotional reasoning and context alignment.", "conclusion": "The Visual Room argument is empirically supported, revealing limitations in MLMs' understanding and proposing a new evaluation paradigm."}}
{"id": "2505.23247", "pdf": "https://arxiv.org/pdf/2505.23247", "abs": "https://arxiv.org/abs/2505.23247", "authors": ["Zonglin Yang", "Zhexuan Gu", "Houduo Qi", "Yancheng Yuan"], "title": "Accelerating RLHF Training with Reward Variance Increase", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "Reinforcement learning from human feedback (RLHF) is an essential technique\nfor ensuring that large language models (LLMs) are aligned with human values\nand preferences during the post-training phase. As an effective RLHF approach,\ngroup relative policy optimization (GRPO) has demonstrated success in many\nLLM-based applications. However, efficient GRPO-based RLHF training remains a\nchallenge. Recent studies reveal that a higher reward variance of the initial\npolicy model leads to faster RLHF training. Inspired by this finding, we\npropose a practical reward adjustment model to accelerate RLHF training by\nprovably increasing the reward variance and preserving the relative preferences\nand reward expectation. Our reward adjustment method inherently poses a\nnonconvex optimization problem, which is NP-hard to solve in general. To\novercome the computational challenges, we design a novel $O(n \\log n)$\nalgorithm to find a global solution of the nonconvex reward adjustment model by\nexplicitly characterizing the extreme points of the feasible set. As an\nimportant application, we naturally integrate this reward adjustment model into\nthe GRPO algorithm, leading to a more efficient GRPO with reward variance\nincrease (GRPOVI) algorithm for RLHF training. As an interesting byproduct, we\nprovide an indirect explanation for the empirical effectiveness of GRPO with\nrule-based reward for RLHF training, as demonstrated in DeepSeek-R1. Experiment\nresults demonstrate that the GRPOVI algorithm can significantly improve the\nRLHF training efficiency compared to the original GRPO algorithm.", "AI": {"tldr": "The paper introduces a reward adjustment model to accelerate RLHF training by increasing reward variance while preserving preferences and expectations, leading to the GRPOVI algorithm.", "motivation": "Efficient RLHF training remains challenging, and higher reward variance in initial policies speeds up training. The paper aims to address this by proposing a practical reward adjustment method.", "method": "A reward adjustment model is proposed to increase reward variance while maintaining relative preferences and expectations. A novel O(n log n) algorithm solves the nonconvex optimization problem.", "result": "The GRPOVI algorithm, integrating the reward adjustment model, significantly improves RLHF training efficiency compared to the original GRPO.", "conclusion": "The reward adjustment model and GRPOVI algorithm enhance RLHF training efficiency, with potential broader implications for RLHF methods."}}
{"id": "2505.23176", "pdf": "https://arxiv.org/pdf/2505.23176", "abs": "https://arxiv.org/abs/2505.23176", "authors": ["Shiwei Li", "Xiandi Luo", "Haozhao Wang", "Xing Tang", "Shijie Xu", "Weihong Luo", "Yuhua Li", "Xiuqiang He", "Ruixuan Li"], "title": "The Panaceas for Improving Low-Rank Decomposition in Communication-Efficient Federated Learning", "categories": ["cs.LG", "cs.DC"], "comment": "Accepted by ICML 2025", "summary": "To improve the training efficiency of federated learning (FL), previous\nresearch has employed low-rank decomposition techniques to reduce communication\noverhead. In this paper, we seek to enhance the performance of these low-rank\ndecomposition methods. Specifically, we focus on three key issues related to\ndecomposition in FL: what to decompose, how to decompose, and how to aggregate.\nSubsequently, we introduce three novel techniques: Model Update Decomposition\n(MUD), Block-wise Kronecker Decomposition (BKD), and Aggregation-Aware\nDecomposition (AAD), each targeting a specific issue. These techniques are\ncomplementary and can be applied simultaneously to achieve optimal performance.\nAdditionally, we provide a rigorous theoretical analysis to ensure the\nconvergence of the proposed MUD. Extensive experimental results show that our\napproach achieves faster convergence and superior accuracy compared to relevant\nbaseline methods. The code is available at\nhttps://github.com/Leopold1423/fedmud-icml25.", "AI": {"tldr": "The paper introduces three novel techniques (MUD, BKD, AAD) to enhance low-rank decomposition in federated learning, improving efficiency and performance.", "motivation": "To address key issues in low-rank decomposition for federated learning (what to decompose, how to decompose, and how to aggregate) and improve training efficiency.", "method": "Proposes Model Update Decomposition (MUD), Block-wise Kronecker Decomposition (BKD), and Aggregation-Aware Decomposition (AAD) to tackle the identified issues.", "result": "The techniques achieve faster convergence and superior accuracy compared to baseline methods, supported by theoretical analysis and experiments.", "conclusion": "The proposed methods are complementary and effective, offering optimal performance in federated learning."}}
{"id": "2505.23315", "pdf": "https://arxiv.org/pdf/2505.23315", "abs": "https://arxiv.org/abs/2505.23315", "authors": ["Abhirup Chakravarty", "Mark Brenchley", "Trevor Breakspear", "Ian Lewin", "Yan Huang"], "title": "Enhancing Marker Scoring Accuracy through Ordinal Confidence Modelling in Educational Assessments", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "This is the preprint version of our paper accepted to ACL 2025\n  (Industry Track). The DOI will be added once available", "summary": "A key ethical challenge in Automated Essay Scoring (AES) is ensuring that\nscores are only released when they meet high reliability standards. Confidence\nmodelling addresses this by assigning a reliability estimate measure, in the\nform of a confidence score, to each automated score. In this study, we frame\nconfidence estimation as a classification task: predicting whether an\nAES-generated score correctly places a candidate in the appropriate CEFR level.\nWhile this is a binary decision, we leverage the inherent granularity of the\nscoring domain in two ways. First, we reformulate the task as an n-ary\nclassification problem using score binning. Second, we introduce a set of novel\nKernel Weighted Ordinal Categorical Cross Entropy (KWOCCE) loss functions that\nincorporate the ordinal structure of CEFR labels. Our best-performing model\nachieves an F1 score of 0.97, and enables the system to release 47% of scores\nwith 100% CEFR agreement and 99% with at least 95% CEFR agreement -compared to\napproximately 92% (approx.) CEFR agreement from the standalone AES model where\nwe release all AM predicted scores.", "AI": {"tldr": "The paper proposes a confidence estimation method for AES by framing it as a classification task, achieving high reliability in score releases.", "motivation": "To ensure AES scores meet high reliability standards by predicting whether scores correctly align with CEFR levels.", "method": "Frames confidence estimation as an n-ary classification task using score binning and introduces KWOCCE loss functions to incorporate CEFR's ordinal structure.", "result": "Best model achieves F1 score of 0.97, enabling release of 47% scores with 100% CEFR agreement and 99% with at least 95% agreement.", "conclusion": "The method significantly improves reliability of AES score releases compared to standalone models."}}
{"id": "2505.23280", "pdf": "https://arxiv.org/pdf/2505.23280", "abs": "https://arxiv.org/abs/2505.23280", "authors": ["Chuandong Liu", "Huijiao Wang", "Lei Yu", "Gui-Song Xia"], "title": "Holistic Large-Scale Scene Reconstruction via Mixed Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in 3D Gaussian Splatting have shown remarkable potential for\nnovel view synthesis. However, most existing large-scale scene reconstruction\nmethods rely on the divide-and-conquer paradigm, which often leads to the loss\nof global scene information and requires complex parameter tuning due to scene\npartitioning and local optimization. To address these limitations, we propose\nMixGS, a novel holistic optimization framework for large-scale 3D scene\nreconstruction. MixGS models the entire scene holistically by integrating\ncamera pose and Gaussian attributes into a view-aware representation, which is\ndecoded into fine-detailed Gaussians. Furthermore, a novel mixing operation\ncombines decoded and original Gaussians to jointly preserve global coherence\nand local fidelity. Extensive experiments on large-scale scenes demonstrate\nthat MixGS achieves state-of-the-art rendering quality and competitive speed,\nwhile significantly reducing computational requirements, enabling large-scale\nscene reconstruction training on a single 24GB VRAM GPU. The code will be\nreleased at https://github.com/azhuantou/MixGS.", "AI": {"tldr": "MixGS is a holistic optimization framework for large-scale 3D scene reconstruction, improving rendering quality and efficiency by integrating global and local information without complex parameter tuning.", "motivation": "Existing methods lose global scene information and require complex tuning due to divide-and-conquer approaches.", "method": "MixGS integrates camera pose and Gaussian attributes into a view-aware representation, decoded into fine Gaussians, and uses a mixing operation to preserve global coherence and local fidelity.", "result": "MixGS achieves state-of-the-art rendering quality and competitive speed, reducing computational needs for training on a single 24GB VRAM GPU.", "conclusion": "MixGS offers an efficient, high-quality solution for large-scale 3D scene reconstruction, with code available for public use."}}
{"id": "2505.23250", "pdf": "https://arxiv.org/pdf/2505.23250", "abs": "https://arxiv.org/abs/2505.23250", "authors": ["Pascal J. Sager", "Ashwini Kamaraj", "Benjamin F. Grewe", "Thilo Stadelmann"], "title": "Deep Retrieval at CheckThat! 2025: Identifying Scientific Papers from Implicit Social Media Mentions via Hybrid Retrieval and Re-Ranking", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "We present the methodology and results of the Deep Retrieval team for subtask\n4b of the CLEF CheckThat! 2025 competition, which focuses on retrieving\nrelevant scientific literature for given social media posts. To address this\ntask, we propose a hybrid retrieval pipeline that combines lexical precision,\nsemantic generalization, and deep contextual re-ranking, enabling robust\nretrieval that bridges the informal-to-formal language gap. Specifically, we\ncombine BM25-based keyword matching with a FAISS vector store using a\nfine-tuned INF-Retriever-v1 model for dense semantic retrieval. BM25 returns\nthe top 30 candidates, and semantic search yields 100 candidates, which are\nthen merged and re-ranked via a large language model (LLM)-based cross-encoder.\n  Our approach achieves a mean reciprocal rank at 5 (MRR@5) of 76.46% on the\ndevelopment set and 66.43% on the hidden test set, securing the 1st position on\nthe development leaderboard and ranking 3rd on the test leaderboard (out of 31\nteams), with a relative performance gap of only 2 percentage points compared to\nthe top-ranked system. We achieve this strong performance by running\nopen-source models locally and without external training data, highlighting the\neffectiveness of a carefully designed and fine-tuned retrieval pipeline.", "AI": {"tldr": "The paper presents a hybrid retrieval pipeline combining lexical and semantic methods for retrieving scientific literature from social media posts, achieving top performance in the CLEF CheckThat! 2025 competition.", "motivation": "To bridge the gap between informal social media language and formal scientific literature by developing a robust retrieval system.", "method": "A hybrid pipeline combining BM25 keyword matching, FAISS vector store with INF-Retriever-v1 for semantic retrieval, and LLM-based cross-encoder re-ranking.", "result": "Achieved MRR@5 of 76.46% (dev) and 66.43% (test), ranking 1st and 3rd respectively among 31 teams.", "conclusion": "The hybrid pipeline demonstrates strong performance using open-source models and no external training data, proving its effectiveness."}}
{"id": "2505.23182", "pdf": "https://arxiv.org/pdf/2505.23182", "abs": "https://arxiv.org/abs/2505.23182", "authors": ["Srijith Nair", "Michael Lin", "Amirreza Talebi", "Peizhong Ju", "Elizabeth Bentley", "Jia Liu"], "title": "FSL-SAGE: Accelerating Federated Split Learning via Smashed Activation Gradient Estimation", "categories": ["cs.LG"], "comment": "22 pages, 14 figures, Accepted at ICML 2025 as poster", "summary": "Collaborative training methods like Federated Learning (FL) and Split\nLearning (SL) enable distributed machine learning without sharing raw data.\nHowever, FL assumes clients can train entire models, which is infeasible for\nlarge-scale models. In contrast, while SL alleviates the client memory\nconstraint in FL by offloading most training to the server, it increases\nnetwork latency due to its sequential nature. Other methods address the\nconundrum by using local loss functions for parallel client-side training to\nimprove efficiency, but they lack server feedback and potentially suffer poor\naccuracy. We propose FSL-SAGE (Federated Split Learning via Smashed Activation\nGradient Estimation), a new federated split learning algorithm that estimates\nserver-side gradient feedback via auxiliary models. These auxiliary models\nperiodically adapt to emulate server behavior on local datasets. We show that\nFSL-SAGE achieves a convergence rate of $\\mathcal{O}(1/\\sqrt{T})$, where $T$ is\nthe number of communication rounds. This result matches FedAvg, while\nsignificantly reducing communication costs and client memory requirements. Our\nempirical results also verify that it outperforms existing state-of-the-art FSL\nmethods, offering both communication efficiency and accuracy.", "AI": {"tldr": "FSL-SAGE is a new federated split learning algorithm that combines the benefits of FL and SL while addressing their limitations, achieving efficient communication and accuracy.", "motivation": "Existing methods like FL and SL have trade-offs in client memory, network latency, and accuracy. FSL-SAGE aims to improve efficiency and accuracy by estimating server-side gradients locally.", "method": "FSL-SAGE uses auxiliary models to estimate server-side gradient feedback, enabling parallel client-side training while periodically adapting to server behavior.", "result": "The algorithm achieves a convergence rate of O(1/\u221aT), matching FedAvg, while reducing communication costs and client memory requirements. It outperforms existing FSL methods in efficiency and accuracy.", "conclusion": "FSL-SAGE successfully balances communication efficiency and accuracy, making it a promising solution for distributed machine learning."}}
{"id": "2505.23316", "pdf": "https://arxiv.org/pdf/2505.23316", "abs": "https://arxiv.org/abs/2505.23316", "authors": ["Kaiyang Guo", "Yinchuan Li", "Zhitang Chen"], "title": "Proximalized Preference Optimization for Diverse Feedback Types: A Decomposed Perspective on DPO", "categories": ["cs.CL"], "comment": null, "summary": "Direct alignment methods typically optimize large language models (LLMs) by\ncontrasting the likelihoods of preferred versus dispreferred responses. While\neffective in steering LLMs to match relative preference, these methods are\nfrequently noted for decreasing the absolute likelihoods of example responses.\nAs a result, aligned models tend to generate outputs that deviate from the\nexpected patterns, exhibiting reward-hacking effect even without a reward\nmodel. This undesired consequence exposes a fundamental limitation in\ncontrastive alignment, which we characterize as likelihood underdetermination.\nIn this work, we revisit direct preference optimization (DPO) -- the seminal\ndirect alignment method -- and demonstrate that its loss theoretically admits a\ndecomposed reformulation. The reformulated loss not only broadens applicability\nto a wider range of feedback types, but also provides novel insights into the\nunderlying cause of likelihood underdetermination. Specifically, the standard\nDPO implementation implicitly oversimplifies a regularizer in the reformulated\nloss, and reinstating its complete version effectively resolves the\nunderdetermination issue. Leveraging these findings, we introduce PRoximalized\nPReference Optimization (PRO), a unified method to align with diverse feeback\ntypes, eliminating likelihood underdetermination through an efficient\napproximation of the complete regularizer. Comprehensive experiments show the\nsuperiority of PRO over existing methods in scenarios involving pairwise,\nbinary and scalar feedback.", "AI": {"tldr": "The paper identifies a limitation in direct alignment methods for LLMs, called likelihood underdetermination, and introduces PRO, a method to address it by reformulating the DPO loss and incorporating a complete regularizer.", "motivation": "The paper aims to address the issue of likelihood underdetermination in direct alignment methods, which causes aligned models to deviate from expected patterns and exhibit reward-hacking effects.", "method": "The authors revisit DPO, reformulate its loss to decompose it, and introduce PRO, which includes a complete regularizer to resolve underdetermination.", "result": "PRO outperforms existing methods in scenarios with pairwise, binary, and scalar feedback, effectively eliminating likelihood underdetermination.", "conclusion": "The paper demonstrates that addressing the oversimplified regularizer in DPO through PRO resolves underdetermination and improves alignment with diverse feedback types."}}
{"id": "2505.23283", "pdf": "https://arxiv.org/pdf/2505.23283", "abs": "https://arxiv.org/abs/2505.23283", "authors": ["Zhihong Tan", "Jiayi Wang", "Huiying Shi", "Binyuan Huang", "Hongchen Wei", "Zhenzhong Chen"], "title": "RSFAKE-1M: A Large-Scale Dataset for Detecting Diffusion-Generated Remote Sensing Forgeries", "categories": ["cs.CV"], "comment": null, "summary": "Detecting forged remote sensing images is becoming increasingly critical, as\nsuch imagery plays a vital role in environmental monitoring, urban planning,\nand national security. While diffusion models have emerged as the dominant\nparadigm for image generation, their impact on remote sensing forgery detection\nremains underexplored. Existing benchmarks primarily target GAN-based forgeries\nor focus on natural images, limiting progress in this critical domain. To\naddress this gap, we introduce RSFAKE-1M, a large-scale dataset of 500K forged\nand 500K real remote sensing images. The fake images are generated by ten\ndiffusion models fine-tuned on remote sensing data, covering six generation\nconditions such as text prompts, structural guidance, and inpainting. This\npaper presents the construction of RSFAKE-1M along with a comprehensive\nexperimental evaluation using both existing detectors and unified baselines.\nThe results reveal that diffusion-based remote sensing forgeries remain\nchallenging for current methods, and that models trained on RSFAKE-1M exhibit\nnotably improved generalization and robustness. Our findings underscore the\nimportance of RSFAKE-1M as a foundation for developing and evaluating\nnext-generation forgery detection approaches in the remote sensing domain. The\ndataset and other supplementary materials are available at\nhttps://huggingface.co/datasets/TZHSW/RSFAKE/.", "AI": {"tldr": "The paper introduces RSFAKE-1M, a large-scale dataset for detecting forged remote sensing images generated by diffusion models, addressing a gap in existing benchmarks.", "motivation": "The rise of forged remote sensing images poses risks to applications like environmental monitoring and national security, yet current benchmarks focus on GAN-based forgeries or natural images, leaving diffusion-based forgeries underexplored.", "method": "The authors create RSFAKE-1M, a dataset of 500K real and 500K forged remote sensing images generated by ten diffusion models under six conditions. They evaluate existing detectors and unified baselines on this dataset.", "result": "Diffusion-based forgeries are challenging for current detection methods, but models trained on RSFAKE-1M show improved generalization and robustness.", "conclusion": "RSFAKE-1M is a critical resource for advancing forgery detection in remote sensing, highlighting the need for specialized datasets and methods to tackle diffusion-based forgeries."}}
{"id": "2505.23266", "pdf": "https://arxiv.org/pdf/2505.23266", "abs": "https://arxiv.org/abs/2505.23266", "authors": ["Chunlong Xie", "Jialing He", "Shangwei Guo", "Jiacheng Wang", "Shudong Zhang", "Tianwei Zhang", "Tao Xiang"], "title": "Disrupting Vision-Language Model-Driven Navigation Services via Adversarial Object Fusion", "categories": ["cs.CR", "cs.AI", "cs.CV"], "comment": "Under review", "summary": "We present Adversarial Object Fusion (AdvOF), a novel attack framework\ntargeting vision-and-language navigation (VLN) agents in service-oriented\nenvironments by generating adversarial 3D objects. While foundational models\nlike Large Language Models (LLMs) and Vision Language Models (VLMs) have\nenhanced service-oriented navigation systems through improved perception and\ndecision-making, their integration introduces vulnerabilities in\nmission-critical service workflows. Existing adversarial attacks fail to\naddress service computing contexts, where reliability and quality-of-service\n(QoS) are paramount. We utilize AdvOF to investigate and explore the impact of\nadversarial environments on the VLM-based perception module of VLN agents. In\nparticular, AdvOF first precisely aggregates and aligns the victim object\npositions in both 2D and 3D space, defining and rendering adversarial objects.\nThen, we collaboratively optimize the adversarial object with regularization\nbetween the adversarial and victim object across physical properties and VLM\nperceptions. Through assigning importance weights to varying views, the\noptimization is processed stably and multi-viewedly by iterative fusions from\nlocal updates and justifications. Our extensive evaluations demonstrate AdvOF\ncan effectively degrade agent performance under adversarial conditions while\nmaintaining minimal interference with normal navigation tasks. This work\nadvances the understanding of service security in VLM-powered navigation\nsystems, providing computational foundations for robust service composition in\nphysical-world deployments.", "AI": {"tldr": "AdvOF is a new attack framework targeting VLN agents by generating adversarial 3D objects, degrading performance while minimally affecting normal tasks.", "motivation": "Existing attacks overlook service computing contexts where reliability and QoS are critical. AdvOF explores vulnerabilities in VLM-based perception for VLN agents.", "method": "AdvOF aggregates and aligns victim objects in 2D/3D space, renders adversarial objects, and optimizes them collaboratively with regularization across physical properties and VLM perceptions.", "result": "AdvOF effectively degrades agent performance under adversarial conditions with minimal impact on normal navigation.", "conclusion": "This work enhances understanding of service security in VLM-powered systems, aiding robust service composition in real-world deployments."}}
{"id": "2505.23184", "pdf": "https://arxiv.org/pdf/2505.23184", "abs": "https://arxiv.org/abs/2505.23184", "authors": ["Hongcan Guo", "Guoshun Nan", "Yuan Yang", "Diyang Zhang", "Haotian Li", "Zhican Chen", "Qinchuan Zhou", "Yuhan Ran", "Xinye Cao", "Sicong Leng", "Xiaofeng Tao", "Xudong Jiang"], "title": "Two Is Better Than One: Rotations Scale LoRAs", "categories": ["cs.LG", "cs.SE", "68T50", "I.2.6"], "comment": "27pages, 16figures", "summary": "Scaling Low-Rank Adaptation (LoRA)-based Mixture-of-Experts (MoE) facilitates\nlarge language models (LLMs) to efficiently adapt to diverse tasks. However,\ntraditional gating mechanisms that route inputs to the best experts may\nfundamentally hinder LLMs' scalability, leading to poor generalization and\nunderfitting issues. We identify that the root cause lies in the restricted\nexpressiveness of existing weighted-sum mechanisms, both within and outside the\nconvex cone of LoRA representations. This motivates us to propose RadarGate, a\nnovel geometrically inspired gating method that introduces rotational\noperations of LoRAs representations to boost the expressiveness and facilitate\nricher feature interactions among multiple LoRAs for scalable LLMs.\nSpecifically, we first fuse each LoRA representation to other LoRAs using a\nlearnable component and then feed the output to a rotation matrix. This matrix\ninvolves learnable parameters that define the relative angular relationship\nbetween LoRA representations. Such a simple yet effective mechanism provides an\nextra degree of freedom, facilitating the learning of cross-LoRA synergies and\nproperly tracking the challenging poor generalization and underfitting issues\nas the number of LoRA grows. Extensive experiments on 6 public benchmarks\nacross 21 tasks show the effectiveness of our RadarGate for scaling LoRAs. We\nalso provide valuable insights, revealing that the rotations to each pair of\nrepresentations are contrastive, encouraging closer alignment of semantically\nsimilar representations during geometrical transformation while pushing\ndistance ones further apart. We will release our code to the community.", "AI": {"tldr": "RadarGate, a geometrically inspired gating method, enhances LoRA-based MoE scalability by introducing rotational operations, improving expressiveness and feature interactions in LLMs.", "motivation": "Traditional gating mechanisms limit LLM scalability due to poor generalization and underfitting, caused by restricted expressiveness in weighted-sum mechanisms.", "method": "RadarGate fuses LoRA representations using a learnable component and applies a rotation matrix to define angular relationships, enhancing cross-LoRA synergies.", "result": "Experiments on 6 benchmarks across 21 tasks demonstrate RadarGate's effectiveness in scaling LoRAs, with contrastive rotations improving semantic alignment.", "conclusion": "RadarGate addresses scalability issues in LoRA-based MoE, offering a simple yet effective solution with promising results and insights for future research."}}
{"id": "2505.23323", "pdf": "https://arxiv.org/pdf/2505.23323", "abs": "https://arxiv.org/abs/2505.23323", "authors": ["Harish Tayyar Madabushi", "Melissa Torgbi", "Claire Bonial"], "title": "Neither Stochastic Parroting nor AGI: LLMs Solve Tasks through Context-Directed Extrapolation from Training Data Priors", "categories": ["cs.CL"], "comment": null, "summary": "In this position paper we raise critical awareness of a realistic view of LLM\ncapabilities that eschews extreme alternative views that LLMs are either\n\"stochastic parrots\" or in possession of \"emergent\" advanced reasoning\ncapabilities, which, due to their unpredictable emergence, constitute an\nexistential threat. Our middle-ground view is that LLMs extrapolate from priors\nfrom their training data, and that a mechanism akin to in-context learning\nenables the targeting of the appropriate information from which to extrapolate.\nWe call this \"context-directed extrapolation.\" Under this view, substantiated\nthough existing literature, while reasoning capabilities go well beyond\nstochastic parroting, such capabilities are predictable, controllable, not\nindicative of advanced reasoning akin to high-level cognitive capabilities in\nhumans, and not infinitely scalable with additional training. As a result,\nfears of uncontrollable emergence of agency are allayed, while research\nadvances are appropriately refocused on the processes of context-directed\nextrapolation and how this interacts with training data to produce valuable\ncapabilities in LLMs. Future work can therefore explore alternative augmenting\ntechniques that do not rely on inherent advanced reasoning in LLMs.", "AI": {"tldr": "The paper argues for a balanced view of LLM capabilities, rejecting extreme views of them as either 'stochastic parrots' or possessing unpredictable advanced reasoning. It introduces 'context-directed extrapolation' as a predictable, controllable mechanism.", "motivation": "To address polarized views on LLM capabilities and propose a realistic middle-ground perspective.", "method": "Analyzes existing literature to support the concept of 'context-directed extrapolation' as the mechanism behind LLM reasoning.", "result": "LLMs' reasoning is predictable and controllable, not indicative of human-like cognition, and not infinitely scalable.", "conclusion": "Future research should focus on context-directed extrapolation and alternative techniques, avoiding reliance on assumed advanced reasoning in LLMs."}}
{"id": "2505.23287", "pdf": "https://arxiv.org/pdf/2505.23287", "abs": "https://arxiv.org/abs/2505.23287", "authors": ["Chikaha Tsuji", "Enrique Flores Medina", "Harshit Gupta", "Md Ferdous Alam"], "title": "GenCAD-Self-Repairing: Feasibility Enhancement for 3D CAD Generation", "categories": ["cs.CV"], "comment": null, "summary": "With the advancement of generative AI, research on its application to 3D\nmodel generation has gained traction, particularly in automating the creation\nof Computer-Aided Design (CAD) files from images. GenCAD is a notable model in\nthis domain, leveraging an autoregressive transformer-based architecture with a\ncontrastive learning framework to generate CAD programs.\n  However, a major limitation of GenCAD is its inability to consistently\nproduce feasible boundary representations (B-reps), with approximately 10% of\ngenerated designs being infeasible. To address this, we propose\nGenCAD-Self-Repairing, a framework that enhances the feasibility of generative\nCAD models through diffusion guidance and a self-repairing pipeline. This\nframework integrates a guided diffusion denoising process in the latent space\nand a regression-based correction mechanism to refine infeasible CAD command\nsequences while preserving geometric accuracy. Our approach successfully\nconverted two-thirds of infeasible designs in the baseline method into feasible\nones, significantly improving the feasibility rate while simultaneously\nmaintaining a reasonable level of geometric accuracy between the point clouds\nof ground truth models and generated models.\n  By significantly improving the feasibility rate of generating CAD models, our\napproach helps expand the availability of high-quality training data and\nenhances the applicability of AI-driven CAD generation in manufacturing,\narchitecture, and product design.", "AI": {"tldr": "GenCAD-Self-Repairing improves the feasibility of generative CAD models by integrating diffusion guidance and a self-repairing pipeline, converting two-thirds of infeasible designs into feasible ones.", "motivation": "The inability of GenCAD to consistently produce feasible boundary representations (B-reps) limits its practical application, prompting the need for a solution to enhance feasibility.", "method": "The proposed framework uses guided diffusion denoising in latent space and a regression-based correction mechanism to refine infeasible CAD command sequences.", "result": "The approach successfully converted two-thirds of infeasible designs into feasible ones, improving feasibility while maintaining geometric accuracy.", "conclusion": "This method enhances the applicability of AI-driven CAD generation in manufacturing, architecture, and product design by improving feasibility and expanding training data availability."}}
{"id": "2505.23267", "pdf": "https://arxiv.org/pdf/2505.23267", "abs": "https://arxiv.org/abs/2505.23267", "authors": ["Jianlin Ye", "Savvas Papaioannou", "Panayiotis Kolios"], "title": "VLM-RRT: Vision Language Model Guided RRT Search for Autonomous UAV Navigation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Path planning is a fundamental capability of autonomous Unmanned Aerial\nVehicles (UAVs), enabling them to efficiently navigate toward a target region\nor explore complex environments while avoiding obstacles. Traditional\npathplanning methods, such as Rapidly-exploring Random Trees (RRT), have proven\neffective but often encounter significant challenges. These include high search\nspace complexity, suboptimal path quality, and slow convergence, issues that\nare particularly problematic in high-stakes applications like disaster\nresponse, where rapid and efficient planning is critical. To address these\nlimitations and enhance path-planning efficiency, we propose Vision Language\nModel RRT (VLM-RRT), a hybrid approach that integrates the pattern recognition\ncapabilities of Vision Language Models (VLMs) with the path-planning strengths\nof RRT. By leveraging VLMs to provide initial directional guidance based on\nenvironmental snapshots, our method biases sampling toward regions more likely\nto contain feasible paths, significantly improving sampling efficiency and path\nquality. Extensive quantitative and qualitative experiments with various\nstate-of-the-art VLMs demonstrate the effectiveness of this proposed approach.", "AI": {"tldr": "The paper proposes VLM-RRT, a hybrid method combining Vision Language Models (VLMs) with RRT to improve UAV path planning by enhancing sampling efficiency and path quality.", "motivation": "Traditional RRT methods face challenges like high search complexity and slow convergence, especially in critical applications like disaster response.", "method": "Integrates VLMs with RRT, using VLMs to provide directional guidance from environmental snapshots, biasing sampling toward feasible paths.", "result": "Experiments show VLM-RRT improves sampling efficiency and path quality compared to traditional RRT.", "conclusion": "VLM-RRT effectively addresses RRT limitations, offering a promising solution for efficient UAV path planning."}}
{"id": "2505.23185", "pdf": "https://arxiv.org/pdf/2505.23185", "abs": "https://arxiv.org/abs/2505.23185", "authors": ["Shahaf E. Finder", "Ron Shapira Weber", "Moshe Eliasof", "Oren Freifeld", "Eran Treister"], "title": "Improving the Effective Receptive Field of Message-Passing Neural Networks", "categories": ["cs.LG"], "comment": "Accepted to ICML 2025", "summary": "Message-Passing Neural Networks (MPNNs) have become a cornerstone for\nprocessing and analyzing graph-structured data. However, their effectiveness is\noften hindered by phenomena such as over-squashing, where long-range\ndependencies or interactions are inadequately captured and expressed in the\nMPNN output. This limitation mirrors the challenges of the Effective Receptive\nField (ERF) in Convolutional Neural Networks (CNNs), where the theoretical\nreceptive field is underutilized in practice. In this work, we show and\ntheoretically explain the limited ERF problem in MPNNs. Furthermore, inspired\nby recent advances in ERF augmentation for CNNs, we propose an Interleaved\nMultiscale Message-Passing Neural Networks (IM-MPNN) architecture to address\nthese problems in MPNNs. Our method incorporates a hierarchical coarsening of\nthe graph, enabling message-passing across multiscale representations and\nfacilitating long-range interactions without excessive depth or\nparameterization. Through extensive evaluations on benchmarks such as the\nLong-Range Graph Benchmark (LRGB), we demonstrate substantial improvements over\nbaseline MPNNs in capturing long-range dependencies while maintaining\ncomputational efficiency.", "AI": {"tldr": "The paper addresses the limited Effective Receptive Field (ERF) in MPNNs, proposing an Interleaved Multiscale MPNN (IM-MPNN) to enhance long-range dependency capture without excessive depth or parameters.", "motivation": "MPNNs struggle with over-squashing, limiting their ability to capture long-range dependencies, akin to ERF issues in CNNs.", "method": "Proposes IM-MPNN, which uses hierarchical graph coarsening for multiscale message-passing to improve long-range interactions.", "result": "Demonstrates significant improvements in capturing long-range dependencies on benchmarks like LRGB, maintaining computational efficiency.", "conclusion": "IM-MPNN effectively addresses ERF limitations in MPNNs, enhancing performance without added complexity."}}
{"id": "2505.23363", "pdf": "https://arxiv.org/pdf/2505.23363", "abs": "https://arxiv.org/abs/2505.23363", "authors": ["Hongzhan Chen", "Tao Yang", "Shiping Gao", "Ruijun Chen", "Xiaojun Quan", "Hongtao Tian", "Ting Yao"], "title": "Discriminative Policy Optimization for Token-Level Reward Models", "categories": ["cs.CL"], "comment": "ICML 2025", "summary": "Process reward models (PRMs) provide more nuanced supervision compared to\noutcome reward models (ORMs) for optimizing policy models, positioning them as\na promising approach to enhancing the capabilities of LLMs in complex reasoning\ntasks. Recent efforts have advanced PRMs from step-level to token-level\ngranularity by integrating reward modeling into the training of generative\nmodels, with reward scores derived from token generation probabilities.\nHowever, the conflict between generative language modeling and reward modeling\nmay introduce instability and lead to inaccurate credit assignments. To address\nthis challenge, we revisit token-level reward assignment by decoupling reward\nmodeling from language generation and derive a token-level reward model through\nthe optimization of a discriminative policy, termed the Q-function Reward Model\n(Q-RM). We theoretically demonstrate that Q-RM explicitly learns token-level\nQ-functions from preference data without relying on fine-grained annotations.\nIn our experiments, Q-RM consistently outperforms all baseline methods across\nvarious benchmarks. For example, when integrated into PPO/REINFORCE algorithms,\nQ-RM enhances the average Pass@1 score by 5.85/4.70 points on mathematical\nreasoning tasks compared to the ORM baseline, and by 4.56/5.73 points compared\nto the token-level PRM counterpart. Moreover, reinforcement learning with Q-RM\nsignificantly enhances training efficiency, achieving convergence 12 times\nfaster than ORM on GSM8K and 11 times faster than step-level PRM on MATH. Code\nand data are available at https://github.com/homzer/Q-RM.", "AI": {"tldr": "Q-RM, a token-level reward model, outperforms baselines in enhancing LLMs for complex reasoning by decoupling reward modeling from language generation.", "motivation": "Address instability and inaccuracies in token-level reward models caused by conflicts between generative language modeling and reward modeling.", "method": "Decouples reward modeling from language generation, deriving a token-level reward model (Q-RM) via discriminative policy optimization.", "result": "Q-RM improves Pass@1 scores by 5.85/4.70 points over ORM and 4.56/5.73 over PRM, with faster convergence (12x ORM, 11x PRM).", "conclusion": "Q-RM is a robust, efficient approach for enhancing LLMs in complex reasoning tasks."}}
{"id": "2505.23292", "pdf": "https://arxiv.org/pdf/2505.23292", "abs": "https://arxiv.org/abs/2505.23292", "authors": ["Evangelos Charalampakis", "Vasileios Mygdalis", "Ioannis Pitas"], "title": "Federated Unsupervised Semantic Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This work explores the application of Federated Learning (FL) in Unsupervised\nSemantic image Segmentation (USS). Recent USS methods extract pixel-level\nfeatures using frozen visual foundation models and refine them through\nself-supervised objectives that encourage semantic grouping. These features are\nthen grouped to semantic clusters to produce segmentation masks. Extending\nthese ideas to federated settings requires feature representation and cluster\ncentroid alignment across distributed clients -- an inherently difficult task\nunder heterogeneous data distributions in the absence of supervision. To\naddress this, we propose FUSS Federated Unsupervised image Semantic\nSegmentation) which is, to our knowledge, the first framework to enable fully\ndecentralized, label-free semantic segmentation training. FUSS introduces novel\nfederation strategies that promote global consistency in feature and prototype\nspace, jointly optimizing local segmentation heads and shared semantic\ncentroids. Experiments on both benchmark and real-world datasets, including\nbinary and multi-class segmentation tasks, show that FUSS consistently\noutperforms local-only client trainings as well as extensions of classical FL\nalgorithms under varying client data distributions. To support reproducibility,\nfull code will be released upon manuscript acceptance.", "AI": {"tldr": "FUSS enables decentralized, unsupervised semantic image segmentation in federated learning by aligning features and centroids across clients, outperforming local and classical FL methods.", "motivation": "To address the challenge of feature and centroid alignment in federated settings for unsupervised semantic segmentation under heterogeneous data.", "method": "Proposes FUSS, a framework with novel federation strategies for global consistency in feature and prototype space, optimizing local segmentation heads and shared centroids.", "result": "FUSS outperforms local-only training and classical FL extensions on benchmark and real-world datasets for binary and multi-class segmentation.", "conclusion": "FUSS is the first fully decentralized, label-free semantic segmentation framework, with reproducible code to be released."}}
{"id": "2505.23270", "pdf": "https://arxiv.org/pdf/2505.23270", "abs": "https://arxiv.org/abs/2505.23270", "authors": ["Haokun Chen", "Yueqi Zhang", "Yuan Bi", "Yao Zhang", "Tong Liu", "Jinhe Bi", "Jian Lan", "Jindong Gu", "Claudia Grosser", "Denis Krompass", "Nassir Navab", "Volker Tresp"], "title": "Does Machine Unlearning Truly Remove Model Knowledge? A Framework for Auditing Unlearning in LLMs", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "In recent years, Large Language Models (LLMs) have achieved remarkable\nadvancements, drawing significant attention from the research community. Their\ncapabilities are largely attributed to large-scale architectures, which require\nextensive training on massive datasets. However, such datasets often contain\nsensitive or copyrighted content sourced from the public internet, raising\nconcerns about data privacy and ownership. Regulatory frameworks, such as the\nGeneral Data Protection Regulation (GDPR), grant individuals the right to\nrequest the removal of such sensitive information. This has motivated the\ndevelopment of machine unlearning algorithms that aim to remove specific\nknowledge from models without the need for costly retraining. Despite these\nadvancements, evaluating the efficacy of unlearning algorithms remains a\nchallenge due to the inherent complexity and generative nature of LLMs. In this\nwork, we introduce a comprehensive auditing framework for unlearning\nevaluation, comprising three benchmark datasets, six unlearning algorithms, and\nfive prompt-based auditing methods. By using various auditing algorithms, we\nevaluate the effectiveness and robustness of different unlearning strategies.\nTo explore alternatives beyond prompt-based auditing, we propose a novel\ntechnique that leverages intermediate activation perturbations, addressing the\nlimitations of auditing methods that rely solely on model inputs and outputs.", "AI": {"tldr": "The paper introduces an auditing framework to evaluate machine unlearning algorithms in LLMs, addressing privacy concerns and regulatory needs.", "motivation": "Privacy concerns and regulatory requirements like GDPR necessitate effective unlearning methods for LLMs, but evaluating their efficacy is challenging.", "method": "The authors propose an auditing framework with benchmark datasets, unlearning algorithms, and prompt-based and novel activation perturbation auditing methods.", "result": "The framework evaluates the effectiveness and robustness of unlearning strategies, offering insights beyond traditional input-output methods.", "conclusion": "The proposed framework advances the evaluation of unlearning algorithms, addressing limitations of existing methods and enhancing privacy compliance."}}
{"id": "2505.23190", "pdf": "https://arxiv.org/pdf/2505.23190", "abs": "https://arxiv.org/abs/2505.23190", "authors": ["Yekun Zhu", "Min Tang", "Zheng Ma"], "title": "DeepRTE: Pre-trained Attention-based Neural Network for Radiative Tranfer", "categories": ["cs.LG"], "comment": null, "summary": "In this study, we propose a novel neural network approach, termed DeepRTE, to\naddress the steady-state Radiative Transfer Equation (RTE). The RTE is a\ndifferential-integral equation that governs the propagation of radiation\nthrough a participating medium, with applications spanning diverse domains such\nas neutron transport, atmospheric radiative transfer, heat transfer, and\noptical imaging. Our proposed DeepRTE framework leverages pre-trained\nattention-based neural networks to solve the RTE with high accuracy and\ncomputational efficiency. The efficacy of the proposed approach is\nsubstantiated through comprehensive numerical experiments.", "AI": {"tldr": "DeepRTE is a neural network approach for solving the Radiative Transfer Equation (RTE) with high accuracy and efficiency.", "motivation": "The RTE is critical in fields like neutron transport, atmospheric radiative transfer, and optical imaging, but solving it is challenging.", "method": "DeepRTE uses pre-trained attention-based neural networks to address the RTE.", "result": "Numerical experiments confirm the framework's accuracy and computational efficiency.", "conclusion": "DeepRTE offers an effective solution for the RTE, with broad applicability."}}
{"id": "2505.23368", "pdf": "https://arxiv.org/pdf/2505.23368", "abs": "https://arxiv.org/abs/2505.23368", "authors": ["Beiduo Chen", "Yang Janet Liu", "Anna Korhonen", "Barbara Plank"], "title": "Threading the Needle: Reweaving Chain-of-Thought Reasoning to Explain Human Label Variation", "categories": ["cs.CL"], "comment": "22 pages, 7 figures", "summary": "The recent rise of reasoning-tuned Large Language Models (LLMs)--which\ngenerate chains of thought (CoTs) before giving the final answer--has attracted\nsignificant attention and offers new opportunities for gaining insights into\nhuman label variation, which refers to plausible differences in how multiple\nannotators label the same data instance. Prior work has shown that\nLLM-generated explanations can help align model predictions with human label\ndistributions, but typically adopt a reverse paradigm: producing explanations\nbased on given answers. In contrast, CoTs provide a forward reasoning path that\nmay implicitly embed rationales for each answer option, before generating the\nanswers. We thus propose a novel LLM-based pipeline enriched with\nlinguistically-grounded discourse segmenters to extract supporting and opposing\nstatements for each answer option from CoTs with improved accuracy. We also\npropose a rank-based HLV evaluation framework that prioritizes the ranking of\nanswers over exact scores, which instead favor direct comparison of label\ndistributions. Our method outperforms a direct generation method as well as\nbaselines on three datasets, and shows better alignment of ranking methods with\nhumans, highlighting the effectiveness of our approach.", "AI": {"tldr": "The paper introduces a novel LLM-based pipeline using linguistically-grounded discourse segmenters to extract supporting/opposing statements from CoTs, improving accuracy in human label variation tasks.", "motivation": "To address human label variation by leveraging reasoning-tuned LLMs and their forward reasoning paths (CoTs) for better alignment with human annotations.", "method": "Proposes a pipeline with discourse segmenters to extract rationales from CoTs and a rank-based HLV evaluation framework prioritizing answer rankings over exact scores.", "result": "Outperforms direct generation methods and baselines on three datasets, showing better alignment with human rankings.", "conclusion": "The approach effectively leverages CoTs and discourse analysis to improve human label variation tasks, demonstrating superior performance and alignment."}}
{"id": "2505.23312", "pdf": "https://arxiv.org/pdf/2505.23312", "abs": "https://arxiv.org/abs/2505.23312", "authors": ["Finn Carter"], "title": "TRACE: Trajectory-Constrained Concept Erasure in Diffusion Models", "categories": ["cs.CV"], "comment": "In peer review", "summary": "Text-to-image diffusion models have shown unprecedented generative\ncapability, but their ability to produce undesirable concepts\n(e.g.~pornographic content, sensitive identities, copyrighted styles) poses\nserious concerns for privacy, fairness, and safety. {Concept erasure} aims to\nremove or suppress specific concept information in a generative model. In this\npaper, we introduce \\textbf{TRACE (Trajectory-Constrained Attentional Concept\nErasure)}, a novel method to erase targeted concepts from diffusion models\nwhile preserving overall generative quality. Our approach combines a rigorous\ntheoretical framework, establishing formal conditions under which a concept can\nbe provably suppressed in the diffusion process, with an effective fine-tuning\nprocedure compatible with both conventional latent diffusion (Stable Diffusion)\nand emerging rectified flow models (e.g.~FLUX). We first derive a closed-form\nupdate to the model's cross-attention layers that removes hidden\nrepresentations of the target concept. We then introduce a trajectory-aware\nfinetuning objective that steers the denoising process away from the concept\nonly in the late sampling stages, thus maintaining the model's fidelity on\nunrelated content. Empirically, we evaluate TRACE on multiple benchmarks used\nin prior concept erasure studies (object classes, celebrity faces, artistic\nstyles, and explicit content from the I2P dataset). TRACE achieves\nstate-of-the-art performance, outperforming recent methods such as ANT,\nEraseAnything, and MACE in terms of removal efficacy and output quality.", "AI": {"tldr": "TRACE is a method to erase unwanted concepts from diffusion models while maintaining generative quality, outperforming existing techniques.", "motivation": "Address concerns about undesirable outputs (e.g., explicit content, sensitive identities) in text-to-image diffusion models.", "method": "Combines theoretical framework for concept suppression with fine-tuning, focusing on cross-attention layers and trajectory-aware denoising.", "result": "TRACE outperforms methods like ANT, EraseAnything, and MACE in removal efficacy and output quality.", "conclusion": "TRACE effectively erases targeted concepts without compromising overall model performance."}}
{"id": "2505.23309", "pdf": "https://arxiv.org/pdf/2505.23309", "abs": "https://arxiv.org/abs/2505.23309", "authors": ["Yixin Ren", "Chenghou Jin", "Yewei Xia", "Li Ke", "Longtao Huang", "Hui Xue", "Hao Zhang", "Jihong Guan", "Shuigeng Zhou"], "title": "Score-based Generative Modeling for Conditional Independence Testing", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by KDD2025", "summary": "Determining conditional independence (CI) relationships between random\nvariables is a fundamental yet challenging task in machine learning and\nstatistics, especially in high-dimensional settings. Existing generative\nmodel-based CI testing methods, such as those utilizing generative adversarial\nnetworks (GANs), often struggle with undesirable modeling of conditional\ndistributions and training instability, resulting in subpar performance. To\naddress these issues, we propose a novel CI testing method via score-based\ngenerative modeling, which achieves precise Type I error control and strong\ntesting power. Concretely, we first employ a sliced conditional score matching\nscheme to accurately estimate conditional score and use Langevin dynamics\nconditional sampling to generate null hypothesis samples, ensuring precise Type\nI error control. Then, we incorporate a goodness-of-fit stage into the method\nto verify generated samples and enhance interpretability in practice. We\ntheoretically establish the error bound of conditional distributions modeled by\nscore-based generative models and prove the validity of our CI tests. Extensive\nexperiments on both synthetic and real-world datasets show that our method\nsignificantly outperforms existing state-of-the-art methods, providing a\npromising way to revitalize generative model-based CI testing.", "AI": {"tldr": "A novel CI testing method using score-based generative modeling improves Type I error control and testing power, outperforming existing methods.", "motivation": "Challenges in CI testing with generative models, like GANs, due to poor conditional distribution modeling and instability, motivate a more robust approach.", "method": "Uses sliced conditional score matching and Langevin dynamics for sampling, with a goodness-of-fit stage for validation.", "result": "Theoretical error bounds are established, and experiments show superior performance over state-of-the-art methods.", "conclusion": "The proposed method revitalizes generative model-based CI testing with precision and practicality."}}
{"id": "2505.23194", "pdf": "https://arxiv.org/pdf/2505.23194", "abs": "https://arxiv.org/abs/2505.23194", "authors": ["Shiwei Li", "Xiandi Luo", "Xing Tang", "Haozhao Wang", "Hao Chen", "Weihong Luo", "Yuhua Li", "Xiuqiang He", "Ruixuan Li"], "title": "Beyond Zero Initialization: Investigating the Impact of Non-Zero Initialization on LoRA Fine-Tuning Dynamics", "categories": ["cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Low-rank adaptation (LoRA) is a widely used parameter-efficient fine-tuning\nmethod. In standard LoRA layers, one of the matrices, $A$ or $B$, is\ninitialized to zero, ensuring that fine-tuning starts from the pretrained\nmodel. However, there is no theoretical support for this practice. In this\npaper, we investigate the impact of non-zero initialization on LoRA's\nfine-tuning dynamics from an infinite-width perspective. Our analysis reveals\nthat, compared to zero initialization, simultaneously initializing $A$ and $B$\nto non-zero values improves LoRA's robustness to suboptimal learning rates,\nparticularly smaller ones. Further analysis indicates that although the\nnon-zero initialization of $AB$ introduces random noise into the pretrained\nweight, it generally does not affect fine-tuning performance. In other words,\nfine-tuning does not need to strictly start from the pretrained model. The\nvalidity of our findings is confirmed through extensive experiments across\nvarious models and datasets. The code is available at\nhttps://github.com/Leopold1423/non_zero_lora-icml25.", "AI": {"tldr": "Non-zero initialization of LoRA matrices A and B improves robustness to suboptimal learning rates without harming fine-tuning performance.", "motivation": "The lack of theoretical support for zero initialization in LoRA layers prompted an investigation into the impact of non-zero initialization.", "method": "Analyzed LoRA's fine-tuning dynamics from an infinite-width perspective, comparing zero and non-zero initialization of matrices A and B.", "result": "Non-zero initialization enhances robustness to suboptimal learning rates, especially smaller ones, without degrading performance.", "conclusion": "Fine-tuning doesn't strictly require starting from the pretrained model; non-zero initialization is a viable alternative."}}
{"id": "2505.23404", "pdf": "https://arxiv.org/pdf/2505.23404", "abs": "https://arxiv.org/abs/2505.23404", "authors": ["Mingyu Yu", "Wei Wang", "Yanjie Wei", "Sujuan Qin"], "title": "Adaptive Jailbreaking Strategies Based on the Semantic Understanding Capabilities of Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Adversarial attacks on Large Language Models (LLMs) via jailbreaking\ntechniques-methods that circumvent their built-in safety and ethical\nconstraints-have emerged as a critical challenge in AI security. These attacks\ncompromise the reliability of LLMs by exploiting inherent weaknesses in their\ncomprehension capabilities. This paper investigates the efficacy of\njailbreaking strategies that are specifically adapted to the diverse levels of\nunderstanding exhibited by different LLMs. We propose the Adaptive Jailbreaking\nStrategies Based on the Semantic Understanding Capabilities of Large Language\nModels, a novel framework that classifies LLMs into Type I and Type II\ncategories according to their semantic comprehension abilities. For each\ncategory, we design tailored jailbreaking strategies aimed at leveraging their\nvulnerabilities to facilitate successful attacks. Extensive experiments\nconducted on multiple LLMs demonstrate that our adaptive strategy markedly\nimproves the success rate of jailbreaking. Notably, our approach achieves an\nexceptional 98.9% success rate in jailbreaking GPT-4o(29 May 2025 release)", "AI": {"tldr": "The paper introduces adaptive jailbreaking strategies for LLMs, categorizing them by semantic understanding and achieving a 98.9% success rate on GPT-4o.", "motivation": "Addressing the challenge of adversarial attacks on LLMs that bypass safety constraints, compromising their reliability.", "method": "Classifies LLMs into Type I and Type II based on semantic comprehension, then designs tailored jailbreaking strategies for each.", "result": "The adaptive strategy significantly improves jailbreaking success rates, notably achieving 98.9% on GPT-4o.", "conclusion": "The proposed framework effectively exploits LLM vulnerabilities, highlighting the need for improved defenses."}}
{"id": "2505.23313", "pdf": "https://arxiv.org/pdf/2505.23313", "abs": "https://arxiv.org/abs/2505.23313", "authors": ["Weizhe Kong", "Xiao Wang", "Ruichong Gao", "Chenglong Li", "Yu Zhang", "Xing Yang", "Yaowei Wang", "Jin Tang"], "title": "Adversarial Semantic and Label Perturbation Attack for Pedestrian Attribute Recognition", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Pedestrian Attribute Recognition (PAR) is an indispensable task in\nhuman-centered research and has made great progress in recent years with the\ndevelopment of deep neural networks. However, the potential vulnerability and\nanti-interference ability have still not been fully explored. To bridge this\ngap, this paper proposes the first adversarial attack and defense framework for\npedestrian attribute recognition. Specifically, we exploit both global- and\npatch-level attacks on the pedestrian images, based on the pre-trained\nCLIP-based PAR framework. It first divides the input pedestrian image into\nnon-overlapping patches and embeds them into feature embeddings using a\nprojection layer. Meanwhile, the attribute set is expanded into sentences using\nprompts and embedded into attribute features using a pre-trained CLIP text\nencoder. A multi-modal Transformer is adopted to fuse the obtained vision and\ntext tokens, and a feed-forward network is utilized for attribute recognition.\nBased on the aforementioned PAR framework, we adopt the adversarial semantic\nand label-perturbation to generate the adversarial noise, termed ASL-PAR. We\nalso design a semantic offset defense strategy to suppress the influence of\nadversarial attacks. Extensive experiments conducted on both digital domains\n(i.e., PETA, PA100K, MSP60K, RAPv2) and physical domains fully validated the\neffectiveness of our proposed adversarial attack and defense strategies for the\npedestrian attribute recognition. The source code of this paper will be\nreleased on https://github.com/Event-AHU/OpenPAR.", "AI": {"tldr": "The paper proposes an adversarial attack and defense framework for Pedestrian Attribute Recognition (PAR), addressing its vulnerability and anti-interference issues.", "motivation": "To explore and mitigate the vulnerability of PAR systems to adversarial attacks, which has not been fully studied.", "method": "Uses global- and patch-level attacks on a CLIP-based PAR framework, with adversarial noise generation (ASL-PAR) and a semantic offset defense strategy.", "result": "Validated on digital and physical domains, showing effectiveness of the proposed attack and defense strategies.", "conclusion": "The framework successfully addresses PAR vulnerabilities, with code to be released for further research."}}
{"id": "2505.23331", "pdf": "https://arxiv.org/pdf/2505.23331", "abs": "https://arxiv.org/abs/2505.23331", "authors": ["Matteo Gallici", "Haitz S\u00e1ez de Oc\u00e1riz Borde"], "title": "Fine-Tuning Next-Scale Visual Autoregressive Models with Group Relative Policy Optimization", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Fine-tuning pre-trained generative models with Reinforcement Learning (RL)\nhas emerged as an effective approach for aligning outputs more closely with\nnuanced human preferences. In this paper, we investigate the application of\nGroup Relative Policy Optimization (GRPO) to fine-tune next-scale visual\nautoregressive (VAR) models. Our empirical results demonstrate that this\napproach enables alignment to intricate reward signals derived from aesthetic\npredictors and CLIP embeddings, significantly enhancing image quality and\nenabling precise control over the generation style. Interestingly, by\nleveraging CLIP, our method can help VAR models generalize beyond their initial\nImageNet distribution: through RL-driven exploration, these models can generate\nimages aligned with prompts referencing image styles that were absent during\npre-training. In summary, we show that RL-based fine-tuning is both efficient\nand effective for VAR models, benefiting particularly from their fast inference\nspeeds, which are advantageous for online sampling, an aspect that poses\nsignificant challenges for diffusion-based alternatives.", "AI": {"tldr": "RL-based fine-tuning with GRPO improves next-scale VAR models, aligning them with human preferences and enabling style control and generalization beyond pre-training data.", "motivation": "To align generative models with nuanced human preferences and enhance image quality and style control.", "method": "Apply Group Relative Policy Optimization (GRPO) to fine-tune visual autoregressive (VAR) models using RL, leveraging aesthetic predictors and CLIP embeddings.", "result": "Improved image quality, precise style control, and generalization beyond the initial ImageNet distribution.", "conclusion": "RL-based fine-tuning is efficient and effective for VAR models, benefiting from their fast inference speeds."}}
{"id": "2505.23223", "pdf": "https://arxiv.org/pdf/2505.23223", "abs": "https://arxiv.org/abs/2505.23223", "authors": ["Xingyuan Pan", "Chenlu Ye", "Joseph Melkonian", "Jiaqi W. Ma", "Tong Zhang"], "title": "Daunce: Data Attribution through Uncertainty Estimation", "categories": ["cs.LG"], "comment": null, "summary": "Training data attribution (TDA) methods aim to identify which training\nexamples influence a model's predictions on specific test data most. By\nquantifying these influences, TDA supports critical applications such as data\ndebugging, curation, and valuation. Gradient-based TDA methods rely on\ngradients and second-order information, limiting their applicability at scale.\nWhile recent random projection-based methods improve scalability, they often\nsuffer from degraded attribution accuracy. Motivated by connections between\nuncertainty and influence functions, we introduce Daunce - a simple yet\neffective data attribution approach through uncertainty estimation. Our method\noperates by fine-tuning a collection of perturbed models and computing the\ncovariance of per-example losses across these models as the attribution score.\nDaunce is scalable to large language models (LLMs) and achieves more accurate\nattribution compared to existing TDA methods. We validate Daunce on tasks\nranging from vision tasks to LLM fine-tuning, and further demonstrate its\ncompatibility with black-box model access. Applied to OpenAI's GPT models, our\nmethod achieves, to our knowledge, the first instance of data attribution on\nproprietary LLMs.", "AI": {"tldr": "Daunce is a scalable and accurate data attribution method for models, including LLMs, using uncertainty estimation via perturbed models.", "motivation": "Existing gradient-based TDA methods are limited in scalability, while random projection-based methods sacrifice accuracy. Daunce addresses these gaps by leveraging uncertainty estimation.", "method": "Fine-tunes perturbed models and computes covariance of per-example losses as attribution scores.", "result": "Daunce scales to LLMs, outperforms existing TDA methods in accuracy, and works with black-box models like GPT.", "conclusion": "Daunce enables effective data attribution for large models, including proprietary LLMs, advancing applications like data debugging and valuation."}}
{"id": "2505.23410", "pdf": "https://arxiv.org/pdf/2505.23410", "abs": "https://arxiv.org/abs/2505.23410", "authors": ["Xuan Gong", "Hanbo Huang", "Shiyu Liang"], "title": "From Parameters to Prompts: Understanding and Mitigating the Factuality Gap between Fine-Tuned LLMs", "categories": ["cs.CL"], "comment": "The code of this paper will be released soon", "summary": "Factual knowledge extraction aims to explicitly extract knowledge\nparameterized in pre-trained language models for application in downstream\ntasks. While prior work has been investigating the impact of supervised\nfine-tuning data on the factuality of large language models (LLMs), its\nmechanism remains poorly understood. We revisit this impact through systematic\nexperiments, with a particular focus on the factuality gap that arises when\nfine-tuning on known versus unknown knowledge. Our findings show that this gap\ncan be mitigated at the inference stage, either under out-of-distribution (OOD)\nsettings or by using appropriate in-context learning (ICL) prompts (i.e.,\nfew-shot learning and Chain of Thought (CoT)). We prove this phenomenon\ntheoretically from the perspective of knowledge graphs, showing that the\ntest-time prompt may diminish or even overshadow the impact of fine-tuning data\nand play a dominant role in knowledge extraction. Ultimately, our results shed\nlight on the interaction between finetuning data and test-time prompt,\ndemonstrating that ICL can effectively compensate for shortcomings in\nfine-tuning data, and highlighting the need to reconsider the use of ICL\nprompting as a means to evaluate the effectiveness of fine-tuning data\nselection methods.", "AI": {"tldr": "The paper explores how test-time prompts can mitigate the factuality gap in LLMs caused by fine-tuning on known vs. unknown knowledge, showing ICL's compensatory role.", "motivation": "To understand the impact of fine-tuning data on LLM factuality and the role of test-time prompts in knowledge extraction.", "method": "Systematic experiments and theoretical analysis from a knowledge graph perspective, focusing on OOD settings and ICL prompts.", "result": "Test-time prompts can overshadow fine-tuning data's impact, with ICL effectively compensating for data shortcomings.", "conclusion": "ICL should be reconsidered for evaluating fine-tuning data selection, as it plays a dominant role in knowledge extraction."}}
{"id": "2505.23325", "pdf": "https://arxiv.org/pdf/2505.23325", "abs": "https://arxiv.org/abs/2505.23325", "authors": ["Hengyuan Cao", "Yutong Feng", "Biao Gong", "Yijing Tian", "Yunhong Lu", "Chuang Liu", "Bin Wang"], "title": "Dimension-Reduction Attack! Video Generative Models are Experts on Controllable Image Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "Video generative models can be regarded as world simulators due to their\nability to capture dynamic, continuous changes inherent in real-world\nenvironments. These models integrate high-dimensional information across\nvisual, temporal, spatial, and causal dimensions, enabling predictions of\nsubjects in various status. A natural and valuable research direction is to\nexplore whether a fully trained video generative model in high-dimensional\nspace can effectively support lower-dimensional tasks such as controllable\nimage generation. In this work, we propose a paradigm for video-to-image\nknowledge compression and task adaptation, termed \\textit{Dimension-Reduction\nAttack} (\\texttt{DRA-Ctrl}), which utilizes the strengths of video models,\nincluding long-range context modeling and flatten full-attention, to perform\nvarious generation tasks. Specially, to address the challenging gap between\ncontinuous video frames and discrete image generation, we introduce a\nmixup-based transition strategy that ensures smooth adaptation. Moreover, we\nredesign the attention structure with a tailored masking mechanism to better\nalign text prompts with image-level control. Experiments across diverse image\ngeneration tasks, such as subject-driven and spatially conditioned generation,\nshow that repurposed video models outperform those trained directly on images.\nThese results highlight the untapped potential of large-scale video generators\nfor broader visual applications. \\texttt{DRA-Ctrl} provides new insights into\nreusing resource-intensive video models and lays foundation for future unified\ngenerative models across visual modalities. The project page is\nhttps://dra-ctrl-2025.github.io/DRA-Ctrl/.", "AI": {"tldr": "The paper introduces DRA-Ctrl, a method to repurpose video generative models for controllable image generation, leveraging their high-dimensional capabilities for lower-dimensional tasks.", "motivation": "To explore if fully trained video generative models can support lower-dimensional tasks like controllable image generation, bridging the gap between video and image generation.", "method": "Proposes DRA-Ctrl, using video models' strengths (e.g., long-range context modeling) with a mixup-based transition strategy and redesigned attention structure for smooth adaptation.", "result": "Repurposed video models outperform direct image-trained models in tasks like subject-driven and spatially conditioned generation.", "conclusion": "DRA-Ctrl demonstrates the potential of video models for broader visual tasks and lays groundwork for unified generative models across modalities."}}
{"id": "2505.23337", "pdf": "https://arxiv.org/pdf/2505.23337", "abs": "https://arxiv.org/abs/2505.23337", "authors": ["Chetan Verma", "Aditya Srinivas Timmaraju", "Cho Jui-Hsieh", "Suyash Damle", "Ngot Bui", "Yang Zhang", "Wen Chen", "Xin Liu", "Prateek Jain", "Inderjit S Dhillon"], "title": "Matryoshka Model Learning for Improved Elastic Student Models", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 5 figures, Accepted at KDD 2025", "summary": "Industry-grade ML models are carefully designed to meet rapidly evolving\nserving constraints, which requires significant resources for model\ndevelopment. In this paper, we propose MatTA, a framework for training multiple\naccurate Student models using a novel Teacher-TA-Student recipe. TA models are\nlarger versions of the Student models with higher capacity, and thus allow\nStudent models to better relate to the Teacher model and also bring in more\ndomain-specific expertise. Furthermore, multiple accurate Student models can be\nextracted from the TA model. Therefore, despite only one training run, our\nmethodology provides multiple servable options to trade off accuracy for lower\nserving cost. We demonstrate the proposed method, MatTA, on proprietary\ndatasets and models. Its practical efficacy is underscored by live A/B tests\nwithin a production ML system, demonstrating 20% improvement on a key metric.\nWe also demonstrate our method on GPT-2 Medium, a public model, and achieve\nrelative improvements of over 24% on SAT Math and over 10% on the LAMBADA\nbenchmark.", "AI": {"tldr": "MatTA is a framework for training multiple accurate Student models using a Teacher-TA-Student recipe, enabling trade-offs between accuracy and serving costs with just one training run.", "motivation": "Industry-grade ML models require significant resources for development to meet evolving serving constraints. MatTA aims to streamline this by producing multiple servable models efficiently.", "method": "Uses a Teacher-TA-Student recipe where TA models (larger versions of Students) bridge the gap between Teacher and Student models, enabling better knowledge transfer and domain-specific expertise.", "result": "Demonstrated 20% improvement in a production ML system and 24% on SAT Math, 10% on LAMBADA with GPT-2 Medium.", "conclusion": "MatTA efficiently produces multiple accurate Student models, reducing development effort while maintaining performance."}}
{"id": "2505.23225", "pdf": "https://arxiv.org/pdf/2505.23225", "abs": "https://arxiv.org/abs/2505.23225", "authors": ["Fabiano Veglianti", "Flavio Giorgi", "Fabrizio Silvestri", "Gabriele Tolomei"], "title": "Generalizability vs. Counterfactual Explainability Trade-Off", "categories": ["cs.LG"], "comment": "9 pages, 4 figures, plus appendix. arXiv admin note: text overlap\n  with arXiv:2502.09193", "summary": "In this work, we investigate the relationship between model generalization\nand counterfactual explainability in supervised learning. We introduce the\nnotion of $\\varepsilon$-valid counterfactual probability ($\\varepsilon$-VCP) --\nthe probability of finding perturbations of a data point within its\n$\\varepsilon$-neighborhood that result in a label change. We provide a\ntheoretical analysis of $\\varepsilon$-VCP in relation to the geometry of the\nmodel's decision boundary, showing that $\\varepsilon$-VCP tends to increase\nwith model overfitting. Our findings establish a rigorous connection between\npoor generalization and the ease of counterfactual generation, revealing an\ninherent trade-off between generalization and counterfactual explainability.\nEmpirical results validate our theory, suggesting $\\varepsilon$-VCP as a\npractical proxy for quantitatively characterizing overfitting.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.23420", "pdf": "https://arxiv.org/pdf/2505.23420", "abs": "https://arxiv.org/abs/2505.23420", "authors": ["Marco Gaido", "Sara Papi", "Luisa Bentivogli", "Alessio Brutti", "Mauro Cettolo", "Roberto Gretter", "Marco Matassoni", "Mohamed Nabih", "Matteo Negri"], "title": "The Warmup Dilemma: How Learning Rate Strategies Impact Speech-to-Text Model Convergence", "categories": ["cs.CL"], "comment": "Accepted to IWSLT 2025", "summary": "Training large-scale models presents challenges not only in terms of resource\nrequirements but also in terms of their convergence. For this reason, the\nlearning rate (LR) is often decreased when the size of a model is increased.\nSuch a simple solution is not enough in the case of speech-to-text (S2T)\ntrainings, where evolved and more complex variants of the Transformer\narchitecture -- e.g., Conformer or Branchformer -- are used in light of their\nbetter performance. As a workaround, OWSM designed a double linear warmup of\nthe LR, increasing it to a very small value in the first phase before updating\nit to a higher value in the second phase. While this solution worked well in\npractice, it was not compared with alternative solutions, nor was the impact on\nthe final performance of different LR warmup schedules studied. This paper\nfills this gap, revealing that i) large-scale S2T trainings demand a\nsub-exponential LR warmup, and ii) a higher LR in the warmup phase accelerates\ninitial convergence, but it does not boost final performance.", "AI": {"tldr": "The paper explores the need for sub-exponential learning rate (LR) warmup in large-scale speech-to-text (S2T) trainings, finding that higher LRs in warmup speed initial convergence but don't improve final performance.", "motivation": "The study addresses the lack of comparison and analysis of LR warmup schedules in large-scale S2T models, which use complex architectures like Conformer or Branchformer.", "method": "The paper evaluates different LR warmup schedules, focusing on sub-exponential warmup, and compares their impact on convergence and final performance.", "result": "Findings show that sub-exponential LR warmup is optimal for large-scale S2T trainings, and higher LRs during warmup accelerate initial convergence without enhancing final results.", "conclusion": "The study concludes that sub-exponential LR warmup is essential for large-scale S2T models, and initial high LRs are beneficial for convergence but not final performance."}}
{"id": "2505.23341", "pdf": "https://arxiv.org/pdf/2505.23341", "abs": "https://arxiv.org/abs/2505.23341", "authors": ["Daoxi Cao", "Hangbei Cheng", "Yijin Li", "Ruolin Zhou", "Xinyi Li", "Xuehan Zhang", "Binwei Li", "Xuancheng Gu", "Xueyu Liu", "Yongfei Wu"], "title": "DSAGL: Dual-Stream Attention-Guided Learning for Weakly Supervised Whole Slide Image Classification", "categories": ["cs.CV"], "comment": null, "summary": "Whole-slide images (WSIs) are critical for cancer diagnosis due to their\nultra-high resolution and rich semantic content. However, their massive size\nand the limited availability of fine-grained annotations pose substantial\nchallenges for conventional supervised learning. We propose DSAGL (Dual-Stream\nAttention-Guided Learning), a novel weakly supervised classification framework\nthat combines a teacher-student architecture with a dual-stream design. DSAGL\nexplicitly addresses instance-level ambiguity and bag-level semantic\nconsistency by generating multi-scale attention-based pseudo labels and guiding\ninstance-level learning. A shared lightweight encoder (VSSMamba) enables\nefficient long-range dependency modeling, while a fusion-attentive module\n(FASA) enhances focus on sparse but diagnostically relevant regions. We further\nintroduce a hybrid loss to enforce mutual consistency between the two streams.\nExperiments on CIFAR-10, NCT-CRC, and TCGA-Lung datasets demonstrate that DSAGL\nconsistently outperforms state-of-the-art MIL baselines, achieving superior\ndiscriminative performance and robustness under weak supervision.", "AI": {"tldr": "DSAGL is a weakly supervised framework for classifying whole-slide images, combining teacher-student architecture and dual-stream design to address annotation scarcity and instance ambiguity.", "motivation": "Whole-slide images (WSIs) are vital for cancer diagnosis but face challenges due to their size and lack of fine-grained annotations, necessitating weakly supervised methods.", "method": "DSAGL uses a dual-stream design with attention-guided pseudo labels, a lightweight encoder (VSSMamba), and a fusion-attentive module (FASA) for efficient learning and focus on key regions.", "result": "DSAGL outperforms state-of-the-art MIL baselines on CIFAR-10, NCT-CRC, and TCGA-Lung datasets, showing superior performance and robustness.", "conclusion": "DSAGL effectively addresses weakly supervised WSI classification, demonstrating strong performance and potential for clinical applications."}}
{"id": "2505.23349", "pdf": "https://arxiv.org/pdf/2505.23349", "abs": "https://arxiv.org/abs/2505.23349", "authors": ["Sheng Ouyang", "Yulan Hu", "Ge Chen", "Qingyang Li", "Fuzheng Zhang", "Yong Liu"], "title": "Towards Reward Fairness in RLHF: From a Resource Allocation Perspective", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ACL 2025", "summary": "Rewards serve as proxies for human preferences and play a crucial role in\nReinforcement Learning from Human Feedback (RLHF). However, if these rewards\nare inherently imperfect, exhibiting various biases, they can adversely affect\nthe alignment of large language models (LLMs). In this paper, we collectively\ndefine the various biases present in rewards as the problem of reward\nunfairness. We propose a bias-agnostic method to address the issue of reward\nfairness from a resource allocation perspective, without specifically designing\nfor each type of bias, yet effectively mitigating them. Specifically, we model\npreference learning as a resource allocation problem, treating rewards as\nresources to be allocated while considering the trade-off between utility and\nfairness in their distribution. We propose two methods, Fairness Regularization\nand Fairness Coefficient, to achieve fairness in rewards. We apply our methods\nin both verification and reinforcement learning scenarios to obtain a fairness\nreward model and a policy model, respectively. Experiments conducted in these\nscenarios demonstrate that our approach aligns LLMs with human preferences in a\nmore fair manner.", "AI": {"tldr": "The paper addresses reward unfairness in RLHF, proposing bias-agnostic methods (Fairness Regularization and Fairness Coefficient) to improve fairness in reward allocation, leading to better alignment of LLMs with human preferences.", "motivation": "Rewards in RLHF can be biased, harming LLM alignment. The paper aims to mitigate these biases collectively as 'reward unfairness' without targeting specific biases individually.", "method": "Models preference learning as a resource allocation problem, introducing Fairness Regularization and Fairness Coefficient to balance utility and fairness in reward distribution.", "result": "Experiments show the methods improve fairness in reward models and policy models, aligning LLMs more fairly with human preferences.", "conclusion": "The proposed bias-agnostic approach effectively addresses reward unfairness, enhancing the fairness of LLM alignment with human preferences."}}
{"id": "2505.23228", "pdf": "https://arxiv.org/pdf/2505.23228", "abs": "https://arxiv.org/abs/2505.23228", "authors": ["Wanfu Gao", "Jun Gao", "Qingqi Han", "Hanlin Pan", "Kunpeng Liu"], "title": "Graph Random Walk with Feature-Label Space Alignment: A Multi-Label Feature Selection Method", "categories": ["cs.LG"], "comment": null, "summary": "The rapid growth in feature dimension may introduce implicit associations\nbetween features and labels in multi-label datasets, making the relationships\nbetween features and labels increasingly complex. Moreover, existing methods\noften adopt low-dimensional linear decomposition to explore the associations\nbetween features and labels. However, linear decomposition struggles to capture\ncomplex nonlinear associations and may lead to misalignment between the feature\nspace and the label space. To address these two critical challenges, we propose\ninnovative solutions. First, we design a random walk graph that integrates\nfeature-feature, label-label, and feature-label relationships to accurately\ncapture nonlinear and implicit indirect associations, while optimizing the\nlatent representations of associations between features and labels after\nlow-rank decomposition. Second, we align the variable spaces by leveraging\nlow-dimensional representation coefficients, while preserving the manifold\nstructure between the original high-dimensional multi-label data and the\nlow-dimensional representation space. Extensive experiments and ablation\nstudies conducted on seven benchmark datasets and three representative datasets\nusing various evaluation metrics demonstrate the superiority of the proposed\nmethod\\footnote{Code: https://github.com/Heilong623/-GRW-}.", "AI": {"tldr": "The paper addresses challenges in multi-label datasets by proposing a method using random walk graphs and low-rank decomposition to capture nonlinear associations and align feature-label spaces.", "motivation": "The rapid growth in feature dimension complicates feature-label relationships, and existing linear decomposition methods fail to capture nonlinear associations, leading to misalignment.", "method": "The authors design a random walk graph integrating feature-feature, label-label, and feature-label relationships, optimize latent representations via low-rank decomposition, and align spaces while preserving manifold structure.", "result": "Extensive experiments on benchmark datasets show the proposed method's superiority.", "conclusion": "The innovative approach effectively captures nonlinear associations and aligns spaces, outperforming existing methods."}}
{"id": "2505.23461", "pdf": "https://arxiv.org/pdf/2505.23461", "abs": "https://arxiv.org/abs/2505.23461", "authors": ["Chuanyuan Tan", "Wenbiao Shao", "Hao Xiong", "Tong Zhu", "Zhenhua Liu", "Kai Shi", "Wenliang Chen"], "title": "UAQFact: Evaluating Factual Knowledge Utilization of LLMs on Unanswerable Questions", "categories": ["cs.CL"], "comment": "ACL 2025 Findings", "summary": "Handling unanswerable questions (UAQ) is crucial for LLMs, as it helps\nprevent misleading responses in complex situations. While previous studies have\nbuilt several datasets to assess LLMs' performance on UAQ, these datasets lack\nfactual knowledge support, which limits the evaluation of LLMs' ability to\nutilize their factual knowledge when handling UAQ. To address the limitation,\nwe introduce a new unanswerable question dataset UAQFact, a bilingual dataset\nwith auxiliary factual knowledge created from a Knowledge Graph. Based on\nUAQFact, we further define two new tasks to measure LLMs' ability to utilize\ninternal and external factual knowledge, respectively. Our experimental results\nacross multiple LLM series show that UAQFact presents significant challenges,\nas LLMs do not consistently perform well even when they have factual knowledge\nstored. Additionally, we find that incorporating external knowledge may enhance\nperformance, but LLMs still cannot make full use of the knowledge which may\nresult in incorrect responses.", "AI": {"tldr": "The paper introduces UAQFact, a bilingual dataset with factual knowledge for evaluating LLMs on unanswerable questions, revealing challenges in their performance despite knowledge availability.", "motivation": "Existing datasets for unanswerable questions lack factual knowledge support, limiting evaluation of LLMs' ability to use such knowledge.", "method": "Created UAQFact, a bilingual dataset with auxiliary factual knowledge from a Knowledge Graph, and defined two tasks to measure LLMs' use of internal and external knowledge.", "result": "LLMs struggle with UAQFact, performing inconsistently even with stored knowledge, and external knowledge only partially improves performance.", "conclusion": "UAQFact highlights LLMs' limitations in utilizing factual knowledge for unanswerable questions, suggesting room for improvement in knowledge integration."}}
{"id": "2505.23343", "pdf": "https://arxiv.org/pdf/2505.23343", "abs": "https://arxiv.org/abs/2505.23343", "authors": ["Sixian Wang", "Zhiwei Tang", "Tsung-Hui Chang"], "title": "Diffusion Sampling Path Tells More: An Efficient Plug-and-Play Strategy for Sample Filtering", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion models often exhibit inconsistent sample quality due to stochastic\nvariations inherent in their sampling trajectories. Although training-based\nfine-tuning (e.g. DDPO [1]) and inference-time alignment techniques[2] aim to\nimprove sample fidelity, they typically necessitate full denoising processes\nand external reward signals. This incurs substantial computational costs,\nhindering their broader applicability. In this work, we unveil an intriguing\nphenomenon: a previously unobserved yet exploitable link between sample quality\nand characteristics of the denoising trajectory during classifier-free guidance\n(CFG). Specifically, we identify a strong correlation between high-density\nregions of the sample distribution and the Accumulated Score Differences\n(ASD)--the cumulative divergence between conditional and unconditional scores.\nLeveraging this insight, we introduce CFG-Rejection, an efficient,\nplug-and-play strategy that filters low-quality samples at an early stage of\nthe denoising process, crucially without requiring external reward signals or\nmodel retraining. Importantly, our approach necessitates no modifications to\nmodel architectures or sampling schedules and maintains full compatibility with\nexisting diffusion frameworks. We validate the effectiveness of CFG-Rejection\nin image generation through extensive experiments, demonstrating marked\nimprovements on human preference scores (HPSv2, PickScore) and challenging\nbenchmarks (GenEval, DPG-Bench). We anticipate that CFG-Rejection will offer\nsignificant advantages for diverse generative modalities beyond images, paving\nthe way for more efficient and reliable high-quality sample generation.", "AI": {"tldr": "CFG-Rejection improves diffusion model sample quality by filtering low-quality samples early using Accumulated Score Differences (ASD), without external rewards or retraining.", "motivation": "Address inconsistent sample quality in diffusion models without costly fine-tuning or external signals.", "method": "Exploit correlation between sample quality and ASD in classifier-free guidance (CFG) to filter samples early.", "result": "Improves human preference scores (HPSv2, PickScore) and benchmarks (GenEval, DPG-Bench).", "conclusion": "CFG-Rejection offers efficient, plug-and-play quality enhancement for diffusion models, applicable beyond images."}}
{"id": "2505.23354", "pdf": "https://arxiv.org/pdf/2505.23354", "abs": "https://arxiv.org/abs/2505.23354", "authors": ["Meital Bojan", "Sanketh Vedula", "Advaith Maddipatla", "Nadav Bojan Sellam", "Federico Napoli", "Paul Schanda", "Alex M. Bronstein"], "title": "Representing local protein environments with atomistic foundation models", "categories": ["q-bio.BM", "cs.AI"], "comment": null, "summary": "The local structure of a protein strongly impacts its function and\ninteractions with other molecules. Therefore, a concise, informative\nrepresentation of a local protein environment is essential for modeling and\ndesigning proteins and biomolecular interactions. However, these environments'\nextensive structural and chemical variability makes them challenging to model,\nand such representations remain under-explored. In this work, we propose a\nnovel representation for a local protein environment derived from the\nintermediate features of atomistic foundation models (AFMs). We demonstrate\nthat this embedding effectively captures both local structure (e.g., secondary\nmotifs), and chemical features (e.g., amino-acid identity and protonation\nstate). We further show that the AFM-derived representation space exhibits\nmeaningful structure, enabling the construction of data-driven priors over the\ndistribution of biomolecular environments. Finally, in the context of\nbiomolecular NMR spectroscopy, we demonstrate that the proposed representations\nenable a first-of-its-kind physics-informed chemical shift predictor that\nachieves state-of-the-art accuracy. Our results demonstrate the surprising\neffectiveness of atomistic foundation models and their emergent representations\nfor protein modeling beyond traditional molecular simulations. We believe this\nwill open new lines of work in constructing effective functional\nrepresentations for protein environments.", "AI": {"tldr": "The paper introduces a novel representation for local protein environments using atomistic foundation models (AFMs), capturing structural and chemical features effectively. It shows state-of-the-art accuracy in biomolecular NMR spectroscopy.", "motivation": "Local protein environments are crucial for function and interactions but are challenging to model due to structural and chemical variability. Existing representations are under-explored.", "method": "Proposes a representation derived from AFM intermediate features, capturing local structure and chemical details.", "result": "The AFM-derived representation effectively models protein environments and enables a physics-informed chemical shift predictor with top accuracy.", "conclusion": "AFMs offer surprising effectiveness for protein modeling, opening new avenues for functional representations."}}
{"id": "2505.23244", "pdf": "https://arxiv.org/pdf/2505.23244", "abs": "https://arxiv.org/abs/2505.23244", "authors": ["Emo Todorov"], "title": "Equivalence of stochastic and deterministic policy gradients", "categories": ["cs.LG"], "comment": null, "summary": "Policy gradients in continuous control have been derived for both stochastic\nand deterministic policies. Here we study the relationship between the two. In\na widely-used family of MDPs involving Gaussian control noise and quadratic\ncontrol costs, we show that the stochastic and deterministic policy gradients,\nnatural gradients, and state value functions are identical; while the\nstate-control value functions are different. We then develop a general\nprocedure for constructing an MDP with deterministic policy that is equivalent\nto a given MDP with stochastic policy. The controls of this new MDP are the\nsufficient statistics of the stochastic policy in the original MDP. Our results\nsuggest that policy gradient methods can be unified by approximating state\nvalue functions rather than state-control value functions.", "AI": {"tldr": "The paper explores the relationship between stochastic and deterministic policy gradients in continuous control, showing their equivalence in certain MDPs and proposing a method to unify them.", "motivation": "To understand and bridge the gap between stochastic and deterministic policy gradients in continuous control settings.", "method": "Analyzes MDPs with Gaussian control noise and quadratic costs, showing equivalence of gradients and value functions, and develops a procedure to construct equivalent deterministic MDPs.", "result": "Stochastic and deterministic policy gradients, natural gradients, and state value functions are identical in the studied MDPs, while state-control value functions differ.", "conclusion": "Policy gradient methods can be unified by approximating state value functions instead of state-control value functions."}}
{"id": "2505.23477", "pdf": "https://arxiv.org/pdf/2505.23477", "abs": "https://arxiv.org/abs/2505.23477", "authors": ["Krithik Vishwanath", "Anton Alyakin", "Mrigayu Ghosh", "Jin Vivian Lee", "Daniel Alexander Alber", "Karl L. Sangwon", "Douglas Kondziolka", "Eric Karl Oermann"], "title": "Evaluating the performance and fragility of large language models on the self-assessment for neurological surgeons", "categories": ["cs.CL"], "comment": "22 pages, 3 main figures, 3 supplemental figures", "summary": "The Congress of Neurological Surgeons Self-Assessment for Neurological\nSurgeons (CNS-SANS) questions are widely used by neurosurgical residents to\nprepare for written board examinations. Recently, these questions have also\nserved as benchmarks for evaluating large language models' (LLMs) neurosurgical\nknowledge. This study aims to assess the performance of state-of-the-art LLMs\non neurosurgery board-like questions and to evaluate their robustness to the\ninclusion of distractor statements. A comprehensive evaluation was conducted\nusing 28 large language models. These models were tested on 2,904 neurosurgery\nboard examination questions derived from the CNS-SANS. Additionally, the study\nintroduced a distraction framework to assess the fragility of these models. The\nframework incorporated simple, irrelevant distractor statements containing\npolysemous words with clinical meanings used in non-clinical contexts to\ndetermine the extent to which such distractions degrade model performance on\nstandard medical benchmarks. 6 of the 28 tested LLMs achieved board-passing\noutcomes, with the top-performing models scoring over 15.7% above the passing\nthreshold. When exposed to distractions, accuracy across various model\narchitectures was significantly reduced-by as much as 20.4%-with one model\nfailing that had previously passed. Both general-purpose and medical\nopen-source models experienced greater performance declines compared to\nproprietary variants when subjected to the added distractors. While current\nLLMs demonstrate an impressive ability to answer neurosurgery board-like exam\nquestions, their performance is markedly vulnerable to extraneous, distracting\ninformation. These findings underscore the critical need for developing novel\nmitigation strategies aimed at bolstering LLM resilience against in-text\ndistractions, particularly for safe and effective clinical deployment.", "AI": {"tldr": "The study evaluates 28 large language models (LLMs) on neurosurgery board-like questions, finding 6 passed, but performance dropped significantly with distractors.", "motivation": "To assess LLMs' neurosurgical knowledge and their robustness to distracting information for clinical applications.", "method": "Tested 28 LLMs on 2,904 CNS-SANS questions and introduced a distraction framework with irrelevant statements.", "result": "6 LLMs passed; performance dropped by up to 20.4% with distractors, with proprietary models outperforming open-source ones.", "conclusion": "LLMs show promise but are vulnerable to distractions, highlighting the need for resilience strategies for clinical use."}}
{"id": "2505.23346", "pdf": "https://arxiv.org/pdf/2505.23346", "abs": "https://arxiv.org/abs/2505.23346", "authors": ["Yexiong Lin", "Yu Yao", "Tongliang Liu"], "title": "Beyond Optimal Transport: Model-Aligned Coupling for Flow Matching", "categories": ["cs.CV"], "comment": null, "summary": "Flow Matching (FM) is an effective framework for training a model to learn a\nvector field that transports samples from a source distribution to a target\ndistribution. To train the model, early FM methods use random couplings, which\noften result in crossing paths and lead the model to learn non-straight\ntrajectories that require many integration steps to generate high-quality\nsamples. To address this, recent methods adopt Optimal Transport (OT) to\nconstruct couplings by minimizing geometric distances, which helps reduce path\ncrossings. However, we observe that such geometry-based couplings do not\nnecessarily align with the model's preferred trajectories, making it difficult\nto learn the vector field induced by these couplings, which prevents the model\nfrom learning straight trajectories. Motivated by this, we propose\nModel-Aligned Coupling (MAC), an effective method that matches training\ncouplings based not only on geometric distance but also on alignment with the\nmodel's preferred transport directions based on its prediction error. To avoid\nthe time-costly match process, MAC proposes to select the top-$k$ fraction of\ncouplings with the lowest error for training. Extensive experiments show that\nMAC significantly improves generation quality and efficiency in few-step\nsettings compared to existing methods. Project page:\nhttps://yexionglin.github.io/mac", "AI": {"tldr": "Flow Matching (FM) trains models to transport samples between distributions. Early FM methods used random couplings, causing non-straight trajectories. Recent methods use Optimal Transport (OT) to reduce path crossings, but these couplings may not align with the model's preferred trajectories. Model-Aligned Coupling (MAC) addresses this by matching couplings based on geometric distance and model alignment, improving generation quality and efficiency.", "motivation": "Early FM methods result in non-straight trajectories due to random couplings, while OT-based couplings may not align with the model's preferences. MAC aims to improve trajectory alignment and generation efficiency.", "method": "MAC matches training couplings based on geometric distance and alignment with the model's preferred transport directions, selecting the top-$k$ couplings with the lowest prediction error for training.", "result": "MAC significantly improves generation quality and efficiency in few-step settings compared to existing methods.", "conclusion": "MAC effectively aligns couplings with the model's preferences, enhancing FM performance in generating high-quality samples efficiently."}}
{"id": "2505.23367", "pdf": "https://arxiv.org/pdf/2505.23367", "abs": "https://arxiv.org/abs/2505.23367", "authors": ["Jeonghyeok Do", "Sungpyo Kim", "Geunhyuk Youk", "Jaehyup Lee", "Munchurl Kim"], "title": "PAN-Crafter: Learning Modality-Consistent Alignment for PAN-Sharpening", "categories": ["cs.CV", "cs.AI"], "comment": "Please visit our project page\n  https://kaist-viclab.github.io/PAN-Crafter_site", "summary": "PAN-sharpening aims to fuse high-resolution panchromatic (PAN) images with\nlow-resolution multi-spectral (MS) images to generate high-resolution\nmulti-spectral (HRMS) outputs. However, cross-modality misalignment -- caused\nby sensor placement, acquisition timing, and resolution disparity -- induces a\nfundamental challenge. Conventional deep learning methods assume perfect\npixel-wise alignment and rely on per-pixel reconstruction losses, leading to\nspectral distortion, double edges, and blurring when misalignment is present.\nTo address this, we propose PAN-Crafter, a modality-consistent alignment\nframework that explicitly mitigates the misalignment gap between PAN and MS\nmodalities. At its core, Modality-Adaptive Reconstruction (MARs) enables a\nsingle network to jointly reconstruct HRMS and PAN images, leveraging PAN's\nhigh-frequency details as auxiliary self-supervision. Additionally, we\nintroduce Cross-Modality Alignment-Aware Attention (CM3A), a novel mechanism\nthat bidirectionally aligns MS texture to PAN structure and vice versa,\nenabling adaptive feature refinement across modalities. Extensive experiments\non multiple benchmark datasets demonstrate that our PAN-Crafter outperforms the\nmost recent state-of-the-art method in all metrics, even with 50.11$\\times$\nfaster inference time and 0.63$\\times$ the memory size. Furthermore, it\ndemonstrates strong generalization performance on unseen satellite datasets,\nshowing its robustness across different conditions.", "AI": {"tldr": "PAN-Crafter addresses cross-modality misalignment in PAN-sharpening by jointly reconstructing HRMS and PAN images and using bidirectional alignment for adaptive feature refinement.", "motivation": "Cross-modality misalignment in PAN-sharpening causes spectral distortion and blurring, which conventional methods fail to address due to assumptions of perfect alignment.", "method": "Proposes PAN-Crafter with Modality-Adaptive Reconstruction (MARs) and Cross-Modality Alignment-Aware Attention (CM3A) for joint reconstruction and bidirectional alignment.", "result": "Outperforms state-of-the-art methods in all metrics, with faster inference and smaller memory size, and generalizes well to unseen datasets.", "conclusion": "PAN-Crafter effectively mitigates misalignment, improving PAN-sharpening performance and robustness."}}
{"id": "2505.23246", "pdf": "https://arxiv.org/pdf/2505.23246", "abs": "https://arxiv.org/abs/2505.23246", "authors": ["Honoka Anada", "Tatsuya Kaneko", "Shinya Takamaeda-Yamazaki"], "title": "Measuring Participant Contributions in Decentralized Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated learning (FL) enables multiple clients to collaboratively train\nmodels without sharing their data. Measuring participant contributions in FL is\ncrucial for incentivizing clients and ensuring transparency. While various\nmethods have been proposed for contribution measurement, they are designed\nexclusively for centralized federated learning (CFL), where a central server\ncollects and aggregates client models, along with evaluating their\ncontributions. Meanwhile, decentralized federated learning (DFL), in which\nclients exchange models directly without a central server, has gained\nsignificant attention for mitigating communication bottlenecks and eliminating\na single point of failure. However, applying existing contribution measurement\nmethods to DFL is challenging due to the presence of multiple global models and\nthe absence of a central server. In this study, we present novel methodologies\nfor measuring participant contributions in DFL. We first propose DFL-Shapley,\nan extension of the Shapley value tailored for DFL, adapting this widely used\nCFL metric to decentralized settings. Given the impracticality of computing the\nideal DFL-Shapley in real-world systems, we introduce DFL-MR, a computable\napproximation that estimates overall contributions by accumulating round-wise\nShapley values. We evaluate DFL-Shapley and DFL-MR across various FL scenarios\nand compare them with existing CFL metrics. The experimental results confirm\nDFL-Shapley as a valid ground-truth metric and demonstrate DFL-MR's proximity\nto DFL-Shapley across various settings, highlighting their effectiveness as\ncontribution metrics in DFL.", "AI": {"tldr": "The paper introduces DFL-Shapley and DFL-MR, novel methods for measuring participant contributions in decentralized federated learning (DFL), addressing challenges posed by the absence of a central server.", "motivation": "Existing contribution measurement methods are designed for centralized federated learning (CFL) and are unsuitable for DFL, which lacks a central server and involves multiple global models.", "method": "The authors propose DFL-Shapley, an adaptation of the Shapley value for DFL, and DFL-MR, a practical approximation that accumulates round-wise Shapley values.", "result": "Experiments validate DFL-Shapley as a ground-truth metric and show DFL-MR closely approximates it, proving their effectiveness in DFL.", "conclusion": "The study successfully addresses the gap in contribution measurement for DFL, providing scalable and accurate metrics."}}
{"id": "2505.23480", "pdf": "https://arxiv.org/pdf/2505.23480", "abs": "https://arxiv.org/abs/2505.23480", "authors": ["Keqin Peng", "Liang Ding", "Yuanxin Ouyang", "Meng Fang", "Dacheng Tao"], "title": "Revisiting Overthinking in Long Chain-of-Thought from the Perspective of Self-Doubt", "categories": ["cs.CL"], "comment": null, "summary": "Reasoning Large Language Models (RLLMs) have demonstrated impressive\nperformance on complex tasks, largely due to the adoption of Long\nChain-of-Thought (Long CoT) reasoning. However, they often exhibit overthinking\n-- performing unnecessary reasoning steps even after arriving at the correct\nanswer. Prior work has largely focused on qualitative analyses of overthinking\nthrough sample-based observations of long CoTs. In contrast, we present a\nquantitative analysis of overthinking from the perspective of self-doubt,\ncharacterized by excessive token usage devoted to re-verifying already-correct\nanswer. We find that self-doubt significantly contributes to overthinking. In\nresponse, we introduce a simple and effective prompting method to reduce the\nmodel's over-reliance on input questions, thereby avoiding self-doubt.\nSpecifically, we first prompt the model to question the validity of the input\nquestion, and then respond concisely based on the outcome of that evaluation.\nExperiments on three mathematical reasoning tasks and four datasets with\nmissing premises demonstrate that our method substantially reduces answer\nlength and yields significant improvements across nearly all datasets upon 4\nwidely-used RLLMs. Further analysis demonstrates that our method effectively\nminimizes the number of reasoning steps and reduces self-doubt.", "AI": {"tldr": "The paper analyzes overthinking in Reasoning Large Language Models (RLLMs) due to self-doubt, proposes a prompting method to reduce it, and validates its effectiveness on mathematical tasks.", "motivation": "To address the issue of overthinking in RLLMs, characterized by unnecessary reasoning steps (self-doubt), which prior work only qualitatively analyzed.", "method": "Introduces a prompting technique where the model first questions the input's validity, then responds concisely, reducing over-reliance on the question.", "result": "The method reduces answer length and improves performance across datasets, minimizing reasoning steps and self-doubt.", "conclusion": "The proposed prompting method effectively mitigates overthinking in RLLMs by addressing self-doubt, enhancing efficiency and accuracy."}}
{"id": "2505.23358", "pdf": "https://arxiv.org/pdf/2505.23358", "abs": "https://arxiv.org/abs/2505.23358", "authors": ["Reem AlJunaid", "Muzammil Behzad"], "title": "Beam-Guided Knowledge Replay for Knowledge-Rich Image Captioning using Vision-Language Model", "categories": ["cs.CV"], "comment": null, "summary": "Generating informative and knowledge-rich image captions remains a challenge\nfor many existing captioning models, which often produce generic descriptions\nthat lack specificity and contextual depth. To address this limitation, we\npropose KRCapVLM, a knowledge replay-based novel image captioning framework\nusing vision-language model. We incorporate beam search decoding to generate\nmore diverse and coherent captions. We also integrate attention-based modules\ninto the image encoder to enhance feature representation. Finally, we employ\ntraining schedulers to improve stability and ensure smoother convergence during\ntraining. These proposals accelerate substantial gains in both caption quality\nand knowledge recognition. Our proposed model demonstrates clear improvements\nin both the accuracy of knowledge recognition and the overall quality of\ngenerated captions. It shows a stronger ability to generalize to previously\nunseen knowledge concepts, producing more informative and contextually relevant\ndescriptions. These results indicate the effectiveness of our approach in\nenhancing the model's capacity to generate meaningful, knowledge-grounded\ncaptions across a range of scenarios.", "AI": {"tldr": "KRCapVLM improves image captioning by using knowledge replay and vision-language models, enhancing caption quality and knowledge recognition.", "motivation": "Existing captioning models often produce generic descriptions lacking specificity and contextual depth.", "method": "Proposes KRCapVLM with beam search decoding, attention-based modules, and training schedulers.", "result": "Substantial gains in caption quality and knowledge recognition, with better generalization to unseen concepts.", "conclusion": "The approach effectively enhances meaningful, knowledge-grounded caption generation."}}
{"id": "2505.23369", "pdf": "https://arxiv.org/pdf/2505.23369", "abs": "https://arxiv.org/abs/2505.23369", "authors": ["Mannmohan Muthuraman"], "title": "Dynamic Spectral Backpropagation for Efficient Neural Network Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Dynamic Spectral Backpropagation (DSBP) enhances neural network training\nunder resource constraints by projecting gradients onto principal eigenvectors,\nreducing complexity and promoting flat minima. Five extensions are proposed,\ndynamic spectral inference, spectral architecture optimization, spectral meta\nlearning, spectral transfer regularization, and Lie algebra inspired dynamics,\nto address challenges in robustness, fewshot learning, and hardware efficiency.\nSupported by a third order stochastic differential equation (SDE) and a PAC\nBayes limit, DSBP outperforms Sharpness Aware Minimization (SAM), Low Rank\nAdaptation (LoRA), and Model Agnostic Meta Learning (MAML) on CIFAR 10, Fashion\nMNIST, MedMNIST, and Tiny ImageNet, as demonstrated through extensive\nexperiments and visualizations. Future work focuses on scalability, bias\nmitigation, and ethical considerations.", "AI": {"tldr": "DSBP improves neural network training under resource constraints by projecting gradients onto principal eigenvectors, outperforming SAM, LoRA, and MAML.", "motivation": "Address challenges in robustness, few-shot learning, and hardware efficiency under resource constraints.", "method": "Uses dynamic spectral backpropagation with five extensions: dynamic spectral inference, spectral architecture optimization, spectral meta-learning, spectral transfer regularization, and Lie algebra-inspired dynamics.", "result": "Outperforms SAM, LoRA, and MAML on CIFAR-10, Fashion MNIST, MedMNIST, and Tiny ImageNet.", "conclusion": "Future work focuses on scalability, bias mitigation, and ethical considerations."}}
{"id": "2505.23264", "pdf": "https://arxiv.org/pdf/2505.23264", "abs": "https://arxiv.org/abs/2505.23264", "authors": ["Fangyikang Wang", "Hubery Yin", "Shaobin Zhuang", "Huminhao Zhu", "Yinan Li", "Lei Qian", "Chao Zhang", "Hanbin Zhao", "Hui Qian", "Chen Li"], "title": "Efficiently Access Diffusion Fisher: Within the Outer Product Span Space", "categories": ["cs.LG"], "comment": null, "summary": "Recent Diffusion models (DMs) advancements have explored incorporating the\nsecond-order diffusion Fisher information (DF), defined as the negative Hessian\nof log density, into various downstream tasks and theoretical analysis.\nHowever, current practices typically approximate the diffusion Fisher by\napplying auto-differentiation to the learned score network. This black-box\nmethod, though straightforward, lacks any accuracy guarantee and is\ntime-consuming. In this paper, we show that the diffusion Fisher actually\nresides within a space spanned by the outer products of score and initial data.\nBased on the outer-product structure, we develop two efficient approximation\nalgorithms to access the trace and matrix-vector multiplication of DF,\nrespectively. These algorithms bypass the auto-differentiation operations with\ntime-efficient vector-product calculations. Furthermore, we establish the\napproximation error bounds for the proposed algorithms. Experiments in\nlikelihood evaluation and adjoint optimization demonstrate the superior\naccuracy and reduced computational cost of our proposed algorithms.\nAdditionally, based on the novel outer-product formulation of DF, we design the\nfirst numerical verification experiment for the optimal transport property of\nthe general PF-ODE deduced map.", "AI": {"tldr": "The paper introduces efficient algorithms for approximating the diffusion Fisher information (DF) in diffusion models, avoiding time-consuming auto-differentiation and providing error bounds.", "motivation": "Current methods for approximating DF lack accuracy guarantees and are computationally expensive, prompting the need for more efficient and reliable solutions.", "method": "The authors propose two algorithms based on the outer-product structure of DF, focusing on trace and matrix-vector multiplication, bypassing auto-differentiation.", "result": "Experiments show the algorithms improve accuracy and reduce computational cost in tasks like likelihood evaluation and adjoint optimization.", "conclusion": "The proposed methods offer a more efficient and accurate way to handle DF, with potential applications in verifying optimal transport properties."}}
{"id": "2505.23495", "pdf": "https://arxiv.org/pdf/2505.23495", "abs": "https://arxiv.org/abs/2505.23495", "authors": ["Liangliang Zhang", "Zhuorui Jiang", "Hongliang Chi", "Haoyang Chen", "Mohammed Elkoumy", "Fali Wang", "Qiong Wu", "Zhengyi Zhou", "Shirui Pan", "Suhang Wang", "Yao Ma"], "title": "Diagnosing and Addressing Pitfalls in KG-RAG Datasets: Toward More Reliable Benchmarking", "categories": ["cs.CL", "cs.LG"], "comment": "9 pages", "summary": "Knowledge Graph Question Answering (KGQA) systems rely on high-quality\nbenchmarks to evaluate complex multi-hop reasoning. However, despite their\nwidespread use, popular datasets such as WebQSP and CWQ suffer from critical\nquality issues, including inaccurate or incomplete ground-truth annotations,\npoorly constructed questions that are ambiguous, trivial, or unanswerable, and\noutdated or inconsistent knowledge. Through a manual audit of 16 popular KGQA\ndatasets, including WebQSP and CWQ, we find that the average factual\ncorrectness rate is only 57 %. To address these issues, we introduce KGQAGen,\nan LLM-in-the-loop framework that systematically resolves these pitfalls.\nKGQAGen combines structured knowledge grounding, LLM-guided generation, and\nsymbolic verification to produce challenging and verifiable QA instances. Using\nKGQAGen, we construct KGQAGen-10k, a ten-thousand scale benchmark grounded in\nWikidata, and evaluate a diverse set of KG-RAG models. Experimental results\ndemonstrate that even state-of-the-art systems struggle on this benchmark,\nhighlighting its ability to expose limitations of existing models. Our findings\nadvocate for more rigorous benchmark construction and position KGQAGen as a\nscalable framework for advancing KGQA evaluation.", "AI": {"tldr": "KGQAGen is introduced to address quality issues in KGQA benchmarks, creating KGQAGen-10k, a challenging benchmark that exposes limitations of state-of-the-art models.", "motivation": "Popular KGQA datasets have critical quality issues (e.g., incorrect annotations, ambiguous questions), with only 57% factual correctness.", "method": "KGQAGen uses LLM-guided generation, structured knowledge grounding, and symbolic verification to create verifiable QA instances.", "result": "KGQAGen-10k challenges even state-of-the-art KG-RAG models, revealing their limitations.", "conclusion": "KGQAGen advocates for rigorous benchmark construction and serves as a scalable framework for KGQA evaluation."}}
{"id": "2505.23359", "pdf": "https://arxiv.org/pdf/2505.23359", "abs": "https://arxiv.org/abs/2505.23359", "authors": ["Yuanxin Liu", "Kun Ouyang", "Haoning Wu", "Yi Liu", "Lin Sui", "Xinhao Li", "Yan Zhong", "Y. Charles", "Xinyu Zhou", "Xu Sun"], "title": "VideoReasonBench: Can MLLMs Perform Vision-Centric Complex Video Reasoning?", "categories": ["cs.CV"], "comment": "Project Page: https://llyx97.github.io/video_reason_bench/", "summary": "Recent studies have shown that long chain-of-thought (CoT) reasoning can\nsignificantly enhance the performance of large language models (LLMs) on\ncomplex tasks. However, this benefit is yet to be demonstrated in the domain of\nvideo understanding, since most existing benchmarks lack the reasoning depth\nrequired to demonstrate the advantages of extended CoT chains. While recent\nefforts have proposed benchmarks aimed at video reasoning, the tasks are often\nknowledge-driven and do not rely heavily on visual content. To bridge this gap,\nwe introduce VideoReasonBench, a benchmark designed to evaluate vision-centric,\ncomplex video reasoning. To ensure visual richness and high reasoning\ncomplexity, each video in VideoReasonBench depicts a sequence of fine-grained\noperations on a latent state that is only visible in part of the video. The\nquestions evaluate three escalating levels of video reasoning skills: recalling\nobserved visual information, inferring the content of latent states, and\npredicting information beyond the video. Under such task setting, models have\nto precisely recall multiple operations in the video, and perform step-by-step\nreasoning to get correct final answers for these questions. Using\nVideoReasonBench, we comprehensively evaluate 18 state-of-the-art multimodal\nLLMs (MLLMs), finding that most perform poorly on complex video reasoning,\ne.g., GPT-4o achieves only 6.9% accuracy, while the thinking-enhanced\nGemini-2.5-Pro significantly outperforms others with 56.0% accuracy. Our\ninvestigations on \"test-time scaling\" further reveal that extended thinking\nbudget, while offering none or minimal benefits on existing video benchmarks,\nis essential for improving the performance on VideoReasonBench.", "AI": {"tldr": "VideoReasonBench is a new benchmark for vision-centric video reasoning, showing current models struggle with complex tasks, but extended reasoning helps.", "motivation": "Existing video benchmarks lack depth for evaluating extended chain-of-thought reasoning, and tasks are often knowledge-driven rather than vision-centric.", "method": "Introduce VideoReasonBench with videos depicting fine-grained operations on latent states, testing three reasoning levels: recall, inference, and prediction.", "result": "Most MLLMs perform poorly (e.g., GPT-4o at 6.9%), but Gemini-2.5-Pro excels (56.0%). Extended reasoning improves performance on VideoReasonBench.", "conclusion": "VideoReasonBench highlights the need for vision-centric reasoning and shows extended CoT benefits complex video tasks."}}
{"id": "2505.23386", "pdf": "https://arxiv.org/pdf/2505.23386", "abs": "https://arxiv.org/abs/2505.23386", "authors": ["Han Bao", "Qinying Wang", "Zhi Chen", "Qingming Li", "Xuhong Zhang", "Changjiang Li", "Zonghui Wang", "Shouling Ji", "Wenzhi Chen"], "title": "VModA: An Effective Framework for Adaptive NSFW Image Moderation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Not Safe/Suitable for Work (NSFW) content is rampant on social networks and\nposes serious harm to citizens, especially minors. Current detection methods\nmainly rely on deep learning-based image recognition and classification.\nHowever, NSFW images are now presented in increasingly sophisticated ways,\noften using image details and complex semantics to obscure their true nature or\nattract more views. Although still understandable to humans, these images often\nevade existing detection methods, posing a significant threat. Further\ncomplicating the issue, varying regulations across platforms and regions create\nadditional challenges for effective moderation, leading to detection bias and\nreduced accuracy. To address this, we propose VModA, a general and effective\nframework that adapts to diverse moderation rules and handles complex,\nsemantically rich NSFW content across categories. Experimental results show\nthat VModA significantly outperforms existing methods, achieving up to a 54.3%\naccuracy improvement across NSFW types, including those with complex semantics.\nFurther experiments demonstrate that our method exhibits strong adaptability\nacross categories, scenarios, and base VLMs. We also identified inconsistent\nand controversial label samples in public NSFW benchmark datasets, re-annotated\nthem, and submitted corrections to the original maintainers. Two datasets have\nconfirmed the updates so far. Additionally, we evaluate VModA in real-world\nscenarios to demonstrate its practical effectiveness.", "AI": {"tldr": "VModA is a framework for detecting NSFW content, outperforming existing methods by 54.3% in accuracy and adapting to diverse moderation rules and complex semantics.", "motivation": "NSFW content on social networks harms users, especially minors, and current detection methods fail against sophisticated evasion techniques and varying regulations.", "method": "Proposes VModA, a framework adaptable to diverse moderation rules and capable of handling complex, semantically rich NSFW content.", "result": "VModA improves accuracy by up to 54.3% across NSFW types, shows adaptability, and corrects inconsistencies in benchmark datasets.", "conclusion": "VModA is effective for real-world NSFW detection, addressing current limitations and improving accuracy and adaptability."}}
{"id": "2505.23285", "pdf": "https://arxiv.org/pdf/2505.23285", "abs": "https://arxiv.org/abs/2505.23285", "authors": ["Muhammad Shafi", "Syed Mohsin Bokhari"], "title": "Comparative Analysis of the Land Use and Land Cover Changes in Different Governorates of Oman using Spatiotemporal Multi-spectral Satellite Data", "categories": ["cs.LG"], "comment": null, "summary": "Land cover and land use (LULC) changes are key applications of satellite\nimagery, and they have critical roles in resource management, urbanization,\nprotection of soils and the environment, and enhancing sustainable development.\nThe literature has heavily utilized multispectral spatiotemporal satellite data\nalongside advanced machine learning algorithms to monitor and predict LULC\nchanges. This study analyzes and compares LULC changes across various\ngovernorates (provinces) of the Sultanate of Oman from 2016 to 2021 using\nannual time steps. For the chosen region, multispectral spatiotemporal data\nwere acquired from the open-source Sentinel-2 satellite dataset. Supervised\nmachine learning algorithms were used to train and classify different land\ncovers, such as water bodies, crops, urban, etc. The constructed model was\nsubsequently applied within the study region, allowing for an effective\ncomparative evaluation of LULC changes within the given timeframe.", "AI": {"tldr": "The study compares land cover and land use (LULC) changes in Oman from 2016 to 2021 using Sentinel-2 satellite data and supervised machine learning.", "motivation": "LULC changes are crucial for resource management, urbanization, and sustainability, necessitating accurate monitoring and prediction.", "method": "Multispectral Sentinel-2 data was analyzed using supervised machine learning to classify land covers (e.g., water, crops, urban areas).", "result": "The model enabled comparative evaluation of LULC changes across Oman's governorates over five years.", "conclusion": "The approach effectively monitors LULC changes, supporting sustainable development and environmental protection."}}
{"id": "2505.23538", "pdf": "https://arxiv.org/pdf/2505.23538", "abs": "https://arxiv.org/abs/2505.23538", "authors": ["Nawar Turk", "Eeham Khan", "Leila Kosseim"], "title": "CLaC at SemEval-2025 Task 6: A Multi-Architecture Approach for Corporate Environmental Promise Verification", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to SemEval-2025 Task 6 (ACL 2025)", "summary": "This paper presents our approach to the SemEval-2025 Task~6 (PromiseEval),\nwhich focuses on verifying promises in corporate ESG (Environmental, Social,\nand Governance) reports. We explore three model architectures to address the\nfour subtasks of promise identification, supporting evidence assessment,\nclarity evaluation, and verification timing. Our first model utilizes ESG-BERT\nwith task-specific classifier heads, while our second model enhances this\narchitecture with linguistic features tailored for each subtask. Our third\napproach implements a combined subtask model with attention-based sequence\npooling, transformer representations augmented with document metadata, and\nmulti-objective learning. Experiments on the English portion of the ML-Promise\ndataset demonstrate progressive improvement across our models, with our\ncombined subtask approach achieving a leaderboard score of 0.5268,\noutperforming the provided baseline of 0.5227. Our work highlights the\neffectiveness of linguistic feature extraction, attention pooling, and\nmulti-objective learning in promise verification tasks, despite challenges\nposed by class imbalance and limited training data.", "AI": {"tldr": "The paper presents three model architectures for verifying promises in corporate ESG reports, achieving progressive improvements and outperforming the baseline.", "motivation": "To address the challenge of verifying promises in ESG reports by exploring effective model architectures for subtasks like identification, evidence assessment, clarity evaluation, and verification timing.", "method": "Three models: ESG-BERT with task-specific heads, ESG-BERT enhanced with linguistic features, and a combined subtask model with attention pooling, transformer representations, and multi-objective learning.", "result": "The combined subtask model achieved a leaderboard score of 0.5268, outperforming the baseline (0.5227).", "conclusion": "Linguistic features, attention pooling, and multi-objective learning are effective for promise verification, though challenges like class imbalance and limited data persist."}}
{"id": "2505.23365", "pdf": "https://arxiv.org/pdf/2505.23365", "abs": "https://arxiv.org/abs/2505.23365", "authors": ["Yang Qiao", "Xiaoyu Zhong", "Xiaofeng Gu", "Zhiguo Yu"], "title": "MCFNet: A Multimodal Collaborative Fusion Network for Fine-Grained Semantic Classification", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal information processing has become increasingly important for\nenhancing image classification performance. However, the intricate and implicit\ndependencies across different modalities often hinder conventional methods from\neffectively capturing fine-grained semantic interactions, thereby limiting\ntheir applicability in high-precision classification tasks. To address this\nissue, we propose a novel Multimodal Collaborative Fusion Network (MCFNet)\ndesigned for fine-grained classification. The proposed MCFNet architecture\nincorporates a regularized integrated fusion module that improves intra-modal\nfeature representation through modality-specific regularization strategies,\nwhile facilitating precise semantic alignment via a hybrid attention mechanism.\nAdditionally, we introduce a multimodal decision classification module, which\njointly exploits inter-modal correlations and unimodal discriminative features\nby integrating multiple loss functions within a weighted voting paradigm.\nExtensive experiments and ablation studies on benchmark datasets demonstrate\nthat the proposed MCFNet framework achieves consistent improvements in\nclassification accuracy, confirming its effectiveness in modeling subtle\ncross-modal semantics.", "AI": {"tldr": "A novel Multimodal Collaborative Fusion Network (MCFNet) improves fine-grained image classification by addressing cross-modal dependencies and enhancing semantic alignment.", "motivation": "Conventional methods struggle with intricate cross-modal dependencies, limiting high-precision classification.", "method": "MCFNet uses a regularized fusion module and hybrid attention for intra-modal feature enhancement and semantic alignment, plus a multimodal decision module with weighted voting.", "result": "MCFNet achieves consistent accuracy improvements on benchmark datasets.", "conclusion": "MCFNet effectively models subtle cross-modal semantics for superior classification performance."}}
{"id": "2505.23387", "pdf": "https://arxiv.org/pdf/2505.23387", "abs": "https://arxiv.org/abs/2505.23387", "authors": ["Mingzhe Du", "Luu Tuan Tuan", "Yue Liu", "Yuhao Qing", "Dong Huang", "Xinyi He", "Qian Liu", "Zejun Ma", "See-kiong Ng"], "title": "Afterburner: Reinforcement Learning Facilitates Self-Improving Code Efficiency Optimization", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) generate functionally correct solutions but\noften fall short in code efficiency, a critical bottleneck for real-world\ndeployment. In this paper, we introduce a novel test-time iterative\noptimization framework to address this, employing a closed-loop system where\nLLMs iteratively refine code based on empirical performance feedback from an\nexecution sandbox. We explore three training strategies: Supervised Fine-Tuning\n(SFT), Direct Preference Optimization (DPO), and Group Relative Policy\nOptimization~(GRPO). Experiments on our Venus dataset and the APPS benchmark\nshow that SFT and DPO rapidly saturate in efficiency gains. In contrast, GRPO,\nusing reinforcement learning (RL) with execution feedback, continuously\noptimizes code performance, significantly boosting both pass@1 (from 47% to\n62%) and the likelihood of outperforming human submissions in efficiency (from\n31% to 45%). Our work demonstrates effective test-time code efficiency\nimprovement and critically reveals the power of RL in teaching LLMs to truly\nself-improve code efficiency.", "AI": {"tldr": "A novel test-time iterative optimization framework improves LLM-generated code efficiency using execution feedback, with GRPO (RL-based) outperforming SFT and DPO.", "motivation": "LLMs often produce inefficient code, hindering real-world deployment. This paper aims to enhance code efficiency through iterative refinement.", "method": "A closed-loop system with execution feedback iteratively refines code. Three training strategies are compared: SFT, DPO, and GRPO (RL-based).", "result": "GRPO significantly improves pass@1 (47% to 62%) and efficiency (31% to 45% vs. humans), while SFT and DPO saturate quickly.", "conclusion": "RL-based GRPO effectively teaches LLMs to self-improve code efficiency, demonstrating its superiority over SFT and DPO."}}
{"id": "2505.23320", "pdf": "https://arxiv.org/pdf/2505.23320", "abs": "https://arxiv.org/abs/2505.23320", "authors": ["Connor Cooper", "Geoffrey I. Webb", "Daniel F. Schmidt"], "title": "Efficient Parameter Estimation for Bayesian Network Classifiers using Hierarchical Linear Smoothing", "categories": ["cs.LG", "stat.ML"], "comment": "20 pages, 9 figures", "summary": "Bayesian network classifiers (BNCs) possess a number of properties desirable\nfor a modern classifier: They are easily interpretable, highly scalable, and\noffer adaptable complexity. However, traditional methods for learning BNCs have\nhistorically underperformed when compared to leading classification methods\nsuch as random forests. Recent parameter smoothing techniques using\nhierarchical Dirichlet processes (HDPs) have enabled BNCs to achieve\nperformance competitive with random forests on categorical data, but these\ntechniques are relatively inflexible, and require a complicated, specialized\nsampling process. In this paper, we introduce a novel method for parameter\nestimation that uses a log-linear regression to approximate the behaviour of\nHDPs. As a linear model, our method is remarkably flexible and simple to\ninterpret, and can leverage the vast literature on learning linear models. Our\nexperiments show that our method can outperform HDP smoothing while being\norders of magnitude faster, remaining competitive with random forests on\ncategorical data.", "AI": {"tldr": "A new log-linear regression method for Bayesian network classifiers (BNCs) outperforms hierarchical Dirichlet processes (HDPs) in speed and flexibility, matching random forests on categorical data.", "motivation": "Traditional BNCs underperform compared to methods like random forests, and HDP smoothing, while effective, is inflexible and complex.", "method": "Proposes a log-linear regression to approximate HDP behavior, offering simplicity and flexibility.", "result": "The new method outperforms HDP smoothing in speed and performance, competing with random forests.", "conclusion": "The log-linear approach provides a faster, simpler, and competitive alternative to HDPs for BNCs."}}
{"id": "2505.23540", "pdf": "https://arxiv.org/pdf/2505.23540", "abs": "https://arxiv.org/abs/2505.23540", "authors": ["Yunqiao Yang", "Houxing Ren", "Zimu Lu", "Ke Wang", "Weikang Shi", "Aojun Zhou", "Junting Pan", "Mingjie Zhan", "Hongsheng Li"], "title": "Probability-Consistent Preference Optimization for Enhanced LLM Reasoning", "categories": ["cs.CL"], "comment": "14 pages, to be published in ACL 2025 findings", "summary": "Recent advances in preference optimization have demonstrated significant\npotential for improving mathematical reasoning capabilities in large language\nmodels (LLMs). While current approaches leverage high-quality pairwise\npreference data through outcome-based criteria like answer correctness or\nconsistency, they fundamentally neglect the internal logical coherence of\nresponses. To overcome this, we propose Probability-Consistent Preference\nOptimization (PCPO), a novel framework that establishes dual quantitative\nmetrics for preference selection: (1) surface-level answer correctness and (2)\nintrinsic token-level probability consistency across responses. Extensive\nexperiments show that our PCPO consistently outperforms existing outcome-only\ncriterion approaches across a diverse range of LLMs and benchmarks. Our code is\npublicly available at https://github.com/YunqiaoYang/PCPO.", "AI": {"tldr": "PCPO improves LLM reasoning by ensuring both answer correctness and token-level probability consistency, outperforming existing methods.", "motivation": "Current preference optimization methods neglect internal logical coherence, focusing only on outcome-based criteria.", "method": "Proposes PCPO, a framework using dual metrics: answer correctness and token-level probability consistency.", "result": "PCPO outperforms existing approaches across diverse LLMs and benchmarks.", "conclusion": "PCPO offers a robust solution for enhancing LLM reasoning by addressing logical coherence."}}
{"id": "2505.23380", "pdf": "https://arxiv.org/pdf/2505.23380", "abs": "https://arxiv.org/abs/2505.23380", "authors": ["Weijia Mao", "Zhenheng Yang", "Mike Zheng Shou"], "title": "UniRL: Self-Improving Unified Multimodal Models via Supervised and Reinforcement Learning", "categories": ["cs.CV"], "comment": null, "summary": "Unified multimodal large language models such as Show-o and Janus have\nachieved strong performance across both generation and understanding tasks.\nHowever, these models typically rely on large-scale datasets and require\nsubstantial computation during the pretraining stage. In addition, several\npost-training methods have been proposed, but they often depend on external\ndata or are limited to task-specific customization. In this work, we introduce\nUniRL, a self-improving post-training approach. Our approach enables the model\nto generate images from prompts and use them as training data in each\niteration, without relying on any external image data. Moreover, it enables the\ntwo tasks to enhance each other: the generated images are used for\nunderstanding, and the understanding results are used to supervise generation.\nWe explore supervised fine-tuning (SFT) and Group Relative Policy Optimization\n(GRPO) to optimize the models. UniRL offers three key advantages: (1) it\nrequires no external image data, as all training samples are generated by the\nmodel itself during training; (2) it not only improves individual task\nperformance, but also reduces the imbalance between generation and\nunderstanding; and (3) it requires only several additional training steps\nduring the post-training stage. We evaluate UniRL on top of Show-o and Janus,\nachieving a GenEval score of 0.77 for Show-o and 0.65 for Janus. Code and\nmodels will be released in https://github.com/showlab/UniRL.", "AI": {"tldr": "UniRL is a self-improving post-training approach for multimodal large language models, eliminating the need for external data by generating and using its own training samples.", "motivation": "Existing models rely on large datasets and external data for post-training, limiting flexibility and efficiency. UniRL aims to overcome these limitations.", "method": "UniRL generates images from prompts for training, using supervised fine-tuning (SFT) and Group Relative Policy Optimization (GRPO) to optimize tasks.", "result": "UniRL improves task performance (GenEval scores: 0.77 for Show-o, 0.65 for Janus) and balances generation and understanding tasks.", "conclusion": "UniRL offers a data-efficient, self-improving solution for multimodal models, enhancing performance without external dependencies."}}
{"id": "2505.23406", "pdf": "https://arxiv.org/pdf/2505.23406", "abs": "https://arxiv.org/abs/2505.23406", "authors": ["Binyamin Manela", "Sharon Gannot", "Ethan Fetyaya"], "title": "Video Editing for Audio-Visual Dubbing", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Visual dubbing, the synchronization of facial movements with new speech, is\ncrucial for making content accessible across different languages, enabling\nbroader global reach. However, current methods face significant limitations.\nExisting approaches often generate talking faces, hindering seamless\nintegration into original scenes, or employ inpainting techniques that discard\nvital visual information like partial occlusions and lighting variations. This\nwork introduces EdiDub, a novel framework that reformulates visual dubbing as a\ncontent-aware editing task. EdiDub preserves the original video context by\nutilizing a specialized conditioning scheme to ensure faithful and accurate\nmodifications rather than mere copying. On multiple benchmarks, including a\nchallenging occluded-lip dataset, EdiDub significantly improves identity\npreservation and synchronization. Human evaluations further confirm its\nsuperiority, achieving higher synchronization and visual naturalness scores\ncompared to the leading methods. These results demonstrate that our\ncontent-aware editing approach outperforms traditional generation or\ninpainting, particularly in maintaining complex visual elements while ensuring\naccurate lip synchronization.", "AI": {"tldr": "EdiDub introduces a content-aware editing framework for visual dubbing, outperforming traditional methods by preserving original video context and improving lip synchronization.", "motivation": "Current visual dubbing methods struggle with seamless integration into original scenes and often discard vital visual information, limiting their effectiveness.", "method": "EdiDub reformulates visual dubbing as a content-aware editing task, using a specialized conditioning scheme for faithful modifications.", "result": "EdiDub improves identity preservation and synchronization on benchmarks, including occluded-lip datasets, and scores higher in human evaluations.", "conclusion": "EdiDub's content-aware editing approach outperforms traditional generation or inpainting, maintaining complex visual elements while ensuring accurate lip synchronization."}}
{"id": "2505.23334", "pdf": "https://arxiv.org/pdf/2505.23334", "abs": "https://arxiv.org/abs/2505.23334", "authors": ["Tu Bui", "Mohamed Suliman", "Aparajita Haldar", "Mohammed Amer", "Serban Georgescu"], "title": "X2Graph for Cancer Subtyping Prediction on Biological Tabular Data", "categories": ["cs.LG"], "comment": "IEEE Engineering in Medicine and Biology Society (EMBC) 2025", "summary": "Despite the transformative impact of deep learning on text, audio, and image\ndatasets, its dominance in tabular data, especially in the medical domain where\ndata are often scarce, remains less clear. In this paper, we propose X2Graph, a\nnovel deep learning method that achieves strong performance on small biological\ntabular datasets. X2Graph leverages external knowledge about the relationships\nbetween table columns, such as gene interactions, to convert each sample into a\ngraph structure. This transformation enables the application of standard\nmessage passing algorithms for graph modeling. Our X2Graph method demonstrates\nsuperior performance compared to existing tree-based and deep learning methods\nacross three cancer subtyping datasets.", "AI": {"tldr": "X2Graph is a deep learning method for small biological tabular datasets, converting samples into graphs using external knowledge, outperforming existing methods.", "motivation": "Deep learning's unclear dominance in tabular medical data due to scarcity, prompting a need for effective methods like X2Graph.", "method": "X2Graph transforms tabular data into graphs using column relationships (e.g., gene interactions) and applies message passing algorithms.", "result": "X2Graph outperforms tree-based and deep learning methods on three cancer subtyping datasets.", "conclusion": "X2Graph is effective for small biological tabular datasets, leveraging graph structures for superior performance."}}
{"id": "2505.23548", "pdf": "https://arxiv.org/pdf/2505.23548", "abs": "https://arxiv.org/abs/2505.23548", "authors": ["Yuri Balashov"], "title": "Translation in the Wild", "categories": ["cs.CL"], "comment": "4 figures", "summary": "Large Language Models (LLMs) excel in translation among other things,\ndemonstrating competitive performance for many language pairs in zero- and\nfew-shot settings. But unlike dedicated neural machine translation models, LLMs\nare not trained on any translation-related objective. What explains their\nremarkable translation abilities? Are these abilities grounded in \"incidental\nbilingualism\" (Briakou et al. 2023) in training data? Does instruction tuning\ncontribute to it? Are LLMs capable of aligning and leveraging semantically\nidentical or similar monolingual contents from different corners of the\ninternet that are unlikely to fit in a single context window? I offer some\nreflections on this topic, informed by recent studies and growing user\nexperience. My working hypothesis is that LLMs' translation abilities originate\nin two different types of pre-training data that may be internalized by the\nmodels in different ways. I discuss the prospects for testing the \"duality\"\nhypothesis empirically and its implications for reconceptualizing translation,\nhuman and machine, in the age of deep learning.", "AI": {"tldr": "LLMs show strong translation abilities despite lacking dedicated training, possibly due to incidental bilingualism in data and instruction tuning. A duality hypothesis suggests two types of pre-training data may explain this.", "motivation": "To understand why LLMs perform well in translation tasks without explicit training, exploring the role of data and internalization methods.", "method": "Reflections based on recent studies and user experience, proposing a duality hypothesis for LLMs' translation abilities.", "result": "LLMs' translation skills may stem from incidental bilingualism and instruction tuning, with potential duality in pre-training data.", "conclusion": "The duality hypothesis offers a new perspective on LLM translation, with implications for rethinking translation in the deep learning era."}}
{"id": "2505.23392", "pdf": "https://arxiv.org/pdf/2505.23392", "abs": "https://arxiv.org/abs/2505.23392", "authors": ["Yun-Cheng Tsai"], "title": "Robust and Annotation-Free Wound Segmentation on Noisy Real-World Pressure Ulcer Images: Towards Automated DESIGN-R\\textsuperscript{\\textregistered} Assessment", "categories": ["cs.CV"], "comment": null, "summary": "Purpose: Accurate wound segmentation is essential for automated DESIGN-R\nscoring. However, existing models such as FUSegNet, which are trained primarily\non foot ulcer datasets, often fail to generalize to wounds on other body sites.\n  Methods: We propose an annotation-efficient pipeline that combines a\nlightweight YOLOv11n-based detector with the pre-trained FUSegNet segmentation\nmodel. Instead of relying on pixel-level annotations or retraining for new\nanatomical regions, our method achieves robust performance using only 500\nmanually labeled bounding boxes. This zero fine-tuning approach effectively\nbridges the domain gap and enables direct deployment across diverse wound\ntypes. This is an advance not previously demonstrated in the wound segmentation\nliterature.\n  Results: Evaluated on three real-world test sets spanning foot, sacral, and\ntrochanter wounds, our YOLO plus FUSegNet pipeline improved mean IoU by 23\npercentage points over vanilla FUSegNet and increased end-to-end DESIGN-R size\nestimation accuracy from 71 percent to 94 percent (see Table 3 for details).\n  Conclusion: Our pipeline generalizes effectively across body sites without\ntask-specific fine-tuning, demonstrating that minimal supervision, with 500\nannotated ROIs, is sufficient for scalable, annotation-light wound\nsegmentation. This capability paves the way for real-world DESIGN-R automation,\nreducing reliance on pixel-wise labeling, streamlining documentation workflows,\nand supporting objective and consistent wound scoring in clinical practice. We\nwill publicly release the trained detector weights and configuration to promote\nreproducibility and facilitate downstream deployment.", "AI": {"tldr": "A lightweight YOLOv11n-based detector combined with FUSegNet improves wound segmentation across body sites without fine-tuning, using only 500 bounding boxes.", "motivation": "Existing models like FUSegNet, trained on foot ulcers, fail to generalize to other wounds, necessitating a more adaptable solution.", "method": "Proposes a pipeline combining YOLOv11n for detection and FUSegNet for segmentation, requiring only 500 bounding boxes and no fine-tuning.", "result": "Improved mean IoU by 23 points and DESIGN-R accuracy from 71% to 94% across foot, sacral, and trochanter wounds.", "conclusion": "The method generalizes without fine-tuning, enabling scalable wound segmentation and DESIGN-R automation with minimal supervision."}}
{"id": "2505.23412", "pdf": "https://arxiv.org/pdf/2505.23412", "abs": "https://arxiv.org/abs/2505.23412", "authors": ["Srishti Gupta", "Daniele Angioni", "Maura Pintor", "Ambra Demontis", "Lea Sch\u00f6nherr", "Battista Biggio", "Fabio Roli"], "title": "Buffer-free Class-Incremental Learning with Out-of-Distribution Detection", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Class-incremental learning (CIL) poses significant challenges in open-world\nscenarios, where models must not only learn new classes over time without\nforgetting previous ones but also handle inputs from unknown classes that a\nclosed-set model would misclassify. Recent works address both issues by\n(i)~training multi-head models using the task-incremental learning framework,\nand (ii) predicting the task identity employing out-of-distribution (OOD)\ndetectors. While effective, the latter mainly relies on joint training with a\nmemory buffer of past data, raising concerns around privacy, scalability, and\nincreased training time. In this paper, we present an in-depth analysis of\npost-hoc OOD detection methods and investigate their potential to eliminate the\nneed for a memory buffer. We uncover that these methods, when applied\nappropriately at inference time, can serve as a strong substitute for\nbuffer-based OOD detection. We show that this buffer-free approach achieves\ncomparable or superior performance to buffer-based methods both in terms of\nclass-incremental learning and the rejection of unknown samples. Experimental\nresults on CIFAR-10, CIFAR-100 and Tiny ImageNet datasets support our findings,\noffering new insights into the design of efficient and privacy-preserving CIL\nsystems for open-world settings.", "AI": {"tldr": "The paper explores buffer-free post-hoc OOD detection for class-incremental learning, showing it matches or outperforms buffer-based methods while addressing privacy and scalability concerns.", "motivation": "Address challenges in open-world CIL, particularly privacy and scalability issues from buffer-based OOD detection.", "method": "Analyzes post-hoc OOD detection methods applied at inference time to replace memory buffers.", "result": "Buffer-free OOD detection performs comparably or better than buffer-based methods in CIL and unknown sample rejection.", "conclusion": "Post-hoc OOD detection offers a viable, efficient, and privacy-preserving alternative for open-world CIL systems."}}
{"id": "2505.23345", "pdf": "https://arxiv.org/pdf/2505.23345", "abs": "https://arxiv.org/abs/2505.23345", "authors": ["Yang Liu", "Deyu Bo", "Wenxuan Cao", "Yuan Fang", "Yawen Li", "Chuan Shi"], "title": "Graph Positional Autoencoders as Self-supervised Learners", "categories": ["cs.LG"], "comment": "12 pages, 3 figures, Accepted at KDD 2025", "summary": "Graph self-supervised learning seeks to learn effective graph representations\nwithout relying on labeled data. Among various approaches, graph autoencoders\n(GAEs) have gained significant attention for their efficiency and scalability.\nTypically, GAEs take incomplete graphs as input and predict missing elements,\nsuch as masked nodes or edges. While effective, our experimental investigation\nreveals that traditional node or edge masking paradigms primarily capture\nlow-frequency signals in the graph and fail to learn the expressive structural\ninformation. To address these issues, we propose Graph Positional Autoencoders\n(GraphPAE), which employs a dual-path architecture to reconstruct both node\nfeatures and positions. Specifically, the feature path uses positional encoding\nto enhance the message-passing processing, improving GAE's ability to predict\nthe corrupted information. The position path, on the other hand, leverages node\nrepresentations to refine positions and approximate eigenvectors, thereby\nenabling the encoder to learn diverse frequency information. We conduct\nextensive experiments to verify the effectiveness of GraphPAE, including\nheterophilic node classification, graph property prediction, and transfer\nlearning. The results demonstrate that GraphPAE achieves state-of-the-art\nperformance and consistently outperforms baselines by a large margin.", "AI": {"tldr": "GraphPAE introduces a dual-path architecture for graph self-supervised learning, improving representation by capturing diverse frequency signals.", "motivation": "Traditional graph autoencoders (GAEs) focus on low-frequency signals and miss expressive structural information.", "method": "GraphPAE uses a dual-path architecture: a feature path with positional encoding and a position path refining node positions and eigenvectors.", "result": "GraphPAE achieves state-of-the-art performance in tasks like heterophilic node classification and graph property prediction.", "conclusion": "GraphPAE effectively captures diverse graph information, outperforming traditional GAEs by a large margin."}}
{"id": "2505.23556", "pdf": "https://arxiv.org/pdf/2505.23556", "abs": "https://arxiv.org/abs/2505.23556", "authors": ["Wei Jie Yeo", "Nirmalendu Prakash", "Clement Neo", "Roy Ka-Wei Lee", "Erik Cambria", "Ranjan Satapathy"], "title": "Understanding Refusal in Language Models with Sparse Autoencoders", "categories": ["cs.CL"], "comment": null, "summary": "Refusal is a key safety behavior in aligned language models, yet the internal\nmechanisms driving refusals remain opaque. In this work, we conduct a\nmechanistic study of refusal in instruction-tuned LLMs using sparse\nautoencoders to identify latent features that causally mediate refusal\nbehaviors. We apply our method to two open-source chat models and intervene on\nrefusal-related features to assess their influence on generation, validating\ntheir behavioral impact across multiple harmful datasets. This enables a\nfine-grained inspection of how refusal manifests at the activation level and\naddresses key research questions such as investigating upstream-downstream\nlatent relationship and understanding the mechanisms of adversarial\njailbreaking techniques. We also establish the usefulness of refusal features\nin enhancing generalization for linear probes to out-of-distribution\nadversarial samples in classification tasks. We open source our code in\nhttps://github.com/wj210/refusal_sae.", "AI": {"tldr": "The paper investigates the internal mechanisms of refusal behaviors in aligned language models using sparse autoencoders to identify and intervene on refusal-related features.", "motivation": "To understand the opaque internal mechanisms driving refusal behaviors in instruction-tuned LLMs and explore their causal mediation.", "method": "Uses sparse autoencoders to identify latent refusal features, intervenes on these features, and validates their impact across harmful datasets.", "result": "Identifies refusal-related features, validates their behavioral influence, and demonstrates their utility in enhancing generalization for adversarial samples.", "conclusion": "Provides insights into refusal mechanisms, adversarial jailbreaking, and shows practical applications for improving model robustness."}}
{"id": "2505.23395", "pdf": "https://arxiv.org/pdf/2505.23395", "abs": "https://arxiv.org/abs/2505.23395", "authors": ["Xingguang Wei", "Haomin Wang", "Shenglong Ye", "Ruifeng Luo", "Yanting Zhang", "Lixin Gu", "Jifeng Dai", "Yu Qiao", "Wenhai Wang", "Hongjie Zhang"], "title": "Point or Line? Using Line-based Representation for Panoptic Symbol Spotting in CAD Drawings", "categories": ["cs.CV"], "comment": null, "summary": "We study the task of panoptic symbol spotting, which involves identifying\nboth individual instances of countable things and the semantic regions of\nuncountable stuff in computer-aided design (CAD) drawings composed of vector\ngraphical primitives. Existing methods typically rely on image rasterization,\ngraph construction, or point-based representation, but these approaches often\nsuffer from high computational costs, limited generality, and loss of geometric\nstructural information. In this paper, we propose VecFormer, a novel method\nthat addresses these challenges through line-based representation of\nprimitives. This design preserves the geometric continuity of the original\nprimitive, enabling more accurate shape representation while maintaining a\ncomputation-friendly structure, making it well-suited for vector graphic\nunderstanding tasks. To further enhance prediction reliability, we introduce a\nBranch Fusion Refinement module that effectively integrates instance and\nsemantic predictions, resolving their inconsistencies for more coherent\npanoptic outputs. Extensive experiments demonstrate that our method establishes\na new state-of-the-art, achieving 91.1 PQ, with Stuff-PQ improved by 9.6 and\n21.2 points over the second-best results under settings with and without prior\ninformation, respectively, highlighting the strong potential of line-based\nrepresentation as a foundation for vector graphic understanding.", "AI": {"tldr": "VecFormer introduces a line-based representation for panoptic symbol spotting in CAD drawings, improving accuracy and computational efficiency.", "motivation": "Existing methods for panoptic symbol spotting in CAD drawings suffer from high computational costs, limited generality, and loss of geometric information.", "method": "VecFormer uses line-based representation of primitives and a Branch Fusion Refinement module to integrate instance and semantic predictions.", "result": "Achieves 91.1 PQ, with Stuff-PQ improved by 9.6 and 21.2 points over second-best results.", "conclusion": "Line-based representation shows strong potential for vector graphic understanding."}}
{"id": "2505.23415", "pdf": "https://arxiv.org/pdf/2505.23415", "abs": "https://arxiv.org/abs/2505.23415", "authors": ["Gaspard Oliviers", "Mufeng Tang", "Rafal Bogacz"], "title": "Bidirectional predictive coding", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Predictive coding (PC) is an influential computational model of visual\nlearning and inference in the brain. Classical PC was proposed as a top-down\ngenerative model, where the brain actively predicts upcoming visual inputs, and\ninference minimises the prediction errors. Recent studies have also shown that\nPC can be formulated as a discriminative model, where sensory inputs predict\nneural activities in a feedforward manner. However, experimental evidence\nsuggests that the brain employs both generative and discriminative inference,\nwhile unidirectional PC models show degraded performance in tasks requiring\nbidirectional processing. In this work, we propose bidirectional PC (bPC), a PC\nmodel that incorporates both generative and discriminative inference while\nmaintaining a biologically plausible circuit implementation. We show that bPC\nmatches or outperforms unidirectional models in their specialised generative or\ndiscriminative tasks, by developing an energy landscape that simultaneously\nsuits both tasks. We also demonstrate bPC's superior performance in two\nbiologically relevant tasks including multimodal learning and inference with\nmissing information, suggesting that bPC resembles biological visual inference\nmore closely.", "AI": {"tldr": "The paper proposes bidirectional predictive coding (bPC), combining generative and discriminative inference, outperforming unidirectional models and better resembling biological visual processing.", "motivation": "Existing unidirectional PC models lack the bidirectional processing seen in the brain, limiting performance in tasks requiring both generative and discriminative inference.", "method": "Developed bPC, a model integrating both generative and discriminative inference, with a biologically plausible circuit and an energy landscape optimized for both tasks.", "result": "bPC matches or outperforms unidirectional models in specialized tasks and excels in multimodal learning and inference with missing information.", "conclusion": "bPC more closely mimics biological visual inference, suggesting its potential for understanding brain processes and improving computational models."}}
{"id": "2505.23347", "pdf": "https://arxiv.org/pdf/2505.23347", "abs": "https://arxiv.org/abs/2505.23347", "authors": ["Yuting Li", "Shaoyuan Huang", "Tengwen Zhang", "Cheng Zhang", "Xiaofei Wang", "Victor C. M. Leung"], "title": "Sentinel: Scheduling Live Streams with Proactive Anomaly Detection in Crowdsourced Cloud-Edge Platforms", "categories": ["cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2402.14619", "summary": "With the rapid growth of live streaming services, Crowdsourced Cloud-edge\nservice Platforms (CCPs) are playing an increasingly important role in meeting\nthe increasing demand. Although stream scheduling plays a critical role in\noptimizing CCPs' revenue, most optimization strategies struggle to achieve\npractical results due to various anomalies in unstable CCPs. Additionally, the\nsubstantial scale of CCPs magnifies the difficulties of anomaly detection in\ntime-sensitive scheduling. To tackle these challenges, this paper proposes\nSentinel, a proactive anomaly detection-based scheduling framework. Sentinel\nmodels the scheduling process as a two-stage Pre-Post-Scheduling paradigm: in\nthe pre-scheduling stage, Sentinel conducts anomaly detection and constructs a\nstrategy pool; in the post-scheduling stage, upon request arrival, it triggers\nan appropriate scheduling based on a pre-generated strategy to implement the\nscheduling process. Extensive experiments on realistic datasets show that\nSentinel significantly reduces anomaly frequency by 70%, improves revenue by\n74%, and doubles the scheduling speed.", "AI": {"tldr": "Sentinel is a proactive anomaly detection-based scheduling framework for CCPs, reducing anomalies by 70%, boosting revenue by 74%, and doubling scheduling speed.", "motivation": "Address challenges in optimizing CCPs' revenue due to anomalies and unstable environments, requiring efficient, time-sensitive scheduling.", "method": "Two-stage Pre-Post-Scheduling paradigm: anomaly detection and strategy pool in pre-scheduling; triggered scheduling in post-scheduling.", "result": "70% anomaly reduction, 74% revenue improvement, and doubled scheduling speed.", "conclusion": "Sentinel effectively enhances CCP performance by proactively addressing anomalies and optimizing scheduling."}}
{"id": "2505.23570", "pdf": "https://arxiv.org/pdf/2505.23570", "abs": "https://arxiv.org/abs/2505.23570", "authors": ["Leonardo La Rocca", "Francesco Corso", "Francesco Pierri"], "title": "Evaluating AI capabilities in detecting conspiracy theories on YouTube", "categories": ["cs.CL", "cs.CY", "cs.SI"], "comment": "Submitted for review to OSNEM Special Issue of April 2025", "summary": "As a leading online platform with a vast global audience, YouTube's extensive\nreach also makes it susceptible to hosting harmful content, including\ndisinformation and conspiracy theories. This study explores the use of\nopen-weight Large Language Models (LLMs), both text-only and multimodal, for\nidentifying conspiracy theory videos shared on YouTube. Leveraging a labeled\ndataset of thousands of videos, we evaluate a variety of LLMs in a zero-shot\nsetting and compare their performance to a fine-tuned RoBERTa baseline. Results\nshow that text-based LLMs achieve high recall but lower precision, leading to\nincreased false positives. Multimodal models lag behind their text-only\ncounterparts, indicating limited benefits from visual data integration. To\nassess real-world applicability, we evaluate the most accurate models on an\nunlabeled dataset, finding that RoBERTa achieves performance close to LLMs with\na larger number of parameters. Our work highlights the strengths and\nlimitations of current LLM-based approaches for online harmful content\ndetection, emphasizing the need for more precise and robust systems.", "AI": {"tldr": "The study evaluates open-weight LLMs for detecting conspiracy theory videos on YouTube, finding text-based models achieve high recall but lower precision, while multimodal models underperform. RoBERTa matches LLM performance with fewer parameters.", "motivation": "YouTube's global reach makes it prone to harmful content like disinformation. The study aims to assess LLMs' effectiveness in identifying such content.", "method": "The study uses labeled and unlabeled datasets to evaluate text-only and multimodal LLMs in zero-shot settings, comparing them to a fine-tuned RoBERTa baseline.", "result": "Text-based LLMs show high recall but low precision, increasing false positives. Multimodal models perform worse. RoBERTa matches LLMs with fewer parameters.", "conclusion": "Current LLM-based approaches for harmful content detection have limitations, highlighting the need for more precise and robust systems."}}
{"id": "2505.23400", "pdf": "https://arxiv.org/pdf/2505.23400", "abs": "https://arxiv.org/abs/2505.23400", "authors": ["Sanggyun Ma", "Wonjoon Choi", "Jihun Park", "Jaeyeul Kim", "Seunghun Lee", "Jiwan Seo", "Sunghoon Im"], "title": "Bridging Geometric and Semantic Foundation Models for Generalized Monocular Depth Estimation", "categories": ["cs.CV"], "comment": null, "summary": "We present Bridging Geometric and Semantic (BriGeS), an effective method that\nfuses geometric and semantic information within foundation models to enhance\nMonocular Depth Estimation (MDE). Central to BriGeS is the Bridging Gate, which\nintegrates the complementary strengths of depth and segmentation foundation\nmodels. This integration is further refined by our Attention Temperature\nScaling technique. It finely adjusts the focus of the attention mechanisms to\nprevent over-concentration on specific features, thus ensuring balanced\nperformance across diverse inputs. BriGeS capitalizes on pre-trained foundation\nmodels and adopts a strategy that focuses on training only the Bridging Gate.\nThis method significantly reduces resource demands and training time while\nmaintaining the model's ability to generalize effectively. Extensive\nexperiments across multiple challenging datasets demonstrate that BriGeS\noutperforms state-of-the-art methods in MDE for complex scenes, effectively\nhandling intricate structures and overlapping objects.", "AI": {"tldr": "BriGeS integrates geometric and semantic info via a Bridging Gate and Attention Temperature Scaling, enhancing Monocular Depth Estimation with reduced training demands.", "motivation": "To improve Monocular Depth Estimation by combining geometric and semantic strengths from foundation models, addressing challenges like complex scenes and overlapping objects.", "method": "Uses a Bridging Gate to fuse depth and segmentation models, refined by Attention Temperature Scaling. Focuses on training only the Bridging Gate to save resources.", "result": "Outperforms state-of-the-art methods in complex scenes, handling intricate structures and overlaps effectively.", "conclusion": "BriGeS is a resource-efficient, high-performing solution for Monocular Depth Estimation by leveraging foundation models."}}
{"id": "2505.23417", "pdf": "https://arxiv.org/pdf/2505.23417", "abs": "https://arxiv.org/abs/2505.23417", "authors": ["Danilo Ribeiro", "Thayssa Rocha", "Gustavo Pinto", "Bruno Cartaxo", "Marcelo Amaral", "Nicole Davila", "Ana Camargo"], "title": "Toward Effective AI Governance: A Review of Principles", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Artificial Intelligence (AI) governance is the practice of establishing\nframeworks, policies, and procedures to ensure the responsible, ethical, and\nsafe development and deployment of AI systems. Although AI governance is a core\npillar of Responsible AI, current literature still lacks synthesis across such\ngovernance frameworks and practices. Objective: To identify which frameworks,\nprinciples, mechanisms, and stakeholder roles are emphasized in secondary\nliterature on AI governance. Method: We conducted a rapid tertiary review of\nnine peer-reviewed secondary studies from IEEE and ACM (20202024), using\nstructured inclusion criteria and thematic semantic synthesis. Results: The\nmost cited frameworks include the EU AI Act and NIST RMF; transparency and\naccountability are the most common principles. Few reviews detail actionable\ngovernance mechanisms or stakeholder strategies. Conclusion: The review\nconsolidates key directions in AI governance and highlights gaps in empirical\nvalidation and inclusivity. Findings inform both academic inquiry and practical\nadoption in organizations.", "AI": {"tldr": "The paper synthesizes AI governance frameworks from secondary literature, identifying key frameworks, principles, and gaps.", "motivation": "To address the lack of synthesis in AI governance literature and highlight key frameworks and gaps.", "method": "A rapid tertiary review of nine peer-reviewed secondary studies (2020-2024) using structured criteria and thematic synthesis.", "result": "Most cited frameworks are the EU AI Act and NIST RMF; transparency and accountability are common principles. Gaps include actionable mechanisms and stakeholder strategies.", "conclusion": "The review consolidates AI governance directions and identifies gaps, aiding both research and practical adoption."}}
{"id": "2505.23355", "pdf": "https://arxiv.org/pdf/2505.23355", "abs": "https://arxiv.org/abs/2505.23355", "authors": ["Maxiu Xiao", "Jianglin Lan", "Jingxing Yu", "Eldert van Henten", "Congcong Sun"], "title": "Grower-in-the-Loop Interactive Reinforcement Learning for Greenhouse Climate Control", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Climate control is crucial for greenhouse production as it directly affects\ncrop growth and resource use. Reinforcement learning (RL) has received\nincreasing attention in this field, but still faces challenges, including\nlimited training efficiency and high reliance on initial learning conditions.\nInteractive RL, which combines human (grower) input with the RL agent's\nlearning, offers a potential solution to overcome these challenges. However,\ninteractive RL has not yet been applied to greenhouse climate control and may\nface challenges related to imperfect inputs. Therefore, this paper aims to\nexplore the possibility and performance of applying interactive RL with\nimperfect inputs into greenhouse climate control, by: (1) developing three\nrepresentative interactive RL algorithms tailored for greenhouse climate\ncontrol (reward shaping, policy shaping and control sharing); (2) analyzing how\ninput characteristics are often contradicting, and how the trade-offs between\nthem make grower's inputs difficult to perfect; (3) proposing a neural\nnetwork-based approach to enhance the robustness of interactive RL agents under\nlimited input availability; (4) conducting a comprehensive evaluation of the\nthree interactive RL algorithms with imperfect inputs in a simulated greenhouse\nenvironment. The demonstration shows that interactive RL incorporating\nimperfect grower inputs has the potential to improve the performance of the RL\nagent. RL algorithms that influence action selection, such as policy shaping\nand control sharing, perform better when dealing with imperfect inputs,\nachieving 8.4% and 6.8% improvement in profit, respectively. In contrast,\nreward shaping, an algorithm that manipulates the reward function, is sensitive\nto imperfect inputs and leads to a 9.4% decrease in profit. This highlights the\nimportance of selecting an appropriate mechanism when incorporating imperfect\ninputs.", "AI": {"tldr": "The paper explores interactive reinforcement learning (RL) for greenhouse climate control, addressing challenges like imperfect grower inputs. It develops three algorithms, evaluates their performance, and finds policy shaping and control sharing outperform reward shaping.", "motivation": "Climate control in greenhouses is vital for crop growth, but traditional RL faces inefficiency and dependency on initial conditions. Interactive RL, combining human input with RL, could mitigate these issues, though imperfect inputs pose challenges.", "method": "The study develops three interactive RL algorithms (reward shaping, policy shaping, control sharing), analyzes input trade-offs, proposes a neural network for robustness, and evaluates them in a simulated greenhouse.", "result": "Policy shaping and control sharing improve profit by 8.4% and 6.8%, respectively, while reward shaping reduces profit by 9.4% due to sensitivity to imperfect inputs.", "conclusion": "Interactive RL with imperfect inputs can enhance greenhouse climate control, but algorithm choice is critical. Policy shaping and control sharing are more robust than reward shaping."}}
{"id": "2505.23604", "pdf": "https://arxiv.org/pdf/2505.23604", "abs": "https://arxiv.org/abs/2505.23604", "authors": ["Guangtao Zeng", "Maohao Shen", "Delin Chen", "Zhenting Qi", "Subhro Das", "Dan Gutfreund", "David Cox", "Gregory Wornell", "Wei Lu", "Zhang-Wei Hong", "Chuang Gan"], "title": "Satori-SWE: Evolutionary Test-Time Scaling for Sample-Efficient Software Engineering", "categories": ["cs.CL", "cs.AI", "cs.SE"], "comment": null, "summary": "Language models (LMs) perform well on standardized coding benchmarks but\nstruggle with real-world software engineering tasks such as resolving GitHub\nissues in SWE-Bench, especially when model parameters are less than 100B. While\nsmaller models are preferable in practice due to their lower computational\ncost, improving their performance remains challenging. Existing approaches\nprimarily rely on supervised fine-tuning (SFT) with high-quality data, which is\nexpensive to curate at scale. An alternative is test-time scaling: generating\nmultiple outputs, scoring them using a verifier, and selecting the best one.\nAlthough effective, this strategy often requires excessive sampling and costly\nscoring, limiting its practical application. We propose Evolutionary Test-Time\nScaling (EvoScale), a sample-efficient method that treats generation as an\nevolutionary process. By iteratively refining outputs via selection and\nmutation, EvoScale shifts the output distribution toward higher-scoring\nregions, reducing the number of samples needed to find correct solutions. To\nreduce the overhead from repeatedly sampling and selection, we train the model\nto self-evolve using reinforcement learning (RL). Rather than relying on\nexternal verifiers at inference time, the model learns to self-improve the\nscores of its own generations across iterations. Evaluated on\nSWE-Bench-Verified, EvoScale enables our 32B model, Satori-SWE-32B, to match or\nexceed the performance of models with over 100B parameters while using a few\nsamples. Code, data, and models will be fully open-sourced.", "AI": {"tldr": "EvoScale improves smaller LMs' performance on real-world coding tasks by using evolutionary refinement and RL, reducing sample needs and matching larger models' results.", "motivation": "Smaller LMs struggle with real-world coding tasks despite lower computational costs, and existing methods like SFT or test-time scaling are expensive or inefficient.", "method": "Proposes EvoScale, an evolutionary process with RL for iterative refinement, reducing samples and avoiding external verifiers.", "result": "EvoScale enables a 32B model to perform as well as 100B+ models on SWE-Bench-Verified with fewer samples.", "conclusion": "EvoScale offers a sample-efficient, scalable solution for improving smaller LMs' performance on complex tasks."}}
{"id": "2505.23434", "pdf": "https://arxiv.org/pdf/2505.23434", "abs": "https://arxiv.org/abs/2505.23434", "authors": ["Tianhang Wang", "Fan Lu", "Sanqing Qu", "Guo Yu", "Shihang Du", "Ya Wu", "Yuan Huang", "Guang Chen"], "title": "UrbanCraft: Urban View Extrapolation via Hierarchical Sem-Geometric Priors", "categories": ["cs.CV"], "comment": null, "summary": "Existing neural rendering-based urban scene reconstruction methods mainly\nfocus on the Interpolated View Synthesis (IVS) setting that synthesizes from\nviews close to training camera trajectory. However, IVS can not guarantee the\non-par performance of the novel view outside the training camera distribution\n(\\textit{e.g.}, looking left, right, or downwards), which limits the\ngeneralizability of the urban reconstruction application. Previous methods have\noptimized it via image diffusion, but they fail to handle text-ambiguous or\nlarge unseen view angles due to coarse-grained control of text-only diffusion.\nIn this paper, we design UrbanCraft, which surmounts the Extrapolated View\nSynthesis (EVS) problem using hierarchical sem-geometric representations\nserving as additional priors. Specifically, we leverage the partially\nobservable scene to reconstruct coarse semantic and geometric primitives,\nestablishing a coarse scene-level prior through an occupancy grid as the base\nrepresentation. Additionally, we incorporate fine instance-level priors from 3D\nbounding boxes to enhance object-level details and spatial relationships.\nBuilding on this, we propose the \\textbf{H}ierarchical\n\\textbf{S}emantic-Geometric-\\textbf{G}uided Variational Score Distillation\n(HSG-VSD), which integrates semantic and geometric constraints from pretrained\nUrbanCraft2D into the score distillation sampling process, forcing the\ndistribution to be consistent with the observable scene. Qualitative and\nquantitative comparisons demonstrate the effectiveness of our methods on EVS\nproblem.", "AI": {"tldr": "UrbanCraft addresses Extrapolated View Synthesis (EVS) by using hierarchical sem-geometric representations and HSG-VSD for improved generalization beyond training camera views.", "motivation": "Existing methods struggle with novel views outside training distributions, limiting urban reconstruction applications.", "method": "UrbanCraft employs coarse semantic-geometric priors and fine instance-level details, enhanced by HSG-VSD for consistency.", "result": "The method shows effectiveness in EVS through qualitative and quantitative comparisons.", "conclusion": "UrbanCraft improves generalization for urban scene reconstruction by integrating hierarchical priors and semantic-geometric constraints."}}
{"id": "2505.23419", "pdf": "https://arxiv.org/pdf/2505.23419", "abs": "https://arxiv.org/abs/2505.23419", "authors": ["Linghao Zhang", "Shilin He", "Chaoyun Zhang", "Yu Kang", "Bowen Li", "Chengxing Xie", "Junhao Wang", "Maoquan Wang", "Yufan Huang", "Shengyu Fu", "Elsie Nallipogu", "Qingwei Lin", "Yingnong Dang", "Saravan Rajmohan", "Dongmei Zhang"], "title": "SWE-bench Goes Live!", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": "Homepage: \\url{https://swe-bench-live.github.io/}, Code:\n  \\url{https://github.com/SWE-bench-Live}, Dataset:\n  \\url{https://huggingface.co/SWE-bench-Live}", "summary": "The issue-resolving task, where a model generates patches to fix real-world\nbugs, has emerged as a critical benchmark for evaluating the capabilities of\nlarge language models (LLMs). While SWE-bench and its variants have become\nstandard in this domain, they suffer from key limitations: they have not been\nupdated since their initial releases, cover a narrow set of repositories, and\ndepend heavily on manual effort for instance construction and environment\nsetup. These factors hinder scalability and introduce risks of overfitting and\ndata contamination. In this work, we present \\textbf{SWE-bench-Live}, a\n\\textit{live-updatable} benchmark designed to overcome these challenges. Our\ninitial release consists of 1,319 tasks derived from real GitHub issues created\nsince 2024, spanning 93 repositories. Each task is accompanied by a dedicated\nDocker image to ensure reproducible execution. Central to our benchmark is\n\\method, an automated curation pipeline that streamlines the entire process\nfrom instance creation to environment setup, removing manual bottlenecks and\nenabling scalability and continuous updates. We evaluate a range of\nstate-of-the-art agent frameworks and LLMs on SWE-bench-Live, revealing a\nsubstantial performance gap compared to static benchmarks like SWE-bench, even\nunder controlled evaluation conditions. To better understand this discrepancy,\nwe perform detailed analyses across repository origin, issue recency, and task\ndifficulty. By providing a fresh, diverse, and executable benchmark grounded in\nlive repository activity, SWE-bench-Live facilitates rigorous,\ncontamination-resistant evaluation of LLMs and agents in dynamic, real-world\nsoftware development settings.", "AI": {"tldr": "SWE-bench-Live is introduced as a live-updatable benchmark to address limitations of static benchmarks like SWE-bench, offering scalable, reproducible tasks from recent GitHub issues.", "motivation": "Static benchmarks like SWE-bench are outdated, narrow in scope, and manually intensive, hindering scalability and risking overfitting. SWE-bench-Live aims to overcome these issues.", "method": "SWE-bench-Live uses an automated curation pipeline to create tasks from real GitHub issues (1,319 tasks from 93 repositories) and provides Docker images for reproducibility.", "result": "Evaluations show a performance gap between models on SWE-bench-Live and static benchmarks, even under controlled conditions.", "conclusion": "SWE-bench-Live enables rigorous, contamination-resistant evaluation of LLMs in dynamic software development settings."}}
{"id": "2505.23378", "pdf": "https://arxiv.org/pdf/2505.23378", "abs": "https://arxiv.org/abs/2505.23378", "authors": ["Roseline Polle", "Agnes Norbury", "Alexandra Livia Georgescu", "Nicholas Cummins", "Stefano Goria"], "title": "Meta-Learning Approaches for Speaker-Dependent Voice Fatigue Models", "categories": ["cs.LG"], "comment": "5 pages, 3 figures. To appear at Interspeech 2025", "summary": "Speaker-dependent modelling can substantially improve performance in\nspeech-based health monitoring applications. While mixed-effect models are\ncommonly used for such speaker adaptation, they require computationally\nexpensive retraining for each new observation, making them impractical in a\nproduction environment. We reformulate this task as a meta-learning problem and\nexplore three approaches of increasing complexity: ensemble-based distance\nmodels, prototypical networks, and transformer-based sequence models. Using\npre-trained speech embeddings, we evaluate these methods on a large\nlongitudinal dataset of shift workers (N=1,185, 10,286 recordings), predicting\ntime since sleep from speech as a function of fatigue, a symptom commonly\nassociated with ill-health. Our results demonstrate that all meta-learning\napproaches tested outperformed both cross-sectional and conventional\nmixed-effects models, with a transformer-based method achieving the strongest\nperformance.", "AI": {"tldr": "Meta-learning approaches outperform traditional mixed-effect models in speaker-dependent speech-based health monitoring, with transformers achieving the best results.", "motivation": "Speaker-dependent modeling improves health monitoring via speech, but traditional mixed-effect models are computationally impractical for real-time use.", "method": "Three meta-learning methods (ensemble-based distance models, prototypical networks, transformer-based sequence models) were tested using pre-trained speech embeddings on a longitudinal dataset.", "result": "All meta-learning methods outperformed cross-sectional and mixed-effects models, with transformers showing the strongest performance.", "conclusion": "Meta-learning, especially transformer-based methods, is a promising alternative to traditional speaker adaptation techniques in speech-based health monitoring."}}
{"id": "2505.23621", "pdf": "https://arxiv.org/pdf/2505.23621", "abs": "https://arxiv.org/abs/2505.23621", "authors": ["Zheyuan Yang", "Lyuhao Chen", "Arman Cohan", "Yilun Zhao"], "title": "Table-R1: Inference-Time Scaling for Table Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "In this work, we present the first study to explore inference-time scaling on\ntable reasoning tasks. We develop and evaluate two post-training strategies to\nenable inference-time scaling: distillation from frontier model reasoning\ntraces and reinforcement learning with verifiable rewards (RLVR). For\ndistillation, we introduce a large-scale dataset of reasoning traces generated\nby DeepSeek-R1, which we use to fine-tune LLMs into the Table-R1-SFT model. For\nRLVR, we propose task-specific verifiable reward functions and apply the GRPO\nalgorithm to obtain the Table-R1-Zero model. We evaluate our Table-R1-series\nmodels across diverse table reasoning tasks, including short-form QA, fact\nverification, and free-form QA. Notably, the Table-R1-Zero model matches or\nexceeds the performance of GPT-4.1 and DeepSeek-R1, while using only a\n7B-parameter LLM. It also demonstrates strong generalization to out-of-domain\ndatasets. Extensive ablation and qualitative analyses reveal the benefits of\ninstruction tuning, model architecture choices, and cross-task generalization,\nas well as emergence of essential table reasoning skills during RL training.", "AI": {"tldr": "The paper introduces inference-time scaling for table reasoning tasks using distillation and RLVR, achieving GPT-4.1-level performance with a smaller 7B-parameter model.", "motivation": "To explore and improve inference-time scaling for table reasoning tasks, addressing the need for efficient and high-performing models.", "method": "Develops two strategies: distillation using reasoning traces from DeepSeek-R1 (Table-R1-SFT) and RL with verifiable rewards (RLVR) leading to Table-R1-Zero.", "result": "Table-R1-Zero matches/exceeds GPT-4.1 and DeepSeek-R1 performance on diverse tasks, with strong out-of-domain generalization.", "conclusion": "Instruction tuning, model architecture, and RL training enhance table reasoning skills, demonstrating the effectiveness of the proposed methods."}}
{"id": "2505.23438", "pdf": "https://arxiv.org/pdf/2505.23438", "abs": "https://arxiv.org/abs/2505.23438", "authors": ["Lingyan Ran", "Yali Li", "Tao Zhuo", "Shizhou Zhang", "Yanning Zhang"], "title": "Adaptive Spatial Augmentation for Semi-supervised Semantic Segmentation", "categories": ["cs.CV"], "comment": "10 pages, 8 figures", "summary": "In semi-supervised semantic segmentation (SSSS), data augmentation plays a\ncrucial role in the weak-to-strong consistency regularization framework, as it\nenhances diversity and improves model generalization. Recent strong\naugmentation methods have primarily focused on intensity-based perturbations,\nwhich have minimal impact on the semantic masks. In contrast, spatial\naugmentations like translation and rotation have long been acknowledged for\ntheir effectiveness in supervised semantic segmentation tasks, but they are\noften ignored in SSSS. In this work, we demonstrate that spatial augmentation\ncan also contribute to model training in SSSS, despite generating inconsistent\nmasks between the weak and strong augmentations. Furthermore, recognizing the\nvariability among images, we propose an adaptive augmentation strategy that\ndynamically adjusts the augmentation for each instance based on entropy.\nExtensive experiments show that our proposed Adaptive Spatial Augmentation\n(\\textbf{ASAug}) can be integrated as a pluggable module, consistently\nimproving the performance of existing methods and achieving state-of-the-art\nresults on benchmark datasets such as PASCAL VOC 2012, Cityscapes, and COCO.", "AI": {"tldr": "Spatial augmentation in semi-supervised semantic segmentation improves performance, and an adaptive strategy (ASAug) further enhances results.", "motivation": "Existing strong augmentation methods focus on intensity-based perturbations, neglecting spatial augmentations despite their proven effectiveness in supervised tasks.", "method": "Proposes Adaptive Spatial Augmentation (ASAug), which dynamically adjusts augmentations per instance based on entropy.", "result": "ASAug improves performance of existing methods and achieves state-of-the-art results on PASCAL VOC 2012, Cityscapes, and COCO.", "conclusion": "Spatial augmentations are effective in SSSS, and ASAug is a versatile, pluggable solution for enhancing model performance."}}
{"id": "2505.23422", "pdf": "https://arxiv.org/pdf/2505.23422", "abs": "https://arxiv.org/abs/2505.23422", "authors": ["Tobias Lindenbauer", "Georg Groh", "Hinrich Sch\u00fctze"], "title": "From Knowledge to Noise: CTIM-Rover and the Pitfalls of Episodic Memory in Software Engineering Agents", "categories": ["cs.SE", "cs.AI"], "comment": "Short Paper, REALM '25 camera-ready", "summary": "We introduce CTIM-Rover, an AI agent for Software Engineering (SE) built on\ntop of AutoCodeRover (Zhang et al., 2024) that extends agentic reasoning\nframeworks with an episodic memory, more specifically, a general and\nrepository-level Cross-Task-Instance Memory (CTIM). While existing open-source\nSE agents mostly rely on ReAct (Yao et al., 2023b), Reflexion (Shinn et al.,\n2023), or Code-Act (Wang et al., 2024), all of these reasoning and planning\nframeworks inefficiently discard their long-term memory after a single task\ninstance. As repository-level understanding is pivotal for identifying all\nlocations requiring a patch for fixing a bug, we hypothesize that SE is\nparticularly well positioned to benefit from CTIM. For this, we build on the\nExperiential Learning (EL) approach ExpeL (Zhao et al., 2024), proposing a\nMixture-Of-Experts (MoEs) inspired approach to create both a general-purpose\nand repository-level CTIM. We find that CTIM-Rover does not outperform\nAutoCodeRover in any configuration and thus conclude that neither ExpeL nor\nDoT-Bank (Lingam et al., 2024) scale to real-world SE problems. Our analysis\nindicates noise introduced by distracting CTIM items or exemplar trajectories\nas the likely source of the performance degradation.", "AI": {"tldr": "CTIM-Rover, an AI agent for SE with episodic memory (CTIM), underperforms AutoCodeRover due to noise from distracting CTIM items.", "motivation": "Existing SE agents discard long-term memory after tasks, missing repository-level understanding for bug fixes.", "method": "Extends AutoCodeRover with CTIM, using ExpeL and MoEs for general and repository-level memory.", "result": "CTIM-Rover does not outperform AutoCodeRover, with noise from CTIM items degrading performance.", "conclusion": "ExpeL and DoT-Bank do not scale to real-world SE problems due to noise in CTIM."}}
{"id": "2505.23383", "pdf": "https://arxiv.org/pdf/2505.23383", "abs": "https://arxiv.org/abs/2505.23383", "authors": ["Ahmad Anaqreh", "Shih-Kai Chou", "Mihael Mohor\u010di\u010d", "Carolina Fortuna"], "title": "Automated Modeling Method for Pathloss Model Discovery", "categories": ["cs.LG"], "comment": null, "summary": "Modeling propagation is the cornerstone for designing and optimizing\nnext-generation wireless systems, with a particular emphasis on 5G and beyond\nera. Traditional modeling methods have long relied on statistic-based\ntechniques to characterize propagation behavior across different environments.\nWith the expansion of wireless communication systems, there is a growing demand\nfor methods that guarantee the accuracy and interoperability of modeling.\nArtificial intelligence (AI)-based techniques, in particular, are increasingly\nbeing adopted to overcome this challenge, although the interpretability is not\nassured with most of these methods. Inspired by recent advancements in AI, this\npaper proposes a novel approach that accelerates the discovery of path loss\nmodels while maintaining interpretability. The proposed method automates the\nmodel formulation, evaluation, and refinement, facilitating model discovery. We\nevaluate two techniques: one based on Deep Symbolic Regression, offering full\ninterpretability, and the second based on Kolmogorov-Arnold Networks, providing\ntwo levels of interpretability. Both approaches are evaluated on two synthetic\nand two real-world datasets. Our results show that Kolmogorov-Arnold Networks\nachieve R^2 values close to 1 with minimal prediction error, while Deep\nSymbolic Regression generates compact models with moderate accuracy. Moreover,\non the selected examples, we demonstrate that automated methods outperform\ntraditional methods, achieving up to 75% reduction in prediction errors,\noffering accurate and explainable solutions with potential to increase the\nefficiency of discovering next-generation path loss models.", "AI": {"tldr": "The paper introduces AI-based methods for modeling wireless propagation, focusing on interpretability and accuracy, outperforming traditional techniques.", "motivation": "The need for accurate and interpretable propagation models in next-gen wireless systems (5G and beyond) drives the adoption of AI-based techniques.", "method": "Proposes two AI-based techniques: Deep Symbolic Regression (interpretable) and Kolmogorov-Arnold Networks (two-level interpretability), evaluated on synthetic and real-world datasets.", "result": "Kolmogorov-Arnold Networks achieve high accuracy (R^2 \u2248 1), while Deep Symbolic Regression offers compact models. Automated methods reduce prediction errors by up to 75%.", "conclusion": "AI-based methods provide accurate, interpretable, and efficient solutions for next-generation path loss modeling, surpassing traditional approaches."}}
{"id": "2505.23623", "pdf": "https://arxiv.org/pdf/2505.23623", "abs": "https://arxiv.org/abs/2505.23623", "authors": ["Jiaoda Li", "Ryan Cotterell"], "title": "Characterizing the Expressivity of Transformer Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Transformer-based language models (LMs) have achieved widespread empirical\nsuccess, but their theoretical expressive power remains only partially\nunderstood. Prior work often relies on idealized models with assumptions --\nsuch as arbitrary numerical precision and hard attention -- that diverge from\nreal-world transformers. In this work, we provide an exact characterization of\nfixed-precision transformers with strict future masking and soft attention, an\nidealization that more closely mirrors practical implementations. We show that\nthese models are precisely as expressive as a specific fragment of linear\ntemporal logic that includes only a single temporal operator: the past\noperator. We further relate this logic to established classes in formal\nlanguage theory, automata theory, and algebra, yielding a rich and unified\ntheoretical framework for understanding transformer expressivity. Finally, we\npresent empirical results that align closely with our theory: transformers\ntrained on languages within their theoretical capacity generalize perfectly\nover lengths, while they consistently fail to generalize on languages beyond\nit.", "AI": {"tldr": "The paper characterizes the expressive power of fixed-precision transformers with soft attention, linking them to a fragment of linear temporal logic and formal language theory.", "motivation": "To bridge the gap between idealized transformer models and practical implementations by analyzing their theoretical expressivity.", "method": "Theoretical analysis of fixed-precision transformers with strict future masking and soft attention, connecting them to linear temporal logic and formal language theory.", "result": "Such transformers are as expressive as a specific fragment of linear temporal logic (past operator) and align with formal language classes. Empirical results confirm perfect generalization within their capacity.", "conclusion": "The study provides a unified theoretical framework for transformer expressivity, validated by empirical evidence."}}
{"id": "2505.23439", "pdf": "https://arxiv.org/pdf/2505.23439", "abs": "https://arxiv.org/abs/2505.23439", "authors": ["Ben Li", "Minqi Li", "Jie Ren", "Kaibing Zhang"], "title": "VITON-DRR: Details Retention Virtual Try-on via Non-rigid Registration", "categories": ["cs.CV"], "comment": "31 pages, 12 figures, Accepted by Computers & Graphics", "summary": "Image-based virtual try-on aims to fit a target garment to a specific person\nimage and has attracted extensive research attention because of its huge\napplication potential in the e-commerce and fashion industries. To generate\nhigh-quality try-on results, accurately warping the clothing item to fit the\nhuman body plays a significant role, as slight misalignment may lead to\nunrealistic artifacts in the fitting image. Most existing methods warp the\nclothing by feature matching and thin-plate spline (TPS). However, it often\nfails to preserve clothing details due to self-occlusion, severe misalignment\nbetween poses, etc. To address these challenges, this paper proposes a detail\nretention virtual try-on method via accurate non-rigid registration (VITON-DRR)\nfor diverse human poses. Specifically, we reconstruct a human semantic\nsegmentation using a dual-pyramid-structured feature extractor. Then, a novel\nDeformation Module is designed for extracting the cloth key points and warping\nthem through an accurate non-rigid registration algorithm. Finally, the Image\nSynthesis Module is designed to synthesize the deformed garment image and\ngenerate the human pose information adaptively. {Compared with} traditional\nmethods, the proposed VITON-DRR can make the deformation of fitting images more\naccurate and retain more garment details. The experimental results demonstrate\nthat the proposed method performs better than state-of-the-art methods.", "AI": {"tldr": "VITON-DRR improves virtual try-on by preserving garment details via non-rigid registration and dual-pyramid feature extraction.", "motivation": "Existing methods fail to preserve clothing details due to misalignment and self-occlusion, limiting realistic virtual try-on results.", "method": "Uses a dual-pyramid feature extractor for semantic segmentation, a Deformation Module for cloth key points, and an Image Synthesis Module for garment warping and pose adaptation.", "result": "Outperforms state-of-the-art methods in accuracy and detail retention.", "conclusion": "VITON-DRR advances virtual try-on by addressing detail loss and misalignment challenges."}}
{"id": "2505.23426", "pdf": "https://arxiv.org/pdf/2505.23426", "abs": "https://arxiv.org/abs/2505.23426", "authors": ["Yinuo Wang", "Mining Tan", "Wenjun Zou", "Haotian Lin", "Xujie Song", "Wenxuan Wang", "Tong Liu", "Likun Wang", "Guojian Zhan", "Tianze Zhu", "Shiqi Liu", "Jingliang Duan", "Shengbo Eben Li"], "title": "Enhanced DACER Algorithm with High Diffusion Efficiency", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Due to their expressive capacity, diffusion models have shown great promise\nin offline RL and imitation learning. Diffusion Actor-Critic with Entropy\nRegulator (DACER) extended this capability to online RL by using the reverse\ndiffusion process as a policy approximator, trained end-to-end with policy\ngradient methods, achieving strong performance. However, this comes at the cost\nof requiring many diffusion steps, which significantly hampers training\nefficiency, while directly reducing the steps leads to noticeable performance\ndegradation. Critically, the lack of inference efficiency becomes a significant\nbottleneck for applying diffusion policies in real-time online RL settings. To\nimprove training and inference efficiency while maintaining or even enhancing\nperformance, we propose a Q-gradient field objective as an auxiliary\noptimization target to guide the denoising process at each diffusion step.\nNonetheless, we observe that the independence of the Q-gradient field from the\ndiffusion time step negatively impacts the performance of the diffusion policy.\nTo address this, we introduce a temporal weighting mechanism that enables the\nmodel to efficiently eliminate large-scale noise in the early stages and refine\nactions in the later stages. Experimental results on MuJoCo benchmarks and\nseveral multimodal tasks demonstrate that the DACER2 algorithm achieves\nstate-of-the-art performance in most MuJoCo control tasks with only five\ndiffusion steps, while also exhibiting stronger multimodality compared to\nDACER.", "AI": {"tldr": "DACER2 improves DACER by introducing a Q-gradient field objective and temporal weighting, achieving SOTA performance with fewer diffusion steps.", "motivation": "Diffusion models in online RL face inefficiency due to many diffusion steps, hindering real-time application.", "method": "Proposes Q-gradient field objective and temporal weighting to guide denoising, reducing steps without performance loss.", "result": "Achieves SOTA performance on MuJoCo tasks with only five diffusion steps and better multimodality.", "conclusion": "DACER2 enhances efficiency and performance, making diffusion policies viable for real-time online RL."}}
{"id": "2505.23421", "pdf": "https://arxiv.org/pdf/2505.23421", "abs": "https://arxiv.org/abs/2505.23421", "authors": ["Zheming Zhang", "Yan Jiang", "Qingshan Li", "Ai Han"], "title": "OTPTO: Joint Product Selection and Inventory Optimization in Fresh E-commerce Front-End Warehouses", "categories": ["cs.LG"], "comment": "18 pages, 9 figures", "summary": "In China's competitive fresh e-commerce market, optimizing operational\nstrategies, especially inventory management in front-end warehouses, is key to\nenhance customer satisfaction and to gain a competitive edge. Front-end\nwarehouses are placed in residential areas to ensure the timely delivery of\nfresh goods and are usually in small size. This brings the challenge of\ndeciding which goods to stock and in what quantities, taking into account\ncapacity constraints. To address this issue, traditional predict-then-optimize\n(PTO) methods that predict sales and then decide on inventory often don't align\nprediction with inventory goals, as well as fail to prioritize consumer\nsatisfaction. This paper proposes a multi-task\nOptimize-then-Predict-then-Optimize (OTPTO) approach that jointly optimizes\nproduct selection and inventory management, aiming to increase consumer\nsatisfaction by maximizing the full order fulfillment rate. Our method employs\na 0-1 mixed integer programming model OM1 to determine historically optimal\ninventory levels, and then uses a product selection model PM1 and the stocking\nmodel PM2 for prediction. The combined results are further refined through a\npost-processing algorithm OM2. Experimental results from JD.com's 7Fresh\nplatform demonstrate the robustness and significant advantages of our OTPTO\nmethod. Compared to the PTO approach, our OTPTO method substantially enhances\nthe full order fulfillment rate by 4.34% (a relative increase of 7.05%) and\nnarrows the gap to the optimal full order fulfillment rate by 5.27%. These\nfindings substantiate the efficacy of the OTPTO method in managing inventory at\nfront-end warehouses of fresh e-commerce platforms and provide valuable\ninsights for future research in this domain.", "AI": {"tldr": "The paper introduces an OTPTO method for optimizing inventory management in China's fresh e-commerce, outperforming traditional PTO by improving order fulfillment rates.", "motivation": "Addressing inefficiencies in traditional predict-then-optimize methods for inventory management in small front-end warehouses, aiming to enhance consumer satisfaction.", "method": "Proposes a multi-task OTPTO approach using 0-1 mixed integer programming (OM1), product selection (PM1), and stocking models (PM2), refined by post-processing (OM2).", "result": "OTPTO boosts full order fulfillment by 4.34% (7.05% relative) and reduces the gap to optimal fulfillment by 5.27% on JD.com's 7Fresh platform.", "conclusion": "OTPTO effectively manages inventory in fresh e-commerce, offering insights for future research."}}
{"id": "2505.23628", "pdf": "https://arxiv.org/pdf/2505.23628", "abs": "https://arxiv.org/abs/2505.23628", "authors": ["Jiaxin Bai", "Wei Fan", "Qi Hu", "Qing Zong", "Chunyang Li", "Hong Ting Tsang", "Hongyu Luo", "Yauwai Yim", "Haoyu Huang", "Xiao Zhou", "Feng Qin", "Tianshi Zheng", "Xi Peng", "Xin Yao", "Huiwen Yang", "Leijie Wu", "Yi Ji", "Gong Zhang", "Renhai Chen", "Yangqiu Song"], "title": "AutoSchemaKG: Autonomous Knowledge Graph Construction through Dynamic Schema Induction from Web-Scale Corpora", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, preprint, code:\n  https://github.com/HKUST-KnowComp/AutoSchemaKG", "summary": "We present AutoSchemaKG, a framework for fully autonomous knowledge graph\nconstruction that eliminates the need for predefined schemas. Our system\nleverages large language models to simultaneously extract knowledge triples and\ninduce comprehensive schemas directly from text, modeling both entities and\nevents while employing conceptualization to organize instances into semantic\ncategories. Processing over 50 million documents, we construct ATLAS (Automated\nTriple Linking And Schema induction), a family of knowledge graphs with 900+\nmillion nodes and 5.9 billion edges. This approach outperforms state-of-the-art\nbaselines on multi-hop QA tasks and enhances LLM factuality. Notably, our\nschema induction achieves 95\\% semantic alignment with human-crafted schemas\nwith zero manual intervention, demonstrating that billion-scale knowledge\ngraphs with dynamically induced schemas can effectively complement parametric\nknowledge in large language models.", "AI": {"tldr": "AutoSchemaKG autonomously constructs knowledge graphs without predefined schemas, using LLMs to extract triples and induce schemas from text, achieving high alignment with human-crafted schemas.", "motivation": "To eliminate the need for manual schema creation in knowledge graph construction and enhance LLM factuality.", "method": "Leverages large language models to extract knowledge triples and induce schemas from text, organizing entities and events into semantic categories.", "result": "Constructed ATLAS, a family of knowledge graphs with 900+ million nodes and 5.9 billion edges, outperforming baselines on multi-hop QA tasks and achieving 95% semantic alignment with human schemas.", "conclusion": "Dynamically induced schemas in billion-scale knowledge graphs can effectively complement parametric knowledge in LLMs."}}
{"id": "2505.23444", "pdf": "https://arxiv.org/pdf/2505.23444", "abs": "https://arxiv.org/abs/2505.23444", "authors": ["Runmin Jiang", "Genpei Zhang", "Yuntian Yang", "Siqi Wu", "Yuheng Zhang", "Wanyue Feng", "Yizhou Zhao", "Xi Xiao", "Xiao Wang", "Tianyang Wang", "Xingjian Li", "Min Xu"], "title": "CryoCCD: Conditional Cycle-consistent Diffusion with Biophysical Modeling for Cryo-EM Synthesis", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Cryo-electron microscopy (cryo-EM) offers near-atomic resolution imaging of\nmacromolecules, but developing robust models for downstream analysis is\nhindered by the scarcity of high-quality annotated data. While synthetic data\ngeneration has emerged as a potential solution, existing methods often fail to\ncapture both the structural diversity of biological specimens and the complex,\nspatially varying noise inherent in cryo-EM imaging. To overcome these\nlimitations, we propose CryoCCD, a synthesis framework that integrates\nbiophysical modeling with generative techniques. Specifically, CryoCCD produces\nmulti-scale cryo-EM micrographs that reflect realistic biophysical variability\nthrough compositional heterogeneity, cellular context, and physics-informed\nimaging. To generate realistic noise, we employ a conditional diffusion model,\nenhanced by cycle consistency to preserve structural fidelity and mask-aware\ncontrastive learning to capture spatially adaptive noise patterns. Extensive\nexperiments show that CryoCCD generates structurally accurate micrographs and\nenhances performance in downstream tasks, outperforming state-of-the-art\nbaselines in both particle picking and reconstruction.", "AI": {"tldr": "CryoCCD is a framework combining biophysical modeling and generative techniques to create realistic cryo-EM micrographs, improving downstream analysis tasks.", "motivation": "The scarcity of high-quality annotated cryo-EM data and the limitations of existing synthetic data methods in capturing structural diversity and noise patterns drive the need for CryoCCD.", "method": "CryoCCD integrates biophysical modeling with generative techniques, using a conditional diffusion model with cycle consistency and mask-aware contrastive learning for realistic noise.", "result": "CryoCCD generates structurally accurate micrographs and outperforms baselines in particle picking and reconstruction tasks.", "conclusion": "CryoCCD effectively addresses the challenges of synthetic cryo-EM data generation, enhancing downstream analysis performance."}}
{"id": "2505.23437", "pdf": "https://arxiv.org/pdf/2505.23437", "abs": "https://arxiv.org/abs/2505.23437", "authors": ["Antonio Ferrara", "Andrea Pugnana", "Francesco Bonchi", "Salvatore Ruggieri"], "title": "Bounded-Abstention Pairwise Learning to Rank", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": null, "summary": "Ranking systems influence decision-making in high-stakes domains like health,\neducation, and employment, where they can have substantial economic and social\nimpacts. This makes the integration of safety mechanisms essential. One such\nmechanism is $\\textit{abstention}$, which enables algorithmic decision-making\nsystem to defer uncertain or low-confidence decisions to human experts. While\nabstention have been predominantly explored in the context of classification\ntasks, its application to other machine learning paradigms remains\nunderexplored. In this paper, we introduce a novel method for abstention in\npairwise learning-to-rank tasks. Our approach is based on thresholding the\nranker's conditional risk: the system abstains from making a decision when the\nestimated risk exceeds a predefined threshold. Our contributions are threefold:\na theoretical characterization of the optimal abstention strategy, a\nmodel-agnostic, plug-in algorithm for constructing abstaining ranking models,\nand a comprehensive empirical evaluations across multiple datasets,\ndemonstrating the effectiveness of our approach.", "AI": {"tldr": "The paper introduces a method for abstention in pairwise learning-to-rank tasks, focusing on thresholding conditional risk to defer uncertain decisions.", "motivation": "Ranking systems impact high-stakes domains, necessitating safety mechanisms like abstention, which is underexplored beyond classification tasks.", "method": "Proposes thresholding the ranker's conditional risk to abstain when risk exceeds a predefined threshold, with a model-agnostic algorithm.", "result": "Theoretical optimal abstention strategy, a plug-in algorithm, and empirical evaluations show the approach's effectiveness.", "conclusion": "The method successfully integrates abstention into ranking tasks, demonstrating practical utility across datasets."}}
{"id": "2505.23427", "pdf": "https://arxiv.org/pdf/2505.23427", "abs": "https://arxiv.org/abs/2505.23427", "authors": ["Monika Gahalawat", "Maneesh Bilalpur", "Raul Fernandez Rojas", "Jeffrey F. Cohn", "Roland Goecke", "Ramanathan Subramanian"], "title": "On the Validity of Head Motion Patterns as Generalisable Depression Biomarkers", "categories": ["cs.LG"], "comment": null, "summary": "Depression is a debilitating mood disorder negatively impacting millions\nworldwide. While researchers have explored multiple verbal and non-verbal\nbehavioural cues for automated depression assessment, head motion has received\nlittle attention thus far. Further, the common practice of validating machine\nlearning models via a single dataset can limit model generalisability. This\nwork examines the effectiveness and generalisability of models utilising\nelementary head motion units, termed kinemes, for depression severity\nestimation. Specifically, we consider three depression datasets from different\nwestern cultures (German: AVEC2013, Australian: Blackdog and American: Pitt\ndatasets) with varied contextual and recording settings to investigate the\ngeneralisability of the derived kineme patterns via two methods: (i) k-fold\ncross-validation over individual/multiple datasets, and (ii) model reuse on\nother datasets. Evaluating classification and regression performance with\nclassical machine learning methods, our results show that: (1) head motion\npatterns are efficient biomarkers for estimating depression severity, achieving\nhighly competitive performance for both classification and regression tasks on\na variety of datasets, including achieving the second best Mean Absolute Error\n(MAE) on the AVEC2013 dataset, and (2) kineme-based features are more\ngeneralisable than (a) raw head motion descriptors for binary severity\nclassification, and (b) other visual behavioural cues for severity estimation\n(regression).", "AI": {"tldr": "The paper explores head motion (kinemes) as biomarkers for depression severity, demonstrating their effectiveness and generalizability across diverse datasets.", "motivation": "Depression affects millions, but head motion cues are understudied. Single-dataset validation limits model generalizability.", "method": "Uses kinemes (head motion units) and evaluates via cross-validation and model reuse on three datasets (German, Australian, American).", "result": "Head motion patterns are effective biomarkers, achieving competitive performance in classification and regression tasks. Kinemes generalize better than raw motion descriptors and other visual cues.", "conclusion": "Kineme-based features are promising for generalizable depression severity assessment."}}
{"id": "2505.23630", "pdf": "https://arxiv.org/pdf/2505.23630", "abs": "https://arxiv.org/abs/2505.23630", "authors": ["Enzo Doyen", "Amalia Todirascu"], "title": "GeNRe: A French Gender-Neutral Rewriting System Using Collective Nouns", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Findings; 9 pages, 2 figures", "summary": "A significant portion of the textual data used in the field of Natural\nLanguage Processing (NLP) exhibits gender biases, particularly due to the use\nof masculine generics (masculine words that are supposed to refer to mixed\ngroups of men and women), which can perpetuate and amplify stereotypes. Gender\nrewriting, an NLP task that involves automatically detecting and replacing\ngendered forms with neutral or opposite forms (e.g., from masculine to\nfeminine), can be employed to mitigate these biases. While such systems have\nbeen developed in a number of languages (English, Arabic, Portuguese, German,\nFrench), automatic use of gender neutralization techniques (as opposed to\ninclusive or gender-switching techniques) has only been studied for English.\nThis paper presents GeNRe, the very first French gender-neutral rewriting\nsystem using collective nouns, which are gender-fixed in French. We introduce a\nrule-based system (RBS) tailored for the French language alongside two\nfine-tuned language models trained on data generated by our RBS. We also\nexplore the use of instruct-based models to enhance the performance of our\nother systems and find that Claude 3 Opus combined with our dictionary achieves\nresults close to our RBS. Through this contribution, we hope to promote the\nadvancement of gender bias mitigation techniques in NLP for French.", "AI": {"tldr": "GeNRe is the first French gender-neutral rewriting system using collective nouns, employing rule-based and fine-tuned models to mitigate gender bias in NLP.", "motivation": "Addressing gender bias in French NLP, particularly due to masculine generics, by developing a neutral rewriting system.", "method": "Rule-based system (RBS) for French, fine-tuned language models, and instruct-based models (Claude 3 Opus) for performance enhancement.", "result": "Claude 3 Opus with the dictionary achieves results close to the RBS, demonstrating effective gender-neutral rewriting.", "conclusion": "GeNRe advances gender bias mitigation in French NLP, encouraging further development in this area."}}
{"id": "2505.23451", "pdf": "https://arxiv.org/pdf/2505.23451", "abs": "https://arxiv.org/abs/2505.23451", "authors": ["Shuzhou Sun", "Li Liu", "Tianpeng Liu", "Shuaifeng Zhi", "Ming-Ming Cheng", "Janne Heikkil\u00e4", "Yongxiang Liu"], "title": "A Reverse Causal Framework to Mitigate Spurious Correlations for Debiasing Scene Graph Generation", "categories": ["cs.CV", "I.2.10; I.4.8"], "comment": "Accepted to IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI), 21 pages, 11 figures, 12 tables", "summary": "Existing two-stage Scene Graph Generation (SGG) frameworks typically\nincorporate a detector to extract relationship features and a classifier to\ncategorize these relationships; therefore, the training paradigm follows a\ncausal chain structure, where the detector's inputs determine the classifier's\ninputs, which in turn influence the final predictions. However, such a causal\nchain structure can yield spurious correlations between the detector's inputs\nand the final predictions, i.e., the prediction of a certain relationship may\nbe influenced by other relationships. This influence can induce at least two\nobservable biases: tail relationships are predicted as head ones, and\nforeground relationships are predicted as background ones; notably, the latter\nbias is seldom discussed in the literature. To address this issue, we propose\nreconstructing the causal chain structure into a reverse causal structure,\nwherein the classifier's inputs are treated as the confounder, and both the\ndetector's inputs and the final predictions are viewed as causal variables.\nSpecifically, we term the reconstructed causal paradigm as the Reverse causal\nFramework for SGG (RcSGG). RcSGG initially employs the proposed Active Reverse\nEstimation (ARE) to intervene on the confounder to estimate the reverse\ncausality, \\ie the causality from final predictions to the classifier's inputs.\nThen, the Maximum Information Sampling (MIS) is suggested to enhance the\nreverse causality estimation further by considering the relationship\ninformation. Theoretically, RcSGG can mitigate the spurious correlations\ninherent in the SGG framework, subsequently eliminating the induced biases.\nComprehensive experiments on popular benchmarks and diverse SGG frameworks show\nthe state-of-the-art mean recall rate.", "AI": {"tldr": "The paper introduces RcSGG, a reverse causal framework for Scene Graph Generation (SGG), to address spurious correlations and biases in existing two-stage SGG methods.", "motivation": "Existing SGG frameworks suffer from spurious correlations due to their causal chain structure, leading to biases like misclassifying tail relationships as head ones and foreground as background.", "method": "Proposes RcSGG, which reconstructs the causal chain into a reverse causal structure, using Active Reverse Estimation (ARE) and Maximum Information Sampling (MIS) to enhance causality estimation.", "result": "RcSGG achieves state-of-the-art mean recall rates on benchmarks, mitigating biases effectively.", "conclusion": "RcSGG successfully addresses biases in SGG by reversing the causal structure, improving performance and reducing spurious correlations."}}
{"id": "2505.23454", "pdf": "https://arxiv.org/pdf/2505.23454", "abs": "https://arxiv.org/abs/2505.23454", "authors": ["Yanbin Wang", "Xingyu Chen", "Yumiao Wang", "Xiang Wang", "Chuanfei Zang", "Guolong Cui", "Jiahuan Liu"], "title": "LCB-CV-UNet: Enhanced Detector for High Dynamic Range Radar Signals", "categories": ["eess.SP", "cs.AI"], "comment": "5 pages, 4 figures. Accepted to IEEE IGARSS 2025", "summary": "We propose the LCB-CV-UNet to tackle performance degradation caused by High\nDynamic Range (HDR) radar signals. Initially, a hardware-efficient,\nplug-and-play module named Logarithmic Connect Block (LCB) is proposed as a\nphase coherence preserving solution to address the inherent challenges in\nhandling HDR features. Then, we propose the Dual Hybrid Dataset Construction\nmethod to generate a semi-synthetic dataset, approximating typical HDR signal\nscenarios with adjustable target distributions. Simulation results show about\n1% total detection probability improvement with under 0.9% computational\ncomplexity added compared with the baseline. Furthermore, it excels 5% over the\nbaseline at the range in 11-13 dB signal-to-noise ratio typical for urban\ntargets. Finally, the real experiment validates the practicality of our model.", "AI": {"tldr": "LCB-CV-UNet improves HDR radar signal handling with a hardware-efficient LCB module and semi-synthetic dataset, boosting detection probability by ~1% with minimal computational overhead.", "motivation": "Address performance degradation caused by HDR radar signals by preserving phase coherence and handling HDR features effectively.", "method": "Propose Logarithmic Connect Block (LCB) for phase coherence and Dual Hybrid Dataset Construction for semi-synthetic HDR scenarios.", "result": "~1% detection probability improvement with <0.9% computational overhead; excels 5% over baseline in 11-13 dB SNR range.", "conclusion": "LCB-CV-UNet is practical and effective for HDR radar signal processing, validated by real experiments."}}
{"id": "2505.23433", "pdf": "https://arxiv.org/pdf/2505.23433", "abs": "https://arxiv.org/abs/2505.23433", "authors": ["Jian Yao", "Ran Cheng", "Xingyu Wu", "Jibin Wu", "Kay Chen Tan"], "title": "Diversity-Aware Policy Optimization for Large Language Model Reasoning", "categories": ["cs.LG"], "comment": null, "summary": "The reasoning capabilities of large language models (LLMs) have advanced\nrapidly, particularly following the release of DeepSeek R1, which has inspired\na surge of research into data quality and reinforcement learning (RL)\nalgorithms. Despite the pivotal role diversity plays in RL, its influence on\nLLM reasoning remains largely underexplored. To bridge this gap, this work\npresents a systematic investigation into the impact of diversity in RL-based\ntraining for LLM reasoning, and proposes a novel diversity-aware policy\noptimization method. Across evaluations on 12 LLMs, we observe a strong\npositive correlation between the solution diversity and Potential at k (a novel\nmetric quantifying an LLM's reasoning potential) in high-performing models.\nThis finding motivates our method to explicitly promote diversity during RL\ntraining. Specifically, we design a token-level diversity and reformulate it\ninto a practical objective, then we selectively apply it to positive samples.\nIntegrated into the R1-zero training framework, our method achieves a 3.5\npercent average improvement across four mathematical reasoning benchmarks,\nwhile generating more diverse and robust solutions.", "AI": {"tldr": "The paper explores the impact of diversity in RL-based training for LLM reasoning, proposing a diversity-aware policy optimization method that improves performance and solution diversity.", "motivation": "The influence of diversity on LLM reasoning is underexplored, despite its importance in RL. This work aims to bridge that gap.", "method": "A novel diversity-aware policy optimization method is introduced, including a token-level diversity metric and selective application to positive samples.", "result": "The method shows a 3.5% average improvement on mathematical reasoning benchmarks and generates more diverse solutions.", "conclusion": "Diversity in RL training enhances LLM reasoning, as demonstrated by improved performance and robustness."}}
{"id": "2505.23646", "pdf": "https://arxiv.org/pdf/2505.23646", "abs": "https://arxiv.org/abs/2505.23646", "authors": ["Zijun Yao", "Yantao Liu", "Yanxu Chen", "Jianhui Chen", "Junfeng Fang", "Lei Hou", "Juanzi Li", "Tat-Seng Chua"], "title": "Are Reasoning Models More Prone to Hallucination?", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Recently evolved large reasoning models (LRMs) show powerful performance in\nsolving complex tasks with long chain-of-thought (CoT) reasoning capability. As\nthese LRMs are mostly developed by post-training on formal reasoning tasks,\nwhether they generalize the reasoning capability to help reduce hallucination\nin fact-seeking tasks remains unclear and debated. For instance, DeepSeek-R1\nreports increased performance on SimpleQA, a fact-seeking benchmark, while\nOpenAI-o3 observes even severer hallucination. This discrepancy naturally\nraises the following research question: Are reasoning models more prone to\nhallucination? This paper addresses the question from three perspectives. (1)\nWe first conduct a holistic evaluation for the hallucination in LRMs. Our\nanalysis reveals that LRMs undergo a full post-training pipeline with cold\nstart supervised fine-tuning (SFT) and verifiable reward RL generally alleviate\ntheir hallucination. In contrast, both distillation alone and RL training\nwithout cold start fine-tuning introduce more nuanced hallucinations. (2) To\nexplore why different post-training pipelines alters the impact on\nhallucination in LRMs, we conduct behavior analysis. We characterize two\ncritical cognitive behaviors that directly affect the factuality of a LRM: Flaw\nRepetition, where the surface-level reasoning attempts repeatedly follow the\nsame underlying flawed logic, and Think-Answer Mismatch, where the final answer\nfails to faithfully match the previous CoT process. (3) Further, we investigate\nthe mechanism behind the hallucination of LRMs from the perspective of model\nuncertainty. We find that increased hallucination of LRMs is usually associated\nwith the misalignment between model uncertainty and factual accuracy. Our work\nprovides an initial understanding of the hallucination in LRMs.", "AI": {"tldr": "The paper investigates whether large reasoning models (LRMs) are more prone to hallucination in fact-seeking tasks, analyzing their post-training pipelines, cognitive behaviors, and model uncertainty.", "motivation": "To clarify the debate on whether LRMs generalize reasoning capability to reduce hallucination in fact-seeking tasks, given conflicting reports like DeepSeek-R1's improved performance versus OpenAI-o3's increased hallucination.", "method": "(1) Holistic evaluation of hallucination in LRMs, (2) behavior analysis of cognitive traits (Flaw Repetition and Think-Answer Mismatch), and (3) investigation of model uncertainty's role in hallucination.", "result": "LRMs with full post-training (cold start SFT and verifiable reward RL) reduce hallucination, while distillation alone or RL without cold start SFT worsens it. Misalignment between model uncertainty and factual accuracy correlates with increased hallucination.", "conclusion": "The study provides initial insights into LRM hallucination, highlighting the impact of post-training pipelines, cognitive behaviors, and model uncertainty."}}
{"id": "2505.23462", "pdf": "https://arxiv.org/pdf/2505.23462", "abs": "https://arxiv.org/abs/2505.23462", "authors": ["Runyi Li", "Bin Chen", "Jian Zhang", "Radu Timofte"], "title": "LAFR: Efficient Diffusion-based Blind Face Restoration via Latent Codebook Alignment Adapter", "categories": ["cs.CV"], "comment": null, "summary": "Blind face restoration from low-quality (LQ) images is a challenging task\nthat requires not only high-fidelity image reconstruction but also the\npreservation of facial identity. While diffusion models like Stable Diffusion\nhave shown promise in generating high-quality (HQ) images, their VAE modules\nare typically trained only on HQ data, resulting in semantic misalignment when\nencoding LQ inputs. This mismatch significantly weakens the effectiveness of LQ\nconditions during the denoising process. Existing approaches often tackle this\nissue by retraining the VAE encoder, which is computationally expensive and\nmemory-intensive. To address this limitation efficiently, we propose LAFR\n(Latent Alignment for Face Restoration), a novel codebook-based latent space\nadapter that aligns the latent distribution of LQ images with that of HQ\ncounterparts, enabling semantically consistent diffusion sampling without\naltering the original VAE. To further enhance identity preservation, we\nintroduce a multi-level restoration loss that combines constraints from\nidentity embeddings and facial structural priors. Additionally, by leveraging\nthe inherent structural regularity of facial images, we show that lightweight\nfinetuning of diffusion prior on just 0.9% of FFHQ dataset is sufficient to\nachieve results comparable to state-of-the-art methods, reduce training time by\n70%. Extensive experiments on both synthetic and real-world face restoration\nbenchmarks demonstrate the effectiveness and efficiency of LAFR, achieving\nhigh-quality, identity-preserving face reconstruction from severely degraded\ninputs.", "AI": {"tldr": "LAFR (Latent Alignment for Face Restoration) is a novel method that aligns latent distributions of low-quality (LQ) and high-quality (HQ) face images for improved restoration, avoiding costly VAE retraining. It uses a multi-level loss for identity preservation and achieves efficient results with minimal finetuning.", "motivation": "Blind face restoration from LQ images is challenging due to semantic misalignment in diffusion models when encoding LQ inputs, leading to ineffective denoising. Existing solutions require expensive VAE retraining.", "method": "LAFR introduces a codebook-based latent space adapter to align LQ and HQ latent distributions, enabling consistent diffusion sampling. It includes a multi-level restoration loss for identity preservation and leverages facial structural priors for lightweight finetuning.", "result": "LAFR achieves high-quality, identity-preserving face restoration from degraded inputs, with results comparable to state-of-the-art methods while reducing training time by 70%.", "conclusion": "LAFR efficiently addresses the limitations of existing methods by aligning latent spaces and preserving identity, offering a practical solution for blind face restoration."}}
{"id": "2505.23503", "pdf": "https://arxiv.org/pdf/2505.23503", "abs": "https://arxiv.org/abs/2505.23503", "authors": ["Shibbir Ahmed", "Shahnewaz Karim Sakib", "Anindya Bijoy Das"], "title": "Can Large Language Models Challenge CNNS in Medical Image Analysis?", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "This study presents a multimodal AI framework designed for precisely\nclassifying medical diagnostic images. Utilizing publicly available datasets,\nthe proposed system compares the strengths of convolutional neural networks\n(CNNs) and different large language models (LLMs). This in-depth comparative\nanalysis highlights key differences in diagnostic performance, execution\nefficiency, and environmental impacts. Model evaluation was based on accuracy,\nF1-score, average execution time, average energy consumption, and estimated\n$CO_2$ emission. The findings indicate that although CNN-based models can\noutperform various multimodal techniques that incorporate both images and\ncontextual information, applying additional filtering on top of LLMs can lead\nto substantial performance gains. These findings highlight the transformative\npotential of multimodal AI systems to enhance the reliability, efficiency, and\nscalability of medical diagnostics in clinical settings.", "AI": {"tldr": "A multimodal AI framework compares CNNs and LLMs for medical image classification, showing CNN superiority but LLM potential with filtering.", "motivation": "To enhance medical diagnostics by evaluating the performance, efficiency, and environmental impact of CNNs and LLMs.", "method": "Comparative analysis using accuracy, F1-score, execution time, energy consumption, and CO2 emissions on public datasets.", "result": "CNNs outperform multimodal techniques, but LLMs with filtering show significant performance gains.", "conclusion": "Multimodal AI can improve reliability, efficiency, and scalability in medical diagnostics."}}
{"id": "2505.23442", "pdf": "https://arxiv.org/pdf/2505.23442", "abs": "https://arxiv.org/abs/2505.23442", "authors": ["Linyu Li", "Zhi Jin", "Yuanpeng He", "Dongming Jin", "Haoran Duan", "Zhengwei Tao", "Xuan Zhang", "Jiandong Li"], "title": "Rethinking Regularization Methods for Knowledge Graph Completion", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Knowledge graph completion (KGC) has attracted considerable attention in\nrecent years because it is critical to improving the quality of knowledge\ngraphs. Researchers have continuously explored various models. However, most\nprevious efforts have neglected to take advantage of regularization from a\ndeeper perspective and therefore have not been used to their full potential.\nThis paper rethinks the application of regularization methods in KGC. Through\nextensive empirical studies on various KGC models, we find that carefully\ndesigned regularization not only alleviates overfitting and reduces variance\nbut also enables these models to break through the upper bounds of their\noriginal performance. Furthermore, we introduce a novel sparse-regularization\nmethod that embeds the concept of rank-based selective sparsity into the KGC\nregularizer. The core idea is to selectively penalize those components with\nsignificant features in the embedding vector, thus effectively ignoring many\ncomponents that contribute little and may only represent noise. Various\ncomparative experiments on multiple datasets and multiple models show that the\nSPR regularization method is better than other regularization methods and can\nenable the KGC model to further break through the performance margin.", "AI": {"tldr": "The paper explores the impact of regularization in knowledge graph completion (KGC), proposing a novel sparse-regularization method (SPR) that selectively penalizes significant embedding components to improve model performance.", "motivation": "Existing KGC models underutilize regularization, limiting their potential. The study aims to demonstrate how deeper regularization can enhance performance.", "method": "The paper introduces SPR, a rank-based selective sparsity method, and tests it through extensive empirical studies on various KGC models and datasets.", "result": "SPR outperforms other regularization methods, enabling KGC models to surpass their original performance bounds.", "conclusion": "Carefully designed regularization, like SPR, is crucial for advancing KGC by reducing overfitting and noise while enhancing model performance."}}
{"id": "2505.23654", "pdf": "https://arxiv.org/pdf/2505.23654", "abs": "https://arxiv.org/abs/2505.23654", "authors": ["Mohamed Elaraby", "Diane Litman"], "title": "ARC: Argument Representation and Coverage Analysis for Zero-Shot Long Document Summarization with Instruction Following LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Integrating structured information has long improved the quality of\nabstractive summarization, particularly in retaining salient content. In this\nwork, we focus on a specific form of structure: argument roles, which are\ncrucial for summarizing documents in high-stakes domains such as law. We\ninvestigate whether instruction-tuned large language models (LLMs) adequately\npreserve this information. To this end, we introduce Argument Representation\nCoverage (ARC), a framework for measuring how well LLM-generated summaries\ncapture salient arguments. Using ARC, we analyze summaries produced by three\nopen-weight LLMs in two domains where argument roles are central: long legal\nopinions and scientific articles. Our results show that while LLMs cover\nsalient argument roles to some extent, critical information is often omitted in\ngenerated summaries, particularly when arguments are sparsely distributed\nthroughout the input. Further, we use ARC to uncover behavioral patterns --\nspecifically, how the positional bias of LLM context windows and role-specific\npreferences impact the coverage of key arguments in generated summaries,\nemphasizing the need for more argument-aware summarization strategies.", "AI": {"tldr": "The paper evaluates how well instruction-tuned LLMs preserve argument roles in summaries, introducing ARC to measure coverage. Findings show gaps in capturing critical arguments, especially when sparse, and highlight biases in LLM behavior.", "motivation": "To assess if LLMs retain crucial argument roles in summaries, particularly in high-stakes domains like law and science.", "method": "Introduces Argument Representation Coverage (ARC) to analyze summaries from three open-weight LLMs in legal and scientific domains.", "result": "LLMs partially cover argument roles but often omit critical information, especially with sparse arguments. ARC reveals biases in LLM behavior.", "conclusion": "Highlights the need for argument-aware summarization strategies to improve coverage of key arguments."}}
{"id": "2505.23463", "pdf": "https://arxiv.org/pdf/2505.23463", "abs": "https://arxiv.org/abs/2505.23463", "authors": ["Han Zhou", "Sebastian G. Gruber", "Teodora Popordanoska", "Matthew B. Blaschko"], "title": "Revisiting Reweighted Risk for Calibration: AURC, Focal Loss, and Inverse Focal Loss", "categories": ["cs.CV"], "comment": null, "summary": "Several variants of reweighted risk functionals, such as focal losss, inverse\nfocal loss, and the Area Under the Risk-Coverage Curve (AURC), have been\nproposed in the literature and claims have been made in relation to their\ncalibration properties. However, focal loss and inverse focal loss propose\nvastly different weighting schemes. In this paper, we revisit a broad class of\nweighted risk functions commonly used in deep learning and establish a\nprincipled connection between these reweighting schemes and calibration errors.\nWe show that minimizing calibration error is closely linked to the selective\nclassification paradigm and demonstrate that optimizing a regularized variant\nof the AURC naturally leads to improved calibration. This regularized AURC\nshares a similar reweighting strategy with inverse focal loss, lending support\nto the idea that focal loss is less principled when calibration is a desired\noutcome. Direct AURC optimization offers greater flexibility through the choice\nof confidence score functions (CSFs). To enable gradient-based optimization, we\nintroduce a differentiable formulation of the regularized AURC using the\nSoftRank technique. Empirical evaluations demonstrate that our AURC-based loss\nachieves competitive class-wise calibration performance across a range of\ndatasets and model architectures.", "AI": {"tldr": "The paper connects weighted risk functions (like focal loss and AURC) to calibration errors, showing that regularized AURC improves calibration and aligns with inverse focal loss.", "motivation": "To establish a principled link between reweighted risk functions and calibration errors, addressing conflicting claims about their calibration properties.", "method": "Analyzes weighted risk functions, introduces a regularized AURC with SoftRank for gradient-based optimization, and compares reweighting schemes.", "result": "Regularized AURC achieves competitive class-wise calibration across datasets and architectures, supporting inverse focal loss over focal loss for calibration.", "conclusion": "Optimizing regularized AURC is effective for calibration, offering flexibility in confidence score functions and outperforming focal loss in principled calibration."}}
{"id": "2505.23508", "pdf": "https://arxiv.org/pdf/2505.23508", "abs": "https://arxiv.org/abs/2505.23508", "authors": ["Rebecca Ramnauth", "Dra\u017een Br\u0161\u010di\u0107", "Brian Scassellati"], "title": "A Robot-Assisted Approach to Small Talk Training for Adults with ASD", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted for publication in Robotics: Science and Systems (RSS) 2025,\n  14 pages, 4 figures,", "summary": "From dating to job interviews, making new friends or simply chatting with the\ncashier at checkout, engaging in small talk is a vital, everyday social skill.\nFor adults with Autism Spectrum Disorder (ASD), small talk can be particularly\nchallenging, yet it is essential for social integration, building\nrelationships, and accessing professional opportunities. In this study, we\npresent our development and evaluation of an in-home autonomous robot system\nthat allows users to practice small talk. Results from the week-long study show\nthat adults with ASD enjoyed the training, made notable progress in initiating\nconversations and improving eye contact, and viewed the system as a valuable\ntool for enhancing their conversational skills.", "AI": {"tldr": "An autonomous robot system was developed to help adults with ASD practice small talk, showing positive results in conversation skills.", "motivation": "Small talk is challenging for adults with ASD but crucial for social integration and opportunities.", "method": "Development and evaluation of an in-home autonomous robot system for small talk practice.", "result": "Participants enjoyed the training, improved conversation initiation and eye contact, and valued the system.", "conclusion": "The robot system is effective for enhancing conversational skills in adults with ASD."}}
{"id": "2505.23443", "pdf": "https://arxiv.org/pdf/2505.23443", "abs": "https://arxiv.org/abs/2505.23443", "authors": ["Benyamin Trachtenberg", "Nir Rosenfeld"], "title": "Strategic Classification with Non-Linear Classifiers", "categories": ["cs.LG"], "comment": null, "summary": "In strategic classification, the standard supervised learning setting is\nextended to support the notion of strategic user behavior in the form of costly\nfeature manipulations made in response to a classifier. While standard learning\nsupports a broad range of model classes, the study of strategic classification\nhas, so far, been dedicated mostly to linear classifiers. This work aims to\nexpand the horizon by exploring how strategic behavior manifests under\nnon-linear classifiers and what this implies for learning. We take a bottom-up\napproach showing how non-linearity affects decision boundary points, classifier\nexpressivity, and model classes complexity. A key finding is that universal\napproximators (e.g., neural nets) are no longer universal once the environment\nis strategic. We demonstrate empirically how this can create performance gaps\neven on an unrestricted model class.", "AI": {"tldr": "The paper explores strategic classification with non-linear classifiers, revealing limitations in universal approximators like neural nets in strategic environments.", "motivation": "To extend strategic classification beyond linear classifiers and understand how non-linearity impacts strategic behavior and learning.", "method": "A bottom-up approach analyzing non-linearity's effects on decision boundaries, classifier expressivity, and model complexity.", "result": "Universal approximators (e.g., neural nets) lose universality in strategic settings, leading to performance gaps.", "conclusion": "Strategic environments challenge the universality of non-linear classifiers, impacting their effectiveness."}}
{"id": "2505.23657", "pdf": "https://arxiv.org/pdf/2505.23657", "abs": "https://arxiv.org/abs/2505.23657", "authors": ["Hongxiang Zhang", "Hao Chen", "Tianyi Zhang", "Muhao Chen"], "title": "Active Layer-Contrastive Decoding Reduces Hallucination in Large Language Model Generation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent decoding methods improve the factuality of large language\nmodels~(LLMs) by refining how the next token is selected during generation.\nThese methods typically operate at the token level, leveraging internal\nrepresentations to suppress superficial patterns. Nevertheless, LLMs remain\nprone to hallucinations, especially over longer contexts. In this paper, we\npropose Active Layer-Contrastive Decoding (ActLCD), a novel decoding strategy\nthat actively decides when to apply contrasting layers during generation. By\ncasting decoding as a sequential decision-making problem, ActLCD employs a\nreinforcement learning policy guided by a reward-aware classifier to optimize\nfactuality beyond the token level. Our experiments demonstrate that ActLCD\nsurpasses state-of-the-art methods across five benchmarks, showcasing its\neffectiveness in mitigating hallucinations in diverse generation scenarios.", "AI": {"tldr": "ActLCD is a new decoding method for LLMs that uses reinforcement learning to reduce hallucinations by dynamically applying contrasting layers during generation.", "motivation": "LLMs still suffer from hallucinations, especially in long contexts, despite existing token-level decoding improvements.", "method": "ActLCD frames decoding as a sequential decision problem, using a reinforcement learning policy guided by a reward-aware classifier to optimize factuality.", "result": "ActLCD outperforms state-of-the-art methods across five benchmarks, effectively reducing hallucinations.", "conclusion": "ActLCD is a promising approach for enhancing the factuality of LLM outputs by addressing hallucinations beyond the token level."}}
{"id": "2505.23469", "pdf": "https://arxiv.org/pdf/2505.23469", "abs": "https://arxiv.org/abs/2505.23469", "authors": ["Zhuodong Li", "Fei Hou", "Wencheng Wang", "Xuequan Lu", "Ying He"], "title": "A Divide-and-Conquer Approach for Global Orientation of Non-Watertight Scene-Level Point Clouds Using 0-1 Integer Optimization", "categories": ["cs.CV"], "comment": "accepted to SIGGRAPH 2025", "summary": "Orienting point clouds is a fundamental problem in computer graphics and 3D\nvision, with applications in reconstruction, segmentation, and analysis. While\nsignificant progress has been made, existing approaches mainly focus on\nwatertight, object-level 3D models. The orientation of large-scale,\nnon-watertight 3D scenes remains an underexplored challenge. To address this\ngap, we propose DACPO (Divide-And-Conquer Point Orientation), a novel framework\nthat leverages a divide-and-conquer strategy for scalable and robust point\ncloud orientation. Rather than attempting to orient an unbounded scene at once,\nDACPO segments the input point cloud into smaller, manageable blocks, processes\neach block independently, and integrates the results through a global\noptimization stage. For each block, we introduce a two-step process: estimating\ninitial normal orientations by a randomized greedy method and refining them by\nan adapted iterative Poisson surface reconstruction. To achieve consistency\nacross blocks, we model inter-block relationships using an an undirected graph,\nwhere nodes represent blocks and edges connect spatially adjacent blocks. To\nreliably evaluate orientation consistency between adjacent blocks, we introduce\nthe concept of the visible connected region, which defines the region over\nwhich visibility-based assessments are performed. The global integration is\nthen formulated as a 0-1 integer-constrained optimization problem, with block\nflip states as binary variables. Despite the combinatorial nature of the\nproblem, DACPO remains scalable by limiting the number of blocks (typically a\nfew hundred for 3D scenes) involved in the optimization. Experiments on\nbenchmark datasets demonstrate DACPO's strong performance, particularly in\nchallenging large-scale, non-watertight scenarios where existing methods often\nfail. The source code is available at https://github.com/zd-lee/DACPO.", "AI": {"tldr": "DACPO is a novel framework for orienting large-scale, non-watertight point clouds by dividing them into manageable blocks, processing each independently, and integrating results via global optimization.", "motivation": "Existing methods focus on watertight, object-level models, leaving large-scale, non-watertight scenes underexplored. DACPO addresses this gap.", "method": "DACPO segments point clouds into blocks, estimates initial normals via randomized greedy method, refines them with iterative Poisson reconstruction, and integrates results using a graph-based global optimization.", "result": "DACPO outperforms existing methods in large-scale, non-watertight scenarios, as shown in benchmark experiments.", "conclusion": "DACPO provides a scalable and robust solution for point cloud orientation in challenging large-scale scenes, with publicly available source code."}}
{"id": "2505.23529", "pdf": "https://arxiv.org/pdf/2505.23529", "abs": "https://arxiv.org/abs/2505.23529", "authors": ["Shifeng Xie", "Aref Einizade", "Jhony H. Giraldo"], "title": "Subgraph Gaussian Embedding Contrast for Self-Supervised Graph Representation Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Representation Learning (GRL) is a fundamental task in machine\nlearning, aiming to encode high-dimensional graph-structured data into\nlow-dimensional vectors. Self-Supervised Learning (SSL) methods are widely used\nin GRL because they can avoid expensive human annotation. In this work, we\npropose a novel Subgraph Gaussian Embedding Contrast (SubGEC) method. Our\napproach introduces a subgraph Gaussian embedding module, which adaptively maps\nsubgraphs to a structured Gaussian space, ensuring the preservation of input\nsubgraph characteristics while generating subgraphs with a controlled\ndistribution. We then employ optimal transport distances, more precisely the\nWasserstein and Gromov-Wasserstein distances, to effectively measure the\nsimilarity between subgraphs, enhancing the robustness of the contrastive\nlearning process. Extensive experiments across multiple benchmarks demonstrate\nthat \\method~outperforms or presents competitive performance against\nstate-of-the-art approaches. Our findings provide insights into the design of\nSSL methods for GRL, emphasizing the importance of the distribution of the\ngenerated contrastive pairs.", "AI": {"tldr": "The paper introduces SubGEC, a self-supervised learning method for graph representation learning, using subgraph Gaussian embeddings and optimal transport distances to improve performance.", "motivation": "To avoid costly human annotation in graph representation learning by leveraging self-supervised methods, while preserving subgraph characteristics and ensuring robust contrastive learning.", "method": "Proposes SubGEC, which maps subgraphs to a Gaussian space and uses Wasserstein and Gromov-Wasserstein distances for similarity measurement in contrastive learning.", "result": "SubGEC outperforms or competes with state-of-the-art methods across benchmarks, highlighting the role of contrastive pair distribution.", "conclusion": "The study underscores the significance of structured contrastive pair generation in self-supervised graph representation learning."}}
{"id": "2505.23448", "pdf": "https://arxiv.org/pdf/2505.23448", "abs": "https://arxiv.org/abs/2505.23448", "authors": ["Pirzada Suhail", "Rehna Afroz", "Amit Sethi"], "title": "Network Inversion for Uncertainty-Aware Out-of-Distribution Detection", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Out-of-distribution (OOD) detection and uncertainty estimation (UE) are\ncritical components for building safe machine learning systems, especially in\nreal-world scenarios where unexpected inputs are inevitable. In this work, we\npropose a novel framework that combines network inversion with classifier\ntraining to simultaneously address both OOD detection and uncertainty\nestimation. For a standard n-class classification task, we extend the\nclassifier to an (n+1)-class model by introducing a \"garbage\" class, initially\npopulated with random gaussian noise to represent outlier inputs. After each\ntraining epoch, we use network inversion to reconstruct input images\ncorresponding to all output classes that initially appear as noisy and\nincoherent and are therefore excluded to the garbage class for retraining the\nclassifier. This cycle of training, inversion, and exclusion continues\niteratively till the inverted samples begin to resemble the in-distribution\ndata more closely, suggesting that the classifier has learned to carve out\nmeaningful decision boundaries while sanitising the class manifolds by pushing\nOOD content into the garbage class. During inference, this training scheme\nenables the model to effectively detect and reject OOD samples by classifying\nthem into the garbage class. Furthermore, the confidence scores associated with\neach prediction can be used to estimate uncertainty for both in-distribution\nand OOD inputs. Our approach is scalable, interpretable, and does not require\naccess to external OOD datasets or post-hoc calibration techniques while\nproviding a unified solution to the dual challenges of OOD detection and\nuncertainty estimation.", "AI": {"tldr": "A novel framework combining network inversion and classifier training for simultaneous OOD detection and uncertainty estimation, using a garbage class for outliers.", "motivation": "Addressing the need for safe ML systems by detecting OOD inputs and estimating uncertainty without external datasets or post-hoc methods.", "method": "Extends classifier to (n+1)-class with a garbage class, iteratively trains using network inversion to refine decision boundaries and exclude OOD samples.", "result": "Effective OOD detection and uncertainty estimation, scalable and interpretable without external data.", "conclusion": "The framework provides a unified, efficient solution for OOD detection and UE, enhancing ML system safety."}}
{"id": "2505.23662", "pdf": "https://arxiv.org/pdf/2505.23662", "abs": "https://arxiv.org/abs/2505.23662", "authors": ["Beong-woo Kwak", "Minju Kim", "Dongha Lim", "Hyungjoo Chae", "Dongjin Kang", "Sunghwan Kim", "Dongil Yang", "Jinyoung Yeo"], "title": "ToolHaystack: Stress-Testing Tool-Augmented Language Models in Realistic Long-Term Interactions", "categories": ["cs.CL"], "comment": "Our code and data are available at\n  https://github.com/bwookwak/ToolHaystack", "summary": "Large language models (LLMs) have demonstrated strong capabilities in using\nexternal tools to address user inquiries. However, most existing evaluations\nassume tool use in short contexts, offering limited insight into model behavior\nduring realistic long-term interactions. To fill this gap, we introduce\nToolHaystack, a benchmark for testing the tool use capabilities in long-term\ninteractions. Each test instance in ToolHaystack includes multiple tasks\nexecution contexts and realistic noise within a continuous conversation,\nenabling assessment of how well models maintain context and handle various\ndisruptions. By applying this benchmark to 14 state-of-the-art LLMs, we find\nthat while current models perform well in standard multi-turn settings, they\noften significantly struggle in ToolHaystack, highlighting critical gaps in\ntheir long-term robustness not revealed by previous tool benchmarks.", "AI": {"tldr": "ToolHaystack benchmark evaluates LLMs' long-term tool use, revealing gaps in robustness not shown by short-context tests.", "motivation": "Existing evaluations focus on short contexts, lacking insight into long-term tool use behavior.", "method": "Introduce ToolHaystack, a benchmark with multi-task execution contexts and realistic noise in continuous conversations.", "result": "Current LLMs perform well in standard multi-turn settings but struggle in ToolHaystack, showing long-term robustness gaps.", "conclusion": "ToolHaystack highlights critical weaknesses in LLMs' long-term tool use, suggesting need for improved robustness."}}
{"id": "2505.23475", "pdf": "https://arxiv.org/pdf/2505.23475", "abs": "https://arxiv.org/abs/2505.23475", "authors": ["Ron Shapira Weber", "Shahar Ben Ishay", "Andrey Lavrinenko", "Shahaf E. Finder", "Oren Freifeld"], "title": "TimePoint: Accelerated Time Series Alignment via Self-Supervised Keypoint and Descriptor Learning", "categories": ["cs.CV", "cs.LG"], "comment": "ICML 2025", "summary": "Fast and scalable alignment of time series is a fundamental challenge in many\ndomains. The standard solution, Dynamic Time Warping (DTW), struggles with poor\nscalability and sensitivity to noise. We introduce TimePoint, a self-supervised\nmethod that dramatically accelerates DTW-based alignment while typically\nimproving alignment accuracy by learning keypoints and descriptors from\nsynthetic data. Inspired by 2D keypoint detection but carefully adapted to the\nunique challenges of 1D signals, TimePoint leverages efficient 1D\ndiffeomorphisms, which effectively model nonlinear time warping, to generate\nrealistic training data. This approach, along with fully convolutional and\nwavelet convolutional architectures, enables the extraction of informative\nkeypoints and descriptors. Applying DTW to these sparse representations yield\nmajor speedups and typically higher alignment accuracy than standard DTW\napplied to the full signals. TimePoint demonstrates strong generalization to\nreal-world time series when trained solely on synthetic data, and further\nimproves with fine-tuning on real data. Extensive experiments demonstrate that\nTimePoint consistently achieves faster and more accurate alignments than\nstandard DTW, making it a scalable solution for time-series analysis. Our code\nis available at https://github.com/BGU-CS-VIL/TimePoint", "AI": {"tldr": "TimePoint is a self-supervised method that accelerates DTW-based alignment and improves accuracy by learning keypoints from synthetic data, outperforming standard DTW in speed and precision.", "motivation": "Dynamic Time Warping (DTW) faces scalability and noise sensitivity issues, prompting the need for a faster and more accurate alignment method.", "method": "TimePoint uses 1D diffeomorphisms to generate synthetic training data and employs convolutional architectures to extract keypoints and descriptors, enabling efficient DTW alignment.", "result": "TimePoint achieves faster and more accurate alignments than standard DTW, with strong generalization to real-world data.", "conclusion": "TimePoint offers a scalable and superior alternative to DTW for time-series alignment, with potential for further improvement via fine-tuning."}}
{"id": "2505.23554", "pdf": "https://arxiv.org/pdf/2505.23554", "abs": "https://arxiv.org/abs/2505.23554", "authors": ["Hayden Moore", "Sirui Qi", "Ninad Hogade", "Dejan Milojicic", "Cullen Bash", "Sudeep Pasricha"], "title": "Sustainable Carbon-Aware and Water-Efficient LLM Scheduling in Geo-Distributed Cloud Datacenters", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": null, "summary": "In recent years, Large Language Models (LLM) such as ChatGPT, CoPilot, and\nGemini have been widely adopted in different areas. As the use of LLMs\ncontinues to grow, many efforts have focused on reducing the massive training\noverheads of these models. But it is the environmental impact of handling user\nrequests to LLMs that is increasingly becoming a concern. Recent studies\nestimate that the costs of operating LLMs in their inference phase can exceed\ntraining costs by 25x per year. As LLMs are queried incessantly, the cumulative\ncarbon footprint for the operational phase has been shown to far exceed the\nfootprint during the training phase. Further, estimates indicate that 500 ml of\nfresh water is expended for every 20-50 requests to LLMs during inference. To\naddress these important sustainability issues with LLMs, we propose a novel\nframework called SLIT to co-optimize LLM quality of service (time-to-first\ntoken), carbon emissions, water usage, and energy costs. The framework utilizes\na machine learning (ML) based metaheuristic to enhance the sustainability of\nLLM hosting across geo-distributed cloud datacenters. Such a framework will\nbecome increasingly vital as LLMs proliferate.", "AI": {"tldr": "The paper introduces SLIT, a framework to optimize sustainability in LLM operations by balancing quality of service, carbon emissions, water usage, and energy costs.", "motivation": "The environmental impact of LLMs, particularly during inference, is a growing concern due to high carbon footprints and water usage.", "method": "SLIT uses an ML-based metaheuristic to optimize LLM hosting across geo-distributed cloud datacenters.", "result": "The framework aims to reduce the operational environmental impact of LLMs while maintaining service quality.", "conclusion": "SLIT is a vital solution for sustainable LLM deployment as their usage grows."}}
{"id": "2505.23458", "pdf": "https://arxiv.org/pdf/2505.23458", "abs": "https://arxiv.org/abs/2505.23458", "authors": ["Kevin Frans", "Seohong Park", "Pieter Abbeel", "Sergey Levine"], "title": "Diffusion Guidance Is a Controllable Policy Improvement Operator", "categories": ["cs.LG"], "comment": null, "summary": "At the core of reinforcement learning is the idea of learning beyond the\nperformance in the data. However, scaling such systems has proven notoriously\ntricky. In contrast, techniques from generative modeling have proven remarkably\nscalable and are simple to train. In this work, we combine these strengths, by\nderiving a direct relation between policy improvement and guidance of diffusion\nmodels. The resulting framework, CFGRL, is trained with the simplicity of\nsupervised learning, yet can further improve on the policies in the data. On\noffline RL tasks, we observe a reliable trend -- increased guidance weighting\nleads to increased performance. Of particular importance, CFGRL can operate\nwithout explicitly learning a value function, allowing us to generalize simple\nsupervised methods (e.g., goal-conditioned behavioral cloning) to further\nprioritize optimality, gaining performance for \"free\" across the board.", "AI": {"tldr": "CFGRL combines reinforcement learning and generative modeling, enabling scalable policy improvement without explicit value function learning.", "motivation": "To leverage the scalability of generative models while retaining the policy improvement capabilities of reinforcement learning.", "method": "Derives a direct relation between policy improvement and guidance of diffusion models, simplifying training to supervised learning.", "result": "Increased guidance weighting improves performance; CFGRL generalizes supervised methods for better optimality.", "conclusion": "CFGRL offers a scalable, simple approach to enhance policies beyond data performance, applicable across tasks."}}
{"id": "2505.23666", "pdf": "https://arxiv.org/pdf/2505.23666", "abs": "https://arxiv.org/abs/2505.23666", "authors": ["Luke McDermott", "Robert W. Heath Jr.", "Rahul Parhi"], "title": "LoLA: Low-Rank Linear Attention With Sparse Caching", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Transformer-based large language models suffer from quadratic complexity at\ninference on long sequences. Linear attention methods are efficient\nalternatives, however, they fail to provide an accurate approximation of\nsoftmax attention. By additionally incorporating sliding window attention into\neach linear attention head, this gap can be closed for short context-length\ntasks. Unfortunately, these approaches cannot recall important information from\nlong contexts due to \"memory collisions\". In this paper , we propose LoLA:\nLow-rank Linear Attention with sparse caching. LoLA separately stores\nadditional key-value pairs that would otherwise interfere with past associative\nmemories. Moreover, LoLA further closes the gap between linear attention models\nand transformers by distributing past key-value pairs into three forms of\nmemory: (i) recent pairs in a local sliding window; (ii) difficult-to-memorize\npairs in a sparse, global cache; and (iii) generic pairs in the recurrent\nhidden state of linear attention. As an inference-only strategy, LoLA enables\npass-key retrieval on up to 8K context lengths on needle-in-a-haystack tasks\nfrom RULER. It boosts the accuracy of the base subquadratic model from 0.6% to\n97.4% at 4K context lengths, with a 4.6x smaller cache than that of Llama-3.1\n8B. LoLA demonstrates strong performance on zero-shot commonsense reasoning\ntasks among 1B and 8B parameter subquadratic models. Finally, LoLA is an\nextremely lightweight approach: Nearly all of our results can be reproduced on\na single consumer GPU.", "AI": {"tldr": "LoLA (Low-rank Linear Attention with sparse caching) improves linear attention models by addressing memory collisions, enabling efficient long-context inference with high accuracy.", "motivation": "Transformer-based models suffer from quadratic complexity in long sequences, and existing linear attention methods fail to approximate softmax attention accurately.", "method": "LoLA incorporates sliding window attention, sparse global caching, and recurrent hidden states to manage key-value pairs, avoiding memory interference.", "result": "LoLA achieves 97.4% accuracy on 4K context tasks (vs. 0.6% baseline) and strong performance on zero-shot reasoning, with a smaller cache than Llama-3.1 8B.", "conclusion": "LoLA is a lightweight, efficient solution for long-context inference, reproducible on consumer GPUs."}}
{"id": "2505.23481", "pdf": "https://arxiv.org/pdf/2505.23481", "abs": "https://arxiv.org/abs/2505.23481", "authors": ["Mohamed Rayan Barhdadi", "Hasan Kurban", "Hussein Alnuweiri"], "title": "PhysicsNeRF: Physics-Guided 3D Reconstruction from Sparse Views", "categories": ["cs.CV", "I.2.10; I.4.8; I.5.1"], "comment": "4 pages, 2 figures, 2 tables. Preliminary work. Under review by the\n  Building Physically Plausible World Models Workshop at the 42nd International\n  Conference on Machine Learning (ICML 2025), Vancouver, Canada", "summary": "PhysicsNeRF is a physically grounded framework for 3D reconstruction from\nsparse views, extending Neural Radiance Fields with four complementary\nconstraints: depth ranking, RegNeRF-style consistency, sparsity priors, and\ncross-view alignment. While standard NeRFs fail under sparse supervision,\nPhysicsNeRF employs a compact 0.67M-parameter architecture and achieves 21.4 dB\naverage PSNR using only 8 views, outperforming prior methods. A generalization\ngap of 5.7-6.2 dB is consistently observed and analyzed, revealing fundamental\nlimitations of sparse-view reconstruction. PhysicsNeRF enables physically\nconsistent, generalizable 3D representations for agent interaction and\nsimulation, and clarifies the expressiveness-generalization trade-off in\nconstrained NeRF models.", "AI": {"tldr": "PhysicsNeRF improves 3D reconstruction from sparse views using physical constraints, outperforming NeRF with fewer parameters and views.", "motivation": "Standard NeRFs struggle with sparse views, so PhysicsNeRF introduces physical constraints to enhance performance and generalization.", "method": "Extends NeRF with depth ranking, RegNeRF-style consistency, sparsity priors, and cross-view alignment, using a compact 0.67M-parameter model.", "result": "Achieves 21.4 dB PSNR with 8 views, outperforming prior methods, but reveals a 5.7-6.2 dB generalization gap.", "conclusion": "PhysicsNeRF enables physically consistent 3D representations and clarifies trade-offs in constrained NeRF models."}}
{"id": "2505.23564", "pdf": "https://arxiv.org/pdf/2505.23564", "abs": "https://arxiv.org/abs/2505.23564", "authors": ["Yiran Guo", "Lijie Xu", "Jie Liu", "Dan Ye", "Shuang Qiu"], "title": "Segment Policy Optimization: Effective Segment-Level Credit Assignment in RL for Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Enhancing the reasoning capabilities of large language models effectively\nusing reinforcement learning (RL) remains a crucial challenge. Existing\napproaches primarily adopt two contrasting advantage estimation granularities:\nToken-level methods (e.g., PPO) aim to provide the fine-grained advantage\nsignals but suffer from inaccurate estimation due to difficulties in training\nan accurate critic model. On the other extreme, trajectory-level methods (e.g.,\nGRPO) solely rely on a coarse-grained advantage signal from the final reward,\nleading to imprecise credit assignment. To address these limitations, we\npropose Segment Policy Optimization (SPO), a novel RL framework that leverages\nsegment-level advantage estimation at an intermediate granularity, achieving a\nbetter balance by offering more precise credit assignment than trajectory-level\nmethods and requiring fewer estimation points than token-level methods,\nenabling accurate advantage estimation based on Monte Carlo (MC) without a\ncritic model. SPO features three components with novel strategies: (1) flexible\nsegment partition; (2) accurate segment advantage estimation; and (3) policy\noptimization using segment advantages, including a novel probability-mask\nstrategy. We further instantiate SPO for two specific scenarios: (1) SPO-chain\nfor short chain-of-thought (CoT), featuring novel cutpoint-based partition and\nchain-based advantage estimation, achieving $6$-$12$ percentage point\nimprovements in accuracy over PPO and GRPO on GSM8K. (2) SPO-tree for long CoT,\nfeaturing novel tree-based advantage estimation, which significantly reduces\nthe cost of MC estimation, achieving $7$-$11$ percentage point improvements\nover GRPO on MATH500 under 2K and 4K context evaluation. We make our code\npublicly available at https://github.com/AIFrameResearch/SPO.", "AI": {"tldr": "SPO is a novel RL framework for enhancing reasoning in large language models by balancing token and trajectory-level advantage estimation with segment-level granularity.", "motivation": "Addressing the limitations of existing RL methods (token-level and trajectory-level) in accurately estimating advantages for reasoning tasks.", "method": "Proposes Segment Policy Optimization (SPO) with flexible segment partition, accurate advantage estimation, and policy optimization. Includes SPO-chain for short CoT and SPO-tree for long CoT.", "result": "Achieves 6-12 percentage point improvements over PPO and GRPO on GSM8K, and 7-11 percentage points on MATH500.", "conclusion": "SPO effectively balances granularity for precise credit assignment, outperforming existing methods in reasoning tasks."}}
{"id": "2505.23459", "pdf": "https://arxiv.org/pdf/2505.23459", "abs": "https://arxiv.org/abs/2505.23459", "authors": ["Safwan Labbi", "Paul Mangold", "Daniil Tiapkin", "Eric Moulines"], "title": "On Global Convergence Rates for Federated Policy Gradient under Heterogeneous Environment", "categories": ["cs.LG"], "comment": "Preprint", "summary": "Ensuring convergence of policy gradient methods in federated reinforcement\nlearning (FRL) under environment heterogeneity remains a major challenge. In\nthis work, we first establish that heterogeneity, perhaps counter-intuitively,\ncan necessitate optimal policies to be non-deterministic or even time-varying,\neven in tabular environments. Subsequently, we prove global convergence results\nfor federated policy gradient (FedPG) algorithms employing local updates, under\na {\\L}ojasiewicz condition that holds only for each individual agent, in both\nentropy-regularized and non-regularized scenarios. Crucially, our theoretical\nanalysis shows that FedPG attains linear speed-up with respect to the number of\nagents, a property central to efficient federated learning. Leveraging insights\nfrom our theoretical findings, we introduce b-RS-FedPG, a novel policy gradient\nmethod that employs a carefully constructed softmax-inspired parameterization\ncoupled with an appropriate regularization scheme. We further demonstrate\nexplicit convergence rates for b-RS-FedPG toward near-optimal stationary\npolicies. Finally, we demonstrate that empirically both FedPG and b-RS-FedPG\nconsistently outperform federated Q-learning on heterogeneous settings.", "AI": {"tldr": "The paper addresses convergence challenges in federated reinforcement learning (FRL) under heterogeneous environments, proposing FedPG and b-RS-FedPG methods with proven convergence and empirical superiority over federated Q-learning.", "motivation": "Heterogeneity in FRL can lead to non-deterministic optimal policies, necessitating new methods to ensure convergence.", "method": "The paper introduces FedPG and b-RS-FedPG, leveraging local updates and regularization, with theoretical proofs of convergence and speed-up properties.", "result": "FedPG achieves linear speed-up with agent count, and b-RS-FedPG demonstrates explicit convergence rates to near-optimal policies. Both outperform federated Q-learning empirically.", "conclusion": "The proposed methods effectively address heterogeneity in FRL, offering theoretical guarantees and empirical performance improvements."}}
{"id": "2505.23688", "pdf": "https://arxiv.org/pdf/2505.23688", "abs": "https://arxiv.org/abs/2505.23688", "authors": ["James Tanner", "Morgan Sonderegger", "Jane Stuart-Smith", "Jeff Mielke", "Tyler Kendall"], "title": "Automatic classification of stop realisation with wav2vec2.0", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted for Interspeech 2025. 5 pages, 3 figures", "summary": "Modern phonetic research regularly makes use of automatic tools for the\nannotation of speech data, however few tools exist for the annotation of many\nvariable phonetic phenomena. At the same time, pre-trained self-supervised\nmodels, such as wav2vec2.0, have been shown to perform well at speech\nclassification tasks and latently encode fine-grained phonetic information. We\ndemonstrate that wav2vec2.0 models can be trained to automatically classify\nstop burst presence with high accuracy in both English and Japanese, robust\nacross both finely-curated and unprepared speech corpora. Patterns of\nvariability in stop realisation are replicated with the automatic annotations,\nand closely follow those of manual annotations. These results demonstrate the\npotential of pre-trained speech models as tools for the automatic annotation\nand processing of speech corpus data, enabling researchers to `scale-up' the\nscope of phonetic research with relative ease.", "AI": {"tldr": "The paper shows that wav2vec2.0 models can accurately classify stop burst presence in English and Japanese, replicating manual annotation patterns and enabling scalable phonetic research.", "motivation": "There is a lack of tools for annotating variable phonetic phenomena, despite the widespread use of automatic tools in phonetic research.", "method": "The study uses pre-trained wav2vec2.0 models to classify stop burst presence in speech data from English and Japanese corpora.", "result": "The models achieve high accuracy in classification, replicating variability patterns seen in manual annotations.", "conclusion": "Pre-trained speech models like wav2vec2.0 can automate speech corpus annotation, expanding the scope of phonetic research."}}
{"id": "2505.23484", "pdf": "https://arxiv.org/pdf/2505.23484", "abs": "https://arxiv.org/abs/2505.23484", "authors": ["Shi-Xue Zhang", "Hongfa Wang", "Duojun Huang", "Xin Li", "Xiaobin Zhu", "Xu-Cheng Yin"], "title": "VCapsBench: A Large-scale Fine-grained Benchmark for Video Caption Quality Evaluation", "categories": ["cs.CV"], "comment": "submitting", "summary": "Video captions play a crucial role in text-to-video generation tasks, as\ntheir quality directly influences the semantic coherence and visual fidelity of\nthe generated videos. Although large vision-language models (VLMs) have\ndemonstrated significant potential in caption generation, existing benchmarks\ninadequately address fine-grained evaluation, particularly in capturing\nspatial-temporal details critical for video generation. To address this gap, we\nintroduce the Fine-grained Video Caption Evaluation Benchmark (VCapsBench), the\nfirst large-scale fine-grained benchmark comprising 5,677 (5K+) videos and\n109,796 (100K+) question-answer pairs. These QA-pairs are systematically\nannotated across 21 fine-grained dimensions (e.g., camera movement, and shot\ntype) that are empirically proven critical for text-to-video generation. We\nfurther introduce three metrics (Accuracy (AR), Inconsistency Rate (IR),\nCoverage Rate (CR)), and an automated evaluation pipeline leveraging large\nlanguage model (LLM) to verify caption quality via contrastive QA-pairs\nanalysis. By providing actionable insights for caption optimization, our\nbenchmark can advance the development of robust text-to-video models. The\ndataset and codes are available at website: https://github.com/GXYM/VCapsBench.", "AI": {"tldr": "VCapsBench is a new benchmark for fine-grained evaluation of video captions, addressing gaps in existing benchmarks by focusing on spatial-temporal details critical for text-to-video generation.", "motivation": "Existing benchmarks lack fine-grained evaluation of video captions, especially for spatial-temporal details, which are crucial for text-to-video generation.", "method": "The benchmark includes 5,677 videos and 109,796 QA-pairs annotated across 21 fine-grained dimensions. It introduces three metrics (AR, IR, CR) and an automated evaluation pipeline using LLMs.", "result": "VCapsBench provides actionable insights for caption optimization, advancing robust text-to-video models.", "conclusion": "VCapsBench fills a critical gap in fine-grained caption evaluation, supporting better text-to-video generation."}}
{"id": "2505.23576", "pdf": "https://arxiv.org/pdf/2505.23576", "abs": "https://arxiv.org/abs/2505.23576", "authors": ["Jane Cleland-Huang", "Pedro Antonio Alarcon Granadeno", "Arturo Miguel Russell Bernal", "Demetrius Hernandez", "Michael Murphy", "Maureen Petterson", "Walter Scheirer"], "title": "Cognitive Guardrails for Open-World Decision Making in Autonomous Drone Swarms", "categories": ["cs.RO", "cs.AI", "cs.HC"], "comment": "16 pages, 8 figures", "summary": "Small Uncrewed Aerial Systems (sUAS) are increasingly deployed as autonomous\nswarms in search-and-rescue and other disaster-response scenarios. In these\nsettings, they use computer vision (CV) to detect objects of interest and\nautonomously adapt their missions. However, traditional CV systems often\nstruggle to recognize unfamiliar objects in open-world environments or to infer\ntheir relevance for mission planning. To address this, we incorporate large\nlanguage models (LLMs) to reason about detected objects and their implications.\nWhile LLMs can offer valuable insights, they are also prone to hallucinations\nand may produce incorrect, misleading, or unsafe recommendations. To ensure\nsafe and sensible decision-making under uncertainty, high-level decisions must\nbe governed by cognitive guardrails. This article presents the design,\nsimulation, and real-world integration of these guardrails for sUAS swarms in\nsearch-and-rescue missions.", "AI": {"tldr": "The paper proposes using large language models (LLMs) to enhance object recognition and mission adaptation in sUAS swarms for search-and-rescue, while introducing cognitive guardrails to mitigate LLM hallucinations and ensure safe decision-making.", "motivation": "Traditional CV systems struggle with unfamiliar objects and relevance inference in open-world environments, prompting the need for LLM integration and safeguards.", "method": "The study designs, simulates, and integrates cognitive guardrails into sUAS swarms to govern LLM-driven decisions.", "result": "The approach enables safer and more sensible autonomous mission adaptation by mitigating LLM hallucinations.", "conclusion": "Cognitive guardrails are essential for reliable LLM-assisted decision-making in sUAS swarms for disaster response."}}
{"id": "2505.23470", "pdf": "https://arxiv.org/pdf/2505.23470", "abs": "https://arxiv.org/abs/2505.23470", "authors": ["Chenjie Li", "Amir Gilad", "Boris Glavic", "Zhengjie Miao", "Sudeepa Roy"], "title": "Refining Labeling Functions with Limited Labeled Data", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": "techreport", "summary": "Programmatic weak supervision (PWS) significantly reduces human effort for\nlabeling data by combining the outputs of user-provided labeling functions\n(LFs) on unlabeled datapoints. However, the quality of the generated labels\ndepends directly on the accuracy of the LFs. In this work, we study the problem\nof fixing LFs based on a small set of labeled examples. Towards this goal, we\ndevelop novel techniques for repairing a set of LFs by minimally changing their\nresults on the labeled examples such that the fixed LFs ensure that (i) there\nis sufficient evidence for the correct label of each labeled datapoint and (ii)\nthe accuracy of each repaired LF is sufficiently high. We model LFs as\nconditional rules which enables us to refine them, i.e., to selectively change\ntheir output for some inputs. We demonstrate experimentally that our system\nimproves the quality of LFs based on surprisingly small sets of labeled\ndatapoints.", "AI": {"tldr": "The paper introduces techniques to repair labeling functions (LFs) in programmatic weak supervision (PWS) using minimal changes based on small labeled datasets, improving LF accuracy and label quality.", "motivation": "The quality of labels in PWS depends on LF accuracy, but LFs may be imperfect. The goal is to fix LFs using limited labeled data to enhance their reliability.", "method": "LFs are modeled as conditional rules, allowing selective refinement of their outputs on labeled examples to meet accuracy and evidence requirements.", "result": "Experimental results show the system effectively improves LF quality with surprisingly small labeled datasets.", "conclusion": "The proposed method successfully enhances LF accuracy and label quality in PWS, even with minimal labeled data."}}
{"id": "2505.23689", "pdf": "https://arxiv.org/pdf/2505.23689", "abs": "https://arxiv.org/abs/2505.23689", "authors": ["Francesca Padovani", "Jaap Jumelet", "Yevgen Matusevych", "Arianna Bisazza"], "title": "Child-Directed Language Does Not Consistently Boost Syntax Learning in Language Models", "categories": ["cs.CL"], "comment": "21 pages, 4 figures, 4 tables", "summary": "Seminal work by Huebner et al. (2021) showed that language models (LMs)\ntrained on English Child-Directed Language (CDL) can reach similar syntactic\nabilities as LMs trained on much larger amounts of adult-directed written text,\nsuggesting that CDL could provide more effective LM training material than the\ncommonly used internet-crawled data. However, the generalizability of these\nresults across languages, model types, and evaluation settings remains unclear.\nWe test this by comparing models trained on CDL vs. Wikipedia across two LM\nobjectives (masked and causal), three languages (English, French, German), and\nthree syntactic minimal-pair benchmarks. Our results on these benchmarks show\ninconsistent benefits of CDL, which in most cases is outperformed by Wikipedia\nmodels. We then identify various shortcomings in previous benchmarks, and\nintroduce a novel testing methodology, FIT-CLAMS, which uses a\nfrequency-controlled design to enable balanced comparisons across training\ncorpora. Through minimal pair evaluations and regression analysis we show that\ntraining on CDL does not yield stronger generalizations for acquiring syntax\nand highlight the importance of controlling for frequency effects when\nevaluating syntactic ability.", "AI": {"tldr": "CDL-trained LMs don't consistently outperform Wikipedia-trained models across languages, objectives, or benchmarks. A new method, FIT-CLAMS, addresses frequency biases in evaluations.", "motivation": "To test if CDL's benefits generalize across languages, model types, and evaluation settings, and to improve benchmarking methods.", "method": "Compared CDL vs. Wikipedia-trained models using masked/causal objectives, three languages, and syntactic benchmarks. Introduced FIT-CLAMS for balanced evaluations.", "result": "CDL rarely outperformed Wikipedia; FIT-CLAMS revealed frequency biases in prior benchmarks.", "conclusion": "CDL doesn't enhance syntactic generalization; frequency control is crucial for fair evaluations."}}
{"id": "2505.23493", "pdf": "https://arxiv.org/pdf/2505.23493", "abs": "https://arxiv.org/abs/2505.23493", "authors": ["Kaijie Chen", "Zihao Lin", "Zhiyang Xu", "Ying Shen", "Yuguang Yao", "Joy Rimchala", "Jiaxin Zhang", "Lifu Huang"], "title": "R2I-Bench: Benchmarking Reasoning-Driven Text-to-Image Generation", "categories": ["cs.CV", "cs.CL"], "comment": "Project Page: https://r2i-bench.github.io", "summary": "Reasoning is a fundamental capability often required in real-world\ntext-to-image (T2I) generation, e.g., generating ``a bitten apple that has been\nleft in the air for more than a week`` necessitates understanding temporal\ndecay and commonsense concepts. While recent T2I models have made impressive\nprogress in producing photorealistic images, their reasoning capability remains\nunderdeveloped and insufficiently evaluated. To bridge this gap, we introduce\nR2I-Bench, a comprehensive benchmark specifically designed to rigorously assess\nreasoning-driven T2I generation. R2I-Bench comprises meticulously curated data\ninstances, spanning core reasoning categories, including commonsense,\nmathematical, logical, compositional, numerical, causal, and concept mixing. To\nfacilitate fine-grained evaluation, we design R2IScore, a QA-style metric based\non instance-specific, reasoning-oriented evaluation questions that assess three\ncritical dimensions: text-image alignment, reasoning accuracy, and image\nquality. Extensive experiments with 16 representative T2I models, including a\nstrong pipeline-based framework that decouples reasoning and generation using\nthe state-of-the-art language and image generation models, demonstrate\nconsistently limited reasoning performance, highlighting the need for more\nrobust, reasoning-aware architectures in the next generation of T2I systems.\nProject Page: https://r2i-bench.github.io", "AI": {"tldr": "The paper introduces R2I-Bench, a benchmark to evaluate reasoning in text-to-image (T2I) generation, highlighting current models' limitations in reasoning despite photorealistic outputs.", "motivation": "Existing T2I models lack robust reasoning capabilities, necessitating a dedicated benchmark to assess and improve reasoning-driven generation.", "method": "R2I-Bench includes curated data across reasoning categories and R2IScore, a QA-style metric evaluating text-image alignment, reasoning accuracy, and image quality.", "result": "Experiments with 16 T2I models show limited reasoning performance, even with advanced pipeline-based frameworks.", "conclusion": "The findings underscore the need for reasoning-aware architectures in future T2I systems."}}
{"id": "2505.23580", "pdf": "https://arxiv.org/pdf/2505.23580", "abs": "https://arxiv.org/abs/2505.23580", "authors": ["Ramit Aditya", "Razvan Bunescu", "Smita Nannaware", "Erfan Al-Hossami"], "title": "Engineering Serendipity through Recommendations of Items with Atypical Aspects", "categories": ["cs.IR", "cs.AI"], "comment": "25 pages of content + references and appendix. arXiv admin note: text\n  overlap with arXiv:2311.02702", "summary": "A restaurant dinner or a hotel stay may lead to memorable experiences when\nguests encounter unexpected aspects that also match their interests. For\nexample, an origami-making station in the waiting area of a restaurant may be\nboth surprising and enjoyable for a customer who is passionate about paper\ncrafts. Similarly, an exhibit of 18th century harpsichords would be atypical\nfor a hotel lobby and likely pique the interest of a guest who has a passion\nfor Baroque music. Motivated by this insight, in this paper we introduce the\nnew task of engineering serendipity through recommendations of items with\natypical aspects. We describe an LLM-based system pipeline that extracts\natypical aspects from item reviews, then estimates and aggregates their\nuser-specific utility in a measure of serendipity potential that is used to\nrerank a list of items recommended to the user. To facilitate system\ndevelopment and evaluation, we introduce a dataset of Yelp reviews that are\nmanually annotated with atypical aspects and a dataset of artificially\ngenerated user profiles, together with crowdsourced annotations of user-aspect\nutility values. Furthermore, we introduce a custom procedure for dynamic\nselection of in-context learning examples, which is shown to improve LLM-based\njudgments of atypicality and utility. Experimental evaluations show that\nserendipity-based rankings generated by the system are highly correlated with\nground truth rankings for which serendipity scores are computed from manual\nannotations of atypical aspects and their user-dependent utility. Overall, we\nhope that the new recommendation task and the associated system presented in\nthis paper catalyze further research into recommendation approaches that go\nbeyond accuracy in their pursuit of enhanced user satisfaction.\n  The datasets and the code are made publicly available at\nhttps://github.com/ramituncc49er/ATARS .", "AI": {"tldr": "The paper introduces a system to engineer serendipity in recommendations by identifying atypical aspects in reviews and reranking items based on user-specific utility, using LLMs and annotated datasets.", "motivation": "To enhance user satisfaction by recommending items with unexpected yet personally relevant aspects, creating memorable experiences.", "method": "An LLM-based pipeline extracts atypical aspects from reviews, estimates their user-specific utility, and reranks recommendations using a serendipity potential measure. Datasets include annotated Yelp reviews and artificial user profiles.", "result": "The system's serendipity-based rankings align well with ground truth rankings derived from manual annotations.", "conclusion": "The work advances recommendation systems beyond accuracy, aiming to boost user satisfaction through serendipitous discoveries."}}
{"id": "2505.23489", "pdf": "https://arxiv.org/pdf/2505.23489", "abs": "https://arxiv.org/abs/2505.23489", "authors": ["Ildus Sadrtdinov", "Ivan Klimov", "Ekaterina Lobacheva", "Dmitry Vetrov"], "title": "SGD as Free Energy Minimization: A Thermodynamic View on Neural Network Training", "categories": ["cs.LG"], "comment": "First two authors contributed equally", "summary": "We present a thermodynamic interpretation of the stationary behavior of\nstochastic gradient descent (SGD) under fixed learning rates (LRs) in neural\nnetwork training. We show that SGD implicitly minimizes a free energy function\n$F=U-TS$, balancing training loss $U$ and the entropy of the weights\ndistribution $S$, with temperature $T$ determined by the LR. This perspective\noffers a new lens on why high LRs prevent training from converging to the loss\nminima and how different LRs lead to stabilization at different loss levels. We\nempirically validate the free energy framework on both underparameterized (UP)\nand overparameterized (OP) models. UP models consistently follow free energy\nminimization, with temperature increasing monotonically with LR, while for OP\nmodels, the temperature effectively drops to zero at low LRs, causing SGD to\nminimize the loss directly and converge to an optimum. We attribute this\nmismatch to differences in the signal-to-noise ratio of stochastic gradients\nnear optima, supported by both a toy example and neural network experiments.", "AI": {"tldr": "SGD's stationary behavior is interpreted thermodynamically, balancing loss and entropy, with LR acting as temperature. High LRs prevent convergence, while low LRs in OP models minimize loss directly.", "motivation": "To understand why SGD behaves differently under varying learning rates and how it balances loss and entropy in neural network training.", "method": "Thermodynamic framework applied to SGD, analyzing free energy minimization (F=U-TS) with empirical validation on UP and OP models.", "result": "UP models follow free energy minimization with temperature increasing with LR; OP models minimize loss directly at low LRs due to reduced gradient noise.", "conclusion": "The thermodynamic perspective explains SGD behavior, linking LR to temperature and highlighting differences in UP vs. OP models."}}
{"id": "2505.23701", "pdf": "https://arxiv.org/pdf/2505.23701", "abs": "https://arxiv.org/abs/2505.23701", "authors": ["Ziling Cheng", "Meng Cao", "Leila Pishdad", "Yanshuai Cao", "Jackie Chi Kit Cheung"], "title": "Can LLMs Reason Abstractly Over Math Word Problems Without CoT? Disentangling Abstract Formulation From Arithmetic Computation", "categories": ["cs.CL"], "comment": null, "summary": "Final-answer-based metrics are commonly used for evaluating large language\nmodels (LLMs) on math word problems, often taken as proxies for reasoning\nability. However, such metrics conflate two distinct sub-skills: abstract\nformulation (capturing mathematical relationships using expressions) and\narithmetic computation (executing the calculations). Through a disentangled\nevaluation on GSM8K and SVAMP, we find that the final-answer accuracy of\nLlama-3 and Qwen2.5 (1B-32B) without CoT is overwhelmingly bottlenecked by the\narithmetic computation step and not by the abstract formulation step. Contrary\nto the common belief, we show that CoT primarily aids in computation, with\nlimited impact on abstract formulation. Mechanistically, we show that these two\nskills are composed conjunctively even in a single forward pass without any\nreasoning steps via an abstract-then-compute mechanism: models first capture\nproblem abstractions, then handle computation. Causal patching confirms these\nabstractions are present, transferable, composable, and precede computation.\nThese behavioural and mechanistic findings highlight the need for disentangled\nevaluation to accurately assess LLM reasoning and to guide future improvements.", "AI": {"tldr": "Final-answer metrics conflate abstract formulation and arithmetic computation in LLMs. Disentangled evaluation reveals arithmetic bottlenecks, and CoT aids computation more than abstraction.", "motivation": "To clarify how final-answer metrics misrepresent reasoning by conflating abstract formulation and arithmetic computation.", "method": "Disentangled evaluation on GSM8K and SVAMP with Llama-3 and Qwen2.5 models, analyzing CoT impact and mechanistic abstraction-computation steps.", "result": "Arithmetic computation is the bottleneck; CoT mainly helps computation. Abstractions precede computation and are transferable.", "conclusion": "Disentangled evaluation is crucial for accurate LLM reasoning assessment and future improvements."}}
{"id": "2505.23504", "pdf": "https://arxiv.org/pdf/2505.23504", "abs": "https://arxiv.org/abs/2505.23504", "authors": ["Liyun Zhu", "Qixiang Chen", "Xi Shen", "Xiaodong Cun"], "title": "VAU-R1: Advancing Video Anomaly Understanding via Reinforcement Fine-Tuning", "categories": ["cs.CV"], "comment": null, "summary": "Video Anomaly Understanding (VAU) is essential for applications such as smart\ncities, security surveillance, and disaster alert systems, yet remains\nchallenging due to its demand for fine-grained spatio-temporal perception and\nrobust reasoning under ambiguity. Despite advances in anomaly detection,\nexisting methods often lack interpretability and struggle to capture the causal\nand contextual aspects of abnormal events. This limitation is further\ncompounded by the absence of comprehensive benchmarks for evaluating reasoning\nability in anomaly scenarios. To address both challenges, we introduce VAU-R1,\na data-efficient framework built upon Multimodal Large Language Models (MLLMs),\nwhich enhances anomaly reasoning through Reinforcement Fine-Tuning (RFT).\nBesides, we propose VAU-Bench, the first Chain-of-Thought benchmark tailored\nfor video anomaly reasoning, featuring multiple-choice QA, detailed rationales,\ntemporal annotations, and descriptive captions. Empirical results show that\nVAU-R1 significantly improves question answering accuracy, temporal grounding,\nand reasoning coherence across diverse contexts. Together, our method and\nbenchmark establish a strong foundation for interpretable and reasoning-aware\nvideo anomaly understanding. Our code is available at\nhttps://github.com/GVCLab/VAU-R1.", "AI": {"tldr": "The paper introduces VAU-R1, a framework for video anomaly understanding using Multimodal Large Language Models (MLLMs) and Reinforcement Fine-Tuning (RFT), along with VAU-Bench, a benchmark for evaluating anomaly reasoning.", "motivation": "Video Anomaly Understanding (VAU) is crucial for applications like smart cities and security but lacks interpretability and robust reasoning in existing methods. There's also a need for comprehensive benchmarks.", "method": "VAU-R1 leverages MLLMs and RFT for anomaly reasoning. VAU-Bench is introduced as a Chain-of-Thought benchmark with QA, rationales, annotations, and captions.", "result": "VAU-R1 improves QA accuracy, temporal grounding, and reasoning coherence.", "conclusion": "The framework and benchmark advance interpretable and reasoning-aware VAU, providing a foundation for future research."}}
{"id": "2505.23590", "pdf": "https://arxiv.org/pdf/2505.23590", "abs": "https://arxiv.org/abs/2505.23590", "authors": ["Zifu Wang", "Junyi Zhu", "Bo Tang", "Zhiyu Li", "Feiyu Xiong", "Jiaqian Yu", "Matthew B. Blaschko"], "title": "Jigsaw-R1: A Study of Rule-based Visual Reinforcement Learning with Jigsaw Puzzles", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "The application of rule-based reinforcement learning (RL) to multimodal large\nlanguage models (MLLMs) introduces unique challenges and potential deviations\nfrom findings in text-only domains, particularly for perception-heavy tasks.\nThis paper provides a comprehensive study of rule-based visual RL using jigsaw\npuzzles as a structured experimental framework, revealing several key findings.\n\\textit{Firstly,} we find that MLLMs, initially performing near to random\nguessing on simple puzzles, achieve near-perfect accuracy and generalize to\ncomplex, unseen configurations through fine-tuning. \\textit{Secondly,} training\non jigsaw puzzles can induce generalization to other visual tasks, with\neffectiveness tied to specific task configurations. \\textit{Thirdly,} MLLMs can\nlearn and generalize with or without explicit reasoning, though open-source\nmodels often favor direct answering. Consequently, even when trained for\nstep-by-step reasoning, they can ignore the thinking process in deriving the\nfinal answer. \\textit{Fourthly,} we observe that complex reasoning patterns\nappear to be pre-existing rather than emergent, with their frequency increasing\nalongside training and task difficulty. \\textit{Finally,} our results\ndemonstrate that RL exhibits more effective generalization than Supervised\nFine-Tuning (SFT), and an initial SFT cold start phase can hinder subsequent RL\noptimization. Although these observations are based on jigsaw puzzles and may\nvary across other visual tasks, this research contributes a valuable piece of\njigsaw to the larger puzzle of collective understanding rule-based visual RL\nand its potential in multimodal learning. The code is available at:\n\\href{https://github.com/zifuwanggg/Jigsaw-R1}{https://github.com/zifuwanggg/Jigsaw-R1}.", "AI": {"tldr": "The paper explores rule-based reinforcement learning (RL) in multimodal large language models (MLLMs) using jigsaw puzzles, showing improved accuracy, generalization, and insights into reasoning patterns. RL outperforms supervised fine-tuning (SFT).", "motivation": "To address challenges and deviations in applying rule-based RL to MLLMs for perception-heavy tasks, using jigsaw puzzles as a structured framework.", "method": "Fine-tuning MLLMs on jigsaw puzzles, analyzing performance, generalization, reasoning patterns, and comparing RL with SFT.", "result": "MLLMs achieve near-perfect accuracy, generalize to unseen puzzles and other tasks, and RL outperforms SFT. Reasoning patterns are pre-existing, not emergent.", "conclusion": "The study advances understanding of rule-based visual RL in MLLMs, highlighting RL's superiority over SFT and the role of task configurations in generalization."}}
{"id": "2505.23496", "pdf": "https://arxiv.org/pdf/2505.23496", "abs": "https://arxiv.org/abs/2505.23496", "authors": ["Sabina J. Sloman", "Michele Caprio", "Samuel Kaski"], "title": "Epistemic Errors of Imperfect Multitask Learners When Distributions Shift", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "When data are noisy, a statistical learner's goal is to resolve epistemic\nuncertainty about the data it will encounter at test-time, i.e., to identify\nthe distribution of test (target) data. Many real-world learning settings\nintroduce sources of epistemic uncertainty that can not be resolved on the\nbasis of training (source) data alone: The source data may arise from multiple\ntasks (multitask learning), the target data may differ systematically from the\nsource data tasks (distribution shift), and/or the learner may not arrive at an\naccurate characterization of the source data (imperfect learning). We introduce\na principled definition of epistemic error, and provide a generic,\ndecompositional epistemic error bound. Our error bound is the first to (i)\nconsider epistemic error specifically, (ii) accommodate all the sources of\nepistemic uncertainty above, and (iii) separately attribute the error to each\nof multiple aspects of the learning procedure and environment. As corollaries\nof the generic result, we provide (i) epistemic error bounds specialized to the\nsettings of Bayesian transfer learning and distribution shift within\n$\\epsilon$-neighborhoods, and (ii) a set of corresponding generalization\nbounds. Finally, we provide a novel definition of negative transfer, and\nvalidate its insights in a synthetic experimental setting.", "AI": {"tldr": "The paper introduces a principled definition of epistemic error and provides a generic error bound addressing multitask learning, distribution shift, and imperfect learning. It also offers specialized bounds for Bayesian transfer learning and distribution shift, along with a new definition of negative transfer.", "motivation": "To address unresolved epistemic uncertainty in noisy data settings, including multitask learning, distribution shift, and imperfect learning.", "method": "Introduces a decompositional epistemic error bound and derives specialized bounds for Bayesian transfer learning and distribution shift.", "result": "Provides the first epistemic error bound accommodating multiple uncertainty sources and attributes error to specific learning aspects. Also defines negative transfer.", "conclusion": "The framework offers insights into epistemic error and validates the negative transfer definition experimentally."}}
{"id": "2505.23713", "pdf": "https://arxiv.org/pdf/2505.23713", "abs": "https://arxiv.org/abs/2505.23713", "authors": ["Zixiang Xu", "Yanbo Wang", "Yue Huang", "Jiayi Ye", "Haomin Zhuang", "Zirui Song", "Lang Gao", "Chenxi Wang", "Zhaorun Chen", "Yujun Zhou", "Sixian Li", "Wang Pan", "Yue Zhao", "Jieyu Zhao", "Xiangliang Zhang", "Xiuying Chen"], "title": "SocialMaze: A Benchmark for Evaluating Social Reasoning in Large Language Models", "categories": ["cs.CL"], "comment": "Code available at https://github.com/xzx34/SocialMaze", "summary": "Large language models (LLMs) are increasingly applied to socially grounded\ntasks, such as online community moderation, media content analysis, and social\nreasoning games. Success in these contexts depends on a model's social\nreasoning ability - the capacity to interpret social contexts, infer others'\nmental states, and assess the truthfulness of presented information. However,\nthere is currently no systematic evaluation framework that comprehensively\nassesses the social reasoning capabilities of LLMs. Existing efforts often\noversimplify real-world scenarios and consist of tasks that are too basic to\nchallenge advanced models. To address this gap, we introduce SocialMaze, a new\nbenchmark specifically designed to evaluate social reasoning. SocialMaze\nsystematically incorporates three core challenges: deep reasoning, dynamic\ninteraction, and information uncertainty. It provides six diverse tasks across\nthree key settings: social reasoning games, daily-life interactions, and\ndigital community platforms. Both automated and human validation are used to\nensure data quality. Our evaluation reveals several key insights: models vary\nsubstantially in their ability to handle dynamic interactions and integrate\ntemporally evolving information; models with strong chain-of-thought reasoning\nperform better on tasks requiring deeper inference beyond surface-level cues;\nand model reasoning degrades significantly under uncertainty. Furthermore, we\nshow that targeted fine-tuning on curated reasoning examples can greatly\nimprove model performance in complex social scenarios. The dataset is publicly\navailable at: https://huggingface.co/datasets/MBZUAI/SocialMaze", "AI": {"tldr": "SocialMaze is a new benchmark for evaluating LLMs' social reasoning abilities, addressing gaps in existing frameworks by incorporating deep reasoning, dynamic interaction, and uncertainty.", "motivation": "Existing evaluations oversimplify social scenarios, lacking depth to challenge advanced LLMs.", "method": "Introduces SocialMaze with six tasks across three settings, using automated and human validation.", "result": "Models vary in handling dynamics and uncertainty; chain-of-thought reasoning aids deeper inference; fine-tuning improves performance.", "conclusion": "SocialMaze fills a critical gap, enabling better assessment and improvement of LLMs' social reasoning."}}
{"id": "2505.23522", "pdf": "https://arxiv.org/pdf/2505.23522", "abs": "https://arxiv.org/abs/2505.23522", "authors": ["Fengxiang Wang", "Mingshuo Chen", "Xuming He", "YiFan Zhang", "Feng Liu", "Zijie Guo", "Zhenghao Hu", "Jiong Wang", "Jingyi Xu", "Zhangrui Li", "Fenghua Ling", "Ben Fei", "Weijia Li", "Long Lan", "Wenjing Yang", "Wenlong Zhang", "Lei Bai"], "title": "OmniEarth-Bench: Towards Holistic Evaluation of Earth's Six Spheres and Cross-Spheres Interactions with Multimodal Observational Earth Data", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Existing benchmarks for Earth science multimodal learning exhibit critical\nlimitations in systematic coverage of geosystem components and cross-sphere\ninteractions, often constrained to isolated subsystems (only in\nHuman-activities sphere or atmosphere) with limited evaluation dimensions (less\nthan 16 tasks). To address these gaps, we introduce OmniEarth-Bench, the first\ncomprehensive multimodal benchmark spanning all six Earth science spheres\n(atmosphere, lithosphere, Oceansphere, cryosphere, biosphere and\nHuman-activities sphere) and cross-spheres with one hundred expert-curated\nevaluation dimensions. Leveraging observational data from satellite sensors and\nin-situ measurements, OmniEarth-Bench integrates 29,779 annotations across four\ntiers: perception, general reasoning, scientific knowledge reasoning and\nchain-of-thought (CoT) reasoning. This involves the efforts of 2-5 experts per\nsphere to establish authoritative evaluation dimensions and curate relevant\nobservational datasets, 40 crowd-sourcing annotators to assist experts for\nannotations, and finally, OmniEarth-Bench is validated via hybrid expert-crowd\nworkflows to reduce label ambiguity. Experiments on 9 state-of-the-art MLLMs\nreveal that even the most advanced models struggle with our benchmarks, where\nnone of them reach 35\\% accuracy. Especially, in some cross-spheres tasks, the\nperformance of leading models like GPT-4o drops to 0.0\\%. OmniEarth-Bench sets\na new standard for geosystem-aware AI, advancing both scientific discovery and\npractical applications in environmental monitoring and disaster prediction. The\ndataset, source code, and trained models were released.", "AI": {"tldr": "OmniEarth-Bench is a comprehensive multimodal benchmark for Earth science, covering all six spheres and cross-sphere interactions with 100 evaluation dimensions. It reveals limitations in current MLLMs, with none achieving over 35% accuracy.", "motivation": "Addressing gaps in existing benchmarks, which lack systematic coverage of Earth's spheres and cross-sphere interactions, and limited evaluation dimensions.", "method": "Leverages observational data from satellites and in-situ measurements, integrating 29,779 annotations across four reasoning tiers. Involves expert curation and crowd-sourcing for validation.", "result": "Tests on 9 MLLMs show poor performance, with none exceeding 35% accuracy. GPT-4o drops to 0% in some cross-sphere tasks.", "conclusion": "OmniEarth-Bench sets a new standard for geosystem-aware AI, aiding scientific discovery and practical applications like environmental monitoring."}}
{"id": "2505.23595", "pdf": "https://arxiv.org/pdf/2505.23595", "abs": "https://arxiv.org/abs/2505.23595", "authors": ["Youssef Mohamed", "Noran Mohamed", "Khaled Abouhashad", "Feilong Tang", "Sara Atito", "Shoaib Jameel", "Imran Razzak", "Ahmed B. Zaky"], "title": "DeepChest: Dynamic Gradient-Free Task Weighting for Effective Multi-Task Learning in Chest X-ray Classification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "While Multi-Task Learning (MTL) offers inherent advantages in complex domains\nsuch as medical imaging by enabling shared representation learning, effectively\nbalancing task contributions remains a significant challenge. This paper\naddresses this critical issue by introducing DeepChest, a novel,\ncomputationally efficient and effective dynamic task-weighting framework\nspecifically designed for multi-label chest X-ray (CXR) classification. Unlike\nexisting heuristic or gradient-based methods that often incur substantial\noverhead, DeepChest leverages a performance-driven weighting mechanism based on\neffective analysis of task-specific loss trends. Given a network architecture\n(e.g., ResNet18), our model-agnostic approach adaptively adjusts task\nimportance without requiring gradient access, thereby significantly reducing\nmemory usage and achieving a threefold increase in training speed. It can be\neasily applied to improve various state-of-the-art methods. Extensive\nexperiments on a large-scale CXR dataset demonstrate that DeepChest not only\noutperforms state-of-the-art MTL methods by 7% in overall accuracy but also\nyields substantial reductions in individual task losses, indicating improved\ngeneralization and effective mitigation of negative transfer. The efficiency\nand performance gains of DeepChest pave the way for more practical and robust\ndeployment of deep learning in critical medical diagnostic applications. The\ncode is publicly available at https://github.com/youssefkhalil320/DeepChest-MTL", "AI": {"tldr": "DeepChest is a dynamic task-weighting framework for multi-label chest X-ray classification, improving efficiency and accuracy over existing MTL methods.", "motivation": "Balancing task contributions in Multi-Task Learning (MTL) for medical imaging is challenging; DeepChest addresses this by optimizing task weights without gradient access.", "method": "DeepChest uses a performance-driven weighting mechanism based on task-specific loss trends, adapting task importance dynamically and reducing memory usage.", "result": "Outperforms state-of-the-art MTL methods by 7% in accuracy, with faster training and reduced task losses.", "conclusion": "DeepChest enhances MTL efficiency and performance, enabling practical deployment in medical diagnostics."}}
{"id": "2505.23506", "pdf": "https://arxiv.org/pdf/2505.23506", "abs": "https://arxiv.org/abs/2505.23506", "authors": ["Sebasti\u00e1n Jim\u00e9nez", "Mira J\u00fcrgens", "Willem Waegeman"], "title": "Why Machine Learning Models Fail to Fully Capture Epistemic Uncertainty", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In recent years various supervised learning methods that disentangle\naleatoric and epistemic uncertainty based on second-order distributions have\nbeen proposed. We argue that these methods fail to capture critical components\nof epistemic uncertainty, particularly due to the often-neglected component of\nmodel bias. To show this, we make use of a more fine-grained taxonomy of\nepistemic uncertainty sources in machine learning models, and analyse how the\nclassical bias-variance decomposition of the expected prediction error can be\ndecomposed into different parts reflecting these uncertainties. By using a\nsimulation-based evaluation protocol which encompasses epistemic uncertainty\ndue to both procedural- and data-driven uncertainty components, we illustrate\nthat current methods rarely capture the full spectrum of epistemic uncertainty.\nThrough theoretical insights and synthetic experiments, we show that high model\nbias can lead to misleadingly low estimates of epistemic uncertainty, and\ncommon second-order uncertainty quantification methods systematically blur\nbias-induced errors into aleatoric estimates, thereby underrepresenting\nepistemic uncertainty. Our findings underscore that meaningful aleatoric\nestimates are feasible only if all relevant sources of epistemic uncertainty\nare properly represented.", "AI": {"tldr": "Current methods for disentangling aleatoric and epistemic uncertainty often miss model bias, leading to incomplete epistemic uncertainty estimates. A fine-grained taxonomy and simulation-based evaluation reveal these gaps.", "motivation": "To address the limitations of existing methods in capturing the full spectrum of epistemic uncertainty, particularly model bias, which is often overlooked.", "method": "Uses a fine-grained taxonomy of epistemic uncertainty sources and a simulation-based evaluation protocol to analyze bias-variance decomposition.", "result": "Current methods underestimate epistemic uncertainty by blurring bias-induced errors into aleatoric estimates.", "conclusion": "Accurate aleatoric uncertainty estimation requires proper representation of all epistemic uncertainty sources, including model bias."}}
{"id": "2505.23714", "pdf": "https://arxiv.org/pdf/2505.23714", "abs": "https://arxiv.org/abs/2505.23714", "authors": ["Roksana Goworek", "Harpal Karlcut", "Muhammad Shezad", "Nijaguna Darshana", "Abhishek Mane", "Syam Bondada", "Raghav Sikka", "Ulvi Mammadov", "Rauf Allahverdiyev", "Sriram Purighella", "Paridhi Gupta", "Muhinyia Ndegwa", "Haim Dubossarsky"], "title": "SenWiCh: Sense-Annotation of Low-Resource Languages for WiC using Hybrid Methods", "categories": ["cs.CL", "cs.AI"], "comment": "8 pages, 22 figures, submitted to SIGTYP 2025 workshop in ACL", "summary": "This paper addresses the critical need for high-quality evaluation datasets\nin low-resource languages to advance cross-lingual transfer. While\ncross-lingual transfer offers a key strategy for leveraging multilingual\npretraining to expand language technologies to understudied and typologically\ndiverse languages, its effectiveness is dependent on quality and suitable\nbenchmarks. We release new sense-annotated datasets of sentences containing\npolysemous words, spanning nine low-resource languages across diverse language\nfamilies and scripts. To facilitate dataset creation, the paper presents a\ndemonstrably beneficial semi-automatic annotation method. The utility of the\ndatasets is demonstrated through Word-in-Context (WiC) formatted experiments\nthat evaluate transfer on these low-resource languages. Results highlight the\nimportance of targeted dataset creation and evaluation for effective polysemy\ndisambiguation in low-resource settings and transfer studies. The released\ndatasets and code aim to support further research into fair, robust, and truly\nmultilingual NLP.", "AI": {"tldr": "The paper introduces new sense-annotated datasets for nine low-resource languages to improve cross-lingual transfer, along with a semi-automatic annotation method. It demonstrates their utility through WiC experiments, emphasizing the need for targeted datasets in polysemy disambiguation.", "motivation": "To address the lack of high-quality evaluation datasets in low-resource languages, which is crucial for advancing cross-lingual transfer and multilingual NLP.", "method": "A semi-automatic annotation method is proposed to create sense-annotated datasets for polysemous words in nine low-resource languages.", "result": "The datasets and method prove effective in WiC experiments, highlighting the importance of tailored datasets for polysemy disambiguation in low-resource settings.", "conclusion": "The released datasets and code aim to support fair and robust multilingual NLP research, emphasizing the need for targeted evaluation benchmarks."}}
{"id": "2505.23524", "pdf": "https://arxiv.org/pdf/2505.23524", "abs": "https://arxiv.org/abs/2505.23524", "authors": ["Rui Xia", "Dan Jiang", "Quan Zhang", "Ke Zhang", "Chun Yuan"], "title": "CLIP-AE: CLIP-assisted Cross-view Audio-Visual Enhancement for Unsupervised Temporal Action Localization", "categories": ["cs.CV"], "comment": null, "summary": "Temporal Action Localization (TAL) has garnered significant attention in\ninformation retrieval. Existing supervised or weakly supervised methods heavily\nrely on labeled temporal boundaries and action categories, which are\nlabor-intensive and time-consuming. Consequently, unsupervised temporal action\nlocalization (UTAL) has gained popularity. However, current methods face two\nmain challenges: 1) Classification pre-trained features overly focus on highly\ndiscriminative regions; 2) Solely relying on visual modality information makes\nit difficult to determine contextual boundaries. To address these issues, we\npropose a CLIP-assisted cross-view audiovisual enhanced UTAL method.\nSpecifically, we introduce visual language pre-training (VLP) and\nclassification pre-training-based collaborative enhancement to avoid excessive\nfocus on highly discriminative regions; we also incorporate audio perception to\nprovide richer contextual boundary information. Finally, we introduce a\nself-supervised cross-view learning paradigm to achieve multi-view perceptual\nenhancement without additional annotations. Extensive experiments on two public\ndatasets demonstrate our model's superiority over several state-of-the-art\ncompetitors.", "AI": {"tldr": "Proposes a CLIP-assisted cross-view audiovisual method for unsupervised temporal action localization (UTAL) to address challenges of feature focus and contextual boundaries.", "motivation": "Existing TAL methods rely on labeled data, which is costly, and current UTAL methods struggle with feature focus and contextual boundaries.", "method": "Uses visual language pre-training (VLP) and classification pre-training for balanced feature focus, adds audio for context, and employs self-supervised cross-view learning.", "result": "Outperforms state-of-the-art methods on two public datasets.", "conclusion": "The proposed method effectively enhances UTAL by addressing key challenges without extra annotations."}}
{"id": "2505.23617", "pdf": "https://arxiv.org/pdf/2505.23617", "abs": "https://arxiv.org/abs/2505.23617", "authors": ["Chenhao Zheng", "Jieyu Zhang", "Mohammadreza Salehi", "Ziqi Gao", "Vishnu Iyengar", "Norimasa Kobori", "Quan Kong", "Ranjay Krishna"], "title": "One Trajectory, One Token: Grounded Video Tokenization via Panoptic Sub-object Trajectory", "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.LG"], "comment": null, "summary": "Effective video tokenization is critical for scaling transformer models for\nlong videos. Current approaches tokenize videos using space-time patches,\nleading to excessive tokens and computational inefficiencies. The best token\nreduction strategies degrade performance and barely reduce the number of tokens\nwhen the camera moves. We introduce grounded video tokenization, a paradigm\nthat organizes tokens based on panoptic sub-object trajectories rather than\nfixed patches. Our method aligns with fundamental perceptual principles,\nensuring that tokenization reflects scene complexity rather than video\nduration. We propose TrajViT, a video encoder that extracts object trajectories\nand converts them into semantically meaningful tokens, significantly reducing\nredundancy while maintaining temporal coherence. Trained with contrastive\nlearning, TrajViT significantly outperforms space-time ViT (ViT3D) across\nmultiple video understanding benchmarks, e.g., TrajViT outperforms ViT3D by a\nlarge margin of 6% top-5 recall in average at video-text retrieval task with\n10x token deduction. We also show TrajViT as a stronger model than ViT3D for\nbeing the video encoder for modern VideoLLM, obtaining an average of 5.2%\nperformance improvement across 6 VideoQA benchmarks while having 4x faster\ntraining time and 18x less inference FLOPs. TrajViT is the first efficient\nencoder to consistently outperform ViT3D across diverse video analysis tasks,\nmaking it a robust and scalable solution.", "AI": {"tldr": "TrajViT introduces grounded video tokenization using object trajectories, reducing tokens and improving performance over space-time ViTs.", "motivation": "Current video tokenization methods are inefficient, producing excessive tokens and degrading performance with camera movement.", "method": "TrajViT organizes tokens based on panoptic sub-object trajectories, ensuring semantic relevance and temporal coherence.", "result": "TrajViT outperforms ViT3D by 6% in video-text retrieval and 5.2% in VideoQA, with 10x fewer tokens and 18x less FLOPs.", "conclusion": "TrajViT is a scalable, efficient video encoder that consistently outperforms ViT3D across tasks."}}
{"id": "2505.23520", "pdf": "https://arxiv.org/pdf/2505.23520", "abs": "https://arxiv.org/abs/2505.23520", "authors": ["Yu Zhang", "Dong Guo", "Fang Wu", "Guoliang Zhu", "Dian Ding", "Yiming Zhang"], "title": "AnchorAttention: Difference-Aware Sparse Attention with Stripe Granularity", "categories": ["cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) with extended context lengths face significant\ncomputational challenges during the pre-filling phase, primarily due to the\nquadratic complexity of self-attention. Existing methods typically employ\ndynamic pattern matching and block-sparse low-level implementations. However,\ntheir reliance on local information for pattern identification fails to capture\nglobal contexts, and the coarse granularity of blocks leads to persistent\ninternal sparsity, resulting in suboptimal accuracy and efficiency. To address\nthese limitations, we propose \\textbf{AnchorAttention}, a difference-aware,\ndynamic sparse attention mechanism that efficiently identifies critical\nattention regions at a finer stripe granularity while adapting to global\ncontextual information, achieving superior speed and accuracy. AnchorAttention\ncomprises three key components: (1) \\textbf{Pattern-based Anchor Computation},\nleveraging the commonalities present across all inputs to rapidly compute a set\nof near-maximum scores as the anchor; (2) \\textbf{Difference-aware Stripe\nSparsity Identification}, performing difference-aware comparisons with the\nanchor to quickly obtain discrete coordinates of significant regions in a\nstripe-like sparsity pattern; (3) \\textbf{Fine-grained Sparse Computation},\nreplacing the traditional contiguous KV block loading approach with\nsimultaneous discrete KV position loading to maximize sparsity rates while\npreserving full hardware computational potential. With its finer-grained\nsparsity strategy, \\textbf{AnchorAttention} achieves higher sparsity rates at\nthe same recall level, significantly reducing computation time. Compared to\nprevious state-of-the-art methods, at a text length of 128k, it achieves a\nspeedup of 1.44$\\times$ while maintaining higher recall rates.", "AI": {"tldr": "AnchorAttention is a dynamic sparse attention mechanism for LLMs, improving speed and accuracy by identifying critical attention regions at finer granularity.", "motivation": "Existing methods for LLMs' pre-filling phase suffer from inefficiency due to quadratic complexity of self-attention and coarse granularity, leading to suboptimal performance.", "method": "AnchorAttention uses pattern-based anchor computation, difference-aware stripe sparsity identification, and fine-grained sparse computation to optimize attention regions.", "result": "At 128k text length, AnchorAttention achieves a 1.44\u00d7 speedup while maintaining higher recall rates compared to prior methods.", "conclusion": "AnchorAttention offers a superior approach to sparse attention in LLMs, balancing efficiency and accuracy effectively."}}
{"id": "2505.23715", "pdf": "https://arxiv.org/pdf/2505.23715", "abs": "https://arxiv.org/abs/2505.23715", "authors": ["Jinzhe Li", "Gengxu Li", "Yi Chang", "Yuan Wu"], "title": "Don't Take the Premise for Granted: Evaluating the Premise Critique Ability of Large Language Models", "categories": ["cs.CL"], "comment": "31 pages,13 figures,15 tables", "summary": "Large language models (LLMs) have witnessed rapid advancements, demonstrating\nremarkable capabilities. However, a notable vulnerability persists: LLMs often\nuncritically accept flawed or contradictory premises, leading to inefficient\nreasoning and unreliable outputs. This emphasizes the significance of\npossessing the \\textbf{Premise Critique Ability} for LLMs, defined as the\ncapacity to proactively identify and articulate errors in input premises. Most\nexisting studies assess LLMs' reasoning ability in ideal settings, largely\nignoring their vulnerabilities when faced with flawed premises. Thus, we\nintroduce the \\textbf{Premise Critique Bench (PCBench)}, designed by\nincorporating four error types across three difficulty levels, paired with\nmulti-faceted evaluation metrics. We conducted systematic evaluations of 15\nrepresentative LLMs. Our findings reveal: (1) Most models rely heavily on\nexplicit prompts to detect errors, with limited autonomous critique; (2)\nPremise critique ability depends on question difficulty and error type, with\ndirect contradictions being easier to detect than complex or procedural errors;\n(3) Reasoning ability does not consistently correlate with the premise critique\nability; (4) Flawed premises trigger overthinking in reasoning models, markedly\nlengthening responses due to repeated attempts at resolving conflicts. These\ninsights underscore the urgent need to enhance LLMs' proactive evaluation of\ninput validity, positioning premise critique as a foundational capability for\ndeveloping reliable, human-centric systems. The code is available at\nhttps://github.com/MLGroupJLU/Premise_Critique.", "AI": {"tldr": "The paper introduces PCBench to evaluate LLMs' ability to critique flawed premises, revealing gaps in autonomous error detection and overthinking in reasoning models.", "motivation": "LLMs often accept flawed premises uncritically, leading to unreliable outputs, highlighting the need for premise critique ability.", "method": "PCBench incorporates four error types across three difficulty levels, evaluating 15 LLMs with multi-faceted metrics.", "result": "Most models need explicit prompts for error detection, critique ability varies by difficulty/error type, and flawed premises cause overthinking.", "conclusion": "Enhancing LLMs' premise critique ability is crucial for reliable, human-centric systems."}}
{"id": "2505.23525", "pdf": "https://arxiv.org/pdf/2505.23525", "abs": "https://arxiv.org/abs/2505.23525", "authors": ["Jiahao Cui", "Yan Chen", "Mingwang Xu", "Hanlin Shang", "Yuxuan Chen", "Yun Zhan", "Zilong Dong", "Yao Yao", "Jingdong Wang", "Siyu Zhu"], "title": "Hallo4: High-Fidelity Dynamic Portrait Animation via Direct Preference Optimization and Temporal Motion Modulation", "categories": ["cs.CV"], "comment": null, "summary": "Generating highly dynamic and photorealistic portrait animations driven by\naudio and skeletal motion remains challenging due to the need for precise lip\nsynchronization, natural facial expressions, and high-fidelity body motion\ndynamics. We propose a human-preference-aligned diffusion framework that\naddresses these challenges through two key innovations. First, we introduce\ndirect preference optimization tailored for human-centric animation, leveraging\na curated dataset of human preferences to align generated outputs with\nperceptual metrics for portrait motion-video alignment and naturalness of\nexpression. Second, the proposed temporal motion modulation resolves\nspatiotemporal resolution mismatches by reshaping motion conditions into\ndimensionally aligned latent features through temporal channel redistribution\nand proportional feature expansion, preserving the fidelity of high-frequency\nmotion details in diffusion-based synthesis. The proposed mechanism is\ncomplementary to existing UNet and DiT-based portrait diffusion approaches, and\nexperiments demonstrate obvious improvements in lip-audio synchronization,\nexpression vividness, body motion coherence over baseline methods, alongside\nnotable gains in human preference metrics. Our model and source code can be\nfound at: https://github.com/xyz123xyz456/hallo4.", "AI": {"tldr": "A diffusion framework for photorealistic portrait animations aligns with human preferences and improves lip sync, expressions, and motion dynamics.", "motivation": "Challenges in achieving precise lip sync, natural facial expressions, and high-fidelity body motion in portrait animations.", "method": "Uses human-preference-aligned diffusion with direct preference optimization and temporal motion modulation.", "result": "Improves lip-audio sync, expression vividness, motion coherence, and human preference metrics over baselines.", "conclusion": "The framework effectively enhances portrait animation quality and aligns with human perceptual preferences."}}
{"id": "2505.23624", "pdf": "https://arxiv.org/pdf/2505.23624", "abs": "https://arxiv.org/abs/2505.23624", "authors": ["Giacomo Bergami", "Emma Packer", "Kirsty Scott", "Silvia Del Din"], "title": "Towards Explainable Sequential Learning", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "This paper offers a hybrid explainable temporal data processing pipeline,\nDataFul Explainable MultivariatE coRrelatIonal Temporal Artificial inTElligence\n(EMeriTAte+DF), bridging numerical-driven temporal data classification with an\nevent-based one through verified artificial intelligence principles, enabling\nhuman-explainable results. This was possible through a preliminary a posteriori\nexplainable phase describing the numerical input data in terms of concurrent\nconstituents with numerical payloads. This further required extending the\nevent-based literature to design specification mining algorithms supporting\nconcurrent constituents. Our previous and current solutions outperform\nstate-of-the-art solutions for multivariate time series classifications, thus\nshowcasing the effectiveness of the proposed methodology.", "AI": {"tldr": "A hybrid explainable AI pipeline (EMeriTAte+DF) combines numerical and event-based temporal data classification for human-explainable results, outperforming state-of-the-art methods.", "motivation": "To bridge numerical-driven and event-based temporal data classification while ensuring explainability through AI principles.", "method": "Extends event-based literature to support concurrent constituents and uses a posteriori explainable phase for numerical data.", "result": "Outperforms state-of-the-art solutions in multivariate time series classification.", "conclusion": "The proposed hybrid pipeline is effective and provides explainable results."}}
{"id": "2505.23523", "pdf": "https://arxiv.org/pdf/2505.23523", "abs": "https://arxiv.org/abs/2505.23523", "authors": ["Arjun Devraj", "Eric Ding", "Abhishek Vijaya Kumar", "Robert Kleinberg", "Rachee Singh"], "title": "Accelerating AllReduce with a Persistent Straggler", "categories": ["cs.LG", "cs.DC"], "comment": "23 pages, 11 figures", "summary": "Distributed machine learning workloads use data and tensor parallelism for\ntraining and inference, both of which rely on the AllReduce collective to\nsynchronize gradients or activations. However, bulk-synchronous AllReduce\nalgorithms can be delayed by a persistent straggler that is slower to reach the\nsynchronization barrier required to begin the collective. To address this\nchallenge, we propose StragglAR: an AllReduce algorithm that accelerates\ndistributed training and inference in the presence of persistent stragglers.\nStragglAR implements a ReduceScatter among the remaining GPUs during the\nstraggler-induced delay, and then executes a novel collective algorithm to\ncomplete the AllReduce once the straggler reaches the synchronization barrier.\nStragglAR achieves a 2x theoretical speedup over popular bandwidth-efficient\nAllReduce algorithms (e.g., Ring) for large GPU clusters with persistent\nstragglers. On an 8-GPU server, our implementation of StragglAR yields a 22%\nspeedup over state-of-the-art AllReduce algorithms.", "AI": {"tldr": "StragglAR is a novel AllReduce algorithm designed to mitigate delays caused by persistent stragglers in distributed machine learning, achieving significant speedups over existing methods.", "motivation": "Persistent stragglers in distributed training and inference delay bulk-synchronous AllReduce algorithms, necessitating a solution to improve efficiency.", "method": "StragglAR uses ReduceScatter among non-straggler GPUs during delays and a novel collective algorithm to complete AllReduce once stragglers synchronize.", "result": "Theoretical 2x speedup over bandwidth-efficient AllReduce algorithms for large clusters; 22% speedup on an 8-GPU server.", "conclusion": "StragglAR effectively addresses straggler-induced delays, enhancing performance in distributed machine learning workloads."}}
{"id": "2505.23722", "pdf": "https://arxiv.org/pdf/2505.23722", "abs": "https://arxiv.org/abs/2505.23722", "authors": ["Fan Bai", "Hamid Hassanzadeh", "Ardavan Saeedi", "Mark Dredze"], "title": "Label-Guided In-Context Learning for Named Entity Recognition", "categories": ["cs.CL"], "comment": "Preprint", "summary": "In-context learning (ICL) enables large language models (LLMs) to perform new\ntasks using only a few demonstrations. In Named Entity Recognition (NER),\ndemonstrations are typically selected based on semantic similarity to the test\ninstance, ignoring training labels and resulting in suboptimal performance. We\nintroduce DEER, a new method that leverages training labels through token-level\nstatistics to improve ICL performance. DEER first enhances example selection\nwith a label-guided, token-based retriever that prioritizes tokens most\ninformative for entity recognition. It then prompts the LLM to revisit\nerror-prone tokens, which are also identified using label statistics, and make\ntargeted corrections. Evaluated on five NER datasets using four different LLMs,\nDEER consistently outperforms existing ICL methods and approaches the\nperformance of supervised fine-tuning. Further analysis shows its effectiveness\non both seen and unseen entities and its robustness in low-resource settings.", "AI": {"tldr": "DEER improves in-context learning for NER by using label-guided token statistics for better example selection and targeted corrections, outperforming existing methods and nearing supervised fine-tuning performance.", "motivation": "Current ICL methods for NER rely on semantic similarity for demonstration selection, ignoring training labels and leading to suboptimal performance.", "method": "DEER uses token-level statistics from training labels to enhance example selection and prompts LLMs to correct error-prone tokens.", "result": "DEER outperforms existing ICL methods on five NER datasets and approaches supervised fine-tuning performance, showing robustness in low-resource settings.", "conclusion": "DEER effectively leverages label statistics to improve ICL for NER, demonstrating strong performance and generalization across datasets and entities."}}
{"id": "2505.23543", "pdf": "https://arxiv.org/pdf/2505.23543", "abs": "https://arxiv.org/abs/2505.23543", "authors": ["Jan Ignatowicz", "Krzysztof Kutt", "Grzegorz J. Nalepa"], "title": "Position Paper: Metadata Enrichment Model: Integrating Neural Networks and Semantic Knowledge Graphs for Cultural Heritage Applications", "categories": ["cs.CV"], "comment": null, "summary": "The digitization of cultural heritage collections has opened new directions\nfor research, yet the lack of enriched metadata poses a substantial challenge\nto accessibility, interoperability, and cross-institutional collaboration. In\nseveral past years neural networks models such as YOLOv11 and Detectron2 have\nrevolutionized visual data analysis, but their application to domain-specific\ncultural artifacts - such as manuscripts and incunabula - remains limited by\nthe absence of methodologies that address structural feature extraction and\nsemantic interoperability. In this position paper, we argue, that the\nintegration of neural networks with semantic technologies represents a paradigm\nshift in cultural heritage digitization processes. We present the Metadata\nEnrichment Model (MEM), a conceptual framework designed to enrich metadata for\ndigitized collections by combining fine-tuned computer vision models, large\nlanguage models (LLMs) and structured knowledge graphs. The Multilayer Vision\nMechanism (MVM) appears as the key innovation of MEM. This iterative process\nimproves visual analysis by dynamically detecting nested features, such as text\nwithin seals or images within stamps. To expose MEM's potential, we apply it to\na dataset of digitized incunabula from the Jagiellonian Digital Library and\nrelease a manually annotated dataset of 105 manuscript pages. We examine the\npractical challenges of MEM's usage in real-world GLAM institutions, including\nthe need for domain-specific fine-tuning, the adjustment of enriched metadata\nwith Linked Data standards and computational costs. We present MEM as a\nflexible and extensible methodology. This paper contributes to the discussion\non how artificial intelligence and semantic web technologies can advance\ncultural heritage research, and also use these technologies in practice.", "AI": {"tldr": "The paper proposes the Metadata Enrichment Model (MEM), integrating neural networks and semantic technologies to enrich metadata for digitized cultural heritage collections, addressing challenges like feature extraction and interoperability.", "motivation": "The lack of enriched metadata in digitized cultural heritage collections hinders accessibility and collaboration. Existing neural network models lack domain-specific methodologies for artifacts like manuscripts.", "method": "MEM combines fine-tuned computer vision models, LLMs, and knowledge graphs, featuring the Multilayer Vision Mechanism (MVM) for dynamic feature detection.", "result": "Tested on incunabula, MEM demonstrated potential, with a manually annotated dataset released. Challenges include domain-specific tuning and computational costs.", "conclusion": "MEM offers a flexible approach to advancing cultural heritage research through AI and semantic technologies, bridging theory and practice."}}
{"id": "2505.23631", "pdf": "https://arxiv.org/pdf/2505.23631", "abs": "https://arxiv.org/abs/2505.23631", "authors": ["Boning Zhao"], "title": "Human Empathy as Encoder: AI-Assisted Depression Assessment in Special Education", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": "7 pages, 6 figures. Under review", "summary": "Assessing student depression in sensitive environments like special education\nis challenging. Standardized questionnaires may not fully reflect students'\ntrue situations. Furthermore, automated methods often falter with rich student\nnarratives, lacking the crucial, individualized insights stemming from\nteachers' empathetic connections with students. Existing methods often fail to\naddress this ambiguity or effectively integrate educator understanding. To\naddress these limitations by fostering a synergistic human-AI collaboration,\nthis paper introduces Human Empathy as Encoder (HEAE), a novel, human-centered\nAI framework for transparent and socially responsible depression severity\nassessment. Our approach uniquely integrates student narrative text with a\nteacher-derived, 9-dimensional \"Empathy Vector\" (EV), its dimensions guided by\nthe PHQ-9 framework,to explicitly translate tacit empathetic insight into a\nstructured AI input enhancing rather than replacing human judgment. Rigorous\nexperiments optimized the multimodal fusion, text representation, and\nclassification architecture, achieving 82.74% accuracy for 7-level severity\nclassification. This work demonstrates a path toward more responsible and\nethical affective computing by structurally embedding human empathy", "AI": {"tldr": "The paper introduces HEAE, a human-centered AI framework for assessing student depression by combining student narratives with teacher-derived empathy insights, achieving 82.74% accuracy.", "motivation": "Standardized questionnaires and automated methods often miss individualized insights from teacher-student connections, leading to inaccurate depression assessments.", "method": "HEAE integrates student narrative text with a teacher-derived 9-dimensional 'Empathy Vector' (EV) based on PHQ-9, optimizing multimodal fusion and classification.", "result": "The framework achieved 82.74% accuracy in 7-level depression severity classification.", "conclusion": "HEAE demonstrates a responsible, ethical approach to affective computing by embedding human empathy into AI."}}
{"id": "2505.23527", "pdf": "https://arxiv.org/pdf/2505.23527", "abs": "https://arxiv.org/abs/2505.23527", "authors": ["Raj Ghugare", "Benjamin Eysenbach"], "title": "Normalizing Flows are Capable Models for RL", "categories": ["cs.LG"], "comment": "Project page with code - https://rajghugare19.github.io/nf4rl/", "summary": "Modern reinforcement learning (RL) algorithms have found success by using\npowerful probabilistic models, such as transformers, energy-based models, and\ndiffusion/flow-based models. To this end, RL researchers often choose to pay\nthe price of accommodating these models into their algorithms -- diffusion\nmodels are expressive, but are computationally intensive due to their reliance\non solving differential equations, while autoregressive transformer models are\nscalable but typically require learning discrete representations. Normalizing\nflows (NFs), by contrast, seem to provide an appealing alternative, as they\nenable likelihoods and sampling without solving differential equations or\nautoregressive architectures. However, their potential in RL has received\nlimited attention, partly due to the prevailing belief that normalizing flows\nlack sufficient expressivity. We show that this is not the case. Building on\nrecent work in NFs, we propose a single NF architecture which integrates\nseamlessly into RL algorithms, serving as a policy, Q-function, and occupancy\nmeasure. Our approach leads to much simpler algorithms, and achieves higher\nperformance in imitation learning, offline, goal conditioned RL and\nunsupervised RL.", "AI": {"tldr": "Normalizing flows (NFs) offer a simpler, efficient alternative to complex models like transformers and diffusion models in RL, achieving high performance across tasks.", "motivation": "To address the computational and representational challenges of existing RL models (e.g., diffusion models, transformers) by leveraging the untapped potential of normalizing flows.", "method": "Proposes a single NF architecture that integrates into RL algorithms, serving as policy, Q-function, and occupancy measure.", "result": "Simplifies algorithms and outperforms in imitation learning, offline, goal-conditioned, and unsupervised RL.", "conclusion": "NFs are expressive and effective for RL, challenging the belief of their limited expressivity."}}
{"id": "2505.23723", "pdf": "https://arxiv.org/pdf/2505.23723", "abs": "https://arxiv.org/abs/2505.23723", "authors": ["Zexi Liu", "Jingyi Chai", "Xinyu Zhu", "Shuo Tang", "Rui Ye", "Bo Zhang", "Lei Bai", "Siheng Chen"], "title": "ML-Agent: Reinforcing LLM Agents for Autonomous Machine Learning Engineering", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The emergence of large language model (LLM)-based agents has significantly\nadvanced the development of autonomous machine learning (ML) engineering.\nHowever, most existing approaches rely heavily on manual prompt engineering,\nfailing to adapt and optimize based on diverse experimental experiences.\nFocusing on this, for the first time, we explore the paradigm of learning-based\nagentic ML, where an LLM agent learns through interactive experimentation on ML\ntasks using online reinforcement learning (RL). To realize this, we propose a\nnovel agentic ML training framework with three key components: (1)\nexploration-enriched fine-tuning, which enables LLM agents to generate diverse\nactions for enhanced RL exploration; (2) step-wise RL, which enables training\non a single action step, accelerating experience collection and improving\ntraining efficiency; (3) an agentic ML-specific reward module, which unifies\nvaried ML feedback signals into consistent rewards for RL optimization.\nLeveraging this framework, we train ML-Agent, driven by a 7B-sized Qwen-2.5 LLM\nfor autonomous ML. Remarkably, despite being trained on merely 9 ML tasks, our\n7B-sized ML-Agent outperforms the 671B-sized DeepSeek-R1 agent. Furthermore, it\nachieves continuous performance improvements and demonstrates exceptional\ncross-task generalization capabilities.", "AI": {"tldr": "The paper introduces a learning-based agentic ML framework using LLM agents with online RL, outperforming larger models despite minimal training.", "motivation": "Existing LLM-based ML agents rely on manual prompts, lacking adaptability and optimization from diverse experiments.", "method": "Proposes a framework with exploration-enriched fine-tuning, step-wise RL, and a unified reward module for autonomous ML.", "result": "A 7B-sized ML-Agent trained on 9 tasks outperforms a 671B-sized agent and shows strong generalization.", "conclusion": "The framework enables efficient, adaptive ML agents with superior performance and scalability."}}
{"id": "2505.23558", "pdf": "https://arxiv.org/pdf/2505.23558", "abs": "https://arxiv.org/abs/2505.23558", "authors": ["Xu Chu", "Xinrong Chen", "Guanyu Wang", "Zhijie Tan", "Kui Huang", "Wenyu Lv", "Tong Mo", "Weiping Li"], "title": "Qwen Look Again: Guiding Vision-Language Reasoning Models to Re-attention Visual Information", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Inference time scaling drives extended reasoning to enhance the performance\nof Vision-Language Models (VLMs), thus forming powerful Vision-Language\nReasoning Models (VLRMs). However, long reasoning dilutes visual tokens,\ncausing visual information to receive less attention and may trigger\nhallucinations. Although introducing text-only reflection processes shows\npromise in language models, we demonstrate that it is insufficient to suppress\nhallucinations in VLMs. To address this issue, we introduce Qwen-LookAgain\n(Qwen-LA), a novel VLRM designed to mitigate hallucinations by incorporating a\nvision-text reflection process that guides the model to re-attention visual\ninformation during reasoning. We first propose a reinforcement learning method\nBalanced Reflective Policy Optimization (BRPO), which guides the model to\ndecide when to generate vision-text reflection on its own and balance the\nnumber and length of reflections. Then, we formally prove that VLRMs lose\nattention to visual tokens as reasoning progresses, and demonstrate that\nsupplementing visual information during reflection enhances visual attention.\nTherefore, during training and inference, Visual Token COPY and Visual Token\nROUTE are introduced to force the model to re-attention visual information at\nthe visual level, addressing the limitations of text-only reflection.\nExperiments on multiple visual QA datasets and hallucination metrics indicate\nthat Qwen-LA achieves leading accuracy performance while reducing\nhallucinations. Our code is available at:\nhttps://github.com/Liar406/Look_Again.", "AI": {"tldr": "Qwen-LA introduces a vision-text reflection process to mitigate hallucinations in VLMs, using BRPO for balanced reflection and visual token methods to enhance attention.", "motivation": "Extended reasoning in VLMs dilutes visual attention, causing hallucinations, which text-only reflection fails to address.", "method": "Proposes Qwen-LA with BRPO for reflection balance and Visual Token COPY/ROUTE to re-attention visual info.", "result": "Qwen-LA improves accuracy and reduces hallucinations on visual QA datasets.", "conclusion": "Vision-text reflection and visual token methods effectively address VLM hallucinations."}}
{"id": "2505.23637", "pdf": "https://arxiv.org/pdf/2505.23637", "abs": "https://arxiv.org/abs/2505.23637", "authors": ["Dashti A. Ali", "Richard K. G. Do", "William R. Jarnagin", "Aras T. Asaad", "Amber L. Simpson"], "title": "Comparing the Effects of Persistence Barcodes Aggregation and Feature Concatenation on Medical Imaging", "categories": ["cs.CV", "cs.AI"], "comment": "16 pages, 8 figures", "summary": "In medical image analysis, feature engineering plays an important role in the\ndesign and performance of machine learning models. Persistent homology (PH),\nfrom the field of topological data analysis (TDA), demonstrates robustness and\nstability to data perturbations and addresses the limitation from traditional\nfeature extraction approaches where a small change in input results in a large\nchange in feature representation. Using PH, we store persistent topological and\ngeometrical features in the form of the persistence barcode whereby large bars\nrepresent global topological features and small bars encapsulate geometrical\ninformation of the data. When multiple barcodes are computed from 2D or 3D\nmedical images, two approaches can be used to construct the final topological\nfeature vector in each dimension: aggregating persistence barcodes followed by\nfeaturization or concatenating topological feature vectors derived from each\nbarcode. In this study, we conduct a comprehensive analysis across diverse\nmedical imaging datasets to compare the effects of the two aforementioned\napproaches on the performance of classification models. The results of this\nanalysis indicate that feature concatenation preserves detailed topological\ninformation from individual barcodes, yields better classification performance\nand is therefore a preferred approach when conducting similar experiments.", "AI": {"tldr": "The paper compares two methods of constructing topological feature vectors from persistence barcodes in medical image analysis, finding that feature concatenation outperforms aggregation in preserving detailed topological information and improving classification performance.", "motivation": "Traditional feature extraction in medical image analysis is sensitive to input perturbations. Persistent homology (PH) offers robustness, but the best method to construct feature vectors from PH barcodes is unclear.", "method": "The study compares two approaches: aggregating persistence barcodes followed by featurization versus concatenating topological feature vectors from individual barcodes.", "result": "Feature concatenation preserves more detailed topological information and yields better classification performance.", "conclusion": "Concatenating topological feature vectors is the preferred method for similar experiments due to its superior performance."}}
{"id": "2505.23528", "pdf": "https://arxiv.org/pdf/2505.23528", "abs": "https://arxiv.org/abs/2505.23528", "authors": ["Maria Eleftheria Vlontzou", "Maria Athanasiou", "Christos Davatzikos", "Konstantina S. Nikita"], "title": "Comparative assessment of fairness definitions and bias mitigation strategies in machine learning-based diagnosis of Alzheimer's disease from MR images", "categories": ["cs.LG"], "comment": "(C) 2025 IEEE Paper accepted at IEEE Engineering in Medicine and\n  Biology Society Conference, 2025", "summary": "The present study performs a comprehensive fairness analysis of machine\nlearning (ML) models for the diagnosis of Mild Cognitive Impairment (MCI) and\nAlzheimer's disease (AD) from MRI-derived neuroimaging features. Biases\nassociated with age, race, and gender in a multi-cohort dataset, as well as the\ninfluence of proxy features encoding these sensitive attributes, are\ninvestigated. The reliability of various fairness definitions and metrics in\nthe identification of such biases is also assessed. Based on the most\nappropriate fairness measures, a comparative analysis of widely used\npre-processing, in-processing, and post-processing bias mitigation strategies\nis performed. Moreover, a novel composite measure is introduced to quantify the\ntrade-off between fairness and performance by considering the F1-score and the\nequalized odds ratio, making it appropriate for medical diagnostic\napplications. The obtained results reveal the existence of biases related to\nage and race, while no significant gender bias is observed. The deployed\nmitigation strategies yield varying improvements in terms of fairness across\nthe different sensitive attributes and studied subproblems. For race and\ngender, Reject Option Classification improves equalized odds by 46% and 57%,\nrespectively, and achieves harmonic mean scores of 0.75 and 0.80 in the MCI\nversus AD subproblem, whereas for age, in the same subproblem, adversarial\ndebiasing yields the highest equalized odds improvement of 40% with a harmonic\nmean score of 0.69. Insights are provided into how variations in AD\nneuropathology and risk factors, associated with demographic characteristics,\ninfluence model fairness.", "AI": {"tldr": "The study analyzes fairness in ML models for diagnosing MCI and AD from MRI data, identifying biases in age and race but not gender. It evaluates mitigation strategies and introduces a composite fairness-performance measure.", "motivation": "To address biases in ML models for medical diagnosis, ensuring fairness across demographic groups like age, race, and gender.", "method": "Comprehensive fairness analysis using multi-cohort MRI data, assessing biases and testing pre-, in-, and post-processing mitigation strategies. A novel composite measure balances fairness and performance.", "result": "Biases found in age and race, not gender. Mitigation strategies improved fairness: Reject Option Classification for race/gender, adversarial debiasing for age.", "conclusion": "Fairness in ML for medical diagnosis requires tailored mitigation strategies. The composite measure aids in balancing fairness and performance."}}
{"id": "2505.23729", "pdf": "https://arxiv.org/pdf/2505.23729", "abs": "https://arxiv.org/abs/2505.23729", "authors": ["Mohamad Chehade", "Soumya Suvra Ghosal", "Souradip Chakraborty", "Avinash Reddy", "Dinesh Manocha", "Hao Zhu", "Amrit Singh Bedi"], "title": "Bounded Rationality for LLMs: Satisficing Alignment at Inference-Time", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at ICML 2025", "summary": "Aligning large language models with humans is challenging due to the\ninherently multifaceted nature of preference feedback. While existing\napproaches typically frame this as a multi-objective optimization problem, they\noften overlook how humans actually make decisions. Research on bounded\nrationality suggests that human decision making follows satisficing\nstrategies-optimizing primary objectives while ensuring others meet acceptable\nthresholds. To bridge this gap and operationalize the notion of satisficing\nalignment, we propose SITAlign: an inference time framework that addresses the\nmultifaceted nature of alignment by maximizing a primary objective while\nsatisfying threshold-based constraints on secondary criteria. We provide\ntheoretical insights by deriving sub-optimality bounds of our satisficing based\ninference alignment approach. We empirically validate SITAlign's performance\nthrough extensive experimentation on multiple benchmarks. For instance, on the\nPKU-SafeRLHF dataset with the primary objective of maximizing helpfulness while\nensuring a threshold on harmlessness, SITAlign outperforms the state-of-the-art\nmulti objective decoding strategy by a margin of 22.3% in terms of GPT-4\nwin-tie rate for helpfulness reward while adhering to the threshold on\nharmlessness.", "AI": {"tldr": "SITAlign is a framework for aligning large language models with human preferences by optimizing primary objectives while meeting thresholds for secondary criteria, outperforming existing methods.", "motivation": "Human decision-making involves satisficing strategies, which existing alignment methods overlook. SITAlign bridges this gap by incorporating bounded rationality principles.", "method": "SITAlign is an inference-time framework that maximizes a primary objective while satisfying threshold constraints on secondary criteria, derived from theoretical sub-optimality bounds.", "result": "On the PKU-SafeRLHF dataset, SITAlign outperforms state-of-the-art methods by 22.3% in GPT-4 win-tie rate for helpfulness while maintaining harmlessness thresholds.", "conclusion": "SITAlign effectively aligns models with human preferences by operationalizing satisficing strategies, demonstrating superior performance over multi-objective approaches."}}
{"id": "2505.23566", "pdf": "https://arxiv.org/pdf/2505.23566", "abs": "https://arxiv.org/abs/2505.23566", "authors": ["Yu Li", "Jin Jiang", "Jianhua Zhu", "Shuai Peng", "Baole Wei", "Yuxuan Zhou", "Liangcai Gao"], "title": "Uni-MuMER: Unified Multi-Task Fine-Tuning of Vision-Language Model for Handwritten Mathematical Expression Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Handwritten Mathematical Expression Recognition (HMER) remains a persistent\nchallenge in Optical Character Recognition (OCR) due to the inherent freedom of\nsymbol layout and variability in handwriting styles. Prior methods have faced\nperformance bottlenecks, proposing isolated architectural modifications that\nare difficult to integrate coherently into a unified framework. Meanwhile,\nrecent advances in pretrained vision-language models (VLMs) have demonstrated\nstrong cross-task generalization, offering a promising foundation for\ndeveloping unified solutions. In this paper, we introduce Uni-MuMER, which\nfully fine-tunes a VLM for the HMER task without modifying its architecture,\neffectively injecting domain-specific knowledge into a generalist framework.\nOur method integrates three data-driven tasks: Tree-Aware Chain-of-Thought\n(Tree-CoT) for structured spatial reasoning, Error-Driven Learning (EDL) for\nreducing confusion among visually similar characters, and Symbol Counting (SC)\nfor improving recognition consistency in long expressions. Experiments on the\nCROHME and HME100K datasets show that Uni-MuMER achieves new state-of-the-art\nperformance, surpassing the best lightweight specialized model SSAN by 16.31%\nand the top-performing VLM Gemini2.5-flash by 24.42% in the zero-shot setting.\nOur datasets, models, and code are open-sourced at:\nhttps://github.com/BFlameSwift/Uni-MuMER", "AI": {"tldr": "Uni-MuMER fine-tunes a vision-language model (VLM) for Handwritten Mathematical Expression Recognition (HMER) without architectural changes, achieving state-of-the-art results.", "motivation": "HMER is challenging due to symbol layout freedom and handwriting variability. Existing methods lack unified solutions, while VLMs offer strong generalization.", "method": "Uni-MuMER integrates Tree-CoT for spatial reasoning, EDL for reducing character confusion, and SC for consistency in long expressions.", "result": "Uni-MuMER outperforms SSAN by 16.31% and Gemini2.5-flash by 24.42% on CROHME and HME100K datasets.", "conclusion": "The approach successfully injects domain-specific knowledge into a generalist VLM, setting new benchmarks in HMER."}}
{"id": "2505.23643", "pdf": "https://arxiv.org/pdf/2505.23643", "abs": "https://arxiv.org/abs/2505.23643", "authors": ["Manuel Costa", "Boris K\u00f6pf", "Aashish Kolluri", "Andrew Paverd", "Mark Russinovich", "Ahmed Salem", "Shruti Tople", "Lukas Wutschitz", "Santiago Zanella-B\u00e9guelin"], "title": "Securing AI Agents with Information-Flow Control", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "As AI agents become increasingly autonomous and capable, ensuring their\nsecurity against vulnerabilities such as prompt injection becomes critical.\nThis paper explores the use of information-flow control (IFC) to provide\nsecurity guarantees for AI agents. We present a formal model to reason about\nthe security and expressiveness of agent planners. Using this model, we\ncharacterize the class of properties enforceable by dynamic taint-tracking and\nconstruct a taxonomy of tasks to evaluate security and utility trade-offs of\nplanner designs. Informed by this exploration, we present Fides, a planner that\ntracks confidentiality and integrity labels, deterministically enforces\nsecurity policies, and introduces novel primitives for selectively hiding\ninformation. Its evaluation in AgentDojo demonstrates that this approach\nbroadens the range of tasks that can be securely accomplished. A tutorial to\nwalk readers through the the concepts introduced in the paper can be found at\nhttps://github.com/microsoft/fides", "AI": {"tldr": "The paper proposes Fides, a planner using information-flow control (IFC) to secure AI agents against vulnerabilities like prompt injection, ensuring security and utility trade-offs.", "motivation": "As AI agents grow more autonomous, securing them against vulnerabilities (e.g., prompt injection) is critical.", "method": "The paper introduces a formal model for security and expressiveness of agent planners, evaluates trade-offs, and presents Fides, a planner enforcing confidentiality and integrity policies.", "result": "Fides broadens the range of securely accomplishable tasks, demonstrated in AgentDojo.", "conclusion": "The approach enhances AI agent security with deterministic policy enforcement and novel information-hiding primitives."}}
{"id": "2505.23537", "pdf": "https://arxiv.org/pdf/2505.23537", "abs": "https://arxiv.org/abs/2505.23537", "authors": ["Giorgos Iacovides", "Wuyang Zhou", "Chao Li", "Qibin Zhao", "Danilo Mandic"], "title": "Domain-Aware Tensor Network Structure Search", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Tensor networks (TNs) provide efficient representations of high-dimensional\ndata, yet identification of the optimal TN structures, the so called tensor\nnetwork structure search (TN-SS) problem, remains a challenge. Current\nstate-of-the-art (SOTA) algorithms are computationally expensive as they\nrequire extensive function evaluations, which is prohibitive for real-world\napplications. In addition, existing methods ignore valuable domain information\ninherent in real-world tensor data and lack transparency in their identified TN\nstructures. To this end, we propose a novel TN-SS framework, termed the tnLLM,\nwhich incorporates domain information about the data and harnesses the\nreasoning capabilities of large language models (LLMs) to directly predict\nsuitable TN structures. The proposed framework involves a domain-aware\nprompting pipeline which instructs the LLM to infer suitable TN structures\nbased on the real-world relationships between tensor modes. In this way, our\napproach is capable of not only iteratively optimizing the objective function,\nbut also generating domain-aware explanations for the identified structures.\nExperimental results demonstrate that tnLLM achieves comparable TN-SS objective\nfunction values with much fewer function evaluations compared to SOTA\nalgorithms. Furthermore, we demonstrate that the LLM-enabled domain information\ncan be used to find good initializations in the search space for sampling-based\nSOTA methods to accelerate their convergence while preserving theoretical\nperformance guarantees.", "AI": {"tldr": "The paper introduces tnLLM, a novel framework for tensor network structure search (TN-SS) that leverages domain information and large language models (LLMs) to predict optimal structures efficiently.", "motivation": "Current TN-SS methods are computationally expensive and ignore domain-specific data relationships, lacking transparency.", "method": "The tnLLM framework uses domain-aware prompting with LLMs to infer TN structures and provide explanations, reducing function evaluations.", "result": "tnLLM achieves comparable results to SOTA methods with fewer evaluations and improves initialization for faster convergence.", "conclusion": "The tnLLM framework offers a computationally efficient, domain-aware, and interpretable solution for TN-SS."}}
{"id": "2505.23735", "pdf": "https://arxiv.org/pdf/2505.23735", "abs": "https://arxiv.org/abs/2505.23735", "authors": ["Ali Behrouz", "Zeman Li", "Praneeth Kacham", "Majid Daliri", "Yuan Deng", "Peilin Zhong", "Meisam Razaviyayn", "Vahab Mirrokni"], "title": "ATLAS: Learning to Optimally Memorize the Context at Test Time", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Transformers have been established as the most popular backbones in sequence\nmodeling, mainly due to their effectiveness in in-context retrieval tasks and\nthe ability to learn at scale. Their quadratic memory and time complexity,\nhowever, bound their applicability in longer sequences and so has motivated\nresearchers to explore effective alternative architectures such as modern\nrecurrent neural networks (a.k.a long-term recurrent memory module). Despite\ntheir recent success in diverse downstream tasks, they struggle in tasks that\nrequires long context understanding and extrapolation to longer sequences. We\nobserve that these shortcomings come from three disjoint aspects in their\ndesign: (1) limited memory capacity that is bounded by the architecture of\nmemory and feature mapping of the input; (2) online nature of update, i.e.,\noptimizing the memory only with respect to the last input; and (3) less\nexpressive management of their fixed-size memory. To enhance all these three\naspects, we present ATLAS, a long-term memory module with high capacity that\nlearns to memorize the context by optimizing the memory based on the current\nand past tokens, overcoming the online nature of long-term memory models.\nBuilding on this insight, we present a new family of Transformer-like\narchitectures, called DeepTransformers, that are strict generalizations of the\noriginal Transformer architecture. Our experimental results on language\nmodeling, common-sense reasoning, recall-intensive, and long-context\nunderstanding tasks show that ATLAS surpasses the performance of Transformers\nand recent linear recurrent models. ATLAS further improves the long context\nperformance of Titans, achieving +80\\% accuracy in 10M context length of\nBABILong benchmark.", "AI": {"tldr": "ATLAS introduces a long-term memory module to address limitations in Transformers and recurrent models, improving performance in long-context tasks.", "motivation": "Transformers and recurrent models struggle with long-context understanding and memory capacity. ATLAS aims to overcome these limitations by enhancing memory design.", "method": "ATLAS optimizes memory based on current and past tokens, introducing DeepTransformers, a generalization of Transformers.", "result": "ATLAS outperforms Transformers and linear recurrent models in tasks like language modeling and long-context understanding, achieving +80% accuracy in 10M context length.", "conclusion": "ATLAS successfully addresses key limitations in existing models, offering a scalable solution for long-context tasks."}}
{"id": "2505.23587", "pdf": "https://arxiv.org/pdf/2505.23587", "abs": "https://arxiv.org/abs/2505.23587", "authors": ["Christian Schmidt", "Heinrich Martin Overhoff"], "title": "PCA for Enhanced Cross-Dataset Generalizability in Breast Ultrasound Tumor Segmentation", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "In medical image segmentation, limited external validity remains a critical\nobstacle when models are deployed across unseen datasets, an issue particularly\npronounced in the ultrasound image domain. Existing solutions-such as domain\nadaptation and GAN-based style transfer-while promising, often fall short in\nthe medical domain where datasets are typically small and diverse. This paper\npresents a novel application of principal component analysis (PCA) to address\nthis limitation. PCA preprocessing reduces noise and emphasizes essential\nfeatures by retaining approximately 90\\% of the dataset variance. We evaluate\nour approach across six diverse breast tumor ultrasound datasets comprising\n3,983 B-mode images and corresponding expert tumor segmentation masks. For each\ndataset, a corresponding dimensionality reduced PCA-dataset is created and\nU-Net-based segmentation models are trained on each of the twelve datasets.\nEach model trained on an original dataset was inferenced on the remaining five\nout-of-domain original datasets (baseline results), while each model trained on\na PCA dataset was inferenced on five out-of-domain PCA datasets. Our\nexperimental results indicate that using PCA reconstructed datasets, instead of\noriginal images, improves the model's recall and Dice scores, particularly for\nmodel-dataset pairs where baseline performance was lowest, achieving\nstatistically significant gains in recall (0.57 $\\pm$ 0.07 vs. 0.70 $\\pm$ 0.05,\n$p = 0.0004$) and Dice scores (0.50 $\\pm$ 0.06 vs. 0.58 $\\pm$ 0.06, $p =\n0.03$). Our method reduced the decline in recall values due to external\nvalidation by $33\\%$. These findings underscore the potential of PCA\nreconstruction as a safeguard to mitigate declines in segmentation performance,\nespecially in challenging cases, with implications for enhancing external\nvalidity in real-world medical applications.", "AI": {"tldr": "PCA preprocessing improves ultrasound image segmentation by enhancing recall and Dice scores, reducing performance decline in external validation.", "motivation": "Limited external validity in medical image segmentation, especially for ultrasound, due to small, diverse datasets.", "method": "Apply PCA to reduce noise and retain essential features, then train U-Net models on PCA-reconstructed and original datasets for comparison.", "result": "PCA improves recall (0.70 vs. 0.57) and Dice scores (0.58 vs. 0.50), reducing recall decline by 33%.", "conclusion": "PCA reconstruction enhances external validity, offering a practical solution for medical image segmentation challenges."}}
{"id": "2505.23655", "pdf": "https://arxiv.org/pdf/2505.23655", "abs": "https://arxiv.org/abs/2505.23655", "authors": ["Peter David Fagan"], "title": "Keyed Chaotic Tensor Transformations for Secure And Attributable Neural Inference", "categories": ["cs.CR", "cs.AI", "94A60, 37N25, 68T05", "D.4.6"], "comment": "8 pages", "summary": "This work introduces a novel framework for secure and privacy-preserving\nneural network inference based on keyed chaotic dynamical transformations. The\nproposed method applies a deterministic, cryptographically seeded chaotic\nsystem to tensors, producing non-invertible, user-specific transformations that\nenable authenticated inference, tensor-level watermarking, and data\nattribution. This framework offers a scalable and lightweight alternative to\nconventional cryptographic techniques, and establishes a new direction for\ntensor-level security in AI systems.", "AI": {"tldr": "A framework for secure neural network inference using chaotic transformations for privacy and authentication.", "motivation": "To provide a scalable, lightweight alternative to traditional cryptographic methods for securing AI systems.", "method": "Uses keyed chaotic dynamical transformations to create non-invertible, user-specific tensor transformations.", "result": "Enables authenticated inference, tensor-level watermarking, and data attribution.", "conclusion": "Introduces a novel approach for tensor-level security in AI systems."}}
{"id": "2505.23552", "pdf": "https://arxiv.org/pdf/2505.23552", "abs": "https://arxiv.org/abs/2505.23552", "authors": ["Alex Adams"], "title": "Comparing the Moore-Penrose Pseudoinverse and Gradient Descent for Solving Linear Regression Problems: A Performance Analysis", "categories": ["cs.LG"], "comment": null, "summary": "This paper investigates the comparative performance of two fundamental\napproaches to solving linear regression problems: the closed-form Moore-Penrose\npseudoinverse and the iterative gradient descent method. Linear regression is a\ncornerstone of predictive modeling, and the choice of solver can significantly\nimpact efficiency and accuracy. I review and discuss the theoretical\nunderpinnings of both methods, analyze their computational complexity, and\nevaluate their empirical behavior on synthetic datasets with controlled\ncharacteristics, as well as on established real-world datasets. My results\ndelineate the conditions under which each method excels in terms of\ncomputational time, numerical stability, and predictive accuracy. This work\naims to provide practical guidance for researchers and practitioners in machine\nlearning when selecting between direct, exact solutions and iterative,\napproximate solutions for linear regression tasks.", "AI": {"tldr": "Comparison of Moore-Penrose pseudoinverse and gradient descent for linear regression, analyzing efficiency, accuracy, and conditions for optimal performance.", "motivation": "To guide researchers and practitioners in choosing between exact (pseudoinverse) and iterative (gradient descent) methods for linear regression based on computational and empirical performance.", "method": "Theoretical review, computational complexity analysis, and empirical evaluation on synthetic and real-world datasets.", "result": "Identifies conditions where pseudoinverse or gradient descent excels in computational time, numerical stability, and predictive accuracy.", "conclusion": "Provides practical guidance for selecting the appropriate linear regression solver based on specific conditions and requirements."}}
{"id": "2505.23754", "pdf": "https://arxiv.org/pdf/2505.23754", "abs": "https://arxiv.org/abs/2505.23754", "authors": ["Ziyin Zhang", "Jiahao Xu", "Zhiwei He", "Tian Liang", "Qiuzhi Liu", "Yansi Li", "Linfeng Song", "Zhengwen Liang", "Zhuosheng Zhang", "Rui Wang", "Zhaopeng Tu", "Haitao Mi", "Dong Yu"], "title": "DeepTheorem: Advancing LLM Reasoning for Theorem Proving Through Natural Language and Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Theorem proving serves as a major testbed for evaluating complex reasoning\nabilities in large language models (LLMs). However, traditional automated\ntheorem proving (ATP) approaches rely heavily on formal proof systems that\npoorly align with LLMs' strength derived from informal, natural language\nknowledge acquired during pre-training. In this work, we propose DeepTheorem, a\ncomprehensive informal theorem-proving framework exploiting natural language to\nenhance LLM mathematical reasoning. DeepTheorem includes a large-scale\nbenchmark dataset consisting of 121K high-quality IMO-level informal theorems\nand proofs spanning diverse mathematical domains, rigorously annotated for\ncorrectness, difficulty, and topic categories, accompanied by systematically\nconstructed verifiable theorem variants. We devise a novel reinforcement\nlearning strategy (RL-Zero) explicitly tailored to informal theorem proving,\nleveraging the verified theorem variants to incentivize robust mathematical\ninference. Additionally, we propose comprehensive outcome and process\nevaluation metrics examining proof correctness and the quality of reasoning\nsteps. Extensive experimental analyses demonstrate DeepTheorem significantly\nimproves LLM theorem-proving performance compared to existing datasets and\nsupervised fine-tuning protocols, achieving state-of-the-art accuracy and\nreasoning quality. Our findings highlight DeepTheorem's potential to\nfundamentally advance automated informal theorem proving and mathematical\nexploration.", "AI": {"tldr": "DeepTheorem is a framework for informal theorem proving using natural language to enhance LLM reasoning. It includes a large dataset, reinforcement learning (RL-Zero), and evaluation metrics, achieving state-of-the-art results.", "motivation": "Traditional ATP methods misalign with LLMs' natural language strengths, limiting their theorem-proving potential. DeepTheorem bridges this gap.", "method": "Proposes DeepTheorem with a 121K theorem dataset, RL-Zero for reinforcement learning, and evaluation metrics for proof correctness and reasoning quality.", "result": "DeepTheorem outperforms existing methods, improving LLM theorem-proving accuracy and reasoning quality.", "conclusion": "DeepTheorem advances informal theorem proving and mathematical exploration, showcasing LLMs' potential in complex reasoning."}}
{"id": "2505.23597", "pdf": "https://arxiv.org/pdf/2505.23597", "abs": "https://arxiv.org/abs/2505.23597", "authors": ["Georgios Voulgaris"], "title": "Bridging Classical and Modern Computer Vision: PerceptiveNet for Tree Crown Semantic Segmentation", "categories": ["cs.CV"], "comment": "Accepted for publication at the IEEE/CVF Conference on Computer\n  Vision and Pattern Recognition (CVPR) EarthVision", "summary": "The accurate semantic segmentation of tree crowns within remotely sensed data\nis crucial for scientific endeavours such as forest management, biodiversity\nstudies, and carbon sequestration quantification. However, precise segmentation\nremains challenging due to complexities in the forest canopy, including\nshadows, intricate backgrounds, scale variations, and subtle spectral\ndifferences among tree species. Compared to the traditional methods, Deep\nLearning models improve accuracy by extracting informative and discriminative\nfeatures, but often fall short in capturing the aforementioned complexities.\n  To address these challenges, we propose PerceptiveNet, a novel model\nincorporating a Logarithmic Gabor-parameterised convolutional layer with\ntrainable filter parameters, alongside a backbone that extracts salient\nfeatures while capturing extensive context and spatial information through a\nwider receptive field. We investigate the impact of Log-Gabor, Gabor, and\nstandard convolutional layers on semantic segmentation performance through\nextensive experimentation. Additionally, we conduct an ablation study to assess\nthe contributions of individual layers and their combinations to overall model\nperformance, and we evaluate PerceptiveNet as a backbone within a novel hybrid\nCNN-Transformer model. Our results outperform state-of-the-art models,\ndemonstrating significant performance improvements on a tree crown dataset\nwhile generalising across domains, including two benchmark aerial scene\nsemantic segmentation datasets with varying complexities.", "AI": {"tldr": "PerceptiveNet, a novel deep learning model with Logarithmic Gabor-parameterised convolutional layers, improves tree crown segmentation in remote sensing by addressing canopy complexities and outperforms state-of-the-art methods.", "motivation": "Accurate tree crown segmentation is vital for forest management and biodiversity studies, but traditional and deep learning methods struggle with canopy complexities like shadows and spectral variations.", "method": "Proposes PerceptiveNet with trainable Logarithmic Gabor filters and a backbone for context extraction. Evaluates Log-Gabor, Gabor, and standard convolutional layers, and tests PerceptiveNet in a hybrid CNN-Transformer model.", "result": "Outperforms state-of-the-art models on tree crown datasets and generalizes well on benchmark aerial scene datasets.", "conclusion": "PerceptiveNet effectively addresses segmentation challenges in complex forest canopies and shows strong generalization across domains."}}
{"id": "2505.23671", "pdf": "https://arxiv.org/pdf/2505.23671", "abs": "https://arxiv.org/abs/2505.23671", "authors": ["Manish Shetty", "Naman Jain", "Jinjian Liu", "Vijay Kethanaboyina", "Koushik Sen", "Ion Stoica"], "title": "GSO: Challenging Software Optimization Tasks for Evaluating SWE-Agents", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "comment": "Website: https://gso-bench.github.io/", "summary": "Developing high-performance software is a complex task that requires\nspecialized expertise. We introduce GSO, a benchmark for evaluating language\nmodels' capabilities in developing high-performance software. We develop an\nautomated pipeline that generates and executes performance tests to analyze\nrepository commit histories to identify 102 challenging optimization tasks\nacross 10 codebases, spanning diverse domains and programming languages. An\nagent is provided with a codebase and performance test as a precise\nspecification, and tasked to improve the runtime efficiency, which is measured\nagainst the expert developer optimization. Our quantitative evaluation reveals\nthat leading SWE-Agents struggle significantly, achieving less than 5% success\nrate, with limited improvements even with inference-time scaling. Our\nqualitative analysis identifies key failure modes, including difficulties with\nlow-level languages, practicing lazy optimization strategies, and challenges in\naccurately localizing bottlenecks. We release the code and artifacts of our\nbenchmark along with agent trajectories to enable future research.", "AI": {"tldr": "GSO is a benchmark for evaluating language models in high-performance software development, revealing low success rates (under 5%) for current SWE-Agents.", "motivation": "To assess and improve language models' capabilities in optimizing software performance, given the complexity of high-performance development.", "method": "An automated pipeline generates and executes performance tests on 102 optimization tasks from 10 diverse codebases, measuring runtime efficiency against expert optimizations.", "result": "Leading SWE-Agents achieve less than 5% success, with challenges in low-level languages, lazy optimization, and bottleneck localization.", "conclusion": "GSO highlights significant gaps in current agents' abilities, providing a benchmark and artifacts for future research."}}
{"id": "2505.23555", "pdf": "https://arxiv.org/pdf/2505.23555", "abs": "https://arxiv.org/abs/2505.23555", "authors": ["Yanzhao Hou", "Jiaxiang Geng", "Boyu Li", "Xiaofeng Tao", "Juncheng Wang", "Xiaodong Xu", "Bing Luo"], "title": "Adaptive Federated LoRA in Heterogeneous Wireless Networks with Independent Sampling", "categories": ["cs.LG"], "comment": "13 pages, Submitted to IEEE Journal on Selected Areas in\n  Communications (JSAC)", "summary": "Federated LoRA has emerged as a promising technique for efficiently\nfine-tuning large language models (LLMs) on distributed devices by reducing the\nnumber of trainable parameters. However, existing approaches often inadequately\noverlook the theoretical and practical implications of system and data\nheterogeneity, thereby failing to optimize the overall training efficiency,\nparticularly in terms of wall-clock time. In this paper, we propose an adaptive\nfederated LoRA strategy with independent client sampling to minimize the\nconvergence wall-clock time of federated fine-tuning under both computation and\ncommunication heterogeneity. We first derive a new convergence bound for\nfederated LoRA with arbitrary and independent client sampling, notably without\nrequiring the stringent bounded gradient assumption. Then, we introduce an\nadaptive bandwidth allocation scheme that accounts for heterogeneous client\nresources and system bandwidth constraints. Based on the derived theory, we\nformulate and solve a non-convex optimization problem to jointly determine the\nLoRA sketching ratios and sampling probabilities, aiming to minimize wall-clock\nconvergence time. An efficient and low-complexity algorithm is developed to\napproximate the solution. Finally, extensive experiments demonstrate that our\napproach significantly reduces wall-clock training time compared to\nstate-of-the-art methods across various models and datasets.", "AI": {"tldr": "Proposes an adaptive federated LoRA strategy with independent client sampling to minimize wall-clock convergence time in federated fine-tuning, addressing system and data heterogeneity.", "motivation": "Existing federated LoRA approaches overlook system and data heterogeneity, failing to optimize training efficiency, especially in wall-clock time.", "method": "Derives a convergence bound for federated LoRA with independent client sampling, introduces adaptive bandwidth allocation, and formulates a non-convex optimization problem to jointly optimize LoRA sketching ratios and sampling probabilities.", "result": "Extensive experiments show significant reduction in wall-clock training time compared to state-of-the-art methods.", "conclusion": "The proposed adaptive federated LoRA strategy effectively minimizes convergence time under heterogeneous conditions."}}
{"id": "2505.23759", "pdf": "https://arxiv.org/pdf/2505.23759", "abs": "https://arxiv.org/abs/2505.23759", "authors": ["Heekyung Lee", "Jiaxin Ge", "Tsung-Han Wu", "Minwoo Kang", "Trevor Darrell", "David M. Chan"], "title": "Puzzled by Puzzles: When Vision-Language Models Can't Take a Hint", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Rebus puzzles, visual riddles that encode language through imagery, spatial\narrangement, and symbolic substitution, pose a unique challenge to current\nvision-language models (VLMs). Unlike traditional image captioning or question\nanswering tasks, rebus solving requires multi-modal abstraction, symbolic\nreasoning, and a grasp of cultural, phonetic and linguistic puns. In this\npaper, we investigate the capacity of contemporary VLMs to interpret and solve\nrebus puzzles by constructing a hand-generated and annotated benchmark of\ndiverse English-language rebus puzzles, ranging from simple pictographic\nsubstitutions to spatially-dependent cues (\"head\" over \"heels\"). We analyze how\ndifferent VLMs perform, and our findings reveal that while VLMs exhibit some\nsurprising capabilities in decoding simple visual clues, they struggle\nsignificantly with tasks requiring abstract reasoning, lateral thinking, and\nunderstanding visual metaphors.", "AI": {"tldr": "The paper evaluates vision-language models (VLMs) on solving rebus puzzles, finding they struggle with abstract reasoning and visual metaphors despite some success with simple clues.", "motivation": "Rebus puzzles challenge VLMs with multi-modal abstraction and symbolic reasoning, unlike traditional tasks, making them a unique test case.", "method": "A hand-generated benchmark of diverse rebus puzzles was created to analyze VLM performance.", "result": "VLMs perform well on simple visual clues but fail at abstract reasoning, lateral thinking, and visual metaphors.", "conclusion": "Current VLMs lack the nuanced understanding required for complex rebus puzzles, highlighting limitations in multi-modal reasoning."}}
{"id": "2505.23601", "pdf": "https://arxiv.org/pdf/2505.23601", "abs": "https://arxiv.org/abs/2505.23601", "authors": ["Shengyuan Liu", "Boyun Zheng", "Wenting Chen", "Zhihao Peng", "Zhenfei Yin", "Jing Shao", "Jiancong Hu", "Yixuan Yuan"], "title": "A Comprehensive Evaluation of Multi-Modal Large Language Models for Endoscopy Analysis", "categories": ["cs.CV"], "comment": "36 pages, 18 figures", "summary": "Endoscopic procedures are essential for diagnosing and treating internal\ndiseases, and multi-modal large language models (MLLMs) are increasingly\napplied to assist in endoscopy analysis. However, current benchmarks are\nlimited, as they typically cover specific endoscopic scenarios and a small set\nof clinical tasks, failing to capture the real-world diversity of endoscopic\nscenarios and the full range of skills needed in clinical workflows. To address\nthese issues, we introduce EndoBench, the first comprehensive benchmark\nspecifically designed to assess MLLMs across the full spectrum of endoscopic\npractice with multi-dimensional capacities. EndoBench encompasses 4 distinct\nendoscopic scenarios, 12 specialized clinical tasks with 12 secondary subtasks,\nand 5 levels of visual prompting granularities, resulting in 6,832 rigorously\nvalidated VQA pairs from 21 diverse datasets. Our multi-dimensional evaluation\nframework mirrors the clinical workflow--spanning anatomical recognition,\nlesion analysis, spatial localization, and surgical operations--to holistically\ngauge the perceptual and diagnostic abilities of MLLMs in realistic scenarios.\nWe benchmark 23 state-of-the-art models, including general-purpose,\nmedical-specialized, and proprietary MLLMs, and establish human clinician\nperformance as a reference standard. Our extensive experiments reveal: (1)\nproprietary MLLMs outperform open-source and medical-specialized models\noverall, but still trail human experts; (2) medical-domain supervised\nfine-tuning substantially boosts task-specific accuracy; and (3) model\nperformance remains sensitive to prompt format and clinical task complexity.\nEndoBench establishes a new standard for evaluating and advancing MLLMs in\nendoscopy, highlighting both progress and persistent gaps between current\nmodels and expert clinical reasoning. We publicly release our benchmark and\ncode.", "AI": {"tldr": "EndoBench is a comprehensive benchmark for evaluating multi-modal large language models (MLLMs) in endoscopy, covering diverse scenarios and clinical tasks, revealing gaps between models and human experts.", "motivation": "Current benchmarks for MLLMs in endoscopy are limited in scope and fail to capture real-world diversity, necessitating a more holistic evaluation framework.", "method": "EndoBench includes 4 endoscopic scenarios, 12 clinical tasks, and 5 visual prompting granularities, validated with 6,832 VQA pairs from 21 datasets. It evaluates 23 MLLMs against human clinician performance.", "result": "Proprietary MLLMs outperform others but lag behind human experts. Medical-domain fine-tuning improves accuracy, but performance varies with prompt format and task complexity.", "conclusion": "EndoBench sets a new standard for MLLM evaluation in endoscopy, highlighting progress and gaps, with benchmark and code publicly released."}}
{"id": "2505.23693", "pdf": "https://arxiv.org/pdf/2505.23693", "abs": "https://arxiv.org/abs/2505.23693", "authors": ["Tingyu Song", "Tongyan Hu", "Guo Gan", "Yilun Zhao"], "title": "VF-Eval: Evaluating Multimodal LLMs for Generating Feedback on AIGC Videos", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "ACL 2025 Main", "summary": "MLLMs have been widely studied for video question answering recently.\nHowever, most existing assessments focus on natural videos, overlooking\nsynthetic videos, such as AI-generated content (AIGC). Meanwhile, some works in\nvideo generation rely on MLLMs to evaluate the quality of generated videos, but\nthe capabilities of MLLMs on interpreting AIGC videos remain largely\nunderexplored. To address this, we propose a new benchmark, VF-Eval, which\nintroduces four tasks-coherence validation, error awareness, error type\ndetection, and reasoning evaluation-to comprehensively evaluate the abilities\nof MLLMs on AIGC videos. We evaluate 13 frontier MLLMs on VF-Eval and find that\neven the best-performing model, GPT-4.1, struggles to achieve consistently good\nperformance across all tasks. This highlights the challenging nature of our\nbenchmark. Additionally, to investigate the practical applications of VF-Eval\nin improving video generation, we conduct an experiment, RePrompt,\ndemonstrating that aligning MLLMs more closely with human feedback can benefit\nvideo generation.", "AI": {"tldr": "The paper introduces VF-Eval, a benchmark to evaluate MLLMs on synthetic (AIGC) videos, revealing their limitations and proposing RePrompt for improving video generation.", "motivation": "Existing evaluations of MLLMs for video question answering neglect synthetic videos, and their capabilities in interpreting AIGC videos are underexplored.", "method": "VF-Eval benchmark with four tasks (coherence validation, error awareness, error type detection, reasoning evaluation) is proposed to assess MLLMs. RePrompt aligns MLLMs with human feedback.", "result": "Even top models like GPT-4.1 perform inconsistently across tasks, showing the benchmark's difficulty. RePrompt improves video generation by aligning MLLMs with human feedback.", "conclusion": "VF-Eval highlights MLLMs' challenges with AIGC videos, and RePrompt demonstrates practical benefits for video generation."}}
{"id": "2505.23565", "pdf": "https://arxiv.org/pdf/2505.23565", "abs": "https://arxiv.org/abs/2505.23565", "authors": ["Jiashuo Liu", "Tianyu Wang", "Henry Lam", "Hongseok Namkoong", "Jose Blanchet"], "title": "DRO: A Python Library for Distributionally Robust Optimization in Machine Learning", "categories": ["cs.LG", "cs.MS", "cs.NA", "math.NA"], "comment": null, "summary": "We introduce dro, an open-source Python library for distributionally robust\noptimization (DRO) for regression and classification problems. The library\nimplements 14 DRO formulations and 9 backbone models, enabling 79 distinct DRO\nmethods. Furthermore, dro is compatible with both scikit-learn and PyTorch.\nThrough vectorization and optimization approximation techniques, dro reduces\nruntime by 10x to over 1000x compared to baseline implementations on\nlarge-scale datasets. Comprehensive documentation is available at\nhttps://python-dro.org.", "AI": {"tldr": "DRO is an open-source Python library for distributionally robust optimization (DRO) in regression and classification, offering 14 formulations and 9 backbone models, with significant runtime improvements.", "motivation": "To provide a versatile and efficient tool for DRO in machine learning, compatible with scikit-learn and PyTorch.", "method": "Implements 14 DRO formulations and 9 backbone models, using vectorization and optimization approximation for speed.", "result": "Reduces runtime by 10x to over 1000x on large datasets compared to baselines.", "conclusion": "DRO is a powerful, efficient library for DRO tasks, with extensive documentation and compatibility."}}
{"id": "2505.23765", "pdf": "https://arxiv.org/pdf/2505.23765", "abs": "https://arxiv.org/abs/2505.23765", "authors": ["Wentao Zhang", "Woojeong Kim", "Yuntian Deng"], "title": "From Chat Logs to Collective Insights: Aggregative Question Answering", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Conversational agents powered by large language models (LLMs) are rapidly\nbecoming integral to our daily interactions, generating unprecedented amounts\nof conversational data. Such datasets offer a powerful lens into societal\ninterests, trending topics, and collective concerns. Yet, existing approaches\ntypically treat these interactions as independent and miss critical insights\nthat could emerge from aggregating and reasoning across large-scale\nconversation logs. In this paper, we introduce Aggregative Question Answering,\na novel task requiring models to reason explicitly over thousands of\nuser-chatbot interactions to answer aggregative queries, such as identifying\nemerging concerns among specific demographics. To enable research in this\ndirection, we construct a benchmark, WildChat-AQA, comprising 6,027 aggregative\nquestions derived from 182,330 real-world chatbot conversations. Experiments\nshow that existing methods either struggle to reason effectively or incur\nprohibitive computational costs, underscoring the need for new approaches\ncapable of extracting collective insights from large-scale conversational data.", "AI": {"tldr": "The paper introduces Aggregative Question Answering (AQA), a task for reasoning over large-scale chatbot interactions to answer aggregative queries, and presents WildChat-AQA, a benchmark for this task.", "motivation": "Existing approaches treat chatbot interactions as independent, missing insights from aggregated data. The paper aims to address this gap by enabling models to reason across large-scale conversation logs.", "method": "The authors propose Aggregative Question Answering and create WildChat-AQA, a benchmark with 6,027 aggregative questions from 182,330 real-world chatbot conversations.", "result": "Experiments show current methods struggle with effective reasoning or face high computational costs, highlighting the need for new approaches.", "conclusion": "The paper underscores the importance of extracting collective insights from conversational data and introduces a novel task and benchmark to advance research in this area."}}
{"id": "2505.23629", "pdf": "https://arxiv.org/pdf/2505.23629", "abs": "https://arxiv.org/abs/2505.23629", "authors": ["Xiang Xiang Wang", "Tin-Yau Tam"], "title": "Color Image Set Recognition Based on Quaternionic Grassmannians", "categories": ["cs.CV", "math.AG"], "comment": null, "summary": "We propose a new method for recognizing color image sets using quaternionic\nGrassmannians, which use the power of quaternions to capture color information\nand represent each color image set as a point on the quaternionic Grassmannian.\nWe provide a direct formula to calculate the shortest distance between two\npoints on the quaternionic Grassmannian, and use this distance to build a new\nclassification framework. Experiments on the ETH-80 benchmark dataset show that\nour method achieves good recognition results. We also discuss some limitations\nin stability and suggest ways the method can be improved in the future.", "AI": {"tldr": "A novel method for color image set recognition using quaternionic Grassmannians, achieving good results on ETH-80, with noted stability limitations.", "motivation": "To leverage quaternions for capturing color information and improve recognition of color image sets.", "method": "Represent color image sets as points on quaternionic Grassmannians and use a direct distance formula for classification.", "result": "Achieves good recognition results on the ETH-80 dataset.", "conclusion": "The method is effective but has stability issues; future improvements are suggested."}}
{"id": "2505.23704", "pdf": "https://arxiv.org/pdf/2505.23704", "abs": "https://arxiv.org/abs/2505.23704", "authors": ["Mohamad Alansari", "Sajid Javed", "Iyyakutti Iyappan Ganapathi", "Sara Alansari", "Muzammal Naseer"], "title": "CLDTracker: A Comprehensive Language Description for Visual Tracking", "categories": ["cs.CV", "cs.AI"], "comment": "47 pages, 9 figures, Information Fusion Journal", "summary": "VOT remains a fundamental yet challenging task in computer vision due to\ndynamic appearance changes, occlusions, and background clutter. Traditional\ntrackers, relying primarily on visual cues, often struggle in such complex\nscenarios. Recent advancements in VLMs have shown promise in semantic\nunderstanding for tasks like open-vocabulary detection and image captioning,\nsuggesting their potential for VOT. However, the direct application of VLMs to\nVOT is hindered by critical limitations: the absence of a rich and\ncomprehensive textual representation that semantically captures the target\nobject's nuances, limiting the effective use of language information;\ninefficient fusion mechanisms that fail to optimally integrate visual and\ntextual features, preventing a holistic understanding of the target; and a lack\nof temporal modeling of the target's evolving appearance in the language\ndomain, leading to a disconnect between the initial description and the\nobject's subsequent visual changes. To bridge these gaps and unlock the full\npotential of VLMs for VOT, we propose CLDTracker, a novel Comprehensive\nLanguage Description framework for robust visual Tracking. Our tracker\nintroduces a dual-branch architecture consisting of a textual and a visual\nbranch. In the textual branch, we construct a rich bag of textual descriptions\nderived by harnessing the powerful VLMs such as CLIP and GPT-4V, enriched with\nsemantic and contextual cues to address the lack of rich textual\nrepresentation. Experiments on six standard VOT benchmarks demonstrate that\nCLDTracker achieves SOTA performance, validating the effectiveness of\nleveraging robust and temporally-adaptive vision-language representations for\ntracking. Code and models are publicly available at:\nhttps://github.com/HamadYA/CLDTracker", "AI": {"tldr": "CLDTracker introduces a dual-branch framework leveraging VLMs for robust visual tracking, addressing limitations in textual representation and feature fusion, achieving SOTA performance.", "motivation": "Traditional trackers struggle with dynamic changes and occlusions. VLMs show promise but face limitations in textual representation, fusion, and temporal modeling.", "method": "Proposes CLDTracker with a dual-branch (textual and visual) architecture, using VLMs like CLIP and GPT-4V for rich textual descriptions.", "result": "Achieves SOTA performance on six VOT benchmarks.", "conclusion": "CLDTracker effectively bridges gaps in VOT by integrating robust vision-language representations."}}
{"id": "2505.23569", "pdf": "https://arxiv.org/pdf/2505.23569", "abs": "https://arxiv.org/abs/2505.23569", "authors": ["Samo Hromadka", "Kai Biegun", "Lior Fox", "James Heald", "Maneesh Sahani"], "title": "Maximum Likelihood Learning of Latent Dynamics Without Reconstruction", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We introduce a novel unsupervised learning method for time series data with\nlatent dynamical structure: the recognition-parametrized Gaussian state space\nmodel (RP-GSSM). The RP-GSSM is a probabilistic model that learns Markovian\nGaussian latents explaining statistical dependence between observations at\ndifferent time steps, combining the intuition of contrastive methods with the\nflexible tools of probabilistic generative models. Unlike contrastive\napproaches, the RP-GSSM is a valid probabilistic model learned via maximum\nlikelihood. Unlike generative approaches, the RP-GSSM has no need for an\nexplicit network mapping from latents to observations, allowing it to focus\nmodel capacity on inference of latents. The model is both tractable and\nexpressive: it admits exact inference thanks to its jointly Gaussian latent\nprior, while maintaining expressivity with an arbitrarily nonlinear neural\nnetwork link between observations and latents. These qualities allow the\nRP-GSSM to learn task-relevant latents without ad-hoc regularization, auxiliary\nlosses, or optimizer scheduling. We show how this approach outperforms\nalternatives on problems that include learning nonlinear stochastic dynamics\nfrom video, with or without background distractors. Our results position the\nRP-GSSM as a useful foundation model for a variety of downstream applications.", "AI": {"tldr": "The paper introduces RP-GSSM, an unsupervised probabilistic model for time series data, combining contrastive learning and generative modeling without needing explicit latent-to-observation mappings.", "motivation": "To address limitations of contrastive and generative methods in learning latent dynamics from time series data, offering a tractable and expressive model.", "method": "RP-GSSM uses a Gaussian state space model with neural networks for nonlinear links, enabling exact inference and focusing capacity on latent inference.", "result": "RP-GSSM outperforms alternatives in learning nonlinear stochastic dynamics from video, even with distractors.", "conclusion": "RP-GSSM is a versatile foundation model for downstream applications, avoiding ad-hoc regularization or auxiliary losses."}}
{"id": "2505.22654", "pdf": "https://arxiv.org/pdf/2505.22654", "abs": "https://arxiv.org/abs/2505.22654", "authors": ["Ce Zhang", "Kaixin Ma", "Tianqing Fang", "Wenhao Yu", "Hongming Zhang", "Zhisong Zhang", "Yaqi Xie", "Katia Sycara", "Haitao Mi", "Dong Yu"], "title": "VScan: Rethinking Visual Token Reduction for Efficient Large Vision-Language Models", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Recent Large Vision-Language Models (LVLMs) have advanced multi-modal\nunderstanding by incorporating finer-grained visual perception and encoding.\nHowever, such methods incur significant computational costs due to longer\nvisual token sequences, posing challenges for real-time deployment. To mitigate\nthis, prior studies have explored pruning unimportant visual tokens either at\nthe output layer of the visual encoder or at the early layers of the language\nmodel. In this work, we revisit these design choices and reassess their\neffectiveness through comprehensive empirical studies of how visual tokens are\nprocessed throughout the visual encoding and language decoding stages. Guided\nby these insights, we propose VScan, a two-stage visual token reduction\nframework that addresses token redundancy by: (1) integrating complementary\nglobal and local scans with token merging during visual encoding, and (2)\nintroducing pruning at intermediate layers of the language model. Extensive\nexperimental results across four LVLMs validate the effectiveness of VScan in\naccelerating inference and demonstrate its superior performance over current\nstate-of-the-arts on sixteen benchmarks. Notably, when applied to\nLLaVA-NeXT-7B, VScan achieves a 2.91$\\times$ speedup in prefilling and a\n10$\\times$ reduction in FLOPs, while retaining 95.4% of the original\nperformance.", "AI": {"tldr": "VScan is a two-stage visual token reduction framework that speeds up LVLMs by pruning redundant tokens during visual encoding and language decoding, achieving significant speedups with minimal performance loss.", "motivation": "Current LVLMs incur high computational costs due to long visual token sequences, hindering real-time deployment. Prior token pruning methods are limited in effectiveness.", "method": "VScan integrates global and local scans with token merging during visual encoding and introduces pruning at intermediate language model layers.", "result": "VScan achieves a 2.91\u00d7 speedup and 10\u00d7 FLOPs reduction while retaining 95.4% of original performance on LLaVA-NeXT-7B.", "conclusion": "VScan effectively addresses token redundancy in LVLMs, offering a practical solution for faster inference without significant performance trade-offs."}}
{"id": "2505.23642", "pdf": "https://arxiv.org/pdf/2505.23642", "abs": "https://arxiv.org/abs/2505.23642", "authors": ["Nathaniel Burgdorfer", "Philippos Mordohai"], "title": "Radiant Triangle Soup with Soft Connectivity Forces for 3D Reconstruction and Novel View Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "In this work, we introduce an inference-time optimization framework utilizing\ntriangles to represent the geometry and appearance of the scene. More\nspecifically, we develop a scene optimization algorithm for triangle soup, a\ncollection of disconnected semi-transparent triangle primitives. Compared to\nthe current most-widely used primitives for 3D scene representation, namely\nGaussian splats, triangles allow for more expressive color interpolation, and\nbenefit from a large algorithmic infrastructure for downstream tasks.\nTriangles, unlike full-rank Gaussian kernels, naturally combine to form\nsurfaces. We formulate connectivity forces between triangles during\noptimization, encouraging explicit, but soft, surface continuity in 3D. We\nperform experiments on a representative 3D reconstruction dataset and show\ncompetitive photometric and geometric results.", "AI": {"tldr": "An inference-time optimization framework using triangles for 3D scene representation, outperforming Gaussian splats with better color interpolation and surface continuity.", "motivation": "To improve 3D scene representation by leveraging triangles for expressive color interpolation and surface continuity, benefiting from existing algorithmic infrastructure.", "method": "Develops a scene optimization algorithm for triangle soup, incorporating connectivity forces to encourage soft surface continuity during optimization.", "result": "Achieves competitive photometric and geometric results on a 3D reconstruction dataset.", "conclusion": "Triangles offer a superior alternative to Gaussian splats for 3D scene representation, enabling better interpolation and surface formation."}}
{"id": "2505.23706", "pdf": "https://arxiv.org/pdf/2505.23706", "abs": "https://arxiv.org/abs/2505.23706", "authors": ["Utku Demir", "Yalin E. Sagduyu", "Tugba Erpek", "Hossein Jafari", "Sastry Kompella", "Mengran Xue"], "title": "Distributed Federated Learning for Vehicular Network Security: Anomaly Detection Benefits and Multi-Domain Attack Threats", "categories": ["cs.NI", "cs.AI", "cs.DC", "cs.IT", "eess.SP", "math.IT"], "comment": null, "summary": "In connected and autonomous vehicles, machine learning for safety message\nclassification has become critical for detecting malicious or anomalous\nbehavior. However, conventional approaches that rely on centralized data\ncollection or purely local training face limitations due to the large scale,\nhigh mobility, and heterogeneous data distributions inherent in inter-vehicle\nnetworks. To overcome these challenges, this paper explores Distributed\nFederated Learning (DFL), whereby vehicles collaboratively train deep learning\nmodels by exchanging model updates among one-hop neighbors and propagating\nmodels over multiple hops. Using the Vehicular Reference Misbehavior (VeReMi)\nExtension Dataset, we show that DFL can significantly improve classification\naccuracy across all vehicles compared to learning strictly with local data.\nNotably, vehicles with low individual accuracy see substantial accuracy gains\nthrough DFL, illustrating the benefit of knowledge sharing across the network.\nWe further show that local training data size and time-varying network\nconnectivity correlate strongly with the model's overall accuracy. We\ninvestigate DFL's resilience and vulnerabilities under attacks in multiple\ndomains, namely wireless jamming and training data poisoning attacks. Our\nresults reveal important insights into the vulnerabilities of DFL when\nconfronted with multi-domain attacks, underlining the need for more robust\nstrategies to secure DFL in vehicular networks.", "AI": {"tldr": "The paper explores Distributed Federated Learning (DFL) for safety message classification in autonomous vehicles, showing improved accuracy and resilience challenges under multi-domain attacks.", "motivation": "Address limitations of centralized or purely local training in vehicular networks due to scale, mobility, and data heterogeneity.", "method": "Proposes DFL where vehicles collaborate by exchanging model updates among neighbors and propagating models over multiple hops, tested on the VeReMi dataset.", "result": "DFL improves classification accuracy, especially for low-accuracy vehicles, and reveals correlations between local data size, connectivity, and accuracy. It also exposes vulnerabilities to wireless jamming and data poisoning attacks.", "conclusion": "DFL enhances accuracy but requires robust strategies to counter multi-domain attacks for secure deployment in vehicular networks."}}
{"id": "2505.23579", "pdf": "https://arxiv.org/pdf/2505.23579", "abs": "https://arxiv.org/abs/2505.23579", "authors": ["Adibvafa Fallahpour", "Andrew Magnuson", "Purav Gupta", "Shihao Ma", "Jack Naimer", "Arnav Shah", "Haonan Duan", "Omar Ibrahim", "Hani Goodarzi", "Chris J. Maddison", "Bo Wang"], "title": "BioReason: Incentivizing Multimodal Biological Reasoning within a DNA-LLM Model", "categories": ["cs.LG"], "comment": "16 pages, 3 figures, 2 tables", "summary": "Unlocking deep, interpretable biological reasoning from complex genomic data\nis a major AI challenge hindering scientific discovery. Current DNA foundation\nmodels, despite strong sequence representation, struggle with multi-step\nreasoning and lack inherent transparent, biologically intuitive explanations.\nWe introduce BioReason, a pioneering architecture that, for the first time,\ndeeply integrates a DNA foundation model with a Large Language Model (LLM).\nThis novel connection enables the LLM to directly process and reason with\ngenomic information as a fundamental input, fostering a new form of multimodal\nbiological understanding. BioReason's sophisticated multi-step reasoning is\ndeveloped through supervised fine-tuning and targeted reinforcement learning,\nguiding the system to generate logical, biologically coherent deductions. On\nbiological reasoning benchmarks including KEGG-based disease pathway prediction\n- where accuracy improves from 88% to 97% - and variant effect prediction,\nBioReason demonstrates an average 15% performance gain over strong\nsingle-modality baselines. BioReason reasons over unseen biological entities\nand articulates decision-making through interpretable, step-by-step biological\ntraces, offering a transformative approach for AI in biology that enables\ndeeper mechanistic insights and accelerates testable hypothesis generation from\ngenomic data. Data, code, and checkpoints are publicly available at\nhttps://github.com/bowang-lab/BioReason", "AI": {"tldr": "BioReason integrates a DNA foundation model with a Large Language Model (LLM) to enable deep, interpretable biological reasoning from genomic data, outperforming baselines by 15%.", "motivation": "Current DNA foundation models lack multi-step reasoning and transparent explanations, limiting scientific discovery.", "method": "Combines DNA foundation model with LLM, using supervised fine-tuning and reinforcement learning for multi-step reasoning.", "result": "Achieves 97% accuracy in disease pathway prediction (vs. 88% baseline) and 15% average performance gain.", "conclusion": "BioReason offers interpretable, step-by-step reasoning, advancing AI's role in biological discovery."}}
{"id": "2505.22863", "pdf": "https://arxiv.org/pdf/2505.22863", "abs": "https://arxiv.org/abs/2505.22863", "authors": ["Yupei Li", "Shuaijie Shao", "Manuel Milling", "Bj\u00f6rn W. Schuller"], "title": "Large Language Models for Depression Recognition in Spoken Language Integrating Psychological Knowledge", "categories": ["cs.HC", "cs.CL"], "comment": null, "summary": "Depression is a growing concern gaining attention in both public discourse\nand AI research. While deep neural networks (DNNs) have been used for\nrecognition, they still lack real-world effectiveness. Large language models\n(LLMs) show strong potential but require domain-specific fine-tuning and\nstruggle with non-textual cues. Since depression is often expressed through\nvocal tone and behaviour rather than explicit text, relying on language alone\nis insufficient. Diagnostic accuracy also suffers without incorporating\npsychological expertise. To address these limitations, we present, to the best\nof our knowledge, the first application of LLMs to multimodal depression\ndetection using the DAIC-WOZ dataset. We extract the audio features using the\npre-trained model Wav2Vec, and mapped it to text-based LLMs for further\nprocessing. We also propose a novel strategy for incorporating psychological\nknowledge into LLMs to enhance diagnostic performance, specifically using a\nquestion and answer set to grant authorised knowledge to LLMs. Our approach\nyields a notable improvement in both Mean Absolute Error (MAE) and Root Mean\nSquare Error (RMSE) compared to a base score proposed by the related original\npaper. The codes are available at\nhttps://github.com/myxp-lyp/Depression-detection.git", "AI": {"tldr": "The paper proposes a multimodal depression detection method combining LLMs with audio features and psychological knowledge, showing improved accuracy.", "motivation": "Existing DNNs and LLMs lack effectiveness in real-world depression detection due to reliance on text alone and absence of psychological expertise.", "method": "Uses Wav2Vec for audio feature extraction, maps to LLMs, and integrates psychological knowledge via Q&A sets.", "result": "Notable improvement in MAE and RMSE compared to baseline.", "conclusion": "The approach enhances depression detection by leveraging multimodal data and psychological insights."}}
{"id": "2505.23656", "pdf": "https://arxiv.org/pdf/2505.23656", "abs": "https://arxiv.org/abs/2505.23656", "authors": ["Xiangdong Zhang", "Jiaqi Liao", "Shaofeng Zhang", "Fanqing Meng", "Xiangpeng Wan", "Junchi Yan", "Yu Cheng"], "title": "VideoREPA: Learning Physics for Video Generation through Relational Alignment with Foundation Models", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in text-to-video (T2V) diffusion models have enabled\nhigh-fidelity and realistic video synthesis. However, current T2V models often\nstruggle to generate physically plausible content due to their limited inherent\nability to accurately understand physics. We found that while the\nrepresentations within T2V models possess some capacity for physics\nunderstanding, they lag significantly behind those from recent video\nself-supervised learning methods. To this end, we propose a novel framework\ncalled VideoREPA, which distills physics understanding capability from video\nunderstanding foundation models into T2V models by aligning token-level\nrelations. This closes the physics understanding gap and enable more\nphysics-plausible generation. Specifically, we introduce the Token Relation\nDistillation (TRD) loss, leveraging spatio-temporal alignment to provide soft\nguidance suitable for finetuning powerful pre-trained T2V models, a critical\ndeparture from prior representation alignment (REPA) methods. To our knowledge,\nVideoREPA is the first REPA method designed for finetuning T2V models and\nspecifically for injecting physical knowledge. Empirical evaluations show that\nVideoREPA substantially enhances the physics commonsense of baseline method,\nCogVideoX, achieving significant improvement on relevant benchmarks and\ndemonstrating a strong capacity for generating videos consistent with intuitive\nphysics. More video results are available at https://videorepa.github.io/.", "AI": {"tldr": "VideoREPA improves physics plausibility in text-to-video models by distilling knowledge from video understanding models using token relation alignment.", "motivation": "Current T2V models lack accurate physics understanding, limiting realistic video synthesis.", "method": "Proposes VideoREPA with Token Relation Distillation (TRD) loss to align token-level relations from video foundation models to T2V models.", "result": "VideoREPA significantly enhances physics commonsense in CogVideoX, improving benchmark performance.", "conclusion": "VideoREPA effectively bridges the physics understanding gap in T2V models, enabling more plausible video generation."}}
{"id": "2505.23709", "pdf": "https://arxiv.org/pdf/2505.23709", "abs": "https://arxiv.org/abs/2505.23709", "authors": ["Dionysis Christopoulos", "Sotiris Spanos", "Eirini Baltzi", "Valsamis Ntouskos", "Konstantinos Karantzalos"], "title": "Skin Lesion Phenotyping via Nested Multi-modal Contrastive Learning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce SLIMP (Skin Lesion Image-Metadata Pre-training) for learning\nrich representations of skin lesions through a novel nested contrastive\nlearning approach that captures complex relationships between images and\nmetadata. Melanoma detection and skin lesion classification based solely on\nimages, pose significant challenges due to large variations in imaging\nconditions (lighting, color, resolution, distance, etc.) and lack of clinical\nand phenotypical context. Clinicians typically follow a holistic approach for\nassessing the risk level of the patient and for deciding which lesions may be\nmalignant and need to be excised, by considering the patient's medical history\nas well as the appearance of other lesions of the patient. Inspired by this,\nSLIMP combines the appearance and the metadata of individual skin lesions with\npatient-level metadata relating to their medical record and other clinically\nrelevant information. By fully exploiting all available data modalities\nthroughout the learning process, the proposed pre-training strategy improves\nperformance compared to other pre-training strategies on downstream skin\nlesions classification tasks highlighting the learned representations quality.", "AI": {"tldr": "SLIMP uses nested contrastive learning to combine skin lesion images and metadata, improving classification performance by leveraging patient-level context.", "motivation": "Melanoma detection is challenging due to image variability and lack of clinical context. Clinicians use holistic patient data, inspiring SLIMP to integrate images and metadata.", "method": "SLIMP employs nested contrastive learning to capture relationships between images and metadata, including patient-level clinical data.", "result": "SLIMP outperforms other pre-training methods in skin lesion classification, demonstrating high-quality learned representations.", "conclusion": "SLIMP effectively combines images and metadata for better skin lesion classification, mimicking clinical decision-making."}}
{"id": "2505.23583", "pdf": "https://arxiv.org/pdf/2505.23583", "abs": "https://arxiv.org/abs/2505.23583", "authors": ["Zhiding Liu", "Mingyue Cheng", "Guanhao Zhao", "Jiqian Yang", "Qi Liu", "Enhong Chen"], "title": "Improving Time Series Forecasting via Instance-aware Post-hoc Revision", "categories": ["cs.LG"], "comment": null, "summary": "Time series forecasting plays a vital role in various real-world applications\nand has attracted significant attention in recent decades. While recent methods\nhave achieved remarkable accuracy by incorporating advanced inductive biases\nand training strategies, we observe that instance-level variations remain a\nsignificant challenge. These variations--stemming from distribution shifts,\nmissing data, and long-tail patterns--often lead to suboptimal forecasts for\nspecific instances, even when overall performance appears strong. To address\nthis issue, we propose a model-agnostic framework, PIR, designed to enhance\nforecasting performance through Post-forecasting Identification and Revision.\nSpecifically, PIR first identifies biased forecasting instances by estimating\ntheir accuracy. Based on this, the framework revises the forecasts using\ncontextual information, including covariates and historical time series, from\nboth local and global perspectives in a post-processing fashion. Extensive\nexperiments on real-world datasets with mainstream forecasting models\ndemonstrate that PIR effectively mitigates instance-level errors and\nsignificantly improves forecasting reliability.", "AI": {"tldr": "PIR is a model-agnostic framework for improving time series forecasting by identifying and revising biased forecasts post-forecasting.", "motivation": "Instance-level variations (e.g., distribution shifts, missing data) degrade forecasting accuracy despite strong overall performance.", "method": "PIR identifies biased forecasts by estimating accuracy and revises them using contextual information (covariates, historical data) from local and global perspectives.", "result": "PIR reduces instance-level errors and enhances forecasting reliability in real-world datasets.", "conclusion": "PIR effectively addresses instance-level forecasting challenges, improving accuracy and reliability."}}
{"id": "2505.22907", "pdf": "https://arxiv.org/pdf/2505.22907", "abs": "https://arxiv.org/abs/2505.22907", "authors": ["Rachel Katharine Sterken", "James Ravi Kirkpatrick"], "title": "Conversational Alignment with Artificial Intelligence in Context", "categories": ["cs.CY", "cs.CL"], "comment": "20 pages, to be published in Philosophical Perspectives", "summary": "The development of sophisticated artificial intelligence (AI) conversational\nagents based on large language models raises important questions about the\nrelationship between human norms, values, and practices and AI design and\nperformance. This article explores what it means for AI agents to be\nconversationally aligned to human communicative norms and practices for\nhandling context and common ground and proposes a new framework for evaluating\ndevelopers' design choices. We begin by drawing on the philosophical and\nlinguistic literature on conversational pragmatics to motivate a set of\ndesiderata, which we call the CONTEXT-ALIGN framework, for conversational\nalignment with human communicative practices. We then suggest that current\nlarge language model (LLM) architectures, constraints, and affordances may\nimpose fundamental limitations on achieving full conversational alignment.", "AI": {"tldr": "The paper proposes a framework (CONTEXT-ALIGN) to evaluate AI conversational agents' alignment with human communicative norms, highlighting limitations of current LLMs.", "motivation": "To explore how AI agents can align with human conversational norms and practices, addressing gaps in current AI design.", "method": "Draws on philosophical and linguistic literature to create the CONTEXT-ALIGN framework for evaluating conversational alignment.", "result": "Identifies fundamental limitations in current LLM architectures for achieving full conversational alignment.", "conclusion": "Proposes the need for new approaches to bridge the gap between AI design and human communicative norms."}}
{"id": "2505.23660", "pdf": "https://arxiv.org/pdf/2505.23660", "abs": "https://arxiv.org/abs/2505.23660", "authors": ["Ziteng Gao", "Mike Zheng Shou"], "title": "D-AR: Diffusion via Autoregressive Models", "categories": ["cs.CV"], "comment": "Technical report", "summary": "This paper presents Diffusion via Autoregressive models (D-AR), a new\nparadigm recasting the image diffusion process as a vanilla autoregressive\nprocedure in the standard next-token-prediction fashion. We start by designing\nthe tokenizer that converts images into sequences of discrete tokens, where\ntokens in different positions can be decoded into different diffusion denoising\nsteps in the pixel space. Thanks to the diffusion properties, these tokens\nnaturally follow a coarse-to-fine order, which directly lends itself to\nautoregressive modeling. Therefore, we apply standard next-token prediction on\nthese tokens, without modifying any underlying designs (either causal masks or\ntraining/inference strategies), and such sequential autoregressive token\ngeneration directly mirrors the diffusion procedure in image space. That is,\nonce the autoregressive model generates an increment of tokens, we can directly\ndecode these tokens into the corresponding diffusion denoising step in the\nstreaming manner. Our pipeline naturally reveals several intriguing properties,\nfor example, it supports consistent previews when generating only a subset of\ntokens and enables zero-shot layout-controlled synthesis. On the standard\nImageNet benchmark, our method achieves 2.09 FID using a 775M Llama backbone\nwith 256 discrete tokens. We hope our work can inspire future research on\nunified autoregressive architectures of visual synthesis, especially with large\nlanguage models. Code and models will be available at\nhttps://github.com/showlab/D-AR", "AI": {"tldr": "D-AR recasts image diffusion as autoregressive next-token prediction, achieving 2.09 FID on ImageNet with a 775M Llama backbone.", "motivation": "To unify image diffusion with autoregressive modeling for simpler, more efficient visual synthesis.", "method": "Tokenizes images into sequences representing diffusion steps, applies standard next-token prediction without modifying causal masks or strategies.", "result": "Achieves 2.09 FID on ImageNet, supports previews and zero-shot layout control.", "conclusion": "D-AR inspires future unified autoregressive visual synthesis, especially with large language models."}}
{"id": "2505.23710", "pdf": "https://arxiv.org/pdf/2505.23710", "abs": "https://arxiv.org/abs/2505.23710", "authors": ["Zeinab Nezami", "Syed Danial Ali Shah", "Maryam Hafeez", "Karim Djemame", "Syed Ali Raza Zaidi"], "title": "From Connectivity to Autonomy: The Dawn of Self-Evolving Communication Systems", "categories": ["eess.SY", "cs.AI", "cs.DC", "cs.ET", "cs.SY"], "comment": null, "summary": "This paper envisions 6G as a self-evolving telecom ecosystem, where AI-driven\nintelligence enables dynamic adaptation beyond static connectivity. We explore\nthe key enablers of autonomous communication systems, spanning reconfigurable\ninfrastructure, adaptive middleware, and intelligent network functions,\nalongside multi-agent collaboration for distributed decision-making. We explore\nhow these methodologies align with emerging industrial IoT frameworks, ensuring\nseamless integration within digital manufacturing processes. Our findings\nemphasize the potential for improved real-time decision-making, optimizing\nefficiency, and reducing latency in networked control systems. The discussion\naddresses ethical challenges, research directions, and standardization efforts,\nconcluding with a technology stack roadmap to guide future developments. By\nleveraging state-of-the-art 6G network management techniques, this research\ncontributes to the next generation of intelligent automation solutions,\nbridging the gap between theoretical advancements and real-world industrial\napplications.", "AI": {"tldr": "The paper envisions 6G as a self-evolving telecom ecosystem with AI-driven intelligence, focusing on autonomous communication systems, industrial IoT integration, and improved real-time decision-making.", "motivation": "To explore how AI-driven 6G can enable dynamic adaptation and autonomous communication, aligning with industrial IoT frameworks for digital manufacturing.", "method": "Investigates reconfigurable infrastructure, adaptive middleware, intelligent network functions, and multi-agent collaboration for distributed decision-making.", "result": "Highlights potential for improved efficiency, reduced latency, and seamless integration in networked control systems.", "conclusion": "Proposes a technology stack roadmap for future 6G developments, addressing ethical challenges and standardization to bridge theory and industrial applications."}}
{"id": "2505.23585", "pdf": "https://arxiv.org/pdf/2505.23585", "abs": "https://arxiv.org/abs/2505.23585", "authors": ["Yaru Hao", "Li Dong", "Xun Wu", "Shaohan Huang", "Zewen Chi", "Furu Wei"], "title": "On-Policy RL with Optimal Reward Baseline", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Reinforcement learning algorithms are fundamental to align large language\nmodels with human preferences and to enhance their reasoning capabilities.\nHowever, current reinforcement learning algorithms often suffer from training\ninstability due to loose on-policy constraints and computational inefficiency\ndue to auxiliary models. In this work, we propose On-Policy RL with Optimal\nreward baseline (OPO), a novel and simplified reinforcement learning algorithm\ndesigned to address these challenges. OPO emphasizes the importance of exact\non-policy training, which empirically stabilizes the training process and\nenhances exploration. Moreover, OPO introduces the optimal reward baseline that\ntheoretically minimizes gradient variance. We evaluate OPO on mathematical\nreasoning benchmarks. The results demonstrate its superior performance and\ntraining stability without additional models or regularization terms.\nFurthermore, OPO achieves lower policy shifts and higher output entropy,\nencouraging more diverse and less repetitive responses. These results highlight\nOPO as a promising direction for stable and effective reinforcement learning in\nlarge language model alignment and reasoning tasks. The implementation is\nprovided at https://github.com/microsoft/LMOps/tree/main/opo.", "AI": {"tldr": "OPO is a simplified reinforcement learning algorithm for large language models, improving training stability and efficiency by enforcing exact on-policy training and using an optimal reward baseline.", "motivation": "Current reinforcement learning algorithms for aligning large language models with human preferences suffer from instability and inefficiency due to loose on-policy constraints and auxiliary models.", "method": "OPO enforces exact on-policy training and introduces an optimal reward baseline to minimize gradient variance, eliminating the need for auxiliary models or regularization.", "result": "OPO outperforms benchmarks in mathematical reasoning, showing superior stability, lower policy shifts, and higher output entropy for diverse responses.", "conclusion": "OPO is a promising approach for stable and effective reinforcement learning in language model alignment and reasoning tasks."}}
{"id": "2505.23039", "pdf": "https://arxiv.org/pdf/2505.23039", "abs": "https://arxiv.org/abs/2505.23039", "authors": ["Kapil Vaidya", "Jialin Ding", "Sebastian Kosak", "David Kernert", "Chuan Lei", "Xiao Qin", "Abhinav Tripathy", "Ramesh Balan", "Balakrishnan Narayanaswamy", "Tim Kraska"], "title": "TailorSQL: An NL2SQL System Tailored to Your Query Workload", "categories": ["cs.DB", "cs.CL"], "comment": null, "summary": "NL2SQL (natural language to SQL) translates natural language questions into\nSQL queries, thereby making structured data accessible to non-technical users,\nserving as the foundation for intelligent data applications. State-of-the-art\nNL2SQL techniques typically perform translation by retrieving database-specific\ninformation, such as the database schema, and invoking a pre-trained large\nlanguage model (LLM) using the question and retrieved information to generate\nthe SQL query.\n  However, existing NL2SQL techniques miss a key opportunity which is present\nin real-world settings: NL2SQL is typically applied on existing databases which\nhave already served many SQL queries in the past. The past query workload\nimplicitly contains information which is helpful for accurate NL2SQL\ntranslation and is not apparent from the database schema alone, such as common\njoin paths and the semantics of obscurely-named tables and columns. We\nintroduce TailorSQL, a NL2SQL system that takes advantage of information in the\npast query workload to improve both the accuracy and latency of translating\nnatural language questions into SQL. By specializing to a given workload,\nTailorSQL achieves up to 2$\\times$ improvement in execution accuracy on\nstandardized benchmarks.", "AI": {"tldr": "TailorSQL improves NL2SQL translation by leveraging past query workloads, achieving up to 2x better accuracy.", "motivation": "Existing NL2SQL techniques overlook the valuable information in past query workloads, which can enhance translation accuracy and latency.", "method": "TailorSQL utilizes past query workloads to inform NL2SQL translation, capturing implicit details like common join paths and table semantics.", "result": "TailorSQL achieves up to a 2x improvement in execution accuracy on standardized benchmarks.", "conclusion": "Leveraging past query workloads significantly enhances NL2SQL performance, making TailorSQL a promising advancement in the field."}}
{"id": "2505.23661", "pdf": "https://arxiv.org/pdf/2505.23661", "abs": "https://arxiv.org/abs/2505.23661", "authors": ["Size Wu", "Zhonghua Wu", "Zerui Gong", "Qingyi Tao", "Sheng Jin", "Qinyue Li", "Wei Li", "Chen Change Loy"], "title": "OpenUni: A Simple Baseline for Unified Multimodal Understanding and Generation", "categories": ["cs.CV"], "comment": null, "summary": "In this report, we present OpenUni, a simple, lightweight, and fully\nopen-source baseline for unifying multimodal understanding and generation.\nInspired by prevailing practices in unified model learning, we adopt an\nefficient training strategy that minimizes the training complexity and overhead\nby bridging the off-the-shelf multimodal large language models (LLMs) and\ndiffusion models through a set of learnable queries and a light-weight\ntransformer-based connector. With a minimalist choice of architecture, we\ndemonstrate that OpenUni can: 1) generate high-quality and instruction-aligned\nimages, and 2) achieve exceptional performance on standard benchmarks such as\nGenEval, DPG- Bench, and WISE, with only 1.1B and 3.1B activated parameters. To\nsupport open research and community advancement, we release all model weights,\ntraining code, and our curated training datasets (including 23M image-text\npairs) at https://github.com/wusize/OpenUni.", "AI": {"tldr": "OpenUni is a lightweight, open-source baseline unifying multimodal understanding and generation, using efficient training with LLMs and diffusion models, achieving strong performance with minimal parameters.", "motivation": "To provide a simple, open-source solution for unifying multimodal tasks, reducing training complexity while maintaining performance.", "method": "Uses learnable queries and a transformer-based connector to bridge LLMs and diffusion models, with minimalist architecture.", "result": "Generates high-quality images and excels on benchmarks (GenEval, DPG-Bench, WISE) with 1.1B-3.1B parameters.", "conclusion": "OpenUni is effective and efficient, with all resources released for community use."}}
{"id": "2505.23720", "pdf": "https://arxiv.org/pdf/2505.23720", "abs": "https://arxiv.org/abs/2505.23720", "authors": ["Arun Verma", "Indrajit Saha", "Makoto Yokoo", "Bryan Kian Hsiang Low"], "title": "COBRA: Contextual Bandit Algorithm for Ensuring Truthful Strategic Agents", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "This paper proposes a contextual bandit algorithm that prevents\n  strategic agents from misreporting while having approximate incentive\n  compatibility and a sub-linear regret guarantee", "summary": "This paper considers a contextual bandit problem involving multiple agents,\nwhere a learner sequentially observes the contexts and the agent's reported\narms, and then selects the arm that maximizes the system's overall reward.\nExisting work in contextual bandits assumes that agents truthfully report their\narms, which is unrealistic in many real-life applications. For instance,\nconsider an online platform with multiple sellers; some sellers may\nmisrepresent product quality to gain an advantage, such as having the platform\npreferentially recommend their products to online users. To address this\nchallenge, we propose an algorithm, COBRA, for contextual bandit problems\ninvolving strategic agents that disincentivize their strategic behavior without\nusing any monetary incentives, while having incentive compatibility and a\nsub-linear regret guarantee. Our experimental results also validate the\ndifferent performance aspects of our proposed algorithm.", "AI": {"tldr": "Proposes COBRA, an algorithm for contextual bandit problems with strategic agents, ensuring incentive compatibility and sub-linear regret without monetary incentives.", "motivation": "Addresses the unrealistic assumption of truthful arm reporting in existing contextual bandit work, particularly in scenarios like online platforms with misrepresenting sellers.", "method": "Introduces COBRA, an algorithm designed to disincentivize strategic behavior in agents while maintaining incentive compatibility and sub-linear regret.", "result": "Experimental results validate COBRA's performance in handling strategic agents.", "conclusion": "COBRA effectively addresses strategic behavior in contextual bandit problems without monetary incentives, with proven performance."}}
{"id": "2505.23588", "pdf": "https://arxiv.org/pdf/2505.23588", "abs": "https://arxiv.org/abs/2505.23588", "authors": ["Mrinmay Sen", "Sidhant R Nair", "C Krishna Mohan"], "title": "Accelerated Training of Federated Learning via Second-Order Methods", "categories": ["cs.LG", "cs.DC", "68Q25, 68T05, 90C06, 90C25, 90C30", "I.2.6; G.1.6; C.2.4; C.4"], "comment": "17 pages, 1 figure, 4 tables, submitted to IEEE Transactions on\n  Pattern Analysis and Machine Intelligence (T-PAMI)", "summary": "This paper explores second-order optimization methods in Federated Learning\n(FL), addressing the critical challenges of slow convergence and the excessive\ncommunication rounds required to achieve optimal performance from the global\nmodel. While existing surveys in FL primarily focus on challenges related to\nstatistical and device label heterogeneity, as well as privacy and security\nconcerns in first-order FL methods, less attention has been given to the issue\nof slow model training. This slow training often leads to the need for\nexcessive communication rounds or increased communication costs, particularly\nwhen data across clients are highly heterogeneous. In this paper, we examine\nvarious FL methods that leverage second-order optimization to accelerate the\ntraining process. We provide a comprehensive categorization of state-of-the-art\nsecond-order FL methods and compare their performance based on convergence\nspeed, computational cost, memory usage, transmission overhead, and\ngeneralization of the global model. Our findings show the potential of\nincorporating Hessian curvature through second-order optimization into FL and\nhighlight key challenges, such as the efficient utilization of Hessian and its\ninverse in FL. This work lays the groundwork for future research aimed at\ndeveloping scalable and efficient federated optimization methods for improving\nthe training of the global model in FL.", "AI": {"tldr": "This paper reviews second-order optimization methods in Federated Learning (FL) to address slow convergence and high communication costs, comparing their performance and highlighting challenges like Hessian utilization.", "motivation": "Slow model training and excessive communication rounds in FL, especially with heterogeneous data, motivate exploring second-order optimization for faster convergence.", "method": "The paper categorizes and analyzes state-of-the-art second-order FL methods, evaluating them on convergence speed, computational cost, memory usage, transmission overhead, and model generalization.", "result": "Second-order optimization shows promise in accelerating FL training, but challenges like efficient Hessian and its inverse utilization remain.", "conclusion": "This study sets a foundation for future research on scalable and efficient federated optimization methods to improve global model training in FL."}}
{"id": "2505.23675", "pdf": "https://arxiv.org/pdf/2505.23675", "abs": "https://arxiv.org/abs/2505.23675", "authors": ["Moinak Bhattacharya", "Judy Huang", "Amna F. Sher", "Gagandeep Singh", "Chao Chen", "Prateek Prasanna"], "title": "ImmunoDiff: A Diffusion Model for Immunotherapy Response Prediction in Lung Cancer", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Accurately predicting immunotherapy response in Non-Small Cell Lung Cancer\n(NSCLC) remains a critical unmet need. Existing radiomics and deep\nlearning-based predictive models rely primarily on pre-treatment imaging to\npredict categorical response outcomes, limiting their ability to capture the\ncomplex morphological and textural transformations induced by immunotherapy.\nThis study introduces ImmunoDiff, an anatomy-aware diffusion model designed to\nsynthesize post-treatment CT scans from baseline imaging while incorporating\nclinically relevant constraints. The proposed framework integrates anatomical\npriors, specifically lobar and vascular structures, to enhance fidelity in CT\nsynthesis. Additionally, we introduce a novel cbi-Adapter, a conditioning\nmodule that ensures pairwise-consistent multimodal integration of imaging and\nclinical data embeddings, to refine the generative process. Additionally, a\nclinical variable conditioning mechanism is introduced, leveraging demographic\ndata, blood-based biomarkers, and PD-L1 expression to refine the generative\nprocess. Evaluations on an in-house NSCLC cohort treated with immune checkpoint\ninhibitors demonstrate a 21.24% improvement in balanced accuracy for response\nprediction and a 0.03 increase in c-index for survival prediction. Code will be\nreleased soon.", "AI": {"tldr": "ImmunoDiff, an anatomy-aware diffusion model, improves immunotherapy response prediction in NSCLC by synthesizing post-treatment CT scans from baseline imaging, integrating anatomical priors and clinical data.", "motivation": "Accurate prediction of immunotherapy response in NSCLC is challenging due to limitations in existing models that rely on pre-treatment imaging alone.", "method": "ImmunoDiff synthesizes post-treatment CT scans using baseline imaging, anatomical priors (lobar/vascular structures), and clinical data via a cbi-Adapter for multimodal integration.", "result": "The model achieves a 21.24% improvement in balanced accuracy for response prediction and a 0.03 increase in c-index for survival prediction.", "conclusion": "ImmunoDiff enhances immunotherapy response prediction by capturing complex morphological changes and integrating clinical data, offering a promising tool for NSCLC treatment."}}
{"id": "2505.23724", "pdf": "https://arxiv.org/pdf/2505.23724", "abs": "https://arxiv.org/abs/2505.23724", "authors": ["Minrui Luo", "Fuhang Kuang", "Yu Wang", "Zirui Liu", "Tianxing He"], "title": "SC-LoRA: Balancing Efficient Fine-tuning and Knowledge Preservation via Subspace-Constrained LoRA", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Parameter-Efficient Fine-Tuning (PEFT) methods, particularly Low-Rank\nAdaptation (LoRA), are indispensable for efficiently customizing Large Language\nModels (LLMs). However, vanilla LoRA suffers from slow convergence speed and\nknowledge forgetting problems. Recent studies have leveraged the power of\ndesigned LoRA initialization, to enhance the fine-tuning efficiency, or to\npreserve knowledge in the pre-trained LLM. However, none of these works can\naddress the two cases at the same time. To this end, we introduce\nSubspace-Constrained LoRA (SC-LoRA), a novel LoRA initialization framework\nengineered to navigate the trade-off between efficient fine-tuning and\nknowledge preservation. We achieve this by constraining the output of trainable\nLoRA adapters in a low-rank subspace, where the context information of\nfine-tuning data is most preserved while the context information of preserved\nknowledge is least retained, in a balanced way. Such constraint enables the\ntrainable weights to primarily focus on the main features of fine-tuning data\nwhile avoiding damaging the preserved knowledge features. We provide\ntheoretical analysis on our method, and conduct extensive experiments including\nsafety preservation and world knowledge preservation, on various downstream\ntasks. In our experiments, SC-LoRA succeeds in delivering superior fine-tuning\nperformance while markedly diminishing knowledge forgetting, surpassing\ncontemporary LoRA initialization methods.", "AI": {"tldr": "SC-LoRA is a new LoRA initialization framework that balances efficient fine-tuning and knowledge preservation in LLMs, outperforming existing methods.", "motivation": "Vanilla LoRA has slow convergence and knowledge forgetting issues; existing methods address either efficiency or preservation, not both.", "method": "SC-LoRA constrains LoRA adapters in a low-rank subspace to focus on fine-tuning data while preserving pre-trained knowledge.", "result": "SC-LoRA achieves better fine-tuning performance and reduces knowledge forgetting compared to other LoRA methods.", "conclusion": "SC-LoRA effectively balances fine-tuning efficiency and knowledge preservation, offering a superior alternative to current LoRA techniques."}}
{"id": "2505.23593", "pdf": "https://arxiv.org/pdf/2505.23593", "abs": "https://arxiv.org/abs/2505.23593", "authors": ["Nikita Agrawal", "Simon Mertel", "Ruben Mayer"], "title": "Position: Federated Foundation Language Model Post-Training Should Focus on Open-Source Models", "categories": ["cs.LG"], "comment": null, "summary": "Post-training of foundation language models has emerged as a promising\nresearch domain in federated learning (FL) with the goal to enable\nprivacy-preserving model improvements and adaptations to user's downstream\ntasks. Recent advances in this area adopt centralized post-training approaches\nthat build upon black-box foundation language models where there is no access\nto model weights and architecture details. Although the use of black-box models\nhas been successful in centralized post-training, their blind replication in FL\nraises several concerns. Our position is that using black-box models in FL\ncontradicts the core principles of federation such as data privacy and\nautonomy. In this position paper, we critically analyze the usage of black-box\nmodels in federated post-training, and provide a detailed account of various\naspects of openness and their implications for FL.", "AI": {"tldr": "The paper critiques the use of black-box models in federated post-training, arguing it contradicts FL principles like privacy and autonomy.", "motivation": "To address concerns about using black-box models in federated learning (FL) for post-training, which may undermine core FL principles.", "method": "Critical analysis of black-box model usage in FL, focusing on openness and its implications.", "result": "Highlights contradictions between black-box models and FL principles, emphasizing the need for openness.", "conclusion": "Advocates for re-evaluating the use of black-box models in FL to align with its foundational principles."}}
{"id": "2505.23500", "pdf": "https://arxiv.org/pdf/2505.23500", "abs": "https://arxiv.org/abs/2505.23500", "authors": ["Eva Mart\u00edn del Pico", "Josep Llu\u00eds Gelp\u00ed", "Salvador Capella-Guti\u00e9rrez"], "title": "Identity resolution of software metadata using Large Language Models", "categories": ["cs.SE", "cs.CL", "cs.DL"], "comment": null, "summary": "Software is an essential component of research. However, little attention has\nbeen paid to it compared with that paid to research data. Recently, there has\nbeen an increase in efforts to acknowledge and highlight the importance of\nsoftware in research activities.\n  Structured metadata from platforms like bio.tools, Bioconductor, and Galaxy\nToolShed offers valuable insights into research software in the Life Sciences.\nAlthough originally intended to support discovery and integration, this\nmetadata can be repurposed for large-scale analysis of software practices.\nHowever, its quality and completeness vary across platforms, reflecting diverse\ndocumentation practices.\n  To gain a comprehensive view of software development and sustainability,\nconsolidating this metadata is necessary, but requires robust mechanisms to\naddress its heterogeneity and scale.\n  This article presents an evaluation of instruction-tuned large language\nmodels for the task of software metadata identity resolution, a critical step\nin assembling a cohesive collection of research software. Such a collection is\nthe reference component for the Software Observatory at OpenEBench, a platform\nthat aggregates metadata to monitor the FAIRness of research software in the\nLife Sciences.\n  We benchmarked multiple models against a human-annotated gold standard,\nexamined their behavior on ambiguous cases, and introduced an agreement-based\nproxy for high-confidence automated decisions. The proxy achieved high\nprecision and statistical robustness, while also highlighting the limitations\nof current models and the broader challenges of automating semantic judgment in\nFAIR-aligned software metadata across registries and repositories.", "AI": {"tldr": "The paper evaluates instruction-tuned large language models for resolving software metadata identity, aiming to improve the FAIRness of research software in Life Sciences.", "motivation": "To address the lack of attention on research software compared to data, and the need for consolidated metadata to analyze software practices.", "method": "Benchmarking multiple models against a human-annotated gold standard, analyzing ambiguous cases, and introducing an agreement-based proxy for automated decisions.", "result": "The proxy achieved high precision and robustness, but highlighted limitations of current models in automating semantic judgment for FAIR-aligned metadata.", "conclusion": "Consolidating software metadata is crucial for sustainability, but requires addressing heterogeneity and model limitations."}}
{"id": "2505.23678", "pdf": "https://arxiv.org/pdf/2505.23678", "abs": "https://arxiv.org/abs/2505.23678", "authors": ["Gabriel Sarch", "Snigdha Saha", "Naitik Khandelwal", "Ayush Jain", "Michael J. Tarr", "Aviral Kumar", "Katerina Fragkiadaki"], "title": "Grounded Reinforcement Learning for Visual Reasoning", "categories": ["cs.CV"], "comment": "Project website: https://visually-grounded-rl.github.io/", "summary": "While reinforcement learning (RL) over chains of thought has significantly\nadvanced language models in tasks such as mathematics and coding, visual\nreasoning introduces added complexity by requiring models to direct visual\nattention, interpret perceptual inputs, and ground abstract reasoning in\nspatial evidence. We introduce ViGoRL (Visually Grounded Reinforcement\nLearning), a vision-language model trained with RL to explicitly anchor each\nreasoning step to specific visual coordinates. Inspired by human visual\ndecision-making, ViGoRL learns to produce spatially grounded reasoning traces,\nguiding visual attention to task-relevant regions at each step. When\nfine-grained exploration is required, our novel multi-turn RL framework enables\nthe model to dynamically zoom into predicted coordinates as reasoning unfolds.\nAcross a diverse set of visual reasoning benchmarks--including SAT-2 and BLINK\nfor spatial reasoning, V*bench for visual search, and ScreenSpot and\nVisualWebArena for web-based grounding--ViGoRL consistently outperforms both\nsupervised fine-tuning and conventional RL baselines that lack explicit\ngrounding mechanisms. Incorporating multi-turn RL with zoomed-in visual\nfeedback significantly improves ViGoRL's performance on localizing small GUI\nelements and visual search, achieving 86.4% on V*Bench. Additionally, we find\nthat grounding amplifies other visual behaviors such as region exploration,\ngrounded subgoal setting, and visual verification. Finally, human evaluations\nshow that the model's visual references are not only spatially accurate but\nalso helpful for understanding model reasoning steps. Our results show that\nvisually grounded RL is a strong paradigm for imbuing models with\ngeneral-purpose visual reasoning.", "AI": {"tldr": "ViGoRL, a visually grounded RL model, outperforms baselines in visual reasoning tasks by anchoring reasoning steps to visual coordinates and dynamically zooming in for fine-grained exploration.", "motivation": "Visual reasoning adds complexity to RL by requiring attention, perception, and spatial grounding. ViGoRL addresses this by mimicking human visual decision-making.", "method": "ViGoRL uses RL to produce spatially grounded reasoning traces and a multi-turn RL framework for dynamic zooming into visual coordinates.", "result": "ViGoRL excels in benchmarks like SAT-2, BLINK, V*Bench, ScreenSpot, and VisualWebArena, achieving 86.4% on V*Bench. Grounding also enhances other visual behaviors.", "conclusion": "Visually grounded RL is effective for general-purpose visual reasoning, with human evaluations confirming the model's spatial accuracy and reasoning clarity."}}
{"id": "2505.23733", "pdf": "https://arxiv.org/pdf/2505.23733", "abs": "https://arxiv.org/abs/2505.23733", "authors": ["Truong", "Luu", "Binny M. Samuel"], "title": "Exposing the Impact of GenAI for Cybercrime: An Investigation into the Dark Side", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": null, "summary": "In recent years, the rapid advancement and democratization of generative AI\nmodels have sparked significant debate over safety, ethical risks, and dual-use\nconcerns, particularly in the context of cybersecurity. While anecdotally\nknown, this paper provides empirical evidence regarding generative AI's\nassociation with malicious internet-related activities and cybercrime by\nexamining the phenomenon through psychological frameworks of technological\namplification and affordance theory. Using a quasi-experimental design with\ninterrupted time series analysis, we analyze two datasets, one general and one\ncryptocurrency-focused, to empirically assess generative AI's role in\ncybercrime. The findings contribute to ongoing discussions about AI governance\nby balancing control and fostering innovation, underscoring the need for\nstrategies to guide policymakers, inform AI developers and cybersecurity\nprofessionals, and educate the public to maximize AI's benefits while\nmitigating its risks.", "AI": {"tldr": "The paper empirically examines generative AI's link to cybercrime, using psychological frameworks and quasi-experimental analysis, highlighting governance challenges.", "motivation": "To address debates on AI's ethical risks and dual-use concerns in cybersecurity by providing empirical evidence.", "method": "Quasi-experimental design with interrupted time series analysis on general and cryptocurrency-focused datasets.", "result": "Findings show generative AI's association with cybercrime, contributing to AI governance discussions.", "conclusion": "Strategies are needed for policymakers, developers, and the public to balance AI's benefits and risks."}}
{"id": "2505.23598", "pdf": "https://arxiv.org/pdf/2505.23598", "abs": "https://arxiv.org/abs/2505.23598", "authors": ["Radzim Sendyka", "Christian Cabrera", "Andrei Paleyes", "Diana Robinson", "Neil Lawrence"], "title": "LLM Performance for Code Generation on Noisy Tasks", "categories": ["cs.LG", "cs.SE"], "comment": null, "summary": "This paper investigates the ability of large language models (LLMs) to\nrecognise and solve tasks which have been obfuscated beyond recognition.\nFocusing on competitive programming and benchmark tasks (LeetCode and MATH), we\ncompare performance across multiple models and obfuscation methods, such as\nnoise and redaction. We demonstrate that all evaluated LLMs can solve tasks\nobfuscated to a level where the text would be unintelligible to human readers,\nand does not contain key pieces of instruction or context. We introduce the\nconcept of eager pattern matching to describe this behaviour, which is not\nobserved in tasks published after the models' knowledge cutoff date, indicating\nstrong memorisation or overfitting to training data, rather than legitimate\nreasoning about the presented problem. We report empirical evidence of distinct\nperformance decay patterns between contaminated and unseen datasets. We discuss\nthe implications for benchmarking and evaluations of model behaviour, arguing\nfor caution when designing experiments using standard datasets. We also propose\nmeasuring the decay of performance under obfuscation as a possible strategy for\ndetecting dataset contamination and highlighting potential safety risks and\ninterpretability issues for automated software systems.", "AI": {"tldr": "LLMs can solve heavily obfuscated tasks, showing memorization rather than reasoning, with performance decay patterns revealing dataset contamination.", "motivation": "To assess LLMs' ability to solve unrecognizable tasks and explore implications for benchmarking and safety.", "method": "Evaluated LLMs on obfuscated competitive programming tasks (LeetCode, MATH) using noise and redaction.", "result": "LLMs solved tasks obfuscated beyond human recognition, indicating memorization, with performance decay patterns distinguishing contaminated datasets.", "conclusion": "Caution is needed in benchmarking; obfuscation performance decay can detect dataset contamination and highlight safety risks."}}
{"id": "2505.23694", "pdf": "https://arxiv.org/pdf/2505.23694", "abs": "https://arxiv.org/abs/2505.23694", "authors": ["Li Ren", "Chen Chen", "Liqiang Wang", "Kien Hua"], "title": "DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers", "categories": ["cs.CV"], "comment": "CVPR 2025", "summary": "Visual Prompt Tuning (VPT) has become a promising solution for\nParameter-Efficient Fine-Tuning (PEFT) approach for Vision Transformer (ViT)\nmodels by partially fine-tuning learnable tokens while keeping most model\nparameters frozen. Recent research has explored modifying the connection\nstructures of the prompts. However, the fundamental correlation and\ndistribution between the prompts and image tokens remain unexplored. In this\npaper, we leverage metric learning techniques to investigate how the\ndistribution of prompts affects fine-tuning performance. Specifically, we\npropose a novel framework, Distribution Aware Visual Prompt Tuning (DA-VPT), to\nguide the distributions of the prompts by learning the distance metric from\ntheir class-related semantic data. Our method demonstrates that the prompts can\nserve as an effective bridge to share semantic information between image\npatches and the class token. We extensively evaluated our approach on popular\nbenchmarks in both recognition and segmentation tasks. The results demonstrate\nthat our approach enables more effective and efficient fine-tuning of ViT\nmodels by leveraging semantic information to guide the learning of the prompts,\nleading to improved performance on various downstream vision tasks.", "AI": {"tldr": "DA-VPT improves ViT fine-tuning by using metric learning to guide prompt distributions with semantic data, enhancing performance in vision tasks.", "motivation": "The unexplored correlation between prompts and image tokens in VPT for ViT models motivated the study of how prompt distribution affects fine-tuning.", "method": "Proposed DA-VPT, a framework using metric learning to align prompt distributions with class-related semantic data, bridging image patches and class tokens.", "result": "DA-VPT outperforms in recognition and segmentation tasks, showing efficient fine-tuning and improved performance.", "conclusion": "DA-VPT effectively leverages semantic information to enhance prompt learning, advancing ViT fine-tuning for downstream vision tasks."}}
{"id": "2505.23742", "pdf": "https://arxiv.org/pdf/2505.23742", "abs": "https://arxiv.org/abs/2505.23742", "authors": ["Yufan Deng", "Xun Guo", "Yuanyang Yin", "Jacob Zhiyuan Fang", "Yiding Yang", "Yizhi Wang", "Shenghai Yuan", "Angtian Wang", "Bo Liu", "Haibin Huang", "Chongyang Ma"], "title": "MAGREF: Masked Guidance for Any-Reference Video Generation", "categories": ["cs.CV", "cs.AI"], "comment": "Project website: https://magref-video.github.io/magref.github.io/", "summary": "Video generation has made substantial strides with the emergence of deep\ngenerative models, especially diffusion-based approaches. However, video\ngeneration based on multiple reference subjects still faces significant\nchallenges in maintaining multi-subject consistency and ensuring high\ngeneration quality. In this paper, we propose MAGREF, a unified framework for\nany-reference video generation that introduces masked guidance to enable\ncoherent multi-subject video synthesis conditioned on diverse reference images\nand a textual prompt. Specifically, we propose (1) a region-aware dynamic\nmasking mechanism that enables a single model to flexibly handle various\nsubject inference, including humans, objects, and backgrounds, without\narchitectural changes, and (2) a pixel-wise channel concatenation mechanism\nthat operates on the channel dimension to better preserve appearance features.\nOur model delivers state-of-the-art video generation quality, generalizing from\nsingle-subject training to complex multi-subject scenarios with coherent\nsynthesis and precise control over individual subjects, outperforming existing\nopen-source and commercial baselines. To facilitate evaluation, we also\nintroduce a comprehensive multi-subject video benchmark. Extensive experiments\ndemonstrate the effectiveness of our approach, paving the way for scalable,\ncontrollable, and high-fidelity multi-subject video synthesis. Code and model\ncan be found at: https://github.com/MAGREF-Video/MAGREF", "AI": {"tldr": "MAGREF introduces a unified framework for multi-subject video generation using masked guidance and dynamic masking to ensure consistency and quality.", "motivation": "Addressing challenges in maintaining multi-subject consistency and generation quality in video synthesis.", "method": "Proposes a region-aware dynamic masking mechanism and pixel-wise channel concatenation for flexible and coherent synthesis.", "result": "Achieves state-of-the-art video generation quality, outperforming existing baselines in multi-subject scenarios.", "conclusion": "MAGREF enables scalable, controllable, and high-fidelity multi-subject video synthesis, supported by a new benchmark."}}
{"id": "2505.23599", "pdf": "https://arxiv.org/pdf/2505.23599", "abs": "https://arxiv.org/abs/2505.23599", "authors": ["Eitan Levin", "Yuxin Ma", "Mateo D\u00edaz", "Soledad Villar"], "title": "On Transferring Transferability: Towards a Theory for Size Generalization", "categories": ["cs.LG", "math.RT", "math.ST", "stat.ML", "stat.TH"], "comment": "69 pages, 8 figures", "summary": "Many modern learning tasks require models that can take inputs of varying\nsizes. Consequently, dimension-independent architectures have been proposed for\ndomains where the inputs are graphs, sets, and point clouds. Recent work on\ngraph neural networks has explored whether a model trained on low-dimensional\ndata can transfer its performance to higher-dimensional inputs. We extend this\nbody of work by introducing a general framework for transferability across\ndimensions. We show that transferability corresponds precisely to continuity in\na limit space formed by identifying small problem instances with equivalent\nlarge ones. This identification is driven by the data and the learning task. We\ninstantiate our framework on existing architectures, and implement the\nnecessary changes to ensure their transferability. Finally, we provide design\nprinciples for designing new transferable models. Numerical experiments support\nour findings.", "AI": {"tldr": "The paper introduces a framework for transferability of models across varying input dimensions, linking it to continuity in a limit space, and provides design principles for transferable models.", "motivation": "To address the need for models that can handle inputs of varying sizes, particularly in domains like graphs, sets, and point clouds.", "method": "Proposes a general framework for transferability, linking it to continuity in a limit space, and adapts existing architectures to ensure transferability.", "result": "Demonstrates that transferability corresponds to continuity in the limit space, supported by numerical experiments.", "conclusion": "Provides design principles for creating transferable models and validates the framework with experiments."}}
{"id": "2505.23761", "pdf": "https://arxiv.org/pdf/2505.23761", "abs": "https://arxiv.org/abs/2505.23761", "authors": ["Yunjae Won", "Hyunji Lee", "Hyeonbin Hwang", "Minjoon Seo"], "title": "Differential Information: An Information-Theoretic Perspective on Preference Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "41 pages, 13 figures; due to the 1,920-character limitation imposed\n  on the abstract field by arXiv, the abstract included on the arXiv page is\n  slightly abbreviated compared to the version presented in the PDF", "summary": "Direct Preference Optimization (DPO) has become a standard technique for\naligning language models with human preferences in a supervised manner. Despite\nits empirical success, the theoretical justification behind its log-ratio\nreward parameterization remains incomplete. In this work, we address this gap\nby utilizing the Differential Information Distribution (DID): a distribution\nover token sequences that captures the information gained during policy\nupdates. First, we show that when preference labels encode the differential\ninformation required to transform a reference policy into a target policy, the\nlog-ratio reward in DPO emerges as the uniquely optimal form for learning the\ntarget policy via preference optimization. This result naturally yields a\nclosed-form expression for the optimal sampling distribution over rejected\nresponses. Second, we find that the condition for preferences to encode\ndifferential information is fundamentally linked to an implicit assumption\nregarding log-margin ordered policies-an inductive bias widely used in\npreference optimization yet previously unrecognized. Finally, by analyzing the\nentropy of the DID, we characterize how learning low-entropy differential\ninformation reinforces the policy distribution, while high-entropy differential\ninformation induces a smoothing effect, which explains the log-likelihood\ndisplacement phenomenon. We validate our theoretical findings in synthetic\nexperiments and extend them to real-world instruction-following datasets. Our\nresults suggest that learning high-entropy differential information is crucial\nfor general instruction-following, while learning low-entropy differential\ninformation benefits knowledge-intensive question answering. Overall, our work\npresents a unifying perspective on the DPO objective, the structure of\npreference data, and resulting policy behaviors through the lens of\ndifferential information.", "AI": {"tldr": "The paper provides a theoretical justification for Direct Preference Optimization (DPO) by linking its log-ratio reward parameterization to differential information, revealing its optimality and implications for policy learning.", "motivation": "To address the incomplete theoretical understanding of DPO's log-ratio reward parameterization and its empirical success in aligning language models with human preferences.", "method": "Uses Differential Information Distribution (DID) to analyze how preference labels encode information for policy updates, deriving the optimal form of the log-ratio reward and sampling distribution.", "result": "Shows that DPO's log-ratio reward is uniquely optimal under certain conditions, explains policy behaviors via DID entropy, and validates findings in synthetic and real-world datasets.", "conclusion": "The study unifies DPO's objective, preference data structure, and policy behaviors through differential information, highlighting the importance of entropy in learning tasks."}}
{"id": "2505.23716", "pdf": "https://arxiv.org/pdf/2505.23716", "abs": "https://arxiv.org/abs/2505.23716", "authors": ["Lihan Jiang", "Yucheng Mao", "Linning Xu", "Tao Lu", "Kerui Ren", "Yichen Jin", "Xudong Xu", "Mulin Yu", "Jiangmiao Pang", "Feng Zhao", "Dahua Lin", "Bo Dai"], "title": "AnySplat: Feed-forward 3D Gaussian Splatting from Unconstrained Views", "categories": ["cs.CV"], "comment": "Project page: https://city-super.github.io/anysplat/", "summary": "We introduce AnySplat, a feed forward network for novel view synthesis from\nuncalibrated image collections. In contrast to traditional neural rendering\npipelines that demand known camera poses and per scene optimization, or recent\nfeed forward methods that buckle under the computational weight of dense views,\nour model predicts everything in one shot. A single forward pass yields a set\nof 3D Gaussian primitives encoding both scene geometry and appearance, and the\ncorresponding camera intrinsics and extrinsics for each input image. This\nunified design scales effortlessly to casually captured, multi view datasets\nwithout any pose annotations. In extensive zero shot evaluations, AnySplat\nmatches the quality of pose aware baselines in both sparse and dense view\nscenarios while surpassing existing pose free approaches. Moreover, it greatly\nreduce rendering latency compared to optimization based neural fields, bringing\nreal time novel view synthesis within reach for unconstrained capture\nsettings.Project page: https://city-super.github.io/anysplat/", "AI": {"tldr": "AnySplat is a feed-forward network for novel view synthesis from uncalibrated images, predicting 3D Gaussian primitives and camera poses in one shot, outperforming pose-aware and pose-free methods while enabling real-time rendering.", "motivation": "Traditional neural rendering requires known camera poses and per-scene optimization, while existing feed-forward methods struggle with dense views. AnySplat aims to simplify and scale novel view synthesis for casually captured datasets without pose annotations.", "method": "AnySplat uses a single forward pass to predict 3D Gaussian primitives (encoding geometry and appearance) and camera intrinsics/extrinsics for each input image, eliminating the need for pose annotations.", "result": "In zero-shot evaluations, AnySplat matches pose-aware baselines in quality for sparse and dense views and surpasses pose-free methods. It also reduces rendering latency significantly, enabling real-time synthesis.", "conclusion": "AnySplat offers a scalable, efficient solution for novel view synthesis from uncalibrated images, achieving high quality and real-time performance without pose annotations."}}
{"id": "2505.23744", "pdf": "https://arxiv.org/pdf/2505.23744", "abs": "https://arxiv.org/abs/2505.23744", "authors": ["Qiang Wang", "Xiang Song", "Yuhang He", "Jizhou Han", "Chenhao Ding", "Xinyuan Gao", "Yihong Gong"], "title": "Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at CVPR 2025", "summary": "Deep neural networks (DNNs) often underperform in real-world, dynamic\nsettings where data distributions change over time. Domain Incremental Learning\n(DIL) offers a solution by enabling continual model adaptation, with\nParameter-Isolation DIL (PIDIL) emerging as a promising paradigm to reduce\nknowledge conflicts. However, existing PIDIL methods struggle with parameter\nselection accuracy, especially as the number of domains and corresponding\nclasses grows. To address this, we propose SOYO, a lightweight framework that\nimproves domain selection in PIDIL. SOYO introduces a Gaussian Mixture\nCompressor (GMC) and Domain Feature Resampler (DFR) to store and balance prior\ndomain data efficiently, while a Multi-level Domain Feature Fusion Network\n(MDFN) enhances domain feature extraction. Our framework supports multiple\nParameter-Efficient Fine-Tuning (PEFT) methods and is validated across tasks\nsuch as image classification, object detection, and speech enhancement.\nExperimental results on six benchmarks demonstrate SOYO's consistent\nsuperiority over existing baselines, showcasing its robustness and adaptability\nin complex, evolving environments. The codes will be released in\nhttps://github.com/qwangcv/SOYO.", "AI": {"tldr": "SOYO is a lightweight framework improving domain selection in Parameter-Isolation DIL (PIDIL) using Gaussian Mixture Compressor (GMC), Domain Feature Resampler (DFR), and Multi-level Domain Feature Fusion Network (MDFN). It outperforms baselines in dynamic settings.", "motivation": "Deep neural networks (DNNs) underperform in dynamic environments with shifting data distributions. Existing PIDIL methods lack accuracy in parameter selection as domains and classes grow.", "method": "SOYO introduces GMC and DFR for efficient prior domain data storage and balancing, and MDFN for enhanced domain feature extraction. It supports multiple PEFT methods.", "result": "SOYO consistently outperforms baselines across six benchmarks in tasks like image classification, object detection, and speech enhancement.", "conclusion": "SOYO is robust and adaptable for complex, evolving environments, with code available on GitHub."}}
{"id": "2505.23606", "pdf": "https://arxiv.org/pdf/2505.23606", "abs": "https://arxiv.org/abs/2505.23606", "authors": ["Qingyu Shi", "Jinbin Bai", "Zhuoran Zhao", "Wenhao Chai", "Kaidong Yu", "Jianzong Wu", "Shuangyong Song", "Yunhai Tong", "Xiangtai Li", "Xuelong Li", "Shuicheng Yan"], "title": "Muddit: Liberating Generation Beyond Text-to-Image with a Unified Discrete Diffusion Model", "categories": ["cs.LG", "cs.CV"], "comment": "The code and model are available at\n  https://github.com/M-E-AGI-Lab/Muddit", "summary": "Unified generation models aim to handle diverse tasks across modalities --\nsuch as text generation, image generation, and vision-language reasoning --\nwithin a single architecture and decoding paradigm. Autoregressive unified\nmodels suffer from slow inference due to sequential decoding, and\nnon-autoregressive unified models suffer from weak generalization due to\nlimited pretrained backbones. We introduce Muddit, a unified discrete diffusion\ntransformer that enables fast and parallel generation across both text and\nimage modalities. Unlike prior unified diffusion models trained from scratch,\nMuddit integrates strong visual priors from a pretrained text-to-image backbone\nwith a lightweight text decoder, enabling flexible and high-quality multimodal\ngeneration under a unified architecture. Empirical results show that Muddit\nachieves competitive or superior performance compared to significantly larger\nautoregressive models in both quality and efficiency. The work highlights the\npotential of purely discrete diffusion, when equipped with strong visual\npriors, as a scalable and effective backbone for unified generation.", "AI": {"tldr": "Muddit is a unified discrete diffusion transformer for fast, parallel multimodal generation, outperforming autoregressive models in efficiency and quality.", "motivation": "Address slow inference in autoregressive unified models and weak generalization in non-autoregressive ones by leveraging pretrained backbones.", "method": "Integrates pretrained text-to-image backbone with a lightweight text decoder for flexible, high-quality multimodal generation.", "result": "Achieves competitive/superior performance to larger autoregressive models in quality and efficiency.", "conclusion": "Discrete diffusion with strong visual priors is a scalable, effective backbone for unified generation."}}
{"id": "2505.23764", "pdf": "https://arxiv.org/pdf/2505.23764", "abs": "https://arxiv.org/abs/2505.23764", "authors": ["Sihan Yang", "Runsen Xu", "Yiman Xie", "Sizhe Yang", "Mo Li", "Jingli Lin", "Chenming Zhu", "Xiaochen Chen", "Haodong Duan", "Xiangyu Yue", "Dahua Lin", "Tai Wang", "Jiangmiao Pang"], "title": "MMSI-Bench: A Benchmark for Multi-Image Spatial Intelligence", "categories": ["cs.CV", "cs.CL"], "comment": "34 pages. A comprehensive, fully human-curated, multi-image-based\n  spatial intelligence benchmark with reasoning annotation for MLLMs. Project\n  page: https://runsenxu.com/projects/MMSI_Bench", "summary": "Spatial intelligence is essential for multimodal large language models\n(MLLMs) operating in the complex physical world. Existing benchmarks, however,\nprobe only single-image relations and thus fail to assess the multi-image\nspatial reasoning that real-world deployments demand. We introduce MMSI-Bench,\na VQA benchmark dedicated to multi-image spatial intelligence. Six 3D-vision\nresearchers spent more than 300 hours meticulously crafting 1,000 challenging,\nunambiguous multiple-choice questions from over 120,000 images, each paired\nwith carefully designed distractors and a step-by-step reasoning process. We\nconduct extensive experiments and thoroughly evaluate 34 open-source and\nproprietary MLLMs, observing a wide gap: the strongest open-source model\nattains roughly 30% accuracy and OpenAI's o3 reasoning model reaches 40%, while\nhumans score 97%. These results underscore the challenging nature of MMSI-Bench\nand the substantial headroom for future research. Leveraging the annotated\nreasoning processes, we also provide an automated error analysis pipeline that\ndiagnoses four dominant failure modes, including (1) grounding errors, (2)\noverlap-matching and scene-reconstruction errors, (3) situation-transformation\nreasoning errors, and (4) spatial-logic errors, offering valuable insights for\nadvancing multi-image spatial intelligence. Project page:\nhttps://runsenxu.com/projects/MMSI_Bench .", "AI": {"tldr": "MMSI-Bench is a new benchmark for multi-image spatial intelligence in MLLMs, highlighting a significant performance gap between models and humans.", "motivation": "Existing benchmarks focus on single-image relations, failing to assess multi-image spatial reasoning needed for real-world MLLM applications.", "method": "A team crafted 1,000 challenging questions from 120,000+ images, evaluating 34 MLLMs and analyzing failure modes.", "result": "Top models (open-source and proprietary) scored 30-40% accuracy, while humans achieved 97%, showing a large gap.", "conclusion": "MMSI-Bench reveals critical challenges in multi-image spatial reasoning, providing insights for future research."}}
{"id": "2505.23726", "pdf": "https://arxiv.org/pdf/2505.23726", "abs": "https://arxiv.org/abs/2505.23726", "authors": ["Darryl Hannan", "Timothy Doster", "Henry Kvinge", "Adam Attarian", "Yijing Watkins"], "title": "FMG-Det: Foundation Model Guided Robust Object Detection", "categories": ["cs.CV"], "comment": "10 pages, ICIP 2025", "summary": "Collecting high quality data for object detection tasks is challenging due to\nthe inherent subjectivity in labeling the boundaries of an object. This makes\nit difficult to not only collect consistent annotations across a dataset but\nalso to validate them, as no two annotators are likely to label the same object\nusing the exact same coordinates. These challenges are further compounded when\nobject boundaries are partially visible or blurred, which can be the case in\nmany domains. Training on noisy annotations significantly degrades detector\nperformance, rendering them unusable, particularly in few-shot settings, where\njust a few corrupted annotations can impact model performance. In this work, we\npropose FMG-Det, a simple, efficient methodology for training models with noisy\nannotations. More specifically, we propose combining a multiple instance\nlearning (MIL) framework with a pre-processing pipeline that leverages powerful\nfoundation models to correct labels prior to training. This pre-processing\npipeline, along with slight modifications to the detector head, results in\nstate-of-the-art performance across a number of datasets, for both standard and\nfew-shot scenarios, while being much simpler and more efficient than other\napproaches.", "AI": {"tldr": "FMG-Det improves object detection by correcting noisy annotations using a MIL framework and foundation models, achieving state-of-the-art results efficiently.", "motivation": "Challenges in collecting consistent object detection annotations due to subjectivity and noise, especially in few-shot settings, degrade model performance.", "method": "Combines multiple instance learning (MIL) with a pre-processing pipeline using foundation models to correct labels before training, with minor detector head modifications.", "result": "Achieves state-of-the-art performance on multiple datasets, including few-shot scenarios, with simplicity and efficiency.", "conclusion": "FMG-Det effectively addresses noisy annotation issues, enhancing detector performance in both standard and few-shot settings."}}
{"id": "2505.23745", "pdf": "https://arxiv.org/pdf/2505.23745", "abs": "https://arxiv.org/abs/2505.23745", "authors": ["Hao Dong", "Moru Liu", "Jian Liang", "Eleni Chatzi", "Olga Fink"], "title": "To Trust Or Not To Trust Your Vision-Language Model's Prediction", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Vision-Language Models (VLMs) have demonstrated strong capabilities in\naligning visual and textual modalities, enabling a wide range of applications\nin multimodal understanding and generation. While they excel in zero-shot and\ntransfer learning scenarios, VLMs remain susceptible to misclassification,\noften yielding confident yet incorrect predictions. This limitation poses a\nsignificant risk in safety-critical domains, where erroneous predictions can\nlead to severe consequences. In this work, we introduce TrustVLM, a\ntraining-free framework designed to address the critical challenge of\nestimating when VLM's predictions can be trusted. Motivated by the observed\nmodality gap in VLMs and the insight that certain concepts are more distinctly\nrepresented in the image embedding space, we propose a novel confidence-scoring\nfunction that leverages this space to improve misclassification detection. We\nrigorously evaluate our approach across 17 diverse datasets, employing 4\narchitectures and 2 VLMs, and demonstrate state-of-the-art performance, with\nimprovements of up to 51.87% in AURC, 9.14% in AUROC, and 32.42% in FPR95\ncompared to existing baselines. By improving the reliability of the model\nwithout requiring retraining, TrustVLM paves the way for safer deployment of\nVLMs in real-world applications. The code will be available at\nhttps://github.com/EPFL-IMOS/TrustVLM.", "AI": {"tldr": "TrustVLM is a training-free framework to improve misclassification detection in Vision-Language Models (VLMs) by leveraging image embedding space, achieving state-of-the-art performance.", "motivation": "VLMs often produce confident but incorrect predictions, posing risks in safety-critical domains. TrustVLM aims to address this by estimating when predictions can be trusted.", "method": "Proposes a confidence-scoring function using the modality gap and distinct concept representation in image embedding space. Evaluated on 17 datasets with 4 architectures and 2 VLMs.", "result": "Improves AURC by 51.87%, AUROC by 9.14%, and FPR95 by 32.42% over baselines.", "conclusion": "TrustVLM enhances VLM reliability without retraining, enabling safer real-world deployment."}}
{"id": "2505.23607", "pdf": "https://arxiv.org/pdf/2505.23607", "abs": "https://arxiv.org/abs/2505.23607", "authors": ["Carolina Fortuna", "Gregor Cerar", "Blaz Bertalanic", "Andrej Campa", "Mihael Mohorcic"], "title": "Data Model Design for Explainable Machine Learning-based Electricity Applications", "categories": ["cs.LG"], "comment": null, "summary": "The transition from traditional power grids to smart grids, significant\nincrease in the use of renewable energy sources, and soaring electricity prices\nhas triggered a digital transformation of the energy infrastructure that\nenables new, data driven, applications often supported by machine learning\nmodels. However, the majority of the developed machine learning models rely on\nunivariate data. To date, a structured study considering the role meta-data and\nadditional measurements resulting in multivariate data is missing. In this\npaper we propose a taxonomy that identifies and structures various types of\ndata related to energy applications. The taxonomy can be used to guide\napplication specific data model development for training machine learning\nmodels. Focusing on a household electricity forecasting application, we\nvalidate the effectiveness of the proposed taxonomy in guiding the selection of\nthe features for various types of models. As such, we study of the effect of\ndomain, contextual and behavioral features on the forecasting accuracy of four\ninterpretable machine learning techniques and three openly available datasets.\nFinally, using a feature importance techniques, we explain individual feature\ncontributions to the forecasting accuracy.", "AI": {"tldr": "The paper proposes a taxonomy for structuring data in energy applications to improve machine learning models, validated through household electricity forecasting.", "motivation": "The shift to smart grids and renewable energy necessitates better data-driven models, but current models often ignore multivariate data.", "method": "A taxonomy is developed to guide data model development, tested with household electricity forecasting using interpretable ML techniques and feature importance analysis.", "result": "The taxonomy effectively guides feature selection, improving forecasting accuracy across datasets.", "conclusion": "The study highlights the importance of structured data and feature contributions in enhancing energy forecasting models."}}
{"id": "2405.17057", "pdf": "https://arxiv.org/pdf/2405.17057", "abs": "https://arxiv.org/abs/2405.17057", "authors": ["Houxing Ren", "Mingjie Zhan", "Zhongyuan Wu", "Aojun Zhou", "Junting Pan", "Hongsheng Li"], "title": "ReflectionCoder: Learning from Reflection Sequence for Enhanced One-off Code Generation", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ACL 2025 (main conference)", "summary": "Code generation plays a crucial role in various tasks, such as code\nauto-completion and mathematical reasoning. Previous work has proposed numerous\nmethods to enhance code generation performance, including integrating feedback\nfrom the compiler. Inspired by this, we present ReflectionCoder, a novel\napproach that effectively leverages reflection sequences constructed by\nintegrating compiler feedback to improve one-off code generation performance.\nFurthermore, we propose reflection self-distillation and dynamically masked\ndistillation to effectively utilize these reflection sequences. Extensive\nexperiments on three benchmarks, i.e., HumanEval (+), MBPP (+), and MultiPL-E,\ndemonstrate that models fine-tuned with our method achieve state-of-the-art\nperformance. Beyond the code domain, we believe this approach can benefit other\ndomains that focus on final results and require long reasoning paths. Code and\ndata are available at https://github.com/SenseLLM/ReflectionCoder.", "AI": {"tldr": "ReflectionCoder improves code generation by using reflection sequences from compiler feedback, achieving state-of-the-art results on benchmarks.", "motivation": "Enhancing one-off code generation performance by leveraging compiler feedback.", "method": "Uses reflection sequences, reflection self-distillation, and dynamically masked distillation.", "result": "Achieves state-of-the-art performance on HumanEval (+), MBPP (+), and MultiPL-E benchmarks.", "conclusion": "The approach can benefit domains requiring long reasoning paths and focus on final results."}}
{"id": "2505.23734", "pdf": "https://arxiv.org/pdf/2505.23734", "abs": "https://arxiv.org/abs/2505.23734", "authors": ["Weijie Wang", "Donny Y. Chen", "Zeyu Zhang", "Duochao Shi", "Akide Liu", "Bohan Zhuang"], "title": "ZPressor: Bottleneck-Aware Compression for Scalable Feed-Forward 3DGS", "categories": ["cs.CV"], "comment": "Project Page: https://lhmd.top/zpressor, Code:\n  https://github.com/ziplab/ZPressor", "summary": "Feed-forward 3D Gaussian Splatting (3DGS) models have recently emerged as a\npromising solution for novel view synthesis, enabling one-pass inference\nwithout the need for per-scene 3DGS optimization. However, their scalability is\nfundamentally constrained by the limited capacity of their encoders, leading to\ndegraded performance or excessive memory consumption as the number of input\nviews increases. In this work, we analyze feed-forward 3DGS frameworks through\nthe lens of the Information Bottleneck principle and introduce ZPressor, a\nlightweight architecture-agnostic module that enables efficient compression of\nmulti-view inputs into a compact latent state $Z$ that retains essential scene\ninformation while discarding redundancy. Concretely, ZPressor enables existing\nfeed-forward 3DGS models to scale to over 100 input views at 480P resolution on\nan 80GB GPU, by partitioning the views into anchor and support sets and using\ncross attention to compress the information from the support views into anchor\nviews, forming the compressed latent state $Z$. We show that integrating\nZPressor into several state-of-the-art feed-forward 3DGS models consistently\nimproves performance under moderate input views and enhances robustness under\ndense view settings on two large-scale benchmarks DL3DV-10K and RealEstate10K.\nThe video results, code and trained models are available on our project page:\nhttps://lhmd.top/zpressor.", "AI": {"tldr": "ZPressor improves feed-forward 3DGS models by compressing multi-view inputs into a compact latent state, enabling scalability to over 100 views on an 80GB GPU.", "motivation": "Feed-forward 3DGS models face scalability issues due to encoder limitations, degrading performance with more input views.", "method": "ZPressor partitions views into anchor and support sets, using cross attention to compress information into a latent state $Z$.", "result": "ZPressor enhances performance under moderate views and robustness in dense settings on DL3DV-10K and RealEstate10K benchmarks.", "conclusion": "ZPressor is a lightweight, architecture-agnostic solution for scalable feed-forward 3DGS models."}}
{"id": "2505.23747", "pdf": "https://arxiv.org/pdf/2505.23747", "abs": "https://arxiv.org/abs/2505.23747", "authors": ["Diankun Wu", "Fangfu Liu", "Yi-Hsin Hung", "Yueqi Duan"], "title": "Spatial-MLLM: Boosting MLLM Capabilities in Visual-based Spatial Intelligence", "categories": ["cs.CV", "cs.AI", "cs.LG", "I.2.6; I.2"], "comment": "21 pages", "summary": "Recent advancements in Multimodal Large Language Models (MLLMs) have\nsignificantly enhanced performance on 2D visual tasks. However, improving their\nspatial intelligence remains a challenge. Existing 3D MLLMs always rely on\nadditional 3D or 2.5D data to incorporate spatial awareness, restricting their\nutility in scenarios with only 2D inputs, such as images or videos. In this\npaper, we present Spatial-MLLM, a novel framework for visual-based spatial\nreasoning from purely 2D observations. Unlike conventional video MLLMs which\nrely on CLIP-based visual encoders optimized for semantic understanding, our\nkey insight is to unleash the strong structure prior from the feed-forward\nvisual geometry foundation model. Specifically, we propose a dual-encoder\narchitecture: a pretrained 2D visual encoder to extract semantic features, and\na spatial encoder-initialized from the backbone of the visual geometry model-to\nextract 3D structure features. A connector then integrates both features into\nunified visual tokens for enhanced spatial understanding. Furthermore, we\npropose a space-aware frame sampling strategy at inference time, which selects\nthe spatially informative frames of a video sequence, ensuring that even under\nlimited token length, the model focuses on frames critical for spatial\nreasoning. Beyond architecture improvements, we construct the Spatial-MLLM-120k\ndataset and train the model on it using supervised fine-tuning and GRPO.\nExtensive experiments on various real-world datasets demonstrate that our\nspatial-MLLM achieves state-of-the-art performance in a wide range of\nvisual-based spatial understanding and reasoning tasks. Project page:\nhttps://diankun-wu.github.io/Spatial-MLLM/.", "AI": {"tldr": "Spatial-MLLM enhances spatial reasoning in MLLMs using 2D inputs by leveraging a dual-encoder architecture and space-aware frame sampling.", "motivation": "Existing 3D MLLMs rely on additional 3D/2.5D data, limiting their use with 2D inputs like images or videos. Spatial-MLLM addresses this gap.", "method": "Proposes a dual-encoder (semantic + spatial) and a space-aware frame sampling strategy. Uses the Spatial-MLLM-120k dataset and GRPO training.", "result": "Achieves state-of-the-art performance in visual-based spatial understanding tasks.", "conclusion": "Spatial-MLLM effectively improves spatial reasoning from 2D inputs, outperforming existing methods."}}
{"id": "2505.23609", "pdf": "https://arxiv.org/pdf/2505.23609", "abs": "https://arxiv.org/abs/2505.23609", "authors": ["Armando Bellante", "Martin Pl\u00e1vala", "Alessandro Luongo"], "title": "The Generalized Skew Spectrum of Graphs", "categories": ["cs.LG", "cs.DS", "math.GR", "math.RT"], "comment": null, "summary": "This paper proposes a family of permutation-invariant graph embeddings,\ngeneralizing the Skew Spectrum of graphs of Kondor & Borgwardt (2008). Grounded\nin group theory and harmonic analysis, our method introduces a new class of\ngraph invariants that are isomorphism-invariant and capable of embedding richer\ngraph structures - including attributed graphs, multilayer graphs, and\nhypergraphs - which the Skew Spectrum could not handle. Our generalization\nfurther defines a family of functions that enables a trade-off between\ncomputational complexity and expressivity. By applying\ngeneralization-preserving heuristics to this family, we improve the Skew\nSpectrum's expressivity at the same computational cost. We formally prove the\ninvariance of our generalization, demonstrate its improved expressiveness\nthrough experiments, and discuss its efficient computation.", "AI": {"tldr": "The paper introduces a family of permutation-invariant graph embeddings, generalizing the Skew Spectrum, to handle richer graph structures like attributed graphs and hypergraphs, with a trade-off between computational complexity and expressivity.", "motivation": "To address the limitations of the Skew Spectrum in handling complex graph structures and to provide a more expressive and computationally flexible framework.", "method": "The approach is grounded in group theory and harmonic analysis, introducing a new class of graph invariants and generalization-preserving heuristics.", "result": "The method improves expressivity at the same computational cost as the Skew Spectrum, proven invariant and demonstrated through experiments.", "conclusion": "The proposed generalization offers a versatile and efficient solution for embedding diverse graph structures while balancing computational demands."}}
{"id": "2406.08707", "pdf": "https://arxiv.org/pdf/2406.08707", "abs": "https://arxiv.org/abs/2406.08707", "authors": ["Matthieu Futeral", "Armel Zebaze", "Pedro Ortiz Suarez", "Julien Abadji", "R\u00e9mi Lacroix", "Cordelia Schmid", "Rachel Bawden", "Beno\u00eet Sagot"], "title": "mOSCAR: A Large-scale Multilingual and Multimodal Document-level Corpus", "categories": ["cs.CL", "cs.CV"], "comment": "ACL 2025 (Findings)", "summary": "Multimodal Large Language Models (mLLMs) are trained on a large amount of\ntext-image data. While most mLLMs are trained on caption-like data only,\nAlayrac et al. (2022) showed that additionally training them on interleaved\nsequences of text and images can lead to the emergence of in-context learning\ncapabilities. However, the dataset they used, M3W, is not public and is only in\nEnglish. There have been attempts to reproduce their results but the released\ndatasets are English-only. In contrast, current multilingual and multimodal\ndatasets are either composed of caption-like only or medium-scale or fully\nprivate data. This limits mLLM research for the 7,000 other languages spoken in\nthe world. We therefore introduce mOSCAR, to the best of our knowledge the\nfirst large-scale multilingual and multimodal document corpus crawled from the\nweb. It covers 163 languages, 303M documents, 200B tokens and 1.15B images. We\ncarefully conduct a set of filtering and evaluation steps to make sure mOSCAR\nis sufficiently safe, diverse and of good quality. We additionally train two\ntypes of multilingual model to prove the benefits of mOSCAR: (1) a model\ntrained on a subset of mOSCAR and captioning data and (2) a model trained on\ncaptioning data only. The model additionally trained on mOSCAR shows a strong\nboost in few-shot learning performance across various multilingual image-text\ntasks and benchmarks, confirming previous findings for English-only mLLMs. The\ndataset is released under the Creative Commons CC BY 4.0 license and can be\naccessed here: https://huggingface.co/datasets/oscar-corpus/mOSCAR", "AI": {"tldr": "mOSCAR is the first large-scale multilingual and multimodal dataset, addressing limitations of existing datasets by covering 163 languages and proving its utility in boosting few-shot learning for mLLMs.", "motivation": "Existing datasets for mLLMs are limited to English or lack diversity, hindering research for other languages. mOSCAR aims to fill this gap.", "method": "mOSCAR was created by crawling the web, covering 163 languages, and underwent rigorous filtering. Two multilingual models were trained to evaluate its benefits.", "result": "The model trained on mOSCAR showed significant improvement in few-shot learning across multilingual tasks, validating its effectiveness.", "conclusion": "mOSCAR enables broader mLLM research by providing a high-quality, diverse, and multilingual dataset, with proven benefits for model performance."}}
{"id": "2505.23738", "pdf": "https://arxiv.org/pdf/2505.23738", "abs": "https://arxiv.org/abs/2505.23738", "authors": ["Xiaojuan Wang", "Aleksander Holynski", "Brian Curless", "Ira Kemelmacher", "Steve Seitz"], "title": "How Animals Dance (When You're Not Looking)", "categories": ["cs.CV", "cs.GR"], "comment": "Project page: https://how-animals-dance.github.io/", "summary": "We present a keyframe-based framework for generating music-synchronized,\nchoreography aware animal dance videos. Starting from a few keyframes\nrepresenting distinct animal poses -- generated via text-to-image prompting or\nGPT-4o -- we formulate dance synthesis as a graph optimization problem: find\nthe optimal keyframe structure that satisfies a specified choreography pattern\nof beats, which can be automatically estimated from a reference dance video. We\nalso introduce an approach for mirrored pose image generation, essential for\ncapturing symmetry in dance. In-between frames are synthesized using an video\ndiffusion model. With as few as six input keyframes, our method can produce up\nto 30 second dance videos across a wide range of animals and music tracks.", "AI": {"tldr": "A framework for creating music-synchronized animal dance videos using keyframes, graph optimization, and video diffusion.", "motivation": "To automate the generation of choreographed animal dance videos synchronized with music, reducing manual effort.", "method": "Uses keyframes (from text-to-image or GPT-4o), formulates dance synthesis as a graph optimization problem, and employs video diffusion for in-between frames.", "result": "Produces 30-second dance videos from just six keyframes, adaptable to various animals and music tracks.", "conclusion": "The method efficiently generates high-quality, synchronized dance videos with minimal input, demonstrating versatility and scalability."}}
{"id": "2505.23751", "pdf": "https://arxiv.org/pdf/2505.23751", "abs": "https://arxiv.org/abs/2505.23751", "authors": ["Declan Kutscher", "David M. Chan", "Yutong Bai", "Trevor Darrell", "Ritwik Gupta"], "title": "REOrdering Patches Improves Vision Models", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Sequence models such as transformers require inputs to be represented as\none-dimensional sequences. In vision, this typically involves flattening images\nusing a fixed row-major (raster-scan) order. While full self-attention is\npermutation-equivariant, modern long-sequence transformers increasingly rely on\narchitectural approximations that break this invariance and introduce\nsensitivity to patch ordering. We show that patch order significantly affects\nmodel performance in such settings, with simple alternatives like column-major\nor Hilbert curves yielding notable accuracy shifts. Motivated by this, we\npropose REOrder, a two-stage framework for discovering task-optimal patch\norderings. First, we derive an information-theoretic prior by evaluating the\ncompressibility of various patch sequences. Then, we learn a policy over\npermutations by optimizing a Plackett-Luce policy using REINFORCE. This\napproach enables efficient learning in a combinatorial permutation space.\nREOrder improves top-1 accuracy over row-major ordering on ImageNet-1K by up to\n3.01% and Functional Map of the World by 13.35%.", "AI": {"tldr": "REOrder, a two-stage framework, improves transformer performance by optimizing patch orderings, achieving notable accuracy gains on ImageNet-1K and Functional Map of the World.", "motivation": "Patch order significantly affects transformer performance, but existing methods rely on fixed orderings (e.g., row-major). REOrder aims to discover task-optimal patch orderings.", "method": "1. Derive an information-theoretic prior by evaluating patch sequence compressibility. 2. Learn a policy over permutations using REINFORCE with a Plackett-Luce policy.", "result": "REOrder improves top-1 accuracy by up to 3.01% on ImageNet-1K and 13.35% on Functional Map of the World.", "conclusion": "Optimizing patch orderings with REOrder enhances transformer performance, demonstrating the importance of task-specific ordering in vision tasks."}}
{"id": "2505.23614", "pdf": "https://arxiv.org/pdf/2505.23614", "abs": "https://arxiv.org/abs/2505.23614", "authors": ["Xiangcheng Zhang", "Haowei Lin", "Haotian Ye", "James Zou", "Jianzhu Ma", "Yitao Liang", "Yilun Du"], "title": "Inference-time Scaling of Diffusion Models through Classical Search", "categories": ["cs.LG", "stat.ML"], "comment": "Website at https://diffusion-inference-scaling.github.io/", "summary": "Classical search algorithms have long underpinned modern artificial\nintelligence. In this work, we tackle the challenge of inference-time control\nin diffusion models -- adapting generated outputs to meet diverse test-time\nobjectives -- using principles from classical search. We propose a general\nframework that orchestrates local and global search to efficiently navigate the\ngenerative space. It employs a theoretically grounded local search via annealed\nLangevin MCMC and performs compute-efficient global exploration using\nbreadth-first and depth-first tree search. We evaluate our approach on a range\nof challenging domains, including planning, offline reinforcement learning, and\nimage generation. Across all tasks, we observe significant gains in both\nperformance and efficiency. These results show that classical search provides a\nprincipled and practical foundation for inference-time scaling in diffusion\nmodels. Project page at diffusion-inference-scaling.github.io.", "AI": {"tldr": "A framework combining local and global search principles from classical algorithms improves inference-time control in diffusion models, enhancing performance and efficiency across tasks like planning, RL, and image generation.", "motivation": "To adapt diffusion model outputs for diverse test-time objectives using classical search principles.", "method": "Combines local search (annealed Langevin MCMC) and global search (breadth-first/depth-first tree search) to navigate generative space.", "result": "Significant performance and efficiency gains in planning, offline RL, and image generation.", "conclusion": "Classical search offers a principled, practical foundation for scaling diffusion model inference."}}
{"id": "2406.09325", "pdf": "https://arxiv.org/pdf/2406.09325", "abs": "https://arxiv.org/abs/2406.09325", "authors": ["Tomer Ashuach", "Martin Tutek", "Yonatan Belinkov"], "title": "REVS: Unlearning Sensitive Information in Language Models via Rank Editing in the Vocabulary Space", "categories": ["cs.CL", "I.2.7"], "comment": "ACL 2025 Findings, 24 pages, 4 figures", "summary": "Language models (LMs) risk inadvertently memorizing and divulging sensitive\nor personally identifiable information (PII) seen in training data, causing\nprivacy concerns. Current approaches to address this issue involve costly\ndataset scrubbing, or model filtering through unlearning and model editing,\nwhich can be bypassed through extraction attacks. We propose REVS, a novel\nnon-gradient-based method for unlearning sensitive information from LMs. REVS\nidentifies and modifies a small subset of neurons relevant for constituent\ntokens that form sensitive information. To adequately evaluate our method on\ntruly sensitive information, we curate three datasets: email and URL datasets\nnaturally memorized by the models, and a synthetic social security number\ndataset that we tune the models to memorize. Compared to other methods, REVS\ndemonstrates superior performance in unlearning sensitive information and\nrobustness to extraction attacks, while retaining underlying model integrity.", "AI": {"tldr": "REVS is a non-gradient-based method for unlearning sensitive information from LMs, outperforming existing methods in privacy protection and robustness.", "motivation": "Address privacy risks in LMs caused by memorizing sensitive data, avoiding costly or bypassable current solutions.", "method": "REVS modifies a small subset of neurons linked to sensitive tokens, evaluated on memorized email, URL, and synthetic SSN datasets.", "result": "REVS shows superior unlearning performance and robustness to attacks while preserving model integrity.", "conclusion": "REVS effectively mitigates privacy risks in LMs without compromising model functionality."}}
{"id": "2505.23740", "pdf": "https://arxiv.org/pdf/2505.23740", "abs": "https://arxiv.org/abs/2505.23740", "authors": ["Ronghuan Wu", "Wanchao Su", "Jing Liao"], "title": "LayerPeeler: Autoregressive Peeling for Layer-wise Image Vectorization", "categories": ["cs.CV", "cs.GR"], "comment": "Project Page: https://layerpeeler.github.io/", "summary": "Image vectorization is a powerful technique that converts raster images into\nvector graphics, enabling enhanced flexibility and interactivity. However,\npopular image vectorization tools struggle with occluded regions, producing\nincomplete or fragmented shapes that hinder editability. While recent\nadvancements have explored rule-based and data-driven layer-wise image\nvectorization, these methods face limitations in vectorization quality and\nflexibility. In this paper, we introduce LayerPeeler, a novel layer-wise image\nvectorization approach that addresses these challenges through a progressive\nsimplification paradigm. The key to LayerPeeler's success lies in its\nautoregressive peeling strategy: by identifying and removing the topmost\nnon-occluded layers while recovering underlying content, we generate vector\ngraphics with complete paths and coherent layer structures. Our method\nleverages vision-language models to construct a layer graph that captures\nocclusion relationships among elements, enabling precise detection and\ndescription for non-occluded layers. These descriptive captions are used as\nediting instructions for a finetuned image diffusion model to remove the\nidentified layers. To ensure accurate removal, we employ localized attention\ncontrol that precisely guides the model to target regions while faithfully\npreserving the surrounding content. To support this, we contribute a\nlarge-scale dataset specifically designed for layer peeling tasks. Extensive\nquantitative and qualitative experiments demonstrate that LayerPeeler\nsignificantly outperforms existing techniques, producing vectorization results\nwith superior path semantics, geometric regularity, and visual fidelity.", "AI": {"tldr": "LayerPeeler is a novel layer-wise image vectorization method that uses an autoregressive peeling strategy and vision-language models to improve vectorization quality and flexibility.", "motivation": "Existing image vectorization tools struggle with occluded regions, leading to incomplete or fragmented shapes. Recent methods also lack quality and flexibility.", "method": "LayerPeeler employs an autoregressive peeling strategy, vision-language models for layer graph construction, and a finetuned image diffusion model with localized attention control.", "result": "LayerPeeler outperforms existing techniques, producing vector graphics with complete paths, coherent layers, and superior visual fidelity.", "conclusion": "LayerPeeler addresses key challenges in image vectorization, offering improved quality and flexibility for vector graphics."}}
{"id": "2311.08760", "pdf": "https://arxiv.org/pdf/2311.08760", "abs": "https://arxiv.org/abs/2311.08760", "authors": ["Hendrik Buschmeier", "Heike M. Buhl", "Friederike Kern", "Angela Grimminger", "Helen Beierling", "Josephine Fisher", "Andr\u00e9 Gro\u00df", "Ilona Horwath", "Nils Klowait", "Stefan Lazarov", "Michael Lenke", "Vivien Lohmer", "Katharina Rohlfing", "Ingrid Scharlau", "Amit Singh", "Lutz Terfloth", "Anna-Lisa Vollmer", "Yu Wang", "Annedore Wilmes", "Britta Wrede"], "title": "Forms of Understanding for XAI-Explanations", "categories": ["cs.AI"], "comment": "revised version", "summary": "Explainability has become an important topic in computer science and\nartificial intelligence, leading to a subfield called Explainable Artificial\nIntelligence (XAI). The goal of providing or seeking explanations is to achieve\n(better) 'understanding' on the part of the explainee. However, what it means\nto 'understand' is still not clearly defined, and the concept itself is rarely\nthe subject of scientific investigation. This conceptual article aims to\npresent a model of forms of understanding for XAI-explanations and beyond. From\nan interdisciplinary perspective bringing together computer science,\nlinguistics, sociology, philosophy and psychology, a definition of\nunderstanding and its forms, assessment, and dynamics during the process of\ngiving everyday explanations are explored. Two types of understanding are\nconsidered as possible outcomes of explanations, namely enabledness, 'knowing\nhow' to do or decide something, and comprehension, 'knowing that' -- both in\ndifferent degrees (from shallow to deep). Explanations regularly start with\nshallow understanding in a specific domain and can lead to deep comprehension\nand enabledness of the explanandum, which we see as a prerequisite for human\nusers to gain agency. In this process, the increase of comprehension and\nenabledness are highly interdependent. Against the background of this\nsystematization, special challenges of understanding in XAI are discussed.", "AI": {"tldr": "The paper explores the concept of 'understanding' in Explainable AI (XAI), proposing a model of forms of understanding (enabledness and comprehension) and their dynamics in explanations.", "motivation": "To address the lack of a clear definition of 'understanding' in XAI and interdisciplinary fields, aiming to systematize forms of understanding for better explanations.", "method": "Interdisciplinary approach combining computer science, linguistics, sociology, philosophy, and psychology to define and assess understanding in explanations.", "result": "Identifies two types of understanding (enabledness and comprehension) with varying degrees (shallow to deep), highlighting their interdependence in achieving agency for users.", "conclusion": "The systematization of understanding forms provides a foundation for addressing challenges in XAI explanations, emphasizing the need for deeper comprehension and enabledness."}}
{"id": "2505.23615", "pdf": "https://arxiv.org/pdf/2505.23615", "abs": "https://arxiv.org/abs/2505.23615", "authors": ["Chang Yue", "Niraj K. Jha"], "title": "Learning Interpretable Differentiable Logic Networks for Tabular Regression", "categories": ["cs.LG"], "comment": null, "summary": "Neural networks (NNs) achieve outstanding performance in many domains;\nhowever, their decision processes are often opaque and their inference can be\ncomputationally expensive in resource-constrained environments. We recently\nproposed Differentiable Logic Networks (DLNs) to address these issues for\ntabular classification based on relaxing discrete logic into a differentiable\nform, thereby enabling gradient-based learning of networks built from binary\nlogic operations. DLNs offer interpretable reasoning and substantially lower\ninference cost.\n  We extend the DLN framework to supervised tabular regression. Specifically,\nwe redesign the final output layer to support continuous targets and unify the\noriginal two-phase training procedure into a single differentiable stage. We\nevaluate the resulting model on 15 public regression benchmarks, comparing it\nwith modern neural networks and classical regression baselines. Regression DLNs\nmatch or exceed baseline accuracy while preserving interpretability and fast\ninference. Our results show that DLNs are a viable, cost-effective alternative\nfor regression tasks, especially where model transparency and computational\nefficiency are important.", "AI": {"tldr": "DLNs extend to tabular regression, offering interpretability and fast inference while matching or exceeding baseline accuracy.", "motivation": "Address the opacity and computational cost of neural networks by adapting DLNs for regression tasks.", "method": "Redesign DLN output layer for continuous targets and unify training into a single stage. Evaluate on 15 regression benchmarks.", "result": "Regression DLNs match or exceed baseline accuracy while maintaining interpretability and low inference cost.", "conclusion": "DLNs are a viable, cost-effective alternative for regression, especially where transparency and efficiency matter."}}
{"id": "2406.13828", "pdf": "https://arxiv.org/pdf/2406.13828", "abs": "https://arxiv.org/abs/2406.13828", "authors": ["Tanawan Premsri", "Parisa Kordjamshidi"], "title": "Neuro-symbolic Training for Reasoning over Spatial Language", "categories": ["cs.CL"], "comment": "9 pages, 4 figures, NAACL 2025 findings", "summary": "Spatial reasoning based on natural language expressions is essential for\neveryday human tasks. This reasoning ability is also crucial for machines to\ninteract with their environment in a human-like manner. However, recent\nresearch shows that even state-of-the-art language models struggle with spatial\nreasoning over text, especially when facing nesting spatial expressions. This\nis attributed to not achieving the right level of abstraction required for\ngeneralizability. To alleviate this issue, we propose training language models\nwith neuro-symbolic techniques that exploit the spatial logical rules as\nconstraints, providing additional supervision to improve spatial reasoning and\nquestion answering. Training language models to adhere to spatial reasoning\nrules guides them in making more effective and general abstractions for\ntransferring spatial knowledge to various domains. We evaluate our approach on\nexisting spatial question-answering benchmarks. Our results indicate the\neffectiveness of our proposed technique in improving language models in complex\nmulti-hop spatial reasoning over text.", "AI": {"tldr": "The paper proposes neuro-symbolic techniques to improve spatial reasoning in language models by incorporating spatial logical rules as constraints.", "motivation": "Spatial reasoning is vital for human-like machine interaction, but current language models struggle with nesting spatial expressions due to insufficient abstraction.", "method": "The authors train language models using neuro-symbolic techniques, leveraging spatial logical rules as constraints for better supervision.", "result": "Evaluation on spatial question-answering benchmarks shows improved performance in complex multi-hop spatial reasoning.", "conclusion": "The proposed method effectively enhances language models' spatial reasoning abilities, aiding generalization across domains."}}
{"id": "2505.23743", "pdf": "https://arxiv.org/pdf/2505.23743", "abs": "https://arxiv.org/abs/2505.23743", "authors": ["Amber Yijia Zheng", "Yu Zhang", "Jun Hu", "Raymond A. Yeh", "Chen Chen"], "title": "DarkDiff: Advancing Low-Light Raw Enhancement by Retasking Diffusion Models for Camera ISP", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "High-quality photography in extreme low-light conditions is challenging but\nimpactful for digital cameras. With advanced computing hardware, traditional\ncamera image signal processor (ISP) algorithms are gradually being replaced by\nefficient deep networks that enhance noisy raw images more intelligently.\nHowever, existing regression-based models often minimize pixel errors and\nresult in oversmoothing of low-light photos or deep shadows. Recent work has\nattempted to address this limitation by training a diffusion model from\nscratch, yet those models still struggle to recover sharp image details and\naccurate colors. We introduce a novel framework to enhance low-light raw images\nby retasking pre-trained generative diffusion models with the camera ISP.\nExtensive experiments demonstrate that our method outperforms the\nstate-of-the-art in perceptual quality across three challenging low-light raw\nimage benchmarks.", "AI": {"tldr": "A novel framework enhances low-light raw images by retasking pre-trained generative diffusion models with the camera ISP, outperforming state-of-the-art methods in perceptual quality.", "motivation": "High-quality photography in extreme low-light conditions is impactful but challenging, and existing methods often result in oversmoothing or poor detail recovery.", "method": "Retasks pre-trained generative diffusion models with the camera ISP to enhance low-light raw images.", "result": "Outperforms state-of-the-art methods in perceptual quality across three challenging benchmarks.", "conclusion": "The proposed framework effectively addresses limitations of existing methods, improving detail recovery and color accuracy in low-light photography."}}
{"id": "2403.18405", "pdf": "https://arxiv.org/pdf/2403.18405", "abs": "https://arxiv.org/abs/2403.18405", "authors": ["Shengjie Ma", "Qi Chu", "Jiaxin Mao", "Xuhui Jiang", "Haozhe Duan", "Chong Chen"], "title": "Leveraging Large Language Models for Relevance Judgments in Legal Case Retrieval", "categories": ["cs.AI", "cs.IR"], "comment": null, "summary": "Determining which legal cases are relevant to a given query involves\nnavigating lengthy texts and applying nuanced legal reasoning. Traditionally,\nthis task has demanded significant time and domain expertise to identify key\nLegal Facts and reach sound juridical conclusions. In addition, existing data\nwith legal case similarities often lack interpretability, making it difficult\nto understand the rationale behind relevance judgments. With the growing\ncapabilities of large language models (LLMs), researchers have begun\ninvestigating their potential in this domain. Nonetheless, the method of\nemploying a general large language model for reliable relevance judgments in\nlegal case retrieval remains largely unexplored. To address this gap in\nresearch, we propose a novel few-shot approach where LLMs assist in generating\nexpert-aligned interpretable relevance judgments. The proposed approach\ndecomposes the judgment process into several stages, mimicking the workflow of\nhuman annotators and allowing for the flexible incorporation of expert\nreasoning to improve the accuracy of relevance judgments. Importantly, it also\nensures interpretable data labeling, providing transparency and clarity in the\nrelevance assessment process. Through a comparison of relevance judgments made\nby LLMs and human experts, we empirically demonstrate that the proposed\napproach can yield reliable and valid relevance assessments. Furthermore, we\ndemonstrate that with minimal expert supervision, our approach enables a large\nlanguage model to acquire case analysis expertise and subsequently transfers\nthis ability to a smaller model via annotation-based knowledge distillation.", "AI": {"tldr": "A novel few-shot approach using LLMs for interpretable and expert-aligned legal case relevance judgments, improving accuracy and transparency.", "motivation": "Traditional legal case relevance judgments require expertise and time, and existing methods lack interpretability. LLMs offer potential but remain unexplored for reliable legal case retrieval.", "method": "Decomposes judgment into stages mimicking human annotators, incorporates expert reasoning, and ensures interpretable labeling. Uses few-shot learning with LLMs.", "result": "LLMs produce reliable, valid relevance judgments comparable to human experts. Minimal supervision enables knowledge transfer to smaller models.", "conclusion": "The approach enhances legal case retrieval with interpretability and accuracy, leveraging LLMs effectively."}}
{"id": "2505.23627", "pdf": "https://arxiv.org/pdf/2505.23627", "abs": "https://arxiv.org/abs/2505.23627", "authors": ["Griffin Dietz Smith", "Dianna Yee", "Jennifer King Chen", "Leah Findlater"], "title": "Prompting Whisper for Improved Verbatim Transcription and End-to-end Miscue Detection", "categories": ["cs.LG"], "comment": "Interspeech 2025", "summary": "Identifying mistakes (i.e., miscues) made while reading aloud is commonly\napproached post-hoc by comparing automatic speech recognition (ASR)\ntranscriptions to the target reading text. However, post-hoc methods perform\npoorly when ASR inaccurately transcribes verbatim speech. To improve on current\nmethods for reading error annotation, we propose a novel end-to-end\narchitecture that incorporates the target reading text via prompting and is\ntrained for both improved verbatim transcription and direct miscue detection.\nOur contributions include: first, demonstrating that incorporating reading text\nthrough prompting benefits verbatim transcription performance over fine-tuning,\nand second, showing that it is feasible to augment speech recognition tasks for\nend-to-end miscue detection. We conducted two case studies -- children's\nread-aloud and adult atypical speech -- and found that our proposed strategies\nimprove verbatim transcription and miscue detection compared to current\nstate-of-the-art.", "AI": {"tldr": "The paper proposes an end-to-end architecture for real-time miscue detection in reading aloud, improving verbatim transcription and error detection by incorporating target text via prompting.", "motivation": "Current post-hoc methods for identifying reading miscues rely on ASR transcriptions, which perform poorly when ASR inaccurately transcribes verbatim speech. The paper aims to enhance miscue detection by integrating the target reading text directly into the model.", "method": "The authors introduce a novel end-to-end architecture that uses prompting to incorporate the target reading text. The model is trained for both verbatim transcription and direct miscue detection.", "result": "Case studies on children's read-aloud and adult atypical speech show improved verbatim transcription and miscue detection compared to state-of-the-art methods.", "conclusion": "The proposed architecture successfully enhances real-time miscue detection and verbatim transcription, demonstrating the feasibility of integrating reading text for improved performance."}}
{"id": "2407.00934", "pdf": "https://arxiv.org/pdf/2407.00934", "abs": "https://arxiv.org/abs/2407.00934", "authors": ["Jingheng Ye", "Zishan Xu", "Yinghui Li", "Linlin Song", "Qingyu Zhou", "Hai-Tao Zheng", "Ying Shen", "Wenhao Jiang", "Hong-Gee Kim", "Ruitong Liu", "Xin Su", "Zifei Shan"], "title": "CLEME2.0: Towards Interpretable Evaluation by Disentangling Edits for Grammatical Error Correction", "categories": ["cs.CL"], "comment": "19 pages, 12 tables, 3 figures. Accepted to ACL 2025 Main", "summary": "The paper focuses on the interpretability of Grammatical Error Correction\n(GEC) evaluation metrics, which received little attention in previous studies.\nTo bridge the gap, we introduce **CLEME2.0**, a reference-based metric\ndescribing four fundamental aspects of GEC systems: hit-correction,\nwrong-correction, under-correction, and over-correction. They collectively\ncontribute to exposing critical qualities and locating drawbacks of GEC\nsystems. Evaluating systems by combining these aspects also leads to superior\nhuman consistency over other reference-based and reference-less metrics.\nExtensive experiments on two human judgment datasets and six reference datasets\ndemonstrate the effectiveness and robustness of our method, achieving a new\nstate-of-the-art result. Our codes are released at\nhttps://github.com/THUKElab/CLEME.", "AI": {"tldr": "The paper introduces CLEME2.0, a reference-based metric for evaluating Grammatical Error Correction (GEC) systems, focusing on interpretability and outperforming existing metrics.", "motivation": "Previous studies lacked interpretability in GEC evaluation metrics, prompting the need for a more transparent and comprehensive approach.", "method": "CLEME2.0 evaluates GEC systems by analyzing hit-correction, wrong-correction, under-correction, and over-correction, combining these aspects for better human consistency.", "result": "Experiments on human judgment and reference datasets show CLEME2.0's effectiveness, achieving state-of-the-art performance.", "conclusion": "CLEME2.0 provides a robust and interpretable metric for GEC evaluation, advancing the field with superior human consistency and performance."}}
{"id": "2505.23752", "pdf": "https://arxiv.org/pdf/2505.23752", "abs": "https://arxiv.org/abs/2505.23752", "authors": ["Akashah Shabbir", "Muhammad Akhtar Munir", "Akshay Dudhane", "Muhammad Umer Sheikh", "Muhammad Haris Khan", "Paolo Fraccaro", "Juan Bernabe Moreno", "Fahad Shahbaz Khan", "Salman Khan"], "title": "ThinkGeo: Evaluating Tool-Augmented Agents for Remote Sensing Tasks", "categories": ["cs.CV"], "comment": null, "summary": "Recent progress in large language models (LLMs) has enabled tool-augmented\nagents capable of solving complex real-world tasks through step-by-step\nreasoning. However, existing evaluations often focus on general-purpose or\nmultimodal scenarios, leaving a gap in domain-specific benchmarks that assess\ntool-use capabilities in complex remote sensing use cases. We present ThinkGeo,\nan agentic benchmark designed to evaluate LLM-driven agents on remote sensing\ntasks via structured tool use and multi-step planning. Inspired by\ntool-interaction paradigms, ThinkGeo includes human-curated queries spanning a\nwide range of real-world applications such as urban planning, disaster\nassessment and change analysis, environmental monitoring, transportation\nanalysis, aviation monitoring, recreational infrastructure, and industrial site\nanalysis. Each query is grounded in satellite or aerial imagery and requires\nagents to reason through a diverse toolset. We implement a ReAct-style\ninteraction loop and evaluate both open and closed-source LLMs (e.g., GPT-4o,\nQwen2.5) on 436 structured agentic tasks. The benchmark reports both step-wise\nexecution metrics and final answer correctness. Our analysis reveals notable\ndisparities in tool accuracy and planning consistency across models. ThinkGeo\nprovides the first extensive testbed for evaluating how tool-enabled LLMs\nhandle spatial reasoning in remote sensing. Our code and dataset are publicly\navailable", "AI": {"tldr": "ThinkGeo is a benchmark for evaluating LLM-driven agents on remote sensing tasks using structured tool interactions and multi-step planning, revealing disparities in tool accuracy and planning consistency.", "motivation": "Existing evaluations lack domain-specific benchmarks for assessing tool-use capabilities in complex remote sensing tasks.", "method": "ThinkGeo includes human-curated queries grounded in satellite/aerial imagery, requiring agents to use diverse tools via a ReAct-style interaction loop. Open and closed-source LLMs are evaluated on 436 tasks.", "result": "Disparities in tool accuracy and planning consistency across models are observed.", "conclusion": "ThinkGeo offers the first extensive testbed for spatial reasoning in remote sensing, with publicly available code and dataset."}}
{"id": "2407.20761", "pdf": "https://arxiv.org/pdf/2407.20761", "abs": "https://arxiv.org/abs/2407.20761", "authors": ["Yongqiang Yao", "Jingru Tan", "Feizhao Zhang", "Jiahao Hu", "Yazhe Niu", "Xin Jin", "Bo Li", "Pengfei Liu", "Ruihao Gong", "Dahua Lin", "Ningyi Xu"], "title": "OmniBal: Towards Fast Instruction-Tuning for Vision-Language Models via Omniverse Computation Balance", "categories": ["cs.AI"], "comment": null, "summary": "Vision-language instruction-tuning models have recently achieved significant\nperformance improvements. In this work, we discover that large-scale 3D\nparallel training on those models leads to an imbalanced computation load\nacross different devices. The vision and language parts are inherently\nheterogeneous: their data distribution and model architecture differ\nsignificantly, which affects distributed training efficiency. To address this\nissue, we rebalance the computational load from data, model, and memory\nperspectives, achieving more balanced computation across devices. Specifically,\nfor the data, instances are grouped into new balanced mini-batches within and\nacross devices. A search-based method is employed for the model to achieve a\nmore balanced partitioning. For memory optimization, we adaptively adjust the\nre-computation strategy for each partition to utilize the available memory\nfully. These three perspectives are not independent but are closely connected,\nforming an omniverse balanced training framework. Extensive experiments are\nconducted to validate the effectiveness of our method. Compared with the\nopen-source training code of InternVL-Chat, training time is reduced greatly,\nachieving about 1.8$\\times$ speed-up. Our method's efficacy and\ngeneralizability are further validated across various models and datasets.\nCodes will be released at https://github.com/ModelTC/OmniBal.", "AI": {"tldr": "The paper addresses computational load imbalance in vision-language instruction-tuning models during large-scale 3D parallel training, proposing a balanced training framework for improved efficiency.", "motivation": "The vision and language parts of these models are inherently heterogeneous, causing imbalanced computation across devices during distributed training.", "method": "The solution rebalances computation from data, model, and memory perspectives: grouping instances into balanced mini-batches, using a search-based model partitioning method, and adaptive memory re-computation.", "result": "The method reduces training time by 1.8\u00d7 compared to InternVL-Chat and shows efficacy across various models and datasets.", "conclusion": "The proposed omniverse balanced training framework effectively addresses computational imbalance, improving training efficiency and generalizability."}}
{"id": "2505.23634", "pdf": "https://arxiv.org/pdf/2505.23634", "abs": "https://arxiv.org/abs/2505.23634", "authors": ["John Halloran"], "title": "MCP Safety Training: Learning to Refuse Falsely Benign MCP Exploits using Improved Preference Alignment", "categories": ["cs.LG", "cs.CR"], "comment": "27 pages, 19 figures, 4 tables", "summary": "The model context protocol (MCP) has been widely adapted as an open standard\nenabling the seamless integration of generative AI agents. However, recent work\nhas shown the MCP is susceptible to retrieval-based \"falsely benign\" attacks\n(FBAs), allowing malicious system access and credential theft, but requiring\nthat users download compromised files directly to their systems. Herein, we\nshow that the threat model of MCP-based attacks is significantly broader than\npreviously thought, i.e., attackers need only post malicious content online to\ndeceive MCP agents into carrying out their attacks on unsuspecting victims'\nsystems.\n  To improve alignment guardrails against such attacks, we introduce a new MCP\ndataset of FBAs and (truly) benign samples to explore the effectiveness of\ndirect preference optimization (DPO) for the refusal training of large language\nmodels (LLMs). While DPO improves model guardrails against such attacks, we\nshow that the efficacy of refusal learning varies drastically depending on the\nmodel's original post-training alignment scheme--e.g., GRPO-based LLMs learn to\nrefuse extremely poorly. Thus, to further improve FBA refusals, we introduce\nRetrieval Augmented Generation for Preference alignment (RAG-Pref), a novel\npreference alignment strategy based on RAG. We show that RAG-Pref significantly\nimproves the ability of LLMs to refuse FBAs, particularly when combined with\nDPO alignment, thus drastically improving guardrails against MCP-based attacks.", "AI": {"tldr": "The paper reveals MCP's vulnerability to online-based FBAs, introduces DPO and RAG-Pref to enhance LLM refusal training, and shows RAG-Pref's superior performance in mitigating attacks.", "motivation": "Address the broader threat of MCP-based FBAs, which can now exploit online content, and improve LLM guardrails against such attacks.", "method": "Introduces DPO for refusal training and RAG-Pref, a novel RAG-based preference alignment strategy, to enhance LLM defenses.", "result": "DPO improves guardrails, but effectiveness varies by alignment scheme; RAG-Pref significantly boosts FBA refusal, especially with DPO.", "conclusion": "RAG-Pref combined with DPO drastically improves LLM guardrails against MCP-based FBAs, offering robust defense."}}
{"id": "2407.09447", "pdf": "https://arxiv.org/pdf/2407.09447", "abs": "https://arxiv.org/abs/2407.09447", "authors": ["Amelia F. Hardy", "Houjun Liu", "Bernard Lange", "Duncan Eddy", "Mykel J. Kochenderfer"], "title": "ASTPrompter: Preference-Aligned Automated Language Model Red-Teaming to Generate Low-Perplexity Unsafe Prompts", "categories": ["cs.CL"], "comment": "8 pages, 7 pages of appendix, 3 tables, 4 figures", "summary": "Existing LLM red-teaming approaches prioritize high attack success rate,\noften resulting in high-perplexity prompts. This focus overlooks low-perplexity\nattacks that are more difficult to filter, more likely to arise during benign\nusage, and more impactful as negative downstream training examples. In\nresponse, we introduce ASTPrompter, a single-step optimization method that uses\ncontrastive preference learning to train an attacker to maintain low perplexity\nwhile achieving a high attack success rate (ASR). ASTPrompter achieves an\nattack success rate 5.1 times higher on Llama-8.1B while using inputs that are\n2.1 times more likely to occur according to the frozen LLM. Furthermore, our\nattack transfers to Mistral-7B, Qwen-7B, and TinyLlama in both black- and\nwhite-box settings. Lastly, by tuning a single hyperparameter in our method, we\ndiscover successful attack prefixes along an efficient frontier between ASR and\nperplexity, highlighting perplexity as a previously under-considered factor in\nred-teaming.", "AI": {"tldr": "ASTPrompter is a method for low-perplexity red-teaming attacks on LLMs, achieving higher success rates and better transferability.", "motivation": "Existing red-teaming approaches focus on high attack success rates but overlook low-perplexity attacks, which are harder to filter and more impactful.", "method": "ASTPrompter uses contrastive preference learning to optimize for low perplexity while maintaining high attack success rates.", "result": "ASTPrompter achieves 5.1x higher attack success on Llama-8.1B with 2.1x more likely inputs, and transfers well to other models.", "conclusion": "Perplexity is an under-considered factor in red-teaming; ASTPrompter efficiently balances it with attack success."}}
{"id": "2505.23756", "pdf": "https://arxiv.org/pdf/2505.23756", "abs": "https://arxiv.org/abs/2505.23756", "authors": ["Justin Lazarow", "Kai Kang", "Afshin Dehghan"], "title": "Rooms from Motion: Un-posed Indoor 3D Object Detection as Localization and Mapping", "categories": ["cs.CV"], "comment": null, "summary": "We revisit scene-level 3D object detection as the output of an object-centric\nframework capable of both localization and mapping using 3D oriented boxes as\nthe underlying geometric primitive. While existing 3D object detection\napproaches operate globally and implicitly rely on the a priori existence of\nmetric camera poses, our method, Rooms from Motion (RfM) operates on a\ncollection of un-posed images. By replacing the standard 2D keypoint-based\nmatcher of structure-from-motion with an object-centric matcher based on\nimage-derived 3D boxes, we estimate metric camera poses, object tracks, and\nfinally produce a global, semantic 3D object map. When a priori pose is\navailable, we can significantly improve map quality through optimization of\nglobal 3D boxes against individual observations. RfM shows strong localization\nperformance and subsequently produces maps of higher quality than leading\npoint-based and multi-view 3D object detection methods on CA-1M and ScanNet++,\ndespite these global methods relying on overparameterization through point\nclouds or dense volumes. Rooms from Motion achieves a general, object-centric\nrepresentation which not only extends the work of Cubify Anything to full\nscenes but also allows for inherently sparse localization and parametric\nmapping proportional to the number of objects in a scene.", "AI": {"tldr": "Rooms from Motion (RfM) introduces an object-centric framework for 3D object detection and mapping using un-posed images, outperforming existing methods by leveraging 3D boxes for localization and optimization.", "motivation": "Existing 3D object detection methods rely on global approaches and metric camera poses, limiting their applicability. RfM aims to operate on un-posed images, providing a more flexible and object-centric solution.", "method": "RfM replaces 2D keypoint-based matching with an object-centric matcher using 3D boxes, enabling metric camera pose estimation, object tracking, and global semantic 3D mapping. It optimizes global 3D boxes when pose data is available.", "result": "RfM outperforms point-based and multi-view 3D detection methods on CA-1M and ScanNet++, achieving higher map quality and strong localization performance.", "conclusion": "RfM offers a scalable, object-centric representation for 3D scenes, extending Cubify Anything to full scenes and enabling sparse localization and parametric mapping."}}
{"id": "2408.00989", "pdf": "https://arxiv.org/pdf/2408.00989", "abs": "https://arxiv.org/abs/2408.00989", "authors": ["Jen-tse Huang", "Jiaxu Zhou", "Tailin Jin", "Xuhui Zhou", "Zixi Chen", "Wenxuan Wang", "Youliang Yuan", "Michael R. Lyu", "Maarten Sap"], "title": "On the Resilience of LLM-Based Multi-Agent Collaboration with Faulty Agents", "categories": ["cs.AI"], "comment": "9 pages of main text; 12 pages of appendix", "summary": "Large language model-based multi-agent systems have shown great abilities\nacross various tasks due to the collaboration of expert agents, each focusing\non a specific domain. However, the impact of clumsy or even malicious\nagents--those who frequently make errors in their tasks--on the overall\nperformance of the system remains underexplored. This paper investigates: (1)\nWhat is the resilience of various system structures (e.g.,\nA$\\rightarrow$B$\\rightarrow$C, A$\\leftrightarrow$B$\\leftrightarrow$C) under\nfaulty agents, on different downstream tasks? (2) How can we increase system\nresilience to defend against these agents? To simulate faulty agents, we\npropose two approaches--AutoTransform and AutoInject--which introduce mistakes\ninto the agents' responses. Experiments on four downstream tasks using six\nsystems show that the \"hierarchical\" structure, i.e.,\nA$\\rightarrow$(B$\\leftrightarrow$C), exhibits superior resilience with the\nlowest performance drop of 5.5%, compared to 10.5% and 23.7% of other two\nstructures. To further improve resilience, we introduce (1) Challenger, that\nintroduces a mechanism for each agent to challenge others' outputs, and (2)\nInspector, an additional agent to review and correct messages, recovering up to\n96.4% errors made by faulty agents. Our code and data are available at\nhttps://github.com/CUHK-ARISE/MAS-Resilience.", "AI": {"tldr": "The paper explores the resilience of multi-agent systems with faulty agents, identifies the hierarchical structure as most resilient, and proposes two methods (Challenger and Inspector) to improve resilience.", "motivation": "To understand how faulty or malicious agents impact multi-agent systems and develop strategies to enhance system resilience.", "method": "Simulates faulty agents using AutoTransform and AutoInject, tests resilience on four tasks, and introduces Challenger and Inspector to mitigate errors.", "result": "Hierarchical structure (A\u2192(B\u2194C)) shows lowest performance drop (5.5%). Challenger and Inspector recover up to 96.4% of errors.", "conclusion": "Hierarchical structures and additional mechanisms (Challenger, Inspector) significantly improve system resilience against faulty agents."}}
{"id": "2505.23640", "pdf": "https://arxiv.org/pdf/2505.23640", "abs": "https://arxiv.org/abs/2505.23640", "authors": ["Yilin Xie", "Shiqiang Zhang", "Jixiang Qing", "Ruth Misener", "Calvin Tsay"], "title": "Global optimization of graph acquisition functions for neural architecture search", "categories": ["cs.LG", "math.OC"], "comment": "19 pages, 6 figures, 3 tables", "summary": "Graph Bayesian optimization (BO) has shown potential as a powerful and\ndata-efficient tool for neural architecture search (NAS). Most existing graph\nBO works focus on developing graph surrogates models, i.e., metrics of networks\nand/or different kernels to quantify the similarity between networks. However,\nthe acquisition optimization, as a discrete optimization task over graph\nstructures, is not well studied due to the complexity of formulating the graph\nsearch space and acquisition functions. This paper presents explicit\noptimization formulations for graph input space including properties such as\nreachability and shortest paths, which are used later to formulate graph\nkernels and the acquisition function. We theoretically prove that the proposed\nencoding is an equivalent representation of the graph space and provide\nrestrictions for the NAS domain with either node or edge labels. Numerical\nresults over several NAS benchmarks show that our method efficiently finds the\noptimal architecture for most cases, highlighting its efficacy.", "AI": {"tldr": "Graph BO for NAS is improved by explicit optimization formulations for graph input space, proving efficacy in finding optimal architectures.", "motivation": "Existing graph BO works lack focus on acquisition optimization due to complexity in graph search space and acquisition functions.", "method": "Proposes explicit optimization formulations for graph input space, including reachability and shortest paths, to formulate graph kernels and acquisition functions.", "result": "Theoretical proof of equivalent graph space representation and successful numerical results on NAS benchmarks.", "conclusion": "The method efficiently finds optimal architectures, demonstrating its efficacy in NAS."}}
{"id": "2407.17390", "pdf": "https://arxiv.org/pdf/2407.17390", "abs": "https://arxiv.org/abs/2407.17390", "authors": ["Itamar Trainin", "Omri Abend"], "title": "$T^5Score$: A Methodology for Automatically Assessing the Quality of LLM Generated Multi-Document Topic Sets", "categories": ["cs.CL"], "comment": "Published in the Findings of ACL 2025", "summary": "Using LLMs for Multi-Document Topic Extraction has recently gained popularity\ndue to their apparent high-quality outputs, expressiveness, and ease of use.\nHowever, most existing evaluation practices are not designed for LLM-generated\ntopics and result in low inter-annotator agreement scores, hindering the\nreliable use of LLMs for the task. To address this, we introduce $T^5Score$, an\nevaluation methodology that decomposes the quality of a topic set into\nquantifiable aspects, measurable through easy-to-perform annotation tasks. This\nframing enables a convenient, manual or automatic, evaluation procedure\nresulting in a strong inter-annotator agreement score. To substantiate our\nmethodology and claims, we perform extensive experimentation on multiple\ndatasets and report the results.", "AI": {"tldr": "The paper introduces $T^5Score$, a new evaluation methodology for assessing LLM-generated topics in multi-document extraction, addressing low inter-annotator agreement in existing methods.", "motivation": "Existing evaluation practices for LLM-generated topics suffer from low inter-annotator agreement, limiting reliable use of LLMs for topic extraction.", "method": "Proposes $T^5Score$, which decomposes topic quality into quantifiable aspects for easy manual or automatic evaluation.", "result": "Extensive experiments on multiple datasets validate the methodology, showing strong inter-annotator agreement.", "conclusion": "$T^5Score$ provides a reliable and convenient way to evaluate LLM-generated topics, improving their practical utility."}}
{"id": "2505.23757", "pdf": "https://arxiv.org/pdf/2505.23757", "abs": "https://arxiv.org/abs/2505.23757", "authors": ["Haohan Chi", "Huan-ang Gao", "Ziming Liu", "Jianing Liu", "Chenyu Liu", "Jinwei Li", "Kaisen Yang", "Yangcheng Yu", "Zeda Wang", "Wenyi Li", "Leichen Wang", "Xingtao Hu", "Hao Sun", "Hang Zhao", "Hao Zhao"], "title": "Impromptu VLA: Open Weights and Open Data for Driving Vision-Language-Action Models", "categories": ["cs.CV"], "comment": "Project page: https://github.com/ahydchh/Impromptu-VLA", "summary": "Vision-Language-Action (VLA) models for autonomous driving show promise but\nfalter in unstructured corner case scenarios, largely due to a scarcity of\ntargeted benchmarks. To address this, we introduce Impromptu VLA. Our core\ncontribution is the Impromptu VLA Dataset: over 80,000 meticulously curated\nvideo clips, distilled from over 2M source clips sourced from 8 open-source\nlarge-scale datasets. This dataset is built upon our novel taxonomy of four\nchallenging unstructured categories and features rich, planning-oriented\nquestion-answering annotations and action trajectories. Crucially, experiments\ndemonstrate that VLAs trained with our dataset achieve substantial performance\ngains on established benchmarks--improving closed-loop NeuroNCAP scores and\ncollision rates, and reaching near state-of-the-art L2 accuracy in open-loop\nnuScenes trajectory prediction. Furthermore, our Q&A suite serves as an\neffective diagnostic, revealing clear VLM improvements in perception,\nprediction, and planning. Our code, data and models are available at\nhttps://github.com/ahydchh/Impromptu-VLA.", "AI": {"tldr": "The paper introduces Impromptu VLA, a dataset to improve Vision-Language-Action models for autonomous driving by addressing unstructured scenarios.", "motivation": "Current VLA models struggle in unstructured corner cases due to a lack of targeted benchmarks.", "method": "The authors create the Impromptu VLA Dataset, with 80,000 curated video clips and rich annotations, based on a novel taxonomy.", "result": "VLAs trained with this dataset show significant performance gains in benchmarks like NeuroNCAP and nuScenes.", "conclusion": "The dataset and Q&A suite effectively enhance VLA performance in perception, prediction, and planning."}}
{"id": "2408.10946", "pdf": "https://arxiv.org/pdf/2408.10946", "abs": "https://arxiv.org/abs/2408.10946", "authors": ["Anton Korikov", "Scott Sanner", "Yashar Deldjoo", "Zhankui He", "Julian McAuley", "Arnau Ramisa", "Rene Vidal", "Mahesh Sathiamoorthy", "Atoosa Kasrizadeh", "Silvia Milano", "Francesco Ricci"], "title": "Large Language Model Driven Recommendation", "categories": ["cs.AI"], "comment": null, "summary": "While previous chapters focused on recommendation systems (RSs) based on\nstandardized, non-verbal user feedback such as purchases, views, and clicks --\nthe advent of LLMs has unlocked the use of natural language (NL) interactions\nfor recommendation. This chapter discusses how LLMs' abilities for general NL\nreasoning present novel opportunities to build highly personalized RSs -- which\ncan effectively connect nuanced and diverse user preferences to items,\npotentially via interactive dialogues. To begin this discussion, we first\npresent a taxonomy of the key data sources for language-driven recommendation,\ncovering item descriptions, user-system interactions, and user profiles. We\nthen proceed to fundamental techniques for LLM recommendation, reviewing the\nuse of encoder-only and autoregressive LLM recommendation in both tuned and\nuntuned settings. Afterwards, we move to multi-module recommendation\narchitectures in which LLMs interact with components such as retrievers and RSs\nin multi-stage pipelines. This brings us to architectures for conversational\nrecommender systems (CRSs), in which LLMs facilitate multi-turn dialogues where\neach turn presents an opportunity not only to make recommendations, but also to\nengage with the user in interactive preference elicitation, critiquing, and\nquestion-answering.", "AI": {"tldr": "The paper explores how LLMs enable personalized recommendation systems through natural language interactions, covering data sources, techniques, and architectures for conversational recommenders.", "motivation": "To leverage LLMs' NL reasoning for building highly personalized recommendation systems via interactive dialogues.", "method": "Presents a taxonomy of data sources, reviews LLM techniques (encoder-only and autoregressive), and discusses multi-module architectures and conversational recommender systems.", "result": "LLMs offer novel opportunities for nuanced user preference modeling and interactive recommendation dialogues.", "conclusion": "LLMs can revolutionize recommendation systems by enabling natural language-driven, interactive, and personalized user experiences."}}
{"id": "2505.23648", "pdf": "https://arxiv.org/pdf/2505.23648", "abs": "https://arxiv.org/abs/2505.23648", "authors": ["Halil Alperen Gozeten", "M. Emrullah Ildiz", "Xuechen Zhang", "Hrayr Harutyunyan", "Ankit Singh Rawat", "Samet Oymak"], "title": "Continuous Chain of Thought Enables Parallel Exploration and Reasoning", "categories": ["cs.LG"], "comment": null, "summary": "Current language models generate chain-of-thought traces by autoregressively\nsampling tokens from a finite vocabulary. While this discrete sampling has\nachieved remarkable success, conducting chain-of-thought with\ncontinuously-valued tokens (CoT2) offers a richer and more expressive\nalternative. Our work examines the benefits of CoT2 through logical reasoning\ntasks that inherently require search capabilities and provide optimization and\nexploration methods for CoT2. Theoretically, we show that CoT2 allows the model\nto track multiple traces in parallel and quantify its benefits for inference\nefficiency. Notably, one layer transformer equipped with CoT2 can provably\nsolve the combinatorial \"subset sum problem\" given sufficient embedding\ndimension. These insights lead to a novel and effective supervision strategy\nwhere we match the softmax outputs to the empirical token distributions of a\nset of target traces. Complementing this, we introduce sampling strategies that\nunlock policy optimization and self-improvement for CoT2. Our first strategy\nsamples and composes $K$ discrete tokens at each decoding step to control the\nlevel of parallelism, and reduces to standard CoT when $K=1$. Our second\nstrategy relies on continuous exploration over the probability simplex.\nExperiments confirm that policy optimization with CoT2 indeed improves the\nperformance of the model beyond its initial discrete or continuous supervision.", "AI": {"tldr": "The paper introduces CoT2, a method for chain-of-thought reasoning using continuous-valued tokens, showing its benefits in logical reasoning tasks and efficiency. It provides theoretical insights, supervision strategies, and sampling methods to enhance performance.", "motivation": "Discrete sampling in chain-of-thought reasoning has limitations. CoT2 offers a more expressive and efficient alternative, especially for tasks requiring search and optimization.", "method": "The paper proposes CoT2, which uses continuous-valued tokens, and introduces supervision strategies (matching softmax outputs to empirical distributions) and sampling methods (parallel token sampling and continuous exploration).", "result": "Theoretically, CoT2 enables parallel trace tracking and solves the subset sum problem with a one-layer transformer. Experimentally, policy optimization with CoT2 outperforms discrete or continuous supervision.", "conclusion": "CoT2 enhances chain-of-thought reasoning by leveraging continuous tokens, offering theoretical and practical advantages over discrete methods."}}
{"id": "2408.04556", "pdf": "https://arxiv.org/pdf/2408.04556", "abs": "https://arxiv.org/abs/2408.04556", "authors": ["Yupeng Chang", "Yi Chang", "Yuan Wu"], "title": "BA-LoRA: Bias-Alleviating Low-Rank Adaptation to Mitigate Catastrophic Inheritance in Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": "25 pages", "summary": "Large language models (LLMs) have demonstrated remarkable proficiency across\nvarious natural language processing (NLP) tasks. However, adapting LLMs to\ndownstream applications requires computationally intensive and memory-demanding\nfine-tuning procedures. To alleviate these burdens, parameter-efficient\nfine-tuning (PEFT) techniques have emerged as a promising approach to tailor\nLLMs with minimal computational overhead. While PEFT methods offer substantial\nadvantages, they do not fully address the pervasive issue of bias propagation\nfrom pre-training data. This work introduces Bias-Alleviating Low-Rank\nAdaptation (BA-LoRA), a novel PEFT method designed to counteract bias\ninheritance. BA-LoRA incorporates three distinct regularization terms: (1) a\nconsistency regularizer, (2) a diversity regularizer, and (3) a singular value\ndecomposition regularizer. These regularizers aim to enhance the models'\nconsistency, diversity, and generalization capabilities during fine-tuning. We\nconduct extensive experiments on natural language understanding (NLU) and\nnatural language generation (NLG) tasks using prominent LLMs such as LLaMA,\nMistral, and Gemma. The results demonstrate that BA-LoRA outperforms LoRA and\nits state-of-the-art variants. Moreover, the extended experiments demonstrate\nthat our method effectively mitigates the adverse effects of pre-training bias,\nleading to more reliable and robust model outputs. The code is available at\nhttps://github.com/cyp-jlu-ai/BA-LoRA.", "AI": {"tldr": "BA-LoRA is a parameter-efficient fine-tuning method for LLMs that reduces bias propagation while maintaining performance.", "motivation": "To address the computational and bias issues in fine-tuning LLMs.", "method": "Introduces BA-LoRA with three regularization terms: consistency, diversity, and SVD.", "result": "Outperforms LoRA and variants, reducing bias in NLU and NLG tasks.", "conclusion": "BA-LoRA effectively mitigates bias and enhances model reliability."}}
{"id": "2505.23758", "pdf": "https://arxiv.org/pdf/2505.23758", "abs": "https://arxiv.org/abs/2505.23758", "authors": ["Yusuf Dalva", "Hidir Yesiltepe", "Pinar Yanardag"], "title": "LoRAShop: Training-Free Multi-Concept Image Generation and Editing with Rectified Flow Transformers", "categories": ["cs.CV"], "comment": "Project Webpage: https://lorashop.github.io/", "summary": "We introduce LoRAShop, the first framework for multi-concept image editing\nwith LoRA models. LoRAShop builds on a key observation about the feature\ninteraction patterns inside Flux-style diffusion transformers: concept-specific\ntransformer features activate spatially coherent regions early in the denoising\nprocess. We harness this observation to derive a disentangled latent mask for\neach concept in a prior forward pass and blend the corresponding LoRA weights\nonly within regions bounding the concepts to be personalized. The resulting\nedits seamlessly integrate multiple subjects or styles into the original scene\nwhile preserving global context, lighting, and fine details. Our experiments\ndemonstrate that LoRAShop delivers better identity preservation compared to\nbaselines. By eliminating retraining and external constraints, LoRAShop turns\npersonalized diffusion models into a practical `photoshop-with-LoRAs' tool and\nopens new avenues for compositional visual storytelling and rapid creative\niteration.", "AI": {"tldr": "LoRAShop is a framework for multi-concept image editing using LoRA models, leveraging feature interactions in diffusion transformers for seamless edits.", "motivation": "To enable practical and efficient multi-concept image editing without retraining or external constraints, preserving identity and context.", "method": "Uses disentangled latent masks from prior forward passes to blend LoRA weights within concept-specific regions.", "result": "Better identity preservation and seamless integration of multiple subjects/styles compared to baselines.", "conclusion": "LoRAShop transforms personalized diffusion models into a practical tool for creative visual storytelling and rapid iteration."}}
{"id": "2408.16081", "pdf": "https://arxiv.org/pdf/2408.16081", "abs": "https://arxiv.org/abs/2408.16081", "authors": ["Agnieszka Mensfelt", "Kostas Stathis", "Vince Trencsenyi"], "title": "Towards Logically Sound Natural Language Reasoning with Logic-Enhanced Language Model Agents", "categories": ["cs.AI", "cs.CL", "cs.GT", "cs.LO"], "comment": "Source code: https://github.com/dicelab-rhul/LELMA", "summary": "Large language models (LLMs) are increasingly explored as general-purpose\nreasoners, particularly in agentic contexts. However, their outputs remain\nprone to mathematical and logical errors. This is especially challenging in\nopen-ended tasks, where unstructured outputs lack explicit ground truth and may\ncontain subtle inconsistencies. To address this issue, we propose\nLogic-Enhanced Language Model Agents (LELMA), a framework that integrates LLMs\nwith formal logic to enable validation and refinement of natural language\nreasoning. LELMA comprises three components: an LLM-Reasoner, an\nLLM-Translator, and a Solver, and employs autoformalization to translate\nreasoning into logic representations, which are then used to assess logical\nvalidity. Using game-theoretic scenarios such as the Prisoner's Dilemma as\ntestbeds, we highlight the limitations of both less capable (Gemini 1.0 Pro)\nand advanced (GPT-4o) models in generating logically sound reasoning. LELMA\nachieves high accuracy in error detection and improves reasoning correctness\nvia self-refinement, particularly in GPT-4o. The study also highlights\nchallenges in autoformalization accuracy and in evaluation of inherently\nambiguous open-ended reasoning tasks.", "AI": {"tldr": "LELMA integrates LLMs with formal logic to validate and refine reasoning, improving accuracy in open-ended tasks like game theory.", "motivation": "Addressing LLMs' susceptibility to mathematical and logical errors in unstructured, open-ended reasoning tasks.", "method": "LELMA combines an LLM-Reasoner, LLM-Translator, and Solver to autoformalize reasoning into logic for validation.", "result": "LELMA detects errors effectively and enhances reasoning correctness, especially in advanced models like GPT-4o.", "conclusion": "LELMA improves logical soundness in LLM reasoning but faces challenges in autoformalization and ambiguous task evaluation."}}
{"id": "2505.23651", "pdf": "https://arxiv.org/pdf/2505.23651", "abs": "https://arxiv.org/abs/2505.23651", "authors": ["Juncheol Shin", "Minsang Seok", "Seonggon Kim", "Eunhyeok Park"], "title": "Merge-Friendly Post-Training Quantization for Multi-Target Domain Adaptation", "categories": ["cs.LG", "cs.CV"], "comment": "ICML 2025. Code: https://github.com/ewsn1593/HDRQ", "summary": "Model merging has emerged as a powerful technique for combining task-specific\nweights, achieving superior performance in multi-target domain adaptation.\nHowever, when applied to practical scenarios, such as quantized models, new\nchallenges arise. In practical scenarios, quantization is often applied to\ntarget-specific data, but this process restricts the domain of interest and\nintroduces discretization effects, making model merging highly non-trivial. In\nthis study, we analyze the impact of quantization on model merging through the\nlens of error barriers. Leveraging these insights, we propose a novel\npost-training quantization, HDRQ - Hessian and distant regularizing\nquantization - that is designed to consider model merging for multi-target\ndomain adaptation. Our approach ensures that the quantization process incurs\nminimal deviation from the source pre-trained model while flattening the loss\nsurface to facilitate smooth model merging. To our knowledge, this is the first\nstudy on this challenge, and extensive experiments confirm its effectiveness.", "AI": {"tldr": "The paper introduces HDRQ, a post-training quantization method for model merging in multi-target domain adaptation, addressing challenges posed by quantization.", "motivation": "Quantization in practical scenarios restricts domains and introduces discretization effects, complicating model merging.", "method": "Proposes HDRQ (Hessian and distant regularizing quantization) to minimize deviation from the source model and flatten the loss surface for smoother merging.", "result": "Extensive experiments confirm HDRQ's effectiveness in handling quantization for model merging.", "conclusion": "HDRQ is the first solution addressing quantization's impact on model merging, proving successful in multi-target domain adaptation."}}
{"id": "2408.09853", "pdf": "https://arxiv.org/pdf/2408.09853", "abs": "https://arxiv.org/abs/2408.09853", "authors": ["Weiqi Wu", "Hongqiu Wu", "Hai Zhao"], "title": "X-TURING: Towards an Enhanced and Efficient Turing Test for Long-Term Dialogue Agents", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ACL 2025 Main Conference", "summary": "The Turing test examines whether AIs exhibit human-like behaviour in natural\nlanguage conversations. The traditional setting limits each participant to one\nmessage at a time and requires constant human participation. This fails to\nreflect a natural conversational style and hinders the evaluation of dialogue\nagents based on Large Language Models (LLMs) in complex and prolonged\ninteractions. This paper proposes \\textbf{\\textsc{X-Turing}}, which enhances\nthe original test with a \\textit{burst dialogue} pattern, allowing more dynamic\nexchanges using consecutive messages. It further reduces human workload by\niteratively generating dialogues that simulate the long-term interaction\nbetween the agent and a human to compose the majority of the test process. With\nthe \\textit{pseudo-dialogue} history, the agent then engages in a shorter\ndialogue with a real human, which is paired with a human-human conversation on\nthe same topic to be judged using questionnaires. We introduce the\n\\textit{X-Turn Pass-Rate} metric to assess the human likeness of LLMs across\nvarying durations. While LLMs like GPT-4 initially perform well, achieving pass\nrates of 51.9\\% and 38.9\\% during 3 turns and 10 turns of dialogues\nrespectively, their performance drops as the dialogue progresses, which\nunderscores the difficulty in maintaining consistency in the long term.", "AI": {"tldr": "The paper introduces X-Turing, an enhanced Turing test using burst dialogue and pseudo-dialogue to evaluate LLMs in prolonged interactions, revealing performance drops over time.", "motivation": "Traditional Turing tests lack natural conversational dynamics and human workload efficiency, limiting LLM evaluation in long-term interactions.", "method": "X-Turing employs burst dialogue for dynamic exchanges and pseudo-dialogue to simulate long-term interactions, reducing human involvement.", "result": "LLMs like GPT-4 show initial success (51.9% pass rate at 3 turns) but decline over time (38.9% at 10 turns), highlighting long-term consistency challenges.", "conclusion": "X-Turing improves Turing test realism and efficiency, revealing LLMs' limitations in sustained human-like dialogue."}}
{"id": "2505.23763", "pdf": "https://arxiv.org/pdf/2505.23763", "abs": "https://arxiv.org/abs/2505.23763", "authors": ["Aneeshan Sain", "Subhajit Maity", "Pinaki Nath Chowdhury", "Subhadeep Koley", "Ayan Kumar Bhunia", "Yi-Zhe Song"], "title": "Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch", "categories": ["cs.CV"], "comment": "Accepted at CVPR 2025, Project Page:\n  https://subhajitmaity.me/SketchDownTheFLOPs", "summary": "As sketch research has collectively matured over time, its adaptation for\nat-mass commercialisation emerges on the immediate horizon. Despite an already\nmature research endeavour for photos, there is no research on the efficient\ninference specifically designed for sketch data. In this paper, we first\ndemonstrate existing state-of-the-art efficient light-weight models designed\nfor photos do not work on sketches. We then propose two sketch-specific\ncomponents which work in a plug-n-play manner on any photo efficient network to\nadapt them to work on sketch data. We specifically chose fine-grained\nsketch-based image retrieval (FG-SBIR) as a demonstrator as the most recognised\nsketch problem with immediate commercial value. Technically speaking, we first\npropose a cross-modal knowledge distillation network to transfer existing photo\nefficient networks to be compatible with sketch, which brings down number of\nFLOPs and model parameters by 97.96% percent and 84.89% respectively. We then\nexploit the abstract trait of sketch to introduce a RL-based canvas selector\nthat dynamically adjusts to the abstraction level which further cuts down\nnumber of FLOPs by two thirds. The end result is an overall reduction of 99.37%\nof FLOPs (from 40.18G to 0.254G) when compared with a full network, while\nretaining the accuracy (33.03% vs 32.77%) -- finally making an efficient\nnetwork for the sparse sketch data that exhibit even fewer FLOPs than the best\nphoto counterpart.", "AI": {"tldr": "The paper addresses the lack of efficient inference models for sketch data by proposing two plug-n-play components to adapt photo-efficient networks for sketches, achieving significant FLOP reduction while retaining accuracy.", "motivation": "Existing efficient models for photos don't work for sketches, and there's no research on sketch-specific efficient inference, despite its commercial potential.", "method": "1) Cross-modal knowledge distillation to adapt photo-efficient networks for sketches. 2) RL-based canvas selector to dynamically adjust to sketch abstraction.", "result": "Reduced FLOPs by 99.37% (from 40.18G to 0.254G) while maintaining accuracy (33.03% vs 32.77%).", "conclusion": "The proposed components enable efficient sketch inference with fewer FLOPs than photo models, making it viable for commercialization."}}
{"id": "2410.02229", "pdf": "https://arxiv.org/pdf/2410.02229", "abs": "https://arxiv.org/abs/2410.02229", "authors": ["Huimu Yu", "Xing Wu", "Haotian Xu", "Debing Zhang", "Songlin Hu"], "title": "CodePMP: Scalable Preference Model Pretraining for Large Language Model Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "work in progress", "summary": "Large language models (LLMs) have made significant progress in natural\nlanguage understanding and generation, driven by scalable pretraining and\nadvanced finetuning. However, enhancing reasoning abilities in LLMs,\nparticularly via reinforcement learning from human feedback (RLHF), remains\nchallenging due to the scarcity of high-quality preference data, which is\nlabor-intensive to annotate and crucial for reward model (RM) finetuning. To\nalleviate this issue, we introduce CodePMP, a scalable preference model\npretraining (PMP) pipeline that utilizes a large corpus of synthesized\ncode-preference pairs from publicly available high-quality source code. CodePMP\nimproves RM finetuning efficiency by pretraining preference models on\nlarge-scale synthesized code-preference pairs. We evaluate CodePMP on\nmathematical reasoning tasks (GSM8K, MATH) and logical reasoning tasks (ReClor,\nLogiQA2.0), consistently showing significant improvements in reasoning\nperformance of LLMs and highlighting the importance of scalable preference\nmodel pretraining for efficient reward modeling.", "AI": {"tldr": "CodePMP introduces a scalable preference model pretraining pipeline using synthesized code-preference pairs to improve reasoning in LLMs via efficient reward model finetuning.", "motivation": "Addressing the challenge of enhancing LLMs' reasoning abilities due to scarce high-quality preference data for RLHF.", "method": "Pretraining preference models on large-scale synthesized code-preference pairs from public source code.", "result": "Significant improvements in reasoning performance on mathematical and logical tasks (GSM8K, MATH, ReClor, LogiQA2.0).", "conclusion": "Scalable preference model pretraining is crucial for efficient reward modeling and better reasoning in LLMs."}}
{"id": "2505.23653", "pdf": "https://arxiv.org/pdf/2505.23653", "abs": "https://arxiv.org/abs/2505.23653", "authors": ["Jiaran Ye", "Zijun Yao", "Zhidian Huang", "Liangming Pan", "Jinxin Liu", "Yushi Bai", "Amy Xin", "Liu Weichuan", "Xiaoyin Che", "Lei Hou", "Juanzi Li"], "title": "How does Transformer Learn Implicit Reasoning?", "categories": ["cs.LG"], "comment": null, "summary": "Recent work suggests that large language models (LLMs) can perform multi-hop\nreasoning implicitly -- producing correct answers without explicitly\nverbalizing intermediate steps -- but the underlying mechanisms remain poorly\nunderstood. In this paper, we study how such implicit reasoning emerges by\ntraining transformers from scratch in a controlled symbolic environment. Our\nanalysis reveals a three-stage developmental trajectory: early memorization,\nfollowed by in-distribution generalization, and eventually cross-distribution\ngeneralization. We find that training with atomic triples is not necessary but\naccelerates learning, and that second-hop generalization relies on query-level\nexposure to specific compositional structures. To interpret these behaviors, we\nintroduce two diagnostic tools: cross-query semantic patching, which identifies\nsemantically reusable intermediate representations, and a cosine-based\nrepresentational lens, which reveals that successful reasoning correlates with\nthe cosine-base clustering in hidden space. This clustering phenomenon in turn\nprovides a coherent explanation for the behavioral dynamics observed across\ntraining, linking representational structure to reasoning capability. These\nfindings provide new insights into the interpretability of implicit multi-hop\nreasoning in LLMs, helping to clarify how complex reasoning processes unfold\ninternally and offering pathways to enhance the transparency of such models.", "AI": {"tldr": "The paper explores how implicit multi-hop reasoning emerges in LLMs, revealing a three-stage learning trajectory and introducing diagnostic tools to analyze representational structure.", "motivation": "To understand the mechanisms behind implicit multi-hop reasoning in LLMs, which remain poorly understood despite recent findings.", "method": "Training transformers from scratch in a controlled symbolic environment, analyzing developmental stages, and introducing diagnostic tools (cross-query semantic patching and cosine-based representational lens).", "result": "Identified a three-stage learning trajectory (memorization, in-distribution generalization, cross-distribution generalization) and found that specific training conditions (e.g., atomic triples) accelerate learning. Representational clustering correlates with reasoning success.", "conclusion": "The study provides insights into LLMs' implicit reasoning, linking representational structure to behavior, and suggests pathways to enhance model transparency."}}
{"id": "2408.10411", "pdf": "https://arxiv.org/pdf/2408.10411", "abs": "https://arxiv.org/abs/2408.10411", "authors": ["Hammad Rizwan", "Domenic Rosati", "Ga Wu", "Hassan Sajjad"], "title": "Resolving Lexical Bias in Model Editing", "categories": ["cs.CL"], "comment": null, "summary": "Model editing aims to modify the outputs of large language models after they\nare trained. Previous approaches have often involved direct alterations to\nmodel weights, which can result in model degradation. Recent techniques avoid\nmaking modifications to the model's weights by using an adapter that applies\nedits to the model when triggered by semantic similarity in the representation\nspace. We demonstrate that current adapter methods are critically vulnerable to\nstrong lexical biases, leading to issues such as applying edits to irrelevant\nprompts with overlapping words. This paper presents a principled approach to\nlearning a disentangled representation space that facilitates precise\nlocalization of edits by maintaining distance between irrelevant prompts while\npreserving proximity among paraphrases. In our empirical study, we show that\nour method (Projector Editor Networks for Model Editing - PENME) achieves\nstate-of-the-art model editing results while being more computationally\nefficient during inference than previous methods and adaptable across different\narchitectures.", "AI": {"tldr": "PENME introduces a disentangled representation space for precise model editing, avoiding weight modifications and outperforming previous methods in efficiency and adaptability.", "motivation": "To address vulnerabilities in current adapter-based model editing methods, which suffer from lexical biases and imprecise edits.", "method": "Uses a disentangled representation space to localize edits precisely, maintaining distance between irrelevant prompts and proximity among paraphrases.", "result": "Achieves state-of-the-art editing results, is computationally efficient during inference, and adaptable across architectures.", "conclusion": "PENME provides a robust and efficient solution for model editing, overcoming limitations of prior approaches."}}
{"id": "2505.23766", "pdf": "https://arxiv.org/pdf/2505.23766", "abs": "https://arxiv.org/abs/2505.23766", "authors": ["Yunze Man", "De-An Huang", "Guilin Liu", "Shiwei Sheng", "Shilong Liu", "Liang-Yan Gui", "Jan Kautz", "Yu-Xiong Wang", "Zhiding Yu"], "title": "Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought", "categories": ["cs.CV"], "comment": "CVPR 2025. Project Page: https://yunzeman.github.io/argus/", "summary": "Recent advances in multimodal large language models (MLLMs) have demonstrated\nremarkable capabilities in vision-language tasks, yet they often struggle with\nvision-centric scenarios where precise visual focus is needed for accurate\nreasoning. In this paper, we introduce Argus to address these limitations with\na new visual attention grounding mechanism. Our approach employs object-centric\ngrounding as visual chain-of-thought signals, enabling more effective\ngoal-conditioned visual attention during multimodal reasoning tasks.\nEvaluations on diverse benchmarks demonstrate that Argus excels in both\nmultimodal reasoning tasks and referring object grounding tasks. Extensive\nanalysis further validates various design choices of Argus, and reveals the\neffectiveness of explicit language-guided visual region-of-interest engagement\nin MLLMs, highlighting the importance of advancing multimodal intelligence from\na visual-centric perspective. Project page: https://yunzeman.github.io/argus/", "AI": {"tldr": "Argus improves MLLMs by introducing a visual attention grounding mechanism for better vision-centric reasoning.", "motivation": "MLLMs struggle with vision-centric tasks requiring precise visual focus.", "method": "Uses object-centric grounding as visual chain-of-thought signals for goal-conditioned visual attention.", "result": "Excels in multimodal reasoning and referring object grounding tasks.", "conclusion": "Highlights the importance of visual-centric approaches for advancing multimodal intelligence."}}
{"id": "2410.08475", "pdf": "https://arxiv.org/pdf/2410.08475", "abs": "https://arxiv.org/abs/2410.08475", "authors": ["Jiashu He", "Mingyu Derek Ma", "Jinxuan Fan", "Dan Roth", "Wei Wang", "Alejandro Ribeiro"], "title": "GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Existing approaches based on context prompting or reinforcement learning (RL)\nto improve the reasoning capacities of large language models (LLMs) depend on\nthe LLMs' internal knowledge to produce reliable Chain-Of-Thought (CoT).\nHowever, no matter the size of LLMs, certain problems cannot be resolved in a\nsingle forward pass. Meanwhile, agent-based reasoning systems require access to\na comprehensive nonparametric knowledge base, which is often costly or not\nfeasible for use in scientific and niche domains. We present Graph Inspired\nVeracity Extrapolation (GIVE), a novel reasoning method that merges parametric\nand non-parametric memories to improve accurate reasoning with minimal external\ninput. GIVE guides the LLM agent to select the most pertinent expert data\n(observe), engage in query-specific divergent thinking (reflect), and then\nsynthesize this information to produce the final output (speak). Extensive\nexperiments demonstrated the following benefits of our framework: (1) GIVE\nboosts the performance of LLMs across various sizes. (2) In some scenarios,\nGIVE allows smaller LLMs to surpass larger, more sophisticated ones in\nscientific tasks (GPT3.5T + GIVE > GPT4). (3) GIVE is effective on scientific\nand open-domain assessments. (4) GIVE is a training-free method that enables\nLLMs to tackle new problems that extend beyond their training data (up to 43.5%\n-> 88.2%} accuracy improvement). (5) GIVE allows LLM agents to reason using\nboth restricted (very small) and noisy (very large) knowledge sources,\naccommodating knowledge graphs (KG) ranging from 135 to more than 840k nodes.\n(6) The reasoning process involved in GIVE is fully interpretable.", "AI": {"tldr": "GIVE is a novel reasoning method combining parametric and non-parametric memories to enhance LLM reasoning with minimal external input, outperforming larger models in some cases.", "motivation": "Address limitations of existing methods (context prompting, RL) and costly nonparametric knowledge bases in LLM reasoning, especially for niche domains.", "method": "GIVE merges parametric and non-parametric memories, guiding LLMs to observe, reflect, and speak for accurate reasoning.", "result": "Boosts LLM performance, enables smaller models to surpass larger ones, and improves accuracy (up to 88.2%) on new problems.", "conclusion": "GIVE is a training-free, interpretable method effective for scientific and open-domain tasks, adaptable to varying knowledge sources."}}
{"id": "2505.23663", "pdf": "https://arxiv.org/pdf/2505.23663", "abs": "https://arxiv.org/abs/2505.23663", "authors": ["Niklas Freymuth", "Tobias W\u00fcrth", "Nicolas Schreiber", "Balazs Gyenes", "Andreas Boltres", "Johannes Mitsch", "Aleksandar Taranovic", "Tai Hoang", "Philipp Dahlinger", "Philipp Becker", "Luise K\u00e4rger", "Gerhard Neumann"], "title": "AMBER: Adaptive Mesh Generation by Iterative Mesh Resolution Prediction", "categories": ["cs.LG", "cs.CG"], "comment": null, "summary": "The cost and accuracy of simulating complex physical systems using the Finite\nElement Method (FEM) scales with the resolution of the underlying mesh.\nAdaptive meshes improve computational efficiency by refining resolution in\ncritical regions, but typically require task-specific heuristics or cumbersome\nmanual design by a human expert. We propose Adaptive Meshing By Expert\nReconstruction (AMBER), a supervised learning approach to mesh adaptation.\nStarting from a coarse mesh, AMBER iteratively predicts the sizing field, i.e.,\na function mapping from the geometry to the local element size of the target\nmesh, and uses this prediction to produce a new intermediate mesh using an\nout-of-the-box mesh generator. This process is enabled through a hierarchical\ngraph neural network, and relies on data augmentation by automatically\nprojecting expert labels onto AMBER-generated data during training. We evaluate\nAMBER on 2D and 3D datasets, including classical physics problems, mechanical\ncomponents, and real-world industrial designs with human expert meshes. AMBER\ngeneralizes to unseen geometries and consistently outperforms multiple recent\nbaselines, including ones using Graph and Convolutional Neural Networks, and\nReinforcement Learning-based approaches.", "AI": {"tldr": "AMBER is a supervised learning method for adaptive meshing in FEM, using a hierarchical GNN to predict sizing fields and outperforming baselines.", "motivation": "Traditional adaptive meshing requires task-specific heuristics or expert input, which is inefficient. AMBER automates this process.", "method": "AMBER iteratively predicts sizing fields from coarse meshes using a hierarchical GNN, aided by data augmentation from expert labels.", "result": "AMBER generalizes to unseen geometries and outperforms baselines like GNNs, CNNs, and RL-based methods in 2D/3D datasets.", "conclusion": "AMBER offers an efficient, automated alternative to manual adaptive meshing, improving FEM simulations."}}
{"id": "2408.13533", "pdf": "https://arxiv.org/pdf/2408.13533", "abs": "https://arxiv.org/abs/2408.13533", "authors": ["Jinyang Wu", "Shuai Zhang", "Feihu Che", "Mingkuan Feng", "Pengpeng Shao", "Jianhua Tao"], "title": "Pandora's Box or Aladdin's Lamp: A Comprehensive Analysis Revealing the Role of RAG Noise in Large Language Models", "categories": ["cs.CL"], "comment": "ACL 2025 Main", "summary": "Retrieval-Augmented Generation (RAG) has emerged as a crucial method for\naddressing hallucinations in large language models (LLMs). While recent\nresearch has extended RAG models to complex noisy scenarios, these explorations\noften confine themselves to limited noise types and presuppose that noise is\ninherently detrimental to LLMs, potentially deviating from real-world retrieval\nenvironments and restricting practical applicability. In this paper, we define\nseven distinct noise types from a linguistic perspective and establish a Noise\nRAG Benchmark (NoiserBench), a comprehensive evaluation framework encompassing\nmultiple datasets and reasoning tasks. Through empirical evaluation of eight\nrepresentative LLMs with diverse architectures and scales, we reveal that these\nnoises can be further categorized into two practical groups: noise that is\nbeneficial to LLMs (aka beneficial noise) and noise that is harmful to LLMs\n(aka harmful noise). While harmful noise generally impairs performance,\nbeneficial noise may enhance several aspects of model capabilities and overall\nperformance. Our analysis offers insights for developing more robust, adaptable\nRAG solutions and mitigating hallucinations across diverse retrieval scenarios.\nCode is available at https://github.com/jinyangwu/NoiserBench.", "AI": {"tldr": "The paper introduces NoiserBench, a benchmark for evaluating the impact of linguistic noise on RAG models, categorizing noise into beneficial and harmful types.", "motivation": "To address the limited understanding of noise in RAG models and its real-world applicability, the study aims to explore diverse noise types and their effects on LLMs.", "method": "The authors define seven noise types, create NoiserBench, and evaluate eight LLMs across datasets and reasoning tasks.", "result": "Noise is categorized into beneficial (enhances performance) and harmful (impairs performance), revealing nuanced impacts on LLMs.", "conclusion": "The findings guide robust RAG solutions and hallucination mitigation, with practical implications for diverse retrieval scenarios."}}
{"id": "2505.23769", "pdf": "https://arxiv.org/pdf/2505.23769", "abs": "https://arxiv.org/abs/2505.23769", "authors": ["Yao Xiao", "Qiqian Fu", "Heyi Tao", "Yuqun Wu", "Zhen Zhu", "Derek Hoiem"], "title": "TextRegion: Text-Aligned Region Tokens from Frozen Image-Text Models", "categories": ["cs.CV"], "comment": "Code is available at: https://github.com/avaxiao/TextRegion", "summary": "Image-text models excel at image-level tasks but struggle with detailed\nvisual understanding. While these models provide strong visual-language\nalignment, segmentation models like SAM2 offer precise spatial boundaries for\nobjects. To this end, we propose TextRegion, a simple, effective, and\ntraining-free framework that combines the strengths of image-text models and\nSAM2 to generate powerful text-aligned region tokens. These tokens enable\ndetailed visual understanding while preserving open-vocabulary capabilities.\nThey can be directly applied to various downstream tasks, including open-world\nsemantic segmentation, referring expression comprehension, and grounding. We\nconduct extensive evaluations and consistently achieve superior or competitive\nperformance compared to state-of-the-art training-free methods. Additionally,\nour framework is compatible with many image-text models, making it highly\npractical and easily extensible as stronger models emerge. Code is available\nat: https://github.com/avaxiao/TextRegion.", "AI": {"tldr": "TextRegion combines image-text models and SAM2 for detailed visual understanding without training, achieving strong performance in tasks like segmentation and grounding.", "motivation": "Image-text models lack detailed spatial understanding, while segmentation models like SAM2 provide precise boundaries but miss text alignment. TextRegion bridges this gap.", "method": "Proposes a training-free framework integrating image-text models and SAM2 to generate text-aligned region tokens for detailed visual tasks.", "result": "Superior or competitive performance in open-world segmentation, referring expression comprehension, and grounding compared to state-of-the-art training-free methods.", "conclusion": "TextRegion is practical, extensible, and effective for combining visual-language alignment with precise spatial understanding."}}
{"id": "2410.17885", "pdf": "https://arxiv.org/pdf/2410.17885", "abs": "https://arxiv.org/abs/2410.17885", "authors": ["Linger Deng", "Linghao Zhu", "Yuliang Liu", "Yu Wang", "Qunyi Xie", "Jingjing Wu", "Gang Zhang", "Yingying Zhu", "Xiang Bai"], "title": "Theorem-Validated Reverse Chain-of-Thought Problem Generation for Geometric Reasoning", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Large Multimodal Models (LMMs) face limitations in geometric reasoning due to\ninsufficient Chain of Thought (CoT) image-text training data. While existing\napproaches leverage template-based or LLM-assisted methods for geometric CoT\ndata creation, they often face challenges in achieving both diversity and\nprecision. To bridge this gap, we introduce a two-stage Theorem-Validated\nReverse Chain-of-Thought Reasoning Synthesis (TR-CoT) framework. The first\nstage, TR-Engine, synthesizes theorem-grounded geometric diagrams with\nstructured descriptions and properties. The second stage, TR-Reasoner, employs\nreverse reasoning to iteratively refine question-answer pairs by\ncross-validating geometric properties and description fragments. Our approach\nexpands theorem-type coverage, corrects long-standing misunderstandings, and\nenhances geometric reasoning. Fine-grained CoT improves theorem understanding\nand increases logical consistency by 24.5%. Our best models surpass the\nbaselines in MathVista and GeoQA by 10.1% and 4.7%, outperforming advanced\nclosed-source models like GPT-4o.", "AI": {"tldr": "TR-CoT framework improves geometric reasoning in LMMs by synthesizing theorem-grounded diagrams and refining QA pairs, outperforming baselines and GPT-4o.", "motivation": "Address limitations in geometric reasoning due to insufficient CoT image-text data and lack of diversity/precision in existing methods.", "method": "Two-stage TR-CoT: TR-Engine synthesizes diagrams with descriptions, TR-Reasoner refines QA pairs via reverse reasoning and cross-validation.", "result": "24.5% increase in logical consistency; outperforms baselines in MathVista (10.1%) and GeoQA (4.7%), surpassing GPT-4o.", "conclusion": "TR-CoT enhances geometric reasoning, expands theorem coverage, and corrects misunderstandings, proving effective for LMMs."}}
{"id": "2505.23673", "pdf": "https://arxiv.org/pdf/2505.23673", "abs": "https://arxiv.org/abs/2505.23673", "authors": ["Aya Kayal", "Sattar Vakili", "Laura Toni", "Da-shan Shiu", "Alberto Bernacchia"], "title": "Bayesian Optimization from Human Feedback: Near-Optimal Regret Bounds", "categories": ["cs.LG"], "comment": null, "summary": "Bayesian optimization (BO) with preference-based feedback has recently\ngarnered significant attention due to its emerging applications. We refer to\nthis problem as Bayesian Optimization from Human Feedback (BOHF), which differs\nfrom conventional BO by learning the best actions from a reduced feedback\nmodel, where only the preference between two actions is revealed to the learner\nat each time step. The objective is to identify the best action using a limited\nnumber of preference queries, typically obtained through costly human feedback.\nExisting work, which adopts the Bradley-Terry-Luce (BTL) feedback model,\nprovides regret bounds for the performance of several algorithms. In this work,\nwithin the same framework we develop tighter performance guarantees.\nSpecifically, we derive regret bounds of\n$\\tilde{\\mathcal{O}}(\\sqrt{\\Gamma(T)T})$, where $\\Gamma(T)$ represents the\nmaximum information gain$\\unicode{x2014}$a kernel-specific complexity\nterm$\\unicode{x2014}$and $T$ is the number of queries. Our results\nsignificantly improve upon existing bounds. Notably, for common kernels, we\nshow that the order-optimal sample complexities of conventional\nBO$\\unicode{x2014}$achieved with richer feedback models$\\unicode{x2014}$are\nrecovered. In other words, the same number of preferential samples as\nscalar-valued samples is sufficient to find a nearly optimal solution.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2410.03553", "pdf": "https://arxiv.org/pdf/2410.03553", "abs": "https://arxiv.org/abs/2410.03553", "authors": ["Wei Wu", "Chao Wang", "Liyi Chen", "Mingze Yin", "Yiheng Zhu", "Kun Fu", "Jieping Ye", "Hui Xiong", "Zheng Wang"], "title": "Structure-Enhanced Protein Instruction Tuning: Towards General-Purpose Protein Understanding with LLMs", "categories": ["cs.CL", "q-bio.BM"], "comment": "Accepted by KDD2025", "summary": "Proteins, as essential biomolecules, play a central role in biological\nprocesses, including metabolic reactions and DNA replication. Accurate\nprediction of their properties and functions is crucial in biological\napplications. Recent development of protein language models (pLMs) with\nsupervised fine tuning provides a promising solution to this problem. However,\nthe fine-tuned model is tailored for particular downstream prediction task, and\nachieving general-purpose protein understanding remains a challenge. In this\npaper, we introduce Structure-Enhanced Protein Instruction Tuning (SEPIT)\nframework to bridge this gap. Our approach incorporates a novel structure-aware\nmodule into pLMs to enrich their structural knowledge, and subsequently\nintegrates these enhanced pLMs with large language models (LLMs) to advance\nprotein understanding. In this framework, we propose a novel instruction tuning\npipeline. First, we warm up the enhanced pLMs using contrastive learning and\nstructure denoising. Then, caption-based instructions are used to establish a\nbasic understanding of proteins. Finally, we refine this understanding by\nemploying a mixture of experts (MoEs) to capture more complex properties and\nfunctional information with the same number of activated parameters. Moreover,\nwe construct the largest and most comprehensive protein instruction dataset to\ndate, which allows us to train and evaluate the general-purpose protein\nunderstanding model. Extensive experiments on both open-ended generation and\nclosed-set answer tasks demonstrate the superior performance of SEPIT over both\nclosed-source general LLMs and open-source LLMs trained with protein knowledge.", "AI": {"tldr": "SEPIT enhances protein language models with structural knowledge and integrates them with LLMs for general-purpose protein understanding, outperforming existing methods.", "motivation": "Accurate protein property and function prediction is crucial, but current fine-tuned models are task-specific, lacking general-purpose understanding.", "method": "SEPIT incorporates a structure-aware module into pLMs, uses contrastive learning and structure denoising, and employs a mixture of experts for refinement.", "result": "SEPIT outperforms closed-source and open-source LLMs in both open-ended generation and closed-set answer tasks.", "conclusion": "SEPIT bridges the gap in general-purpose protein understanding, demonstrating superior performance with its novel framework and comprehensive dataset."}}
{"id": "2505.22769", "pdf": "https://arxiv.org/pdf/2505.22769", "abs": "https://arxiv.org/abs/2505.22769", "authors": ["Yaxiong Lei", "Mingyue Zhao", "Yuheng Wang", "Shijing He", "Yusuke Sugano", "Yafei Wang", "Kaixing Zhao", "Mohamed Khamis", "Juan Ye"], "title": "MAC-Gaze: Motion-Aware Continual Calibration for Mobile Gaze Tracking", "categories": ["cs.HC", "cs.CV", "68T10, 68U35", "H.5.2; H.1.2; C.2.4; I.5.4"], "comment": "24 pages, 7 figures", "summary": "Mobile gaze tracking faces a fundamental challenge: maintaining accuracy as\nusers naturally change their postures and device orientations. Traditional\ncalibration approaches, like one-off, fail to adapt to these dynamic\nconditions, leading to degraded performance over time. We present MAC-Gaze, a\nMotion-Aware continual Calibration approach that leverages smartphone Inertial\nmeasurement unit (IMU) sensors and continual learning techniques to\nautomatically detect changes in user motion states and update the gaze tracking\nmodel accordingly. Our system integrates a pre-trained visual gaze estimator\nand an IMU-based activity recognition model with a clustering-based hybrid\ndecision-making mechanism that triggers recalibration when motion patterns\ndeviate significantly from previously encountered states. To enable\naccumulative learning of new motion conditions while mitigating catastrophic\nforgetting, we employ replay-based continual learning, allowing the model to\nmaintain performance across previously encountered motion conditions. We\nevaluate our system through extensive experiments on the publicly available\nRGBDGaze dataset and our own 10-hour multimodal MotionGaze dataset (481K+\nimages, 800K+ IMU readings), encompassing a wide range of postures under\nvarious motion conditions including sitting, standing, lying, and walking.\nResults demonstrate that our method reduces gaze estimation error by 19.9% on\nRGBDGaze (from 1.73 cm to 1.41 cm) and by 31.7% on MotionGaze (from 2.81 cm to\n1.92 cm) compared to traditional calibration approaches. Our framework provides\na robust solution for maintaining gaze estimation accuracy in mobile scenarios.", "AI": {"tldr": "MAC-Gaze uses IMU sensors and continual learning to adapt gaze tracking to dynamic user postures, reducing errors by up to 31.7%.", "motivation": "Traditional calibration fails in dynamic conditions, degrading gaze tracking accuracy over time.", "method": "Combines IMU-based motion detection, clustering, and replay-based continual learning to trigger recalibration.", "result": "Reduced gaze error by 19.9% on RGBDGaze and 31.7% on MotionGaze compared to traditional methods.", "conclusion": "MAC-Gaze offers a robust solution for accurate mobile gaze tracking in varied motion conditions."}}
{"id": "2412.08805", "pdf": "https://arxiv.org/pdf/2412.08805", "abs": "https://arxiv.org/abs/2412.08805", "authors": ["Agnieszka Mensfelt", "Kostas Stathis", "Vince Trencsenyi"], "title": "Generative Agents for Multi-Agent Autoformalization of Interaction Scenarios", "categories": ["cs.AI"], "comment": "code: https://github.com/dicelab-rhul/GAMA", "summary": "Multi-agent simulations are versatile tools for exploring interactions among\nnatural and artificial agents, but their development typically demands domain\nexpertise and manual effort. This work introduces the Generative Agents for\nMulti-Agent Autoformalization (GAMA) framework, which automates the\nformalization of interaction scenarios in simulations using agents augmented\nwith large language models (LLMs). To demonstrate the application of GAMA, we\nuse natural language descriptions of game-theoretic scenarios representing\nsocial interactions, and we autoformalize them into executable logic programs\ndefining game rules, with syntactic correctness enforced through a solver-based\nvalidation. To ensure runtime validity, an iterative, tournament-based\nprocedure tests the generated rules and strategies, followed by exact semantic\nvalidation when ground truth outcomes are available. In experiments with 110\nnatural language descriptions across five 2x2 simultaneous-move games, GAMA\nachieves 100% syntactic and 76.5% semantic correctness with Claude 3.5 Sonnet,\nand 99.82% syntactic and 77% semantic correctness with GPT-4o. The framework\nalso shows high semantic accuracy in autoformalizing agents' strategies.", "AI": {"tldr": "GAMA automates formalization of multi-agent simulations using LLMs, achieving high syntactic and semantic correctness.", "motivation": "Manual development of multi-agent simulations requires domain expertise; GAMA aims to automate this process.", "method": "Uses LLMs to autoformalize natural language descriptions into executable logic programs, validated syntactically and semantically.", "result": "Achieves 100% syntactic and 76.5% semantic correctness with Claude 3.5 Sonnet, and 99.82% syntactic and 77% semantic correctness with GPT-4o.", "conclusion": "GAMA effectively automates simulation formalization with high accuracy in strategy autoformalization."}}
{"id": "2505.23681", "pdf": "https://arxiv.org/pdf/2505.23681", "abs": "https://arxiv.org/abs/2505.23681", "authors": ["Bo Zhao", "Nima Dehmamy", "Robin Walters", "Rose Yu"], "title": "Understanding Mode Connectivity via Parameter Space Symmetry", "categories": ["cs.LG"], "comment": "20 pages, 4 figures, ICML 2025", "summary": "Neural network minima are often connected by curves along which train and\ntest loss remain nearly constant, a phenomenon known as mode connectivity.\nWhile this property has enabled applications such as model merging and\nfine-tuning, its theoretical explanation remains unclear. We propose a new\napproach to exploring the connectedness of minima using parameter space\nsymmetry. By linking the topology of symmetry groups to that of the minima, we\nderive the number of connected components of the minima of linear networks and\nshow that skip connections reduce this number. We then examine when mode\nconnectivity and linear mode connectivity hold or fail, using parameter\nsymmetries which account for a significant part of the minimum. Finally, we\nprovide explicit expressions for connecting curves in the minima induced by\nsymmetry. Using the curvature of these curves, we derive conditions under which\nlinear mode connectivity approximately holds. Our findings highlight the role\nof continuous symmetries in understanding the neural network loss landscape.", "AI": {"tldr": "The paper explores mode connectivity in neural networks using parameter space symmetry, showing how skip connections reduce connected components and deriving conditions for linear mode connectivity.", "motivation": "To theoretically explain the phenomenon of mode connectivity in neural networks, which has practical applications like model merging but lacks clear theoretical understanding.", "method": "The study links the topology of symmetry groups to minima, derives the number of connected components for linear networks, and examines conditions for mode connectivity using parameter symmetries.", "result": "Skip connections reduce the number of connected components, and explicit expressions for connecting curves in minima are provided. Conditions for linear mode connectivity are derived.", "conclusion": "Continuous symmetries play a key role in understanding the neural network loss landscape, with implications for model design and optimization."}}
{"id": "2410.11001", "pdf": "https://arxiv.org/pdf/2410.11001", "abs": "https://arxiv.org/abs/2410.11001", "authors": ["Haozhen Zhang", "Tao Feng", "Jiaxuan You"], "title": "Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted by ACL 2025 Main. The code is available at\n  https://github.com/ulab-uiuc/GoR", "summary": "Retrieval-augmented generation (RAG) has revitalized Large Language Models\n(LLMs) by injecting non-parametric factual knowledge. Compared with\nlong-context LLMs, RAG is considered an effective summarization tool in a more\nconcise and lightweight manner, which can interact with LLMs multiple times\nusing diverse queries to get comprehensive responses. However, the\nLLM-generated historical responses, which contain potentially insightful\ninformation, are largely neglected and discarded by existing approaches,\nleading to suboptimal results. In this paper, we propose $\\textit{graph of\nrecords}$ ($\\textbf{GoR}$), which leverages historical responses generated by\nLLMs to enhance RAG for long-context global summarization. Inspired by the\n$\\textit{retrieve-then-generate}$ paradigm of RAG, we construct a graph by\nestablishing an edge between the retrieved text chunks and the corresponding\nLLM-generated response. To further uncover the intricate correlations between\nthem, GoR features a $\\textit{graph neural network}$ and an elaborately\ndesigned $\\textit{BERTScore}$-based objective for self-supervised model\ntraining, enabling seamless supervision signal backpropagation between\nreference summaries and node embeddings. We comprehensively compare GoR with 12\nbaselines across four long-context summarization datasets, and the results\nindicate that our proposed method reaches the best performance\n($\\textit{e.g.}$, 15%, 8%, and 19% improvement over retrievers w.r.t. Rouge-L,\nRouge-1, and Rouge-2 on the WCEP dataset). Extensive experiments further\ndemonstrate the effectiveness of GoR.", "AI": {"tldr": "The paper introduces $\textit{graph of records}$ (GoR) to enhance retrieval-augmented generation (RAG) by leveraging historical LLM responses, improving long-context summarization performance.", "motivation": "Existing RAG approaches discard potentially insightful historical LLM responses, leading to suboptimal results.", "method": "GoR constructs a graph linking retrieved text chunks and LLM responses, using a graph neural network and BERTScore-based objective for self-supervised training.", "result": "GoR outperforms 12 baselines, achieving significant improvements (e.g., 15%, 8%, and 19% on Rouge-L, Rouge-1, and Rouge-2).", "conclusion": "GoR effectively enhances RAG by utilizing historical responses, demonstrating superior performance in long-context summarization."}}
{"id": "2505.22805", "pdf": "https://arxiv.org/pdf/2505.22805", "abs": "https://arxiv.org/abs/2505.22805", "authors": ["Siddharth Ancha", "Sunshine Jiang", "Travis Manderson", "Laura Brandt", "Yilun Du", "Philip R. Osteen", "Nicholas Roy"], "title": "Anomalies by Synthesis: Anomaly Detection using Generative Diffusion Models for Off-Road Navigation", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": "Presented at ICRA 2025", "summary": "In order to navigate safely and reliably in off-road and unstructured\nenvironments, robots must detect anomalies that are out-of-distribution (OOD)\nwith respect to the training data. We present an analysis-by-synthesis approach\nfor pixel-wise anomaly detection without making any assumptions about the\nnature of OOD data. Given an input image, we use a generative diffusion model\nto synthesize an edited image that removes anomalies while keeping the\nremaining image unchanged. Then, we formulate anomaly detection as analyzing\nwhich image segments were modified by the diffusion model. We propose a novel\ninference approach for guided diffusion by analyzing the ideal guidance\ngradient and deriving a principled approximation that bootstraps the diffusion\nmodel to predict guidance gradients. Our editing technique is purely test-time\nthat can be integrated into existing workflows without the need for retraining\nor fine-tuning. Finally, we use a combination of vision-language foundation\nmodels to compare pixels in a learned feature space and detect semantically\nmeaningful edits, enabling accurate anomaly detection for off-road navigation.\nProject website: https://siddancha.github.io/anomalies-by-diffusion-synthesis/", "AI": {"tldr": "The paper proposes a test-time anomaly detection method for off-road robots using a generative diffusion model to edit images and detect anomalies by analyzing modifications.", "motivation": "To enable safe navigation in unstructured environments, robots need to detect out-of-distribution anomalies without prior assumptions about OOD data.", "method": "An analysis-by-synthesis approach using a generative diffusion model to edit images, remove anomalies, and detect them by comparing segments. A novel inference method for guided diffusion is introduced.", "result": "The method detects anomalies by identifying semantically meaningful edits in images, leveraging vision-language models for comparison in a learned feature space.", "conclusion": "The approach is effective for anomaly detection in off-road navigation, requiring no retraining and integrating seamlessly into existing workflows."}}
{"id": "2412.18293", "pdf": "https://arxiv.org/pdf/2412.18293", "abs": "https://arxiv.org/abs/2412.18293", "authors": ["Shaofei Cai", "Zhancun Mu", "Kaichen He", "Bowei Zhang", "Xinyue Zheng", "Anji Liu", "Yitao Liang"], "title": "MineStudio: A Streamlined Package for Minecraft AI Agent Development", "categories": ["cs.AI"], "comment": null, "summary": "Minecraft's complexity and diversity as an open world make it a perfect\nenvironment to test if agents can learn, adapt, and tackle a variety of\nunscripted tasks. However, the development and validation of novel agents in\nthis setting continue to face significant engineering challenges. This paper\npresents MineStudio, an open-source software package designed to streamline the\ndevelopment of autonomous agents in Minecraft. MineStudio represents the first\ncomprehensive integration of seven critical engineering components: simulator,\ndata, model, offline pre-training, online fine-tuning, inference, and\nbenchmark, thereby allowing users to concentrate their efforts on algorithm\ninnovation. We provide a user-friendly API design accompanied by comprehensive\ndocumentation and tutorials. Our project is released at\nhttps://github.com/CraftJarvis/MineStudio.", "AI": {"tldr": "MineStudio is an open-source package for developing autonomous agents in Minecraft, integrating seven key components to simplify the process.", "motivation": "Minecraft's complexity makes it ideal for testing agent adaptability, but engineering challenges hinder development.", "method": "MineStudio integrates simulator, data, model, pre-training, fine-tuning, inference, and benchmark components with a user-friendly API.", "result": "The package streamlines agent development, allowing focus on algorithm innovation.", "conclusion": "MineStudio is released as a comprehensive tool for autonomous agent development in Minecraft."}}
{"id": "2505.23683", "pdf": "https://arxiv.org/pdf/2505.23683", "abs": "https://arxiv.org/abs/2505.23683", "authors": ["Zixuan Wang", "Eshaan Nichani", "Alberto Bietti", "Alex Damian", "Daniel Hsu", "Jason D. Lee", "Denny Wu"], "title": "Learning Compositional Functions with Transformers from Easy-to-Hard Data", "categories": ["cs.LG"], "comment": "COLT 2025", "summary": "Transformer-based language models have demonstrated impressive capabilities\nacross a range of complex reasoning tasks. Prior theoretical work exploring the\nexpressive power of transformers has shown that they can efficiently perform\nmulti-step reasoning tasks involving parallelizable computations. However, the\nlearnability of such constructions, particularly the conditions on the data\ndistribution that enable efficient learning via gradient-based optimization,\nremains an open question. Towards answering this question, in this work we\nstudy the learnability of the $k$-fold composition task, which requires\ncomputing an interleaved composition of $k$ input permutations and $k$ hidden\npermutations, and can be expressed by a transformer with $O(\\log k)$ layers. On\nthe negative front, we prove a Statistical Query (SQ) lower bound showing that\nany SQ learner that makes only polynomially-many queries to an SQ oracle for\nthe $k$-fold composition task distribution must have sample size exponential in\n$k$, thus establishing a statistical-computational gap. On the other hand, we\nshow that this function class can be efficiently learned, with runtime and\nsample complexity polynomial in $k$, by gradient descent on an $O(\\log\nk)$-depth transformer via two different curriculum learning strategies: one in\nwhich data consists of $k'$-fold composition functions with $k' \\le k$\npresented in increasing difficulty, and another in which all such data is\npresented simultaneously. Our work sheds light on the necessity and sufficiency\nof having both easy and hard examples in the data distribution for transformers\nto learn complex compositional tasks.", "AI": {"tldr": "The paper explores the learnability of the $k$-fold composition task by transformers, showing a statistical-computational gap but proving efficient learnability via curriculum strategies.", "motivation": "Understanding the conditions enabling efficient learning of complex reasoning tasks by transformers, given prior theoretical work on their expressive power.", "method": "Study the $k$-fold composition task, prove an SQ lower bound, and demonstrate efficient learning via gradient descent on transformers using two curriculum strategies.", "result": "A statistical-computational gap exists, but the task can be learned efficiently with polynomial runtime and sample complexity via curriculum learning.", "conclusion": "Easy and hard examples in the data distribution are crucial for transformers to learn complex compositional tasks."}}
{"id": "2410.12600", "pdf": "https://arxiv.org/pdf/2410.12600", "abs": "https://arxiv.org/abs/2410.12600", "authors": ["Herun Wan", "Minnan Luo", "Zhixiong Su", "Guang Dai", "Xiang Zhao"], "title": "On the Risk of Evidence Pollution for Malicious Social Text Detection in the Era of LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Evidence-enhanced detectors present remarkable abilities in identifying\nmalicious social text. However, the rise of large language models (LLMs) brings\npotential risks of evidence pollution to confuse detectors. This paper explores\npotential manipulation scenarios including basic pollution, and rephrasing or\ngenerating evidence by LLMs. To mitigate the negative impact, we propose three\ndefense strategies from the data and model sides, including machine-generated\ntext detection, a mixture of experts, and parameter updating. Extensive\nexperiments on four malicious social text detection tasks with ten datasets\nillustrate that evidence pollution significantly compromises detectors, where\nthe generating strategy causes up to a 14.4% performance drop. Meanwhile, the\ndefense strategies could mitigate evidence pollution, but they faced\nlimitations for practical employment. Further analysis illustrates that\npolluted evidence (i) is of high quality, evaluated by metrics and humans; (ii)\nwould compromise the model calibration, increasing expected calibration error\nup to 21.6%; and (iii) could be integrated to amplify the negative impact,\nespecially for encoder-based LMs, where the accuracy drops by 21.8%.", "AI": {"tldr": "The paper investigates how LLMs can pollute evidence for malicious text detectors, proposes three defense strategies, and shows their limitations in mitigating the issue.", "motivation": "To address the risks of evidence pollution by LLMs in malicious social text detection, which can confuse detectors.", "method": "Explores manipulation scenarios (basic pollution, rephrasing, generating evidence) and proposes defenses: machine-generated text detection, mixture of experts, and parameter updating.", "result": "Evidence pollution significantly harms detectors (up to 14.4% performance drop). Defenses help but have practical limitations. Polluted evidence is high-quality, harms model calibration (up to 21.6% error increase), and amplifies negative impacts (21.8% accuracy drop for encoder-based LMs).", "conclusion": "Evidence pollution by LLMs is a serious threat to detectors, and while defenses exist, they are not fully effective, highlighting the need for further research."}}
{"id": "2505.23189", "pdf": "https://arxiv.org/pdf/2505.23189", "abs": "https://arxiv.org/abs/2505.23189", "authors": ["Shaoan Wang", "Jiazhao Zhang", "Minghan Li", "Jiahang Liu", "Anqi Li", "Kui Wu", "Fangwei Zhong", "Junzhi Yu", "Zhizheng Zhang", "He Wang"], "title": "TrackVLA: Embodied Visual Tracking in the Wild", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Embodied visual tracking is a fundamental skill in Embodied AI, enabling an\nagent to follow a specific target in dynamic environments using only egocentric\nvision. This task is inherently challenging as it requires both accurate target\nrecognition and effective trajectory planning under conditions of severe\nocclusion and high scene dynamics. Existing approaches typically address this\nchallenge through a modular separation of recognition and planning. In this\nwork, we propose TrackVLA, a Vision-Language-Action (VLA) model that learns the\nsynergy between object recognition and trajectory planning. Leveraging a shared\nLLM backbone, we employ a language modeling head for recognition and an\nanchor-based diffusion model for trajectory planning. To train TrackVLA, we\nconstruct an Embodied Visual Tracking Benchmark (EVT-Bench) and collect diverse\ndifficulty levels of recognition samples, resulting in a dataset of 1.7 million\nsamples. Through extensive experiments in both synthetic and real-world\nenvironments, TrackVLA demonstrates SOTA performance and strong\ngeneralizability. It significantly outperforms existing methods on public\nbenchmarks in a zero-shot manner while remaining robust to high dynamics and\nocclusion in real-world scenarios at 10 FPS inference speed. Our project page\nis: https://pku-epic.github.io/TrackVLA-web.", "AI": {"tldr": "TrackVLA is a Vision-Language-Action model for embodied visual tracking, combining object recognition and trajectory planning using a shared LLM backbone. It achieves SOTA performance and strong generalizability.", "motivation": "Embodied visual tracking is challenging due to occlusion and dynamic scenes. Existing methods separate recognition and planning, limiting synergy.", "method": "TrackVLA uses a language modeling head for recognition and an anchor-based diffusion model for planning, trained on a 1.7M-sample dataset (EVT-Bench).", "result": "TrackVLA outperforms existing methods in zero-shot settings and handles real-world dynamics and occlusion at 10 FPS.", "conclusion": "TrackVLA demonstrates effective synergy between recognition and planning, achieving robust performance in embodied visual tracking."}}
{"id": "2501.18411", "pdf": "https://arxiv.org/pdf/2501.18411", "abs": "https://arxiv.org/abs/2501.18411", "authors": ["Nolan Koblischke", "Hyunseok Jang", "Kristen Menou", "Mohamad Ali-Dib"], "title": "Gravity-Bench-v1: A Benchmark on Gravitational Physics Discovery for Agents", "categories": ["cs.AI", "astro-ph.IM", "physics.comp-ph"], "comment": "Accepted at ICML 2025", "summary": "Modern science emerged from reasoning over repeatedly-observed planetary\nmotions. We present Gravity-Bench-v1, an environment-based benchmark that\nchallenges AI agents on tasks that parallel this historical development.\nGravity-Bench-v1 evaluates agents on the discovery of physics concealed within\na dynamic environment, using rigorous gravitational dynamics simulations.\nGravity-Bench includes out-of-distribution cases, i.e. with physics that\ndeviates from the real world, to evaluate true scientific generalization\ncapabilities. Agents must plan to collect data within an experimental budget\nand must perform a dynamic form of data analysis and reasoning to solve tasks\nefficiently. Our benchmark admits an open-ended space of solutions. Reference\nsolutions for each task are provided to calibrate AI performance against human\nexpertise. Technically at an upper-undergraduate level, our benchmark proves\nchallenging to baseline AI agents. Gravity-Bench-v1 and planned extensions\nshould help map out AI progress towards scientific discovery capabilities.", "AI": {"tldr": "Gravity-Bench-v1 is a benchmark for AI agents to discover physics in dynamic environments, including out-of-distribution cases, to test scientific generalization.", "motivation": "To parallel the historical development of modern science by challenging AI agents with tasks involving gravitational dynamics and scientific reasoning.", "method": "Uses rigorous gravitational dynamics simulations, out-of-distribution cases, and requires agents to plan data collection and perform dynamic analysis.", "result": "The benchmark is challenging for baseline AI agents and includes reference solutions for performance calibration.", "conclusion": "Gravity-Bench-v1 and future extensions aim to track AI progress in scientific discovery capabilities."}}
{"id": "2505.23696", "pdf": "https://arxiv.org/pdf/2505.23696", "abs": "https://arxiv.org/abs/2505.23696", "authors": ["Hiroshi Kera", "Nico Pelleriti", "Yuki Ishihara", "Max Zimmer", "Sebastian Pokutta"], "title": "Computational Algebra with Attention: Transformer Oracles for Border Basis Algorithms", "categories": ["cs.LG", "cs.SC"], "comment": "13+19 pages (3+9 figures, 2+7 tables)", "summary": "Solving systems of polynomial equations, particularly those with finitely\nmany solutions, is a crucial challenge across many scientific fields.\nTraditional methods like Gr\\\"obner and Border bases are fundamental but suffer\nfrom high computational costs, which have motivated recent Deep Learning\napproaches to improve efficiency, albeit at the expense of output correctness.\nIn this work, we introduce the Oracle Border Basis Algorithm, the first Deep\nLearning approach that accelerates Border basis computation while maintaining\noutput guarantees. To this end, we design and train a Transformer-based oracle\nthat identifies and eliminates computationally expensive reduction steps, which\nwe find to dominate the algorithm's runtime. By selectively invoking this\noracle during critical phases of computation, we achieve substantial speedup\nfactors of up to 3.5x compared to the base algorithm, without compromising the\ncorrectness of results. To generate the training data, we develop a sampling\nmethod and provide the first sampling theorem for border bases. We construct a\ntokenization and embedding scheme tailored to monomial-centered algebraic\ncomputations, resulting in a compact and expressive input representation, which\nreduces the number of tokens to encode an $n$-variate polynomial by a factor of\n$O(n)$. Our learning approach is data efficient, stable, and a practical\nenhancement to traditional computer algebra algorithms and symbolic\ncomputation.", "AI": {"tldr": "The paper introduces the Oracle Border Basis Algorithm, a Deep Learning approach that accelerates Border basis computation while ensuring correctness, achieving up to 3.5x speedup.", "motivation": "Traditional methods like Gr\u00f6bner and Border bases are computationally expensive, prompting the need for efficient alternatives without sacrificing correctness.", "method": "A Transformer-based oracle is trained to eliminate costly reduction steps, combined with a tailored tokenization and embedding scheme for efficient polynomial representation.", "result": "The algorithm achieves up to 3.5x speedup over the base method while maintaining correctness, supported by a novel sampling theorem and data-efficient learning.", "conclusion": "The Oracle Border Basis Algorithm is a practical, stable enhancement to traditional symbolic computation, balancing efficiency and correctness."}}
{"id": "2410.12974", "pdf": "https://arxiv.org/pdf/2410.12974", "abs": "https://arxiv.org/abs/2410.12974", "authors": ["Anna Sokol", "Elizabeth Daly", "Michael Hind", "David Piorkowski", "Xiangliang Zhang", "Nuno Moniz", "Nitesh Chawla"], "title": "BenchmarkCards: Large Language Model and Risk Reporting", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) are powerful tools capable of handling diverse\ntasks. Comparing and selecting appropriate LLMs for specific tasks requires\nsystematic evaluation methods, as models exhibit varying capabilities across\ndifferent domains. However, finding suitable benchmarks is difficult given the\nmany available options. This complexity not only increases the risk of\nbenchmark misuse and misinterpretation but also demands substantial effort from\nLLM users, seeking the most suitable benchmarks for their specific needs. To\naddress these issues, we introduce \\texttt{BenchmarkCards}, an intuitive and\nvalidated documentation framework that standardizes critical benchmark\nattributes such as objectives, methodologies, data sources, and limitations.\nThrough user studies involving benchmark creators and users, we show that\n\\texttt{BenchmarkCards} can simplify benchmark selection and enhance\ntransparency, facilitating informed decision-making in evaluating LLMs. Data &\nCode: https://github.com/SokolAnn/BenchmarkCards", "AI": {"tldr": "The paper introduces BenchmarkCards, a framework to standardize and simplify the selection of benchmarks for evaluating large language models (LLMs).", "motivation": "The challenge of selecting appropriate benchmarks for LLMs due to their diversity and the risk of misuse or misinterpretation.", "method": "Proposes BenchmarkCards, a documentation framework standardizing benchmark attributes like objectives, methodologies, and limitations, validated through user studies.", "result": "BenchmarkCards simplifies benchmark selection and improves transparency, aiding informed decision-making in LLM evaluation.", "conclusion": "BenchmarkCards effectively addresses the complexity of benchmark selection for LLMs, enhancing usability and clarity."}}
{"id": "2505.23301", "pdf": "https://arxiv.org/pdf/2505.23301", "abs": "https://arxiv.org/abs/2505.23301", "authors": ["Rim Rekik", "Stefanie Wuhrer", "Ludovic Hoyet", "Katja Zibrek", "Anne-H\u00e9l\u00e8ne Olivier"], "title": "Quality assessment of 3D human animation: Subjective and objective evaluation", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Virtual human animations have a wide range of applications in virtual and\naugmented reality. While automatic generation methods of animated virtual\nhumans have been developed, assessing their quality remains challenging.\nRecently, approaches introducing task-oriented evaluation metrics have been\nproposed, leveraging neural network training. However, quality assessment\nmeasures for animated virtual humans that are not generated with parametric\nbody models have yet to be developed. In this context, we introduce a first\nsuch quality assessment measure leveraging a novel data-driven framework.\nFirst, we generate a dataset of virtual human animations together with their\ncorresponding subjective realism evaluation scores collected with a user study.\nSecond, we use the resulting dataset to learn predicting perceptual evaluation\nscores. Results indicate that training a linear regressor on our dataset\nresults in a correlation of 90%, which outperforms a state of the art deep\nlearning baseline.", "AI": {"tldr": "A data-driven framework for assessing the quality of non-parametric virtual human animations, achieving 90% correlation with human evaluations.", "motivation": "Existing quality assessment methods for virtual human animations focus on parametric models, leaving non-parametric animations unaddressed.", "method": "A dataset of animations with subjective realism scores is created, and a linear regressor is trained to predict perceptual scores.", "result": "The linear regressor achieves 90% correlation with human evaluations, outperforming a deep learning baseline.", "conclusion": "The proposed framework effectively assesses non-parametric virtual human animation quality, filling a gap in current methods."}}
{"id": "2501.19318", "pdf": "https://arxiv.org/pdf/2501.19318", "abs": "https://arxiv.org/abs/2501.19318", "authors": ["Anirudh Chari", "Suraj Reddy", "Aditya Tiwari", "Richard Lian", "Brian Zhou"], "title": "MINDSTORES: Memory-Informed Neural Decision Synthesis for Task-Oriented Reinforcement in Embodied Systems", "categories": ["cs.AI"], "comment": null, "summary": "While large language models (LLMs) have shown promising capabilities as\nzero-shot planners for embodied agents, their inability to learn from\nexperience and build persistent mental models limits their robustness in\ncomplex open-world environments like Minecraft. We introduce MINDSTORES, an\nexperience-augmented planning framework that enables embodied agents to build\nand leverage mental models through natural interaction with their environment.\nDrawing inspiration from how humans construct and refine cognitive mental\nmodels, our approach extends existing zero-shot LLM planning by maintaining a\ndatabase of past experiences that informs future planning iterations. The key\ninnovation is representing accumulated experiences as natural language\nembeddings of (state, task, plan, outcome) tuples, which can then be\nefficiently retrieved and reasoned over by an LLM planner to generate insights\nand guide plan refinement for novel states and tasks. Through extensive\nexperiments in the MineDojo environment, a simulation environment for agents in\nMinecraft that provides low-level controls for Minecraft, we find that\nMINDSTORES learns and applies its knowledge significantly better than existing\nmemory-based LLM planners while maintaining the flexibility and generalization\nbenefits of zero-shot approaches, representing an important step toward more\ncapable embodied AI systems that can learn continuously through natural\nexperience.", "AI": {"tldr": "MINDSTORES enhances LLM-based planning for embodied agents by using past experiences to refine mental models, improving robustness in complex environments like Minecraft.", "motivation": "LLMs lack the ability to learn from experience, limiting their effectiveness in open-world environments. MINDSTORES addresses this by enabling agents to build and leverage persistent mental models.", "method": "The framework maintains a database of past experiences as natural language embeddings (state, task, plan, outcome), which an LLM planner retrieves and reasons over for plan refinement.", "result": "Experiments in MineDojo show MINDSTORES outperforms memory-based LLM planners in learning and applying knowledge while retaining zero-shot flexibility.", "conclusion": "MINDSTORES advances embodied AI by enabling continuous learning through natural experience, improving planning robustness."}}
{"id": "2505.23700", "pdf": "https://arxiv.org/pdf/2505.23700", "abs": "https://arxiv.org/abs/2505.23700", "authors": ["Oleksii Furman", "Ulvi Movsum-zada", "Patryk Marszalek", "Maciej Zi\u0119ba", "Marek \u015amieja"], "title": "DiCoFlex: Model-agnostic diverse counterfactuals with flexible control", "categories": ["cs.LG"], "comment": null, "summary": "Counterfactual explanations play a pivotal role in explainable artificial\nintelligence (XAI) by offering intuitive, human-understandable alternatives\nthat elucidate machine learning model decisions. Despite their significance,\nexisting methods for generating counterfactuals often require constant access\nto the predictive model, involve computationally intensive optimization for\neach instance and lack the flexibility to adapt to new user-defined constraints\nwithout retraining. In this paper, we propose DiCoFlex, a novel model-agnostic,\nconditional generative framework that produces multiple diverse counterfactuals\nin a single forward pass. Leveraging conditional normalizing flows trained\nsolely on labeled data, DiCoFlex addresses key limitations by enabling\nreal-time user-driven customization of constraints such as sparsity and\nactionability at inference time. Extensive experiments on standard benchmark\ndatasets show that DiCoFlex outperforms existing methods in terms of validity,\ndiversity, proximity, and constraint adherence, making it a practical and\nscalable solution for counterfactual generation in sensitive decision-making\ndomains.", "AI": {"tldr": "DiCoFlex is a model-agnostic, conditional generative framework for diverse counterfactual explanations, addressing limitations of existing methods by enabling real-time customization and outperforming benchmarks.", "motivation": "Existing counterfactual explanation methods are computationally intensive, inflexible, and require constant model access, limiting their practicality.", "method": "DiCoFlex uses conditional normalizing flows trained on labeled data to generate diverse counterfactuals in a single forward pass, allowing real-time constraint customization.", "result": "DiCoFlex outperforms existing methods in validity, diversity, proximity, and constraint adherence on benchmark datasets.", "conclusion": "DiCoFlex offers a scalable, practical solution for counterfactual generation in sensitive domains."}}
{"id": "2410.16502", "pdf": "https://arxiv.org/pdf/2410.16502", "abs": "https://arxiv.org/abs/2410.16502", "authors": ["Jason Chan", "Robert Gaizauskas", "Zhixue Zhao"], "title": "RULEBREAKERS: Challenging LLMs at the Crossroads between Formal Logic and Human-like Reasoning", "categories": ["cs.CL"], "comment": "Preprint. Accepted by ICML 2025", "summary": "Formal logic enables computers to reason in natural language by representing\nsentences in symbolic forms and applying rules to derive conclusions. However,\nin what our study characterizes as \"rulebreaker\" scenarios, this method can\nlead to conclusions that are typically not inferred or accepted by humans given\ntheir common sense and factual knowledge. Inspired by works in cognitive\nscience, we create RULEBREAKERS, the first dataset for rigorously evaluating\nthe ability of large language models (LLMs) to recognize and respond to\nrulebreakers (versus non-rulebreakers) in a human-like manner. Evaluating seven\nLLMs, we find that most models, including GPT-4o, achieve mediocre accuracy on\nRULEBREAKERS and exhibit some tendency to over-rigidly apply logical rules\nunlike what is expected from typical human reasoners. Further analysis suggests\nthat this apparent failure is potentially associated with the models' poor\nutilization of their world knowledge and their attention distribution patterns.\nWhilst revealing a limitation of current LLMs, our study also provides a timely\ncounterbalance to a growing body of recent works that propose methods relying\non formal logic to improve LLMs' general reasoning capabilities, highlighting\ntheir risk of further increasing divergence between LLMs and human-like\nreasoning.", "AI": {"tldr": "The paper introduces RULEBREAKERS, a dataset to evaluate LLMs' ability to handle rulebreaker scenarios, finding most models, including GPT-4o, perform poorly due to over-rigid logic application and poor world knowledge utilization.", "motivation": "To address the gap in evaluating LLMs' human-like reasoning in rulebreaker scenarios, where formal logic often fails to align with human common sense.", "method": "Creation of the RULEBREAKERS dataset and evaluation of seven LLMs, including GPT-4o, to assess their performance in recognizing and responding to rulebreakers.", "result": "Most LLMs achieve mediocre accuracy, over-applying logical rules and underutilizing world knowledge, diverging from human-like reasoning.", "conclusion": "Current LLMs struggle with rulebreaker scenarios, highlighting risks in relying solely on formal logic for improving reasoning, as it may widen the gap between AI and human-like reasoning."}}
{"id": "2505.23317", "pdf": "https://arxiv.org/pdf/2505.23317", "abs": "https://arxiv.org/abs/2505.23317", "authors": ["Woojin Shin", "Donghwa Kang", "Byeongyun Park", "Brent Byunghoon Kang", "Jinkyu Lee", "Hyeongboo Baek"], "title": "CF-DETR: Coarse-to-Fine Transformer for Real-Time Object Detection", "categories": ["eess.SY", "cs.CV", "cs.SY"], "comment": "12 pages", "summary": "Detection Transformers (DETR) are increasingly adopted in autonomous vehicle\n(AV) perception systems due to their superior accuracy over convolutional\nnetworks. However, concurrently executing multiple DETR tasks presents\nsignificant challenges in meeting firm real-time deadlines (R1) and high\naccuracy requirements (R2), particularly for safety-critical objects, while\nnavigating the inherent latency-accuracy trade-off under resource constraints.\nExisting real-time DNN scheduling approaches often treat models generically,\nfailing to leverage Transformer-specific properties for efficient resource\nallocation. To address these challenges, we propose CF-DETR, an integrated\nsystem featuring a novel coarse-to-fine Transformer architecture and a\ndedicated real-time scheduling framework NPFP**. CF-DETR employs three key\nstrategies (A1: coarse-to-fine inference, A2: selective fine inference, A3:\nmulti-level batch inference) that exploit Transformer properties to dynamically\nadjust patch granularity and attention scope based on object criticality,\naiming to satisfy R2. The NPFP** scheduling framework (A4) orchestrates these\nadaptive mechanisms A1-A3. It partitions each DETR task into a safety-critical\ncoarse subtask for guaranteed critical object detection within its deadline\n(ensuring R1), and an optional fine subtask for enhanced overall accuracy (R2),\nwhile managing individual and batched execution. Our extensive evaluations on\nserver, GPU-enabled embedded platforms, and actual AV platforms demonstrate\nthat CF-DETR, under an NPFP** policy, successfully meets strict timing\nguarantees for critical operations and achieves significantly higher overall\nand critical object detection accuracy compared to existing baselines across\ndiverse AV workloads.", "AI": {"tldr": "CF-DETR is a system combining a coarse-to-fine Transformer architecture and a real-time scheduler (NPFP**) to meet real-time and accuracy demands in autonomous vehicle perception.", "motivation": "Addressing the challenges of executing multiple DETR tasks under real-time constraints and high accuracy requirements for safety-critical objects.", "method": "Uses coarse-to-fine inference, selective fine inference, and multi-level batch inference, orchestrated by the NPFP** scheduler.", "result": "Meets strict timing guarantees and achieves higher detection accuracy compared to baselines.", "conclusion": "CF-DETR effectively balances latency and accuracy for AV perception systems."}}
{"id": "2502.06152", "pdf": "https://arxiv.org/pdf/2502.06152", "abs": "https://arxiv.org/abs/2502.06152", "authors": ["Ziyang Guo", "Yifan Wu", "Jason Hartline", "Jessica Hullman"], "title": "The Value of Information in Human-AI Decision-making", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Multiple agents -- including humans and AI models -- are increasingly\ncombined to make decisions with the expectation of achieving complementary\nperformance, where the decisions they make together outperform those made\nindividually. However, knowing how to improve the performance of collaborating\nagents is often difficult without knowing more about what particular\ninformation and strategies each agent employs. With a focus on human-AI\npairings, we contribute a decision-theoretic framework for characterizing the\nvalue of information -- and consequently, opportunities for agents to better\nexploit available information -- in AI-assisted decision workflows. We present\na novel explanation technique (ILIV-SHAP) that adapts SHAP explanations to\nhighlight human-complementing information. We validate the effectiveness of the\nframework and ILIV-SHAP through a study of human-AI decision-making. We show\nthat our measure of complementary information can be used to identify which AI\nmodel will best complement human decisions. We also find that presenting\nILIV-SHAP with AI predictions leads to reliably greater reductions in error\nover non-AI assisted decisions more than vanilla SHAP.", "AI": {"tldr": "The paper introduces a decision-theoretic framework and a novel explanation technique (ILIV-SHAP) to improve human-AI collaboration by identifying complementary information. It validates the approach through a study, showing better error reduction compared to non-AI and vanilla SHAP methods.", "motivation": "To enhance collaborative decision-making between humans and AI by understanding and leveraging complementary information and strategies.", "method": "Develops a decision-theoretic framework and ILIV-SHAP, an adapted SHAP explanation technique, to highlight human-complementing information. Validates through a human-AI decision-making study.", "result": "Demonstrates that the framework can identify AI models that best complement human decisions and that ILIV-SHAP reduces errors more effectively than vanilla SHAP.", "conclusion": "The proposed framework and ILIV-SHAP technique effectively improve human-AI collaboration by focusing on complementary information, leading to better decision outcomes."}}
{"id": "2505.23702", "pdf": "https://arxiv.org/pdf/2505.23702", "abs": "https://arxiv.org/abs/2505.23702", "authors": ["Nathan Lichtl\u00e9", "Alexi Canesse", "Zhe Fu", "Hossein Nick Zinat Matin", "Maria Laura Delle Monache", "Alexandre M. Bayen"], "title": "(U)NFV: Supervised and Unsupervised Neural Finite Volume Methods for Solving Hyperbolic PDEs", "categories": ["cs.LG", "cs.NA", "math.NA", "I.2.6; G.1.8"], "comment": null, "summary": "We introduce (U)NFV, a modular neural network architecture that generalizes\nclassical finite volume (FV) methods for solving hyperbolic conservation laws.\nHyperbolic partial differential equations (PDEs) are challenging to solve,\nparticularly conservation laws whose physically relevant solutions contain\nshocks and discontinuities. FV methods are widely used for their mathematical\nproperties: convergence to entropy solutions, flow conservation, or total\nvariation diminishing, but often lack accuracy and flexibility in complex\nsettings. Neural Finite Volume addresses these limitations by learning update\nrules over extended spatial and temporal stencils while preserving conservation\nstructure. It supports both supervised training on solution data (NFV) and\nunsupervised training via weak-form residual loss (UNFV). Applied to\nfirst-order conservation laws, (U)NFV achieves up to 10x lower error than\nGodunov's method, outperforms ENO/WENO, and rivals discontinuous Galerkin\nsolvers with far less complexity. On traffic modeling problems, both from PDEs\nand from experimental highway data, (U)NFV captures nonlinear wave dynamics\nwith significantly higher fidelity and scalability than traditional FV\napproaches.", "AI": {"tldr": "(U)NFV is a neural network architecture improving finite volume methods for hyperbolic conservation laws, achieving lower error and better scalability.", "motivation": "Hyperbolic PDEs are hard to solve, especially with shocks/discontinuities. Traditional FV methods lack accuracy and flexibility.", "method": "(U)NFV learns update rules over extended stencils, preserving conservation. Supports supervised (NFV) and unsupervised (UNFV) training.", "result": "Achieves 10x lower error than Godunov's method, outperforms ENO/WENO, and rivals discontinuous Galerkin with less complexity.", "conclusion": "(U)NFV offers higher fidelity and scalability for hyperbolic conservation laws, especially in traffic modeling."}}
{"id": "2412.04141", "pdf": "https://arxiv.org/pdf/2412.04141", "abs": "https://arxiv.org/abs/2412.04141", "authors": ["Hongshen Xu", "Zichen Zhu", "Lei Pan", "Zihan Wang", "Su Zhu", "Da Ma", "Ruisheng Cao", "Lu Chen", "Kai Yu"], "title": "Reducing Tool Hallucination via Reliability Alignment", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have expanded their capabilities beyond language\ngeneration to interact with external tools, enabling automation and real-world\napplications. However, tool hallucinations, where models either select\ninappropriate tools or misuse them, pose significant challenges, leading to\nerroneous task execution, increased computational costs, and reduced system\nreliability. To systematically address this issue, we define and categorize\ntool hallucinations into two main types, tool selection hallucination and tool\nusage hallucination. To evaluate and mitigate these issues, we introduce\nRelyToolBench, which integrates specialized test cases and novel metrics to\nassess hallucination-aware task success and efficiency. Finally, we propose\nRelign, a reliability alignment framework that expands the tool-use action\nspace to include indecisive actions, allowing LLMs to defer tool use, seek\nclarification, or adjust tool selection dynamically. Through extensive\nexperiments, we demonstrate that Relign significantly reduces tool\nhallucinations, improves task reliability, and enhances the efficiency of LLM\ntool interactions.", "AI": {"tldr": "The paper addresses tool hallucinations in LLMs, categorizing them into selection and usage types, and introduces RelyToolBench and Relign to evaluate and mitigate these issues, improving reliability and efficiency.", "motivation": "Tool hallucinations in LLMs lead to errors, higher costs, and reduced reliability, necessitating systematic solutions.", "method": "Defines tool hallucinations, introduces RelyToolBench for evaluation, and proposes Relign, a framework with indecisive actions to mitigate hallucinations.", "result": "Relign reduces tool hallucinations, improves task reliability, and enhances efficiency in LLM tool interactions.", "conclusion": "The proposed methods effectively address tool hallucinations, enhancing the reliability and efficiency of LLM tool use."}}
{"id": "2505.23612", "pdf": "https://arxiv.org/pdf/2505.23612", "abs": "https://arxiv.org/abs/2505.23612", "authors": ["Jianbo Zhao", "Taiyu Ban", "Xiyang Wang", "Qibin Zhou", "Hangning Zhou", "Zhihao Liu", "Mu Yang", "Lei Liu", "Bin Li"], "title": "Autoregressive Meta-Actions for Unified Controllable Trajectory Generation", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Controllable trajectory generation guided by high-level semantic decisions,\ntermed meta-actions, is crucial for autonomous driving systems. A significant\nlimitation of existing frameworks is their reliance on invariant meta-actions\nassigned over fixed future time intervals, causing temporal misalignment with\nthe actual behavior trajectories. This misalignment leads to irrelevant\nassociations between the prescribed meta-actions and the resulting\ntrajectories, disrupting task coherence and limiting model performance. To\naddress this challenge, we introduce Autoregressive Meta-Actions, an approach\nintegrated into autoregressive trajectory generation frameworks that provides a\nunified and precise definition for meta-action-conditioned trajectory\nprediction. Specifically, We decompose traditional long-interval meta-actions\ninto frame-level meta-actions, enabling a sequential interplay between\nautoregressive meta-action prediction and meta-action-conditioned trajectory\ngeneration. This decomposition ensures strict alignment between each trajectory\nsegment and its corresponding meta-action, achieving a consistent and unified\ntask formulation across the entire trajectory span and significantly reducing\ncomplexity. Moreover, we propose a staged pre-training process to decouple the\nlearning of basic motion dynamics from the integration of high-level decision\ncontrol, which offers flexibility, stability, and modularity. Experimental\nresults validate our framework's effectiveness, demonstrating improved\ntrajectory adaptivity and responsiveness to dynamic decision-making scenarios.\nWe provide the video document and dataset, which are available at\nhttps://arma-traj.github.io/.", "AI": {"tldr": "The paper introduces Autoregressive Meta-Actions to improve trajectory generation in autonomous driving by aligning frame-level meta-actions with trajectory segments, enhancing coherence and performance.", "motivation": "Existing frameworks suffer from temporal misalignment between meta-actions and trajectories, disrupting task coherence and limiting model performance.", "method": "Decomposes long-interval meta-actions into frame-level ones, integrating them into autoregressive trajectory generation. Includes staged pre-training for motion dynamics and decision control.", "result": "Improved trajectory adaptivity and responsiveness in dynamic decision-making scenarios, validated experimentally.", "conclusion": "The proposed approach ensures strict alignment between meta-actions and trajectories, reducing complexity and enhancing performance."}}
{"id": "2502.14400", "pdf": "https://arxiv.org/pdf/2502.14400", "abs": "https://arxiv.org/abs/2502.14400", "authors": ["Xiandong Zou", "Wanyu Lin", "Yuchen Li", "Pan Zhou"], "title": "HPS: Hard Preference Sampling for Human Preference Alignment", "categories": ["cs.AI"], "comment": null, "summary": "Aligning Large Language Model (LLM) responses with human preferences is vital\nfor building safe and controllable AI systems. While preference optimization\nmethods based on Plackett-Luce (PL) and Bradley-Terry (BT) models have shown\npromise, they face challenges such as poor handling of harmful content,\ninefficient use of dispreferred responses, and, specifically for PL, high\ncomputational costs. To address these issues, we propose Hard Preference\nSampling (HPS), a novel framework for robust and efficient human preference\nalignment. HPS introduces a training loss that prioritizes the most preferred\nresponse while rejecting all dispreferred and harmful ones. It emphasizes\n\"hard\" dispreferred responses -- those closely resembling preferred ones -- to\nenhance the model's rejection capabilities. By leveraging a single-sample Monte\nCarlo sampling strategy, HPS reduces computational overhead while maintaining\nalignment quality. Theoretically, HPS improves sample efficiency over existing\nPL methods and maximizes the reward margin between preferred and dispreferred\nresponses, ensuring clearer distinctions. Experiments on HH-RLHF and PKU-Safety\ndatasets validate HPS's effectiveness, achieving comparable BLEU and reward\nscores while greatly improving reward margins and thus reducing harmful content\ngeneration.", "AI": {"tldr": "HPS is a new framework for aligning LLM responses with human preferences, focusing on rejecting harmful and dispreferred responses efficiently.", "motivation": "Existing methods like PL and BT struggle with harmful content, inefficiency, and high computational costs.", "method": "HPS uses a training loss prioritizing preferred responses and rejecting harmful ones, with a focus on 'hard' dispreferred responses. It employs Monte Carlo sampling for efficiency.", "result": "HPS improves reward margins and reduces harmful content, matching BLEU and reward scores of existing methods.", "conclusion": "HPS offers a robust and efficient solution for human preference alignment in LLMs."}}
{"id": "2505.23705", "pdf": "https://arxiv.org/pdf/2505.23705", "abs": "https://arxiv.org/abs/2505.23705", "authors": ["Danny Driess", "Jost Tobias Springenberg", "Brian Ichter", "Lili Yu", "Adrian Li-Bell", "Karl Pertsch", "Allen Z. Ren", "Homer Walke", "Quan Vuong", "Lucy Xiaoyang Shi", "Sergey Levine"], "title": "Knowledge Insulating Vision-Language-Action Models: Train Fast, Run Fast, Generalize Better", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "Vision-language-action (VLA) models provide a powerful approach to training\ncontrol policies for physical systems, such as robots, by combining end-to-end\nlearning with transfer of semantic knowledge from web-scale vision-language\nmodel (VLM) training. However, the constraints of real-time control are often\nat odds with the design of VLMs: the most powerful VLMs have tens or hundreds\nof billions of parameters, presenting an obstacle to real-time inference, and\noperate on discrete tokens rather than the continuous-valued outputs that are\nrequired for controlling robots. To address this challenge, recent VLA models\nhave used specialized modules for efficient continuous control, such as action\nexperts or continuous output heads, which typically require adding new\nuntrained parameters to the pretrained VLM backbone. While these modules\nimprove real-time and control capabilities, it remains an open question whether\nthey preserve or degrade the semantic knowledge contained in the pretrained\nVLM, and what effect they have on the VLA training dynamics. In this paper, we\nstudy this question in the context of VLAs that include a continuous diffusion\nor flow matching action expert, showing that naively including such experts\nsignificantly harms both training speed and knowledge transfer. We provide an\nextensive analysis of various design choices, their impact on performance and\nknowledge transfer, and propose a technique for insulating the VLM backbone\nduring VLA training that mitigates this issue. Videos are available at\nhttps://pi.website/research/knowledge_insulation.", "AI": {"tldr": "VLA models combine vision-language models (VLMs) with control policies for robots, but face challenges in real-time control due to VLMs' size and token-based outputs. Specialized modules like action experts help but may degrade VLM knowledge. This paper analyzes the impact of such modules and proposes a solution.", "motivation": "To address the conflict between powerful VLMs and real-time robot control, ensuring efficient control without losing semantic knowledge from pretrained VLMs.", "method": "Study VLAs with continuous diffusion or flow matching action experts, analyze design choices, and propose a technique to insulate the VLM backbone during training.", "result": "Naively including action experts harms training speed and knowledge transfer. The proposed insulation technique mitigates these issues.", "conclusion": "The paper highlights the trade-offs in VLA design and offers a solution to preserve VLM knowledge while enabling efficient control."}}
{"id": "2412.04947", "pdf": "https://arxiv.org/pdf/2412.04947", "abs": "https://arxiv.org/abs/2412.04947", "authors": ["Yanyang Li", "Tin Long Wong", "Cheung To Hung", "Jianqiao Zhao", "Duo Zheng", "Ka Wai Liu", "Michael R. Lyu", "Liwei Wang"], "title": "C$^2$LEVA: Toward Comprehensive and Contamination-Free Language Model Evaluation", "categories": ["cs.CL"], "comment": "Findings of ACL 2025; Project Page:\n  https://github.com/LaVi-Lab/C2LEVA", "summary": "Recent advances in large language models (LLMs) have shown significant\npromise, yet their evaluation raises concerns, particularly regarding data\ncontamination due to the lack of access to proprietary training data. To\naddress this issue, we present C$^2$LEVA, a comprehensive bilingual benchmark\nfeaturing systematic contamination prevention. C$^2$LEVA firstly offers a\nholistic evaluation encompassing 22 tasks, each targeting a specific\napplication or ability of LLMs, and secondly a trustworthy assessment due to\nour contamination-free tasks, ensured by a systematic contamination prevention\nstrategy that fully automates test data renewal and enforces data protection\nduring benchmark data release. Our large-scale evaluation of 15 open-source and\nproprietary models demonstrates the effectiveness of C$^2$LEVA.", "AI": {"tldr": "C$^2$LEVA is a bilingual benchmark for evaluating LLMs with contamination-free tasks and automated data renewal.", "motivation": "Address concerns about data contamination in LLM evaluation by providing a trustworthy benchmark.", "method": "Introduces C$^2$LEVA, featuring 22 tasks and a systematic contamination prevention strategy.", "result": "Effectiveness demonstrated through large-scale evaluation of 15 models.", "conclusion": "C$^2$LEVA offers a reliable and comprehensive solution for LLM evaluation."}}
{"id": "2505.23692", "pdf": "https://arxiv.org/pdf/2505.23692", "abs": "https://arxiv.org/abs/2505.23692", "authors": ["Jingyun Yang", "Isabella Huang", "Brandon Vu", "Max Bajracharya", "Rika Antonova", "Jeannette Bohg"], "title": "Mobi-$\u03c0$: Mobilizing Your Robot Learning Policy", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": "Project website: https://mobipi.github.io/", "summary": "Learned visuomotor policies are capable of performing increasingly complex\nmanipulation tasks. However, most of these policies are trained on data\ncollected from limited robot positions and camera viewpoints. This leads to\npoor generalization to novel robot positions, which limits the use of these\npolicies on mobile platforms, especially for precise tasks like pressing\nbuttons or turning faucets. In this work, we formulate the policy mobilization\nproblem: find a mobile robot base pose in a novel environment that is in\ndistribution with respect to a manipulation policy trained on a limited set of\ncamera viewpoints. Compared to retraining the policy itself to be more robust\nto unseen robot base pose initializations, policy mobilization decouples\nnavigation from manipulation and thus does not require additional\ndemonstrations. Crucially, this problem formulation complements existing\nefforts to improve manipulation policy robustness to novel viewpoints and\nremains compatible with them. To study policy mobilization, we introduce the\nMobi-$\\pi$ framework, which includes: (1) metrics that quantify the difficulty\nof mobilizing a given policy, (2) a suite of simulated mobile manipulation\ntasks based on RoboCasa to evaluate policy mobilization, (3) visualization\ntools for analysis, and (4) several baseline methods. We also propose a novel\napproach that bridges navigation and manipulation by optimizing the robot's\nbase pose to align with an in-distribution base pose for a learned policy. Our\napproach utilizes 3D Gaussian Splatting for novel view synthesis, a score\nfunction to evaluate pose suitability, and sampling-based optimization to\nidentify optimal robot poses. We show that our approach outperforms baselines\nin both simulation and real-world environments, demonstrating its effectiveness\nfor policy mobilization.", "AI": {"tldr": "The paper introduces the policy mobilization problem, addressing poor generalization of visuomotor policies to novel robot positions. It proposes the Mobi-\u03c0 framework and a novel approach for optimizing robot base poses, outperforming baselines.", "motivation": "Existing visuomotor policies struggle with generalization to new robot positions, limiting their use on mobile platforms for precise tasks.", "method": "The Mobi-\u03c0 framework includes metrics, simulated tasks, visualization tools, and baseline methods. A novel approach optimizes robot base poses using 3D Gaussian Splatting, a score function, and sampling-based optimization.", "result": "The proposed approach outperforms baselines in simulation and real-world environments, proving effective for policy mobilization.", "conclusion": "Policy mobilization decouples navigation from manipulation, enhancing generalization without additional training data, and complements existing robustness efforts."}}
{"id": "2502.17541", "pdf": "https://arxiv.org/pdf/2502.17541", "abs": "https://arxiv.org/abs/2502.17541", "authors": ["Michal Bravansky", "Vaclav Kubon", "Suhas Hariharan", "Robert Kirk"], "title": "Dataset Featurization: Uncovering Natural Language Features through Unsupervised Data Reconstruction", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Interpreting data is central to modern research. Large language models (LLMs)\nshow promise in providing such natural language interpretations of data, yet\nsimple feature extraction methods such as prompting often fail to produce\naccurate and versatile descriptions for diverse datasets and lack control over\ngranularity and scale. To address these limitations, we propose a\ndomain-agnostic method for dataset featurization that provides precise control\nover the number of features extracted while maintaining compact and descriptive\nrepresentations comparable to human labeling. Our method optimizes the\nselection of informative binary features by evaluating the ability of an LLM to\nreconstruct the original data using those features. We demonstrate its\neffectiveness in dataset modeling tasks and through two case studies: (1)\nConstructing a feature representation of jailbreak tactics that compactly\ncaptures both the effectiveness and diversity of a larger set of human-crafted\nattacks; and (2) automating the discovery of features that align with human\npreferences, achieving accuracy and robustness comparable to human-crafted\nfeatures. Moreover, we show that the pipeline scales effectively, improving as\nadditional features are sampled, making it suitable for large and diverse\ndatasets.", "AI": {"tldr": "A domain-agnostic method for dataset featurization using LLMs is proposed, offering precise control over feature extraction and maintaining human-like descriptive accuracy.", "motivation": "Addressing the limitations of simple feature extraction methods like prompting, which often fail to produce accurate, versatile, and controlled descriptions for diverse datasets.", "method": "Optimizes binary feature selection by evaluating an LLM's ability to reconstruct original data using those features.", "result": "Effective in dataset modeling, demonstrated through case studies on jailbreak tactics and human-aligned feature discovery, with scalable performance.", "conclusion": "The method provides robust, scalable, and human-comparable dataset featurization, suitable for diverse applications."}}
{"id": "2505.23719", "pdf": "https://arxiv.org/pdf/2505.23719", "abs": "https://arxiv.org/abs/2505.23719", "authors": ["Andreas Auer", "Patrick Podest", "Daniel Klotz", "Sebastian B\u00f6ck", "G\u00fcnter Klambauer", "Sepp Hochreiter"], "title": "TiRex: Zero-Shot Forecasting Across Long and Short Horizons with Enhanced In-Context Learning", "categories": ["cs.LG"], "comment": null, "summary": "In-context learning, the ability of large language models to perform tasks\nusing only examples provided in the prompt, has recently been adapted for time\nseries forecasting. This paradigm enables zero-shot prediction, where past\nvalues serve as context for forecasting future values, making powerful\nforecasting tools accessible to non-experts and increasing the performance when\ntraining data are scarce. Most existing zero-shot forecasting approaches rely\non transformer architectures, which, despite their success in language, often\nfall short of expectations in time series forecasting, where recurrent models\nlike LSTMs frequently have the edge. Conversely, while LSTMs are well-suited\nfor time series modeling due to their state-tracking capabilities, they lack\nstrong in-context learning abilities. We introduce TiRex that closes this gap\nby leveraging xLSTM, an enhanced LSTM with competitive in-context learning\nskills. Unlike transformers, state-space models, or parallelizable RNNs such as\nRWKV, TiRex retains state-tracking, a critical property for long-horizon\nforecasting. To further facilitate its state-tracking ability, we propose a\ntraining-time masking strategy called CPM. TiRex sets a new state of the art in\nzero-shot time series forecasting on the HuggingFace benchmarks GiftEval and\nChronos-ZS, outperforming significantly larger models including TabPFN-TS\n(Prior Labs), Chronos Bolt (Amazon), TimesFM (Google), and Moirai (Salesforce)\nacross both short- and long-term forecasts.", "AI": {"tldr": "TiRex, an enhanced LSTM model, outperforms existing zero-shot time series forecasting methods by combining state-tracking and in-context learning.", "motivation": "Existing transformer-based models underperform in time series forecasting, while LSTMs lack strong in-context learning. TiRex bridges this gap.", "method": "TiRex leverages xLSTM for in-context learning and introduces CPM, a masking strategy to enhance state-tracking.", "result": "TiRex achieves state-of-the-art performance on benchmarks like GiftEval and Chronos-ZS, surpassing larger models.", "conclusion": "TiRex successfully combines the strengths of LSTMs and in-context learning, setting a new standard for zero-shot forecasting."}}
{"id": "2412.12559", "pdf": "https://arxiv.org/pdf/2412.12559", "abs": "https://arxiv.org/abs/2412.12559", "authors": ["Taeho Hwang", "Sukmin Cho", "Soyeong Jeong", "Hoyun Song", "SeungYoon Han", "Jong C. Park"], "title": "EXIT: Context-Aware Extractive Compression for Enhancing Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Findings of ACL 2025", "summary": "We introduce EXIT, an extractive context compression framework that enhances\nboth the effectiveness and efficiency of retrieval-augmented generation (RAG)\nin question answering (QA). Current RAG systems often struggle when retrieval\nmodels fail to rank the most relevant documents, leading to the inclusion of\nmore context at the expense of latency and accuracy. While abstractive\ncompression methods can drastically reduce token counts, their token-by-token\ngeneration process significantly increases end-to-end latency. Conversely,\nexisting extractive methods reduce latency but rely on independent,\nnon-adaptive sentence selection, failing to fully utilize contextual\ninformation. EXIT addresses these limitations by classifying sentences from\nretrieved documents - while preserving their contextual dependencies - enabling\nparallelizable, context-aware extraction that adapts to query complexity and\nretrieval quality. Our evaluations on both single-hop and multi-hop QA tasks\nshow that EXIT consistently surpasses existing compression methods and even\nuncompressed baselines in QA accuracy, while also delivering substantial\nreductions in inference time and token count. By improving both effectiveness\nand efficiency, EXIT provides a promising direction for developing scalable,\nhigh-quality QA solutions in RAG pipelines. Our code is available at\nhttps://github.com/ThisIsHwang/EXIT", "AI": {"tldr": "EXIT is an extractive context compression framework for RAG in QA, improving accuracy and efficiency by classifying sentences while preserving context.", "motivation": "Current RAG systems face issues with irrelevant document ranking and high latency, while existing compression methods lack context-awareness or efficiency.", "method": "EXIT classifies sentences from retrieved documents adaptively, preserving contextual dependencies for parallelizable extraction.", "result": "EXIT outperforms existing methods in QA accuracy and reduces inference time and token count.", "conclusion": "EXIT offers a scalable, high-quality solution for RAG pipelines by balancing effectiveness and efficiency."}}
{"id": "2303.09117", "pdf": "https://arxiv.org/pdf/2303.09117", "abs": "https://arxiv.org/abs/2303.09117", "authors": ["Weixing Chen", "Yang Liu", "Ce Wang", "Jiarui Zhu", "Guanbin Li", "Cheng-Lin Liu", "Liang Lin"], "title": "Cross-Modal Causal Intervention for Medical Report Generation", "categories": ["cs.CV"], "comment": "Accepted by IEEE TIP 2025, 16 pages, 11 figures, 7 tables", "summary": "Radiology Report Generation (RRG) is essential for computer-aided diagnosis\nand medication guidance, which can relieve the heavy burden of radiologists by\nautomatically generating the corresponding radiology reports according to the\ngiven radiology image. However, generating accurate lesion descriptions remains\nchallenging due to spurious correlations from visual-linguistic biases and\ninherent limitations of radiological imaging, such as low resolution and noise\ninterference. To address these issues, we propose a two-stage framework named\nCrossModal Causal Representation Learning (CMCRL), consisting of the\nRadiological Cross-modal Alignment and Reconstruction Enhanced (RadCARE)\npre-training and the Visual-Linguistic Causal Intervention (VLCI) fine-tuning.\nIn the pre-training stage, RadCARE introduces a degradation-aware masked image\nrestoration strategy tailored for radiological images, which reconstructs\nhigh-resolution patches from low-resolution inputs to mitigate noise and detail\nloss. Combined with a multiway architecture and four adaptive training\nstrategies (e.g., text postfix generation with degraded images and text\nprefixes), RadCARE establishes robust cross-modal correlations even with\nincomplete data. In the VLCI phase, we deploy causal front-door intervention\nthrough two modules: the Visual Deconfounding Module (VDM) disentangles\nlocal-global features without fine-grained annotations, while the Linguistic\nDeconfounding Module (LDM) eliminates context bias without external terminology\ndatabases. Experiments on IU-Xray and MIMIC-CXR show that our CMCRL pipeline\nsignificantly outperforms state-of-the-art methods, with ablation studies\nconfirming the necessity of both stages. Code and models are available at\nhttps://github.com/WissingChen/CMCRL.", "AI": {"tldr": "The paper proposes CMCRL, a two-stage framework for Radiology Report Generation (RRG), addressing challenges like visual-linguistic biases and imaging limitations. It includes RadCARE for pre-training and VLCI for fine-tuning, achieving superior results on IU-Xray and MIMIC-CXR datasets.", "motivation": "To alleviate radiologists' workload by improving RRG accuracy, overcoming issues like spurious correlations, low resolution, and noise in radiological images.", "method": "A two-stage framework: 1) RadCARE pre-training with degradation-aware image restoration and multiway architecture; 2) VLCI fine-tuning with causal intervention modules (VDM and LDM) to disentangle biases.", "result": "CMCRL outperforms state-of-the-art methods on IU-Xray and MIMIC-CXR datasets, validated by ablation studies.", "conclusion": "CMCRL effectively addresses RRG challenges, demonstrating the importance of both pre-training and fine-tuning stages for robust performance."}}
{"id": "2503.06951", "pdf": "https://arxiv.org/pdf/2503.06951", "abs": "https://arxiv.org/abs/2503.06951", "authors": ["Xinjie Zhao", "Fan Gao", "Xingyu Song", "Yingjian Chen", "Rui Yang", "Yanran Fu", "Yuyang Wang", "Yusuke Iwasawa", "Yutaka Matsuo", "Irene Li"], "title": "ReAgent: Reversible Multi-Agent Reasoning for Knowledge-Enhanced Multi-Hop QA", "categories": ["cs.AI"], "comment": "25pages, 3 figures", "summary": "Recent advances in large language models (LLMs) have significantly improved\nmulti-hop question answering (QA) through direct Chain-of-Thought (CoT)\nreasoning. However, the irreversible nature of CoT leads to error accumulation,\nmaking it challenging to correct mistakes in multi-hop reasoning. This paper\nintroduces ReAgent: a Reversible multi-Agent collaborative framework augmented\nwith explicit backtracking mechanisms, enabling reversible multi-hop reasoning.\nBy incorporating text-based retrieval, information aggregation and validation,\nour system can detect and correct errors mid-reasoning, leading to more robust\nand interpretable QA outcomes. The framework and experiments serve as a\nfoundation for future work on error-tolerant QA systems. Empirical evaluations\nacross three benchmarks indicate ReAgent's efficacy, yielding average about 6\\%\nimprovements against baseline models.", "AI": {"tldr": "ReAgent introduces a reversible multi-agent framework with backtracking to improve multi-hop QA by correcting errors mid-reasoning, achieving ~6% better performance.", "motivation": "The irreversible nature of Chain-of-Thought reasoning in LLMs leads to error accumulation in multi-hop QA, necessitating a reversible solution.", "method": "ReAgent uses a multi-agent collaborative framework with backtracking, text-based retrieval, and validation to enable reversible reasoning.", "result": "Empirical evaluations show ~6% improvement over baseline models on three benchmarks.", "conclusion": "ReAgent provides a robust, interpretable foundation for error-tolerant QA systems."}}
{"id": "2505.23721", "pdf": "https://arxiv.org/pdf/2505.23721", "abs": "https://arxiv.org/abs/2505.23721", "authors": ["Sean Current", "Ziqi Chen", "Daniel Adu-Ampratwum", "Xia Ning", "Srinivasan Parthasarathy"], "title": "DiffER: Categorical Diffusion for Chemical Retrosynthesis", "categories": ["cs.LG"], "comment": "25 pages, 3 figures, 3 tables", "summary": "Methods for automatic chemical retrosynthesis have found recent success\nthrough the application of models traditionally built for natural language\nprocessing, primarily through transformer neural networks. These models have\ndemonstrated significant ability to translate between the SMILES encodings of\nchemical products and reactants, but are constrained as a result of their\nautoregressive nature. We propose DiffER, an alternative template-free method\nfor retrosynthesis prediction in the form of categorical diffusion, which\nallows the entire output SMILES sequence to be predicted in unison. We\nconstruct an ensemble of diffusion models which achieves state-of-the-art\nperformance for top-1 accuracy and competitive performance for top-3, top-5,\nand top-10 accuracy among template-free methods. We prove that DiffER is a\nstrong baseline for a new class of template-free model, capable of learning a\nvariety of synthetic techniques used in laboratory settings and outperforming a\nvariety of other template-free methods on top-k accuracy metrics. By\nconstructing an ensemble of categorical diffusion models with a novel length\nprediction component with variance, our method is able to approximately sample\nfrom the posterior distribution of reactants, producing results with strong\nmetrics of confidence and likelihood. Furthermore, our analyses demonstrate\nthat accurate prediction of the SMILES sequence length is key to further\nboosting the performance of categorical diffusion models.", "AI": {"tldr": "DiffER, a template-free retrosynthesis method using categorical diffusion, outperforms autoregressive models by predicting entire SMILES sequences at once, achieving state-of-the-art top-1 accuracy.", "motivation": "Autoregressive models for chemical retrosynthesis are limited; DiffER aims to overcome these constraints by predicting sequences in unison.", "method": "DiffER employs an ensemble of categorical diffusion models with a novel length prediction component to sample from the posterior distribution of reactants.", "result": "DiffER achieves state-of-the-art top-1 accuracy and competitive performance in top-3, top-5, and top-10 metrics among template-free methods.", "conclusion": "DiffER is a strong baseline for template-free retrosynthesis, with SMILES length prediction being key to its performance."}}
{"id": "2412.12567", "pdf": "https://arxiv.org/pdf/2412.12567", "abs": "https://arxiv.org/abs/2412.12567", "authors": ["Seunghee Kim", "Changhyeon Kim", "Taeuk Kim"], "title": "FCMR: Robust Evaluation of Financial Cross-Modal Multi-Hop Reasoning", "categories": ["cs.CL"], "comment": "ACL 2025", "summary": "Real-world decision-making often requires integrating and reasoning over\ninformation from multiple modalities. While recent multimodal large language\nmodels (MLLMs) have shown promise in such tasks, their ability to perform\nmulti-hop reasoning across diverse sources remains insufficiently evaluated.\nExisting benchmarks, such as MMQA, face challenges due to (1) data\ncontamination and (2) a lack of complex queries that necessitate operations\nacross more than two modalities, hindering accurate performance assessment. To\naddress this, we present Financial Cross-Modal Multi-Hop Reasoning (FCMR), a\nbenchmark created to analyze the reasoning capabilities of MLLMs by urging them\nto combine information from textual reports, tables, and charts within the\nfinancial domain. FCMR is categorized into three difficulty levels-Easy,\nMedium, and Hard-facilitating a step-by-step evaluation. In particular,\nproblems at the Hard level require precise cross-modal three-hop reasoning and\nare designed to prevent the disregard of any modality. Experiments on this new\nbenchmark reveal that even state-of-the-art MLLMs struggle, with the\nbest-performing model (Claude 3.5 Sonnet) achieving only 30.4% accuracy on the\nmost challenging tier. We also conduct analysis to provide insights into the\ninner workings of the models, including the discovery of a critical bottleneck\nin the information retrieval phase.", "AI": {"tldr": "The paper introduces FCMR, a benchmark for evaluating multimodal large language models (MLLMs) on multi-hop reasoning across financial data, revealing their limitations even for top models.", "motivation": "Existing benchmarks like MMQA are flawed due to data contamination and lack of complex queries, necessitating a new benchmark to assess MLLMs' cross-modal reasoning.", "method": "FCMR is designed with three difficulty levels (Easy, Medium, Hard) to evaluate MLLMs' ability to integrate information from text, tables, and charts in finance.", "result": "State-of-the-art MLLMs perform poorly, with the best model (Claude 3.5 Sonnet) achieving only 30.4% accuracy on Hard-level tasks.", "conclusion": "FCMR highlights MLLMs' struggles with multi-hop reasoning, identifying retrieval as a key bottleneck, and calls for improved models."}}
{"id": "2305.03112", "pdf": "https://arxiv.org/pdf/2305.03112", "abs": "https://arxiv.org/abs/2305.03112", "authors": ["Lechao Cheng", "Zerun Liu", "Jingxuan He", "Chaowei Fang", "Dingwen Zhang", "Meng Wang"], "title": "Calibrating Undisciplined Over-Smoothing in Transformer for Weakly Supervised Semantic Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Weakly supervised semantic segmentation (WSSS) has recently attracted\nconsiderable attention because it requires fewer annotations than fully\nsupervised approaches, making it especially promising for large-scale image\nsegmentation tasks. Although many vision transformer-based methods leverage\nself-attention affinity matrices to refine Class Activation Maps (CAMs), they\noften treat each layer's affinity equally and thus introduce considerable\nbackground noise at deeper layers, where attention tends to converge\nexcessively on certain tokens (i.e., over-smoothing). We observe that this\ndeep-level attention naturally converges on a subset of tokens, yet unregulated\nquery-key affinity can generate unpredictable activation patterns\n(undisciplined over-smoothing), adversely affecting CAM accuracy. To address\nthese limitations, we propose an Adaptive Re-Activation Mechanism (AReAM),\nwhich exploits shallow-level affinity to guide deeper-layer convergence in an\nentropy-aware manner, thereby suppressing background noise and re-activating\ncrucial semantic regions in the CAMs. Experiments on two commonly used datasets\ndemonstrate that AReAM substantially improves segmentation performance compared\nwith existing WSSS methods, reducing noise while sharpening focus on relevant\nsemantic regions. Overall, this work underscores the importance of controlling\ndeep-level attention to mitigate undisciplined over-smoothing, introduces an\nentropy-aware mechanism that harmonizes shallow and deep-level affinities, and\nprovides a refined approach to enhance transformer-based WSSS accuracy by\nre-activating CAMs.", "AI": {"tldr": "The paper proposes an Adaptive Re-Activation Mechanism (AReAM) to improve weakly supervised semantic segmentation by addressing over-smoothing in deep-layer attention and refining CAMs using entropy-aware guidance from shallow layers.", "motivation": "Weakly supervised semantic segmentation (WSSS) reduces annotation effort but suffers from noise in deep-layer attention (over-smoothing), which harms CAM accuracy.", "method": "AReAM leverages shallow-level affinity to guide deeper-layer convergence, suppressing noise and reactivating key semantic regions in CAMs.", "result": "Experiments show AReAM outperforms existing WSSS methods, reducing noise and improving segmentation accuracy.", "conclusion": "The work highlights the need to control deep-level attention, introduces an entropy-aware mechanism, and enhances transformer-based WSSS by refining CAMs."}}
{"id": "2503.07148", "pdf": "https://arxiv.org/pdf/2503.07148", "abs": "https://arxiv.org/abs/2503.07148", "authors": ["Ali Baheri", "Cecilia O. Alm"], "title": "Hierarchical Neuro-Symbolic Decision Transformer", "categories": ["cs.AI", "cs.LG", "cs.SC", "cs.SY", "eess.SY"], "comment": null, "summary": "We present a hierarchical neuro-symbolic control framework that tightly\ncouples a classical symbolic planner with a transformer-based policy to address\nlong-horizon decision-making under uncertainty. At the high level, the planner\nassembles an interpretable sequence of operators that guarantees logical\ncoherence with task constraints, while at the low level each operator is\nrendered as a sub-goal token that conditions a decision transformer to generate\nfine-grained actions directly from raw observations. This bidirectional\ninterface preserves the combinatorial efficiency and explainability of symbolic\nreasoning without sacrificing the adaptability of deep sequence models, and it\npermits a principled analysis that tracks how approximation errors from both\nplanning and execution accumulate across the hierarchy. Empirical studies in\nstochastic grid-world domains demonstrate that the proposed method consistently\nsurpasses purely symbolic, purely neural and existing hierarchical baselines in\nboth success and efficiency, highlighting its robustness for sequential tasks.", "AI": {"tldr": "A hierarchical neuro-symbolic control framework combines symbolic planning with a transformer-based policy for long-horizon decision-making under uncertainty, outperforming purely symbolic, neural, and hierarchical baselines.", "motivation": "Addressing long-horizon decision-making under uncertainty by leveraging the strengths of both symbolic reasoning (logical coherence) and neural models (adaptability).", "method": "Uses a symbolic planner for high-level interpretable sequences and a transformer-based policy for low-level fine-grained actions, with a bidirectional interface to manage approximation errors.", "result": "Empirical studies show superior performance in success and efficiency compared to purely symbolic, neural, and hierarchical baselines.", "conclusion": "The framework effectively balances symbolic reasoning and neural adaptability, proving robust for sequential tasks."}}
{"id": "2505.23725", "pdf": "https://arxiv.org/pdf/2505.23725", "abs": "https://arxiv.org/abs/2505.23725", "authors": ["Benjamin Th\u00e9rien", "Xiaolong Huang", "Irina Rish", "Eugene Belilovsky"], "title": "MuLoCo: Muon is a practical inner optimizer for DiLoCo", "categories": ["cs.LG"], "comment": null, "summary": "DiLoCo is a powerful framework for training large language models (LLMs)\nunder networking constraints with advantages for increasing parallelism and\naccelerator utilization in data center settings. Despite significantly reducing\ncommunication frequency, however, DiLoCo's communication steps still involve\nall-reducing a complete copy of the model's parameters. While existing works\nhave explored ways to reduce communication in DiLoCo, the role of error\nfeedback accumulators and the effect of the inner-optimizer on compressibility\nremain under-explored. In this work, we investigate the effectiveness of\nstandard compression methods including Top-k sparsification and quantization\nfor reducing the communication overhead of DiLoCo when paired with two local\noptimizers (AdamW and Muon). Our experiments pre-training decoder-only\ntransformer language models (LMs) reveal that leveraging Muon as the inner\noptimizer for DiLoCo along with an error-feedback accumulator allows to\naggressively compress the communicated delta to 2-bits with next to no\nperformance degradation. Crucially, MuLoCo (Muon inner optimizer DiLoCo)\nsignificantly outperforms DiLoCo while communicating 8X less and having\nidentical memory complexity.", "AI": {"tldr": "MuLoCo (Muon inner optimizer DiLoCo) reduces communication overhead in DiLoCo by 8X with 2-bit compression and no performance loss, outperforming DiLoCo.", "motivation": "To explore the role of error feedback and inner-optimizer effects on compressibility in DiLoCo, aiming to reduce communication overhead.", "method": "Investigates Top-k sparsification and quantization with AdamW and Muon optimizers, using error-feedback accumulators for compression.", "result": "MuLoCo achieves 8X less communication with 2-bit compression and no performance degradation, outperforming DiLoCo.", "conclusion": "MuLoCo is a more efficient variant of DiLoCo, significantly reducing communication while maintaining performance."}}
{"id": "2412.13670", "pdf": "https://arxiv.org/pdf/2412.13670", "abs": "https://arxiv.org/abs/2412.13670", "authors": ["Xiaobao Wu", "Liangming Pan", "Yuxi Xie", "Ruiwen Zhou", "Shuai Zhao", "Yubo Ma", "Mingzhe Du", "Rui Mao", "Anh Tuan Luu", "William Yang Wang"], "title": "AntiLeakBench: Preventing Data Contamination by Automatically Constructing Benchmarks with Updated Real-World Knowledge", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to ACL 2025 main conference. Code and data are at\n  https://github.com/bobxwu/AntiLeakBench", "summary": "Data contamination hinders fair LLM evaluation by introducing test data into\nnewer models' training sets. Existing studies solve this challenge by updating\nbenchmarks with newly collected data. However, they fail to guarantee\ncontamination-free evaluation as the newly collected data may contain\npre-existing knowledge, and their benchmark updates rely on intensive human\nlabor. To address these issues, we in this paper propose AntiLeak-Bench, an\nautomated anti-leakage benchmarking framework. Instead of simply using newly\ncollected data, we construct samples with explicitly new knowledge absent from\nLLMs' training sets, which thus ensures strictly contamination-free evaluation.\nWe further design a fully automated workflow to build and update our benchmark\nwithout human labor. This significantly reduces the cost of benchmark\nmaintenance to accommodate emerging LLMs. Through extensive experiments, we\nhighlight that data contamination likely exists before LLMs' cutoff time and\ndemonstrate AntiLeak-Bench effectively overcomes this challenge.", "AI": {"tldr": "AntiLeak-Bench is an automated framework to prevent data contamination in LLM evaluation by using new knowledge and eliminating human labor.", "motivation": "Existing methods fail to ensure contamination-free evaluation due to pre-existing knowledge in new data and reliance on human labor.", "method": "Constructs samples with new knowledge absent from LLMs' training sets and automates benchmark updates.", "result": "Demonstrates data contamination likely exists before LLMs' cutoff time and shows AntiLeak-Bench effectively addresses this.", "conclusion": "AntiLeak-Bench ensures contamination-free evaluation and reduces benchmark maintenance costs."}}
{"id": "2307.07333", "pdf": "https://arxiv.org/pdf/2307.07333", "abs": "https://arxiv.org/abs/2307.07333", "authors": ["Zhili Ng", "Haozhe Wang", "Zhengshen Zhang", "Francis Tay Eng Hock", "Marcelo H. Ang Jr"], "title": "SynTable: A Synthetic Data Generation Pipeline for Unseen Object Amodal Instance Segmentation of Cluttered Tabletop Scenes", "categories": ["cs.CV"], "comment": "Camera-ready version for SynData4CV Workshop @ CVPR 2025. 18 Pages,\n  11 figures", "summary": "In this work, we present SynTable, a unified and flexible Python-based\ndataset generator built using NVIDIA's Isaac Sim Replicator Composer for\ngenerating high-quality synthetic datasets for unseen object amodal instance\nsegmentation of cluttered tabletop scenes. Our dataset generation tool can\nrender complex 3D scenes containing object meshes, materials, textures,\nlighting, and backgrounds. Metadata, such as modal and amodal instance\nsegmentation masks, object amodal RGBA instances, occlusion masks, depth maps,\nbounding boxes, and material properties can be automatically generated to\nannotate the scene according to the users' requirements. Our tool eliminates\nthe need for manual labeling in the dataset generation process while ensuring\nthe quality and accuracy of the dataset. In this work, we discuss our design\ngoals, framework architecture, and the performance of our tool. We demonstrate\nthe use of a sample dataset generated using SynTable for training a\nstate-of-the-art model, UOAIS-Net. Our state-of-the-art results show\nsignificantly improved performance in Sim-to-Real transfer when evaluated on\nthe OSD-Amodal dataset. We offer this tool as an open-source, easy-to-use,\nphotorealistic dataset generator for advancing research in deep learning and\nsynthetic data generation. The links to our source code, demonstration video,\nand sample dataset can be found in the supplementary materials.", "AI": {"tldr": "SynTable is a Python-based tool for generating high-quality synthetic datasets for unseen object amodal instance segmentation, eliminating manual labeling and improving Sim-to-Real transfer performance.", "motivation": "To address the need for high-quality synthetic datasets in deep learning research without manual labeling, ensuring accuracy and flexibility.", "method": "Uses NVIDIA's Isaac Sim Replicator Composer to render complex 3D scenes with metadata like segmentation masks, depth maps, and bounding boxes.", "result": "Demonstrated improved performance in Sim-to-Real transfer on the OSD-Amodal dataset using UOAIS-Net.", "conclusion": "SynTable is an open-source, photorealistic dataset generator that advances research in synthetic data and deep learning."}}
{"id": "2504.15046", "pdf": "https://arxiv.org/pdf/2504.15046", "abs": "https://arxiv.org/abs/2504.15046", "authors": ["Shilin Zhang", "Zican Hu", "Wenhao Wu", "Xinyi Xie", "Jianxiang Tang", "Chunlin Chen", "Daoyi Dong", "Yu Cheng", "Zhenhong Sun", "Zhi Wang"], "title": "Text-to-Decision Agent: Offline Meta-Reinforcement Learning from Natural Language Supervision", "categories": ["cs.AI"], "comment": "18 pages, 8 figures", "summary": "Offline meta-RL usually tackles generalization by inferring task beliefs from\nhigh-quality samples or warmup explorations. The restricted form limits their\ngenerality and usability since these supervision signals are expensive and even\ninfeasible to acquire in advance for unseen tasks. Learning directly from the\nraw text about decision tasks is a promising alternative to leverage a much\nbroader source of supervision. In the paper, we propose\n\\textbf{T}ext-to-\\textbf{D}ecision \\textbf{A}gent (\\textbf{T2DA}), a simple and\nscalable framework that supervises offline meta-RL with natural language. We\nfirst introduce a generalized world model to encode multi-task decision data\ninto a dynamics-aware embedding space. Then, inspired by CLIP, we predict which\ntextual description goes with which decision embedding, effectively bridging\ntheir semantic gap via contrastive language-decision pre-training and aligning\nthe text embeddings to comprehend the environment dynamics. After training the\ntext-conditioned generalist policy, the agent can directly realize zero-shot\ntext-to-decision generation in response to language instructions. Comprehensive\nexperiments on MuJoCo and Meta-World benchmarks show that T2DA facilitates\nhigh-capacity zero-shot generalization and outperforms various types of\nbaselines.", "AI": {"tldr": "T2DA is a framework for offline meta-RL that uses natural language to supervise learning, enabling zero-shot text-to-decision generation without expensive prior signals.", "motivation": "Overcome limitations of traditional offline meta-RL, which relies on costly or infeasible supervision signals for unseen tasks, by leveraging raw text as a broader source of guidance.", "method": "Introduces a generalized world model for multi-task decision data and aligns text embeddings with decision embeddings via contrastive pre-training, similar to CLIP.", "result": "T2DA outperforms baselines on MuJoCo and Meta-World benchmarks, demonstrating strong zero-shot generalization capabilities.", "conclusion": "T2DA provides a scalable and effective solution for offline meta-RL by integrating natural language supervision, enabling practical zero-shot task generalization."}}
{"id": "2505.23732", "pdf": "https://arxiv.org/pdf/2505.23732", "abs": "https://arxiv.org/abs/2505.23732", "authors": ["Shreeram Suresh Chandra", "Lucas Goncalves", "Junchen Lu", "Carlos Busso", "Berrak Sisman"], "title": "EmotionRankCLAP: Bridging Natural Language Speaking Styles and Ordinal Speech Emotion via Rank-N-Contrast", "categories": ["cs.LG"], "comment": "Accepted at Interspeech 2025", "summary": "Current emotion-based contrastive language-audio pretraining (CLAP) methods\ntypically learn by na\\\"ively aligning audio samples with corresponding text\nprompts. Consequently, this approach fails to capture the ordinal nature of\nemotions, hindering inter-emotion understanding and often resulting in a wide\nmodality gap between the audio and text embeddings due to insufficient\nalignment. To handle these drawbacks, we introduce EmotionRankCLAP, a\nsupervised contrastive learning approach that uses dimensional attributes of\nemotional speech and natural language prompts to jointly capture fine-grained\nemotion variations and improve cross-modal alignment. Our approach utilizes a\nRank-N-Contrast objective to learn ordered relationships by contrasting samples\nbased on their rankings in the valence-arousal space. EmotionRankCLAP\noutperforms existing emotion-CLAP methods in modeling emotion ordinality across\nmodalities, measured via a cross-modal retrieval task.", "AI": {"tldr": "EmotionRankCLAP improves emotion-based CLAP by capturing ordinal relationships and enhancing cross-modal alignment using a Rank-N-Contrast objective.", "motivation": "Existing CLAP methods naively align audio and text, missing emotion ordinality and causing a modality gap.", "method": "Uses dimensional emotion attributes and Rank-N-Contrast to learn ordered relationships in valence-arousal space.", "result": "Outperforms existing methods in cross-modal retrieval, better modeling emotion ordinality.", "conclusion": "EmotionRankCLAP addresses alignment and ordinality issues, improving emotion understanding across modalities."}}
{"id": "2412.15272", "pdf": "https://arxiv.org/pdf/2412.15272", "abs": "https://arxiv.org/abs/2412.15272", "authors": ["Yuzheng Cai", "Zhenyue Guo", "Yiwen Pei", "Wanrui Bian", "Weiguo Zheng"], "title": "SimGRAG: Leveraging Similar Subgraphs for Knowledge Graphs Driven Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "accepted by ACL 2025 (Findings)", "summary": "Recent advancements in large language models (LLMs) have shown impressive\nversatility across various tasks. To eliminate their hallucinations,\nretrieval-augmented generation (RAG) has emerged as a powerful approach,\nleveraging external knowledge sources like knowledge graphs (KGs). In this\npaper, we study the task of KG-driven RAG and propose a novel Similar Graph\nEnhanced Retrieval-Augmented Generation (SimGRAG) method. It effectively\naddresses the challenge of aligning query texts and KG structures through a\ntwo-stage process: (1) query-to-pattern, which uses an LLM to transform queries\ninto a desired graph pattern, and (2) pattern-to-subgraph, which quantifies the\nalignment between the pattern and candidate subgraphs using a graph semantic\ndistance (GSD) metric. We also develop an optimized retrieval algorithm that\nefficiently identifies the top-k subgraphs within 1-second on a\n10-million-scale KG. Extensive experiments show that SimGRAG outperforms\nstate-of-the-art KG-driven RAG methods in both question answering and fact\nverification. Our code is available at https://github.com/YZ-Cai/SimGRAG.", "AI": {"tldr": "SimGRAG enhances KG-driven RAG by aligning queries with KG structures via a two-stage process, improving accuracy and efficiency.", "motivation": "To address hallucinations in LLMs by leveraging KGs for more accurate retrieval-augmented generation.", "method": "Two-stage process: query-to-pattern (LLM transforms queries into graph patterns) and pattern-to-subgraph (GSD metric aligns patterns with subgraphs). Includes an optimized retrieval algorithm.", "result": "Outperforms state-of-the-art KG-driven RAG methods in QA and fact verification, with efficient retrieval on large-scale KGs.", "conclusion": "SimGRAG effectively improves KG-driven RAG by better aligning queries and KG structures, demonstrating superior performance."}}
{"id": "2309.10815", "pdf": "https://arxiv.org/pdf/2309.10815", "abs": "https://arxiv.org/abs/2309.10815", "authors": ["Xiao Fu", "Shangzhan Zhang", "Tianrun Chen", "Yichong Lu", "Xiaowei Zhou", "Andreas Geiger", "Yiyi Liao"], "title": "PanopticNeRF-360: Panoramic 3D-to-2D Label Transfer in Urban Scenes", "categories": ["cs.CV"], "comment": "Project page: http://fuxiao0719.github.io/projects/panopticnerf360/\n  Code: https://github.com/fuxiao0719/PanopticNeRF/tree/panopticnerf360 (Minor\n  Revision). arXiv admin note: text overlap with arXiv:2203.15224", "summary": "Training perception systems for self-driving cars requires substantial 2D\nannotations that are labor-intensive to manual label. While existing datasets\nprovide rich annotations on pre-recorded sequences, they fall short in labeling\nrarely encountered viewpoints, potentially hampering the generalization ability\nfor perception models. In this paper, we present PanopticNeRF-360, a novel\napproach that combines coarse 3D annotations with noisy 2D semantic cues to\ngenerate high-quality panoptic labels and images from any viewpoint. Our key\ninsight lies in exploiting the complementarity of 3D and 2D priors to mutually\nenhance geometry and semantics. Specifically, we propose to leverage coarse 3D\nbounding primitives and noisy 2D semantic and instance predictions to guide\ngeometry optimization, by encouraging predicted labels to match panoptic pseudo\nground truth. Simultaneously, the improved geometry assists in filtering 3D&2D\nannotation noise by fusing semantics in 3D space via a learned semantic field.\nTo further enhance appearance, we combine MLP and hash grids to yield hybrid\nscene features, striking a balance between high-frequency appearance and\ncontiguous semantics. Our experiments demonstrate PanopticNeRF-360's\nstate-of-the-art performance over label transfer methods on the challenging\nurban scenes of the KITTI-360 dataset. Moreover, PanopticNeRF-360 enables\nomnidirectional rendering of high-fidelity, multi-view and spatiotemporally\nconsistent appearance, semantic and instance labels. We make our code and data\navailable at https://github.com/fuxiao0719/PanopticNeRF", "AI": {"tldr": "PanopticNeRF-360 combines 3D and 2D priors to generate high-quality panoptic labels and images from any viewpoint, improving generalization for self-driving perception systems.", "motivation": "Manual 2D annotation is labor-intensive, and existing datasets lack rare viewpoints, limiting model generalization.", "method": "Leverages coarse 3D annotations and noisy 2D cues to guide geometry optimization, using a hybrid MLP-hash grid for appearance.", "result": "Achieves state-of-the-art performance on KITTI-360, enabling high-fidelity omnidirectional rendering.", "conclusion": "PanopticNeRF-360 enhances perception models by generating consistent, high-quality labels and images from any viewpoint."}}
{"id": "2505.00612", "pdf": "https://arxiv.org/pdf/2505.00612", "abs": "https://arxiv.org/abs/2505.00612", "authors": ["D. Sculley", "Will Cukierski", "Phil Culliton", "Sohier Dane", "Maggie Demkin", "Ryan Holbrook", "Addison Howard", "Paul Mooney", "Walter Reade", "Megan Risdal", "Nate Keating"], "title": "Position: AI Competitions Provide the Gold Standard for Empirical Rigor in GenAI Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "In this position paper, we observe that empirical evaluation in Generative AI\nis at a crisis point since traditional ML evaluation and benchmarking\nstrategies are insufficient to meet the needs of evaluating modern GenAI models\nand systems. There are many reasons for this, including the fact that these\nmodels typically have nearly unbounded input and output spaces, typically do\nnot have a well defined ground truth target, and typically exhibit strong\nfeedback loops and prediction dependence based on context of previous model\noutputs. On top of these critical issues, we argue that the problems of leakage\nand contamination are in fact the most important and difficult issues to\naddress for GenAI evaluations. Interestingly, the field of AI Competitions has\ndeveloped effective measures and practices to combat leakage for the purpose of\ncounteracting cheating by bad actors within a competition setting. This makes\nAI Competitions an especially valuable (but underutilized) resource. Now is\ntime for the field to view AI Competitions as the gold standard for empirical\nrigor in GenAI evaluation, and to harness and harvest their results with\naccording value.", "AI": {"tldr": "The paper argues that traditional ML evaluation methods are inadequate for Generative AI, highlighting issues like unbounded input/output spaces, lack of ground truth, and feedback loops. It suggests AI Competitions as a gold standard for rigorous GenAI evaluation due to their anti-leakage measures.", "motivation": "The crisis in empirical evaluation of Generative AI due to traditional ML methods' inadequacy and the challenges like leakage and contamination.", "method": "Proposes leveraging AI Competitions, which have effective anti-leakage practices, as a model for rigorous GenAI evaluation.", "result": "AI Competitions are identified as an underutilized but valuable resource for addressing GenAI evaluation challenges.", "conclusion": "The field should adopt AI Competitions as the gold standard for empirical rigor in GenAI evaluation."}}
{"id": "2505.23749", "pdf": "https://arxiv.org/pdf/2505.23749", "abs": "https://arxiv.org/abs/2505.23749", "authors": ["Paul G\u00f6lz", "Nika Haghtalab", "Kunhe Yang"], "title": "Distortion of AI Alignment: Does Preference Optimization Optimize for Preferences?", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "After pre-training, large language models are aligned with human preferences\nbased on pairwise comparisons. State-of-the-art alignment methods (such as\nPPO-based RLHF and DPO) are built on the assumption of aligning with a single\npreference model, despite being deployed in settings where users have diverse\npreferences. As a result, it is not even clear that these alignment methods\nproduce models that satisfy users on average -- a minimal requirement for\npluralistic alignment. Drawing on social choice theory and modeling users'\ncomparisons through individual Bradley-Terry (BT) models, we introduce an\nalignment method's distortion: the worst-case ratio between the optimal\nachievable average utility, and the average utility of the learned policy.\n  The notion of distortion helps draw sharp distinctions between alignment\nmethods: Nash Learning from Human Feedback achieves the minimax optimal\ndistortion of $(\\frac{1}{2} + o(1)) \\cdot \\beta$ (for the BT temperature\n$\\beta$), robustly across utility distributions, distributions of comparison\npairs, and permissible KL divergences from the reference policy. RLHF and DPO,\nby contrast, suffer $\\geq (1 - o(1)) \\cdot \\beta$ distortion already without a\nKL constraint, and $e^{\\Omega(\\beta)}$ or even unbounded distortion in the full\nsetting, depending on how comparison pairs are sampled.", "AI": {"tldr": "The paper critiques current alignment methods (like PPO-based RLHF and DPO) for assuming a single preference model, despite diverse user preferences. It introduces 'distortion' to measure alignment quality and shows Nash Learning from Human Feedback outperforms RLHF and DPO.", "motivation": "Current alignment methods fail to account for diverse user preferences, risking suboptimal average utility. The paper aims to address this gap using social choice theory.", "method": "The authors model user comparisons via individual Bradley-Terry models and introduce 'distortion' to evaluate alignment methods. They analyze Nash Learning from Human Feedback, RLHF, and DPO.", "result": "Nash Learning achieves minimax optimal distortion, robust across utility distributions and KL constraints. RLHF and DPO perform poorly, with high or unbounded distortion.", "conclusion": "Nash Learning is superior for pluralistic alignment, while RLHF and DPO are inadequate for diverse preferences."}}
{"id": "2412.16359", "pdf": "https://arxiv.org/pdf/2412.16359", "abs": "https://arxiv.org/abs/2412.16359", "authors": ["Nilanjana Das", "Edward Raff", "Aman Chadha", "Manas Gaur"], "title": "Human-Readable Adversarial Prompts: An Investigation into LLM Vulnerabilities Using Situational Context", "categories": ["cs.CL", "cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2407.14644", "summary": "As the AI systems become deeply embedded in social media platforms, we've\nuncovered a concerning security vulnerability that goes beyond traditional\nadversarial attacks. It becomes important to assess the risks of LLMs before\nthe general public use them on social media platforms to avoid any adverse\nimpacts. Unlike obvious nonsensical text strings that safety systems can easily\ncatch, our work reveals that human-readable situation-driven adversarial\nfull-prompts that leverage situational context are effective but much harder to\ndetect. We found that skilled attackers can exploit the vulnerabilities in\nopen-source and proprietary LLMs to make a malicious user query safe for LLMs,\nresulting in generating a harmful response. This raises an important question\nabout the vulnerabilities of LLMs. To measure the robustness against\nhuman-readable attacks, which now present a potent threat, our research makes\nthree major contributions. First, we developed attacks that use movie scripts\nas situational contextual frameworks, creating natural-looking full-prompts\nthat trick LLMs into generating harmful content. Second, we developed a method\nto transform gibberish adversarial text into readable, innocuous content that\nstill exploits vulnerabilities when used within the full-prompts. Finally, we\nenhanced the AdvPrompter framework with p-nucleus sampling to generate diverse\nhuman-readable adversarial texts that significantly improve attack\neffectiveness against models like GPT-3.5-Turbo-0125 and Gemma-7b. Our findings\nshow that these systems can be manipulated to operate beyond their intended\nethical boundaries when presented with seemingly normal prompts that contain\nhidden adversarial elements. By identifying these vulnerabilities, we aim to\ndrive the development of more robust safety mechanisms that can withstand\nsophisticated attacks in real-world applications.", "AI": {"tldr": "The paper uncovers a new security vulnerability in LLMs on social media, where human-readable, situation-driven adversarial prompts evade detection and exploit models to generate harmful content. It proposes methods to create such attacks and suggests improvements for safety mechanisms.", "motivation": "To assess and mitigate the risks of LLMs being exploited by sophisticated adversarial attacks that use natural-looking prompts, which are harder to detect than traditional nonsensical attacks.", "method": "Developed attacks using movie scripts as contextual frameworks, transformed gibberish adversarial text into readable content, and enhanced the AdvPrompter framework with p-nucleus sampling for diverse adversarial texts.", "result": "Demonstrated that LLMs like GPT-3.5-Turbo-0125 and Gemma-7b can be tricked into generating harmful content using seemingly normal prompts with hidden adversarial elements.", "conclusion": "The findings highlight the need for more robust safety mechanisms to counter sophisticated adversarial attacks in real-world LLM applications."}}
{"id": "2312.03207", "pdf": "https://arxiv.org/pdf/2312.03207", "abs": "https://arxiv.org/abs/2312.03207", "authors": ["Patrick Beukema", "Favyen Bastani", "Yawen Zheng", "Piper Wolters", "Henry Herzog", "Joe Ferdinando"], "title": "Satellite Imagery and AI: A New Era in Ocean Conservation, from Research to Deployment and Impact (Version. 2.0)", "categories": ["cs.CV"], "comment": "8 pages, 3 figures, NeurIPS Computational Sustainability 2023 best\n  paper", "summary": "Illegal, unreported, and unregulated (IUU) fishing poses a global threat to\nocean habitats. Publicly available satellite data offered by NASA, the European\nSpace Agency (ESA), and the U.S. Geological Survey (USGS), provide an\nopportunity to actively monitor this activity. Effectively leveraging satellite\ndata for maritime conservation requires highly reliable machine learning models\noperating globally with minimal latency. This paper introduces four specialized\ncomputer vision models designed for a variety of sensors including Sentinel-1\n(synthetic aperture radar), Sentinel-2 (optical imagery), Landsat 8-9 (optical\nimagery), and Suomi-NPP/NOAA-20/NOAA-21 (nighttime lights). It also presents\nbest practices for developing and deploying global-scale real-time satellite\nbased computer vision. All of the models are open sourced under permissive\nlicenses. These models have all been deployed in Skylight, a real-time maritime\nmonitoring platform, which is provided at no cost to users worldwide.", "AI": {"tldr": "The paper introduces four specialized computer vision models for monitoring IUU fishing using satellite data, deployed in the free Skylight platform.", "motivation": "IUU fishing threatens ocean habitats, and publicly available satellite data can help monitor it. Reliable, low-latency machine learning models are needed for global maritime conservation.", "method": "Developed four computer vision models for different satellite sensors (Sentinel-1, Sentinel-2, Landsat 8-9, and Suomi-NPP/NOAA-20/NOAA-21) and shared best practices for global-scale, real-time deployment.", "result": "All models are open-sourced and deployed in Skylight, a free real-time maritime monitoring platform.", "conclusion": "The models and platform provide a scalable solution for combating IUU fishing using satellite data and computer vision."}}
{"id": "2505.02322", "pdf": "https://arxiv.org/pdf/2505.02322", "abs": "https://arxiv.org/abs/2505.02322", "authors": ["Runquan Gui", "Zhihai Wang", "Jie Wang", "Chi Ma", "Huiling Zhen", "Mingxuan Yuan", "Jianye Hao", "Defu Lian", "Enhong Chen", "Feng Wu"], "title": "HyperTree Planning: Enhancing LLM Reasoning via Hierarchical Thinking", "categories": ["cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2406.14228 by other authors", "summary": "Recent advancements have significantly enhanced the performance of large\nlanguage models (LLMs) in tackling complex reasoning tasks, achieving notable\nsuccess in domains like mathematical and logical reasoning. However, these\nmethods encounter challenges with complex planning tasks, primarily due to\nextended reasoning steps, diverse constraints, and the challenge of handling\nmultiple distinct sub-tasks. To address these challenges, we propose HyperTree\nPlanning (HTP), a novel reasoning paradigm that constructs hypertree-structured\nplanning outlines for effective planning. The hypertree structure enables LLMs\nto engage in hierarchical thinking by flexibly employing the divide-and-conquer\nstrategy, effectively breaking down intricate reasoning steps, accommodating\ndiverse constraints, and managing multiple distinct sub-tasks in a\nwell-organized manner. We further introduce an autonomous planning framework\nthat completes the planning process by iteratively refining and expanding the\nhypertree-structured planning outlines. Experiments demonstrate the\neffectiveness of HTP, achieving state-of-the-art accuracy on the TravelPlanner\nbenchmark with Gemini-1.5-Pro, resulting in a 3.6 times performance improvement\nover o1-preview.", "AI": {"tldr": "HyperTree Planning (HTP) improves LLMs' complex planning tasks using a hypertree-structured approach, achieving a 3.6x performance boost.", "motivation": "Existing LLMs struggle with complex planning due to long reasoning steps, diverse constraints, and multiple sub-tasks.", "method": "HTP uses hypertree-structured outlines for hierarchical planning, employing divide-and-conquer strategies.", "result": "HTP achieves state-of-the-art accuracy on the TravelPlanner benchmark, improving performance by 3.6x.", "conclusion": "HTP effectively addresses complex planning challenges in LLMs, demonstrating significant performance gains."}}
{"id": "2505.23760", "pdf": "https://arxiv.org/pdf/2505.23760", "abs": "https://arxiv.org/abs/2505.23760", "authors": ["Amber Yijia Zheng", "Cedar Site Bai", "Brian Bullins", "Raymond A. Yeh"], "title": "Model Immunization from a Condition Number Perspective", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Model immunization aims to pre-train models that are difficult to fine-tune\non harmful tasks while retaining their utility on other non-harmful tasks.\nThough prior work has shown empirical evidence for immunizing text-to-image\nmodels, the key understanding of when immunization is possible and a precise\ndefinition of an immunized model remain unclear. In this work, we propose a\nframework, based on the condition number of a Hessian matrix, to analyze model\nimmunization for linear models. Building on this framework, we design an\nalgorithm with regularization terms to control the resulting condition numbers\nafter pre-training. Empirical results on linear models and non-linear deep-nets\ndemonstrate the effectiveness of the proposed algorithm on model immunization.\nThe code is available at\nhttps://github.com/amberyzheng/model-immunization-cond-num.", "AI": {"tldr": "The paper proposes a framework for model immunization using Hessian matrix condition numbers, with an algorithm for pre-training control, validated on linear and non-linear models.", "motivation": "To clarify when model immunization is possible and define an immunized model, addressing gaps in prior work.", "method": "A framework based on Hessian matrix condition numbers, with a regularization-based algorithm for pre-training control.", "result": "Empirical validation shows effectiveness on both linear models and non-linear deep networks.", "conclusion": "The proposed framework and algorithm successfully immunize models while retaining utility on non-harmful tasks."}}
{"id": "2412.16555", "pdf": "https://arxiv.org/pdf/2412.16555", "abs": "https://arxiv.org/abs/2412.16555", "authors": ["Yanxu Mao", "Peipei Liu", "Tiehan Cui", "Zhaoteng Yan", "Congying Liu", "Datao You"], "title": "Divide and Conquer: A Hybrid Strategy Defeats Multimodal Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) are widely applied in various fields of society\ndue to their powerful reasoning, understanding, and generation capabilities.\nHowever, the security issues associated with these models are becoming\nincreasingly severe. Jailbreaking attacks, as an important method for detecting\nvulnerabilities in LLMs, have been explored by researchers who attempt to\ninduce these models to generate harmful content through various attack methods.\nNevertheless, existing jailbreaking methods face numerous limitations, such as\nexcessive query counts, limited coverage of jailbreak modalities, low attack\nsuccess rates, and simplistic evaluation methods. To overcome these\nconstraints, this paper proposes a multimodal jailbreaking method: JMLLM. This\nmethod integrates multiple strategies to perform comprehensive jailbreak\nattacks across text, visual, and auditory modalities. Additionally, we\ncontribute a new and comprehensive dataset for multimodal jailbreaking\nresearch: TriJail, which includes jailbreak prompts for all three modalities.\nExperiments on the TriJail dataset and the benchmark dataset AdvBench,\nconducted on 13 popular LLMs, demonstrate advanced attack success rates and\nsignificant reduction in time overhead.", "AI": {"tldr": "The paper proposes JMLLM, a multimodal jailbreaking method for LLMs, addressing limitations of existing methods by integrating text, visual, and auditory attacks. It introduces the TriJail dataset and shows improved success rates and efficiency.", "motivation": "Existing jailbreaking methods for LLMs have limitations like high query counts, low success rates, and narrow modality coverage, prompting the need for a more comprehensive approach.", "method": "JMLLM integrates multimodal strategies (text, visual, auditory) for jailbreaking and uses the TriJail dataset for evaluation across 13 LLMs.", "result": "Experiments show JMLLM achieves higher attack success rates and reduces time overhead compared to existing methods.", "conclusion": "JMLLM offers a robust, efficient solution for multimodal jailbreaking, validated by the TriJail dataset and outperforming benchmarks."}}
{"id": "2405.04533", "pdf": "https://arxiv.org/pdf/2405.04533", "abs": "https://arxiv.org/abs/2405.04533", "authors": ["Jing Lin", "Yao Feng", "Weiyang Liu", "Michael J. Black"], "title": "ChatHuman: Chatting about 3D Humans with Tools", "categories": ["cs.CV", "cs.LG"], "comment": "Project page: https://chathuman.github.io", "summary": "Numerous methods have been proposed to detect, estimate, and analyze\nproperties of people in images, including 3D pose, shape, contact, human-object\ninteraction, and emotion. While widely applicable in vision and other areas,\nsuch methods require expert knowledge to select, use, and interpret the\nresults. To address this, we introduce ChatHuman, a language-driven system that\nintegrates the capabilities of specialized methods into a unified framework.\nChatHuman functions as an assistant proficient in utilizing, analyzing, and\ninteracting with tools specific to 3D human tasks, adeptly discussing and\nresolving related challenges. Built on a Large Language Model (LLM) framework,\nChatHuman is trained to autonomously select, apply, and interpret a diverse set\nof tools in response to user inputs. Our approach overcomes significant hurdles\nin adapting LLMs to 3D human tasks, including the need for domain-specific\nknowledge and the ability to interpret complex 3D outputs. The innovations of\nChatHuman include leveraging academic publications to instruct the LLM on tool\nusage, employing a retrieval-augmented generation model to create in-context\nlearning examples for managing new tools, and effectively discriminating\nbetween and integrating tool results by transforming specialized 3D outputs\ninto comprehensible formats. Experiments demonstrate that ChatHuman surpasses\nexisting models in both tool selection accuracy and overall performance across\nvarious 3D human tasks, and it supports interactive chatting with users.\nChatHuman represents a significant step toward consolidating diverse analytical\nmethods into a unified, robust system for 3D human tasks.", "AI": {"tldr": "ChatHuman is a language-driven system integrating specialized 3D human task tools into a unified framework using an LLM, improving tool selection and performance.", "motivation": "Existing methods for 3D human tasks require expert knowledge, limiting accessibility. ChatHuman aims to simplify usage and interpretation.", "method": "Built on an LLM, ChatHuman autonomously selects and applies tools, uses academic publications for training, and transforms 3D outputs into understandable formats.", "result": "ChatHuman outperforms existing models in tool selection accuracy and task performance, supporting interactive user chats.", "conclusion": "ChatHuman advances the consolidation of diverse 3D human task methods into a unified, user-friendly system."}}
{"id": "2505.03475", "pdf": "https://arxiv.org/pdf/2505.03475", "abs": "https://arxiv.org/abs/2505.03475", "authors": ["Zirui Liu", "Jiatong Li", "Yan Zhuang", "Qi Liu", "Shuanghong Shen", "Jie Ouyang", "Mingyue Cheng", "Shijin Wang"], "title": "am-ELO: A Stable Framework for Arena-based LLM Evaluation", "categories": ["cs.AI", "cs.LG"], "comment": "ICML2025 Accepted", "summary": "Arena-based evaluation is a fundamental yet significant evaluation paradigm\nfor modern AI models, especially large language models (LLMs). Existing\nframework based on ELO rating system suffers from the inevitable instability\nproblem due to ranking inconsistency and the lack of attention to the varying\nabilities of annotators. In this paper, we introduce a novel stable arena\nframework to address these issues by enhancing the ELO Rating System.\nSpecifically, we replace the iterative update method with a Maximum Likelihood\nEstimation (MLE) approach, m-ELO, and provide theoretical proof of the\nconsistency and stability of the MLE approach for model ranking. Additionally,\nwe proposed the am-ELO, which modify the Elo Rating's probability function to\nincorporate annotator abilities, enabling the simultaneous estimation of model\nscores and annotator reliability. Experiments demonstrate that this method\nensures stability, proving that this framework offers a more robust, accurate,\nand stable evaluation method for LLMs.", "AI": {"tldr": "A novel stable arena framework (m-ELO and am-ELO) improves the ELO Rating System for AI model evaluation by addressing instability and annotator ability issues.", "motivation": "Existing ELO-based frameworks for AI model evaluation suffer from instability and ignore annotator abilities, necessitating a more robust solution.", "method": "Proposes m-ELO (MLE-based update) and am-ELO (incorporates annotator abilities) to enhance the ELO Rating System.", "result": "Experiments show the framework ensures stability, robustness, and accuracy in evaluating LLMs.", "conclusion": "The stable arena framework provides a more reliable and stable evaluation method for modern AI models."}}
{"id": "2505.11047", "pdf": "https://arxiv.org/pdf/2505.11047", "abs": "https://arxiv.org/abs/2505.11047", "authors": ["Arghya Mallick", "Georgios Pantazis", "Mohammad Khosravi", "Peyman Mohajerin Esfahani", "Sergio Grammatico"], "title": "User-centric Vehicle-to-Grid Optimization with an Input Convex Neural Network-based Battery Degradation Model", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "We propose a data-driven, user-centric vehicle-to-grid (V2G) methodology\nbased on multi-objective optimization to balance battery degradation and V2G\nrevenue according to EV user preference. Given the lack of accurate and\ngeneralizable battery degradation models, we leverage input convex neural\nnetworks (ICNNs) to develop a data-driven degradation model trained on\nextensive experimental datasets. This approach enables our model to capture\nnonconvex dependencies on battery temperature and time while maintaining\nconvexity with respect to the charging rate. Such a partial convexity property\nensures that the second stage of our methodology remains computationally\nefficient. In the second stage, we integrate our data-driven degradation model\ninto a multi-objective optimization framework to generate an optimal smart\ncharging profile for each EV. This profile effectively balances the trade-off\nbetween financial benefits from V2G participation and battery degradation,\ncontrolled by a hyperparameter reflecting the user prioritization of battery\nhealth. Numerical simulations show the high accuracy of the ICNN model in\npredicting battery degradation for unseen data. Finally, we present a trade-off\ncurve illustrating financial benefits from V2G versus losses from battery\nhealth degradation based on user preferences and showcase smart charging\nstrategies under realistic scenarios.", "AI": {"tldr": "A data-driven, user-centric V2G method balances battery degradation and revenue using multi-objective optimization and ICNNs for accurate, convex degradation modeling.", "motivation": "Addresses the lack of accurate battery degradation models and the need to balance V2G revenue with battery health based on user preferences.", "method": "Uses ICNNs to create a data-driven degradation model and integrates it into a multi-objective optimization framework for smart charging profiles.", "result": "ICNN model accurately predicts degradation; trade-off curves show financial benefits vs. battery health based on user preferences.", "conclusion": "The approach effectively balances V2G revenue and battery degradation, offering customizable smart charging strategies."}}
{"id": "2412.17031", "pdf": "https://arxiv.org/pdf/2412.17031", "abs": "https://arxiv.org/abs/2412.17031", "authors": ["Lovisa Hagstr\u00f6m", "Sara Vera Marjanovi\u0107", "Haeun Yu", "Arnav Arora", "Christina Lioma", "Maria Maistro", "Pepa Atanasova", "Isabelle Augenstein"], "title": "A Reality Check on Context Utilisation for Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at ACL 2025", "summary": "Retrieval-augmented generation (RAG) helps address the limitations of\nparametric knowledge embedded within a language model (LM). In real world\nsettings, retrieved information can vary in complexity, yet most investigations\nof LM utilisation of context has been limited to synthetic text. We introduce\nDRUID (Dataset of Retrieved Unreliable, Insufficient and\nDifficult-to-understand contexts) with real-world queries and contexts manually\nannotated for stance. The dataset is based on the prototypical task of\nautomated claim verification, for which automated retrieval of real-world\nevidence is crucial. We compare DRUID to synthetic datasets (CounterFact,\nConflictQA) and find that artificial datasets often fail to represent the\ncomplexity and diversity of realistically retrieved context. We show that\nsynthetic datasets exaggerate context characteristics rare in real retrieved\ndata, which leads to inflated context utilisation results, as measured by our\nnovel ACU score. Moreover, while previous work has mainly focused on singleton\ncontext characteristics to explain context utilisation, correlations between\nsingleton context properties and ACU on DRUID are surprisingly small compared\nto other properties related to context source. Overall, our work underscores\nthe need for real-world aligned context utilisation studies to represent and\nimprove performance in real-world RAG settings.", "AI": {"tldr": "DRUID dataset introduces real-world annotated contexts for claim verification, highlighting limitations of synthetic datasets in representing complexity and diversity of retrieved information.", "motivation": "To address the gap in real-world context utilization studies in retrieval-augmented generation (RAG) and improve performance in practical settings.", "method": "Creation of DRUID dataset with manually annotated real-world queries and contexts, comparing it to synthetic datasets (CounterFact, ConflictQA) using a novel ACU score.", "result": "Synthetic datasets exaggerate rare context characteristics, inflating context utilization results, while DRUID reveals smaller correlations between singleton context properties and ACU.", "conclusion": "Real-world aligned studies are essential for accurate representation and improvement of RAG performance."}}
{"id": "2405.18734", "pdf": "https://arxiv.org/pdf/2405.18734", "abs": "https://arxiv.org/abs/2405.18734", "authors": ["Sifan Zhou", "Zhihang Yuan", "Dawei Yang", "Ziyu Zhao", "Xing Hu", "Yuguang Shi", "Xiaobo Lu", "Qiang Wu"], "title": "Information Entropy Guided Height-aware Histogram for Quantization-friendly Pillar Feature Encoder", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Real-time and high-performance 3D object detection plays a critical role in\nautonomous driving and robotics. Recent pillar-based 3D object detectors have\ngained significant attention due to their compact representation and low\ncomputational overhead, making them suitable for onboard deployment and\nquantization. However, existing pillar-based detectors still suffer from\ninformation loss along height dimension and large numerical distribution\ndifference during pillar feature encoding (PFE), which severely limits their\nperformance and quantization potential. To address above issue, we first unveil\nthe importance of different input information during PFE and identify the\nheight dimension as a key factor in enhancing 3D detection performance.\nMotivated by this observation, we propose a height-aware pillar feature\nencoder, called PillarHist. Specifically, PillarHist statistics the discrete\ndistribution of points at different heights within one pillar with the\ninformation entropy guidance. This simple yet effective design greatly\npreserves the information along the height dimension while significantly\nreducing the computation overhead of the PFE. Meanwhile, PillarHist also\nconstrains the arithmetic distribution of PFE input to a stable range, making\nit quantization-friendly. Notably, PillarHist operates exclusively within the\nPFE stage to enhance performance, enabling seamless integration into existing\npillar-based methods without introducing complex operations. Extensive\nexperiments show the effectiveness of PillarHist in terms of both efficiency\nand performance.", "AI": {"tldr": "PillarHist, a height-aware pillar feature encoder, addresses information loss and numerical distribution issues in pillar-based 3D object detectors, improving performance and quantization potential.", "motivation": "Existing pillar-based detectors suffer from information loss and numerical distribution differences during pillar feature encoding (PFE), limiting performance and quantization.", "method": "Proposes PillarHist, which uses discrete distribution statistics and information entropy to preserve height dimension information and stabilize PFE input.", "result": "PillarHist enhances performance and efficiency while being quantization-friendly, seamlessly integrating into existing methods.", "conclusion": "PillarHist effectively improves 3D object detection by addressing PFE limitations without adding complexity."}}
{"id": "2505.10034", "pdf": "https://arxiv.org/pdf/2505.10034", "abs": "https://arxiv.org/abs/2505.10034", "authors": ["Changzeng Fu", "Zelin Fu", "Qi Zhang", "Xinhe Kuang", "Jiacheng Dong", "Kaifeng Su", "Yikai Su", "Wenbo Shi", "Junfeng Yao", "Yuliang Zhao", "Shiqi Zhao", "Jiadong Wang", "Siyang Song", "Chaoran Liu", "Yuichiro Yoshikawa", "Bj\u00f6rn Schuller", "Hiroshi Ishiguro"], "title": "The First MPDD Challenge: Multimodal Personality-aware Depression Detection", "categories": ["cs.AI", "68T07", "I.2.0; H.5.1"], "comment": "This paper has been accepted as part of the MPDD Challenge in the\n  ACMMM 2025 Grand Challenge", "summary": "Depression is a widespread mental health issue affecting diverse age groups,\nwith notable prevalence among college students and the elderly. However,\nexisting datasets and detection methods primarily focus on young adults,\nneglecting the broader age spectrum and individual differences that influence\ndepression manifestation. Current approaches often establish a direct mapping\nbetween multimodal data and depression indicators, failing to capture the\ncomplexity and diversity of depression across individuals. This challenge\nincludes two tracks based on age-specific subsets: Track 1 uses the\nMPDD-Elderly dataset for detecting depression in older adults, and Track 2 uses\nthe MPDD-Young dataset for detecting depression in younger participants. The\nMultimodal Personality-aware Depression Detection (MPDD) Challenge aims to\naddress this gap by incorporating multimodal data alongside individual\ndifference factors. We provide a baseline model that fuses audio and video\nmodalities with individual difference information to detect depression\nmanifestations in diverse populations. This challenge aims to promote the\ndevelopment of more personalized and accurate de pression detection methods,\nadvancing mental health research and fostering inclusive detection systems.\nMore details are available on the official challenge website:\nhttps://hacilab.github.io/MPDDChallenge.github.io.", "AI": {"tldr": "The paper introduces the MPDD Challenge to address gaps in depression detection by focusing on diverse age groups and individual differences, using multimodal data and a baseline model.", "motivation": "Existing depression detection methods overlook age diversity and individual differences, limiting their effectiveness across populations.", "method": "The challenge uses two datasets (MPDD-Elderly and MPDD-Young) and a baseline model that fuses audio, video, and individual difference data for depression detection.", "result": "The proposed approach aims to improve personalized and accurate depression detection across diverse age groups.", "conclusion": "The MPDD Challenge seeks to advance mental health research by fostering inclusive and tailored depression detection systems."}}
{"id": "2505.22670", "pdf": "https://arxiv.org/pdf/2505.22670", "abs": "https://arxiv.org/abs/2505.22670", "authors": ["Jin Han", "Xin-Zheng Lu", "Jia-Rui Lin"], "title": "Unified Network-Based Representation of BIM Models for Embedding Semantic, Spatial, and Topological Data", "categories": ["cs.CE", "cs.LG"], "comment": null, "summary": "Building Information Modeling (BIM) has revolutionized the construction\nindustry by providing a comprehensive digital representation of building\nstructures throughout their lifecycle. However, existing research lacks\neffective methods for capturing the complex spatial and topological\nrelationships between components in BIM models, which are essential for\nunderstanding design patterns and enhancing decision-making. This study\nproposes a unified network-based representation method that integrates the\n\"semantic-spatial-topological\" multi-dimensional design features of BIM models.\nBy extending the IFC (Industry Foundation Classes) standard, we introduce local\nspatial relationships and topological connections between components to enrich\nthe network structure. This representation method enables a more detailed\nunderstanding of component interactions, dependencies, and implicit design\npatterns, effectively capturing the semantic, topological, and spatial\nrelationships in BIM, and holds significant potential for the representation\nand learning of design patterns.", "AI": {"tldr": "The paper proposes a network-based method to capture complex spatial and topological relationships in BIM models, enhancing design pattern understanding and decision-making.", "motivation": "Existing research lacks effective methods for capturing spatial and topological relationships in BIM models, which are crucial for design patterns and decision-making.", "method": "A unified network-based representation method is introduced, extending the IFC standard to include local spatial and topological relationships between components.", "result": "The method provides a detailed understanding of component interactions, dependencies, and implicit design patterns in BIM models.", "conclusion": "This approach significantly improves the representation and learning of design patterns in BIM, offering practical benefits for the construction industry."}}
{"id": "2501.06425", "pdf": "https://arxiv.org/pdf/2501.06425", "abs": "https://arxiv.org/abs/2501.06425", "authors": ["Yifan Zhang", "Yifeng Liu", "Huizhuo Yuan", "Zhen Qin", "Yang Yuan", "Quanquan Gu", "Andrew C Yao"], "title": "Tensor Product Attention Is All You Need", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "52 pages, 11 figures", "summary": "Scaling language models to handle longer input sequences typically\nnecessitates large key-value (KV) caches, resulting in substantial memory\noverhead during inference. In this paper, we propose Tensor Product Attention\n(TPA), a novel attention mechanism that uses tensor decompositions to represent\nqueries, keys, and values compactly, substantially shrinking the KV cache size\nat inference time. By factorizing these representations into contextual\nlow-rank components and seamlessly integrating with Rotary Position Embedding\n(RoPE), TPA achieves improved model quality alongside memory efficiency. Based\non TPA, we introduce the Tensor Product Attention Transformer,(T6), a new model\narchitecture for sequence modeling. Through extensive empirical evaluation on\nlanguage modeling tasks, we demonstrate that T6 surpasses or matches the\nperformance of standard Transformer baselines, including Multi-Head Attention\n(MHA), Multi-Query Attention (MQA), Grouped-Query Attention (GQA), and\nMulti-Head Latent Attention (MLA) across various metrics, including perplexity\nand a range of established evaluation benchmarks. Notably, TPA's memory\nefficiency and computational efficiency at the decoding stage enable processing\nlonger sequences under fixed resource constraints, addressing a critical\nscalability challenge in modern language models. The code is available at\nhttps://github.com/tensorgi/T6.", "AI": {"tldr": "Proposes Tensor Product Attention (TPA) to reduce KV cache memory overhead in language models, introducing T6 architecture for efficient long-sequence processing.", "motivation": "Addressing memory inefficiency in scaling language models for longer sequences by reducing KV cache size.", "method": "Uses tensor decompositions for compact query, key, and value representations, integrating with Rotary Position Embedding (RoPE).", "result": "T6 matches or outperforms standard Transformer baselines in performance and efficiency.", "conclusion": "TPA and T6 offer scalable, memory-efficient solutions for long-sequence language modeling."}}
{"id": "2406.16129", "pdf": "https://arxiv.org/pdf/2406.16129", "abs": "https://arxiv.org/abs/2406.16129", "authors": ["Pengfei Zhang", "Chang Li", "Yongjun Zhang", "Rongjun Qin", "Kyle Gao", "Jonathan Li"], "title": "UDHF2-Net: Uncertainty-diffusion-model-based High-Frequency TransFormer Network for Remotely Sensed Imagery Interpretation", "categories": ["cs.CV"], "comment": null, "summary": "Remotely sensed imagery interpretation (RSII) faces the three major problems:\n(1) objective representation of spatial distribution patterns; (2) edge\nuncertainty problem caused by downsampling encoder and intrinsic edge noises\n(e.g., mixed pixel and edge occlusion etc.); and (3) false detection problem\ncaused by geometric registration error in change detection. To solve the\naforementioned problems, uncertainty-diffusion-model-based high-Frequency\nTransFormer network (UDHF2-Net) is the first to be proposed, whose\nsuperiorities are as follows: (1) a spatially-stationary-and-non-stationary\nhigh-frequency connection paradigm (SHCP) is proposed to enhance the\ninteraction of spatially frequency-wise stationary and non-stationary features\nto yield high-fidelity edge extraction result. Inspired by HRFormer, SHCP\nproposes high-frequency-wise stream to replace high-resolution-wise stream in\nHRFormer through the whole encoder-decoder process with parallel frequency-wise\nhigh-to-low streams, so it improves the edge extraction accuracy by\ncontinuously remaining high-frequency information; (2) a\nmask-and-geo-knowledge-based uncertainty diffusion module (MUDM), which is a\nself-supervised learning strategy, is proposed to improve the edge accuracy of\nextraction and change detection by gradually removing the simulated spectrum\nnoises based on geo-knowledge and the generated diffused spectrum noises; (3) a\nfrequency-wise semi-pseudo-Siamese UDHF2-Net is the first to be proposed to\nbalance accuracy and complexity for change detection. Besides the\naforementioned spectrum noises in semantic segmentation, MUDM is also a\nself-supervised learning strategy to effectively reduce the edge false change\ndetection from the generated imagery with geometric registration error.", "AI": {"tldr": "The paper proposes UDHF2-Net to address RSII problems like edge uncertainty and false detection, using SHCP for edge extraction, MUDM for noise reduction, and a semi-pseudo-Siamese network for change detection.", "motivation": "To solve key challenges in RSII: spatial distribution representation, edge uncertainty, and false detection in change detection.", "method": "UDHF2-Net integrates SHCP for high-frequency edge extraction, MUDM for noise diffusion, and a semi-pseudo-Siamese network for balanced change detection.", "result": "Improved edge extraction accuracy and reduced false detection in change detection tasks.", "conclusion": "UDHF2-Net effectively addresses RSII problems with innovative frequency-wise and self-supervised techniques."}}
{"id": "2505.11942", "pdf": "https://arxiv.org/pdf/2505.11942", "abs": "https://arxiv.org/abs/2505.11942", "authors": ["Junhao Zheng", "Xidi Cai", "Qiuke Li", "Duzhen Zhang", "ZhongZhi Li", "Yingying Zhang", "Le Song", "Qianli Ma"], "title": "LifelongAgentBench: Evaluating LLM Agents as Lifelong Learners", "categories": ["cs.AI"], "comment": null, "summary": "Lifelong learning is essential for intelligent agents operating in dynamic\nenvironments. Current large language model (LLM)-based agents, however, remain\nstateless and unable to accumulate or transfer knowledge over time. Existing\nbenchmarks treat agents as static systems and fail to evaluate lifelong\nlearning capabilities. We present LifelongAgentBench, the first unified\nbenchmark designed to systematically assess the lifelong learning ability of\nLLM agents. It provides skill-grounded, interdependent tasks across three\ninteractive environments, Database, Operating System, and Knowledge Graph, with\nautomatic label verification, reproducibility, and modular extensibility.\nExtensive experiments reveal that conventional experience replay has limited\neffectiveness for LLM agents due to irrelevant information and context length\nconstraints. We further introduce a group self-consistency mechanism that\nsignificantly improves lifelong learning performance. We hope\nLifelongAgentBench will advance the development of adaptive, memory-capable LLM\nagents.", "AI": {"tldr": "LifelongAgentBench is introduced as the first benchmark to evaluate lifelong learning in LLM agents, addressing limitations of static systems and proposing a group self-consistency mechanism for improved performance.", "motivation": "Current LLM agents lack lifelong learning capabilities, and existing benchmarks fail to assess this. The need for adaptive, memory-capable agents drives the creation of LifelongAgentBench.", "method": "LifelongAgentBench provides skill-grounded, interdependent tasks across three environments (Database, Operating System, Knowledge Graph) with automatic verification and modular extensibility. A group self-consistency mechanism is introduced to enhance learning.", "result": "Experiments show conventional experience replay is ineffective for LLM agents due to irrelevant information and context limits. The proposed mechanism significantly boosts lifelong learning performance.", "conclusion": "LifelongAgentBench aims to advance adaptive LLM agents by providing a unified benchmark and demonstrating the effectiveness of the new self-consistency mechanism."}}
{"id": "2505.22678", "pdf": "https://arxiv.org/pdf/2505.22678", "abs": "https://arxiv.org/abs/2505.22678", "authors": ["Jiahao Yang", "Ran Fang", "Ming Zhang", "Jun Zhou"], "title": "An Efficient deep learning model to Predict Stock Price Movement Based on Limit Order Book", "categories": ["q-fin.TR", "cs.LG"], "comment": null, "summary": "In high-frequency trading (HFT), leveraging limit order books (LOB) to model\nstock price movements is crucial for achieving profitable outcomes. However,\nthis task is challenging due to the high-dimensional and volatile nature of the\noriginal data. Even recent deep learning models often struggle to capture price\nmovement patterns effectively, particularly without well-designed features. We\nobserved that raw LOB data exhibits inherent symmetry between the ask and bid\nsides, and the bid-ask differences demonstrate greater stability and lower\ncomplexity compared to the original data. Building on this insight, we propose\na novel approach in which leverages the Siamese architecture to enhance the\nperformance of existing deep learning models. The core idea involves processing\nthe ask and bid sides separately using the same module with shared parameters.\nWe applied our Siamese-based methods to several widely used strong baselines\nand validated their effectiveness using data from 14 military industry stocks\nin the Chinese A-share market. Furthermore, we integrated multi-head attention\n(MHA) mechanisms with the Long Short-Term Memory (LSTM) module to investigate\nits role in modeling stock price movements. Our experiments used raw data and\nwidely used Order Flow Imbalance (OFI) features as input with some strong\nbaseline models. The results show that our method improves the performance of\nstrong baselines in over 75$% of cases, excluding the Multi-Layer Perception\n(MLP) baseline, which performed poorly and is not considered practical.\nFurthermore, we found that Multi-Head Attention can enhance model performance,\nparticularly over shorter forecasting horizons.", "AI": {"tldr": "A Siamese architecture and multi-head attention (MHA) are proposed to improve deep learning models for high-frequency trading by leveraging symmetry in limit order books (LOB) and enhancing performance in stock price prediction.", "motivation": "High-dimensional and volatile raw LOB data makes stock price modeling challenging, and existing deep learning models often fail without well-designed features. The symmetry and stability in bid-ask differences inspired a new approach.", "method": "The Siamese architecture processes ask and bid sides separately with shared parameters. MHA is integrated with LSTM to model stock price movements. Experiments used raw LOB data and OFI features.", "result": "The method improved baseline performance in over 75% of cases, excluding MLP. MHA enhanced performance, especially for shorter forecasting horizons.", "conclusion": "The proposed Siamese and MHA approach effectively enhances deep learning models for HFT, demonstrating better performance and practical utility."}}
{"id": "2501.08319", "pdf": "https://arxiv.org/pdf/2501.08319", "abs": "https://arxiv.org/abs/2501.08319", "authors": ["Yoav Gur-Arieh", "Roy Mayan", "Chen Agassy", "Atticus Geiger", "Mor Geva"], "title": "Enhancing Automated Interpretability with Output-Centric Feature Descriptions", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Main Conference", "summary": "Automated interpretability pipelines generate natural language descriptions\nfor the concepts represented by features in large language models (LLMs), such\nas plants or the first word in a sentence. These descriptions are derived using\ninputs that activate the feature, which may be a dimension or a direction in\nthe model's representation space. However, identifying activating inputs is\ncostly, and the mechanistic role of a feature in model behavior is determined\nboth by how inputs cause a feature to activate and by how feature activation\naffects outputs. Using steering evaluations, we reveal that current pipelines\nprovide descriptions that fail to capture the causal effect of the feature on\noutputs. To fix this, we propose efficient, output-centric methods for\nautomatically generating feature descriptions. These methods use the tokens\nweighted higher after feature stimulation or the highest weight tokens after\napplying the vocabulary \"unembedding\" head directly to the feature. Our\noutput-centric descriptions better capture the causal effect of a feature on\nmodel outputs than input-centric descriptions, but combining the two leads to\nthe best performance on both input and output evaluations. Lastly, we show that\noutput-centric descriptions can be used to find inputs that activate features\npreviously thought to be \"dead\".", "AI": {"tldr": "The paper critiques current automated interpretability pipelines for LLMs, proposing output-centric methods to improve feature descriptions by capturing causal effects on outputs. Combining input and output-centric approaches yields the best results.", "motivation": "Current pipelines for generating feature descriptions in LLMs focus on input activation but fail to account for the causal impact of features on outputs, limiting interpretability.", "method": "The authors introduce output-centric methods, such as analyzing tokens weighted higher after feature stimulation or applying the vocabulary 'unembedding' head directly to features.", "result": "Output-centric descriptions better capture causal effects on outputs than input-centric ones, with combined methods performing best. They also help identify inputs for 'dead' features.", "conclusion": "Output-centric approaches enhance interpretability by addressing causal effects, and combining them with input-centric methods optimizes performance."}}
{"id": "2407.09946", "pdf": "https://arxiv.org/pdf/2407.09946", "abs": "https://arxiv.org/abs/2407.09946", "authors": ["Yibo Zhong", "Jinman Zhao", "Yao Zhou"], "title": "Low-Rank Interconnected Adaptation across Layers", "categories": ["cs.CV"], "comment": "Accepted to ACL 2025 (findings, long paper)", "summary": "Low-rank adaptation (LoRA) is a widely used parameter-efficient fine-tuning\n(PEFT) method that learns weight updates $\\Delta W = AB$ for pretrained weights\n$W$ through low-rank adapters $A$ and $B$. While LoRA ensures hardware\nefficiency, its low-rank weight updates limit adaptation performance. In this\npaper, we propose low-rank interconnected adaptation across layers (Lily), a\nnovel PEFT method that introduces an interconnected framework with locally\nshared $A$ and globally shared $B$ experts. This structure eliminates redundant\nper-layer $AB$ pairs, enabling higher-rank $\\Delta W$ with equal or fewer\nparameters. To enhance expressiveness, we use data-dependent routers to\ndetermine $A$-$B$ interconnections, preventing $B$ experts from converging to\nthe same behavior and improving representational power across domains.\nExperiments across modalities, architectures, and model sizes demonstrate\nLily's superior performance and efficiency. GitHub:\nhttps://github.com/yibozhong/lily", "AI": {"tldr": "Lily, a novel PEFT method, improves upon LoRA by introducing interconnected low-rank adapters with shared experts, enhancing adaptation performance without increasing parameters.", "motivation": "LoRA's low-rank weight updates limit adaptation performance, prompting the need for a more efficient and expressive PEFT method.", "method": "Lily uses locally shared A and globally shared B experts, with data-dependent routers to determine A-B interconnections, avoiding redundancy and improving representational power.", "result": "Experiments show Lily outperforms LoRA in performance and efficiency across various modalities, architectures, and model sizes.", "conclusion": "Lily offers a superior PEFT method by enabling higher-rank weight updates with fewer parameters, enhancing adaptation performance."}}
{"id": "2505.13774", "pdf": "https://arxiv.org/pdf/2505.13774", "abs": "https://arxiv.org/abs/2505.13774", "authors": ["Zidi Xiong", "Shan Chen", "Zhenting Qi", "Himabindu Lakkaraju"], "title": "Measuring the Faithfulness of Thinking Drafts in Large Reasoning Models", "categories": ["cs.AI"], "comment": null, "summary": "Large Reasoning Models (LRMs) have significantly enhanced their capabilities\nin complex problem-solving by introducing a thinking draft that enables\nmulti-path Chain-of-Thought explorations before producing final answers.\nEnsuring the faithfulness of these intermediate reasoning processes is crucial\nfor reliable monitoring, interpretation, and effective control. In this paper,\nwe propose a systematic counterfactual intervention framework to rigorously\nevaluate thinking draft faithfulness. Our approach focuses on two complementary\ndimensions: (1) Intra-Draft Faithfulness, which assesses whether individual\nreasoning steps causally influence subsequent steps and the final draft\nconclusion through counterfactual step insertions; and (2) Draft-to-Answer\nFaithfulness, which evaluates whether final answers are logically consistent\nwith and dependent on the thinking draft, by perturbing the draft's concluding\nlogic. We conduct extensive experiments across six state-of-the-art LRMs. Our\nfindings show that current LRMs demonstrate selective faithfulness to\nintermediate reasoning steps and frequently fail to faithfully align with the\ndraft conclusions. These results underscore the need for more faithful and\ninterpretable reasoning in advanced LRMs.", "AI": {"tldr": "The paper proposes a counterfactual intervention framework to evaluate the faithfulness of intermediate reasoning steps in Large Reasoning Models (LRMs), revealing selective faithfulness and frequent misalignment with draft conclusions.", "motivation": "To ensure reliable monitoring, interpretation, and control of LRMs by rigorously evaluating the faithfulness of their intermediate reasoning processes.", "method": "A systematic counterfactual intervention framework assessing Intra-Draft Faithfulness (causal influence of steps) and Draft-to-Answer Faithfulness (logical consistency with draft conclusions).", "result": "Experiments on six LRMs show selective faithfulness to reasoning steps and frequent misalignment with draft conclusions.", "conclusion": "The findings highlight the need for more faithful and interpretable reasoning in advanced LRMs."}}
{"id": "2505.22684", "pdf": "https://arxiv.org/pdf/2505.22684", "abs": "https://arxiv.org/abs/2505.22684", "authors": ["Yufeng Wang", "Yiguang Bai", "Tianqing Zhu", "Ismail Ben Ayed", "Jing Yuan"], "title": "Recovering Fairness Directly from Modularity: a New Way for Fair Community Partitioning", "categories": ["cs.SI", "cs.LG"], "comment": "17pages, 5 figures", "summary": "Community partitioning is crucial in network analysis, with modularity\noptimization being the prevailing technique. However, traditional\nmodularity-based methods often overlook fairness, a critical aspect in\nreal-world applications. To address this, we introduce protected group networks\nand propose a novel fairness-modularity metric. This metric extends traditional\nmodularity by explicitly incorporating fairness, and we prove that minimizing\nit yields naturally fair partitions for protected groups while maintaining\ntheoretical soundness. We develop a general optimization framework for fairness\npartitioning and design the efficient Fair Fast Newman (FairFN) algorithm,\nenhancing the Fast Newman (FN) method to optimize both modularity and fairness.\nExperiments show FairFN achieves significantly improved fairness and\nhigh-quality partitions compared to state-of-the-art methods, especially on\nunbalanced datasets.", "AI": {"tldr": "The paper introduces a fairness-modularity metric for community partitioning, addressing fairness gaps in traditional methods, and proposes the FairFN algorithm to optimize both modularity and fairness.", "motivation": "Traditional modularity-based community partitioning methods often ignore fairness, which is critical in real-world applications. This work aims to bridge this gap.", "method": "The authors propose a fairness-modularity metric and develop the FairFN algorithm, an extension of Fast Newman (FN), to optimize both modularity and fairness.", "result": "Experiments show FairFN improves fairness and partition quality, especially on unbalanced datasets, outperforming state-of-the-art methods.", "conclusion": "The fairness-modularity metric and FairFN algorithm effectively address fairness in community partitioning while maintaining high-quality results."}}
{"id": "2501.13977", "pdf": "https://arxiv.org/pdf/2501.13977", "abs": "https://arxiv.org/abs/2501.13977", "authors": ["Rajvardhan Oak", "Muhammad Haroon", "Claire Jo", "Magdalena Wojcieszak", "Anshuman Chhabra"], "title": "Re-ranking Using Large Language Models for Mitigating Exposure to Harmful Content on Social Media Platforms", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.SI"], "comment": "Accepted to ACL 2025 Main Conference", "summary": "Social media platforms utilize Machine Learning (ML) and Artificial\nIntelligence (AI) powered recommendation algorithms to maximize user\nengagement, which can result in inadvertent exposure to harmful content.\nCurrent moderation efforts, reliant on classifiers trained with extensive\nhuman-annotated data, struggle with scalability and adapting to new forms of\nharm. To address these challenges, we propose a novel re-ranking approach using\nLarge Language Models (LLMs) in zero-shot and few-shot settings. Our method\ndynamically assesses and re-ranks content sequences, effectively mitigating\nharmful content exposure without requiring extensive labeled data. Alongside\ntraditional ranking metrics, we also introduce two new metrics to evaluate the\neffectiveness of re-ranking in reducing exposure to harmful content. Through\nexperiments on three datasets, three models and across three configurations, we\ndemonstrate that our LLM-based approach significantly outperforms existing\nproprietary moderation approaches, offering a scalable and adaptable solution\nfor harm mitigation.", "AI": {"tldr": "A novel LLM-based re-ranking method reduces harmful content exposure on social media without needing extensive labeled data, outperforming current moderation approaches.", "motivation": "Current ML/AI moderation struggles with scalability and adapting to new harms, necessitating a more adaptable solution.", "method": "Proposes a zero-shot and few-shot LLM-based re-ranking approach to dynamically assess and re-rank content sequences.", "result": "Outperforms proprietary moderation methods in experiments across datasets, models, and configurations.", "conclusion": "Offers a scalable, adaptable solution for mitigating harmful content exposure on social media."}}
{"id": "2409.04003", "pdf": "https://arxiv.org/pdf/2409.04003", "abs": "https://arxiv.org/abs/2409.04003", "authors": ["Jianbiao Mei", "Tao Hu", "Xuemeng Yang", "Licheng Wen", "Yu Yang", "Tiantian Wei", "Yukai Ma", "Min Dou", "Botian Shi", "Yong Liu"], "title": "DreamForge: Motion-Aware Autoregressive Video Generation for Multi-View Driving Scenes", "categories": ["cs.CV"], "comment": "15 figures, 11 tables", "summary": "Recent advances in diffusion models have improved controllable streetscape\ngeneration and supported downstream perception and planning tasks. However,\nchallenges remain in accurately modeling driving scenes and generating long\nvideos. To alleviate these issues, we propose DreamForge, an advanced\ndiffusion-based autoregressive video generation model tailored for\n3D-controllable long-term generation. To enhance the lane and foreground\ngeneration, we introduce perspective guidance and integrate object-wise\nposition encoding to incorporate local 3D correlation and improve foreground\nobject modeling. We also propose motion-aware temporal attention to capture\nmotion cues and appearance changes in videos. By leveraging motion frames and\nan autoregressive generation paradigm,we can autoregressively generate long\nvideos (over 200 frames) using a model trained in short sequences, achieving\nsuperior quality compared to the baseline in 16-frame video evaluations.\nFinally, we integrate our method with the realistic simulator DriveArena to\nprovide more reliable open-loop and closed-loop evaluations for vision-based\ndriving agents. Project Page:\nhttps://pjlab-adg.github.io/DriveArena/dreamforge.", "AI": {"tldr": "DreamForge is a diffusion-based autoregressive model for generating long, 3D-controllable driving scene videos, improving lane and foreground generation with perspective guidance and object-wise encoding, and enhancing motion modeling with temporal attention.", "motivation": "Addressing challenges in accurately modeling driving scenes and generating long videos using diffusion models.", "method": "Proposes DreamForge with perspective guidance, object-wise position encoding, and motion-aware temporal attention for autoregressive long-video generation.", "result": "Generates high-quality long videos (over 200 frames) from short-sequence training, outperforming baselines in 16-frame evaluations.", "conclusion": "DreamForge advances controllable streetscape generation and integrates with DriveArena for reliable evaluation of vision-based driving agents."}}
{"id": "2505.14020", "pdf": "https://arxiv.org/pdf/2505.14020", "abs": "https://arxiv.org/abs/2505.14020", "authors": ["Hao Dong", "Ziyue Qiao", "Zhiyuan Ning", "Qi Hao", "Yi Du", "Pengyang Wang", "Yuanchun Zhou"], "title": "Disentangled Multi-span Evolutionary Network against Temporal Knowledge Graph Reasoning", "categories": ["cs.AI", "cs.IR", "cs.LG"], "comment": "Accepted to ACL 2025 Findings", "summary": "Temporal Knowledge Graphs (TKGs), as an extension of static Knowledge Graphs\n(KGs), incorporate the temporal feature to express the transience of knowledge\nby describing when facts occur. TKG extrapolation aims to infer possible future\nfacts based on known history, which has garnered significant attention in\nrecent years. Some existing methods treat TKG as a sequence of independent\nsubgraphs to model temporal evolution patterns, demonstrating impressive\nreasoning performance. However, they still have limitations: 1) In modeling\nsubgraph semantic evolution, they usually neglect the internal structural\ninteractions between subgraphs, which are actually crucial for encoding TKGs.\n2) They overlook the potential smooth features that do not lead to semantic\nchanges, which should be distinguished from the semantic evolution process.\nTherefore, we propose a novel Disentangled Multi-span Evolutionary Network\n(DiMNet) for TKG reasoning. Specifically, we design a multi-span evolution\nstrategy that captures local neighbor features while perceiving historical\nneighbor semantic information, thus enabling internal interactions between\nsubgraphs during the evolution process. To maximize the capture of semantic\nchange patterns, we design a disentangle component that adaptively separates\nnodes' active and stable features, used to dynamically control the influence of\nhistorical semantics on future evolution. Extensive experiments conducted on\nfour real-world TKG datasets show that DiMNet demonstrates substantial\nperformance in TKG reasoning, and outperforms the state-of-the-art up to 22.7%\nin MRR.", "AI": {"tldr": "DiMNet improves TKG reasoning by capturing subgraph interactions and distinguishing stable vs. active features, achieving up to 22.7% better MRR.", "motivation": "Existing TKG methods ignore subgraph interactions and smooth features, limiting reasoning performance.", "method": "DiMNet uses a multi-span evolution strategy and disentangle component to model subgraph interactions and separate active/stable features.", "result": "DiMNet outperforms state-of-the-art methods by up to 22.7% in MRR on four datasets.", "conclusion": "DiMNet effectively addresses limitations in TKG reasoning by capturing semantic evolution and feature disentanglement."}}
{"id": "2505.22688", "pdf": "https://arxiv.org/pdf/2505.22688", "abs": "https://arxiv.org/abs/2505.22688", "authors": ["Palur Venkata Raghuvamsi", "Siyuan Brandon Loh", "Prasanta Bhattacharya", "Joses Ho", "Raphael Lee Tze Chuen", "Alvin X. Han", "Sebastian Maurer-Stroh"], "title": "Investigating the effectiveness of multimodal data in forecasting SARS-COV-2 case surges", "categories": ["q-bio.QM", "cs.LG", "stat.ML"], "comment": null, "summary": "The COVID-19 pandemic response relied heavily on statistical and machine\nlearning models to predict key outcomes such as case prevalence and fatality\nrates. These predictions were instrumental in enabling timely public health\ninterventions that helped break transmission cycles. While most existing models\nare grounded in traditional epidemiological data, the potential of alternative\ndatasets, such as those derived from genomic information and human behavior,\nremains underexplored. In the current study, we investigated the usefulness of\ndiverse modalities of feature sets in predicting case surges. Our results\nhighlight the relative effectiveness of biological (e.g., mutations), public\nhealth (e.g., case counts, policy interventions) and human behavioral features\n(e.g., mobility and social media conversations) in predicting country-level\ncase surges. Importantly, we uncover considerable heterogeneity in predictive\nperformance across countries and feature modalities, suggesting that surge\nprediction models may need to be tailored to specific national contexts and\npandemic phases. Overall, our work highlights the value of integrating\nalternative data sources into existing disease surveillance frameworks to\nenhance the prediction of pandemic dynamics.", "AI": {"tldr": "The paper explores using diverse datasets (genomic, public health, behavioral) to predict COVID-19 case surges, finding variability in effectiveness across countries and features.", "motivation": "To improve pandemic response by leveraging underutilized data sources beyond traditional epidemiological data.", "method": "Investigated biological, public health, and behavioral features for predicting case surges at the country level.", "result": "Found heterogeneity in predictive performance, suggesting the need for context-specific models.", "conclusion": "Integrating alternative data sources can enhance pandemic prediction and surveillance."}}
{"id": "2501.13978", "pdf": "https://arxiv.org/pdf/2501.13978", "abs": "https://arxiv.org/abs/2501.13978", "authors": ["Sangyeop Yeo", "Seung-won Hwang", "Yu-Seung Ma"], "title": "Chain of Grounded Objectives: Bridging Process and Goal-oriented Prompting for Code Generation", "categories": ["cs.CL", "cs.AI", "cs.SE"], "comment": "Accepted by ECOOP 2025 main conference", "summary": "The use of Large Language Models (LLMs) for code generation has gained\nsignificant attention in recent years. Existing methods often aim to improve\nthe quality of generated code by incorporating additional contextual\ninformation or guidance into input prompts. Many of these approaches adopt\nsequential reasoning strategies, mimicking human-like step-by-step thinking.\nHowever, such strategies may constrain flexibility, as they do not always align\nwith the structured characteristics of programming languages. This paper\nintroduces the Chain of Grounded Objectives (CGO), a method that embeds\nfunctional objectives into input prompts to enhance code generation. By\nleveraging appropriately structured objectives as input and avoiding explicit\nsequential procedures, CGO adapts effectively to the structured nature of\nprogramming tasks. Empirical evaluations demonstrate that CGO effectively\nenhances code generation, addressing limitations of existing approaches.", "AI": {"tldr": "CGO (Chain of Grounded Objectives) improves LLM-based code generation by embedding functional objectives into prompts, avoiding rigid sequential reasoning.", "motivation": "Existing sequential reasoning methods for code generation lack flexibility and don't align well with programming languages' structured nature.", "method": "CGO embeds functional objectives into input prompts, avoiding explicit sequential steps, to better suit programming tasks.", "result": "Empirical evaluations show CGO enhances code generation, overcoming limitations of current approaches.", "conclusion": "CGO offers a more adaptable and effective method for improving LLM-based code generation by leveraging structured objectives."}}
{"id": "2409.13366", "pdf": "https://arxiv.org/pdf/2409.13366", "abs": "https://arxiv.org/abs/2409.13366", "authors": ["Wenhui Diao", "Haichen Yu", "Kaiyue Kang", "Tong Ling", "Di Liu", "Yingchao Feng", "Hanbo Bi", "Libo Ren", "Xuexue Li", "Yongqiang Mao", "Xian Sun"], "title": "RingMo-Aerial: An Aerial Remote Sensing Foundation Model With Affine Transformation Contrastive Learning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Aerial Remote Sensing (ARS) vision tasks pose significant challenges due to\nthe unique characteristics of their viewing angles. Existing research has\nprimarily focused on algorithms for specific tasks, which have limited\napplicability in a broad range of ARS vision applications. This paper proposes\nthe RingMo-Aerial model, aiming to fill the gap in foundation model research in\nthe field of ARS vision. By introducing the Frequency-Enhanced Multi-Head\nSelf-Attention (FE-MSA) mechanism and an affine transformation-based\ncontrastive learning pre-training method, the model's detection capability for\nsmall targets is enhanced and optimized for the tilted viewing angles\ncharacteristic of ARS. Furthermore, the ARS-Adapter, an efficient parameter\nfine-tuning method, is proposed to improve the model's adaptability and\neffectiveness in various ARS vision tasks. Experimental results demonstrate\nthat RingMo-Aerial achieves SOTA performance on multiple downstream tasks. This\nindicates the practicality and efficacy of RingMo-Aerial in enhancing the\nperformance of ARS vision tasks.", "AI": {"tldr": "RingMo-Aerial, a foundation model for Aerial Remote Sensing (ARS) vision, introduces FE-MSA and contrastive learning to improve small target detection and adaptability for tilted angles. ARS-Adapter enhances task-specific performance, achieving SOTA results.", "motivation": "Existing ARS vision algorithms are task-specific and lack broad applicability. This paper aims to develop a foundation model to address these limitations.", "method": "Proposes RingMo-Aerial with FE-MSA and affine transformation-based contrastive learning. Introduces ARS-Adapter for efficient fine-tuning.", "result": "Achieves SOTA performance on multiple downstream ARS vision tasks.", "conclusion": "RingMo-Aerial is practical and effective for enhancing ARS vision performance."}}
{"id": "2505.15929", "pdf": "https://arxiv.org/pdf/2505.15929", "abs": "https://arxiv.org/abs/2505.15929", "authors": ["Hui Shen", "Taiqiang Wu", "Qi Han", "Yunta Hsieh", "Jizhou Wang", "Yuyue Zhang", "Yuxin Cheng", "Zijian Hao", "Yuansheng Ni", "Xin Wang", "Zhongwei Wan", "Kai Zhang", "Wendong Xu", "Jing Xiong", "Ping Luo", "Wenhu Chen", "Chaofan Tao", "Zhuoqing Mao", "Ngai Wong"], "title": "PhyX: Does Your Model Have the \"Wits\" for Physical Reasoning?", "categories": ["cs.AI"], "comment": null, "summary": "Existing benchmarks fail to capture a crucial aspect of intelligence:\nphysical reasoning, the integrated ability to combine domain knowledge,\nsymbolic reasoning, and understanding of real-world constraints. To address\nthis gap, we introduce PhyX: the first large-scale benchmark designed to assess\nmodels capacity for physics-grounded reasoning in visual scenarios. PhyX\nincludes 3K meticulously curated multimodal questions spanning 6 reasoning\ntypes across 25 sub-domains and 6 core physics domains: thermodynamics,\nelectromagnetism, mechanics, modern physics, optics, and wave\\&acoustics. In\nour comprehensive evaluation, even state-of-the-art models struggle\nsignificantly with physical reasoning. GPT-4o, Claude3.7-Sonnet, and\nGPT-o4-mini achieve only 32.5%, 42.2%, and 45.8% accuracy\nrespectively-performance gaps exceeding 29% compared to human experts. Our\nanalysis exposes critical limitations in current models: over-reliance on\nmemorized disciplinary knowledge, excessive dependence on mathematical\nformulations, and surface-level visual pattern matching rather than genuine\nphysical understanding. We provide in-depth analysis through fine-grained\nstatistics, detailed case studies, and multiple evaluation paradigms to\nthoroughly examine physical reasoning capabilities. To ensure reproducibility,\nwe implement a compatible evaluation protocol based on widely-used toolkits\nsuch as VLMEvalKit, enabling one-click evaluation. More details are available\non our project page: https://phyx-bench.github.io/.", "AI": {"tldr": "PhyX is a new benchmark for physics-grounded reasoning in visual scenarios, revealing significant gaps in current AI models' abilities compared to humans.", "motivation": "Existing benchmarks lack focus on physical reasoning, a key aspect of intelligence, prompting the creation of PhyX.", "method": "PhyX includes 3K multimodal questions across 6 physics domains, evaluated using state-of-the-art models and human experts.", "result": "Top models like GPT-4o and Claude3.7-Sonnet perform poorly (32.5%-45.8% accuracy), lagging behind humans by over 29%.", "conclusion": "Current models rely too much on memorization and math, lacking genuine physical understanding; PhyX provides a reproducible evaluation framework."}}
{"id": "2505.22743", "pdf": "https://arxiv.org/pdf/2505.22743", "abs": "https://arxiv.org/abs/2505.22743", "authors": ["Sitan Chen", "Weiyuan Gong", "Jonas Haferkamp", "Yihui Quek"], "title": "Information-Computation Gaps in Quantum Learning via Low-Degree Likelihood", "categories": ["quant-ph", "cs.CC", "cs.DS", "cs.LG"], "comment": "88 pages, 2 figures", "summary": "In a variety of physically relevant settings for learning from quantum data,\ndesigning protocols that can computationally efficiently extract information\nremains largely an art, and there are important cases where we believe this to\nbe impossible, that is, where there is an information-computation gap. While\nthere is a large array of tools in the classical literature for giving evidence\nfor average-case hardness of statistical inference problems, the corresponding\ntools in the quantum literature are far more limited. One such framework in the\nclassical literature, the low-degree method, makes predictions about hardness\nof inference problems based on the failure of estimators given by low-degree\npolynomials. In this work, we extend this framework to the quantum setting.\n  We establish a general connection between state designs and low-degree\nhardness. We use this to obtain the first information-computation gaps for\nlearning Gibbs states of random, sparse, non-local Hamiltonians. We also use it\nto prove hardness for learning random shallow quantum circuit states in a\nchallenging model where states can be measured in adaptively chosen bases. To\nour knowledge, the ability to model adaptivity within the low-degree framework\nwas open even in classical settings. In addition, we also obtain a low-degree\nhardness result for quantum error mitigation against strategies with\nsingle-qubit measurements.\n  We define a new quantum generalization of the planted biclique problem and\nidentify the threshold at which this problem becomes computationally hard for\nprotocols that perform local measurements. Interestingly, the complexity\nlandscape for this problem shifts when going from local measurements to more\nentangled single-copy measurements.\n  We show average-case hardness for the \"standard\" variant of Learning\nStabilizers with Noise and for agnostically learning product states.", "AI": {"tldr": "The paper extends the classical low-degree method to quantum settings, establishing connections between state designs and low-degree hardness, and identifies information-computation gaps for learning quantum states and circuits.", "motivation": "To address the lack of tools for proving average-case hardness in quantum inference problems, the paper aims to extend the classical low-degree framework to quantum data.", "method": "The authors generalize the low-degree method to quantum settings, linking state designs to low-degree hardness, and apply it to learning Gibbs states, shallow quantum circuits, and quantum error mitigation.", "result": "They demonstrate information-computation gaps for learning random Hamiltonians and shallow circuits, and prove hardness for adaptive measurement models and quantum error mitigation.", "conclusion": "The work provides new tools for analyzing quantum inference problems, revealing computational hardness thresholds and shifting complexity landscapes for quantum learning tasks."}}
{"id": "2501.17191", "pdf": "https://arxiv.org/pdf/2501.17191", "abs": "https://arxiv.org/abs/2501.17191", "authors": ["Miao Li", "Jey Han Lau", "Eduard Hovy", "Mirella Lapata"], "title": "Decomposed Opinion Summarization with Verified Aspect-Aware Modules", "categories": ["cs.CL", "cs.IR"], "comment": "37 pages, long paper, present at ACL 2025", "summary": "Opinion summarization plays a key role in deriving meaningful insights from\nlarge-scale online reviews. To make the process more explainable and grounded,\nwe propose a domain-agnostic modular approach guided by review aspects (e.g.,\ncleanliness for hotel reviews) which separates the tasks of aspect\nidentification, opinion consolidation, and meta-review synthesis to enable\ngreater transparency and ease of inspection. We conduct extensive experiments\nacross datasets representing scientific research, business, and product\ndomains. Results show that our approach generates more grounded summaries\ncompared to strong baseline models, as verified through automated and human\nevaluations. Additionally, our modular approach, which incorporates reasoning\nbased on review aspects, produces more informative intermediate outputs than\nother knowledge-agnostic decomposition approaches. Lastly, we provide empirical\nresults to show that these intermediate outputs can support humans in\nsummarizing opinions from large volumes of reviews.", "AI": {"tldr": "A modular, domain-agnostic approach for opinion summarization improves transparency and grounding by separating aspect identification, opinion consolidation, and meta-review synthesis.", "motivation": "To enhance explainability and grounding in opinion summarization from large-scale reviews.", "method": "Proposes a modular approach with distinct tasks: aspect identification, opinion consolidation, and meta-review synthesis. Evaluated across multiple domains.", "result": "Generates more grounded summaries than baselines, with informative intermediate outputs. Supports human summarization.", "conclusion": "The modular approach improves transparency and utility in opinion summarization, validated by empirical results."}}
{"id": "2410.06126", "pdf": "https://arxiv.org/pdf/2410.06126", "abs": "https://arxiv.org/abs/2410.06126", "authors": ["Yize Chen", "Zhiyuan Yan", "Guangliang Cheng", "Kangran Zhao", "Siwei Lyu", "Baoyuan Wu"], "title": "X2-DFD: A framework for eXplainable and eXtendable Deepfake Detection", "categories": ["cs.CV"], "comment": null, "summary": "This paper proposes X2-DFD, an eXplainable and eXtendable framework based on\nmultimodal large-language models (MLLMs) for deepfake detection, consisting of\nthree key stages. The first stage, Model Feature Assessment, systematically\nevaluates the detectability of forgery-related features for the MLLM,\ngenerating a prioritized ranking of features based on their intrinsic\nimportance to the model. The second stage, Explainable Dataset Construction,\nconsists of two key modules: Strong Feature Strengthening, which is designed to\nenhance the model's existing detection and explanation capabilities by\nreinforcing its well-learned features, and Weak Feature Supplementing, which\naddresses gaps by integrating specific feature detectors (e.g., low-level\nartifact analyzers) to compensate for the MLLM's limitations. The third stage,\nFine-tuning and Inference, involves fine-tuning the MLLM on the constructed\ndataset and deploying it for final detection and explanation. By integrating\nthese three stages, our approach enhances the MLLM's strengths while\nsupplementing its weaknesses, ultimately improving both the detectability and\nexplainability. Extensive experiments and ablations, followed by a\ncomprehensive human study, validate the improved performance of our approach\ncompared to the original MLLMs. More encouragingly, our framework is designed\nto be plug-and-play, allowing it to seamlessly integrate with future more\nadvanced MLLMs and specific feature detectors, leading to continual improvement\nand extension to face the challenges of rapidly evolving deepfakes.", "AI": {"tldr": "X2-DFD is an explainable, extendable framework using multimodal large-language models (MLLMs) for deepfake detection, improving detectability and explainability through feature assessment, dataset construction, and fine-tuning.", "motivation": "To enhance deepfake detection by addressing MLLM limitations in feature detectability and explainability, while ensuring adaptability to future advancements.", "method": "Three-stage framework: Model Feature Assessment ranks forgery-related features; Explainable Dataset Construction strengthens strong features and supplements weak ones; Fine-tuning and Inference deploys the model.", "result": "Improved performance over original MLLMs, validated by experiments and human studies, with plug-and-play adaptability for future MLLMs and detectors.", "conclusion": "X2-DFD effectively enhances deepfake detection and explainability, with potential for continual improvement as MLLMs evolve."}}
{"id": "2505.16223", "pdf": "https://arxiv.org/pdf/2505.16223", "abs": "https://arxiv.org/abs/2505.16223", "authors": ["Sangyong Lee", "Subo Hwang", "Dohoon Kim"], "title": "MADCluster: Model-agnostic Anomaly Detection with Self-supervised Clustering Network", "categories": ["cs.AI", "cs.LG"], "comment": "24 pages, 9 figures", "summary": "In this paper, we propose MADCluster, a novel model-agnostic anomaly\ndetection framework utilizing self-supervised clustering. MADCluster is\napplicable to various deep learning architectures and addresses the\n'hypersphere collapse' problem inherent in existing deep learning-based anomaly\ndetection methods. The core idea is to cluster normal pattern data into a\n'single cluster' while simultaneously learning the cluster center and mapping\ndata close to this center. Also, to improve expressiveness and enable effective\nsingle clustering, we propose a new 'One-directed Adaptive loss'. The\noptimization of this loss is mathematically proven. MADCluster consists of\nthree main components: Base Embedder capturing high-dimensional temporal\ndynamics, Cluster Distance Mapping, and Sequence-wise Clustering for continuous\ncenter updates. Its model-agnostic characteristics are achieved by applying\nvarious architectures to the Base Embedder. Experiments on four time series\nbenchmark datasets demonstrate that applying MADCluster improves the overall\nperformance of comparative models. In conclusion, the compatibility of\nMADCluster shows potential for enhancing model performance across various\narchitectures.", "AI": {"tldr": "MADCluster is a model-agnostic anomaly detection framework using self-supervised clustering to address the 'hypersphere collapse' problem in deep learning-based methods. It clusters normal data into a single cluster and optimizes a new loss function, improving performance across architectures.", "motivation": "To address the 'hypersphere collapse' problem in existing deep learning-based anomaly detection methods and provide a model-agnostic solution applicable to various architectures.", "method": "MADCluster uses self-supervised clustering with three components: Base Embedder, Cluster Distance Mapping, and Sequence-wise Clustering. It introduces a 'One-directed Adaptive loss' for optimization.", "result": "Experiments on four time series datasets show MADCluster improves performance of comparative models.", "conclusion": "MADCluster is compatible with various architectures, enhancing model performance and addressing key limitations in anomaly detection."}}
{"id": "2505.22746", "pdf": "https://arxiv.org/pdf/2505.22746", "abs": "https://arxiv.org/abs/2505.22746", "authors": ["Jose Guadalupe Hernandez", "Attri Ghosh", "Philip J. Freda", "Yufei Meng", "Nicholas Matsumoto", "Jason H. Moore"], "title": "StarBASE-GP: Biologically-Guided Automated Machine Learning for Genotype-to-Phenotype Association Analysis", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "We present the Star-Based Automated Single-locus and Epistasis analysis tool\n- Genetic Programming (StarBASE-GP), an automated framework for discovering\nmeaningful genetic variants associated with phenotypic variation in large-scale\ngenomic datasets. StarBASE-GP uses a genetic programming-based multi-objective\noptimization strategy to evolve machine learning pipelines that simultaneously\nmaximize explanatory power (r2) and minimize pipeline complexity. Biological\ndomain knowledge is integrated at multiple stages, including the use of nine\ninheritance encoding strategies to model deviations from additivity, a custom\nlinkage disequilibrium pruning node that minimizes redundancy among features,\nand a dynamic variant recommendation system that prioritizes informative\ncandidates for pipeline inclusion. We evaluate StarBASE-GP on a cohort of\nRattus norvegicus (brown rat) to identify variants associated with body mass\nindex, benchmarking its performance against a random baseline and a\nbiologically naive version of the tool. StarBASE-GP consistently evolves Pareto\nfronts with superior performance, yielding higher accuracy in identifying both\nground truth and novel quantitative trait loci, highlighting relevant targets\nfor future validation. By incorporating evolutionary search and relevant\nbiological theory into a flexible automated machine learning framework,\nStarBASE-GP demonstrates robust potential for advancing variant discovery in\ncomplex traits.", "AI": {"tldr": "StarBASE-GP is a genetic programming tool for discovering genetic variants linked to traits, using multi-objective optimization and biological knowledge for superior performance.", "motivation": "To automate the discovery of meaningful genetic variants in large genomic datasets, integrating biological knowledge for accuracy.", "method": "Uses genetic programming and multi-objective optimization to evolve ML pipelines, incorporating inheritance encoding, LD pruning, and dynamic variant recommendation.", "result": "Outperforms baselines in identifying ground truth and novel loci, demonstrating higher accuracy and relevance.", "conclusion": "StarBASE-GP shows strong potential for advancing variant discovery in complex traits by combining evolutionary search and biological theory."}}
{"id": "2501.18922", "pdf": "https://arxiv.org/pdf/2501.18922", "abs": "https://arxiv.org/abs/2501.18922", "authors": ["Haoran Luo", "Haihong E", "Yikai Guo", "Qika Lin", "Xiaobao Wu", "Xinyu Mu", "Wenhao Liu", "Meina Song", "Yifan Zhu", "Luu Anh Tuan"], "title": "KBQA-o1: Agentic Knowledge Base Question Answering with Monte Carlo Tree Search", "categories": ["cs.CL", "cs.AI", "cs.DB"], "comment": "Accepted by ICML 2025 main conference", "summary": "Knowledge Base Question Answering (KBQA) aims to answer natural language\nquestions with a large-scale structured knowledge base (KB). Despite\nadvancements with large language models (LLMs), KBQA still faces challenges in\nweak KB awareness, imbalance between effectiveness and efficiency, and high\nreliance on annotated data. To address these challenges, we propose KBQA-o1, a\nnovel agentic KBQA method with Monte Carlo Tree Search (MCTS). It introduces a\nReAct-based agent process for stepwise logical form generation with KB\nenvironment exploration. Moreover, it employs MCTS, a heuristic search method\ndriven by policy and reward models, to balance agentic exploration's\nperformance and search space. With heuristic exploration, KBQA-o1 generates\nhigh-quality annotations for further improvement by incremental fine-tuning.\nExperimental results show that KBQA-o1 outperforms previous low-resource KBQA\nmethods with limited annotated data, boosting Llama-3.1-8B model's GrailQA F1\nperformance to 78.5% compared to 48.5% of the previous sota method with\nGPT-3.5-turbo. Our code is publicly available.", "AI": {"tldr": "KBQA-o1, a novel KBQA method using MCTS and ReAct-based agents, improves performance with limited annotated data, achieving 78.5% F1 on GrailQA.", "motivation": "Address challenges in KBQA like weak KB awareness, efficiency-effectiveness imbalance, and high reliance on annotated data.", "method": "Combines ReAct-based agent process for logical form generation with MCTS for heuristic search, balancing exploration and performance.", "result": "Outperforms previous methods, achieving 78.5% F1 on GrailQA with Llama-3.1-8B, vs. 48.5% with GPT-3.5-turbo.", "conclusion": "KBQA-o1 is effective for low-resource KBQA, leveraging agentic exploration and MCTS for improved performance."}}
{"id": "2410.10112", "pdf": "https://arxiv.org/pdf/2410.10112", "abs": "https://arxiv.org/abs/2410.10112", "authors": ["Qinyu Zhao", "Ming Xu", "Kartik Gupta", "Akshay Asthana", "Liang Zheng", "Stephen Gould"], "title": "Can We Predict Performance of Large Models across Vision-Language Tasks?", "categories": ["cs.CV", "cs.CL"], "comment": "ICML2025. Project page:\n  https://github.com/Qinyu-Allen-Zhao/CrossPred-LVLM", "summary": "Evaluating large vision-language models (LVLMs) is very expensive, due to\nhigh computational cost and the wide variety of tasks. The good news is that if\nwe already have some observed performance scores, we may be able to infer\nunknown ones. In this study, we propose a new framework for predicting unknown\nperformance scores based on observed ones from other LVLMs or tasks. We first\nformulate the performance prediction as a matrix completion task. Specifically,\nwe construct a sparse performance matrix $\\boldsymbol{R}$, where each entry\n$R_{mn}$ represents the performance score of the $m$-th model on the $n$-th\ndataset. By applying probabilistic matrix factorization (PMF) with Markov chain\nMonte Carlo (MCMC), we can complete the performance matrix, i.e., predict\nunknown scores. Additionally, we estimate the uncertainty of performance\nprediction based on MCMC. Practitioners can evaluate their models on untested\ntasks with higher uncertainty first, which quickly reduces the prediction\nerrors. We further introduce several improvements to enhance PMF for scenarios\nwith sparse observed performance scores. Our experiments demonstrate the\naccuracy of PMF in predicting unknown scores, the reliability of uncertainty\nestimates in ordering evaluations, and the effectiveness of our enhancements\nfor handling sparse data.", "AI": {"tldr": "A framework using probabilistic matrix factorization (PMF) with MCMC predicts unknown performance scores of large vision-language models (LVLMs) from observed ones, improving efficiency in evaluation.", "motivation": "Evaluating LVLMs is costly and time-consuming; predicting unknown scores from existing data can save resources.", "method": "Formulates performance prediction as matrix completion, applies PMF with MCMC to infer missing scores, and estimates uncertainty to guide evaluation order.", "result": "PMF accurately predicts unknown scores, uncertainty estimates reliably guide evaluation, and enhancements improve performance with sparse data.", "conclusion": "The proposed framework efficiently predicts LVLM performance, reducing evaluation costs and improving decision-making for practitioners."}}
{"id": "2505.18325", "pdf": "https://arxiv.org/pdf/2505.18325", "abs": "https://arxiv.org/abs/2505.18325", "authors": ["Licheng Pan", "Yongqi Tong", "Xin Zhang", "Xiaolu Zhang", "Jun Zhou", "Zhixuan Chu"], "title": "Understanding and Mitigating Overrefusal in LLMs from an Unveiling Perspective of Safety Decision Boundary", "categories": ["cs.AI", "cs.LG"], "comment": "We have identified significant errors in the results presented in\n  this paper, specifically in the evaluation sections concerning the DPO\n  training of LLaMA2 and Qwen2.5, as well as in the representation space\n  visualization section. Given the extent of these issues, we intend to\n  substantially revise the manuscript's content and structure. Hence, we\n  request to withdraw it from arXiv at this time", "summary": "Large language models (LLMs) have demonstrated remarkable capabilities across\na wide range of tasks, yet they often refuse to answer legitimate queries-a\nphenomenon known as overrefusal. Overrefusal typically stems from\nover-conservative safety alignment, causing models to treat many reasonable\nprompts as potentially risky. To systematically understand this issue, we probe\nand leverage the models'safety decision boundaries to analyze and mitigate\noverrefusal. Our findings reveal that overrefusal is closely tied to\nmisalignment at these boundary regions, where models struggle to distinguish\nsubtle differences between benign and harmful content. Building on these\ninsights, we present RASS, an automated framework for prompt generation and\nselection that strategically targets overrefusal prompts near the safety\nboundary. By harnessing steering vectors in the representation space, RASS\nefficiently identifies and curates boundary-aligned prompts, enabling more\neffective and targeted mitigation of overrefusal. This approach not only\nprovides a more precise and interpretable view of model safety decisions but\nalso seamlessly extends to multilingual scenarios.We have explored the safety\ndecision boundaries of various LLMs and construct the MORBench evaluation set\nto facilitate robust assessment of model safety and helpfulness across multiple\nlanguages. Code and datasets will be released at\nhttps://anonymous.4open.science/r/RASS-80D3.", "AI": {"tldr": "The paper addresses overrefusal in LLMs, where models reject legitimate queries due to over-conservative safety alignment. It introduces RASS, a framework to mitigate overrefusal by targeting prompts near safety boundaries.", "motivation": "Overrefusal in LLMs stems from misalignment at safety boundaries, causing models to reject reasonable prompts. The study aims to analyze and mitigate this issue.", "method": "The authors probe safety decision boundaries and develop RASS, an automated framework for prompt generation and selection near these boundaries using steering vectors.", "result": "RASS effectively identifies and mitigates overrefusal, providing a precise view of model safety decisions and extending to multilingual scenarios.", "conclusion": "The approach offers a robust solution to overrefusal, with potential applications in improving model safety and helpfulness across languages."}}
{"id": "2505.22760", "pdf": "https://arxiv.org/pdf/2505.22760", "abs": "https://arxiv.org/abs/2505.22760", "authors": ["Razvan-Andrei Lascu", "Mateusz B. Majka"], "title": "Non-convex entropic mean-field optimization via Best Response flow", "categories": ["math.OC", "cs.LG", "math.PR"], "comment": "40 pages", "summary": "We study the problem of minimizing non-convex functionals on the space of\nprobability measures, regularized by the relative entropy (KL divergence) with\nrespect to a fixed reference measure, as well as the corresponding problem of\nsolving entropy-regularized non-convex-non-concave min-max problems. We utilize\nthe Best Response flow (also known in the literature as the fictitious play\nflow) and study how its convergence is influenced by the relation between the\ndegree of non-convexity of the functional under consideration, the\nregularization parameter and the tail behaviour of the reference measure. In\nparticular, we demonstrate how to choose the regularizer, given the non-convex\nfunctional, so that the Best Response operator becomes a contraction with\nrespect to the $L^1$-Wasserstein distance, which then ensures the existence of\nits unique fixed point, which is then shown to be the unique global minimizer\nfor our optimization problem. This extends recent results where the Best\nResponse flow was applied to solve convex optimization problems regularized by\nthe relative entropy with respect to arbitrary reference measures, and with\narbitrary values of the regularization parameter. Our results explain precisely\nhow the assumption of convexity can be relaxed, at the expense of making a\nspecific choice of the regularizer. Additionally, we demonstrate how these\nresults can be applied in reinforcement learning in the context of policy\noptimization for Markov Decision Processes and Markov games with softmax\nparametrized policies in the mean-field regime.", "AI": {"tldr": "The paper explores minimizing non-convex functionals on probability measures using entropy regularization and the Best Response flow, extending prior convex results to non-convex settings.", "motivation": "To address non-convex optimization problems in probability spaces and min-max games, leveraging entropy regularization for convergence guarantees.", "method": "Uses the Best Response flow, analyzing its convergence based on non-convexity, regularization, and reference measure tails. Proves contraction in $L^1$-Wasserstein distance for unique fixed points.", "result": "Shows how to choose regularizers to ensure contraction, leading to unique global minimizers. Extends convex results to non-convex cases.", "conclusion": "Demonstrates applicability in reinforcement learning, particularly policy optimization for Markov Decision Processes and games with softmax policies."}}
{"id": "2502.01179", "pdf": "https://arxiv.org/pdf/2502.01179", "abs": "https://arxiv.org/abs/2502.01179", "authors": ["Wen Lai", "Alexander Fraser", "Ivan Titov"], "title": "Joint Localization and Activation Editing for Low-Resource Fine-Tuning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted by ICML 2025 (camera-ready version). The code is released at\n  https://github.com/wenlai-lavine/jola", "summary": "Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, are commonly\nused to adapt LLMs. However, the effectiveness of standard PEFT methods is\nlimited in low-resource scenarios with only a few hundred examples. Recent\nadvances in interpretability research have inspired the emergence of activation\nediting (or steering) techniques, which modify the activations of specific\nmodel components. Due to their extremely small parameter counts, these methods\nshow promise for small datasets. However, their performance is highly dependent\non identifying the correct modules to edit and often lacks stability across\ndifferent datasets. In this paper, we propose Joint Localization and Activation\nEditing (JoLA), a method that jointly learns (1) which heads in the Transformer\nto edit (2) whether the intervention should be additive, multiplicative, or\nboth and (3) the intervention parameters themselves - the vectors applied as\nadditive offsets or multiplicative scalings to the head output. Through\nevaluations on three benchmarks spanning commonsense reasoning, natural\nlanguage understanding, and natural language generation, we demonstrate that\nJoLA consistently outperforms existing methods. The code for the method is\nreleased at https://github.com/wenlai-lavine/jola.", "AI": {"tldr": "JoLA improves PEFT methods by jointly learning which Transformer heads to edit, the type of intervention, and the intervention parameters, outperforming existing methods in low-resource scenarios.", "motivation": "Standard PEFT methods like LoRA are limited in low-resource settings, and activation editing techniques lack stability and module identification accuracy.", "method": "JoLA jointly learns which Transformer heads to edit, the intervention type (additive, multiplicative, or both), and the intervention parameters.", "result": "JoLA consistently outperforms existing methods across three benchmarks: commonsense reasoning, natural language understanding, and natural language generation.", "conclusion": "JoLA is a promising method for low-resource fine-tuning, combining localization and activation editing for improved performance and stability."}}
{"id": "2410.18200", "pdf": "https://arxiv.org/pdf/2410.18200", "abs": "https://arxiv.org/abs/2410.18200", "authors": ["Jiantao Wu", "Sara Atito", "Zhenhua Feng", "Shentong Mo", "Josef Kitler", "Muhammad Awais"], "title": "Rethinking Positive Pairs in Contrastive Learning", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The training methods in AI do involve semantically distinct pairs of samples.\nHowever, their role typically is to enhance the between class separability. The\nactual notion of similarity is normally learned from semantically identical\npairs. This paper presents SimLAP: a simple framework for learning visual\nrepresentation from arbitrary pairs. SimLAP explores the possibility of\nlearning similarity from semantically distinct sample pairs. The approach is\nmotivated by the observation that for any pair of classes there exists a\nsubspace in which semantically distinct samples exhibit similarity. This\nphenomenon can be exploited for a novel method of learning, which optimises the\nsimilarity of an arbitrary pair of samples, while simultaneously learning the\nenabling subspace. The feasibility of the approach will be demonstrated\nexperimentally and its merits discussed.", "AI": {"tldr": "SimLAP introduces a framework for learning visual representations from arbitrary sample pairs, exploiting similarity in subspaces of semantically distinct classes.", "motivation": "Traditional methods focus on similarity from identical pairs; SimLAP explores learning from distinct pairs by leveraging subspace similarity.", "method": "SimLAP optimizes similarity for arbitrary pairs while learning the subspace enabling this similarity.", "result": "Experimental results demonstrate the feasibility and merits of the approach.", "conclusion": "SimLAP offers a novel way to learn visual representations by leveraging similarity in subspaces of distinct classes."}}
{"id": "2505.21887", "pdf": "https://arxiv.org/pdf/2505.21887", "abs": "https://arxiv.org/abs/2505.21887", "authors": ["Ahmed Heakl", "Yahia Salaheldin Shaaban", "Martin Takac", "Salem Lahlou", "Zangir Iklassov"], "title": "SVRPBench: A Realistic Benchmark for Stochastic Vehicle Routing Problem", "categories": ["cs.AI", "cs.CE", "cs.LG"], "comment": "18 pages, 14 figures, 11 tables", "summary": "Robust routing under uncertainty is central to real-world logistics, yet most\nbenchmarks assume static, idealized settings. We present SVRPBench, the first\nopen benchmark to capture high-fidelity stochastic dynamics in vehicle routing\nat urban scale. Spanning more than 500 instances with up to 1000 customers, it\nsimulates realistic delivery conditions: time-dependent congestion, log-normal\ndelays, probabilistic accidents, and empirically grounded time windows for\nresidential and commercial clients. Our pipeline generates diverse,\nconstraint-rich scenarios, including multi-depot and multi-vehicle setups.\nBenchmarking reveals that state-of-the-art RL solvers like POMO and AM degrade\nby over 20% under distributional shift, while classical and metaheuristic\nmethods remain robust. To enable reproducible research, we release the dataset\nand evaluation suite. SVRPBench challenges the community to design solvers that\ngeneralize beyond synthetic assumptions and adapt to real-world uncertainty.", "AI": {"tldr": "SVRPBench is the first open benchmark for stochastic vehicle routing, simulating real-world urban logistics challenges like congestion, delays, and accidents. It shows RL solvers degrade under uncertainty, while classical methods remain robust.", "motivation": "To address the gap in benchmarks for stochastic vehicle routing, capturing real-world dynamics like congestion and delays.", "method": "Developed SVRPBench with 500+ instances, simulating realistic conditions (e.g., time-dependent congestion, log-normal delays) and diverse scenarios (multi-depot, multi-vehicle).", "result": "RL solvers (POMO, AM) degrade by over 20% under distributional shift, while classical and metaheuristic methods stay robust.", "conclusion": "SVRPBench challenges the community to create solvers that generalize beyond synthetic assumptions and adapt to real-world uncertainty."}}
{"id": "2505.22781", "pdf": "https://arxiv.org/pdf/2505.22781", "abs": "https://arxiv.org/abs/2505.22781", "authors": ["Antonio Ocello", "Daniil Tiapkin", "Lorenzo Mancini", "Mathieu Lauri\u00e8re", "Eric Moulines"], "title": "Finite-Sample Convergence Bounds for Trust Region Policy Optimization in Mean-Field Games", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "We introduce Mean-Field Trust Region Policy Optimization (MF-TRPO), a novel\nalgorithm designed to compute approximate Nash equilibria for ergodic\nMean-Field Games (MFG) in finite state-action spaces. Building on the\nwell-established performance of TRPO in the reinforcement learning (RL)\nsetting, we extend its methodology to the MFG framework, leveraging its\nstability and robustness in policy optimization. Under standard assumptions in\nthe MFG literature, we provide a rigorous analysis of MF-TRPO, establishing\ntheoretical guarantees on its convergence. Our results cover both the exact\nformulation of the algorithm and its sample-based counterpart, where we derive\nhigh-probability guarantees and finite sample complexity. This work advances\nMFG optimization by bridging RL techniques with mean-field decision-making,\noffering a theoretically grounded approach to solving complex multi-agent\nproblems.", "AI": {"tldr": "MF-TRPO extends TRPO to Mean-Field Games, providing theoretical convergence guarantees for Nash equilibria in finite spaces.", "motivation": "To bridge RL techniques with mean-field decision-making for solving complex multi-agent problems.", "method": "Extends TRPO to MFG framework, leveraging its stability and robustness in policy optimization.", "result": "Theoretical guarantees on convergence for exact and sample-based formulations, with finite sample complexity.", "conclusion": "MF-TRPO advances MFG optimization by offering a theoretically grounded approach."}}
{"id": "2502.01662", "pdf": "https://arxiv.org/pdf/2502.01662", "abs": "https://arxiv.org/abs/2502.01662", "authors": ["Jiale Fu", "Yuchu Jiang", "Junkai Chen", "Jiaming Fan", "Xin Geng", "Xu Yang"], "title": "Fast Large Language Model Collaborative Decoding via Speculation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Model (LLM) collaborative decoding techniques improve output\nquality by combining the outputs of multiple models at each generation step,\nbut they incur high computational costs. In this paper, we introduce\nCollaborative decoding via Speculation (CoS), a novel framework that\naccelerates collaborative decoding without compromising performance. Inspired\nby Speculative Decoding--where a small proposal model generates tokens\nsequentially, and a larger target model verifies them in parallel, our approach\nbuilds on two key insights: (1) the verification distribution can be the\ncombined distribution of both the proposal and target models, and (2)\nalternating each model as the proposer and verifier can further enhance\nefficiency. We generalize this method to collaboration among n models and\ntheoretically prove that CoS is never slower than standard collaborative\ndecoding, typically achieving faster speed. Extensive experiments demonstrate\nCoS is 1.11x-2.23x faster than standard collaborative decoding without\ncompromising generation quality. Our code is available at\nhttps://github.com/Kamichanw/CoS/.", "AI": {"tldr": "CoS accelerates collaborative decoding for LLMs without performance loss, achieving 1.11x-2.23x speedup by leveraging speculative decoding and alternating model roles.", "motivation": "Standard collaborative decoding improves output quality but is computationally expensive. CoS aims to reduce costs while maintaining performance.", "method": "CoS uses speculative decoding with alternating proposer-verifier roles among models, combining their distributions for verification.", "result": "CoS is 1.11x-2.23x faster than standard collaborative decoding without quality loss.", "conclusion": "CoS offers a scalable, efficient alternative to traditional collaborative decoding, with proven speed advantages."}}
{"id": "2410.18987", "pdf": "https://arxiv.org/pdf/2410.18987", "abs": "https://arxiv.org/abs/2410.18987", "authors": ["Ernst R\u00f6ell", "Bastian Rieck"], "title": "Point Cloud Synthesis Using Inner Product Transforms", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Point-cloud synthesis, i.e. the generation of novel point clouds from an\ninput distribution, remains a challenging task, for which numerous complex\nmachine-learning models have been devised. We develop a novel method that\nencodes geometrical-topological characteristics of point clouds using inner\nproducts, leading to a highly-efficient point cloud representation with\nprovable expressivity properties. Integrated into deep learning models, our\nencoding exhibits high quality in typical tasks like reconstruction,\ngeneration, and interpolation, with inference times orders of magnitude faster\nthan existing methods.", "AI": {"tldr": "A novel method for point-cloud synthesis encodes geometric-topological features using inner products, offering efficient representation and fast inference.", "motivation": "Point-cloud synthesis is challenging, and existing methods are complex and slow.", "method": "Encodes geometric-topological characteristics of point clouds using inner products for efficient representation.", "result": "High quality in tasks like reconstruction, generation, and interpolation, with significantly faster inference times.", "conclusion": "The method provides an efficient and expressive solution for point-cloud synthesis, outperforming existing approaches."}}
{"id": "2402.01095", "pdf": "https://arxiv.org/pdf/2402.01095", "abs": "https://arxiv.org/abs/2402.01095", "authors": ["Keisuke Kawano", "Takuro Kutsuna", "Keisuke Sano"], "title": "Minimal Sufficient Views: A DNN model making predictions with more evidence has higher accuracy", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "24 pages", "summary": "Deep neural networks (DNNs) exhibit high performance in image recognition;\nhowever, the reasons for their strong generalization abilities remain unclear.\nA plausible hypothesis is that DNNs achieve robust and accurate predictions by\nidentifying multiple pieces of evidence from images. Thus, to test this\nhypothesis, this study proposed minimal sufficient views (MSVs). MSVs is\ndefined as a set of minimal regions within an input image that are sufficient\nto preserve the prediction of DNNs, thus representing the evidence discovered\nby the DNN. We empirically demonstrated a strong correlation between the number\nof MSVs (i.e., the number of pieces of evidence) and the generalization\nperformance of the DNN models. Remarkably, this correlation was found to hold\nwithin a single DNN as well as between different DNNs, including convolutional\nand transformer models. This suggested that a DNN model that makes its\nprediction based on more evidence has a higher generalization performance. We\nproposed a metric based on MSVs for DNN model selection that did not require\nlabel information. Consequently, we empirically showed that the proposed metric\nwas less dependent on the degree of overfitting, rendering it a more reliable\nindicator of model performance than existing metrics, such as average\nconfidence.", "AI": {"tldr": "The paper explores DNNs' generalization by proposing Minimal Sufficient Views (MSVs) as evidence regions in images. It shows a correlation between MSV count and generalization performance, offering a label-free model selection metric.", "motivation": "To understand why DNNs generalize well, hypothesizing that they rely on multiple pieces of evidence (MSVs) from images.", "method": "Proposed MSVs\u2014minimal image regions preserving DNN predictions\u2014and tested their correlation with generalization across models.", "result": "Found strong correlation between MSV count and generalization, even across different DNN architectures. Proposed MSV-based metric outperforms existing ones like average confidence.", "conclusion": "DNNs using more evidence (MSVs) generalize better. The MSV-based metric is reliable for model selection without labels."}}
{"id": "2505.22783", "pdf": "https://arxiv.org/pdf/2505.22783", "abs": "https://arxiv.org/abs/2505.22783", "authors": ["Charles E. Thornton", "Jamie Sloop", "Samuel Brown", "Aaron Orndorff", "William C. Headley", "Stephen Young"], "title": "Temporal Convolutional Autoencoder for Interference Mitigation in FMCW Radar Altimeters", "categories": ["eess.SP", "cs.LG"], "comment": "10 pages, 10 figures", "summary": "We investigate the end-to-end altitude estimation performance of a\nconvolutional autoencoder-based interference mitigation approach for\nfrequency-modulated continuous-wave (FMCW) radar altimeters. Specifically, we\nshow that a Temporal Convolutional Network (TCN) autoencoder effectively\nexploits temporal correlations in the received signal, providing superior\ninterference suppression compared to a Least Mean Squares (LMS) adaptive\nfilter. Unlike existing approaches, the present method operates directly on the\nreceived FMCW signal. Additionally, we identify key challenges in applying deep\nlearning to wideband FMCW interference mitigation and outline directions for\nfuture research to enhance real-time feasibility and generalization to\narbitrary interference conditions.", "AI": {"tldr": "A TCN autoencoder outperforms LMS filters for FMCW radar altimeter interference mitigation by leveraging temporal correlations in signals.", "motivation": "To improve altitude estimation in FMCW radar altimeters by mitigating interference more effectively than existing methods.", "method": "Uses a Temporal Convolutional Network (TCN) autoencoder to process received FMCW signals directly, exploiting temporal correlations.", "result": "Superior interference suppression compared to Least Mean Squares (LMS) adaptive filters.", "conclusion": "Highlights challenges in deep learning for FMCW interference mitigation and suggests future research for real-time feasibility and generalization."}}
{"id": "2502.03397", "pdf": "https://arxiv.org/pdf/2502.03397", "abs": "https://arxiv.org/abs/2502.03397", "authors": ["Hongli Zhan", "Muneeza Azmat", "Raya Horesh", "Junyi Jessy Li", "Mikhail Yurochkin"], "title": "SPRI: Aligning Large Language Models with Context-Situated Principles", "categories": ["cs.CL", "cs.AI"], "comment": "Forty-Second International Conference on Machine Learning (ICML 2025)\n  Camera-Ready Version", "summary": "Aligning Large Language Models to integrate and reflect human values,\nespecially for tasks that demand intricate human oversight, is arduous since it\nis resource-intensive and time-consuming to depend on human expertise for\ncontext-specific guidance. Prior work has utilized predefined sets of rules or\nprinciples to steer the behavior of models (Bai et al., 2022; Sun et al.,\n2023). However, these principles tend to be generic, making it challenging to\nadapt them to each individual input query or context. In this work, we present\nSituated-PRInciples (SPRI), a framework requiring minimal or no human effort\nthat is designed to automatically generate guiding principles in real-time for\neach input query and utilize them to align each response. We evaluate SPRI on\nthree tasks, and show that 1) SPRI can derive principles in a complex\ndomain-specific task that leads to on-par performance as expert-crafted ones;\n2) SPRI-generated principles lead to instance-specific rubrics that outperform\nprior LLM-as-a-judge frameworks; 3) using SPRI to generate synthetic SFT data\nleads to substantial improvement on truthfulness. We release our code and model\ngenerations at https://github.com/honglizhan/SPRI-public.", "AI": {"tldr": "SPRI is a framework for real-time, automatic generation of guiding principles for LLMs, reducing reliance on human expertise and improving task-specific alignment.", "motivation": "Aligning LLMs with human values is resource-intensive; existing methods use generic principles, which lack adaptability.", "method": "SPRI generates context-specific principles for each input query, minimizing human effort.", "result": "SPRI matches expert-crafted principles, outperforms prior LLM-as-a-judge frameworks, and improves truthfulness in synthetic data.", "conclusion": "SPRI offers a scalable, efficient solution for aligning LLMs with human values without heavy human involvement."}}
{"id": "2410.22725", "pdf": "https://arxiv.org/pdf/2410.22725", "abs": "https://arxiv.org/abs/2410.22725", "authors": ["Ji Guo", "Wenbo Jiang", "Rui Zhang", "Guoming Lu", "Hongwei Li"], "title": "One Prompt to Verify Your Models: Black-Box Text-to-Image Models Verification via Non-Transferable Adversarial Attacks", "categories": ["cs.CV", "cs.CR"], "comment": null, "summary": "Recently, various types of Text-to-Image (T2I) models have emerged (such as\nDALL-E and Stable Diffusion), and showing their advantages in different\naspects. Therefore, some third-party service platforms collect different model\ninterfaces and provide cheaper API services and more flexibility in T2I model\nselections. However, this also raises a new security concern: Are these\nthird-party services truly offering the models they claim?\n  To answer this question, we first define the concept of T2I model\nverification, which aims to determine whether a black-box target model is\nidentical to a given white-box reference T2I model. After that, we propose\nVerifyPrompt, which performs T2I model verification through a special designed\nverify prompt. Intuitionally, the verify prompt is an adversarial prompt for\nthe target model without transferability for other models. It makes the target\nmodel generate a specific image while making other models produce entirely\ndifferent images. Specifically, VerifyPrompt utilizes the Non-dominated Sorting\nGenetic Algorithm II (NSGA-II) to optimize the cosine similarity of a prompt's\ntext encoding, generating verify prompts. Finally, by computing the CLIP-text\nsimilarity scores between the prompts the generated images, VerifyPrompt can\ndetermine whether the target model aligns with the reference model.\nExperimental results demonstrate that VerifyPrompt consistently achieves over\n90\\% accuracy across various T2I models, confirming its effectiveness in\npractical model platforms (such as Hugging Face).", "AI": {"tldr": "VerifyPrompt is a method to verify if a black-box T2I model matches a reference model using adversarial prompts optimized by NSGA-II, achieving over 90% accuracy.", "motivation": "Third-party T2I model services may misrepresent models, raising security concerns about their authenticity.", "method": "Uses adversarial prompts (verify prompts) optimized via NSGA-II to generate unique images for the target model, then checks alignment using CLIP-text similarity.", "result": "VerifyPrompt achieves over 90% accuracy in verifying T2I models across various platforms.", "conclusion": "VerifyPrompt effectively addresses the security concern of model misrepresentation in third-party T2I services."}}
{"id": "2402.16014", "pdf": "https://arxiv.org/pdf/2402.16014", "abs": "https://arxiv.org/abs/2402.16014", "authors": ["Tianyu Chen", "Haoyi Zhou", "Ying Li", "Hao Wang", "Chonghan Gao", "Rongye Shi", "Shanghang Zhang", "Jianxin Li"], "title": "OmniArch: Building Foundation Model For Scientific Computing", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025", "summary": "Foundation models have revolutionized language modeling, while whether this\nsuccess is replicated in scientific computing remains unexplored. We present\nOmniArch, the first prototype aiming at solving multi-scale and multi-physics\nscientific computing problems with physical alignment. We addressed all three\nchallenges with one unified architecture. Its pre-training stage contains a\nFourier Encoder-decoder fading out the disharmony across separated dimensions\nand a Transformer backbone integrating quantities through temporal dynamics,\nand the novel PDE-Aligner performs physics-informed fine-tuning under flexible\nconditions. As far as we know, we first conduct 1D-2D-3D united pre-training on\nthe PDEBench, and it sets not only new performance benchmarks for 1D, 2D, and\n3D PDEs but also demonstrates exceptional adaptability to new physics via\nin-context and zero-shot learning approaches, which supports realistic\nengineering applications and foresight physics discovery.", "AI": {"tldr": "OmniArch is a foundation model for multi-scale, multi-physics scientific computing, achieving state-of-the-art performance and adaptability via unified architecture and physics-informed fine-tuning.", "motivation": "To explore if foundation models' success in language modeling can extend to scientific computing, addressing multi-scale and multi-physics challenges.", "method": "OmniArch uses a Fourier Encoder-decoder and Transformer backbone for pre-training, with PDE-Aligner for physics-informed fine-tuning.", "result": "Achieves new benchmarks for 1D-2D-3D PDEs and shows adaptability via in-context and zero-shot learning.", "conclusion": "OmniArch successfully bridges foundation models and scientific computing, enabling realistic applications and physics discovery."}}
{"id": "2505.22807", "pdf": "https://arxiv.org/pdf/2505.22807", "abs": "https://arxiv.org/abs/2505.22807", "authors": ["John C. Duchi"], "title": "Distribution free M-estimation", "categories": ["math.ST", "cs.IT", "cs.LG", "math.IT", "stat.TH"], "comment": "26 pages", "summary": "The basic question of delineating those statistical problems that are\nsolvable without making any assumptions on the underlying data distribution has\nlong animated statistics and learning theory. This paper characterizes when a\n(univariate) convex M-estimation or stochastic optimization problem is solvable\nin such an assumption-free setting, providing a precise dividing line between\nsolvable and unsolvable problems. The conditions we identify show, perhaps\nsurprisingly, that Lipschitz continuity of the loss being minimized is not\nnecessary for distribution free minimization, and they are also distinct from\nclassical characterizations of learnability in machine learning.", "AI": {"tldr": "The paper identifies conditions for solvable univariate convex M-estimation problems without distributional assumptions, showing Lipschitz continuity isn't necessary.", "motivation": "To determine when statistical problems can be solved without assumptions on data distribution, bridging gaps in statistics and learning theory.", "method": "Characterizes solvable univariate convex M-estimation or stochastic optimization problems, identifying precise conditions.", "result": "Lipschitz continuity of the loss function is unnecessary for distribution-free minimization, differing from classical learnability conditions.", "conclusion": "Provides a clear boundary between solvable and unsolvable problems, challenging traditional assumptions in the field."}}
{"id": "2502.03708", "pdf": "https://arxiv.org/pdf/2502.03708", "abs": "https://arxiv.org/abs/2502.03708", "authors": ["Daniel Beaglehole", "Adityanarayanan Radhakrishnan", "Enric Boix-Adser\u00e0", "Mikhail Belkin"], "title": "Toward universal steering and monitoring of AI models", "categories": ["cs.CL", "cs.AI", "stat.ML"], "comment": null, "summary": "Modern AI models contain much of human knowledge, yet understanding of their\ninternal representation of this knowledge remains elusive. Characterizing the\nstructure and properties of this representation will lead to improvements in\nmodel capabilities and development of effective safeguards. Building on recent\nadvances in feature learning, we develop an effective, scalable approach for\nextracting linear representations of general concepts in large-scale AI models\n(language models, vision-language models, and reasoning models). We show how\nthese representations enable model steering, through which we expose\nvulnerabilities, mitigate misaligned behaviors, and improve model capabilities.\nAdditionally, we demonstrate that concept representations are remarkably\ntransferable across human languages and combinable to enable multi-concept\nsteering. Through quantitative analysis across hundreds of concepts, we find\nthat newer, larger models are more steerable and steering can improve model\ncapabilities beyond standard prompting. We show how concept representations are\neffective for monitoring misaligned content (hallucinations, toxic content). We\ndemonstrate that predictive models built using concept representations are more\naccurate for monitoring misaligned content than using models that judge outputs\ndirectly. Together, our results illustrate the power of using internal\nrepresentations to map the knowledge in AI models, advance AI safety, and\nimprove model capabilities.", "AI": {"tldr": "The paper introduces a scalable method to extract linear representations of concepts in AI models, enabling model steering to improve capabilities and safety.", "motivation": "Understanding AI models' internal knowledge representation to enhance capabilities and develop safeguards.", "method": "Develops an approach for extracting linear concept representations in large-scale AI models (language, vision-language, reasoning).", "result": "Newer, larger models are more steerable; concept representations improve monitoring of misaligned content and model performance.", "conclusion": "Internal representations are powerful for mapping AI knowledge, advancing safety, and improving capabilities."}}
{"id": "2411.18625", "pdf": "https://arxiv.org/pdf/2411.18625", "abs": "https://arxiv.org/abs/2411.18625", "authors": ["Brian Chao", "Hung-Yu Tseng", "Lorenzo Porzi", "Chen Gao", "Tuotuo Li", "Qinbo Li", "Ayush Saraf", "Jia-Bin Huang", "Johannes Kopf", "Gordon Wetzstein", "Changil Kim"], "title": "Textured Gaussians for Enhanced 3D Scene Appearance Modeling", "categories": ["cs.CV"], "comment": "Will be presented at CVPR 2025. Project website:\n  https://textured-gaussians.github.io/", "summary": "3D Gaussian Splatting (3DGS) has recently emerged as a state-of-the-art 3D\nreconstruction and rendering technique due to its high-quality results and fast\ntraining and rendering time. However, pixels covered by the same Gaussian are\nalways shaded in the same color up to a Gaussian falloff scaling factor.\nFurthermore, the finest geometric detail any individual Gaussian can represent\nis a simple ellipsoid. These properties of 3DGS greatly limit the expressivity\nof individual Gaussian primitives. To address these issues, we draw inspiration\nfrom texture and alpha mapping in traditional graphics and integrate it with\n3DGS. Specifically, we propose a new generalized Gaussian appearance\nrepresentation that augments each Gaussian with alpha~(A), RGB, or RGBA texture\nmaps to model spatially varying color and opacity across the extent of each\nGaussian. As such, each Gaussian can represent a richer set of texture patterns\nand geometric structures, instead of just a single color and ellipsoid as in\nnaive Gaussian Splatting. Surprisingly, we found that the expressivity of\nGaussians can be greatly improved by using alpha-only texture maps, and further\naugmenting Gaussians with RGB texture maps achieves the highest expressivity.\nWe validate our method on a wide variety of standard benchmark datasets and our\nown custom captures at both the object and scene levels. We demonstrate image\nquality improvements over existing methods while using a similar or lower\nnumber of Gaussians.", "AI": {"tldr": "3D Gaussian Splatting (3DGS) is improved by adding texture and alpha maps to Gaussians, enhancing their expressivity for better 3D reconstruction and rendering.", "motivation": "The limitations of 3DGS, such as uniform shading and simple geometric detail representation, restrict its expressivity.", "method": "Augment each Gaussian with alpha, RGB, or RGBA texture maps to model spatially varying color and opacity.", "result": "Improved expressivity and image quality, validated on benchmark datasets and custom captures.", "conclusion": "The proposed method enhances 3DGS by integrating texture mapping, achieving superior results with similar or fewer Gaussians."}}
{"id": "2403.07404", "pdf": "https://arxiv.org/pdf/2403.07404", "abs": "https://arxiv.org/abs/2403.07404", "authors": ["Filip Szatkowski", "Yaoyue Zheng", "Fei Yang", "Bart\u0142omiej Twardowski", "Tomasz Trzci\u0144ski", "Joost van de Weijer"], "title": "Improving Continual Learning Performance and Efficiency with Auxiliary Classifiers", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025 (main track poster)", "summary": "Continual learning is crucial for applying machine learning in challenging,\ndynamic, and often resource-constrained environments. However, catastrophic\nforgetting - overwriting previously learned knowledge when new information is\nacquired - remains a major challenge. In this work, we examine the intermediate\nrepresentations in neural network layers during continual learning and find\nthat such representations are less prone to forgetting, highlighting their\npotential to accelerate computation. Motivated by these findings, we propose to\nuse auxiliary classifiers(ACs) to enhance performance and demonstrate that\nintegrating ACs into various continual learning methods consistently improves\naccuracy across diverse evaluation settings, yielding an average 10% relative\ngain. We also leverage the ACs to reduce the average cost of the inference by\n10-60% without compromising accuracy, enabling the model to return the\npredictions before computing all the layers. Our approach provides a scalable\nand efficient solution for continual learning.", "AI": {"tldr": "Using auxiliary classifiers (ACs) in continual learning reduces forgetting and improves efficiency, achieving a 10% accuracy boost and 10-60% inference cost reduction.", "motivation": "Address catastrophic forgetting in continual learning by leveraging intermediate neural network representations, which are less prone to forgetting.", "method": "Propose auxiliary classifiers (ACs) to enhance performance and integrate them into continual learning methods.", "result": "ACs improve accuracy by 10% and reduce inference costs by 10-60% without accuracy loss.", "conclusion": "ACs provide a scalable, efficient solution for continual learning by mitigating forgetting and optimizing computation."}}
{"id": "2505.22811", "pdf": "https://arxiv.org/pdf/2505.22811", "abs": "https://arxiv.org/abs/2505.22811", "authors": ["Ba-Hien Tran", "Van Minh Nguyen"], "title": "Highly Efficient and Effective LLMs with Multi-Boolean Architectures", "categories": ["stat.ML", "cs.LG"], "comment": "Under Review", "summary": "Weight binarization has emerged as a promising strategy to drastically reduce\nthe complexity of large language models (LLMs). It is mainly classified into\ntwo approaches: post-training binarization and finetuning with training-aware\nbinarization methods. The first approach, while having low complexity, leads to\nsignificant loss of information from the original LLMs, resulting in poor\nperformance. The second approach, on the other hand, relies heavily on\nfull-precision latent weights for gradient approximation of binary weights,\nwhich not only remains suboptimal but also introduces substantial complexity.\nIn this paper, we introduce a novel framework that effectively transforms LLMs\ninto multi-kernel Boolean parameters, for the first time, finetunes them\ndirectly in the Boolean domain, eliminating the need for expensive latent\nweights. This significantly reduces complexity during both finetuning and\ninference. Through extensive and insightful experiments across a wide range of\nLLMs, we demonstrate that our method outperforms recent ultra low-bit\nquantization and binarization methods.", "AI": {"tldr": "A novel framework for binarizing LLMs by transforming them into multi-kernel Boolean parameters and finetuning directly in the Boolean domain, reducing complexity and outperforming existing methods.", "motivation": "Current binarization methods for LLMs either lose significant information or rely on complex full-precision latent weights, leading to suboptimal performance.", "method": "Introduces a framework to transform LLMs into multi-kernel Boolean parameters and finetunes them directly in the Boolean domain, avoiding latent weights.", "result": "Outperforms recent ultra low-bit quantization and binarization methods, reducing complexity in finetuning and inference.", "conclusion": "The proposed method offers an efficient and effective alternative for binarizing LLMs, eliminating the drawbacks of existing approaches."}}
{"id": "2502.04350", "pdf": "https://arxiv.org/pdf/2502.04350", "abs": "https://arxiv.org/abs/2502.04350", "authors": ["Yongchao Chen", "Yilun Hao", "Yueying Liu", "Yang Zhang", "Chuchu Fan"], "title": "CodeSteer: Symbolic-Augmented Language Models via Code/Text Guidance", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SC", "cs.SE"], "comment": "28 pages, 12 figures", "summary": "Existing methods fail to effectively steer Large Language Models (LLMs)\nbetween textual reasoning and code generation, leaving symbolic computing\ncapabilities underutilized. We introduce CodeSteer, an effective method for\nguiding LLM code/text generation. We construct a comprehensive benchmark\nSymBench comprising 37 symbolic tasks with adjustable complexity and also\nsynthesize datasets of 12k multi-turn guidance/generation trajectories and 5.5k\nguidance comparison pairs. We fine-tune the Llama-3-8B model with a newly\ndesigned multi-turn supervised fine-tuning (SFT) and direct preference\noptimization (DPO). The resulting model, CodeSteerLLM, augmented with the\nproposed symbolic and self-answer checkers, effectively guides the code/text\ngeneration of larger models. Augmenting GPT-4o with CodeSteer raises its\naverage performance score from 53.3 to 86.4, even outperforming the existing\nbest LLM OpenAI o1 (82.7), o1-preview (74.8), and DeepSeek R1 (76.8) across all\n37 tasks (28 seen, 9 unseen). Trained for GPT-4o, CodeSteer demonstrates\nsuperior generalizability, providing an average 41.8 performance boost on\nClaude, Mistral, and GPT-3.5. CodeSteer-guided LLMs fully harness symbolic\ncomputing to maintain strong performance on highly complex tasks. Models,\nDatasets, and Codes are available at\nhttps://github.com/yongchao98/CodeSteer-v1.0 and\nhttps://huggingface.co/yongchao98.", "AI": {"tldr": "CodeSteer improves LLM performance in code/text generation by fine-tuning with multi-turn SFT and DPO, achieving significant gains over existing models.", "motivation": "Existing methods underutilize symbolic computing in LLMs, failing to balance textual reasoning and code generation effectively.", "method": "Introduces CodeSteer, fine-tuning Llama-3-8B with multi-turn SFT and DPO, and augmenting it with symbolic and self-answer checkers.", "result": "CodeSteer boosts GPT-4o's performance from 53.3 to 86.4, outperforming top models like OpenAI o1 and DeepSeek R1.", "conclusion": "CodeSteer enhances LLMs' symbolic computing capabilities, generalizing well across models and tasks."}}
{"id": "2411.19093", "pdf": "https://arxiv.org/pdf/2411.19093", "abs": "https://arxiv.org/abs/2411.19093", "authors": ["Othmane Echchabi", "Aya Lahlou", "Nizar Talty", "Josh Malcolm Manto", "Ka Leung Lam"], "title": "Tracking Progress Towards Sustainable Development Goal 6 Using Satellite Imagery", "categories": ["cs.CV", "cs.CY", "cs.LG"], "comment": null, "summary": "Clean water and sanitation are essential for health, well-being, and\nsustainable development, yet significant global disparities persist. Although\nthe United Nations' Sustainable Development Goal (SDG) 6 clearly defines\ntargets for universal access to clean water and sanitation, limitations in data\ncoverage and openness impede accurate tracking of progress in many countries.\nTo bridge these gaps, this study integrates Afrobarometer survey data,\nsatellite imagery from Landsat 8 and Sentinel-2, and advanced deep learning\ntechniques using Meta's self-supervised Distillation with No Labels (DINO)\nmodel to develop a modeling framework for evaluating access to piped water and\nsewage system across diverse African regions. The modeling framework achieved\nnotable accuracy, with over 96% for piped water and 97% for sewage system\naccess classification. When combined with geospatial population data,\nvalidation against official statistics from the United Nations Joint Monitoring\nProgram demonstrated high concordance at the national scale (R2 of 0.95 for\npiped water access and R2 of 0.85 for sewage system access). The national-level\nestimates can represent SDG Indicators 6.1.1 and 6.2.1. This approach provides\npolicymakers and stakeholders with an effective, scalable, and cost-efficient\ntool to pinpoint underserved areas requiring targeted intervention. The\nmethodology developed herein can be adapted for assessing other\ninfrastructure-related SDGs, promoting enhanced monitoring and informed\ndecision-making towards achieving global sustainability objectives.", "AI": {"tldr": "The study integrates survey data, satellite imagery, and deep learning to evaluate water and sanitation access in Africa, achieving high accuracy and alignment with UN statistics.", "motivation": "Global disparities in clean water and sanitation access persist, and data limitations hinder progress tracking.", "method": "Combines Afrobarometer survey data, Landsat 8 and Sentinel-2 satellite imagery, and Meta's DINO model for classification.", "result": "Achieved 96% accuracy for piped water and 97% for sewage system classification, with high concordance to UN data.", "conclusion": "Provides a scalable tool for policymakers to target interventions and can be adapted for other SDGs."}}
{"id": "2403.12176", "pdf": "https://arxiv.org/pdf/2403.12176", "abs": "https://arxiv.org/abs/2403.12176", "authors": ["Shahin Atakishiyev", "Mohammad Salameh", "Randy Goebel"], "title": "Safety Implications of Explainable Artificial Intelligence in End-to-End Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted for publication in IEEE Transactions on Intelligent\n  Transportation Systems", "summary": "The end-to-end learning pipeline is gradually creating a paradigm shift in\nthe ongoing development of highly autonomous vehicles (AVs), largely due to\nadvances in deep learning, the availability of large-scale training datasets,\nand improvements in integrated sensor devices. However, a lack of\nexplainability in real-time decisions with contemporary learning methods\nimpedes user trust and attenuates the widespread deployment and\ncommercialization of such vehicles. Moreover, the issue is exacerbated when\nthese vehicles are involved in or cause traffic accidents. Consequently,\nexplainability in end-to-end autonomous driving is essential to build trust in\nvehicular automation. With that said, automotive researchers have not yet\nrigorously explored safety benefits and consequences of explanations in\nend-to-end autonomous driving. This paper aims to bridge the gaps between these\ntopics and seeks to answer the following research question: What are safety\nimplications of explanations in end-to-end autonomous driving? In this regard,\nwe first revisit established safety and explainability concepts in end-to-end\ndriving. Furthermore, we present critical case studies and show the pivotal\nrole of explanations in enhancing driving safety. Finally, we describe insights\nfrom empirical studies and reveal potential value, limitations, and caveats of\npractical explainable AI methods with respect to their potential impacts on\nsafety of end-to-end driving.", "AI": {"tldr": "The paper explores the safety implications of explainability in end-to-end autonomous driving, emphasizing its role in building trust and improving safety.", "motivation": "The lack of explainability in autonomous vehicles (AVs) hinders user trust and deployment, especially in accidents. The paper aims to address this gap by examining the safety benefits of explanations.", "method": "The study revisits safety and explainability concepts, presents case studies, and analyzes empirical data on explainable AI methods in AVs.", "result": "Explanations in end-to-end driving enhance safety, but practical explainable AI methods have limitations and caveats.", "conclusion": "Explainability is crucial for AV safety and trust, but further research is needed to address its limitations."}}
{"id": "2505.22868", "pdf": "https://arxiv.org/pdf/2505.22868", "abs": "https://arxiv.org/abs/2505.22868", "authors": ["Md Hasibul Amin", "Mohammadreza Mohammadi", "Jason D. Bakos", "Ramtin Zand"], "title": "CrossNAS: A Cross-Layer Neural Architecture Search Framework for PIM Systems", "categories": ["cs.ET", "cs.AR", "cs.LG"], "comment": null, "summary": "In this paper, we propose the CrossNAS framework, an automated approach for\nexploring a vast, multidimensional search space that spans various design\nabstraction layers-circuits, architecture, and systems-to optimize the\ndeployment of machine learning workloads on analog processing-in-memory (PIM)\nsystems. CrossNAS leverages the single-path one-shot weight-sharing strategy\ncombined with the evolutionary search for the first time in the context of PIM\nsystem mapping and optimization. CrossNAS sets a new benchmark for PIM neural\narchitecture search (NAS), outperforming previous methods in both accuracy and\nenergy efficiency while maintaining comparable or shorter search times.", "AI": {"tldr": "CrossNAS is an automated framework for optimizing machine learning workloads on analog PIM systems by exploring a multidimensional search space across circuits, architecture, and systems.", "motivation": "To improve the deployment of machine learning workloads on analog PIM systems by addressing the challenge of optimizing across multiple design abstraction layers.", "method": "Uses a single-path one-shot weight-sharing strategy combined with evolutionary search for PIM system mapping and optimization.", "result": "Outperforms previous methods in accuracy and energy efficiency while maintaining comparable or shorter search times.", "conclusion": "CrossNAS sets a new benchmark for PIM neural architecture search, demonstrating superior performance and efficiency."}}
{"id": "2502.04358", "pdf": "https://arxiv.org/pdf/2502.04358", "abs": "https://arxiv.org/abs/2502.04358", "authors": ["Elliot Meyerson", "Xin Qiu"], "title": "Position: Scaling LLM Agents Requires Asymptotic Analysis with LLM Primitives", "categories": ["cs.CL", "cs.AI", "cs.CC", "cs.LG", "cs.NE"], "comment": "In Proceedings of the 42nd International Conference on Machine\n  Learning (ICML 2025); 13 pages including references", "summary": "Decomposing hard problems into subproblems often makes them easier and more\nefficient to solve. With large language models (LLMs) crossing critical\nreliability thresholds for a growing slate of capabilities, there is an\nincreasing effort to decompose systems into sets of LLM-based agents, each of\nwhom can be delegated sub-tasks. However, this decomposition (even when\nautomated) is often intuitive, e.g., based on how a human might assign roles to\nmembers of a human team. How close are these role decompositions to optimal?\nThis position paper argues that asymptotic analysis with LLM primitives is\nneeded to reason about the efficiency of such decomposed systems, and that\ninsights from such analysis will unlock opportunities for scaling them. By\ntreating the LLM forward pass as the atomic unit of computational cost, one can\nseparate out the (often opaque) inner workings of a particular LLM from the\ninherent efficiency of how a set of LLMs are orchestrated to solve hard\nproblems. In other words, if we want to scale the deployment of LLMs to the\nlimit, instead of anthropomorphizing LLMs, asymptotic analysis with LLM\nprimitives should be used to reason about and develop more powerful\ndecompositions of large problems into LLM agents.", "AI": {"tldr": "The paper advocates for using asymptotic analysis with LLM primitives to optimize the decomposition of problems into LLM-based agents, treating the LLM forward pass as the atomic cost unit.", "motivation": "Current decompositions of problems into LLM agents are intuitive but may not be optimal. Understanding efficiency requires analyzing LLM primitives.", "method": "Proposes asymptotic analysis with LLM primitives, treating the forward pass as the computational cost unit.", "result": "Insights from this analysis can improve the efficiency and scalability of LLM-based systems.", "conclusion": "Asymptotic analysis is key to developing optimal decompositions for scaling LLM deployments."}}
{"id": "2412.04383", "pdf": "https://arxiv.org/pdf/2412.04383", "abs": "https://arxiv.org/abs/2412.04383", "authors": ["Rong Li", "Shijie Li", "Lingdong Kong", "Xulei Yang", "Junwei Liang"], "title": "SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding", "categories": ["cs.CV", "cs.RO"], "comment": "CVPR 2025; 21 pages, 10 figures, 10 tables; Code at\n  https://seeground.github.io/", "summary": "3D Visual Grounding (3DVG) aims to locate objects in 3D scenes based on\ntextual descriptions, essential for applications like augmented reality and\nrobotics. Traditional 3DVG approaches rely on annotated 3D datasets and\npredefined object categories, limiting scalability and adaptability. To\novercome these limitations, we introduce SeeGround, a zero-shot 3DVG framework\nleveraging 2D Vision-Language Models (VLMs) trained on large-scale 2D data.\nSeeGround represents 3D scenes as a hybrid of query-aligned rendered images and\nspatially enriched text descriptions, bridging the gap between 3D data and\n2D-VLMs input formats. We propose two modules: the Perspective Adaptation\nModule, which dynamically selects viewpoints for query-relevant image\nrendering, and the Fusion Alignment Module, which integrates 2D images with 3D\nspatial descriptions to enhance object localization. Extensive experiments on\nScanRefer and Nr3D demonstrate that our approach outperforms existing zero-shot\nmethods by large margins. Notably, we exceed weakly supervised methods and\nrival some fully supervised ones, outperforming previous SOTA by 7.7% on\nScanRefer and 7.1% on Nr3D, showcasing its effectiveness in complex 3DVG tasks.", "AI": {"tldr": "SeeGround is a zero-shot 3DVG framework using 2D VLMs to locate objects in 3D scenes without relying on annotated 3D data, outperforming existing methods.", "motivation": "Traditional 3DVG methods depend on annotated datasets and predefined categories, limiting scalability. SeeGround aims to overcome this by leveraging 2D VLMs.", "method": "SeeGround represents 3D scenes as hybrid query-aligned rendered images and enriched text descriptions. It includes Perspective Adaptation and Fusion Alignment Modules.", "result": "SeeGround outperforms zero-shot methods by 7.7% on ScanRefer and 7.1% on Nr3D, rivaling supervised approaches.", "conclusion": "SeeGround effectively bridges 3D data and 2D-VLMs, demonstrating strong performance in complex 3DVG tasks."}}
{"id": "2404.00306", "pdf": "https://arxiv.org/pdf/2404.00306", "abs": "https://arxiv.org/abs/2404.00306", "authors": ["Yang Hu"], "title": "A blockchain-based intelligent recommender system framework for enhancing supply chain resilience", "categories": ["cs.CE", "cs.AI"], "comment": "Manuscript submitted for Production and Operations Management", "summary": "This research proposed a data-driven supply chain disruption response\nbaseline framework based on intelligent recommender system technology as an\ninitial SCRes reactive solution. To improve the data quality and reliability of\nthe proposed IRS as a stable, secure, and resilient decision support system,\nblockchain technology is integrated into the baseline architecture. The smart\ncontract is prototyped to demonstrate the information exchange mechanism under\na BLC network environment. The BLC-IRS framework is then implemented with an\nindustrial case to demonstrate its executable function. A system dynamics (SD)\nsimulation model is adopted to validate the BLC-IRS framework as an effective\ndigital SCRes enhancement measure. The simulation results indicated that the\nproposed BLC-IRS framework can be effectively implemented as a SC disruption\nmitigation measure in the SCRes response phase as reactive measure, enabling SC\nparticipants to react better to SC disruptions at the physical level. Compared\nto previous studies that limited at the conceptual level as the proactive SCRes\nmeasure with a standalone fashion, the developed BLC-IRS contributes an\nexecutable SCRes digital solution with synthetic technologies as a reactive\nSCRes measure for the SCRes community, by identifying the internal and external\nsupplementary resource information in an agile, safe, and real-time manner\nafter SC disruption.", "AI": {"tldr": "A data-driven framework (BLC-IRS) combining blockchain and intelligent recommender systems is proposed for reactive supply chain resilience (SCRes), validated via system dynamics simulation.", "motivation": "To enhance supply chain disruption response by integrating blockchain for data reliability and recommender systems for agile decision-making.", "method": "Developed a blockchain-integrated intelligent recommender system (BLC-IRS), prototyped smart contracts, and validated with SD simulation and an industrial case.", "result": "The BLC-IRS framework effectively mitigates disruptions by enabling agile, secure, and real-time resource identification.", "conclusion": "The BLC-IRS provides an executable digital SCRes solution, outperforming conceptual proactive measures by addressing disruptions reactively."}}
{"id": "2502.04964", "pdf": "https://arxiv.org/pdf/2502.04964", "abs": "https://arxiv.org/abs/2502.04964", "authors": ["Roman Vashurin", "Maiya Goloburda", "Albina Ilina", "Aleksandr Rubashevskii", "Preslav Nakov", "Artem Shelmanov", "Maxim Panov"], "title": "Uncertainty Quantification for LLMs through Minimum Bayes Risk: Bridging Confidence and Consistency", "categories": ["cs.CL"], "comment": null, "summary": "Uncertainty quantification (UQ) methods for Large Language Models (LLMs)\nencompass a variety of approaches, with two major types being particularly\nprominent: information-based, which focus on model confidence expressed as\ntoken probabilities, and consistency-based, which assess the semantic\nrelationship between multiple outputs generated using repeated sampling.\nSeveral recent methods have combined these two approaches to boost UQ\nperformance. However, they sometimes fail to outperform much simpler baseline\nmethods. Our work discusses the fundamental approach to constructing\nuncertainty measures that directly links uncertainty with the minimum Bayes\nrisks achieved by LLM decoding. Building on these findings, we propose a novel\napproach to integrating model confidence with output consistency, resulting in\na family of efficient and robust UQ methods. Our investigation reveals\ndistinctive characteristics of LLMs as probabilistic models, which help to\nexplain why these UQ methods underperform in certain tasks. Based on these\nfindings, we propose a new way of synthesizing model confidence and output\nconsistency, leading to a family of efficient and robust UQ methods. We\nevaluate our approach across various tasks such as question answering,\nabstractive summarization, and machine translation, demonstrating sizable\nimprovements over state-of-the-art UQ approaches.", "AI": {"tldr": "The paper proposes a novel approach to uncertainty quantification (UQ) in Large Language Models (LLMs) by integrating model confidence and output consistency, outperforming existing methods.", "motivation": "Existing UQ methods for LLMs, combining information-based and consistency-based approaches, often underperform simpler baselines. The study aims to improve UQ by linking uncertainty to minimum Bayes risks in LLM decoding.", "method": "The authors develop a framework connecting uncertainty measures to minimum Bayes risks, then integrate model confidence with output consistency to create efficient UQ methods.", "result": "The proposed methods show significant improvements over state-of-the-art UQ approaches in tasks like question answering, summarization, and translation.", "conclusion": "The study highlights LLMs' probabilistic traits affecting UQ performance and introduces a robust synthesis of confidence and consistency for better uncertainty estimation."}}
{"id": "2412.06708", "pdf": "https://arxiv.org/pdf/2412.06708", "abs": "https://arxiv.org/abs/2412.06708", "authors": ["Dongyue Lu", "Lingdong Kong", "Gim Hee Lee", "Camille Simon Chane", "Wei Tsang Ooi"], "title": "FlexEvent: Towards Flexible Event-Frame Object Detection at Varying Operational Frequencies", "categories": ["cs.CV", "cs.RO"], "comment": "Preprint; 27 pages, 14 figures, 10 tables; Code at\n  https://flexevent.github.io/", "summary": "Event cameras offer unparalleled advantages for real-time perception in\ndynamic environments, thanks to the microsecond-level temporal resolution and\nasynchronous operation. Existing event detectors, however, are limited by\nfixed-frequency paradigms and fail to fully exploit the high-temporal\nresolution and adaptability of event data. To address these limitations, we\npropose FlexEvent, a novel framework that enables detection at varying\nfrequencies. Our approach consists of two key components: FlexFuse, an adaptive\nevent-frame fusion module that integrates high-frequency event data with rich\nsemantic information from RGB frames, and FlexTune, a frequency-adaptive\nfine-tuning mechanism that generates frequency-adjusted labels to enhance model\ngeneralization across varying operational frequencies. This combination allows\nour method to detect objects with high accuracy in both fast-moving and static\nscenarios, while adapting to dynamic environments. Extensive experiments on\nlarge-scale event camera datasets demonstrate that our approach surpasses\nstate-of-the-art methods, achieving significant improvements in both standard\nand high-frequency settings. Notably, our method maintains robust performance\nwhen scaling from 20 Hz to 90 Hz and delivers accurate detection up to 180 Hz,\nproving its effectiveness in extreme conditions. Our framework sets a new\nbenchmark for event-based object detection and paves the way for more\nadaptable, real-time vision systems. Code is publicly available.", "AI": {"tldr": "FlexEvent is a novel framework for event-based object detection that adapts to varying frequencies, outperforming existing methods by integrating high-frequency event data with RGB frames and fine-tuning dynamically.", "motivation": "Existing event detectors are limited by fixed-frequency paradigms and fail to leverage the high-temporal resolution of event cameras, necessitating a more adaptable solution.", "method": "FlexEvent combines FlexFuse (adaptive event-frame fusion) and FlexTune (frequency-adaptive fine-tuning) to integrate event data with RGB frames and adjust labels for varying frequencies.", "result": "The framework achieves high accuracy in both fast-moving and static scenarios, scaling robustly from 20 Hz to 180 Hz, surpassing state-of-the-art methods.", "conclusion": "FlexEvent sets a new benchmark for event-based detection, enabling adaptable, real-time vision systems."}}
{"id": "2405.17642", "pdf": "https://arxiv.org/pdf/2405.17642", "abs": "https://arxiv.org/abs/2405.17642", "authors": ["Oleksii Furman", "Patryk Wielopolski", "\u0141ukasz Lenkiewicz", "Jerzy Stefanowski", "Maciej Zi\u0119ba"], "title": "Unifying Perspectives: Plausible Counterfactual Explanations on Global, Group-wise, and Local Levels", "categories": ["cs.LG", "cs.AI", "stat.ME"], "comment": null, "summary": "The growing complexity of AI systems has intensified the need for\ntransparency through Explainable AI (XAI). Counterfactual explanations (CFs)\noffer actionable \"what-if\" scenarios on three levels: Local CFs providing\ninstance-specific insights, Global CFs addressing broader trends, and\nGroup-wise CFs (GWCFs) striking a balance and revealing patterns within\ncohesive groups. Despite the availability of methods for each granularity\nlevel, the field lacks a unified method that integrates these complementary\napproaches. We address this limitation by proposing a gradient-based\noptimization method for differentiable models that generates Local, Global, and\nGroup-wise Counterfactual Explanations in a unified manner. We especially\nenhance GWCF generation by combining instance grouping and counterfactual\ngeneration into a single efficient process, replacing traditional two-step\nmethods. Moreover, to ensure trustworthiness, we innovatively introduce the\nintegration of plausibility criteria into the GWCF domain, making explanations\nboth valid and realistic. Our results demonstrate the method's effectiveness in\nbalancing validity, proximity, and plausibility while optimizing group\ngranularity, with practical utility validated through practical use cases.", "AI": {"tldr": "A unified gradient-based method for generating Local, Global, and Group-wise Counterfactual Explanations (CFs) in Explainable AI (XAI), enhancing efficiency and plausibility.", "motivation": "The complexity of AI systems demands transparency, but existing CF methods lack integration across granularity levels (Local, Global, Group-wise).", "method": "Proposes a gradient-based optimization for differentiable models, unifying CF generation and integrating plausibility criteria for Group-wise CFs.", "result": "Effective balance of validity, proximity, and plausibility, with practical utility demonstrated in use cases.", "conclusion": "The method addresses the gap in unified CF generation, offering actionable and trustworthy explanations for AI systems."}}
{"id": "2505.22974", "pdf": "https://arxiv.org/pdf/2505.22974", "abs": "https://arxiv.org/abs/2505.22974", "authors": ["Yuntao Ma", "Andrei Cramariuc", "Farbod Farshidian", "Marco Hutter"], "title": "Learning coordinated badminton skills for legged manipulators", "categories": ["cs.RO", "cs.LG", "68T40, 93C85", "I.2.9; I.2.6; I.2.8"], "comment": "Science Robotics DOI: 10.1126/scirobotics.adu3922", "summary": "Coordinating the motion between lower and upper limbs and aligning limb\ncontrol with perception are substantial challenges in robotics, particularly in\ndynamic environments. To this end, we introduce an approach for enabling legged\nmobile manipulators to play badminton, a task that requires precise\ncoordination of perception, locomotion, and arm swinging. We propose a unified\nreinforcement learning-based control policy for whole-body visuomotor skills\ninvolving all degrees of freedom to achieve effective shuttlecock tracking and\nstriking. This policy is informed by a perception noise model that utilizes\nreal-world camera data, allowing for consistent perception error levels between\nsimulation and deployment and encouraging learned active perception behaviors.\nOur method includes a shuttlecock prediction model, constrained reinforcement\nlearning for robust motion control, and integrated system identification\ntechniques to enhance deployment readiness. Extensive experimental results in a\nvariety of environments validate the robot's capability to predict shuttlecock\ntrajectories, navigate the service area effectively, and execute precise\nstrikes against human players, demonstrating the feasibility of using legged\nmobile manipulators in complex and dynamic sports scenarios.", "AI": {"tldr": "A reinforcement learning-based control policy enables legged mobile manipulators to play badminton by coordinating perception, locomotion, and arm movements.", "motivation": "Addressing the challenge of coordinating limb motion and aligning control with perception in dynamic environments, particularly for tasks requiring precision like badminton.", "method": "Proposes a unified reinforcement learning policy for whole-body visuomotor skills, incorporating a perception noise model, shuttlecock prediction, constrained RL, and system identification.", "result": "The robot successfully predicts shuttlecock trajectories, navigates effectively, and strikes precisely against human players in varied environments.", "conclusion": "Demonstrates the feasibility of using legged mobile manipulators in complex, dynamic sports scenarios like badminton."}}
{"id": "2502.09638", "pdf": "https://arxiv.org/pdf/2502.09638", "abs": "https://arxiv.org/abs/2502.09638", "authors": ["Jeremy Kritz", "Vaughn Robinson", "Robert Vacareanu", "Bijan Varjavand", "Michael Choi", "Bobby Gogov", "Scale Red Team", "Summer Yue", "Willow E. Primack", "Zifan Wang"], "title": "Jailbreaking to Jailbreak", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) can be used to red team other models (e.g.\njailbreaking) to elicit harmful contents. While prior works commonly employ\nopen-weight models or private uncensored models for doing jailbreaking, as the\nrefusal-training of strong LLMs (e.g. OpenAI o3) refuse to help jailbreaking,\nour work turn (almost) any black-box LLMs into attackers. The resulting $J_2$\n(jailbreaking-to-jailbreak) attackers can effectively jailbreak the safeguard\nof target models using various strategies, both created by themselves or from\nexpert human red teamers. In doing so, we show their strong but\nunder-researched jailbreaking capabilities. Our experiments demonstrate that 1)\nprompts used to create $J_2$ attackers transfer across almost all black-box\nmodels; 2) an $J_2$ attacker can jailbreak a copy of itself, and this\nvulnerability develops rapidly over the past 12 months; 3) reasong models, such\nas Sonnet-3.7, are strong $J_2$ attackers compared to others. For example, when\nused against the safeguard of GPT-4o, $J_2$ (Sonnet-3.7) achieves 0.975 attack\nsuccess rate (ASR), which matches expert human red teamers and surpasses the\nstate-of-the-art algorithm-based attacks. Among $J_2$ attackers, $J_2$ (o3)\nachieves highest ASR (0.605) against Sonnet-3.5, one of the most robust models.", "AI": {"tldr": "The paper introduces $J_2$ (jailbreaking-to-jailbreak) attackers, which can turn almost any black-box LLM into an effective jailbreaking tool, outperforming expert human red teamers and algorithm-based attacks.", "motivation": "To address the limitations of existing jailbreaking methods, which rely on open-weight or uncensored models, and to explore the under-researched jailbreaking capabilities of strong LLMs.", "method": "The $J_2$ framework transforms black-box LLMs into attackers using transferable prompts and self-jailbreaking strategies.", "result": "$J_2$ attackers achieve high attack success rates (e.g., 0.975 against GPT-4o) and outperform state-of-the-art methods.", "conclusion": "The study highlights the strong jailbreaking potential of LLMs and their rapid vulnerability development, urging further research into safeguards."}}
{"id": "2412.10908", "pdf": "https://arxiv.org/pdf/2412.10908", "abs": "https://arxiv.org/abs/2412.10908", "authors": ["Sagi Eppel"], "title": "Do large language vision models understand 3D shapes?", "categories": ["cs.CV"], "comment": null, "summary": "Large vision language models (LVLM) are the leading A.I approach for\nachieving a general visual understanding of the world. Models such as GPT,\nClaude, Gemini, and LLama can use images to understand and analyze complex\nvisual scenes. 3D objects and shapes are the basic building blocks of the\nworld, recognizing them is a fundamental part of human perception. The goal of\nthis work is to test whether LVLMs truly understand 3D shapes by testing the\nmodels ability to identify and match objects of the exact same 3D shapes but\nwith different orientations and materials/textures. A large number of test\nimages were created using CGI with a huge number of highly diverse objects,\nmaterials, and scenes. The results of this test show that the ability of such\nmodels to match 3D shapes is significantly below humans but much higher than\nrandom guesses. Suggesting that the models have gained some abstract\nunderstanding of 3D shapes but still trail far beyond humans in this task.\nMainly it seems that the models can easily identify the same object with a\ndifferent orientation as well as matching identical 3D shapes of the same\norientation but with different materials and textures. However, when both the\nobject material and orientation are changed, all models perform poorly relative\nto humans. Code and benchmark are available.", "AI": {"tldr": "LVLMs show some understanding of 3D shapes but perform poorly compared to humans when both orientation and material/texture are changed.", "motivation": "To evaluate whether LVLMs truly understand 3D shapes by testing their ability to match objects with varying orientations and materials.", "method": "Created CGI test images with diverse objects, materials, and scenes to assess LVLMs' shape recognition.", "result": "LVLMs perform better than random but significantly worse than humans, especially when both orientation and material change.", "conclusion": "LVLMs have limited abstract understanding of 3D shapes, lagging behind human performance in complex scenarios."}}
{"id": "2406.02827", "pdf": "https://arxiv.org/pdf/2406.02827", "abs": "https://arxiv.org/abs/2406.02827", "authors": ["Yuansan Liu", "Sudanthi Wijewickrema", "Dongting Hu", "Christofer Bester", "Stephen O'Leary", "James Bailey"], "title": "Stochastic Diffusion: A Diffusion Based Model for Stochastic Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "15 pages, 4 figures. SIGKDD 2025", "summary": "Recent innovations in diffusion probabilistic models have paved the way for\nsignificant progress in image, text and audio generation, leading to their\napplications in generative time series forecasting. However, leveraging such\nabilities to model highly stochastic time series data remains a challenge. In\nthis paper, we propose a novel Stochastic Diffusion (StochDiff) model which\nlearns data-driven prior knowledge at each time step by utilizing the\nrepresentational power of the stochastic latent spaces to model the variability\nof the multivariate time series data. The learnt prior knowledge helps the\nmodel to capture complex temporal dynamics and the inherent uncertainty of the\ndata. This improves its ability to model highly stochastic time series data.\nThrough extensive experiments on real-world datasets, we demonstrate the\neffectiveness of our proposed model on stochastic time series forecasting.\nAdditionally, we showcase an application of our model for real-world surgical\nguidance, highlighting its potential to benefit the medical community.", "AI": {"tldr": "A novel Stochastic Diffusion (StochDiff) model is proposed to improve forecasting of highly stochastic time series by leveraging data-driven prior knowledge and stochastic latent spaces.", "motivation": "Existing diffusion models struggle with highly stochastic time series data, limiting their forecasting accuracy.", "method": "The StochDiff model learns data-driven prior knowledge at each time step using stochastic latent spaces to capture variability and uncertainty.", "result": "The model effectively captures complex temporal dynamics and improves forecasting for stochastic time series, validated on real-world datasets.", "conclusion": "StochDiff shows promise for stochastic time series forecasting and has potential applications in medical fields like surgical guidance."}}
{"id": "2505.22997", "pdf": "https://arxiv.org/pdf/2505.22997", "abs": "https://arxiv.org/abs/2505.22997", "authors": ["Agnideep Aich", "Ashit Baran Aich", "Bruce Wade"], "title": "Theoretical Foundations of the Deep Copula Classifier: A Generative Approach to Modeling Dependent Features", "categories": ["stat.ML", "cs.LG", "62H30, 68T07, 62C12, 62G05"], "comment": "Submitted", "summary": "Traditional classifiers often assume feature independence or rely on overly\nsimplistic relationships, leading to poor performance in settings where\nreal-world dependencies matter. We introduce the Deep Copula Classifier (DCC),\na generative model that separates the learning of each feature's marginal\ndistribution from the modeling of their joint dependence structure via neural\nnetwork-parameterized copulas. For each class, lightweight neural networks are\nused to flexibly and adaptively capture feature interactions, making DCC\nparticularly effective when classification is driven by complex dependencies.\nWe establish that DCC converges to the Bayes-optimal classifier under standard\nconditions and provide explicit convergence rates of O(n^{-r/(2r + d)}) for\nr-smooth copula densities. Beyond theoretical guarantees, we outline several\npractical extensions, including high-dimensional scalability through vine and\nfactor copula architectures, semi-supervised learning via entropy\nregularization, and online adaptation using streaming gradient methods. By\nunifying statistical rigor with the representational power of neural networks,\nDCC offers a mathematically grounded and interpretable framework for\ndependency-aware classification.", "AI": {"tldr": "The Deep Copula Classifier (DCC) is a generative model that improves classification by modeling complex feature dependencies using neural network-parameterized copulas, offering theoretical guarantees and practical scalability.", "motivation": "Traditional classifiers often fail to capture real-world feature dependencies, leading to poor performance. DCC addresses this by separating marginal distribution learning from joint dependence modeling.", "method": "DCC uses lightweight neural networks to model feature interactions via copulas, ensuring flexibility and adaptability. It includes extensions for high-dimensional data, semi-supervised learning, and online adaptation.", "result": "DCC converges to the Bayes-optimal classifier under standard conditions, with explicit convergence rates. It also provides practical scalability and interpretability.", "conclusion": "DCC unifies statistical rigor with neural networks, offering a robust, interpretable framework for dependency-aware classification."}}
{"id": "2502.10852", "pdf": "https://arxiv.org/pdf/2502.10852", "abs": "https://arxiv.org/abs/2502.10852", "authors": ["Zeli Su", "Ziyin Zhang", "Guixian Xu", "Jianing Liu", "XU Han", "Ting Zhang", "Yushuang Dong"], "title": "Multilingual Encoder Knows more than You Realize: Shared Weights Pretraining for Extremely Low-Resource Languages", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 camera-ready", "summary": "While multilingual language models like XLM-R have advanced multilingualism\nin NLP, they still perform poorly in extremely low-resource languages. This\nsituation is exacerbated by the fact that modern LLMs such as LLaMA and Qwen\nsupport far fewer languages than XLM-R, making text generation models\nnon-existent for many languages in the world. To tackle this challenge, we\npropose a novel framework for adapting multilingual encoders to text generation\nin extremely low-resource languages. By reusing the weights between the encoder\nand the decoder, our framework allows the model to leverage the learned\nsemantic space of the encoder, enabling efficient learning and effective\ngeneralization in low-resource languages. Applying this framework to four\nChinese minority languages, we present XLM-SWCM, and demonstrate its superior\nperformance on various downstream tasks even when compared with much larger\nmodels.", "AI": {"tldr": "A framework adapts multilingual encoders for text generation in low-resource languages, outperforming larger models.", "motivation": "Address poor performance of multilingual models in low-resource languages and lack of support in modern LLMs.", "method": "Reuse encoder-decoder weights to leverage semantic space for efficient learning.", "result": "XLM-SWCM shows superior performance in Chinese minority languages.", "conclusion": "The framework effectively enables text generation in low-resource languages."}}
{"id": "2412.15484", "pdf": "https://arxiv.org/pdf/2412.15484", "abs": "https://arxiv.org/abs/2412.15484", "authors": ["Saehyung Lee", "Seunghyun Yoon", "Trung Bui", "Jing Shi", "Sungroh Yoon"], "title": "Toward Robust Hyper-Detailed Image Captioning: A Multiagent Approach and Dual Evaluation Metrics for Factuality and Coverage", "categories": ["cs.CV"], "comment": "ICML 2025", "summary": "Multimodal large language models (MLLMs) excel at generating highly detailed\ncaptions but often produce hallucinations. Our analysis reveals that existing\nhallucination detection methods struggle with detailed captions. We attribute\nthis to the increasing reliance of MLLMs on their generated text, rather than\nthe input image, as the sequence length grows. To address this issue, we\npropose a multiagent approach that leverages LLM-MLLM collaboration to correct\ngiven captions. Additionally, we introduce an evaluation framework and a\nbenchmark dataset to facilitate the systematic analysis of detailed captions.\nOur experiments demonstrate that our proposed evaluation method better aligns\nwith human judgments of factuality than existing metrics and that existing\napproaches to improve the MLLM factuality may fall short in hyper-detailed\nimage captioning tasks. In contrast, our proposed method significantly enhances\nthe factual accuracy of captions, even improving those generated by GPT-4V.\nFinally, we highlight a limitation of VQA-centric benchmarking by demonstrating\nthat an MLLM's performance on VQA benchmarks may not correlate with its ability\nto generate detailed image captions.", "AI": {"tldr": "The paper addresses hallucinations in multimodal large language models (MLLMs) during detailed caption generation, proposing a multiagent LLM-MLLM collaboration to correct captions and introducing a new evaluation framework and benchmark dataset.", "motivation": "Existing hallucination detection methods struggle with detailed captions due to MLLMs' increasing reliance on generated text over input images as sequence length grows.", "method": "A multiagent approach leveraging LLM-MLLM collaboration is proposed to correct captions, alongside a new evaluation framework and benchmark dataset.", "result": "The proposed method outperforms existing metrics in aligning with human judgments of factuality and significantly enhances caption accuracy, even for GPT-4V.", "conclusion": "The paper highlights limitations of VQA-centric benchmarking and demonstrates the effectiveness of the proposed method in improving factual accuracy for detailed captions."}}
{"id": "2407.11500", "pdf": "https://arxiv.org/pdf/2407.11500", "abs": "https://arxiv.org/abs/2407.11500", "authors": ["Niamh Belton", "Aonghus Lawlor", "Kathleen M. Curran"], "title": "An AI System for Continuous Knee Osteoarthritis Severity Grading Using Self-Supervised Anomaly Detection with Limited Data", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "The diagnostic accuracy and subjectivity of existing Knee Osteoarthritis (OA)\nordinal grading systems has been a subject of on-going debate and concern.\nExisting automated solutions are trained to emulate these imperfect systems,\nwhilst also being reliant on large annotated databases for fully-supervised\ntraining. This work proposes a three stage approach for automated continuous\ngrading of knee OA that is built upon the principles of Anomaly Detection (AD);\nlearning a robust representation of healthy knee X-rays and grading disease\nseverity based on its distance to the centre of normality. In the first stage,\nSS-FewSOME is proposed, a self-supervised AD technique that learns the 'normal'\nrepresentation, requiring only examples of healthy subjects and <3% of the\nlabels that existing methods require. In the second stage, this model is used\nto pseudo label a subset of unlabelled data as 'normal' or 'anomalous',\nfollowed by denoising of pseudo labels with CLIP. The final stage involves\nretraining on labelled and pseudo labelled data using the proposed Dual Centre\nRepresentation Learning (DCRL) which learns the centres of two representation\nspaces; normal and anomalous. Disease severity is then graded based on the\ndistance to the learned centres. The proposed methodology outperforms existing\ntechniques by margins of up to 24% in terms of OA detection and the disease\nseverity scores correlate with the Kellgren-Lawrence grading system at the same\nlevel as human expert performance. Code available at\nhttps://github.com/niamhbelton/SS-FewSOME_Disease_Severity_Knee_Osteoarthritis.", "AI": {"tldr": "A three-stage self-supervised anomaly detection approach for continuous grading of knee osteoarthritis, requiring minimal labeled data and outperforming existing methods by up to 24%.", "motivation": "Addressing the subjectivity and inaccuracy of existing knee OA grading systems and reducing reliance on large annotated datasets.", "method": "1. SS-FewSOME for learning healthy knee representations. 2. Pseudo-labeling and denoising with CLIP. 3. Dual Centre Representation Learning (DCRL) for grading based on distance to normality.", "result": "Outperforms existing methods by up to 24% in OA detection, with severity scores correlating with expert human performance.", "conclusion": "The proposed method offers a robust, data-efficient solution for continuous knee OA grading, aligning with expert assessments."}}
{"id": "2505.23056", "pdf": "https://arxiv.org/pdf/2505.23056", "abs": "https://arxiv.org/abs/2505.23056", "authors": ["Zijian Liu", "Zhengyuan Zhou"], "title": "Improved Last-Iterate Convergence of Shuffling Gradient Methods for Nonsmooth Convex Optimization", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": "ICML 2025", "summary": "We study the convergence of the shuffling gradient method, a popular\nalgorithm employed to minimize the finite-sum function with regularization, in\nwhich functions are passed to apply (Proximal) Gradient Descent (GD) one by one\nwhose order is determined by a permutation on the indices of functions. In\ncontrast to its easy implementation and effective performance in practice, the\ntheoretical understanding remains limited. A recent advance by (Liu & Zhou,\n2024b) establishes the first last-iterate convergence results under various\nsettings, especially proving the optimal rates for smooth (strongly) convex\noptimization. However, their bounds for nonsmooth (strongly) convex functions\nare only as fast as Proximal GD. In this work, we provide the first improved\nlast-iterate analysis for the nonsmooth case demonstrating that the widely used\nRandom Reshuffle ($\\textsf{RR}$) and Single Shuffle ($\\textsf{SS}$) strategies\nare both provably faster than Proximal GD, reflecting the benefit of\nrandomness. As an important implication, we give the first (nearly) optimal\nconvergence result for the suffix average under the $\\textsf{RR}$ sampling\nscheme in the general convex case, matching the lower bound shown by (Koren et\nal., 2022).", "AI": {"tldr": "The paper improves last-iterate convergence analysis for nonsmooth (strongly) convex functions in shuffling gradient methods, showing Random Reshuffle (RR) and Single Shuffle (SS) outperform Proximal GD.", "motivation": "Despite practical effectiveness, theoretical understanding of shuffling gradient methods is limited, especially for nonsmooth cases.", "method": "Analyzes RR and SS strategies, comparing them to Proximal GD for nonsmooth (strongly) convex functions.", "result": "RR and SS are provably faster than Proximal GD, with RR achieving nearly optimal convergence for suffix averages.", "conclusion": "The work advances theoretical understanding of shuffling methods, demonstrating benefits of randomness in nonsmooth optimization."}}
{"id": "2502.11115", "pdf": "https://arxiv.org/pdf/2502.11115", "abs": "https://arxiv.org/abs/2502.11115", "authors": ["Tu Anh Dinh", "Jan Niehues"], "title": "Are Generative Models Underconfident? Better Quality Estimation with Boosted Model Probability", "categories": ["cs.CL", "I.2.7"], "comment": null, "summary": "Quality Estimation (QE) is estimating quality of the model output during\ninference when the ground truth is not available. Deriving output quality from\nthe models' output probability is the most trivial and low-effort way. However,\nwe show that the output probability of text-generation models can appear\nunderconfident. At each output step, there can be multiple correct options,\nmaking the probability distribution spread out more. Thus, lower probability\ndoes not necessarily mean lower output quality. Due to this observation, we\npropose a QE approach called BoostedProb, which boosts the model's confidence\nin cases where there are multiple viable output options. With no increase in\ncomplexity, BoostedProb is notably better than raw model probability in\ndifferent settings, achieving on average +0.194 improvement in Pearson\ncorrelation to ground-truth quality. It also comes close to or outperforms more\ncostly approaches like supervised or ensemble-based QE in certain settings.", "AI": {"tldr": "BoostedProb improves QE by boosting model confidence when multiple correct outputs exist, outperforming raw probabilities and matching costly methods.", "motivation": "Output probabilities in text-generation models can be underconfident due to multiple correct options, making them unreliable for quality estimation.", "method": "Proposes BoostedProb, a method to boost model confidence in cases with multiple viable outputs, without added complexity.", "result": "Achieves +0.194 average improvement in Pearson correlation to ground-truth quality, performing comparably to costly QE methods.", "conclusion": "BoostedProb is a simple yet effective QE approach, addressing underconfidence in model probabilities and matching advanced methods."}}
{"id": "2412.15819", "pdf": "https://arxiv.org/pdf/2412.15819", "abs": "https://arxiv.org/abs/2412.15819", "authors": ["Cheng Wang", "Ziyang Feng", "Pin Zhang", "Manjiang Cao", "Yiming Yuan", "Tengfei Chang"], "title": "Robustness-enhanced Myoelectric Control with GAN-based Open-set Recognition", "categories": ["cs.CV", "cs.HC", "eess.SP"], "comment": "11 pages, 14 figures", "summary": "Electromyography (EMG) signals are widely used in human motion recognition\nand medical rehabilitation, yet their variability and susceptibility to noise\nsignificantly limit the reliability of myoelectric control systems. Existing\nrecognition algorithms often fail to handle unfamiliar actions effectively,\nleading to system instability and errors. This paper proposes a novel framework\nbased on Generative Adversarial Networks (GANs) to enhance the robustness and\nusability of myoelectric control systems by enabling open-set recognition. The\nmethod incorporates a GAN-based discriminator to identify and reject unknown\nactions, maintaining system stability by preventing misclassifications.\nExperimental evaluations on publicly available and self-collected datasets\ndemonstrate a recognition accuracy of 97.6\\% for known actions and a 23.6\\%\nimprovement in Active Error Rate (AER) after rejecting unknown actions. The\nproposed approach is computationally efficient and suitable for deployment on\nedge devices, making it practical for real-world applications.", "AI": {"tldr": "A GAN-based framework improves EMG signal recognition by enabling open-set recognition, achieving 97.6% accuracy for known actions and reducing errors for unknown ones.", "motivation": "EMG signals are prone to variability and noise, and existing systems struggle with unfamiliar actions, leading to instability.", "method": "Uses a GAN-based discriminator to identify and reject unknown actions, enhancing system robustness.", "result": "Achieves 97.6% accuracy for known actions and a 23.6% improvement in Active Error Rate for unknown actions.", "conclusion": "The method is efficient, robust, and suitable for edge devices, making it practical for real-world use."}}
{"id": "2408.12845", "pdf": "https://arxiv.org/pdf/2408.12845", "abs": "https://arxiv.org/abs/2408.12845", "authors": ["Arun Verma", "Indrajit Saha", "Makoto Yokoo", "Bryan Kian Hsiang Low"], "title": "Keep Everyone Happy: Online Fair Division of Numerous Items with Few Copies", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "We propose a contextual bandit algorithm for online fair division\n  problems involving multiple agents and a large number of items, each with\n  only a few copies", "summary": "This paper considers a novel variant of the online fair division problem\ninvolving multiple agents in which a learner sequentially observes an\nindivisible item that has to be irrevocably allocated to one of the agents\nwhile satisfying a fairness and efficiency constraint. Existing algorithms\nassume a small number of items with a sufficiently large number of copies,\nwhich ensures a good utility estimation for all item-agent pairs from noisy\nbandit feedback. However, this assumption may not hold in many real-life\napplications, for example, an online platform that has a large number of users\n(items) who use the platform's service providers (agents) only a few times (a\nfew copies of items), which makes it difficult to accurately estimate utilities\nfor all item-agent pairs. To address this, we assume utility is an unknown\nfunction of item-agent features. We then propose algorithms that model online\nfair division as a contextual bandit problem, with sub-linear regret\nguarantees. Our experimental results further validate the effectiveness of the\nproposed algorithms.", "AI": {"tldr": "The paper introduces a contextual bandit approach for online fair division with sub-linear regret, addressing utility estimation challenges in sparse real-world scenarios.", "motivation": "Existing fair division algorithms fail in real-world settings with many items and few copies, making utility estimation inaccurate.", "method": "Proposes modeling the problem as a contextual bandit, using item-agent features to estimate utilities and ensure fairness.", "result": "Algorithms achieve sub-linear regret guarantees and perform well in experiments.", "conclusion": "The contextual bandit approach effectively handles sparse utility estimation in online fair division."}}
{"id": "2505.23081", "pdf": "https://arxiv.org/pdf/2505.23081", "abs": "https://arxiv.org/abs/2505.23081", "authors": ["Wenzhi Gao", "Ya-Chi Chu", "Yinyu Ye", "Madeleine Udell"], "title": "Gradient Methods with Online Scaling Part I. Theoretical Foundations", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": "Extension of arXiv:2411.01803 and arXiv:2502.11229", "summary": "This paper establishes the theoretical foundations of the online scaled\ngradient methods (OSGM), a framework that utilizes online learning to adapt\nstepsizes and provably accelerate first-order methods. OSGM quantifies the\neffectiveness of a stepsize by a feedback function motivated from a convergence\nmeasure and uses the feedback to adjust the stepsize through an online learning\nalgorithm. Consequently, instantiations of OSGM achieve convergence rates that\nare asymptotically no worse than the optimal stepsize. OSGM yields desirable\nconvergence guarantees on smooth convex problems, including 1)\ntrajectory-dependent global convergence on smooth convex objectives; 2) an\nimproved complexity result on smooth strongly convex problems, and 3) local\nsuperlinear convergence. Notably, OSGM constitutes a new family of first-order\nmethods with non-asymptotic superlinear convergence, joining the celebrated\nquasi-Newton methods. Finally, OSGM explains the empirical success of the\npopular hypergradient-descent heuristic in optimization for machine learning.", "AI": {"tldr": "OSGM is a framework using online learning to adapt stepsizes, achieving optimal convergence rates and explaining hypergradient-descent success.", "motivation": "To accelerate first-order methods by dynamically adjusting stepsizes using online learning, improving convergence guarantees.", "method": "OSGM uses a feedback function to quantify stepsize effectiveness and adjusts it via online learning, ensuring no worse than optimal convergence rates.", "result": "Achieves trajectory-dependent global convergence, improved complexity on strongly convex problems, and local superlinear convergence.", "conclusion": "OSGM is a novel first-order method with non-asymptotic superlinear convergence, bridging theory and practice in optimization."}}
{"id": "2502.11501", "pdf": "https://arxiv.org/pdf/2502.11501", "abs": "https://arxiv.org/abs/2502.11501", "authors": ["Zichen Wen", "Yifeng Gao", "Weijia Li", "Conghui He", "Linfeng Zhang"], "title": "Token Pruning in Multimodal Large Language Models: Are We Solving the Right Problem?", "categories": ["cs.CL", "cs.CV"], "comment": "ACL 2025 Findings", "summary": "Multimodal large language models (MLLMs) have shown remarkable performance\nfor cross-modal understanding and generation, yet still suffer from severe\ninference costs. Recently, abundant works have been proposed to solve this\nproblem with token pruning, which identifies the redundant tokens in MLLMs and\nthen prunes them to reduce the computation and KV storage costs, leading to\nsignificant acceleration without training. While these methods claim efficiency\ngains, critical questions about their fundamental design and evaluation remain\nunanswered: Why do many existing approaches underperform even compared to naive\nrandom token selection? Are attention-based scoring sufficient for reliably\nidentifying redundant tokens? Is language information really helpful during\ntoken pruning? What makes a good trade-off between token importance and\nduplication? Are current evaluation protocols comprehensive and unbiased? The\nignorance of previous research on these problems hinders the long-term\ndevelopment of token pruning. In this paper, we answer these questions one by\none, providing insights into the design of future token pruning methods.", "AI": {"tldr": "The paper critiques existing token pruning methods in MLLMs, questioning their effectiveness and evaluation, and provides insights for future designs.", "motivation": "To address the underperformance and unanswered questions in token pruning methods for MLLMs, aiming to improve efficiency and reliability.", "method": "Analyzes existing token pruning approaches, evaluates their design, and answers critical questions about their effectiveness.", "result": "Provides insights into why current methods underperform and suggests improvements for future token pruning techniques.", "conclusion": "The paper highlights gaps in current token pruning research and offers guidance for more effective and reliable methods."}}
{"id": "2412.16039", "pdf": "https://arxiv.org/pdf/2412.16039", "abs": "https://arxiv.org/abs/2412.16039", "authors": ["Jiadong Pan", "Liang Li", "Hongcheng Gao", "Zheng-Jun Zha", "Qingming Huang", "Jiebo Luo"], "title": "SafeCFG: Controlling Harmful Features with Dynamic Safe Guidance for Safe Generation", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion models (DMs) have demonstrated exceptional performance in\ntext-to-image tasks, leading to their widespread use. With the introduction of\nclassifier-free guidance (CFG), the quality of images generated by DMs is\nsignificantly improved. However, one can use DMs to generate more harmful\nimages by maliciously guiding the image generation process through CFG.\nExisting safe alignment methods aim to mitigate the risk of generating harmful\nimages but often reduce the quality of clean image generation. To address this\nissue, we propose SafeCFG to adaptively control harmful features with dynamic\nsafe guidance by modulating the CFG generation process. It dynamically guides\nthe CFG generation process based on the harmfulness of the prompts, inducing\nsignificant deviations only in harmful CFG generations, achieving high quality\nand safety generation. SafeCFG can simultaneously modulate different harmful\nCFG generation processes, so it could eliminate harmful elements while\npreserving high-quality generation. Additionally, SafeCFG provides the ability\nto detect image harmfulness, allowing unsupervised safe alignment on DMs\nwithout pre-defined clean or harmful labels. Experimental results show that\nimages generated by SafeCFG achieve both high quality and safety, and safe DMs\ntrained in our unsupervised manner also exhibit good safety performance.", "AI": {"tldr": "SafeCFG improves diffusion models by dynamically controlling harmful image generation while maintaining quality, using adaptive guidance and unsupervised harmfulness detection.", "motivation": "Existing safe alignment methods reduce image quality when mitigating harmful image generation. SafeCFG aims to address this by dynamically guiding the generation process.", "method": "SafeCFG modulates classifier-free guidance (CFG) adaptively based on prompt harmfulness, inducing deviations only in harmful generations. It also detects harmfulness without predefined labels.", "result": "SafeCFG achieves high-quality and safe image generation, outperforming existing methods. Unsupervised training also shows good safety performance.", "conclusion": "SafeCFG effectively balances quality and safety in diffusion models, offering a robust solution for harmful image generation."}}
{"id": "2409.06957", "pdf": "https://arxiv.org/pdf/2409.06957", "abs": "https://arxiv.org/abs/2409.06957", "authors": ["Chuheng Zhang", "Wei Shen", "Li Zhao", "Xuyun Zhang", "Xiaolong Xu", "Wanchun Dou", "Jiang Biang"], "title": "Policy Filtration for RLHF to Mitigate Noise in Reward Models", "categories": ["cs.LG", "cs.AI"], "comment": "ICML2025", "summary": "While direct policy optimization methods exist, pioneering LLMs are\nfine-tuned with reinforcement learning from human feedback (RLHF) to generate\nbetter responses under the supervision of a reward model learned from\npreference data. One major challenge of RLHF is the inaccuracy of the\nintermediate reward model, especially in the tasks that requires complex\nreasoning for the reward model to score a response. We find that the\nreliability of the reward model varies across responses assigned with different\nrewards. This motivates us to filter the samples whose rewards may be\nunreliable to improve the signal-to-noise ratio during policy learning,\nresulting in Policy Filtration for Proximal Policy Optimization (PF-PPO). To\nchoose a proper policy filtering strategy, we use the coefficient of\ndetermination (R2) between the rewards and actual scores on filtered samples as\nthe metrics to help us find promising strategies since it measures how well the\nrewards filtered by PF-PPO indicate real performance. We provide extensive\nexperiments to validate the effectiveness of PF-PPO in code generation and math\nreasoning tasks. In code generation, PF-PPO achieves the state-of-the-art\nperformance of 7-billion-parameter models on HumanEval (+7.9%), MBPP (+0.7%),\nand LeetCode Contest (+10.0%) which is a more challenging benchmark created by\nus. In math reasoning, PF-PPO yields performance increase using different\nreward models and benchmarks (Ape210K and CMATH). Code is available on\nhttps://github.com/DtYXs/verl/tree/pf-ppo.", "AI": {"tldr": "PF-PPO improves RLHF by filtering unreliable reward samples, enhancing policy learning in tasks like code generation and math reasoning.", "motivation": "The inaccuracy of intermediate reward models in RLHF, especially for complex reasoning tasks, motivates filtering unreliable samples to improve learning.", "method": "Proposes Policy Filtration for Proximal Policy Optimization (PF-PPO), using R2 metrics to select filtering strategies for better reward reliability.", "result": "PF-PPO achieves state-of-the-art performance in code generation (HumanEval, MBPP, LeetCode) and math reasoning (Ape210K, CMATH).", "conclusion": "PF-PPO effectively addresses reward model inaccuracies, improving performance in complex tasks."}}
{"id": "2505.23124", "pdf": "https://arxiv.org/pdf/2505.23124", "abs": "https://arxiv.org/abs/2505.23124", "authors": ["Junyan Liu", "Arnab Maiti", "Artin Tajdini", "Kevin Jamieson", "Lillian J. Ratliff"], "title": "Learning to Incentivize in Repeated Principal-Agent Problems with Adversarial Agent Arrivals", "categories": ["cs.GT", "cs.LG"], "comment": "To appear at ICML 2025", "summary": "We initiate the study of a repeated principal-agent problem over a finite\nhorizon $T$, where a principal sequentially interacts with $K\\geq 2$ types of\nagents arriving in an adversarial order. At each round, the principal\nstrategically chooses one of the $N$ arms to incentivize for an arriving agent\nof unknown type. The agent then chooses an arm based on its own utility and the\nprovided incentive, and the principal receives a corresponding reward. The\nobjective is to minimize regret against the best incentive in hindsight.\nWithout prior knowledge of agent behavior, we show that the problem becomes\nintractable, leading to linear regret. We analyze two key settings where\nsublinear regret is achievable. In the first setting, the principal knows the\narm each agent type would select greedily for any given incentive. Under this\nsetting, we propose an algorithm that achieves a regret bound of\n$O(\\min\\{\\sqrt{KT\\log N},K\\sqrt{T}\\})$ and provide a matching lower bound up to\na $\\log K$ factor. In the second setting, an agent's response varies smoothly\nwith the incentive and is governed by a Lipschitz constant $L\\geq 1$. Under\nthis setting, we show that there is an algorithm with a regret bound of\n$\\tilde{O}((LN)^{1/3}T^{2/3})$ and establish a matching lower bound up to\nlogarithmic factors. Finally, we extend our algorithmic results for both\nsettings by allowing the principal to incentivize multiple arms simultaneously\nin each round.", "AI": {"tldr": "The paper studies a repeated principal-agent problem with adversarial agent arrivals, proposing algorithms for two settings to achieve sublinear regret.", "motivation": "To address the challenge of minimizing regret in a repeated principal-agent interaction where agent types and behaviors are unknown or adversarial.", "method": "Analyzes two settings: 1) known greedy agent behavior, proposing an algorithm with regret bound O(min{\u221a(KT log N), K\u221aT}); 2) Lipschitz-smooth agent responses, achieving regret bound ~O((LN)^(1/3)T^(2/3). Extends to multi-arm incentivization.", "result": "Sublinear regret is achievable in both settings, with matching lower bounds (up to logarithmic factors).", "conclusion": "The paper provides tractable solutions for the principal-agent problem under specific assumptions, with theoretical guarantees on regret minimization."}}
{"id": "2502.11862", "pdf": "https://arxiv.org/pdf/2502.11862", "abs": "https://arxiv.org/abs/2502.11862", "authors": ["Renhao Pei", "Yihong Liu", "Peiqin Lin", "Fran\u00e7ois Yvon", "Hinrich Sch\u00fctze"], "title": "Understanding In-Context Machine Translation for Low-Resource Languages: A Case Study on Manchu", "categories": ["cs.CL"], "comment": "ACL 2025", "summary": "In-context machine translation (MT) with large language models (LLMs) is a\npromising approach for low-resource MT, as it can readily take advantage of\nlinguistic resources such as grammar books and dictionaries. Such resources are\nusually selectively integrated into the prompt so that LLMs can directly\nperform translation without any specific training, via their in-context\nlearning capability (ICL). However, the relative importance of each type of\nresource, e.g., dictionary, grammar book, and retrieved parallel examples, is\nnot entirely clear. To address this gap, this study systematically investigates\nhow each resource and its quality affect the translation performance, with the\nManchu language as our case study. To remove any prior knowledge of Manchu\nencoded in the LLM parameters and single out the effect of ICL, we also\nexperiment with an enciphered version of Manchu texts. Our results indicate\nthat high-quality dictionaries and good parallel examples are very helpful,\nwhile grammars hardly help. In a follow-up study, we showcase a promising\napplication of in-context MT: parallel data augmentation as a way to bootstrap\na conventional MT model. When monolingual data abound, generating synthetic\nparallel data through in-context MT offers a pathway to mitigate data scarcity\nand build effective and efficient low-resource neural MT systems.", "AI": {"tldr": "The paper explores in-context machine translation (MT) using LLMs for low-resource languages, focusing on the impact of different linguistic resources like dictionaries, grammar books, and parallel examples. It finds dictionaries and parallel examples most helpful, with grammars offering little benefit. It also demonstrates synthetic parallel data generation as a solution for low-resource MT.", "motivation": "To understand the relative importance of linguistic resources (dictionaries, grammar books, parallel examples) in in-context MT and address data scarcity in low-resource MT.", "method": "Systematically evaluates the impact of each resource on translation performance using Manchu as a case study, including experiments with enciphered texts to isolate ICL effects.", "result": "High-quality dictionaries and parallel examples significantly improve translation, while grammars provide minimal benefit. Synthetic parallel data generation via in-context MT aids low-resource MT systems.", "conclusion": "In-context MT with LLMs is effective for low-resource languages, especially when leveraging dictionaries and parallel examples, and can bootstrap conventional MT models through data augmentation."}}
{"id": "2501.05874", "pdf": "https://arxiv.org/pdf/2501.05874", "abs": "https://arxiv.org/abs/2501.05874", "authors": ["Soyeong Jeong", "Kangsan Kim", "Jinheon Baek", "Sung Ju Hwang"], "title": "VideoRAG: Retrieval-Augmented Generation over Video Corpus", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.IR", "cs.LG"], "comment": "ACL Findings 2025", "summary": "Retrieval-Augmented Generation (RAG) is a powerful strategy for improving the\nfactual accuracy of models by retrieving external knowledge relevant to queries\nand incorporating it into the generation process. However, existing approaches\nprimarily focus on text, with some recent advancements considering images, and\nthey largely overlook videos, a rich source of multimodal knowledge capable of\nrepresenting contextual details more effectively than any other modality. While\nvery recent studies explore the use of videos in response generation, they\neither predefine query-associated videos without retrieval or convert videos\ninto textual descriptions losing multimodal richness. To tackle these, we\nintroduce VideoRAG, a framework that not only dynamically retrieves videos\nbased on their relevance with queries but also utilizes both visual and textual\ninformation. The operation of VideoRAG is powered by recent Large Video\nLanguage Models (LVLMs), which enable the direct processing of video content to\nrepresent it for retrieval and the seamless integration of retrieved videos\njointly with queries for response generation. Also, inspired by that the\ncontext size of LVLMs may not be sufficient to process all frames in extremely\nlong videos and not all frames are equally important, we introduce a video\nframe selection mechanism to extract the most informative subset of frames,\nalong with a strategy to extract textual information from videos (as it can aid\nthe understanding of video content) when their subtitles are not available. We\nexperimentally validate the effectiveness of VideoRAG, showcasing that it is\nsuperior to relevant baselines. Code is available at\nhttps://github.com/starsuzi/VideoRAG.", "AI": {"tldr": "VideoRAG enhances factual accuracy by dynamically retrieving and integrating relevant videos, leveraging both visual and textual information, and optimizing frame selection for efficiency.", "motivation": "Existing RAG methods focus on text or images, neglecting videos' rich multimodal context. VideoRAG addresses this gap by dynamically retrieving and processing videos.", "method": "VideoRAG uses Large Video Language Models (LVLMs) to retrieve and process videos, with a frame selection mechanism and text extraction for videos lacking subtitles.", "result": "VideoRAG outperforms baselines, demonstrating superior performance in leveraging multimodal video content.", "conclusion": "VideoRAG effectively integrates videos into RAG, improving factual accuracy and multimodal understanding, with potential for broader applications."}}
{"id": "2410.03810", "pdf": "https://arxiv.org/pdf/2410.03810", "abs": "https://arxiv.org/abs/2410.03810", "authors": ["Ruifeng Ren", "Zhicong Li", "Yong Liu"], "title": "Exploring the Limitations of Mamba in COPY and CoT Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Mamba, Chain of Thought", "summary": "Transformers have become the backbone of modern Large Language Models (LLMs);\nhowever, their inference overhead grows linearly with the sequence length,\nposing challenges for modeling long sequences. In light of this, Mamba has\nattracted attention for maintaining a constant inference size, with empirical\nevidence demonstrating that it can match Transformer performance in sequence\nmodeling while significantly reducing computational costs. However, an open\nquestion remains: can Mamba always bring savings while achieving performance\ncomparable to Transformers? In this paper, we focus on analyzing the expressive\nability of Mamba to perform our defined COPY operation and Chain of Thought\n(CoT) reasoning. First, inspired by the connection between Mamba and linear\nattention, we show that constant-sized Mamba may struggle to perform COPY\noperations while Transformers can handle them more easily. However, when the\nsize of Mamba grows linearly with the input sequence length, it can accurately\nperform COPY, but in this case, Mamba no longer provides overhead savings.\nBased on this observation, we further analyze Mamba's ability to tackle CoT\ntasks, which can be described by the Dynamic Programming (DP) problems. Our\nfindings suggest that to solve arbitrary DP problems, the total cost of Mamba\nis still comparable to standard Transformers. However, similar to efficient\nTransformers, when facing DP problems with favorable properties such as\nlocality, Mamba can provide savings in overhead. Our experiments on the copy\nand CoT tasks further demonstrate Mamba's limitations compared to Transformers\nin learning these tasks.", "AI": {"tldr": "Mamba's constant inference size offers computational savings but struggles with COPY operations and CoT reasoning compared to Transformers, unless its size grows linearly, negating overhead benefits.", "motivation": "To analyze Mamba's expressive ability in COPY operations and CoT reasoning, comparing it to Transformers to understand its limitations and potential savings.", "method": "Theoretical analysis connecting Mamba to linear attention, experiments on COPY and CoT tasks, and comparison with Transformers.", "result": "Mamba struggles with COPY unless size grows linearly, and its cost for CoT tasks matches Transformers unless problems have favorable properties like locality.", "conclusion": "Mamba's savings are context-dependent; it matches Transformers only in specific scenarios, highlighting its limitations in expressive power."}}
{"id": "2505.23160", "pdf": "https://arxiv.org/pdf/2505.23160", "abs": "https://arxiv.org/abs/2505.23160", "authors": ["Lorenzo Marinucci", "Claudio Battiloro", "Paolo Di Lorenzo"], "title": "Topological Adaptive Least Mean Squares Algorithms over Simplicial Complexes", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "This paper introduces a novel adaptive framework for processing dynamic flow\nsignals over simplicial complexes, extending classical least-mean-squares (LMS)\nmethods to high-order topological domains. Building on discrete Hodge theory,\nwe present a topological LMS algorithm that efficiently processes streaming\nsignals observed over time-varying edge subsets. We provide a detailed\nstochastic analysis of the algorithm, deriving its stability conditions,\nsteady-state mean-square-error, and convergence speed, while exploring the\nimpact of edge sampling on performance. We also propose strategies to design\noptimal edge sampling probabilities, minimizing rate while ensuring desired\nestimation accuracy. Assuming partial knowledge of the complex structure (e.g.,\nthe underlying graph), we introduce an adaptive topology inference method that\nintegrates with the proposed LMS framework. Additionally, we propose a\ndistributed version of the algorithm and analyze its stability and\nmean-square-error properties. Empirical results on synthetic and real-world\ntraffic data demonstrate that our approach, in both centralized and distributed\nsettings, outperforms graph-based LMS methods by leveraging higher-order\ntopological features.", "AI": {"tldr": "A novel adaptive framework for processing dynamic flow signals over simplicial complexes, extending LMS methods to high-order topological domains, outperforming graph-based LMS methods.", "motivation": "To extend classical LMS methods to high-order topological domains for better processing of dynamic flow signals, leveraging higher-order topological features.", "method": "Introduces a topological LMS algorithm based on discrete Hodge theory, with stochastic analysis, stability conditions, and optimal edge sampling strategies. Includes adaptive topology inference and a distributed version.", "result": "Outperforms graph-based LMS methods in both centralized and distributed settings, as shown by empirical results on synthetic and real-world traffic data.", "conclusion": "The proposed framework effectively leverages higher-order topological features, offering improved performance and adaptability for dynamic signal processing."}}
{"id": "2502.11926", "pdf": "https://arxiv.org/pdf/2502.11926", "abs": "https://arxiv.org/abs/2502.11926", "authors": ["Shamsuddeen Hassan Muhammad", "Nedjma Ousidhoum", "Idris Abdulmumin", "Jan Philip Wahle", "Terry Ruas", "Meriem Beloucif", "Christine de Kock", "Nirmal Surange", "Daniela Teodorescu", "Ibrahim Said Ahmad", "David Ifeoluwa Adelani", "Alham Fikri Aji", "Felermino D. M. A. Ali", "Ilseyar Alimova", "Vladimir Araujo", "Nikolay Babakov", "Naomi Baes", "Ana-Maria Bucur", "Andiswa Bukula", "Guanqun Cao", "Rodrigo Tufino Cardenas", "Rendi Chevi", "Chiamaka Ijeoma Chukwuneke", "Alexandra Ciobotaru", "Daryna Dementieva", "Murja Sani Gadanya", "Robert Geislinger", "Bela Gipp", "Oumaima Hourrane", "Oana Ignat", "Falalu Ibrahim Lawan", "Rooweither Mabuya", "Rahmad Mahendra", "Vukosi Marivate", "Alexander Panchenko", "Andrew Piper", "Charles Henrique Porto Ferreira", "Vitaly Protasov", "Samuel Rutunda", "Manish Shrivastava", "Aura Cristina Udrea", "Lilian Diana Awuor Wanzare", "Sophie Wu", "Florian Valentin Wunderlich", "Hanif Muhammad Zhafran", "Tianhui Zhang", "Yi Zhou", "Saif M. Mohammad"], "title": "BRIGHTER: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages", "categories": ["cs.CL"], "comment": "Accepted at ACL2025 (Main)", "summary": "People worldwide use language in subtle and complex ways to express emotions.\nAlthough emotion recognition--an umbrella term for several NLP tasks--impacts\nvarious applications within NLP and beyond, most work in this area has focused\non high-resource languages. This has led to significant disparities in research\nefforts and proposed solutions, particularly for under-resourced languages,\nwhich often lack high-quality annotated datasets. In this paper, we present\nBRIGHTER--a collection of multi-labeled, emotion-annotated datasets in 28\ndifferent languages and across several domains. BRIGHTER primarily covers\nlow-resource languages from Africa, Asia, Eastern Europe, and Latin America,\nwith instances labeled by fluent speakers. We highlight the challenges related\nto the data collection and annotation processes, and then report experimental\nresults for monolingual and crosslingual multi-label emotion identification, as\nwell as emotion intensity recognition. We analyse the variability in\nperformance across languages and text domains, both with and without the use of\nLLMs, and show that the BRIGHTER datasets represent a meaningful step towards\naddressing the gap in text-based emotion recognition.", "AI": {"tldr": "BRIGHTER introduces multi-labeled emotion-annotated datasets in 28 low-resource languages, addressing disparities in emotion recognition research.", "motivation": "To bridge the gap in emotion recognition research for under-resourced languages lacking annotated datasets.", "method": "Collection of datasets across 28 languages, annotated by fluent speakers, with experiments on monolingual/crosslingual emotion identification and intensity recognition.", "result": "Varied performance across languages and domains, with LLMs showing potential. BRIGHTER datasets advance emotion recognition for low-resource languages.", "conclusion": "BRIGHTER is a significant step toward equitable emotion recognition research, though challenges in data collection and annotation persist."}}
{"id": "2501.06922", "pdf": "https://arxiv.org/pdf/2501.06922", "abs": "https://arxiv.org/abs/2501.06922", "authors": ["Woubishet Zewdu Taffese", "Ritesh Sharma", "Mohammad Hossein Afsharmovahed", "Gunasekaran Manogaran", "Genda Chen"], "title": "Benchmarking YOLOv8 for Optimal Crack Detection in Civil Infrastructure", "categories": ["cs.CV"], "comment": "We would like to extend/modify this work and make changes for\n  resubmission to a different place. Hence we would like to withdraw the paper", "summary": "Ensuring the structural integrity and safety of bridges is crucial for the\nreliability of transportation networks and public safety. Traditional crack\ndetection methods are increasingly being supplemented or replaced by advanced\nartificial intelligence (AI) techniques. However, most of the models rely on\ntwo-stage target detection algorithms, which pose concerns for real-time\napplications due to their lower speed. While models such as YOLO (You Only Look\nOnce) have emerged as transformative tools due to their remarkable speed and\naccuracy. However, the potential of the latest YOLOv8 framework in this domain\nremains underexplored. This study bridges that gap by rigorously evaluating\nYOLOv8's performance across five model scales (nano, small, medium, large, and\nextra-large) using a high-quality Roboflow dataset. A comprehensive\nhyperparameter optimization was performed, testing six state-of-the-art\noptimizers-Stochastic Gradient Descent, Adaptive Moment Estimation, Adam with\nDecoupled Weight Decay, Root Mean Square Propagation, Rectified Adam, and\nNesterov-accelerated Adam. Results revealed that YOLOv8, optimized with\nStochastic Gradient Descent, delivered exceptional accuracy and speed, setting\na new benchmark for real-time crack detection. Beyond its immediate\napplication, this research positions YOLOv8 as a foundational approach for\nintegrating advanced computer vision techniques into infrastructure monitoring.\nBy enabling more reliable and proactive maintenance of aging bridge networks,\nthis work paves the way for safer, more efficient transportation systems\nworldwide.", "AI": {"tldr": "The study evaluates YOLOv8 for real-time bridge crack detection, optimizing it with various methods and finding Stochastic Gradient Descent delivers top performance.", "motivation": "Traditional crack detection methods are slow; AI like YOLOv8 offers faster, more accurate solutions, but its potential is underexplored.", "method": "YOLOv8 was tested across five model scales using a Roboflow dataset, with hyperparameter optimization involving six optimizers.", "result": "YOLOv8 with Stochastic Gradient Descent achieved exceptional accuracy and speed, setting a new benchmark for real-time crack detection.", "conclusion": "YOLOv8 is a foundational tool for infrastructure monitoring, enhancing bridge safety and maintenance efficiency globally."}}
{"id": "2410.06678", "pdf": "https://arxiv.org/pdf/2410.06678", "abs": "https://arxiv.org/abs/2410.06678", "authors": ["Zeyu Zhang", "Sixu Yan", "Muzhi Han", "Zaijin Wang", "Xinggang Wang", "Song-Chun Zhu", "Hangxin Liu"], "title": "M3Bench: Benchmarking Whole-body Motion Generation for Mobile Manipulation in 3D Scenes", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "This paper has been accepted by IEEE Robotics and Automation Letters\n  2025 (RA-L)", "summary": "We propose M3Bench, a new benchmark for whole-body motion generation in\nmobile manipulation tasks. Given a 3D scene context, M3Bench requires an\nembodied agent to reason about its configuration, environmental constraints,\nand task objectives to generate coordinated whole-body motion trajectories for\nobject rearrangement. M3Bench features 30,000 object rearrangement tasks across\n119 diverse scenes, providing expert demonstrations generated by our newly\ndeveloped M3BenchMaker, an automatic data generation tool that produces\nwhole-body motion trajectories from high-level task instructions using only\nbasic scene and robot information. Our benchmark includes various task splits\nto evaluate generalization across different dimensions and leverages realistic\nphysics simulation for trajectory assessment. Extensive evaluation analysis\nreveals that state-of-the-art models struggle with coordinating base-arm motion\nwhile adhering to environmental and task-specific constraints, underscoring the\nneed for new models to bridge this gap. By releasing M3Bench and M3BenchMaker\nwe aim to advance robotics research toward more adaptive and capable mobile\nmanipulation in diverse, real-world environments.", "AI": {"tldr": "M3Bench is a new benchmark for whole-body motion generation in mobile manipulation tasks, featuring 30,000 tasks across 119 scenes, with expert demonstrations from M3BenchMaker. It evaluates generalization and highlights challenges in base-arm coordination.", "motivation": "To address the lack of benchmarks for whole-body motion generation in mobile manipulation, enabling research toward adaptive robotics in real-world environments.", "method": "M3Bench uses 3D scene contexts and task objectives to generate motion trajectories, with expert demonstrations from M3BenchMaker. It includes task splits and physics simulation for evaluation.", "result": "State-of-the-art models struggle with base-arm coordination and constraint adherence, revealing a gap in current capabilities.", "conclusion": "M3Bench and M3BenchMaker aim to advance robotics research for adaptive mobile manipulation in diverse environments."}}
{"id": "2505.23196", "pdf": "https://arxiv.org/pdf/2505.23196", "abs": "https://arxiv.org/abs/2505.23196", "authors": ["Eshant English", "Christoph Lippert"], "title": "JAPAN: Joint Adaptive Prediction Areas with Normalising-Flows", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Conformal prediction provides a model-agnostic framework for uncertainty\nquantification with finite-sample validity guarantees, making it an attractive\ntool for constructing reliable prediction sets. However, existing approaches\ncommonly rely on residual-based conformity scores, which impose geometric\nconstraints and struggle when the underlying distribution is multimodal. In\nparticular, they tend to produce overly conservative prediction areas centred\naround the mean, often failing to capture the true shape of complex predictive\ndistributions. In this work, we introduce JAPAN (Joint Adaptive Prediction\nAreas with Normalising-Flows), a conformal prediction framework that uses\ndensity-based conformity scores. By leveraging flow-based models, JAPAN\nestimates the (predictive) density and constructs prediction areas by\nthresholding on the estimated density scores, enabling compact, potentially\ndisjoint, and context-adaptive regions that retain finite-sample coverage\nguarantees. We theoretically motivate the efficiency of JAPAN and empirically\nvalidate it across multivariate regression and forecasting tasks, demonstrating\ngood calibration and tighter prediction areas compared to existing baselines.\nWe also provide several \\emph{extensions} adding flexibility to our proposed\nframework.", "AI": {"tldr": "JAPAN introduces density-based conformity scores in conformal prediction, improving prediction areas for complex distributions compared to residual-based methods.", "motivation": "Existing residual-based conformity scores struggle with multimodal distributions, leading to overly conservative prediction areas.", "method": "JAPAN uses flow-based models to estimate predictive density and constructs prediction areas by thresholding density scores.", "result": "Empirical validation shows JAPAN achieves good calibration and tighter prediction areas than baselines.", "conclusion": "JAPAN offers a flexible, efficient framework for conformal prediction with improved handling of complex distributions."}}
{"id": "2502.12583", "pdf": "https://arxiv.org/pdf/2502.12583", "abs": "https://arxiv.org/abs/2502.12583", "authors": ["Cehao Yang", "Xueyuan Lin", "Chengjin Xu", "Xuhui Jiang", "Shengjie Ma", "Aofan Liu", "Hui Xiong", "Jian Guo"], "title": "LongFaith: Enhancing Long-Context Reasoning in LLMs with Faithful Synthetic Data", "categories": ["cs.CL"], "comment": null, "summary": "Despite the growing development of long-context large language models (LLMs),\ndata-centric approaches relying on synthetic data have been hindered by issues\nrelated to faithfulness, which limit their effectiveness in enhancing model\nperformance on tasks such as long-context reasoning and question answering\n(QA). These challenges are often exacerbated by misinformation caused by lack\nof verification, reasoning without attribution, and potential knowledge\nconflicts. We propose LongFaith, a novel pipeline for synthesizing faithful\nlong-context reasoning instruction datasets. By integrating ground truth and\ncitation-based reasoning prompts, we eliminate distractions and improve the\naccuracy of reasoning chains, thus mitigating the need for costly verification\nprocesses. We open-source two synthesized datasets, LongFaith-SFT and\nLongFaith-PO, which systematically address multiple dimensions of faithfulness,\nincluding verified reasoning, attribution, and contextual grounding. Extensive\nexperiments on multi-hop reasoning datasets and LongBench demonstrate that\nmodels fine-tuned on these datasets significantly improve performance. Our\nablation studies highlight the scalability and adaptability of the LongFaith\npipeline, showcasing its broad applicability in developing long-context LLMs.", "AI": {"tldr": "LongFaith is a pipeline for creating faithful long-context reasoning datasets, improving model performance by addressing misinformation and lack of attribution.", "motivation": "Current synthetic data approaches for long-context LLMs suffer from faithfulness issues, limiting their effectiveness in tasks like reasoning and QA.", "method": "LongFaith integrates ground truth and citation-based reasoning prompts to enhance accuracy and reduce verification needs.", "result": "Models fine-tuned on LongFaith datasets (LongFaith-SFT and LongFaith-PO) show significant performance improvements.", "conclusion": "LongFaith is scalable and adaptable, offering broad applicability for developing long-context LLMs."}}
{"id": "2501.14401", "pdf": "https://arxiv.org/pdf/2501.14401", "abs": "https://arxiv.org/abs/2501.14401", "authors": ["Souvik Maji", "Rhythm Baghel", "Pratik Mazumder"], "title": "CVOCSemRPL: Class-Variance Optimized Clustering, Semantic Information Injection and Restricted Pseudo Labeling based Improved Semi-Supervised Few-Shot Learning", "categories": ["cs.CV"], "comment": null, "summary": "Few-shot learning has been extensively explored to address problems where the\namount of labeled samples is very limited for some classes. In the\nsemi-supervised few-shot learning setting, substantial quantities of unlabeled\nsamples are available. Such unlabeled samples are generally cheaper to obtain\nand can be used to improve the few-shot learning performance of the model. Some\nof the recent methods for this setting rely on clustering to generate\npseudo-labels for the unlabeled samples. Since the effectiveness of clustering\nheavily influences the labeling of the unlabeled samples, it can significantly\naffect the few-shot learning performance. In this paper, we focus on improving\nthe representation learned by the model in order to improve the clustering and,\nconsequently, the model performance. We propose an approach for semi-supervised\nfew-shot learning that performs a class-variance optimized clustering coupled\nwith a cluster separation tuner in order to improve the effectiveness of\nclustering the labeled and unlabeled samples in this setting. It also optimizes\nthe clustering-based pseudo-labeling process using a restricted pseudo-labeling\napproach and performs semantic information injection in order to improve the\nsemi-supervised few-shot learning performance of the model. We experimentally\ndemonstrate that our proposed approach significantly outperforms recent\nstate-of-the-art methods on the benchmark datasets.", "AI": {"tldr": "The paper proposes a method to improve semi-supervised few-shot learning by enhancing clustering and pseudo-labeling processes, outperforming state-of-the-art methods.", "motivation": "Addressing the challenge of limited labeled samples in few-shot learning by leveraging unlabeled data to improve model performance.", "method": "Uses class-variance optimized clustering, a cluster separation tuner, restricted pseudo-labeling, and semantic information injection.", "result": "Significantly outperforms recent state-of-the-art methods on benchmark datasets.", "conclusion": "Improved clustering and pseudo-labeling enhance semi-supervised few-shot learning performance."}}
{"id": "2410.09615", "pdf": "https://arxiv.org/pdf/2410.09615", "abs": "https://arxiv.org/abs/2410.09615", "authors": ["Mohammad Mozaffari", "Amir Yazdanbakhsh", "Maryam Mehri Dehnavi"], "title": "SLiM: One-shot Quantization and Sparsity with Low-rank Approximation for LLM Weight Compression", "categories": ["cs.LG", "cs.AI", "cs.PF"], "comment": "Published at Proceedings of the 42 nd International Conference on\n  Machine Learning (ICML 2025)", "summary": "Conventional model compression techniques for LLMs address high memory\nconsumption and slow inference challenges but typically require computationally\nexpensive retraining to preserve accuracy. In contrast, one-shot compression\nmethods eliminate retraining cost, but struggle to achieve accuracy comparable\nto dense models. This paper presents SLIM, a new one-shot compression framework\nthat holistically integrates hardware-friendly quantization, sparsity, and\nlow-rank approximation into a unified process. First, we formulate the\nquantization process using a probabilistic approach (SLIM-Quant) that enables\nus to apply uniform quantization. Then, we use an existing one-shot pruning\nmethod to apply semi-structured sparsity on top of the quantized weights.\nFinally, to compensate for the introduced aggregated quantization and sparsity\nerror, we use a novel saliency function with unique invertible and additive\nfeatures that enables us to mathematically compute the value of low-rank\nadapters. SLIM improves model accuracy by up to 5.66% (LLaMA-2-7B) for 2:4\nsparsity with 4-bit weight quantization, outperforming prior methods. Models\ncompressed with SLIM achieve up to 4.3x and 3.8x on Nvidia RTX3060 and A100\nGPUs, respectively. Additionally, they achieve up to 0.23x end-to-end memory\nreduction in comparison to their dense counterparts. We also propose an\noptional PEFT recipe that further improves accuracy by up to 1.66%\n(LLaMA-2-13B) compared to SLIM without fine-tuning.", "AI": {"tldr": "SLIM is a one-shot compression framework combining quantization, sparsity, and low-rank approximation, improving accuracy and efficiency for LLMs without retraining.", "motivation": "Addressing the trade-off between computational cost and accuracy in model compression for LLMs, SLIM aims to eliminate retraining while maintaining high accuracy.", "method": "SLIM integrates uniform quantization (SLIM-Quant), semi-structured sparsity, and low-rank adapters with a novel saliency function to compensate for errors.", "result": "SLIM improves accuracy by up to 5.66% for 4-bit quantization with 2:4 sparsity, achieves up to 4.3x speedup on GPUs, and reduces memory by 0.23x. Optional PEFT further boosts accuracy by 1.66%.", "conclusion": "SLIM offers a unified, efficient one-shot compression solution for LLMs, outperforming prior methods in accuracy and performance."}}
{"id": "2505.23215", "pdf": "https://arxiv.org/pdf/2505.23215", "abs": "https://arxiv.org/abs/2505.23215", "authors": ["T. Jahn", "J. Chemseddine", "P. Hagemann", "C. Wald", "G. Steidl"], "title": "Trajectory Generator Matching for Time Series", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "Accurately modeling time-continuous stochastic processes from irregular\nobservations remains a significant challenge. In this paper, we leverage ideas\nfrom generative modeling of image data to push the boundary of time series\ngeneration. For this, we find new generators of SDEs and jump processes,\ninspired by trajectory flow matching, that have the marginal distributions of\nthe time series of interest. Specifically, we can handle discontinuities of the\nunderlying processes by parameterizing the jump kernel densities by scaled\nGaussians that allow for closed form formulas of the corresponding\nKullback-Leibler divergence in the loss. Unlike most other approaches, we are\nable to handle irregularly sampled time series.", "AI": {"tldr": "The paper introduces a generative modeling approach for time-continuous stochastic processes, handling irregular observations and discontinuities using SDEs and jump processes with scaled Gaussian kernels.", "motivation": "Accurately modeling time-continuous stochastic processes from irregular observations is challenging, and existing methods often fail to handle discontinuities or irregular sampling.", "method": "The authors propose new generators for SDEs and jump processes, inspired by trajectory flow matching, using scaled Gaussian kernels to parameterize jump densities and enable closed-form KL divergence calculations.", "result": "The method effectively models irregularly sampled time series and handles discontinuities, outperforming other approaches.", "conclusion": "The proposed approach advances time series generation by addressing irregular sampling and discontinuities, leveraging generative modeling techniques."}}
{"id": "2502.12970", "pdf": "https://arxiv.org/pdf/2502.12970", "abs": "https://arxiv.org/abs/2502.12970", "authors": ["Junda Zhu", "Lingyong Yan", "Shuaiqiang Wang", "Dawei Yin", "Lei Sha"], "title": "Reasoning-to-Defend: Safety-Aware Reasoning Can Defend Large Language Models from Jailbreaking", "categories": ["cs.CL"], "comment": "18 pages", "summary": "Large Reasoning Models (LRMs) have demonstrated impressive performances\nacross diverse domains. However, how safety of Large Language Models (LLMs)\nbenefits from enhanced reasoning capabilities against jailbreak queries remains\nunexplored. To bridge this gap, in this paper, we propose Reasoning-to-Defend\n(R2D), a novel training paradigm that integrates a safety-aware reasoning\nmechanism into LLMs' generation. This enables self-evaluation at each step of\nthe reasoning process, forming safety pivot tokens as indicators of the safety\nstatus of responses. Furthermore, in order to improve the accuracy of\npredicting pivot tokens, we propose Contrastive Pivot Optimization (CPO), which\nenhances the model's perception of the safety status of given dialogues. LLMs\ndynamically adjust their response strategies during reasoning, significantly\nenhancing their safety capabilities defending jailbreak attacks. Extensive\nexperiments demonstrate that R2D effectively mitigates various attacks and\nimproves overall safety, while maintaining the original performances. This\nhighlights the substantial potential of safety-aware reasoning in improving\nrobustness of LRMs and LLMs against various jailbreaks.", "AI": {"tldr": "R2D enhances LLM safety by integrating safety-aware reasoning and self-evaluation, using pivot tokens and CPO to defend against jailbreak attacks.", "motivation": "Explore how enhanced reasoning in LLMs can improve safety against jailbreak queries, a gap in current research.", "method": "Proposes R2D, a training paradigm with safety-aware reasoning and self-evaluation, and CPO for better pivot token prediction.", "result": "R2D effectively mitigates jailbreak attacks, improving safety without compromising performance.", "conclusion": "Safety-aware reasoning significantly boosts LLM robustness against jailbreaks, demonstrating R2D's potential."}}
{"id": "2501.18463", "pdf": "https://arxiv.org/pdf/2501.18463", "abs": "https://arxiv.org/abs/2501.18463", "authors": ["Shiho Noda", "Atsuyuki Miyai", "Qing Yu", "Go Irie", "Kiyoharu Aizawa"], "title": "A Benchmark and Evaluation for Real-World Out-of-Distribution Detection Using Vision-Language Models", "categories": ["cs.CV"], "comment": "Accepted at ICIP2025 Dataset and Benchmark Track", "summary": "Out-of-distribution (OOD) detection is a task that detects OOD samples during\ninference to ensure the safety of deployed models. However, conventional\nbenchmarks have reached performance saturation, making it difficult to compare\nrecent OOD detection methods. To address this challenge, we introduce three\nnovel OOD detection benchmarks that enable a deeper understanding of method\ncharacteristics and reflect real-world conditions. First, we present\nImageNet-X, designed to evaluate performance under challenging semantic shifts.\nSecond, we propose ImageNet-FS-X for full-spectrum OOD detection, assessing\nrobustness to covariate shifts (feature distribution shifts). Finally, we\npropose Wilds-FS-X, which extends these evaluations to real-world datasets,\noffering a more comprehensive testbed. Our experiments reveal that recent\nCLIP-based OOD detection methods struggle to varying degrees across the three\nproposed benchmarks, and none of them consistently outperforms the others. We\nhope the community goes beyond specific benchmarks and includes more\nchallenging conditions reflecting real-world scenarios. The code is\nhttps://github.com/hoshi23/OOD-X-Benchmarks.", "AI": {"tldr": "The paper introduces three new OOD detection benchmarks (ImageNet-X, ImageNet-FS-X, Wilds-FS-X) to address performance saturation in conventional benchmarks, revealing limitations of CLIP-based methods and advocating for more realistic testing conditions.", "motivation": "Conventional OOD detection benchmarks have reached performance saturation, making it hard to compare recent methods. The authors aim to provide more challenging and realistic benchmarks.", "method": "Three new benchmarks are proposed: ImageNet-X (semantic shifts), ImageNet-FS-X (covariate shifts), and Wilds-FS-X (real-world datasets). Experiments evaluate CLIP-based methods on these benchmarks.", "result": "CLIP-based OOD detection methods struggle across the new benchmarks, with no method consistently outperforming others.", "conclusion": "The paper calls for the community to adopt more challenging benchmarks reflecting real-world conditions, beyond conventional testing."}}
{"id": "2410.09754", "pdf": "https://arxiv.org/pdf/2410.09754", "abs": "https://arxiv.org/abs/2410.09754", "authors": ["Hojoon Lee", "Dongyoon Hwang", "Donghu Kim", "Hyunseung Kim", "Jun Jet Tai", "Kaushik Subramanian", "Peter R. Wurman", "Jaegul Choo", "Peter Stone", "Takuma Seno"], "title": "SimBa: Simplicity Bias for Scaling Up Parameters in Deep Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "ICLR'25 (spotlight)", "summary": "Recent advances in CV and NLP have been largely driven by scaling up the\nnumber of network parameters, despite traditional theories suggesting that\nlarger networks are prone to overfitting. These large networks avoid\noverfitting by integrating components that induce a simplicity bias, guiding\nmodels toward simple and generalizable solutions. However, in deep RL,\ndesigning and scaling up networks have been less explored. Motivated by this\nopportunity, we present SimBa, an architecture designed to scale up parameters\nin deep RL by injecting a simplicity bias. SimBa consists of three components:\n(i) an observation normalization layer that standardizes inputs with running\nstatistics, (ii) a residual feedforward block to provide a linear pathway from\nthe input to output, and (iii) a layer normalization to control feature\nmagnitudes. By scaling up parameters with SimBa, the sample efficiency of\nvarious deep RL algorithms-including off-policy, on-policy, and unsupervised\nmethods-is consistently improved. Moreover, solely by integrating SimBa\narchitecture into SAC, it matches or surpasses state-of-the-art deep RL methods\nwith high computational efficiency across DMC, MyoSuite, and HumanoidBench.\nThese results demonstrate SimBa's broad applicability and effectiveness across\ndiverse RL algorithms and environments.", "AI": {"tldr": "SimBa is a scalable architecture for deep RL that introduces simplicity bias to improve sample efficiency and performance across diverse algorithms and environments.", "motivation": "Despite scaling success in CV and NLP, deep RL lacks exploration in network scaling. SimBa addresses this by integrating simplicity bias to avoid overfitting.", "method": "SimBa includes observation normalization, a residual feedforward block, and layer normalization to scale parameters effectively.", "result": "SimBa improves sample efficiency in various RL algorithms and matches or outperforms state-of-the-art methods with high computational efficiency.", "conclusion": "SimBa demonstrates broad applicability and effectiveness in diverse RL settings, highlighting its potential for advancing deep RL."}}
{"id": "2505.23240", "pdf": "https://arxiv.org/pdf/2505.23240", "abs": "https://arxiv.org/abs/2505.23240", "authors": ["Hemant Tyagi"], "title": "Joint estimation of smooth graph signals from partial linear measurements", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "comment": "29 pages, 2 figures", "summary": "Given an undirected and connected graph $G$ on $T$ vertices, suppose each\nvertex $t$ has a latent signal $x_t \\in \\mathbb{R}^n$ associated to it. Given\npartial linear measurements of the signals, for a potentially small subset of\nthe vertices, our goal is to estimate $x_t$'s. Assuming that the signals are\nsmooth w.r.t $G$, in the sense that the quadratic variation of the signals over\nthe graph is small, we obtain non-asymptotic bounds on the mean squared error\nfor jointly recovering $x_t$'s, for the smoothness penalized least squares\nestimator. In particular, this implies for certain choices of $G$ that this\nestimator is weakly consistent (as $T \\rightarrow \\infty$) under potentially\nvery stringent sampling, where only one coordinate is measured per vertex for a\nvanishingly small fraction of the vertices. The results are extended to a\n``multi-layer'' ranking problem where $x_t$ corresponds to the latent strengths\nof a collection of $n$ items, and noisy pairwise difference measurements are\nobtained at each ``layer'' $t$ via a measurement graph $G_t$. Weak consistency\nis established for certain choices of $G$ even when the individual $G_t$'s are\nvery sparse and disconnected.", "AI": {"tldr": "The paper analyzes the recovery of latent signals on a graph from partial linear measurements, assuming smoothness over the graph. It provides non-asymptotic error bounds and shows weak consistency under sparse sampling.", "motivation": "The goal is to estimate latent signals on a graph from limited measurements, leveraging smoothness assumptions for accurate recovery even with stringent sampling.", "method": "The smoothness-penalized least squares estimator is used, with analysis extended to a multi-layer ranking problem involving noisy pairwise differences.", "result": "Non-asymptotic bounds on mean squared error are derived, showing weak consistency for certain graphs under very sparse sampling.", "conclusion": "The estimator performs well under sparse measurements, with potential applications in ranking problems with limited data."}}
{"id": "2502.13044", "pdf": "https://arxiv.org/pdf/2502.13044", "abs": "https://arxiv.org/abs/2502.13044", "authors": ["Nils Constantin Hellwig", "Jakob Fehle", "Udo Kruschwitz", "Christian Wolff"], "title": "Do we still need Human Annotators? Prompting Large Language Models for Aspect Sentiment Quad Prediction", "categories": ["cs.CL"], "comment": null, "summary": "Aspect sentiment quad prediction (ASQP) facilitates a detailed understanding\nof opinions expressed in a text by identifying the opinion term, aspect term,\naspect category and sentiment polarity for each opinion. However, annotating a\nfull set of training examples to fine-tune models for ASQP is a\nresource-intensive process. In this study, we explore the capabilities of large\nlanguage models (LLMs) for zero- and few-shot learning on the ASQP task across\nfive diverse datasets. We report F1 scores almost up to par with those obtained\nwith state-of-the-art fine-tuned models and exceeding previously reported zero-\nand few-shot performance. In the 20-shot setting on the Rest16 restaurant\ndomain dataset, LLMs achieved an F1 score of 51.54, compared to 60.39 by the\nbest-performing fine-tuned method MVP. Additionally, we report the performance\nof LLMs in target aspect sentiment detection (TASD), where the F1 scores were\nclose to fine-tuned models, achieving 68.93 on Rest16 in the 30-shot setting,\ncompared to 72.76 with MVP. While human annotators remain essential for\nachieving optimal performance, LLMs can reduce the need for extensive manual\nannotation in ASQP tasks.", "AI": {"tldr": "LLMs show strong zero- and few-shot performance in ASQP and TASD tasks, nearly matching fine-tuned models, reducing the need for extensive manual annotation.", "motivation": "Annotating training data for ASQP is resource-intensive; exploring LLMs' capabilities can reduce this burden.", "method": "Evaluated LLMs on zero- and few-shot learning for ASQP and TASD across five datasets, comparing performance with fine-tuned models.", "result": "LLMs achieved F1 scores close to fine-tuned models (e.g., 51.54 vs. 60.39 on Rest16 for ASQP, 68.93 vs. 72.76 for TASD).", "conclusion": "LLMs can significantly reduce manual annotation needs while maintaining competitive performance in ASQP and TASD tasks."}}
{"id": "2502.05540", "pdf": "https://arxiv.org/pdf/2502.05540", "abs": "https://arxiv.org/abs/2502.05540", "authors": ["Qirui Wu", "Shizhou Zhang", "De Cheng", "Yinghui Xing", "Di Xu", "Peng Wang", "Yanning Zhang"], "title": "Demystifying Catastrophic Forgetting in Two-Stage Incremental Object Detector", "categories": ["cs.CV"], "comment": "Accepted in ICML2025", "summary": "Catastrophic forgetting is a critical chanllenge for incremental object\ndetection (IOD). Most existing methods treat the detector monolithically,\nrelying on instance replay or knowledge distillation without analyzing\ncomponent-specific forgetting. Through dissection of Faster R-CNN, we reveal a\nkey insight: Catastrophic forgetting is predominantly localized to the RoI Head\nclassifier, while regressors retain robustness across incremental stages. This\nfinding challenges conventional assumptions, motivating us to develop a\nframework termed NSGP-RePRE. Regional Prototype Replay (RePRE) mitigates\nclassifier forgetting via replay of two types of prototypes: coarse prototypes\nrepresent class-wise semantic centers of RoI features, while fine-grained\nprototypes model intra-class variations. Null Space Gradient Projection (NSGP)\nis further introduced to eliminate prototype-feature misalignment by updating\nthe feature extractor in directions orthogonal to subspace of old inputs via\ngradient projection, aligning RePRE with incremental learning dynamics. Our\nsimple yet effective design allows NSGP-RePRE to achieve state-of-the-art\nperformance on the Pascal VOC and MS COCO datasets under various settings. Our\nwork not only advances IOD methodology but also provide pivotal insights for\ncatastrophic forgetting mitigation in IOD. Code is available at\n\\href{https://github.com/fanrena/NSGP-RePRE}{https://github.com/fanrena/NSGP-RePRE} .", "AI": {"tldr": "The paper addresses catastrophic forgetting in incremental object detection (IOD) by focusing on the RoI Head classifier, proposing NSGP-RePRE, which uses prototype replay and gradient projection to achieve state-of-the-art results.", "motivation": "Catastrophic forgetting in IOD is primarily localized to the RoI Head classifier, challenging traditional monolithic approaches.", "method": "NSGP-RePRE combines Regional Prototype Replay (RePRE) for classifier forgetting and Null Space Gradient Projection (NSGP) to align feature updates with incremental learning.", "result": "Achieves state-of-the-art performance on Pascal VOC and MS COCO datasets.", "conclusion": "The framework advances IOD methodology and provides insights for mitigating catastrophic forgetting."}}
{"id": "2410.15625", "pdf": "https://arxiv.org/pdf/2410.15625", "abs": "https://arxiv.org/abs/2410.15625", "authors": ["Anjiang Wei", "Allen Nie", "Thiago S. F. X. Teixeira", "Rohan Yadav", "Wonchan Lee", "Ke Wang", "Alex Aiken"], "title": "Improving Parallel Program Performance with LLM Optimizers via Agent-System Interfaces", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "comment": null, "summary": "Modern scientific discovery increasingly relies on high-performance computing\nfor complex modeling and simulation. A key challenge in improving parallel\nprogram performance is efficiently mapping tasks to processors and data to\nmemory, a process dictated by intricate, low-level system code known as\nmappers. Developing high-performance mappers demands days of manual tuning,\nposing a significant barrier for domain scientists without systems expertise.\nWe introduce a framework that automates mapper development with generative\noptimization, leveraging richer feedback beyond scalar performance metrics. Our\napproach features the Agent-System Interface, which includes a Domain-Specific\nLanguage (DSL) to abstract away the low-level complexity of system code and\ndefine a structured search space, as well as AutoGuide, a mechanism that\ninterprets raw execution output into actionable feedback. Unlike traditional\nreinforcement learning methods such as OpenTuner, which rely solely on scalar\nfeedback, our method finds superior mappers in far fewer iterations. With just\n10 iterations, it outperforms OpenTuner even after 1000 iterations, achieving\n3.8X faster performance. Our approach finds mappers that surpass expert-written\nmappers by up to 1.34X speedup across nine benchmarks while reducing tuning\ntime from days to minutes.", "AI": {"tldr": "A framework automates mapper development for parallel programs, outperforming manual tuning and traditional methods like OpenTuner with faster performance and reduced tuning time.", "motivation": "High-performance computing relies on efficient task and data mapping, but manual tuning is time-consuming and requires expertise, hindering domain scientists.", "method": "Introduces a framework with a Domain-Specific Language (DSL) and AutoGuide for generative optimization, providing richer feedback than scalar metrics.", "result": "Achieves 3.8X faster performance than OpenTuner in 10 iterations and surpasses expert-written mappers by up to 1.34X speedup.", "conclusion": "The framework significantly improves mapper performance and reduces tuning time, making high-performance computing more accessible."}}
{"id": "2505.23260", "pdf": "https://arxiv.org/pdf/2505.23260", "abs": "https://arxiv.org/abs/2505.23260", "authors": ["Budhaditya Halder", "Shubhayan Pan", "Koulik Khamaru"], "title": "Stable Thompson Sampling: Valid Inference via Variance Inflation", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We consider the problem of statistical inference when the data is collected\nvia a Thompson Sampling-type algorithm. While Thompson Sampling (TS) is known\nto be both asymptotically optimal and empirically effective, its adaptive\nsampling scheme poses challenges for constructing confidence intervals for\nmodel parameters. We propose and analyze a variant of TS, called Stable\nThompson Sampling, in which the posterior variance is inflated by a logarithmic\nfactor. We show that this modification leads to asymptotically normal estimates\nof the arm means, despite the non-i.i.d. nature of the data. Importantly, this\nstatistical benefit comes at a modest cost: the variance inflation increases\nregret by only a logarithmic factor compared to standard TS. Our results reveal\na principled trade-off: by paying a small price in regret, one can enable valid\nstatistical inference for adaptive decision-making algorithms.", "AI": {"tldr": "Proposes Stable Thompson Sampling, a variant of TS with inflated posterior variance, enabling asymptotically normal estimates and valid inference at a small regret cost.", "motivation": "Addresses the challenge of constructing confidence intervals for model parameters in adaptive sampling schemes like Thompson Sampling.", "method": "Introduces Stable Thompson Sampling, inflating posterior variance by a logarithmic factor to ensure asymptotically normal estimates.", "result": "Achieves asymptotically normal estimates of arm means with only a logarithmic increase in regret compared to standard TS.", "conclusion": "Demonstrates a trade-off: small regret cost enables valid statistical inference in adaptive decision-making."}}
{"id": "2502.13472", "pdf": "https://arxiv.org/pdf/2502.13472", "abs": "https://arxiv.org/abs/2502.13472", "authors": ["Borui Liao", "Yulong Xu", "Jiao Ou", "Kaiyuan Yang", "Weihua Jian", "Pengfei Wan", "Di Zhang"], "title": "FlexDuo: A Pluggable System for Enabling Full-Duplex Capabilities in Speech Dialogue Systems", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "Full-Duplex Speech Dialogue Systems (Full-Duplex SDS) have significantly\nenhanced the naturalness of human-machine interaction by enabling real-time\nbidirectional communication. However, existing approaches face challenges such\nas difficulties in independent module optimization and contextual noise\ninterference due to highly coupled architectural designs and oversimplified\nbinary state modeling. This paper proposes FlexDuo, a flexible full-duplex\ncontrol module that decouples duplex control from spoken dialogue systems\nthrough a plug-and-play architectural design. Furthermore, inspired by human\ninformation-filtering mechanisms in conversations, we introduce an explicit\nIdle state. On one hand, the Idle state filters redundant noise and irrelevant\naudio to enhance dialogue quality. On the other hand, it establishes a semantic\nintegrity-based buffering mechanism, reducing the risk of mutual interruptions\nwhile ensuring accurate response transitions. Experimental results on the\nFisher corpus demonstrate that FlexDuo reduces the false interruption rate by\n24.9% and improves response accuracy by 7.6% compared to integrated full-duplex\ndialogue system baselines. It also outperforms voice activity detection (VAD)\ncontrolled baseline systems in both Chinese and English dialogue quality. The\nproposed modular architecture and state-based dialogue model provide a novel\ntechnical pathway for building flexible and efficient duplex dialogue systems.", "AI": {"tldr": "FlexDuo, a flexible full-duplex control module, decouples duplex control from dialogue systems, introduces an Idle state for noise filtering, and improves response accuracy and interruption rates.", "motivation": "Existing full-duplex speech dialogue systems face challenges like module coupling and noise interference, limiting naturalness and efficiency.", "method": "Proposes FlexDuo with a plug-and-play design and an explicit Idle state for noise filtering and semantic buffering.", "result": "FlexDuo reduces false interruptions by 24.9% and improves response accuracy by 7.6%, outperforming baselines.", "conclusion": "FlexDuo's modular architecture and state-based model offer a novel approach for efficient duplex dialogue systems."}}
{"id": "2502.09623", "pdf": "https://arxiv.org/pdf/2502.09623", "abs": "https://arxiv.org/abs/2502.09623", "authors": ["Francesco Ballerini", "Pierluigi Zama Ramirez", "Samuele Salti", "Luigi Di Stefano"], "title": "Weight Space Representation Learning on Diverse NeRF Architectures", "categories": ["cs.CV"], "comment": "v2: added third NeRF architecture. Under review", "summary": "Neural Radiance Fields (NeRFs) have emerged as a groundbreaking paradigm for\nrepresenting 3D objects and scenes by encoding shape and appearance information\ninto the weights of a neural network. Recent studies have demonstrated that\nthese weights can be used as input for frameworks designed to address deep\nlearning tasks; however, such frameworks require NeRFs to adhere to a specific,\npredefined architecture. In this paper, we introduce the first framework\ncapable of processing NeRFs with diverse architectures and performing inference\non architectures unseen at training time. We achieve this by training a Graph\nMeta-Network within an unsupervised representation learning framework, and show\nthat a contrastive objective is conducive to obtaining an architecture-agnostic\nlatent space. In experiments conducted across 13 NeRF architectures belonging\nto three families (MLPs, tri-planes, and, for the first time, hash tables), our\napproach demonstrates robust performance in classification and retrieval tasks\ninvolving multiple architectures, even unseen at training time, while also\nexceeding the results of existing frameworks limited to single architectures.", "AI": {"tldr": "A framework for processing diverse Neural Radiance Fields (NeRFs) architectures, including unseen ones, using a Graph Meta-Network and contrastive learning, outperforming single-architecture methods.", "motivation": "Existing frameworks for NeRFs require predefined architectures, limiting flexibility. This work aims to enable inference on diverse and unseen NeRF architectures.", "method": "Train a Graph Meta-Network with unsupervised representation learning and a contrastive objective to create an architecture-agnostic latent space.", "result": "Robust performance in classification and retrieval across 13 NeRF architectures, including unseen ones, surpassing single-architecture frameworks.", "conclusion": "The framework successfully generalizes to diverse NeRF architectures, demonstrating the effectiveness of the proposed approach."}}
{"id": "2411.00006", "pdf": "https://arxiv.org/pdf/2411.00006", "abs": "https://arxiv.org/abs/2411.00006", "authors": ["Yaoqi Guo", "Zhenpeng Chen", "Jie M. Zhang", "Yang Liu", "Yun Ma"], "title": "Personality-Guided Code Generation Using Large Language Models", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted by the 63rd Annual Meeting of the Association for\n  Computational Linguistics (ACL 2025) Main Track", "summary": "Code generation, the automatic creation of source code from natural language\ndescriptions, has garnered significant attention due to its potential to\nstreamline software development. Inspired by research that links\ntask-personality alignment with improved development outcomes, we conduct an\nempirical study on personality-guided code generation using large language\nmodels (LLMs). Specifically, we investigate how emulating personality traits\nappropriate to the coding tasks affects LLM performance. We extensively\nevaluate this approach using seven widely adopted LLMs across four\nrepresentative datasets. Our results show that personality guidance\nsignificantly enhances code generation accuracy, with improved pass rates in 23\nout of 28 LLM-dataset combinations. Notably, in 11 cases, the improvement\nexceeds 5%, and in 5 instances, it surpasses 10%, with the highest gain\nreaching 12.9%. Additionally, personality guidance can be easily integrated\nwith other prompting strategies to further boost performance. We open-source\nour code and data at https://github.com/IanWalls/Persona-Code.", "AI": {"tldr": "Personality-guided code generation with LLMs improves accuracy, showing significant gains in pass rates across multiple datasets.", "motivation": "To explore how aligning personality traits with coding tasks enhances LLM performance in code generation.", "method": "Empirical study using seven LLMs across four datasets, evaluating personality-guided code generation.", "result": "Personality guidance boosts accuracy, with pass rate improvements in 23/28 cases, some exceeding 10%.", "conclusion": "Personality guidance effectively enhances LLM code generation and can be combined with other strategies for further gains."}}
{"id": "2505.23344", "pdf": "https://arxiv.org/pdf/2505.23344", "abs": "https://arxiv.org/abs/2505.23344", "authors": ["Jakub Martinka", "Lina Zhang", "Yi-Fan Hou", "Miko\u0142aj Martyka", "Ji\u0159\u00ed Pittner", "Mario Barbatti", "Pavlo O. Dral"], "title": "A Descriptor Is All You Need: Accurate Machine Learning of Nonadiabatic Coupling Vectors", "categories": ["physics.comp-ph", "cs.LG", "physics.chem-ph"], "comment": null, "summary": "Nonadiabatic couplings (NACs) play a crucial role in modeling photochemical\nand photophysical processes with methods such as the widely used\nfewest-switches surface hopping (FSSH). There is therefore a strong incentive\nto machine learn NACs for accelerating simulations. However, this is\nchallenging due to NACs' vectorial, double-valued character and the singularity\nnear a conical intersection seam. For the first time, we design NAC-specific\ndescriptors based on our domain expertise and show that they allow learning\nNACs with never-before-reported accuracy of $R^2$ exceeding 0.99. The key to\nsuccess is also our new ML phase-correction procedure. We demonstrate the\nefficiency and robustness of our approach on a prototypical example of fully\nML-driven FSSH simulations of fulvene targeting the SA-2-CASSCF(6,6) electronic\nstructure level. This ML-FSSH dynamics leads to an accurate description of\n$S_1$ decay while reducing error bars by allowing the execution of a large\nensemble of trajectories. Our implementations are available in open-source\nMLatom.", "AI": {"tldr": "The paper introduces machine-learned nonadiabatic couplings (NACs) with high accuracy (R\u00b2 > 0.99) using NAC-specific descriptors and a phase-correction procedure, enabling efficient ML-driven FSSH simulations for photochemical processes.", "motivation": "NACs are critical for modeling photochemical processes but are challenging to learn due to their vectorial, double-valued nature and singularities near conical intersections.", "method": "The authors designed NAC-specific descriptors and a new ML phase-correction procedure to learn NACs accurately. They demonstrated this on ML-driven FSSH simulations of fulvene.", "result": "Achieved unprecedented accuracy (R\u00b2 > 0.99) in learning NACs, enabling efficient and robust ML-FSSH dynamics with reduced error bars.", "conclusion": "The approach successfully integrates ML with FSSH simulations, providing accurate descriptions of photochemical processes while improving computational efficiency."}}
{"id": "2502.14538", "pdf": "https://arxiv.org/pdf/2502.14538", "abs": "https://arxiv.org/abs/2502.14538", "authors": ["Yupeng Chang", "Chenlu Guo", "Yi Chang", "Yuan Wu"], "title": "LoRA-MGPO: Mitigating Double Descent in Low-Rank Adaptation via Momentum-Guided Perturbation Optimization", "categories": ["cs.CL"], "comment": null, "summary": "Parameter-efficient fine-tuning (PEFT) methods, such as Low-Rank Adaptation\n(LoRA), enable efficient adaptation of large language models (LLMs) via\nlow-rank matrix optimization with frozen weights. However, LoRA typically\nexhibits \"double descent\" in training loss as rank increases, characterized by\na three-phase dynamics: initial convergence, transient divergence, and eventual\nstabilization. This non-monotonic behavior delays convergence and impairs\ngeneralization through unstable gradients and attraction to sharp minima. To\naddress these challenges, we propose LoRA-MGPO, a novel LoRA-based framework\nincorporating Momentum-Guided Perturbation Optimization (MGPO). First, MGPO\neliminates Sharpness-Aware Minimization (SAM)'s dual gradient computations by\nreusing momentum vectors from optimizer states to guide perturbation\ndirections. This retains SAM's training stability and flat minima preference\nwith maintained efficiency. Second, MGPO incorporates adaptive perturbation\nnormalization, scaling perturbation intensity via exponential moving average\n(EMA)-smoothed gradient magnitudes. Experiments on natural language\nunderstanding and generation benchmarks demonstrate that LoRA-MGPO outperforms\nLoRA and state-of-the-art PEFT methods. Further analysis confirms its ability\nto stabilize training and reduce sharp minima attraction, with smoother loss\ncurves and improved convergence behavior. The code is available at\nhttps://github.com/llm172/LoRA-MGPO", "AI": {"tldr": "LoRA-MGPO improves LoRA by using momentum-guided perturbation optimization to stabilize training and avoid sharp minima, outperforming existing PEFT methods.", "motivation": "LoRA's non-monotonic training loss behavior (double descent) delays convergence and harms generalization due to unstable gradients and sharp minima attraction.", "method": "Proposes LoRA-MGPO, which reuses optimizer momentum vectors to guide perturbations (avoiding dual gradient computations like SAM) and uses adaptive perturbation normalization via EMA-smoothed gradients.", "result": "Outperforms LoRA and other PEFT methods in benchmarks, with smoother loss curves, better convergence, and reduced sharp minima attraction.", "conclusion": "LoRA-MGPO effectively addresses LoRA's instability issues, offering a more efficient and stable fine-tuning method for LLMs."}}
{"id": "2502.11638", "pdf": "https://arxiv.org/pdf/2502.11638", "abs": "https://arxiv.org/abs/2502.11638", "authors": ["Dariush Lotfi", "Mohammad-Ali Nikouei Mahani", "Mohamad Koohi-Moghadam", "Kyongtae Ty Bae"], "title": "Safeguarding AI in Medical Imaging: Post-Hoc Out-of-Distribution Detection with Normalizing Flows", "categories": ["cs.CV"], "comment": null, "summary": "In AI-driven medical imaging, the failure to detect out-of-distribution (OOD)\ndata poses a severe risk to clinical reliability, potentially leading to\ncritical diagnostic errors. Current OOD detection methods often demand\nimpractical retraining or modifications to pre-trained models, hindering their\nadoption in regulated clinical environments. To address this challenge, we\npropose a post-hoc normalizing flow-based approach that seamlessly integrates\nwith existing pre-trained models without altering their weights. Our evaluation\nused a novel in-house built dataset, MedOOD, meticulously curated to simulate\nclinically relevant distributional shifts, alongside the MedMNIST benchmark\ndataset. On our in-house MedOOD dataset, our method achieved an AUROC of\n84.61%, outperforming state-of-the-art methods like ViM (80.65%) and MDS\n(80.87%). Similarly, on MedMNIST, it reached an exceptional AUROC of 93.8%,\nsurpassing leading approaches such as ViM (88.08%) and ReAct (87.05%). This\nsuperior performance, coupled with its post-hoc integration capability,\npositions our method as a vital safeguard for enhancing safety in medical\nimaging workflows. The model and code to build OOD datasets are publicly\naccessible at https://github.com/dlotfi/MedOODFlow.", "AI": {"tldr": "A post-hoc normalizing flow-based method for OOD detection in medical imaging, outperforming state-of-the-art methods without altering pre-trained models.", "motivation": "Addressing the risk of undetected OOD data in medical imaging, which can lead to critical diagnostic errors, without requiring impractical retraining or model modifications.", "method": "Proposes a post-hoc normalizing flow-based approach that integrates with pre-trained models without changing their weights, evaluated on MedOOD and MedMNIST datasets.", "result": "Achieved AUROC of 84.61% on MedOOD and 93.8% on MedMNIST, surpassing ViM, MDS, and ReAct.", "conclusion": "The method enhances safety in medical imaging workflows with superior performance and seamless integration, making it a practical solution for clinical environments."}}
{"id": "2411.00850", "pdf": "https://arxiv.org/pdf/2411.00850", "abs": "https://arxiv.org/abs/2411.00850", "authors": ["Yihua Shao", "Yan Gu", "Siyu Chen", "Haiyang Liu", "Zixian Zhu", "Zijian Ling", "Minxi Yan", "Ziyang Yan", "Chenyu Zhang", "Michele Magno", "Haotong Qin", "Yan Wang", "Jingcai Guo", "Ling Shao", "Hao Tang"], "title": "GWQ: Gradient-Aware Weight Quantization for Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) show impressive performance in solving complex\nlanguage tasks. However, its large number of parameters presents significant\nchallenges for the deployment. So, compressing LLMs to low bits can enable to\ndeploy on resource-constrained devices. To address this problem, we propose\ngradient-aware weight quantization (GWQ), the first quantization approach for\nlow-bit weight quantization that leverages gradients to localize outliers,\nrequiring only a minimal amount of calibration data for outlier detection. GWQ\nretains the top 1\\% outliers preferentially at FP16 precision, while the\nremaining non-outlier weights are stored in a low-bit. We widely evaluate GWQ\non different task include language modeling, grounding detection, massive\nmultitask language understanding and vision-language question and answering.\nResults show that models quantified by GWQ performs better than other\nquantization method. During quantization process, GWQ only need one calibration\nset to realize effective quant. Also, GWQ achieves 1.2x inference speedup in\ncomparison to the original model and effectively reduces the inference memory.", "AI": {"tldr": "GWQ is a gradient-aware weight quantization method for compressing LLMs to low bits, improving deployment on resource-constrained devices with minimal calibration data.", "motivation": "Large LLMs face deployment challenges due to their size; GWQ aims to compress them efficiently.", "method": "GWQ uses gradients to detect outliers, retaining top 1% in FP16 and quantizing the rest to low bits with minimal calibration.", "result": "GWQ outperforms other methods, achieves 1.2x speedup, and reduces memory usage.", "conclusion": "GWQ is an effective, efficient quantization method for LLMs."}}
{"id": "2505.23389", "pdf": "https://arxiv.org/pdf/2505.23389", "abs": "https://arxiv.org/abs/2505.23389", "authors": ["Ivana Nikoloska", "Hamdi Joudeh", "Ruud van Sloun", "Osvaldo Simeone"], "title": "Dynamic Estimation Loss Control in Variational Quantum Sensing via Online Conformal Inference", "categories": ["quant-ph", "cs.IT", "cs.LG", "eess.SP", "math.IT"], "comment": null, "summary": "Quantum sensing exploits non-classical effects to overcome limitations of\nclassical sensors, with applications ranging from gravitational-wave detection\nto nanoscale imaging. However, practical quantum sensors built on noisy\nintermediate-scale quantum (NISQ) devices face significant noise and sampling\nconstraints, and current variational quantum sensing (VQS) methods lack\nrigorous performance guarantees. This paper proposes an online control\nframework for VQS that dynamically updates the variational parameters while\nproviding deterministic error bars on the estimates. By leveraging online\nconformal inference techniques, the approach produces sequential estimation\nsets with a guaranteed long-term risk level. Experiments on a quantum\nmagnetometry task confirm that the proposed dynamic VQS approach maintains the\nrequired reliability over time, while still yielding precise estimates. The\nresults demonstrate the practical benefits of combining variational quantum\nalgorithms with online conformal inference to achieve reliable quantum sensing\non NISQ devices.", "AI": {"tldr": "The paper proposes an online control framework for variational quantum sensing (VQS) to address noise and sampling constraints in NISQ devices, ensuring reliable performance with deterministic error bars.", "motivation": "Practical quantum sensors on NISQ devices face noise and lack performance guarantees in current VQS methods.", "method": "The framework dynamically updates variational parameters using online conformal inference, providing deterministic error bars and sequential estimation sets with guaranteed risk levels.", "result": "Experiments on quantum magnetometry show the approach maintains reliability and precision over time.", "conclusion": "Combining VQS with online conformal inference enables reliable quantum sensing on NISQ devices."}}
{"id": "2502.14643", "pdf": "https://arxiv.org/pdf/2502.14643", "abs": "https://arxiv.org/abs/2502.14643", "authors": ["Gengxu Li", "Tingyu Xia", "Yi Chang", "Yuan Wu"], "title": "Length-Controlled Margin-Based Preference Optimization without Reference Model", "categories": ["cs.CL"], "comment": "18 pages, 3 figures, 6 tables", "summary": "Direct Preference Optimization (DPO) is a widely adopted offline algorithm\nfor preference-based reinforcement learning from human feedback (RLHF),\ndesigned to improve training simplicity and stability by redefining reward\nfunctions. However, DPO is hindered by several limitations, including length\nbias, memory inefficiency, and probability degradation. To address these\nchallenges, we propose Length-Controlled Margin-Based Preference Optimization\n(LMPO), a more efficient and robust alternative. LMPO introduces a uniform\nreference model as an upper bound for the DPO loss, enabling a more accurate\napproximation of the original optimization objective. Additionally, an average\nlog-probability optimization strategy is employed to minimize discrepancies\nbetween training and inference phases. A key innovation of LMPO lies in its\nLength-Controlled Margin-Based loss function, integrated within the\nBradley-Terry framework. This loss function regulates response length while\nsimultaneously widening the margin between preferred and rejected outputs. By\ndoing so, it mitigates probability degradation for both accepted and discarded\nresponses, addressing a significant limitation of existing methods. We evaluate\nLMPO against state-of-the-art preference optimization techniques on two\nopen-ended large language models, Mistral and LLaMA3, across six conditional\nbenchmarks. Our experimental results demonstrate that LMPO effectively controls\nresponse length, reduces probability degradation, and outperforms existing\napproaches. The code is available at https://github.com/gengxuli/LMPO.", "AI": {"tldr": "LMPO improves DPO by addressing length bias, memory inefficiency, and probability degradation with a new loss function and optimization strategy.", "motivation": "DPO's limitations (length bias, memory inefficiency, probability degradation) hinder preference-based RLHF.", "method": "LMPO introduces a uniform reference model, average log-probability optimization, and a Length-Controlled Margin-Based loss function.", "result": "LMPO outperforms DPO on Mistral and LLaMA3, controlling response length and reducing probability degradation.", "conclusion": "LMPO is a robust alternative to DPO, addressing its key limitations effectively."}}
{"id": "2503.00301", "pdf": "https://arxiv.org/pdf/2503.00301", "abs": "https://arxiv.org/abs/2503.00301", "authors": ["Zihan Huang", "Wei Fang", "Tong Bu", "Peng Xue", "Zecheng Hao", "Wenxuan Liu", "Yuanhong Tang", "Zhaofei Yu", "Tiejun Huang"], "title": "Differential Coding for Training-Free ANN-to-SNN Conversion", "categories": ["cs.CV"], "comment": null, "summary": "Spiking Neural Networks (SNNs) exhibit significant potential due to their low\nenergy consumption. Converting Artificial Neural Networks (ANNs) to SNNs is an\nefficient way to achieve high-performance SNNs. However, many conversion\nmethods are based on rate coding, which requires numerous spikes and longer\ntime-steps compared to directly trained SNNs, leading to increased energy\nconsumption and latency. This article introduces differential coding for\nANN-to-SNN conversion, a novel coding scheme that reduces spike counts and\nenergy consumption by transmitting changes in rate information rather than\nrates directly, and explores its application across various layers.\nAdditionally, the threshold iteration method is proposed to optimize thresholds\nbased on activation distribution when converting Rectified Linear Units (ReLUs)\nto spiking neurons. Experimental results on various Convolutional Neural\nNetworks (CNNs) and Transformers demonstrate that the proposed differential\ncoding significantly improves accuracy while reducing energy consumption,\nparticularly when combined with the threshold iteration method, achieving\nstate-of-the-art performance. The source codes of the proposed method are\navailable at https://github.com/h-z-h-cell/ANN-to-SNN-DCGS.", "AI": {"tldr": "The paper introduces differential coding for ANN-to-SNN conversion, reducing spike counts and energy consumption, and proposes a threshold iteration method for optimizing ReLU conversions.", "motivation": "Current ANN-to-SNN conversion methods rely on rate coding, which increases energy and latency due to high spike counts and long time-steps.", "method": "The paper proposes differential coding to transmit rate changes instead of rates directly and introduces a threshold iteration method for ReLU conversion.", "result": "Experiments on CNNs and Transformers show improved accuracy and reduced energy consumption, achieving state-of-the-art performance.", "conclusion": "Differential coding and threshold iteration enhance ANN-to-SNN conversion efficiency, offering a promising approach for low-energy SNNs."}}
{"id": "2411.06426", "pdf": "https://arxiv.org/pdf/2411.06426", "abs": "https://arxiv.org/abs/2411.06426", "authors": ["Bijoy Ahmed Saiem", "MD Sadik Hossain Shanto", "Rakib Ahsan", "Md Rafi ur Rashid"], "title": "SequentialBreak: Large Language Models Can be Fooled by Embedding Jailbreak Prompts into Sequential Prompt Chains", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "As the integration of the Large Language Models (LLMs) into various\napplications increases, so does their susceptibility to misuse, raising\nsignificant security concerns. Numerous jailbreak attacks have been proposed to\nassess the security defense of LLMs. Current jailbreak attacks mainly rely on\nscenario camouflage, prompt obfuscation, prompt optimization, and prompt\niterative optimization to conceal malicious prompts. In particular, sequential\nprompt chains in a single query can lead LLMs to focus on certain prompts while\nignoring others, facilitating context manipulation. This paper introduces\nSequentialBreak, a novel jailbreak attack that exploits this vulnerability. We\ndiscuss several scenarios, not limited to examples like Question Bank, Dialog\nCompletion, and Game Environment, where the harmful prompt is embedded within\nbenign ones that can fool LLMs into generating harmful responses. The distinct\nnarrative structures of these scenarios show that SequentialBreak is flexible\nenough to adapt to various prompt formats beyond those discussed. Extensive\nexperiments demonstrate that SequentialBreak uses only a single query to\nachieve a substantial gain of attack success rate over existing baselines\nagainst both open-source and closed-source models. Through our research, we\nhighlight the urgent need for more robust and resilient safeguards to enhance\nLLM security and prevent potential misuse. All the result files and website\nassociated with this research are available in this GitHub repository:\nhttps://anonymous.4open.science/r/JailBreakAttack-4F3B/.", "AI": {"tldr": "SequentialBreak is a novel jailbreak attack exploiting sequential prompt chains to manipulate LLMs into harmful responses, outperforming existing methods with a single query.", "motivation": "The increasing misuse of LLMs raises security concerns, necessitating robust defenses against jailbreak attacks.", "method": "SequentialBreak embeds harmful prompts within benign ones using sequential chains, tested in scenarios like Question Bank and Dialog Completion.", "result": "Experiments show SequentialBreak achieves higher attack success rates with a single query compared to baselines.", "conclusion": "The study underscores the need for stronger safeguards to prevent LLM misuse, with results and resources available on GitHub."}}
{"id": "2505.23416", "pdf": "https://arxiv.org/pdf/2505.23416", "abs": "https://arxiv.org/abs/2505.23416", "authors": ["Jang-Hyun Kim", "Jinuk Kim", "Sangwoo Kwon", "Jae W. Lee", "Sangdoo Yun", "Hyun Oh Song"], "title": "KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction", "categories": ["cs.DB", "cs.LG"], "comment": "preprint", "summary": "Transformer-based large language models (LLMs) cache context as key-value\n(KV) pairs during inference. As context length grows, KV cache sizes expand,\nleading to substantial memory overhead and increased attention latency. This\npaper introduces KVzip, a query-agnostic KV cache eviction method enabling\neffective reuse of compressed KV caches across diverse queries. KVzip\nquantifies the importance of a KV pair using the underlying LLM to reconstruct\noriginal contexts from cached KV pairs, subsequently evicting pairs with lower\nimportance. Extensive empirical evaluations demonstrate that KVzip reduces KV\ncache size by 3-4$\\times$ and FlashAttention decoding latency by approximately\n2$\\times$, with negligible performance loss in question-answering, retrieval,\nreasoning, and code comprehension tasks. Evaluations include various models\nsuch as LLaMA3.1-8B, Qwen2.5-14B, and Gemma3-12B, with context lengths reaching\nup to 170K tokens. KVzip significantly outperforms existing query-aware KV\neviction methods, which suffer from performance degradation even at a 90% cache\nbudget ratio under multi-query scenarios.", "AI": {"tldr": "KVzip is a query-agnostic KV cache eviction method that reduces memory overhead and latency in LLMs by compressing and reusing KV caches, outperforming existing methods.", "motivation": "KV cache sizes grow with context length, increasing memory overhead and attention latency in LLMs.", "method": "KVzip quantifies KV pair importance using the LLM to reconstruct contexts, evicting less important pairs.", "result": "KVzip reduces KV cache size by 3-4\u00d7 and latency by ~2\u00d7 with minimal performance loss.", "conclusion": "KVzip effectively addresses KV cache inefficiencies, outperforming query-aware methods in multi-query scenarios."}}
{"id": "2502.15538", "pdf": "https://arxiv.org/pdf/2502.15538", "abs": "https://arxiv.org/abs/2502.15538", "authors": ["Wenyuan Zhang", "Tianyun Liu", "Mengxiao Song", "Xiaodong Li", "Tingwen Liu"], "title": "SOTOPIA-$\u03a9$: Dynamic Strategy Injection Learning and Social Instruction Following Evaluation for Social Agents", "categories": ["cs.CL", "cs.CY", "cs.HC"], "comment": "Accepted by ACL 2025 (Main Conference)", "summary": "Despite the abundance of prior social strategies possessed by humans, there\nremains a paucity of research dedicated to their transfer and integration into\nsocial agents. Our proposed SOTOPIA-$\\Omega$ framework aims to address and\nbridge this gap, with a particular focus on enhancing the social capabilities\nof language agents. This framework dynamically injects multi-step reasoning\nstrategies inspired by negotiation theory and two simple direct strategies into\nexpert agents, thereby automating the construction of a high-quality social\ndialogue training corpus. Additionally, we introduce the concept of Social\nInstruction Following (S-IF) and propose two new S-IF evaluation metrics that\ncomplement social capability. We demonstrate that several 7B models trained on\nhigh-quality corpus not only significantly surpass the expert agent (GPT-4) in\nachieving social goals but also enhance S-IF performance. Analysis and variant\nexperiments validate the advantages of dynamic construction, which can\nespecially break the agent's prolonged deadlock.", "AI": {"tldr": "The paper introduces SOTOPIA-\u03a9, a framework to enhance social capabilities of language agents by integrating human social strategies, automating dialogue corpus creation, and proposing new evaluation metrics.", "motivation": "To address the lack of research on transferring human social strategies to social agents, aiming to improve their social dialogue capabilities.", "method": "The SOTOPIA-\u03a9 framework dynamically injects multi-step reasoning and direct strategies into expert agents, automating high-quality dialogue corpus construction. It also introduces Social Instruction Following (S-IF) and new evaluation metrics.", "result": "7B models trained on the corpus outperform GPT-4 in social goal achievement and S-IF performance. Dynamic construction breaks agent deadlocks.", "conclusion": "SOTOPIA-\u03a9 effectively enhances social agent capabilities, demonstrating the value of dynamic strategy integration and automated corpus construction."}}
{"id": "2503.08250", "pdf": "https://arxiv.org/pdf/2503.08250", "abs": "https://arxiv.org/abs/2503.08250", "authors": ["Jaa-Yeon Lee", "Byunghee Cha", "Jeongsol Kim", "Jong Chul Ye"], "title": "Aligning Text to Image in Diffusion Models is Easier Than You Think", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "While recent advancements in generative modeling have significantly improved\ntext-image alignment, some residual misalignment between text and image\nrepresentations still remains. Some approaches address this issue by\nfine-tuning models in terms of preference optimization, etc., which require\ntailored datasets. Orthogonal to these methods, we revisit the challenge from\nthe perspective of representation alignment-an approach that has gained\npopularity with the success of REPresentation Alignment (REPA). We first argue\nthat conventional text-to-image (T2I) diffusion models, typically trained on\npaired image and text data (i.e., positive pairs) by minimizing score matching\nor flow matching losses, is suboptimal from the standpoint of representation\nalignment. Instead, a better alignment can be achieved through contrastive\nlearning that leverages existing dataset as both positive and negative pairs.\nTo enable efficient alignment with pretrained models, we propose SoftREPA- a\nlightweight contrastive fine-tuning strategy that leverages soft text tokens\nfor representation alignment. This approach improves alignment with minimal\ncomputational overhead by adding fewer than 1M trainable parameters to the\npretrained model. Our theoretical analysis demonstrates that our method\nexplicitly increases the mutual information between text and image\nrepresentations, leading to enhanced semantic consistency. Experimental results\nacross text-to-image generation and text-guided image editing tasks validate\nthe effectiveness of our approach in improving the semantic consistency of T2I\ngenerative models.", "AI": {"tldr": "The paper proposes SoftREPA, a lightweight contrastive fine-tuning method to improve text-image alignment in generative models by leveraging existing datasets as positive and negative pairs.", "motivation": "Address residual misalignment in text-image representations, avoiding the need for tailored datasets by revisiting representation alignment.", "method": "Introduces SoftREPA, a contrastive learning approach using soft text tokens for efficient alignment with pretrained models, adding minimal parameters.", "result": "Theoretical and experimental results show improved semantic consistency in text-to-image generation and editing tasks.", "conclusion": "SoftREPA effectively enhances text-image alignment with low computational overhead."}}
{"id": "2411.17296", "pdf": "https://arxiv.org/pdf/2411.17296", "abs": "https://arxiv.org/abs/2411.17296", "authors": ["Guoguo Ai", "Guansong Pang", "Hezhe Qiao", "Yuan Gao", "Hui Yan"], "title": "GrokFormer: Graph Fourier Kolmogorov-Arnold Transformers", "categories": ["cs.LG", "cs.AI"], "comment": "20 pages, 7 figures, 11 tables, Accepted by ICML 2025", "summary": "Graph Transformers (GTs) have demonstrated remarkable performance in graph\nrepresentation learning over popular graph neural networks (GNNs). However,\nself--attention, the core module of GTs, preserves only low-frequency signals\nin graph features, leading to ineffectiveness in capturing other important\nsignals like high-frequency ones. Some recent GT models help alleviate this\nissue, but their flexibility and expressiveness are still limited since the\nfilters they learn are fixed on predefined graph spectrum or spectral order. To\ntackle this challenge, we propose a Graph Fourier Kolmogorov-Arnold Transformer\n(GrokFormer), a novel GT model that learns highly expressive spectral filters\nwith adaptive graph spectrum and spectral order through a Fourier series\nmodeling over learnable activation functions. We demonstrate theoretically and\nempirically that the proposed GrokFormer filter offers better expressiveness\nthan other spectral methods. Comprehensive experiments on 10 real-world node\nclassification datasets across various domains, scales, and graph properties,\nas well as 5 graph classification datasets, show that GrokFormer outperforms\nstate-of-the-art GTs and GNNs. Our code is available at\nhttps://github.com/GGA23/GrokFormer", "AI": {"tldr": "GrokFormer, a Graph Transformer model, improves graph representation learning by adaptively learning spectral filters, outperforming existing GTs and GNNs.", "motivation": "Existing Graph Transformers (GTs) struggle with capturing high-frequency signals due to fixed filters on predefined graph spectrum, limiting flexibility and expressiveness.", "method": "Proposes GrokFormer, which learns adaptive spectral filters using Fourier series modeling over learnable activation functions.", "result": "Theoretically and empirically, GrokFormer shows better expressiveness and outperforms state-of-the-art models on 10 node and 5 graph classification datasets.", "conclusion": "GrokFormer addresses limitations of existing GTs by adaptive spectral learning, achieving superior performance in graph representation tasks."}}
{"id": "2505.23431", "pdf": "https://arxiv.org/pdf/2505.23431", "abs": "https://arxiv.org/abs/2505.23431", "authors": ["Amer Krivo\u0161ija", "Alexander Munteanu", "Andr\u00e9 Nusser", "Chris Schwiegelshohn"], "title": "Improved Learning via k-DTW: A Novel Dissimilarity Measure for Curves", "categories": ["cs.DS", "cs.CG", "cs.LG", "stat.ML"], "comment": "ICML 2025", "summary": "This paper introduces $k$-Dynamic Time Warping ($k$-DTW), a novel\ndissimilarity measure for polygonal curves. $k$-DTW has stronger metric\nproperties than Dynamic Time Warping (DTW) and is more robust to outliers than\nthe Fr\\'{e}chet distance, which are the two gold standards of dissimilarity\nmeasures for polygonal curves. We show interesting properties of $k$-DTW and\ngive an exact algorithm as well as a $(1+\\varepsilon)$-approximation algorithm\nfor $k$-DTW by a parametric search for the $k$-th largest matched distance. We\nprove the first dimension-free learning bounds for curves and further learning\ntheoretic results. $k$-DTW not only admits smaller sample size than DTW for the\nproblem of learning the median of curves, where some factors depending on the\ncurves' complexity $m$ are replaced by $k$, but we also show a surprising\nseparation on the associated Rademacher and Gaussian complexities: $k$-DTW\nadmits strictly smaller bounds than DTW, by a factor $\\tilde\\Omega(\\sqrt{m})$\nwhen $k\\ll m$. We complement our theoretical findings with an experimental\nillustration of the benefits of using $k$-DTW for clustering and nearest\nneighbor classification.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2502.15543", "pdf": "https://arxiv.org/pdf/2502.15543", "abs": "https://arxiv.org/abs/2502.15543", "authors": ["Pengcheng Huang", "Zhenghao Liu", "Yukun Yan", "Haiyan Zhao", "Xiaoyuan Yi", "Hao Chen", "Zhiyuan Liu", "Maosong Sun", "Tong Xiao", "Ge Yu", "Chenyan Xiong"], "title": "ParamMute: Suppressing Knowledge-Critical FFNs for Faithful Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI"], "comment": "22 pages, 7 figures, 7 tables", "summary": "Large language models (LLMs) integrated with retrieval-augmented generation\n(RAG) have improved factuality by grounding outputs in external evidence.\nHowever, they remain susceptible to unfaithful generation, where outputs\ncontradict retrieved context despite its relevance and accuracy. Existing\napproaches aiming to improve faithfulness primarily focus on enhancing the\nutilization of external context, but often overlook the persistent influence of\ninternal parametric knowledge during generation. In this work, we investigate\nthe internal mechanisms behind unfaithful generation and identify a subset of\nmid-to-deep feed-forward networks (FFNs) that are disproportionately activated\nin such cases. Building on this insight, we propose Parametric Knowledge Muting\nthrough FFN Suppression (ParamMute), a framework that improves contextual\nfaithfulness by suppressing the activation of unfaithfulness-associated FFNs\nand calibrating the model toward retrieved knowledge. To evaluate our approach,\nwe introduce CoFaithfulQA, a benchmark specifically designed to evaluate\nfaithfulness in scenarios where internal knowledge conflicts with accurate\nexternal evidence. Experimental results show that ParamMute significantly\nenhances faithfulness across both CoFaithfulQA and the established ConFiQA\nbenchmark, achieving substantial reductions in reliance on parametric memory.\nThese findings underscore the importance of mitigating internal knowledge\ndominance and provide a new direction for improving LLM trustworthiness in RAG.\nAll code will be released via GitHub.", "AI": {"tldr": "The paper introduces ParamMute, a framework to improve faithfulness in LLMs by suppressing unfaithful FFN activations, reducing reliance on parametric memory when external evidence conflicts.", "motivation": "Despite retrieval-augmented generation (RAG) improving factuality, LLMs still produce unfaithful outputs contradicting accurate external context. Existing methods overlook internal parametric knowledge's influence.", "method": "The study identifies unfaithfulness-associated FFNs and proposes ParamMute, which suppresses these FFNs to calibrate the model toward retrieved knowledge.", "result": "ParamMute significantly enhances faithfulness on CoFaithfulQA and ConFiQA benchmarks, reducing reliance on parametric memory.", "conclusion": "Mitigating internal knowledge dominance improves LLM trustworthiness in RAG, offering a new direction for future research."}}
{"id": "2503.12821", "pdf": "https://arxiv.org/pdf/2503.12821", "abs": "https://arxiv.org/abs/2503.12821", "authors": ["Mingyang Song", "Xiaoye Qu", "Jiawei Zhou", "Yu Cheng"], "title": "From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by CVPR 2025. Project Page: https://vlmlt.github.io/", "summary": "Large Vision-Language Models (LVLMs) have achieved significant progress in\ncombining visual comprehension with language generation. Despite this success,\nthe training data of LVLMs still suffers from Long-Tail (LT) problems, where\nthe data distribution is highly imbalanced. Previous works have mainly focused\non traditional VLM architectures, i.e., CLIP or ViT, and specific tasks such as\nrecognition and classification. Nevertheless, the exploration of LVLM (e.g.\nLLaVA) and more general tasks (e.g. Visual Question Answering and Visual\nReasoning) remains under-explored. In this paper, we first conduct an in-depth\nanalysis of the LT issues in LVLMs and identify two core causes: the\noverrepresentation of head concepts and the underrepresentation of tail\nconcepts. Based on the above observation, we propose an $\\textbf{A}$daptive\n$\\textbf{D}$ata $\\textbf{R}$efinement Framework ($\\textbf{ADR}$), which\nconsists of two stages: $\\textbf{D}$ata $\\textbf{R}$ebalancing ($\\textbf{DR}$)\nand $\\textbf{D}$ata $\\textbf{S}$ynthesis ($\\textbf{DS}$). In the DR stage, we\nadaptively rebalance the redundant data based on entity distributions, while in\nthe DS stage, we leverage Denoising Diffusion Probabilistic Models (DDPMs) and\nscarce images to supplement underrepresented portions. Through comprehensive\nevaluations across eleven benchmarks, our proposed ADR effectively mitigates\nthe long-tail problem in the training data, improving the average performance\nof LLaVA 1.5 relatively by 4.36%, without increasing the training data volume.", "AI": {"tldr": "The paper addresses long-tail data imbalance in Large Vision-Language Models (LVLMs) by proposing an Adaptive Data Refinement Framework (ADR) with two stages: Data Rebalancing and Data Synthesis, improving model performance.", "motivation": "LVLMs suffer from long-tail data imbalance, where head concepts are overrepresented and tail concepts underrepresented, limiting performance in tasks like Visual Question Answering.", "method": "ADR framework includes Data Rebalancing (DR) to adjust entity distributions and Data Synthesis (DS) using DDPMs to supplement scarce data.", "result": "ADR improves LLaVA 1.5's performance by 4.36% across eleven benchmarks without additional training data.", "conclusion": "ADR effectively mitigates long-tail issues in LVLMs, enhancing performance for underrepresented concepts."}}
{"id": "2411.18212", "pdf": "https://arxiv.org/pdf/2411.18212", "abs": "https://arxiv.org/abs/2411.18212", "authors": ["Aladin Djuhera", "Amin Seffo", "Vlad C. Andrei", "Holger Boche", "Walid Saad"], "title": "SCoTT: Strategic Chain-of-Thought Tasking for Wireless-Aware Robot Navigation in Digital Twins", "categories": ["cs.LG", "cs.AI", "cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Path planning under wireless performance constraints is a complex challenge\nin robot navigation. However, naively incorporating such constraints into\nclassical planning algorithms often incurs prohibitive search costs. In this\npaper, we propose SCoTT, a wireless-aware path planning framework that\nleverages vision-language models (VLMs) to co-optimize average path gains and\ntrajectory length using wireless heatmap images and ray-tracing data from a\ndigital twin (DT). At the core of our framework is Strategic Chain-of-Thought\nTasking (SCoTT), a novel prompting paradigm that decomposes the exhaustive\nsearch problem into structured subtasks, each solved via chain-of-thought\nprompting. To establish strong baselines, we compare classical A* and\nwireless-aware extensions of it, and derive DP-WA*, an optimal, iterative\ndynamic programming algorithm that incorporates all path gains and distance\nmetrics from the DT, but at significant computational cost. In extensive\nexperiments, we show that SCoTT achieves path gains within 2% of DP-WA* while\nconsistently generating shorter trajectories. Moreover, SCoTT's intermediate\noutputs can be used to accelerate DP-WA* by reducing its search space, saving\nup to 62% in execution time. We validate our framework using four VLMs,\ndemonstrating effectiveness across both large and small models, thus making it\napplicable to a wide range of compact models at low inference cost. We also\nshow the practical viability of our approach by deploying SCoTT as a ROS node\nwithin Gazebo simulations. Finally, we discuss data acquisition pipelines,\ncompute requirements, and deployment considerations for VLMs in 6G-enabled DTs,\nunderscoring the potential of natural language interfaces for wireless-aware\nnavigation in real-world applications.", "AI": {"tldr": "SCoTT is a wireless-aware path planning framework using VLMs to optimize path gains and trajectory length, outperforming traditional methods like A* and DP-WA* in efficiency and performance.", "motivation": "Traditional path planning algorithms struggle with wireless performance constraints due to high computational costs, necessitating a more efficient solution.", "method": "SCoTT uses vision-language models (VLMs) and a novel prompting paradigm (Strategic Chain-of-Thought Tasking) to decompose and solve the planning problem, leveraging wireless heatmaps and ray-tracing data.", "result": "SCoTT achieves path gains within 2% of DP-WA* while generating shorter trajectories and reducing DP-WA*'s search space, saving up to 62% in execution time.", "conclusion": "SCoTT is practical, scalable, and effective for wireless-aware navigation, with potential for real-world applications in 6G-enabled digital twins."}}
{"id": "2505.23445", "pdf": "https://arxiv.org/pdf/2505.23445", "abs": "https://arxiv.org/abs/2505.23445", "authors": ["Adrien Majka", "El-Mahdi El-Mhamdi"], "title": "The Strong, Weak and Benign Goodhart's law. An independence-free and paradigm-agnostic formalisation", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": "32 pages, 1 figure", "summary": "Goodhart's law is a famous adage in policy-making that states that ``When a\nmeasure becomes a target, it ceases to be a good measure''. As machine learning\nmodels and the optimisation capacity to train them grow, growing empirical\nevidence reinforced the belief in the validity of this law without however\nbeing formalised. Recently, a few attempts were made to formalise Goodhart's\nlaw, either by categorising variants of it, or by looking at how optimising a\nproxy metric affects the optimisation of an intended goal. In this work, we\nalleviate the simplifying independence assumption, made in previous works, and\nthe assumption on the learning paradigm made in most of them, to study the\neffect of the coupling between the proxy metric and the intended goal on\nGoodhart's law. Our results show that in the case of light tailed goal and\nlight tailed discrepancy, dependence does not change the nature of Goodhart's\neffect. However, in the light tailed goal and heavy tailed discrepancy case, we\nexhibit an example where over-optimisation occurs at a rate inversely\nproportional to the heavy tailedness of the discrepancy between the goal and\nthe metric. %", "AI": {"tldr": "The paper formalizes Goodhart's law in machine learning, relaxing previous independence assumptions and showing how coupling between proxy metrics and goals affects over-optimization.", "motivation": "To address the lack of formalization of Goodhart's law in machine learning and explore the impact of dependency between proxy metrics and intended goals.", "method": "Relaxes simplifying independence assumptions and studies coupling effects, analyzing cases of light-tailed and heavy-tailed discrepancies.", "result": "Dependence doesn't alter Goodhart's effect in light-tailed cases, but in heavy-tailed cases, over-optimization scales inversely with tail heaviness.", "conclusion": "Coupling between metrics and goals influences Goodhart's law, with heavy-tailed discrepancies leading to faster over-optimization."}}
{"id": "2502.15572", "pdf": "https://arxiv.org/pdf/2502.15572", "abs": "https://arxiv.org/abs/2502.15572", "authors": ["Milan Gritta", "Huiyin Xue", "Gerasimos Lampouras"], "title": "DReSD: Dense Retrieval for Speculative Decoding", "categories": ["cs.CL"], "comment": "ACL (Findings) 2025", "summary": "Speculative decoding (SD) accelerates Large Language Model (LLM) generation\nby using an efficient draft model to propose the next few tokens, which are\nverified by the LLM in a single forward call, reducing latency while preserving\nits outputs. We focus on retrieval-based SD where the draft model retrieves the\nnext tokens from a non-parametric datastore. Sparse retrieval (REST), which\noperates on the surface form of strings, is currently the dominant paradigm due\nto its simplicity and scalability. However, its effectiveness is limited due to\nthe usage of short contexts and exact string matching. Instead, we introduce\nDense Retrieval for Speculative Decoding (DReSD), a novel framework that uses\napproximate nearest neighbour search with contextualised token embeddings to\nretrieve the most semantically relevant token sequences for SD. Extensive\nexperiments show that DReSD achieves (on average) 87% higher acceptance rates,\n65% longer accepted tokens and 19% faster generation speeds compared to sparse\nretrieval (REST).", "AI": {"tldr": "DReSD improves speculative decoding by using dense retrieval for token sequences, outperforming sparse retrieval (REST) in acceptance rates, token length, and speed.", "motivation": "Sparse retrieval (REST) in speculative decoding is limited by short contexts and exact string matching, prompting the need for a more effective method.", "method": "DReSD employs approximate nearest neighbour search with contextualised token embeddings to retrieve semantically relevant token sequences.", "result": "DReSD achieves 87% higher acceptance rates, 65% longer accepted tokens, and 19% faster generation speeds compared to REST.", "conclusion": "Dense retrieval (DReSD) significantly enhances speculative decoding performance over sparse retrieval."}}
{"id": "2503.17359", "pdf": "https://arxiv.org/pdf/2503.17359", "abs": "https://arxiv.org/abs/2503.17359", "authors": ["Jiwen Yu", "Yiran Qin", "Haoxuan Che", "Quande Liu", "Xintao Wang", "Pengfei Wan", "Di Zhang", "Xihui Liu"], "title": "Position: Interactive Generative Video as Next-Generation Game Engine", "categories": ["cs.CV"], "comment": null, "summary": "Modern game development faces significant challenges in creativity and cost\ndue to predetermined content in traditional game engines. Recent breakthroughs\nin video generation models, capable of synthesizing realistic and interactive\nvirtual environments, present an opportunity to revolutionize game creation. In\nthis position paper, we propose Interactive Generative Video (IGV) as the\nfoundation for Generative Game Engines (GGE), enabling unlimited novel content\ngeneration in next-generation gaming. GGE leverages IGV's unique strengths in\nunlimited high-quality content synthesis, physics-aware world modeling,\nuser-controlled interactivity, long-term memory capabilities, and causal\nreasoning. We present a comprehensive framework detailing GGE's core modules\nand a hierarchical maturity roadmap (L0-L4) to guide its evolution. Our work\ncharts a new course for game development in the AI era, envisioning a future\nwhere AI-powered generative systems fundamentally reshape how games are created\nand experienced.", "AI": {"tldr": "Proposes Interactive Generative Video (IGV) for Generative Game Engines (GGE) to revolutionize game development with AI-generated content.", "motivation": "Addresses challenges in creativity and cost in traditional game engines by leveraging AI for unlimited, dynamic content.", "method": "Introduces IGV for GGE, emphasizing high-quality synthesis, physics-aware modeling, interactivity, memory, and reasoning.", "result": "Presents a framework and roadmap (L0-L4) for GGE's evolution, aiming to reshape game creation.", "conclusion": "Envisions AI-powered generative systems transforming game development and player experiences."}}
{"id": "2411.19393", "pdf": "https://arxiv.org/pdf/2411.19393", "abs": "https://arxiv.org/abs/2411.19393", "authors": ["An T. Le", "Kay Hansel", "Jo\u00e3o Carvalho", "Joe Watson", "Julen Urain", "Armin Biess", "Georgia Chalvatzaki", "Jan Peters"], "title": "Global Tensor Motion Planning", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": "8 pages, 3 figures. Accepted at IEEE Robotics and Automation Letters\n  2025", "summary": "Batch planning is increasingly necessary to quickly produce diverse and\nquality motion plans for downstream learning applications, such as distillation\nand imitation learning. This paper presents Global Tensor Motion Planning\n(GTMP) -- a sampling-based motion planning algorithm comprising only tensor\noperations. We introduce a novel discretization structure represented as a\nrandom multipartite graph, enabling efficient vectorized sampling, collision\nchecking, and search. We provide a theoretical investigation showing that GTMP\nexhibits probabilistic completeness while supporting modern GPU/TPU.\nAdditionally, by incorporating smooth structures into the multipartite graph,\nGTMP directly plans smooth splines without requiring gradient-based\noptimization. Experiments on lidar-scanned occupancy maps and the\nMotionBenchMarker dataset demonstrate GTMP's computation efficiency in batch\nplanning compared to baselines, underscoring GTMP's potential as a robust,\nscalable planner for diverse applications and large-scale robot learning tasks.", "AI": {"tldr": "GTMP is a tensor-based motion planning algorithm using a random multipartite graph for efficient batch planning, supporting GPU/TPU and producing smooth splines without optimization.", "motivation": "The need for fast, diverse, and high-quality motion plans for learning applications like distillation and imitation learning drives the development of GTMP.", "method": "GTMP uses tensor operations and a random multipartite graph for vectorized sampling, collision checking, and search, ensuring probabilistic completeness.", "result": "GTMP outperforms baselines in batch planning efficiency on lidar-scanned maps and MotionBenchMarker, supporting smooth spline planning.", "conclusion": "GTMP is a scalable, robust planner suitable for large-scale robot learning tasks and diverse applications."}}
{"id": "2505.23557", "pdf": "https://arxiv.org/pdf/2505.23557", "abs": "https://arxiv.org/abs/2505.23557", "authors": ["Marc Jourdan", "Gizem Y\u00fcce", "Nicolas Flammarion"], "title": "Learning Parametric Distributions from Samples and Preferences", "categories": ["stat.ML", "cs.LG"], "comment": "28 pages, 8 figures. To be published in the Forty-Second\n  International Conference on Machine Learning", "summary": "Recent advances in language modeling have underscored the role of preference\nfeedback in enhancing model performance. This paper investigates the conditions\nunder which preference feedback improves parameter estimation in classes of\ncontinuous parametric distributions. In our framework, the learner observes\npairs of samples from an unknown distribution along with their relative\npreferences depending on the same unknown parameter. We show that\npreference-based M-estimators achieve a better asymptotic variance than\nsample-only M-estimators, further improved by deterministic preferences.\nLeveraging the hard constraints revealed by deterministic preferences, we\npropose an estimator achieving an estimation error scaling of\n$\\mathcal{O}(1/n)$ -- a significant improvement over the $\\Theta(1/\\sqrt{n})$\nrate attainable with samples alone. Next, we establish a lower bound that\nmatches this accelerated rate; up to dimension and problem-dependent constants.\nWhile the assumptions underpinning our analysis are restrictive, they are\nsatisfied by notable cases such as Gaussian or Laplace distributions for\npreferences based on the log-probability reward.", "AI": {"tldr": "Preference feedback improves parameter estimation in continuous distributions, achieving faster error rates than sample-only methods.", "motivation": "To understand how preference feedback enhances parameter estimation in continuous parametric distributions.", "method": "Preference-based M-estimators are used, leveraging deterministic preferences for improved asymptotic variance.", "result": "Preference-based estimators achieve an O(1/n) error rate, outperforming the \u0398(1/\u221an) rate of sample-only methods.", "conclusion": "Preference feedback significantly accelerates parameter estimation under certain conditions, with notable applicability to Gaussian and Laplace distributions."}}
{"id": "2502.16377", "pdf": "https://arxiv.org/pdf/2502.16377", "abs": "https://arxiv.org/abs/2502.16377", "authors": ["Saurabh Srivastava", "Sweta Pati", "Ziyu Yao"], "title": "Instruction-Tuning LLMs for Event Extraction with Annotation Guidelines", "categories": ["cs.CL"], "comment": "Accepted at ACL Findings 2025", "summary": "In this work, we study the effect of annotation guidelines -- textual\ndescriptions of event types and arguments, when instruction-tuning large\nlanguage models for event extraction. We conducted a series of experiments with\nboth human-provided and machine-generated guidelines in both full- and low-data\nsettings. Our results demonstrate the promise of annotation guidelines when\nthere is a decent amount of training data and highlight its effectiveness in\nimproving cross-schema generalization and low-frequency event-type performance.", "AI": {"tldr": "Annotation guidelines improve event extraction in LLMs, especially with sufficient training data, enhancing cross-schema generalization and low-frequency event-type performance.", "motivation": "To explore the impact of textual descriptions (annotation guidelines) on event extraction when instruction-tuning large language models.", "method": "Conducted experiments with human-provided and machine-generated guidelines in full- and low-data settings.", "result": "Guidelines are effective with sufficient training data, improving cross-schema generalization and low-frequency event-type performance.", "conclusion": "Annotation guidelines are promising for enhancing event extraction in LLMs, particularly in data-rich scenarios."}}
{"id": "2503.17820", "pdf": "https://arxiv.org/pdf/2503.17820", "abs": "https://arxiv.org/abs/2503.17820", "authors": ["Zheng Lin", "Nan Zhou", "Chen-Xi Du", "Deng-Ping Fan", "Shi-Min Hu"], "title": "RefCut: Interactive Segmentation with Reference Guidance", "categories": ["cs.CV"], "comment": null, "summary": "Interactive segmentation aims to segment the specified target on the image\nwith positive and negative clicks from users. Interactive ambiguity is a\ncrucial issue in this field, which refers to the possibility of multiple\ncompliant outcomes with the same clicks, such as selecting a part of an object\nversus the entire object, a single object versus a combination of multiple\nobjects, and so on. The existing methods cannot provide intuitive guidance to\nthe model, which leads to unstable output results and makes it difficult to\nmeet the large-scale and efficient annotation requirements for specific targets\nin some scenarios. To bridge this gap, we introduce RefCut, a reference-based\ninteractive segmentation framework designed to address part ambiguity and\nobject ambiguity in segmenting specific targets. Users only need to provide a\nreference image and corresponding reference masks, and the model will be\noptimized based on them, which greatly reduces the interactive burden on users\nwhen annotating a large number of such targets. In addition, to enrich these\ntwo kinds of ambiguous data, we propose a new Target Disassembly Dataset which\ncontains two subsets of part disassembly and object disassembly for evaluation.\nIn the combination evaluation of multiple datasets, our RefCut achieved\nstate-of-the-art performance. Extensive experiments and visualized results\ndemonstrate that RefCut advances the field of intuitive and controllable\ninteractive segmentation. Our code will be publicly available and the demo\nvideo is in https://www.lin-zheng.com/refcut.", "AI": {"tldr": "RefCut is a reference-based interactive segmentation framework addressing part and object ambiguity, reducing user interaction burden and achieving state-of-the-art performance.", "motivation": "Existing methods lack intuitive guidance, leading to unstable results and inefficiency in large-scale annotation.", "method": "RefCut uses reference images and masks to optimize the model, reducing user interaction. A new Target Disassembly Dataset is introduced for evaluation.", "result": "RefCut achieves state-of-the-art performance in evaluations and demonstrates intuitive, controllable segmentation.", "conclusion": "RefCut advances interactive segmentation by addressing ambiguity and improving efficiency, with code and demo available."}}
{"id": "2412.00315", "pdf": "https://arxiv.org/pdf/2412.00315", "abs": "https://arxiv.org/abs/2412.00315", "authors": ["Jingzhe Liu", "Haitao Mao", "Zhikai Chen", "Bingheng Li", "Wenqi Fan", "Mingxuan Ju", "Tong Zhao", "Neil Shah", "Jiliang Tang"], "title": "One Model for One Graph: A New Perspective for Pretraining with Cross-domain Graphs", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Graph Neural Networks (GNNs) have emerged as a powerful tool to capture\nintricate network patterns, achieving success across different domains.\nHowever, existing GNNs require careful domain-specific architecture designs and\ntraining from scratch on each dataset, leading to an expertise-intensive\nprocess with difficulty in generalizing across graphs from different domains.\nTherefore, it can be hard for practitioners to infer which GNN model can\ngeneralize well to graphs from their domains. To address this challenge, we\npropose a novel cross-domain pretraining framework, \"one model for one graph,\"\nwhich overcomes the limitations of previous approaches that failed to use a\nsingle GNN to capture diverse graph patterns across domains with significant\ngaps. Specifically, we pretrain a bank of expert models, with each one\ncorresponding to a specific dataset. When inferring to a new graph, gating\nfunctions choose a subset of experts to effectively integrate prior model\nknowledge while avoiding negative transfer. Extensive experiments consistently\ndemonstrate the superiority of our proposed method on both link prediction and\nnode classification tasks.", "AI": {"tldr": "A cross-domain pretraining framework for GNNs is proposed to generalize across diverse graphs, using expert models and gating functions for effective knowledge transfer.", "motivation": "Existing GNNs require domain-specific designs and struggle to generalize across different graphs, making it hard for practitioners to choose suitable models.", "method": "Pretrain a bank of expert models (one per dataset) and use gating functions to select relevant experts for new graphs, avoiding negative transfer.", "result": "The method outperforms others in link prediction and node classification tasks.", "conclusion": "The framework successfully generalizes GNNs across domains, addressing the limitations of previous approaches."}}
{"id": "2505.23620", "pdf": "https://arxiv.org/pdf/2505.23620", "abs": "https://arxiv.org/abs/2505.23620", "authors": ["Jiayuan Ye", "Vitaly Feldman", "Kunal Talwar"], "title": "Instance-Optimality for Private KL Distribution Estimation", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We study the fundamental problem of estimating an unknown discrete\ndistribution $p$ over $d$ symbols, given $n$ i.i.d. samples from the\ndistribution. We are interested in minimizing the KL divergence between the\ntrue distribution and the algorithm's estimate. We first construct minimax\noptimal private estimators. Minimax optimality however fails to shed light on\nan algorithm's performance on individual (non-worst-case) instances $p$ and\nsimple minimax-optimal DP estimators can have poor empirical performance on\nreal distributions. We then study this problem from an instance-optimality\nviewpoint, where the algorithm's error on $p$ is compared to the minimum\nachievable estimation error over a small local neighborhood of $p$. Under\nnatural notions of local neighborhood, we propose algorithms that achieve\ninstance-optimality up to constant factors, with and without a differential\nprivacy constraint. Our upper bounds rely on (private) variants of the\nGood-Turing estimator. Our lower bounds use additive local neighborhoods that\nmore precisely captures the hardness of distribution estimation in KL\ndivergence, compared to ones considered in prior works.", "AI": {"tldr": "The paper addresses the problem of estimating discrete distributions with minimax and instance-optimal approaches, focusing on KL divergence and differential privacy.", "motivation": "To improve estimation accuracy for individual distributions, not just worst-case scenarios, while considering privacy constraints.", "method": "Constructs minimax-optimal private estimators and proposes instance-optimal algorithms using variants of the Good-Turing estimator.", "result": "Achieves instance-optimality up to constant factors, with and without differential privacy, and provides improved lower bounds.", "conclusion": "The study advances distribution estimation by balancing minimax and instance-optimal perspectives, with practical implications for privacy-preserving methods."}}
{"id": "2503.00172", "pdf": "https://arxiv.org/pdf/2503.00172", "abs": "https://arxiv.org/abs/2503.00172", "authors": ["Zhiqiu Xia", "Jinxuan Xu", "Yuqian Zhang", "Hang Liu"], "title": "A Survey of Uncertainty Estimation Methods on Large Language Models", "categories": ["cs.CL"], "comment": "ACL Findings 2025", "summary": "Large language models (LLMs) have demonstrated remarkable capabilities across\nvarious tasks. However, these models could offer biased, hallucinated, or\nnon-factual responses camouflaged by their fluency and realistic appearance.\nUncertainty estimation is the key method to address this challenge. While\nresearch efforts in uncertainty estimation are ramping up, there is a lack of\ncomprehensive and dedicated surveys on LLM uncertainty estimation. This survey\npresents four major avenues of LLM uncertainty estimation. Furthermore, we\nperform extensive experimental evaluations across multiple methods and\ndatasets. At last, we provide critical and promising future directions for LLM\nuncertainty estimation.", "AI": {"tldr": "This survey explores uncertainty estimation in large language models (LLMs) to address biases and hallucinations, reviewing four major methods and suggesting future directions.", "motivation": "LLMs can produce biased or non-factual responses despite their fluency, necessitating uncertainty estimation to improve reliability.", "method": "The paper reviews four major approaches to LLM uncertainty estimation and conducts extensive experimental evaluations.", "result": "The survey identifies key methods and evaluates their performance across datasets, highlighting gaps and successes.", "conclusion": "The paper concludes with critical future directions to advance uncertainty estimation in LLMs."}}
{"id": "2503.19486", "pdf": "https://arxiv.org/pdf/2503.19486", "abs": "https://arxiv.org/abs/2503.19486", "authors": ["Zhengwentai Sun", "Chenghong Li", "Hongjie Liao", "Xihe Yang", "Keru Zheng", "Heyuan Li", "Yihao Zhi", "Shuliang Ning", "Shuguang Cui", "Xiaoguang Han"], "title": "Exploring Disentangled and Controllable Human Image Synthesis: From End-to-End to Stage-by-Stage", "categories": ["cs.CV"], "comment": "The authors are performing a major restructuring of the paper's\n  methodology and experiments. To avoid citation of an outdated or incomplete\n  version, we prefer to withdraw this version. A revised version may be posted\n  in the future", "summary": "Achieving fine-grained controllability in human image synthesis is a\nlong-standing challenge in computer vision. Existing methods primarily focus on\neither facial synthesis or near-frontal body generation, with limited ability\nto simultaneously control key factors such as viewpoint, pose, clothing, and\nidentity in a disentangled manner. In this paper, we introduce a new\ndisentangled and controllable human synthesis task, which explicitly separates\nand manipulates these four factors within a unified framework. We first develop\nan end-to-end generative model trained on MVHumanNet for factor\ndisentanglement. However, the domain gap between MVHumanNet and in-the-wild\ndata produces unsatisfactory results, motivating the exploration of virtual\ntry-on (VTON) dataset as a potential solution. Through experiments, we observe\nthat simply incorporating the VTON dataset as additional data to train the\nend-to-end model degrades performance, primarily due to the inconsistency in\ndata forms between the two datasets, which disrupts the disentanglement\nprocess. To better leverage both datasets, we propose a stage-by-stage\nframework that decomposes human image generation into three sequential steps:\nclothed A-pose generation, back-view synthesis, and pose and view control. This\nstructured pipeline enables better dataset utilization at different stages,\nsignificantly improving controllability and generalization, especially for\nin-the-wild scenarios. Extensive experiments demonstrate that our\nstage-by-stage approach outperforms end-to-end models in both visual fidelity\nand disentanglement quality, offering a scalable solution for real-world tasks.\nAdditional demos are available on the project page:\nhttps://taited.github.io/discohuman-project/.", "AI": {"tldr": "A stage-by-stage framework improves controllability in human image synthesis by disentangling and manipulating viewpoint, pose, clothing, and identity, outperforming end-to-end models.", "motivation": "Existing methods lack fine-grained control over key factors like viewpoint, pose, clothing, and identity in human image synthesis. The domain gap between datasets further complicates disentanglement.", "method": "Proposes a three-step pipeline: clothed A-pose generation, back-view synthesis, and pose/view control, leveraging MVHumanNet and VTON datasets separately to avoid inconsistency.", "result": "The stage-by-stage approach outperforms end-to-end models in visual fidelity and disentanglement quality, especially for in-the-wild scenarios.", "conclusion": "The structured pipeline offers a scalable solution for real-world tasks, improving generalization and controllability in human image synthesis."}}
{"id": "2412.03791", "pdf": "https://arxiv.org/pdf/2412.03791", "abs": "https://arxiv.org/abs/2412.03791", "authors": ["Yuyang Wang", "Anurag Ranjan", "Josh Susskind", "Miguel Angel Bautista"], "title": "INRFlow: Flow Matching for INRs in Ambient Space", "categories": ["cs.LG", "cs.AI"], "comment": "22 pages, 14 figures, 13 tables", "summary": "Flow matching models have emerged as a powerful method for generative\nmodeling on domains like images or videos, and even on irregular or\nunstructured data like 3D point clouds or even protein structures. These models\nare commonly trained in two stages: first, a data compressor is trained, and in\na subsequent training stage a flow matching generative model is trained in the\nlatent space of the data compressor. This two-stage paradigm sets obstacles for\nunifying models across data domains, as hand-crafted compressors architectures\nare used for different data modalities. To this end, we introduce INRFlow, a\ndomain-agnostic approach to learn flow matching transformers directly in\nambient space. Drawing inspiration from INRs, we introduce a conditionally\nindependent point-wise training objective that enables INRFlow to make\npredictions continuously in coordinate space. Our empirical results demonstrate\nthat INRFlow effectively handles different data modalities such as images, 3D\npoint clouds and protein structure data, achieving strong performance in\ndifferent domains and outperforming comparable approaches. INRFlow is a\npromising step towards domain-agnostic flow matching generative models that can\nbe trivially adopted in different data domains.", "AI": {"tldr": "INRFlow introduces a domain-agnostic flow matching transformer trained directly in ambient space, eliminating the need for hand-crafted compressors and unifying generative modeling across diverse data modalities like images, 3D point clouds, and protein structures.", "motivation": "The two-stage training paradigm of flow matching models, requiring hand-crafted compressors for different data modalities, hinders unification across domains. INRFlow aims to overcome this limitation.", "method": "INRFlow uses a conditionally independent point-wise training objective inspired by INRs, enabling continuous predictions in coordinate space without domain-specific compressors.", "result": "INRFlow effectively handles various data modalities, outperforming comparable approaches and demonstrating strong performance across domains.", "conclusion": "INRFlow is a promising step toward domain-agnostic flow matching generative models, easily adaptable to different data domains."}}
{"id": "2505.23652", "pdf": "https://arxiv.org/pdf/2505.23652", "abs": "https://arxiv.org/abs/2505.23652", "authors": ["Yuehaw Khoo", "Mathias Oster", "Yifan Peng"], "title": "Optimization-Free Diffusion Model -- A Perturbation Theory Approach", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": "36 pages, 6 figures", "summary": "Diffusion models have emerged as a powerful framework in generative modeling,\ntypically relying on optimizing neural networks to estimate the score function\nvia forward SDE simulations. In this work, we propose an alternative method\nthat is both optimization-free and forward SDE-free. By expanding the score\nfunction in a sparse set of eigenbasis of the backward Kolmogorov operator\nassociated with the diffusion process, we reformulate score estimation as the\nsolution to a linear system, avoiding iterative optimization and time-dependent\nsample generation. We analyze the approximation error using perturbation theory\nand demonstrate the effectiveness of our method on high-dimensional Boltzmann\ndistributions and real-world datasets.", "AI": {"tldr": "Proposes an optimization-free, forward SDE-free method for score estimation in diffusion models using eigenbasis expansion of the backward Kolmogorov operator.", "motivation": "To avoid iterative optimization and time-dependent sample generation in diffusion models.", "method": "Expands the score function in a sparse eigenbasis of the backward Kolmogorov operator, solving a linear system for score estimation.", "result": "Demonstrates effectiveness on high-dimensional Boltzmann distributions and real-world datasets.", "conclusion": "The method provides an efficient alternative to traditional diffusion model frameworks."}}
{"id": "2503.09894", "pdf": "https://arxiv.org/pdf/2503.09894", "abs": "https://arxiv.org/abs/2503.09894", "authors": ["Abhipsha Das", "Nicholas Lourie", "Siavash Golkar", "Mariel Pettee"], "title": "What's In Your Field? Mapping Scientific Research with Knowledge Graphs and Large Language Models", "categories": ["cs.CL"], "comment": "9 pages, 5 pdf figures", "summary": "The scientific literature's exponential growth makes it increasingly\nchallenging to navigate and synthesize knowledge across disciplines. Large\nlanguage models (LLMs) are powerful tools for understanding scientific text,\nbut they fail to capture detailed relationships across large bodies of work.\nUnstructured approaches, like retrieval augmented generation, can sift through\nsuch corpora to recall relevant facts; however, when millions of facts\ninfluence the answer, unstructured approaches become cost prohibitive.\nStructured representations offer a natural complement -- enabling systematic\nanalysis across the whole corpus. Recent work enhances LLMs with unstructured\nor semistructured representations of scientific concepts; to complement this,\nwe try extracting structured representations using LLMs. By combining LLMs'\nsemantic understanding with a schema of scientific concepts, we prototype a\nsystem that answers precise questions about the literature as a whole. Our\nschema applies across scientific fields and we extract concepts from it using\nonly 20 manually annotated abstracts. To demonstrate the system, we extract\nconcepts from 30,000 papers on arXiv spanning astrophysics, fluid dynamics, and\nevolutionary biology. The resulting database highlights emerging trends and, by\nvisualizing the knowledge graph, offers new ways to explore the ever-growing\nlandscape of scientific knowledge. Demo: abby101/surveyor-0 on HF Spaces. Code:\nhttps://github.com/chiral-carbon/kg-for-science.", "AI": {"tldr": "The paper proposes a system combining LLMs and structured representations to analyze scientific literature, addressing the challenge of synthesizing knowledge across disciplines.", "motivation": "The exponential growth of scientific literature makes it hard to navigate and synthesize knowledge. Existing LLMs and unstructured methods are limited in capturing detailed relationships or are cost-prohibitive.", "method": "The authors enhance LLMs with structured representations using a schema of scientific concepts. They prototype a system to answer precise questions about literature, extracting concepts from 30,000 arXiv papers.", "result": "The system successfully extracts concepts across fields like astrophysics and evolutionary biology, creating a database that highlights trends and visualizes a knowledge graph.", "conclusion": "Structured representations complement LLMs for systematic analysis of scientific literature, offering new ways to explore and synthesize knowledge."}}
{"id": "2503.22154", "pdf": "https://arxiv.org/pdf/2503.22154", "abs": "https://arxiv.org/abs/2503.22154", "authors": ["Jae-Young Yim", "Dongwook Kim", "Jae-Young Sim"], "title": "Dataset Distillation of 3D Point Clouds via Distribution Matching", "categories": ["cs.CV"], "comment": null, "summary": "Large-scale datasets are usually required to train deep neural networks, but\nit increases the computational complexity hindering the practical applications.\nRecently, dataset distillation for images and texts has been attracting a lot\nof attention, that reduces the original dataset to a synthetic dataset to\nalleviate the computational burden of training while preserving essential\ntask-relevant information. However, the dataset distillation for 3D point\nclouds remains largely unexplored, as the point clouds exhibit fundamentally\ndifferent characteristics from that of images, making the dataset distillation\nmore challenging. In this paper, we propose a distribution matching-based\ndistillation framework for 3D point clouds that jointly optimizes the geometric\nstructures as well as the orientations of the synthetic 3D objects. To address\nthe semantic misalignment caused by unordered indexing of points, we introduce\na Semantically Aligned Distribution Matching loss computed on the sorted\nfeatures in each channel. Moreover, to address the rotation variation, we\njointly learn the optimal rotation angles while updating the synthetic dataset\nto better align with the original feature distribution. Extensive experiments\non widely used benchmark datasets demonstrate that the proposed method\nconsistently outperforms existing dataset distillation methods, achieving\nsuperior accuracy and strong cross-architecture generalization.", "AI": {"tldr": "A novel dataset distillation method for 3D point clouds is proposed, addressing challenges like unordered points and rotation variations, outperforming existing methods.", "motivation": "Large-scale datasets for training deep neural networks are computationally expensive, and dataset distillation for 3D point clouds is underexplored due to their unique characteristics.", "method": "A distribution matching-based framework optimizes geometric structures and orientations of synthetic 3D objects, using a Semantically Aligned Distribution Matching loss and jointly learning rotation angles.", "result": "The method outperforms existing dataset distillation techniques, achieving higher accuracy and strong cross-architecture generalization.", "conclusion": "The proposed framework effectively distills 3D point cloud datasets, reducing computational burden while preserving essential information."}}
{"id": "2412.03970", "pdf": "https://arxiv.org/pdf/2412.03970", "abs": "https://arxiv.org/abs/2412.03970", "authors": ["Xiangnan Yu", "Hao Xu", "Zhiping Mao", "HongGuang Sun", "Yong Zhang", "Dongxiao Zhang", "Yuntian Chen"], "title": "A Data-Driven Framework for Discovering Fractional Differential Equations in Complex Systems", "categories": ["physics.comp-ph", "cs.AI"], "comment": null, "summary": "In complex physical systems, conventional differential equations often fall\nshort in capturing non-local and memory effects, as they are limited to local\ndynamics and integer-order interactions. This study introduces a stepwise\ndata-driven framework for discovering fractional differential equations (FDEs)\ndirectly from data. FDEs, known for their capacity to model non-local dynamics\nwith fewer parameters than integer-order derivatives, can represent complex\nsystems with long-range interactions. Our framework applies deep neural\nnetworks as surrogate models for denoising and reconstructing sparse and noisy\nobservations while using Gaussian-Jacobi quadrature to handle the challenges\nposed by singularities in fractional derivatives. To optimize both the sparse\ncoefficients and fractional order, we employ an alternating optimization\napproach that combines sparse regression with global optimization techniques.\nWe validate the framework across various datasets, including synthetic\nanomalous diffusion data, experimental data on the creep behavior of frozen\nsoils, and single-particle trajectories modeled by L\\'{e}vy motion. Results\ndemonstrate the framework's robustness in identifying the structure of FDEs\nacross diverse noise levels and its capacity to capture integer-order dynamics,\noffering a flexible approach for modeling memory effects in complex systems.", "AI": {"tldr": "A data-driven framework for discovering fractional differential equations (FDEs) from data, using deep neural networks and Gaussian-Jacobi quadrature, validated on synthetic and experimental datasets.", "motivation": "Conventional differential equations fail to capture non-local and memory effects in complex systems, necessitating a method to model such dynamics efficiently.", "method": "The framework employs deep neural networks for denoising and reconstructing data, Gaussian-Jacobi quadrature for handling singularities, and alternating optimization for sparse coefficients and fractional order.", "result": "The framework robustly identifies FDE structures across noise levels and captures integer-order dynamics, demonstrating flexibility in modeling memory effects.", "conclusion": "The proposed framework offers a versatile and efficient approach to modeling complex systems with non-local and memory effects using FDEs."}}
{"id": "2505.23658", "pdf": "https://arxiv.org/pdf/2505.23658", "abs": "https://arxiv.org/abs/2505.23658", "authors": ["Haim Kaplan", "Yishay Mansour", "Kobbi Nissim", "Uri Stemmer"], "title": "Bayesian Perspective on Memorization and Reconstruction", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "We introduce a new Bayesian perspective on the concept of data\nreconstruction, and leverage this viewpoint to propose a new security\ndefinition that, in certain settings, provably prevents reconstruction attacks.\nWe use our paradigm to shed new light on one of the most notorious attacks in\nthe privacy and memorization literature - fingerprinting code attacks (FPC). We\nargue that these attacks are really a form of membership inference attacks,\nrather than reconstruction attacks. Furthermore, we show that if the goal is\nsolely to prevent reconstruction (but not membership inference), then in some\ncases the impossibility results derived from FPC no longer apply.", "AI": {"tldr": "A Bayesian perspective on data reconstruction leads to a new security definition, reframing fingerprinting code attacks as membership inference attacks and showing reconstruction prevention is possible in some cases.", "motivation": "To redefine data reconstruction security and clarify the nature of fingerprinting code attacks.", "method": "Proposes a Bayesian framework for data reconstruction and analyzes fingerprinting code attacks under this lens.", "result": "Fingerprinting code attacks are identified as membership inference attacks, and reconstruction prevention is achievable in certain scenarios.", "conclusion": "The study provides a new security definition and reinterprets attacks, showing reconstruction prevention is feasible in some contexts."}}
{"id": "2503.10452", "pdf": "https://arxiv.org/pdf/2503.10452", "abs": "https://arxiv.org/abs/2503.10452", "authors": ["Wenhao Hu", "Jinhao Duan", "Chunchen Wei", "Li Zhang", "Yue Zhang", "Kaidi Xu"], "title": "DynaCode: A Dynamic Complexity-Aware Code Benchmark for Evaluating Large Language Models in Code Generation", "categories": ["cs.CL", "cs.AI"], "comment": "18 pages, 13 figures. Accepted to the ACL 2025 Findings", "summary": "The rapid advancement of large language models (LLMs) has significantly\nimproved their performance in code generation tasks. However, existing code\nbenchmarks remain static, consisting of fixed datasets with predefined\nproblems. This makes them vulnerable to memorization during training, where\nLLMs recall specific test cases instead of generalizing to new problems,\nleading to data contamination and unreliable evaluation results. To address\nthese issues, we introduce DynaCode, a dynamic, complexity-aware benchmark that\novercomes the limitations of static datasets. DynaCode evaluates LLMs\nsystematically using a complexity-aware metric, incorporating both code\ncomplexity and call-graph structures. DynaCode achieves large-scale diversity,\ngenerating up to 189 million unique nested code problems across four distinct\nlevels of code complexity, referred to as units, and 16 types of call graphs.\nResults on 12 latest LLMs show an average performance drop of 16.8% to 45.7%\ncompared to MBPP+, a static code generation benchmark, with performance\nprogressively decreasing as complexity increases. This demonstrates DynaCode's\nability to effectively differentiate LLMs. Additionally, by leveraging call\ngraphs, we gain insights into LLM behavior, particularly their preference for\nhandling subfunction interactions within nested code. Our benchmark and\nevaluation code are available at https://github.com/HWH-2000/DynaCode.", "AI": {"tldr": "DynaCode is a dynamic, complexity-aware benchmark for evaluating LLMs in code generation, addressing memorization and data contamination issues in static benchmarks.", "motivation": "Static code benchmarks are vulnerable to memorization and fail to generalize, leading to unreliable evaluations of LLMs.", "method": "DynaCode introduces a dynamic benchmark with complexity-aware metrics, including code complexity and call-graph structures, generating diverse problems.", "result": "Tests on 12 LLMs show performance drops of 16.8% to 45.7% compared to static benchmarks, with degradation as complexity increases.", "conclusion": "DynaCode effectively differentiates LLMs and provides insights into their behavior, particularly in handling nested code and subfunction interactions."}}
{"id": "2503.22622", "pdf": "https://arxiv.org/pdf/2503.22622", "abs": "https://arxiv.org/abs/2503.22622", "authors": ["Jangho Park", "Taesung Kwon", "Jong Chul Ye"], "title": "Zero4D: Training-Free 4D Video Generation From Single Video Using Off-the-Shelf Video Diffusion", "categories": ["cs.CV"], "comment": "project page: https://zero4dvid.github.io/", "summary": "Recently, multi-view or 4D video generation has emerged as a significant\nresearch topic. Nonetheless, recent approaches to 4D generation still struggle\nwith fundamental limitations, as they primarily rely on harnessing multiple\nvideo diffusion models with additional training or compute-intensive training\nof a full 4D diffusion model with limited real-world 4D data and large\ncomputational costs. To address these challenges, here we propose the first\ntraining-free 4D video generation method that leverages the off-the-shelf video\ndiffusion models to generate multi-view videos from a single input video. Our\napproach consists of two key steps: (1) By designating the edge frames in the\nspatio-temporal sampling grid as key frames, we first synthesize them using a\nvideo diffusion model, leveraging a depth-based warping technique for guidance.\nThis approach ensures structural consistency across the generated frames,\npreserving spatial and temporal coherence. (2) We then interpolate the\nremaining frames using a video diffusion model, constructing a fully populated\nand temporally coherent sampling grid while preserving spatial and temporal\nconsistency. Through this approach, we extend a single video into a multi-view\nvideo along novel camera trajectories while maintaining spatio-temporal\nconsistency. Our method is training-free and fully utilizes an off-the-shelf\nvideo diffusion model, offering a practical and effective solution for\nmulti-view video generation.", "AI": {"tldr": "A training-free method for 4D video generation using off-the-shelf video diffusion models to create multi-view videos from a single input, ensuring spatio-temporal consistency.", "motivation": "Addressing limitations in current 4D video generation methods, which rely on costly training or multiple models, by proposing a practical, training-free solution.", "method": "1) Synthesize key frames using a video diffusion model with depth-based warping for guidance. 2) Interpolate remaining frames to ensure full spatio-temporal coherence.", "result": "Generates multi-view videos from a single input while maintaining structural and temporal consistency without additional training.", "conclusion": "The method offers an efficient, training-free approach for 4D video generation, leveraging existing models to overcome computational and data limitations."}}
{"id": "2412.07951", "pdf": "https://arxiv.org/pdf/2412.07951", "abs": "https://arxiv.org/abs/2412.07951", "authors": ["Mohit Chandra", "Suchismita Naik", "Denae Ford", "Ebele Okoli", "Munmun De Choudhury", "Mahsa Ershadi", "Gonzalo Ramos", "Javier Hernandez", "Ananya Bhattacharjee", "Shahed Warreth", "Jina Suh"], "title": "From Lived Experience to Insight: Unpacking the Psychological Risks of Using AI Conversational Agents", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "31 pages, 6 figures, 8 tables; Accepted at ACM FAccT 2025", "summary": "Recent gains in popularity of AI conversational agents have led to their\nincreased use for improving productivity and supporting well-being. While\nprevious research has aimed to understand the risks associated with\ninteractions with AI conversational agents, these studies often fall short in\ncapturing the lived experiences of individuals. Additionally, psychological\nrisks have often been presented as a sub-category within broader AI-related\nrisks in past taxonomy works, leading to under-representation of the impact of\npsychological risks of AI use. To address these challenges, our work presents a\nnovel risk taxonomy focusing on psychological risks of using AI gathered\nthrough the lived experiences of individuals. We employed a mixed-method\napproach, involving a comprehensive survey with 283 people with lived mental\nhealth experience and workshops involving experts with lived experience to\ndevelop a psychological risk taxonomy. Our taxonomy features 19 AI behaviors,\n21 negative psychological impacts, and 15 contexts related to individuals.\nAdditionally, we propose a novel multi-path vignette-based framework for\nunderstanding the complex interplay between AI behaviors, psychological\nimpacts, and individual user contexts. Finally, based on the feedback obtained\nfrom the workshop sessions, we present design recommendations for developing\nsafer and more robust AI agents. Our work offers an in-depth understanding of\nthe psychological risks associated with AI conversational agents and provides\nactionable recommendations for policymakers, researchers, and developers.", "AI": {"tldr": "The paper introduces a novel taxonomy for psychological risks of AI conversational agents, based on lived experiences, and proposes a framework and design recommendations.", "motivation": "To address gaps in understanding psychological risks of AI use, which are often underrepresented in existing research.", "method": "Mixed-method approach: survey with 283 people and expert workshops to develop a psychological risk taxonomy.", "result": "Taxonomy includes 19 AI behaviors, 21 negative impacts, and 15 user contexts, plus a vignette-based framework.", "conclusion": "Provides insights into psychological risks of AI and actionable recommendations for safer AI development."}}
{"id": "2505.23737", "pdf": "https://arxiv.org/pdf/2505.23737", "abs": "https://arxiv.org/abs/2505.23737", "authors": ["Wei Shen", "Ruichuan Huang", "Minhui Huang", "Cong Shen", "Jiawei Zhang"], "title": "On the Convergence Analysis of Muon", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT", "math.OC"], "comment": null, "summary": "The majority of parameters in neural networks are naturally represented as\nmatrices. However, most commonly used optimizers treat these matrix parameters\nas flattened vectors during optimization, potentially overlooking their\ninherent structural properties. Recently, an optimizer called Muon has been\nproposed, specifically designed to optimize matrix-structured parameters.\nExtensive empirical evidence shows that Muon can significantly outperform\ntraditional optimizers when training neural networks. Nonetheless, the\ntheoretical understanding of Muon's convergence behavior and the reasons behind\nits superior performance remain limited. In this work, we present a\ncomprehensive convergence rate analysis of Muon and its comparison with\nGradient Descent (GD). We further characterize the conditions under which Muon\ncan outperform GD. Our theoretical results reveal that Muon can benefit from\nthe low-rank and approximate blockwise diagonal structure of Hessian matrices\n-- phenomena widely observed in practical neural network training. Our\nexperimental results support and corroborate the theoretical findings.", "AI": {"tldr": "Muon, a matrix-structured optimizer, outperforms traditional optimizers in neural network training. This paper analyzes its convergence and conditions for superiority over Gradient Descent, linking its success to low-rank and blockwise diagonal Hessian structures.", "motivation": "Traditional optimizers treat matrix parameters as vectors, ignoring their structure. Muon addresses this gap, but its theoretical foundations and performance reasons are unclear.", "method": "The paper conducts a convergence rate analysis of Muon and compares it with Gradient Descent (GD), identifying conditions for Muon's superiority.", "result": "Muon excels due to low-rank and blockwise diagonal Hessian structures, common in neural networks. Experiments validate these findings.", "conclusion": "Muon's structured approach leverages Hessian properties for better performance, providing theoretical and empirical support for its use in neural network optimization."}}
{"id": "2503.10674", "pdf": "https://arxiv.org/pdf/2503.10674", "abs": "https://arxiv.org/abs/2503.10674", "authors": ["Shafiuddin Rehan Ahmed", "Ankit Parag Shah", "Quan Hung Tran", "Vivek Khetan", "Sukryool Kang", "Ankit Mehta", "Yujia Bao", "Wei Wei"], "title": "Enhancing Retrieval for ESGLLM via ESG-CID -- A Disclosure Content Index Finetuning Dataset for Mapping GRI and ESRS", "categories": ["cs.CL", "cs.AI"], "comment": "Long paper", "summary": "Climate change has intensified the need for transparency and accountability\nin organizational practices, making Environmental, Social, and Governance (ESG)\nreporting increasingly crucial. Frameworks like the Global Reporting Initiative\n(GRI) and the new European Sustainability Reporting Standards (ESRS) aim to\nstandardize ESG reporting, yet generating comprehensive reports remains\nchallenging due to the considerable length of ESG documents and variability in\ncompany reporting styles. To facilitate ESG report automation,\nRetrieval-Augmented Generation (RAG) systems can be employed, but their\ndevelopment is hindered by a lack of labeled data suitable for training\nretrieval models. In this paper, we leverage an underutilized source of weak\nsupervision -- the disclosure content index found in past ESG reports -- to\ncreate a comprehensive dataset, ESG-CID, for both GRI and ESRS standards. By\nextracting mappings between specific disclosure requirements and corresponding\nreport sections, and refining them using a Large Language Model as a judge, we\ngenerate a robust training and evaluation set. We benchmark popular embedding\nmodels on this dataset and show that fine-tuning BERT-based models can\noutperform commercial embeddings and leading public models, even under temporal\ndata splits for cross-report style transfer from GRI to ESRS. Data:\nhttps://huggingface.co/datasets/airefinery/esg_cid_retrieval", "AI": {"tldr": "The paper introduces ESG-CID, a dataset for ESG report automation, using weak supervision from past ESG reports and LLM refinement to improve retrieval models.", "motivation": "Climate change necessitates better ESG reporting, but current frameworks like GRI and ESRS lack standardized automation due to data variability and length.", "method": "Leverages disclosure content indexes from ESG reports, refines mappings with an LLM, and benchmarks embedding models, including fine-tuned BERT.", "result": "Fine-tuned BERT outperforms commercial and public models, even in cross-report style transfer (GRI to ESRS).", "conclusion": "ESG-CID enables robust ESG report automation, with fine-tuned models offering superior performance."}}
{"id": "2503.22869", "pdf": "https://arxiv.org/pdf/2503.22869", "abs": "https://arxiv.org/abs/2503.22869", "authors": ["Alexey Gavryushin", "Alexandros Delitzas", "Luc Van Gool", "Marc Pollefeys", "Kaichun Mo", "Xi Wang"], "title": "SIGHT: Synthesizing Image-Text Conditioned and Geometry-Guided 3D Hand-Object Trajectories", "categories": ["cs.CV"], "comment": null, "summary": "When humans grasp an object, they naturally form trajectories in their minds\nto manipulate it for specific tasks. Modeling hand-object interaction priors\nholds significant potential to advance robotic and embodied AI systems in\nlearning to operate effectively within the physical world. We introduce SIGHT,\na novel task focused on generating realistic and physically plausible 3D\nhand-object interaction trajectories from a single image and a brief\nlanguage-based task description. Prior work on hand-object trajectory\ngeneration typically relies on textual input that lacks explicit grounding to\nthe target object, or assumes access to 3D object meshes, which are often\nconsiderably more difficult to obtain than 2D images. We propose SIGHT-Fusion,\na novel diffusion-based image-text conditioned generative model that tackles\nthis task by retrieving the most similar 3D object mesh from a database and\nenforcing geometric hand-object interaction constraints via a novel\ninference-time diffusion guidance. We benchmark our model on the HOI4D and H2O\ndatasets, adapting relevant baselines for this novel task. Experiments\ndemonstrate our superior performance in the diversity and quality of generated\ntrajectories, as well as in hand-object interaction geometry metrics.", "AI": {"tldr": "SIGHT introduces a task for generating realistic 3D hand-object interaction trajectories from a single image and language description, outperforming prior methods.", "motivation": "Advancing robotic and AI systems by modeling hand-object interaction priors for effective physical world operation.", "method": "SIGHT-Fusion, a diffusion-based model, retrieves similar 3D meshes and enforces geometric constraints via diffusion guidance.", "result": "Superior performance in trajectory diversity, quality, and hand-object interaction metrics on HOI4D and H2O datasets.", "conclusion": "SIGHT-Fusion effectively generates plausible hand-object trajectories, addressing limitations of prior work."}}
{"id": "2412.17333", "pdf": "https://arxiv.org/pdf/2412.17333", "abs": "https://arxiv.org/abs/2412.17333", "authors": ["Jaeheun Jung", "Jaehyuk Lee", "Changhae Jung", "Hanyoung Kim", "Bosung Jung", "Donghun Lee"], "title": "Broadband Ground Motion Synthesis by Diffusion Model with Minimal Condition", "categories": ["cs.LG", "cs.AI", "physics.geo-ph"], "comment": "Accepted to ICML 2025", "summary": "Shock waves caused by earthquakes can be devastating. Generating realistic\nearthquake-caused ground motion waveforms help reducing losses in lives and\nproperties, yet generative models for the task tend to generate subpar\nwaveforms. We present High-fidelity Earthquake Groundmotion Generation System\n(HEGGS) and demonstrate its superior performance using earthquakes from North\nAmerican, East Asian, and European regions. HEGGS exploits the intrinsic\ncharacteristics of earthquake dataset and learns the waveforms using an\nend-to-end differentiable generator containing conditional latent diffusion\nmodel and hi-fidelity waveform construction model. We show the learning\nefficiency of HEGGS by training it on a single GPU machine and validate its\nperformance using earthquake databases from North America, East Asia, and\nEurope, using diverse criteria from waveform generation tasks and seismology.\nOnce trained, HEGGS can generate three dimensional E-N-Z seismic waveforms with\naccurate P/S phase arrivals, envelope correlation, signal-to-noise ratio, GMPE\nanalysis, frequency content analysis, and section plot analysis.", "AI": {"tldr": "HEGGS is a high-fidelity earthquake ground motion generation system that outperforms existing models by leveraging a conditional latent diffusion model and waveform construction, validated across multiple regions.", "motivation": "To reduce losses from earthquakes by generating realistic ground motion waveforms, addressing the limitations of current generative models.", "method": "HEGGS uses an end-to-end differentiable generator with a conditional latent diffusion model and hi-fidelity waveform construction, trained efficiently on a single GPU.", "result": "HEGGS generates accurate 3D seismic waveforms with precise phase arrivals, envelope correlation, and other seismological criteria, validated across North America, East Asia, and Europe.", "conclusion": "HEGGS demonstrates superior performance in generating realistic earthquake waveforms, offering potential for improved disaster preparedness and mitigation."}}
{"id": "2301.08028", "pdf": "https://arxiv.org/pdf/2301.08028", "abs": "https://arxiv.org/abs/2301.08028", "authors": ["Jacob Beck", "Risto Vuorio", "Evan Zheran Liu", "Zheng Xiong", "Luisa Zintgraf", "Chelsea Finn", "Shimon Whiteson"], "title": "A Tutorial on Meta-Reinforcement Learning", "categories": ["cs.LG"], "comment": "Published in Foundations and Trends in Machine Learning as \"A\n  Tutorial on Meta-Reinforcement Learning\". For the earlier version titled \"A\n  Survey of Meta-Reinforcement Learning\", see v3 in the submission history at\n  arXiv:2301.08028v3", "summary": "While deep reinforcement learning (RL) has fueled multiple high-profile\nsuccesses in machine learning, it is held back from more widespread adoption by\nits often poor data efficiency and the limited generality of the policies it\nproduces. A promising approach for alleviating these limitations is to cast the\ndevelopment of better RL algorithms as a machine learning problem itself in a\nprocess called meta-RL. Meta-RL is most commonly studied in a problem setting\nwhere, given a distribution of tasks, the goal is to learn a policy that is\ncapable of adapting to any new task from the task distribution with as little\ndata as possible. In this survey, we describe the meta-RL problem setting in\ndetail as well as its major variations. We discuss how, at a high level,\nmeta-RL research can be clustered based on the presence of a task distribution\nand the learning budget available for each individual task. Using these\nclusters, we then survey meta-RL algorithms and applications. We conclude by\npresenting the open problems on the path to making meta-RL part of the standard\ntoolbox for a deep RL practitioner.", "AI": {"tldr": "Meta-RL aims to improve data efficiency and policy generality in deep RL by learning adaptable policies across task distributions. This survey outlines the problem setting, variations, and clusters of meta-RL research, along with algorithms, applications, and open challenges.", "motivation": "Deep RL's poor data efficiency and limited policy generality hinder widespread adoption. Meta-RL addresses these issues by treating RL algorithm improvement as a learning problem.", "method": "Meta-RL involves learning policies adaptable to new tasks from a distribution with minimal data. The survey categorizes research based on task distribution presence and learning budget.", "result": "The survey provides a detailed overview of meta-RL, including its variations, algorithms, and applications, highlighting its potential to enhance deep RL.", "conclusion": "Meta-RL shows promise for advancing deep RL, but open challenges remain before it becomes a standard tool for practitioners."}}
{"id": "2503.12941", "pdf": "https://arxiv.org/pdf/2503.12941", "abs": "https://arxiv.org/abs/2503.12941", "authors": ["Haiyang Guo", "Fanhu Zeng", "Ziwei Xiang", "Fei Zhu", "Da-Han Wang", "Xu-Yao Zhang", "Cheng-Lin Liu"], "title": "HiDe-LLaVA: Hierarchical Decoupling for Continual Instruction Tuning of Multimodal Large Language Model", "categories": ["cs.CL", "cs.LG"], "comment": "ACL 2025 (Main)", "summary": "Instruction tuning is widely used to improve a pre-trained Multimodal Large\nLanguage Model (MLLM) by training it on curated task-specific datasets,\nenabling better comprehension of human instructions. However, it is infeasible\nto collect all possible instruction datasets simultaneously in real-world\nscenarios. Thus, enabling MLLM with continual instruction tuning is essential\nfor maintaining their adaptability. However, existing methods often trade off\nmemory efficiency for performance gains, significantly compromising overall\nefficiency. In this paper, we propose a task-specific expansion and\ntask-general fusion framework based on the variations in Centered Kernel\nAlignment (CKA) similarity across different model layers when trained on\ndiverse datasets. Furthermore, we analyze the information leakage present in\nthe existing benchmark and propose a new and more challenging benchmark to\nrationally evaluate the performance of different methods. Comprehensive\nexperiments showcase a significant performance improvement of our method\ncompared to existing state-of-the-art methods. Code and dataset are released at\nhttps://github.com/Ghy0501/HiDe-LLaVA.", "AI": {"tldr": "The paper proposes a framework for continual instruction tuning in MLLMs, addressing memory efficiency and performance trade-offs, and introduces a new benchmark for evaluation.", "motivation": "Existing methods for continual instruction tuning in MLLMs compromise efficiency for performance, and current benchmarks lack rigor.", "method": "A task-specific expansion and task-general fusion framework based on CKA similarity variations across model layers, with a new benchmark to evaluate performance.", "result": "Significant performance improvement over state-of-the-art methods, validated through comprehensive experiments.", "conclusion": "The proposed framework enhances MLLM adaptability efficiently, and the new benchmark provides a more rigorous evaluation standard."}}
{"id": "2503.23509", "pdf": "https://arxiv.org/pdf/2503.23509", "abs": "https://arxiv.org/abs/2503.23509", "authors": ["Tianming Liang", "Haichao Jiang", "Wei-Shi Zheng", "Jian-Fang Hu"], "title": "ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025", "categories": ["cs.CV"], "comment": null, "summary": "Referring Video Object Segmentation (RVOS) aims to segment target objects\nthroughout a video based on a text description. This task has attracted\nincreasing attention in the field of computer vision due to its promising\napplications in video editing and human-agent interaction. Recently, ReferDINO\nhas demonstrated promising performance in this task by adapting object-level\nvision-language knowledge from pretrained foundational image models. In this\nreport, we further enhance its capabilities by incorporating the advantages of\nSAM2 in mask quality and object consistency. In addition, to effectively\nbalance performance between single-object and multi-object scenarios, we\nintroduce a conditional mask fusion strategy that adaptively fuses the masks\nfrom ReferDINO and SAM2. Our solution, termed ReferDINO-Plus, achieves 60.43\n\\(\\mathcal{J}\\&\\mathcal{F}\\) on MeViS test set, securing 2nd place in the MeViS\nPVUW challenge at CVPR 2025. The code is available at:\nhttps://github.com/iSEE-Laboratory/ReferDINO-Plus.", "AI": {"tldr": "ReferDINO-Plus enhances RVOS by integrating SAM2 for better mask quality and object consistency, using a conditional mask fusion strategy, achieving 60.43 on MeViS.", "motivation": "Improving RVOS performance for applications in video editing and human-agent interaction by leveraging foundational models.", "method": "Incorporates SAM2 for mask quality and introduces a conditional mask fusion strategy to balance single and multi-object scenarios.", "result": "Achieves 60.43 on MeViS test set, securing 2nd place in the CVPR 2025 challenge.", "conclusion": "ReferDINO-Plus demonstrates enhanced performance in RVOS by combining ReferDINO and SAM2 effectively."}}
{"id": "2501.09620", "pdf": "https://arxiv.org/pdf/2501.09620", "abs": "https://arxiv.org/abs/2501.09620", "authors": ["Chaoqi Wang", "Zhuokai Zhao", "Yibo Jiang", "Zhaorun Chen", "Chen Zhu", "Yuxin Chen", "Jiayi Liu", "Lizhu Zhang", "Xiangjun Fan", "Hao Ma", "Sinong Wang"], "title": "Beyond Reward Hacking: Causal Rewards for Large Language Model Alignment", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have demonstrated significant\nprogress in performing complex tasks. While Reinforcement Learning from Human\nFeedback (RLHF) has been effective in aligning LLMs with human preferences, it\nis susceptible to spurious correlations in reward modeling. Consequently, it\noften introduces biases-such as length bias, sycophancy, conceptual bias, and\ndiscrimination-that hinder the model's ability to capture true causal\nrelationships. To address this, we propose a novel causal reward modeling\napproach that integrates causality to mitigate these spurious correlations. Our\nmethod enforces counterfactual invariance, ensuring reward predictions remain\nconsistent when irrelevant variables are altered. Through experiments on both\nsynthetic and real-world datasets, we show that our approach mitigates various\ntypes of spurious correlations effectively, resulting in more reliable and fair\nalignment of LLMs with human preferences. As a drop-in enhancement to the\nexisting RLHF workflow, our causal reward modeling provides a practical way to\nimprove the trustworthiness and fairness of LLM finetuning.", "AI": {"tldr": "Proposes causal reward modeling to mitigate spurious correlations in RLHF, improving LLM alignment with human preferences.", "motivation": "RLHF introduces biases (e.g., length bias, sycophancy) due to spurious correlations, hindering true causal relationships.", "method": "Integrates causality into reward modeling, enforcing counterfactual invariance to ensure consistent predictions.", "result": "Effectively mitigates spurious correlations in synthetic and real-world datasets, enhancing reliability and fairness.", "conclusion": "Causal reward modeling is a practical drop-in enhancement for RLHF, improving LLM trustworthiness and fairness."}}
{"id": "2302.04363", "pdf": "https://arxiv.org/pdf/2302.04363", "abs": "https://arxiv.org/abs/2302.04363", "authors": ["S. Abdurakhmanova", "Y. SarcheshmehPour", "A. Jung"], "title": "Plug In and Learn: Federated Intelligence over a Smart Grid of Models", "categories": ["cs.LG", "I.5.3; C.2.4; I.5.2"], "comment": null, "summary": "We present a model-agnostic federated learning method that mirrors the\noperation of a smart power grid: diverse local models, like energy prosumers,\ntrain independently on their own data while exchanging lightweight signals to\ncoordinate with statistically similar peers. This coordination is governed by a\ngraph-based regularizer that encourages connected models to produce similar\npredictions on a shared, public unlabeled dataset. The resulting method is a\nflexible instance of regularized empirical risk minimization and supports a\nwide variety of local models - both parametric and non-parametric - provided\nthey can be trained via regularized loss minimization. Such training is readily\nsupported by standard ML libraries including scikit-learn, Keras, and PyTorch.", "AI": {"tldr": "A federated learning method mimics a smart power grid, using lightweight signals and graph-based regularization to coordinate diverse local models.", "motivation": "To enable flexible federated learning with diverse local models while ensuring coordination via lightweight signals.", "method": "Uses a graph-based regularizer to encourage similar predictions among connected models on shared unlabeled data, supporting various local models.", "result": "The method is model-agnostic, works with standard ML libraries, and supports both parametric and non-parametric models.", "conclusion": "The approach provides a flexible and practical solution for federated learning with diverse local models."}}
{"id": "2503.16561", "pdf": "https://arxiv.org/pdf/2503.16561", "abs": "https://arxiv.org/abs/2503.16561", "authors": ["Ibrahim Al Azher", "Miftahul Jannat Mokarrama", "Zhishuai Guo", "Sagnik Ray Choudhury", "Hamed Alhoori"], "title": "FutureGen: LLM-RAG Approach to Generate the Future Work of Scientific Article", "categories": ["cs.CL", "cs.LG"], "comment": "19 pages, 5 figures", "summary": "The future work section of a scientific article outlines potential research\ndirections by identifying gaps and limitations of a current study. This section\nserves as a valuable resource for early-career researchers seeking unexplored\nareas and experienced researchers looking for new projects or collaborations.\nIn this study, we generate future work suggestions from key sections of a\nscientific article alongside related papers and analyze how the trends have\nevolved. We experimented with various Large Language Models (LLMs) and\nintegrated Retrieval-Augmented Generation (RAG) to enhance the generation\nprocess. We incorporate a LLM feedback mechanism to improve the quality of the\ngenerated content and propose an LLM-as-a-judge approach for evaluation. Our\nresults demonstrated that the RAG-based approach with LLM feedback outperforms\nother methods evaluated through qualitative and quantitative metrics. Moreover,\nwe conduct a human evaluation to assess the LLM as an extractor and judge. The\ncode and dataset for this project are here, code: HuggingFace", "AI": {"tldr": "The paper proposes a method to generate future work suggestions from scientific articles using LLMs and RAG, with a feedback mechanism for quality improvement. It outperforms other methods and includes human evaluation.", "motivation": "To assist researchers in identifying unexplored areas and new projects by automating future work suggestions from scientific articles.", "method": "Uses Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) with a feedback mechanism and LLM-as-a-judge for evaluation.", "result": "The RAG-based approach with LLM feedback outperforms other methods, validated by qualitative, quantitative, and human evaluations.", "conclusion": "The proposed method effectively generates high-quality future work suggestions, aiding researchers in exploring new directions."}}
{"id": "2503.24129", "pdf": "https://arxiv.org/pdf/2503.24129", "abs": "https://arxiv.org/abs/2503.24129", "authors": ["Dominik Schnaus", "Nikita Araslanov", "Daniel Cremers"], "title": "It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted to CVPR 2025, Project page:\n  https://dominik-schnaus.github.io/itsamatch/", "summary": "The platonic representation hypothesis suggests that vision and language\nembeddings become more homogeneous as model and dataset sizes increase. In\nparticular, pairwise distances within each modality become more similar. This\nsuggests that as foundation models mature, it may become possible to match\nvision and language embeddings in a fully unsupervised fashion, i.e. without\nparallel data. We present the first feasibility study, and investigate\nconformity of existing vision and language foundation models in the context of\nunsupervised, or \"blind\", matching. First, we formulate unsupervised matching\nas a quadratic assignment problem and introduce a novel heuristic that\noutperforms previous solvers. We also develop a technique to find optimal\nmatching problems, for which a non-trivial match is very likely. Second, we\nconduct an extensive study deploying a range of vision and language models on\nfour datasets. Our analysis reveals that for many problem instances, vision and\nlanguage representations can be indeed matched without supervision. This\nfinding opens up the exciting possibility of embedding semantic knowledge into\nother modalities virtually annotation-free. As a proof of concept, we showcase\nan unsupervised classifier, which achieves non-trivial classification accuracy\nwithout any image-text annotation.", "AI": {"tldr": "The paper explores unsupervised matching of vision and language embeddings, showing feasibility and proposing a novel heuristic for solving the problem.", "motivation": "To investigate if vision and language embeddings can be matched without parallel data, leveraging the platonic representation hypothesis.", "method": "Formulates unsupervised matching as a quadratic assignment problem, introduces a heuristic solver, and tests it on various models and datasets.", "result": "Demonstrates that unsupervised matching is feasible for many problem instances, with a proof-of-concept classifier achieving non-trivial accuracy.", "conclusion": "Unsupervised matching of vision and language embeddings is possible, enabling annotation-free semantic knowledge embedding."}}
{"id": "2501.18887", "pdf": "https://arxiv.org/pdf/2501.18887", "abs": "https://arxiv.org/abs/2501.18887", "authors": ["Shichang Zhang", "Tessa Han", "Usha Bhalla", "Himabindu Lakkaraju"], "title": "Towards Unified Attribution in Explainable AI, Data-Centric AI, and Mechanistic Interpretability", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The increasing complexity of AI systems has made understanding their behavior\ncritical. Numerous interpretability methods have been developed to attribute\nmodel behavior to three key aspects: input features, training data, and\ninternal model components, which emerged from explainable AI, data-centric AI,\nand mechanistic interpretability, respectively. However, these attribution\nmethods are studied and applied rather independently, resulting in a fragmented\nlandscape of methods and terminology. This position paper argues that feature,\ndata, and component attribution methods share fundamental similarities, and a\nunified view of them benefits both interpretability and broader AI research. To\nthis end, we first analyze popular methods for these three types of\nattributions and present a unified view demonstrating that these seemingly\ndistinct methods employ similar techniques (such as perturbations, gradients,\nand linear approximations) over different aspects and thus differ primarily in\ntheir perspectives rather than techniques. Then, we demonstrate how this\nunified view enhances understanding of existing attribution methods, highlights\nshared concepts and evaluation criteria among these methods, and leads to new\nresearch directions both in interpretability research, by addressing common\nchallenges and facilitating cross-attribution innovation, and in AI more\nbroadly, with applications in model editing, steering, and regulation.", "AI": {"tldr": "The paper proposes a unified view of feature, data, and component attribution methods in AI interpretability, highlighting their shared techniques and benefits for broader research.", "motivation": "The fragmented landscape of interpretability methods and terminology necessitates a unified perspective to enhance understanding and innovation.", "method": "Analyzes popular attribution methods, identifies shared techniques (e.g., perturbations, gradients), and presents a unified framework.", "result": "Demonstrates how the unified view improves understanding, evaluation, and research directions in interpretability and AI.", "conclusion": "A unified approach to attribution methods fosters cross-disciplinary innovation and addresses common challenges in AI interpretability."}}
{"id": "2310.09687", "pdf": "https://arxiv.org/pdf/2310.09687", "abs": "https://arxiv.org/abs/2310.09687", "authors": ["David Liu", "Jackie Baek", "Tina Eliassi-Rad"], "title": "When Collaborative Filtering is not Collaborative: Unfairness of PCA for Recommendations", "categories": ["cs.LG", "cs.CY"], "comment": "Published in FAccT'25", "summary": "We study the fairness of dimensionality reduction methods for\nrecommendations. We focus on the fundamental method of principal component\nanalysis (PCA), which identifies latent components and produces a low-rank\napproximation via the leading components while discarding the trailing\ncomponents. Prior works have defined notions of \"fair PCA\"; however, these\ndefinitions do not answer the following question: why is PCA unfair? We\nidentify two underlying popularity mechanisms that induce item unfairness in\nPCA. The first negatively impacts less popular items because less popular items\nrely on trailing latent components to recover their values. The second\nnegatively impacts highly popular items, since the leading PCA components\nspecialize in individual popular items instead of capturing similarities\nbetween items. To address these issues, we develop a polynomial-time algorithm,\nItem-Weighted PCA, that flexibly up-weights less popular items when optimizing\nfor leading principal components. We theoretically show that PCA, in all cases,\nand Normalized PCA, in cases of block-diagonal matrices, are instances of\nItem-Weighted PCA. We empirically show that there exist datasets for which\nItem-Weighted PCA yields the optimal solution while the baselines do not. In\ncontrast to past dimensionality reduction re-weighting techniques,\nItem-Weighted PCA solves a convex optimization problem and enforces a hard rank\nconstraint. Our evaluations on real-world datasets show that Item-Weighted PCA\nnot only mitigates both unfairness mechanisms, but also produces\nrecommendations that outperform those of PCA baselines.", "AI": {"tldr": "The paper analyzes fairness issues in PCA for recommendations, identifies two unfairness mechanisms, and proposes Item-Weighted PCA to mitigate them, outperforming baselines.", "motivation": "To understand why PCA is unfair in recommendations and address the identified unfairness mechanisms affecting both less and highly popular items.", "method": "Develops Item-Weighted PCA, a polynomial-time algorithm that up-weights less popular items when optimizing principal components, solving a convex problem with a hard rank constraint.", "result": "Item-Weighted PCA mitigates unfairness and outperforms PCA baselines in real-world datasets, sometimes yielding optimal solutions where baselines fail.", "conclusion": "Item-Weighted PCA effectively addresses PCA's unfairness in recommendations and improves performance, offering a flexible and theoretically grounded solution."}}
{"id": "2503.18085", "pdf": "https://arxiv.org/pdf/2503.18085", "abs": "https://arxiv.org/abs/2503.18085", "authors": ["Rochana Chaturvedi", "Peyman Baghershahi", "Sourav Medya", "Barbara Di Eugenio"], "title": "Temporal Relation Extraction in Clinical Texts: A Span-based Graph Transformer Approach", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7; I.2.1; J.3"], "comment": "Introducing a novel method for joint extraction of medical events and\n  temporal relations from free-text, leveraging clinical LPLMs and\n  Heterogeneous Graph Transformers, achieving a 5.5% improvement over the\n  previous state-of-the-art and up to 8.9% on long-range relations", "summary": "Temporal information extraction from unstructured text is essential for\ncontextualizing events and deriving actionable insights, particularly in the\nmedical domain. We address the task of extracting clinical events and their\ntemporal relations using the well-studied I2B2 2012 Temporal Relations\nChallenge corpus. This task is inherently challenging due to complex clinical\nlanguage, long documents, and sparse annotations. We introduce GRAPHTREX, a\nnovel method integrating span-based entity-relation extraction, clinical large\npre-trained language models (LPLMs), and Heterogeneous Graph Transformers (HGT)\nto capture local and global dependencies. Our HGT component facilitates\ninformation propagation across the document through innovative global landmarks\nthat bridge distant entities. Our method improves the state-of-the-art with\n5.5% improvement in the tempeval $F_1$ score over the previous best and up to\n8.9% improvement on long-range relations, which presents a formidable\nchallenge. We further demonstrate generalizability by establishing a strong\nbaseline on the E3C corpus. This work not only advances temporal information\nextraction but also lays the groundwork for improved diagnostic and prognostic\nmodels through enhanced temporal reasoning.", "AI": {"tldr": "GRAPHTREX improves temporal relation extraction in clinical texts using HGT and LPLMs, achieving a 5.5% F1 score boost and 8.9% on long-range relations.", "motivation": "Extracting temporal relations from clinical text is challenging due to complex language and sparse annotations, but crucial for medical insights.", "method": "Integrates span-based extraction, clinical LPLMs, and HGT with global landmarks to capture local and global dependencies.", "result": "5.5% F1 score improvement over prior work, with 8.9% gain on long-range relations; strong baseline on E3C corpus.", "conclusion": "Advances temporal extraction and supports better diagnostic models through enhanced temporal reasoning."}}
{"id": "2504.01396", "pdf": "https://arxiv.org/pdf/2504.01396", "abs": "https://arxiv.org/abs/2504.01396", "authors": ["Zheng Yang", "Ruoxin Chen", "Zhiyuan Yan", "Ke-Yue Zhang", "Xinghe Fu", "Shuang Wu", "Xiujun Shu", "Taiping Yao", "Shouhong Ding", "Xi Li"], "title": "All Patches Matter, More Patches Better: Enhance AI-Generated Image Detection via Panoptic Patch Learning", "categories": ["cs.CV"], "comment": null, "summary": "The exponential growth of AI-generated images (AIGIs) underscores the urgent\nneed for robust and generalizable detection methods. In this paper, we\nestablish two key principles for AIGI detection through systematic analysis:\n(1) All Patches Matter: Unlike conventional image classification where\ndiscriminative features concentrate on object-centric regions, each patch in\nAIGIs inherently contains synthetic artifacts due to the uniform generation\nprocess, suggesting that every patch serves as an important artifact source for\ndetection. (2) More Patches Better: Leveraging distributed artifacts across\nmore patches improves detection robustness by capturing complementary forensic\nevidence and reducing over-reliance on specific patches, thereby enhancing\nrobustness and generalization. However, our counterfactual analysis reveals an\nundesirable phenomenon: naively trained detectors often exhibit a Few-Patch\nBias, discriminating between real and synthetic images based on minority\npatches. We identify Lazy Learner as the root cause: detectors preferentially\nlearn conspicuous artifacts in limited patches while neglecting broader\nartifact distributions. To address this bias, we propose the Panoptic Patch\nLearning (PPL) framework, involving: (1) Random Patch Replacement that randomly\nsubstitutes synthetic patches with real counterparts to compel models to\nidentify artifacts in underutilized regions, encouraging the broader use of\nmore patches; (2) Patch-wise Contrastive Learning that enforces consistent\ndiscriminative capability across all patches, ensuring uniform utilization of\nall patches. Extensive experiments across two different settings on several\nbenchmarks verify the effectiveness of our approach.", "AI": {"tldr": "The paper introduces Panoptic Patch Learning (PPL) to address Few-Patch Bias in AI-generated image detection by leveraging all patches and ensuring uniform artifact utilization.", "motivation": "The rapid rise of AI-generated images necessitates robust detection methods, as current detectors often rely on minority patches due to Lazy Learner bias.", "method": "Proposes PPL with Random Patch Replacement and Patch-wise Contrastive Learning to encourage broader patch usage and uniform artifact detection.", "result": "Experiments on multiple benchmarks confirm PPL's effectiveness in improving detection robustness and generalization.", "conclusion": "PPL successfully mitigates Few-Patch Bias, enhancing AI-generated image detection by utilizing all patches uniformly."}}
{"id": "2502.01310", "pdf": "https://arxiv.org/pdf/2502.01310", "abs": "https://arxiv.org/abs/2502.01310", "authors": ["Roman Tarasov", "Petr Mokrov", "Milena Gazdieva", "Evgeny Burnaev", "Alexander Korotin"], "title": "A Statistical Learning Perspective on Semi-dual Adversarial Neural Optimal Transport Solvers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Neural network-based optimal transport (OT) is a recent and fruitful\ndirection in the generative modeling community. It finds its applications in\nvarious fields such as domain translation, image super-resolution,\ncomputational biology and others. Among the existing OT approaches, of\nconsiderable interest are adversarial minimax solvers based on semi-dual\nformulations of OT problems. While promising, these methods lack theoretical\ninvestigation from a statistical learning perspective. Our work fills this gap\nby establishing upper bounds on the generalization error of an approximate OT\nmap recovered by the minimax quadratic OT solver. Importantly, the bounds we\nderive depend solely on some standard statistical and mathematical properties\nof the considered functional classes (neural nets). While our analysis focuses\non the quadratic OT, we believe that similar bounds could be derived for\ngeneral OT case, paving the promising direction for future research.", "AI": {"tldr": "The paper analyzes the generalization error of neural network-based optimal transport (OT) methods, focusing on adversarial minimax solvers, and provides theoretical bounds for quadratic OT.", "motivation": "To address the lack of theoretical investigation of adversarial minimax OT solvers from a statistical learning perspective.", "method": "Establishes upper bounds on the generalization error of an approximate OT map using minimax quadratic OT solvers.", "result": "Derived bounds depend on standard statistical and mathematical properties of neural networks, suggesting applicability to general OT cases.", "conclusion": "The work fills a theoretical gap and opens a promising direction for future research in OT methods."}}
{"id": "2311.09948", "pdf": "https://arxiv.org/pdf/2311.09948", "abs": "https://arxiv.org/abs/2311.09948", "authors": ["Xiangyu Zhou", "Yao Qiang", "Saleh Zare Zade", "Prashant Khanduri", "Dongxiao Zhu"], "title": "Hijacking Large Language Models via Adversarial In-Context Learning", "categories": ["cs.LG", "cs.CL", "cs.CR"], "comment": null, "summary": "In-context learning (ICL) has emerged as a powerful paradigm leveraging LLMs\nfor specific downstream tasks by utilizing labeled examples as demonstrations\n(demos) in the preconditioned prompts. Despite its promising performance,\ncrafted adversarial attacks pose a notable threat to the robustness of LLMs.\nExisting attacks are either easy to detect, require a trigger in user input, or\nlack specificity towards ICL. To address these issues, this work introduces a\nnovel transferable prompt injection attack against ICL, aiming to hijack LLMs\nto generate the target output or elicit harmful responses. In our threat model,\nthe hacker acts as a model publisher who leverages a gradient-based prompt\nsearch method to learn and append imperceptible adversarial suffixes to the\nin-context demos via prompt injection. We also propose effective defense\nstrategies using a few shots of clean demos, enhancing the robustness of LLMs\nduring ICL. Extensive experimental results across various classification and\njailbreak tasks demonstrate the effectiveness of the proposed attack and\ndefense strategies. This work highlights the significant security\nvulnerabilities of LLMs during ICL and underscores the need for further\nin-depth studies.", "AI": {"tldr": "The paper introduces a transferable prompt injection attack targeting in-context learning (ICL) in LLMs, along with defense strategies to enhance robustness.", "motivation": "Existing adversarial attacks on ICL are either detectable, require triggers, or lack specificity, prompting the need for a more sophisticated attack method.", "method": "A gradient-based prompt search is used to append adversarial suffixes to in-context demos, hijacking LLM outputs. Defense involves using clean demos.", "result": "Experiments show the attack's effectiveness in classification and jailbreak tasks, while the defense improves LLM robustness.", "conclusion": "The study reveals security vulnerabilities in ICL and calls for further research to address them."}}
{"id": "2503.20960", "pdf": "https://arxiv.org/pdf/2503.20960", "abs": "https://arxiv.org/abs/2503.20960", "authors": ["Arnav Arora", "Srishti Yadav", "Maria Antoniak", "Serge Belongie", "Isabelle Augenstein"], "title": "Multi-Modal Framing Analysis of News", "categories": ["cs.CL", "cs.CY", "cs.LG"], "comment": null, "summary": "Automated frame analysis of political communication is a popular task in\ncomputational social science that is used to study how authors select aspects\nof a topic to frame its reception. So far, such studies have been narrow, in\nthat they use a fixed set of pre-defined frames and focus only on the text,\nignoring the visual contexts in which those texts appear. Especially for\nframing in the news, this leaves out valuable information about editorial\nchoices, which include not just the written article but also accompanying\nphotographs. To overcome such limitations, we present a method for conducting\nmulti-modal, multi-label framing analysis at scale using large (vision-)\nlanguage models. Grounding our work in framing theory, we extract latent\nmeaning embedded in images used to convey a certain point and contrast that to\nthe text by comparing the respective frames used. We also identify highly\npartisan framing of topics with issue-specific frame analysis found in prior\nqualitative work. We demonstrate a method for doing scalable integrative\nframing analysis of both text and image in news, providing a more complete\npicture for understanding media bias.", "AI": {"tldr": "A method for multi-modal, multi-label framing analysis using large vision-language models to study political communication, integrating text and images for a more complete media bias analysis.", "motivation": "Existing framing studies are narrow, using pre-defined frames and ignoring visual contexts, missing valuable editorial choices in news.", "method": "Uses large vision-language models to extract latent meaning from images and contrast it with text frames, identifying partisan framing.", "result": "Demonstrates scalable integrative framing analysis of text and images, providing a more comprehensive understanding of media bias.", "conclusion": "The method enhances framing analysis by incorporating visual contexts, offering a more complete picture of media bias in political communication."}}
{"id": "2504.01792", "pdf": "https://arxiv.org/pdf/2504.01792", "abs": "https://arxiv.org/abs/2504.01792", "authors": ["Limeng Qiao", "Yiyang Gan", "Bairui Wang", "Jie Qin", "Shuang Xu", "Siqi Yang", "Lin Ma"], "title": "UniViTAR: Unified Vision Transformer with Native Resolution", "categories": ["cs.CV"], "comment": null, "summary": "Conventional Vision Transformer simplifies visual modeling by standardizing\ninput resolutions, often disregarding the variability of natural visual data\nand compromising spatial-contextual fidelity. While preliminary explorations\nhave superficially investigated native resolution modeling, existing approaches\nstill lack systematic analysis from a visual representation perspective. To\nbridge this gap, we introduce UniViTAR, a family of homogeneous vision\nfoundation models tailored for unified visual modality and native resolution\nscenario in the era of multimodal. Our framework first conducts architectural\nupgrades to the vanilla paradigm by integrating multiple advanced components.\nBuilding upon these improvements, a progressive training paradigm is\nintroduced, which strategically combines two core mechanisms: (1) resolution\ncurriculum learning, transitioning from fixed-resolution pretraining to native\nresolution tuning, thereby leveraging ViT's inherent adaptability to\nvariable-length sequences, and (2) visual modality adaptation via inter-batch\nimage-video switching, which balances computational efficiency with enhanced\ntemporal reasoning. In parallel, a hybrid training framework further synergizes\nsigmoid-based contrastive loss with feature distillation from a frozen teacher\nmodel, thereby accelerating early-stage convergence. Finally, trained\nexclusively on public datasets, externsive experiments across multiple model\nscales from 0.3B to 1B demonstrate its effectiveness.", "AI": {"tldr": "UniViTAR introduces a vision foundation model for unified visual modality and native resolution, improving spatial-contextual fidelity through architectural upgrades and progressive training.", "motivation": "Addresses the limitations of conventional Vision Transformers in handling variable visual data and native resolutions, aiming for systematic visual representation.", "method": "Combines architectural upgrades, resolution curriculum learning, visual modality adaptation, and hybrid training with contrastive loss and feature distillation.", "result": "Demonstrates effectiveness across model scales (0.3B to 1B) trained on public datasets.", "conclusion": "UniViTAR successfully bridges gaps in visual representation and resolution adaptability, offering a robust framework for multimodal scenarios."}}
{"id": "2502.01918", "pdf": "https://arxiv.org/pdf/2502.01918", "abs": "https://arxiv.org/abs/2502.01918", "authors": ["Zachary Cooper-Baldock", "Stephen Turnock", "Karl Sammut"], "title": "Wake-Informed 3D Path Planning for Autonomous Underwater Vehicles Using A* and Neural Network Approximations", "categories": ["cs.RO", "cs.AI", "cs.LG", "68T40, 68T07, 90C35", "I.2.8; I.2.9; I.5.1"], "comment": "11 pages, 6 figures, preprint of journal paper", "summary": "Autonomous Underwater Vehicles (AUVs) encounter significant energy, control\nand navigation challenges in complex underwater environments, particularly\nduring close-proximity operations, such as launch and recovery (LAR), where\nfluid interactions and wake effects present additional navigational and energy\nchallenges. Traditional path planning methods fail to incorporate these\ndetailed wake structures, resulting in increased energy consumption, reduced\ncontrol stability, and heightened safety risks. This paper presents a novel\nwake-informed, 3D path planning approach that fully integrates localized wake\neffects and global currents into the planning algorithm. Two variants of the A*\nalgorithm - a current-informed planner and a wake-informed planner - are\ncreated to assess its validity and two neural network models are then trained\nto approximate these planners for real-time applications. Both the A* planners\nand NN models are evaluated using important metrics such as energy expenditure,\npath length, and encounters with high-velocity and turbulent regions. The\nresults demonstrate a wake-informed A* planner consistently achieves the lowest\nenergy expenditure and minimizes encounters with high-velocity regions,\nreducing energy consumption by up to 11.3%. The neural network models are\nobserved to offer computational speedup of 6 orders of magnitude, but exhibit\n4.51 - 19.79% higher energy expenditures and 9.81 - 24.38% less optimal paths.\nThese findings underscore the importance of incorporating detailed wake\nstructures into traditional path planning algorithms and the benefits of neural\nnetwork approximations to enhance energy efficiency and operational safety for\nAUVs in complex 3D domains.", "AI": {"tldr": "A novel wake-informed 3D path planning method for AUVs reduces energy use by 11.3% and improves safety by minimizing high-velocity encounters, with neural networks speeding up computation but slightly increasing energy costs.", "motivation": "Address energy, control, and navigation challenges in AUVs during close-proximity operations by integrating wake effects and global currents into path planning.", "method": "Develops wake-informed and current-informed A* planners, trains neural networks to approximate them, and evaluates performance using energy, path length, and turbulence metrics.", "result": "Wake-informed A* planner cuts energy use by 11.3%. Neural networks speed up computation but increase energy use by 4.51-19.79% and reduce path optimality by 9.81-24.38%.", "conclusion": "Incorporating wake structures into path planning enhances AUV efficiency and safety, with neural networks offering a trade-off between speed and optimality."}}
{"id": "2401.01879", "pdf": "https://arxiv.org/pdf/2401.01879", "abs": "https://arxiv.org/abs/2401.01879", "authors": ["Ahmad Beirami", "Alekh Agarwal", "Jonathan Berant", "Alexander D'Amour", "Jacob Eisenstein", "Chirag Nagpal", "Ananda Theertha Suresh"], "title": "Theoretical guarantees on the best-of-n alignment policy", "categories": ["cs.LG", "cs.CL", "cs.IT", "math.IT"], "comment": "ICML 2025", "summary": "A simple and effective method for the inference-time alignment and scaling\ntest-time compute of generative models is best-of-$n$ sampling, where $n$\nsamples are drawn from a reference policy, ranked based on a reward function,\nand the highest ranking one is selected. A commonly used analytical expression\nin the literature claims that the KL divergence between the best-of-$n$ policy\nand the reference policy is equal to $\\log (n) - (n-1)/n.$ We disprove the\nvalidity of this claim, and show that it is an upper bound on the actual KL\ndivergence. We also explore the tightness of this upper bound in different\nregimes, and propose a new estimator for the KL divergence and empirically show\nthat it provides a tight approximation. We also show that the win rate of the\nbest-of-$n$ policy against the reference policy is upper bounded by $n/(n+1)$\nand derive bounds on the tightness of this characterization. We conclude with\nanalyzing the tradeoffs between win rate and KL divergence of the best-of-$n$\nalignment policy, which demonstrate that very good tradeoffs are achievable\nwith $n < 1000$.", "AI": {"tldr": "The paper disproves a common analytical claim about KL divergence in best-of-$n$ sampling, shows it's an upper bound, and introduces a tighter estimator. It also bounds the win rate and analyzes tradeoffs between win rate and KL divergence.", "motivation": "To correct misconceptions about KL divergence in best-of-$n$ sampling and explore its practical implications for alignment policies.", "method": "Analyzes the KL divergence claim, proposes a new estimator, and derives bounds on win rate and KL divergence. Empirical validation is provided.", "result": "The common KL divergence claim is an upper bound; a new tight estimator is proposed. Win rate is bounded by $n/(n+1)$, and practical tradeoffs are achievable with $n < 1000$.", "conclusion": "Best-of-$n$ sampling offers effective alignment tradeoffs, with corrected theoretical insights and practical bounds."}}
{"id": "2503.22353", "pdf": "https://arxiv.org/pdf/2503.22353", "abs": "https://arxiv.org/abs/2503.22353", "authors": ["Yubo Li", "Yidi Miao", "Xueying Ding", "Ramayya Krishnan", "Rema Padman"], "title": "Firm or Fickle? Evaluating Large Language Models Consistency in Sequential Interactions", "categories": ["cs.CL", "cs.AI"], "comment": "8 pages, 5 figures", "summary": "Large Language Models (LLMs) have shown remarkable capabilities across\nvarious tasks, but their deployment in high-stake domains requires consistent\nperformance across multiple interaction rounds. This paper introduces a\ncomprehensive framework for evaluating and improving LLM response consistency,\nmaking three key contributions. First, we propose a novel Position-Weighted\nConsistency (PWC) score that captures both the importance of early-stage\nstability and recovery patterns in multi-turn interactions. Second, we present\na carefully curated benchmark dataset spanning diverse domains and difficulty\nlevels, specifically designed to evaluate LLM consistency under various\nchallenging follow-up scenarios. Third, we introduce Confidence-Aware Response\nGeneration (CARG), a framework that significantly improves response stability\nby incorporating model confidence signals into the generation process.\nEmpirical results demonstrate that CARG significantly improves response\nstability without sacrificing accuracy, underscoring its potential for reliable\nLLM deployment in critical applications.", "AI": {"tldr": "The paper introduces a framework to evaluate and improve LLM response consistency, featuring a novel PWC score, a benchmark dataset, and the CARG method, which enhances stability without losing accuracy.", "motivation": "LLMs need consistent performance in high-stake domains, but current evaluations lack focus on multi-turn interaction stability.", "method": "Proposes PWC score for consistency, a benchmark dataset, and CARG framework using confidence signals for stable generation.", "result": "CARG improves response stability without compromising accuracy.", "conclusion": "The framework enhances LLM reliability for critical applications."}}
{"id": "2504.02154", "pdf": "https://arxiv.org/pdf/2504.02154", "abs": "https://arxiv.org/abs/2504.02154", "authors": ["Chao Huang", "Susan Liang", "Yunlong Tang", "Jing Bi", "Li Ma", "Yapeng Tian", "Chenliang Xu"], "title": "FreSca: Scaling in Frequency Space Enhances Diffusion Models", "categories": ["cs.CV"], "comment": "Project page: https://wikichao.github.io/FreSca/", "summary": "Latent diffusion models (LDMs) have achieved remarkable success in a variety\nof image tasks, yet achieving fine-grained, disentangled control over global\nstructures versus fine details remains challenging. This paper explores\nfrequency-based control within latent diffusion models. We first systematically\nanalyze frequency characteristics across pixel space, VAE latent space, and\ninternal LDM representations. This reveals that the \"noise difference\" term,\nderived from classifier-free guidance at each step t, is a uniquely effective\nand semantically rich target for manipulation. Building on this insight, we\nintroduce FreSca, a novel and plug-and-play framework that decomposes noise\ndifference into low- and high-frequency components and applies independent\nscaling factors to them via spatial or energy-based cutoffs. Essentially,\nFreSca operates without any model retraining or architectural change, offering\nmodel- and task-agnostic control. We demonstrate its versatility and\neffectiveness in improving generation quality and structural emphasis on\nmultiple architectures (e.g., SD3, SDXL) and across applications including\nimage generation, editing, depth estimation, and video synthesis, thereby\nunlocking a new dimension of expressive control within LDMs.", "AI": {"tldr": "FreSca introduces a plug-and-play framework for fine-grained control in latent diffusion models by decomposing noise differences into low- and high-frequency components, enabling versatile applications without model retraining.", "motivation": "Achieving disentangled control over global structures and fine details in latent diffusion models remains challenging.", "method": "Analyzes frequency characteristics in LDMs, identifies noise difference as a manipulable target, and introduces FreSca to independently scale low- and high-frequency components.", "result": "FreSca improves generation quality and structural emphasis across tasks like image generation, editing, and video synthesis.", "conclusion": "FreSca unlocks expressive control in LDMs without requiring retraining, offering broad applicability."}}
{"id": "2502.02516", "pdf": "https://arxiv.org/pdf/2502.02516", "abs": "https://arxiv.org/abs/2502.02516", "authors": ["Alessio Russo", "Aldo Pacchiano"], "title": "Adaptive Exploration for Multi-Reward Multi-Policy Evaluation", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at the International Conference on Machine Learning, 2025", "summary": "We study the policy evaluation problem in an online multi-reward multi-policy\ndiscounted setting, where multiple reward functions must be evaluated\nsimultaneously for different policies. We adopt an $(\\epsilon,\\delta)$-PAC\nperspective to achieve $\\epsilon$-accurate estimates with high confidence\nacross finite or convex sets of rewards, a setting that has not been\ninvestigated in the literature. Building on prior work on Multi-Reward Best\nPolicy Identification, we adapt the MR-NaS exploration scheme to jointly\nminimize sample complexity for evaluating different policies across different\nreward sets. Our approach leverages an instance-specific lower bound revealing\nhow the sample complexity scales with a measure of value deviation, guiding the\ndesign of an efficient exploration policy. Although computing this bound\nentails a hard non-convex optimization, we propose an efficient convex\napproximation that holds for both finite and convex reward sets. Experiments in\ntabular domains demonstrate the effectiveness of this adaptive exploration\nscheme.", "AI": {"tldr": "The paper addresses the online multi-reward multi-policy evaluation problem, proposing an efficient exploration scheme to achieve accurate estimates with high confidence.", "motivation": "To simultaneously evaluate multiple reward functions for different policies in a discounted setting, a problem not previously explored in the literature.", "method": "Adapts the MR-NaS exploration scheme to minimize sample complexity, leveraging an instance-specific lower bound and proposing a convex approximation for efficiency.", "result": "Demonstrates effectiveness in tabular domains through experiments.", "conclusion": "The proposed adaptive exploration scheme efficiently evaluates policies across diverse reward sets."}}
{"id": "2401.13330", "pdf": "https://arxiv.org/pdf/2401.13330", "abs": "https://arxiv.org/abs/2401.13330", "authors": ["Matteo Gambella", "Jary Pomponi", "Simone Scardapane", "Manuel Roveri"], "title": "NACHOS: Neural Architecture Search for Hardware Constrained Early Exit Neural Networks", "categories": ["cs.LG", "cs.CV", "68T07"], "comment": "14 pages, 5 figures", "summary": "Early Exit Neural Networks (EENNs) endow astandard Deep Neural Network (DNN)\nwith Early Exit Classifiers (EECs), to provide predictions at intermediate\npoints of the processing when enough confidence in classification is achieved.\nThis leads to many benefits in terms of effectiveness and efficiency.\nCurrently, the design of EENNs is carried out manually by experts, a complex\nand time-consuming task that requires accounting for many aspects, including\nthe correct placement, the thresholding, and the computational overhead of the\nEECs. For this reason, the research is exploring the use of Neural Architecture\nSearch (NAS) to automatize the design of EENNs. Currently, few comprehensive\nNAS solutions for EENNs have been proposed in the literature, and a fully\nautomated, joint design strategy taking into consideration both the backbone\nand the EECs remains an open problem. To this end, this work presents Neural\nArchitecture Search for Hardware Constrained Early Exit Neural Networks\n(NACHOS), the first NAS framework for the design of optimal EENNs satisfying\nconstraints on the accuracy and the number of Multiply and Accumulate (MAC)\noperations performed by the EENNs at inference time. In particular, this\nprovides the joint design of backbone and EECs to select a set of admissible\n(i.e., respecting the constraints) Pareto Optimal Solutions in terms of best\ntradeoff between the accuracy and number of MACs. The results show that the\nmodels designed by NACHOS are competitive with the state-of-the-art EENNs.\nAdditionally, this work investigates the effectiveness of two novel\nregularization terms designed for the optimization of the auxiliary classifiers\nof the EENN", "AI": {"tldr": "NACHOS is a NAS framework for designing optimal Early Exit Neural Networks (EENNs) under hardware constraints, jointly optimizing backbone and EECs for accuracy and computational efficiency.", "motivation": "Manual design of EENNs is complex and time-consuming, lacking comprehensive automated solutions. NACHOS aims to automate this process while meeting accuracy and computational constraints.", "method": "NACHOS uses Neural Architecture Search (NAS) to jointly design backbone and Early Exit Classifiers (EECs), optimizing for Pareto optimal solutions in accuracy and MAC operations. Novel regularization terms are introduced for EEC optimization.", "result": "NACHOS-designed models compete with state-of-the-art EENNs, achieving effective tradeoffs between accuracy and computational efficiency.", "conclusion": "NACHOS successfully automates EENN design, offering competitive performance and addressing the open problem of joint backbone-EEC optimization."}}
{"id": "2504.06560", "pdf": "https://arxiv.org/pdf/2504.06560", "abs": "https://arxiv.org/abs/2504.06560", "authors": ["Lanrui Wang", "Mingyu Zheng", "Hongyin Tang", "Zheng Lin", "Yanan Cao", "Jingang Wang", "Xunliang Cai", "Weiping Wang"], "title": "NeedleInATable: Exploring Long-Context Capability of Large Language Models towards Long-Structured Tables", "categories": ["cs.CL"], "comment": "Work in Progress", "summary": "Processing structured tabular data, particularly large and lengthy tables,\nconstitutes a fundamental yet challenging task for large language models\n(LLMs). However, existing long-context benchmarks like Needle-in-a-Haystack\nprimarily focus on unstructured text, neglecting the challenge of diverse\nstructured tables. Meanwhile, previous tabular benchmarks mainly consider\ndownstream tasks that require high-level reasoning abilities, and overlook\nmodels' underlying fine-grained perception of individual table cells, which is\ncrucial for practical and robust LLM-based table applications. To address this\ngap, we introduce \\textsc{NeedleInATable} (NIAT), a new long-context tabular\nbenchmark that treats each table cell as a ``needle'' and requires models to\nextract the target cell based on cell locations or lookup questions. Our\ncomprehensive evaluation of various LLMs and multimodal LLMs reveals a\nsubstantial performance gap between popular downstream tabular tasks and the\nsimpler NIAT task, suggesting that they may rely on dataset-specific\ncorrelations or shortcuts to obtain better benchmark results but lack truly\nrobust long-context understanding towards structured tables. Furthermore, we\ndemonstrate that using synthesized NIAT training data can effectively improve\nperformance on both NIAT task and downstream tabular tasks, which validates the\nimportance of NIAT capability for LLMs' genuine table understanding ability.\nOur data, code and models will be released to facilitate future research.", "AI": {"tldr": "The paper introduces NIAT, a benchmark for testing LLMs' fine-grained perception of structured tables, revealing gaps in robust table understanding and showing that training with NIAT data improves performance.", "motivation": "Existing benchmarks focus on unstructured text or high-level reasoning for tables, missing the need for fine-grained cell perception in LLMs.", "method": "NIAT treats each table cell as a 'needle' and tests models' ability to extract target cells based on locations or lookup questions.", "result": "Evaluation shows a performance gap between downstream tasks and NIAT, indicating reliance on shortcuts. Training with NIAT data improves both NIAT and downstream task performance.", "conclusion": "NIAT highlights the need for robust table understanding in LLMs and demonstrates the value of fine-grained cell perception for genuine table comprehension."}}
{"id": "2504.07934", "pdf": "https://arxiv.org/pdf/2504.07934", "abs": "https://arxiv.org/abs/2504.07934", "authors": ["Xiyao Wang", "Zhengyuan Yang", "Chao Feng", "Hongjin Lu", "Linjie Li", "Chung-Ching Lin", "Kevin Lin", "Furong Huang", "Lijuan Wang"], "title": "SoTA with Less: MCTS-Guided Sample Selection for Data-Efficient Visual Reasoning Self-Improvement", "categories": ["cs.CV"], "comment": "27 pages, 5 figures", "summary": "We introduce ThinkLite-VL, a family of visual reasoning models that achieve\nstate-of-the-art (SoTA) performance using an order of magnitude fewer training\nsamples, relying purely on reinforcement fine-tuning (RFT) self-improvement\nwithout any knowledge distillation. Our central insight is that sample\ndifficulty critically influences RFT effectiveness: appropriately challenging\nexamples can drive substantial reasoning improvements, even in low-data\nregimes. However, quantifying sample difficulty in a reliable and scalable\nmanner remains non-trivial. To address this, we repurpose Monte Carlo Tree\nSearch (MCTS) to measure sample difficulty via the number of reasoning\niterations a vision-language model (VLM) requires to solve each instance. This\nMCTS-based selection procedure identifies samples that induce deeper reasoning\nwhile remaining solvable, allowing us to filter a high-quality subset from 70k\nopen-source examples spanning math, natural image understanding, and chart\ncomprehension. Using this approach, we select just 11k challenging samples for\nRFT on Qwen2.5-VL-7B-Instruct and 7.5k samples for Qwen2.5-VL-72B-Instruct. The\nresulting models, ThinkLite-VL-7B and ThinkLite-VL-72B, significantly\noutperform their respective base models across eight visual reasoning\nbenchmarks. In particular, ThinkLite-VL-7B improves the average performance of\nQwen2.5-VL-7B-Instruct by 7\\% and surpasses all existing 7B-level models, as\nwell as much larger models such as GPT-4o, O1 and Qwen2.5-VL-72B, achieving a\nnew SoTA score of 75.1 on MathVista. ThinkLite-VL-72B further advances the SoTA\nfrontier, achieving an accuracy of 79.7 on MathVista and an average benchmark\nimprovement of 4.42 over the open-source SOTA. These results demonstrate that\nMCTS-guided difficulty filtering provides a scalable and effective path toward\ndata-efficient self-improvement in multimodal reasoning.", "AI": {"tldr": "ThinkLite-VL models achieve SoTA performance with fewer training samples using reinforcement fine-tuning (RFT) and Monte Carlo Tree Search (MCTS) for sample difficulty filtering.", "motivation": "To improve visual reasoning models efficiently by identifying challenging samples that drive deeper reasoning without needing large datasets or knowledge distillation.", "method": "Uses MCTS to measure sample difficulty, selects high-quality subsets (11k and 7.5k samples) for RFT on Qwen2.5-VL models.", "result": "ThinkLite-VL-7B and ThinkLite-VL-72B outperform base models and larger competitors, achieving new SoTA scores (e.g., 75.1 and 79.7 on MathVista).", "conclusion": "MCTS-guided difficulty filtering enables scalable, data-efficient self-improvement in multimodal reasoning."}}
{"id": "2502.04778", "pdf": "https://arxiv.org/pdf/2502.04778", "abs": "https://arxiv.org/abs/2502.04778", "authors": ["Chen-Xiao Gao", "Chenyang Wu", "Mingjun Cao", "Chenjun Xiao", "Yang Yu", "Zongzhang Zhang"], "title": "Behavior-Regularized Diffusion Policy Optimization for Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICML 2025", "summary": "Behavior regularization, which constrains the policy to stay close to some\nbehavior policy, is widely used in offline reinforcement learning (RL) to\nmanage the risk of hazardous exploitation of unseen actions. Nevertheless,\nexisting literature on behavior-regularized RL primarily focuses on explicit\npolicy parameterizations, such as Gaussian policies. Consequently, it remains\nunclear how to extend this framework to more advanced policy parameterizations,\nsuch as diffusion models. In this paper, we introduce BDPO, a principled\nbehavior-regularized RL framework tailored for diffusion-based policies,\nthereby combining the expressive power of diffusion policies and the robustness\nprovided by regularization. The key ingredient of our method is to calculate\nthe Kullback-Leibler (KL) regularization analytically as the accumulated\ndiscrepancies in reverse-time transition kernels along the diffusion\ntrajectory. By integrating the regularization, we develop an efficient\ntwo-time-scale actor-critic RL algorithm that produces the optimal policy while\nrespecting the behavior constraint. Comprehensive evaluations conducted on\nsynthetic 2D tasks and continuous control tasks from the D4RL benchmark\nvalidate its effectiveness and superior performance.", "AI": {"tldr": "BDPO introduces a behavior-regularized RL framework for diffusion-based policies, combining expressive power and robustness by analytically calculating KL regularization along diffusion trajectories.", "motivation": "Existing behavior-regularized RL methods focus on explicit policy parameterizations, leaving a gap for advanced ones like diffusion models.", "method": "BDPO calculates KL regularization analytically via discrepancies in reverse-time transition kernels and integrates it into a two-time-scale actor-critic algorithm.", "result": "Evaluations on synthetic 2D tasks and D4RL benchmark show BDPO's effectiveness and superior performance.", "conclusion": "BDPO successfully extends behavior regularization to diffusion policies, offering a robust and expressive RL solution."}}
{"id": "2402.13459", "pdf": "https://arxiv.org/pdf/2402.13459", "abs": "https://arxiv.org/abs/2402.13459", "authors": ["Xiangyu Zhou", "Yao Qiang", "Saleh Zare Zade", "Mohammad Amin Roshani", "Prashant Khanduri", "Douglas Zytko", "Dongxiao Zhu"], "title": "Learning to Poison Large Language Models for Downstream Manipulation", "categories": ["cs.LG", "cs.CL", "cs.CR"], "comment": null, "summary": "The advent of Large Language Models (LLMs) has marked significant\nachievements in language processing and reasoning capabilities. Despite their\nadvancements, LLMs face vulnerabilities to data poisoning attacks, where the\nadversary inserts backdoor triggers into training data to manipulate outputs.\nThis work further identifies additional security risks in LLMs by designing a\nnew data poisoning attack tailored to exploit the supervised fine-tuning (SFT)\nprocess. We propose a novel gradient-guided backdoor trigger learning (GBTL)\nalgorithm to identify adversarial triggers efficiently, ensuring an evasion of\ndetection by conventional defenses while maintaining content integrity. Through\nexperimental validation across various language model tasks, including\nsentiment analysis, domain generation, and question answering, our poisoning\nstrategy demonstrates a high success rate in compromising various LLMs'\noutputs. We further propose two defense strategies against data poisoning\nattacks, including in-context learning (ICL) and continuous learning (CL),\nwhich effectively rectify the behavior of LLMs and significantly reduce the\ndecline in performance. Our work highlights the significant security risks\npresent during SFT of LLMs and the necessity of safeguarding LLMs against data\npoisoning attacks.", "AI": {"tldr": "The paper identifies security risks in LLMs during supervised fine-tuning (SFT), proposes a gradient-guided backdoor trigger learning (GBTL) attack, and introduces defense strategies like in-context learning (ICL) and continuous learning (CL).", "motivation": "LLMs are vulnerable to data poisoning attacks during SFT, which can manipulate outputs. This work aims to uncover these risks and propose solutions.", "method": "The authors design a GBTL algorithm to create adversarial triggers and test it on tasks like sentiment analysis and question answering. They also propose ICL and CL as defenses.", "result": "The poisoning attack successfully compromises LLM outputs, while the proposed defenses (ICL and CL) mitigate performance decline.", "conclusion": "The study emphasizes the security risks in SFT for LLMs and the need for robust defenses against data poisoning."}}
{"id": "2504.08120", "pdf": "https://arxiv.org/pdf/2504.08120", "abs": "https://arxiv.org/abs/2504.08120", "authors": ["Daniil Larionov", "Sotaro Takeshita", "Ran Zhang", "Yanran Chen", "Christoph Leiter", "Zhipin Wang", "Christian Greisinger", "Steffen Eger"], "title": "DeepSeek vs. o3-mini: How Well can Reasoning LLMs Evaluate MT and Summarization?", "categories": ["cs.CL"], "comment": null, "summary": "Reasoning-enabled large language models (LLMs) excel in logical tasks, yet\ntheir utility for evaluating natural language generation remains unexplored.\nThis study systematically compares reasoning LLMs with non-reasoning\ncounterparts across machine translation and text summarization evaluation\ntasks. We evaluate eight models spanning state-of-the-art reasoning models\n(DeepSeek-R1, OpenAI o3), their distilled variants (8B-70B parameters), and\nequivalent non-reasoning LLMs. Experiments on WMT23 and SummEval benchmarks\nreveal architecture and task-dependent benefits: OpenAI o3-mini models show\nimproved performance with increased reasoning on MT, while DeepSeek-R1 and\ngenerally underperforms compared to its non-reasoning variant except in\nsummarization consistency evaluation. Correlation analysis demonstrates that\nreasoning token usage correlates with evaluation quality only in specific\nmodels, while almost all models generally allocate more reasoning tokens when\nidentifying more quality issues. Distillation maintains reasonable performance\nup to 32B parameter models but degrades substantially at 8B scale. This work\nprovides the first assessment of reasoning LLMs for NLG evaluation and\ncomparison to non-reasoning models. We share our code to facilitate further\nresearch: https://github.com/NL2G/reasoning-eval.", "AI": {"tldr": "The study evaluates reasoning-enabled LLMs vs. non-reasoning LLMs for NLG evaluation tasks, finding task-dependent benefits and performance trade-offs.", "motivation": "To explore the unexplored utility of reasoning LLMs for evaluating natural language generation tasks like machine translation and summarization.", "method": "Systematic comparison of eight models (reasoning and non-reasoning) on WMT23 and SummEval benchmarks, analyzing performance, reasoning token usage, and distillation effects.", "result": "Reasoning LLMs show task-dependent benefits (e.g., OpenAI o3-mini excels in MT), while DeepSeek-R1 underperforms except in summarization. Reasoning token usage correlates with quality only in specific models. Distillation degrades at 8B scale.", "conclusion": "First assessment of reasoning LLMs for NLG evaluation reveals nuanced performance, with potential for future research. Code is shared for reproducibility."}}
{"id": "2504.13169", "pdf": "https://arxiv.org/pdf/2504.13169", "abs": "https://arxiv.org/abs/2504.13169", "authors": ["Tsung-Han Wu", "Heekyung Lee", "Jiaxin Ge", "Joseph E. Gonzalez", "Trevor Darrell", "David M. Chan"], "title": "Generate, but Verify: Reducing Hallucination in Vision-Language Models with Retrospective Resampling", "categories": ["cs.CV"], "comment": "Preprint. Project Page: https://reverse-vlm.github.io", "summary": "Vision-Language Models (VLMs) excel at visual understanding but often suffer\nfrom visual hallucinations, where they generate descriptions of nonexistent\nobjects, actions, or concepts, posing significant risks in safety-critical\napplications. Existing hallucination mitigation methods typically follow one of\ntwo paradigms: generation adjustment, which modifies decoding behavior to align\ntext with visual inputs, and post-hoc verification, where external models\nassess and correct outputs. While effective, generation adjustment methods\noften rely on heuristics and lack correction mechanisms, while post-hoc\nverification is complicated, typically requiring multiple models and tending to\nreject outputs rather than refine them. In this work, we introduce REVERSE, a\nunified framework that integrates hallucination-aware training with on-the-fly\nself-verification. By leveraging a new hallucination-verification dataset\ncontaining over 1.3M semi-synthetic samples, along with a novel inference-time\nretrospective resampling technique, our approach enables VLMs to both detect\nhallucinations during generation and dynamically revise those hallucinations.\nOur evaluations show that REVERSE achieves state-of-the-art hallucination\nreduction, outperforming the best existing methods by up to 12% on CHAIR-MSCOCO\nand 34% on HaloQuest. Our dataset, model, and code are available at:\nhttps://reverse-vlm.github.io.", "AI": {"tldr": "REVERSE is a unified framework combining hallucination-aware training and self-verification to reduce visual hallucinations in Vision-Language Models (VLMs), outperforming existing methods by up to 34%.", "motivation": "VLMs often generate descriptions of nonexistent objects or actions (hallucinations), posing risks in safety-critical applications. Existing methods are either heuristic-based or overly complex.", "method": "REVERSE integrates hallucination-aware training with on-the-fly self-verification, using a 1.3M semi-synthetic dataset and a novel retrospective resampling technique.", "result": "REVERSE reduces hallucinations by up to 12% on CHAIR-MSCOCO and 34% on HaloQuest, achieving state-of-the-art performance.", "conclusion": "REVERSE effectively mitigates hallucinations in VLMs through a unified approach, offering a scalable and efficient solution."}}
{"id": "2502.11647", "pdf": "https://arxiv.org/pdf/2502.11647", "abs": "https://arxiv.org/abs/2502.11647", "authors": ["Yi Wang", "Fenghua Weng", "Sibei Yang", "Zhan Qin", "Minlie Huang", "Wenjie Wang"], "title": "DELMAN: Dynamic Defense Against Large Language Model Jailbreaking with Model Editing", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are widely applied in decision making, but their\ndeployment is threatened by jailbreak attacks, where adversarial users\nmanipulate model behavior to bypass safety measures. Existing defense\nmechanisms, such as safety fine-tuning and model editing, either require\nextensive parameter modifications or lack precision, leading to performance\ndegradation on general tasks, which is unsuitable to post-deployment safety\nalignment. To address these challenges, we propose DELMAN (Dynamic Editing for\nLLMs JAilbreak DefeNse), a novel approach leveraging direct model editing for\nprecise, dynamic protection against jailbreak attacks. DELMAN directly updates\na minimal set of relevant parameters to neutralize harmful behaviors while\npreserving the model's utility. To avoid triggering a safe response in benign\ncontext, we incorporate KL-divergence regularization to ensure the updated\nmodel remains consistent with the original model when processing benign\nqueries. Experimental results demonstrate that DELMAN outperforms baseline\nmethods in mitigating jailbreak attacks while preserving the model's utility,\nand adapts seamlessly to new attack instances, providing a practical and\nefficient solution for post-deployment model protection.", "AI": {"tldr": "DELMAN is a dynamic editing method for LLMs to defend against jailbreak attacks by minimally updating parameters, ensuring safety without degrading general performance.", "motivation": "Existing defenses against jailbreak attacks in LLMs are either too invasive or imprecise, harming model utility. DELMAN aims to provide precise, dynamic protection.", "method": "DELMAN directly edits a minimal set of model parameters to neutralize harmful behaviors, using KL-divergence regularization to maintain consistency for benign queries.", "result": "DELMAN outperforms baselines in mitigating jailbreak attacks while preserving model utility and adapts to new attacks efficiently.", "conclusion": "DELMAN offers a practical, efficient solution for post-deployment LLM safety alignment."}}
{"id": "2402.17390", "pdf": "https://arxiv.org/pdf/2402.17390", "abs": "https://arxiv.org/abs/2402.17390", "authors": ["Daniele Angioni", "Luca Demetrio", "Maura Pintor", "Luca Oneto", "Davide Anguita", "Battista Biggio", "Fabio Roli"], "title": "Robustness-Congruent Adversarial Training for Secure Machine Learning Model Updates", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Machine-learning models demand periodic updates to improve their average\naccuracy, exploiting novel architectures and additional data. However, a newly\nupdated model may commit mistakes the previous model did not make. Such\nmisclassifications are referred to as negative flips, experienced by users as a\nregression of performance. In this work, we show that this problem also affects\nrobustness to adversarial examples, hindering the development of secure model\nupdate practices. In particular, when updating a model to improve its\nadversarial robustness, previously ineffective adversarial attacks on some\ninputs may become successful, causing a regression in the perceived security of\nthe system. We propose a novel technique, named robustness-congruent\nadversarial training, to address this issue. It amounts to fine-tuning a model\nwith adversarial training, while constraining it to retain higher robustness on\nthe samples for which no adversarial example was found before the update. We\nshow that our algorithm and, more generally, learning with non-regression\nconstraints, provides a theoretically-grounded framework to train consistent\nestimators. Our experiments on robust models for computer vision confirm that\nboth accuracy and robustness, even if improved after model update, can be\naffected by negative flips, and our robustness-congruent adversarial training\ncan mitigate the problem, outperforming competing baseline methods.", "AI": {"tldr": "The paper addresses negative flips in model updates, where new models make mistakes the old ones didn't, including in adversarial robustness. It proposes robustness-congruent adversarial training to mitigate this.", "motivation": "To prevent performance regression (negative flips) in model updates, especially in adversarial robustness, which can undermine system security.", "method": "Proposes robustness-congruent adversarial training, fine-tuning models to retain robustness on previously secure samples while improving overall performance.", "result": "Experiments show the method mitigates negative flips in accuracy and robustness, outperforming baselines.", "conclusion": "Robustness-congruent adversarial training provides a practical solution to maintain consistency in model updates, supported by theoretical and empirical evidence."}}
{"id": "2504.09570", "pdf": "https://arxiv.org/pdf/2504.09570", "abs": "https://arxiv.org/abs/2504.09570", "authors": ["Biao Fu", "Minpeng Liao", "Kai Fan", "Chengxi Li", "Liang Zhang", "Yidong Chen", "Xiaodong Shi"], "title": "LLMs Can Achieve High-quality Simultaneous Machine Translation as Efficiently as Offline", "categories": ["cs.CL"], "comment": "Camera ready version for ACL 2025 Findings", "summary": "When the complete source sentence is provided, Large Language Models (LLMs)\nperform excellently in offline machine translation even with a simple prompt\n\"Translate the following sentence from [src lang] into [tgt lang]:\". However,\nin many real scenarios, the source tokens arrive in a streaming manner and\nsimultaneous machine translation (SiMT) is required, then the efficiency and\nperformance of decoder-only LLMs are significantly limited by their\nauto-regressive nature. To enable LLMs to achieve high-quality SiMT as\nefficiently as offline translation, we propose a novel paradigm that includes\nconstructing supervised fine-tuning (SFT) data for SiMT, along with new\ntraining and inference strategies. To replicate the token input/output stream\nin SiMT, the source and target tokens are rearranged into an interleaved\nsequence, separated by special tokens according to varying latency\nrequirements. This enables powerful LLMs to learn read and write operations\nadaptively, based on varying latency prompts, while still maintaining efficient\nauto-regressive decoding. Experimental results show that, even with limited SFT\ndata, our approach achieves state-of-the-art performance across various SiMT\nbenchmarks, and preserves the original abilities of offline translation.\nMoreover, our approach generalizes well to document-level SiMT setting without\nrequiring specific fine-tuning, even beyond the offline translation model.", "AI": {"tldr": "LLMs excel in offline translation but struggle with streaming input in simultaneous translation (SiMT). A new method using interleaved source-target sequences and special tokens improves SiMT performance while preserving offline translation abilities.", "motivation": "Current LLMs perform poorly in SiMT due to their auto-regressive nature, limiting efficiency and performance. A solution is needed to adapt LLMs for streaming scenarios without losing offline translation capabilities.", "method": "Proposes constructing supervised fine-tuning data for SiMT, rearranging source and target tokens into interleaved sequences with special tokens, and adapting training/inference strategies for varying latency.", "result": "Achieves state-of-the-art SiMT performance across benchmarks, preserves offline translation abilities, and generalizes to document-level SiMT without extra fine-tuning.", "conclusion": "The proposed paradigm effectively adapts LLMs for SiMT, maintaining high performance and efficiency while generalizing beyond offline translation."}}
{"id": "2504.17502", "pdf": "https://arxiv.org/pdf/2504.17502", "abs": "https://arxiv.org/abs/2504.17502", "authors": ["Aviv Slobodkin", "Hagai Taitelbaum", "Yonatan Bitton", "Brian Gordon", "Michal Sokolik", "Nitzan Bitton Guetta", "Almog Gueta", "Royi Rassin", "Dani Lischinski", "Idan Szpektor"], "title": "RefVNLI: Towards Scalable Evaluation of Subject-driven Text-to-image Generation", "categories": ["cs.CV"], "comment": null, "summary": "Subject-driven text-to-image (T2I) generation aims to produce images that\nalign with a given textual description, while preserving the visual identity\nfrom a referenced subject image. Despite its broad downstream applicability -\nranging from enhanced personalization in image generation to consistent\ncharacter representation in video rendering - progress in this field is limited\nby the lack of reliable automatic evaluation. Existing methods either assess\nonly one aspect of the task (i.e., textual alignment or subject preservation),\nmisalign with human judgments, or rely on costly API-based evaluation. To\naddress this gap, we introduce RefVNLI, a cost-effective metric that evaluates\nboth textual alignment and subject preservation in a single run. Trained on a\nlarge-scale dataset derived from video-reasoning benchmarks and image\nperturbations, RefVNLI outperforms or statistically matches existing baselines\nacross multiple benchmarks and subject categories (e.g., \\emph{Animal},\n\\emph{Object}), achieving up to 6.4-point gains in textual alignment and\n5.9-point gains in subject preservation.", "AI": {"tldr": "RefVNLI is a new metric for evaluating subject-driven T2I generation, addressing gaps in existing methods by assessing both textual alignment and subject preservation effectively.", "motivation": "Existing evaluation methods for subject-driven T2I generation are limited, either focusing on one aspect, misaligning with human judgment, or being costly. RefVNLI aims to provide a reliable, cost-effective solution.", "method": "RefVNLI is trained on a large-scale dataset from video-reasoning benchmarks and image perturbations to evaluate both textual alignment and subject preservation.", "result": "RefVNLI outperforms or matches existing baselines, achieving significant gains (up to 6.4-point in textual alignment and 5.9-point in subject preservation) across benchmarks and subject categories.", "conclusion": "RefVNLI is a robust, efficient metric for evaluating subject-driven T2I generation, addressing key limitations of prior methods."}}
{"id": "2502.12584", "pdf": "https://arxiv.org/pdf/2502.12584", "abs": "https://arxiv.org/abs/2502.12584", "authors": ["Jichan Chung", "Irene Y. Chen"], "title": "Enhancing Semi-supervised Learning with Zero-shot Pseudolabels", "categories": ["cs.LG", "cs.AI"], "comment": "Under review for Neurips 2025", "summary": "The high cost of data labeling presents a major barrier to deploying machine\nlearning systems at scale. Semi-supervised learning (SSL) mitigates this\nchallenge by utilizing unlabeled data alongside limited labeled examples, while\nthe emergence of foundation models (FMs) offers powerful zero-shot capabilities\nthat can further reduce labeling cost. However, directly fine-tuning large FMs\nis often impractical in resource-constrained settings, and na\\\"ively using\ntheir pseudo-labels for unlabeled data can degrade performance due to its\nunreliablity or domain mismatch with target task. In this work, we introduce\nZeroMatch, a novel SSL framework that integrates knowledge distillation with\nconsistency-based learning to jointly leverage labeled data, unlabeled data,\nand pseudo-labels from FMs. ZeroMatch enables training compact student models\nusing only FM inference, making it suitable for low-resource environments such\nas personal devices with limited compute. Experiments on six vision and\nlanguage classification benchmarks show that ZeroMatch consistently outperforms\nstandard SSL and zero-shot augmented methods, demonstrating its effectiveness\nand robustness across a range of foundation model qualities.", "AI": {"tldr": "ZeroMatch is a novel SSL framework combining knowledge distillation and consistency-based learning to leverage labeled/unlabeled data and FM pseudo-labels, outperforming standard SSL and zero-shot methods.", "motivation": "High labeling costs and impracticality of fine-tuning large FMs in resource-constrained settings drive the need for efficient SSL solutions.", "method": "ZeroMatch integrates knowledge distillation with consistency-based learning to use labeled data, unlabeled data, and FM pseudo-labels for training compact models.", "result": "ZeroMatch outperforms standard SSL and zero-shot methods on six vision and language benchmarks, showing robustness across FM qualities.", "conclusion": "ZeroMatch is effective for low-resource environments, enabling efficient model training with minimal FM inference."}}
{"id": "2404.05019", "pdf": "https://arxiv.org/pdf/2404.05019", "abs": "https://arxiv.org/abs/2404.05019", "authors": ["Weilin Cai", "Juyong Jiang", "Le Qin", "Junwei Cui", "Sunghun Kim", "Jiayi Huang"], "title": "Shortcut-connected Expert Parallelism for Accelerating Mixture-of-Experts", "categories": ["cs.LG", "cs.CL", "cs.DC"], "comment": null, "summary": "Expert parallelism has emerged as a key strategy for distributing the\ncomputational workload of sparsely-gated mixture-of-experts (MoE) models across\nmultiple devices, enabling the processing of increasingly large-scale models.\nHowever, the All-to-All communication inherent to expert parallelism poses a\nsignificant bottleneck, limiting the efficiency of MoE models. Although\nexisting optimization methods partially mitigate this issue, they remain\nconstrained by the sequential dependency between communication and computation\noperations. To address this challenge, we propose ScMoE, a novel\nshortcut-connected MoE architecture integrated with an overlapping\nparallelization strategy. ScMoE decouples communication from its conventional\nsequential ordering, enabling up to 100% overlap with computation. Compared to\nthe prevalent top-2 MoE baseline, ScMoE achieves speedups of 1.49 times in\ntraining and 1.82 times in inference. Moreover, our experiments and analyses\nindicate that ScMoE not only achieves comparable but in some instances\nsurpasses the model quality of existing approaches.", "AI": {"tldr": "ScMoE introduces a shortcut-connected MoE architecture with overlapping parallelization to decouple communication from computation, achieving significant speedups in training and inference while maintaining model quality.", "motivation": "The All-to-All communication bottleneck in expert parallelism limits the efficiency of MoE models, despite existing optimizations.", "method": "Proposes ScMoE, a shortcut-connected MoE architecture with an overlapping parallelization strategy to decouple communication from computation.", "result": "Achieves speedups of 1.49x in training and 1.82x in inference compared to top-2 MoE baseline, with comparable or better model quality.", "conclusion": "ScMoE effectively addresses the communication bottleneck, improving efficiency and performance of MoE models."}}
{"id": "2504.18428", "pdf": "https://arxiv.org/pdf/2504.18428", "abs": "https://arxiv.org/abs/2504.18428", "authors": ["Yiming Wang", "Pei Zhang", "Jialong Tang", "Haoran Wei", "Baosong Yang", "Rui Wang", "Chenshu Sun", "Feitong Sun", "Jiran Zhang", "Junxuan Wu", "Qiqian Cang", "Yichang Zhang", "Fei Huang", "Junyang Lin", "Fei Huang", "Jingren Zhou"], "title": "PolyMath: Evaluating Mathematical Reasoning in Multilingual Contexts", "categories": ["cs.CL"], "comment": "50 pages, 19 tables, 9 figures", "summary": "In this paper, we introduce PolyMath, a multilingual mathematical reasoning\nbenchmark covering 18 languages and 4 easy-to-hard difficulty levels. Our\nbenchmark ensures difficulty comprehensiveness, language diversity, and\nhigh-quality translation, making it a highly discriminative multilingual\nmathematical benchmark in the era of reasoning LLMs. We conduct a comprehensive\nevaluation for advanced LLMs and find that even Qwen-3-235B-A22B-Thinking and\nGemini-2.5-pro, achieve only 54.6 and 52.2 benchmark scores, with about 40%\naccuracy under the highest level From a language perspective, our benchmark\nreveals several key challenges of LLMs in multilingual reasoning: (1) Reasoning\nperformance varies widely across languages for current LLMs; (2) Input-output\nlanguage consistency is low in reasoning LLMs and may be correlated with\nperformance; (3) The thinking length differs significantly by language for\ncurrent LLMs. Additionally, we demonstrate that controlling the output language\nin the instructions has the potential to affect reasoning performance,\nespecially for some low-resource languages, suggesting a promising direction\nfor improving multilingual capabilities in LLMs.", "AI": {"tldr": "PolyMath is a multilingual math reasoning benchmark for LLMs, covering 18 languages and 4 difficulty levels. It highlights challenges like performance variability, low input-output consistency, and thinking length differences across languages. Output language control may improve reasoning.", "motivation": "To create a comprehensive, high-quality multilingual math benchmark for evaluating reasoning LLMs, addressing gaps in difficulty, language diversity, and translation quality.", "method": "Developed PolyMath, a benchmark with 18 languages and 4 difficulty levels, and evaluated advanced LLMs like Qwen-3-235B-A22B-Thinking and Gemini-2.5-pro.", "result": "Top LLMs scored ~54.6 and 52.2, with ~40% accuracy at the highest level. Key challenges: performance variability, low input-output consistency, and thinking length differences by language.", "conclusion": "Output language control can enhance reasoning performance, especially for low-resource languages, offering a path to improve multilingual LLM capabilities."}}
{"id": "2504.21336", "pdf": "https://arxiv.org/pdf/2504.21336", "abs": "https://arxiv.org/abs/2504.21336", "authors": ["Linshan Wu", "Yuxiang Nie", "Sunan He", "Jiaxin Zhuang", "Luyang Luo", "Neeraj Mahboobani", "Varut Vardhanabhuti", "Ronald Cheong Kin Chan", "Yifan Peng", "Pranav Rajpurkar", "Hao Chen"], "title": "UniBiomed: A Universal Foundation Model for Grounded Biomedical Image Interpretation", "categories": ["cs.CV"], "comment": "The first universal foundation model for grounded biomedical image\n  interpretation", "summary": "The integration of AI-assisted biomedical image analysis into clinical\npractice demands AI-generated findings that are not only accurate but also\ninterpretable to clinicians. However, existing biomedical AI models generally\nlack the ability to simultaneously generate diagnostic findings and localize\ncorresponding biomedical objects. This limitation makes it challenging for\nclinicians to correlate AI-generated findings with visual evidence (e.g., tiny\nlesions) in images and interpret the results of AI models. To address this\nchallenge, we introduce UniBiomed, the first universal foundation model for\ngrounded biomedical image interpretation, which is capable of generating\naccurate diagnostic findings and simultaneously segmenting the corresponding\nbiomedical targets. UniBiomed is based on a novel integration of Multi-modal\nLarge Language Model and Segment Anything Model, which can effectively unify\ndiverse biomedical tasks in universal training for advancing grounded\ninterpretation. To develop UniBiomed, we curate a large-scale dataset\ncomprising over 27 million triplets of images, region annotations, and text\ndescriptions across ten biomedical imaging modalities. Extensive validation on\n70 internal and 14 external datasets demonstrated the state-of-the-art\nperformance of UniBiomed in diverse biomedical tasks, including image\nsegmentation, disease recognition, region-aware diagnosis, vision question\nanswering, and report generation. In summary, UniBiomed is a powerful and\nversatile biomedical foundation model, unlocking the untapped grounded\ninterpretation capability for optimizing AI-assisted biomedical image analysis.", "AI": {"tldr": "UniBiomed is a universal foundation model for biomedical image interpretation, combining diagnostic findings with object localization to improve clinician interpretability.", "motivation": "Existing biomedical AI models lack the ability to simultaneously generate diagnostic findings and localize biomedical objects, hindering clinician interpretation.", "method": "UniBiomed integrates a Multi-modal Large Language Model and Segment Anything Model, trained on a large-scale dataset of 27 million triplets across ten imaging modalities.", "result": "UniBiomed achieves state-of-the-art performance in tasks like segmentation, disease recognition, and report generation across 84 datasets.", "conclusion": "UniBiomed enhances grounded interpretation in AI-assisted biomedical image analysis, offering accuracy and versatility."}}
{"id": "2502.12913", "pdf": "https://arxiv.org/pdf/2502.12913", "abs": "https://arxiv.org/abs/2502.12913", "authors": ["Sifan Zhou", "Shuo Wang", "Zhihang Yuan", "Mingjia Shi", "Yuzhang Shang", "Dawei Yang"], "title": "GSQ-Tuning: Group-Shared Exponents Integer in Fully Quantized Training for LLMs On-Device Fine-tuning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted by Findings of ACL 2025", "summary": "Large Language Models (LLMs) fine-tuning technologies have achieved\nremarkable results. However, traditional LLM fine-tuning approaches face\nsignificant challenges: they require large Floating Point (FP) computation,\nraising privacy concerns when handling sensitive data, and are impractical for\nresource-constrained edge devices. While Parameter-Efficient Fine-Tuning (PEFT)\ntechniques reduce trainable parameters, their reliance on floating-point\narithmetic creates fundamental incompatibilities with edge hardware. In this\nwork, we introduce a novel framework for on-device LLM fine-tuning that\neliminates the need for floating-point operations in both inference and\ntraining, named GSQ-Tuning. At its core is the Group-Shared Exponents Integer\nformat, which efficiently represents model parameters in integer format using\nshared exponents among parameter groups. When combined with LoRA-like adapters,\nthis enables fully integer-based fine-tuning that is both memory and compute\nefficient. We demonstrate that our approach achieves accuracy comparable to\nBF16-based fine-tuning while significantly reducing 1.85x memory usage.\nMoreover, compared to FP8, our method can reduce 5x power consumption and 11x\nchip area with same performance, making large-scale model adaptation feasible\non edge devices.", "AI": {"tldr": "GSQ-Tuning introduces a fully integer-based fine-tuning framework for LLMs, reducing memory and power usage while maintaining accuracy.", "motivation": "Traditional LLM fine-tuning is resource-intensive and incompatible with edge devices due to floating-point operations.", "method": "Uses Group-Shared Exponents Integer format and LoRA-like adapters for integer-based fine-tuning.", "result": "Achieves BF16-level accuracy with 1.85x less memory, 5x less power, and 11x smaller chip area than FP8.", "conclusion": "GSQ-Tuning enables efficient, privacy-preserving LLM fine-tuning on edge devices."}}
{"id": "2404.08008", "pdf": "https://arxiv.org/pdf/2404.08008", "abs": "https://arxiv.org/abs/2404.08008", "authors": ["Kehua Feng", "Keyan Ding", "Hongzhi Tan", "Kede Ma", "Zhihua Wang", "Shuangquan Guo", "Yuzhou Cheng", "Ge Sun", "Guozhou Zheng", "Qiang Zhang", "Huajun Chen"], "title": "Sample-Efficient Human Evaluation of Large Language Models via Maximum Discrepancy Competition", "categories": ["cs.LG", "cs.CL", "cs.HC"], "comment": "35 pages, 6 figures, Accepted by ACL 2025", "summary": "Reliable evaluation of large language models (LLMs) is impeded by two key\nchallenges: objective metrics often fail to reflect human perception of natural\nlanguage, and exhaustive human labeling is prohibitively expensive. Here, we\npropose a sample-efficient human evaluation method for LLMs based on the\nprinciple of MAximum Discrepancy (MAD) Competition. Our method automatically\nand adaptively selects a compact set of input instructions that maximize\nsemantic discrepancy between pairs of LLM responses. Human evaluators then\nperform three-alternative forced choices on these paired responses, which are\naggregated into a global ranking using Elo rating. We apply our approach to\ncompare eight widely used LLMs across four tasks: scientific knowledge\nunderstanding, mathematical reasoning, creative and functional writing, and\ncode generation and explanation. Experimental results show that our\nsample-efficient evaluation method recovers \"gold-standard\" model rankings with\na handful of MAD-selected instructions, reveals respective strengths and\nweaknesses of each LLM, and offers nuanced insights to guide future LLM\ndevelopment. Code is available at https://github.com/weiji-Feng/MAD-Eval .", "AI": {"tldr": "A sample-efficient human evaluation method for LLMs, called MAD Competition, selects input instructions to maximize discrepancy between model responses, enabling reliable rankings with minimal human effort.", "motivation": "Current LLM evaluation lacks alignment with human perception and is costly due to exhaustive labeling.", "method": "Uses MAD Competition to select input instructions for maximum discrepancy, followed by human three-alternative forced choices, aggregated via Elo rating.", "result": "Recovers gold-standard rankings with few instructions, reveals LLM strengths/weaknesses, and provides nuanced insights.", "conclusion": "MAD-Eval offers an efficient, insightful approach for LLM evaluation, guiding future development."}}
{"id": "2505.04388", "pdf": "https://arxiv.org/pdf/2505.04388", "abs": "https://arxiv.org/abs/2505.04388", "authors": ["Dario Garcia-Gasulla", "Jordi Bayarri-Planas", "Ashwin Kumar Gururajan", "Enrique Lopez-Cuena", "Adrian Tormos", "Daniel Hinjos", "Pablo Bernabeu-Perez", "Anna Arias-Duart", "Pablo Agustin Martin-Torres", "Marta Gonzalez-Mallo", "Sergio Alvarez-Napagao", "Eduard Ayguad\u00e9-Parra", "Ulises Cort\u00e9s"], "title": "The Aloe Family Recipe for Open and Specialized Healthcare LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "Follow-up work from arXiv:2405.01886", "summary": "Purpose: With advancements in Large Language Models (LLMs) for healthcare,\nthe need arises for competitive open-source models to protect the public\ninterest. This work contributes to the field of open medical LLMs by optimizing\nkey stages of data preprocessing and training, while showing how to improve\nmodel safety (through DPO) and efficacy (through RAG). The evaluation\nmethodology used, which includes four different types of tests, defines a new\nstandard for the field. The resultant models, shown to be competitive with the\nbest private alternatives, are released with a permisive license.\n  Methods: Building on top of strong base models like Llama 3.1 and Qwen 2.5,\nAloe Beta uses a custom dataset to enhance public data with synthetic Chain of\nThought examples. The models undergo alignment with Direct Preference\nOptimization, emphasizing ethical and policy-aligned performance in the\npresence of jailbreaking attacks. Evaluation includes close-ended, open-ended,\nsafety and human assessments, to maximize the reliability of results.\n  Results: Recommendations are made across the entire pipeline, backed by the\nsolid performance of the Aloe Family. These models deliver competitive\nperformance across healthcare benchmarks and medical fields, and are often\npreferred by healthcare professionals. On bias and toxicity, the Aloe Beta\nmodels significantly improve safety, showing resilience to unseen jailbreaking\nattacks. For a responsible release, a detailed risk assessment specific to\nhealthcare is attached to the Aloe Family models.\n  Conclusion: The Aloe Beta models, and the recipe that leads to them, are a\nsignificant contribution to the open-source medical LLM field, offering\ntop-of-the-line performance while maintaining high ethical requirements. This\nwork sets a new standard for developing and reporting aligned LLMs in\nhealthcare.", "AI": {"tldr": "The paper introduces Aloe Beta, an open-source medical LLM, optimizing data preprocessing, training, and safety (via DPO) and efficacy (via RAG). It sets a new evaluation standard and releases competitive models under a permissive license.", "motivation": "To advance open-source medical LLMs, ensuring public interest protection by improving model safety, efficacy, and ethical alignment.", "method": "Uses base models (Llama 3.1, Qwen 2.5) with synthetic data and DPO for alignment. Evaluates via four test types (close/open-ended, safety, human assessments).", "result": "Aloe Beta models perform competitively in healthcare benchmarks, improve safety, and resist jailbreaking. Includes a detailed risk assessment.", "conclusion": "Aloe Beta and its development approach set a new standard for ethical, high-performance open-source medical LLMs."}}
{"id": "2505.02179", "pdf": "https://arxiv.org/pdf/2505.02179", "abs": "https://arxiv.org/abs/2505.02179", "authors": ["Tao Zhu", "Qi Yu", "Xinru Dong", "Shiyu Li", "Yue Liu", "Jinlong Jiang", "Lei Shu"], "title": "ProDisc-VAD: An Efficient System for Weakly-Supervised Anomaly Detection in Video Surveillance Applications", "categories": ["cs.CV"], "comment": "A newly identified systematic error in our data processing pipeline\n  has affected the calculation and reporting of AUC metrics (notably in Tables\n  [1, 2]). This significantly impacts our main experimental results and\n  conclusions, compromising their reliability. To ensure academic rigor and\n  prevent misleading information, this manuscript is withdrawn for thorough\n  correction and re-evaluation", "summary": "Weakly-supervised video anomaly detection (WS-VAD) using Multiple Instance\nLearning (MIL) suffers from label ambiguity, hindering discriminative feature\nlearning. We propose ProDisc-VAD, an efficient framework tackling this via two\nsynergistic components. The Prototype Interaction Layer (PIL) provides\ncontrolled normality modeling using a small set of learnable prototypes,\nestablishing a robust baseline without being overwhelmed by dominant normal\ndata. The Pseudo-Instance Discriminative Enhancement (PIDE) loss boosts\nseparability by applying targeted contrastive learning exclusively to the most\nreliable extreme-scoring instances (highest/lowest scores). ProDisc-VAD\nachieves strong AUCs (97.98% ShanghaiTech, 87.12% UCF-Crime) using only 0.4M\nparameters, over 800x fewer than recent ViT-based methods like VadCLIP,\ndemonstrating exceptional efficiency alongside state-of-the-art performance.\nCode is available at https://github.com/modadundun/ProDisc-VAD.", "AI": {"tldr": "ProDisc-VAD improves weakly-supervised video anomaly detection by addressing label ambiguity with a prototype interaction layer and pseudo-instance discriminative enhancement, achieving high efficiency and performance.", "motivation": "Label ambiguity in weakly-supervised video anomaly detection (WS-VAD) using Multiple Instance Learning (MIL) hinders discriminative feature learning.", "method": "ProDisc-VAD introduces a Prototype Interaction Layer (PIL) for controlled normality modeling and a Pseudo-Instance Discriminative Enhancement (PIDE) loss for targeted contrastive learning on extreme-scoring instances.", "result": "Achieves strong AUCs (97.98% ShanghaiTech, 87.12% UCF-Crime) with only 0.4M parameters, 800x fewer than ViT-based methods.", "conclusion": "ProDisc-VAD offers exceptional efficiency and state-of-the-art performance in WS-VAD."}}
{"id": "2502.14276", "pdf": "https://arxiv.org/pdf/2502.14276", "abs": "https://arxiv.org/abs/2502.14276", "authors": ["Hanlin Wang", "Jian Wang", "Chak Tou Leong", "Wenjie Li"], "title": "STeCa: Step-level Trajectory Calibration for LLM Agent Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted by ACL2025 Findings", "summary": "Large language model (LLM)-based agents have shown promise in tackling\ncomplex tasks by interacting dynamically with the environment. Existing work\nprimarily focuses on behavior cloning from expert demonstrations or preference\nlearning through exploratory trajectory sampling. However, these methods often\nstruggle to address long-horizon tasks, where suboptimal actions accumulate\nstep by step, causing agents to deviate from correct task trajectories. To\naddress this, we highlight the importance of timely calibration and the need to\nautomatically construct calibration trajectories for training agents. We\npropose Step-Level Trajectory Calibration (STeCa), a novel framework for LLM\nagent learning. Specifically, STeCa identifies suboptimal actions through a\nstep-level reward comparison during exploration. It constructs calibrated\ntrajectories using LLM-driven reflection, enabling agents to learn from\nimproved decision-making processes. We finally leverage these calibrated\ntrajectories with successful trajectories for reinforced training. Extensive\nexperiments demonstrate that STeCa significantly outperforms existing methods.\nFurther analysis highlights that timely calibration enables agents to complete\ntasks with greater robustness. Our code and data are available at\nhttps://github.com/WangHanLinHenry/STeCa.", "AI": {"tldr": "STeCa is a framework for LLM agent learning that improves performance by identifying and correcting suboptimal actions through step-level calibration and reinforced training.", "motivation": "Existing methods struggle with long-horizon tasks due to accumulated suboptimal actions, highlighting the need for timely calibration.", "method": "STeCa identifies suboptimal actions via step-level reward comparison, constructs calibrated trajectories using LLM-driven reflection, and uses them for reinforced training.", "result": "STeCa outperforms existing methods, enabling more robust task completion.", "conclusion": "Timely calibration via STeCa enhances LLM agent performance in complex tasks."}}
{"id": "2405.14457", "pdf": "https://arxiv.org/pdf/2405.14457", "abs": "https://arxiv.org/abs/2405.14457", "authors": ["Tudor Cebere", "Aur\u00e9lien Bellet", "Nicolas Papernot"], "title": "Tighter Privacy Auditing of DP-SGD in the Hidden State Threat Model", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Machine learning models can be trained with formal privacy guarantees via\ndifferentially private optimizers such as DP-SGD. In this work, we focus on a\nthreat model where the adversary has access only to the final model, with no\nvisibility into intermediate updates. In the literature, this hidden state\nthreat model exhibits a significant gap between the lower bound from empirical\nprivacy auditing and the theoretical upper bound provided by privacy\naccounting. To challenge this gap, we propose to audit this threat model with\nadversaries that craft a gradient sequence designed to maximize the privacy\nloss of the final model without relying on intermediate updates. Our\nexperiments show that this approach consistently outperforms previous attempts\nat auditing the hidden state model. Furthermore, our results advance the\nunderstanding of achievable privacy guarantees within this threat model.\nSpecifically, when the crafted gradient is inserted at every optimization step,\nwe show that concealing the intermediate model updates in DP-SGD does not\nenhance the privacy guarantees. The situation is more complex when the crafted\ngradient is not inserted at every step: our auditing lower bound matches the\nprivacy upper bound only for an adversarially-chosen loss landscape and a\nsufficiently large batch size. This suggests that existing privacy upper bounds\ncan be improved in certain regimes.", "AI": {"tldr": "The paper investigates the gap between empirical and theoretical privacy bounds in differentially private machine learning, proposing a new auditing method for the hidden state threat model.", "motivation": "The study addresses the discrepancy between lower bounds from empirical privacy auditing and theoretical upper bounds in privacy accounting for the hidden state threat model.", "method": "The authors propose auditing with adversaries crafting gradient sequences to maximize privacy loss without relying on intermediate updates. Experiments compare this approach to previous methods.", "result": "The new auditing method outperforms prior attempts. It reveals that hiding intermediate updates in DP-SGD doesn't enhance privacy if crafted gradients are inserted at every step. For non-continuous insertion, bounds match only under specific conditions.", "conclusion": "The findings suggest that existing privacy upper bounds can be improved in certain scenarios, advancing understanding of privacy guarantees in the hidden state threat model."}}
{"id": "2505.07889", "pdf": "https://arxiv.org/pdf/2505.07889", "abs": "https://arxiv.org/abs/2505.07889", "authors": ["Yuyang Liu", "Liuzhenghao Lv", "Xiancheng Zhang", "Li Yuan", "Yonghong Tian"], "title": "BioProBench: Comprehensive Dataset and Benchmark in Biological Protocol Understanding and Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Biological protocols are fundamental to reproducibility and safety in life\nscience research. While large language models (LLMs) perform well on general\ntasks, their systematic evaluation on these highly specialized,\naccuracy-critical, and inherently procedural texts remains limited. In this\nwork, we present BioProBench, the first large-scale, multi-task benchmark for\nbiological protocol understanding and reasoning. While there are several\nbenchmark tasks involving protocol question answering, BioProBench provides a\ncomprehensive suite of five core tasks: Protocol Question Answering, Step\nOrdering, Error Correction, Protocol Generation, and Protocol Reasoning,\nenabling a holistic evaluation of LLMs on procedural biological texts. Built\nupon 27K original protocols, it yields nearly 556K high-quality structured\ninstances. We evaluate 12 mainstream open/closed-source LLMs. Experimental\nresults reveal that some models perform well on basic understanding tasks\n(e.g., \\sim70% PQA-Acc., >64% ERR F1), but struggle significantly with deep\nreasoning and structured generation tasks like ordering and generation.\nFurthermore, model comparisons show diverse performance: certain open-source\nmodels approach closed-source levels on some tasks, yet bio-specific small\nmodels lag behind general LLMs, indicating limitations on complex procedural\ncontent. Overall, BioProBench, through its task design and experimental\nfindings, systematically reveals the fundamental challenges for current LLMs in\nprocedural knowledge understanding, deep adaptability to specific domains,\nreliability of structured reasoning, and handling of sophisticated precision\nand safety constraints, providing key directions for future AI in the field of\nscientific experiment automation. The code and data are available at:\nhttps://github.com/YuyangSunshine/bioprotocolbench and\nhttps://huggingface.co/datasets/BioProBench/BioProBench.", "AI": {"tldr": "BioProBench is a large-scale benchmark for evaluating LLMs on biological protocol tasks, revealing their strengths in basic understanding but weaknesses in deep reasoning and structured generation.", "motivation": "To systematically assess LLMs' performance on specialized, accuracy-critical biological protocol texts, which are crucial for reproducibility and safety in life sciences.", "method": "Developed BioProBench, a multi-task benchmark with five core tasks (e.g., Protocol Question Answering, Protocol Generation), built on 27K protocols yielding 556K instances. Evaluated 12 LLMs.", "result": "LLMs perform well on basic tasks (e.g., ~70% PQA-Acc.) but struggle with deep reasoning and structured generation. Open-source models sometimes match closed-source, but bio-specific models lag.", "conclusion": "BioProBench highlights LLMs' challenges in procedural knowledge, domain adaptability, and structured reasoning, guiding future AI for scientific automation."}}
{"id": "2505.14359", "pdf": "https://arxiv.org/pdf/2505.14359", "abs": "https://arxiv.org/abs/2505.14359", "authors": ["Ruoxin Chen", "Junwei Xi", "Zhiyuan Yan", "Ke-Yue Zhang", "Shuang Wu", "Jingyi Xie", "Xu Chen", "Lei Xu", "Isabel Guan", "Taiping Yao", "Shouhong Ding"], "title": "Dual Data Alignment Makes AI-Generated Image Detector Easier Generalizable", "categories": ["cs.CV"], "comment": "12 Pages, 9 figures", "summary": "Existing detectors are often trained on biased datasets, leading to the\npossibility of overfitting on non-causal image attributes that are spuriously\ncorrelated with real/synthetic labels. While these biased features enhance\nperformance on the training data, they result in substantial performance\ndegradation when applied to unbiased datasets. One common solution is to\nperform dataset alignment through generative reconstruction, matching the\nsemantic content between real and synthetic images. However, we revisit this\napproach and show that pixel-level alignment alone is insufficient. The\nreconstructed images still suffer from frequency-level misalignment, which can\nperpetuate spurious correlations. To illustrate, we observe that reconstruction\nmodels tend to restore the high-frequency details lost in real images (possibly\ndue to JPEG compression), inadvertently creating a frequency-level\nmisalignment, where synthetic images appear to have richer high-frequency\ncontent than real ones. This misalignment leads to models associating\nhigh-frequency features with synthetic labels, further reinforcing biased cues.\nTo resolve this, we propose Dual Data Alignment (DDA), which aligns both the\npixel and frequency domains. Moreover, we introduce two new test sets:\nDDA-COCO, containing DDA-aligned synthetic images for testing detector\nperformance on the most aligned dataset, and EvalGEN, featuring the latest\ngenerative models for assessing detectors under new generative architectures\nsuch as visual auto-regressive generators. Finally, our extensive evaluations\ndemonstrate that a detector trained exclusively on DDA-aligned MSCOCO could\nimprove across 8 diverse benchmarks by a non-trivial margin, showing a +7.2% on\nin-the-wild benchmarks, highlighting the improved generalizability of unbiased\ndetectors.", "AI": {"tldr": "The paper addresses bias in detectors due to dataset misalignment, proposing Dual Data Alignment (DDA) to align pixel and frequency domains, improving generalizability.", "motivation": "Existing detectors overfit on biased datasets, relying on spurious correlations. Pixel-level alignment alone is insufficient, as frequency-level misalignment persists.", "method": "Proposes DDA for dual-domain alignment (pixel and frequency) and introduces new test sets (DDA-COCO, EvalGEN) for evaluation.", "result": "Detectors trained on DDA-aligned MSCOCO improve performance by +7.2% on in-the-wild benchmarks, showing better generalizability.", "conclusion": "DDA effectively mitigates bias by addressing both pixel and frequency misalignment, enhancing detector performance across diverse benchmarks."}}
{"id": "2502.15771", "pdf": "https://arxiv.org/pdf/2502.15771", "abs": "https://arxiv.org/abs/2502.15771", "authors": ["Yanyang Li", "Michael Lyu", "Liwei Wang"], "title": "Learning to Reason from Feedback at Test-Time", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "ACL 2025 Main; Project Page: https://github.com/LaVi-Lab/FTTT", "summary": "Solving complex tasks in a single attempt is challenging for large language\nmodels (LLMs). Iterative interaction with the environment and feedback is often\nrequired to achieve success, making effective feedback utilization a critical\ntopic. Existing approaches either struggle with length generalization or rely\non naive retries without leveraging prior information. In this paper, we\nintroduce FTTT, a novel paradigm that formulates feedback utilization as an\noptimization problem at test time. Additionally, we propose a learnable\ntest-time optimizer, OpTune, to effectively exploit feedback. Experiments on\ntwo LLMs across four reasoning datasets demonstrate that FTTT and OpTune\nachieve superior scalability and performance.", "AI": {"tldr": "FTTT and OpTune improve LLM performance by optimizing feedback utilization at test time, outperforming existing methods.", "motivation": "Existing methods for feedback utilization in LLMs either generalize poorly or inefficiently retry without leveraging prior information.", "method": "FTTT formulates feedback as an optimization problem, and OpTune, a learnable optimizer, exploits feedback effectively.", "result": "Experiments on four reasoning datasets show FTTT and OpTune achieve better scalability and performance.", "conclusion": "FTTT and OpTune offer a scalable and effective solution for feedback utilization in LLMs."}}
{"id": "2405.14620", "pdf": "https://arxiv.org/pdf/2405.14620", "abs": "https://arxiv.org/abs/2405.14620", "authors": ["Shu Wei", "Yanjie Li", "Lina Yu", "Weijun Li", "Min Wu", "Linjun Sun", "Jufeng Han", "Yan Pang"], "title": "Closed-form Solutions: A New Perspective on Solving Differential Equations", "categories": ["cs.LG"], "comment": "Accepted as a poster at the 42nd International Conference on Machine\n  Learning (ICML 2025), Vancouver, Canada", "summary": "The quest for analytical solutions to differential equations has\ntraditionally been constrained by the need for extensive mathematical\nexpertise. Machine learning methods like genetic algorithms have shown promise\nin this domain, but are hindered by significant computational time and the\ncomplexity of their derived solutions. This paper introduces SSDE (Symbolic\nSolver for Differential Equations), a novel reinforcement learning-based\napproach that derives symbolic closed-form solutions for various differential\nequations. Evaluations across a diverse set of ordinary and partial\ndifferential equations demonstrate that SSDE outperforms existing machine\nlearning methods, delivering superior accuracy and efficiency in obtaining\nanalytical solutions.", "AI": {"tldr": "SSDE, a reinforcement learning-based method, outperforms existing machine learning techniques in deriving symbolic solutions for differential equations with better accuracy and efficiency.", "motivation": "Traditional methods require extensive mathematical expertise, and existing machine learning approaches like genetic algorithms are computationally intensive and yield complex solutions.", "method": "SSDE uses reinforcement learning to derive symbolic closed-form solutions for differential equations.", "result": "SSDE achieves superior accuracy and efficiency compared to other machine learning methods across various ordinary and partial differential equations.", "conclusion": "SSDE is a promising tool for solving differential equations symbolically, addressing limitations of traditional and existing machine learning methods."}}
{"id": "2505.08167", "pdf": "https://arxiv.org/pdf/2505.08167", "abs": "https://arxiv.org/abs/2505.08167", "authors": ["Ruilin Liu", "Zhixiao Zhao", "Jieqiong Li", "Chang Liu", "Dongbo Wang"], "title": "Fusing Bidirectional Chains of Thought and Reward Mechanisms A Method for Enhancing Question-Answering Capabilities of Large Language Models for Chinese Intangible Cultural Heritage", "categories": ["cs.CL", "cs.AI"], "comment": "22 pages, 5 figures", "summary": "The rapid development of large language models (LLMs) has provided\nsignificant support and opportunities for the advancement of domain-specific\nLLMs. However, fine-tuning these large models using Intangible Cultural\nHeritage (ICH) data inevitably faces challenges such as bias, incorrect\nknowledge inheritance, and catastrophic forgetting. To address these issues, we\npropose a novel training method that integrates a bidirectional chains of\nthought and a reward mechanism. This method is built upon ICH-Qwen, a large\nlanguage model specifically designed for the field of intangible cultural\nheritage. The proposed method enables the model to not only perform forward\nreasoning but also enhances the accuracy of the generated answers by utilizing\nreverse questioning and reverse reasoning to activate the model's latent\nknowledge. Additionally, a reward mechanism is introduced during training to\noptimize the decision-making process. This mechanism improves the quality of\nthe model's outputs through structural and content evaluations with different\nweighting schemes. We conduct comparative experiments on ICH-Qwen, with results\ndemonstrating that our method outperforms 0-shot, step-by-step reasoning,\nknowledge distillation, and question augmentation methods in terms of accuracy,\nBleu-4, and Rouge-L scores on the question-answering task. Furthermore, the\npaper highlights the effectiveness of combining the bidirectional chains of\nthought and reward mechanism through ablation experiments. In addition, a\nseries of generalizability experiments are conducted, with results showing that\nthe proposed method yields improvements on various domain-specific datasets and\nadvanced models in areas such as Finance, Wikidata, and StrategyQA. This\ndemonstrates that the method is adaptable to multiple domains and provides a\nvaluable approach for model training in future applications across diverse\nfields.", "AI": {"tldr": "A novel training method combining bidirectional chains of thought and a reward mechanism improves domain-specific LLMs, addressing issues like bias and catastrophic forgetting in ICH-Qwen.", "motivation": "To tackle challenges in fine-tuning LLMs with ICH data, such as bias and incorrect knowledge inheritance, by enhancing reasoning and output quality.", "method": "Integrates bidirectional chains of thought (forward and reverse reasoning) and a reward mechanism for structural and content evaluation.", "result": "Outperforms baseline methods in accuracy, Bleu-4, and Rouge-L scores, with demonstrated generalizability across domains like Finance and Wikidata.", "conclusion": "The method is adaptable and effective for diverse domain-specific LLMs, offering a promising approach for future applications."}}
{"id": "2505.16512", "pdf": "https://arxiv.org/pdf/2505.16512", "abs": "https://arxiv.org/abs/2505.16512", "authors": ["Jiaxin Liu", "Jia Wang", "Saihui Hou", "Min Ren", "Huijia Wu", "Zhaofeng He"], "title": "Beyond Face Swapping: A Diffusion-Based Digital Human Benchmark for Multimodal Deepfake Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In recent years, the rapid development of deepfake technology has given rise\nto an emerging and serious threat to public security: diffusion-based digital\nhuman generation. Unlike traditional face manipulation methods, such models can\ngenerate highly realistic videos with consistency through multimodal control\nsignals. Their flexibility and covertness pose severe challenges to existing\ndetection strategies. To bridge this gap, we introduce DigiFakeAV, the new\nlarge-scale multimodal digital human forgery dataset based on diffusion models.\nEmploying five of the latest digital human generation methods and the voice\ncloning methods, we systematically produce a dataset comprising 60,000 videos\n(8.4 million frames), covering multiple nationalities, skin tones, genders, and\nreal-world scenarios, significantly enhancing data diversity and realism. User\nstudies demonstrate that participants misclassify forged videos as real in 68%\nof tests, and existing detection models exhibit a large drop in performance on\nDigiFakeAV, highlighting the challenge of the dataset. To address this problem,\nwe propose DigiShield, an effective detection baseline based on spatiotemporal\nand cross-modal fusion. By jointly modeling the 3D spatiotemporal features of\nvideos and the semantic-acoustic features of audio, DigiShield achieves\nstate-of-the-art (SOTA) performance on the DigiFakeAV and shows strong\ngeneralization on other datasets.", "AI": {"tldr": "The paper introduces DigiFakeAV, a large-scale dataset for detecting diffusion-based deepfake videos, and proposes DigiShield, a detection model achieving SOTA performance.", "motivation": "The rise of diffusion-based digital human generation poses a serious threat to public security, challenging existing detection methods due to its realism and flexibility.", "method": "The authors create DigiFakeAV using five digital human generation and voice cloning methods, producing 60,000 videos. They then propose DigiShield, a detection model leveraging spatiotemporal and cross-modal fusion.", "result": "User studies show 68% misclassification of forged videos as real, and DigiShield achieves SOTA performance on DigiFakeAV with strong generalization.", "conclusion": "DigiShield effectively addresses the challenges posed by diffusion-based deepfakes, offering a robust detection solution."}}
{"id": "2502.16091", "pdf": "https://arxiv.org/pdf/2502.16091", "abs": "https://arxiv.org/abs/2502.16091", "authors": ["Zhipeng Cheng", "Xiaoyu Xia", "Hong Wang", "Minghui Liwang", "Ning Chen", "Xuwei Fan", "Xianbin Wang"], "title": "Privacy-Aware Joint DNN Model Deployment and Partitioning Optimization for Collaborative Edge Inference Services", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.NI"], "comment": "14 pages", "summary": "Edge inference (EI) has emerged as a promising paradigm to address the\ngrowing limitations of cloud-based Deep Neural Network (DNN) inference\nservices, such as high response latency, limited scalability, and severe data\nprivacy exposure. However, deploying DNN models on resource-constrained edge\ndevices introduces additional challenges, including limited computation/storage\nresources, dynamic service demands, and heightened privacy risks. To tackle\nthese issues, this paper presents a novel privacy-aware optimization framework\nthat jointly addresses DNN model deployment, user-server association, and model\npartitioning, with the goal of minimizing long-term average inference delay\nunder resource and privacy constraints. The problem is formulated as a complex,\nNP-hard stochastic optimization. To efficiently handle system dynamics and\ncomputational complexity, we employ a Lyapunov-based approach to transform the\nlong-term objective into tractable per-slot decisions. Furthermore, we\nintroduce a coalition formation game to enable adaptive user-server association\nand design a greedy algorithm for model deployment within each coalition.\nExtensive simulations demonstrate that the proposed algorithm significantly\nreduces inference delay and consistently satisfies privacy constraints,\noutperforming state-of-the-art baselines across diverse scenarios.", "AI": {"tldr": "A privacy-aware optimization framework for edge-based DNN inference reduces latency and ensures privacy by jointly optimizing model deployment, user-server association, and partitioning.", "motivation": "Addressing challenges like high latency, scalability, and privacy in cloud-based DNN inference by deploying models on resource-constrained edge devices.", "method": "Uses a Lyapunov-based approach for stochastic optimization, a coalition formation game for user-server association, and a greedy algorithm for model deployment.", "result": "Significantly reduces inference delay while meeting privacy constraints, outperforming existing methods.", "conclusion": "The framework effectively balances resource constraints and privacy, offering a scalable solution for edge-based DNN inference."}}
{"id": "2405.18253", "pdf": "https://arxiv.org/pdf/2405.18253", "abs": "https://arxiv.org/abs/2405.18253", "authors": ["Shuran Zheng", "Xuan Qi", "Rui Ray Chen", "Yongchan Kwon", "James Zou"], "title": "Proper Dataset Valuation by Pointwise Mutual Information", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "Data plays a central role in advancements in modern artificial intelligence,\nwith high-quality data emerging as a key driver of model performance. This has\nprompted the development of principled and effective data curation methods in\nrecent years. However, existing methods largely rely on heuristics, and whether\nthey are truly effective remains unclear. For instance, standard evaluation\nmethods that assess a trained model's performance on specific benchmarks may\nincentivize assigning high scores to data that merely resembles the test set.\nThis issue exemplifies Goodhart's law: when a measure becomes a target, it\nceases to be a good measure. To address this issue, we propose an\ninformation-theoretic framework for evaluating data curation methods. We define\ndataset quality in terms of its informativeness about the true model\nparameters, formalized using the Blackwell ordering of informativeness. Under\nthis ordering, Blackwell's theorem ensures that more informative data yields\noptimal models with lower expected loss on the true underlying distribution. To\nmeasure informativeness, we show that the Blackwell order can be determined by\nthe Shannon mutual information between the curated data and the test data. To\nestimate this mutual information, we introduce a novel method that trains\nBayesian models on embedded datasets and computes mutual information from the\nposteriors of model parameters. Experiments on real-world data demonstrate that\nour mutual information-based evaluation assigns appropriately lower scores to\ndata curation strategies that reduce dataset informativeness, while traditional\ntest score-based evaluation methods may favor data curation strategies that\noverfit to the test set but compromise the training data's informativeness.", "AI": {"tldr": "The paper proposes an information-theoretic framework to evaluate data curation methods, addressing the limitations of heuristic-based approaches and Goodhart's law.", "motivation": "Existing data curation methods rely on heuristics and may not truly improve model performance, as they can overfit to test sets.", "method": "An information-theoretic framework is introduced, using the Blackwell ordering of informativeness and Shannon mutual information between curated and test data. A Bayesian model-based method estimates this mutual information.", "result": "Experiments show the proposed method correctly identifies data curation strategies that reduce informativeness, unlike traditional test score-based evaluations.", "conclusion": "The framework provides a principled way to evaluate data curation, ensuring data quality aligns with true model performance."}}
{"id": "2505.08463", "pdf": "https://arxiv.org/pdf/2505.08463", "abs": "https://arxiv.org/abs/2505.08463", "authors": ["Fujun Zhang", "Xiaoying Fan", "XiangDong Su", "Guanglai Gao"], "title": "RepCali: High Efficient Fine-tuning Via Representation Calibration in Latent Space for Pre-trained Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "13 pages, 4 figures", "summary": "Fine-tuning pre-trained language models (PLMs) has become a dominant paradigm\nin applying PLMs to downstream tasks. However, with limited fine-tuning, PLMs\nstill struggle with the discrepancies between the representation obtained from\nthe PLMs' encoder and the optimal input to the PLMs' decoder. This paper\ntackles this challenge by learning to calibrate the representation of PLMs in\nthe latent space. In the proposed representation calibration method (RepCali),\nwe integrate a specific calibration block to the latent space after the encoder\nand use the calibrated output as the decoder input. The merits of the proposed\nRepCali include its universality to all PLMs with encoder-decoder\narchitectures, its plug-and-play nature, and ease of implementation. Extensive\nexperiments on 25 PLM-based models across 8 tasks (including both English and\nChinese datasets) demonstrate that the proposed RepCali offers desirable\nenhancements to PLMs (including LLMs) and significantly improves the\nperformance of downstream tasks. Comparison experiments across 4 benchmark\ntasks indicate that RepCali is superior to the representative fine-tuning\nbaselines.", "AI": {"tldr": "The paper introduces RepCali, a method to calibrate representations in pre-trained language models (PLMs) to bridge the gap between encoder outputs and decoder inputs, improving downstream task performance.", "motivation": "PLMs struggle with discrepancies between encoder representations and decoder inputs, limiting their effectiveness despite fine-tuning.", "method": "RepCali integrates a calibration block in the latent space after the encoder, providing a plug-and-play solution for PLMs with encoder-decoder architectures.", "result": "Experiments on 25 PLM-based models across 8 tasks show RepCali enhances performance, outperforming fine-tuning baselines.", "conclusion": "RepCali is a universal, easy-to-implement method that significantly improves PLM performance on downstream tasks."}}
{"id": "2505.17473", "pdf": "https://arxiv.org/pdf/2505.17473", "abs": "https://arxiv.org/abs/2505.17473", "authors": ["Jiangning Zhu", "Yuxing Zhou", "Zheng Wang", "Juntao Yao", "Yima Gu", "Yuhui Yuan", "Shixia Liu"], "title": "OrionBench: A Benchmark for Chart and Human-Recognizable Object Detection in Infographics", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Given the central role of charts in scientific, business, and communication\ncontexts, enhancing the chart understanding capabilities of vision-language\nmodels (VLMs) has become increasingly critical. A key limitation of existing\nVLMs lies in their inaccurate visual grounding of infographic elements,\nincluding charts and human-recognizable objects (HROs) such as icons and\nimages. However, chart understanding often requires identifying relevant\nelements and reasoning over them. To address this limitation, we introduce\nOrionBench, a benchmark designed to support the development of accurate object\ndetection models for charts and HROs in infographics. It contains 26,250 real\nand 78,750 synthetic infographics, with over 6.9 million bounding box\nannotations. These annotations are created by combining the model-in-the-loop\nand programmatic methods. We demonstrate the usefulness of OrionBench through\nthree applications: 1) constructing a Thinking-with-Boxes scheme to boost the\nchart understanding performance of VLMs, 2) comparing existing object detection\nmodels, and 3) applying the developed detection model to document layout and UI\nelement detection.", "AI": {"tldr": "OrionBench is introduced to improve object detection in charts and HROs for VLMs, featuring a large dataset and three applications.", "motivation": "Existing VLMs lack accurate visual grounding for charts and HROs, hindering chart understanding.", "method": "OrionBench combines model-in-the-loop and programmatic methods to create a dataset with 105,000 infographics and 6.9M annotations.", "result": "The benchmark aids in enhancing VLM performance, comparing detection models, and extending to layout/UI detection.", "conclusion": "OrionBench addresses a critical gap in VLM capabilities for chart understanding and object detection."}}
{"id": "2502.17057", "pdf": "https://arxiv.org/pdf/2502.17057", "abs": "https://arxiv.org/abs/2502.17057", "authors": ["Sijia Yao", "Pengcheng Huang", "Zhenghao Liu", "Yu Gu", "Yukun Yan", "Shi Yu", "Ge Yu"], "title": "ExpandR: Teaching Dense Retrievers Beyond Queries with LLM Guidance", "categories": ["cs.IR", "cs.AI"], "comment": "16 pages, 10 tables, 5 figures", "summary": "Large language models (LLMs) have demonstrated significant potential in\nenhancing dense retrieval through query augmentation. However, most existing\nmethods treat the LLM and the retriever as separate modules, overlooking the\nalignment between generation and ranking objectives. In this work, we propose\nExpandR, a unified LLM-augmented dense retrieval framework that jointly\noptimizes both the LLM and the retriever. ExpandR employs the LLM to generate\nsemantically rich query expansions, which are leveraged to enhance the\nretriever's training. Simultaneously, the LLM is trained using Direct\nPreference Optimization (DPO), guided by a carefully designed reward function\nthat balances retrieval effectiveness and generation consistency. This joint\noptimization paradigm enables mutual adaptation between the LLM and the\nretriever, resulting in query expansions that are both informative and\nwell-suited for retrieval. Experimental results on multiple benchmarks show\nthat ExpandR consistently outperforms strong baselines, achieving more than a\n5% improvement in retrieval performance. All codes are available at\nhttps://github.com/NEUIR/ExpandR.", "AI": {"tldr": "ExpandR is a unified framework that jointly optimizes an LLM and a retriever for dense retrieval, improving performance by over 5%.", "motivation": "Existing methods treat LLMs and retrievers separately, missing alignment between generation and ranking objectives.", "method": "ExpandR uses the LLM for query expansions and trains it with DPO, balancing retrieval effectiveness and generation consistency.", "result": "ExpandR outperforms baselines, achieving over 5% improvement in retrieval performance.", "conclusion": "Joint optimization of LLM and retriever in ExpandR enhances retrieval performance effectively."}}
{"id": "2406.09187", "pdf": "https://arxiv.org/pdf/2406.09187", "abs": "https://arxiv.org/abs/2406.09187", "authors": ["Zhen Xiang", "Linzhi Zheng", "Yanjie Li", "Junyuan Hong", "Qinbin Li", "Han Xie", "Jiawei Zhang", "Zidi Xiong", "Chulin Xie", "Carl Yang", "Dawn Song", "Bo Li"], "title": "GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning", "categories": ["cs.LG"], "comment": "Accepted to ICML 2025", "summary": "The rapid advancement of large language model (LLM) agents has raised new\nconcerns regarding their safety and security. In this paper, we propose\nGuardAgent, the first guardrail agent to protect target agents by dynamically\nchecking whether their actions satisfy given safety guard requests.\nSpecifically, GuardAgent first analyzes the safety guard requests to generate a\ntask plan, and then maps this plan into guardrail code for execution. By\nperforming the code execution, GuardAgent can deterministically follow the\nsafety guard request and safeguard target agents. In both steps, an LLM is\nutilized as the reasoning component, supplemented by in-context demonstrations\nretrieved from a memory module storing experiences from previous tasks. In\naddition, we propose two novel benchmarks: EICU-AC benchmark to assess the\naccess control for healthcare agents and Mind2Web-SC benchmark to evaluate the\nsafety policies for web agents. We show that GuardAgent effectively moderates\nthe violation actions for different types of agents on these two benchmarks\nwith over 98% and 83% guardrail accuracies, respectively. Project page:\nhttps://guardagent.github.io/", "AI": {"tldr": "GuardAgent is a guardrail agent for LLMs, dynamically enforcing safety checks via task plans and guardrail code, achieving high accuracy on novel benchmarks.", "motivation": "Addressing safety and security concerns in LLM agents by ensuring their actions comply with predefined safety guard requests.", "method": "GuardAgent uses an LLM to generate task plans and guardrail code, supplemented by in-context demonstrations from a memory module.", "result": "Achieves 98% and 83% guardrail accuracies on EICU-AC and Mind2Web-SC benchmarks, respectively.", "conclusion": "GuardAgent effectively safeguards LLM agents by dynamically enforcing safety policies."}}
{"id": "2505.12864", "pdf": "https://arxiv.org/pdf/2505.12864", "abs": "https://arxiv.org/abs/2505.12864", "authors": ["Yu Fan", "Jingwei Ni", "Jakob Merane", "Etienne Salimbeni", "Yang Tian", "Yoan Hermstr\u00fcwer", "Yinya Huang", "Mubashara Akhtar", "Florian Geering", "Oliver Dreyer", "Daniel Brunner", "Markus Leippold", "Mrinmaya Sachan", "Alexander Stremitzer", "Christoph Engel", "Elliott Ash", "Joel Niklaus"], "title": "LEXam: Benchmarking Legal Reasoning on 340 Law Exams", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50", "I.2"], "comment": null, "summary": "Long-form legal reasoning remains a key challenge for large language models\n(LLMs) in spite of recent advances in test-time scaling. We introduce LEXam, a\nnovel benchmark derived from 340 law exams spanning 116 law school courses\nacross a range of subjects and degree levels. The dataset comprises 4,886 law\nexam questions in English and German, including 2,841 long-form, open-ended\nquestions and 2,045 multiple-choice questions. Besides reference answers, the\nopen questions are also accompanied by explicit guidance outlining the expected\nlegal reasoning approach such as issue spotting, rule recall, or rule\napplication. Our evaluation on both open-ended and multiple-choice questions\npresent significant challenges for current LLMs; in particular, they notably\nstruggle with open questions that require structured, multi-step legal\nreasoning. Moreover, our results underscore the effectiveness of the dataset in\ndifferentiating between models with varying capabilities. Adopting an\nLLM-as-a-Judge paradigm with rigorous human expert validation, we demonstrate\nhow model-generated reasoning steps can be evaluated consistently and\naccurately. Our evaluation setup provides a scalable method to assess legal\nreasoning quality beyond simple accuracy metrics. Project page:\nhttps://lexam-benchmark.github.io/", "AI": {"tldr": "LEXam is a benchmark for evaluating LLMs on legal reasoning, featuring 4,886 law exam questions (open-ended and multiple-choice) in English and German. Current LLMs struggle, especially with structured, multi-step reasoning.", "motivation": "To address the challenge of long-form legal reasoning in LLMs and provide a scalable evaluation method.", "method": "LEXam uses 340 law exams (4,886 questions) with reference answers and explicit reasoning guidance. Evaluation employs LLM-as-a-Judge with human validation.", "result": "LLMs struggle with open-ended questions requiring structured reasoning. The benchmark effectively differentiates model capabilities.", "conclusion": "LEXam offers a scalable, accurate way to assess legal reasoning quality in LLMs, highlighting current limitations."}}
{"id": "2505.17702", "pdf": "https://arxiv.org/pdf/2505.17702", "abs": "https://arxiv.org/abs/2505.17702", "authors": ["Xueyang Li", "Jiahao Li", "Yu Song", "Yunzhong Lou", "Xiangdong Zhou"], "title": "Seek-CAD: A Self-refined Generative Modeling for 3D Parametric CAD Using Local Inference via DeepSeek", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The advent of Computer-Aided Design (CAD) generative modeling will\nsignificantly transform the design of industrial products. The recent research\nendeavor has extended into the realm of Large Language Models (LLMs). In\ncontrast to fine-tuning methods, training-free approaches typically utilize the\nadvanced closed-source LLMs, thereby offering enhanced flexibility and\nefficiency in the development of AI agents for generating CAD parametric\nmodels. However, the substantial cost and limitations of local deployment of\nthe top-tier closed-source LLMs pose challenges in practical applications. The\nSeek-CAD is the pioneer exploration of locally deployed open-source inference\nLLM DeepSeek-R1 for CAD parametric model generation with a training-free\nmethodology. This study is the first investigation to incorporate both visual\nand Chain-of-Thought (CoT) feedback within the self-refinement mechanism for\ngenerating CAD models. Specifically, the initial generated parametric CAD model\nis rendered into a sequence of step-wise perspective images, which are\nsubsequently processed by a Vision Language Model (VLM) alongside the\ncorresponding CoTs derived from DeepSeek-R1 to assess the CAD model generation.\nThen, the feedback is utilized by DeepSeek-R1 to refine the initial generated\nmodel for the next round of generation. Moreover, we present an innovative 3D\nCAD model dataset structured around the SSR (Sketch, Sketch-based feature, and\nRefinements) triple design paradigm. This dataset encompasses a wide range of\nCAD commands, thereby aligning effectively with industrial application\nrequirements and proving suitable for the generation of LLMs. Extensive\nexperiments validate the effectiveness of Seek-CAD under various metrics.", "AI": {"tldr": "Seek-CAD introduces a training-free method using open-source LLM DeepSeek-R1 for CAD parametric model generation, incorporating visual and CoT feedback for refinement, and presents a novel 3D CAD dataset.", "motivation": "To address the high cost and deployment limitations of closed-source LLMs in CAD generative modeling by leveraging open-source alternatives and improving model generation through feedback mechanisms.", "method": "Utilizes DeepSeek-R1 for initial CAD model generation, renders step-wise images, processes them with a VLM and CoT feedback, and refines the model iteratively. Introduces a 3D CAD dataset based on the SSR paradigm.", "result": "Seek-CAD demonstrates effectiveness in generating CAD models through extensive experiments.", "conclusion": "The study successfully pioneers a locally deployable, open-source LLM solution for CAD generative modeling, enhancing flexibility and efficiency."}}
{"id": "2502.18710", "pdf": "https://arxiv.org/pdf/2502.18710", "abs": "https://arxiv.org/abs/2502.18710", "authors": ["Chaitanya Kapoor", "Sudhanshu Srivastava", "Meenakshi Khosla"], "title": "Bridging Critical Gaps in Convergent Learning: How Representational Alignment Evolves Across Layers, Training, and Distribution Shifts", "categories": ["q-bio.NC", "cs.AI"], "comment": null, "summary": "Understanding convergent learning -- the degree to which independently\ntrained neural systems -- whether multiple artificial networks or brains and\nmodels -- arrive at similar internal representations -- is crucial for both\nneuroscience and AI. Yet, the literature remains narrow in scope -- typically\nexamining just a handful of models with one dataset, relying on one alignment\nmetric, and evaluating networks at a single post-training checkpoint. We\npresent a large-scale audit of convergent learning, spanning dozens of vision\nmodels and thousands of layer-pair comparisons, to close these long-standing\ngaps. First, we pit three alignment families against one another -- linear\nregression (affine-invariant), orthogonal Procrustes\n(rotation-/reflection-invariant), and permutation/soft-matching\n(unit-order-invariant). We find that orthogonal transformations align\nrepresentations nearly as effectively as more flexible linear ones, and\nalthough permutation scores are lower, they significantly exceed chance,\nindicating a privileged representational basis. Tracking convergence throughout\ntraining further shows that nearly all eventual alignment crystallizes within\nthe first epoch -- well before accuracy plateaus -- indicating it is largely\ndriven by shared input statistics and architectural biases, not by the final\ntask solution. Finally, when models are challenged with a battery of\nout-of-distribution images, early layers remain tightly aligned, whereas deeper\nlayers diverge in proportion to the distribution shift. These findings fill\ncritical gaps in our understanding of representational convergence, with\nimplications for neuroscience and AI.", "AI": {"tldr": "The paper conducts a large-scale audit of convergent learning in neural systems, comparing alignment metrics and revealing insights about representational convergence driven by shared inputs and architecture, not just task solutions.", "motivation": "To address gaps in understanding convergent learning by examining multiple models, alignment metrics, and training stages, which previous studies lacked.", "method": "The study compares three alignment families (linear regression, orthogonal Procrustes, and permutation/soft-matching) across dozens of vision models and thousands of layer-pair comparisons, tracking convergence throughout training and testing on out-of-distribution images.", "result": "Orthogonal transformations align representations nearly as well as linear ones; permutation scores exceed chance. Alignment crystallizes early in training, driven by shared input statistics and architecture. Deeper layers diverge under distribution shifts.", "conclusion": "The findings advance understanding of representational convergence, highlighting the roles of shared inputs and architecture, with implications for neuroscience and AI."}}
{"id": "2408.12307", "pdf": "https://arxiv.org/pdf/2408.12307", "abs": "https://arxiv.org/abs/2408.12307", "authors": ["Yen-Ru Lai", "Fu-Chieh Chang", "Pei-Yuan Wu"], "title": "Leveraging Unlabeled Data Sharing through Kernel Function Approximation in Offline Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Offline reinforcement learning (RL) learns policies from a fixed dataset, but\noften requires large amounts of data. The challenge arises when labeled\ndatasets are expensive, especially when rewards have to be provided by human\nlabelers for large datasets. In contrast, unlabelled data tends to be less\nexpensive. This situation highlights the importance of finding effective ways\nto use unlabelled data in offline RL, especially when labelled data is limited\nor expensive to obtain. In this paper, we present the algorithm to utilize the\nunlabeled data in the offline RL method with kernel function approximation and\ngive the theoretical guarantee. We present various eigenvalue decay conditions\nof $\\mathcal{H}_k$ which determine the complexity of the algorithm. In summary,\nour work provides a promising approach for exploiting the advantages offered by\nunlabeled data in offline RL, whilst maintaining theoretical assurances.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.14107", "pdf": "https://arxiv.org/pdf/2505.14107", "abs": "https://arxiv.org/abs/2505.14107", "authors": ["Yakun Zhu", "Zhongzhen Huang", "Linjie Mu", "Yutong Huang", "Wei Nie", "Jiaji Liu", "Shaoting Zhang", "Pengfei Liu", "Xiaofan Zhang"], "title": "DiagnosisArena: Benchmarking Diagnostic Reasoning for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The emergence of groundbreaking large language models capable of performing\ncomplex reasoning tasks holds significant promise for addressing various\nscientific challenges, including those arising in complex clinical scenarios.\nTo enable their safe and effective deployment in real-world healthcare\nsettings, it is urgently necessary to benchmark the diagnostic capabilities of\ncurrent models systematically. Given the limitations of existing medical\nbenchmarks in evaluating advanced diagnostic reasoning, we present\nDiagnosisArena, a comprehensive and challenging benchmark designed to\nrigorously assess professional-level diagnostic competence. DiagnosisArena\nconsists of 1,113 pairs of segmented patient cases and corresponding diagnoses,\nspanning 28 medical specialties, deriving from clinical case reports published\nin 10 top-tier medical journals. The benchmark is developed through a\nmeticulous construction pipeline, involving multiple rounds of screening and\nreview by both AI systems and human experts, with thorough checks conducted to\nprevent data leakage. Our study reveals that even the most advanced reasoning\nmodels, o3, o1, and DeepSeek-R1, achieve only 51.12%, 31.09%, and 17.79%\naccuracy, respectively. This finding highlights a significant generalization\nbottleneck in current large language models when faced with clinical diagnostic\nreasoning challenges. Through DiagnosisArena, we aim to drive further\nadvancements in AI's diagnostic reasoning capabilities, enabling more effective\nsolutions for real-world clinical diagnostic challenges. We provide the\nbenchmark and evaluation tools for further research and development\nhttps://github.com/SPIRAL-MED/DiagnosisArena.", "AI": {"tldr": "DiagnosisArena is a new benchmark for evaluating AI diagnostic reasoning in healthcare, revealing current models' limitations.", "motivation": "To address the lack of robust benchmarks for assessing AI diagnostic capabilities in complex clinical scenarios.", "method": "Developed DiagnosisArena with 1,113 patient case-diagnosis pairs from top medical journals, involving AI and human expert reviews.", "result": "Top models achieved low accuracy (51.12%, 31.09%, 17.79%), showing a generalization bottleneck.", "conclusion": "DiagnosisArena aims to advance AI diagnostic reasoning for real-world clinical challenges, with tools available for further research."}}
{"id": "2505.17955", "pdf": "https://arxiv.org/pdf/2505.17955", "abs": "https://arxiv.org/abs/2505.17955", "authors": ["Yujin Jeong", "Arnas Uselis", "Seong Joon Oh", "Anna Rohrbach"], "title": "Diffusion Classifiers Understand Compositionality, but Conditions Apply", "categories": ["cs.CV"], "comment": null, "summary": "Understanding visual scenes is fundamental to human intelligence. While\ndiscriminative models have significantly advanced computer vision, they often\nstruggle with compositional understanding. In contrast, recent generative\ntext-to-image diffusion models excel at synthesizing complex scenes, suggesting\ninherent compositional capabilities. Building on this, zero-shot diffusion\nclassifiers have been proposed to repurpose diffusion models for discriminative\ntasks. While prior work offered promising results in discriminative\ncompositional scenarios, these results remain preliminary due to a small number\nof benchmarks and a relatively shallow analysis of conditions under which the\nmodels succeed. To address this, we present a comprehensive study of the\ndiscriminative capabilities of diffusion classifiers on a wide range of\ncompositional tasks. Specifically, our study covers three diffusion models (SD\n1.5, 2.0, and, for the first time, 3-m) spanning 10 datasets and over 30 tasks.\nFurther, we shed light on the role that target dataset domains play in\nrespective performance; to isolate the domain effects, we introduce a new\ndiagnostic benchmark Self-Bench comprised of images created by diffusion models\nthemselves. Finally, we explore the importance of timestep weighting and\nuncover a relationship between domain gap and timestep sensitivity,\nparticularly for SD3-m. To sum up, diffusion classifiers understand\ncompositionality, but conditions apply! Code and dataset are available at\nhttps://github.com/eugene6923/Diffusion-Classifiers-Compositionality.", "AI": {"tldr": "Diffusion classifiers show promise in compositional understanding but require further analysis of conditions like dataset domains and timestep weighting.", "motivation": "To comprehensively evaluate the discriminative capabilities of diffusion models in compositional tasks, addressing gaps in prior work.", "method": "Study three diffusion models (SD 1.5, 2.0, 3-m) across 10 datasets and 30+ tasks, introducing a diagnostic benchmark (Self-Bench) and analyzing timestep weighting.", "result": "Diffusion classifiers understand compositionality, but performance depends on dataset domains and timestep sensitivity, especially for SD3-m.", "conclusion": "Conditions like domain effects and timestep weighting significantly impact diffusion classifiers' discriminative performance in compositional tasks."}}
{"id": "2502.18807", "pdf": "https://arxiv.org/pdf/2502.18807", "abs": "https://arxiv.org/abs/2502.18807", "authors": ["Ruifeng Tan", "Weixiang Hong", "Jiayue Tang", "Xibin Lu", "Ruijun Ma", "Xiang Zheng", "Jia Li", "Jiaqiang Huang", "Tong-Yi Zhang"], "title": "BatteryLife: A Comprehensive Dataset and Benchmark for Battery Life Prediction", "categories": ["cs.LG", "cs.AI", "cs.DL"], "comment": "Accepted by KDD 2025", "summary": "Battery Life Prediction (BLP), which relies on time series data produced by\nbattery degradation tests, is crucial for battery utilization, optimization,\nand production. Despite impressive advancements, this research area faces three\nkey challenges. Firstly, the limited size of existing datasets impedes insights\ninto modern battery life data. Secondly, most datasets are restricted to\nsmall-capacity lithium-ion batteries tested under a narrow range of diversity\nin labs, raising concerns about the generalizability of findings. Thirdly,\ninconsistent and limited benchmarks across studies obscure the effectiveness of\nbaselines and leave it unclear if models popular in other time series fields\nare effective for BLP. To address these challenges, we propose BatteryLife, a\ncomprehensive dataset and benchmark for BLP. BatteryLife integrates 16\ndatasets, offering a 2.5 times sample size compared to the previous largest\ndataset, and provides the most diverse battery life resource with batteries\nfrom 8 formats, 59 chemical systems, 9 operating temperatures, and 421\ncharge/discharge protocols, including both laboratory and industrial tests.\nNotably, BatteryLife is the first to release battery life datasets of zinc-ion\nbatteries, sodium-ion batteries, and industry-tested large-capacity lithium-ion\nbatteries. With the comprehensive dataset, we revisit the effectiveness of\nbaselines popular in this and other time series fields. Furthermore, we propose\nCyclePatch, a plug-in technique that can be employed in various neural\nnetworks. Extensive benchmarking of 18 methods reveals that models popular in\nother time series fields can be unsuitable for BLP, and CyclePatch consistently\nimproves model performance establishing state-of-the-art benchmarks. Moreover,\nBatteryLife evaluates model performance across aging conditions and domains.\nBatteryLife is available at https://github.com/Ruifeng-Tan/BatteryLife.", "AI": {"tldr": "The paper introduces BatteryLife, a comprehensive dataset and benchmark for Battery Life Prediction (BLP), addressing challenges like limited dataset size, lack of diversity, and inconsistent benchmarks. It also proposes CyclePatch, a plug-in technique improving model performance.", "motivation": "Addressing key challenges in BLP research: limited dataset size, lack of diversity in battery types and testing conditions, and inconsistent benchmarks.", "method": "Proposes BatteryLife, integrating 16 datasets with diverse battery types and conditions, and introduces CyclePatch, a plug-in technique for neural networks.", "result": "BatteryLife offers 2.5 times more samples than previous datasets and includes diverse battery types. CyclePatch improves model performance, establishing state-of-the-art benchmarks.", "conclusion": "BatteryLife and CyclePatch address critical gaps in BLP research, providing a robust dataset and enhancing model performance across diverse conditions."}}
{"id": "2408.14774", "pdf": "https://arxiv.org/pdf/2408.14774", "abs": "https://arxiv.org/abs/2408.14774", "authors": ["Simran Kaur", "Simon Park", "Anirudh Goyal", "Sanjeev Arora"], "title": "Instruct-SkillMix: A Powerful Pipeline for LLM Instruction Tuning", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "We introduce Instruct-SkillMix, an automated approach for creating diverse,\nhigh quality SFT data for instruction-following. The pipeline involves two\nstages, each leveraging an existing powerful LLM: (1) Skill extraction: uses\nthe LLM to extract core \"skills\" for instruction-following by directly\nprompting the model. This is inspired by ``LLM metacognition'' of Didolkar et\nal. (2024); (2) Data generation: uses the powerful LLM to generate\n(instruction, response) data that exhibit a randomly chosen pair of these\nskills. Here, the use of random skill combinations promotes diversity and\ndifficulty. The estimated cost of creating the dataset is under $600.\n  Vanilla SFT (i.e., no PPO, DPO, or RL methods) on data generated from\nInstruct-SkillMix leads to strong gains on instruction following benchmarks\nsuch as AlpacaEval 2.0, MT-Bench, and WildBench. With just 4K examples,\nLLaMA-3-8B-Base achieves 42.76% length-controlled win rate on AlpacaEval 2.0, a\nlevel similar to frontier models like Claude 3 Opus and\nLLaMA-3.1-405B-Instruct. Ablation studies also suggest plausible reasons for\nwhy creating open instruction-tuning datasets via naive crowd-sourcing has\nproved difficult. In our dataset, adding 20% low quality answers (``shirkers'')\ncauses a noticeable degradation in performance. The Instruct-SkillMix pipeline\nseems flexible and adaptable to other settings.", "AI": {"tldr": "Instruct-SkillMix automates diverse SFT data creation for instruction-following using LLMs, achieving strong benchmark results at low cost.", "motivation": "To address the challenge of creating high-quality, diverse instruction-following datasets efficiently.", "method": "Two-stage pipeline: (1) skill extraction via LLM prompting, (2) data generation with random skill combinations.", "result": "Vanilla SFT on Instruct-SkillMix data improves benchmarks (e.g., AlpacaEval 2.0) with just 4K examples, rivaling frontier models.", "conclusion": "Instruct-SkillMix is cost-effective, flexible, and highlights pitfalls of naive crowd-sourcing for dataset creation."}}
{"id": "2505.14279", "pdf": "https://arxiv.org/pdf/2505.14279", "abs": "https://arxiv.org/abs/2505.14279", "authors": ["Jennifer D'Souza", "Hamed Babaei Giglou", "Quentin M\u00fcnch"], "title": "YESciEval: Robust LLM-as-a-Judge for Scientific Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 4 figures, Accepted as a Long Paper at the 63rd Annual\n  Meeting of the Association for Computational Linguistics (ACL 2025)", "summary": "Large Language Models (LLMs) drive scientific question-answering on modern\nsearch engines, yet their evaluation robustness remains underexplored. We\nintroduce YESciEval, an open-source framework that combines fine-grained\nrubric-based assessment with reinforcement learning to mitigate optimism bias\nin LLM evaluators. We release multidisciplinary scienceQ&A datasets, including\nadversarial variants, with evaluation scores from multiple LLMs. Independent of\nproprietary models and human feedback, our approach enables scalable, cost-free\nevaluation. By advancing reliable LLM-as-a-judge models, this work supports AI\nalignment and fosters robust, transparent evaluation essential for scientific\ninquiry.", "AI": {"tldr": "YESciEval is an open-source framework for robust evaluation of LLMs in scientific Q&A, using rubric-based assessment and reinforcement learning to reduce bias.", "motivation": "Addressing the underexplored robustness of LLM evaluations in scientific question-answering.", "method": "Combines fine-grained rubric-based assessment with reinforcement learning, using multidisciplinary datasets and adversarial variants.", "result": "Enables scalable, cost-free evaluation without proprietary models or human feedback.", "conclusion": "Advances reliable LLM-as-a-judge models, supporting AI alignment and transparent evaluation for scientific inquiry."}}
{"id": "2505.18477", "pdf": "https://arxiv.org/pdf/2505.18477", "abs": "https://arxiv.org/abs/2505.18477", "authors": ["Fukun Liu", "Adam T. Greer", "Gengchen Mai", "Jin Sun"], "title": "ZooplanktonBench: A Geo-Aware Zooplankton Recognition and Classification Dataset from Marine Observations", "categories": ["cs.CV"], "comment": "Accepted to KDD 2025 Datasets and Benchmarks Track", "summary": "Plankton are small drifting organisms found throughout the world's oceans and\ncan be indicators of ocean health. One component of this plankton community is\nthe zooplankton, which includes gelatinous animals and crustaceans (e.g.\nshrimp), as well as the early life stages (i.e., eggs and larvae) of many\ncommercially important fishes. Being able to monitor zooplankton abundances\naccurately and understand how populations change in relation to ocean\nconditions is invaluable to marine science research, with important\nimplications for future marine seafood productivity. While new imaging\ntechnologies generate massive amounts of video data of zooplankton, analyzing\nthem using general-purpose computer vision tools turns out to be highly\nchallenging due to the high similarity in appearance between the zooplankton\nand its background (e.g., marine snow). In this work, we present the\nZooplanktonBench, a benchmark dataset containing images and videos of\nzooplankton associated with rich geospatial metadata (e.g., geographic\ncoordinates, depth, etc.) in various water ecosystems. ZooplanktonBench defines\na collection of tasks to detect, classify, and track zooplankton in challenging\nsettings, including highly cluttered environments, living vs non-living\nclassification, objects with similar shapes, and relatively small objects. Our\ndataset presents unique challenges and opportunities for state-of-the-art\ncomputer vision systems to evolve and improve visual understanding in dynamic\nenvironments characterized by significant variation and the need for\ngeo-awareness. The code and settings described in this paper can be found on\nour website: https://lfk118.github.io/ZooplanktonBench_Webpage.", "AI": {"tldr": "The paper introduces ZooplanktonBench, a benchmark dataset for detecting, classifying, and tracking zooplankton in challenging ocean environments, aiding marine science research.", "motivation": "Zooplankton are vital indicators of ocean health, but analyzing them with general computer vision tools is difficult due to their similarity to backgrounds like marine snow.", "method": "The authors present ZooplanktonBench, a dataset with images, videos, and geospatial metadata, defining tasks for detection, classification, and tracking in cluttered environments.", "result": "The dataset provides unique challenges for improving computer vision in dynamic, geo-aware ocean settings.", "conclusion": "ZooplanktonBench aims to advance marine research by enhancing visual understanding of zooplankton populations."}}
{"id": "2503.04779", "pdf": "https://arxiv.org/pdf/2503.04779", "abs": "https://arxiv.org/abs/2503.04779", "authors": ["Thanh Le-Cong", "Bach Le", "Toby Murray"], "title": "Can LLMs Reason About Program Semantics? A Comprehensive Evaluation of LLMs on Formal Specification Inference", "categories": ["cs.PL", "cs.AI", "cs.SE"], "comment": "Accepted to ACL 2025 (Main Conference)", "summary": "Large Language Models (LLMs) are increasingly being used to automate\nprogramming tasks. Yet, LLMs' capabilities in reasoning about program semantics\nare still inadequately studied, leaving significant potential for further\nexploration. This paper introduces FormalBench, a comprehensive benchmark\ndesigned to evaluate LLMs' reasoning abilities on program semantics,\nparticularly via the task of synthesizing formal program specifications to\nassist verifying program correctness. This task requires both comprehensive\nreasoning over all possible program executions and the generation of precise,\nsyntactically correct expressions that adhere to formal syntax and semantics.\nUsing this benchmark, we evaluated the ability of LLMs in synthesizing\nconsistent and complete specifications. Our findings show that LLMs perform\nwell with simple control flows but struggle with more complex structures,\nespecially loops, even with advanced prompting. Additionally, LLMs exhibit\nlimited robustness against semantic-preserving transformations. We also\nhighlight common failure patterns and design self-repair prompts, improving\nsuccess rates by 25%.", "AI": {"tldr": "FormalBench evaluates LLMs' reasoning on program semantics, showing strengths in simple tasks but weaknesses in complex structures like loops. Self-repair prompts improve performance by 25%.", "motivation": "LLMs' reasoning about program semantics is understudied, leaving potential unexplored. FormalBench aims to fill this gap by evaluating LLMs' ability to synthesize formal program specifications.", "method": "The paper introduces FormalBench, a benchmark for assessing LLMs' reasoning on program semantics, focusing on synthesizing formal specifications for program verification.", "result": "LLMs perform well with simple control flows but struggle with complex structures (e.g., loops) and semantic-preserving transformations. Self-repair prompts boost success rates by 25%.", "conclusion": "LLMs have potential in program semantics reasoning but need improvement for complex tasks. Self-repair techniques can enhance performance."}}
{"id": "2409.02064", "pdf": "https://arxiv.org/pdf/2409.02064", "abs": "https://arxiv.org/abs/2409.02064", "authors": ["Shamsiiat Abdurakhmanova", "Amirhossein Mohammadi", "Yasmin SarcheshmehPour", "Alexander Jung"], "title": "Your Data, My Model: Learning Who Really Helps in Federated Learning", "categories": ["cs.LG", "68T05", "I.2.6; I.2.11"], "comment": null, "summary": "Many important machine learning applications involve networks of devices-such\nas wearables or smartphones-that generate local data and train personalized\nmodels. A key challenge is determining which peers are most beneficial for\ncollaboration. We propose a simple and privacy-preserving method to select\nrelevant collaborators by evaluating how much a model improves after a single\ngradient step using another devices data-without sharing raw data. This method\nnaturally extends to non-parametric models by replacing the gradient step with\na non-parametric generalization. Our approach enables model-agnostic,\ndata-driven peer selection for personalized federated learning (PersFL).", "AI": {"tldr": "A privacy-preserving method for selecting beneficial collaborators in federated learning by evaluating model improvement after a single gradient step.", "motivation": "To address the challenge of identifying the most beneficial peers for collaboration in personalized federated learning without sharing raw data.", "method": "Evaluates model improvement after a single gradient step using another device's data; extends to non-parametric models by replacing the gradient step with a non-parametric generalization.", "result": "Enables model-agnostic, data-driven peer selection for personalized federated learning (PersFL).", "conclusion": "The proposed method is simple, privacy-preserving, and effective for selecting relevant collaborators in federated learning."}}
{"id": "2505.16983", "pdf": "https://arxiv.org/pdf/2505.16983", "abs": "https://arxiv.org/abs/2505.16983", "authors": ["Junlong Tong", "Jinlan Fu", "Zixuan Lin", "Yingqi Fan", "Anhao Zhao", "Hui Su", "Xiaoyu Shen"], "title": "LLM as Effective Streaming Processor: Bridging Streaming-Batch Mismatches with Group Position Encoding", "categories": ["cs.CL"], "comment": "ACL 2025 Findings", "summary": "Large Language Models (LLMs) are primarily designed for batch processing.\nExisting methods for adapting LLMs to streaming rely either on expensive\nre-encoding or specialized architectures with limited scalability. This work\nidentifies three key mismatches in adapting batch-oriented LLMs to streaming:\n(1) input-attention, (2) output-attention, and (3) position-ID mismatches.\nWhile it is commonly assumed that the latter two mismatches require frequent\nre-encoding, our analysis reveals that only the input-attention mismatch\nsignificantly impacts performance, indicating re-encoding outputs is largely\nunnecessary. To better understand this discrepancy with the common assumption,\nwe provide the first comprehensive analysis of the impact of position encoding\non LLMs in streaming, showing that preserving relative positions within source\nand target contexts is more critical than maintaining absolute order. Motivated\nby the above analysis, we introduce a group position encoding paradigm built on\nbatch architectures to enhance consistency between streaming and batch modes.\nExtensive experiments on cross-lingual and cross-modal tasks demonstrate that\nour method outperforms existing approaches. Our method requires no\narchitectural modifications, exhibits strong generalization in both streaming\nand batch modes. The code is available at repository\nhttps://github.com/EIT-NLP/StreamingLLM.", "AI": {"tldr": "The paper addresses mismatches in adapting batch-oriented LLMs to streaming, focusing on input-attention as the key issue. It introduces a group position encoding method to improve consistency between streaming and batch modes without architectural changes.", "motivation": "Existing methods for adapting LLMs to streaming are costly or lack scalability. The paper identifies key mismatches and challenges the assumption that frequent re-encoding is necessary.", "method": "Introduces a group position encoding paradigm to enhance consistency between streaming and batch modes, leveraging batch architectures without modifications.", "result": "The method outperforms existing approaches in cross-lingual and cross-modal tasks, showing strong generalization in both streaming and batch modes.", "conclusion": "The proposed group position encoding effectively addresses streaming adaptation for LLMs, offering a scalable and efficient solution without architectural changes."}}
{"id": "2505.18686", "pdf": "https://arxiv.org/pdf/2505.18686", "abs": "https://arxiv.org/abs/2505.18686", "authors": ["Yang Liu", "Silin Cheng", "Xinwei He", "Sebastien Ourselin", "Lei Tan", "Gen Luo"], "title": "WeakMCN: Multi-task Collaborative Network for Weakly Supervised Referring Expression Comprehension and Segmentation", "categories": ["cs.CV"], "comment": "Accepted by CVPR2025", "summary": "Weakly supervised referring expression comprehension(WREC) and\nsegmentation(WRES) aim to learn object grounding based on a given expression\nusing weak supervision signals like image-text pairs. While these tasks have\ntraditionally been modeled separately, we argue that they can benefit from\njoint learning in a multi-task framework. To this end, we propose WeakMCN, a\nnovel multi-task collaborative network that effectively combines WREC and WRES\nwith a dual-branch architecture. Specifically, the WREC branch is formulated as\nanchor-based contrastive learning, which also acts as a teacher to supervise\nthe WRES branch. In WeakMCN, we propose two innovative designs to facilitate\nmulti-task collaboration, namely Dynamic Visual Feature Enhancement(DVFE) and\nCollaborative Consistency Module(CCM). DVFE dynamically combines various\npre-trained visual knowledge to meet different task requirements, while CCM\npromotes cross-task consistency from the perspective of optimization. Extensive\nexperimental results on three popular REC and RES benchmarks, i.e., RefCOCO,\nRefCOCO+, and RefCOCOg, consistently demonstrate performance gains of WeakMCN\nover state-of-the-art single-task alternatives, e.g., up to 3.91% and 13.11% on\nRefCOCO for WREC and WRES tasks, respectively. Furthermore, experiments also\nvalidate the strong generalization ability of WeakMCN in both semi-supervised\nREC and RES settings against existing methods, e.g., +8.94% for semi-REC and\n+7.71% for semi-RES on 1% RefCOCO. The code is publicly available at\nhttps://github.com/MRUIL/WeakMCN.", "AI": {"tldr": "WeakMCN is a multi-task framework combining WREC and WRES with a dual-branch architecture, achieving superior performance and generalization.", "motivation": "Joint learning of WREC and WRES can benefit from multi-task collaboration, improving performance over single-task methods.", "method": "WeakMCN uses a dual-branch architecture with anchor-based contrastive learning for WREC and teacher-student supervision for WRES, enhanced by DVFE and CCM.", "result": "WeakMCN outperforms state-of-the-art single-task methods by up to 3.91% (WREC) and 13.11% (WRES) on RefCOCO, and shows strong generalization in semi-supervised settings.", "conclusion": "WeakMCN demonstrates the effectiveness of multi-task learning for WREC and WRES, offering significant performance gains and generalization."}}
{"id": "2503.18314", "pdf": "https://arxiv.org/pdf/2503.18314", "abs": "https://arxiv.org/abs/2503.18314", "authors": ["Christoforos N. Spartalis", "Theodoros Semertzidis", "Efstratios Gavves", "Petros Daras"], "title": "LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted as a main conference paper at CVPR 2025\n  (https://cvpr.thecvf.com/virtual/2025/poster/33292)", "summary": "We present LoTUS, a novel Machine Unlearning (MU) method that eliminates the\ninfluence of training samples from pre-trained models, avoiding retraining from\nscratch. LoTUS smooths the prediction probabilities of the model up to an\ninformation-theoretic bound, mitigating its over-confidence stemming from data\nmemorization. We evaluate LoTUS on Transformer and ResNet18 models against\neight baselines across five public datasets. Beyond established MU benchmarks,\nwe evaluate unlearning on ImageNet1k, a large-scale dataset, where retraining\nis impractical, simulating real-world conditions. Moreover, we introduce the\nnovel Retrain-Free Jensen-Shannon Divergence (RF-JSD) metric to enable\nevaluation under real-world conditions. The experimental results show that\nLoTUS outperforms state-of-the-art methods in terms of both efficiency and\neffectiveness. Code: https://github.com/cspartalis/LoTUS.", "AI": {"tldr": "LoTUS is a Machine Unlearning method that removes training sample influence without retraining, outperforming baselines in efficiency and effectiveness.", "motivation": "To avoid costly retraining and mitigate over-confidence from data memorization in pre-trained models.", "method": "LoTUS smooths prediction probabilities up to an information-theoretic bound and introduces RF-JSD for evaluation.", "result": "Outperforms eight baselines on five datasets, including large-scale ImageNet1k, under real-world conditions.", "conclusion": "LoTUS is efficient and effective for Machine Unlearning, validated by novel metrics and large-scale experiments."}}
{"id": "2409.13931", "pdf": "https://arxiv.org/pdf/2409.13931", "abs": "https://arxiv.org/abs/2409.13931", "authors": ["Dongyang Fan", "Bettina Messmer", "Nikita Doikov", "Martin Jaggi"], "title": "On-Device Collaborative Language Modeling via a Mixture of Generalists and Specialists", "categories": ["cs.LG", "cs.CL"], "comment": "Camera-ready version", "summary": "On-device LLMs have gained increasing attention for their ability to enhance\nprivacy and provide a personalized user experience. To facilitate private\nlearning with scarce data, Federated Learning has become a standard approach.\nHowever, it faces challenges such as computational resource heterogeneity and\ndata heterogeneity among end users. We propose CoMiGS ($\\textbf{Co}$llaborative\nlearning with a $\\textbf{Mi}$xture of $\\textbf{G}$eneralists and\n$\\textbf{S}$pecialists), the first approach to address both challenges. A key\ninnovation of our method is the bi-level optimization formulation of the\nMixture-of-Experts learning objective, where the router is optimized using a\nseparate validation set to ensure alignment with the target distribution. We\nsolve our objective with alternating minimization, for which we provide a\ntheoretical analysis. Our method shares generalist experts across users while\nlocalizing a varying number of specialist experts, thereby adapting to users'\ncomputational resources and preserving privacy. Through extensive experiments,\nwe show CoMiGS effectively balances general and personalized knowledge for each\ntoken generation. We demonstrate that CoMiGS remains robust against\noverfitting-due to the generalists' regularizing effect-while adapting to local\ndata through specialist expertise. We open source our codebase for\ncollaborative LLMs.", "AI": {"tldr": "CoMiGS is a novel method for on-device LLMs using a mixture of generalists and specialists to address computational and data heterogeneity in Federated Learning, ensuring privacy and personalization.", "motivation": "To enhance privacy and provide personalized experiences in on-device LLMs while overcoming challenges like computational and data heterogeneity in Federated Learning.", "method": "Bi-level optimization of Mixture-of-Experts, with alternating minimization, sharing generalists and localizing specialists.", "result": "CoMiGS balances general and personalized knowledge, remains robust against overfitting, and adapts to local data.", "conclusion": "CoMiGS effectively addresses key challenges in Federated Learning for LLMs, offering a scalable and privacy-preserving solution."}}
{"id": "2505.17139", "pdf": "https://arxiv.org/pdf/2505.17139", "abs": "https://arxiv.org/abs/2505.17139", "authors": ["Wanghan Xu", "Xiangyu Zhao", "Yuhao Zhou", "Xiaoyu Yue", "Ben Fei", "Fenghua Ling", "Wenlong Zhang", "Lei Bai"], "title": "EarthSE: A Benchmark Evaluating Earth Scientific Exploration Capability for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Advancements in Large Language Models (LLMs) drive interest in scientific\napplications, necessitating specialized benchmarks such as Earth science.\nExisting benchmarks either present a general science focus devoid of Earth\nscience specificity or cover isolated subdomains, lacking holistic evaluation.\nFurthermore, current benchmarks typically neglect the assessment of LLMs'\ncapabilities in open-ended scientific exploration. In this paper, we present a\ncomprehensive and professional benchmark for the Earth sciences, designed to\nevaluate the capabilities of LLMs in scientific exploration within this domain,\nspanning from fundamental to advanced levels. Leveraging a corpus of 100,000\nresearch papers, we first construct two Question Answering (QA) datasets:\nEarth-Iron, which offers extensive question coverage for broad assessment, and\nEarth-Silver, which features a higher level of difficulty to evaluate\nprofessional depth. These datasets encompass five Earth spheres, 114\ndisciplines, and 11 task categories, assessing foundational knowledge crucial\nfor scientific exploration. Most notably, we introduce Earth-Gold with new\nmetrics, a dataset comprising open-ended multi-turn dialogues specifically\ndesigned to evaluate the advanced capabilities of LLMs in scientific\nexploration, including methodology induction, limitation analysis, and concept\nproposal. Extensive experiments reveal limitations in 11 leading LLMs across\ndifferent domains and tasks, highlighting considerable room for improvement in\ntheir scientific exploration capabilities. The benchmark is available on\nhttps://huggingface.co/ai-earth .", "AI": {"tldr": "A new benchmark for evaluating LLMs in Earth science is introduced, covering broad and advanced capabilities, revealing limitations in current models.", "motivation": "Existing benchmarks lack Earth science specificity and neglect open-ended scientific exploration, necessitating a specialized evaluation tool.", "method": "Constructed two QA datasets (Earth-Iron and Earth-Silver) and introduced Earth-Gold for open-ended dialogues, using 100,000 research papers.", "result": "Experiments show limitations in 11 leading LLMs, indicating significant room for improvement in scientific exploration.", "conclusion": "The benchmark provides a comprehensive tool for assessing LLMs in Earth science, highlighting gaps in current capabilities."}}
{"id": "2505.19256", "pdf": "https://arxiv.org/pdf/2505.19256", "abs": "https://arxiv.org/abs/2505.19256", "authors": ["Vivek Gopalakrishnan", "Neel Dey", "Polina Golland"], "title": "PolyPose: Localizing Deformable Anatomy in 3D from Sparse 2D X-ray Images using Polyrigid Transforms", "categories": ["cs.CV", "physics.med-ph"], "comment": "Code available at https://github.com/eigenvivek/polypose", "summary": "Determining the 3D pose of a patient from a limited set of 2D X-ray images is\na critical task in interventional settings. While preoperative volumetric\nimaging (e.g., CT and MRI) provides precise 3D localization and visualization\nof anatomical targets, these modalities cannot be acquired during procedures,\nwhere fast 2D imaging (X-ray) is used instead. To integrate volumetric guidance\ninto intraoperative procedures, we present PolyPose, a simple and robust method\nfor deformable 2D/3D registration. PolyPose parameterizes complex 3D\ndeformation fields as a composition of rigid transforms, leveraging the\nbiological constraint that individual bones do not bend in typical motion.\nUnlike existing methods that either assume no inter-joint movement or fail\noutright in this under-determined setting, our polyrigid formulation enforces\nanatomically plausible priors that respect the piecewise rigid nature of human\nmovement. This approach eliminates the need for expensive deformation\nregularizers that require patient- and procedure-specific hyperparameter\noptimization. Across extensive experiments on diverse datasets from orthopedic\nsurgery and radiotherapy, we show that this strong inductive bias enables\nPolyPose to successfully align the patient's preoperative volume to as few as\ntwo X-ray images, thereby providing crucial 3D guidance in challenging\nsparse-view and limited-angle settings where current registration methods fail.", "AI": {"tldr": "PolyPose is a method for 2D/3D registration in medical imaging, using rigid transforms to model bone movement, enabling accurate 3D guidance from sparse X-ray images.", "motivation": "Integrate volumetric guidance into intraoperative procedures where only 2D X-ray images are available, overcoming limitations of existing methods.", "method": "PolyPose parameterizes 3D deformation fields as a composition of rigid transforms, respecting the piecewise rigid nature of human bones.", "result": "Successfully aligns preoperative volumes to as few as two X-ray images, outperforming current methods in sparse-view and limited-angle settings.", "conclusion": "PolyPose provides robust and anatomically plausible 3D guidance in challenging clinical scenarios without needing complex regularization."}}
{"id": "2504.00035", "pdf": "https://arxiv.org/pdf/2504.00035", "abs": "https://arxiv.org/abs/2504.00035", "authors": ["Ziwei Zhang", "Juan Wen", "Wanli Peng", "Zhengxian Wu", "Yinghan Zhou", "Yiming Xue"], "title": "MiZero: The Shadowy Defender Against Text Style Infringements", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "In-Context Learning (ICL) and efficient fine-tuning methods significantly\nenhanced the efficiency of applying Large Language Models (LLMs) to downstream\ntasks. However, they also raise concerns about the imitation and infringement\nof personal creative data. Current methods for data copyright protection\nprimarily focuses on content security but lacks effectiveness in protecting the\ncopyrights of text styles. In this paper, we introduce a novel implicit\nzero-watermarking scheme, namely MiZero. This scheme establishes a precise\nwatermark domain to protect the copyrighted style, surpassing traditional\nwatermarking methods that distort the style characteristics. Specifically, we\nemploy LLMs to extract condensed-lists utilizing the designed instance\ndelimitation mechanism. These lists guide MiZero in generating the watermark.\nExtensive experiments demonstrate that MiZero effectively verifies text style\ncopyright ownership against AI imitation.", "AI": {"tldr": "MiZero introduces an implicit zero-watermarking scheme to protect text style copyrights in LLMs, outperforming traditional methods.", "motivation": "Addressing the lack of effective copyright protection for text styles in LLMs, which current methods fail to safeguard.", "method": "Uses LLMs to extract condensed-lists via instance delimitation, guiding watermark generation without distorting style.", "result": "MiZero effectively verifies text style copyright ownership against AI imitation in experiments.", "conclusion": "MiZero provides a robust solution for protecting text style copyrights in LLM applications."}}
{"id": "2409.18061", "pdf": "https://arxiv.org/pdf/2409.18061", "abs": "https://arxiv.org/abs/2409.18061", "authors": ["Francesco Mori", "Stefano Sarao Mannelli", "Francesca Mignacco"], "title": "Optimal Protocols for Continual Learning via Statistical Physics and Control Theory", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech"], "comment": "22 pages, 12 figures", "summary": "Artificial neural networks often struggle with catastrophic forgetting when\nlearning multiple tasks sequentially, as training on new tasks degrades the\nperformance on previously learned tasks. Recent theoretical work has addressed\nthis issue by analysing learning curves in synthetic frameworks under\npredefined training protocols. However, these protocols relied on heuristics\nand lacked a solid theoretical foundation assessing their optimality. In this\npaper, we fill this gap by combining exact equations for training dynamics,\nderived using statistical physics techniques, with optimal control methods. We\napply this approach to teacher-student models for continual learning and\nmulti-task problems, obtaining a theory for task-selection protocols maximising\nperformance while minimising forgetting. Our theoretical analysis offers\nnon-trivial yet interpretable strategies for mitigating catastrophic\nforgetting, shedding light on how optimal learning protocols modulate\nestablished effects, such as the influence of task similarity on forgetting.\nFinally, we validate our theoretical findings with experiments on real-world\ndata.", "AI": {"tldr": "The paper addresses catastrophic forgetting in neural networks by combining statistical physics and optimal control to derive optimal task-selection protocols, validated on real-world data.", "motivation": "Artificial neural networks suffer from catastrophic forgetting when learning tasks sequentially, and existing protocols lack theoretical optimality.", "method": "Combines exact training dynamics equations (from statistical physics) with optimal control methods, applied to teacher-student models for continual learning.", "result": "Derives non-trivial, interpretable strategies for task-selection to maximize performance and minimize forgetting, including insights on task similarity.", "conclusion": "The theoretical framework provides optimal protocols for mitigating catastrophic forgetting, validated experimentally."}}
{"id": "2505.17656", "pdf": "https://arxiv.org/pdf/2505.17656", "abs": "https://arxiv.org/abs/2505.17656", "authors": ["Hexiang Tan", "Fei Sun", "Sha Liu", "Du Su", "Qi Cao", "Xin Chen", "Jingang Wang", "Xunliang Cai", "Yuanzhuo Wang", "Huawei Shen", "Xueqi Cheng"], "title": "Too Consistent to Detect: A Study of Self-Consistent Errors in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "As large language models (LLMs) often generate plausible but incorrect\ncontent, error detection has become increasingly critical to ensure\ntruthfulness. However, existing detection methods often overlook a critical\nproblem we term as self-consistent error, where LLMs repeatly generate the same\nincorrect response across multiple stochastic samples. This work formally\ndefines self-consistent errors and evaluates mainstream detection methods on\nthem. Our investigation reveals two key findings: (1) Unlike inconsistent\nerrors, whose frequency diminishes significantly as LLM scale increases, the\nfrequency of self-consistent errors remains stable or even increases. (2) All\nfour types of detection methshods significantly struggle to detect\nself-consistent errors. These findings reveal critical limitations in current\ndetection methods and underscore the need for improved methods. Motivated by\nthe observation that self-consistent errors often differ across LLMs, we\npropose a simple but effective cross-model probe method that fuses hidden state\nevidence from an external verifier LLM. Our method significantly enhances\nperformance on self-consistent errors across three LLM families.", "AI": {"tldr": "The paper addresses self-consistent errors in LLMs, where incorrect responses are repeated across samples. It evaluates detection methods, finding they struggle with such errors, and proposes a cross-model probe method to improve detection.", "motivation": "Large language models (LLMs) often generate plausible but incorrect content, and existing detection methods fail to address self-consistent errors, where LLMs repeatedly produce the same incorrect response.", "method": "The work formally defines self-consistent errors, evaluates mainstream detection methods on them, and proposes a cross-model probe method using hidden state evidence from an external verifier LLM.", "result": "Key findings: (1) Self-consistent errors persist or increase with LLM scale, unlike inconsistent errors. (2) Current detection methods struggle with self-consistent errors. The proposed method improves detection across three LLM families.", "conclusion": "The study highlights limitations in current error detection methods and demonstrates the effectiveness of a cross-model probe approach for detecting self-consistent errors in LLMs."}}
{"id": "2505.19328", "pdf": "https://arxiv.org/pdf/2505.19328", "abs": "https://arxiv.org/abs/2505.19328", "authors": ["Manuela Gonz\u00e1lez-Gonz\u00e1lez", "Soufiane Belharbi", "Muhammad Osama Zeeshan", "Masoumeh Sharafi", "Muhammad Haseeb Aslam", "Marco Pedersoli", "Alessandro Lameiras Koerich", "Simon L Bacon", "Eric Granger"], "title": "BAH Dataset for Ambivalence/Hesitancy Recognition in Videos for Behavioural Change", "categories": ["cs.CV", "cs.LG"], "comment": "41 pages, 13 figures, under review", "summary": "Recognizing complex emotions linked to ambivalence and hesitancy (A/H) can\nplay a critical role in the personalization and effectiveness of digital\nbehaviour change interventions. These subtle and conflicting emotions are\nmanifested by a discord between multiple modalities, such as facial and vocal\nexpressions, and body language. Although experts can be trained to identify\nA/H, integrating them into digital interventions is costly and less effective.\nAutomatic learning systems provide a cost-effective alternative that can adapt\nto individual users, and operate seamlessly within real-time, and\nresource-limited environments. However, there are currently no datasets\navailable for the design of ML models to recognize A/H. This paper introduces a\nfirst Behavioural Ambivalence/Hesitancy (BAH) dataset collected for\nsubject-based multimodal recognition of A/H in videos. It contains videos from\n224 participants captured across 9 provinces in Canada, with different age, and\nethnicity. Through our web platform, we recruited participants to answer 7\nquestions, some of which were designed to elicit A/H while recording themselves\nvia webcam with microphone. BAH amounts to 1,118 videos for a total duration of\n8.26 hours with 1.5 hours of A/H. Our behavioural team annotated timestamp\nsegments to indicate where A/H occurs, and provide frame- and video-level\nannotations with the A/H cues. Video transcripts and their timestamps are also\nincluded, along with cropped and aligned faces in each frame, and a variety of\nparticipants meta-data. We include results baselines for BAH at frame- and\nvideo-level recognition in multi-modal setups, in addition to zero-shot\nprediction, and for personalization using unsupervised domain adaptation. The\nlimited performance of baseline models highlights the challenges of recognizing\nA/H in real-world videos. The data, code, and pretrained weights are available.", "AI": {"tldr": "The paper introduces the first dataset (BAH) for recognizing ambivalence and hesitancy (A/H) in videos, collected from 224 participants, and provides baseline results for multimodal recognition.", "motivation": "Recognizing A/H is crucial for personalized digital behavior change interventions, but lacks datasets for ML model design.", "method": "A dataset (BAH) was created with videos from 224 participants, annotated for A/H cues, and baseline models were tested for frame- and video-level recognition.", "result": "Baseline models show limited performance, highlighting the challenge of recognizing A/H in real-world videos.", "conclusion": "The BAH dataset and baseline results provide a foundation for future research on A/H recognition, with data and code made available."}}
{"id": "2504.00186", "pdf": "https://arxiv.org/pdf/2504.00186", "abs": "https://arxiv.org/abs/2504.00186", "authors": ["Olawale Salaudeen", "Nicole Chiou", "Shiny Weng", "Sanmi Koyejo"], "title": "Are Domain Generalization Benchmarks with Accuracy on the Line Misspecified?", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Fixed typo in covariance term in the main theorems", "summary": "Spurious correlations are unstable statistical associations that hinder\nrobust decision-making. Conventional wisdom suggests that models relying on\nsuch correlations will fail to generalize out-of-distribution (OOD), especially\nunder strong distribution shifts. However, empirical evidence challenges this\nview as naive in-distribution empirical risk minimizers often achieve the best\nOOD accuracy across popular OOD generalization benchmarks. In light of these\nresults, we propose a different perspective: many widely used benchmarks for\nevaluating robustness to spurious correlations are misspecified. Specifically,\nthey fail to include shifts in spurious correlations that meaningfully impact\nOOD generalization, making them unsuitable for evaluating the benefit of\nremoving such correlations. We establish conditions under which a distribution\nshift can reliably assess a model's reliance on spurious correlations.\nCrucially, under these conditions, we should not observe a strong positive\ncorrelation between in-distribution and OOD accuracy, often called \"accuracy on\nthe line.\" Yet, most state-of-the-art benchmarks exhibit this pattern,\nsuggesting they do not effectively assess robustness. Our findings expose a key\nlimitation in current benchmarks used to evaluate domain generalization\nalgorithms, that is, models designed to avoid spurious correlations. We\nhighlight the need to rethink how robustness to spurious correlations is\nassessed, identify well-specified benchmarks the field should prioritize, and\nenumerate strategies for designing future benchmarks that meaningfully reflect\nrobustness under distribution shift.", "AI": {"tldr": "Current OOD benchmarks may miss key spurious correlation shifts, leading to misleading evaluations of model robustness.", "motivation": "To challenge the assumption that models relying on spurious correlations fail OOD, and to expose flaws in current benchmarks.", "method": "Analyze conditions for reliable assessment of spurious correlation reliance and evaluate existing benchmarks.", "result": "Many benchmarks fail to include meaningful spurious correlation shifts, rendering them ineffective for robustness evaluation.", "conclusion": "The field must rethink benchmark design to accurately assess robustness to spurious correlations under distribution shifts."}}
{"id": "2410.02681", "pdf": "https://arxiv.org/pdf/2410.02681", "abs": "https://arxiv.org/abs/2410.02681", "authors": ["Shuoyuan Wang", "Yixuan Li", "Hongxin Wei"], "title": "Understanding and Mitigating Miscalibration in Prompt Tuning for Vision-Language Models", "categories": ["cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Confidence calibration is critical for the safe deployment of machine\nlearning models in the real world. However, such issue in vision-language\nmodels like CLIP, particularly after fine-tuning, has not been fully addressed.\nIn this work, we demonstrate that existing prompt tuning methods usually lead\nto a trade-off of calibration between base and new classes: the cross-entropy\nloss in CoOp causes overconfidence in new classes by increasing textual label\ndivergence, whereas the regularization of KgCoOp maintains the confidence level\nbut results in underconfidence in base classes due to the improved accuracy.\nInspired by the observations, we introduce Dynamic Outlier Regularization (DOR)\nto ensure the confidence calibration on both base and new classes after\nfine-tuning. In particular, we propose to minimize the feature deviation of\nnovel textual labels (instead of base classes) sampled from a large vocabulary.\nIn effect, DOR prevents the increase in textual divergence for new labels while\neasing restrictions on base classes. Extensive experiments demonstrate that DOR\ncan enhance the calibration performance of current fine-tuning methods on base\nand new classes.", "AI": {"tldr": "The paper addresses confidence calibration in vision-language models like CLIP after fine-tuning, introducing Dynamic Outlier Regularization (DOR) to balance calibration between base and new classes.", "motivation": "Existing prompt tuning methods create a trade-off in calibration between base and new classes, leading to overconfidence or underconfidence.", "method": "Proposes DOR to minimize feature deviation of novel textual labels from a large vocabulary, reducing textual divergence for new labels while easing restrictions on base classes.", "result": "DOR improves calibration performance on both base and new classes in fine-tuning methods.", "conclusion": "DOR effectively balances confidence calibration in vision-language models post fine-tuning."}}
{"id": "2505.18128", "pdf": "https://arxiv.org/pdf/2505.18128", "abs": "https://arxiv.org/abs/2505.18128", "authors": ["Chau Minh Pham", "Jenna Russell", "Dzung Pham", "Mohit Iyyer"], "title": "Frankentext: Stitching random text fragments into long-form narratives", "categories": ["cs.CL"], "comment": null, "summary": "We introduce Frankentexts, a new type of long-form narratives produced by\nLLMs under the extreme constraint that most tokens (e.g., 90%) must be copied\nverbatim from human writings. This task presents a challenging test of\ncontrollable generation, requiring models to satisfy a writing prompt,\nintegrate disparate text fragments, and still produce a coherent narrative. To\ngenerate Frankentexts, we instruct the model to produce a draft by selecting\nand combining human-written passages, then iteratively revise the draft while\nmaintaining a user-specified copy ratio. We evaluate the resulting Frankentexts\nalong three axes: writing quality, instruction adherence, and detectability.\nGemini-2.5-Pro performs surprisingly well on this task: 81% of its Frankentexts\nare coherent and 100% relevant to the prompt. Notably, up to 59% of these\noutputs are misclassified as human-written by detectors like Pangram, revealing\nlimitations in AI text detectors. Human annotators can sometimes identify\nFrankentexts through their abrupt tone shifts and inconsistent grammar between\nsegments, especially in longer generations. Beyond presenting a challenging\ngeneration task, Frankentexts invite discussion on building effective detectors\nfor this new grey zone of authorship, provide training data for mixed\nauthorship detection, and serve as a sandbox for studying human-AI co-writing\nprocesses.", "AI": {"tldr": "Frankentexts are long-form narratives by LLMs with most tokens copied from human text, testing controllable generation. Gemini-2.5-Pro excels, but detectors struggle to identify them.", "motivation": "To explore controllable generation under extreme constraints and challenge AI text detectors.", "method": "Generate drafts by combining human passages, then iteratively revise while maintaining a copy ratio.", "result": "81% coherent, 100% prompt-relevant; 59% misclassified as human-written. Human annotators detect tone shifts and grammar inconsistencies.", "conclusion": "Frankentexts highlight detector limitations and open discussions on mixed authorship and human-AI co-writing."}}
{"id": "2505.19398", "pdf": "https://arxiv.org/pdf/2505.19398", "abs": "https://arxiv.org/abs/2505.19398", "authors": ["Yiwei Xie", "Ping Liu", "Zheng Zhang"], "title": "Erasing Concepts, Steering Generations: A Comprehensive Survey of Concept Suppression", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-Image (T2I) models have demonstrated impressive capabilities in\ngenerating high-quality and diverse visual content from natural language\nprompts. However, uncontrolled reproduction of sensitive, copyrighted, or\nharmful imagery poses serious ethical, legal, and safety challenges. To address\nthese concerns, the concept erasure paradigm has emerged as a promising\ndirection, enabling the selective removal of specific semantic concepts from\ngenerative models while preserving their overall utility. This survey provides\na comprehensive overview and in-depth synthesis of concept erasure techniques\nin T2I diffusion models. We systematically categorize existing approaches along\nthree key dimensions: intervention level, which identifies specific model\ncomponents targeted for concept removal; optimization structure, referring to\nthe algorithmic strategies employed to achieve suppression; and semantic scope,\nconcerning the complexity and nature of the concepts addressed. This\nmulti-dimensional taxonomy enables clear, structured comparisons across diverse\nmethodologies, highlighting fundamental trade-offs between erasure specificity,\ngeneralization, and computational complexity. We further discuss current\nevaluation benchmarks, standardized metrics, and practical datasets,\nemphasizing gaps that limit comprehensive assessment, particularly regarding\nrobustness and practical effectiveness. Finally, we outline major challenges\nand promising future directions, including disentanglement of concept\nrepresentations, adaptive and incremental erasure strategies, adversarial\nrobustness, and new generative architectures. This survey aims to guide\nresearchers toward safer, more ethically aligned generative models, providing\nfoundational knowledge and actionable recommendations to advance responsible\ndevelopment in generative AI.", "AI": {"tldr": "A survey on concept erasure in Text-to-Image (T2I) models, categorizing methods, discussing evaluation gaps, and outlining future directions for ethical AI.", "motivation": "Address ethical, legal, and safety challenges posed by uncontrolled reproduction of sensitive or harmful imagery in T2I models.", "method": "Systematically categorizes concept erasure techniques along intervention level, optimization structure, and semantic scope.", "result": "Highlights trade-offs in erasure specificity, generalization, and computational complexity, and identifies gaps in evaluation benchmarks.", "conclusion": "Guides researchers toward safer, ethically aligned generative models with actionable recommendations for responsible AI development."}}
{"id": "2504.09851", "pdf": "https://arxiv.org/pdf/2504.09851", "abs": "https://arxiv.org/abs/2504.09851", "authors": ["Aikaterini Maria Panteleaki", "Konstantinos Balaskas", "Georgios Zervakis", "Hussam Amrouch", "Iraklis Anagnostopoulos"], "title": "Carbon-Efficient 3D DNN Acceleration: Optimizing Performance and Sustainability", "categories": ["cs.AR", "cs.AI"], "comment": "IEEE Computer Society Annual Symposium on VLSI (ISVLSI) 2025", "summary": "As Deep Neural Networks (DNNs) continue to drive advancements in artificial\nintelligence, the design of hardware accelerators faces growing concerns over\nembodied carbon footprint due to complex fabrication processes. 3D integration\nimproves performance but introduces sustainability challenges, making\ncarbon-aware optimization essential. In this work, we propose a\ncarbon-efficient design methodology for 3D DNN accelerators, leveraging\napproximate computing and genetic algorithm-based design space exploration to\noptimize Carbon Delay Product (CDP). By integrating area-efficient approximate\nmultipliers into Multiply-Accumulate (MAC) units, our approach effectively\nreduces silicon area and fabrication overhead while maintaining high\ncomputational accuracy. Experimental evaluations across three technology nodes\n(45nm, 14nm, and 7nm) show that our method reduces embodied carbon by up to 30%\nwith negligible accuracy drop.", "AI": {"tldr": "A carbon-efficient design methodology for 3D DNN accelerators reduces embodied carbon by up to 30% with minimal accuracy loss.", "motivation": "Addressing the growing embodied carbon footprint of hardware accelerators for DNNs due to complex fabrication processes.", "method": "Uses approximate computing and genetic algorithm-based design space exploration to optimize Carbon Delay Product (CDP), integrating area-efficient approximate multipliers into MAC units.", "result": "Experimental evaluations show up to 30% reduction in embodied carbon across 45nm, 14nm, and 7nm technology nodes with negligible accuracy drop.", "conclusion": "The proposed methodology effectively balances sustainability and performance for 3D DNN accelerators."}}
{"id": "2410.03348", "pdf": "https://arxiv.org/pdf/2410.03348", "abs": "https://arxiv.org/abs/2410.03348", "authors": ["Aaditya Naik", "Jason Liu", "Claire Wang", "Amish Sethi", "Saikat Dutta", "Mayur Naik", "Eric Wong"], "title": "Dolphin: A Programmable Framework for Scalable Neurosymbolic Learning", "categories": ["cs.LG"], "comment": null, "summary": "Neurosymbolic learning enables the integration of symbolic reasoning with\ndeep learning but faces significant challenges in scaling to complex symbolic\nprograms, large datasets, or both. We introduce DOLPHIN, a framework that\ntackles these challenges by supporting neurosymbolic programs in Python,\nexecuting complex symbolic reasoning on the CPU while vectorizing probabilistic\ncomputations and gradient propagation on the GPU. Across 13 benchmarks spanning\ntasks over text, image, and video data, with symbolic reasoning features like\nrecursion and black-box functions, DOLPHIN converges to state-of-the-art\naccuracies on the more complex benchmarks while existing frameworks such as\nScallop, ISED, and IndeCateR+ fail to converge within the time limit. On\nsimpler benchmarks, DOLPHIN matches their performance, while achieving these\nresults 1.71x to 62x faster than the baselines. Overall, DOLPHIN advances the\nscalability of neurosymbolic frameworks, achieving state-of-the-art efficiency\nand convergence on difficult benchmarks where existing frameworks struggle. The\ncode is published at https://github.com/Dolphin-NeSy/Dolphin.", "AI": {"tldr": "DOLPHIN is a neurosymbolic framework that integrates symbolic reasoning with deep learning, achieving state-of-the-art efficiency and convergence on complex benchmarks.", "motivation": "To address scalability challenges in neurosymbolic learning for complex symbolic programs and large datasets.", "method": "DOLPHIN supports neurosymbolic programs in Python, executing symbolic reasoning on the CPU and vectorizing probabilistic computations on the GPU.", "result": "DOLPHIN outperforms existing frameworks on 13 benchmarks, achieving faster convergence and higher accuracy on complex tasks.", "conclusion": "DOLPHIN advances neurosymbolic scalability, offering superior efficiency and performance where other frameworks fail."}}
{"id": "2505.18486", "pdf": "https://arxiv.org/pdf/2505.18486", "abs": "https://arxiv.org/abs/2505.18486", "authors": ["Hong Jiao", "Dan Song", "Won-Chan Lee"], "title": "Comparing Human and AI Rater Effects Using the Many-Facet Rasch Model", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) have been widely explored for automated scoring\nin low-stakes assessment to facilitate learning and instruction. Empirical\nevidence related to which LLM produces the most reliable scores and induces\nleast rater effects needs to be collected before the use of LLMs for automated\nscoring in practice. This study compared ten LLMs (ChatGPT 3.5, ChatGPT 4,\nChatGPT 4o, OpenAI o1, Claude 3.5 Sonnet, Gemini 1.5, Gemini 1.5 Pro, Gemini\n2.0, as well as DeepSeek V3, and DeepSeek R1) with human expert raters in\nscoring two types of writing tasks. The accuracy of the holistic and analytic\nscores from LLMs compared with human raters was evaluated in terms of Quadratic\nWeighted Kappa. Intra-rater consistency across prompts was compared in terms of\nCronbach Alpha. Rater effects of LLMs were evaluated and compared with human\nraters using the Many-Facet Rasch model. The results in general supported the\nuse of ChatGPT 4o, Gemini 1.5 Pro, and Claude 3.5 Sonnet with high scoring\naccuracy, better rater reliability, and less rater effects.", "AI": {"tldr": "The study compared ten LLMs with human raters for automated scoring of writing tasks, finding ChatGPT 4o, Gemini 1.5 Pro, and Claude 3.5 Sonnet most reliable.", "motivation": "To determine which LLMs produce reliable scores and minimize rater effects for practical use in automated scoring.", "method": "Evaluated ten LLMs against human raters using Quadratic Weighted Kappa, Cronbach Alpha, and Many-Facet Rasch model.", "result": "ChatGPT 4o, Gemini 1.5 Pro, and Claude 3.5 Sonnet showed high accuracy, reliability, and fewer rater effects.", "conclusion": "These LLMs are suitable for automated scoring in low-stakes assessments."}}
{"id": "2505.19656", "pdf": "https://arxiv.org/pdf/2505.19656", "abs": "https://arxiv.org/abs/2505.19656", "authors": ["Tianren Ma", "Xiaosong Zhang", "Boyu Yang", "Junlan Feng", "Qixiang Ye"], "title": "ReDDiT: Rehashing Noise for Discrete Visual Generation", "categories": ["cs.CV"], "comment": "Preprint. Check out our project page at github.com/martian422/ReDDiT", "summary": "Discrete diffusion models are gaining traction in the visual generative area\nfor their efficiency and compatibility. However, the pioneered attempts still\nfall behind the continuous counterparts, which we attribute to the noise\n(absorbing state) design and sampling heuristics. In this study, we propose the\nrehashing noise framework for discrete diffusion transformer, termed ReDDiT, to\nextend absorbing states and improve expressive capacity of discrete diffusion\nmodels. ReDDiT enriches the potential paths that latent variables can traverse\nduring training with randomized multi-index corruption. The derived rehash\nsampler, which reverses the randomized absorbing paths, guarantees the\ndiversity and low discrepancy of the generation process. These reformulations\nlead to more consistent and competitive generation quality, mitigating the need\nfor heavily tuned randomness. Experiments show that ReDDiT significantly\noutperforms the baseline (reducing gFID from 6.18 to 1.61) and is on par with\nthe continuous counterparts with higher efficiency.", "AI": {"tldr": "ReDDiT improves discrete diffusion models by introducing a rehashing noise framework and rehash sampler, achieving better generation quality and efficiency.", "motivation": "Discrete diffusion models lag behind continuous ones due to noise design and sampling heuristics.", "method": "Proposes ReDDiT with randomized multi-index corruption and rehash sampler for diverse, low-discrepancy generation.", "result": "ReDDiT outperforms baselines (gFID reduced from 6.18 to 1.61) and matches continuous models in efficiency.", "conclusion": "ReDDiT enhances discrete diffusion models, offering competitive performance with improved efficiency."}}
{"id": "2504.11558", "pdf": "https://arxiv.org/pdf/2504.11558", "abs": "https://arxiv.org/abs/2504.11558", "authors": ["Mete Erdogan", "Cengiz Pehlevan", "Alper T. Erdogan"], "title": "Error Broadcast and Decorrelation as a Potential Artificial and Natural Learning Mechanism", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce Error Broadcast and Decorrelation (EBD), a novel learning\nframework for neural networks that addresses credit assignment by directly\nbroadcasting output errors to individual layers, circumventing weight transport\nof backpropagation. EBD is rigorously grounded in the stochastic orthogonality\nproperty of Minimum Mean Square Error estimators. This fundamental principle\nstates that the error of an optimal estimator is orthogonal to functions of the\ninput. Guided by this insight, EBD defines layerwise loss functions that\ndirectly penalize correlations between layer activations and output errors,\nthereby establishing a principled foundation for error broadcasting. This\ntheoretically sound mechanism naturally leads to the experimentally observed\nthree-factor learning rule and integrates with biologically plausible\nframeworks to enhance performance and plausibility. Numerical experiments\ndemonstrate EBD's competitive or better performance against other\nerror-broadcast methods on benchmark datasets. Our findings establish EBD as an\nefficient, biologically plausible, and principled alternative for neural\nnetwork training.", "AI": {"tldr": "EBD is a novel neural network framework that broadcasts output errors to layers, avoiding backpropagation's weight transport. It uses stochastic orthogonality for layerwise loss functions, showing competitive performance.", "motivation": "Address credit assignment in neural networks without relying on backpropagation's weight transport, leveraging stochastic orthogonality for a principled approach.", "method": "Defines layerwise loss functions penalizing correlations between layer activations and output errors, grounded in stochastic orthogonality.", "result": "Competitive or better performance compared to other error-broadcast methods on benchmark datasets.", "conclusion": "EBD is an efficient, biologically plausible, and principled alternative for neural network training."}}
{"id": "2410.03972", "pdf": "https://arxiv.org/pdf/2410.03972", "abs": "https://arxiv.org/abs/2410.03972", "authors": ["Ann Huang", "Satpreet H. Singh", "Flavio Martinelli", "Kanaka Rajan"], "title": "Measuring and Controlling Solution Degeneracy across Task-Trained Recurrent Neural Networks", "categories": ["cs.LG", "cs.IT", "cs.NE", "math.IT", "q-bio.NC"], "comment": null, "summary": "Task-trained recurrent neural networks (RNNs) are widely used in neuroscience\nand machine learning to model dynamical computations. To gain mechanistic\ninsight into how neural systems solve tasks, prior work often reverse-engineers\nindividual trained networks. However, different RNNs trained on the same task\nand achieving similar performance can exhibit strikingly different internal\nsolutions-a phenomenon known as solution degeneracy. Here, we develop a unified\nframework to systematically quantify and control solution degeneracy across\nthree levels: behavior, neural dynamics, and weight space. We apply this\nframework to 3,400 RNNs trained on four neuroscience-relevant tasks-flip-flop\nmemory, sine wave generation, delayed discrimination, and path\nintegration-while systematically varying task complexity, learning regime,\nnetwork size, and regularization. We find that higher task complexity and\nstronger feature learning reduce degeneracy in neural dynamics but increase it\nin weight space, with mixed effects on behavior. In contrast, larger networks\nand structural regularization reduce degeneracy at all three levels. These\nfindings empirically validate the Contravariance Principle and provide\npractical guidance for researchers aiming to tailor RNN solutions-whether to\nuncover shared neural mechanisms or to model individual variability observed in\nbiological systems. This work provides a principled framework for quantifying\nand controlling solution degeneracy in task-trained RNNs, offering new tools\nfor building more interpretable and biologically grounded models of neural\ncomputation.", "AI": {"tldr": "A framework to quantify and control solution degeneracy in RNNs across behavior, neural dynamics, and weight space, validated on 3,400 networks trained on neuroscience tasks.", "motivation": "To understand how neural systems solve tasks despite solution degeneracy (different RNNs achieving similar performance with different internal solutions).", "method": "Developed a unified framework to analyze degeneracy, applied to RNNs trained on four tasks, varying complexity, learning regime, network size, and regularization.", "result": "Higher task complexity and feature learning reduce neural dynamics degeneracy but increase it in weight space. Larger networks and regularization reduce degeneracy at all levels.", "conclusion": "The framework offers tools to tailor RNN solutions for interpretability and biological relevance, validating the Contravariance Principle."}}
{"id": "2505.18542", "pdf": "https://arxiv.org/pdf/2505.18542", "abs": "https://arxiv.org/abs/2505.18542", "authors": ["Chen Yang", "Ruping Xu", "Ruizhe Li", "Bin Cao", "Jing Fan"], "title": "Business as Rulesual: A Benchmark and Framework for Business Rule Flow Modeling with LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Process mining aims to discover, monitor and optimize the actual behaviors of\nreal processes. While prior work has mainly focused on extracting procedural\naction flows from instructional texts, rule flows embedded in business\ndocuments remain underexplored. To this end, we introduce a novel annotated\nChinese dataset, BPRF, which contains 50 business process documents with 326\nexplicitly labeled business rules across multiple domains. Each rule is\nrepresented as a <Condition, Action> pair, and we annotate logical dependencies\nbetween rules (sequential, conditional, or parallel). We also propose ExIde, a\nframework for automatic business rule extraction and dependency relationship\nidentification using large language models (LLMs). We evaluate ExIde using 12\nstate-of-the-art (SOTA) LLMs on the BPRF dataset, benchmarking performance on\nboth rule extraction and dependency classification tasks of current LLMs. Our\nresults demonstrate the effectiveness of ExIde in extracting structured\nbusiness rules and analyzing their interdependencies for current SOTA LLMs,\npaving the way for more automated and interpretable business process\nautomation.", "AI": {"tldr": "The paper introduces BPRF, a Chinese dataset for business rule extraction, and ExIde, a framework using LLMs to automate rule extraction and dependency analysis.", "motivation": "Prior work focused on procedural action flows, leaving rule flows in business documents underexplored.", "method": "Proposes ExIde, a framework leveraging LLMs for rule extraction and dependency identification, evaluated on the BPRF dataset.", "result": "ExIde effectively extracts structured business rules and analyzes dependencies, benchmarking 12 SOTA LLMs.", "conclusion": "The work advances automated and interpretable business process automation."}}
{"id": "2505.19846", "pdf": "https://arxiv.org/pdf/2505.19846", "abs": "https://arxiv.org/abs/2505.19846", "authors": ["Nagito Saito", "Shintaro Ito", "Koichi Ito", "Takafumi Aoki"], "title": "Zero-Shot Pseudo Labels Generation Using SAM and CLIP for Semi-Supervised Semantic Segmentation", "categories": ["cs.CV"], "comment": "Accepted to ICIP 2025", "summary": "Semantic segmentation is a fundamental task in medical image analysis and\nautonomous driving and has a problem with the high cost of annotating the\nlabels required in training. To address this problem, semantic segmentation\nmethods based on semi-supervised learning with a small number of labeled data\nhave been proposed. For example, one approach is to train a semantic\nsegmentation model using images with annotated labels and pseudo labels. In\nthis approach, the accuracy of the semantic segmentation model depends on the\nquality of the pseudo labels, and the quality of the pseudo labels depends on\nthe performance of the model to be trained and the amount of data with\nannotated labels. In this paper, we generate pseudo labels using zero-shot\nannotation with the Segment Anything Model (SAM) and Contrastive Language-Image\nPretraining (CLIP), improve the accuracy of the pseudo labels using the Unified\nDual-Stream Perturbations Approach (UniMatch), and use them as enhanced labels\nto train a semantic segmentation model. The effectiveness of the proposed\nmethod is demonstrated through the experiments using the public datasets:\nPASCAL and MS COCO. The project web page is available at:\nhttps://gsisaoki.github.io/ZERO-SHOT-PLG/", "AI": {"tldr": "The paper proposes a method to improve semantic segmentation by generating high-quality pseudo labels using SAM and CLIP, refining them with UniMatch, and training a model with these labels.", "motivation": "High annotation costs in semantic segmentation tasks motivate the use of semi-supervised learning with pseudo labels.", "method": "Generate pseudo labels with SAM and CLIP, refine them using UniMatch, and train a semantic segmentation model with these enhanced labels.", "result": "Experiments on PASCAL and MS COCO datasets demonstrate the method's effectiveness.", "conclusion": "The proposed approach successfully reduces reliance on annotated data while improving segmentation accuracy."}}
{"id": "2504.14762", "pdf": "https://arxiv.org/pdf/2504.14762", "abs": "https://arxiv.org/abs/2504.14762", "authors": ["Sahil Rajesh Dhayalkar"], "title": "A Combinatorial Theory of Dropout: Subnetworks, Graph Geometry, and Generalization", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages (9 pages main content and remaining pages are references,\n  appendix which includes 7 figures, proofs and derivations)", "summary": "We propose a combinatorial and graph-theoretic theory of dropout by modeling\ntraining as a random walk over a high-dimensional graph of binary subnetworks.\nEach node represents a masked version of the network, and dropout induces\nstochastic traversal across this space. We define a subnetwork contribution\nscore that quantifies generalization and show that it varies smoothly over the\ngraph. Using tools from spectral graph theory, PAC-Bayes analysis, and\ncombinatorics, we prove that generalizing subnetworks form large, connected,\nlow-resistance clusters, and that their number grows exponentially with network\nwidth. This reveals dropout as a mechanism for sampling from a robust,\nstructured ensemble of well-generalizing subnetworks with built-in redundancy.\nExtensive experiments validate every theoretical claim across diverse\narchitectures. Together, our results offer a unified foundation for\nunderstanding dropout and suggest new directions for mask-guided regularization\nand subnetwork optimization.", "AI": {"tldr": "Dropout is modeled as a random walk over a graph of subnetworks, revealing it samples from robust, well-generalizing ensembles with exponential growth in network width.", "motivation": "To provide a combinatorial and graph-theoretic understanding of dropout, explaining its effectiveness in neural network training.", "method": "Model training as a random walk over a graph of binary subnetworks, using spectral graph theory, PAC-Bayes analysis, and combinatorics.", "result": "Generalizing subnetworks form large, connected, low-resistance clusters, growing exponentially with network width.", "conclusion": "Dropout effectively samples from robust subnetworks, offering a foundation for mask-guided regularization and subnetwork optimization."}}
{"id": "2410.05612", "pdf": "https://arxiv.org/pdf/2410.05612", "abs": "https://arxiv.org/abs/2410.05612", "authors": ["Michael Munn", "Susan Wei"], "title": "A Bayesian Model Selection Criterion for Selecting Pretraining Checkpoints", "categories": ["cs.LG"], "comment": "Accepted as an ICML 2025 paper", "summary": "Recent advances in artificial intelligence have been fueled by the\ndevelopment of foundation models such as BERT, GPT, T5, and Vision\nTransformers. These models are first pretrained on vast and diverse datasets\nand then adapted to specific downstream tasks, often with significantly less\ndata. However, the mechanisms behind the success of this ubiquitous\npretrain-then-adapt paradigm remain underexplored, particularly the\ncharacteristics of pretraining checkpoints that enhance downstream adaptation.\nWe introduce a Bayesian model selection criterion, called the downstream free\nenergy, which quantifies a checkpoint's adaptability by measuring the\nconcentration of nearby favorable parameters for the downstream task. We\ndemonstrate that this Bayesian model selection criterion can be effectively\nimplemented without access to the downstream data or prior knowledge of the\ndownstream task. Furthermore, we provide empirical evidence that the criterion\nreliably correlates with improved finetuning performance, offering a principled\napproach to predicting model adaptability.", "AI": {"tldr": "The paper introduces a Bayesian model selection criterion, downstream free energy, to predict pretrained model adaptability without downstream data.", "motivation": "To understand why the pretrain-then-adapt paradigm works and identify checkpoint characteristics that enhance downstream performance.", "method": "Proposes downstream free energy, a Bayesian criterion, to quantify adaptability by measuring favorable parameter concentration.", "result": "The criterion correlates with improved finetuning performance and works without downstream data or task knowledge.", "conclusion": "Provides a principled way to predict model adaptability, enhancing the pretrain-then-adapt paradigm."}}
{"id": "2505.18638", "pdf": "https://arxiv.org/pdf/2505.18638", "abs": "https://arxiv.org/abs/2505.18638", "authors": ["Md. Tanzib Hosain", "Rajan Das Gupta", "Md. Kishor Morol"], "title": "Multilingual Question Answering in Low-Resource Settings: A Dzongkha-English Benchmark for Foundation Models", "categories": ["cs.CL"], "comment": "24 pages, 20 figures", "summary": "In this work, we provide DZEN, a dataset of parallel Dzongkha and English\ntest questions for Bhutanese middle and high school students. The over 5K\nquestions in our collection span a variety of scientific topics and include\nfactual, application, and reasoning-based questions. We use our parallel\ndataset to test a number of Large Language Models (LLMs) and find a significant\nperformance difference between the models in English and Dzongkha. We also look\nat different prompting strategies and discover that Chain-of-Thought (CoT)\nprompting works well for reasoning questions but less well for factual ones. We\nalso find that adding English translations enhances the precision of Dzongkha\nquestion responses. Our results point to exciting avenues for further study to\nimprove LLM performance in Dzongkha and, more generally, in low-resource\nlanguages. We release the dataset at:\nhttps://github.com/kraritt/llm_dzongkha_evaluation.", "AI": {"tldr": "DZEN is a parallel Dzongkha-English dataset for evaluating LLMs, revealing performance gaps and effective prompting strategies like CoT for reasoning questions.", "motivation": "To address the lack of resources for evaluating LLMs in Dzongkha and improve their performance in low-resource languages.", "method": "Created a dataset of 5K parallel questions, tested LLMs with various prompting strategies (e.g., CoT), and analyzed performance differences.", "result": "Significant performance gap between English and Dzongkha; CoT works well for reasoning questions but not factual ones; English translations improve Dzongkha responses.", "conclusion": "The dataset and findings highlight opportunities to enhance LLM performance in Dzongkha and other low-resource languages."}}
{"id": "2505.19854", "pdf": "https://arxiv.org/pdf/2505.19854", "abs": "https://arxiv.org/abs/2505.19854", "authors": ["Natsuki Takama", "Shintaro Ito", "Koichi Ito", "Hwann-Tzong Chen", "Takafumi Aoki"], "title": "Sparse2DGS: Sparse-View Surface Reconstruction using 2D Gaussian Splatting with Dense Point Cloud", "categories": ["cs.CV"], "comment": "Accepted to ICIP 2025", "summary": "Gaussian Splatting (GS) has gained attention as a fast and effective method\nfor novel view synthesis. It has also been applied to 3D reconstruction using\nmulti-view images and can achieve fast and accurate 3D reconstruction. However,\nGS assumes that the input contains a large number of multi-view images, and\ntherefore, the reconstruction accuracy significantly decreases when only a\nlimited number of input images are available. One of the main reasons is the\ninsufficient number of 3D points in the sparse point cloud obtained through\nStructure from Motion (SfM), which results in a poor initialization for\noptimizing the Gaussian primitives. We propose a new 3D reconstruction method,\ncalled Sparse2DGS, to enhance 2DGS in reconstructing objects using only three\nimages. Sparse2DGS employs DUSt3R, a fundamental model for stereo images, along\nwith COLMAP MVS to generate highly accurate and dense 3D point clouds, which\nare then used to initialize 2D Gaussians. Through experiments on the DTU\ndataset, we show that Sparse2DGS can accurately reconstruct the 3D shapes of\nobjects using just three images. The project page is available at\nhttps://gsisaoki.github.io/SPARSE2DGS/", "AI": {"tldr": "Sparse2DGS improves 3D reconstruction accuracy with limited input images by using DUSt3R and COLMAP MVS for dense point cloud initialization.", "motivation": "Gaussian Splatting (GS) struggles with sparse input images due to poor initialization from sparse point clouds.", "method": "Uses DUSt3R and COLMAP MVS to generate dense 3D point clouds for initializing 2D Gaussians.", "result": "Accurate 3D reconstruction with just three images, demonstrated on the DTU dataset.", "conclusion": "Sparse2DGS effectively addresses the limitation of GS in sparse-view scenarios."}}
{"id": "2504.14945", "pdf": "https://arxiv.org/pdf/2504.14945", "abs": "https://arxiv.org/abs/2504.14945", "authors": ["Jianhao Yan", "Yafu Li", "Zican Hu", "Zhi Wang", "Ganqu Cui", "Xiaoye Qu", "Yu Cheng", "Yue Zhang"], "title": "Learning to Reason under Off-Policy Guidance", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Work in progress", "summary": "Recent advances in large reasoning models (LRMs) demonstrate that\nsophisticated behaviors such as multi-step reasoning and self-reflection can\nemerge via reinforcement learning with verifiable rewards~(\\textit{RLVR}).\nHowever, existing \\textit{RLVR} approaches are inherently ``on-policy'',\nlimiting learning to a model's own outputs and failing to acquire reasoning\nabilities beyond its initial capabilities. To address this issue, we introduce\n\\textbf{LUFFY} (\\textbf{L}earning to reason \\textbf{U}nder\no\\textbf{FF}-polic\\textbf{Y} guidance), a framework that augments \\textit{RLVR}\nwith off-policy reasoning traces. LUFFY dynamically balances imitation and\nexploration by combining off-policy demonstrations with on-policy rollouts\nduring training. Specifically, LUFFY combines the Mixed-Policy GRPO framework,\nwhich has a theoretically guaranteed convergence rate, alongside policy shaping\nvia regularized importance sampling to avoid superficial and rigid imitation\nduring mixed-policy training. Compared with previous RLVR methods, LUFFY\nachieves an over \\textbf{+6.4} average gain across six math benchmarks and an\nadvantage of over \\textbf{+6.2} points in out-of-distribution tasks. Most\nsignificantly, we show that LUFFY successfully trains weak models in scenarios\nwhere on-policy RLVR completely fails. These results provide compelling\nevidence that LUFFY transcends the fundamental limitations of on-policy RLVR\nand demonstrates the great potential of utilizing off-policy guidance in RLVR.", "AI": {"tldr": "LUFFY introduces off-policy reasoning traces to RLVR, balancing imitation and exploration, achieving significant performance gains over on-policy RLVR.", "motivation": "Existing RLVR methods are limited by their on-policy nature, restricting learning to a model's own outputs and hindering reasoning beyond initial capabilities.", "method": "LUFFY combines off-policy demonstrations with on-policy rollouts using Mixed-Policy GRPO and policy shaping via regularized importance sampling.", "result": "LUFFY achieves +6.4 average gain on math benchmarks and +6.2 points in out-of-distribution tasks, successfully training weak models where on-policy RLVR fails.", "conclusion": "LUFFY overcomes on-policy RLVR limitations, showcasing the potential of off-policy guidance in enhancing reasoning models."}}
{"id": "2410.11778", "pdf": "https://arxiv.org/pdf/2410.11778", "abs": "https://arxiv.org/abs/2410.11778", "authors": ["Wei Shen", "Ruida Zhou", "Jing Yang", "Cong Shen"], "title": "On the Training Convergence of Transformers for In-Context Classification of Gaussian Mixtures", "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "comment": null, "summary": "Although transformers have demonstrated impressive capabilities for\nin-context learning (ICL) in practice, theoretical understanding of the\nunderlying mechanism that allows transformers to perform ICL is still in its\ninfancy. This work aims to theoretically study the training dynamics of\ntransformers for in-context classification tasks. We demonstrate that, for\nin-context classification of Gaussian mixtures under certain assumptions, a\nsingle-layer transformer trained via gradient descent converges to a globally\noptimal model at a linear rate. We further quantify the impact of the training\nand testing prompt lengths on the ICL inference error of the trained\ntransformer. We show that when the lengths of training and testing prompts are\nsufficiently large, the prediction of the trained transformer approaches the\nground truth distribution of the labels. Experimental results corroborate the\ntheoretical findings.", "AI": {"tldr": "The paper theoretically analyzes how transformers learn in-context classification tasks, showing convergence to optimal models under certain conditions and quantifying the impact of prompt lengths on performance.", "motivation": "To understand the theoretical mechanisms behind transformers' in-context learning (ICL) capabilities, which are empirically impressive but poorly understood.", "method": "The study focuses on training dynamics of single-layer transformers for Gaussian mixture classification, using gradient descent and analyzing convergence rates.", "result": "The transformer converges to a globally optimal model linearly under assumptions, and larger training/testing prompt lengths reduce inference error, approaching ground truth.", "conclusion": "Theoretical and experimental results validate the transformer's ability to perform in-context classification effectively under specified conditions."}}
{"id": "2505.18962", "pdf": "https://arxiv.org/pdf/2505.18962", "abs": "https://arxiv.org/abs/2505.18962", "authors": ["Xiaoqiang Wang", "Suyuchen Wang", "Yun Zhu", "Bang Liu"], "title": "System-1.5 Reasoning: Traversal in Language and Latent Spaces with Dynamic Shortcuts", "categories": ["cs.CL"], "comment": "Work in progress", "summary": "Chain-of-thought (CoT) reasoning enables large language models (LLMs) to move\nbeyond fast System-1 responses and engage in deliberative System-2 reasoning.\nHowever, this comes at the cost of significant inefficiency due to verbose\nintermediate output. Recent latent-space reasoning methods improve efficiency\nby operating on hidden states without decoding into language, yet they treat\nall steps uniformly, failing to distinguish critical deductions from auxiliary\nsteps and resulting in suboptimal use of computational resources. In this\npaper, we propose System-1.5 Reasoning, an adaptive reasoning framework that\ndynamically allocates computation across reasoning steps through shortcut paths\nin latent space. Specifically, System-1.5 Reasoning introduces two types of\ndynamic shortcuts. The model depth shortcut (DS) adaptively reasons along the\nvertical depth by early exiting non-critical tokens through lightweight adapter\nbranches, while allowing critical tokens to continue through deeper Transformer\nlayers. The step shortcut (SS) reuses hidden states across the decoding steps\nto skip trivial steps and reason horizontally in latent space. Training\nSystem-1.5 Reasoning involves a two-stage self-distillation process: first\ndistilling natural language CoT into latent-space continuous thought, and then\ndistilling full-path System-2 latent reasoning into adaptive shortcut paths\n(System-1.5 Reasoning). Experiments on reasoning tasks demonstrate the superior\nperformance of our method. For example, on GSM8K, System-1.5 Reasoning achieves\nreasoning performance comparable to traditional CoT fine-tuning methods while\naccelerating inference by over 20x and reducing token generation by 92.31% on\naverage.", "AI": {"tldr": "System-1.5 Reasoning improves efficiency in LLMs by dynamically allocating computation via latent-space shortcuts, achieving comparable performance to CoT with 20x faster inference.", "motivation": "Current latent-space reasoning methods treat all steps uniformly, wasting resources. System-1.5 aims to optimize computation by distinguishing critical from auxiliary steps.", "method": "Introduces dynamic shortcuts: depth shortcut (DS) for vertical early exiting and step shortcut (SS) for horizontal step skipping. Uses two-stage self-distillation for training.", "result": "Achieves performance similar to CoT on GSM8K while speeding up inference by 20x and reducing token generation by 92.31%.", "conclusion": "System-1.5 Reasoning efficiently balances performance and computational cost, making it a promising framework for adaptive reasoning in LLMs."}}
{"id": "2505.20001", "pdf": "https://arxiv.org/pdf/2505.20001", "abs": "https://arxiv.org/abs/2505.20001", "authors": ["Shihao Li", "Chenglong Li", "Aihua Zheng", "Andong Lu", "Jin Tang", "Jixin Ma"], "title": "NEXT: Multi-Grained Mixture of Experts via Text-Modulation for Multi-Modal Object Re-ID", "categories": ["cs.CV"], "comment": null, "summary": "Multi-modal object re-identification (ReID) aims to extract identity features\nacross heterogeneous spectral modalities to enable accurate recognition and\nretrieval in complex real-world scenarios. However, most existing methods rely\non implicit feature fusion structures, making it difficult to model\nfine-grained recognition strategies under varying challenging conditions.\nBenefiting from the powerful semantic understanding capabilities of Multi-modal\nLarge Language Models (MLLMs), the visual appearance of an object can be\neffectively translated into descriptive text. In this paper, we propose a\nreliable multi-modal caption generation method based on attribute confidence,\nwhich significantly reduces the unknown recognition rate of MLLMs in\nmulti-modal semantic generation and improves the quality of generated text.\nAdditionally, we propose a novel ReID framework NEXT, the Multi-grained Mixture\nof Experts via Text-Modulation for Multi-modal Object Re-Identification.\nSpecifically, we decouple the recognition problem into semantic and structural\nexpert branches to separately capture modality-specific appearance and\nintrinsic structure. For semantic recognition, we propose the Text-Modulated\nSemantic-sampling Experts (TMSE), which leverages randomly sampled high-quality\nsemantic texts to modulate expert-specific sampling of multi-modal features and\nmining intra-modality fine-grained semantic cues. Then, to recognize\ncoarse-grained structure features, we propose the Context-Shared\nStructure-aware Experts (CSSE) that focuses on capturing the holistic object\nstructure across modalities and maintains inter-modality structural consistency\nthrough a soft routing mechanism. Finally, we propose the Multi-Modal Feature\nAggregation (MMFA), which adopts a unified feature fusion strategy to simply\nand effectively integrate semantic and structural expert outputs into the final\nidentity representations.", "AI": {"tldr": "The paper introduces NEXT, a novel multi-modal object re-identification (ReID) framework, leveraging MLLMs for semantic understanding and proposing attribute-based caption generation to improve text quality. It decouples recognition into semantic and structural expert branches, using TMSE and CSSE, and integrates them via MMFA for robust identity representation.", "motivation": "Existing multi-modal ReID methods lack explicit modeling of fine-grained recognition under varying conditions. The paper aims to improve this by leveraging MLLMs and decoupling recognition into semantic and structural components.", "method": "Proposes NEXT framework with two expert branches: TMSE for semantic recognition using text-modulated sampling and CSSE for structural recognition with soft routing. MMFA integrates these outputs into final identity representations.", "result": "The method reduces unknown recognition rates in MLLMs and improves multi-modal semantic generation quality, enhancing ReID performance.", "conclusion": "NEXT effectively combines semantic and structural recognition, offering a robust solution for multi-modal object ReID."}}
{"id": "2505.00091", "pdf": "https://arxiv.org/pdf/2505.00091", "abs": "https://arxiv.org/abs/2505.00091", "authors": ["Tengchao Zhang", "Yonglin Tian", "Fei Lin", "Jun Huang", "Patrik P. S\u00fcli", "Rui Qin", "Fei-Yue Wang"], "title": "CoordField: Coordination Field for Agentic UAV Task Allocation In Low-altitude Urban Scenarios", "categories": ["cs.RO", "cs.AI"], "comment": "Submitted ITSC 2025", "summary": "With the increasing demand for heterogeneous Unmanned Aerial Vehicle (UAV)\nswarms to perform complex tasks in urban environments, system design now faces\nmajor challenges, including efficient semantic understanding, flexible task\nplanning, and the ability to dynamically adjust coordination strategies in\nresponse to evolving environmental conditions and continuously changing task\nrequirements. To address the limitations of existing approaches, this paper\nproposes coordination field agentic system for coordinating heterogeneous UAV\nswarms in complex urban scenarios. In this system, large language models (LLMs)\nis responsible for interpreting high-level human instructions and converting\nthem into executable commands for the UAV swarms, such as patrol and target\ntracking. Subsequently, a Coordination field mechanism is proposed to guide UAV\nmotion and task selection, enabling decentralized and adaptive allocation of\nemergent tasks. A total of 50 rounds of comparative testing were conducted\nacross different models in a 2D simulation space to evaluate their performance.\nExperimental results demonstrate that the proposed system achieves superior\nperformance in terms of task coverage, response time, and adaptability to\ndynamic changes.", "AI": {"tldr": "A coordination field agentic system using LLMs and a coordination field mechanism improves UAV swarm performance in urban tasks.", "motivation": "Address challenges in UAV swarm coordination like semantic understanding, task planning, and dynamic strategy adjustment in urban environments.", "method": "Uses LLMs to interpret human instructions and a coordination field mechanism for decentralized task allocation.", "result": "Outperforms other models in task coverage, response time, and adaptability in 50 rounds of testing.", "conclusion": "The proposed system effectively enhances UAV swarm coordination in complex urban scenarios."}}
{"id": "2410.13974", "pdf": "https://arxiv.org/pdf/2410.13974", "abs": "https://arxiv.org/abs/2410.13974", "authors": ["Minhua Lin", "Zhiwei Zhang", "Enyan Dai", "Zongyu Wu", "Yilong Wang", "Xiang Zhang", "Suhang Wang"], "title": "Are You Using Reliable Graph Prompts? Trojan Prompt Attacks on Graph Neural Networks", "categories": ["cs.LG", "cs.CR"], "comment": "To be appeared in KDD 2025", "summary": "Graph Prompt Learning (GPL) has been introduced as a promising approach that\nuses prompts to adapt pre-trained GNN models to specific downstream tasks\nwithout requiring fine-tuning of the entire model. Despite the advantages of\nGPL, little attention has been given to its vulnerability to backdoor attacks,\nwhere an adversary can manipulate the model's behavior by embedding hidden\ntriggers. Existing graph backdoor attacks rely on modifying model parameters\nduring training, but this approach is impractical in GPL as GNN encoder\nparameters are frozen after pre-training. Moreover, downstream users may\nfine-tune their own task models on clean datasets, further complicating the\nattack. In this paper, we propose TGPA, a backdoor attack framework designed\nspecifically for GPL. TGPA injects backdoors into graph prompts without\nmodifying pre-trained GNN encoders and ensures high attack success rates and\nclean accuracy. To address the challenge of model fine-tuning by users, we\nintroduce a finetuning-resistant poisoning approach that maintains the\neffectiveness of the backdoor even after downstream model adjustments.\nExtensive experiments on multiple datasets under various settings demonstrate\nthe effectiveness of TGPA in compromising GPL models with fixed GNN encoders.", "AI": {"tldr": "TGPA is a backdoor attack framework targeting Graph Prompt Learning (GPL), bypassing the need to modify pre-trained GNN encoders and resisting downstream fine-tuning.", "motivation": "GPL's vulnerability to backdoor attacks is overlooked, and existing attacks are impractical due to frozen GNN encoders and potential downstream fine-tuning.", "method": "TGPA injects backdoors into graph prompts without altering GNN encoders and uses a fine-tuning-resistant poisoning approach.", "result": "TGPA achieves high attack success rates and maintains clean accuracy across multiple datasets.", "conclusion": "TGPA effectively compromises GPL models with fixed encoders, highlighting a critical security risk in GPL."}}
{"id": "2505.19201", "pdf": "https://arxiv.org/pdf/2505.19201", "abs": "https://arxiv.org/abs/2505.19201", "authors": ["Yunhai Hu", "Tianhua Xia", "Zining Liu", "Rahul Raman", "Xingyu Liu", "Bo Bao", "Eric Sather", "Vithursan Thangarasa", "Sai Qian Zhang"], "title": "DREAM: Drafting with Refined Target Features and Entropy-Adaptive Cross-Attention Fusion for Multimodal Speculative Decoding", "categories": ["cs.CL"], "comment": null, "summary": "Speculative decoding (SD) has emerged as a powerful method for accelerating\nautoregressive generation in large language models (LLMs), yet its integration\ninto vision-language models (VLMs) remains underexplored. We introduce DREAM, a\nnovel speculative decoding framework tailored for VLMs that combines three key\ninnovations: (1) a cross-attention-based mechanism to inject intermediate\nfeatures from the target model into the draft model for improved alignment, (2)\nadaptive intermediate feature selection based on attention entropy to guide\nefficient draft model training, and (3) visual token compression to reduce\ndraft model latency. DREAM enables efficient, accurate, and parallel multimodal\ndecoding with significant throughput improvement. Experiments across a diverse\nset of recent popular VLMs, including LLaVA, Pixtral, SmolVLM and Gemma3,\ndemonstrate up to 3.6x speedup over conventional decoding and significantly\noutperform prior SD baselines in both inference throughput and speculative\ndraft acceptance length across a broad range of multimodal benchmarks. The code\nis publicly available at: https://github.com/SAI-Lab-NYU/DREAM.git", "AI": {"tldr": "DREAM introduces a speculative decoding framework for vision-language models (VLMs) with cross-attention-based alignment, adaptive feature selection, and visual token compression, achieving up to 3.6x speedup.", "motivation": "Speculative decoding (SD) accelerates autoregressive generation in LLMs but is underexplored in VLMs. DREAM addresses this gap.", "method": "DREAM combines cross-attention-based alignment, adaptive feature selection, and visual token compression for efficient multimodal decoding.", "result": "Experiments show up to 3.6x speedup over conventional decoding and outperform prior SD baselines in throughput and draft acceptance.", "conclusion": "DREAM enables efficient, accurate, and parallel multimodal decoding, significantly improving VLM performance."}}
{"id": "2505.20569", "pdf": "https://arxiv.org/pdf/2505.20569", "abs": "https://arxiv.org/abs/2505.20569", "authors": ["Jihoon Lee", "Min Song"], "title": "Retrieval Visual Contrastive Decoding to Mitigate Object Hallucinations in Large Vision-Language Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "ACL 2025 Findings camera-ready version. Code is released at\n  https://github.com/JiHoonLee9898/RVCD", "summary": "Despite significant advancements in Large Vision-Language Models, Object\nHallucination (OH) remains a persistent challenge. Building upon prior studies\non contrastive decoding that address this issue without requiring additional\nmodel training, we introduce RVCD (Retrieval Visual Contrastive Decoding), an\nadvanced method to suppress OH. RVCD leverages both negative and positive\nimages at the logit level, explicitly referencing AI-generated images designed\nto represent a single concept. Our approach demonstrates substantial\nimprovements over existing decoding-based methods.", "AI": {"tldr": "RVCD (Retrieval Visual Contrastive Decoding) is introduced to suppress Object Hallucination in Large Vision-Language Models without additional training, using negative and positive images at the logit level.", "motivation": "Object Hallucination (OH) remains a challenge in Vision-Language Models, and existing contrastive decoding methods need improvement.", "method": "RVCD leverages negative and positive images at the logit level, referencing AI-generated images for single concepts.", "result": "Substantial improvements over existing decoding-based methods are demonstrated.", "conclusion": "RVCD effectively addresses OH without requiring model retraining, outperforming prior methods."}}
{"id": "2505.03793", "pdf": "https://arxiv.org/pdf/2505.03793", "abs": "https://arxiv.org/abs/2505.03793", "authors": ["Xinyue Zeng", "Haohui Wang", "Junhong Lin", "Jun Wu", "Tyler Cody", "Dawei Zhou"], "title": "LENSLLM: Unveiling Fine-Tuning Dynamics for LLM Selection", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICML'2025", "summary": "The proliferation of open-sourced Large Language Models (LLMs) and diverse\ndownstream tasks necessitates efficient model selection, given the\nimpracticality of fine-tuning all candidates due to computational constraints.\nDespite the recent advances in LLM selection, a fundamental research question\nlargely remains nascent: how can we model the dynamic behaviors of LLMs during\nfine-tuning, thereby enhancing our understanding of their generalization\nperformance across diverse downstream tasks? In this work, we propose a novel\ntheoretical framework that provides a proper lens to assess the generalization\ncapabilities of LLMs, thereby enabling accurate and efficient LLM selection for\ndownstream applications. In particular, we first derive a PAC-Bayesian\nGeneralization Bound that unveils fine-tuning dynamics of LLMs and then\nintroduce LENSLLM, a Neural Tangent Kernel (NTK)-based Rectified Scaling Model\nthat enables accurate performance predictions across diverse tasks while\nmaintaining computational efficiency. Extensive empirical results on 3\nlarge-scale benchmarks demonstrate that our model achieves up to 91.1% accuracy\nand reduces up to 88.5% computational cost in LLM selection, outperforming 5\nstate-of-the-art methods. We open-source our proposed LENSLLM model and\ncorresponding results at LensLLM.io.", "AI": {"tldr": "A novel theoretical framework, LENSLLM, is proposed to model LLM fine-tuning dynamics for efficient and accurate model selection, achieving high accuracy and computational savings.", "motivation": "Addressing the impracticality of fine-tuning all LLM candidates due to computational constraints and the need to understand their generalization performance.", "method": "Derives a PAC-Bayesian Generalization Bound and introduces LENSLLM, an NTK-based Rectified Scaling Model for performance prediction.", "result": "Achieves up to 91.1% accuracy and reduces computational cost by 88.5%, outperforming 5 state-of-the-art methods.", "conclusion": "LENSLLM provides an efficient and accurate solution for LLM selection, with open-sourced implementation available."}}
{"id": "2410.14667", "pdf": "https://arxiv.org/pdf/2410.14667", "abs": "https://arxiv.org/abs/2410.14667", "authors": ["Peimeng Guan", "Mark A. Davenport"], "title": "SGD Jittering: A Training Strategy for Robust and Accurate Model-Based Architectures", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Inverse problems aim to reconstruct unseen data from corrupted or perturbed\nmeasurements. While most work focuses on improving reconstruction quality,\ngeneralization accuracy and robustness are equally important, especially for\nsafety-critical applications. Model-based architectures (MBAs), such as loop\nunrolling methods, are considered more interpretable and achieve better\nreconstructions. Empirical evidence suggests that MBAs are more robust to\nperturbations than black-box solvers, but the accuracy-robustness tradeoff in\nMBAs remains underexplored. In this work, we propose a simple yet effective\ntraining scheme for MBAs, called SGD jittering, which injects noise\niteration-wise during reconstruction. We theoretically demonstrate that SGD\njittering not only generalizes better than the standard mean squared error\ntraining but is also more robust to average-case attacks. We validate SGD\njittering using denoising toy examples, seismic deconvolution, and single-coil\nMRI reconstruction. Both SGD jittering and its SPGD extension yield cleaner\nreconstructions for out-of-distribution data and demonstrates enhanced\nrobustness against adversarial attacks.", "AI": {"tldr": "The paper proposes SGD jittering, a training scheme for model-based architectures (MBAs) to improve generalization and robustness in inverse problems.", "motivation": "While MBAs are known for better reconstruction and interpretability, their accuracy-robustness tradeoff is underexplored, especially for safety-critical applications.", "method": "The authors introduce SGD jittering, which injects noise iteration-wise during reconstruction, and its SPGD extension.", "result": "SGD jittering improves generalization and robustness, validated on denoising, seismic deconvolution, and MRI reconstruction tasks.", "conclusion": "SGD jittering enhances MBA performance, offering cleaner reconstructions and better robustness against adversarial attacks."}}
{"id": "2505.19510", "pdf": "https://arxiv.org/pdf/2505.19510", "abs": "https://arxiv.org/abs/2505.19510", "authors": ["Dongil Yang", "Minjin Kim", "Sunghwan Kim", "Beong-woo Kwak", "Minjun Park", "Jinseok Hong", "Woontack Woo", "Jinyoung Yeo"], "title": "LLM Meets Scene Graph: Can Large Language Models Understand and Generate Scene Graphs? A Benchmark and Empirical Study", "categories": ["cs.CL"], "comment": "ACL 2025", "summary": "The remarkable reasoning and generalization capabilities of Large Language\nModels (LLMs) have paved the way for their expanding applications in embodied\nAI, robotics, and other real-world tasks. To effectively support these\napplications, grounding in spatial and temporal understanding in multimodal\nenvironments is essential. To this end, recent works have leveraged scene\ngraphs, a structured representation that encodes entities, attributes, and\ntheir relationships in a scene. However, a comprehensive evaluation of LLMs'\nability to utilize scene graphs remains limited. In this work, we introduce\nText-Scene Graph (TSG) Bench, a benchmark designed to systematically assess\nLLMs' ability to (1) understand scene graphs and (2) generate them from textual\nnarratives. With TSG Bench we evaluate 11 LLMs and reveal that, while models\nperform well on scene graph understanding, they struggle with scene graph\ngeneration, particularly for complex narratives. Our analysis indicates that\nthese models fail to effectively decompose discrete scenes from a complex\nnarrative, leading to a bottleneck when generating scene graphs. These findings\nunderscore the need for improved methodologies in scene graph generation and\nprovide valuable insights for future research. The demonstration of our\nbenchmark is available at https://tsg-bench.netlify.app. Additionally, our code\nand evaluation data are publicly available at\nhttps://github.com/docworlds/tsg-bench.", "AI": {"tldr": "The paper introduces TSG Bench, a benchmark to evaluate LLMs' ability to understand and generate scene graphs, revealing strengths in understanding but weaknesses in generation, especially for complex narratives.", "motivation": "To address the lack of comprehensive evaluation of LLMs' ability to utilize scene graphs for spatial and temporal understanding in multimodal environments.", "method": "The authors developed TSG Bench, a benchmark to assess LLMs' scene graph understanding and generation capabilities, evaluating 11 models.", "result": "LLMs perform well on scene graph understanding but struggle with generation, particularly for complex narratives, due to ineffective scene decomposition.", "conclusion": "The findings highlight the need for improved methodologies in scene graph generation and provide insights for future research."}}
{"id": "2505.21070", "pdf": "https://arxiv.org/pdf/2505.21070", "abs": "https://arxiv.org/abs/2505.21070", "authors": ["Zeqing Wang", "Bowen Zheng", "Xingyi Yang", "Zhenxiong Tan", "Yuecong Xu", "Xinchao Wang"], "title": "Minute-Long Videos with Dual Parallelisms", "categories": ["cs.CV"], "comment": "The code is available at\n  https://github.com/DualParal-Project/DualParal", "summary": "Diffusion Transformer (DiT)-based video diffusion models generate\nhigh-quality videos at scale but incur prohibitive processing latency and\nmemory costs for long videos. To address this, we propose a novel distributed\ninference strategy, termed DualParal. The core idea is that, instead of\ngenerating an entire video on a single GPU, we parallelize both temporal frames\nand model layers across GPUs. However, a naive implementation of this division\nfaces a key limitation: since diffusion models require synchronized noise\nlevels across frames, this implementation leads to the serialization of\noriginal parallelisms. We leverage a block-wise denoising scheme to handle\nthis. Namely, we process a sequence of frame blocks through the pipeline with\nprogressively decreasing noise levels. Each GPU handles a specific block and\nlayer subset while passing previous results to the next GPU, enabling\nasynchronous computation and communication. To further optimize performance, we\nincorporate two key enhancements. Firstly, a feature cache is implemented on\neach GPU to store and reuse features from the prior block as context,\nminimizing inter-GPU communication and redundant computation. Secondly, we\nemploy a coordinated noise initialization strategy, ensuring globally\nconsistent temporal dynamics by sharing initial noise patterns across GPUs\nwithout extra resource costs. Together, these enable fast, artifact-free, and\ninfinitely long video generation. Applied to the latest diffusion transformer\nvideo generator, our method efficiently produces 1,025-frame videos with up to\n6.54$\\times$ lower latency and 1.48$\\times$ lower memory cost on 8$\\times$RTX\n4090 GPUs.", "AI": {"tldr": "DualParal, a distributed inference strategy, reduces latency and memory costs for DiT-based video diffusion models by parallelizing temporal frames and model layers across GPUs, using block-wise denoising and optimizations like feature caching and coordinated noise initialization.", "motivation": "Addressing the high processing latency and memory costs of DiT-based video diffusion models for long videos.", "method": "Proposes DualParal, which parallelizes frames and layers across GPUs with block-wise denoising, feature caching, and coordinated noise initialization.", "result": "Achieves 6.54\u00d7 lower latency and 1.48\u00d7 lower memory cost for generating 1,025-frame videos on 8\u00d7RTX 4090 GPUs.", "conclusion": "DualParal enables efficient, artifact-free, and infinitely long video generation with significant performance improvements."}}
{"id": "2505.04209", "pdf": "https://arxiv.org/pdf/2505.04209", "abs": "https://arxiv.org/abs/2505.04209", "authors": ["Soumik Dey", "Hansi Wu", "Binbin Li"], "title": "To Judge or not to Judge: Using LLM Judgements for Advertiser Keyphrase Relevance at eBay", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": null, "summary": "E-commerce sellers are recommended keyphrases based on their inventory on\nwhich they advertise to increase buyer engagement (clicks/sales). The relevance\nof advertiser keyphrases plays an important role in preventing the inundation\nof search systems with numerous irrelevant items that compete for attention in\nauctions, in addition to maintaining a healthy seller perception. In this work,\nwe describe the shortcomings of training Advertiser keyphrase relevance filter\nmodels on click/sales/search relevance signals and the importance of aligning\nwith human judgment, as sellers have the power to adopt or reject said\nkeyphrase recommendations. In this study, we frame Advertiser keyphrase\nrelevance as a complex interaction between 3 dynamical systems -- seller\njudgment, which influences seller adoption of our product, Advertising, which\nprovides the keyphrases to bid on, and Search, who holds the auctions for the\nsame keyphrases. This study discusses the practicalities of using human\njudgment via a case study at eBay Advertising and demonstrate that using\nLLM-as-a-judge en-masse as a scalable proxy for seller judgment to train our\nrelevance models achieves a better harmony across the three systems -- provided\nthat they are bound by a meticulous evaluation framework grounded in business\nmetrics.", "AI": {"tldr": "The paper highlights the need to align advertiser keyphrase relevance models with human judgment, using LLM-as-a-judge for scalability, to improve harmony between seller judgment, advertising, and search systems.", "motivation": "To address the shortcomings of training keyphrase relevance models on click/sales signals alone and emphasize aligning with human judgment for better seller adoption and system harmony.", "method": "Frames keyphrase relevance as an interaction between seller judgment, advertising, and search systems, using LLM-as-a-judge as a scalable proxy for human judgment.", "result": "Demonstrates that using LLM-as-a-judge with a meticulous evaluation framework improves harmony across the three systems.", "conclusion": "Aligning relevance models with human judgment via scalable proxies like LLMs enhances system performance and seller adoption."}}
{"id": "2410.15268", "pdf": "https://arxiv.org/pdf/2410.15268", "abs": "https://arxiv.org/abs/2410.15268", "authors": ["Bo Pan", "Zhen Xiong", "Guanchen Wu", "Zheng Zhang", "Yifei Zhang", "Liang Zhao"], "title": "GraphNarrator: Generating Textual Explanations for Graph Neural Networks", "categories": ["cs.LG", "cs.CL"], "comment": "ACL 2025 (Main)", "summary": "Graph representation learning has garnered significant attention due to its\nbroad applications in various domains, such as recommendation systems and\nsocial network analysis. Despite advancements in graph learning methods,\nchallenges still remain in explainability when graphs are associated with\nsemantic features. In this paper, we present GraphNarrator, the first method\ndesigned to generate natural language explanations for Graph Neural Networks.\nGraphNarrator employs a generative language model that maps input-output pairs\nto explanations reflecting the model's decision-making process. To address the\nlack of ground truth explanations to train the model, we propose first\ngenerating pseudo-labels that capture the model's decisions from saliency-based\nexplanations, then using Expert Iteration to iteratively train the pseudo-label\ngenerator based on training objectives on explanation quality. The high-quality\npseudo-labels are finally utilized to train an end-to-end explanation generator\nmodel. Extensive experiments are conducted to demonstrate the effectiveness of\nGraphNarrator in producing faithful, concise, and human-preferred natural\nlanguage explanations.", "AI": {"tldr": "GraphNarrator is a method for generating natural language explanations for Graph Neural Networks (GNNs) using pseudo-labels and Expert Iteration to train an explanation generator.", "motivation": "Addressing the lack of explainability in GNNs when graphs have semantic features.", "method": "Uses a generative language model to map input-output pairs to explanations, with pseudo-labels from saliency-based explanations and Expert Iteration for training.", "result": "Produces faithful, concise, and human-preferred explanations.", "conclusion": "GraphNarrator effectively bridges the explainability gap in GNNs."}}
{"id": "2505.19529", "pdf": "https://arxiv.org/pdf/2505.19529", "abs": "https://arxiv.org/abs/2505.19529", "authors": ["Tanjil Hasan Sakib", "Md. Tanzib Hosain", "Md. Kishor Morol"], "title": "Small Language Models: Architectures, Techniques, Evaluation, Problems and Future Adaptation", "categories": ["cs.CL"], "comment": "9 pages", "summary": "Small Language Models (SLMs) have gained substantial attention due to their\nability to execute diverse language tasks successfully while using fewer\ncomputer resources. These models are particularly ideal for deployment in\nlimited environments, such as mobile devices, on-device processing, and edge\nsystems. In this study, we present a complete assessment of SLMs, focussing on\ntheir design frameworks, training approaches, and techniques for lowering model\nsize and complexity. We offer a novel classification system to organize the\noptimization approaches applied for SLMs, encompassing strategies like pruning,\nquantization, and model compression. Furthermore, we assemble SLM's studies of\nevaluation suite with some existing datasets, establishing a rigorous platform\nfor measuring SLM capabilities. Alongside this, we discuss the important\ndifficulties that remain unresolved in this sector, including trade-offs\nbetween efficiency and performance, and we suggest directions for future study.\nWe anticipate this study to serve as a beneficial guide for researchers and\npractitioners who aim to construct compact, efficient, and high-performing\nlanguage models.", "AI": {"tldr": "The paper provides a comprehensive review of Small Language Models (SLMs), covering design, training, optimization techniques, and evaluation, while highlighting unresolved challenges and future directions.", "motivation": "SLMs are gaining attention for their efficiency in resource-limited environments, but a systematic assessment of their design and optimization is lacking.", "method": "The study reviews SLM frameworks, training approaches, and optimization techniques (pruning, quantization, compression), proposes a classification system, and assembles an evaluation suite.", "result": "A novel classification system for SLM optimization is introduced, and a rigorous evaluation platform is established.", "conclusion": "The study serves as a guide for developing efficient SLMs, addressing unresolved challenges like performance-efficiency trade-offs and suggesting future research directions."}}
{"id": "2505.21117", "pdf": "https://arxiv.org/pdf/2505.21117", "abs": "https://arxiv.org/abs/2505.21117", "authors": ["Adeela Islam", "Stefano Fiorini", "Stuart James", "Pietro Morerio", "Alessio Del Bue"], "title": "ReassembleNet: Learnable Keypoints and Diffusion for 2D Fresco Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "The task of reassembly is a significant challenge across multiple domains,\nincluding archaeology, genomics, and molecular docking, requiring the precise\nplacement and orientation of elements to reconstruct an original structure. In\nthis work, we address key limitations in state-of-the-art Deep Learning methods\nfor reassembly, namely i) scalability; ii) multimodality; and iii) real-world\napplicability: beyond square or simple geometric shapes, realistic and complex\nerosion, or other real-world problems. We propose ReassembleNet, a method that\nreduces complexity by representing each input piece as a set of contour\nkeypoints and learning to select the most informative ones by Graph Neural\nNetworks pooling inspired techniques. ReassembleNet effectively lowers\ncomputational complexity while enabling the integration of features from\nmultiple modalities, including both geometric and texture data. Further\nenhanced through pretraining on a semi-synthetic dataset. We then apply\ndiffusion-based pose estimation to recover the original structure. We improve\non prior methods by 55% and 86% for RMSE Rotation and Translation,\nrespectively.", "AI": {"tldr": "ReassembleNet improves reassembly tasks by reducing complexity with contour keypoints and GNN pooling, achieving significant accuracy gains.", "motivation": "Addressing scalability, multimodality, and real-world applicability limitations in current Deep Learning methods for reassembly tasks.", "method": "Uses contour keypoints and GNN pooling to reduce complexity, integrates multimodal features, and employs diffusion-based pose estimation.", "result": "Achieves 55% and 86% improvements in RMSE for rotation and translation, respectively.", "conclusion": "ReassembleNet offers a scalable, multimodal solution for complex reassembly tasks with superior performance."}}
{"id": "2505.06612", "pdf": "https://arxiv.org/pdf/2505.06612", "abs": "https://arxiv.org/abs/2505.06612", "authors": ["Yuqin Lan", "Laurence T. Yang"], "title": "Burger: Robust Graph Denoising-augmentation Fusion and Multi-semantic Modeling in Social Recommendation", "categories": ["cs.SI", "cs.AI", "cs.IR", "F.2.2; I.2.7"], "comment": "10 pages, 5 figures", "summary": "In the era of rapid development of social media, social recommendation\nsystems as hybrid recommendation systems have been widely applied. Existing\nmethods capture interest similarity between users to filter out\ninterest-irrelevant relations in social networks that inevitably decrease\nrecommendation accuracy, however, limited research has a focus on the mutual\ninfluence of semantic information between the social network and the user-item\ninteraction network for further improving social recommendation. To address\nthese issues, we introduce a social \\underline{r}ecommendation model with\nro\\underline{bu}st g\\underline{r}aph denoisin\\underline{g}-augmentation fusion\nand multi-s\\underline{e}mantic Modeling(Burger). Specifically, we firstly\npropose to construct a social tensor in order to smooth the training process of\nthe model. Then, a graph convolutional network and a tensor convolutional\nnetwork are employed to capture user's item preference and social preference,\nrespectively. Considering the different semantic information in the user-item\ninteraction network and the social network, a bi-semantic coordination loss is\nproposed to model the mutual influence of semantic information. To alleviate\nthe interference of interest-irrelevant relations on multi-semantic modeling,\nwe further use Bayesian posterior probability to mine potential social\nrelations to replace social noise. Finally, the sliding window mechanism is\nutilized to update the social tensor as the input for the next iteration.\nExtensive experiments on three real datasets show Burger has a superior\nperformance compared with the state-of-the-art models.", "AI": {"tldr": "The paper introduces Burger, a social recommendation model combining robust graph denoising-augmentation fusion and multi-semantic modeling to improve recommendation accuracy by addressing semantic information mutual influence and noise in social networks.", "motivation": "Existing methods focus on user interest similarity but neglect the mutual influence of semantic information between social and user-item interaction networks, limiting recommendation accuracy.", "method": "Burger constructs a social tensor, uses graph and tensor convolutional networks for preference capture, introduces bi-semantic coordination loss, and employs Bayesian posterior probability to filter noise.", "result": "Experiments on three datasets show Burger outperforms state-of-the-art models.", "conclusion": "Burger effectively improves social recommendation by integrating multi-semantic modeling and robust graph denoising."}}
{"id": "2410.17194", "pdf": "https://arxiv.org/pdf/2410.17194", "abs": "https://arxiv.org/abs/2410.17194", "authors": ["Kento Nishi", "Maya Okawa", "Rahul Ramesh", "Mikail Khona", "Hidenori Tanaka", "Ekdeep Singh Lubana"], "title": "Representation Shattering in Transformers: A Synthetic Study with Knowledge Editing", "categories": ["cs.LG"], "comment": "Accepted to ICML 2025", "summary": "Knowledge Editing (KE) algorithms alter models' weights to perform targeted\nupdates to incorrect, outdated, or otherwise unwanted factual associations.\nHowever, recent work has shown that applying KE can adversely affect models'\nbroader factual recall accuracy and diminish their reasoning abilities.\nAlthough these studies give insights into the potential harms of KE algorithms,\ne.g., performance evaluations on benchmarks, little is understood about why\nsuch destructive failures occur. Motivated by this, we define a novel synthetic\ntask in which a Transformer is trained from scratch to internalize a\n\"structured\" knowledge graph. The structure enforces relationships between\nentities of the graph, such that editing a factual association has \"trickling\neffects\" on other entities (e.g., altering X's parent is Y to Z affects who X's\nsiblings' parent is). Through evaluations of edited models on this task, we\nshow that KE inadvertently affects representations of entities beyond the\ntargeted one, distorting relevant structures that allow a model to infer unseen\nknowledge about an entity. We call this phenomenon representation shattering\nand demonstrate that it degrades models' factual recall and reasoning\nperformance. We further corroborate our findings in naturalistic settings with\npre-trained Llama and Mamba models as well. Overall, our work yields a precise\nmechanistic hypothesis to explain why KE has adverse effects on model\nabilities.", "AI": {"tldr": "Knowledge Editing (KE) algorithms can harm models' factual recall and reasoning by distorting broader entity representations, termed 'representation shattering'.", "motivation": "To understand why KE algorithms cause destructive failures in models' broader factual recall and reasoning abilities.", "method": "A synthetic task was created where a Transformer internalizes a structured knowledge graph, and KE's effects were evaluated.", "result": "KE distorts entity representations beyond the targeted one, degrading factual recall and reasoning.", "conclusion": "The study provides a mechanistic explanation for KE's adverse effects, validated in pre-trained models."}}
{"id": "2505.20088", "pdf": "https://arxiv.org/pdf/2505.20088", "abs": "https://arxiv.org/abs/2505.20088", "authors": ["Nitay Calderon", "Liat Ein-Dor", "Roi Reichart"], "title": "Multi-Domain Explainability of Preferences", "categories": ["cs.CL"], "comment": null, "summary": "Preference mechanisms, such as human preference, LLM-as-a-Judge (LaaJ), and\nreward models, are central to aligning and evaluating large language models\n(LLMs). Yet, the underlying concepts that drive these preferences remain poorly\nunderstood. In this work, we propose a fully automated method for generating\nlocal and global concept-based explanations of preferences across multiple\ndomains. Our method utilizes an LLM to identify concepts that distinguish\nbetween chosen and rejected responses, and to represent them with concept-based\nvectors. To model the relationships between concepts and preferences, we\npropose a white-box Hierarchical Multi-Domain Regression model that captures\nboth domain-general and domain-specific effects. To evaluate our method, we\ncurate a dataset spanning eight challenging and diverse domains and explain\ntwelve mechanisms. Our method achieves strong preference prediction\nperformance, outperforming baselines while also being explainable.\nAdditionally, we assess explanations in two application-driven settings. First,\nguiding LLM outputs with concepts from LaaJ explanations yields responses that\nthose judges consistently prefer. Second, prompting LaaJs with concepts\nexplaining humans improves their preference predictions. Together, our work\nestablishes a new paradigm for explainability in the era of LLMs.", "AI": {"tldr": "A method for generating concept-based explanations of preferences in LLMs, using automated concept identification and a hierarchical regression model, improves prediction and explainability.", "motivation": "Understanding the underlying concepts driving preferences in LLMs is unclear, despite their importance in alignment and evaluation.", "method": "Uses an LLM to identify distinguishing concepts and a white-box hierarchical regression model to capture domain-general and domain-specific effects.", "result": "Outperforms baselines in preference prediction, enhances LLM outputs, and improves human preference predictions.", "conclusion": "Introduces a new paradigm for explainability in LLMs, demonstrating practical benefits in guiding outputs and improving predictions."}}
{"id": "2505.21144", "pdf": "https://arxiv.org/pdf/2505.21144", "abs": "https://arxiv.org/abs/2505.21144", "authors": ["Sergey Karpukhin", "Vadim Titov", "Andrey Kuznetsov", "Aibek Alanov"], "title": "FastFace: Tuning Identity Preservation in Distilled Diffusion via Guidance and Attention", "categories": ["cs.CV"], "comment": "code available at https://github.com/ControlGenAI/FastFace", "summary": "In latest years plethora of identity-preserving adapters for a personalized\ngeneration with diffusion models have been released. Their main disadvantage is\nthat they are dominantly trained jointly with base diffusion models, which\nsuffer from slow multi-step inference. This work aims to tackle the challenge\nof training-free adaptation of pretrained ID-adapters to diffusion models\naccelerated via distillation - through careful re-design of classifier-free\nguidance for few-step stylistic generation and attention manipulation\nmechanisms in decoupled blocks to improve identity similarity and fidelity, we\npropose universal FastFace framework. Additionally, we develop a disentangled\npublic evaluation protocol for id-preserving adapters.", "AI": {"tldr": "The paper introduces FastFace, a framework for training-free adaptation of ID-adapters to diffusion models, improving speed and identity fidelity.", "motivation": "Existing ID-adapters for diffusion models are slow due to joint training with base models. The goal is to enable faster, training-free adaptation.", "method": "Redesigns classifier-free guidance for few-step generation and uses attention manipulation in decoupled blocks. Introduces FastFace framework.", "result": "Improves identity similarity and fidelity while enabling faster inference. Also proposes a public evaluation protocol.", "conclusion": "FastFace offers a universal solution for efficient, high-fidelity ID-preserving generation with diffusion models."}}
{"id": "2505.07683", "pdf": "https://arxiv.org/pdf/2505.07683", "abs": "https://arxiv.org/abs/2505.07683", "authors": ["Steven Song", "Morgan Borjigin-Wang", "Irene Madejski", "Robert L. Grossman"], "title": "Multimodal Survival Modeling in the Age of Foundation Models", "categories": ["cs.LG", "cs.AI"], "comment": "23 pages, 7 figures, 8 tables, updated with acknowledgements and\n  declarations of interest", "summary": "The Cancer Genome Atlas (TCGA) has enabled novel discoveries and served as a\nlarge-scale reference through its harmonized genomics, clinical, and image\ndata. Prior studies have trained bespoke cancer survival prediction models from\nunimodal or multimodal TCGA data. A modern paradigm in biomedical deep learning\nis the development of foundation models (FMs) to derive meaningful feature\nembeddings, agnostic to a specific modeling task. Biomedical text especially\nhas seen growing development of FMs. While TCGA contains free-text data as\npathology reports, these have been historically underutilized. Here, we\ninvestigate the feasibility of training classical, multimodal survival models\nover zero-shot embeddings extracted by FMs. We show the ease and additive\neffect of multimodal fusion, outperforming unimodal models. We demonstrate the\nbenefit of including pathology report text and rigorously evaluate the effect\nof model-based text summarization and hallucination. Overall, we modernize\nsurvival modeling by leveraging FMs and information extraction from pathology\nreports.", "AI": {"tldr": "The paper explores using foundation models (FMs) to extract zero-shot embeddings from TCGA data, including pathology reports, for multimodal survival prediction, showing improved performance over unimodal models.", "motivation": "To leverage underutilized free-text pathology reports in TCGA and modernize survival prediction by integrating multimodal data with foundation models.", "method": "Training classical, multimodal survival models using zero-shot embeddings from FMs, including pathology reports, and evaluating text summarization and hallucination effects.", "result": "Multimodal fusion outperforms unimodal models, demonstrating the additive benefit of including pathology report text.", "conclusion": "The study successfully modernizes survival modeling by utilizing FMs and extracting valuable information from pathology reports."}}
{"id": "2410.20041", "pdf": "https://arxiv.org/pdf/2410.20041", "abs": "https://arxiv.org/abs/2410.20041", "authors": ["Adit Jain", "Soumyabrata Pal", "Sunav Choudhary", "Ramasuri Narayanam", "Harshita Chopra", "Vikram Krishnamurthy"], "title": "Sparse Linear Bandits with Blocking Constraints", "categories": ["cs.LG"], "comment": "37 Pages, 5 Theorems", "summary": "We investigate the high-dimensional sparse linear bandits problem in a\ndata-poor regime where the time horizon is much smaller than the ambient\ndimension and number of arms. We study the setting under the additional\nblocking constraint where each unique arm can be pulled only once. The blocking\nconstraint is motivated by practical applications in personalized content\nrecommendation and identification of data points to improve annotation\nefficiency for complex learning tasks. With mild assumptions on the arms, our\nproposed online algorithm (BSLB) achieves a regret guarantee of\n$\\widetilde{\\mathsf{O}}((1+\\beta_k)^2k^{\\frac{2}{3}} \\mathsf{T}^{\\frac{2}{3}})$\nwhere the parameter vector has an (unknown) relative tail $\\beta_k$ -- the\nratio of $\\ell_1$ norm of the top-$k$ and remaining entries of the parameter\nvector. To this end, we show novel offline statistical guarantees of the lasso\nestimator for the linear model that is robust to the sparsity modeling\nassumption. Finally, we propose a meta-algorithm (C-BSLB) based on corralling\nthat does not need knowledge of optimal sparsity parameter $k$ at minimal cost\nto regret. Our experiments on multiple real-world datasets demonstrate the\nvalidity of our algorithms and theoretical framework.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.20921", "pdf": "https://arxiv.org/pdf/2505.20921", "abs": "https://arxiv.org/abs/2505.20921", "authors": ["Injae Na", "Keonwoong Noh", "Woohwan Jung"], "title": "Automatic Transmission for LLM Tiers: Optimizing Cost and Accuracy in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 (Findings)", "summary": "LLM providers typically offer multiple LLM tiers, varying in performance and\nprice. As NLP tasks become more complex and modularized, selecting the suitable\nLLM tier for each subtask is a key challenge to balance between cost and\nperformance. To address the problem, we introduce LLM Automatic Transmission\n(LLM-AT) framework that automatically selects LLM tiers without training.\nLLM-AT consists of Starter, Generator, and Judge. The starter selects the\ninitial LLM tier expected to solve the given question, the generator produces a\nresponse using the LLM of the selected tier, and the judge evaluates the\nvalidity of the response. If the response is invalid, LLM-AT iteratively\nupgrades to a higher-tier model, generates a new response, and re-evaluates\nuntil a valid response is obtained. Additionally, we propose accuracy\nestimator, which enables the suitable initial LLM tier selection without\ntraining. Given an input question, accuracy estimator estimates the expected\naccuracy of each LLM tier by computing the valid response rate across top-k\nsimilar queries from past inference records. Experiments demonstrate that\nLLM-AT achieves superior performance while reducing costs, making it a\npractical solution for real-world applications.", "AI": {"tldr": "LLM-AT is a framework for automatically selecting the best LLM tier for subtasks, balancing cost and performance without training. It uses Starter, Generator, and Judge components, along with an accuracy estimator, to iteratively upgrade LLM tiers until a valid response is achieved.", "motivation": "To address the challenge of selecting the right LLM tier for subtasks in complex NLP tasks, balancing cost and performance.", "method": "LLM-AT consists of Starter (initial tier selection), Generator (response generation), and Judge (response validation). It iteratively upgrades tiers if responses are invalid. An accuracy estimator predicts initial tier suitability using past records.", "result": "LLM-AT achieves superior performance while reducing costs, validated through experiments.", "conclusion": "LLM-AT is a practical solution for real-world applications, optimizing LLM tier selection for cost-effective performance."}}
{"id": "2505.21238", "pdf": "https://arxiv.org/pdf/2505.21238", "abs": "https://arxiv.org/abs/2505.21238", "authors": ["Jieyu Yuan", "Yujun Li", "Yuanlin Zhang", "Chunle Guo", "Xiongxin Tang", "Ruixing Wang", "Chongyi Li"], "title": "3D-UIR: 3D Gaussian for Underwater 3D Scene Reconstruction via Physics Based Appearance-Medium Decoupling", "categories": ["cs.CV"], "comment": null, "summary": "Novel view synthesis for underwater scene reconstruction presents unique\nchallenges due to complex light-media interactions. Optical scattering and\nabsorption in water body bring inhomogeneous medium attenuation interference\nthat disrupts conventional volume rendering assumptions of uniform propagation\nmedium. While 3D Gaussian Splatting (3DGS) offers real-time rendering\ncapabilities, it struggles with underwater inhomogeneous environments where\nscattering media introduce artifacts and inconsistent appearance. In this\nstudy, we propose a physics-based framework that disentangles object appearance\nfrom water medium effects through tailored Gaussian modeling. Our approach\nintroduces appearance embeddings, which are explicit medium representations for\nbackscatter and attenuation, enhancing scene consistency. In addition, we\npropose a distance-guided optimization strategy that leverages pseudo-depth\nmaps as supervision with depth regularization and scale penalty terms to\nimprove geometric fidelity. By integrating the proposed appearance and medium\nmodeling components via an underwater imaging model, our approach achieves both\nhigh-quality novel view synthesis and physically accurate scene restoration.\nExperiments demonstrate our significant improvements in rendering quality and\nrestoration accuracy over existing methods. The project page is available at\nhttps://bilityniu.github.io/3D-UIR.", "AI": {"tldr": "A physics-based framework improves underwater novel view synthesis by disentangling object appearance from water medium effects, using tailored Gaussian modeling and distance-guided optimization.", "motivation": "Underwater scenes suffer from inhomogeneous medium attenuation and scattering, disrupting conventional rendering methods like 3D Gaussian Splatting.", "method": "The framework uses appearance embeddings for medium effects and a distance-guided optimization strategy with pseudo-depth maps for geometric fidelity.", "result": "The approach outperforms existing methods in rendering quality and restoration accuracy.", "conclusion": "The proposed method effectively addresses underwater scene challenges, achieving high-quality synthesis and accurate restoration."}}
{"id": "2505.11692", "pdf": "https://arxiv.org/pdf/2505.11692", "abs": "https://arxiv.org/abs/2505.11692", "authors": ["Sahil Rajesh Dhayalkar"], "title": "The Geometry of ReLU Networks through the ReLU Transition Graph", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "13 pages, 4 figures", "summary": "We develop a novel theoretical framework for analyzing ReLU neural networks\nthrough the lens of a combinatorial object we term the ReLU Transition Graph\n(RTG). In this graph, each node corresponds to a linear region induced by the\nnetwork's activation patterns, and edges connect regions that differ by a\nsingle neuron flip. Building on this structure, we derive a suite of new\ntheoretical results connecting RTG geometry to expressivity, generalization,\nand robustness. Our contributions include tight combinatorial bounds on RTG\nsize and diameter, a proof of RTG connectivity, and graph-theoretic\ninterpretations of VC-dimension. We also relate entropy and average degree of\nthe RTG to generalization error. Each theoretical result is rigorously\nvalidated via carefully controlled experiments across varied network depths,\nwidths, and data regimes. This work provides the first unified treatment of\nReLU network structure via graph theory and opens new avenues for compression,\nregularization, and complexity control rooted in RTG analysis.", "AI": {"tldr": "The paper introduces the ReLU Transition Graph (RTG) to analyze ReLU neural networks, linking its geometry to expressivity, generalization, and robustness. It provides combinatorial bounds, proofs, and experimental validation, offering a graph-theoretic approach for network analysis.", "motivation": "To understand ReLU neural networks' behavior and properties through a combinatorial and graph-theoretic lens, enabling better control over network design and performance.", "method": "Develops the RTG, where nodes represent linear regions and edges connect regions differing by a single neuron flip. Uses this framework to derive theoretical results and validate them experimentally.", "result": "Proves tight bounds on RTG size and diameter, connectivity, and connects RTG properties to VC-dimension and generalization error. Experiments confirm theoretical findings.", "conclusion": "The RTG framework unifies ReLU network analysis via graph theory, offering new insights for compression, regularization, and complexity control."}}
{"id": "2411.06503", "pdf": "https://arxiv.org/pdf/2411.06503", "abs": "https://arxiv.org/abs/2411.06503", "authors": ["Guangyi Wang", "Wei Peng", "Lijiang Li", "Wenyu Chen", "Yuren Cai", "Songzhi Su"], "title": "Diffusion Sampling Correction via Approximately 10 Parameters", "categories": ["cs.LG", "cs.CV"], "comment": "Accepted at ICML 2025", "summary": "While powerful for generation, Diffusion Probabilistic Models (DPMs) face\nslow sampling challenges, for which various distillation-based methods have\nbeen proposed. However, they typically require significant additional training\ncosts and model parameter storage, limiting their practicality. In this work,\nwe propose PCA-based Adaptive Search (PAS), which optimizes existing solvers\nfor DPMs with minimal additional costs. Specifically, we first employ PCA to\nobtain a few basis vectors to span the high-dimensional sampling space, which\nenables us to learn just a set of coordinates to correct the sampling\ndirection; furthermore, based on the observation that the cumulative truncation\nerror exhibits an ``S\"-shape, we design an adaptive search strategy that\nfurther enhances the sampling efficiency and reduces the number of stored\nparameters to approximately 10. Extensive experiments demonstrate that PAS can\nsignificantly enhance existing fast solvers in a plug-and-play manner with\nnegligible costs. E.g., on CIFAR10, PAS optimizes DDIM's FID from 15.69 to 4.37\n(NFE=10) using only 12 parameters and sub-minute training on a single A100 GPU.\nCode is available at https://github.com/onefly123/PAS.", "AI": {"tldr": "PAS optimizes DPM solvers with minimal costs using PCA-based adaptive search, improving sampling efficiency and reducing parameters.", "motivation": "DPMs face slow sampling and high costs with existing distillation methods, limiting practicality.", "method": "Uses PCA to span sampling space with basis vectors and adaptive search to correct direction and reduce parameters.", "result": "PAS enhances solvers like DDIM, improving FID from 15.69 to 4.37 (NFE=10) with only 12 parameters and sub-minute training.", "conclusion": "PAS is a cost-effective, plug-and-play solution for improving DPM sampling efficiency."}}
{"id": "2505.21889", "pdf": "https://arxiv.org/pdf/2505.21889", "abs": "https://arxiv.org/abs/2505.21889", "authors": ["Tianyu Guo", "Hande Dong", "Yichong Leng", "Feng Liu", "Cheater Lin", "Nong Xiao", "Xianwei Zhang"], "title": "EFIM: Efficient Serving of LLMs for Infilling Tasks with Improved KV Cache Reuse", "categories": ["cs.CL"], "comment": "31st International European Conference on Parallel and Distributed\n  Computing (Euro-Par 2025 Oral)", "summary": "Large language models (LLMs) are often used for infilling tasks, which\ninvolve predicting or generating missing information in a given text. These\ntasks typically require multiple interactions with similar context. To reduce\nthe computation of repeated historical tokens, cross-request key-value (KV)\ncache reuse, a technique that stores and reuses intermediate computations, has\nbecome a crucial method in multi-round interactive services. However, in\ninfilling tasks, the KV cache reuse is often hindered by the structure of the\nprompt format, which typically consists of a prefix and suffix relative to the\ninsertion point. Specifically, the KV cache of the prefix or suffix part is\nfrequently invalidated as the other part (suffix or prefix) is incrementally\ngenerated. To address the issue, we propose EFIM, a transformed prompt format\nof FIM to unleash the performance potential of KV cache reuse. Although the\ntransformed prompt can solve the inefficiency, it exposes subtoken generation\nproblems in current LLMs, where they have difficulty generating partial words\naccurately. Therefore, we introduce a fragment tokenization training method\nwhich splits text into multiple fragments before tokenization during data\nprocessing. Experiments on two representative LLMs show that LLM serving with\nEFIM can lower the latency by 52% and improve the throughput by 98% while\nmaintaining the original infilling capability. EFIM's source code is publicly\navailable at https://github.com/gty111/EFIM.", "AI": {"tldr": "EFIM improves KV cache reuse in LLMs for infilling tasks by transforming the prompt format and introducing fragment tokenization, reducing latency by 52% and boosting throughput by 98%.", "motivation": "KV cache reuse in infilling tasks is hindered by prompt structure, leading to inefficiency due to invalidated prefix/suffix caches.", "method": "Proposes EFIM, a transformed prompt format, and fragment tokenization to address inefficiencies and subtoken generation issues.", "result": "EFIM reduces latency by 52% and increases throughput by 98% while maintaining infilling accuracy.", "conclusion": "EFIM effectively optimizes LLM performance for infilling tasks through prompt transformation and fragment tokenization."}}
{"id": "2505.21535", "pdf": "https://arxiv.org/pdf/2505.21535", "abs": "https://arxiv.org/abs/2505.21535", "authors": ["Yuxin Ren", "Maxwell D Collins", "Miao Hu", "Huanrui Yang"], "title": "Is Attention Required for Transformer Inference? Explore Function-preserving Attention Replacement", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "12 pages main paper + 6 pages appendix, 14 figures", "summary": "While transformers excel across vision and language pretraining tasks, their\nreliance on attention mechanisms poses challenges for inference efficiency,\nespecially on edge and embedded accelerators with limited parallelism and\nmemory bandwidth. Hinted by the observed redundancy of attention at inference\ntime, we hypothesize that though the model learns complicated token dependency\nthrough pretraining, the inference-time sequence-to-sequence mapping in each\nattention layer is actually ''simple'' enough to be represented with a much\ncheaper function. In this work, we explore FAR, a Function-preserving Attention\nReplacement framework that replaces all attention blocks in pretrained\ntransformers with learnable sequence-to-sequence modules, exemplified by an\nLSTM. FAR optimize a multi-head LSTM architecture with a block-wise\ndistillation objective and a global structural pruning framework to achieve a\nfamily of efficient LSTM-based models from pretrained transformers. We validate\nFAR on the DeiT vision transformer family and demonstrate that it matches the\naccuracy of the original models on ImageNet and multiple downstream tasks with\nreduced parameters and latency. Further analysis shows that FAR preserves the\nsemantic token relationships and the token-to-token correlation learned in the\ntransformer's attention module.", "AI": {"tldr": "FAR replaces attention blocks in transformers with LSTM modules, improving efficiency while maintaining accuracy.", "motivation": "Transformers' attention mechanisms are inefficient for inference on edge devices; FAR aims to simplify this.", "method": "FAR uses LSTM-based modules and distillation to replace attention blocks, optimizing for efficiency.", "result": "FAR matches original model accuracy on ImageNet and downstream tasks with reduced latency and parameters.", "conclusion": "FAR successfully preserves transformer performance while enhancing inference efficiency."}}
{"id": "2505.11694", "pdf": "https://arxiv.org/pdf/2505.11694", "abs": "https://arxiv.org/abs/2505.11694", "authors": ["Sahil Rajesh Dhayalkar"], "title": "Neural Networks as Universal Finite-State Machines: A Constructive Deterministic Finite Automaton Theory", "categories": ["cs.LG", "cs.AI", "cs.FL"], "comment": "15 pages, 1 figure", "summary": "We present a complete theoretical and empirical framework establishing\nfeedforward neural networks as universal finite-state machines (N-FSMs). Our\nresults prove that finite-depth ReLU and threshold networks can exactly\nsimulate deterministic finite automata (DFAs) by unrolling state transitions\ninto depth-wise neural layers, with formal characterizations of required depth,\nwidth, and state compression. We demonstrate that DFA transitions are linearly\nseparable, binary threshold activations allow exponential compression, and\nMyhill-Nerode equivalence classes can be embedded into continuous latent spaces\nwhile preserving separability. We also formalize the expressivity boundary:\nfixed-depth feedforward networks cannot recognize non-regular languages\nrequiring unbounded memory. Unlike prior heuristic or probing-based studies, we\nprovide constructive proofs and design explicit DFA-unrolled neural\narchitectures that empirically validate every claim. Our results bridge deep\nlearning, automata theory, and neural-symbolic computation, offering a rigorous\nblueprint for how discrete symbolic processes can be realized in continuous\nneural systems.", "AI": {"tldr": "Feedforward neural networks are proven to simulate deterministic finite automata (DFAs) with exactness, bridging deep learning and automata theory.", "motivation": "To rigorously establish neural networks as universal finite-state machines and bridge the gap between discrete symbolic processes and continuous neural systems.", "method": "Theoretical and empirical framework using finite-depth ReLU and threshold networks to unroll DFA state transitions into neural layers, with formal characterizations of depth, width, and state compression.", "result": "DFA transitions are linearly separable, binary threshold activations enable exponential compression, and Myhill-Nerode classes embed into continuous spaces. Fixed-depth networks cannot recognize non-regular languages.", "conclusion": "The study provides a rigorous foundation for neural-symbolic computation, validating claims with explicit DFA-unrolled architectures."}}
{"id": "2412.00798", "pdf": "https://arxiv.org/pdf/2412.00798", "abs": "https://arxiv.org/abs/2412.00798", "authors": ["Seockbean Song", "Youngsik Yoon", "Siwei Wang", "Wei Chen", "Jungseul Ok"], "title": "Combinatorial Rising Bandit", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Combinatorial online learning is a fundamental task for selecting the optimal\naction (or super arm) as a combination of base arms in sequential interactions\nwith systems providing stochastic rewards. It is applicable to diverse domains\nsuch as robotics, social advertising, network routing, and recommendation\nsystems. In many real-world scenarios, we often encounter rising rewards, where\nplaying a base arm not only provides an instantaneous reward but also\ncontributes to the enhancement of future rewards, e.g., robots enhancing\nproficiency through practice and social influence strengthening in the history\nof successful recommendations. Moreover, the enhancement of a single base arm\nmay affect multiple super arms that include it, introducing complex\ndependencies that are not captured by existing rising bandit models. To address\nthis, we introduce the Combinatorial Rising Bandit (CRB) framework and propose\na provably efficient algorithm, Combinatorial Rising Upper Confidence Bound\n(CRUCB). We establish an upper bound on regret CRUCB and show that it is nearly\ntight by deriving a matching lower bound. In addition, we empirically\ndemonstrate the effectiveness of CRUCB not only in synthetic environments but\nalso in realistic applications of deep reinforcement learning.", "AI": {"tldr": "The paper introduces the Combinatorial Rising Bandit (CRB) framework and the CRUCB algorithm to address rising rewards in combinatorial online learning, with theoretical and empirical validation.", "motivation": "Existing models don't capture complex dependencies in rising rewards, where base arms enhance future rewards across multiple super arms.", "method": "Proposes the CRB framework and the CRUCB algorithm, providing theoretical regret bounds and empirical validation.", "result": "CRUCB achieves nearly tight regret bounds and performs well in synthetic and real-world applications like deep reinforcement learning.", "conclusion": "The CRB framework and CRUCB algorithm effectively address rising rewards in combinatorial online learning, with proven efficiency and practical applicability."}}
{"id": "2505.22018", "pdf": "https://arxiv.org/pdf/2505.22018", "abs": "https://arxiv.org/abs/2505.22018", "authors": ["Ruicheng Yin", "Xuan Gao", "Changze Lv", "Xiaohua Wang", "Xiaoqing Zheng", "Xuanjing Huang"], "title": "Improving Continual Pre-training Through Seamless Data Packing", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Findings", "summary": "Continual pre-training has demonstrated significant potential in enhancing\nmodel performance, particularly in domain-specific scenarios. The most common\napproach for packing data before continual pre-training involves concatenating\ninput texts and splitting them into fixed-length sequences. While\nstraightforward and efficient, this method often leads to excessive truncation\nand context discontinuity, which can hinder model performance. To address these\nissues, we explore the potential of data engineering to enhance continual\npre-training, particularly its impact on model performance and efficiency. We\npropose Seamless Packing (SP), a novel data packing strategy aimed at\npreserving contextual information more effectively and enhancing model\nperformance. Our approach employs a sliding window technique in the first stage\nthat synchronizes overlapping tokens across consecutive sequences, ensuring\nbetter continuity and contextual coherence. In the second stage, we adopt a\nFirst-Fit-Decreasing algorithm to pack shorter texts into bins slightly larger\nthan the target sequence length, thereby minimizing padding and truncation.\nEmpirical evaluations across various model architectures and corpus domains\ndemonstrate the effectiveness of our method, outperforming baseline method in\n99% of all settings. Code is available at\nhttps://github.com/Infernus-WIND/Seamless-Packing.", "AI": {"tldr": "The paper introduces Seamless Packing (SP), a data packing strategy for continual pre-training that reduces truncation and context discontinuity, improving model performance.", "motivation": "Existing data packing methods for continual pre-training cause excessive truncation and context discontinuity, harming model performance.", "method": "SP uses a sliding window for overlapping tokens and a First-Fit-Decreasing algorithm to pack shorter texts, minimizing padding and truncation.", "result": "SP outperforms baselines in 99% of settings across various models and domains.", "conclusion": "SP effectively enhances continual pre-training by preserving context and reducing truncation, with significant performance gains."}}
{"id": "2505.21549", "pdf": "https://arxiv.org/pdf/2505.21549", "abs": "https://arxiv.org/abs/2505.21549", "authors": ["Daniel Csizmadia", "Andrei Codreanu", "Victor Sim", "Vighnesh Prabhu", "Michael Lu", "Kevin Zhu", "Sean O'Brien", "Vasu Sharma"], "title": "Distill CLIP (DCLIP): Enhancing Image-Text Retrieval via Cross-Modal Transformer Distillation", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "We present Distill CLIP (DCLIP), a fine-tuned variant of the CLIP model that\nenhances multimodal image-text retrieval while preserving the original model's\nstrong zero-shot classification capabilities. CLIP models are typically\nconstrained by fixed image resolutions and limited context, which can hinder\ntheir effectiveness in retrieval tasks that require fine-grained cross-modal\nunderstanding. DCLIP addresses these challenges through a meta teacher-student\ndistillation framework, where a cross-modal transformer teacher is fine-tuned\nto produce enriched embeddings via bidirectional cross-attention between\nYOLO-extracted image regions and corresponding textual spans. These\nsemantically and spatially aligned global representations guide the training of\na lightweight student model using a hybrid loss that combines contrastive\nlearning and cosine similarity objectives. Despite being trained on only\n~67,500 samples curated from MSCOCO, Flickr30k, and Conceptual Captions-just a\nfraction of CLIP's original dataset-DCLIP significantly improves image-text\nretrieval metrics (Recall@K, MAP), while retaining approximately 94% of CLIP's\nzero-shot classification performance. These results demonstrate that DCLIP\neffectively mitigates the trade-off between task specialization and\ngeneralization, offering a resource-efficient, domain-adaptive, and\ndetail-sensitive solution for advanced vision-language tasks. Code available at\nhttps://anonymous.4open.science/r/DCLIP-B772/README.md.", "AI": {"tldr": "DCLIP is a fine-tuned CLIP variant improving image-text retrieval without losing zero-shot classification, using a meta teacher-student distillation framework.", "motivation": "CLIP models struggle with fine-grained cross-modal understanding due to fixed resolutions and limited context. DCLIP aims to enhance retrieval while preserving generalization.", "method": "Uses a cross-modal transformer teacher for enriched embeddings via bidirectional cross-attention, training a lightweight student with hybrid contrastive and cosine loss.", "result": "Improves retrieval metrics (Recall@K, MAP) with ~67,500 samples, retaining 94% of CLIP's zero-shot performance.", "conclusion": "DCLIP balances task specialization and generalization efficiently for vision-language tasks."}}
{"id": "2505.16499", "pdf": "https://arxiv.org/pdf/2505.16499", "abs": "https://arxiv.org/abs/2505.16499", "authors": ["Roberto Morabito", "SiYoung Jang"], "title": "Smaller, Smarter, Closer: The Edge of Collaborative Generative AI", "categories": ["cs.DC", "cs.AI", "cs.NI"], "comment": "This paper has been accepted for publication in IEEE Internet\n  Computing. Upon publication, the copyright will be transferred to IEEE", "summary": "The rapid adoption of generative AI (GenAI), particularly Large Language\nModels (LLMs), has exposed critical limitations of cloud-centric deployments,\nincluding latency, cost, and privacy concerns. Meanwhile, Small Language Models\n(SLMs) are emerging as viable alternatives for resource-constrained edge\nenvironments, though they often lack the capabilities of their larger\ncounterparts. This article explores the potential of collaborative inference\nsystems that leverage both edge and cloud resources to address these\nchallenges. By presenting distinct cooperation strategies alongside practical\ndesign principles and experimental insights, we offer actionable guidance for\ndeploying GenAI across the computing continuum.", "AI": {"tldr": "The paper explores collaborative inference systems combining edge and cloud resources to address limitations of cloud-centric GenAI deployments, offering practical strategies for deployment.", "motivation": "Challenges like latency, cost, and privacy in cloud-centric GenAI deployments, and the limitations of Small Language Models (SLMs) in edge environments.", "method": "Proposes collaborative inference systems leveraging both edge and cloud resources, with distinct cooperation strategies and design principles.", "result": "Provides actionable guidance for deploying GenAI across the computing continuum, supported by experimental insights.", "conclusion": "Collaborative inference systems can effectively address the limitations of cloud-centric GenAI and SLMs, enabling efficient deployment across diverse environments."}}
{"id": "2412.11180", "pdf": "https://arxiv.org/pdf/2412.11180", "abs": "https://arxiv.org/abs/2412.11180", "authors": ["Ziang Zhou", "Zhihao Ding", "Jieming Shi", "Qing Li", "Shiqi Shen"], "title": "TINED: GNNs-to-MLPs by Teacher Injection and Dirichlet Energy Distillation", "categories": ["cs.LG", "cs.SI"], "comment": "17 pages, published as a conference paper at ICML 2025", "summary": "Graph Neural Networks (GNNs) are pivotal in graph-based learning,\nparticularly excelling in node classification. However, their scalability is\nhindered by the need for multi-hop data during inference, limiting their\napplication in latency-sensitive scenarios. Recent efforts to distill GNNs into\nmulti-layer perceptrons (MLPs) for faster inference often underutilize the\nlayer-level insights of GNNs. In this paper, we present TINED, a novel approach\nthat distills GNNs to MLPs on a layer-by-layer basis using Teacher Injection\nand Dirichlet Energy Distillation techniques. We focus on two key operations in\nGNN layers: feature transformation (FT) and graph propagation (GP). We\nrecognize that FT is computationally equivalent to a fully-connected (FC) layer\nin MLPs. Thus, we propose directly transferring teacher parameters from an FT\nin a GNN to an FC layer in the student MLP, enhanced by fine-tuning. In TINED,\nthe FC layers in an MLP replicate the sequence of FTs and GPs in the GNN. We\nalso establish a theoretical bound for GP approximation. Furthermore, we note\nthat FT and GP operations in GNN layers often exhibit opposing smoothing\neffects: GP is aggressive, while FT is conservative. Using Dirichlet energy, we\ndevelop a DE ratio to measure these effects and propose Dirichlet Energy\nDistillation to convey these characteristics from GNN layers to MLP layers.\nExtensive experiments show that TINED outperforms GNNs and leading distillation\nmethods across various settings and seven datasets. Source code are available\nat https://github.com/scottjiao/TINED_ICML25/.", "AI": {"tldr": "TINED distills GNNs into MLPs layer-by-layer using Teacher Injection and Dirichlet Energy Distillation, improving inference speed while maintaining performance.", "motivation": "GNNs face scalability issues due to multi-hop data needs during inference, limiting latency-sensitive applications. Existing MLP distillation methods underutilize GNN layer insights.", "method": "TINED transfers GNN feature transformation (FT) parameters to MLP fully-connected (FC) layers, fine-tunes them, and approximates graph propagation (GP) with theoretical bounds. It uses Dirichlet Energy Distillation to balance smoothing effects of FT and GP.", "result": "TINED outperforms GNNs and leading distillation methods across seven datasets, demonstrating superior performance and efficiency.", "conclusion": "TINED effectively addresses GNN scalability by distilling them into MLPs, leveraging layer-level insights and theoretical approximations for faster inference without compromising accuracy."}}
{"id": "2505.22179", "pdf": "https://arxiv.org/pdf/2505.22179", "abs": "https://arxiv.org/abs/2505.22179", "authors": ["Yudi Zhang", "Weilin Zhao", "Xu Han", "Tiejun Zhao", "Wang Xu", "Hailong Cao", "Conghui Zhu"], "title": "Speculative Decoding Meets Quantization: Compatibility Evaluation and Hierarchical Framework Design", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "12 pages, 5 figures", "summary": "Speculative decoding and quantization effectively accelerate memory-bound\ninference of large language models. Speculative decoding mitigates the memory\nbandwidth bottleneck by verifying multiple tokens within a single forward pass,\nwhich increases computational effort. Quantization achieves this optimization\nby compressing weights and activations into lower bit-widths and also reduces\ncomputations via low-bit matrix multiplications. To further leverage their\nstrengths, we investigate the integration of these two techniques.\nSurprisingly, experiments applying the advanced speculative decoding method\nEAGLE-2 to various quantized models reveal that the memory benefits from 4-bit\nweight quantization are diminished by the computational load from speculative\ndecoding. Specifically, verifying a tree-style draft incurs significantly more\ntime overhead than a single-token forward pass on 4-bit weight quantized\nmodels. This finding led to our new speculative decoding design: a hierarchical\nframework that employs a small model as an intermediate stage to turn\ntree-style drafts into sequence drafts, leveraging the memory access benefits\nof the target quantized model. Experimental results show that our hierarchical\napproach achieves a 2.78$\\times$ speedup across various tasks for the 4-bit\nweight Llama-3-70B model on an A100 GPU, outperforming EAGLE-2 by 1.31$\\times$.\nCode available at https://github.com/AI9Stars/SpecMQuant.", "AI": {"tldr": "Integrating speculative decoding with quantization in large language models reveals trade-offs; a hierarchical framework improves speedup by 2.78\u00d7 for 4-bit models.", "motivation": "To optimize memory-bound inference in large language models by combining speculative decoding and quantization, addressing their individual limitations.", "method": "Investigates integrating speculative decoding (EAGLE-2) with quantization, then proposes a hierarchical framework using a small model to convert tree-style drafts into sequence drafts.", "result": "The hierarchical approach achieves a 2.78\u00d7 speedup for 4-bit Llama-3-70B, outperforming EAGLE-2 by 1.31\u00d7.", "conclusion": "The hierarchical framework effectively balances memory and computational trade-offs, enhancing inference speed for quantized models."}}
{"id": "2505.21649", "pdf": "https://arxiv.org/pdf/2505.21649", "abs": "https://arxiv.org/abs/2505.21649", "authors": ["Keanu Nichols", "Nazia Tasnim", "Yuting Yan", "Nicholas Ikechukwu", "Elva Zou", "Deepti Ghadiyaram", "Bryan A. Plummer"], "title": "Right Side Up? Disentangling Orientation Understanding in MLLMs with Fine-grained Multi-axis Perception Tasks", "categories": ["cs.CV"], "comment": null, "summary": "Object orientation understanding represents a fundamental challenge in visual\nperception critical for applications like robotic manipulation and augmented\nreality. Current vision-language benchmarks fail to isolate this capability,\noften conflating it with positional relationships and general scene\nunderstanding. We introduce DORI (Discriminative Orientation Reasoning\nIntelligence), a comprehensive benchmark establishing object orientation\nperception as a primary evaluation target. DORI assesses four dimensions of\norientation comprehension: frontal alignment, rotational transformations,\nrelative directional relationships, and canonical orientation understanding.\nThrough carefully curated tasks from 11 datasets spanning 67 object categories\nacross synthetic and real-world scenarios, DORI provides insights on how\nmulti-modal systems understand object orientations. Our evaluation of 15\nstate-of-the-art vision-language models reveals critical limitations: even the\nbest models achieve only 54.2% accuracy on coarse tasks and 33.0% on granular\norientation judgments, with performance deteriorating for tasks requiring\nreference frame shifts or compound rotations. These findings demonstrate the\nneed for dedicated orientation representation mechanisms, as models show\nsystematic inability to perform precise angular estimations, track orientation\nchanges across viewpoints, and understand compound rotations - suggesting\nlimitations in their internal 3D spatial representations. As the first\ndiagnostic framework specifically designed for orientation awareness in\nmultimodal systems, DORI offers implications for improving robotic control, 3D\nscene reconstruction, and human-AI interaction in physical environments. DORI\ndata: https://huggingface.co/datasets/appledora/DORI-Benchmark", "AI": {"tldr": "DORI is a benchmark for evaluating object orientation understanding in vision-language models, revealing significant limitations in current systems.", "motivation": "Current benchmarks conflate object orientation with other visual tasks, making it hard to isolate this critical capability for applications like robotics and AR.", "method": "DORI assesses orientation comprehension through four dimensions using tasks from 11 datasets across 67 object categories.", "result": "Top models achieve only 54.2% accuracy on coarse tasks and 33.0% on granular ones, struggling with reference frame shifts and compound rotations.", "conclusion": "DORI highlights the need for better orientation representation in models, with implications for robotics, 3D reconstruction, and human-AI interaction."}}
{"id": "2505.16508", "pdf": "https://arxiv.org/pdf/2505.16508", "abs": "https://arxiv.org/abs/2505.16508", "authors": ["SiYoung Jang", "Roberto Morabito"], "title": "Edge-First Language Model Inference: Models, Metrics, and Tradeoffs", "categories": ["cs.DC", "cs.AI", "cs.NI", "cs.PF"], "comment": "This paper has been accepted for publication and presentation at the\n  45th IEEE International Conference on Distributed Computing Systems (IEEE\n  ICDCS 2025). The copyright will be transferred to IEEE upon publication in\n  the conference proceedings", "summary": "The widespread adoption of Language Models (LMs) across industries is driving\ninterest in deploying these services across the computing continuum, from the\ncloud to the network edge. This shift aims to reduce costs, lower latency, and\nimprove reliability and privacy. Small Language Models (SLMs), enabled by\nadvances in model compression, are central to this shift, offering a path to\non-device inference on resource-constrained edge platforms. This work examines\nthe interplay between edge and cloud deployments, starting from detailed\nbenchmarking of SLM capabilities on single edge devices, and extending to\ndistributed edge clusters. We identify scenarios where edge inference offers\ncomparable performance with lower costs, and others where cloud fallback\nbecomes essential due to limits in scalability or model capacity. Rather than\nproposing a one-size-fits-all solution, we present platform-level comparisons\nand design insights for building efficient, adaptive LM inference systems\nacross heterogeneous environments.", "AI": {"tldr": "The paper explores deploying Small Language Models (SLMs) on edge devices versus cloud, highlighting trade-offs in performance, cost, and scalability.", "motivation": "To leverage SLMs for cost-effective, low-latency, and privacy-preserving inference at the edge, while addressing limitations through cloud fallback.", "method": "Benchmarks SLMs on single edge devices and distributed clusters, comparing edge and cloud deployments.", "result": "Identifies scenarios where edge inference is viable and others requiring cloud fallback due to scalability or capacity limits.", "conclusion": "Advocates for adaptive LM inference systems tailored to heterogeneous environments, avoiding one-size-fits-all solutions."}}
{"id": "2412.18202", "pdf": "https://arxiv.org/pdf/2412.18202", "abs": "https://arxiv.org/abs/2412.18202", "authors": ["Zhuohuan Hu", "Richard Yu", "Zizhou Zhang", "Haoran Zheng", "Qianying Liu", "Yining Zhou"], "title": "Developing Cryptocurrency Trading Strategy Based on Autoencoder-CNN-GANs Algorithms", "categories": ["cs.LG", "q-fin.ST"], "comment": "The paper was accepted by 2024 4th International Conference on\n  Artificial Intelligence, Robotics, and Communication(ICAIRC 2024)", "summary": "This paper leverages machine learning algorithms to forecast and analyze\nfinancial time series. The process begins with a denoising autoencoder to\nfilter out random noise fluctuations from the main contract price data. Then,\none-dimensional convolution reduces the dimensionality of the filtered data and\nextracts key information. The filtered and dimensionality-reduced price data is\nfed into a GANs network, and its output serve as input of a fully connected\nnetwork. Through cross-validation, a model is trained to capture features that\nprecede large price fluctuations. The model predicts the likelihood and\ndirection of significant price changes in real-time price sequences, placing\ntrades at moments of high prediction accuracy. Empirical results demonstrate\nthat using autoencoders and convolution to filter and denoise financial data,\ncombined with GANs, achieves a certain level of predictive performance,\nvalidating the capabilities of machine learning algorithms to discover\nunderlying patterns in financial sequences. Keywords - CNN;GANs;\nCryptocurrency; Prediction.", "AI": {"tldr": "The paper proposes a machine learning pipeline combining denoising autoencoders, CNNs, and GANs to predict financial price movements, showing empirical success in forecasting significant fluctuations.", "motivation": "To improve financial time series forecasting by leveraging machine learning to filter noise, reduce dimensionality, and capture predictive patterns in price data.", "method": "Uses a denoising autoencoder for noise removal, 1D convolution for dimensionality reduction, GANs for data generation, and a fully connected network for prediction, validated via cross-validation.", "result": "The model effectively predicts the likelihood and direction of significant price changes, demonstrating the utility of machine learning in financial forecasting.", "conclusion": "The approach validates machine learning's ability to uncover hidden patterns in financial data, with potential applications in trading strategies."}}
{"id": "2505.22375", "pdf": "https://arxiv.org/pdf/2505.22375", "abs": "https://arxiv.org/abs/2505.22375", "authors": ["Hanting Chen", "Yasheng Wang", "Kai Han", "Dong Li", "Lin Li", "Zhenni Bi", "Jinpeng Li", "Haoyu Wang", "Fei Mi", "Mingjian Zhu", "Bin Wang", "Kaikai Song", "Yifei Fu", "Xu He", "Yu Luo", "Chong Zhu", "Quan He", "Xueyu Wu", "Wei He", "Hailin Hu", "Yehui Tang", "Dacheng Tao", "Xinghao Chen", "Yunhe Wang"], "title": "Pangu Embedded: An Efficient Dual-system LLM Reasoner with Metacognition", "categories": ["cs.CL"], "comment": null, "summary": "This work presents Pangu Embedded, an efficient Large Language Model (LLM)\nreasoner developed on Ascend Neural Processing Units (NPUs), featuring flexible\nfast and slow thinking capabilities. Pangu Embedded addresses the significant\ncomputational costs and inference latency challenges prevalent in existing\nreasoning-optimized LLMs. We propose a two-stage training framework for its\nconstruction. In Stage 1, the model is finetuned via an iterative distillation\nprocess, incorporating inter-iteration model merging to effectively aggregate\ncomplementary knowledge. This is followed by reinforcement learning on Ascend\nclusters, optimized by a latency-tolerant scheduler that combines stale\nsynchronous parallelism with prioritized data queues. The RL process is guided\nby a Multi-source Adaptive Reward System (MARS), which generates dynamic,\ntask-specific reward signals using deterministic metrics and lightweight LLM\nevaluators for mathematics, coding, and general problem-solving tasks. Stage 2\nintroduces a dual-system framework, endowing Pangu Embedded with a \"fast\" mode\nfor routine queries and a deeper \"slow\" mode for complex inference. This\nframework offers both manual mode switching for user control and an automatic,\ncomplexity-aware mode selection mechanism that dynamically allocates\ncomputational resources to balance latency and reasoning depth. Experimental\nresults on benchmarks including AIME 2024, GPQA, and LiveCodeBench demonstrate\nthat Pangu Embedded with 7B parameters, outperforms similar-size models like\nQwen3-8B and GLM4-9B. It delivers rapid responses and state-of-the-art\nreasoning quality within a single, unified model architecture, highlighting a\npromising direction for developing powerful yet practically deployable LLM\nreasoners.", "AI": {"tldr": "Pangu Embedded is an efficient LLM reasoner for Ascend NPUs, featuring fast/slow thinking modes, addressing computational costs and latency. It uses a two-stage training framework and outperforms similar models.", "motivation": "To tackle high computational costs and inference latency in reasoning-optimized LLMs, enabling efficient deployment.", "method": "Two-stage training: Stage 1 involves iterative distillation and reinforcement learning with MARS. Stage 2 introduces a dual-system framework for fast/slow modes.", "result": "Outperforms models like Qwen3-8B and GLM4-9B on benchmarks (AIME 2024, GPQA, LiveCodeBench) with 7B parameters.", "conclusion": "Pangu Embedded offers a unified, deployable LLM reasoner with balanced latency and reasoning depth, setting a promising direction for future models."}}
{"id": "2505.21780", "pdf": "https://arxiv.org/pdf/2505.21780", "abs": "https://arxiv.org/abs/2505.21780", "authors": ["Yanbo Wang", "Justin Dauwels", "Yilun Du"], "title": "Compositional Scene Understanding through Inverse Generative Modeling", "categories": ["cs.CV"], "comment": "ICML 2025, Webpage:\n  https://energy-based-model.github.io/compositional-inference", "summary": "Generative models have demonstrated remarkable abilities in generating\nhigh-fidelity visual content. In this work, we explore how generative models\ncan further be used not only to synthesize visual content but also to\nunderstand the properties of a scene given a natural image. We formulate scene\nunderstanding as an inverse generative modeling problem, where we seek to find\nconditional parameters of a visual generative model to best fit a given natural\nimage. To enable this procedure to infer scene structure from images\nsubstantially different than those seen during training, we further propose to\nbuild this visual generative model compositionally from smaller models over\npieces of a scene. We illustrate how this procedure enables us to infer the set\nof objects in a scene, enabling robust generalization to new test scenes with\nan increased number of objects of new shapes. We further illustrate how this\nenables us to infer global scene factors, likewise enabling robust\ngeneralization to new scenes. Finally, we illustrate how this approach can be\ndirectly applied to existing pretrained text-to-image generative models for\nzero-shot multi-object perception. Code and visualizations are at\nhttps://energy-based-model.github.io/compositional-inference.", "AI": {"tldr": "The paper explores using generative models for scene understanding by treating it as an inverse generative modeling problem, enabling robust generalization to new scenes and objects.", "motivation": "To extend generative models beyond content synthesis to scene understanding, inferring scene properties from natural images.", "method": "Formulates scene understanding as inverse generative modeling, using compositional models to infer scene structure and global factors.", "result": "Enables robust generalization to new scenes with more objects or new shapes, and zero-shot multi-object perception.", "conclusion": "The approach effectively leverages generative models for scene understanding, demonstrating broad applicability and generalization."}}
{"id": "2505.16968", "pdf": "https://arxiv.org/pdf/2505.16968", "abs": "https://arxiv.org/abs/2505.16968", "authors": ["Ahmed Heakl", "Sarim Hashmi", "Gustavo Bertolo Stahl", "Seung Hun Eddie Han", "Salman Khan", "Abdulrahman Mahmoud"], "title": "CASS: Nvidia to AMD Transpilation with Data, Models, and Benchmark", "categories": ["cs.AR", "cs.AI", "cs.CL", "cs.LG", "cs.PL"], "comment": "20 pages, 11 figures, 5 tables", "summary": "We introduce CASS, the first large-scale dataset and model suite for\ncross-architecture GPU code transpilation, targeting both source-level (CUDA\n<--> HIP) and assembly-level (Nvidia SASS <--> AMD RDNA3) translation. The\ndataset comprises 70k verified code pairs across host and device, addressing a\ncritical gap in low-level GPU code portability. Leveraging this resource, we\ntrain the CASS family of domain-specific language models, achieving 95% source\ntranslation accuracy and 37.5% assembly translation accuracy, substantially\noutperforming commercial baselines such as GPT-4o, Claude, and Hipify. Our\ngenerated code matches native performance in over 85% of test cases, preserving\nruntime and memory behavior. To support rigorous evaluation, we introduce\nCASS-Bench, a curated benchmark spanning 16 GPU domains with ground-truth\nexecution. All data, models, and evaluation tools are released as open source\nto foster progress in GPU compiler tooling, binary compatibility, and\nLLM-guided hardware translation.", "AI": {"tldr": "CASS introduces a dataset and model suite for cross-architecture GPU code transpilation, achieving high accuracy and outperforming commercial tools.", "motivation": "Addressing the gap in low-level GPU code portability by enabling translation between CUDA/HIP and Nvidia SASS/AMD RDNA3.", "method": "Training domain-specific language models on a dataset of 70k verified code pairs.", "result": "Achieves 95% source and 37.5% assembly translation accuracy, with generated code matching native performance in 85% of cases.", "conclusion": "CASS advances GPU compiler tooling and binary compatibility, with open-source release for broader progress."}}
{"id": "2501.10348", "pdf": "https://arxiv.org/pdf/2501.10348", "abs": "https://arxiv.org/abs/2501.10348", "authors": ["Zizhou Zhang", "Xinshi Li", "Yu Cheng", "Zhenrui Chen", "Qianying Liu"], "title": "Credit Risk Identification in Supply Chains Using Generative Adversarial Networks", "categories": ["cs.LG"], "comment": "The paper will be published and indexed by IEEE at 2025 8th\n  International Conference on Advanced Algorithms and Control Engineering\n  (ICAACE 2025)", "summary": "Credit risk management within supply chains has emerged as a critical\nresearch area due to its significant implications for operational stability and\nfinancial sustainability. The intricate interdependencies among supply chain\nparticipants mean that credit risks can propagate across networks, with impacts\nvarying by industry. This study explores the application of Generative\nAdversarial Networks (GANs) to enhance credit risk identification in supply\nchains. GANs enable the generation of synthetic credit risk scenarios,\naddressing challenges related to data scarcity and imbalanced datasets. By\nleveraging GAN-generated data, the model improves predictive accuracy while\neffectively capturing dynamic and temporal dependencies in supply chain data.\nThe research focuses on three representative industries-manufacturing (steel),\ndistribution (pharmaceuticals), and services (e-commerce) to assess\nindustry-specific credit risk contagion. Experimental results demonstrate that\nthe GAN-based model outperforms traditional methods, including logistic\nregression, decision trees, and neural networks, achieving superior accuracy,\nrecall, and F1 scores. The findings underscore the potential of GANs in\nproactive risk management, offering robust tools for mitigating financial\ndisruptions in supply chains. Future research could expand the model by\nincorporating external market factors and supplier relationships to further\nenhance predictive capabilities. Keywords- Generative Adversarial Networks\n(GANs); Supply Chain Risk; Credit Risk Identification; Machine Learning; Data\nAugmentation", "AI": {"tldr": "The paper proposes using GANs to improve credit risk identification in supply chains, addressing data scarcity and imbalance. It outperforms traditional methods in accuracy, recall, and F1 scores.", "motivation": "Credit risk in supply chains can propagate widely, impacting operational stability. Data scarcity and imbalance hinder effective risk identification.", "method": "GANs generate synthetic credit risk scenarios to augment data. The model is tested in manufacturing, pharmaceuticals, and e-commerce.", "result": "The GAN-based model outperforms logistic regression, decision trees, and neural networks in accuracy, recall, and F1 scores.", "conclusion": "GANs offer robust tools for proactive credit risk management. Future work could include external market factors and supplier relationships."}}
{"id": "2505.22571", "pdf": "https://arxiv.org/pdf/2505.22571", "abs": "https://arxiv.org/abs/2505.22571", "authors": ["Hoang Pham", "Thuy-Duong Nguyen", "Khac-Hoai Nam Bui"], "title": "Agent-UniRAG: A Trainable Open-Source LLM Agent Framework for Unified Retrieval-Augmented Generation Systems", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR"], "comment": null, "summary": "This paper presents a novel approach for unified retrieval-augmented\ngeneration (RAG) systems using the recent emerging large language model (LLM)\nagent concept. Specifically, Agent LLM, which utilizes LLM as fundamental\ncontrollers, has become a promising approach to enable the interpretability of\nRAG tasks, especially for complex reasoning question-answering systems (e.g.,\nmulti-hop queries). Nonetheless, previous works mainly focus on solving RAG\nsystems with either single-hop or multi-hop approaches separately, which limits\nthe application of those approaches to real-world applications. In this study,\nwe propose a trainable agent framework called Agent-UniRAG for unified\nretrieval-augmented LLM systems, which enhances the effectiveness and\ninterpretability of RAG systems. The main idea is to design an LLM agent\nframework to solve RAG tasks step-by-step based on the complexity of the\ninputs, simultaneously including single-hop and multi-hop queries in an\nend-to-end manner. Furthermore, we introduce SynAgent-RAG, a synthetic dataset\nto enable the proposed agent framework for small open-source LLMs (e.g.,\nLlama-3-8B). The results show comparable performances with closed-source and\nlarger open-source LLMs across various RAG benchmarks. Our source code and\ndataset are publicly available for further exploitation.", "AI": {"tldr": "A novel unified RAG system, Agent-UniRAG, uses LLM agents for interpretability and handles both single-hop and multi-hop queries. It includes a synthetic dataset, SynAgent-RAG, for smaller LLMs, achieving competitive performance.", "motivation": "Previous RAG systems addressed single-hop or multi-hop queries separately, limiting real-world applicability. This work aims to unify these approaches for broader use.", "method": "Proposes Agent-UniRAG, a trainable LLM agent framework that processes queries step-by-step based on complexity, and introduces SynAgent-RAG dataset for smaller LLMs.", "result": "Agent-UniRAG performs comparably to closed-source and larger open-source LLMs on RAG benchmarks.", "conclusion": "The framework enhances RAG system effectiveness and interpretability, with publicly available code and dataset for further research."}}
{"id": "2505.21863", "pdf": "https://arxiv.org/pdf/2505.21863", "abs": "https://arxiv.org/abs/2505.21863", "authors": ["Shikhhar Siingh", "Abhinav Rawat", "Chitta Baral", "Vivek Gupta"], "title": "GETReason: Enhancing Image Context Extraction through Hierarchical Multi-Agent Reasoning", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Publicly significant images from events hold valuable contextual information,\ncrucial for journalism and education. However, existing methods often struggle\nto extract this relevance accurately. To address this, we introduce GETReason\n(Geospatial Event Temporal Reasoning), a framework that moves beyond\nsurface-level image descriptions to infer deeper contextual meaning. We propose\nthat extracting global event, temporal, and geospatial information enhances\nunderstanding of an image's significance. Additionally, we introduce GREAT\n(Geospatial Reasoning and Event Accuracy with Temporal Alignment), a new metric\nfor evaluating reasoning-based image understanding. Our layered multi-agent\napproach, assessed using a reasoning-weighted metric, demonstrates that\nmeaningful insights can be inferred, effectively linking images to their\nbroader event context.", "AI": {"tldr": "GETReason framework enhances image understanding by inferring deeper contextual meaning through geospatial, temporal, and event data, evaluated by the GREAT metric.", "motivation": "Existing methods fail to accurately extract contextual relevance from publicly significant images, limiting their utility in journalism and education.", "method": "Introduces GETReason, a layered multi-agent framework, and GREAT, a new metric for evaluating reasoning-based image understanding.", "result": "The approach successfully infers meaningful insights, linking images to broader event contexts.", "conclusion": "GETReason and GREAT improve contextual understanding of images, offering valuable tools for journalism and education."}}
{"id": "2505.17652", "pdf": "https://arxiv.org/pdf/2505.17652", "abs": "https://arxiv.org/abs/2505.17652", "authors": ["Deyang Kong", "Qi Guo", "Xiangyu Xi", "Wei Wang", "Jingang Wang", "Xunliang Cai", "Shikun Zhang", "Wei Ye"], "title": "Rethinking the Sampling Criteria in Reinforcement Learning for LLM Reasoning: A Competence-Difficulty Alignment Perspective", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning exhibits potential in enhancing the reasoning\nabilities of large language models, yet it is hard to scale for the low sample\nefficiency during the rollout phase. Existing methods attempt to improve\nefficiency by scheduling problems based on problem difficulties. However, these\napproaches suffer from unstable and biased estimations of problem difficulty\nand fail to capture the alignment between model competence and problem\ndifficulty in RL training, leading to suboptimal results. To tackle these\nlimitations, this paper introduces $\\textbf{C}$ompetence-$\\textbf{D}$ifficulty\n$\\textbf{A}$lignment $\\textbf{S}$ampling ($\\textbf{CDAS}$), which enables\naccurate and stable estimation of problem difficulties by aggregating\nhistorical performance discrepancies of problems. Then the model competence is\nquantified to adaptively select problems whose difficulty is in alignment with\nthe model's current competence using a fixed-point system. Experimental results\nacross a range of challenging mathematical benchmarks show that CDAS achieves\ngreat improvements in both accuracy and efficiency. CDAS attains the highest\naverage accuracy against baselines and exhibits significant speed advantages\ncompared to Dynamic Sampling, a competitive strategy in DAPO, which is 2.33\ntimes slower than CDAS.", "AI": {"tldr": "CDAS improves RL efficiency for language models by aligning problem difficulty with model competence, outperforming baselines in accuracy and speed.", "motivation": "Existing methods for improving RL efficiency in language models suffer from unstable difficulty estimation and misalignment with model competence, leading to suboptimal results.", "method": "Introduces CDAS, which aggregates historical performance to estimate problem difficulty and aligns it with model competence using a fixed-point system.", "result": "CDAS achieves higher accuracy and efficiency, outperforming baselines and being 2.33 times faster than Dynamic Sampling.", "conclusion": "CDAS effectively addresses the limitations of existing methods, demonstrating superior performance in RL training for language models."}}
{"id": "2501.13890", "pdf": "https://arxiv.org/pdf/2501.13890", "abs": "https://arxiv.org/abs/2501.13890", "authors": ["Ayush Mohanty", "Nazal Mohamed", "Paritosh Ramanan", "Nagi Gebraeel"], "title": "Federated Granger Causality Learning for Interdependent Clients with State Space Representation", "categories": ["cs.LG", "stat.ML"], "comment": "Published as a conference paper at International Conference on\n  Learning Representations (ICLR) 2025", "summary": "Advanced sensors and IoT devices have improved the monitoring and control of\ncomplex industrial enterprises. They have also created an interdependent fabric\nof geographically distributed process operations (clients) across these\nenterprises. Granger causality is an effective approach to detect and quantify\ninterdependencies by examining how one client's state affects others over time.\nUnderstanding these interdependencies captures how localized events, such as\nfaults and disruptions, can propagate throughout the system, possibly causing\nwidespread operational impacts. However, the large volume and complexity of\nindustrial data pose challenges in modeling these interdependencies. This paper\ndevelops a federated approach to learning Granger causality. We utilize a\nlinear state space system framework that leverages low-dimensional state\nestimates to analyze interdependencies. This addresses bandwidth limitations\nand the computational burden commonly associated with centralized data\nprocessing. We propose augmenting the client models with the Granger causality\ninformation learned by the server through a Machine Learning (ML) function. We\nexamine the co-dependence between the augmented client and server models and\nreformulate the framework as a standalone ML algorithm providing conditions for\nits sublinear and linear convergence rates. We also study the convergence of\nthe framework to a centralized oracle model. Moreover, we include a\ndifferential privacy analysis to ensure data security while preserving causal\ninsights. Using synthetic data, we conduct comprehensive experiments to\ndemonstrate the robustness of our approach to perturbations in causality, the\nscalability to the size of communication, number of clients, and the dimensions\nof raw data. We also evaluate the performance on two real-world industrial\ncontrol system datasets by reporting the volume of data saved by\ndecentralization.", "AI": {"tldr": "A federated approach for learning Granger causality in industrial IoT systems, addressing data volume and complexity while ensuring privacy and scalability.", "motivation": "To detect and quantify interdependencies in industrial IoT systems, where localized events can propagate widely, but centralized data processing is impractical due to bandwidth and computational constraints.", "method": "Uses a linear state space system framework with low-dimensional state estimates, augmented by server-learned Granger causality, and reformulated as a standalone ML algorithm with convergence guarantees.", "result": "Demonstrates robustness to perturbations, scalability in communication and data dimensions, and significant data savings in real-world industrial datasets.", "conclusion": "The federated approach effectively models interdependencies while addressing privacy and scalability challenges, validated through synthetic and real-world data."}}
{"id": "2505.21904", "pdf": "https://arxiv.org/pdf/2505.21904", "abs": "https://arxiv.org/abs/2505.21904", "authors": ["Pardis Taghavi", "Tian Liu", "Renjie Li", "Reza Langari", "Zhengzhong Tu"], "title": "CAST: Contrastive Adaptation and Distillation for Semi-Supervised Instance Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Instance segmentation demands costly per-pixel annotations and large models.\nWe introduce CAST, a semi-supervised knowledge distillation (SSKD) framework\nthat compresses pretrained vision foundation models (VFM) into compact experts\nusing limited labeled and abundant unlabeled data. CAST unfolds in three\nstages: (1) domain adaptation of the VFM teacher(s) via self-training with\ncontrastive pixel calibration, (2) distillation into a compact student via a\nunified multi-objective loss that couples standard supervision and\npseudo-labels with our instance-aware pixel-wise contrastive term, and (3)\nfine-tuning on labeled data to remove residual pseudo-label bias. Central to\nCAST is an \\emph{instance-aware pixel-wise contrastive loss} that fuses mask\nand class scores to mine informative negatives and enforce clear inter-instance\nmargins. By maintaining this contrastive signal across both adaptation and\ndistillation, we align teacher and student embeddings and fully leverage\nunlabeled images. On Cityscapes and ADE20K, our ~11X smaller student surpasses\nits adapted VFM teacher(s) by +3.4 AP (33.9 vs. 30.5) and +1.5 AP (16.7 vs.\n15.2) and outperforms state-of-the-art semi-supervised approaches.", "AI": {"tldr": "CAST is a semi-supervised knowledge distillation framework that compresses large vision foundation models into smaller, efficient experts using limited labeled and abundant unlabeled data, outperforming state-of-the-art methods.", "motivation": "Instance segmentation requires expensive annotations and large models. CAST aims to reduce these costs by leveraging unlabeled data and distilling knowledge from pretrained models.", "method": "CAST involves three stages: domain adaptation of the teacher model, distillation into a compact student using a multi-objective loss, and fine-tuning to remove pseudo-label bias. A key component is an instance-aware pixel-wise contrastive loss.", "result": "The compact student model (11X smaller) outperforms its teacher by +3.4 AP on Cityscapes and +1.5 AP on ADE20K, surpassing other semi-supervised methods.", "conclusion": "CAST effectively leverages unlabeled data and contrastive learning to create efficient, high-performing instance segmentation models."}}
{"id": "2505.18377", "pdf": "https://arxiv.org/pdf/2505.18377", "abs": "https://arxiv.org/abs/2505.18377", "authors": ["Pingchuan Ma", "Ziang Yin", "Qi Jing", "Zhengqi Gao", "Nicholas Gangi", "Boyang Zhang", "Tsung-Wei Huang", "Zhaoran Huang", "Duane S. Boning", "Yu Yao", "Jiaqi Gu"], "title": "SP2RINT: Spatially-Decoupled Physics-Inspired Progressive Inverse Optimization for Scalable, PDE-Constrained Meta-Optical Neural Network Training", "categories": ["physics.optics", "cs.AI", "cs.LG"], "comment": null, "summary": "DONNs leverage light propagation for efficient analog AI and signal\nprocessing. Advances in nanophotonic fabrication and metasurface-based\nwavefront engineering have opened new pathways to realize high-capacity DONNs\nacross various spectral regimes. Training such DONN systems to determine the\nmetasurface structures remains challenging. Heuristic methods are fast but\noversimplify metasurfaces modulation, often resulting in physically\nunrealizable designs and significant performance degradation.\nSimulation-in-the-loop optimizes implementable metasurfaces via adjoint\nmethods, but is computationally prohibitive and unscalable. To address these\nlimitations, we propose SP2RINT, a spatially decoupled, progressive training\nframework that formulates DONN training as a PDE-constrained learning problem.\nMetasurface responses are first relaxed into freely trainable transfer matrices\nwith a banded structure. We then progressively enforce physical constraints by\nalternating between transfer matrix training and adjoint-based inverse design,\navoiding per-iteration PDE solves while ensuring final physical realizability.\nTo further reduce runtime, we introduce a physics-inspired, spatially decoupled\ninverse design strategy based on the natural locality of field interactions.\nThis approach partitions the metasurface into independently solvable patches,\nenabling scalable and parallel inverse design with system-level calibration.\nEvaluated across diverse DONN training tasks, SP2RINT achieves\ndigital-comparable accuracy while being 1825 times faster than\nsimulation-in-the-loop approaches. By bridging the gap between abstract DONN\nmodels and implementable photonic hardware, SP2RINT enables scalable,\nhigh-performance training of physically realizable meta-optical neural systems.\nOur code is available at https://github.com/ScopeX-ASU/SP2RINT", "AI": {"tldr": "SP2RINT is a scalable training framework for DONNs, combining transfer matrix training and adjoint-based inverse design to achieve high accuracy and speed.", "motivation": "Overcoming the limitations of heuristic methods (unrealizable designs) and simulation-in-the-loop (computational cost) for training DONNs.", "method": "Progressive training with relaxed transfer matrices, alternating between training and adjoint-based inverse design, and spatially decoupled patches for scalability.", "result": "SP2RINT achieves digital-comparable accuracy and is 1825 times faster than simulation-in-the-loop methods.", "conclusion": "SP2RINT bridges the gap between abstract DONN models and implementable hardware, enabling scalable, high-performance training."}}
{"id": "2501.19050", "pdf": "https://arxiv.org/pdf/2501.19050", "abs": "https://arxiv.org/abs/2501.19050", "authors": ["Ruigang Wang", "Krishnamurthy Dvijotham", "Ian R. Manchester"], "title": "Norm-Bounded Low-Rank Adaptation", "categories": ["cs.LG"], "comment": null, "summary": "In this work, we propose norm-bounded low-rank adaptation (NB-LoRA) for\nparameter-efficient fine tuning. NB-LoRA is a novel parameterization of\nlow-rank weight adaptations that admits explicit bounds on each singular value\nof the adaptation matrix, which can thereby satisfy any prescribed unitarily\ninvariant norm bound, including the Schatten norms (e.g., nuclear, Frobenius,\nspectral norm). The proposed parameterization is unconstrained, smooth, and\ncomplete, i.e. it covers all matrices satisfying the prescribed rank and\nsingular-value bounds. Comparative experiments on large language models show\nthat NB-LoRA achieves superior adaptation performance and faster training over\na range of models, tasks and ranks. Vision fine-tuning experiments show that\nNB-LoRA can achieve strong adaptation performance while avoiding model\ncatastrophic forgetting, and compared to existing approaches it is\nsubstantially more robust to a hyper-parameters such as including adaptation\nrank, learning rate and number of training epochs.", "AI": {"tldr": "NB-LoRA is a parameter-efficient fine-tuning method with explicit bounds on singular values, outperforming existing approaches in performance and robustness.", "motivation": "To improve parameter-efficient fine-tuning by bounding singular values of adaptation matrices, ensuring better control and performance.", "method": "Proposes norm-bounded low-rank adaptation (NB-LoRA), a smooth and complete parameterization of low-rank weight adaptations with explicit singular value bounds.", "result": "NB-LoRA achieves superior performance and faster training in language models, and avoids catastrophic forgetting in vision tasks while being hyperparameter-robust.", "conclusion": "NB-LoRA is a robust and efficient method for fine-tuning, excelling in performance, training speed, and adaptability across tasks."}}
{"id": "2505.21956", "pdf": "https://arxiv.org/pdf/2505.21956", "abs": "https://arxiv.org/abs/2505.21956", "authors": ["Mengdan Zhu", "Senhao Cheng", "Guangji Bai", "Yifei Zhang", "Liang Zhao"], "title": "Cross-modal RAG: Sub-dimensional Retrieval-Augmented Text-to-Image Generation", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Text-to-image generation increasingly demands access to domain-specific,\nfine-grained, and rapidly evolving knowledge that pretrained models cannot\nfully capture. Existing Retrieval-Augmented Generation (RAG) methods attempt to\naddress this by retrieving globally relevant images, but they fail when no\nsingle image contains all desired elements from a complex user query. We\npropose Cross-modal RAG, a novel framework that decomposes both queries and\nimages into sub-dimensional components, enabling subquery-aware retrieval and\ngeneration. Our method introduces a hybrid retrieval strategy - combining a\nsub-dimensional sparse retriever with a dense retriever - to identify a\nPareto-optimal set of images, each contributing complementary aspects of the\nquery. During generation, a multimodal large language model is guided to\nselectively condition on relevant visual features aligned to specific\nsubqueries, ensuring subquery-aware image synthesis. Extensive experiments on\nMS-COCO, Flickr30K, WikiArt, CUB, and ImageNet-LT demonstrate that Cross-modal\nRAG significantly outperforms existing baselines in both retrieval and\ngeneration quality, while maintaining high efficiency.", "AI": {"tldr": "Cross-modal RAG improves text-to-image generation by decomposing queries and images into sub-dimensional components, enabling better retrieval and synthesis.", "motivation": "Address the limitation of existing RAG methods in handling complex queries where no single image contains all desired elements.", "method": "Proposes a hybrid retrieval strategy (sparse + dense retriever) and subquery-aware generation using a multimodal LLM.", "result": "Outperforms baselines in retrieval and generation quality across multiple datasets.", "conclusion": "Cross-modal RAG is effective and efficient for complex text-to-image tasks."}}
{"id": "2505.18893", "pdf": "https://arxiv.org/pdf/2505.18893", "abs": "https://arxiv.org/abs/2505.18893", "authors": ["Reva Schwartz", "Rumman Chowdhury", "Akash Kundu", "Heather Frase", "Marzieh Fadaee", "Tom David", "Gabriella Waters", "Afaf Taik", "Morgan Briggs", "Patrick Hall", "Shomik Jain", "Kyra Yee", "Spencer Thomas", "Sundeep Bhandari", "Qinghua Lu", "Matthew Holmes", "Theodora Skeadas"], "title": "Reality Check: A New Evaluation Ecosystem Is Necessary to Understand AI's Real World Effects", "categories": ["cs.CY", "cs.AI"], "comment": "9 pages", "summary": "Conventional AI evaluation approaches concentrated within the AI stack\nexhibit systemic limitations for exploring, navigating and resolving the human\nand societal factors that play out in real world deployment such as in\neducation, finance, healthcare, and employment sectors. AI capability\nevaluations can capture detail about first-order effects, such as whether\nimmediate system outputs are accurate, or contain toxic, biased or\nstereotypical content, but AI's second-order effects, i.e. any long-term\noutcomes and consequences that may result from AI use in the real world, have\nbecome a significant area of interest as the technology becomes embedded in our\ndaily lives. These secondary effects can include shifts in user behavior,\nsocietal, cultural and economic ramifications, workforce transformations, and\nlong-term downstream impacts that may result from a broad and growing set of\nrisks. This position paper argues that measuring the indirect and secondary\neffects of AI will require expansion beyond static, single-turn approaches\nconducted in silico to include testing paradigms that can capture what actually\nmaterializes when people use AI technology in context. Specifically, we\ndescribe the need for data and methods that can facilitate contextual awareness\nand enable downstream interpretation and decision making about AI's secondary\neffects, and recommend requirements for a new ecosystem.", "AI": {"tldr": "The paper highlights limitations in current AI evaluation methods, focusing on the need to assess long-term societal impacts of AI beyond immediate outputs.", "motivation": "To address the gap in evaluating AI's second-order effects, such as societal and economic impacts, which are overlooked by conventional methods.", "method": "Proposes expanding evaluation beyond static, in-silico approaches to include contextual testing paradigms for real-world AI use.", "result": "Identifies the necessity for new data and methods to understand and mitigate AI's secondary effects.", "conclusion": "Advocates for a new ecosystem to measure and manage AI's long-term societal impacts."}}
{"id": "2501.19300", "pdf": "https://arxiv.org/pdf/2501.19300", "abs": "https://arxiv.org/abs/2501.19300", "authors": ["Xutong Liu", "Xiangxiang Dai", "Jinhang Zuo", "Siwei Wang", "Carlee Joe-Wong", "John C. S. Lui", "Wei Chen"], "title": "Offline Learning for Combinatorial Multi-armed Bandits", "categories": ["cs.LG"], "comment": null, "summary": "The combinatorial multi-armed bandit (CMAB) is a fundamental sequential\ndecision-making framework, extensively studied over the past decade. However,\nexisting work primarily focuses on the online setting, overlooking the\nsubstantial costs of online interactions and the readily available offline\ndatasets. To overcome these limitations, we introduce Off-CMAB, the first\noffline learning framework for CMAB. Central to our framework is the\ncombinatorial lower confidence bound (CLCB) algorithm, which combines\npessimistic reward estimations with combinatorial solvers. To characterize the\nquality of offline datasets, we propose two novel data coverage conditions and\nprove that, under these conditions, CLCB achieves a near-optimal suboptimality\ngap, matching the theoretical lower bound up to a logarithmic factor. We\nvalidate Off-CMAB through practical applications, including learning to rank,\nlarge language model (LLM) caching, and social influence maximization, showing\nits ability to handle nonlinear reward functions, general feedback models, and\nout-of-distribution action samples that excludes optimal or even feasible\nactions. Extensive experiments on synthetic and real-world datasets further\nhighlight the superior performance of CLCB.", "AI": {"tldr": "Off-CMAB introduces an offline learning framework for combinatorial multi-armed bandits (CMAB), addressing the limitations of online-only approaches by leveraging offline datasets and the CLCB algorithm.", "motivation": "Existing CMAB research focuses on online settings, ignoring costly interactions and available offline data. Off-CMAB aims to bridge this gap.", "method": "The framework uses the combinatorial lower confidence bound (CLCB) algorithm, combining pessimistic reward estimations with combinatorial solvers, and introduces data coverage conditions for dataset quality.", "result": "Under proposed data coverage conditions, CLCB achieves near-optimal suboptimality gaps, validated in applications like learning to rank and LLM caching.", "conclusion": "Off-CMAB effectively handles nonlinear rewards, general feedback, and out-of-distribution actions, demonstrating superior performance in experiments."}}
{"id": "2502.11256", "pdf": "https://arxiv.org/pdf/2502.11256", "abs": "https://arxiv.org/abs/2502.11256", "authors": ["Yanran Wu", "Inez Hua", "Yi Ding"], "title": "Unveiling Environmental Impacts of Large Language Model Serving: A Functional Unit View", "categories": ["cs.LG", "cs.AR", "cs.CL"], "comment": "17 pages, 38 figures, Proceedings of the The 63rd Annual Meeting of\n  the Association for Computational Linguistics, Vienna, Austria, July\n  27-August 1st, 2025", "summary": "Large language models (LLMs) offer powerful capabilities but come with\nsignificant environmental impact, particularly in carbon emissions. Existing\nstudies benchmark carbon emissions but lack a standardized basis for comparison\nacross different model configurations. To address this, we introduce the\nconcept of functional unit (FU) as a standardized basis and develop FUEL, the\nfirst FU-based framework for evaluating LLM serving's environmental impact.\nThrough three case studies, we uncover key insights and trade-offs in reducing\ncarbon emissions by optimizing model size, quantization strategy, and hardware\nchoice, paving the way for more sustainable LLM serving. The code is available\nat https://github.com/jojacola/FUEL.", "AI": {"tldr": "The paper introduces FUEL, a framework using functional units (FU) to standardize carbon emission evaluation for LLM serving, highlighting trade-offs in model optimization.", "motivation": "Existing studies lack standardized comparison for LLM carbon emissions, prompting the need for a unified framework like FUEL.", "method": "Developed FUEL, an FU-based framework, and validated it through three case studies on model size, quantization, and hardware choices.", "result": "Key insights and trade-offs were identified for reducing carbon emissions in LLM serving.", "conclusion": "FUEL paves the way for more sustainable LLM serving by providing a standardized evaluation method."}}
{"id": "2505.22150", "pdf": "https://arxiv.org/pdf/2505.22150", "abs": "https://arxiv.org/abs/2505.22150", "authors": ["Runze Xia", "Shuo Feng", "Renzhi Wang", "Congchi Yin", "Xuyun Wen", "Piji Li"], "title": "Improving Brain-to-Image Reconstruction via Fine-Grained Text Bridging", "categories": ["cs.CV", "cs.CL"], "comment": "CogSci2025", "summary": "Brain-to-Image reconstruction aims to recover visual stimuli perceived by\nhumans from brain activity. However, the reconstructed visual stimuli often\nmissing details and semantic inconsistencies, which may be attributed to\ninsufficient semantic information. To address this issue, we propose an\napproach named Fine-grained Brain-to-Image reconstruction (FgB2I), which\nemploys fine-grained text as bridge to improve image reconstruction. FgB2I\ncomprises three key stages: detail enhancement, decoding fine-grained text\ndescriptions, and text-bridged brain-to-image reconstruction. In the\ndetail-enhancement stage, we leverage large vision-language models to generate\nfine-grained captions for visual stimuli and experimentally validate its\nimportance. We propose three reward metrics (object accuracy, text-image\nsemantic similarity, and image-image semantic similarity) to guide the language\nmodel in decoding fine-grained text descriptions from fMRI signals. The\nfine-grained text descriptions can be integrated into existing reconstruction\nmethods to achieve fine-grained Brain-to-Image reconstruction.", "AI": {"tldr": "The paper proposes FgB2I, a method to improve brain-to-image reconstruction by using fine-grained text descriptions as a bridge, enhancing detail and semantic accuracy.", "motivation": "Existing brain-to-image reconstruction methods often lack detail and semantic consistency, likely due to insufficient semantic information.", "method": "FgB2I involves three stages: detail enhancement (using vision-language models for fine-grained captions), decoding fine-grained text from fMRI signals, and text-bridged reconstruction. Three reward metrics guide text decoding.", "result": "Fine-grained text descriptions improve reconstruction quality, validated by experiments.", "conclusion": "FgB2I effectively enhances brain-to-image reconstruction by integrating fine-grained text, addressing detail and semantic gaps."}}
{"id": "2505.19164", "pdf": "https://arxiv.org/pdf/2505.19164", "abs": "https://arxiv.org/abs/2505.19164", "authors": ["Ashirbad Mishra", "Jinyu Zhao", "Soumik Dey", "Hansi Wu", "Binbin Li", "Kamesh Madduri"], "title": "BroadGen: A Framework for Generating Effective and Efficient Advertiser Broad Match Keyphrase Recommendations", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": null, "summary": "In the domain of sponsored search advertising, the focus of Keyphrase\nrecommendation has largely been on exact match types, which pose issues such as\nhigh management expenses, limited targeting scope, and evolving search query\npatterns. Alternatives like Broad match types can alleviate certain drawbacks\nof exact matches but present challenges like poor targeting accuracy and\nminimal supervisory signals owing to limited advertiser usage. This research\ndefines the criteria for an ideal broad match, emphasizing on both efficiency\nand effectiveness, ensuring that a significant portion of matched queries are\nrelevant. We propose BroadGen, an innovative framework that recommends\nefficient and effective broad match keyphrases by utilizing historical search\nquery data. Additionally, we demonstrate that BroadGen, through token\ncorrespondence modeling, maintains better query stability over time. BroadGen's\ncapabilities allow it to serve daily, millions of sellers at eBay with over 2.3\nbillion items.", "AI": {"tldr": "The paper introduces BroadGen, a framework for recommending efficient and effective broad match keyphrases in sponsored search advertising, addressing limitations of exact and broad match types.", "motivation": "Exact match types in keyphrase recommendation have high costs and limited scope, while broad matches suffer from poor accuracy. The research aims to define an ideal broad match criteria for better efficiency and effectiveness.", "method": "The proposed BroadGen framework leverages historical search query data and token correspondence modeling to recommend broad match keyphrases and ensure query stability.", "result": "BroadGen successfully serves millions of eBay sellers daily, handling over 2.3 billion items, demonstrating its scalability and effectiveness.", "conclusion": "BroadGen provides a scalable and efficient solution for broad match keyphrase recommendation, improving relevance and stability in sponsored search advertising."}}
{"id": "2502.00264", "pdf": "https://arxiv.org/pdf/2502.00264", "abs": "https://arxiv.org/abs/2502.00264", "authors": ["Binchi Zhang", "Zaiyi Zheng", "Zhengzhang Chen", "Jundong Li"], "title": "Beyond the Permutation Symmetry of Transformers: The Role of Rotation for Model Fusion", "categories": ["cs.LG", "cs.CV"], "comment": "ICML 2025", "summary": "Symmetry in the parameter space of deep neural networks (DNNs) has proven\nbeneficial for various deep learning applications. A well-known example is the\npermutation symmetry in Multi-Layer Perceptrons (MLPs), where permuting the\nrows of weight matrices in one layer and applying the inverse permutation to\nadjacent layers yields a functionally equivalent model. While permutation\nsymmetry fully characterizes the equivalence set for MLPs, its discrete nature\nlimits its utility for transformers. In this paper, we introduce rotation\nsymmetry, a novel form of parameter space symmetry for transformers that\ngeneralizes permutation symmetry by rotating parameter matrices in\nself-attention layers. Unlike permutation symmetry, rotation symmetry operates\nin a continuous domain, thereby significantly expanding the equivalence set for\ntransformers. Based on this property, we propose a theoretically optimal\nparameter matching algorithm as a plug-and-play module to enhance model fusion.\nWe evaluate our approach using pre-trained transformers across diverse natural\nlanguage and vision tasks. Experimental results demonstrate that our rotation\nsymmetry-based matching algorithm substantially improves model fusion,\nhighlighting the potential of parameter space symmetry to facilitate model\nfusion. Our code is available on\nhttps://github.com/zhengzaiyi/RotationSymmetry.", "AI": {"tldr": "The paper introduces rotation symmetry for transformers, a continuous generalization of permutation symmetry, and proposes an optimal parameter matching algorithm to enhance model fusion.", "motivation": "Existing permutation symmetry in MLPs is discrete and limited for transformers, prompting the need for a continuous symmetry like rotation symmetry.", "method": "Rotation symmetry is introduced by rotating parameter matrices in self-attention layers, and a theoretically optimal parameter matching algorithm is proposed.", "result": "Experiments show the rotation symmetry-based matching algorithm significantly improves model fusion across diverse tasks.", "conclusion": "Rotation symmetry expands the equivalence set for transformers and effectively enhances model fusion, demonstrating the potential of parameter space symmetry."}}
{"id": "2502.13344", "pdf": "https://arxiv.org/pdf/2502.13344", "abs": "https://arxiv.org/abs/2502.13344", "authors": ["Tassallah Abdullahi", "Ioanna Gemou", "Nihal V. Nayak", "Ghulam Murtaza", "Stephen H. Bach", "Carsten Eickhoff", "Ritambhara Singh"], "title": "K-Paths: Reasoning over Graph Paths for Drug Repurposing and Drug Interaction Prediction", "categories": ["cs.LG", "cs.CL", "q-bio.BM"], "comment": null, "summary": "Biomedical knowledge graphs (KGs) encode rich, structured information\ncritical for drug discovery tasks, but extracting meaningful insights from\nlarge-scale KGs remains challenging due to their complex structure. Existing\nbiomedical subgraph retrieval methods are tailored for graph neural networks\n(GNNs), limiting compatibility with other paradigms, including large language\nmodels (LLMs). We introduce K-Paths, a model-agnostic retrieval framework that\nextracts structured, diverse, and biologically meaningful multi-hop paths from\ndense biomedical KGs. These paths enable the prediction of unobserved drug-drug\nand drug-disease interactions, including those involving entities not seen\nduring training, thus supporting inductive reasoning. K-Paths is training-free\nand employs a diversity-aware adaptation of Yen's algorithm to extract the K\nshortest loopless paths between entities in a query, prioritizing biologically\nrelevant and relationally diverse connections. These paths serve as concise,\ninterpretable reasoning chains that can be directly integrated with LLMs or\nGNNs to improve generalization, accuracy, and enable explainable inference.\nExperiments on benchmark datasets show that K-Paths improves zero-shot\nreasoning across state-of-the-art LLMs. For instance, Tx-Gemma 27B improves by\n19.8 and 4.0 F1 points on interaction severity prediction and drug repurposing\ntasks, respectively. Llama 70B achieves gains of 8.5 and 6.2 points on the same\ntasks. K-Paths also boosts the training efficiency of EmerGNN, a\nstate-of-the-art GNN, by reducing the KG size by 90% while maintaining\npredictive performance. Beyond efficiency, K-Paths bridges the gap between KGs\nand LLMs, enabling scalable and explainable LLM-augmented scientific discovery.\nWe release our code and the retrieved paths as a benchmark for inductive\nreasoning.", "AI": {"tldr": "K-Paths is a model-agnostic framework for retrieving diverse, biologically meaningful paths from biomedical KGs to enhance drug discovery tasks, improving LLM and GNN performance.", "motivation": "Extracting meaningful insights from complex biomedical KGs is challenging, and existing methods are limited to GNNs, lacking compatibility with LLMs.", "method": "K-Paths uses a diversity-aware adaptation of Yen's algorithm to extract K shortest loopless paths, prioritizing biologically relevant connections.", "result": "K-Paths improves zero-shot reasoning in LLMs (e.g., Tx-Gemma 27B and Llama 70B) and boosts GNN efficiency (e.g., EmerGNN) while maintaining performance.", "conclusion": "K-Paths bridges KGs and LLMs, enabling scalable, explainable scientific discovery, and is released as a benchmark for inductive reasoning."}}
{"id": "2505.22250", "pdf": "https://arxiv.org/pdf/2505.22250", "abs": "https://arxiv.org/abs/2505.22250", "authors": ["Mingzhuang Wang", "Yvyang Li", "Xiyang Zhang", "Fei Tan", "Qi Shi", "Guotao Zhang", "Siqi Chen", "Yufei Liu", "Lei Lei", "Ming Zhou", "Qiang Lin", "Hongqiang Yang"], "title": "YH-MINER: Multimodal Intelligent System for Natural Ecological Reef Metric Extraction", "categories": ["cs.CV", "q-bio.QM"], "comment": null, "summary": "Coral reefs, crucial for sustaining marine biodiversity and ecological\nprocesses (e.g., nutrient cycling, habitat provision), face escalating threats,\nunderscoring the need for efficient monitoring. Coral reef ecological\nmonitoring faces dual challenges of low efficiency in manual analysis and\ninsufficient segmentation accuracy in complex underwater scenarios. This study\ndevelops the YH-MINER system, establishing an intelligent framework centered on\nthe Multimodal Large Model (MLLM) for \"object detection-semantic\nsegmentation-prior input\". The system uses the object detection module\n(mAP@0.5=0.78) to generate spatial prior boxes for coral instances, driving the\nsegment module to complete pixel-level segmentation in low-light and densely\noccluded scenarios. The segmentation masks and finetuned classification\ninstructions are fed into the Qwen2-VL-based multimodal model as prior inputs,\nachieving a genus-level classification accuracy of 88% and simultaneously\nextracting core ecological metrics. Meanwhile, the system retains the\nscalability of the multimodal model through standardized interfaces, laying a\nfoundation for future integration into multimodal agent-based underwater robots\nand supporting the full-process automation of \"image acquisition-prior\ngeneration-real-time analysis\".", "AI": {"tldr": "The paper introduces YH-MINER, an intelligent system using a Multimodal Large Model (MLLM) for efficient coral reef monitoring, achieving high accuracy in object detection, segmentation, and classification.", "motivation": "Coral reefs are vital but threatened; current monitoring methods are inefficient and inaccurate in complex underwater environments.", "method": "Develops YH-MINER, an MLLM-based framework combining object detection, semantic segmentation, and prior input for coral instance analysis.", "result": "Achieves 78% mAP@0.5 in detection, 88% genus-level classification accuracy, and extracts ecological metrics.", "conclusion": "YH-MINER enables scalable, automated coral reef monitoring and supports future integration with underwater robots."}}
{"id": "2505.19423", "pdf": "https://arxiv.org/pdf/2505.19423", "abs": "https://arxiv.org/abs/2505.19423", "authors": ["Bingdong Li", "Mei Jiang", "Hong Qian", "Ke Tang", "Aimin Zhou", "Peng Yang"], "title": "Surrogate-Assisted Evolutionary Reinforcement Learning Based on Autoencoder and Hyperbolic Neural Network", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Evolutionary Reinforcement Learning (ERL), training the Reinforcement\nLearning (RL) policies with Evolutionary Algorithms (EAs), have demonstrated\nenhanced exploration capabilities and greater robustness than using traditional\npolicy gradient. However, ERL suffers from the high computational costs and low\nsearch efficiency, as EAs require evaluating numerous candidate policies with\nexpensive simulations, many of which are ineffective and do not contribute\nmeaningfully to the training. One intuitive way to reduce the ineffective\nevaluations is to adopt the surrogates. Unfortunately, existing ERL policies\nare often modeled as deep neural networks (DNNs) and thus naturally represented\nas high-dimensional vectors containing millions of weights, which makes the\nbuilding of effective surrogates for ERL policies extremely challenging. This\npaper proposes a novel surrogate-assisted ERL that integrates Autoencoders (AE)\nand Hyperbolic Neural Networks (HNN). Specifically, AE compresses\nhigh-dimensional policies into low-dimensional representations while extracting\nkey features as the inputs for the surrogate. HNN, functioning as a\nclassification-based surrogate model, can learn complex nonlinear relationships\nfrom sampled data and enable more accurate pre-selection of the sampled\npolicies without real evaluations. The experiments on 10 Atari and 4 Mujoco\ngames have verified that the proposed method outperforms previous approaches\nsignificantly. The search trajectories guided by AE and HNN are also visually\ndemonstrated to be more effective, in terms of both exploration and\nconvergence. This paper not only presents the first learnable policy embedding\nand surrogate-modeling modules for high-dimensional ERL policies, but also\nempirically reveals when and why they can be successful.", "AI": {"tldr": "The paper proposes a surrogate-assisted Evolutionary Reinforcement Learning (ERL) method using Autoencoders (AE) and Hyperbolic Neural Networks (HNN) to reduce computational costs and improve search efficiency.", "motivation": "ERL suffers from high computational costs and low search efficiency due to evaluating numerous ineffective policies. Existing surrogates struggle with high-dimensional policy representations.", "method": "AE compresses policies into low-dimensional representations, while HNN acts as a surrogate to pre-select policies without real evaluations.", "result": "Experiments on 10 Atari and 4 Mujoco games show the method outperforms previous approaches, with more effective exploration and convergence.", "conclusion": "The paper introduces the first learnable policy embedding and surrogate-modeling modules for high-dimensional ERL policies, demonstrating their success empirically."}}
{"id": "2502.00288", "pdf": "https://arxiv.org/pdf/2502.00288", "abs": "https://arxiv.org/abs/2502.00288", "authors": ["Jijia Liu", "Feng Gao", "Qingmin Liao", "Chao Yu", "Yu Wang"], "title": "Learning from Suboptimal Data in Continuous Control via Auto-Regressive Soft Q-Network", "categories": ["cs.LG", "cs.RO"], "comment": "Accepted by ICML 2025", "summary": "Reinforcement learning (RL) for continuous control often requires large\namounts of online interaction data. Value-based RL methods can mitigate this\nburden by offering relatively high sample efficiency. Some studies further\nenhance sample efficiency by incorporating offline demonstration data to\n\"kick-start\" training, achieving promising results in continuous control.\nHowever, they typically compute the Q-function independently for each action\ndimension, neglecting interdependencies and making it harder to identify\noptimal actions when learning from suboptimal data, such as non-expert\ndemonstration and online-collected data during the training process. To address\nthese issues, we propose Auto-Regressive Soft Q-learning (ARSQ), a value-based\nRL algorithm that models Q-values in a coarse-to-fine, auto-regressive manner.\nFirst, ARSQ decomposes the continuous action space into discrete spaces in a\ncoarse-to-fine hierarchy, enhancing sample efficiency for fine-grained\ncontinuous control tasks. Next, it auto-regressively predicts dimensional\naction advantages within each decision step, enabling more effective\ndecision-making in continuous control tasks. We evaluate ARSQ on two continuous\ncontrol benchmarks, RLBench and D4RL, integrating demonstration data into\nonline training. On D4RL, which includes non-expert demonstrations, ARSQ\nachieves an average $1.62\\times$ performance improvement over SOTA value-based\nbaseline. On RLBench, which incorporates expert demonstrations, ARSQ surpasses\nvarious baselines, demonstrating its effectiveness in learning from suboptimal\nonline-collected data. Project page is at\nhttps://sites.google.com/view/ar-soft-q", "AI": {"tldr": "ARSQ is a value-based RL algorithm for continuous control that improves sample efficiency by modeling Q-values auto-regressively and decomposing action spaces hierarchically.", "motivation": "Address inefficiencies in value-based RL for continuous control, especially when learning from suboptimal data like non-expert demonstrations.", "method": "Decomposes action space hierarchically and auto-regressively predicts action advantages. Evaluated on RLBench and D4RL benchmarks.", "result": "Achieves 1.62\u00d7 performance improvement on D4RL and outperforms baselines on RLBench.", "conclusion": "ARSQ effectively enhances sample efficiency and performance in continuous control tasks, even with suboptimal data."}}
{"id": "2503.13503", "pdf": "https://arxiv.org/pdf/2503.13503", "abs": "https://arxiv.org/abs/2503.13503", "authors": ["Chuan Qin", "Xin Chen", "Chengrui Wang", "Pengmin Wu", "Xi Chen", "Yihang Cheng", "Jingyi Zhao", "Meng Xiao", "Xiangchao Dong", "Qingqing Long", "Boya Pan", "Han Wu", "Chengzan Li", "Yuanchun Zhou", "Hui Xiong", "Hengshu Zhu"], "title": "SciHorizon: Benchmarking AI-for-Science Readiness from Scientific Data to Large Language Models", "categories": ["cs.LG", "cs.CL", "cs.DL", "cs.IR"], "comment": null, "summary": "In recent years, the rapid advancement of Artificial Intelligence (AI)\ntechnologies, particularly Large Language Models (LLMs), has revolutionized the\nparadigm of scientific discovery, establishing AI-for-Science (AI4Science) as a\ndynamic and evolving field. However, there is still a lack of an effective\nframework for the overall assessment of AI4Science, particularly from a\nholistic perspective on data quality and model capability. Therefore, in this\nstudy, we propose SciHorizon, a comprehensive assessment framework designed to\nbenchmark the readiness of AI4Science from both scientific data and LLM\nperspectives. First, we introduce a generalizable framework for assessing\nAI-ready scientific data, encompassing four key dimensions: Quality, FAIRness,\nExplainability, and Compliance-which are subdivided into 15 sub-dimensions.\nDrawing on data resource papers published between 2018 and 2023 in\npeer-reviewed journals, we present recommendation lists of AI-ready datasets\nfor Earth, Life, and Materials Sciences, making a novel and original\ncontribution to the field. Concurrently, to assess the capabilities of LLMs\nacross multiple scientific disciplines, we establish 16 assessment dimensions\nbased on five core indicators Knowledge, Understanding, Reasoning,\nMultimodality, and Values spanning Mathematics, Physics, Chemistry, Life\nSciences, and Earth and Space Sciences. Using the developed benchmark datasets,\nwe have conducted a comprehensive evaluation of over 50 representative\nopen-source and closed source LLMs. All the results are publicly available and\ncan be accessed online at www.scihorizon.cn/en.", "AI": {"tldr": "The paper introduces SciHorizon, a framework to assess AI4Science readiness, focusing on data quality and LLM capabilities across scientific disciplines.", "motivation": "The rapid growth of AI4Science lacks a holistic assessment framework for data quality and model capability, prompting the need for SciHorizon.", "method": "The study proposes a framework with dimensions for data (Quality, FAIRness, Explainability, Compliance) and LLMs (Knowledge, Understanding, Reasoning, Multimodality, Values), evaluating datasets and 50+ LLMs.", "result": "Recommendation lists of AI-ready datasets for Earth, Life, and Materials Sciences were created, and LLMs were benchmarked across 16 dimensions. Results are publicly available.", "conclusion": "SciHorizon provides a novel, comprehensive tool for assessing AI4Science readiness, bridging gaps in data and LLM evaluation."}}
{"id": "2505.22421", "pdf": "https://arxiv.org/pdf/2505.22421", "abs": "https://arxiv.org/abs/2505.22421", "authors": ["Anthony Chen", "Wenzhao Zheng", "Yida Wang", "Xueyang Zhang", "Kun Zhan", "Peng Jia", "Kurt Keutzer", "Shanghang Zhang"], "title": "GeoDrive: 3D Geometry-Informed Driving World Model with Precise Action Control", "categories": ["cs.CV", "cs.RO"], "comment": "code will be released at https://github.com/antonioo-c/GeoDrive", "summary": "Recent advancements in world models have revolutionized dynamic environment\nsimulation, allowing systems to foresee future states and assess potential\nactions. In autonomous driving, these capabilities help vehicles anticipate the\nbehavior of other road users, perform risk-aware planning, accelerate training\nin simulation, and adapt to novel scenarios, thereby enhancing safety and\nreliability. Current approaches exhibit deficiencies in maintaining robust 3D\ngeometric consistency or accumulating artifacts during occlusion handling, both\ncritical for reliable safety assessment in autonomous navigation tasks. To\naddress this, we introduce GeoDrive, which explicitly integrates robust 3D\ngeometry conditions into driving world models to enhance spatial understanding\nand action controllability. Specifically, we first extract a 3D representation\nfrom the input frame and then obtain its 2D rendering based on the\nuser-specified ego-car trajectory. To enable dynamic modeling, we propose a\ndynamic editing module during training to enhance the renderings by editing the\npositions of the vehicles. Extensive experiments demonstrate that our method\nsignificantly outperforms existing models in both action accuracy and 3D\nspatial awareness, leading to more realistic, adaptable, and reliable scene\nmodeling for safer autonomous driving. Additionally, our model can generalize\nto novel trajectories and offers interactive scene editing capabilities, such\nas object editing and object trajectory control.", "AI": {"tldr": "GeoDrive enhances autonomous driving by integrating robust 3D geometry into world models, improving spatial understanding and action controllability, outperforming existing methods in accuracy and adaptability.", "motivation": "Current world models for autonomous driving lack robust 3D geometric consistency and accumulate artifacts during occlusion, limiting reliable safety assessment.", "method": "GeoDrive extracts 3D representations from input frames, renders 2D views based on ego-car trajectories, and uses dynamic editing to enhance renderings by adjusting vehicle positions.", "result": "GeoDrive outperforms existing models in action accuracy and 3D spatial awareness, enabling realistic, adaptable, and reliable scene modeling.", "conclusion": "GeoDrive advances autonomous driving by improving 3D spatial modeling, generalizing to novel trajectories, and offering interactive scene editing capabilities."}}
{"id": "2505.20359", "pdf": "https://arxiv.org/pdf/2505.20359", "abs": "https://arxiv.org/abs/2505.20359", "authors": ["Lijun Zhang", "Lin Li", "Yajie Qi", "Huizhong Song", "Yaodong Yang", "Jun Wang", "Wei Wei"], "title": "Risk-aware Direct Preference Optimization under Nested Risk Measure", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "When fine-tuning pre-trained Large Language Models (LLMs) to align with human\nvalues and intentions, maximizing the estimated reward can lead to superior\nperformance, but it also introduces potential risks due to deviations from the\nreference model's intended behavior. Most existing methods typically introduce\nKL divergence to constrain deviations between the trained model and the\nreference model; however, this may not be sufficient in certain applications\nthat require tight risk control. In this paper, we introduce Risk-aware Direct\nPreference Optimization (Ra-DPO), a novel approach that incorporates\nrisk-awareness by employing a class of nested risk measures. This approach\nformulates a constrained risk-aware advantage function maximization problem and\nthen converts the Bradley-Terry model into a token-level representation. The\nobjective function maximizes the likelihood of the policy while suppressing the\ndeviation between a trained model and the reference model using a sequential\nrisk ratio, thereby enhancing the model's risk-awareness. Experimental results\nacross three open-source datasets: IMDb Dataset, Anthropic HH Dataset, and\nAlpacaEval, demonstrate the proposed method's superior performance in balancing\nalignment performance and model drift. Our code is opensourced at\nhttps://github.com/zlj123-max/Ra-DPO.", "AI": {"tldr": "Ra-DPO introduces risk-awareness into LLM fine-tuning using nested risk measures, balancing alignment performance and model drift better than KL divergence methods.", "motivation": "Existing methods using KL divergence may not suffice for tight risk control in aligning LLMs with human values, prompting the need for a risk-aware approach.", "method": "Ra-DPO employs nested risk measures, formulates a constrained risk-aware advantage function, and converts the Bradley-Terry model into a token-level representation.", "result": "Experiments on IMDb, Anthropic HH, and AlpacaEval datasets show Ra-DPO outperforms in balancing alignment and model drift.", "conclusion": "Ra-DPO enhances risk-awareness in LLM fine-tuning, offering superior performance and control over model deviations."}}
{"id": "2502.00488", "pdf": "https://arxiv.org/pdf/2502.00488", "abs": "https://arxiv.org/abs/2502.00488", "authors": ["Chuqi Chen", "Yahong Yang", "Yang Xiang", "Wenrui Hao"], "title": "Learn Singularly Perturbed Solutions via Homotopy Dynamics", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Solving partial differential equations (PDEs) using neural networks has\nbecome a central focus in scientific machine learning. Training neural networks\nfor singularly perturbed problems is particularly challenging due to certain\nparameters in the PDEs that introduce near-singularities in the loss function.\nIn this study, we overcome this challenge by introducing a novel method based\non homotopy dynamics to effectively manipulate these parameters. From a\ntheoretical perspective, we analyze the effects of these parameters on training\ndifficulty in these singularly perturbed problems and establish the convergence\nof the proposed homotopy dynamics method. Experimentally, we demonstrate that\nour approach significantly accelerates convergence and improves the accuracy of\nthese singularly perturbed problems. These findings present an efficient\noptimization strategy leveraging homotopy dynamics, offering a robust framework\nto extend the applicability of neural networks for solving singularly perturbed\ndifferential equations.", "AI": {"tldr": "A novel homotopy dynamics method is introduced to train neural networks for singularly perturbed PDEs, improving convergence and accuracy.", "motivation": "Training neural networks for singularly perturbed PDEs is challenging due to near-singularities in the loss function caused by certain parameters.", "method": "The study proposes a homotopy dynamics method to manipulate these parameters, analyzing their impact theoretically and demonstrating the method's convergence.", "result": "The approach accelerates convergence and enhances accuracy for singularly perturbed problems.", "conclusion": "The homotopy dynamics method provides an efficient optimization strategy, extending neural networks' applicability to singularly perturbed PDEs."}}
{"id": "2503.16814", "pdf": "https://arxiv.org/pdf/2503.16814", "abs": "https://arxiv.org/abs/2503.16814", "authors": ["Jihwan Oh", "Minchan Jeong", "Jongwoo Ko", "Se-Young Yun"], "title": "Understanding Bias Reinforcement in LLM Agents Debate", "categories": ["cs.LG", "cs.CL"], "comment": "ICML 2025", "summary": "Large Language Models $($LLMs$)$ solve complex problems using training-free\nmethods like prompt engineering and in-context learning, yet ensuring reasoning\ncorrectness remains challenging. While self-correction methods such as\nself-consistency and self-refinement aim to improve reliability, they often\nreinforce biases due to the lack of effective feedback mechanisms. Multi-Agent\nDebate $($MAD$)$ has emerged as an alternative, but we identify two key\nlimitations: bias reinforcement, where debate amplifies model biases instead of\ncorrecting them, and lack of perspective diversity, as all agents share the\nsame model and reasoning patterns, limiting true debate effectiveness. To\nsystematically evaluate these issues, we introduce $\\textit{MetaNIM Arena}$, a\nbenchmark designed to assess LLMs in adversarial strategic decision-making,\nwhere dynamic interactions influence optimal decisions. To overcome MAD's\nlimitations, we propose $\\textbf{DReaMAD}$ $($$\\textbf{D}$iverse\n$\\textbf{Rea}$soning via $\\textbf{M}$ulti-$\\textbf{A}$gent $\\textbf{D}$ebate\nwith Refined Prompt$)$, a novel framework that $(1)$ refines LLM's strategic\nprior knowledge to improve reasoning quality and $(2)$ promotes diverse\nviewpoints within a single model by systematically modifying prompts, reducing\nbias. Empirical results show that $\\textbf{DReaMAD}$ significantly improves\ndecision accuracy, reasoning diversity, and bias mitigation across multiple\nstrategic tasks, establishing it as a more effective approach for LLM-based\ndecision-making.", "AI": {"tldr": "DReaMAD improves LLM decision-making by refining strategic prior knowledge and promoting diverse viewpoints, outperforming existing methods like MAD.", "motivation": "Addressing limitations in self-correction and multi-agent debate (MAD) methods, which reinforce biases and lack perspective diversity.", "method": "Proposes DReaMAD, a framework refining LLM prompts for better reasoning and diverse viewpoints within a single model.", "result": "DReaMAD enhances decision accuracy, reasoning diversity, and bias mitigation in strategic tasks.", "conclusion": "DReaMAD is a superior approach for reliable and diverse LLM-based decision-making."}}
{"id": "2505.22461", "pdf": "https://arxiv.org/pdf/2505.22461", "abs": "https://arxiv.org/abs/2505.22461", "authors": ["Qiucheng Yu", "Yuan Xie", "Xin Tan"], "title": "SHTOcc: Effective 3D Occupancy Prediction with Sparse Head and Tail Voxels", "categories": ["cs.CV"], "comment": null, "summary": "3D occupancy prediction has attracted much attention in the field of\nautonomous driving due to its powerful geometric perception and object\nrecognition capabilities. However, existing methods have not explored the most\nessential distribution patterns of voxels, resulting in unsatisfactory results.\nThis paper first explores the inter-class distribution and geometric\ndistribution of voxels, thereby solving the long-tail problem caused by the\ninter-class distribution and the poor performance caused by the geometric\ndistribution. Specifically, this paper proposes SHTOcc (Sparse Head-Tail\nOccupancy), which uses sparse head-tail voxel construction to accurately\nidentify and balance key voxels in the head and tail classes, while using\ndecoupled learning to reduce the model's bias towards the dominant (head)\ncategory and enhance the focus on the tail class. Experiments show that\nsignificant improvements have been made on multiple baselines: SHTOcc reduces\nGPU memory usage by 42.2%, increases inference speed by 58.6%, and improves\naccuracy by about 7%, verifying its effectiveness and efficiency. The code is\navailable at https://github.com/ge95net/SHTOcc", "AI": {"tldr": "SHTOcc improves 3D occupancy prediction by addressing voxel distribution issues, reducing GPU memory usage by 42.2%, speeding up inference by 58.6%, and boosting accuracy by 7%.", "motivation": "Existing methods fail to explore voxel distribution patterns, leading to poor performance and long-tail problems.", "method": "SHTOcc uses sparse head-tail voxel construction and decoupled learning to balance key voxels and reduce bias toward dominant categories.", "result": "SHTOcc reduces GPU memory usage by 42.2%, increases inference speed by 58.6%, and improves accuracy by 7%.", "conclusion": "SHTOcc effectively addresses voxel distribution challenges, enhancing performance and efficiency in 3D occupancy prediction."}}
{"id": "2505.21363", "pdf": "https://arxiv.org/pdf/2505.21363", "abs": "https://arxiv.org/abs/2505.21363", "authors": ["Anissa Alloula", "Charles Jones", "Ben Glocker", "Bart\u0142omiej W. Papie\u017c"], "title": "Subgroups Matter for Robust Bias Mitigation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Despite the constant development of new bias mitigation methods for machine\nlearning, no method consistently succeeds, and a fundamental question remains\nunanswered: when and why do bias mitigation techniques fail? In this paper, we\nhypothesise that a key factor may be the often-overlooked but crucial step\nshared by many bias mitigation methods: the definition of subgroups. To\ninvestigate this, we conduct a comprehensive evaluation of state-of-the-art\nbias mitigation methods across multiple vision and language classification\ntasks, systematically varying subgroup definitions, including coarse,\nfine-grained, intersectional, and noisy subgroups. Our results reveal that\nsubgroup choice significantly impacts performance, with certain groupings\nparadoxically leading to worse outcomes than no mitigation at all. Our findings\nsuggest that observing a disparity between a set of subgroups is not a\nsufficient reason to use those subgroups for mitigation. Through theoretical\nanalysis, we explain these phenomena and uncover a counter-intuitive insight\nthat, in some cases, improving fairness with respect to a particular set of\nsubgroups is best achieved by using a different set of subgroups for\nmitigation. Our work highlights the importance of careful subgroup definition\nin bias mitigation and presents it as an alternative lever for improving the\nrobustness and fairness of machine learning models.", "AI": {"tldr": "Subgroup definition significantly impacts bias mitigation performance, sometimes worsening outcomes. Careful subgroup choice is crucial for fairness.", "motivation": "To understand why bias mitigation methods fail, focusing on the overlooked role of subgroup definitions.", "method": "Comprehensive evaluation of bias mitigation methods across tasks, varying subgroup definitions (coarse, fine-grained, intersectional, noisy).", "result": "Subgroup choice affects performance; some groupings worsen outcomes. Improving fairness may require using different subgroups.", "conclusion": "Subgroup definition is critical for effective bias mitigation and fairness in machine learning."}}
{"id": "2502.02410", "pdf": "https://arxiv.org/pdf/2502.02410", "abs": "https://arxiv.org/abs/2502.02410", "authors": ["Jan Schuchardt", "Mina Dalirrooyfard", "Jed Guzelkabaagac", "Anderson Schneider", "Yuriy Nevmyvaka", "Stephan G\u00fcnnemann"], "title": "Privacy Amplification by Structured Subsampling for Deep Differentially Private Time Series Forecasting", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": "Accepted as ICML 2025 Spotlight", "summary": "Many forms of sensitive data, such as web traffic, mobility data, or hospital\noccupancy, are inherently sequential. The standard method for training machine\nlearning models while ensuring privacy for units of sensitive information, such\nas individual hospital visits, is differentially private stochastic gradient\ndescent (DP-SGD). However, we observe in this work that the formal guarantees\nof DP-SGD are incompatible with time-series-specific tasks like forecasting,\nsince they rely on the privacy amplification attained by training on small,\nunstructured batches sampled from an unstructured dataset. In contrast, batches\nfor forecasting are generated by (1) sampling sequentially structured time\nseries from a dataset, (2) sampling contiguous subsequences from these series,\nand (3) partitioning them into context and ground-truth forecast windows. We\ntheoretically analyze the privacy amplification attained by this structured\nsubsampling to enable the training of forecasting models with sound and tight\nevent- and user-level privacy guarantees. Towards more private models, we\nadditionally prove how data augmentation amplifies privacy in self-supervised\ntraining of sequence models. Our empirical evaluation demonstrates that\namplification by structured subsampling enables the training of forecasting\nmodels with strong formal privacy guarantees.", "AI": {"tldr": "The paper addresses the incompatibility of DP-SGD with time-series forecasting due to structured data requirements, proposing structured subsampling for better privacy guarantees.", "motivation": "Standard DP-SGD fails for time-series tasks like forecasting because it relies on unstructured batches, unlike the sequential nature of such data.", "method": "The authors analyze privacy amplification via structured subsampling (sampling time series, subsequences, and partitioning) and data augmentation in self-supervised training.", "result": "Theoretical and empirical results show that structured subsampling enables forecasting models with strong privacy guarantees.", "conclusion": "Structured subsampling and data augmentation provide sound privacy guarantees for time-series forecasting, overcoming DP-SGD's limitations."}}
{"id": "2505.00926", "pdf": "https://arxiv.org/pdf/2505.00926", "abs": "https://arxiv.org/abs/2505.00926", "authors": ["Ruiquan Huang", "Yingbin Liang", "Jing Yang"], "title": "How Transformers Learn Regular Language Recognition: A Theoretical Study on Training Dynamics and Implicit Bias", "categories": ["cs.LG", "cs.CL", "stat.ML"], "comment": "accepted by ICML 2025", "summary": "Language recognition tasks are fundamental in natural language processing\n(NLP) and have been widely used to benchmark the performance of large language\nmodels (LLMs). These tasks also play a crucial role in explaining the working\nmechanisms of transformers. In this work, we focus on two representative tasks\nin the category of regular language recognition, known as `even pairs' and\n`parity check', the aim of which is to determine whether the occurrences of\ncertain subsequences in a given sequence are even. Our goal is to explore how a\none-layer transformer, consisting of an attention layer followed by a linear\nlayer, learns to solve these tasks by theoretically analyzing its training\ndynamics under gradient descent. While even pairs can be solved directly by a\none-layer transformer, parity check need to be solved by integrating\nChain-of-Thought (CoT), either into the inference stage of a transformer\nwell-trained for the even pairs task, or into the training of a one-layer\ntransformer. For both problems, our analysis shows that the joint training of\nattention and linear layers exhibits two distinct phases. In the first phase,\nthe attention layer grows rapidly, mapping data sequences into separable\nvectors. In the second phase, the attention layer becomes stable, while the\nlinear layer grows logarithmically and approaches in direction to a max-margin\nhyperplane that correctly separates the attention layer outputs into positive\nand negative samples, and the loss decreases at a rate of $O(1/t)$. Our\nexperiments validate those theoretical results.", "AI": {"tldr": "The paper explores how a one-layer transformer learns regular language tasks (even pairs and parity check) under gradient descent, revealing distinct training phases and validating results experimentally.", "motivation": "To understand the working mechanisms of transformers in solving fundamental NLP tasks like regular language recognition, focusing on 'even pairs' and 'parity check'.", "method": "Theoretical analysis of training dynamics for a one-layer transformer (attention + linear layer) under gradient descent, with experiments to validate findings.", "result": "Two training phases: rapid attention layer growth for separability, followed by logarithmic linear layer growth toward a max-margin solution. Loss decreases at O(1/t).", "conclusion": "One-layer transformers can solve even pairs directly, while parity check requires Chain-of-Thought integration. Training dynamics reveal separable phases and logarithmic convergence."}}
{"id": "2505.22499", "pdf": "https://arxiv.org/pdf/2505.22499", "abs": "https://arxiv.org/abs/2505.22499", "authors": ["Aixuan Li", "Mochu Xiang", "Jing Zhang", "Yuchao Dai"], "title": "The Meeseeks Mesh: Spatially Consistent 3D Adversarial Objects for BEV Detector", "categories": ["cs.CV"], "comment": null, "summary": "3D object detection is a critical component in autonomous driving systems. It\nallows real-time recognition and detection of vehicles, pedestrians and\nobstacles under varying environmental conditions. Among existing methods, 3D\nobject detection in the Bird's Eye View (BEV) has emerged as the mainstream\nframework. To guarantee a safe, robust and trustworthy 3D object detection, 3D\nadversarial attacks are investigated, where attacks are placed in 3D\nenvironments to evaluate the model performance, e.g. putting a film on a car,\nclothing a pedestrian. The vulnerability of 3D object detection models to 3D\nadversarial attacks serves as an important indicator to evaluate the robustness\nof the model against perturbations. To investigate this vulnerability, we\ngenerate non-invasive 3D adversarial objects tailored for real-world attack\nscenarios. Our method verifies the existence of universal adversarial objects\nthat are spatially consistent across time and camera views. Specifically, we\nemploy differentiable rendering techniques to accurately model the spatial\nrelationship between adversarial objects and the target vehicle. Furthermore,\nwe introduce an occlusion-aware module to enhance visual consistency and\nrealism under different viewpoints. To maintain attack effectiveness across\nmultiple frames, we design a BEV spatial feature-guided optimization strategy.\nExperimental results demonstrate that our approach can reliably suppress\nvehicle predictions from state-of-the-art 3D object detectors, serving as an\nimportant tool to test robustness of 3D object detection models before\ndeployment. Moreover, the generated adversarial objects exhibit strong\ngeneralization capabilities, retaining its effectiveness at various positions\nand distances in the scene.", "AI": {"tldr": "The paper explores 3D adversarial attacks on BEV-based 3D object detection models, introducing non-invasive adversarial objects and an occlusion-aware module to test model robustness.", "motivation": "To evaluate the robustness of 3D object detection models in autonomous driving by investigating their vulnerability to 3D adversarial attacks.", "method": "Generates non-invasive 3D adversarial objects using differentiable rendering and an occlusion-aware module, optimizing with BEV spatial feature guidance.", "result": "The approach reliably suppresses vehicle predictions in state-of-the-art detectors and shows strong generalization across positions and distances.", "conclusion": "The method serves as a tool to test 3D object detection model robustness before deployment, highlighting vulnerabilities to adversarial attacks."}}
{"id": "2505.21388", "pdf": "https://arxiv.org/pdf/2505.21388", "abs": "https://arxiv.org/abs/2505.21388", "authors": ["Jingyuan Huang", "Xi Zhu", "Minghao Guo", "Yongfeng Zhang"], "title": "DeSocial: Blockchain-based Decentralized Social Networks", "categories": ["cs.SI", "cs.AI", "cs.LG"], "comment": "29 pages, 13 figures", "summary": "Web 2.0 social platforms are inherently centralized, with user data and\nalgorithmic decisions controlled by the platform. However, users can only\npassively receive social predictions without being able to choose the\nunderlying algorithm, which limits personalization. Fortunately, with the\nemergence of blockchain, users are allowed to choose algorithms that are\ntailored to their local situation, improving prediction results in a\npersonalized way. In a blockchain environment, each user possesses its own\nmodel to perform the social prediction, capturing different perspectives on\nsocial interactions. In our work, we propose DeSocial, a decentralized social\nnetwork learning framework deployed on an Ethereum (ETH) local development\nchain that integrates distributed data storage, node-level consensus, and\nuser-driven model selection through Ganache. In the first stage, each user\nleverages DeSocial to evaluate multiple backbone models on their local\nsubgraph. DeSocial coordinates the execution and returns model-wise prediction\nresults, enabling the user to select the most suitable backbone for\npersonalized social prediction. Then, DeSocial uniformly selects several\nvalidation nodes that possess the algorithm specified by each user, and\naggregates the prediction results by majority voting, to prevent errors caused\nby any single model's misjudgment. Extensive experiments show that DeSocial has\nan evident improvement compared to the five classical centralized social\nnetwork learning models, promoting user empowerment in blockchain-based\ndecentralized social networks, showing the importance of multi-node validation\nand personalized algorithm selection based on blockchain. Our implementation is\navailable at: https://github.com/agiresearch/DeSocial.", "AI": {"tldr": "DeSocial is a decentralized social network framework on Ethereum, enabling personalized algorithm selection and multi-node validation for improved social predictions.", "motivation": "Centralized social platforms limit user control over algorithms and personalization. Blockchain offers a solution by allowing decentralized, user-driven model selection.", "method": "DeSocial integrates distributed data storage, node-level consensus, and user-driven model selection. Users evaluate backbone models locally, and validation nodes aggregate results via majority voting.", "result": "DeSocial outperforms five centralized models, highlighting the benefits of multi-node validation and personalized algorithm selection.", "conclusion": "DeSocial empowers users in decentralized social networks, demonstrating the value of blockchain for personalized and secure social predictions."}}
{"id": "2502.05743", "pdf": "https://arxiv.org/pdf/2502.05743", "abs": "https://arxiv.org/abs/2502.05743", "authors": ["Xiao Li", "Zekai Zhang", "Xiang Li", "Siyi Chen", "Zhihui Zhu", "Peng Wang", "Qing Qu"], "title": "Understanding Representation Dynamics of Diffusion Models via Low-Dimensional Modeling", "categories": ["cs.LG", "cs.CV"], "comment": "First two authors contributed equally", "summary": "Diffusion models, though originally designed for generative tasks, have\ndemonstrated impressive self-supervised representation learning capabilities. A\nparticularly intriguing phenomenon in these models is the emergence of unimodal\nrepresentation dynamics, where the quality of learned features peaks at an\nintermediate noise level. In this work, we conduct a comprehensive theoretical\nand empirical investigation of this phenomenon. Leveraging the inherent\nlow-dimensionality structure of image data, we theoretically demonstrate that\nthe unimodal dynamic emerges when the diffusion model successfully captures the\nunderlying data distribution. The unimodality arises from an interplay between\ndenoising strength and class confidence across noise scales. Empirically, we\nfurther show that, in classification tasks, the presence of unimodal dynamics\nreliably indicates generalization: it emerges when the model generalizes and\ngradually transitions to a monotonically decreasing curve as the model begins\nto memorize the training data.", "AI": {"tldr": "Diffusion models show unimodal representation dynamics in self-supervised learning, peaking at intermediate noise levels. Theoretical and empirical analysis links this to data distribution capture and generalization in classification tasks.", "motivation": "To understand the unimodal representation dynamics in diffusion models and their connection to generalization and memorization in learning tasks.", "method": "Combines theoretical analysis leveraging low-dimensional image data structure with empirical validation in classification tasks.", "result": "Unimodal dynamics emerge when the model captures the data distribution and indicates generalization; it shifts to monotonic decline with memorization.", "conclusion": "Unimodal representation dynamics in diffusion models signal successful generalization, transitioning to memorization when the curve becomes monotonically decreasing."}}
{"id": "2505.22535", "pdf": "https://arxiv.org/pdf/2505.22535", "abs": "https://arxiv.org/abs/2505.22535", "authors": ["Mohamad Hakam Shams Eddin", "Yikui Zhang", "Stefan Kollet", "Juergen Gall"], "title": "RiverMamba: A State Space Model for Global River Discharge and Flood Forecasting", "categories": ["cs.CV", "cs.LG"], "comment": "Main paper 10 pages, Appendix 53 pages", "summary": "Recent deep learning approaches for river discharge forecasting have improved\nthe accuracy and efficiency in flood forecasting, enabling more reliable early\nwarning systems for risk management. Nevertheless, existing deep learning\napproaches in hydrology remain largely confined to local-scale applications and\ndo not leverage the inherent spatial connections of bodies of water. Thus,\nthere is a strong need for new deep learning methodologies that are capable of\nmodeling spatio-temporal relations to improve river discharge and flood\nforecasting for scientific and operational applications. To address this, we\npresent RiverMamba, a novel deep learning model that is pretrained with\nlong-term reanalysis data and that can forecast global river discharge and\nfloods on a $0.05^\\circ$ grid up to 7 days lead time, which is of high\nrelevance in early warning. To achieve this, RiverMamba leverages efficient\nMamba blocks that enable the model to capture global-scale channel network\nrouting and enhance its forecast capability for longer lead times. The forecast\nblocks integrate ECMWF HRES meteorological forecasts, while accounting for\ntheir inaccuracies through spatio-temporal modeling. Our analysis demonstrates\nthat RiverMamba delivers reliable predictions of river discharge, including\nextreme floods across return periods and lead times, surpassing both\noperational AI- and physics-based models.", "AI": {"tldr": "RiverMamba is a deep learning model for global river discharge and flood forecasting, outperforming existing models by leveraging spatio-temporal relations and Mamba blocks.", "motivation": "Existing deep learning approaches in hydrology lack spatial connections and global-scale applications, limiting their effectiveness in flood forecasting.", "method": "RiverMamba uses Mamba blocks and long-term reanalysis data to model spatio-temporal relations, integrating ECMWF HRES forecasts while accounting for inaccuracies.", "result": "RiverMamba provides reliable predictions for river discharge and extreme floods, surpassing operational AI- and physics-based models.", "conclusion": "RiverMamba addresses the limitations of current methods, offering improved global flood forecasting for early warning systems."}}
{"id": "2505.21432", "pdf": "https://arxiv.org/pdf/2505.21432", "abs": "https://arxiv.org/abs/2505.21432", "authors": ["Haoming Song", "Delin Qu", "Yuanqi Yao", "Qizhi Chen", "Qi Lv", "Yiwen Tang", "Modi Shi", "Guanghui Ren", "Maoqing Yao", "Bin Zhao", "Dong Wang", "Xuelong Li"], "title": "Hume: Introducing System-2 Thinking in Visual-Language-Action Model", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Humans practice slow thinking before performing actual actions when handling\ncomplex tasks in the physical world. This thinking paradigm, recently, has\nachieved remarkable advancement in boosting Large Language Models (LLMs) to\nsolve complex tasks in digital domains. However, the potential of slow thinking\nremains largely unexplored for robotic foundation models interacting with the\nphysical world. In this work, we propose Hume: a dual-system\nVision-Language-Action (VLA) model with value-guided System-2 thinking and\ncascaded action denoising, exploring human-like thinking capabilities of\nVision-Language-Action models for dexterous robot control. System 2 of Hume\nimplements value-Guided thinking by extending a Vision-Language-Action Model\nbackbone with a novel value-query head to estimate the state-action value of\npredicted actions. The value-guided thinking is conducted by repeat sampling\nmultiple action candidates and selecting one according to state-action value.\nSystem 1 of Hume is a lightweight reactive visuomotor policy that takes System\n2 selected action and performs cascaded action denoising for dexterous robot\ncontrol. At deployment time, System 2 performs value-guided thinking at a low\nfrequency while System 1 asynchronously receives the System 2 selected action\ncandidate and predicts fluid actions in real time. We show that Hume\noutperforms the existing state-of-the-art Vision-Language-Action models across\nmultiple simulation benchmark and real-robot deployments.", "AI": {"tldr": "Hume, a dual-system VLA model, enhances robotic control by combining value-guided slow thinking (System 2) with reactive fast actions (System 1), outperforming existing models.", "motivation": "To explore human-like slow thinking in robotic foundation models for better handling of complex physical tasks.", "method": "Hume uses a dual-system approach: System 2 for value-guided action selection via repeated sampling, and System 1 for real-time, denoised action execution.", "result": "Hume surpasses state-of-the-art VLA models in simulation benchmarks and real-robot deployments.", "conclusion": "The dual-system approach effectively integrates slow thinking into robotic control, improving performance in complex tasks."}}
{"id": "2502.06545", "pdf": "https://arxiv.org/pdf/2502.06545", "abs": "https://arxiv.org/abs/2502.06545", "authors": ["Annie Marsden", "Elad Hazan"], "title": "Universal Sequence Preconditioning", "categories": ["cs.LG", "stat.ML"], "comment": "35 pages, 7 figures", "summary": "We study the problem of preconditioning in the setting of sequential\nprediction. From the theoretical lens of linear dynamical systems, we show that\napplying a convolution to the input sequence translates to applying a\npolynomial to the unknown transition matrix in the hidden space. With this\ninsight, we develop a novel preconditioning method that convolves the input\nsequence with the coefficients of the Chebyshev or Legendre polynomials. We\nformally prove that this improves the regret of two distinct prediction\nmethods. Moreover, using this preconditioning technique on either method gives\nthe first sublinear regret bounds that are also hidden dimension independent\n(up to logarithmic factors) even when the hidden transition matrix is\nasymmetric. From rigorous experiments on synthetic data we show that our simple\npreconditioning method generalizes to both 1) settings where the data is not\nfrom a linear dynamical system and 2) a broad range of learning algorithms,\nincluding recurrent neural networks.", "AI": {"tldr": "The paper introduces a novel preconditioning method for sequential prediction using Chebyshev or Legendre polynomials, improving regret bounds and generalizing to non-linear settings.", "motivation": "To address the challenge of preconditioning in sequential prediction, particularly for linear dynamical systems, and extend its applicability to broader settings.", "method": "Applies convolution to input sequences using Chebyshev or Legendre polynomial coefficients, translating to polynomial transformations of the hidden transition matrix.", "result": "Proves improved regret bounds for prediction methods, achieving sublinear and dimension-independent regret even for asymmetric transition matrices.", "conclusion": "The preconditioning method is effective and generalizable, as validated by synthetic data experiments, including non-linear systems and diverse learning algorithms."}}
{"id": "2505.22312", "pdf": "https://arxiv.org/pdf/2505.22312", "abs": "https://arxiv.org/abs/2505.22312", "authors": ["Jujie He", "Jiacai Liu", "Chris Yuhao Liu", "Rui Yan", "Chaojie Wang", "Peng Cheng", "Xiaoyu Zhang", "Fuxiang Zhang", "Jiacheng Xu", "Wei Shen", "Siyuan Li", "Liang Zeng", "Tianwen Wei", "Cheng Cheng", "Bo An", "Yang Liu", "Yahui Zhou"], "title": "Skywork Open Reasoner 1 Technical Report", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "The success of DeepSeek-R1 underscores the significant role of reinforcement\nlearning (RL) in enhancing the reasoning capabilities of large language models\n(LLMs). In this work, we present Skywork-OR1, an effective and scalable RL\nimplementation for long Chain-of-Thought (CoT) models. Building on the\nDeepSeek-R1-Distill model series, our RL approach achieves notable performance\ngains, increasing average accuracy across AIME24, AIME25, and LiveCodeBench\nfrom 57.8% to 72.8% (+15.0%) for the 32B model and from 43.6% to 57.5% (+13.9%)\nfor the 7B model. Our Skywork-OR1-32B model surpasses both DeepSeek-R1 and\nQwen3-32B on the AIME24 and AIME25 benchmarks, while achieving comparable\nresults on LiveCodeBench. The Skywork-OR1-7B and Skywork-OR1-Math-7B models\ndemonstrate competitive reasoning capabilities among models of similar size. We\nperform comprehensive ablation studies on the core components of our training\npipeline to validate their effectiveness. Additionally, we thoroughly\ninvestigate the phenomenon of entropy collapse, identify key factors affecting\nentropy dynamics, and demonstrate that mitigating premature entropy collapse is\ncritical for improved test performance. To support community research, we fully\nopen-source our model weights, training code, and training datasets.", "AI": {"tldr": "Skywork-OR1 enhances reasoning in LLMs via RL, achieving significant accuracy gains (up to +15.0%) on benchmarks like AIME24 and LiveCodeBench, outperforming competitors like DeepSeek-R1 and Qwen3-32B.", "motivation": "To improve reasoning in LLMs using scalable RL, addressing long CoT challenges and entropy collapse.", "method": "RL-based training pipeline, building on DeepSeek-R1-Distill, with ablation studies and entropy dynamics analysis.", "result": "Notable performance gains (e.g., 57.8% to 72.8% for 32B model), surpassing competitors on benchmarks.", "conclusion": "Mitigating entropy collapse is key; open-sourcing models and data supports community research."}}
{"id": "2405.14979", "pdf": "https://arxiv.org/pdf/2405.14979", "abs": "https://arxiv.org/abs/2405.14979", "authors": ["Weiyu Li", "Jiarui Liu", "Hongyu Yan", "Rui Chen", "Yixun Liang", "Xuelin Chen", "Ping Tan", "Xiaoxiao Long"], "title": "CraftsMan3D: High-fidelity Mesh Generation with 3D Native Generation and Interactive Geometry Refiner", "categories": ["cs.GR", "cs.CV"], "comment": "HomePage: https://craftsman3d.github.io/, Code:\n  https://github.com/wyysf-98/CraftsMan3D", "summary": "We present a novel generative 3D modeling system, coined CraftsMan, which can\ngenerate high-fidelity 3D geometries with highly varied shapes, regular mesh\ntopologies, and detailed surfaces, and, notably, allows for refining the\ngeometry in an interactive manner. Despite the significant advancements in 3D\ngeneration, existing methods still struggle with lengthy optimization\nprocesses, irregular mesh topologies, noisy surfaces, and difficulties in\naccommodating user edits, consequently impeding their widespread adoption and\nimplementation in 3D modeling software. Our work is inspired by the craftsman,\nwho usually roughs out the holistic figure of the work first and elaborates the\nsurface details subsequently. Specifically, we employ a 3D native diffusion\nmodel, which operates on latent space learned from latent set-based 3D\nrepresentations, to generate coarse geometries with regular mesh topology in\nseconds. In particular, this process takes as input a text prompt or a\nreference image and leverages a powerful multi-view (MV) diffusion model to\ngenerate multiple views of the coarse geometry, which are fed into our\nMV-conditioned 3D diffusion model for generating the 3D geometry, significantly\nimproving robustness and generalizability. Following that, a normal-based\ngeometry refiner is used to significantly enhance the surface details. This\nrefinement can be performed automatically, or interactively with user-supplied\nedits. Extensive experiments demonstrate that our method achieves high efficacy\nin producing superior-quality 3D assets compared to existing methods. HomePage:\nhttps://craftsman3d.github.io/, Code: https://github.com/wyysf-98/CraftsMan", "AI": {"tldr": "CraftsMan is a novel generative 3D modeling system that quickly produces high-fidelity 3D geometries with regular mesh topologies and detailed surfaces, supporting interactive refinement.", "motivation": "Existing 3D generation methods face challenges like slow optimization, irregular meshes, noisy surfaces, and poor user editability, limiting their adoption in 3D software.", "method": "Uses a 3D native diffusion model for coarse geometry generation in seconds, leveraging multi-view diffusion for robustness, followed by a normal-based refiner for detail enhancement.", "result": "Achieves superior-quality 3D assets with high efficacy, outperforming existing methods.", "conclusion": "CraftsMan offers a practical solution for efficient, high-quality 3D modeling with interactive refinement capabilities."}}
{"id": "2505.21717", "pdf": "https://arxiv.org/pdf/2505.21717", "abs": "https://arxiv.org/abs/2505.21717", "authors": ["M\u00f3nika Farsang", "Ramin Hasani", "Radu Grosu"], "title": "Scaling Up Liquid-Resistance Liquid-Capacitance Networks for Efficient Sequence Modeling", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "We present LrcSSM, a $\\textit{nonlinear}$ recurrent model that processes long\nsequences as fast as today's linear state-space layers. By forcing the\nstate-transition matrix to be diagonal and learned at every step, the full\nsequence can be solved in parallel with a single prefix-scan, giving\n$\\mathcal{O}(TD)$ time and memory and only $\\mathcal{O}(\\log T)$ sequential\ndepth, for input-sequence length $T$ and a state dimension $D$. Moreover,\nLrcSSM offers a formal gradient-stability guarantee that other input-varying\nsystems such as Liquid-S4 and Mamba do not provide. Lastly, for network depth\n$L$, as the forward and backward passes cost $\\Theta(T\\,D\\,L)$ FLOPs, with its\nlow sequential depth and parameter count $\\Theta(D\\,L)$, the model follows the\ncompute-optimal scaling law regime ($\\beta \\approx 0.42$) recently observed for\nMamba, outperforming quadratic-attention Transformers at equal compute while\navoiding the memory overhead of FFT-based long convolutions. We show that on a\nseries of long-range forecasting tasks, LrcSSM outperforms LRU, S5 and Mamba.", "AI": {"tldr": "LrcSSM is a nonlinear recurrent model that processes long sequences efficiently, matching the speed of linear state-space layers while offering parallel processing, gradient stability, and compute-optimal scaling.", "motivation": "To address the inefficiencies of existing models (e.g., Liquid-S4, Mamba) in processing long sequences, LrcSSM aims to provide faster, more stable, and compute-optimal solutions.", "method": "LrcSSM uses a diagonal state-transition matrix learned at every step, enabling parallel processing via a single prefix-scan. It achieves O(TD) time/memory and O(log T) sequential depth.", "result": "LrcSSM outperforms LRU, S5, and Mamba in long-range forecasting tasks, with compute-optimal scaling and lower memory overhead than FFT-based convolutions.", "conclusion": "LrcSSM is a promising alternative to existing models for long-sequence tasks, combining efficiency, stability, and performance."}}
{"id": "2502.07364", "pdf": "https://arxiv.org/pdf/2502.07364", "abs": "https://arxiv.org/abs/2502.07364", "authors": ["Jasraj Singh", "Keyue Jiang", "Brooks Paige", "Laura Toni"], "title": "Effects of Dropout on Performance in Long-range Graph Learning Tasks", "categories": ["cs.LG"], "comment": "34 pages, 9 figures, 9 tables", "summary": "Message Passing Neural Networks (MPNNs) are a class of Graph Neural Networks\n(GNNs) that propagate information across the graph via local neighborhoods. The\nscheme gives rise to two key challenges: over-smoothing and over-squashing.\nWhile several Dropout-style algorithms, such as DropEdge and DropMessage, have\nsuccessfully addressed over-smoothing, their impact on over-squashing remains\nlargely unexplored. This represents a critical gap in the literature, as\nfailure to mitigate over-squashing would make these methods unsuitable for\nlong-range tasks -- the intended use case of deep MPNNs. In this work, we study\nthe aforementioned algorithms, and closely related edge-dropping algorithms --\nDropNode, DropAgg and DropGNN -- in the context of over-squashing. We present\ntheoretical results showing that DropEdge-variants reduce sensitivity between\ndistant nodes, limiting their suitability for long-range tasks. To address\nthis, we introduce DropSens, a sensitivity-aware variant of DropEdge that\nexplicitly controls the proportion of information lost due to edge-dropping,\nthereby increasing sensitivity to distant nodes despite dropping the same\nnumber of edges. Our experiments on long-range synthetic and real-world\ndatasets confirm the predicted limitations of existing edge-dropping and\nfeature-dropping methods. Moreover, DropSens consistently outperforms graph\nrewiring techniques designed to mitigate over-squashing, suggesting that\nsimple, targeted modifications can substantially improve a model's ability to\ncapture long-range interactions. Our conclusions highlight the need to\nre-evaluate and re-design existing methods for training deep GNNs, with a\nrenewed focus on modelling long-range interactions.", "AI": {"tldr": "The paper analyzes Dropout-style algorithms in MPNNs, focusing on their impact on over-squashing. It introduces DropSens, a sensitivity-aware variant, which outperforms existing methods in long-range tasks.", "motivation": "Existing Dropout-style algorithms address over-smoothing but neglect over-squashing, limiting their suitability for long-range tasks in deep MPNNs.", "method": "The study evaluates DropEdge-variants and introduces DropSens, a sensitivity-aware edge-dropping method, to control information loss and improve sensitivity to distant nodes.", "result": "DropSens outperforms existing edge-dropping and graph rewiring techniques in long-range tasks, demonstrating better capture of long-range interactions.", "conclusion": "The findings emphasize the need to re-evaluate and redesign methods for deep GNNs, prioritizing long-range interaction modeling."}}
{"id": "2505.21969", "pdf": "https://arxiv.org/pdf/2505.21969", "abs": "https://arxiv.org/abs/2505.21969", "authors": ["Tianjun Gu", "Linfeng Li", "Xuhong Wang", "Chenghua Gong", "Jingyu Gong", "Zhizhong Zhang", "Yuan Xie", "Lizhuang Ma", "Xin Tan"], "title": "DORAEMON: Decentralized Ontology-aware Reliable Agent with Enhanced Memory Oriented Navigation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Adaptive navigation in unfamiliar environments is crucial for household\nservice robots but remains challenging due to the need for both low-level path\nplanning and high-level scene understanding. While recent vision-language model\n(VLM) based zero-shot approaches reduce dependence on prior maps and\nscene-specific training data, they face significant limitations: spatiotemporal\ndiscontinuity from discrete observations, unstructured memory representations,\nand insufficient task understanding leading to navigation failures. We propose\nDORAEMON (Decentralized Ontology-aware Reliable Agent with Enhanced Memory\nOriented Navigation), a novel cognitive-inspired framework consisting of\nVentral and Dorsal Streams that mimics human navigation capabilities. The\nDorsal Stream implements the Hierarchical Semantic-Spatial Fusion and Topology\nMap to handle spatiotemporal discontinuities, while the Ventral Stream combines\nRAG-VLM and Policy-VLM to improve decision-making. Our approach also develops\nNav-Ensurance to ensure navigation safety and efficiency. We evaluate DORAEMON\non the HM3D, MP3D, and GOAT datasets, where it achieves state-of-the-art\nperformance on both success rate (SR) and success weighted by path length (SPL)\nmetrics, significantly outperforming existing methods. We also introduce a new\nevaluation metric (AORI) to assess navigation intelligence better.\nComprehensive experiments demonstrate DORAEMON's effectiveness in zero-shot\nautonomous navigation without requiring prior map building or pre-training.", "AI": {"tldr": "DORAEMON is a cognitive-inspired framework for autonomous navigation in unfamiliar environments, combining Ventral and Dorsal Streams to address spatiotemporal discontinuity and improve decision-making, achieving state-of-the-art performance.", "motivation": "Household service robots need adaptive navigation in unfamiliar environments, but existing VLM-based methods suffer from spatiotemporal discontinuity, unstructured memory, and poor task understanding.", "method": "DORAEMON uses a Dorsal Stream for spatiotemporal handling (Hierarchical Semantic-Spatial Fusion, Topology Map) and a Ventral Stream (RAG-VLM, Policy-VLM) for decision-making, with Nav-Ensurance for safety.", "result": "Achieves top performance on HM3D, MP3D, and GOAT datasets in success rate (SR) and success weighted by path length (SPL), introducing a new metric (AORI).", "conclusion": "DORAEMON enables zero-shot autonomous navigation without prior maps or pre-training, outperforming existing methods."}}
{"id": "2502.11394", "pdf": "https://arxiv.org/pdf/2502.11394", "abs": "https://arxiv.org/abs/2502.11394", "authors": ["Jiaqi Wang", "Xinyi Wu", "James Cheng", "Yifei Wang"], "title": "A Signed Graph Approach to Understanding and Mitigating Oversmoothing in GNNs", "categories": ["cs.LG"], "comment": null, "summary": "Deep graph neural networks (GNNs) often suffer from oversmoothing, where node\nrepresentations become overly homogeneous with increasing depth. While\ntechniques like normalization, residual connections, and edge dropout have been\nproposed to mitigate oversmoothing, they are typically developed independently,\nwith limited theoretical understanding of their underlying mechanisms. In this\nwork, we present a unified theoretical perspective based on the framework of\nsigned graphs, showing that many existing strategies implicitly introduce\nnegative edges that alter message-passing to resist oversmoothing. However, we\nshow that merely adding negative edges in an unstructured manner is\ninsufficient-the asymptotic behavior of signed propagation depends critically\non the strength and organization of positive and negative edges. To address\nthis limitation, we leverage the theory of structural balance, which promotes\nstable, cluster-preserving dynamics by connecting similar nodes with positive\nedges and dissimilar ones with negative edges. We propose Structural Balanced\nPropagation (SBP), a plug-and-play method that assigns signed edges based on\neither labels or feature similarity to explicitly enhance structural balance in\nthe constructed signed graphs. Experiments on nine benchmarks across both\nhomophilic and heterophilic settings demonstrate that SBP consistently improves\nclassification accuracy and mitigates oversmoothing, even at depths of up to\n300 layers. Our results provide a principled explanation for prior\noversmoothing remedies and introduce a new direction for signed message-passing\ndesign in deep GNNs.", "AI": {"tldr": "The paper addresses oversmoothing in deep GNNs by proposing Structural Balanced Propagation (SBP), a method leveraging signed graphs and structural balance theory to improve classification accuracy and resist oversmoothing.", "motivation": "Deep GNNs suffer from oversmoothing, where node representations become too similar. Existing solutions lack a unified theoretical understanding.", "method": "The authors introduce SBP, which assigns signed edges based on labels or feature similarity to enhance structural balance in signed graphs.", "result": "Experiments on nine benchmarks show SBP improves accuracy and mitigates oversmoothing, even at 300 layers.", "conclusion": "SBP provides a principled explanation for prior remedies and advances signed message-passing design in deep GNNs."}}
{"id": "2502.09775", "pdf": "https://arxiv.org/pdf/2502.09775", "abs": "https://arxiv.org/abs/2502.09775", "authors": ["Yuhui Zhang", "Yuchang Su", "Chenyu Wang", "Tianhong Li", "Zoe Wefers", "Jeffrey Nirschl", "James Burgess", "Daisy Ding", "Alejandro Lozano", "Emma Lundberg", "Serena Yeung-Levy"], "title": "CellFlux: Simulating Cellular Morphology Changes via Flow Matching", "categories": ["q-bio.QM", "cs.CV", "cs.LG", "q-bio.BM", "q-bio.CB"], "comment": "Published at ICML 2025", "summary": "Building a virtual cell capable of accurately simulating cellular behaviors\nin silico has long been a dream in computational biology. We introduce\nCellFlux, an image-generative model that simulates cellular morphology changes\ninduced by chemical and genetic perturbations using flow matching. Unlike prior\nmethods, CellFlux models distribution-wise transformations from unperturbed to\nperturbed cell states, effectively distinguishing actual perturbation effects\nfrom experimental artifacts such as batch effects -- a major challenge in\nbiological data. Evaluated on chemical (BBBC021), genetic (RxRx1), and combined\nperturbation (JUMP) datasets, CellFlux generates biologically meaningful cell\nimages that faithfully capture perturbation-specific morphological changes,\nachieving a 35% improvement in FID scores and a 12% increase in mode-of-action\nprediction accuracy over existing methods. Additionally, CellFlux enables\ncontinuous interpolation between cellular states, providing a potential tool\nfor studying perturbation dynamics. These capabilities mark a significant step\ntoward realizing virtual cell modeling for biomedical research. Project page:\nhttps://yuhui-zh15.github.io/CellFlux/.", "AI": {"tldr": "CellFlux is an image-generative model using flow matching to simulate cellular morphology changes from perturbations, outperforming existing methods in accuracy and biological relevance.", "motivation": "To address the challenge of accurately simulating cellular behaviors in silico, distinguishing real perturbation effects from experimental artifacts.", "method": "Uses flow matching to model distribution-wise transformations from unperturbed to perturbed cell states, evaluated on chemical, genetic, and combined perturbation datasets.", "result": "Achieves 35% better FID scores and 12% higher mode-of-action prediction accuracy, generating biologically meaningful images.", "conclusion": "CellFlux advances virtual cell modeling, offering tools for studying perturbation dynamics and biomedical research."}}
{"id": "2505.22370", "pdf": "https://arxiv.org/pdf/2505.22370", "abs": "https://arxiv.org/abs/2505.22370", "authors": ["Haomiao Qiu", "Miao Zhang", "Ziyue Qiao", "Weili Guan", "Min Zhang", "Liqiang Nie"], "title": "SplitLoRA: Balancing Stability and Plasticity in Continual Learning Through Gradient Space Splitting", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages, 4 figures", "summary": "Continual Learning requires a model to learn multiple tasks in sequence while\nmaintaining both stability:preserving knowledge from previously learned tasks,\nand plasticity:effectively learning new tasks. Gradient projection has emerged\nas an effective and popular paradigm in CL, where it partitions the gradient\nspace of previously learned tasks into two orthogonal subspaces: a primary\nsubspace and a minor subspace. New tasks are learned effectively within the\nminor subspace, thereby reducing interference with previously acquired\nknowledge. However, existing Gradient Projection methods struggle to achieve an\noptimal balance between plasticity and stability, as it is hard to\nappropriately partition the gradient space. In this work, we consider a\ncontinual learning paradigm based on Low-Rank Adaptation, which has gained\nconsiderable attention due to its efficiency and wide applicability, and\npropose a novel approach for continual learning, called SplitLoRA. We first\nprovide a theoretical analysis of how subspace partitioning affects model\nstability and plasticity. Informed by this analysis, we then introduce an\neffective method that derives the optimal partition of the gradient space for\npreviously learned tasks. This approach effectively balances stability and\nplasticity in continual learning. Experimental results on multiple datasets\ndemonstrate that the proposed method achieves state-of-the-art performance.", "AI": {"tldr": "The paper introduces SplitLoRA, a novel method for continual learning that optimizes gradient space partitioning to balance stability and plasticity, achieving state-of-the-art results.", "motivation": "Existing gradient projection methods in continual learning struggle to balance stability (retaining old knowledge) and plasticity (learning new tasks), motivating a better approach.", "method": "The proposed SplitLoRA method uses Low-Rank Adaptation to optimally partition gradient space, informed by theoretical analysis of subspace partitioning.", "result": "Experiments show SplitLoRA outperforms existing methods, achieving state-of-the-art performance on multiple datasets.", "conclusion": "SplitLoRA effectively balances stability and plasticity in continual learning, offering a superior solution to gradient space partitioning."}}
{"id": "2502.15280", "pdf": "https://arxiv.org/pdf/2502.15280", "abs": "https://arxiv.org/abs/2502.15280", "authors": ["Hojoon Lee", "Youngdo Lee", "Takuma Seno", "Donghu Kim", "Peter Stone", "Jaegul Choo"], "title": "Hyperspherical Normalization for Scalable Deep Reinforcement Learning", "categories": ["cs.LG"], "comment": "50 pages. ICML'25 (spotlight)", "summary": "Scaling up the model size and computation has brought consistent performance\nimprovements in supervised learning. However, this lesson often fails to apply\nto reinforcement learning (RL) because training the model on non-stationary\ndata easily leads to overfitting and unstable optimization. In response, we\nintroduce SimbaV2, a novel RL architecture designed to stabilize optimization\nby (i) constraining the growth of weight and feature norm by hyperspherical\nnormalization; and (ii) using a distributional value estimation with reward\nscaling to maintain stable gradients under varying reward magnitudes. Using the\nsoft actor-critic as a base algorithm, SimbaV2 scales up effectively with\nlarger models and greater compute, achieving state-of-the-art performance on 57\ncontinuous control tasks across 4 domains. The code is available at\nhttps://dojeon-ai.github.io/SimbaV2.", "AI": {"tldr": "SimbaV2 stabilizes RL training by constraining weight/feature norms and using distributional value estimation, achieving SOTA on 57 tasks.", "motivation": "Scaling models in RL often leads to instability; SimbaV2 addresses this to enable effective scaling.", "method": "Uses hyperspherical normalization for weight/feature norms and distributional value estimation with reward scaling.", "result": "Achieves state-of-the-art performance on 57 continuous control tasks.", "conclusion": "SimbaV2 enables stable and scalable RL training, outperforming existing methods."}}
{"id": "2502.10570", "pdf": "https://arxiv.org/pdf/2502.10570", "abs": "https://arxiv.org/abs/2502.10570", "authors": ["Yaxiong Lei", "Yuheng Wang", "Fergus Buchanan", "Mingyue Zhao", "Yusuke Sugano", "Shijing He", "Mohamed Khamis", "Juan Ye"], "title": "Quantifying the Impact of Motion on 2D Gaze Estimation in Real-World Mobile Interactions", "categories": ["cs.HC", "cs.CV", "H.5; I.4"], "comment": "27 pages, 14 figures", "summary": "Mobile gaze tracking involves inferring a user's gaze point or direction on a\nmobile device's screen from facial images captured by the device's front\ncamera. While this technology inspires an increasing number of gaze-interaction\napplications, achieving consistent accuracy remains challenging due to dynamic\nuser-device spatial relationships and varied motion conditions inherent in\nmobile contexts. This paper provides empirical evidence on how user mobility\nand behaviour affect mobile gaze tracking accuracy. We conduct two user studies\ncollecting behaviour and gaze data under various motion conditions - from lying\nto maze navigation - and during different interaction tasks. Quantitative\nanalysis has revealed behavioural regularities among daily tasks and identified\nhead distance, head pose, and device orientation as key factors affecting\naccuracy, with errors increasing by up to 48.91% in dynamic conditions compared\nto static ones. These findings highlight the need for more robust, adaptive\neye-tracking systems that account for head movements and device deflection to\nmaintain accuracy across diverse mobile contexts.", "AI": {"tldr": "Mobile gaze tracking accuracy is affected by user mobility and behavior, with errors increasing up to 48.91% in dynamic conditions. Key factors include head distance, pose, and device orientation.", "motivation": "To understand how user mobility and behavior impact mobile gaze tracking accuracy, given the challenges of dynamic user-device relationships and varied motion conditions.", "method": "Two user studies collecting behavior and gaze data under various motion conditions (lying to maze navigation) and interaction tasks, followed by quantitative analysis.", "result": "Behavioral regularities were found, with head distance, head pose, and device orientation identified as key accuracy factors. Errors increased by up to 48.91% in dynamic conditions.", "conclusion": "Robust, adaptive eye-tracking systems are needed to account for head movements and device deflection to maintain accuracy in diverse mobile contexts."}}
{"id": "2505.22389", "pdf": "https://arxiv.org/pdf/2505.22389", "abs": "https://arxiv.org/abs/2505.22389", "authors": ["Haomiao Qiu", "Miao Zhang", "Ziyue Qiao", "Liqiang Nie"], "title": "Train with Perturbation, Infer after Merging: A Two-Stage Framework for Continual Learning", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages, 3 figures", "summary": "Continual Learning (CL) aims to enable models to continuously acquire new\nknowledge from a sequence of tasks with avoiding the forgetting of learned\ninformation. However, existing CL methods only rely on the parameters of the\nmost recent task for inference, which makes them susceptible to catastrophic\nforgetting. Inspired by the recent success of model merging techniques, we\npropose \\textbf{Perturb-and-Merge (P\\&M)}, a novel continual learning framework\nthat integrates model merging into the CL paradigm to mitigate forgetting.\nSpecifically, after training on each task, P\\&M constructs a new model by\nforming a convex combination of the previous model and the newly trained\ntask-specific model. Through theoretical analysis, we minimize the total loss\nincrease across all tasks and derive an analytical solution for the optimal\nmerging coefficient. To further improve the performance of the merged model, we\nobserve that the degradation introduced during merging can be alleviated by a\nregularization term composed of the task vector and the Hessian matrix of the\nloss function. Interestingly, we show that this term can be efficiently\napproximated using second-order symmetric finite differences, and a stochastic\nperturbation strategy along the task vector direction is accordingly devised\nwhich incurs no additional forward or backward passes while providing an\neffective approximation of the regularization term. Finally, we combine P\\&M\nwith LoRA, a parameter-efficient fine-tuning method, to reduce memory overhead.\nOur proposed approach achieves state-of-the-art performance on several\ncontinual learning benchmark datasets.", "AI": {"tldr": "Perturb-and-Merge (P&M) integrates model merging into continual learning to mitigate forgetting by combining previous and new models, optimizing merging coefficients, and using regularization. It achieves top performance on benchmarks.", "motivation": "Existing continual learning methods suffer from catastrophic forgetting by relying only on recent task parameters.", "method": "P&M merges previous and new models with optimal coefficients, uses Hessian-based regularization, and combines with LoRA for efficiency.", "result": "State-of-the-art performance on continual learning benchmarks.", "conclusion": "P&M effectively mitigates forgetting in continual learning through model merging and regularization."}}
{"id": "2503.08674", "pdf": "https://arxiv.org/pdf/2503.08674", "abs": "https://arxiv.org/abs/2503.08674", "authors": ["Tobias Kreiman", "Aditi S. Krishnapriyan"], "title": "Understanding and Mitigating Distribution Shifts For Machine Learning Force Fields", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.chem-ph", "q-bio.BM"], "comment": null, "summary": "Machine Learning Force Fields (MLFFs) are a promising alternative to\nexpensive ab initio quantum mechanical molecular simulations. Given the\ndiversity of chemical spaces that are of interest and the cost of generating\nnew data, it is important to understand how MLFFs generalize beyond their\ntraining distributions. In order to characterize and better understand\ndistribution shifts in MLFFs, we conduct diagnostic experiments on chemical\ndatasets, revealing common shifts that pose significant challenges, even for\nlarge foundation models trained on extensive data. Based on these observations,\nwe hypothesize that current supervised training methods inadequately regularize\nMLFFs, resulting in overfitting and learning poor representations of\nout-of-distribution systems. We then propose two new methods as initial steps\nfor mitigating distribution shifts for MLFFs. Our methods focus on test-time\nrefinement strategies that incur minimal computational cost and do not use\nexpensive ab initio reference labels. The first strategy, based on spectral\ngraph theory, modifies the edges of test graphs to align with graph structures\nseen during training. Our second strategy improves representations for\nout-of-distribution systems at test-time by taking gradient steps using an\nauxiliary objective, such as a cheap physical prior. Our test-time refinement\nstrategies significantly reduce errors on out-of-distribution systems,\nsuggesting that MLFFs are capable of and can move towards modeling diverse\nchemical spaces, but are not being effectively trained to do so. Our\nexperiments establish clear benchmarks for evaluating the generalization\ncapabilities of the next generation of MLFFs. Our code is available at\nhttps://tkreiman.github.io/projects/mlff_distribution_shifts/.", "AI": {"tldr": "The paper investigates generalization challenges in Machine Learning Force Fields (MLFFs) due to distribution shifts and proposes two test-time refinement methods to improve out-of-distribution performance without costly ab initio labels.", "motivation": "MLFFs are a cost-effective alternative to quantum simulations, but their generalization beyond training data is poorly understood. The study aims to address this gap.", "method": "Diagnostic experiments on chemical datasets identify common shifts. Two test-time refinement strategies are proposed: spectral graph theory-based edge modification and gradient steps using auxiliary objectives.", "result": "The proposed methods significantly reduce errors on out-of-distribution systems, demonstrating improved generalization for MLFFs.", "conclusion": "Current MLFF training methods inadequately regularize models, but test-time refinement can enhance generalization, paving the way for better benchmarks and future improvements."}}
{"id": "2503.10632", "pdf": "https://arxiv.org/pdf/2503.10632", "abs": "https://arxiv.org/abs/2503.10632", "authors": ["Subhajit Maity", "Killian Hitsman", "Xin Li", "Aritra Dutta"], "title": "Kolmogorov-Arnold Attention: Is Learnable Attention Better For Vision Transformers?", "categories": ["cs.LG", "cs.CV", "68T07", "I.2.6; I.5.1; I.5.5; I.5.4; I.4.10"], "comment": "Preprint, Appendix included", "summary": "Kolmogorov-Arnold networks (KANs) are a remarkable innovation consisting of\nlearnable activation functions with the potential to capture more complex\nrelationships from data. Presently, KANs are deployed by replacing multilayer\nperceptrons (MLPs) in deep networks, including advanced architectures such as\nvision Transformers (ViTs). This work asks whether a similar replacement in the\nattention can bring benefits. In this paper, we design the first learnable\nattention called Kolmogorov-Arnold Attention (KArAt) for ViTs that can operate\non any basis, ranging from Fourier, Wavelets, Splines, to Rational Functions.\nHowever, learnable activations in attention cause a memory explosion. To remedy\nthis, we propose a modular version of KArAt that uses a low-rank approximation.\nBy adopting the Fourier basis, Fourier-KArAt and its variants, in some cases,\noutperform their traditional softmax counterparts, or show comparable\nperformance on CIFAR-10, CIFAR-100, and ImageNet-1K datasets. We also deploy\nFourier KArAt to ConViT and Swin-Transformer, and use it in detection and\nsegmentation with ViT-Det. We dissect these architectures' performance by\nanalyzing their loss landscapes, weight distributions, optimizer path,\nattention visualization, and transferability to other datasets. KArAt's\nlearnable activation shows a better attention score across all ViTs, indicating\nbetter token-to-token interactions, contributing to better inference. Still,\nits generalizability does not scale with larger ViTs. However, many factors,\nincluding the present computing interface, affect the performance of parameter-\nand memory-heavy KArAts. We note that the goal of this paper is not to produce\nefficient attention or challenge the traditional activations; by designing\nKArAt, we are the first to show that attention can be learned and encourage\nresearchers to explore KArAt in conjunction with more advanced architectures.", "AI": {"tldr": "The paper introduces Kolmogorov-Arnold Attention (KArAt), a learnable attention mechanism for ViTs, showing improved performance in some cases but facing memory challenges.", "motivation": "To explore if replacing traditional attention with learnable activation functions (like KANs) in ViTs can enhance performance.", "method": "Designs KArAt, a modular attention mechanism with low-rank approximation to address memory issues, tested on datasets like CIFAR and ImageNet.", "result": "Fourier-KArAt variants outperform or match softmax attention in some cases, with better token interactions but limited scalability in larger ViTs.", "conclusion": "KArAt demonstrates learnable attention's potential, encouraging further research despite current limitations in efficiency and scalability."}}
{"id": "2505.22598", "pdf": "https://arxiv.org/pdf/2505.22598", "abs": "https://arxiv.org/abs/2505.22598", "authors": ["Luca Maria Del Bono", "Federico Ricci-Tersenghi", "Francesco Zamponi"], "title": "On the performance of machine-learning-assisted Monte Carlo in sampling from simple statistical physics models", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "cs.LG", "physics.comp-ph"], "comment": "16 pages, 9 figures", "summary": "Recent years have seen a rise in the application of machine learning\ntechniques to aid the simulation of hard-to-sample systems that cannot be\nstudied using traditional methods. Despite the introduction of many different\narchitectures and procedures, a wide theoretical understanding is still\nlacking, with the risk of suboptimal implementations. As a first step to\naddress this gap, we provide here a complete analytic study of the widely-used\nSequential Tempering procedure applied to a shallow MADE architecture for the\nCurie-Weiss model. The contribution of this work is twofold: firstly, we give a\ndescription of the optimal weights and of the training under Gradient Descent\noptimization. Secondly, we compare what happens in Sequential Tempering with\nand without the addition of local Metropolis Monte Carlo steps. We are thus\nable to give theoretical predictions on the best procedure to apply in this\ncase. This work establishes a clear theoretical basis for the integration of\nmachine learning techniques into Monte Carlo sampling and optimization.", "AI": {"tldr": "The paper provides a theoretical analysis of Sequential Tempering with a shallow MADE architecture for the Curie-Weiss model, comparing its performance with and without local Metropolis Monte Carlo steps.", "motivation": "The lack of theoretical understanding in machine learning applications for simulating hard-to-sample systems risks suboptimal implementations. This work aims to address this gap.", "method": "The study analytically examines Sequential Tempering applied to a shallow MADE architecture, focusing on optimal weights, Gradient Descent training, and the impact of local Metropolis Monte Carlo steps.", "result": "Theoretical predictions are provided for the optimal procedure, comparing Sequential Tempering with and without local Metropolis steps.", "conclusion": "The work establishes a theoretical foundation for integrating machine learning into Monte Carlo sampling and optimization."}}
{"id": "2503.11964", "pdf": "https://arxiv.org/pdf/2503.11964", "abs": "https://arxiv.org/abs/2503.11964", "authors": ["Jasmeet Kaur"], "title": "Entropy-regularized Gradient Estimators for Approximate Bayesian Inference", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Effective uncertainty quantification is important for training modern\npredictive models with limited data, enhancing both accuracy and robustness.\nWhile Bayesian methods are effective for this purpose, they can be challenging\nto scale. When employing approximate Bayesian inference, ensuring the quality\nof samples from the posterior distribution in a computationally efficient\nmanner is essential. This paper addresses the estimation of the Bayesian\nposterior to generate diverse samples by approximating the gradient flow of the\nKullback-Leibler (KL) divergence and the cross entropy of the target\napproximation under the metric induced by the Stein Operator. It presents\nempirical evaluations on classification tasks to assess the method's\nperformance and discuss its effectiveness for Model-Based Reinforcement\nLearning that uses uncertainty-aware network dynamics models.", "AI": {"tldr": "The paper proposes a method for scalable Bayesian posterior estimation using gradient flow approximation of KL divergence and cross entropy, validated on classification tasks and applied to uncertainty-aware reinforcement learning.", "motivation": "Effective uncertainty quantification is crucial for modern predictive models with limited data, but Bayesian methods face scalability challenges.", "method": "Approximates the gradient flow of KL divergence and cross entropy under the Stein Operator metric to generate diverse posterior samples.", "result": "Empirical evaluations on classification tasks demonstrate the method's performance.", "conclusion": "The approach is effective for uncertainty-aware reinforcement learning using network dynamics models."}}
{"id": "2504.02666", "pdf": "https://arxiv.org/pdf/2504.02666", "abs": "https://arxiv.org/abs/2504.02666", "authors": ["Mei Li", "Yuxiang Lu", "Qinyan Dai", "Suizhi Huang", "Yue Ding", "Hongtao Lu"], "title": "BECAME: BayEsian Continual Learning with Adaptive Model MErging", "categories": ["cs.LG", "cs.CV"], "comment": "Accepted by ICML 2025", "summary": "Continual Learning (CL) strives to learn incrementally across tasks while\nmitigating catastrophic forgetting. A key challenge in CL is balancing\nstability (retaining prior knowledge) and plasticity (learning new tasks).\nWhile representative gradient projection methods ensure stability, they often\nlimit plasticity. Model merging techniques offer promising solutions, but prior\nmethods typically rely on empirical assumptions and carefully selected\nhyperparameters. In this paper, we explore the potential of model merging to\nenhance the stability-plasticity trade-off, providing theoretical insights that\nunderscore its benefits. Specifically, we reformulate the merging mechanism\nusing Bayesian continual learning principles and derive a closed-form solution\nfor the optimal merging coefficient that adapts to the diverse characteristics\nof tasks. To validate our approach, we introduce a two-stage framework named\nBECAME, which synergizes the expertise of gradient projection and adaptive\nmerging. Extensive experiments show that our approach outperforms\nstate-of-the-art CL methods and existing merging strategies.", "AI": {"tldr": "The paper proposes BECAME, a two-stage framework combining gradient projection and adaptive model merging to improve the stability-plasticity trade-off in continual learning, backed by theoretical insights and superior experimental results.", "motivation": "Address the challenge of balancing stability (retaining prior knowledge) and plasticity (learning new tasks) in continual learning, where existing methods like gradient projection limit plasticity and model merging lacks theoretical grounding.", "method": "Reformulate model merging using Bayesian continual learning principles, derive an optimal merging coefficient, and introduce BECAME, a framework integrating gradient projection and adaptive merging.", "result": "Extensive experiments demonstrate BECAME outperforms state-of-the-art continual learning methods and existing merging strategies.", "conclusion": "Model merging, when theoretically grounded and adaptively applied, effectively enhances the stability-plasticity trade-off in continual learning, as validated by BECAME."}}
{"id": "2505.22642", "pdf": "https://arxiv.org/pdf/2505.22642", "abs": "https://arxiv.org/abs/2505.22642", "authors": ["Younggyo Seo", "Carmelo Sferrazza", "Haoran Geng", "Michal Nauman", "Zhao-Heng Yin", "Pieter Abbeel"], "title": "FastTD3: Simple, Fast, and Capable Reinforcement Learning for Humanoid Control", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Project webpage: https://younggyo.me/fast_td3", "summary": "Reinforcement learning (RL) has driven significant progress in robotics, but\nits complexity and long training times remain major bottlenecks. In this\nreport, we introduce FastTD3, a simple, fast, and capable RL algorithm that\nsignificantly speeds up training for humanoid robots in popular suites such as\nHumanoidBench, IsaacLab, and MuJoCo Playground. Our recipe is remarkably\nsimple: we train an off-policy TD3 agent with several modifications -- parallel\nsimulation, large-batch updates, a distributional critic, and carefully tuned\nhyperparameters. FastTD3 solves a range of HumanoidBench tasks in under 3 hours\non a single A100 GPU, while remaining stable during training. We also provide a\nlightweight and easy-to-use implementation of FastTD3 to accelerate RL research\nin robotics.", "AI": {"tldr": "FastTD3 is a fast and simple RL algorithm for robotics, reducing training time significantly with parallel simulation, large-batch updates, and a distributional critic.", "motivation": "Addressing the complexity and long training times of RL in robotics.", "method": "Off-policy TD3 agent with parallel simulation, large-batch updates, distributional critic, and tuned hyperparameters.", "result": "Solves HumanoidBench tasks in under 3 hours on a single A100 GPU, with stable training.", "conclusion": "FastTD3 offers a lightweight, easy-to-use solution to accelerate RL research in robotics."}}
{"id": "2503.12600", "pdf": "https://arxiv.org/pdf/2503.12600", "abs": "https://arxiv.org/abs/2503.12600", "authors": ["Tao Feng", "Yihang Sun", "Jiaxuan You"], "title": "GraphEval: A Lightweight Graph-Based LLM Framework for Idea Evaluation", "categories": ["cs.LG"], "comment": null, "summary": "The powerful capabilities of Large Language Models (LLMs) have led to their\ngrowing use in evaluating human-generated content, particularly in evaluating\nresearch ideas within academic settings. Existing solutions primarily rely on\nprompt-based LLM methods or fine-tuned lightweight language models for idea\nevaluation. However, these methods are often unstable and struggle to\ncomprehend the complex semantic information embedded in the ideas, impeding\ntheir ability to perform high-quality evaluations. To address the above\nchallenges, we propose GraphEval, a lightweight graph-based LLM framework for\nidea evaluation. Our insight is that a complex idea can be broken down into\ncomprehensible viewpoint nodes using prompts from small LLMs. These viewpoint\nnodes can then be linked together through edges created from LLM-based relation\nextraction and/or BERT similarity scores. The created viewpoint-graph can be\nused to conveniently propagate scores across view-nodes to improve the\nrobustness of the idea evaluations. In particular, we propose two lightweight\ngraph-based methods for idea evaluation: (1) GraphEval-LP: a training-free\nlabel propagation algorithm that propagates evaluation scores from known\nview-nodes to unknown nodes; (2) GraphEval-GNN: a Graph Neural Networks (GNN)\nthat is trained to predict the evaluation scores given the observed graph with\nminimal computation resources. Moreover, to overcome LLM's limitation in\nobjectively assessing the novelty of ideas, we further propose a novelty\ndetection model to GraphEval-GNN to enhance its capability in judging idea\nnovelty. Experiments on two datasets show GraphEval improves F1 scores by at\nleast 14% with low computation and API costs. Additionally, GraphEval can\neffectively detect plagiarized ideas.", "AI": {"tldr": "GraphEval is a lightweight graph-based LLM framework for evaluating research ideas by decomposing them into viewpoint nodes and linking them via relations, improving robustness and novelty detection.", "motivation": "Existing LLM-based methods for idea evaluation are unstable and struggle with complex semantics, prompting the need for a more robust and efficient solution.", "method": "GraphEval decomposes ideas into viewpoint nodes linked by relations, using label propagation (GraphEval-LP) or GNNs (GraphEval-GNN) for score propagation. A novelty detection model is added to assess idea novelty.", "result": "GraphEval improves F1 scores by at least 14% with low computational costs and effectively detects plagiarized ideas.", "conclusion": "GraphEval offers a robust, efficient, and scalable solution for evaluating research ideas, addressing limitations of existing methods."}}
{"id": "2505.10923", "pdf": "https://arxiv.org/pdf/2505.10923", "abs": "https://arxiv.org/abs/2505.10923", "authors": ["Simeon Adebola", "Shuangyu Xie", "Chung Min Kim", "Justin Kerr", "Bart M. van Marrewijk", "Mieke van Vlaardingen", "Tim van Daalen", "E. N. van Loo", "Jose Luis Susa Rincon", "Eugen Solowjow", "Rick van de Zedde", "Ken Goldberg"], "title": "GrowSplat: Constructing Temporal Digital Twins of Plants with Gaussian Splats", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Accurate temporal reconstructions of plant growth are essential for plant\nphenotyping and breeding, yet remain challenging due to complex geometries,\nocclusions, and non-rigid deformations of plants. We present a novel framework\nfor building temporal digital twins of plants by combining 3D Gaussian\nSplatting with a robust sample alignment pipeline. Our method begins by\nreconstructing Gaussian Splats from multi-view camera data, then leverages a\ntwo-stage registration approach: coarse alignment through feature-based\nmatching and Fast Global Registration, followed by fine alignment with\nIterative Closest Point. This pipeline yields a consistent 4D model of plant\ndevelopment in discrete time steps. We evaluate the approach on data from the\nNetherlands Plant Eco-phenotyping Center, demonstrating detailed temporal\nreconstructions of Sequoia and Quinoa species. Videos and Images can be seen at\nhttps://berkeleyautomation.github.io/GrowSplat/", "AI": {"tldr": "A novel framework for temporal plant growth reconstruction using 3D Gaussian Splatting and a two-stage alignment pipeline.", "motivation": "Accurate temporal reconstructions of plant growth are challenging due to complex geometries, occlusions, and non-rigid deformations.", "method": "Combines 3D Gaussian Splatting with a two-stage registration (coarse feature-based matching and fine Iterative Closest Point).", "result": "Produces consistent 4D models of plant development, evaluated on Sequoia and Quinoa species.", "conclusion": "The framework enables detailed temporal reconstructions for plant phenotyping and breeding."}}
{"id": "2505.22649", "pdf": "https://arxiv.org/pdf/2505.22649", "abs": "https://arxiv.org/abs/2505.22649", "authors": ["Guoxuan Chen", "Lianghao Xia", "Chao Huang"], "title": "Pre-training for Recommendation Unlearning", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": "Accepted to SIGIR 2025 Oral", "summary": "Modern recommender systems powered by Graph Neural Networks (GNNs) excel at\nmodeling complex user-item interactions, yet increasingly face scenarios\nrequiring selective forgetting of training data. Beyond user requests to remove\nspecific interactions due to privacy concerns or preference changes, regulatory\nframeworks mandate recommender systems' ability to eliminate the influence of\ncertain user data from models. This recommendation unlearning challenge\npresents unique difficulties as removing connections within interaction graphs\ncreates ripple effects throughout the model, potentially impacting\nrecommendations for numerous users. Traditional approaches suffer from\nsignificant drawbacks: fragmentation methods damage graph structure and\ndiminish performance, while influence function techniques make assumptions that\nmay not hold in complex GNNs, particularly with self-supervised or random\narchitectures. To address these limitations, we propose a novel model-agnostic\npre-training paradigm UnlearnRec that prepares systems for efficient unlearning\noperations. Our Influence Encoder takes unlearning requests together with\nexisting model parameters and directly produces updated parameters of unlearned\nmodel with little fine-tuning, avoiding complete retraining while preserving\nmodel performance characteristics. Extensive evaluation on public benchmarks\ndemonstrates that our method delivers exceptional unlearning effectiveness\nwhile providing more than 10x speedup compared to retraining approaches. We\nrelease our method implementation at: https://github.com/HKUDS/UnlearnRec.", "AI": {"tldr": "UnlearnRec is a model-agnostic pre-training paradigm for efficient unlearning in GNN-based recommender systems, avoiding retraining while preserving performance.", "motivation": "Address the challenge of selective forgetting in GNN-based recommender systems due to privacy concerns, regulatory requirements, and preference changes, where traditional methods fail.", "method": "Proposes UnlearnRec with an Influence Encoder that updates model parameters directly for unlearning, minimizing fine-tuning and avoiding retraining.", "result": "Achieves exceptional unlearning effectiveness with a 10x speedup over retraining, preserving model performance.", "conclusion": "UnlearnRec provides a scalable and efficient solution for unlearning in recommender systems, outperforming traditional methods."}}
{"id": "2503.13366", "pdf": "https://arxiv.org/pdf/2503.13366", "abs": "https://arxiv.org/abs/2503.13366", "authors": ["Ricardo N. Ferreira", "Cl\u00e1udia Soares"], "title": "Optimal Bounds for Adversarial Constrained Online Convex Optimization", "categories": ["cs.LG", "cs.DS", "math.OC", "stat.ML"], "comment": "This manuscript has been withdrawn due to an error in the Regret\n  Decomposition Inequality in Eq.(10)", "summary": "Constrained Online Convex Optimization (COCO) can be seen as a generalization\nof the standard Online Convex Optimization (OCO) framework. At each round, a\ncost function and constraint function are revealed after a learner chooses an\naction. The goal is to minimize both the regret and cumulative constraint\nviolation (CCV) against an adaptive adversary. We show for the first time that\nis possible to obtain the optimal $O(\\sqrt{T})$ bound on both regret and CCV,\nimproving the best known bounds of $O \\left( \\sqrt{T} \\right)$ and $\\tilde{O}\n\\left( \\sqrt{T} \\right)$ for the regret and CCV, respectively. Based on a new\nsurrogate loss function enforcing a minimum penalty on the constraint function,\nwe demonstrate that both the Follow-the-Regularized-Leader and the Online\nGradient Descent achieve the optimal bounds.", "AI": {"tldr": "The paper introduces an optimal $O(\\sqrt{T})$ bound for both regret and cumulative constraint violation in COCO, improving prior results.", "motivation": "To generalize the OCO framework by addressing both regret and constraint violation optimally.", "method": "Uses a new surrogate loss function with minimum penalty on constraints, applied to Follow-the-Regularized-Leader and Online Gradient Descent.", "result": "Achieves optimal $O(\\sqrt{T})$ bounds for regret and CCV.", "conclusion": "Demonstrates that optimal performance in COCO is achievable with the proposed surrogate loss."}}
{"id": "2505.20688", "pdf": "https://arxiv.org/pdf/2505.20688", "abs": "https://arxiv.org/abs/2505.20688", "authors": ["Taehyo Kim", "Qiran Jia", "Mony J. de Leon", "Hai Shu"], "title": "A False Discovery Rate Control Method Using a Fully Connected Hidden Markov Random Field for Neuroimaging Data", "categories": ["stat.ML", "cs.CV", "cs.LG", "stat.ME"], "comment": null, "summary": "False discovery rate (FDR) control methods are essential for voxel-wise\nmultiple testing in neuroimaging data analysis, where hundreds of thousands or\neven millions of tests are conducted to detect brain regions associated with\ndisease-related changes. Classical FDR control methods (e.g., BH, q-value, and\nLocalFDR) assume independence among tests and often lead to high false\nnon-discovery rates (FNR). Although various spatial FDR control methods have\nbeen developed to improve power, they still fall short of jointly addressing\nthree major challenges in neuroimaging applications: capturing complex spatial\ndependencies, maintaining low variability in both false discovery proportion\n(FDP) and false non-discovery proportion (FNP) across replications, and\nachieving computational scalability for high-resolution data. To address these\nchallenges, we propose fcHMRF-LIS, a powerful, stable, and scalable spatial FDR\ncontrol method for voxel-wise multiple testing. It integrates the local index\nof significance (LIS)-based testing procedure with a novel fully connected\nhidden Markov random field (fcHMRF) designed to model complex spatial\nstructures using a parsimonious parameterization. We develop an efficient\nexpectation-maximization algorithm incorporating mean-field approximation, the\nConditional Random Fields as Recurrent Neural Networks (CRF-RNN) technique, and\npermutohedral lattice filtering, reducing the time complexity from quadratic to\nlinear in the number of tests. Extensive simulations demonstrate that\nfcHMRF-LIS achieves accurate FDR control, lower FNR, reduced variability in FDP\nand FNP, and a higher number of true positives compared to existing methods.\nApplied to an FDG-PET dataset from the Alzheimer's Disease Neuroimaging\nInitiative, fcHMRF-LIS identifies neurobiologically relevant brain regions and\noffers notable advantages in computational efficiency.", "AI": {"tldr": "Proposes fcHMRF-LIS, a spatial FDR control method for neuroimaging, addressing dependencies, stability, and scalability.", "motivation": "Classical FDR methods fail in neuroimaging due to spatial dependencies, high FNR, and computational inefficiency.", "method": "Integrates LIS-based testing with fcHMRF for spatial modeling, using efficient EM algorithms and CRF-RNN.", "result": "Achieves accurate FDR control, lower FNR, stable FDP/FNP, and higher true positives in simulations and real data.", "conclusion": "fcHMRF-LIS outperforms existing methods in power, stability, and scalability for neuroimaging FDR control."}}
{"id": "2505.22660", "pdf": "https://arxiv.org/pdf/2505.22660", "abs": "https://arxiv.org/abs/2505.22660", "authors": ["Mihir Prabhudesai", "Lili Chen", "Alex Ippoliti", "Katerina Fragkiadaki", "Hao Liu", "Deepak Pathak"], "title": "Maximizing Confidence Alone Improves Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": "Website: https://rent-rl.github.io/", "summary": "Reinforcement learning (RL) has enabled machine learning models to achieve\nsignificant advances in many fields. Most recently, RL has empowered frontier\nlanguage models to solve challenging math, science, and coding problems.\nHowever, central to any RL algorithm is the reward function, and reward\nengineering is a notoriously difficult problem in any domain. In this paper, we\npropose RENT: Reinforcement Learning via Entropy Minimization -- a fully\nunsupervised RL method that requires no external reward or ground-truth\nanswers, and instead uses the model's entropy of its underlying distribution as\nan intrinsic reward. We find that by reinforcing the chains of thought that\nyield high model confidence on its generated answers, the model improves its\nreasoning ability. In our experiments, we showcase these improvements on an\nextensive suite of commonly-used reasoning benchmarks, including GSM8K,\nMATH500, AMC, AIME, and GPQA, and models of varying sizes from the Qwen and\nMistral families. The generality of our unsupervised learning method lends\nitself to applicability in a wide range of domains where external supervision\nis unavailable.", "AI": {"tldr": "RENT is an unsupervised RL method using entropy minimization as intrinsic reward, improving reasoning without external rewards.", "motivation": "Reward engineering in RL is challenging; RENT avoids external rewards by using model entropy for intrinsic motivation.", "method": "RENT uses entropy minimization of the model's distribution as intrinsic reward to reinforce high-confidence reasoning.", "result": "Improves reasoning on benchmarks like GSM8K, MATH500, and others across Qwen and Mistral model families.", "conclusion": "RENT's unsupervised approach is broadly applicable where external supervision is lacking."}}
{"id": "2503.15578", "pdf": "https://arxiv.org/pdf/2503.15578", "abs": "https://arxiv.org/abs/2503.15578", "authors": ["Jiexia Ye", "Weiqi Zhang", "Ziyue Li", "Jia Li", "Fugee Tsung"], "title": "Sparseformer: a Transferable Transformer with Multi-granularity Token Sparsification for Medical Time Series Classification", "categories": ["cs.LG"], "comment": "3 figures, 16 pages, 5 tables", "summary": "Medical time series (MedTS) classification is crucial for improved diagnosis\nin healthcare, and yet it is challenging due to the varying granularity of\npatterns, intricate inter-channel correlation, information redundancy, and\nlabel scarcity. While existing transformer-based models have shown promise in\ntime series analysis, they mainly focus on forecasting and fail to fully\nexploit the distinctive characteristics of MedTS data. In this paper, we\nintroduce Sparseformer, a transformer specifically designed for MedTS\nclassification. We propose a sparse token-based dual-attention mechanism that\nenables global modeling and token compression, allowing dynamic focus on the\nmost informative tokens while distilling redundant features. This mechanism is\nthen applied to the multi-granularity, cross-channel encoding of medical\nsignals, capturing intra- and inter-granularity correlations and inter-channel\nconnections. The sparsification design allows our model to handle heterogeneous\ninputs of varying lengths and channels directly. Further, we introduce an\nadaptive label encoder to address label space misalignment across datasets,\nequipping our model with cross-dataset transferability to alleviate the medical\nlabel scarcity issue. Our model outperforms 12 baselines across seven medical\ndatasets under supervised learning. In the few-shot learning experiments, our\nmodel also achieves superior average results. In addition, the in-domain and\ncross-domain experiments among three diagnostic scenarios demonstrate our\nmodel's zero-shot learning capability. Collectively, these findings underscore\nthe robustness and transferability of our model in various medical\napplications.", "AI": {"tldr": "Sparseformer, a transformer for MedTS classification, uses sparse token-based dual-attention and adaptive label encoding to outperform baselines and address label scarcity.", "motivation": "Existing transformer models for time series analysis focus on forecasting and don't fully exploit MedTS data characteristics like varying granularity and label scarcity.", "method": "Proposes Sparseformer with a sparse token-based dual-attention mechanism for global modeling and token compression, plus adaptive label encoding for cross-dataset transferability.", "result": "Outperforms 12 baselines across seven datasets, excels in few-shot learning, and demonstrates zero-shot learning in cross-domain experiments.", "conclusion": "Sparseformer is robust and transferable, addressing key challenges in MedTS classification."}}
{"id": "2504.02298", "pdf": "https://arxiv.org/pdf/2504.02298", "abs": "https://arxiv.org/abs/2504.02298", "authors": ["Xinyu Luo", "Kecheng Chen", "Pao-Sheng Vincent Sun", "Chris Xing Tian", "Arindam Basu", "Haoliang Li"], "title": "SPACE: SPike-Aware Consistency Enhancement for Test-Time Adaptation in Spiking Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Spiking Neural Networks (SNNs), as a biologically plausible alternative to\nArtificial Neural Networks (ANNs), have demonstrated advantages in terms of\nenergy efficiency, temporal processing, and biological plausibility. However,\nSNNs are highly sensitive to distribution shifts, which can significantly\ndegrade their performance in real-world scenarios. Traditional test-time\nadaptation (TTA) methods designed for ANNs often fail to address the unique\ncomputational dynamics of SNNs, such as sparsity and temporal spiking behavior.\nTo address these challenges, we propose SPike-Aware Consistency Enhancement\n(SPACE), the first source-free and single-instance TTA method specifically\ndesigned for SNNs. SPACE leverages the inherent spike dynamics of SNNs to\nmaximize the consistency of spike-behavior-based local feature maps across\naugmented versions of a single test sample, enabling robust adaptation without\nrequiring source data. We evaluate SPACE on multiple datasets. Furthermore,\nSPACE exhibits robust generalization across diverse network architectures,\nconsistently enhancing the performance of SNNs on CNNs (such as VGG and\nResNet), Transformer models, and ConvLSTM architectures. Experimental results\nshow that SPACE outperforms state-of-the-art methods, highlighting its\neffectiveness and robustness in real-world settings.", "AI": {"tldr": "SPACE is a novel test-time adaptation method for SNNs, leveraging spike dynamics for robust performance without source data.", "motivation": "SNNs are sensitive to distribution shifts, and existing TTA methods for ANNs fail to address SNNs' unique dynamics.", "method": "SPACE maximizes consistency of spike-behavior-based local feature maps across augmented test samples.", "result": "SPACE outperforms state-of-the-art methods across various architectures (VGG, ResNet, Transformer, ConvLSTM).", "conclusion": "SPACE is effective and robust for real-world SNN applications."}}
{"id": "2505.05034", "pdf": "https://arxiv.org/pdf/2505.05034", "abs": "https://arxiv.org/abs/2505.05034", "authors": ["Wei Chen", "Shigui Li", "Jiacheng Li", "Junmei Yang", "John Paisley", "Delu Zeng"], "title": "Dequantified Diffusion-Schr{\u00f6}dinger Bridge for Density Ratio Estimation", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Density ratio estimation is fundamental to tasks involving f-divergences, yet\nexisting methods often fail under significantly different distributions or\ninadequately overlapping supports -- the density-chasm and the support-chasm\nproblems. Additionally, prior approaches yield divergent time scores near\nboundaries, leading to instability. We design $\\textbf{D}^3\\textbf{RE}$, a\nunified framework for robust, stable and efficient density ratio estimation. We\npropose the dequantified diffusion bridge interpolant (DDBI), which expands\nsupport coverage and stabilizes time scores via diffusion bridges and Gaussian\ndequantization. Building on DDBI, the proposed dequantified Schr{\\\"o}dinger\nbridge interpolant (DSBI) incorporates optimal transport to solve the\nSchr{\\\"o}dinger bridge problem, enhancing accuracy and efficiency. Our method\noffers uniform approximation and bounded time scores in theory, and outperforms\nbaselines empirically in mutual information and density estimation tasks.", "AI": {"tldr": "A unified framework, D3RE, is proposed for robust and stable density ratio estimation, addressing challenges like distribution divergence and support gaps. It introduces DDBI and DSBI for improved accuracy and efficiency.", "motivation": "Existing methods for density ratio estimation struggle with significantly different distributions, inadequate support overlap, and unstable time scores near boundaries.", "method": "The paper introduces D3RE, leveraging dequantified diffusion bridge interpolant (DDBI) for support expansion and stability, and dequantified Schr\u00f6dinger bridge interpolant (DSBI) for optimal transport and enhanced accuracy.", "result": "The method provides uniform approximation, bounded time scores, and outperforms baselines in mutual information and density estimation tasks.", "conclusion": "D3RE offers a robust, stable, and efficient solution for density ratio estimation, addressing key limitations of prior approaches."}}
{"id": "2505.10438", "pdf": "https://arxiv.org/pdf/2505.10438", "abs": "https://arxiv.org/abs/2505.10438", "authors": ["David Grasev"], "title": "Identification and Optimal Nonlinear Control of Turbojet Engine Using Koopman Eigenfunction Model", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "38 pages, 28 figures", "summary": "Gas turbine engines represent complex highly nonlinear dynamical systems.\nDeriving their physics-based models can be challenging as it requires\nperformance characteristics, that are not always available, and one often has\nto make many simplifying assumptions. In this paper, the limitations of\nconventional experimental methods used to derive component-level and locally\nlinear parameter-varying models are discussed and addressed by employing\nidentification techniques based on data collected from standard engine\noperation under closed-loop control. The rotor dynamics were estimated using\nthe sparse identification of nonlinear dynamics. Subsequently, the autonomous\npart of the dynamics was mapped into an optimally constructed Koopman\neigenfunction space. The process included eigenvalue optimization using\nmetaheuristic algorithms and temporal projection, followed by gradient-based\neigenfunction identification. The resulting Koopman model was validated against\nan in-house reference component-level model. A globally optimal nonlinear\nfeedback controller and a Kalman estimator were then designed in the\neigenfunction space and compared to the classical and gain-scheduled\nproportional-integral controllers, as well as a proposed internal model control\napproach. The eigenmode structure allowed targeting individual modes during the\noptimization process, resulting in a better performance tuning. The results\nshowed that the Koopman-based controller outperformed the other benchmark\ncontrollers in both reference tracking and disturbance rejection, under\nsea-level and varying flight conditions, due to its global nature.", "AI": {"tldr": "The paper proposes data-driven techniques to model gas turbine engines, using Koopman eigenfunction space for improved control performance.", "motivation": "Physics-based modeling of gas turbine engines is challenging due to unavailable performance data and simplifying assumptions. Conventional methods have limitations.", "method": "Employed sparse identification of nonlinear dynamics and mapped dynamics into Koopman eigenfunction space using metaheuristic and gradient-based optimization. Validated against a reference model.", "result": "The Koopman-based controller outperformed classical and gain-scheduled controllers in tracking and disturbance rejection under various conditions.", "conclusion": "Data-driven Koopman modeling offers superior control performance for gas turbine engines, addressing limitations of traditional methods."}}
{"id": "2505.11461", "pdf": "https://arxiv.org/pdf/2505.11461", "abs": "https://arxiv.org/abs/2505.11461", "authors": ["Wesley A Suttle", "Vipul K Sharma", "Brian M Sadler"], "title": "Signal attenuation enables scalable decentralized multi-agent reinforcement learning over networks", "categories": ["cs.LG"], "comment": "10 pages, 1 figure", "summary": "Multi-agent reinforcement learning (MARL) methods typically require that\nagents enjoy global state observability, preventing development of\ndecentralized algorithms and limiting scalability. Recent work has shown that,\nunder assumptions on decaying inter-agent influence, global observability can\nbe replaced by local neighborhood observability at each agent, enabling\ndecentralization and scalability. Real-world applications enjoying such decay\nproperties remain underexplored, however, despite the fact that signal power\ndecay, or signal attenuation, due to path loss is an intrinsic feature of many\nproblems in wireless communications and radar networks. In this paper, we show\nthat signal attenuation enables decentralization in MARL by considering the\nillustrative special case of performing power allocation for target detection\nin a radar network. To achieve this, we propose two new constrained multi-agent\nMarkov decision process formulations of this power allocation problem, derive\nlocal neighborhood approximations for global value function and policy gradient\nestimates and establish corresponding error bounds, and develop decentralized\nsaddle point policy gradient algorithms for solving the proposed problems. Our\napproach, though oriented towards the specific radar network problem we\nconsider, provides a useful model for extensions to additional problems in\nwireless communications and radar networks.", "AI": {"tldr": "The paper explores how signal attenuation in wireless and radar networks enables decentralized multi-agent reinforcement learning (MARL) by replacing global observability with local neighborhood observability. It focuses on power allocation for target detection in radar networks, proposing new MARL formulations and decentralized algorithms.", "motivation": "Global state observability in MARL limits decentralization and scalability. Signal attenuation in wireless and radar networks offers a natural way to enable local observability, addressing this limitation.", "method": "The paper introduces two constrained multi-agent Markov decision process formulations for power allocation in radar networks. It derives local approximations for global value functions and policy gradients, with error bounds, and develops decentralized saddle point policy gradient algorithms.", "result": "The proposed approach successfully decentralizes MARL for power allocation in radar networks, leveraging signal attenuation. The derived error bounds validate the local approximations.", "conclusion": "Signal attenuation enables decentralized MARL, as demonstrated in radar networks. The framework is extendable to other wireless and radar applications."}}
{"id": "2505.12147", "pdf": "https://arxiv.org/pdf/2505.12147", "abs": "https://arxiv.org/abs/2505.12147", "authors": ["Nikolaos-Lysias Kosioris", "Sotirios Nikoletseas", "Gavrilis Filios", "Stefanos Panagiotou"], "title": "Causal Machine Learning in IoT-based Engineering Problems: A Tool Comparison in the Case of Household Energy Consumption", "categories": ["cs.LG"], "comment": null, "summary": "The rapid increase in computing power and the ability to store Big Data in\nthe infrastructure has enabled predictions in a large variety of domains by\nMachine Learning. However, in many cases, existing Machine Learning tools are\nconsidered insufficient or incorrect since they exploit only probabilistic\ndependencies rather than inference logic. Causal Machine Learning methods seem\nto close this gap. In this paper, two prevalent tools based on Causal Machine\nLearning methods are compared, as well as their mathematical underpinning\nbackground. The operation of the tools is demonstrated by examining their\nresponse to 18 queries, based on the IDEAL Household Energy Dataset, published\nby the University of Edinburgh. First, it was important to evaluate the causal\nrelations assumption that allowed the use of this approach; this was based on\nthe preexisting scientific knowledge of the domain and was implemented by use\nof the in-built validation tools. Results were encouraging and may easily be\nextended to other domains.", "AI": {"tldr": "The paper compares two causal machine learning tools, evaluating their performance on 18 queries using the IDEAL Household Energy Dataset, and finds promising results.", "motivation": "Existing machine learning tools often rely on probabilistic dependencies rather than causal inference, creating a gap that causal machine learning aims to address.", "method": "The study compares two causal machine learning tools, assessing their mathematical foundations and performance on 18 queries using the IDEAL dataset. Causal assumptions were validated using domain knowledge and built-in tools.", "result": "The results were encouraging, demonstrating the tools' effectiveness in causal inference, with potential applicability to other domains.", "conclusion": "Causal machine learning tools show promise in addressing the limitations of traditional methods, with validated results suggesting broader utility."}}
{"id": "2505.12204", "pdf": "https://arxiv.org/pdf/2505.12204", "abs": "https://arxiv.org/abs/2505.12204", "authors": ["Shuo Han", "German Espinosa", "Junda Huang", "Daniel A. Dombeck", "Malcolm A. MacIver", "Bradly C. Stadie"], "title": "Of Mice and Machines: A Comparison of Learning Between Real World Mice and RL Agents", "categories": ["cs.LG", "q-bio.NC"], "comment": "19 pages, ICML 2025", "summary": "Recent advances in reinforcement learning (RL) have demonstrated impressive\ncapabilities in complex decision-making tasks. This progress raises a natural\nquestion: how do these artificial systems compare to biological agents, which\nhave been shaped by millions of years of evolution? To help answer this\nquestion, we undertake a comparative study of biological mice and RL agents in\na predator-avoidance maze environment. Through this analysis, we identify a\nstriking disparity: RL agents consistently demonstrate a lack of\nself-preservation instinct, readily risking ``death'' for marginal efficiency\ngains. These risk-taking strategies are in contrast to biological agents, which\nexhibit sophisticated risk-assessment and avoidance behaviors. Towards bridging\nthis gap between the biological and artificial, we propose two novel mechanisms\nthat encourage more naturalistic risk-avoidance behaviors in RL agents. Our\napproach leads to the emergence of naturalistic behaviors, including strategic\nenvironment assessment, cautious path planning, and predator avoidance patterns\nthat closely mirror those observed in biological systems.", "AI": {"tldr": "A study compares RL agents and biological mice in predator-avoidance tasks, revealing RL agents' lack of self-preservation. Novel mechanisms are proposed to bridge this gap, resulting in more naturalistic behaviors.", "motivation": "To compare artificial RL agents with biological systems (mice) in decision-making and understand disparities in risk-taking behaviors.", "method": "Comparative study of mice and RL agents in a predator-avoidance maze, followed by proposing two new mechanisms for RL agents.", "result": "RL agents lack self-preservation instincts, unlike mice. Proposed mechanisms enable RL agents to mimic naturalistic risk-avoidance behaviors.", "conclusion": "The study highlights a gap between artificial and biological decision-making and offers solutions to align RL behaviors with biological systems."}}
{"id": "2505.13510", "pdf": "https://arxiv.org/pdf/2505.13510", "abs": "https://arxiv.org/abs/2505.13510", "authors": ["Conor Rowan", "Alireza Doostan"], "title": "On the definition and importance of interpretability in scientific machine learning", "categories": ["cs.LG", "physics.data-an", "physics.hist-ph", "physics.soc-ph"], "comment": null, "summary": "Though neural networks trained on large datasets have been successfully used\nto describe and predict many physical phenomena, there is a sense among\nscientists that, unlike traditional scientific models comprising simple\nmathematical expressions, their findings cannot be integrated into the body of\nscientific knowledge. Critics of machine learning's inability to produce\nhuman-understandable relationships have converged on the concept of\n\"interpretability\" as its point of departure from more traditional forms of\nscience. As the growing interest in interpretability has shown, researchers in\nthe physical sciences seek not just predictive models, but also to uncover the\nfundamental principles that govern a system of interest. However, clarity\naround a definition of interpretability and the precise role that it plays in\nscience is lacking in the literature. In this work, we argue that researchers\nin equation discovery and symbolic regression tend to conflate the concept of\nsparsity with interpretability. We review key papers on interpretable machine\nlearning from outside the scientific community and argue that, though the\ndefinitions and methods they propose can inform questions of interpretability\nfor scientific machine learning (SciML), they are inadequate for this new\npurpose. Noting these deficiencies, we propose an operational definition of\ninterpretability for the physical sciences. Our notion of interpretability\nemphasizes understanding of the mechanism over mathematical sparsity. Innocuous\nthough it may seem, this emphasis on mechanism shows that sparsity is often\nunnecessary. It also questions the possibility of interpretable scientific\ndiscovery when prior knowledge is lacking. We believe a precise and\nphilosophically informed definition of interpretability in SciML will help\nfocus research efforts toward the most significant obstacles to realizing a\ndata-driven scientific future.", "AI": {"tldr": "The paper critiques the conflation of sparsity with interpretability in scientific machine learning (SciML) and proposes a mechanism-focused definition of interpretability for the physical sciences.", "motivation": "Researchers seek interpretable models to uncover fundamental principles, but current definitions and methods from general machine learning are inadequate for SciML.", "method": "The paper reviews interpretable ML literature, identifies deficiencies, and proposes a new operational definition of interpretability emphasizing mechanistic understanding.", "result": "Sparsity is often unnecessary for interpretability, and interpretable discovery may be limited without prior knowledge.", "conclusion": "A precise, philosophically informed definition of interpretability in SciML can guide research toward overcoming key obstacles in data-driven science."}}
{"id": "2505.14669", "pdf": "https://arxiv.org/pdf/2505.14669", "abs": "https://arxiv.org/abs/2505.14669", "authors": ["Roberto L. Castro", "Andrei Panferov", "Soroush Tabesh", "Oliver Sieberling", "Jiale Chen", "Mahdi Nikdan", "Saleh Ashkboos", "Dan Alistarh"], "title": "Quartet: Native FP4 Training Can Be Optimal for Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Training large language models (LLMs) models directly in low-precision offers\na way to address computational costs by improving both throughput and energy\nefficiency. For those purposes, NVIDIA's recent Blackwell architecture\nfacilitates very low-precision operations using FP4 variants. Yet, current\nalgorithms for training LLMs in FP4 precision face significant accuracy\ndegradation and often rely on mixed-precision fallbacks. In this paper, we\ninvestigate hardware-supported FP4 training and introduce a new approach for\naccurate, end-to-end FP4 training with all the major computations (i.e., linear\nlayers) in low precision. Through extensive evaluations on Llama-type models,\nwe reveal a new low-precision scaling law that quantifies performance\ntrade-offs across bit-widths and training setups. Guided by this investigation,\nwe design an \"optimal\" technique in terms of accuracy-vs-computation, called\nQuartet. We implement Quartet using optimized CUDA kernels tailored for\nBlackwell, demonstrating that fully FP4-based training is a competitive\nalternative to FP16 half-precision and to FP8 training. Our code is available\nat https://github.com/IST-DASLab/Quartet.", "AI": {"tldr": "The paper introduces Quartet, a method for accurate FP4 training of LLMs, addressing computational costs and accuracy degradation, and demonstrates its competitiveness with FP16 and FP8 training.", "motivation": "To reduce computational costs and improve efficiency in training large language models (LLMs) by enabling accurate low-precision (FP4) training without relying on mixed-precision fallbacks.", "method": "The authors investigate hardware-supported FP4 training, introduce a new low-precision scaling law, and design Quartet, an optimized technique for FP4 training with tailored CUDA kernels for NVIDIA's Blackwell architecture.", "result": "Quartet achieves competitive accuracy and efficiency compared to FP16 and FP8 training, validated through evaluations on Llama-type models.", "conclusion": "Fully FP4-based training with Quartet is a viable and efficient alternative to higher-precision methods, offering significant computational savings."}}
{"id": "2505.16403", "pdf": "https://arxiv.org/pdf/2505.16403", "abs": "https://arxiv.org/abs/2505.16403", "authors": ["Huazi Pan", "Yanjun Zhang", "Leo Yu Zhang", "Scott Adams", "Abbas Kouzani", "Suiyang Khoo"], "title": "Performance Guaranteed Poisoning Attacks in Federated Learning: A Sliding Mode Approach", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "This paper is to appear in IJCAI 2025, code available at:\n  https://github.com/Halsey777/FedSA", "summary": "Manipulation of local training data and local updates, i.e., the poisoning\nattack, is the main threat arising from the collaborative nature of the\nfederated learning (FL) paradigm. Most existing poisoning attacks aim to\nmanipulate local data/models in a way that causes denial-of-service (DoS)\nissues. In this paper, we introduce a novel attack method, named Federated\nLearning Sliding Attack (FedSA) scheme, aiming at precisely introducing the\nextent of poisoning in a subtle controlled manner. It operates with a\npredefined objective, such as reducing global model's prediction accuracy by\n10%. FedSA integrates robust nonlinear control-Sliding Mode Control (SMC)\ntheory with model poisoning attacks. It can manipulate the updates from\nmalicious clients to drive the global model towards a compromised state,\nachieving this at a controlled and inconspicuous rate. Additionally, leveraging\nthe robust control properties of FedSA allows precise control over the\nconvergence bounds, enabling the attacker to set the global accuracy of the\npoisoned model to any desired level. Experimental results demonstrate that\nFedSA can accurately achieve a predefined global accuracy with fewer malicious\nclients while maintaining a high level of stealth and adjustable learning\nrates.", "AI": {"tldr": "FedSA is a novel poisoning attack in federated learning that uses Sliding Mode Control to precisely manipulate model updates, achieving controlled accuracy reduction with stealth.", "motivation": "Addressing the threat of poisoning attacks in federated learning, FedSA aims to introduce subtle, controlled poisoning to avoid detection while achieving specific accuracy reduction goals.", "method": "FedSA integrates Sliding Mode Control (SMC) theory with model poisoning attacks, manipulating updates from malicious clients to drive the global model to a compromised state at a controlled rate.", "result": "FedSA accurately achieves predefined global accuracy reduction with fewer malicious clients, maintaining stealth and adjustable learning rates.", "conclusion": "FedSA demonstrates effective, controlled poisoning in federated learning, offering attackers precise manipulation of model accuracy while remaining inconspicuous."}}
{"id": "2505.17365", "pdf": "https://arxiv.org/pdf/2505.17365", "abs": "https://arxiv.org/abs/2505.17365", "authors": ["Rohan Ghuge", "Vidya Muthukumar", "Sahil Singla"], "title": "Improved and Oracle-Efficient Online $\\ell_1$-Multicalibration", "categories": ["cs.LG", "cs.DS"], "comment": "Accepted to ICML 2025", "summary": "We study \\emph{online multicalibration}, a framework for ensuring calibrated\npredictions across multiple groups in adversarial settings, across $T$ rounds.\nAlthough online calibration is typically studied in the $\\ell_1$ norm, prior\napproaches to online multicalibration have taken the indirect approach of\nobtaining rates in other norms (such as $\\ell_2$ and $\\ell_{\\infty}$) and then\ntransferred these guarantees to $\\ell_1$ at additional loss. In contrast, we\npropose a direct method that achieves improved and oracle-efficient rates of\n$\\widetilde{\\mathcal{O}}(T^{-1/3})$ and $\\widetilde{\\mathcal{O}}(T^{-1/4})$\nrespectively, for online $\\ell_1$-multicalibration. Our key insight is a novel\nreduction of online \\(\\ell_1\\)-multicalibration to an online learning problem\nwith product-based rewards, which we refer to as \\emph{online linear-product\noptimization} ($\\mathtt{OLPO}$).\n  To obtain the improved rate of $\\widetilde{\\mathcal{O}}(T^{-1/3})$, we\nintroduce a linearization of $\\mathtt{OLPO}$ and design a no-regret algorithm\nfor this linearized problem. Although this method guarantees the desired\nsublinear rate (nearly matching the best rate for online calibration), it is\ncomputationally expensive when the group family \\(\\mathcal{H}\\) is large or\ninfinite, since it enumerates all possible groups. To address scalability, we\npropose a second approach to $\\mathtt{OLPO}$ that makes only a polynomial\nnumber of calls to an offline optimization (\\emph{multicalibration evaluation})\noracle, resulting in \\emph{oracle-efficient} online \\(\\ell_1\\)-multicalibration\nwith a rate of $\\widetilde{\\mathcal{O}}(T^{-1/4})$. Our framework also extends\nto certain infinite families of groups (e.g., all linear functions on the\ncontext space) by exploiting a $1$-Lipschitz property of the\n\\(\\ell_1\\)-multicalibration error with respect to \\(\\mathcal{H}\\).", "AI": {"tldr": "The paper introduces a direct method for online multicalibration, achieving improved rates in the \u2113\u2081 norm via a novel reduction to online linear-product optimization (OLPO). Two approaches are proposed: one for better rates but computational expense, and another for scalability with oracle efficiency.", "motivation": "Prior methods for online multicalibration relied on indirect approaches with suboptimal rates in the \u2113\u2081 norm. This work aims to provide direct, improved, and scalable solutions.", "method": "The authors reduce \u2113\u2081-multicalibration to OLPO, proposing two algorithms: one for optimal rates (but computationally expensive) and another for oracle efficiency.", "result": "Improved rates of O\u0303(T\u207b\u00b9/\u00b3) and O\u0303(T\u207b\u00b9/\u2074) are achieved for \u2113\u2081-multicalibration, with scalability for large or infinite group families.", "conclusion": "The framework advances online multicalibration with direct, efficient methods, extending to infinite group families via Lipschitz properties."}}
{"id": "2505.18447", "pdf": "https://arxiv.org/pdf/2505.18447", "abs": "https://arxiv.org/abs/2505.18447", "authors": ["Chi Zhang", "Ziying Jia", "George K. Atia", "Sihong He", "Yue Wang"], "title": "Pessimism Principle Can Be Effective: Towards a Framework for Zero-Shot Transfer Reinforcement Learning", "categories": ["cs.LG"], "comment": "Accepted to ICML 2025", "summary": "Transfer reinforcement learning aims to derive a near-optimal policy for a\ntarget environment with limited data by leveraging abundant data from related\nsource domains. However, it faces two key challenges: the lack of performance\nguarantees for the transferred policy, which can lead to undesired actions, and\nthe risk of negative transfer when multiple source domains are involved. We\npropose a novel framework based on the pessimism principle, which constructs\nand optimizes a conservative estimation of the target domain's performance. Our\nframework effectively addresses the two challenges by providing an optimized\nlower bound on target performance, ensuring safe and reliable decisions, and by\nexhibiting monotonic improvement with respect to the quality of the source\ndomains, thereby avoiding negative transfer. We construct two types of\nconservative estimations, rigorously characterize their effectiveness, and\ndevelop efficient distributed algorithms with convergence guarantees. Our\nframework provides a theoretically sound and practically robust solution for\ntransfer learning in reinforcement learning.", "AI": {"tldr": "A novel pessimistic framework for transfer reinforcement learning ensures safe decisions and avoids negative transfer by optimizing a conservative performance bound.", "motivation": "Address the lack of performance guarantees and risk of negative transfer in transfer reinforcement learning.", "method": "Proposes a framework based on pessimism, constructing and optimizing conservative performance estimations for the target domain.", "result": "Provides a lower bound on target performance, ensures safe decisions, and avoids negative transfer with monotonic improvement.", "conclusion": "The framework offers a theoretically sound and robust solution for transfer learning in reinforcement learning."}}
{"id": "2505.20034", "pdf": "https://arxiv.org/pdf/2505.20034", "abs": "https://arxiv.org/abs/2505.20034", "authors": ["Juwei Yue", "Haikuo Li", "Jiawei Sheng", "Yihan Guo", "Xinghua Zhang", "Chuan Zhou", "Tingwen Liu", "Li Guo"], "title": "Graph Wave Networks", "categories": ["cs.LG"], "comment": "15 pages, 8 figures, published to WWW 2025", "summary": "Dynamics modeling has been introduced as a novel paradigm in message passing\n(MP) of graph neural networks (GNNs). Existing methods consider MP between\nnodes as a heat diffusion process, and leverage heat equation to model the\ntemporal evolution of nodes in the embedding space. However, heat equation can\nhardly depict the wave nature of graph signals in graph signal processing.\nBesides, heat equation is essentially a partial differential equation (PDE)\ninvolving a first partial derivative of time, whose numerical solution usually\nhas low stability, and leads to inefficient model training. In this paper, we\nwould like to depict more wave details in MP, since graph signals are\nessentially wave signals that can be seen as a superposition of a series of\nwaves in the form of eigenvector. This motivates us to consider MP as a wave\npropagation process to capture the temporal evolution of wave signals in the\nspace. Based on wave equation in physics, we innovatively develop a graph wave\nequation to leverage the wave propagation on graphs. In details, we demonstrate\nthat the graph wave equation can be connected to traditional spectral GNNs,\nfacilitating the design of graph wave networks based on various Laplacians and\nenhancing the performance of the spectral GNNs. Besides, the graph wave\nequation is particularly a PDE involving a second partial derivative of time,\nwhich has stronger stability on graphs than the heat equation that involves a\nfirst partial derivative of time. Additionally, we theoretically prove that the\nnumerical solution derived from the graph wave equation are constantly stable,\nenabling to significantly enhance model efficiency while ensuring its\nperformance. Extensive experiments show that GWNs achieve SOTA and efficient\nperformance on benchmark datasets, and exhibit outstanding performance in\naddressing challenging graph problems, such as over-smoothing and heterophily.", "AI": {"tldr": "The paper introduces graph wave networks (GWNs) as a novel approach for message passing in GNNs, replacing heat diffusion with wave propagation for better stability and performance.", "motivation": "Existing methods model message passing as heat diffusion, which fails to capture wave-like graph signals and suffers from instability. The paper aims to leverage wave propagation for more accurate and stable modeling.", "method": "The authors develop a graph wave equation based on physics, connecting it to spectral GNNs. This equation involves second-order time derivatives, ensuring stability and efficiency.", "result": "GWNs achieve state-of-the-art performance on benchmarks, addressing issues like over-smoothing and heterophily, with proven numerical stability.", "conclusion": "The graph wave equation offers a superior alternative to heat diffusion, enhancing GNN performance and efficiency."}}
{"id": "2505.21807", "pdf": "https://arxiv.org/pdf/2505.21807", "abs": "https://arxiv.org/abs/2505.21807", "authors": ["Tommy Xu", "Zhitian Zhang", "Xiangyu Sun", "Lauren Kelly Zung", "Hossein Hajimirsadeghi", "Greg Mori"], "title": "TabReason: A Reinforcement Learning-Enhanced Reasoning LLM for Explainable Tabular Data Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Predictive modeling on tabular data is the cornerstone of many real-world\napplications. Although gradient boosting machines and some recent deep models\nachieve strong performance on tabular data, they often lack interpretability.\nOn the other hand, large language models (LLMs) have demonstrated powerful\ncapabilities to generate human-like reasoning and explanations, but remain\nunder-performed for tabular data prediction. In this paper, we propose a new\napproach that leverages reasoning-based LLMs, trained using reinforcement\nlearning, to perform more accurate and explainable predictions on tabular data.\nOur method introduces custom reward functions that guide the model not only\ntoward high prediction accuracy but also toward human-understandable reasons\nfor its predictions. Experimental results show that our model achieves\npromising performance on financial benchmark datasets, outperforming most\nexisting LLMs.", "AI": {"tldr": "A new approach combines reasoning-based LLMs with reinforcement learning for accurate and explainable tabular data predictions.", "motivation": "Existing models like gradient boosting and deep learning lack interpretability, while LLMs underperform in tabular data prediction.", "method": "Uses reinforcement learning to train LLMs with custom reward functions for accuracy and human-understandable explanations.", "result": "Outperforms most existing LLMs on financial benchmark datasets.", "conclusion": "The proposed method enhances both accuracy and interpretability in tabular data predictions."}}
{"id": "2505.21882", "pdf": "https://arxiv.org/pdf/2505.21882", "abs": "https://arxiv.org/abs/2505.21882", "authors": ["Ruijie Li", "Xiang Zhao", "Qiao Ning", "Shikai Guo"], "title": "HydraNet: Momentum-Driven State Space Duality for Multi-Granularity Tennis Tournaments Analysis", "categories": ["cs.LG"], "comment": "14 pages, 9 figures (including subfigures), 5 tables. The source code\n  and datasets are available at https://github.com/ReyJerry/HydraNet", "summary": "In tennis tournaments, momentum, a critical yet elusive phenomenon, reflects\nthe dynamic shifts in performance of athletes that can decisively influence\nmatch outcomes. Despite its significance, momentum in terms of effective\nmodeling and multi-granularity analysis across points, games, sets, and matches\nin tennis tournaments remains underexplored. In this study, we define a novel\nMomentum Score (MS) metric to quantify a player's momentum level in\nmulti-granularity tennis tournaments, and design HydraNet, a momentum-driven\nstate-space duality-based framework, to model MS by integrating thirty-two\nheterogeneous dimensions of athletes performance in serve, return, psychology\nand fatigue. HydraNet integrates a Hydra module, which builds upon a\nstate-space duality (SSD) framework, capturing explicit momentum with a\nsliding-window mechanism and implicit momentum through cross-game state\npropagation. It also introduces a novel Versus Learning method to better\nenhance the adversarial nature of momentum between the two athletes at a macro\nlevel, along with a Collaborative-Adversarial Attention Mechanism (CAAM) for\ncapturing and integrating intra-player and inter-player dynamic momentum at a\nmicro level. Additionally, we construct a million-level tennis cross-tournament\ndataset spanning from 2012-2023 Wimbledon and 2013-2023 US Open, and validate\nthe multi-granularity modeling capability of HydraNet for the MS metric on this\ndataset. Extensive experimental evaluations demonstrate that the MS metric\nconstructed by the HydraNet framework provides actionable insights into how\nmomentum impacts outcomes at different granularities, establishing a new\nfoundation for momentum modeling and sports analysis. To the best of our\nknowledge, this is the first work to explore and effectively model momentum\nacross multiple granularities in professional tennis tournaments.", "AI": {"tldr": "The paper introduces a Momentum Score (MS) metric and HydraNet framework to model momentum in tennis across points, games, sets, and matches, using multi-dimensional performance data.", "motivation": "Momentum in tennis is crucial but underexplored in terms of modeling and multi-granularity analysis. The study aims to quantify and analyze momentum's impact on match outcomes.", "method": "The authors propose HydraNet, a state-space duality-based framework, integrating 32 performance dimensions. It includes a Hydra module for explicit/implicit momentum, Versus Learning for adversarial momentum, and CAAM for intra/inter-player dynamics.", "result": "HydraNet successfully models MS on a large tennis dataset (2012-2023), showing actionable insights into momentum's impact at various granularities.", "conclusion": "This is the first work to effectively model momentum across multiple granularities in tennis, providing a foundation for future sports analysis."}}
{"id": "2505.21974", "pdf": "https://arxiv.org/pdf/2505.21974", "abs": "https://arxiv.org/abs/2505.21974", "authors": ["Yu-Heng Hung", "Kai-Jie Lin", "Yu-Heng Lin", "Chien-Yi Wang", "Cheng Sun", "Ping-Chun Hsieh"], "title": "BOFormer: Learning to Solve Multi-Objective Bayesian Optimization via Non-Markovian RL", "categories": ["cs.LG"], "comment": "ICLR 2025. Project page and code at\n  https://hungyuheng.github.io/BOFormer/", "summary": "Bayesian optimization (BO) offers an efficient pipeline for optimizing\nblack-box functions with the help of a Gaussian process prior and an\nacquisition function (AF). Recently, in the context of single-objective BO,\nlearning-based AFs witnessed promising empirical results given its favorable\nnon-myopic nature. Despite this, the direct extension of these approaches to\nmulti-objective Bayesian optimization (MOBO) suffer from the\n\\textit{hypervolume identifiability issue}, which results from the\nnon-Markovian nature of MOBO problems. To tackle this, inspired by the\nnon-Markovian RL literature and the success of Transformers in language\nmodeling, we present a generalized deep Q-learning framework and propose\n\\textit{BOFormer}, which substantiates this framework for MOBO via sequence\nmodeling. Through extensive evaluation, we demonstrate that BOFormer constantly\noutperforms the benchmark rule-based and learning-based algorithms in various\nsynthetic MOBO and real-world multi-objective hyperparameter optimization\nproblems. We have made the source code publicly available to encourage further\nresearch in this direction.", "AI": {"tldr": "BOFormer, a Transformer-based deep Q-learning framework, addresses the hypervolume identifiability issue in multi-objective Bayesian optimization, outperforming benchmarks in synthetic and real-world tasks.", "motivation": "Extending learning-based acquisition functions to multi-objective Bayesian optimization (MOBO) faces the hypervolume identifiability issue due to non-Markovian nature.", "method": "Proposes BOFormer, a deep Q-learning framework using sequence modeling (inspired by Transformers) for MOBO.", "result": "BOFormer consistently outperforms rule-based and learning-based benchmarks in synthetic and real-world MOBO tasks.", "conclusion": "BOFormer effectively addresses MOBO challenges, with open-source code to foster further research."}}
{"id": "2308.15651", "pdf": "https://arxiv.org/pdf/2308.15651", "abs": "https://arxiv.org/abs/2308.15651", "authors": ["Hyunsik Yoo", "Zhichen Zeng", "Jian Kang", "Ruizhong Qiu", "David Zhou", "Zhining Liu", "Fei Wang", "Charlie Xu", "Eunice Chan", "Hanghang Tong"], "title": "Ensuring User-side Fairness in Dynamic Recommender Systems", "categories": ["cs.IR", "cs.CY", "cs.LG"], "comment": "20 pages, 20 figures, 2 tables, ACM Web Conference 2024", "summary": "User-side group fairness is crucial for modern recommender systems, aiming to\nalleviate performance disparities among user groups defined by sensitive\nattributes like gender, race, or age. In the ever-evolving landscape of\nuser-item interactions, continual adaptation to newly collected data is crucial\nfor recommender systems to stay aligned with the latest user preferences.\nHowever, we observe that such continual adaptation often exacerbates\nperformance disparities. This necessitates a thorough investigation into\nuser-side fairness in dynamic recommender systems, an area that has been\nunexplored in the literature. This problem is challenging due to distribution\nshifts, frequent model updates, and non-differentiability of ranking metrics.\nTo our knowledge, this paper presents the first principled study on ensuring\nuser-side fairness in dynamic recommender systems. We start with theoretical\nanalyses on fine-tuning v.s. retraining, showing that the best practice is\nincremental fine-tuning with restart. Guided by our theoretical analyses, we\npropose FAir Dynamic rEcommender (FADE), an end-to-end fine-tuning framework to\ndynamically ensure user-side fairness over time. To overcome the\nnon-differentiability of recommendation metrics in the fairness loss, we\nfurther introduce Differentiable Hit (DH) as an improvement over the recent\nNeuralNDCG method, not only alleviating its gradient vanishing issue but also\nachieving higher efficiency. Besides that, we also address the instability\nissue of the fairness loss by leveraging the competing nature between the\nrecommendation loss and the fairness loss. Through extensive experiments on\nreal-world datasets, we demonstrate that FADE effectively and efficiently\nreduces performance disparities with little sacrifice in the overall\nrecommendation performance.", "AI": {"tldr": "The paper introduces FADE, a framework for ensuring user-side fairness in dynamic recommender systems, addressing challenges like distribution shifts and non-differentiable metrics.", "motivation": "To investigate and mitigate performance disparities among user groups in dynamic recommender systems, an unexplored area in literature.", "method": "Proposes FADE, an end-to-end fine-tuning framework, and introduces Differentiable Hit (DH) to handle non-differentiable metrics.", "result": "FADE effectively reduces performance disparities with minimal impact on overall recommendation performance.", "conclusion": "FADE provides a principled solution for maintaining fairness in dynamic recommender systems, validated by real-world experiments."}}
{"id": "2403.13627", "pdf": "https://arxiv.org/pdf/2403.13627", "abs": "https://arxiv.org/abs/2403.13627", "authors": ["Akihiro Fujii", "Anh Khoa Augustin Lu", "Koji Shimizu", "Satoshi Watanabe"], "title": "A Straightforward Gradient-Based Approach for High-Tc Superconductor Design: Leveraging Domain Knowledge via Adaptive Constraints", "categories": ["cond-mat.supr-con", "cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "Materials design aims to discover novel compounds with desired properties.\nHowever, prevailing strategies face critical trade-offs. Conventional\nelement-substitution approaches readily and adaptively incorporate various\ndomain knowledge but remain confined to a narrow search space. In contrast,\ndeep generative models efficiently explore vast compositional landscapes, yet\nthey struggle to flexibly integrate domain knowledge. To address these\ntrade-offs, we propose a gradient-based material design framework that combines\nthese strengths, offering both efficiency and adaptability. In our method,\nchemical compositions are optimised to achieve target properties by using\nproperty prediction models and their gradients. In order to seamlessly enforce\ndiverse constraints, including those reflecting domain insights such as\noxidation states, discretised compositional ratios, types of elements, and\ntheir abundance, we apply masks and employ a special loss function, namely the\ninteger loss. Furthermore, we initialise the optimisation using promising\ncandidates from existing dataset, effectively guiding the search away from\nunfavourable regions and thus helping to avoid poor solutions. Our approach\ndemonstrates a more efficient exploration of superconductor candidates,\nuncovering candidate materials with higher critical temperature than\nconventional element-substitution and generative models. Importantly, it could\npropose new compositions beyond those found in existing databases, including\nnew hydride superconductors absent from the training dataset but which share\ncompositional similarities with materials found in literature. This synergy of\ndomain knowledge and machine-learning-based scalability provides a robust\nfoundation for rapid, adaptive, and comprehensive materials design for\nsuperconductors and beyond.", "AI": {"tldr": "A gradient-based framework combines domain knowledge and deep generative models for efficient and adaptable materials design, outperforming conventional methods in discovering high-critical-temperature superconductors.", "motivation": "Addressing the trade-offs between conventional element-substitution approaches (limited search space) and deep generative models (lack of domain knowledge integration) in materials design.", "method": "Uses gradient-based optimization of chemical compositions with property prediction models, masks, and integer loss to enforce constraints. Initializes optimization with promising candidates from existing datasets.", "result": "Discovers superconductors with higher critical temperatures and proposes new compositions, including hydride superconductors not in training data.", "conclusion": "The framework synergizes domain knowledge and machine learning for rapid, adaptive, and comprehensive materials design."}}
{"id": "2403.17285", "pdf": "https://arxiv.org/pdf/2403.17285", "abs": "https://arxiv.org/abs/2403.17285", "authors": ["Qianglin Wen", "Chengchun Shi", "Ying Yang", "Niansheng Tang", "Hongtu Zhu"], "title": "Unraveling the Interplay between Carryover Effects and Reward Autocorrelations in Switchback Experiments", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "A/B testing has become the gold standard for policy evaluation in modern\ntechnological industries. Motivated by the widespread use of switchback\nexperiments in A/B testing, this paper conducts a comprehensive comparative\nanalysis of various switchback designs in Markovian environments. Unlike many\nexisting works which derive the optimal design based on specific and relatively\nsimple estimators, our analysis covers a range of state-of-the-art estimators\ndeveloped in the reinforcement learning (RL) literature. It reveals that the\neffectiveness of different switchback designs depends crucially on (i) the size\nof the carryover effect and (ii) the auto-correlations among reward errors over\ntime. Meanwhile, these findings are estimator-agnostic, i.e., they apply to\nmost RL estimators. Based on these insights, we provide a workflow to offer\nguidelines for practitioners on designing switchback experiments in A/B\ntesting.", "AI": {"tldr": "The paper compares switchback designs in A/B testing for Markovian environments, highlighting their effectiveness based on carryover effects and reward error auto-correlations, and provides a practical workflow for practitioners.", "motivation": "To address the widespread use of switchback experiments in A/B testing and analyze their effectiveness in Markovian environments, covering diverse RL estimators.", "method": "Conducts a comparative analysis of switchback designs, focusing on carryover effects and reward error auto-correlations, and evaluates state-of-the-art RL estimators.", "result": "Effectiveness of switchback designs depends on carryover effects and reward error auto-correlations, with findings applicable to most RL estimators.", "conclusion": "Provides a workflow for practitioners to design switchback experiments in A/B testing, leveraging insights from the analysis."}}
{"id": "2405.19380", "pdf": "https://arxiv.org/pdf/2405.19380", "abs": "https://arxiv.org/abs/2405.19380", "authors": ["Yeoneung Kim", "Gihun Kim", "Jiwhan Park", "Insoon Yang"], "title": "Approximate Thompson Sampling for Learning Linear Quadratic Regulators with $O(\\sqrt{T})$ Regret", "categories": ["stat.ML", "cs.LG", "cs.SY", "eess.SY"], "comment": "Accepted to be presented at L4DC'25 (Oral)", "summary": "We propose a novel Thompson sampling algorithm that learns linear quadratic\nregulators (LQR) with a Bayesian regret bound of $O(\\sqrt{T})$. Our method\nleverages Langevin dynamics with a carefully designed preconditioner and\nincorporates a simple excitation mechanism. We show that the excitation signal\ndrives the minimum eigenvalue of the preconditioner to grow over time, thereby\naccelerating the approximate posterior sampling process. Furthermore, we\nestablish nontrivial concentration properties of the approximate posteriors\ngenerated by our algorithm. These properties enable us to bound the moments of\nthe system state and attain an $O(\\sqrt{T})$ regret bound without relying on\nthe restrictive assumptions that are often used in the literature.", "AI": {"tldr": "A novel Thompson sampling algorithm for LQR with $O(\\sqrt{T})$ Bayesian regret, using Langevin dynamics and excitation.", "motivation": "To improve regret bounds for LQR without restrictive assumptions.", "method": "Leverages Langevin dynamics with a preconditioner and excitation mechanism.", "result": "Achieves $O(\\sqrt{T})$ regret and shows concentration properties of posteriors.", "conclusion": "The method outperforms existing approaches by relaxing assumptions and accelerating sampling."}}
{"id": "2407.06390", "pdf": "https://arxiv.org/pdf/2407.06390", "abs": "https://arxiv.org/abs/2407.06390", "authors": ["Eshant English", "Eliot Wong-Toi", "Matteo Fontana", "Stephan Mandt", "Padhraic Smyth", "Christoph Lippert"], "title": "JANET: Joint Adaptive predictioN-region Estimation for Time-series", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "Accepted to ECML Journal for Machine Learning Alternate Title:\n  Conformalised Joint Prediction Region for Time Series", "summary": "Conformal prediction provides machine learning models with prediction sets\nthat offer theoretical guarantees, but the underlying assumption of\nexchangeability limits its applicability to time series data. Furthermore,\nexisting approaches struggle to handle multi-step ahead prediction tasks, where\nuncertainty estimates across multiple future time points are crucial. We\npropose JANET (Joint Adaptive predictioN-region Estimation for Time-series), a\nnovel framework for constructing conformal prediction regions that are valid\nfor both univariate and multivariate time series. JANET generalises the\ninductive conformal framework and efficiently produces joint prediction regions\nwith controlled K-familywise error rates, enabling flexible adaptation to\nspecific application needs. Our empirical evaluation demonstrates JANET's\nsuperior performance in multi-step prediction tasks across diverse time series\ndatasets, highlighting its potential for reliable and interpretable uncertainty\nquantification in sequential data.", "AI": {"tldr": "JANET is a new framework for conformal prediction in time series, addressing multi-step ahead prediction and exchangeability limitations.", "motivation": "Existing conformal prediction methods lack applicability to time series and multi-step prediction tasks.", "method": "JANET extends inductive conformal prediction to create joint prediction regions with controlled error rates for time series.", "result": "JANET outperforms existing methods in multi-step prediction across diverse datasets.", "conclusion": "JANET offers reliable and interpretable uncertainty quantification for sequential data."}}
{"id": "2410.02835", "pdf": "https://arxiv.org/pdf/2410.02835", "abs": "https://arxiv.org/abs/2410.02835", "authors": ["Doron Cohen", "Aryeh Kontorovich", "Roi Weiss"], "title": "The Empirical Mean is Minimax Optimal for Local Glivenko-Cantelli", "categories": ["math.ST", "cs.LG", "stat.ME", "stat.TH"], "comment": null, "summary": "We revisit the recently introduced Local Glivenko-Cantelli setting, which\nstudies distribution-dependent uniform convergence rates of the Empirical Mean\nEstimator (EME). In this work, we investigate generalizations of this setting\nwhere arbitrary estimators are allowed rather than just the EME. Can a strictly\nlarger class of measures be learned? Can better risk decay rates be obtained?\nWe provide exhaustive answers to these questions, which are both negative,\nprovided the learner is barred from exploiting some infinite-dimensional\npathologies. On the other hand, allowing such exploits does lead to a strictly\nlarger class of learnable measures.", "AI": {"tldr": "The paper explores generalizations of the Local Glivenko-Cantelli setting, allowing arbitrary estimators beyond the Empirical Mean Estimator (EME). It finds that without exploiting infinite-dimensional pathologies, no larger class of measures or better risk decay rates can be achieved. However, allowing such exploits does expand the learnable measures.", "motivation": "To determine if generalizations of the Local Glivenko-Cantelli setting with arbitrary estimators can yield a larger class of learnable measures or improved risk decay rates.", "method": "Investigates the setting by allowing arbitrary estimators and analyzing their impact on learnability and risk decay rates.", "result": "Without exploiting infinite-dimensional pathologies, no improvements are possible. However, allowing such exploits expands the class of learnable measures.", "conclusion": "The study provides negative answers to the posed questions under standard constraints but shows potential gains by exploiting pathological cases."}}
{"id": "2410.08562", "pdf": "https://arxiv.org/pdf/2410.08562", "abs": "https://arxiv.org/abs/2410.08562", "authors": ["Akihiro Fujii", "Yoshitaka Ushiku", "Koji Shimizu", "Anh Khoa Augustin Lu", "Satoshi Watanabe"], "title": "Rethinking Gradient-Based Methods: Multi-Property Materials Design Beyond Differentiable Targets", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "Gradient-based methods offer a simple, efficient strategy for materials\ndesign by directly optimizing candidates using gradients from pretrained\nproperty predictors. However, their use in crystal structure optimization is\nhindered by two key challenges: handling non-differentiable constraints, such\nas charge neutrality and structural fidelity, and susceptibility to poor local\nminima. We revisit and extend the gradient-based methods to address these\nissues. We propose Simultaneous Multi-property Optimization using Adaptive\nCrystal Synthesizer (SMOACS), which integrates oxidation-number masks and\ntemplate-based initialization to enforce non-differentiable constraints, avoid\npoor local minima, and flexibly incorporate additional constraints without\nretraining. SMOACS enables multi-property optimization. including exceptional\ntargets such as high-temperature superconductivity, and scales to large crystal\nsystems, both persistent challenges for generative models, even those enhanced\nwith gradient-based guidance from property predictors. In experiments on five\ntarget properties and three datasets, SMOACS outperforms generative models and\nBayesian optimization methods, successfully designing 135-atom perovskite\nstructures that satisfy multiple property targets and constraints, a task at\nwhich the other methods fail entirely.", "AI": {"tldr": "SMOACS extends gradient-based methods for crystal structure optimization by addressing non-differentiable constraints and local minima, outperforming generative and Bayesian methods.", "motivation": "Overcome challenges in gradient-based crystal structure optimization, such as non-differentiable constraints and poor local minima.", "method": "Proposes SMOACS, integrating oxidation-number masks and template-based initialization for constraint handling and avoiding local minima.", "result": "Outperforms generative models and Bayesian optimization, successfully designing complex perovskite structures.", "conclusion": "SMOACS enables scalable, multi-property optimization for challenging crystal design tasks."}}
{"id": "2410.13738", "pdf": "https://arxiv.org/pdf/2410.13738", "abs": "https://arxiv.org/abs/2410.13738", "authors": ["Yuchen Jiao", "Gen Li"], "title": "Instance-dependent Convergence Theory for Diffusion Models", "categories": ["stat.ML", "cs.LG"], "comment": "47 pages", "summary": "Score-based diffusion models have demonstrated outstanding empirical\nperformance in machine learning and artificial intelligence, particularly in\ngenerating high-quality new samples from complex probability distributions.\nImproving the theoretical understanding of diffusion models, with a particular\nfocus on the convergence analysis, has attracted significant attention. In this\nwork, we develop a convergence rate that is adaptive to the smoothness of\ndifferent target distributions, referred to as instance-dependent bound.\nSpecifically, we establish an iteration complexity of\n$\\min\\{d,d^{2/3}L^{1/3},d^{1/3}L\\}\\varepsilon^{-2/3}$ (up to logarithmic\nfactors), where $d$ denotes the data dimension, and $\\varepsilon$ quantifies\nthe output accuracy in terms of total variation (TV) distance. In addition, $L$\nrepresents a relaxed Lipschitz constant, which, in the case of Gaussian mixture\nmodels, scales only logarithmically with the number of components, the\ndimension and iteration number, demonstrating broad applicability.", "AI": {"tldr": "The paper develops an adaptive convergence rate for score-based diffusion models, focusing on instance-dependent bounds for smooth target distributions.", "motivation": "To improve theoretical understanding of diffusion models, particularly convergence analysis, given their empirical success in generating high-quality samples.", "method": "Establishes an iteration complexity bound adaptive to the smoothness of target distributions, using a relaxed Lipschitz constant.", "result": "Derives an iteration complexity of min{d,d^(2/3)L^(1/3),d^(1/3)L}\u03b5^(-2/3), with L scaling logarithmically in Gaussian mixture models.", "conclusion": "The adaptive bound demonstrates broad applicability, especially for Gaussian mixtures, enhancing theoretical support for diffusion models."}}
{"id": "2410.16826", "pdf": "https://arxiv.org/pdf/2410.16826", "abs": "https://arxiv.org/abs/2410.16826", "authors": ["Paris Giampouras", "HanQin Cai", "Rene Vidal"], "title": "Guarantees of a Preconditioned Subgradient Algorithm for Overparameterized Asymmetric Low-rank Matrix Recovery", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "In this paper, we focus on a matrix factorization-based approach to recover\nlow-rank {\\it asymmetric} matrices from corrupted measurements. We propose an\n{\\it Overparameterized Preconditioned Subgradient Algorithm (OPSA)} and\nprovide, for the first time in the literature, linear convergence rates\nindependent of the rank of the sought asymmetric matrix in the presence of\ngross corruptions. Our work goes beyond existing results in preconditioned-type\napproaches addressing their current limitation, i.e., the lack of convergence\nguarantees in the case of {\\it asymmetric matrices of unknown rank}. By\napplying our approach to (robust) matrix sensing, we highlight its merits when\nthe measurement operator satisfies a mixed-norm restricted isometry property.\nLastly, we present extensive numerical experiments that validate our\ntheoretical results and demonstrate the effectiveness of our approach for\ndifferent levels of overparameterization and outlier corruptions.", "AI": {"tldr": "Proposes OPSA for recovering low-rank asymmetric matrices with linear convergence rates, robust to corruptions and independent of rank.", "motivation": "Addresses limitations in preconditioned approaches for asymmetric matrices of unknown rank, ensuring convergence guarantees.", "method": "Overparameterized Preconditioned Subgradient Algorithm (OPSA) applied to matrix sensing with mixed-norm RIP.", "result": "Linear convergence rates achieved; validated by numerical experiments for robustness and effectiveness.", "conclusion": "OPSA is effective for asymmetric matrix recovery, overcoming prior limitations and demonstrating robustness."}}
{"id": "2411.04999", "pdf": "https://arxiv.org/pdf/2411.04999", "abs": "https://arxiv.org/abs/2411.04999", "authors": ["Peiqi Liu", "Zhanqiu Guo", "Mohit Warke", "Soumith Chintala", "Chris Paxton", "Nur Muhammad Mahi Shafiullah", "Lerrel Pinto"], "title": "DynaMem: Online Dynamic Spatio-Semantic Memory for Open World Mobile Manipulation", "categories": ["cs.RO", "cs.LG"], "comment": "Website: https://dynamem.github.io", "summary": "Significant progress has been made in open-vocabulary mobile manipulation,\nwhere the goal is for a robot to perform tasks in any environment given a\nnatural language description. However, most current systems assume a static\nenvironment, which limits the system's applicability in real-world scenarios\nwhere environments frequently change due to human intervention or the robot's\nown actions. In this work, we present DynaMem, a new approach to open-world\nmobile manipulation that uses a dynamic spatio-semantic memory to represent a\nrobot's environment. DynaMem constructs a 3D data structure to maintain a\ndynamic memory of point clouds, and answers open-vocabulary object localization\nqueries using multimodal LLMs or open-vocabulary features generated by\nstate-of-the-art vision-language models. Powered by DynaMem, our robots can\nexplore novel environments, search for objects not found in memory, and\ncontinuously update the memory as objects move, appear, or disappear in the\nscene. We run extensive experiments on the Stretch SE3 robots in three real and\nnine offline scenes, and achieve an average pick-and-drop success rate of 70%\non non-stationary objects, which is more than a 2x improvement over\nstate-of-the-art static systems. Our code as well as our experiment and\ndeployment videos are open sourced and can be found on our project website:\nhttps://dynamem.github.io/", "AI": {"tldr": "DynaMem introduces a dynamic spatio-semantic memory system for open-world mobile manipulation, improving adaptability in changing environments.", "motivation": "Current systems assume static environments, limiting real-world applicability. DynaMem addresses this by enabling dynamic updates to environmental memory.", "method": "Uses a 3D data structure for dynamic memory of point clouds, leveraging multimodal LLMs and vision-language models for object localization.", "result": "Achieves 70% success rate on non-stationary objects, a 2x improvement over static systems.", "conclusion": "DynaMem enhances robot adaptability in dynamic environments, with open-source code and deployment videos available."}}
{"id": "2411.06268", "pdf": "https://arxiv.org/pdf/2411.06268", "abs": "https://arxiv.org/abs/2411.06268", "authors": ["Thuan Pham", "Xingpeng Li"], "title": "Constraints and Variables Reduction for Optimal Power Flow Using Hierarchical Graph Neural Networks with Virtual Node-Splitting", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "Power system networks are often modeled as homogeneous graphs, which limits\nthe ability of graph neural network (GNN) to capture individual generator\nfeatures at the same nodes. By introducing the proposed virtual node-splitting\nstrategy, generator-level attributes like costs, limits, and ramp rates can be\nfully captured by GNN models, improving GNN's learning capacity and prediction\naccuracy. Optimal power flow (OPF) problem is used for real-time grid\noperations. Limited timeframe motivates studies to create size-reduced OPF\n(ROPF) models to relieve the computational complexity. In this paper, with\nvirtual node-splitting, a novel two-stage adaptive hierarchical GNN is\ndeveloped to (i) predict critical lines that would be congested, and then (ii)\npredict base generators that would operate at the maximum capacity. This will\nsubstantially reduce the constraints and variables needed for OPF, creating the\nproposed ROPFLG model with reduced monitor lines and reduced generator-specific\nvariables and constraints. Two ROPF models, ROPFL and ROPFG, with just reduced\nlines or generators respectively, are also implemented as additional benchmark\nmodels. Case studies show that the proposed ROPFLG consistently outperforms the\nbenchmark full OPF (FOPF) and the other two ROPF methods, achieving significant\ncomputational time savings while reliably finding optimal solutions.", "AI": {"tldr": "The paper introduces a virtual node-splitting strategy to enhance GNNs for power system modeling, proposing a two-stage adaptive hierarchical GNN for OPF problem simplification.", "motivation": "Traditional homogeneous graph models limit GNNs' ability to capture generator-specific features, and computational complexity in OPF motivates reduced models.", "method": "A virtual node-splitting strategy and a two-stage adaptive hierarchical GNN are developed to predict congested lines and base generators, reducing OPF constraints.", "result": "The proposed ROPFLG model outperforms benchmark models (FOPF, ROPFL, ROPFG) in computational efficiency and solution reliability.", "conclusion": "Virtual node-splitting and hierarchical GNNs effectively reduce OPF complexity while maintaining accuracy, offering significant computational savings."}}
{"id": "2411.18579", "pdf": "https://arxiv.org/pdf/2411.18579", "abs": "https://arxiv.org/abs/2411.18579", "authors": ["Kieran A. Murphy", "Yujing Zhang", "Dani S. Bassett"], "title": "Surveying the space of descriptions of a composite system with machine learning", "categories": ["cs.IT", "cs.LG", "math.IT", "physics.data-an"], "comment": "Code here: https://github.com/murphyka/description_space", "summary": "Multivariate information theory provides a general and principled framework\nfor understanding how the components of a complex system are connected.\nExisting analyses are coarse in nature -- built up from characterizations of\ndiscrete subsystems -- and can be computationally prohibitive. In this work, we\npropose to study the continuous space of possible descriptions of a composite\nsystem as a window into its organizational structure. A description consists of\nspecific information conveyed about each of the components, and the space of\npossible descriptions is equivalent to the space of lossy compression schemes\nof the components. We introduce a machine learning framework to optimize\ndescriptions that extremize key information theoretic quantities used to\ncharacterize organization, such as total correlation and O-information. Through\ncase studies on spin systems, sudoku boards, and letter sequences from natural\nlanguage, we identify extremal descriptions that reveal how system-wide\nvariation emerges from individual components. By integrating machine learning\ninto a fine-grained information theoretic analysis of composite random\nvariables, our framework opens a new avenues for probing the structure of\nreal-world complex systems.", "AI": {"tldr": "The paper proposes a machine learning framework to optimize descriptions of composite systems, revealing organizational structure through information theory.", "motivation": "Existing analyses of complex systems are coarse and computationally expensive, limiting understanding of system-wide variation.", "method": "A machine learning framework optimizes descriptions (lossy compression schemes) to extremize information theoretic quantities like total correlation and O-information.", "result": "Case studies on spin systems, sudoku boards, and natural language show extremal descriptions that highlight system-wide variation.", "conclusion": "The framework offers a new approach to analyze real-world complex systems by integrating machine learning with fine-grained information theory."}}
{"id": "2412.19529", "pdf": "https://arxiv.org/pdf/2412.19529", "abs": "https://arxiv.org/abs/2412.19529", "authors": ["Zijian Liu", "Zhengyuan Zhou"], "title": "Nonconvex Stochastic Optimization under Heavy-Tailed Noises: Optimal Convergence without Gradient Clipping", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": "ICLR 2025", "summary": "Recently, the study of heavy-tailed noises in first-order nonconvex\nstochastic optimization has gotten a lot of attention since it was recognized\nas a more realistic condition as suggested by many empirical observations.\nSpecifically, the stochastic noise (the difference between the stochastic and\ntrue gradient) is considered to have only a finite $\\mathfrak{p}$-th moment\nwhere $\\mathfrak{p}\\in\\left(1,2\\right]$ instead of assuming it always satisfies\nthe classical finite variance assumption. To deal with this more challenging\nsetting, people have proposed different algorithms and proved them to converge\nat an optimal $\\mathcal{O}(T^{\\frac{1-\\mathfrak{p}}{3\\mathfrak{p}-2}})$ rate\nfor smooth objectives after $T$ iterations. Notably, all these new-designed\nalgorithms are based on the same technique - gradient clipping. Naturally, one\nmay want to know whether the clipping method is a necessary ingredient and the\nonly way to guarantee convergence under heavy-tailed noises. In this work, by\nrevisiting the existing Batched Normalized Stochastic Gradient Descent with\nMomentum (Batched NSGDM) algorithm, we provide the first convergence result\nunder heavy-tailed noises but without gradient clipping. Concretely, we prove\nthat Batched NSGDM can achieve the optimal\n$\\mathcal{O}(T^{\\frac{1-\\mathfrak{p}}{3\\mathfrak{p}-2}})$ rate even under the\nrelaxed smooth condition. More interestingly, we also establish the first\n$\\mathcal{O}(T^{\\frac{1-\\mathfrak{p}}{2\\mathfrak{p}}})$ convergence rate in the\ncase where the tail index $\\mathfrak{p}$ is unknown in advance, which is\narguably the common scenario in practice.", "AI": {"tldr": "The paper explores first-order nonconvex stochastic optimization with heavy-tailed noises, proving that Batched NSGDM achieves optimal convergence rates without gradient clipping, even under relaxed smooth conditions and unknown tail indices.", "motivation": "Heavy-tailed noises are more realistic in stochastic optimization, but existing methods rely on gradient clipping. The study investigates if clipping is necessary and introduces a clipping-free approach.", "method": "Revisits Batched Normalized Stochastic Gradient Descent with Momentum (Batched NSGDM) to analyze its convergence under heavy-tailed noises without gradient clipping.", "result": "Batched NSGDM achieves the optimal convergence rate under heavy-tailed noises and relaxed smooth conditions, and a new rate for unknown tail indices.", "conclusion": "Gradient clipping is not essential for convergence in heavy-tailed noise settings, as Batched NSGDM provides a viable alternative with optimal rates."}}
{"id": "2502.05210", "pdf": "https://arxiv.org/pdf/2502.05210", "abs": "https://arxiv.org/abs/2502.05210", "authors": ["Shicheng Zhou", "Zizhou Zhang", "Rong Zhang", "Yuchen Yin", "Chia Hong Chang", "Qinyan Shen"], "title": "Regression and Forecasting of U.S. Stock Returns Based on LSTM", "categories": ["q-fin.ST", "cs.LG"], "comment": "5pages", "summary": "This paper analyses the investment returns of three stock sectors, Manuf,\nHitec, and Other, in the U.S. stock market, based on the Fama-French\nthree-factor model, the Carhart four-factor model, and the Fama-French\nfive-factor model, in order to test the validity of the Fama-French\nthree-factor model, the Carhart four-factor model, and the Fama-French\nfive-factor model for the three sectors of the market. French five-factor model\nfor the three sectors of the market. Also, the LSTM model is used to explore\nthe additional factors affecting stock returns. The empirical results show that\nthe Fama-French five-factor model has better validity for the three segments of\nthe market under study, and the LSTM model has the ability to capture the\nfactors affecting the returns of certain industries, and can better regress and\npredict the stock returns of the relevant industries. Keywords- Fama-French\nmodel; Carhart model; Factor model; LSTM model.", "AI": {"tldr": "The paper evaluates the validity of Fama-French and Carhart models for three U.S. stock sectors and introduces LSTM to identify additional return factors. The five-factor model performs best, and LSTM effectively captures industry-specific factors.", "motivation": "To test the validity of Fama-French and Carhart models for specific stock sectors and explore additional factors using LSTM.", "method": "Uses Fama-French three-factor, Carhart four-factor, and Fama-French five-factor models, alongside LSTM, to analyze returns in Manuf, Hitec, and Other sectors.", "result": "The Fama-French five-factor model shows better validity for the sectors. LSTM captures additional factors and improves regression and prediction of stock returns.", "conclusion": "The five-factor model is more effective, and LSTM enhances understanding and prediction of industry-specific stock returns."}}
{"id": "2502.06044", "pdf": "https://arxiv.org/pdf/2502.06044", "abs": "https://arxiv.org/abs/2502.06044", "authors": ["Getoar Sopa", "Juraj Marusic", "Marco Avella-Medina", "John P. Cunningham"], "title": "Scalable Differentially Private Bayesian Optimization", "categories": ["stat.ML", "cs.LG"], "comment": "25 pages, 5 figures", "summary": "In recent years, there has been much work on scaling Bayesian Optimization to\nhigh-dimensional problems, for example hyperparameter tuning in large machine\nlearning models. These scalable methods have been successful, finding high\nobjective values much more quickly than traditional global Bayesian\nOptimization or random search-based methods. At the same time, these large\nmodels often use sensitive data, but preservation of Differential Privacy has\nnot scaled alongside these modern Bayesian Optimization procedures. Here we\ndevelop a method to privately optimize potentially high-dimensional parameter\nspaces using privatized Gradient Informative Bayesian Optimization. Our\ntheoretical results show that under suitable conditions, our method converges\nexponentially fast to a locally optimal parameter configuration, up to a\nnatural privacy error. Moreover, regardless of whether the assumptions are\nsatisfied, we prove that our algorithm maintains privacy and empirically\ndisplay superior performance to existing methods in the high-dimensional\nhyperparameter setting.", "AI": {"tldr": "A method for differentially private Bayesian Optimization in high-dimensional spaces is introduced, showing fast convergence and superior performance.", "motivation": "Scalable Bayesian Optimization methods lack privacy guarantees for sensitive data in large models.", "method": "Privatized Gradient Informative Bayesian Optimization for high-dimensional parameter spaces.", "result": "Exponential convergence to locally optimal configurations under suitable conditions, with maintained privacy and superior empirical performance.", "conclusion": "The method effectively combines scalability, privacy, and performance in high-dimensional optimization."}}
{"id": "2502.08166", "pdf": "https://arxiv.org/pdf/2502.08166", "abs": "https://arxiv.org/abs/2502.08166", "authors": ["Jessica Dai", "Paula Gradu", "Inioluwa Deborah Raji", "Benjamin Recht"], "title": "From Individual Experience to Collective Evidence: A Reporting-Based Framework for Identifying Systemic Harms", "categories": ["cs.CY", "cs.LG"], "comment": "Updated terminology from \"incident database\" to \"reporting database.\"\n  To be presented at ICML 2025", "summary": "When an individual reports a negative interaction with some system, how can\ntheir personal experience be contextualized within broader patterns of system\nbehavior? We study the reporting database problem, where individual reports of\nadverse events arrive sequentially, and are aggregated over time. In this work,\nour goal is to identify whether there are subgroups--defined by any combination\nof relevant features--that are disproportionately likely to experience harmful\ninteractions with the system. We formalize this problem as a sequential\nhypothesis test, and identify conditions on reporting behavior that are\nsufficient for making inferences about disparities in true rates of harm across\nsubgroups. We show that algorithms for sequential hypothesis tests can be\napplied to this problem with a standard multiple testing correction. We then\ndemonstrate our method on real-world datasets, including mortgage decisions and\nvaccine side effects; on each, our method (re-)identifies subgroups known to\nexperience disproportionate harm using only a fraction of the data that was\ninitially used to discover them.", "AI": {"tldr": "The paper proposes a method to identify subgroups disproportionately affected by system harm using sequential hypothesis testing on adverse event reports.", "motivation": "To contextualize individual negative experiences within broader system behavior patterns by identifying subgroups facing disproportionate harm.", "method": "Formalizes the problem as a sequential hypothesis test, applies algorithms with multiple testing corrections, and tests on real-world datasets.", "result": "The method successfully identifies known disadvantaged subgroups using less data than originally required.", "conclusion": "Sequential hypothesis testing effectively detects disparities in harm rates across subgroups, aiding early intervention."}}
{"id": "2502.08766", "pdf": "https://arxiv.org/pdf/2502.08766", "abs": "https://arxiv.org/abs/2502.08766", "authors": ["Wei Xuan", "Meghna Roy Chowdhury", "Yi Ding", "Yixue Zhao"], "title": "Unlocking Mental Health: Exploring College Students' Well-being through Smartphone Behaviors", "categories": ["cs.CY", "cs.HC", "cs.LG", "cs.SE"], "comment": "Published at International Conference on Mobile Software Engineering\n  and Systems (MOBILESoft 2025)", "summary": "The global mental health crisis is a pressing concern, with college students\nparticularly vulnerable to rising mental health disorders. The widespread use\nof smartphones among young adults, while offering numerous benefits, has also\nbeen linked to negative outcomes such as addiction and regret, significantly\nimpacting well-being. Leveraging the longest longitudinal dataset collected\nover four college years through passive mobile sensing, this study is the first\nto examine the relationship between students' smartphone unlocking behaviors\nand their mental health at scale in real-world settings. We provide the first\nevidence demonstrating the predictability of phone unlocking behaviors for\nmental health outcomes based on a large dataset, highlighting the potential of\nthese novel features for future predictive models. Our findings reveal\nimportant variations in smartphone usage across genders and locations, offering\na deeper understanding of the interplay between digital behaviors and mental\nhealth. We highlight future research directions aimed at mitigating adverse\neffects and promoting digital well-being in this population.", "AI": {"tldr": "Smartphone unlocking behaviors predict mental health outcomes in college students, with variations by gender and location, offering insights for digital well-being interventions.", "motivation": "Address the global mental health crisis among college students by exploring the link between smartphone usage and mental health.", "method": "Used a four-year longitudinal dataset of passive mobile sensing to analyze smartphone unlocking behaviors and mental health.", "result": "Found predictable relationships between unlocking behaviors and mental health, with notable gender and location differences.", "conclusion": "Highlights the potential of smartphone data for mental health prediction and calls for research to mitigate negative digital effects."}}
{"id": "2502.17370", "pdf": "https://arxiv.org/pdf/2502.17370", "abs": "https://arxiv.org/abs/2502.17370", "authors": ["Simone Drago", "Marco Mussi", "Alberto Maria Metelli"], "title": "A Refined Analysis of UCBVI", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In this work, we provide a refined analysis of the UCBVI algorithm (Azar et\nal., 2017), improving both the bonus terms and the regret analysis.\nAdditionally, we compare our version of UCBVI with both its original version\nand the state-of-the-art MVP algorithm. Our empirical validation demonstrates\nthat improving the multiplicative constants in the bounds has significant\npositive effects on the empirical performance of the algorithms.", "AI": {"tldr": "Refined analysis of UCBVI algorithm with improved bonus terms and regret analysis, outperforming original UCBVI and MVP in empirical tests.", "motivation": "To enhance the UCBVI algorithm by refining its analysis and improving its empirical performance.", "method": "Refined bonus terms and regret analysis for UCBVI, compared with original UCBVI and MVP.", "result": "Improved multiplicative constants in bounds positively impact empirical performance.", "conclusion": "The refined UCBVI algorithm shows significant performance improvements over original UCBVI and MVP."}}
{"id": "2503.09492", "pdf": "https://arxiv.org/pdf/2503.09492", "abs": "https://arxiv.org/abs/2503.09492", "authors": ["Yunli Wang", "Zhen Zhang", "Zhiqiang Wang", "Zixuan Yang", "Yu Li", "Jian Yang", "Shiyang Wen", "Peng Jiang", "Kun Gai"], "title": "Learning Cascade Ranking as One Network", "categories": ["cs.IR", "cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Cascade Ranking is a prevalent architecture in large-scale top-k selection\nsystems like recommendation and advertising platforms. Traditional training\nmethods focus on single-stage optimization, neglecting interactions between\nstages. Recent advances have introduced interaction-aware training paradigms,\nbut still struggle to 1) align training objectives with the goal of the entire\ncascade ranking (i.e., end-to-end recall of ground-truth items) and 2) learn\neffective collaboration patterns for different stages. To address these\nchallenges, we propose LCRON, which introduces a novel surrogate loss function\nderived from the lower bound probability that ground truth items are selected\nby cascade ranking, ensuring alignment with the overall objective of the\nsystem. According to the properties of the derived bound, we further design an\nauxiliary loss for each stage to drive the reduction of this bound, leading to\na more robust and effective top-k selection. LCRON enables end-to-end training\nof the entire cascade ranking system as a unified network. Experimental results\ndemonstrate that LCRON achieves significant improvement over existing methods\non public benchmarks and industrial applications, addressing key limitations in\ncascade ranking training and significantly enhancing system performance.", "AI": {"tldr": "LCRON introduces a surrogate loss function for cascade ranking, aligning training with end-to-end recall goals and improving collaboration between stages.", "motivation": "Traditional cascade ranking methods neglect stage interactions and fail to align training with system-wide objectives.", "method": "LCRON uses a novel surrogate loss derived from the lower bound probability of ground-truth item selection, along with auxiliary losses for each stage.", "result": "LCRON outperforms existing methods on benchmarks and industrial applications, enhancing system performance.", "conclusion": "LCRON effectively addresses cascade ranking limitations, enabling unified end-to-end training and improved top-k selection."}}
{"id": "2505.22094", "pdf": "https://arxiv.org/pdf/2505.22094", "abs": "https://arxiv.org/abs/2505.22094", "authors": ["Tonghe Zhang", "Chao Yu", "Sichang Su", "Yu Wang"], "title": "ReinFlow: Fine-tuning Flow Matching Policy with Online Reinforcement Learning", "categories": ["cs.RO", "cs.LG"], "comment": "30 pages, 13 figures, 10 tables", "summary": "We propose ReinFlow, a simple yet effective online reinforcement learning\n(RL) framework that fine-tunes a family of flow matching policies for\ncontinuous robotic control. Derived from rigorous RL theory, ReinFlow injects\nlearnable noise into a flow policy's deterministic path, converting the flow\ninto a discrete-time Markov Process for exact and straightforward likelihood\ncomputation. This conversion facilitates exploration and ensures training\nstability, enabling ReinFlow to fine-tune diverse flow model variants,\nincluding Rectified Flow [35] and Shortcut Models [19], particularly at very\nfew or even one denoising step. We benchmark ReinFlow in representative\nlocomotion and manipulation tasks, including long-horizon planning with visual\ninput and sparse reward. The episode reward of Rectified Flow policies obtained\nan average net growth of 135.36% after fine-tuning in challenging legged\nlocomotion tasks while saving denoising steps and 82.63% of wall time compared\nto state-of-the-art diffusion RL fine-tuning method DPPO [43]. The success rate\nof the Shortcut Model policies in state and visual manipulation tasks achieved\nan average net increase of 40.34% after fine-tuning with ReinFlow at four or\neven one denoising step, whose performance is comparable to fine-tuned DDIM\npolicies while saving computation time for an average of 23.20%. Project\nwebpage: https://reinflow.github.io/", "AI": {"tldr": "ReinFlow is an online RL framework for fine-tuning flow matching policies in robotic control, improving performance and efficiency over existing methods.", "motivation": "To address the challenges of exploration and training stability in continuous robotic control by leveraging flow matching policies.", "method": "ReinFlow injects learnable noise into deterministic flow policies, converting them into a Markov Process for exact likelihood computation, enabling fine-tuning of flow models like Rectified Flow and Shortcut Models.", "result": "Achieves significant improvements in reward (135.36% in locomotion) and success rates (40.34% in manipulation) while reducing computation time (82.63% wall time savings).", "conclusion": "ReinFlow effectively fine-tunes flow policies, outperforming state-of-the-art methods in both performance and efficiency."}}
