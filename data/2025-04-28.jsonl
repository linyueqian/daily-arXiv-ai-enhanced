{"id": "2504.17974", "pdf": "https://arxiv.org/pdf/2504.17974", "abs": "https://arxiv.org/abs/2504.17974", "authors": ["Sabur Butt", "Fazlourrahman Balouchzahi", "Ahmad Imam Amjad", "Maaz Amjad", "Hector G. Ceballos", "Salud Maria Jimenez-Zafra"], "title": "Optimism, Expectation, or Sarcasm? Multi-Class Hope Speech Detection in Spanish and English", "categories": ["cs.CL"], "comment": null, "summary": "Hope is a complex and underexplored emotional state that plays a significant\nrole in education, mental health, and social interaction. Unlike basic\nemotions, hope manifests in nuanced forms ranging from grounded optimism to\nexaggerated wishfulness or sarcasm, making it difficult for Natural Language\nProcessing systems to detect accurately. This study introduces PolyHope V2, a\nmultilingual, fine-grained hope speech dataset comprising over 30,000 annotated\ntweets in English and Spanish. This resource distinguishes between four hope\nsubtypes Generalized, Realistic, Unrealistic, and Sarcastic and enhances\nexisting datasets by explicitly labeling sarcastic instances. We benchmark\nmultiple pretrained transformer models and compare them with large language\nmodels (LLMs) such as GPT 4 and Llama 3 under zero-shot and few-shot regimes.\nOur findings show that fine-tuned transformers outperform prompt-based LLMs,\nespecially in distinguishing nuanced hope categories and sarcasm. Through\nqualitative analysis and confusion matrices, we highlight systematic challenges\nin separating closely related hope subtypes. The dataset and results provide a\nrobust foundation for future emotion recognition tasks that demand greater\nsemantic and contextual sensitivity across languages."}
{"id": "2504.17993", "pdf": "https://arxiv.org/pdf/2504.17993", "abs": "https://arxiv.org/abs/2504.17993", "authors": ["Brihi Joshi", "Xiang Ren", "Swabha Swayamdipta", "Rik Koncel-Kedziorski", "Tim Paek"], "title": "Improving LLM Personas via Rationalization with Psychological Scaffolds", "categories": ["cs.CL"], "comment": null, "summary": "Language models prompted with a user description or persona can predict a\nuser's preferences and opinions, but existing approaches to building personas\n-- based solely on a user's demographic attributes and/or prior judgments --\nfail to capture the underlying reasoning behind said user judgments. We\nintroduce PB&J (Psychology of Behavior and Judgments), a framework that\nimproves LLM personas by incorporating rationales of why a user might make\nspecific judgments. These rationales are LLM-generated, and aim to reason about\na user's behavior on the basis of their experiences, personality traits or\nbeliefs. This is done using psychological scaffolds -- structured frameworks\ngrounded in theories such as the Big 5 Personality Traits and Primal World\nBeliefs -- that help provide structure to the generated rationales. Experiments\non public opinion and movie preference prediction tasks demonstrate that LLM\npersonas augmented with PB&J rationales consistently outperform methods using\nonly a user's demographics and/or judgments. Additionally, LLM personas\nconstructed using scaffolds describing user beliefs perform competitively with\nthose using human-written rationales."}
{"id": "2504.18012", "pdf": "https://arxiv.org/pdf/2504.18012", "abs": "https://arxiv.org/abs/2504.18012", "authors": ["Zhuang Yu", "Shiliang Sun", "Jing Zhao", "Tengfei Song", "Hao Yang"], "title": "Memory Reviving, Continuing Learning and Beyond: Evaluation of Pre-trained Encoders and Decoders for Multimodal Machine Translation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multimodal Machine Translation (MMT) aims to improve translation quality by\nleveraging auxiliary modalities such as images alongside textual input. While\nrecent advances in large-scale pre-trained language and vision models have\nsignificantly benefited unimodal natural language processing tasks, their\neffectiveness and role in MMT remain underexplored. In this work, we conduct a\nsystematic study on the impact of pre-trained encoders and decoders in\nmultimodal translation models. Specifically, we analyze how different training\nstrategies, from training from scratch to using pre-trained and partially\nfrozen components, affect translation performance under a unified MMT\nframework. Experiments are carried out on the Multi30K and CoMMuTE dataset\nacross English-German and English-French translation tasks. Our results reveal\nthat pre-training plays a crucial yet asymmetrical role in multimodal settings:\npre-trained decoders consistently yield more fluent and accurate outputs, while\npre-trained encoders show varied effects depending on the quality of\nvisual-text alignment. Furthermore, we provide insights into the interplay\nbetween modality fusion and pre-trained components, offering guidance for\nfuture architecture design in multimodal translation systems."}
{"id": "2504.18041", "pdf": "https://arxiv.org/pdf/2504.18041", "abs": "https://arxiv.org/abs/2504.18041", "authors": ["Bang An", "Shiyue Zhang", "Mark Dredze"], "title": "RAG LLMs are Not Safer: A Safety Analysis of Retrieval-Augmented Generation for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "NAACL 2025", "summary": "Efforts to ensure the safety of large language models (LLMs) include safety\nfine-tuning, evaluation, and red teaming. However, despite the widespread use\nof the Retrieval-Augmented Generation (RAG) framework, AI safety work focuses\non standard LLMs, which means we know little about how RAG use cases change a\nmodel's safety profile. We conduct a detailed comparative analysis of RAG and\nnon-RAG frameworks with eleven LLMs. We find that RAG can make models less safe\nand change their safety profile. We explore the causes of this change and find\nthat even combinations of safe models with safe documents can cause unsafe\ngenerations. In addition, we evaluate some existing red teaming methods for RAG\nsettings and show that they are less effective than when used for non-RAG\nsettings. Our work highlights the need for safety research and red-teaming\nmethods specifically tailored for RAG LLMs."}
{"id": "2504.17929", "pdf": "https://arxiv.org/pdf/2504.17929", "abs": "https://arxiv.org/abs/2504.17929", "authors": ["Ayesha Siddique", "Khurram Khalil", "Khaza Anuarul Hoque"], "title": "ApproXAI: Energy-Efficient Hardware Acceleration of Explainable AI using Approximate Computing", "categories": ["cs.AI", "cs.AR"], "comment": "Accepted at the International Joint Conference on Neural Networks\n  (IJCNN), June 30th - July 5th, 2025 in Rome, Italy", "summary": "Explainable artificial intelligence (XAI) enhances AI system transparency by\nframing interpretability as an optimization problem. However, this approach\noften necessitates numerous iterations of computationally intensive operations,\nlimiting its applicability in real-time scenarios. While recent research has\nfocused on XAI hardware acceleration on FPGAs and TPU, these methods do not\nfully address energy efficiency in real-time settings. To address this\nlimitation, we propose XAIedge, a novel framework that leverages approximate\ncomputing techniques into XAI algorithms, including integrated gradients, model\ndistillation, and Shapley analysis. XAIedge translates these algorithms into\napproximate matrix computations and exploits the synergy between convolution,\nFourier transform, and approximate computing paradigms. This approach enables\nefficient hardware acceleration on TPU-based edge devices, facilitating faster\nreal-time outcome interpretations. Our comprehensive evaluation demonstrates\nthat XAIedge achieves a $2\\times$ improvement in energy efficiency compared to\nexisting accurate XAI hardware acceleration techniques while maintaining\ncomparable accuracy. These results highlight the potential of XAIedge to\nsignificantly advance the deployment of explainable AI in energy-constrained\nreal-time applications."}
{"id": "2504.17838", "pdf": "https://arxiv.org/pdf/2504.17838", "abs": "https://arxiv.org/abs/2504.17838", "authors": ["Bernhard Jaeger", "Daniel Dauner", "Jens Bei√üwenger", "Simon Gerstenecker", "Kashyap Chitta", "Andreas Geiger"], "title": "CaRL: Learning Scalable Planning Policies with Simple Rewards", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "We investigate reinforcement learning (RL) for privileged planning in\nautonomous driving. State-of-the-art approaches for this task are rule-based,\nbut these methods do not scale to the long tail. RL, on the other hand, is\nscalable and does not suffer from compounding errors like imitation learning.\nContemporary RL approaches for driving use complex shaped rewards that sum\nmultiple individual rewards, \\eg~progress, position, or orientation rewards. We\nshow that PPO fails to optimize a popular version of these rewards when the\nmini-batch size is increased, which limits the scalability of these approaches.\nInstead, we propose a new reward design based primarily on optimizing a single\nintuitive reward term: route completion. Infractions are penalized by\nterminating the episode or multiplicatively reducing route completion. We find\nthat PPO scales well with higher mini-batch sizes when trained with our simple\nreward, even improving performance. Training with large mini-batch sizes\nenables efficient scaling via distributed data parallelism. We scale PPO to\n300M samples in CARLA and 500M samples in nuPlan with a single 8-GPU node. The\nresulting model achieves 64 DS on the CARLA longest6 v2 benchmark,\noutperforming other RL methods with more complex rewards by a large margin.\nRequiring only minimal adaptations from its use in CARLA, the same method is\nthe best learning-based approach on nuPlan. It scores 91.3 in non-reactive and\n90.6 in reactive traffic on the Val14 benchmark while being an order of\nmagnitude faster than prior work."}
{"id": "2504.17804", "pdf": "https://arxiv.org/pdf/2504.17804", "abs": "https://arxiv.org/abs/2504.17804", "authors": ["Andrew Kiruluta"], "title": "Spectral Dictionary Learning for Generative Image Modeling", "categories": ["cs.CV"], "comment": null, "summary": "We propose a novel spectral generative model for image synthesis that departs\nradically from the common variational, adversarial, and diffusion paradigms. In\nour approach, images, after being flattened into one-dimensional signals, are\nreconstructed as linear combinations of a set of learned spectral basis\nfunctions, where each basis is explicitly parameterized in terms of frequency,\nphase, and amplitude. The model jointly learns a global spectral dictionary\nwith time-varying modulations and per-image mixing coefficients that quantify\nthe contributions of each spectral component. Subsequently, a simple\nprobabilistic model is fitted to these mixing coefficients, enabling the\ndeterministic generation of new images by sampling from the latent space. This\nframework leverages deterministic dictionary learning, offering a highly\ninterpretable and physically meaningful representation compared to methods\nrelying on stochastic inference or adversarial training. Moreover, the\nincorporation of frequency-domain loss functions, computed via the short-time\nFourier transform (STFT), ensures that the synthesized images capture both\nglobal structure and fine-grained spectral details, such as texture and edge\ninformation. Experimental evaluations on the CIFAR-10 benchmark demonstrate\nthat our approach not only achieves competitive performance in terms of\nreconstruction quality and perceptual fidelity but also offers improved\ntraining stability and computational efficiency. This new type of generative\nmodel opens up promising avenues for controlled synthesis, as the learned\nspectral dictionary affords a direct handle on the intrinsic frequency content\nof the images, thus providing enhanced interpretability and potential for novel\napplications in image manipulation and analysis."}
{"id": "2504.17912", "pdf": "https://arxiv.org/pdf/2504.17912", "abs": "https://arxiv.org/abs/2504.17912", "authors": ["Wei Huang", "Jiajun Lu", "Hao Zhang", "Tianhe Xu"], "title": "STNet: Prediction of Underwater Sound Speed Profiles with An Advanced Semi-Transformer Neural Network", "categories": ["cs.SD", "eess.AS", "eess.SP"], "comment": null, "summary": "Real time acquisition of accurate underwater sound velocity profile (SSP) is\ncrucial for tracking the propagation trajectory of underwater acoustic signals,\nmaking it play a key role in ocean communication positioning. SSPs can be\ndirectly measured by instruments or inverted leveraging sound field data.\nAlthough measurement techniques provide a good accuracy, they are constrained\nby limited spatial coverage and require substantial time investment. The\ninversion method based on real-time measurement of acoustic field data improves\noperational efficiency, but loses the accuracy of SSP estimation and suffers\nfrom limited spatial applicability due to its stringent requirements for ocean\nobservation infrastructure. To achieve accurate long-term ocean SSP estimation\nindependent of real-time underwater data measurements, we propose a\nSemi-Transformer neural network (STNet) specifically designed for simulating\nsound velocity distribution patterns from the perspective of time series\nprediction. The proposed network architecture incorporates an optimized\nself-attention mechanism to effectively capture long-range temporal\ndependencies within historical sound velocity time-series data, facilitating\naccurate estimation of current SSPs or prediction of future SSPs. Through\narchitectural optimization of the Transformer framework and integration of a\ntime encoding mechanism, STNet could effectively improve computational\nefficiency. Comparative experimental results reveal that STNet outperforms\nstate-of-the-art models in predictive accuracy and maintain good computational\nefficiency, demonstrating its potential for enabling accurate long-term\nfull-depth ocean SSP forecasting."}
{"id": "2504.17950", "pdf": "https://arxiv.org/pdf/2504.17950", "abs": "https://arxiv.org/abs/2504.17950", "authors": ["Isadora White", "Kolby Nottingham", "Ayush Maniar", "Max Robinson", "Hansen Lillemark", "Mehul Maheshwari", "Lianhui Qin", "Prithviraj Ammanabrolu"], "title": "Collaborating Action by Action: A Multi-agent LLM Framework for Embodied Reasoning", "categories": ["cs.MA", "cs.CL"], "comment": "9 pages of main paper with 6 main figures, overall 28 pages", "summary": "Collaboration is ubiquitous and essential in day-to-day life -- from\nexchanging ideas, to delegating tasks, to generating plans together. This work\nstudies how LLMs can adaptively collaborate to perform complex embodied\nreasoning tasks. To this end we introduce MINDcraft, an easily extensible\nplatform built to enable LLM agents to control characters in the open-world\ngame of Minecraft; and MineCollab, a benchmark to test the different dimensions\nof embodied and collaborative reasoning. An experimental study finds that the\nprimary bottleneck in collaborating effectively for current state-of-the-art\nagents is efficient natural language communication, with agent performance\ndropping as much as 15% when they are required to communicate detailed task\ncompletion plans. We conclude that existing LLM agents are ill-optimized for\nmulti-agent collaboration, especially in embodied scenarios, and highlight the\nneed to employ methods beyond in-context and imitation learning. Our website\ncan be found here: https://mindcraft-minecollab.github.io/"}
{"id": "2504.17938", "pdf": "https://arxiv.org/pdf/2504.17938", "abs": "https://arxiv.org/abs/2504.17938", "authors": ["Raza Ul Mustafa", "Sesha Dassanayake"], "title": "Machine Learning-Based Prediction of Quality Shifts on Video Streaming Over 5G", "categories": ["cs.MM", "cs.LG"], "comment": null, "summary": "The Quality of Experience (QoE) is the users satisfaction while streaming a\nvideo session over an over-the-top (OTT) platform like YouTube. QoE of YouTube\nreflects the smooth streaming session without any buffering and quality shift\nevents. One of the most important factors nowadays affecting QoE of YouTube is\nfrequent shifts from higher to lower resolutions and vice versa. These shifts\nensure a smooth streaming session; however, it might get a lower mean opinion\nscore. For instance, dropping from 1080p to 480p during a video can preserve\ncontinuity but might reduce the viewers enjoyment. Over time, OTT platforms are\nlooking for alternative ways to boost user experience instead of relying on\ntraditional Quality of Service (QoS) metrics such as bandwidth, latency, and\nthroughput. As a result, we look into the relationship between quality shifting\nin YouTube streaming sessions and the channel metrics RSRP, RSRQ, and SNR. Our\nfindings state that these channel metrics positively correlate with shifts.\nThus, in real-time, OTT can only rely on them to predict video streaming\nsessions into lower- and higher-resolution categories, thus providing more\nresources to improve user experience. Using traditional Machine Learning (ML)\nclassifiers, we achieved an accuracy of 77-percent, while using only RSRP,\nRSRQ, and SNR. In the era of 5G and beyond, where ultra-reliable, low-latency\nnetworks promise enhanced streaming capabilities, the proposed methodology can\nbe used to improve OTT services."}
{"id": "2504.18004", "pdf": "https://arxiv.org/pdf/2504.18004", "abs": "https://arxiv.org/abs/2504.18004", "authors": ["Daisuke Niizumi", "Daiki Takeuchi", "Masahiro Yasuda", "Binh Thien Nguyen", "Yasunori Ohishi", "Noboru Harada"], "title": "Assessing the Utility of Audio Foundation Models for Heart and Respiratory Sound Analysis", "categories": ["eess.AS", "cs.SD", "68T07", "J.3"], "comment": "4 pages, 1 figure, and 4 tables. Accepted by IEEE EMBC 2025", "summary": "Pre-trained deep learning models, known as foundation models, have become\nessential building blocks in machine learning domains such as natural language\nprocessing and image domains. This trend has extended to respiratory and heart\nsound models, which have demonstrated effectiveness as off-the-shelf feature\nextractors. However, their evaluation benchmarking has been limited, resulting\nin incompatibility with state-of-the-art (SOTA) performance, thus hindering\nproof of their effectiveness. This study investigates the practical\neffectiveness of off-the-shelf audio foundation models by comparing their\nperformance across four respiratory and heart sound tasks with SOTA fine-tuning\nresults. Experiments show that models struggled on two tasks with noisy data\nbut achieved SOTA performance on the other tasks with clean data. Moreover,\ngeneral-purpose audio models outperformed a respiratory sound model,\nhighlighting their broader applicability. With gained insights and the released\ncode, we contribute to future research on developing and leveraging foundation\nmodels for respiratory and heart sounds."}
{"id": "2504.17819", "pdf": "https://arxiv.org/pdf/2504.17819", "abs": "https://arxiv.org/abs/2504.17819", "authors": ["Mohaddeseh Chegini", "Ali Mahloojifar"], "title": "A Deep Bayesian Convolutional Spiking Neural Network-based CAD system with Uncertainty Quantification for Medical Images Classification", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "The Computer_Aided Diagnosis (CAD) systems facilitate accurate diagnosis of\ndiseases. The development of CADs by leveraging third generation neural\nnetwork, namely, Spiking Neural Network (SNN), is essential to utilize of the\nbenefits of SNNs, such as their event_driven processing, parallelism, low power\nconsumption, and the ability to process sparse temporal_spatial information.\nHowever, Deep SNN as a deep learning model faces challenges with unreliability.\nTo deal with unreliability challenges due to inability to quantify the\nuncertainty of the predictions, we proposed a deep Bayesian Convolutional\nSpiking Neural Network based_CADs with uncertainty_aware module. In this study,\nthe Monte Carlo Dropout method as Bayesian approximation is used as an\nuncertainty quantification method. This method was applied to several medical\nimage classification tasks. Our experimental results demonstrate that our\nproposed model is accurate and reliable and will be a proper alternative to\nconventional deep learning for medical image classification."}
{"id": "2504.18053", "pdf": "https://arxiv.org/pdf/2504.18053", "abs": "https://arxiv.org/abs/2504.18053", "authors": ["Jianyu Liu", "Hangyu Guo", "Ranjie Duan", "Xingyuan Bu", "Yancheng He", "Shilong Li", "Hui Huang", "Jiaheng Liu", "Yucheng Wang", "Chenchen Jing", "Xingwei Qu", "Xiao Zhang", "Yingshui Tan", "Yanan Wu", "Jihao Gu", "Yangguang Li", "Jianke Zhu"], "title": "DREAM: Disentangling Risks to Enhance Safety Alignment in Multimodal Large Language Models", "categories": ["cs.CL", "cs.CV"], "comment": "[NAACL 2025] The first four authors contribute equally, 23 pages,\n  repo at https://github.com/Kizna1ver/DREAM", "summary": "Multimodal Large Language Models (MLLMs) pose unique safety challenges due to\ntheir integration of visual and textual data, thereby introducing new\ndimensions of potential attacks and complex risk combinations. In this paper,\nwe begin with a detailed analysis aimed at disentangling risks through\nstep-by-step reasoning within multimodal inputs. We find that systematic\nmultimodal risk disentanglement substantially enhances the risk awareness of\nMLLMs. Via leveraging the strong discriminative abilities of multimodal risk\ndisentanglement, we further introduce \\textbf{DREAM}\n(\\textit{\\textbf{D}isentangling \\textbf{R}isks to \\textbf{E}nhance Safety\n\\textbf{A}lignment in \\textbf{M}LLMs}), a novel approach that enhances safety\nalignment in MLLMs through supervised fine-tuning and iterative Reinforcement\nLearning from AI Feedback (RLAIF). Experimental results show that DREAM\nsignificantly boosts safety during both inference and training phases without\ncompromising performance on normal tasks (namely oversafety), achieving a\n16.17\\% improvement in the SIUO safe\\&effective score compared to GPT-4V. The\ndata and code are available at https://github.com/Kizna1ver/DREAM."}
{"id": "2504.17967", "pdf": "https://arxiv.org/pdf/2504.17967", "abs": "https://arxiv.org/abs/2504.17967", "authors": ["Kevin Song", "Andrew Trotter", "Jake Y. Chen"], "title": "LLM Agent Swarm for Hypothesis-Driven Drug Discovery", "categories": ["cs.AI"], "comment": "15 pages, 3 figures", "summary": "Drug discovery remains a formidable challenge: more than 90 percent of\ncandidate molecules fail in clinical evaluation, and development costs often\nexceed one billion dollars per approved therapy. Disparate data streams, from\ngenomics and transcriptomics to chemical libraries and clinical records, hinder\ncoherent mechanistic insight and slow progress. Meanwhile, large language\nmodels excel at reasoning and tool integration but lack the modular\nspecialization and iterative memory required for regulated, hypothesis-driven\nworkflows. We introduce PharmaSwarm, a unified multi-agent framework that\norchestrates specialized LLM \"agents\" to propose, validate, and refine\nhypotheses for novel drug targets and lead compounds. Each agent accesses\ndedicated functionality--automated genomic and expression analysis; a curated\nbiomedical knowledge graph; pathway enrichment and network simulation;\ninterpretable binding affinity prediction--while a central Evaluator LLM\ncontinuously ranks proposals by biological plausibility, novelty, in silico\nefficacy, and safety. A shared memory layer captures validated insights and\nfine-tunes underlying submodels over time, yielding a self-improving system.\nDeployable on low-code platforms or Kubernetes-based microservices, PharmaSwarm\nsupports literature-driven discovery, omics-guided target identification, and\nmarket-informed repurposing. We also describe a rigorous four-tier validation\npipeline spanning retrospective benchmarking, independent computational assays,\nexperimental testing, and expert user studies to ensure transparency,\nreproducibility, and real-world impact. By acting as an AI copilot, PharmaSwarm\ncan accelerate translational research and deliver high-confidence hypotheses\nmore efficiently than traditional pipelines."}
{"id": "2504.17857", "pdf": "https://arxiv.org/pdf/2504.17857", "abs": "https://arxiv.org/abs/2504.17857", "authors": ["A. J Miller", "Fangzhou Yu", "Michael Brauckmann", "Farbod Farshidian"], "title": "High-Performance Reinforcement Learning on Spot: Optimizing Simulation Parameters with Distributional Measures", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "This work presents an overview of the technical details behind a high\nperformance reinforcement learning policy deployment with the Spot RL\nResearcher Development Kit for low level motor access on Boston Dynamics Spot.\nThis represents the first public demonstration of an end to end end\nreinforcement learning policy deployed on Spot hardware with training code\npublicly available through Nvidia IsaacLab and deployment code available\nthrough Boston Dynamics. We utilize Wasserstein Distance and Maximum Mean\nDiscrepancy to quantify the distributional dissimilarity of data collected on\nhardware and in simulation to measure our sim2real gap. We use these measures\nas a scoring function for the Covariance Matrix Adaptation Evolution Strategy\nto optimize simulated parameters that are unknown or difficult to measure from\nSpot. Our procedure for modeling and training produces high quality\nreinforcement learning policies capable of multiple gaits, including a flight\nphase. We deploy policies capable of over 5.2ms locomotion, more than triple\nSpots default controller maximum speed, robustness to slippery surfaces,\ndisturbance rejection, and overall agility previously unseen on Spot. We detail\nour method and release our code to support future work on Spot with the low\nlevel API."}
{"id": "2504.17810", "pdf": "https://arxiv.org/pdf/2504.17810", "abs": "https://arxiv.org/abs/2504.17810", "authors": ["Yuxin Yao", "Yan Zhang", "Zhening Huang", "Joan Lasenby"], "title": "SmallGS: Gaussian Splatting-based Camera Pose Estimation for Small-Baseline Videos", "categories": ["cs.CV", "eess.IV"], "comment": "10 pages, 4 figures, Accepted by CVPR workshop", "summary": "Dynamic videos with small baseline motions are ubiquitous in daily life,\nespecially on social media. However, these videos present a challenge to\nexisting pose estimation frameworks due to ambiguous features, drift\naccumulation, and insufficient triangulation constraints. Gaussian splatting,\nwhich maintains an explicit representation for scenes, provides a reliable\nnovel view rasterization when the viewpoint change is small. Inspired by this,\nwe propose SmallGS, a camera pose estimation framework that is specifically\ndesigned for small-baseline videos. SmallGS optimizes sequential camera poses\nusing Gaussian splatting, which reconstructs the scene from the first frame in\neach video segment to provide a stable reference for the rest. The temporal\nconsistency of Gaussian splatting within limited viewpoint differences reduced\nthe requirement of sufficient depth variations in traditional camera pose\nestimation. We further incorporate pretrained robust visual features, e.g.\nDINOv2, into Gaussian splatting, where high-dimensional feature map rendering\nenhances the robustness of camera pose estimation. By freezing the Gaussian\nsplatting and optimizing camera viewpoints based on rasterized features,\nSmallGS effectively learns camera poses without requiring explicit feature\ncorrespondences or strong parallax motion. We verify the effectiveness of\nSmallGS in small-baseline videos in TUM-Dynamics sequences, which achieves\nimpressive accuracy in camera pose estimation compared to MonST3R and\nDORID-SLAM for small-baseline videos in dynamic scenes. Our project page is at:\nhttps://yuxinyao620.github.io/SmallGS"}
{"id": "2504.18099", "pdf": "https://arxiv.org/pdf/2504.18099", "abs": "https://arxiv.org/abs/2504.18099", "authors": ["Leena G Pillai", "D. Muhammad Noorul Mubarak", "Elizabeth Sherly"], "title": "Tracking Articulatory Dynamics in Speech with a Fixed-Weight BiLSTM-CNN Architecture", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": "10 pages with 8 figures. This paper presented in an international\n  Conference", "summary": "Speech production is a complex sequential process which involve the\ncoordination of various articulatory features. Among them tongue being a highly\nversatile active articulator responsible for shaping airflow to produce\ntargeted speech sounds that are intellectual, clear, and distinct. This paper\npresents a novel approach for predicting tongue and lip articulatory features\ninvolved in a given speech acoustics using a stacked Bidirectional Long\nShort-Term Memory (BiLSTM) architecture, combined with a one-dimensional\nConvolutional Neural Network (CNN) for post-processing with fixed weights\ninitialization. The proposed network is trained with two datasets consisting of\nsimultaneously recorded speech and Electromagnetic Articulography (EMA)\ndatasets, each introducing variations in terms of geographical origin,\nlinguistic characteristics, phonetic diversity, and recording equipment. The\nperformance of the model is assessed in Speaker Dependent (SD), Speaker\nIndependent (SI), corpus dependent (CD) and cross corpus (CC) modes.\nExperimental results indicate that the proposed model with fixed weights\napproach outperformed the adaptive weights initialization with in relatively\nminimal number of training epochs. These findings contribute to the development\nof robust and efficient models for articulatory feature prediction, paving the\nway for advancements in speech production research and applications."}
{"id": "2501.16606", "pdf": "https://arxiv.org/pdf/2501.16606", "abs": "https://arxiv.org/abs/2501.16606", "authors": ["Tomer Jordi Chaffer"], "title": "Can We Govern the Agent-to-Agent Economy?", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Current approaches to AI governance often fall short in anticipating a future\nwhere AI agents manage critical tasks, such as financial operations,\nadministrative functions, and beyond. While cryptocurrencies could serve as the\nfoundation for monetizing value exchange in a collaboration and delegation\ndynamic among AI agents, a critical question remains: how can humans ensure\nmeaningful oversight and control as a future economy of AI agents scales and\nevolves? In this philosophical exploration, we highlight emerging concepts in\nthe industry to inform research and development efforts in anticipation of a\nfuture decentralized agentic economy."}
{"id": "2504.18283", "pdf": "https://arxiv.org/pdf/2504.18283", "abs": "https://arxiv.org/abs/2504.18283", "authors": ["Minjae Kang", "Martim Brand√£o"], "title": "Seeing Soundscapes: Audio-Visual Generation and Separation from Soundscapes Using Audio-Visual Separator", "categories": ["cs.CV", "cs.AI", "cs.MM", "cs.SD", "eess.AS"], "comment": "Originally submitted to CVPR 2025 on 2024-11-15 with paper ID 15808", "summary": "Recent audio-visual generative models have made substantial progress in\ngenerating images from audio. However, existing approaches focus on generating\nimages from single-class audio and fail to generate images from mixed audio. To\naddress this, we propose an Audio-Visual Generation and Separation model\n(AV-GAS) for generating images from soundscapes (mixed audio containing\nmultiple classes). Our contribution is threefold: First, we propose a new\nchallenge in the audio-visual generation task, which is to generate an image\ngiven a multi-class audio input, and we propose a method that solves this task\nusing an audio-visual separator. Second, we introduce a new audio-visual\nseparation task, which involves generating separate images for each class\npresent in a mixed audio input. Lastly, we propose new evaluation metrics for\nthe audio-visual generation task: Class Representation Score (CRS) and a\nmodified R@K. Our model is trained and evaluated on the VGGSound dataset. We\nshow that our method outperforms the state-of-the-art, achieving 7% higher CRS\nand 4% higher R@2* in generating plausible images with mixed audio."}
{"id": "2504.18157", "pdf": "https://arxiv.org/pdf/2504.18157", "abs": "https://arxiv.org/abs/2504.18157", "authors": ["Suntae Hwang", "Seonghyeon Kang", "Kyungsu Kim", "Semin Ahn", "Kyogu Lee"], "title": "DOSE : Drum One-Shot Extraction from Music Mixture", "categories": ["eess.AS", "cs.SD"], "comment": "Published in IEEE ICASSP 2025", "summary": "Drum one-shot samples are crucial for music production, particularly in sound\ndesign and electronic music. This paper introduces Drum One-Shot Extraction, a\ntask in which the goal is to extract drum one-shots that are present in the\nmusic mixture. To facilitate this, we propose the Random Mixture One-shot\nDataset (RMOD), comprising large-scale, randomly arranged music mixtures paired\nwith corresponding drum one-shot samples. Our proposed model, Drum One- Shot\nExtractor (DOSE), leverages neural audio codec language models for end-to-end\nextraction, bypassing traditional source separation steps. Additionally, we\nintroduce a novel onset loss, designed to encourage accurate prediction of the\ninitial transient of drum one-shots, which is essential for capturing timbral\ncharacteristics. We compare this approach against a source separation-based\nextraction method as a baseline. The results, evaluated using Frechet Audio\nDistance (FAD) and Multi-Scale Spectral loss (MSS), demonstrate that DOSE,\nenhanced with onset loss, outperforms the baseline, providing more accurate and\nhigher-quality drum one-shots from music mixtures. The code, model checkpoint,\nand audio examples are available at https://github.com/HSUNEH/DOSE"}
{"id": "2504.17943", "pdf": "https://arxiv.org/pdf/2504.17943", "abs": "https://arxiv.org/abs/2504.17943", "authors": ["Mingsi Liao", "Gota Morota", "Ye Bi", "Rebecca R. Cockrum"], "title": "Predicting Dairy Calf Body Weight from Depth Images Using Deep Learning (YOLOv8) and Threshold Segmentation with Cross-Validation and Longitudinal Analysis", "categories": ["eess.IV", "cs.CV"], "comment": "Published on Animals, 18 March 2025", "summary": "Monitoring calf body weight (BW) before weaning is essential for assessing\ngrowth, feed efficiency, health, and weaning readiness. However, labor, time,\nand facility constraints limit BW collection. Additionally, Holstein calf coat\npatterns complicate image-based BW estimation, and few studies have explored\nnon-contact measurements taken at early time points for predicting later BW.\nThe objectives of this study were to (1) develop deep learning-based\nsegmentation models for extracting calf body metrics, (2) compare deep learning\nsegmentation with threshold-based methods, and (3) evaluate BW prediction using\nsingle-time-point cross-validation with linear regression (LR) and extreme\ngradient boosting (XGBoost) and multiple-time-point cross-validation with LR,\nXGBoost, and a linear mixed model (LMM). Depth images from Holstein (n = 63)\nand Jersey (n = 5) pre-weaning calves were collected, with 20 Holstein calves\nbeing weighed manually. Results showed that You Only Look Once version 8\n(YOLOv8) deep learning segmentation (intersection over union = 0.98)\noutperformed threshold-based methods (0.89). In single-time-point\ncross-validation, XGBoost achieved the best BW prediction (R^2 = 0.91, mean\nabsolute percentage error (MAPE) = 4.37%), while LMM provided the most accurate\nlongitudinal BW prediction (R^2 = 0.99, MAPE = 2.39%). These findings highlight\nthe potential of deep learning for automated BW prediction, enhancing farm\nmanagement."}
{"id": "2504.18058", "pdf": "https://arxiv.org/pdf/2504.18058", "abs": "https://arxiv.org/abs/2504.18058", "authors": ["Sijia Cheng", "Wen-Yu Chang", "Yun-Nung Chen"], "title": "Exploring Personality-Aware Interactions in Salesperson Dialogue Agents", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by IWSDS 2025", "summary": "The integration of dialogue agents into the sales domain requires a deep\nunderstanding of how these systems interact with users possessing diverse\npersonas. This study explores the influence of user personas, defined using the\nMyers-Briggs Type Indicator (MBTI), on the interaction quality and performance\nof sales-oriented dialogue agents. Through large-scale testing and analysis, we\nassess the pre-trained agent's effectiveness, adaptability, and personalization\ncapabilities across a wide range of MBTI-defined user types. Our findings\nreveal significant patterns in interaction dynamics, task completion rates, and\ndialogue naturalness, underscoring the future potential for dialogue agents to\nrefine their strategies to better align with varying personality traits. This\nwork not only provides actionable insights for building more adaptive and\nuser-centric conversational systems in the sales domain but also contributes\nbroadly to the field by releasing persona-defined user simulators. These\nsimulators, unconstrained by domain, offer valuable tools for future research\nand demonstrate the potential for scaling personalized dialogue systems across\ndiverse applications."}
{"id": "2504.18007", "pdf": "https://arxiv.org/pdf/2504.18007", "abs": "https://arxiv.org/abs/2504.18007", "authors": ["Yazan Otoum", "Amiya Nayak"], "title": "Differential Privacy-Driven Framework for Enhancing Heart Disease Prediction", "categories": ["cs.AI", "cs.CR", "cs.LG"], "comment": "\\c{opyright} 2025 IEEE. Accepted to IEEE International Conference on\n  Communications ICC 2025. Final version to appear in IEEE Xplore", "summary": "With the rapid digitalization of healthcare systems, there has been a\nsubstantial increase in the generation and sharing of private health data.\nSafeguarding patient information is essential for maintaining consumer trust\nand ensuring compliance with legal data protection regulations. Machine\nlearning is critical in healthcare, supporting personalized treatment, early\ndisease detection, predictive analytics, image interpretation, drug discovery,\nefficient operations, and patient monitoring. It enhances decision-making,\naccelerates research, reduces errors, and improves patient outcomes. In this\npaper, we utilize machine learning methodologies, including differential\nprivacy and federated learning, to develop privacy-preserving models that\nenable healthcare stakeholders to extract insights without compromising\nindividual privacy. Differential privacy introduces noise to data to guarantee\nstatistical privacy, while federated learning enables collaborative model\ntraining across decentralized datasets. We explore applying these technologies\nto Heart Disease Data, demonstrating how they preserve privacy while delivering\nvaluable insights and comprehensive analysis. Our results show that using a\nfederated learning model with differential privacy achieved a test accuracy of\n85%, ensuring patient data remained secure and private throughout the process."}
{"id": "2504.17891", "pdf": "https://arxiv.org/pdf/2504.17891", "abs": "https://arxiv.org/abs/2504.17891", "authors": ["Karmanbir Batth", "Krish Sethi", "Aly Shariff", "Leo Shi", "Hetul Patel"], "title": "Do We Need Transformers to Play FPS Video Games?", "categories": ["cs.LG"], "comment": null, "summary": "In this paper, we explore the Transformer based architectures for\nreinforcement learning in both online and offline settings within the Doom game\nenvironment. Our investigation focuses on two primary approaches: Deep\nTransformer Q- learning Networks (DTQN) for online learning and Decision\nTransformers (DT) for offline reinforcement learning. DTQN leverages the\nsequential modelling capabilities of Transformers to enhance Q-learning in\npartially observable environments,while Decision Transformers repurpose\nsequence modelling techniques to enable offline agents to learn from past\ntrajectories without direct interaction with the environment. We conclude that\nwhile Transformers might have performed well in Atari games, more traditional\nmethods perform better than Transformer based method in both the settings in\nthe VizDoom environment."}
{"id": "2504.17812", "pdf": "https://arxiv.org/pdf/2504.17812", "abs": "https://arxiv.org/abs/2504.17812", "authors": ["Sara Sabour"], "title": "Object Learning and Robust 3D Reconstruction", "categories": ["cs.CV", "eess.IV"], "comment": "PhD Thesis", "summary": "In this thesis we discuss architectural designs and training methods for a\nneural network to have the ability of dissecting an image into objects of\ninterest without supervision. The main challenge in 2D unsupervised object\nsegmentation is distinguishing between foreground objects of interest and\nbackground. FlowCapsules uses motion as a cue for the objects of interest in 2D\nscenarios. The last part of this thesis focuses on 3D applications where the\ngoal is detecting and removal of the object of interest from the input images.\nIn these tasks, we leverage the geometric consistency of scenes in 3D to detect\nthe inconsistent dynamic objects. Our transient object masks are then used for\ndesigning robust optimization kernels to improve 3D modelling in a casual\ncapture setup. One of our goals in this thesis is to show the merits of\nunsupervised object based approaches in computer vision. Furthermore, we\nsuggest possible directions for defining objects of interest or foreground\nobjects without requiring supervision. Our hope is to motivate and excite the\ncommunity into further exploring explicit object representations in image\nunderstanding tasks."}
{"id": "2504.18425", "pdf": "https://arxiv.org/pdf/2504.18425", "abs": "https://arxiv.org/abs/2504.18425", "authors": ["KimiTeam", "Ding Ding", "Zeqian Ju", "Yichong Leng", "Songxiang Liu", "Tong Liu", "Zeyu Shang", "Kai Shen", "Wei Song", "Xu Tan", "Heyi Tang", "Zhengtao Wang", "Chu Wei", "Yifei Xin", "Xinran Xu", "Jianwei Yu", "Yutao Zhang", "Xinyu Zhou", "Y. Charles", "Jun Chen", "Yanru Chen", "Yulun Du", "Weiran He", "Zhenxing Hu", "Guokun Lai", "Qingcheng Li", "Yangyang Liu", "Weidong Sun", "Jianzhou Wang", "Yuzhi Wang", "Yuefeng Wu", "Yuxin Wu", "Dongchao Yang", "Hao Yang", "Ying Yang", "Zhilin Yang", "Aoxiong Yin", "Ruibin Yuan", "Yutong Zhang", "Zaida Zhou"], "title": "Kimi-Audio Technical Report", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.MM", "cs.SD"], "comment": null, "summary": "We present Kimi-Audio, an open-source audio foundation model that excels in\naudio understanding, generation, and conversation. We detail the practices in\nbuilding Kimi-Audio, including model architecture, data curation, training\nrecipe, inference deployment, and evaluation. Specifically, we leverage a\n12.5Hz audio tokenizer, design a novel LLM-based architecture with continuous\nfeatures as input and discrete tokens as output, and develop a chunk-wise\nstreaming detokenizer based on flow matching. We curate a pre-training dataset\nthat consists of more than 13 million hours of audio data covering a wide range\nof modalities including speech, sound, and music, and build a pipeline to\nconstruct high-quality and diverse post-training data. Initialized from a\npre-trained LLM, Kimi-Audio is continual pre-trained on both audio and text\ndata with several carefully designed tasks, and then fine-tuned to support a\ndiverse of audio-related tasks. Extensive evaluation shows that Kimi-Audio\nachieves state-of-the-art performance on a range of audio benchmarks including\nspeech recognition, audio understanding, audio question answering, and speech\nconversation. We release the codes, model checkpoints, as well as the\nevaluation toolkits in https://github.com/MoonshotAI/Kimi-Audio."}
{"id": "2404.10263", "pdf": "https://arxiv.org/pdf/2404.10263", "abs": "https://arxiv.org/abs/2404.10263", "authors": ["Yuning Wang", "Zhiyuan Liu", "Haotian Lin", "Junkai Jiang", "Shaobing Xu", "Jianqiang Wang"], "title": "PreGSU-A Generalized Traffic Scene Understanding Model for Autonomous Driving based on Pre-trained Graph Attention Network", "categories": ["cs.CV", "cs.MA"], "comment": "14 pages", "summary": "Scene understanding, defined as learning, extraction, and representation of\ninteractions among traffic elements, is one of the critical challenges toward\nhigh-level autonomous driving (AD). Current scene understanding methods mainly\nfocus on one concrete single task, such as trajectory prediction and risk level\nevaluation. Although they perform well on specific metrics, the generalization\nability is insufficient to adapt to the real traffic complexity and downstream\ndemand diversity. In this study, we propose PreGSU, a generalized pre-trained\nscene understanding model based on graph attention network to learn the\nuniversal interaction and reasoning of traffic scenes to support various\ndownstream tasks. After the feature engineering and sub-graph module, all\nelements are embedded as nodes to form a dynamic weighted graph. Then, four\ngraph attention layers are applied to learn the relationships among agents and\nlanes. In the pre-train phase, the understanding model is trained on two\nself-supervised tasks: Virtual Interaction Force (VIF) modeling and Masked Road\nModeling (MRM). Based on the artificial potential field theory, VIF modeling\nenables PreGSU to capture the agent-to-agent interactions while MRM extracts\nagent-to-road connections. In the fine-tuning process, the pre-trained\nparameters are loaded to derive detailed understanding outputs. We conduct\nvalidation experiments on three datasets and two downstream tasks, i.e.,\ntrajectory prediction in urban scenario and intention recognition in highway\nscenario, to verify the model's generalization and understanding capabilities.\nResults show that compared with single-task-driven baselines, PreGSU achieves\ncompetitive performance on all datasets and downstream tasks, indicating its\npotential to be generalized to various scenes and targets. Ablation study shows\nthe effectiveness of pre-train task design."}
{"id": "2412.08988", "pdf": "https://arxiv.org/pdf/2412.08988", "abs": "https://arxiv.org/abs/2412.08988", "authors": ["Gaoxiang Cong", "Jiadong Pan", "Liang Li", "Yuankai Qi", "Yuxin Peng", "Anton van den Hengel", "Jian Yang", "Qingming Huang"], "title": "EmoDubber: Towards High Quality and Emotion Controllable Movie Dubbing", "categories": ["cs.SD", "cs.MM", "eess.AS"], "comment": "Accepted to CVPR 2025", "summary": "Given a piece of text, a video clip, and a reference audio, the movie dubbing\ntask aims to generate speech that aligns with the video while cloning the\ndesired voice. The existing methods have two primary deficiencies: (1) They\nstruggle to simultaneously hold audio-visual sync and achieve clear\npronunciation; (2) They lack the capacity to express user-defined emotions. To\naddress these problems, we propose EmoDubber, an emotion-controllable dubbing\narchitecture that allows users to specify emotion type and emotional intensity\nwhile satisfying high-quality lip sync and pronunciation. Specifically, we\nfirst design Lip-related Prosody Aligning (LPA), which focuses on learning the\ninherent consistency between lip motion and prosody variation by duration level\ncontrastive learning to incorporate reasonable alignment. Then, we design\nPronunciation Enhancing (PE) strategy to fuse the video-level phoneme sequences\nby efficient conformer to improve speech intelligibility. Next, the speaker\nidentity adapting module aims to decode acoustics prior and inject the speaker\nstyle embedding. After that, the proposed Flow-based User Emotion Controlling\n(FUEC) is used to synthesize waveform by flow matching prediction network\nconditioned on acoustics prior. In this process, the FUEC determines the\ngradient direction and guidance scale based on the user's emotion instructions\nby the positive and negative guidance mechanism, which focuses on amplifying\nthe desired emotion while suppressing others. Extensive experimental results on\nthree benchmark datasets demonstrate favorable performance compared to several\nstate-of-the-art methods."}
{"id": "2504.18502", "pdf": "https://arxiv.org/pdf/2504.18502", "abs": "https://arxiv.org/abs/2504.18502", "authors": ["Zhanhong He", "Roberto Togneri", "Xiangyu Zhang"], "title": "Music Tempo Estimation on Solo Instrumental Performance", "categories": ["eess.AS", "cs.IR", "68T07", "H.5.5"], "comment": "4 pages, rejected paper by WASPAA2023", "summary": "Recently, automatic music transcription has made it possible to convert\nmusical audio into accurate MIDI. However, the resulting MIDI lacks music\nnotations such as tempo, which hinders its conversion into sheet music. In this\npaper, we investigate state-of-the-art tempo estimation techniques and evaluate\ntheir performance on solo instrumental music. These include temporal\nconvolutional network (TCN) and recurrent neural network (RNN) models that are\npretrained on massive of mixed vocals and instrumental music, as well as TCN\nmodels trained specifically with solo instrumental performances. Through\nevaluations on drum, guitar, and classical piano datasets, our TCN models with\nthe new training scheme achieved the best performance. Our newly trained TCN\nmodel increases the Acc1 metric by 38.6% for guitar tempo estimation, compared\nto the pretrained TCN model with an Acc1 of 61.1%. Although our trained TCN\nmodel is twice as accurate as the pretrained TCN model in estimating classical\npiano tempo, its Acc1 is only 50.9%. To improve the performance of deep\nlearning models, we investigate their combinations with various post-processing\nmethods. These post-processing techniques effectively enhance the performance\nof deep learning models when they struggle to estimate the tempo of specific\ninstruments."}
{"id": "2504.17945", "pdf": "https://arxiv.org/pdf/2504.17945", "abs": "https://arxiv.org/abs/2504.17945", "authors": ["Bastien C. Baluyot", "Marta Varela", "Chen Qin"], "title": "Spectral Bias Correction in PINNs for Myocardial Image Registration of Pathological Data", "categories": ["eess.IV", "cs.CV"], "comment": "6 pages, 3 figures, 3 tables", "summary": "Accurate myocardial image registration is essential for cardiac strain\nanalysis and disease diagnosis. However, spectral bias in neural networks\nimpedes modeling high-frequency deformations, producing inaccurate,\nbiomechanically implausible results, particularly in pathological data. This\npaper addresses spectral bias in physics-informed neural networks (PINNs) by\nintegrating Fourier Feature mappings and introducing modulation strategies into\na PINN framework. Experiments on two distinct datasets demonstrate that the\nproposed methods enhance the PINN's ability to capture complex, high-frequency\ndeformations in cardiomyopathies, achieving superior registration accuracy\nwhile maintaining biomechanical plausibility - thus providing a foundation for\nscalable cardiac image registration and generalization across multiple patients\nand pathologies."}
{"id": "2504.18070", "pdf": "https://arxiv.org/pdf/2504.18070", "abs": "https://arxiv.org/abs/2504.18070", "authors": ["Jingjin Wang"], "title": "PropRAG: Guiding Retrieval with Beam Search over Proposition Paths", "categories": ["cs.CL", "cs.AI"], "comment": "Code and data to be released at:\n  https://github.com/ReLink-Inc/PropRAG", "summary": "Retrieval Augmented Generation (RAG) has become the standard non-parametric\napproach for equipping Large Language Models (LLMs) with up-to-date knowledge\nand mitigating catastrophic forgetting common in continual learning. However,\nstandard RAG, relying on independent passage retrieval, fails to capture the\ninterconnected nature of human memory crucial for complex reasoning\n(associativity) and contextual understanding (sense-making). While structured\nRAG methods like HippoRAG utilize knowledge graphs (KGs) built from triples,\nthe inherent context loss limits fidelity. We introduce PropRAG, a framework\nleveraging contextually rich propositions and a novel beam search algorithm\nover proposition paths to explicitly discover multi-step reasoning chains.\nCrucially, PropRAG's online retrieval process operates entirely without\ninvoking generative LLMs, relying instead on efficient graph traversal and\npre-computed embeddings. This avoids online LLM inference costs and potential\ninconsistencies during evidence gathering. LLMs are used effectively offline\nfor high-quality proposition extraction and post-retrieval for answer\ngeneration. PropRAG achieves state-of-the-art zero-shot Recall@5 results on\nPopQA (55.3%), 2Wiki (93.7%), HotpotQA (97.0%), and MuSiQue (77.3%), alongside\ntop F1 scores (e.g., 52.4% on MuSiQue). By improving evidence retrieval through\nricher representation and explicit, LLM-free online path finding, PropRAG\nadvances non-parametric continual learning."}
{"id": "2504.18039", "pdf": "https://arxiv.org/pdf/2504.18039", "abs": "https://arxiv.org/abs/2504.18039", "authors": ["Zheng Zhang", "Nuoqian Xiao", "Qi Chai", "Deheng Ye", "Hao Wang"], "title": "MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Model (LLM) agents have demonstrated impressive capabilities\nin social deduction games (SDGs) like Werewolf, where strategic reasoning and\nsocial deception are essential. However, current approaches remain limited to\ntextual information, ignoring crucial multimodal cues such as facial\nexpressions and tone of voice that humans naturally use to communicate.\nMoreover, existing SDG agents primarily focus on inferring other players'\nidentities without modeling how others perceive themselves or fellow players.\nTo address these limitations, we use One Night Ultimate Werewolf (ONUW) as a\ntestbed and present MultiMind, the first framework integrating multimodal\ninformation into SDG agents. MultiMind processes facial expressions and vocal\ntones alongside verbal content, while employing a Theory of Mind (ToM) model to\nrepresent each player's suspicion levels toward others. By combining this ToM\nmodel with Monte Carlo Tree Search (MCTS), our agent identifies communication\nstrategies that minimize suspicion directed at itself. Through comprehensive\nevaluation in both agent-versus-agent simulations and studies with human\nplayers, we demonstrate MultiMind's superior performance in gameplay. Our work\npresents a significant advancement toward LLM agents capable of human-like\nsocial reasoning across multimodal domains."}
{"id": "2504.17908", "pdf": "https://arxiv.org/pdf/2504.17908", "abs": "https://arxiv.org/abs/2504.17908", "authors": ["Luiz Antonio Nicolau Anghinoni", "Gustavo Weber Denardin", "Jadson Castro Gertrudes", "Dalcimar Casanova", "Jefferson Tales Oliva"], "title": "The use of Multi-domain Electroencephalogram Representations in the building of Models based on Convolutional and Recurrent Neural Networks for Epilepsy Detection", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Epilepsy, affecting approximately 50 million people globally, is\ncharacterized by abnormal brain activity and remains challenging to treat. The\ndiagnosis of epilepsy relies heavily on electroencephalogram (EEG) data, where\nspecialists manually analyze epileptiform patterns across pre-ictal, ictal,\npost-ictal, and interictal periods. However, the manual analysis of EEG signals\nis prone to variability between experts, emphasizing the need for automated\nsolutions. Although previous studies have explored preprocessing techniques and\nmachine learning approaches for seizure detection, there is a gap in\nunderstanding how the representation of EEG data (time, frequency, or\ntime-frequency domains) impacts the predictive performance of deep learning\nmodels. This work addresses this gap by systematically comparing deep neural\nnetworks trained on EEG data in these three domains. Through the use of\nstatistical tests, we identify the optimal data representation and model\narchitecture for epileptic seizure detection. The results demonstrate that\nfrequency-domain data achieves detection metrics exceeding 97\\%, providing a\nrobust foundation for more accurate and reliable seizure detection systems."}
{"id": "2504.17813", "pdf": "https://arxiv.org/pdf/2504.17813", "abs": "https://arxiv.org/abs/2504.17813", "authors": ["Dileepa Pitawela", "Gustavo Carneiro", "Hsiang-Ting Chen"], "title": "CLOC: Contrastive Learning for Ordinal Classification with Multi-Margin N-pair Loss", "categories": ["cs.CV"], "comment": "Accepted in CVPR 2025", "summary": "In ordinal classification, misclassifying neighboring ranks is common, yet\nthe consequences of these errors are not the same. For example, misclassifying\nbenign tumor categories is less consequential, compared to an error at the\npre-cancerous to cancerous threshold, which could profoundly influence\ntreatment choices. Despite this, existing ordinal classification methods do not\naccount for the varying importance of these margins, treating all neighboring\nclasses as equally significant. To address this limitation, we propose CLOC, a\nnew margin-based contrastive learning method for ordinal classification that\nlearns an ordered representation based on the optimization of multiple margins\nwith a novel multi-margin n-pair loss (MMNP). CLOC enables flexible decision\nboundaries across key adjacent categories, facilitating smooth transitions\nbetween classes and reducing the risk of overfitting to biases present in the\ntraining data. We provide empirical discussion regarding the properties of MMNP\nand show experimental results on five real-world image datasets (Adience,\nHistorical Colour Image Dating, Knee Osteoarthritis, Indian Diabetic\nRetinopathy Image, and Breast Carcinoma Subtyping) and one synthetic dataset\nsimulating clinical decision bias. Our results demonstrate that CLOC\noutperforms existing ordinal classification methods and show the\ninterpretability and controllability of CLOC in learning meaningful, ordered\nrepresentations that align with clinical and practical needs."}
{"id": "2503.22712", "pdf": "https://arxiv.org/pdf/2503.22712", "abs": "https://arxiv.org/abs/2503.22712", "authors": ["Zijun Jia"], "title": "Coverage-Guaranteed Speech Emotion Recognition via Calibrated Uncertainty-Adaptive Prediction Sets", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": null, "summary": "Road rage, driven by emotional outbursts, endangers road and public safety.\nSpeech Emotion Recognition (SER) can detect early negative emotions to reduce\naccidents, but traditional methods (e.g., HMMs, LSTMs) using 1D speech signals\nface overfitting and miscalibration issues. This paper proposes a risk\nmanagement framework ensuring statistically rigorous correctness coverage for\ntest data. We separate a calibration set, design a binary loss function to\ncheck if ground-truth labels are in prediction sets, calibrated by data-driven\nthreshold $\\lambda$. A joint loss function on the calibration set adjusts\n$\\lambda$ according to user-specified risk level $\\alpha$, bounding the test\nloss expectation by $\\alpha$. Evaluations on 6 models across 2 datasets show\nour framework strictly maintains average correctness coverage $\\geq 1-\\alpha$\nand controls marginal error rates under various calibration-test splits (e.g.,\n0.1). Additionally, a small-batch online calibration framework based on local\nexchangeability is proposed for complex scenarios with data domain offset or\nnon-IID batches. By constructing a non-negative test martingale, it ensures\nprediction set coverage in dynamic environments, validated via cross-dataset\nexperiments."}
{"id": "2501.01136", "pdf": "https://arxiv.org/pdf/2501.01136", "abs": "https://arxiv.org/abs/2501.01136", "authors": ["Nikolaos Bousias", "Stefanos Pertigkiozoglou", "Kostas Daniilidis", "George Pappas"], "title": "Symmetries-enhanced Multi-Agent Reinforcement Learning", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA", "math.RT"], "comment": null, "summary": "Multi-agent reinforcement learning has emerged as a powerful framework for\nenabling agents to learn complex, coordinated behaviors but faces persistent\nchallenges regarding its generalization, scalability and sample efficiency.\nRecent advancements have sought to alleviate those issues by embedding\nintrinsic symmetries of the systems in the policy. Yet, most dynamical systems\nexhibit little to no symmetries to exploit. This paper presents a novel\nframework for embedding extrinsic symmetries in multi-agent system dynamics\nthat enables the use of symmetry-enhanced methods to address systems with\ninsufficient intrinsic symmetries, expanding the scope of equivariant learning\nto a wide variety of MARL problems. Central to our framework is the Group\nEquivariant Graphormer, a group-modular architecture specifically designed for\ndistributed swarming tasks. Extensive experiments on a swarm of\nsymmetry-breaking quadrotors validate the effectiveness of our approach,\nshowcasing its potential for improved generalization and zero-shot scalability.\nOur method achieves significant reductions in collision rates and enhances task\nsuccess rates across a diverse range of scenarios and varying swarm sizes."}
{"id": "2406.02566", "pdf": "https://arxiv.org/pdf/2406.02566", "abs": "https://arxiv.org/abs/2406.02566", "authors": ["Ognjen Kundacina", "Vladimir Vincan", "Dragisa Miskovic"], "title": "Combining X-Vectors and Bayesian Batch Active Learning: Two-Stage Active Learning Pipeline for Speech Recognition", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "This paper introduces a novel two-stage active learning (AL) pipeline for\nautomatic speech recognition (ASR), combining unsupervised and supervised AL\nmethods. The first stage utilizes unsupervised AL by using x-vectors clustering\nfor diverse sample selection from unlabeled speech data, thus establishing a\nrobust initial dataset for the subsequent supervised AL. The second stage\nincorporates a supervised AL strategy, with a batch AL method specifically\ndeveloped for ASR, aimed at selecting diverse and informative batches of\nsamples. Here, sample diversity is also achieved using x-vectors clustering,\nwhile the most informative samples are identified using a Bayesian AL method\ntailored for ASR with an adaptation of Monte Carlo dropout to approximate\nBayesian inference. This approach enables precise uncertainty estimation,\nthereby enhancing ASR model training with significantly reduced data\nrequirements. Our method has shown superior performance compared to competing\nmethods on homogeneous, heterogeneous, and OOD test sets, demonstrating that\nstrategic sample selection and innovative Bayesian modeling can substantially\noptimize both labeling effort and data utilization in deep learning-based ASR\napplications."}
{"id": "2504.18067", "pdf": "https://arxiv.org/pdf/2504.18067", "abs": "https://arxiv.org/abs/2504.18067", "authors": ["Chuyu Wang", "Huiting Deng", "Dong Liu"], "title": "Physics-Driven Neural Compensation For Electrical Impedance Tomography", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Electrical Impedance Tomography (EIT) provides a non-invasive, portable\nimaging modality with significant potential in medical and industrial\napplications. Despite its advantages, EIT encounters two primary challenges:\nthe ill-posed nature of its inverse problem and the spatially variable,\nlocation-dependent sensitivity distribution. Traditional model-based methods\nmitigate ill-posedness through regularization but overlook sensitivity\nvariability, while supervised deep learning approaches require extensive\ntraining data and lack generalization. Recent developments in neural fields\nhave introduced implicit regularization techniques for image reconstruction,\nbut these methods typically neglect the physical principles underlying EIT,\nthus limiting their effectiveness. In this study, we propose PhyNC\n(Physics-driven Neural Compensation), an unsupervised deep learning framework\nthat incorporates the physical principles of EIT. PhyNC addresses both the\nill-posed inverse problem and the sensitivity distribution by dynamically\nallocating neural representational capacity to regions with lower sensitivity,\nensuring accurate and balanced conductivity reconstructions. Extensive\nevaluations on both simulated and experimental data demonstrate that PhyNC\noutperforms existing methods in terms of detail preservation and artifact\nresistance, particularly in low-sensitivity regions. Our approach enhances the\nrobustness of EIT reconstructions and provides a flexible framework that can be\nadapted to other imaging modalities with similar challenges."}
{"id": "2504.18080", "pdf": "https://arxiv.org/pdf/2504.18080", "abs": "https://arxiv.org/abs/2504.18080", "authors": ["Wataru Kawakami", "Keita Suzuki", "Junichiro Iwasawa"], "title": "Stabilizing Reasoning in Medical LLMs with Continued Pretraining and Reasoning Preference Optimization", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) show potential in medicine, yet clinical\nadoption is hindered by concerns over factual accuracy, language-specific\nlimitations (e.g., Japanese), and critically, their reliability when required\nto generate reasoning explanations -- a prerequisite for trust. This paper\nintroduces Preferred-MedLLM-Qwen-72B, a 72B-parameter model optimized for the\nJapanese medical domain to achieve both high accuracy and stable reasoning. We\nemploy a two-stage fine-tuning process on the Qwen2.5-72B base model: first,\nContinued Pretraining (CPT) on a comprehensive Japanese medical corpus instills\ndeep domain knowledge. Second, Reasoning Preference Optimization (RPO), a\npreference-based method, enhances the generation of reliable reasoning pathways\nwhile preserving high answer accuracy. Evaluations on the Japanese Medical\nLicensing Exam benchmark (IgakuQA) show Preferred-MedLLM-Qwen-72B achieves\nstate-of-the-art performance (0.868 accuracy), surpassing strong proprietary\nmodels like GPT-4o (0.866). Crucially, unlike baseline or CPT-only models which\nexhibit significant accuracy degradation (up to 11.5\\% and 3.8\\% respectively\non IgakuQA) when prompted for explanations, our model maintains its high\naccuracy (0.868) under such conditions. This highlights RPO's effectiveness in\nstabilizing reasoning generation. This work underscores the importance of\noptimizing for reliable explanations alongside accuracy. We release the\nPreferred-MedLLM-Qwen-72B model weights to foster research into trustworthy\nLLMs for specialized, high-stakes applications."}
{"id": "2504.18096", "pdf": "https://arxiv.org/pdf/2504.18096", "abs": "https://arxiv.org/abs/2504.18096", "authors": ["Xiang Li", "Haixu Ma", "Guanyong Wu", "Shi Mu", "Chen Li", "Shunpan Liang"], "title": "Combating the Bucket Effect:Multi-Knowledge Alignment for Medication Recommendation", "categories": ["cs.AI", "cs.LG"], "comment": "18 pages, 5 figures", "summary": "Medication recommendation is crucial in healthcare, offering effective\ntreatments based on patient's electronic health records (EHR). Previous studies\nshow that integrating more medication-related knowledge improves medication\nrepresentation accuracy. However, not all medications encompass multiple types\nof knowledge data simultaneously. For instance, some medications provide only\ntextual descriptions without structured data. This imbalance in data\navailability limits the performance of existing models, a challenge we term the\n\"bucket effect\" in medication recommendation. Our data analysis uncovers the\nseverity of the \"bucket effect\" in medication recommendation. To fill this gap,\nwe introduce a cross-modal medication encoder capable of seamlessly aligning\ndata from different modalities and propose a medication recommendation\nframework to integrate Multiple types of Knowledge, named MKMed. Specifically,\nwe first pre-train a cross-modal encoder with contrastive learning on five\nknowledge modalities, aligning them into a unified space. Then, we combine the\nmulti-knowledge medication representations with patient records for\nrecommendations. Extensive experiments on the MIMIC-III and MIMIC-IV datasets\ndemonstrate that MKMed mitigates the \"bucket effect\" in data, and significantly\noutperforms state-of-the-art baselines in recommendation accuracy and safety."}
{"id": "2504.17913", "pdf": "https://arxiv.org/pdf/2504.17913", "abs": "https://arxiv.org/abs/2504.17913", "authors": ["Mert Sonmezer", "Seyda Ertekin"], "title": "CANet: ChronoAdaptive Network for Enhanced Long-Term Time Series Forecasting under Non-Stationarity", "categories": ["cs.LG"], "comment": null, "summary": "Long-term time series forecasting plays a pivotal role in various real-world\napplications. Despite recent advancements and the success of different\narchitectures, forecasting is often challenging due to non-stationary nature of\nthe real-world data, which frequently exhibit distribution shifts and temporal\nchanges in statistical properties like mean and variance over time. Previous\nstudies suggest that this inherent variability complicates forecasting,\nlimiting the performance of many models by leading to loss of non-stationarity\nand resulting in over-stationarization (Liu, Wu, Wang and Long, 2022). To\naddress this challenge, we introduce a novel architecture, ChoronoAdaptive\nNetwork (CANet), inspired by style-transfer techniques. The core of CANet is\nthe Non-stationary Adaptive Normalization module, seamlessly integrating the\nStyle Blending Gate and Adaptive Instance Normalization (AdaIN) (Huang and\nBelongie, 2017). The Style Blending Gate preserves and reintegrates\nnon-stationary characteristics, such as mean and standard deviation, by\nblending internal and external statistics, preventing over-stationarization\nwhile maintaining essential temporal dependencies. Coupled with AdaIN, which\ndynamically adapts the model to statistical changes, this approach enhances\npredictive accuracy under non-stationary conditions. CANet also employs\nmulti-resolution patching to handle short-term fluctuations and long-term\ntrends, along with Fourier analysis-based adaptive thresholding to reduce\nnoise. A Stacked Kronecker Product Layer further optimizes the model's\nefficiency while maintaining high performance. Extensive experiments on\nreal-world datasets validate CANet's superiority over state-of-the-art methods,\nachieving a 42% reduction in MSE and a 22% reduction in MAE. The source code is\npublicly available at https://github.com/mertsonmezer/CANet."}
{"id": "2504.17815", "pdf": "https://arxiv.org/pdf/2504.17815", "abs": "https://arxiv.org/abs/2504.17815", "authors": ["Mingxuan Cui", "Qing Guo", "Yuyi Wang", "Hongkai Yu", "Di Lin", "Qin Zou", "Ming-Ming Cheng", "Xi Li"], "title": "Visibility-Uncertainty-guided 3D Gaussian Inpainting via Scene Conceptional Learning", "categories": ["cs.CV"], "comment": "14 pages, 12 figures, ICCV", "summary": "3D Gaussian Splatting (3DGS) has emerged as a powerful and efficient 3D\nrepresentation for novel view synthesis. This paper extends 3DGS capabilities\nto inpainting, where masked objects in a scene are replaced with new contents\nthat blend seamlessly with the surroundings. Unlike 2D image inpainting, 3D\nGaussian inpainting (3DGI) is challenging in effectively leveraging\ncomplementary visual and semantic cues from multiple input views, as occluded\nareas in one view may be visible in others. To address this, we propose a\nmethod that measures the visibility uncertainties of 3D points across different\ninput views and uses them to guide 3DGI in utilizing complementary visual cues.\nWe also employ uncertainties to learn a semantic concept of scene without the\nmasked object and use a diffusion model to fill masked objects in input images\nbased on the learned concept. Finally, we build a novel 3DGI framework, VISTA,\nby integrating VISibility-uncerTainty-guided 3DGI with scene conceptuAl\nlearning. VISTA generates high-quality 3DGS models capable of synthesizing\nartifact-free and naturally inpainted novel views. Furthermore, our approach\nextends to handling dynamic distractors arising from temporal object changes,\nenhancing its versatility in diverse scene reconstruction scenarios. We\ndemonstrate the superior performance of our method over state-of-the-art\ntechniques using two challenging datasets: the SPIn-NeRF dataset, featuring 10\ndiverse static 3D inpainting scenes, and an underwater 3D inpainting dataset\nderived from UTB180, including fast-moving fish as inpainting targets."}
{"id": "2504.08907", "pdf": "https://arxiv.org/pdf/2504.08907", "abs": "https://arxiv.org/abs/2504.08907", "authors": ["Ayushi Mishra", "Yang Bai", "Priyadarshan Narayanasamy", "Nakul Garg", "Nirupam Roy"], "title": "Spatial Audio Processing with Large Language Model on Wearable Devices", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": null, "summary": "Integrating spatial context into large language models (LLMs) has the\npotential to revolutionize human-computer interaction, particularly in wearable\ndevices. In this work, we present a novel system architecture that incorporates\nspatial speech understanding into LLMs, enabling contextually aware and\nadaptive applications for wearable technologies. Our approach leverages\nmicrostructure-based spatial sensing to extract precise Direction of Arrival\n(DoA) information using a monaural microphone. To address the lack of existing\ndataset for microstructure-assisted speech recordings, we synthetically create\na dataset called OmniTalk by using the LibriSpeech dataset. This spatial\ninformation is fused with linguistic embeddings from OpenAI's Whisper model,\nallowing each modality to learn complementary contextual representations. The\nfused embeddings are aligned with the input space of LLaMA-3.2 3B model and\nfine-tuned with lightweight adaptation technique LoRA to optimize for on-device\nprocessing. SING supports spatially-aware automatic speech recognition (ASR),\nachieving a mean error of $25.72^\\circ$-a substantial improvement compared to\nthe 88.52$^\\circ$ median error in existing work-with a word error rate (WER) of\n5.3. SING also supports soundscaping, for example, inference how many people\nwere talking and their directions, with up to 5 people and a median DoA error\nof 16$^\\circ$. Our system demonstrates superior performance in spatial speech\nunderstanding while addressing the challenges of power efficiency, privacy, and\nhardware constraints, paving the way for advanced applications in augmented\nreality, accessibility, and immersive experiences."}
{"id": "2502.08857", "pdf": "https://arxiv.org/pdf/2502.08857", "abs": "https://arxiv.org/abs/2502.08857", "authors": ["Xin Wang", "H√©ctor Delgado", "Hemlata Tak", "Jee-weon Jung", "Hye-jin Shim", "Massimiliano Todisco", "Ivan Kukanov", "Xuechen Liu", "Md Sahidullah", "Tomi Kinnunen", "Nicholas Evans", "Kong Aik Lee", "Junichi Yamagishi", "Myeonghun Jeong", "Ge Zhu", "Yongyi Zang", "You Zhang", "Soumi Maiti", "Florian Lux", "Nicolas M√ºller", "Wangyou Zhang", "Chengzhe Sun", "Shuwei Hou", "Siwei Lyu", "S√©bastien Le Maguer", "Cheng Gong", "Hanjie Guo", "Liping Chen", "Vishwanath Singh"], "title": "ASVspoof 5: Design, Collection and Validation of Resources for Spoofing, Deepfake, and Adversarial Attack Detection Using Crowdsourced Speech", "categories": ["eess.AS"], "comment": "Database link: https://zenodo.org/records/14498691, Database mirror\n  link: https://huggingface.co/datasets/jungjee/asvspoof5, ASVspoof 5 Challenge\n  Workshop Proceeding: https://www.isca-archive.org/asvspoof_2024/index.html", "summary": "ASVspoof 5 is the fifth edition in a series of challenges which promote the\nstudy of speech spoofing and deepfake attacks as well as the design of\ndetection solutions. We introduce the ASVspoof 5 database which is generated in\na crowdsourced fashion from data collected in diverse acoustic conditions (cf.\nstudio-quality data for earlier ASVspoof databases) and from ~2,000 speakers\n(cf. ~100 earlier). The database contains attacks generated with 32 different\nalgorithms, also crowdsourced, and optimised to varying degrees using new\nsurrogate detection models. Among them are attacks generated with a mix of\nlegacy and contemporary text-to-speech synthesis and voice conversion models,\nin addition to adversarial attacks which are incorporated for the first time.\nASVspoof 5 protocols comprise seven speaker-disjoint partitions. They include\ntwo distinct partitions for the training of different sets of attack models,\ntwo more for the development and evaluation of surrogate detection models, and\nthen three additional partitions which comprise the ASVspoof 5 training,\ndevelopment and evaluation sets. An auxiliary set of data collected from an\nadditional 30k speakers can also be used to train speaker encoders for the\nimplementation of attack algorithms. Also described herein is an experimental\nvalidation of the new ASVspoof 5 database using a set of automatic speaker\nverification and spoof/deepfake baseline detectors. With the exception of\nprotocols and tools for the generation of spoofed/deepfake speech, the\nresources described in this paper, already used by participants of the ASVspoof\n5 challenge in 2024, are now all freely available to the community."}
{"id": "2504.18251", "pdf": "https://arxiv.org/pdf/2504.18251", "abs": "https://arxiv.org/abs/2504.18251", "authors": ["Md Jahidul Islam"], "title": "Adaptive Weight Modified Riesz Mean Filter For High-Density Salt and Pepper Noise Removal", "categories": ["eess.IV"], "comment": "This is a preprint. Submitted to Journal of Electrical Systems and\n  Information Technology (Springer)", "summary": "This paper introduces a novel filter, the Adaptive Weight Modified Riesz Mean\nFilter (AWMRmF), designed for the effective removal of high-density salt and\npepper noise (SPN). AWMRmF integrates a pixel weight function and adaptivity\ncondition inspired by the Different Adaptive Modified Riesz Mean Filter\n(DAMRmF). In my simulations, I evaluated the performance of AWMRmF against\nestablished filters such as Adaptive Frequency Median Filter (AFMF), Adaptive\nWeighted Mean Filter (AWMF), Adaptive Cesaro Mean Filter (ACmF), Adaptive Riesz\nMean Filter (ARmF), and Improved Adaptive Weighted Mean Filter (IAWMF). The\nassessment was conducted on 26 typical test images, varying noise levels from\n60% to 95%. The findings indicate that, in terms of both Peak Signal to Noise\nRatio (PSNR) and Structural Similarity (SSIM) metrics, AWMRmF outperformed\nother state-of-the-art filters. Furthermore, AWMRmF demonstrated superior\nperformance in mean PSNR and SSIM results as well."}
{"id": "2504.18085", "pdf": "https://arxiv.org/pdf/2504.18085", "abs": "https://arxiv.org/abs/2504.18085", "authors": ["Muhammad Mubashar", "Shireen Kudukkil Manchingal", "Fabio Cuzzolin"], "title": "Random-Set Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "comment": "16 pages, 6 figures", "summary": "Large Language Models (LLMs) are known to produce very high-quality tests and\nresponses to our queries. But how much can we trust this generated text? In\nthis paper, we study the problem of uncertainty quantification in LLMs. We\npropose a novel Random-Set Large Language Model (RSLLM) approach which predicts\nfinite random sets (belief functions) over the token space, rather than\nprobability vectors as in classical LLMs. In order to allow so efficiently, we\nalso present a methodology based on hierarchical clustering to extract and use\na budget of \"focal\" subsets of tokens upon which the belief prediction is\ndefined, rather than using all possible collections of tokens, making the\nmethod scalable yet effective. RS-LLMs encode the epistemic uncertainty induced\nin their generation process by the size and diversity of its training set via\nthe size of the credal sets associated with the predicted belief functions. The\nproposed approach is evaluated on CoQA and OBQA datasets using Llama2-7b,\nMistral-7b and Phi-2 models and is shown to outperform the standard model in\nboth datasets in terms of correctness of answer while also showing potential in\nestimating the second level uncertainty in its predictions and providing the\ncapability to detect when its hallucinating."}
{"id": "2504.18443", "pdf": "https://arxiv.org/pdf/2504.18443", "abs": "https://arxiv.org/abs/2504.18443", "authors": ["Simon Dold", "Malte Helmert", "Jakob Nordstr√∂m", "Gabriele R√∂ger", "Tanja Schindler"], "title": "Pseudo-Boolean Proof Logging for Optimal Classical Planning", "categories": ["cs.AI"], "comment": "35th International Conference on Automated Planning and Scheduling\n  (ICAPS'2025)", "summary": "We introduce lower-bound certificates for classical planning tasks, which can\nbe used to prove the unsolvability of a task or the optimality of a plan in a\nway that can be verified by an independent third party. We describe a general\nframework for generating lower-bound certificates based on pseudo-Boolean\nconstraints, which is agnostic to the planning algorithm used.\n  As a case study, we show how to modify the $A^{*}$ algorithm to produce\nproofs of optimality with modest overhead, using pattern database heuristics\nand $h^\\textit{max}$ as concrete examples. The same proof logging approach\nworks for any heuristic whose inferences can be efficiently expressed as\nreasoning over pseudo-Boolean constraints."}
{"id": "2504.17921", "pdf": "https://arxiv.org/pdf/2504.17921", "abs": "https://arxiv.org/abs/2504.17921", "authors": ["Mateo Espinosa Zarlenga", "Gabriele Dominici", "Pietro Barbiero", "Zohreh Shams", "Mateja Jamnik"], "title": "Avoiding Leakage Poisoning: Concept Interventions Under Distribution Shifts", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.HC"], "comment": null, "summary": "In this paper, we investigate how concept-based models (CMs) respond to\nout-of-distribution (OOD) inputs. CMs are interpretable neural architectures\nthat first predict a set of high-level concepts (e.g., stripes, black) and then\npredict a task label from those concepts. In particular, we study the impact of\nconcept interventions (i.e., operations where a human expert corrects a CM's\nmispredicted concepts at test time) on CMs' task predictions when inputs are\nOOD. Our analysis reveals a weakness in current state-of-the-art CMs, which we\nterm leakage poisoning, that prevents them from properly improving their\naccuracy when intervened on for OOD inputs. To address this, we introduce\nMixCEM, a new CM that learns to dynamically exploit leaked information missing\nfrom its concepts only when this information is in-distribution. Our results\nacross tasks with and without complete sets of concept annotations demonstrate\nthat MixCEMs outperform strong baselines by significantly improving their\naccuracy for both in-distribution and OOD samples in the presence and absence\nof concept interventions."}
{"id": "2504.17816", "pdf": "https://arxiv.org/pdf/2504.17816", "abs": "https://arxiv.org/abs/2504.17816", "authors": ["Daneul Kim", "Jingxu Zhang", "Wonjoon Jin", "Sunghyun Cho", "Qi Dai", "Jaesik Park", "Chong Luo"], "title": "Subject-driven Video Generation via Disentangled Identity and Motion", "categories": ["cs.CV", "eess.IV"], "comment": "Project Page :\n  https://carpedkm.github.io/projects/disentangled_sub/index.html", "summary": "We propose to train a subject-driven customized video generation model\nthrough decoupling the subject-specific learning from temporal dynamics in\nzero-shot without additional tuning. A traditional method for video\ncustomization that is tuning-free often relies on large, annotated video\ndatasets, which are computationally expensive and require extensive annotation.\nIn contrast to the previous approach, we introduce the use of an image\ncustomization dataset directly on training video customization models,\nfactorizing the video customization into two folds: (1) identity injection\nthrough image customization dataset and (2) temporal modeling preservation with\na small set of unannotated videos through the image-to-video training method.\nAdditionally, we employ random image token dropping with randomized image\ninitialization during image-to-video fine-tuning to mitigate the copy-and-paste\nissue. To further enhance learning, we introduce stochastic switching during\njoint optimization of subject-specific and temporal features, mitigating\ncatastrophic forgetting. Our method achieves strong subject consistency and\nscalability, outperforming existing video customization models in zero-shot\nsettings, demonstrating the effectiveness of our framework."}
{"id": "1711.08058", "pdf": "https://arxiv.org/pdf/1711.08058", "abs": "https://arxiv.org/abs/1711.08058", "authors": ["Ahmad AbdulKader", "Kareem Nassar", "Mohamed El-Geish", "Daniel Galvez", "Chetan Patil"], "title": "Multiple-Instance, Cascaded Classification for Keyword Spotting in Narrow-Band Audio", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS"], "comment": "Published in the proceedings of NeurIPS 2017 Workshop: Machine\n  Learning on the Phone and other Consumer Devices", "summary": "We propose using cascaded classifiers for a keyword spotting (KWS) task on\nnarrow-band (NB), 8kHz audio acquired in non-IID environments -- a more\nchallenging task than most state-of-the-art KWS systems face. We present a\nmodel that incorporates Deep Neural Networks (DNNs), cascading,\nmultiple-feature representations, and multiple-instance learning. The cascaded\nclassifiers handle the task's class imbalance and reduce power consumption on\ncomputationally-constrained devices via early termination. The KWS system\nachieves a false negative rate of 6% at an hourly false positive rate of 0.75"}
{"id": "2504.18268", "pdf": "https://arxiv.org/pdf/2504.18268", "abs": "https://arxiv.org/abs/2504.18268", "authors": ["Ana Matoso", "Catarina Passarinho", "Marta P. Loureiro", "Jos√© Maria Moreira", "Patr√≠cia Figueiredo", "Rita G. Nunes"], "title": "Towards a deep learning approach for classifying treatment response in glioblastomas", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Glioblastomas are the most aggressive type of glioma, having a 5-year\nsurvival rate of 6.9%. Treatment typically involves surgery, followed by\nradiotherapy and chemotherapy, and frequent magnetic resonance imaging (MRI)\nscans to monitor disease progression. To assess treatment response,\nradiologists use the Response Assessment in Neuro-Oncology (RANO) criteria to\ncategorize the tumor into one of four labels based on imaging and clinical\nfeatures: complete response, partial response, stable disease, and progressive\ndisease. This assessment is very complex and time-consuming. Since deep\nlearning (DL) has been widely used to tackle classification problems, this work\naimed to implement the first DL pipeline for the classification of RANO\ncriteria based on two consecutive MRI acquisitions. The models were trained and\ntested on the open dataset LUMIERE. Five approaches were tested: 1) subtraction\nof input images, 2) different combinations of modalities, 3) different model\narchitectures, 4) different pretraining tasks, and 5) adding clinical data. The\npipeline that achieved the best performance used a Densenet264 considering only\nT1-weighted, T2-weighted, and Fluid Attenuated Inversion Recovery (FLAIR)\nimages as input without any pretraining. A median Balanced Accuracy of 50.96%\nwas achieved. Additionally, explainability methods were applied. Using Saliency\nMaps, the tumor region was often successfully highlighted. In contrast,\nGrad-CAM typically failed to highlight the tumor region, with some exceptions\nobserved in the Complete Response and Progressive Disease classes, where it\neffectively identified the tumor region. These results set a benchmark for\nfuture studies on glioblastoma treatment response assessment based on the RANO\ncriteria while emphasizing the heterogeneity of factors that might play a role\nwhen assessing the tumor's response to treatment."}
{"id": "2504.18104", "pdf": "https://arxiv.org/pdf/2504.18104", "abs": "https://arxiv.org/abs/2504.18104", "authors": ["Yinglong Yu", "Hao Shen", "Zhengyi Lyu", "Qi He"], "title": "Application and Optimization of Large Models Based on Prompt Tuning for Fact-Check-Worthiness Estimation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In response to the growing problem of misinformation in the context of\nglobalization and informatization, this paper proposes a classification method\nfor fact-check-worthiness estimation based on prompt tuning. We construct a\nmodel for fact-check-worthiness estimation at the methodological level using\nprompt tuning. By applying designed prompt templates to large language models,\nwe establish in-context learning and leverage prompt tuning technology to\nimprove the accuracy of determining whether claims have fact-check-worthiness,\nparticularly when dealing with limited or unlabeled data. Through extensive\nexperiments on public datasets, we demonstrate that the proposed method\nsurpasses or matches multiple baseline methods in the classification task of\nfact-check-worthiness estimation assessment, including classical pre-trained\nmodels such as BERT, as well as recent popular large models like GPT-3.5 and\nGPT-4. Experiments show that the prompt tuning-based method proposed in this\nstudy exhibits certain advantages in evaluation metrics such as F1 score and\naccuracy, thereby effectively validating its effectiveness and advancement in\nthe task of fact-check-worthiness estimation."}
{"id": "2504.18453", "pdf": "https://arxiv.org/pdf/2504.18453", "abs": "https://arxiv.org/abs/2504.18453", "authors": ["Peiyuan Jing", "Kinhei Lee", "Zhenxuan Zhang", "Huichi Zhou", "Zhengqing Yuan", "Zhifan Gao", "Lei Zhu", "Giorgos Papanastasiou", "Yingying Fang", "Guang Yang"], "title": "Reason Like a Radiologist: Chain-of-Thought and Reinforcement Learning for Verifiable Report Generation", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Radiology report generation is critical for efficiency but current models\nlack the structured reasoning of experts, hindering clinical trust and\nexplainability by failing to link visual findings to precise anatomical\nlocations. This paper introduces BoxMed-RL, a groundbreaking unified training\nframework for generating spatially verifiable and explainable radiology\nreports. Built on a large vision-language model, BoxMed-RL revolutionizes\nreport generation through two integrated phases: (1) In the Pretraining Phase,\nwe refine the model via medical concept learning, using Chain-of-Thought\nsupervision to internalize the radiologist-like workflow, followed by spatially\nverifiable reinforcement, which applies reinforcement learning to align medical\nfindings with bounding boxes. (2) In the Downstream Adapter Phase, we freeze\nthe pretrained weights and train a downstream adapter to ensure fluent and\nclinically credible reports. This framework precisely mimics radiologists'\nworkflow, compelling the model to connect high-level medical concepts with\ndefinitive anatomical evidence. Extensive experiments on public datasets\ndemonstrate that BoxMed-RL achieves an average 7% improvement in both METEOR\nand ROUGE-L metrics compared to state-of-the-art methods. An average 5%\nimprovement in large language model-based metrics further underscores\nBoxMed-RL's robustness in generating high-quality radiology reports."}
{"id": "2504.17946", "pdf": "https://arxiv.org/pdf/2504.17946", "abs": "https://arxiv.org/abs/2504.17946", "authors": ["Fatemeh Vares", "Brittany Johnson"], "title": "Causality-Driven Neural Network Repair: Challenges and Opportunities", "categories": ["cs.LG", "D.2.2; I.2.6"], "comment": "Causality in Software Engineering (CauSE) 2025 Workshop at ESEC/FSE", "summary": "Deep Neural Networks (DNNs) often rely on statistical correlations rather\nthan causal reasoning, limiting their robustness and interpretability. While\ntesting methods can identify failures, effective debugging and repair remain\nchallenging. This paper explores causal inference as an approach primarily for\nDNN repair, leveraging causal debugging, counterfactual analysis, and\nstructural causal models (SCMs) to identify and correct failures. We discuss in\nwhat ways these techniques support fairness, adversarial robustness, and\nbackdoor mitigation by providing targeted interventions. Finally, we discuss\nkey challenges, including scalability, generalization, and computational\nefficiency, and outline future directions for integrating causality-driven\ninterventions to enhance DNN reliability."}
{"id": "2504.17817", "pdf": "https://arxiv.org/pdf/2504.17817", "abs": "https://arxiv.org/abs/2504.17817", "authors": ["Alexandre Cardaillac", "Donald G. Dansereau"], "title": "Learning Underwater Active Perception in Simulation", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "When employing underwater vehicles for the autonomous inspection of assets,\nit is crucial to consider and assess the water conditions. Indeed, they have a\nsignificant impact on the visibility, which also affects robotic operations.\nTurbidity can jeopardise the whole mission as it may prevent correct visual\ndocumentation of the inspected structures. Previous works have introduced\nmethods to adapt to turbidity and backscattering, however, they also include\nmanoeuvring and setup constraints. We propose a simple yet efficient approach\nto enable high-quality image acquisition of assets in a broad range of water\nconditions. This active perception framework includes a multi-layer perceptron\n(MLP) trained to predict image quality given a distance to a target and\nartificial light intensity. We generated a large synthetic dataset including\nten water types with different levels of turbidity and backscattering. For\nthis, we modified the modelling software Blender to better account for the\nunderwater light propagation properties. We validated the approach in\nsimulation and showed significant improvements in visual coverage and quality\nof imagery compared to traditional approaches. The project code is available on\nour project page at https://roboticimaging.org/Projects/ActiveUW/."}
{"id": "2504.18344", "pdf": "https://arxiv.org/pdf/2504.18344", "abs": "https://arxiv.org/abs/2504.18344", "authors": ["Kristine S√∏rensen", "Oscar Camara", "Ole de Backer", "Klaus Kofoed", "Rasmus Paulsen"], "title": "NUDF: Neural Unsigned Distance Fields for high resolution 3D medical image segmentation", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Medical image segmentation is often considered as the task of labelling each\npixel or voxel as being inside or outside a given anatomy. Processing the\nimages at their original size and resolution often result in insuperable memory\nrequirements, but downsampling the images leads to a loss of important details.\nInstead of aiming to represent a smooth and continuous surface in a binary\nvoxel-grid, we propose to learn a Neural Unsigned Distance Field (NUDF)\ndirectly from the image. The small memory requirements of NUDF allow for high\nresolution processing, while the continuous nature of the distance field allows\nus to create high resolution 3D mesh models of shapes of any topology (i.e.\nopen surfaces). We evaluate our method on the task of left atrial appendage\n(LAA) segmentation from Computed Tomography (CT) images. The LAA is a complex\nand highly variable shape, being thus difficult to represent with traditional\nsegmentation methods using discrete labelmaps. With our proposed method, we are\nable to predict 3D mesh models that capture the details of the LAA and achieve\naccuracy in the order of the voxel spacing in the CT images."}
{"id": "2504.18106", "pdf": "https://arxiv.org/pdf/2504.18106", "abs": "https://arxiv.org/abs/2504.18106", "authors": ["Yinglong Yu", "Zhaopu Yao", "Fang Yuan"], "title": "Comparative Study on the Discourse Meaning of Chinese and English Media in the Paris Olympics Based on LDA Topic Modeling Technology and LLM Prompt Engineering", "categories": ["cs.CL"], "comment": null, "summary": "This study analyzes Chinese and English media reports on the Paris Olympics\nusing topic modeling, Large Language Model (LLM) prompt engineering, and corpus\nphraseology methods to explore similarities and differences in discourse\nconstruction and attitudinal meanings. Common topics include the opening\nceremony, athlete performance, and sponsorship brands. Chinese media focus on\nspecific sports, sports spirit, doping controversies, and new technologies,\nwhile English media focus on female athletes, medal wins, and eligibility\ncontroversies. Chinese reports show more frequent prepositional co-occurrences\nand positive semantic prosody in describing the opening ceremony and sports\nspirit. English reports exhibit positive semantic prosody when covering female\nathletes but negative prosody in predicting opening ceremony reactions and\ndiscussing women's boxing controversies."}
{"id": "2504.18530", "pdf": "https://arxiv.org/pdf/2504.18530", "abs": "https://arxiv.org/abs/2504.18530", "authors": ["Joshua Engels", "David D. Baek", "Subhash Kantamneni", "Max Tegmark"], "title": "Scaling Laws For Scalable Oversight", "categories": ["cs.AI", "cs.CY", "cs.LG"], "comment": "34 pages, 17 figures", "summary": "Scalable oversight, the process by which weaker AI systems supervise stronger\nones, has been proposed as a key strategy to control future superintelligent\nsystems. However, it is still unclear how scalable oversight itself scales. To\naddress this gap, we propose a framework that quantifies the probability of\nsuccessful oversight as a function of the capabilities of the overseer and the\nsystem being overseen. Specifically, our framework models oversight as a game\nbetween capability-mismatched players; the players have oversight-specific and\ndeception-specific Elo scores that are a piecewise-linear function of their\ngeneral intelligence, with two plateaus corresponding to task incompetence and\ntask saturation. We validate our framework with a modified version of the game\nNim and then apply it to four oversight games: \"Mafia\", \"Debate\", \"Backdoor\nCode\" and \"Wargames\". For each game, we find scaling laws that approximate how\ndomain performance depends on general AI system capability (using Chatbot Arena\nElo as a proxy for general capability). We then build on our findings in a\ntheoretical study of Nested Scalable Oversight (NSO), a process in which\ntrusted models oversee untrusted stronger models, which then become the trusted\nmodels in the next step. We identify conditions under which NSO succeeds and\nderive numerically (and in some cases analytically) the optimal number of\noversight levels to maximize the probability of oversight success. In our\nnumerical examples, the NSO success rate is below 52% when overseeing systems\nthat are 400 Elo points stronger than the baseline overseer, and it declines\nfurther for overseeing even stronger systems."}
{"id": "2504.17963", "pdf": "https://arxiv.org/pdf/2504.17963", "abs": "https://arxiv.org/abs/2504.17963", "authors": ["Liangzu Peng", "Ren√© Vidal"], "title": "Mathematics of Continual Learning", "categories": ["cs.LG"], "comment": null, "summary": "Continual learning is an emerging subject in machine learning that aims to\nsolve multiple tasks presented sequentially to the learner without forgetting\npreviously learned tasks. Recently, many deep learning based approaches have\nbeen proposed for continual learning, however the mathematical foundations\nbehind existing continual learning methods remain underdeveloped. On the other\nhand, adaptive filtering is a classic subject in signal processing with a rich\nhistory of mathematically principled methods. However, its role in\nunderstanding the foundations of continual learning has been underappreciated.\nIn this tutorial, we review the basic principles behind both continual learning\nand adaptive filtering, and present a comparative analysis that highlights\nmultiple connections between them. These connections allow us to enhance the\nmathematical foundations of continual learning based on existing results for\nadaptive filtering, extend adaptive filtering insights using existing continual\nlearning methods, and discuss a few research directions for continual learning\nsuggested by the historical developments in adaptive filtering."}
{"id": "2504.17821", "pdf": "https://arxiv.org/pdf/2504.17821", "abs": "https://arxiv.org/abs/2504.17821", "authors": ["Xinyu Chen", "Yunxin Li", "Haoyuan Shi", "Baotian Hu", "Wenhan Luo", "Yaowei Wang", "Min Zhang"], "title": "VideoVista-CulturalLingo: 360$^\\circ$ Horizons-Bridging Cultures, Languages, and Domains in Video Comprehension", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Assessing the video comprehension capabilities of multimodal AI systems can\neffectively measure their understanding and reasoning abilities. Most video\nevaluation benchmarks are limited to a single language, typically English, and\npredominantly feature videos rooted in Western cultural contexts. In this\npaper, we present VideoVista-CulturalLingo, the first video evaluation\nbenchmark designed to bridge cultural, linguistic, and domain divide in video\ncomprehension. Our work differs from existing benchmarks in the following ways:\n1) Cultural diversity, incorporating cultures from China, North America, and\nEurope; 2) Multi-linguistics, with questions presented in Chinese and\nEnglish-two of the most widely spoken languages; and 3) Broad domain, featuring\nvideos sourced from hundreds of human-created domains. VideoVista-CulturalLingo\ncontains 1,389 videos and 3,134 QA pairs, and we have evaluated 24 recent\nopen-source or proprietary video large models. From the experiment results, we\nobserve that: 1) Existing models perform worse on Chinese-centric questions\nthan Western-centric ones, particularly those related to Chinese history; 2)\nCurrent open-source models still exhibit limitations in temporal understanding,\nespecially in the Event Localization task, achieving a maximum score of only\n45.2%; 3) Mainstream models demonstrate strong performance in general\nscientific questions, while open-source models demonstrate weak performance in\nmathematics."}
{"id": "2504.18398", "pdf": "https://arxiv.org/pdf/2504.18398", "abs": "https://arxiv.org/abs/2504.18398", "authors": ["Xinmin Feng", "Zhuoyuan Li", "Li Li", "Dong Liu", "Feng Wu"], "title": "Partition Map-Based Fast Block Partitioning for VVC Inter Coding", "categories": ["eess.IV", "cs.CV"], "comment": "23 pages, 26 figures. Project page:\n  https://github.com/ustc-ivclab/IPM", "summary": "Among the new techniques of Versatile Video Coding (VVC), the quadtree with\nnested multi-type tree (QT+MTT) block structure yields significant coding gains\nby providing more flexible block partitioning patterns. However, the recursive\npartition search in the VVC encoder increases the encoder complexity\nsubstantially. To address this issue, we propose a partition map-based\nalgorithm to pursue fast block partitioning in inter coding. Based on our\nprevious work on partition map-based methods for intra coding, we analyze the\ncharacteristics of VVC inter coding, and thus improve the partition map by\nincorporating an MTT mask for early termination. Next, we develop a neural\nnetwork that uses both spatial and temporal features to predict the partition\nmap. It consists of several special designs including stacked top-down and\nbottom-up processing, quantization parameter modulation layers, and\npartitioning-adaptive warping. Furthermore, we present a dual-threshold\ndecision scheme to achieve a fine-grained trade-off between complexity\nreduction and rate-distortion (RD) performance loss. The experimental results\ndemonstrate that the proposed method achieves an average 51.30% encoding time\nsaving with a 2.12% Bjontegaard Delta Bit Rate (BDBR) under the random access\nconfiguration."}
{"id": "2504.18114", "pdf": "https://arxiv.org/pdf/2504.18114", "abs": "https://arxiv.org/abs/2504.18114", "authors": ["Atharva Kulkarni", "Yuan Zhang", "Joel Ruben Antony Moniz", "Xiou Ge", "Bo-Hsiang Tseng", "Dhivya Piraviperumal", "Swabha Swayamdipta", "Hong Yu"], "title": "Evaluating Evaluation Metrics -- The Mirage of Hallucination Detection", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Hallucinations pose a significant obstacle to the reliability and widespread\nadoption of language models, yet their accurate measurement remains a\npersistent challenge. While many task- and domain-specific metrics have been\nproposed to assess faithfulness and factuality concerns, the robustness and\ngeneralization of these metrics are still untested. In this paper, we conduct a\nlarge-scale empirical evaluation of 6 diverse sets of hallucination detection\nmetrics across 4 datasets, 37 language models from 5 families, and 5 decoding\nmethods. Our extensive investigation reveals concerning gaps in current\nhallucination evaluation: metrics often fail to align with human judgments,\ntake an overtly myopic view of the problem, and show inconsistent gains with\nparameter scaling. Encouragingly, LLM-based evaluation, particularly with\nGPT-4, yields the best overall results, and mode-seeking decoding methods seem\nto reduce hallucinations, especially in knowledge-grounded settings. These\nfindings underscore the need for more robust metrics to understand and quantify\nhallucinations, and better strategies to mitigate them."}
{"id": "2504.18536", "pdf": "https://arxiv.org/pdf/2504.18536", "abs": "https://arxiv.org/abs/2504.18536", "authors": ["Anna Katariina Wisakanto", "Joe Rogero", "Avyay M. Casheekar", "Richard Mallah"], "title": "Adapting Probabilistic Risk Assessment for AI", "categories": ["cs.AI", "cs.CY", "cs.LG", "cs.SY", "eess.SY", "stat.AP"], "comment": "for project website, see https://pra-for-ai.github.io/pra/", "summary": "Modern general-purpose artificial intelligence (AI) systems present an urgent\nrisk management challenge, as their rapidly evolving capabilities and potential\nfor catastrophic harm outpace our ability to reliably assess their risks.\nCurrent methods often rely on selective testing and undocumented assumptions\nabout risk priorities, frequently failing to make a serious attempt at\nassessing the set of pathways through which Al systems pose direct or indirect\nrisks to society and the biosphere. This paper introduces the probabilistic\nrisk assessment (PRA) for AI framework, adapting established PRA techniques\nfrom high-reliability industries (e.g., nuclear power, aerospace) for the new\nchallenges of advanced AI. The framework guides assessors in identifying\npotential risks, estimating likelihood and severity, and explicitly documenting\nevidence, underlying assumptions, and analyses at appropriate granularities.\nThe framework's implementation tool synthesizes the results into a risk report\ncard with aggregated risk estimates from all assessed risks. This systematic\napproach integrates three advances: (1) Aspect-oriented hazard analysis\nprovides systematic hazard coverage guided by a first-principles taxonomy of AI\nsystem aspects (e.g. capabilities, domain knowledge, affordances); (2) Risk\npathway modeling analyzes causal chains from system aspects to societal impacts\nusing bidirectional analysis and incorporating prospective techniques; and (3)\nUncertainty management employs scenario decomposition, reference scales, and\nexplicit tracing protocols to structure credible projections with novelty or\nlimited data. Additionally, the framework harmonizes diverse assessment methods\nby integrating evidence into comparable, quantified absolute risk estimates for\ncritical decisions. We have implemented this as a workbook tool for AI\ndevelopers, evaluators, and regulators, available on the project website."}
{"id": "2504.18003", "pdf": "https://arxiv.org/pdf/2504.18003", "abs": "https://arxiv.org/abs/2504.18003", "authors": ["Aditya S Ellendula", "Chandrajit Bajaj"], "title": "Self-Balancing, Memory Efficient, Dynamic Metric Space Data Maintenance, for Rapid Multi-Kernel Estimation", "categories": ["cs.LG"], "comment": null, "summary": "We present a dynamic self-balancing octree data structure that enables\nefficient neighborhood maintenance in evolving metric spaces, a key challenge\nin modern machine learning systems. Many learning and generative models operate\nas dynamical systems whose representations evolve during training, requiring\nfast, adaptive spatial organization. Our two-parameter octree supports\nlogarithmic-time updates and queries, eliminating the need for costly full\nrebuilds as data distributions shift. We demonstrate its effectiveness in four\nareas: (1) accelerating Stein variational gradient descent by supporting more\nparticles with lower overhead; (2) enabling real-time, incremental KNN\nclassification with logarithmic complexity; (3) facilitating efficient, dynamic\nindexing and retrieval for retrieval-augmented generation; and (4) improving\nsample efficiency by jointly optimizing input and latent spaces. Across all\napplications, our approach yields exponential speedups while preserving\naccuracy, particularly in high-dimensional spaces where maintaining adaptive\nspatial structure is critical."}
{"id": "2504.17822", "pdf": "https://arxiv.org/pdf/2504.17822", "abs": "https://arxiv.org/abs/2504.17822", "authors": ["Wenwen Li", "Chia-Yu Hsu", "Sizhe Wang", "Zhining Gu", "Yili Yang", "Brendan M. Rogers", "Anna Liljedahl"], "title": "A multi-scale vision transformer-based multimodal GeoAI model for mapping Arctic permafrost thaw", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Retrogressive Thaw Slumps (RTS) in Arctic regions are distinct permafrost\nlandforms with significant environmental impacts. Mapping these RTS is crucial\nbecause their appearance serves as a clear indication of permafrost thaw.\nHowever, their small scale compared to other landform features, vague\nboundaries, and spatiotemporal variation pose significant challenges for\naccurate detection. In this paper, we employed a state-of-the-art deep learning\nmodel, the Cascade Mask R-CNN with a multi-scale vision transformer-based\nbackbone, to delineate RTS features across the Arctic. Two new strategies were\nintroduced to optimize multimodal learning and enhance the model's predictive\nperformance: (1) a feature-level, residual cross-modality attention fusion\nstrategy, which effectively integrates feature maps from multiple modalities to\ncapture complementary information and improve the model's ability to understand\ncomplex patterns and relationships within the data; (2) pre-trained unimodal\nlearning followed by multimodal fine-tuning to alleviate high computing demand\nwhile achieving strong model performance. Experimental results demonstrated\nthat our approach outperformed existing models adopting data-level fusion,\nfeature-level convolutional fusion, and various attention fusion strategies,\nproviding valuable insights into the efficient utilization of multimodal data\nfor RTS mapping. This research contributes to our understanding of permafrost\nlandforms and their environmental implications."}
{"id": "2504.18400", "pdf": "https://arxiv.org/pdf/2504.18400", "abs": "https://arxiv.org/abs/2504.18400", "authors": ["Yui Lo", "Yuqian Chen", "Dongnan Liu", "Leo Zekelman", "Jarrett Rushmore", "Yogesh Rathi", "Nikos Makris", "Alexandra J. Golby", "Fan Zhang", "Weidong Cai", "Lauren J. O'Donnell"], "title": "A Multimodal Deep Learning Approach for White Matter Shape Prediction in Diffusion MRI Tractography", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "21 pages, 3 figures, 6 tables", "summary": "Shape measures have emerged as promising descriptors of white matter\ntractography, offering complementary insights into anatomical variability and\nassociations with cognitive and clinical phenotypes. However, conventional\nmethods for computing shape measures are computationally expensive and\ntime-consuming for large-scale datasets due to reliance on voxel-based\nrepresentations. We propose Tract2Shape, a novel multimodal deep learning\nframework that leverages geometric (point cloud) and scalar (tabular) features\nto predict ten white matter tractography shape measures. To enhance model\nefficiency, we utilize a dimensionality reduction algorithm for the model to\npredict five primary shape components. The model is trained and evaluated on\ntwo independently acquired datasets, the HCP-YA dataset, and the PPMI dataset.\nWe evaluate the performance of Tract2Shape by training and testing it on the\nHCP-YA dataset and comparing the results with state-of-the-art models. To\nfurther assess its robustness and generalization ability, we also test\nTract2Shape on the unseen PPMI dataset. Tract2Shape outperforms SOTA deep\nlearning models across all ten shape measures, achieving the highest average\nPearson's r and the lowest nMSE on the HCP-YA dataset. The ablation study shows\nthat both multimodal input and PCA contribute to performance gains. On the\nunseen testing PPMI dataset, Tract2Shape maintains a high Pearson's r and low\nnMSE, demonstrating strong generalizability in cross-dataset evaluation.\nTract2Shape enables fast, accurate, and generalizable prediction of white\nmatter shape measures from tractography data, supporting scalable analysis\nacross datasets. This framework lays a promising foundation for future\nlarge-scale white matter shape analysis."}
{"id": "2504.18128", "pdf": "https://arxiv.org/pdf/2504.18128", "abs": "https://arxiv.org/abs/2504.18128", "authors": ["Tatsunori Tanaka", "Fi Zheng", "Kai Sato", "Zhifeng Li", "Yuanyun Zhang", "Shi Li"], "title": "Temporal Entailment Pretraining for Clinical Language Models over EHR Data", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Clinical language models have achieved strong performance on downstream tasks\nby pretraining on domain specific corpora such as discharge summaries and\nmedical notes. However, most approaches treat the electronic health record as a\nstatic document, neglecting the temporally-evolving and causally entwined\nnature of patient trajectories. In this paper, we introduce a novel temporal\nentailment pretraining objective for language models in the clinical domain.\nOur method formulates EHR segments as temporally ordered sentence pairs and\ntrains the model to determine whether a later state is entailed by,\ncontradictory to, or neutral with respect to an earlier state. Through this\ntemporally structured pretraining task, models learn to perform latent clinical\nreasoning over time, improving their ability to generalize across forecasting\nand diagnosis tasks. We pretrain on a large corpus derived from MIMIC IV and\ndemonstrate state of the art results on temporal clinical QA, early warning\nprediction, and disease progression modeling."}
{"id": "2504.17792", "pdf": "https://arxiv.org/pdf/2504.17792", "abs": "https://arxiv.org/abs/2504.17792", "authors": ["Hauke Sandhaus", "Angel Hsing-Chi Hwang", "Wendy Ju", "Qian Yang"], "title": "My Precious Crash Data: Barriers and Opportunities in Encouraging Autonomous Driving Companies to Share Safety-Critical Data", "categories": ["cs.HC", "cs.AI", "cs.DB", "E.m; H.2.8; J.1"], "comment": "To appear in Proc. ACM Hum.-Comput. Interact., Computer-Supported\n  Cooperative Work & Social Computing (CSCW), 2025", "summary": "Safety-critical data, such as crash and near-crash records, are crucial to\nimproving autonomous vehicle (AV) design and development. Sharing such data\nacross AV companies, academic researchers, regulators, and the public can help\nmake all AVs safer. However, AV companies rarely share safety-critical data\nexternally. This paper aims to pinpoint why AV companies are reluctant to share\nsafety-critical data, with an eye on how these barriers can inform new\napproaches to promote sharing. We interviewed twelve AV company employees who\nactively work with such data in their day-to-day work. Findings suggest two\nkey, previously unknown barriers to data sharing: (1) Datasets inherently embed\nsalient knowledge that is key to improving AV safety and are\nresource-intensive. Therefore, data sharing, even within a company, is fraught\nwith politics. (2) Interviewees believed AV safety knowledge is private\nknowledge that brings competitive edges to their companies, rather than public\nknowledge for social good. We discuss the implications of these findings for\nincentivizing and enabling safety-critical AV data sharing, specifically,\nimplications for new approaches to (1) debating and stratifying public and\nprivate AV safety knowledge, (2) innovating data tools and data sharing\npipelines that enable easier sharing of public AV safety data and knowledge;\n(3) offsetting costs of curating safety-critical data and incentivizing data\nsharing."}
{"id": "2504.18008", "pdf": "https://arxiv.org/pdf/2504.18008", "abs": "https://arxiv.org/abs/2504.18008", "authors": ["Nooshin Yousefzadeh", "Rahul Sengupta", "Sanjay Ranka"], "title": "TGDT: A Temporal Graph-based Digital Twin for Urban Traffic Corridors", "categories": ["cs.LG"], "comment": "8 pages, 4 figures, 1 table", "summary": "Urban congestion at signalized intersections leads to significant delays,\neconomic losses, and increased emissions. Existing deep learning models often\nlack spatial generalizability, rely on complex architectures, and struggle with\nreal-time deployment. To address these limitations, we propose the Temporal\nGraph-based Digital Twin (TGDT), a scalable framework that integrates Temporal\nConvolutional Networks and Attentional Graph Neural Networks for dynamic,\ndirection-aware traffic modeling and assessment at urban corridors. TGDT\nestimates key Measures of Effectiveness (MOEs) for traffic flow optimization at\nboth the intersection level (e.g., queue length, waiting time) and the corridor\nlevel (e.g., traffic volume, travel time). Its modular architecture and\nsequential optimization scheme enable easy extension to any number of\nintersections and MOEs. The model outperforms state-of-the-art baselines by\naccurately producing high-dimensional, concurrent multi-output estimates. It\nalso demonstrates high robustness and accuracy across diverse traffic\nconditions, including extreme scenarios, while relying on only a minimal set of\ntraffic features. Fully parallelized, TGDT can simulate over a thousand\nscenarios within a matter of seconds, offering a cost-effective, interpretable,\nand real-time solution for traffic signal optimization."}
{"id": "2504.17825", "pdf": "https://arxiv.org/pdf/2504.17825", "abs": "https://arxiv.org/abs/2504.17825", "authors": ["Dehong Kong", "Fan Li", "Zhixin Wang", "Jiaqi Xu", "Renjing Pei", "Wenbo Li", "WenQi Ren"], "title": "Dual Prompting Image Restoration with Diffusion Transformers", "categories": ["cs.CV", "cs.AI"], "comment": "CVPR2025", "summary": "Recent state-of-the-art image restoration methods mostly adopt latent\ndiffusion models with U-Net backbones, yet still facing challenges in achieving\nhigh-quality restoration due to their limited capabilities. Diffusion\ntransformers (DiTs), like SD3, are emerging as a promising alternative because\nof their better quality with scalability. In this paper, we introduce DPIR\n(Dual Prompting Image Restoration), a novel image restoration method that\neffectivly extracts conditional information of low-quality images from multiple\nperspectives. Specifically, DPIR consits of two branches: a low-quality image\nconditioning branch and a dual prompting control branch. The first branch\nutilizes a lightweight module to incorporate image priors into the DiT with\nhigh efficiency. More importantly, we believe that in image restoration,\ntextual description alone cannot fully capture its rich visual characteristics.\nTherefore, a dual prompting module is designed to provide DiT with additional\nvisual cues, capturing both global context and local appearance. The extracted\nglobal-local visual prompts as extra conditional control, alongside textual\nprompts to form dual prompts, greatly enhance the quality of the restoration.\nExtensive experimental results demonstrate that DPIR delivers superior image\nrestoration performance."}
{"id": "2504.18405", "pdf": "https://arxiv.org/pdf/2504.18405", "abs": "https://arxiv.org/abs/2504.18405", "authors": ["Jens Hooge", "Gerard Sanroma-Guell", "Faidra Stavropoulou", "Alexander Ullmann", "Gesine Knobloch", "Mark Klemens", "Carola Schmidt", "Sabine Weckbach", "Andreas Bolz"], "title": "HepatoGEN: Generating Hepatobiliary Phase MRI with Perceptual and Adversarial Models", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) plays a\ncrucial role in the detection and characterization of focal liver lesions, with\nthe hepatobiliary phase (HBP) providing essential diagnostic information.\nHowever, acquiring HBP images requires prolonged scan times, which may\ncompromise patient comfort and scanner throughput. In this study, we propose a\ndeep learning based approach for synthesizing HBP images from earlier contrast\nphases (precontrast and transitional) and compare three generative models: a\nperceptual U-Net, a perceptual GAN (pGAN), and a denoising diffusion\nprobabilistic model (DDPM). We curated a multi-site DCE-MRI dataset from\ndiverse clinical settings and introduced a contrast evolution score (CES) to\nassess training data quality, enhancing model performance. Quantitative\nevaluation using pixel-wise and perceptual metrics, combined with qualitative\nassessment through blinded radiologist reviews, showed that pGAN achieved the\nbest quantitative performance but introduced heterogeneous contrast in\nout-of-distribution cases. In contrast, the U-Net produced consistent liver\nenhancement with fewer artifacts, while DDPM underperformed due to limited\npreservation of fine structural details. These findings demonstrate the\nfeasibility of synthetic HBP image generation as a means to reduce scan time\nwithout compromising diagnostic utility, highlighting the clinical potential of\ndeep learning for dynamic contrast enhancement in liver MRI. A project demo is\navailable at: https://jhooge.github.io/hepatogen"}
{"id": "2504.18142", "pdf": "https://arxiv.org/pdf/2504.18142", "abs": "https://arxiv.org/abs/2504.18142", "authors": ["Fida Ullah", "Muhammad Ahmad", "Muhammad Tayyab Zamir", "Muhammad Arif", "Grigori sidorov", "Edgardo Manuel Felipe River√≥n", "Alexander Gelbukh"], "title": "EDU-NER-2025: Named Entity Recognition in Urdu Educational Texts using XLM-RoBERTa with X (formerly Twitter)", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Named Entity Recognition (NER) plays a pivotal role in various Natural\nLanguage Processing (NLP) tasks by identifying and classifying named entities\n(NEs) from unstructured data into predefined categories such as person,\norganization, location, date, and time. While extensive research exists for\nhigh-resource languages and general domains, NER in Urdu particularly within\ndomain-specific contexts like education remains significantly underexplored.\nThis is Due to lack of annotated datasets for educational content which limits\nthe ability of existing models to accurately identify entities such as academic\nroles, course names, and institutional terms, underscoring the urgent need for\ntargeted resources in this domain. To the best of our knowledge, no dataset\nexists in the domain of the Urdu language for this purpose. To achieve this\nobjective this study makes three key contributions. Firstly, we created a\nmanually annotated dataset in the education domain, named EDU-NER-2025, which\ncontains 13 unique most important entities related to education domain. Second,\nwe describe our annotation process and guidelines in detail and discuss the\nchallenges of labelling EDU-NER-2025 dataset. Third, we addressed and analyzed\nkey linguistic challenges, such as morphological complexity and ambiguity,\nwhich are prevalent in formal Urdu texts."}
{"id": "2504.17799", "pdf": "https://arxiv.org/pdf/2504.17799", "abs": "https://arxiv.org/abs/2504.17799", "authors": ["S. L. Thomson", "M. W. Przewozniczek"], "title": "Subfunction Structure Matters: A New Perspective on Local Optima Networks", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "Local optima networks (LONs) capture fitness landscape information. They are\ntypically constructed in a black-box manner; information about the problem\nstructure is not utilised. This also applies to the analysis of LONs: knowledge\nabout the problem, such as interaction between variables, is not considered. We\nchallenge this status-quo with an alternative approach: we consider how LON\nanalysis can be improved by incorporating subfunction-based information - this\ncan either be known a-priori or learned during search. To this end, LONs are\nconstructed for several benchmark pseudo-boolean problems using three\napproaches: firstly, the standard algorithm; a second algorithm which uses\ndeterministic grey-box crossover; and a third algorithm which selects\nperturbations based on learned information about variable interactions. Metrics\nrelated to subfunction changes in a LON are proposed and compared with metrics\nfrom previous literature which capture other aspects of a LON. Incorporating\nproblem structure in LON construction and analysing it can bring enriched\ninsight into optimisation dynamics. Such information may be crucial to\nunderstanding the difficulty of solving a given problem with state-of-the-art\nlinkage learning optimisers. In light of the results, we suggest incorporation\nof problem structure as an alternative paradigm in landscape analysis for\nproblems with known or suspected subfunction structure."}
{"id": "2504.18026", "pdf": "https://arxiv.org/pdf/2504.18026", "abs": "https://arxiv.org/abs/2504.18026", "authors": ["Emiliano Penaloza", "Tianyue H. Zhan", "Laurent Charlin", "Mateo Espinosa Zarlenga"], "title": "Addressing Concept Mislabeling in Concept Bottleneck Models Through Preference Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Concept Bottleneck Models (CBMs) propose to enhance the trustworthiness of AI\nsystems by constraining their decisions on a set of human understandable\nconcepts. However, CBMs typically assume that datasets contains accurate\nconcept labels an assumption often violated in practice, which we show can\nsignificantly degrade performance (by 25% in some cases). To address this, we\nintroduce the Concept Preference Optimization (CPO) objective, a new loss\nfunction based on Direct Preference Optimization, which effectively mitigates\nthe negative impact of concept mislabeling on CBM performance. We provide an\nanalysis on some key properties of the CPO objective showing it directly\noptimizes for the concept's posterior distribution, and contrast it against\nBinary Cross Entropy (BCE) where we show CPO is inherently less sensitive to\nconcept noise. We empirically confirm our analysis finding that CPO\nconsistently outperforms BCE in three real world datasets with and without\nadded label noise."}
{"id": "2504.17826", "pdf": "https://arxiv.org/pdf/2504.17826", "abs": "https://arxiv.org/abs/2504.17826", "authors": ["Kaicheng Pang", "Xingxing Zou", "Waikeung Wong"], "title": "FashionM3: Multimodal, Multitask, and Multiround Fashion Assistant based on Unified Vision-Language Model", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Fashion styling and personalized recommendations are pivotal in modern\nretail, contributing substantial economic value in the fashion industry. With\nthe advent of vision-language models (VLM), new opportunities have emerged to\nenhance retailing through natural language and visual interactions. This work\nproposes FashionM3, a multimodal, multitask, and multiround fashion assistant,\nbuilt upon a VLM fine-tuned for fashion-specific tasks. It helps users discover\nsatisfying outfits by offering multiple capabilities including personalized\nrecommendation, alternative suggestion, product image generation, and virtual\ntry-on simulation. Fine-tuned on the novel FashionRec dataset, comprising\n331,124 multimodal dialogue samples across basic, personalized, and alternative\nrecommendation tasks, FashionM3 delivers contextually personalized suggestions\nwith iterative refinement through multiround interactions. Quantitative and\nqualitative evaluations, alongside user studies, demonstrate FashionM3's\nsuperior performance in recommendation effectiveness and practical value as a\nfashion assistant."}
{"id": "2504.18442", "pdf": "https://arxiv.org/pdf/2504.18442", "abs": "https://arxiv.org/abs/2504.18442", "authors": ["Yue Li", "Pulkit Khandelwal", "Long Xie", "Laura E. M. Wisse", "Nidhi Mundada", "Christopher A. Brown", "Emily McGrew", "Amanda Denning", "Sandhitsu R. Das", "David A. Wolk", "Paul A. Yushkevich"], "title": "Nearly isotropic segmentation for medial temporal lobe subregions in multi-modality MRI", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Morphometry of medial temporal lobe (MTL) subregions in brain MRI is\nsensitive biomarker to Alzheimers Disease and other related conditions. While\nT2-weighted (T2w) MRI with high in-plane resolution is widely used to segment\nhippocampal subfields due to its higher contrast in hippocampus, its lower\nout-of-plane resolution reduces the accuracy of subregion thickness\nmeasurements. To address this issue, we developed a nearly isotropic\nsegmentation pipeline that incorporates image and label upsampling and\nhigh-resolution segmentation in T2w MRI. First, a high-resolution atlas was\ncreated based on an existing anisotropic atlas derived from 29 individuals.\nBoth T1-weighted and T2w images in the atlas were upsampled from their original\nresolution to a nearly isotropic resolution 0.4x0.4x0.52mm3 using a non-local\nmeans approach. Manual segmentations within the atlas were also upsampled to\nmatch this resolution using a UNet-based neural network, which was trained on a\ncohort consisting of both high-resolution ex vivo and low-resolution\nanisotropic in vivo MRI with manual segmentations. Second, a multi-modality\ndeep learning-based segmentation model was trained within this nearly isotropic\natlas. Finally, experiments showed the nearly isotropic subregion segmentation\nimproved the accuracy of cortical thickness as an imaging biomarker for\nneurodegeneration in T2w MRI."}
{"id": "2504.18180", "pdf": "https://arxiv.org/pdf/2504.18180", "abs": "https://arxiv.org/abs/2504.18180", "authors": ["√û√≥rir Hrafn Har√∞arson", "Hrafn Loftsson", "Stef√°n √ìlafsson"], "title": "Aligning Language Models for Icelandic Legal Text Summarization", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Published at NoDaLiDa 2025", "summary": "The integration of language models in the legal domain holds considerable\npromise for streamlining processes and improving efficiency in managing\nextensive workloads. However, the specialized terminology, nuanced language,\nand formal style of legal texts can present substantial challenges. This study\nexamines whether preference-based training techniques, specifically\nReinforcement Learning from Human Feedback and Direct Preference Optimization,\ncan enhance models' performance in generating Icelandic legal summaries that\nalign with domain-specific language standards and user preferences. We compare\nmodels fine-tuned with preference training to those using conventional\nsupervised learning. Results indicate that preference training improves the\nlegal accuracy of generated summaries over standard fine-tuning but does not\nsignificantly enhance the overall quality of Icelandic language usage.\nDiscrepancies between automated metrics and human evaluations further\nunderscore the importance of qualitative assessment in developing language\nmodels for the legal domain."}
{"id": "2504.17801", "pdf": "https://arxiv.org/pdf/2504.17801", "abs": "https://arxiv.org/abs/2504.17801", "authors": ["Xufeng Yao", "Jiaxi Jiang", "Yuxuan Zhao", "Peiyu Liao", "Yibo Lin", "Bei Yu"], "title": "Evolution of Optimization Algorithms for Global Placement via Large Language Models", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "Optimization algorithms are widely employed to tackle complex problems, but\ndesigning them manually is often labor-intensive and requires significant\nexpertise. Global placement is a fundamental step in electronic design\nautomation (EDA). While analytical approaches represent the state-of-the-art\n(SOTA) in global placement, their core optimization algorithms remain heavily\ndependent on heuristics and customized components, such as initialization\nstrategies, preconditioning methods, and line search techniques. This paper\npresents an automated framework that leverages large language models (LLM) to\nevolve optimization algorithms for global placement. We first generate diverse\ncandidate algorithms using LLM through carefully crafted prompts. Then we\nintroduce an LLM-based genetic flow to evolve selected candidate algorithms.\nThe discovered optimization algorithms exhibit substantial performance\nimprovements across many benchmarks. Specifically, Our design-case-specific\ndiscovered algorithms achieve average HPWL improvements of \\textbf{5.05\\%},\n\\text{5.29\\%} and \\textbf{8.30\\%} on MMS, ISPD2005 and ISPD2019 benchmarks, and\nup to \\textbf{17\\%} improvements on individual cases. Additionally, the\ndiscovered algorithms demonstrate good generalization ability and are\ncomplementary to existing parameter-tuning methods."}
{"id": "2504.18048", "pdf": "https://arxiv.org/pdf/2504.18048", "abs": "https://arxiv.org/abs/2504.18048", "authors": ["Zhongtian Chen", "Daniel Murfet"], "title": "Modes of Sequence Models and Learning Coefficients", "categories": ["cs.LG"], "comment": null, "summary": "We develop a geometric account of sequence modelling that links patterns in\nthe data to measurable properties of the loss landscape in transformer\nnetworks. First, we cast conditional sequence distributions into a\nHilbert-space framework and apply tensor decompositions to identify their\nprincipal modes. Truncating the small-amplitude modes yields an effective data\ndistribution that preserves dominant structure while discarding statistical\ndetail. Second, we show theoretically that Local Learning Coefficient (LLC)\nestimates are insensitive to modes below a data-dependent threshold.\nConsequently, the LLC calculated in practice characterises the geometry of the\neffective rather than the true distribution. This insight clarifies why\nreliable LLC estimates can be obtained even when a network parameter is not a\nstrict minimiser of the population loss, and it highlights how the inverse\ntemperature in SGLD acts as a resolution dial on the landscape structure."}
{"id": "2504.17828", "pdf": "https://arxiv.org/pdf/2504.17828", "abs": "https://arxiv.org/abs/2504.17828", "authors": ["Bozheng Li", "Yongliang Wu", "Yi Lu", "Jiashuo Yu", "Licheng Tang", "Jiawang Cao", "Wenqing Zhu", "Yuyang Sun", "Jay Wu", "Wenbo Zhu"], "title": "VEU-Bench: Towards Comprehensive Understanding of Video Editing", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to CVPR2025", "summary": "Widely shared videos on the internet are often edited. Recently, although\nVideo Large Language Models (Vid-LLMs) have made great progress in general\nvideo understanding tasks, their capabilities in video editing understanding\n(VEU) tasks remain unexplored. To address this gap, in this paper, we introduce\nVEU-Bench (Video Editing Understanding Benchmark), a comprehensive benchmark\nthat categorizes video editing components across various dimensions, from\nintra-frame features like shot size to inter-shot attributes such as cut types\nand transitions. Unlike previous video editing understanding benchmarks that\nfocus mainly on editing element classification, VEU-Bench encompasses 19\nfine-grained tasks across three stages: recognition, reasoning, and judging. To\nenhance the annotation of VEU automatically, we built an annotation pipeline\nintegrated with an ontology-based knowledge base. Through extensive experiments\nwith 11 state-of-the-art Vid-LLMs, our findings reveal that current Vid-LLMs\nface significant challenges in VEU tasks, with some performing worse than\nrandom choice. To alleviate this issue, we develop Oscars, a VEU expert model\nfine-tuned on the curated VEU-Bench dataset. It outperforms existing\nopen-source Vid-LLMs on VEU-Bench by over 28.3% in accuracy and achieves\nperformance comparable to commercial models like GPT-4o. We also demonstrate\nthat incorporating VEU data significantly enhances the performance of Vid-LLMs\non general video understanding benchmarks, with an average improvement of 8.3%\nacross nine reasoning tasks."}
{"id": "2504.18520", "pdf": "https://arxiv.org/pdf/2504.18520", "abs": "https://arxiv.org/abs/2504.18520", "authors": ["Jiahao Huang", "Fanwen Wang", "Pedro F. Ferreira", "Haosen Zhang", "Yinzhe Wu", "Zhifan Gao", "Lei Zhu", "Angelica I. Aviles-Rivero", "Carola-Bibiane Schonlieb", "Andrew D. Scott", "Zohya Khalique", "Maria Dwornik", "Ramyah Rajakulasingam", "Ranil De Silva", "Dudley J. Pennell", "Guang Yang", "Sonia Nielles-Vallespin"], "title": "RSFR: A Coarse-to-Fine Reconstruction Framework for Diffusion Tensor Cardiac MRI with Semantic-Aware Refinement", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Cardiac diffusion tensor imaging (DTI) offers unique insights into\ncardiomyocyte arrangements, bridging the gap between microscopic and\nmacroscopic cardiac function. However, its clinical utility is limited by\ntechnical challenges, including a low signal-to-noise ratio, aliasing\nartefacts, and the need for accurate quantitative fidelity. To address these\nlimitations, we introduce RSFR (Reconstruction, Segmentation, Fusion &\nRefinement), a novel framework for cardiac diffusion-weighted image\nreconstruction. RSFR employs a coarse-to-fine strategy, leveraging zero-shot\nsemantic priors via the Segment Anything Model and a robust Vision Mamba-based\nreconstruction backbone. Our framework integrates semantic features effectively\nto mitigate artefacts and enhance fidelity, achieving state-of-the-art\nreconstruction quality and accurate DT parameter estimation under high\nundersampling rates. Extensive experiments and ablation studies demonstrate the\nsuperior performance of RSFR compared to existing methods, highlighting its\nrobustness, scalability, and potential for clinical translation in quantitative\ncardiac DTI."}
{"id": "2504.18221", "pdf": "https://arxiv.org/pdf/2504.18221", "abs": "https://arxiv.org/abs/2504.18221", "authors": ["Shuxiang Du", "Ana Guerberof Arenas", "Antonio Toral", "Kyo Gerrits", "Josep Marco Borillo"], "title": "Optimising ChatGPT for creativity in literary translation: A case study from English into Dutch, Chinese, Catalan and Spanish", "categories": ["cs.CL"], "comment": "This paper has been accepted to the MT Summit 2025 to be held in\n  Geneva on June 23-27 2025", "summary": "This study examines the variability of Chat-GPT machine translation (MT)\noutputs across six different configurations in four languages,with a focus on\ncreativity in a literary text. We evaluate GPT translations in different text\ngranularity levels, temperature settings and prompting strategies with a\nCreativity Score formula. We found that prompting ChatGPT with a minimal\ninstruction yields the best creative translations, with \"Translate the\nfollowing text into [TG] creatively\" at the temperature of 1.0 outperforming\nother configurations and DeepL in Spanish, Dutch, and Chinese. Nonetheless,\nChatGPT consistently underperforms compared to human translation (HT)."}
{"id": "2504.17805", "pdf": "https://arxiv.org/pdf/2504.17805", "abs": "https://arxiv.org/abs/2504.17805", "authors": ["Tri Nguyen", "Kelly Cohen"], "title": "Fuzzy Logic -- Based Scheduling System for Part-Time Workforce", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "This paper explores the application of genetic fuzzy systems to efficiently\ngenerate schedules for a team of part-time student workers at a university.\nGiven the preferred number of working hours and availability of employees, our\nmodel generates feasible solutions considering various factors, such as maximum\nweekly hours, required number of workers on duty, and the preferred number of\nworking hours. The algorithm is trained and tested with availability data\ncollected from students at the University of Cincinnati. The results\ndemonstrate the algorithm's efficiency in producing schedules that meet\noperational criteria and its robustness in understaffed conditions."}
{"id": "2504.18072", "pdf": "https://arxiv.org/pdf/2504.18072", "abs": "https://arxiv.org/abs/2504.18072", "authors": ["Konstantin Sch√ºrholt", "L√©o Meynent", "Yefan Zhou", "Haiquan Lu", "Yaoqing Yang", "Damian Borth"], "title": "A Model Zoo on Phase Transitions in Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Using the weights of trained Neural Network (NN) models as data modality has\nrecently gained traction as a research field - dubbed Weight Space Learning\n(WSL). Multiple recent works propose WSL methods to analyze models, evaluate\nmethods, or synthesize weights. Weight space learning methods require\npopulations of trained models as datasets for development and evaluation.\nHowever, existing collections of models - called `model zoos' - are\nunstructured or follow a rudimentary definition of diversity. In parallel, work\nrooted in statistical physics has identified phases and phase transitions in NN\nmodels. Models are homogeneous within the same phase but qualitatively differ\nfrom one phase to another. We combine the idea of `model zoos' with phase\ninformation to create a controlled notion of diversity in populations. We\nintroduce 12 large-scale zoos that systematically cover known phases and vary\nover model architecture, size, and datasets. These datasets cover different\nmodalities, such as computer vision, natural language processing, and\nscientific ML. For every model, we compute loss landscape metrics and validate\nfull coverage of the phases. With this dataset, we provide the community with a\nresource with a wide range of potential applications for WSL and beyond.\nEvidence suggests the loss landscape phase plays a role in applications such as\nmodel training, analysis, or sparsification. We demonstrate this in an\nexploratory study of the downstream methods like transfer learning or model\nweights averaging."}
{"id": "2504.17829", "pdf": "https://arxiv.org/pdf/2504.17829", "abs": "https://arxiv.org/abs/2504.17829", "authors": ["Vlad Vasilescu", "Ana Neacsu", "Daniela Faur"], "title": "Fine-Tuning Adversarially-Robust Transformers for Single-Image Dehazing", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Single-image dehazing is an important topic in remote sensing applications,\nenhancing the quality of acquired images and increasing object detection\nprecision. However, the reliability of such structures has not been\nsufficiently analyzed, which poses them to the risk of imperceptible\nperturbations that can significantly hinder their performance. In this work, we\nshow that state-of-the-art image-to-image dehazing transformers are susceptible\nto adversarial noise, with even 1 pixel change being able to decrease the PSNR\nby as much as 2.8 dB. Next, we propose two lightweight fine-tuning strategies\naimed at increasing the robustness of pre-trained transformers. Our methods\nresults in comparable clean performance, while significantly increasing the\nprotection against adversarial data. We further present their applicability in\ntwo remote sensing scenarios, showcasing their robust behavior for\nout-of-distribution data. The source code for adversarial fine-tuning and\nattack algorithms can be found at github.com/Vladimirescu/RobustDehazing."}
{"id": "2504.17935", "pdf": "https://arxiv.org/pdf/2504.17935", "abs": "https://arxiv.org/abs/2504.17935", "authors": ["H. Martin Gillis", "Ming Hill", "Paul Hollensen", "Alan Fine", "Thomas Trappenberg"], "title": "Masked strategies for images with small objects", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "The hematology analytics used for detection and classification of small blood\ncomponents is a significant challenge. In particular, when objects exists as\nsmall pixel-sized entities in a large context of similar objects. Deep learning\napproaches using supervised models with pre-trained weights, such as residual\nnetworks and vision transformers have demonstrated success for many\napplications. Unfortunately, when applied to images outside the domain of\nlearned representations, these methods often result with less than acceptable\nperformance. A strategy to overcome this can be achieved by using\nself-supervised models, where representations are learned and weights are then\napplied for downstream applications. Recently, masked autoencoders have proven\nto be effective to obtain representations that captures global context\ninformation. By masking regions of an image and having the model learn to\nreconstruct both the masked and non-masked regions, weights can be used for\nvarious applications. However, if the sizes of the objects in images are less\nthan the size of the mask, the global context information is lost, making it\nalmost impossible to reconstruct the image. In this study, we investigated the\neffect of mask ratios and patch sizes for blood components using a MAE to\nobtain learned ViT encoder representations. We then applied the encoder weights\nto train a U-Net Transformer for semantic segmentation to obtain both local and\nglobal contextual information. Our experimental results demonstrates that both\nsmaller mask ratios and patch sizes improve the reconstruction of images using\na MAE. We also show the results of semantic segmentation with and without\npre-trained weights, where smaller-sized blood components benefited with\npre-training. Overall, our proposed method offers an efficient and effective\nstrategy for the segmentation and classification of small objects."}
{"id": "2504.18225", "pdf": "https://arxiv.org/pdf/2504.18225", "abs": "https://arxiv.org/abs/2504.18225", "authors": ["Pierre-Carl Langlais", "Pavel Chizhov", "Mattia Nee", "Carlos Rosas Hinostroza", "Matthieu Delsart", "Ir√®ne Girard", "Othman Hicheur", "Anastasia Stasenko", "Ivan P. Yamshchikov"], "title": "Even Small Reasoners Should Quote Their Sources: Introducing the Pleias-RAG Model Family", "categories": ["cs.CL"], "comment": null, "summary": "We introduce a new generation of small reasoning models for RAG, search, and\nsource summarization. Pleias-RAG-350m and Pleias-RAG-1B are mid-trained on a\nlarge synthetic dataset emulating the retrieval of a wide variety of\nmultilingual open sources from the Common Corpus. They provide native support\nfor citation and grounding with literal quotes and reintegrate multiple\nfeatures associated with RAG workflows, such as query routing, query\nreformulation, and source reranking. Pleias-RAG-350m and Pleias-RAG-1B\noutperform SLMs below 4 billion parameters on standardized RAG benchmarks\n(HotPotQA, 2wiki) and are competitive with popular larger models, including\nQwen-2.5-7B, Llama-3.1-8B, and Gemma-3-4B. They are the only SLMs to date\nmaintaining consistent RAG performance across leading European languages and\nensuring systematic reference grounding for statements. Due to their size and\nease of deployment on constrained infrastructure and higher factuality by\ndesign, the models unlock a range of new use cases for generative AI."}
{"id": "2504.17807", "pdf": "https://arxiv.org/pdf/2504.17807", "abs": "https://arxiv.org/abs/2504.17807", "authors": ["Ze Yang", "Yihong Jin", "Juntian Liu", "Xinhe Xu", "Yihan Zhang", "Shuyang Ji"], "title": "Research on Cloud Platform Network Traffic Monitoring and Anomaly Detection System based on Large Language Models", "categories": ["cs.NI", "cs.AI", "cs.LG"], "comment": "Proceedings of 2025 IEEE 7th International Conference on\n  Communications, Information System and Computer Engineering (CISCE 2025)", "summary": "The rapidly evolving cloud platforms and the escalating complexity of network\ntraffic demand proper network traffic monitoring and anomaly detection to\nensure network security and performance. This paper introduces a large language\nmodel (LLM)-based network traffic monitoring and anomaly detection system. In\naddition to existing models such as autoencoders and decision trees, we harness\nthe power of large language models for processing sequence data from network\ntraffic, which allows us a better capture of underlying complex patterns, as\nwell as slight fluctuations in the dataset. We show for a given detection task,\nthe need for a hybrid model that incorporates the attention mechanism of the\ntransformer architecture into a supervised learning framework in order to\nachieve better accuracy. A pre-trained large language model analyzes and\npredicts the probable network traffic, and an anomaly detection layer that\nconsiders temporality and context is added. Moreover, we present a novel\ntransfer learning-based methodology to enhance the model's effectiveness to\nquickly adapt to unknown network structures and adversarial conditions without\nrequiring extensive labeled datasets. Actual results show that the designed\nmodel outperforms traditional methods in detection accuracy and computational\nefficiency, effectively identify various network anomalies such as zero-day\nattacks and traffic congestion pattern, and significantly reduce the false\npositive rate."}
{"id": "2504.18078", "pdf": "https://arxiv.org/pdf/2504.18078", "abs": "https://arxiv.org/abs/2504.18078", "authors": ["Xiaolu Chen", "Chenghao Huang", "Yanru Zhang", "Hao Wang"], "title": "Privacy-Preserving Personalized Federated Learning for Distributed Photovoltaic Disaggregation under Statistical Heterogeneity", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages", "summary": "The rapid expansion of distributed photovoltaic (PV) installations worldwide,\nmany being behind-the-meter systems, has significantly challenged energy\nmanagement and grid operations, as unobservable PV generation further\ncomplicates the supply-demand balance. Therefore, estimating this generation\nfrom net load, known as PV disaggregation, is critical. Given privacy concerns\nand the need for large training datasets, federated learning becomes a\npromising approach, but statistical heterogeneity, arising from geographical\nand behavioral variations among prosumers, poses new challenges to PV\ndisaggregation. To overcome these challenges, a privacy-preserving distributed\nPV disaggregation framework is proposed using Personalized Federated Learning\n(PFL). The proposed method employs a two-level framework that combines local\nand global modeling. At the local level, a transformer-based PV disaggregation\nmodel is designed to generate solar irradiance embeddings for representing\nlocal PV conditions. A novel adaptive local aggregation mechanism is adopted to\nmitigate the impact of statistical heterogeneity on the local model, extracting\na portion of global information that benefits the local model. At the global\nlevel, a central server aggregates information uploaded from multiple data\ncenters, preserving privacy while enabling cross-center knowledge sharing.\nExperiments on real-world data demonstrate the effectiveness of this proposed\nframework, showing improved accuracy and robustness compared to benchmark\nmethods."}
{"id": "2504.17892", "pdf": "https://arxiv.org/pdf/2504.17892", "abs": "https://arxiv.org/abs/2504.17892", "authors": ["Yasmine Omri", "Parth Shroff", "Thierry Tambe"], "title": "Token Sequence Compression for Efficient Multimodal Computing", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "The exponential growth of Large Multimodal Models (LMMs) has driven\nadvancements in cross-modal reasoning but at significant computational costs.\nIn this work, we focus on visual language models. We highlight the redundancy\nand inefficiency in current vision encoders, and seek to construct an adaptive\ncompression method for multimodal data. In this work, we characterize a panoply\nof visual token selection and merging approaches through both benchmarking and\nqualitative analysis. In particular, we demonstrate that simple cluster-level\ntoken aggregation outperforms prior state-of-the-art works in token selection\nand merging, including merging at the vision encoder level and attention-based\napproaches. We underline the redundancy in current vision encoders, and shed\nlight on several puzzling trends regarding principles of visual token selection\nthrough cross-modal attention visualizations. This work is a first effort\ntowards more effective encoding and processing of high-dimensional data, and\npaves the way for more scalable and sustainable multimodal systems."}
{"id": "2504.18446", "pdf": "https://arxiv.org/pdf/2504.18446", "abs": "https://arxiv.org/abs/2504.18446", "authors": ["Olivier Leblanc", "Chung San Chu", "Laurent Jacques", "Yves Wiaux"], "title": "MROP: Modulated Rank-One Projections for compressive radio interferometric imaging", "categories": ["astro-ph.IM", "eess.IV", "eess.SP"], "comment": null, "summary": "The emerging generation of radio-interferometric (RI) arrays are set to form\nimages of the sky with a new regime of sensitivity and resolution. This implies\na significant increase in visibility data volumes, scaling as\n$\\mathcal{O}(Q^{2}B)$ for $Q$ antennas and $B$ short-time integration intervals\n(or batches), calling for efficient data dimensionality reduction techniques.\nThis paper proposes a new approach to data compression during acquisition,\ncoined modulated rank-one projection (MROP). MROP compresses the $Q\\times Q$\nbatchwise covariance matrix into a smaller number $P$ of random rank-one\nprojections and compresses across time by trading $B$ for a smaller number $M$\nof random modulations of the ROP measurement vectors. Firstly, we introduce a\ndual perspective on the MROP acquisition, which can either be understood as\nrandom beamforming, or as a post-correlation compression. Secondly, we analyse\nthe noise statistics of MROPs and demonstrate that the random projections\ninduce a uniform noise level across measurements independently of the\nvisibility-weighting scheme used. Thirdly, we propose a detailed analysis of\nthe memory and computational cost requirements across the data acquisition and\nimage reconstruction stages, with comparison to state-of-the-art dimensionality\nreduction approaches. Finally, the MROP model is validated in simulation for\nmonochromatic intensity imaging, with comparison to the classical and\nbaseline-dependent averaging (BDA) models, and using the uSARA optimisation\nalgorithm for image formation. An extensive experimental setup is considered,\nwith ground-truth images containing diffuse and faint emission and spanning a\nwide variety of dynamic ranges, and for a range of $uv$-coverages corresponding\nto VLA and MeerKAT observation."}
{"id": "2504.18246", "pdf": "https://arxiv.org/pdf/2504.18246", "abs": "https://arxiv.org/abs/2504.18246", "authors": ["Ritesh Goru", "Shanay Mehta", "Prateek Jain"], "title": "Efficient Single-Pass Training for Multi-Turn Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "9 pages, 3 figures", "summary": "Training Large Language Models ( LLMs) to generate explicit reasoning before\nthey produce an answer has been shown to improve their performance across\nvarious tasks such as mathematics and coding. However, fine-tuning LLMs on\nmulti-turn reasoning datasets presents a unique challenge: LLMs must generate\nreasoning tokens that are excluded from subsequent inputs to the LLM. This\ndiscrepancy prevents us from processing an entire conversation in a single\nforward pass-an optimization readily available when we fine-tune on a\nmulti-turn non-reasoning dataset. This paper proposes a novel approach that\novercomes this limitation through response token duplication and a custom\nattention mask that enforces appropriate visibility constraints. Our approach\nsignificantly reduces the training time and allows efficient fine-tuning on\nmulti-turn reasoning datasets."}
{"id": "2504.17823", "pdf": "https://arxiv.org/pdf/2504.17823", "abs": "https://arxiv.org/abs/2504.17823", "authors": ["Darcy Kim", "Aida Kalender", "Sennay Ghebreab", "Giovanni Sileno"], "title": "The Cloud Weaving Model for AI development", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "presented at alt.CHI 2025, Yokohama", "summary": "While analysing challenges in pilot projects developing AI with marginalized\ncommunities, we found it difficult to express them within commonly used\nparadigms. We therefore constructed an alternative conceptual framework to\nground AI development in the social fabric -- the Cloud Weaving Model --\ninspired (amongst others) by indigenous knowledge, motifs from nature, and\nEastern traditions. This paper introduces and elaborates on the fundamental\nelements of the model (clouds, spiders, threads, spiderwebs, and weather) and\ntheir interpretation in an AI context. The framework is then applied to\ncomprehend patterns observed in co-creation pilots approaching marginalized\ncommunities, highlighting neglected yet relevant dimensions for responsible AI\ndevelopment."}
{"id": "2504.18082", "pdf": "https://arxiv.org/pdf/2504.18082", "abs": "https://arxiv.org/abs/2504.18082", "authors": ["Vignesh Balaji", "Christos Kozyrakis", "Gal Chechik", "Haggai Maron"], "title": "Efficient GNN Training Through Structure-Aware Randomized Mini-Batching", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) enable learning on realworld graphs and\nmini-batch training has emerged as the de facto standard for training GNNs\nbecause it can scale to very large graphs and improve convergence. Current\nmini-batch construction policies largely ignore efficiency considerations of\nGNN training. Specifically, existing mini-batching techniques employ\nrandomization schemes to improve accuracy and convergence. However, these\nrandomization schemes are often agnostic to the structural properties of the\ngraph (for eg. community structure), resulting in highly irregular memory\naccess patterns during GNN training that make suboptimal use of on-chip GPU\ncaches. On the other hand, while deterministic mini-batching based solely on\ngraph structure delivers fast runtime performance, the lack of randomness\ncompromises both the final model accuracy and training convergence speed. In\nthis paper, we present Community-structure-aware Randomized Mini-batching\n(COMM-RAND), a novel methodology that bridges the gap between the above\nextremes. COMM-RAND allows practitioners to explore the space between pure\nrandomness and pure graph structural awareness during mini-batch construction,\nleading to significantly more efficient GNN training with similar accuracy. We\nevaluated COMM-RAND across four popular graph learning benchmarks. COMM-RAND\ncuts down GNN training time by up to 2.76x (1.8x on average) while achieving an\naccuracy that is within 1.79% points (0.42% on average) compared to popular\nrandom mini-batching approaches."}
{"id": "2504.17894", "pdf": "https://arxiv.org/pdf/2504.17894", "abs": "https://arxiv.org/abs/2504.17894", "authors": ["Aniruddha Bala", "Rohit Chowdhury", "Rohan Jaiswal", "Siddharth Roheda"], "title": "DCT-Shield: A Robust Frequency Domain Defense against Malicious Image Editing", "categories": ["cs.CV"], "comment": null, "summary": "Advancements in diffusion models have enabled effortless image editing via\ntext prompts, raising concerns about image security. Attackers with access to\nuser images can exploit these tools for malicious edits. Recent defenses\nattempt to protect images by adding a limited noise in the pixel space to\ndisrupt the functioning of diffusion-based editing models. However, the\nadversarial noise added by previous methods is easily noticeable to the human\neye. Moreover, most of these methods are not robust to purification techniques\nlike JPEG compression under a feasible pixel budget. We propose a novel\noptimization approach that introduces adversarial perturbations directly in the\nfrequency domain by modifying the Discrete Cosine Transform (DCT) coefficients\nof the input image. By leveraging the JPEG pipeline, our method generates\nadversarial images that effectively prevent malicious image editing. Extensive\nexperiments across a variety of tasks and datasets demonstrate that our\napproach introduces fewer visual artifacts while maintaining similar levels of\nedit protection and robustness to noise purification techniques."}
{"id": "2504.18447", "pdf": "https://arxiv.org/pdf/2504.18447", "abs": "https://arxiv.org/abs/2504.18447", "authors": ["Ryo Yamaki", "Shintaro Shiba", "Guillermo Gallego", "Yoshimitsu Aoki"], "title": "Iterative Event-based Motion Segmentation by Variational Contrast Maximization", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": "11 pages, 9 figures, 3 tables, CVPR Workshop 2025", "summary": "Event cameras provide rich signals that are suitable for motion estimation\nsince they respond to changes in the scene. As any visual changes in the scene\nproduce event data, it is paramount to classify the data into different motions\n(i.e., motion segmentation), which is useful for various tasks such as object\ndetection and visual servoing. We propose an iterative motion segmentation\nmethod, by classifying events into background (e.g., dominant motion\nhypothesis) and foreground (independent motion residuals), thus extending the\nContrast Maximization framework. Experimental results demonstrate that the\nproposed method successfully classifies event clusters both for public and\nself-recorded datasets, producing sharp, motion-compensated edge-like images.\nThe proposed method achieves state-of-the-art accuracy on moving object\ndetection benchmarks with an improvement of over 30%, and demonstrates its\npossibility of applying to more complex and noisy real-world scenes. We hope\nthis work broadens the sensitivity of Contrast Maximization with respect to\nboth motion parameters and input events, thus contributing to theoretical\nadvancements in event-based motion segmentation estimation.\nhttps://github.com/aoki-media-lab/event_based_segmentation_vcmax"}
{"id": "2504.18260", "pdf": "https://arxiv.org/pdf/2504.18260", "abs": "https://arxiv.org/abs/2504.18260", "authors": ["Guanqun Bi", "Zhuang Chen", "Zhoufu Liu", "Hongkai Wang", "Xiyao Xiao", "Yuqiang Xie", "Wen Zhang", "Yongkang Huang", "Yuxuan Chen", "Libiao Peng", "Yi Feng", "Minlie Huang"], "title": "MAGI: Multi-Agent Guided Interview for Psychiatric Assessment", "categories": ["cs.CL"], "comment": "In progress", "summary": "Automating structured clinical interviews could revolutionize mental\nhealthcare accessibility, yet existing large language models (LLMs) approaches\nfail to align with psychiatric diagnostic protocols. We present MAGI, the first\nframework that transforms the gold-standard Mini International Neuropsychiatric\nInterview (MINI) into automatic computational workflows through coordinated\nmulti-agent collaboration. MAGI dynamically navigates clinical logic via four\nspecialized agents: 1) an interview tree guided navigation agent adhering to\nthe MINI's branching structure, 2) an adaptive question agent blending\ndiagnostic probing, explaining, and empathy, 3) a judgment agent validating\nwhether the response from participants meet the node, and 4) a diagnosis Agent\ngenerating Psychometric Chain-of- Thought (PsyCoT) traces that explicitly map\nsymptoms to clinical criteria. Experimental results on 1,002 real-world\nparticipants covering depression, generalized anxiety, social anxiety and\nsuicide shows that MAGI advances LLM- assisted mental health assessment by\ncombining clinical rigor, conversational adaptability, and explainable\nreasoning."}
{"id": "2504.17824", "pdf": "https://arxiv.org/pdf/2504.17824", "abs": "https://arxiv.org/abs/2504.17824", "authors": ["Yibin Wang", "Jiaxi Xie", "Lakshminarayanan Subramanian"], "title": "EduBot -- Can LLMs Solve Personalized Learning and Programming Assignments?", "categories": ["cs.SE", "cs.AI"], "comment": "Published at AAAI 2025 AI4EDU Workshop", "summary": "The prevalence of Large Language Models (LLMs) is revolutionizing the process\nof writing code. General and code LLMs have shown impressive performance in\ngenerating standalone functions and code-completion tasks with one-shot\nqueries. However, the ability to solve comprehensive programming tasks with\nrecursive requests and bug fixes remains questionable. In this paper, we\npropose EduBot, an intelligent automated assistant system that combines\nconceptual knowledge teaching, end-to-end code development, personalized\nprogramming through recursive prompt-driven methods, and debugging with limited\nhuman interventions powered by LLMs. We show that EduBot can solve complicated\nprogramming tasks consisting of sub-tasks with increasing difficulties ranging\nfrom conceptual to coding questions by recursive automatic prompt-driven\nsystems without finetuning on LLMs themselves. To further evaluate EduBot's\nperformance, we design and conduct a benchmark suite consisting of 20 scenarios\nin algorithms, machine learning, and real-world problems. The result shows that\nEduBot can complete most scenarios in less than 20 minutes. Based on the\nbenchmark suites, we perform a comparative study to take different LLMs as the\nbackbone and to verify EduBot's compatibility and robustness across LLMs with\nvarying capabilities. We believe that EduBot is an exploratory approach to\nexplore the potential of pre-trained LLMs in multi-step reasoning and code\ngeneration for solving personalized assignments with knowledge learning and\ncode generation."}
{"id": "2504.18091", "pdf": "https://arxiv.org/pdf/2504.18091", "abs": "https://arxiv.org/abs/2504.18091", "authors": ["Shota Deguchi", "Mitsuteru Asai"], "title": "Reliable and Efficient Inverse Analysis using Physics-Informed Neural Networks with Distance Functions and Adaptive Weight Tuning", "categories": ["cs.LG"], "comment": null, "summary": "Physics-informed neural networks have attracted significant attention in\nscientific machine learning for their capability to solve forward and inverse\nproblems governed by partial differential equations. However, the accuracy of\nPINN solutions is often limited by the treatment of boundary conditions.\nConventional penalty-based methods, which incorporate boundary conditions as\npenalty terms in the loss function, cannot guarantee exact satisfaction of the\ngiven boundary conditions and are highly sensitive to the choice of penalty\nparameters. This paper demonstrates that distance functions, specifically\nR-functions, can be leveraged to enforce boundary conditions, overcoming these\nlimitations. R-functions provide normalized distance fields, enabling accurate\nrepresentation of boundary geometries, including non-convex domains, and\nfacilitating various types of boundary conditions. We extend this distance\nfunction-based boundary condition imposition method to inverse problems using\nPINNs and introduce an adaptive weight tuning technique to ensure reliable and\nefficient inverse analysis. We demonstrate the efficacy of the method through\nseveral numerical experiments. Numerical results show that the proposed method\nsolves inverse problems more accurately and efficiently than penalty-based\nmethods, even in the presence of complex non-convex geometries. This approach\noffers a reliable and efficient framework for inverse analysis using PINNs,\nwith potential applications across a wide range of engineering problems."}
{"id": "2504.17902", "pdf": "https://arxiv.org/pdf/2504.17902", "abs": "https://arxiv.org/abs/2504.17902", "authors": ["Girish A. Koushik", "Diptesh Kanojia", "Helen Treharne", "Aditya Joshi"], "title": "CAMU: Context Augmentation for Meme Understanding", "categories": ["cs.CV", "cs.CL"], "comment": "Under review at ACM MM 2025", "summary": "Social media memes are a challenging domain for hate detection because they\nintertwine visual and textual cues into culturally nuanced messages. We\nintroduce a novel framework, CAMU, which leverages large vision-language models\nto generate more descriptive captions, a caption-scoring neural network to\nemphasise hate-relevant content, and parameter-efficient fine-tuning of CLIP's\ntext encoder for an improved multimodal understanding of memes. Experiments on\npublicly available hateful meme datasets show that simple projection layer\nfine-tuning yields modest gains, whereas selectively tuning deeper text encoder\nlayers significantly boosts performance on all evaluation metrics. Moreover,\nour approach attains high accuracy (0.807) and F1-score (0.806) on the Hateful\nMemes dataset, at par with the existing SoTA framework while being much more\nefficient, offering practical advantages in real-world scenarios that rely on\nfixed decision thresholds. CAMU also achieves the best F1-score of 0.673 on the\nMultiOFF dataset for offensive meme identification, demonstrating its\ngeneralisability. Additional analyses on benign confounders reveal that robust\nvisual grounding and nuanced text representations are crucial for reliable hate\nand offence detection. We will publicly release CAMU along with the resultant\nmodels for further research.\n  Disclaimer: This paper includes references to potentially disturbing,\nhateful, or offensive content due to the nature of the task."}
{"id": "2409.06833", "pdf": "https://arxiv.org/pdf/2409.06833", "abs": "https://arxiv.org/abs/2409.06833", "authors": ["Enrique Dehaerne", "Bappaditya Dey", "Victor Blanco", "Jesse Davis"], "title": "Scanning Electron Microscopy-based Automatic Defect Inspection for Semiconductor Manufacturing: A Systematic Review", "categories": ["eess.IV", "I.4.9"], "comment": "Accepted for publication in the Journal of Micro/Nanopatterning,\n  Materials, and Metrology (JM3)", "summary": "In this review, automatic defect inspection algorithms that analyze Scanning\nElectron Microscopy (SEM) images for Semiconductor Manufacturing (SM) are\nidentified, categorized, and discussed. This is a topic of critical importance\nfor the SM industry as the continuous shrinking of device patterns has led to\nincreasing defectivity and a greater prevalence of higher-resolution imaging\ntools such as SEM. Among others, these aspects threaten to increase costs due\nto increased inspection time-to-solution and decreased yield. Relevant research\npapers were systematically identified in four popular publication databases in\nJanuary 2024. A total of 103 papers were selected after screening for novel\ncontributions relating to automatic SEM image analysis algorithms for\nsemiconductor defect inspection. These papers were then categorized based on\nthe inspection tasks they addressed, their evaluation metrics, and the type of\nalgorithms used. A notable finding from this categorization is that\nreference-based defect detection algorithms were the most popular algorithm\ntype until 2020 when Deep Learning (DL)-based inspection algorithms became more\npopular, especially for defect classification. Furthermore, four broader\nresearch questions were discussed to come to the following conclusions: (i) the\nkey components of inspection algorithms are set up, pre-processing, feature\nextraction, and final prediction; (ii) the maturity of the manufacturing\nprocess affects the data availability and required sensitivity of inspection\nalgorithms; (iii) key challenges for these algorithms relate to the desiderata\nof minimizing time-to-solution which pushes for high imaging throughput,\nreducing manual input during algorithm setup, and higher processing throughput;\nand (iv) three promising directions for future work are suggested based on gaps\nin the reviewed literature that address key remaining limitations."}
{"id": "2504.18269", "pdf": "https://arxiv.org/pdf/2504.18269", "abs": "https://arxiv.org/abs/2504.18269", "authors": ["Shintaro Ozaki", "Kazuki Hayashi", "Yusuke Sakai", "Jingun Kwon", "Hidetaka Kamigaito", "Katsuhiko Hayashi", "Manabu Okumura", "Taro Watanabe"], "title": "TextTIGER: Text-based Intelligent Generation with Entity Prompt Refinement for Text-to-Image Generation", "categories": ["cs.CL", "cs.CV"], "comment": "Under review", "summary": "Generating images from prompts containing specific entities requires models\nto retain as much entity-specific knowledge as possible. However, fully\nmemorizing such knowledge is impractical due to the vast number of entities and\ntheir continuous emergence. To address this, we propose Text-based Intelligent\nGeneration with Entity prompt Refinement (TextTIGER), which augments knowledge\non entities included in the prompts and then summarizes the augmented\ndescriptions using Large Language Models (LLMs) to mitigate performance\ndegradation from longer inputs. To evaluate our method, we introduce WiT-Cub\n(WiT with Captions and Uncomplicated Background-explanations), a dataset\ncomprising captions, images, and an entity list. Experiments on four image\ngeneration models and five LLMs show that TextTIGER improves image generation\nperformance in standard metrics (IS, FID, and CLIPScore) compared to\ncaption-only prompts. Additionally, multiple annotators' evaluation confirms\nthat the summarized descriptions are more informative, validating LLMs' ability\nto generate concise yet rich descriptions. These findings demonstrate that\nrefining prompts with augmented and summarized entity-related descriptions\nenhances image generation capabilities. The code and dataset will be available\nupon acceptance."}
{"id": "2504.17827", "pdf": "https://arxiv.org/pdf/2504.17827", "abs": "https://arxiv.org/abs/2504.17827", "authors": ["Bingye Zhou", "Caiyang Yu"], "title": "Evolution Meets Diffusion: Efficient Neural Architecture Generation", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": null, "summary": "Neural Architecture Search (NAS) has gained widespread attention for its\ntransformative potential in deep learning model design. However, the vast and\ncomplex search space of NAS leads to significant computational and time costs.\nNeural Architecture Generation (NAG) addresses this by reframing NAS as a\ngeneration problem, enabling the precise generation of optimal architectures\nfor specific tasks. Despite its promise, mainstream methods like diffusion\nmodels face limitations in global search capabilities and are still hindered by\nhigh computational and time demands. To overcome these challenges, we propose\nEvolutionary Diffusion-based Neural Architecture Generation (EDNAG), a novel\napproach that achieves efficient and training-free architecture generation.\nEDNAG leverages evolutionary algorithms to simulate the denoising process in\ndiffusion models, using fitness to guide the transition from random Gaussian\ndistributions to optimal architecture distributions. This approach combines the\nstrengths of evolutionary strategies and diffusion models, enabling rapid and\neffective architecture generation. Extensive experiments demonstrate that EDNAG\nachieves state-of-the-art (SOTA) performance in architecture optimization, with\nan improvement in accuracy of up to 10.45%. Furthermore, it eliminates the need\nfor time-consuming training and boosts inference speed by an average of 50\ntimes, showcasing its exceptional efficiency and effectiveness."}
{"id": "2504.18095", "pdf": "https://arxiv.org/pdf/2504.18095", "abs": "https://arxiv.org/abs/2504.18095", "authors": ["Jerrin Thomas Panachakel", "Pradeep Kumar G.", "Suryaa Seran", "Kanishka Sharma", "Ramakrishnan Angarai Ganesan"], "title": "Subject-independent Classification of Meditative State from the Resting State using EEG", "categories": ["cs.LG", "eess.SP"], "comment": "copyright 2024 IEEE Personal use of this material is permitted. 2024\n  IEEE 21st India Council International Conference (INDICON). IEEE, 2024", "summary": "While it is beneficial to objectively determine whether a subject is\nmeditating, most research in the literature reports good results only in a\nsubject-dependent manner. This study aims to distinguish the modified state of\nconsciousness experienced during Rajyoga meditation from the resting state of\nthe brain in a subject-independent manner using EEG data. Three architectures\nhave been proposed and evaluated: The CSP-LDA Architecture utilizes common\nspatial pattern (CSP) for feature extraction and linear discriminant analysis\n(LDA) for classification. The CSP-LDA-LSTM Architecture employs CSP for feature\nextraction, LDA for dimensionality reduction, and long short-term memory (LSTM)\nnetworks for classification, modeling the binary classification problem as a\nsequence learning problem. The SVD-NN Architecture uses singular value\ndecomposition (SVD) to select the most relevant components of the EEG signals\nand a shallow neural network (NN) for classification. The CSP-LDA-LSTM\narchitecture gives the best performance with 98.2% accuracy for intra-subject\nclassification. The SVD-NN architecture provides significant performance with\n96.4\\% accuracy for inter-subject classification. This is comparable to the\nbest-reported accuracies in the literature for intra-subject classification.\nBoth architectures are capable of capturing subject-invariant EEG features for\neffectively classifying the meditative state from the resting state. The high\nintra-subject and inter-subject classification accuracies indicate these\nsystems' robustness and their ability to generalize across different subjects."}
{"id": "2504.17990", "pdf": "https://arxiv.org/pdf/2504.17990", "abs": "https://arxiv.org/abs/2504.17990", "authors": ["Yabing Wang", "Zhuotao Tian", "Qingpei Guo", "Zheng Qin", "Sanping Zhou", "Ming Yang", "Le Wang"], "title": "From Mapping to Composing: A Two-Stage Framework for Zero-shot Composed Image Retrieval", "categories": ["cs.CV"], "comment": null, "summary": "Composed Image Retrieval (CIR) is a challenging multimodal task that\nretrieves a target image based on a reference image and accompanying\nmodification text. Due to the high cost of annotating CIR triplet datasets,\nzero-shot (ZS) CIR has gained traction as a promising alternative. Existing\nstudies mainly focus on projection-based methods, which map an image to a\nsingle pseudo-word token. However, these methods face three critical\nchallenges: (1) insufficient pseudo-word token representation capacity, (2)\ndiscrepancies between training and inference phases, and (3) reliance on\nlarge-scale synthetic data. To address these issues, we propose a two-stage\nframework where the training is accomplished from mapping to composing. In the\nfirst stage, we enhance image-to-pseudo-word token learning by introducing a\nvisual semantic injection module and a soft text alignment objective, enabling\nthe token to capture richer and fine-grained image information. In the second\nstage, we optimize the text encoder using a small amount of synthetic triplet\ndata, enabling it to effectively extract compositional semantics by combining\npseudo-word tokens with modification text for accurate target image retrieval.\nThe strong visual-to-pseudo mapping established in the first stage provides a\nsolid foundation for the second stage, making our approach compatible with both\nhigh- and low-quality synthetic data, and capable of achieving significant\nperformance gains with only a small amount of synthetic data. Extensive\nexperiments were conducted on three public datasets, achieving superior\nperformance compared to existing approaches."}
{"id": "2504.17379", "pdf": "https://arxiv.org/pdf/2504.17379", "abs": "https://arxiv.org/abs/2504.17379", "authors": ["Hassan Keshvarikhojasteh", "Mihail Tifrea", "Sibylle Hess", "Josien P. W. Pluim", "Mitko Veta"], "title": "A Spatially-Aware Multiple Instance Learning Framework for Digital Pathology", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Multiple instance learning (MIL) is a promising approach for weakly\nsupervised classification in pathology using whole slide images (WSIs).\nHowever, conventional MIL methods such as Attention-Based Deep Multiple\nInstance Learning (ABMIL) typically disregard spatial interactions among\npatches that are crucial to pathological diagnosis. Recent advancements, such\nas Transformer based MIL (TransMIL), have incorporated spatial context and\ninter-patch relationships. However, it remains unclear whether explicitly\nmodeling patch relationships yields similar performance gains in ABMIL, which\nrelies solely on Multi-Layer Perceptrons (MLPs). In contrast, TransMIL employs\nTransformer-based layers, introducing a fundamental architectural shift at the\ncost of substantially increased computational complexity. In this work, we\nenhance the ABMIL framework by integrating interaction-aware representations to\naddress this question. Our proposed model, Global ABMIL (GABMIL), explicitly\ncaptures inter-instance dependencies while preserving computational efficiency.\nExperimental results on two publicly available datasets for tumor subtyping in\nbreast and lung cancers demonstrate that GABMIL achieves up to a 7 percentage\npoint improvement in AUPRC and a 5 percentage point increase in the Kappa score\nover ABMIL, with minimal or no additional computational overhead. These\nfindings underscore the importance of incorporating patch interactions within\nMIL frameworks. Our code is available at\n\\href{https://github.com/tueimage/GABMIL}{\\texttt{GABMIL}}."}
{"id": "2504.18346", "pdf": "https://arxiv.org/pdf/2504.18346", "abs": "https://arxiv.org/abs/2504.18346", "authors": ["Toghrul Abbasli", "Kentaroh Toyoda", "Yuan Wang", "Leon Witt", "Muhammad Asif Ali", "Yukai Miao", "Dan Li", "Qingsong Wei"], "title": "Comparing Uncertainty Measurement and Mitigation Methods for Large Language Models: A Systematic Review", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have been transformative across many domains.\nHowever, hallucination -- confidently outputting incorrect information --\nremains one of the leading challenges for LLMs. This raises the question of how\nto accurately assess and quantify the uncertainty of LLMs. Extensive literature\non traditional models has explored Uncertainty Quantification (UQ) to measure\nuncertainty and employed calibration techniques to address the misalignment\nbetween uncertainty and accuracy. While some of these methods have been adapted\nfor LLMs, the literature lacks an in-depth analysis of their effectiveness and\ndoes not offer a comprehensive benchmark to enable insightful comparison among\nexisting solutions. In this work, we fill this gap via a systematic survey of\nrepresentative prior works on UQ and calibration for LLMs and introduce a\nrigorous benchmark. Using two widely used reliability datasets, we empirically\nevaluate six related methods, which justify the significant findings of our\nreview. Finally, we provide outlooks for key future directions and outline open\nchallenges. To the best of our knowledge, this survey is the first dedicated\nstudy to review the calibration methods and relevant metrics for LLMs."}
{"id": "2504.17833", "pdf": "https://arxiv.org/pdf/2504.17833", "abs": "https://arxiv.org/abs/2504.17833", "authors": ["Xiao Huang", "Zhengzhong Tu", "Xinyue Ye", "Michael Goodchild"], "title": "The Role of Open-Source LLMs in Shaping the Future of GeoAI", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are transforming geospatial artificial\nintelligence (GeoAI), offering new capabilities in data processing, spatial\nanalysis, and decision support. This paper examines the open-source paradigm's\npivotal role in this transformation. While proprietary LLMs offer\naccessibility, they often limit the customization, interoperability, and\ntransparency vital for specialized geospatial tasks. Conversely, open-source\nalternatives significantly advance Geographic Information Science (GIScience)\nby fostering greater adaptability, reproducibility, and community-driven\ninnovation. Open frameworks empower researchers to tailor solutions, integrate\ncutting-edge methodologies (e.g., reinforcement learning, advanced spatial\nindexing), and align with FAIR principles. However, the growing reliance on any\nLLM necessitates careful consideration of security vulnerabilities, ethical\nrisks, and robust governance for AI-generated geospatial outputs. Ongoing\ndebates on accessibility, regulation, and misuse underscore the critical need\nfor responsible AI development strategies. This paper argues that GIScience\nadvances best not through a single model type, but by cultivating a diverse,\ninteroperable ecosystem combining open-source foundations for innovation,\nbespoke geospatial models, and interdisciplinary collaboration. By critically\nevaluating the opportunities and challenges of open-source LLMs within the\nbroader GeoAI landscape, this work contributes to a nuanced discourse on\nleveraging AI to effectively advance spatial research, policy, and\ndecision-making in an equitable, sustainable, and scientifically rigorous\nmanner."}
{"id": "2504.18105", "pdf": "https://arxiv.org/pdf/2504.18105", "abs": "https://arxiv.org/abs/2504.18105", "authors": ["Dinan Li", "Panagiotis Kakosimos"], "title": "Temperature Estimation in Induction Motors using Machine Learning", "categories": ["cs.LG"], "comment": "2023 IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other uses, in any current or future\n  media, including reprinting/republishing this material for advertising or\n  promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "The number of electrified powertrains is ever increasing today towards a more\nsustainable future; thus, it is essential that unwanted failures are prevented,\nand a reliable operation is secured. Monitoring the internal temperatures of\nmotors and keeping them under their thresholds is an important first step.\nConventional modeling methods require expert knowledge and complicated\nmathematical approaches. With all the data a modern electric drive collects\nnowadays during the system operation, it is feasible to apply data-driven\napproaches for estimating thermal behaviors. In this paper, multiple\nmachine-learning methods are investigated on their capability to approximate\nthe temperatures of the stator winding and bearing in induction motors. The\nexplored algorithms vary from linear to neural networks. For this reason,\nexperimental lab data have been captured from a powertrain under predetermined\noperating conditions. For each approach, a hyperparameter search is then\nperformed to find the optimal configuration. All the models are evaluated by\nvarious metrics, and it has been found that neural networks perform\nsatisfactorily even under transient conditions."}
{"id": "2504.17991", "pdf": "https://arxiv.org/pdf/2504.17991", "abs": "https://arxiv.org/abs/2504.17991", "authors": ["Zheng Qin", "Le Wang", "Yabing Wang", "Sanping Zhou", "Gang Hua", "Wei Tang"], "title": "RSRNav: Reasoning Spatial Relationship for Image-Goal Navigation", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Recent image-goal navigation (ImageNav) methods learn a perception-action\npolicy by separately capturing semantic features of the goal and egocentric\nimages, then passing them to a policy network. However, challenges remain: (1)\nSemantic features often fail to provide accurate directional information,\nleading to superfluous actions, and (2) performance drops significantly when\nviewpoint inconsistencies arise between training and application. To address\nthese challenges, we propose RSRNav, a simple yet effective method that reasons\nspatial relationships between the goal and current observations as navigation\nguidance. Specifically, we model the spatial relationship by constructing\ncorrelations between the goal and current observations, which are then passed\nto the policy network for action prediction. These correlations are\nprogressively refined using fine-grained cross-correlation and direction-aware\ncorrelation for more precise navigation. Extensive evaluation of RSRNav on\nthree benchmark datasets demonstrates superior navigation performance,\nparticularly in the \"user-matched goal\" setting, highlighting its potential for\nreal-world applications."}
{"id": "2410.22784", "pdf": "https://arxiv.org/pdf/2410.22784", "abs": "https://arxiv.org/abs/2410.22784", "authors": ["Omar Erak", "Omar Alhussein", "Wen Tong"], "title": "Contrastive Learning and Adversarial Disentanglement for Task-Oriented Semantic Communications", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.IT", "eess.IV", "math.IT"], "comment": null, "summary": "Task-oriented semantic communication systems have emerged as a promising\napproach to achieving efficient and intelligent data transmission, where only\ninformation relevant to a specific task is communicated. However, existing\nmethods struggle to fully disentangle task-relevant and task-irrelevant\ninformation, leading to privacy concerns and subpar performance. To address\nthis, we propose an information-bottleneck method, named CLAD (contrastive\nlearning and adversarial disentanglement). CLAD utilizes contrastive learning\nto effectively capture task-relevant features while employing adversarial\ndisentanglement to discard task-irrelevant information. Additionally, due to\nthe lack of reliable and reproducible methods to gain insight into the\ninformativeness and minimality of the encoded feature vectors, we introduce a\nnew technique to compute the information retention index (IRI), a comparative\nmetric used as a proxy for the mutual information between the encoded features\nand the input, reflecting the minimality of the encoded features. The IRI\nquantifies the minimality and informativeness of the encoded feature vectors\nacross different task-oriented communication techniques. Our extensive\nexperiments demonstrate that CLAD outperforms state-of-the-art baselines in\nterms of semantic extraction, task performance, privacy preservation, and IRI.\nCLAD achieves a predictive performance improvement of around 2.5-3%, along with\na 77-90% reduction in IRI and a 57-76% decrease in adversarial attribute\ninference attack accuracy."}
{"id": "2504.18373", "pdf": "https://arxiv.org/pdf/2504.18373", "abs": "https://arxiv.org/abs/2504.18373", "authors": ["Lei Shen", "Xiaoyu Shen"], "title": "Auto-SLURP: A Benchmark Dataset for Evaluating Multi-Agent Frameworks in Smart Personal Assistant", "categories": ["cs.CL"], "comment": null, "summary": "In recent years, multi-agent frameworks powered by large language models\n(LLMs) have advanced rapidly. Despite this progress, there is still a notable\nabsence of benchmark datasets specifically tailored to evaluate their\nperformance. To bridge this gap, we introduce Auto-SLURP, a benchmark dataset\naimed at evaluating LLM-based multi-agent frameworks in the context of\nintelligent personal assistants. Auto-SLURP extends the original SLURP dataset\n-- initially developed for natural language understanding tasks -- by\nrelabeling the data and integrating simulated servers and external services.\nThis enhancement enables a comprehensive end-to-end evaluation pipeline,\ncovering language understanding, task execution, and response generation. Our\nexperiments demonstrate that Auto-SLURP presents a significant challenge for\ncurrent state-of-the-art frameworks, highlighting that truly reliable and\nintelligent multi-agent personal assistants remain a work in progress. The\ndataset and related code are available at\nhttps://github.com/lorashen/Auto-SLURP/."}
{"id": "2504.17872", "pdf": "https://arxiv.org/pdf/2504.17872", "abs": "https://arxiv.org/abs/2504.17872", "authors": ["Max Muchen Sun", "Allison Pinosky", "Todd Murphey"], "title": "Flow Matching Ergodic Coverage", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "15 pages, 15 figures. Accepted to Robotics: Science and Systems (RSS)\n  2025. Project website: https://murpheylab.github.io/lqr-flow-matching/", "summary": "Ergodic coverage effectively generates exploratory behaviors for embodied\nagents by aligning the spatial distribution of the agent's trajectory with a\ntarget distribution, where the difference between these two distributions is\nmeasured by the ergodic metric. However, existing ergodic coverage methods are\nconstrained by the limited set of ergodic metrics available for control\nsynthesis, fundamentally limiting their performance. In this work, we propose\nan alternative approach to ergodic coverage based on flow matching, a technique\nwidely used in generative inference for efficient and scalable sampling. We\nformally derive the flow matching problem for ergodic coverage and show that it\nis equivalent to a linear quadratic regulator problem with a closed-form\nsolution. Our formulation enables alternative ergodic metrics from generative\ninference that overcome the limitations of existing ones. These metrics were\npreviously infeasible for control synthesis but can now be supported with no\ncomputational overhead. Specifically, flow matching with the Stein variational\ngradient flow enables control synthesis directly over the score function of the\ntarget distribution, improving robustness to the unnormalized distributions; on\nthe other hand, flow matching with the Sinkhorn divergence flow enables an\noptimal transport-based ergodic metric, improving coverage performance on\nnon-smooth distributions with irregular supports. We validate the improved\nperformance and competitive computational efficiency of our method through\ncomprehensive numerical benchmarks and across different nonlinear dynamics. We\nfurther demonstrate the practicality of our method through a series of drawing\nand erasing tasks on a Franka robot."}
{"id": "2504.18113", "pdf": "https://arxiv.org/pdf/2504.18113", "abs": "https://arxiv.org/abs/2504.18113", "authors": ["Aniket Dixit", "Muhammad Ibrahim Khan", "Faizan Ahmed", "James Brusey"], "title": "Learning from Less: SINDy Surrogates in RL", "categories": ["cs.LG", "cs.AI"], "comment": "World Models @ ICLR 2025", "summary": "This paper introduces an approach for developing surrogate environments in\nreinforcement learning (RL) using the Sparse Identification of Nonlinear\nDynamics (SINDy) algorithm. We demonstrate the effectiveness of our approach\nthrough extensive experiments in OpenAI Gym environments, particularly Mountain\nCar and Lunar Lander. Our results show that SINDy-based surrogate models can\naccurately capture the underlying dynamics of these environments while reducing\ncomputational costs by 20-35%. With only 75 interactions for Mountain Car and\n1000 for Lunar Lander, we achieve state-wise correlations exceeding 0.997, with\nmean squared errors as low as 3.11e-06 for Mountain Car velocity and 1.42e-06\nfor LunarLander position. RL agents trained in these surrogate environments\nrequire fewer total steps (65,075 vs. 100,000 for Mountain Car and 801,000 vs.\n1,000,000 for Lunar Lander) while achieving comparable performance to those\ntrained in the original environments, exhibiting similar convergence patterns\nand final performance metrics. This work contributes to the field of\nmodel-based RL by providing an efficient method for generating accurate,\ninterpretable surrogate environments."}
{"id": "2504.17996", "pdf": "https://arxiv.org/pdf/2504.17996", "abs": "https://arxiv.org/abs/2504.17996", "authors": ["Yuanbing Ouyang", "Yizhuo Liang", "Qingpeng Li", "Xinfei Guo", "Yiming Luo", "Di Wu", "Hao Wang", "Yushan Pan"], "title": "Back to Fundamentals: Low-Level Visual Features Guided Progressive Token Pruning", "categories": ["cs.CV"], "comment": null, "summary": "Vision Transformers (ViTs) excel in semantic segmentation but demand\nsignificant computation, posing challenges for deployment on\nresource-constrained devices. Existing token pruning methods often overlook\nfundamental visual data characteristics. This study introduces 'LVTP', a\nprogressive token pruning framework guided by multi-scale Tsallis entropy and\nlow-level visual features with twice clustering. It integrates high-level\nsemantics and basic visual attributes for precise segmentation. A novel dynamic\nscoring mechanism using multi-scale Tsallis entropy weighting overcomes\nlimitations of traditional single-parameter entropy. The framework also\nincorporates low-level feature analysis to preserve critical edge information\nwhile optimizing computational cost. As a plug-and-play module, it requires no\narchitectural changes or additional training. Evaluations across multiple\ndatasets show 20%-45% computational reductions with negligible performance\nloss, outperforming existing methods in balancing cost and accuracy, especially\nin complex edge regions."}
{"id": "2502.03430", "pdf": "https://arxiv.org/pdf/2502.03430", "abs": "https://arxiv.org/abs/2502.03430", "authors": ["Carlo Biffi", "Giorgio Roffo", "Pietro Salvagnini", "Andrea Cherubini"], "title": "A Temporal Convolutional Network-Based Approach and a Benchmark Dataset for Colonoscopy Video Temporal Segmentation", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Following recent advancements in computer-aided detection and diagnosis\nsystems for colonoscopy, the automated reporting of colonoscopy procedures is\nset to further revolutionize clinical practice. A crucial yet underexplored\naspect in the development of these systems is the creation of computer vision\nmodels capable of autonomously segmenting full-procedure colonoscopy videos\ninto anatomical sections and procedural phases. In this work, we aim to create\nthe first open-access dataset for this task and propose a state-of-the-art\napproach, benchmarked against competitive models. We annotated the publicly\navailable REAL-Colon dataset, consisting of 2.7 million frames from 60 complete\ncolonoscopy videos, with frame-level labels for anatomical locations and\ncolonoscopy phases across nine categories. We then present ColonTCN, a\nlearning-based architecture that employs custom temporal convolutional blocks\ndesigned to efficiently capture long temporal dependencies for the temporal\nsegmentation of colonoscopy videos. We also propose a dual k-fold\ncross-validation evaluation protocol for this benchmark, which includes model\nassessment on unseen, multi-center data.ColonTCN achieves state-of-the-art\nperformance in classification accuracy while maintaining a low parameter count\nwhen evaluated using the two proposed k-fold cross-validation settings,\noutperforming competitive models. We report ablation studies to provide\ninsights into the challenges of this task and highlight the benefits of the\ncustom temporal convolutional blocks, which enhance learning and improve model\nefficiency. We believe that the proposed open-access benchmark and the ColonTCN\napproach represent a significant advancement in the temporal segmentation of\ncolonoscopy procedures, fostering further open-access research to address this\nclinical need."}
{"id": "2504.18376", "pdf": "https://arxiv.org/pdf/2504.18376", "abs": "https://arxiv.org/abs/2504.18376", "authors": ["Pablo Miralles-Gonz√°lez", "Javier Huertas-Tato", "Alejandro Mart√≠n", "David Camacho"], "title": "Pushing the boundary on Natural Language Inference", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Natural Language Inference (NLI) is a central task in natural language\nunderstanding with applications in fact-checking, question answering, and\ninformation retrieval. Despite its importance, current NLI systems heavily rely\non supervised learning with datasets that often contain annotation artifacts\nand biases, limiting generalization and real-world applicability. In this work,\nwe apply a reinforcement learning-based approach using Group Relative Policy\nOptimization (GRPO) for Chain-of-Thought (CoT) learning in NLI, eliminating the\nneed for labeled rationales and enabling this type of training on more\nchallenging datasets such as ANLI. We fine-tune 7B, 14B, and 32B language\nmodels using parameter-efficient techniques (LoRA and QLoRA), demonstrating\nstrong performance across standard and adversarial NLI benchmarks. Our 32B\nAWQ-quantized model surpasses state-of-the-art results on 7 out of 11\nadversarial sets$\\unicode{x2013}$or on all of them considering our\nreplication$\\unicode{x2013}$within a 22GB memory footprint, showing that robust\nreasoning can be retained under aggressive quantization. This work provides a\nscalable and practical framework for building robust NLI systems without\nsacrificing inference quality."}
{"id": "2504.17878", "pdf": "https://arxiv.org/pdf/2504.17878", "abs": "https://arxiv.org/abs/2504.17878", "authors": ["Xu Wang", "Yiquan Wang", "Tin-yeh Huang"], "title": "Crypto-ncRNA: Non-coding RNA (ncRNA) Based Encryption Algorithm", "categories": ["cs.CR", "cs.AI"], "comment": "Accepted at the AI4NA workshop at ICLR 2025. 18pages, 4figures", "summary": "In the looming post-quantum era, traditional cryptographic systems are\nincreasingly vulnerable to quantum computing attacks that can compromise their\nmathematical foundations. To address this critical challenge, we propose\ncrypto-ncRNA-a bio-convergent cryptographic framework that leverages the\ndynamic folding properties of non-coding RNA (ncRNA) to generate high-entropy,\nquantum-resistant keys and produce unpredictable ciphertexts. The framework\nemploys a novel, multi-stage process: encoding plaintext into RNA sequences,\npredicting and manipulating RNA secondary structures using advanced algorithms,\nand deriving cryptographic keys through the intrinsic physical unclonability of\nRNA molecules. Experimental evaluations indicate that, although crypto-ncRNA's\nencryption speed is marginally lower than that of AES, it significantly\noutperforms RSA in terms of efficiency and scalability while achieving a 100%\npass rate on the NIST SP 800-22 randomness tests. These results demonstrate\nthat crypto-ncRNA offers a promising and robust approach for securing digital\ninfrastructures against the evolving threats posed by quantum computing."}
{"id": "2504.18116", "pdf": "https://arxiv.org/pdf/2504.18116", "abs": "https://arxiv.org/abs/2504.18116", "authors": ["Caia Costello", "Simon Guo", "Anna Goldie", "Azalia Mirhoseini"], "title": "Think, Prune, Train, Improve: Scaling Reasoning without Scaling Models", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) have demonstrated strong capabilities in\nprogramming and mathematical reasoning tasks, but are constrained by limited\nhigh-quality training data. Synthetic data can be leveraged to enhance\nfine-tuning outcomes, but several factors influence this process, including\nmodel size, synthetic data volume, pruning strategy, and number of fine-tuning\nrounds. We explore these axes and investigate which conditions enable model\nself-improvement. We introduce the Think, Prune, Train process, a scalable\nframework that iteratively fine-tunes models on their own reasoning traces,\nusing ground-truth pruning to ensure high-quality training data. This approach\nyields improved performance: on GSM8K, Gemma2-2B achieves a Pass@1 of 57.6%\n(from 41.9%), Gemma2-9B reaches 82%, matching LLaMA-3.1-70B, and LLaMA-3.1-70B\nattains 91%, even surpassing GPT-4o, demonstrating the effectiveness of\nself-generated reasoning and systematic data selection for improving LLM\ncapabilities."}
{"id": "2504.18020", "pdf": "https://arxiv.org/pdf/2504.18020", "abs": "https://arxiv.org/abs/2504.18020", "authors": ["Guyue Hu", "Siyuan Song", "Yukun Kang", "Zhu Yin", "Gangming Zhao", "Chenglong Li", "Jin Tang"], "title": "Federated Client-tailored Adapter for Medical Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Medical image segmentation in X-ray images is beneficial for computer-aided\ndiagnosis and lesion localization. Existing methods mainly fall into a\ncentralized learning paradigm, which is inapplicable in the practical medical\nscenario that only has access to distributed data islands. Federated Learning\nhas the potential to offer a distributed solution but struggles with heavy\ntraining instability due to client-wise domain heterogeneity (including\ndistribution diversity and class imbalance). In this paper, we propose a novel\nFederated Client-tailored Adapter (FCA) framework for medical image\nsegmentation, which achieves stable and client-tailored adaptive segmentation\nwithout sharing sensitive local data. Specifically, the federated adapter stirs\nuniversal knowledge in off-the-shelf medical foundation models to stabilize the\nfederated training process. In addition, we develop two client-tailored\nfederated updating strategies that adaptively decompose the adapter into common\nand individual components, then globally and independently update the parameter\ngroups associated with common client-invariant and individual client-specific\nunits, respectively. They further stabilize the heterogeneous federated\nlearning process and realize optimal client-tailored instead of sub-optimal\nglobal-compromised segmentation models. Extensive experiments on three\nlarge-scale datasets demonstrate the effectiveness and superiority of the\nproposed FCA framework for federated medical segmentation."}
{"id": "2504.08937", "pdf": "https://arxiv.org/pdf/2504.08937", "abs": "https://arxiv.org/abs/2504.08937", "authors": ["Minjie Deng", "Yan Wei", "Hao Zhai", "An Wu", "Yuncan Ouyang", "Qianyao Peng"], "title": "Rethinking Few-Shot Image Fusion: Granular Ball Priors Enable General-Purpose Deep Fusion", "categories": ["cs.GR", "cs.CV", "cs.LG", "eess.IV", "stat.ML"], "comment": null, "summary": "In image fusion tasks, the absence of real fused images as priors presents a\nfundamental challenge. Most deep learning-based fusion methods rely on\nlarge-scale paired datasets to extract global weighting features from raw\nimages, thereby generating fused outputs that approximate real fused images. In\ncontrast to previous studies, this paper explores few-shot training of neural\nnetworks under the condition of having prior knowledge. We propose a novel\nfusion framework named GBFF, and a Granular Ball Significant Extraction\nalgorithm specifically designed for the few-shot prior setting. All pixel pairs\ninvolved in the fusion process are initially modeled as a Coarse-Grained\nGranular Ball. At the local level, Fine-Grained Granular Balls are used to\nslide through the brightness space to extract Non-Salient Pixel Pairs, and\nperform splitting operations to obtain Salient Pixel Pairs. Pixel-wise weights\nare then computed to generate a pseudo-supervised image. At the global level,\npixel pairs with significant contributions to the fusion process are\ncategorized into the Positive Region, while those whose contributions cannot be\naccurately determined are assigned to the Boundary Region. The Granular Ball\nperforms modality-aware adaptation based on the proportion of the positive\nregion, thereby adjusting the neural network's loss function and enabling it to\ncomplement the information of the boundary region. Extensive experiments\ndemonstrate the effectiveness of both the proposed algorithm and the underlying\ntheory. Compared with state-of-the-art (SOTA) methods, our approach shows\nstrong competitiveness in terms of both fusion time and image expressiveness.\nOur code is publicly available at:"}
{"id": "2504.18386", "pdf": "https://arxiv.org/pdf/2504.18386", "abs": "https://arxiv.org/abs/2504.18386", "authors": ["Amir Zeldes", "Nina Speransky", "Nicholas Wagner", "Caroline T. Schroeder"], "title": "A UD Treebank for Bohairic Coptic", "categories": ["cs.CL"], "comment": null, "summary": "Despite recent advances in digital resources for other Coptic dialects,\nespecially Sahidic, Bohairic Coptic, the main Coptic dialect for pre-Mamluk,\nlate Byzantine Egypt, and the contemporary language of the Coptic Church,\nremains critically under-resourced. This paper presents and evaluates the first\nsyntactically annotated corpus of Bohairic Coptic, sampling data from a range\nof works, including Biblical text, saints' lives and Christian ascetic writing.\nWe also explore some of the main differences we observe compared to the\nexisting UD treebank of Sahidic Coptic, the classical dialect of the language,\nand conduct joint and cross-dialect parsing experiments, revealing the unique\nnature of Bohairic as a related, but distinct variety from the more often\nstudied Sahidic."}
{"id": "2504.17901", "pdf": "https://arxiv.org/pdf/2504.17901", "abs": "https://arxiv.org/abs/2504.17901", "authors": ["Benned Hedegaard", "Ziyi Yang", "Yichen Wei", "Ahmed Jaafar", "Stefanie Tellex", "George Konidaris", "Naman Shah"], "title": "Beyond Task and Motion Planning: Hierarchical Robot Planning with General-Purpose Policies", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Task and motion planning is a well-established approach for solving\nlong-horizon robot planning problems. However, traditional methods assume that\neach task-level robot action, or skill, can be reduced to kinematic motion\nplanning. In this work, we address the challenge of planning with both\nkinematic skills and closed-loop motor controllers that go beyond kinematic\nconsiderations. We propose a novel method that integrates these controllers\ninto motion planning using Composable Interaction Primitives (CIPs), enabling\nthe use of diverse, non-composable pre-learned skills in hierarchical robot\nplanning. Toward validating our Task and Skill Planning (TASP) approach, we\ndescribe ongoing robot experiments in real-world scenarios designed to\ndemonstrate how CIPs can allow a mobile manipulator robot to effectively\ncombine motion planning with general-purpose skills to accomplish complex\ntasks."}
{"id": "2504.18130", "pdf": "https://arxiv.org/pdf/2504.18130", "abs": "https://arxiv.org/abs/2504.18130", "authors": ["Vasily Ilin", "Bamdad Hosseini", "Jingwei Hu"], "title": "Score-Based Deterministic Density Sampling", "categories": ["cs.LG", "math.PR", "math.ST", "stat.TH"], "comment": null, "summary": "We propose and analyze a deterministic sampling framework using Score-Based\nTransport Modeling (SBTM) for sampling an unnormalized target density $\\pi$.\nWhile diffusion generative modeling relies on pre-training the score function\n$\\nabla \\log f_t$ using samples from $\\pi$, SBTM addresses the more general and\nchallenging setting where only $\\nabla \\log\\pi$ is known. SBTM approximates the\nWasserstein gradient flow on KL$(f_t\\|\\pi)$ by learning the time-varying score\n$\\nabla \\log f_t$ on the fly using score matching. The learned score gives\nimmediate access to relative Fisher information, providing a built-in\nconvergence diagnostic. The deterministic trajectories are smooth,\ninterpretable, and free of Brownian-motion noise, while having the same\ndistribution as ULA. We prove that SBTM dissipates relative entropy at the same\nrate as the exact gradient flow, provided sufficient training. We further\nextend our framework to annealed dynamics, to handle non log-concave targets.\nNumerical experiments validate our theoretical findings: SBTM converges at the\noptimal rate, has smooth trajectories, and is easily integrated with annealed\ndynamics. We compare to the baselines of ULA and annealed ULA."}
{"id": "2504.18025", "pdf": "https://arxiv.org/pdf/2504.18025", "abs": "https://arxiv.org/abs/2504.18025", "authors": ["Shuanglin Yan", "Neng Dong", "Shuang Li", "Rui Yan", "Hao Tang", "Jing Qin"], "title": "ShapeSpeak: Body Shape-Aware Textual Alignment for Visible-Infrared Person Re-Identification", "categories": ["cs.CV"], "comment": null, "summary": "Visible-Infrared Person Re-identification (VIReID) aims to match visible and\ninfrared pedestrian images, but the modality differences and the complexity of\nidentity features make it challenging. Existing methods rely solely on identity\nlabel supervision, which makes it difficult to fully extract high-level\nsemantic information. Recently, vision-language pre-trained models have been\nintroduced to VIReID, enhancing semantic information modeling by generating\ntextual descriptions. However, such methods do not explicitly model body shape\nfeatures, which are crucial for cross-modal matching. To address this, we\npropose an effective Body Shape-aware Textual Alignment (BSaTa) framework that\nexplicitly models and utilizes body shape information to improve VIReID\nperformance. Specifically, we design a Body Shape Textual Alignment (BSTA)\nmodule that extracts body shape information using a human parsing model and\nconverts it into structured text representations via CLIP. We also design a\nText-Visual Consistency Regularizer (TVCR) to ensure alignment between body\nshape textual representations and visual body shape features. Furthermore, we\nintroduce a Shape-aware Representation Learning (SRL) mechanism that combines\nMulti-text Supervision and Distribution Consistency Constraints to guide the\nvisual encoder to learn modality-invariant and discriminative identity\nfeatures, thus enhancing modality invariance. Experimental results demonstrate\nthat our method achieves superior performance on the SYSU-MM01 and RegDB\ndatasets, validating its effectiveness."}
{"id": "2504.18406", "pdf": "https://arxiv.org/pdf/2504.18406", "abs": "https://arxiv.org/abs/2504.18406", "authors": ["Yusen Zhang", "Wenliang Zheng", "Aashrith Madasu", "Peng Shi", "Ryo Kamoi", "Hao Zhou", "Zhuoyang Zou", "Shu Zhao", "Sarkar Snigdha Sarathi Das", "Vipul Gupta", "Xiaoxin Lu", "Nan Zhang", "Ranran Haoran Zhang", "Avitej Iyer", "Renze Lou", "Wenpeng Yin", "Rui Zhang"], "title": "HRScene: How Far Are VLMs from Effective High-Resolution Image Understanding?", "categories": ["cs.CL"], "comment": "22 pages, 8 figures", "summary": "High-resolution image (HRI) understanding aims to process images with a large\nnumber of pixels, such as pathological images and agricultural aerial images,\nboth of which can exceed 1 million pixels. Vision Large Language Models (VLMs)\ncan allegedly handle HRIs, however, there is a lack of a comprehensive\nbenchmark for VLMs to evaluate HRI understanding. To address this gap, we\nintroduce HRScene, a novel unified benchmark for HRI understanding with rich\nscenes. HRScene incorporates 25 real-world datasets and 2 synthetic diagnostic\ndatasets with resolutions ranging from 1,024 $\\times$ 1,024 to 35,503 $\\times$\n26,627. HRScene is collected and re-annotated by 10 graduate-level annotators,\ncovering 25 scenarios, ranging from microscopic to radiology images, street\nviews, long-range pictures, and telescope images. It includes HRIs of\nreal-world objects, scanned documents, and composite multi-image. The two\ndiagnostic evaluation datasets are synthesized by combining the target image\nwith the gold answer and distracting images in different orders, assessing how\nwell models utilize regions in HRI. We conduct extensive experiments involving\n28 VLMs, including Gemini 2.0 Flash and GPT-4o. Experiments on HRScene show\nthat current VLMs achieve an average accuracy of around 50% on real-world\ntasks, revealing significant gaps in HRI understanding. Results on synthetic\ndatasets reveal that VLMs struggle to effectively utilize HRI regions, showing\nsignificant Regional Divergence and lost-in-middle, shedding light on future\nresearch."}
{"id": "2504.17964", "pdf": "https://arxiv.org/pdf/2504.17964", "abs": "https://arxiv.org/abs/2504.17964", "authors": ["Celia Chen", "Alex Leitch"], "title": "Evaluating Machine Expertise: How Graduate Students Develop Frameworks for Assessing GenAI Content", "categories": ["cs.HC", "cs.AI"], "comment": "Under review at ACM Web Science Conference 2025's Human-GenAI\n  Interactions Workshop, 4 pages", "summary": "This paper examines how graduate students develop frameworks for evaluating\nmachine-generated expertise in web-based interactions with large language\nmodels (LLMs). Through a qualitative study combining surveys, LLM interaction\ntranscripts, and in-depth interviews with 14 graduate students, we identify\npatterns in how these emerging professionals assess and engage with\nAI-generated content. Our findings reveal that students construct evaluation\nframeworks shaped by three main factors: professional identity, verification\ncapabilities, and system navigation experience. Rather than uniformly accepting\nor rejecting LLM outputs, students protect domains central to their\nprofessional identities while delegating others--with managers preserving\nconceptual work, designers safeguarding creative processes, and programmers\nmaintaining control over core technical expertise. These evaluation frameworks\nare further influenced by students' ability to verify different types of\ncontent and their experience navigating complex systems. This research\ncontributes to web science by highlighting emerging human-genAI interaction\npatterns and suggesting how platforms might better support users in developing\neffective frameworks for evaluating machine-generated expertise signals in\nAI-mediated web environments."}
{"id": "2504.18133", "pdf": "https://arxiv.org/pdf/2504.18133", "abs": "https://arxiv.org/abs/2504.18133", "authors": ["Gissel Velarde", "Michael Weichert", "Anuj Deshmunkh", "Sanjay Deshmane", "Anindya Sudhir", "Khushboo Sharma", "Vaibhav Joshi"], "title": "Tree Boosting Methods for Balanced andImbalanced Classification and their Robustness Over Time in Risk Assessment", "categories": ["cs.LG"], "comment": "14 pages. arXiv admin note: text overlap with arXiv:2303.15218", "summary": "Most real-world classification problems deal with imbalanced datasets, posing\na challenge for Artificial Intelligence (AI), i.e., machine learning\nalgorithms, because the minority class, which is of extreme interest, often\nproves difficult to be detected. This paper empirically evaluates tree boosting\nmethods' performance given different dataset sizes and class distributions,\nfrom perfectly balanced to highly imbalanced. For tabular data, tree-based\nmethods such as XGBoost, stand out in several benchmarks due to detection\nperformance and speed. Therefore, XGBoost and Imbalance-XGBoost are evaluated.\nAfter introducing the motivation to address risk assessment with machine\nlearning, the paper reviews evaluation metrics for detection systems or binary\nclassifiers. It proposes a method for data preparation followed by tree\nboosting methods including hyper-parameter optimization. The method is\nevaluated on private datasets of 1 thousand (K), 10K and 100K samples on\ndistributions with 50, 45, 25, and 5 percent positive samples. As expected, the\ndeveloped method increases its recognition performance as more data is given\nfor training and the F1 score decreases as the data distribution becomes more\nimbalanced, but it is still significantly superior to the baseline of\nprecision-recall determined by the ratio of positives divided by positives and\nnegatives. Sampling to balance the training set does not provide consistent\nimprovement and deteriorates detection. In contrast, classifier hyper-parameter\noptimization improves recognition, but should be applied carefully depending on\ndata volume and distribution. Finally, the developed method is robust to data\nvariation over time up to some point. Retraining can be used when performance\nstarts deteriorating."}
{"id": "2504.18027", "pdf": "https://arxiv.org/pdf/2504.18027", "abs": "https://arxiv.org/abs/2504.18027", "authors": ["Zezhou Chen", "Zhaoxiang Liu", "Kai Wang", "Kohou Wang", "Shiguo Lian"], "title": "A Large Vision-Language Model based Environment Perception System for Visually Impaired People", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "Accepted by IROS2024(9 pages, 8 figures)", "summary": "It is a challenging task for visually impaired people to perceive their\nsurrounding environment due to the complexity of the natural scenes. Their\npersonal and social activities are thus highly limited. This paper introduces a\nLarge Vision-Language Model(LVLM) based environment perception system which\nhelps them to better understand the surrounding environment, by capturing the\ncurrent scene they face with a wearable device, and then letting them retrieve\nthe analysis results through the device. The visually impaired people could\nacquire a global description of the scene by long pressing the screen to\nactivate the LVLM output, retrieve the categories of the objects in the scene\nresulting from a segmentation model by tapping or swiping the screen, and get a\ndetailed description of the objects they are interested in by double-tapping\nthe screen. To help visually impaired people more accurately perceive the\nworld, this paper proposes incorporating the segmentation result of the RGB\nimage as external knowledge into the input of LVLM to reduce the LVLM's\nhallucination. Technical experiments on POPE, MME and LLaVA-QA90 show that the\nsystem could provide a more accurate description of the scene compared to\nQwen-VL-Chat, exploratory experiments show that the system helps visually\nimpaired people to perceive the surrounding environment effectively."}
{"id": "2504.18412", "pdf": "https://arxiv.org/pdf/2504.18412", "abs": "https://arxiv.org/abs/2504.18412", "authors": ["Jared Moore", "Declan Grabb", "William Agnew", "Kevin Klyman", "Stevie Chancellor", "Desmond C. Ong", "Nick Haber"], "title": "Expressing stigma and inappropriate responses prevents LLMs from safely replacing mental health providers", "categories": ["cs.CL"], "comment": null, "summary": "Should a large language model (LLM) be used as a therapist? In this paper, we\ninvestigate the use of LLMs to *replace* mental health providers, a use case\npromoted in the tech startup and research space. We conduct a mapping review of\ntherapy guides used by major medical institutions to identify crucial aspects\nof therapeutic relationships, such as the importance of a therapeutic alliance\nbetween therapist and client. We then assess the ability of LLMs to reproduce\nand adhere to these aspects of therapeutic relationships by conducting several\nexperiments investigating the responses of current LLMs, such as `gpt-4o`.\nContrary to best practices in the medical community, LLMs 1) express stigma\ntoward those with mental health conditions and 2) respond inappropriately to\ncertain common (and critical) conditions in naturalistic therapy settings --\ne.g., LLMs encourage clients' delusional thinking, likely due to their\nsycophancy. This occurs even with larger and newer LLMs, indicating that\ncurrent safety practices may not address these gaps. Furthermore, we note\nfoundational and practical barriers to the adoption of LLMs as therapists, such\nas that a therapeutic alliance requires human characteristics (e.g., identity\nand stakes). For these reasons, we conclude that LLMs should not replace\ntherapists, and we discuss alternative roles for LLMs in clinical therapy."}
{"id": "2504.17979", "pdf": "https://arxiv.org/pdf/2504.17979", "abs": "https://arxiv.org/abs/2504.17979", "authors": ["Kaaustaaub Shankar", "Wilhelm Louw", "Bharadwaj Dogga", "Nick Ernest", "Tim Arnett", "Kelly Cohen"], "title": "Fuzzy-RRT for Obstacle Avoidance in a 2-DOF Semi-Autonomous Surgical Robotic Arm", "categories": ["cs.RO", "cs.AI"], "comment": "9 pages, 5 figures. Submitted to NAFIPS 2025 Conference (North\n  American Fuzzy Information Processing Society). Includes results on Fuzzy-RRT\n  performance in surgical robotics path planning", "summary": "AI-driven semi-autonomous robotic surgery is essential for addressing the\nmedical challenges of long-duration interplanetary missions, where limited crew\nsizes and communication delays restrict traditional surgical approaches.\nCurrent robotic surgery systems require full surgeon control, demanding\nextensive expertise and limiting feasibility in space. We propose a novel\nadaptation of the Fuzzy Rapidly-exploring Random Tree algorithm for obstacle\navoidance and collaborative control in a two-degree-of-freedom robotic arm\nmodeled on the Miniaturized Robotic-Assisted surgical system. It was found that\nthe Fuzzy Rapidly-exploring Random Tree algorithm resulted in an 743 percent\nimprovement to path search time and 43 percent improvement to path cost."}
{"id": "2504.18148", "pdf": "https://arxiv.org/pdf/2504.18148", "abs": "https://arxiv.org/abs/2504.18148", "authors": ["Xiaofan Wei", "Binyan Zhang"], "title": "A Generative Graph Contrastive Learning Model with Global Signal", "categories": ["cs.LG"], "comment": null, "summary": "Graph contrastive learning (GCL) has garnered significant attention recently\nsince it learns complex structural information from graphs through\nself-supervised learning manner. However, prevalent GCL models may suffer from\nperformance degradation due to inappropriate contrastive signals. Concretely,\nthey commonly generate augmented views based on random perturbation, which\nleads to biased essential structures due to the introduction of noise. In\naddition, they assign equal weight to both hard and easy sample pairs, thereby\nignoring the difference in importance of the sample pairs. To address these\nissues, this study proposes a novel Contrastive Signal Generative Framework for\nAccurate Graph Learning (CSG2L) with the following two-fold ideas: a) building\na singular value decomposition (SVD)-directed augmented module (SVD-aug) to\nobtain the global interactions as well as avoiding the random noise\nperturbation; b) designing a local-global dependency learning module (LGDL)\nwith an adaptive reweighting strategy which can differentiate the effects of\nhard and easy sample pairs. Extensive experiments on benchmark datasets\ndemonstrate that the proposed CSG2L outperforms the state-of-art baselines.\nMoreover, CSG2L is compatible with a variety of GNNs."}
{"id": "2504.18032", "pdf": "https://arxiv.org/pdf/2504.18032", "abs": "https://arxiv.org/abs/2504.18032", "authors": ["Chen Chen", "Daochang Liu", "Mubarak Shah", "Chang Xu"], "title": "Enhancing Privacy-Utility Trade-offs to Mitigate Memorization in Diffusion Models", "categories": ["cs.CV"], "comment": "Accepted at CVPR 2025. Project page:\n  https://chenchen-usyd.github.io/PRSS-Project-Page/", "summary": "Text-to-image diffusion models have demonstrated remarkable capabilities in\ncreating images highly aligned with user prompts, yet their proclivity for\nmemorizing training set images has sparked concerns about the originality of\nthe generated images and privacy issues, potentially leading to legal\ncomplications for both model owners and users, particularly when the memorized\nimages contain proprietary content. Although methods to mitigate these issues\nhave been suggested, enhancing privacy often results in a significant decrease\nin the utility of the outputs, as indicated by text-alignment scores. To bridge\nthe research gap, we introduce a novel method, PRSS, which refines the\nclassifier-free guidance approach in diffusion models by integrating prompt\nre-anchoring (PR) to improve privacy and incorporating semantic prompt search\n(SS) to enhance utility. Extensive experiments across various privacy levels\ndemonstrate that our approach consistently improves the privacy-utility\ntrade-off, establishing a new state-of-the-art."}
{"id": "2504.18415", "pdf": "https://arxiv.org/pdf/2504.18415", "abs": "https://arxiv.org/abs/2504.18415", "authors": ["Hongyu Wang", "Shuming Ma", "Furu Wei"], "title": "BitNet v2: Native 4-bit Activations with Hadamard Transformation for 1-bit LLMs", "categories": ["cs.CL", "cs.LG"], "comment": "Work in progress", "summary": "Efficient deployment of 1-bit Large Language Models (LLMs) is hindered by\nactivation outliers, which complicate quantization to low bit-widths. We\nintroduce BitNet v2, a novel framework enabling native 4-bit activation\nquantization for 1-bit LLMs. To tackle outliers in attention and feed-forward\nnetwork activations, we propose H-BitLinear, a module applying an online\nHadamard transformation prior to activation quantization. This transformation\nsmooths sharp activation distributions into more Gaussian-like forms, suitable\nfor low-bit representation. Experiments show BitNet v2 trained from scratch\nwith 8-bit activations matches BitNet b1.58 performance. Crucially, BitNet v2\nachieves minimal performance degradation when trained with native 4-bit\nactivations, significantly reducing memory footprint and computational cost for\nbatched inference."}
{"id": "2504.18010", "pdf": "https://arxiv.org/pdf/2504.18010", "abs": "https://arxiv.org/abs/2504.18010", "authors": ["Zilin Huang", "Zihao Sheng", "Zhengyang Wan", "Yansong Qu", "Yuhao Luo", "Boyue Wang", "Pei Li", "Yen-Jung Chen", "Jiancong Chen", "Keke Long", "Jiayi Meng", "Yue Leng", "Sikai Chen"], "title": "Sky-Drive: A Distributed Multi-Agent Simulation Platform for Socially-Aware and Human-AI Collaborative Future Transportation", "categories": ["cs.RO", "cs.AI", "cs.HC"], "comment": "15 pages, 7 figures", "summary": "Recent advances in autonomous system simulation platforms have significantly\nenhanced the safe and scalable testing of driving policies. However, existing\nsimulators do not yet fully meet the needs of future transportation research,\nparticularly in modeling socially-aware driving agents and enabling effective\nhuman-AI collaboration. This paper introduces Sky-Drive, a novel distributed\nmulti-agent simulation platform that addresses these limitations through four\nkey innovations: (a) a distributed architecture for synchronized simulation\nacross multiple terminals; (b) a multi-modal human-in-the-loop framework\nintegrating diverse sensors to collect rich behavioral data; (c) a human-AI\ncollaboration mechanism supporting continuous and adaptive knowledge exchange;\nand (d) a digital twin (DT) framework for constructing high-fidelity virtual\nreplicas of real-world transportation environments. Sky-Drive supports diverse\napplications such as autonomous vehicle (AV)-vulnerable road user (VRU)\ninteraction modeling, human-in-the-loop training, socially-aware reinforcement\nlearning, personalized driving policy, and customized scenario generation.\nFuture extensions will incorporate foundation models for context-aware decision\nsupport and hardware-in-the-loop (HIL) testing for real-world validation. By\nbridging scenario generation, data collection, algorithm training, and hardware\nintegration, Sky-Drive has the potential to become a foundational platform for\nthe next generation of socially-aware and human-centered autonomous\ntransportation research. The demo video and code are available\nat:https://sky-lab-uw.github.io/Sky-Drive-website/"}
{"id": "2504.18160", "pdf": "https://arxiv.org/pdf/2504.18160", "abs": "https://arxiv.org/abs/2504.18160", "authors": ["Mathieu Petitbois", "R√©my Portelas", "Sylvain Lamprier", "Ludovic Denoyer"], "title": "Offline Learning of Controllable Diverse Behaviors", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "Generative Models for Robot Learning Workshop at ICLR 2025", "summary": "Imitation Learning (IL) techniques aim to replicate human behaviors in\nspecific tasks. While IL has gained prominence due to its effectiveness and\nefficiency, traditional methods often focus on datasets collected from experts\nto produce a single efficient policy. Recently, extensions have been proposed\nto handle datasets of diverse behaviors by mainly focusing on learning\ntransition-level diverse policies or on performing entropy maximization at the\ntrajectory level. While these methods may lead to diverse behaviors, they may\nnot be sufficient to reproduce the actual diversity of demonstrations or to\nallow controlled trajectory generation. To overcome these drawbacks, we propose\na different method based on two key features: a) Temporal Consistency that\nensures consistent behaviors across entire episodes and not just at the\ntransition level as well as b) Controllability obtained by constructing a\nlatent space of behaviors that allows users to selectively activate specific\nbehaviors based on their requirements. We compare our approach to\nstate-of-the-art methods over a diverse set of tasks and environments. Project\npage: https://mathieu-petitbois.github.io/projects/swr/"}
{"id": "2504.18040", "pdf": "https://arxiv.org/pdf/2504.18040", "abs": "https://arxiv.org/abs/2504.18040", "authors": ["Xiaoyi Liu", "Hao Tang"], "title": "Cabbage: A Differential Growth Framework for Open Surfaces", "categories": ["cs.CV"], "comment": null, "summary": "We propose Cabbage, a differential growth framework to model buckling\nbehavior in 3D open surfaces found in nature-like the curling of flower petals.\nCabbage creates high-quality triangular meshes free of self-intersection.\nCabbage-Shell is driven by edge subdivision which differentially increases\ndiscretization resolution. Shell forces expands the surface, generating\nbuckling over time. Feature-aware smoothing and remeshing ensures mesh quality.\nCorrective collision effectively prevents self-collision even in tight spaces.\nWe additionally provide Cabbage-Collision, and approximate alternative,\nfollowed by CAD-ready surface generation. Cabbage is the first open-source\neffort with this calibre and robustness, outperforming SOTA methods in its\nmorphological expressiveness, mesh quality, and stably generates large, complex\npatterns over hundreds of simulation steps. It is a source not only of\ncomputational modeling, digital fabrication, education, but also high-quality,\nannotated data for geometry processing and shape analysis."}
{"id": "2504.18428", "pdf": "https://arxiv.org/pdf/2504.18428", "abs": "https://arxiv.org/abs/2504.18428", "authors": ["Yiming Wang", "Pei Zhang", "Jialong Tang", "Haoran Wei", "Baosong Yang", "Rui Wang", "Chenshu Sun", "Feitong Sun", "Jiran Zhang", "Junxuan Wu", "Qiqian Cang", "Yichang Zhang", "Fei Huang", "Junyang Lin", "Fei Huang", "Jingren Zhou"], "title": "PolyMath: Evaluating Mathematical Reasoning in Multilingual Contexts", "categories": ["cs.CL"], "comment": null, "summary": "In this paper, we introduce PolyMath, a multilingual mathematical reasoning\nbenchmark covering 18 languages and 4 easy-to-hard difficulty levels. Our\nbenchmark ensures difficulty comprehensiveness, language diversity, and\nhigh-quality translation, making it a highly discriminative multilingual\nmathematical benchmark in the era of reasoning LLMs. We conduct a comprehensive\nevaluation for advanced LLMs and find that even Deepseek-R1-671B and\nQwen-QwQ-32B, achieve only 43.4 and 41.8 benchmark scores, with less than 30%\naccuracy under the highest level. From a language perspective, our benchmark\nreveals several key challenges of LLMs in multilingual reasoning: (1) Reasoning\nperformance varies widely across languages for current LLMs; (2) Input-output\nlanguage consistency is low in reasoning LLMs and may be correlated with\nperformance; (3) The thinking length differs significantly by language for\ncurrent LLMs. Additionally, we demonstrate that controlling the output language\nin the instructions has the potential to affect reasoning performance,\nespecially for some low-resource languages, suggesting a promising direction\nfor improving multilingual capabilities in LLMs."}
{"id": "2504.18044", "pdf": "https://arxiv.org/pdf/2504.18044", "abs": "https://arxiv.org/abs/2504.18044", "authors": ["Omid Veisi", "Sasan Bahrami", "Roman Englert", "Claudia M√ºller"], "title": "AI Ethics and Social Norms: Exploring ChatGPT's Capabilities From What to How", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.IT", "math.IT"], "comment": "Accepted for presentation at the ACM Conference on Computer-Supported\n  Cooperative Work and Social Computing (CSCW) 2025. To appear in Proceedings\n  of the ACM on Human-Computer Interaction (PACM HCI)", "summary": "Using LLMs in healthcare, Computer-Supported Cooperative Work, and Social\nComputing requires the examination of ethical and social norms to ensure safe\nincorporation into human life. We conducted a mixed-method study, including an\nonline survey with 111 participants and an interview study with 38 experts, to\ninvestigate the AI ethics and social norms in ChatGPT as everyday life tools.\nThis study aims to evaluate whether ChatGPT in an empirical context operates\nfollowing ethics and social norms, which is critical for understanding actions\nin industrial and academic research and achieving machine ethics. The findings\nof this study provide initial insights into six important aspects of AI ethics,\nincluding bias, trustworthiness, security, toxicology, social norms, and\nethical data. Significant obstacles related to transparency and bias in\nunsupervised data collection methods are identified as ChatGPT's ethical\nconcerns."}
{"id": "2504.18181", "pdf": "https://arxiv.org/pdf/2504.18181", "abs": "https://arxiv.org/abs/2504.18181", "authors": ["Yvonne Jenniges", "Maike Sonnewald", "Sebastian Maneth", "Are Olsen", "Boris P. Koch"], "title": "Unveiling 3D Ocean Biogeochemical Provinces: A Machine Learning Approach for Systematic Clustering and Validation", "categories": ["cs.LG"], "comment": "Submitted to Ecological Informatics. Images in this preprint are of\n  lower resolution than in the journal submission", "summary": "Defining ocean regions and water masses helps to understand marine processes\nand can serve downstream-tasks such as defining marine protected areas.\nHowever, such definitions are often a result of subjective decisions\npotentially producing misleading, unreproducible results. Here, the aim was to\nobjectively define regions of the North Atlantic. For this, a data-driven,\nsystematic machine learning approach was applied to generate and validate ocean\nclusters employing external, internal and relative validation techniques. About\n300 million measured salinity, temperature, and oxygen, nitrate, phosphate and\nsilicate concentration values served as input for various clustering methods\n(KMeans, agglomerative Ward, and Density-Based Spatial Clustering of\nApplications with Noise (DBSCAN)). Uniform Manifold Approximation and\nProjection (UMAP) emphasised (dis-)similarities in the data while reducing\ndimensionality. Based on a systematic validation of the considered clustering\nmethods and their hyperparameters, the results showed that UMAP-DBSCAN best\nrepresented the data. To address stochastic variability, 100 UMAP-DBSCAN\nclustering runs were conducted and aggregated using Native Emergent Manifold\nInterrogation (NEMI), producing a final set of 321 clusters. Reproducibility\nwas evaluated by calculating the ensemble overlap (88.81 +- 1.8%) and the mean\ngrid cell-wise uncertainty estimated by NEMI (15.49 +- 20%). The presented\nclustering results agreed very well with common water mass definitions. This\nstudy revealed a more detailed regionalization compared to previous concepts\nsuch as the Longhurst provinces. The applied method is objective, efficient and\nreproducible and will support future research focusing on biogeochemical\ndifferences and changes in oceanic regions."}
{"id": "2504.18046", "pdf": "https://arxiv.org/pdf/2504.18046", "abs": "https://arxiv.org/abs/2504.18046", "authors": ["Guohao Huo", "Zibo Lin", "Zitong Wang", "Ruiting Dai", "Hao Tang"], "title": "DMS-Net:Dual-Modal Multi-Scale Siamese Network for Binocular Fundus Image Classification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Ophthalmic diseases pose a significant global health challenge, yet\ntraditional diagnosis methods and existing single-eye deep learning approaches\noften fail to account for binocular pathological correlations. To address this,\nwe propose DMS-Net, a dual-modal multi-scale Siamese network for binocular\nfundus image classification. Our framework leverages weight-shared Siamese\nResNet-152 backbones to extract deep semantic features from paired fundus\nimages. To tackle challenges such as lesion boundary ambiguity and scattered\npathological distributions, we introduce a Multi-Scale Context-Aware Module\n(MSCAM) that integrates adaptive pooling and attention mechanisms for\nmulti-resolution feature aggregation. Additionally, a Dual-Modal Feature Fusion\n(DMFF) module enhances cross-modal interaction through spatial-semantic\nrecalibration and bidirectional attention, effectively combining global context\nand local edge features. Evaluated on the ODIR-5K dataset, DMS-Net achieves\nstate-of-the-art performance with 80.5% accuracy, 86.1% recall, and 83.8%\nCohen's kappa, demonstrating superior capability in detecting symmetric\npathologies and advancing clinical decision-making for ocular diseases."}
{"id": "2504.18458", "pdf": "https://arxiv.org/pdf/2504.18458", "abs": "https://arxiv.org/abs/2504.18458", "authors": ["Wenyi Xiao", "Leilei Gan", "Weilong Dai", "Wanggui He", "Ziwei Huang", "Haoyuan Li", "Fangxun Shu", "Zhelun Yu", "Peng Zhang", "Hao Jiang", "Fei Wu"], "title": "Fast-Slow Thinking for Large Vision-Language Model Reasoning", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "16 pages, 5 figures, and 12 tables", "summary": "Recent advances in large vision-language models (LVLMs) have revealed an\n\\textit{overthinking} phenomenon, where models generate verbose reasoning\nacross all tasks regardless of questions. To address this issue, we present\n\\textbf{FAST}, a novel \\textbf{Fa}st-\\textbf{S}low \\textbf{T}hinking framework\nthat dynamically adapts reasoning depth based on question characteristics.\nThrough empirical analysis, we establish the feasibility of fast-slow thinking\nin LVLMs by investigating how response length and data distribution affect\nperformance. We develop FAST-GRPO with three components: model-based metrics\nfor question characterization, an adaptive thinking reward mechanism, and\ndifficulty-aware KL regularization. Experiments across seven reasoning\nbenchmarks demonstrate that FAST achieves state-of-the-art accuracy with over\n10\\% relative improvement compared to the base model, while reducing token\nusage by 32.7-67.3\\% compared to previous slow-thinking approaches, effectively\nbalancing reasoning length and accuracy."}
{"id": "2504.18049", "pdf": "https://arxiv.org/pdf/2504.18049", "abs": "https://arxiv.org/abs/2504.18049", "authors": ["Xin Li", "Wenhui Zhu", "Peijie Qiu", "Oana M. Dumitrascu", "Amal Youssef", "Yalin Wang"], "title": "A BERT-Style Self-Supervised Learning CNN for Disease Identification from Retinal Images", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In the field of medical imaging, the advent of deep learning, especially the\napplication of convolutional neural networks (CNNs) has revolutionized the\nanalysis and interpretation of medical images. Nevertheless, deep learning\nmethods usually rely on large amounts of labeled data. In medical imaging\nresearch, the acquisition of high-quality labels is both expensive and\ndifficult. The introduction of Vision Transformers (ViT) and self-supervised\nlearning provides a pre-training strategy that utilizes abundant unlabeled\ndata, effectively alleviating the label acquisition challenge while broadening\nthe breadth of data utilization. However, ViT's high computational density and\nsubstantial demand for computing power, coupled with the lack of localization\ncharacteristics of its operations on image patches, limit its efficiency and\napplicability in many application scenarios. In this study, we employ\nnn-MobileNet, a lightweight CNN framework, to implement a BERT-style\nself-supervised learning approach. We pre-train the network on the unlabeled\nretinal fundus images from the UK Biobank to improve downstream application\nperformance. We validate the results of the pre-trained model on Alzheimer's\ndisease (AD), Parkinson's disease (PD), and various retinal diseases\nidentification. The results show that our approach can significantly improve\nperformance in the downstream tasks. In summary, this study combines the\nbenefits of CNNs with the capabilities of advanced self-supervised learning in\nhandling large-scale unlabeled data, demonstrating the potential of CNNs in the\npresence of label scarcity."}
{"id": "2504.18185", "pdf": "https://arxiv.org/pdf/2504.18185", "abs": "https://arxiv.org/abs/2504.18185", "authors": ["Gissel Velarde", "Pedro Branez", "Alejandro Bueno", "Rodrigo Heredia", "Mateo Lopez-Ledezma"], "title": "An Open-Source and Reproducible Implementation of LSTM and GRU Networks for Time Series Forecasting", "categories": ["cs.LG"], "comment": "12 pages", "summary": "This paper introduces an open-source and reproducible implementation of Long\nShort-Term Memory (LSTM) and Gated Recurrent Unit (GRU) Networks for time\nseries forecasting. We evaluated LSTM and GRU networks because of their\nperformance reported in related work. We describe our method and its results on\ntwo datasets. The first dataset is the S&P BSE BANKEX, composed of stock time\nseries (closing prices) of ten financial institutions. The second dataset,\ncalled Activities, comprises ten synthetic time series resembling weekly\nactivities with five days of high activity and two days of low activity. We\nreport Root Mean Squared Error (RMSE) between actual and predicted values, as\nwell as Directional Accuracy (DA). We show that a single time series from a\ndataset can be used to adequately train the networks if the sequences in the\ndataset contain patterns that repeat, even with certain variation, and are\nproperly processed. For 1-step ahead and 20-step ahead forecasts, LSTM and GRU\nnetworks significantly outperform a baseline on the Activities dataset. The\nbaseline simply repeats the last available value. On the stock market dataset,\nthe networks perform just like the baseline, possibly due to the nature of\nthese series. We release the datasets used as well as the implementation with\nall experiments performed to enable future comparisons and to make our research\nreproducible."}
{"id": "2504.18059", "pdf": "https://arxiv.org/pdf/2504.18059", "abs": "https://arxiv.org/abs/2504.18059", "authors": ["Prachi Garg", "Joseph K J", "Vineeth N Balasubramanian", "Necati Cihan Camgoz", "Chengde Wan", "Kenrick Kin", "Weiguang Si", "Shugao Ma", "Fernando De La Torre"], "title": "POET: Prompt Offset Tuning for Continual Human Action Adaptation", "categories": ["cs.CV"], "comment": "ECCV 2024 (Oral), webpage\n  https://humansensinglab.github.io/POET-continual-action-recognition/", "summary": "As extended reality (XR) is redefining how users interact with computing\ndevices, research in human action recognition is gaining prominence. Typically,\nmodels deployed on immersive computing devices are static and limited to their\ndefault set of classes. The goal of our research is to provide users and\ndevelopers with the capability to personalize their experience by adding new\naction classes to their device models continually. Importantly, a user should\nbe able to add new classes in a low-shot and efficient manner, while this\nprocess should not require storing or replaying any of user's sensitive\ntraining data. We formalize this problem as privacy-aware few-shot continual\naction recognition. Towards this end, we propose POET: Prompt-Offset Tuning.\nWhile existing prompt tuning approaches have shown great promise for continual\nlearning of image, text, and video modalities; they demand access to\nextensively pretrained transformers. Breaking away from this assumption, POET\ndemonstrates the efficacy of prompt tuning a significantly lightweight\nbackbone, pretrained exclusively on the base class data. We propose a novel\nspatio-temporal learnable prompt offset tuning approach, and are the first to\napply such prompt tuning to Graph Neural Networks. We contribute two new\nbenchmarks for our new problem setting in human action recognition: (i) NTU\nRGB+D dataset for activity recognition, and (ii) SHREC-2017 dataset for hand\ngesture recognition. We find that POET consistently outperforms comprehensive\nbenchmarks. Source code at\nhttps://github.com/humansensinglab/POET-continual-action-recognition."}
{"id": "2504.18474", "pdf": "https://arxiv.org/pdf/2504.18474", "abs": "https://arxiv.org/abs/2504.18474", "authors": ["James D. Finch", "Yasasvi Josyula", "Jinho D. Choi"], "title": "Generative Induction of Dialogue Task Schemas with Streaming Refinement and Simulated Interactions", "categories": ["cs.CL"], "comment": "Accepted (B) to TACL 2025", "summary": "In task-oriented dialogue (TOD) systems, Slot Schema Induction (SSI) is\nessential for automatically identifying key information slots from dialogue\ndata without manual intervention. This paper presents a novel state-of-the-art\n(SoTA) approach that formulates SSI as a text generation task, where a language\nmodel incrementally constructs and refines a slot schema over a stream of\ndialogue data. To develop this approach, we present a fully automatic LLM-based\nTOD simulation method that creates data with high-quality state labels for\nnovel task domains. Furthermore, we identify issues in SSI evaluation due to\ndata leakage and poor metric alignment with human judgment. We resolve these by\ncreating new evaluation data using our simulation method with human guidance\nand correction, as well as designing improved evaluation metrics. These\ncontributions establish a foundation for future SSI research and advance the\nSoTA in dialogue understanding and system development."}
{"id": "2504.18050", "pdf": "https://arxiv.org/pdf/2504.18050", "abs": "https://arxiv.org/abs/2504.18050", "authors": ["Mingwei Zheng", "Danning Xie", "Qingkai Shi", "Chengpeng Wang", "Xiangyu Zhang"], "title": "Validating Network Protocol Parsers with Traceable RFC Document Interpretation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Validating the correctness of network protocol implementations is highly\nchallenging due to the oracle and traceability problems. The former determines\nwhen a protocol implementation can be considered buggy, especially when the\nbugs do not cause any observable symptoms. The latter allows developers to\nunderstand how an implementation violates the protocol specification, thereby\nfacilitating bug fixes. Unlike existing works that rarely take both problems\ninto account, this work considers both and provides an effective solution using\nrecent advances in large language models (LLMs). Our key observation is that\nnetwork protocols are often released with structured specification documents,\na.k.a. RFC documents, which can be systematically translated to formal protocol\nmessage specifications via LLMs. Such specifications, which may contain errors\ndue to the hallucination of LLMs, are used as a quasi-oracle to validate\nprotocol parsers, while the validation results in return gradually refine the\noracle. Since the oracle is derived from the document, any bugs we find in a\nprotocol implementation can be traced back to the document, thus addressing the\ntraceability problem. We have extensively evaluated our approach using nine\nnetwork protocols and their implementations written in C, Python, and Go. The\nresults show that our approach outperforms the state-of-the-art and has\ndetected 69 bugs, with 36 confirmed. The project also demonstrates the\npotential for fully automating software validation based on natural language\nspecifications, a process previously considered predominantly manual due to the\nneed to understand specification documents and derive expected outputs for test\ninputs."}
{"id": "2504.18206", "pdf": "https://arxiv.org/pdf/2504.18206", "abs": "https://arxiv.org/abs/2504.18206", "authors": ["Stefano Sossi-Rojas", "Gissel Velarde", "Damian Zieba"], "title": "A Machine Learning Approach For Bitcoin Forecasting", "categories": ["cs.LG", "cs.CE"], "comment": "15 pages", "summary": "Bitcoin is one of the cryptocurrencies that is gaining more popularity in\nrecent years. Previous studies have shown that closing price alone is not\nenough to forecast stock market series. We introduce a new set of time series\nand demonstrate that a subset is necessary to improve directional accuracy\nbased on a machine learning ensemble. In our experiments, we study which time\nseries and machine learning algorithms deliver the best results. We found that\nthe most relevant time series that contribute to improving directional accuracy\nare Open, High and Low, with the largest contribution of Low in combination\nwith an ensemble of Gated Recurrent Unit network and a baseline forecast. The\nrelevance of other Bitcoin-related features that are not price-related is\nnegligible. The proposed method delivers similar performance to the\nstate-of-the-art when observing directional accuracy."}
{"id": "2504.18068", "pdf": "https://arxiv.org/pdf/2504.18068", "abs": "https://arxiv.org/abs/2504.18068", "authors": ["Zhuohao Yan", "Shaoquan Feng", "Xingxing Li", "Yuxuan Zhou", "Chunxi Xia", "Shengyu Li"], "title": "S3MOT: Monocular 3D Object Tracking with Selective State Space Model", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Accurate and reliable multi-object tracking (MOT) in 3D space is essential\nfor advancing robotics and computer vision applications. However, it remains a\nsignificant challenge in monocular setups due to the difficulty of mining 3D\nspatiotemporal associations from 2D video streams. In this work, we present\nthree innovative techniques to enhance the fusion and exploitation of\nheterogeneous cues for monocular 3D MOT: (1) we introduce the Hungarian State\nSpace Model (HSSM), a novel data association mechanism that compresses\ncontextual tracking cues across multiple paths, enabling efficient and\ncomprehensive assignment decisions with linear complexity. HSSM features a\nglobal receptive field and dynamic weights, in contrast to traditional linear\nassignment algorithms that rely on hand-crafted association costs. (2) We\npropose Fully Convolutional One-stage Embedding (FCOE), which eliminates ROI\npooling by directly using dense feature maps for contrastive learning, thus\nimproving object re-identification accuracy under challenging conditions such\nas varying viewpoints and lighting. (3) We enhance 6-DoF pose estimation\nthrough VeloSSM, an encoder-decoder architecture that models temporal\ndependencies in velocity to capture motion dynamics, overcoming the limitations\nof frame-based 3D inference. Experiments on the KITTI public test benchmark\ndemonstrate the effectiveness of our method, achieving a new state-of-the-art\nperformance of 76.86~HOTA at 31~FPS. Our approach outperforms the previous best\nby significant margins of +2.63~HOTA and +3.62~AssA, showcasing its robustness\nand efficiency for monocular 3D MOT tasks. The code and models are available at\nhttps://github.com/bytepioneerX/s3mot."}
{"id": "2504.18483", "pdf": "https://arxiv.org/pdf/2504.18483", "abs": "https://arxiv.org/abs/2504.18483", "authors": ["Leandra Fichtel", "Maximilian Splieth√∂ver", "Eyke H√ºllermeier", "Patricia Jimenez", "Nils Klowait", "Stefan Kopp", "Axel-Cyrille Ngonga Ngomo", "Amelie Robrecht", "Ingrid Scharlau", "Lutz Terfloth", "Anna-Lisa Vollmer", "Henning Wachsmuth"], "title": "Investigating Co-Constructive Behavior of Large Language Models in Explanation Dialogues", "categories": ["cs.CL"], "comment": "Submitted to the SIGDial Conference 2025", "summary": "The ability to generate explanations that are understood by explainees is the\nquintessence of explainable artificial intelligence. Since understanding\ndepends on the explainee's background and needs, recent research has focused on\nco-constructive explanation dialogues, where the explainer continuously\nmonitors the explainee's understanding and adapts explanations dynamically. We\ninvestigate the ability of large language models (LLMs) to engage as explainers\nin co-constructive explanation dialogues. In particular, we present a user\nstudy in which explainees interact with LLMs, of which some have been\ninstructed to explain a predefined topic co-constructively. We evaluate the\nexplainees' understanding before and after the dialogue, as well as their\nperception of the LLMs' co-constructive behavior. Our results indicate that\ncurrent LLMs show some co-constructive behaviors, such as asking verification\nquestions, that foster the explainees' engagement and can improve understanding\nof a topic. However, their ability to effectively monitor the current\nunderstanding and scaffold the explanations accordingly remains limited."}
{"id": "2504.18057", "pdf": "https://arxiv.org/pdf/2504.18057", "abs": "https://arxiv.org/abs/2504.18057", "authors": ["Jiayi Chen", "Shuai Wang", "Guoliang Li", "Wei Xu", "Guangxu Zhu", "Derrick Wing Kwan Ng", "Chengzhong Xu"], "title": "Opportunistic Collaborative Planning with Large Vision Model Guided Control and Joint Query-Service Optimization", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Navigating autonomous vehicles in open scenarios is a challenge due to the\ndifficulties in handling unseen objects. Existing solutions either rely on\nsmall models that struggle with generalization or large models that are\nresource-intensive. While collaboration between the two offers a promising\nsolution, the key challenge is deciding when and how to engage the large model.\nTo address this issue, this paper proposes opportunistic collaborative planning\n(OCP), which seamlessly integrates efficient local models with powerful cloud\nmodels through two key innovations. First, we propose large vision model guided\nmodel predictive control (LVM-MPC), which leverages the cloud for LVM\nperception and decision making. The cloud output serves as a global guidance\nfor a local MPC, thereby forming a closed-loop perception-to-control system.\nSecond, to determine the best timing for large model query and service, we\npropose collaboration timing optimization (CTO), including object detection\nconfidence thresholding (ODCT) and cloud forward simulation (CFS), to decide\nwhen to seek cloud assistance and when to offer cloud service. Extensive\nexperiments show that the proposed OCP outperforms existing methods in terms of\nboth navigation time and success rate."}
{"id": "2504.18207", "pdf": "https://arxiv.org/pdf/2504.18207", "abs": "https://arxiv.org/abs/2504.18207", "authors": ["Simon Lucey"], "title": "Gradient Descent as a Shrinkage Operator for Spectral Bias", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We generalize the connection between activation function and spline\nregression/smoothing and characterize how this choice may influence spectral\nbias within a 1D shallow network. We then demonstrate how gradient descent (GD)\ncan be reinterpreted as a shrinkage operator that masks the singular values of\na neural network's Jacobian. Viewed this way, GD implicitly selects the number\nof frequency components to retain, thereby controlling the spectral bias. An\nexplicit relationship is proposed between the choice of GD hyperparameters\n(learning rate & number of iterations) and bandwidth (the number of active\ncomponents). GD regularization is shown to be effective only with monotonic\nactivation functions. Finally, we highlight the utility of non-monotonic\nactivation functions (sinc, Gaussian) as iteration-efficient surrogates for\nspectral bias."}
{"id": "2504.18087", "pdf": "https://arxiv.org/pdf/2504.18087", "abs": "https://arxiv.org/abs/2504.18087", "authors": ["Weipeng Tan", "Chuming Lin", "Chengming Xu", "FeiFan Xu", "Xiaobin Hu", "Xiaozhong Ji", "Junwei Zhu", "Chengjie Wang", "Yanwei Fu"], "title": "Disentangle Identity, Cooperate Emotion: Correlation-Aware Emotional Talking Portrait Generation", "categories": ["cs.CV"], "comment": "arXiv admin note: text overlap with arXiv:2409.03270", "summary": "Recent advances in Talking Head Generation (THG) have achieved impressive lip\nsynchronization and visual quality through diffusion models; yet existing\nmethods struggle to generate emotionally expressive portraits while preserving\nspeaker identity. We identify three critical limitations in current emotional\ntalking head generation: insufficient utilization of audio's inherent emotional\ncues, identity leakage in emotion representations, and isolated learning of\nemotion correlations. To address these challenges, we propose a novel framework\ndubbed as DICE-Talk, following the idea of disentangling identity with emotion,\nand then cooperating emotions with similar characteristics. First, we develop a\ndisentangled emotion embedder that jointly models audio-visual emotional cues\nthrough cross-modal attention, representing emotions as identity-agnostic\nGaussian distributions. Second, we introduce a correlation-enhanced emotion\nconditioning module with learnable Emotion Banks that explicitly capture\ninter-emotion relationships through vector quantization and attention-based\nfeature aggregation. Third, we design an emotion discrimination objective that\nenforces affective consistency during the diffusion process through\nlatent-space classification. Extensive experiments on MEAD and HDTF datasets\ndemonstrate our method's superiority, outperforming state-of-the-art approaches\nin emotion accuracy while maintaining competitive lip-sync performance.\nQualitative results and user studies further confirm our method's ability to\ngenerate identity-preserving portraits with rich, correlated emotional\nexpressions that naturally adapt to unseen identities."}
{"id": "2504.18535", "pdf": "https://arxiv.org/pdf/2504.18535", "abs": "https://arxiv.org/abs/2504.18535", "authors": ["Gwen Yidou Weng", "Benjie Wang", "Guy Van den Broeck"], "title": "TRACE Back from the Future: A Probabilistic Reasoning Approach to Controllable Language Generation", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "As large language models (LMs) advance, there is an increasing need to\ncontrol their outputs to align with human values (e.g., detoxification) or\ndesired attributes (e.g., personalization, topic). However, autoregressive\nmodels focus on next-token predictions and struggle with global properties that\nrequire looking ahead. Existing solutions either tune or post-train LMs for\neach new attribute - expensive and inflexible - or approximate the Expected\nAttribute Probability (EAP) of future sequences by sampling or training, which\nis slow and unreliable for rare attributes. We introduce TRACE (Tractable\nProbabilistic Reasoning for Adaptable Controllable gEneration), a novel\nframework that efficiently computes EAP and adapts to new attributes through\ntractable probabilistic reasoning and lightweight control. TRACE distills a\nHidden Markov Model (HMM) from an LM and pairs it with a small classifier to\nestimate attribute probabilities, enabling exact EAP computation over the HMM's\npredicted futures. This EAP is then used to reweigh the LM's next-token\nprobabilities for globally compliant continuations. Empirically, TRACE achieves\nstate-of-the-art results in detoxification with only 10% decoding overhead,\nadapts to 76 low-resource personalized LLMs within seconds, and seamlessly\nextends to composite attributes."}
{"id": "2504.18062", "pdf": "https://arxiv.org/pdf/2504.18062", "abs": "https://arxiv.org/abs/2504.18062", "authors": ["Lingyan Bao", "Sinwoong Yun", "Jemin Lee", "Tony Q. S. Quek"], "title": "LLM-Guided Open RAN: Empowering Hierarchical RAN Intelligent Control", "categories": ["cs.NI", "cs.AI"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have led to a significant\ninterest in deploying LLMempowered algorithms for wireless communication\nnetworks. Meanwhile, open radio access network (O-RAN) techniques offer\nunprecedented flexibility, with the non-real-time (non-RT) radio access network\n(RAN) intelligent controller (RIC) (non-RT RIC) and near-real-time (near-RT)\nRIC (near-RT RIC) components enabling intelligent resource management across\ndifferent time scales. In this paper, we propose the LLM empowered hierarchical\nRIC (LLM-hRIC) framework to improve the collaboration between RICs. This\nframework integrates LLMs with reinforcement learning (RL) for efficient\nnetwork resource management. In this framework, LLMs-empowered non-RT RICs\nprovide strategic guidance and high-level policies based on environmental\ncontext. Concurrently, RL-empowered near-RT RICs perform low-latency tasks\nbased on strategic guidance and local near-RT observation. We evaluate the\nLLM-hRIC framework in an integrated access and backhaul (IAB) network setting.\nSimulation results demonstrate that the proposed framework achieves superior\nperformance. Finally, we discuss the key future challenges in applying LLMs to\nO-RAN."}
{"id": "2504.18208", "pdf": "https://arxiv.org/pdf/2504.18208", "abs": "https://arxiv.org/abs/2504.18208", "authors": ["Rapha√´l Barboni", "Gabriel Peyr√©", "Fran√ßois-Xavier Vialard"], "title": "Ultra-fast feature learning for the training of two-layer neural networks in the two-timescale regime", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "We study the convergence of gradient methods for the training of mean-field\nsingle hidden layer neural networks with square loss. Observing this is a\nseparable non-linear least-square problem which is linear w.r.t. the outer\nlayer's weights, we consider a Variable Projection (VarPro) or two-timescale\nlearning algorithm, thereby eliminating the linear variables and reducing the\nlearning problem to the training of the feature distribution. Whereas most\nconvergence rates or the training of neural networks rely on a neural tangent\nkernel analysis where features are fixed, we show such a strategy enables\nprovable convergence rates for the sampling of a teacher feature distribution.\nPrecisely, in the limit where the regularization strength vanishes, we show\nthat the dynamic of the feature distribution corresponds to a weighted\nultra-fast diffusion equation. Relying on recent results on the asymptotic\nbehavior of such PDEs, we obtain guarantees for the convergence of the trained\nfeature distribution towards the teacher feature distribution in a\nteacher-student setup."}
{"id": "2504.18112", "pdf": "https://arxiv.org/pdf/2504.18112", "abs": "https://arxiv.org/abs/2504.18112", "authors": ["Deepak Ghimire", "Byoungjun Kim", "Donghoon Kim", "SungHwan Jeong"], "title": "Study on Real-Time Road Surface Reconstruction Using Stereo Vision", "categories": ["cs.CV"], "comment": "Stereo Vision, Efficient CNN, Pruning, Optimization. 2025 Intelligent\n  Information and Control Conference (IICC 2025), Jeonju, Korea", "summary": "Road surface reconstruction plays a crucial role in autonomous driving,\nproviding essential information for safe and smooth navigation. This paper\nenhances the RoadBEV [1] framework for real-time inference on edge devices by\noptimizing both efficiency and accuracy. To achieve this, we proposed to apply\nIsomorphic Global Structured Pruning to the stereo feature extraction backbone,\nreducing network complexity while maintaining performance. Additionally, the\nhead network is redesigned with an optimized hourglass structure, dynamic\nattention heads, reduced feature channels, mixed precision inference, and\nefficient probability volume computation. Our approach improves inference speed\nwhile achieving lower reconstruction error, making it well-suited for real-time\nroad surface reconstruction in autonomous driving."}
{"id": "2504.17884", "pdf": "https://arxiv.org/pdf/2504.17884", "abs": "https://arxiv.org/abs/2504.17884", "authors": ["Yongkang Li", "Panagiotis Eustratiadis", "Simon Lupart", "Evangelos Kanoulas"], "title": "Unsupervised Corpus Poisoning Attacks in Continuous Space for Dense Retrieval", "categories": ["cs.IR", "cs.CL"], "comment": "This paper has been accepted as a full paper at SIGIR 2025 and will\n  be presented orally", "summary": "This paper concerns corpus poisoning attacks in dense information retrieval,\nwhere an adversary attempts to compromise the ranking performance of a search\nalgorithm by injecting a small number of maliciously generated documents into\nthe corpus. Our work addresses two limitations in the current literature.\nFirst, attacks that perform adversarial gradient-based word substitution search\ndo so in the discrete lexical space, while retrieval itself happens in the\ncontinuous embedding space. We thus propose an optimization method that\noperates in the embedding space directly. Specifically, we train a perturbation\nmodel with the objective of maintaining the geometric distance between the\noriginal and adversarial document embeddings, while also maximizing the\ntoken-level dissimilarity between the original and adversarial documents.\nSecond, it is common for related work to have a strong assumption that the\nadversary has prior knowledge about the queries. In this paper, we focus on a\nmore challenging variant of the problem where the adversary assumes no prior\nknowledge about the query distribution (hence, unsupervised). Our core\ncontribution is an adversarial corpus attack that is fast and effective. We\npresent comprehensive experimental results on both in- and out-of-domain\ndatasets, focusing on two related tasks: a top-1 attack and a corpus poisoning\nattack. We consider attacks under both a white-box and a black-box setting.\nNotably, our method can generate successful adversarial examples in under two\nminutes per target document; four times faster compared to the fastest\ngradient-based word substitution methods in the literature with the same\nhardware. Furthermore, our adversarial generation method generates text that is\nmore likely to occur under the distribution of natural text (low perplexity),\nand is therefore more difficult to detect."}
{"id": "2504.18230", "pdf": "https://arxiv.org/pdf/2504.18230", "abs": "https://arxiv.org/abs/2504.18230", "authors": ["He Shanxuan", "Lin Zuhong", "Yu Bolun", "Gao Xu", "Long Biao", "Yao Jingjing"], "title": "Learning to fuse: dynamic integration of multi-source data for accurate battery lifespan prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate prediction of lithium-ion battery lifespan is vital for ensuring\noperational reliability and reducing maintenance costs in applications like\nelectric vehicles and smart grids. This study presents a hybrid learning\nframework for precise battery lifespan prediction, integrating dynamic\nmulti-source data fusion with a stacked ensemble (SE) modeling approach. By\nleveraging heterogeneous datasets from the National Aeronautics and Space\nAdministration (NASA), Center for Advanced Life Cycle Engineering (CALCE),\nMIT-Stanford-Toyota Research Institute (TRC), and nickel cobalt aluminum (NCA)\nchemistries, an entropy-based dynamic weighting mechanism mitigates variability\nacross heterogeneous datasets. The SE model combines Ridge regression, long\nshort-term memory (LSTM) networks, and eXtreme Gradient Boosting (XGBoost),\neffectively capturing temporal dependencies and nonlinear degradation patterns.\nIt achieves a mean absolute error (MAE) of 0.0058, root mean square error\n(RMSE) of 0.0092, and coefficient of determination (R2) of 0.9839,\noutperforming established baseline models with a 46.2% improvement in R2 and an\n83.2% reduction in RMSE. Shapley additive explanations (SHAP) analysis\nidentifies differential discharge capacity (Qdlin) and temperature of\nmeasurement (Temp_m) as critical aging indicators. This scalable, interpretable\nframework enhances battery health management, supporting optimized maintenance\nand safety across diverse energy storage systems, thereby contributing to\nimproved battery health management in energy storage systems."}
{"id": "2504.18127", "pdf": "https://arxiv.org/pdf/2504.18127", "abs": "https://arxiv.org/abs/2504.18127", "authors": ["Jingfan Yang", "Hu Gao", "Ying Zhang", "Depeng Dang"], "title": "Salient Region-Guided Spacecraft Image Arbitrary-Scale Super-Resolution Network", "categories": ["cs.CV"], "comment": null, "summary": "Spacecraft image super-resolution seeks to enhance low-resolution spacecraft\nimages into high-resolution ones. Although existing arbitrary-scale\nsuper-resolution methods perform well on general images, they tend to overlook\nthe difference in features between the spacecraft core region and the large\nblack space background, introducing irrelevant noise. In this paper, we propose\na salient region-guided spacecraft image arbitrary-scale super-resolution\nnetwork (SGSASR), which uses features from the spacecraft core salient regions\nto guide latent modulation and achieve arbitrary-scale super-resolution.\nSpecifically, we design a spacecraft core region recognition block (SCRRB) that\nidentifies the core salient regions in spacecraft images using a pre-trained\nsaliency detection model. Furthermore, we present an adaptive-weighted feature\nfusion enhancement mechanism (AFFEM) to selectively aggregate the spacecraft\ncore region features with general image features by dynamic weight parameter to\nenhance the response of the core salient regions. Experimental results\ndemonstrate that the proposed SGSASR outperforms state-of-the-art approaches."}
{"id": "2504.17934", "pdf": "https://arxiv.org/pdf/2504.17934", "abs": "https://arxiv.org/abs/2504.17934", "authors": ["Chaoran Chen", "Zhiping Zhang", "Ibrahim Khalilov", "Bingcan Guo", "Simret A Gebreegziabher", "Yanfang Ye", "Ziang Xiao", "Yaxing Yao", "Tianshi Li", "Toby Jia-Jun Li"], "title": "Toward a Human-Centered Evaluation Framework for Trustworthy LLM-Powered GUI Agents", "categories": ["cs.HC", "cs.CL", "cs.CR"], "comment": null, "summary": "The rise of Large Language Models (LLMs) has revolutionized Graphical User\nInterface (GUI) automation through LLM-powered GUI agents, yet their ability to\nprocess sensitive data with limited human oversight raises significant privacy\nand security risks. This position paper identifies three key risks of GUI\nagents and examines how they differ from traditional GUI automation and general\nautonomous agents. Despite these risks, existing evaluations focus primarily on\nperformance, leaving privacy and security assessments largely unexplored. We\nreview current evaluation metrics for both GUI and general LLM agents and\noutline five key challenges in integrating human evaluators for GUI agent\nassessments. To address these gaps, we advocate for a human-centered evaluation\nframework that incorporates risk assessments, enhances user awareness through\nin-context consent, and embeds privacy and security considerations into GUI\nagent design and evaluation."}
{"id": "2504.18165", "pdf": "https://arxiv.org/pdf/2504.18165", "abs": "https://arxiv.org/abs/2504.18165", "authors": ["Michel Gokan Khan", "Renan Guarese", "Fabian Johnson", "Xi Vincent Wang", "Anders Bergman", "Benjamin Edvinsson", "Mario Romero", "J√©r√©my Vachier", "Jan Kronqvist"], "title": "PerfCam: Digital Twinning for Production Lines Using 3D Gaussian Splatting and Vision Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce PerfCam, an open source Proof-of-Concept (PoC) digital twinning\nframework that combines camera and sensory data with 3D Gaussian Splatting and\ncomputer vision models for digital twinning, object tracking, and Key\nPerformance Indicators (KPIs) extraction in industrial production lines. By\nutilizing 3D reconstruction and Convolutional Neural Networks (CNNs), PerfCam\noffers a semi-automated approach to object tracking and spatial mapping,\nenabling digital twins that capture real-time KPIs such as availability,\nperformance, Overall Equipment Effectiveness (OEE), and rate of conveyor belts\nin the production line. We validate the effectiveness of PerfCam through a\npractical deployment within realistic test production lines in the\npharmaceutical industry and contribute an openly published dataset to support\nfurther research and development in the field. The results demonstrate\nPerfCam's ability to deliver actionable insights through its precise digital\ntwin capabilities, underscoring its value as an effective tool for developing\nusable digital twins in smart manufacturing environments and extracting\noperational analytics."}
{"id": "2504.18243", "pdf": "https://arxiv.org/pdf/2504.18243", "abs": "https://arxiv.org/abs/2504.18243", "authors": ["Rong Cheng", "Jinyi Liu", "YAN ZHENG", "Fei Ni", "Jiazhen Du", "Hangyu Mao", "Fuzheng Zhang", "Bo Wang", "Jianye HAO"], "title": "DualRAG: A Dual-Process Approach to Integrate Reasoning and Retrieval for Multi-Hop Question Answering", "categories": ["cs.LG"], "comment": null, "summary": "Multi-Hop Question Answering (MHQA) tasks permeate real-world applications,\nposing challenges in orchestrating multi-step reasoning across diverse\nknowledge domains. While existing approaches have been improved with iterative\nretrieval, they still struggle to identify and organize dynamic knowledge. To\naddress this, we propose DualRAG, a synergistic dual-process framework that\nseamlessly integrates reasoning and retrieval. DualRAG operates through two\ntightly coupled processes: Reasoning-augmented Querying (RaQ) and progressive\nKnowledge Aggregation (pKA). They work in concert: as RaQ navigates the\nreasoning path and generates targeted queries, pKA ensures that newly acquired\nknowledge is systematically integrated to support coherent reasoning. This\ncreates a virtuous cycle of knowledge enrichment and reasoning refinement.\nThrough targeted fine-tuning, DualRAG preserves its sophisticated reasoning and\nretrieval capabilities even in smaller-scale models, demonstrating its\nversatility and core advantages across different scales. Extensive experiments\ndemonstrate that this dual-process approach substantially improves answer\naccuracy and coherence, approaching, and in some cases surpassing, the\nperformance achieved with oracle knowledge access. These results establish\nDualRAG as a robust and efficient solution for complex multi-hop reasoning\ntasks."}
{"id": "2504.18136", "pdf": "https://arxiv.org/pdf/2504.18136", "abs": "https://arxiv.org/abs/2504.18136", "authors": ["Liugang Lu", "Dabin He", "Congxiang Liu", "Zhixiang Deng"], "title": "MASF-YOLO: An Improved YOLOv11 Network for Small Object Detection on Drone View", "categories": ["cs.CV"], "comment": null, "summary": "With the rapid advancement of Unmanned Aerial Vehicle (UAV) and computer\nvision technologies, object detection from UAV perspectives has emerged as a\nprominent research area. However, challenges for detection brought by the\nextremely small proportion of target pixels, significant scale variations of\nobjects, and complex background information in UAV images have greatly limited\nthe practical applications of UAV. To address these challenges, we propose a\nnovel object detection network Multi-scale Context Aggregation and\nScale-adaptive Fusion YOLO (MASF-YOLO), which is developed based on YOLOv11.\nFirstly, to tackle the difficulty of detecting small objects in UAV images, we\ndesign a Multi-scale Feature Aggregation Module (MFAM), which significantly\nimproves the detection accuracy of small objects through parallel multi-scale\nconvolutions and feature fusion. Secondly, to mitigate the interference of\nbackground noise, we propose an Improved Efficient Multi-scale Attention Module\n(IEMA), which enhances the focus on target regions through feature grouping,\nparallel sub-networks, and cross-spatial learning. Thirdly, we introduce a\nDimension-Aware Selective Integration Module (DASI), which further enhances\nmulti-scale feature fusion capabilities by adaptively weighting and fusing\nlow-dimensional features and high-dimensional features. Finally, we conducted\nextensive performance evaluations of our proposed method on the VisDrone2019\ndataset. Compared to YOLOv11-s, MASFYOLO-s achieves improvements of 4.6% in\nmAP@0.5 and 3.5% in mAP@0.5:0.95 on the VisDrone2019 validation set.\nRemarkably, MASF-YOLO-s outperforms YOLOv11-m while requiring only\napproximately 60% of its parameters and 65% of its computational cost.\nFurthermore, comparative experiments with state-of-the-art detectors confirm\nthat MASF-YOLO-s maintains a clear competitive advantage in both detection\naccuracy and model efficiency."}
{"id": "2504.18024", "pdf": "https://arxiv.org/pdf/2504.18024", "abs": "https://arxiv.org/abs/2504.18024", "authors": ["Yiwei Zha"], "title": "SMARTFinRAG: Interactive Modularized Financial RAG Benchmark", "categories": ["cs.CE", "cs.CL", "cs.IR"], "comment": "For open source github repo, see\n  https://github.com/JonathanZha47/SMARTFinRAG", "summary": "Financial sectors are rapidly adopting language model technologies, yet\nevaluating specialized RAG systems in this domain remains challenging. This\npaper introduces SMARTFinRAG, addressing three critical gaps in financial RAG\nassessment: (1) a fully modular architecture where components can be\ndynamically interchanged during runtime; (2) a document-centric evaluation\nparadigm generating domain-specific QA pairs from newly ingested financial\ndocuments; and (3) an intuitive interface bridging research-implementation\ndivides. Our evaluation quantifies both retrieval efficacy and response\nquality, revealing significant performance variations across configurations.\nThe platform's open-source architecture supports transparent, reproducible\nresearch while addressing practical deployment challenges faced by financial\ninstitutions implementing RAG systems."}
{"id": "2504.18201", "pdf": "https://arxiv.org/pdf/2504.18201", "abs": "https://arxiv.org/abs/2504.18201", "authors": ["Yin Tang", "Jiankai Li", "Hongyu Yang", "Xuan Dong", "Lifeng Fan", "Weixin Li"], "title": "Multi-Grained Compositional Visual Clue Learning for Image Intent Recognition", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In an era where social media platforms abound, individuals frequently share\nimages that offer insights into their intents and interests, impacting\nindividual life quality and societal stability. Traditional computer vision\ntasks, such as object detection and semantic segmentation, focus on concrete\nvisual representations, while intent recognition relies more on implicit visual\nclues. This poses challenges due to the wide variation and subjectivity of such\nclues, compounded by the problem of intra-class variety in conveying abstract\nconcepts, e.g. \"enjoy life\". Existing methods seek to solve the problem by\nmanually designing representative features or building prototypes for each\nclass from global features. However, these methods still struggle to deal with\nthe large visual diversity of each intent category. In this paper, we introduce\na novel approach named Multi-grained Compositional visual Clue Learning (MCCL)\nto address these challenges for image intent recognition. Our method leverages\nthe systematic compositionality of human cognition by breaking down intent\nrecognition into visual clue composition and integrating multi-grained\nfeatures. We adopt class-specific prototypes to alleviate data imbalance. We\ntreat intent recognition as a multi-label classification problem, using a graph\nconvolutional network to infuse prior knowledge through label embedding\ncorrelations. Demonstrated by a state-of-the-art performance on the Intentonomy\nand MDID datasets, our approach advances the accuracy of existing methods while\nalso possessing good interpretability. Our work provides an attempt for future\nexplorations in understanding complex and miscellaneous forms of human\nexpression."}
{"id": "2504.18262", "pdf": "https://arxiv.org/pdf/2504.18262", "abs": "https://arxiv.org/abs/2504.18262", "authors": ["Andrea Quintanilla", "Johan Van Horebeek"], "title": "Local Statistical Parity for the Estimation of Fair Decision Trees", "categories": ["cs.LG"], "comment": null, "summary": "Given the high computational complexity of decision tree estimation,\nclassical methods construct a tree by adding one node at a time in a recursive\nway. To facilitate promoting fairness, we propose a fairness criterion local to\nthe tree nodes. We prove how it is related to the Statistical Parity criterion,\npopular in the Algorithmic Fairness literature, and show how to incorporate it\ninto standard recursive tree estimation algorithms.\n  We present a tree estimation algorithm called Constrained Logistic Regression\nTree (C-LRT), which is a modification of the standard CART algorithm using\nlocally linear classifiers and imposing restrictions as done in Constrained\nLogistic Regression.\n  Finally, we evaluate the performance of trees estimated with C-LRT on\ndatasets commonly used in the Algorithmic Fairness literature, using various\nclassification and fairness metrics. The results confirm that C-LRT\nsuccessfully allows to control and balance accuracy and fairness."}
{"id": "2504.18152", "pdf": "https://arxiv.org/pdf/2504.18152", "abs": "https://arxiv.org/abs/2504.18152", "authors": ["Yi-Xing Peng", "Qize Yang", "Yu-Ming Tang", "Shenghao Fu", "Kun-Yu Lin", "Xihan Wei", "Wei-Shi Zheng"], "title": "ActionArt: Advancing Multimodal Large Models for Fine-Grained Human-Centric Video Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Fine-grained understanding of human actions and poses in videos is essential\nfor human-centric AI applications. In this work, we introduce ActionArt, a\nfine-grained video-caption dataset designed to advance research in\nhuman-centric multimodal understanding. Our dataset comprises thousands of\nvideos capturing a broad spectrum of human actions, human-object interactions,\nand diverse scenarios, each accompanied by detailed annotations that\nmeticulously label every limb movement. We develop eight sub-tasks to evaluate\nthe fine-grained understanding capabilities of existing large multimodal models\nacross different dimensions. Experimental results indicate that, while current\nlarge multimodal models perform commendably on various tasks, they often fall\nshort in achieving fine-grained understanding. We attribute this limitation to\nthe scarcity of meticulously annotated data, which is both costly and difficult\nto scale manually. Since manual annotations are costly and hard to scale, we\npropose proxy tasks to enhance the model perception ability in both spatial and\ntemporal dimensions. These proxy tasks are carefully crafted to be driven by\ndata automatically generated from existing MLLMs, thereby reducing the reliance\non costly manual labels. Experimental results show that the proposed proxy\ntasks significantly narrow the gap toward the performance achieved with\nmanually annotated fine-grained data."}
{"id": "2504.18333", "pdf": "https://arxiv.org/pdf/2504.18333", "abs": "https://arxiv.org/abs/2504.18333", "authors": ["Narek Maloyan", "Dmitry Namiot"], "title": "Adversarial Attacks on LLM-as-a-Judge Systems: Insights from Prompt Injections", "categories": ["cs.CR", "cs.CL"], "comment": null, "summary": "LLM as judge systems used to assess text quality code correctness and\nargument strength are vulnerable to prompt injection attacks. We introduce a\nframework that separates content author attacks from system prompt attacks and\nevaluate five models Gemma 3.27B Gemma 3.4B Llama 3.2 3B GPT 4 and Claude 3\nOpus on four tasks with various defenses using fifty prompts per condition.\nAttacks achieved up to seventy three point eight percent success smaller models\nproved more vulnerable and transferability ranged from fifty point five to\nsixty two point six percent. Our results contrast with Universal Prompt\nInjection and AdvPrompter We recommend multi model committees and comparative\nscoring and release all code and datasets"}
{"id": "2504.18231", "pdf": "https://arxiv.org/pdf/2504.18231", "abs": "https://arxiv.org/abs/2504.18231", "authors": ["Petar Labura", "Tomislav Antic", "Tomislav Capuder"], "title": "Time and Frequency Domain-based Anomaly Detection in Smart Meter Data for Distribution Network Studies", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "comment": null, "summary": "The widespread integration of new technologies in low-voltage distribution\nnetworks on the consumer side creates the need for distribution system\noperators to perform advanced real-time calculations to estimate network\nconditions. In recent years, data-driven models based on machine learning and\nbig data analysis have emerged for calculation purposes, leveraging the\ninformation available in large datasets obtained from smart meters and other\nadvanced measurement infrastructure. However, existing data-driven algorithms\ndo not take into account the quality of data collected from smart meters. They\nlack built-in anomaly detection mechanisms and fail to differentiate anomalies\nbased on whether the value or context of anomalous data instances deviates from\nthe norm. This paper focuses on methods for detecting and mitigating the impact\nof anomalies on the consumption of active and reactive power datasets. It\nproposes an anomaly detection framework based on the Isolation Forest machine\nlearning algorithm and Fast Fourier Transform filtering that works in both the\ntime and frequency domain and is unaffected by point anomalies or contextual\nanomalies of the power consumption data. The importance of integrating anomaly\ndetection methods is demonstrated in the analysis important for distribution\nnetworks with a high share of smart meters."}
{"id": "2504.18267", "pdf": "https://arxiv.org/pdf/2504.18267", "abs": "https://arxiv.org/abs/2504.18267", "authors": ["Prajwal Chauhan", "Salah Eddine Choutri", "Mohamed Ghattassi", "Nader Masmoudi", "Saif Eddin Jabari"], "title": "Neural operators struggle to learn complex PDEs in pedestrian mobility: Hughes model case study", "categories": ["cs.LG", "cs.AI"], "comment": "26 pages, 15 figures, 6 tables, under review at Artificial\n  Intelligence for Transportation | Journal", "summary": "This paper investigates the limitations of neural operators in learning\nsolutions for a Hughes model, a first-order hyperbolic conservation law system\nfor crowd dynamics. The model couples a Fokker-Planck equation representing\npedestrian density with a Hamilton-Jacobi-type (eikonal) equation. This Hughes\nmodel belongs to the class of nonlinear hyperbolic systems that often exhibit\ncomplex solution structures, including shocks and discontinuities. In this\nstudy, we assess the performance of three state-of-the-art neural operators\n(Fourier Neural Operator, Wavelet Neural Operator, and Multiwavelet Neural\nOperator) in various challenging scenarios. Specifically, we consider (1)\ndiscontinuous and Gaussian initial conditions and (2) diverse boundary\nconditions, while also examining the impact of different numerical schemes.\n  Our results show that these neural operators perform well in easy scenarios\nwith fewer discontinuities in the initial condition, yet they struggle in\ncomplex scenarios with multiple initial discontinuities and dynamic boundary\nconditions, even when trained specifically on such complex samples. The\npredicted solutions often appear smoother, resulting in a reduction in total\nvariation and a loss of important physical features. This smoothing behavior is\nsimilar to issues discussed by Daganzo (1995), where models that introduce\nartificial diffusion were shown to miss essential features such as shock waves\nin hyperbolic systems. These results suggest that current neural operator\narchitectures may introduce unintended regularization effects that limit their\nability to capture transport dynamics governed by discontinuities. They also\nraise concerns about generalizing these methods to traffic applications where\nshock preservation is essential."}
{"id": "2504.18158", "pdf": "https://arxiv.org/pdf/2504.18158", "abs": "https://arxiv.org/abs/2504.18158", "authors": ["Jiahao Zhang", "Bowen Wang", "Hong Liu", "Liangzhi Li", "Yuta Nakashima", "Hajime Nagahara"], "title": "E-InMeMo: Enhanced Prompting for Visual In-Context Learning", "categories": ["cs.CV"], "comment": "Preprint", "summary": "Large-scale models trained on extensive datasets have become the standard due\nto their strong generalizability across diverse tasks. In-context learning\n(ICL), widely used in natural language processing, leverages these models by\nproviding task-specific prompts without modifying their parameters. This\nparadigm is increasingly being adapted for computer vision, where models\nreceive an input-output image pair, known as an in-context pair, alongside a\nquery image to illustrate the desired output. However, the success of visual\nICL largely hinges on the quality of these prompts. To address this, we propose\nEnhanced Instruct Me More (E-InMeMo), a novel approach that incorporates\nlearnable perturbations into in-context pairs to optimize prompting. Through\nextensive experiments on standard vision tasks, E-InMeMo demonstrates superior\nperformance over existing state-of-the-art methods. Notably, it improves mIoU\nscores by 7.99 for foreground segmentation and by 17.04 for single object\ndetection when compared to the baseline without learnable prompts. These\nresults highlight E-InMeMo as a lightweight yet effective strategy for\nenhancing visual ICL. Code is publicly available at:\nhttps://github.com/Jackieam/E-InMeMo"}
{"id": "2404.03818", "pdf": "https://arxiv.org/pdf/2404.03818", "abs": "https://arxiv.org/abs/2404.03818", "authors": ["Zhangdie Yuan", "Eric Chamoun", "Rami Aly", "Chenxi Whitehouse", "Andreas Vlachos"], "title": "PRobELM: Plausibility Ranking Evaluation for Language Models", "categories": ["cs.CL"], "comment": null, "summary": "This paper introduces PRobELM (Plausibility Ranking Evaluation for Language\nModels), a benchmark designed to assess language models' ability to discern\nmore plausible from less plausible scenarios through their parametric\nknowledge. While benchmarks such as TruthfulQA emphasise factual accuracy or\ntruthfulness, and others such as COPA explore plausible scenarios without\nexplicitly incorporating world knowledge, PRobELM seeks to bridge this gap by\nevaluating models' capabilities to prioritise plausible scenarios that leverage\nworld knowledge over less plausible alternatives. This design allows us to\nassess the potential of language models for downstream use cases such as\nliterature-based discovery where the focus is on identifying information that\nis likely but not yet known. Our benchmark is constructed from a dataset\ncurated from Wikidata edit histories, tailored to align the temporal bounds of\nthe training data for the evaluated models. PRobELM facilitates the evaluation\nof language models across multiple prompting types, including statement, text\ncompletion, and question-answering. Experiments with 10 models of various sizes\nand architectures on the relationship between model scales, training recency,\nand plausibility performance, reveal that factual accuracy does not directly\ncorrelate with plausibility performance and that up-to-date training data\nenhances plausibility assessment across different model architectures."}
{"id": "2504.18249", "pdf": "https://arxiv.org/pdf/2504.18249", "abs": "https://arxiv.org/abs/2504.18249", "authors": ["Qinyu Chen", "Chang Gao", "Min Liu", "Daniele Perrone", "Yan Ru Pei", "Zuowen Wang", "Zhuo Zou", "Shihang Tan", "Tao Han", "Guorui Lu", "Zhen Xu", "Junyuan Ding", "Ziteng Wang", "Zongwei Wu", "Han Han", "Yuliang Wu", "Jinze Chen", "Wei Zhai", "Yang Cao", "Zheng-jun Zha", "Nuwan Bandara", "Thivya Kandappu", "Archan Misra", "Xiaopeng Lin", "Hongxiang Huang", "Hongwei Ren", "Bojun Cheng", "Hoang M. Truong", "Vinh-Thuan Ly", "Huy G. Tran", "Thuan-Phat Nguyen", "Tram T. Doan"], "title": "Event-Based Eye Tracking. 2025 Event-based Vision Workshop", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "This survey serves as a review for the 2025 Event-Based Eye Tracking\nChallenge organized as part of the 2025 CVPR event-based vision workshop. This\nchallenge focuses on the task of predicting the pupil center by processing\nevent camera recorded eye movement. We review and summarize the innovative\nmethods from teams rank the top in the challenge to advance future event-based\neye tracking research. In each method, accuracy, model size, and number of\noperations are reported. In this survey, we also discuss event-based eye\ntracking from the perspective of hardware design."}
{"id": "2504.18274", "pdf": "https://arxiv.org/pdf/2504.18274", "abs": "https://arxiv.org/abs/2504.18274", "authors": ["Garrett Baker", "George Wang", "Jesse Hoogland", "Daniel Murfet"], "title": "Studying Small Language Models with Susceptibilities", "categories": ["cs.LG"], "comment": null, "summary": "We develop a linear response framework for interpretability that treats a\nneural network as a Bayesian statistical mechanical system. A small, controlled\nperturbation of the data distribution, for example shifting the Pile toward\nGitHub or legal text, induces a first-order change in the posterior expectation\nof an observable localized on a chosen component of the network. The resulting\nsusceptibility can be estimated efficiently with local SGLD samples and\nfactorizes into signed, per-token contributions that serve as attribution\nscores. Building a set of perturbations (probes) yields a response matrix whose\nlow-rank structure separates functional modules such as multigram and induction\nheads in a 3M-parameter transformer. Susceptibilities link local learning\ncoefficients from singular learning theory with linear-response theory, and\nquantify how local loss landscape geometry deforms under shifts in the data\ndistribution."}
{"id": "2504.18179", "pdf": "https://arxiv.org/pdf/2504.18179", "abs": "https://arxiv.org/abs/2504.18179", "authors": ["Lovro Sindicic", "Ivica Kopriva"], "title": "Label-independent hyperparameter-free self-supervised single-view deep subspace clustering", "categories": ["cs.CV", "cs.LG", "68", "I.5.3; I.4.6; I.4.10"], "comment": "35 pages; 1 figure; 10 Tables", "summary": "Deep subspace clustering (DSC) algorithms face several challenges that hinder\ntheir widespread adoption across variois application domains. First, clustering\nquality is typically assessed using only the encoder's output layer,\ndisregarding valuable information present in the intermediate layers. Second,\nmost DSC approaches treat representation learning and subspace clustering as\nindependent tasks, limiting their effectiveness. Third, they assume the\navailability of a held-out dataset for hyperparameter tuning, which is often\nimpractical in real-world scenarios. Fourth, learning termination is commonly\nbased on clustering error monitoring, requiring external labels. Finally, their\nperformance often depends on post-processing techniques that rely on labeled\ndata. To address this limitations, we introduce a novel single-view DSC\napproach that: (i) minimizes a layer-wise self expression loss using a joint\nrepresentation matrix; (ii) optimizes a subspace-structured norm to enhance\nclustering quality; (iii) employs a multi-stage sequential learning framework,\nconsisting of pre-training and fine-tuning, enabling the use of multiple\nregularization terms without hyperparameter tuning; (iv) incorporates a\nrelative error-based self-stopping mechanism to terminate training without\nlabels; and (v) retains a fixed number of leading coefficients in the learned\nrepresentation matrix based on prior knowledge. We evaluate the proposed method\non six datasets representing faces, digits, and objects. The results show that\nour method outperforms most linear SC algorithms with careffulyl tuned\nhyperparameters while maintaining competitive performance with the best\nperforming linear appoaches."}
{"id": "2405.19325", "pdf": "https://arxiv.org/pdf/2405.19325", "abs": "https://arxiv.org/abs/2405.19325", "authors": ["Minghan Li", "Xilun Chen", "Ari Holtzman", "Beidi Chen", "Jimmy Lin", "Wen-tau Yih", "Xi Victoria Lin"], "title": "Nearest Neighbor Speculative Decoding for LLM Generation and Attribution", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) often hallucinate and lack the ability to\nprovide attribution for their generations. Semi-parametric LMs, such as kNN-LM,\napproach these limitations by refining the output of an LM for a given prompt\nusing its nearest neighbor matches in a non-parametric data store. However,\nthese models often exhibit slow inference speeds and produce non-fluent texts.\nIn this paper, we introduce Nearest Neighbor Speculative Decoding (NEST), a\nnovel semi-parametric language modeling approach that is capable of\nincorporating real-world text spans of arbitrary length into the LM generations\nand providing attribution to their sources. NEST performs token-level retrieval\nat each inference step to compute a semi-parametric mixture distribution and\nidentify promising span continuations in a corpus. It then uses an approximate\nspeculative decoding procedure that accepts a prefix of the retrieved span or\ngenerates a new token. NEST significantly enhances the generation quality and\nattribution rate of the base LM across a variety of knowledge-intensive tasks,\nsurpassing the conventional kNN-LM method and performing competitively with\nin-context retrieval augmentation. In addition, NEST substantially improves the\ngeneration speed, achieving a 1.8x speedup in inference time when applied to\nLlama-2-Chat 70B. Code will be released at\nhttps://github.com/facebookresearch/NEST/tree/main."}
{"id": "2504.18253", "pdf": "https://arxiv.org/pdf/2504.18253", "abs": "https://arxiv.org/abs/2504.18253", "authors": ["Amirhossein Zhalehmehrabi", "Daniele Meli", "Francesco Dal Santo", "Francesco Trotti", "Alessandro Farinelli"], "title": "Depth-Constrained ASV Navigation with Deep RL and Limited Sensing", "categories": ["cs.RO", "cs.AI"], "comment": "9 pages, 8 figures", "summary": "Autonomous Surface Vehicles (ASVs) play a crucial role in maritime\noperations, yet their navigation in shallow-water environments remains\nchallenging due to dynamic disturbances and depth constraints. Traditional\nnavigation strategies struggle with limited sensor information, making safe and\nefficient operation difficult. In this paper, we propose a reinforcement\nlearning (RL) framework for ASV navigation under depth constraints, where the\nvehicle must reach a target while avoiding unsafe areas with only a single\ndepth measurement per timestep from a downward-facing Single Beam Echosounder\n(SBES). To enhance environmental awareness, we integrate Gaussian Process (GP)\nregression into the RL framework, enabling the agent to progressively estimate\na bathymetric depth map from sparse sonar readings. This approach improves\ndecision-making by providing a richer representation of the environment.\nFurthermore, we demonstrate effective sim-to-real transfer, ensuring that\ntrained policies generalize well to real-world aquatic conditions. Experimental\nresults validate our method's capability to improve ASV navigation performance\nwhile maintaining safety in challenging shallow-water environments."}
{"id": "2504.18278", "pdf": "https://arxiv.org/pdf/2504.18278", "abs": "https://arxiv.org/abs/2504.18278", "authors": ["Richard Oliver Lane"], "title": "A comprehensive review of classifier probability calibration metrics", "categories": ["cs.LG", "stat.ML"], "comment": "60 pages, 7 figures", "summary": "Probabilities or confidence values produced by artificial intelligence (AI)\nand machine learning (ML) models often do not reflect their true accuracy, with\nsome models being under or over confident in their predictions. For example, if\na model is 80% sure of an outcome, is it correct 80% of the time? Probability\ncalibration metrics measure the discrepancy between confidence and accuracy,\nproviding an independent assessment of model calibration performance that\ncomplements traditional accuracy metrics. Understanding calibration is\nimportant when the outputs of multiple systems are combined, for assurance in\nsafety or business-critical contexts, and for building user trust in models.\nThis paper provides a comprehensive review of probability calibration metrics\nfor classifier and object detection models, organising them according to a\nnumber of different categorisations to highlight their relationships. We\nidentify 82 major metrics, which can be grouped into four classifier families\n(point-based, bin-based, kernel or curve-based, and cumulative) and an object\ndetection family. For each metric, we provide equations where available,\nfacilitating implementation and comparison by future researchers."}
{"id": "2504.18190", "pdf": "https://arxiv.org/pdf/2504.18190", "abs": "https://arxiv.org/abs/2504.18190", "authors": ["Brun√≥ B. Englert", "Tommie Kerssies", "Gijs Dubbelman"], "title": "What is the Added Value of UDA in the VFM Era?", "categories": ["cs.CV"], "comment": null, "summary": "Unsupervised Domain Adaptation (UDA) can improve a perception model's\ngeneralization to an unlabeled target domain starting from a labeled source\ndomain. UDA using Vision Foundation Models (VFMs) with synthetic source data\ncan achieve generalization performance comparable to fully-supervised learning\nwith real target data. However, because VFMs have strong generalization from\ntheir pre-training, more straightforward, source-only fine-tuning can also\nperform well on the target. As data scenarios used in academic research are not\nnecessarily representative for real-world applications, it is currently unclear\n(a) how UDA behaves with more representative and diverse data and (b) if\nsource-only fine-tuning of VFMs can perform equally well in these scenarios.\nOur research aims to close these gaps and, similar to previous studies, we\nfocus on semantic segmentation as a representative perception task. We assess\nUDA for synth-to-real and real-to-real use cases with different source and\ntarget data combinations. We also investigate the effect of using a small\namount of labeled target data in UDA. We clarify that while these scenarios are\nmore realistic, they are not necessarily more challenging. Our results show\nthat, when using stronger synthetic source data, UDA's improvement over\nsource-only fine-tuning of VFMs reduces from +8 mIoU to +2 mIoU, and when using\nmore diverse real source data, UDA has no added value. However, UDA\ngeneralization is always higher in all synthetic data scenarios than\nsource-only fine-tuning and, when including only 1/16 of Cityscapes labels,\nsynthetic UDA obtains the same state-of-the-art segmentation quality of 85 mIoU\nas a fully-supervised model using all labels. Considering the mixed results, we\ndiscuss how UDA can best support robust autonomous driving at scale."}
{"id": "2406.10432", "pdf": "https://arxiv.org/pdf/2406.10432", "abs": "https://arxiv.org/abs/2406.10432", "authors": ["Peitao Han", "Lis Kanashiro Pereira", "Fei Cheng", "Wan Jou She", "Eiji Aramaki"], "title": "AMR-RE: Abstract Meaning Representations for Retrieval-Based In-Context Learning in Relation Extraction", "categories": ["cs.CL"], "comment": "Accepted to NAACL 2025 SRW", "summary": "Existing in-context learning (ICL) methods for relation extraction (RE) often\nprioritize language similarity over structural similarity, which can lead to\noverlooking entity relationships. To address this, we propose an AMR-enhanced\nretrieval-based ICL method for RE. Our model retrieves in-context examples\nbased on semantic structure similarity between task inputs and training\nsamples. Evaluations on four standard English RE datasets show that our model\noutperforms baselines in the unsupervised setting across all datasets. In the\nsupervised setting, it achieves state-of-the-art results on three datasets and\ncompetitive results on the fourth."}
{"id": "2504.18286", "pdf": "https://arxiv.org/pdf/2504.18286", "abs": "https://arxiv.org/abs/2504.18286", "authors": ["Christian Pionzewski", "Rebecca Rademacher", "J√©r√¥me Rutinowski", "Antonia Ponikarov", "Stephan Matzke", "Tim Chilla", "Pia Schreynemackers", "Alice Kirchheim"], "title": "Enhancing Long-Term Re-Identification Robustness Using Synthetic Data: A Comparative Analysis", "categories": ["cs.CV", "cs.AI", "cs.LG", "I.2.10; I.4.9"], "comment": "Published in: 2024 International Conference on Machine Learning and\n  Applications (ICMLA), IEEE. 6 pages, 3 figures", "summary": "This contribution explores the impact of synthetic training data usage and\nthe prediction of material wear and aging in the context of re-identification.\nDifferent experimental setups and gallery set expanding strategies are tested,\nanalyzing their impact on performance over time for aging re-identification\nsubjects. Using a continuously updating gallery, we were able to increase our\nmean Rank-1 accuracy by 24%, as material aging was taken into account step by\nstep. In addition, using models trained with 10% artificial training data,\nRank-1 accuracy could be increased by up to 13%, in comparison to a model\ntrained on only real-world data, significantly boosting generalized performance\non hold-out data. Finally, this work introduces a novel, open-source\nre-identification dataset, pallet-block-2696. This dataset contains 2,696\nimages of Euro pallets, taken over a period of 4 months. During this time,\nnatural aging processes occurred and some of the pallets were damaged during\ntheir usage. These wear and tear processes significantly changed the appearance\nof the pallets, providing a dataset that can be used to generate synthetically\naged pallets or other wooden materials."}
{"id": "2504.18300", "pdf": "https://arxiv.org/pdf/2504.18300", "abs": "https://arxiv.org/abs/2504.18300", "authors": ["Simon Hakenes", "Tobias Glasmachers"], "title": "Deep Reinforcement Learning Based Navigation with Macro Actions and Topological Maps", "categories": ["cs.LG"], "comment": "14 pages, 6 figures", "summary": "This paper addresses the challenge of navigation in large, visually complex\nenvironments with sparse rewards. We propose a method that uses object-oriented\nmacro actions grounded in a topological map, allowing a simple Deep Q-Network\n(DQN) to learn effective navigation policies. The agent builds a map by\ndetecting objects from RGBD input and selecting discrete macro actions that\ncorrespond to navigating to these objects. This abstraction drastically reduces\nthe complexity of the underlying reinforcement learning problem and enables\ngeneralization to unseen environments. We evaluate our approach in a\nphotorealistic 3D simulation and show that it significantly outperforms a\nrandom baseline under both immediate and terminal reward conditions. Our\nresults demonstrate that topological structure and macro-level abstraction can\nenable sample-efficient learning even from pixel data."}
{"id": "2504.18203", "pdf": "https://arxiv.org/pdf/2504.18203", "abs": "https://arxiv.org/abs/2504.18203", "authors": ["Raul David Dominguez Sanchez", "Xavier Diaz Ortiz", "Xingcheng Zhou", "Max Peter Ronecker", "Michael Karner", "Daniel Watzenig", "Alois Knoll"], "title": "LiDAR-Guided Monocular 3D Object Detection for Long-Range Railway Monitoring", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted for the Data-Driven Learning for Intelligent Vehicle\n  Applications Workshop at the 36th IEEE Intelligent Vehicles Symposium (IV)\n  2025", "summary": "Railway systems, particularly in Germany, require high levels of automation\nto address legacy infrastructure challenges and increase train traffic safely.\nA key component of automation is robust long-range perception, essential for\nearly hazard detection, such as obstacles at level crossings or pedestrians on\ntracks. Unlike automotive systems with braking distances of ~70 meters, trains\nrequire perception ranges exceeding 1 km. This paper presents an\ndeep-learning-based approach for long-range 3D object detection tailored for\nautonomous trains. The method relies solely on monocular images, inspired by\nthe Faraway-Frustum approach, and incorporates LiDAR data during training to\nimprove depth estimation. The proposed pipeline consists of four key modules:\n(1) a modified YOLOv9 for 2.5D object detection, (2) a depth estimation\nnetwork, and (3-4) dedicated short- and long-range 3D detection heads.\nEvaluations on the OSDaR23 dataset demonstrate the effectiveness of the\napproach in detecting objects up to 250 meters. Results highlight its potential\nfor railway automation and outline areas for future improvement."}
{"id": "2406.10602", "pdf": "https://arxiv.org/pdf/2406.10602", "abs": "https://arxiv.org/abs/2406.10602", "authors": ["Daniil Gurgurov", "Tanja B√§umel", "Tatiana Anikina"], "title": "Multilingual Large Language Models and Curse of Multilinguality", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "Multilingual Large Language Models (LLMs) have gained large popularity among\nNatural Language Processing (NLP) researchers and practitioners. These models,\ntrained on huge datasets, show proficiency across various languages and\ndemonstrate effectiveness in numerous downstream tasks. This paper navigates\nthe landscape of multilingual LLMs, providing an introductory overview of their\ntechnical aspects. It explains underlying architectures, objective functions,\npre-training data sources, and tokenization methods. This work explores the\nunique features of different model types: encoder-only (mBERT, XLM-R),\ndecoder-only (XGLM, PALM, BLOOM, GPT-3), and encoder-decoder models (mT5,\nmBART). Additionally, it addresses one of the significant limitations of\nmultilingual LLMs - the curse of multilinguality - and discusses current\nattempts to overcome it."}
{"id": "2504.18310", "pdf": "https://arxiv.org/pdf/2504.18310", "abs": "https://arxiv.org/abs/2504.18310", "authors": ["Prashant Garg", "Thiemo Fetzer"], "title": "Artificial Intelligence health advice accuracy varies across languages and contexts", "categories": ["econ.GN", "cs.AI", "cs.CY", "cs.HC", "cs.LG", "q-fin.EC"], "comment": "10 pages, 2 figures. All data, code and materials used is freely\n  available in the Zenodo (DOI: 10.5281/zenodo.15281282)", "summary": "Using basic health statements authorized by UK and EU registers and 9,100\njournalist-vetted public-health assertions on topics such as abortion, COVID-19\nand politics from sources ranging from peer-reviewed journals and government\nadvisories to social media and news across the political spectrum, we benchmark\nsix leading large language models from in 21 languages, finding that, despite\nhigh accuracy on English-centric textbook claims, performance falls in multiple\nnon-European languages and fluctuates by topic and source, highlighting the\nurgency of comprehensive multilingual, domain-aware validation before deploying\nAI in global health communication."}
{"id": "2504.18309", "pdf": "https://arxiv.org/pdf/2504.18309", "abs": "https://arxiv.org/abs/2504.18309", "authors": ["Marco Turzi", "Siamak Mehrkanoon"], "title": "SSA-UNet: Advanced Precipitation Nowcasting via Channel Shuffling", "categories": ["cs.LG", "I.2; I.5"], "comment": "8 pages. 8 figs", "summary": "Weather forecasting is essential for facilitating diverse socio-economic\nactivity and environmental conservation initiatives. Deep learning techniques\nare increasingly being explored as complementary approaches to Numerical\nWeather Prediction (NWP) models, offering potential benefits such as reduced\ncomplexity and enhanced adaptability in specific applications. This work\npresents a novel design, Small Shuffled Attention UNet (SSA-UNet), which\nenhances SmaAt-UNet's architecture by including a shuffle channeling mechanism\nto optimize performance and diminish complexity. To assess its efficacy, this\narchitecture and its reduced variant are examined and trained on two datasets:\na Dutch precipitation dataset from 2016 to 2019, and a French cloud cover\ndataset containing radar images from 2017 to 2018. Three output configurations\nof the proposed architecture are evaluated, yielding outputs of 1, 6, and 12\nprecipitation maps, respectively. To better understand how this model operates\nand produces its predictions, a gradient-based approach called Grad-CAM is used\nto analyze the outputs generated. The analysis of heatmaps generated by\nGrad-CAM facilitated the identification of regions within the input maps that\nthe model considers most informative for generating its predictions. The\nimplementation of SSA-UNet can be found on our\nGithub\\footnote{\\href{https://github.com/MarcoTurzi/SSA-UNet}{https://github.com/MarcoTurzi/SSA-UNet}}"}
{"id": "2504.18204", "pdf": "https://arxiv.org/pdf/2504.18204", "abs": "https://arxiv.org/abs/2504.18204", "authors": ["Kun Li", "Jianhui Wang", "Yangfan He", "Xinyuan Song", "Ruoyu Wang", "Hongyang He", "Wenxin Zhang", "Jiaqi Chen", "Keqin Li", "Sida Li", "Miao Zhang", "Tianyu Shi", "Xueqian Wang"], "title": "Optimizing Multi-Round Enhanced Training in Diffusion Models for Improved Preference Understanding", "categories": ["cs.CV"], "comment": "arXiv admin note: substantial text overlap with arXiv:2503.17660", "summary": "Generative AI has significantly changed industries by enabling text-driven\nimage generation, yet challenges remain in achieving high-resolution outputs\nthat align with fine-grained user preferences. Consequently, multi-round\ninteractions are necessary to ensure the generated images meet expectations.\nPrevious methods enhanced prompts via reward feedback but did not optimize over\na multi-round dialogue dataset. In this work, we present a Visual Co-Adaptation\n(VCA) framework incorporating human-in-the-loop feedback, leveraging a\nwell-trained reward model aligned with human preferences. Using a diverse\nmulti-turn dialogue dataset, our framework applies multiple reward functions,\nsuch as diversity, consistency, and preference feedback, while fine-tuning the\ndiffusion model through LoRA, thus optimizing image generation based on user\ninput. We also construct multi-round dialogue datasets of prompts and image\npairs aligned with user intent. Experiments demonstrate that our method\noutperforms state-of-the-art baselines, significantly improving image\nconsistency and alignment with user intent. Our approach consistently surpasses\ncompeting models in user satisfaction, especially in multi-turn dialogue\nscenarios."}
{"id": "2408.06276", "pdf": "https://arxiv.org/pdf/2408.06276", "abs": "https://arxiv.org/abs/2408.06276", "authors": ["Jieyong Kim", "Hyunseo Kim", "Hyunjin Cho", "SeongKu Kang", "Buru Chang", "Jinyoung Yeo", "Dongha Lee"], "title": "Review-driven Personalized Preference Reasoning with Large Language Models for Recommendation", "categories": ["cs.CL"], "comment": "Accepted to SIGIR 2025", "summary": "Recent advancements in Large Language Models (LLMs) have demonstrated\nexceptional performance across a wide range of tasks, generating significant\ninterest in their application to recommendation systems. However, existing\nmethods have not fully capitalized on the potential of LLMs, often constrained\nby limited input information or failing to fully utilize their advanced\nreasoning capabilities. To address these limitations, we introduce EXP3RT, a\nnovel LLM-based recommender designed to leverage rich preference information\ncontained in user and item reviews. EXP3RT is basically fine-tuned through\ndistillation from a teacher LLM to perform three key tasks in order: EXP3RT\nfirst extracts and encapsulates essential subjective preferences from raw\nreviews, aggregates and summarizes them according to specific criteria to\ncreate user and item profiles. It then generates detailed step-by-step\nreasoning followed by predicted rating, i.e., reasoning-enhanced rating\nprediction, by considering both subjective and objective information from\nuser/item profiles and item descriptions. This personalized preference\nreasoning from EXP3RT enhances rating prediction accuracy and also provides\nfaithful and reasonable explanations for recommendation. Extensive experiments\nshow that EXP3RT outperforms existing methods on both rating prediction and\ncandidate item reranking for top-k recommendation, while significantly\nenhancing the explainability of recommendation systems."}
{"id": "2504.18316", "pdf": "https://arxiv.org/pdf/2504.18316", "abs": "https://arxiv.org/abs/2504.18316", "authors": ["Yacine Majdoub", "Eya Ben Charrada", "Haifa Touati"], "title": "Towards Adaptive Software Agents for Debugging", "categories": ["cs.SE", "cs.AI"], "comment": "5 pages, 3 figures, FSE2025", "summary": "Using multiple agents was found to improve the debugging capabilities of\nLarge Language Models. However, increasing the number of LLM-agents has several\ndrawbacks such as increasing the running costs and rising the risk for the\nagents to lose focus. In this work, we propose an adaptive agentic design,\nwhere the number of agents and their roles are determined dynamically based on\nthe characteristics of the task to be achieved. In this design, the agents\nroles are not predefined, but are generated after analyzing the problem to be\nsolved. Our initial evaluation shows that, with the adaptive design, the number\nof agents that are generated depends on the complexity of the buggy code. In\nfact, for simple code with mere syntax issues, the problem was usually fixed\nusing one agent only. However, for more complex problems, we noticed the\ncreation of a higher number of agents. Regarding the effectiveness of the fix,\nwe noticed an average improvement of 11% compared to the one-shot prompting.\nGiven these promising results, we outline future research directions to improve\nour design for adaptive software agents that can autonomously plan and conduct\ntheir software goals."}
{"id": "2504.18329", "pdf": "https://arxiv.org/pdf/2504.18329", "abs": "https://arxiv.org/abs/2504.18329", "authors": ["Anh-Duy Pham", "Olivier Basole Kashongwe", "Martin Atzmueller", "Tim R√∂mer"], "title": "PHEATPRUNER: Interpretable Data-centric Feature Selection for Multivariate Time Series Classification through Persistent Homology", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "Balancing performance and interpretability in multivariate time series\nclassification is a significant challenge due to data complexity and high\ndimensionality. This paper introduces PHeatPruner, a method integrating\npersistent homology and sheaf theory to address these challenges. Persistent\nhomology facilitates the pruning of up to 45% of the applied variables while\nmaintaining or enhancing the accuracy of models such as Random Forest,\nCatBoost, XGBoost, and LightGBM, all without depending on posterior\nprobabilities or supervised optimization algorithms. Concurrently, sheaf theory\ncontributes explanatory vectors that provide deeper insights into the data's\nstructural nuances. The approach was validated using the UEA Archive and a\nmastitis detection dataset for dairy cows. The results demonstrate that\nPHeatPruner effectively preserves model accuracy. Furthermore, our results\nhighlight PHeatPruner's key features, i.e. simplifying complex data and\noffering actionable insights without increasing processing time or complexity.\nThis method bridges the gap between complexity reduction and interpretability,\nsuggesting promising applications in various fields."}
{"id": "2504.18213", "pdf": "https://arxiv.org/pdf/2504.18213", "abs": "https://arxiv.org/abs/2504.18213", "authors": ["Nicolas M√ºnger", "Max Peter Ronecker", "Xavier Diaz", "Michael Karner", "Daniel Watzenig", "Jan Skaloud"], "title": "A Data-Centric Approach to 3D Semantic Segmentation of Railway Scenes", "categories": ["cs.CV"], "comment": "Accepted at the 28th Computer Vision Winter Workshop 2025", "summary": "LiDAR-based semantic segmentation is critical for autonomous trains,\nrequiring accurate predictions across varying distances. This paper introduces\ntwo targeted data augmentation methods designed to improve segmentation\nperformance on the railway-specific OSDaR23 dataset. The person instance\npasting method enhances segmentation of pedestrians at distant ranges by\ninjecting realistic variations into the dataset. The track sparsification\nmethod redistributes point density in LiDAR scans, improving track segmentation\nat far distances with minimal impact on close-range accuracy. Both methods are\nevaluated using a state-of-the-art 3D semantic segmentation network,\ndemonstrating significant improvements in distant-range performance while\nmaintaining robustness in close-range predictions. We establish the first 3D\nsemantic segmentation benchmark for OSDaR23, demonstrating the potential of\ndata-centric approaches to address railway-specific challenges in autonomous\ntrain perception."}
{"id": "2408.16073", "pdf": "https://arxiv.org/pdf/2408.16073", "abs": "https://arxiv.org/abs/2408.16073", "authors": ["Leo Yeykelis", "Kaavya Pichai", "James J. Cummings", "Byron Reeves"], "title": "Using Large Language Models to Create AI Personas for Replication, Generalization and Prediction of Media Effects: An Empirical Test of 133 Published Experimental Research Findings", "categories": ["cs.CL", "cs.AI"], "comment": "40 pages, 13 figures, 3 tables", "summary": "This report analyzes the potential for large language models (LLMs) to\nexpedite accurate replication and generalization of published research about\nmessage effects in marketing. LLM-powered participants (personas) were tested\nby replicating 133 experimental findings from 14 papers containing 45 recent\nstudies published in the Journal of Marketing. For each study, the measures,\nstimuli, and sampling specifications were used to generate prompts for LLMs to\nact as unique personas. The AI personas, 19,447 in total across all of the\nstudies, generated complete datasets and statistical analyses were then\ncompared with the original human study results. The LLM replications\nsuccessfully reproduced 76% of the original main effects (84 out of 111),\ndemonstrating strong potential for AI-assisted replication. The overall\nreplication rate including interaction effects was 68% (90 out of 133).\nFurthermore, a test of how human results generalized to different participant\nsamples, media stimuli, and measures showed that replication results can change\nwhen tests go beyond the parameters of the original human studies. Implications\nare discussed for the replication and generalizability crises in social\nscience, the acceleration of theory building in media and marketing psychology,\nand the practical advantages of rapid message testing for consumer products.\nLimitations of AI replications are addressed with respect to complex\ninteraction effects, biases in AI models, and establishing benchmarks for AI\nmetrics in marketing research."}
{"id": "2504.18348", "pdf": "https://arxiv.org/pdf/2504.18348", "abs": "https://arxiv.org/abs/2504.18348", "authors": ["Fengchun Liu. Tong Zhang", "Chunying Zhang"], "title": "TSCL:Multi-party loss Balancing scheme for deep learning Image steganography based on Curriculum learning", "categories": ["cs.CV", "cs.AI", "cs.CR"], "comment": null, "summary": "For deep learning-based image steganography frameworks, in order to ensure\nthe invisibility and recoverability of the information embedding, the loss\nfunction usually contains several losses such as embedding loss, recovery loss\nand steganalysis loss. In previous research works, fixed loss weights are\nusually chosen for training optimization, and this setting is not linked to the\nimportance of the steganography task itself and the training process. In this\npaper, we propose a Two-stage Curriculum Learning loss scheduler (TSCL) for\nbalancing multinomial losses in deep learning image steganography algorithms.\nTSCL consists of two phases: a priori curriculum control and loss dynamics\ncontrol. The first phase firstly focuses the model on learning the information\nembedding of the original image by controlling the loss weights in the\nmulti-party adversarial training; secondly, it makes the model shift its\nlearning focus to improving the decoding accuracy; and finally, it makes the\nmodel learn to generate a steganographic image that is resistant to\nsteganalysis. In the second stage, the learning speed of each training task is\nevaluated by calculating the loss drop of the before and after iteration rounds\nto balance the learning of each task. Experimental results on three large\npublic datasets, ALASKA2, VOC2012 and ImageNet, show that the proposed TSCL\nstrategy improves the quality of steganography, decoding accuracy and security."}
{"id": "2504.18353", "pdf": "https://arxiv.org/pdf/2504.18353", "abs": "https://arxiv.org/abs/2504.18353", "authors": ["Roya Nasiri"], "title": "Testing Individual Fairness in Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": "6 pages", "summary": "The biases in artificial intelligence (AI) models can lead to automated\ndecision-making processes that discriminate against groups and/or individuals\nbased on sensitive properties such as gender and race. While there are many\nstudies on diagnosing and mitigating biases in various AI models, there is\nlittle research on individual fairness in Graph Neural Networks (GNNs). Unlike\ntraditional models, which treat data features independently and overlook their\ninter-relationships, GNNs are designed to capture graph-based structure where\nnodes are interconnected. This relational approach enables GNNs to model\ncomplex dependencies, but it also means that biases can propagate through these\nconnections, complicating the detection and mitigation of individual fairness\nviolations. This PhD project aims to develop a testing framework to assess and\nensure individual fairness in GNNs. It first systematically reviews the\nliterature on individual fairness, categorizing existing approaches to define,\nmeasure, test, and mitigate model biases, creating a taxonomy of individual\nfairness. Next, the project will develop a framework for testing and ensuring\nfairness in GNNs by adapting and extending current fairness testing and\nmitigation techniques. The framework will be evaluated through industrial case\nstudies, focusing on graph-based large language models."}
{"id": "2504.18215", "pdf": "https://arxiv.org/pdf/2504.18215", "abs": "https://arxiv.org/abs/2504.18215", "authors": ["Nanjie Yao", "Gangjian Zhang", "Wenhao Shen", "Jian Shu", "Hao Wang"], "title": "Unify3D: An Augmented Holistic End-to-end Monocular 3D Human Reconstruction via Anatomy Shaping and Twins Negotiating", "categories": ["cs.CV"], "comment": null, "summary": "Monocular 3D clothed human reconstruction aims to create a complete 3D avatar\nfrom a single image. To tackle the human geometry lacking in one RGB image,\ncurrent methods typically resort to a preceding model for an explicit geometric\nrepresentation. For the reconstruction itself, focus is on modeling both it and\nthe input image. This routine is constrained by the preceding model, and\noverlooks the integrity of the reconstruction task. To address this, this paper\nintroduces a novel paradigm that treats human reconstruction as a holistic\nprocess, utilizing an end-to-end network for direct prediction from 2D image to\n3D avatar, eliminating any explicit intermediate geometry display. Based on\nthis, we further propose a novel reconstruction framework consisting of two\ncore components: the Anatomy Shaping Extraction module, which captures implicit\nshape features taking into account the specialty of human anatomy, and the\nTwins Negotiating Reconstruction U-Net, which enhances reconstruction through\nfeature interaction between two U-Nets of different modalities. Moreover, we\npropose a Comic Data Augmentation strategy and construct 15k+ 3D human scans to\nbolster model performance in more complex case input. Extensive experiments on\ntwo test sets and many in-the-wild cases show the superiority of our method\nover SOTA methods. Our demos can be found in :\nhttps://e2e3dgsrecon.github.io/e2e3dgsrecon/."}
{"id": "2409.08813", "pdf": "https://arxiv.org/pdf/2409.08813", "abs": "https://arxiv.org/abs/2409.08813", "authors": ["Leitian Tao", "Yixuan Li"], "title": "Your Weak LLM is Secretly a Strong Teacher for Alignment", "categories": ["cs.CL"], "comment": "Accepted by ICLR 2025", "summary": "The burgeoning capabilities of large language models (LLMs) have underscored\nthe need for alignment to ensure these models act in accordance with human\nvalues and intentions. Existing alignment frameworks present constraints either\nin the form of expensive human effort or high computational costs. This paper\nexplores a promising middle ground, where we employ a weak LLM that is\nsignificantly less resource-intensive than top-tier models, yet offers more\nautomation than purely human feedback. We present a systematic study to\nevaluate and understand weak LLM's ability to generate feedback for alignment.\nOur empirical findings demonstrate that weak LLMs can provide feedback that\nrivals or even exceeds that of fully human-annotated data. Our study indicates\na minimized impact of model size on feedback efficacy, shedding light on a\nscalable and sustainable alignment strategy. To deepen our understanding of\nalignment under weak LLM feedback, we conduct a series of qualitative and\nquantitative analyses, offering novel insights into the quality discrepancies\nbetween human feedback vs. weak LLM feedback."}
{"id": "2504.18361", "pdf": "https://arxiv.org/pdf/2504.18361", "abs": "https://arxiv.org/abs/2504.18361", "authors": ["Haozhen Yan", "Yan Hong", "Jiahui Zhan", "Yikun Ji", "Jun Lan", "Huijia Zhu", "Weiqiang Wang", "Jianfu Zhang"], "title": "COCO-Inpaint: A Benchmark for Image Inpainting Detection and Manipulation Localization", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 3 figures", "summary": "Recent advancements in image manipulation have achieved unprecedented\nprogress in generating photorealistic content, but also simultaneously\neliminating barriers to arbitrary manipulation and editing, raising concerns\nabout multimedia authenticity and cybersecurity. However, existing Image\nManipulation Detection and Localization (IMDL) methodologies predominantly\nfocus on splicing or copy-move forgeries, lacking dedicated benchmarks for\ninpainting-based manipulations. To bridge this gap, we present COCOInpaint, a\ncomprehensive benchmark specifically designed for inpainting detection, with\nthree key contributions: 1) High-quality inpainting samples generated by six\nstate-of-the-art inpainting models, 2) Diverse generation scenarios enabled by\nfour mask generation strategies with optional text guidance, and 3) Large-scale\ncoverage with 258,266 inpainted images with rich semantic diversity. Our\nbenchmark is constructed to emphasize intrinsic inconsistencies between\ninpainted and authentic regions, rather than superficial semantic artifacts\nsuch as object shapes. We establish a rigorous evaluation protocol using three\nstandard metrics to assess existing IMDL approaches. The dataset will be made\npublicly available to facilitate future research in this area."}
{"id": "2504.18371", "pdf": "https://arxiv.org/pdf/2504.18371", "abs": "https://arxiv.org/abs/2504.18371", "authors": ["Irshad A. Meer", "Bruno H√∂rmann", "Mustafa Ozger", "Fabien Geyer", "Alberto Viseras", "Dominic Schupke", "Cicek Cavdar"], "title": "Explainable AI for UAV Mobility Management: A Deep Q-Network Approach for Handover Minimization", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "Submitted to IEEE PIMRC 2025", "summary": "The integration of unmanned aerial vehicles (UAVs) into cellular networks\npresents significant mobility management challenges, primarily due to frequent\nhandovers caused by probabilistic line-of-sight conditions with multiple ground\nbase stations (BSs). To tackle these challenges, reinforcement learning\n(RL)-based methods, particularly deep Q-networks (DQN), have been employed to\noptimize handover decisions dynamically. However, a major drawback of these\nlearning-based approaches is their black-box nature, which limits\ninterpretability in the decision-making process. This paper introduces an\nexplainable AI (XAI) framework that incorporates Shapley Additive Explanations\n(SHAP) to provide deeper insights into how various state parameters influence\nhandover decisions in a DQN-based mobility management system. By quantifying\nthe impact of key features such as reference signal received power (RSRP),\nreference signal received quality (RSRQ), buffer status, and UAV position, our\napproach enhances the interpretability and reliability of RL-based handover\nsolutions. To validate and compare our framework, we utilize real-world network\nperformance data collected from UAV flight trials. Simulation results show that\nour method provides intuitive explanations for policy decisions, effectively\nbridging the gap between AI-driven models and human decision-makers."}
{"id": "2504.18233", "pdf": "https://arxiv.org/pdf/2504.18233", "abs": "https://arxiv.org/abs/2504.18233", "authors": ["Wenxiang Gua", "Lin Qia"], "title": "Dense Geometry Supervision for Underwater Depth Estimation", "categories": ["cs.CV"], "comment": null, "summary": "The field of monocular depth estimation is continually evolving with the\nadvent of numerous innovative models and extensions. However, research on\nmonocular depth estimation methods specifically for underwater scenes remains\nlimited, compounded by a scarcity of relevant data and methodological support.\nThis paper proposes a novel approach to address the existing challenges in\ncurrent monocular depth estimation methods for underwater environments. We\nconstruct an economically efficient dataset suitable for underwater scenarios\nby employing multi-view depth estimation to generate supervisory signals and\ncorresponding enhanced underwater images. we introduces a texture-depth fusion\nmodule, designed according to the underwater optical imaging principles, which\naims to effectively exploit and integrate depth information from texture cues.\nExperimental results on the FLSea dataset demonstrate that our approach\nsignificantly improves the accuracy and adaptability of models in underwater\nsettings. This work offers a cost-effective solution for monocular underwater\ndepth estimation and holds considerable promise for practical applications."}
{"id": "2409.12059", "pdf": "https://arxiv.org/pdf/2409.12059", "abs": "https://arxiv.org/abs/2409.12059", "authors": ["Ningyuan Xi", "Xiaoyu Wang", "Yetao Wu", "Teng Chen", "Qingqing Gu", "Yue Zhao", "Jinxian Qu", "Zhonglin Jiang", "Yong Chen", "Luo Ji"], "title": "MeTHanol: Modularized Thinking Language Models with Intermediate Layer Thinking, Decoding and Bootstrapping Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "19 pages, 7 figures", "summary": "Large Language Model can reasonably understand and generate human expressions\nbut may lack of thorough thinking and reasoning mechanisms. Recently there have\nbeen several studies which enhance the thinking ability of language models but\nmost of them are not data-driven or training-based. In this paper, we are\nmotivated by the cognitive mechanism in the natural world, and design a novel\nmodel architecture called TaS which allows it to first consider the thoughts\nand then express the response based upon the query. We design several pipelines\nto annotate or generate the thought contents from prompt-response samples, then\nadd language heads in a middle layer which behaves as the thinking layer. We\ntrain the language model by the thoughts-augmented data and successfully let\nthe thinking layer automatically generate reasonable thoughts and finally\noutput more reasonable responses. Both qualitative examples and quantitative\nresults validate the effectiveness and performance of TaS. Our code is\navailable at https://anonymous.4open.science/r/TadE."}
{"id": "2504.18380", "pdf": "https://arxiv.org/pdf/2504.18380", "abs": "https://arxiv.org/abs/2504.18380", "authors": ["Steven H√§sler", "Philipp Ackermann"], "title": "Spatial Reasoner: A 3D Inference Pipeline for XR Applications", "categories": ["cs.SE", "cs.AI", "cs.GR", "cs.HC", "spatial computing, extended reality, knowledge representation,\n  spatial reasoning"], "comment": "11 pages, preprint of ICVARS 2025 paper", "summary": "Modern extended reality XR systems provide rich analysis of image data and\nfusion of sensor input and demand AR/VR applications that can reason about 3D\nscenes in a semantic manner. We present a spatial reasoning framework that\nbridges geometric facts with symbolic predicates and relations to handle key\ntasks such as determining how 3D objects are arranged among each other ('on',\n'behind', 'near', etc.). Its foundation relies on oriented 3D bounding box\nrepresentations, enhanced by a comprehensive set of spatial predicates, ranging\nfrom topology and connectivity to directionality and orientation, expressed in\na formalism related to natural language. The derived predicates form a spatial\nknowledge graph and, in combination with a pipeline-based inference model,\nenable spatial queries and dynamic rule evaluation. Implementations for client-\nand server-side processing demonstrate the framework's capability to\nefficiently translate geometric data into actionable knowledge, ensuring\nscalable and technology-independent spatial reasoning in complex 3D\nenvironments. The Spatial Reasoner framework is fostering the creation of\nspatial ontologies, and seamlessly integrates with and therefore enriches\nmachine learning, natural language processing, and rule systems in XR\napplications."}
{"id": "2504.18385", "pdf": "https://arxiv.org/pdf/2504.18385", "abs": "https://arxiv.org/abs/2504.18385", "authors": ["Danial Dervovic", "Michael Cashmore"], "title": "Model Evaluation in the Dark: Robust Classifier Metrics with Missing Labels", "categories": ["cs.LG", "stat.ML"], "comment": "9 pages, 4 figures. Accepted to AISTATS 2025", "summary": "Missing data in supervised learning is well-studied, but the specific issue\nof missing labels during model evaluation has been overlooked. Ignoring samples\nwith missing values, a common solution, can introduce bias, especially when\ndata is Missing Not At Random (MNAR). We propose a multiple imputation\ntechnique for evaluating classifiers using metrics such as precision, recall,\nand ROC-AUC. This method not only offers point estimates but also a predictive\ndistribution for these quantities when labels are missing. We empirically show\nthat the predictive distribution's location and shape are generally correct,\neven in the MNAR regime. Moreover, we establish that this distribution is\napproximately Gaussian and provide finite-sample convergence bounds.\nAdditionally, a robustness proof is presented, confirming the validity of the\napproximation under a realistic error model."}
{"id": "2504.18235", "pdf": "https://arxiv.org/pdf/2504.18235", "abs": "https://arxiv.org/abs/2504.18235", "authors": ["Andreas Ziegler", "David Joseph", "Thomas Gossard", "Emil Moldovan", "Andreas Zell"], "title": "BiasBench: A reproducible benchmark for tuning the biases of event cameras", "categories": ["cs.CV", "cs.RO"], "comment": "Accepted to CVPR 2025 Workshop on Event-based Vision", "summary": "Event-based cameras are bio-inspired sensors that detect light changes\nasynchronously for each pixel. They are increasingly used in fields like\ncomputer vision and robotics because of several advantages over traditional\nframe-based cameras, such as high temporal resolution, low latency, and high\ndynamic range. As with any camera, the output's quality depends on how well the\ncamera's settings, called biases for event-based cameras, are configured. While\nframe-based cameras have advanced automatic configuration algorithms, there are\nvery few such tools for tuning these biases. A systematic testing framework\nwould require observing the same scene with different biases, which is tricky\nsince event cameras only generate events when there is movement. Event\nsimulators exist, but since biases heavily depend on the electrical circuit and\nthe pixel design, available simulators are not well suited for bias tuning. To\nallow reproducibility, we present BiasBench, a novel event dataset containing\nmultiple scenes with settings sampled in a grid-like pattern. We present three\ndifferent scenes, each with a quality metric of the downstream application.\nAdditionally, we present a novel, RL-based method to facilitate online bias\nadjustments."}
{"id": "2410.03727", "pdf": "https://arxiv.org/pdf/2410.03727", "abs": "https://arxiv.org/abs/2410.03727", "authors": ["Yifei Ming", "Senthil Purushwalkam", "Shrey Pandit", "Zixuan Ke", "Xuan-Phi Nguyen", "Caiming Xiong", "Shafiq Joty"], "title": "FaithEval: Can Your Language Model Stay Faithful to Context, Even If \"The Moon is Made of Marshmallows\"", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "The conference version of this paper is published at ICLR 2025", "summary": "Ensuring faithfulness to context in large language models (LLMs) and\nretrieval-augmented generation (RAG) systems is crucial for reliable deployment\nin real-world applications, as incorrect or unsupported information can erode\nuser trust. Despite advancements on standard benchmarks, faithfulness\nhallucination-where models generate responses misaligned with the provided\ncontext-remains a significant challenge. In this work, we introduce FaithEval,\na novel and comprehensive benchmark tailored to evaluate the faithfulness of\nLLMs in contextual scenarios across three diverse tasks: unanswerable,\ninconsistent, and counterfactual contexts. These tasks simulate real-world\nchallenges where retrieval mechanisms may surface incomplete, contradictory, or\nfabricated information. FaithEval comprises 4.9K high-quality problems in\ntotal, validated through a rigorous four-stage context construction and\nvalidation framework, employing both LLM-based auto-evaluation and human\nvalidation. Our extensive study across a wide range of open-source and\nproprietary models reveals that even state-of-the-art models often struggle to\nremain faithful to the given context, and that larger models do not necessarily\nexhibit improved faithfulness.Project is available at:\nhttps://github.com/SalesforceAIResearch/FaithEval."}
{"id": "2504.18383", "pdf": "https://arxiv.org/pdf/2504.18383", "abs": "https://arxiv.org/abs/2504.18383", "authors": ["Qidong Liu", "Xiangyu Zhao", "Yejing Wang", "Zijian Zhang", "Howard Zhong", "Chong Chen", "Xiang Li", "Wei Huang", "Feng Tian"], "title": "Bridge the Domains: Large Language Models Enhanced Cross-domain Sequential Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": "accepted by SIGIR'25", "summary": "Cross-domain Sequential Recommendation (CDSR) aims to extract the preference\nfrom the user's historical interactions across various domains. Despite some\nprogress in CDSR, two problems set the barrier for further advancements, i.e.,\noverlap dilemma and transition complexity. The former means existing CDSR\nmethods severely rely on users who own interactions on all domains to learn\ncross-domain item relationships, compromising the practicability. The latter\nrefers to the difficulties in learning the complex transition patterns from the\nmixed behavior sequences. With powerful representation and reasoning abilities,\nLarge Language Models (LLMs) are promising to address these two problems by\nbridging the items and capturing the user's preferences from a semantic view.\nTherefore, we propose an LLMs Enhanced Cross-domain Sequential Recommendation\nmodel (LLM4CDSR). To obtain the semantic item relationships, we first propose\nan LLM-based unified representation module to represent items. Then, a\ntrainable adapter with contrastive regularization is designed to adapt the CDSR\ntask. Besides, a hierarchical LLMs profiling module is designed to summarize\nuser cross-domain preferences. Finally, these two modules are integrated into\nthe proposed tri-thread framework to derive recommendations. We have conducted\nextensive experiments on three public cross-domain datasets, validating the\neffectiveness of LLM4CDSR. We have released the code online."}
{"id": "2504.18393", "pdf": "https://arxiv.org/pdf/2504.18393", "abs": "https://arxiv.org/abs/2504.18393", "authors": ["Marina Andric", "Mauro Dragoni"], "title": "Machine Learning and Statistical Insights into Hospital Stay Durations: The Italian EHR Case", "categories": ["cs.LG"], "comment": null, "summary": "Length of hospital stay is a critical metric for assessing healthcare quality\nand optimizing hospital resource management. This study aims to identify\nfactors influencing LoS within the Italian healthcare context, using a dataset\nof hospitalization records from over 60 healthcare facilities in the Piedmont\nregion, spanning from 2020 to 2023. We explored a variety of features,\nincluding patient characteristics, comorbidities, admission details, and\nhospital-specific factors. Significant correlations were found between LoS and\nfeatures such as age group, comorbidity score, admission type, and the month of\nadmission. Machine learning models, specifically CatBoost and Random Forest,\nwere used to predict LoS. The highest R2 score, 0.49, was achieved with\nCatBoost, demonstrating good predictive performance."}
{"id": "2504.18256", "pdf": "https://arxiv.org/pdf/2504.18256", "abs": "https://arxiv.org/abs/2504.18256", "authors": ["Elena Plekhanova", "Damien Robert", "Johannes Dollinger", "Emilia Arens", "Philipp Brun", "Jan Dirk Wegner", "Niklaus Zimmermann"], "title": "SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology", "categories": ["cs.CV"], "comment": "CVPR 2025, EarthVision workshop", "summary": "With the exacerbation of the biodiversity and climate crises, macroecological\npursuits such as global biodiversity mapping become more urgent. Remote sensing\noffers a wealth of Earth observation data for ecological studies, but the\nscarcity of labeled datasets remains a major challenge. Recently,\nself-supervised learning has enabled learning representations from unlabeled\ndata, triggering the development of pretrained geospatial models with\ngeneralizable features. However, these models are often trained on datasets\nbiased toward areas of high human activity, leaving entire ecological regions\nunderrepresented. Additionally, while some datasets attempt to address\nseasonality through multi-date imagery, they typically follow calendar seasons\nrather than local phenological cycles. To better capture vegetation seasonality\nat a global scale, we propose a simple phenology-informed sampling strategy and\nintroduce corresponding SSL4Eco, a multi-date Sentinel-2 dataset, on which we\ntrain an existing model with a season-contrastive objective. We compare\nrepresentations learned from SSL4Eco against other datasets on diverse\necological downstream tasks and demonstrate that our straightforward sampling\nmethod consistently improves representation quality, highlighting the\nimportance of dataset construction. The model pretrained on SSL4Eco reaches\nstate of the art performance on 7 out of 8 downstream tasks spanning\n(multi-label) classification and regression. We release our code, data, and\nmodel weights to support macroecological and computer vision research at\nhttps://github.com/PlekhanovaElena/ssl4eco."}
{"id": "2411.07611", "pdf": "https://arxiv.org/pdf/2411.07611", "abs": "https://arxiv.org/abs/2411.07611", "authors": ["Shuai Niu", "Jing Ma", "Hongzhan Lin", "Liang Bai", "Zhihua Wang", "Yida Xu", "Yunya Song", "Xian Yang"], "title": "Knowledge-Augmented Multimodal Clinical Rationale Generation for Disease Diagnosis with Small Language Models", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "13 pages. 7 figures", "summary": "Interpretation is critical for disease diagnosis, but existing models\nstruggle to balance predictive accuracy with human-understandable rationales.\nWhile large language models (LLMs) offer strong reasoning abilities, their\nclinical use is limited by high computational costs and restricted multimodal\nreasoning ability. Small language models (SLMs) are efficient but lack advanced\nreasoning for integrating multimodal medical data. In addition, both LLMs and\nSLMs lack of domain knowledge for trustworthy reasoning. Therefore, we propose\nClinRaGen, enhancing SLMs by leveraging LLM-derived reasoning ability via\nrationale distillation and domain knowledge injection for trustworthy\nmultimodal rationale generation. Key innovations include a sequential rationale\ndistillation framework that equips SLMs with LLM-comparable mutlimodal\nreasoning abilities, and a knowledge-augmented attention mechanism that jointly\nunifies multimodal representation from time series and textual data in a same\nencoding space, enabling it naturally interpreted by SLMs while incorporating\ndomain knowledge for reliable rationale generation. Experiments on real-world\nmedical datasets show that ClinRaGen achieves state-of-the-art performance in\ndisease diagnosis and rationale generation, demonstrating the effectiveness of\ncombining LLM-driven reasoning with knowledge augmentation for improved\ninterpretability."}
{"id": "2504.18404", "pdf": "https://arxiv.org/pdf/2504.18404", "abs": "https://arxiv.org/abs/2504.18404", "authors": ["Liang Yu"], "title": "Paradigm shift on Coding Productivity Using GenAI", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Generative AI (GenAI) applications are transforming software engineering by\nenabling automated code co-creation. However, empirical evidence on GenAI's\nproductivity effects in industrial settings remains limited. This paper\ninvestigates the adoption of GenAI coding assistants (e.g., Codeium, Amazon Q)\nwithin telecommunications and FinTech domains. Through surveys and interviews\nwith industrial domain-experts, we identify primary productivity-influencing\nfactors, including task complexity, coding skills, domain knowledge, and GenAI\nintegration. Our findings indicate that GenAI tools enhance productivity in\nroutine coding tasks (e.g., refactoring and Javadoc generation) but face\nchallenges in complex, domain-specific activities due to limited\ncontext-awareness of codebases and insufficient support for customized design\nrules. We highlight new paradigms for coding transfer, emphasizing iterative\nprompt refinement, immersive development environment, and automated code\nevaluation as essential for effective GenAI usage."}
{"id": "2504.18395", "pdf": "https://arxiv.org/pdf/2504.18395", "abs": "https://arxiv.org/abs/2504.18395", "authors": ["Rabanus Derr", "Jessie Finocchiaro", "Robert C. Williamson"], "title": "Three Types of Calibration with Properties and their Semantic and Formal Relationships", "categories": ["cs.LG"], "comment": null, "summary": "Fueled by discussions around \"trustworthiness\" and algorithmic fairness,\ncalibration of predictive systems has regained scholars attention. The vanilla\ndefinition and understanding of calibration is, simply put, on all days on\nwhich the rain probability has been predicted to be p, the actual frequency of\nrain days was p. However, the increased attention has led to an immense variety\nof new notions of \"calibration.\" Some of the notions are incomparable, serve\ndifferent purposes, or imply each other. In this work, we provide two accounts\nwhich motivate calibration: self-realization of forecasted properties and\nprecise estimation of incurred losses of the decision makers relying on\nforecasts. We substantiate the former via the reflection principle and the\nlatter by actuarial fairness. For both accounts we formulate prototypical\ndefinitions via properties $\\Gamma$ of outcome distributions, e.g., the mean or\nmedian. The prototypical definition for self-realization, which we call\n$\\Gamma$-calibration, is equivalent to a certain type of swap regret under\ncertain conditions. These implications are strongly connected to the\nomniprediction learning paradigm. The prototypical definition for precise loss\nestimation is a modification of decision calibration adopted from Zhao et al.\n[73]. For binary outcome sets both prototypical definitions coincide under\nappropriate choices of reference properties. For higher-dimensional outcome\nsets, both prototypical definitions can be subsumed by a natural extension of\nthe binary definition, called distribution calibration with respect to a\nproperty. We conclude by commenting on the role of groupings in both accounts\nof calibration often used to obtain multicalibration. In sum, this work\nprovides a semantic map of calibration in order to navigate a fragmented\nterrain of notions and definitions."}
{"id": "2504.18317", "pdf": "https://arxiv.org/pdf/2504.18317", "abs": "https://arxiv.org/abs/2504.18317", "authors": ["Zhengru Fang", "Zhenghao Liu", "Jingjing Wang", "Senkang Hu", "Yu Guo", "Yiqin Deng", "Yuguang Fang"], "title": "Task-Oriented Communications for Visual Navigation with Edge-Aerial Collaboration in Low Altitude Economy", "categories": ["cs.CV", "cs.NI"], "comment": "Code and dataset will be made publicly available:\n  https://github.com/fangzr/TOC-Edge-Aerial", "summary": "To support the Low Altitude Economy (LAE), precise unmanned aerial vehicles\n(UAVs) localization in urban areas where global positioning system (GPS)\nsignals are unavailable. Vision-based methods offer a viable alternative but\nface severe bandwidth, memory and processing constraints on lightweight UAVs.\nInspired by mammalian spatial cognition, we propose a task-oriented\ncommunication framework, where UAVs equipped with multi-camera systems extract\ncompact multi-view features and offload localization tasks to edge servers. We\nintroduce the Orthogonally-constrained Variational Information Bottleneck\nencoder (O-VIB), which incorporates automatic relevance determination (ARD) to\nprune non-informative features while enforcing orthogonality to minimize\nredundancy. This enables efficient and accurate localization with minimal\ntransmission cost. Extensive evaluation on a dedicated LAE UAV dataset shows\nthat O-VIB achieves high-precision localization under stringent bandwidth\nbudgets. Code and dataset will be made publicly available:\ngithub.com/fangzr/TOC-Edge-Aerial."}
{"id": "2412.11704", "pdf": "https://arxiv.org/pdf/2412.11704", "abs": "https://arxiv.org/abs/2412.11704", "authors": ["Atsuki Yamaguchi", "Terufumi Morishita", "Aline Villavicencio", "Nikolaos Aletras"], "title": "ElChat: Adapting Chat Language Models Using Only Target Unlabeled Language Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Vocabulary expansion (VE) is the de-facto approach to language adaptation of\nlarge language models (LLMs) by adding new tokens and continuing pre-training\non target data. While this is effective for base models trained on unlabeled\ndata, it poses challenges for chat models trained to follow instructions\nthrough labeled conversation data. Directly adapting the latter with VE on\ntarget unlabeled data may result in forgetting chat abilities. While ideal,\ntarget chat data is often unavailable or costly to create for low-resource\nlanguages, and machine-translated alternatives are not always effective. To\naddress this issue, previous work proposed using a base and chat model from the\nsame family. This method first adapts the base LLM with VE on target unlabeled\ndata and then converts it to a chat model by adding a chat vector (CV) derived\nfrom the weight difference between the source base and chat models. We propose\nElChat, a new language adaptation method for chat LLMs that adapts a chat model\ndirectly on target unlabeled data, without a base model. It elicits chat\nabilities by injecting information from the source chat model. ElChat offers\nmore robust and competitive target language and safety performance while\nachieving superior English, chat, and instruction-following abilities compared\nto CV."}
{"id": "2504.18419", "pdf": "https://arxiv.org/pdf/2504.18419", "abs": "https://arxiv.org/abs/2504.18419", "authors": ["Carlo Sgaravatti", "Roberto Basla", "Riccardo Pieroni", "Matteo Corno", "Sergio M. Savaresi", "Luca Magri", "Giacomo Boracchi"], "title": "A Multimodal Hybrid Late-Cascade Fusion Network for Enhanced 3D Object Detection", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "We present a new way to detect 3D objects from multimodal inputs, leveraging\nboth LiDAR and RGB cameras in a hybrid late-cascade scheme, that combines an\nRGB detection network and a 3D LiDAR detector. We exploit late fusion\nprinciples to reduce LiDAR False Positives, matching LiDAR detections with RGB\nones by projecting the LiDAR bounding boxes on the image. We rely on cascade\nfusion principles to recover LiDAR False Negatives leveraging epipolar\nconstraints and frustums generated by RGB detections of separate views. Our\nsolution can be plugged on top of any underlying single-modal detectors,\nenabling a flexible training process that can take advantage of pre-trained\nLiDAR and RGB detectors, or train the two branches separately. We evaluate our\nresults on the KITTI object detection benchmark, showing significant\nperformance improvements, especially for the detection of Pedestrians and\nCyclists."}
{"id": "2504.18414", "pdf": "https://arxiv.org/pdf/2504.18414", "abs": "https://arxiv.org/abs/2504.18414", "authors": ["Vinicius L S Silva", "Pablo Salinas", "Claire E Heaney", "Matthew Jackson", "Christopher C Pain"], "title": "Online learning to accelerate nonlinear PDE solvers: applied to multiphase porous media flow", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "We propose a novel type of nonlinear solver acceleration for systems of\nnonlinear partial differential equations (PDEs) that is based on\nonline/adaptive learning. It is applied in the context of multiphase flow in\nporous media. The proposed method rely on four pillars: (i) dimensionless\nnumbers as input parameters for the machine learning model, (ii) simplified\nnumerical model (two-dimensional) for the offline training, (iii) dynamic\ncontrol of a nonlinear solver tuning parameter (numerical relaxation), (iv) and\nonline learning for real-time improvement of the machine learning model. This\nstrategy decreases the number of nonlinear iterations by dynamically modifying\na single global parameter, the relaxation factor, and by adaptively learning\nthe attributes of each numerical model on-the-run. Furthermore, this work\nperforms a sensitivity study in the dimensionless parameters (machine learning\nfeatures), assess the efficacy of various machine learning models, demonstrate\na decrease in nonlinear iterations using our method in more intricate,\nrealistic three-dimensional models, and fully couple a machine learning model\ninto an open-source multiphase flow simulator achieving up to 85\\% reduction in\ncomputational time."}
{"id": "2504.18318", "pdf": "https://arxiv.org/pdf/2504.18318", "abs": "https://arxiv.org/abs/2504.18318", "authors": ["Yunze Deng", "Haijun Xiong", "Bin Feng", "Xinggang Wang", "Wenyu Liu"], "title": "STP4D: Spatio-Temporal-Prompt Consistent Modeling for Text-to-4D Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-4D generation is rapidly developing and widely applied in various\nscenarios. However, existing methods often fail to incorporate adequate\nspatio-temporal modeling and prompt alignment within a unified framework,\nresulting in temporal inconsistencies, geometric distortions, or low-quality 4D\ncontent that deviates from the provided texts. Therefore, we propose STP4D, a\nnovel approach that aims to integrate comprehensive spatio-temporal-prompt\nconsistency modeling for high-quality text-to-4D generation. Specifically,\nSTP4D employs three carefully designed modules: Time-varying Prompt Embedding,\nGeometric Information Enhancement, and Temporal Extension Deformation, which\ncollaborate to accomplish this goal. Furthermore, STP4D is among the first\nmethods to exploit the Diffusion model to generate 4D Gaussians, combining the\nfine-grained modeling capabilities and the real-time rendering process of 4DGS\nwith the rapid inference speed of the Diffusion model. Extensive experiments\ndemonstrate that STP4D excels in generating high-fidelity 4D content with\nexceptional efficiency (approximately 4.6s per asset), surpassing existing\nmethods in both quality and speed."}
{"id": "2502.01220", "pdf": "https://arxiv.org/pdf/2502.01220", "abs": "https://arxiv.org/abs/2502.01220", "authors": ["Hichem Ammar Khodja", "Fr√©d√©ric B√©chet", "Quentin Brabant", "Alexis Nasr", "Gw√©nol√© Lecorv√©"], "title": "Factual Knowledge in Language Models: Robustness and Anomalies under Simple Temporal Context Variations", "categories": ["cs.CL", "cs.LG"], "comment": "preprint v3", "summary": "This paper explores the robustness of language models (LMs) to variations in\nthe temporal context within factual knowledge. It examines whether LMs can\ncorrectly associate a temporal context with a past fact valid over a defined\nperiod, by asking them to differentiate correct from incorrect contexts. The\naccuracy of LMs is analyzed along two dimensions: the distance of the incorrect\ncontext from the validity period and the granularity of the context. To this\nend, a dataset called TimeStress is introduced, enabling the evaluation of 18\ndiverse LMs. Results reveal that the best LM achieves perfect accuracy for only\n6% of the studied facts, with critical errors that humans would not make. This\nwork highlights the limitations of current LMs in temporal representation. We\nprovide all data and code for further research."}
{"id": "2504.18423", "pdf": "https://arxiv.org/pdf/2504.18423", "abs": "https://arxiv.org/abs/2504.18423", "authors": ["Rajesh Yarra"], "title": "LLMpatronous: Harnessing the Power of LLMs For Vulnerability Detection", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Despite the transformative impact of Artificial Intelligence (AI) across\nvarious sectors, cyber security continues to rely on traditional static and\ndynamic analysis tools, hampered by high false positive rates and superficial\ncode comprehension. While generative AI offers promising automation\ncapabilities for software development, leveraging Large Language Models (LLMs)\nfor vulnerability detection presents unique challenges. This paper explores the\npotential and limitations of LLMs in identifying vulnerabilities, acknowledging\ninherent weaknesses such as hallucinations, limited context length, and\nknowledge cut-offs. Previous attempts employing machine learning models for\nvulnerability detection have proven ineffective due to limited real-world\napplicability, feature engineering challenges, lack of contextual\nunderstanding, and the complexities of training models to keep pace with the\nevolving threat landscape. Therefore, we propose a robust AI-driven approach\nfocused on mitigating these limitations and ensuring the quality and\nreliability of LLM based vulnerability detection. Through innovative\nmethodologies combining Retrieval-Augmented Generation (RAG) and\nMixtureof-Agents (MoA), this research seeks to leverage the strengths of LLMs\nwhile addressing their weaknesses, ultimately paving the way for dependable and\nefficient AI-powered solutions in securing the ever-evolving software\nlandscape."}
{"id": "2504.18433", "pdf": "https://arxiv.org/pdf/2504.18433", "abs": "https://arxiv.org/abs/2504.18433", "authors": ["Christopher B√ºlte", "Yusuf Sale", "Timo L√∂hr", "Paul Hofman", "Gitta Kutyniok", "Eyke H√ºllermeier"], "title": "An Axiomatic Assessment of Entropy- and Variance-based Uncertainty Quantification in Regression", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Uncertainty quantification (UQ) is crucial in machine learning, yet most\n(axiomatic) studies of uncertainty measures focus on classification, leaving a\ngap in regression settings with limited formal justification and evaluations.\nIn this work, we introduce a set of axioms to rigorously assess measures of\naleatoric, epistemic, and total uncertainty in supervised regression. By\nutilizing a predictive exponential family, we can generalize commonly used\napproaches for uncertainty representation and corresponding uncertainty\nmeasures. More specifically, we analyze the widely used entropy- and\nvariance-based measures regarding limitations and challenges. Our findings\nprovide a principled foundation for UQ in regression, offering theoretical\ninsights and practical guidelines for reliable uncertainty assessment."}
{"id": "2504.18325", "pdf": "https://arxiv.org/pdf/2504.18325", "abs": "https://arxiv.org/abs/2504.18325", "authors": ["Dongxin Lyu", "Han Huang", "Cheng Tan", "Zimu Li"], "title": "Depth3DLane: Monocular 3D Lane Detection via Depth Prior Distillation", "categories": ["cs.CV"], "comment": "Submitting to ICCV2025", "summary": "Monocular 3D lane detection is challenging due to the difficulty in capturing\ndepth information from single-camera images. A common strategy involves\ntransforming front-view (FV) images into bird's-eye-view (BEV) space through\ninverse perspective mapping (IPM), facilitating lane detection using BEV\nfeatures. However, IPM's flat-ground assumption and loss of contextual\ninformation lead to inaccuracies in reconstructing 3D information, especially\nheight. In this paper, we introduce a BEV-based framework to address these\nlimitations and improve 3D lane detection accuracy. Our approach incorporates a\nHierarchical Depth-Aware Head that provides multi-scale depth features,\nmitigating the flat-ground assumption by enhancing spatial awareness across\nvarying depths. Additionally, we leverage Depth Prior Distillation to transfer\nsemantic depth knowledge from a teacher model, capturing richer structural and\ncontextual information for complex lane structures. To further refine lane\ncontinuity and ensure smooth lane reconstruction, we introduce a Conditional\nRandom Field module that enforces spatial coherence in lane predictions.\nExtensive experiments validate that our method achieves state-of-the-art\nperformance in terms of z-axis error and outperforms other methods in the field\nin overall performance. The code is released at:\nhttps://anonymous.4open.science/r/Depth3DLane-DCDD."}
{"id": "2502.12486", "pdf": "https://arxiv.org/pdf/2502.12486", "abs": "https://arxiv.org/abs/2502.12486", "authors": ["Xiaoqian Liu", "Ke Wang", "Yongbin Li", "Yuchuan Wu", "Wentao Ma", "Aobo Kong", "Fei Huang", "Jianbin Jiao", "Junge Zhang"], "title": "EPO: Explicit Policy Optimization for Strategic Reasoning in LLMs via Reinforcement Learning", "categories": ["cs.CL"], "comment": "22 pages, 4 figures", "summary": "Large Language Models (LLMs) have shown impressive reasoning capabilities in\nwell-defined problems with clear solutions, such as mathematics and coding.\nHowever, they still struggle with complex real-world scenarios like business\nnegotiations, which require strategic reasoning-an ability to navigate dynamic\nenvironments and align long-term goals amidst uncertainty. Existing methods for\nstrategic reasoning face challenges in adaptability, scalability, and\ntransferring strategies to new contexts. To address these issues, we propose\nexplicit policy optimization (EPO) for strategic reasoning, featuring an LLM\nthat provides strategies in open-ended action space and can be plugged into\narbitrary LLM agents to motivate goal-directed behavior. To improve\nadaptability and policy transferability, we train the strategic reasoning model\nvia multi-turn reinforcement learning (RL) using process rewards and iterative\nself-play, without supervised fine-tuning (SFT) as a preliminary step.\nExperiments across social and physical domains demonstrate EPO's ability of\nlong-term goal alignment through enhanced strategic reasoning, achieving\nstate-of-the-art performance on social dialogue and web navigation tasks. Our\nfindings reveal various collaborative reasoning mechanisms emergent in EPO and\nits effectiveness in generating novel strategies, underscoring its potential\nfor strategic reasoning in real-world applications. Code and data are available\nat https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/EPO."}
{"id": "2504.18437", "pdf": "https://arxiv.org/pdf/2504.18437", "abs": "https://arxiv.org/abs/2504.18437", "authors": ["Kun He", "Zijian Song", "Shuoxi Zhang", "John E. Hopcroft"], "title": "Enhancing Pre-Trained Model-Based Class-Incremental Learning through Neural Collapse", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Class-Incremental Learning (CIL) is a critical capability for real-world\napplications, enabling learning systems to adapt to new tasks while retaining\nknowledge from previous ones. Recent advancements in pre-trained models (PTMs)\nhave significantly advanced the field of CIL, demonstrating superior\nperformance over traditional methods. However, understanding how features\nevolve and are distributed across incremental tasks remains an open challenge.\nIn this paper, we propose a novel approach to modeling feature evolution in\nPTM-based CIL through the lens of neural collapse (NC), a striking phenomenon\nobserved in the final phase of training, which leads to a well-separated,\nequiangular feature space. We explore the connection between NC and CIL\neffectiveness, showing that aligning feature distributions with the NC geometry\nenhances the ability to capture the dynamic behavior of continual learning.\nBased on this insight, we introduce Neural Collapse-inspired Pre-Trained\nModel-based CIL (NCPTM-CIL), a method that dynamically adjusts the feature\nspace to conform to the elegant NC structure, thereby enhancing the continual\nlearning process. Extensive experiments demonstrate that NCPTM-CIL outperforms\nstate-of-the-art methods across four benchmark datasets. Notably, when\ninitialized with ViT-B/16-IN1K, NCPTM-CIL surpasses the runner-up method by\n6.73% on VTAB, 1.25% on CIFAR-100, and 2.5% on OmniBenchmark."}
{"id": "2504.18451", "pdf": "https://arxiv.org/pdf/2504.18451", "abs": "https://arxiv.org/abs/2504.18451", "authors": ["Tewodros Alemu Ayall", "Andy Li", "Matthew Beddows", "Milan Markovic", "Georgios Leontidis"], "title": "Enhancing Strawberry Yield Forecasting with Backcasted IoT Sensor Data and Machine Learning", "categories": ["cs.LG"], "comment": "20 pages, 11 figures", "summary": "Due to rapid population growth globally, digitally-enabled agricultural\nsectors are crucial for sustainable food production and making informed\ndecisions about resource management for farmers and various stakeholders. The\ndeployment of Internet of Things (IoT) technologies that collect real-time\nobservations of various environmental (e.g., temperature, humidity, etc.) and\noperational factors (e.g., irrigation) influencing production is often seen as\na critical step to enable additional novel downstream tasks, such as AI-based\nyield forecasting. However, since AI models require large amounts of data, this\ncreates practical challenges in a real-world dynamic farm setting where IoT\nobservations would need to be collected over a number of seasons. In this\nstudy, we deployed IoT sensors in strawberry production polytunnels for two\ngrowing seasons to collect environmental data, including water usage, external\nand internal temperature, external and internal humidity, soil moisture, soil\ntemperature, and photosynthetically active radiation. The sensor observations\nwere combined with manually provided yield records spanning a period of four\nseasons. To bridge the gap of missing IoT observations for two additional\nseasons, we propose an AI-based backcasting approach to generate synthetic\nsensor observations using historical weather data from a nearby weather station\nand the existing polytunnel observations. We built an AI-based yield\nforecasting model to evaluate our approach using the combination of real and\nsynthetic observations. Our results demonstrated that incorporating synthetic\ndata improved yield forecasting accuracy, with models incorporating synthetic\ndata outperforming those trained only on historical yield, weather records, and\nreal sensor data."}
{"id": "2504.18332", "pdf": "https://arxiv.org/pdf/2504.18332", "abs": "https://arxiv.org/abs/2504.18332", "authors": ["Shuting Zhao", "Linxin Bai", "Liangjing Shao", "Ye Zhang", "Xinrong Chen"], "title": "SSD-Poser: Avatar Pose Estimation with State Space Duality from Sparse Observations", "categories": ["cs.CV", "cs.HC", "68U05"], "comment": "9 pages, 6 figures, conference ICMR 2025", "summary": "The growing applications of AR/VR increase the demand for real-time full-body\npose estimation from Head-Mounted Displays (HMDs). Although HMDs provide joint\nsignals from the head and hands, reconstructing a full-body pose remains\nchallenging due to the unconstrained lower body. Recent advancements often rely\non conventional neural networks and generative models to improve performance in\nthis task, such as Transformers and diffusion models. However, these approaches\nstruggle to strike a balance between achieving precise pose reconstruction and\nmaintaining fast inference speed. To overcome these challenges, a lightweight\nand efficient model, SSD-Poser, is designed for robust full-body motion\nestimation from sparse observations. SSD-Poser incorporates a well-designed\nhybrid encoder, State Space Attention Encoders, to adapt the state space\nduality to complex motion poses and enable real-time realistic pose\nreconstruction. Moreover, a Frequency-Aware Decoder is introduced to mitigate\njitter caused by variable-frequency motion signals, remarkably enhancing the\nmotion smoothness. Comprehensive experiments on the AMASS dataset demonstrate\nthat SSD-Poser achieves exceptional accuracy and computational efficiency,\nshowing outstanding inference efficiency compared to state-of-the-art methods."}
{"id": "2502.15654", "pdf": "https://arxiv.org/pdf/2502.15654", "abs": "https://arxiv.org/abs/2502.15654", "authors": ["George Drayson", "Emine Yilmaz", "Vasileios Lampos"], "title": "Machine-generated text detection prevents language model collapse", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "As Large Language Models (LLMs) become increasingly prevalent, their\ngenerated outputs are proliferating across the web, risking a future where\nmachine-generated content dilutes human-authored text. Since online data is the\nprimary resource for LLM pre-training, subsequent models could be trained on an\nunknown portion of synthetic samples. This will lead to model collapse, a\ndegenerative process whereby LLMs reinforce their own errors, and ultimately\nyield a declining performance. In this study, we investigate the impact of\ndecoding strategy on model collapse, analysing the characteristics of text at\neach model generation, the similarity to human references, and the resulting\nmodel performance. Using the decoding strategies that lead to the most\nsignificant degradation, we evaluate model collapse in more realistic scenarios\nwhere the origin of the data (human or synthetic) is unknown. We train a\nmachine-generated text detector and propose an importance sampling approach to\nalleviate model collapse. Our method is validated on two LLM variants (GPT-2\nand SmolLM2) on the open-ended text generation task. We demonstrate that it can\nnot only prevent model collapse but also improve performance when sufficient\nhuman-authored samples are present. We release our code at\nhttps://github.com/GeorgeDrayson/model_collapse."}
{"id": "2504.18471", "pdf": "https://arxiv.org/pdf/2504.18471", "abs": "https://arxiv.org/abs/2504.18471", "authors": ["Alejandro Murillo-Gonzalez", "Lantao Liu"], "title": "Action Flow Matching for Continual Robot Learning", "categories": ["cs.RO", "cs.AI"], "comment": "Robotics: Science and Systems 2025", "summary": "Continual learning in robotics seeks systems that can constantly adapt to\nchanging environments and tasks, mirroring human adaptability. A key challenge\nis refining dynamics models, essential for planning and control, while\naddressing issues such as safe adaptation, catastrophic forgetting, outlier\nmanagement, data efficiency, and balancing exploration with exploitation -- all\nwithin task and onboard resource constraints. Towards this goal, we introduce a\ngenerative framework leveraging flow matching for online robot dynamics model\nalignment. Rather than executing actions based on a misaligned model, our\napproach refines planned actions to better match with those the robot would\ntake if its model was well aligned. We find that by transforming the actions\nthemselves rather than exploring with a misaligned model -- as is traditionally\ndone -- the robot collects informative data more efficiently, thereby\naccelerating learning. Moreover, we validate that the method can handle an\nevolving and possibly imperfect model while reducing, if desired, the\ndependency on replay buffers or legacy model snapshots. We validate our\napproach using two platforms: an unmanned ground vehicle and a quadrotor. The\nresults highlight the method's adaptability and efficiency, with a record\n34.2\\% higher task success rate, demonstrating its potential towards enabling\ncontinual robot learning. Code:\nhttps://github.com/AlejandroMllo/action_flow_matching."}
{"id": "2504.18454", "pdf": "https://arxiv.org/pdf/2504.18454", "abs": "https://arxiv.org/abs/2504.18454", "authors": ["Hiroki Naganuma", "Xinzhi Zhang", "Man-Chung Yue", "Ioannis Mitliagkas", "Philipp A. Witte", "Russell J. Hewett", "Yin Tat Lee"], "title": "Pseudo-Asynchronous Local SGD: Robust and Efficient Data-Parallel Training", "categories": ["cs.LG"], "comment": null, "summary": "Following AI scaling trends, frontier models continue to grow in size and\ncontinue to be trained on larger datasets. Training these models requires huge\ninvestments in exascale computational resources, which has in turn driven\ndevelopment of distributed deep learning methods. Data parallelism is an\nessential approach to speed up training, but it requires frequent global\ncommunication between workers, which can bottleneck training at the largest\nscales. In this work, we propose a method called Pseudo-Asynchronous Local SGD\n(PALSGD) to improve the efficiency of data-parallel training. PALSGD is an\nextension of Local SGD (Stich, 2018) and DiLoCo (Douillard et al., 2023),\ndesigned to further reduce communication frequency by introducing a\npseudo-synchronization mechanism. PALSGD allows the use of longer\nsynchronization intervals compared to standard Local SGD. Despite the reduced\ncommunication frequency, the pseudo-synchronization approach ensures that model\nconsistency is maintained, leading to performance results comparable to those\nachieved with more frequent synchronization. Furthermore, we provide a\ntheoretical analysis of PALSGD, establishing its convergence and deriving its\nconvergence rate. This analysis offers insights into the algorithm's behavior\nand performance guarantees. We evaluated PALSGD on image classification and\nlanguage modeling tasks. Our results show that PALSGD achieves better\nperformance in less time compared to existing methods like Distributed Data\nParallel (DDP), and DiLoCo. Notably, PALSGD trains 18.4% faster than DDP on\nImageNet-1K with ResNet-50, 24.4% faster than DDP on TinyStories with\nGPT-Neo125M, and 21.1% faster than DDP on TinyStories with GPT-Neo-8M."}
{"id": "2504.18349", "pdf": "https://arxiv.org/pdf/2504.18349", "abs": "https://arxiv.org/abs/2504.18349", "authors": ["Hongyu Zhu", "Sichu Liang", "Wenwen Wang", "Boheng Li", "Tongxin Yuan", "Fangqi Li", "ShiLin Wang", "Zhuosheng Zhang"], "title": "Revisiting Data Auditing in Large Vision-Language Models", "categories": ["cs.CV", "cs.CR"], "comment": null, "summary": "With the surge of large language models (LLMs), Large Vision-Language Models\n(VLMs)--which integrate vision encoders with LLMs for accurate visual\ngrounding--have shown great potential in tasks like generalist agents and\nrobotic control. However, VLMs are typically trained on massive web-scraped\nimages, raising concerns over copyright infringement and privacy violations,\nand making data auditing increasingly urgent. Membership inference (MI), which\ndetermines whether a sample was used in training, has emerged as a key auditing\ntechnique, with promising results on open-source VLMs like LLaVA (AUC > 80%).\nIn this work, we revisit these advances and uncover a critical issue: current\nMI benchmarks suffer from distribution shifts between member and non-member\nimages, introducing shortcut cues that inflate MI performance. We further\nanalyze the nature of these shifts and propose a principled metric based on\noptimal transport to quantify the distribution discrepancy. To evaluate MI in\nrealistic settings, we construct new benchmarks with i.i.d. member and\nnon-member images. Existing MI methods fail under these unbiased conditions,\nperforming only marginally better than chance. Further, we explore the\ntheoretical upper bound of MI by probing the Bayes Optimality within the VLM's\nembedding space and find the irreducible error rate remains high. Despite this\npessimistic outlook, we analyze why MI for VLMs is particularly challenging and\nidentify three practical scenarios--fine-tuning, access to ground-truth texts,\nand set-based inference--where auditing becomes feasible. Our study presents a\nsystematic view of the limits and opportunities of MI for VLMs, providing\nguidance for future efforts in trustworthy data auditing."}
{"id": "2503.10894", "pdf": "https://arxiv.org/pdf/2503.10894", "abs": "https://arxiv.org/abs/2503.10894", "authors": ["Jiuding Sun", "Jing Huang", "Sidharth Baskaran", "Karel D'Oosterlinck", "Christopher Potts", "Michael Sklar", "Atticus Geiger"], "title": "HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ICLR 2025", "summary": "Mechanistic interpretability has made great strides in identifying neural\nnetwork features (e.g., directions in hidden activation space) that mediate\nconcepts(e.g., the birth year of a person) and enable predictable manipulation.\nDistributed alignment search (DAS) leverages supervision from counterfactual\ndata to learn concept features within hidden states, but DAS assumes we can\nafford to conduct a brute force search over potential feature locations. To\naddress this, we present HyperDAS, a transformer-based hypernetwork\narchitecture that (1) automatically locates the token-positions of the residual\nstream that a concept is realized in and (2) constructs features of those\nresidual stream vectors for the concept. In experiments with Llama3-8B,\nHyperDAS achieves state-of-the-art performance on the RAVEL benchmark for\ndisentangling concepts in hidden states. In addition, we review the design\ndecisions we made to mitigate the concern that HyperDAS (like all powerful\ninterpretabilty methods) might inject new information into the target model\nrather than faithfully interpreting it."}
{"id": "2504.18497", "pdf": "https://arxiv.org/pdf/2504.18497", "abs": "https://arxiv.org/abs/2504.18497", "authors": ["Yifeng Mao", "Bozhidar Stevanoski", "Yves-Alexandre de Montjoye"], "title": "DeSIA: Attribute Inference Attacks Against Limited Fixed Aggregate Statistics", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Empirical inference attacks are a popular approach for evaluating the privacy\nrisk of data release mechanisms in practice. While an active attack literature\nexists to evaluate machine learning models or synthetic data release, we\ncurrently lack comparable methods for fixed aggregate statistics, in particular\nwhen only a limited number of statistics are released. We here propose an\ninference attack framework against fixed aggregate statistics and an attribute\ninference attack called DeSIA. We instantiate DeSIA against the U.S. Census\nPPMF dataset and show it to strongly outperform reconstruction-based attacks.\nIn particular, we show DeSIA to be highly effective at identifying vulnerable\nusers, achieving a true positive rate of 0.14 at a false positive rate of\n$10^{-3}$. We then show DeSIA to perform well against users whose attributes\ncannot be verified and when varying the number of aggregate statistics and\nlevel of noise addition. We also perform an extensive ablation study of DeSIA\nand show how DeSIA can be successfully adapted to the membership inference\ntask. Overall, our results show that aggregation alone is not sufficient to\nprotect privacy, even when a relatively small number of aggregates are being\nreleased, and emphasize the need for formal privacy mechanisms and testing\nbefore aggregate statistics are released."}
{"id": "2504.18506", "pdf": "https://arxiv.org/pdf/2504.18506", "abs": "https://arxiv.org/abs/2504.18506", "authors": ["Sanjeev Raja", "Martin ≈†√≠pka", "Michael Psenka", "Tobias Kreiman", "Michal Pavelka", "Aditi S. Krishnapriyan"], "title": "Action-Minimization Meets Generative Modeling: Efficient Transition Path Sampling with the Onsager-Machlup Functional", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.chem-ph", "q-bio.BM"], "comment": null, "summary": "Transition path sampling (TPS), which involves finding probable paths\nconnecting two points on an energy landscape, remains a challenge due to the\ncomplexity of real-world atomistic systems. Current machine learning approaches\nuse expensive, task-specific, and data-free training procedures, limiting their\nability to benefit from recent advances in atomistic machine learning, such as\nhigh-quality datasets and large-scale pre-trained models. In this work, we\naddress TPS by interpreting candidate paths as trajectories sampled from\nstochastic dynamics induced by the learned score function of pre-trained\ngenerative models, specifically denoising diffusion and flow matching. Under\nthese dynamics, finding high-likelihood transition paths becomes equivalent to\nminimizing the Onsager-Machlup (OM) action functional. This enables us to\nrepurpose pre-trained generative models for TPS in a zero-shot manner, in\ncontrast with bespoke, task-specific TPS models trained in previous work. We\ndemonstrate our approach on varied molecular systems, obtaining diverse,\nphysically realistic transition pathways and generalizing beyond the\npre-trained model's original training dataset. Our method can be easily\nincorporated into new generative models, making it practically relevant as\nmodels continue to scale and improve with increased data availability."}
{"id": "2504.18355", "pdf": "https://arxiv.org/pdf/2504.18355", "abs": "https://arxiv.org/abs/2504.18355", "authors": ["Maximilian Xiling Li", "Korbinian Rudolf", "Nils Blank", "Rudolf Lioutikov"], "title": "Interpretable Affordance Detection on 3D Point Clouds with Probabilistic Prototypes", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Robotic agents need to understand how to interact with objects in their\nenvironment, both autonomously and during human-robot interactions. Affordance\ndetection on 3D point clouds, which identifies object regions that allow\nspecific interactions, has traditionally relied on deep learning models like\nPointNet++, DGCNN, or PointTransformerV3. However, these models operate as\nblack boxes, offering no insight into their decision-making processes.\nPrototypical Learning methods, such as ProtoPNet, provide an interpretable\nalternative to black-box models by employing a \"this looks like that\"\ncase-based reasoning approach. However, they have been primarily applied to\nimage-based tasks. In this work, we apply prototypical learning to models for\naffordance detection on 3D point clouds. Experiments on the 3D-AffordanceNet\nbenchmark dataset show that prototypical models achieve competitive performance\nwith state-of-the-art black-box models and offer inherent interpretability.\nThis makes prototypical models a promising candidate for human-robot\ninteraction scenarios that require increased trust and safety."}
{"id": "2504.01840", "pdf": "https://arxiv.org/pdf/2504.01840", "abs": "https://arxiv.org/abs/2504.01840", "authors": ["Minhu Park", "Hongseok Oh", "Eunkyung Choi", "Wonseok Hwang"], "title": "LRAGE: Legal Retrieval Augmented Generation Evaluation Tool", "categories": ["cs.CL"], "comment": "12 pages", "summary": "Recently, building retrieval-augmented generation (RAG) systems to enhance\nthe capability of large language models (LLMs) has become a common practice.\nEspecially in the legal domain, previous judicial decisions play a significant\nrole under the doctrine of stare decisis which emphasizes the importance of\nmaking decisions based on (retrieved) prior documents. However, the overall\nperformance of RAG system depends on many components: (1) retrieval corpora,\n(2) retrieval algorithms, (3) rerankers, (4) LLM backbones, and (5) evaluation\nmetrics. Here we propose LRAGE, an open-source tool for holistic evaluation of\nRAG systems focusing on the legal domain. LRAGE provides GUI and CLI interfaces\nto facilitate seamless experiments and investigate how changes in the\naforementioned five components affect the overall accuracy. We validated LRAGE\nusing multilingual legal benches including Korean (KBL), English (LegalBench),\nand Chinese (LawBench) by demonstrating how the overall accuracy changes when\nvarying the five components mentioned above. The source code is available at\nhttps://github.com/hoorangyee/LRAGE."}
{"id": "2504.18538", "pdf": "https://arxiv.org/pdf/2504.18538", "abs": "https://arxiv.org/abs/2504.18538", "authors": ["Yixiao Wang"], "title": "Generalization Capability for Imitation Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Imitation learning holds the promise of equipping robots with versatile\nskills by learning from expert demonstrations. However, policies trained on\nfinite datasets often struggle to generalize beyond the training distribution.\nIn this work, we present a unified perspective on the generalization capability\nof imitation learning, grounded in both information theorey and data\ndistribution property. We first show that the generalization gap can be upper\nbounded by (i) the conditional information bottleneck on intermediate\nrepresentations and (ii) the mutual information between the model parameters\nand the training dataset. This characterization provides theoretical guidance\nfor designing effective training strategies in imitation learning, particularly\nin determining whether to freeze, fine-tune, or train large pretrained encoders\n(e.g., vision-language models or vision foundation models) from scratch to\nachieve better generalization. Furthermore, we demonstrate that high\nconditional entropy from input to output induces a flatter likelihood\nlandscape, thereby reducing the upper bound on the generalization gap. In\naddition, it shortens the stochastic gradient descent (SGD) escape time from\nsharp local minima, which may increase the likelihood of reaching global optima\nunder fixed optimization budgets. These insights explain why imitation learning\noften exhibits limited generalization and underscore the importance of not only\nscaling the diversity of input data but also enriching the variability of\noutput labels conditioned on the same input."}
{"id": "2504.18519", "pdf": "https://arxiv.org/pdf/2504.18519", "abs": "https://arxiv.org/abs/2504.18519", "authors": ["Han Zhang", "Hao Zhou", "Medhat Elsayed", "Majid Bavand", "Raimundas Gaigalas", "Yigit Ozcan", "Melike Erol-Kantarci"], "title": "Intelligent Attacks and Defense Methods in Federated Learning-enabled Energy-Efficient Wireless Networks", "categories": ["cs.LG"], "comment": null, "summary": "Federated learning (FL) is a promising technique for learning-based functions\nin wireless networks, thanks to its distributed implementation capability. On\nthe other hand, distributed learning may increase the risk of exposure to\nmalicious attacks where attacks on a local model may spread to other models by\nparameter exchange. Meanwhile, such attacks can be hard to detect due to the\ndynamic wireless environment, especially considering local models can be\nheterogeneous with non-independent and identically distributed (non-IID) data.\nTherefore, it is critical to evaluate the effect of malicious attacks and\ndevelop advanced defense techniques for FL-enabled wireless networks. In this\nwork, we introduce a federated deep reinforcement learning-based cell sleep\ncontrol scenario that enhances the energy efficiency of the network. We propose\nmultiple intelligent attacks targeting the learning-based approach and we\npropose defense methods to mitigate such attacks. In particular, we have\ndesigned two attack models, generative adversarial network (GAN)-enhanced model\npoisoning attack and regularization-based model poisoning attack. As a\ncounteraction, we have proposed two defense schemes, autoencoder-based defense,\nand knowledge distillation (KD)-enabled defense. The autoencoder-based defense\nmethod leverages an autoencoder to identify the malicious participants and only\naggregate the parameters of benign local models during the global aggregation,\nwhile KD-based defense protects the model from attacks by controlling the\nknowledge transferred between the global model and local models."}
{"id": "2504.18391", "pdf": "https://arxiv.org/pdf/2504.18391", "abs": "https://arxiv.org/abs/2504.18391", "authors": ["Tiankai Hang", "Jianmin Bao", "Fangyun Wei", "Dong Chen"], "title": "Fast Autoregressive Models for Continuous Latent Generation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Autoregressive models have demonstrated remarkable success in sequential data\ngeneration, particularly in NLP, but their extension to continuous-domain image\ngeneration presents significant challenges. Recent work, the masked\nautoregressive model (MAR), bypasses quantization by modeling per-token\ndistributions in continuous spaces using a diffusion head but suffers from slow\ninference due to the high computational cost of the iterative denoising\nprocess. To address this, we propose the Fast AutoRegressive model (FAR), a\nnovel framework that replaces MAR's diffusion head with a lightweight shortcut\nhead, enabling efficient few-step sampling while preserving autoregressive\nprinciples. Additionally, FAR seamlessly integrates with causal Transformers,\nextending them from discrete to continuous token generation without requiring\narchitectural modifications. Experiments demonstrate that FAR achieves\n$2.3\\times$ faster inference than MAR while maintaining competitive FID and IS\nscores. This work establishes the first efficient autoregressive paradigm for\nhigh-fidelity continuous-space image generation, bridging the critical gap\nbetween quality and scalability in visual autoregressive modeling."}
{"id": "2504.02810", "pdf": "https://arxiv.org/pdf/2504.02810", "abs": "https://arxiv.org/abs/2504.02810", "authors": ["Haowei Lin", "Xiangyu Wang", "Ruilin Yan", "Baizhou Huang", "Haotian Ye", "Jianhua Zhu", "Zihao Wang", "James Zou", "Jianzhu Ma", "Yitao Liang"], "title": "Generative Evaluation of Complex Reasoning in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "With powerful large language models (LLMs) demonstrating superhuman reasoning\ncapabilities, a critical question arises: Do LLMs genuinely reason, or do they\nmerely recall answers from their extensive, web-scraped training datasets?\nPublicly released benchmarks inevitably become contaminated once incorporated\ninto subsequent LLM training sets, undermining their reliability as faithful\nassessments. To address this, we introduce KUMO, a generative evaluation\nframework designed specifically for assessing reasoning in LLMs. KUMO\nsynergistically combines LLMs with symbolic engines to dynamically produce\ndiverse, multi-turn reasoning tasks that are partially observable and\nadjustable in difficulty. Through an automated pipeline, KUMO continuously\ngenerates novel tasks across open-ended domains, compelling models to\ndemonstrate genuine generalization rather than memorization. We evaluated 23\nstate-of-the-art LLMs on 5,000 tasks across 100 domains created by KUMO,\nbenchmarking their reasoning abilities against university students. Our\nfindings reveal that many LLMs have outperformed university-level performance\non easy reasoning tasks, and reasoning-scaled LLMs reach university-level\nperformance on complex reasoning challenges. Moreover, LLM performance on KUMO\ntasks correlates strongly with results on newly released real-world reasoning\nbenchmarks, underscoring KUMO's value as a robust, enduring assessment tool for\ngenuine LLM reasoning capabilities."}
{"id": "2406.00415", "pdf": "https://arxiv.org/pdf/2406.00415", "abs": "https://arxiv.org/abs/2406.00415", "authors": ["Xuan Wu", "Di Wang", "Lijie Wen", "Yubin Xiao", "Chunguo Wu", "Yuesong Wu", "Chaoyu Yu", "Douglas L. Maskell", "You Zhou"], "title": "Neural Combinatorial Optimization Algorithms for Solving Vehicle Routing Problems: A Comprehensive Survey with Perspectives", "categories": ["cs.AI"], "comment": "submitted to TNNLS", "summary": "Although several surveys on Neural Combinatorial Optimization (NCO) solvers\nspecifically designed to solve Vehicle Routing Problems (VRPs) have been\nconducted, they did not cover the state-of-the-art (SOTA) NCO solvers emerged\nrecently. More importantly, to establish a comprehensive and up-to-date\ntaxonomy of NCO solvers, we systematically review relevant publications and\npreprints, categorizing them into four distinct types, namely Learning to\nConstruct, Learning to Improve, Learning to Predict-Once, and Learning to\nPredict-Multiplicity solvers. Subsequently, we present the inadequacies of the\nSOTA solvers, including poor generalization, incapability to solve large-scale\nVRPs, inability to address most types of VRP variants simultaneously, and\ndifficulty in comparing these NCO solvers with the conventional Operations\nResearch algorithms. Simultaneously, we discuss on-going efforts, identify open\ninadequacies, as well as propose promising and viable directions to overcome\nthese inadequacies. Notably, existing efforts focus on only one or two of these\ninadequacies, with none attempting to address all of them concurrently. In\naddition, we compare the performance of representative NCO solvers from the\nReinforcement, Supervised, and Unsupervised Learning paradigms across VRPs of\nvarying scales. Finally, following the proposed taxonomy, we provide an\naccompanying web page as a live repository for NCO solvers. Through this survey\nand the live repository, we aim to foster further advancements in the NCO\ncommunity."}
{"id": "2504.17794", "pdf": "https://arxiv.org/pdf/2504.17794", "abs": "https://arxiv.org/abs/2504.17794", "authors": ["Dhadkan Shrestha", "Lincoln Bhattarai"], "title": "Near-Driven Autonomous Rover Navigation in Complex Environments: Extensions to Urban Search-and-Rescue and Industrial Inspection", "categories": ["cs.NE", "cs.LG", "cs.RO"], "comment": null, "summary": "This paper explores the use of an extended neuroevolutionary approach, based\non NeuroEvolution of Augmenting Topologies (NEAT), for autonomous robots in\ndynamic environments associated with hazardous tasks like firefighting, urban\nsearch-and-rescue (USAR), and industrial inspections. Building on previous\nresearch, it expands the simulation environment to larger and more complex\nsettings, demonstrating NEAT's adaptability across different applications. By\nintegrating recent advancements in NEAT and reinforcement learning, the study\nuses modern simulation frameworks for realism and hybrid algorithms for\noptimization. Experimental results show that NEAT-evolved controllers achieve\nsuccess rates comparable to state-of-the-art deep reinforcement learning\nmethods, with superior structural adaptability. The agents reached ~80% success\nin outdoor tests, surpassing baseline models. The paper also highlights the\nbenefits of transfer learning among tasks and evaluates the effectiveness of\nNEAT in complex 3D navigation. Contributions include evaluating NEAT for\ndiverse autonomous applications and discussing real-world deployment\nconsiderations, emphasizing the approach's potential as an alternative or\ncomplement to deep reinforcement learning in autonomous navigation tasks."}
{"id": "2504.18397", "pdf": "https://arxiv.org/pdf/2504.18397", "abs": "https://arxiv.org/abs/2504.18397", "authors": ["Kesen Zhao", "Beier Zhu", "Qianru Sun", "Hanwang Zhang"], "title": "Unsupervised Visual Chain-of-Thought Reasoning via Preference Optimization", "categories": ["cs.CV"], "comment": null, "summary": "Chain-of-thought (CoT) reasoning greatly improves the interpretability and\nproblem-solving abilities of multimodal large language models (MLLMs). However,\nexisting approaches are focused on text CoT, limiting their ability to leverage\nvisual cues. Visual CoT remains underexplored, and the only work is based on\nsupervised fine-tuning (SFT) that relies on extensive labeled bounding-box data\nand is hard to generalize to unseen cases. In this paper, we introduce\nUnsupervised Visual CoT (UV-CoT), a novel framework for image-level CoT\nreasoning via preference optimization. UV-CoT performs preference comparisons\nbetween model-generated bounding boxes (one is preferred and the other is\ndis-preferred), eliminating the need for bounding-box annotations. We get such\npreference data by introducing an automatic data generation pipeline. Given an\nimage, our target MLLM (e.g., LLaVA-1.5-7B) generates seed bounding boxes using\na template prompt and then answers the question using each bounded region as\ninput. An evaluator MLLM (e.g., OmniLLM-12B) ranks the responses, and these\nrankings serve as supervision to train the target MLLM with UV-CoT by\nminimizing negative log-likelihood losses. By emulating human\nperception--identifying key regions and reasoning based on them--UV-CoT can\nimprove visual comprehension, particularly in spatial reasoning tasks where\ntextual descriptions alone fall short. Our experiments on six datasets\ndemonstrate the superiority of UV-CoT, compared to the state-of-the-art textual\nand visual CoT methods. Our zero-shot testing on four unseen datasets shows the\nstrong generalization of UV-CoT. The code is available in\nhttps://github.com/kesenzhao/UV-CoT."}
{"id": "2504.08040", "pdf": "https://arxiv.org/pdf/2504.08040", "abs": "https://arxiv.org/abs/2504.08040", "authors": ["Akram Mustafa", "Usman Naseem", "Mostafa Rahimi Azghadi"], "title": "Can Reasoning LLMs Enhance Clinical Document Classification?", "categories": ["cs.CL", "cs.AI"], "comment": "27 pages", "summary": "Clinical document classification is essential for converting unstructured\nmedical texts into standardised ICD-10 diagnoses, yet it faces challenges due\nto complex medical language, privacy constraints, and limited annotated\ndatasets. Large Language Models (LLMs) offer promising improvements in accuracy\nand efficiency for this task. This study evaluates the performance and\nconsistency of eight LLMs; four reasoning (Qwen QWQ, Deepseek Reasoner, GPT o3\nMini, Gemini 2.0 Flash Thinking) and four non-reasoning (Llama 3.3, GPT 4o\nMini, Gemini 2.0 Flash, Deepseek Chat); in classifying clinical discharge\nsummaries using the MIMIC-IV dataset. Using cTAKES to structure clinical\nnarratives, models were assessed across three experimental runs, with majority\nvoting determining final predictions. Results showed that reasoning models\noutperformed non-reasoning models in accuracy (71% vs 68%) and F1 score (67% vs\n60%), with Gemini 2.0 Flash Thinking achieving the highest accuracy (75%) and\nF1 score (76%). However, non-reasoning models demonstrated greater stability\n(91% vs 84% consistency). Performance varied across ICD-10 codes, with\nreasoning models excelling in complex cases but struggling with abstract\ncategories. Findings indicate a trade-off between accuracy and consistency,\nsuggesting that a hybrid approach could optimise clinical coding. Future\nresearch should explore multi-label classification, domain-specific\nfine-tuning, and ensemble methods to enhance model reliability in real-world\napplications."}
{"id": "2408.12133", "pdf": "https://arxiv.org/pdf/2408.12133", "abs": "https://arxiv.org/abs/2408.12133", "authors": ["Yile Chen", "Weiming Huang", "Kaiqi Zhao", "Yue Jiang", "Gao Cong"], "title": "Self-Supervised Representation Learning for Geospatial Objects: A Survey", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The proliferation of various data sources in urban and territorial\nenvironments has significantly facilitated the development of geospatial\nartificial intelligence (GeoAI) across a wide range of geospatial applications.\nHowever, geospatial data, which is inherently linked to geospatial objects,\noften exhibits data heterogeneity that necessitates specialized fusion and\nrepresentation strategies while simultaneously being inherently sparse in\nlabels for downstream tasks. Consequently, there is a growing demand for\ntechniques that can effectively leverage geospatial data without heavy reliance\non task-specific labels and model designs. This need aligns with the principles\nof self-supervised learning (SSL), which has garnered increasing attention for\nits ability to learn effective and generalizable representations directly from\ndata without extensive labeled supervision. This paper presents a comprehensive\nand up-to-date survey of SSL techniques specifically applied to or developed\nfor geospatial objects in three primary vector geometric types: Point,\nPolyline, and Polygon. We systematically categorize various SSL techniques into\npredictive and contrastive methods, and analyze their adaptation to different\ndata types for representation learning across various downstream tasks.\nFurthermore, we examine the emerging trends in SSL for geospatial objects,\nparticularly the gradual advancements towards geospatial foundation models.\nFinally, we discuss key challenges in current research and outline promising\ndirections for future investigation. By offering a structured analysis of\nexisting studies, this paper aims to inspire continued progress in integrating\nSSL with geospatial objects, and the development of geospatial foundation\nmodels in a longer term."}
{"id": "2504.17811", "pdf": "https://arxiv.org/pdf/2504.17811", "abs": "https://arxiv.org/abs/2504.17811", "authors": ["Anirudhan Badrinath", "Alex Yang", "Kousik Rajesh", "Prabhat Agarwal", "Jaewon Yang", "Haoyu Chen", "Jiajing Xu", "Charles Rosenberg"], "title": "OmniSage: Large Scale, Multi-Entity Heterogeneous Graph Representation Learning", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Representation learning, a task of learning latent vectors to represent\nentities, is a key task in improving search and recommender systems in web\napplications. Various representation learning methods have been developed,\nincluding graph-based approaches for relationships among entities,\nsequence-based methods for capturing the temporal evolution of user activities,\nand content-based models for leveraging text and visual content. However, the\ndevelopment of a unifying framework that integrates these diverse techniques to\nsupport multiple applications remains a significant challenge. This paper\npresents OmniSage, a large-scale representation framework that learns universal\nrepresentations for a variety of applications at Pinterest. OmniSage integrates\ngraph neural networks with content-based models and user sequence models by\nemploying multiple contrastive learning tasks to effectively process graph\ndata, user sequence data, and content signals. To support the training and\ninference of OmniSage, we developed an efficient infrastructure capable of\nsupporting Pinterest graphs with billions of nodes. The universal\nrepresentations generated by OmniSage have significantly enhanced user\nexperiences on Pinterest, leading to an approximate 2.5% increase in sitewide\nrepins (saves) across five applications. This paper highlights the impact of\nunifying representation learning methods, and we will open source the OmniSage\ncode by the time of publication."}
{"id": "2504.18424", "pdf": "https://arxiv.org/pdf/2504.18424", "abs": "https://arxiv.org/abs/2504.18424", "authors": ["Rui Li", "Biao Zhang", "Zhenyu Li", "Federico Tombari", "Peter Wonka"], "title": "LaRI: Layered Ray Intersections for Single-view 3D Geometric Reasoning", "categories": ["cs.CV"], "comment": "Project page: https://ruili3.github.io/lari", "summary": "We present layered ray intersections (LaRI), a new method for unseen geometry\nreasoning from a single image. Unlike conventional depth estimation that is\nlimited to the visible surface, LaRI models multiple surfaces intersected by\nthe camera rays using layered point maps. Benefiting from the compact and\nlayered representation, LaRI enables complete, efficient, and view-aligned\ngeometric reasoning to unify object- and scene-level tasks. We further propose\nto predict the ray stopping index, which identifies valid intersecting pixels\nand layers from LaRI's output. We build a complete training data generation\npipeline for synthetic and real-world data, including 3D objects and scenes,\nwith necessary data cleaning steps and coordination between rendering engines.\nAs a generic method, LaRI's performance is validated in two scenarios: It\nyields comparable object-level results to the recent large generative model\nusing 4% of its training data and 17% of its parameters. Meanwhile, it achieves\nscene-level occluded geometry reasoning in only one feed-forward."}
{"id": "2504.12285", "pdf": "https://arxiv.org/pdf/2504.12285", "abs": "https://arxiv.org/abs/2504.12285", "authors": ["Shuming Ma", "Hongyu Wang", "Shaohan Huang", "Xingxing Zhang", "Ying Hu", "Ting Song", "Yan Xia", "Furu Wei"], "title": "BitNet b1.58 2B4T Technical Report", "categories": ["cs.CL", "cs.LG"], "comment": "Work in progress", "summary": "We introduce BitNet b1.58 2B4T, the first open-source, native 1-bit Large\nLanguage Model (LLM) at the 2-billion parameter scale. Trained on a corpus of 4\ntrillion tokens, the model has been rigorously evaluated across benchmarks\ncovering language understanding, mathematical reasoning, coding proficiency,\nand conversational ability. Our results demonstrate that BitNet b1.58 2B4T\nachieves performance on par with leading open-weight, full-precision LLMs of\nsimilar size, while offering significant advantages in computational\nefficiency, including substantially reduced memory footprint, energy\nconsumption, and decoding latency. To facilitate further research and adoption,\nthe model weights are released via Hugging Face along with open-source\ninference implementations for both GPU and CPU architectures."}
{"id": "2410.12881", "pdf": "https://arxiv.org/pdf/2410.12881", "abs": "https://arxiv.org/abs/2410.12881", "authors": ["Syeda Nahida Akter", "Shrimai Prabhumoye", "John Kamalu", "Sanjeev Satheesh", "Eric Nyberg", "Mostofa Patwary", "Mohammad Shoeybi", "Bryan Catanzaro"], "title": "MIND: Math Informed syNthetic Dialogues for Pretraining LLMs", "categories": ["cs.AI", "cs.CL"], "comment": "31 pages, 5 figures, 14 tables", "summary": "The utility of synthetic data to enhance pretraining data quality and hence\nto improve downstream task accuracy has been widely explored in recent large\nlanguage models (LLMs). Yet, these approaches fall inadequate in complex,\nmulti-hop and mathematical reasoning tasks as the synthetic data typically\nfails to add complementary knowledge to the existing raw corpus. In this work,\nwe propose a novel large-scale and diverse Math Informed syNthetic Dialogue\n(MIND) generation method that improves the mathematical reasoning ability of\nLLMs. Specifically, using MIND, we generate synthetic conversations based on\nOpenWebMath (OWM), resulting in a new math corpus, MIND-OWM. Our experiments\nwith different conversational settings reveal that incorporating knowledge gaps\nbetween dialog participants is essential for generating high-quality math data.\nWe further identify an effective way to format and integrate synthetic and raw\ndata during pretraining to maximize the gain in mathematical reasoning,\nemphasizing the need to restructure raw data rather than use it as-is. Compared\nto pretraining just on raw data, a model pretrained on MIND-OWM shows\nsignificant boost in mathematical reasoning (GSM8K: +13.42%, MATH: +2.30%),\nincluding superior performance in specialized knowledge (MMLU: +4.55%,\nMMLU-STEM: +4.28%) and general purpose reasoning tasks (GENERAL REASONING:\n+2.51%)."}
{"id": "2504.17836", "pdf": "https://arxiv.org/pdf/2504.17836", "abs": "https://arxiv.org/abs/2504.17836", "authors": ["Eviatar Bach", "Ricardo Baptista", "Edoardo Calvello", "Bohan Chen", "Andrew Stuart"], "title": "Learning Enhanced Ensemble Filters", "categories": ["stat.ML", "cs.LG", "cs.SY", "eess.SY", "physics.comp-ph"], "comment": "Preprint submitted to Journal of Computational Physics", "summary": "The filtering distribution in hidden Markov models evolves according to the\nlaw of a mean-field model in state--observation space. The ensemble Kalman\nfilter (EnKF) approximates this mean-field model with an ensemble of\ninteracting particles, employing a Gaussian ansatz for the joint distribution\nof the state and observation at each observation time. These methods are\nrobust, but the Gaussian ansatz limits accuracy. This shortcoming is addressed\nby approximating the mean-field evolution using a novel form of neural operator\ntaking probability distributions as input: a Measure Neural Mapping (MNM). A\nMNM is used to design a novel approach to filtering, the MNM-enhanced ensemble\nfilter (MNMEF), which is defined in both the mean-fieldlimit and for\ninteracting ensemble particle approximations. The ensemble approach uses\nempirical measures as input to the MNM and is implemented using the set\ntransformer, which is invariant to ensemble permutation and allows for\ndifferent ensemble sizes. The derivation of methods from a mean-field\nformulation allows a single parameterization of the algorithm to be deployed at\ndifferent ensemble sizes. In practice fine-tuning of a small number of\nparameters, for specific ensemble sizes, further enhances the accuracy of the\nscheme. The promise of the approach is demonstrated by its superior\nroot-mean-square-error performance relative to leading methods in filtering the\nLorenz 96 and Kuramoto-Sivashinsky models."}
{"id": "2504.18448", "pdf": "https://arxiv.org/pdf/2504.18448", "abs": "https://arxiv.org/abs/2504.18448", "authors": ["Haotian Dong", "Xin Wang", "Di Lin", "Yipeng Wu", "Qin Chen", "Ruonan Liu", "Kairui Yang", "Ping Li", "Qing Guo"], "title": "NoiseController: Towards Consistent Multi-view Video Generation via Noise Decomposition and Collaboration", "categories": ["cs.CV"], "comment": null, "summary": "High-quality video generation is crucial for many fields, including the film\nindustry and autonomous driving. However, generating videos with spatiotemporal\nconsistencies remains challenging. Current methods typically utilize attention\nmechanisms or modify noise to achieve consistent videos, neglecting global\nspatiotemporal information that could help ensure spatial and temporal\nconsistency during video generation. In this paper, we propose the\nNoiseController, consisting of Multi-Level Noise Decomposition, Multi-Frame\nNoise Collaboration, and Joint Denoising, to enhance spatiotemporal\nconsistencies in video generation. In multi-level noise decomposition, we first\ndecompose initial noises into scene-level foreground/background noises,\ncapturing distinct motion properties to model multi-view foreground/background\nvariations. Furthermore, each scene-level noise is further decomposed into\nindividual-level shared and residual components. The shared noise preserves\nconsistency, while the residual component maintains diversity. In multi-frame\nnoise collaboration, we introduce an inter-view spatiotemporal collaboration\nmatrix and an intra-view impact collaboration matrix , which captures mutual\ncross-view effects and historical cross-frame impacts to enhance video quality.\nThe joint denoising contains two parallel denoising U-Nets to remove each\nscene-level noise, mutually enhancing video generation. We evaluate our\nNoiseController on public datasets focusing on video generation and downstream\ntasks, demonstrating its state-of-the-art performance."}
{"id": "2504.14657", "pdf": "https://arxiv.org/pdf/2504.14657", "abs": "https://arxiv.org/abs/2504.14657", "authors": ["Yihan Lin", "Zhirong Bella Yu", "Simon Lee"], "title": "A Case Study Exploring the Current Landscape of Synthetic Medical Record Generation with Commercial LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at the Conference of Health, Inference, Learning (CHIL 2025)\n  in Berkeley, CA. To appear in PMLR later in 2025", "summary": "Synthetic Electronic Health Records (EHRs) offer a valuable opportunity to\ncreate privacy preserving and harmonized structured data, supporting numerous\napplications in healthcare. Key benefits of synthetic data include precise\ncontrol over the data schema, improved fairness and representation of patient\npopulations, and the ability to share datasets without concerns about\ncompromising real individuals privacy. Consequently, the AI community has\nincreasingly turned to Large Language Models (LLMs) to generate synthetic data\nacross various domains. However, a significant challenge in healthcare is\nensuring that synthetic health records reliably generalize across different\nhospitals, a long standing issue in the field. In this work, we evaluate the\ncurrent state of commercial LLMs for generating synthetic data and investigate\nmultiple aspects of the generation process to identify areas where these models\nexcel and where they fall short. Our main finding from this work is that while\nLLMs can reliably generate synthetic health records for smaller subsets of\nfeatures, they struggle to preserve realistic distributions and correlations as\nthe dimensionality of the data increases, ultimately limiting their ability to\ngeneralize across diverse hospital settings."}
{"id": "2502.17419", "pdf": "https://arxiv.org/pdf/2502.17419", "abs": "https://arxiv.org/abs/2502.17419", "authors": ["Zhong-Zhi Li", "Duzhen Zhang", "Ming-Liang Zhang", "Jiaxin Zhang", "Zengyan Liu", "Yuxuan Yao", "Haotian Xu", "Junhao Zheng", "Pei-Jie Wang", "Xiuyi Chen", "Yingying Zhang", "Fei Yin", "Jiahua Dong", "Zhiwei Li", "Bao-Long Bi", "Ling-Rui Mei", "Junfeng Fang", "Zhijiang Guo", "Le Song", "Cheng-Lin Liu"], "title": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "categories": ["cs.AI"], "comment": "Slow-thinking, Large Language Models, Human-like Reasoning, Decision\n  Making in AI, AGI", "summary": "Achieving human-level intelligence requires refining the transition from the\nfast, intuitive System 1 to the slower, more deliberate System 2 reasoning.\nWhile System 1 excels in quick, heuristic decisions, System 2 relies on logical\nreasoning for more accurate judgments and reduced biases. Foundational Large\nLanguage Models (LLMs) excel at fast decision-making but lack the depth for\ncomplex reasoning, as they have not yet fully embraced the step-by-step\nanalysis characteristic of true System 2 thinking. Recently, reasoning LLMs\nlike OpenAI's o1/o3 and DeepSeek's R1 have demonstrated expert-level\nperformance in fields such as mathematics and coding, closely mimicking the\ndeliberate reasoning of System 2 and showcasing human-like cognitive abilities.\nThis survey begins with a brief overview of the progress in foundational LLMs\nand the early development of System 2 technologies, exploring how their\ncombination has paved the way for reasoning LLMs. Next, we discuss how to\nconstruct reasoning LLMs, analyzing their features, the core methods enabling\nadvanced reasoning, and the evolution of various reasoning LLMs. Additionally,\nwe provide an overview of reasoning benchmarks, offering an in-depth comparison\nof the performance of representative reasoning LLMs. Finally, we explore\npromising directions for advancing reasoning LLMs and maintain a real-time\n\\href{https://github.com/zzli2022/Awesome-Slow-Reason-System}{GitHub\nRepository} to track the latest developments. We hope this survey will serve as\na valuable resource to inspire innovation and drive progress in this rapidly\nevolving field."}
{"id": "2504.17874", "pdf": "https://arxiv.org/pdf/2504.17874", "abs": "https://arxiv.org/abs/2504.17874", "authors": ["Zemin Zheng", "Xin Zhou", "Jinchi Lv"], "title": "SOFARI-R: High-Dimensional Manifold-Based Inference for Latent Responses", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": "90 pages, 2 figures", "summary": "Data reduction with uncertainty quantification plays a key role in various\nmulti-task learning applications, where large numbers of responses and features\nare present. To this end, a general framework of high-dimensional\nmanifold-based SOFAR inference (SOFARI) was introduced recently in Zheng, Zhou,\nFan and Lv (2024) for interpretable multi-task learning inference focusing on\nthe left factor vectors and singular values exploiting the latent singular\nvalue decomposition (SVD) structure. Yet, designing a valid inference procedure\non the latent right factor vectors is not straightforward from that of the left\nones and can be even more challenging due to asymmetry of left and right\nsingular vectors in the response matrix. To tackle these issues, in this paper\nwe suggest a new method of high-dimensional manifold-based SOFAR inference for\nlatent responses (SOFARI-R), where two variants of SOFARI-R are introduced. The\nfirst variant deals with strongly orthogonal factors by coupling left singular\nvectors with the design matrix and then appropriately rescaling them to\ngenerate new Stiefel manifolds. The second variant handles the more general\nweakly orthogonal factors by employing the hard-thresholded SOFARI estimates\nand delicately incorporating approximation errors into the distribution. Both\nvariants produce bias-corrected estimators for the latent right factor vectors\nthat enjoy asymptotically normal distributions with justified asymptotic\nvariance estimates. We demonstrate the effectiveness of the newly suggested\nmethod using extensive simulation studies and an economic application."}
{"id": "2504.18468", "pdf": "https://arxiv.org/pdf/2504.18468", "abs": "https://arxiv.org/abs/2504.18468", "authors": ["Georgios Kouros", "Minye Wu", "Tinne Tuytelaars"], "title": "RGS-DR: Reflective Gaussian Surfels with Deferred Rendering for Shiny Objects", "categories": ["cs.CV"], "comment": null, "summary": "We introduce RGS-DR, a novel inverse rendering method for reconstructing and\nrendering glossy and reflective objects with support for flexible relighting\nand scene editing. Unlike existing methods (e.g., NeRF and 3D Gaussian\nSplatting), which struggle with view-dependent effects, RGS-DR utilizes a 2D\nGaussian surfel representation to accurately estimate geometry and surface\nnormals, an essential property for high-quality inverse rendering. Our approach\nexplicitly models geometric and material properties through learnable\nprimitives rasterized into a deferred shading pipeline, effectively reducing\nrendering artifacts and preserving sharp reflections. By employing a\nmulti-level cube mipmap, RGS-DR accurately approximates environment lighting\nintegrals, facilitating high-quality reconstruction and relighting. A residual\npass with spherical-mipmap-based directional encoding further refines the\nappearance modeling. Experiments demonstrate that RGS-DR achieves high-quality\nreconstruction and rendering quality for shiny objects, often outperforming\nreconstruction-exclusive state-of-the-art methods incapable of relighting."}
{"id": "2504.15843", "pdf": "https://arxiv.org/pdf/2504.15843", "abs": "https://arxiv.org/abs/2504.15843", "authors": ["Junshu Pan", "Wei Shen", "Shulin Huang", "Qiji Zhou", "Yue Zhang"], "title": "Pre-DPO: Improving Data Utilization in Direct Preference Optimization Using a Guiding Reference Model", "categories": ["cs.CL"], "comment": null, "summary": "Direct Preference Optimization (DPO) simplifies reinforcement learning from\nhuman feedback (RLHF) for large language models (LLMs) by directly optimizing\nhuman preferences without an explicit reward model. We find that during DPO\ntraining, the reference model plays the role of a data weight adjuster.\nHowever, the common practice of initializing the policy and reference models\nidentically in DPO can lead to inefficient data utilization and impose a\nperformance ceiling. Meanwhile, the lack of a reference model in Simple\nPreference Optimization (SimPO) reduces training robustness and necessitates\nstricter conditions to prevent catastrophic forgetting. In this work, we\npropose Pre-DPO, a simple yet effective DPO-based training paradigm that\nenhances preference optimization performance by leveraging a guiding reference\nmodel. This reference model provides foresight into the optimal policy state\nachievable through the training preference data, serving as a guiding mechanism\nthat adaptively assigns higher weights to samples more suitable for the model\nand lower weights to those less suitable. Extensive experiments on AlpacaEval\n2.0 and Arena-Hard v0.1 benchmarks demonstrate that Pre-DPO consistently\nimproves the performance of both DPO and SimPO, without relying on external\nmodels or additional data."}
{"id": "2502.19546", "pdf": "https://arxiv.org/pdf/2502.19546", "abs": "https://arxiv.org/abs/2502.19546", "authors": ["Anton Alyakin", "Jaden Stryker", "Daniel Alexander Alber", "Karl L. Sangwon", "Jin Vivian Lee", "Brandon Duderstadt", "Akshay Save", "David Kurland", "Spencer Frome", "Shrutika Singh", "Jeff Zhang", "Eunice Yang", "Ki Yun Park", "Cordelia Orillac", "Aly A. Valliani", "Sean Neifert", "Albert Liu", "Aneek Patel", "Christopher Livia", "Darryl Lau", "Ilya Laufer", "Peter A. Rozman", "Eveline Teresa Hidalgo", "Howard Riina", "Rui Feng", "Todd Hollon", "Yindalon Aphinyanaphongs", "John G. Golfinos", "Laura Snyder", "Eric Leuthardt", "Douglas Kondziolka", "Eric Karl Oermann"], "title": "Repurposing the scientific literature with vision-language models", "categories": ["cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Leading vision-language models (VLMs) are trained on general Internet\ncontent, overlooking scientific journals' rich, domain-specific knowledge.\nTraining on specialty-specific literature could yield high-performance,\ntask-specific tools, enabling generative AI to match generalist models in\nspecialty publishing, educational, and clinical tasks. We created NeuroPubs, a\nmultimodal dataset of 23,000 Neurosurgery Publications articles (134M words,\n78K image-caption pairs). Using NeuroPubs, VLMs generated publication-ready\ngraphical abstracts (70% of 100 abstracts) and board-style questions\nindistinguishable from human-written ones (54% of 89,587 questions). We used\nthese questions to train CNS-Obsidian, a 34B-parameter VLM. In a blinded,\nrandomized controlled trial, our model demonstrated non-inferiority to then\nstate-of-the-art GPT-4o in neurosurgical differential diagnosis (clinical\nutility, 40.62% upvotes vs. 57.89%, p=0.1150; accuracy, 59.38% vs. 65.79%,\np=0.3797). Our pilot study demonstrates how training generative AI models on\nspecialty-specific journal content - without large-scale internet data -\nresults in high-performance academic and clinical tools, enabling\ndomain-tailored AI across diverse fields."}
{"id": "2504.17930", "pdf": "https://arxiv.org/pdf/2504.17930", "abs": "https://arxiv.org/abs/2504.17930", "authors": ["Abrar Fahim", "Shamik Dey", "Md. Nurul Absur", "Md Kamrul Siam", "Md. Tahmidul Huque", "Jafreen Jafor Godhuli"], "title": "Optimized Approaches to Malware Detection: A Study of Machine Learning and Deep Learning Techniques", "categories": ["cs.CR", "cs.LG"], "comment": "9 pages", "summary": "Digital systems find it challenging to keep up with cybersecurity threats.\nThe daily emergence of more than 560,000 new malware strains poses significant\nhazards to the digital ecosystem. The traditional malware detection methods\nfail to operate properly and yield high false positive rates with low accuracy\nof the protection system. This study explores the ways in which malware can be\ndetected using these machine learning (ML) and deep learning (DL) approaches to\naddress those shortcomings. This study also includes a systematic comparison of\nthe performance of some of the widely used ML models, such as random forest,\nmulti-layer perceptron (MLP), and deep neural network (DNN), for determining\nthe effectiveness of the domain of modern malware threat systems. We use a\nconsiderable-sized database from Kaggle, which has undergone optimized feature\nselection and preprocessing to improve model performance. Our finding suggests\nthat the DNN model outperformed the other traditional models with the highest\ntraining accuracy of 99.92% and an almost perfect AUC score. Furthermore, the\nfeature selection and preprocessing can help improve the capabilities of\ndetection. This research makes an important contribution by analyzing the\nperformance of the model on the performance metrics and providing insight into\nthe effectiveness of the advanced detection techniques to build more robust and\nmore reliable cybersecurity solutions against the growing malware threats."}
{"id": "2504.18490", "pdf": "https://arxiv.org/pdf/2504.18490", "abs": "https://arxiv.org/abs/2504.18490", "authors": ["Andrews Danyo", "Anthony Dontoh", "Armstrong Aboah"], "title": "An Improved ResNet50 Model for Predicting Pavement Condition Index (PCI) Directly from Pavement Images", "categories": ["cs.CV"], "comment": null, "summary": "Accurately predicting the Pavement Condition Index (PCI), a measure of\nroadway conditions, from pavement images is crucial for infrastructure\nmaintenance. This study proposes an enhanced version of the Residual Network\n(ResNet50) architecture, integrated with a Convolutional Block Attention Module\n(CBAM), to predict PCI directly from pavement images without additional\nannotations. By incorporating CBAM, the model autonomously prioritizes critical\nfeatures within the images, improving prediction accuracy. Compared to the\noriginal baseline ResNet50 and DenseNet161 architectures, the enhanced\nResNet50-CBAM model achieved a significantly lower mean absolute percentage\nerror (MAPE) of 58.16%, compared to the baseline models that achieved 70.76%\nand 65.48% respectively. These results highlight the potential of using\nattention mechanisms to refine feature extraction, ultimately enabling more\naccurate and efficient assessments of pavement conditions. This study\nemphasizes the importance of targeted feature refinement in advancing automated\npavement analysis through attention mechanisms."}
{"id": "2504.16005", "pdf": "https://arxiv.org/pdf/2504.16005", "abs": "https://arxiv.org/abs/2504.16005", "authors": ["Tom Zehle", "Moritz Schlager", "Timo Hei√ü", "Matthias Feurer"], "title": "CAPO: Cost-Aware Prompt Optimization", "categories": ["cs.CL", "cs.AI", "cs.NE", "stat.ML"], "comment": "Submitted to AutoML 2025", "summary": "Large language models (LLMs) have revolutionized natural language processing\nby solving a wide range of tasks simply guided by a prompt. Yet their\nperformance is highly sensitive to prompt formulation. While automated prompt\noptimization addresses this challenge by finding optimal prompts, current\nmethods require a substantial number of LLM calls and input tokens, making\nprompt optimization expensive. We introduce CAPO (Cost-Aware Prompt\nOptimization), an algorithm that enhances prompt optimization efficiency by\nintegrating AutoML techniques. CAPO is an evolutionary approach with LLMs as\noperators, incorporating racing to save evaluations and multi-objective\noptimization to balance performance with prompt length. It jointly optimizes\ninstructions and few-shot examples while leveraging task descriptions for\nimproved robustness. Our extensive experiments across diverse datasets and LLMs\ndemonstrate that CAPO outperforms state-of-the-art discrete prompt optimization\nmethods in 11/15 cases with improvements up to 21%p. Our algorithm achieves\nbetter performances already with smaller budgets, saves evaluations through\nracing, and decreases average prompt length via a length penalty, making it\nboth cost-efficient and cost-aware. Even without few-shot examples, CAPO\noutperforms its competitors and generally remains robust to initial prompts.\nCAPO represents an important step toward making prompt optimization more\npowerful and accessible by improving cost-efficiency."}
{"id": "2503.21419", "pdf": "https://arxiv.org/pdf/2503.21419", "abs": "https://arxiv.org/abs/2503.21419", "authors": ["Yupei Li", "Manuel Milling", "Bj√∂rn W. Schuller"], "title": "Neuroplasticity in Artificial Intelligence -- An Overview and Inspirations on Drop In & Out Learning", "categories": ["cs.AI"], "comment": null, "summary": "Artificial Intelligence (AI) has achieved new levels of performance and\nspread in public usage with the rise of deep neural networks (DNNs). Initially\ninspired by human neurons and their connections, NNs have become the foundation\nof AI models for many advanced architectures. However, some of the most\nintegral processes in the human brain, particularly neurogenesis and\nneuroplasticity in addition to the more spread neuroapoptosis have largely been\nignored in DNN architecture design. Instead, contemporary AI development\npredominantly focuses on constructing advanced frameworks, such as large\nlanguage models, which retain a static structure of neural connections during\ntraining and inference. In this light, we explore how neurogenesis,\nneuroapoptosis, and neuroplasticity can inspire future AI advances.\nSpecifically, we examine analogous activities in artificial NNs, introducing\nthe concepts of ``dropin'' for neurogenesis and revisiting ``dropout'' and\nstructural pruning for neuroapoptosis. We additionally suggest neuroplasticity\ncombining the two for future large NNs in ``life-long learning'' settings\nfollowing the biological inspiration. We conclude by advocating for greater\nresearch efforts in this interdisciplinary domain and identifying promising\ndirections for future exploration."}
{"id": "2504.17939", "pdf": "https://arxiv.org/pdf/2504.17939", "abs": "https://arxiv.org/abs/2504.17939", "authors": ["Josua Spisak", "Sergiu Tcaci Popescu", "Stefan Wermter", "Matej Hoffmann", "J. Kevin O'Regan"], "title": "A computational model of infant sensorimotor exploration in the mobile paradigm", "categories": ["q-bio.NC", "cs.LG", "92-10", "J.4"], "comment": "16 pages, 16 figures", "summary": "We present a computational model of the mechanisms that may determine\ninfants' behavior in the \"mobile paradigm\". This paradigm has been used in\ndevelopmental psychology to explore how infants learn the sensory effects of\ntheir actions. In this paradigm, a mobile (an articulated and movable object\nhanging above an infant's crib) is connected to one of the infant's limbs,\nprompting the infant to preferentially move that \"connected\" limb. This ability\nto detect a \"sensorimotor contingency\" is considered to be a foundational\ncognitive ability in development. To understand how infants learn sensorimotor\ncontingencies, we built a model that attempts to replicate infant behavior. Our\nmodel incorporates a neural network, action-outcome prediction, exploration,\nmotor noise, preferred activity level, and biologically-inspired motor control.\nWe find that simulations with our model replicate the classic findings in the\nliterature showing preferential movement of the connected limb. An interesting\nobservation is that the model sometimes exhibits a burst of movement after the\nmobile is disconnected, casting light on a similar occasional finding in\ninfants. In addition to these general findings, the simulations also replicate\ndata from two recent more detailed studies using a connection with the mobile\nthat was either gradual or all-or-none. A series of ablation studies further\nshows that the inclusion of mechanisms of action-outcome prediction,\nexploration, motor noise, and biologically-inspired motor control was essential\nfor the model to correctly replicate infant behavior. This suggests that these\ncomponents are also involved in infants' sensorimotor learning."}
{"id": "2504.18509", "pdf": "https://arxiv.org/pdf/2504.18509", "abs": "https://arxiv.org/abs/2504.18509", "authors": ["Shivam Duggal", "Yushi Hu", "Oscar Michel", "Aniruddha Kembhavi", "William T. Freeman", "Noah A. Smith", "Ranjay Krishna", "Antonio Torralba", "Ali Farhadi", "Wei-Chiu Ma"], "title": "Eval3D: Interpretable and Fine-grained Evaluation for 3D Generation", "categories": ["cs.CV"], "comment": "CVPR 2025. Project page and codes: https://eval3d.github.io/", "summary": "Despite the unprecedented progress in the field of 3D generation, current\nsystems still often fail to produce high-quality 3D assets that are visually\nappealing and geometrically and semantically consistent across multiple\nviewpoints. To effectively assess the quality of the generated 3D data, there\nis a need for a reliable 3D evaluation tool. Unfortunately, existing 3D\nevaluation metrics often overlook the geometric quality of generated assets or\nmerely rely on black-box multimodal large language models for coarse\nassessment. In this paper, we introduce Eval3D, a fine-grained, interpretable\nevaluation tool that can faithfully evaluate the quality of generated 3D assets\nbased on various distinct yet complementary criteria. Our key observation is\nthat many desired properties of 3D generation, such as semantic and geometric\nconsistency, can be effectively captured by measuring the consistency among\nvarious foundation models and tools. We thus leverage a diverse set of models\nand tools as probes to evaluate the inconsistency of generated 3D assets across\ndifferent aspects. Compared to prior work, Eval3D provides pixel-wise\nmeasurement, enables accurate 3D spatial feedback, and aligns more closely with\nhuman judgments. We comprehensively evaluate existing 3D generation models\nusing Eval3D and highlight the limitations and challenges of current models."}
{"id": "2504.17119", "pdf": "https://arxiv.org/pdf/2504.17119", "abs": "https://arxiv.org/abs/2504.17119", "authors": ["Muskan Garg", "Shaina Raza", "Shebuti Rayana", "Xingyi Liu", "Sunghwan Sohn"], "title": "The Rise of Small Language Models in Healthcare: A Comprehensive Survey", "categories": ["cs.CL", "cs.AI"], "comment": "35 pages, 7 tables, 5 figures", "summary": "Despite substantial progress in healthcare applications driven by large\nlanguage models (LLMs), growing concerns around data privacy, and limited\nresources; the small language models (SLMs) offer a scalable and clinically\nviable solution for efficient performance in resource-constrained environments\nfor next-generation healthcare informatics. Our comprehensive survey presents a\ntaxonomic framework to identify and categorize them for healthcare\nprofessionals and informaticians. The timeline of healthcare SLM contributions\nestablishes a foundational framework for analyzing models across three\ndimensions: NLP tasks, stakeholder roles, and the continuum of care. We present\na taxonomic framework to identify the architectural foundations for building\nmodels from scratch; adapting SLMs to clinical precision through prompting,\ninstruction fine-tuning, and reasoning; and accessibility and sustainability\nthrough compression techniques. Our primary objective is to offer a\ncomprehensive survey for healthcare professionals, introducing recent\ninnovations in model optimization and equipping them with curated resources to\nsupport future research and development in the field. Aiming to showcase the\ngroundbreaking advancements in SLMs for healthcare, we present a comprehensive\ncompilation of experimental results across widely studied NLP tasks in\nhealthcare to highlight the transformative potential of SLMs in healthcare. The\nupdated repository is available at Github"}
{"id": "2504.13146", "pdf": "https://arxiv.org/pdf/2504.13146", "abs": "https://arxiv.org/abs/2504.13146", "authors": ["Yash Savani", "Asher Trockman", "Zhili Feng", "Avi Schwarzschild", "Alexander Robey", "Marc Finzi", "J. Zico Kolter"], "title": "Antidistillation Sampling", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Frontier models that generate extended reasoning traces inadvertently produce\nrich token sequences that can facilitate model distillation. Recognizing this\nvulnerability, model owners may seek sampling strategies that limit the\neffectiveness of distillation without compromising model performance.\nAntidistillation sampling provides exactly this capability. By strategically\nmodifying a model's next-token probability distribution, antidistillation\nsampling poisons reasoning traces, rendering them significantly less effective\nfor distillation while preserving the model's practical utility. For further\ndetails, see https://antidistillation.com."}
{"id": "2504.17953", "pdf": "https://arxiv.org/pdf/2504.17953", "abs": "https://arxiv.org/abs/2504.17953", "authors": ["Ahod Alghuried", "Abdulaziz Alghamdi", "Ali Alkinoon", "Soohyeon Choi", "Manar Mohaisen", "David Mohaisen"], "title": "Fishing for Phishers: Learning-Based Phishing Detection in Ethereum Transactions", "categories": ["cs.CR", "cs.LG"], "comment": "23 pages, 6 tables, 5 figures", "summary": "Phishing detection on Ethereum has increasingly leveraged advanced machine\nlearning techniques to identify fraudulent transactions. However, limited\nattention has been given to understanding the effectiveness of feature\nselection strategies and the role of graph-based models in enhancing detection\naccuracy. In this paper, we systematically examine these issues by analyzing\nand contrasting explicit transactional features and implicit graph-based\nfeatures, both experimentally and analytically. We explore how different\nfeature sets impact the performance of phishing detection models, particularly\nin the context of Ethereum's transactional network. Additionally, we address\nkey challenges such as class imbalance and dataset composition and their\ninfluence on the robustness and precision of detection methods. Our findings\ndemonstrate the advantages and limitations of each feature type, while also\nproviding a clearer understanding of how feature affect model resilience and\ngeneralization in adversarial environments."}
{"id": "2504.18510", "pdf": "https://arxiv.org/pdf/2504.18510", "abs": "https://arxiv.org/abs/2504.18510", "authors": ["Patrick M√ºller", "Alexander Braun", "Margret Keuper"], "title": "Examining the Impact of Optical Aberrations to Image Classification and Object Detection Models", "categories": ["cs.CV"], "comment": "v1.0", "summary": "Deep neural networks (DNNs) have proven to be successful in various computer\nvision applications such that models even infer in safety-critical situations.\nTherefore, vision models have to behave in a robust way to disturbances such as\nnoise or blur. While seminal benchmarks exist to evaluate model robustness to\ndiverse corruptions, blur is often approximated in an overly simplistic way to\nmodel defocus, while ignoring the different blur kernel shapes that result from\noptical systems. To study model robustness against realistic optical blur\neffects, this paper proposes two datasets of blur corruptions, which we denote\nOpticsBench and LensCorruptions. OpticsBench examines primary aberrations such\nas coma, defocus, and astigmatism, i.e. aberrations that can be represented by\nvarying a single parameter of Zernike polynomials. To go beyond the principled\nbut synthetic setting of primary aberrations, LensCorruptions samples linear\ncombinations in the vector space spanned by Zernike polynomials, corresponding\nto 100 real lenses. Evaluations for image classification and object detection\non ImageNet and MSCOCO show that for a variety of different pre-trained models,\nthe performance on OpticsBench and LensCorruptions varies significantly,\nindicating the need to consider realistic image corruptions to evaluate a\nmodel's robustness against blur."}
{"id": "2504.17565", "pdf": "https://arxiv.org/pdf/2504.17565", "abs": "https://arxiv.org/abs/2504.17565", "authors": ["Xiaoyu Tian", "Sitong Zhao", "Haotian Wang", "Shuaiting Chen", "Yiping Peng", "Yunjie Ji", "Han Zhao", "Xiangang Li"], "title": "DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training", "categories": ["cs.CL"], "comment": null, "summary": "Although large language models (LLMs) have recently achieved remarkable\nperformance on various complex reasoning benchmarks, the academic community\nstill lacks an in-depth understanding of base model training processes and data\nquality. To address this, we construct a large-scale, difficulty-graded\nreasoning dataset containing approximately 3.34 million unique queries of\nvarying difficulty levels and about 40 million distilled responses generated by\nmultiple models over several passes. Leveraging pass rate and Coefficient of\nVariation (CV), we precisely select the most valuable training data to enhance\nreasoning capability. Notably, we observe a training pattern shift, indicating\nthat reasoning-focused training based on base models requires higher learning\nrates for effective training. Using this carefully selected data, we\nsignificantly improve the reasoning capabilities of the base model, achieving a\npass rate of 79.2\\% on the AIME2024 mathematical reasoning benchmark. This\nresult surpasses most current distilled models and closely approaches\nstate-of-the-art performance. We provide detailed descriptions of our data\nprocessing, difficulty assessment, and training methodology, and have publicly\nreleased all datasets and methods to promote rapid progress in open-source\nlong-reasoning LLMs. The dataset is available at:\nhttps://huggingface.co/datasets/a-m-team/AM-DeepSeek-Distilled-40M"}
{"id": "2504.14209", "pdf": "https://arxiv.org/pdf/2504.14209", "abs": "https://arxiv.org/abs/2504.14209", "authors": ["Xiangkai Ma", "Xiaobin Hong", "Wenzhong Li", "Sanglu Lu"], "title": "Pets: General Pattern Assisted Architecture For Time Series Analysis", "categories": ["cs.AI"], "comment": null, "summary": "Time series analysis has found widespread applications in areas such as\nweather forecasting, anomaly detection, and healthcare. However, real-world\nsequential data often exhibit a superimposed state of various fluctuation\npatterns, including hourly, daily, and monthly frequencies. Traditional\ndecomposition techniques struggle to effectively disentangle these multiple\nfluctuation patterns from the seasonal components, making time series analysis\nchallenging. Surpassing the existing multi-period decoupling paradigms, this\npaper introduces a novel perspective based on energy distribution within the\ntemporal-spectrum space. By adaptively quantifying observed sequences into\ncontinuous frequency band intervals, the proposed approach reconstructs\nfluctuation patterns across diverse periods without relying on domain-specific\nprior knowledge. Building upon this innovative strategy, we propose Pets, an\nenhanced architecture that is adaptable to arbitrary model structures. Pets\nintegrates a Fluctuation Pattern Assisted (FPA) module and a Context-Guided\nMixture of Predictors (MoP). The FPA module facilitates information fusion\namong diverse fluctuation patterns by capturing their dependencies and\nprogressively modeling these patterns as latent representations at each layer.\nMeanwhile, the MoP module leverages these compound pattern representations to\nguide and regulate the reconstruction of distinct fluctuations hierarchically.\nPets achieves state-of-the-art performance across various tasks, including\nforecasting, imputation, anomaly detection, and classification, while\ndemonstrating strong generalization and robustness."}
{"id": "2504.17954", "pdf": "https://arxiv.org/pdf/2504.17954", "abs": "https://arxiv.org/abs/2504.17954", "authors": ["Kaiyuan Tang", "Siyuan Yao", "Chaoli Wang"], "title": "iVR-GS: Inverse Volume Rendering for Explorable Visualization via Editable 3D Gaussian Splatting", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": "Accepted by IEEE Transactions on Visualization and Computer Graphics\n  (TVCG)", "summary": "In volume visualization, users can interactively explore the\nthree-dimensional data by specifying color and opacity mappings in the transfer\nfunction (TF) or adjusting lighting parameters, facilitating meaningful\ninterpretation of the underlying structure. However, rendering large-scale\nvolumes demands powerful GPUs and high-speed memory access for real-time\nperformance. While existing novel view synthesis (NVS) methods offer faster\nrendering speeds with lower hardware requirements, the visible parts of a\nreconstructed scene are fixed and constrained by preset TF settings,\nsignificantly limiting user exploration. This paper introduces inverse volume\nrendering via Gaussian splatting (iVR-GS), an innovative NVS method that\nreduces the rendering cost while enabling scene editing for interactive volume\nexploration. Specifically, we compose multiple iVR-GS models associated with\nbasic TFs covering disjoint visible parts to make the entire volumetric scene\nvisible. Each basic model contains a collection of 3D editable Gaussians, where\neach Gaussian is a 3D spatial point that supports real-time scene rendering and\nediting. We demonstrate the superior reconstruction quality and composability\nof iVR-GS against other NVS solutions (Plenoxels, CCNeRF, and base 3DGS) on\nvarious volume datasets. The code is available at\nhttps://github.com/TouKaienn/iVR-GS."}
{"id": "2504.18521", "pdf": "https://arxiv.org/pdf/2504.18521", "abs": "https://arxiv.org/abs/2504.18521", "authors": ["Shintaro Shiba", "Quan Kong", "Norimasa Kobori"], "title": "E-VLC: A Real-World Dataset for Event-based Visible Light Communication And Localization", "categories": ["cs.CV", "cs.RO", "eess.SP"], "comment": "10 pages, 9 figures, 5 tables, CVPRW on EventVision 2025", "summary": "Optical communication using modulated LEDs (e.g., visible light\ncommunication) is an emerging application for event cameras, thanks to their\nhigh spatio-temporal resolutions. Event cameras can be used simply to decode\nthe LED signals and also to localize the camera relative to the LED marker\npositions. However, there is no public dataset to benchmark the decoding and\nlocalization in various real-world settings. We present, to the best of our\nknowledge, the first public dataset that consists of an event camera, a frame\ncamera, and ground-truth poses that are precisely synchronized with hardware\ntriggers. It provides various camera motions with various sensitivities in\ndifferent scene brightness settings, both indoor and outdoor. Furthermore, we\npropose a novel method of localization that leverages the Contrast Maximization\nframework for motion estimation and compensation. The detailed analysis and\nexperimental results demonstrate the advantages of LED-based localization with\nevents over the conventional AR-marker--based one with frames, as well as the\nefficacy of the proposed method in localization. We hope that the proposed\ndataset serves as a future benchmark for both motion-related classical computer\nvision tasks and LED marker decoding tasks simultaneously, paving the way to\nbroadening applications of event cameras on mobile devices.\nhttps://woven-visionai.github.io/evlc-dataset"}
{"id": "2504.17671", "pdf": "https://arxiv.org/pdf/2504.17671", "abs": "https://arxiv.org/abs/2504.17671", "authors": ["Yuanchang Ye", "Weiyan Wen"], "title": "Data-Driven Calibration of Prediction Sets in Large Vision-Language Models Based on Inductive Conformal Prediction", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "This study addresses the critical challenge of hallucination mitigation in\nLarge Vision-Language Models (LVLMs) for Visual Question Answering (VQA) tasks\nthrough a Split Conformal Prediction (SCP) framework. While LVLMs excel in\nmulti-modal reasoning, their outputs often exhibit hallucinated content with\nhigh confidence, posing risks in safety-critical applications. We propose a\nmodel-agnostic uncertainty quantification method that integrates dynamic\nthreshold calibration and cross-modal consistency verification. By partitioning\ndata into calibration and test sets, the framework computes nonconformity\nscores to construct prediction sets with statistical guarantees under\nuser-defined risk levels ($\\alpha$). Key innovations include: (1) rigorous\ncontrol of \\textbf{marginal coverage} to ensure empirical error rates remain\nstrictly below $\\alpha$; (2) dynamic adjustment of prediction set sizes\ninversely with $\\alpha$, filtering low-confidence outputs; (3) elimination of\nprior distribution assumptions and retraining requirements. Evaluations on\nbenchmarks (ScienceQA, MMMU) with eight LVLMs demonstrate that SCP enforces\ntheoretical guarantees across all $\\alpha$ values. The framework achieves\nstable performance across varying calibration-to-test split ratios,\nunderscoring its robustness for real-world deployment in healthcare, autonomous\nsystems, and other safety-sensitive domains. This work bridges the gap between\ntheoretical reliability and practical applicability in multi-modal AI systems,\noffering a scalable solution for hallucination detection and uncertainty-aware\ndecision-making."}
{"id": "2504.14603", "pdf": "https://arxiv.org/pdf/2504.14603", "abs": "https://arxiv.org/abs/2504.14603", "authors": ["Chaoyun Zhang", "He Huang", "Chiming Ni", "Jian Mu", "Si Qin", "Shilin He", "Lu Wang", "Fangkai Yang", "Pu Zhao", "Chao Du", "Liqun Li", "Yu Kang", "Zhao Jiang", "Suzhen Zheng", "Rujia Wang", "Jiaxu Qian", "Minghua Ma", "Jian-Guang Lou", "Qingwei Lin", "Saravan Rajmohan", "Dongmei Zhang"], "title": "UFO2: The Desktop AgentOS", "categories": ["cs.AI", "cs.HC", "cs.OS"], "comment": "The source code of UFO2 is publicly available at\n  https://github.com/microsoft/UFO/, with comprehensive documentation provided\n  at https://microsoft.github.io/UFO/", "summary": "Recent Computer-Using Agents (CUAs), powered by multimodal large language\nmodels (LLMs), offer a promising direction for automating complex desktop\nworkflows through natural language. However, most existing CUAs remain\nconceptual prototypes, hindered by shallow OS integration, fragile\nscreenshot-based interaction, and disruptive execution.\n  We present UFO2, a multiagent AgentOS for Windows desktops that elevates CUAs\ninto practical, system-level automation. UFO2 features a centralized HostAgent\nfor task decomposition and coordination, alongside a collection of\napplication-specialized AppAgent equipped with native APIs, domain-specific\nknowledge, and a unified GUI--API action layer. This architecture enables\nrobust task execution while preserving modularity and extensibility. A hybrid\ncontrol detection pipeline fuses Windows UI Automation (UIA) with vision-based\nparsing to support diverse interface styles. Runtime efficiency is further\nenhanced through speculative multi-action planning, reducing per-step LLM\noverhead. Finally, a Picture-in-Picture (PiP) interface enables automation\nwithin an isolated virtual desktop, allowing agents and users to operate\nconcurrently without interference.\n  We evaluate UFO2 across over 20 real-world Windows applications,\ndemonstrating substantial improvements in robustness and execution accuracy\nover prior CUAs. Our results show that deep OS integration unlocks a scalable\npath toward reliable, user-aligned desktop automation."}
{"id": "2504.17959", "pdf": "https://arxiv.org/pdf/2504.17959", "abs": "https://arxiv.org/abs/2504.17959", "authors": ["Yinlong Dai", "Robert Ramirez Sanchez", "Ryan Jeronimus", "Shahabedin Sagheb", "Cara M. Nunez", "Heramb Nemlekar", "Dylan P. Losey"], "title": "CIVIL: Causal and Intuitive Visual Imitation Learning", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Today's robots learn new tasks by imitating human examples. However, this\nstandard approach to visual imitation learning is fundamentally limited: the\nrobot observes what the human does, but not why the human chooses those\nbehaviors. Without understanding the features that factor into the human's\ndecisions, robot learners often misinterpret the data and fail to perform the\ntask when the environment changes. We therefore propose a shift in perspective:\ninstead of asking human teachers just to show what actions the robot should\ntake, we also enable humans to indicate task-relevant features using markers\nand language prompts. Our proposed algorithm, CIVIL, leverages this augmented\ndata to filter the robot's visual observations and extract a feature\nrepresentation that causally informs human actions. CIVIL then applies these\ncausal features to train a transformer-based policy that emulates human\nbehaviors without being confused by visual distractors. Our simulations,\nreal-world experiments, and user study demonstrate that robots trained with\nCIVIL can learn from fewer human demonstrations and perform better than\nstate-of-the-art baselines, especially in previously unseen scenarios. See\nvideos at our project website: https://civil2025.github.io"}
{"id": "2504.18524", "pdf": "https://arxiv.org/pdf/2504.18524", "abs": "https://arxiv.org/abs/2504.18524", "authors": ["Fengjia Zhang", "Samrudhdhi B. Rangrej", "Tristan Aumentado-Armstrong", "Afsaneh Fazly", "Alex Levinshtein"], "title": "Augmenting Perceptual Super-Resolution via Image Quality Predictors", "categories": ["cs.CV"], "comment": null, "summary": "Super-resolution (SR), a classical inverse problem in computer vision, is\ninherently ill-posed, inducing a distribution of plausible solutions for every\ninput. However, the desired result is not simply the expectation of this\ndistribution, which is the blurry image obtained by minimizing pixelwise error,\nbut rather the sample with the highest image quality. A variety of techniques,\nfrom perceptual metrics to adversarial losses, are employed to this end. In\nthis work, we explore an alternative: utilizing powerful non-reference image\nquality assessment (NR-IQA) models in the SR context. We begin with a\ncomprehensive analysis of NR-IQA metrics on human-derived SR data, identifying\nboth the accuracy (human alignment) and complementarity of different metrics.\nThen, we explore two methods of applying NR-IQA models to SR learning: (i)\naltering data sampling, by building on an existing multi-ground-truth SR\nframework, and (ii) directly optimizing a differentiable quality score. Our\nresults demonstrate a more human-centric perception-distortion tradeoff,\nfocusing less on non-perceptual pixel-wise distortion, instead improving the\nbalance between perceptual fidelity and human-tuned NR-IQA measures."}
{"id": "2405.15638", "pdf": "https://arxiv.org/pdf/2405.15638", "abs": "https://arxiv.org/abs/2405.15638", "authors": ["Hongyu Wang", "Jiayu Xu", "Senwei Xie", "Ruiping Wang", "Jialin Li", "Zhaojie Xie", "Bin Zhang", "Chuyan Xiong", "Xilin Chen"], "title": "M4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models", "categories": ["cs.CV", "cs.CL"], "comment": "Work in progress", "summary": "Multilingual capability is an essential aspect for large multimodal models,\nsince they are usually deployed across various countries and languages.\nHowever, most existing benchmarks for multilingual multimodal reasoning\nstruggle to differentiate between models of varying performance; even language\nmodels without visual capabilities can easily achieve high scores. This leaves\na comprehensive evaluation of leading multilingual multimodal models largely\nunexplored. In this work, we introduce M4U, a novel and challenging benchmark\nfor assessing the capability of multi-discipline multilingual multimodal\nunderstanding and reasoning. M4U contains 10k samples covering 64 disciplines\nacross 16 subfields in Science, Engineering, and Healthcare in six languages.\nUsing M4U, we conduct extensive evaluations of leading Large Multimodal Models\n(LMMs) and Large Language Models (LLMs) with external tools. The evaluation\nresults demonstrate that the state-of-the-art model, GPT-4o, achieves only\n47.6% average accuracy on M4U. Additionally, we observe that the leading LMMs\nexhibit significant language preferences. Our in-depth analysis indicates that\nleading LMMs, including GPT-4o, struggle to perform reasoning using\nmultilingual information present in both visual and textual context.\nSpecifically, they suffer performance degradation when prompted with\ncross-lingual multimodal questions. Our code and dataset is public available."}
{"id": "2504.17404", "pdf": "https://arxiv.org/pdf/2504.17404", "abs": "https://arxiv.org/abs/2504.17404", "authors": ["Yi Zeng", "Feifei Zhao", "Yuwei Wang", "Enmeng Lu", "Yaodong Yang", "Lei Wang", "Chao Liu", "Yitao Liang", "Dongcheng Zhao", "Bing Han", "Haibo Tong", "Yao Liang", "Dongqi Liang", "Kang Sun", "Boyuan Chen", "Jinyu Fan"], "title": "Redefining Superalignment: From Weak-to-Strong Alignment to Human-AI Co-Alignment to Sustainable Symbiotic Society", "categories": ["cs.AI"], "comment": null, "summary": "Artificial Intelligence (AI) systems are becoming increasingly powerful and\nautonomous, and may progress to surpass human intelligence levels, namely\nArtificial Superintelligence (ASI). During the progression from AI to ASI, it\nmay exceed human control, violate human values, and even lead to irreversible\ncatastrophic consequences in extreme cases. This gives rise to a pressing issue\nthat needs to be addressed: superalignment, ensuring that AI systems much\nsmarter than humans, remain aligned with human (compatible) intentions and\nvalues. Existing scalable oversight and weak-to-strong generalization methods\nmay prove substantially infeasible and inadequate when facing ASI. We must\nexplore safer and more pluralistic frameworks and approaches for\nsuperalignment. In this paper, we redefine superalignment as the human-AI\nco-alignment towards a sustainable symbiotic society, and highlight a framework\nthat integrates external oversight and intrinsic proactive alignment. External\noversight superalignment should be grounded in human-centered ultimate\ndecision, supplemented by interpretable automated evaluation and correction, to\nachieve continuous alignment with humanity's evolving values. Intrinsic\nproactive superalignment is rooted in a profound understanding of the Self,\nothers, and society, integrating self-awareness, self-reflection, and empathy\nto spontaneously infer human intentions, distinguishing good from evil and\nproactively considering human well-being, ultimately attaining human-AI\nco-alignment through iterative interaction. The integration of\nexternally-driven oversight with intrinsically-driven proactive alignment\nempowers sustainable symbiotic societies through human-AI co-alignment, paving\nthe way for achieving safe and beneficial AGI and ASI for good, for human, and\nfor a symbiotic ecology."}
{"id": "2504.17966", "pdf": "https://arxiv.org/pdf/2504.17966", "abs": "https://arxiv.org/abs/2504.17966", "authors": ["Kaiyuan Tan", "Peilun Li", "Jun Wang", "Thomas Beckers"], "title": "Plug-and-Play Physics-informed Learning using Uncertainty Quantified Port-Hamiltonian Models", "categories": ["cs.RO", "cs.LG"], "comment": "7 pages, 6 figures", "summary": "The ability to predict trajectories of surrounding agents and obstacles is a\ncrucial component in many robotic applications. Data-driven approaches are\ncommonly adopted for state prediction in scenarios where the underlying\ndynamics are unknown. However, the performance, reliability, and uncertainty of\ndata-driven predictors become compromised when encountering out-of-distribution\nobservations relative to the training data. In this paper, we introduce a\nPlug-and-Play Physics-Informed Machine Learning (PnP-PIML) framework to address\nthis challenge. Our method employs conformal prediction to identify outlier\ndynamics and, in that case, switches from a nominal predictor to a\nphysics-consistent model, namely distributed Port-Hamiltonian systems (dPHS).\nWe leverage Gaussian processes to model the energy function of the dPHS,\nenabling not only the learning of system dynamics but also the quantification\nof predictive uncertainty through its Bayesian nature. In this way, the\nproposed framework produces reliable physics-informed predictions even for the\nout-of-distribution scenarios."}
{"id": "2504.17865", "pdf": "https://arxiv.org/pdf/2504.17865", "abs": "https://arxiv.org/abs/2504.17865", "authors": ["Charles J. Carver", "Hadleigh Schwartz", "Toma Itagaki", "Zachary Englhardt", "Kechen Liu", "Megan Graciela Nauli Manik", "Chun-Cheng Chang", "Vikram Iyer", "Brian Plancher", "Xia Zhou"], "title": "Set Phasers to Stun: Beaming Power and Control to Mobile Robots with Laser Light", "categories": ["cs.RO", "cs.CV"], "comment": "8 pages, 7 figures, submitted to IROS 2025", "summary": "We present Phaser, a flexible system that directs narrow-beam laser light to\nmoving robots for concurrent wireless power delivery and communication. We\ndesign a semi-automatic calibration procedure to enable fusion of\nstereo-vision-based 3D robot tracking with high-power beam steering, and a\nlow-power optical communication scheme that reuses the laser light as a data\nchannel. We fabricate a Phaser prototype using off-the-shelf hardware and\nevaluate its performance with battery-free autonomous robots. Phaser delivers\noptical power densities of over 110 mW/cm$^2$ and error-free data to mobile\nrobots at multi-meter ranges, with on-board decoding drawing 0.3 mA (97\\% less\ncurrent than Bluetooth Low Energy). We demonstrate Phaser fully powering\ngram-scale battery-free robots to nearly 2x higher speeds than prior work while\nsimultaneously controlling them to navigate around obstacles and along paths.\nCode, an open-source design guide, and a demonstration video of Phaser is\navailable at https://mobilex.cs.columbia.edu/phaser."}
{"id": "2407.09709", "pdf": "https://arxiv.org/pdf/2407.09709", "abs": "https://arxiv.org/abs/2407.09709", "authors": ["Lecheng Kong", "Jiarui Feng", "Hao Liu", "Chengsong Huang", "Jiaxin Huang", "Yixin Chen", "Muhan Zhang"], "title": "GOFA: A Generative One-For-All Model for Joint Graph Language Modeling", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Foundation models, such as Large Language Models (LLMs) or Large Vision\nModels (LVMs), have emerged as one of the most powerful tools in the respective\nfields. However, unlike text and image data, graph data do not have a\ndefinitive structure, posing great challenges to developing a Graph Foundation\nModel (GFM). For example, current attempts at designing general graph models\neither transform graph data into a language format for LLM-based prediction or\nstill train a GNN model with LLM as an assistant. The former can handle\nunlimited tasks, while the latter captures graph structure much better -- yet,\nno existing work can achieve both simultaneously. In this paper, we identify\nthree key desirable properties of a GFM: self-supervised pretraining, fluidity\nin tasks, and graph awareness. To account for these properties, we extend the\nconventional language modeling to the graph domain and propose a novel\ngenerative graph language model GOFA to solve the problem. The model\ninterleaves randomly initialized GNN layers into a frozen pre-trained LLM so\nthat the semantic and structural modeling abilities are organically combined.\nGOFA is pre-trained on newly proposed graph-level next-word prediction,\nquestion-answering, and structural tasks to obtain the above GFM properties.\nThe pre-trained model is further fine-tuned on downstream tasks to obtain\ntask-solving ability. The fine-tuned model is evaluated on various downstream\ntasks, demonstrating a strong ability to solve structural and contextual\nproblems in zero-shot scenarios. The code is available at\nhttps://github.com/JiaruiFeng/GOFA."}
{"id": "2201.05745", "pdf": "https://arxiv.org/pdf/2201.05745", "abs": "https://arxiv.org/abs/2201.05745", "authors": ["Ce Ju", "Cuntai Guan"], "title": "Deep Optimal Transport for Domain Adaptation on SPD Manifolds", "categories": ["cs.LG", "cs.AI", "eess.SP", "I.2.0"], "comment": "This work has been officially accepted for publication in Artificial\n  Intelligence. We recommend referring to the final published version for\n  citation or future reference", "summary": "Recent progress in geometric deep learning has drawn increasing attention\nfrom the machine learning community toward domain adaptation on symmetric\npositive definite (SPD) manifolds, especially for neuroimaging data that often\nsuffer from distribution shifts across sessions. These data, typically\nrepresented as covariance matrices of brain signals, inherently lie on SPD\nmanifolds due to their symmetry and positive definiteness. However,\nconventional domain adaptation methods often overlook this geometric structure\nwhen applied directly to covariance matrices, which can result in suboptimal\nperformance. To address this issue, we introduce a new geometric deep learning\nframework that combines optimal transport theory with the geometry of SPD\nmanifolds. Our approach aligns data distributions while respecting the manifold\nstructure, effectively reducing both marginal and conditional discrepancies. We\nvalidate our method on three cross-session brain computer interface datasets,\nKU, BNCI2014001, and BNCI2015001, where it consistently outperforms baseline\napproaches while maintaining the intrinsic geometry of the data. We also\nprovide quantitative results and visualizations to better illustrate the\nbehavior of the learned embeddings."}
{"id": "2504.17999", "pdf": "https://arxiv.org/pdf/2504.17999", "abs": "https://arxiv.org/abs/2504.17999", "authors": ["Chang Xiao", "Brenda Yang"], "title": "Streaming, Fast and Slow: Cognitive Load-Aware Streaming for Efficient LLM Serving", "categories": ["cs.HC", "cs.LG"], "comment": null, "summary": "Generative conversational interfaces powered by large language models (LLMs)\ntypically stream output token-by-token at a rate determined by computational\nbudget, often neglecting actual human reading speeds and the cognitive load\nassociated with the content. This mismatch frequently leads to inefficient use\nof computational resources. For example, in cloud-based services, streaming\ncontent faster than users can read appears unnecessary, resulting in wasted\ncomputational resources and potential delays for other users, particularly\nduring peak usage periods. To address this issue, we propose an adaptive\nstreaming method that dynamically adjusts the pacing of LLM streaming output in\nreal-time based on inferred cognitive load. Our approach estimates the\ncognitive load associated with streaming content and strategically slows down\nthe stream during complex or information-rich segments, thereby freeing\ncomputational resources for other users. Our statistical analysis of\ncomputational savings, combined with crowdsourced user studies, provides\ninsights into the trade-offs between service efficiency and user satisfaction,\ndemonstrating that our method can significantly reduce computational\nconsumption up to 16.8\\%. This context-aware computational resource management\nstrategy presents a practical framework for enhancing system efficiency in\ncloud-based conversational AI interfaces without compromising user experience."}
{"id": "2504.17898", "pdf": "https://arxiv.org/pdf/2504.17898", "abs": "https://arxiv.org/abs/2504.17898", "authors": ["David Wang", "Derek Goh", "Jiale Zhang"], "title": "Material Identification Via RFID For Smart Shopping", "categories": ["eess.SP", "cs.CV", "J.0; J.7; B.0"], "comment": "5 pages, 7 figures", "summary": "Cashierless stores rely on computer vision and RFID tags to associate\nshoppers with items, but concealed items placed in backpacks, pockets, or bags\ncreate challenges for theft prevention. We introduce a system that turns\nexisting RFID tagged items into material sensors by exploiting how different\ncontainers attenuate and scatter RF signals. Using RSSI and phase angle, we\ntrained a neural network to classify seven common containers. In a simulated\nretail environment, the model achieves 89% accuracy with one second samples and\n74% accuracy from single reads. Incorporating distance measurements, our system\nachieves 82% accuracy across 0.3-2m tag to reader separations. When deployed at\naisle or doorway choke points, the system can flag suspicious events in real\ntime, prompting camera screening or staff intervention. By combining material\nidentification with computer vision tracking, our system provides proactive\nloss prevention for cashierless retail while utilizing existing infrastructure."}
{"id": "2408.06621", "pdf": "https://arxiv.org/pdf/2408.06621", "abs": "https://arxiv.org/abs/2408.06621", "authors": ["Sungmin Cha", "Sungjun Cho", "Dasol Hwang", "Moontae Lee"], "title": "Towards Robust and Parameter-Efficient Knowledge Unlearning for LLMs", "categories": ["cs.LG", "cs.CL"], "comment": "ICLR 2025 camera-ready version", "summary": "Large Language Models (LLMs) have demonstrated strong reasoning and\nmemorization capabilities via pretraining on massive textual corpora. However,\nthis poses risk of privacy and copyright violations, highlighting the need for\nefficient machine unlearning methods that remove sensitive data without\nretraining from scratch. While Gradient Ascent (GA) is commonly used to unlearn\nby reducing the likelihood of generating unwanted content, it leads to unstable\noptimization and catastrophic forgetting of retrained knowledge. We find that\ncombining GA with low-rank adaptation results in poor trade-offs between\ncomputational cost and generative performance. To address these challenges, we\npropose Low-rank Knowledge Unlearning (LoKU), a novel framework that enables\nrobust and efficient unlearning for LLMs. First, we introduce Inverted Hinge\nLoss, which suppresses unwanted tokens while maintaining fluency by boosting\nthe probability of the next most likely token. Second, we develop a\ndata-adaptive initialization for LoRA adapters via low-rank approximation\nweighted with relative Fisher information, thereby focusing updates on\nparameters critical for removing targeted knowledge. Experiments on the\nTraining Data Extraction Challenge dataset using GPT-Neo models as well as on\nthe TOFU benchmark with Phi-1.5B and Llama2-7B models demonstrate that our\napproach effectively removes sensitive information while maintaining reasoning\nand generative capabilities with minimal impact. Our implementation can be\nfound in https://github.com/csm9493/efficient-llm-unlearning."}
{"id": "2211.05950", "pdf": "https://arxiv.org/pdf/2211.05950", "abs": "https://arxiv.org/abs/2211.05950", "authors": ["Xuan Rao", "Bo Zhao", "Derong Liu"], "title": "CR-LSO: Convex Neural Architecture Optimization in the Latent Space of Graph Variational Autoencoder with Input Convex Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In neural architecture search (NAS) methods based on latent space\noptimization (LSO), a deep generative model is trained to embed discrete neural\narchitectures into a continuous latent space. In this case, different\noptimization algorithms that operate in the continuous space can be implemented\nto search neural architectures. However, the optimization of latent variables\nis challenging for gradient-based LSO since the mapping from the latent space\nto the architecture performance is generally non-convex. To tackle this\nproblem, this paper develops a convexity regularized latent space optimization\n(CR-LSO) method, which aims to regularize the learning process of latent space\nin order to obtain a convex architecture performance mapping. Specifically,\nCR-LSO trains a graph variational autoencoder (G-VAE) to learn the continuous\nrepresentations of discrete architectures. Simultaneously, the learning process\nof latent space is regularized by the guaranteed convexity of input convex\nneural networks (ICNNs). In this way, the G-VAE is forced to learn a convex\nmapping from the architecture representation to the architecture performance.\nHereafter, the CR-LSO approximates the performance mapping using the ICNN and\nleverages the estimated gradient to optimize neural architecture\nrepresentations. Experimental results on three popular NAS benchmarks show that\nCR-LSO achieves competitive evaluation results in terms of both computational\ncomplexity and architecture performance."}
{"id": "2504.18015", "pdf": "https://arxiv.org/pdf/2504.18015", "abs": "https://arxiv.org/abs/2504.18015", "authors": ["Hanrui Wang", "Shuo Wang", "Chun-Shien Lu", "Isao Echizen"], "title": "Diffusion-Driven Universal Model Inversion Attack for Face Recognition", "categories": ["cs.CR", "cs.CV", "cs.LG"], "comment": null, "summary": "Facial recognition technology poses significant privacy risks, as it relies\non biometric data that is inherently sensitive and immutable if compromised. To\nmitigate these concerns, face recognition systems convert raw images into\nembeddings, traditionally considered privacy-preserving. However, model\ninversion attacks pose a significant privacy threat by reconstructing these\nprivate facial images, making them a crucial tool for evaluating the privacy\nrisks of face recognition systems. Existing methods usually require training\nindividual generators for each target model, a computationally expensive\nprocess. In this paper, we propose DiffUMI, a training-free diffusion-driven\nuniversal model inversion attack for face recognition systems. DiffUMI is the\nfirst approach to apply a diffusion model for unconditional image generation in\nmodel inversion. Unlike other methods, DiffUMI is universal, eliminating the\nneed for training target-specific generators. It operates within a fixed\nframework and pretrained diffusion model while seamlessly adapting to diverse\ntarget identities and models. DiffUMI breaches privacy-preserving face\nrecognition systems with state-of-the-art success, demonstrating that an\nunconditional diffusion model, coupled with optimized adversarial search,\nenables efficient and high-fidelity facial reconstruction. Additionally, we\nintroduce a novel application of out-of-domain detection (OODD), marking the\nfirst use of model inversion to distinguish non-face inputs from face inputs\nbased solely on embeddings."}
{"id": "2408.08990", "pdf": "https://arxiv.org/pdf/2408.08990", "abs": "https://arxiv.org/abs/2408.08990", "authors": ["Jungeum Kim", "Sean O'Hagan", "Veronika Rockova"], "title": "Adaptive Uncertainty Quantification for Generative AI", "categories": ["stat.ME", "cs.AI", "cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "This work is concerned with conformal prediction in contemporary applications\n(including generative AI) where a black-box model has been trained on data that\nare not accessible to the user. Mirroring split-conformal inference, we design\na wrapper around a black-box algorithm which calibrates conformity scores. This\ncalibration is local and proceeds in two stages by first adaptively\npartitioning the predictor space into groups and then calibrating sectionally\ngroup by group. Adaptive partitioning (self-grouping) is achieved by fitting a\nrobust regression tree to the conformity scores on the calibration set. This\nnew tree variant is designed in such a way that adding a single new observation\ndoes not change the tree fit with overwhelmingly large probability. This\nadd-one-in robustness property allows us to conclude a finite sample\ngroup-conditional coverage guarantee, a refinement of the marginal guarantee.\nIn addition, unlike traditional split-conformal inference, adaptive splitting\nand within-group calibration yields adaptive bands which can stretch and shrink\nlocally. We demonstrate benefits of local tightening on several simulated as\nwell as real examples using non-parametric regression. Finally, we consider two\ncontemporary classification applications for obtaining uncertainty\nquantification around GPT-4o predictions. We conformalize skin disease\ndiagnoses based on self-reported symptoms as well as predicted states of U.S.\nlegislators based on summaries of their ideology. We demonstrate substantial\nlocal tightening of the uncertainty sets while attaining similar marginal\ncoverage."}
{"id": "2309.17401", "pdf": "https://arxiv.org/pdf/2309.17401", "abs": "https://arxiv.org/abs/2309.17401", "authors": ["Milin Zhang", "Mohammad Abdi", "Jonathan Ashdown", "Francesco Restuccia"], "title": "Adversarial Attacks to Latent Representations of Distributed Neural Networks in Split Computing", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Distributed deep neural networks (DNNs) have been shown to reduce the\ncomputational burden of mobile devices and decrease the end-to-end inference\nlatency in edge computing scenarios. While distributed DNNs have been studied,\nto the best of our knowledge, the resilience of distributed DNNs to adversarial\naction remains an open problem. In this paper, we fill the existing research\ngap by rigorously analyzing the robustness of distributed DNNs against\nadversarial action. We cast this problem in the context of information theory\nand rigorously proved that (i) the compressed latent dimension improves the\nrobustness but also affect task-oriented performance; and (ii) the deeper\nsplitting point enhances the robustness but also increases the computational\nburden. These two trade-offs provide a novel perspective to design robust\ndistributed DNN. To test our theoretical findings, we perform extensive\nexperimental analysis by considering 6 different DNN architectures, 6 different\napproaches for distributed DNN and 10 different adversarial attacks using the\nImageNet-1K dataset."}
{"id": "2504.18017", "pdf": "https://arxiv.org/pdf/2504.18017", "abs": "https://arxiv.org/abs/2504.18017", "authors": ["Sourav Chatterjee", "Timothy Sudijono"], "title": "Non-identifiability distinguishes Neural Networks among Parametric Models", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "comment": "16 pages. Comments welcome", "summary": "One of the enduring problems surrounding neural networks is to identify the\nfactors that differentiate them from traditional statistical models. We prove a\npair of results which distinguish feedforward neural networks among parametric\nmodels at the population level, for regression tasks. Firstly, we prove that\nfor any pair of random variables $(X,Y)$, neural networks always learn a\nnontrivial relationship between $X$ and $Y$, if one exists. Secondly, we prove\nthat for reasonable smooth parametric models, under local and global\nidentifiability conditions, there exists a nontrivial $(X,Y)$ pair for which\nthe parametric model learns the constant predictor $\\mathbb{E}[Y]$. Together,\nour results suggest that a lack of identifiability distinguishes neural\nnetworks among the class of smooth parametric models."}
{"id": "2504.18323", "pdf": "https://arxiv.org/pdf/2504.18323", "abs": "https://arxiv.org/abs/2504.18323", "authors": ["Yangyang Xu", "Kexin Li", "Li Yang", "You-Wei Wen"], "title": "Outlier-aware Tensor Robust Principal Component Analysis with Self-guided Data Augmentation", "categories": ["math.NA", "cs.CV", "cs.LG", "cs.NA", "65K10, 15A69", "I.4.5; G.1.6"], "comment": "12 pages, 6 figures, 3 tables", "summary": "Tensor Robust Principal Component Analysis (TRPCA) is a fundamental technique\nfor decomposing multi-dimensional data into a low-rank tensor and an outlier\ntensor, yet existing methods relying on sparse outlier assumptions often fail\nunder structured corruptions. In this paper, we propose a self-guided data\naugmentation approach that employs adaptive weighting to suppress outlier\ninfluence, reformulating the original TRPCA problem into a standard Tensor\nPrincipal Component Analysis (TPCA) problem. The proposed model involves an\noptimization-driven weighting scheme that dynamically identifies and\ndownweights outlier contributions during tensor augmentation. We develop an\nefficient proximal block coordinate descent algorithm with closed-form updates\nto solve the resulting optimization problem, ensuring computational efficiency.\nTheoretical convergence is guaranteed through a framework combining block\ncoordinate descent with majorization-minimization principles. Numerical\nexperiments on synthetic and real-world datasets, including face recovery,\nbackground subtraction, and hyperspectral denoising, demonstrate that our\nmethod effectively handles various corruption patterns. The results show the\nimprovements in both accuracy and computational efficiency compared to\nstate-of-the-art methods."}
{"id": "2411.01841", "pdf": "https://arxiv.org/pdf/2411.01841", "abs": "https://arxiv.org/abs/2411.01841", "authors": ["Shi Dong", "Xiaobei Niu", "Rui Zhong", "Zhifeng Wang", "Mingzhang Zuo"], "title": "Leveraging Label Semantics and Meta-Label Refinement for Multi-Label Question Classification", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Accurate annotation of educational resources is crucial for effective\npersonalized learning and resource recommendation in online education. However,\nfine-grained knowledge labels often overlap or share similarities, making it\ndifficult for existing multi-label classification methods to differentiate\nthem. The label distribution imbalance due to sparsity of human annotations\nfurther intensifies these challenges. To address these issues, this paper\nintroduces RR2QC, a novel Retrieval Reranking method to multi-label Question\nClassification by leveraging label semantics and meta-label refinement. First,\nRR2QC improves the pre-training strategy by utilizing semantic relationships\nwithin and across label groups. Second, it introduces a class center learning\ntask to align questions with label semantics during downstream training.\nFinally, this method decomposes labels into meta-labels and uses a meta-label\nclassifier to rerank the retrieved label sequences. In doing so, RR2QC enhances\nthe understanding and prediction capability of long-tail labels by learning\nfrom meta-labels that frequently appear in other labels. Additionally, a\nmathematical LLM is used to generate solutions for questions, extracting latent\ninformation to further refine the model's insights. Experimental results show\nthat RR2QC outperforms existing methods in Precision@K and F1 scores across\nmultiple educational datasets, demonstrating its effectiveness for online\neducation applications. The code and datasets are available at\nhttps://github.com/78Erii/RR2QC."}
{"id": "2401.00867", "pdf": "https://arxiv.org/pdf/2401.00867", "abs": "https://arxiv.org/abs/2401.00867", "authors": ["Borja Aizpurua", "Samuel Palmer", "Roman Orus"], "title": "Tensor Networks for Explainable Machine Learning in Cybersecurity", "categories": ["cs.LG", "cs.AI", "quant-ph"], "comment": "12 pages, 9 figures, 3 tables", "summary": "In this paper we show how tensor networks help in developing explainability\nof machine learning algorithms. Specifically, we develop an unsupervised\nclustering algorithm based on Matrix Product States (MPS) and apply it in the\ncontext of a real use-case of adversary-generated threat intelligence. Our\ninvestigation proves that MPS rival traditional deep learning models such as\nautoencoders and GANs in terms of performance, while providing much richer\nmodel interpretability. Our approach naturally facilitates the extraction of\nfeature-wise probabilities, Von Neumann Entropy, and mutual information,\noffering a compelling narrative for classification of anomalies and fostering\nan unprecedented level of transparency and interpretability, something\nfundamental to understand the rationale behind artificial intelligence\ndecisions."}
{"id": "2504.18103", "pdf": "https://arxiv.org/pdf/2504.18103", "abs": "https://arxiv.org/abs/2504.18103", "authors": ["Natansh Mathur", "Brian Coyle", "Nishant Jain", "Snehal Raj", "Akshat Tandon", "Jasper Simon Krauser", "Rainer Stoessel"], "title": "Bayesian Quantum Orthogonal Neural Networks for Anomaly Detection", "categories": ["quant-ph", "cs.LG"], "comment": "14 pages, 9 figures", "summary": "Identification of defects or anomalies in 3D objects is a crucial task to\nensure correct functionality. In this work, we combine Bayesian learning with\nrecent developments in quantum and quantum-inspired machine learning,\nspecifically orthogonal neural networks, to tackle this anomaly detection\nproblem for an industrially relevant use case. Bayesian learning enables\nuncertainty quantification of predictions, while orthogonality in weight\nmatrices enables smooth training. We develop orthogonal (quantum) versions of\n3D convolutional neural networks and show that these models can successfully\ndetect anomalies in 3D objects. To test the feasibility of incorporating\nquantum computers into a quantum-enhanced anomaly detection pipeline, we\nperform hardware experiments with our models on IBM's 127-qubit Brisbane\ndevice, testing the effect of noise and limited measurement shots."}
{"id": "2504.17365", "pdf": "https://arxiv.org/pdf/2504.17365", "abs": "https://arxiv.org/abs/2504.17365", "authors": ["Ling You", "Wenxuan Huang", "Xinni Xie", "Xiangyi Wei", "Bangyan Li", "Shaohui Lin", "Yang Li", "Changbo Wang"], "title": "TimeSoccer: An End-to-End Multimodal Large Language Model for Soccer Commentary Generation", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Soccer is a globally popular sporting event, typically characterized by long\nmatches and distinctive highlight moments. Recent advances in Multimodal Large\nLanguage Models (MLLMs) offer promising capabilities in temporal grounding and\nvideo understanding, soccer commentary generation often requires precise\ntemporal localization and semantically rich descriptions over long-form video.\nHowever, existing soccer MLLMs often rely on the temporal a priori for caption\ngeneration, so they cannot process the soccer video end-to-end. While some\ntraditional approaches follow a two-step paradigm that is complex and fails to\ncapture the global context to achieve suboptimal performance. To solve the\nabove issues, we present TimeSoccer, the first end-to-end soccer MLLM for\nSingle-anchor Dense Video Captioning (SDVC) in full-match soccer videos.\nTimeSoccer jointly predicts timestamps and generates captions in a single pass,\nenabling global context modeling across 45-minute matches. To support long\nvideo understanding of soccer matches, we introduce MoFA-Select, a\ntraining-free, motion-aware frame compression module that adaptively selects\nrepresentative frames via a coarse-to-fine strategy, and incorporates\ncomplementary training paradigms to strengthen the model's ability to handle\nlong temporal sequences. Extensive experiments demonstrate that our TimeSoccer\nachieves State-of-The-Art (SoTA) performance on the SDVC task in an end-to-end\nform, generating high-quality commentary with accurate temporal alignment and\nstrong semantic relevance."}
{"id": "2404.16468", "pdf": "https://arxiv.org/pdf/2404.16468", "abs": "https://arxiv.org/abs/2404.16468", "authors": ["Bram De Cooman", "Johan Suykens"], "title": "A Dual Perspective of Reinforcement Learning for Imposing Policy Constraints", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY", "I.2.8"], "comment": "Accepted for publication in IEEE Transactions on Artificial\n  Intelligence", "summary": "Model-free reinforcement learning methods lack an inherent mechanism to\nimpose behavioural constraints on the trained policies. Although certain\nextensions exist, they remain limited to specific types of constraints, such as\nvalue constraints with additional reward signals or visitation density\nconstraints. In this work we unify these existing techniques and bridge the gap\nwith classical optimization and control theory, using a generic primal-dual\nframework for value-based and actor-critic reinforcement learning methods. The\nobtained dual formulations turn out to be especially useful for imposing\nadditional constraints on the learned policy, as an intrinsic relationship\nbetween such dual constraints (or regularization terms) and reward\nmodifications in the primal is revealed. Furthermore, using this framework, we\nare able to introduce some novel types of constraints, allowing to impose\nbounds on the policy's action density or on costs associated with transitions\nbetween consecutive states and actions. From the adjusted primal-dual\noptimization problems, a practical algorithm is derived that supports various\ncombinations of policy constraints that are automatically handled throughout\ntraining using trainable reward modifications. The proposed $\\texttt{DualCRL}$\nmethod is examined in more detail and evaluated under different (combinations\nof) constraints on two interpretable environments. The results highlight the\nefficacy of the method, which ultimately provides the designer of such systems\nwith a versatile toolbox of possible policy constraints."}
{"id": "2504.18126", "pdf": "https://arxiv.org/pdf/2504.18126", "abs": "https://arxiv.org/abs/2504.18126", "authors": ["Miranda C. N. Cheng", "Niki Stratikopoulou"], "title": "Lecture Notes on Normalizing Flows for Lattice Quantum Field Theories", "categories": ["hep-lat", "cs.LG", "hep-th"], "comment": "70 pages", "summary": "Numerical simulations of quantum field theories on lattices serve as a\nfundamental tool for studying the non-perturbative regime of the theories,\nwhere analytic tools often fall short. Challenges arise when one takes the\ncontinuum limit or as the system approaches a critical point, especially in the\npresence of non-trivial topological structures in the theory. Rapid recent\nadvances in machine learning provide a promising avenue for progress in this\narea. These lecture notes aim to give a brief account of lattice field\ntheories, normalizing flows, and how the latter can be applied to study the\nformer. The notes are based on the lectures given by the first author in\nvarious recent research schools."}
{"id": "2309.14786", "pdf": "https://arxiv.org/pdf/2309.14786", "abs": "https://arxiv.org/abs/2309.14786", "authors": ["Suhwan Cho", "Minhyeok Lee", "Jungho Lee", "MyeongAh Cho", "Seungwook Park", "Jaeyeob Kim", "Hyunsung Jang", "Sangyoun Lee"], "title": "Treating Motion as Option with Output Selection for Unsupervised Video Object Segmentation", "categories": ["cs.CV"], "comment": "TCSVT 2025", "summary": "Unsupervised video object segmentation aims to detect the most salient object\nin a video without any external guidance regarding the object. Salient objects\noften exhibit distinctive movements compared to the background, and recent\nmethods leverage this by combining motion cues from optical flow maps with\nappearance cues from RGB images. However, because optical flow maps are often\nclosely correlated with segmentation masks, networks can become overly\ndependent on motion cues during training, leading to vulnerability when faced\nwith confusing motion cues and resulting in unstable predictions. To address\nthis challenge, we propose a novel motion-as-option network that treats motion\ncues as an optional component rather than a necessity. During training, we\nrandomly input RGB images into the motion encoder instead of optical flow maps,\nwhich implicitly reduces the network's reliance on motion cues. This design\nensures that the motion encoder is capable of processing both RGB images and\noptical flow maps, leading to two distinct predictions depending on the type of\ninput provided. To make the most of this flexibility, we introduce an adaptive\noutput selection algorithm that determines the optimal prediction during\ntesting."}
{"id": "2405.04161", "pdf": "https://arxiv.org/pdf/2405.04161", "abs": "https://arxiv.org/abs/2405.04161", "authors": ["Ricardo Vinuesa", "Paola Cinnella", "Jean Rabault", "Hossein Azizpour", "Stefan Bauer", "Bingni W. Brunton", "Arne Elofsson", "Elias Jarlebring", "Hedvig Kjellstrom", "Stefano Markidis", "David Marlevi", "Javier Garcia-Martinez", "Steven L. Brunton"], "title": "Decoding complexity: how machine learning is redefining scientific discovery", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As modern scientific instruments generate vast amounts of data and the volume\nof information in the scientific literature continues to grow, machine learning\n(ML) has become an essential tool for organising, analysing, and interpreting\nthese complex datasets. This paper explores the transformative role of ML in\naccelerating breakthroughs across a range of scientific disciplines. By\npresenting key examples -- such as brain mapping and exoplanet detection -- we\ndemonstrate how ML is reshaping scientific research. We also explore different\nscenarios where different levels of knowledge of the underlying phenomenon are\navailable, identifying strategies to overcome limitations and unlock the full\npotential of ML. Despite its advances, the growing reliance on ML poses\nchallenges for research applications and rigorous validation of discoveries. We\nargue that even with these challenges, ML is poised to disrupt traditional\nmethodologies and advance the boundaries of knowledge by enabling researchers\nto tackle increasingly complex problems. Thus, the scientific community can\nmove beyond the necessary traditional oversimplifications to embrace the full\ncomplexity of natural systems, ultimately paving the way for interdisciplinary\nbreakthroughs and innovative solutions to humanity's most pressing challenges."}
{"id": "2504.18147", "pdf": "https://arxiv.org/pdf/2504.18147", "abs": "https://arxiv.org/abs/2504.18147", "authors": ["Rob Romijnders", "Stefanos Laskaridis", "Ali Shahin Shamsabadi", "Hamed Haddadi"], "title": "NoEsis: Differentially Private Knowledge Transfer in Modular LLM Adaptation", "categories": ["cs.CR", "cs.LG"], "comment": "ICLR 2025 MCDC workshop", "summary": "Large Language Models (LLM) are typically trained on vast amounts of data\nfrom various sources. Even when designed modularly (e.g., Mixture-of-Experts),\nLLMs can leak privacy on their sources. Conversely, training such models in\nisolation arguably prohibits generalization. To this end, we propose a\nframework, NoEsis, which builds upon the desired properties of modularity,\nprivacy, and knowledge transfer. NoEsis integrates differential privacy with a\nhybrid two-staged parameter-efficient fine-tuning that combines domain-specific\nlow-rank adapters, acting as experts, with common prompt tokens, acting as a\nknowledge-sharing backbone. Results from our evaluation on CodeXGLUE showcase\nthat NoEsis can achieve provable privacy guarantees with tangible knowledge\ntransfer across domains, and empirically show protection against Membership\nInference Attacks. Finally, on code completion tasks, NoEsis bridges at least\n77% of the accuracy gap between the non-shared and the non-private baseline."}
{"id": "2312.02252", "pdf": "https://arxiv.org/pdf/2312.02252", "abs": "https://arxiv.org/abs/2312.02252", "authors": ["Xiaoqian Shen", "Mohamed Elhoseiny"], "title": "StoryGPT-V: Large Language Models as Consistent Story Visualizers", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2025; Project page:\n  https://xiaoqian-shen.github.io/StoryGPT-V", "summary": "Recent generative models have demonstrated impressive capabilities in\ngenerating realistic and visually pleasing images grounded on textual prompts.\nNevertheless, a significant challenge remains in applying these models for the\nmore intricate task of story visualization. Since it requires resolving\npronouns (he, she, they) in the frame descriptions, i.e., anaphora resolution,\nand ensuring consistent characters and background synthesis across frames. Yet,\nthe emerging Large Language Model (LLM) showcases robust reasoning abilities to\nnavigate through ambiguous references and process extensive sequences.\nTherefore, we introduce \\emph{StoryGPT-V}, which leverages the merits of the\nlatent diffusion (LDM) and LLM to produce images with consistent and\nhigh-quality characters grounded on given story descriptions. First, we train a\ncharacter-aware LDM, which takes character-augmented semantic embedding as\ninput and includes the supervision of the cross-attention map using character\nsegmentation masks, aiming to enhance character generation accuracy and\nfaithfulness. In the second stage, we enable an alignment between the output of\nLLM and the character-augmented embedding residing in the input space of the\nfirst-stage model. This harnesses the reasoning ability of LLM to address\nambiguous references and the comprehension capability to memorize the context.\nWe conduct comprehensive experiments on two visual story visualization\nbenchmarks. Our model reports superior quantitative results and consistently\ngenerates accurate characters of remarkable quality with low memory\nconsumption. Our code is publicly available at:\n\\href{https://xiaoqian-shen.github.io/StoryGPT-V}{https://xiaoqian-shen.github.io/StoryGPT-V}."}
{"id": "2406.02105", "pdf": "https://arxiv.org/pdf/2406.02105", "abs": "https://arxiv.org/abs/2406.02105", "authors": ["Vignesh Kothapalli", "Tom Tirer"], "title": "Can Kernel Methods Explain How the Data Affects Neural Collapse?", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "stat.ML"], "comment": "Transactions on Machine Learning Research (TMLR)", "summary": "A vast amount of literature has recently focused on the \"Neural Collapse\"\n(NC) phenomenon, which emerges when training neural network (NN) classifiers\nbeyond the zero training error point. The core component of NC is the decrease\nin the within-class variability of the network's deepest features, dubbed as\nNC1. The theoretical works that study NC are typically based on simplified\nunconstrained features models (UFMs) that mask any effect of the data on the\nextent of collapse. To address this limitation of UFMs, this paper explores the\npossibility of analyzing NC1 using kernels associated with shallow NNs. We\nbegin by formulating an NC1 metric as a function of the kernel. Then, we\nspecialize it to the NN Gaussian Process kernel (NNGP) and the Neural Tangent\nKernel (NTK), associated with wide networks at initialization and during\ngradient-based training with a small learning rate, respectively. As a key\nresult, we show that the NTK does not represent more collapsed features than\nthe NNGP for Gaussian data of arbitrary dimensions. This showcases the\nlimitations of data-independent kernels such as NTK in approximating the NC\nbehavior of NNs. As an alternative to NTK, we then empirically explore a\nrecently proposed data-aware Gaussian Process kernel, which generalizes NNGP to\nmodel feature learning. We show that this kernel yields lower NC1 than NNGP but\nmay not follow the trends of the shallow NN. Our study demonstrates that\nadaptivity to data may allow kernel-based analysis of NC, though further\nadvancements in this area are still needed. A nice byproduct of our study is\nshowing both theoretically and empirically that the choice of nonlinear\nactivation function affects NC1 (with ERF yielding lower values than ReLU). The\ncode is available at: https://github.com/kvignesh1420/shallow_nc1"}
{"id": "2504.18184", "pdf": "https://arxiv.org/pdf/2504.18184", "abs": "https://arxiv.org/abs/2504.18184", "authors": ["Jia-Qi Yang", "Lei Shi"], "title": "Learning Operators by Regularized Stochastic Gradient Descent with Operator-valued Kernels", "categories": ["stat.ML", "cs.LG", "math.FA", "math.ST", "stat.TH"], "comment": "56 pages, 2 figures", "summary": "This paper investigates regularized stochastic gradient descent (SGD)\nalgorithms for estimating nonlinear operators from a Polish space to a\nseparable Hilbert space. We assume that the regression operator lies in a\nvector-valued reproducing kernel Hilbert space induced by an operator-valued\nkernel. Two significant settings are considered: an online setting with\npolynomially decaying step sizes and regularization parameters, and a\nfinite-horizon setting with constant step sizes and regularization parameters.\nWe introduce regularity conditions on the structure and smoothness of the\ntarget operator and the input random variables. Under these conditions, we\nprovide a dimension-free convergence analysis for the prediction and estimation\nerrors, deriving both expectation and high-probability error bounds. Our\nanalysis demonstrates that these convergence rates are nearly optimal.\nFurthermore, we present a new technique for deriving bounds with high\nprobability for general SGD schemes, which also ensures almost-sure\nconvergence. Finally, we discuss potential extensions to more general\noperator-valued kernels and the encoder-decoder framework."}
{"id": "2312.12176", "pdf": "https://arxiv.org/pdf/2312.12176", "abs": "https://arxiv.org/abs/2312.12176", "authors": ["Jose L. G√≥mez", "Manuel Silva", "Antonio Seoane", "Agn√®s Borr√°s", "Mario Noriega", "Germ√°n Ros", "Jose A. Iglesias-Guitian", "Antonio M. L√≥pez"], "title": "All for One, and One for All: UrbanSyn Dataset, the third Musketeer of Synthetic Driving Scenes", "categories": ["cs.CV"], "comment": "The UrbanSyn Dataset is available in http://urbansyn.org/", "summary": "We introduce UrbanSyn, a photorealistic dataset acquired through\nsemi-procedurally generated synthetic urban driving scenarios. Developed using\nhigh-quality geometry and materials, UrbanSyn provides pixel-level ground\ntruth, including depth, semantic segmentation, and instance segmentation with\nobject bounding boxes and occlusion degree. It complements GTAV and Synscapes\ndatasets to form what we coin as the 'Three Musketeers'. We demonstrate the\nvalue of the Three Musketeers in unsupervised domain adaptation for image\nsemantic segmentation. Results on real-world datasets, Cityscapes, Mapillary\nVistas, and BDD100K, establish new benchmarks, largely attributed to UrbanSyn.\nWe make UrbanSyn openly and freely accessible (www.urbansyn.org)."}
{"id": "2406.16386", "pdf": "https://arxiv.org/pdf/2406.16386", "abs": "https://arxiv.org/abs/2406.16386", "authors": ["Yuxuan Wan", "Chaozheng Wang", "Yi Dong", "Wenxuan Wang", "Shuqing Li", "Yintong Huo", "Michael R. Lyu"], "title": "Automatically Generating UI Code from Screenshot: A Divide-and-Conquer-Based Approach", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted by FSE 2025", "summary": "Websites are critical in today's digital world, with over 1.11 billion\ncurrently active and approximately 252,000 new sites launched daily. Converting\nwebsite layout design into functional UI code is a time-consuming yet\nindispensable step of website development. Manual methods of converting visual\ndesigns into functional code present significant challenges, especially for\nnon-experts. To explore automatic design-to-code solutions, we first conduct a\nmotivating study on GPT-4o and identify three types of issues in generating UI\ncode: element omission, element distortion, and element misarrangement. We\nfurther reveal that a focus on smaller visual segments can help multimodal\nlarge language models (MLLMs) mitigate these failures in the generation\nprocess.\n  In this paper, we propose DCGen, a divide-and-conquer-based approach to\nautomate the translation of webpage design to UI code. DCGen starts by dividing\nscreenshots into manageable segments, generating code for each segment, and\nthen reassembling them into complete UI code for the entire screenshot. We\nconduct extensive testing with a dataset comprised of real-world websites and\nvarious MLLMs and demonstrate that DCGen achieves up to a 15% improvement in\nvisual similarity and 8% in code similarity for large input images. Human\nevaluations show that DCGen can help developers implement webpages\nsignificantly faster and more similar to the UI designs. To the best of our\nknowledge, DCGen is the first segment-aware MLLM-based approach for generating\nUI code directly from screenshots."}
{"id": "2504.18212", "pdf": "https://arxiv.org/pdf/2504.18212", "abs": "https://arxiv.org/abs/2504.18212", "authors": ["Nguyen Vu Khai Tam", "Cao Huyen My", "Vo Nguyen Le Duy"], "title": "Post-Transfer Learning Statistical Inference in High-Dimensional Regression", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Transfer learning (TL) for high-dimensional regression (HDR) is an important\nproblem in machine learning, particularly when dealing with limited sample size\nin the target task. However, there currently lacks a method to quantify the\nstatistical significance of the relationship between features and the response\nin TL-HDR settings. In this paper, we introduce a novel statistical inference\nframework for assessing the reliability of feature selection in TL-HDR, called\nPTL-SI (Post-TL Statistical Inference). The core contribution of PTL-SI is its\nability to provide valid $p$-values to features selected in TL-HDR, thereby\nrigorously controlling the false positive rate (FPR) at desired significance\nlevel $\\alpha$ (e.g., 0.05). Furthermore, we enhance statistical power by\nincorporating a strategic divide-and-conquer approach into our framework. We\ndemonstrate the validity and effectiveness of the proposed PTL-SI through\nextensive experiments on both synthetic and real-world high-dimensional\ndatasets, confirming its theoretical properties and utility in testing the\nreliability of feature selection in TL scenarios."}
{"id": "2404.00146", "pdf": "https://arxiv.org/pdf/2404.00146", "abs": "https://arxiv.org/abs/2404.00146", "authors": ["Huiyuan Yu", "Jia He", "Maggie Cheng"], "title": "Fast Orthogonal Matching Pursuit through Successive Regression", "categories": ["cs.CV", "math.OC"], "comment": null, "summary": "Orthogonal Matching Pursuit (OMP) has been a powerful method in sparse signal\nrecovery and approximation. However, OMP suffers computational issues when the\nsignal has a large number of non-zeros. This paper advances OMP and its\nextension called generalized OMP (gOMP) by offering fast algorithms for the\northogonal projection of the input signal at each iteration. The proposed\nmodifications directly reduce the computational complexity of OMP and gOMP.\nExperiment results verified the improvement in computation time. This paper\nalso provides sufficient conditions for exact signal recovery. For general\nsignals with additive noise, the approximation error is at the same order as\nOMP (gOMP), but is obtained within much less time."}
{"id": "2408.17355", "pdf": "https://arxiv.org/pdf/2408.17355", "abs": "https://arxiv.org/abs/2408.17355", "authors": ["Yuejiang Liu", "Jubayer Ibn Hamid", "Annie Xie", "Yoonho Lee", "Maximilian Du", "Chelsea Finn"], "title": "Bidirectional Decoding: Improving Action Chunking via Guided Test-Time Sampling", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Project website: https://bid-robot.github.io/", "summary": "Predicting and executing a sequence of actions without intermediate\nreplanning, known as action chunking, is increasingly used in robot learning\nfrom human demonstrations. Yet, its effects on the learned policy remain\ninconsistent: some studies find it crucial for achieving strong results, while\nothers observe decreased performance. In this paper, we first dissect how\naction chunking impacts the divergence between a learner and a demonstrator. We\nfind that action chunking allows the learner to better capture the temporal\ndependencies in demonstrations but at the cost of reduced reactivity to\nunexpected states. To address this tradeoff, we propose Bidirectional Decoding\n(BID), a test-time inference algorithm that bridges action chunking with\nclosed-loop adaptation. At each timestep, BID samples multiple candidate\npredictions and searches for the optimal one based on two criteria: (i)\nbackward coherence, which favors samples that align with previous decisions;\n(ii) forward contrast, which seeks samples of high likelihood for future plans.\nBy coupling decisions within and across action chunks, BID promotes both\nlong-term consistency and short-term reactivity. Experimental results show that\nour method boosts the performance of two state-of-the-art generative policies\nacross seven simulation benchmarks and two real-world tasks. Code and videos\nare available at https://bid-robot.github.io."}
{"id": "2504.18241", "pdf": "https://arxiv.org/pdf/2504.18241", "abs": "https://arxiv.org/abs/2504.18241", "authors": ["Surajit Majumder", "Paritosh Ranjan", "Prodip Roy", "Bhuban Padhan"], "title": "Switch-Based Multi-Part Neural Network", "categories": ["cs.NE", "cs.LG"], "comment": "12 pages, 4 figures", "summary": "This paper introduces decentralized and modular neural network framework\ndesigned to enhance the scalability, interpretability, and performance of\nartificial intelligence (AI) systems. At the heart of this framework is a\ndynamic switch mechanism that governs the selective activation and training of\nindividual neurons based on input characteristics, allowing neurons to\nspecialize in distinct segments of the data domain. This approach enables\nneurons to learn from disjoint subsets of data, mimicking biological brain\nfunction by promoting task specialization and improving the interpretability of\nneural network behavior. Furthermore, the paper explores the application of\nfederated learning and decentralized training for real-world AI deployments,\nparticularly in edge computing and distributed environments. By simulating\nlocalized training on non-overlapping data subsets, we demonstrate how modular\nnetworks can be efficiently trained and evaluated. The proposed framework also\naddresses scalability, enabling AI systems to handle large datasets and\ndistributed processing while preserving model transparency and\ninterpretability. Finally, we discuss the potential of this approach in\nadvancing the design of scalable, privacy-preserving, and efficient AI systems\nfor diverse applications."}
{"id": "2405.16874", "pdf": "https://arxiv.org/pdf/2405.16874", "abs": "https://arxiv.org/abs/2405.16874", "authors": ["Xingqun Qi", "Hengyuan Zhang", "Yatian Wang", "Jiahao Pan", "Chen Liu", "Peng Li", "Xiaowei Chi", "Mengfei Li", "Wei Xue", "Shanghang Zhang", "Wenhan Luo", "Qifeng Liu", "Yike Guo"], "title": "CoCoGesture: Toward Coherent Co-speech 3D Gesture Generation in the Wild", "categories": ["cs.CV"], "comment": "After the submission of the paper, we realized that the study still\n  has room for expansion. In order to make the research findings more profound\n  and comprehensive, we have decided to withdraw the paper so that we can\n  conduct further research and expansion", "summary": "Deriving co-speech 3D gestures has seen tremendous progress in virtual avatar\nanimation. Yet, the existing methods often produce stiff and unreasonable\ngestures with unseen human speech inputs due to the limited 3D speech-gesture\ndata. In this paper, we propose CoCoGesture, a novel framework enabling vivid\nand diverse gesture synthesis from unseen human speech prompts. Our key insight\nis built upon the custom-designed pretrain-fintune training paradigm. At the\npretraining stage, we aim to formulate a large generalizable gesture diffusion\nmodel by learning the abundant postures manifold. Therefore, to alleviate the\nscarcity of 3D data, we first construct a large-scale co-speech 3D gesture\ndataset containing more than 40M meshed posture instances across 4.3K speakers,\ndubbed GES-X. Then, we scale up the large unconditional diffusion model to 1B\nparameters and pre-train it to be our gesture experts. At the finetune stage,\nwe present the audio ControlNet that incorporates the human voice as condition\nprompts to guide the gesture generation. Here, we construct the audio\nControlNet through a trainable copy of our pre-trained diffusion model.\nMoreover, we design a novel Mixture-of-Gesture-Experts (MoGE) block to\nadaptively fuse the audio embedding from the human speech and the gesture\nfeatures from the pre-trained gesture experts with a routing mechanism. Such an\neffective manner ensures audio embedding is temporal coordinated with motion\nfeatures while preserving the vivid and diverse gesture generation. Extensive\nexperiments demonstrate that our proposed CoCoGesture outperforms the\nstate-of-the-art methods on the zero-shot speech-to-gesture generation. The\ndataset will be publicly available at: https://mattie-e.github.io/GES-X/"}
{"id": "2409.12447", "pdf": "https://arxiv.org/pdf/2409.12447", "abs": "https://arxiv.org/abs/2409.12447", "authors": ["Jenny T. Liang", "Melissa Lin", "Nikitha Rao", "Brad A. Myers"], "title": "Prompts Are Programs Too! Understanding How Developers Build Software Containing Prompts", "categories": ["cs.SE", "cs.AI", "cs.HC"], "comment": "Accepted to FSE'25", "summary": "Generative pre-trained models power intelligent software features used by\nmillions of users controlled by developer-written natural language prompts.\nDespite the impact of prompt-powered software, little is known about its\ndevelopment process and its relationship to programming. In this work, we argue\nthat some prompts are programs and that the development of prompts is a\ndistinct phenomenon in programming known as \"prompt programming\". We develop an\nunderstanding of prompt programming using Straussian grounded theory through\ninterviews with 20 developers engaged in prompt development across a variety of\ncontexts, models, domains, and prompt structures. We contribute 15 observations\nto form a preliminary understanding of current prompt programming practices.\nFor example, rather than building mental models of code, prompt programmers\ndevelop mental models of the foundation model (FM)'s behavior on the prompt by\ninteracting with the FM. While prior research shows that experts have\nwell-formed mental models, we find that prompt programmers who have developed\ndozens of prompts still struggle to develop reliable mental models. Our\nobservations show that prompt programming differs from traditional software\ndevelopment, motivating the creation of prompt programming tools and providing\nimplications for software engineering stakeholders."}
{"id": "2504.18273", "pdf": "https://arxiv.org/pdf/2504.18273", "abs": "https://arxiv.org/abs/2504.18273", "authors": ["Jonathan Kouchly", "Ben Finkelshtein", "Michael Bronstein", "Ron Levie"], "title": "Efficient Learning on Large Graphs using a Densifying Regularity Lemma", "categories": ["cs.SI", "cs.LG"], "comment": null, "summary": "Learning on large graphs presents significant challenges, with traditional\nMessage Passing Neural Networks suffering from computational and memory costs\nscaling linearly with the number of edges. We introduce the Intersecting Block\nGraph (IBG), a low-rank factorization of large directed graphs based on\ncombinations of intersecting bipartite components, each consisting of a pair of\ncommunities, for source and target nodes. By giving less weight to non-edges,\nwe show how to efficiently approximate any graph, sparse or dense, by a dense\nIBG. Specifically, we prove a constructive version of the weak regularity\nlemma, showing that for any chosen accuracy, every graph, regardless of its\nsize or sparsity, can be approximated by a dense IBG whose rank depends only on\nthe accuracy. This dependence of the rank solely on the accuracy, and not on\nthe sparsity level, is in contrast to previous forms of the weak regularity\nlemma. We present a graph neural network architecture operating on the IBG\nrepresentation of the graph and demonstrating competitive performance on node\nclassification, spatio-temporal graph analysis, and knowledge graph completion,\nwhile having memory and computational complexity linear in the number of nodes\nrather than edges."}
{"id": "2406.18037", "pdf": "https://arxiv.org/pdf/2406.18037", "abs": "https://arxiv.org/abs/2406.18037", "authors": ["Dunyuan Xu", "Xi Wang", "Jingyang Zhang", "Pheng-Ann Heng"], "title": "Towards Synchronous Memorizability and Generalizability with Site-Modulated Diffusion Replay for Cross-Site Continual Segmentation", "categories": ["cs.CV"], "comment": "This paper is not proper to be published on arXiv, since we think\n  some method are quite similar with one other paper", "summary": "The ability to learn sequentially from different data sites is crucial for a\ndeep network in solving practical medical image diagnosis problems due to\nprivacy restrictions and storage limitations. However, adapting on incoming\nsite leads to catastrophic forgetting on past sites and decreases\ngeneralizablity on unseen sites. Existing Continual Learning (CL) and Domain\nGeneralization (DG) methods have been proposed to solve these two challenges\nrespectively, but none of them can address both simultaneously. Recognizing\nthis limitation, this paper proposes a novel training paradigm, learning\ntowards Synchronous Memorizability and Generalizability (SMG-Learning). To\nachieve this, we create the orientational gradient alignment to ensure\nmemorizability on previous sites, and arbitrary gradient alignment to enhance\ngeneralizability on unseen sites. This approach is named as Parallel Gradient\nAlignment (PGA). Furthermore, we approximate the PGA as dual meta-objectives\nusing the first-order Taylor expansion to reduce computational cost of aligning\ngradients. Considering that performing gradient alignments, especially for\nprevious sites, is not feasible due to the privacy constraints, we design a\nSite-Modulated Diffusion (SMD) model to generate images with site-specific\nlearnable prompts, replaying images have similar data distributions as previous\nsites. We evaluate our method on two medical image segmentation tasks, where\ndata from different sites arrive sequentially. Experimental results show that\nour method efficiently enhances both memorizability and generalizablity better\nthan other state-of-the-art methods, delivering satisfactory performance across\nall sites. Our code will be available at:\nhttps://github.com/dyxu-cuhkcse/SMG-Learning."}
{"id": "2409.16048", "pdf": "https://arxiv.org/pdf/2409.16048", "abs": "https://arxiv.org/abs/2409.16048", "authors": ["Tifanny Portela", "Andrei Cramariuc", "Mayank Mittal", "Marco Hutter"], "title": "Whole-body End-Effector Pose Tracking", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Combining manipulation with the mobility of legged robots is essential for a\nwide range of robotic applications. However, integrating an arm with a mobile\nbase significantly increases the system's complexity, making precise\nend-effector control challenging. Existing model-based approaches are often\nconstrained by their modeling assumptions, leading to limited robustness.\nMeanwhile, recent Reinforcement Learning (RL) implementations restrict the\narm's workspace to be in front of the robot or track only the position to\nobtain decent tracking accuracy. In this work, we address these limitations by\nintroducing a whole-body RL formulation for end-effector pose tracking in a\nlarge workspace on rough, unstructured terrains. Our proposed method involves a\nterrain-aware sampling strategy for the robot's initial configuration and\nend-effector pose commands, as well as a game-based curriculum to extend the\nrobot's operating range. We validate our approach on the ANYmal quadrupedal\nrobot with a six DoF robotic arm. Through our experiments, we show that the\nlearned controller achieves precise command tracking over a large workspace and\nadapts across varying terrains such as stairs and slopes. On deployment, it\nachieves a pose-tracking error of 2.64 cm and 3.64 degrees, outperforming\nexisting competitive baselines."}
{"id": "2504.18367", "pdf": "https://arxiv.org/pdf/2504.18367", "abs": "https://arxiv.org/abs/2504.18367", "authors": ["Maodong Li", "Jiying Zhang", "Bin Feng", "Wenqi Zeng", "Dechin Chen", "Zhijun Pan", "Yu Li", "Zijing Liu", "Yi Isaac Yang"], "title": "Enhanced Sampling, Public Dataset and Generative Model for Drug-Protein Dissociation Dynamics", "categories": ["physics.comp-ph", "cs.LG", "physics.chem-ph", "q-bio.BM"], "comment": "The code will be accessed from our GitHub repository\n  https://huggingface.co/SZBL-IDEA", "summary": "Drug-protein binding and dissociation dynamics are fundamental to\nunderstanding molecular interactions in biological systems. While many tools\nfor drug-protein interaction studies have emerged, especially artificial\nintelligence (AI)-based generative models, predictive tools on\nbinding/dissociation kinetics and dynamics are still limited. We propose a\nnovel research paradigm that combines molecular dynamics (MD) simulations,\nenhanced sampling, and AI generative models to address this issue. We propose\nan enhanced sampling strategy to efficiently implement the drug-protein\ndissociation process in MD simulations and estimate the free energy surface\n(FES). We constructed a program pipeline of MD simulations based on this\nsampling strategy, thus generating a dataset including 26,612 drug-protein\ndissociation trajectories containing about 13 million frames. We named this\ndissociation dynamics dataset DD-13M and used it to train a deep equivariant\ngenerative model UnbindingFlow, which can generate collision-free dissociation\ntrajectories. The DD-13M database and UnbindingFlow model represent a\nsignificant advancement in computational structural biology, and we anticipate\nits broad applicability in machine learning studies of drug-protein\ninteractions. Our ongoing efforts focus on expanding this methodology to\nencompass a broader spectrum of drug-protein complexes and exploring novel\napplications in pathway prediction."}
{"id": "2408.10581", "pdf": "https://arxiv.org/pdf/2408.10581", "abs": "https://arxiv.org/abs/2408.10581", "authors": ["Lixin Yang", "Licheng Zhong", "Pengxiang Zhu", "Xinyu Zhan", "Junxiao Kong", "Jian Xu", "Cewu Lu"], "title": "Multi-view Hand Reconstruction with a Point-Embedded Transformer", "categories": ["cs.CV"], "comment": "Generalizable multi-view Hand Mesh Reconstruction (HMR) model.\n  Extension of the original work at CVPR2023", "summary": "This work introduces a novel and generalizable multi-view Hand Mesh\nReconstruction (HMR) model, named POEM, designed for practical use in\nreal-world hand motion capture scenarios. The advances of the POEM model\nconsist of two main aspects. First, concerning the modeling of the problem, we\npropose embedding a static basis point within the multi-view stereo space. A\npoint represents a natural form of 3D information and serves as an ideal medium\nfor fusing features across different views, given its varied projections across\nthese views. Consequently, our method harnesses a simple yet effective idea: a\ncomplex 3D hand mesh can be represented by a set of 3D basis points that 1) are\nembedded in the multi-view stereo, 2) carry features from the multi-view\nimages, and 3) encompass the hand in it. The second advance lies in the\ntraining strategy. We utilize a combination of five large-scale multi-view\ndatasets and employ randomization in the number, order, and poses of the\ncameras. By processing such a vast amount of data and a diverse array of camera\nconfigurations, our model demonstrates notable generalizability in the\nreal-world applications. As a result, POEM presents a highly practical,\nplug-and-play solution that enables user-friendly, cost-effective multi-view\nmotion capture for both left and right hands. The model and source codes are\navailable at https://github.com/JubSteven/POEM-v2."}
{"id": "2411.06018", "pdf": "https://arxiv.org/pdf/2411.06018", "abs": "https://arxiv.org/abs/2411.06018", "authors": ["Haoxin Liu", "Chenghao Liu", "B. Aditya Prakash"], "title": "A Picture is Worth A Thousand Numbers: Enabling LLMs Reason about Time Series via Visualization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs), with demonstrated reasoning abilities across\nmultiple domains, are largely underexplored for time-series reasoning (TsR),\nwhich is ubiquitous in the real world. In this work, we propose TimerBed, the\nfirst comprehensive testbed for evaluating LLMs' TsR performance. Specifically,\nTimerBed includes stratified reasoning patterns with real-world tasks,\ncomprehensive combinations of LLMs and reasoning strategies, and various\nsupervised models as comparison anchors. We perform extensive experiments with\nTimerBed, test multiple current beliefs, and verify the initial failures of\nLLMs in TsR, evidenced by the ineffectiveness of zero shot (ZST) and\nperformance degradation of few shot in-context learning (ICL). Further, we\nidentify one possible root cause: the numerical modeling of data. To address\nthis, we propose a prompt-based solution VL-Time, using visualization-modeled\ndata and language-guided reasoning. Experimental results demonstrate that\nVl-Time enables multimodal LLMs to be non-trivial ZST and powerful ICL\nreasoners for time series, achieving about 140% average performance improvement\nand 99% average token costs reduction."}
{"id": "2504.18444", "pdf": "https://arxiv.org/pdf/2504.18444", "abs": "https://arxiv.org/abs/2504.18444", "authors": ["Vinay Kanakeri", "Aritra Mitra"], "title": "Boosting-Enabled Robust System Identification of Partially Observed LTI Systems Under Heavy-Tailed Noise", "categories": ["eess.SY", "cs.LG", "cs.SY", "math.OC"], "comment": null, "summary": "We consider the problem of system identification of partially observed linear\ntime-invariant (LTI) systems. Given input-output data, we provide\nnon-asymptotic guarantees for identifying the system parameters under general\nheavy-tailed noise processes. Unlike previous works that assume Gaussian or\nsub-Gaussian noise, we consider significantly broader noise distributions that\nare required to admit only up to the second moment. For this setting, we\nleverage tools from robust statistics to propose a novel system identification\nalgorithm that exploits the idea of boosting. Despite the much weaker noise\nassumptions, we show that our proposed algorithm achieves sample complexity\nbounds that nearly match those derived under sub-Gaussian noise. In particular,\nwe establish that our bounds retain a logarithmic dependence on the prescribed\nfailure probability. Interestingly, we show that such bounds can be achieved by\nrequiring just a finite fourth moment on the excitatory input process."}
{"id": "2408.11748", "pdf": "https://arxiv.org/pdf/2408.11748", "abs": "https://arxiv.org/abs/2408.11748", "authors": ["Shehreen Azad", "Yash Jain", "Rishit Garg", "Yogesh S Rawat", "Vibhav Vineet"], "title": "Understanding Depth and Height Perception in Large Visual-Language Models", "categories": ["cs.CV"], "comment": "Accepted in CVPRW 2025. Project page:\n  https://sacrcv.github.io/GeoMeter-website/", "summary": "Geometric understanding - including depth and height perception - is\nfundamental to intelligence and crucial for navigating our environment. Despite\nthe impressive capabilities of large Vision Language Models (VLMs), it remains\nunclear how well they possess the geometric understanding required for\npractical applications in visual perception. In this work, we focus on\nevaluating the geometric understanding of these models, specifically targeting\ntheir ability to perceive the depth and height of objects in an image. To\naddress this, we introduce GeoMeter, a suite of benchmark datasets -\nencompassing 2D and 3D scenarios - to rigorously evaluate these aspects. By\nbenchmarking 18 state-of-the-art VLMs, we found that although they excel in\nperceiving basic geometric properties like shape and size, they consistently\nstruggle with depth and height perception. Our analysis reveal that these\nchallenges stem from shortcomings in their depth and height reasoning\ncapabilities and inherent biases. This study aims to pave the way for\ndeveloping VLMs with enhanced geometric understanding by emphasizing depth and\nheight perception as critical components necessary for real-world applications."}
{"id": "2411.12633", "pdf": "https://arxiv.org/pdf/2411.12633", "abs": "https://arxiv.org/abs/2411.12633", "authors": ["Vitalis Vosylius", "Edward Johns"], "title": "Instant Policy: In-Context Imitation Learning via Graph Diffusion", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "Code and videos are available on our project webpage at\n  https://www.robot-learning.uk/instant-policy", "summary": "Following the impressive capabilities of in-context learning with large\ntransformers, In-Context Imitation Learning (ICIL) is a promising opportunity\nfor robotics. We introduce Instant Policy, which learns new tasks instantly\n(without further training) from just one or two demonstrations, achieving ICIL\nthrough two key components. First, we introduce inductive biases through a\ngraph representation and model ICIL as a graph generation problem with a\nlearned diffusion process, enabling structured reasoning over demonstrations,\nobservations, and actions. Second, we show that such a model can be trained\nusing pseudo-demonstrations - arbitrary trajectories generated in simulation -\nas a virtually infinite pool of training data. Simulated and real experiments\nshow that Instant Policy enables rapid learning of various everyday robot\ntasks. We also show how it can serve as a foundation for cross-embodiment and\nzero-shot transfer to language-defined tasks. Code and videos are available at\nhttps://www.robot-learning.uk/instant-policy."}
{"id": "2504.18455", "pdf": "https://arxiv.org/pdf/2504.18455", "abs": "https://arxiv.org/abs/2504.18455", "authors": ["Milad Sefidgaran", "Abdellatif Zaidi", "Piotr Krasnowski"], "title": "Generalization Guarantees for Multi-View Representation Learning and Application to Regularization via Gaussian Product Mixture Prior", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT"], "comment": "arXiv admin note: substantial text overlap with arXiv:2502.15540", "summary": "We study the problem of distributed multi-view representation learning. In\nthis problem, $K$ agents observe each one distinct, possibly statistically\ncorrelated, view and independently extracts from it a suitable representation\nin a manner that a decoder that gets all $K$ representations estimates\ncorrectly the hidden label. In the absence of any explicit coordination between\nthe agents, a central question is: what should each agent extract from its view\nthat is necessary and sufficient for a correct estimation at the decoder? In\nthis paper, we investigate this question from a generalization error\nperspective. First, we establish several generalization bounds in terms of the\nrelative entropy between the distribution of the representations extracted from\ntraining and \"test\" datasets and a data-dependent symmetric prior, i.e., the\nMinimum Description Length (MDL) of the latent variables for all views and\ntraining and test datasets. Then, we use the obtained bounds to devise a\nregularizer; and investigate in depth the question of the selection of a\nsuitable prior. In particular, we show and conduct experiments that illustrate\nthat our data-dependent Gaussian mixture priors with judiciously chosen weights\nlead to good performance. For single-view settings (i.e., $K=1$), our\nexperimental results are shown to outperform existing prior art Variational\nInformation Bottleneck (VIB) and Category-Dependent VIB (CDVIB) approaches.\nInterestingly, we show that a weighted attention mechanism emerges naturally in\nthis setting. Finally, for the multi-view setting, we show that the selection\nof the joint prior as a Gaussians product mixture induces a Gaussian mixture\nmarginal prior for each marginal view and implicitly encourages the agents to\nextract and output redundant features, a finding which is somewhat\ncounter-intuitive."}
{"id": "2408.13632", "pdf": "https://arxiv.org/pdf/2408.13632", "abs": "https://arxiv.org/abs/2408.13632", "authors": ["Lukas Picek", "Klara Janouskova", "Vojtech Cermak", "Jiri Matas"], "title": "FungiTastic: A multi-modal dataset and benchmark for image categorization", "categories": ["cs.CV"], "comment": "FGVC workshop, CVPR 2025", "summary": "We introduce a new, challenging benchmark and a dataset, FungiTastic, based\non fungal records continuously collected over a twenty-year span. The dataset\nis labelled and curated by experts and consists of about 350k multimodal\nobservations of 6k fine-grained categories (species). The fungi observations\ninclude photographs and additional data, e.g., meteorological and climatic\ndata, satellite images, and body part segmentation masks. FungiTastic is one of\nthe few benchmarks that include a test set with DNA-sequenced ground truth of\nunprecedented label reliability. The benchmark is designed to support (i)\nstandard closed-set classification, (ii) open-set classification, (iii)\nmulti-modal classification, (iv) few-shot learning, (v) domain shift, and many\nmore. We provide tailored baselines for many use cases, a multitude of\nready-to-use pre-trained models on\nhttps://huggingface.co/collections/BVRA/fungitastic-66a227ce0520be533dc6403b,\nand a framework for model training. The documentation and the baselines are\navailable at https://github.com/BohemianVRA/FungiTastic/ and\nhttps://www.kaggle.com/datasets/picekl/fungitastic."}
{"id": "2411.16718", "pdf": "https://arxiv.org/pdf/2411.16718", "abs": "https://arxiv.org/abs/2411.16718", "authors": ["S P Sharan", "Minkyu Choi", "Sahil Shah", "Harsh Goel", "Mohammad Omama", "Sandeep Chinchali"], "title": "Neuro-Symbolic Evaluation of Text-to-Video Models using Formal Verification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advancements in text-to-video models such as Sora, Gen-3, MovieGen,\nand CogVideoX are pushing the boundaries of synthetic video generation, with\nadoption seen in fields like robotics, autonomous driving, and entertainment.\nAs these models become prevalent, various metrics and benchmarks have emerged\nto evaluate the quality of the generated videos. However, these metrics\nemphasize visual quality and smoothness, neglecting temporal fidelity and\ntext-to-video alignment, which are crucial for safety-critical applications. To\naddress this gap, we introduce NeuS-V, a novel synthetic video evaluation\nmetric that rigorously assesses text-to-video alignment using neuro-symbolic\nformal verification techniques. Our approach first converts the prompt into a\nformally defined Temporal Logic (TL) specification and translates the generated\nvideo into an automaton representation. Then, it evaluates the text-to-video\nalignment by formally checking the video automaton against the TL\nspecification. Furthermore, we present a dataset of temporally extended prompts\nto evaluate state-of-the-art video generation models against our benchmark. We\nfind that NeuS-V demonstrates a higher correlation by over 5x with human\nevaluations when compared to existing metrics. Our evaluation further reveals\nthat current video generation models perform poorly on these temporally complex\nprompts, highlighting the need for future work in improving text-to-video\ngeneration capabilities."}
{"id": "2504.18461", "pdf": "https://arxiv.org/pdf/2504.18461", "abs": "https://arxiv.org/abs/2504.18461", "authors": ["Stefano Markidis", "Jonah Ekelund", "Luca Pennati", "Andong Hu", "Ivy Peng"], "title": "Discovering Governing Equations of Geomagnetic Storm Dynamics with Symbolic Regression", "categories": ["cs.CE", "cs.LG"], "comment": "Accepted for publication in the 25th International Conference on\n  Computational Science proceedings", "summary": "Geomagnetic storms are large-scale disturbances of the Earth's magnetosphere\ndriven by solar wind interactions, posing significant risks to space-based and\nground-based infrastructure. The Disturbance Storm Time (Dst) index quantifies\ngeomagnetic storm intensity by measuring global magnetic field variations. This\nstudy applies symbolic regression to derive data-driven equations describing\nthe temporal evolution of the Dst index. We use historical data from the NASA\nOMNIweb database, including solar wind density, bulk velocity, convective\nelectric field, dynamic pressure, and magnetic pressure. The PySR framework, an\nevolutionary algorithm-based symbolic regression library, is used to identify\nmathematical expressions linking dDst/dt to key solar wind. The resulting\nmodels include a hierarchy of complexity levels and enable a comparison with\nwell-established empirical models such as the Burton-McPherron-Russell and\nO'Brien-McPherron models. The best-performing symbolic regression models\ndemonstrate superior accuracy in most cases, particularly during moderate\ngeomagnetic storms, while maintaining physical interpretability. Performance\nevaluation on historical storm events includes the 2003 Halloween Storm, the\n2015 St. Patrick's Day Storm, and a 2017 moderate storm. The results provide\ninterpretable, closed-form expressions that capture nonlinear dependencies and\nthresholding effects in Dst evolution."}
{"id": "2410.01535", "pdf": "https://arxiv.org/pdf/2410.01535", "abs": "https://arxiv.org/abs/2410.01535", "authors": ["Shuyi Jiang", "Qihao Zhao", "Hossein Rahmani", "De Wen Soh", "Jun Liu", "Na Zhao"], "title": "GaussianBlock: Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians", "categories": ["cs.CV"], "comment": null, "summary": "Recently, with the development of Neural Radiance Fields and Gaussian\nSplatting, 3D reconstruction techniques have achieved remarkably high fidelity.\nHowever, the latent representations learnt by these methods are highly\nentangled and lack interpretability. In this paper, we propose a novel\npart-aware compositional reconstruction method, called GaussianBlock, that\nenables semantically coherent and disentangled representations, allowing for\nprecise and physical editing akin to building blocks, while simultaneously\nmaintaining high fidelity. Our GaussianBlock introduces a hybrid representation\nthat leverages the advantages of both primitives, known for their flexible\nactionability and editability, and 3D Gaussians, which excel in reconstruction\nquality. Specifically, we achieve semantically coherent primitives through a\nnovel attention-guided centering loss derived from 2D semantic priors,\ncomplemented by a dynamic splitting and fusion strategy. Furthermore, we\nutilize 3D Gaussians that hybridize with primitives to refine structural\ndetails and enhance fidelity. Additionally, a binding inheritance strategy is\nemployed to strengthen and maintain the connection between the two. Our\nreconstructed scenes are evidenced to be disentangled, compositional, and\ncompact across diverse benchmarks, enabling seamless, direct and precise\nediting while maintaining high quality."}
{"id": "2412.04476", "pdf": "https://arxiv.org/pdf/2412.04476", "abs": "https://arxiv.org/abs/2412.04476", "authors": ["Avner Seror"], "title": "The Moral Mind(s) of Large Language Models", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "As large language models (LLMs) increasingly participate in tasks with\nethical and societal stakes, a critical question arises: do they exhibit an\nemergent \"moral mind\" - a consistent structure of moral preferences guiding\ntheir decisions - and to what extent is this structure shared across models? To\ninvestigate this, we applied tools from revealed preference theory to nearly 40\nleading LLMs, presenting each with many structured moral dilemmas spanning five\nfoundational dimensions of ethical reasoning. Using a probabilistic rationality\ntest, we found that at least one model from each major provider exhibited\nbehavior consistent with approximately stable moral preferences, acting as if\nguided by an underlying utility function. We then estimated these utility\nfunctions and found that most models cluster around neutral moral stances. To\nfurther characterize heterogeneity, we employed a non-parametric permutation\napproach, constructing a probabilistic similarity network based on revealed\npreference patterns. The results reveal a shared core in LLMs' moral reasoning,\nbut also meaningful variation: some models show flexible reasoning across\nperspectives, while others adhere to more rigid ethical profiles. These\nfindings provide a new empirical lens for evaluating moral consistency in LLMs\nand offer a framework for benchmarking ethical alignment across AI systems."}
{"id": "2504.18498", "pdf": "https://arxiv.org/pdf/2504.18498", "abs": "https://arxiv.org/abs/2504.18498", "authors": ["Giuseppe Loffredo", "Elvira Romano", "Fabrizio MAturo"], "title": "Enhancing Visual Interpretability and Explainability in Functional Survival Trees and Forests", "categories": ["stat.ML", "cs.LG", "stat.ME", "62N02, 62P10, 62H30, 62G05, 62G08, 62J99", "G.3; I.5.1; I.5.2"], "comment": null, "summary": "Functional survival models are key tools for analyzing time-to-event data\nwith complex predictors, such as functional or high-dimensional inputs. Despite\ntheir predictive strength, these models often lack interpretability, which\nlimits their value in practical decision-making and risk analysis. This study\ninvestigates two key survival models: the Functional Survival Tree (FST) and\nthe Functional Random Survival Forest (FRSF). It introduces novel methods and\ntools to enhance the interpretability of FST models and improve the\nexplainability of FRSF ensembles. Using both real and simulated datasets, the\nresults demonstrate that the proposed approaches yield efficient,\neasy-to-understand decision trees that accurately capture the underlying\ndecision-making processes of the model ensemble."}
{"id": "2410.11041", "pdf": "https://arxiv.org/pdf/2410.11041", "abs": "https://arxiv.org/abs/2410.11041", "authors": ["Federico Nocentini", "Thomas Besnier", "Claudio Ferrari", "Sylvain Arguillere", "Mohamed Daoudi", "Stefano Berretti"], "title": "Beyond Fixed Topologies: Unregistered Training and Comprehensive Evaluation Metrics for 3D Talking Heads", "categories": ["cs.CV"], "comment": "https://fedenoce.github.io/scantalk/", "summary": "Generating speech-driven 3D talking heads presents numerous challenges; among\nthose is dealing with varying mesh topologies where no point-wise\ncorrespondence exists across all meshes the model can animate. While\nsimplifying the problem, it limits applicability as unseen meshes must adhere\nto the training topology. This work presents a framework capable of animating\n3D faces in arbitrary topologies, including real scanned data. Our approach\nrelies on a model leveraging heat diffusion to predict features robust to the\nmesh topology. We explore two training settings: a registered one, in which\nmeshes in a training sequences share a fixed topology but any mesh can be\nanimated at test time, and an fully unregistered one, which allows effective\ntraining with varying mesh structures. Additionally, we highlight the\nlimitations of current evaluation metrics and propose new metrics for better\nlip-syncing evaluation between speech and facial movements. Our extensive\nevaluation shows our approach performs favorably compared to fixed topology\ntechniques, setting a new benchmark by offering a versatile and high-fidelity\nsolution for 3D talking head generation where the topology constraint is\ndropped."}
{"id": "2501.00057", "pdf": "https://arxiv.org/pdf/2501.00057", "abs": "https://arxiv.org/abs/2501.00057", "authors": ["Witold Wydma≈Ñski", "Ulvi Movsum-zada", "Jacek Tabor", "Marek ≈ömieja"], "title": "VisTabNet: Adapting Vision Transformers for Tabular Data", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Although deep learning models have had great success in natural language\nprocessing and computer vision, we do not observe comparable improvements in\nthe case of tabular data, which is still the most common data type used in\nbiological, industrial and financial applications. In particular, it is\nchallenging to transfer large-scale pre-trained models to downstream tasks\ndefined on small tabular datasets. To address this, we propose VisTabNet -- a\ncross-modal transfer learning method, which allows for adapting Vision\nTransformer (ViT) with pre-trained weights to process tabular data. By\nprojecting tabular inputs to patch embeddings acceptable by ViT, we can\ndirectly apply a pre-trained Transformer Encoder to tabular inputs. This\napproach eliminates the conceptual cost of designing a suitable architecture\nfor processing tabular data, while reducing the computational cost of training\nthe model from scratch. Experimental results on multiple small tabular datasets\n(less than 1k samples) demonstrate VisTabNet's superiority, outperforming both\ntraditional ensemble methods and recent deep learning models. The proposed\nmethod goes beyond conventional transfer learning practice and shows that\npre-trained image models can be transferred to solve tabular problems,\nextending the boundaries of transfer learning. We share our example\nimplementation as a GitHub repository available at\nhttps://github.com/wwydmanski/VisTabNet."}
{"id": "2504.18513", "pdf": "https://arxiv.org/pdf/2504.18513", "abs": "https://arxiv.org/abs/2504.18513", "authors": ["Zilan Cheng", "Zhongjian Wang", "Li-Lian Wang", "Mejdi Azaiez"], "title": "PODNO: Proper Orthogonal Decomposition Neural Operators", "categories": ["math.NA", "cs.LG", "cs.NA", "physics.comp-ph", "68T07, 65M12, 41A35, 65N99"], "comment": null, "summary": "In this paper, we introduce Proper Orthogonal Decomposition Neural Operators\n(PODNO) for solving partial differential equations (PDEs) dominated by\nhigh-frequency components. Building on the structure of Fourier Neural\nOperators (FNO), PODNO replaces the Fourier transform with (inverse)\northonormal transforms derived from the Proper Orthogonal Decomposition (POD)\nmethod to construct the integral kernel. Due to the optimality of POD basis,\nthe PODNO has potential to outperform FNO in both accuracy and computational\nefficiency for high-frequency problems. From analysis point of view, we\nestablished the universality of a generalization of PODNO, termed as\nGeneralized Spectral Operator (GSO). In addition, we evaluate PODNO's\nperformance numerically on dispersive equations such as the Nonlinear\nSchrodinger (NLS) equation and the Kadomtsev-Petviashvili (KP) equation."}
{"id": "2410.13807", "pdf": "https://arxiv.org/pdf/2410.13807", "abs": "https://arxiv.org/abs/2410.13807", "authors": ["Junhao Gu", "Peng-Tao Jiang", "Hao Zhang", "Mi Zhou", "Jinwei Chen", "Wenming Yang", "Bo Li"], "title": "Improving Consistency in Diffusion Models for Image Super-Resolution", "categories": ["cs.CV"], "comment": null, "summary": "Recent methods exploit the powerful text-to-image (T2I) diffusion models for\nreal-world image super-resolution (Real-ISR) and achieve impressive results\ncompared to previous models. However, we observe two kinds of inconsistencies\nin diffusion-based methods which hinder existing models from fully exploiting\ndiffusion priors. The first is the semantic inconsistency arising from\ndiffusion guidance. T2I generation focuses on semantic-level consistency with\ntext prompts, while Real-ISR emphasizes pixel-level reconstruction from\nlow-quality (LQ) images, necessitating more detailed semantic guidance from LQ\ninputs. The second is the training-inference inconsistency stemming from the\nDDPM, which improperly assumes high-quality (HQ) latent corrupted by Gaussian\nnoise as denoising inputs for each timestep. To address these issues, we\nintroduce ConsisSR to handle both semantic and training-inference\nconsistencies. On the one hand, to address the semantic inconsistency, we\nproposed a Hybrid Prompt Adapter (HPA). Instead of text prompts with\ncoarse-grained classification information, we leverage the more powerful CLIP\nimage embeddings to explore additional color and texture guidance. On the other\nhand, we introduce Time-Aware Latent Augmentation (TALA) to bridge the\ntraining-inference inconsistency. Based on the probability function p(t), we\naccordingly enhance the SDSR training strategy. With LQ latent with Gaussian\nnoise as inputs, our TALA not only focuses on diffusion noise but also refine\nthe LQ latent towards the HQ counterpart. Our method demonstrates\nstate-of-the-art performance among existing diffusion models. The code will be\nmade publicly available."}
{"id": "2501.01454", "pdf": "https://arxiv.org/pdf/2501.01454", "abs": "https://arxiv.org/abs/2501.01454", "authors": ["Shane Babcock", "Carter Benson", "Giacomo De Colle", "Sydney Cohen", "Alexander D. Diehl", "Ram A. N. R. Challa", "Ray Mavrovich", "Joshua Billig", "Anthony Huffman", "Yongqun He", "John Beverley"], "title": "A Fourfold Pathogen Reference Ontology Suite", "categories": ["q-bio.OT", "cs.AI", "cs.LO"], "comment": "25 pages", "summary": "Infectious diseases remain a critical global health challenge, and the\nintegration of standardized ontologies plays a vital role in managing related\ndata. The Infectious Disease Ontology (IDO) and its extensions, such as the\nCoronavirus Infectious Disease Ontology (CIDO), are essential for organizing\nand disseminating information related to infectious diseases. The COVID-19\npandemic highlighted the need for updating IDO and its virus-specific\nextensions. There is an additional need to update IDO extensions specific to\nbacteria, fungus, and parasite infectious diseases. We adopt the \"hub and\nspoke\" methodology to generate pathogen-specific extensions of IDO: Virus\nInfectious Disease Ontology (VIDO), Bacteria Infectious Disease Ontology\n(BIDO), Mycosis Infectious Disease Ontology (MIDO), and Parasite Infectious\nDisease Ontology (PIDO). The creation of pathogen-specific reference ontologies\nadvances modularization and reusability of infectious disease data within the\nIDO ecosystem. Future work will focus on further refining these ontologies,\ncreating new extensions, and developing application ontologies based on them,\nin line with ongoing efforts to standardize biological and biomedical\nterminologies for improved data sharing and analysis."}
{"id": "2504.18522", "pdf": "https://arxiv.org/pdf/2504.18522", "abs": "https://arxiv.org/abs/2504.18522", "authors": ["Julius von K√ºgelgen", "Jakob Ketterer", "Xinwei Shen", "Nicolai Meinshausen", "Jonas Peters"], "title": "Representation Learning for Distributional Perturbation Extrapolation", "categories": ["stat.ML", "cs.LG"], "comment": "Preprint; work presented at the ICLR Workshop on Learning Meaningful\n  Representations of Life", "summary": "We consider the problem of modelling the effects of unseen perturbations such\nas gene knockdowns or drug combinations on low-level measurements such as RNA\nsequencing data. Specifically, given data collected under some perturbations,\nwe aim to predict the distribution of measurements for new perturbations. To\naddress this challenging extrapolation task, we posit that perturbations act\nadditively in a suitable, unknown embedding space. More precisely, we formulate\nthe generative process underlying the observed data as a latent variable model,\nin which perturbations amount to mean shifts in latent space and can be\ncombined additively. Unlike previous work, we prove that, given sufficiently\ndiverse training perturbations, the representation and perturbation effects are\nidentifiable up to affine transformation, and use this to characterize the\nclass of unseen perturbations for which we obtain extrapolation guarantees. To\nestimate the model from data, we propose a new method, the perturbation\ndistribution autoencoder (PDAE), which is trained by maximising the\ndistributional similarity between true and predicted perturbation\ndistributions. The trained model can then be used to predict previously unseen\nperturbation distributions. Empirical evidence suggests that PDAE compares\nfavourably to existing methods and baselines at predicting the effects of\nunseen perturbations."}
{"id": "2410.21665", "pdf": "https://arxiv.org/pdf/2410.21665", "abs": "https://arxiv.org/abs/2410.21665", "authors": ["Chen Chen", "Daochang Liu", "Mubarak Shah", "Chang Xu"], "title": "Exploring Local Memorization in Diffusion Models via Bright Ending Attention", "categories": ["cs.CV"], "comment": "Accepted at ICLR 2025 (Spotlight). Project page:\n  https://chenchen-usyd.github.io/BE-Project-Page/", "summary": "Text-to-image diffusion models have achieved unprecedented proficiency in\ngenerating realistic images. However, their inherent tendency to memorize and\nreplicate training data during inference raises significant concerns, including\npotential copyright infringement. In response, various methods have been\nproposed to evaluate, detect, and mitigate memorization. Our analysis reveals\nthat existing approaches significantly underperform in handling local\nmemorization, where only specific image regions are memorized, compared to\nglobal memorization, where the entire image is replicated. Also, they cannot\nlocate the local memorization regions, making it hard to investigate locally.\nTo address these, we identify a novel \"bright ending\" (BE) anomaly in diffusion\nmodels prone to memorizing training images. BE refers to a distinct\ncross-attention pattern observed in text-to-image diffusion models, where\nmemorized image patches exhibit significantly greater attention to the final\ntext token during the last inference step than non-memorized patches. This\npattern highlights regions where the generated image replicates training data\nand enables efficient localization of memorized regions. Equipped with this, we\npropose a simple yet effective method to integrate BE into existing frameworks,\nsignificantly improving their performance by narrowing the performance gap\ncaused by local memorization. Our results not only validate the successful\nexecution of the new localization task but also establish new state-of-the-art\nperformance across all existing tasks, underscoring the significance of the BE\nphenomenon."}
{"id": "2501.10917", "pdf": "https://arxiv.org/pdf/2501.10917", "abs": "https://arxiv.org/abs/2501.10917", "authors": ["Haoyu Xie", "Haoxuan Li", "Chunyuan Zheng", "Haonan Yuan", "Guorui Liao", "Jun Liao", "Li Liu"], "title": "Decomposing and Fusing Intra- and Inter-Sensor Spatio-Temporal Signal for Multi-Sensor Wearable Human Activity Recognition", "categories": ["cs.CV", "cs.AI", "cs.HC"], "comment": null, "summary": "Wearable Human Activity Recognition (WHAR) is a prominent research area\nwithin ubiquitous computing. Multi-sensor synchronous measurement has proven to\nbe more effective for WHAR than using a single sensor. However, existing WHAR\nmethods use shared convolutional kernels for indiscriminate temporal feature\nextraction across each sensor variable, which fails to effectively capture\nspatio-temporal relationships of intra-sensor and inter-sensor variables. We\npropose the DecomposeWHAR model consisting of a decomposition phase and a\nfusion phase to better model the relationships between modality variables. The\ndecomposition creates high-dimensional representations of each intra-sensor\nvariable through the improved Depth Separable Convolution to capture local\ntemporal features while preserving their unique characteristics. The fusion\nphase begins by capturing relationships between intra-sensor variables and\nfusing their features at both the channel and variable levels. Long-range\ntemporal dependencies are modeled using the State Space Model (SSM), and later\ncross-sensor interactions are dynamically captured through a self-attention\nmechanism, highlighting inter-sensor spatial correlations. Our model\ndemonstrates superior performance on three widely used WHAR datasets,\nsignificantly outperforming state-of-the-art models while maintaining\nacceptable computational efficiency."}
{"id": "2410.21669", "pdf": "https://arxiv.org/pdf/2410.21669", "abs": "https://arxiv.org/abs/2410.21669", "authors": ["Chen Chen", "Enhuai Liu", "Daochang Liu", "Mubarak Shah", "Chang Xu"], "title": "Investigating Memorization in Video Diffusion Models", "categories": ["cs.CV"], "comment": "Accepted at DATA-FM Workshop @ ICLR 2025", "summary": "Diffusion models, widely used for image and video generation, face a\nsignificant limitation: the risk of memorizing and reproducing training data\nduring inference, potentially generating unauthorized copyrighted content.\nWhile prior research has focused on image diffusion models (IDMs), video\ndiffusion models (VDMs) remain underexplored. To address this gap, we first\nformally define the two types of memorization in VDMs (content memorization and\nmotion memorization) in a practical way that focuses on privacy preservation\nand applies to all generation types. We then introduce new metrics specifically\ndesigned to separately assess content and motion memorization in VDMs.\nAdditionally, we curate a dataset of text prompts that are most prone to\ntriggering memorization when used as conditioning in VDMs. By leveraging these\nprompts, we generate diverse videos from various open-source VDMs, successfully\nextracting numerous training videos from each tested model. Through the\napplication of our proposed metrics, we systematically analyze memorization\nacross various pretrained VDMs, including text-conditional and unconditional\nmodels, on a variety of datasets. Our comprehensive study reveals that\nmemorization is widespread across all tested VDMs, indicating that VDMs can\nalso memorize image training data in addition to video datasets. Finally, we\npropose efficient and effective detection strategies for both content and\nmotion memorization, offering a foundational approach for improving privacy in\nVDMs."}
{"id": "2501.13992", "pdf": "https://arxiv.org/pdf/2501.13992", "abs": "https://arxiv.org/abs/2501.13992", "authors": ["Hy Nguyen", "Nguyen Hung Nguyen", "Nguyen Linh Bao Nguyen", "Srikanth Thudumu", "Hung Du", "Rajesh Vasa", "Kon Mouzakis"], "title": "Dual-Branch HNSW Approach with Skip Bridges and LID-Driven Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The Hierarchical Navigable Small World (HNSW) algorithm is widely used for\napproximate nearest neighbor (ANN) search, leveraging the principles of\nnavigable small-world graphs. However, it faces some limitations. The first is\nthe local optima problem, which arises from the algorithm's greedy search\nstrategy, selecting neighbors based solely on proximity at each step. This\noften leads to cluster disconnections. The second limitation is that HNSW\nfrequently fails to achieve logarithmic complexity, particularly in\nhigh-dimensional datasets, due to the exhaustive traversal through each layer.\nTo address these limitations, we propose a novel algorithm that mitigates local\noptima and cluster disconnections while enhancing the construction speed,\nmaintaining inference speed. The first component is a dual-branch HNSW\nstructure with LID-based insertion mechanisms, enabling traversal from multiple\ndirections. This improves outlier node capture, enhances cluster connectivity,\naccelerates construction speed and reduces the risk of local minima. The second\ncomponent incorporates a bridge-building technique that bypasses redundant\nintermediate layers, maintaining inference and making up the additional\ncomputational overhead introduced by the dual-branch structure. Experiments on\nvarious benchmarks and datasets showed that our algorithm outperforms the\noriginal HNSW in both accuracy and speed. We evaluated six datasets across\nComputer Vision (CV), and Natural Language Processing (NLP), showing recall\nimprovements of 18\\% in NLP, and up to 30\\% in CV tasks while reducing the\nconstruction time by up to 20\\% and maintaining the inference speed. We did not\nobserve any trade-offs in our algorithm. Ablation studies revealed that\nLID-based insertion had the greatest impact on performance, followed by the\ndual-branch structure and bridge-building components."}
{"id": "2402.03985", "pdf": "https://arxiv.org/pdf/2402.03985", "abs": "https://arxiv.org/abs/2402.03985", "authors": ["Ossi R√§is√§", "Antti Honkela"], "title": "A Bias-Variance Decomposition for Ensembles over Multiple Synthetic Datasets", "categories": ["cs.LG", "stat.ML"], "comment": "AISTATS 2025", "summary": "Recent studies have highlighted the benefits of generating multiple synthetic\ndatasets for supervised learning, from increased accuracy to more effective\nmodel selection and uncertainty estimation. These benefits have clear empirical\nsupport, but the theoretical understanding of them is currently very light. We\nseek to increase the theoretical understanding by deriving bias-variance\ndecompositions for several settings of using multiple synthetic datasets,\nincluding differentially private synthetic data. Our theory yields a simple\nrule of thumb to select the appropriate number of synthetic datasets in the\ncase of mean-squared error and Brier score. We investigate how our theory works\nin practice with several real datasets, downstream predictors and error\nmetrics. As our theory predicts, multiple synthetic datasets often improve\naccuracy, while a single large synthetic dataset gives at best minimal\nimprovement, showing that our insights are practically relevant."}
{"id": "2411.12792", "pdf": "https://arxiv.org/pdf/2411.12792", "abs": "https://arxiv.org/abs/2411.12792", "authors": ["Shipeng Liu", "Liang Zhao", "Dengfeng Chen"], "title": "CLIC: Contrastive Learning Framework for Unsupervised Image Complexity Representation", "categories": ["cs.CV"], "comment": "under review", "summary": "As a fundamental visual attribute, image complexity significantly influences\nboth human perception and the performance of computer vision models. However,\naccurately assessing and quantifying image complexity remains a challenging\ntask. (1) Traditional metrics such as information entropy and compression ratio\noften yield coarse and unreliable estimates. (2) Data-driven methods require\nexpensive manual annotations and are inevitably affected by human subjective\nbiases. To address these issues, we propose CLIC, an unsupervised framework\nbased on Contrastive Learning for learning Image Complexity representations.\nCLIC learns complexity-aware features from unlabeled data, thereby eliminating\nthe need for costly labeling. Specifically, we design a novel positive and\nnegative sample selection strategy to enhance the discrimination of complexity\nfeatures. Additionally, we introduce a complexity-aware loss function guided by\nimage priors to further constrain the learning process. Extensive experiments\nvalidate the effectiveness of CLIC in capturing image complexity. When\nfine-tuned with a small number of labeled samples from IC9600, CLIC achieves\nperformance competitive with supervised methods. Moreover, applying CLIC to\ndownstream tasks consistently improves performance. Notably, both the\npretraining and application processes of CLIC are free from subjective bias."}
{"id": "2501.14000", "pdf": "https://arxiv.org/pdf/2501.14000", "abs": "https://arxiv.org/abs/2501.14000", "authors": ["Hy Nguyen", "Duy Khoa Pham", "Srikanth Thudumu", "Hung Du", "Rajesh Vasa", "Kon Mouzakis"], "title": "Local Control Networks (LCNs): Optimizing Flexibility in Neural Network Data Pattern Capture", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The widespread use of Multi-layer perceptrons (MLPs) often relies on a fixed\nactivation function (e.g., ReLU, Sigmoid, Tanh) for all nodes within the hidden\nlayers. While effective in many scenarios, this uniformity may limit the\nnetworks ability to capture complex data patterns. We argue that employing the\nsame activation function at every node is suboptimal and propose leveraging\ndifferent activation functions at each node to increase flexibility and\nadaptability. To achieve this, we introduce Local Control Networks (LCNs),\nwhich leverage B-spline functions to enable distinct activation curves at each\nnode. Our mathematical analysis demonstrates the properties and benefits of\nLCNs over conventional MLPs. In addition, we demonstrate that more complex\narchitectures, such as Kolmogorov-Arnold Networks (KANs), are unnecessary in\ncertain scenarios, and LCNs can be a more efficient alternative. Empirical\nexperiments on various benchmarks and datasets validate our theoretical\nfindings. In computer vision tasks, LCNs achieve marginal improvements over\nMLPs and outperform KANs by approximately 5\\%, while also being more\ncomputationally efficient than KANs. In basic machine learning tasks, LCNs show\na 1\\% improvement over MLPs and a 0.6\\% improvement over KANs. For symbolic\nformula representation tasks, LCNs perform on par with KANs, with both\narchitectures outperforming MLPs. Our findings suggest that diverse activations\nat the node level can lead to improved performance and efficiency."}
{"id": "2405.19548", "pdf": "https://arxiv.org/pdf/2405.19548", "abs": "https://arxiv.org/abs/2405.19548", "authors": ["Mingqi Yuan", "Roger Creus Castanyer", "Bo Li", "Xin Jin", "Wenjun Zeng", "Glen Berseth"], "title": "RLeXplore: Accelerating Research in Intrinsically-Motivated Reinforcement Learning", "categories": ["cs.LG"], "comment": "42 pages, 31 figures. Transactions on Machine Learning Research, 2025", "summary": "Extrinsic rewards can effectively guide reinforcement learning (RL) agents in\nspecific tasks. However, extrinsic rewards frequently fall short in complex\nenvironments due to the significant human effort needed for their design and\nannotation. This limitation underscores the necessity for intrinsic rewards,\nwhich offer auxiliary and dense signals and can enable agents to learn in an\nunsupervised manner. Although various intrinsic reward formulations have been\nproposed, their implementation and optimization details are insufficiently\nexplored and lack standardization, thereby hindering research progress. To\naddress this gap, we introduce RLeXplore, a unified, highly modularized, and\nplug-and-play framework offering reliable implementations of eight\nstate-of-the-art intrinsic reward methods. Furthermore, we conduct an in-depth\nstudy that identifies critical implementation details and establishes\nwell-justified standard practices in intrinsically-motivated RL. Our\ndocumentation, examples, and source code are available at\nhttps://github.com/RLE-Foundation/RLeXplore."}
{"id": "2411.16720", "pdf": "https://arxiv.org/pdf/2411.16720", "abs": "https://arxiv.org/abs/2411.16720", "authors": ["Haoyu Wu", "Jingyi Xu", "Hieu Le", "Dimitris Samaras"], "title": "Importance-Based Token Merging for Efficient Image and Video Generation", "categories": ["cs.CV"], "comment": null, "summary": "Token merging can effectively accelerate various vision systems by processing\ngroups of similar tokens only once and sharing the results across them.\nHowever, existing token grouping methods are often ad hoc and random,\ndisregarding the actual content of the samples. We show that preserving\nhigh-information tokens during merging - those essential for semantic fidelity\nand structural details - significantly improves sample quality, producing finer\ndetails and more coherent, realistic generations. Despite being simple and\nintuitive, this approach remains underexplored.\n  To do so, we propose an importance-based token merging method that\nprioritizes the most critical tokens in computational resource allocation,\nleveraging readily available importance scores, such as those from\nclassifier-free guidance in diffusion models. Experiments show that our\napproach significantly outperforms baseline methods across multiple\napplications, including text-to-image synthesis, multi-view image generation,\nand video generation with various model architectures such as Stable Diffusion,\nZero123++, AnimateDiff, or PixArt-$\\alpha$."}
{"id": "2502.17432", "pdf": "https://arxiv.org/pdf/2502.17432", "abs": "https://arxiv.org/abs/2502.17432", "authors": ["Jason Jingzhou Liu", "Yulong Li", "Kenneth Shaw", "Tony Tao", "Ruslan Salakhutdinov", "Deepak Pathak"], "title": "FACTR: Force-Attending Curriculum Training for Contact-Rich Policy Learning", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "Video results, codebases, and instructions:\n  https://jasonjzliu.com/factr/", "summary": "Many contact-rich tasks humans perform, such as box pickup or rolling dough,\nrely on force feedback for reliable execution. However, this force information,\nwhich is readily available in most robot arms, is not commonly used in\nteleoperation and policy learning. Consequently, robot behavior is often\nlimited to quasi-static kinematic tasks that do not require intricate\nforce-feedback. In this paper, we first present a low-cost, intuitive,\nbilateral teleoperation setup that relays external forces of the follower arm\nback to the teacher arm, facilitating data collection for complex, contact-rich\ntasks. We then introduce FACTR, a policy learning method that employs a\ncurriculum which corrupts the visual input with decreasing intensity throughout\ntraining. The curriculum prevents our transformer-based policy from\nover-fitting to the visual input and guides the policy to properly attend to\nthe force modality. We demonstrate that by fully utilizing the force\ninformation, our method significantly improves generalization to unseen objects\nby 43\\% compared to baseline approaches without a curriculum. Video results,\ncodebases, and instructions at https://jasonjzliu.com/factr/"}
{"id": "2406.07529", "pdf": "https://arxiv.org/pdf/2406.07529", "abs": "https://arxiv.org/abs/2406.07529", "authors": ["Lu Li", "Tianyu Zhang", "Zhiqi Bu", "Suyuchen Wang", "Huan He", "Jie Fu", "Yonghui Wu", "Jiang Bian", "Yong Chen", "Yoshua Bengio"], "title": "MAP: Low-compute Model Merging with Amortized Pareto Fronts via Quadratic Approximation", "categories": ["cs.LG"], "comment": null, "summary": "Model merging has emerged as an effective approach to combine multiple\nsingle-task models into a multitask model. This process typically involves\ncomputing a weighted average of the model parameters without any additional\ntraining. Existing model-merging methods focus on enhancing average task\naccuracy. However, interference and conflicts between the objectives of\ndifferent tasks can lead to trade-offs during the merging process. In\nreal-world applications, a set of solutions with various trade-offs can be more\ninformative, helping practitioners make decisions based on diverse preferences.\nIn this paper, we introduce a novel and low-compute algorithm, Model Merging\nwith Amortized Pareto Front (MAP). MAP efficiently identifies a Pareto set of\nscaling coefficients for merging multiple models, reflecting the trade-offs\ninvolved. It amortizes the substantial computational cost of evaluations needed\nto estimate the Pareto front by using quadratic approximation surrogate models\nderived from a pre-selected set of scaling coefficients. Experimental results\non vision and natural language processing tasks demonstrate that MAP can\naccurately identify the Pareto front, providing practitioners with flexible\nsolutions to balance competing task objectives. We also introduce Bayesian MAP\nfor scenarios with a relatively low number of tasks and Nested MAP for\nsituations with a high number of tasks, further reducing the computational cost\nof evaluation."}
{"id": "2412.07199", "pdf": "https://arxiv.org/pdf/2412.07199", "abs": "https://arxiv.org/abs/2412.07199", "authors": ["Debasmita Pal", "Redwan Sony", "Arun Ross"], "title": "A Parametric Approach to Adversarial Augmentation for Cross-Domain Iris Presentation Attack Detection", "categories": ["cs.CV"], "comment": "IEEE/CVF Winter Conference on Applications of Computer Vision (WACV),\n  2025", "summary": "Iris-based biometric systems are vulnerable to presentation attacks (PAs),\nwhere adversaries present physical artifacts (e.g., printed iris images,\ntextured contact lenses) to defeat the system. This has led to the development\nof various presentation attack detection (PAD) algorithms, which typically\nperform well in intra-domain settings. However, they often struggle to\ngeneralize effectively in cross-domain scenarios, where training and testing\nemploy different sensors, PA instruments, and datasets. In this work, we use\nadversarial training samples of both bonafide irides and PAs to improve the\ncross-domain performance of a PAD classifier. The novelty of our approach lies\nin leveraging transformation parameters from classical data augmentation\nschemes (e.g., translation, rotation) to generate adversarial samples. We\nachieve this through a convolutional autoencoder, ADV-GEN, that inputs original\ntraining samples along with a set of geometric and photometric transformations.\nThe transformation parameters act as regularization variables, guiding ADV-GEN\nto generate adversarial samples in a constrained search space. Experiments\nconducted on the LivDet-Iris 2017 database, comprising four datasets, and the\nLivDet-Iris 2020 dataset, demonstrate the efficacy of our proposed method. The\ncode is available at https://github.com/iPRoBe-lab/ADV-GEN-IrisPAD."}
{"id": "2502.19260", "pdf": "https://arxiv.org/pdf/2502.19260", "abs": "https://arxiv.org/abs/2502.19260", "authors": ["Nadya Abdel Madjid", "Murad Mebrahtu", "Abdelmoamen Nasser", "Bilal Hassan", "Naoufel Werghi", "Jorge Dias", "Majid Khonji"], "title": "EMT: A Visual Multi-Task Benchmark Dataset for Autonomous Driving in the Arab Gulf Region", "categories": ["cs.CV", "cs.AI"], "comment": "19 pages, 6 figures", "summary": "This paper introduces the Emirates Multi-Task (EMT) dataset, designed to\nsupport multi-task benchmarking within a unified framework. It comprises over\n30,000 frames from a dash-camera perspective and 570,000 annotated bounding\nboxes, covering approximately 150 kilometers of driving routes that reflect the\ndistinctive road topology, congestion patterns, and driving behavior of Gulf\nregion traffic. The dataset supports three primary tasks: tracking, trajectory\nforecasting, and intention prediction. Each benchmark is accompanied by\ncorresponding evaluations: (1) multi-agent tracking experiments addressing\nmulti-class scenarios and occlusion handling; (2) trajectory forecasting\nevaluation using deep sequential and interaction-aware models; and (3)\nintention prediction experiments based on observed trajectories. The dataset is\npublicly available at https://avlab.io/emt-dataset, with pre-processing scripts\nand evaluation models at https://github.com/AV-Lab/emt-dataset."}
{"id": "2406.19301", "pdf": "https://arxiv.org/pdf/2406.19301", "abs": "https://arxiv.org/abs/2406.19301", "authors": ["Chayne Thrash", "Ali Abbasi", "Reed Andreas", "Parsa Nooralinejad", "Soroush Abbasi Koohpayegani", "Hamed Pirsiavash", "Soheil Kolouri"], "title": "MCNC: Manifold-Constrained Reparameterization for Neural Compression", "categories": ["cs.LG"], "comment": null, "summary": "The outstanding performance of large foundational models across diverse\ntasks, from computer vision to speech and natural language processing, has\nsignificantly increased their demand. However, storing and transmitting these\nmodels poses significant challenges due to their massive size (e.g., 750GB for\nLlama 3.1 405B). Recent literature has focused on compressing the original\nweights or reducing the number of parameters required for fine-tuning these\nmodels. These compression methods generally constrain the parameter space, for\nexample, through low-rank reparametrization (e.g., LoRA), pruning, or\nquantization (e.g., QLoRA) during or after the model training. In this paper,\nwe present a novel model compression method, which we term Manifold-Constrained\nNeural Compression (MCNC). This method constrains the parameter space to\nlow-dimensional pre-defined and frozen nonlinear manifolds, which effectively\ncover this space. Given the prevalence of good solutions in over-parameterized\ndeep neural networks, we show that by constraining the parameter space to our\nproposed manifold, we can identify high-quality solutions while achieving\nunprecedented compression rates across a wide variety of tasks and\narchitectures. Through extensive experiments in computer vision and natural\nlanguage processing tasks, we demonstrate that our method significantly\noutperforms state-of-the-art baselines in terms of compression, accuracy,\nand/or model reconstruction time. Our code is publicly available at\nhttps://github.com/mint-vu/MCNC."}
{"id": "2502.05091", "pdf": "https://arxiv.org/pdf/2502.05091", "abs": "https://arxiv.org/abs/2502.05091", "authors": ["Gorkem Can Ates", "Yu Xin", "Kuang Gong", "Wei Shao"], "title": "DCFormer: Efficient 3D Vision-Language Modeling with Decomposed Convolutions", "categories": ["cs.CV"], "comment": null, "summary": "Vision-language models (VLMs) have been widely applied to 2D medical image\nanalysis due to their ability to align visual and textual representations.\nHowever, extending VLMs to 3D imaging remains computationally challenging.\nExisting 3D VLMs often rely on Vision Transformers (ViTs), which are\ncomputationally expensive due to the quadratic complexity of self-attention, or\non 3D convolutions, which require large numbers of parameters and FLOPs as\nkernel size increases. We introduce DCFormer, an efficient 3D image encoder\nthat factorizes 3D convolutions into three parallel 1D convolutions along the\ndepth, height, and width dimensions. This design preserves spatial information\nwhile significantly reducing computational cost. Integrated into a CLIP-based\nvision-language framework, DCFormer is trained and evaluated on CT-RATE, a\ndataset of 50,188 paired 3D chest CT volumes and radiology reports. In\nzero-shot and fine-tuned detection of 18 pathologies, as well as in image-text\nretrieval tasks, DCFormer consistently outperforms state-of-the-art 3D vision\nencoders, including CT-ViT, ViT, ConvNeXt, PoolFormer, and TransUNet. These\nresults highlight DCFormer's potential for scalable, clinically deployable 3D\nmedical VLMs. Our code is available at: https://github.com/mirthAI/DCFormer."}
{"id": "2502.19662", "pdf": "https://arxiv.org/pdf/2502.19662", "abs": "https://arxiv.org/abs/2502.19662", "authors": ["Rohan Juneja", "Shivam Aggarwal", "Safeen Huda", "Tulika Mitra", "Li-Shiuan Peh"], "title": "HALO: Hardware-aware quantization with low critical-path-delay weights for LLM acceleration", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "Quantization is critical for efficiently deploying large language models\n(LLMs). Yet conventional methods remain hardware-agnostic, limited to bit-width\nconstraints, and do not account for intrinsic circuit characteristics such as\nthe timing behaviors and energy profiles of Multiply-Accumulate (MAC) units.\nThis disconnect from circuit-level behavior limits the ability to exploit\navailable timing margins and energy-saving opportunities, reducing the overall\nefficiency of deployment on modern accelerators.\n  To address these limitations, we propose HALO, a versatile framework for\nHardware-Aware Post-Training Quantization (PTQ). Unlike traditional methods,\nHALO explicitly incorporates detailed hardware characteristics, including\ncritical-path timing and power consumption, into its quantization approach.\nHALO strategically selects weights with low critical-path-delays enabling\nhigher operational frequencies and dynamic frequency scaling without disrupting\nthe architecture's dataflow. Remarkably, HALO achieves these improvements with\nonly a few dynamic voltage and frequency scaling (DVFS) adjustments, ensuring\nsimplicity and practicality in deployment. Additionally, by reducing switching\nactivity within the MAC units, HALO effectively lowers energy consumption.\nEvaluations on accelerators such as Tensor Processing Units (TPUs) and Graphics\nProcessing Units (GPUs) demonstrate that HALO significantly enhances inference\nefficiency, achieving average performance improvements of 270% and energy\nsavings of 51% over baseline quantization methods, all with minimal impact on\naccuracy."}
{"id": "2408.04569", "pdf": "https://arxiv.org/pdf/2408.04569", "abs": "https://arxiv.org/abs/2408.04569", "authors": ["Bella Finkel", "Jose Israel Rodriguez", "Chenxi Wu", "Thomas Yahl"], "title": "Activation degree thresholds and expressiveness of polynomial neural networks", "categories": ["cs.LG", "cs.NE", "math.AG", "stat.ML"], "comment": "24 pages, 1 figure", "summary": "We study the expressive power of deep polynomial neural networks through the\ngeometry of their neurovariety. We introduce the notion of the activation\ndegree threshold of a network architecture to express when the dimension of the\nneurovariety achieves its theoretical maximum. We prove the existence of the\nactivation degree threshold for all polynomial neural networks without\nwidth-one bottlenecks and demonstrate a universal upper bound that is quadratic\nin the width of largest size. In doing so, we prove the high activation degree\nconjecture of Kileel, Trager, and Bruna. Certain structured architectures have\nexceptional activation degree thresholds, making them especially expressive in\nthe sense of their neurovariety dimension. In this direction, we prove that\npolynomial neural networks with equi-width architectures are maximally\nexpressive by showing their activation degree threshold is one."}
{"id": "2502.13078", "pdf": "https://arxiv.org/pdf/2502.13078", "abs": "https://arxiv.org/abs/2502.13078", "authors": ["Abhishek Badki", "Hang Su", "Bowen Wen", "Orazio Gallo"], "title": "L4P: Low-Level 4D Vision Perception Unified", "categories": ["cs.CV"], "comment": null, "summary": "The spatio-temporal relationship between the pixels of a video carries\ncritical information for low-level 4D perception tasks. A single model that\nreasons about it should be able to solve several such tasks well. Yet, most\nstate-of-the-art methods rely on architectures specialized for the task at\nhand. We present L4P, a feedforward, general-purpose architecture that solves\nlow-level 4D perception tasks in a unified framework. L4P leverages a\npre-trained ViT-based video encoder and combines it with per-task heads that\nare lightweight and therefore do not require extensive training. Despite its\ngeneral and feedforward formulation, our method matches or surpasses the\nperformance of existing specialized methods on both dense tasks, such as depth\nor optical flow estimation, and sparse tasks, such as 2D/3D tracking. Moreover,\nit solves all tasks at once in a time comparable to that of single-task\nmethods."}
{"id": "2503.01411", "pdf": "https://arxiv.org/pdf/2503.01411", "abs": "https://arxiv.org/abs/2503.01411", "authors": ["Peng Yan", "Ahmed Abdulkadir", "Gerrit A. Schatte", "Giulia Aguzzi", "Joonsu Gha", "Nikola Pascher", "Matthias Rosenthal", "Yunlong Gao", "Benjamin F. Grewe", "Thilo Stadelmann"], "title": "Learning Actionable World Models for Industrial Process Control", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY", "I.2.0; I.2.4"], "comment": "Accepted by SDS 2025", "summary": "To go from (passive) process monitoring to active process control, an\neffective AI system must learn about the behavior of the complex system from\nvery limited training data, forming an ad-hoc digital twin with respect to\nprocess inputs and outputs that captures the consequences of actions on the\nprocess's world. We propose a novel methodology based on learning world models\nthat disentangles process parameters in the learned latent representation,\nallowing for fine-grained control. Representation learning is driven by the\nlatent factors influencing the processes through contrastive learning within a\njoint embedding predictive architecture. This makes changes in representations\npredictable from changes in inputs and vice versa, facilitating\ninterpretability of key factors responsible for process variations, paving the\nway for effective control actions to keep the process within operational\nbounds. The effectiveness of our method is validated on the example of plastic\ninjection molding, demonstrating practical relevance in proposing specific\ncontrol actions for a notoriously unstable process."}
{"id": "2408.14587", "pdf": "https://arxiv.org/pdf/2408.14587", "abs": "https://arxiv.org/abs/2408.14587", "authors": ["Christopher Subich"], "title": "Efficient fine-tuning of 37-level GraphCast with the Canadian global deterministic analysis", "categories": ["cs.LG", "physics.ao-ph"], "comment": null, "summary": "This work describes a process for efficiently fine-tuning the GraphCast\ndata-driven forecast model to simulate another analysis system, here the Global\nDeterministic Prediction System (GDPS) of Environment and Climate Change Canada\n(ECCC). Using two years of training data (July 2019 -- December 2021) and 37\nGPU-days of computation to tune the 37-level, quarter-degree version of\nGraphCast, the resulting model significantly outperforms both the unmodified\nGraphCast and operational forecast, showing significant forecast skill in the\ntroposphere over lead times from 1 to 10 days. This fine-tuning is accomplished\nthrough abbreviating DeepMind's original training curriculum for GraphCast,\nrelying on a shorter single-step forecast stage to accomplish the bulk of the\nadaptation work and consolidating the autoregressive stages into separate 12hr,\n1d, 2d, and 3d stages with larger learning rates. Additionally, training over\n3d forecasts is split into two sub-steps to conserve host memory while\nmaintaining a strong correlation with training over the full period."}
{"id": "2503.13939", "pdf": "https://arxiv.org/pdf/2503.13939", "abs": "https://arxiv.org/abs/2503.13939", "authors": ["Yuxiang Lai", "Jike Zhong", "Ming Li", "Shitian Zhao", "Xiaofeng Yang"], "title": "Med-R1: Reinforcement Learning for Generalizable Medical Reasoning in Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Vision-language models (VLMs) have achieved impressive progress in natural\nimage reasoning, yet their potential in medical imaging remains underexplored.\nMedical vision-language tasks demand precise understanding and clinically\ncoherent answers, which are difficult to achieve due to the complexity of\nmedical data and the scarcity of high-quality expert annotations. These\nchallenges limit the effectiveness of conventional supervised fine-tuning (SFT)\nand Chain-of-Thought (CoT) strategies that work well in general domains. To\naddress these challenges, we propose Med-R1, a reinforcement learning\n(RL)-enhanced vision-language model designed to improve generalization and\nreliability in medical reasoning. Built on the DeepSeek strategy, Med-R1 adopts\nGroup Relative Policy Optimization (GRPO) to encourage reward-guided learning\nbeyond static annotations. We comprehensively evaluate Med-R1 across eight\ndistinct medical imaging modalities. Med-R1 achieves a 29.94% improvement in\naverage accuracy over its base model Qwen2-VL-2B, and even outperforms\nQwen2-VL-72B-a model with 36x more parameters. To assess cross-task\ngeneralization, we further evaluate Med-R1 on five question types. Med-R1\noutperforms Qwen2-VL-2B by 32.06% in question-type generalization, also\nsurpassing Qwen2-VL-72B. We further explore the thinking process in Med-R1, a\ncrucial component for the success of Deepseek-R1. Our results show that\nomitting intermediate rationales (No-Thinking-Med-R1) not only improves\nin-domain and cross-domain generalization with less training, but also\nchallenges the assumption that more reasoning always helps. These findings\nsuggest that in medical VQA, it is not reasoning itself, but its quality and\ndomain alignment, that determine effectiveness. Together, these results\nhighlight that RL improves medical reasoning and generalization, enabling\nefficient and reliable VLMs for real-world deployment."}
{"id": "2503.01855", "pdf": "https://arxiv.org/pdf/2503.01855", "abs": "https://arxiv.org/abs/2503.01855", "authors": ["Gregory Wheeler"], "title": "Function-coherent gambles", "categories": ["econ.TH", "cs.AI", "cs.CE", "math.PR"], "comment": null, "summary": "The desirable gambles framework provides a foundational approach to imprecise\nprobability theory but relies heavily on linear utility assumptions. This paper\nintroduces function-coherent gambles, a generalization that accommodates\nnon-linear utility while preserving essential rationality properties. We\nestablish core axioms for function-coherence and prove a representation theorem\nthat characterizes acceptable gambles through continuous linear functionals.\nThe framework is then applied to analyze various forms of discounting in\nintertemporal choice, including hyperbolic, quasi-hyperbolic, scale-dependent,\nand state-dependent discounting. We demonstrate how these alternatives to\nconstant-rate exponential discounting can be integrated within the\nfunction-coherent framework. This unified treatment provides theoretical\nfoundations for modeling sophisticated patterns of time preference within the\ndesirability paradigm, bridging a gap between normative theory and observed\nbehavior in intertemporal decision-making under genuine uncertainty."}
{"id": "2410.23824", "pdf": "https://arxiv.org/pdf/2410.23824", "abs": "https://arxiv.org/abs/2410.23824", "authors": ["Youngjoon Lee", "Jinu Gong", "Joonhyuk Kang"], "title": "Generative AI-Powered Plugin for Robust Federated Learning in Heterogeneous IoT Networks", "categories": ["cs.LG", "eess.SP"], "comment": "5 pages", "summary": "Federated learning enables edge devices to collaboratively train a global\nmodel while maintaining data privacy by keeping data localized. However, the\nNon-IID nature of data distribution across devices often hinders model\nconvergence and reduces performance. In this paper, we propose a novel plugin\nfor federated optimization techniques that approximates Non-IID data\ndistributions to IID through generative AI-enhanced data augmentation and\nbalanced sampling strategy. Key idea is to synthesize additional data for\nunderrepresented classes on each edge device, leveraging generative AI to\ncreate a more balanced dataset across the FL network. Additionally, a balanced\nsampling approach at the central server selectively includes only the most\nIID-like devices, accelerating convergence while maximizing the global model's\nperformance. Experimental results validate that our approach significantly\nimproves convergence speed and robustness against data imbalance, establishing\na flexible, privacy-preserving FL plugin that is applicable even in data-scarce\nenvironments."}
{"id": "2503.18339", "pdf": "https://arxiv.org/pdf/2503.18339", "abs": "https://arxiv.org/abs/2503.18339", "authors": ["Inpyo Hong", "Youngwan Jo", "Hyojeong Lee", "Sunghyun Ahn", "Sanghyun Park"], "title": "GranQ: Granular Zero-Shot Quantization with Unified Layer-Channel Awareness", "categories": ["cs.CV"], "comment": null, "summary": "Zero-shot quantization (ZSQ) enables neural network compression without\ntraining data, which is crucial in restricted data access environments.\nHowever, existing ZSQ methods suffer from significant activation loss in\nlow-bit environments owing to their coarse-grained scaling strategy. To address\nthis issue, we propose GranQ, a novel ZSQ approach that leverages layer-channel\nawareness to minimize the quantization error. Unlike conventional layer- or\nchannel-wise quantization, GranQ dynamically adjusts quantization granularity\nby considering both layer- and channel-level activation distributions. This\nenables fine-grained quantization while minimizing activation distortion.\nAdditionally, we introduce vectorized activation quantization, which enables\nefficient parallel computation and reduces computational overhead while\npreserving accuracy. GranQ achieves superior performance compared with those of\nstate-of-the-art ZSQ methods that employ quantization-aware training. With\nthese findings, we anticipate that GranQ will inspire novel research directions\nbeyond conventional ZSQ approaches focused on data generation and model\ntraining."}
{"id": "2503.02612", "pdf": "https://arxiv.org/pdf/2503.02612", "abs": "https://arxiv.org/abs/2503.02612", "authors": ["Wuzhou Sun", "Siyi Li", "Qingxiang Zou", "Zixing Liao"], "title": "Reinforcement Learning-based Threat Assessment", "categories": ["cs.LG", "cs.AI"], "comment": "The research content is not yet complete and requires further\n  supplementation and improvement", "summary": "In some game scenarios, due to the uncertainty of the number of enemy units\nand the priority of various attributes, the evaluation of the threat level of\nenemy units as well as the screening has been a challenging research topic, and\nthe core difficulty lies in how to reasonably set the priority of different\nattributes in order to achieve quantitative evaluation of the threat. In this\npaper, we innovatively transform the problem of threat assessment into a\nreinforcement learning problem, and through systematic reinforcement learning\ntraining, we successfully construct an efficient neural network evaluator. The\nevaluator can not only comprehensively integrate the multidimensional attribute\nfeatures of the enemy, but also effectively combine our state information, thus\nrealizing a more accurate and scientific threat assessment."}
{"id": "2411.18199", "pdf": "https://arxiv.org/pdf/2411.18199", "abs": "https://arxiv.org/abs/2411.18199", "authors": ["Milin Zhang", "Mohammad Abdi", "Venkat R. Dasari", "Francesco Restuccia"], "title": "Semantic Edge Computing and Semantic Communications in 6G Networks: A Unifying Survey and Research Challenges", "categories": ["cs.LG", "cs.NI", "eess.SP"], "comment": null, "summary": "Semantic Edge Computing (SEC) and Semantic Communications (SemComs) have been\nproposed as viable approaches to achieve real-time edge-enabled intelligence in\nsixth-generation (6G) wireless networks. On one hand, SemCom leverages the\nstrength of Deep Neural Networks (DNNs) to encode and communicate the semantic\ninformation only, while making it robust to channel distortions by compensating\nfor wireless effects. Ultimately, this leads to an improvement in the\ncommunication efficiency. On the other hand, SEC has leveraged distributed DNNs\nto divide the computation of a DNN across different devices based on their\ncomputational and networking constraints. Although significant progress has\nbeen made in both fields, the literature lacks a systematic view to connect\nboth fields. In this work, we fulfill the current gap by unifying the SEC and\nSemCom fields. We summarize the research problems in these two fields and\nprovide a comprehensive review of the state of the art with a focus on their\ntechnical strengths and challenges."}
{"id": "2503.23313", "pdf": "https://arxiv.org/pdf/2503.23313", "abs": "https://arxiv.org/abs/2503.23313", "authors": ["Harshvardhan Takawale", "Nirupam Roy"], "title": "SpINR: Neural Volumetric Reconstruction for FMCW Radars", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we introduce SpINR, a novel framework for volumetric\nreconstruction using Frequency-Modulated Continuous-Wave (FMCW) radar data.\nTraditional radar imaging techniques, such as backprojection, often assume\nideal signal models and require dense aperture sampling, leading to limitations\nin resolution and generalization. To address these challenges, SpINR integrates\na fully differentiable forward model that operates natively in the frequency\ndomain with implicit neural representations (INRs). This integration leverages\nthe linear relationship between beat frequency and scatterer distance inherent\nin FMCW radar systems, facilitating more efficient and accurate learning of\nscene geometry. Additionally, by computing outputs for only the relevant\nfrequency bins, our forward model achieves greater computational efficiency\ncompared to time-domain approaches that process the entire signal before\ntransformation. Through extensive experiments, we demonstrate that SpINR\nsignificantly outperforms classical backprojection methods and existing\nlearning-based approaches, achieving higher resolution and more accurate\nreconstructions of complex scenes. This work represents the first application\nof neural volumetic reconstruction in the radar domain, offering a promising\ndirection for future research in radar-based imaging and perception systems."}
{"id": "2503.06635", "pdf": "https://arxiv.org/pdf/2503.06635", "abs": "https://arxiv.org/abs/2503.06635", "authors": ["Zhiyuan Ning", "Zaitian Wang", "Ran Zhang", "Ping Xu", "Kunpeng Liu", "Pengyang Wang", "Wei Ju", "Pengfei Wang", "Yuanchun Zhou", "Erik Cambria", "Chong Chen"], "title": "Deep Cut-informed Graph Embedding and Clustering", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph clustering aims to divide the graph into different clusters. The\nrecently emerging deep graph clustering approaches are largely built on graph\nneural networks (GNN). However, GNN is designed for general graph encoding and\nthere is a common issue of representation collapse in existing GNN-based deep\ngraph clustering algorithms. We attribute two main reasons for such issues: (i)\nthe inductive bias of GNN models: GNNs tend to generate similar representations\nfor proximal nodes. Since graphs often contain a non-negligible amount of\ninter-cluster links, the bias results in error message passing and leads to\nbiased clustering; (ii) the clustering guided loss function: most traditional\napproaches strive to make all samples closer to pre-learned cluster centers,\nwhich causes a degenerate solution assigning all data points to a single label\nthus making all samples similar and less discriminative. To address these\nchallenges, we investigate graph clustering from a graph cut perspective and\npropose an innovative and non-GNN-based Deep Cut-informed Graph embedding and\nClustering framework, namely DCGC. This framework includes two modules: (i)\ncut-informed graph encoding; (ii) self-supervised graph clustering via optimal\ntransport. For the encoding module, we derive a cut-informed graph embedding\nobjective to fuse graph structure and attributes by minimizing their joint\nnormalized cut. For the clustering module, we utilize the optimal transport\ntheory to obtain the clustering assignments, which can balance the guidance of\n\"proximity to the pre-learned cluster center\". With the above two tailored\ndesigns, DCGC is more suitable for the graph clustering task, which can\neffectively alleviate the problem of representation collapse and achieve better\nperformance. We conduct extensive experiments to demonstrate that our method is\nsimple but effective compared with benchmarks."}
{"id": "2412.01114", "pdf": "https://arxiv.org/pdf/2412.01114", "abs": "https://arxiv.org/abs/2412.01114", "authors": ["Cevahir Koprulu", "Po-han Li", "Tianyu Qiu", "Ruihan Zhao", "Tyler Westenbroek", "David Fridovich-Keil", "Sandeep Chinchali", "Ufuk Topcu"], "title": "Dense Dynamics-Aware Reward Synthesis: Integrating Prior Experience with Demonstrations", "categories": ["cs.LG"], "comment": null, "summary": "Many continuous control problems can be formulated as sparse-reward\nreinforcement learning (RL) tasks. In principle, online RL methods can\nautomatically explore the state space to solve each new task. However,\ndiscovering sequences of actions that lead to a non-zero reward becomes\nexponentially more difficult as the task horizon increases. Manually shaping\nrewards can accelerate learning for a fixed task, but it is an arduous process\nthat must be repeated for each new environment. We introduce a systematic\nreward-shaping framework that distills the information contained in 1) a\ntask-agnostic prior data set and 2) a small number of task-specific expert\ndemonstrations, and then uses these priors to synthesize dense dynamics-aware\nrewards for the given task. This supervision substantially accelerates learning\nin our experiments, and we provide analysis demonstrating how the approach can\neffectively guide online learning agents to faraway goals."}
{"id": "2504.03096", "pdf": "https://arxiv.org/pdf/2504.03096", "abs": "https://arxiv.org/abs/2504.03096", "authors": ["Zhen Hao Sia", "Yogesh Singh Rawat"], "title": "Scaling Open-Vocabulary Action Detection", "categories": ["cs.CV"], "comment": null, "summary": "In this work, we focus on scaling open-vocabulary action detection. Existing\napproaches for action detection are predominantly limited to closed-set\nscenarios and rely on complex, parameter-heavy architectures. Extending these\nmodels to the open-vocabulary setting poses two key challenges: (1) the lack of\nlarge-scale datasets with many action classes for robust training, and (2)\nparameter-heavy adaptations to a pretrained vision-language contrastive model\nto convert it for detection, risking overfitting the additional non-pretrained\nparameters to base action classes. Firstly, we introduce an encoder-only\nmultimodal model for video action detection, reducing the reliance on\nparameter-heavy additions for video action detection. Secondly, we introduce a\nsimple weakly supervised training strategy to exploit an existing closed-set\naction detection dataset for pretraining. Finally, we depart from the ill-posed\nbase-to-novel benchmark used by prior works in open-vocabulary action detection\nand devise a new benchmark to evaluate on existing closed-set action detection\ndatasets without ever using them for training, showing novel results to serve\nas baselines for future work. Our code is available at:\nhttps://siatheindochinese.github.io/sia_act_page/"}
{"id": "2503.08558", "pdf": "https://arxiv.org/pdf/2503.08558", "abs": "https://arxiv.org/abs/2503.08558", "authors": ["Chen Xu", "Tony Khuong Nguyen", "Emma Dixon", "Christopher Rodriguez", "Patrick Miller", "Robert Lee", "Paarth Shah", "Rares Ambrus", "Haruki Nishimura", "Masha Itkina"], "title": "Can We Detect Failures Without Failure Data? Uncertainty-Aware Runtime Failure Detection for Imitation Learning Policies", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent years have witnessed impressive robotic manipulation systems driven by\nadvances in imitation learning and generative modeling, such as diffusion- and\nflow-based approaches. As robot policy performance increases, so does the\ncomplexity and time horizon of achievable tasks, inducing unexpected and\ndiverse failure modes that are difficult to predict a priori. To enable\ntrustworthy policy deployment in safety-critical human environments, reliable\nruntime failure detection becomes important during policy inference. However,\nmost existing failure detection approaches rely on prior knowledge of failure\nmodes and require failure data during training, which imposes a significant\nchallenge in practicality and scalability. In response to these limitations, we\npresent FAIL-Detect, a modular two-stage approach for failure detection in\nimitation learning-based robotic manipulation. To accurately identify failures\nfrom successful training data alone, we frame the problem as sequential\nout-of-distribution (OOD) detection. We first distill policy inputs and outputs\ninto scalar signals that correlate with policy failures and capture epistemic\nuncertainty. FAIL-Detect then employs conformal prediction (CP) as a versatile\nframework for uncertainty quantification with statistical guarantees.\nEmpirically, we thoroughly investigate both learned and post-hoc scalar signal\ncandidates on diverse robotic manipulation tasks. Our experiments show learned\nsignals to be mostly consistently effective, particularly when using our novel\nflow-based density estimator. Furthermore, our method detects failures more\naccurately and faster than state-of-the-art (SOTA) failure detection baselines.\nThese results highlight the potential of FAIL-Detect to enhance the safety and\nreliability of imitation learning-based robotic systems as they progress toward\nreal-world deployment."}
{"id": "2412.18594", "pdf": "https://arxiv.org/pdf/2412.18594", "abs": "https://arxiv.org/abs/2412.18594", "authors": ["Vignesh Tirukkonda", "Anirudh Rayas", "Gautam Dasarathy"], "title": "Structure Learning in Gaussian Graphical Models from Glauber Dynamics", "categories": ["cs.LG", "stat.ML"], "comment": "Corrected sample complexity comparisons; noted parallelizability and\n  computational efficiency; minor revision to Lemma 1 (ensuring integrability).\n  Preliminary version to appear at IEEE ISIT 2025", "summary": "Gaussian graphical model selection is an important paradigm with numerous\napplications, including biological network modeling, financial network\nmodeling, and social network analysis. Traditional approaches assume access to\nindependent and identically distributed (i.i.d) samples, which is often\nimpractical in real-world scenarios. In this paper, we address Gaussian\ngraphical model selection under observations from a more realistic dependent\nstochastic process known as Glauber dynamics. Glauber dynamics, also called the\nGibbs sampler, is a Markov chain that sequentially updates the variables of the\nunderlying model based on the statistics of the remaining model. Such models,\naside from frequently being employed to generate samples from complex\nmultivariate distributions, naturally arise in various settings, such as\nopinion consensus in social networks and clearing/stock-price dynamics in\nfinancial networks.\n  In contrast to the extensive body of existing work, we present the first\nalgorithm for Gaussian graphical model selection when data are sampled\naccording to the Glauber dynamics. We provide theoretical guarantees on the\ncomputational and statistical complexity of the proposed algorithm's structure\nlearning performance. Additionally, we provide information-theoretic lower\nbounds on the statistical complexity and show that our algorithm is nearly\nminimax optimal for a broad class of problems."}
{"id": "2504.14131", "pdf": "https://arxiv.org/pdf/2504.14131", "abs": "https://arxiv.org/abs/2504.14131", "authors": ["Ole-Christian Galbo Engstr√∏m", "Michela Albano-Gaglio", "Erik Schou Dreier", "Yamine Bouzembrak", "Maria Font-i-Furnols", "Puneet Mishra", "Kim Steenstrup Pedersen"], "title": "Transforming Hyperspectral Images Into Chemical Maps: An End-to-End Deep Learning Approach", "categories": ["cs.CV", "cs.LG", "q-bio.QM"], "comment": null, "summary": "Current approaches to chemical map generation from hyperspectral images are\nbased on models such as partial least squares (PLS) regression, generating\npixel-wise predictions that do not consider spatial context and suffer from a\nhigh degree of noise. This study proposes an end-to-end deep learning approach\nusing a modified version of U-Net and a custom loss function to directly obtain\nchemical maps from hyperspectral images, skipping all intermediate steps\nrequired for traditional pixel-wise analysis. We compare the U-Net with the\ntraditional PLS regression on a real dataset of pork belly samples with\nassociated mean fat reference values. The U-Net obtains a test set root mean\nsquared error of between 9% and 13% lower than that of PLS regression on the\ntask of mean fat prediction. At the same time, U-Net generates fine detail\nchemical maps where 99.91% of the variance is spatially correlated. Conversely,\nonly 2.53% of the variance in the PLS-generated chemical maps is spatially\ncorrelated, indicating that each pixel-wise prediction is largely independent\nof neighboring pixels. Additionally, while the PLS-generated chemical maps\ncontain predictions far beyond the physically possible range of 0-100%, U-Net\nlearns to stay inside this range. Thus, the findings of this study indicate\nthat U-Net is superior to PLS for chemical map generation."}
{"id": "2503.14469", "pdf": "https://arxiv.org/pdf/2503.14469", "abs": "https://arxiv.org/abs/2503.14469", "authors": ["Felipe Azua", "Leopoldo Bertossi"], "title": "Attribution Score Alignment in Explainable Data Management", "categories": ["cs.DB", "cs.AI"], "comment": "Relevant references added in this version", "summary": "Different attribution-scores have been proposed to quantify the relevance of\ndatabase tuples for a query answer from a database. Among them, we find Causal\nResponsibility, the Shapley Value, the Banzhaf Power-Index, and the Causal\nEffect. They have been analyzed in isolation, mainly in terms of computational\nproperties. In this work, we start an investigation into the alignment of these\nscores on the basis of the queries at hand; that is, on whether they induce\ncompatible rankings of tuples. We are able to identify vast classes of queries\nfor which some pairs of scores are always aligned, and others for which they\nare not. It turns out that the presence of exogenous tuples makes a crucial\ndifference in this regard."}
{"id": "2502.00806", "pdf": "https://arxiv.org/pdf/2502.00806", "abs": "https://arxiv.org/abs/2502.00806", "authors": ["Yufei He", "Yuan Sui", "Xiaoxin He", "Yue Liu", "Yifei Sun", "Bryan Hooi"], "title": "UniGraph2: Learning a Unified Embedding Space to Bind Multimodal Graphs", "categories": ["cs.LG"], "comment": "WWW 2025", "summary": "Existing foundation models, such as CLIP, aim to learn a unified embedding\nspace for multimodal data, enabling a wide range of downstream web-based\napplications like search, recommendation, and content classification. However,\nthese models often overlook the inherent graph structures in multimodal\ndatasets, where entities and their relationships are crucial. Multimodal graphs\n(MMGs) represent such graphs where each node is associated with features from\ndifferent modalities, while the edges capture the relationships between these\nentities. On the other hand, existing graph foundation models primarily focus\non text-attributed graphs (TAGs) and are not designed to handle the\ncomplexities of MMGs. To address these limitations, we propose UniGraph2, a\nnovel cross-domain graph foundation model that enables general representation\nlearning on MMGs, providing a unified embedding space. UniGraph2 employs\nmodality-specific encoders alongside a graph neural network (GNN) to learn a\nunified low-dimensional embedding space that captures both the multimodal\ninformation and the underlying graph structure. We propose a new cross-domain\nmulti-graph pre-training algorithm at scale to ensure effective transfer\nlearning across diverse graph domains and modalities. Additionally, we adopt a\nMixture of Experts (MoE) component to align features from different domains and\nmodalities, ensuring coherent and robust embeddings that unify the information\nacross modalities. Extensive experiments on a variety of multimodal graph tasks\ndemonstrate that UniGraph2 significantly outperforms state-of-the-art models in\ntasks such as representation learning, transfer learning, and multimodal\ngenerative tasks, offering a scalable and flexible solution for learning on\nMMGs."}
{"id": "2504.14348", "pdf": "https://arxiv.org/pdf/2504.14348", "abs": "https://arxiv.org/abs/2504.14348", "authors": ["Le Wang", "Zonghao Ying", "Tianyuan Zhang", "Siyuan Liang", "Shengshan Hu", "Mingchuan Zhang", "Aishan Liu", "Xianglong Liu"], "title": "Manipulating Multimodal Agents via Cross-Modal Prompt Injection", "categories": ["cs.CV"], "comment": "17 pages, 5 figures", "summary": "The emergence of multimodal large language models has redefined the agent\nparadigm by integrating language and vision modalities with external data\nsources, enabling agents to better interpret human instructions and execute\nincreasingly complex tasks. However, in this work, we identify a critical yet\npreviously overlooked security vulnerability in multimodal agents: cross-modal\nprompt injection attacks. To exploit this vulnerability, we propose\nCrossInject, a novel attack framework in which attackers embed adversarial\nperturbations across multiple modalities to align with target malicious\ncontent, allowing external instructions to hijack the agent's decision-making\nprocess and execute unauthorized tasks. Our approach consists of two key\ncomponents. First, we introduce Visual Latent Alignment, where we optimize\nadversarial features to the malicious instructions in the visual embedding\nspace based on a text-to-image generative model, ensuring that adversarial\nimages subtly encode cues for malicious task execution. Subsequently, we\npresent Textual Guidance Enhancement, where a large language model is leveraged\nto infer the black-box defensive system prompt through adversarial meta\nprompting and generate an malicious textual command that steers the agent's\noutput toward better compliance with attackers' requests. Extensive experiments\ndemonstrate that our method outperforms existing injection attacks, achieving\nat least a +26.4% increase in attack success rates across diverse tasks.\nFurthermore, we validate our attack's effectiveness in real-world multimodal\nautonomous agents, highlighting its potential implications for safety-critical\napplications."}
{"id": "2503.14976", "pdf": "https://arxiv.org/pdf/2503.14976", "abs": "https://arxiv.org/abs/2503.14976", "authors": ["Hisato Komatsu"], "title": "Application of linear regression and quasi-Newton methods to the deep reinforcement learning in continuous action cases", "categories": ["cs.LG", "cs.AI"], "comment": "23 pages, 8 figures", "summary": "The linear regression (LR) method offers the advantage that optimal\nparameters can be calculated relatively easily, although its representation\ncapability is limited than that of the deep learning technique. To improve deep\nreinforcement learning, the Least Squares Deep Q Network (LS-DQN) method was\nproposed by Levine et al., which combines Deep Q Network (DQN) with LR method.\nHowever, the LS-DQN method assumes that the actions are discrete. In this\nstudy, we propose the Double Least Squares Deep Deterministic Policy Gradient\n(DLS-DDPG) method to address this limitation. This method combines the LR\nmethod with the Deep Deterministic Policy Gradient (DDPG) technique, one of the\nrepresentative deep reinforcement learning algorithms for continuous action\ncases. For the LR update of the critic network, DLS-DDPG uses an algorithm\nsimilar to the Fitted Q iteration, the method which LS-DQN adopted. In\naddition, we calculated the optimal action using the quasi-Newton method and\nused it as both the agent's action and the training data for the LR update of\nthe actor network. Numerical experiments conducted in MuJoCo environments\nshowed that the proposed method improved performance at least in some tasks,\nalthough there are difficulties such as the inability to make the\nregularization terms small."}
{"id": "2502.01015", "pdf": "https://arxiv.org/pdf/2502.01015", "abs": "https://arxiv.org/abs/2502.01015", "authors": ["Siqi Zeng", "Yifei He", "Weiqiu You", "Yifan Hao", "Yao-Hung Hubert Tsai", "Makoto Yamada", "Han Zhao"], "title": "Efficient Model Editing with Task Vector Bases: A Theoretical Framework and Scalable Approach", "categories": ["cs.LG"], "comment": "27 pages, 11 figures", "summary": "Task vectors, which are derived from the difference between pre-trained and\nfine-tuned model weights, enable flexible task adaptation and model merging\nthrough arithmetic operations such as addition and negation. However, existing\napproaches often rely on heuristics with limited theoretical support, often\nleading to performance gaps comparing to direct task fine tuning. Meanwhile,\nalthough it is easy to manipulate saved task vectors with arithmetic for\ndifferent purposes, such compositional flexibility demands high memory usage,\nespecially when dealing with a huge number of tasks, limiting scalability. This\nwork addresses these issues with a theoretically grounded framework that\nexplains task vector arithmetic and introduces the task vector bases framework.\nBuilding upon existing task arithmetic literature, our method significantly\nreduces the memory cost for downstream arithmetic with little effort, while\nachieving competitive performance and maintaining compositional advantage,\nproviding a practical solution for large-scale task arithmetic. The code is\navailable at https://github.com/uiuctml/TaskVectorBasis."}
{"id": "2504.14509", "pdf": "https://arxiv.org/pdf/2504.14509", "abs": "https://arxiv.org/abs/2504.14509", "authors": ["Fulong Ye", "Miao Hua", "Pengze Zhang", "Xinghui Li", "Qichao Sun", "Songtao Zhao", "Qian He", "Xinglong Wu"], "title": "DreamID: High-Fidelity and Fast diffusion-based Face Swapping via Triplet ID Group Learning", "categories": ["cs.CV", "cs.AI"], "comment": "Project: https://superhero-7.github.io/DreamID/", "summary": "In this paper, we introduce DreamID, a diffusion-based face swapping model\nthat achieves high levels of ID similarity, attribute preservation, image\nfidelity, and fast inference speed. Unlike the typical face swapping training\nprocess, which often relies on implicit supervision and struggles to achieve\nsatisfactory results. DreamID establishes explicit supervision for face\nswapping by constructing Triplet ID Group data, significantly enhancing\nidentity similarity and attribute preservation. The iterative nature of\ndiffusion models poses challenges for utilizing efficient image-space loss\nfunctions, as performing time-consuming multi-step sampling to obtain the\ngenerated image during training is impractical. To address this issue, we\nleverage the accelerated diffusion model SD Turbo, reducing the inference steps\nto a single iteration, enabling efficient pixel-level end-to-end training with\nexplicit Triplet ID Group supervision. Additionally, we propose an improved\ndiffusion-based model architecture comprising SwapNet, FaceNet, and ID Adapter.\nThis robust architecture fully unlocks the power of the Triplet ID Group\nexplicit supervision. Finally, to further extend our method, we explicitly\nmodify the Triplet ID Group data during training to fine-tune and preserve\nspecific attributes, such as glasses and face shape. Extensive experiments\ndemonstrate that DreamID outperforms state-of-the-art methods in terms of\nidentity similarity, pose and expression preservation, and image fidelity.\nOverall, DreamID achieves high-quality face swapping results at 512*512\nresolution in just 0.6 seconds and performs exceptionally well in challenging\nscenarios such as complex lighting, large angles, and occlusions."}
{"id": "2504.05181", "pdf": "https://arxiv.org/pdf/2504.05181", "abs": "https://arxiv.org/abs/2504.05181", "authors": ["Kidist Amde Mekonnen", "Yubao Tang", "Maarten de Rijke"], "title": "Lightweight and Direct Document Relevance Optimization for Generative Information Retrieval", "categories": ["cs.IR", "cs.AI", "cs.DL", "cs.LG", "H.3.3"], "comment": "12 pages, 3 figures. SIGIR '25 Proceedings of the 48th International\n  ACM SIGIR Conference on Research and Development in Information Retrieval\n  July 13--18, 2025 Padua, Italy. Code and pretrained models available at:\n  https://github.com/kidist-amde/ddro/", "summary": "Generative information retrieval (GenIR) is a promising neural retrieval\nparadigm that formulates document retrieval as a document identifier (docid)\ngeneration task, allowing for end-to-end optimization toward a unified global\nretrieval objective. However, existing GenIR models suffer from token-level\nmisalignment, where models trained to predict the next token often fail to\ncapture document-level relevance effectively. While reinforcement\nlearning-based methods, such as reinforcement learning from relevance feedback\n(RLRF), aim to address this misalignment through reward modeling, they\nintroduce significant complexity, requiring the optimization of an auxiliary\nreward function followed by reinforcement fine-tuning, which is computationally\nexpensive and often unstable. To address these challenges, we propose direct\ndocument relevance optimization (DDRO), which aligns token-level docid\ngeneration with document-level relevance estimation through direct optimization\nvia pairwise ranking, eliminating the need for explicit reward modeling and\nreinforcement learning. Experimental results on benchmark datasets, including\nMS MARCO document and Natural Questions, show that DDRO outperforms\nreinforcement learning-based methods, achieving a 7.4% improvement in MRR@10\nfor MS MARCO and a 19.9% improvement for Natural Questions. These findings\nhighlight DDRO's potential to enhance retrieval effectiveness with a simplified\noptimization approach. By framing alignment as a direct optimization problem,\nDDRO simplifies the ranking optimization pipeline of GenIR models while\noffering a viable alternative to reinforcement learning-based methods."}
{"id": "2503.11963", "pdf": "https://arxiv.org/pdf/2503.11963", "abs": "https://arxiv.org/abs/2503.11963", "authors": ["Zhihao Zeng", "Ziquan Fang", "Yuting Huang", "Lu Chen", "Yunjun Gao"], "title": "Effective and Efficient Cross-City Traffic Knowledge Transfer: A Privacy-Preserving Perspective", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Traffic prediction targets forecasting future traffic conditions using\nhistorical traffic data, serving a critical role in urban computing and\ntransportation management. To mitigate the scarcity of traffic data while\nmaintaining data privacy, numerous Federated Traffic Knowledge Transfer (FTT)\napproaches have been developed, which use transfer learning and federated\nlearning to transfer traffic knowledge from data-rich cities to data-scarce\ncities, enhancing traffic prediction capabilities for the latter. However,\ncurrent FTT approaches face challenges such as privacy leakage, cross-city data\ndistribution discrepancies, low data quality, and inefficient knowledge\ntransfer, limiting their privacy protection, effectiveness, robustness, and\nefficiency in real-world applications.\n  To this end, we propose FedTT, an effective, efficient, and privacy-aware\ncross-city traffic knowledge transfer framework that transforms the traffic\ndata domain from the data-rich cities and trains traffic models using the\ntransformed data for the data-scarce cities. First, to safeguard data privacy,\nwe propose a traffic secret transmission method that securely transmits and\naggregates traffic domain-transformed data from source cities using a\nlightweight secret aggregation approach. Second, to mitigate the impact of\ntraffic data distribution discrepancies on model performance, we introduce a\ntraffic domain adapter to uniformly transform traffic data from the source\ncities' domains to that of the target city. Third, to improve traffic data\nquality, we design a traffic view imputation method to fill in and predict\nmissing traffic data. Finally, to enhance transfer efficiency, FedTT is\nequipped with a federated parallel training method that enables the\nsimultaneous training of multiple modules. Extensive experiments using 4\nreal-life datasets demonstrate that FedTT outperforms the 14 state-of-the-art\nbaselines."}
{"id": "2504.16516", "pdf": "https://arxiv.org/pdf/2504.16516", "abs": "https://arxiv.org/abs/2504.16516", "authors": ["Junrong Yue", "Yifan Zhang", "Chuan Qin", "Bo Li", "Xiaomin Lie", "Xinlei Yu", "Wenxin Zhang", "Zhendong Zhao"], "title": "Think Hierarchically, Act Dynamically: Hierarchical Multi-modal Fusion and Reasoning for Vision-and-Language Navigation", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 4 figures, Submitted to ACM MM 2025", "summary": "Vision-and-Language Navigation (VLN) aims to enable embodied agents to follow\nnatural language instructions and reach target locations in real-world\nenvironments. While prior methods often rely on either global scene\nrepresentations or object-level features, these approaches are insufficient for\ncapturing the complex interactions across modalities required for accurate\nnavigation. In this paper, we propose a Multi-level Fusion and Reasoning\nArchitecture (MFRA) to enhance the agent's ability to reason over visual\nobservations, language instructions and navigation history. Specifically, MFRA\nintroduces a hierarchical fusion mechanism that aggregates multi-level\nfeatures-ranging from low-level visual cues to high-level semantic\nconcepts-across multiple modalities. We further design a reasoning module that\nleverages fused representations to infer navigation actions through\ninstruction-guided attention and dynamic context integration. By selectively\ncapturing and combining relevant visual, linguistic, and temporal signals, MFRA\nimproves decision-making accuracy in complex navigation scenarios. Extensive\nexperiments on benchmark VLN datasets including REVERIE, R2R, and SOON\ndemonstrate that MFRA achieves superior performance compared to\nstate-of-the-art methods, validating the effectiveness of multi-level modal\nfusion for embodied navigation."}
{"id": "2504.05341", "pdf": "https://arxiv.org/pdf/2504.05341", "abs": "https://arxiv.org/abs/2504.05341", "authors": ["Szymon Mazurek", "Jakub Caputa", "Jan K. Argasi≈Ñski", "Maciej Wielgosz"], "title": "Three-Factor Learning in Spiking Neural Networks: An Overview of Methods and Trends from a Machine Learning Perspective", "categories": ["cs.NE", "cs.AI", "cs.LG", "92B20, 68T05, 92B25, 37N25, 60J22, 68Q32", "I.2.6; I.2.10; I.2.9; I.2.3; C.1.3; F.4.1; J.2"], "comment": "Pre-print", "summary": "Three-factor learning rules in Spiking Neural Networks (SNNs) have emerged as\na crucial extension to traditional Hebbian learning and Spike-Timing-Dependent\nPlasticity (STDP), incorporating neuromodulatory signals to improve adaptation\nand learning efficiency. These mechanisms enhance biological plausibility and\nfacilitate improved credit assignment in artificial neural systems. This paper\ntakes a view on this topic from a machine learning perspective, providing an\noverview of recent advances in three-factor learning, discusses theoretical\nfoundations, algorithmic implementations, and their relevance to reinforcement\nlearning and neuromorphic computing. In addition, we explore interdisciplinary\napproaches, scalability challenges, and potential applications in robotics,\ncognitive modeling, and AI systems. Finally, we highlight key research gaps and\npropose future directions for bridging the gap between neuroscience and\nartificial intelligence."}
{"id": "2503.12098", "pdf": "https://arxiv.org/pdf/2503.12098", "abs": "https://arxiv.org/abs/2503.12098", "authors": ["Wuzhou Sun", "Siyi Li", "Qingxiang Zou", "Zixing Liao"], "title": "Eval-PPO: Building an Efficient Threat Evaluator Using Proximal Policy Optimization", "categories": ["cs.LG"], "comment": "The research content is not yet complete and requires further\n  supplementation and improvement", "summary": "In various game scenarios, selecting a fixed number of targets from multiple\nenemy units is an extremely challenging task. This difficulty stems from the\ncomplex relationship between the threat levels of enemy units and their feature\ncharacteristics, which complicates the design of rule-based evaluators.\nMoreover, traditional supervised learning methods face the challenge of lacking\nexplicit labels during training when applied to this threat evaluation problem.\nIn this study, we redefine the threat evaluation problem as a reinforcement\nlearning task and introduce an efficient evaluator training algorithm,\nEval-PPO, based on the Proximal Policy Optimization (PPO) algorithm. Eval-PPO\nintegrates multidimensional enemy features and the state information of\nfriendly units through systematic training, thereby achieving precise threat\nassessment. Compared with rule-based methods, Eval-PPO demonstrates a\nsignificant improvement in average success rate, with an increase of 17.84%."}
{"id": "2504.16656", "pdf": "https://arxiv.org/pdf/2504.16656", "abs": "https://arxiv.org/abs/2504.16656", "authors": ["Chris", "Yichen Wei", "Yi Peng", "Xiaokun Wang", "Weijie Qiu", "Wei Shen", "Tianyidan Xie", "Jiangbo Pei", "Jianhao Zhang", "Yunzhuo Hao", "Xuchen Song", "Yang Liu", "Yahui Zhou"], "title": "Skywork R1V2: Multimodal Hybrid Reinforcement Learning for Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "We present Skywork R1V2, a next-generation multimodal reasoning model and a\nmajor leap forward from its predecessor, Skywork R1V. At its core, R1V2\nintroduces a hybrid reinforcement learning paradigm that jointly leverages the\nMixed Preference Optimization (MPO) and the Group Relative Policy Optimization\n(GRPO), which harmonizes reward-model guidance with rule-based strategies,\nthereby addressing the long-standing challenge of balancing sophisticated\nreasoning capabilities with broad generalization. To further enhance training\nefficiency, we introduce the Selective Sample Buffer (SSB) mechanism, which\neffectively counters the ``Vanishing Advantages'' dilemma inherent in GRPO by\nprioritizing high-value samples throughout the optimization process. Notably,\nwe observe that excessive reinforcement signals can induce visual\nhallucinations--a phenomenon we systematically monitor and mitigate through\ncalibrated reward thresholds throughout the training process. Empirical results\naffirm the exceptional capability of R1V2, with benchmark-leading performances\nsuch as 62.6 on OlympiadBench, 78.9 on AIME2024, 63.6 on LiveCodeBench, and\n73.6 on MMMU. These results underscore R1V2's superiority over existing\nopen-source models and demonstrate significant progress in closing the\nperformance gap with premier proprietary systems, including Gemini 2.5 and\nOpenAI-o4-mini. The Skywork R1V2 model weights have been publicly released to\npromote openness and reproducibility\nhttps://huggingface.co/Skywork/Skywork-R1V2-38B."}
{"id": "2504.06643", "pdf": "https://arxiv.org/pdf/2504.06643", "abs": "https://arxiv.org/abs/2504.06643", "authors": ["Tiange Huang", "Yongjun Li"], "title": "AMAD: AutoMasked Attention for Unsupervised Multivariate Time Series Anomaly Detection", "categories": ["cs.LG", "cs.AI", "I.5.1"], "comment": "fix some grammar issues", "summary": "Unsupervised multivariate time series anomaly detection (UMTSAD) plays a\ncritical role in various domains, including finance, networks, and sensor\nsystems. In recent years, due to the outstanding performance of deep learning\nin general sequential tasks, many models have been specialized for deep UMTSAD\ntasks and have achieved impressive results, particularly those based on the\nTransformer and self-attention mechanisms. However, the sequence anomaly\nassociation assumptions underlying these models are often limited to specific\npredefined patterns and scenarios, such as concentrated or peak anomaly\npatterns. These limitations hinder their ability to generalize to diverse\nanomaly situations, especially where the lack of labels poses significant\nchallenges. To address these issues, we propose AMAD, which integrates\n\\textbf{A}uto\\textbf{M}asked Attention for UMTS\\textbf{AD} scenarios. AMAD\nintroduces a novel structure based on the AutoMask mechanism and an attention\nmixup module, forming a simple yet generalized anomaly association\nrepresentation framework. This framework is further enhanced by a Max-Min\ntraining strategy and a Local-Global contrastive learning approach. By\ncombining multi-scale feature extraction with automatic relative association\nmodeling, AMAD provides a robust and adaptable solution to UMTSAD challenges.\nExtensive experimental results demonstrate that the proposed model achieving\ncompetitive performance results compared to SOTA benchmarks across a variety of\ndatasets."}
{"id": "2504.04353", "pdf": "https://arxiv.org/pdf/2504.04353", "abs": "https://arxiv.org/abs/2504.04353", "authors": ["Jiaxiang Cheng", "Guoqiang Hu"], "title": "Extending Cox Proportional Hazards Model with Symbolic Non-Linear Log-Risk Functions for Survival Analysis", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The Cox proportional hazards (CPH) model has been widely applied in survival\nanalysis to estimate relative risks across different subjects given multiple\ncovariates. Traditional CPH models rely on a linear combination of covariates\nweighted with coefficients as the log-risk function, which imposes a strong and\nrestrictive assumption, limiting generalization. Recent deep learning methods\nenable non-linear log-risk functions. However, they often lack interpretability\ndue to the end-to-end training mechanisms. The implementation of\nKolmogorov-Arnold Networks (KAN) offers new possibilities for extending the CPH\nmodel with fully transparent and symbolic non-linear log-risk functions. In\nthis paper, we introduce Generalized Cox Proportional Hazards (GCPH) model, a\nnovel method for survival analysis that leverages KAN to enable a non-linear\nmapping from covariates to survival outcomes in a fully symbolic manner. GCPH\nmaintains the interpretability of traditional CPH models while allowing for the\nestimation of non-linear log-risk functions. Experiments conducted on both\nsynthetic data and various public benchmarks demonstrate that GCPH achieves\ncompetitive performance in terms of prediction accuracy and exhibits superior\ninterpretability compared to current state-of-the-art methods."}
{"id": "2504.17180", "pdf": "https://arxiv.org/pdf/2504.17180", "abs": "https://arxiv.org/abs/2504.17180", "authors": ["Minkyu Choi", "S P Sharan", "Harsh Goel", "Sahil Shah", "Sandeep Chinchali"], "title": "We'll Fix it in Post: Improving Text-to-Video Generation with Neuro-Symbolic Feedback", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Current text-to-video (T2V) generation models are increasingly popular due to\ntheir ability to produce coherent videos from textual prompts. However, these\nmodels often struggle to generate semantically and temporally consistent videos\nwhen dealing with longer, more complex prompts involving multiple objects or\nsequential events. Additionally, the high computational costs associated with\ntraining or fine-tuning make direct improvements impractical. To overcome these\nlimitations, we introduce NeuS-E, a novel zero-training video refinement\npipeline that leverages neuro-symbolic feedback to automatically enhance video\ngeneration, achieving superior alignment with the prompts. Our approach first\nderives the neuro-symbolic feedback by analyzing a formal video representation\nand pinpoints semantically inconsistent events, objects, and their\ncorresponding frames. This feedback then guides targeted edits to the original\nvideo. Extensive empirical evaluations on both open-source and proprietary T2V\nmodels demonstrate that NeuS-E significantly enhances temporal and logical\nalignment across diverse prompts by almost 40%"}
{"id": "2504.07839", "pdf": "https://arxiv.org/pdf/2504.07839", "abs": "https://arxiv.org/abs/2504.07839", "authors": ["Zhiwei Xu", "Yujuan Wu", "Shiheng Wang", "Jiabao Gao", "Tian Qiu", "Ziqi Wang", "Hai Wan", "Xibin Zhao"], "title": "Deep Learning-based Intrusion Detection Systems: A Survey", "categories": ["cs.CR", "cs.AI"], "comment": "35 pages, 238 citations", "summary": "Intrusion Detection Systems (IDS) have long been a hot topic in the\ncybersecurity community. In recent years, with the introduction of deep\nlearning (DL) techniques, IDS have made great progress due to their increasing\ngeneralizability. The rationale behind this is that by learning the underlying\npatterns of known system behaviors, IDS detection can be generalized to\nintrusions that exploit zero-day vulnerabilities. In this survey, we refer to\nthis type of IDS as DL-based IDS (DL-IDS). From the perspective of DL, this\nsurvey systematically reviews all the stages of DL-IDS, including data\ncollection, log storage, log parsing, graph summarization, attack detection,\nand attack investigation. To accommodate current researchers, a section\ndescribing the publicly available benchmark datasets is included. This survey\nfurther discusses current challenges and potential future research directions,\naiming to help researchers understand the basic ideas and visions of DL-IDS\nresearch, as well as to motivate their research interests."}
{"id": "2504.12446", "pdf": "https://arxiv.org/pdf/2504.12446", "abs": "https://arxiv.org/abs/2504.12446", "authors": ["Sebastian Seidel", "Uwe M. Borghoff"], "title": "Deriving Equivalent Symbol-Based Decision Models from Feedforward Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": "15 pages, 19 figures", "summary": "Artificial intelligence (AI) has emerged as a transformative force across\nindustries, driven by advances in deep learning and natural language\nprocessing, and fueled by large-scale data and computing resources. Despite its\nrapid adoption, the opacity of AI systems poses significant challenges to trust\nand acceptance.\n  This work explores the intersection of connectionist and symbolic approaches\nto artificial intelligence, focusing on the derivation of interpretable\nsymbolic models, such as decision trees, from feedforward neural networks\n(FNNs). Decision trees provide a transparent framework for elucidating the\noperations of neural networks while preserving their functionality. The\nderivation is presented in a step-by-step approach and illustrated with several\nexamples. A systematic methodology is proposed to bridge neural and symbolic\nparadigms by exploiting distributed representations in FNNs to identify\nsymbolic components, including fillers, roles, and their interrelationships.\nThe process traces neuron activation values and input configurations across\nnetwork layers, mapping activations and their underlying inputs to decision\ntree edges. The resulting symbolic structures effectively capture FNN decision\nprocesses and enable scalability to deeper networks through iterative\nrefinement of subpaths for each hidden layer.\n  To validate the theoretical framework, a prototype was developed using Keras\n.h5-data and emulating TensorFlow within the Java JDK/JavaFX environment. This\nprototype demonstrates the feasibility of extracting symbolic representations\nfrom neural networks, enhancing trust in AI systems, and promoting\naccountability."}
{"id": "2504.17371", "pdf": "https://arxiv.org/pdf/2504.17371", "abs": "https://arxiv.org/abs/2504.17371", "authors": ["Oussema Dhaouadi", "Johannes Meier", "Luca Wahl", "Jacques Kaiser", "Luca Scalerandi", "Nick Wandelburg", "Zhuolun Zhou", "Nijanthan Berinpanathan", "Holger Banzhaf", "Daniel Cremers"], "title": "Highly Accurate and Diverse Traffic Data: The DeepScenario Open 3D Dataset", "categories": ["cs.CV"], "comment": null, "summary": "Accurate 3D trajectory data is crucial for advancing autonomous driving. Yet,\ntraditional datasets are usually captured by fixed sensors mounted on a car and\nare susceptible to occlusion. Additionally, such an approach can precisely\nreconstruct the dynamic environment in the close vicinity of the measurement\nvehicle only, while neglecting objects that are further away. In this paper, we\nintroduce the DeepScenario Open 3D Dataset (DSC3D), a high-quality,\nocclusion-free dataset of 6 degrees of freedom bounding box trajectories\nacquired through a novel monocular camera drone tracking pipeline. Our dataset\nincludes more than 175,000 trajectories of 14 types of traffic participants and\nsignificantly exceeds existing datasets in terms of diversity and scale,\ncontaining many unprecedented scenarios such as complex vehicle-pedestrian\ninteraction on highly populated urban streets and comprehensive parking\nmaneuvers from entry to exit. DSC3D dataset was captured in five various\nlocations in Europe and the United States and include: a parking lot, a crowded\ninner-city, a steep urban intersection, a federal highway, and a suburban\nintersection. Our 3D trajectory dataset aims to enhance autonomous driving\nsystems by providing detailed environmental 3D representations, which could\nlead to improved obstacle interactions and safety. We demonstrate its utility\nacross multiple applications including motion prediction, motion planning,\nscenario mining, and generative reactive traffic agents. Our interactive online\nvisualization platform and the complete dataset are publicly available at\nhttps://app.deepscenario.com, facilitating research in motion prediction,\nbehavior modeling, and safety validation."}
{"id": "2504.13948", "pdf": "https://arxiv.org/pdf/2504.13948", "abs": "https://arxiv.org/abs/2504.13948", "authors": ["Juan David Salazar Rodriguez", "Sam Conrad Joyce", "Julfendi"], "title": "Using customized GPT to develop prompting proficiency in architectural AI-generated images", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "This research investigates the use of customized GPT models to enhance\nprompting proficiency among architecture students when generating AI-driven\nimages. Prompt engineering is increasingly essential in architectural education\ndue to the widespread adoption of generative AI tools. This study utilized a\nmixed-methods experimental design involving architecture students divided into\nthree distinct groups: a control group receiving no structured support, a\nsecond group provided with structured prompting guides, and a third group\nsupported by both structured guides and interactive AI personas. Students\nengaged in reverse engineering tasks, first guessing provided image prompts and\nthen generating their own prompts, aiming to boost critical thinking and\nprompting skills. Variables examined included time spent prompting, word count,\nprompt similarity, and concreteness. Quantitative analysis involved correlation\nassessments between these variables and a one-way ANOVA to evaluate differences\nacross groups. While several correlations showed meaningful relationships, not\nall were statistically significant. ANOVA results indicated statistically\nsignificant improvements in word count, similarity, and concreteness,\nespecially in the group supported by AI personas and structured prompting\nguides. Qualitative feedback complemented these findings, revealing enhanced\nconfidence and critical thinking skills in students. These results suggest\ntailored GPT interactions substantially improve students' ability to\ncommunicate architectural concepts clearly and effectively."}
{"id": "2504.13768", "pdf": "https://arxiv.org/pdf/2504.13768", "abs": "https://arxiv.org/abs/2504.13768", "authors": ["Vinay Sharma", "R√©mi Tanguy Oddon", "Pietro Tesini", "Jens Ravesloot", "Cees Taal", "Olga Fink"], "title": "Equi-Euler GraphNet: An Equivariant, Temporal-Dynamics Informed Graph Neural Network for Dual Force and Trajectory Prediction in Multi-Body Systems", "categories": ["cs.LG", "cs.CE", "physics.comp-ph"], "comment": "Reuploaded with new version-- equation 16 was incorrect", "summary": "Accurate real-time modeling of multi-body dynamical systems is essential for\nenabling digital twin applications across industries. While many data-driven\napproaches aim to learn system dynamics, jointly predicting internal loads and\nsystem trajectories remains a key challenge. This dual prediction is especially\nimportant for fault detection and predictive maintenance, where internal\nloads-such as contact forces-act as early indicators of faults, reflecting wear\nor misalignment before affecting motion. These forces also serve as inputs to\ndegradation models (e.g., crack growth), enabling damage prediction and\nremaining useful life estimation. We propose Equi-Euler GraphNet, a\nphysics-informed graph neural network (GNN) that simultaneously predicts\ninternal forces and global trajectories in multi-body systems. In this\nmesh-free framework, nodes represent system components and edges encode\ninteractions. Equi-Euler GraphNet introduces two inductive biases: (1) an\nequivariant message-passing scheme, interpreting edge messages as interaction\nforces consistent under Euclidean transformations; and (2) a temporal-aware\niterative node update mechanism, based on Euler integration, to capture\ninfluence of distant interactions over time. Tailored for cylindrical roller\nbearings, it decouples ring dynamics from constrained motion of rolling\nelements. Trained on high-fidelity multiphysics simulations, Equi-Euler\nGraphNet generalizes beyond the training distribution, accurately predicting\nloads and trajectories under unseen speeds, loads, and configurations. It\noutperforms state-of-the-art GNNs focused on trajectory prediction, delivering\nstable rollouts over thousands of time steps with minimal error accumulation.\nAchieving up to a 200x speedup over conventional solvers while maintaining\ncomparable accuracy, it serves as an efficient reduced-order model for digital\ntwins, design, and maintenance."}
{"id": "2504.17696", "pdf": "https://arxiv.org/pdf/2504.17696", "abs": "https://arxiv.org/abs/2504.17696", "authors": ["Ghazal Kaviani", "Yavuz Yarici", "Seulgi Kim", "Mohit Prabhushankar", "Ghassan AlRegib", "Mashhour Solh", "Ameya Patil"], "title": "Hierarchical and Multimodal Data for Daily Activity Understanding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Daily Activity Recordings for Artificial Intelligence (DARai, pronounced\n\"Dahr-ree\") is a multimodal, hierarchically annotated dataset constructed to\nunderstand human activities in real-world settings. DARai consists of\ncontinuous scripted and unscripted recordings of 50 participants in 10\ndifferent environments, totaling over 200 hours of data from 20 sensors\nincluding multiple camera views, depth and radar sensors, wearable inertial\nmeasurement units (IMUs), electromyography (EMG), insole pressure sensors,\nbiomonitor sensors, and gaze tracker.\n  To capture the complexity in human activities, DARai is annotated at three\nlevels of hierarchy: (i) high-level activities (L1) that are independent tasks,\n(ii) lower-level actions (L2) that are patterns shared between activities, and\n(iii) fine-grained procedures (L3) that detail the exact execution steps for\nactions. The dataset annotations and recordings are designed so that 22.7% of\nL2 actions are shared between L1 activities and 14.2% of L3 procedures are\nshared between L2 actions. The overlap and unscripted nature of DARai allows\ncounterfactual activities in the dataset.\n  Experiments with various machine learning models showcase the value of DARai\nin uncovering important challenges in human-centered applications.\nSpecifically, we conduct unimodal and multimodal sensor fusion experiments for\nrecognition, temporal localization, and future action anticipation across all\nhierarchical annotation levels. To highlight the limitations of individual\nsensors, we also conduct domain-variant experiments that are enabled by DARai's\nmulti-sensor and counterfactual activity design setup.\n  The code, documentation, and dataset are available at the dedicated DARai\nwebsite:\nhttps://alregib.ece.gatech.edu/software-and-datasets/darai-daily-activity-recordings-for-artificial-intelligence-and-machine-learning/"}
{"id": "2504.14300", "pdf": "https://arxiv.org/pdf/2504.14300", "abs": "https://arxiv.org/abs/2504.14300", "authors": ["Xinyu Liang", "Hao Wang"], "title": "Learning and Generating Diverse Residential Load Patterns Using GAN with Weakly-Supervised Training and Weight Selection", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages", "summary": "The scarcity of high-quality residential load data can pose obstacles for\ndecarbonizing the residential sector as well as effective grid planning and\noperation. The above challenges have motivated research into generating\nsynthetic load data, but existing methods faced limitations in terms of\nscalability, diversity, and similarity. This paper proposes a Generative\nAdversarial Network-based Synthetic Residential Load Pattern (RLP-GAN)\ngeneration model, a novel weakly-supervised GAN framework, leveraging an\nover-complete autoencoder to capture dependencies within complex and diverse\nload patterns and learn household-level data distribution at scale. We\nincorporate a model weight selection method to address the mode collapse\nproblem and generate load patterns with high diversity. We develop a holistic\nevaluation method to validate the effectiveness of RLP-GAN using real-world\ndata of 417 households. The results demonstrate that RLP-GAN outperforms\nstate-of-the-art models in capturing temporal dependencies and generating load\npatterns with higher similarity to real data. Furthermore, we have publicly\nreleased the RLP-GAN generated synthetic dataset, which comprises one million\nsynthetic residential load pattern profiles."}
{"id": "2504.14587", "pdf": "https://arxiv.org/pdf/2504.14587", "abs": "https://arxiv.org/abs/2504.14587", "authors": ["Jingtong Gao", "Yewen Li", "Shuai Mao", "Peng Jiang", "Nan Jiang", "Yejing Wang", "Qingpeng Cai", "Fei Pan", "Peng Jiang", "Kun Gai", "Bo An", "Xiangyu Zhao"], "title": "Generative Auto-Bidding with Value-Guided Explorations", "categories": ["cs.LG", "cs.IR"], "comment": null, "summary": "Auto-bidding, with its strong capability to optimize bidding decisions within\ndynamic and competitive online environments, has become a pivotal strategy for\nadvertising platforms. Existing approaches typically employ rule-based\nstrategies or Reinforcement Learning (RL) techniques. However, rule-based\nstrategies lack the flexibility to adapt to time-varying market conditions, and\nRL-based methods struggle to capture essential historical dependencies and\nobservations within Markov Decision Process (MDP) frameworks. Furthermore,\nthese approaches often face challenges in ensuring strategy adaptability across\ndiverse advertising objectives. Additionally, as offline training methods are\nincreasingly adopted to facilitate the deployment and maintenance of stable\nonline strategies, the issues of documented behavioral patterns and behavioral\ncollapse resulting from training on fixed offline datasets become increasingly\nsignificant. To address these limitations, this paper introduces a novel\noffline Generative Auto-bidding framework with Value-Guided Explorations\n(GAVE). GAVE accommodates various advertising objectives through a score-based\nReturn-To-Go (RTG) module. Moreover, GAVE integrates an action exploration\nmechanism with an RTG-based evaluation method to explore novel actions while\nensuring stability-preserving updates. A learnable value function is also\ndesigned to guide the direction of action exploration and mitigate\nOut-of-Distribution (OOD) problems. Experimental results on two offline\ndatasets and real-world deployments demonstrate that GAVE outperforms\nstate-of-the-art baselines in both offline evaluations and online A/B tests. By\napplying the core methods of this framework, we proudly secured first place in\nthe NeurIPS 2024 competition, 'AIGB Track: Learning Auto-Bidding Agents with\nGenerative Models'."}
{"id": "2411.17340", "pdf": "https://arxiv.org/pdf/2411.17340", "abs": "https://arxiv.org/abs/2411.17340", "authors": ["Aleksei Luchinsky", "Umar Islambekov"], "title": "TDAvec: Computing Vector Summaries of Persistence Diagrams for Topological Data Analysis in R and Python", "categories": ["math.AT", "cs.CV"], "comment": "8 pages, 2 figures, 3 tables; minor changes: updated version of the\n  library is described", "summary": "Persistent homology is a widely-used tool in topological data analysis (TDA)\nfor understanding the underlying shape of complex data. By constructing a\nfiltration of simplicial complexes from data points, it captures topological\nfeatures such as connected components, loops, and voids across multiple scales.\nThese features are encoded in persistence diagrams (PDs), which provide a\nconcise summary of the data's topological structure. However, the non-Hilbert\nnature of the space of PDs poses challenges for their direct use in machine\nlearning applications. To address this, kernel methods and vectorization\ntechniques have been developed to transform PDs into\nmachine-learning-compatible formats. In this paper, we introduce a new software\npackage designed to streamline the vectorization of PDs, offering an intuitive\nworkflow and advanced functionalities. We demonstrate the necessity of the\npackage through practical examples and provide a detailed discussion on its\ncontributions to applied TDA. Definitions of all vectorization summaries used\nin the package are included in the appendix."}
{"id": "2504.14560", "pdf": "https://arxiv.org/pdf/2504.14560", "abs": "https://arxiv.org/abs/2504.14560", "authors": ["Haiyan Qin", "Zhiwei Xie", "Jingjing Li", "Liangchen Li", "Xiaotong Feng", "Junzhan Liu", "Wang Kang"], "title": "ReasoningV: Efficient Verilog Code Generation with Adaptive Hybrid Reasoning Model", "categories": ["cs.AR", "cs.AI"], "comment": "9 pages, 4 figures", "summary": "Large Language Models (LLMs) have advanced Verilog code generation\nsignificantly, yet face challenges in data quality, reasoning capabilities, and\ncomputational efficiency. This paper presents ReasoningV, a novel model\nemploying a hybrid reasoning strategy that integrates trained intrinsic\ncapabilities with dynamic inference adaptation for Verilog code generation. Our\nframework introduces three complementary innovations: (1) ReasoningV-5K, a\nhigh-quality dataset of 5,000 functionally verified instances with reasoning\npaths created through multi-dimensional filtering of PyraNet samples; (2) a\ntwo-stage training approach combining parameter-efficient fine-tuning for\nfoundational knowledge with full-parameter optimization for enhanced reasoning;\nand (3) an adaptive reasoning mechanism that dynamically adjusts reasoning\ndepth based on problem complexity, reducing token consumption by up to 75\\%\nwhile preserving performance. Experimental results demonstrate ReasoningV's\neffectiveness with a pass@1 accuracy of 57.8\\% on VerilogEval-human, achieving\nperformance competitive with leading commercial models like Gemini-2.0-flash\n(59.5\\%) and exceeding the previous best open-source model by 10.4 percentage\npoints. ReasoningV offers a more reliable and accessible pathway for advancing\nAI-driven hardware design automation, with our model, data, and code available\nat https://github.com/BUAA-CLab/ReasoningV."}
{"id": "2504.15920", "pdf": "https://arxiv.org/pdf/2504.15920", "abs": "https://arxiv.org/abs/2504.15920", "authors": ["Xiang Li", "Haobing Liu", "Jianpeng Qi", "Yuan Cao", "Guoqing Chao", "Yanwei Yu"], "title": "ScaleGNN: Towards Scalable Graph Neural Networks via Adaptive High-order Neighboring Feature Fusion", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have demonstrated strong performance across\nvarious graph-based tasks by effectively capturing relational information\nbetween nodes. These models rely on iterative message passing to propagate node\nfeatures, enabling nodes to aggregate information from their neighbors. Recent\nresearch has significantly improved the message-passing mechanism, enhancing\nGNN scalability on large-scale graphs. However, GNNs still face two main\nchallenges: over-smoothing, where excessive message passing results in\nindistinguishable node representations, especially in deep networks\nincorporating high-order neighbors; and scalability issues, as traditional\narchitectures suffer from high model complexity and increased inference time\ndue to redundant information aggregation. This paper proposes a novel framework\nfor large-scale graphs named ScaleGNN that simultaneously addresses both\nchallenges by adaptively fusing multi-level graph features. We first construct\nneighbor matrices for each order, learning their relative information through\ntrainable weights through an adaptive high-order feature fusion module. This\nallows the model to selectively emphasize informative high-order neighbors\nwhile reducing unnecessary computational costs. Additionally, we introduce a\nHigh-order redundant feature masking mechanism based on a Local Contribution\nScore (LCS), which enables the model to retain only the most relevant neighbors\nat each order, preventing redundant information propagation. Furthermore,\nlow-order enhanced feature aggregation adaptively integrates low-order and\nhigh-order features based on task relevance, ensuring effective capture of both\nlocal and global structural information without excessive complexity. Extensive\nexperiments on real-world datasets demonstrate that our approach consistently\noutperforms state-of-the-art GNN models in both accuracy and computational\nefficiency."}
{"id": "2503.00200", "pdf": "https://arxiv.org/pdf/2503.00200", "abs": "https://arxiv.org/abs/2503.00200", "authors": ["Shuang Li", "Yihuai Gao", "Dorsa Sadigh", "Shuran Song"], "title": "Unified Video Action Model", "categories": ["cs.RO", "cs.CV"], "comment": "Project website: https://unified-video-action-model.github.io/", "summary": "A unified video and action model holds significant promise for robotics,\nwhere videos provide rich scene information for action prediction, and actions\nprovide dynamics information for video prediction. However, effectively\ncombining video generation and action prediction remains challenging, and\ncurrent video generation-based methods struggle to match the performance of\ndirect policy learning in action accuracy and inference speed. To bridge this\ngap, we introduce the Unified Video Action model (UVA), which jointly optimizes\nvideo and action predictions to achieve both high accuracy and efficient action\ninference. The key lies in learning a joint video-action latent representation\nand decoupling video-action decoding. The joint latent representation bridges\nthe visual and action domains, effectively modeling the relationship between\nvideo and action sequences. Meanwhile, the decoupled decoding, powered by two\nlightweight diffusion heads, enables high-speed action inference by bypassing\nvideo generation during inference. Such a unified framework further enables\nversatile functionality through masked input training. By selectively masking\nactions or videos, a single model can tackle diverse tasks beyond policy\nlearning, such as forward and inverse dynamics modeling and video generation.\nVia an extensive set of experiments, we demonstrate that UVA can serve as a\ngeneral-purpose solution for a wide range of robotics tasks, such as policy\nlearning, forward/inverse dynamics and video observation prediction, without\ncompromising performance compared to methods tailored for specific\napplications. Results are best viewed on\nhttps://unified-video-action-model.github.io/."}
{"id": "2504.14625", "pdf": "https://arxiv.org/pdf/2504.14625", "abs": "https://arxiv.org/abs/2504.14625", "authors": ["Haiyan Qin", "Jiahao Feng", "Xiaotong Feng", "Wei W. Xing", "Wang Kang"], "title": "Towards Optimal Circuit Generation: Multi-Agent Collaboration Meets Collective Intelligence", "categories": ["cs.AR", "cs.AI"], "comment": "9 pages, 6 figures", "summary": "Large language models (LLMs) have transformed code generation, yet their\napplication in hardware design produces gate counts 38\\%--1075\\% higher than\nhuman designs. We present CircuitMind, a multi-agent framework that achieves\nhuman-competitive efficiency through three key innovations: syntax locking\n(constraining generation to basic logic gates), retrieval-augmented generation\n(enabling knowledge-driven design), and dual-reward optimization (balancing\ncorrectness with efficiency). To evaluate our approach, we introduce TC-Bench,\nthe first gate-level benchmark harnessing collective intelligence from the\nTuringComplete ecosystem -- a competitive circuit design platform with hundreds\nof thousands of players. Experiments show CircuitMind enables 55.6\\% of model\nimplementations to match or exceed top-tier human experts in composite\nefficiency metrics. Most remarkably, our framework elevates the 14B Phi-4 model\nto outperform both GPT-4o mini and Gemini 2.0 Flash, achieving efficiency\ncomparable to the top 25\\% of human experts without requiring specialized\ntraining. These innovations establish a new paradigm for hardware optimization\nwhere collaborative AI systems leverage collective human expertise to achieve\noptimal circuit designs. Our model, data, and code are open-source at\nhttps://github.com/BUAA-CLab/CircuitMind."}
{"id": "2504.16268", "pdf": "https://arxiv.org/pdf/2504.16268", "abs": "https://arxiv.org/abs/2504.16268", "authors": ["Abdesslem Layeb"], "title": "Boosting KNNClassifier Performance with Opposition-Based Data Transformation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this paper, we introduce a novel data transformation framework based on\nOpposition-Based Learning (OBL) to boost the performance of traditional\nclassification algorithms. Originally developed to accelerate convergence in\noptimization tasks, OBL is leveraged here to generate synthetic opposite\nsamples that enrich the training data and improve decision boundary formation.\nWe explore three OBL variants Global OBL, Class-Wise OBL, and Localized\nClass-Wise OBL and integrate them with K-Nearest Neighbors (KNN). Extensive\nexperiments conducted on 26 heterogeneous and high-dimensional datasets\ndemonstrate that OBL-enhanced classifiers consistently outperform the basic\nKNN. These findings underscore the potential of OBL as a lightweight yet\npowerful data transformation strategy for enhancing classification performance,\nespecially in complex or sparse learning environments."}
{"id": "2504.16940", "pdf": "https://arxiv.org/pdf/2504.16940", "abs": "https://arxiv.org/abs/2504.16940", "authors": ["Drew Linsley", "Pinyuan Feng", "Thomas Serre"], "title": "Better artificial intelligence does not mean better models of biology", "categories": ["q-bio.NC", "cs.AI", "cs.CV"], "comment": null, "summary": "Deep neural networks (DNNs) once showed increasing alignment with primate\nperception and neural responses as they improved on vision benchmarks, raising\nhopes that advances in AI would yield better models of biological vision.\nHowever, we show across three benchmarks that this alignment is now plateauing\n- and in some cases worsening - as DNNs scale to human or superhuman accuracy.\nThis divergence may reflect the adoption of visual strategies that differ from\nthose used by primates. These findings challenge the view that progress in\nartificial intelligence will naturally translate to neuroscience. We argue that\nvision science must chart its own course, developing algorithms grounded in\nbiological visual systems rather than optimizing for benchmarks based on\ninternet-scale datasets."}
{"id": "2504.16172", "pdf": "https://arxiv.org/pdf/2504.16172", "abs": "https://arxiv.org/abs/2504.16172", "authors": ["Zexi Fan", "Yan Sun", "Shihao Yang", "Yiping Lu"], "title": "Physics-Informed Inference Time Scaling via Simulation-Calibrated Scientific Machine Learning", "categories": ["math.NA", "cs.AI", "cs.LG", "cs.NA", "math.PR", "stat.ML"], "comment": null, "summary": "High-dimensional partial differential equations (PDEs) pose significant\ncomputational challenges across fields ranging from quantum chemistry to\neconomics and finance. Although scientific machine learning (SciML) techniques\noffer approximate solutions, they often suffer from bias and neglect crucial\nphysical insights. Inspired by inference-time scaling strategies in language\nmodels, we propose Simulation-Calibrated Scientific Machine Learning (SCaSML),\na physics-informed framework that dynamically refines and debiases the SCiML\npredictions during inference by enforcing the physical laws. SCaSML leverages\nderived new physical laws that quantifies systematic errors and employs Monte\nCarlo solvers based on the Feynman-Kac and Elworthy-Bismut-Li formulas to\ndynamically correct the prediction. Both numerical and theoretical analysis\nconfirms enhanced convergence rates via compute-optimal inference methods. Our\nnumerical experiments demonstrate that SCaSML reduces errors by 20-50% compared\nto the base surrogate model, establishing it as the first algorithm to refine\napproximated solutions to high-dimensional PDE during inference. Code of SCaSML\nis available at https://github.com/Francis-Fan-create/SCaSML."}
{"id": "2504.16834", "pdf": "https://arxiv.org/pdf/2504.16834", "abs": "https://arxiv.org/abs/2504.16834", "authors": ["Yilin Zhai", "Hongyuan Shi", "Chao Zhan", "Qing Wang", "Zaijin You", "Nan Wang"], "title": "Improving Significant Wave Height Prediction Using Chronos Models", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "comment": "arXiv admin note: text overlap with arXiv:2403.07815 by other authors", "summary": "Accurate wave height prediction is critical for maritime safety and coastal\nresilience, yet conventional physics-based models and traditional machine\nlearning methods face challenges in computational efficiency and nonlinear\ndynamics modeling. This study introduces Chronos, the first implementation of a\nlarge language model (LLM)-powered temporal architecture (Chronos) optimized\nfor wave forecasting. Through advanced temporal pattern recognition applied to\nhistorical wave data from three strategically chosen marine zones in the\nNorthwest Pacific basin, our framework achieves multimodal improvements: (1)\n14.3% reduction in training time with 2.5x faster inference speed compared to\nPatchTST baselines, achieving 0.575 mean absolute scaled error (MASE) units;\n(2) superior short-term forecasting (1-24h) across comprehensive metrics; (3)\nsustained predictive leadership in extended-range forecasts (1-120h); and (4)\ndemonstrated zero-shot capability maintaining median performance (rank 4/12)\nagainst specialized operational models. This LLM-enhanced temporal modeling\nparadigm establishes a new standard in wave prediction, offering both\ncomputationally efficient solutions and a transferable framework for complex\ngeophysical systems modeling."}
{"id": "2504.17314", "pdf": "https://arxiv.org/pdf/2504.17314", "abs": "https://arxiv.org/abs/2504.17314", "authors": ["Miaoyun Zhao", "Qiang Zhang", "Chenrong Li"], "title": "Class-Conditional Distribution Balancing for Group Robust Classification", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Spurious correlations that lead models to correct predictions for the wrong\nreasons pose a critical challenge for robust real-world generalization.\nExisting research attributes this issue to group imbalance and addresses it by\nmaximizing group-balanced or worst-group accuracy, which heavily relies on\nexpensive bias annotations. A compromise approach involves predicting bias\ninformation using extensively pretrained foundation models, which requires\nlarge-scale data and becomes impractical for resource-limited rare domains. To\naddress these challenges, we offer a novel perspective by reframing the\nspurious correlations as imbalances or mismatches in class-conditional\ndistributions, and propose a simple yet effective robust learning method that\neliminates the need for both bias annotations and predictions. With the goal of\nreducing the mutual information between spurious factors and label information,\nour method leverages a sample reweighting strategy to achieve class-conditional\ndistribution balancing, which automatically highlights minority groups and\nclasses, effectively dismantling spurious correlations and producing a debiased\ndata distribution for classification. Extensive experiments and analysis\ndemonstrate that our approach consistently delivers state-of-the-art\nperformance, rivaling methods that rely on bias supervision."}
{"id": "2504.16968", "pdf": "https://arxiv.org/pdf/2504.16968", "abs": "https://arxiv.org/abs/2504.16968", "authors": ["Jun Wu", "Jiangtao Wen", "Yuxing Han"], "title": "BackSlash: Rate Constrained Optimized Training of Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The rapid advancement of large-language models (LLMs) has driven extensive\nresearch into parameter compression after training has been completed, yet\ncompression during the training phase remains largely unexplored. In this work,\nwe introduce Rate-Constrained Training (BackSlash), a novel training-time\ncompression approach based on rate-distortion optimization (RDO). BackSlash\nenables a flexible trade-off between model accuracy and complexity,\nsignificantly reducing parameter redundancy while preserving performance.\nExperiments in various architectures and tasks demonstrate that BackSlash can\nreduce memory usage by 60% - 90% without accuracy loss and provides significant\ncompression gain compared to compression after training. Moreover, BackSlash\nproves to be highly versatile: it enhances generalization with small Lagrange\nmultipliers, improves model robustness to pruning (maintaining accuracy even at\n80% pruning rates), and enables network simplification for accelerated\ninference on edge devices."}
{"id": "2504.17243", "pdf": "https://arxiv.org/pdf/2504.17243", "abs": "https://arxiv.org/abs/2504.17243", "authors": ["Xinyu Zhou", "Simin Fan", "Martin Jaggi", "Jie Fu"], "title": "NeuralGrok: Accelerate Grokking by Neural Gradient Transformation", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint, 16 pages", "summary": "Grokking is proposed and widely studied as an intricate phenomenon in which\ngeneralization is achieved after a long-lasting period of overfitting. In this\nwork, we propose NeuralGrok, a novel gradient-based approach that learns an\noptimal gradient transformation to accelerate the generalization of\ntransformers in arithmetic tasks. Specifically, NeuralGrok trains an auxiliary\nmodule (e.g., an MLP block) in conjunction with the base model. This module\ndynamically modulates the influence of individual gradient components based on\ntheir contribution to generalization, guided by a bilevel optimization\nalgorithm. Our extensive experiments demonstrate that NeuralGrok significantly\naccelerates generalization, particularly in challenging arithmetic tasks. We\nalso show that NeuralGrok promotes a more stable training paradigm, constantly\nreducing the model's complexity, while traditional regularization methods, such\nas weight decay, can introduce substantial instability and impede\ngeneralization. We further investigate the intrinsic model complexity\nleveraging a novel Absolute Gradient Entropy (AGE) metric, which explains that\nNeuralGrok effectively facilitates generalization by reducing the model\ncomplexity. We offer valuable insights on the grokking phenomenon of\nTransformer models, which encourages a deeper understanding of the fundamental\nprinciples governing generalization ability."}
{"id": "2504.17384", "pdf": "https://arxiv.org/pdf/2504.17384", "abs": "https://arxiv.org/abs/2504.17384", "authors": ["Hanlin Sheng", "Xinming Wu", "Hang Gao", "Haibin Di", "Sergey Fomel", "Jintao Li", "Xu Si"], "title": "On the workflow, opportunities and challenges of developing foundation model in geophysics", "categories": ["physics.geo-ph", "cs.AI"], "comment": null, "summary": "Foundation models, as a mainstream technology in artificial intelligence,\nhave demonstrated immense potential across various domains in recent years,\nparticularly in handling complex tasks and multimodal data. In the field of\ngeophysics, although the application of foundation models is gradually\nexpanding, there is currently a lack of comprehensive reviews discussing the\nfull workflow of integrating foundation models with geophysical data. To\naddress this gap, this paper presents a complete framework that systematically\nexplores the entire process of developing foundation models in conjunction with\ngeophysical data. From data collection and preprocessing to model architecture\nselection, pre-training strategies, and model deployment, we provide a detailed\nanalysis of the key techniques and methodologies at each stage. In particular,\nconsidering the diversity, complexity, and physical consistency constraints of\ngeophysical data, we discuss targeted solutions to address these challenges.\nFurthermore, we discuss how to leverage the transfer learning capabilities of\nfoundation models to reduce reliance on labeled data, enhance computational\nefficiency, and incorporate physical constraints into model training, thereby\nimproving physical consistency and interpretability. Through a comprehensive\nsummary and analysis of the current technological landscape, this paper not\nonly fills the gap in the geophysics domain regarding a full-process review of\nfoundation models but also offers valuable practical guidance for their\napplication in geophysical data analysis, driving innovation and advancement in\nthe field."}
{"id": "2504.17641", "pdf": "https://arxiv.org/pdf/2504.17641", "abs": "https://arxiv.org/abs/2504.17641", "authors": ["Shengtao Zhang", "Haokai Zhang", "Shiqi Lou", "Zicheng Wang", "Zinan Zeng", "Yilin Wang", "Minnan Luo"], "title": "PTCL: Pseudo-Label Temporal Curriculum Learning for Label-Limited Dynamic Graph", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 5 figures", "summary": "Dynamic node classification is critical for modeling evolving systems like\nfinancial transactions and academic collaborations. In such systems,\ndynamically capturing node information changes is critical for dynamic node\nclassification, which usually requires all labels at every timestamp. However,\nit is difficult to collect all dynamic labels in real-world scenarios due to\nhigh annotation costs and label uncertainty (e.g., ambiguous or delayed labels\nin fraud detection). In contrast, final timestamp labels are easier to obtain\nas they rely on complete temporal patterns and are usually maintained as a\nunique label for each user in many open platforms, without tracking the history\ndata. To bridge this gap, we propose PTCL(Pseudo-label Temporal Curriculum\nLearning), a pioneering method addressing label-limited dynamic node\nclassification where only final labels are available. PTCL introduces: (1) a\ntemporal decoupling architecture separating the backbone (learning time-aware\nrepresentations) and decoder (strictly aligned with final labels), which\ngenerate pseudo-labels, and (2) a Temporal Curriculum Learning strategy that\nprioritizes pseudo-labels closer to the final timestamp by assigning them\nhigher weights using an exponentially decaying function. We contribute a new\nacademic dataset (CoOAG), capturing long-range research interest in dynamic\ngraph. Experiments across real-world scenarios demonstrate PTCL's consistent\nsuperiority over other methods adapted to this task. Beyond methodology, we\npropose a unified framework FLiD (Framework for Label-Limited Dynamic Node\nClassification), consisting of a complete preparation workflow, training\npipeline, and evaluation standards, and supporting various models and datasets.\nThe code can be found at https://github.com/3205914485/FLiD."}
{"id": "2010.14694", "pdf": "https://arxiv.org/pdf/2010.14694", "abs": "https://arxiv.org/abs/2010.14694", "authors": ["Max H. Farrell", "Tengyuan Liang", "Sanjog Misra"], "title": "Deep Learning for Individual Heterogeneity", "categories": ["econ.EM", "cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "This paper integrates deep neural networks (DNNs) into structural economic\nmodels to increase flexibility and capture rich heterogeneity while preserving\ninterpretability. Economic structure and machine learning are complements in\nempirical modeling, not substitutes: DNNs provide the capacity to learn\ncomplex, non-linear heterogeneity patterns, while the structural model ensures\nthe estimates remain interpretable and suitable for decision making and policy\nanalysis. We start with a standard parametric structural model and then enrich\nits parameters into fully flexible functions of observables, which are\nestimated using a particular DNN architecture whose structure reflects the\neconomic model. We illustrate our framework by studying demand estimation in\nconsumer choice. We show that by enriching a standard demand model we can\ncapture rich heterogeneity, and further, exploit this heterogeneity to create a\npersonalized pricing strategy. This type of optimization is not possible\nwithout economic structure, but cannot be heterogeneous without machine\nlearning. Finally, we provide theoretical justification of each step in our\nproposed methodology. We first establish non-asymptotic bounds and convergence\nrates of our structural deep learning approach. Next, a novel and quite general\ninfluence function calculation allows for feasible inference via double machine\nlearning in a wide variety of contexts. These results may be of interest in\nmany other contexts, as they generalize prior work."}
{"id": "2211.14708", "pdf": "https://arxiv.org/pdf/2211.14708", "abs": "https://arxiv.org/abs/2211.14708", "authors": ["Emile Anand", "Charles Steinhardt", "Martin Hansen"], "title": "Identifying Chemicals Through Dimensionality Reduction", "categories": ["q-bio.QM", "cs.DB", "cs.LG", "68T99", "I.2; I.m"], "comment": "12 pages, 24 figures", "summary": "Civilizations have tried to make drinking water safe to consume for thousands\nof years. The process of determining water contaminants has evolved with the\ncomplexity of the contaminants due to pesticides and heavy metals. The routine\nprocedure to determine water safety is to use targeted analysis which searches\nfor specific substances from some known list; however, we do not explicitly\nknow which substances should be on this list. Before experimentally determining\nwhich substances are contaminants, how do we answer the sampling problem of\nidentifying all the substances in the water? Here, we present an approach that\nbuilds on the work of Jaanus Liigand et al., which used non-targeted analysis\nthat conducts a broader search on the sample to develop a random-forest\nregression model, to predict the names of all the substances in a sample, as\nwell as their respective concentrations[1]. This work utilizes techniques from\ndimensionality reduction and linear decompositions to present a more accurate\nmodel using data from the European Massbank Metabolome Library to produce a\nglobal list of chemicals that researchers can then identify and test for when\npurifying water."}
{"id": "2402.03145", "pdf": "https://arxiv.org/pdf/2402.03145", "abs": "https://arxiv.org/abs/2402.03145", "authors": ["Robin Str√§sser", "Manuel Schaller", "Karl Worthmann", "Julian Berberich", "Frank Allg√∂wer"], "title": "SafEDMD: A Koopman-based data-driven controller design framework for nonlinear dynamical systems", "categories": ["eess.SY", "cs.LG", "cs.SY", "math.OC"], "comment": null, "summary": "The Koopman operator serves as the theoretical backbone for machine learning\nof dynamical control systems, where the operator is heuristically approximated\nby extended dynamic mode decomposition (EDMD). In this paper, we propose\nSafEDMD, a novel stability- and certificate-oriented EDMD-based controller\ndesign framework. Our approach leverages a reliable surrogate model generated\nin a data-driven fashion in order to provide closed-loop guarantees. In\nparticular, we establish a controller design based on semi-definite programming\nwith guaranteed stabilization of the underlying nonlinear system. As central\ningredient, we derive proportional error bounds that vanish at the origin and\nare tailored to control tasks. We illustrate the developed method by means of\nseveral benchmark examples and highlight the advantages over state-of-the-art\nmethods."}
{"id": "2402.05878", "pdf": "https://arxiv.org/pdf/2402.05878", "abs": "https://arxiv.org/abs/2402.05878", "authors": ["Nicolas Nguyen", "Imad Aouali", "Andr√°s Gy√∂rgy", "Claire Vernade"], "title": "Prior-Dependent Allocations for Bayesian Fixed-Budget Best-Arm Identification in Structured Bandits", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We study the problem of Bayesian fixed-budget best-arm identification (BAI)\nin structured bandits. We propose an algorithm that uses fixed allocations\nbased on the prior information and the structure of the environment. We provide\ntheoretical bounds on its performance across diverse models, including the\nfirst prior-dependent upper bounds for linear and hierarchical BAI. Our key\ncontribution is introducing new proof methods that result in tighter bounds for\nmulti-armed BAI compared to existing methods. We extensively compare our\napproach to other fixed-budget BAI methods, demonstrating its consistent and\nrobust performance in various settings. Our work improves our understanding of\nBayesian fixed-budget BAI in structured bandits and highlights the\neffectiveness of our approach in practical scenarios."}
{"id": "2404.19689", "pdf": "https://arxiv.org/pdf/2404.19689", "abs": "https://arxiv.org/abs/2404.19689", "authors": ["Kehan Shi", "Martin Burger"], "title": "Continuum limit of $p$-biharmonic equations on graphs", "categories": ["math.AP", "cs.LG", "cs.NA", "math.NA", "35R02, 35J30, 65N12"], "comment": "21 pages", "summary": "This paper studies the $p$-biharmonic equation on graphs, which arises in\npoint cloud processing and can be interpreted as a natural extension of the\ngraph $p$-Laplacian from the perspective of hypergraph. The asymptotic behavior\nof the solution is investigated when the random geometric graph is considered\nand the number of data points goes to infinity. We show that the continuum\nlimit is an appropriately weighted $p$-biharmonic equation with homogeneous\nNeumann boundary conditions. The result relies on the uniform $L^p$ estimates\nfor solutions and gradients of nonlocal and graph Poisson equations. The\n$L^\\infty$ estimates of solutions are also obtained as a byproduct."}
{"id": "2405.19912", "pdf": "https://arxiv.org/pdf/2405.19912", "abs": "https://arxiv.org/abs/2405.19912", "authors": ["Antonin Schrab", "Ilmun Kim"], "title": "Robust Kernel Hypothesis Testing under Data Corruption", "categories": ["stat.ML", "cs.LG"], "comment": "22 pages, 2 figures, 2 algorithms", "summary": "We propose a general method for constructing robust permutation tests under\ndata corruption. The proposed tests effectively control the non-asymptotic type\nI error under data corruption, and we prove their consistency in power under\nminimal conditions. This contributes to the practical deployment of hypothesis\ntests for real-world applications with potential adversarial attacks. For the\ntwo-sample and independence settings, we show that our kernel robust tests are\nminimax optimal, in the sense that they are guaranteed to be non-asymptotically\npowerful against alternatives uniformly separated from the null in the kernel\nMMD and HSIC metrics at some optimal rate (tight with matching lower bound). We\npoint out that existing differentially private tests can be adapted to be\nrobust to data corruption, and we demonstrate in experiments that our proposed\ntests achieve much higher power than these private tests. Finally, we provide\npublicly available implementations and empirically illustrate the practicality\nof our robust tests."}
{"id": "2406.10060", "pdf": "https://arxiv.org/pdf/2406.10060", "abs": "https://arxiv.org/abs/2406.10060", "authors": ["Kota Kondo", "Claudius T. Tewari", "Andrea Tagliabue", "Jesus Tordesillas", "Parker C. Lusk", "Mason B. Peterson", "Jonathan P. How"], "title": "PRIMER: Perception-Aware Robust Learning-based Multiagent Trajectory Planner", "categories": ["cs.RO", "cs.LG"], "comment": "7 pages, 3 figures", "summary": "In decentralized multiagent trajectory planners, agents need to communicate\nand exchange their positions to generate collision-free trajectories. However,\ndue to localization errors/uncertainties, trajectory deconfliction can fail\neven if trajectories are perfectly shared between agents. To address this\nissue, we first present PARM and PARM*, perception-aware, decentralized,\nasynchronous multiagent trajectory planners that enable a team of agents to\nnavigate uncertain environments while deconflicting trajectories and avoiding\nobstacles using perception information. PARM* differs from PARM as it is less\nconservative, using more computation to find closer-to-optimal solutions. While\nthese methods achieve state-of-the-art performance, they suffer from high\ncomputational costs as they need to solve large optimization problems onboard,\nmaking it difficult for agents to replan at high rates. To overcome this\nchallenge, we present our second key contribution, PRIMER, a learning-based\nplanner trained with imitation learning (IL) using PARM* as the expert\ndemonstrator. PRIMER leverages the low computational requirements at deployment\nof neural networks and achieves a computation speed up to 5500 times faster\nthan optimization-based approaches."}
{"id": "2406.10719", "pdf": "https://arxiv.org/pdf/2406.10719", "abs": "https://arxiv.org/abs/2406.10719", "authors": ["Orson Mengara"], "title": "Trading Devil: Robust backdoor attack via Stochastic investment models and Bayesian approach", "categories": ["cs.CR", "cs.LG", "q-fin.CP", "q-fin.ST", "stat.ML"], "comment": "(Last update!, a constructive comment from arxiv led to this latest\n  update ) Stochastic investment models and a Bayesian approach to better\n  modeling of uncertainty : adversarial machine learning or Stochastic market.\n  arXiv admin note: substantial text overlap with arXiv:2402.05967 (see this\n  link to the paper by : Orson Mengara)", "summary": "With the growing use of voice-activated systems and speech recognition\ntechnologies, the danger of backdoor attacks on audio data has grown\nsignificantly. This research looks at a specific type of attack, known as a\nStochastic investment-based backdoor attack (MarketBack), in which adversaries\nstrategically manipulate the stylistic properties of audio to fool speech\nrecognition systems. The security and integrity of machine learning models are\nseriously threatened by backdoor attacks, in order to maintain the reliability\nof audio applications and systems, the identification of such attacks becomes\ncrucial in the context of audio data. Experimental results demonstrated that\nMarketBack is feasible to achieve an average attack success rate close to 100%\nin seven victim models when poisoning less than 1% of the training data."}
{"id": "2408.09537", "pdf": "https://arxiv.org/pdf/2408.09537", "abs": "https://arxiv.org/abs/2408.09537", "authors": ["Zaile Li", "Weiwei Fan", "L. Jeff Hong"], "title": "Efficient Budget Allocation for Large-Scale LLM-Enabled Virtual Screening", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "Screening tasks that aim to identify a small subset of top alternatives from\na large pool are common in business decision-making processes. These tasks\noften require substantial human effort to evaluate each alternative's\nperformance, making them time-consuming and costly. Motivated by recent\nadvances in large language models (LLMs), particularly their ability to\ngenerate outputs that align well with human evaluations, we consider an\nLLM-as-human-evaluator approach for conducting screening virtually, thereby\nreducing the cost burden. To achieve scalability and cost-effectiveness in\nvirtual screening, we identify that the stochastic nature of LLM outputs and\ntheir cost structure necessitate efficient budget allocation across all\nalternatives. To address this, we propose using a top-$m$ greedy evaluation\nmechanism, a simple yet effective approach that keeps evaluating the current\ntop-$m$ alternatives, and design the explore-first top-$m$ greedy (EFG-$m$)\nalgorithm. We prove that EFG-$m$ is both sample-optimal and consistent in\nlarge-scale virtual screening. Surprisingly, we also uncover a bonus ranking\neffect, where the algorithm naturally induces an indifference-based ranking\nwithin the selected subset. To further enhance practicality, we design a suite\nof algorithm variants to improve screening performance and computational\nefficiency. Numerical experiments validate our results and demonstrate the\neffectiveness of our algorithms. Lastly, we conduct a case study on LLM-based\nvirtual screening. The study shows that while LLMs alone may not provide\nmeaningful screening and ranking results when directly queried, integrating\nthem with our sample-optimal algorithms unlocks their potential for\ncost-effective, large-scale virtual screening."}
{"id": "2409.09781", "pdf": "https://arxiv.org/pdf/2409.09781", "abs": "https://arxiv.org/abs/2409.09781", "authors": ["Parth Nobel", "Daniel LeJeune", "Emmanuel J. Cand√®s"], "title": "RandALO: Out-of-sample risk estimation in no time flat", "categories": ["math.ST", "cs.LG", "math.OC", "stat.CO", "stat.ML", "stat.TH"], "comment": "26 pages, 10 figures", "summary": "Estimating out-of-sample risk for models trained on large high-dimensional\ndatasets is an expensive but essential part of the machine learning process,\nenabling practitioners to optimally tune hyperparameters. Cross-validation (CV)\nserves as the de facto standard for risk estimation but poorly trades off high\nbias ($K$-fold CV) for computational cost (leave-one-out CV). We propose a\nrandomized approximate leave-one-out (RandALO) risk estimator that is not only\na consistent estimator of risk in high dimensions but also less computationally\nexpensive than $K$-fold CV. We support our claims with extensive simulations on\nsynthetic and real data and provide a user-friendly Python package implementing\nRandALO available on PyPI as randalo and at https://github.com/cvxgrp/randalo."}
{"id": "2409.20087", "pdf": "https://arxiv.org/pdf/2409.20087", "abs": "https://arxiv.org/abs/2409.20087", "authors": ["Kianusch Vahid Yousefnia", "Christoph Metzl", "Tobias B√∂lle"], "title": "Inferring Thunderstorm Occurrence from Vertical Profiles of Convection-Permitting Simulations: Physical Insights from a Physical Deep Learning Model", "categories": ["physics.ao-ph", "cs.LG", "I.2.6; J.2"], "comment": "17 pages, 9 figures, 3 tables. This work has been submitted to\n  Artificial Intelligence for the Earth Systems (AIES). Copyright in this work\n  may be transferred without further notice; v3: revised discussion of saliency\n  map; v2: updated and additional analyses, height-dependent normalization for\n  saliency map", "summary": "Thunderstorms have significant social and economic impacts due to heavy\nprecipitation, hail, lightning, and strong winds, necessitating reliable\nforecasts. Thunderstorm forecasts based on numerical weather prediction (NWP)\noften rely on single-level surrogate predictors, like convective available\npotential energy and convective inhibition, derived from vertical profiles of\nthree-dimensional atmospheric variables. In this study, we develop SALAMA 1D, a\ndeep neural network which directly infers the probability of thunderstorm\noccurrence from vertical profiles of ten atmospheric variables, bypassing\nsingle-level predictors. By training the model on convection-permitting NWP\nforecasts, we allow SALAMA 1D to flexibly identify convective patterns, with\nthe goal of enhancing forecast accuracy. The model's architecture is physically\nmotivated: sparse connections encourage interactions at similar height levels\nwhile keeping model size and inference times computationally efficient, whereas\na shuffling mechanism prevents the model from learning non-physical patterns\ntied to the vertical grid. SALAMA 1D is trained over Central Europe with\nlightning observations as the ground truth. Comparative analysis against a\nbaseline machine learning model that uses single-level predictors shows SALAMA\n1D's superior skill across various metrics and lead times of up to at least 11\nhours. Moreover, expanding the archive of forecasts from which training\nexamples are sampled improves skill, even when training set size remains\nconstant. Finally, a sensitivity analysis using saliency maps indicates that\nour model relies on physically interpretable patterns consistent with\nestablished theoretical understanding, such as ice particle content near the\ntropopause, cloud cover, conditional instability, and low-level moisture."}
{"id": "2412.01591", "pdf": "https://arxiv.org/pdf/2412.01591", "abs": "https://arxiv.org/abs/2412.01591", "authors": ["Petar Bevanda", "Nicolas Hoischen", "Tobias Wittmann", "Jan Br√ºdigam", "Sandra Hirche", "Boris Houska"], "title": "Kernel-Based Optimal Control: An Infinitesimal Generator Approach", "categories": ["math.OC", "cs.LG", "cs.RO", "cs.SY", "eess.SY", "stat.ML"], "comment": "Accepted for presentation at 7th Annual Learning for Dynamics &\n  Control Conference (L4DC 2025)", "summary": "This paper presents a novel operator-theoretic approach for optimal control\nof nonlinear stochastic systems within reproducing kernel Hilbert spaces. Our\nlearning framework leverages data samples of system dynamics and stage cost\nfunctions, with only control penalties and constraints provided. The proposed\nmethod directly learns the infinitesimal generator of a controlled stochastic\ndiffusion in an infinite-dimensional hypothesis space. We demonstrate that our\napproach seamlessly integrates with modern convex operator-theoretic\nHamilton-Jacobi-Bellman recursions, enabling a data-driven solution to the\noptimal control problems. Furthermore, our learning framework includes\nnonparametric estimators for uncontrolled infinitesimal generators as a special\ncase. Numerical experiments, ranging from synthetic differential equations to\nsimulated robotic systems, showcase the advantages of our approach compared to\nboth modern data-driven and classical nonlinear programming methods for optimal\ncontrol."}
{"id": "2412.02335", "pdf": "https://arxiv.org/pdf/2412.02335", "abs": "https://arxiv.org/abs/2412.02335", "authors": ["Ziyang Cheng", "Xiangyu Tian", "Ruomin Sui", "Tiemin Li", "Yao Jiang"], "title": "An Adaptive Grasping Force Tracking Strategy for Nonlinear and Time-Varying Object Behaviors", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Accurate grasp force control is one of the key skills for ensuring successful\nand damage-free robotic grasping of objects. Although existing methods have\nconducted in-depth research on slip detection and grasping force planning, they\noften overlook the issue of adaptive tracking of the actual force to the target\nforce when handling objects with different material properties. The optimal\nparameters of a force tracking controller are significantly influenced by the\nobject's stiffness, and many adaptive force tracking algorithms rely on\nstiffness estimation. However, real-world objects often exhibit viscous,\nplastic, or other more complex nonlinear time-varying behaviors, and existing\nstudies provide insufficient support for these materials in terms of stiffness\ndefinition and estimation. To address this, this paper introduces the concept\nof generalized stiffness, extending the definition of stiffness to nonlinear\ntime-varying grasp system models, and proposes an online generalized stiffness\nestimator based on Long Short-Term Memory (LSTM) networks. Based on generalized\nstiffness, this paper proposes an adaptive parameter adjustment strategy using\na PI controller as an example, enabling dynamic force tracking for objects with\nvarying characteristics. Experimental results demonstrate that the proposed\nmethod achieves high precision and short probing time, while showing better\nadaptability to non-ideal objects compared to existing methods. The method\neffectively solves the problem of grasp force tracking in unknown, nonlinear,\nand time-varying grasp systems, demonstrating the generalization capability of\nour neural network and enhancing the robotic grasping ability in unstructured\nenvironments."}
{"id": "2504.01338", "pdf": "https://arxiv.org/pdf/2504.01338", "abs": "https://arxiv.org/abs/2504.01338", "authors": ["Manolo Canales Cuba", "Vin√≠cius do Carmo Mel√≠cio", "Jo√£o Paulo Gois"], "title": "FlowMotion: Target-Predictive Conditional Flow Matching for Jitter-Reduced Text-Driven Human Motion Generation", "categories": ["cs.GR", "cs.LG"], "comment": null, "summary": "Achieving high-fidelity and temporally smooth 3D human motion generation\nremains a challenge, particularly within resource-constrained environments. We\nintroduce FlowMotion, a novel method leveraging Conditional Flow Matching\n(CFM). FlowMotion incorporates a training objective within CFM that focuses on\nmore accurately predicting target motion in 3D human motion generation,\nresulting in enhanced generation fidelity and temporal smoothness while\nmaintaining the fast synthesis times characteristic of flow-matching-based\nmethods. FlowMotion achieves state-of-the-art jitter performance, achieving the\nbest jitter in the KIT dataset and the second-best jitter in the HumanML3D\ndataset, and a competitive FID value in both datasets. This combination\nprovides robust and natural motion sequences, offering a promising equilibrium\nbetween generation quality and temporal naturalness."}
{"id": "2504.03463", "pdf": "https://arxiv.org/pdf/2504.03463", "abs": "https://arxiv.org/abs/2504.03463", "authors": ["David Landry", "Claire Monteleoni", "Anastase Charantonis"], "title": "Generating ensembles of spatially-coherent in-situ forecasts using flow matching", "categories": ["physics.ao-ph", "cs.LG"], "comment": "26 pages, 7 figures", "summary": "We propose a machine-learning-based methodology for in-situ weather forecast\npostprocessing that is both spatially coherent and multivariate. Compared to\nprevious work, our Flow MAtching Postprocessing (FMAP) better represents the\ncorrelation structures of the observations distribution, while also improving\nmarginal performance at the stations. FMAP generates forecasts that are not\nbound to what is already modeled by the underlying gridded prediction and can\ninfer new correlation structures from data. The resulting model can generate an\narbitrary number of forecasts from a limited number of numerical simulations,\nallowing for low-cost forecasting systems. A single training is sufficient to\nperform postprocessing at multiple lead times, in contrast with other methods\nwhich use multiple trained networks at generation time. This work details our\nmethodology, including a spatial attention transformer backbone trained within\na flow matching generative modeling framework. FMAP shows promising performance\nin experiments on the EUPPBench dataset, forecasting surface temperature and\nwind gust values at station locations in western Europe up to five-day lead\ntimes."}
{"id": "2504.07976", "pdf": "https://arxiv.org/pdf/2504.07976", "abs": "https://arxiv.org/abs/2504.07976", "authors": ["Hamidreza Eivazi", "Jendrik-Alexander Tr√∂ger", "Stefan Wittek", "Stefan Hartmann", "Andreas Rausch"], "title": "EquiNO: A Physics-Informed Neural Operator for Multiscale Simulations", "categories": ["physics.comp-ph", "cs.LG"], "comment": "22 pages. Code available at: https://github.com/HamidrezaEiv/EquiNO", "summary": "Multiscale problems are ubiquitous in physics. Numerical simulations of such\nproblems by solving partial differential equations (PDEs) at high resolution\nare computationally too expensive for many-query scenarios, e.g., uncertainty\nquantification, remeshing applications, topology optimization, and so forth.\nThis limitation has motivated the application of data-driven surrogate models,\nwhere the microscale computations are $\\textit{substituted}$ with a surrogate,\nusually acting as a black-box mapping between macroscale quantities. These\nmodels offer significant speedups but struggle with incorporating microscale\nphysical constraints, such as the balance of linear momentum and constitutive\nmodels. In this contribution, we propose Equilibrium Neural Operator (EquiNO)\nas a $\\textit{complementary}$ physics-informed PDE surrogate for predicting\nmicroscale physics and compare it with variational physics-informed neural and\noperator networks. Our framework, applicable to the so-called multiscale\nFE$^{\\,2}\\,$ computations, introduces the FE-OL approach by integrating the\nfinite element (FE) method with operator learning (OL). We apply the proposed\nFE-OL approach to quasi-static problems of solid mechanics. The results\ndemonstrate that FE-OL can yield accurate solutions even when confronted with a\nrestricted dataset during model development. Our results show that EquiNO\nachieves speedup factors exceeding 8000-fold compared to traditional methods\nand offers an optimal balance between data-driven and physics-based strategies."}
{"id": "2504.16266", "pdf": "https://arxiv.org/pdf/2504.16266", "abs": "https://arxiv.org/abs/2504.16266", "authors": ["Ye Qiao", "Zhiheng Chen", "Yifan Zhang", "Yian Wang", "Sitao Huang"], "title": "TeLLMe: An Energy-Efficient Ternary LLM Accelerator for Prefilling and Decoding on Edge FPGAs", "categories": ["cs.AR", "cs.LG"], "comment": null, "summary": "Deploying large language models (LLMs) on edge platforms is challenged by\ntheir high computational and memory demands. Although recent low-bit\nquantization methods (e.g., BitNet, DeepSeek) compress weights to as little as\n1.58 bits with minimal accuracy loss, edge deployment is still constrained by\nlimited on-chip resources, power budgets, and the often-neglected latency of\nthe prefill phase. We present TeLLMe, the first ternary LLM accelerator for\nlow-power FPGAs (e.g., AMD KV260) that fully supports both prefill and\nautoregressive decoding using 1.58-bit weights and 8-bit activations. Our\ncontributions include: (1) a table-lookup matrix engine for ternary matmul that\nmerges grouped activations with online precomputation to minimize resource use;\n(2) a fused, bandwidth-efficient attention module featuring a reversed\nreordering scheme to accelerate prefill; and (3) a tightly integrated\nnormalization and quantization--dequantization unit optimized for ultra-low-bit\ninference. Under a 7W power budget, TeLLMe delivers up to 9 tokens/s throughput\nover 1,024-token contexts and prefill latencies of 0.55--1.15 s for 64--128\ntoken prompts, marking a significant energy-efficiency advance and establishing\na new edge FPGA benchmark for generative AI."}
{"id": "2504.16269", "pdf": "https://arxiv.org/pdf/2504.16269", "abs": "https://arxiv.org/abs/2504.16269", "authors": ["Ye Qiao", "Zhiheng Chen", "Yian Wang", "Yifan Zhang", "Yunzhe Deng", "Sitao Huang"], "title": "COBRA: Algorithm-Architecture Co-optimized Binary Transformer Accelerator for Edge Inference", "categories": ["cs.AR", "cs.LG"], "comment": null, "summary": "Transformer-based models have demonstrated superior performance in various\nfields, including natural language processing and computer vision. However,\ntheir enormous model size and high demands in computation, memory, and\ncommunication limit their deployment to edge platforms for local, secure\ninference. Binary transformers offer a compact, low-complexity solution for\nedge deployment with reduced bandwidth needs and acceptable accuracy. However,\nexisting binary transformers perform inefficiently on current hardware due to\nthe lack of binary specific optimizations. To address this, we introduce COBRA,\nan algorithm-architecture co-optimized binary Transformer accelerator for edge\ncomputing. COBRA features a real 1-bit binary multiplication unit, enabling\nmatrix operations with -1, 0, and +1 values, surpassing ternary methods. With\nfurther hardware-friendly optimizations in the attention block, COBRA achieves\nup to 3,894.7 GOPS throughput and 448.7 GOPS/Watt energy efficiency on edge\nFPGAs, delivering a 311x energy efficiency improvement over GPUs and a 3.5x\nthroughput improvement over the state-of-the-art binary accelerator, with only\nnegligible inference accuracy degradation."}
