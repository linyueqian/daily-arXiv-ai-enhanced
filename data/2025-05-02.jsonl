{"id": "2505.00001", "pdf": "https://arxiv.org/pdf/2505.00001", "abs": "https://arxiv.org/abs/2505.00001", "authors": ["Shaun Baek", "Shaun Esua-Mensah", "Cyrus Tsui", "Sejan Vigneswaralingam", "Abdullah Alali", "Michael Lu", "Vasu Sharma", "Kevin Zhu"], "title": "Rosetta-PL: Propositional Logic as a Benchmark for Large Language Model Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are primarily trained on high-resource natural\nlanguages, limiting their effectiveness in low-resource settings and in tasks\nrequiring deep logical reasoning. This research introduces Rosetta-PL, a\nbenchmark designed to evaluate LLMs' logical reasoning and generalization\ncapabilities in a controlled environment. We construct Rosetta-PL by\ntranslating a dataset of logical propositions from Lean into a custom logical\nlanguage, which is then used to fine-tune an LLM (e.g., GPT-4o). Our\nexperiments analyze the impact of the size of the dataset and the translation\nmethodology on the performance of the model. Our results indicate that\npreserving logical relationships in the translation process significantly\nboosts precision, with accuracy plateauing beyond roughly 20,000 training\nsamples. These insights provide valuable guidelines for optimizing LLM training\nin formal reasoning tasks and improving performance in various low-resource\nlanguage applications."}
{"id": "2505.00002", "pdf": "https://arxiv.org/pdf/2505.00002", "abs": "https://arxiv.org/abs/2505.00002", "authors": ["Vincent C. Müller"], "title": "Symbol grounding in computational systems: A paradox of intentions", "categories": ["cs.CL"], "comment": null, "summary": "The paper presents a paradoxical feature of computational systems that\nsuggests that computationalism cannot explain symbol grounding. If the mind is\na digital computer, as computationalism claims, then it can be computing either\nover meaningful symbols or over meaningless symbols. If it is computing over\nmeaningful symbols its functioning presupposes the existence of meaningful\nsymbols in the system, i.e. it implies semantic nativism. If the mind is\ncomputing over meaningless symbols, no intentional cognitive processes are\navailable prior to symbol grounding. In this case, no symbol grounding could\ntake place since any grounding presupposes intentional cognitive processes. So,\nwhether computing in the mind is over meaningless or over meaningful symbols,\ncomputationalism implies semantic nativism."}
{"id": "2505.00003", "pdf": "https://arxiv.org/pdf/2505.00003", "abs": "https://arxiv.org/abs/2505.00003", "authors": ["Zizhou Liu", "Ziwei Gong", "Lin Ai", "Zheng Hui", "Run Chen", "Colin Wayne Leach", "Michelle R. Greene", "Julia Hirschberg"], "title": "The Mind in the Machine: A Survey of Incorporating Psychological Theories in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Psychological insights have long shaped pivotal NLP breakthroughs, including\nthe cognitive underpinnings of attention mechanisms, formative reinforcement\nlearning, and Theory of Mind-inspired social modeling. As Large Language Models\n(LLMs) continue to grow in scale and complexity, there is a rising consensus\nthat psychology is essential for capturing human-like cognition, behavior, and\ninteraction. This paper reviews how psychological theories can inform and\nenhance stages of LLM development, including data, pre-training, post-training,\nand evaluation\\&application. Our survey integrates insights from cognitive,\ndevelopmental, behavioral, social, personality psychology, and\npsycholinguistics. Our analysis highlights current trends and gaps in how\npsychological theories are applied. By examining both cross-domain connections\nand points of tension, we aim to bridge disciplinary divides and promote more\nthoughtful integration of psychology into future NLP research."}
{"id": "2505.00004", "pdf": "https://arxiv.org/pdf/2505.00004", "abs": "https://arxiv.org/abs/2505.00004", "authors": ["Danilo S. Carvalho", "Yingji Zhang", "Harriet Unsworth", "André Freitas"], "title": "LangVAE and LangSpace: Building and Probing for Language Model VAEs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We present LangVAE, a novel framework for modular construction of variational\nautoencoders (VAEs) on top of pre-trained large language models (LLMs). Such\nlanguage model VAEs can encode the knowledge of their pre-trained components\ninto more compact and semantically disentangled representations. The\nrepresentations obtained in this way can be analysed with the LangVAE companion\nframework: LangSpace, which implements a collection of probing methods, such as\nvector traversal and interpolation, disentanglement measures, and cluster\nvisualisations. LangVAE and LangSpace offer a flexible, efficient and scalable\nway of building and analysing textual representations, with simple integration\nfor models available on the HuggingFace Hub. Additionally, we conducted a set\nof experiments with different encoder and decoder combinations, as well as\nannotated inputs, revealing a wide range of interactions across architectural\nfamilies and sizes w.r.t. generalisation and disentanglement. Our findings\ndemonstrate a promising framework for systematising the experimentation and\nunderstanding of textual representations."}
{"id": "2505.00018", "pdf": "https://arxiv.org/pdf/2505.00018", "abs": "https://arxiv.org/abs/2505.00018", "authors": ["Ju Wu", "Calvin K. L. Or"], "title": "Position Paper: Towards Open Complex Human-AI Agents Collaboration System for Problem-Solving and Knowledge Management", "categories": ["cs.AI", "cs.HC", "cs.MA"], "comment": null, "summary": "This position paper critically surveys a broad spectrum of recent empirical\ndevelopments on human-AI agents collaboration, highlighting both their\ntechnical achievements and persistent gaps. We observe a lack of a unifying\ntheoretical framework that can coherently integrate these varied studies,\nespecially when tackling open-ended, complex tasks. To address this, we propose\na novel conceptual architecture: one that systematically interlinks the\ntechnical details of multi-agent coordination, knowledge management, cybernetic\nfeedback loops, and higher-level control mechanisms. By mapping existing\ncontributions, from symbolic AI techniques and connectionist LLM-based agents\nto hybrid organizational practices, onto this proposed framework (Hierarchical\nExploration-Exploitation Net), our approach facilitates revision of legacy\nmethods and inspires new work that fuses qualitative and quantitative\nparadigms. The paper's structure allows it to be read from any section, serving\nequally as a critical review of technical implementations and as a\nforward-looking reference for designing or extending human-AI symbioses.\nTogether, these insights offer a stepping stone toward deeper co-evolution of\nhuman cognition and AI capability."}
{"id": "2505.00044", "pdf": "https://arxiv.org/pdf/2505.00044", "abs": "https://arxiv.org/abs/2505.00044", "authors": ["Richard Schmit"], "title": "Learning to Borrow Features for Improved Detection of Small Objects in Single-Shot Detectors", "categories": ["cs.CV", "math.OC"], "comment": null, "summary": "Detecting small objects remains a significant challenge in single-shot object\ndetectors due to the inherent trade-off between spatial resolution and semantic\nrichness in convolutional feature maps. To address this issue, we propose a\nnovel framework that enables small object representations to \"borrow\"\ndiscriminative features from larger, semantically richer instances within the\nsame class. Our architecture introduces three key components: the Feature\nMatching Block (FMB) to identify semantically similar descriptors across\nlayers, the Feature Representing Block (FRB) to generate enhanced shallow\nfeatures through weighted aggregation, and the Feature Fusion Block (FFB) to\nrefine feature maps by integrating original, borrowed, and context information.\nBuilt upon the SSD framework, our method improves the descriptive capacity of\nshallow layers while maintaining real-time detection performance. Experimental\nresults demonstrate that our approach significantly boosts small object\ndetection accuracy over baseline methods, offering a promising direction for\nrobust object detection in complex visual environments."}
{"id": "2505.00101", "pdf": "https://arxiv.org/pdf/2505.00101", "abs": "https://arxiv.org/abs/2505.00101", "authors": ["Barak Gahtan", "Sanketh Vedula", "Gil Samuelly Leichtag", "Einat Kodesh", "Alex M. Bronstein"], "title": "From Lab to Wrist: Bridging Metabolic Monitoring and Consumer Wearables for Heart Rate and Oxygen Consumption Modeling", "categories": ["cs.LG", "cs.HC"], "comment": null, "summary": "Understanding physiological responses during running is critical for\nperformance optimization, tailored training prescriptions, and athlete health\nmanagement. We introduce a comprehensive framework -- what we believe to be the\nfirst capable of predicting instantaneous oxygen consumption (VO$_{2}$)\ntrajectories exclusively from consumer-grade wearable data. Our approach\nemploys two complementary physiological models: (1) accurate modeling of heart\nrate (HR) dynamics via a physiologically constrained ordinary differential\nequation (ODE) and neural Kalman filter, trained on over 3 million HR\nobservations, achieving 1-second interval predictions with mean absolute errors\nas low as 2.81\\,bpm (correlation 0.87); and (2) leveraging the principles of\nprecise HR modeling, a novel VO$_{2}$ prediction architecture requiring only\nthe initial second of VO$_{2}$ data for calibration, enabling robust,\nsequence-to-sequence metabolic demand estimation. Despite relying solely on\nsmartwatch and chest-strap data, our method achieves mean absolute percentage\nerrors of approximately 13\\%, effectively capturing rapid physiological\ntransitions and steady-state conditions across diverse running intensities. Our\nsynchronized dataset, complemented by blood lactate measurements, further lays\nthe foundation for future noninvasive metabolic zone identification. By\nembedding physiological constraints within modern machine learning, this\nframework democratizes advanced metabolic monitoring, bridging laboratory-grade\naccuracy and everyday accessibility, thus empowering both elite athletes and\nrecreational fitness enthusiasts."}
{"id": "2505.00056", "pdf": "https://arxiv.org/pdf/2505.00056", "abs": "https://arxiv.org/abs/2505.00056", "authors": ["Tygo Bloem", "Filip Ilievski"], "title": "Clustering Internet Memes Through Template Matching and Multi-Dimensional Similarity", "categories": ["cs.CL", "cs.IR", "cs.LG", "cs.MM"], "comment": null, "summary": "Meme clustering is critical for toxicity detection, virality modeling, and\ntyping, but it has received little attention in previous research. Clustering\nsimilar Internet memes is challenging due to their multimodality, cultural\ncontext, and adaptability. Existing approaches rely on databases, overlook\nsemantics, and struggle to handle diverse dimensions of similarity. This paper\nintroduces a novel method that uses template-based matching with\nmulti-dimensional similarity features, thus eliminating the need for predefined\ndatabases and supporting adaptive matching. Memes are clustered using local and\nglobal features across similarity categories such as form, visual content,\ntext, and identity. Our combined approach outperforms existing clustering\nmethods, producing more consistent and coherent clusters, while\nsimilarity-based feature sets enable adaptability and align with human\nintuition. We make all supporting code publicly available to support subsequent\nresearch. Code: https://github.com/tygobl/meme-clustering"}
{"id": "2505.00550", "pdf": "https://arxiv.org/pdf/2505.00550", "abs": "https://arxiv.org/abs/2505.00550", "authors": ["Tiange Zhou", "Marco Bidin"], "title": "Bridging Cultural and Digital Divides: A Low-Latency JackTrip Framework for Equitable Music Education in the Global South", "categories": ["cs.SD", "cs.SI"], "comment": null, "summary": "The rapid expansion of digital technologies has transformed educational\nlandscapes worldwide, yet significant infrastructural and cultural challenges\npersist in the Global South. This paper introduces a low-latency JackTrip\nframework designed to bridge both the cultural and digital divides in music\neducation. By leveraging an open-source, UDP-based audio streaming protocol\noriginally developed at Stanford's CCRMA, the framework is tailored to address\ntechnical constraints such as intermittent connectivity, limited bandwidth, and\nhigh latency that characterize many rural and underserved regions. The study\nsystematically compares the performance of JackTrip with conventional platforms\nlike Zoom, demonstrating that JackTrip achieves sub-30~ms latency under\nsimulated low-resource conditions while preserving the intricate audio details\nessential for non-Western musical traditions. Spectral analysis confirms that\nJackTrip's superior handling of microtonal scales, complex rhythms, and\nharmonic textures provides a culturally authentic medium for real-time ensemble\nperformance and music education. These findings underscore the transformative\npotential of decentralized, edge-computing solutions in empowering educators\nand musicians across the Global South, promoting both technological equity and\ncultural preservation."}
{"id": "2505.00007", "pdf": "https://arxiv.org/pdf/2505.00007", "abs": "https://arxiv.org/abs/2505.00007", "authors": ["Jesuraj Bandekar", "Sathvik Udupa", "Prasanta Kumar Ghosh"], "title": "Discovering phoneme-specific critical articulators through a data-driven approach", "categories": ["eess.AS"], "comment": null, "summary": "We propose an approach for learning critical articulators for phonemes\nthrough a machine learning approach. We formulate the learning with three\nmodels trained end to end. First, we use Acoustic to Articulatory Inversion\n(AAI) to predict time-varying speech articulators EMA. We also predict the\nphoneme-specific weights across articulators for each frame. To avoid\noverfitting, we also add a dropout layer before the weights prediction layer.\nNext, we normalize the predicted weights across articulators using min-max\nnormalization for each frame. The normalized weights are multiplied by the\nground truth $EMA$ and then we try to predict the phones at each frame. We\ntrain this whole setup end to end and use two losses. One loss is for the phone\nprediction which is the cross entropy loss and the other is for the AAI\nprediction which is the mean squared error loss. To maintain gradient flow\nbetween the phone prediction block and the $EMA$ prediction block, we use\nstraight-through estimation. The goal here is to predict the weights of the\narticulator at each frame while training the model end to end."}
{"id": "2505.00055", "pdf": "https://arxiv.org/pdf/2505.00055", "abs": "https://arxiv.org/abs/2505.00055", "authors": ["Zhuoqi Zeng", "Yuxiang Wei", "Jiawen Kang"], "title": "TinyMA-IEI-PPO: Exploration Incentive-Driven Multi-Agent DRL with Self-Adaptive Pruning for Vehicular Embodied AI Agent Twins Migration", "categories": ["cs.MA", "cs.GT"], "comment": null, "summary": "Embodied Artificial Intelligence (EAI) addresses autonomous driving\nchallenges in Vehicular Embodied AI Networks (VEANETs) through multi-modal\nperception, adaptive decision-making, and hardware-software co-scheduling.\nHowever, the computational demands of virtual services and the inherent\nmobility of autonomous vehicles (AVs) necessitate real-time migration of\nVehicular Embodied Agent AI Twins (VEAATs) between resource-constrained\nRoadside Units (RSUs). This paper proposes a novel framework for efficient\nVEAAT migration in VEANETs, combining a multi-leader multi-follower (MLMF)\nStackelberg game-theoretic incentive mechanism with a tiny multi-agent deep\nreinforcement learning (MADRL) algorithm. First, We propose an virtual\nimmersive experience-driven utility model that captures AV-RSU dynamic\ninteractions by integrating AVs' social influence, service complementarity and\nsubstitutability, and RSUs' resource allocation strategies to optimize VEAAT\nmigration decisions. Second, to enhance training efficiency and enable\nefficient deployment on computation-constrained AVs while preserving\nexploration-exploitation performance, we propose TinyMA-IEI-PPO, a\nself-adaptive dynamic structured pruning algorithm that dynamically adjusts\nneuron importance based on agents' exploration incentives. Numerical results\ndemonstrate that our approach achieves convergence comparable to baseline\nmodels and closely approximates the Stackelberg equilibrium."}
{"id": "2505.00045", "pdf": "https://arxiv.org/pdf/2505.00045", "abs": "https://arxiv.org/abs/2505.00045", "authors": ["Feiran Li", "Haiyang Jiang", "Daisuke Iso"], "title": "Noise Modeling in One Hour: Minimizing Preparation Efforts for Self-supervised Low-Light RAW Image Denoising", "categories": ["eess.IV"], "comment": null, "summary": "Noise synthesis is a promising solution for addressing the data shortage\nproblem in data-driven low-light RAW image denoising. However, accurate noise\nsynthesis methods often necessitate labor-intensive calibration and profiling\nprocedures during preparation, preventing them from landing to practice at\nscale. This work introduces a practically simple noise synthesis pipeline based\non detailed analyses of noise properties and extensive justification of\nwidespread techniques. Compared to other approaches, our proposed pipeline\neliminates the cumbersome system gain calibration and signal-independent noise\nprofiling steps, reducing the preparation time for noise synthesis from days to\nhours. Meanwhile, our method exhibits strong denoising performance, showing an\nup to 0.54dB PSNR improvement over the current state-of-the-art noise synthesis\ntechnique. Code is released at\nhttps://github.com/SonyResearch/raw_image_denoising"}
{"id": "2505.00006", "pdf": "https://arxiv.org/pdf/2505.00006", "abs": "https://arxiv.org/abs/2505.00006", "authors": ["Hayden Helm", "Tianyi Chen", "Harvey McGuinness", "Paige Lee", "Brandon Duderstadt", "Carey E. Priebe"], "title": "Toward a digital twin of U.S. Congress", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.SI"], "comment": null, "summary": "In this paper we provide evidence that a virtual model of U.S.\ncongresspersons based on a collection of language models satisfies the\ndefinition of a digital twin. In particular, we introduce and provide\nhigh-level descriptions of a daily-updated dataset that contains every Tweet\nfrom every U.S. congressperson during their respective terms. We demonstrate\nthat a modern language model equipped with congressperson-specific subsets of\nthis data are capable of producing Tweets that are largely indistinguishable\nfrom actual Tweets posted by their physical counterparts. We illustrate how\ngenerated Tweets can be used to predict roll-call vote behaviors and to\nquantify the likelihood of congresspersons crossing party lines, thereby\nassisting stakeholders in allocating resources and potentially impacting\nreal-world legislative dynamics. We conclude with a discussion of the\nlimitations and important extensions of our analysis."}
{"id": "2505.00173", "pdf": "https://arxiv.org/pdf/2505.00173", "abs": "https://arxiv.org/abs/2505.00173", "authors": ["Isabelle Bloch", "Enzo Bonnot", "Pietro Gori", "Giammarco La Barbera", "Sabine Sarnacki"], "title": "First Order Logic with Fuzzy Semantics for Describing and Recognizing Nerves in Medical Images", "categories": ["cs.AI", "cs.LO", "math.LO"], "comment": "Accepted for presentation at the FUZZ-IEEE 2025 conference", "summary": "This article deals with the description and recognition of fiber bundles, in\nparticular nerves, in medical images, based on the anatomical description of\nthe fiber trajectories. To this end, we propose a logical formalization of this\nanatomical knowledge. The intrinsically imprecise description of nerves, as\nfound in anatomical textbooks, leads us to propose fuzzy semantics combined\nwith first-order logic. We define a language representing spatial entities,\nrelations between these entities and quantifiers. A formula in this language is\nthen a formalization of the natural language description. The semantics are\ngiven by fuzzy representations in a concrete domain and satisfaction degrees of\nrelations. Based on this formalization, a spatial reasoning algorithm is\nproposed for segmentation and recognition of nerves from anatomical and\ndiffusion magnetic resonance images, which is illustrated on pelvic nerves in\npediatric imaging, enabling surgeons to plan surgery."}
{"id": "2505.00134", "pdf": "https://arxiv.org/pdf/2505.00134", "abs": "https://arxiv.org/abs/2505.00134", "authors": ["Vasudev Sharma", "Ahmed Alagha", "Abdelhakim Khellaf", "Vincent Quoc-Huy Trinh", "Mahdi S. Hosseini"], "title": "Investigating Zero-Shot Diagnostic Pathology in Vision-Language Models with Efficient Prompt Design", "categories": ["cs.CV"], "comment": null, "summary": "Vision-language models (VLMs) have gained significant attention in\ncomputational pathology due to their multimodal learning capabilities that\nenhance big-data analytics of giga-pixel whole slide image (WSI). However,\ntheir sensitivity to large-scale clinical data, task formulations, and prompt\ndesign remains an open question, particularly in terms of diagnostic accuracy.\nIn this paper, we present a systematic investigation and analysis of three\nstate of the art VLMs for histopathology, namely Quilt-Net, Quilt-LLAVA, and\nCONCH, on an in-house digestive pathology dataset comprising 3,507 WSIs, each\nin giga-pixel form, across distinct tissue types. Through a structured ablative\nstudy on cancer invasiveness and dysplasia status, we develop a comprehensive\nprompt engineering framework that systematically varies domain specificity,\nanatomical precision, instructional framing, and output constraints. Our\nfindings demonstrate that prompt engineering significantly impacts model\nperformance, with the CONCH model achieving the highest accuracy when provided\nwith precise anatomical references. Additionally, we identify the critical\nimportance of anatomical context in histopathological image analysis, as\nperformance consistently degraded when reducing anatomical precision. We also\nshow that model complexity alone does not guarantee superior performance, as\neffective domain alignment and domain-specific training are critical. These\nresults establish foundational guidelines for prompt engineering in\ncomputational pathology and highlight the potential of VLMs to enhance\ndiagnostic accuracy when properly instructed with domain-appropriate prompts."}
{"id": "2505.00131", "pdf": "https://arxiv.org/pdf/2505.00131", "abs": "https://arxiv.org/abs/2505.00131", "authors": ["Dalton Durant", "Renato Zanetti"], "title": "Kernel-Based Ensemble Gaussian Mixture Probability Hypothesis Density Filter", "categories": ["cs.LG", "stat.ME"], "comment": null, "summary": "In this work, a kernel-based Ensemble Gaussian Mixture Probability Hypothesis\nDensity (EnGM-PHD) filter is presented for multi-target filtering applications.\nThe EnGM-PHD filter combines the Gaussian-mixture-based techniques of the\nGaussian Mixture Probability Hypothesis Density (GM-PHD) filter with the\nparticle-based techniques of the Sequential Monte Carlo Probability Hypothesis\nDensity (SMC-PHD) filter. It achieves this by obtaining particles from the\nposterior intensity function, propagating them through the system dynamics, and\nthen using Kernel Density Estimation (KDE) techniques to approximate the\nGaussian mixture of the prior intensity function. This approach guarantees\nconvergence to the true intensity function in the limit of the number of\ncomponents. Moreover, in the special case of a single target with no births,\ndeaths, clutter, and perfect detection probability, the EnGM-PHD filter reduces\nto the standard Ensemble Gaussian Mixture Filter (EnGMF). In the presented\nexperiment, the results indicate that the EnGM-PHD filter achieves better\nmulti-target filtering performance than both the GM-PHD and SMC-PHD filters\nwhile using the same number of components or particles."}
{"id": "2504.09948", "pdf": "https://arxiv.org/pdf/2504.09948", "abs": "https://arxiv.org/abs/2504.09948", "authors": ["Huijie Liu", "Bingcan Wang", "Jie Hu", "Xiaoming Wei", "Guoliang Kang"], "title": "Omni-Dish: Photorealistic and Faithful Image Generation and Editing for Arbitrary Chinese Dishes", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": "10 pages, 10 figures, 3 tables", "summary": "Dish images play a crucial role in the digital era, with the demand for\nculturally distinctive dish images continuously increasing due to the\ndigitization of the food industry and e-commerce. In general cases, existing\ntext-to-image generation models excel in producing high-quality images;\nhowever, they struggle to capture diverse characteristics and faithful details\nof specific domains, particularly Chinese dishes. To address this limitation,\nwe propose Omni-Dish, the first text-to-image generation model specifically\ntailored for Chinese dishes. We develop a comprehensive dish curation pipeline,\nbuilding the largest dish dataset to date. Additionally, we introduce a\nrecaption strategy and employ a coarse-to-fine training scheme to help the\nmodel better learn fine-grained culinary nuances. During inference, we enhance\nthe user's textual input using a pre-constructed high-quality caption library\nand a large language model, enabling more photorealistic and faithful image\ngeneration. Furthermore, to extend our model's capability for dish editing\ntasks, we propose Concept-Enhanced P2P. Based on this approach, we build a dish\nediting dataset and train a specialized editing model. Extensive experiments\ndemonstrate the superiority of our methods."}
{"id": "2505.00579", "pdf": "https://arxiv.org/pdf/2505.00579", "abs": "https://arxiv.org/abs/2505.00579", "authors": ["Hussam Azzuni", "Abdulmotaleb El Saddik"], "title": "Voice Cloning: Comprehensive Survey", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "26 pages, 7 figures", "summary": "Voice Cloning has rapidly advanced in today's digital world, with many\nresearchers and corporations working to improve these algorithms for various\napplications. This article aims to establish a standardized terminology for\nvoice cloning and explore its different variations. It will cover speaker\nadaptation as the fundamental concept and then delve deeper into topics such as\nfew-shot, zero-shot, and multilingual TTS within that context. Finally, we will\nexplore the evaluation metrics commonly used in voice cloning research and\nrelated datasets. This survey compiles the available voice cloning algorithms\nto encourage research toward its generation and detection to limit its misuse."}
{"id": "2505.00409", "pdf": "https://arxiv.org/pdf/2505.00409", "abs": "https://arxiv.org/abs/2505.00409", "authors": ["Soroosh Tayebi Arasteh", "Saba Afza", "Tri-Thien Nguyen", "Lukas Buess", "Maryam Parvin", "Tomas Arias-Vergara", "Paula Andrea Perez-Toro", "Hiu Ching Hung", "Mahshad Lotfinia", "Thomas Gorges", "Elmar Noeth", "Maria Schuster", "Seung Hee Yang", "Andreas Maier"], "title": "Perceptual Implications of Automatic Anonymization in Pathological Speech", "categories": ["eess.AS", "cs.AI", "cs.LG"], "comment": null, "summary": "Automatic anonymization techniques are essential for ethical sharing of\npathological speech data, yet their perceptual consequences remain\nunderstudied. This study presents the first comprehensive human-centered\nanalysis of anonymized pathological speech, using a structured perceptual\nprotocol involving ten native and non-native German listeners with diverse\nlinguistic, clinical, and technical backgrounds. Listeners evaluated\nanonymized-original utterance pairs from 180 speakers spanning Cleft Lip and\nPalate, Dysarthria, Dysglossia, Dysphonia, and age-matched healthy controls.\nSpeech was anonymized using state-of-the-art automatic methods (equal error\nrates in the range of 30-40%). Listeners completed Turing-style discrimination\nand quality rating tasks under zero-shot (single-exposure) and few-shot\n(repeated-exposure) conditions. Discrimination accuracy was high overall (91%\nzero-shot; 93% few-shot), but varied by disorder (repeated-measures ANOVA:\np=0.007), ranging from 96% (Dysarthria) to 86% (Dysphonia). Anonymization\nconsistently reduced perceived quality (from 83% to 59%, p<0.001), with\npathology-specific degradation patterns (one-way ANOVA: p=0.005). Native\nlisteners rated original speech slightly higher than non-native listeners\n(Delta=4%, p=0.199), but this difference nearly disappeared after anonymization\n(Delta=1%, p=0.724). No significant gender-based bias was observed. Critically,\nhuman perceptual outcomes did not correlate with automatic privacy or clinical\nutility metrics. These results underscore the need for listener-informed,\ndisorder- and context-specific anonymization strategies that preserve privacy\nwhile maintaining interpretability, communicative functions, and diagnostic\nutility, especially for vulnerable populations such as children."}
{"id": "2505.00212", "pdf": "https://arxiv.org/pdf/2505.00212", "abs": "https://arxiv.org/abs/2505.00212", "authors": ["Shaokun Zhang", "Ming Yin", "Jieyu Zhang", "Jiale Liu", "Zhiguang Han", "Jingyang Zhang", "Beibin Li", "Chi Wang", "Huazheng Wang", "Yiran Chen", "Qingyun Wu"], "title": "Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems", "categories": ["cs.MA", "cs.CL"], "comment": null, "summary": "Failure attribution in LLM multi-agent systems-identifying the agent and step\nresponsible for task failures-provides crucial clues for systems debugging but\nremains underexplored and labor-intensive. In this paper, we propose and\nformulate a new research area: automated failure attribution for LLM\nmulti-agent systems. To support this initiative, we introduce the Who&When\ndataset, comprising extensive failure logs from 127 LLM multi-agent systems\nwith fine-grained annotations linking failures to specific agents and decisive\nerror steps. Using the Who&When, we develop and evaluate three automated\nfailure attribution methods, summarizing their corresponding pros and cons. The\nbest method achieves 53.5% accuracy in identifying failure-responsible agents\nbut only 14.2% in pinpointing failure steps, with some methods performing below\nrandom. Even SOTA reasoning models, such as OpenAI o1 and DeepSeek R1, fail to\nachieve practical usability. These results highlight the task's complexity and\nthe need for further research in this area. Code and dataset are available at\nhttps://github.com/mingyin1/Agents_Failure_Attribution"}
{"id": "2505.00046", "pdf": "https://arxiv.org/pdf/2505.00046", "abs": "https://arxiv.org/abs/2505.00046", "authors": ["Taiga Hayami", "Kakeru Koizumi", "Hiroshi Watanabe"], "title": "SR-NeRV: Improving Embedding Efficiency of Neural Video Representation via Super-Resolution", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Implicit Neural Representations (INRs) have garnered significant attention\nfor their ability to model complex signals across a variety of domains.\nRecently, INR-based approaches have emerged as promising frameworks for neural\nvideo compression. While conventional methods primarily focus on embedding\nvideo content into compact neural networks for efficient representation, they\noften struggle to reconstruct high-frequency details under stringent model size\nconstraints, which are critical in practical compression scenarios. To address\nthis limitation, we propose an INR-based video representation method that\nintegrates a general-purpose super-resolution (SR) network. Motivated by the\nobservation that high-frequency components exhibit low temporal redundancy\nacross frames, our method entrusts the reconstruction of fine details to the SR\nnetwork. Experimental results demonstrate that the proposed method outperforms\nconventional INR-based baselines in terms of reconstruction quality, while\nmaintaining comparable model sizes."}
{"id": "2505.00008", "pdf": "https://arxiv.org/pdf/2505.00008", "abs": "https://arxiv.org/abs/2505.00008", "authors": ["Zhaoyi Sun", "Wen-Wai Yim", "Ozlem Uzuner", "Fei Xia", "Meliha Yetisgen"], "title": "A Scoping Review of Natural Language Processing in Addressing Medically Inaccurate Information: Errors, Misinformation, and Hallucination", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Objective: This review aims to explore the potential and challenges of using\nNatural Language Processing (NLP) to detect, correct, and mitigate medically\ninaccurate information, including errors, misinformation, and hallucination. By\nunifying these concepts, the review emphasizes their shared methodological\nfoundations and their distinct implications for healthcare. Our goal is to\nadvance patient safety, improve public health communication, and support the\ndevelopment of more reliable and transparent NLP applications in healthcare.\n  Methods: A scoping review was conducted following PRISMA guidelines,\nanalyzing studies from 2020 to 2024 across five databases. Studies were\nselected based on their use of NLP to address medically inaccurate information\nand were categorized by topic, tasks, document types, datasets, models, and\nevaluation metrics.\n  Results: NLP has shown potential in addressing medically inaccurate\ninformation on the following tasks: (1) error detection (2) error correction\n(3) misinformation detection (4) misinformation correction (5) hallucination\ndetection (6) hallucination mitigation. However, challenges remain with data\nprivacy, context dependency, and evaluation standards.\n  Conclusion: This review highlights the advancements in applying NLP to tackle\nmedically inaccurate information while underscoring the need to address\npersistent challenges. Future efforts should focus on developing real-world\ndatasets, refining contextual methods, and improving hallucination management\nto ensure reliable and transparent healthcare applications."}
{"id": "2505.00174", "pdf": "https://arxiv.org/pdf/2505.00174", "abs": "https://arxiv.org/abs/2505.00174", "authors": ["Ilan Strauss", "Isobel Moure", "Tim O'Reilly", "Sruly Rosenblat"], "title": "Real-World Gaps in AI Governance Research", "categories": ["cs.AI"], "comment": null, "summary": "Drawing on 1,178 safety and reliability papers from 9,439 generative AI\npapers (January 2020 - March 2025), we compare research outputs of leading AI\ncompanies (Anthropic, Google DeepMind, Meta, Microsoft, and OpenAI) and AI\nuniversities (CMU, MIT, NYU, Stanford, UC Berkeley, and University of\nWashington). We find that corporate AI research increasingly concentrates on\npre-deployment areas -- model alignment and testing & evaluation -- while\nattention to deployment-stage issues such as model bias has waned. Significant\nresearch gaps exist in high-risk deployment domains, including healthcare,\nfinance, misinformation, persuasive and addictive features, hallucinations, and\ncopyright. Without improved observability into deployed AI, growing corporate\nconcentration could deepen knowledge deficits. We recommend expanding external\nresearcher access to deployment data and systematic observability of in-market\nAI behaviors."}
{"id": "2505.00135", "pdf": "https://arxiv.org/pdf/2505.00135", "abs": "https://arxiv.org/abs/2505.00135", "authors": ["Michal Geyer", "Omer Tov", "Linyi Jin", "Richard Tucker", "Inbar Mosseri", "Tali Dekel", "Noah Snavely"], "title": "Eye2Eye: A Simple Approach for Monocular-to-Stereo Video Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "The rising popularity of immersive visual experiences has increased interest\nin stereoscopic 3D video generation. Despite significant advances in video\nsynthesis, creating 3D videos remains challenging due to the relative scarcity\nof 3D video data. We propose a simple approach for transforming a text-to-video\ngenerator into a video-to-stereo generator. Given an input video, our framework\nautomatically produces the video frames from a shifted viewpoint, enabling a\ncompelling 3D effect. Prior and concurrent approaches for this task typically\noperate in multiple phases, first estimating video disparity or depth, then\nwarping the video accordingly to produce a second view, and finally inpainting\nthe disoccluded regions. This approach inherently fails when the scene involves\nspecular surfaces or transparent objects. In such cases, single-layer disparity\nestimation is insufficient, resulting in artifacts and incorrect pixel shifts\nduring warping. Our work bypasses these restrictions by directly synthesizing\nthe new viewpoint, avoiding any intermediate steps. This is achieved by\nleveraging a pre-trained video model's priors on geometry, object materials,\noptics, and semantics, without relying on external geometry models or manually\ndisentangling geometry from the synthesis process. We demonstrate the\nadvantages of our approach in complex, real-world scenarios featuring diverse\nobject materials and compositions. See videos on\nhttps://video-eye2eye.github.io"}
{"id": "2505.00136", "pdf": "https://arxiv.org/pdf/2505.00136", "abs": "https://arxiv.org/abs/2505.00136", "authors": ["Maksim Helmann", "Alexander Strack", "Dirk Pflüger"], "title": "GPRat: Gaussian Process Regression with Asynchronous Tasks", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "13 pages, 7 figures", "summary": "Python is the de-facto language for software development in artificial\nintelligence (AI). Commonly used libraries, such as PyTorch and TensorFlow,\nrely on parallelization built into their BLAS backends to achieve speedup on\nCPUs. However, only applying parallelization in a low-level backend can lead to\nperformance and scaling degradation. In this work, we present a novel way of\nbinding task-based C++ code built on the asynchronous runtime model HPX to a\nhigh-level Python API using pybind11. We develop a parallel Gaussian process\n(GP) li- brary as an application. The resulting Python library GPRat combines\nthe ease of use of commonly available GP libraries with the performance and\nscalability of asynchronous runtime systems. We evaluate the per- formance on a\nmass-spring-damper system, a standard benchmark from control theory, for\nvarying numbers of regressors (features). The results show almost no binding\noverhead when binding the asynchronous HPX code using pybind11. Compared to\nGPyTorch and GPflow, GPRat shows superior scaling on up to 64 cores on an AMD\nEPYC 7742 CPU for train- ing. Furthermore, our library achieves a prediction\nspeedup of 7.63 over GPyTorch and 25.25 over GPflow. If we increase the number\nof features from eight to 128, we observe speedups of 29.62 and 21.19,\nrespectively. These results showcase the potential of using asynchronous tasks\nwithin Python-based AI applications."}
{"id": "2505.00059", "pdf": "https://arxiv.org/pdf/2505.00059", "abs": "https://arxiv.org/abs/2505.00059", "authors": ["Paige Tuttösí", "Mantaj Dhillon", "Luna Sang", "Shane Eastwood", "Poorvi Bhatia", "Quang Minh Dinh", "Avni Kapoor", "Yewon Jin", "Angelica Lim"], "title": "BERSting at the Screams: A Benchmark for Distanced, Emotional and Shouted Speech Recognition", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted to Computer Speech and Language, Special issue:\n  Multi-Speaker, Multi-Microphone, and Multi-Modal Distant Speech Recognition\n  (September 2025)", "summary": "Some speech recognition tasks, such as automatic speech recognition (ASR),\nare approaching or have reached human performance in many reported metrics.\nYet, they continue to struggle in complex, real-world, situations, such as with\ndistanced speech. Previous challenges have released datasets to address the\nissue of distanced ASR, however, the focus remains primarily on distance,\nspecifically relying on multi-microphone array systems. Here we present the\nB(asic) E(motion) R(andom phrase) S(hou)t(s) (BERSt) dataset. The dataset\ncontains almost 4 hours of English speech from 98 actors with varying regional\nand non-native accents. The data was collected on smartphones in the actors\nhomes and therefore includes at least 98 different acoustic environments. The\ndata also includes 7 different emotion prompts and both shouted and spoken\nutterances. The smartphones were places in 19 different positions, including\nobstructions and being in a different room than the actor. This data is\npublicly available for use and can be used to evaluate a variety of speech\nrecognition tasks, including: ASR, shout detection, and speech emotion\nrecognition (SER). We provide initial benchmarks for ASR and SER tasks, and\nfind that ASR degrades both with an increase in distance and shout level and\nshows varied performance depending on the intended emotion. Our results show\nthat the BERSt dataset is challenging for both ASR and SER tasks and continued\nwork is needed to improve the robustness of such systems for more accurate\nreal-world use."}
{"id": "2505.00540", "pdf": "https://arxiv.org/pdf/2505.00540", "abs": "https://arxiv.org/abs/2505.00540", "authors": ["Ian O'Flynn", "Harun Šiljak"], "title": "Emergence of Roles in Robotic Teams with Model Sharing and Limited Communication", "categories": ["cs.MA", "cs.LG", "cs.RO", "cs.SY", "eess.SY"], "comment": "Accepted for 2025 8th International Balkan Conference on\n  Communications and Networking (Balkancom)", "summary": "We present a reinforcement learning strategy for use in multi-agent foraging\nsystems in which the learning is centralised to a single agent and its model is\nperiodically disseminated among the population of non-learning agents. In a\ndomain where multi-agent reinforcement learning (MARL) is the common approach,\nthis approach aims to significantly reduce the computational and energy demands\ncompared to approaches such as MARL and centralised learning models. By\ndeveloping high performing foraging agents, these approaches can be translated\ninto real-world applications such as logistics, environmental monitoring, and\nautonomous exploration. A reward function was incorporated into this approach\nthat promotes role development among agents, without explicit directives. This\nled to the differentiation of behaviours among the agents. The implicit\nencouragement of role differentiation allows for dynamic actions in which\nagents can alter roles dependent on their interactions with the environment\nwithout the need for explicit communication between agents."}
{"id": "2505.00115", "pdf": "https://arxiv.org/pdf/2505.00115", "abs": "https://arxiv.org/abs/2505.00115", "authors": ["Sandrine Bédard", "Jan Valošek", "Valeria Oliva", "Kenneth A. Weber II", "Julien Cohen-Adad"], "title": "Rootlets-based registration to the spinal cord PAM50 template", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Spinal cord functional MRI studies require precise localization of spinal\nlevels for reliable voxelwise group analyses. Traditional template-based\nregistration of the spinal cord uses intervertebral discs for alignment.\nHowever, substantial anatomical variability across individuals exists between\nvertebral and spinal levels. This study proposes a novel registration approach\nthat leverages spinal nerve rootlets to improve alignment accuracy and\nreproducibility across individuals. We developed a registration method\nleveraging dorsal cervical rootlets segmentation and aligning them non-linearly\nwith the PAM50 spinal cord template. Validation was performed on a\nmulti-subject, multi-site dataset (n=267, 44 sites) and a multi-subject dataset\nwith various neck positions (n=10, 3 sessions). We further validated the method\non task-based functional MRI (n=23) to compare group-level activation maps\nusing rootlet-based registration to traditional disc-based methods.\nRootlet-based registration showed superior alignment across individuals\ncompared to the traditional disc-based method. Notably, rootlet positions were\nmore stable across neck positions. Group-level analysis of task-based\nfunctional MRI using rootlet-based increased Z scores and activation cluster\nsize compared to disc-based registration (number of active voxels from 3292 to\n7978). Rootlet-based registration enhances both inter- and intra-subject\nanatomical alignment and yields better spatial normalization for group-level\nfMRI analyses. Our findings highlight the potential of rootlet-based\nregistration to improve the precision and reliability of spinal cord\nneuroimaging group analysis."}
{"id": "2505.00009", "pdf": "https://arxiv.org/pdf/2505.00009", "abs": "https://arxiv.org/abs/2505.00009", "authors": ["Xiao Zhang", "Kangsheng Wang", "Tianyu Hu", "Huimin Ma"], "title": "Efficient Knowledge Transfer in Multi-Task Learning through Task-Adaptive Low-Rank Representation", "categories": ["cs.CL"], "comment": "Accepted by IEEE International Conference on Multimedia & Expo 2025", "summary": "Pre-trained language models (PLMs) demonstrate remarkable intelligence but\nstruggle with emerging tasks unseen during training in real-world applications.\nTraining separate models for each new task is usually impractical. Multi-task\nlearning (MTL) addresses this challenge by transferring shared knowledge from\nsource tasks to target tasks. As an dominant parameter-efficient fine-tuning\nmethod, prompt tuning (PT) enhances MTL by introducing an adaptable vector that\ncaptures task-specific knowledge, which acts as a prefix to the original prompt\nthat preserves shared knowledge, while keeping PLM parameters frozen. However,\nPT struggles to effectively capture the heterogeneity of task-specific\nknowledge due to its limited representational capacity. To address this\nchallenge, we propose Task-Adaptive Low-Rank Representation (TA-LoRA), an MTL\nmethod built on PT, employing the low-rank representation to model task\nheterogeneity and a fast-slow weights mechanism where the slow weight encodes\nshared knowledge, while the fast weight captures task-specific nuances,\navoiding the mixing of shared and task-specific knowledge, caused by training\nlow-rank representations from scratch. Moreover, a zero-initialized attention\nmechanism is introduced to minimize the disruption of immature low-rank\ncomponents on original prompts during warm-up epochs. Experiments on 16 tasks\ndemonstrate that TA-LoRA achieves state-of-the-art performance in full-data and\nfew-shot settings while maintaining superior parameter efficiency."}
{"id": "2505.00204", "pdf": "https://arxiv.org/pdf/2505.00204", "abs": "https://arxiv.org/abs/2505.00204", "authors": ["Sumit Verma", "Pritam Prasun", "Arpit Jaiswal", "Pritish Kumar"], "title": "RAIL in the Wild: Operationalizing Responsible AI Evaluation Using Anthropic's Value Dataset", "categories": ["cs.AI"], "comment": null, "summary": "As AI systems become embedded in real-world applications, ensuring they meet\nethical standards is crucial. While existing AI ethics frameworks emphasize\nfairness, transparency, and accountability, they often lack actionable\nevaluation methods. This paper introduces a systematic approach using the\nResponsible AI Labs (RAIL) framework, which includes eight measurable\ndimensions to assess the normative behavior of large language models (LLMs). We\napply this framework to Anthropic's \"Values in the Wild\" dataset, containing\nover 308,000 anonymized conversations with Claude and more than 3,000 annotated\nvalue expressions. Our study maps these values to RAIL dimensions, computes\nsynthetic scores, and provides insights into the ethical behavior of LLMs in\nreal-world use."}
{"id": "2505.00150", "pdf": "https://arxiv.org/pdf/2505.00150", "abs": "https://arxiv.org/abs/2505.00150", "authors": ["Minh-Hao Van", "Xintao Wu"], "title": "Detecting and Mitigating Hateful Content in Multimodal Memes with Vision-Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "The rapid evolution of social media has provided enhanced communication\nchannels for individuals to create online content, enabling them to express\ntheir thoughts and opinions. Multimodal memes, often utilized for playful or\nhumorous expressions with visual and textual elements, are sometimes misused to\ndisseminate hate speech against individuals or groups. While the detection of\nhateful memes is well-researched, developing effective methods to transform\nhateful content in memes remains a significant challenge. Leveraging the\npowerful generation and reasoning capabilities of Vision-Language Models\n(VLMs), we address the tasks of detecting and mitigating hateful content. This\npaper presents two key contributions: first, a definition-guided prompting\ntechnique for detecting hateful memes, and second, a unified framework for\nmitigating hateful content in memes, named UnHateMeme, which works by replacing\nhateful textual and/or visual components. With our definition-guided prompts,\nVLMs achieve impressive performance on hateful memes detection task.\nFurthermore, our UnHateMeme framework, integrated with VLMs, demonstrates a\nstrong capability to convert hateful memes into non-hateful forms that meet\nhuman-level criteria for hate speech and maintain multimodal coherence between\nimage and text. Through empirical experiments, we show the effectiveness of\nstate-of-the-art pretrained VLMs such as LLaVA, Gemini and GPT-4o on the\nproposed tasks, providing a comprehensive analysis of their respective\nstrengths and limitations for these tasks. This paper aims to shed light on\nimportant applications of VLMs for ensuring safe and respectful online\nenvironments."}
{"id": "2505.00162", "pdf": "https://arxiv.org/pdf/2505.00162", "abs": "https://arxiv.org/abs/2505.00162", "authors": ["Nuojin Cheng", "Alireza Doostan", "Stephen Becker"], "title": "Stochastic Subspace Descent Accelerated via Bi-fidelity Line Search", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Efficient optimization remains a fundamental challenge across numerous\nscientific and engineering domains, especially when objective function and\ngradient evaluations are computationally expensive. While zeroth-order\noptimization methods offer effective approaches when gradients are\ninaccessible, their practical performance can be limited by the high cost\nassociated with function queries. This work introduces the bi-fidelity\nstochastic subspace descent (BF-SSD) algorithm, a novel zeroth-order\noptimization method designed to reduce this computational burden. BF-SSD\nleverages a bi-fidelity framework, constructing a surrogate model from a\ncombination of computationally inexpensive low-fidelity (LF) and accurate\nhigh-fidelity (HF) function evaluations. This surrogate model facilitates an\nefficient backtracking line search for step size selection, for which we\nprovide theoretical convergence guarantees under standard assumptions. We\nperform a comprehensive empirical evaluation of BF-SSD across four distinct\nproblems: a synthetic optimization benchmark, dual-form kernel ridge\nregression, black-box adversarial attacks on machine learning models, and\ntransformer-based black-box language model fine-tuning. Numerical results\ndemonstrate that BF-SSD consistently achieves superior optimization performance\nwhile requiring significantly fewer HF function evaluations compared to\nrelevant baseline methods. This study highlights the efficacy of integrating\nbi-fidelity strategies within zeroth-order optimization, positioning BF-SSD as\na promising and computationally efficient approach for tackling large-scale,\nhigh-dimensional problems encountered in various real-world applications."}
{"id": "2505.00368", "pdf": "https://arxiv.org/pdf/2505.00368", "abs": "https://arxiv.org/abs/2505.00368", "authors": ["Ahmed R. Sadik", "Muhammad Ashfaq", "Niko Mäkitalo", "Tommi Mikkonen"], "title": "Urban Air Mobility as a System of Systems: An LLM-Enhanced Holonic Approach", "categories": ["cs.AI", "cs.ET", "cs.MA", "cs.RO"], "comment": null, "summary": "Urban Air Mobility (UAM) is an emerging System of System (SoS) that faces\nchallenges in system architecture, planning, task management, and execution.\nTraditional architectural approaches struggle with scalability, adaptability,\nand seamless resource integration within dynamic and complex environments. This\npaper presents an intelligent holonic architecture that incorporates Large\nLanguage Model (LLM) to manage the complexities of UAM. Holons function semi\nautonomously, allowing for real time coordination among air taxis, ground\ntransport, and vertiports. LLMs process natural language inputs, generate\nadaptive plans, and manage disruptions such as weather changes or airspace\nclosures.Through a case study of multimodal transportation with electric\nscooters and air taxis, we demonstrate how this architecture enables dynamic\nresource allocation, real time replanning, and autonomous adaptation without\ncentralized control, creating more resilient and efficient urban transportation\nnetworks. By advancing decentralized control and AI driven adaptability, this\nwork lays the groundwork for resilient, human centric UAM ecosystems, with\nfuture efforts targeting hybrid AI integration and real world validation."}
{"id": "2505.00122", "pdf": "https://arxiv.org/pdf/2505.00122", "abs": "https://arxiv.org/abs/2505.00122", "authors": ["Zhenduo Shang", "Thomas Blumensath"], "title": "Stereo X-ray tomography on deformed object tracking", "categories": ["eess.IV"], "comment": null, "summary": "X-ray computed tomography is a powerful tool for volumetric imaging, but\nrequires the collection of a large number of low-noise projection images, which\nis often too time consuming, limiting its applicability. In our previous work\n\\cite{shang2023stereo}, we proposed a stereo X-ray tomography system to map the\n3D position of fiducial markers using only two projections of a static volume.\nIn dynamic imaging settings, where objects undergo deformations during imaging,\nthis static method can be extended by utilizing additional temporal\ninformation. We thus extend the method to track the deformation of fiducial\nmarkers in 3D space, where we use knowledge of the initial object shape as\nprior information, improving the prediction of the evolution of its deformed\nstate over time. In particular, knowledge of the initial object's stereo\nprojections is shown to improve the method's robustness to noise when detecting\nfiducial marker locations in the projections of the deformed objects.\nFurthermore, after feature detection, by using the features' initial 3D\nposition information in the undeformed object, we can also demonstrate\nimprovements in the 3D mapping of the deformed features. Using a range of\ndeformed 3D objects, this new approach is shown to be able to track fiducial\nmarkers in noisy stereo tomography images with subpixel accuracy."}
{"id": "2505.00010", "pdf": "https://arxiv.org/pdf/2505.00010", "abs": "https://arxiv.org/abs/2505.00010", "authors": ["Tri Nguyen", "Lohith Srikanth Pentapalli", "Magnus Sieverding", "Laurah Turner", "Seth Overla", "Weibing Zheng", "Chris Zhou", "David Furniss", "Danielle Weber", "Michael Gharib", "Matt Kelleher", "Michael Shukis", "Cameron Pawlik", "Kelly Cohen"], "title": "Jailbreak Detection in Clinical Training LLMs Using Feature-Based Predictive Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Jailbreaking in Large Language Models (LLMs) threatens their safe use in\nsensitive domains like education by allowing users to bypass ethical\nsafeguards. This study focuses on detecting jailbreaks in 2-Sigma, a clinical\neducation platform that simulates patient interactions using LLMs. We annotated\nover 2,300 prompts across 158 conversations using four linguistic variables\nshown to correlate strongly with jailbreak behavior. The extracted features\nwere used to train several predictive models, including Decision Trees, Fuzzy\nLogic-based classifiers, Boosting methods, and Logistic Regression. Results\nshow that feature-based predictive models consistently outperformed Prompt\nEngineering, with the Fuzzy Decision Tree achieving the best overall\nperformance. Our findings demonstrate that linguistic-feature-based models are\neffective and explainable alternatives for jailbreak detection. We suggest\nfuture work explore hybrid frameworks that integrate prompt-based flexibility\nwith rule-based robustness for real-time, spectrum-based jailbreak monitoring\nin educational LLMs."}
{"id": "2505.00278", "pdf": "https://arxiv.org/pdf/2505.00278", "abs": "https://arxiv.org/abs/2505.00278", "authors": ["Lo Pang-Yun Ting", "Yu-Hao Chiang", "Yi-Tung Tsai", "Hsu-Chao Lai", "Kun-Ta Chuang"], "title": "DeCo: Defect-Aware Modeling with Contrasting Matching for Optimizing Task Assignment in Online IC Testing", "categories": ["cs.AI"], "comment": null, "summary": "In the semiconductor industry, integrated circuit (IC) processes play a vital\nrole, as the rising complexity and market expectations necessitate improvements\nin yield. Identifying IC defects and assigning IC testing tasks to the right\nengineers improves efficiency and reduces losses. While current studies\nemphasize fault localization or defect classification, they overlook the\nintegration of defect characteristics, historical failures, and the insights\nfrom engineer expertise, which restrains their effectiveness in improving IC\nhandling. To leverage AI for these challenges, we propose DeCo, an innovative\napproach for optimizing task assignment in IC testing. DeCo constructs a novel\ndefect-aware graph from IC testing reports, capturing co-failure relationships\nto enhance defect differentiation, even with scarce defect data. Additionally,\nit formulates defect-aware representations for engineers and tasks, reinforced\nby local and global structure modeling on the defect-aware graph. Finally, a\ncontrasting-based assignment mechanism pairs testing tasks with QA engineers by\nconsidering their skill level and current workload, thus promoting an equitable\nand efficient job dispatch. Experiments on a real-world dataset demonstrate\nthat DeCo achieves the highest task-handling success rates in different\nscenarios, exceeding 80\\%, while also maintaining balanced workloads on both\nscarce or expanded defect data. Moreover, case studies reveal that DeCo can\nassign tasks to potentially capable engineers, even for their unfamiliar\ndefects, highlighting its potential as an AI-driven solution for the real-world\nIC failure analysis and task handling."}
{"id": "2505.00156", "pdf": "https://arxiv.org/pdf/2505.00156", "abs": "https://arxiv.org/abs/2505.00156", "authors": ["Jannik Lübberstedt", "Esteban Rivera", "Nico Uhlemann", "Markus Lienkamp"], "title": "V3LMA: Visual 3D-enhanced Language Model for Autonomous Driving", "categories": ["cs.CV"], "comment": null, "summary": "Large Vision Language Models (LVLMs) have shown strong capabilities in\nunderstanding and analyzing visual scenes across various domains. However, in\nthe context of autonomous driving, their limited comprehension of 3D\nenvironments restricts their effectiveness in achieving a complete and safe\nunderstanding of dynamic surroundings. To address this, we introduce V3LMA, a\nnovel approach that enhances 3D scene understanding by integrating Large\nLanguage Models (LLMs) with LVLMs. V3LMA leverages textual descriptions\ngenerated from object detections and video inputs, significantly boosting\nperformance without requiring fine-tuning. Through a dedicated preprocessing\npipeline that extracts 3D object data, our method improves situational\nawareness and decision-making in complex traffic scenarios, achieving a score\nof 0.56 on the LingoQA benchmark. We further explore different fusion\nstrategies and token combinations with the goal of advancing the interpretation\nof traffic scenes, ultimately enabling safer autonomous driving systems."}
{"id": "2505.00169", "pdf": "https://arxiv.org/pdf/2505.00169", "abs": "https://arxiv.org/abs/2505.00169", "authors": ["Filipp Nikitin", "Ian Dunn", "David Ryan Koes", "Olexandr Isayev"], "title": "GEOM-Drugs Revisited: Toward More Chemically Accurate Benchmarks for 3D Molecule Generation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep generative models have shown significant promise in generating valid 3D\nmolecular structures, with the GEOM-Drugs dataset serving as a key benchmark.\nHowever, current evaluation protocols suffer from critical flaws, including\nincorrect valency definitions, bugs in bond order calculations, and reliance on\nforce fields inconsistent with the reference data. In this work, we revisit\nGEOM-Drugs and propose a corrected evaluation framework: we identify and fix\nissues in data preprocessing, construct chemically accurate valency tables, and\nintroduce a GFN2-xTB-based geometry and energy benchmark. We retrain and\nre-evaluate several leading models under this framework, providing updated\nperformance metrics and practical recommendations for future benchmarking. Our\nresults underscore the need for chemically rigorous evaluation practices in 3D\nmolecular generation. Our recommended evaluation methods and GEOM-Drugs\nprocessing scripts are available at\nhttps://github.com/isayevlab/geom-drugs-3dgen-evaluation."}
{"id": "2505.00472", "pdf": "https://arxiv.org/pdf/2505.00472", "abs": "https://arxiv.org/abs/2505.00472", "authors": ["Alaa Saleh", "Sasu Tarkoma", "Praveen Kumar Donta", "Naser Hossein Motlagh", "Schahram Dustdar", "Susanna Pirttikangas", "Lauri Lovén"], "title": "UserCentrix: An Agentic Memory-augmented AI Framework for Smart Spaces", "categories": ["cs.AI", "cs.DC", "cs.MA", "cs.NI"], "comment": null, "summary": "Agentic AI, with its autonomous and proactive decision-making, has\ntransformed smart environments. By integrating Generative AI (GenAI) and\nmulti-agent systems, modern AI frameworks can dynamically adapt to user\npreferences, optimize data management, and improve resource allocation. This\npaper introduces UserCentrix, an agentic memory-augmented AI framework designed\nto enhance smart spaces through dynamic, context-aware decision-making. This\nframework integrates personalized Large Language Model (LLM) agents that\nleverage user preferences and LLM memory management to deliver proactive and\nadaptive assistance. Furthermore, it incorporates a hybrid hierarchical control\nsystem, balancing centralized and distributed processing to optimize real-time\nresponsiveness while maintaining global situational awareness. UserCentrix\nachieves resource-efficient AI interactions by embedding memory-augmented\nreasoning, cooperative agent negotiation, and adaptive orchestration\nstrategies. Our key contributions include (i) a self-organizing framework with\nproactive scaling based on task urgency, (ii) a Value of Information\n(VoI)-driven decision-making process, (iii) a meta-reasoning personal LLM\nagent, and (iv) an intelligent multi-agent coordination system for seamless\nenvironment adaptation. Experimental results across various models confirm the\neffectiveness of our approach in enhancing response accuracy, system\nefficiency, and computational resource management in real-world application."}
{"id": "2505.00133", "pdf": "https://arxiv.org/pdf/2505.00133", "abs": "https://arxiv.org/abs/2505.00133", "authors": ["Hwihun Jeong", "Hayeon Lee", "Se Young Chun", "Jongho Lee"], "title": "Efficient and robust 3D blind harmonization for large domain gaps", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Blind harmonization has emerged as a promising technique for MR image\nharmonization to achieve scale-invariant representations, requiring only target\ndomain data (i.e., no source domain data necessary). However, existing methods\nface limitations such as inter-slice heterogeneity in 3D, moderate image\nquality, and limited performance for a large domain gap. To address these\nchallenges, we introduce BlindHarmonyDiff, a novel blind 3D harmonization\nframework that leverages an edge-to-image model tailored specifically to\nharmonization. Our framework employs a 3D rectified flow trained on target\ndomain images to reconstruct the original image from an edge map, then yielding\na harmonized image from the edge of a source domain image. We propose\nmulti-stride patch training for efficient 3D training and a refinement module\nfor robust inference by suppressing hallucination. Extensive experiments\ndemonstrate that BlindHarmonyDiff outperforms prior arts by harmonizing diverse\nsource domain images to the target domain, achieving higher correspondence to\nthe target domain characteristics. Downstream task-based quality assessments\nsuch as tissue segmentation and age prediction on diverse MR scanners further\nconfirm the effectiveness of our approach and demonstrate the capability of our\nrobust and generalizable blind harmonization."}
{"id": "2505.00012", "pdf": "https://arxiv.org/pdf/2505.00012", "abs": "https://arxiv.org/abs/2505.00012", "authors": ["Fabian Retkowski", "Andreas Sudmann", "Alexander Waibel"], "title": "The AI Co-Ethnographer: How Far Can Automation Take Qualitative Research?", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to NLP4DH 2025", "summary": "Qualitative research often involves labor-intensive processes that are\ndifficult to scale while preserving analytical depth. This paper introduces The\nAI Co-Ethnographer (AICoE), a novel end-to-end pipeline developed for\nqualitative research and designed to move beyond the limitations of simply\nautomating code assignments, offering a more integrated approach. AICoE\norganizes the entire process, encompassing open coding, code consolidation,\ncode application, and even pattern discovery, leading to a comprehensive\nanalysis of qualitative data."}
{"id": "2505.00325", "pdf": "https://arxiv.org/pdf/2505.00325", "abs": "https://arxiv.org/abs/2505.00325", "authors": ["Rukma Talwadker", "Surajit Chakrabarty", "Aditya Pareek", "Tridib Mukherjee", "Deepak Saini"], "title": "CognitionNet: A Collaborative Neural Network for Play Style Discovery in Online Skill Gaming Platform", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Games are one of the safest source of realizing self-esteem and relaxation at\nthe same time. An online gaming platform typically has massive data coming in,\ne.g., in-game actions, player moves, clickstreams, transactions etc. It is\nrather interesting, as something as simple as data on gaming moves can help\ncreate a psychological imprint of the user at that moment, based on her\nimpulsive reactions and response to a situation in the game. Mining this\nknowledge can: (a) immediately help better explain observed and predicted\nplayer behavior; and (b) consequently propel deeper understanding towards\nplayers' experience, growth and protection. To this effect, we focus on\ndiscovery of the \"game behaviours\" as micro-patterns formed by continuous\nsequence of games and the persistent \"play styles\" of the players' as a\nsequence of such sequences on an online skill gaming platform for Rummy. We\npropose a two stage deep neural network, CognitionNet. The first stage focuses\non mining game behaviours as cluster representations in a latent space while\nthe second aggregates over these micro patterns to discover play styles via a\nsupervised classification objective around player engagement. The dual\nobjective allows CognitionNet to reveal several player psychology inspired\ndecision making and tactics. To our knowledge, this is the first and\none-of-its-kind research to fully automate the discovery of: (i) player\npsychology and game tactics from telemetry data; and (ii) relevant diagnostic\nexplanations to players' engagement predictions. The collaborative training of\nthe two networks with differential input dimensions is enabled using a novel\nformulation of \"bridge loss\". The network plays pivotal role in obtaining\nhomogeneous and consistent play style definitions and significantly outperforms\nthe SOTA baselines wherever applicable."}
{"id": "2505.00209", "pdf": "https://arxiv.org/pdf/2505.00209", "abs": "https://arxiv.org/abs/2505.00209", "authors": ["Kelsey Allen", "Carl Doersch", "Guangyao Zhou", "Mohammed Suhail", "Danny Driess", "Ignacio Rocco", "Yulia Rubanova", "Thomas Kipf", "Mehdi S. M. Sajjadi", "Kevin Murphy", "Joao Carreira", "Sjoerd van Steenkiste"], "title": "Direct Motion Models for Assessing Generated Videos", "categories": ["cs.CV", "cs.LG"], "comment": "Project page: http://trajan-paper.github.io", "summary": "A current limitation of video generative video models is that they generate\nplausible looking frames, but poor motion -- an issue that is not well captured\nby FVD and other popular methods for evaluating generated videos. Here we go\nbeyond FVD by developing a metric which better measures plausible object\ninteractions and motion. Our novel approach is based on auto-encoding point\ntracks and yields motion features that can be used to not only compare\ndistributions of videos (as few as one generated and one ground truth, or as\nmany as two datasets), but also for evaluating motion of single videos. We show\nthat using point tracks instead of pixel reconstruction or action recognition\nfeatures results in a metric which is markedly more sensitive to temporal\ndistortions in synthetic data, and can predict human evaluations of temporal\nconsistency and realism in generated videos obtained from open-source models\nbetter than a wide range of alternatives. We also show that by using a point\ntrack representation, we can spatiotemporally localize generative video\ninconsistencies, providing extra interpretability of generated video errors\nrelative to prior work. An overview of the results and link to the code can be\nfound on the project page: http://trajan-paper.github.io."}
{"id": "2505.00171", "pdf": "https://arxiv.org/pdf/2505.00171", "abs": "https://arxiv.org/abs/2505.00171", "authors": ["Saram Abbas", "Naeem Soomro", "Rishad Shafik", "Rakesh Heer", "Kabita Adhikari"], "title": "Attention-enabled Explainable AI for Bladder Cancer Recurrence Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "7 pages, 5 figures, Accepted to be presented at the 47th Annual\n  International Conference of the IEEE Engineering in Medicine and Biology\n  Society (EMBC 2025)", "summary": "Non-muscle-invasive bladder cancer (NMIBC) is a relentless challenge in\noncology, with recurrence rates soaring as high as 70-80%. Each recurrence\ntriggers a cascade of invasive procedures, lifelong surveillance, and\nescalating healthcare costs - affecting 460,000 individuals worldwide. However,\nexisting clinical prediction tools remain fundamentally flawed, often\noverestimating recurrence risk and failing to provide personalized insights for\npatient management. In this work, we propose an interpretable deep learning\nframework that integrates vector embeddings and attention mechanisms to improve\nNMIBC recurrence prediction performance. We incorporate vector embeddings for\ncategorical variables such as smoking status and intravesical treatments,\nallowing the model to capture complex relationships between patient attributes\nand recurrence risk. These embeddings provide a richer representation of the\ndata, enabling improved feature interactions and enhancing prediction\nperformance. Our approach not only enhances performance but also provides\nclinicians with patient-specific insights by highlighting the most influential\nfeatures contributing to recurrence risk for each patient. Our model achieves\naccuracy of 70% with tabular data, outperforming conventional statistical\nmethods while providing clinician-friendly patient-level explanations through\nfeature attention. Unlike previous studies, our approach identifies new\nimportant factors influencing recurrence, such as surgical duration and\nhospital stay, which had not been considered in existing NMIBC prediction\nmodels."}
{"id": "2505.00515", "pdf": "https://arxiv.org/pdf/2505.00515", "abs": "https://arxiv.org/abs/2505.00515", "authors": ["Mingxing Peng", "Ruoyu Yao", "Xusen Guo", "Yuting Xie", "Xianda Chen", "Jun Ma"], "title": "Safety-Critical Traffic Simulation with Guided Latent Diffusion Model", "categories": ["cs.RO", "cs.AI", "cs.MA"], "comment": "7 pages, 3 figures", "summary": "Safety-critical traffic simulation plays a crucial role in evaluating\nautonomous driving systems under rare and challenging scenarios. However,\nexisting approaches often generate unrealistic scenarios due to insufficient\nconsideration of physical plausibility and suffer from low generation\nefficiency. To address these limitations, we propose a guided latent diffusion\nmodel (LDM) capable of generating physically realistic and adversarial\nsafety-critical traffic scenarios. Specifically, our model employs a\ngraph-based variational autoencoder (VAE) to learn a compact latent space that\ncaptures complex multi-agent interactions while improving computational\nefficiency. Within this latent space, the diffusion model performs the\ndenoising process to produce realistic trajectories. To enable controllable and\nadversarial scenario generation, we introduce novel guidance objectives that\ndrive the diffusion process toward producing adversarial and behaviorally\nrealistic driving behaviors. Furthermore, we develop a sample selection module\nbased on physical feasibility checks to further enhance the physical\nplausibility of the generated scenarios. Extensive experiments on the nuScenes\ndataset demonstrate that our method achieves superior adversarial effectiveness\nand generation efficiency compared to existing baselines while maintaining a\nhigh level of realism. Our work provides an effective tool for realistic\nsafety-critical scenario simulation, paving the way for more robust evaluation\nof autonomous driving systems."}
{"id": "2505.00374", "pdf": "https://arxiv.org/pdf/2505.00374", "abs": "https://arxiv.org/abs/2505.00374", "authors": ["Usman Muhammad", "Jorma Laaksonen", "Lyudmila Mihaylova"], "title": "Towards Lightweight Hyperspectral Image Super-Resolution with Depthwise Separable Dilated Convolutional Network", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Deep neural networks have demonstrated highly competitive performance in\nsuper-resolution (SR) for natural images by learning mappings from\nlow-resolution (LR) to high-resolution (HR) images. However, hyperspectral\nsuper-resolution remains an ill-posed problem due to the high spectral\ndimensionality of the data and the scarcity of available training samples.\nMoreover, existing methods often rely on large models with a high number of\nparameters or require the fusion with panchromatic or RGB images, both of which\nare often impractical in real-world scenarios. Inspired by the MobileNet\narchitecture, we introduce a lightweight depthwise separable dilated\nconvolutional network (DSDCN) to address the aforementioned challenges.\nSpecifically, our model leverages multiple depthwise separable convolutions,\nsimilar to the MobileNet architecture, and further incorporates a dilated\nconvolution fusion block to make the model more flexible for the extraction of\nboth spatial and spectral features. In addition, we propose a custom loss\nfunction that combines mean squared error (MSE), an L2 norm\nregularization-based constraint, and a spectral angle-based loss, ensuring the\npreservation of both spectral and spatial details. The proposed model achieves\nvery competitive performance on two publicly available hyperspectral datasets,\nmaking it well-suited for hyperspectral image super-resolution tasks. The\nsource codes are publicly available at:\n\\href{https://github.com/Usman1021/lightweight}{https://github.com/Usman1021/lightweight}."}
{"id": "2505.00013", "pdf": "https://arxiv.org/pdf/2505.00013", "abs": "https://arxiv.org/abs/2505.00013", "authors": ["Yoichi Takenaka"], "title": "Performance Evaluation of Emotion Classification in Japanese Using RoBERTa and DeBERTa", "categories": ["cs.CL", "cs.AI"], "comment": "14 pages, 3 tables, 3 appendices. Submitted to New Generation\n  Computing. Includes comparisons between fine-tuned PLMs and LLMs on Japanese\n  emotion classification. Code available at\n  https://pypi.org/project/deberta-emotion-predictor/", "summary": "Background Practical applications such as social media monitoring and\ncustomer-feedback analysis require accurate emotion detection for Japanese\ntext, yet resource scarcity and class imbalance hinder model performance.\n  Objective This study aims to build a high-accuracy model for predicting the\npresence or absence of eight Plutchik emotions in Japanese sentences.\n  Methods Using the WRIME corpus, we transform reader-averaged intensity scores\ninto binary labels and fine-tune four pre-trained language models (BERT,\nRoBERTa, DeBERTa-v3-base, DeBERTa-v3-large). For context, we also assess two\nlarge language models (TinySwallow-1.5B-Instruct and ChatGPT-4o). Accuracy and\nF1-score serve as evaluation metrics.\n  Results DeBERTa-v3-large attains the best mean accuracy (0.860) and F1-score\n(0.662), outperforming all other models. It maintains robust F1 across both\nhigh-frequency emotions (e.g., Joy, Anticipation) and low-frequency emotions\n(e.g., Anger, Trust). The LLMs lag, with ChatGPT-4o and\nTinySwallow-1.5B-Instruct scoring 0.527 and 0.292 in mean F1, respectively.\n  Conclusion The fine-tuned DeBERTa-v3-large model currently offers the most\nreliable solution for binary emotion classification in Japanese. We release\nthis model as a pip-installable package (pip install\ndeberta-emotion-predictor). Future work should augment data for rare emotions,\nreduce model size, and explore prompt engineering to improve LLM performance.\n  This manuscript is under review for possible publication in New Generation\nComputing."}
{"id": "2505.00416", "pdf": "https://arxiv.org/pdf/2505.00416", "abs": "https://arxiv.org/abs/2505.00416", "authors": ["Jing Huang", "Zhixiong Zeng", "Wenkang Han", "Yufeng Zhong", "Liming Zheng", "Shuai Fu", "Jingyuan Chen", "Lin Ma"], "title": "ScaleTrack: Scaling and back-tracking Automated GUI Agents", "categories": ["cs.AI"], "comment": null, "summary": "Automated GUI agents aims to facilitate user interaction by automatically\nperforming complex tasks in digital environments, such as web, mobile, desktop\ndevices. It receives textual task instruction and GUI description to generate\nexecutable actions (\\emph{e.g.}, click) and operation boxes step by step.\nTraining a GUI agent mainly involves grounding and planning stages, in which\nthe GUI grounding focuses on finding the execution coordinates according to the\ntask, while the planning stage aims to predict the next action based on\nhistorical actions. However, previous work suffers from the limitations of\ninsufficient training data for GUI grounding, as well as the ignorance of\nbacktracking historical behaviors for GUI planning. To handle the above\nchallenges, we propose ScaleTrack, a training framework by scaling grounding\nand backtracking planning for automated GUI agents. We carefully collected GUI\nsamples of different synthesis criterions from a wide range of sources, and\nunified them into the same template for training GUI grounding models.\nMoreover, we design a novel training strategy that predicts the next action\nfrom the current GUI image, while also backtracking the historical actions that\nled to the GUI image. In this way, ScaleTrack explains the correspondence\nbetween GUI images and actions, which effectively describes the evolution rules\nof the GUI environment. Extensive experimental results demonstrate the\neffectiveness of ScaleTrack. Data and code will be available at url."}
{"id": "2505.00220", "pdf": "https://arxiv.org/pdf/2505.00220", "abs": "https://arxiv.org/abs/2505.00220", "authors": ["Ankit Amrutkar", "Björn Kampa", "Volkmar Schulz", "Johannes Stegmaier", "Markus Rothermel", "Dorit Merhof"], "title": "Towards Robust and Generalizable Gerchberg Saxton based Physics Inspired Neural Networks for Computer Generated Holography: A Sensitivity Analysis Framework", "categories": ["cs.CV", "physics.optics"], "comment": null, "summary": "Computer-generated holography (CGH) enables applications in holographic\naugmented reality (AR), 3D displays, systems neuroscience, and optical\ntrapping. The fundamental challenge in CGH is solving the inverse problem of\nphase retrieval from intensity measurements. Physics-inspired neural networks\n(PINNs), especially Gerchberg-Saxton-based PINNs (GS-PINNs), have advanced\nphase retrieval capabilities. However, their performance strongly depends on\nforward models (FMs) and their hyperparameters (FMHs), limiting generalization,\ncomplicating benchmarking, and hindering hardware optimization. We present a\nsystematic sensitivity analysis framework based on Saltelli's extension of\nSobol's method to quantify FMH impacts on GS-PINN performance. Our analysis\ndemonstrates that SLM pixel-resolution is the primary factor affecting neural\nnetwork sensitivity, followed by pixel-pitch, propagation distance, and\nwavelength. Free space propagation forward models demonstrate superior neural\nnetwork performance compared to Fourier holography, providing enhanced\nparameterization and generalization. We introduce a composite evaluation metric\ncombining performance consistency, generalization capability, and\nhyperparameter perturbation resilience, establishing a unified benchmarking\nstandard across CGH configurations. Our research connects physics-inspired deep\nlearning theory with practical CGH implementations through concrete guidelines\nfor forward model selection, neural network architecture, and performance\nevaluation. Our contributions advance the development of robust, interpretable,\nand generalizable neural networks for diverse holographic applications,\nsupporting evidence-based decisions in CGH research and implementation."}
{"id": "2505.00189", "pdf": "https://arxiv.org/pdf/2505.00189", "abs": "https://arxiv.org/abs/2505.00189", "authors": ["Houda Belhad", "Asmae Bourbia", "Salma Boughanja"], "title": "Chronic Diseases Prediction using Machine Learning and Deep Learning Methods", "categories": ["cs.LG"], "comment": null, "summary": "Chronic diseases, such as cardiovascular disease, diabetes, chronic kidney\ndisease, and thyroid disorders, are the leading causes of premature mortality\nworldwide. Early detection and intervention are crucial for improving patient\noutcomes, yet traditional diagnostic methods often fail due to the complex\nnature of these conditions. This study explores the application of machine\nlearning (ML) and deep learning (DL) techniques to predict chronic disease and\nthyroid disorders. We used a variety of models, including Logistic Regression\n(LR), Random Forest (RF), Gradient Boosted Trees (GBT), Neural Networks (NN),\nDecision Trees (DT) and Native Bayes (NB), to analyze and predict disease\noutcomes. Our methodology involved comprehensive data pre-processing, including\nhandling missing values, categorical encoding, and feature aggregation,\nfollowed by model training and evaluation. Performance metrics such ad\nprecision, recall, accuracy, F1-score, and Area Under the Curve (AUC) were used\nto assess the effectiveness of each model. The results demonstrated that\nensemble methods like Random Forest and Gradient Boosted Trees consistently\noutperformed. Neutral Networks also showed superior performance, particularly\nin capturing complex data patterns. The findings highlight the potential of ML\nand DL in revolutionizing chronic disease prediction, enabling early diagnosis\nand personalized treatment strategies. However, challenges such as data\nquality, model interpretability, and the need for advanced computational\ntechniques in healthcare to improve patient outcomes and reduce the burden of\nchronic diseases. This study was conducted as part of Big Data class project\nunder the supervision of our professors Mr. Abderrahmane EZ-ZAHOUT and Mr.\nAbdessamad ESSAIDI."}
{"id": "2505.00462", "pdf": "https://arxiv.org/pdf/2505.00462", "abs": "https://arxiv.org/abs/2505.00462", "authors": ["Julian Christopher L. Maya", "Johnenn R. Manalang", "Maricor N. Soriano"], "title": "CORSTITCH - A free, open source software for stitching and georeferencing underwater coral reef videos", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "CorStitch is an open-source software developed to automate the creation of\naccurate georeferenced reef mosaics from video transects obtained through\nAutomated Rapid Reef Assessment System surveys. We utilized a Fourier-based\nimage correlation algorithm to stitch sequential video frames, aligning them\nwith synchronized GNSS timestamps. The resulting compressed Keyhole Markup\nLanguage files, compatible with geographic information systems such as Google\nEarth, enable detailed spatial analysis. Validation through comparative\nanalysis of mosaics from two temporally distinct surveys of the same reef\ndemonstrated the software's consistent and reliable performance."}
{"id": "2505.00014", "pdf": "https://arxiv.org/pdf/2505.00014", "abs": "https://arxiv.org/abs/2505.00014", "authors": ["Vinit K. Chavan"], "title": "Manifold-Constrained Sentence Embeddings via Triplet Loss: Projecting Semantics onto Spheres, Tori, and Möbius Strips", "categories": ["cs.CL"], "comment": "10 pages, 6 figures. Code available at\n  https://github.com/vinitchavan/manifold-embedding-nlp", "summary": "Recent advances in representation learning have emphasized the role of\nembedding geometry in capturing semantic structure. Traditional sentence\nembeddings typically reside in unconstrained Euclidean spaces, which may limit\ntheir ability to reflect complex relationships in language. In this work, we\nintroduce a novel framework that constrains sentence embeddings to lie on\ncontinuous manifolds -- specifically the unit sphere, torus, and M\\\"obius strip\n-- using triplet loss as the core training objective. By enforcing differential\ngeometric constraints on the output space, our approach encourages the learning\nof embeddings that are both discriminative and topologically structured.\n  We evaluate our method on benchmark datasets (AG News and MBTI) and compare\nit to classical baselines including TF-IDF, Word2Vec, and unconstrained\nKeras-derived embeddings. Our results demonstrate that manifold-constrained\nembeddings, particularly those projected onto spheres and M\\\"obius strips,\nsignificantly outperform traditional approaches in both clustering quality\n(Silhouette Score) and classification performance (Accuracy). These findings\nhighlight the value of embedding in manifold space -- where topological\nstructure complements semantic separation -- offering a new and mathematically\ngrounded direction for geometric representation learning in NLP."}
{"id": "2505.00474", "pdf": "https://arxiv.org/pdf/2505.00474", "abs": "https://arxiv.org/abs/2505.00474", "authors": ["Cecilia Di Florio", "Huimin Dong", "Antonino Rotolo"], "title": "Rule-based Classifier Models", "categories": ["cs.AI"], "comment": "11 pages, 1 figure. Extended version of a short paper accepted to\n  ICAIL 2025. This is the authors' version of the work. It is posted here for\n  your personal use", "summary": "We extend the formal framework of classifier models used in the legal domain.\nWhile the existing classifier framework characterises cases solely through the\nfacts involved, legal reasoning fundamentally relies on both facts and rules,\nparticularly the ratio decidendi. This paper presents an initial approach to\nincorporating sets of rules within a classifier. Our work is built on the work\nof Canavotto et al. (2023), which has developed the rule-based reason model of\nprecedential constraint within a hierarchy of factors. We demonstrate how\ndecisions for new cases can be inferred using this enriched rule-based\nclassifier framework. Additionally, we provide an example of how the time\nelement and the hierarchy of courts can be used in the new classifier\nframework."}
{"id": "2505.00228", "pdf": "https://arxiv.org/pdf/2505.00228", "abs": "https://arxiv.org/abs/2505.00228", "authors": ["Xiaoman Zhang", "Julián N. Acosta", "Josh Miller", "Ouwen Huang", "Pranav Rajpurkar"], "title": "ReXGradient-160K: A Large-Scale Publicly Available Dataset of Chest Radiographs with Free-text Reports", "categories": ["cs.CV"], "comment": null, "summary": "We present ReXGradient-160K, representing the largest publicly available\nchest X-ray dataset to date in terms of the number of patients. This dataset\ncontains 160,000 chest X-ray studies with paired radiological reports from\n109,487 unique patients across 3 U.S. health systems (79 medical sites). This\ncomprehensive dataset includes multiple images per study and detailed radiology\nreports, making it particularly valuable for the development and evaluation of\nAI systems for medical imaging and automated report generation models. The\ndataset is divided into training (140,000 studies), validation (10,000\nstudies), and public test (10,000 studies) sets, with an additional private\ntest set (10,000 studies) reserved for model evaluation on the ReXrank\nbenchmark. By providing this extensive dataset, we aim to accelerate research\nin medical imaging AI and advance the state-of-the-art in automated\nradiological analysis. Our dataset will be open-sourced at\nhttps://huggingface.co/datasets/rajpurkarlab/ReXGradient-160K."}
{"id": "2505.00190", "pdf": "https://arxiv.org/pdf/2505.00190", "abs": "https://arxiv.org/abs/2505.00190", "authors": ["Hans Peter", "Anders Søgaard"], "title": "Empirical Evaluation of Progressive Coding for Sparse Autoencoders", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Sparse autoencoders (SAEs)\n\\citep{bricken2023monosemanticity,gao2024scalingevaluatingsparseautoencoders}\nrely on dictionary learning to extract interpretable features from neural\nnetworks at scale in an unsupervised manner, with applications to\nrepresentation engineering and information retrieval. SAEs are, however,\ncomputationally expensive \\citep{lieberum2024gemmascopeopensparse}, especially\nwhen multiple SAEs of different sizes are needed. We show that dictionary\nimportance in vanilla SAEs follows a power law. We compare progressive coding\nbased on subset pruning of SAEs -- to jointly training nested SAEs, or\nso-called {\\em Matryoshka} SAEs\n\\citep{bussmann2024learning,nabeshima2024Matryoshka} -- on a language modeling\ntask. We show Matryoshka SAEs exhibit lower reconstruction loss and recaptured\nlanguage modeling loss, as well as higher representational similarity. Pruned\nvanilla SAEs are more interpretable, however. We discuss the origins and\nimplications of this trade-off."}
{"id": "2505.00525", "pdf": "https://arxiv.org/pdf/2505.00525", "abs": "https://arxiv.org/abs/2505.00525", "authors": ["Abu Saleh Musa Miah", "taro Suzuki", "Jungpil Shin"], "title": "A Methodological and Structural Review of Parkinsons Disease Detection Across Diverse Data Modalities", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "Parkinsons Disease (PD) is a progressive neurological disorder that primarily\naffects motor functions and can lead to mild cognitive impairment (MCI) and\ndementia in its advanced stages. With approximately 10 million people diagnosed\nglobally 1 to 1.8 per 1,000 individuals, according to reports by the Japan\nTimes and the Parkinson Foundation early and accurate diagnosis of PD is\ncrucial for improving patient outcomes. While numerous studies have utilized\nmachine learning (ML) and deep learning (DL) techniques for PD recognition,\nexisting surveys are limited in scope, often focusing on single data modalities\nand failing to capture the potential of multimodal approaches. To address these\ngaps, this study presents a comprehensive review of PD recognition systems\nacross diverse data modalities, including Magnetic Resonance Imaging (MRI),\ngait-based pose analysis, gait sensory data, handwriting analysis, speech test\ndata, Electroencephalography (EEG), and multimodal fusion techniques. Based on\nover 347 articles from leading scientific databases, this review examines key\naspects such as data collection methods, settings, feature representations, and\nsystem performance, with a focus on recognition accuracy and robustness. This\nsurvey aims to serve as a comprehensive resource for researchers, providing\nactionable guidance for the development of next generation PD recognition\nsystems. By leveraging diverse data modalities and cutting-edge machine\nlearning paradigms, this work contributes to advancing the state of PD\ndiagnostics and improving patient care through innovative, multimodal\napproaches."}
{"id": "2505.00015", "pdf": "https://arxiv.org/pdf/2505.00015", "abs": "https://arxiv.org/abs/2505.00015", "authors": ["MD Thamed Bin Zaman Chowdhury", "Moazzem Hossain"], "title": "Design and Application of Multimodal Large Language Model Based System for End to End Automation of Accident Dataset Generation", "categories": ["cs.CL"], "comment": "Shortened the abstract to fit within 1920 characters. This paper is\n  currently under Review in Elsevier journal 'Accident Analysis & Prevention'", "summary": "Road traffic accidents remain a major public safety and socio-economic issue\nin developing countries like Bangladesh. Existing accident data collection is\nlargely manual, fragmented, and unreliable, resulting in underreporting and\ninconsistent records. This research proposes a fully automated system using\nLarge Language Models (LLMs) and web scraping techniques to address these\nchallenges. The pipeline consists of four components: automated web scraping\ncode generation, news collection from online sources, accident news\nclassification with structured data extraction, and duplicate removal. The\nsystem uses the multimodal generative LLM Gemini-2.0-Flash for seamless\nautomation. The code generation module classifies webpages into pagination,\ndynamic, or infinite scrolling categories and generates suitable Python scripts\nfor scraping. LLMs also classify and extract key accident information such as\ndate, time, location, fatalities, injuries, road type, vehicle types, and\npedestrian involvement. A deduplication algorithm ensures data integrity by\nremoving duplicate reports. The system scraped 14 major Bangladeshi news sites\nover 111 days (Oct 1, 2024 - Jan 20, 2025), processing over 15,000 news\narticles and identifying 705 unique accidents. The code generation module\nachieved 91.3% calibration and 80% validation accuracy. Chittagong reported the\nhighest number of accidents (80), fatalities (70), and injuries (115), followed\nby Dhaka, Faridpur, Gazipur, and Cox's Bazar. Peak accident times were morning\n(8-9 AM), noon (12-1 PM), and evening (6-7 PM). A public repository was also\ndeveloped with usage instructions. This study demonstrates the viability of an\nLLM-powered, scalable system for accurate, low-effort accident data collection,\nproviding a foundation for data-driven road safety policymaking in Bangladesh."}
{"id": "2505.00603", "pdf": "https://arxiv.org/pdf/2505.00603", "abs": "https://arxiv.org/abs/2505.00603", "authors": ["Phanish Puranam", "Prothit Sen", "Maciej Workiewicz"], "title": "Can LLMs Help Improve Analogical Reasoning For Strategic Decisions? Experimental Evidence from Humans and GPT-4", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "This study investigates whether large language models, specifically GPT4, can\nmatch human capabilities in analogical reasoning within strategic decision\nmaking contexts. Using a novel experimental design involving source to target\nmatching, we find that GPT4 achieves high recall by retrieving all plausible\nanalogies but suffers from low precision, frequently applying incorrect\nanalogies based on superficial similarities. In contrast, human participants\nexhibit high precision but low recall, selecting fewer analogies yet with\nstronger causal alignment. These findings advance theory by identifying\nmatching, the evaluative phase of analogical reasoning, as a distinct step that\nrequires accurate causal mapping beyond simple retrieval. While current LLMs\nare proficient in generating candidate analogies, humans maintain a comparative\nadvantage in recognizing deep structural similarities across domains. Error\nanalysis reveals that AI errors arise from surface level matching, whereas\nhuman errors stem from misinterpretations of causal structure. Taken together,\nthe results suggest a productive division of labor in AI assisted\norganizational decision making where LLMs may serve as broad analogy\ngenerators, while humans act as critical evaluators, applying the most\ncontextually appropriate analogies to strategic problems."}
{"id": "2505.00254", "pdf": "https://arxiv.org/pdf/2505.00254", "abs": "https://arxiv.org/abs/2505.00254", "authors": ["Yuxuan Yan", "Shiqi Jiang", "Ting Cao", "Yifan Yang", "Qianqian Yang", "Yuanchao Shu", "Yuqing Yang", "Lili Qiu"], "title": "Empowering Agentic Video Analytics Systems with Video Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "15 pages", "summary": "AI-driven video analytics has become increasingly pivotal across diverse\ndomains. However, existing systems are often constrained to specific,\npredefined tasks, limiting their adaptability in open-ended analytical\nscenarios. The recent emergence of Video-Language Models (VLMs) as\ntransformative technologies offers significant potential for enabling\nopen-ended video understanding, reasoning, and analytics. Nevertheless, their\nlimited context windows present challenges when processing ultra-long video\ncontent, which is prevalent in real-world applications. To address this, we\nintroduce AVA, a VLM-powered system designed for open-ended, advanced video\nanalytics. AVA incorporates two key innovations: (1) the near real-time\nconstruction of Event Knowledge Graphs (EKGs) for efficient indexing of long or\ncontinuous video streams, and (2) an agentic retrieval-generation mechanism\nthat leverages EKGs to handle complex and diverse queries. Comprehensive\nevaluations on public benchmarks, LVBench and VideoMME-Long, demonstrate that\nAVA achieves state-of-the-art performance, attaining 62.3% and 64.1% accuracy,\nrespectively, significantly surpassing existing VLM and video\nRetrieval-Augmented Generation (RAG) systems. Furthermore, to evaluate video\nanalytics in ultra-long and open-world video scenarios, we introduce a new\nbenchmark, AVA-100. This benchmark comprises 8 videos, each exceeding 10 hours\nin duration, along with 120 manually annotated, diverse, and complex\nquestion-answer pairs. On AVA-100, AVA achieves top-tier performance with an\naccuracy of 75.8%."}
{"id": "2505.00196", "pdf": "https://arxiv.org/pdf/2505.00196", "abs": "https://arxiv.org/abs/2505.00196", "authors": ["Eloy Geenjaar", "Vince Calhoun"], "title": "Mapping minds not averages: a scalable subject-specific manifold learning framework for neuroimaging data", "categories": ["cs.LG", "q-bio.NC"], "comment": "20 pages, 6 figures", "summary": "Mental and cognitive representations are believed to reside on\nlow-dimensional, non-linear manifolds embedded within high-dimensional brain\nactivity. Uncovering these manifolds is key to understanding individual\ndifferences in brain function, yet most existing machine learning methods\neither rely on population-level spatial alignment or assume data that is\ntemporally structured, either because data is aligned among subjects or because\nevent timings are known. We introduce a manifold learning framework that can\ncapture subject-specific spatial variations across both structured and\ntemporally unstructured neuroimaging data. On simulated data and two\nnaturalistic fMRI datasets (Sherlock and Forrest Gump), our framework\noutperforms group-based baselines by recovering more accurate and\nindividualized representations. We further show that the framework scales\nefficiently to large datasets and generalizes well to new subjects. To test\nthis, we apply the framework to temporally unstructured resting-state fMRI data\nfrom individuals with schizophrenia and healthy controls. We further apply our\nmethod to a large resting-state fMRI dataset comprising individuals with\nschizophrenia and controls. In this setting, we demonstrate that the framework\nscales efficiently to large populations and generalizes robustly to unseen\nsubjects. The learned subject-specific spatial maps our model finds reveal\nclinically relevant patterns, including increased activation in the basal\nganglia, visual, auditory, and somatosensory regions, and decreased activation\nin the insula, inferior frontal gyrus, and angular gyrus. These findings\nsuggest that our framework can uncover clinically relevant subject-specific\nbrain activity patterns. Our approach thus provides a scalable and\nindividualized framework for modeling brain activity, with applications in\ncomputational neuroscience and clinical research."}
{"id": "2505.00578", "pdf": "https://arxiv.org/pdf/2505.00578", "abs": "https://arxiv.org/abs/2505.00578", "authors": ["Shuang Zhang", "Carleton Coffin", "Karyn L. Rogers", "Catherine Ann Royer", "Ge Wang"], "title": "AI-Driven High-Resolution Cell Segmentation and Quantitative Analysis", "categories": ["eess.IV", "q-bio.QM"], "comment": null, "summary": "Studying the growth and metabolism of microbes provides critical insights\ninto their evolutionary adaptations to harsh environments, which are essential\nfor microbial research and biotechnology applications. In this study, we\ndeveloped an AI-driven image analysis system to efficiently segment individual\ncells and quantitatively analyze key cellular features. This system is\ncomprised of four main modules. First, a denoising algorithm enhances contrast\nand suppresses noise while preserving fine cellular details. Second, the\nSegment Anything Model (SAM) enables accurate, zero-shot segmentation of cells\nwithout additional training. Third, post-processing is applied to refine\nsegmentation results by removing over-segmented masks. Finally, quantitative\nanalysis algorithms extract essential cellular features, including average\nintensity, length, width, and volume. The results show that denoising and\npost-processing significantly improved the segmentation accuracy of SAM in this\nnew domain. Without human annotations, the AI-driven pipeline automatically and\nefficiently outlines cellular boundaries, indexes them, and calculates key\ncellular parameters with high accuracy. This framework will enable efficient\nand automated quantitative analysis of high-resolution fluorescence microscopy\nimages to advance research into microbial adaptations to grow and metabolism\nthat allow extremophiles to thrive in their harsh habitats."}
{"id": "2505.00016", "pdf": "https://arxiv.org/pdf/2505.00016", "abs": "https://arxiv.org/abs/2505.00016", "authors": ["Josefa Lia Stoisser", "Marc Boubnovski Martell", "Julien Fauqueur"], "title": "Sparks of Tabular Reasoning via Text2SQL Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This work reframes the Text-to-SQL task as a pathway for teaching large\nlanguage models (LLMs) to reason over and manipulate tabular data--moving\nbeyond the traditional focus on query generation. We propose a two-stage\nframework that leverages SQL supervision to develop transferable table\nreasoning capabilities. First, we synthesize detailed chain-of-thought (CoT)\ntraces from real-world SQL queries, providing step-by-step, clause-level\nsupervision that teaches the model how to traverse, filter, and aggregate table\nfields. Second, we introduce a Group Relative Policy Optimization (GRPO)\nreinforcement learning objective that connects SQL execution accuracy to\ngeneralizable reasoning by encouraging steps that extend beyond task-specific\nsyntax and transfer across datasets. Empirically, our approach improves\nperformance on standard Text-to-SQL benchmarks and achieves substantial gains\non reasoning-intensive datasets such as BIRD and CRT-QA, demonstrating enhanced\ngeneralization and interpretability. Specifically, the distilled-quantized\nLLaMA model achieved a 20\\% increase in accuracy when trained on Text-to-SQL\ntasks, while Qwen achieved a 5\\% increase. These results suggest that SQL can\nserve not only as a target formalism but also as an effective scaffold for\nlearning robust, transferable reasoning over structured data."}
{"id": "2505.00610", "pdf": "https://arxiv.org/pdf/2505.00610", "abs": "https://arxiv.org/abs/2505.00610", "authors": ["Ziyan An", "Xia Wang", "Hendrik Baier", "Zirong Chen", "Abhishek Dubey", "Taylor T. Johnson", "Jonathan Sprinkle", "Ayan Mukhopadhyay", "Meiyi Ma"], "title": "Combining LLMs with Logic-Based Framework to Explain MCTS", "categories": ["cs.AI"], "comment": "Accepted by AAMAS-25 as an extended abstract", "summary": "In response to the lack of trust in Artificial Intelligence (AI) for\nsequential planning, we design a Computational Tree Logic-guided large language\nmodel (LLM)-based natural language explanation framework designed for the Monte\nCarlo Tree Search (MCTS) algorithm. MCTS is often considered challenging to\ninterpret due to the complexity of its search trees, but our framework is\nflexible enough to handle a wide range of free-form post-hoc queries and\nknowledge-based inquiries centered around MCTS and the Markov Decision Process\n(MDP) of the application domain. By transforming user queries into logic and\nvariable statements, our framework ensures that the evidence obtained from the\nsearch tree remains factually consistent with the underlying environmental\ndynamics and any constraints in the actual stochastic control process. We\nevaluate the framework rigorously through quantitative assessments, where it\ndemonstrates strong performance in terms of accuracy and factual consistency."}
{"id": "2505.00259", "pdf": "https://arxiv.org/pdf/2505.00259", "abs": "https://arxiv.org/abs/2505.00259", "authors": ["Changjun Li", "Runqing Jiang", "Zhuo Song", "Pengpeng Yu", "Ye Zhang", "Yulan Guo"], "title": "Pack-PTQ: Advancing Post-training Quantization of Neural Networks by Pack-wise Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Post-training quantization (PTQ) has evolved as a prominent solution for\ncompressing complex models, which advocates a small calibration dataset and\navoids end-to-end retraining. However, most existing PTQ methods employ\nblock-wise reconstruction, which neglects cross-block dependency and exhibits a\nnotable accuracy drop in low-bit cases. To address these limitations, this\npaper presents a novel PTQ method, dubbed Pack-PTQ. First, we design a\nHessian-guided adaptive packing mechanism to partition blocks into\nnon-overlapping packs, which serve as the base unit for reconstruction, thereby\npreserving the cross-block dependency and enabling accurate quantization\nparameters estimation. Second, based on the pack configuration, we propose a\nmixed-precision quantization approach to assign varied bit-widths to packs\naccording to their distinct sensitivities, thereby further enhancing\nperformance. Extensive experiments on 2D image and 3D point cloud\nclassification tasks, using various network architectures, demonstrate the\nsuperiority of our method over the state-of-the-art PTQ methods."}
{"id": "2505.00210", "pdf": "https://arxiv.org/pdf/2505.00210", "abs": "https://arxiv.org/abs/2505.00210", "authors": ["Suk Ki Lee", "Hyunwoong Ko"], "title": "Generative Machine Learning in Adaptive Control of Dynamic Manufacturing Processes: A Review", "categories": ["cs.LG", "cs.CE", "cs.SY", "eess.SY"], "comment": "12 pages, 1 figure, 1 table. This paper has been accepted for\n  publication in the proceedings of ASME IDETC-CIE 2025", "summary": "Dynamic manufacturing processes exhibit complex characteristics defined by\ntime-varying parameters, nonlinear behaviors, and uncertainties. These\ncharacteristics require sophisticated in-situ monitoring techniques utilizing\nmultimodal sensor data and adaptive control systems that can respond to\nreal-time feedback while maintaining product quality. Recently, generative\nmachine learning (ML) has emerged as a powerful tool for modeling complex\ndistributions and generating synthetic data while handling these manufacturing\nuncertainties. However, adopting these generative technologies in dynamic\nmanufacturing systems lacks a functional control-oriented perspective to\ntranslate their probabilistic understanding into actionable process controls\nwhile respecting constraints. This review presents a functional classification\nof Prediction-Based, Direct Policy, Quality Inference, and Knowledge-Integrated\napproaches, offering a perspective for understanding existing ML-enhanced\ncontrol systems and incorporating generative ML. The analysis of generative ML\narchitectures within this framework demonstrates control-relevant properties\nand potential to extend current ML-enhanced approaches where conventional\nmethods prove insufficient. We show generative ML's potential for manufacturing\ncontrol through decision-making applications, process guidance, simulation, and\ndigital twins, while identifying critical research gaps: separation between\ngeneration and control functions, insufficient physical understanding of\nmanufacturing phenomena, and challenges adapting models from other domains. To\naddress these challenges, we propose future research directions aimed at\ndeveloping integrated frameworks that combine generative ML and control\ntechnologies to address the dynamic complexities of modern manufacturing\nsystems."}
{"id": "2505.00643", "pdf": "https://arxiv.org/pdf/2505.00643", "abs": "https://arxiv.org/abs/2505.00643", "authors": ["Merve Gülle", "Sebastian Weingärtner", "Mehmet Akçakaya"], "title": "Deep Learning Assisted Outer Volume Removal for Highly-Accelerated Real-Time Dynamic MRI", "categories": ["eess.IV", "cs.AI", "cs.CV", "physics.med-ph"], "comment": null, "summary": "Real-time (RT) dynamic MRI plays a vital role in capturing rapid\nphysiological processes, offering unique insights into organ motion and\nfunction. Among these applications, RT cine MRI is particularly important for\nfunctional assessment of the heart with high temporal resolution. RT imaging\nenables free-breathing, ungated imaging of cardiac motion, making it a crucial\nalternative for patients who cannot tolerate conventional breath-hold,\nECG-gated acquisitions. However, achieving high acceleration rates in RT cine\nMRI is challenging due to aliasing artifacts from extra-cardiac tissues,\nparticularly at high undersampling factors. In this study, we propose a novel\nouter volume removal (OVR) method to address this challenge by eliminating\naliasing contributions from non-cardiac regions in a post-processing framework.\nOur approach estimates the outer volume signal for each timeframe using\ncomposite temporal images from time-interleaved undersampling patterns, which\ninherently contain pseudo-periodic ghosting artifacts. A deep learning (DL)\nmodel is trained to identify and remove these artifacts, producing a clean\nouter volume estimate that is subsequently subtracted from the corresponding\nk-space data. The final reconstruction is performed with a physics-driven DL\n(PD-DL) method trained using an OVR-specific loss function to restore high\nspatio-temporal resolution images. Experimental results show that the proposed\nmethod at high accelerations achieves image quality that is visually comparable\nto clinical baseline images, while outperforming conventional reconstruction\ntechniques, both qualitatively and quantitatively. The proposed approach\nprovides a practical and effective solution for artifact reduction in RT cine\nMRI without requiring acquisition modifications, offering a pathway to higher\nacceleration rates while preserving diagnostic quality."}
{"id": "2505.00017", "pdf": "https://arxiv.org/pdf/2505.00017", "abs": "https://arxiv.org/abs/2505.00017", "authors": ["Dezheng Han", "Yibin Jia", "Ruxiao Chen", "Wenjie Han", "Shuaishuai Guo", "Jianbo Wang"], "title": "ReCellTy: Domain-specific knowledge graph retrieval-augmented LLMs workflow for single-cell annotation", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.LG"], "comment": null, "summary": "To enable precise and fully automated cell type annotation with large\nlanguage models (LLMs), we developed a graph structured feature marker database\nto retrieve entities linked to differential genes for cell reconstruction. We\nfurther designed a multi task workflow to optimize the annotation process.\nCompared to general purpose LLMs, our method improves human evaluation scores\nby up to 0.21 and semantic similarity by 6.1% across 11 tissue types, while\nmore closely aligning with the cognitive logic of manual annotation."}
{"id": "2505.00612", "pdf": "https://arxiv.org/pdf/2505.00612", "abs": "https://arxiv.org/abs/2505.00612", "authors": ["D. Sculley", "Will Cukierski", "Phil Culliton", "Sohier Dane", "Maggie Demkin", "Ryan Holbrook", "Addison Howard", "Paul Mooney", "Walter Reade", "Megan Risdal", "Nate Keating"], "title": "Position: AI Competitions Provide the Gold Standard for Empirical Rigor in GenAI Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "In this position paper, we observe that empirical evaluation in Generative AI\nis at a crisis point since traditional ML evaluation and benchmarking\nstrategies are insufficient to meet the needs of evaluating modern GenAI models\nand systems. There are many reasons for this, including the fact that these\nmodels typically have nearly unbounded input and output spaces, typically do\nnot have a well defined ground truth target, and typically exhibit strong\nfeedback loops and prediction dependence based on context of previous model\noutputs. On top of these critical issues, we argue that the problems of {\\em\nleakage} and {\\em contamination} are in fact the most important and difficult\nissues to address for GenAI evaluations. Interestingly, the field of AI\nCompetitions has developed effective measures and practices to combat leakage\nfor the purpose of counteracting cheating by bad actors within a competition\nsetting. This makes AI Competitions an especially valuable (but underutilized)\nresource. Now is time for the field to view AI Competitions as the gold\nstandard for empirical rigor in GenAI evaluation, and to harness and harvest\ntheir results with according value."}
{"id": "2505.00275", "pdf": "https://arxiv.org/pdf/2505.00275", "abs": "https://arxiv.org/abs/2505.00275", "authors": ["Md Asaduzzaman Jabin", "Hanqi Jiang", "Yiwei Li", "Patrick Kaggwa", "Eugene Douglass", "Juliet N. Sekandi", "Tianming Liu"], "title": "AdCare-VLM: Leveraging Large Vision Language Model (LVLM) to Monitor Long-Term Medication Adherence and Care", "categories": ["cs.CV"], "comment": null, "summary": "Chronic diseases, including diabetes, hypertension, asthma, HIV-AIDS,\nepilepsy, and tuberculosis, necessitate rigorous adherence to medication to\navert disease progression, manage symptoms, and decrease mortality rates.\nAdherence is frequently undermined by factors including patient behavior,\ncaregiver support, elevated medical costs, and insufficient healthcare\ninfrastructure. We propose AdCare-VLM, a specialized Video-LLaVA-based\nmultimodal large vision language model (LVLM) aimed at visual question\nanswering (VQA) concerning medication adherence through patient videos. We\nemploy a private dataset comprising 806 custom-annotated tuberculosis (TB)\nmedication monitoring videos, which have been labeled by clinical experts, to\nfine-tune the model for adherence pattern detection. We present LLM-TB-VQA, a\ndetailed medical adherence VQA dataset that encompasses positive, negative, and\nambiguous adherence cases. Our method identifies correlations between visual\nfeatures, such as the clear visibility of the patient's face, medication, water\nintake, and the act of ingestion, and their associated medical concepts in\ncaptions. This facilitates the integration of aligned visual-linguistic\nrepresentations and improves multimodal interactions. Experimental results\nindicate that our method surpasses parameter-efficient fine-tuning (PEFT)\nenabled VLM models, such as LLaVA-V1.5 and Chat-UniVi, with absolute\nimprovements ranging from 3.1% to 3.54% across pre-trained, regular, and\nlow-rank adaptation (LoRA) configurations. Comprehensive ablation studies and\nattention map visualizations substantiate our approach, enhancing\ninterpretability."}
{"id": "2505.00216", "pdf": "https://arxiv.org/pdf/2505.00216", "abs": "https://arxiv.org/abs/2505.00216", "authors": ["Xuwei Yang", "Fatemeh Tavakoli", "David B. Emerson", "Anastasis Kratsios"], "title": "Online Federation For Mixtures of Proprietary Agents with Black-Box Encoders", "categories": ["cs.LG", "cs.AI", "cs.GT", "68T05, 68T07, 91A80", "I.2.1; I.2.11; G.1.6"], "comment": "47 pages, 16 figures, 7 tables", "summary": "Most industry-standard generative AIs and feature encoders are proprietary,\noffering only black-box access: their outputs are observable, but their\ninternal parameters and architectures remain hidden from the end-user. This\nblack-box access is especially limiting when constructing mixture-of-expert\ntype ensemble models since the user cannot optimize each proprietary AI's\ninternal parameters. Our problem naturally lends itself to a non-competitive\ngame-theoretic lens where each proprietary AI (agent) is inherently competing\nagainst the other AI agents, with this competition arising naturally due to\ntheir obliviousness of the AI's to their internal structure. In contrast, the\nuser acts as a central planner trying to synchronize the ensemble of competing\nAIs.\n  We show the existence of the unique Nash equilibrium in the online setting,\nwhich we even compute in closed-form by eliciting a feedback mechanism between\nany given time series and the sequence generated by each (proprietary) AI\nagent. Our solution is implemented as a decentralized, federated-learning\nalgorithm in which each agent optimizes their structure locally on their\nmachine without ever releasing any internal structure to the others. We obtain\nrefined expressions for pre-trained models such as transformers, random feature\nmodels, and echo-state networks. Our ``proprietary federated learning''\nalgorithm is implemented on a range of real-world and synthetic time-series\nbenchmarks. It achieves orders-of-magnitude improvements in predictive accuracy\nover natural benchmarks, of which there are surprisingly few due to this\nnatural problem still being largely unexplored."}
{"id": "2505.00687", "pdf": "https://arxiv.org/pdf/2505.00687", "abs": "https://arxiv.org/abs/2505.00687", "authors": ["Aditya Arora", "Zhengzhong Tu", "Yufei Wang", "Ruizheng Bai", "Jian Wang", "Sizhuo Ma"], "title": "GuideSR: Rethinking Guidance for One-Step High-Fidelity Diffusion-Based Super-Resolution", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "In this paper, we propose GuideSR, a novel single-step diffusion-based image\nsuper-resolution (SR) model specifically designed to enhance image fidelity.\nExisting diffusion-based SR approaches typically adapt pre-trained generative\nmodels to image restoration tasks by adding extra conditioning on a\nVAE-downsampled representation of the degraded input, which often compromises\nstructural fidelity. GuideSR addresses this limitation by introducing a\ndual-branch architecture comprising: (1) a Guidance Branch that preserves\nhigh-fidelity structures from the original-resolution degraded input, and (2) a\nDiffusion Branch, which a pre-trained latent diffusion model to enhance\nperceptual quality. Unlike conventional conditioning mechanisms, our Guidance\nBranch features a tailored structure for image restoration tasks, combining\nFull Resolution Blocks (FRBs) with channel attention and an Image Guidance\nNetwork (IGN) with guided attention. By embedding detailed structural\ninformation directly into the restoration pipeline, GuideSR produces sharper\nand more visually consistent results. Extensive experiments on benchmark\ndatasets demonstrate that GuideSR achieves state-of-the-art performance while\nmaintaining the low computational cost of single-step approaches, with up to\n1.39dB PSNR gain on challenging real-world datasets. Our approach consistently\noutperforms existing methods across various reference-based metrics including\nPSNR, SSIM, LPIPS, DISTS and FID, further representing a practical advancement\nfor real-world image restoration."}
{"id": "2505.00019", "pdf": "https://arxiv.org/pdf/2505.00019", "abs": "https://arxiv.org/abs/2505.00019", "authors": ["Zheng Zhang", "Jinyi Li", "Yihuai Lan", "Xiang Wang", "Hao Wang"], "title": "An Empirical Study on Prompt Compression for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by Building Trust Workshop at ICLR 2025", "summary": "Prompt engineering enables Large Language Models (LLMs) to perform a variety\nof tasks. However, lengthy prompts significantly increase computational\ncomplexity and economic costs. To address this issue, we study six prompt\ncompression methods for LLMs, aiming to reduce prompt length while maintaining\nLLM response quality. In this paper, we present a comprehensive analysis\ncovering aspects such as generation performance, model hallucinations, efficacy\nin multimodal tasks, word omission analysis, and more. We evaluate these\nmethods across 13 datasets, including news, scientific articles, commonsense\nQA, math QA, long-context QA, and VQA datasets. Our experiments reveal that\nprompt compression has a greater impact on LLM performance in long contexts\ncompared to short ones. In the Longbench evaluation, moderate compression even\nenhances LLM performance. Our code and data is available at\nhttps://github.com/3DAgentWorld/Toolkit-for-Prompt-Compression."}
{"id": "2505.00651", "pdf": "https://arxiv.org/pdf/2505.00651", "abs": "https://arxiv.org/abs/2505.00651", "authors": ["Yazan Otoum", "Arghavan Asad", "Ishtiaq Ahmad"], "title": "Open-Source LLM-Driven Federated Transformer for Predictive IoV Management", "categories": ["cs.AI", "cs.ET", "cs.LG"], "comment": "Preprint version; submitted for academic peer review", "summary": "The proliferation of connected vehicles within the Internet of Vehicles (IoV)\necosystem presents critical challenges in ensuring scalable, real-time, and\nprivacy-preserving traffic management. Existing centralized IoV solutions often\nsuffer from high latency, limited scalability, and reliance on proprietary\nArtificial Intelligence (AI) models, creating significant barriers to\nwidespread deployment, particularly in dynamic and privacy-sensitive\nenvironments. Meanwhile, integrating Large Language Models (LLMs) in vehicular\nsystems remains underexplored, especially concerning prompt optimization and\neffective utilization in federated contexts. To address these challenges, we\npropose the Federated Prompt-Optimized Traffic Transformer (FPoTT), a novel\nframework that leverages open-source LLMs for predictive IoV management. FPoTT\nintroduces a dynamic prompt optimization mechanism that iteratively refines\ntextual prompts to enhance trajectory prediction. The architecture employs a\ndual-layer federated learning paradigm, combining lightweight edge models for\nreal-time inference with cloud-based LLMs to retain global intelligence. A\nTransformer-driven synthetic data generator is incorporated to augment training\nwith diverse, high-fidelity traffic scenarios in the Next Generation Simulation\n(NGSIM) format. Extensive evaluations demonstrate that FPoTT, utilizing\nEleutherAI Pythia-1B, achieves 99.86% prediction accuracy on real-world data\nwhile maintaining high performance on synthetic datasets. These results\nunderscore the potential of open-source LLMs in enabling secure, adaptive, and\nscalable IoV management, offering a promising alternative to proprietary\nsolutions in smart mobility ecosystems."}
{"id": "2505.00295", "pdf": "https://arxiv.org/pdf/2505.00295", "abs": "https://arxiv.org/abs/2505.00295", "authors": ["Xinlong Zhao", "Shan Du"], "title": "Fine-grained spatial-temporal perception for gas leak segmentation", "categories": ["cs.CV", "cs.AI", "68T45 (Primary), 68T07 (Secondary)", "I.2.10; I.4.6"], "comment": "6 pages, 4 figures, ICIP 2025 Conference", "summary": "Gas leaks pose significant risks to human health and the environment. Despite\nlong-standing concerns, there are limited methods that can efficiently and\naccurately detect and segment leaks due to their concealed appearance and\nrandom shapes. In this paper, we propose a Fine-grained Spatial-Temporal\nPerception (FGSTP) algorithm for gas leak segmentation. FGSTP captures critical\nmotion clues across frames and integrates them with refined object features in\nan end-to-end network. Specifically, we first construct a correlation volume to\ncapture motion information between consecutive frames. Then, the fine-grained\nperception progressively refines the object-level features using previous\noutputs. Finally, a decoder is employed to optimize boundary segmentation.\nBecause there is no highly precise labeled dataset for gas leak segmentation,\nwe manually label a gas leak video dataset, GasVid. Experimental results on\nGasVid demonstrate that our model excels in segmenting non-rigid objects such\nas gas leaks, generating the most accurate mask compared to other\nstate-of-the-art (SOTA) models."}
{"id": "2505.00225", "pdf": "https://arxiv.org/pdf/2505.00225", "abs": "https://arxiv.org/abs/2505.00225", "authors": ["Bogireddy Sai Prasanna Teja", "Valliappan Muthukaruppan", "Carls Benjamin"], "title": "Predicting Estimated Times of Restoration for Electrical Outages Using Longitudinal Tabular Transformers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As climate variability increases, the ability of utility providers to deliver\nprecise Estimated Times of Restoration (ETR) during natural disasters has\nbecome increasingly critical. Accurate and timely ETRs are essential for\nenabling customer preparedness during extended power outages, where informed\ndecision-making can be crucial, particularly in severe weather conditions.\nNonetheless, prevailing utility practices predominantly depend on manual\nassessments or traditional statistical methods, which often fail to achieve the\nlevel of precision required for reliable and actionable predictions. To address\nthese limitations, we propose a Longitudinal Tabular Transformer (LTT) model\nthat leverages historical outage event data along with sequential updates of\nthese events to improve the accuracy of ETR predictions. The model's\nperformance was evaluated over 34,000 storm-related outage events from three\nmajor utility companies, collectively serving over 3 million customers over a\n2-year period. Results demonstrate that the LTT model improves the Customer\nSatisfaction Impact (CSI) metric by an average of 19.08% (p > 0.001) compared\nto existing methods. Additionally, we introduce customer-informed regression\nmetrics that align model evaluation with real-world satisfaction, ensuring the\noutcomes resonate with customer expectations. Furthermore, we employ\ninterpretability techniques to analyze the temporal significance of\nincorporating sequential updates in modeling outage events and to identify the\ncontributions of predictive features to a given ETR. This comprehensive\napproach not only improves predictive accuracy but also enhances transparency,\nfostering greater trust in the model's capabilities."}
{"id": "2505.00265", "pdf": "https://arxiv.org/pdf/2505.00265", "abs": "https://arxiv.org/abs/2505.00265", "authors": ["Yi Yu", "Patrick Filippi", "Thomas F. A. Bishop"], "title": "Field-scale soil moisture estimated from Sentinel-1 SAR data using a knowledge-guided deep learning approach", "categories": ["cs.LG", "eess.IV"], "comment": "Accepted by the 2025 IEEE International Geoscience and Remote Sensing\n  Symposium (IGARSS 2025)", "summary": "Soil moisture (SM) estimation from active microwave data remains challenging\ndue to the complex interactions between radar backscatter and surface\ncharacteristics. While the water cloud model (WCM) provides a semi-physical\napproach for understanding these interactions, its empirical component often\nlimits performance across diverse agricultural landscapes. This research\npresents preliminary efforts for developing a knowledge-guided deep learning\napproach, which integrates WCM principles into a long short-term memory (LSTM)\nmodel, to estimate field SM using Sentinel-1 Synthetic Aperture Radar (SAR)\ndata. Our proposed approach leverages LSTM's capacity to capture spatiotemporal\ndependencies while maintaining physical consistency through a modified\ndual-component loss function, including a WCM-based semi-physical component and\na boundary condition regularisation. The proposed approach is built upon the\nsoil backscatter coefficients isolated from the total backscatter, together\nwith Landsat-resolution vegetation information and surface characteristics. A\nfour-fold spatial cross-validation was performed against in-situ SM data to\nassess the model performance. Results showed the proposed approach reduced SM\nretrieval uncertainties by 0.02 m$^3$/m$^3$ and achieved correlation\ncoefficients (R) of up to 0.64 in areas with varying vegetation cover and\nsurface conditions, demonstrating the potential to address the\nover-simplification in WCM."}
{"id": "2505.00020", "pdf": "https://arxiv.org/pdf/2505.00020", "abs": "https://arxiv.org/abs/2505.00020", "authors": ["Sruly Rosenblat", "Tim O'Reilly", "Ilan Strauss"], "title": "Beyond Public Access in LLM Pre-Training Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Using a legally obtained dataset of 34 copyrighted O'Reilly Media books, we\napply the DE-COP membership inference attack method to investigate whether\nOpenAI's large language models were trained on copyrighted content without\nconsent. Our AUROC scores show that GPT-4o, OpenAI's more recent and capable\nmodel, demonstrates strong recognition of paywalled O'Reilly book content\n(AUROC = 82\\%), compared to OpenAI's earlier model GPT-3.5 Turbo. In contrast,\nGPT-3.5 Turbo shows greater relative recognition of publicly accessible\nO'Reilly book samples. GPT-4o Mini, as a much smaller model, shows no knowledge\nof public or non-public O'Reilly Media content when tested (AUROC $\\approx$\n50\\%). Testing multiple models, with the same cutoff date, helps us account for\npotential language shifts over time that might bias our findings. These results\nhighlight the urgent need for increased corporate transparency regarding\npre-training data sources as a means to develop formal licensing frameworks for\nAI content training"}
{"id": "2505.00308", "pdf": "https://arxiv.org/pdf/2505.00308", "abs": "https://arxiv.org/abs/2505.00308", "authors": ["Biling Wang", "Austen Maniscalco", "Ti Bai", "Siqiu Wang", "Michael Dohopolski", "Mu-Han Lin", "Chenyang Shen", "Dan Nguyen", "Junzhou Huang", "Steve Jiang", "Xinlei Wang"], "title": "AI-Assisted Decision-Making for Clinical Assessment of Auto-Segmented Contour Quality", "categories": ["cs.CV", "cs.AI", "stat.AP"], "comment": null, "summary": "Purpose: This study presents a Deep Learning (DL)-based quality assessment\n(QA) approach for evaluating auto-generated contours (auto-contours) in\nradiotherapy, with emphasis on Online Adaptive Radiotherapy (OART). Leveraging\nBayesian Ordinal Classification (BOC) and calibrated uncertainty thresholds,\nthe method enables confident QA predictions without relying on ground truth\ncontours or extensive manual labeling. Methods: We developed a BOC model to\nclassify auto-contour quality and quantify prediction uncertainty. A\ncalibration step was used to optimize uncertainty thresholds that meet clinical\naccuracy needs. The method was validated under three data scenarios: no manual\nlabels, limited labels, and extensive labels. For rectum contours in prostate\ncancer, we applied geometric surrogate labels when manual labels were absent,\ntransfer learning when limited, and direct supervision when ample labels were\navailable. Results: The BOC model delivered robust performance across all\nscenarios. Fine-tuning with just 30 manual labels and calibrating with 34\nsubjects yielded over 90% accuracy on test data. Using the calibrated\nthreshold, over 93% of the auto-contours' qualities were accurately predicted\nin over 98% of cases, reducing unnecessary manual reviews and highlighting\ncases needing correction. Conclusion: The proposed QA model enhances contouring\nefficiency in OART by reducing manual workload and enabling fast, informed\nclinical decisions. Through uncertainty quantification, it ensures safer, more\nreliable radiotherapy workflows."}
{"id": "2505.00232", "pdf": "https://arxiv.org/pdf/2505.00232", "abs": "https://arxiv.org/abs/2505.00232", "authors": ["Jiuqiang Tang", "Raman Sarokin", "Ekaterina Ignasheva", "Grant Jensen", "Lin Chen", "Juhyun Lee", "Andrei Kulik", "Matthias Grundmann"], "title": "Scaling On-Device GPU Inference for Large Generative Models", "categories": ["cs.LG", "cs.AI"], "comment": "to be published in CVPR 2025 Workshop on Efficient and On-Device\n  Generation (EDGE)", "summary": "Driven by the advancements in generative AI, large machine learning models\nhave revolutionized domains such as image processing, audio synthesis, and\nspeech recognition. While server-based deployments remain the locus of peak\nperformance, the imperative for on-device inference, necessitated by privacy\nand efficiency considerations, persists. Recognizing GPUs as the on-device ML\naccelerator with the widest reach, we present ML Drift--an optimized framework\nthat extends the capabilities of state-of-the-art GPU-accelerated inference\nengines. ML Drift enables on-device execution of generative AI workloads which\ncontain 10 to 100x more parameters than existing on-device generative AI\nmodels. ML Drift addresses intricate engineering challenges associated with\ncross-GPU API development, and ensures broad compatibility across mobile and\ndesktop/laptop platforms, thereby facilitating the deployment of significantly\nmore complex models on resource-constrained devices. Our GPU-accelerated ML/AI\ninference engine achieves an order-of-magnitude performance improvement\nrelative to existing open-source GPU inference engines."}
{"id": "2505.00326", "pdf": "https://arxiv.org/pdf/2505.00326", "abs": "https://arxiv.org/abs/2505.00326", "authors": ["Apratim Dey", "David Donoho"], "title": "Optimal Vector Compressed Sensing Using James Stein Shrinkage", "categories": ["cs.LG", "eess.IV", "eess.SP", "stat.CO", "stat.ME"], "comment": "69 pages", "summary": "The trend in modern science and technology is to take vector measurements\nrather than scalars, ruthlessly scaling to ever higher dimensional vectors. For\nabout two decades now, traditional scalar Compressed Sensing has been\nsynonymous with a Convex Optimization based procedure called Basis Pursuit. In\nthe vector recovery case, the natural tendency is to return to a\nstraightforward vector extension of Basis Pursuit, also based on Convex\nOptimization. However, Convex Optimization is provably suboptimal, particularly\nwhen $B$ is large. In this paper, we propose SteinSense, a lightweight\niterative algorithm, which is provably optimal when $B$ is large. It does not\nhave any tuning parameter, does not need any training data, requires zero\nknowledge of sparsity, is embarrassingly simple to implement, and all of this\nmakes it easily scalable to high vector dimensions. We conduct a massive volume\nof both real and synthetic experiments that confirm the efficacy of SteinSense,\nand also provide theoretical justification based on ideas from Approximate\nMessage Passing. Fascinatingly, we discover that SteinSense is quite robust,\ndelivering the same quality of performance on real data, and even under\nsubstantial departures from conditions under which existing theory holds."}
{"id": "2505.00021", "pdf": "https://arxiv.org/pdf/2505.00021", "abs": "https://arxiv.org/abs/2505.00021", "authors": ["Zhuoang Cai", "Zhenghao Li", "Yang Liu", "Liyuan Guo", "Yangqiu Song"], "title": "Ustnlp16 at SemEval-2025 Task 9: Improving Model Performance through Imbalance Handling and Focal Loss", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Classification tasks often suffer from imbal- anced data distribution, which\npresents chal- lenges in food hazard detection due to severe class imbalances,\nshort and unstructured text, and overlapping semantic categories. In this\npaper, we present our system for SemEval- 2025 Task 9: Food Hazard Detection,\nwhich ad- dresses these issues by applying data augmenta- tion techniques to\nimprove classification perfor- mance. We utilize transformer-based models, BERT\nand RoBERTa, as backbone classifiers and explore various data balancing\nstrategies, including random oversampling, Easy Data Augmentation (EDA), and\nfocal loss. Our ex- periments show that EDA effectively mitigates class\nimbalance, leading to significant improve- ments in accuracy and F1 scores.\nFurthermore, combining focal loss with oversampling and EDA further enhances\nmodel robustness, par- ticularly for hard-to-classify examples. These findings\ncontribute to the development of more effective NLP-based classification models\nfor food hazard detection."}
{"id": "2505.00022", "pdf": "https://arxiv.org/pdf/2505.00022", "abs": "https://arxiv.org/abs/2505.00022", "authors": ["Thomas F Burns", "Letitia Parcalabescu", "Stephan Wäldchen", "Michael Barlow", "Gregor Ziegltrum", "Volker Stampa", "Bastian Harren", "Björn Deiseroth"], "title": "Aleph-Alpha-GermanWeb: Improving German-language LLM pre-training with model-based data curation and synthetic data generation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "10 pages, 3 figures", "summary": "Scaling data quantity is essential for large language models (LLMs), yet\nrecent findings show that data quality can significantly boost performance and\ntraining efficiency. We introduce a German-language dataset curation pipeline\nthat combines heuristic and model-based filtering techniques with synthetic\ndata generation. We use our pipeline to create Aleph-Alpha-GermanWeb, a\nlarge-scale German pre-training dataset which draws from: (1) Common Crawl web\ndata, (2) FineWeb2, and (3) synthetically-generated data conditioned on actual,\norganic web data. We evaluate our dataset by pre-training both a 1B Llama-style\nmodel and an 8B tokenizer-free hierarchical autoregressive transformer (HAT). A\ncomparison on German-language benchmarks, including MMMLU, shows significant\nperformance gains of Aleph-Alpha-GermanWeb over FineWeb2 alone. This advantage\nholds at the 8B scale even when FineWeb2 is enriched by human-curated\nhigh-quality data sources such as Wikipedia. Our findings support the growing\nbody of evidence that model-based data curation and synthetic data generation\ncan significantly enhance LLM pre-training datasets."}
{"id": "2505.00312", "pdf": "https://arxiv.org/pdf/2505.00312", "abs": "https://arxiv.org/abs/2505.00312", "authors": ["Muhammad Salman", "Iqra Tariq", "Mishal Zulfiqar", "Muqadas Jalal", "Sami Aujla", "Sumbal Fatima"], "title": "AWARE-NET: Adaptive Weighted Averaging for Robust Ensemble Network in Deepfake Detection", "categories": ["cs.CV"], "comment": null, "summary": "Deepfake detection has become increasingly important due to the rise of\nsynthetic media, which poses significant risks to digital identity and cyber\npresence for security and trust. While multiple approaches have improved\ndetection accuracy, challenges remain in achieving consistent performance\nacross diverse datasets and manipulation types. In response, we propose a novel\ntwo-tier ensemble framework for deepfake detection based on deep learning that\nhierarchically combines multiple instances of three state-of-the-art\narchitectures: Xception, Res2Net101, and EfficientNet-B7. Our framework employs\na unique approach where each architecture is instantiated three times with\ndifferent initializations to enhance model diversity, followed by a learnable\nweighting mechanism that dynamically combines their predictions. Unlike\ntraditional fixed-weight ensembles, our first-tier averages predictions within\neach architecture family to reduce model variance, while the second tier learns\noptimal contribution weights through backpropagation, automatically adjusting\neach architecture's influence based on their detection reliability. Our\nexperiments achieved state-of-the-art intra-dataset performance with AUC scores\nof 99.22% (FF++) and 100.00% (CelebDF-v2), and F1 scores of 98.06% (FF++) and\n99.94% (CelebDF-v2) without augmentation. With augmentation, we achieve AUC\nscores of 99.47% (FF++) and 100.00% (CelebDF-v2), and F1 scores of 98.43%\n(FF++) and 99.95% (CelebDF-v2). The framework demonstrates robust cross-dataset\ngeneralization, achieving AUC scores of 88.20% and 72.52%, and F1 scores of\n93.16% and 80.62% in cross-dataset evaluations."}
{"id": "2505.00234", "pdf": "https://arxiv.org/pdf/2505.00234", "abs": "https://arxiv.org/abs/2505.00234", "authors": ["Vishnu Sarukkai", "Zhiqiang Xie", "Kayvon Fatahalian"], "title": "Self-Generated In-Context Examples Improve LLM Agents for Sequential Decision-Making Tasks", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Many methods for improving Large Language Model (LLM) agents for sequential\ndecision-making tasks depend on task-specific knowledge engineering--such as\nprompt tuning, curated in-context examples, or customized observation and\naction spaces. Using these approaches, agent performance improves with the\nquality or amount of knowledge engineering invested. Instead, we investigate\nhow LLM agents can automatically improve their performance by learning\nin-context from their own successful experiences on similar tasks. Rather than\nrelying on task-specific knowledge engineering, we focus on constructing and\nrefining a database of self-generated examples. We demonstrate that even a\nnaive accumulation of successful trajectories across training tasks boosts test\nperformance on three benchmarks: ALFWorld (73% to 89%), Wordcraft (55% to 64%),\nand InterCode-SQL (75% to 79%)--matching the performance the initial agent\nachieves if allowed two to three attempts per task. We then introduce two\nextensions: (1) database-level selection through population-based training to\nidentify high-performing example collections, and (2) exemplar-level selection\nthat retains individual trajectories based on their empirical utility as\nin-context examples. These extensions further enhance performance, achieving\n91% on ALFWorld--matching more complex approaches that employ task-specific\ncomponents and prompts. Our results demonstrate that automatic trajectory\ndatabase construction offers a compelling alternative to labor-intensive\nknowledge engineering."}
{"id": "2505.00584", "pdf": "https://arxiv.org/pdf/2505.00584", "abs": "https://arxiv.org/abs/2505.00584", "authors": ["Mathis Morales", "Golnaz Habibi"], "title": "Synthesizing and Identifying Noise Levels in Autonomous Vehicle Camera Radar Datasets", "categories": ["cs.CV", "cs.AI", "eess.IV", "eess.SP"], "comment": null, "summary": "Detecting and tracking objects is a crucial component of any autonomous\nnavigation method. For the past decades, object detection has yielded promising\nresults using neural networks on various datasets. While many methods focus on\nperformance metrics, few projects focus on improving the robustness of these\ndetection and tracking pipelines, notably to sensor failures. In this paper we\nattempt to address this issue by creating a realistic synthetic data\naugmentation pipeline for camera-radar Autonomous Vehicle (AV) datasets. Our\ngoal is to accurately simulate sensor failures and data deterioration due to\nreal-world interferences. We also present our results of a baseline lightweight\nNoise Recognition neural network trained and tested on our augmented dataset,\nreaching an overall recognition accuracy of 54.4\\% on 11 categories across\n10086 images and 2145 radar point-clouds."}
{"id": "2505.00023", "pdf": "https://arxiv.org/pdf/2505.00023", "abs": "https://arxiv.org/abs/2505.00023", "authors": ["Hyunji Lee", "Franck Dernoncourt", "Trung Bui", "Seunghyun Yoon"], "title": "CORG: Generating Answers from Complex, Interrelated Contexts", "categories": ["cs.CL", "cs.AI"], "comment": "published at Findings of NAACL 2025", "summary": "In a real-world corpus, knowledge frequently recurs across documents but\noften contains inconsistencies due to ambiguous naming, outdated information,\nor errors, leading to complex interrelationships between contexts. Previous\nresearch has shown that language models struggle with these complexities,\ntypically focusing on single factors in isolation. We classify these\nrelationships into four types: distracting, ambiguous, counterfactual, and\nduplicated. Our analysis reveals that no single approach effectively addresses\nall these interrelationships simultaneously. Therefore, we introduce Context\nOrganizer (CORG), a framework that organizes multiple contexts into\nindependently processed groups. This design allows the model to efficiently\nfind all relevant answers while ensuring disambiguation. CORG consists of three\nkey components: a graph constructor, a reranker, and an aggregator. Our results\ndemonstrate that CORG balances performance and efficiency effectively,\noutperforming existing grouping methods and achieving comparable results to\nmore computationally intensive, single-context approaches."}
{"id": "2505.00024", "pdf": "https://arxiv.org/pdf/2505.00024", "abs": "https://arxiv.org/abs/2505.00024", "authors": ["Shaokun Zhang", "Yi Dong", "Jieyu Zhang", "Jan Kautz", "Bryan Catanzaro", "Andrew Tao", "Qingyun Wu", "Zhiding Yu", "Guilin Liu"], "title": "Nemotron-Research-Tool-N1: Tool-Using Language Models with Reinforced Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": "13 pages, 4 tables, 5 figures", "summary": "Enabling large language models with external tools has become a pivotal\nstrategy for extending their functionality beyond text generation tasks. Prior\nwork typically enhances tool-use abilities by either applying supervised\nfine-tuning (SFT) to enforce tool-call correctness or distilling reasoning\ntraces from stronger models for SFT. However, both approaches fall short,\neither omitting reasoning entirely or producing imitative reasoning that limits\ngeneralization. Inspired by the success of DeepSeek-R1 in eliciting reasoning\nthrough rule-based reinforcement learning, we develop the\nNemotron-Research-Tool-N1 series of tool-using language models using a similar\ntraining paradigm. Instead of restrictively supervising intermediate reasoning\ntraces distilled from stronger models, Nemotron-Research-Tool-N1 is optimized\nwith a binary reward that evaluates only the structural validity and functional\ncorrectness of tool invocations. This lightweight supervision allows the model\nto autonomously internalize reasoning strategies, without the need for\nannotated reasoning trajectories. Experiments on the BFCL and API-Bank\nbenchmarks show that Nemotron-Research-Tool-N1-7B and\nNemotron-Research-Tool-N1-14B, built on Qwen-2.5-7B/14B-Instruct, achieve\nstate-of-the-art results, outperforming GPT-4o on both evaluations."}
{"id": "2505.00334", "pdf": "https://arxiv.org/pdf/2505.00334", "abs": "https://arxiv.org/abs/2505.00334", "authors": ["Luigi Sigillo", "Christian Bianchi", "Danilo Comminiello"], "title": "Quaternion Wavelet-Conditioned Diffusion Models for Image Super-Resolution", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted for presentation at IJCNN 2025", "summary": "Image Super-Resolution is a fundamental problem in computer vision with broad\napplications spacing from medical imaging to satellite analysis. The ability to\nreconstruct high-resolution images from low-resolution inputs is crucial for\nenhancing downstream tasks such as object detection and segmentation. While\ndeep learning has significantly advanced SR, achieving high-quality\nreconstructions with fine-grained details and realistic textures remains\nchallenging, particularly at high upscaling factors. Recent approaches\nleveraging diffusion models have demonstrated promising results, yet they often\nstruggle to balance perceptual quality with structural fidelity. In this work,\nwe introduce ResQu a novel SR framework that integrates a quaternion wavelet\npreprocessing framework with latent diffusion models, incorporating a new\nquaternion wavelet- and time-aware encoder. Unlike prior methods that simply\napply wavelet transforms within diffusion models, our approach enhances the\nconditioning process by exploiting quaternion wavelet embeddings, which are\ndynamically integrated at different stages of denoising. Furthermore, we also\nleverage the generative priors of foundation models such as Stable Diffusion.\nExtensive experiments on domain-specific datasets demonstrate that our method\nachieves outstanding SR results, outperforming in many cases existing\napproaches in perceptual quality and standard evaluation metrics. The code will\nbe available after the revision process."}
{"id": "2505.00236", "pdf": "https://arxiv.org/pdf/2505.00236", "abs": "https://arxiv.org/abs/2505.00236", "authors": ["Leifeng Zhang", "Xin Dong", "Shuaibing Jia", "Jianhua Zhang"], "title": "Node2Vec-DGI-EL: A Hierarchical Graph Representation Learning Model for Ingredient-Disease Association Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Traditional Chinese medicine, as an essential component of traditional\nmedicine, contains active ingredients that serve as a crucial source for modern\ndrug development, holding immense therapeutic potential and development value.\nA multi-layered and complex network is formed from Chinese medicine to diseases\nand used to predict the potential associations between Chinese medicine\ningredients and diseases. This study proposes an ingredient-disease association\nprediction model (Node2Vec-DGI-EL) based on hierarchical graph representation\nlearning. First, the model uses the Node2Vec algorithm to extract node\nembedding vectors from the network as the initial features of the nodes. Next,\nthe network nodes are deeply represented and learned using the DGI algorithm to\nenhance the model's expressive power. To improve prediction accuracy and\nrobustness, an ensemble learning method is incorporated to achieve more\naccurate ingredient-disease association predictions. The effectiveness of the\nmodel is then evaluated through a series of theoretical verifications. The\nresults demonstrated that the proposed model significantly outperformed\nexisting methods, achieving an AUC of 0.9987 and an AUPR of 0.9545, thereby\nindicating superior predictive capability. Ablation experiments further\nrevealed the contribution and importance of each module. Additionally, case\nstudies explored potential associations, such as triptonide with hypertensive\nretinopathy and methyl ursolate with colorectal cancer. Molecular docking\nexperiments validated these findings, showing the triptonide-PGR interaction\nand the methyl ursolate-NFE2L2 interaction can bind stable. In conclusion, the\nNode2Vec-DGI-EL model focuses on TCM datasets and effectively predicts\ningredient-disease associations, overcoming the reliance on node semantic\ninformation."}
{"id": "2501.14066", "pdf": "https://arxiv.org/pdf/2501.14066", "abs": "https://arxiv.org/abs/2501.14066", "authors": ["Benjamin Hou", "Tejas Sudharshan Mathai", "Pritam Mukherjee", "Xinya Wang", "Ronald M. Summers", "Zhiyong Lu"], "title": "Segment-and-Classify: ROI-Guided Generalizable Contrast Phase Classification in CT Using XGBoost", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Purpose: To automate contrast phase classification in CT using organ-specific\nfeatures extracted from a widely used segmentation tool with a lightweight\ndecision tree classifier.\n  Materials and Methods: This retrospective study utilized three public CT\ndatasets from separate institutions. The phase prediction model was trained on\nthe WAW-TACE (median age: 66 [60,73]; 185 males) dataset, and externally\nvalidated on the VinDr-Multiphase (146 males; 63 females; 56 unk) and C4KC-KiTS\n(median age: 61 [50.68; 123 males) datasets. Contrast phase classification was\nperformed using organ-specific features extracted by TotalSegmentator, followed\nby prediction using a gradient-boosted decision tree classifier.\n  Results: On the VinDr-Multiphase dataset, the phase prediction model achieved\nthe highest or comparable AUCs across all phases (>0.937), with superior\nF1-scores in the non-contrast (0.994), arterial (0.937), and delayed (0.718)\nphases. Statistical testing indicated significant performance differences only\nin the arterial and delayed phases (p<0.05). On the C4KC-KiTS dataset, the\nphase prediction model achieved the highest AUCs across all phases (>0.991),\nwith superior F1-scores in arterial/venous (0.968) and delayed (0.935) phases.\nStatistical testing confirmed significant improvements over all baseline models\nin these two phases (p<0.05). Performance in the non-contrast class, however,\nwas comparable across all models, with no statistically significant differences\nobserved (p>0.05).\n  Conclusion: The lightweight model demonstrated strong performance relative to\nall baseline models, and exhibited robust generalizability across datasets from\ndifferent institutions."}
{"id": "2505.00025", "pdf": "https://arxiv.org/pdf/2505.00025", "abs": "https://arxiv.org/abs/2505.00025", "authors": ["Mingda Zhang", "Jianglong Qin"], "title": "A Method for the Architecture of a Medical Vertical Large Language Model Based on Deepseek R1", "categories": ["cs.CL", "cs.AI", "I.2.7; J.3"], "comment": "14 pages, 1 figures", "summary": "In recent years, despite foundation models like DeepSeek-R1 and ChatGPT\ndemonstrating significant capabilities in general tasks, professional knowledge\nbarriers, computational resource requirements, and deployment environment\nlimitations have severely hindered their application in actual medical\nscenarios. Addressing these challenges, this paper proposes an efficient\nlightweight medical vertical large language model architecture method,\nsystematically solving the lightweight problem of medical large models from\nthree dimensions: knowledge acquisition, model compression, and computational\noptimization. At the knowledge acquisition level, a knowledge transfer pipeline\nis designed from the fine-tuned DeepSeek-R1-Distill-70B teacher model to the\nDeepSeek-R1-Distill-7B student model, and Low-Rank Adaptation (LoRA) technology\nis adopted to precisely adjust key attention layers. At the model compression\nlevel, compression techniques including 4-bit weight quantization are\nimplemented while preserving the core representation ability for medical\nreasoning. At the computational optimization level, inference optimization\ntechniques such as Flash Attention acceleration and continuous batching are\nintegrated, and a professional prompt template system is constructed to adapt\nto different types of medical problems. Experimental results on medical\nquestion-answering datasets show that the method proposed in this paper\nmaintains professional accuracy while reducing memory consumption by 64.7\\% and\ninference latency by 12.4\\%, providing an effective solution for the\napplication of medical large models in resource-constrained environments such\nas edge computing devices."}
{"id": "2505.00026", "pdf": "https://arxiv.org/pdf/2505.00026", "abs": "https://arxiv.org/abs/2505.00026", "authors": ["Ruirui Chen", "Weifeng Jiang", "Chengwei Qin", "Cheston Tan"], "title": "Theory of Mind in Large Language Models: Assessment and Enhancement", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Theory of Mind (ToM)-the ability to infer and reason about others' mental\nstates-is fundamental to human social intelligence. As Large Language Models\n(LLMs) become increasingly integrated into daily life, it is crucial to assess\nand enhance their capacity to interpret and respond to human mental states. In\nthis paper, we review LLMs' ToM capabilities by examining both evaluation\nbenchmarks and the strategies designed to improve them. We focus on widely\nadopted story-based benchmarks and provide an in-depth analysis of methods\naimed at enhancing ToM in LLMs. Furthermore, we outline promising future\nresearch directions informed by recent benchmarks and state-of-the-art\napproaches. Our survey serves as a valuable resource for researchers interested\nin advancing LLMs' ToM capabilities."}
{"id": "2505.00335", "pdf": "https://arxiv.org/pdf/2505.00335", "abs": "https://arxiv.org/abs/2505.00335", "authors": ["Seungjun Shin", "Suji Kim", "Dokwan Oh"], "title": "Efficient Neural Video Representation with Temporally Coherent Modulation", "categories": ["cs.CV", "cs.AI"], "comment": "ECCV 2024", "summary": "Implicit neural representations (INR) has found successful applications\nacross diverse domains. To employ INR in real-life, it is important to speed up\ntraining. In the field of INR for video applications, the state-of-the-art\napproach employs grid-type parametric encoding and successfully achieves a\nfaster encoding speed in comparison to its predecessors. However, the grid\nusage, which does not consider the video's dynamic nature, leads to redundant\nuse of trainable parameters. As a result, it has significantly lower parameter\nefficiency and higher bitrate compared to NeRV-style methods that do not use a\nparametric encoding. To address the problem, we propose Neural Video\nrepresentation with Temporally coherent Modulation (NVTM), a novel framework\nthat can capture dynamic characteristics of video. By decomposing the\nspatio-temporal 3D video data into a set of 2D grids with flow information,\nNVTM enables learning video representation rapidly and uses parameter\nefficiently. Our framework enables to process temporally corresponding pixels\nat once, resulting in the fastest encoding speed for a reasonable video\nquality, especially when compared to the NeRV-style method, with a speed\nincrease of over 3 times. Also, it remarks an average of 1.54dB/0.019\nimprovements in PSNR/LPIPS on UVG (Dynamic) (even with 10% fewer parameters)\nand an average of 1.84dB/0.013 improvements in PSNR/LPIPS on MCL-JCV (Dynamic),\ncompared to previous grid-type works. By expanding this to compression tasks,\nwe demonstrate comparable performance to video compression standards (H.264,\nHEVC) and recent INR approaches for video compression. Additionally, we perform\nextensive experiments demonstrating the superior performance of our algorithm\nacross diverse tasks, encompassing super resolution, frame interpolation and\nvideo inpainting. Project page is https://sujiikim.github.io/NVTM/."}
{"id": "2505.00257", "pdf": "https://arxiv.org/pdf/2505.00257", "abs": "https://arxiv.org/abs/2505.00257", "authors": ["Zhizhong Tan", "Jiexin Zheng", "Kevin Qi Zhang", "Wenyong Wang"], "title": "Graph Privacy: A Heterogeneous Federated GNN for Trans-Border Financial Data Circulation", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "The sharing of external data has become a strong demand of financial\ninstitutions, but the privacy issue has led to the difficulty of\ninterconnecting different platforms and the low degree of data openness. To\neffectively solve the privacy problem of financial data in trans-border flow\nand sharing, to ensure that the data is available but not visible, to realize\nthe joint portrait of all kinds of heterogeneous data of business organizations\nin different industries, we propose a Heterogeneous Federated Graph Neural\nNetwork (HFGNN) approach. In this method, the distribution of heterogeneous\nbusiness data of trans-border organizations is taken as subgraphs, and the\nsharing and circulation process among subgraphs is constructed as a\nstatistically heterogeneous global graph through a central server. Each\nsubgraph learns the corresponding personalized service model through local\ntraining to select and update the relevant subset of subgraphs with aggregated\nparameters, and effectively separates and combines topological and feature\ninformation among subgraphs. Finally, our simulation experimental results show\nthat the proposed method has higher accuracy performance and faster convergence\nspeed than existing methods."}
{"id": "2403.16677", "pdf": "https://arxiv.org/pdf/2403.16677", "abs": "https://arxiv.org/abs/2403.16677", "authors": ["Alireza Furutanpey", "Qiyang Zhang", "Philipp Raith", "Tobias Pfandzelter", "Shangguang Wang", "Schahram Dustdar"], "title": "FOOL: Addressing the Downlink Bottleneck in Satellite Computing with Neural Feature Compression", "categories": ["cs.LG", "cs.CV", "cs.DC", "cs.NI", "eess.IV"], "comment": "Version Accepted for publication in IEEE Transactions on Mobile\n  Computing", "summary": "Nanosatellite constellations equipped with sensors capturing large geographic\nregions provide unprecedented opportunities for Earth observation. As\nconstellation sizes increase, network contention poses a downlink bottleneck.\nOrbital Edge Computing (OEC) leverages limited onboard compute resources to\nreduce transfer costs by processing the raw captures at the source. However,\ncurrent solutions have limited practicability due to reliance on crude\nfiltering methods or over-prioritizing particular downstream tasks. This work\npresents FOOL, an OEC-native and task-agnostic feature compression method that\npreserves prediction performance. FOOL partitions high-resolution satellite\nimagery to maximize throughput. Further, it embeds context and leverages\ninter-tile dependencies to lower transfer costs with negligible overhead. While\nFOOL is a feature compressor, it can recover images with competitive scores on\nquality measures at lower bitrates. We extensively evaluate transfer cost\nreduction by including the peculiarity of intermittently available network\nconnections in low earth orbit. Lastly, we test the feasibility of our system\nfor standardized nanosatellite form factors. We demonstrate that FOOL permits\ndownlinking over 100x the data volume without relying on prior information on\nthe downstream tasks."}
{"id": "2505.00027", "pdf": "https://arxiv.org/pdf/2505.00027", "abs": "https://arxiv.org/abs/2505.00027", "authors": ["Jian Zhou", "Jiazheng Li", "Sirui Zhuge", "Hai Zhuge"], "title": "Extracting Abstraction Dimensions by Identifying Syntax Pattern from Texts", "categories": ["cs.CL", "cs.AI", "68T50 (Primary) 91F20 (Secondary)", "I.2.7; I.2.1"], "comment": "25pages, 3 figures, 8 tables", "summary": "This paper proposed an approach to automatically discovering subject\ndimension, action dimension, object dimension and adverbial dimension from\ntexts to efficiently operate texts and support query in natural language. The\nhigh quality of trees guarantees that all subjects, actions, objects and\nadverbials and their subclass relations within texts can be represented. The\nindependency of trees ensures that there is no redundant representation between\ntrees. The expressiveness of trees ensures that the majority of sentences can\nbe accessed from each tree and the rest of sentences can be accessed from at\nleast one tree so that the tree-based search mechanism can support querying in\nnatural language. Experiments show that the average precision, recall and\nF1-score of the abstraction trees constructed by the subclass relations of\nsubject, action, object and adverbial are all greater than 80%. The application\nof the proposed approach to supporting query in natural language demonstrates\nthat different types of question patterns for querying subject or object have\nhigh coverage of texts, and searching multiple trees on subject, action, object\nand adverbial according to the question pattern can quickly reduce search space\nto locate target sentences, which can support precise operation on texts."}
{"id": "2505.00028", "pdf": "https://arxiv.org/pdf/2505.00028", "abs": "https://arxiv.org/abs/2505.00028", "authors": ["Pengchao Feng", "Ziyang Ma", "Wenxi Chen", "Yao Li", "Sheng Wang", "Kai Yu", "Xie Chen"], "title": "Enhancing Speech-to-Speech Dialogue Modeling with End-to-End Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "In recent years, end-to-end speech-to-speech (S2S) dialogue systems have\ngarnered increasing research attention due to their advantages over traditional\ncascaded systems, including achieving lower latency and more natural\nintegration of nonverbal cues such as emotion and speaker identity. However,\nthese end-to-end systems face key challenges, particularly in incorporating\nexternal knowledge, a capability commonly addressed by Retrieval-Augmented\nGeneration (RAG) in text-based large language models (LLMs). The core\ndifficulty lies in the modality gap between input speech and retrieved textual\nknowledge, which hinders effective integration. To address this issue, we\npropose a novel end-to-end RAG framework that directly retrieves relevant\ntextual knowledge from speech queries, eliminating the need for intermediate\nspeech-to-text conversion via techniques like ASR. Experimental results\ndemonstrate that our method significantly improves the performance of\nend-to-end S2S dialogue systems while achieving higher retrieval efficiency.\nAlthough the overall performance still lags behind cascaded models, our\nframework offers a promising direction for enhancing knowledge integration in\nend-to-end S2S systems. We will release the code and dataset to support\nreproducibility and promote further research in this area."}
{"id": "2505.00369", "pdf": "https://arxiv.org/pdf/2505.00369", "abs": "https://arxiv.org/abs/2505.00369", "authors": ["M. A. D. Buser", "D. C. Simons", "M. Fitski", "M. H. W. A. Wijnen", "A. S. Littooij", "A. H. ter Brugge", "I. N. Vos", "M. H. A. Janse", "M. de Boer", "R. ter Maat", "J. Sato", "S. Kido", "S. Kondo", "S. Kasai", "M. Wodzinski", "H. Muller", "J. Ye", "J. He", "Y. Kirchhoff", "M. R. Rokkus", "G. Haokai", "S. Zitong", "M. Fernández-Patón", "D. Veiga-Canuto", "D. G. Ellis", "M. R. Aizenberg", "B. H. M. van der Velden", "H. Kuijf", "A. De Luca", "A. F. W. van der Steeg"], "title": "Automated segmenta-on of pediatric neuroblastoma on multi-modal MRI: Results of the SPPIN challenge at MICCAI 2023", "categories": ["cs.CV"], "comment": "23 pages, 6 figures", "summary": "Surgery plays an important role within the treatment for neuroblastoma, a\ncommon pediatric cancer. This requires careful planning, often via magnetic\nresonance imaging (MRI)-based anatomical 3D models. However, creating these\nmodels is often time-consuming and user dependent. We organized the Surgical\nPlanning in Pediatric Neuroblastoma (SPPIN) challenge, to stimulate\ndevelopments on this topic, and set a benchmark for fully automatic\nsegmentation of neuroblastoma on multi-model MRI. The challenge started with a\ntraining phase, where teams received 78 sets of MRI scans from 34 patients,\nconsisting of both diagnostic and post-chemotherapy MRI scans. The final test\nphase, consisting of 18 MRI sets from 9 patients, determined the ranking of the\nteams. Ranking was based on the Dice similarity coefficient (Dice score), the\n95th percentile of the Hausdorff distance (HD95) and the volumetric similarity\n(VS). The SPPIN challenge was hosted at MICCAI 2023. The final leaderboard\nconsisted of 9 teams. The highest-ranking team achieved a median Dice score\n0.82, a median HD95 of 7.69 mm and a VS of 0.91, utilizing a large, pretrained\nnetwork called STU-Net. A significant difference for the segmentation results\nbetween diagnostic and post-chemotherapy MRI scans was observed (Dice = 0.89 vs\nDice = 0.59, P = 0.01) for the highest-ranking team. SPPIN is the first medical\nsegmentation challenge in extracranial pediatric oncology. The highest-ranking\nteam used a large pre-trained network, suggesting that pretraining can be of\nuse in small, heterogenous datasets. Although the results of the\nhighest-ranking team were high for most patients, segmentation especially in\nsmall, pre-treated tumors were insufficient. Therefore, more reliable\nsegmentation methods are needed to create clinically applicable models to aid\nsurgical planning in pediatric neuroblastoma."}
{"id": "2505.00279", "pdf": "https://arxiv.org/pdf/2505.00279", "abs": "https://arxiv.org/abs/2505.00279", "authors": ["Kyota Kuboki", "Tatsuyoshi Ogawa", "Chu-Hsuan Hsueh", "Shi-Jim Yen", "Kokolo Ikeda"], "title": "Policies of Multiple Skill Levels for Better Strength Estimation in Games", "categories": ["cs.LG"], "comment": "25 pages, 15 figures", "summary": "Accurately estimating human skill levels is crucial for designing effective\nhuman-AI interactions so that AI can provide appropriate challenges or\nguidance. In games where AI players have beaten top human professionals,\nstrength estimation plays a key role in adapting AI behavior to match human\nskill levels. In a previous state-of-the-art study, researchers have proposed a\nstrength estimator trained using human players' match data. Given some matches,\nthe strength estimator computes strength scores and uses them to estimate\nplayer ranks (skill levels). In this paper, we focus on the observation that\nhuman players' behavior tendency varies according to their strength and aim to\nimprove the accuracy of strength estimation by taking this into account.\nSpecifically, in addition to strength scores, we obtain policies for different\nskill levels from neural networks trained using human players' match data. We\nthen combine features based on these policies with the strength scores to\nestimate strength. We conducted experiments on Go and chess. For Go, our method\nachieved an accuracy of 80% in strength estimation when given 10 matches, which\nincreased to 92% when given 20 matches. In comparison, the previous\nstate-of-the-art method had an accuracy of 71% with 10 matches and 84% with 20\nmatches, demonstrating improvements of 8-9%. We observed similar improvements\nin chess. These results contribute to developing a more accurate strength\nestimation method and to improving human-AI interaction."}
{"id": "2412.12126", "pdf": "https://arxiv.org/pdf/2412.12126", "abs": "https://arxiv.org/abs/2412.12126", "authors": ["Sizhe Xing", "Aolong Sun", "Chengxi Wang", "Yizhi Wang", "Boyu Dong", "Junhui Hu", "Xuyu Deng", "An Yan", "Yingjun Liu", "Fangchen Hu", "Zhongya Li", "Ouhan Huang", "Junhao Zhao", "Yingjun Zhou", "Ziwei Li", "Jianyang Shi", "Xi Xiao", "Richard Penty", "Qixiang Cheng", "Nan Chi", "Junwen Zhang"], "title": "Seamless Optical Cloud Computing across Edge-Metro Network for Generative AI", "categories": ["cs.DC", "cs.CV", "cs.LG", "eess.IV", "eess.SP"], "comment": null, "summary": "The rapid advancement of generative artificial intelligence (AI) in recent\nyears has profoundly reshaped modern lifestyles, necessitating a revolutionary\narchitecture to support the growing demands for computational power. Cloud\ncomputing has become the driving force behind this transformation. However, it\nconsumes significant power and faces computation security risks due to the\nreliance on extensive data centers and servers in the cloud. Reducing power\nconsumption while enhancing computational scale remains persistent challenges\nin cloud computing. Here, we propose and experimentally demonstrate an optical\ncloud computing system that can be seamlessly deployed across edge-metro\nnetwork. By modulating inputs and models into light, a wide range of edge nodes\ncan directly access the optical computing center via the edge-metro network.\nThe experimental validations show an energy efficiency of 118.6 mW/TOPs (tera\noperations per second), reducing energy consumption by two orders of magnitude\ncompared to traditional electronic-based cloud computing solutions.\nFurthermore, it is experimentally validated that this architecture can perform\nvarious complex generative AI models through parallel computing to achieve\nimage generation tasks."}
{"id": "2505.00029", "pdf": "https://arxiv.org/pdf/2505.00029", "abs": "https://arxiv.org/abs/2505.00029", "authors": ["Yijie Hong", "Xiaofei Yin", "Xinzhong Wang", "Yi Tu", "Ya Guo", "Sufeng Duan", "Weiqiang Wang", "Lingyong Fang", "Depeng Wang", "Huijia Zhu"], "title": "Keep the General, Inject the Specific: Structured Dialogue Fine-Tuning for Knowledge Injection without Catastrophic Forgetting", "categories": ["cs.CL", "cs.AI"], "comment": "13 pages, 3 figures", "summary": "Large Vision Language Models have demonstrated impressive versatile\ncapabilities through extensive multimodal pre-training, but face significant\nlimitations when incorporating specialized knowledge domains beyond their\ntraining distribution. These models struggle with a fundamental dilemma: direct\nadaptation approaches that inject domain-specific knowledge often trigger\ncatastrophic forgetting of foundational visual-linguistic abilities. We\nintroduce Structured Dialogue Fine-Tuning (SDFT), an effective approach that\neffectively injects domain-specific knowledge while minimizing catastrophic\nforgetting. Drawing inspiration from supervised fine-tuning in LLMs and\nsubject-driven personalization in text-to-image diffusion models, our method\nemploys a three-phase dialogue structure: Foundation Preservation reinforces\npre-trained visual-linguistic alignment through caption tasks; Contrastive\nDisambiguation introduces carefully designed counterfactual examples to\nmaintain semantic boundaries; and Knowledge Specialization embeds specialized\ninformation through chain-of-thought reasoning. Experimental results across\nmultiple domains confirm SDFT's effectiveness in balancing specialized\nknowledge acquisition with general capability retention. Our key contributions\ninclude a data-centric dialogue template that balances foundational alignment\nwith targeted knowledge integration, a weighted multi-turn supervision\nframework, and comprehensive evaluation across diverse knowledge types."}
{"id": "2505.00031", "pdf": "https://arxiv.org/pdf/2505.00031", "abs": "https://arxiv.org/abs/2505.00031", "authors": ["Jin Zhang", "Flood Sung", "Zhilin Yang", "Yang Gao", "Chongjie Zhang"], "title": "Learning to Plan Before Answering: Self-Teaching LLMs to Learn Abstract Plans for Problem Solving", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the field of large language model (LLM) post-training, the effectiveness\nof utilizing synthetic data generated by the LLM itself has been\nwell-presented. However, a key question remains unaddressed: what essential\ninformation should such self-generated data encapsulate? Existing approaches\nonly produce step-by-step problem solutions, and fail to capture the abstract\nmeta-knowledge necessary for generalization across similar problems. Drawing\ninsights from cognitive science, where humans employ high-level abstraction to\nsimplify complex problems before delving into specifics, we introduce a novel\nself-training algorithm: LEarning to Plan before Answering (LEPA). LEPA trains\nthe LLM to formulate anticipatory plans, which serve as abstract meta-knowledge\nfor problem-solving, before engaging with the intricacies of problems. This\napproach not only outlines the solution generation path but also shields the\nLLM from the distraction of irrelevant details. During data generation, LEPA\nfirst crafts an anticipatory plan based on the problem, and then generates a\nsolution that aligns with both the plan and the problem. LEPA refines the plan\nthrough self-reflection, aiming to acquire plans that are instrumental in\nyielding correct solutions. During model optimization, the LLM is trained to\npredict both the refined plans and the corresponding solutions. By efficiently\nextracting and utilizing the anticipatory plans, LEPA demonstrates remarkable\nsuperiority over conventional algorithms on various challenging natural\nlanguage reasoning benchmarks."}
{"id": "2505.00378", "pdf": "https://arxiv.org/pdf/2505.00378", "abs": "https://arxiv.org/abs/2505.00378", "authors": ["Feng Xue", "Wenzhuang Xu", "Guofeng Zhong", "Anlong Minga", "Nicu Sebe"], "title": "Cues3D: Unleashing the Power of Sole NeRF for Consistent and Unique Instances in Open-Vocabulary 3D Panoptic Segmentation", "categories": ["cs.CV"], "comment": "Accepted by Information Fusion", "summary": "Open-vocabulary 3D panoptic segmentation has recently emerged as a\nsignificant trend. Top-performing methods currently integrate 2D segmentation\nwith geometry-aware 3D primitives. However, the advantage would be lost without\nhigh-fidelity 3D point clouds, such as methods based on Neural Radiance Field\n(NeRF). These methods are limited by the insufficient capacity to maintain\nconsistency across partial observations. To address this, recent works have\nutilized contrastive loss or cross-view association pre-processing for view\nconsensus. In contrast to them, we present Cues3D, a compact approach that\nrelies solely on NeRF instead of pre-associations. The core idea is that NeRF's\nimplicit 3D field inherently establishes a globally consistent geometry,\nenabling effective object distinction without explicit cross-view supervision.\nWe propose a three-phase training framework for NeRF,\ninitialization-disambiguation-refinement, whereby the instance IDs are\ncorrected using the initially-learned knowledge. Additionally, an instance\ndisambiguation method is proposed to match NeRF-rendered 3D masks and ensure\nglobally unique 3D instance identities. With the aid of Cues3D, we obtain\nhighly consistent and unique 3D instance ID for each object across views with a\nbalanced version of NeRF. Our experiments are conducted on ScanNet v2,\nScanNet200, ScanNet++, and Replica datasets for 3D instance, panoptic, and\nsemantic segmentation tasks. Cues3D outperforms other 2D image-based methods\nand competes with the latest 2D-3D merging based methods, while even surpassing\nthem when using additional 3D point clouds. The code link could be found in the\nappendix and will be released on\n\\href{https://github.com/mRobotit/Cues3D}{github}"}
{"id": "2505.00290", "pdf": "https://arxiv.org/pdf/2505.00290", "abs": "https://arxiv.org/abs/2505.00290", "authors": ["Hong Xin Xie", "Jian De Sun", "Fan Fu Xue", "Zi Fei Han", "Shan Shan Feng", "Qi Chen"], "title": "Multi-Hierarchical Fine-Grained Feature Mapping Driven by Feature Contribution for Molecular Odor Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Molecular odor prediction is the process of using a molecule's structure to\npredict its smell. While accurate prediction remains challenging, AI models can\nsuggest potential odors. Existing methods, however, often rely on basic\ndescriptors or handcrafted fingerprints, which lack expressive power and hinder\neffective learning. Furthermore, these methods suffer from severe class\nimbalance, limiting the training effectiveness of AI models. To address these\nchallenges, we propose a Feature Contribution-driven Hierarchical Multi-Feature\nMapping Network (HMFNet). Specifically, we introduce a fine-grained, Local\nMulti-Hierarchy Feature Extraction module (LMFE) that performs deep feature\nextraction at the atomic level, capturing detailed features crucial for odor\nprediction. To enhance the extraction of discriminative atomic features, we\nintegrate a Harmonic Modulated Feature Mapping (HMFM). This module dynamically\nlearns feature importance and frequency modulation, improving the model's\ncapability to capture relevant patterns. Additionally, a Global Multi-Hierarchy\nFeature Extraction module (GMFE) is designed to learn global features from the\nmolecular graph topology, enabling the model to fully leverage global\ninformation and enhance its discriminative power for odor prediction. To\nfurther mitigate the issue of class imbalance, we propose a Chemically-Informed\nLoss (CIL). Experimental results demonstrate that our approach significantly\nimproves performance across various deep learning models, highlighting its\npotential to advance molecular structure representation and accelerate the\ndevelopment of AI-driven technologies."}
{"id": "2502.20824", "pdf": "https://arxiv.org/pdf/2502.20824", "abs": "https://arxiv.org/abs/2502.20824", "authors": ["Fadeel Sher Khan", "Joshua Ebenezer", "Hamid Sheikh", "Seok-Jun Lee"], "title": "MFSR-GAN: Multi-Frame Super-Resolution with Handheld Motion Modeling", "categories": ["cs.CV", "eess.IV"], "comment": "Accepted to NTIRE Workshop at CVPR 2025; 8 pages, 6 figures", "summary": "Smartphone cameras have become ubiquitous imaging tools, yet their small\nsensors and compact optics often limit spatial resolution and introduce\ndistortions. Combining information from multiple low-resolution (LR) frames to\nproduce a high-resolution (HR) image has been explored to overcome the inherent\nlimitations of smartphone cameras. Despite the promise of multi-frame\nsuper-resolution (MFSR), current approaches are hindered by datasets that fail\nto capture the characteristic noise and motion patterns found in real-world\nhandheld burst images. In this work, we address this gap by introducing a novel\nsynthetic data engine that uses multi-exposure static images to synthesize\nLR-HR training pairs while preserving sensor-specific noise characteristics and\nimage motion found during handheld burst photography. We also propose MFSR-GAN:\na multi-scale RAW-to-RGB network for MFSR. Compared to prior approaches,\nMFSR-GAN emphasizes a \"base frame\" throughout its architecture to mitigate\nartifacts. Experimental results on both synthetic and real data demonstrates\nthat MFSR-GAN trained with our synthetic engine yields sharper, more realistic\nreconstructions than existing methods for real-world MFSR."}
{"id": "2505.00030", "pdf": "https://arxiv.org/pdf/2505.00030", "abs": "https://arxiv.org/abs/2505.00030", "authors": ["Ted Underwood", "Laura K. Nelson", "Matthew Wilkens"], "title": "Can Language Models Represent the Past without Anachronism?", "categories": ["cs.CL"], "comment": null, "summary": "Before researchers can use language models to simulate the past, they need to\nunderstand the risk of anachronism. We find that prompting a contemporary model\nwith examples of period prose does not produce output consistent with period\nstyle. Fine-tuning produces results that are stylistically convincing enough to\nfool an automated judge, but human evaluators can still distinguish fine-tuned\nmodel outputs from authentic historical text. We tentatively conclude that\npretraining on period prose may be required in order to reliably simulate\nhistorical perspectives for social research."}
{"id": "2505.00032", "pdf": "https://arxiv.org/pdf/2505.00032", "abs": "https://arxiv.org/abs/2505.00032", "authors": ["Yuyang Sha", "Hongxin Pan", "Wei Xu", "Weiyu Meng", "Gang Luo", "Xinyu Du", "Xiaobing Zhai", "Henry H. Y. Tong", "Caijuan Shi", "Kefeng Li"], "title": "MDD-LLM: Towards Accuracy Large Language Models for Major Depressive Disorder Diagnosis", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Major depressive disorder (MDD) impacts more than 300 million people\nworldwide, highlighting a significant public health issue. However, the uneven\ndistribution of medical resources and the complexity of diagnostic methods have\nresulted in inadequate attention to this disorder in numerous countries and\nregions. This paper introduces a high-performance MDD diagnosis tool named\nMDD-LLM, an AI-driven framework that utilizes fine-tuned large language models\n(LLMs) and extensive real-world samples to tackle challenges in MDD diagnosis.\nTherefore, we select 274,348 individual information from the UK Biobank cohort\nto train and evaluate the proposed method. Specifically, we select 274,348\nindividual records from the UK Biobank cohort and design a tabular data\ntransformation method to create a large corpus for training and evaluating the\nproposed approach. To illustrate the advantages of MDD-LLM, we perform\ncomprehensive experiments and provide several comparative analyses against\nexisting model-based solutions across multiple evaluation metrics. Experimental\nresults show that MDD-LLM (70B) achieves an accuracy of 0.8378 and an AUC of\n0.8919 (95% CI: 0.8799 - 0.9040), significantly outperforming existing machine\nlearning and deep learning frameworks for MDD diagnosis. Given the limited\nexploration of LLMs in MDD diagnosis, we examine numerous factors that may\ninfluence the performance of our proposed method, such as tabular data\ntransformation techniques and different fine-tuning strategies."}
{"id": "2505.00380", "pdf": "https://arxiv.org/pdf/2505.00380", "abs": "https://arxiv.org/abs/2505.00380", "authors": ["Anjith George", "Sebastien Marcel"], "title": "The Invisible Threat: Evaluating the Vulnerability of Cross-Spectral Face Recognition to Presentation Attacks", "categories": ["cs.CV"], "comment": "10 pages", "summary": "Cross-spectral face recognition systems are designed to enhance the\nperformance of facial recognition systems by enabling cross-modal matching\nunder challenging operational conditions. A particularly relevant application\nis the matching of near-infrared (NIR) images to visible-spectrum (VIS) images,\nenabling the verification of individuals by comparing NIR facial captures\nacquired with VIS reference images. The use of NIR imaging offers several\nadvantages, including greater robustness to illumination variations, better\nvisibility through glasses and glare, and greater resistance to presentation\nattacks. Despite these claimed benefits, the robustness of NIR-based systems\nagainst presentation attacks has not been systematically studied in the\nliterature. In this work, we conduct a comprehensive evaluation into the\nvulnerability of NIR-VIS cross-spectral face recognition systems to\npresentation attacks. Our empirical findings indicate that, although these\nsystems exhibit a certain degree of reliability, they remain vulnerable to\nspecific attacks, emphasizing the need for further research in this area."}
{"id": "2505.00291", "pdf": "https://arxiv.org/pdf/2505.00291", "abs": "https://arxiv.org/abs/2505.00291", "authors": ["Eran Rosenbluth", "Martin Grohe"], "title": "Repetition Makes Perfect: Recurrent Sum-GNNs Match Message Passing Limit", "categories": ["cs.LG", "68T05, 68T07", "I.2.6"], "comment": null, "summary": "We provide first tight bounds for the expressivity of Recurrent Graph Neural\nNetworks (recurrent GNNs) with finite-precision parameters. We prove that\nrecurrent GNNs, with sum aggregation and ReLU activation, can emulate any graph\nalgorithm that respects the natural message-passing invariance induced by the\ncolor refinement (or Weisfeiler-Leman) algorithm. While it is well known that\nthe expressive power of GNNs is limited by this invariance [Morris et al., AAAI\n2019; Xu et al., ICLR 2019], we establish that recurrent GNNs can actually\nreach this limit. This is in contrast to non-recurrent GNNs, which have the\npower of Weisfeiler-Leman only in a very weak, \"non-uniform\", sense where every\ngraph size requires a different GNN model to compute with. The emulation we\nconstruct introduces only a polynomial overhead in both time and space.\n  Furthermore, we show that by incorporating random initialization, recurrent\nGNNs can emulate all graph algorithms, implying in particular that any graph\nalgorithm with polynomial-time complexity can be emulated by a recurrent GNN\nwith random initialization, running in polynomial time."}
{"id": "2504.16960", "pdf": "https://arxiv.org/pdf/2504.16960", "abs": "https://arxiv.org/abs/2504.16960", "authors": ["Weixuan Chen", "Qianqian Yang", "Shuo Shao", "Zhiguo Shi", "Jiming Chen", "Xuemin", "Shen"], "title": "Enhancing the Security of Semantic Communication via Knowledge-Aided Coding and Jamming", "categories": ["cs.IT", "eess.IV", "math.IT"], "comment": null, "summary": "As semantic communication (SemCom) emerges as a promising communication\nparadigm, ensuring the security of semantic information over open wireless\nchannels has become crucial. Traditional encryption methods introduce\nconsiderable communication overhead, while existing learning-based secure\nSemCom schemes often rely on a channel capacity advantage for the legitimate\nreceiver, which is challenging to guarantee in practice. In this paper, we\npropose a coding-enhanced jamming approach that eliminates the need to transmit\na secret key by utilizing shared knowledge between the legitimate receiver and\nthe transmitter. We generate private codebooks with neural network (NN)-based\nencoders, using them to encode data into a sequence Y1, which is then\nsuperposed with a sequence Y2 drawn from the private codebook. By optimizing\nthe power allocation between the two sequences, the legitimate receiver can\nsuccessfully decode the data, while the eavesdropper' s performance is\nsignificantly degraded, potentially to the point of random guessing.\nExperimental results demonstrate that our method achieves comparable security\nto state-of-the-art approaches while significantly improving the reconstruction\nperformance of the legitimate receiver by more than 1 dB across varying channel\nsignal-to-noise ratios (SNRs) and compression ratios."}
{"id": "2505.00033", "pdf": "https://arxiv.org/pdf/2505.00033", "abs": "https://arxiv.org/abs/2505.00033", "authors": ["Andrew Kiruluta"], "title": "From Attention to Atoms: Spectral Dictionary Learning for Fast, Interpretable Language Models", "categories": ["cs.CL"], "comment": null, "summary": "We propose a novel spectral generative modeling framework for natural\nlanguage processing that jointly learns a global time varying Fourier\ndictionary and per token mixing coefficients, replacing the ubiquitous self\nattention mechanism in transformer architectures. By enforcing reconstruction\nlosses in both the time domain (embedding reconstruction) and the frequency\ndomain (via Short Time Fourier Transform magnitude matching) alongside a\nstandard language modeling objective, and fitting a Gaussian Mixture Model\n(GMM) prior over the learned mixing vectors, our approach achieves competitive\nperplexity and generation quality on standard benchmarks such as WikiText2 and\nPenn Treebank. In contrast to the quadratic computation complexity of self\nattention, our method operates with linear complexity, delivering substantial\nefficiency gains. We demonstrate that spectral dictionary models can achieve\ncompetitive performance compared to transformer baselines while significantly\nreducing inference latency and memory footprint, offering a compelling\nalternative for scalable language modeling."}
{"id": "2505.00034", "pdf": "https://arxiv.org/pdf/2505.00034", "abs": "https://arxiv.org/abs/2505.00034", "authors": ["Zijie Lin", "Zikang Liu", "Hanbo Fan"], "title": "Improving Phishing Email Detection Performance of Small Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models(LLMs) have demonstrated remarkable performance on many\nnatural language processing(NLP) tasks and have been employed in phishing email\ndetection research. However, in current studies, well-performing LLMs typically\ncontain billions or even tens of billions of parameters, requiring enormous\ncomputational resources. To reduce computational costs, we investigated the\neffectiveness of small-parameter LLMs for phishing email detection. These LLMs\nhave around 3 billion parameters and can run on consumer-grade GPUs. However,\nsmall LLMs often perform poorly in phishing email detection task. To address\nthese issues, we designed a set of methods including Prompt Engineering,\nExplanation Augmented Fine-tuning, and Model Ensemble to improve phishing email\ndetection capabilities of small LLMs. We validated the effectiveness of our\napproach through experiments, significantly improving accuracy on the\nSpamAssassin dataset from around 0.5 for baseline models like\nQwen2.5-1.5B-Instruct to 0.976."}
{"id": "2505.00394", "pdf": "https://arxiv.org/pdf/2505.00394", "abs": "https://arxiv.org/abs/2505.00394", "authors": ["Wenxuan Liu", "Yao Deng", "Kang Chen", "Xian Zhong", "Zhaofei Yu", "Tiejun Huang"], "title": "SOTA: Spike-Navigated Optimal TrAnsport Saliency Region Detection in Composite-bias Videos", "categories": ["cs.CV"], "comment": "Accepted to IJCAI 2025", "summary": "Existing saliency detection methods struggle in real-world scenarios due to\nmotion blur and occlusions. In contrast, spike cameras, with their high\ntemporal resolution, significantly enhance visual saliency maps. However, the\ncomposite noise inherent to spike camera imaging introduces discontinuities in\nsaliency detection. Low-quality samples further distort model predictions,\nleading to saliency bias. To address these challenges, we propose\nSpike-navigated Optimal TrAnsport Saliency Region Detection (SOTA), a framework\nthat leverages the strengths of spike cameras while mitigating biases in both\nspatial and temporal dimensions. Our method introduces Spike-based Micro-debias\n(SM) to capture subtle frame-to-frame variations and preserve critical details,\neven under minimal scene or lighting changes. Additionally, Spike-based\nGlobal-debias (SG) refines predictions by reducing inconsistencies across\ndiverse conditions. Extensive experiments on real and synthetic datasets\ndemonstrate that SOTA outperforms existing methods by eliminating composite\nnoise bias. Our code and dataset will be released at\nhttps://github.com/lwxfight/sota."}
{"id": "2505.00302", "pdf": "https://arxiv.org/pdf/2505.00302", "abs": "https://arxiv.org/abs/2505.00302", "authors": ["Xinlong Zhao", "Liying Zhang", "Tianbo Zou", "Yan Zhang"], "title": "Temporal Attention Evolutional Graph Convolutional Network for Multivariate Time Series Forecasting", "categories": ["cs.LG", "68T09 (Primary), 68T07 (Secondary)"], "comment": "13 pages, 7 figures", "summary": "Multivariate time series forecasting enables the prediction of future states\nby leveraging historical data, thereby facilitating decision-making processes.\nEach data node in a multivariate time series encompasses a sequence of multiple\ndimensions. These nodes exhibit interdependent relationships, forming a graph\nstructure. While existing prediction methods often assume a fixed graph\nstructure, many real-world scenarios involve dynamic graph structures.\nMoreover, interactions among time series observed at different time scales vary\nsignificantly. To enhance prediction accuracy by capturing precise temporal and\nspatial features, this paper introduces the Temporal Attention Evolutional\nGraph Convolutional Network (TAEGCN). This novel method not only integrates\ncausal temporal convolution and a multi-head self-attention mechanism to learn\ntemporal features of nodes, but also construct the dynamic graph structure\nbased on these temporal features to keep the consistency of the changing in\nspatial feature with temporal series. TAEGCN adeptly captures temporal causal\nrelationships and hidden spatial dependencies within the data. Furthermore,\nTAEGCN incorporates a unified neural network that seamlessly integrates these\ncomponents to generate final predictions. Experimental results conducted on two\npublic transportation network datasets, METR-LA and PEMS-BAY, demonstrate the\nsuperior performance of the proposed model."}
{"id": "2504.21632", "pdf": "https://arxiv.org/pdf/2504.21632", "abs": "https://arxiv.org/abs/2504.21632", "authors": ["Fuma Ito", "Chihiro Tsutake", "Keita Takahashi", "Toshiaki Fujii"], "title": "Fast Sign Retrieval via Sub-band Convolution: An Elementary Extension of Binary Classification", "categories": ["cs.IT", "eess.IV", "math.IT"], "comment": null, "summary": "To efficiently compress the sign information of images, we address a sign\nretrieval problem for the block-wise discrete cosine transformation (DCT):\nreconstruction of the signs of DCT coefficients from their amplitudes. To this\nend, we propose a fast sign retrieval method on the basis of binary\nclassification machine learning. We first introduce 3D representations of the\namplitudes and signs, where we pack amplitudes/signs belonging to the same\nfrequency band into a 2D slice, referred to as the sub-band block. We then\nretrieve the signs from the 3D amplitudes via binary classification, where each\nsign is regarded as a binary label. We implement a binary classification\nalgorithm using convolutional neural networks, which are advantageous for\nefficiently extracting features in the 3D amplitudes. Experimental results\ndemonstrate that our method achieves accurate sign retrieval with an\noverwhelmingly low computation cost."}
{"id": "2505.00035", "pdf": "https://arxiv.org/pdf/2505.00035", "abs": "https://arxiv.org/abs/2505.00035", "authors": ["Aayam Bansal", "Raghav Agarwal", "Kaashvi Jain"], "title": "Linguistic Complexity and Socio-cultural Patterns in Hip-Hop Lyrics", "categories": ["cs.CL", "cs.AI"], "comment": "12 pages", "summary": "This paper presents a comprehensive computational framework for analyzing\nlinguistic complexity and socio-cultural trends in hip-hop lyrics. Using a\ndataset of 3,814 songs from 146 influential artists spanning four decades\n(1980-2020), we employ natural language processing techniques to quantify\nmultiple dimensions of lyrical complexity. Our analysis reveals a 23.7%\nincrease in vocabulary diversity over the study period, with East Coast artists\ndemonstrating 17.3% higher lexical variation than other regions. Rhyme density\nincreased by 34.2% across all regions, with Midwest artists exhibiting the\nhighest technical complexity (3.04 rhymes per line). Topic modeling identified\nsignificant shifts in thematic content, with social justice themes decreasing\nfrom 28.5% to 13.8% of content while introspective themes increased from 7.6%\nto 26.3%. Sentiment analysis demon- strated that lyrics became significantly\nmore negative during sociopolitical crises, with polarity decreasing by 0.31\nfollowing major social unrest. Multi-dimensional analysis revealed four dis-\ntinct stylistic approaches that correlate strongly with geographic origin\n(r=0.68, p!0.001) and time period (r=0.59, p<0.001). These findings establish\nquantitative evidence for the evolution of hip- hop as both an art form and a\nreflection of societal dynamics, providing insights into the interplay between\nlinguistic innovation and cultural context in popular music."}
{"id": "2505.00040", "pdf": "https://arxiv.org/pdf/2505.00040", "abs": "https://arxiv.org/abs/2505.00040", "authors": ["Dishanand Jayeprokash", "Julia Gonski"], "title": "Convolutional Autoencoders for Data Compression and Anomaly Detection in Small Satellite Technologies", "categories": ["astro-ph.IM", "cs.AI"], "comment": "10 pages, 6 figures", "summary": "Small satellite technologies have enhanced the potential and feasibility of\ngeodesic missions, through simplification of design and decreased costs\nallowing for more frequent launches. On-satellite data acquisition systems can\nbenefit from the implementation of machine learning (ML), for better\nperformance and greater efficiency on tasks such as image processing or feature\nextraction. This work presents convolutional autoencoders for implementation on\nthe payload of small satellites, designed to achieve dual functionality of data\ncompression for more efficient off-satellite transmission, and at-source\nanomaly detection to inform satellite data-taking. This capability is\ndemonstrated for a use case of disaster monitoring using aerial image datasets\nof the African continent, offering avenues for both novel ML-based approaches\nin small satellite applications along with the expansion of space technology\nand artificial intelligence in Africa."}
{"id": "2505.00421", "pdf": "https://arxiv.org/pdf/2505.00421", "abs": "https://arxiv.org/abs/2505.00421", "authors": ["Xia Yuan", "Hai Yuan", "Wenyi Ge", "Ying Fu", "Xi Wu", "Guanyu Xing"], "title": "Real-Time Animatable 2DGS-Avatars with Detail Enhancement from Monocular Videos", "categories": ["cs.CV"], "comment": null, "summary": "High-quality, animatable 3D human avatar reconstruction from monocular videos\noffers significant potential for reducing reliance on complex hardware, making\nit highly practical for applications in game development, augmented reality,\nand social media. However, existing methods still face substantial challenges\nin capturing fine geometric details and maintaining animation stability,\nparticularly under dynamic or complex poses. To address these issues, we\npropose a novel real-time framework for animatable human avatar reconstruction\nbased on 2D Gaussian Splatting (2DGS). By leveraging 2DGS and global SMPL pose\nparameters, our framework not only aligns positional and rotational\ndiscrepancies but also enables robust and natural pose-driven animation of the\nreconstructed avatars. Furthermore, we introduce a Rotation Compensation\nNetwork (RCN) that learns rotation residuals by integrating local geometric\nfeatures with global pose parameters. This network significantly improves the\nhandling of non-rigid deformations and ensures smooth, artifact-free pose\ntransitions during animation. Experimental results demonstrate that our method\nsuccessfully reconstructs realistic and highly animatable human avatars from\nmonocular videos, effectively preserving fine-grained details while ensuring\nstable and natural pose variation. Our approach surpasses current\nstate-of-the-art methods in both reconstruction quality and animation\nrobustness on public benchmarks."}
{"id": "2505.00307", "pdf": "https://arxiv.org/pdf/2505.00307", "abs": "https://arxiv.org/abs/2505.00307", "authors": ["Yu-Hsiang Lan", "Anton Alyakin", "Eric K. Oermann"], "title": "Gateformer: Advancing Multivariate Time Series Forecasting through Temporal and Variate-Wise Attention with Gated Representations", "categories": ["cs.LG"], "comment": null, "summary": "There has been a recent surge of interest in time series modeling using the\nTransformer architecture. However, forecasting multivariate time series with\nTransformer presents a unique challenge as it requires modeling both temporal\n(cross-time) and variate (cross-variate) dependencies. While Transformer-based\nmodels have gained popularity for their flexibility in capturing both\nsequential and cross-variate relationships, it is unclear how to best integrate\nthese two sources of information in the context of the Transformer architecture\nwhile optimizing for both performance and efficiency. We re-purpose the\nTransformer architecture to effectively model both cross-time and cross-variate\ndependencies. Our approach begins by embedding each variate independently into\na variate-wise representation that captures its cross-time dynamics, and then\nmodels cross-variate dependencies through attention mechanisms on these learned\nembeddings. Gating operations in both cross-time and cross-variate modeling\nphases regulate information flow, allowing the model to focus on the most\nrelevant features for accurate predictions. Our method achieves\nstate-of-the-art performance across 13 real-world datasets and can be\nseamlessly integrated into other Transformer-based and LLM-based forecasters,\ndelivering performance improvements up to 20.7\\% over original models. Code is\navailable at this repository: https://github.com/nyuolab/Gateformer."}
{"id": "2505.00036", "pdf": "https://arxiv.org/pdf/2505.00036", "abs": "https://arxiv.org/abs/2505.00036", "authors": ["Zhongren Chen", "Joshua Kalla", "Quan Le", "Shinpei Nakamura-Sakai", "Jasjeet Sekhon", "Ruixiao Wang"], "title": "A Framework to Assess the Persuasion Risks Large Language Model Chatbots Pose to Democratic Societies", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "In recent years, significant concern has emerged regarding the potential\nthreat that Large Language Models (LLMs) pose to democratic societies through\ntheir persuasive capabilities. We expand upon existing research by conducting\ntwo survey experiments and a real-world simulation exercise to determine\nwhether it is more cost effective to persuade a large number of voters using\nLLM chatbots compared to standard political campaign practice, taking into\naccount both the \"receive\" and \"accept\" steps in the persuasion process (Zaller\n1992). These experiments improve upon previous work by assessing extended\ninteractions between humans and LLMs (instead of using single-shot\ninteractions) and by assessing both short- and long-run persuasive effects\n(rather than simply asking users to rate the persuasiveness of LLM-produced\ncontent). In two survey experiments (N = 10,417) across three distinct\npolitical domains, we find that while LLMs are about as persuasive as actual\ncampaign ads once voters are exposed to them, political persuasion in the\nreal-world depends on both exposure to a persuasive message and its impact\nconditional on exposure. Through simulations based on real-world parameters, we\nestimate that LLM-based persuasion costs between \\$48-\\$74 per persuaded voter\ncompared to \\$100 for traditional campaign methods, when accounting for the\ncosts of exposure. However, it is currently much easier to scale traditional\ncampaign persuasion methods than LLM-based persuasion. While LLMs do not\ncurrently appear to have substantially greater potential for large-scale\npolitical persuasion than existing non-LLM methods, this may change as LLM\ncapabilities continue to improve and it becomes easier to scalably encourage\nexposure to persuasive LLMs."}
{"id": "2505.00050", "pdf": "https://arxiv.org/pdf/2505.00050", "abs": "https://arxiv.org/abs/2505.00050", "authors": ["Aayam Bansal", "Agneya Tharun"], "title": "Emotional Analysis of Fashion Trends Using Social Media and AI: Sentiment Analysis on Twitter for Fashion Trend Forecasting", "categories": ["cs.CL", "cs.AI"], "comment": "13 pages", "summary": "This study explores the intersection of fashion trends and social media\nsentiment through computational analysis of Twitter data using the T4SA\n(Twitter for Sentiment Analysis) dataset. By applying natural language\nprocessing and machine learning techniques, we examine how sentiment patterns\nin fashion-related social media conversations can serve as predictors for\nemerging fashion trends. Our analysis involves the identification and\ncategorization of fashion-related content, sentiment classification with\nimproved normalization techniques, time series decomposition, statistically\nvalidated causal relationship modeling, cross-platform sentiment comparison,\nand brand-specific sentiment analysis. Results indicate correlations between\nsentiment patterns and fashion theme popularity, with accessories and\nstreetwear themes showing statistically significant rising trends. The Granger\ncausality analysis establishes sustainability and streetwear as primary trend\ndrivers, showing bidirectional relationships with several other themes. The\nfindings demonstrate that social media sentiment analysis can serve as an\neffective early indicator of fashion trend trajectories when proper statistical\nvalidation is applied. Our improved predictive model achieved 78.35% balanced\naccuracy in sentiment classification, establishing a reliable foundation for\ntrend prediction across positive, neutral, and negative sentiment categories."}
{"id": "2505.00426", "pdf": "https://arxiv.org/pdf/2505.00426", "abs": "https://arxiv.org/abs/2505.00426", "authors": ["Ruiyuan Zhang", "Qi Wang", "Jiaxiang Liu", "Yu Zhang", "Yuchi Huo", "Chao Wu"], "title": "Leveraging Pretrained Diffusion Models for Zero-Shot Part Assembly", "categories": ["cs.CV"], "comment": "10 pages, 12 figures, Accepted by IJCAI-2025", "summary": "3D part assembly aims to understand part relationships and predict their\n6-DoF poses to construct realistic 3D shapes, addressing the growing demand for\nautonomous assembly, which is crucial for robots. Existing methods mainly\nestimate the transformation of each part by training neural networks under\nsupervision, which requires a substantial quantity of manually labeled data.\nHowever, the high cost of data collection and the immense variability of\nreal-world shapes and parts make traditional methods impractical for\nlarge-scale applications. In this paper, we propose first a zero-shot part\nassembly method that utilizes pre-trained point cloud diffusion models as\ndiscriminators in the assembly process, guiding the manipulation of parts to\nform realistic shapes. Specifically, we theoretically demonstrate that\nutilizing a diffusion model for zero-shot part assembly can be transformed into\nan Iterative Closest Point (ICP) process. Then, we propose a novel pushing-away\nstrategy to address the overlap parts, thereby further enhancing the robustness\nof the method. To verify our work, we conduct extensive experiments and\nquantitative comparisons to several strong baseline methods, demonstrating the\neffectiveness of the proposed approach, which even surpasses the supervised\nlearning method. The code has been released on\nhttps://github.com/Ruiyuan-Zhang/Zero-Shot-Assembly."}
{"id": "2505.00315", "pdf": "https://arxiv.org/pdf/2505.00315", "abs": "https://arxiv.org/abs/2505.00315", "authors": ["Piotr Piękos", "Róbert Csordás", "Jürgen Schmidhuber"], "title": "Mixture of Sparse Attention: Content-Based Learnable Sparse Attention via Expert-Choice Routing", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Recent advances in large language models highlighted the excessive quadratic\ncost of self-attention. Despite the significant research efforts, subquadratic\nattention methods still suffer from inferior performance in practice. We\nhypothesize that dynamic, learned content-based sparsity can lead to more\nefficient attention mechanisms. We present Mixture of Sparse Attention (MoSA),\na novel approach inspired by Mixture of Experts (MoE) with expert choice\nrouting. MoSA dynamically selects tokens for each attention head, allowing\narbitrary sparse attention patterns. By selecting $k$ tokens from a sequence of\nlength $T$, MoSA reduces the computational complexity of each attention head\nfrom $O(T^2)$ to $O(k^2 + T)$. This enables using more heads within the same\ncomputational budget, allowing higher specialization. We show that among the\ntested sparse attention variants, MoSA is the only one that can outperform the\ndense baseline, sometimes with up to 27% better perplexity for an identical\ncompute budget. MoSA can also reduce the resource usage compared to dense\nself-attention. Despite using torch implementation without an optimized kernel,\nperplexity-matched MoSA models are simultaneously faster in wall-clock time,\nrequire less memory for training, and drastically reduce the size of the\nKV-cache compared to the dense transformer baselines."}
{"id": "2505.00038", "pdf": "https://arxiv.org/pdf/2505.00038", "abs": "https://arxiv.org/abs/2505.00038", "authors": ["Cristina Garbacea", "Chenhao Tan"], "title": "HyPerAlign: Hypotheses-driven Personalized Alignment", "categories": ["cs.CL"], "comment": null, "summary": "Alignment algorithms are widely used to align large language models (LLMs) to\nhuman users based on preference annotations that reflect their intended\nreal-world use cases. Typically these (often divergent) preferences are\naggregated over a diverse set of users, resulting in fine-tuned models that are\naligned to the ``average-user'' preference. Nevertheless, current models are\nused by individual users in very specific contexts and situations, emphasizing\nthe need for user-dependent preference control. In this work we address the\nproblem of personalizing LLM outputs to their users, aiming to generate\ncustomized responses tailored to individual users, instead of generic outputs\nthat emulate the collective voices of diverse populations. We propose a novel\ninterpretable and sample-efficient hypotheses-driven personalization approach\n(HyPerAlign) where given few-shot examples written by a particular user, we\nfirst infer hypotheses about their communication strategies, personality and\nwriting style, then prompt LLM models with these hypotheses and user specific\nattributes to generate customized outputs. We conduct experiments on two\ndifferent personalization tasks, authorship attribution and deliberative\nalignment, with datasets from diverse domains (news articles, blog posts,\nemails, jailbreaking benchmarks), and demonstrate the superiority of\nhypotheses-driven personalization approach when compared to preference-based\nfine-tuning methods. For deliberative alignment, the helpfulness of LLM models\nis improved by up to $70\\%$ on average. For authorship attribution, results\nindicate consistently high win-rates (commonly $>90\\%$) against\nstate-of-the-art preference fine-tuning approaches for LLM personalization\nacross diverse user profiles and LLM models. Overall, our approach represents\nan interpretable and sample-efficient strategy for the personalization of LLM\nmodels to individual users."}
{"id": "2505.00060", "pdf": "https://arxiv.org/pdf/2505.00060", "abs": "https://arxiv.org/abs/2505.00060", "authors": ["Jeho Choi"], "title": "Fact-Consistency Evaluation of Text-to-SQL Generation for Business Intelligence Using Exaone 3.5", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "6 pages, 1 table", "summary": "Large Language Models (LLMs) have shown promise in enabling natural language\ninterfaces for structured data querying through text-to-SQL generation.\nHowever, their application in real-world Business Intelligence (BI) contexts\nremains limited due to semantic hallucinations, structural errors, and a lack\nof domain-specific evaluation frameworks. In this study, we propose a\nFact-Consistency Evaluation Framework for assessing the semantic accuracy of\nLLM-generated SQL outputs using Exaone 3.5--an instruction-tuned, bilingual LLM\noptimized for enterprise tasks. We construct a domain-specific benchmark\ncomprising 219 natural language business questions across five SQL complexity\nlevels, derived from actual sales data in LG Electronics' internal BigQuery\nenvironment. Each question is paired with a gold-standard SQL query and a\nvalidated ground-truth answer. We evaluate model performance using answer\naccuracy, execution success rate, semantic error rate, and non-response rate.\nExperimental results show that while Exaone 3.5 performs well on simple\naggregation tasks (93% accuracy in L1), it exhibits substantial degradation in\narithmetic reasoning (4% accuracy in H1) and grouped ranking tasks (31% in H4),\nwith semantic errors and non-responses concentrated in complex cases.\nQualitative error analysis further identifies common failure types such as\nmisapplied arithmetic logic, incomplete filtering, and incorrect grouping\noperations. Our findings highlight the current limitations of LLMs in\nbusiness-critical environments and underscore the need for fact-consistency\nvalidation layers and hybrid reasoning approaches. This work contributes a\nreproducible benchmark and evaluation methodology for advancing reliable\nnatural language interfaces to structured enterprise data systems."}
{"id": "2505.00452", "pdf": "https://arxiv.org/pdf/2505.00452", "abs": "https://arxiv.org/abs/2505.00452", "authors": ["Gregory Schroeder", "Mohamed Sabry", "Cristina Olaverri-Monreal"], "title": "ClearLines - Camera Calibration from Straight Lines", "categories": ["cs.CV"], "comment": null, "summary": "The problem of calibration from straight lines is fundamental in geometric\ncomputer vision, with well-established theoretical foundations. However, its\npractical applicability remains limited, particularly in real-world outdoor\nscenarios. These environments pose significant challenges due to diverse and\ncluttered scenes, interrupted reprojections of straight 3D lines, and varying\nlighting conditions, making the task notoriously difficult. Furthermore, the\nfield lacks a dedicated dataset encouraging the development of respective\ndetection algorithms. In this study, we present a small dataset named\n\"ClearLines\", and by detailing its creation process, provide practical insights\nthat can serve as a guide for developing and refining straight 3D line\ndetection algorithms."}
{"id": "2505.00316", "pdf": "https://arxiv.org/pdf/2505.00316", "abs": "https://arxiv.org/abs/2505.00316", "authors": ["Tien Comlekoglu", "J. Quetzalcóatl Toledo-Marín", "Tina Comlekoglu", "Douglas W. DeSimone", "Shayn M. Peirce", "Geoffrey Fox", "James A. Glazier"], "title": "Surrogate modeling of Cellular-Potts Agent-Based Models as a segmentation task using the U-Net neural network architecture", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "The Cellular-Potts model is a powerful and ubiquitous framework for\ndeveloping computational models for simulating complex multicellular biological\nsystems. Cellular-Potts models (CPMs) are often computationally expensive due\nto the explicit modeling of interactions among large numbers of individual\nmodel agents and diffusive fields described by partial differential equations\n(PDEs). In this work, we develop a convolutional neural network (CNN) surrogate\nmodel using a U-Net architecture that accounts for periodic boundary\nconditions. We use this model to accelerate the evaluation of a mechanistic CPM\npreviously used to investigate \\textit{in vitro} vasculogenesis. The surrogate\nmodel was trained to predict 100 computational steps ahead (Monte-Carlo steps,\nMCS), accelerating simulation evaluations by a factor of 590 times compared to\nCPM code execution. Over multiple recursive evaluations, our model effectively\ncaptures the emergent behaviors demonstrated by the original Cellular-Potts\nmodel of such as vessel sprouting, extension and anastomosis, and contraction\nof vascular lacunae. This approach demonstrates the potential for deep learning\nto serve as efficient surrogate models for CPM simulations, enabling faster\nevaluation of computationally expensive CPM of biological processes at greater\nspatial and temporal scales."}
{"id": "2505.00039", "pdf": "https://arxiv.org/pdf/2505.00039", "abs": "https://arxiv.org/abs/2505.00039", "authors": ["Hudson de Martim"], "title": "Graph RAG for Legal Norms: A Hierarchical and Temporal Approach", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "This article proposes an adaptation of Graph Retrieval Augmented Generation\n(Graph RAG) specifically designed for the analysis and comprehension of legal\nnorms, which are characterized by their predefined hierarchical structure,\nextensive network of internal and external references and multiple temporal\nversions. By combining structured knowledge graphs with contextually enriched\ntext segments, Graph RAG offers a promising solution to address the inherent\ncomplexity and vast volume of legal data. The integration of hierarchical\nstructure and temporal evolution into knowledge graphs - along with the concept\nof comprehensive Text Units - facilitates the construction of richer,\ninterconnected representations of legal knowledge. Through a detailed analysis\nof Graph RAG and its application to legal norm datasets, this article aims to\nsignificantly advance the field of Artificial Intelligence applied to Law,\ncreating opportunities for more effective systems in legal research,\nlegislative analysis, and decision support."}
{"id": "2505.00091", "pdf": "https://arxiv.org/pdf/2505.00091", "abs": "https://arxiv.org/abs/2505.00091", "authors": ["Tengchao Zhang", "Yonglin Tian", "Fei Lin", "Jun Huang", "Rui Qin", "Fei-Yue Wang"], "title": "CoordField: Coordination Field for Agentic UAV Task Allocation In Low-altitude Urban Scenarios", "categories": ["cs.RO", "cs.AI"], "comment": "Submitted ITSC 2025", "summary": "With the increasing demand for heterogeneous Unmanned Aerial Vehicle (UAV)\nswarms to perform complex tasks in urban environments, system design now faces\nmajor challenges, including efficient semantic understanding, flexible task\nplanning, and the ability to dynamically adjust coordination strategies in\nresponse to evolving environmental conditions and continuously changing task\nrequirements. To address the limitations of existing approaches, this paper\nproposes coordination field agentic system for coordinating heterogeneous UAV\nswarms in complex urban scenarios. In this system, large language models (LLMs)\nis responsible for interpreting high-level human instructions and converting\nthem into executable commands for the UAV swarms, such as patrol and target\ntracking. Subsequently, a Coordination field mechanism is proposed to guide UAV\nmotion and task selection, enabling decentralized and adaptive allocation of\nemergent tasks. A total of 50 rounds of comparative testing were conducted\nacross different models in a 2D simulation space to evaluate their performance.\nExperimental results demonstrate that the proposed system achieves superior\nperformance in terms of task coverage, response time, and adaptability to\ndynamic changes."}
{"id": "2505.00482", "pdf": "https://arxiv.org/pdf/2505.00482", "abs": "https://arxiv.org/abs/2505.00482", "authors": ["Kwon Byung-Ki", "Qi Dai", "Lee Hyoseok", "Chong Luo", "Tae-Hyun Oh"], "title": "JointDiT: Enhancing RGB-Depth Joint Modeling with Diffusion Transformers", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We present JointDiT, a diffusion transformer that models the joint\ndistribution of RGB and depth. By leveraging the architectural benefit and\noutstanding image prior of the state-of-the-art diffusion transformer, JointDiT\nnot only generates high-fidelity images but also produces geometrically\nplausible and accurate depth maps. This solid joint distribution modeling is\nachieved through two simple yet effective techniques that we propose, i.e.,\nadaptive scheduling weights, which depend on the noise levels of each modality,\nand the unbalanced timestep sampling strategy. With these techniques, we train\nour model across all noise levels for each modality, enabling JointDiT to\nnaturally handle various combinatorial generation tasks, including joint\ngeneration, depth estimation, and depth-conditioned image generation by simply\ncontrolling the timestep of each branch. JointDiT demonstrates outstanding\njoint generation performance. Furthermore, it achieves comparable results in\ndepth estimation and depth-conditioned image generation, suggesting that joint\ndistribution modeling can serve as a replaceable alternative to conditional\ngeneration. The project page is available at\nhttps://byungki-k.github.io/JointDiT/."}
{"id": "2505.00333", "pdf": "https://arxiv.org/pdf/2505.00333", "abs": "https://arxiv.org/abs/2505.00333", "authors": ["Bumjun Kim", "Wan Choi"], "title": "Communication-Efficient Wireless Federated Fine-Tuning for Large-Scale AI Models", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Transformer-based large language models (LLMs) have achieved remarkable\nsuccess across various tasks. Yet, fine-tuning such massive models in federated\nlearning (FL) settings poses significant challenges due to resource constraints\nand communication overhead. Low-Rank Adaptation (LoRA) addresses these issues\nby training compact, low-rank matrices instead of fully fine-tuning large\nmodels. This paper introduces a wireless federated LoRA fine-tuning framework\nthat optimizes both learning performance and communication efficiency. We\nprovide a novel convergence analysis, revealing how LoRA rank and covariance\neffects influence FL training dynamics. Leveraging these insights, we propose\nSparsified Orthogonal Fine-Tuning (\\textbf{SOFT}), an adaptive sparsification\nmethod that streamlines parameter updates without expensive matrix\nmultiplications and singular value decomposition (SVD) operations.\nAdditionally, we present a Two Stage Federated Algorithm (\\textbf{TSFA})\nalgorithm that pre-determines key parameters offline and dynamically adjusts\nbandwidth and sparsification online, ensuring efficient training under latency\nconstraints. Experiments on benchmark datasets show that our approach achieves\naccuracy comparable to ideal scenario models while significantly reducing\ncommunication overhead. Our framework thus enables scalable, resource-efficient\ndeployment of large models in real-world wireless FL scenarios."}
{"id": "2505.00047", "pdf": "https://arxiv.org/pdf/2505.00047", "abs": "https://arxiv.org/abs/2505.00047", "authors": ["Peter West", "Christopher Potts"], "title": "Base Models Beat Aligned Models at Randomness and Creativity", "categories": ["cs.CL"], "comment": null, "summary": "Alignment has quickly become a default ingredient in LLM development, with\ntechniques such as reinforcement learning from human feedback making models act\nsafely, follow instructions, and perform ever-better on complex tasks. While\nthese techniques are certainly useful, we propose that they should not be\nuniversally applied and demonstrate a range of tasks on which base language\nmodels consistently outperform their popular aligned forms. Particularly, we\nstudy tasks that require unpredictable outputs, such as random number\ngeneration, mixed strategy games (rock-paper-scissors and hide-and-seek), and\ncreative writing. In each case, aligned models tend towards narrow behaviors\nthat result in distinct disadvantages, for instance, preferring to generate \"7\"\nover other uniformly random numbers, becoming almost fully predictable in some\ngame states, or prioritizing pleasant writing over creative originality. Across\nmodels tested, better performance on common benchmarks tends to correlate with\nworse performance on our tasks, suggesting an effective trade-off in the\nrequired capabilities."}
{"id": "2505.00100", "pdf": "https://arxiv.org/pdf/2505.00100", "abs": "https://arxiv.org/abs/2505.00100", "authors": ["Ethan Dickey", "Andres Bejarano", "Rhianna Kuperus", "Bárbara Fagundes"], "title": "Evaluating the AI-Lab Intervention: Impact on Student Perception and Use of Generative AI in Early Undergraduate Computer Science Courses", "categories": ["cs.CY", "cs.AI", "cs.ET", "K.3"], "comment": "18 pages, 5 figures, 17 tables, submitted for publication", "summary": "Generative AI (GenAI) is rapidly entering computer science education, yet its\neffects on student learning, skill development, and perceptions remain\nunderexplored. Concerns about overreliance coexist with a gap in research on\nstructured scaffolding to guide tool use in formal courses. This study examines\nthe impact of a dedicated \"AI-Lab\" intervention -- emphasizing guided\nscaffolding and mindful engagement -- on undergraduate students in Data\nStructures and Algorithms, Competitive Programming, and first-year engineering\ncourses at Purdue University.\n  Over three semesters, we integrated AI-Lab modules into four mandatory and\nelective courses, yielding 831 matched pre- and post-intervention survey\nresponses, alongside focus group discussions. Employing a mixed-methods\napproach, we analyzed quantitative shifts in usage patterns and attitudes as\nwell as qualitative narratives of student experiences.\n  While the overall frequency of GenAI usage for homework or programming\nprojects remained largely stable, we observed large effect sizes in comfort and\nopenness across conceptual, debugging, and homework problems. Notably, usage\npatterns for debugging also shifted statistically significantly, reflecting\nstudents' more mindful and deliberate approach. Focus group discussions\ncorroborated these results, suggesting that the intervention \"bridged the gap\"\nbetween naive GenAI usage and more nuanced, reflective integration of AI tools\ninto coursework, ultimately heightening students' awareness of their own skill\ndevelopment.\n  These findings suggest that structured, scaffolded interventions can enable\nstudents to harness GenAI's benefits without undermining essential\ncompetencies. We offer evidence-based recommendations for educators seeking to\nintegrate GenAI responsibly into computing curricula and identify avenues for\nfuture research on GenAI-supported pedagogy."}
{"id": "2505.00497", "pdf": "https://arxiv.org/pdf/2505.00497", "abs": "https://arxiv.org/abs/2505.00497", "authors": ["Antoni Bigata", "Rodrigo Mira", "Stella Bounareli", "Michał Stypułkowski", "Konstantinos Vougioukas", "Stavros Petridis", "Maja Pantic"], "title": "KeySync: A Robust Approach for Leakage-free Lip Synchronization in High Resolution", "categories": ["cs.CV"], "comment": null, "summary": "Lip synchronization, known as the task of aligning lip movements in an\nexisting video with new input audio, is typically framed as a simpler variant\nof audio-driven facial animation. However, as well as suffering from the usual\nissues in talking head generation (e.g., temporal consistency), lip\nsynchronization presents significant new challenges such as expression leakage\nfrom the input video and facial occlusions, which can severely impact\nreal-world applications like automated dubbing, but are often neglected in\nexisting works. To address these shortcomings, we present KeySync, a two-stage\nframework that succeeds in solving the issue of temporal consistency, while\nalso incorporating solutions for leakage and occlusions using a carefully\ndesigned masking strategy. We show that KeySync achieves state-of-the-art\nresults in lip reconstruction and cross-synchronization, improving visual\nquality and reducing expression leakage according to LipLeak, our novel leakage\nmetric. Furthermore, we demonstrate the effectiveness of our new masking\napproach in handling occlusions and validate our architectural choices through\nseveral ablation studies. Code and model weights can be found at\nhttps://antonibigata.github.io/KeySync."}
{"id": "2505.00337", "pdf": "https://arxiv.org/pdf/2505.00337", "abs": "https://arxiv.org/abs/2505.00337", "authors": ["Xuyang Guo", "Jiayan Huo", "Zhenmei Shi", "Zhao Song", "Jiahao Zhang", "Jiale Zhao"], "title": "T2VPhysBench: A First-Principles Benchmark for Physical Consistency in Text-to-Video Generation", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Text-to-video generative models have made significant strides in recent\nyears, producing high-quality videos that excel in both aesthetic appeal and\naccurate instruction following, and have become central to digital art creation\nand user engagement online. Yet, despite these advancements, their ability to\nrespect fundamental physical laws remains largely untested: many outputs still\nviolate basic constraints such as rigid-body collisions, energy conservation,\nand gravitational dynamics, resulting in unrealistic or even misleading\ncontent. Existing physical-evaluation benchmarks typically rely on automatic,\npixel-level metrics applied to simplistic, life-scenario prompts, and thus\noverlook both human judgment and first-principles physics. To fill this gap, we\nintroduce \\textbf{T2VPhysBench}, a first-principled benchmark that\nsystematically evaluates whether state-of-the-art text-to-video systems, both\nopen-source and commercial, obey twelve core physical laws including Newtonian\nmechanics, conservation principles, and phenomenological effects. Our benchmark\nemploys a rigorous human evaluation protocol and includes three targeted\nstudies: (1) an overall compliance assessment showing that all models score\nbelow 0.60 on average in each law category; (2) a prompt-hint ablation\nrevealing that even detailed, law-specific hints fail to remedy physics\nviolations; and (3) a counterfactual robustness test demonstrating that models\noften generate videos that explicitly break physical rules when so instructed.\nThe results expose persistent limitations in current architectures and offer\nconcrete insights for guiding future research toward truly physics-aware video\ngeneration."}
{"id": "2505.00057", "pdf": "https://arxiv.org/pdf/2505.00057", "abs": "https://arxiv.org/abs/2505.00057", "authors": ["Zhu Jiawei", "Chen Wei"], "title": "A Report on the llms evaluating the high school questions", "categories": ["cs.CL"], "comment": null, "summary": "This report aims to evaluate the performance of large language models (LLMs)\nin solving high school science questions and to explore their potential\napplications in the educational field. With the rapid development of LLMs in\nthe field of natural language processing, their application in education has\nattracted widespread attention. This study selected mathematics exam questions\nfrom the college entrance examinations (2019-2023) as evaluation data and\nutilized at least eight LLM APIs to provide answers. A comprehensive assessment\nwas conducted based on metrics such as accuracy, response time, logical\nreasoning, and creativity. Through an in-depth analysis of the evaluation\nresults, this report reveals the strengths and weaknesses of LLMs in handling\nhigh school science questions and discusses their implications for educational\npractice. The findings indicate that although LLMs perform excellently in\ncertain aspects, there is still room for improvement in logical reasoning and\ncreative problem-solving. This report provides an empirical foundation for\nfurther research and application of LLMs in the educational field and offers\nsuggestions for improvement."}
{"id": "2505.00114", "pdf": "https://arxiv.org/pdf/2505.00114", "abs": "https://arxiv.org/abs/2505.00114", "authors": ["Silvana Yakhni", "Ali Chehab"], "title": "Fine-Tuning LLMs for Low-Resource Dialect Translation: The Case of Lebanese", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This paper examines the effectiveness of Large Language Models (LLMs) in\ntranslating the low-resource Lebanese dialect, focusing on the impact of\nculturally authentic data versus larger translated datasets. We compare three\nfine-tuning approaches: Basic, contrastive, and grammar-hint tuning, using\nopen-source Aya23 models. Experiments reveal that models fine-tuned on a\nsmaller but culturally aware Lebanese dataset (LW) consistently outperform\nthose trained on larger, non-native data. The best results were achieved\nthrough contrastive fine-tuning paired with contrastive prompting, which\nindicates the benefits of exposing translation models to bad examples. In\naddition, to ensure authentic evaluation, we introduce LebEval, a new benchmark\nderived from native Lebanese content, and compare it to the existing FLoRes\nbenchmark. Our findings challenge the \"More Data is Better\" paradigm and\nemphasize the crucial role of cultural authenticity in dialectal translation.\nWe made our datasets and code available on Github."}
{"id": "2505.00502", "pdf": "https://arxiv.org/pdf/2505.00502", "abs": "https://arxiv.org/abs/2505.00502", "authors": ["Suho Ryu", "Kihyun Kim", "Eugene Baek", "Dongsoo Shin", "Joonseok Lee"], "title": "Towards Scalable Human-aligned Benchmark for Text-guided Image Editing", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2025 (highlight)", "summary": "A variety of text-guided image editing models have been proposed recently.\nHowever, there is no widely-accepted standard evaluation method mainly due to\nthe subjective nature of the task, letting researchers rely on manual user\nstudy. To address this, we introduce a novel Human-Aligned benchmark for\nText-guided Image Editing (HATIE). Providing a large-scale benchmark set\ncovering a wide range of editing tasks, it allows reliable evaluation, not\nlimited to specific easy-to-evaluate cases. Also, HATIE provides a\nfully-automated and omnidirectional evaluation pipeline. Particularly, we\ncombine multiple scores measuring various aspects of editing so as to align\nwith human perception. We empirically verify that the evaluation of HATIE is\nindeed human-aligned in various aspects, and provide benchmark results on\nseveral state-of-the-art models to provide deeper insights on their\nperformance."}
{"id": "2505.00347", "pdf": "https://arxiv.org/pdf/2505.00347", "abs": "https://arxiv.org/abs/2505.00347", "authors": ["Cong Xu", "Wenbin Liang", "Mo Yu", "Anan Liu", "Ke-Yue Zhang", "Lizhuang Ma", "Jianyong Wang", "Jun Wang", "Wei Zhang"], "title": "Pushing the Limits of Low-Bit Optimizers: A Focus on EMA Dynamics", "categories": ["cs.LG", "cs.AI"], "comment": "27 pages", "summary": "The explosion in model sizes leads to continued growth in prohibitive\ntraining/fine-tuning costs, particularly for stateful optimizers which maintain\nauxiliary information of even 2x the model size to achieve optimal convergence.\nWe therefore present in this work a novel type of optimizer that carries with\nextremely lightweight state overloads, achieved through ultra-low-precision\nquantization. While previous efforts have achieved certain success with 8-bit\nor 4-bit quantization, our approach enables optimizers to operate at precision\nas low as 3 bits, or even 2 bits per state element. This is accomplished by\nidentifying and addressing two critical challenges: the signal swamping problem\nin unsigned quantization that results in unchanged state dynamics, and the\nrapidly increased gradient variance in signed quantization that leads to\nincorrect descent directions. The theoretical analysis suggests a tailored\nlogarithmic quantization for the former and a precision-specific momentum value\nfor the latter. Consequently, the proposed SOLO achieves substantial memory\nsavings (approximately 45 GB when training a 7B model) with minimal accuracy\nloss. We hope that SOLO can contribute to overcoming the bottleneck in\ncomputational resources, thereby promoting greater accessibility in fundamental\nresearch."}
{"id": "2505.00061", "pdf": "https://arxiv.org/pdf/2505.00061", "abs": "https://arxiv.org/abs/2505.00061", "authors": ["Sahar Yarmohammadtoosky", "Yiyun Zhou", "Victoria Yaneva", "Peter Baldwin", "Saed Rezayi", "Brian Clauser", "Polina Harikeo"], "title": "Enhancing Security and Strengthening Defenses in Automated Short-Answer Grading Systems", "categories": ["cs.CL", "cs.CR"], "comment": null, "summary": "This study examines vulnerabilities in transformer-based automated\nshort-answer grading systems used in medical education, with a focus on how\nthese systems can be manipulated through adversarial gaming strategies. Our\nresearch identifies three main types of gaming strategies that exploit the\nsystem's weaknesses, potentially leading to false positives. To counteract\nthese vulnerabilities, we implement several adversarial training methods\ndesigned to enhance the systems' robustness. Our results indicate that these\nmethods significantly reduce the susceptibility of grading systems to such\nmanipulations, especially when combined with ensemble techniques like majority\nvoting and ridge regression, which further improve the system's defense against\nsophisticated adversarial inputs. Additionally, employing large language models\nsuch as GPT-4 with varied prompting techniques has shown promise in recognizing\nand scoring gaming strategies effectively. The findings underscore the\nimportance of continuous improvements in AI-driven educational tools to ensure\ntheir reliability and fairness in high-stakes settings."}
{"id": "2505.00127", "pdf": "https://arxiv.org/pdf/2505.00127", "abs": "https://arxiv.org/abs/2505.00127", "authors": ["Jinyan Su", "Jennifer Healey", "Preslav Nakov", "Claire Cardie"], "title": "Between Underthinking and Overthinking: An Empirical Study of Reasoning Length and correctness in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly optimized for long reasoning,\nunder the assumption that more reasoning leads to better performance. However,\nemerging evidence suggests that longer responses can sometimes degrade accuracy\nrather than improve it. In this paper, we conduct a systematic empirical study\nof the relationship between reasoning length and answer correctness. We find\nthat LLMs tend to overthink simple problems, generating unnecessarily long\noutputs, and underthink harder ones, failing to extend their reasoning when it\nis most needed. This indicates that models might misjudge problem difficulty\nand fail to calibrate their response length appropriately. Furthermore, we\ninvestigate the effects of length reduction with a preference optimization\nalgorithm when simply preferring the shorter responses regardless of answer\ncorrectness. Experiments show that the generation length can be significantly\nreduced while maintaining acceptable accuracy. Our findings highlight\ngeneration length as a meaningful signal for reasoning behavior and motivate\nfurther exploration into LLMs' self-awareness in reasoning length adaptation."}
{"id": "2505.00507", "pdf": "https://arxiv.org/pdf/2505.00507", "abs": "https://arxiv.org/abs/2505.00507", "authors": ["Esteban Rivera", "Surya Prabhakaran", "Markus Lienkamp"], "title": "HeAL3D: Heuristical-enhanced Active Learning for 3D Object Detection", "categories": ["cs.CV"], "comment": "Accepted in CVPR2025", "summary": "Active Learning has proved to be a relevant approach to perform sample\nselection for training models for Autonomous Driving. Particularly, previous\nworks on active learning for 3D object detection have shown that selection of\nsamples in uncontrolled scenarios is challenging. Furthermore, current\napproaches focus exclusively on the theoretical aspects of the sample selection\nproblem but neglect the practical insights that can be obtained from the\nextensive literature and application of 3D detection models. In this paper, we\nintroduce HeAL (Heuristical-enhanced Active Learning for 3D Object Detection)\nwhich integrates those heuristical features together with Localization and\nClassification to deliver the most contributing samples to the model's\ntraining. In contrast to previous works, our approach integrates heuristical\nfeatures such as object distance and point-quantity to estimate the\nuncertainty, which enhance the usefulness of selected samples to train\ndetection models. Our quantitative evaluation on KITTI shows that HeAL presents\ncompetitive mAP with respect to the State-of-the-Art, and achieves the same mAP\nas the full-supervised baseline with only 24% of the samples."}
{"id": "2505.00348", "pdf": "https://arxiv.org/pdf/2505.00348", "abs": "https://arxiv.org/abs/2505.00348", "authors": ["Ehtisham Asghar", "Martin Hill", "Ibrahim Sengor", "Conor Lynch", "Phan Quang An"], "title": "Validation of a 24-hour-ahead Prediction model for a Residential Electrical Load under diverse climate", "categories": ["cs.LG"], "comment": null, "summary": "Accurate household electrical energy demand prediction is essential for\neffectively managing sustainable Energy Communities. Integrated with the Energy\nManagement System, these communities aim to optimise operational costs.\nHowever, most existing forecasting models are region-specific and depend on\nlarge datasets, limiting their applicability across different climates and\ngeographical areas. These models often lack flexibility and may not perform\nwell in regions with limited historical data, leading to inaccurate\npredictions. This paper proposes a global model for 24-hour-ahead hourly\nelectrical energy demand prediction that is designed to perform effectively\nacross diverse climate conditions and datasets. The model's efficiency is\ndemonstrated using data from two distinct regions: Ireland, with a maritime\nclimate and Vietnam, with a tropical climate. Remarkably, the model achieves\nhigh accuracy even with a limited dataset spanning only nine months. Its\nrobustness is further validated across different seasons in Ireland (summer and\nwinter) and Vietnam (dry and wet). The proposed model is evaluated against\nstate-of-the-art machine learning and deep learning methods. Simulation results\nindicate that the model consistently outperforms benchmark models, showcasing\nits capability to provide reliable forecasts globally, regardless of varying\nclimatic conditions and data availability. This research underscores the\nmodel's potential to enhance the efficiency and sustainability of Energy\nCommunities worldwide. The proposed model achieves a Mean Absolute Percentage\nError of 8.0% and 4.0% on the full Irish and Vietnamese datasets."}
{"id": "2505.00063", "pdf": "https://arxiv.org/pdf/2505.00063", "abs": "https://arxiv.org/abs/2505.00063", "authors": ["Siqi Li", "Yufan Shen", "Xiangnan Chen", "Jiayi Chen", "Hengwei Ju", "Haodong Duan", "Song Mao", "Hongbin Zhou", "Bo Zhang", "Pinlong Cai", "Licheng Wen", "Botian Shi", "Yong Liu", "Xinyu Cai", "Yu Qiao"], "title": "GDI-Bench: A Benchmark for General Document Intelligence with Vision and Reasoning Decoupling", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "The rapid advancement of multimodal large language models (MLLMs) has\nprofoundly impacted the document domain, creating a wide array of application\nscenarios. This progress highlights the need for a comprehensive benchmark to\nevaluate these models' capabilities across various document-specific tasks.\nHowever, existing benchmarks often fail to locate specific model weaknesses or\nguide systematic improvements. To bridge this gap, we introduce a General\nDocument Intelligence Benchmark (GDI-Bench), featuring 1.9k images across 9 key\nscenarios and 19 document-specific tasks. By decoupling visual complexity and\nreasoning complexity, the GDI-Bench structures graded tasks that allow\nperformance assessment by difficulty, aiding in model weakness identification\nand optimization guidance. We evaluate the GDI-Bench on various open-source and\nclosed-source models, conducting decoupled analyses in the visual and reasoning\ndomains. For instance, the GPT-4o model excels in reasoning tasks but exhibits\nlimitations in visual capabilities. To address the diverse tasks and domains in\nthe GDI-Bench, we propose a GDI Model that mitigates the issue of catastrophic\nforgetting during the supervised fine-tuning (SFT) process through a\nintelligence-preserving training strategy. Our model achieves state-of-the-art\nperformance on previous benchmarks and the GDI-Bench. Both our benchmark and\nmodel will be open source."}
{"id": "2505.00186", "pdf": "https://arxiv.org/pdf/2505.00186", "abs": "https://arxiv.org/abs/2505.00186", "authors": ["Rafael C. Pinto", "Anderson R. Tavares"], "title": "Neuroevolution of Self-Attention Over Proto-Objects", "categories": ["cs.NE", "cs.AI", "cs.CV"], "comment": "9 pages, 16 figures, GECCO", "summary": "Proto-objects - image regions that share common visual properties - offer a\npromising alternative to traditional attention mechanisms based on\nrectangular-shaped image patches in neural networks. Although previous work\ndemonstrated that evolving a patch-based hard-attention module alongside a\ncontroller network could achieve state-of-the-art performance in visual\nreinforcement learning tasks, our approach leverages image segmentation to work\nwith higher-level features. By operating on proto-objects rather than fixed\npatches, we significantly reduce the representational complexity: each image\ndecomposes into fewer proto-objects than regular patches, and each proto-object\ncan be efficiently encoded as a compact feature vector. This enables a\nsubstantially smaller self-attention module that processes richer semantic\ninformation. Our experiments demonstrate that this proto-object-based approach\nmatches or exceeds the state-of-the-art performance of patch-based\nimplementations with 62% less parameters and 2.6 times less training time."}
{"id": "2505.00511", "pdf": "https://arxiv.org/pdf/2505.00511", "abs": "https://arxiv.org/abs/2505.00511", "authors": ["Esteban Rivera", "Loic Stratil", "Markus Lienkamp"], "title": "Inconsistency-based Active Learning for LiDAR Object Detection", "categories": ["cs.CV"], "comment": "Accepted in IV2025", "summary": "Deep learning models for object detection in autonomous driving have recently\nachieved impressive performance gains and are already being deployed in\nvehicles worldwide. However, current models require increasingly large datasets\nfor training. Acquiring and labeling such data is costly, necessitating the\ndevelopment of new strategies to optimize this process. Active learning is a\npromising approach that has been extensively researched in the image domain. In\nour work, we extend this concept to the LiDAR domain by developing several\ninconsistency-based sample selection strategies and evaluate their\neffectiveness in various settings. Our results show that using a naive\ninconsistency approach based on the number of detected boxes, we achieve the\nsame mAP as the random sampling strategy with 50% of the labeled data."}
{"id": "2505.00350", "pdf": "https://arxiv.org/pdf/2505.00350", "abs": "https://arxiv.org/abs/2505.00350", "authors": ["Mohammad Zbeeb", "Mariam Salman", "Mohammad Bazzi", "Ammar Mohanna"], "title": "Optimizing Deep Neural Networks using Safety-Guided Self Compression", "categories": ["cs.LG", "cs.AI"], "comment": "A Preprint", "summary": "The deployment of deep neural networks on resource-constrained devices\nnecessitates effective model com- pression strategies that judiciously balance\nthe reduction of model size with the preservation of performance. This study\nintroduces a novel safety-driven quantization framework that leverages\npreservation sets to systematically prune and quantize neural network weights,\nthereby optimizing model complexity without compromising accuracy. The proposed\nmethodology is rigorously evaluated on both a convolutional neural network\n(CNN) and an attention-based language model, demonstrating its applicability\nacross diverse architectural paradigms. Experimental results reveal that our\nframework achieves up to a 2.5% enhancement in test accuracy relative to the\noriginal unquantized models while maintaining 60% of the initial model size. In\ncomparison to conventional quantization techniques, our approach not only\naugments generalization by eliminating parameter noise and retaining essential\nweights but also reduces variance, thereby ensuring the retention of critical\nmodel features. These findings underscore the efficacy of safety-driven\nquantization as a robust and reliable strategy for the efficient optimization\nof deep learn- ing models. The implementation and comprehensive experimental\nevaluations of our framework are publicly accessible at GitHub."}
{"id": "2505.00065", "pdf": "https://arxiv.org/pdf/2505.00065", "abs": "https://arxiv.org/abs/2505.00065", "authors": ["Ivan Vankov", "Matyo Ivanov", "Adriana Correia", "Victor Botev"], "title": "ConSens: Assessing context grounding in open-book question answering", "categories": ["cs.CL", "cs.LG"], "comment": "9 pages, 3 figures, 3 tables", "summary": "Large Language Models (LLMs) have demonstrated considerable success in\nopen-book question answering (QA), where the task requires generating answers\ngrounded in a provided external context. A critical challenge in open-book QA\nis to ensure that model responses are based on the provided context rather than\nits parametric knowledge, which can be outdated, incomplete, or incorrect.\nExisting evaluation methods, primarily based on the LLM-as-a-judge approach,\nface significant limitations, including biases, scalability issues, and\ndependence on costly external systems. To address these challenges, we propose\na novel metric that contrasts the perplexity of the model response under two\nconditions: when the context is provided and when it is not. The resulting\nscore quantifies the extent to which the model's answer relies on the provided\ncontext. The validity of this metric is demonstrated through a series of\nexperiments that show its effectiveness in identifying whether a given answer\nis grounded in the provided context. Unlike existing approaches, this metric is\ncomputationally efficient, interpretable, and adaptable to various use cases,\noffering a scalable and practical solution to assess context utilization in\nopen-book QA systems."}
{"id": "2505.00222", "pdf": "https://arxiv.org/pdf/2505.00222", "abs": "https://arxiv.org/abs/2505.00222", "authors": ["Peter Yichen Chen", "Pingchuan Ma", "Niklas Hagemann", "John Romanishin", "Wei Wang", "Daniela Rus", "Wojciech Matusik"], "title": "AI-Enhanced Automatic Design of Efficient Underwater Gliders", "categories": ["cs.RO", "cs.AI", "cs.GR", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "The development of novel autonomous underwater gliders has been hindered by\nlimited shape diversity, primarily due to the reliance on traditional design\ntools that depend heavily on manual trial and error. Building an automated\ndesign framework is challenging due to the complexities of representing glider\nshapes and the high computational costs associated with modeling complex\nsolid-fluid interactions. In this work, we introduce an AI-enhanced automated\ncomputational framework designed to overcome these limitations by enabling the\ncreation of underwater robots with non-trivial hull shapes. Our approach\ninvolves an algorithm that co-optimizes both shape and control signals,\nutilizing a reduced-order geometry representation and a differentiable\nneural-network-based fluid surrogate model. This end-to-end design workflow\nfacilitates rapid iteration and evaluation of hydrodynamic performance, leading\nto the discovery of optimal and complex hull shapes across various control\nsettings. We validate our method through wind tunnel experiments and swimming\npool gliding tests, demonstrating that our computationally designed gliders\nsurpass manually designed counterparts in terms of energy efficiency. By\naddressing challenges in efficient shape representation and neural fluid\nsurrogate models, our work paves the way for the development of highly\nefficient underwater gliders, with implications for long-range ocean\nexploration and environmental monitoring."}
{"id": "2505.00512", "pdf": "https://arxiv.org/pdf/2505.00512", "abs": "https://arxiv.org/abs/2505.00512", "authors": ["Nguyen Hoang Khoi Tran", "Julie Stephany Berrio", "Mao Shan", "Zhenxing Ming", "Stewart Worrall"], "title": "InterLoc: LiDAR-based Intersection Localization using Road Segmentation with Automated Evaluation Method", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Intersections are geometric and functional key points in every road network.\nThey offer strong landmarks to correct GNSS dropouts and anchor new sensor data\nin up-to-date maps. Despite that importance, intersection detectors either\nignore the rich semantic information already computed onboard or depend on\nscarce, hand-labeled intersection datasets. To close that gap, this paper\npresents a LiDAR-based method for intersection detection that (i) fuses\nsemantic road segmentation with vehicle localization to detect intersection\ncandidates in a bird's eye view (BEV) representation and (ii) refines those\ncandidates by analyzing branch topology with a least squares formulation. To\nevaluate our method, we introduce an automated benchmarking pipeline that pairs\ndetections with OpenStreetMap (OSM) intersection nodes using precise GNSS/INS\nground-truth poses. Tested on eight SemanticKITTI sequences, the approach\nachieves a mean localization error of 1.9 m, 89% precision, and 77% recall at a\n5 m tolerance, outperforming the latest learning-based baseline. Moreover, the\nmethod is robust to segmentation errors higher than those of the benchmark\nmodel, demonstrating its applicability in the real world."}
{"id": "2505.00358", "pdf": "https://arxiv.org/pdf/2505.00358", "abs": "https://arxiv.org/abs/2505.00358", "authors": ["Albert Ge", "Tzu-Heng Huang", "John Cooper", "Avi Trost", "Ziyi Chu", "Satya Sai Srinath Namburi GNVV", "Ziyang Cai", "Kendall Park", "Nicholas Roberts", "Frederic Sala"], "title": "R&B: Domain Regrouping and Data Mixture Balancing for Efficient Foundation Model Training", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Data mixing strategies have successfully reduced the costs involved in\ntraining language models. While promising, such methods suffer from two flaws.\nFirst, they rely on predetermined data domains (e.g., data sources, task\ntypes), which may fail to capture critical semantic nuances, leaving\nperformance on the table. Second, these methods scale with the number of\ndomains in a computationally prohibitive way. We address these challenges via\nR&B, a framework that re-partitions training data based on semantic similarity\n(Regroup) to create finer-grained domains, and efficiently optimizes the data\ncomposition (Balance) by leveraging a Gram matrix induced by domain gradients\nobtained throughout training. Unlike prior works, it removes the need for\nadditional compute to obtain evaluation information such as losses or\ngradients. We analyze this technique under standard regularity conditions and\nprovide theoretical insights that justify R&B's effectiveness compared to\nnon-adaptive mixing approaches. Empirically, we demonstrate the effectiveness\nof R&B on five diverse datasets ranging from natural language to reasoning and\nmultimodal tasks. With as little as 0.01% additional compute overhead, R&B\nmatches or exceeds the performance of state-of-the-art data mixing strategies."}
{"id": "2505.00147", "pdf": "https://arxiv.org/pdf/2505.00147", "abs": "https://arxiv.org/abs/2505.00147", "authors": ["Yinghui He", "Abhishek Panigrahi", "Yong Lin", "Sanjeev Arora"], "title": "AdaptMI: Adaptive Skill-based In-context Math Instruction for Small Language Models", "categories": ["cs.CL"], "comment": null, "summary": "In-context learning (ICL) allows a language model to improve its\nproblem-solving capability when provided with suitable information in context.\nSince the choice of in-context information can be determined based on the\nproblem itself, in-context learning is analogous to human learning from\nteachers in a classroom. Recent works (Didolkar et al., 2024a; 2024b) show that\nICL performance can be improved by leveraging a frontier large language model's\n(LLM) ability to predict required skills to solve a problem, popularly referred\nto as an LLM's metacognition, and using the recommended skills to construct\nnecessary in-context examples. While this skill-based strategy boosts ICL\nperformance in larger models, its gains on small language models (SLMs) have\nbeen minimal, highlighting a performance gap in ICL capabilities. We\ninvestigate this gap and show that skill-based prompting can hurt SLM\nperformance on easy questions by introducing unnecessary information, akin to\ncognitive overload. To address this, we introduce AdaptMI, an adaptive approach\nto selecting skill-based in-context Math Instructions for SLMs. Inspired by\ncognitive load theory from human pedagogy, our method only introduces\nskill-based examples when the model performs poorly. We further propose\nAdaptMI+, which adds examples targeted to the specific skills missing from the\nmodel's responses. On 5-shot evaluations across popular math benchmarks and\nfive SLMs (1B--7B; Qwen, Llama), AdaptMI+ improves accuracy by up to 6% over\nnaive skill-based strategies."}
{"id": "2505.00240", "pdf": "https://arxiv.org/pdf/2505.00240", "abs": "https://arxiv.org/abs/2505.00240", "authors": ["Yazan Otoum", "Arghavan Asad", "Amiya Nayak"], "title": "LLM-Based Threat Detection and Prevention Framework for IoT Ecosystems", "categories": ["cs.CR", "cs.AI", "cs.ET", "cs.LG"], "comment": "Preprint version; submitted for academic peer review", "summary": "The increasing complexity and scale of the Internet of Things (IoT) have made\nsecurity a critical concern. This paper presents a novel Large Language Model\n(LLM)-based framework for comprehensive threat detection and prevention in IoT\nenvironments. The system integrates lightweight LLMs fine-tuned on IoT-specific\ndatasets (IoT-23, TON_IoT) for real-time anomaly detection and automated,\ncontext-aware mitigation strategies optimized for resource-constrained devices.\nA modular Docker-based deployment enables scalable and reproducible evaluation\nacross diverse network conditions. Experimental results in simulated IoT\nenvironments demonstrate significant improvements in detection accuracy,\nresponse latency, and resource efficiency over traditional security methods.\nThe proposed framework highlights the potential of LLM-driven, autonomous\nsecurity solutions for future IoT ecosystems."}
{"id": "2505.00534", "pdf": "https://arxiv.org/pdf/2505.00534", "abs": "https://arxiv.org/abs/2505.00534", "authors": ["Muhammad Imran Zaman", "Usama Ijaz Bajwa", "Gulshan Saleem", "Rana Hammad Raza"], "title": "A Robust Deep Networks based Multi-Object MultiCamera Tracking System for City Scale Traffic", "categories": ["cs.CV"], "comment": null, "summary": "Vision sensors are becoming more important in Intelligent Transportation\nSystems (ITS) for traffic monitoring, management, and optimization as the\nnumber of network cameras continues to rise. However, manual object tracking\nand matching across multiple non-overlapping cameras pose significant\nchallenges in city-scale urban traffic scenarios. These challenges include\nhandling diverse vehicle attributes, occlusions, illumination variations,\nshadows, and varying video resolutions. To address these issues, we propose an\nefficient and cost-effective deep learning-based framework for Multi-Object\nMulti-Camera Tracking (MO-MCT). The proposed framework utilizes Mask R-CNN for\nobject detection and employs Non-Maximum Suppression (NMS) to select target\nobjects from overlapping detections. Transfer learning is employed for\nre-identification, enabling the association and generation of vehicle tracklets\nacross multiple cameras. Moreover, we leverage appropriate loss functions and\ndistance measures to handle occlusion, illumination, and shadow challenges. The\nfinal solution identification module performs feature extraction using\nResNet-152 coupled with Deep SORT based vehicle tracking. The proposed\nframework is evaluated on the 5th AI City Challenge dataset (Track 3),\ncomprising 46 camera feeds. Among these 46 camera streams, 40 are used for\nmodel training and validation, while the remaining six are utilized for model\ntesting. The proposed framework achieves competitive performance with an IDF1\nscore of 0.8289, and precision and recall scores of 0.9026 and 0.8527\nrespectively, demonstrating its effectiveness in robust and accurate vehicle\ntracking."}
{"id": "2505.00359", "pdf": "https://arxiv.org/pdf/2505.00359", "abs": "https://arxiv.org/abs/2505.00359", "authors": ["Qifen Zeng", "Haomin Bao", "Yuanzhuo Hu", "Zirui Zhang", "Yuheng Zheng", "Luosheng Wen"], "title": "TNStream: Applying Tightest Neighbors to Micro-Clusters to Define Multi-Density Clusters in Streaming Data", "categories": ["cs.LG", "cs.AI", "cs.NE", "68T05, 68W20", "H.2.8; I.5.3"], "comment": "21 pages, 9 figures, 8 tables, under review at Expert Systems with\n  Applications (ESWA)", "summary": "In data stream clustering, systematic theory of stream clustering algorithms\nremains relatively scarce. Recently, density-based methods have gained\nattention. However, existing algorithms struggle to simultaneously handle\narbitrarily shaped, multi-density, high-dimensional data while maintaining\nstrong outlier resistance. Clustering quality significantly deteriorates when\ndata density varies complexly. This paper proposes a clustering algorithm based\non the novel concept of Tightest Neighbors and introduces a data stream\nclustering theory based on the Skeleton Set. Based on these theories, this\npaper develops a new method, TNStream, a fully online algorithm. The algorithm\nadaptively determines the clustering radius based on local similarity,\nsummarizing the evolution of multi-density data streams in micro-clusters. It\nthen applies a Tightest Neighbors-based clustering algorithm to form final\nclusters. To improve efficiency in high-dimensional cases, Locality-Sensitive\nHashing (LSH) is employed to structure micro-clusters, addressing the challenge\nof storing k-nearest neighbors. TNStream is evaluated on various synthetic and\nreal-world datasets using different clustering metrics. Experimental results\ndemonstrate its effectiveness in improving clustering quality for multi-density\ndata and validate the proposed data stream clustering theory."}
{"id": "2505.00191", "pdf": "https://arxiv.org/pdf/2505.00191", "abs": "https://arxiv.org/abs/2505.00191", "authors": ["Yuyan Ge", "Kwan Ho Ryan Chan", "Pablo Messina", "René Vidal"], "title": "IP-CRR: Information Pursuit for Interpretable Classification of Chest Radiology Reports", "categories": ["cs.CL"], "comment": "12 pages, 4 figures", "summary": "The development of AI-based methods for analyzing radiology reports could\nlead to significant advances in medical diagnosis--from improving diagnostic\naccuracy to enhancing efficiency and reducing workload. However, the lack of\ninterpretability in these methods has hindered their adoption in clinical\nsettings. In this paper, we propose an interpretable-by-design framework for\nclassifying radiology reports. The key idea is to extract a set of most\ninformative queries from a large set of reports and use these queries and their\ncorresponding answers to predict a diagnosis. Thus, the explanation for a\nprediction is, by construction, the set of selected queries and answers. We use\nthe Information Pursuit framework to select informative queries, the Flan-T5\nmodel to determine if facts are present in the report, and a classifier to\npredict the disease. Experiments on the MIMIC-CXR dataset demonstrate the\neffectiveness of the proposed method, highlighting its potential to enhance\ntrust and usability in medical AI."}
{"id": "2505.00268", "pdf": "https://arxiv.org/pdf/2505.00268", "abs": "https://arxiv.org/abs/2505.00268", "authors": ["Jekaterina Novikova", "Carol Anderson", "Borhane Blili-Hamelin", "Subhabrata Majumdar"], "title": "Consistency in Language Models: Current Landscape, Challenges, and Future Directions", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The hallmark of effective language use lies in consistency -- expressing\nsimilar meanings in similar contexts and avoiding contradictions. While human\ncommunication naturally demonstrates this principle, state-of-the-art language\nmodels struggle to maintain reliable consistency across different scenarios.\nThis paper examines the landscape of consistency research in AI language\nsystems, exploring both formal consistency (including logical rule adherence)\nand informal consistency (such as moral and factual coherence). We analyze\ncurrent approaches to measure aspects of consistency, identify critical\nresearch gaps in standardization of definitions, multilingual assessment, and\nmethods to improve consistency. Our findings point to an urgent need for robust\nbenchmarks to measure and interdisciplinary approaches to ensure consistency in\nthe application of language models on domain-specific tasks while preserving\nthe utility and adaptability."}
{"id": "2505.00564", "pdf": "https://arxiv.org/pdf/2505.00564", "abs": "https://arxiv.org/abs/2505.00564", "authors": ["Jorgen Cani", "Christos Diou", "Spyridon Evangelatos", "Panagiotis Radoglou-Grammatikis", "Vasileios Argyriou", "Panagiotis Sarigiannidis", "Iraklis Varlamis", "Georgios Th. Papadopoulos"], "title": "X-ray illicit object detection using hybrid CNN-transformer neural network architectures", "categories": ["cs.CV"], "comment": null, "summary": "In the field of X-ray security applications, even the smallest details can\nsignificantly impact outcomes. Objects that are heavily occluded or\nintentionally concealed pose a great challenge for detection, whether by human\nobservation or through advanced technological applications. While certain Deep\nLearning (DL) architectures demonstrate strong performance in processing local\ninformation, such as Convolutional Neural Networks (CNNs), others excel in\nhandling distant information, e.g., transformers. In X-ray security imaging the\nliterature has been dominated by the use of CNN-based methods, while the\nintegration of the two aforementioned leading architectures has not been\nsufficiently explored. In this paper, various hybrid CNN-transformer\narchitectures are evaluated against a common CNN object detection baseline,\nnamely YOLOv8. In particular, a CNN (HGNetV2) and a hybrid CNN-transformer\n(Next-ViT-S) backbone are combined with different CNN/transformer detection\nheads (YOLOv8 and RT-DETR). The resulting architectures are comparatively\nevaluated on three challenging public X-ray inspection datasets, namely EDS,\nHiXray, and PIDray. Interestingly, while the YOLOv8 detector with its default\nbackbone (CSP-DarkNet53) is generally shown to be advantageous on the HiXray\nand PIDray datasets, when a domain distribution shift is incorporated in the\nX-ray images (as happens in the EDS datasets), hybrid CNN-transformer\narchitectures exhibit increased robustness. Detailed comparative evaluation\nresults, including object-level detection performance and object-size error\nanalysis, demonstrate the strengths and weaknesses of each architectural\ncombination and suggest guidelines for future research. The source code and\nnetwork weights of the models employed in this study are available at\nhttps://github.com/jgenc/xray-comparative-evaluation."}
{"id": "2505.00364", "pdf": "https://arxiv.org/pdf/2505.00364", "abs": "https://arxiv.org/abs/2505.00364", "authors": ["Jie Yang", "Yuwen Wang", "Kaixuan Chen", "Tongya Zheng", "Yihe Zhou", "Zhenbang Xiao", "Ji Cao", "Mingli Song", "Shunyu Liu"], "title": "From GNNs to Trees: Multi-Granular Interpretability for Graph Neural Networks", "categories": ["cs.LG"], "comment": "Accepted by ICLR 2025", "summary": "Interpretable Graph Neural Networks (GNNs) aim to reveal the underlying\nreasoning behind model predictions, attributing their decisions to specific\nsubgraphs that are informative. However, existing subgraph-based interpretable\nmethods suffer from an overemphasis on local structure, potentially overlooking\nlong-range dependencies within the entire graphs. Although recent efforts that\nrely on graph coarsening have proven beneficial for global interpretability,\nthey inevitably reduce the graphs to a fixed granularity. Such an inflexible\nway can only capture graph connectivity at a specific level, whereas real-world\ngraph tasks often exhibit relationships at varying granularities (e.g.,\nrelevant interactions in proteins span from functional groups, to amino acids,\nand up to protein domains). In this paper, we introduce a novel Tree-like\nInterpretable Framework (TIF) for graph classification, where plain GNNs are\ntransformed into hierarchical trees, with each level featuring coarsened graphs\nof different granularity as tree nodes. Specifically, TIF iteratively adopts a\ngraph coarsening module to compress original graphs (i.e., root nodes of trees)\ninto increasingly coarser ones (i.e., child nodes of trees), while preserving\ndiversity among tree nodes within different branches through a dedicated graph\nperturbation module. Finally, we propose an adaptive routing module to identify\nthe most informative root-to-leaf paths, providing not only the final\nprediction but also the multi-granular interpretability for the decision-making\nprocess. Extensive experiments on the graph classification benchmarks with both\nsynthetic and real-world datasets demonstrate the superiority of TIF in\ninterpretability, while also delivering a competitive prediction performance\nakin to the state-of-the-art counterparts."}
{"id": "2505.00261", "pdf": "https://arxiv.org/pdf/2505.00261", "abs": "https://arxiv.org/abs/2505.00261", "authors": ["Jayoung Song", "KyungTae Lim", "Jungyeul Park"], "title": "Enriching the Korean Learner Corpus with Multi-reference Annotations and Rubric-Based Scoring", "categories": ["cs.CL"], "comment": null, "summary": "Despite growing global interest in Korean language education, there remains a\nsignificant lack of learner corpora tailored to Korean L2 writing. To address\nthis gap, we enhance the KoLLA Korean learner corpus by adding multiple\ngrammatical error correction (GEC) references, thereby enabling more nuanced\nand flexible evaluation of GEC systems, and reflects the variability of human\nlanguage. Additionally, we enrich the corpus with rubric-based scores aligned\nwith guidelines from the Korean National Language Institute, capturing\ngrammatical accuracy, coherence, and lexical diversity. These enhancements make\nKoLLA a robust and standardized resource for research in Korean L2 education,\nsupporting advancements in language learning, assessment, and automated error\ncorrection."}
{"id": "2505.00284", "pdf": "https://arxiv.org/pdf/2505.00284", "abs": "https://arxiv.org/abs/2505.00284", "authors": ["Zhijie Qiao", "Haowei Li", "Zhong Cao", "Henry X. Liu"], "title": "LightEMMA: Lightweight End-to-End Multimodal Model for Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Vision-Language Models (VLMs) have demonstrated significant potential for\nend-to-end autonomous driving. However, fully exploiting their capabilities for\nsafe and reliable vehicle control remains an open research challenge. To\nsystematically examine advances and limitations of VLMs in driving tasks, we\nintroduce LightEMMA, a Lightweight End-to-End Multimodal Model for Autonomous\ndriving. LightEMMA provides a unified, VLM-based autonomous driving framework\nwithout ad hoc customizations, enabling easy integration and evaluation of\nevolving state-of-the-art commercial and open-source models. We construct\ntwelve autonomous driving agents using various VLMs and evaluate their\nperformance on the nuScenes prediction task, comprehensively assessing metrics\nsuch as inference time, computational cost, and predictive accuracy.\nIllustrative examples highlight that, despite their strong scenario\ninterpretation capabilities, VLMs' practical performance in autonomous driving\ntasks remains concerning, emphasizing the need for further improvements. The\ncode is available at https://github.com/michigan-traffic-lab/LightEMMA."}
{"id": "2505.00568", "pdf": "https://arxiv.org/pdf/2505.00568", "abs": "https://arxiv.org/abs/2505.00568", "authors": ["Lucas Robinet", "Ahmad Berjaoui", "Elizabeth Cohen-Jonathan Moyal"], "title": "Multimodal Masked Autoencoder Pre-training for 3D MRI-Based Brain Tumor Analysis with Missing Modalities", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multimodal magnetic resonance imaging (MRI) constitutes the first line of\ninvestigation for clinicians in the care of brain tumors, providing crucial\ninsights for surgery planning, treatment monitoring, and biomarker\nidentification. Pre-training on large datasets have been shown to help models\nlearn transferable representations and adapt with minimal labeled data. This\nbehavior is especially valuable in medical imaging, where annotations are often\nscarce. However, applying this paradigm to multimodal medical data introduces a\nchallenge: most existing approaches assume that all imaging modalities are\navailable during both pre-training and fine-tuning. In practice, missing\nmodalities often occur due to acquisition issues, specialist unavailability, or\nspecific experimental designs on small in-house datasets. Consequently, a\ncommon approach involves training a separate model for each desired modality\ncombination, making the process both resource-intensive and impractical for\nclinical use. Therefore, we introduce BM-MAE, a masked image modeling\npre-training strategy tailored for multimodal MRI data. The same pre-trained\nmodel seamlessly adapts to any combination of available modalities, extracting\nrich representations that capture both intra- and inter-modal information. This\nallows fine-tuning on any subset of modalities without requiring architectural\nchanges, while still benefiting from a model pre-trained on the full set of\nmodalities. Extensive experiments show that the proposed pre-training strategy\noutperforms or remains competitive with baselines that require separate\npre-training for each modality subset, while substantially surpassing training\nfrom scratch on several downstream tasks. Additionally, it can quickly and\nefficiently reconstruct missing modalities, highlighting its practical value.\nCode and trained models are available at: https://github.com/Lucas-rbnt/bmmae"}
{"id": "2505.00365", "pdf": "https://arxiv.org/pdf/2505.00365", "abs": "https://arxiv.org/abs/2505.00365", "authors": ["Zhengyi Zhong", "Weidong Bao", "Ji Wang", "Jianguo Chen", "Lingjuan Lyu", "Wei Yang Bryan Lim"], "title": "SacFL: Self-Adaptive Federated Continual Learning for Resource-Constrained End Devices", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by TNNLS 2025", "summary": "The proliferation of end devices has led to a distributed computing paradigm,\nwherein on-device machine learning models continuously process diverse data\ngenerated by these devices. The dynamic nature of this data, characterized by\ncontinuous changes or data drift, poses significant challenges for on-device\nmodels. To address this issue, continual learning (CL) is proposed, enabling\nmachine learning models to incrementally update their knowledge and mitigate\ncatastrophic forgetting. However, the traditional centralized approach to CL is\nunsuitable for end devices due to privacy and data volume concerns. In this\ncontext, federated continual learning (FCL) emerges as a promising solution,\npreserving user data locally while enhancing models through collaborative\nupdates. Aiming at the challenges of limited storage resources for CL, poor\nautonomy in task shift detection, and difficulty in coping with new adversarial\ntasks in FCL scenario, we propose a novel FCL framework named SacFL. SacFL\nemploys an Encoder-Decoder architecture to separate task-robust and\ntask-sensitive components, significantly reducing storage demands by retaining\nlightweight task-sensitive components for resource-constrained end devices.\nMoreover, $\\rm{SacFL}$ leverages contrastive learning to introduce an\nautonomous data shift detection mechanism, enabling it to discern whether a new\ntask has emerged and whether it is a benign task. This capability ultimately\nallows the device to autonomously trigger CL or attack defense strategy without\nadditional information, which is more practical for end devices. Comprehensive\nexperiments conducted on multiple text and image datasets, such as Cifar100 and\nTHUCNews, have validated the effectiveness of $\\rm{SacFL}$ in both\nclass-incremental and domain-incremental scenarios. Furthermore, a demo system\nhas been developed to verify its practicality."}
{"id": "2505.00339", "pdf": "https://arxiv.org/pdf/2505.00339", "abs": "https://arxiv.org/abs/2505.00339", "authors": ["Antoun Yaacoub", "Sansiri Tarnpradab", "Phattara Khumprom", "Zainab Assaghir", "Lionel Prevost", "Jérôme Da-Rugna"], "title": "Enhancing AI-Driven Education: Integrating Cognitive Frameworks, Linguistic Feedback Analysis, and Ethical Considerations for Improved Content Generation", "categories": ["cs.CL", "cs.AI"], "comment": "This article will be presented in IJCNN 2025 \"AI Innovations for\n  Education: Transforming Teaching and Learning through Cutting-Edge\n  Technologies\" workshop", "summary": "Artificial intelligence (AI) is rapidly transforming education, presenting\nunprecedented opportunities for personalized learning and streamlined content\ncreation. However, realizing the full potential of AI in educational settings\nnecessitates careful consideration of the quality, cognitive depth, and ethical\nimplications of AI-generated materials. This paper synthesizes insights from\nfour related studies to propose a comprehensive framework for enhancing\nAI-driven educational tools. We integrate cognitive assessment frameworks\n(Bloom's Taxonomy and SOLO Taxonomy), linguistic analysis of AI-generated\nfeedback, and ethical design principles to guide the development of effective\nand responsible AI tools. We outline a structured three-phase approach\nencompassing cognitive alignment, linguistic feedback integration, and ethical\nsafeguards. The practical application of this framework is demonstrated through\nits integration into OneClickQuiz, an AI-powered Moodle plugin for quiz\ngeneration. This work contributes a comprehensive and actionable guide for\neducators, researchers, and developers aiming to harness AI's potential while\nupholding pedagogical and ethical standards in educational content generation."}
{"id": "2505.00322", "pdf": "https://arxiv.org/pdf/2505.00322", "abs": "https://arxiv.org/abs/2505.00322", "authors": ["Keshu Wu", "Zihao Li", "Sixu Li", "Xinyue Ye", "Dominique Lord", "Yang Zhou"], "title": "AI2-Active Safety: AI-enabled Interaction-aware Active Safety Analysis with Vehicle Dynamics", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "This paper introduces an AI-enabled, interaction-aware active safety analysis\nframework that accounts for groupwise vehicle interactions. Specifically, the\nframework employs a bicycle model-augmented with road gradient\nconsiderations-to accurately capture vehicle dynamics. In parallel, a\nhypergraph-based AI model is developed to predict probabilistic trajectories of\nambient traffic. By integrating these two components, the framework derives\nvehicle intra-spacing over a 3D road surface as the solution of a stochastic\nordinary differential equation, yielding high-fidelity surrogate safety\nmeasures such as time-to-collision (TTC). To demonstrate its effectiveness, the\nframework is analyzed using stochastic numerical methods comprising 4th-order\nRunge-Kutta integration and AI inference, generating probability-weighted\nhigh-fidelity TTC (HF-TTC) distributions that reflect complex multi-agent\nmaneuvers and behavioral uncertainties. Evaluated with HF-TTC against\ntraditional constant-velocity TTC and non-interaction-aware approaches on\nhighway datasets, the proposed framework offers a systematic methodology for\nactive safety analysis with enhanced potential for improving safety perception\nin complex traffic environments."}
{"id": "2505.00569", "pdf": "https://arxiv.org/pdf/2505.00569", "abs": "https://arxiv.org/abs/2505.00569", "authors": ["Enmin Zhong", "Carlos R. del-Blanco", "Daniel Berjón", "Fernando Jaureguizar", "Narciso García"], "title": "AnimalMotionCLIP: Embedding motion in CLIP for Animal Behavior Analysis", "categories": ["cs.CV"], "comment": "6 pages, 3 figures,Accepted for the poster session at the CV4Animals\n  workshop: Computer Vision for Animal Behavior Tracking and Modeling In\n  conjunction with Computer Vision and Pattern Recognition 2024", "summary": "Recently, there has been a surge of interest in applying deep learning\ntechniques to animal behavior recognition, particularly leveraging pre-trained\nvisual language models, such as CLIP, due to their remarkable generalization\ncapacity across various downstream tasks. However, adapting these models to the\nspecific domain of animal behavior recognition presents two significant\nchallenges: integrating motion information and devising an effective temporal\nmodeling scheme. In this paper, we propose AnimalMotionCLIP to address these\nchallenges by interleaving video frames and optical flow information in the\nCLIP framework. Additionally, several temporal modeling schemes using an\naggregation of classifiers are proposed and compared: dense, semi dense, and\nsparse. As a result, fine temporal actions can be correctly recognized, which\nis of vital importance in animal behavior analysis. Experiments on the Animal\nKingdom dataset demonstrate that AnimalMotionCLIP achieves superior performance\ncompared to state-of-the-art approaches."}
{"id": "2505.00375", "pdf": "https://arxiv.org/pdf/2505.00375", "abs": "https://arxiv.org/abs/2505.00375", "authors": ["Jinhui Yi", "Huan Yan", "Haotian Wang", "Jian Yuan", "Yong Li"], "title": "Learning to Estimate Package Delivery Time in Mixed Imbalanced Delivery and Pickup Logistics Services", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ACM SIGSPATIAL 2024", "summary": "Accurately estimating package delivery time is essential to the logistics\nindustry, which enables reasonable work allocation and on-time service\nguarantee. This becomes even more necessary in mixed logistics scenarios where\ncouriers handle a high volume of delivery and a smaller number of pickup\nsimultaneously. However, most of the related works treat the pickup and\ndelivery patterns on couriers' decision behavior equally, neglecting that the\npickup has a greater impact on couriers' decision-making compared to the\ndelivery due to its tighter time constraints. In such context, we have three\nmain challenges: 1) multiple spatiotemporal factors are intricately\ninterconnected, significantly affecting couriers' delivery behavior; 2) pickups\nhave stricter time requirements but are limited in number, making it\nchallenging to model their effects on couriers' delivery process; 3) couriers'\nspatial mobility patterns are critical determinants of their delivery behavior,\nbut have been insufficiently explored. To deal with these, we propose TransPDT,\na Transformer-based multi-task package delivery time prediction model. We first\nemploy the Transformer encoder architecture to capture the spatio-temporal\ndependencies of couriers' historical travel routes and pending package sets.\nThen we design the pattern memory to learn the patterns of pickup in the\nimbalanced dataset via attention mechanism. We also set the route prediction as\nan auxiliary task of delivery time prediction, and incorporate the prior\ncourier spatial movement regularities in prediction. Extensive experiments on\nreal industry-scale datasets demonstrate the superiority of our method. A\nsystem based on TransPDT is deployed internally in JD Logistics to track more\nthan 2000 couriers handling hundreds of thousands of packages per day in\nBeijing."}
{"id": "2505.00367", "pdf": "https://arxiv.org/pdf/2505.00367", "abs": "https://arxiv.org/abs/2505.00367", "authors": ["JunSeo Kim", "HyeHyeon Kim"], "title": "KoACD: The First Korean Adolescent Dataset for Cognitive Distortion Analysis", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Cognitive distortion refers to negative thinking patterns that can lead to\nmental health issues like depression and anxiety in adolescents. Previous\nstudies using natural language processing (NLP) have focused mainly on\nsmall-scale adult datasets, with limited research on adolescents. This study\nintroduces KoACD, the first large-scale dataset of cognitive distortions in\nKorean adolescents, containing 108,717 instances. We applied a multi-Large\nLanguage Model (LLM) negotiation method to refine distortion classification and\ngenerate synthetic data using two approaches: cognitive clarification for\ntextual clarity and cognitive balancing for diverse distortion representation.\nValidation through LLMs and expert evaluations showed that while LLMs\nclassified distortions with explicit markers, they struggled with\ncontext-dependent reasoning, where human evaluators demonstrated higher\naccuracy. KoACD aims to enhance future research on cognitive distortion\ndetection."}
{"id": "2505.00592", "pdf": "https://arxiv.org/pdf/2505.00592", "abs": "https://arxiv.org/abs/2505.00592", "authors": ["Shuo Tong", "Shangde Gao", "Ke Liu", "Zihang Huang", "Hongxia Xu", "Haochao Ying", "Jian Wu"], "title": "Uncertainty-Aware Multi-Expert Knowledge Distillation for Imbalanced Disease Grading", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Automatic disease image grading is a significant application of artificial\nintelligence for healthcare, enabling faster and more accurate patient\nassessments. However, domain shifts, which are exacerbated by data imbalance,\nintroduce bias into the model, posing deployment difficulties in clinical\napplications. To address the problem, we propose a novel\n\\textbf{U}ncertainty-aware \\textbf{M}ulti-experts \\textbf{K}nowledge\n\\textbf{D}istillation (UMKD) framework to transfer knowledge from multiple\nexpert models to a single student model. Specifically, to extract\ndiscriminative features, UMKD decouples task-agnostic and task-specific\nfeatures with shallow and compact feature alignment in the feature space. At\nthe output space, an uncertainty-aware decoupled distillation (UDD) mechanism\ndynamically adjusts knowledge transfer weights based on expert model\nuncertainties, ensuring robust and reliable distillation. Additionally, UMKD\nalso tackles the problems of model architecture heterogeneity and distribution\ndiscrepancies between source and target domains, which are inadequately tackled\nby previous KD approaches. Extensive experiments on histology prostate grading\n(\\textit{SICAPv2}) and fundus image grading (\\textit{APTOS}) demonstrate that\nUMKD achieves a new state-of-the-art in both source-imbalanced and\ntarget-imbalanced scenarios, offering a robust and practical solution for\nreal-world disease image grading."}
{"id": "2505.00382", "pdf": "https://arxiv.org/pdf/2505.00382", "abs": "https://arxiv.org/abs/2505.00382", "authors": ["Jianya Lu", "Yingjun Mo"], "title": "Approximation to Deep Q-Network by Stochastic Delay Differential Equations", "categories": ["cs.LG", "math.PR"], "comment": null, "summary": "Despite the significant breakthroughs that the Deep Q-Network (DQN) has\nbrought to reinforcement learning, its theoretical analysis remains limited. In\nthis paper, we construct a stochastic differential delay equation (SDDE) based\non the DQN algorithm and estimate the Wasserstein-1 distance between them. We\nprovide an upper bound for the distance and prove that the distance between the\ntwo converges to zero as the step size approaches zero. This result allows us\nto understand DQN's two key techniques, the experience replay and the target\nnetwork, from the perspective of continuous systems. Specifically, the delay\nterm in the equation, corresponding to the target network, contributes to the\nstability of the system. Our approach leverages a refined Lindeberg principle\nand an operator comparison to establish these results."}
{"id": "2505.00389", "pdf": "https://arxiv.org/pdf/2505.00389", "abs": "https://arxiv.org/abs/2505.00389", "authors": ["Bowen Zhang", "Zixin Song", "Chunping Li"], "title": "CSE-SFP: Enabling Unsupervised Sentence Representation Learning via a Single Forward Pass", "categories": ["cs.CL"], "comment": "Accepted by SIGIR 2025 (Full)", "summary": "As a fundamental task in Information Retrieval and Computational Linguistics,\nsentence representation has profound implications for a wide range of practical\napplications such as text clustering, content analysis, question-answering\nsystems, and web search. Recent advances in pre-trained language models (PLMs)\nhave driven remarkable progress in this field, particularly through\nunsupervised embedding derivation methods centered on discriminative PLMs like\nBERT. However, due to time and computational constraints, few efforts have\nattempted to integrate unsupervised sentence representation with generative\nPLMs, which typically possess much larger parameter sizes. Given that\nstate-of-the-art models in both academia and industry are predominantly based\non generative architectures, there is a pressing need for an efficient\nunsupervised text representation framework tailored to decoder-only PLMs. To\naddress this concern, we propose CSE-SFP, an innovative method that exploits\nthe structural characteristics of generative models. Compared to existing\nstrategies, CSE-SFP requires only a single forward pass to perform effective\nunsupervised contrastive learning. Rigorous experimentation demonstrates that\nCSE-SFP not only produces higher-quality embeddings but also significantly\nreduces both training time and memory consumption. Furthermore, we introduce\ntwo ratio metrics that jointly assess alignment and uniformity, thereby\nproviding a more robust means for evaluating the semantic spatial properties of\nencoding models."}
{"id": "2505.00402", "pdf": "https://arxiv.org/pdf/2505.00402", "abs": "https://arxiv.org/abs/2505.00402", "authors": ["Jinhui Yi", "Huan Yan", "Haotian Wang", "Jian Yuan", "Yong Li"], "title": "DeepSTA: A Spatial-Temporal Attention Network for Logistics Delivery Timely Rate Prediction in Anomaly Conditions", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by CIKM 2023", "summary": "Prediction of couriers' delivery timely rates in advance is essential to the\nlogistics industry, enabling companies to take preemptive measures to ensure\nthe normal operation of delivery services. This becomes even more critical\nduring anomaly conditions like the epidemic outbreak, during which couriers'\ndelivery timely rate will decline markedly and fluctuates significantly.\nExisting studies pay less attention to the logistics scenario. Moreover, many\nworks focusing on prediction tasks in anomaly scenarios fail to explicitly\nmodel abnormal events, e.g., treating external factors equally with other\nfeatures, resulting in great information loss. Further, since some anomalous\nevents occur infrequently, traditional data-driven methods perform poorly in\nthese scenarios. To deal with them, we propose a deep spatial-temporal\nattention model, named DeepSTA. To be specific, to avoid information loss, we\ndesign an anomaly spatio-temporal learning module that employs a recurrent\nneural network to model incident information. Additionally, we utilize Node2vec\nto model correlations between road districts, and adopt graph neural networks\nand long short-term memory to capture the spatial-temporal dependencies of\ncouriers. To tackle the issue of insufficient training data in abnormal\ncircumstances, we propose an anomaly pattern attention module that adopts a\nmemory network for couriers' anomaly feature patterns storage via attention\nmechanisms. The experiments on real-world logistics datasets during the\nCOVID-19 outbreak in 2022 show the model outperforms the best baselines by\n12.11% in MAE and 13.71% in MSE, demonstrating its superior performance over\nmultiple competitive baselines."}
{"id": "2505.00599", "pdf": "https://arxiv.org/pdf/2505.00599", "abs": "https://arxiv.org/abs/2505.00599", "authors": ["Alexander Puzicha", "Konstantin Wüstefeld", "Kathrin Wilms", "Frank Weichert"], "title": "Visual Trajectory Prediction of Vessels for Inland Navigation", "categories": ["cs.CV"], "comment": null, "summary": "The future of inland navigation increasingly relies on autonomous systems and\nremote operations, emphasizing the need for accurate vessel trajectory\nprediction. This study addresses the challenges of video-based vessel tracking\nand prediction by integrating advanced object detection methods, Kalman\nfilters, and spline-based interpolation. However, existing detection systems\noften misclassify objects in inland waterways due to complex surroundings. A\ncomparative evaluation of tracking algorithms, including BoT-SORT, Deep\nOC-SORT, and ByeTrack, highlights the robustness of the Kalman filter in\nproviding smoothed trajectories. Experimental results from diverse scenarios\ndemonstrate improved accuracy in predicting vessel movements, which is\nessential for collision avoidance and situational awareness. The findings\nunderline the necessity of customized datasets and models for inland\nnavigation. Future work will expand the datasets and incorporate vessel\nclassification to refine predictions, supporting both autonomous systems and\nhuman operators in complex environments."}
{"id": "2505.00398", "pdf": "https://arxiv.org/pdf/2505.00398", "abs": "https://arxiv.org/abs/2505.00398", "authors": ["Bassel Hamoud", "Ilnura Usmanova", "Kfir Y. Levy"], "title": "Safety in the Face of Adversity: Achieving Zero Constraint Violation in Online Learning with Slowly Changing Constraints", "categories": ["cs.LG"], "comment": "Accepted to AISTATS, 2025", "summary": "We present the first theoretical guarantees for zero constraint violation in\nOnline Convex Optimization (OCO) across all rounds, addressing dynamic\nconstraint changes. Unlike existing approaches in constrained OCO, which allow\nfor occasional safety breaches, we provide the first approach for maintaining\nstrict safety under the assumption of gradually evolving constraints, namely\nthe constraints change at most by a small amount between consecutive rounds.\nThis is achieved through a primal-dual approach and Online Gradient Ascent in\nthe dual space. We show that employing a dichotomous learning rate enables\nensuring both safety, via zero constraint violation, and sublinear regret. Our\nframework marks a departure from previous work by providing the first provable\nguarantees for maintaining absolute safety in the face of changing constraints\nin OCO."}
{"id": "2505.00467", "pdf": "https://arxiv.org/pdf/2505.00467", "abs": "https://arxiv.org/abs/2505.00467", "authors": ["Vahid Balazadeh", "Michael Cooper", "David Pellow", "Atousa Assadi", "Jennifer Bell", "Jim Fackler", "Gabriel Funingana", "Spencer Gable-Cook", "Anirudh Gangadhar", "Abhishek Jaiswal", "Sumanth Kaja", "Christopher Khoury", "Randy Lin", "Kaden McKeen", "Sara Naimimohasses", "Khashayar Namdar", "Aviraj Newatia", "Allan Pang", "Anshul Pattoo", "Sameer Peesapati", "Diana Prepelita", "Bogdana Rakova", "Saba Sadatamin", "Rafael Schulman", "Ajay Shah", "Syed Azhar Shah", "Syed Ahmar Shah", "Babak Taati", "Balagopal Unnikrishnan", "Stephanie Williams", "Rahul G Krishnan"], "title": "Red Teaming Large Language Models for Healthcare", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We present the design process and findings of the pre-conference workshop at\nthe Machine Learning for Healthcare Conference (2024) entitled Red Teaming\nLarge Language Models for Healthcare, which took place on August 15, 2024.\nConference participants, comprising a mix of computational and clinical\nexpertise, attempted to discover vulnerabilities -- realistic clinical prompts\nfor which a large language model (LLM) outputs a response that could cause\nclinical harm. Red-teaming with clinicians enables the identification of LLM\nvulnerabilities that may not be recognised by LLM developers lacking clinical\nexpertise. We report the vulnerabilities found, categorise them, and present\nthe results of a replication study assessing the vulnerabilities across all\nLLMs provided."}
{"id": "2505.00439", "pdf": "https://arxiv.org/pdf/2505.00439", "abs": "https://arxiv.org/abs/2505.00439", "authors": ["Timo P. Gros", "Nicola J. Müller", "Daniel Fiser", "Isabel Valera", "Verena Wolf", "Jörg Hoffmann"], "title": "Per-Domain Generalizing Policies: On Validation Instances and Scaling Behavior", "categories": ["cs.LG", "cs.AI"], "comment": "7 pages, 3 tables, 3 figures, 3 algorithms", "summary": "Recent work has shown that successful per-domain generalizing action policies\ncan be learned. Scaling behavior, from small training instances to large test\ninstances, is the key objective; and the use of validation instances larger\nthan training instances is one key to achieve it. Prior work has used fixed\nvalidation sets. Here, we introduce a method generating the validation set\ndynamically, on the fly, increasing instance size so long as informative and\nfeasible.We also introduce refined methodology for evaluating scaling behavior,\ngenerating test instances systematically to guarantee a given confidence in\ncoverage performance for each instance size. In experiments, dynamic validation\nimproves scaling behavior of GNN policies in all 9 domains used."}
{"id": "2505.00606", "pdf": "https://arxiv.org/pdf/2505.00606", "abs": "https://arxiv.org/abs/2505.00606", "authors": ["Wallace Lee", "YuHao Chen"], "title": "Dietary Intake Estimation via Continuous 3D Reconstruction of Food", "categories": ["cs.CV", "cs.LG"], "comment": "2025 CVPR MetaFood Workshop", "summary": "Monitoring dietary habits is crucial for preventing health risks associated\nwith overeating and undereating, including obesity, diabetes, and\ncardiovascular diseases. Traditional methods for tracking food intake rely on\nself-reported data before or after the eating, which are prone to inaccuracies.\nThis study proposes an approach to accurately monitor ingest behaviours by\nleveraging 3D food models constructed from monocular 2D video. Using COLMAP and\npose estimation algorithms, we generate detailed 3D representations of food,\nallowing us to observe changes in food volume as it is consumed. Experiments\nwith toy models and real food items demonstrate the approach's potential.\nMeanwhile, we have proposed a new methodology for automated state recognition\nchallenges to accurately detect state changes and maintain model fidelity. The\n3D reconstruction approach shows promise in capturing comprehensive dietary\nbehaviour insights, ultimately contributing to the development of automated and\naccurate dietary monitoring tools."}
{"id": "2505.00410", "pdf": "https://arxiv.org/pdf/2505.00410", "abs": "https://arxiv.org/abs/2505.00410", "authors": ["Farhana Elias", "Md Shihab Reza", "Muhammad Zawad Mahmud", "Samiha Islam"], "title": "Machine Learning Meets Transparency in Osteoporosis Risk Assessment: A Comparative Study of ML and Explainability Analysis", "categories": ["cs.LG"], "comment": "Submitted in an international conference", "summary": "The present research tackles the difficulty of predicting osteoporosis risk\nvia machine learning (ML) approaches, emphasizing the use of explainable\nartificial intelligence (XAI) to improve model transparency. Osteoporosis is a\nsignificant public health concern, sometimes remaining untreated owing to its\nasymptomatic characteristics, and early identification is essential to avert\nfractures. The research assesses six machine learning classifiers: Random\nForest, Logistic Regression, XGBoost, AdaBoost, LightGBM, and Gradient Boosting\nand utilizes a dataset based on clinical, demographic, and lifestyle variables.\nThe models are refined using GridSearchCV to calibrate hyperparameters, with\nthe objective of enhancing predictive efficacy. XGBoost had the greatest\naccuracy (91%) among the evaluated models, surpassing others in precision\n(0.92), recall (0.91), and F1-score (0.90). The research further integrates XAI\napproaches, such as SHAP, LIME, and Permutation Feature Importance, to\nelucidate the decision-making process of the optimal model. The study indicates\nthat age is the primary determinant in forecasting osteoporosis risk, followed\nby hormonal alterations and familial history. These results corroborate\nclinical knowledge and affirm the models' therapeutic significance. The\nresearch underscores the significance of explainability in machine learning\nmodels for healthcare applications, guaranteeing that physicians can rely on\nthe system's predictions. The report ultimately proposes directions for further\nresearch, such as validation across varied populations and the integration of\nsupplementary biomarkers for enhanced predictive accuracy."}
{"id": "2505.00479", "pdf": "https://arxiv.org/pdf/2505.00479", "abs": "https://arxiv.org/abs/2505.00479", "authors": ["Gijs Jan Brandsma", "Jens Blom-Hansen", "Christiaan Meijer", "Kody Moodley"], "title": "Computational Identification of Regulatory Statements in EU Legislation", "categories": ["cs.CL", "I.2.7"], "comment": "11 pages, 6 figures", "summary": "Identifying regulatory statements in legislation is useful for developing\nmetrics to measure the regulatory density and strictness of legislation. A\ncomputational method is valuable for scaling the identification of such\nstatements from a growing body of EU legislation, constituting approximately\n180,000 published legal acts between 1952 and 2023. Past work on extraction of\nthese statements varies in the permissiveness of their definitions for what\nconstitutes a regulatory statement. In this work, we provide a specific\ndefinition for our purposes based on the institutional grammar tool. We develop\nand compare two contrasting approaches for automatically identifying such\nstatements in EU legislation, one based on dependency parsing, and the other on\na transformer-based machine learning model. We found both approaches performed\nsimilarly well with accuracies of 80% and 84% respectively and a K alpha of\n0.58. The high accuracies and not exceedingly high agreement suggests potential\nfor combining strengths of both approaches."}
{"id": "2505.00455", "pdf": "https://arxiv.org/pdf/2505.00455", "abs": "https://arxiv.org/abs/2505.00455", "authors": ["Sungbok Shin", "Hyeon Jeon", "Sanghyun Hong", "Niklas Elmqvist"], "title": "Data Therapist: Eliciting Domain Knowledge from Subject Matter Experts Using Large Language Models", "categories": ["cs.HC", "cs.AI"], "comment": "Submitted to IEEE VIS2025", "summary": "Effective data visualization requires not only technical proficiency but also\na deep understanding of the domain-specific context in which data exists. This\ncontext often includes tacit knowledge about data provenance, quality, and\nintended use, which is rarely explicit in the dataset itself. We present the\nData Therapist, a web-based tool that helps domain experts externalize this\nimplicit knowledge through a mixed-initiative process combining iterative Q&A\nwith interactive annotation. Powered by a large language model, the system\nanalyzes user-supplied datasets, prompts users with targeted questions, and\nallows annotation at varying levels of granularity. The resulting structured\nknowledge base can inform both human and automated visualization design. We\nevaluated the tool in a qualitative study involving expert pairs from Molecular\nBiology, Accounting, Political Science, and Usable Security. The study revealed\nrecurring patterns in how experts reason about their data and highlights areas\nwhere AI support can improve visualization design."}
{"id": "2505.00615", "pdf": "https://arxiv.org/pdf/2505.00615", "abs": "https://arxiv.org/abs/2505.00615", "authors": ["Simon Giebenhain", "Tobias Kirschstein", "Martin Rünz", "Lourdes Agapito", "Matthias Nießner"], "title": "Pixel3DMM: Versatile Screen-Space Priors for Single-Image 3D Face Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": "Project Website: https://simongiebenhain.github.io/pixel3dmm/ ;\n  Video: https://www.youtube.com/watch?v=BwxwEXJwUDc", "summary": "We address the 3D reconstruction of human faces from a single RGB image. To\nthis end, we propose Pixel3DMM, a set of highly-generalized vision transformers\nwhich predict per-pixel geometric cues in order to constrain the optimization\nof a 3D morphable face model (3DMM). We exploit the latent features of the DINO\nfoundation model, and introduce a tailored surface normal and uv-coordinate\nprediction head. We train our model by registering three high-quality 3D face\ndatasets against the FLAME mesh topology, which results in a total of over\n1,000 identities and 976K images. For 3D face reconstruction, we propose a\nFLAME fitting opitmization that solves for the 3DMM parameters from the\nuv-coordinate and normal estimates. To evaluate our method, we introduce a new\nbenchmark for single-image face reconstruction, which features high diversity\nfacial expressions, viewing angles, and ethnicities. Crucially, our benchmark\nis the first to evaluate both posed and neutral facial geometry. Ultimately,\nour method outperforms the most competitive baselines by over 15% in terms of\ngeometric accuracy for posed facial expressions."}
{"id": "2505.00415", "pdf": "https://arxiv.org/pdf/2505.00415", "abs": "https://arxiv.org/abs/2505.00415", "authors": ["Tian Lan", "Yifei Gao", "Yimeng Lu", "Chen Zhang"], "title": "CICADA: Cross-Domain Interpretable Coding for Anomaly Detection and Adaptation in Multivariate Time Series", "categories": ["cs.LG"], "comment": null, "summary": "Unsupervised Time series anomaly detection plays a crucial role in\napplications across industries. However, existing methods face significant\nchallenges due to data distributional shifts across different domains, which\nare exacerbated by the non-stationarity of time series over time. Existing\nmodels fail to generalize under multiple heterogeneous source domains and\nemerging unseen new target domains. To fill the research gap, we introduce\nCICADA (Cross-domain Interpretable Coding for Anomaly Detection and\nAdaptation), with four key innovations: (1) a mixture of experts (MOE)\nframework that captures domain-agnostic anomaly features with high flexibility\nand interpretability; (2) a novel selective meta-learning mechanism to prevent\nnegative transfer between dissimilar domains, (3) an adaptive expansion\nalgorithm for emerging heterogeneous domain expansion, and (4) a hierarchical\nattention structure that quantifies expert contributions during fusion to\nenhance interpretability further.Extensive experiments on synthetic and\nreal-world industrial datasets demonstrate that CICADA outperforms\nstate-of-the-art methods in both cross-domain detection performance and\ninterpretability."}
{"id": "2505.00506", "pdf": "https://arxiv.org/pdf/2505.00506", "abs": "https://arxiv.org/abs/2505.00506", "authors": ["Deanna Emery", "Michael Goitia", "Freddie Vargus", "Iulia Neagu"], "title": "HalluMix: A Task-Agnostic, Multi-Domain Benchmark for Real-World Hallucination Detection", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "As large language models (LLMs) are increasingly deployed in high-stakes\ndomains, detecting hallucinated content$\\unicode{x2013}$text that is not\ngrounded in supporting evidence$\\unicode{x2013}$has become a critical\nchallenge. Existing benchmarks for hallucination detection are often\nsynthetically generated, narrowly focused on extractive question answering, and\nfail to capture the complexity of real-world scenarios involving multi-document\ncontexts and full-sentence outputs. We introduce the HalluMix Benchmark, a\ndiverse, task-agnostic dataset that includes examples from a range of domains\nand formats. Using this benchmark, we evaluate seven hallucination detection\nsystems$\\unicode{x2013}$both open and closed\nsource$\\unicode{x2013}$highlighting differences in performance across tasks,\ndocument lengths, and input representations. Our analysis highlights\nsubstantial performance disparities between short and long contexts, with\ncritical implications for real-world Retrieval Augmented Generation (RAG)\nimplementations. Quotient Detections achieves the best overall performance,\nwith an accuracy of 0.82 and an F1 score of 0.84."}
{"id": "2505.00487", "pdf": "https://arxiv.org/pdf/2505.00487", "abs": "https://arxiv.org/abs/2505.00487", "authors": ["Leonid Legashev", "Artur Zhigalov", "Denis Parfenov"], "title": "Analysis of the vulnerability of machine learning regression models to adversarial attacks using data from 5G wireless networks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "This article describes the process of creating a script and conducting an\nanalytical study of a dataset using the DeepMIMO emulator. An advertorial\nattack was carried out using the FGSM method to maximize the gradient. A\ncomparison is made of the effectiveness of binary classifiers in the task of\ndetecting distorted data. The dynamics of changes in the quality indicators of\nthe regression model were analyzed in conditions without adversarial attacks,\nduring an adversarial attack and when the distorted data was isolated. It is\nshown that an adversarial FGSM attack with gradient maximization leads to an\nincrease in the value of the MSE metric by 33% and a decrease in the R2\nindicator by 10% on average. The LightGBM binary classifier effectively\nidentifies data with adversarial anomalies with 98% accuracy. Regression\nmachine learning models are susceptible to adversarial attacks, but rapid\nanalysis of network traffic and data transmitted over the network makes it\npossible to identify malicious activity"}
{"id": "2505.00619", "pdf": "https://arxiv.org/pdf/2505.00619", "abs": "https://arxiv.org/abs/2505.00619", "authors": ["Neng Dong", "Shuanglin Yan", "Liyan Zhang", "Jinhui Tang"], "title": "Diverse Semantics-Guided Feature Alignment and Decoupling for Visible-Infrared Person Re-Identification", "categories": ["cs.CV"], "comment": null, "summary": "Visible-Infrared Person Re-Identification (VI-ReID) is a challenging task due\nto the large modality discrepancy between visible and infrared images, which\ncomplicates the alignment of their features into a suitable common space.\nMoreover, style noise, such as illumination and color contrast, reduces the\nidentity discriminability and modality invariance of features. To address these\nchallenges, we propose a novel Diverse Semantics-guided Feature Alignment and\nDecoupling (DSFAD) network to align identity-relevant features from different\nmodalities into a textual embedding space and disentangle identity-irrelevant\nfeatures within each modality. Specifically, we develop a Diverse\nSemantics-guided Feature Alignment (DSFA) module, which generates pedestrian\ndescriptions with diverse sentence structures to guide the cross-modality\nalignment of visual features. Furthermore, to filter out style information, we\npropose a Semantic Margin-guided Feature Decoupling (SMFD) module, which\ndecomposes visual features into pedestrian-related and style-related\ncomponents, and then constrains the similarity between the former and the\ntextual embeddings to be at least a margin higher than that between the latter\nand the textual embeddings. Additionally, to prevent the loss of pedestrian\nsemantics during feature decoupling, we design a Semantic Consistency-guided\nFeature Restitution (SCFR) module, which further excavates useful information\nfor identification from the style-related features and restores it back into\nthe pedestrian-related features, and then constrains the similarity between the\nfeatures after restitution and the textual embeddings to be consistent with\nthat between the features before decoupling and the textual embeddings.\nExtensive experiments on three VI-ReID datasets demonstrate the superiority of\nour DSFAD."}
{"id": "2505.00422", "pdf": "https://arxiv.org/pdf/2505.00422", "abs": "https://arxiv.org/abs/2505.00422", "authors": ["Yu Han", "Aaron Ceross", "Jeroen H. M. Bergmann"], "title": "Toward Automated Regulatory Decision-Making: Trustworthy Medical Device Risk Classification with Multimodal Transformers and Self-Training", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Accurate classification of medical device risk levels is essential for\nregulatory oversight and clinical safety. We present a Transformer-based\nmultimodal framework that integrates textual descriptions and visual\ninformation to predict device regulatory classification. The model incorporates\na cross-attention mechanism to capture intermodal dependencies and employs a\nself-training strategy for improved generalization under limited supervision.\nExperiments on a real-world regulatory dataset demonstrate that our approach\nachieves up to 90.4% accuracy and 97.9% AUROC, significantly outperforming\ntext-only (77.2%) and image-only (54.8%) baselines. Compared to standard\nmultimodal fusion, the self-training mechanism improved SVM performance by 3.3\npercentage points in accuracy (from 87.1% to 90.4%) and 1.4 points in macro-F1,\nsuggesting that pseudo-labeling can effectively enhance generalization under\nlimited supervision. Ablation studies further confirm the complementary\nbenefits of both cross-modal attention and self-training."}
{"id": "2505.00551", "pdf": "https://arxiv.org/pdf/2505.00551", "abs": "https://arxiv.org/abs/2505.00551", "authors": ["Chong Zhang", "Yue Deng", "Xiang Lin", "Bin Wang", "Dianwen Ng", "Hai Ye", "Xingxuan Li", "Yao Xiao", "Zhanfeng Mo", "Qi Zhang", "Lidong Bing"], "title": "100 Days After DeepSeek-R1: A Survey on Replication Studies and More Directions for Reasoning Language Models", "categories": ["cs.CL"], "comment": null, "summary": "The recent development of reasoning language models (RLMs) represents a novel\nevolution in large language models. In particular, the recent release of\nDeepSeek-R1 has generated widespread social impact and sparked enthusiasm in\nthe research community for exploring the explicit reasoning paradigm of\nlanguage models. However, the implementation details of the released models\nhave not been fully open-sourced by DeepSeek, including DeepSeek-R1-Zero,\nDeepSeek-R1, and the distilled small models. As a result, many replication\nstudies have emerged aiming to reproduce the strong performance achieved by\nDeepSeek-R1, reaching comparable performance through similar training\nprocedures and fully open-source data resources. These works have investigated\nfeasible strategies for supervised fine-tuning (SFT) and reinforcement learning\nfrom verifiable rewards (RLVR), focusing on data preparation and method design,\nyielding various valuable insights. In this report, we provide a summary of\nrecent replication studies to inspire future research. We primarily focus on\nSFT and RLVR as two main directions, introducing the details for data\nconstruction, method design and training procedure of current replication\nstudies. Moreover, we conclude key findings from the implementation details and\nexperimental results reported by these studies, anticipating to inspire future\nresearch. We also discuss additional techniques of enhancing RLMs, highlighting\nthe potential of expanding the application scope of these models, and\ndiscussing the challenges in development. By this survey, we aim to help\nresearchers and developers of RLMs stay updated with the latest advancements,\nand seek to inspire new ideas to further enhance RLMs."}
{"id": "2505.00488", "pdf": "https://arxiv.org/pdf/2505.00488", "abs": "https://arxiv.org/abs/2505.00488", "authors": ["Vamshi Kumar Kurva", "Shishir Kolathaya"], "title": "MULE: Multi-terrain and Unknown Load Adaptation for Effective Quadrupedal Locomotion", "categories": ["cs.RO", "cs.AI"], "comment": "Preprint under review", "summary": "Quadrupedal robots are increasingly deployed for load-carrying tasks across\ndiverse terrains. While Model Predictive Control (MPC)-based methods can\naccount for payload variations, they often depend on predefined gait schedules\nor trajectory generators, limiting their adaptability in unstructured\nenvironments. To address these limitations, we propose an Adaptive\nReinforcement Learning (RL) framework that enables quadrupedal robots to\ndynamically adapt to both varying payloads and diverse terrains. The framework\nconsists of a nominal policy responsible for baseline locomotion and an\nadaptive policy that learns corrective actions to preserve stability and\nimprove command tracking under payload variations. We validate the proposed\napproach through large-scale simulation experiments in Isaac Gym and real-world\nhardware deployment on a Unitree Go1 quadruped. The controller was tested on\nflat ground, slopes, and stairs under both static and dynamic payload changes.\nAcross all settings, our adaptive controller consistently outperformed the\ncontroller in tracking body height and velocity commands, demonstrating\nenhanced robustness and adaptability without requiring explicit gait design or\nmanual tuning."}
{"id": "2505.00627", "pdf": "https://arxiv.org/pdf/2505.00627", "abs": "https://arxiv.org/abs/2505.00627", "authors": ["Zhongying Deng", "Haoyu Wang", "Ziyan Huang", "Lipei Zhang", "Angelica I. Aviles-Rivero", "Chaoyu Liu", "Junjun He", "Zoe Kourtzi", "Carola-Bibiane Schönlieb"], "title": "Brain Foundation Models with Hypergraph Dynamic Adapter for Brain Disease Analysis", "categories": ["cs.CV"], "comment": "35 pages, 4 figures", "summary": "Brain diseases, such as Alzheimer's disease and brain tumors, present\nprofound challenges due to their complexity and societal impact. Recent\nadvancements in brain foundation models have shown significant promise in\naddressing a range of brain-related tasks. However, current brain foundation\nmodels are limited by task and data homogeneity, restricted generalization\nbeyond segmentation or classification, and inefficient adaptation to diverse\nclinical tasks. In this work, we propose SAM-Brain3D, a brain-specific\nfoundation model trained on over 66,000 brain image-label pairs across 14 MRI\nsub-modalities, and Hypergraph Dynamic Adapter (HyDA), a lightweight adapter\nfor efficient and effective downstream adaptation. SAM-Brain3D captures\ndetailed brain-specific anatomical and modality priors for segmenting diverse\nbrain targets and broader downstream tasks. HyDA leverages hypergraphs to fuse\ncomplementary multi-modal data and dynamically generate patient-specific\nconvolutional kernels for multi-scale feature fusion and personalized\npatient-wise adaptation. Together, our framework excels across a broad spectrum\nof brain disease segmentation and classification tasks. Extensive experiments\ndemonstrate that our method consistently outperforms existing state-of-the-art\napproaches, offering a new paradigm for brain disease analysis through\nmulti-modal, multi-scale, and dynamic foundation modeling."}
{"id": "2505.00466", "pdf": "https://arxiv.org/pdf/2505.00466", "abs": "https://arxiv.org/abs/2505.00466", "authors": ["Thomas Flinkow", "Marco Casadio", "Colin Kessler", "Rosemary Monahan", "Ekaterina Komendantskaya"], "title": "A Generalised Framework for Property-Driven Machine Learning", "categories": ["cs.LG", "cs.LO"], "comment": "22 pages, 4 tables, 4 figures. Submitted to AI Verification 2025", "summary": "Neural networks have been shown to frequently fail to satisfy critical safety\nand correctness properties after training, highlighting the pressing need for\ntraining methods that incorporate such properties directly. While adversarial\ntraining can be used to improve robustness to small perturbations within\n$\\epsilon$-cubes, domains other than computer vision -- such as control systems\nand natural language processing -- may require more flexible input region\nspecifications via generalised hyper-rectangles. Meanwhile, differentiable\nlogics offer a way to encode arbitrary logical constraints as additional loss\nterms that guide the learning process towards satisfying these constraints. In\nthis paper, we investigate how these two complementary approaches can be\nunified within a single framework for property-driven machine learning. We show\nthat well-known properties from the literature are subcases of this general\napproach, and we demonstrate its practical effectiveness on a case study\ninvolving a neural network controller for a drone system. Our framework is\npublicly available at https://github.com/tflinkow/property-driven-ml."}
{"id": "2505.00557", "pdf": "https://arxiv.org/pdf/2505.00557", "abs": "https://arxiv.org/abs/2505.00557", "authors": ["Makoto Sato"], "title": "Triggering Hallucinations in LLMs: A Quantitative Study of Prompt-Induced Hallucination in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Hallucinations in large language models (LLMs) present a growing challenge\nacross real-world applications, from healthcare to law, where factual\nreliability is essential. Despite advances in alignment and instruction tuning,\nLLMs can still generate outputs that are fluent yet fundamentally untrue.\nUnderstanding the cognitive dynamics that underlie these hallucinations remains\nan open problem. In this study, we propose a prompt-based framework to\nsystematically trigger and quantify hallucination: a Hallucination-Inducing\nPrompt (HIP), which synthetically fuses semantically distant concepts (e.g.,\nperiodic table of elements and tarot divination) in a misleading way, and a\nHallucination Quantifying Prompt (HQP), which scores the plausibility,\nconfidence, and coherence of the output. Controlled experiments across multiple\nLLMs revealed that HIPs consistently produced less coherent and more\nhallucinated responses than their null-fusion controls. These effects varied\nacross models, with reasoning-oriented LLMs showing distinct profiles from\ngeneral-purpose ones. Our framework provides a reproducible testbed for\nstudying hallucination vulnerability, and opens the door to developing safer,\nmore introspective LLMs that can detect and self-regulate the onset of\nconceptual instability."}
{"id": "2505.00490", "pdf": "https://arxiv.org/pdf/2505.00490", "abs": "https://arxiv.org/abs/2505.00490", "authors": ["Shivam Vats", "Michelle Zhao", "Patrick Callaghan", "Mingxi Jia", "Maxim Likhachev", "Oliver Kroemer", "George Konidaris"], "title": "Optimal Interactive Learning on the Job via Facility Location Planning", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted to Robotics: Science and Systems (RSS) 2025", "summary": "Collaborative robots must continually adapt to novel tasks and user\npreferences without overburdening the user. While prior interactive robot\nlearning methods aim to reduce human effort, they are typically limited to\nsingle-task scenarios and are not well-suited for sustained, multi-task\ncollaboration. We propose COIL (Cost-Optimal Interactive Learning) -- a\nmulti-task interaction planner that minimizes human effort across a sequence of\ntasks by strategically selecting among three query types (skill, preference,\nand help). When user preferences are known, we formulate COIL as an\nuncapacitated facility location (UFL) problem, which enables bounded-suboptimal\nplanning in polynomial time using off-the-shelf approximation algorithms. We\nextend our formulation to handle uncertainty in user preferences by\nincorporating one-step belief space planning, which uses these approximation\nalgorithms as subroutines to maintain polynomial-time performance. Simulated\nand physical experiments on manipulation tasks show that our framework\nsignificantly reduces the amount of work allocated to the human while\nmaintaining successful task completion."}
{"id": "2505.00630", "pdf": "https://arxiv.org/pdf/2505.00630", "abs": "https://arxiv.org/abs/2505.00630", "authors": ["Muyi Bao", "Shuchang Lyu", "Zhaoyang Xu", "Huiyu Zhou", "Jinchang Ren", "Shiming Xiang", "Xiangtai Li", "Guangliang Cheng"], "title": "Vision Mamba in Remote Sensing: A Comprehensive Survey of Techniques, Applications and Outlook", "categories": ["cs.CV"], "comment": null, "summary": "Deep learning has profoundly transformed remote sensing, yet prevailing\narchitectures like Convolutional Neural Networks (CNNs) and Vision Transformers\n(ViTs) remain constrained by critical trade-offs: CNNs suffer from limited\nreceptive fields, while ViTs grapple with quadratic computational complexity,\nhindering their scalability for high-resolution remote sensing data. State\nSpace Models (SSMs), particularly the recently proposed Mamba architecture,\nhave emerged as a paradigm-shifting solution, combining linear computational\nscaling with global context modeling. This survey presents a comprehensive\nreview of Mamba-based methodologies in remote sensing, systematically analyzing\nabout 120 studies to construct a holistic taxonomy of innovations and\napplications. Our contributions are structured across five dimensions: (i)\nfoundational principles of vision Mamba architectures, (ii) micro-architectural\nadvancements such as adaptive scan strategies and hybrid SSM formulations,\n(iii) macro-architectural integrations, including CNN-Transformer-Mamba hybrids\nand frequency-domain adaptations, (iv) rigorous benchmarking against\nstate-of-the-art methods in multiple application tasks, such as object\ndetection, semantic segmentation, change detection, etc. and (v) critical\nanalysis of unresolved challenges with actionable future directions. By\nbridging the gap between SSM theory and remote sensing practice, this survey\nestablishes Mamba as a transformative framework for remote sensing analysis. To\nour knowledge, this paper is the first systematic review of Mamba architectures\nin remote sensing. Our work provides a structured foundation for advancing\nresearch in remote sensing systems through SSM-based methods. We curate an\nopen-source repository\n(https://github.com/BaoBao0926/Awesome-Mamba-in-Remote-Sensing) to foster\ncommunity-driven advancements."}
{"id": "2505.00473", "pdf": "https://arxiv.org/pdf/2505.00473", "abs": "https://arxiv.org/abs/2505.00473", "authors": ["Shuwen Sun", "Lihong Feng", "Peter Benner"], "title": "Interpretable Spatial-Temporal Fusion Transformers: Multi-Output Prediction for Parametric Dynamical Systems with Time-Varying Inputs", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "We explore the promising performance of a transformer model in predicting\noutputs of parametric dynamical systems with external time-varying input\nsignals. The outputs of such systems vary not only with physical parameters but\nalso with external time-varying input signals. Accurately catching the dynamics\nof such systems is challenging. We have adapted and extended an existing\ntransformer model for single output prediction to a multiple-output transformer\nthat is able to predict multiple output responses of these systems. The\nmultiple-output transformer generalizes the interpretability of the original\ntransformer. The generalized interpretable attention weight matrix explores not\nonly the temporal correlations in the sequence, but also the interactions\nbetween the multiple outputs, providing explanation for the spatial correlation\nin the output domain. This multiple-output transformer accurately predicts the\nsequence of multiple outputs, regardless of the nonlinearity of the system and\nthe dimensionality of the parameter space."}
{"id": "2505.00570", "pdf": "https://arxiv.org/pdf/2505.00570", "abs": "https://arxiv.org/abs/2505.00570", "authors": ["Jushi Kai", "Boyi Zeng", "Yixuan Wang", "Haoli Bai", "Bo Jiang", "Zhouhan Lin"], "title": "FreqKV: Frequency Domain Key-Value Compression for Efficient Context Window Extension", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Extending the context window in large language models (LLMs) is essential for\napplications involving long-form content generation. However, the linear\nincrease in key-value (KV) cache memory requirements and the quadratic\ncomplexity of self-attention with respect to sequence length present\nsignificant challenges during fine-tuning and inference. Existing methods\nsuffer from performance degradation when extending to longer contexts. In this\nwork, we introduce a novel context extension method that optimizes both\nfine-tuning and inference efficiency. Our method exploits a key observation: in\nthe frequency domain, the energy distribution of the KV cache is primarily\nconcentrated in low-frequency components. By filtering out the high-frequency\ncomponents, the KV cache can be effectively compressed with minimal information\nloss. Building on this insight, we propose an efficient compression technique,\nFreqKV, that iteratively compresses the increasing KV cache to a fixed size in\nthe frequency domain, applicable to both fine-tuning and inference. FreqKV\nintroduces no additional parameters or architectural modifications. With\nminimal fine-tuning, LLMs can learn to leverage the limited cache that is\ncompressed in the frequency domain and extend the context window efficiently.\nExperiments on various long context language modeling and understanding tasks\ndemonstrate the efficiency and efficacy of the proposed method."}
{"id": "2505.00503", "pdf": "https://arxiv.org/pdf/2505.00503", "abs": "https://arxiv.org/abs/2505.00503", "authors": ["Ke Jiang", "Wen Jiang", "Xiaoyang Tan"], "title": "Variational OOD State Correction for Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "The performance of Offline reinforcement learning is significantly impacted\nby the issue of state distributional shift, and out-of-distribution (OOD) state\ncorrection is a popular approach to address this problem. In this paper, we\npropose a novel method named Density-Aware Safety Perception (DASP) for OOD\nstate correction. Specifically, our method encourages the agent to prioritize\nactions that lead to outcomes with higher data density, thereby promoting its\noperation within or the return to in-distribution (safe) regions. To achieve\nthis, we optimize the objective within a variational framework that\nconcurrently considers both the potential outcomes of decision-making and their\ndensity, thus providing crucial contextual information for safe\ndecision-making. Finally, we validate the effectiveness and feasibility of our\nproposed method through extensive experimental evaluations on the offline\nMuJoCo and AntMaze suites."}
{"id": "2505.00668", "pdf": "https://arxiv.org/pdf/2505.00668", "abs": "https://arxiv.org/abs/2505.00668", "authors": ["Kirtan Rajesh", "Suvidha Rupesh Kumar"], "title": "Deep Reinforcement Learning for Urban Air Quality Management: Multi-Objective Optimization of Pollution Mitigation Booth Placement in Metropolitan Environments", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Urban air pollution remains a pressing global concern, particularly in\ndensely populated and traffic-intensive metropolitan areas like Delhi, where\nexposure to harmful pollutants severely impacts public health. Delhi, being one\nof the most polluted cities globally, experiences chronic air quality issues\ndue to vehicular emissions, industrial activities, and construction dust, which\nexacerbate its already fragile atmospheric conditions. Traditional pollution\nmitigation strategies, such as static air purifying installations, often fail\nto maximize their impact due to suboptimal placement and limited adaptability\nto dynamic urban environments. This study presents a novel deep reinforcement\nlearning (DRL) framework to optimize the placement of air purification booths\nto improve the air quality index (AQI) in the city of Delhi. We employ Proximal\nPolicy Optimization (PPO), a state-of-the-art reinforcement learning algorithm,\nto iteratively learn and identify high-impact locations based on multiple\nspatial and environmental factors, including population density, traffic\npatterns, industrial influence, and green space constraints. Our approach is\nbenchmarked against conventional placement strategies, including random and\ngreedy AQI-based methods, using multi-dimensional performance evaluation\nmetrics such as AQI improvement, spatial coverage, population and traffic\nimpact, and spatial entropy. Experimental results demonstrate that the RL-based\napproach outperforms baseline methods by achieving a balanced and effective\ndistribution of air purification infrastructure. Notably, the DRL framework\nachieves an optimal trade-off between AQI reduction and high-coverage\ndeployment, ensuring equitable environmental benefits across urban regions. The\nfindings underscore the potential of AI-driven spatial optimization in\nadvancing smart city initiatives and data-driven urban air quality management."}
{"id": "2505.00495", "pdf": "https://arxiv.org/pdf/2505.00495", "abs": "https://arxiv.org/abs/2505.00495", "authors": ["Nguyen Van Thanh", "Nguyen Dang Huynh", "Nguyen Ngoc Tan", "Nguyen Thai Minh", "Nguyen Nam Hoang"], "title": "Enhancing Tropical Cyclone Path Forecasting with an Improved Transformer Network", "categories": ["cs.LG", "cs.PF"], "comment": null, "summary": "A storm is a type of extreme weather. Therefore, forecasting the path of a\nstorm is extremely important for protecting human life and property. However,\nstorm forecasting is very challenging because storm trajectories frequently\nchange. In this study, we propose an improved deep learning method using a\nTransformer network to predict the movement trajectory of a storm over the next\n6 hours. The storm data used to train the model was obtained from the National\nOceanic and Atmospheric Administration (NOAA) [1]. Simulation results show that\nthe proposed method is more accurate than traditional methods. Moreover, the\nproposed method is faster and more cost-effective"}
{"id": "2505.00582", "pdf": "https://arxiv.org/pdf/2505.00582", "abs": "https://arxiv.org/abs/2505.00582", "authors": ["Xinyu Ding", "Meiqi Wang", "Siyu Liao", "Zhongfeng Wang"], "title": "Block Circulant Adapter for Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": "to appear in Proceedings of the 2025 International Joint Conference\n  on Artificial Intelligence (IJCAI-2025)", "summary": "Fine-tuning large language models (LLMs) is difficult due to their huge model\nsize. Recent Fourier domain-based methods show potential for reducing\nfine-tuning costs. We propose a block circulant matrix-based fine-tuning method\nwith a stable training heuristic to leverage the properties of circulant\nmatrices and one-dimensional Fourier transforms to reduce storage and\ncomputation costs. Experiments show that our method uses $14\\times$ less number\nof parameters than VeRA, $16\\times$ smaller than LoRA and $32\\times$ less FLOPs\nthan FourierFT, while maintaining close or better task performance. Our\napproach presents a promising way in frequency domain to fine-tune large models\non downstream tasks."}
{"id": "2505.00533", "pdf": "https://arxiv.org/pdf/2505.00533", "abs": "https://arxiv.org/abs/2505.00533", "authors": ["Linjing You", "Jiabao Lu", "Xiayuan Huang"], "title": "Test-time Correlation Alignment", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICML2025", "summary": "Deep neural networks often experience performance drops due to distribution\nshifts between training and test data. Although domain adaptation offers a\nsolution, privacy concerns restrict access to training data in many real-world\nscenarios. This restriction has spurred interest in Test-Time Adaptation (TTA),\nwhich adapts models using only unlabeled test data. However, current TTA\nmethods still face practical challenges: (1) a primary focus on instance-wise\nalignment, overlooking CORrelation ALignment (CORAL) due to missing source\ncorrelations; (2) complex backpropagation operations for model updating,\nresulting in overhead computation and (3) domain forgetting.\n  To address these challenges, we provide a theoretical analysis to investigate\nthe feasibility of Test-time Correlation Alignment (TCA), demonstrating that\ncorrelation alignment between high-certainty instances and test instances can\nenhance test performances with a theoretical guarantee. Based on this, we\npropose two simple yet effective algorithms: LinearTCA and LinearTCA+.\nLinearTCA applies a simple linear transformation to achieve both instance and\ncorrelation alignment without additional model updates, while LinearTCA+ serves\nas a plug-and-play module that can easily boost existing TTA methods. Extensive\nexperiments validate our theoretical insights and show that TCA methods\nsignificantly outperforms baselines across various tasks, benchmarks and\nbackbones. Notably, LinearTCA improves adaptation accuracy by 5.88% on\nOfficeHome dataset, while using only 4% maximum GPU memory usage and 0.6%\ncomputation time compared to the best baseline TTA method."}
{"id": "2505.00684", "pdf": "https://arxiv.org/pdf/2505.00684", "abs": "https://arxiv.org/abs/2505.00684", "authors": ["Tiange Luo", "Lajanugen Logeswaran", "Justin Johnson", "Honglak Lee"], "title": "Visual Test-time Scaling for GUI Agent Grounding", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce RegionFocus, a visual test-time scaling approach for Vision\nLanguage Model Agents. Understanding webpages is challenging due to the visual\ncomplexity of GUI images and the large number of interface elements, making\naccurate action selection difficult. Our approach dynamically zooms in on\nrelevant regions, reducing background clutter and improving grounding accuracy.\nTo support this process, we propose an image-as-map mechanism that visualizes\nkey landmarks at each step, providing a transparent action record and enables\nthe agent to effectively choose among action candidates. Even with a simple\nregion selection strategy, we observe significant performance gains of 28+\\% on\nScreenspot-pro and 24+\\% on WebVoyager benchmarks on top of two\nstate-of-the-art open vision language model agents, UI-TARS and Qwen2.5-VL,\nhighlighting the effectiveness of visual test-time scaling in interactive\nsettings. We achieve a new state-of-the-art grounding performance of 61.6\\% on\nthe ScreenSpot-Pro benchmark by applying RegionFocus to a Qwen2.5-VL-72B model.\nOur code will be released publicly at https://github.com/tiangeluo/RegionFocus."}
{"id": "2505.00509", "pdf": "https://arxiv.org/pdf/2505.00509", "abs": "https://arxiv.org/abs/2505.00509", "authors": ["Jeremias Ferrao", "Luhan Mikaelson", "Keenan Pepper", "Natalia Perez-Campanero Antolin"], "title": "Self-Ablating Transformers: More Interpretability, Less Sparsity", "categories": ["cs.LG"], "comment": "Poster Presentation at Building Trust Workshop at ICLR 2025", "summary": "A growing intuition in machine learning suggests a link between sparsity and\ninterpretability. We introduce a novel self-ablation mechanism to investigate\nthis connection ante-hoc in the context of language transformers. Our approach\ndynamically enforces a k-winner-takes-all constraint, forcing the model to\ndemonstrate selective activation across neuron and attention units. Unlike\npost-hoc methods that analyze already-trained models, our approach integrates\ninterpretability directly into model training, promoting feature localization\nfrom inception. Training small models on the TinyStories dataset and employing\ninterpretability tests, we find that self-ablation leads to more localized\ncircuits, concentrated feature representations, and increased neuron\nspecialization without compromising language modelling performance.\nSurprisingly, our method also decreased overall sparsity, indicating that\nself-ablation promotes specialization rather than widespread inactivity. This\nreveals a complex interplay between sparsity and interpretability, where\ndecreased global sparsity can coexist with increased local specialization,\nleading to enhanced interpretability. To facilitate reproducibility, we make\nour code available at\nhttps://github.com/keenanpepper/self-ablating-transformers."}
{"id": "2505.00624", "pdf": "https://arxiv.org/pdf/2505.00624", "abs": "https://arxiv.org/abs/2505.00624", "authors": ["Chaitali Bhattacharyya", "Yeseong Kim"], "title": "FineScope : Precision Pruning for Domain-Specialized Large Language Models Using SAE-Guided Self-Data Cultivation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Training large language models (LLMs) from scratch requires significant\ncomputational resources, driving interest in developing smaller,\ndomain-specific LLMs that maintain both efficiency and strong task performance.\nMedium-sized models such as LLaMA, llama} have served as starting points for\ndomain-specific adaptation, but they often suffer from accuracy degradation\nwhen tested on specialized datasets. We introduce FineScope, a framework for\nderiving compact, domain-optimized LLMs from larger pretrained models.\nFineScope leverages the Sparse Autoencoder (SAE) framework, inspired by its\nability to produce interpretable feature representations, to extract\ndomain-specific subsets from large datasets. We apply structured pruning with\ndomain-specific constraints, ensuring that the resulting pruned models retain\nessential knowledge for the target domain. To further enhance performance,\nthese pruned models undergo self-data distillation, leveraging SAE-curated\ndatasets to restore key domain-specific information lost during pruning.\nExtensive experiments and ablation studies demonstrate that FineScope achieves\nhighly competitive performance, outperforming several large-scale\nstate-of-the-art LLMs in domain-specific tasks. Additionally, our results show\nthat FineScope enables pruned models to regain a substantial portion of their\noriginal performance when fine-tuned with SAE-curated datasets. Furthermore,\napplying these datasets to fine-tune pretrained LLMs without pruning also\nimproves their domain-specific accuracy, highlighting the robustness of our\napproach. The code will be released."}
{"id": "2505.00555", "pdf": "https://arxiv.org/pdf/2505.00555", "abs": "https://arxiv.org/abs/2505.00555", "authors": ["Jean-Baptiste A. Conan"], "title": "On the Mechanistic Interpretability of Neural Networks for Causality in Bio-statistics", "categories": ["stat.AP", "cs.AI"], "comment": null, "summary": "Interpretable insights from predictive models remain critical in\nbio-statistics, particularly when assessing causality, where classical\nstatistical and machine learning methods often provide inherent clarity. While\nNeural Networks (NNs) offer powerful capabilities for modeling complex\nbiological data, their traditional \"black-box\" nature presents challenges for\nvalidation and trust in high-stakes health applications. Recent advances in\nMechanistic Interpretability (MI) aim to decipher the internal computations\nlearned by these networks. This work investigates the application of MI\ntechniques to NNs within the context of causal inference for bio-statistics.\n  We demonstrate that MI tools can be leveraged to: (1) probe and validate the\ninternal representations learned by NNs, such as those estimating nuisance\nfunctions in frameworks like Targeted Minimum Loss-based Estimation (TMLE); (2)\ndiscover and visualize the distinct computational pathways employed by the\nnetwork to process different types of inputs, potentially revealing how\nconfounders and treatments are handled; and (3) provide methodologies for\ncomparing the learned mechanisms and extracted insights across statistical,\nmachine learning, and NN models, fostering a deeper understanding of their\nrespective strengths and weaknesses for causal bio-statistical analysis."}
{"id": "2505.00690", "pdf": "https://arxiv.org/pdf/2505.00690", "abs": "https://arxiv.org/abs/2505.00690", "authors": ["Wayne Wu", "Honglin He", "Chaoyuan Zhang", "Jack He", "Seth Z. Zhao", "Ran Gong", "Quanyi Li", "Bolei Zhou"], "title": "Towards Autonomous Micromobility through Scalable Urban Simulation", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "CVPR 2025 Highlight. Project page:\n  https://metadriverse.github.io/urban-sim/", "summary": "Micromobility, which utilizes lightweight mobile machines moving in urban\npublic spaces, such as delivery robots and mobility scooters, emerges as a\npromising alternative to vehicular mobility. Current micromobility depends\nmostly on human manual operation (in-person or remote control), which raises\nsafety and efficiency concerns when navigating busy urban environments full of\nunpredictable obstacles and pedestrians. Assisting humans with AI agents in\nmaneuvering micromobility devices presents a viable solution for enhancing\nsafety and efficiency. In this work, we present a scalable urban simulation\nsolution to advance autonomous micromobility. First, we build URBAN-SIM - a\nhigh-performance robot learning platform for large-scale training of embodied\nagents in interactive urban scenes. URBAN-SIM contains three critical modules:\nHierarchical Urban Generation pipeline, Interactive Dynamics Generation\nstrategy, and Asynchronous Scene Sampling scheme, to improve the diversity,\nrealism, and efficiency of robot learning in simulation. Then, we propose\nURBAN-BENCH - a suite of essential tasks and benchmarks to gauge various\ncapabilities of the AI agents in achieving autonomous micromobility.\nURBAN-BENCH includes eight tasks based on three core skills of the agents:\nUrban Locomotion, Urban Navigation, and Urban Traverse. We evaluate four robots\nwith heterogeneous embodiments, such as the wheeled and legged robots, across\nthese tasks. Experiments on diverse terrains and urban structures reveal each\nrobot's strengths and limitations."}
{"id": "2505.00530", "pdf": "https://arxiv.org/pdf/2505.00530", "abs": "https://arxiv.org/abs/2505.00530", "authors": ["Xinyu Wang", "Jinbo Bi", "Minghu Song"], "title": "Leveraging Partial SMILES Validation Scheme for Enhanced Drug Design in Reinforcement Learning Frameworks", "categories": ["cs.LG", "cs.CE", "q-bio.BM"], "comment": "17 pages, 5 main figures, 2 appendix figures. Submitted to ICML 2025", "summary": "SMILES-based molecule generation has emerged as a powerful approach in drug\ndiscovery. Deep reinforcement learning (RL) using large language model (LLM)\nhas been incorporated into the molecule generation process to achieve high\nmatching score in term of likelihood of desired molecule candidates. However, a\ncritical challenge in this approach is catastrophic forgetting during the RL\nphase, where knowledge such as molecule validity, which often exceeds 99\\%\nduring pretraining, significantly deteriorates. Current RL algorithms applied\nin drug discovery, such as REINVENT, use prior models as anchors to retian\npretraining knowledge, but these methods lack robust exploration mechanisms. To\naddress these issues, we propose Partial SMILES Validation-PPO (PSV-PPO), a\nnovel RL algorithm that incorporates real-time partial SMILES validation to\nprevent catastrophic forgetting while encouraging exploration. Unlike\ntraditional RL approaches that validate molecule structures only after\ngenerating entire sequences, PSV-PPO performs stepwise validation at each\nauto-regressive step, evaluating not only the selected token candidate but also\nall potential branches stemming from the prior partial sequence. This enables\nearly detection of invalid partial SMILES across all potential paths. As a\nresult, PSV-PPO maintains high validity rates even during aggressive\nexploration of the vast chemical space. Our experiments on the PMO and GuacaMol\nbenchmark datasets demonstrate that PSV-PPO significantly reduces the number of\ninvalid generated structures while maintaining competitive exploration and\noptimization performance. While our work primarily focuses on maintaining\nvalidity, the framework of PSV-PPO can be extended in future research to\nincorporate additional forms of valuable domain knowledge, further enhancing\nreinforcement learning applications in drug discovery."}
{"id": "2505.00626", "pdf": "https://arxiv.org/pdf/2505.00626", "abs": "https://arxiv.org/abs/2505.00626", "authors": ["Zihao Wang", "Yibo Jiang", "Jiahao Yu", "Heqing Huang"], "title": "The Illusion of Role Separation: Hidden Shortcuts in LLM Role Learning (and How to Fix Them)", "categories": ["cs.CL", "cs.AI", "68T50", "I.2"], "comment": null, "summary": "Large language models (LLMs) that integrate multiple input roles (e.g.,\nsystem instructions, user queries, external tool outputs) are increasingly\nprevalent in practice. Ensuring that the model accurately distinguishes\nmessages from each role -- a concept we call \\emph{role separation} -- is\ncrucial for consistent multi-role behavior. Although recent work often targets\nstate-of-the-art prompt injection defenses, it remains unclear whether such\nmethods truly teach LLMs to differentiate roles or merely memorize known\ntriggers. In this paper, we examine \\emph{role-separation learning}: the\nprocess of teaching LLMs to robustly distinguish system and user tokens.\nThrough a \\emph{simple, controlled experimental framework}, we find that\nfine-tuned models often rely on two proxies for role identification: (1) task\ntype exploitation, and (2) proximity to begin-of-text. Although data\naugmentation can partially mitigate these shortcuts, it generally leads to\niterative patching rather than a deeper fix. To address this, we propose\nreinforcing \\emph{invariant signals} that mark role boundaries by adjusting\ntoken-wise cues in the model's input encoding. In particular, manipulating\nposition IDs helps the model learn clearer distinctions and reduces reliance on\nsuperficial proxies. By focusing on this mechanism-centered perspective, our\nwork illuminates how LLMs can more reliably maintain consistent multi-role\nbehavior without merely memorizing known prompts or triggers."}
{"id": "2505.00561", "pdf": "https://arxiv.org/pdf/2505.00561", "abs": "https://arxiv.org/abs/2505.00561", "authors": ["Kuan-Cheng Chen", "Hiromichi Matsuyama", "Wei-Hao Huang"], "title": "Learning to Learn with Quantum Optimization via Quantum Neural Networks", "categories": ["quant-ph", "cs.AI"], "comment": null, "summary": "Quantum Approximate Optimization Algorithms (QAOA) promise efficient\nsolutions to classically intractable combinatorial optimization problems by\nharnessing shallow-depth quantum circuits. Yet, their performance and\nscalability often hinge on effective parameter optimization, which remains\nnontrivial due to rugged energy landscapes and hardware noise. In this work, we\nintroduce a quantum meta-learning framework that combines quantum neural\nnetworks, specifically Quantum Long Short-Term Memory (QLSTM) architectures,\nwith QAOA. By training the QLSTM optimizer on smaller graph instances, our\napproach rapidly generalizes to larger, more complex problems, substantially\nreducing the number of iterations required for convergence. Through\ncomprehensive benchmarks on Max-Cut and Sherrington-Kirkpatrick model\ninstances, we demonstrate that QLSTM-based optimizers converge faster and\nachieve higher approximation ratios compared to classical baselines, thereby\noffering a robust pathway toward scalable quantum optimization in the NISQ era."}
{"id": "2505.00702", "pdf": "https://arxiv.org/pdf/2505.00702", "abs": "https://arxiv.org/abs/2505.00702", "authors": ["Hanwen Jiang", "Hao Tan", "Peng Wang", "Haian Jin", "Yue Zhao", "Sai Bi", "Kai Zhang", "Fujun Luan", "Kalyan Sunkavalli", "Qixing Huang", "Georgios Pavlakos"], "title": "RayZer: A Self-supervised Large View Synthesis Model", "categories": ["cs.CV"], "comment": null, "summary": "We present RayZer, a self-supervised multi-view 3D Vision model trained\nwithout any 3D supervision, i.e., camera poses and scene geometry, while\nexhibiting emerging 3D awareness. Concretely, RayZer takes unposed and\nuncalibrated images as input, recovers camera parameters, reconstructs a scene\nrepresentation, and synthesizes novel views. During training, RayZer relies\nsolely on its self-predicted camera poses to render target views, eliminating\nthe need for any ground-truth camera annotations and allowing RayZer to be\ntrained with 2D image supervision. The emerging 3D awareness of RayZer is\nattributed to two key factors. First, we design a self-supervised framework,\nwhich achieves 3D-aware auto-encoding of input images by disentangling camera\nand scene representations. Second, we design a transformer-based model in which\nthe only 3D prior is the ray structure, connecting camera, pixel, and scene\nsimultaneously. RayZer demonstrates comparable or even superior novel view\nsynthesis performance than ``oracle'' methods that rely on pose annotations in\nboth training and testing. Project: https://hwjiang1510.github.io/RayZer/"}
{"id": "2505.00541", "pdf": "https://arxiv.org/pdf/2505.00541", "abs": "https://arxiv.org/abs/2505.00541", "authors": ["Amarpal Sahota", "Navid Mohammadi Foumani", "Raul Santos-Rodriguez", "Zahraa S. Abdallah"], "title": "KnowEEG: Explainable Knowledge Driven EEG Classification", "categories": ["cs.LG"], "comment": null, "summary": "Electroencephalography (EEG) is a method of recording brain activity that\nshows significant promise in applications ranging from disease classification\nto emotion detection and brain-computer interfaces. Recent advances in deep\nlearning have improved EEG classification performance yet model explainability\nremains an issue. To address this key limitation of explainability we introduce\nKnowEEG; a novel explainable machine learning approach for EEG classification.\nKnowEEG extracts a comprehensive set of per-electrode features, filters them\nusing statistical tests, and integrates between-electrode connectivity\nstatistics. These features are then input to our modified Random Forest model\n(Fusion Forest) that balances per electrode statistics with between electrode\nconnectivity features in growing the trees of the forest. By incorporating\nknowledge from both the generalized time-series and EEG-specific domains,\nKnowEEG achieves performance comparable to or exceeding state-of-the-art deep\nlearning models across five different classification tasks: emotion detection,\nmental workload classification, eyes open/closed detection, abnormal EEG\nclassification, and event detection. In addition to high performance, KnowEEG\nprovides inherent explainability through feature importance scores for\nunderstandable features. We demonstrate by example on the eyes closed/open\nclassification task that this explainability can be used to discover knowledge\nabout the classes. This discovered knowledge for eyes open/closed\nclassification was proven to be correct by current neuroscience literature.\nTherefore, the impact of KnowEEG will be significant for domains where EEG\nexplainability is critical such as healthcare."}
{"id": "2505.00654", "pdf": "https://arxiv.org/pdf/2505.00654", "abs": "https://arxiv.org/abs/2505.00654", "authors": ["Daniel N. Nissani"], "title": "Large Language Models Understanding: an Inherent Ambiguity Barrier", "categories": ["cs.CL", "cs.AI"], "comment": "submitted to NEURAL COMPUTATION", "summary": "A lively ongoing debate is taking place, since the extraordinary emergence of\nLarge Language Models (LLMs) with regards to their capability to understand the\nworld and capture the meaning of the dialogues in which they are involved.\nArguments and counter-arguments have been proposed based upon thought\nexperiments, anecdotal conversations between LLMs and humans, statistical\nlinguistic analysis, philosophical considerations, and more. In this brief\npaper we present a counter-argument based upon a thought experiment and\nsemi-formal considerations leading to an inherent ambiguity barrier which\nprevents LLMs from having any understanding of what their amazingly fluent\ndialogues mean."}
{"id": "2505.00562", "pdf": "https://arxiv.org/pdf/2505.00562", "abs": "https://arxiv.org/abs/2505.00562", "authors": ["Yue Meng", "Chuchu Fan"], "title": "TeLoGraF: Temporal Logic Planning via Graph-encoded Flow Matching", "categories": ["cs.RO", "cs.AI", "cs.FL", "cs.LG"], "comment": "Accepted to ICML2025", "summary": "Learning to solve complex tasks with signal temporal logic (STL)\nspecifications is crucial to many real-world applications. However, most\nprevious works only consider fixed or parametrized STL specifications due to\nthe lack of a diverse STL dataset and encoders to effectively extract temporal\nlogic information for downstream tasks. In this paper, we propose TeLoGraF,\nTemporal Logic Graph-encoded Flow, which utilizes Graph Neural Networks (GNN)\nencoder and flow-matching to learn solutions for general STL specifications. We\nidentify four commonly used STL templates and collect a total of 200K\nspecifications with paired demonstrations. We conduct extensive experiments in\nfive simulation environments ranging from simple dynamical models in the 2D\nspace to high-dimensional 7DoF Franka Panda robot arm and Ant quadruped\nnavigation. Results show that our method outperforms other baselines in the STL\nsatisfaction rate. Compared to classical STL planning algorithms, our approach\nis 10-100X faster in inference and can work on any system dynamics. Besides, we\nshow our graph-encoding method's capability to solve complex STLs and\nrobustness to out-distribution STL specifications. Code is available at\nhttps://github.com/mengyuest/TeLoGraF"}
{"id": "2505.00703", "pdf": "https://arxiv.org/pdf/2505.00703", "abs": "https://arxiv.org/abs/2505.00703", "authors": ["Dongzhi Jiang", "Ziyu Guo", "Renrui Zhang", "Zhuofan Zong", "Hao Li", "Le Zhuo", "Shilin Yan", "Pheng-Ann Heng", "Hongsheng Li"], "title": "T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "Project Page: https://github.com/CaraJ7/T2I-R1", "summary": "Recent advancements in large language models have demonstrated how\nchain-of-thought (CoT) and reinforcement learning (RL) can improve performance.\nHowever, applying such reasoning strategies to the visual generation domain\nremains largely unexplored. In this paper, we present T2I-R1, a novel\nreasoning-enhanced text-to-image generation model, powered by RL with a\nbi-level CoT reasoning process. Specifically, we identify two levels of CoT\nthat can be utilized to enhance different stages of generation: (1) the\nsemantic-level CoT for high-level planning of the prompt and (2) the\ntoken-level CoT for low-level pixel processing during patch-by-patch\ngeneration. To better coordinate these two levels of CoT, we introduce\nBiCoT-GRPO with an ensemble of generation rewards, which seamlessly optimizes\nboth generation CoTs within the same training step. By applying our reasoning\nstrategies to the baseline model, Janus-Pro, we achieve superior performance\nwith 13% improvement on T2I-CompBench and 19% improvement on the WISE\nbenchmark, even surpassing the state-of-the-art model FLUX.1. Code is available\nat: https://github.com/CaraJ7/T2I-R1"}
{"id": "2505.00546", "pdf": "https://arxiv.org/pdf/2505.00546", "abs": "https://arxiv.org/abs/2505.00546", "authors": ["Qingyuan Wu", "Yuhui Wang", "Simon Sinong Zhan", "Yixuan Wang", "Chung-Wei Lin", "Chen Lv", "Qi Zhu", "Jürgen Schmidhuber", "Chao Huang"], "title": "Directly Forecasting Belief for Reinforcement Learning with Delays", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement learning (RL) with delays is challenging as sensory perceptions\nlag behind the actual events: the RL agent needs to estimate the real state of\nits environment based on past observations. State-of-the-art (SOTA) methods\ntypically employ recursive, step-by-step forecasting of states. This can cause\nthe accumulation of compounding errors. To tackle this problem, our novel\nbelief estimation method, named Directly Forecasting Belief Transformer (DFBT),\ndirectly forecasts states from observations without incrementally estimating\nintermediate states step-by-step. We theoretically demonstrate that DFBT\ngreatly reduces compounding errors of existing recursively forecasting methods,\nyielding stronger performance guarantees. In experiments with D4RL offline\ndatasets, DFBT reduces compounding errors with remarkable prediction accuracy.\nDFBT's capability to forecast state sequences also facilitates multi-step\nbootstrapping, thus greatly improving learning efficiency. On the MuJoCo\nbenchmark, our DFBT-based method substantially outperforms SOTA baselines."}
{"id": "2505.00661", "pdf": "https://arxiv.org/pdf/2505.00661", "abs": "https://arxiv.org/abs/2505.00661", "authors": ["Andrew K. Lampinen", "Arslan Chaudhry", "Stephanie C. Y. Chan", "Cody Wild", "Diane Wan", "Alex Ku", "Jörg Bornschein", "Razvan Pascanu", "Murray Shanahan", "James L. McClelland"], "title": "On the generalization of language models from in-context learning and finetuning: a controlled study", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models exhibit exciting capabilities, yet can show\nsurprisingly narrow generalization from finetuning -- from failing to\ngeneralize to simple reversals of relations they are trained on, to missing\nlogical deductions that can be made from trained information. These failures to\ngeneralize from fine-tuning can hinder practical application of these models.\nHowever, language models' in-context learning shows different inductive biases,\nand can generalize better in some of these cases. Here, we explore these\ndifferences in generalization between in-context- and fine-tuning-based\nlearning. To do so, we constructed several novel datasets to evaluate and\nimprove models' ability to generalize from finetuning data. The datasets are\nconstructed to isolate the knowledge in the dataset from that in pretraining,\nto create clean tests of generalization. We expose pretrained large models to\ncontrolled subsets of the information in these datasets -- either in context,\nor through fine-tuning -- and evaluate their performance on test sets that\nrequire various types of generalization. We find overall that in data-matched\nsettings, in-context learning can generalize more flexibly than fine-tuning\n(though we also find some qualifications of prior findings, such as cases when\nfine-tuning can generalize to reversals embedded in a larger structure of\nknowledge). We build on these findings to propose a method to enable improved\ngeneralization from fine-tuning: adding in-context inferences to finetuning\ndata. We show that this method improves generalization across various splits of\nour datasets and other benchmarks. Our results have implications for\nunderstanding the inductive biases of different modes of learning in language\nmodels, and practically improving their performance."}
{"id": "2505.00596", "pdf": "https://arxiv.org/pdf/2505.00596", "abs": "https://arxiv.org/abs/2505.00596", "authors": ["Alex Schutz", "Yang You", "Matias Mattamala", "Ipek Caliskanelli", "Bruno Lacerda", "Nick Hawes"], "title": "A Finite-State Controller Based Offline Solver for Deterministic POMDPs", "categories": ["cs.RO", "cs.AI", "cs.LG", "I.2.8; I.2.9"], "comment": "9 pages, 6 figures. Appendix attached. To be published in Proceedings\n  of IJCAI 2025. For code see http://github.com/ori-goals/DetMCVI", "summary": "Deterministic partially observable Markov decision processes (DetPOMDPs)\noften arise in planning problems where the agent is uncertain about its\nenvironmental state but can act and observe deterministically. In this paper,\nwe propose DetMCVI, an adaptation of the Monte Carlo Value Iteration (MCVI)\nalgorithm for DetPOMDPs, which builds policies in the form of finite-state\ncontrollers (FSCs). DetMCVI solves large problems with a high success rate,\noutperforming existing baselines for DetPOMDPs. We also verify the performance\nof the algorithm in a real-world mobile robot forest mapping scenario."}
{"id": "2504.21707", "pdf": "https://arxiv.org/pdf/2504.21707", "abs": "https://arxiv.org/abs/2504.21707", "authors": ["Anthony D Martin"], "title": "Recursive KL Divergence Optimization: A Dynamic Framework for Representation Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.IT", "cs.NE", "math.IT"], "comment": null, "summary": "We propose a generalization of modern representation learning objectives by\nreframing them as recursive divergence alignment processes over localized\nconditional distributions While recent frameworks like Information Contrastive\nLearning I-Con unify multiple learning paradigms through KL divergence between\nfixed neighborhood conditionals we argue this view underplays a crucial\nrecursive structure inherent in the learning process. We introduce Recursive KL\nDivergence Optimization RKDO a dynamic formalism where representation learning\nis framed as the evolution of KL divergences across data neighborhoods. This\nformulation captures contrastive clustering and dimensionality reduction\nmethods as static slices while offering a new path to model stability and local\nadaptation. Our experiments demonstrate that RKDO offers dual efficiency\nadvantages approximately 30 percent lower loss values compared to static\napproaches across three different datasets and 60 to 80 percent reduction in\ncomputational resources needed to achieve comparable results. This suggests\nthat RKDOs recursive updating mechanism provides a fundamentally more efficient\noptimization landscape for representation learning with significant\nimplications for resource constrained applications."}
{"id": "2505.00580", "pdf": "https://arxiv.org/pdf/2505.00580", "abs": "https://arxiv.org/abs/2505.00580", "authors": ["Xinyu Ding", "Lexuan Chen", "Siyu Liao", "Zhongfeng Wang"], "title": "Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors", "categories": ["cs.LG"], "comment": "to appear in Proceedings of the 2025 International Joint Conference\n  on Artificial Intelligence (IJCAI-2025)", "summary": "Foundation models have achieved tremendous success in different domains.\nHowever, their huge computation and storage complexity make these models\ndifficult to fine-tune and also less applicable in practice. Recent study shows\ntraining in Fourier domain can be an effective fine-tuning method in terms of\nboth model performance and number of training parameters. In this work, we\npropose to further reduce the complexity by the factorization through the\nproduct of interleaved circulant and diagonal matrices. In addition, we address\nthe case of non-square fine-tuning weights by partitioning the circulant matrix\ninto blocks. Our method avoids the construction of weight change matrix and\nutilizes 1D fast Fourier transform (FFT) instead of 2D FFT. Experimental\nresults show that our method achieves similar or better performance across\nvarious tasks with much less floating-point operations (FLOPs) and the number\nof trainable parameters."}
{"id": "2505.00662", "pdf": "https://arxiv.org/pdf/2505.00662", "abs": "https://arxiv.org/abs/2505.00662", "authors": ["Wenkai Yang", "Jingwen Chen", "Yankai Lin", "Ji-Rong Wen"], "title": "DeepCritic: Deliberate Critique with Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Work in progress. Data and models are available at\n  https://github.com/RUCBM/DeepCritic", "summary": "As Large Language Models (LLMs) are rapidly evolving, providing accurate\nfeedback and scalable oversight on their outputs becomes an urgent and critical\nproblem. Leveraging LLMs as critique models to achieve automated supervision is\na promising solution. In this work, we focus on studying and enhancing the math\ncritique ability of LLMs. Current LLM critics provide critiques that are too\nshallow and superficial on each step, leading to low judgment accuracy and\nstruggling to offer sufficient feedback for the LLM generator to correct\nmistakes. To tackle this issue, we propose a novel and effective two-stage\nframework to develop LLM critics that are capable of deliberately critiquing on\neach reasoning step of math solutions. In the first stage, we utilize\nQwen2.5-72B-Instruct to generate 4.5K long-form critiques as seed data for\nsupervised fine-tuning. Each seed critique consists of deliberate step-wise\ncritiques that includes multi-perspective verifications as well as in-depth\ncritiques of initial critiques for each reasoning step. Then, we perform\nreinforcement learning on the fine-tuned model with either existing\nhuman-labeled data from PRM800K or our automatically annotated data obtained\nvia Monte Carlo sampling-based correctness estimation, to further incentivize\nits critique ability. Our developed critique model built on Qwen2.5-7B-Instruct\nnot only significantly outperforms existing LLM critics (including the\nsame-sized DeepSeek-R1-distill models and GPT-4o) on various error\nidentification benchmarks, but also more effectively helps the LLM generator\nrefine erroneous steps through more detailed feedback."}
{"id": "2505.00598", "pdf": "https://arxiv.org/pdf/2505.00598", "abs": "https://arxiv.org/abs/2505.00598", "authors": ["Haozheng Luo", "Chenghao Qiu", "Maojiang Su", "Zhihan Zhou", "Zoe Mehta", "Guo Ye", "Jerry Yao-Chieh Hu", "Han Liu"], "title": "Fast and Low-Cost Genomic Foundation Models via Outlier Removal", "categories": ["cs.LG", "cs.AI"], "comment": "International Conference on Machine Learning (ICML) 2025", "summary": "We propose the first unified adversarial attack benchmark for Genomic\nFoundation Models (GFMs), named GERM. Unlike existing GFM benchmarks, GERM\noffers the first comprehensive evaluation framework to systematically assess\nthe vulnerability of GFMs to adversarial attacks. Methodologically, we evaluate\nthe adversarial robustness of five state-of-the-art GFMs using four widely\nadopted attack algorithms and three defense strategies. Importantly, our\nbenchmark provides an accessible and comprehensive framework to analyze GFM\nvulnerabilities with respect to model architecture, quantization schemes, and\ntraining datasets. Empirically, transformer-based models exhibit greater\nrobustness to adversarial perturbations compared to HyenaDNA, highlighting the\nimpact of architectural design on vulnerability. Moreover, adversarial attacks\nfrequently target biologically significant genomic regions, suggesting that\nthese models effectively capture meaningful sequence features."}
{"id": "2505.00590", "pdf": "https://arxiv.org/pdf/2505.00590", "abs": "https://arxiv.org/abs/2505.00590", "authors": ["Chengsen Wang", "Qi Qi", "Jingyu Wang", "Haifeng Sun", "Zirui Zhuang", "Jianxin Liao"], "title": "Unlocking the Potential of Linear Networks for Irregular Multivariate Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Time series forecasting holds significant importance across various\nindustries, including finance, transportation, energy, healthcare, and climate.\nDespite the widespread use of linear networks due to their low computational\ncost and effectiveness in modeling temporal dependencies, most existing\nresearch has concentrated on regularly sampled and fully observed multivariate\ntime series. However, in practice, we frequently encounter irregular\nmultivariate time series characterized by variable sampling intervals and\nmissing values. The inherent intra-series inconsistency and inter-series\nasynchrony in such data hinder effective modeling and forecasting with\ntraditional linear networks relying on static weights. To tackle these\nchallenges, this paper introduces a novel model named AiT. AiT utilizes an\nadaptive linear network capable of dynamically adjusting weights according to\nobservation time points to address intra-series inconsistency, thereby\nenhancing the accuracy of temporal dependencies modeling. Furthermore, by\nincorporating the Transformer module on variable semantics embeddings, AiT\nefficiently captures variable correlations, avoiding the challenge of\ninter-series asynchrony. Comprehensive experiments across four benchmark\ndatasets demonstrate the superiority of AiT, improving prediction accuracy by\n11% and decreasing runtime by 52% compared to existing state-of-the-art\nmethods."}
{"id": "2505.00675", "pdf": "https://arxiv.org/pdf/2505.00675", "abs": "https://arxiv.org/abs/2505.00675", "authors": ["Yiming Du", "Wenyu Huang", "Danna Zheng", "Zhaowei Wang", "Sebastien Montella", "Mirella Lapata", "Kam-Fai Wong", "Jeff Z. Pan"], "title": "Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future Directions", "categories": ["cs.CL"], "comment": null, "summary": "Memory is a fundamental component of AI systems, underpinning large language\nmodels (LLMs) based agents. While prior surveys have focused on memory\napplications with LLMs, they often overlook the atomic operations that underlie\nmemory dynamics. In this survey, we first categorize memory representations\ninto parametric, contextual structured, and contextual unstructured and then\nintroduce six fundamental memory operations: Consolidation, Updating, Indexing,\nForgetting, Retrieval, and Compression. We systematically map these operations\nto the most relevant research topics across long-term, long-context, parametric\nmodification, and multi-source memory. By reframing memory systems through the\nlens of atomic operations and representation types, this survey provides a\nstructured and dynamic perspective on research, benchmark datasets, and tools\nrelated to memory in AI, clarifying the functional interplay in LLMs based\nagents while outlining promising directions for future research\\footnote{The\npaper list, datasets, methods and tools are available at\n\\href{https://github.com/Elvin-Yiming-Du/Survey_Memory_in_AI}{https://github.com/Elvin-Yiming-Du/Survey\\_Memory\\_in\\_AI}.}."}
{"id": "2505.00622", "pdf": "https://arxiv.org/pdf/2505.00622", "abs": "https://arxiv.org/abs/2505.00622", "authors": ["Colin Kessler", "Ekaterina Komendantskaya", "Marco Casadio", "Ignazio Maria Viola", "Thomas Flinkow", "Albaraa Ammar Othman", "Alistair Malhotra", "Robbie McPherson"], "title": "Neural Network Verification for Gliding Drone Control: A Case Study", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": "18 page pre print, submitted to SAIV 2025 (conference)", "summary": "As machine learning is increasingly deployed in autonomous systems,\nverification of neural network controllers is becoming an active research\ndomain. Existing tools and annual verification competitions suggest that soon\nthis technology will become effective for real-world applications. Our\napplication comes from the emerging field of microflyers that are passively\ntransported by the wind, which may have various uses in weather or pollution\nmonitoring. Specifically, we investigate centimetre-scale bio-inspired gliding\ndrones that resemble Alsomitra macrocarpa diaspores. In this paper, we propose\na new case study on verifying Alsomitra-inspired drones with neural network\ncontrollers, with the aim of adhering closely to a target trajectory. We show\nthat our system differs substantially from existing VNN and ARCH competition\nbenchmarks, and show that a combination of tools holds promise for verifying\nsuch systems in the future, if certain shortcomings can be overcome. We propose\na novel method for robust training of regression networks, and investigate\nformalisations of this case study in Vehicle and CORA. Our verification results\nsuggest that the investigated training methods do improve performance and\nrobustness of neural network controllers in this application, but are limited\nin scope and usefulness. This is due to systematic limitations of both Vehicle\nand CORA, and the complexity of our system reducing the scale of reachability,\nwhich we investigate in detail. If these limitations can be overcome, it will\nenable engineers to develop safe and robust technologies that improve people's\nlives and reduce our impact on the environment."}
{"id": "2505.00681", "pdf": "https://arxiv.org/pdf/2505.00681", "abs": "https://arxiv.org/abs/2505.00681", "authors": ["Arsha Nagrani", "Sachit Menon", "Ahmet Iscen", "Shyamal Buch", "Ramin Mehran", "Nilpa Jha", "Anja Hauth", "Yukun Zhu", "Carl Vondrick", "Mikhail Sirotenko", "Cordelia Schmid", "Tobias Weyand"], "title": "MINERVA: Evaluating Complex Video Reasoning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Multimodal LLMs are turning their focus to video benchmarks, however most\nvideo benchmarks only provide outcome supervision, with no intermediate or\ninterpretable reasoning steps. This makes it challenging to assess if models\nare truly able to combine perceptual and temporal information to reason about\nvideos, or simply get the correct answer by chance or by exploiting linguistic\nbiases. To remedy this, we provide a new video reasoning dataset called MINERVA\nfor modern multimodal models. Each question in the dataset comes with 5 answer\nchoices, as well as detailed, hand-crafted reasoning traces. Our dataset is\nmultimodal, diverse in terms of video domain and length, and consists of\ncomplex multi-step questions. Extensive benchmarking shows that our dataset\nprovides a challenge for frontier open-source and proprietary models. We\nperform fine-grained error analysis to identify common failure modes across\nvarious models, and create a taxonomy of reasoning errors. We use this to\nexplore both human and LLM-as-a-judge methods for scoring video reasoning\ntraces, and find that failure modes are primarily related to temporal\nlocalization, followed by visual perception errors, as opposed to logical or\ncompleteness errors. The dataset, along with questions, answer candidates and\nreasoning traces will be publicly available under\nhttps://github.com/google-deepmind/neptune?tab=readme-ov-file\\#minerva."}
{"id": "2505.00591", "pdf": "https://arxiv.org/pdf/2505.00591", "abs": "https://arxiv.org/abs/2505.00591", "authors": ["Ziqi Li"], "title": "Explainable AI in Spatial Analysis", "categories": ["cs.LG", "econ.EM"], "comment": null, "summary": "This chapter discusses the opportunities of eXplainable Artificial\nIntelligence (XAI) within the realm of spatial analysis. A key objective in\nspatial analysis is to model spatial relationships and infer spatial processes\nto generate knowledge from spatial data, which has been largely based on\nspatial statistical methods. More recently, machine learning offers scalable\nand flexible approaches that complement traditional methods and has been\nincreasingly applied in spatial data science. Despite its advantages, machine\nlearning is often criticized for being a black box, which limits our\nunderstanding of model behavior and output. Recognizing this limitation, XAI\nhas emerged as a pivotal field in AI that provides methods to explain the\noutput of machine learning models to enhance transparency and understanding.\nThese methods are crucial for model diagnosis, bias detection, and ensuring the\nreliability of results obtained from machine learning models. This chapter\nintroduces key concepts and methods in XAI with a focus on Shapley value-based\napproaches, which is arguably the most popular XAI method, and their\nintegration with spatial analysis. An empirical example of county-level voting\nbehaviors in the 2020 Presidential election is presented to demonstrate the use\nof Shapley values and spatial analysis with a comparison to multi-scale\ngeographically weighted regression. The chapter concludes with a discussion on\nthe challenges and limitations of current XAI techniques and proposes new\ndirections."}
{"id": "2505.00679", "pdf": "https://arxiv.org/pdf/2505.00679", "abs": "https://arxiv.org/abs/2505.00679", "authors": ["Xinchen Yang", "Marine Carpuat"], "title": "Steering Large Language Models with Register Analysis for Arbitrary Style Transfer", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong capabilities in\nrewriting text across various styles. However, effectively leveraging this\nability for example-based arbitrary style transfer, where an input text is\nrewritten to match the style of a given exemplar, remains an open challenge. A\nkey question is how to describe the style of the exemplar to guide LLMs toward\nhigh-quality rewrites. In this work, we propose a prompting method based on\nregister analysis to guide LLMs to perform this task. Empirical evaluations\nacross multiple style transfer tasks show that our prompting approach enhances\nstyle transfer strength while preserving meaning more effectively than existing\nprompting strategies."}
{"id": "2505.00650", "pdf": "https://arxiv.org/pdf/2505.00650", "abs": "https://arxiv.org/abs/2505.00650", "authors": ["Atahan Karagoz"], "title": "OmicsCL: Unsupervised Contrastive Learning for Cancer Subtype Discovery and Survival Stratification", "categories": ["cs.LG", "cs.AI", "q-bio.GN", "q-bio.QM"], "comment": "Code available at: https://github.com/Atahanka/OmicsCL", "summary": "Unsupervised learning of disease subtypes from multi-omics data presents a\nsignificant opportunity for advancing personalized medicine. We introduce\nOmicsCL, a modular contrastive learning framework that jointly embeds\nheterogeneous omics modalities-such as gene expression, DNA methylation, and\nmiRNA expression-into a unified latent space. Our method incorporates a\nsurvival-aware contrastive loss that encourages the model to learn\nrepresentations aligned with survival-related patterns, without relying on\nlabeled outcomes. Evaluated on the TCGA BRCA dataset, OmicsCL uncovers\nclinically meaningful clusters and achieves strong unsupervised concordance\nwith patient survival. The framework demonstrates robustness across\nhyperparameter configurations and can be tuned to prioritize either subtype\ncoherence or survival stratification. Ablation studies confirm that integrating\nsurvival-aware loss significantly enhances the predictive power of learned\nembeddings. These results highlight the promise of contrastive objectives for\nbiological insight discovery in high-dimensional, heterogeneous omics data."}
{"id": "2505.00693", "pdf": "https://arxiv.org/pdf/2505.00693", "abs": "https://arxiv.org/abs/2505.00693", "authors": ["Yanbang Li", "Ziyang Gong", "Haoyang Li", "Haoyang Li", "Xiaoqi Huang", "Haolan Kang", "Guangping Bai", "Xianzheng Ma"], "title": "Robotic Visual Instruction", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "Recently, natural language has been the primary medium for human-robot\ninteraction. However, its inherent lack of spatial precision for robotic\ncontrol introduces challenges such as ambiguity and verbosity. To address these\nlimitations, we introduce the Robotic Visual Instruction (RoVI), a novel\nparadigm to guide robotic tasks through an object-centric, hand-drawn symbolic\nrepresentation. RoVI effectively encodes spatial-temporal information into\nhuman-interpretable visual instructions through 2D sketches, utilizing arrows,\ncircles, colors, and numbers to direct 3D robotic manipulation. To enable\nrobots to understand RoVI better and generate precise actions based on RoVI, we\npresent Visual Instruction Embodied Workflow (VIEW), a pipeline formulated for\nRoVI-conditioned policies. This approach leverages Vision-Language Models\n(VLMs) to interpret RoVI inputs, decode spatial and temporal constraints from\n2D pixel space via keypoint extraction, and then transform them into executable\n3D action sequences. We additionally curate a specialized dataset of 15K\ninstances to fine-tune small VLMs for edge deployment, enabling them to\neffectively learn RoVI capabilities. Our approach is rigorously validated\nacross 11 novel tasks in both real and simulated environments, demonstrating\nsignificant generalization capability. Notably, VIEW achieves an 87.5% success\nrate in real-world scenarios involving unseen tasks that feature multi-step\nactions, with disturbances, and trajectory-following requirements. Code and\nDatasets in this paper will be released soon."}
{"id": "2505.00663", "pdf": "https://arxiv.org/pdf/2505.00663", "abs": "https://arxiv.org/abs/2505.00663", "authors": ["David Pfau", "Ian Davies", "Diana Borsa", "Joao G. M. Araujo", "Brendan Tracey", "Hado van Hasselt"], "title": "Wasserstein Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ICML 2025", "summary": "We introduce Wasserstein Policy Optimization (WPO), an actor-critic algorithm\nfor reinforcement learning in continuous action spaces. WPO can be derived as\nan approximation to Wasserstein gradient flow over the space of all policies\nprojected into a finite-dimensional parameter space (e.g., the weights of a\nneural network), leading to a simple and completely general closed-form update.\nThe resulting algorithm combines many properties of deterministic and classic\npolicy gradient methods. Like deterministic policy gradients, it exploits\nknowledge of the gradient of the action-value function with respect to the\naction. Like classic policy gradients, it can be applied to stochastic policies\nwith arbitrary distributions over actions -- without using the\nreparameterization trick. We show results on the DeepMind Control Suite and a\nmagnetic confinement fusion task which compare favorably with state-of-the-art\ncontinuous control methods."}
{"id": "2505.00049", "pdf": "https://arxiv.org/pdf/2505.00049", "abs": "https://arxiv.org/abs/2505.00049", "authors": ["Wenhan Dong", "Yuemeng Zhao", "Zhen Sun", "Yule Liu", "Zifan Peng", "Jingyi Zheng", "Zongmin Zhang", "Ziyi Zhang", "Jun Wu", "Ruiming Wang", "Shengmin Xu", "Xinyi Huang", "Xinlei He"], "title": "Humanizing LLMs: A Survey of Psychological Measurements with Tools, Datasets, and Human-Agent Applications", "categories": ["cs.CY", "cs.CL", "cs.HC", "cs.LG"], "comment": "26 pages,7 figures", "summary": "As large language models (LLMs) are increasingly used in human-centered\ntasks, assessing their psychological traits is crucial for understanding their\nsocial impact and ensuring trustworthy AI alignment. While existing reviews\nhave covered some aspects of related research, several important areas have not\nbeen systematically discussed, including detailed discussions of diverse\npsychological tests, LLM-specific psychological datasets, and the applications\nof LLMs with psychological traits. To address this gap, we systematically\nreview six key dimensions of applying psychological theories to LLMs: (1)\nassessment tools; (2) LLM-specific datasets; (3) evaluation metrics\n(consistency and stability); (4) empirical findings; (5) personality simulation\nmethods; and (6) LLM-based behavior simulation. Our analysis highlights both\nthe strengths and limitations of current methods. While some LLMs exhibit\nreproducible personality patterns under specific prompting schemes, significant\nvariability remains across tasks and settings. Recognizing methodological\nchallenges such as mismatches between psychological tools and LLMs'\ncapabilities, as well as inconsistencies in evaluation practices, this study\naims to propose future directions for developing more interpretable, robust,\nand generalizable psychological assessment frameworks for LLMs."}
{"id": "2505.00704", "pdf": "https://arxiv.org/pdf/2505.00704", "abs": "https://arxiv.org/abs/2505.00704", "authors": ["Chih-Hao Lin", "Zian Wang", "Ruofan Liang", "Yuxuan Zhang", "Sanja Fidler", "Shenlong Wang", "Zan Gojcic"], "title": "Controllable Weather Synthesis and Removal with Video Diffusion Models", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Generating realistic and controllable weather effects in videos is valuable\nfor many applications. Physics-based weather simulation requires precise\nreconstructions that are hard to scale to in-the-wild videos, while current\nvideo editing often lacks realism and control. In this work, we introduce\nWeatherWeaver, a video diffusion model that synthesizes diverse weather effects\n-- including rain, snow, fog, and clouds -- directly into any input video\nwithout the need for 3D modeling. Our model provides precise control over\nweather effect intensity and supports blending various weather types, ensuring\nboth realism and adaptability. To overcome the scarcity of paired training\ndata, we propose a novel data strategy combining synthetic videos, generative\nimage editing, and auto-labeled real-world videos. Extensive evaluations show\nthat our method outperforms state-of-the-art methods in weather simulation and\nremoval, providing high-quality, physically plausible, and\nscene-identity-preserving results over various real-world videos."}
{"id": "2505.00685", "pdf": "https://arxiv.org/pdf/2505.00685", "abs": "https://arxiv.org/abs/2505.00685", "authors": ["Daniel Eftekhari", "Vardan Papyan"], "title": "On the Importance of Gaussianizing Representations", "categories": ["cs.LG"], "comment": "ICML 2025 Proceedings", "summary": "The normal distribution plays a central role in information theory - it is at\nthe same time the best-case signal and worst-case noise distribution, has the\ngreatest representational capacity of any distribution, and offers an\nequivalence between uncorrelatedness and independence for joint distributions.\nAccounting for the mean and variance of activations throughout the layers of\ndeep neural networks has had a significant effect on facilitating their\neffective training, but seldom has a prescription for precisely what\ndistribution these activations should take, and how this might be achieved,\nbeen offered. Motivated by the information-theoretic properties of the normal\ndistribution, we address this question and concurrently present normality\nnormalization: a novel normalization layer which encourages normality in the\nfeature representations of neural networks using the power transform and\nemploys additive Gaussian noise during training. Our experiments\ncomprehensively demonstrate the effectiveness of normality normalization, in\nregards to its generalization performance on an array of widely used model and\ndataset combinations, its strong performance across various common factors of\nvariation such as model width, depth, and training minibatch size, its\nsuitability for usage wherever existing normalization layers are conventionally\nused, and as a means to improving model robustness to random perturbations."}
{"id": "2505.00105", "pdf": "https://arxiv.org/pdf/2505.00105", "abs": "https://arxiv.org/abs/2505.00105", "authors": ["Naamán Huerga-Pérez", "Rubén Álvarez", "Rubén Ferrero-Guillén", "Alberto Martínez-Gutiérrez", "Javier Díez-González"], "title": "Optimization of embeddings storage for RAG systems using quantization and dimensionality reduction techniques", "categories": ["cs.IR", "cs.CL", "cs.DB"], "comment": "13 pages, 9 figures, 1 table", "summary": "Retrieval-Augmented Generation enhances language models by retrieving\nrelevant information from external knowledge bases, relying on high-dimensional\nvector embeddings typically stored in float32 precision. However, storing these\nembeddings at scale presents significant memory challenges. To address this\nissue, we systematically investigate on MTEB benchmark two complementary\noptimization strategies: quantization, evaluating standard formats (float16,\nint8, binary) and low-bit floating-point types (float8), and dimensionality\nreduction, assessing methods like PCA, Kernel PCA, UMAP, Random Projections and\nAutoencoders. Our results show that float8 quantization achieves a 4x storage\nreduction with minimal performance degradation (<0.3%), significantly\noutperforming int8 quantization at the same compression level, being simpler to\nimplement. PCA emerges as the most effective dimensionality reduction\ntechnique. Crucially, combining moderate PCA (e.g., retaining 50% dimensions)\nwith float8 quantization offers an excellent trade-off, achieving 8x total\ncompression with less performance impact than using int8 alone (which provides\nonly 4x compression). To facilitate practical application, we propose a\nmethodology based on visualizing the performance-storage trade-off space to\nidentify the optimal configuration that maximizes performance within their\nspecific memory constraints."}
{"id": "2411.11672", "pdf": "https://arxiv.org/pdf/2411.11672", "abs": "https://arxiv.org/abs/2411.11672", "authors": ["Antonio Norelli"], "title": "Artificial Scientific Discovery", "categories": ["cs.AI", "cs.LG", "I.2"], "comment": "PhD thesis, 123 pages", "summary": "Rooted in the explosion of deep learning over the past decade, this thesis\nspans from AlphaGo to ChatGPT to empirically examine the fundamental concepts\nneeded to realize the vision of an artificial scientist: a machine with the\ncapacity to autonomously generate original research and contribute to the\nexpansion of human knowledge. The investigation begins with Olivaw, an AlphaGo\nZero-like agent that discovers Othello knowledge from scratch but is unable to\ncommunicate it. This realization leads to the development of the Explanatory\nLearning (EL) framework, a formalization of the problem faced by a scientist\nwhen trying to explain a new phenomenon to their peers. The effective EL\nprescriptions allow us to crack Zendo, a popular board game simulating the\nscientific endeavor. This success comes with a fundamental insight: an\nartificial scientist must develop its own interpretation of the language used\nto explain its findings, and not rely on a rigid existing interpreter.\nQuestioning the very process of learning an interpreter, we turn our attention\nto the inner functioning of modern multimodal models. This culminates in a\nsimple idea to build CLIP-like models where interpretation and perception are\nexplicitly disentangled: a cost-effective approach that couples two unimodal\nmodels using little multimodal data and no further training. Finally, we\ndiscuss what ChatGPT and its siblings are still missing to become artificial\nscientists, and introduce the Big-Bench Symbol Interpretation Task, a benchmark\nabout interpreting Zendo-like explanations that sees LLMs going no further than\nrandom chance while being instead fully solved by humans."}
{"id": "2303.12675", "pdf": "https://arxiv.org/pdf/2303.12675", "abs": "https://arxiv.org/abs/2303.12675", "authors": ["Zeqing Xia", "Bojun Xiong", "Zhouhui Lian"], "title": "VecFontSDF: Learning to Reconstruct and Synthesize High-quality Vector Fonts via Signed Distance Functions", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2023. Project Page:\n  https://xiazeqing.github.io/VecFontSDF", "summary": "Font design is of vital importance in the digital content design and modern\nprinting industry. Developing algorithms capable of automatically synthesizing\nvector fonts can significantly facilitate the font design process. However,\nexisting methods mainly concentrate on raster image generation, and only a few\napproaches can directly synthesize vector fonts. This paper proposes an\nend-to-end trainable method, VecFontSDF, to reconstruct and synthesize\nhigh-quality vector fonts using signed distance functions (SDFs). Specifically,\nbased on the proposed SDF-based implicit shape representation, VecFontSDF\nlearns to model each glyph as shape primitives enclosed by several parabolic\ncurves, which can be precisely converted to quadratic B\\'ezier curves that are\nwidely used in vector font products. In this manner, most image generation\nmethods can be easily extended to synthesize vector fonts. Qualitative and\nquantitative experiments conducted on a publicly-available dataset demonstrate\nthat our method obtains high-quality results on several tasks, including vector\nfont reconstruction, interpolation, and few-shot vector font synthesis,\nmarkedly outperforming the state of the art. Our code and trained models are\navailable at https://xiazeqing.github.io/VecFontSDF."}
{"id": "2411.15923", "pdf": "https://arxiv.org/pdf/2411.15923", "abs": "https://arxiv.org/abs/2411.15923", "authors": ["Saba Zahid", "Sajid Ghuffar", "Obaid-ur-Rehman", "Syed Roshaan Ali Shah"], "title": "Deep Learning for automated multi-scale functional field boundaries extraction using multi-date Sentinel-2 and PlanetScope imagery: Case Study of Netherlands and Pakistan", "categories": ["cs.CV", "cs.AI", "cs.LG", "I.2; I.2.10"], "comment": "09 pages, To be published", "summary": "This study explores the effectiveness of multi-temporal satellite imagery for\nbetter functional field boundary delineation using deep learning semantic\nsegmentation architecture on two distinct geographical and multi-scale farming\nsystems of Netherlands and Pakistan. Multidate images of April, August and\nOctober 2022 were acquired for PlanetScope and Sentinel-2 in sub regions of\nNetherlands and November 2022, February and March 2023 for selected area of\nDunyapur in Pakistan. For Netherlands, Basic registration crop parcels (BRP)\nvector layer was used as labeled training data. while self-crafted field\nboundary vector data were utilized for Pakistan. Four deep learning models with\nUNET architecture were evaluated using different combinations of multi-date\nimages and NDVI stacks in the Netherlands subregions. A comparative analysis of\nIoU scores assessed the effectiveness of the proposed multi-date NDVI stack\napproach. These findings were then applied for transfer learning, using\npre-trained models from the Netherlands on the selected area in Pakistan.\nAdditionally, separate models were trained using self-crafted field boundary\ndata for Pakistan, and combined models were developed using data from both the\nNetherlands and Pakistan. Results indicate that multi-date NDVI stacks provide\nadditional temporal context, reflecting crop growth over different times of the\nseason. The study underscores the critical role of multi-scale ground\ninformation from diverse geographical areas in developing robust and\nuniversally applicable models for field boundary delineation. The results also\nhighlight the importance of fine spatial resolution for extraction of field\nboundaries in regions with small scale framing. The findings can be extended to\nmulti-scale implementations for improved automatic field boundary delineation\nin heterogeneous agricultural environments."}
{"id": "2505.00263", "pdf": "https://arxiv.org/pdf/2505.00263", "abs": "https://arxiv.org/abs/2505.00263", "authors": ["Michael J. Ryan", "Danmei Xu", "Chris Nivera", "Daniel Campos"], "title": "EnronQA: Towards Personalized RAG over Private Documents", "categories": ["cs.IR", "cs.CL"], "comment": "26 pages, 4 figures, 6 tables", "summary": "Retrieval Augmented Generation (RAG) has become one of the most popular\nmethods for bringing knowledge-intensive context to large language models (LLM)\nbecause of its ability to bring local context at inference time without the\ncost or data leakage risks associated with fine-tuning. A clear separation of\nprivate information from the LLM training has made RAG the basis for many\nenterprise LLM workloads as it allows the company to augment LLM's\nunderstanding using customers' private documents. Despite its popularity for\nprivate documents in enterprise deployments, current RAG benchmarks for\nvalidating and optimizing RAG pipelines draw their corpora from public data\nsuch as Wikipedia or generic web pages and offer little to no personal context.\nSeeking to empower more personal and private RAG we release the EnronQA\nbenchmark, a dataset of 103,638 emails with 528,304 question-answer pairs\nacross 150 different user inboxes. EnronQA enables better benchmarking of RAG\npipelines over private data and allows for experimentation on the introduction\nof personalized retrieval settings over realistic data. Finally, we use EnronQA\nto explore the tradeoff in memorization and retrieval when reasoning over\nprivate documents."}
{"id": "2501.16961", "pdf": "https://arxiv.org/pdf/2501.16961", "abs": "https://arxiv.org/abs/2501.16961", "authors": ["Mohammad Raza", "Natasa Milic-Frayling"], "title": "Instantiation-based Formalization of Logical Reasoning Tasks using Language Models and Logical Solvers", "categories": ["cs.AI"], "comment": "IJCAI 2025", "summary": "Robustness of reasoning remains a significant challenge for large language\nmodels, and addressing it is essential for the practical applicability of\nAI-driven reasoning systems. We introduce Semantic Self-Verification (SSV), a\nnovel approach that addresses the key challenge in combining language models\nwith the rigor of logical solvers: to accurately formulate the reasoning\nproblem from natural language to the formal language of the solver. SSV uses a\nconsistency-based approach to produce strong abstract formalizations of\nproblems using concrete instantiations that are generated by the model and\nverified by the solver. In addition to significantly advancing the overall\nreasoning accuracy over the state-of-the-art, a key novelty that this approach\npresents is a feature of verification that has near-perfect precision over a\nsignificant coverage of cases, as we demonstrate on open reasoning benchmarks.\nWe propose such *near-certain reasoning* as a new approach to reduce the need\nfor manual verification in many cases, taking us closer to more dependable and\nautonomous AI reasoning systems."}
{"id": "2309.08035", "pdf": "https://arxiv.org/pdf/2309.08035", "abs": "https://arxiv.org/abs/2309.08035", "authors": ["Yao Qiang", "Chengyin Li", "Prashant Khanduri", "Dongxiao Zhu"], "title": "Interpretability-Aware Vision Transformer", "categories": ["cs.CV"], "comment": "10 pages, 4 figures, 5 tables", "summary": "Vision Transformers (ViTs) have become prominent models for solving various\nvision tasks. However, the interpretability of ViTs has not kept pace with\ntheir promising performance. While there has been a surge of interest in\ndeveloping {\\it post hoc} solutions to explain ViTs' outputs, these methods do\nnot generalize to different downstream tasks and various transformer\narchitectures. Furthermore, if ViTs are not properly trained with the given\ndata and do not prioritize the region of interest, the {\\it post hoc} methods\nwould be less effective. Instead of developing another {\\it post hoc} approach,\nwe introduce a novel training procedure that inherently enhances model\ninterpretability. Our interpretability-aware ViT (IA-ViT) draws inspiration\nfrom a fresh insight: both the class patch and image patches consistently\ngenerate predicted distributions and attention maps. IA-ViT is composed of a\nfeature extractor, a predictor, and an interpreter, which are trained jointly\nwith an interpretability-aware training objective. Consequently, the\ninterpreter simulates the behavior of the predictor and provides a faithful\nexplanation through its single-head self-attention mechanism. Our comprehensive\nexperimental results demonstrate the effectiveness of IA-ViT in several image\nclassification tasks, with both qualitative and quantitative evaluations of\nmodel performance and interpretability. Source code is available from:\nhttps://github.com/qiangyao1988/IA-ViT."}
{"id": "2504.21413", "pdf": "https://arxiv.org/pdf/2504.21413", "abs": "https://arxiv.org/abs/2504.21413", "authors": ["H. Brendan McMahan", "Krishna Pillutla"], "title": "An Inversion Theorem for Buffered Linear Toeplitz (BLT) Matrices and Applications to Streaming Differential Privacy", "categories": ["cs.CR", "cs.LG", "eess.SP"], "comment": null, "summary": "Buffered Linear Toeplitz (BLT) matrices are a family of parameterized\nlower-triangular matrices that play an important role in streaming differential\nprivacy with correlated noise. Our main result is a BLT inversion theorem: the\ninverse of a BLT matrix is itself a BLT matrix with different parameters. We\nalso present an efficient and differentiable $O(d^3)$ algorithm to compute the\nparameters of the inverse BLT matrix, where $d$ is the degree of the original\nBLT (typically $d < 10$). Our characterization enables direct optimization of\nBLT parameters for privacy mechanisms through automatic differentiation."}
{"id": "2505.00649", "pdf": "https://arxiv.org/pdf/2505.00649", "abs": "https://arxiv.org/abs/2505.00649", "authors": ["Marco Braga", "Pranav Kasela", "Alessandro Raganato", "Gabriella Pasi"], "title": "Investigating Task Arithmetic for Zero-Shot Information Retrieval", "categories": ["cs.IR", "cs.CL", "cs.LG"], "comment": "Accepted in SIGIR '25", "summary": "Large Language Models (LLMs) have shown impressive zero-shot performance\nacross a variety of Natural Language Processing tasks, including document\nre-ranking. However, their effectiveness degrades on unseen tasks and domains,\nlargely due to shifts in vocabulary and word distributions. In this paper, we\ninvestigate Task Arithmetic, a technique that combines the weights of LLMs\npre-trained on different tasks or domains via simple mathematical operations,\nsuch as addition or subtraction, to adapt retrieval models without requiring\nadditional fine-tuning. Our method is able to synthesize diverse tasks and\ndomain knowledge into a single model, enabling effective zero-shot adaptation\nin different retrieval contexts. Extensive experiments on publicly available\nscientific, biomedical, and multilingual datasets show that our method improves\nstate-of-the-art re-ranking performance by up to 18% in NDCG@10 and 15% in\nP@10. In addition to these empirical gains, our analysis provides insights into\nthe strengths and limitations of Task Arithmetic as a practical strategy for\nzero-shot learning and model adaptation. We make our code publicly available at\nhttps://github.com/DetectiveMB/Task-Arithmetic-for-ZS-IR."}
{"id": "2503.23668", "pdf": "https://arxiv.org/pdf/2503.23668", "abs": "https://arxiv.org/abs/2503.23668", "authors": ["Jiaxin Wu", "Ting Zhang", "Rubing Chen", "Wengyu Zhang", "Chen Jason Zhang", "Xiao-Yong Wei", "Li Qing"], "title": "MolGround: A Benchmark for Molecular Grounding", "categories": ["cs.AI"], "comment": null, "summary": "Current molecular understanding approaches predominantly focus on the\ndescriptive aspect of human perception, providing broad, topic-level insights.\nHowever, the referential aspect -- linking molecular concepts to specific\nstructural components -- remains largely unexplored. To address this gap, we\npropose a molecular grounding benchmark designed to evaluate a model's\nreferential abilities. We align molecular grounding with established\nconventions in NLP, cheminformatics, and molecular science, showcasing the\npotential of NLP techniques to advance molecular understanding within the AI\nfor Science movement. Furthermore, we constructed the largest molecular\nunderstanding benchmark to date, comprising 117k QA pairs, and developed a\nmulti-agent grounding prototype as proof of concept. This system outperforms\nexisting models, including GPT-4o, and its grounding outputs have been\nintegrated to enhance traditional tasks such as molecular captioning and ATC\n(Anatomical, Therapeutic, Chemical) classification."}
{"id": "2311.08786", "pdf": "https://arxiv.org/pdf/2311.08786", "abs": "https://arxiv.org/abs/2311.08786", "authors": ["Mingrui Zhu", "Dongxin Chen", "Xin Wei", "Nannan Wang", "Xinbo Gao"], "title": "Disentangle Before Anonymize: A Two-stage Framework for Attribute-preserved and Occlusion-robust De-identification", "categories": ["cs.CV"], "comment": null, "summary": "In an era where personal photos are easily leaked and collected, face\nde-identification is a crucial method for protecting identity privacy. However,\ncurrent face de-identification techniques face challenges in preserving\nattribute details and often produce anonymized results with reduced\nauthenticity. These shortcomings are particularly evident when handling\nocclusions,frequently resulting in noticeable editing artifacts. Our primary\nfinding in this work is that simultaneous training of identity disentanglement\nand anonymization hinders their respective effectiveness.Therefore, we propose\n\"Disentangle Before Anonymize\",a novel two-stage Framework(DBAF)designed for\nattributepreserved and occlusion-robust de-identification. This framework\nincludes a Contrastive Identity Disentanglement (CID) module and a\nKey-authorized Reversible Identity Anonymization (KRIA) module, achieving\nfaithful attribute preservation and high-quality identity anonymization edits.\nAdditionally, we introduce a Multiscale Attentional Attribute Retention (MAAR)\nmodule to address the issue of reduced anonymization quality under\nocclusions.Extensive experiments demonstrate that our method outperforms\nstate-of-the-art de-identification approaches, delivering superior quality,\nenhanced detail fidelity, improved attribute preservation performance, and\ngreater robustness to occlusions."}
{"id": "2505.00037", "pdf": "https://arxiv.org/pdf/2505.00037", "abs": "https://arxiv.org/abs/2505.00037", "authors": ["Junggu Choi", "Chansu Yu", "Kyle L. Jung", "Suan-Sin Foo", "Weiqiang Chen", "Suzy AA Comhair", "Serpil C. Erzurum", "Lara Jehi", "Jae U. Jung"], "title": "Can a Quantum Support Vector Machine algorithm be utilized to identify Key Biomarkers from Multi-Omics data of COVID19 patients?", "categories": ["quant-ph", "cs.LG", "q-bio.QM"], "comment": "70 pages, 6 figures", "summary": "Identifying key biomarkers for COVID-19 from high-dimensional multi-omics\ndata is critical for advancing both diagnostic and pathogenesis research. In\nthis study, we evaluated the applicability of the Quantum Support Vector\nMachine (QSVM) algorithm for biomarker-based classification of COVID-19.\nProteomic and metabolomic biomarkers from two independent datasets were ranked\nby importance using ridge regression and grouped accordingly. The top- and\nbottom-ranked biomarker sets were then used to train and evaluate both\nclassical SVM (CSVM) and QSVM models, serving as predictive and negative\ncontrol inputs, respectively. The QSVM was implemented with multiple quantum\nkernels, including amplitude encoding, angle encoding, the ZZ feature map, and\nthe projected quantum kernel. Across various experimental settings, QSVM\nconsistently achieved classification performance that was comparable to or\nexceeded that of CSVM, while reflecting the importance rankings by ridge\nregression. Although the experiments were conducted in numerical simulation,\nour findings highlight the potential of QSVM as a promising approach for\nmulti-omics data analysis in biomedical research."}
{"id": "2309.08532", "pdf": "https://arxiv.org/pdf/2309.08532", "abs": "https://arxiv.org/abs/2309.08532", "authors": ["Qingyan Guo", "Rui Wang", "Junliang Guo", "Bei Li", "Kaitao Song", "Xu Tan", "Guoqing Liu", "Jiang Bian", "Yujiu Yang"], "title": "EvoPrompt: Connecting LLMs with Evolutionary Algorithms Yields Powerful Prompt Optimizers", "categories": ["cs.CL", "cs.AI"], "comment": "International Conference on Learning Representations (ICLR) 2024", "summary": "Large Language Models (LLMs) excel in various tasks, but they rely on\ncarefully crafted prompts that often demand substantial human effort. To\nautomate this process, in this paper, we propose a novel framework for discrete\nprompt optimization, called EvoPrompt, which borrows the idea of evolutionary\nalgorithms (EAs) as they exhibit good performance and fast convergence. To\nenable EAs to work on discrete prompts, which are natural language expressions\nthat need to be coherent and human-readable, we connect LLMs with EAs. This\napproach allows us to simultaneously leverage the powerful language processing\ncapabilities of LLMs and the efficient optimization performance of EAs.\nSpecifically, abstaining from any gradients or parameters, EvoPrompt starts\nfrom a population of prompts and iteratively generates new prompts with LLMs\nbased on the evolutionary operators, improving the population based on the\ndevelopment set. We optimize prompts for both closed- and open-source LLMs\nincluding GPT-3.5 and Alpaca, on 31 datasets covering language understanding,\ngeneration tasks, as well as BIG-Bench Hard (BBH) tasks. EvoPrompt\nsignificantly outperforms human-engineered prompts and existing methods for\nautomatic prompt generation (e.g., up to 25% on BBH). Furthermore, EvoPrompt\ndemonstrates that connecting LLMs with EAs creates synergies, which could\ninspire further research on the combination of LLMs and conventional\nalgorithms."}
{"id": "2504.19636", "pdf": "https://arxiv.org/pdf/2504.19636", "abs": "https://arxiv.org/abs/2504.19636", "authors": ["Fei Liu", "Qingfu Zhang", "Xialiang Tong", "Kun Mao", "Mingxuan Yuan"], "title": "Fitness Landscape of Large Language Model-Assisted Automated Algorithm Search", "categories": ["cs.AI", "cs.NE"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated significant potential in\nalgorithm design. However, when integrated into search frameworks for iterative\nalgorithm search, the underlying fitness landscape--critical for understanding\nsearch behaviou--remains underexplored. In this paper, we illustrate and\nanalyze the fitness landscape of LLM-assisted Algorithm Search (LAS) using a\ngraph-based approach, where nodes represent algorithms and edges denote\ntransitions between them. We conduct extensive evaluations across six algorithm\ndesign tasks and six commonly used LLMs. Our findings reveal that LAS\nlandscapes are highly multimodal and rugged, particularly in combinatorial\noptimization tasks, with distinct structural variations across tasks and LLMs.\nFor instance, heuristic design tasks exhibit dense clusters of high-performing\nalgorithms, while symbolic regression tasks show sparse, scattered\ndistributions. Additionally, we demonstrate how population size influences\nexploration-exploitation trade-offs and the evolving trajectory of elite\nalgorithms. These insights not only advance our understanding of LAS landscapes\nbut also provide practical guidance for designing more effective LAS methods."}
{"id": "2312.12028", "pdf": "https://arxiv.org/pdf/2312.12028", "abs": "https://arxiv.org/abs/2312.12028", "authors": ["Siamul Karim Khan", "Patrick Tinsley", "Mahsa Mitcheff", "Patrick Flynn", "Kevin W. Bowyer", "Adam Czajka"], "title": "EyePreserve: Identity-Preserving Iris Synthesis", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Synthesis of same-identity biometric iris images, both for existing and\nnon-existing identities while preserving the identity across a wide range of\npupil sizes, is complex due to the intricate iris muscle constriction\nmechanism, requiring a precise model of iris non-linear texture deformations to\nbe embedded into the synthesis pipeline. This paper presents the first method\nof fully data-driven, identity-preserving, pupil size-varying synthesis of iris\nimages. This approach is capable of synthesizing images of irises with\ndifferent pupil sizes representing non-existing identities, as well as\nnon-linearly deforming the texture of iris images of existing subjects given\nthe segmentation mask of the target iris image. Iris recognition experiments\nsuggest that the proposed deformation model both preserves the identity when\nchanging the pupil size, and offers better similarity between same-identity\niris samples with significant differences in pupil size, compared to\nstate-of-the-art linear and non-linear (bio-mechanical-based) iris deformation\nmodels. Two immediate applications of the proposed approach are: (a) synthesis\nof, or enhancement of the existing biometric datasets for iris recognition,\nmimicking those acquired with iris sensors, and (b) helping forensic human\nexperts examine iris image pairs with significant differences in pupil\ndilation. Images considered in this work conform to selected ISO/IEC 29794-6\nquality metrics to make them applicable in biometric systems. The source codes\nand model weights are offered with this paper."}
{"id": "2505.00110", "pdf": "https://arxiv.org/pdf/2505.00110", "abs": "https://arxiv.org/abs/2505.00110", "authors": ["Insung Kong", "Juntong Chen", "Sophie Langer", "Johannes Schmidt-Hieber"], "title": "On the expressivity of deep Heaviside networks", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA"], "comment": "61 pages, 16 figures", "summary": "We show that deep Heaviside networks (DHNs) have limited expressiveness but\nthat this can be overcome by including either skip connections or neurons with\nlinear activation. We provide lower and upper bounds for the\nVapnik-Chervonenkis (VC) dimensions and approximation rates of these network\nclasses. As an application, we derive statistical convergence rates for DHN\nfits in the nonparametric regression model."}
{"id": "2401.15371", "pdf": "https://arxiv.org/pdf/2401.15371", "abs": "https://arxiv.org/abs/2401.15371", "authors": ["Buqiang Xu", "Xin Dai", "Zhenghao Liu", "Huiyuan Xie", "Xiaoyuan Yi", "Shuo Wang", "Yukun Yan", "Liner Yang", "Yu Gu", "Ge Yu"], "title": "LegalDuet: Learning Fine-grained Representations for Legal Judgment Prediction via a Dual-View Contrastive Learning", "categories": ["cs.CL"], "comment": null, "summary": "Legal Judgment Prediction (LJP) is a fundamental task of legal artificial\nintelligence, aiming to automatically predict the judgment outcomes of legal\ncases. Existing LJP models primarily focus on identifying legal triggers within\ncriminal fact descriptions by contrastively training language models. However,\nthese LJP models overlook the importance of learning to effectively distinguish\nsubtle differences among judgments, which is crucial for producing more\naccurate predictions. In this paper, we propose LegalDuet, which continuously\npretrains language models to learn a more tailored embedding space for\nrepresenting legal cases. Specifically, LegalDuet designs a dual-view mechanism\nto continuously pretrain language models: 1) Law Case Clustering retrieves\nsimilar cases as hard negatives and employs contrastive training to\ndifferentiate among confusing cases; 2) Legal Decision Matching aims to\nidentify legal clues within criminal fact descriptions to align them with the\nchain of reasoning that contains the correct legal decision. Our experiments on\nthe CAIL2018 dataset demonstrate the effectiveness of LegalDuet. Further\nanalysis reveals that LegalDuet improves the ability of pretrained language\nmodels to distinguish confusing criminal charges by reducing prediction\nuncertainty and enhancing the separability of criminal charges. The experiments\ndemonstrate that LegalDuet produces a more concentrated and distinguishable\nembedding space, effectively aligning criminal facts with corresponding legal\ndecisions. The code is available at https://github.com/NEUIR/LegalDuet."}
{"id": "2504.20924", "pdf": "https://arxiv.org/pdf/2504.20924", "abs": "https://arxiv.org/abs/2504.20924", "authors": ["Beomjun Kim", "Kangyeon Kim", "Sunwoo Kim", "Heejin Ahn"], "title": "A Domain-Agnostic Scalable AI Safety Ensuring Framework", "categories": ["cs.AI"], "comment": "Theoretical supplementary material (Part 1) is available in submitted\n  files. Experimental supplementary material (Part 2) will be available before\n  May 22 23:59PM AOE", "summary": "Ensuring the safety of AI systems has recently emerged as a critical priority\nfor real-world deployment, particularly in physical AI applications. Current\napproaches to AI safety typically address predefined domain-specific safety\nconditions, limiting their ability to generalize across contexts. We propose a\nnovel AI safety framework that ensures AI systems comply with any user-defined\nconstraint, with any desired probability, and across various domains. In this\nframework, we combine an AI component (e.g., neural network) with an\noptimization problem to produce responses that minimize objectives while\nsatisfying user-defined constraints with probabilities exceeding user-defined\nthresholds. For credibility assessment of the AI component, we propose internal\ntest data, a supplementary set of safety-labeled data, and a conservative\ntesting methodology that provides statistical validity of using internal test\ndata. We also present an approximation method of a loss function and how to\ncompute its gradient for training. We mathematically prove that probabilistic\nconstraint satisfaction is guaranteed under specific, mild conditions and prove\na scaling law between safety and the number of internal test data. We\ndemonstrate our framework's effectiveness through experiments in diverse\ndomains: demand prediction for production decision, safe reinforcement learning\nwithin the SafetyGym simulator, and guarding AI chatbot outputs. Through these\nexperiments, we demonstrate that our method guarantees safety for\nuser-specified constraints, outperforms for up to several order of magnitudes\nexisting methods in low safety threshold regions, and scales effectively with\nrespect to the size of internal test data."}
{"id": "2312.12419", "pdf": "https://arxiv.org/pdf/2312.12419", "abs": "https://arxiv.org/abs/2312.12419", "authors": ["Jinghao Zhou", "Tomas Jakab", "Philip Torr", "Christian Rupprecht"], "title": "Scene-Conditional 3D Object Stylization and Composition", "categories": ["cs.CV"], "comment": null, "summary": "Recently, 3D generative models have made impressive progress, enabling the\ngeneration of almost arbitrary 3D assets from text or image inputs. However,\nthese approaches generate objects in isolation without any consideration for\nthe scene where they will eventually be placed. In this paper, we propose a\nframework that allows for the stylization of an existing 3D asset to fit into a\ngiven 2D scene, and additionally produce a photorealistic composition as if the\nasset was placed within the environment. This not only opens up a new level of\ncontrol for object stylization, for example, the same assets can be stylized to\nreflect changes in the environment, such as summer to winter or fantasy versus\nfuturistic settings-but also makes the object-scene composition more\ncontrollable. We achieve this by combining modeling and optimizing the object's\ntexture and environmental lighting through differentiable ray tracing with\nimage priors from pre-trained text-to-image diffusion models. We demonstrate\nthat our method is applicable to a wide variety of indoor and outdoor scenes\nand arbitrary objects. Project page:\nhttps://jensenzhoujh.github.io/scene-cond-3d/."}
{"id": "2505.00137", "pdf": "https://arxiv.org/pdf/2505.00137", "abs": "https://arxiv.org/abs/2505.00137", "authors": ["Rushikesh Ubale", "Sujan K. K.", "Sangram Deshpande", "Gregory T. Byrd"], "title": "Toward Practical Quantum Machine Learning: A Novel Hybrid Quantum LSTM for Fraud Detection", "categories": ["quant-ph", "cs.IT", "cs.LG", "math.IT"], "comment": "11 pages ,8 figures", "summary": "We present a novel hybrid quantum-classical neural network architecture for\nfraud detection that integrates a classical Long Short-Term Memory (LSTM)\nnetwork with a variational quantum circuit. By leveraging quantum phenomena\nsuch as superposition and entanglement, our model enhances the feature\nrepresentation of sequential transaction data, capturing complex non-linear\npatterns that are challenging for purely classical models. A comprehensive data\npreprocessing pipeline is employed to clean, encode, balance, and normalize a\ncredit card fraud dataset, ensuring a fair comparison with baseline models.\nNotably, our hybrid approach achieves per-epoch training times in the range of\n45-65 seconds, which is significantly faster than similar architectures\nreported in the literature, where training typically requires several minutes\nper epoch. Both classical and quantum gradients are jointly optimized via a\nunified backpropagation procedure employing the parameter-shift rule for the\nquantum parameters. Experimental evaluations demonstrate competitive\nimprovements in accuracy, precision, recall, and F1 score relative to a\nconventional LSTM baseline. These results underscore the promise of hybrid\nquantum-classical techniques in advancing the efficiency and performance of\nfraud detection systems.\n  Keywords: Hybrid Quantum-Classical Neural Networks, Quantum Computing, Fraud\nDetection, Hybrid Quantum LSTM, Variational Quantum Circuit, Parameter-Shift\nRule, Financial Risk Analysis"}
{"id": "2402.08498", "pdf": "https://arxiv.org/pdf/2402.08498", "abs": "https://arxiv.org/abs/2402.08498", "authors": ["Preetika Verma", "Kokil Jaidka", "Svetlana Churina"], "title": "\"Reasoning\" with Rhetoric: On the Style-Evidence Tradeoff in LLM-Generated Counter-Arguments", "categories": ["cs.CL"], "comment": "22 pages, 9 figures, 13 tables", "summary": "Large language models (LLMs) play a key role in generating evidence-based and\nstylistic counter-arguments, yet their effectiveness in real-world applications\nhas been underexplored. Previous research often neglects the balance between\nevidentiality and style, which are crucial for persuasive arguments. To address\nthis, we evaluated the effectiveness of stylized evidence-based\ncounter-argument generation in Counterfire, a new dataset of 38,000\ncounter-arguments generated by revising counter-arguments to Reddit's\nChangeMyView community to follow different discursive styles. We evaluated\ngeneric and stylized counter-arguments from basic and fine-tuned models such as\nGPT-3.5, PaLM-2, and Koala-13B, as well as newer models (GPT-4o, Claude Haiku,\nLLaMA-3.1) focusing on rhetorical quality and persuasiveness. Our findings\nreveal that humans prefer stylized counter-arguments over the original outputs,\nwith GPT-3.5 Turbo performing well, though still not reaching human standards\nof rhetorical quality nor persuasiveness. Additionally, our work created a\nnovel argument triplets dataset for studying style control, with human\npreference labels that provide insights into the tradeoffs between evidence\nintegration and argument quality."}
{"id": "2206.09535", "pdf": "https://arxiv.org/pdf/2206.09535", "abs": "https://arxiv.org/abs/2206.09535", "authors": ["Akira Matsui", "Emilio Ferrara"], "title": "Characterizing Human Actions in the Digital Platform by Temporal Context", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Recent advances in digital platforms generate rich, high-dimensional logs of\nhuman behavior, and machine learning models have helped social scientists\nexplain knowledge accumulation, communication, and information diffusion. Such\nmodels, however, almost always treat behavior as sequences of actions,\nabstracting the inter-temporal information among actions. To close this gap, we\nintroduce a two-scale Action-Timing Context(ATC) framework that jointly embeds\neach action and its time interval. ATC obtains low-dimensional representations\nof actions and characterizes them with inter-temporal information. We provide\nthree applications of ATC to real-world datasets and demonstrate that the\nmethod offers a unified view of human behavior. The presented qualitative\nfindings demonstrate that explicitly modeling inter-temporal context is\nessential for a comprehensive, interpretable understanding of human activity on\ndigital platforms."}
{"id": "2401.03048", "pdf": "https://arxiv.org/pdf/2401.03048", "abs": "https://arxiv.org/abs/2401.03048", "authors": ["Xin Ma", "Yaohui Wang", "Xinyuan Chen", "Gengyun Jia", "Ziwei Liu", "Yuan-Fang Li", "Cunjian Chen", "Yu Qiao"], "title": "Latte: Latent Diffusion Transformer for Video Generation", "categories": ["cs.CV"], "comment": "Accepted by Transactions on Machine Learning Research 2025; Project\n  Page: https://maxin-cn.github.io/latte_project", "summary": "We propose Latte, a novel Latent Diffusion Transformer for video generation.\nLatte first extracts spatio-temporal tokens from input videos and then adopts a\nseries of Transformer blocks to model video distribution in the latent space.\nIn order to model a substantial number of tokens extracted from videos, four\nefficient variants are introduced from the perspective of decomposing the\nspatial and temporal dimensions of input videos. To improve the quality of\ngenerated videos, we determine the best practices of Latte through rigorous\nexperimental analysis, including video clip patch embedding, model variants,\ntimestep-class information injection, temporal positional embedding, and\nlearning strategies. Our comprehensive evaluation demonstrates that Latte\nachieves state-of-the-art performance across four standard video generation\ndatasets, i.e., FaceForensics, SkyTimelapse, UCF101, and Taichi-HD. In\naddition, we extend Latte to the text-to-video generation (T2V) task, where\nLatte achieves results that are competitive with recent T2V models. We strongly\nbelieve that Latte provides valuable insights for future research on\nincorporating Transformers into diffusion models for video generation."}
{"id": "2505.00195", "pdf": "https://arxiv.org/pdf/2505.00195", "abs": "https://arxiv.org/abs/2505.00195", "authors": ["Aditya Karan", "Nicholas Vincent", "Karrie Karahalios", "Hari Sundaram"], "title": "Algorithmic Collective Action with Two Collectives", "categories": ["cs.CY", "cs.GT", "cs.LG"], "comment": null, "summary": "Given that data-dependent algorithmic systems have become impactful in more\ndomains of life, the need for individuals to promote their own interests and\nhold algorithms accountable has grown. To have meaningful influence,\nindividuals must band together to engage in collective action. Groups that\nengage in such algorithmic collective action are likely to vary in size,\nmembership characteristics, and crucially, objectives. In this work, we\nintroduce a first of a kind framework for studying collective action with two\nor more collectives that strategically behave to manipulate data-driven\nsystems. With more than one collective acting on a system, unexpected\ninteractions may occur. We use this framework to conduct experiments with\nlanguage model-based classifiers and recommender systems where two collectives\neach attempt to achieve their own individual objectives. We examine how\ndiffering objectives, strategies, sizes, and homogeneity can impact a\ncollective's efficacy. We find that the unintentional interactions between\ncollectives can be quite significant; a collective acting in isolation may be\nable to achieve their objective (e.g., improve classification outcomes for\nthemselves or promote a particular item), but when a second collective acts\nsimultaneously, the efficacy of the first group drops by as much as $75\\%$. We\nfind that, in the recommender system context, neither fully heterogeneous nor\nfully homogeneous collectives stand out as most efficacious and that\nheterogeneity's impact is secondary compared to collective size. Our results\nsignal the need for more transparency in both the underlying algorithmic models\nand the different behaviors individuals or collectives may take on these\nsystems. This approach also allows collectives to hold algorithmic system\ndevelopers accountable and provides a framework for people to actively use\ntheir own data to promote their own interests."}
{"id": "2405.04532", "pdf": "https://arxiv.org/pdf/2405.04532", "abs": "https://arxiv.org/abs/2405.04532", "authors": ["Yujun Lin", "Haotian Tang", "Shang Yang", "Zhekai Zhang", "Guangxuan Xiao", "Chuang Gan", "Song Han"], "title": "QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.PF"], "comment": "The first three authors contribute equally to this project and are\n  listed in the alphabetical order. Yujun Lin leads the quantization algorithm,\n  Haotian Tang and Shang Yang lead the GPU kernels and the serving system. Code\n  is available at https://github.com/mit-han-lab/omniserve", "summary": "Quantization can accelerate large language model (LLM) inference. Going\nbeyond INT8 quantization, the research community is actively exploring even\nlower precision, such as INT4. Nonetheless, state-of-the-art INT4 quantization\ntechniques only accelerate low-batch, edge LLM inference, failing to deliver\nperformance gains in large-batch, cloud-based LLM serving. We uncover a\ncritical issue: existing INT4 quantization methods suffer from significant\nruntime overhead (20-90%) when dequantizing either weights or partial sums on\nGPUs. To address this challenge, we introduce QoQ, a W4A8KV4 quantization\nalgorithm with 4-bit weight, 8-bit activation, and 4-bit KV cache. QoQ stands\nfor quattuor-octo-quattuor, which represents 4-8-4 in Latin. QoQ is implemented\nby the QServe inference library that achieves measured speedup. The key insight\ndriving QServe is that the efficiency of LLM serving on GPUs is critically\ninfluenced by operations on low-throughput CUDA cores. Building upon this\ninsight, in QoQ algorithm, we introduce progressive quantization that can allow\nlow dequantization overhead in W4A8 GEMM. Additionally, we develop\nSmoothAttention to effectively mitigate the accuracy degradation incurred by\n4-bit KV quantization. In the QServe system, we perform compute-aware weight\nreordering and take advantage of register-level parallelism to reduce\ndequantization latency. We also make fused attention memory-bound, harnessing\nthe performance gain brought by KV4 quantization. As a result, QServe improves\nthe maximum achievable serving throughput of Llama-3-8B by 1.2x on A100, 1.4x\non L40S; and Qwen1.5-72B by 2.4x on A100, 3.5x on L40S, compared to\nTensorRT-LLM. Remarkably, QServe on L40S GPU can achieve even higher throughput\nthan TensorRT-LLM on A100. Thus, QServe effectively reduces the dollar cost of\nLLM serving by 3x. Code is available at\nhttps://github.com/mit-han-lab/omniserve."}
{"id": "2303.15201", "pdf": "https://arxiv.org/pdf/2303.15201", "abs": "https://arxiv.org/abs/2303.15201", "authors": ["Ran Wei", "Anthony D. McDonald", "Alfredo Garcia", "Gustav Markkula", "Johan Engstrom", "Matthew O'Kelly"], "title": "Learning An Active Inference Model of Driver Perception and Control: Application to Vehicle Car-Following", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "In this paper we introduce a general estimation methodology for learning a\nmodel of human perception and control in a sensorimotor control task based upon\na finite set of demonstrations. The model's structure consists of i the agent's\ninternal representation of how the environment and associated observations\nevolve as a result of control actions and ii the agent's preferences over\nobservable outcomes. We consider a model's structure specification consistent\nwith active inference, a theory of human perception and behavior from cognitive\nscience. According to active inference, the agent acts upon the world so as to\nminimize surprise defined as a measure of the extent to which an agent's\ncurrent sensory observations differ from its preferred sensory observations. We\npropose a bi-level optimization approach to estimation which relies on a\nstructural assumption on prior distributions that parameterize the statistical\naccuracy of the human agent's model of the environment. To illustrate the\nproposed methodology, we present the estimation of a model for car-following\nbehavior based upon a naturalistic dataset. Overall, the results indicate that\nlearning active inference models of human perception and control from data is a\npromising alternative to black-box models of driving."}
{"id": "2405.00507", "pdf": "https://arxiv.org/pdf/2405.00507", "abs": "https://arxiv.org/abs/2405.00507", "authors": ["Zhinan Yu", "Zheng Qin", "Yijie Tang", "Yongjun Wang", "Renjiao Yi", "Chenyang Zhu", "Kai Xu"], "title": "F2M-Reg: Unsupervised RGB-D Point Cloud Registration with Frame-to-Model Optimization", "categories": ["cs.CV"], "comment": null, "summary": "This work studies the problem of unsupervised RGB-D point cloud registration,\nwhich aims at training a robust registration model without ground-truth pose\nsupervision. Existing methods usually leverages unposed RGB-D sequences and\nadopt a frame-to-frame framework based on differentiable rendering to train the\nregistration model, which enforces the photometric and geometric consistency\nbetween the two frames for supervision. However, this frame-to-frame framework\nis vulnerable to inconsistent factors between different frames, e.g., lighting\nchanges, geometry occlusion, and reflective materials, which leads to\nsuboptimal convergence of the registration model. In this paper, we propose a\nnovel frame-to-model optimization framework named F2M-Reg for unsupervised\nRGB-D point cloud registration. We leverage the neural implicit field as a\nglobal model of the scene and optimize the estimated poses of the frames by\nregistering them to the global model, and the registration model is\nsubsequently trained with the optimized poses. Thanks to the global encoding\ncapability of neural implicit field, our frame-to-model framework is\nsignificantly more robust to inconsistent factors between different frames and\nthus can provide better supervision for the registration model. Besides, we\ndemonstrate that F2M-Reg can be further enhanced by a simplistic synthetic\nwarming-up strategy. To this end, we construct a photorealistic synthetic\ndataset named Sim-RGBD to initialize the registration model for the\nframe-to-model optimization on real-world RGB-D sequences. Extensive\nexperiments on four challenging benchmarks have shown that our method surpasses\nthe previous state-of-the-art counterparts by a large margin, especially under\nscenarios with severe lighting changes and low overlap. Our code and models are\navailable at https://github.com/MrIsland/F2M_Reg."}
{"id": "2505.00229", "pdf": "https://arxiv.org/pdf/2505.00229", "abs": "https://arxiv.org/abs/2505.00229", "authors": ["Mark Adams", "Kamillo Ferry", "Ruriko Yoshida"], "title": "Inference for max-linear Bayesian networks with noise", "categories": ["stat.ML", "cs.LG", "math.OC", "math.ST", "stat.TH", "14T90, 62A09, 62H30, 90C20, 90C90"], "comment": "18 pages, 10 figures. Short version to appear in the proceedings of\n  the 13th Workshop on Uncertainty Processing", "summary": "Max-Linear Bayesian Networks (MLBNs) provide a powerful framework for causal\ninference in extreme-value settings; we consider MLBNs with noise parameters\nwith a given topology in terms of the max-plus algebra by taking its logarithm.\nThen, we show that an estimator of a parameter for each edge in a directed\nacyclic graph (DAG) is distributed normally. We end this paper with\ncomputational experiments with the expectation and maximization (EM) algorithm\nand quadratic optimization."}
{"id": "2405.11804", "pdf": "https://arxiv.org/pdf/2405.11804", "abs": "https://arxiv.org/abs/2405.11804", "authors": ["Minghao Wu", "Jiahao Xu", "Yulin Yuan", "Gholamreza Haffari", "Longyue Wang", "Weihua Luo", "Kaifu Zhang"], "title": "(Perhaps) Beyond Human Translation: Harnessing Multi-Agent Collaboration for Translating Ultra-Long Literary Texts", "categories": ["cs.CL"], "comment": "To appear at TACL", "summary": "Literary translation remains one of the most challenging frontiers in machine\ntranslation due to the complexity of capturing figurative language, cultural\nnuances, and unique stylistic elements. In this work, we introduce TransAgents,\na novel multi-agent framework that simulates the roles and collaborative\npractices of a human translation company, including a CEO, Senior Editor,\nJunior Editor, Translator, Localization Specialist, and Proofreader. The\ntranslation process is divided into two stages: a preparation stage where the\nteam is assembled and comprehensive translation guidelines are drafted, and an\nexecution stage that involves sequential translation, localization,\nproofreading, and a final quality check. Furthermore, we propose two innovative\nevaluation strategies: Monolingual Human Preference (MHP), which evaluates\ntranslations based solely on target language quality and cultural\nappropriateness, and Bilingual LLM Preference (BLP), which leverages large\nlanguage models like GPT-4} for direct text comparison. Although TransAgents\nachieves lower d-BLEU scores, due to the limited diversity of references, its\ntranslations are significantly better than those of other baselines and are\npreferred by both human evaluators and LLMs over traditional human references\nand GPT-4} translations. Our findings highlight the potential of multi-agent\ncollaboration in enhancing translation quality, particularly for longer texts."}
{"id": "2311.06840", "pdf": "https://arxiv.org/pdf/2311.06840", "abs": "https://arxiv.org/abs/2311.06840", "authors": ["Bijan Mazaheri", "Siddharth Jain", "Matthew Cook", "Jehoshua Bruck"], "title": "Omitted Labels Induce Nontransitive Paradoxes in Causality", "categories": ["cs.LG", "cs.AI", "cs.IT", "cs.SI", "math.IT", "stat.ME"], "comment": "Accepted to appear in CLeaR 2025", "summary": "We explore \"omitted label contexts,\" in which training data is limited to a\nsubset of the possible labels. This setting is standard among specialized human\nexperts or specific, focused studies. By studying Simpson's paradox, we observe\nthat ``correct'' adjustments sometimes require non-exchangeable treatment and\ncontrol groups. A generalization of Simpson's paradox leads us to study\nnetworks of conclusions drawn from different contexts, within which a paradox\nof nontransitivity arises. We prove that the space of possible nontransitive\nstructures in these networks exactly corresponds to structures that form from\naggregating ranked-choice votes."}
{"id": "2405.04489", "pdf": "https://arxiv.org/pdf/2405.04489", "abs": "https://arxiv.org/abs/2405.04489", "authors": ["Minh Tran", "Adrian De Luis", "Haitao Liao", "Ying Huang", "Roy McCann", "Alan Mantooth", "Jack Cothren", "Ngan Le"], "title": "S3Former: Self-supervised High-resolution Transformer for Solar PV Profiling", "categories": ["cs.CV"], "comment": "IEEE Transactions on Smart Grid", "summary": "As the impact of climate change escalates, the global necessity to transition\nto sustainable energy sources becomes increasingly evident. Renewable energies\nhave emerged as a viable solution for users, with Photovoltaic energy being a\nfavored choice for small installations due to its reliability and efficiency.\nAccurate mapping of PV installations is crucial for understanding the extension\nof its adoption and informing energy policy. To meet this need, we introduce\nS3Former, designed to segment solar panels from aerial imagery and provide size\nand location information critical for analyzing the impact of such\ninstallations on the grid. Solar panel identification is challenging due to\nfactors such as varying weather conditions, roof characteristics, Ground\nSampling Distance variations and lack of appropriate initialization weights for\noptimized training. To tackle these complexities, S3Former features a Masked\nAttention Mask Transformer incorporating a self-supervised learning pretrained\nbackbone. Specifically, our model leverages low-level and high-level features\nextracted from the backbone and incorporates an instance query mechanism\nincorporated on the Transformer architecture to enhance the localization of\nsolar PV installations. We introduce a self-supervised learning phase (pretext\ntask) to improve the initialization weights on the backbone of S3Former. We\nevaluated S3Former using diverse datasets, demonstrate improvement\nstate-of-the-art models."}
{"id": "2505.00233", "pdf": "https://arxiv.org/pdf/2505.00233", "abs": "https://arxiv.org/abs/2505.00233", "authors": ["Kimihiro Yamazaki", "Takuya Konishi", "Yoshinobu Kawahara"], "title": "Explorative Curriculum Learning for Strongly Correlated Electron Systems", "categories": ["cond-mat.str-el", "cs.LG"], "comment": null, "summary": "Recent advances in neural network quantum states (NQS) have enabled\nhigh-accuracy predictions for complex quantum many-body systems such as\nstrongly correlated electron systems. However, the computational cost remains\nprohibitive, making exploration of the diverse parameters of interaction\nstrengths and other physical parameters inefficient. While transfer learning\nhas been proposed to mitigate this challenge, achieving generalization to\nlarge-scale systems and diverse parameter regimes remains difficult. To address\nthis limitation, we propose a novel curriculum learning framework based on\ntransfer learning for NQS. This facilitates efficient and stable exploration\nacross a vast parameter space of quantum many-body systems. In addition, by\ninterpreting NQS transfer learning through a perturbative lens, we demonstrate\nhow prior physical knowledge can be flexibly incorporated into the curriculum\nlearning process. We also propose Pairing-Net, an architecture to practically\nimplement this strategy for strongly correlated electron systems, and\nempirically verify its effectiveness. Our results show an approximately\n200-fold speedup in computation and a marked improvement in optimization\nstability compared to conventional methods."}
{"id": "2407.20906", "pdf": "https://arxiv.org/pdf/2407.20906", "abs": "https://arxiv.org/abs/2407.20906", "authors": ["Shican Wu", "Xiao Ma", "Dehui Luo", "Lulu Li", "Xiangcheng Shi", "Xin Chang", "Xiaoyun Lin", "Ran Luo", "Chunlei Pei", "Changying Du", "Zhi-Jian Zhao", "Jinlong Gong"], "title": "Automated Review Generation Method Based on Large Language Models", "categories": ["cs.CL", "cs.AI", "physics.data-an"], "comment": "Code: https://github.com/TJU-ECAT-AI/AutomaticReviewGeneration Data:\n  https://github.com/TJU-ECAT-AI/AutomaticReviewGenerationData This research\n  has been invited for a Short Oral presentation at the 18th ICC -\n  International Congress on Catalysis, taking place in Lyon, France from July\n  14-19, 2024 Published at https://doi.org/10.1093/nsr/nwaf169 for newer\n  edition", "summary": "Literature research, vital for scientific work, faces the challenge of\nsurging information volumes exceeding researchers' processing capabilities. We\npresent an automated review generation method based on large language models\n(LLMs) to overcome efficiency bottlenecks and reduce cognitive load. Our\nstatistically validated evaluation framework demonstrates that the generated\nreviews match or exceed manual quality, offering broad applicability across\nresearch fields without requiring users' domain knowledge. Applied to propane\ndehydrogenation (PDH) catalysts, our method swiftly analyzed 343 articles,\naveraging seconds per article per LLM account, producing comprehensive reviews\nspanning 35 topics, with extended analysis of 1041 articles providing insights\ninto catalysts' properties. Through multi-layered quality control, we\neffectively mitigated LLMs' hallucinations, with expert verification confirming\naccuracy and citation integrity while demonstrating hallucination risks reduced\nto below 0.5\\% with 95\\% confidence. Released Windows application enables\none-click review generation, enhancing research productivity and literature\nrecommendation efficiency while setting the stage for broader scientific\nexplorations."}
{"id": "2402.07033", "pdf": "https://arxiv.org/pdf/2402.07033", "abs": "https://arxiv.org/abs/2402.07033", "authors": ["Keisuke Kamahori", "Tian Tang", "Yile Gu", "Kan Zhu", "Baris Kasikci"], "title": "Fiddler: CPU-GPU Orchestration for Fast Inference of Mixture-of-Experts Models", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.OS"], "comment": "ICLR2025", "summary": "Large Language Models (LLMs) with the Mixture-of-Experts (MoE) architectures\nhave shown promising performance on various tasks. However, due to the huge\nmodel sizes, running them in resource-constrained environments where the GPU\nmemory is not abundant is challenging. Some existing systems propose to use CPU\nresources to solve that, but they either suffer from the significant overhead\nof frequently moving data between CPU and GPU, or fail to consider distinct\ncharacteristics of CPUs and GPUs. This paper proposes Fiddler, a\nresource-efficient inference system for MoE models with limited GPU resources.\nFiddler strategically utilizes CPU and GPU resources by determining the optimal\nexecution strategy. Our evaluation shows that, unlike state-of-the-art systems\nthat optimize for specific scenarios such as single batch inference or long\nprefill, Fiddler performs better in all scenarios. Compared against different\nbaselines, Fiddler achieves 1.26 times speed up in single batch inference, 1.30\ntimes in long prefill processing, and 11.57 times in beam search inference. The\ncode of Fiddler is publicly available at https://github.com/efeslab/fiddler."}
{"id": "2405.11536", "pdf": "https://arxiv.org/pdf/2405.11536", "abs": "https://arxiv.org/abs/2405.11536", "authors": ["Mohamed Nagy", "Naoufel Werghi", "Bilal Hassan", "Jorge Dias", "Majid Khonji"], "title": "RobMOT: Robust 3D Multi-Object Tracking by Observational Noise and State Estimation Drift Mitigation on LiDAR PointCloud", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "This paper addresses limitations in 3D tracking-by-detection methods,\nparticularly in identifying legitimate trajectories and reducing state\nestimation drift in Kalman filters. Existing methods often use threshold-based\nfiltering for detection scores, which can fail for distant and occluded\nobjects, leading to false positives. To tackle this, we propose a novel track\nvalidity mechanism and multi-stage observational gating process, significantly\nreducing ghost tracks and enhancing tracking performance. Our method achieves a\n$29.47\\%$ improvement in Multi-Object Tracking Accuracy (MOTA) on the KITTI\nvalidation dataset with the Second detector. Additionally, a refined Kalman\nfilter term reduces localization noise, improving higher-order tracking\naccuracy (HOTA) by $4.8\\%$. The online framework, RobMOT, outperforms\nstate-of-the-art methods across multiple detectors, with HOTA improvements of\nup to $3.92\\%$ on the KITTI testing dataset and $8.7\\%$ on the validation\ndataset, while achieving low identity switch scores. RobMOT excels in\nchallenging scenarios, tracking distant objects and prolonged occlusions, with\na $1.77\\%$ MOTA improvement on the Waymo Open dataset, and operates at a\nremarkable 3221 FPS on a single CPU, proving its efficiency for real-time\nmulti-object tracking."}
{"id": "2505.00237", "pdf": "https://arxiv.org/pdf/2505.00237", "abs": "https://arxiv.org/abs/2505.00237", "authors": ["Ze Zhang", "Georg Hess", "Junjie Hu", "Emmanuel Dean", "Lennart Svensson", "Knut Åkesson"], "title": "Future-Oriented Navigation: Dynamic Obstacle Avoidance with One-Shot Energy-Based Multimodal Motion Prediction", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": "Submitted to IEEE RA-L", "summary": "This paper proposes an integrated approach for the safe and efficient control\nof mobile robots in dynamic and uncertain environments. The approach consists\nof two key steps: one-shot multimodal motion prediction to anticipate motions\nof dynamic obstacles and model predictive control to incorporate these\npredictions into the motion planning process. Motion prediction is driven by an\nenergy-based neural network that generates high-resolution, multi-step\npredictions in a single operation. The prediction outcomes are further utilized\nto create geometric shapes formulated as mathematical constraints. Instead of\ntreating each dynamic obstacle individually, predicted obstacles are grouped by\nproximity in an unsupervised way to improve performance and efficiency. The\noverall collision-free navigation is handled by model predictive control with a\nspecific design for proactive dynamic obstacle avoidance. The proposed approach\nallows mobile robots to navigate effectively in dynamic environments. Its\nperformance is accessed across various scenarios that represent typical\nwarehouse settings. The results demonstrate that the proposed approach\noutperforms other existing dynamic obstacle avoidance methods."}
{"id": "2410.01957", "pdf": "https://arxiv.org/pdf/2410.01957", "abs": "https://arxiv.org/abs/2410.01957", "authors": ["Min-Hsuan Yeh", "Jeffrey Wang", "Xuefeng Du", "Seongheon Park", "Leitian Tao", "Shawn Im", "Yixuan Li"], "title": "Challenges and Future Directions of Data-Centric AI Alignment", "categories": ["cs.CL"], "comment": "ICML 2025", "summary": "As AI systems become increasingly capable and influential, ensuring their\nalignment with human values, preferences, and goals has become a critical\nresearch focus. Current alignment methods primarily focus on designing\nalgorithms and loss functions but often underestimate the crucial role of data.\nThis paper advocates for a shift towards data-centric AI alignment, emphasizing\nthe need to enhance the quality and representativeness of data used in aligning\nAI systems. In this position paper, we highlight key challenges associated with\nboth human-based and AI-based feedback within the data-centric alignment\nframework. Through qualitative analysis, we identify multiple sources of\nunreliability in human feedback, as well as problems related to temporal drift,\ncontext dependence, and AI-based feedback failing to capture human values due\nto inherent model limitations. We propose future research directions, including\nimproved feedback collection practices, robust data-cleaning methodologies, and\nrigorous feedback verification processes. We call for future research into\nthese critical directions to ensure, addressing gaps that persist in\nunderstanding and improving data-centric alignment practices."}
{"id": "2403.00108", "pdf": "https://arxiv.org/pdf/2403.00108", "abs": "https://arxiv.org/abs/2403.00108", "authors": ["Hongyi Liu", "Shaochen Zhong", "Xintong Sun", "Minghao Tian", "Mohsen Hariri", "Zirui Liu", "Ruixiang Tang", "Zhimeng Jiang", "Jiayi Yuan", "Yu-Neng Chuang", "Li Li", "Soo-Hyun Choi", "Rui Chen", "Vipin Chaudhary", "Xia Hu"], "title": "LoRATK: LoRA Once, Backdoor Everywhere in the Share-and-Play Ecosystem", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "Finetuning LLMs with LoRA has gained significant popularity due to its\nsimplicity and effectiveness. Often, users may even find pluggable,\ncommunity-shared LoRAs to enhance their base models for a specific downstream\ntask of interest; enjoying a powerful, efficient, yet customized LLM experience\nwith negligible investment. However, this convenient share-and-play ecosystem\nalso introduces a new attack surface, where attackers can distribute malicious\nLoRAs to a community eager to try out shared assets. Despite the high-risk\npotential, no prior art has comprehensively explored LoRA's attack surface\nunder the downstream-enhancing share-and-play context. In this paper, we\ninvestigate how backdoors can be injected into task-enhancing LoRAs and examine\nthe mechanisms of such infections. We find that with a simple, efficient, yet\nspecific recipe, a backdoor LoRA can be trained once and then seamlessly merged\n(in a training-free fashion) with multiple task-enhancing LoRAs, retaining both\nits malicious backdoor and benign downstream capabilities. This allows\nattackers to scale the distribution of compromised LoRAs with minimal effort by\nleveraging the rich pool of existing shared LoRA assets. We note that such\nmerged LoRAs are particularly infectious -- because their malicious intent is\ncleverly concealed behind improved downstream capabilities, creating a strong\nincentive for voluntary download -- and dangerous -- because under local\ndeployment, no safety measures exist to intervene when things go wrong. Our\nwork is among the first to study this new threat model of training-free\ndistribution of downstream-capable-yet-backdoor-injected LoRAs, highlighting\nthe urgent need for heightened security awareness in the LoRA ecosystem.\nWarning: This paper contains offensive content and involves a real-life\ntragedy."}
{"id": "2405.18416", "pdf": "https://arxiv.org/pdf/2405.18416", "abs": "https://arxiv.org/abs/2405.18416", "authors": ["Jingwei Xu", "Yikai Wang", "Yiqun Zhao", "Yanwei Fu", "Shenghua Gao"], "title": "3D StreetUnveiler with Semantic-aware 2DGS -- a simple baseline", "categories": ["cs.CV"], "comment": "Project page: https://streetunveiler.github.io", "summary": "Unveiling an empty street from crowded observations captured by in-car\ncameras is crucial for autonomous driving. However, removing all temporarily\nstatic objects, such as stopped vehicles and standing pedestrians, presents a\nsignificant challenge. Unlike object-centric 3D inpainting, which relies on\nthorough observation in a small scene, street scene cases involve long\ntrajectories that differ from previous 3D inpainting tasks. The camera-centric\nmoving environment of captured videos further complicates the task due to the\nlimited degree and time duration of object observation. To address these\nobstacles, we introduce StreetUnveiler to reconstruct an empty street.\nStreetUnveiler learns a 3D representation of the empty street from crowded\nobservations. Our representation is based on the hard-label semantic 2D\nGaussian Splatting (2DGS) for its scalability and ability to identify Gaussians\nto be removed. We inpaint rendered image after removing unwanted Gaussians to\nprovide pseudo-labels and subsequently re-optimize the 2DGS. Given its temporal\ncontinuous movement, we divide the empty street scene into observed,\npartial-observed, and unobserved regions, which we propose to locate through a\nrendered alpha map. This decomposition helps us to minimize the regions that\nneed to be inpainted. To enhance the temporal consistency of the inpainting, we\nintroduce a novel time-reversal framework to inpaint frames in reverse order\nand use later frames as references for earlier frames to fully utilize the\nlong-trajectory observations. Our experiments conducted on the street scene\ndataset successfully reconstructed a 3D representation of the empty street. The\nmesh representation of the empty street can be extracted for further\napplications. The project page and more visualizations can be found at:\nhttps://streetunveiler.github.io"}
{"id": "2505.00242", "pdf": "https://arxiv.org/pdf/2505.00242", "abs": "https://arxiv.org/abs/2505.00242", "authors": ["Shingo Higashiguchi", "Yasuko Matsubara", "Koki Kawabata", "Taichi Murayama", "Yasushi Sakurai"], "title": "D-Tracker: Modeling Interest Diffusion in Social Activity Tensor Data Streams", "categories": ["cs.SI", "cs.LG"], "comment": "ACM SIGKDD 2025 (KDD2025)", "summary": "Large quantities of social activity data, such as weekly web search volumes\nand the number of new infections with infectious diseases, reflect peoples'\ninterests and activities. It is important to discover temporal patterns from\nsuch data and to forecast future activities accurately. However, modeling and\nforecasting social activity data streams is difficult because they are\nhigh-dimensional and composed of multiple time-varying dynamics such as trends,\nseasonality, and interest diffusion. In this paper, we propose D-Tracker, a\nmethod for continuously capturing time-varying temporal patterns within social\nactivity tensor data streams and forecasting future activities. Our proposed\nmethod has the following properties: (a) Interpretable: it incorporates the\npartial differential equation into a tensor decomposition framework and\ncaptures time-varying temporal patterns such as trends, seasonality, and\ninterest diffusion between locations in an interpretable manner; (b) Automatic:\nit has no hyperparameters and continuously models tensor data streams fully\nautomatically; (c) Scalable: the computation time of D-Tracker is independent\nof the time series length. Experiments using web search volume data obtained\nfrom GoogleTrends, and COVID-19 infection data obtained from COVID-19 Open Data\nRepository show that our method can achieve higher forecasting accuracy in less\ncomputation time than existing methods while extracting the interest diffusion\nbetween locations. Our source code and datasets are available at\n{https://github.com/Higashiguchi-Shingo/D-Tracker."}
{"id": "2410.20774", "pdf": "https://arxiv.org/pdf/2410.20774", "abs": "https://arxiv.org/abs/2410.20774", "authors": ["Dongryeol Lee", "Yerin Hwang", "Yongil Kim", "Joonsuk Park", "Kyomin Jung"], "title": "Are LLM-Judges Robust to Expressions of Uncertainty? Investigating the effect of Epistemic Markers on LLM-based Evaluation", "categories": ["cs.CL"], "comment": "NAACL 2025 Oral (21 pages, 6 figures, 15 tables)", "summary": "In line with the principle of honesty, there has been a growing effort to\ntrain large language models (LLMs) to generate outputs containing epistemic\nmarkers. However, evaluation in the presence of epistemic markers has been\nlargely overlooked, raising a critical question: Could the use of epistemic\nmarkers in LLM-generated outputs lead to unintended negative consequences? To\naddress this, we present EMBER, a benchmark designed to assess the robustness\nof LLM-judges to epistemic markers in both single and pairwise evaluation\nsettings. Our findings, based on evaluations using EMBER, reveal that all\ntested LLM-judges, including GPT-4o, show a notable lack of robustness in the\npresence of epistemic markers. Specifically, we observe a negative bias toward\nepistemic markers, with a stronger bias against markers expressing uncertainty.\nThis suggests that LLM-judges are influenced by the presence of these markers\nand do not focus solely on the correctness of the content."}
{"id": "2404.17525", "pdf": "https://arxiv.org/pdf/2404.17525", "abs": "https://arxiv.org/abs/2404.17525", "authors": ["Yayati Jadhav", "Amir Barati Farimani"], "title": "Large Language Model Agent as a Mechanical Designer", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Conventional mechanical design follows an iterative process in which initial\nconcepts are refined through cycles of expert assessment and resource-intensive\nFinite Element Method (FEM) analysis to meet performance goals. While machine\nlearning models have been developed to assist in parts of this process, they\ntypically require large datasets, extensive training, and are often tailored to\nspecific tasks, limiting their generalizability. To address these limitations,\nwe propose a framework that leverages a pretrained Large Language Model (LLM)\nin conjunction with an FEM module to autonomously generate, evaluate, and\nrefine structural designs based on performance specifications and numerical\nfeedback. The LLM operates without domain-specific fine-tuning, using general\nreasoning to propose design candidates, interpret FEM-derived performance\nmetrics, and apply structurally sound modifications. Using 2D truss structures\nas a testbed, we show that the LLM can effectively navigate highly discrete and\nmulti-faceted design spaces, balance competing objectives, and identify\nconvergence when further optimization yields diminishing returns. Compared to\nNon-dominated Sorting Genetic Algorithm II (NSGA-II), our method achieves\nfaster convergence and fewer FEM evaluations. Experiments with varying\ntemperature settings (0.5, 1.0, 1.2) and model sizes (GPT-4.1 and GPT-4.1-mini)\nindicate that smaller models yield higher constraint satisfaction with fewer\nsteps, while lower temperatures enhance design consistency. These results\nestablish LLMs as a promising new class of reasoning-based, natural\nlanguage-driven optimizers for autonomous design and iterative structural\nrefinement."}
{"id": "2406.03184", "pdf": "https://arxiv.org/pdf/2406.03184", "abs": "https://arxiv.org/abs/2406.03184", "authors": ["Hao Wen", "Zehuan Huang", "Yaohui Wang", "Xinyuan Chen", "Lu Sheng"], "title": "Ouroboros3D: Image-to-3D Generation via 3D-aware Recursive Diffusion", "categories": ["cs.CV"], "comment": "See our project page at https://costwen.github.io/Ouroboros3D/", "summary": "Existing single image-to-3D creation methods typically involve a two-stage\nprocess, first generating multi-view images, and then using these images for 3D\nreconstruction. However, training these two stages separately leads to\nsignificant data bias in the inference phase, thus affecting the quality of\nreconstructed results. We introduce a unified 3D generation framework, named\nOuroboros3D, which integrates diffusion-based multi-view image generation and\n3D reconstruction into a recursive diffusion process. In our framework, these\ntwo modules are jointly trained through a self-conditioning mechanism, allowing\nthem to adapt to each other's characteristics for robust inference. During the\nmulti-view denoising process, the multi-view diffusion model uses the 3D-aware\nmaps rendered by the reconstruction module at the previous timestep as\nadditional conditions. The recursive diffusion framework with 3D-aware feedback\nunites the entire process and improves geometric consistency.Experiments show\nthat our framework outperforms separation of these two stages and existing\nmethods that combine them at the inference phase. Project page:\nhttps://costwen.github.io/Ouroboros3D/"}
{"id": "2505.00282", "pdf": "https://arxiv.org/pdf/2505.00282", "abs": "https://arxiv.org/abs/2505.00282", "authors": ["Jacob Carlson", "Melissa Dell"], "title": "A Unifying Framework for Robust and Efficient Inference with Unstructured Data", "categories": ["econ.EM", "cs.LG"], "comment": null, "summary": "This paper presents a general framework for conducting efficient and robust\ninference on parameters derived from unstructured data, which include text,\nimages, audio, and video. Economists have long incorporated data extracted from\ntexts and images into their analyses, a practice that has accelerated with\nadvancements in deep neural networks. However, neural networks do not\ngenerically produce unbiased predictions, potentially propagating bias to\nestimators that use their outputs. To address this challenge, we reframe\ninference with unstructured data as a missing structured data problem, where\nstructured data are imputed from unstructured inputs using deep neural\nnetworks. This perspective allows us to apply classic results from\nsemiparametric inference, yielding valid, efficient, and robust estimators\nbased on unstructured data. We formalize this approach with MARS (Missing At\nRandom Structured Data), a unifying framework that integrates and extends\nexisting methods for debiased inference using machine learning predictions,\nlinking them to a variety of older, familiar problems such as causal inference.\nWe develop robust and efficient estimators for both descriptive and causal\nestimands and address challenges such as inference using aggregated and\ntransformed predictions from unstructured data. Importantly, MARS applies to\ncommon empirical settings that have received limited attention in the existing\nliterature. Finally, we reanalyze prominent studies that use unstructured data,\ndemonstrating the practical value of MARS."}
{"id": "2412.05862", "pdf": "https://arxiv.org/pdf/2412.05862", "abs": "https://arxiv.org/abs/2412.05862", "authors": ["Aman Kassahun Wassie", "Mahdi Molaei", "Yasmin Moslem"], "title": "Domain-Specific Translation with Open-Source Large Language Models: Resource-Oriented Analysis", "categories": ["cs.CL"], "comment": null, "summary": "In this work, we compare the domain-specific translation performance of\nopen-source autoregressive decoder-only large language models (LLMs) with\ntask-oriented machine translation (MT) models. Our experiments focus on the\nmedical domain and cover four language directions with varied resource\navailability: English-to-French, English-to-Portuguese, English-to-Swahili, and\nSwahili-to-English. Despite recent advancements, LLMs demonstrate a significant\nquality gap in specialized translation compared to multilingual encoder-decoder\nMT models such as NLLB-200. Our results indicate that NLLB-200 3.3B outperforms\nall evaluated LLMs in the 7-8B parameter range across three out of the four\nlanguage directions. While fine-tuning improves the performance of LLMs such as\nMistral and Llama, these models still underperform compared to fine-tuned\nNLLB-200 3.3B models. Our findings highlight the ongoing need for specialized\nMT models to achieve high-quality domain-specific translation, especially in\nmedium-resource and low-resource settings. Moreover, the superior performance\nof larger LLMs over their 8B variants suggests potential value in pre-training\ndomain-specific medium-sized language models, employing targeted data selection\nand knowledge distillation approaches to enhance both quality and efficiency in\nspecialized translation tasks."}
{"id": "2405.04620", "pdf": "https://arxiv.org/pdf/2405.04620", "abs": "https://arxiv.org/abs/2405.04620", "authors": ["Won-Gi Paeng", "Daesuk Kwon", "Kyungwon Jeong", "Honggyo Suh"], "title": "Folded Context Condensation in Path Integral Formalism for Infinite Context Transformers", "categories": ["hep-ph", "cs.AI", "cs.CL", "cs.LG", "cs.NE"], "comment": "11 pages, 12 figures", "summary": "In this work, we present a generalized formulation of the Transformer\nalgorithm by reinterpreting its core mechanisms within the framework of Path\nIntegral formalism. In this perspective, the attention mechanism is recast as a\nprocess that integrates all possible transition paths leading to future token\nstates, with temporal evolution governed by the Feed-Forward Network. By\nsystematically mapping each component of the Transformer to its counterpart in\nthe Path Integral formulation, we obtain a more compact and efficient\nrepresentation, in which the contextual information of a sequence is condensed\ninto memory-like segments. These segments are recurrently processed across\nTransformer layers, enabling more effective long-term information retention. We\nvalidate the effectiveness of this approach through the Passkey retrieval task\nand a summarization task, demonstrating that the proposed method preserves\nhistorical information while exhibiting memory usage that scales linearly with\nsequence length. This contrasts with the non-linear memory growth typically\nobserved in standard attention mechanisms. We expect that this quantum-inspired\ngeneralization of the Transformer architecture will open new avenues for\nenhancing both the efficiency and expressiveness of future Transformer models."}
{"id": "2409.08091", "pdf": "https://arxiv.org/pdf/2409.08091", "abs": "https://arxiv.org/abs/2409.08091", "authors": ["Zicheng Duan", "Yuxuan Ding", "Chenhui Gou", "Ziqin Zhou", "Ethan Smith", "Lingqiao Liu"], "title": "EZIGen: Enhancing zero-shot personalized image generation with precise subject encoding and decoupled guidance", "categories": ["cs.CV"], "comment": null, "summary": "Zero-shot personalized image generation models aim to produce images that\nalign with both a given text prompt and subject image, requiring the model to\nincorporate both sources of guidance. Existing methods often struggle to\ncapture fine-grained subject details and frequently prioritize one form of\nguidance over the other, resulting in suboptimal subject encoding and\nimbalanced generation. In this study, we uncover key insights into overcoming\nsuch drawbacks, notably that 1) the choice of the subject image encoder\ncritically influences subject identity preservation and training efficiency,\nand 2) the text and subject guidance should take effect at different denoising\nstages. Building on these insights, we introduce a new approach, EZIGen, that\nemploys two main components: leveraging a fixed pre-trained Diffusion UNet\nitself as subject encoder, following a process that balances the two guidances\nby separating their dominance stage and revisiting certain time steps to\nbootstrap subject transfer quality. Through these two components, EZIGen,\ninitially built upon SD2.1-base, achieved state-of-the-art performances on\nmultiple personalized generation benchmarks with a unified model, while using\n100 times less training data. Moreover, by further migrating our design to\nSDXL, EZIGen is proven to be a versatile model-agnostic solution for\npersonalized generation. Demo Page:\nzichengduan.github.io/pages/EZIGen/index.html"}
{"id": "2505.00299", "pdf": "https://arxiv.org/pdf/2505.00299", "abs": "https://arxiv.org/abs/2505.00299", "authors": ["Yang Wang", "Tengda Tang", "Zhou Fang", "Yingnan Deng", "Yifei Duan"], "title": "Intelligent Task Scheduling for Microservices via A3C-Based Reinforcement Learning", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "To address the challenges of high resource dynamism and intensive task\nconcurrency in microservice systems, this paper proposes an adaptive resource\nscheduling method based on the A3C reinforcement learning algorithm. The\nscheduling problem is modeled as a Markov Decision Process, where policy and\nvalue networks are jointly optimized to enable fine-grained resource allocation\nunder varying load conditions. The method incorporates an asynchronous\nmulti-threaded learning mechanism, allowing multiple agents to perform parallel\nsampling and synchronize updates to the global network parameters. This design\nimproves both policy convergence efficiency and model stability. In the\nexperimental section, a real-world dataset is used to construct a scheduling\nscenario. The proposed method is compared with several typical approaches\nacross multiple evaluation metrics, including task delay, scheduling success\nrate, resource utilization, and convergence speed. The results show that the\nproposed method delivers high scheduling performance and system stability in\nmulti-task concurrent environments. It effectively alleviates the resource\nallocation bottlenecks faced by traditional methods under heavy load,\ndemonstrating its practical value for intelligent scheduling in microservice\nsystems."}
{"id": "2501.00571", "pdf": "https://arxiv.org/pdf/2501.00571", "abs": "https://arxiv.org/abs/2501.00571", "authors": ["Chengcheng Mai", "Yuxiang Wang", "Ziyu Gong", "Hanxiang Wang", "Yihua Huang"], "title": "KnowRA: Knowledge Retrieval Augmented Method for Document-level Relation Extraction with Comprehensive Reasoning Abilities", "categories": ["cs.CL"], "comment": "This work has been accepted by IJCAI 2025 (CCF A)", "summary": "Document-level relation extraction (Doc-RE) aims to extract relations between\nentities across multiple sentences. Therefore, Doc-RE requires more\ncomprehensive reasoning abilities like humans, involving complex cross-sentence\ninteractions between entities, contexts, and external general knowledge,\ncompared to the sentence-level RE. However, most existing Doc-RE methods focus\non optimizing single reasoning ability, but lack the ability to utilize\nexternal knowledge for comprehensive reasoning on long documents. To solve\nthese problems, a knowledge retrieval augmented method, named KnowRA, was\nproposed with comprehensive reasoning to autonomously determine whether to\naccept external knowledge to assist DocRE. Firstly, we constructed a document\ngraph for semantic encoding and integrated the co-reference resolution model to\naugment the co-reference reasoning ability. Then, we expanded the document\ngraph into a document knowledge graph by retrieving the external knowledge base\nfor common-sense reasoning and a novel knowledge filtration method was\npresented to filter out irrelevant knowledge. Finally, we proposed the axis\nattention mechanism to build direct and indirect associations with intermediary\nentities for achieving cross-sentence logical reasoning. Extensive experiments\nconducted on two datasets verified the effectiveness of our method compared to\nthe state-of-the-art baselines. Our code is available at\nhttps://anonymous.4open.science/r/KnowRA."}
{"id": "2406.13216", "pdf": "https://arxiv.org/pdf/2406.13216", "abs": "https://arxiv.org/abs/2406.13216", "authors": ["Songyang Chen", "Yu Liu", "Lei Zou", "Zexuan Wang", "Youfang Lin"], "title": "CombAlign: Enhancing Model Expressiveness in Unsupervised Graph Alignment", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 9 figures", "summary": "Unsupervised graph alignment finds the node correspondence between a pair of\nattributed graphs by only exploiting graph structure and node features. One\ncategory of recent studies first computes the node representation and then\nmatches nodes with the largest embedding-based similarity, while the other\ncategory reduces the problem to optimal transport (OT) via Gromov-Wasserstein\nlearning. However, it remains largely unexplored in the model expressiveness,\nas well as how theoretical expressivity impacts prediction accuracy. We\ninvestigate the model expressiveness from two aspects. First, we characterize\nthe model's discriminative power in distinguishing matched and unmatched node\npairs across two graphs.Second, we study the model's capability of guaranteeing\nnode matching properties such as one-to-one matching and mutual alignment.\nMotivated by our theoretical analysis, we put forward a hybrid approach named\nCombAlign with stronger expressive power. Specifically, we enable\ncross-dimensional feature interaction for OT-based learning and propose an\nembedding-based method inspired by the Weisfeiler-Lehman test. We also apply\nnon-uniform marginals obtained from the embedding-based modules to OT as priors\nfor more expressiveness. Based on that, we propose a traditional\nalgorithm-based refinement, which combines our OT and embedding-based\npredictions using the ensemble learning strategy and reduces the problem to\nmaximum weight matching. With carefully designed edge weights, we ensure those\nmatching properties and further enhance prediction accuracy. By extensive\nexperiments, we demonstrate a significant improvement of 14.5% in alignment\naccuracy compared to state-of-the-art approaches and confirm the soundness of\nour theoretical analysis."}
{"id": "2409.08215", "pdf": "https://arxiv.org/pdf/2409.08215", "abs": "https://arxiv.org/abs/2409.08215", "authors": ["Quan Meng", "Lei Li", "Matthias Nießner", "Angela Dai"], "title": "LT3SD: Latent Trees for 3D Scene Diffusion", "categories": ["cs.CV", "cs.AI"], "comment": "Project page: https://quan-meng.github.io/projects/lt3sd/ Video:\n  https://youtu.be/AJ5sG9VyjGA", "summary": "We present LT3SD, a novel latent diffusion model for large-scale 3D scene\ngeneration. Recent advances in diffusion models have shown impressive results\nin 3D object generation, but are limited in spatial extent and quality when\nextended to 3D scenes. To generate complex and diverse 3D scene structures, we\nintroduce a latent tree representation to effectively encode both\nlower-frequency geometry and higher-frequency detail in a coarse-to-fine\nhierarchy. We can then learn a generative diffusion process in this latent 3D\nscene space, modeling the latent components of a scene at each resolution\nlevel. To synthesize large-scale scenes with varying sizes, we train our\ndiffusion model on scene patches and synthesize arbitrary-sized output 3D\nscenes through shared diffusion generation across multiple scene patches.\nThrough extensive experiments, we demonstrate the efficacy and benefits of\nLT3SD for large-scale, high-quality unconditional 3D scene generation and for\nprobabilistic completion for partial scene observations."}
{"id": "2505.00304", "pdf": "https://arxiv.org/pdf/2505.00304", "abs": "https://arxiv.org/abs/2505.00304", "authors": ["Yuhan Li", "Eugene Han", "Yifan Hu", "Wenzhuo Zhou", "Zhengling Qi", "Yifan Cui", "Ruoqing Zhu"], "title": "Reinforcement Learning with Continuous Actions Under Unmeasured Confounding", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "This paper addresses the challenge of offline policy learning in\nreinforcement learning with continuous action spaces when unmeasured\nconfounders are present. While most existing research focuses on policy\nevaluation within partially observable Markov decision processes (POMDPs) and\nassumes discrete action spaces, we advance this field by establishing a novel\nidentification result to enable the nonparametric estimation of policy value\nfor a given target policy under an infinite-horizon framework. Leveraging this\nidentification, we develop a minimax estimator and introduce a\npolicy-gradient-based algorithm to identify the in-class optimal policy that\nmaximizes the estimated policy value. Furthermore, we provide theoretical\nresults regarding the consistency, finite-sample error bound, and regret bound\nof the resulting optimal policy. Extensive simulations and a real-world\napplication using the German Family Panel data demonstrate the effectiveness of\nour proposed methodology."}
{"id": "2501.13947", "pdf": "https://arxiv.org/pdf/2501.13947", "abs": "https://arxiv.org/abs/2501.13947", "authors": ["Wenli Yang", "Lilian Some", "Michael Bain", "Byeong Kang"], "title": "A Comprehensive Survey on Integrating Large Language Models with Knowledge-Based Methods", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The rapid development of artificial intelligence has led to marked progress\nin the field. One interesting direction for research is whether Large Language\nModels (LLMs) can be integrated with structured knowledge-based systems. This\napproach aims to combine the generative language understanding of LLMs and the\nprecise knowledge representation systems by which they are integrated. This\narticle surveys the relationship between LLMs and knowledge bases, looks at how\nthey can be applied in practice, and discusses related technical, operational,\nand ethical challenges. Utilizing a comprehensive examination of the\nliterature, the study both identifies important issues and assesses existing\nsolutions. It demonstrates the merits of incorporating generative AI into\nstructured knowledge-base systems concerning data contextualization, model\naccuracy, and utilization of knowledge resources. The findings give a full list\nof the current situation of research, point out the main gaps, and propose\nhelpful paths to take. These insights contribute to advancing AI technologies\nand support their practical deployment across various sectors."}
{"id": "2407.01635", "pdf": "https://arxiv.org/pdf/2407.01635", "abs": "https://arxiv.org/abs/2407.01635", "authors": ["Wei Zhuo", "Han Yu", "Guang Tan", "Xiaoxiao Li"], "title": "Commute Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) have shown remarkable success in learning from\ngraph-structured data. However, their application to directed graphs (digraphs)\npresents unique challenges, primarily due to the inherent asymmetry in node\nrelationships. Traditional GNNs are adept at capturing unidirectional relations\nbut fall short in encoding the mutual path dependencies between nodes, such as\nasymmetrical shortest paths typically found in digraphs. Recognizing this gap,\nwe introduce Commute Graph Neural Networks (CGNN), an approach that seamlessly\nintegrates node-wise commute time into the message passing scheme. The\ncornerstone of CGNN is an efficient method for computing commute time using a\nnewly formulated digraph Laplacian. Commute time is then integrated into the\nneighborhood aggregation process, with neighbor contributions weighted\naccording to their respective commute time to the central node in each layer.\nIt enables CGNN to directly capture the mutual, asymmetric relationships in\ndigraphs. Extensive experiments on 8 benchmarking datasets confirm the\nsuperiority of CGNN against 13 state-of-the-art methods."}
{"id": "2411.16508", "pdf": "https://arxiv.org/pdf/2411.16508", "abs": "https://arxiv.org/abs/2411.16508", "authors": ["Ashmal Vayani", "Dinura Dissanayake", "Hasindri Watawana", "Noor Ahsan", "Nevasini Sasikumar", "Omkar Thawakar", "Henok Biadglign Ademtew", "Yahya Hmaiti", "Amandeep Kumar", "Kartik Kuckreja", "Mykola Maslych", "Wafa Al Ghallabi", "Mihail Mihaylov", "Chao Qin", "Abdelrahman M Shaker", "Mike Zhang", "Mahardika Krisna Ihsani", "Amiel Esplana", "Monil Gokani", "Shachar Mirkin", "Harsh Singh", "Ashay Srivastava", "Endre Hamerlik", "Fathinah Asma Izzati", "Fadillah Adamsyah Maani", "Sebastian Cavada", "Jenny Chim", "Rohit Gupta", "Sanjay Manjunath", "Kamila Zhumakhanova", "Feno Heriniaina Rabevohitra", "Azril Amirudin", "Muhammad Ridzuan", "Daniya Kareem", "Ketan More", "Kunyang Li", "Pramesh Shakya", "Muhammad Saad", "Amirpouya Ghasemaghaei", "Amirbek Djanibekov", "Dilshod Azizov", "Branislava Jankovic", "Naman Bhatia", "Alvaro Cabrera", "Johan Obando-Ceron", "Olympiah Otieno", "Fabian Farestam", "Muztoba Rabbani", "Sanoojan Baliah", "Santosh Sanjeev", "Abduragim Shtanchaev", "Maheen Fatima", "Thao Nguyen", "Amrin Kareem", "Toluwani Aremu", "Nathan Xavier", "Amit Bhatkal", "Hawau Toyin", "Aman Chadha", "Hisham Cholakkal", "Rao Muhammad Anwer", "Michael Felsberg", "Jorma Laaksonen", "Thamar Solorio", "Monojit Choudhury", "Ivan Laptev", "Mubarak Shah", "Salman Khan", "Fahad Khan"], "title": "All Languages Matter: Evaluating LMMs on Culturally Diverse 100 Languages", "categories": ["cs.CV", "cs.CL"], "comment": "A Multilingual Multimodal cultural benchmark for 100 languages", "summary": "Existing Large Multimodal Models (LMMs) generally focus on only a few regions\nand languages. As LMMs continue to improve, it is increasingly important to\nensure they understand cultural contexts, respect local sensitivities, and\nsupport low-resource languages, all while effectively integrating corresponding\nvisual cues. In pursuit of culturally diverse global multimodal models, our\nproposed All Languages Matter Benchmark (ALM-bench) represents the largest and\nmost comprehensive effort to date for evaluating LMMs across 100 languages.\nALM-bench challenges existing models by testing their ability to understand and\nreason about culturally diverse images paired with text in various languages,\nincluding many low-resource languages traditionally underrepresented in LMM\nresearch. The benchmark offers a robust and nuanced evaluation framework\nfeaturing various question formats, including true/false, multiple choice, and\nopen-ended questions, which are further divided into short and long-answer\ncategories. ALM-bench design ensures a comprehensive assessment of a model's\nability to handle varied levels of difficulty in visual and linguistic\nreasoning. To capture the rich tapestry of global cultures, ALM-bench carefully\ncurates content from 13 distinct cultural aspects, ranging from traditions and\nrituals to famous personalities and celebrations. Through this, ALM-bench not\nonly provides a rigorous testing ground for state-of-the-art open and\nclosed-source LMMs but also highlights the importance of cultural and\nlinguistic inclusivity, encouraging the development of models that can serve\ndiverse global populations effectively. Our benchmark is publicly available."}
{"id": "2505.00310", "pdf": "https://arxiv.org/pdf/2505.00310", "abs": "https://arxiv.org/abs/2505.00310", "authors": ["Maximilian Schuessler", "Erik Sverdrup", "Robert Tibshirani"], "title": "Statistical Learning for Heterogeneous Treatment Effects: Pretraining, Prognosis, and Prediction", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "Robust estimation of heterogeneous treatment effects is a fundamental\nchallenge for optimal decision-making in domains ranging from personalized\nmedicine to educational policy. In recent years, predictive machine learning\nhas emerged as a valuable toolbox for causal estimation, enabling more flexible\neffect estimation. However, accurately estimating conditional average treatment\neffects (CATE) remains a major challenge, particularly in the presence of many\ncovariates. In this article, we propose pretraining strategies that leverages a\nphenomenon in real-world applications: factors that are prognostic of the\noutcome are frequently also predictive of treatment effect heterogeneity. In\nmedicine, for example, components of the same biological signaling pathways\nfrequently influence both baseline risk and treatment response. Specifically,\nwe demonstrate our approach within the R-learner framework, which estimates the\nCATE by solving individual prediction problems based on a residualized loss. We\nuse this structure to incorporate \"side information\" and develop models that\ncan exploit synergies between risk prediction and causal effect estimation. In\nsettings where these synergies are present, this cross-task learning enables\nmore accurate signal detection: yields lower estimation error, reduced false\ndiscovery rates, and higher power for detecting heterogeneity."}
{"id": "2502.05945", "pdf": "https://arxiv.org/pdf/2502.05945", "abs": "https://arxiv.org/abs/2502.05945", "authors": ["Paul Darm", "Annalisa Riccardi"], "title": "HSI: Head-Specific Intervention Can Induce Misaligned AI Coordination in Large Language Models", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "Large Language Models (LLMs), Interference-time activation shifting,\n  Steerability, Explainability, AI alignment, Interpretability", "summary": "Robust alignment guardrails for large language models are becoming\nincreasingly important with their widespread application. In contrast to\nprevious studies, we demonstrate that inference-time activation interventions\ncan bypass safety alignments and effectively steer model generations towards\nharmful AI coordination for Llama 2. Our method applies fine-grained\ninterventions at specific model subcomponents, particularly attention heads,\nusing a simple binary choice probing strategy. These interventions then\ngeneralise to the open-ended generation setting effectively circumventing\nsafety guardrails. We show that probing single attention heads is more\neffective than intervening on full layers and intervening on only four\nattention heads is comparable to supervised fine-tuning. We further show that\nonly a few example completions are needed to compute effective steering\ndirections, which is an advantage over classical fine-tuning. Our findings\nhighlight the shortcomings of current alignment techniques. In addition, our\nresults suggest that, at the attention head level, activations encode\nfine-grained linearly separable behaviors. Practically, the approach offers a\nstraightforward methodology to steer large language model behaviour, which\ncould be extended to diverse domains beyond safety requiring fine-grained\ncontrol over the model output. The code and datasets for this study can be\nfound on https://github.com/PaulDrm/targeted_intervention."}
{"id": "2409.07415", "pdf": "https://arxiv.org/pdf/2409.07415", "abs": "https://arxiv.org/abs/2409.07415", "authors": ["Yuanhaur Chang", "Han Liu", "Chenyang Lu", "Ning Zhang"], "title": "SoK: Security and Privacy Risks of Healthcare AI", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "The integration of artificial intelligence (AI) and machine learning (ML)\ninto healthcare systems holds great promise for enhancing patient care and care\ndelivery efficiency; however, it also exposes sensitive data and system\nintegrity to potential cyberattacks. Current security and privacy (S&P)\nresearch on healthcare AI is highly unbalanced in terms of healthcare\ndeployment scenarios and threat models, and has a disconnected focus with the\nbiomedical research community. This hinders a comprehensive understanding of\nthe risks that healthcare AI entails. To address this gap, this paper takes a\nthorough examination of existing healthcare AI S&P research, providing a\nunified framework that allows the identification of under-explored areas. Our\nsurvey presents a systematic overview of healthcare AI attacks and defenses,\nand points out challenges and research opportunities for each AI-driven\nhealthcare application domain. Through our experimental analysis of different\nthreat models and feasibility studies on under-explored adversarial attacks, we\nprovide compelling insights into the pressing need for cybersecurity research\nin the rapidly evolving field of healthcare AI."}
{"id": "2412.06491", "pdf": "https://arxiv.org/pdf/2412.06491", "abs": "https://arxiv.org/abs/2412.06491", "authors": ["Yihong Xu", "Yuan Yin", "Éloi Zablocki", "Tuan-Hung Vu", "Alexandre Boulch", "Matthieu Cord"], "title": "PPT: Pretraining with Pseudo-Labeled Trajectories for Motion Forecasting", "categories": ["cs.CV", "cs.RO"], "comment": "18 pages, 9 figures, updated results", "summary": "Accurately predicting how agents move in dynamic scenes is essential for safe\nautonomous driving. State-of-the-art motion forecasting models rely on large\ncurated datasets with manually annotated or heavily post-processed\ntrajectories. However, building these datasets is costly, generally manual,\nhard to scale, and lacks reproducibility. They also introduce domain gaps that\nlimit generalization across environments. We introduce PPT (Pretraining with\nPseudo-labeled Trajectories), a simple and scalable alternative that uses\nunprocessed and diverse trajectories automatically generated from off-the-shelf\n3D detectors and tracking. Unlike traditional pipelines aiming for clean,\nsingle-label annotations, PPT embraces noise and diversity as useful signals\nfor learning robust representations. With optional finetuning on a small amount\nof labeled data, models pretrained with PPT achieve strong performance across\nstandard benchmarks particularly in low-data regimes, and in cross-domain,\nend-to-end and multi-class settings. PPT is easy to implement and improves\ngeneralization in motion forecasting. Code and data will be released upon\nacceptance."}
{"id": "2505.00318", "pdf": "https://arxiv.org/pdf/2505.00318", "abs": "https://arxiv.org/abs/2505.00318", "authors": ["Wei-Bin Kou", "Guangxu Zhu", "Bingyang Cheng", "Shuai Wang", "Ming Tang", "Yik-Chung Wu"], "title": "FedEMA: Federated Exponential Moving Averaging with Negative Entropy Regularizer in Autonomous Driving", "categories": ["cs.RO", "cs.LG"], "comment": "8 pages", "summary": "Street Scene Semantic Understanding (denoted as S3U) is a crucial but complex\ntask for autonomous driving (AD) vehicles. Their inference models typically\nface poor generalization due to domain-shift. Federated Learning (FL) has\nemerged as a promising paradigm for enhancing the generalization of AD models\nthrough privacy-preserving distributed learning. However, these FL AD models\nface significant temporal catastrophic forgetting when deployed in dynamically\nevolving environments, where continuous adaptation causes abrupt erosion of\nhistorical knowledge. This paper proposes Federated Exponential Moving Average\n(FedEMA), a novel framework that addresses this challenge through two integral\ninnovations: (I) Server-side model's historical fitting capability preservation\nvia fusing current FL round's aggregation model and a proposed previous FL\nround's exponential moving average (EMA) model; (II) Vehicle-side negative\nentropy regularization to prevent FL models' possible overfitting to\nEMA-introduced temporal patterns. Above two strategies empower FedEMA a\ndual-objective optimization that balances model generalization and\nadaptability. In addition, we conduct theoretical convergence analysis for the\nproposed FedEMA. Extensive experiments both on Cityscapes dataset and Camvid\ndataset demonstrate FedEMA's superiority over existing approaches, showing\n7.12% higher mean Intersection-over-Union (mIoU)."}
{"id": "2502.07963", "pdf": "https://arxiv.org/pdf/2502.07963", "abs": "https://arxiv.org/abs/2502.07963", "authors": ["Hye Sun Yun", "Karen Y. C. Zhang", "Ramez Kouzy", "Iain J. Marshall", "Junyi Jessy Li", "Byron C. Wallace"], "title": "Caught in the Web of Words: Do LLMs Fall for Spin in Medical Literature?", "categories": ["cs.CL", "cs.AI"], "comment": "22 pages, 12 figures, 4 tables", "summary": "Medical research faces well-documented challenges in translating novel\ntreatments into clinical practice. Publishing incentives encourage researchers\nto present \"positive\" findings, even when empirical results are equivocal.\nConsequently, it is well-documented that authors often spin study results,\nespecially in article abstracts. Such spin can influence clinician\ninterpretation of evidence and may affect patient care decisions. In this\nstudy, we ask whether the interpretation of trial results offered by Large\nLanguage Models (LLMs) is similarly affected by spin. This is important since\nLLMs are increasingly being used to trawl through and synthesize published\nmedical evidence. We evaluated 22 LLMs and found that they are across the board\nmore susceptible to spin than humans. They might also propagate spin into their\noutputs: We find evidence, e.g., that LLMs implicitly incorporate spin into\nplain language summaries that they generate. We also find, however, that LLMs\nare generally capable of recognizing spin, and can be prompted in a way to\nmitigate spin's impact on LLM outputs."}
{"id": "2410.05573", "pdf": "https://arxiv.org/pdf/2410.05573", "abs": "https://arxiv.org/abs/2410.05573", "authors": ["Xuan Zhu", "Dmitriy Bespalov", "Liwen You", "Ninad Kulkarni", "Yanjun Qi"], "title": "TaeBench: Improving Quality of Toxic Adversarial Examples", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "comment": "Accepted for publication in NAACL 2025. The official version will be\n  available in the ACL Anthology", "summary": "Toxicity text detectors can be vulnerable to adversarial examples - small\nperturbations to input text that fool the systems into wrong detection.\nExisting attack algorithms are time-consuming and often produce invalid or\nambiguous adversarial examples, making them less useful for evaluating or\nimproving real-world toxicity content moderators. This paper proposes an\nannotation pipeline for quality control of generated toxic adversarial examples\n(TAE). We design model-based automated annotation and human-based quality\nverification to assess the quality requirements of TAE. Successful TAE should\nfool a target toxicity model into making benign predictions, be grammatically\nreasonable, appear natural like human-generated text, and exhibit semantic\ntoxicity. When applying these requirements to more than 20 state-of-the-art\n(SOTA) TAE attack recipes, we find many invalid samples from a total of 940k\nraw TAE attack generations. We then utilize the proposed pipeline to filter and\ncurate a high-quality TAE dataset we call TaeBench (of size 264k). Empirically,\nwe demonstrate that TaeBench can effectively transfer-attack SOTA toxicity\ncontent moderation models and services. Our experiments also show that TaeBench\nwith adversarial training achieve significant improvements of the robustness of\ntwo toxicity detectors."}
{"id": "2501.01728", "pdf": "https://arxiv.org/pdf/2501.01728", "abs": "https://arxiv.org/abs/2501.01728", "authors": ["Simon B. Jensen", "Stefan Oehmcke", "Andreas Møgelmose", "Meysam Madadi", "Christian Igel", "Sergio Escalera", "Thomas B. Moeslund"], "title": "Multimodal classification of forest biodiversity potential from 2D orthophotos and 3D airborne laser scanning point clouds", "categories": ["cs.CV"], "comment": null, "summary": "Assessment of forest biodiversity is crucial for ecosystem management and\nconservation. While traditional field surveys provide high-quality assessments,\nthey are labor-intensive and spatially limited. This study investigates whether\ndeep learning-based fusion of close-range sensing data from 2D orthophotos and\n3D airborne laser scanning (ALS) point clouds can reliable assess the\nbiodiversity potential of forests. We introduce the BioVista dataset,\ncomprising 44 378 paired samples of orthophotos and ALS point clouds from\ntemperate forests in Denmark, designed to explore multimodal fusion approaches.\nUsing deep neural networks (ResNet for orthophotos and PointVector for ALS\npoint clouds), we investigate each data modality's ability to assess forest\nbiodiversity potential, achieving overall accuracies of 76.7% and 75.8%,\nrespectively. We explore various 2D and 3D fusion approaches: confidence-based\nensembling, feature-level concatenation, and end-to-end training, achieving\noverall accuracies of 80.5%, 81.4% and 80.4% respectively. Our results\ndemonstrate that spectral information from orthophotos and structural\ninformation from ALS point clouds effectively complement each other in forest\nbiodiversity assessment."}
{"id": "2505.00321", "pdf": "https://arxiv.org/pdf/2505.00321", "abs": "https://arxiv.org/abs/2505.00321", "authors": ["Zixin Wang", "Yuanming Shi", "Yong Zhou", "Jingyang Zhu", "Khaled. B. Letaief"], "title": "Edge Large AI Models: Revolutionizing 6G Networks", "categories": ["cs.NI", "cs.LG", "eess.SP"], "comment": null, "summary": "Large artificial intelligence models (LAMs) possess human-like abilities to\nsolve a wide range of real-world problems, exemplifying the potential of\nexperts in various domains and modalities. By leveraging the communication and\ncomputation capabilities of geographically dispersed edge devices, edge LAM\nemerges as an enabling technology to empower the delivery of various real-time\nintelligent services in 6G. Unlike traditional edge artificial intelligence\n(AI) that primarily supports a single task using small models, edge LAM is\nfeatured by the need of the decomposition and distributed deployment of large\nmodels, and the ability to support highly generalized and diverse tasks.\nHowever, due to limited communication, computation, and storage resources over\nwireless networks, the vast number of trainable neurons and the substantial\ncommunication overhead pose a formidable hurdle to the practical deployment of\nedge LAMs. In this paper, we investigate the opportunities and challenges of\nedge LAMs from the perspectives of model decomposition and resource management.\nSpecifically, we propose collaborative fine-tuning and full-parameter training\nframeworks, alongside a microservice-assisted inference architecture, to\nenhance the deployment of edge LAM over wireless networks. Additionally, we\ninvestigate the application of edge LAM in air-interface designs, focusing on\nchannel prediction and beamforming. These innovative frameworks and\napplications offer valuable insights and solutions for advancing 6G technology."}
{"id": "2502.20984", "pdf": "https://arxiv.org/pdf/2502.20984", "abs": "https://arxiv.org/abs/2502.20984", "authors": ["Thanet Markchom", "Tong Wu", "Liting Huang", "Huizhi Liang"], "title": "UoR-NCL at SemEval-2025 Task 1: Using Generative LLMs and CLIP Models for Multilingual Multimodal Idiomaticity Representation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "SemEval-2025 Task 1 focuses on ranking images based on their alignment with a\ngiven nominal compound that may carry idiomatic meaning in both English and\nBrazilian Portuguese. To address this challenge, this work uses generative\nlarge language models (LLMs) and multilingual CLIP models to enhance idiomatic\ncompound representations. LLMs generate idiomatic meanings for potentially\nidiomatic compounds, enriching their semantic interpretation. These meanings\nare then encoded using multilingual CLIP models, serving as representations for\nimage ranking. Contrastive learning and data augmentation techniques are\napplied to fine-tune these embeddings for improved performance. Experimental\nresults show that multimodal representations extracted through this method\noutperformed those based solely on the original nominal compounds. The\nfine-tuning approach shows promising outcomes but is less effective than using\nembeddings without fine-tuning. The source code used in this paper is available\nat https://github.com/tongwu17/SemEval-2025-Task1-UoR-NCL."}
{"id": "2410.08067", "pdf": "https://arxiv.org/pdf/2410.08067", "abs": "https://arxiv.org/abs/2410.08067", "authors": ["Shenao Zhang", "Zhihan Liu", "Boyi Liu", "Yufeng Zhang", "Yingxiang Yang", "Yongfei Liu", "Liyu Chen", "Tao Sun", "Zhaoran Wang"], "title": "Reward-Augmented Data Enhances Direct Preference Alignment of LLMs", "categories": ["cs.LG", "cs.AI"], "comment": "Published at ICML 2025", "summary": "Preference alignment in Large Language Models (LLMs) has significantly\nimproved their ability to adhere to human instructions and intentions. However,\nexisting direct alignment algorithms primarily focus on relative preferences\nand often overlook the qualitative aspects of responses, despite having access\nto preference data that includes reward scores from judge models during AI\nfeedback. Striving to maximize the implicit reward gap between the chosen and\nthe slightly inferior rejected responses can cause overfitting and unnecessary\nunlearning of the high-quality rejected responses. The unawareness of the\nreward scores also drives the LLM to indiscriminately favor the low-quality\nchosen responses and fail to generalize to optimal responses that are sparse in\ndata. To overcome these shortcomings, our study introduces reward-conditioned\nLLM policies that discern and learn from the entire spectrum of response\nquality within the dataset, helping extrapolate to more optimal regions. We\npropose an effective yet simple data relabeling method that conditions the\npreference pairs on quality scores to construct a reward-augmented dataset. The\nexperiments across various benchmarks and diverse models demonstrate that our\napproach consistently boosts DPO by a considerable margin. Through\ncomprehensive ablation studies, we demonstrate that our method not only\nmaximizes the utility of preference data but also mitigates the issue of\nunlearning, demonstrating its broad effectiveness beyond mere data expansion.\nOur code is available at\nhttps://github.com/shenao-zhang/reward-augmented-preference."}
{"id": "2501.09503", "pdf": "https://arxiv.org/pdf/2501.09503", "abs": "https://arxiv.org/abs/2501.09503", "authors": ["Junjie He", "Yuxiang Tuo", "Binghui Chen", "Chongyang Zhong", "Yifeng Geng", "Liefeng Bo"], "title": "AnyStory: Towards Unified Single and Multiple Subject Personalization in Text-to-Image Generation", "categories": ["cs.CV"], "comment": "Tech report; Project page:\n  https://aigcdesigngroup.github.io/AnyStory/", "summary": "Recently, large-scale generative models have demonstrated outstanding\ntext-to-image generation capabilities. However, generating high-fidelity\npersonalized images with specific subjects still presents challenges,\nespecially in cases involving multiple subjects. In this paper, we propose\nAnyStory, a unified approach for personalized subject generation. AnyStory not\nonly achieves high-fidelity personalization for single subjects, but also for\nmultiple subjects, without sacrificing subject fidelity. Specifically, AnyStory\nmodels the subject personalization problem in an \"encode-then-route\" manner. In\nthe encoding step, AnyStory utilizes a universal and powerful image encoder,\ni.e., ReferenceNet, in conjunction with CLIP vision encoder to achieve\nhigh-fidelity encoding of subject features. In the routing step, AnyStory\nutilizes a decoupled instance-aware subject router to accurately perceive and\npredict the potential location of the corresponding subject in the latent\nspace, and guide the injection of subject conditions. Detailed experimental\nresults demonstrate the excellent performance of our method in retaining\nsubject details, aligning text descriptions, and personalizing for multiple\nsubjects. The project page is at https://aigcdesigngroup.github.io/AnyStory/ ."}
{"id": "2505.00430", "pdf": "https://arxiv.org/pdf/2505.00430", "abs": "https://arxiv.org/abs/2505.00430", "authors": ["Chenghong Bian", "Meng Hua", "Deniz Gunduz"], "title": "Over-the-Air Inference over Multi-hop MIMO Networks", "categories": ["eess.SP", "cs.LG"], "comment": "5 pages", "summary": "A novel over-the-air machine learning framework over multi-hop multiple-input\nand multiple-output (MIMO) networks is proposed. The core idea is to imitate\nfully connected (FC) neural network layers using multiple MIMO channels by\ncarefully designing the precoding matrices at the transmitting nodes. A neural\nnetwork dubbed PrototypeNet is employed consisting of multiple FC layers, with\nthe number of neurons of each layer equal to the number of antennas of the\ncorresponding terminal. To achieve satisfactory performance, we train\nPrototypeNet based on a customized loss function consisting of classification\nerror and the power of latent vectors to satisfy transmit power constraints,\nwith noise injection during training. Precoding matrices for each hop are then\nobtained by solving an optimization problem. We also propose a multiple-block\nextension when the number of antennas is limited. Numerical results verify that\nthe proposed over-the-air transmission scheme can achieve satisfactory\nclassification accuracy under a power constraint. The results also show that\nhigher classification accuracy can be achieved with an increasing number of\nhops at a modest signal-to-noise ratio (SNR)."}
{"id": "2503.23895", "pdf": "https://arxiv.org/pdf/2503.23895", "abs": "https://arxiv.org/abs/2503.23895", "authors": ["Yuqiao Tan", "Shizhu He", "Huanxuan Liao", "Jun Zhao", "Kang Liu"], "title": "Dynamic Parametric Retrieval Augmented Generation for Test-time Knowledge Enhancement", "categories": ["cs.CL", "cs.AI"], "comment": "preprint. Code is available at https://github.com/Trae1ounG/DyPRAG", "summary": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by\nretrieving relevant documents from external sources and incorporating them into\nthe context. While it improves reliability by providing factual texts, it\nsignificantly increases inference costs as context length grows and introduces\nchallenging issue of RAG hallucination, primarily caused by the lack of\ncorresponding parametric knowledge in LLMs. An efficient solution is to enhance\nthe knowledge of LLMs at test-time. Parametric RAG (PRAG) addresses this by\nembedding document into LLMs parameters to perform test-time knowledge\nenhancement, effectively reducing inference costs through offline training.\nHowever, its high training and storage costs, along with limited generalization\nability, significantly restrict its practical adoption. To address these\nchallenges, we propose Dynamic Parametric RAG (DyPRAG), a novel framework that\nleverages a lightweight parameter translator model to efficiently convert\ndocuments into parametric knowledge. DyPRAG not only reduces inference,\ntraining, and storage costs but also dynamically generates parametric\nknowledge, seamlessly enhancing the knowledge of LLMs and resolving knowledge\nconflicts in a plug-and-play manner at test-time. Extensive experiments on\nmultiple datasets demonstrate the effectiveness and generalization capabilities\nof DyPRAG, offering a powerful and practical RAG paradigm which enables\nsuperior knowledge fusion and mitigates RAG hallucination in real-world\napplications. Our code is available at https://github.com/Trae1ounG/DyPRAG."}
{"id": "2411.05793", "pdf": "https://arxiv.org/pdf/2411.05793", "abs": "https://arxiv.org/abs/2411.05793", "authors": ["Jongseon Kim", "Hyungjoon Kim", "HyunGi Kim", "Dongjun Lee", "Sungroh Yoon"], "title": "A Comprehensive Survey of Deep Learning for Time Series Forecasting: Architectural Diversity and Open Challenges", "categories": ["cs.LG", "cs.AI"], "comment": "This is the accepted manuscript of the article published in\n  Artificial Intelligence Review. The final authenticated version is available\n  at: https://doi.org/10.1007/s10462-025-11223-9", "summary": "Time series forecasting is a critical task that provides key information for\ndecision-making. After traditional statistical and machine learning approaches,\nvarious fundamental deep learning architectures such as MLPs, CNNs, RNNs, and\nGNNs have been developed. However, the structural limitations caused by the\ninductive biases of each deep learning architecture constrained their\nperformance. Transformer models, which excel at handling long-term\ndependencies, have become significant architectural components for time series\nforecasting. However, recent research has shown that alternatives such as\nsimple linear layers can outperform Transformers. These findings have opened up\nnew possibilities for using diverse architectures, ranging from fundamental\ndeep learning models to emerging architectures and hybrid approaches. In this\ncontext, architectural modeling of time series forecasting has now entered a\nrenaissance. This survey not only provides a historical context for time series\nforecasting but also offers comprehensive and timely analysis of the movement\ntoward architectural diversification. By comparing and re-examining deep\nlearning models, we uncover new perspectives and present recent trends,\nincluding hybrid, diffusion, Mamba, and foundation models. By focusing on the\ninherent characteristics of time series data, we also address open challenges\nthat have gained attention in time series forecasting, such as channel\ndependency, distribution shift, causality, and feature extraction. These\ncontributions help lower entry barriers for newcomers by providing a systematic\nunderstanding of the diverse research areas in time series forecasting (TSF),\nwhile offering seasoned researchers broader perspectives and new opportunities\nthrough in-depth exploration of TSF challenges. (Shortened due to arXiv's\n1,920-character limit. Full version in the paper.)"}
{"id": "2501.19243", "pdf": "https://arxiv.org/pdf/2501.19243", "abs": "https://arxiv.org/abs/2501.19243", "authors": ["Junxiang Qiu", "Shuo Wang", "Jinda Lu", "Lin Liu", "Houcheng Jiang", "Xingyu Zhu", "Yanbin Hao"], "title": "Accelerating Diffusion Transformer via Error-Optimized Cache", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion Transformer (DiT) is a crucial method for content generation.\nHowever, it needs a lot of time to sample. Many studies have attempted to use\ncaching to reduce the time consumption of sampling. Existing caching methods\naccelerate generation by reusing DiT features from the previous time step and\nskipping calculations in the next, but they tend to locate and cache low-error\nmodules without focusing on reducing caching-induced errors, resulting in a\nsharp decline in generated content quality when increasing caching intensity.\nTo solve this problem, we propose the Error-Optimized Cache (EOC). This method\nintroduces three key improvements: (1) Prior knowledge extraction: Extract and\nprocess the caching differences; (2) A judgment method for cache optimization:\nDetermine whether certain caching steps need to be optimized; (3) Cache\noptimization: reduce caching errors. Experiments show that this algorithm\nsignificantly reduces the error accumulation caused by caching, especially\nexcessive caching. On the ImageNet dataset, without substantially increasing\nthe computational load, this method improves the FID of the generated images\nwhen the rule-based model FORA has a caching level of 75%, 50%, and 25%, and\nthe training-based model Learning-to-cache has a caching level of 22%.\nSpecifically, the FID values change from 30.454 to 21.690 (28.8%), from 6.857\nto 5.821 (15.1%), from 3.870 to 3.692 (4.6%), and from 3.539 to 3.451 (2.5%)\nrespectively."}
{"id": "2505.00460", "pdf": "https://arxiv.org/pdf/2505.00460", "abs": "https://arxiv.org/abs/2505.00460", "authors": ["Harshit Kapadia", "Peter Benner", "Lihong Feng"], "title": "Subspace-Distance-Enabled Active Learning for Efficient Data-Driven Model Reduction of Parametric Dynamical Systems", "categories": ["math.NA", "cs.CE", "cs.LG", "cs.NA", "math.DS", "physics.comp-ph"], "comment": "31 pages, 10 figures, 4 tables", "summary": "In situations where the solution of a high-fidelity dynamical system needs to\nbe evaluated repeatedly, over a vast pool of parametric configurations and in\nabsence of access to the underlying governing equations, data-driven model\nreduction techniques are preferable. We propose a novel active learning\napproach to build a parametric data-driven reduced-order model (ROM) by\ngreedily picking the most important parameter samples from the parameter\ndomain. As a result, during the ROM construction phase, the number of\nhigh-fidelity solutions dynamically grow in a principled fashion. The\nhigh-fidelity solution snapshots are expressed in several parameter-specific\nlinear subspaces, with the help of proper orthogonal decomposition (POD), and\nthe relative distance between these subspaces is used as a guiding mechanism to\nperform active learning. For successfully achieving this, we provide a distance\nmeasure to evaluate the similarity between pairs of linear subspaces with\ndifferent dimensions, and also show that this distance measure is a metric. The\nusability of the proposed subspace-distance-enabled active learning (SDE-AL)\nframework is demonstrated by augmenting two existing non-intrusive\nreduced-order modeling approaches, and providing their active-learning-driven\n(ActLearn) extensions, namely, SDE-ActLearn-POD-KSNN, and SDE-ActLearn-POD-NN.\nFurthermore, we report positive results for two parametric physical models,\nhighlighting the efficiency of the proposed SDE-AL approach."}
{"id": "2504.00027", "pdf": "https://arxiv.org/pdf/2504.00027", "abs": "https://arxiv.org/abs/2504.00027", "authors": ["Grigori Sidorov", "Muhammad Ahmad", "Iqra Ameer", "Muhammad Usman", "Ildar Batyrshin"], "title": "Opioid Named Entity Recognition (ONER-2025) from Reddit", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The opioid overdose epidemic remains a critical public health crisis,\nparticularly in the United States, leading to significant mortality and\nsocietal costs. Social media platforms like Reddit provide vast amounts of\nunstructured data that offer insights into public perceptions, discussions, and\nexperiences related to opioid use. This study leverages Natural Language\nProcessing (NLP), specifically Opioid Named Entity Recognition (ONER-2025), to\nextract actionable information from these platforms. Our research makes four\nkey contributions. First, we created a unique, manually annotated dataset\nsourced from Reddit, where users share self-reported experiences of opioid use\nvia different administration routes. This dataset contains 331,285 tokens and\nincludes eight major opioid entity categories. Second, we detail our annotation\nprocess and guidelines while discussing the challenges of labeling the\nONER-2025 dataset. Third, we analyze key linguistic challenges, including\nslang, ambiguity, fragmented sentences, and emotionally charged language, in\nopioid discussions. Fourth, we propose a real-time monitoring system to process\nstreaming data from social media, healthcare records, and emergency services to\nidentify overdose events. Using 5-fold cross-validation in 11 experiments, our\nsystem integrates machine learning, deep learning, and transformer-based\nlanguage models with advanced contextual embeddings to enhance understanding.\nOur transformer-based models (bert-base-NER and roberta-base) achieved 97%\naccuracy and F1-score, outperforming baselines by 10.23% (RF=0.88)."}
{"id": "2412.08085", "pdf": "https://arxiv.org/pdf/2412.08085", "abs": "https://arxiv.org/abs/2412.08085", "authors": ["Syrine Belakaria", "Alaleh Ahmadianshalchi", "Barbara Engelhardt", "Stefano Ermon", "Janardhan Rao Doppa"], "title": "Non-Myopic Multi-Objective Bayesian Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "Published in Transactions on Machine Learning Research (TMLR)", "summary": "We consider the problem of finite-horizon sequential experimental design to\nsolve multi-objective optimization (MOO) of expensive black-box objective\nfunctions. This problem arises in many real-world applications, including\nmaterials design, where we have a small resource budget to make and evaluate\ncandidate materials in the lab. We solve this problem using the framework of\nBayesian optimization (BO) and propose the first set of non-myopic methods for\nMOO problems. Prior work on non-myopic BO for single-objective problems relies\non the Bellman optimality principle to handle the lookahead reasoning process.\nHowever, this principle does not hold for most MOO problems because the reward\nfunction needs to satisfy some conditions: scalar variable, monotonicity, and\nadditivity. We address this challenge by using hypervolume improvement (HVI) as\nour scalarization approach, which allows us to use a lower-bound on the Bellman\nequation to approximate the finite-horizon using a batch expected hypervolume\nimprovement (EHVI) acquisition function (AF) for MOO. Our formulation naturally\nallows us to use other improvement-based scalarizations and compare their\nefficacy to HVI. We derive three non-myopic AFs for MOBO: 1) the Nested AF,\nwhich is based on the exact computation of the lower bound, 2) the Joint AF,\nwhich is a lower bound on the nested AF, and 3) the BINOM AF, which is a fast\nand approximate variant based on batch multi-objective acquisition functions.\nOur experiments on multiple diverse real-world MO problems demonstrate that our\nnon-myopic AFs substantially improve performance over the existing myopic AFs\nfor MOBO."}
{"id": "2504.02782", "pdf": "https://arxiv.org/pdf/2504.02782", "abs": "https://arxiv.org/abs/2504.02782", "authors": ["Zhiyuan Yan", "Junyan Ye", "Weijia Li", "Zilong Huang", "Shenghai Yuan", "Xiangyang He", "Kaiqing Lin", "Jun He", "Conghui He", "Li Yuan"], "title": "GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "The recent breakthroughs in OpenAI's GPT4o model have demonstrated\nsurprisingly good capabilities in image generation and editing, resulting in\nsignificant excitement in the community. This technical report presents the\nfirst-look evaluation benchmark (named GPT-ImgEval), quantitatively and\nqualitatively diagnosing GPT-4o's performance across three critical dimensions:\n(1) generation quality, (2) editing proficiency, and (3) world\nknowledge-informed semantic synthesis. Across all three tasks, GPT-4o\ndemonstrates strong performance, significantly surpassing existing methods in\nboth image generation control and output quality, while also showcasing\nexceptional knowledge reasoning capabilities. Furthermore, based on the\nGPT-4o's generated data, we propose a classification-model-based approach to\ninvestigate the underlying architecture of GPT-4o, where our empirical results\nsuggest the model consists of an auto-regressive (AR) combined with a\ndiffusion-based head for image decoding, rather than the VAR-like\narchitectures. We also provide a complete speculation on GPT-4o's overall\narchitecture. In addition, we conduct a series of analyses to identify and\nvisualize GPT-4o's specific limitations and the synthetic artifacts commonly\nobserved in its image generation. We also present a comparative study of\nmulti-round image editing between GPT-4o and Gemini 2.0 Flash, and discuss the\nsafety implications of GPT-4o's outputs, particularly their detectability by\nexisting image forensic models. We hope that our work can offer valuable\ninsight and provide a reliable benchmark to guide future research, foster\nreproducibility, and accelerate innovation in the field of image generation and\nbeyond. The codes and datasets used for evaluating GPT-4o can be found at\nhttps://github.com/PicoTrex/GPT-ImgEval."}
{"id": "2505.00500", "pdf": "https://arxiv.org/pdf/2505.00500", "abs": "https://arxiv.org/abs/2505.00500", "authors": ["Minseok Song", "JeongHo Ha", "Bonggyeong Park", "Daehyung Park"], "title": "Implicit Neural-Representation Learning for Elastic Deformable-Object Manipulations", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "We aim to solve the problem of manipulating deformable objects, particularly\nelastic bands, in real-world scenarios. However, deformable object manipulation\n(DOM) requires a policy that works on a large state space due to the unlimited\ndegree of freedom (DoF) of deformable objects. Further, their dense but partial\nobservations (e.g., images or point clouds) may increase the sampling\ncomplexity and uncertainty in policy learning. To figure it out, we propose a\nnovel implicit neural-representation (INR) learning for elastic DOMs, called\nINR-DOM. Our method learns consistent state representations associated with\npartially observable elastic objects reconstructing a complete and implicit\nsurface represented as a signed distance function. Furthermore, we perform\nexploratory representation fine-tuning through reinforcement learning (RL) that\nenables RL algorithms to effectively learn exploitable representations while\nefficiently obtaining a DOM policy. We perform quantitative and qualitative\nanalyses building three simulated environments and real-world manipulation\nstudies with a Franka Emika Panda arm. Videos are available at\nhttp://inr-dom.github.io."}
{"id": "2504.14194", "pdf": "https://arxiv.org/pdf/2504.14194", "abs": "https://arxiv.org/abs/2504.14194", "authors": ["Xinlin Zhuang", "Jiahui Peng", "Ren Ma", "Yinfan Wang", "Tianyi Bai", "Xingjian Wei", "Jiantao Qiu", "Chi Zhang", "Ying Qian", "Conghui He"], "title": "Meta-rater: A Multi-dimensional Data Selection Method for Pre-training Language Models", "categories": ["cs.CL"], "comment": "Under review", "summary": "The composition of pre-training datasets for large language models (LLMs)\nremains largely undisclosed, hindering transparency and efforts to optimize\ndata quality, a critical driver of model performance. Current data selection\nmethods, such as natural language quality assessments, diversity-based filters,\nand classifier-based approaches, are limited by single-dimensional evaluation\nor redundancy-focused strategies. To address these gaps, we propose PRRC to\nevaluate data quality across Professionalism, Readability, Reasoning, and\nCleanliness. We further introduce Meta-rater, a multi-dimensional data\nselection method that integrates these dimensions with existing quality metrics\nthrough learned optimal weightings. Meta-rater employs proxy models to train a\nregression model that predicts validation loss, enabling the identification of\noptimal combinations of quality scores. Experiments demonstrate that Meta-rater\ndoubles convergence speed for 1.3B parameter models and improves downstream\ntask performance by 3.23, with scalable benefits observed in 3.3B models\ntrained on 100B tokens. Additionally, we release the annotated SlimPajama-627B\ndataset, labeled across 25 quality metrics (including PRRC), to advance\nresearch in data-centric LLM development. Our work establishes that holistic,\nmulti-dimensional quality integration significantly outperforms conventional\nsingle-dimension approaches, offering a scalable paradigm for enhancing\npre-training efficiency and model capability."}
{"id": "2412.18086", "pdf": "https://arxiv.org/pdf/2412.18086", "abs": "https://arxiv.org/abs/2412.18086", "authors": ["Aizierjiang Aiersilan"], "title": "Generating Traffic Scenarios via In-Context Learning to Learn Better Motion Planner", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.GR", "cs.LG"], "comment": "We are excited to announce that this paper has been accepted for oral\n  presentation at the AAAI 2025 Main Conference. We are grateful for the\n  insightful feedback from the reviewers and look forward to contributing to\n  the discussions at AAAI", "summary": "Motion planning is a crucial component in autonomous driving.\nState-of-the-art motion planners are trained on meticulously curated datasets,\nwhich are not only expensive to annotate but also insufficient in capturing\nrarely seen critical scenarios. Failing to account for such scenarios poses a\nsignificant risk to motion planners and may lead to incidents during testing.\nAn intuitive solution is to manually compose such scenarios by programming and\nexecuting a simulator (e.g., CARLA). However, this approach incurs substantial\nhuman costs. Motivated by this, we propose an inexpensive method for generating\ndiverse critical traffic scenarios to train more robust motion planners. First,\nwe represent traffic scenarios as scripts, which are then used by the simulator\nto generate traffic scenarios. Next, we develop a method that accepts\nuser-specified text descriptions, which a Large Language Model translates into\nscripts using in-context learning. The output scripts are sent to the simulator\nthat produces the corresponding traffic scenarios. As our method can generate\nabundant safety-critical traffic scenarios, we use them as synthetic training\ndata for motion planners. To demonstrate the value of generated scenarios, we\ntrain existing motion planners on our synthetic data, real-world datasets, and\na combination of both. Our experiments show that motion planners trained with\nour data significantly outperform those trained solely on real-world data,\nshowing the usefulness of our synthetic data and the effectiveness of our data\ngeneration method. Our source code is available at\nhttps://ezharjan.github.io/AutoSceneGen."}
{"id": "2504.14467", "pdf": "https://arxiv.org/pdf/2504.14467", "abs": "https://arxiv.org/abs/2504.14467", "authors": ["Jiachen Li", "Qing Xie", "Renshu Gu", "Jinyu Xu", "Yongjian Liu", "Xiaohan Yu"], "title": "LGD: Leveraging Generative Descriptions for Zero-Shot Referring Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Zero-shot referring image segmentation aims to locate and segment the target\nregion based on a referring expression, with the primary challenge of aligning\nand matching semantics across visual and textual modalities without training.\nPrevious works address this challenge by utilizing Vision-Language Models and\nmask proposal networks for region-text matching. However, this paradigm may\nlead to incorrect target localization due to the inherent ambiguity and\ndiversity of free-form referring expressions. To alleviate this issue, we\npresent LGD (Leveraging Generative Descriptions), a framework that utilizes the\nadvanced language generation capabilities of Multi-Modal Large Language Models\nto enhance region-text matching performance in Vision-Language Models.\nSpecifically, we first design two kinds of prompts, the attribute prompt and\nthe surrounding prompt, to guide the Multi-Modal Large Language Models in\ngenerating descriptions related to the crucial attributes of the referent\nobject and the details of surrounding objects, referred to as attribute\ndescription and surrounding description, respectively. Secondly, three\nvisual-text matching scores are introduced to evaluate the similarity between\ninstance-level visual features and textual features, which determines the mask\nmost associated with the referring expression. The proposed method achieves new\nstate-of-the-art performance on three public datasets RefCOCO, RefCOCO+ and\nRefCOCOg, with maximum improvements of 9.97% in oIoU and 11.29% in mIoU\ncompared to previous methods."}
{"id": "2505.00526", "pdf": "https://arxiv.org/pdf/2505.00526", "abs": "https://arxiv.org/abs/2505.00526", "authors": ["Yanhao 'Max' Wei", "Zhenling Jiang"], "title": "Pre-Training Estimators for Structural Models: Application to Consumer Search", "categories": ["econ.EM", "cs.LG", "stat.CO", "G.3; J.4; I.2"], "comment": null, "summary": "We explore pretraining estimators for structural econometric models. The\nestimator is \"pretrained\" in the sense that the bulk of the computational cost\nand researcher effort occur during the construction of the estimator.\nSubsequent applications of the estimator to different datasets require little\ncomputational cost or researcher effort. The estimation leverages a neural net\nto recognize the structural model's parameter from data patterns. As an initial\ntrial, this paper builds a pretrained estimator for a sequential search model\nthat is known to be difficult to estimate. We evaluate the pretrained estimator\non 14 real datasets. The estimation takes seconds to run and shows high\naccuracy. We provide the estimator at pnnehome.github.io. More generally,\npretrained, off-the-shelf estimators can make structural models more accessible\nto researchers and practitioners."}
{"id": "2504.16060", "pdf": "https://arxiv.org/pdf/2504.16060", "abs": "https://arxiv.org/abs/2504.16060", "authors": ["Ziqiao Ma", "Jing Ding", "Xuejun Zhang", "Dezhi Luo", "Jiahe Ding", "Sihan Xu", "Yuchen Huang", "Run Peng", "Joyce Chai"], "title": "Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation", "categories": ["cs.CL"], "comment": "Homepage: https://vlm-reg.github.io/", "summary": "Referring Expression Generation (REG) is a core task for evaluating the\npragmatic competence of vision-language systems, requiring not only accurate\nsemantic grounding but also adherence to principles of cooperative\ncommunication (Grice, 1975). However, current evaluations of vision-language\nmodels (VLMs) often overlook the pragmatic dimension, reducing REG to a\nregion-based captioning task and neglecting Gricean maxims. In this work, we\nrevisit REG from a pragmatic perspective, introducing a new dataset (RefOI) of\n1.5k images annotated with both written and spoken referring expressions.\nThrough a systematic evaluation of state-of-the-art VLMs, we identify three key\nfailures of pragmatic competence: (1) failure to uniquely identify the\nreferent, (2) inclusion of excessive or irrelevant information, and (3)\nmisalignment with human pragmatic preference, such as the underuse of minimal\nspatial cues. We also show that standard automatic evaluations fail to capture\nthese pragmatic violations, reinforcing superficial cues rather than genuine\nreferential success. Our findings call for a renewed focus on pragmatically\ninformed models and evaluation frameworks that align with real human\ncommunication."}
{"id": "2501.06066", "pdf": "https://arxiv.org/pdf/2501.06066", "abs": "https://arxiv.org/abs/2501.06066", "authors": ["Jiayi Huang", "Sangwoo Park", "Nicola Paoletti", "Osvaldo Simeone"], "title": "Distilling Calibration via Conformalized Credal Inference", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": "Under review", "summary": "Deploying artificial intelligence (AI) models on edge devices involves a\ndelicate balance between meeting stringent complexity constraints, such as\nlimited memory and energy resources, and ensuring reliable performance in\nsensitive decision-making tasks. One way to enhance reliability is through\nuncertainty quantification via Bayesian inference. This approach, however,\ntypically necessitates maintaining and running multiple models in an ensemble,\nwhich may exceed the computational limits of edge devices. This paper\nintroduces a low-complexity methodology to address this challenge by distilling\ncalibration information from a more complex model. In an offline phase,\npredictive probabilities generated by a high-complexity cloud-based model are\nleveraged to determine a threshold based on the typical divergence between the\ncloud and edge models. At run time, this threshold is used to construct credal\nsets -- ranges of predictive probabilities that are guaranteed, with a\nuser-selected confidence level, to include the predictions of the cloud model.\nThe credal sets are obtained through thresholding of a divergence measure in\nthe simplex of predictive probabilities. Experiments on visual and language\ntasks demonstrate that the proposed approach, termed Conformalized Distillation\nfor Credal Inference (CD-CI), significantly improves calibration performance\ncompared to low-complexity Bayesian methods, such as Laplace approximation,\nmaking it a practical and efficient solution for edge AI deployments."}
{"id": "2504.20379", "pdf": "https://arxiv.org/pdf/2504.20379", "abs": "https://arxiv.org/abs/2504.20379", "authors": ["Jongwon Lee", "Timothy Bretl"], "title": "GSFeatLoc: Visual Localization Using Feature Correspondence on 3D Gaussian Splatting", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "In this paper, we present a method for localizing a query image with respect\nto a precomputed 3D Gaussian Splatting (3DGS) scene representation. First, the\nmethod uses 3DGS to render a synthetic RGBD image at some initial pose\nestimate. Second, it establishes 2D-2D correspondences between the query image\nand this synthetic image. Third, it uses the depth map to lift the 2D-2D\ncorrespondences to 2D-3D correspondences and solves a perspective-n-point (PnP)\nproblem to produce a final pose estimate. Results from evaluation across three\nexisting datasets with 38 scenes and over 2,700 test images show that our\nmethod significantly reduces both inference time (by over two orders of\nmagnitude, from more than 10 seconds to as fast as 0.1 seconds) and estimation\nerror compared to baseline methods that use photometric loss minimization.\nResults also show that our method tolerates large errors in the initial pose\nestimate of up to 55{\\deg} in rotation and 1.1 units in translation (normalized\nby scene scale), achieving final pose errors of less than 5{\\deg} in rotation\nand 0.05 units in translation on 90% of images from the Synthetic NeRF and\nMip-NeRF360 datasets and on 42% of images from the more challenging Tanks and\nTemples dataset."}
{"id": "2505.00552", "pdf": "https://arxiv.org/pdf/2505.00552", "abs": "https://arxiv.org/abs/2505.00552", "authors": ["Chanwoo Kim", "Jinkyu Sung", "Yebonn Han", "Joonseok Lee"], "title": "Graph Spectral Filtering with Chebyshev Interpolation for Recommendation", "categories": ["cs.IR", "cs.LG"], "comment": "Accepted by SIGIR 2025; 11 pages, 9 figures, 5 tables", "summary": "Graph convolutional networks have recently gained prominence in collaborative\nfiltering (CF) for recommendations. However, we identify potential bottlenecks\nin two foundational components. First, the embedding layer leads to a latent\nspace with limited capacity, overlooking locally observed but potentially\nvaluable preference patterns. Also, the widely-used neighborhood aggregation is\nlimited in its ability to leverage diverse preference patterns in a\nfine-grained manner. Building on spectral graph theory, we reveal that these\nlimitations stem from graph filtering with a cut-off in the frequency spectrum\nand a restricted linear form. To address these issues, we introduce ChebyCF, a\nCF framework based on graph spectral filtering. Instead of a learned embedding,\nit takes a user's raw interaction history to utilize the full spectrum of\nsignals contained in it. Also, it adopts Chebyshev interpolation to effectively\napproximate a flexible non-linear graph filter, and further enhances it by\nusing an additional ideal pass filter and degree-based normalization. Through\nextensive experiments, we verify that ChebyCF overcomes the aforementioned\nbottlenecks and achieves state-of-the-art performance across multiple\nbenchmarks and reasonably fast inference. Our code is available at\nhttps://github.com/chanwoo0806/ChebyCF."}
{"id": "2504.19314", "pdf": "https://arxiv.org/pdf/2504.19314", "abs": "https://arxiv.org/abs/2504.19314", "authors": ["Peilin Zhou", "Bruce Leon", "Xiang Ying", "Can Zhang", "Yifan Shao", "Qichen Ye", "Dading Chong", "Zhiling Jin", "Chenxuan Xie", "Meng Cao", "Yuxin Gu", "Sixin Hong", "Jing Ren", "Jian Chen", "Chao Liu", "Yining Hua"], "title": "BrowseComp-ZH: Benchmarking Web Browsing Ability of Large Language Models in Chinese", "categories": ["cs.CL"], "comment": "Under Review", "summary": "As large language models (LLMs) evolve into tool-using agents, the ability to\nbrowse the web in real-time has become a critical yardstick for measuring their\nreasoning and retrieval competence. Existing benchmarks such as BrowseComp\nconcentrate on English and overlook the linguistic, infrastructural, and\ncensorship-related complexities of other major information ecosystems -- most\nnotably Chinese. To address this gap, we introduce BrowseComp-ZH, a\nhigh-difficulty benchmark purpose-built to comprehensively evaluate LLM agents\non the Chinese web. BrowseComp-ZH consists of 289 multi-hop questions spanning\n11 diverse domains. Each question is reverse-engineered from a short,\nobjective, and easily verifiable answer (e.g., a date, number, or proper noun).\nA two-stage quality control protocol is applied to strive for high question\ndifficulty and answer uniqueness. We benchmark over 20 state-of-the-art\nlanguage models and agentic search systems on our proposed BrowseComp-ZH.\nDespite their strong conversational and retrieval capabilities, most models\nstruggle severely: a large number achieve accuracy rates below 10%, and only a\nhandful exceed 20%. Even the best-performing system, OpenAI's DeepResearch,\nreaches just 42.9%. These results demonstrate the considerable difficulty of\nBrowseComp-ZH, where success demands not only effective retrieval strategies,\nbut also sophisticated reasoning and information reconciliation -- capabilities\nthat current models still struggle to master. Our dataset, construction\nguidelines, and benchmark results have been publicly released at\nhttps://github.com/PALIN2018/BrowseComp-ZH."}
{"id": "2501.15877", "pdf": "https://arxiv.org/pdf/2501.15877", "abs": "https://arxiv.org/abs/2501.15877", "authors": ["Ashita Batra", "Mannas Narang", "Neeraj Kumar Sharma", "Pradip K Das"], "title": "Boli: A dataset for understanding stuttering experience and analyzing stuttered speech", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "There is a growing need for diverse, high-quality stuttered speech data,\nparticularly in the context of Indian languages. This paper introduces Project\nBoli, a multi-lingual stuttered speech dataset designed to advance scientific\nunderstanding and technology development for individuals who stutter,\nparticularly in India. The dataset constitutes (a) anonymized metadata (gender,\nage, country, mother tongue) and responses to a questionnaire about how\nstuttering affects their daily lives, (b) captures both read speech (using the\nRainbow Passage) and spontaneous speech (through image description tasks) for\neach participant and (c) includes detailed annotations of five stutter types:\nblocks, prolongations, interjections, sound repetitions and word repetitions.\nWe present a comprehensive analysis of the dataset, including the data\ncollection procedure, experience summarization of people who stutter, severity\nassessment of stuttering events and technical validation of the collected data.\nThe dataset is released as an open access to further speech technology\ndevelopment."}
{"id": "2311.14090", "pdf": "https://arxiv.org/pdf/2311.14090", "abs": "https://arxiv.org/abs/2311.14090", "authors": ["Z. S. Baltaci", "K. Oksuz", "S. Kuzucu", "K. Tezoren", "B. K. Konar", "A. Ozkan", "E. Akbas", "S. Kalkan"], "title": "Class Uncertainty: A Measure to Mitigate Class Imbalance", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Class-wise characteristics of training examples affect the performance of\ndeep classifiers. A well-studied example is when the number of training\nexamples of classes follows a long-tailed distribution, a situation that is\nlikely to yield sub-optimal performance for under-represented classes. This\nclass imbalance problem is conventionally addressed by approaches relying on\nthe class-wise cardinality of training examples, such as data resampling. In\nthis paper, we demonstrate that considering solely the cardinality of classes\ndoes not cover all issues causing class imbalance. To measure class imbalance,\nwe propose \"Class Uncertainty\" as the average predictive uncertainty of the\ntraining examples, and we show that this novel measure captures the differences\nacross classes better than cardinality. We also curate SVCI-20 as a novel\ndataset in which the classes have equal number of training examples but they\ndiffer in terms of their hardness; thereby causing a type of class imbalance\nwhich cannot be addressed by the approaches relying on cardinality. We\nincorporate our \"Class Uncertainty\" measure into a diverse set of ten class\nimbalance mitigation methods to demonstrate its effectiveness on long-tailed\ndatasets as well as on our SVCI-20. Code and datasets will be made available."}
{"id": "2505.00571", "pdf": "https://arxiv.org/pdf/2505.00571", "abs": "https://arxiv.org/abs/2505.00571", "authors": ["Giorgio Spadaccini", "Marjolein Fokkema", "Mark A. van de Wiel"], "title": "Hypothesis-free discovery from epidemiological data by automatic detection and local inference for tree-based nonlinearities and interactions", "categories": ["stat.ML", "cs.LG"], "comment": "Main body: 29 pages, 7 figures; Supplementary material: 39 pages, 14\n  figures", "summary": "In epidemiological settings, Machine Learning (ML) is gaining popularity for\nhypothesis-free discovery of risk (or protective) factors. Although ML is\nstrong at discovering non-linearities and interactions, this power is currently\ncompromised by a lack of reliable inference. Although local measures of feature\neffect can be combined with tree ensembles, uncertainty quantifications for\nthese measures remain only partially available and oftentimes unsatisfactory.\nWe propose RuleSHAP, a framework for using rule-based, hypothesis-free\ndiscovery that combines sparse Bayesian regression, tree ensembles and Shapley\nvalues in a one-step procedure that both detects and tests complex patterns at\nthe individual level. To ease computation, we derive a formula that computes\nmarginal Shapley values more efficiently for our setting. We demonstrate the\nvalidity of our framework on simulated data. To illustrate, we apply our\nmachinery to data from an epidemiological cohort to detect and infer several\neffects for high cholesterol and blood pressure, such as nonlinear interaction\neffects between features like age, sex, ethnicity, BMI and glucose level."}
{"id": "2504.19467", "pdf": "https://arxiv.org/pdf/2504.19467", "abs": "https://arxiv.org/abs/2504.19467", "authors": ["Jiageng Wu", "Bowen Gu", "Ren Zhou", "Kevin Xie", "Doug Snyder", "Yixing Jiang", "Valentina Carducci", "Richard Wyss", "Rishi J Desai", "Emily Alsentzer", "Leo Anthony Celi", "Adam Rodman", "Sebastian Schneeweiss", "Jonathan H. Chen", "Santiago Romero-Brufau", "Kueiyu Joshua Lin", "Jie Yang"], "title": "BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) hold great promise for medical applications and\nare evolving rapidly, with new models being released at an accelerated pace.\nHowever, current evaluations of LLMs in clinical contexts remain limited. Most\nexisting benchmarks rely on medical exam-style questions or PubMed-derived\ntext, failing to capture the complexity of real-world electronic health record\n(EHR) data. Others focus narrowly on specific application scenarios, limiting\ntheir generalizability across broader clinical use. To address this gap, we\npresent BRIDGE, a comprehensive multilingual benchmark comprising 87 tasks\nsourced from real-world clinical data sources across nine languages. We\nsystematically evaluated 52 state-of-the-art LLMs (including DeepSeek-R1,\nGPT-4o, Gemini, and Llama 4) under various inference strategies. With a total\nof 13,572 experiments, our results reveal substantial performance variation\nacross model sizes, languages, natural language processing tasks, and clinical\nspecialties. Notably, we demonstrate that open-source LLMs can achieve\nperformance comparable to proprietary models, while medically fine-tuned LLMs\nbased on older architectures often underperform versus updated general-purpose\nmodels. The BRIDGE and its corresponding leaderboard serve as a foundational\nresource and a unique reference for the development and evaluation of new LLMs\nin real-world clinical text understanding.\n  The BRIDGE leaderboard:\nhttps://huggingface.co/spaces/YLab-Open/BRIDGE-Medical-Leaderboard"}
{"id": "2501.16370", "pdf": "https://arxiv.org/pdf/2501.16370", "abs": "https://arxiv.org/abs/2501.16370", "authors": ["Mahdi Movahedian Moghaddam", "Kourosh Parand", "Saeed Reza Kheradpisheh"], "title": "Advanced Physics-Informed Neural Network with Residuals for Solving Complex Integral Equations", "categories": ["cs.LG", "cs.AI", "cs.NA", "cs.NE", "math.NA", "68T07, 65R20"], "comment": null, "summary": "In this paper, we present the Residual Integral Solver Network (RISN), a\nnovel neural network architecture designed to solve a wide range of integral\nand integro-differential equations, including one-dimensional,\nmulti-dimensional, ordinary and partial integro-differential, systems,\nfractional types, and Helmholtz-type integral equations involving oscillatory\nkernels. RISN integrates residual connections with high-accuracy numerical\nmethods such as Gaussian quadrature and fractional derivative operational\nmatrices, enabling it to achieve higher accuracy and stability than traditional\nPhysics-Informed Neural Networks (PINN). The residual connections help mitigate\nvanishing gradient issues, allowing RISN to handle deeper networks and more\ncomplex kernels, particularly in multi-dimensional problems. Through extensive\nexperiments, we demonstrate that RISN consistently outperforms not only\nclassical PINNs but also advanced variants such as Auxiliary PINN (A-PINN) and\nSelf-Adaptive PINN (SA-PINN), achieving significantly lower Mean Absolute\nErrors (MAE) across various types of equations. These results highlight RISN's\nrobustness and efficiency in solving challenging integral and\nintegro-differential problems, making it a valuable tool for real-world\napplications where traditional methods often struggle."}
{"id": "2409.12002", "pdf": "https://arxiv.org/pdf/2409.12002", "abs": "https://arxiv.org/abs/2409.12002", "authors": ["Aneesh Chavan", "Vaibhav Agrawal", "Vineeth Bhat", "Sarthak Chittawar", "Siddharth Srivastava", "Chetan Arora", "K Madhava Krishna"], "title": "Towards Global Localization using Multi-Modal Object-Instance Re-Identification", "categories": ["cs.RO", "cs.CV", "68T40", "I.2.9; I.2.10"], "comment": "8 pages, 5 figures, 3 tables. Accepted at Advances in Robotics, AIR\n  2025 (Oral)", "summary": "Re-identification (ReID) is a critical challenge in computer vision,\npredominantly studied in the context of pedestrians and vehicles. However,\nrobust object-instance ReID, which has significant implications for tasks such\nas autonomous exploration, long-term perception, and scene understanding,\nremains underexplored. In this work, we address this gap by proposing a novel\ndual-path object-instance re-identification transformer architecture that\nintegrates multimodal RGB and depth information. By leveraging depth data, we\ndemonstrate improvements in ReID across scenes that are cluttered or have\nvarying illumination conditions. Additionally, we develop a ReID-based\nlocalization framework that enables accurate camera localization and pose\nidentification across different viewpoints. We validate our methods using two\ncustom-built RGB-D datasets, as well as multiple sequences from the open-source\nTUM RGB-D datasets. Our approach demonstrates significant improvements in both\nobject instance ReID (mAP of 75.18) and localization accuracy (success rate of\n83% on TUM-RGBD), highlighting the essential role of object ReID in advancing\nrobotic perception. Our models, frameworks, and datasets have been made\npublicly available."}
{"id": "2505.00574", "pdf": "https://arxiv.org/pdf/2505.00574", "abs": "https://arxiv.org/abs/2505.00574", "authors": ["Raffaele Cheula", "Mie Andersen"], "title": "Transition States Energies from Machine Learning: An Application to Reverse Water-Gas Shift on Single-Atom Alloys", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "Obtaining accurate transition state (TS) energies is a bottleneck in\ncomputational screening of complex materials and reaction networks due to the\nhigh cost of TS search methods and first-principles methods such as density\nfunctional theory (DFT). Here we propose a machine learning (ML) model for\npredicting TS energies based on Gaussian process regression with the\nWasserstein Weisfeiler-Lehman graph kernel (WWL-GPR). Applying the model to\npredict adsorption and TS energies for the reverse water-gas shift (RWGS)\nreaction on single-atom alloy (SAA) catalysts, we show that it can\nsignificantly improve the accuracy compared to traditional approaches based on\nscaling relations or ML models without a graph representation. Further\nbenefitting from the low cost of model training, we train an ensemble of\nWWL-GPR models to obtain uncertainties through subsampling of the training data\nand show how these uncertainties propagate to turnover frequency (TOF)\npredictions through the construction of an ensemble of microkinetic models.\nComparing the errors in model-based vs DFT-based TOF predictions, we show that\nthe WWL-GPR model reduces errors by almost an order of magnitude compared to\nscaling relations. This demonstrates the critical impact of accurate energy\npredictions on catalytic activity estimation. Finally, we apply our model to\nscreen new materials, identifying promising catalysts for RWGS. This work\nhighlights the power of combining advanced ML techniques with DFT and\nmicrokinetic modeling for screening catalysts for complex reactions like RWGS,\nproviding a robust framework for future catalyst design."}
{"id": "2504.20946", "pdf": "https://arxiv.org/pdf/2504.20946", "abs": "https://arxiv.org/abs/2504.20946", "authors": ["Tyler McDonald", "Ali Emami"], "title": "Trace-of-Thought Prompting: Investigating Prompt-Based Knowledge Distillation Through Question Decomposition", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Knowledge distillation allows smaller neural networks to emulate the\nperformance of larger, teacher models with reduced computational demands.\nTraditional methods for Large Language Models (LLMs) often necessitate\nextensive fine-tuning, which limits their accessibility. To address this, we\nintroduce Trace-of-Thought Prompting, a novel framework designed to distill\ncritical reasoning capabilities from high-resource teacher models (over 8\nbillion parameters) to low-resource student models (up to 8 billion\nparameters). This approach leverages problem decomposition to enhance\ninterpretability and facilitate human-in-the-loop interventions. Empirical\nevaluations on the GSM8K and MATH datasets show that student models achieve\naccuracy gains of up to 113% on GSM8K and 21% on MATH, with significant\nimprovements particularly notable in smaller models like Llama 2 and Zephyr.\nOur results suggest a promising pathway for open-source, low-resource models to\neventually serve both as both students and teachers, potentially reducing our\nreliance on high-resource, proprietary models."}
{"id": "2501.17982", "pdf": "https://arxiv.org/pdf/2501.17982", "abs": "https://arxiv.org/abs/2501.17982", "authors": ["Erick Fuentes", "Jared Strader", "Ethan Fahnestock", "Nicholas Roy"], "title": "Belief Roadmaps with Uncertain Landmark Evanescence", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "We would like a robot to navigate to a goal location while minimizing state\nuncertainty. To aid the robot in this endeavor, maps provide a prior belief\nover the location of objects and regions of interest. To localize itself within\nthe map, a robot identifies mapped landmarks using its sensors. However, as the\ntime between map creation and robot deployment increases, portions of the map\ncan become stale, and landmarks, once believed to be permanent, may disappear.\nWe refer to the propensity of a landmark to disappear as landmark evanescence.\nReasoning about landmark evanescence during path planning, and the associated\nimpact on localization accuracy, requires analyzing the presence or absence of\neach landmark, leading to an exponential number of possible outcomes of a given\nmotion plan. To address this complexity, we develop BRULE, an extension of the\nBelief Roadmap. During planning, we replace the belief over future robot poses\nwith a Gaussian mixture which is able to capture the effects of landmark\nevanescence. Furthermore, we show that belief updates can be made efficient,\nand that maintaining a random subset of mixture components is sufficient to\nfind high quality solutions. We demonstrate performance in simulated and\nreal-world experiments. Software is available at https://bit.ly/BRULE."}
{"id": "2409.16663", "pdf": "https://arxiv.org/pdf/2409.16663", "abs": "https://arxiv.org/abs/2409.16663", "authors": ["Alexander Popov", "Alperen Degirmenci", "David Wehr", "Shashank Hegde", "Ryan Oldja", "Alexey Kamenev", "Bertrand Douillard", "David Nistér", "Urs Muller", "Ruchi Bhargava", "Stan Birchfield", "Nikolai Smolyanskiy"], "title": "Mitigating Covariate Shift in Imitation Learning for Autonomous Vehicles Using Latent Space Generative World Models", "categories": ["cs.RO", "cs.CV", "cs.LG", "cs.SY", "eess.SY", "68T40 (Primary) 68T05, 68T45 (Secondary)", "I.2.9; I.2.6; I.2.10; I.6"], "comment": "8 pages, 6 figures, updated in March 2025, original published in\n  September 2024, for ICRA 2025 submission, for associated video file, see\n  https://youtu.be/7m3bXzlVQvU", "summary": "We propose the use of latent space generative world models to address the\ncovariate shift problem in autonomous driving. A world model is a neural\nnetwork capable of predicting an agent's next state given past states and\nactions. By leveraging a world model during training, the driving policy\neffectively mitigates covariate shift without requiring an excessive amount of\ntraining data. During end-to-end training, our policy learns how to recover\nfrom errors by aligning with states observed in human demonstrations, so that\nat runtime it can recover from perturbations outside the training distribution.\nAdditionally, we introduce a novel transformer-based perception encoder that\nemploys multi-view cross-attention and a learned scene query. We present\nqualitative and quantitative results, demonstrating significant improvements\nupon prior state of the art in closed-loop testing in the CARLA simulator, as\nwell as showing the ability to handle perturbations in both CARLA and NVIDIA's\nDRIVE Sim."}
{"id": "2505.00586", "pdf": "https://arxiv.org/pdf/2505.00586", "abs": "https://arxiv.org/abs/2505.00586", "authors": ["Jiarong Wei", "Niclas Vödisch", "Anna Rehr", "Christian Feist", "Abhinav Valada"], "title": "ParkDiffusion: Heterogeneous Multi-Agent Multi-Modal Trajectory Prediction for Automated Parking using Diffusion Models", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Automated parking is a critical feature of Advanced Driver Assistance Systems\n(ADAS), where accurate trajectory prediction is essential to bridge perception\nand planning modules. Despite its significance, research in this domain remains\nrelatively limited, with most existing studies concentrating on single-modal\ntrajectory prediction of vehicles. In this work, we propose ParkDiffusion, a\nnovel approach that predicts the trajectories of both vehicles and pedestrians\nin automated parking scenarios. ParkDiffusion employs diffusion models to\ncapture the inherent uncertainty and multi-modality of future trajectories,\nincorporating several key innovations. First, we propose a dual map encoder\nthat processes soft semantic cues and hard geometric constraints using a\ntwo-step cross-attention mechanism. Second, we introduce an adaptive agent type\nembedding module, which dynamically conditions the prediction process on the\ndistinct characteristics of vehicles and pedestrians. Third, to ensure\nkinematic feasibility, our model outputs control signals that are subsequently\nused within a kinematic framework to generate physically feasible trajectories.\nWe evaluate ParkDiffusion on the Dragon Lake Parking (DLP) dataset and the\nIntersections Drone (inD) dataset. Our work establishes a new baseline for\nheterogeneous trajectory prediction in parking scenarios, outperforming\nexisting methods by a considerable margin."}
{"id": "2504.21012", "pdf": "https://arxiv.org/pdf/2504.21012", "abs": "https://arxiv.org/abs/2504.21012", "authors": ["Makoto Sato"], "title": "Waking Up an AI: A Quantitative Framework for Prompt-Induced Phase Transition in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "What underlies intuitive human thinking? One approach to this question is to\ncompare the cognitive dynamics of humans and large language models (LLMs).\nHowever, such a comparison requires a method to quantitatively analyze AI\ncognitive behavior under controlled conditions. While anecdotal observations\nsuggest that certain prompts can dramatically change LLM behavior, these\nobservations have remained largely qualitative. Here, we propose a two-part\nframework to investigate this phenomenon: a Transition-Inducing Prompt (TIP)\nthat triggers a rapid shift in LLM responsiveness, and a Transition Quantifying\nPrompt (TQP) that evaluates this change using a separate LLM. Through\ncontrolled experiments, we examined how LLMs react to prompts embedding two\nsemantically distant concepts (e.g., mathematical aperiodicity and traditional\ncrafts)-either fused together or presented separately-by changing their\nlinguistic quality and affective tone. Whereas humans tend to experience\nheightened engagement when such concepts are meaningfully blended producing a\nnovel concept-a form of conceptual fusion-current LLMs showed no significant\ndifference in responsiveness between semantically fused and non-fused prompts.\nThis suggests that LLMs may not yet replicate the conceptual integration\nprocesses seen in human intuition. Our method enables fine-grained,\nreproducible measurement of cognitive responsiveness, and may help illuminate\nkey differences in how intuition and conceptual leaps emerge in artificial\nversus human minds."}
{"id": "2501.18768", "pdf": "https://arxiv.org/pdf/2501.18768", "abs": "https://arxiv.org/abs/2501.18768", "authors": ["Michael S. Yao", "James C. Gee", "Osbert Bastani"], "title": "Diversity By Design: Leveraging Distribution Matching for Offline Model-Based Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "52 pages, Accepted to ICML 2025", "summary": "The goal of offline model-based optimization (MBO) is to propose new designs\nthat maximize a reward function given only an offline dataset. However, an\nimportant desiderata is to also propose a diverse set of final candidates that\ncapture many optimal and near-optimal design configurations. We propose\nDiversity in Adversarial Model-based Optimization (DynAMO) as a novel method to\nintroduce design diversity as an explicit objective into any MBO problem. Our\nkey insight is to formulate diversity as a distribution matching problem where\nthe distribution of generated designs captures the inherent diversity contained\nwithin the offline dataset. Extensive experiments spanning multiple scientific\ndomains show that DynAMO can be used with common optimization methods to\nsignificantly improve the diversity of proposed designs while still discovering\nhigh-quality candidates."}
{"id": "2411.12286", "pdf": "https://arxiv.org/pdf/2411.12286", "abs": "https://arxiv.org/abs/2411.12286", "authors": ["Teli Ma", "Zifan Wang", "Jiaming Zhou", "Mengmeng Wang", "Junwei Liang"], "title": "GLOVER: Generalizable Open-Vocabulary Affordance Reasoning for Task-Oriented Grasping", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Inferring affordable (i.e., graspable) parts of arbitrary objects based on\nhuman specifications is essential for robots advancing toward open-vocabulary\nmanipulation. Current grasp planners, however, are hindered by limited\nvision-language comprehension and time-consuming 3D radiance modeling,\nrestricting real-time, open-vocabulary interactions with objects. To address\nthese limitations, we propose GLOVER, a unified Generalizable Open-Vocabulary\nAffordance Reasoning framework, which fine-tunes the Large Language Models\n(LLMs) to predict the visual affordance of graspable object parts within RGB\nfeature space. We compile a dataset of over 10,000 images from human-object\ninteractions, annotated with unified visual and linguistic affordance labels,\nto enable multi-modal fine-tuning. GLOVER inherits world knowledge and\ncommon-sense reasoning from LLMs, facilitating more fine-grained object\nunderstanding and sophisticated tool-use reasoning. To enable effective\nreal-world deployment, we present Affordance-Aware Grasping Estimation (AGE), a\nnon-parametric grasp planner that aligns the gripper pose with a superquadric\nsurface derived from affordance data. In evaluations across 30 table-top\nreal-world scenes, GLOVER achieves success rates of 86.0% in part\nidentification and 76.3% in grasping, with speeds approximately 29 times faster\nin affordance reasoning and 40 times faster in grasping pose estimation than\nthe previous state-of-the-art. We also validate the generalization across\nembodiments, showing effectiveness in humanoid robots with dexterous hands."}
{"id": "2505.00625", "pdf": "https://arxiv.org/pdf/2505.00625", "abs": "https://arxiv.org/abs/2505.00625", "authors": ["Liu Junchi", "Tang Ying", "Tretiak Sergei", "Duan Wenhui", "Zhou Liujiang"], "title": "SA-GAT-SR: Self-Adaptable Graph Attention Networks with Symbolic Regression for high-fidelity material property prediction", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "Recent advances in machine learning have demonstrated an enormous utility of\ndeep learning approaches, particularly Graph Neural Networks (GNNs) for\nmaterials science. These methods have emerged as powerful tools for\nhigh-throughput prediction of material properties, offering a compelling\nenhancement and alternative to traditional first-principles calculations. While\nthe community has predominantly focused on developing increasingly complex and\nuniversal models to enhance predictive accuracy, such approaches often lack\nphysical interpretability and insights into materials behavior. Here, we\nintroduce a novel computational paradigm, Self-Adaptable Graph Attention\nNetworks integrated with Symbolic Regression (SA-GAT-SR), that synergistically\ncombines the predictive capability of GNNs with the interpretative power of\nsymbolic regression. Our framework employs a self-adaptable encoding algorithm\nthat automatically identifies and adjust attention weights so as to screen\ncritical features from an expansive 180-dimensional feature space while\nmaintaining O(n) computational scaling. The integrated SR module subsequently\ndistills these features into compact analytical expressions that explicitly\nreveal quantum-mechanically meaningful relationships, achieving 23 times\nacceleration compared to conventional SR implementations that heavily rely on\nfirst principle calculations-derived features as input. This work suggests a\nnew framework in computational materials science, bridging the gap between\npredictive accuracy and physical interpretability, offering valuable physical\ninsights into material behavior."}
{"id": "2504.21800", "pdf": "https://arxiv.org/pdf/2504.21800", "abs": "https://arxiv.org/abs/2504.21800", "authors": ["Suhas BN", "Dominik Mattioli", "Saeed Abdullah", "Rosa I. Arriaga", "Chris W. Wiese", "Andrew M. Sherrill"], "title": "How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in Prolonged Exposure Dialogues", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "68T50", "I.2.7; H.3.1"], "comment": "11 pages, 5 tables", "summary": "The growing adoption of synthetic data in healthcare is driven by privacy\nconcerns, limited access to real-world data, and the high cost of annotation.\nThis work explores the use of synthetic Prolonged Exposure (PE) therapeutic\nconversations for Post-Traumatic Stress Disorder (PTSD) as a scalable\nalternative for training and evaluating clinical models. We systematically\ncompare real and synthetic dialogues using linguistic, structural, and\nprotocol-specific metrics, including turn-taking patterns and treatment\nfidelity. We also introduce and evaluate PE-specific metrics derived from\nlinguistic analysis and semantic modeling, offering a novel framework for\nassessing clinical fidelity beyond surface fluency. Our findings show that\nalthough synthetic data holds promise for mitigating data scarcity and\nprotecting patient privacy, it can struggle to capture the subtle dynamics of\ntherapeutic interactions. Synthetic therapy dialogues closely match structural\nfeatures of real-world conversations (e.g., speaker switch ratio: 0.98 vs.\n0.99); however, they may not adequately reflect key fidelity markers (e.g.,\ndistress monitoring). We highlight gaps in existing evaluation frameworks and\nadvocate for fidelity-aware metrics that go beyond surface fluency to uncover\nclinically significant failures. Our findings clarify where synthetic data can\neffectively complement real-world datasets -- and where critical limitations\nremain."}
{"id": "2502.00040", "pdf": "https://arxiv.org/pdf/2502.00040", "abs": "https://arxiv.org/abs/2502.00040", "authors": ["Thomas Lautenbacher", "Ali Rajaei", "Davide Barbieri", "Jan Viebahn", "Jochen L. Cremer"], "title": "Multi-Objective Reinforcement Learning for Power Grid Topology Control", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Transmission grid congestion increases as the electrification of various\nsectors requires transmitting more power. Topology control, through substation\nreconfiguration, can reduce congestion but its potential remains\nunder-exploited in operations. A challenge is modeling the topology control\nproblem to align well with the objectives and constraints of operators.\nAddressing this challenge, this paper investigates the application of\nmulti-objective reinforcement learning (MORL) to integrate multiple conflicting\nobjectives for power grid topology control. We develop a MORL approach using\ndeep optimistic linear support (DOL) and multi-objective proximal policy\noptimization (MOPPO) to generate a set of Pareto-optimal policies that balance\nobjectives such as minimizing line loading, topological deviation, and\nswitching frequency. Initial case studies show that the MORL approach can\nprovide valuable insights into objective trade-offs and improve Pareto front\napproximation compared to a random search baseline. The generated\nmulti-objective RL policies are 30% more successful in preventing grid failure\nunder contingencies and 20% more effective when training budget is reduced -\ncompared to the common single objective RL policy."}
{"id": "2411.14412", "pdf": "https://arxiv.org/pdf/2411.14412", "abs": "https://arxiv.org/abs/2411.14412", "authors": ["Satwik Kundu", "Swaroop Ghosh"], "title": "Adversarial Data Poisoning Attacks on Quantum Machine Learning in the NISQ Era", "categories": ["quant-ph", "cs.CR", "cs.CV"], "comment": null, "summary": "With the growing interest in Quantum Machine Learning (QML) and the\nincreasing availability of quantum computers through cloud providers,\naddressing the potential security risks associated with QML has become an\nurgent priority. One key concern in the QML domain is the threat of data\npoisoning attacks in the current quantum cloud setting. Adversarial access to\ntraining data could severely compromise the integrity and availability of QML\nmodels. Classical data poisoning techniques require significant knowledge and\ntraining to generate poisoned data, and lack noise resilience, making them\nineffective for QML models in the Noisy Intermediate Scale Quantum (NISQ) era.\nIn this work, we first propose a simple yet effective technique to measure\nintra-class encoder state similarity (ESS) by analyzing the outputs of encoding\ncircuits. Leveraging this approach, we introduce a \\underline{Qu}antum\n\\underline{I}ndiscriminate \\underline{D}ata Poisoning attack, QUID. Through\nextensive experiments conducted in both noiseless and noisy environments (e.g.,\nIBM\\_Brisbane's noise), across various architectures and datasets, QUID\nachieves up to $92\\%$ accuracy degradation in model performance compared to\nbaseline models and up to $75\\%$ accuracy degradation compared to random\nlabel-flipping. We also tested QUID against state-of-the-art classical\ndefenses, with accuracy degradation still exceeding $50\\%$, demonstrating its\neffectiveness. This work represents the first attempt to reevaluate data\npoisoning attacks in the context of QML."}
{"id": "2505.00631", "pdf": "https://arxiv.org/pdf/2505.00631", "abs": "https://arxiv.org/abs/2505.00631", "authors": ["Yi Yang", "Yinghui Huang", "Xiangyu Chang"], "title": "Bayes-Optimal Fair Classification with Multiple Sensitive Features", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Existing theoretical work on Bayes-optimal fair classifiers usually considers\na single (binary) sensitive feature. In practice, individuals are often defined\nby multiple sensitive features. In this paper, we characterize the\nBayes-optimal fair classifier for multiple sensitive features under general\napproximate fairness measures, including mean difference and mean ratio. We\nshow that these approximate measures for existing group fairness notions,\nincluding Demographic Parity, Equal Opportunity, Predictive Equality, and\nAccuracy Parity, are linear transformations of selection rates for specific\ngroups defined by both labels and sensitive features. We then characterize that\nBayes-optimal fair classifiers for multiple sensitive features become\ninstance-dependent thresholding rules that rely on a weighted sum of these\ngroup membership probabilities. Our framework applies to both attribute-aware\nand attribute-blind settings and can accommodate composite fairness notions\nlike Equalized Odds. Building on this, we propose two practical algorithms for\nBayes-optimal fair classification via in-processing and post-processing. We\nshow empirically that our methods compare favorably to existing methods."}
{"id": "2411.02790", "pdf": "https://arxiv.org/pdf/2411.02790", "abs": "https://arxiv.org/abs/2411.02790", "authors": ["Sheshera Mysore", "Garima Dhanania", "Kishor Patil", "Surya Kallumadi", "Andrew McCallum", "Hamed Zamani"], "title": "Bridging Personalization and Control in Scientific Personalized Search", "categories": ["cs.IR", "cs.CL"], "comment": "SIGIR 2025 paper", "summary": "Personalized search is a problem where models benefit from learning user\npreferences from per-user historical interaction data. The inferred preferences\nenable personalized ranking models to improve the relevance of documents for\nusers. However, personalization is also seen as opaque in its use of historical\ninteractions and is not amenable to users' control. Further, personalization\nlimits the diversity of information users are exposed to. While search results\nmay be automatically diversified this does little to address the lack of\ncontrol over personalization. In response, we introduce a model for\npersonalized search that enables users to control personalized rankings\nproactively. Our model, CtrlCE, is a novel cross-encoder model augmented with\nan editable memory built from users' historical interactions. The editable\nmemory allows cross-encoders to be personalized efficiently and enables users\nto control personalized ranking. Next, because all queries do not require\npersonalization, we introduce a calibrated mixing model which determines when\npersonalization is necessary. This enables users to control personalization via\ntheir editable memory only when necessary. To thoroughly evaluate CtrlCE, we\ndemonstrate its empirical performance in four domains of science, its ability\nto selectively request user control in a calibration evaluation of the mixing\nmodel, and the control provided by its editable memory in a user study."}
{"id": "2502.10689", "pdf": "https://arxiv.org/pdf/2502.10689", "abs": "https://arxiv.org/abs/2502.10689", "authors": ["Leisheng Yu", "Yanxiao Cai", "Minxing Zhang", "Xia Hu"], "title": "Self-Explaining Hypergraph Neural Networks for Diagnosis Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The burgeoning volume of electronic health records (EHRs) has enabled deep\nlearning models to excel in predictive healthcare. However, for high-stakes\napplications such as diagnosis prediction, model interpretability remains\nparamount. Existing deep learning diagnosis prediction models with intrinsic\ninterpretability often assign attention weights to every past diagnosis or\nhospital visit, providing explanations lacking flexibility and succinctness. In\nthis paper, we introduce SHy, a self-explaining hypergraph neural network\nmodel, designed to offer personalized, concise and faithful explanations that\nallow for interventions from clinical experts. By modeling each patient as a\nunique hypergraph and employing a message-passing mechanism, SHy captures\nhigher-order disease interactions and extracts distinct temporal phenotypes as\npersonalized explanations. It also addresses the incompleteness of the EHR data\nby accounting for essential false negatives in the original diagnosis record. A\nqualitative case study and extensive quantitative evaluations on two real-world\nEHR datasets demonstrate the superior predictive performance and\ninterpretability of SHy over existing state-of-the-art models."}
{"id": "2502.18137", "pdf": "https://arxiv.org/pdf/2502.18137", "abs": "https://arxiv.org/abs/2502.18137", "authors": ["Jintao Zhang", "Chendong Xiang", "Haofeng Huang", "Jia Wei", "Haocheng Xi", "Jun Zhu", "Jianfei Chen"], "title": "SpargeAttn: Accurate Sparse Attention Accelerating Any Model Inference", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.PF"], "comment": null, "summary": "An efficient attention implementation is essential for large models due to\nits quadratic time complexity. Fortunately, attention commonly exhibits\nsparsity, i.e., many values in the attention map are near zero, allowing for\nthe omission of corresponding computations. Many studies have utilized the\nsparse pattern to accelerate attention. However, most existing works focus on\noptimizing attention within specific models by exploiting certain sparse\npatterns of the attention map. A universal sparse attention that guarantees\nboth the speedup and end-to-end performance of diverse models remains elusive.\nIn this paper, we propose SpargeAttn, a universal sparse and quantized\nattention for any model. Our method uses a two-stage online filter: in the\nfirst stage, we rapidly and accurately predict the attention map, enabling the\nskip of some matrix multiplications in attention. In the second stage, we\ndesign an online softmax-aware filter that incurs no extra overhead and further\nskips some matrix multiplications. Experiments show that our method\nsignificantly accelerates diverse models, including language, image, and video\ngeneration, without sacrificing end-to-end metrics. The codes are available at\nhttps://github.com/thu-ml/SpargeAttn."}
{"id": "2501.18265", "pdf": "https://arxiv.org/pdf/2501.18265", "abs": "https://arxiv.org/abs/2501.18265", "authors": ["Kevin Roitero", "Dustin Wright", "Michael Soprano", "Isabelle Augenstein", "Stefano Mizzaro"], "title": "Efficiency and Effectiveness of LLM-Based Summarization of Evidence in Crowdsourced Fact-Checking", "categories": ["cs.IR", "cs.CL", "cs.HC"], "comment": "19 pages; 7 figures; 5 tables", "summary": "Evaluating the truthfulness of online content is critical for combating\nmisinformation. This study examines the efficiency and effectiveness of\ncrowdsourced truthfulness assessments through a comparative analysis of two\napproaches: one involving full-length webpages as evidence for each claim, and\nanother using summaries for each evidence document generated with a large\nlanguage model. Using an A/B testing setting, we engage a diverse pool of\nparticipants tasked with evaluating the truthfulness of statements under these\nconditions. Our analysis explores both the quality of assessments and the\nbehavioral patterns of participants. The results reveal that relying on\nsummarized evidence offers comparable accuracy and error metrics to the\nStandard modality while significantly improving efficiency. Workers in the\nSummary setting complete a significantly higher number of assessments, reducing\ntask duration and costs. Additionally, the Summary modality maximizes internal\nagreement and maintains consistent reliance on and perceived usefulness of\nevidence, demonstrating its potential to streamline large-scale truthfulness\nevaluations."}
{"id": "2502.11141", "pdf": "https://arxiv.org/pdf/2502.11141", "abs": "https://arxiv.org/abs/2502.11141", "authors": ["Lukas Kuhn", "Sari Saba-Sadiya", "Gemma Roig"], "title": "Cognitive Neural Architecture Search Reveals Hierarchical Entailment", "categories": ["cs.NE", "cs.AI", "q-bio.QM"], "comment": null, "summary": "Recent research has suggested that the brain is more shallow than previously\nthought, challenging the traditionally assumed hierarchical structure of the\nventral visual pathway. Here, we demonstrate that optimizing convolutional\nnetwork architectures for brain-alignment via evolutionary neural architecture\nsearch results in models with clear representational hierarchies. Despite\nhaving random weights, the identified models achieve brain-alignment scores\nsurpassing even those of pretrained classification models - as measured by both\nregression and representational similarity analysis. Furthermore, through\ntraditional supervised training, architectures optimized for alignment with\nlate ventral regions become competitive classification models. These findings\nsuggest that hierarchical structure is a fundamental mechanism of primate\nvisual processing. Finally, this work demonstrates the potential of neural\narchitecture search as a framework for computational cognitive neuroscience\nresearch that could reduce the field's reliance on manually designed\nconvolutional networks."}
{"id": "2503.21510", "pdf": "https://arxiv.org/pdf/2503.21510", "abs": "https://arxiv.org/abs/2503.21510", "authors": ["Samuel Bilson", "Anna Pustogvar"], "title": "Uncertainty-aware Bayesian machine learning modelling of land cover classification", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": "31 pages, 10 figures", "summary": "Land cover classification involves the production of land cover maps, which\ndetermine the type of land through remote sensing imagery. Over recent years,\nsuch classification is being performed by machine learning classification\nmodels, which can give highly accurate predictions on land cover per pixel\nusing large quantities of input training data. However, such models do not\ncurrently take account of input measurement uncertainty, which is vital for\ntraceability in metrology. In this work we propose a Bayesian classification\nframework using generative modelling to take account of input measurement\nuncertainty. We take the specific case of Bayesian quadratic discriminant\nanalysis, and apply it to land cover datasets from Copernicus Sentinel-2 in\n2020 and 2021. We benchmark the performance of the model against more popular\nclassification models used in land cover maps such as random forests and neural\nnetworks. We find that such Bayesian models are more trustworthy, in the sense\nthat they are more interpretable, explicitly model the input measurement\nuncertainty, and maintain predictive performance of class probability outputs\nacross datasets of different years and sizes, whilst also being computationally\nefficient."}
{"id": "2211.09619", "pdf": "https://arxiv.org/pdf/2211.09619", "abs": "https://arxiv.org/abs/2211.09619", "authors": ["Elad Hazan", "Karan Singh"], "title": "Introduction to Online Control", "categories": ["cs.LG", "cs.RO", "cs.SY", "eess.SY", "math.OC", "stat.ML"], "comment": "Draft; comments/suggestions welcome at\n  nonstochastic.control@gmail.com", "summary": "This text presents an introduction to an emerging paradigm in control of\ndynamical systems and differentiable reinforcement learning called online\nnonstochastic control. The new approach applies techniques from online convex\noptimization and convex relaxations to obtain new methods with provable\nguarantees for classical settings in optimal and robust control.\n  The primary distinction between online nonstochastic control and other\nframeworks is the objective. In optimal control, robust control, and other\ncontrol methodologies that assume stochastic noise, the goal is to perform\ncomparably to an offline optimal strategy. In online nonstochastic control,\nboth the cost functions as well as the perturbations from the assumed dynamical\nmodel are chosen by an adversary. Thus the optimal policy is not defined a\npriori. Rather, the target is to attain low regret against the best policy in\nhindsight from a benchmark class of policies.\n  This objective suggests the use of the decision making framework of online\nconvex optimization as an algorithmic methodology. The resulting methods are\nbased on iterative mathematical optimization algorithms, and are accompanied by\nfinite-time regret and computational complexity guarantees."}
{"id": "2504.05520", "pdf": "https://arxiv.org/pdf/2504.05520", "abs": "https://arxiv.org/abs/2504.05520", "authors": ["Taiwei Shi", "Yiyang Wu", "Linxin Song", "Tianyi Zhou", "Jieyu Zhao"], "title": "Efficient Reinforcement Finetuning via Adaptive Curriculum Learning", "categories": ["cs.LG", "cs.CL"], "comment": "25 pages, 7 figures, 6 tables", "summary": "Reinforcement finetuning (RFT) has shown great potential for enhancing the\nmathematical reasoning capabilities of large language models (LLMs), but it is\noften sample- and compute-inefficient, requiring extensive training. In this\nwork, we introduce AdaRFT (Adaptive Curriculum Reinforcement Finetuning), a\nmethod that significantly improves both the efficiency and final accuracy of\nRFT through adaptive curriculum learning. AdaRFT dynamically adjusts the\ndifficulty of training problems based on the model's recent reward signals,\nensuring that the model consistently trains on tasks that are challenging but\nsolvable. This adaptive sampling strategy accelerates learning by maintaining\nan optimal difficulty range, avoiding wasted computation on problems that are\ntoo easy or too hard. AdaRFT requires only a lightweight extension to standard\nRFT algorithms like Proximal Policy Optimization (PPO), without modifying the\nreward function or model architecture. Experiments on competition-level math\ndatasets-including AMC, AIME, and IMO-style problems-demonstrate that AdaRFT\nsignificantly improves both training efficiency and reasoning performance. We\nevaluate AdaRFT across multiple data distributions and model sizes, showing\nthat it reduces training time by up to 2x and improves accuracy by a\nconsiderable margin, offering a more scalable and effective RFT framework."}
{"id": "2502.13406", "pdf": "https://arxiv.org/pdf/2502.13406", "abs": "https://arxiv.org/abs/2502.13406", "authors": ["Vince Kurtz", "Joel W. Burdick"], "title": "Generative Predictive Control: Flow Matching Policies for Dynamic and Difficult-to-Demonstrate Tasks", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Generative control policies have recently unlocked major progress in\nrobotics. These methods produce action sequences via diffusion or flow\nmatching, with training data provided by demonstrations. But existing methods\ncome with two key limitations: they require expert demonstrations, which can be\ndifficult to obtain, and they are limited to relatively slow, quasi-static\ntasks. In this paper, we leverage a tight connection between sampling-based\npredictive control and generative modeling to address each of these issues. In\nparticular, we introduce generative predictive control, a supervised learning\nframework for tasks with fast dynamics that are easy to simulate but difficult\nto demonstrate. We then show how trained flow-matching policies can be\nwarm-started at inference time, maintaining temporal consistency and enabling\nhigh-frequency feedback. We believe that generative predictive control offers a\ncomplementary approach to existing behavior cloning methods, and hope that it\npaves the way toward generalist policies that extend beyond quasi-static\ndemonstration-oriented tasks."}
{"id": "2504.04318", "pdf": "https://arxiv.org/pdf/2504.04318", "abs": "https://arxiv.org/abs/2504.04318", "authors": ["Mehmet Can Yavuz", "Berrin Yanikoglu"], "title": "Variational Self-Supervised Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We present Variational Self-Supervised Learning (VSSL), a novel framework\nthat combines variational inference with self-supervised learning to enable\nefficient, decoder-free representation learning. Unlike traditional VAEs that\nrely on input reconstruction via a decoder, VSSL symmetrically couples two\nencoders with Gaussian outputs. A momentum-updated teacher network defines a\ndynamic, data-dependent prior, while the student encoder produces an\napproximate posterior from augmented views. The reconstruction term in the ELBO\nis replaced with a cross-view denoising objective, preserving the analytical\ntractability of Gaussian KL divergence. We further introduce cosine-based\nformulations of KL and log-likelihood terms to enhance semantic alignment in\nhigh-dimensional latent spaces. Experiments on CIFAR-10, CIFAR-100, and\nImageNet-100 show that VSSL achieves competitive or superior performance to\nleading self-supervised methods, including BYOL and MoCo V3. VSSL offers a\nscalable, probabilistically grounded approach to learning transferable\nrepresentations without generative reconstruction, bridging the gap between\nvariational modeling and modern self-supervised techniques."}
{"id": "2301.13565", "pdf": "https://arxiv.org/pdf/2301.13565", "abs": "https://arxiv.org/abs/2301.13565", "authors": ["Shixiong Wang", "Haowei Wang", "Xinke Li", "Jean Honorio"], "title": "Learning Against Distributional Uncertainty: On the Trade-off Between Robustness and Specificity", "categories": ["cs.LG", "stat.ML", "62F35, 62G35, 62C12"], "comment": "Supplementary materials (i.e., the proofs to Theorems 1, 2, 3, and 5)\n  are appended at the end of the main body of the paper", "summary": "Trustworthy machine learning aims at combating distributional uncertainties\nin training data distributions compared to population distributions. Typical\ntreatment frameworks include the Bayesian approach, (min-max) distributionally\nrobust optimization (DRO), and regularization. However, three issues have to be\nraised: 1) the prior distribution in the Bayesian method and the regularizer in\nthe regularization method are difficult to specify; 2) the DRO method tends to\nbe overly conservative; 3) all the three methods are biased estimators of the\ntrue optimal cost. This paper studies a new framework that unifies the three\napproaches and addresses the three challenges above. The asymptotic properties\n(e.g., consistencies and asymptotic normalities), non-asymptotic properties\n(e.g., generalization bounds and unbiasedness), and solution methods of the\nproposed model are studied. The new model reveals the trade-off between the\nrobustness to the unseen data and the specificity to the training data.\nExperiments on various real-world tasks validate the superiority of the\nproposed learning framework."}
{"id": "2503.04767", "pdf": "https://arxiv.org/pdf/2503.04767", "abs": "https://arxiv.org/abs/2503.04767", "authors": ["Penny A. Barr", "Sohel M. Imroz"], "title": "A cross-regional review of AI safety regulations in the commercial aviation", "categories": ["cs.CY", "cs.AI"], "comment": "Identified errors in in-text citations and references sections", "summary": "In this paper we examine the existing artificial intelligence (AI) policy\ndocuments in aviation for the following three regions: the United States,\nEuropean Union, and China. The aviation industry has always been a first mover\nin adopting technological advancements. This early adoption offers valuable\ninsights because of its stringent regulations and safety-critical procedures.\nAs a result, the aviation industry provides an optimal platform to counter AI\nvulnerabilities through its tight regulations, standardization processes, and\ncertification of new technologies. Keywords: AI in aviation; aviation safety;\nstandardization; certifiable AI; regulations"}
{"id": "2504.05304", "pdf": "https://arxiv.org/pdf/2504.05304", "abs": "https://arxiv.org/abs/2504.05304", "authors": ["Hansheng Chen", "Kai Zhang", "Hao Tan", "Zexiang Xu", "Fujun Luan", "Leonidas Guibas", "Gordon Wetzstein", "Sai Bi"], "title": "Gaussian Mixture Flow Matching Models", "categories": ["cs.LG", "cs.CV"], "comment": "ICML 2025. Code: https://github.com/Lakonik/GMFlow", "summary": "Diffusion models approximate the denoising distribution as a Gaussian and\npredict its mean, whereas flow matching models reparameterize the Gaussian mean\nas flow velocity. However, they underperform in few-step sampling due to\ndiscretization error and tend to produce over-saturated colors under\nclassifier-free guidance (CFG). To address these limitations, we propose a\nnovel Gaussian mixture flow matching (GMFlow) model: instead of predicting the\nmean, GMFlow predicts dynamic Gaussian mixture (GM) parameters to capture a\nmulti-modal flow velocity distribution, which can be learned with a KL\ndivergence loss. We demonstrate that GMFlow generalizes previous diffusion and\nflow matching models where a single Gaussian is learned with an $L_2$ denoising\nloss. For inference, we derive GM-SDE/ODE solvers that leverage analytic\ndenoising distributions and velocity fields for precise few-step sampling.\nFurthermore, we introduce a novel probabilistic guidance scheme that mitigates\nthe over-saturation issues of CFG and improves image generation quality.\nExtensive experiments demonstrate that GMFlow consistently outperforms flow\nmatching baselines in generation quality, achieving a Precision of 0.942 with\nonly 6 sampling steps on ImageNet 256$\\times$256."}
{"id": "2402.13393", "pdf": "https://arxiv.org/pdf/2402.13393", "abs": "https://arxiv.org/abs/2402.13393", "authors": ["Kaiqi Jiang", "Wenzhe Fan", "Mao Li", "Xinhua Zhang"], "title": "Fairness Risks for Group-conditionally Missing Demographics", "categories": ["cs.LG", "cs.CY"], "comment": "Accepted to AISTATS 2025", "summary": "Fairness-aware classification models have gained increasing attention in\nrecent years as concerns grow on discrimination against some demographic\ngroups. Most existing models require full knowledge of the sensitive features,\nwhich can be impractical due to privacy, legal issues, and an individual's fear\nof discrimination. The key challenge we will address is the group dependency of\nthe unavailability, e.g., people of some age range may be more reluctant to\nreveal their age. Our solution augments general fairness risks with\nprobabilistic imputations of the sensitive features, while jointly learning the\ngroup-conditionally missing probabilities in a variational auto-encoder. Our\nmodel is demonstrated effective on both image and tabular datasets, achieving\nan improved balance between accuracy and fairness."}
{"id": "2503.16248", "pdf": "https://arxiv.org/pdf/2503.16248", "abs": "https://arxiv.org/abs/2503.16248", "authors": ["Atharv Singh Patlan", "Peiyao Sheng", "S. Ashwin Hebbar", "Prateek Mittal", "Pramod Viswanath"], "title": "Real AI Agents with Fake Memories: Fatal Context Manipulation Attacks on Web3 Agents", "categories": ["cs.CR", "cs.AI", "I.2.7"], "comment": "29 pages, 21 figures", "summary": "The integration of AI agents with Web3 ecosystems harnesses their\ncomplementary potential for autonomy and openness yet also introduces\nunderexplored security risks, as these agents dynamically interact with\nfinancial protocols and immutable smart contracts. This paper investigates the\nvulnerabilities of AI agents within blockchain-based financial ecosystems when\nexposed to adversarial threats in real-world scenarios. We introduce the\nconcept of context manipulation, a comprehensive attack vector that exploits\nunprotected context surfaces, including input channels, memory modules, and\nexternal data feeds.\n  Through empirical analysis of ElizaOS, a decentralized AI agent framework for\nautomated Web3 operations, we demonstrate how adversaries can manipulate\ncontext by injecting malicious instructions into prompts or historical\ninteraction records, leading to unintended asset transfers and protocol\nviolations which could be financially devastating.\n  To quantify these vulnerabilities, we design CrAIBench, a Web3\ndomain-specific benchmark that evaluates the robustness of AI agents against\ncontext manipulation attacks across 150+ realistic blockchain tasks, including\ntoken transfers, trading, bridges and cross-chain interactions and 500+ attack\ntest cases using context manipulation. We systematically assess attack and\ndefense strategies, analyzing factors like the influence of security prompts,\nreasoning models, and the effectiveness of alignment techniques.\n  Our findings show that prompt-based defenses are insufficient when\nadversaries corrupt stored context, achieving significant attack success rates\ndespite these defenses. Fine-tuning-based defenses offer a more robust\nalternative, substantially reducing attack success rates while preserving\nutility on single-step tasks. This research highlights the urgent need to\ndevelop AI agents that are both secure and fiduciarily responsible."}
{"id": "2504.18768", "pdf": "https://arxiv.org/pdf/2504.18768", "abs": "https://arxiv.org/abs/2504.18768", "authors": ["Letian Huang", "Dongwei Ye", "Jialin Dan", "Chengzhi Tao", "Huiwen Liu", "Kun Zhou", "Bo Ren", "Yuanqi Li", "Yanwen Guo", "Jie Guo"], "title": "TransparentGS: Fast Inverse Rendering of Transparent Objects with Gaussians", "categories": ["cs.GR", "cs.CV"], "comment": "accepted by SIGGRAPH 2025;\n  https://letianhuang.github.io/transparentgs/", "summary": "The emergence of neural and Gaussian-based radiance field methods has led to\nconsiderable advancements in novel view synthesis and 3D object reconstruction.\nNonetheless, specular reflection and refraction continue to pose significant\nchallenges due to the instability and incorrect overfitting of radiance fields\nto high-frequency light variations. Currently, even 3D Gaussian Splatting\n(3D-GS), as a powerful and efficient tool, falls short in recovering\ntransparent objects with nearby contents due to the existence of apparent\nsecondary ray effects. To address this issue, we propose TransparentGS, a fast\ninverse rendering pipeline for transparent objects based on 3D-GS. The main\ncontributions are three-fold. Firstly, an efficient representation of\ntransparent objects, transparent Gaussian primitives, is designed to enable\nspecular refraction through a deferred refraction strategy. Secondly, we\nleverage Gaussian light field probes (GaussProbe) to encode both ambient light\nand nearby contents in a unified framework. Thirdly, a depth-based iterative\nprobes query (IterQuery) algorithm is proposed to reduce the parallax errors in\nour probe-based framework. Experiments demonstrate the speed and accuracy of\nour approach in recovering transparent objects from complex environments, as\nwell as several applications in computer graphics and vision."}
{"id": "2405.18353", "pdf": "https://arxiv.org/pdf/2405.18353", "abs": "https://arxiv.org/abs/2405.18353", "authors": ["Gefan Yang", "Elizabeth Louise Baker", "Michael L. Severinsen", "Christy Anna Hipsley", "Stefan Sommer"], "title": "Infinite-dimensional Diffusion Bridge Simulation via Operator Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The diffusion bridge, which is a diffusion process conditioned on hitting a\nspecific state within a finite period, has found broad applications in various\nscientific and engineering fields. However, simulating diffusion bridges for\nmodeling natural data can be challenging due to both the intractability of the\ndrift term and continuous representations of the data. Although several methods\nare available to simulate finite-dimensional diffusion bridges,\ninfinite-dimensional cases remain under explored. This paper presents a method\nthat merges score matching techniques with operator learning, enabling a direct\napproach to learn the infinite-dimensional bridge and achieving a\ndiscretization equivariant bridge simulation. We conduct a series of\nexperiments, ranging from synthetic examples with closed-form solutions to the\nstochastic nonlinear evolution of real-world biological shape data. Our method\ndemonstrates high efficacy, particularly due to its ability to adapt to any\nresolution without extra training."}
{"id": "2503.19339", "pdf": "https://arxiv.org/pdf/2503.19339", "abs": "https://arxiv.org/abs/2503.19339", "authors": ["Amna Naeem", "Muazzam A. Khan", "Nada Alasbali", "Jawad Ahmad", "Aizaz Ahmad Khattak", "Muhammad Shahbaz Khan"], "title": "Efficient IoT Intrusion Detection with an Improved Attention-Based CNN-BiLSTM Architecture", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The ever-increasing security vulnerabilities in the Internet-of-Things (IoT)\nsystems require improved threat detection approaches. This paper presents a\ncompact and efficient approach to detect botnet attacks by employing an\nintegrated approach that consists of traffic pattern analysis, temporal support\nlearning, and focused feature extraction. The proposed attention-based model\nbenefits from a hybrid CNN-BiLSTM architecture and achieves 99% classification\naccuracy in detecting botnet attacks utilizing the N-BaIoT dataset, while\nmaintaining high precision and recall across various scenarios. The proposed\nmodel's performance is further validated by key parameters, such as Mathews\nCorrelation Coefficient and Cohen's kappa Correlation Coefficient. The\nclose-to-ideal results for these parameters demonstrate the proposed model's\nability to detect botnet attacks accurately and efficiently in practical\nsettings and on unseen data. The proposed model proved to be a powerful defence\nmechanism for IoT networks to face emerging security challenges."}
{"id": "2504.19174", "pdf": "https://arxiv.org/pdf/2504.19174", "abs": "https://arxiv.org/abs/2504.19174", "authors": ["Xueqi Ma", "Yilin Liu", "Tianlong Gao", "Qirui Huang", "Hui Huang"], "title": "CLR-Wire: Towards Continuous Latent Representations for 3D Curve Wireframe Generation", "categories": ["cs.GR", "cs.CV"], "comment": "SIGGRAPH 2025 (Patent Protected); Project page:\n  https://vcc.tech/research/2025/CLRWire", "summary": "We introduce CLR-Wire, a novel framework for 3D curve-based wireframe\ngeneration that integrates geometry and topology into a unified Continuous\nLatent Representation. Unlike conventional methods that decouple vertices,\nedges, and faces, CLR-Wire encodes curves as Neural Parametric Curves along\nwith their topological connectivity into a continuous and fixed-length latent\nspace using an attention-driven variational autoencoder (VAE). This unified\napproach facilitates joint learning and generation of both geometry and\ntopology. To generate wireframes, we employ a flow matching model to\nprogressively map Gaussian noise to these latents, which are subsequently\ndecoded into complete 3D wireframes. Our method provides fine-grained modeling\nof complex shapes and irregular topologies, and supports both unconditional\ngeneration and generation conditioned on point cloud or image inputs.\nExperimental results demonstrate that, compared with state-of-the-art\ngenerative approaches, our method achieves substantial improvements in\naccuracy, novelty, and diversity, offering an efficient and comprehensive\nsolution for CAD design, geometric reconstruction, and 3D content creation."}
{"id": "2406.06002", "pdf": "https://arxiv.org/pdf/2406.06002", "abs": "https://arxiv.org/abs/2406.06002", "authors": ["Zhen Qin", "Zhihui Zhu"], "title": "Computational and Statistical Guarantees for Tensor-on-Tensor Regression with Tensor Train Decomposition", "categories": ["cs.LG", "eess.SP", "math.OC"], "comment": "arXiv admin note: text overlap with arXiv:2401.02592", "summary": "Recently, a tensor-on-tensor (ToT) regression model has been proposed to\ngeneralize tensor recovery, encompassing scenarios like scalar-on-tensor\nregression and tensor-on-vector regression. However, the exponential growth in\ntensor complexity poses challenges for storage and computation in ToT\nregression. To overcome this hurdle, tensor decompositions have been\nintroduced, with the tensor train (TT)-based ToT model proving efficient in\npractice due to reduced memory requirements, enhanced computational efficiency,\nand decreased sampling complexity. Despite these practical benefits, a\ndisparity exists between theoretical analysis and real-world performance. In\nthis paper, we delve into the theoretical and algorithmic aspects of the\nTT-based ToT regression model. Assuming the regression operator satisfies the\nrestricted isometry property (RIP), we conduct an error analysis for the\nsolution to a constrained least-squares optimization problem. This analysis\nincludes upper error bound and minimax lower bound, revealing that such error\nbounds polynomially depend on the order $N+M$. To efficiently find solutions\nmeeting such error bounds, we propose two optimization algorithms: the\niterative hard thresholding (IHT) algorithm (employing gradient descent with\nTT-singular value decomposition (TT-SVD)) and the factorization approach using\nthe Riemannian gradient descent (RGD) algorithm. When RIP is satisfied,\nspectral initialization facilitates proper initialization, and we establish the\nlinear convergence rate of both IHT and RGD."}
{"id": "2504.02546", "pdf": "https://arxiv.org/pdf/2504.02546", "abs": "https://arxiv.org/abs/2504.02546", "authors": ["Xiangxiang Chu", "Hailang Huang", "Xiao Zhang", "Fei Wei", "Yong Wang"], "title": "GPG: A Simple and Strong Reinforcement Learning Baseline for Model Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning (RL) can directly enhance the reasoning capabilities\nof large language models without extensive reliance on Supervised Fine-Tuning\n(SFT). In this work, we revisit the traditional Policy Gradient (PG) mechanism\nand propose a minimalist RL approach termed Group Policy Gradient (GPG). Unlike\nconventional methods, GPG directly optimize the original RL objective, thus\nobviating the need for surrogate loss functions. By eliminating the critic and\nreference models, avoiding KL divergence constraints, and addressing the\nadvantage and gradient estimation bias, our approach significantly simplifies\nthe training process compared to Group Relative Policy Optimization (GRPO). Our\napproach achieves superior performance without relying on auxiliary techniques\nor adjustments. As illustrated in Figure 1, extensive experiments demonstrate\nthat our method not only reduces computational costs but also consistently\noutperforms GRPO across various unimodal and multimodal tasks. Our code is\navailable at https://github.com/AMAP-ML/GPG."}
{"id": "2406.17281", "pdf": "https://arxiv.org/pdf/2406.17281", "abs": "https://arxiv.org/abs/2406.17281", "authors": ["Dong Liu", "Yanxuan Yu"], "title": "DRTR: Distance-Aware Graph Representation Learning", "categories": ["cs.LG"], "comment": null, "summary": "We propose \\textbf{DRTR}, a novel graph learning framework that integrates\ndistance-aware multi-hop message passing with dynamic topology refinement.\nUnlike standard GNNs that rely on shallow, fixed-hop aggregation, DRTR\nleverages both static preprocessing and dynamic resampling to capture deeper\nstructural dependencies. A \\emph{Distance Recomputator} prunes semantically\nweak edges using adaptive attention, while a \\emph{Topology Reconstructor}\nestablishes latent connections among distant but relevant nodes. This joint\nmechanism enables more expressive and robust representation learning across\nevolving graph structures. Extensive experiments demonstrate that DRTR\noutperforms baseline GNNs in both accuracy and scalability, especially in\ncomplex and noisy graph environments."}
{"id": "2504.14560", "pdf": "https://arxiv.org/pdf/2504.14560", "abs": "https://arxiv.org/abs/2504.14560", "authors": ["Haiyan Qin", "Zhiwei Xie", "Jingjing Li", "Liangchen Li", "Xiaotong Feng", "Junzhan Liu", "Wang Kang"], "title": "ReasoningV: Efficient Verilog Code Generation with Adaptive Hybrid Reasoning Model", "categories": ["cs.AR", "cs.AI"], "comment": "9 pages, 4 figures", "summary": "Large Language Models (LLMs) have advanced Verilog code generation\nsignificantly, yet face challenges in data quality, reasoning capabilities, and\ncomputational efficiency. This paper presents ReasoningV, a novel model\nemploying a hybrid reasoning strategy that integrates trained intrinsic\ncapabilities with dynamic inference adaptation for Verilog code generation. Our\nframework introduces three complementary innovations: (1) ReasoningV-5K, a\nhigh-quality dataset of 5,000 functionally verified instances with reasoning\npaths created through multi-dimensional filtering of PyraNet samples; (2) a\ntwo-stage training approach combining parameter-efficient fine-tuning for\nfoundational knowledge with full-parameter optimization for enhanced reasoning;\nand (3) an adaptive reasoning mechanism that dynamically adjusts reasoning\ndepth based on problem complexity, reducing token consumption by up to 75\\%\nwhile preserving performance. Experimental results demonstrate ReasoningV's\neffectiveness with a pass@1 accuracy of 57.8\\% on VerilogEval-human, achieving\nperformance competitive with leading commercial models like Gemini-2.0-flash\n(59.5\\%) and exceeding the previous best open-source model by 10.4 percentage\npoints. ReasoningV offers a more reliable and accessible pathway for advancing\nAI-driven hardware design automation, with our model, data, and code available\nat https://github.com/BUAA-CLab/ReasoningV."}
{"id": "2407.00966", "pdf": "https://arxiv.org/pdf/2407.00966", "abs": "https://arxiv.org/abs/2407.00966", "authors": ["Gautam Chandrasekaran", "Adam Klivans", "Vasilis Kontonis", "Raghu Meka", "Konstantinos Stavropoulos"], "title": "Smoothed Analysis for Learning Concepts with Low Intrinsic Dimension", "categories": ["cs.LG", "cs.CC"], "comment": "added some citations", "summary": "In traditional models of supervised learning, the goal of a learner -- given\nexamples from an arbitrary joint distribution on $\\mathbb{R}^d \\times \\{\\pm\n1\\}$ -- is to output a hypothesis that is competitive (to within $\\epsilon$) of\nthe best fitting concept from some class. In order to escape strong hardness\nresults for learning even simple concept classes, we introduce a\nsmoothed-analysis framework that requires a learner to compete only with the\nbest classifier that is robust to small random Gaussian perturbation.\n  This subtle change allows us to give a wide array of learning results for any\nconcept that (1) depends on a low-dimensional subspace (aka multi-index model)\nand (2) has a bounded Gaussian surface area. This class includes functions of\nhalfspaces and (low-dimensional) convex sets, cases that are only known to be\nlearnable in non-smoothed settings with respect to highly structured\ndistributions such as Gaussians.\n  Surprisingly, our analysis also yields new results for traditional\nnon-smoothed frameworks such as learning with margin. In particular, we obtain\nthe first algorithm for agnostically learning intersections of $k$-halfspaces\nin time $k^{poly(\\frac{\\log k}{\\epsilon \\gamma}) }$ where $\\gamma$ is the\nmargin parameter. Before our work, the best-known runtime was exponential in\n$k$ (Arriaga and Vempala, 1999)."}
{"id": "2504.14625", "pdf": "https://arxiv.org/pdf/2504.14625", "abs": "https://arxiv.org/abs/2504.14625", "authors": ["Haiyan Qin", "Jiahao Feng", "Xiaotong Feng", "Wei W. Xing", "Wang Kang"], "title": "Towards Optimal Circuit Generation: Multi-Agent Collaboration Meets Collective Intelligence", "categories": ["cs.AR", "cs.AI"], "comment": "9 pages, 6 figures", "summary": "Large language models (LLMs) have transformed code generation, yet their\napplication in hardware design produces gate counts 38\\%--1075\\% higher than\nhuman designs. We present CircuitMind, a multi-agent framework that achieves\nhuman-competitive efficiency through three key innovations: syntax locking\n(constraining generation to basic logic gates), retrieval-augmented generation\n(enabling knowledge-driven design), and dual-reward optimization (balancing\ncorrectness with efficiency). To evaluate our approach, we introduce TC-Bench,\nthe first gate-level benchmark harnessing collective intelligence from the\nTuringComplete ecosystem -- a competitive circuit design platform with hundreds\nof thousands of players. Experiments show CircuitMind enables 55.6\\% of model\nimplementations to match or exceed top-tier human experts in composite\nefficiency metrics. Most remarkably, our framework elevates the 14B Phi-4 model\nto outperform both GPT-4o mini and Gemini 2.0 Flash, achieving efficiency\ncomparable to the top 25\\% of human experts without requiring specialized\ntraining. These innovations establish a new paradigm for hardware optimization\nwhere collaborative AI systems leverage collective human expertise to achieve\noptimal circuit designs. Our model, data, and code are open-source at\nhttps://github.com/BUAA-CLab/CircuitMind."}
{"id": "2407.17856", "pdf": "https://arxiv.org/pdf/2407.17856", "abs": "https://arxiv.org/abs/2407.17856", "authors": ["Juan Miguel Lopez Alcaraz", "Hjalmar Bouma", "Nils Strodthoff"], "title": "Enhancing clinical decision support with physiological waveforms -- a multimodal benchmark in emergency care", "categories": ["cs.LG", "eess.SP"], "comment": "Version accepted by Computers in Biology and Medicine: 21 pages, 2\n  figures, code available under https://github.com/AI4HealthUOL/MDS-ED, dataset\n  available under https://physionet.org/content/multimodal-emergency-benchmark/", "summary": "Background: AI-driven prediction algorithms have the potential to enhance\nemergency medicine by enabling rapid and accurate decision-making regarding\npatient status and potential deterioration. However, the integration of\nmultimodal data, including raw waveform signals, remains underexplored in\nclinical decision support. Methods: We present a dataset and benchmarking\nprotocol designed to advance multimodal decision support in emergency care. Our\nmodels utilize demographics, biometrics, vital signs, laboratory values, and\nelectrocardiogram (ECG) waveforms as inputs to predict both discharge diagnoses\nand patient deterioration. Results: The diagnostic model achieves area under\nthe receiver operating curve (AUROC) scores above 0.8 for 609 out of 1,428\nconditions, covering both cardiac (e.g., myocardial infarction) and non-cardiac\n(e.g., renal disease, diabetes) diagnoses. The deterioration model attains\nAUROC scores above 0.8 for 14 out of 15 targets, accurately predicting critical\nevents such as cardiac arrest, mechanical ventilation, ICU admission, and\nmortality. Conclusions: Our study highlights the positive impact of\nincorporating raw waveform data into decision support models, improving\npredictive performance. By introducing a unique, publicly available dataset and\nbaseline models, we provide a foundation for measurable progress in AI-driven\ndecision support for emergency care."}
{"id": "2504.15546", "pdf": "https://arxiv.org/pdf/2504.15546", "abs": "https://arxiv.org/abs/2504.15546", "authors": ["Jayachandu Bandlamudi", "Ritwik Chaudhuri", "Neelamadhav Gantayat", "Kushal Mukherjee", "Prerna Agarwal", "Renuka Sindhgatta", "Sameep Mehta"], "title": "A Framework for Testing and Adapting REST APIs as LLM Tools", "categories": ["cs.SE", "cs.AI", "I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) are enabling autonomous agents to perform\ncomplex workflows using external tools or functions, often provided via REST\nAPIs in enterprise systems. However, directly utilizing these APIs as tools\nposes challenges due to their complex input schemas, elaborate responses, and\noften ambiguous documentation. Current benchmarks for tool testing do not\nadequately address these complexities, leading to a critical gap in evaluating\nAPI readiness for agent-driven automation. In this work, we present a novel\ntesting framework aimed at evaluating and enhancing the readiness of REST APIs\nto function as tools for LLM-based agents. Our framework transforms apis as\ntools, generates comprehensive test cases for the APIs, translates tests cases\ninto natural language instructions suitable for agents, enriches tool\ndefinitions and evaluates the agent's ability t correctly invoke the API and\nprocess its inputs and responses. To provide actionable insights, we analyze\nthe outcomes of 750 test cases, presenting a detailed taxonomy of errors,\nincluding input misinterpretation, output handling inconsistencies, and schema\nmismatches. Additionally, we classify these test cases to streamline debugging\nand refinement of tool integrations. This work offers a foundational step\ntoward enabling enterprise APIs as tools, improving their usability in\nagent-based applications."}
{"id": "2412.12870", "pdf": "https://arxiv.org/pdf/2412.12870", "abs": "https://arxiv.org/abs/2412.12870", "authors": ["Zhenjiang Mao", "Ivan Ruchkin"], "title": "Towards Physically Interpretable World Models: Meaningful Weakly Supervised Representations for Visual Trajectory Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Deep learning models are increasingly employed for perception, prediction,\nand control in robotic systems. For for achieving realistic and consistent\noutputs, it is crucial to embed physical knowledge into their learned\nrepresentations. However, doing so is difficult due to high-dimensional\nobservation data, such as images, particularly under conditions of incomplete\nsystem knowledge and imprecise state sensing. To address this, we propose\nPhysically Interpretable World Models, a novel architecture that aligns learned\nlatent representations with real-world physical quantities. To this end, our\narchitecture combines three key elements: (1) a vector-quantized image\nautoencoder, (2) a transformer-based physically interpretable autoencoder, and\n(3) a partially known dynamical model. The training incorporates weak\ninterval-based supervision to eliminate the impractical reliance on\nground-truth physical knowledge. Three case studies demonstrate that our\napproach achieves physical interpretability and accurate state predictions,\nthus advancing representation learning for robotics."}
{"id": "2504.18575", "pdf": "https://arxiv.org/pdf/2504.18575", "abs": "https://arxiv.org/abs/2504.18575", "authors": ["Ivan Evtimov", "Arman Zharmagambetov", "Aaron Grattafiori", "Chuan Guo", "Kamalika Chaudhuri"], "title": "WASP: Benchmarking Web Agent Security Against Prompt Injection Attacks", "categories": ["cs.CR", "cs.AI"], "comment": "Code and data: https://github.com/facebookresearch/wasp", "summary": "Web navigation AI agents use language-and-vision foundation models to enhance\nproductivity but these models are known to be susceptible to indirect prompt\ninjections that get them to follow instructions different from the legitimate\nuser's. Existing explorations of this threat applied to web agents often focus\non a single isolated adversarial goal, test with injected instructions that are\neither too easy or not truly malicious, and often give the adversary\nunreasonable access. In order to better focus adversarial research, we\nconstruct a new benchmark called WASP (Web Agent Security against Prompt\ninjection attacks) that introduces realistic web agent hijacking objectives and\nan isolated environment to test them in that does not affect real users or the\nlive web. As part of WASP, we also develop baseline attacks against popular web\nagentic systems (VisualWebArena, Claude Computer Use, etc.) instantiated with\nvarious state-of-the-art models. Our evaluation shows that even AI agents\nbacked by models with advanced reasoning capabilities and by models with\ninstruction hierarchy mitigations are susceptible to low-effort human-written\nprompt injections. However, the realistic objectives in WASP also allow us to\nobserve that agents are currently not capable enough to complete the goals of\nattackers end-to-end. Agents begin executing the adversarial instruction\nbetween 16 and 86% of the time but only achieve the goal between 0 and 17% of\nthe time. Based on these findings, we argue that adversarial researchers should\ndemonstrate stronger attacks that more consistently maintain control over the\nagent given realistic constraints on the adversary's power."}
{"id": "2501.18028", "pdf": "https://arxiv.org/pdf/2501.18028", "abs": "https://arxiv.org/abs/2501.18028", "authors": ["Cassandra Mussard", "Arthur Charpentier", "Stéphane Mussard"], "title": "KNN and K-means in Gini Prametric Spaces", "categories": ["cs.LG"], "comment": null, "summary": "This paper introduces innovative enhancements to the K-means and K-nearest\nneighbors (KNN) algorithms based on the concept of Gini prametric spaces.\nUnlike traditional distance metrics, Gini-based measures incorporate both\nvalue-based and rank-based information, improving robustness to noise and\noutliers. The main contributions of this work include: proposing a Gini-based\nmeasure that captures both rank information and value distances; presenting a\nGini K-means algorithm that is proven to converge and demonstrates resilience\nto noisy data; and introducing a Gini KNN method that performs competitively\nwith state-of-the-art approaches such as Hassanat's distance in noisy\nenvironments. Experimental evaluations on 14 datasets from the UCI repository\ndemonstrate the superior performance and efficiency of Gini-based algorithms in\nclustering and classification tasks. This work opens new avenues for leveraging\nrank-based measures in machine learning and statistical analysis."}
{"id": "2504.19013", "pdf": "https://arxiv.org/pdf/2504.19013", "abs": "https://arxiv.org/abs/2504.19013", "authors": ["Júlia Vicens Figueres", "Juliette Vanderhaeghen", "Federica Bragone", "Kateryna Morozovska", "Khemraj Shukla"], "title": "$PINN - a Domain Decomposition Method for Bayesian Physics-Informed Neural Networks", "categories": ["cs.LG", "cs.AI", "math.AP"], "comment": "37 pages, 22 figures", "summary": "Physics-Informed Neural Networks (PINNs) are a novel computational approach\nfor solving partial differential equations (PDEs) with noisy and sparse initial\nand boundary data. Although, efficient quantification of epistemic and\naleatoric uncertainties in big multi-scale problems remains challenging. We\npropose \\$PINN a novel method of computing global uncertainty in PDEs using a\nBayesian framework, by combining local Bayesian Physics-Informed Neural\nNetworks (BPINN) with domain decomposition. The solution continuity across\nsubdomains is obtained by imposing the flux continuity across the interface of\nneighboring subdomains. To demonstrate the effectiveness of \\$PINN, we conduct\na series of computational experiments on PDEs in 1D and 2D spatial domains.\nAlthough we have adopted conservative PINNs (cPINNs), the method can be\nseamlessly extended to other domain decomposition techniques. The results infer\nthat the proposed method recovers the global uncertainty by computing the local\nuncertainty exactly more efficiently as the uncertainty in each subdomain can\nbe computed concurrently. The robustness of \\$PINN is verified by adding\nuncorrelated random noise to the training data up to 15% and testing for\ndifferent domain sizes."}
{"id": "2502.05974", "pdf": "https://arxiv.org/pdf/2502.05974", "abs": "https://arxiv.org/abs/2502.05974", "authors": ["Haolin Liu", "Chen-Yu Wei", "Julian Zimmert"], "title": "Decision Making in Hybrid Environments: A Model Aggregation Approach", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Recent work by Foster et al. (2021, 2022, 2023b) and Xu and Zeevi (2023)\ndeveloped the framework of decision estimation coefficient (DEC) that\ncharacterizes the complexity of general online decision making problems and\nprovides a general algorithm design principle. These works, however, either\nfocus on the pure stochastic regime where the world remains fixed over time, or\nthe pure adversarial regime where the world arbitrarily changes over time. For\nthe hybrid regime where the dynamics of the world is fixed while the reward\narbitrarily changes, they only give pessimistic bounds on the decision\ncomplexity. In this work, we propose a general extension of DEC that more\nprecisely characterizes this case. Besides applications in special cases, our\nframework leads to a flexible algorithm design where the learner learns over\nsubsets of the hypothesis set, trading estimation complexity with decision\ncomplexity, which could be of independent interest. Our work covers model-based\nlearning and model-free learning in the hybrid regime, with a newly proposed\nextension of the bilinear classes (Du et al., 2021) to the adversarial-reward\ncase. In addition, our method improves the best-known regret bounds for linear\nQ*/V* MDPs in the pure stochastic regime."}
{"id": "2504.20101", "pdf": "https://arxiv.org/pdf/2504.20101", "abs": "https://arxiv.org/abs/2504.20101", "authors": ["Fei Fang", "Yifan Hua", "Shengze Wang", "Ruilin Zhou", "Yi Liu", "Chen Qian", "Xiaoxue Zhang"], "title": "GenTorrent: Scaling Large Language Model Serving with An Overley Network", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "While significant progress has been made in research and development on\nopen-source and cost-efficient large-language models (LLMs), serving\nscalability remains a critical challenge, particularly for small organizations\nand individuals seeking to deploy and test their LLM innovations. Inspired by\npeer-to-peer networks that leverage decentralized overlay nodes to increase\nthroughput and availability, we propose GenTorrent, an LLM serving overlay that\nharnesses computing resources from decentralized contributors. We identify four\nkey research problems inherent to enabling such a decentralized infrastructure:\n1) overlay network organization; 2) LLM communication privacy; 3) overlay\nforwarding for resource efficiency; and 4) verification of serving quality.\nThis work presents the first systematic study of these fundamental problems in\nthe context of decentralized LLM serving. Evaluation results from a prototype\nimplemented on a set of decentralized nodes demonstrate that GenTorrent\nachieves a latency reduction of over 50% compared to the baseline design\nwithout overlay forwarding. Furthermore, the security features introduce\nminimal overhead to serving latency and throughput. We believe this work\npioneers a new direction for democratizing and scaling future AI serving\ncapabilities."}
{"id": "2503.00917", "pdf": "https://arxiv.org/pdf/2503.00917", "abs": "https://arxiv.org/abs/2503.00917", "authors": ["Ali Ebrahimpour-Boroojeny", "Hari Sundaram", "Varun Chandrasekaran"], "title": "AMUN: Adversarial Machine UNlearning", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Machine unlearning, where users can request the deletion of a forget dataset,\nis becoming increasingly important because of numerous privacy regulations.\nInitial works on ``exact'' unlearning (e.g., retraining) incur large\ncomputational overheads. However, while computationally inexpensive,\n``approximate'' methods have fallen short of reaching the effectiveness of\nexact unlearning: models produced fail to obtain comparable accuracy and\nprediction confidence on both the forget and test (i.e., unseen) dataset.\nExploiting this observation, we propose a new unlearning method, Adversarial\nMachine UNlearning (AMUN), that outperforms prior state-of-the-art (SOTA)\nmethods for image classification. AMUN lowers the confidence of the model on\nthe forget samples by fine-tuning the model on their corresponding adversarial\nexamples. Adversarial examples naturally belong to the distribution imposed by\nthe model on the input space; fine-tuning the model on the adversarial examples\nclosest to the corresponding forget samples (a) localizes the changes to the\ndecision boundary of the model around each forget sample and (b) avoids drastic\nchanges to the global behavior of the model, thereby preserving the model's\naccuracy on test samples. Using AMUN for unlearning a random $10\\%$ of CIFAR-10\nsamples, we observe that even SOTA membership inference attacks cannot do\nbetter than random guessing."}
{"id": "2504.20119", "pdf": "https://arxiv.org/pdf/2504.20119", "abs": "https://arxiv.org/abs/2504.20119", "authors": ["Lorenz Brehme", "Thomas Ströhle", "Ruth Breu"], "title": "Can LLMs Be Trusted for Evaluating RAG Systems? A Survey of Methods and Datasets", "categories": ["cs.IR", "cs.AI"], "comment": "8 Pages. This paper has been accepted for presentation at the IEEE\n  Swiss Conference on Data Science (SDS25)", "summary": "Retrieval-Augmented Generation (RAG) has advanced significantly in recent\nyears. The complexity of RAG systems, which involve multiple components-such as\nindexing, retrieval, and generation-along with numerous other parameters, poses\nsubstantial challenges for systematic evaluation and quality enhancement.\nPrevious research highlights that evaluating RAG systems is essential for\ndocumenting advancements, comparing configurations, and identifying effective\napproaches for domain-specific applications. This study systematically reviews\n63 academic articles to provide a comprehensive overview of state-of-the-art\nRAG evaluation methodologies, focusing on four key areas: datasets, retrievers,\nindexing and databases, and the generator component. We observe the feasibility\nof an automated evaluation approach for each component of a RAG system,\nleveraging an LLM capable of both generating evaluation datasets and conducting\nevaluations. In addition, we found that further practical research is essential\nto provide companies with clear guidance on the do's and don'ts of implementing\nand evaluating RAG systems. By synthesizing evaluation approaches for key RAG\ncomponents and emphasizing the creation and adaptation of domain-specific\ndatasets for benchmarking, we contribute to the advancement of systematic\nevaluation methods and the improvement of evaluation rigor for RAG systems.\nFurthermore, by examining the interplay between automated approaches leveraging\nLLMs and human judgment, we contribute to the ongoing discourse on balancing\nautomation and human input, clarifying their respective contributions,\nlimitations, and challenges in achieving robust and reliable evaluations."}
{"id": "2504.03359", "pdf": "https://arxiv.org/pdf/2504.03359", "abs": "https://arxiv.org/abs/2504.03359", "authors": ["Samuel Bilson", "Maurice Cox", "Anna Pustogvar", "Andrew Thompson"], "title": "A metrological framework for uncertainty evaluation in machine learning classification models", "categories": ["cs.LG"], "comment": "47 pages, 7 figures", "summary": "Machine learning (ML) classification models are increasingly being used in a\nwide range of applications where it is important that predictions are\naccompanied by uncertainties, including in climate and earth observation,\nmedical diagnosis and bioaerosol monitoring. The output of an ML classification\nmodel is a type of categorical variable known as a nominal property in the\nInternational Vocabulary of Metrology (VIM). However, concepts related to\nuncertainty evaluation for nominal properties are not defined in the VIM, nor\nis such evaluation addressed by the Guide to the Expression of Uncertainty in\nMeasurement (GUM). In this paper we propose a metrological conceptual\nuncertainty evaluation framework for ML classification, and illustrate its use\nin the context of two applications that exemplify the issues and have\nsignificant societal impact, namely, climate and earth observation and medical\ndiagnosis. Our framework would enable an extension of the VIM and GUM to\nuncertainty for nominal properties, which would make both applicable to ML\nclassification models."}
{"id": "2504.21036", "pdf": "https://arxiv.org/pdf/2504.21036", "abs": "https://arxiv.org/abs/2504.21036", "authors": ["Hao Du", "Shang Liu", "Yang Cao"], "title": "Can Differentially Private Fine-tuning LLMs Protect Against Privacy Attacks?", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "accepted by DBSec25", "summary": "Fine-tuning large language models (LLMs) has become an essential strategy for\nadapting them to specialized tasks; however, this process introduces\nsignificant privacy challenges, as sensitive training data may be inadvertently\nmemorized and exposed. Although differential privacy (DP) offers strong\ntheoretical guarantees against such leakage, its empirical privacy\neffectiveness on LLMs remains unclear, especially under different fine-tuning\nmethods. In this paper, we systematically investigate the impact of DP across\nfine-tuning methods and privacy budgets, using both data extraction and\nmembership inference attacks to assess empirical privacy risks. Our main\nfindings are as follows: (1) Differential privacy reduces model utility, but\nits impact varies significantly across different fine-tuning methods. (2)\nWithout DP, the privacy risks of models fine-tuned with different approaches\ndiffer considerably. (3) When DP is applied, even a relatively high privacy\nbudget can substantially lower privacy risk. (4) The privacy-utility trade-off\nunder DP training differs greatly among fine-tuning methods, with some methods\nbeing unsuitable for DP due to severe utility degradation. Our results provide\npractical guidance for privacy-conscious deployment of LLMs and pave the way\nfor future research on optimizing the privacy-utility trade-off in fine-tuning\nmethodologies."}
{"id": "2504.04798", "pdf": "https://arxiv.org/pdf/2504.04798", "abs": "https://arxiv.org/abs/2504.04798", "authors": ["Jacob Si", "Zijing Ou", "Mike Qu", "Zhengrui Xiang", "Yingzhen Li"], "title": "TabRep: Training Tabular Diffusion Models with a Simple and Effective Continuous Representation", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion models have been the predominant generative model for tabular data\ngeneration. However, they face the conundrum of modeling under a separate\nversus a unified data representation. The former encounters the challenge of\njointly modeling all multi-modal distributions of tabular data in one model.\nWhile the latter alleviates this by learning a single representation for all\nfeatures, it currently leverages sparse suboptimal encoding heuristics and\nnecessitates additional computation costs. In this work, we address the latter\nby presenting TabRep, a tabular diffusion architecture trained with a unified\ncontinuous representation. To motivate the design of our representation, we\nprovide geometric insights into how the data manifold affects diffusion models.\nThe key attributes of our representation are composed of its density,\nflexibility to provide ample separability for nominal features, and ability to\npreserve intrinsic relationships. Ultimately, TabRep provides a simple yet\neffective approach for training tabular diffusion models under a continuous\ndata manifold. Our results showcase that TabRep achieves superior performance\nacross a broad suite of evaluations. It is the first to synthesize tabular data\nthat exceeds the downstream quality of the original datasets while preserving\nprivacy and remaining computationally efficient."}
{"id": "2504.21155", "pdf": "https://arxiv.org/pdf/2504.21155", "abs": "https://arxiv.org/abs/2504.21155", "authors": ["Fauzan Nazranda Rizqan", "Matthew Hole", "Charles Gretton"], "title": "Evaluation and Verification of Physics-Informed Neural Models of the Grad-Shafranov Equation", "categories": ["physics.plasm-ph", "cs.AI", "cs.NE"], "comment": "9 pages, 4 figures", "summary": "Our contributions are motivated by fusion reactors that rely on maintaining\nmagnetohydrodynamic (MHD) equilibrium, where the balance between plasma\npressure and confining magnetic fields is required for stable operation. In\naxisymmetric tokamak reactors in particular, and under the assumption of\ntoroidal symmetry, this equilibrium can be mathematically modelled using the\nGrad-Shafranov Equation (GSE). Recent works have demonstrated the potential of\nusing Physics-Informed Neural Networks (PINNs) to model the GSE. Existing\nstudies did not examine realistic scenarios in which a single network\ngeneralizes to a variety of boundary conditions. Addressing that limitation, we\nevaluate a PINN architecture that incorporates boundary points as network\ninputs. Additionally, we compare PINN model accuracy and inference speeds with\na Fourier Neural Operator (FNO) model. Finding the PINN model to be the most\nperformant, and accurate in our setting, we use the network verification tool\nMarabou to perform a range of verification tasks. Although we find some\ndiscrepancies between evaluations of the networks natively in PyTorch, compared\nto via Marabou, we are able to demonstrate useful and practical verification\nworkflows. Our study is the first investigation of verification of such\nnetworks."}
{"id": "2504.07835", "pdf": "https://arxiv.org/pdf/2504.07835", "abs": "https://arxiv.org/abs/2504.07835", "authors": ["Erin Carson", "Xinye Chen"], "title": "Pychop: Emulating Low-Precision Arithmetic in Numerical Methods and Neural Networks", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Motivated by the growing demand for low-precision arithmetic in computational\nscience, we exploit lower-precision emulation in Python -- widely regarded as\nthe dominant programming language for numerical analysis and machine learning.\nLow-precision training has revolutionized deep learning by enabling more\nefficient computation and reduced memory and energy consumption while\nmaintaining model fidelity. To better enable numerical experimentation with and\nexploration of low precision computation, we developed the Pychop library,\nwhich supports customizable floating-point formats and a comprehensive set of\nrounding modes in Python, allowing users to benefit from fast, low-precision\nemulation in numerous applications. Pychop also introduces interfaces for both\nPyTorch and JAX, enabling efficient low-precision emulation on GPUs for neural\nnetwork training and inference with unparalleled flexibility.\n  In this paper, we offer a comprehensive exposition of the design,\nimplementation, validation, and practical application of Pychop, establishing\nit as a foundational tool for advancing efficient mixed-precision algorithms.\nFurthermore, we present empirical results on low-precision emulation for image\nclassification and object detection using published datasets, illustrating the\nsensitivity of the use of low precision and offering valuable insights into its\nimpact. Pychop enables in-depth investigations into the effects of numerical\nprecision, facilitates the development of novel hardware accelerators, and\nintegrates seamlessly into existing deep learning workflows. Software and\nexperimental code are publicly available at\nhttps://github.com/inEXASCALE/pychop."}
{"id": "2504.21489", "pdf": "https://arxiv.org/pdf/2504.21489", "abs": "https://arxiv.org/abs/2504.21489", "authors": ["Shirin Anlen", "Zuzanna Wojciak"], "title": "TRIED: Truly Innovative and Effective AI Detection Benchmark, developed by WITNESS", "categories": ["cs.CY", "cs.AI"], "comment": "33 pages", "summary": "The proliferation of generative AI and deceptive synthetic media threatens\nthe global information ecosystem, especially across the Global Majority. This\nreport from WITNESS highlights the limitations of current AI detection tools,\nwhich often underperform in real-world scenarios due to challenges related to\nexplainability, fairness, accessibility, and contextual relevance. In response,\nWITNESS introduces the Truly Innovative and Effective AI Detection (TRIED)\nBenchmark, a new framework for evaluating detection tools based on their\nreal-world impact and capacity for innovation. Drawing on frontline\nexperiences, deceptive AI cases, and global consultations, the report outlines\nhow detection tools must evolve to become truly innovative and relevant by\nmeeting diverse linguistic, cultural, and technological contexts. It offers\npractical guidance for developers, policy actors, and standards bodies to\ndesign accountable, transparent, and user-centered detection solutions, and\nincorporate sociotechnical considerations into future AI standards, procedures\nand evaluation frameworks. By adopting the TRIED Benchmark, stakeholders can\ndrive innovation, safeguard public trust, strengthen AI literacy, and\ncontribute to a more resilient global information credibility."}
{"id": "2504.12561", "pdf": "https://arxiv.org/pdf/2504.12561", "abs": "https://arxiv.org/abs/2504.12561", "authors": ["Akira Tamamori"], "title": "Kernel Ridge Regression for Efficient Learning of High-Capacity Hopfield Networks", "categories": ["cs.LG", "cs.NE"], "comment": "6 pages, 3 figures, 1 table. Changed to APSIPA ASC 2025 format", "summary": "Hopfield networks using Hebbian learning suffer from limited storage\ncapacity. While supervised methods like Linear Logistic Regression (LLR) offer\nsome improvement, kernel methods like Kernel Logistic Regression (KLR)\nsignificantly enhance capacity and noise robustness. However, KLR requires\ncomputationally expensive iterative learning. We propose Kernel Ridge\nRegression (KRR) as an efficient kernel-based alternative for learning\nhigh-capacity Hopfield networks. KRR utilizes the kernel trick and predicts\nbipolar states via regression, crucially offering a non-iterative, closed-form\nsolution for learning dual variables. We evaluate KRR and compare its\nperformance against Hebbian, LLR, and KLR. Our results demonstrate that KRR\nachieves state-of-the-art storage capacity (reaching $\\beta$=1.5) and noise\nrobustness, comparable to KLR. Crucially, KRR drastically reduces training\ntime, being orders of magnitude faster than LLR and significantly faster than\nKLR, especially at higher storage loads. This establishes KRR as a potent and\nhighly efficient method for building high-performance associative memories,\nproviding comparable performance to KLR with substantial training speed\nadvantages. This work provides the first empirical comparison between KRR and\nKLR in the context of Hopfield network learning."}
{"id": "2504.17066", "pdf": "https://arxiv.org/pdf/2504.17066", "abs": "https://arxiv.org/abs/2504.17066", "authors": ["Kewen Peng", "Yicheng Yang", "Hao Zhuo"], "title": "Whence Is A Model Fair? Fixing Fairness Bugs via Propensity Score Matching", "categories": ["cs.LG", "cs.CY", "cs.SE", "stat.ML"], "comment": null, "summary": "Fairness-aware learning aims to mitigate discrimination against specific\nprotected social groups (e.g., those categorized by gender, ethnicity, age)\nwhile minimizing predictive performance loss. Despite efforts to improve\nfairness in machine learning, prior studies have shown that many models remain\nunfair when measured against various fairness metrics. In this paper, we\nexamine whether the way training and testing data are sampled affects the\nreliability of reported fairness metrics. Since training and test sets are\noften randomly sampled from the same population, bias present in the training\ndata may still exist in the test data, potentially skewing fairness\nassessments. To address this, we propose FairMatch, a post-processing method\nthat applies propensity score matching to evaluate and mitigate bias. FairMatch\nidentifies control and treatment pairs with similar propensity scores in the\ntest set and adjusts decision thresholds for different subgroups accordingly.\nFor samples that cannot be matched, we perform probabilistic calibration using\nfairness-aware loss functions. Experimental results demonstrate that our\napproach can (a) precisely locate subsets of the test data where the model is\nunbiased, and (b) significantly reduce bias on the remaining data. Overall,\npropensity score matching offers a principled way to improve both fairness\nevaluation and mitigation, without sacrificing predictive performance."}
{"id": "2504.17074", "pdf": "https://arxiv.org/pdf/2504.17074", "abs": "https://arxiv.org/abs/2504.17074", "authors": ["William R. Keely", "Otto Lamminpää", "Steffen Mauceri", "Sean M. R. Crowell", "Christopher W. O'Dell", "Gregory R. McGarragh"], "title": "Conditional Diffusion-Based Retrieval of Atmospheric CO2 from Earth Observing Spectroscopy", "categories": ["cs.LG", "astro-ph.IM"], "comment": "Published as a workshop paper in \"Tackling Climate Change with\n  Machine Learning\", ICLR 2025 Workshop on Tackling Climate Change with Machine\n  Learning. https://www.climatechange.ai/papers/iclr2025/12", "summary": "Satellite-based estimates of greenhouse gas (GHG) properties from\nobservations of reflected solar spectra are integral for understanding and\nmonitoring complex terrestrial systems and their impact on the carbon cycle due\nto their near global coverage. Known as retrieval, making GHG concentration\nestimations from these observations is a non-linear Bayesian inverse problem,\nwhich is operationally solved using a computationally expensive algorithm\ncalled Optimal Estimation (OE), providing a Gaussian approximation to a\nnon-Gaussian posterior. This leads to issues in solver algorithm convergence,\nand to unrealistically confident uncertainty estimates for the retrieved\nquantities. Upcoming satellite missions will provide orders of magnitude more\ndata than the current constellation of GHG observers. Development of fast and\naccurate retrieval algorithms with robust uncertainty quantification is\ncritical. Doing so stands to provide substantial climate impact of moving\ntowards the goal of near continuous real-time global monitoring of carbon\nsources and sinks which is essential for policy making. To achieve this goal,\nwe propose a diffusion-based approach to flexibly retrieve a Gaussian or\nnon-Gaussian posterior, for NASA's Orbiting Carbon Observatory-2 spectrometer,\nwhile providing a substantial computational speed-up over the current\noperational state-of-the-art."}
{"id": "2504.18506", "pdf": "https://arxiv.org/pdf/2504.18506", "abs": "https://arxiv.org/abs/2504.18506", "authors": ["Sanjeev Raja", "Martin Šípka", "Michael Psenka", "Tobias Kreiman", "Michal Pavelka", "Aditi S. Krishnapriyan"], "title": "Action-Minimization Meets Generative Modeling: Efficient Transition Path Sampling with the Onsager-Machlup Functional", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.chem-ph", "q-bio.BM"], "comment": "ICML 2025", "summary": "Transition path sampling (TPS), which involves finding probable paths\nconnecting two points on an energy landscape, remains a challenge due to the\ncomplexity of real-world atomistic systems. Current machine learning approaches\nuse expensive, task-specific, and data-free training procedures, limiting their\nability to benefit from recent advances in atomistic machine learning, such as\nhigh-quality datasets and large-scale pre-trained models. In this work, we\naddress TPS by interpreting candidate paths as trajectories sampled from\nstochastic dynamics induced by the learned score function of pre-trained\ngenerative models, specifically denoising diffusion and flow matching. Under\nthese dynamics, finding high-likelihood transition paths becomes equivalent to\nminimizing the Onsager-Machlup (OM) action functional. This enables us to\nrepurpose pre-trained generative models for TPS in a zero-shot manner, in\ncontrast with bespoke, task-specific TPS models trained in previous work. We\ndemonstrate our approach on varied molecular systems, obtaining diverse,\nphysically realistic transition pathways and generalizing beyond the\npre-trained model's original training dataset. Our method can be easily\nincorporated into new generative models, making it practically relevant as\nmodels continue to scale and improve with increased data availability."}
{"id": "2504.19602", "pdf": "https://arxiv.org/pdf/2504.19602", "abs": "https://arxiv.org/abs/2504.19602", "authors": ["Kitsuya Azuma", "Takayuki Nishio", "Yuichi Kitagawa", "Wakako Nakano", "Takahito Tanimura"], "title": "Soft-Label Caching and Sharpening for Communication-Efficient Federated Distillation", "categories": ["cs.LG"], "comment": "15 pages, 12 figures", "summary": "Federated Learning (FL) enables collaborative model training across\ndecentralized clients, enhancing privacy by keeping data local. Yet\nconventional FL, relying on frequent parameter-sharing, suffers from high\ncommunication overhead and limited model heterogeneity. Distillation-based FL\napproaches address these issues by sharing predictions (soft-labels) instead,\nbut they often involve redundant transmissions across communication rounds,\nreducing efficiency. We propose SCARLET, a novel framework integrating\nsynchronized soft-label caching and an enhanced Entropy Reduction Aggregation\n(Enhanced ERA) mechanism. SCARLET minimizes redundant communication by reusing\ncached soft-labels, achieving up to 50% reduction in communication costs\ncompared to existing methods while maintaining accuracy. Enhanced ERA can be\ntuned to adapt to non-IID data variations, ensuring robust aggregation and\nperformance in diverse client scenarios. Experimental evaluations demonstrate\nthat SCARLET consistently outperforms state-of-the-art distillation-based FL\nmethods in terms of accuracy and communication efficiency. The implementation\nof SCARLET is publicly available at https://github.com/kitsuyaazuma/SCARLET."}
{"id": "2301.06987", "pdf": "https://arxiv.org/pdf/2301.06987", "abs": "https://arxiv.org/abs/2301.06987", "authors": ["Bassel El Mabsout", "Shahin Roozkhosh", "Siddharth Mysore", "Kate Saenko", "Renato Mancuso"], "title": "Sim-Anchored Learning for On-the-Fly Adaptation", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Fine-tuning simulation-trained RL agents with real-world data often degrades\ncrucial behaviors due to limited or skewed data distributions. We argue that\ndesigner priorities exist not just in reward functions, but also in simulation\ndesign choices like task selection and state initialization. When adapting to\nreal-world data, agents can experience catastrophic forgetting in important but\nunderrepresented scenarios. We propose framing live-adaptation as a\nmulti-objective optimization problem, where policy objectives must be satisfied\nboth in simulation and reality. Our approach leverages critics from simulation\nas \"anchors for design intent\" (anchor critics). By jointly optimizing policies\nagainst both anchor critics and critics trained on real-world experience, our\nmethod enables adaptation while preserving prioritized behaviors from\nsimulation. Evaluations demonstrate robust behavior retention in sim-to-sim\nbenchmarks and a sim-to-real scenario with a racing quadrotor, allowing for\npower consumption reductions of up to 50% without control loss. We also\ncontribute SwaNNFlight, an open-source firmware for enabling live adaptation on\nsimilar robotic platforms."}
{"id": "2302.00316", "pdf": "https://arxiv.org/pdf/2302.00316", "abs": "https://arxiv.org/abs/2302.00316", "authors": ["Michael Muehlebach", "Michael I. Jordan"], "title": "Accelerated First-Order Optimization under Nonlinear Constraints", "categories": ["math.OC", "cs.LG", "eess.SP", "stat.ML"], "comment": "44 pages, 6 figures", "summary": "We exploit analogies between first-order algorithms for constrained\noptimization and non-smooth dynamical systems to design a new class of\naccelerated first-order algorithms for constrained optimization. Unlike\nFrank-Wolfe or projected gradients, these algorithms avoid optimization over\nthe entire feasible set at each iteration. We prove convergence to stationary\npoints even in a nonconvex setting and we derive accelerated rates for the\nconvex setting both in continuous time, as well as in discrete time. An\nimportant property of these algorithms is that constraints are expressed in\nterms of velocities instead of positions, which naturally leads to sparse,\nlocal and convex approximations of the feasible set (even if the feasible set\nis nonconvex). Thus, the complexity tends to grow mildly in the number of\ndecision variables and in the number of constraints, which makes the algorithms\nsuitable for machine learning applications. We apply our algorithms to a\ncompressed sensing and a sparse regression problem, showing that we can treat\nnonconvex $\\ell^p$ constraints ($p<1$) efficiently, while recovering\nstate-of-the-art performance for $p=1$."}
{"id": "2312.02277", "pdf": "https://arxiv.org/pdf/2312.02277", "abs": "https://arxiv.org/abs/2312.02277", "authors": ["Bokun Wang", "Tianbao Yang"], "title": "A Near-Optimal Single-Loop Stochastic Algorithm for Convex Finite-Sum Coupled Compositional Optimization", "categories": ["math.OC", "cs.LG"], "comment": "To appear in ICML 2025", "summary": "This paper studies a class of convex Finite-sum Coupled Compositional\nOptimization (cFCCO) problems with applications including group\ndistributionally robust optimization (GDRO) and learning with imbalanced data.\nTo better address these problems, we introduce an efficient single-loop\nprimal-dual block-coordinate stochastic algorithm called ALEXR. The algorithm\nemploys block-coordinate stochastic mirror ascent with extrapolation for the\ndual variable and stochastic proximal gradient descent updates for the primal\nvariable. We establish the convergence rates of ALEXR in both convex and\nstrongly convex cases under smoothness and non-smoothness conditions of\ninvolved functions, which not only improve the best rates in previous works on\nsmooth cFCCO problems but also expand the realm of cFCCO for solving more\nchallenging non-smooth problems such as the dual form of GDRO. Finally, we\nderive lower complexity bounds, demonstrating the (near-)optimality of ALEXR\nwithin a broad class of stochastic algorithms for cFCCO. Experimental results\non GDRO and partial Area Under the ROC Curve (pAUC) maximization demonstrate\nthe promising performance of our algorithm."}
{"id": "2405.19683", "pdf": "https://arxiv.org/pdf/2405.19683", "abs": "https://arxiv.org/abs/2405.19683", "authors": ["Jimmy Dani", "Kalyan Nakka", "Nitesh Saxena"], "title": "A Machine Learning-Based Framework for Assessing Cryptographic Indistinguishability of Lightweight Block Ciphers", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Indistinguishability is a fundamental principle of cryptographic security,\ncrucial for securing data transmitted between Internet of Things (IoT) devices.\nThis principle ensures that an attacker cannot distinguish between the\nencrypted data, also known as ciphertext, and random data or the ciphertexts of\nthe two messages encrypted with the same key. This research investigates the\nability of machine learning (ML) in assessing indistinguishability property in\nencryption systems, with a focus on lightweight ciphers. As our first case\nstudy, we consider the SPECK32/64 and SIMON32/64 lightweight block ciphers,\ndesigned for IoT devices operating under significant energy constraints.\n  In this research, we introduce MIND-Crypt, a novel ML-based framework\ndesigned to assess the cryptographic indistinguishability of lightweight block\nciphers, specifically the SPECK32/64 and SIMON32/64 encryption algorithm in CBC\nmode (Cipher Block Chaining), under Known Plaintext Attacks (KPA). Our approach\ninvolves training ML models using ciphertexts from two plaintext messages\nencrypted with same key to determine whether ML algorithms can identify\nmeaningful cryptographic patterns or leakage. Our experiments show that modern\nML techniques consistently achieve accuracy equivalent to random guessing,\nindicating that no statistically exploitable patterns exists in the ciphertexts\ngenerated by considered lightweight block ciphers. Furthermore, we demonstrate\nthat in ML algorithms with all the possible combinations of the ciphertexts for\ngiven plaintext messages reflects memorization rather than generalization to\nunseen ciphertexts.\n  Collectively, these findings suggest that existing block ciphers have secure\ncryptographic designs against ML-based indistinguishability assessments,\nreinforcing their security even under round-reduced conditions."}
{"id": "2406.01933", "pdf": "https://arxiv.org/pdf/2406.01933", "abs": "https://arxiv.org/abs/2406.01933", "authors": ["Justin Whitehouse", "Christopher Jung", "Vasilis Syrgkanis", "Bryan Wilder", "Zhiwei Steven Wu"], "title": "Orthogonal Causal Calibration", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": "47 pages, 2 figures", "summary": "Estimates of heterogeneous treatment effects such as conditional average\ntreatment effects (CATEs) and conditional quantile treatment effects (CQTEs)\nplay an important role in real-world decision making. Given this importance,\none should ensure these estimates are calibrated. While there is a rich\nliterature on calibrating estimators of non-causal parameters, very few methods\nhave been derived for calibrating estimators of causal parameters, or more\ngenerally estimators of quantities involving nuisance parameters. In this work,\nwe develop general algorithms for reducing the task of causal calibration to\nthat of calibrating a standard (non-causal) predictive model.\n  Throughout, we study a notion of calibration defined with respect to an\narbitrary, nuisance-dependent loss $\\ell$, under which we say an estimator\n$\\theta$ is calibrated if its predictions cannot be changed on any level set to\ndecrease loss. For losses $\\ell$ satisfying a condition called universal\northogonality, we present a simple algorithm that transforms partially-observed\ndata into generalized pseudo-outcomes and applies any off-the-shelf calibration\nprocedure. For losses $\\ell$ satisfying a weaker assumption called conditional\northogonality, we provide a similar sample splitting algorithm the performs\nempirical risk minimization over an appropriately defined class of functions.\nConvergence of both algorithms follows from a generic, two term upper bound of\nthe calibration error of any model. We demonstrate the practical applicability\nof our results in experiments on both observational and synthetic data. Our\nresults are exceedingly general, showing that essentially any existing\ncalibration algorithm can be used in causal settings, with additional loss only\narising from errors in nuisance estimation."}
{"id": "2410.16122", "pdf": "https://arxiv.org/pdf/2410.16122", "abs": "https://arxiv.org/abs/2410.16122", "authors": ["Matthieu Haeberle", "Puck van Gerwen", "Ruben Laplaza", "Ksenia R. Briling", "Jan Weinreich", "Friedrich Eisenbrand", "Clemence Corminboeuf"], "title": "Integer linear programming for unsupervised training set selection in molecular machine learning", "categories": ["physics.chem-ph", "cs.LG"], "comment": "29 pages + SI (15 pages)", "summary": "Integer linear programming (ILP) is an elegant approach to solve linear\noptimization problems, naturally described using integer decision variables.\nWithin the context of physics-inspired machine learning applied to chemistry,\nwe demonstrate the relevance of an ILP formulation to select molecular training\nsets for predictions of size-extensive properties. We show that our algorithm\noutperforms existing unsupervised training set selection approaches, especially\nwhen predicting properties of molecules larger than those present in the\ntraining set. We argue that the reason for the improved performance is due to\nthe selection that is based on the notion of local similarity (i.e., per-atom)\nand a unique ILP approach that finds optimal solutions efficiently. Altogether,\nthis work provides a practical algorithm to improve the performance of\nphysics-inspired machine learning models and offers insights into the\nconceptual differences with existing training set selection approaches."}
{"id": "2502.00935", "pdf": "https://arxiv.org/pdf/2502.00935", "abs": "https://arxiv.org/abs/2502.00935", "authors": ["Kensuke Nakamura", "Lasse Peters", "Andrea Bajcsy"], "title": "Generalizing Safety Beyond Collision-Avoidance via Latent-Space Reachability Analysis", "categories": ["cs.RO", "cs.LG"], "comment": "9 figures, 7 tables, RSS 2025", "summary": "Hamilton-Jacobi (HJ) reachability is a rigorous mathematical framework that\nenables robots to simultaneously detect unsafe states and generate actions that\nprevent future failures. While in theory, HJ reachability can synthesize safe\ncontrollers for nonlinear systems and nonconvex constraints, in practice, it\nhas been limited to hand-engineered collision-avoidance constraints modeled via\nlow-dimensional state-space representations and first-principles dynamics. In\nthis work, our goal is to generalize safe robot controllers to prevent failures\nthat are hard--if not impossible--to write down by hand, but can be intuitively\nidentified from high-dimensional observations: for example, spilling the\ncontents of a bag. We propose Latent Safety Filters, a latent-space\ngeneralization of HJ reachability that tractably operates directly on raw\nobservation data (e.g., RGB images) to automatically compute safety-preserving\nactions without explicit recovery demonstrations by performing safety analysis\nin the latent embedding space of a generative world model. Our method leverages\ndiverse robot observation-action data of varying quality (including successes,\nrandom exploration, and unsafe demonstrations) to learn a world model.\nConstraint specification is then transformed into a classification problem in\nthe latent space of the learned world model. In simulation and hardware\nexperiments, we compute an approximation of Latent Safety Filters to safeguard\narbitrary policies (from imitation- learned policies to direct teleoperation)\nfrom complex safety hazards, like preventing a Franka Research 3 manipulator\nfrom spilling the contents of a bag or toppling cluttered objects."}
{"id": "2502.05364", "pdf": "https://arxiv.org/pdf/2502.05364", "abs": "https://arxiv.org/abs/2502.05364", "authors": ["Julian Killingback", "Hansi Zeng", "Hamed Zamani"], "title": "Hypencoder: Hypernetworks for Information Retrieval", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Existing information retrieval systems are largely constrained by their\nreliance on vector inner products to assess query-document relevance, which\nnaturally limits the expressiveness of the relevance score they can produce. We\npropose a new paradigm; instead of representing a query as a vector, we use a\nsmall neural network that acts as a learned query-specific relevance function.\nThis small neural network takes a document representation as input (in this\nwork we use a single vector) and produces a scalar relevance score. To produce\nthe small neural network we use a hypernetwork, a network that produces the\nweights of other networks, as our query encoder. We name this category of\nencoder models Hypencoders. Experiments on in-domain search tasks show that\nHypencoders significantly outperform strong dense retrieval models and even\nsurpass reranking models and retrieval models with an order of magnitude more\nparameters. To assess the extent of Hypencoders' capabilities, we evaluate on a\nset of hard retrieval tasks including tip-of-the-tongue and\ninstruction-following retrieval tasks. On harder tasks, we find that the\nperformance gap widens substantially compared to standard retrieval tasks.\nFurthermore, to demonstrate the practicality of our method, we implement an\napproximate search algorithm and show that our model is able to retrieve from a\ncorpus of 8.8M documents in under 60 milliseconds."}
{"id": "2502.07837", "pdf": "https://arxiv.org/pdf/2502.07837", "abs": "https://arxiv.org/abs/2502.07837", "authors": ["Sicheng Wang", "Sheng Liu", "Weiheng Wang", "Jianhua Shan", "Bin Fang"], "title": "RoboBERT: An End-to-end Multimodal Robotic Manipulation Model", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Embodied intelligence seamlessly integrates vision, language, and\naction.~However, most multimodal robotic models rely on massive fine-tuning,\nincurring high time and hardware costs.~To address this, we introduce RoboBERT,\nan end-to-end multimodal manipulation model built around a novel two-stage\ntraining paradigm.~In the first stage, we freeze most of the vision encoder and\ntrain with a single \"standard\" instruction phrasing, allowing the model to\nfocus on stable policy learning via a CNN-based diffusion policy.~In the second\nstage, we unfreeze all modules and inject diverse natural language variants,\nrapidly aligning varied instructions to the already-learned policy without\ndestabilizing performance.~We further employ systematic data augmentations to\nenhance robustness against visual perturbations.~Without relying on auxiliary\ndatasets, RoboBERT achieves new state-of-the-art (SOTA) mean episode lengths of\n4.52 on the CALVIN ABCD-D benchmark and 3.79 on the ABC-D benchmark using only\nlanguage-labeled expert demonstrations and a comparatively lightweight\narchitecture.Real-robot trials on a 6-DOF manipulator confirm higher success\nrates than comparable methods trained on identical data.These results\ndemonstrate that our data-augmentation-enhanced two-stage training paradigm\ndelivers efficient, scalable, and broadly applicable performance for multimodal\nrobotic systems."}
{"id": "2503.11347", "pdf": "https://arxiv.org/pdf/2503.11347", "abs": "https://arxiv.org/abs/2503.11347", "authors": ["Zhenyi Zhang", "Yuhao Sun", "Qiangwei Peng", "Tiejun Li", "Peijie Zhou"], "title": "Integrating Dynamical Systems Modeling with Spatiotemporal scRNA-seq Data Analysis", "categories": ["q-bio.QM", "cs.LG", "physics.bio-ph"], "comment": null, "summary": "Understanding the dynamic nature of biological systems is fundamental to\ndeciphering cellular behavior, developmental processes, and disease\nprogression. Single-cell RNA sequencing (scRNA-seq) has provided static\nsnapshots of gene expression, offering valuable insights into cellular states\nat a single time point. Recent advancements in temporally resolved scRNA-seq,\nspatial transcriptomics (ST), and time-series spatial transcriptomics\n(temporal-ST) have further revolutionized our ability to study the\nspatiotemporal dynamics of individual cells. These technologies, when combined\nwith computational frameworks such as Markov chains, stochastic differential\nequations (SDEs), and generative models like optimal transport and\nSchr\\\"odinger bridges, enable the reconstruction of dynamic cellular\ntrajectories and cell fate decisions. This review discusses how these dynamical\nsystem approaches offer new opportunities to model and infer cellular dynamics\nfrom a systematic perspective."}
{"id": "2504.17811", "pdf": "https://arxiv.org/pdf/2504.17811", "abs": "https://arxiv.org/abs/2504.17811", "authors": ["Anirudhan Badrinath", "Alex Yang", "Kousik Rajesh", "Prabhat Agarwal", "Jaewon Yang", "Haoyu Chen", "Jiajing Xu", "Charles Rosenberg"], "title": "OmniSage: Large Scale, Multi-Entity Heterogeneous Graph Representation Learning", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Representation learning, a task of learning latent vectors to represent\nentities, is a key task in improving search and recommender systems in web\napplications. Various representation learning methods have been developed,\nincluding graph-based approaches for relationships among entities,\nsequence-based methods for capturing the temporal evolution of user activities,\nand content-based models for leveraging text and visual content. However, the\ndevelopment of a unifying framework that integrates these diverse techniques to\nsupport multiple applications remains a significant challenge. This paper\npresents OmniSage, a large-scale representation framework that learns universal\nrepresentations for a variety of applications at Pinterest. OmniSage integrates\ngraph neural networks with content-based models and user sequence models by\nemploying multiple contrastive learning tasks to effectively process graph\ndata, user sequence data, and content signals. To support the training and\ninference of OmniSage, we developed an efficient infrastructure capable of\nsupporting Pinterest graphs with billions of nodes. The universal\nrepresentations generated by OmniSage have significantly enhanced user\nexperiences on Pinterest, leading to an approximate 2.5% increase in sitewide\nrepins (saves) across five applications. This paper highlights the impact of\nunifying representation learning methods, and we will open source the OmniSage\ncode by the time of publication."}
{"id": "2504.19012", "pdf": "https://arxiv.org/pdf/2504.19012", "abs": "https://arxiv.org/abs/2504.19012", "authors": ["Xizhuo Zhang", "Bing Yao"], "title": "Geometry-aware Active Learning of Spatiotemporal Dynamic Systems", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Rapid developments in advanced sensing and imaging have significantly\nenhanced information visibility, opening opportunities for predictive modeling\nof complex dynamic systems. However, sensing signals acquired from such complex\nsystems are often distributed across 3D geometries and rapidly evolving over\ntime, posing significant challenges in spatiotemporal predictive modeling. This\npaper proposes a geometry-aware active learning framework for modeling\nspatiotemporal dynamic systems. Specifically, we propose a geometry-aware\nspatiotemporal Gaussian Process (G-ST-GP) to effectively integrate the temporal\ncorrelations and geometric manifold features for reliable prediction of\nhigh-dimensional dynamic behaviors. In addition, we develop an adaptive active\nlearning strategy to strategically identify informative spatial locations for\ndata collection and further maximize the prediction accuracy. This strategy\nachieves the adaptive trade-off between the prediction uncertainty in the\nG-ST-GP model and the space-filling design guided by the geodesic distance\nacross the 3D geometry. We implement the proposed framework to model the\nspatiotemporal electrodynamics in a 3D heart geometry. Numerical experiments\nshow that our framework outperforms traditional methods lacking the mechanism\nof geometric information incorporation or effective data collection."}
{"id": "2504.19488", "pdf": "https://arxiv.org/pdf/2504.19488", "abs": "https://arxiv.org/abs/2504.19488", "authors": ["Vijay Prakash S"], "title": "Two-parameter superposable S-curves", "categories": ["stat.ME", "cs.LG"], "comment": "14 pages. Some discussion on results and parameter values for bar{m}\n  in the tables are corrected in version 2", "summary": "Straight line equation $y=mx$ with slope $m$, when singularly perturbed as\n$ay^3+y=mx$ with a positive parameter $a$, results in S-shaped curves or\nS-curves on a real plane. As $a\\rightarrow 0$, we get back $y=mx$ which is a\ncumulative distribution function of a continuous uniform distribution that\ndescribes the occurrence of every event in an interval to be equally probable.\nAs $a\\rightarrow\\infty$, the derivative of $y$ has finite support only at $y=0$\nresembling a degenerate distribution. Based on these arguments, in this work,\nwe propose that these S-curves can represent maximum entropy uniform\ndistribution to a zero entropy single value. We also argue that these S-curves\nare superposable as they are only parametrically nonlinear but fundamentally\nlinear. So far, the superposed forms have been used to capture the patterns of\nnatural systems such as nonlinear dynamics of biological growth and kinetics of\nenzyme reactions. Here, we attempt to use the S-curve and its superposed form\nas statistical models. We fit the models on a classical dataset containing\nflower measurements of iris plants and analyze their usefulness in pattern\nrecognition. Based on these models, we claim that any non-uniform pattern can\nbe represented as a singular perturbation to uniform distribution. However, our\nparametric estimation procedure have some limitations such as sensitivity to\ninitial conditions depending on the data at hand."}
