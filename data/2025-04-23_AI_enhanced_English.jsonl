{"id": "2504.15349", "pdf": "https://arxiv.org/pdf/2504.15349", "abs": "https://arxiv.org/abs/2504.15349", "authors": ["William Bruns"], "title": "Exploring Compositional Generalization (in ReCOGS_pos) by Transformers using Restricted Access Sequence Processing (RASP)", "categories": ["cs.CL"], "comment": "8 pages main text with 3 figures and 1 table; limitations page and\n  references separate; 4 more figures, 1 image, and 1 more table in the\n  appendices supplement the work. 29 pages of appendix content", "summary": "Humans understand new combinations of words encountered if they are\ncombinations of words recognized from different contexts, an ability called\nCompositional Generalization. The COGS benchmark (Kim and Linzen, 2020)\narXiv:2010.05465 reports 0% accuracy for Transformer models on some structural\ngeneralizations. We use (Weiss et al., 2021) arXiv:2106.06981's Restricted\nAccess Sequence Processing (RASP), a Transformer-equivalent programming\nlanguage, to prove by construction that a Transformer encoder-decoder can\nperform the semantically equivalent ReCOGS_pos (Wu et al., 2024)\narXiv:2303.13716 variant of COGS systematically and compositionally: Our RASP\nmodel attains 100% semantic exact match on the ReCOGS test set and 100% SEM on\nall generalization splits except obj_pp_to_subj_pp which gets 92%. Furthermore,\nour RASP model shows the ReCOGS_pos task does not require a hierarchical or\ntree-structured solution: we use word-level tokens with an \"embedding\" layer\nthat tags with possible parts of speech, applying just once per encoder pass 19\nattention-head compatible flat pattern-matching rules, shown using grammar\ncoverage (Zeller et al., 2023) to be learnable from the training data, plus\ngeneral prepositional phrase (pp) handling and sentential complement (cp)\nhandling logic, and output the next logical form (LF) token (repeating until\nthe LF is complete). The model does not apply recursive, tree-structured rules\nlike 'np_det pp np -> np_pp -> np', but scores 100% semantic and string exact\nmatch on pp recursion, cp recursion using the decoder loop.", "AI": {"tldr": "The paper demonstrates that a Transformer encoder-decoder, using RASP, can achieve 100% semantic exact match on ReCOGS_pos, proving it doesn't require hierarchical solutions.", "motivation": "To address the 0% accuracy of Transformer models on certain structural generalizations in COGS, showing systematic and compositional capabilities.", "method": "Uses RASP to construct a Transformer-equivalent model with flat pattern-matching rules, handling prepositional phrases and sentential complements without recursion.", "result": "Achieves 100% semantic exact match on ReCOGS_pos, except for one split (92%), and handles recursion via decoder loop.", "conclusion": "Transformers can perform compositional generalization without hierarchical rules, as shown by the RASP model's success."}}
{"id": "2504.15392", "pdf": "https://arxiv.org/pdf/2504.15392", "abs": "https://arxiv.org/abs/2504.15392", "authors": ["Myrthe Reuver", "Indira Sen", "Matteo Melis", "Gabriella Lapesa"], "title": "Tell Me What You Know About Sexism: Expert-LLM Interaction Strategies and Co-Created Definitions for Zero-Shot Sexism Detection", "categories": ["cs.CL", "cs.CY"], "comment": "Accepted and published at Findings of NAACL 2025: cite published\n  version whenever possible", "summary": "This paper investigates hybrid intelligence and collaboration between\nresearchers of sexism and Large Language Models (LLMs), with a four-component\npipeline. First, nine sexism researchers answer questions about their knowledge\nof sexism and of LLMs. They then participate in two interactive experiments\ninvolving an LLM (GPT3.5). The first experiment has experts assessing the\nmodel's knowledge about sexism and suitability for use in research. The second\nexperiment tasks them with creating three different definitions of sexism: an\nexpert-written definition, an LLM-written one, and a co-created definition.\nLastly, zero-shot classification experiments use the three definitions from\neach expert in a prompt template for sexism detection, evaluating GPT4o on\n2.500 texts sampled from five sexism benchmarks. We then analyze the resulting\n67.500 classification decisions. The LLM interactions lead to longer and more\ncomplex definitions of sexism. Expert-written definitions on average perform\npoorly compared to LLM-generated definitions. However, some experts do improve\nclassification performance with their co-created definitions of sexism, also\nexperts who are inexperienced in using LLMs.", "AI": {"tldr": "The paper explores hybrid intelligence by collaborating sexism researchers with LLMs, testing their knowledge and co-creating definitions of sexism, then evaluating classification performance.", "motivation": "To investigate how human experts and LLMs can collaborate to improve understanding and detection of sexism.", "method": "A four-component pipeline: expert surveys, two interactive experiments with LLMs (knowledge assessment and definition creation), and zero-shot classification tests on sexism benchmarks.", "result": "LLM-generated definitions were longer and more complex, outperforming expert-written ones in classification. Some co-created definitions improved performance, even for LLM-inexperienced experts.", "conclusion": "Hybrid intelligence can enhance sexism detection, with LLMs aiding experts, though individual expertise still plays a role."}}
{"id": "2504.15431", "pdf": "https://arxiv.org/pdf/2504.15431", "abs": "https://arxiv.org/abs/2504.15431", "authors": ["Sungjun Han", "Juyoung Suk", "Suyeong An", "Hyungguk Kim", "Kyuseok Kim", "Wonsuk Yang", "Seungtaek Choi", "Jamin Shin"], "title": "Trillion 7B Technical Report", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Preview version", "summary": "We introduce Trillion-7B, the most token-efficient Korean-centric\nmultilingual LLM available. Our novel Cross-lingual Document Attention (XLDA)\nmechanism enables highly efficient and effective knowledge transfer from\nEnglish to target languages like Korean and Japanese. Combined with optimized\ndata mixtures, language-specific filtering, and tailored tokenizer\nconstruction, Trillion-7B achieves competitive performance while dedicating\nonly 10\\% of its 2T training tokens to multilingual data and requiring just\n59.4K H100 GPU hours (\\$148K) for full training. Comprehensive evaluations\nacross 27 benchmarks in four languages demonstrate Trillion-7B's robust\nmultilingual performance and exceptional cross-lingual consistency.", "AI": {"tldr": "Trillion-7B is a token-efficient Korean-centric multilingual LLM using XLDA for cross-lingual knowledge transfer, achieving strong performance with minimal multilingual data and training costs.", "motivation": "To create a highly efficient multilingual LLM focused on Korean, leveraging cross-lingual knowledge transfer while minimizing resource usage.", "method": "Uses Cross-lingual Document Attention (XLDA), optimized data mixtures, language-specific filtering, and tailored tokenizer construction.", "result": "Competitive performance across 27 benchmarks in four languages, with only 10% multilingual data and low training costs ($148K).", "conclusion": "Trillion-7B is a robust, efficient multilingual model with exceptional cross-lingual consistency."}}
{"id": "2504.15301", "pdf": "https://arxiv.org/pdf/2504.15301", "abs": "https://arxiv.org/abs/2504.15301", "authors": ["Zoi Lygizou", "Dimitris Kalles"], "title": "A biologically Inspired Trust Model for Open Multi-Agent Systems that is Resilient to Rapid Performance Fluctuations", "categories": ["cs.MA", "cs.AI", "cs.DC"], "comment": null, "summary": "Trust management provides an alternative solution for securing open, dynamic,\nand distributed multi-agent systems, where conventional cryptographic methods\nprove to be impractical. However, existing trust models face challenges related\nto agent mobility, changing behaviors, and the cold start problem. To address\nthese issues we introduced a biologically inspired trust model in which\ntrustees assess their own capabilities and store trust data locally. This\ndesign improves mobility support, reduces communication overhead, resists\ndisinformation, and preserves privacy. Despite these advantages, prior\nevaluations revealed limitations of our model in adapting to provider\npopulation changes and continuous performance fluctuations. This study proposes\na novel algorithm, incorporating a self-classification mechanism for providers\nto detect performance drops potentially harmful for the service consumers.\nSimulation results demonstrate that the new algorithm outperforms its original\nversion and FIRE, a well-known trust and reputation model, particularly in\nhandling dynamic trustee behavior. While FIRE remains competitive under extreme\nenvironmental changes, the proposed algorithm demonstrates greater adaptability\nacross various conditions. In contrast to existing trust modeling research,\nthis study conducts a comprehensive evaluation of our model using widely\nrecognized trust model criteria, assessing its resilience against common\ntrust-related attacks while identifying strengths, weaknesses, and potential\ncountermeasures. Finally, several key directions for future research are\nproposed.", "AI": {"tldr": "A biologically inspired trust model addresses mobility and behavior changes in multi-agent systems, with a new algorithm improving adaptability and outperforming existing models like FIRE.", "motivation": "Existing trust models struggle with agent mobility, behavior changes, and cold start problems in dynamic systems.", "method": "Introduces a self-classification mechanism for providers to detect harmful performance drops, enhancing the original biologically inspired trust model.", "result": "The new algorithm outperforms the original and FIRE in dynamic conditions, showing greater adaptability.", "conclusion": "The study evaluates resilience against attacks and suggests future research directions for further improvements."}}
{"id": "2504.15432", "pdf": "https://arxiv.org/pdf/2504.15432", "abs": "https://arxiv.org/abs/2504.15432", "authors": ["Yucheng Lu", "Kazimier Smith"], "title": "Feeding LLM Annotations to BERT Classifiers at Your Own Risk", "categories": ["cs.CL"], "comment": null, "summary": "Using LLM-generated labels to fine-tune smaller encoder-only models for text\nclassification has gained popularity in various settings. While this approach\nmay be justified in simple and low-stakes applications, we conduct empirical\nanalysis to demonstrate how the perennial curse of training on synthetic data\nmanifests itself in this specific setup. Compared to models trained on gold\nlabels, we observe not only the expected performance degradation in accuracy\nand F1 score, but also increased instability across training runs and premature\nperformance plateaus. These findings cast doubts on the reliability of such\napproaches in real-world applications. We contextualize the observed phenomena\nthrough the lens of error propagation and offer several practical mitigation\nstrategies, including entropy-based filtering and ensemble techniques. Although\nthese heuristics offer partial relief, they do not fully resolve the inherent\nrisks of propagating non-random errors from LLM annotations to smaller\nclassifiers, underscoring the need for caution when applying this workflow in\nhigh-stakes text classification tasks.", "AI": {"tldr": "Using LLM-generated labels to fine-tune smaller models for text classification shows performance degradation, instability, and premature plateaus compared to gold labels, raising reliability concerns. Mitigation strategies like entropy filtering help but don't eliminate risks.", "motivation": "To investigate the reliability of using LLM-generated labels for fine-tuning smaller models in text classification, especially in high-stakes applications.", "method": "Empirical analysis comparing models trained on LLM-generated labels versus gold labels, measuring accuracy, F1 score, stability, and performance plateaus.", "result": "Degraded performance, increased instability, and premature plateaus in models trained on synthetic data. Mitigation strategies like entropy-based filtering and ensembles offer partial relief.", "conclusion": "Caution is needed when using LLM-generated labels for high-stakes tasks, as inherent risks of error propagation remain unresolved."}}
{"id": "2504.15676", "pdf": "https://arxiv.org/pdf/2504.15676", "abs": "https://arxiv.org/abs/2504.15676", "authors": ["Fernando Castillo", "Oscar Castillo", "Eduardo Brito", "Simon Espinola"], "title": "Trustworthy Decentralized Autonomous Machines: A New Paradigm in Automation Economy", "categories": ["cs.MA", "cs.CR"], "comment": "To be published in IEEE International Workshop on Decentralized\n  Physical Infrastructure Networks 2025, in conjunction with ICBC'25. 7 pages.\n  3 figures", "summary": "Decentralized Autonomous Machines (DAMs) represent a transformative paradigm\nin automation economy, integrating artificial intelligence (AI), blockchain\ntechnology, and Internet of Things (IoT) devices to create self-governing\neconomic agents participating in Decentralized Physical Infrastructure Networks\n(DePIN). Capable of managing both digital and physical assets and unlike\ntraditional Decentralized Autonomous Organizations (DAOs), DAMs extend autonomy\ninto the physical world, enabling trustless systems for Real and Digital World\nAssets (RDWAs). In this paper, we explore the technological foundations, and\nchallenges of DAMs and argue that DAMs are pivotal in transitioning from\ntrust-based to trustless economic models, offering scalable, transparent, and\nequitable solutions for asset management. The integration of AI-driven\ndecision-making, IoT-enabled operational autonomy, and blockchain-based\ngovernance allows DAMs to decentralize ownership, optimize resource allocation,\nand democratize access to economic opportunities. Therefore, in this research,\nwe highlight the potential of DAMs to address inefficiencies in centralized\nsystems, reduce wealth disparities, and foster a post-labor economy.", "AI": {"tldr": "DAMs combine AI, blockchain, and IoT to create self-governing economic agents, enabling trustless management of digital and physical assets.", "motivation": "To transition from trust-based to trustless economic models and address inefficiencies in centralized systems.", "method": "Integration of AI-driven decision-making, IoT autonomy, and blockchain governance.", "result": "DAMs offer scalable, transparent, and equitable solutions for asset management.", "conclusion": "DAMs can reduce wealth disparities and foster a post-labor economy."}}
{"id": "2504.15575", "pdf": "https://arxiv.org/pdf/2504.15575", "abs": "https://arxiv.org/abs/2504.15575", "authors": ["Haohe Liu", "Thomas Deacon", "Wenwu Wang", "Matt Paradis", "Mark D. Plumbley"], "title": "Exploring the User Experience of AI-Assisted Sound Searching Systems for Creative Workflows", "categories": ["eess.AS", "cs.SD"], "comment": null, "summary": "Locating the right sound effect efficiently is an important yet challenging\ntopic for audio production. Most current sound-searching systems rely on\npre-annotated audio labels created by humans, which can be time-consuming to\nproduce and prone to inaccuracies, limiting the efficiency of audio production.\nFollowing the recent advancement of contrastive language-audio pre-training\n(CLAP) models, we explore an alternative CLAP-based sound-searching system\n(CLAP-UI) that does not rely on human annotations. To evaluate the\neffectiveness of CLAP-UI, we conducted comparative experiments with a widely\nused sound effect searching platform, the BBC Sound Effect Library. Our study\nevaluates user performance, cognitive load, and satisfaction through\necologically valid tasks based on professional sound-searching workflows. Our\nresult shows that CLAP-UI demonstrated significantly enhanced productivity and\nreduced frustration while maintaining comparable cognitive demands. We also\nqualitatively analyzed the participants' feedback, which offered valuable\nperspectives on the design of future AI-assisted sound search systems.", "AI": {"tldr": "CLAP-UI, a CLAP-based sound-searching system, outperforms traditional human-annotated systems in productivity and user satisfaction while maintaining cognitive demands.", "motivation": "Current sound-searching systems rely on time-consuming and error-prone human annotations, limiting efficiency.", "method": "Developed CLAP-UI, a system using contrastive language-audio pre-training (CLAP) without human annotations, and compared it with the BBC Sound Effect Library.", "result": "CLAP-UI significantly improved productivity and reduced frustration, with comparable cognitive load.", "conclusion": "CLAP-UI is a promising alternative to traditional systems, with insights for future AI-assisted sound search designs."}}
{"id": "2504.15822", "pdf": "https://arxiv.org/pdf/2504.15822", "abs": "https://arxiv.org/abs/2504.15822", "authors": ["Scott Wellington", "Xuechen Liu", "Junichi Yamagishi"], "title": "Quantifying Source Speaker Leakage in One-to-One Voice Conversion", "categories": ["cs.SD", "cs.CR", "eess.AS"], "comment": "Accepted at IEEE 23rd International Conference of the Biometrics\n  Special Interest Group (BIOSIG 2024)", "summary": "Using a multi-accented corpus of parallel utterances for use with commercial\nspeech devices, we present a case study to show that it is possible to quantify\na degree of confidence about a source speaker's identity in the case of\none-to-one voice conversion. Following voice conversion using a HiFi-GAN\nvocoder, we compare information leakage for a range speaker characteristics;\nassuming a \"worst-case\" white-box scenario, we quantify our confidence to\nperform inference and narrow the pool of likely source speakers, reinforcing\nthe regulatory obligation and moral duty that providers of synthetic voices\nhave to ensure the privacy of their speakers' data.", "AI": {"tldr": "The paper demonstrates a method to quantify confidence in identifying source speakers in one-to-one voice conversion, using a multi-accented corpus and HiFi-GAN vocoder, highlighting privacy concerns.", "motivation": "To address privacy risks in synthetic voice technology by quantifying information leakage in voice conversion.", "method": "Uses a multi-accented corpus and HiFi-GAN vocoder for voice conversion, analyzing speaker characteristics in a white-box scenario.", "result": "Shows it's possible to infer and narrow down source speakers, emphasizing privacy risks.", "conclusion": "Highlights the need for providers of synthetic voices to protect speaker data privacy."}}
{"id": "2504.15304", "pdf": "https://arxiv.org/pdf/2504.15304", "abs": "https://arxiv.org/abs/2504.15304", "authors": ["Kangyu Wang"], "title": "Can Machine Learning Agents Deal with Hard Choices?", "categories": ["cs.AI"], "comment": "22 pages excluding bibliography, 27 pagas including bibliography, 3\n  figures", "summary": "Machine Learning ML agents have been increasingly used in decision-making\nacross a wide range of tasks and environments. These ML agents are typically\ndesigned to balance multiple objectives when making choices. Understanding how\ntheir decision-making processes align with or diverge from human reasoning is\nessential. Human agents often encounter hard choices, that is, situations where\noptions are incommensurable; neither option is preferred, yet the agent is not\nindifferent between them. In such cases, human agents can identify hard choices\nand resolve them through deliberation. In contrast, current ML agents, due to\nfundamental limitations in Multi-Objective Optimisation or MOO methods, cannot\nidentify hard choices, let alone resolve them. Neither Scalarised Optimisation\nnor Pareto Optimisation, the two principal MOO approaches, can capture\nincommensurability. This limitation generates three distinct alignment\nproblems: the alienness of ML decision-making behaviour from a human\nperspective; the unreliability of preference-based alignment strategies for\nhard choices; and the blockage of alignment strategies pursuing multiple\nobjectives. Evaluating two potential technical solutions, I recommend an\nensemble solution that appears most promising for enabling ML agents to\nidentify hard choices and mitigate alignment problems. However, no known\ntechnique allows ML agents to resolve hard choices through deliberation, as\nthey cannot autonomously change their goals. This underscores the\ndistinctiveness of human agency and urges ML researchers to reconceptualise\nmachine autonomy and develop frameworks and methods that can better address\nthis fundamental gap.", "AI": {"tldr": "ML agents struggle with hard choices due to limitations in Multi-Objective Optimisation, unlike humans who deliberate. Proposed ensemble solution helps identify but not resolve hard choices, highlighting a gap in machine autonomy.", "motivation": "Understanding how ML agents' decision-making diverges from human reasoning, especially in hard choices, is crucial for alignment and reliability.", "method": "Analyzes limitations of Scalarised and Pareto Optimisation in capturing incommensurability and evaluates two potential technical solutions.", "result": "An ensemble solution is recommended for identifying hard choices, but no method exists for resolving them like humans do.", "conclusion": "Highlights the need to reconceptualize machine autonomy to bridge the gap between human and ML decision-making."}}
{"id": "2504.15300", "pdf": "https://arxiv.org/pdf/2504.15300", "abs": "https://arxiv.org/abs/2504.15300", "authors": ["Chaoyue Niu", "Yucheng Ding", "Junhui Lu", "Zhengxiang Huang", "Hang Zeng", "Yutong Dai", "Xuezhen Tu", "Chengfei Lv", "Fan Wu", "Guihai Chen"], "title": "Collaborative Learning of On-Device Small Model and Cloud-Based Large Model: Advances and Future Directions", "categories": ["cs.LG", "cs.DC", "cs.MA"], "comment": null, "summary": "The conventional cloud-based large model learning framework is increasingly\nconstrained by latency, cost, personalization, and privacy concerns. In this\nsurvey, we explore an emerging paradigm: collaborative learning between\non-device small model and cloud-based large model, which promises low-latency,\ncost-efficient, and personalized intelligent services while preserving user\nprivacy. We provide a comprehensive review across hardware, system, algorithm,\nand application layers. At each layer, we summarize key problems and recent\nadvances from both academia and industry. In particular, we categorize\ncollaboration algorithms into data-based, feature-based, and parameter-based\nframeworks. We also review publicly available datasets and evaluation metrics\nwith user-level or device-level consideration tailored to collaborative\nlearning settings. We further highlight real-world deployments, ranging from\nrecommender systems and mobile livestreaming to personal intelligent\nassistants. We finally point out open research directions to guide future\ndevelopment in this rapidly evolving field.", "AI": {"tldr": "The paper surveys collaborative learning between on-device small models and cloud-based large models, addressing latency, cost, personalization, and privacy concerns. It reviews hardware, system, algorithm, and application layers, categorizing collaboration algorithms and highlighting real-world deployments.", "motivation": "To address the limitations of conventional cloud-based large model learning, such as latency, cost, personalization, and privacy issues, by exploring collaborative learning between on-device small models and cloud-based large models.", "method": "The paper provides a comprehensive review across hardware, system, algorithm, and application layers, categorizing collaboration algorithms into data-based, feature-based, and parameter-based frameworks. It also reviews datasets and evaluation metrics tailored to collaborative learning.", "result": "The survey highlights real-world deployments in recommender systems, mobile livestreaming, and personal intelligent assistants, showcasing the effectiveness of the collaborative learning paradigm.", "conclusion": "The paper identifies open research directions to guide future development in collaborative learning, emphasizing its potential for low-latency, cost-efficient, and privacy-preserving intelligent services."}}
{"id": "2504.15309", "pdf": "https://arxiv.org/pdf/2504.15309", "abs": "https://arxiv.org/abs/2504.15309", "authors": ["Anran Yu", "Wei Feng", "Yaochen Zhang", "Xiang Li", "Lei Meng", "Lei Wu", "Xiangxu Meng"], "title": "LLM-Enabled Style and Content Regularization for Personalized Text-to-Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "The personalized text-to-image generation has rapidly advanced with the\nemergence of Stable Diffusion. Existing methods, which typically fine-tune\nmodels using embedded identifiers, often struggle with insufficient stylization\nand inaccurate image content due to reduced textual controllability. In this\npaper, we propose style refinement and content preservation strategies. The\nstyle refinement strategy leverages the semantic information of visual\nreasoning prompts and reference images to optimize style embeddings, allowing a\nmore precise and consistent representation of style information. The content\npreservation strategy addresses the content bias problem by preserving the\nmodel's generalization capabilities, ensuring enhanced textual controllability\nwithout compromising stylization. Experimental results verify that our approach\nachieves superior performance in generating consistent and personalized\ntext-to-image outputs.", "AI": {"tldr": "Proposes style refinement and content preservation strategies for personalized text-to-image generation, improving stylization and textual controllability.", "motivation": "Existing methods struggle with insufficient stylization and inaccurate image content due to reduced textual controllability.", "method": "Uses style refinement (optimizing style embeddings via visual reasoning prompts and reference images) and content preservation (maintaining model generalization).", "result": "Achieves superior performance in generating consistent and personalized text-to-image outputs.", "conclusion": "The approach effectively balances stylization and textual controllability."}}
{"id": "2504.15376", "pdf": "https://arxiv.org/pdf/2504.15376", "abs": "https://arxiv.org/abs/2504.15376", "authors": ["Zhiqiu Lin", "Siyuan Cen", "Daniel Jiang", "Jay Karhade", "Hewei Wang", "Chancharik Mitra", "Tiffany Ling", "Yuhan Huang", "Sifan Liu", "Mingyu Chen", "Rushikesh Zawar", "Xue Bai", "Yilun Du", "Chuang Gan", "Deva Ramanan"], "title": "Towards Understanding Camera Motions in Any Video", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "comment": "Project site: https://linzhiqiu.github.io/papers/camerabench/", "summary": "We introduce CameraBench, a large-scale dataset and benchmark designed to\nassess and improve camera motion understanding. CameraBench consists of ~3,000\ndiverse internet videos, annotated by experts through a rigorous multi-stage\nquality control process. One of our contributions is a taxonomy of camera\nmotion primitives, designed in collaboration with cinematographers. We find,\nfor example, that some motions like \"follow\" (or tracking) require\nunderstanding scene content like moving subjects. We conduct a large-scale\nhuman study to quantify human annotation performance, revealing that domain\nexpertise and tutorial-based training can significantly enhance accuracy. For\nexample, a novice may confuse zoom-in (a change of intrinsics) with translating\nforward (a change of extrinsics), but can be trained to differentiate the two.\nUsing CameraBench, we evaluate Structure-from-Motion (SfM) and Video-Language\nModels (VLMs), finding that SfM models struggle to capture semantic primitives\nthat depend on scene content, while VLMs struggle to capture geometric\nprimitives that require precise estimation of trajectories. We then fine-tune a\ngenerative VLM on CameraBench to achieve the best of both worlds and showcase\nits applications, including motion-augmented captioning, video question\nanswering, and video-text retrieval. We hope our taxonomy, benchmark, and\ntutorials will drive future efforts towards the ultimate goal of understanding\ncamera motions in any video.", "AI": {"tldr": "CameraBench is a dataset and benchmark for camera motion understanding, featuring expert-annotated videos and a taxonomy of motion primitives. It evaluates SfM and VLMs, and fine-tunes a generative VLM for improved performance.", "motivation": "To advance camera motion understanding by providing a large-scale, high-quality dataset and benchmark, addressing gaps in existing methods.", "method": "Created CameraBench with ~3,000 annotated videos, a taxonomy of motion primitives, and conducted human studies to assess annotation accuracy. Evaluated SfM and VLMs, then fine-tuned a generative VLM.", "result": "SfM models struggle with semantic primitives, while VLMs struggle with geometric primitives. Fine-tuning a generative VLM improved performance across tasks like captioning and retrieval.", "conclusion": "CameraBench, with its taxonomy and tutorials, aims to drive future research in understanding camera motions, bridging gaps between semantic and geometric understanding."}}
{"id": "2504.15311", "pdf": "https://arxiv.org/pdf/2504.15311", "abs": "https://arxiv.org/abs/2504.15311", "authors": ["Fei Shang", "Haohua Du", "Dawei Yan", "Panlong Yang", "Xiang-Yang Li"], "title": "RINN: One Sample Radio Frequency Imaging based on Physics Informed Neural Network", "categories": ["eess.IV", "cs.AI"], "comment": null, "summary": "Due to its ability to work in non-line-of-sight and low-light environments,\nradio frequency (RF) imaging technology is expected to bring new possibilities\nfor embodied intelligence and multimodal sensing. However, widely used RF\ndevices (such as Wi-Fi) often struggle to provide high-precision\nelectromagnetic measurements and large-scale datasets, hindering the\napplication of RF imaging technology. In this paper, we combine the ideas of\nPINN to design the RINN network, using physical constraints instead of true\nvalue comparison constraints and adapting it with the characteristics of\nubiquitous RF signals, allowing the RINN network to achieve RF imaging using\nonly one sample without phase and with amplitude noise. Our numerical\nevaluation results show that compared with 5 classic algorithms based on phase\ndata for imaging results, RINN's imaging results based on phaseless data are\ngood, with indicators such as RRMSE (0.11) performing similarly well. RINN\nprovides new possibilities for the universal development of radio frequency\nimaging technology.", "AI": {"tldr": "RINN network uses physical constraints for RF imaging with noisy, phaseless data, outperforming classic phase-based methods.", "motivation": "RF imaging is limited by low precision and lack of large datasets; RINN addresses this by leveraging physical constraints.", "method": "Combines PINN ideas to design RINN, using physical constraints instead of true value comparison, adapting to RF signal characteristics.", "result": "RINN achieves good imaging with phaseless, noisy data (RRMSE 0.11), comparable to phase-based methods.", "conclusion": "RINN enables universal RF imaging development by overcoming data and precision limitations."}}
{"id": "2504.15471", "pdf": "https://arxiv.org/pdf/2504.15471", "abs": "https://arxiv.org/abs/2504.15471", "authors": ["Tyler A. Chang", "Benjamin K. Bergen"], "title": "Bigram Subnetworks: Mapping to Next Tokens in Transformer Language Models", "categories": ["cs.CL"], "comment": null, "summary": "In Transformer language models, activation vectors transform from current\ntoken embeddings to next token predictions as they pass through the model. To\nisolate a minimal form of this transformation, we identify language model\nsubnetworks that make bigram predictions, naive next token predictions based\nonly on the current token. We find that bigram subnetworks can be found in\nfully trained language models up to 1B parameters, and these subnetworks are\ncritical for model performance even when they consist of less than 0.2% of\nmodel parameters. Bigram subnetworks are concentrated in the first Transformer\nMLP layer, and they overlap significantly with subnetworks trained to optimally\nprune a given model. Mechanistically, the bigram subnetworks often recreate a\npattern from the full models where the first layer induces a sharp change that\naligns activations with next token predictions rather than current token\nrepresentations. Our results demonstrate that bigram subnetworks comprise a\nminimal subset of parameters that are both necessary and sufficient for basic\nnext token predictions in language models, and they help drive the\ntransformation from current to next token activations in the residual stream.\nThese subnetworks can lay a foundation for studying language model circuits by\nbuilding up from a minimal circuit rather than the traditional approach of\nablating circuits from a full model.", "AI": {"tldr": "Bigram subnetworks in Transformer models are minimal, critical for performance, and concentrated in the first MLP layer, aiding next token predictions.", "motivation": "To isolate and understand the minimal transformation from current token embeddings to next token predictions in language models.", "method": "Identify and analyze bigram subnetworks in fully trained language models up to 1B parameters.", "result": "Bigram subnetworks are critical for performance, concentrated in the first MLP layer, and overlap with optimal pruning subnetworks.", "conclusion": "Bigram subnetworks are necessary and sufficient for basic next token predictions, providing a foundation for studying model circuits."}}
{"id": "2504.16010", "pdf": "https://arxiv.org/pdf/2504.16010", "abs": "https://arxiv.org/abs/2504.16010", "authors": ["Tuong Manh Vu", "Ernesto Carrella", "Robert Axtell", "Omar A. Guerrero"], "title": "The Formation of Production Networks: How Supply Chains Arise from Simple Learning with Minimal Information", "categories": ["cs.MA", "cs.LG", "econ.GN", "q-fin.EC"], "comment": null, "summary": "We develop a model where firms determine the price at which they sell their\ndifferentiable goods, the volume that they produce, and the inputs (types and\namounts) that they purchase from other firms. A steady-state production network\nemerges endogenously without resorting to assumptions such as equilibrium or\nperfect knowledge about production technologies. Through a simple version of\nreinforcement learning, firms with heterogeneous technologies cope with\nuncertainty and maximize profits. Due to this learning process, firms can adapt\nto shocks such as demand shifts, suppliers/clients closure, productivity\nchanges, and production technology modifications; effectively reshaping the\nproduction network. To demonstrate the potential of this model, we analyze the\nupstream and downstream impact of demand and productivity shocks.", "AI": {"tldr": "A model where firms use reinforcement learning to set prices, production volumes, and input choices, forming a dynamic production network without equilibrium assumptions.", "motivation": "To understand how firms adapt to uncertainty and shocks without relying on equilibrium or perfect knowledge assumptions.", "method": "Firms use reinforcement learning to make decisions, adapting to shocks like demand shifts or productivity changes.", "result": "The model shows firms can reshape the production network dynamically in response to shocks.", "conclusion": "The approach offers a flexible framework for analyzing production networks under uncertainty."}}
{"id": "2504.15663", "pdf": "https://arxiv.org/pdf/2504.15663", "abs": "https://arxiv.org/abs/2504.15663", "authors": ["Ju Yeon Kang", "Ji Won Yoon", "Semin Kim", "Min Hyun Han", "Nam Soo Kim"], "title": "FADEL: Uncertainty-aware Fake Audio Detection with Evidential Deep Learning", "categories": ["eess.AS", "cs.AI"], "comment": "Accepted at ICASSP 2025", "summary": "Recently, fake audio detection has gained significant attention, as\nadvancements in speech synthesis and voice conversion have increased the\nvulnerability of automatic speaker verification (ASV) systems to spoofing\nattacks. A key challenge in this task is generalizing models to detect unseen,\nout-of-distribution (OOD) attacks. Although existing approaches have shown\npromising results, they inherently suffer from overconfidence issues due to the\nusage of softmax for classification, which can produce unreliable predictions\nwhen encountering unpredictable spoofing attempts. To deal with this\nlimitation, we propose a novel framework called fake audio detection with\nevidential learning (FADEL). By modeling class probabilities with a Dirichlet\ndistribution, FADEL incorporates model uncertainty into its predictions,\nthereby leading to more robust performance in OOD scenarios. Experimental\nresults on the ASVspoof2019 Logical Access (LA) and ASVspoof2021 LA datasets\nindicate that the proposed method significantly improves the performance of\nbaseline models. Furthermore, we demonstrate the validity of uncertainty\nestimation by analyzing a strong correlation between average uncertainty and\nequal error rate (EER) across different spoofing algorithms.", "AI": {"tldr": "Fake audio detection is critical due to spoofing attacks on ASV systems. The proposed FADEL framework uses evidential learning to improve robustness against unseen attacks by modeling uncertainty.", "motivation": "Advancements in speech synthesis increase spoofing risks, but current methods overconfidently classify unpredictable attacks.", "method": "FADEL models class probabilities with a Dirichlet distribution to incorporate uncertainty, enhancing OOD detection.", "result": "FADEL outperforms baselines on ASVspoof2019 and ASVspoof2021 datasets, with uncertainty correlating to EER.", "conclusion": "FADEL's evidential learning effectively addresses overconfidence, improving fake audio detection robustness."}}
{"id": "2504.15509", "pdf": "https://arxiv.org/pdf/2504.15509", "abs": "https://arxiv.org/abs/2504.15509", "authors": ["Keqi Deng", "Wenxi Chen", "Xie Chen", "Philip C. Woodland"], "title": "SimulS2S-LLM: Unlocking Simultaneous Inference of Speech LLMs for Speech-to-Speech Translation", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "Simultaneous speech translation (SST) outputs translations in parallel with\nstreaming speech input, balancing translation quality and latency. While large\nlanguage models (LLMs) have been extended to handle the speech modality,\nstreaming remains challenging as speech is prepended as a prompt for the entire\ngeneration process. To unlock LLM streaming capability, this paper proposes\nSimulS2S-LLM, which trains speech LLMs offline and employs a test-time policy\nto guide simultaneous inference. SimulS2S-LLM alleviates the mismatch between\ntraining and inference by extracting boundary-aware speech prompts that allows\nit to be better matched with text input data. SimulS2S-LLM achieves\nsimultaneous speech-to-speech translation (Simul-S2ST) by predicting discrete\noutput speech tokens and then synthesising output speech using a pre-trained\nvocoder. An incremental beam search is designed to expand the search space of\nspeech token prediction without increasing latency. Experiments on the CVSS\nspeech data show that SimulS2S-LLM offers a better translation quality-latency\ntrade-off than existing methods that use the same training data, such as\nimproving ASR-BLEU scores by 3 points at similar latency.", "AI": {"tldr": "SimulS2S-LLM enables simultaneous speech-to-speech translation using LLMs by training offline and guiding inference with boundary-aware prompts, improving quality-latency trade-offs.", "motivation": "To address the challenge of streaming speech translation with LLMs, which struggle with prepended speech prompts during generation.", "method": "Proposes SimulS2S-LLM, which trains speech LLMs offline, uses boundary-aware prompts for alignment, and employs incremental beam search for token prediction.", "result": "Achieves better translation quality-latency trade-offs, improving ASR-BLEU scores by 3 points at similar latency.", "conclusion": "SimulS2S-LLM effectively bridges the gap between training and inference for simultaneous speech translation, outperforming existing methods."}}
{"id": "2504.15313", "pdf": "https://arxiv.org/pdf/2504.15313", "abs": "https://arxiv.org/abs/2504.15313", "authors": ["Yajie Yu", "Yue Feng"], "title": "PolicyEvol-Agent: Evolving Policy via Environment Perception and Self-Awareness with Theory of Mind", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Multi-agents has exhibited significant intelligence in real-word simulations\nwith Large language models (LLMs) due to the capabilities of social cognition\nand knowledge retrieval. However, existing research on agents equipped with\neffective cognition chains including reasoning, planning, decision-making and\nreflecting remains limited, especially in the dynamically interactive\nscenarios. In addition, unlike human, prompt-based responses face challenges in\npsychological state perception and empirical calibration during uncertain\ngaming process, which can inevitably lead to cognition bias. In light of above,\nwe introduce PolicyEvol-Agent, a comprehensive LLM-empowered framework\ncharacterized by systematically acquiring intentions of others and adaptively\noptimizing irrational strategies for continual enhancement. Specifically,\nPolicyEvol-Agent first obtains reflective expertise patterns and then\nintegrates a range of cognitive operations with Theory of Mind alongside\ninternal and external perspectives. Simulation results, outperforming RL-based\nmodels and agent-based methods, demonstrate the superiority of PolicyEvol-Agent\nfor final gaming victory. Moreover, the policy evolution mechanism reveals the\neffectiveness of dynamic guideline adjustments in both automatic and human\nevaluation.", "AI": {"tldr": "PolicyEvol-Agent, an LLM-powered framework, enhances multi-agent intelligence by integrating cognitive operations and dynamic policy adjustments, outperforming existing methods in gaming simulations.", "motivation": "Addressing limitations in current multi-agent systems, particularly in dynamic interactions and cognitive bias, by improving social cognition and adaptive strategy optimization.", "method": "PolicyEvol-Agent combines reflective expertise patterns, cognitive operations (reasoning, planning, decision-making), and Theory of Mind for adaptive strategy optimization.", "result": "Outperforms RL-based and agent-based models in gaming simulations, demonstrating superior performance and dynamic policy effectiveness.", "conclusion": "PolicyEvol-Agent effectively addresses cognitive bias and enhances multi-agent intelligence through adaptive policy evolution, validated by simulations and evaluations."}}
{"id": "2504.15310", "pdf": "https://arxiv.org/pdf/2504.15310", "abs": "https://arxiv.org/abs/2504.15310", "authors": ["Syeda Tahreem Zahra", "Syed Kashif Imdad", "Sohail Khan", "Sohail Khalid", "Nauman Anwar Baig"], "title": "Power Transformer Health Index and Life Span Assessment: A Comprehensive Review of Conventional and Machine Learning based Approaches", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Power transformers play a critical role within the electrical power system,\nmaking their health assessment and the prediction of their remaining lifespan\nparamount for the purpose of ensuring efficient operation and facilitating\neffective maintenance planning. This paper undertakes a comprehensive\nexamination of existent literature, with a primary focus on both conventional\nand cutting-edge techniques employed within this domain. The merits and\ndemerits of recent methodologies and techniques are subjected to meticulous\nscrutiny and explication. Furthermore, this paper expounds upon intelligent\nfault diagnosis methodologies and delves into the most widely utilized\nintelligent algorithms for the assessment of transformer conditions. Diverse\nArtificial Intelligence (AI) approaches, including Artificial Neural Networks\n(ANN) and Convolutional Neural Network (CNN), Support Vector Machine (SVM),\nRandom Forest (RF), Genetic Algorithm (GA), and Particle Swarm Optimization\n(PSO), are elucidated offering pragmatic solutions for enhancing the\nperformance of transformer fault diagnosis. The amalgamation of multiple AI\nmethodologies and the exploration of timeseries analysis further contribute to\nthe augmentation of diagnostic precision and the early detection of faults in\ntransformers. By furnishing a comprehensive panorama of AI applications in the\nfield of transformer fault diagnosis, this study lays the groundwork for future\nresearch endeavors and the progression of this critical area of study.", "AI": {"tldr": "The paper reviews AI-based techniques for transformer fault diagnosis, analyzing their pros and cons, and explores combining methods for improved accuracy.", "motivation": "To enhance transformer health assessment and lifespan prediction for efficient operation and maintenance planning.", "method": "Examines conventional and advanced techniques, focusing on AI algorithms like ANN, CNN, SVM, RF, GA, and PSO, and explores timeseries analysis.", "result": "Identifies strengths and weaknesses of AI methods and demonstrates their potential for precise fault diagnosis and early detection.", "conclusion": "Provides a foundation for future research in AI applications for transformer fault diagnosis."}}
{"id": "2504.15362", "pdf": "https://arxiv.org/pdf/2504.15362", "abs": "https://arxiv.org/abs/2504.15362", "authors": ["Yuan-Hong Liao", "Sven Elflein", "Liu He", "Laura Leal-Taix\u00e9", "Yejin Choi", "Sanja Fidler", "David Acuna"], "title": "LongPerceptualThoughts: Distilling System-2 Reasoning for System-1 Perception", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "24 pages, 10 figures, in submission. Project page:\n  https://andrewliao11.github.io/LongPerceptualThoughts", "summary": "Recent reasoning models through test-time scaling have demonstrated that long\nchain-of-thoughts can unlock substantial performance boosts in hard reasoning\ntasks such as math and code. However, the benefit of such long thoughts for\nsystem-2 reasoning is relatively less explored in other domains such as\nperceptual tasks where shallower, system-1 reasoning seems sufficient. In this\npaper, we introduce LongPerceptualThoughts, a new synthetic dataset with 30K\nlong-thought traces for perceptual tasks. The key challenges in synthesizing\nelaborate reasoning thoughts for perceptual tasks are that off-the-shelf models\nare not yet equipped with such thinking behavior and that it is not\nstraightforward to build a reliable process verifier for perceptual tasks.\nThus, we propose a novel three-stage data synthesis framework that first\nsynthesizes verifiable multiple-choice questions from dense image descriptions,\nthen extracts simple CoTs from VLMs for those verifiable problems, and finally\nexpands those simple thoughts to elaborate long thoughts via frontier reasoning\nmodels. In controlled experiments with a strong instruction-tuned 7B model, we\ndemonstrate notable improvements over existing visual reasoning data-generation\nmethods. Our model, trained on the generated dataset, achieves an average +3.4\npoints improvement over 5 vision-centric benchmarks, including +11.8 points on\nV$^*$ Bench. Notably, despite being tuned for vision tasks, it also improves\nperformance on the text reasoning benchmark, MMLU-Pro, by +2 points.", "AI": {"tldr": "LongPerceptualThoughts introduces a synthetic dataset for perceptual tasks, improving reasoning performance in vision and text benchmarks.", "motivation": "Explore the benefits of long chain-of-thoughts in perceptual tasks, where system-1 reasoning is typically sufficient.", "method": "A three-stage framework synthesizes verifiable questions, extracts simple CoTs, and expands them into long thoughts using frontier models.", "result": "+3.4 points improvement on vision benchmarks, +11.8 on V$^*$ Bench, and +2 on MMLU-Pro.", "conclusion": "LongPerceptualThoughts effectively enhances reasoning in perceptual and text tasks."}}
{"id": "2410.07369", "pdf": "https://arxiv.org/pdf/2410.07369", "abs": "https://arxiv.org/abs/2410.07369", "authors": ["Sam Gunn", "Xuandong Zhao", "Dawn Song"], "title": "An Undetectable Watermark for Generative Image Models", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.MM"], "comment": "ICLR 2025", "summary": "We present the first undetectable watermarking scheme for generative image\nmodels. Undetectability ensures that no efficient adversary can distinguish\nbetween watermarked and un-watermarked images, even after making many adaptive\nqueries. In particular, an undetectable watermark does not degrade image\nquality under any efficiently computable metric. Our scheme works by selecting\nthe initial latents of a diffusion model using a pseudorandom error-correcting\ncode (Christ and Gunn, 2024), a strategy which guarantees undetectability and\nrobustness. We experimentally demonstrate that our watermarks are\nquality-preserving and robust using Stable Diffusion 2.1. Our experiments\nverify that, in contrast to every prior scheme we tested, our watermark does\nnot degrade image quality. Our experiments also demonstrate robustness:\nexisting watermark removal attacks fail to remove our watermark from images\nwithout significantly degrading the quality of the images. Finally, we find\nthat we can robustly encode 512 bits in our watermark, and up to 2500 bits when\nthe images are not subjected to watermark removal attacks. Our code is\navailable at https://github.com/XuandongZhao/PRC-Watermark.", "AI": {"tldr": "An undetectable watermarking scheme for generative image models ensures no degradation in image quality and robustness against removal attacks, encoding up to 512 bits (2500 bits without attacks).", "motivation": "To create a watermarking scheme for generative models that is undetectable and preserves image quality without being removable by adversaries.", "method": "Uses pseudorandom error-correcting codes to select initial latents in a diffusion model, ensuring undetectability and robustness.", "result": "Watermarks are quality-preserving, robust against removal attacks, and can encode 512 bits (2500 bits without attacks).", "conclusion": "The scheme successfully achieves undetectability, quality preservation, and robustness, outperforming prior methods."}}
{"id": "2504.15317", "pdf": "https://arxiv.org/pdf/2504.15317", "abs": "https://arxiv.org/abs/2504.15317", "authors": ["Meher Boulaabi", "Takwa Ben A\u00efcha Gader", "Afef Kacem Echi", "Zied Bouraoui"], "title": "Enhancing DR Classification with Swin Transformer and Shifted Window Attention", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Diabetic retinopathy (DR) is a leading cause of blindness worldwide,\nunderscoring the importance of early detection for effective treatment.\nHowever, automated DR classification remains challenging due to variations in\nimage quality, class imbalance, and pixel-level similarities that hinder model\ntraining. To address these issues, we propose a robust preprocessing pipeline\nincorporating image cropping, Contrast-Limited Adaptive Histogram Equalization\n(CLAHE), and targeted data augmentation to improve model generalization and\nresilience. Our approach leverages the Swin Transformer, which utilizes\nhierarchical token processing and shifted window attention to efficiently\ncapture fine-grained features while maintaining linear computational\ncomplexity. We validate our method on the Aptos and IDRiD datasets for\nmulti-class DR classification, achieving accuracy rates of 89.65% and 97.40%,\nrespectively. These results demonstrate the effectiveness of our model,\nparticularly in detecting early-stage DR, highlighting its potential for\nimproving automated retinal screening in clinical settings.", "AI": {"tldr": "A robust preprocessing pipeline and Swin Transformer model improve diabetic retinopathy classification, achieving high accuracy on Aptos and IDRiD datasets.", "motivation": "Early detection of diabetic retinopathy (DR) is crucial to prevent blindness, but automated classification faces challenges like image quality variations and class imbalance.", "method": "Proposes a preprocessing pipeline (cropping, CLAHE, data augmentation) and uses Swin Transformer for hierarchical feature extraction.", "result": "Achieved 89.65% accuracy on Aptos and 97.40% on IDRiD datasets, excelling in early-stage DR detection.", "conclusion": "The method shows promise for enhancing automated retinal screening in clinical settings."}}
{"id": "2504.15475", "pdf": "https://arxiv.org/pdf/2504.15475", "abs": "https://arxiv.org/abs/2504.15475", "authors": ["Szymon Kobus", "Deniz G\u00fcnd\u00fcz"], "title": "Speculative Sampling via Exponential Races", "categories": ["cs.CL", "cs.IT", "math.IT"], "comment": null, "summary": "Speculative decoding accelerates large language model inference using a\nsmaller draft model. In this paper, we establish a surprising connection\nbetween speculative decoding and channel simulation, which aims at simulating a\nnoisy channel using as few bits as possible. This connection allows us to\nprovide an information-theoretic analysis of the speed up that can be achieved\nby speculative decoding. Leveraging this link, we derive an explicit relation\nbetween generation speed-up and the number of tokens $k$ generated by the draft\nmodel for large $k$, which serves as an upper bound for all $k$. We also\npropose a novel speculative decoding method via exponential race ERSD that\nmatches state-of-the-art performance.", "AI": {"tldr": "Speculative decoding connects to channel simulation for speed-up analysis, proposing ERSD for state-of-the-art performance.", "motivation": "To analyze and improve the speed-up of speculative decoding in large language model inference.", "method": "Information-theoretic analysis linking speculative decoding to channel simulation, and proposing ERSD.", "result": "Derived an explicit relation between speed-up and draft tokens, with ERSD matching top performance.", "conclusion": "Speculative decoding's speed-up is theoretically bounded, and ERSD offers competitive performance."}}
{"id": "2504.15425", "pdf": "https://arxiv.org/pdf/2504.15425", "abs": "https://arxiv.org/abs/2504.15425", "authors": ["Songyuan Zhang", "Oswin So", "Mitchell Black", "Zachary Serlin", "Chuchu Fan"], "title": "Solving Multi-Agent Safe Optimal Control with Distributed Epigraph Form MARL", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA", "math.OC"], "comment": "28 pages, 16 figures; Accepted by Robotics: Science and Systems 2025", "summary": "Tasks for multi-robot systems often require the robots to collaborate and\ncomplete a team goal while maintaining safety. This problem is usually\nformalized as a constrained Markov decision process (CMDP), which targets\nminimizing a global cost and bringing the mean of constraint violation below a\nuser-defined threshold. Inspired by real-world robotic applications, we define\nsafety as zero constraint violation. While many safe multi-agent reinforcement\nlearning (MARL) algorithms have been proposed to solve CMDPs, these algorithms\nsuffer from unstable training in this setting. To tackle this, we use the\nepigraph form for constrained optimization to improve training stability and\nprove that the centralized epigraph form problem can be solved in a distributed\nfashion by each agent. This results in a novel centralized training distributed\nexecution MARL algorithm named Def-MARL. Simulation experiments on 8 different\ntasks across 2 different simulators show that Def-MARL achieves the best\noverall performance, satisfies safety constraints, and maintains stable\ntraining. Real-world hardware experiments on Crazyflie quadcopters demonstrate\nthe ability of Def-MARL to safely coordinate agents to complete complex\ncollaborative tasks compared to other methods.", "AI": {"tldr": "Def-MARL, a novel MARL algorithm, ensures safe multi-robot collaboration by using the epigraph form for constrained optimization, achieving stable training and zero constraint violations.", "motivation": "Real-world robotic applications require zero constraint violations for safety, but existing MARL algorithms for CMDPs suffer from unstable training.", "method": "The paper introduces Def-MARL, which uses the epigraph form for constrained optimization, enabling distributed problem-solving by each agent.", "result": "Def-MARL outperforms other methods in simulations and real-world experiments, ensuring safety and stable training.", "conclusion": "Def-MARL is effective for safe multi-robot collaboration, demonstrating superior performance and stability in both simulations and hardware experiments."}}
{"id": "2504.12867", "pdf": "https://arxiv.org/pdf/2504.12867", "abs": "https://arxiv.org/abs/2504.12867", "authors": ["Guanrou Yang", "Chen Yang", "Qian Chen", "Ziyang Ma", "Wenxi Chen", "Wen Wang", "Tianrui Wang", "Yifan Yang", "Zhikang Niu", "Wenrui Liu", "Fan Yu", "Zhihao Du", "Zhifu Gao", "ShiLiang Zhang", "Xie Chen"], "title": "EmoVoice: LLM-based Emotional Text-To-Speech Model with Freestyle Text Prompting", "categories": ["eess.AS", "cs.AI", "cs.CL"], "comment": null, "summary": "Human speech goes beyond the mere transfer of information; it is a profound\nexchange of emotions and a connection between individuals. While Text-to-Speech\n(TTS) models have made huge progress, they still face challenges in controlling\nthe emotional expression in the generated speech. In this work, we propose\nEmoVoice, a novel emotion-controllable TTS model that exploits large language\nmodels (LLMs) to enable fine-grained freestyle natural language emotion\ncontrol, and a phoneme boost variant design that makes the model output phoneme\ntokens and audio tokens in parallel to enhance content consistency, inspired by\nchain-of-thought (CoT) and chain-of-modality (CoM) techniques. Besides, we\nintroduce EmoVoice-DB, a high-quality 40-hour English emotion dataset featuring\nexpressive speech and fine-grained emotion labels with natural language\ndescriptions. EmoVoice achieves state-of-the-art performance on the English\nEmoVoice-DB test set using only synthetic training data, and on the Chinese\nSecap test set using our in-house data. We further investigate the reliability\nof existing emotion evaluation metrics and their alignment with human\nperceptual preferences, and explore using SOTA multimodal LLMs GPT-4o-audio and\nGemini to assess emotional speech. Demo samples are available at\nhttps://yanghaha0908.github.io/EmoVoice/. Dataset, code, and checkpoints will\nbe released.", "AI": {"tldr": "EmoVoice is a novel emotion-controllable TTS model using LLMs for fine-grained emotion control and phoneme boost for content consistency, achieving SOTA results on English and Chinese datasets.", "motivation": "Current TTS models lack fine-grained emotional control, limiting their ability to convey human-like emotional expression.", "method": "EmoVoice integrates LLMs for natural language emotion control and a phoneme boost variant for parallel phoneme and audio token generation. It also introduces EmoVoice-DB, a high-quality emotion dataset.", "result": "EmoVoice achieves SOTA performance on English and Chinese test sets and evaluates emotion metrics' reliability with human preferences.", "conclusion": "EmoVoice advances emotion-controllable TTS with LLMs and phoneme boost, supported by a new dataset and evaluation framework."}}
{"id": "2405.17615", "pdf": "https://arxiv.org/pdf/2405.17615", "abs": "https://arxiv.org/abs/2405.17615", "authors": ["Francesco Paissan", "Luca Della Libera", "Mirco Ravanelli", "Cem Subakan"], "title": "Listenable Maps for Zero-Shot Audio Classifiers", "categories": ["cs.SD", "cs.LG", "eess.AS", "eess.SP"], "comment": "Accepted to NeurIPS 2024", "summary": "Interpreting the decisions of deep learning models, including audio\nclassifiers, is crucial for ensuring the transparency and trustworthiness of\nthis technology. In this paper, we introduce LMAC-ZS (Listenable Maps for Audio\nClassifiers in the Zero-Shot context), which, to the best of our knowledge, is\nthe first decoder-based post-hoc interpretation method for explaining the\ndecisions of zero-shot audio classifiers. The proposed method utilizes a novel\nloss function that maximizes the faithfulness to the original similarity\nbetween a given text-and-audio pair. We provide an extensive evaluation using\nthe Contrastive Language-Audio Pretraining (CLAP) model to showcase that our\ninterpreter remains faithful to the decisions in a zero-shot classification\ncontext. Moreover, we qualitatively show that our method produces meaningful\nexplanations that correlate well with different text prompts.", "AI": {"tldr": "LMAC-ZS is the first decoder-based post-hoc method for interpreting zero-shot audio classifiers, using a novel loss function for faithfulness and producing meaningful explanations.", "motivation": "To enhance transparency and trustworthiness of deep learning models, especially audio classifiers, by providing interpretable explanations for their decisions.", "method": "Introduces LMAC-ZS, a decoder-based post-hoc interpretation method with a novel loss function to maximize faithfulness to original text-audio pair similarity, evaluated using the CLAP model.", "result": "LMAC-ZS remains faithful to zero-shot classification decisions and produces meaningful explanations correlating well with text prompts.", "conclusion": "LMAC-ZS effectively interprets zero-shot audio classifiers, offering transparency and trustworthiness through faithful and meaningful explanations."}}
{"id": "2504.15360", "pdf": "https://arxiv.org/pdf/2504.15360", "abs": "https://arxiv.org/abs/2504.15360", "authors": ["Javier Fumanal-Idocin", "Javier Andreu-Perez"], "title": "Reliable Classification with Conformal Learning and Interval-Type 2 Fuzzy Sets", "categories": ["cs.AI"], "comment": null, "summary": "Classical machine learning classifiers tend to be overconfident can be\nunreliable outside of the laboratory benchmarks. Properly assessing the\nreliability of the output of the model per sample is instrumental for real-life\nscenarios where these systems are deployed. Because of this, different\ntechniques have been employed to properly quantify the quality of prediction\nfor a given model. These are most commonly Bayesian statistics and, more\nrecently, conformal learning. Given a calibration set, conformal learning can\nproduce outputs that are guaranteed to cover the target class with a desired\nsignificance level, and are more reliable than the standard confidence\nintervals used by Bayesian methods. In this work, we propose to use conformal\nlearning with fuzzy rule-based systems in classification and show some metrics\nof their performance. Then, we discuss how the use of type 2 fuzzy sets can\nimprove the quality of the output of the system compared to both fuzzy and\ncrisp rules. Finally, we also discuss how the fine-tuning of the system can be\nadapted to improve the quality of the conformal prediction.", "AI": {"tldr": "The paper explores using conformal learning with fuzzy rule-based systems to improve prediction reliability, comparing it to Bayesian methods and highlighting the benefits of type 2 fuzzy sets.", "motivation": "Classical ML classifiers are often overconfident and unreliable in real-world scenarios, necessitating better methods to assess prediction reliability.", "method": "The study employs conformal learning with fuzzy rule-based systems, comparing their performance to Bayesian methods and exploring the impact of type 2 fuzzy sets.", "result": "Conformal learning with fuzzy systems provides more reliable predictions than Bayesian methods, with type 2 fuzzy sets further enhancing output quality.", "conclusion": "The work demonstrates the effectiveness of conformal learning with fuzzy systems, particularly with type 2 fuzzy sets, for reliable predictions, and suggests fine-tuning for improved conformal prediction quality."}}
{"id": "2504.15312", "pdf": "https://arxiv.org/pdf/2504.15312", "abs": "https://arxiv.org/abs/2504.15312", "authors": ["Muhammad Mursil", "Hatem A. Rashwan", "Luis Santos-Calderon", "Pere Cavalle-Busquets", "Michelle M. Murphy", "Domenec Puig"], "title": "M-TabNet: A Multi-Encoder Transformer Model for Predicting Neonatal Birth Weight from Multimodal Data", "categories": ["cs.LG"], "comment": null, "summary": "Birth weight (BW) is a key indicator of neonatal health, with low birth\nweight (LBW) linked to increased mortality and morbidity. Early prediction of\nBW enables timely interventions; however, current methods like ultrasonography\nhave limitations, including reduced accuracy before 20 weeks and operator\ndependent variability. Existing models often neglect nutritional and genetic\ninfluences, focusing mainly on physiological and lifestyle factors. This study\npresents an attention-based transformer model with a multi-encoder architecture\nfor early (less than 12 weeks of gestation) BW prediction. Our model\neffectively integrates diverse maternal data such as physiological, lifestyle,\nnutritional, and genetic, addressing limitations seen in prior attention-based\nmodels such as TabNet. The model achieves a Mean Absolute Error (MAE) of 122\ngrams and an R-squared value of 0.94, demonstrating high predictive accuracy\nand interoperability with our in-house private dataset. Independent validation\nconfirms generalizability (MAE: 105 grams, R-squared: 0.95) with the IEEE\nchildren dataset. To enhance clinical utility, predicted BW is classified into\nlow and normal categories, achieving a sensitivity of 97.55% and a specificity\nof 94.48%, facilitating early risk stratification. Model interpretability is\nreinforced through feature importance and SHAP analyses, highlighting\nsignificant influences of maternal age, tobacco exposure, and vitamin B12\nstatus, with genetic factors playing a secondary role. Our results emphasize\nthe potential of advanced deep-learning models to improve early BW prediction,\noffering clinicians a robust, interpretable, and personalized tool for\nidentifying pregnancies at risk and optimizing neonatal outcomes.", "AI": {"tldr": "An attention-based transformer model integrates diverse maternal data for early birth weight prediction, achieving high accuracy and interpretability.", "motivation": "Early prediction of birth weight is crucial for neonatal health, but current methods like ultrasonography have limitations in accuracy and scope. Existing models often overlook nutritional and genetic factors.", "method": "The study uses an attention-based transformer model with a multi-encoder architecture to integrate physiological, lifestyle, nutritional, and genetic data for early prediction (less than 12 weeks of gestation).", "result": "The model achieves high predictive accuracy (MAE: 122 grams, R-squared: 0.94) and generalizability (MAE: 105 grams, R-squared: 0.95). It also performs well in classifying low and normal birth weight (sensitivity: 97.55%, specificity: 94.48%).", "conclusion": "The model demonstrates the potential of deep learning for early birth weight prediction, offering a robust, interpretable tool for clinicians to improve neonatal outcomes."}}
{"id": "2504.15371", "pdf": "https://arxiv.org/pdf/2504.15371", "abs": "https://arxiv.org/abs/2504.15371", "authors": ["Wei Fang", "Priyadarshini Panda"], "title": "Event2Vec: Processing neuromorphic events directly by representations in vector space", "categories": ["cs.CV", "cs.NE"], "comment": null, "summary": "The neuromorphic event cameras have overwhelming advantages in temporal\nresolution, power efficiency, and dynamic range compared to traditional\ncameras. However, the event cameras output asynchronous, sparse, and irregular\nevents, which are not compatible with mainstream computer vision and deep\nlearning methods. Various methods have been proposed to solve this issue but at\nthe cost of long preprocessing procedures, losing temporal resolutions, or\nbeing incompatible with massively parallel computation. Inspired by the great\nsuccess of the word to vector, we summarize the similarities between words and\nevents, then propose the first event to vector (event2vec) representation. We\nvalidate event2vec on classifying the ASL-DVS dataset, showing impressive\nparameter efficiency, accuracy, and speed than previous graph/image/voxel-based\nrepresentations. Beyond task performance, the most attractive advantage of\nevent2vec is that it aligns events to the domain of natural language\nprocessing, showing the promising prospect of integrating events into large\nlanguage and multimodal models. Our codes, models, and training logs are\navailable at https://github.com/fangwei123456/event2vec.", "AI": {"tldr": "The paper introduces 'event2vec,' a novel representation for neuromorphic event cameras, inspired by word embeddings, to address compatibility issues with traditional vision methods. It shows improved efficiency, accuracy, and speed in classification tasks.", "motivation": "Event cameras output sparse, irregular data incompatible with mainstream vision methods. Existing solutions compromise temporal resolution or parallel computation.", "method": "Proposes 'event2vec,' an event-to-vector representation, drawing parallels between words and events. Validated on ASL-DVS dataset classification.", "result": "Demonstrates superior parameter efficiency, accuracy, and speed compared to graph/image/voxel-based methods. Aligns events with NLP for multimodal integration.", "conclusion": "event2vec offers a promising approach for integrating event data into large language and multimodal models, with open-source resources provided."}}
{"id": "2504.10150", "pdf": "https://arxiv.org/pdf/2504.10150", "abs": "https://arxiv.org/abs/2504.10150", "authors": ["Chen Zhang", "Bo Hu", "Weidong Chen", "Zhendong Mao"], "title": "HistLLM: A Unified Framework for LLM-Based Multimodal Recommendation with User History Encoding and Compression", "categories": ["cs.IR", "cs.MM"], "comment": "We want to withdraw this paper and revise its experimental details.\n  The revised version will be uploaded after further verification", "summary": "While large language models (LLMs) have proven effective in leveraging\ntextual data for recommendations, their application to multimodal\nrecommendation tasks remains relatively underexplored. Although LLMs can\nprocess multimodal information through projection functions that map visual\nfeatures into their semantic space, recommendation tasks often require\nrepresenting users' history interactions through lengthy prompts combining text\nand visual elements, which not only hampers training and inference efficiency\nbut also makes it difficult for the model to accurately capture user\npreferences from complex and extended prompts, leading to reduced\nrecommendation performance. To address this challenge, we introduce HistLLM, an\ninnovative multimodal recommendation framework that integrates textual and\nvisual features through a User History Encoding Module (UHEM), compressing\nmultimodal user history interactions into a single token representation,\neffectively facilitating LLMs in processing user preferences. Extensive\nexperiments demonstrate the effectiveness and efficiency of our proposed\nmechanism.", "AI": {"tldr": "HistLLM is a multimodal recommendation framework that compresses user history interactions into a single token for efficient LLM processing, improving recommendation performance.", "motivation": "LLMs struggle with lengthy multimodal prompts in recommendation tasks, reducing efficiency and accuracy.", "method": "Introduces User History Encoding Module (UHEM) to compress multimodal user history into a single token.", "result": "Demonstrates improved effectiveness and efficiency in experiments.", "conclusion": "HistLLM effectively addresses the challenges of multimodal recommendation tasks with LLMs."}}
{"id": "2504.15390", "pdf": "https://arxiv.org/pdf/2504.15390", "abs": "https://arxiv.org/abs/2504.15390", "authors": ["Nikola Janjusevic", "Amirhoussein Khalilian-Gourtani", "Yao Wang", "Li Feng"], "title": "Learned Primal Dual Splitting for Self-Supervised Noise-Adaptive MRI Reconstruction", "categories": ["eess.IV"], "comment": "4 pages, 3 figures, 1 table", "summary": "Magnetic resonance imaging (MRI) reconstruction has largely been dominated by\ndeep neural networks (DNN); however, many state-of-the-art architectures use\nblack-box structures, which hinder interpretability and improvement. Here, we\npropose an interpretable DNN architecture for self-supervised MRI\nreconstruction and denoising by directly parameterizing and learning the\nclassical primal-dual splitting, dubbed LPDSNet. This splitting algorithm\nallows us to decouple the observation model from the signal prior.\nExperimentally, we show other interpretable architectures without this\ndecoupling property exhibit failure in the self-supervised learning regime. We\nreport state-of-the-art self-supervised joint MRI reconstruction and denoising\nperformance and novel noise-level generalization capabilities, where in\ncontrast black-box networks fail to generalize.", "AI": {"tldr": "Proposes LPDSNet, an interpretable DNN for self-supervised MRI reconstruction and denoising, outperforming black-box methods.", "motivation": "Addresses the lack of interpretability in state-of-the-art DNNs for MRI reconstruction, hindering improvement.", "method": "Uses a classical primal-dual splitting algorithm (LPDSNet) to decouple observation model from signal prior.", "result": "Achieves state-of-the-art self-supervised performance and noise-level generalization, where black-box methods fail.", "conclusion": "LPDSNet offers interpretability and superior performance, advancing MRI reconstruction and denoising."}}
{"id": "2504.15521", "pdf": "https://arxiv.org/pdf/2504.15521", "abs": "https://arxiv.org/abs/2504.15521", "authors": ["Minghao Wu", "Weixuan Wang", "Sinuo Liu", "Huifeng Yin", "Xintong Wang", "Yu Zhao", "Chenyang Lyu", "Longyue Wang", "Weihua Luo", "Kaifu Zhang"], "title": "The Bitter Lesson Learned from 2,000+ Multilingual Benchmarks", "categories": ["cs.CL"], "comment": "work in progress; 22 pages, 8 figures, 3 tables;", "summary": "As large language models (LLMs) continue to advance in linguistic\ncapabilities, robust multilingual evaluation has become essential for promoting\nequitable technological progress. This position paper examines over 2,000\nmultilingual (non-English) benchmarks from 148 countries, published between\n2021 and 2024, to evaluate past, present, and future practices in multilingual\nbenchmarking. Our findings reveal that, despite significant investments\namounting to tens of millions of dollars, English remains significantly\noverrepresented in these benchmarks. Additionally, most benchmarks rely on\noriginal language content rather than translations, with the majority sourced\nfrom high-resource countries such as China, India, Germany, the UK, and the\nUSA. Furthermore, a comparison of benchmark performance with human judgments\nhighlights notable disparities. STEM-related tasks exhibit strong correlations\nwith human evaluations (0.70 to 0.85), while traditional NLP tasks like\nquestion answering (e.g., XQuAD) show much weaker correlations (0.11 to 0.30).\nMoreover, translating English benchmarks into other languages proves\ninsufficient, as localized benchmarks demonstrate significantly higher\nalignment with local human judgments (0.68) than their translated counterparts\n(0.47). This underscores the importance of creating culturally and\nlinguistically tailored benchmarks rather than relying solely on translations.\nThrough this comprehensive analysis, we highlight six key limitations in\ncurrent multilingual evaluation practices, propose the guiding principles\naccordingly for effective multilingual benchmarking, and outline five critical\nresearch directions to drive progress in the field. Finally, we call for a\nglobal collaborative effort to develop human-aligned benchmarks that prioritize\nreal-world applications.", "AI": {"tldr": "The paper critiques multilingual benchmarking practices, revealing English overrepresentation and the inadequacy of translations, advocating for culturally tailored benchmarks.", "motivation": "To address inequities in multilingual evaluation and promote equitable progress in large language models (LLMs).", "method": "Analysis of over 2,000 multilingual benchmarks from 148 countries (2021-2024), comparing performance with human judgments.", "result": "English is overrepresented; localized benchmarks outperform translations (0.68 vs. 0.47 correlation with human judgments). STEM tasks align better with humans than NLP tasks.", "conclusion": "Proposes principles for effective multilingual benchmarking and calls for global collaboration to develop human-aligned benchmarks."}}
{"id": "2504.15970", "pdf": "https://arxiv.org/pdf/2504.15970", "abs": "https://arxiv.org/abs/2504.15970", "authors": ["Baichuan Zeng"], "title": "Recent Advances and Future Directions in Extended Reality (XR): Exploring AI-Powered Spatial Intelligence", "categories": ["cs.HC", "cs.CV", "cs.MA"], "comment": "7 pages,4 figures", "summary": "Extended Reality (XR), encompassing Augmented Reality (AR), Virtual Reality\n(VR) and Mixed Reality (MR), is a transformative technology bridging the\nphysical and virtual world and it has diverse potential which will be\nubiquitous in the future. This review examines XR's evolution through\nfoundational framework - hardware ranging from monitors to sensors and software\nranging from visual tasks to user interface; highlights state of the art (SOTA)\nXR products with the comparison and analysis of performance based on their\nfoundational framework; discusses how commercial XR devices can support the\ndemand of high-quality performance focusing on spatial intelligence. For future\ndirections, attention should be given to the integration of multi-modal AI and\nIoT-driven digital twins to enable adaptive XR systems. With the concept of\nspatial intelligence, future XR should establish a new digital space with\nrealistic experience that benefits humanity. This review underscores the\npivotal role of AI in unlocking XR as the next frontier in human-computer\ninteraction.", "AI": {"tldr": "A review of Extended Reality (XR) covering its evolution, current state, and future potential, emphasizing AI and spatial intelligence.", "motivation": "To explore XR's transformative potential in bridging physical and virtual worlds and its future ubiquity.", "method": "Examines XR's hardware, software, and SOTA products, comparing performance and discussing commercial devices' capabilities.", "result": "Highlights the need for multi-modal AI and IoT-driven digital twins to create adaptive XR systems with realistic experiences.", "conclusion": "AI is key to advancing XR as the next frontier in human-computer interaction, benefiting humanity through spatial intelligence."}}
{"id": "2309.13259", "pdf": "https://arxiv.org/pdf/2309.13259", "abs": "https://arxiv.org/abs/2309.13259", "authors": ["Monan Zhou", "Xiaobing Li", "Feng Yu", "Wei Li"], "title": "EMelodyGen: Emotion-Conditioned Melody Generation in ABC Notation with the Musical Feature Template", "categories": ["cs.IR", "cs.AI", "cs.SD", "eess.AS"], "comment": "6 pages, 4 figures, accepted by ICMEW2025", "summary": "The EMelodyGen system focuses on emotional melody generation in ABC notation\ncontrolled by the musical feature template. Owing to the scarcity of\nwell-structured and emotionally labeled sheet music, we designed a template for\ncontrolling emotional melody generation by statistical correlations between\nmusical features and emotion labels derived from small-scale emotional symbolic\nmusic datasets and music psychology conclusions. We then automatically\nannotated a large, well-structured sheet music collection with rough emotional\nlabels by the template, converted them into ABC notation, and reduced label\nimbalance by data augmentation, resulting in a dataset named Rough4Q. Our\nsystem backbone pre-trained on Rough4Q can achieve up to 99% music21 parsing\nrate and melodies generated by our template can lead to a 91% alignment on\nemotional expressions in blind listening tests. Ablation studies further\nvalidated the effectiveness of the feature controls in the template. Available\ncode and demos are at https://github.com/monetjoe/EMelodyGen.", "AI": {"tldr": "EMelodyGen generates emotional melodies in ABC notation using a musical feature template, leveraging small datasets and psychology insights. It achieved high parsing and emotional alignment rates.", "motivation": "Addressing the lack of well-structured, emotionally labeled sheet music for melody generation.", "method": "Designed a template for emotional melody generation, annotated a large dataset (Rough4Q), and used data augmentation to reduce label imbalance.", "result": "Achieved 99% parsing rate and 91% emotional alignment in blind tests. Ablation studies confirmed template effectiveness.", "conclusion": "EMelodyGen successfully generates emotionally aligned melodies, validated by high performance metrics."}}
{"id": "2409.03597", "pdf": "https://arxiv.org/pdf/2409.03597", "abs": "https://arxiv.org/abs/2409.03597", "authors": ["Yucong Zhang", "Xin Zou", "Jinshan Yang", "Wenjun Chen", "Juan Liu", "Faya Liang", "Ming Li"], "title": "Multimodal Laryngoscopic Video Analysis for Assisted Diagnosis of Vocal Fold Paralysis", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Submitted to CSL", "summary": "This paper presents the Multimodal Laryngoscopic Video Analyzing System\n(MLVAS), a novel system that leverages both audio and video data to\nautomatically extract key video segments and metrics from raw laryngeal\nvideostroboscopic videos for assisted clinical assessment. The system\nintegrates video-based glottis detection with an audio keyword spotting method\nto analyze both video and audio data, identifying patient vocalizations and\nrefining video highlights to ensure optimal inspection of vocal fold movements.\nBeyond key video segment extraction from the raw laryngeal videos, MLVAS is\nable to generate effective audio and visual features for Vocal Fold Paralysis\n(VFP) detection. Pre-trained audio encoders are utilized to encode the patient\nvoice to get the audio features. Visual features are generated by measuring the\nangle deviation of both the left and right vocal folds to the estimated glottal\nmidline on the segmented glottis masks. To get better masks, we introduce a\ndiffusion-based refinement that follows traditional U-Net segmentation to\nreduce false positives. We conducted several ablation studies to demonstrate\nthe effectiveness of each module and modalities in the proposed MLVAS. The\nexperimental results on a public segmentation dataset show the effectiveness of\nour proposed segmentation module. In addition, unilateral VFP classification\nresults on a real-world clinic dataset demonstrate MLVAS's ability of providing\nreliable and objective metrics as well as visualization for assisted clinical\ndiagnosis.", "AI": {"tldr": "MLVAS is a system combining audio and video data to analyze laryngeal videos, extracting key segments and features for clinical assessment, including VFP detection.", "motivation": "To improve clinical assessment of vocal fold movements by automating the extraction of key video segments and metrics from laryngeal videos.", "method": "Integrates video-based glottis detection and audio keyword spotting, uses pre-trained audio encoders and diffusion-based refinement for segmentation, and measures vocal fold angles.", "result": "Effective segmentation and VFP classification, validated on public and real-world datasets.", "conclusion": "MLVAS provides reliable, objective metrics and visualization for assisted clinical diagnosis."}}
{"id": "2504.15364", "pdf": "https://arxiv.org/pdf/2504.15364", "abs": "https://arxiv.org/abs/2504.15364", "authors": ["Junyoung Park", "Dalton Jones", "Matt Morse", "Raghavv Goel", "Mingu Lee", "Chris Lott"], "title": "KeDiff: Key Similarity-Based KV Cache Eviction for Long-Context LLM Inference in Resource-Constrained Environments", "categories": ["cs.AI"], "comment": "8 pages, 14 figures", "summary": "In this work, we demonstrate that distinctive keys during LLM inference tend\nto have high attention scores. We explore this phenomenon and propose KeyDiff,\na training-free KV cache eviction method based on key similarity. This method\nfacilitates the deployment of LLM-based application requiring long input\nprompts in resource-constrained environments with limited memory and compute\nbudgets. Unlike other KV cache eviction methods, KeyDiff can process\narbitrarily long prompts within strict resource constraints and efficiently\ngenerate responses. We demonstrate that KeyDiff computes the optimal solution\nto a KV cache selection problem that maximizes key diversity, providing a\ntheoretical understanding of KeyDiff. Notably,KeyDiff does not rely on\nattention scores, allowing the use of optimized attention mechanisms like\nFlashAttention. We demonstrate the effectiveness of KeyDiff across diverse\ntasks and models, illustrating a performance gap of less than 0.04\\% with 8K\ncache budget ($\\sim$ 23\\% KV cache reduction) from the non-evicting baseline on\nthe LongBench benchmark for Llama 3.1-8B and Llama 3.2-3B.", "AI": {"tldr": "KeyDiff is a training-free KV cache eviction method based on key similarity, enabling efficient LLM deployment in resource-constrained environments.", "motivation": "To address the challenge of deploying LLMs with long input prompts in memory- and compute-limited settings.", "method": "Proposes KeyDiff, which evicts KV cache entries based on key similarity, maximizing diversity without relying on attention scores.", "result": "KeyDiff achieves near-optimal performance (0.04% gap) with a 23% KV cache reduction on LongBench for Llama models.", "conclusion": "KeyDiff is a practical, theoretically grounded solution for efficient LLM inference under strict resource constraints."}}
{"id": "2504.15315", "pdf": "https://arxiv.org/pdf/2504.15315", "abs": "https://arxiv.org/abs/2504.15315", "authors": ["Noa Cohen", "Rotem Dror", "Itzik Klein"], "title": "Diffusion-Driven Inertial Generated Data for Smartphone Location Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Despite the crucial role of inertial measurements in motion tracking and\nnavigation systems, the time-consuming and resource-intensive nature of\ncollecting extensive inertial data has hindered the development of robust\nmachine learning models in this field. In recent years, diffusion models have\nemerged as a revolutionary class of generative models, reshaping the landscape\nof artificial data generation. These models surpass generative adversarial\nnetworks and other state-of-the-art approaches to complex tasks. In this work,\nwe propose diffusion-driven specific force-generated data for smartphone\nlocation recognition. We provide a comprehensive evaluation methodology by\ncomparing synthetic and real recorded specific force data across multiple\nmetrics. Our results demonstrate that our diffusion-based generative model\nsuccessfully captures the distinctive characteristics of specific force signals\nacross different smartphone placement conditions. Thus, by creating diverse,\nrealistic synthetic data, we can reduce the burden of extensive data collection\nwhile providing high-quality training data for machine learning models.", "AI": {"tldr": "A diffusion-based generative model is proposed to create synthetic specific force data for smartphone location recognition, reducing the need for extensive real data collection.", "motivation": "The time and resource constraints of collecting large inertial datasets hinder robust machine learning model development in motion tracking and navigation.", "method": "Uses diffusion models to generate synthetic specific force data, comparing it with real data across multiple metrics.", "result": "The model captures distinctive characteristics of specific force signals under various smartphone placements, producing realistic synthetic data.", "conclusion": "Diffusion-driven synthetic data can alleviate data collection burdens while providing high-quality training data for machine learning."}}
{"id": "2504.15378", "pdf": "https://arxiv.org/pdf/2504.15378", "abs": "https://arxiv.org/abs/2504.15378", "authors": ["Scott Sorensen", "Wayne Treible", "Robert Wagner", "Andrew D. Gilliam", "Todd Rovito", "Joseph L. Mundy"], "title": "Physics Driven Image Simulation from Commercial Satellite Imagery", "categories": ["cs.CV"], "comment": "15 pages, 9 figures", "summary": "Physics driven image simulation allows for the modeling and creation of\nrealistic imagery beyond what is afforded by typical rendering pipelines. We\naim to automatically generate a physically realistic scene for simulation of a\ngiven region using satellite imagery to model the scene geometry, drive\nmaterial estimates, and populate the scene with dynamic elements. We present\nautomated techniques to utilize satellite imagery throughout the simulated\nscene to expedite scene construction and decrease manual overhead. Our\ntechnique does not use lidar, enabling simulations that could not be\nconstructed previously. To develop a 3D scene, we model the various components\nof the real location, addressing the terrain, modelling man-made structures,\nand populating the scene with smaller elements such as vegetation and vehicles.\nTo create the scene we begin with a Digital Surface Model, which serves as the\nbasis for scene geometry, and allows us to reason about the real location in a\ncommon 3D frame of reference. These simulated scenes can provide increased\nfidelity with less manual intervention for novel locations on earth, and can\nfacilitate algorithm development, and processing pipelines for imagery ranging\nfrom UV to LWIR $(200nm-20\\mu m)$.", "AI": {"tldr": "Automated generation of physically realistic 3D scenes from satellite imagery, bypassing lidar, for high-fidelity simulations.", "motivation": "To create realistic simulations of real-world locations with minimal manual effort, enabling applications in algorithm development and imagery processing.", "method": "Uses satellite imagery and a Digital Surface Model to construct scene geometry, estimate materials, and populate dynamic elements like vegetation and vehicles.", "result": "Produces high-fidelity 3D scenes without lidar, suitable for diverse imagery ranges (UV to LWIR).", "conclusion": "The method enables efficient, realistic scene simulation for novel locations, reducing manual overhead and expanding simulation capabilities."}}
{"id": "2504.15481", "pdf": "https://arxiv.org/pdf/2504.15481", "abs": "https://arxiv.org/abs/2504.15481", "authors": ["Michel Berthier", "Nicoletta Prencipe", "Edoardo Provenzi"], "title": "Split-quaternions for perceptual white balance", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "We propose a perceptual chromatic adaptation transform for white balance that\nmakes use of split-quaternions. The novelty of the present work, which is\nmotivated by a recently developed quantum-like model of color perception,\nconsists at stressing the link between the algebraic structures appearing in\nthis model and a certain sub-algebra of the split-quaternions. We show the\npotentiality of this approach for color image processing applications by\nproposing a chromatic adaptation transform, implemented via an appropriate use\nof the split-quaternion multiplication. Moreover, quantitative comparisons with\nthe widely used state-of-the art von Kries chromatic adaptation transform are\nprovided.", "AI": {"tldr": "A perceptual chromatic adaptation transform using split-quaternions is proposed, linking algebraic structures in color perception to split-quaternions, and outperforming the von Kries transform.", "motivation": "Motivated by a quantum-like model of color perception, the work explores algebraic structures in this model and their connection to split-quaternions.", "method": "The method involves a chromatic adaptation transform implemented via split-quaternion multiplication.", "result": "The approach shows potential for color image processing and outperforms the von Kries chromatic adaptation transform in quantitative comparisons.", "conclusion": "The proposed split-quaternion-based transform offers a novel and effective alternative for chromatic adaptation in image processing."}}
{"id": "2504.15524", "pdf": "https://arxiv.org/pdf/2504.15524", "abs": "https://arxiv.org/abs/2504.15524", "authors": ["Qiyao Wang", "Guhong Chen", "Hongbo Wang", "Huaren Liu", "Minghui Zhu", "Zhifei Qin", "Linwei Li", "Yilin Yue", "Shiqiang Wang", "Jiayan Li", "Yihang Wu", "Ziqiang Liu", "Longze Chen", "Run Luo", "Liyang Fan", "Jiaming Li", "Lei Zhang", "Kan Xu", "Hongfei Lin", "Hamid Alinejad-Rokny", "Shiwen Ni", "Yuan Lin", "Min Yang"], "title": "IPBench: Benchmarking the Knowledge of Large Language Models in Intellectual Property", "categories": ["cs.CL", "cs.AI"], "comment": "89 pages, 75 figures, 55 tables", "summary": "Intellectual Property (IP) is a unique domain that integrates technical and\nlegal knowledge, making it inherently complex and knowledge-intensive. As large\nlanguage models (LLMs) continue to advance, they show great potential for\nprocessing IP tasks, enabling more efficient analysis, understanding, and\ngeneration of IP-related content. However, existing datasets and benchmarks\neither focus narrowly on patents or cover limited aspects of the IP field,\nlacking alignment with real-world scenarios. To bridge this gap, we introduce\nthe first comprehensive IP task taxonomy and a large, diverse bilingual\nbenchmark, IPBench, covering 8 IP mechanisms and 20 tasks. This benchmark is\ndesigned to evaluate LLMs in real-world intellectual property applications,\nencompassing both understanding and generation. We benchmark 16 LLMs, ranging\nfrom general-purpose to domain-specific models, and find that even the\nbest-performing model achieves only 75.8% accuracy, revealing substantial room\nfor improvement. Notably, open-source IP and law-oriented models lag behind\nclosed-source general-purpose models. We publicly release all data and code of\nIPBench and will continue to update it with additional IP-related tasks to\nbetter reflect real-world challenges in the intellectual property domain.", "AI": {"tldr": "The paper introduces IPBench, a comprehensive bilingual benchmark for evaluating LLMs in real-world IP tasks, revealing significant performance gaps.", "motivation": "The complexity of IP tasks and the lack of aligned datasets necessitate a robust benchmark to assess LLM capabilities in this domain.", "method": "Developed a taxonomy of 8 IP mechanisms and 20 tasks, benchmarked 16 LLMs (general and domain-specific) using IPBench.", "result": "Best-performing model achieved 75.8% accuracy, with open-source and law-oriented models underperforming compared to closed-source general models.", "conclusion": "IPBench addresses the gap in IP task evaluation, highlighting the need for further LLM improvement in this domain."}}
{"id": "2504.16028", "pdf": "https://arxiv.org/pdf/2504.16028", "abs": "https://arxiv.org/abs/2504.16028", "authors": ["Tigran Bakaryan", "Christoph Aoun", "Ricardo de Lima Ribeiro", "Naira Hovakimyan", "Diogo Gomes"], "title": "Hessian Riemannian Flow For Multi-Population Wardrop Equilibrium", "categories": ["eess.SY", "cs.MA", "cs.SY", "math.OC"], "comment": null, "summary": "In this paper, we address the problem of optimizing flows on generalized\ngraphs that feature multiple entry points and multiple populations, each with\nvarying cost structures. We tackle this problem by considering the\nmulti-population Wardrop equilibrium, defined through variational inequalities.\nWe rigorously analyze the existence and uniqueness of the Wardrop equilibrium.\nFurthermore, we introduce an efficient numerical method to find the solution.\nIn particular, we reformulate the equilibrium problem as a distributed\noptimization problem over subgraphs and introduce a novel Hessian Riemannian\nflow method, a Riemannian-manifold-projected Hessian flow, to efficiently\ncompute a solution. Finally, we demonstrate the effectiveness of our approach\nthrough examples in urban traffic management, including routing for diverse\nvehicle types and strategies for minimizing emissions in congested\nenvironments.", "AI": {"tldr": "The paper proposes a method to optimize flows on generalized graphs with multiple entry points and populations, using the multi-population Wardrop equilibrium and a novel Hessian Riemannian flow method.", "motivation": "To address the challenge of optimizing flows in complex networks with diverse populations and cost structures, particularly in urban traffic management.", "method": "The multi-population Wardrop equilibrium is analyzed, and a distributed optimization problem is reformulated. A Hessian Riemannian flow method is introduced for efficient computation.", "result": "The approach demonstrates effectiveness in urban traffic scenarios, such as routing diverse vehicles and minimizing emissions.", "conclusion": "The proposed method efficiently solves flow optimization problems in generalized graphs with multiple populations and cost structures."}}
{"id": "2410.21897", "pdf": "https://arxiv.org/pdf/2410.21897", "abs": "https://arxiv.org/abs/2410.21897", "authors": ["Yifu Sun", "Xulong Zhang", "Monan Zhou", "Wei Li"], "title": "Semi-Supervised Self-Learning Enhanced Music Emotion Recognition", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "12 pages, 2 figures", "summary": "Music emotion recognition (MER) aims to identify the emotions conveyed in a\ngiven musical piece. However, currently, in the field of MER, the available\npublic datasets have limited sample sizes. Recently, segment-based methods for\nemotion-related tasks have been proposed, which train backbone networks on\nshorter segments instead of entire audio clips, thereby naturally augmenting\ntraining samples without requiring additional resources. Then, the predicted\nsegment-level results are aggregated to obtain the entire song prediction. The\nmost commonly used method is that the segment inherits the label of the clip\ncontaining it, but music emotion is not constant during the whole clip. Doing\nso will introduce label noise and make the training easy to overfit. To handle\nthe noisy label issue, we propose a semi-supervised self-learning (SSSL)\nmethod, which can differentiate between samples with correct and incorrect\nlabels in a self-learning manner, thus effectively utilizing the augmented\nsegment-level data. Experiments on three public emotional datasets demonstrate\nthat the proposed method can achieve better or comparable performance.", "AI": {"tldr": "A semi-supervised self-learning method is proposed to address label noise in segment-based music emotion recognition, improving performance on limited datasets.", "motivation": "Current MER datasets are small, and segment-based methods introduce label noise by inheriting clip-level labels, leading to overfitting.", "method": "Proposes a semi-supervised self-learning (SSSL) method to differentiate correct and incorrect segment labels, leveraging augmented data.", "result": "Achieves better or comparable performance on three public emotional datasets.", "conclusion": "The SSSL method effectively handles label noise and enhances MER performance without additional resources."}}
{"id": "2412.11272", "pdf": "https://arxiv.org/pdf/2412.11272", "abs": "https://arxiv.org/abs/2412.11272", "authors": ["Rongxiang Wang", "Zhiming Xu", "Felix Xiaozhu Lin"], "title": "WhisperFlow: speech foundation models in real time", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Speech foundation models, such as OpenAI's Whisper, become the state of the\nart in speech understanding due to their strong accuracy and generalizability.\nYet, their applications are mostly limited to processing pre-recorded speech,\nwhereas processing of streaming speech, in particular doing it efficiently,\nremains rudimentary. Behind this inefficiency are multiple fundamental reasons:\n(1) speech foundation models are trained to process long, fixed-length voice\ninputs (often 30 seconds); (2) encoding each voice input requires encoding as\nmany as 1,500 tokens with tens of transformer layers; (3) decoding each output\nentails an irregular, complex beam search. As such, streaming speech processing\non resource-constrained client devices is more expensive than other AI tasks,\ne.g., text generation.\n  To this end, we present a novel framework, WhisperFlow, which embodies both\nmodel and system optimizations. (1) Hush word as a short, learnable audio\nsegment; appended to a voice input, a hush word gracefully stops the speech\nmodel from processing more input without hallucination; (2) Beam pruning, which\naligns streaming audio buffers over time and reuses results from earlier\ndecoding rounds, therefore significantly accelerating decoding; and (3) CPU/GPU\npipelining, which not only maps to the encoding/decoding stages dynamically,\nbut also tunes to an optimal resource ratio, respecting the encoding/decoding\nspeed that varies across voice inputs, models, and hardware.\n  We test WhisperFlow on commodity ARM platforms with 4-12 CPU cores and 10-30\nGPU cores. It reduces per-word latency by 1.6x-4.7x to as low as 0.5 second,\nwhile seeing negligible accuracy degradation. On an entry-level MacBook Air,\nWhisperFlow can keep the per-word latency around 1 second, with the whole\ndevice drawing only 7 Watts in total.", "AI": {"tldr": "WhisperFlow introduces optimizations for streaming speech processing, reducing latency and resource usage while maintaining accuracy.", "motivation": "Current speech foundation models like Whisper are inefficient for streaming speech due to fixed-length inputs, high token encoding costs, and complex decoding.", "method": "WhisperFlow uses hush words, beam pruning, and CPU/GPU pipelining to optimize streaming speech processing.", "result": "WhisperFlow reduces per-word latency by 1.6x-4.7x and maintains accuracy, even on low-power devices like a MacBook Air.", "conclusion": "WhisperFlow effectively addresses inefficiencies in streaming speech processing, enabling efficient deployment on resource-constrained devices."}}
{"id": "2504.15434", "pdf": "https://arxiv.org/pdf/2504.15434", "abs": "https://arxiv.org/abs/2504.15434", "authors": ["Sarath Shekkizhar", "Romain Cosentino"], "title": "AGI Is Coming... Right After AI Learns to Play Wordle", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "This paper investigates multimodal agents, in particular, OpenAI's\nComputer-User Agent (CUA), trained to control and complete tasks through a\nstandard computer interface, similar to humans. We evaluated the agent's\nperformance on the New York Times Wordle game to elicit model behaviors and\nidentify shortcomings. Our findings revealed a significant discrepancy in the\nmodel's ability to recognize colors correctly depending on the context. The\nmodel had a $5.36\\%$ success rate over several hundred runs across a week of\nWordle. Despite the immense enthusiasm surrounding AI agents and their\npotential to usher in Artificial General Intelligence (AGI), our findings\nreinforce the fact that even simple tasks present substantial challenges for\ntoday's frontier AI models. We conclude with a discussion of the potential\nunderlying causes, implications for future development, and research directions\nto improve these AI systems.", "AI": {"tldr": "The paper evaluates OpenAI's Computer-User Agent (CUA) on the Wordle game, revealing challenges in color recognition and a low success rate (5.36%). It highlights gaps in current AI capabilities despite AGI enthusiasm.", "motivation": "To assess the performance and limitations of multimodal AI agents like CUA in real-world tasks, using Wordle as a test case.", "method": "The study tested CUA on the New York Times Wordle game over hundreds of runs to analyze its task-completion abilities and identify shortcomings.", "result": "CUA showed a 5.36% success rate, with notable difficulties in color recognition, indicating significant challenges for current AI models.", "conclusion": "The paper underscores the limitations of frontier AI models in simple tasks, suggesting further research to address these gaps and improve AI systems."}}
{"id": "2504.15322", "pdf": "https://arxiv.org/pdf/2504.15322", "abs": "https://arxiv.org/abs/2504.15322", "authors": ["Xiao Zhou", "Yuze Sun", "Jie Wu", "Xiaomeng Huang"], "title": "How to systematically develop an effective AI-based bias correction model?", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "comment": null, "summary": "This study introduces ReSA-ConvLSTM, an artificial intelligence (AI)\nframework for systematic bias correction in numerical weather prediction (NWP).\nWe propose three innovations by integrating dynamic climatological\nnormalization, ConvLSTM with temporal causality constraints, and residual\nself-attention mechanisms. The model establishes a physics-aware nonlinear\nmapping between ECMWF forecasts and ERA5 reanalysis data. Using 41 years\n(1981-2021) of global atmospheric data, the framework reduces systematic biases\nin 2-m air temperature (T2m), 10-m winds (U10/V10), and sea-level pressure\n(SLP), achieving up to 20% RMSE reduction over 1-7 day forecasts compared to\noperational ECMWF outputs. The lightweight architecture (10.6M parameters)\nenables efficient generalization to multiple variables and downstream\napplications, reducing retraining time by 85% for cross-variable correction\nwhile improving ocean model skill through bias-corrected boundary conditions.\nThe ablation experiments demonstrate that our innovations significantly improve\nthe model's correction performance, suggesting that incorporating variable\ncharacteristics into the model helps enhance forecasting skills.", "AI": {"tldr": "ReSA-ConvLSTM is an AI framework for bias correction in weather prediction, integrating dynamic normalization, ConvLSTM, and self-attention. It reduces biases in forecasts by 20% RMSE and improves efficiency.", "motivation": "To address systematic biases in numerical weather prediction (NWP) by developing a physics-aware AI framework.", "method": "Combines dynamic climatological normalization, ConvLSTM with temporal causality, and residual self-attention to map ECMWF forecasts to ERA5 reanalysis data.", "result": "Achieves up to 20% RMSE reduction in 1-7 day forecasts for T2m, U10/V10, and SLP, with efficient generalization and reduced retraining time.", "conclusion": "The innovations significantly improve correction performance, suggesting variable-specific modeling enhances forecasting accuracy."}}
{"id": "2504.15380", "pdf": "https://arxiv.org/pdf/2504.15380", "abs": "https://arxiv.org/abs/2504.15380", "authors": ["Huimin Zeng", "Jiacheng Li", "Zhiwei Xiong"], "title": "Plug-and-Play Versatile Compressed Video Enhancement", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2025", "summary": "As a widely adopted technique in data transmission, video compression\neffectively reduces the size of files, making it possible for real-time cloud\ncomputing. However, it comes at the cost of visual quality, posing challenges\nto the robustness of downstream vision models. In this work, we present a\nversatile codec-aware enhancement framework that reuses codec information to\nadaptively enhance videos under different compression settings, assisting\nvarious downstream vision tasks without introducing computation bottleneck.\nSpecifically, the proposed codec-aware framework consists of a\ncompression-aware adaptation (CAA) network that employs a hierarchical\nadaptation mechanism to estimate parameters of the frame-wise enhancement\nnetwork, namely the bitstream-aware enhancement (BAE) network. The BAE network\nfurther leverages temporal and spatial priors embedded in the bitstream to\neffectively improve the quality of compressed input frames. Extensive\nexperimental results demonstrate the superior quality enhancement performance\nof our framework over existing enhancement methods, as well as its versatility\nin assisting multiple downstream tasks on compressed videos as a plug-and-play\nmodule. Code and models are available at\nhttps://huimin-zeng.github.io/PnP-VCVE/.", "AI": {"tldr": "A codec-aware enhancement framework improves compressed video quality by reusing codec information, aiding downstream vision tasks without computational overhead.", "motivation": "Video compression reduces file sizes but degrades visual quality, challenging downstream vision models. This work aims to enhance compressed videos adaptively.", "method": "The framework uses a compression-aware adaptation (CAA) network to estimate parameters for a bitstream-aware enhancement (BAE) network, leveraging temporal and spatial priors.", "result": "The framework outperforms existing enhancement methods and supports multiple downstream tasks as a plug-and-play module.", "conclusion": "The proposed framework effectively enhances compressed video quality and is versatile for various vision tasks."}}
{"id": "2504.15545", "pdf": "https://arxiv.org/pdf/2504.15545", "abs": "https://arxiv.org/abs/2504.15545", "authors": ["Zizhi Chen", "Xinyu Zhang", "Minghao Han", "Yizhou Liu", "Ziyun Qian", "Weifeng Zhang", "Xukun Zhang", "Jingwei Wei", "Lihua Zhang"], "title": "VLM-based Prompts as the Optimal Assistant for Unpaired Histopathology Virtual Staining", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "In histopathology, tissue sections are typically stained using common H&E\nstaining or special stains (MAS, PAS, PASM, etc.) to clearly visualize specific\ntissue structures. The rapid advancement of deep learning offers an effective\nsolution for generating virtually stained images, significantly reducing the\ntime and labor costs associated with traditional histochemical staining.\nHowever, a new challenge arises in separating the fundamental visual\ncharacteristics of tissue sections from the visual differences induced by\nstaining agents. Additionally, virtual staining often overlooks essential\npathological knowledge and the physical properties of staining, resulting in\nonly style-level transfer. To address these issues, we introduce, for the first\ntime in virtual staining tasks, a pathological vision-language large model\n(VLM) as an auxiliary tool. We integrate contrastive learnable prompts,\nfoundational concept anchors for tissue sections, and staining-specific concept\nanchors to leverage the extensive knowledge of the pathological VLM. This\napproach is designed to describe, frame, and enhance the direction of virtual\nstaining. Furthermore, we have developed a data augmentation method based on\nthe constraints of the VLM. This method utilizes the VLM's powerful image\ninterpretation capabilities to further integrate image style and structural\ninformation, proving beneficial in high-precision pathological diagnostics.\nExtensive evaluations on publicly available multi-domain unpaired staining\ndatasets demonstrate that our method can generate highly realistic images and\nenhance the accuracy of downstream tasks, such as glomerular detection and\nsegmentation. Our code is available at:\nhttps://github.com/CZZZZZZZZZZZZZZZZZ/VPGAN-HARBOR", "AI": {"tldr": "A pathological vision-language model (VLM) is introduced for virtual staining to improve realism and accuracy in histopathology by integrating contrastive prompts and concept anchors.", "motivation": "Traditional virtual staining methods lack pathological knowledge and physical properties, leading to style-level transfer issues.", "method": "Uses a pathological VLM with contrastive prompts and concept anchors, plus a VLM-based data augmentation method.", "result": "Generates highly realistic images and improves accuracy in tasks like glomerular detection and segmentation.", "conclusion": "The method effectively enhances virtual staining by leveraging pathological knowledge and VLM capabilities."}}
{"id": "2504.15527", "pdf": "https://arxiv.org/pdf/2504.15527", "abs": "https://arxiv.org/abs/2504.15527", "authors": ["Sophia Maria"], "title": "Compass-V2 Technical Report", "categories": ["cs.CL"], "comment": null, "summary": "Predominant LLMs focus on high-resource languages while leaving low-resource\nlanguages, particularly those in Southeast Asia (SEA), underrepresented. In\naddition, those models are general-purpose and pay limited attention to the\ne-commerce domain. To overcome these limitations, we introduce Compass-v2, a\nlightweight Mixture-of-Experts (MoE) model specifically designed for Southeast\nAsian languages and e-commerce applications. To balance model performance and\ninference cost, the model is designed with 30B total parameters and 5B active\nparameters, incorporating both fine-grained and shared expert modules. To\nenhance multilingual performance, we curated and constructed a high-quality,\nindustry-leading SEA dataset, to the best of our knowledge. To boost\nperformance in the e-commerce domain, we built a dataset comprising hundreds of\nbillions of tokens, sourced through external data mining and internal platform\ncollection. Besides, we pioneered a hybrid reasoning model that supports both\nfast thinking and deep thinking within a unified framework to enhance the\nreasoning capabilities, diverging from the conventional industry practice of\ndeploying two separate models. Through extensive experimental evaluations, our\nmodel demonstrates state-of-the-art SEA multilingual and e-commerce performance\namong sub-30B models, while maintaining significantly lower inference cost.", "AI": {"tldr": "Compass-v2 is a lightweight MoE model for SEA languages and e-commerce, balancing performance and cost with 30B total parameters. It uses a hybrid reasoning model and curated datasets to achieve state-of-the-art results.", "motivation": "Address underrepresentation of SEA languages and lack of e-commerce focus in existing LLMs.", "method": "Lightweight MoE design (30B total, 5B active parameters), hybrid reasoning, and high-quality SEA/e-commerce datasets.", "result": "State-of-the-art performance in SEA multilingual and e-commerce tasks among sub-30B models, with lower inference cost.", "conclusion": "Compass-v2 effectively bridges gaps in multilingual and domain-specific LLM performance for SEA and e-commerce."}}
{"id": "2504.10915", "pdf": "https://arxiv.org/pdf/2504.10915", "abs": "https://arxiv.org/abs/2504.10915", "authors": ["Rajesh Ranjan", "Shailja Gupta", "Surya Narayan Singh"], "title": "LOKA Protocol: A Decentralized Framework for Trustworthy and Ethical AI Agent Ecosystems", "categories": ["cs.MA", "cs.AI", "cs.CY"], "comment": "4 Figures, 1 Table", "summary": "The rise of autonomous AI agents, capable of perceiving, reasoning, and\nacting independently, signals a profound shift in how digital ecosystems\noperate, govern, and evolve. As these agents proliferate beyond centralized\ninfrastructures, they expose foundational gaps in identity, accountability, and\nethical alignment. Three critical questions emerge: Identity: Who or what is\nthe agent? Accountability: Can its actions be verified, audited, and trusted?\nEthical Consensus: Can autonomous systems reliably align with human values and\nprevent harmful emergent behaviors? We present the novel LOKA Protocol (Layered\nOrchestration for Knowledgeful Agents), a unified, systems-level architecture\nfor building ethically governed, interoperable AI agent ecosystems. LOKA\nintroduces a proposed Universal Agent Identity Layer (UAIL) for decentralized,\nverifiable identity; intent-centric communication protocols for semantic\ncoordination across diverse agents; and a Decentralized Ethical Consensus\nProtocol (DECP) that could enable agents to make context-aware decisions\ngrounded in shared ethical baselines. Anchored in emerging standards such as\nDecentralized Identifiers (DIDs), Verifiable Credentials (VCs), and\npost-quantum cryptography, LOKA proposes a scalable, future-resilient blueprint\nfor multi-agent AI governance. By embedding identity, trust, and ethics into\nthe protocol layer itself, LOKA proposes the foundation for a new era of\nresponsible, transparent, and autonomous AI ecosystems operating across digital\nand physical domains.", "AI": {"tldr": "The LOKA Protocol is a systems-level architecture designed to address identity, accountability, and ethical alignment in autonomous AI ecosystems.", "motivation": "The proliferation of autonomous AI agents reveals gaps in identity, accountability, and ethical alignment, necessitating a unified governance framework.", "method": "LOKA introduces a Universal Agent Identity Layer (UAIL), intent-centric communication protocols, and a Decentralized Ethical Consensus Protocol (DECP), leveraging standards like DIDs and VCs.", "result": "The protocol provides a scalable blueprint for ethically governed, interoperable AI ecosystems.", "conclusion": "LOKA lays the foundation for responsible, transparent, and autonomous AI ecosystems."}}
{"id": "2412.15726", "pdf": "https://arxiv.org/pdf/2412.15726", "abs": "https://arxiv.org/abs/2412.15726", "authors": ["Vincenzo Timmel", "Claudio Paonessa", "Reza Kakooee", "Manfred Vogel", "Daniel Perruchoud"], "title": "Fine-tuning Whisper on Low-Resource Languages for Real-World Applications", "categories": ["cs.CL", "eess.AS"], "comment": null, "summary": "This paper presents a new approach to fine-tuning OpenAI's Whisper model for\nlow-resource languages by introducing a novel data generation method that\nconverts sentence-level data into a long-form corpus, using Swiss German as a\ncase study. Non-sentence-level data, which could improve the performance of\nlong-form audio, is difficult to obtain and often restricted by copyright laws.\nOur method bridges this gap by transforming more accessible sentence-level data\ninto a format that preserves the model's ability to handle long-form audio and\nperform segmentation without requiring non-sentence-level data. Our data\ngeneration process improves performance in several real-world applications and\nleads to the development of a new state-of-the-art speech-to-text (STT) model\nfor Swiss German. We compare our model with a non-fine-tuned Whisper and our\nprevious state-of-the-art Swiss German STT models, where our new model achieves\nhigher BLEU scores. Our results also indicate that the proposed method is\nadaptable to other low-resource languages, supported by written guidance and\ncode that allows the creation of fine-tuned Whisper models, which keep\nsegmentation capabilities and allow the transcription of longer audio files\nusing only sentence-level data with high quality.", "AI": {"tldr": "A novel method for fine-tuning Whisper for low-resource languages by converting sentence-level data into long-form corpus, demonstrated with Swiss German, achieving state-of-the-art results.", "motivation": "Addressing the lack of non-sentence-level data for low-resource languages, which is crucial for long-form audio performance but often restricted by copyright.", "method": "Transform sentence-level data into a long-form corpus to preserve Whisper's long-form audio handling and segmentation capabilities without needing non-sentence-level data.", "result": "Improved performance in real-world applications, higher BLEU scores compared to non-fine-tuned Whisper and previous models, and adaptability to other low-resource languages.", "conclusion": "The method successfully bridges the data gap for low-resource languages, enabling high-quality long-form transcription using only sentence-level data."}}
{"id": "2504.02407", "pdf": "https://arxiv.org/pdf/2504.02407", "abs": "https://arxiv.org/abs/2504.02407", "authors": ["Xiaohui Sun", "Ruitong Xiao", "Jianye Mo", "Bowen Wu", "Qun Yu", "Baoxun Wang"], "title": "F5R-TTS: Improving Flow-Matching based Text-to-Speech with Group Relative Policy Optimization", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "We present F5R-TTS, a novel text-to-speech (TTS) system that integrates Group\nRelative Policy Optimization (GRPO) into a flow-matching based architecture. By\nreformulating the deterministic outputs of flow-matching TTS into probabilistic\nGaussian distributions, our approach enables seamless integration of\nreinforcement learning algorithms. During pretraining, we train a\nprobabilistically reformulated flow-matching based model which is derived from\nF5-TTS with an open-source dataset. In the subsequent reinforcement learning\n(RL) phase, we employ a GRPO-driven enhancement stage that leverages dual\nreward metrics: word error rate (WER) computed via automatic speech recognition\nand speaker similarity (SIM) assessed by verification models. Experimental\nresults on zero-shot voice cloning demonstrate that F5R-TTS achieves\nsignificant improvements in both speech intelligibility (a 29.5% relative\nreduction in WER) and speaker similarity (a 4.6% relative increase in SIM\nscore) compared to conventional flow-matching based TTS systems. Audio samples\nare available at https://frontierlabs.github.io/F5R.", "AI": {"tldr": "F5R-TTS integrates GRPO into flow-matching TTS, improving speech intelligibility and speaker similarity via dual RL rewards.", "motivation": "To enhance flow-matching TTS by integrating reinforcement learning for better intelligibility and speaker similarity.", "method": "Combines probabilistic reformulation of flow-matching with GRPO-driven RL, using WER and SIM as rewards.", "result": "Achieves 29.5% WER reduction and 4.6% SIM score increase in zero-shot voice cloning.", "conclusion": "F5R-TTS outperforms conventional flow-matching TTS, demonstrating RL's effectiveness in TTS enhancement."}}
{"id": "2504.15457", "pdf": "https://arxiv.org/pdf/2504.15457", "abs": "https://arxiv.org/abs/2504.15457", "authors": ["Paresh Chaudhary", "Yancheng Liang", "Daphne Chen", "Simon S. Du", "Natasha Jaques"], "title": "Improving Human-AI Coordination through Adversarial Training and Generative Models", "categories": ["cs.AI"], "comment": null, "summary": "Being able to cooperate with new people is an important component of many\neconomically valuable AI tasks, from household robotics to autonomous driving.\nHowever, generalizing to novel humans requires training on data that captures\nthe diversity of human behaviors. Adversarial training is one avenue for\nsearching for such data and ensuring that agents are robust. However, it is\ndifficult to apply in the cooperative setting because adversarial policies\nintentionally learn to sabotage the task instead of simulating valid\ncooperation partners. To address this challenge, we propose a novel strategy\nfor overcoming self-sabotage that combines a pre-trained generative model to\nsimulate valid cooperative agent policies with adversarial training to maximize\nregret. We call our method GOAT: Generative Online Adversarial Training. In\nthis framework, the GOAT dynamically searches for and generates coordination\nstrategies where the learning policy -- the Cooperator agent -- underperforms.\nGOAT enables better generalization by exposing the Cooperator to various\nchallenging interaction scenarios. We maintain realistic coordination\nstrategies by updating only the generative model's embedding while keeping its\nparameters frozen, thus avoiding adversarial exploitation. We evaluate GOAT\nwith real human partners, and the results demonstrate state-of-the-art\nperformance on the Overcooked benchmark, highlighting its effectiveness in\ngeneralizing to diverse human behaviors.", "AI": {"tldr": "GOAT (Generative Online Adversarial Training) combines a pre-trained generative model with adversarial training to improve AI cooperation with diverse humans, achieving state-of-the-art results on the Overcooked benchmark.", "motivation": "Generalizing AI cooperation to novel humans requires diverse training data, but adversarial training often sabotages tasks instead of simulating valid cooperation.", "method": "GOAT uses a generative model to simulate valid cooperative policies and adversarial training to maximize regret, dynamically generating challenging coordination strategies.", "result": "GOAT achieves state-of-the-art performance on the Overcooked benchmark, demonstrating effective generalization to diverse human behaviors.", "conclusion": "GOAT successfully balances adversarial training with realistic cooperation, enabling robust AI generalization to new human partners."}}
{"id": "2504.15323", "pdf": "https://arxiv.org/pdf/2504.15323", "abs": "https://arxiv.org/abs/2504.15323", "authors": ["Donggyun Kim", "Chanwoo Kim", "Seunghoon Hong"], "title": "HyperFlow: Gradient-Free Emulation of Few-Shot Fine-Tuning", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "While test-time fine-tuning is beneficial in few-shot learning, the need for\nmultiple backpropagation steps can be prohibitively expensive in real-time or\nlow-resource scenarios. To address this limitation, we propose an approach that\nemulates gradient descent without computing gradients, enabling efficient\ntest-time adaptation. Specifically, we formulate gradient descent as an Euler\ndiscretization of an ordinary differential equation (ODE) and train an\nauxiliary network to predict the task-conditional drift using only the few-shot\nsupport set. The adaptation then reduces to a simple numerical integration\n(e.g., via the Euler method), which requires only a few forward passes of the\nauxiliary network -- no gradients or forward passes of the target model are\nneeded. In experiments on cross-domain few-shot classification using the\nMeta-Dataset and CDFSL benchmarks, our method significantly improves\nout-of-domain performance over the non-fine-tuned baseline while incurring only\n6\\% of the memory cost and 0.02\\% of the computation time of standard\nfine-tuning, thus establishing a practical middle ground between direct\ntransfer and fully fine-tuned approaches.", "AI": {"tldr": "Proposes a gradient-free test-time adaptation method for few-shot learning, reducing computational costs significantly.", "motivation": "Addresses the inefficiency of multiple backpropagation steps in test-time fine-tuning for real-time or low-resource scenarios.", "method": "Formulates gradient descent as an ODE discretization, using an auxiliary network to predict task-conditional drift, enabling adaptation via numerical integration.", "result": "Improves out-of-domain performance with 6% memory cost and 0.02% computation time of standard fine-tuning.", "conclusion": "Offers a practical middle ground between direct transfer and full fine-tuning, balancing efficiency and performance."}}
{"id": "2504.15384", "pdf": "https://arxiv.org/pdf/2504.15384", "abs": "https://arxiv.org/abs/2504.15384", "authors": ["Chen Zhao", "Anjum Shaik", "Joyce H. Keyak", "Nancy E. Lane", "Jeffrey D. Deng", "Kuan-Jui Su", "Qiuying Sha", "Hui Shen", "Hong-Wen Deng", "Weihua Zhou"], "title": "ICGM-FRAX: Iterative Cross Graph Matching for Hip Fracture Risk Assessment using Dual-energy X-ray Absorptiometry Images", "categories": ["cs.CV"], "comment": "23 pages, 4 figures", "summary": "Hip fractures represent a major health concern, particularly among the\nelderly, often leading decreased mobility and increased mortality. Early and\naccurate detection of at risk individuals is crucial for effective\nintervention. In this study, we propose Iterative Cross Graph Matching for Hip\nFracture Risk Assessment (ICGM-FRAX), a novel approach for predicting hip\nfractures using Dual-energy X-ray Absorptiometry (DXA) images. ICGM-FRAX\ninvolves iteratively comparing a test (subject) graph with multiple template\ngraphs representing the characteristics of hip fracture subjects to assess the\nsimilarity and accurately to predict hip fracture risk. These graphs are\nobtained as follows. The DXA images are separated into multiple regions of\ninterest (RoIs), such as the femoral head, shaft, and lesser trochanter.\nRadiomic features are then calculated for each RoI, with the central\ncoordinates used as nodes in a graph. The connectivity between nodes is\nestablished according to the Euclidean distance between these coordinates. This\nprocess transforms each DXA image into a graph, where each node represents a\nRoI, and edges derived by the centroids of RoIs capture the spatial\nrelationships between them. If the test graph closely matches a set of template\ngraphs representing subjects with incident hip fractures, it is classified as\nindicating high hip fracture risk. We evaluated our method using 547 subjects\nfrom the UK Biobank dataset, and experimental results show that ICGM-FRAX\nachieved a sensitivity of 0.9869, demonstrating high accuracy in predicting hip\nfractures.", "AI": {"tldr": "ICGM-FRAX uses graph matching on DXA images to predict hip fracture risk with high accuracy.", "motivation": "Early detection of hip fracture risk in elderly individuals is critical for intervention.", "method": "Transform DXA images into graphs of radiomic features and iteratively match test graphs to fracture templates.", "result": "Achieved a sensitivity of 0.9869 on 547 UK Biobank subjects.", "conclusion": "ICGM-FRAX is highly accurate for hip fracture risk assessment."}}
{"id": "2504.15649", "pdf": "https://arxiv.org/pdf/2504.15649", "abs": "https://arxiv.org/abs/2504.15649", "authors": ["Biao Wu", "Diankai Zhang", "Shaoli Liu", "Si Gao", "Chengjian Zheng", "Ning Wang"], "title": "RepNet-VSR: Reparameterizable Architecture for High-Fidelity Video Super-Resolution", "categories": ["eess.IV", "cs.CV"], "comment": "Champion Solution for CVPR 2025 MAI VSR Track", "summary": "As a fundamental challenge in visual computing, video super-resolution (VSR)\nfocuses on reconstructing highdefinition video sequences from their degraded\nlowresolution counterparts. While deep convolutional neural networks have\ndemonstrated state-of-the-art performance in spatial-temporal super-resolution\ntasks, their computationally intensive nature poses significant deployment\nchallenges for resource-constrained edge devices, particularly in real-time\nmobile video processing scenarios where power efficiency and latency\nconstraints coexist. In this work, we propose a Reparameterizable Architecture\nfor High Fidelity Video Super Resolution method, named RepNet-VSR, for\nreal-time 4x video super-resolution. On the REDS validation set, the proposed\nmodel achieves 27.79 dB PSNR when processing 180p to 720p frames in 103 ms per\n10 frames on a MediaTek Dimensity NPU. The competition results demonstrate an\nexcellent balance between restoration quality and deployment efficiency. The\nproposed method scores higher than the previous champion algorithm of MAI video\nsuper-resolution challenge.", "AI": {"tldr": "RepNet-VSR is a reparameterizable architecture for efficient 4x video super-resolution, balancing quality and speed on edge devices.", "motivation": "Addressing the computational inefficiency of deep CNNs in VSR for real-time mobile applications.", "method": "Proposes RepNet-VSR, a reparameterizable architecture for high-fidelity VSR, optimized for edge devices.", "result": "Achieves 27.79 dB PSNR on REDS, processing 180p to 720p in 103 ms per 10 frames, outperforming prior methods.", "conclusion": "RepNet-VSR offers a practical solution for real-time VSR on resource-constrained devices, excelling in quality and efficiency."}}
{"id": "2504.15544", "pdf": "https://arxiv.org/pdf/2504.15544", "abs": "https://arxiv.org/abs/2504.15544", "authors": ["Issa Sugiura", "Kouta Nakayama", "Yusuke Oda"], "title": "llm-jp-modernbert: A ModernBERT Model Trained on a Large-Scale Japanese Corpus with Long Context Length", "categories": ["cs.CL"], "comment": "9 pages, 5 figures", "summary": "Encoder-only transformer models like BERT are widely adopted as a pre-trained\nbackbone for tasks like sentence classification and retrieval. However,\npretraining of encoder models with large-scale corpora and long contexts has\nbeen relatively underexplored compared to decoder-only transformers. In this\nwork, we present llm-jp-modernbert, a ModernBERT model trained on a publicly\navailable, massive Japanese corpus with a context length of 8192 tokens. While\nour model does not surpass existing baselines on downstream tasks, it achieves\ngood results on fill-mask test evaluations. We also analyze the effect of\ncontext length expansion through pseudo-perplexity experiments. Furthermore, we\ninvestigate sentence embeddings in detail, analyzing their transitions during\ntraining and comparing them with those from other existing models, confirming\nsimilar trends with models sharing the same architecture. To support\nreproducibility and foster the development of long-context BERT, we release our\nmodel, along with the training and evaluation code.", "AI": {"tldr": "A ModernBERT model (llm-jp-modernbert) trained on a large Japanese corpus with 8192-token contexts achieves good fill-mask results but doesn't surpass baselines in downstream tasks. The study includes analysis of context length effects and sentence embeddings.", "motivation": "To explore pretraining encoder models with large-scale corpora and long contexts, an area less studied compared to decoder-only transformers.", "method": "Train a ModernBERT model on a massive Japanese corpus with 8192-token contexts, evaluate on fill-mask tasks, and analyze context length and sentence embeddings.", "result": "Good fill-mask performance but no improvement over baselines in downstream tasks; insights into context length and sentence embeddings.", "conclusion": "The model supports reproducibility and advances long-context BERT research, though further improvements are needed for downstream tasks."}}
{"id": "2503.17436", "pdf": "https://arxiv.org/pdf/2503.17436", "abs": "https://arxiv.org/abs/2503.17436", "authors": ["Lars Kr\u00f6ger", "Cristian Cioflan", "Victor Kartsch", "Luca Benini"], "title": "On-Device Federated Continual Learning on RISC-V-based Ultra-Low-Power SoC for Intelligent Nano-Drone Swarms", "categories": ["cs.LG", "cs.CV", "cs.MA", "I.2.11; I.2.6; C.5.3; I.4.9"], "comment": "2 pages, 2 tables, 1 figure. Accepted as a poster at the RISC-V\n  Summit Europe 2025", "summary": "RISC-V-based architectures are paving the way for efficient On-Device\nLearning (ODL) in smart edge devices. When applied across multiple nodes, ODL\nenables the creation of intelligent sensor networks that preserve data privacy.\nHowever, developing ODL-capable, battery-operated embedded platforms presents\nsignificant challenges due to constrained computational resources and limited\ndevice lifetime, besides intrinsic learning issues such as catastrophic\nforgetting. We face these challenges by proposing a regularization-based\nOn-Device Federated Continual Learning algorithm tailored for multiple\nnano-drones performing face recognition tasks. We demonstrate our approach on a\nRISC-V-based 10-core ultra-low-power SoC, optimizing the ODL computational\nrequirements. We improve the classification accuracy by 24% over naive\nfine-tuning, requiring 178 ms per local epoch and 10.5 s per global epoch,\ndemonstrating the effectiveness of the architecture for this task.", "AI": {"tldr": "A RISC-V-based architecture enables efficient On-Device Learning (ODL) for smart edge devices, addressing challenges like computational constraints and catastrophic forgetting with a novel federated continual learning algorithm.", "motivation": "To overcome the challenges of constrained resources and data privacy in battery-operated embedded platforms for ODL, particularly in intelligent sensor networks.", "method": "Proposed a regularization-based On-Device Federated Continual Learning algorithm for nano-drones performing face recognition, implemented on a RISC-V-based 10-core ultra-low-power SoC.", "result": "Achieved a 24% improvement in classification accuracy over naive fine-tuning, with 178 ms per local epoch and 10.5 s per global epoch.", "conclusion": "The RISC-V-based architecture and proposed algorithm effectively optimize ODL for resource-constrained devices, demonstrating practical viability."}}
{"id": "2502.15430", "pdf": "https://arxiv.org/pdf/2502.15430", "abs": "https://arxiv.org/abs/2502.15430", "authors": ["David Valdivia", "Marien Renaud", "Elsa Cazelles", "C\u00e9dric F\u00e9votte"], "title": "Audio signal interpolation using optimal transportation of spectrograms", "categories": ["eess.SP", "cs.SD", "eess.AS"], "comment": null, "summary": "We present a novel approach for generating an artificial audio signal that\ninterpolates between given source and target sounds. Our approach relies on the\ncomputation of Wasserstein barycenters of the source and target spectrograms,\nfollowed by phase reconstruction and inversion. In contrast with previous\nworks, our new method considers the spectrograms globally and does not operate\non a temporal frame-to-frame basis. Another contribution is to endow the\ntransportation cost matrix with a specific structure that prohibits remote\ndisplacements of energy along the time axis, and for which optimal transport is\nmade possible by leveraging the unbalanced transport framework. The proposed\ncost matrix makes sense from the audio perspective and also allows to reduce\nthe computation load. Results with synthetic musical notes and real\nenvironmental sounds illustrate the potential of our novel approach.", "AI": {"tldr": "A novel method for interpolating audio signals using Wasserstein barycenters of spectrograms, with a structured cost matrix for efficiency.", "motivation": "To improve audio signal interpolation by considering spectrograms globally and avoiding frame-to-frame operations, while reducing computational load.", "method": "Uses Wasserstein barycenters of source and target spectrograms, phase reconstruction, and a structured cost matrix to limit energy displacement along time.", "result": "Demonstrated effectiveness with synthetic musical notes and real environmental sounds.", "conclusion": "The approach offers a promising and efficient method for audio signal interpolation."}}
{"id": "2504.08365", "pdf": "https://arxiv.org/pdf/2504.08365", "abs": "https://arxiv.org/abs/2504.08365", "authors": ["Xueping Zhang", "Yaxiong Chen", "Ruilin Yao", "Yunfei Zi", "Shengwu Xiong"], "title": "Location-Oriented Sound Event Localization and Detection with Spatial Mapping and Regression Localization", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Sound Event Localization and Detection (SELD) combines the Sound Event\nDetection (SED) with the corresponding Direction Of Arrival (DOA). Recently,\nadopted event oriented multi-track methods affect the generality in polyphonic\nenvironments due to the limitation of the number of tracks. To enhance the\ngenerality in polyphonic environments, we propose Spatial Mapping and\nRegression Localization for SELD (SMRL-SELD). SMRL-SELD segments the 3D spatial\nspace, mapping it to a 2D plane, and a new regression localization loss is\nproposed to help the results converge toward the location of the corresponding\nevent. SMRL-SELD is location-oriented, allowing the model to learn event\nfeatures based on orientation. Thus, the method enables the model to process\npolyphonic sounds regardless of the number of overlapping events. We conducted\nexperiments on STARSS23 and STARSS22 datasets and our proposed SMRL-SELD\noutperforms the existing SELD methods in overall evaluation and polyphony\nenvironments.", "AI": {"tldr": "SMRL-SELD improves SELD by segmenting 3D space into 2D and using regression loss for better localization in polyphonic environments.", "motivation": "Existing multi-track methods limit generality in polyphonic settings due to track number constraints.", "method": "SMRL-SELD segments 3D space into 2D and introduces a regression localization loss for event-oriented learning.", "result": "Outperforms existing SELD methods on STARSS23 and STARSS22 datasets, especially in polyphony.", "conclusion": "SMRL-SELD enhances generality and performance in polyphonic sound environments."}}
{"id": "2504.15466", "pdf": "https://arxiv.org/pdf/2504.15466", "abs": "https://arxiv.org/abs/2504.15466", "authors": ["Jiayi Pan", "Xiuyu Li", "Long Lian", "Charlie Snell", "Yifei Zhou", "Adam Yala", "Trevor Darrell", "Kurt Keutzer", "Alane Suhr"], "title": "Learning Adaptive Parallel Reasoning with Language Models", "categories": ["cs.AI", "cs.CL"], "comment": "Code, model, and data are available at\n  https://github.com/Parallel-Reasoning/APR. The first three authors\n  contributed equally to this work", "summary": "Scaling inference-time computation has substantially improved the reasoning\ncapabilities of language models. However, existing methods have significant\nlimitations: serialized chain-of-thought approaches generate overly long\noutputs, leading to increased latency and exhausted context windows, while\nparallel methods such as self-consistency suffer from insufficient\ncoordination, resulting in redundant computations and limited performance\ngains. To address these shortcomings, we propose Adaptive Parallel Reasoning\n(APR), a novel reasoning framework that enables language models to orchestrate\nboth serialized and parallel computations end-to-end. APR generalizes existing\nreasoning methods by enabling adaptive multi-threaded inference using spawn()\nand join() operations. A key innovation is our end-to-end reinforcement\nlearning strategy, optimizing both parent and child inference threads to\nenhance task success rate without requiring predefined reasoning structures.\nExperiments on the Countdown reasoning task demonstrate significant benefits of\nAPR: (1) higher performance within the same context window (83.4% vs. 60.0% at\n4k context); (2) superior scalability with increased computation (80.1% vs.\n66.6% at 20k total tokens); (3) improved accuracy at equivalent latency (75.2%\nvs. 57.3% at approximately 5,000ms). APR represents a step towards enabling\nlanguage models to autonomously optimize their reasoning processes through\nadaptive allocation of computation.", "AI": {"tldr": "APR is a novel reasoning framework combining serial and parallel computations, outperforming existing methods in performance, scalability, and accuracy.", "motivation": "Existing reasoning methods like chain-of-thought and self-consistency have limitations in efficiency and coordination.", "method": "APR uses adaptive multi-threaded inference with spawn() and join() operations and reinforcement learning to optimize threads.", "result": "APR achieves higher performance (83.4% vs. 60.0%), better scalability (80.1% vs. 66.6%), and improved accuracy (75.2% vs. 57.3%).", "conclusion": "APR advances autonomous optimization of reasoning processes in language models."}}
{"id": "2504.15325", "pdf": "https://arxiv.org/pdf/2504.15325", "abs": "https://arxiv.org/abs/2504.15325", "authors": ["Alberto Casagrande", "Francesco Fabris", "Rossano Girometti", "Roberto Pagliarini"], "title": "Significativity Indices for Agreement Values", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "27 pages, 6 figures", "summary": "Agreement measures, such as Cohen's kappa or intraclass correlation, gauge\nthe matching between two or more classifiers. They are used in a wide range of\ncontexts from medicine, where they evaluate the effectiveness of medical\ntreatments and clinical trials, to artificial intelligence, where they can\nquantify the approximation due to the reduction of a classifier. The\nconsistency of different classifiers to a golden standard can be compared\nsimply by using the order induced by their agreement measure with respect to\nthe golden standard itself. Nevertheless, labelling an approach as good or bad\nexclusively by using the value of an agreement measure requires a scale or a\nsignificativity index. Some quality scales have been proposed in the literature\nfor Cohen's kappa, but they are mainly naive, and their boundaries are\narbitrary. This work proposes a general approach to evaluate the\nsignificativity of any agreement value between two classifiers and introduces\ntwo significativity indices: one dealing with finite data sets, the other one\nhandling classification probability distributions. Moreover, this manuscript\nconsiders the computational issues of evaluating such indices and identifies\nsome efficient algorithms to evaluate them.", "AI": {"tldr": "The paper proposes a general method to evaluate the significance of agreement measures between classifiers, introducing two new indices and addressing computational efficiency.", "motivation": "Current agreement measures lack robust scales or significance indices, leading to arbitrary evaluations of classifier performance.", "method": "Introduces two significativity indices for finite data sets and classification probability distributions, along with efficient computational algorithms.", "result": "Provides a framework to assess the significance of agreement values, improving the evaluation of classifier consistency.", "conclusion": "The proposed indices and computational methods enhance the reliability of agreement measure evaluations in various fields."}}
{"id": "2504.15397", "pdf": "https://arxiv.org/pdf/2504.15397", "abs": "https://arxiv.org/abs/2504.15397", "authors": ["Ankit Dhiman", "Manan Shah", "R Venkatesh Babu"], "title": "MirrorVerse: Pushing Diffusion Models to Realistically Reflect the World", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2025. Project Page: https://mirror-verse.github.io/", "summary": "Diffusion models have become central to various image editing tasks, yet they\noften fail to fully adhere to physical laws, particularly with effects like\nshadows, reflections, and occlusions. In this work, we address the challenge of\ngenerating photorealistic mirror reflections using diffusion-based generative\nmodels. Despite extensive training data, existing diffusion models frequently\noverlook the nuanced details crucial to authentic mirror reflections. Recent\napproaches have attempted to resolve this by creating synhetic datasets and\nframing reflection generation as an inpainting task; however, they struggle to\ngeneralize across different object orientations and positions relative to the\nmirror. Our method overcomes these limitations by introducing key augmentations\ninto the synthetic data pipeline: (1) random object positioning, (2) randomized\nrotations, and (3) grounding of objects, significantly enhancing generalization\nacross poses and placements. To further address spatial relationships and\nocclusions in scenes with multiple objects, we implement a strategy to pair\nobjects during dataset generation, resulting in a dataset robust enough to\nhandle these complex scenarios. Achieving generalization to real-world scenes\nremains a challenge, so we introduce a three-stage training curriculum to\ndevelop the MirrorFusion 2.0 model to improve real-world performance. We\nprovide extensive qualitative and quantitative evaluations to support our\napproach. The project page is available at: https://mirror-verse.github.io/.", "AI": {"tldr": "The paper introduces MirrorFusion 2.0, a diffusion-based model for generating photorealistic mirror reflections, addressing limitations in existing models by enhancing synthetic data and training strategies.", "motivation": "Existing diffusion models often fail to adhere to physical laws in image editing, particularly for mirror reflections, lacking nuanced details and generalization across object orientations.", "method": "The method augments synthetic data with random object positioning, rotations, and grounding, and pairs objects for complex scenes. A three-stage training curriculum improves real-world performance.", "result": "MirrorFusion 2.0 achieves improved generalization and photorealistic results, supported by qualitative and quantitative evaluations.", "conclusion": "The proposed approach effectively addresses the challenges of mirror reflection generation, offering a robust solution for real-world applications."}}
{"id": "2504.15667", "pdf": "https://arxiv.org/pdf/2504.15667", "abs": "https://arxiv.org/abs/2504.15667", "authors": ["Jingchen Zou", "Jianqiang Li", "Gabriel Jimenez", "Qing Zhao", "Daniel Racoceanu", "Matias Cosarinsky", "Enzo Ferrante", "Guanghui Fu"], "title": "Performance Estimation for Supervised Medical Image Segmentation Models on Unlabeled Data Using UniverSeg", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "The performance of medical image segmentation models is usually evaluated\nusing metrics like the Dice score and Hausdorff distance, which compare\npredicted masks to ground truth annotations. However, when applying the model\nto unseen data, such as in clinical settings, it is often impractical to\nannotate all the data, making the model's performance uncertain. To address\nthis challenge, we propose the Segmentation Performance Evaluator (SPE), a\nframework for estimating segmentation models' performance on unlabeled data.\nThis framework is adaptable to various evaluation metrics and model\narchitectures. Experiments on six publicly available datasets across six\nevaluation metrics including pixel-based metrics such as Dice score and\ndistance-based metrics like HD95, demonstrated the versatility and\neffectiveness of our approach, achieving a high correlation (0.956$\\pm$0.046)\nand low MAE (0.025$\\pm$0.019) compare with real Dice score on the independent\ntest set. These results highlight its ability to reliably estimate model\nperformance without requiring annotations. The SPE framework integrates\nseamlessly into any model training process without adding training overhead,\nenabling performance estimation and facilitating the real-world application of\nmedical image segmentation algorithms. The source code is publicly available", "AI": {"tldr": "The paper introduces the Segmentation Performance Evaluator (SPE), a framework for estimating medical image segmentation model performance on unlabeled data without needing ground truth annotations.", "motivation": "Evaluating segmentation models in clinical settings is challenging due to the impracticality of annotating all data, leading to uncertain performance on unseen data.", "method": "The SPE framework estimates performance using adaptable metrics (e.g., Dice score, HD95) and is tested on six datasets.", "result": "SPE achieved high correlation (0.956\u00b10.046) and low MAE (0.025\u00b10.019) compared to real Dice scores, proving its reliability.", "conclusion": "SPE enables practical performance estimation for medical image segmentation without annotations, facilitating real-world application."}}
{"id": "2504.15548", "pdf": "https://arxiv.org/pdf/2504.15548", "abs": "https://arxiv.org/abs/2504.15548", "authors": ["Elyas Meguellati", "Assaad Zeghina", "Shazia Sadiq", "Gianluca Demartini"], "title": "LLM-based Semantic Augmentation for Harmful Content Detection", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "Recent advances in large language models (LLMs) have demonstrated strong\nperformance on simple text classification tasks, frequently under zero-shot\nsettings. However, their efficacy declines when tackling complex social media\nchallenges such as propaganda detection, hateful meme classification, and\ntoxicity identification. Much of the existing work has focused on using LLMs to\ngenerate synthetic training data, overlooking the potential of LLM-based text\npreprocessing and semantic augmentation. In this paper, we introduce an\napproach that prompts LLMs to clean noisy text and provide context-rich\nexplanations, thereby enhancing training sets without substantial increases in\ndata volume. We systematically evaluate on the SemEval 2024 multi-label\nPersuasive Meme dataset and further validate on the Google Jigsaw toxic\ncomments and Facebook hateful memes datasets to assess generalizability. Our\nresults reveal that zero-shot LLM classification underperforms on these\nhigh-context tasks compared to supervised models. In contrast, integrating\nLLM-based semantic augmentation yields performance on par with approaches that\nrely on human-annotated data, at a fraction of the cost. These findings\nunderscore the importance of strategically incorporating LLMs into machine\nlearning (ML) pipeline for social media classification tasks, offering broad\nimplications for combating harmful content online.", "AI": {"tldr": "LLMs perform poorly on complex social media tasks like propaganda detection, but LLM-based text preprocessing and semantic augmentation can improve performance without large data increases.", "motivation": "Address the decline in LLM efficacy for high-context social media tasks by leveraging LLMs for text cleaning and semantic augmentation.", "method": "Use LLMs to preprocess noisy text and provide context-rich explanations, enhancing training sets. Evaluated on SemEval 2024, Google Jigsaw, and Facebook datasets.", "result": "Zero-shot LLM classification underperforms, but LLM-based augmentation matches human-annotated data performance at lower cost.", "conclusion": "Strategic LLM integration into ML pipelines is crucial for social media classification, offering cost-effective solutions for harmful content detection."}}
{"id": "2504.13920", "pdf": "https://arxiv.org/pdf/2504.13920", "abs": "https://arxiv.org/abs/2504.13920", "authors": ["Martina Vanelli", "Giacomo Como", "Fabio Fagnani"], "title": "How competitive are pay-as-bid auction games?", "categories": ["math.OC", "cs.GT", "cs.MA", "cs.SY", "eess.SY"], "comment": null, "summary": "We study the pay-as-bid auction game, a supply function model with\ndiscriminatory pricing and asymmetric firms. In this game, strategies are\nnon-decreasing supply functions relating pric to quantity and the exact choice\nof the strategy space turns out to be a crucial issue: when it includes all\nnon-decreasing continuous functions, pure-strategy Nash equilibria often fail\nto exist. To overcome this, we restrict the strategy space to the set of\nLipschitz-continuous functions and we prove that Nash equilibria always exist\n(under standard concavity assumptions) and consist of functions that are affine\non their own support and have slope equal to the maximum allowed Lipschitz\nconstant. We further show that the Nash equilibrium is unique up to the\nmarket-clearing price when the demand is affine and the asymmetric marginal\nproduction costs are homogeneous in zero. For quadratic production costs, we\nderive a closed-form expression and we compute the limit as the allowed\nLipschitz constant grows to infinity. Our results show that in the limit the\npay-as-bid auction game achieves perfect competition with efficient allocation\nand induces a lower market-clearing price compared to supply function models\nbased on uniform price auctions.", "AI": {"tldr": "The paper analyzes pay-as-bid auctions with asymmetric firms, proving Nash equilibria exist under Lipschitz-continuous strategies and showing perfect competition in the limit.", "motivation": "To address the lack of pure-strategy Nash equilibria in pay-as-bid auctions with unrestricted strategies by restricting the strategy space to Lipschitz-continuous functions.", "method": "Restrict strategies to Lipschitz-continuous functions, prove equilibrium existence, and analyze uniqueness and properties under specific conditions (affine demand, homogeneous costs).", "result": "Nash equilibria exist and are unique under certain conditions; the limit achieves perfect competition with efficient allocation and lower prices.", "conclusion": "Lipschitz restrictions enable equilibrium existence, and pay-as-bid auctions outperform uniform price auctions in achieving competitive outcomes."}}
{"id": "2504.04060", "pdf": "https://arxiv.org/pdf/2504.04060", "abs": "https://arxiv.org/abs/2504.04060", "authors": ["Yuhao Wang", "Heyang Liu", "Ziyang Cheng", "Ronghua Wu", "Qunshan Gu", "Yanfeng Wang", "Yu Wang"], "title": "VocalNet: Speech LLM with Multi-Token Prediction for Faster and High-Quality Generation", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "comment": null, "summary": "Speech large language models (LLMs) have emerged as a prominent research\nfocus in speech processing. We introduce VocalNet-1B and VocalNet-8B, a series\nof high-performance, low-latency speech LLMs enabled by a scalable and\nmodel-agnostic training framework designed for real-time voice interaction.\nCentral to our contribution is the first application of multi-token prediction\n(MTP) to speech LLMs. This approach represents a paradigm shift from standard\nnext-token prediction (NTP), offering simultaneous improvements in generation\nspeed and quality. Informed by analysis of MTP's effect on speech generation\nand experimental comparisons, we designed a straightforward and highly\neffective MTP implementation. Experiments demonstrate that VocalNet performs on\npar with mainstream Omni LLMs even with limited training data, and\nsignificantly surpasses existing open-source speech LLMs. To foster\nreproducibility and community advancement, all model weights, inference code,\ntraining data, and framework implementations have been made publicly available\nat https://github.com/SJTU-OmniAgent/VocalNet", "AI": {"tldr": "VocalNet-1B and VocalNet-8B are high-performance, low-latency speech LLMs using multi-token prediction (MTP) for faster, better speech generation, outperforming existing models.", "motivation": "To advance speech LLMs by improving generation speed and quality for real-time voice interaction.", "method": "Introduced multi-token prediction (MTP) as a paradigm shift from next-token prediction (NTP), with a scalable, model-agnostic training framework.", "result": "VocalNet matches mainstream Omni LLMs with limited data and surpasses open-source speech LLMs.", "conclusion": "MTP significantly enhances speech LLMs; VocalNet's open-source release aims to foster community progress."}}
{"id": "2504.15214", "pdf": "https://arxiv.org/pdf/2504.15214", "abs": "https://arxiv.org/abs/2504.15214", "authors": ["Amirmohammad Mohammadi", "Davelle Carreiro", "Alexandra Van Dine", "Joshua Peeples"], "title": "Histogram-based Parameter-efficient Tuning for Passive Sonar Classification", "categories": ["cs.LG", "cs.SD"], "comment": "5 pages, 4 figures. Under Review", "summary": "Parameter-efficient transfer learning (PETL) methods adapt large artificial\nneural networks to downstream tasks without fine-tuning the entire model.\nHowever, existing additive methods, such as adapters, sometimes struggle to\ncapture distributional shifts in intermediate feature embeddings. We propose a\nnovel histogram-based parameter-efficient tuning (HPT) technique that captures\nthe statistics of the target domain and modulates the embeddings. Experimental\nresults on three downstream passive sonar datasets (ShipsEar, DeepShip, VTUAD)\ndemonstrate that HPT outperforms conventional adapters. Notably, HPT achieves\n91.8% vs. 89.8% accuracy on VTUAD. Furthermore, HPT trains faster and yields\nfeature representations closer to those of fully fine-tuned models. Overall,\nHPT balances parameter savings and performance, providing a distribution-aware\nalternative to existing adapters and shows a promising direction for scalable\ntransfer learning in resource-constrained environments. The code is publicly\navailable:\nhttps://github.com/Advanced-Vision-and-Learning-Lab/HLAST_DeepShip_ParameterEfficient.", "AI": {"tldr": "HPT, a histogram-based parameter-efficient tuning method, outperforms adapters in accuracy and training speed for passive sonar tasks.", "motivation": "Address limitations of additive PETL methods like adapters in capturing distributional shifts in feature embeddings.", "method": "Proposes HPT to capture target domain statistics and modulate embeddings.", "result": "HPT achieves higher accuracy (91.8% vs. 89.8%) on VTUAD and trains faster than adapters.", "conclusion": "HPT balances parameter efficiency and performance, offering a scalable transfer learning solution for resource-constrained settings."}}
{"id": "2504.15552", "pdf": "https://arxiv.org/pdf/2504.15552", "abs": "https://arxiv.org/abs/2504.15552", "authors": ["Gengxian Cao", "Fengyuan Li", "Hong Duan", "Ye Yang", "Bofeng Wang", "Donghe Li"], "title": "A Multi-Agent Framework for Automated Qinqiang Opera Script Generation Using Large Language Models", "categories": ["cs.AI"], "comment": "17 pages,7 figures,1 tables", "summary": "This paper introduces a novel multi-Agent framework that automates the end to\nend production of Qinqiang opera by integrating Large Language Models , visual\ngeneration, and Text to Speech synthesis. Three specialized agents collaborate\nin sequence: Agent1 uses an LLM to craft coherent, culturally grounded\nscripts;Agent2 employs visual generation models to render contextually accurate\nstage scenes; and Agent3 leverages TTS to produce synchronized, emotionally\nexpressive vocal performances. In a case study on Dou E Yuan, the system\nachieved expert ratings of 3.8 for script fidelity, 3.5 for visual coherence,\nand 3.8 for speech accuracy-culminating in an overall score of 3.6, a 0.3 point\nimprovement over a Single Agent baseline. Ablation experiments demonstrate that\nremoving Agent2 or Agent3 leads to drops of 0.4 and 0.5 points, respectively,\nunderscoring the value of modular collaboration. This work showcases how AI\ndriven pipelines can streamline and scale the preservation of traditional\nperforming arts, and points toward future enhancements in cross modal\nalignment, richer emotional nuance, and support for additional opera genres.", "AI": {"tldr": "A multi-agent framework automates Qinqiang opera production using LLMs, visual generation, and TTS, achieving higher scores than a single-agent baseline.", "motivation": "To streamline and scale the preservation of traditional performing arts using AI-driven pipelines.", "method": "Three specialized agents collaborate: LLM for scripts, visual generation for scenes, and TTS for vocal performances.", "result": "Achieved expert ratings of 3.6 overall, with improvements over single-agent baselines and drops in ablation tests.", "conclusion": "The framework demonstrates AI's potential in preserving traditional arts, with future enhancements suggested."}}
{"id": "2504.15328", "pdf": "https://arxiv.org/pdf/2504.15328", "abs": "https://arxiv.org/abs/2504.15328", "authors": ["Usevalad Milasheuski", "Luca Barbieri", "Sanaz Kianoush", "Monica Nicoli", "Stefano Savazzi"], "title": "Bayesian Federated Learning for Continual Training", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Bayesian Federated Learning (BFL) enables uncertainty quantification and\nrobust adaptation in distributed learning. In contrast to the frequentist\napproach, it estimates the posterior distribution of a global model, offering\ninsights into model reliability. However, current BFL methods neglect continual\nlearning challenges in dynamic environments where data distributions shift over\ntime. We propose a continual BFL framework applied to human sensing with radar\ndata collected over several days. Using Stochastic Gradient Langevin Dynamics\n(SGLD), our approach sequentially updates the model, leveraging past posteriors\nto construct the prior for the new tasks. We assess the accuracy, the expected\ncalibration error (ECE) and the convergence speed of our approach against\nseveral baselines. Results highlight the effectiveness of continual Bayesian\nupdates in preserving knowledge and adapting to evolving data.", "AI": {"tldr": "A continual Bayesian Federated Learning (BFL) framework is proposed for dynamic environments, using SGLD to update models sequentially, outperforming baselines in accuracy, calibration, and convergence.", "motivation": "Current BFL methods lack adaptability to shifting data distributions in dynamic environments, limiting their practical utility.", "method": "The framework employs Stochastic Gradient Langevin Dynamics (SGLD) to sequentially update models, using past posteriors as priors for new tasks.", "result": "The approach demonstrates superior accuracy, lower expected calibration error (ECE), and faster convergence compared to baselines.", "conclusion": "Continual Bayesian updates effectively preserve knowledge and adapt to evolving data, enhancing BFL's robustness in dynamic settings."}}
{"id": "2504.15404", "pdf": "https://arxiv.org/pdf/2504.15404", "abs": "https://arxiv.org/abs/2504.15404", "authors": ["Tajamul Ashraf", "Rajes Manna", "Partha Sarathi Purkayastha", "Tavaheed Tariq", "Janibul Bashir"], "title": "Context Aware Grounded Teacher for Source Free Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "We focus on the Source Free Object Detection (SFOD) problem, when source data\nis unavailable during adaptation, and the model must adapt to the unlabeled\ntarget domain. In medical imaging, several approaches have leveraged a\nsemi-supervised student-teacher architecture to bridge domain discrepancy.\nContext imbalance in labeled training data and significant domain shifts\nbetween domains can lead to biased teacher models that produce inaccurate\npseudolabels, degrading the student model's performance and causing a mode\ncollapse. Class imbalance, particularly when one class significantly outnumbers\nanother, leads to contextual bias. To tackle the problem of context bias and\nthe significant performance drop of the student model in the SFOD setting, we\nintroduce Grounded Teacher (GT) as a standard framework. In this study, we\nmodel contextual relationships using a dedicated relational context module and\nleverage it to mitigate inherent biases in the model. This approach enables us\nto apply augmentations to closely related classes, across and within domains,\nenhancing the performance of underrepresented classes while keeping the effect\non dominant classes minimal. We further improve the quality of predictions by\nimplementing an expert foundational branch to supervise the student model. We\nvalidate the effectiveness of our approach in mitigating context bias under the\nSFOD setting through experiments on three medical datasets supported by\ncomprehensive ablation studies. All relevant resources, including preprocessed\ndata, trained model weights, and code, are publicly available at this\nhttps://github.com/Tajamul21/Grounded_Teacher.", "AI": {"tldr": "The paper introduces Grounded Teacher (GT) to address context bias and performance drops in Source Free Object Detection (SFOD) by leveraging a relational context module and expert foundational branch.", "motivation": "To mitigate biased teacher models and mode collapse in SFOD, especially in medical imaging, where domain shifts and class imbalance degrade performance.", "method": "Uses a relational context module to model contextual relationships and an expert foundational branch to supervise the student model, applying augmentations to related classes.", "result": "Validated on three medical datasets, GT effectively reduces context bias and improves performance for underrepresented classes.", "conclusion": "GT provides a robust framework for SFOD, addressing bias and enhancing model adaptability in domain-shifted scenarios."}}
{"id": "2504.15473", "pdf": "https://arxiv.org/pdf/2504.15473", "abs": "https://arxiv.org/abs/2504.15473", "authors": ["Berk Tinaz", "Zalan Fabian", "Mahdi Soltanolkotabi"], "title": "Emergence and Evolution of Interpretable Concepts in Diffusion Models", "categories": ["cs.CV", "cs.LG", "eess.IV", "I.2.6; I.2.10"], "comment": "32 pages, 32 figures, preliminary version", "summary": "Diffusion models have become the go-to method for text-to-image generation,\nproducing high-quality images from noise through a process called reverse\ndiffusion. Understanding the dynamics of the reverse diffusion process is\ncrucial in steering the generation and achieving high sample quality. However,\nthe inner workings of diffusion models is still largely a mystery due to their\nblack-box nature and complex, multi-step generation process. Mechanistic\nInterpretability (MI) techniques, such as Sparse Autoencoders (SAEs), aim at\nuncovering the operating principles of models through granular analysis of\ntheir internal representations. These MI techniques have been successful in\nunderstanding and steering the behavior of large language models at scale.\nHowever, the great potential of SAEs has not yet been applied toward gaining\ninsight into the intricate generative process of diffusion models. In this\nwork, we leverage the SAE framework to probe the inner workings of a popular\ntext-to-image diffusion model, and uncover a variety of human-interpretable\nconcepts in its activations. Interestingly, we find that even before the first\nreverse diffusion step is completed, the final composition of the scene can be\npredicted surprisingly well by looking at the spatial distribution of activated\nconcepts. Moreover, going beyond correlational analysis, we show that the\ndiscovered concepts have a causal effect on the model output and can be\nleveraged to steer the generative process. We design intervention techniques\naimed at manipulating image composition and style, and demonstrate that (1) in\nearly stages of diffusion image composition can be effectively controlled, (2)\nin the middle stages of diffusion image composition is finalized, however\nstylistic interventions are effective, and (3) in the final stages of diffusion\nonly minor textural details are subject to change.", "AI": {"tldr": "The paper explores using Sparse Autoencoders (SAEs) to interpret and control the reverse diffusion process in text-to-image diffusion models, uncovering human-interpretable concepts and demonstrating their causal effects on image generation.", "motivation": "To demystify the black-box nature of diffusion models and understand their internal dynamics for better control over image generation.", "method": "Leverages SAEs to analyze activations in a text-to-image diffusion model, identifying interpretable concepts and testing their causal impact through interventions.", "result": "Reveals that scene composition can be predicted early in diffusion, and concepts can be used to control composition and style at different stages.", "conclusion": "SAEs provide valuable insights into diffusion models, enabling targeted interventions for steering image generation."}}
{"id": "2504.15573", "pdf": "https://arxiv.org/pdf/2504.15573", "abs": "https://arxiv.org/abs/2504.15573", "authors": ["Yuxin Jiang", "Yufei Wang", "Chuhan Wu", "Xinyi Dai", "Yan Xu", "Weinan Gan", "Yasheng Wang", "Xin Jiang", "Lifeng Shang", "Ruiming Tang", "Wei Wang"], "title": "Instruction-Tuning Data Synthesis from Scratch via Web Reconstruction", "categories": ["cs.CL"], "comment": "15 pages, 11 figures, 9 tables", "summary": "The improvement of LLMs' instruction-following capabilities depends\ncritically on the availability of high-quality instruction-response pairs.\nWhile existing automatic data synthetic methods alleviate the burden of manual\ncuration, they often rely heavily on either the quality of seed data or strong\nassumptions about the structure and content of web documents. To tackle these\nchallenges, we propose Web Reconstruction (WebR), a fully automated framework\nfor synthesizing high-quality instruction-tuning (IT) data directly from raw\nweb documents with minimal assumptions. Leveraging the inherent diversity of\nraw web content, we conceptualize web reconstruction as an instruction-tuning\ndata synthesis task via a novel dual-perspective paradigm--Web as Instruction\nand Web as Response--where each web document is designated as either an\ninstruction or a response to trigger the reconstruction process. Comprehensive\nexperiments show that datasets generated by WebR outperform state-of-the-art\nbaselines by up to 16.65% across four instruction-following benchmarks.\nNotably, WebR demonstrates superior compatibility, data efficiency, and\nscalability, enabling enhanced domain adaptation with minimal effort. The data\nand code are publicly available at https://github.com/YJiangcm/WebR.", "AI": {"tldr": "WebR is an automated framework for synthesizing high-quality instruction-tuning data from raw web documents, outperforming existing methods by up to 16.65% in benchmarks.", "motivation": "Existing methods rely on seed data quality or strong assumptions about web documents, limiting their effectiveness.", "method": "WebR uses a dual-perspective paradigm (Web as Instruction and Web as Response) to reconstruct web documents into instruction-response pairs.", "result": "WebR outperforms state-of-the-art baselines by up to 16.65% in benchmarks, showing superior compatibility, data efficiency, and scalability.", "conclusion": "WebR enables enhanced domain adaptation with minimal effort, offering a scalable solution for high-quality instruction-tuning data."}}
{"id": "2504.15610", "pdf": "https://arxiv.org/pdf/2504.15610", "abs": "https://arxiv.org/abs/2504.15610", "authors": ["Md Millat", "Md Motiur"], "title": "A LoRA-Based Approach to Fine-Tuning LLMs for Educational Guidance in Resource-Constrained Settings", "categories": ["cs.AI", "68T05 (Learning and adaptive systems), 68T07 (Artificial\n  intelligence and education)"], "comment": "18 pages, 6 figures (3 graphs + 3 flowchart/architecture diagrams),\n  submitted as a preprint for review consideration in AI for Education or\n  Machine Learning applications in low-resource settings. Includes detailed\n  experiments with LoRA and quantization methods for efficient LLM fine-tuning", "summary": "The current study describes a cost-effective method for adapting large\nlanguage models (LLMs) for academic advising with study-abroad contexts in mind\nand for application in low-resource methods for acculturation. With the\nMistral-7B-Instruct model applied with a Low-Rank Adaptation (LoRA) method and\na 4-bit quantization method, the model underwent training in two distinct\nstages related to this study's purpose to enhance domain specificity while\nmaintaining computational efficiency. In Phase 1, the model was conditioned\nwith a synthetic dataset via the Gemini Pro API, and in Phase 2, it was trained\nwith manually curated datasets from the StudyAbroadGPT project to achieve\nenhanced, contextualized responses. Technical innovations entailed\nmemory-efficient quantization, parameter-efficient adaptation, and continuous\ntraining analytics via Weights & Biases. After training, this study\ndemonstrated a reduction in training loss by 52.7%, 92% accuracy in\ndomain-specific recommendations, achieved 95% markdown-based formatting\nsupport, and a median run-rate of 100 samples per second on off-the-shelf GPU\nequipment. These findings support the effective application of\ninstruction-tuned LLMs within educational advisers, especially in low-resource\ninstitutional scenarios. Limitations included decreased generalizability and\nthe application of a synthetically generated dataset, but this framework is\nscalable for adding new multilingual-augmented and real-time academic advising\nprocesses. Future directions may include plans for the integration of\nretrieval-augmented generation, applying dynamic quantization routines, and\nconnecting to real-time academic databases to increase adaptability and\naccuracy.", "AI": {"tldr": "A cost-effective method adapts LLMs for academic advising in study-abroad contexts using Mistral-7B-Instruct with LoRA and 4-bit quantization, achieving high accuracy and efficiency.", "motivation": "To enhance domain specificity and computational efficiency for academic advising in low-resource settings.", "method": "Two-phase training: synthetic dataset conditioning (Phase 1) and manual dataset training (Phase 2) with memory-efficient quantization and LoRA.", "result": "52.7% training loss reduction, 92% accuracy, 95% formatting support, and 100 samples/sec on standard GPUs.", "conclusion": "Effective for low-resource educational advising, with future plans for retrieval-augmented generation and real-time database integration."}}
{"id": "2504.15366", "pdf": "https://arxiv.org/pdf/2504.15366", "abs": "https://arxiv.org/abs/2504.15366", "authors": ["Qifan Yan", "Andrew Liu", "Shiqi He", "Mathias L\u00e9cuyer", "Ivan Beschastnikh"], "title": "FedFetch: Faster Federated Learning with Adaptive Downstream Prefetching", "categories": ["cs.LG", "cs.DC"], "comment": "Accepted at INFOCOM 2025", "summary": "Federated learning (FL) is a machine learning paradigm that facilitates\nmassively distributed model training with end-user data on edge devices\ndirected by a central server. However, the large number of heterogeneous\nclients in FL deployments leads to a communication bottleneck between the\nserver and the clients. This bottleneck is made worse by straggling clients,\nany one of which will further slow down training. To tackle these challenges,\nresearchers have proposed techniques like client sampling and update\ncompression. These techniques work well in isolation but combine poorly in the\ndownstream, server-to-client direction. This is because unselected clients have\noutdated local model states and need to synchronize these states with the\nserver first.\n  We introduce FedFetch, a strategy to mitigate the download time overhead\ncaused by combining client sampling and compression techniques. FedFetch\nachieves this with an efficient prefetch schedule for clients to prefetch model\nstates multiple rounds before a stated training round. We empirically show that\nadding FedFetch to communication efficient FL techniques reduces end-to-end\ntraining time by 1.26$\\times$ and download time by 4.49$\\times$ across\ncompression techniques with heterogeneous client settings. Our implementation\nis available at https://github.com/DistributedML/FedFetch", "AI": {"tldr": "FedFetch reduces download time in federated learning by prefetching model states, improving training efficiency.", "motivation": "Address communication bottlenecks in FL caused by heterogeneous clients and stragglers, especially when combining client sampling and compression.", "method": "Introduces FedFetch, a prefetch schedule for clients to synchronize model states ahead of training rounds.", "result": "Reduces end-to-end training time by 1.26\u00d7 and download time by 4.49\u00d7 in heterogeneous settings.", "conclusion": "FedFetch effectively mitigates download overhead, enhancing FL efficiency when combined with existing techniques."}}
{"id": "2504.15415", "pdf": "https://arxiv.org/pdf/2504.15415", "abs": "https://arxiv.org/abs/2504.15415", "authors": ["David Ma", "Yuanxing Zhang", "Jincheng Ren", "Jarvis Guo", "Yifan Yao", "Zhenlin Wei", "Zhenzhu Yang", "Zhongyuan Peng", "Boyu Feng", "Jun Ma", "Xiao Gu", "Zhoufutu Wen", "King Zhu", "Yancheng He", "Meng Cao", "Shiwen Ni", "Jiaheng Liu", "Wenhao Huang", "Ge Zhang", "Xiaojie Jin"], "title": "IV-Bench: A Benchmark for Image-Grounded Video Perception and Reasoning in Multimodal LLMs", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Existing evaluation frameworks for Multimodal Large Language Models (MLLMs)\nprimarily focus on image reasoning or general video understanding tasks,\nlargely overlooking the significant role of image context in video\ncomprehension. To bridge this gap, we propose IV-Bench, the first comprehensive\nbenchmark for evaluating Image-Grounded Video Perception and Reasoning.\nIV-Bench consists of 967 videos paired with 2,585 meticulously annotated\nimage-text queries across 13 tasks (7 perception and 6 reasoning tasks) and 5\nrepresentative categories. Extensive evaluations of state-of-the-art\nopen-source (e.g., InternVL2.5, Qwen2.5-VL) and closed-source (e.g., GPT-4o,\nGemini2-Flash and Gemini2-Pro) MLLMs demonstrate that current models\nsubstantially underperform in image-grounded video Perception and Reasoning,\nmerely achieving at most 28.9% accuracy. Further analysis reveals key factors\ninfluencing model performance on IV-Bench, including inference pattern, frame\nnumber, and resolution. Additionally, through a simple data synthesis approach,\nwe demonstratethe challenges of IV- Bench extend beyond merely aligning the\ndata format in the training proecss. These findings collectively provide\nvaluable insights for future research. Our codes and data are released in\nhttps://github.com/multimodal-art-projection/IV-Bench.", "AI": {"tldr": "IV-Bench is a new benchmark for evaluating image-grounded video perception and reasoning in MLLMs, revealing current models' limitations (max 28.9% accuracy) and key performance factors.", "motivation": "Existing MLLM evaluation frameworks neglect image context in video comprehension, prompting the creation of IV-Bench to address this gap.", "method": "IV-Bench includes 967 videos with 2,585 annotated image-text queries across 13 tasks (7 perception, 6 reasoning) and 5 categories. Evaluated state-of-the-art MLLMs (open/closed-source).", "result": "Current MLLMs perform poorly (\u226428.9% accuracy). Key factors: inference pattern, frame number, resolution. Data synthesis shows challenges beyond format alignment.", "conclusion": "IV-Bench highlights MLLMs' shortcomings in image-grounded video tasks, offering insights for future research. Data and code are publicly available."}}
{"id": "2504.15496", "pdf": "https://arxiv.org/pdf/2504.15496", "abs": "https://arxiv.org/abs/2504.15496", "authors": ["Eammon A. Littler", "Emmanuel A. Mannoh", "Ethan P. M. LaRochelle"], "title": "Fluorescence Reference Target Quantitative Analysis Library", "categories": ["physics.med-ph", "cs.CV", "eess.IV", "q-bio.QM"], "comment": "12 pages, 1 table, 4 figures. Code available:\n  https://github.com/QUEL-Imaging/quel-qal), PyPi: quel-qal", "summary": "Standardized performance evaluation of fluorescence imaging systems remains a\ncritical unmet need in the field of fluorescence-guided surgery (FGS). While\nthe American Association of Physicists in Medicine (AAPM) TG311 report and\nrecent FDA draft guidance provide recommended metrics for system\ncharacterization, practical tools for extracting these metrics remain limited,\ninconsistent, and often inaccessible. We present QUEL-QAL, an open-source\nPython library designed to streamline and standardize the quantitative analysis\nof fluorescence images using solid reference targets. The library provides a\nmodular, reproducible workflow that includes region of interest (ROI)\ndetection, statistical analysis, and visualization capabilities. QUEL-QAL\nsupports key metrics such as response linearity, limit of detection, depth\nsensitivity, and spatial resolution, in alignment with regulatory and academic\nguidance. Built on widely adopted Python packages, the library is designed to\nbe extensible, enabling users to adapt it to novel target designs and analysis\nprotocols. By promoting transparency, reproducibility, and regulatory\nalignment, QUEL-QAL offers a foundational tool to support standardized\nbenchmarking and accelerate the development and evaluation of fluorescence\nimaging systems.", "AI": {"tldr": "QUEL-QAL is an open-source Python library for standardized quantitative analysis of fluorescence images in FGS, addressing unmet needs in performance evaluation.", "motivation": "Standardized performance evaluation tools for fluorescence imaging systems are lacking, despite existing guidelines.", "method": "QUEL-QAL provides a modular workflow for ROI detection, statistical analysis, and visualization, supporting key metrics like response linearity and spatial resolution.", "result": "The library enables reproducible, transparent, and regulatory-aligned analysis, facilitating standardized benchmarking.", "conclusion": "QUEL-QAL is a foundational tool to improve fluorescence imaging system evaluation and development."}}
{"id": "2504.15604", "pdf": "https://arxiv.org/pdf/2504.15604", "abs": "https://arxiv.org/abs/2504.15604", "authors": ["Pavan Yadav", "Nikhil Khandalkar", "Krishna Shinde", "Lokesh B. Ramegowda", "Rajarshi Das"], "title": "Exploring Next Token Prediction in Theory of Mind (ToM) Tasks: Comparative Experiments with GPT-2 and LLaMA-2 AI Models", "categories": ["cs.CL", "cs.AI"], "comment": "75 pages, 60 figures", "summary": "Language models have made significant progress in generating coherent text\nand predicting next tokens based on input prompts. This study compares the\nnext-token prediction performance of two well-known models: OpenAI's GPT-2 and\nMeta's Llama-2-7b-chat-hf on Theory of Mind (ToM) tasks. To evaluate their\ncapabilities, we built a dataset from 10 short stories sourced from the Explore\nToM Dataset. We enhanced these stories by programmatically inserting additional\nsentences (infills) using GPT-4, creating variations that introduce different\nlevels of contextual complexity. This setup enables analysis of how increasing\ncontext affects model performance. We tested both models under four temperature\nsettings (0.01, 0.5, 1.0, 2.0) and evaluated their ability to predict the next\ntoken across three reasoning levels. Zero-order reasoning involves tracking the\nstate, either current (ground truth) or past (memory). First-order reasoning\nconcerns understanding another's mental state (e.g., \"Does Anne know the apple\nis salted?\"). Second-order reasoning adds recursion (e.g., \"Does Anne think\nthat Charles knows the apple is salted?\").\n  Our results show that adding more infill sentences slightly reduces\nprediction accuracy, as added context increases complexity and ambiguity.\nLlama-2 consistently outperforms GPT-2 in prediction accuracy, especially at\nlower temperatures, demonstrating greater confidence in selecting the most\nprobable token. As reasoning complexity rises, model responses diverge more.\nNotably, GPT-2 and Llama-2 display greater variability in predictions during\nfirst- and second-order reasoning tasks. These findings illustrate how model\narchitecture, temperature, and contextual complexity influence next-token\nprediction, contributing to a better understanding of the strengths and\nlimitations of current language models.", "AI": {"tldr": "The study compares GPT-2 and Llama-2-7b-chat-hf on Theory of Mind tasks, finding Llama-2 outperforms GPT-2, especially at lower temperatures, with added context reducing accuracy.", "motivation": "To evaluate how model architecture, temperature, and contextual complexity affect next-token prediction in Theory of Mind tasks.", "method": "Built a dataset from 10 short stories, enhanced with GPT-4 infills, and tested models under four temperature settings across three reasoning levels.", "result": "Llama-2 outperforms GPT-2, especially at lower temperatures. Added context reduces accuracy, and higher reasoning complexity increases prediction variability.", "conclusion": "The study highlights the impact of model architecture, temperature, and context on next-token prediction, revealing strengths and limitations of current language models."}}
{"id": "2504.15668", "pdf": "https://arxiv.org/pdf/2504.15668", "abs": "https://arxiv.org/abs/2504.15668", "authors": ["Mir Md Sajid Sarwar", "Rajarshi Ray"], "title": "Exploring Inevitable Waypoints for Unsolvability Explanation in Hybrid Planning Problems", "categories": ["cs.AI", "cs.FL", "I.2.0; F.4.3"], "comment": null, "summary": "Explaining unsolvability of planning problems is of significant research\ninterest in Explainable AI Planning. AI planning literature has reported\nseveral research efforts on generating explanations of solutions to planning\nproblems. However, explaining the unsolvability of planning problems remains a\nlargely open and understudied problem. A widely practiced approach to plan\ngeneration and automated problem solving, in general, is to decompose tasks\ninto sub-problems that help progressively converge towards the goal. In this\npaper, we propose to adopt the same philosophy of sub-problem identification as\na mechanism for analyzing and explaining unsolvability of planning problems in\nhybrid systems. In particular, for a given unsolvable planning problem, we\npropose to identify common waypoints, which are universal obstacles to plan\nexistence; in other words, they appear on every plan from the source to the\nplanning goal. This work envisions such waypoints as sub-problems of the\nplanning problem and the unreachability of any of these waypoints as an\nexplanation for the unsolvability of the original planning problem. We propose\na novel method of waypoint identification by casting the problem as an instance\nof the longest common subsequence problem, a widely popular problem in computer\nscience, typically considered as an illustrative example for the dynamic\nprogramming paradigm. Once the waypoints are identified, we perform symbolic\nreachability analysis on them to identify the earliest unreachable waypoint and\nreport it as the explanation of unsolvability. We present experimental results\non unsolvable planning problems in hybrid domains.", "AI": {"tldr": "The paper proposes a method to explain unsolvability in planning problems by identifying universal obstacles (waypoints) and analyzing their unreachability.", "motivation": "Explaining unsolvability in planning problems is understudied, and the paper aims to address this gap by leveraging sub-problem decomposition.", "method": "The approach identifies waypoints as common obstacles, formulates their identification as a longest common subsequence problem, and uses symbolic reachability analysis to find the earliest unreachable waypoint.", "result": "Experimental results demonstrate the method's effectiveness in explaining unsolvability in hybrid domains.", "conclusion": "The proposed method provides a systematic way to explain unsolvability by focusing on unreachable waypoints, advancing Explainable AI Planning."}}
{"id": "2504.15369", "pdf": "https://arxiv.org/pdf/2504.15369", "abs": "https://arxiv.org/abs/2504.15369", "authors": ["Calvin Luo", "Zilai Zeng", "Yilun Du", "Chen Sun"], "title": "Solving New Tasks by Adapting Internet Video Knowledge", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "ICLR 2025. Project Webpage:\n  https://diffusion-supervision.github.io/adapt2act/", "summary": "Video generative models demonstrate great promise in robotics by serving as\nvisual planners or as policy supervisors. When pretrained on internet-scale\ndata, such video models intimately understand alignment with natural language,\nand can thus facilitate generalization to novel downstream behavior through\ntext-conditioning. However, they may not be sensitive to the specificities of\nthe particular environment the agent inhabits. On the other hand, training\nvideo models on in-domain examples of robotic behavior naturally encodes\nenvironment-specific intricacies, but the scale of available demonstrations may\nnot be sufficient to support generalization to unseen tasks via natural\nlanguage specification. In this work, we investigate different adaptation\ntechniques that integrate in-domain information with large-scale pretrained\nvideo models, and explore the extent to which they enable novel\ntext-conditioned generalization for robotic tasks, while also considering their\nindependent data and resource considerations. We successfully demonstrate\nacross robotic environments that adapting powerful video models with small\nscales of example data can successfully facilitate generalization to novel\nbehaviors. In particular, we present a novel adaptation strategy, termed\nInverse Probabilistic Adaptation, that not only consistently achieves strong\ngeneralization performance across robotic tasks and settings, but also exhibits\nrobustness to the quality of adaptation data, successfully solving novel tasks\neven when only suboptimal in-domain demonstrations are available.", "AI": {"tldr": "The paper explores adaptation techniques to combine in-domain robotic data with large-scale pretrained video models for text-conditioned generalization in robotics.", "motivation": "To address the limitations of pretrained video models (lack of environment-specific details) and in-domain models (limited generalization), the study aims to integrate both for better robotic task performance.", "method": "Investigates various adaptation techniques, including a novel Inverse Probabilistic Adaptation, to merge in-domain data with pretrained models.", "result": "Demonstrates successful generalization to novel tasks using small-scale in-domain data, with the proposed method showing robustness to data quality.", "conclusion": "Adapting large-scale video models with in-domain data enables effective generalization in robotics, even with suboptimal demonstrations."}}
{"id": "2504.15470", "pdf": "https://arxiv.org/pdf/2504.15470", "abs": "https://arxiv.org/abs/2504.15470", "authors": ["Jonathan Brokman", "Amit Giloni", "Omer Hofman", "Roman Vainshtein", "Hisashi Kojima", "Guy Gilboa"], "title": "Manifold Induced Biases for Zero-shot and Few-shot Detection of Generated Images", "categories": ["cs.CV"], "comment": "Accepted to ICLR 2025 (The International Conference on Learning\n  Representations)", "summary": "Distinguishing between real and AI-generated images, commonly referred to as\n'image detection', presents a timely and significant challenge. Despite\nextensive research in the (semi-)supervised regime, zero-shot and few-shot\nsolutions have only recently emerged as promising alternatives. Their main\nadvantage is in alleviating the ongoing data maintenance, which quickly becomes\noutdated due to advances in generative technologies. We identify two main gaps:\n(1) a lack of theoretical grounding for the methods, and (2) significant room\nfor performance improvements in zero-shot and few-shot regimes. Our approach is\nfounded on understanding and quantifying the biases inherent in generated\ncontent, where we use these quantities as criteria for characterizing generated\nimages. Specifically, we explore the biases of the implicit probability\nmanifold, captured by a pre-trained diffusion model. Through score-function\nanalysis, we approximate the curvature, gradient, and bias towards points on\nthe probability manifold, establishing criteria for detection in the zero-shot\nregime. We further extend our contribution to the few-shot setting by employing\na mixture-of-experts methodology. Empirical results across 20 generative models\ndemonstrate that our method outperforms current approaches in both zero-shot\nand few-shot settings. This work advances the theoretical understanding and\npractical usage of generated content biases through the lens of manifold\nanalysis.", "AI": {"tldr": "The paper addresses the challenge of distinguishing real from AI-generated images, proposing a zero-shot and few-shot detection method based on analyzing biases in generated content using manifold analysis.", "motivation": "The motivation is to overcome the limitations of outdated data in supervised methods and improve detection performance in zero-shot and few-shot regimes.", "method": "The method involves quantifying biases in generated content using a pre-trained diffusion model, analyzing score functions, and extending to few-shot detection with a mixture-of-experts approach.", "result": "Empirical results show superior performance over existing methods across 20 generative models in both zero-shot and few-shot settings.", "conclusion": "The work advances theoretical understanding and practical detection of generated content biases through manifold analysis."}}
{"id": "2504.15756", "pdf": "https://arxiv.org/pdf/2504.15756", "abs": "https://arxiv.org/abs/2504.15756", "authors": ["Qirui Yang", "Fangpu Zhang", "Yeying Jin", "Qihua Cheng", "Pengtao Jiang", "Huanjing Yue", "Jingyu Yang"], "title": "DSDNet: Raw Domain Demoir\u00e9ing via Dual Color-Space Synergy", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "With the rapid advancement of mobile imaging, capturing screens using\nsmartphones has become a prevalent practice in distance learning and conference\nrecording. However, moir\\'e artifacts, caused by frequency aliasing between\ndisplay screens and camera sensors, are further amplified by the image signal\nprocessing pipeline, leading to severe visual degradation. Existing sRGB domain\ndemoir\\'eing methods struggle with irreversible information loss, while recent\ntwo-stage raw domain approaches suffer from information bottlenecks and\ninference inefficiency. To address these limitations, we propose a single-stage\nraw domain demoir\\'eing framework, Dual-Stream Demoir\\'eing Network (DSDNet),\nwhich leverages the synergy of raw and YCbCr images to remove moir\\'e while\npreserving luminance and color fidelity. Specifically, to guide luminance\ncorrection and moir\\'e removal, we design a raw-to-YCbCr mapping pipeline and\nintroduce the Synergic Attention with Dynamic Modulation (SADM) module. This\nmodule enriches the raw-to-sRGB conversion with cross-domain contextual\nfeatures. Furthermore, to better guide color fidelity, we develop a\nLuminance-Chrominance Adaptive Transformer (LCAT), which decouples luminance\nand chrominance representations. Extensive experiments demonstrate that DSDNet\noutperforms state-of-the-art methods in both visual quality and quantitative\nevaluation, and achieves an inference speed $\\mathrm{\\textbf{2.4x}}$ faster\nthan the second-best method, highlighting its practical advantages. We provide\nan anonymous online demo at https://xxxxxxxxdsdnet.github.io/DSDNet/.", "AI": {"tldr": "DSDNet is a single-stage raw domain demoir\u00e9ing framework that outperforms existing methods in visual quality, speed, and color fidelity.", "motivation": "Addressing the limitations of existing demoir\u00e9ing methods, which suffer from irreversible information loss or inefficiency.", "method": "Proposes DSDNet, leveraging raw and YCbCr images, with Synergic Attention with Dynamic Modulation (SADM) and Luminance-Chrominance Adaptive Transformer (LCAT).", "result": "DSDNet achieves superior visual quality, faster inference speed (2.4x), and better color fidelity.", "conclusion": "DSDNet is a practical and efficient solution for demoir\u00e9ing, validated by extensive experiments."}}
{"id": "2504.15630", "pdf": "https://arxiv.org/pdf/2504.15630", "abs": "https://arxiv.org/abs/2504.15630", "authors": ["Xiaowei Yuan", "Zhao Yang", "Ziyang Huang", "Yequan Wang", "Siqi Fan", "Yiming Ju", "Jun Zhao", "Kang Liu"], "title": "Exploiting Contextual Knowledge in LLMs through V-usable Information based Layer Enhancement", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious tasks, yet they often struggle with context-faithfulness generations\nthat properly reflect contextual knowledge. While existing approaches focus on\nenhancing the decoding strategies, they ignore the fundamental mechanism of how\ncontextual information is processed within LLMs' internal states. As a result,\nLLMs remain limited in their ability to fully leverage contextual knowledge. In\nthis paper, we propose Context-aware Layer Enhancement (CaLE), a novel\nintervention method that enhances the utilization of contextual knowledge\nwithin LLMs' internal representations. By employing V-usable information\nanalysis, CaLE strategically amplifies the growth of contextual information at\nan optimal layer, thereby enriching representations in the final layer. Our\nexperiments demonstrate that CaLE effectively improves context-faithful\ngeneration in Question-Answering tasks, particularly in scenarios involving\nunknown or conflicting contextual knowledge.", "AI": {"tldr": "The paper introduces Context-aware Layer Enhancement (CaLE), a method to improve LLMs' context-faithful generation by optimizing internal contextual information processing.", "motivation": "LLMs struggle with context-faithful generation despite their capabilities. Existing methods overlook internal contextual processing mechanisms.", "method": "Proposes CaLE, using V-usable information analysis to amplify contextual information at an optimal layer, enhancing final representations.", "result": "CaLE improves context-faithful generation in Question-Answering tasks, especially with unknown or conflicting contexts.", "conclusion": "CaLE effectively addresses LLMs' limitations in leveraging contextual knowledge, enhancing their performance in context-dependent tasks."}}
{"id": "2504.15699", "pdf": "https://arxiv.org/pdf/2504.15699", "abs": "https://arxiv.org/abs/2504.15699", "authors": ["Ning Wang", "Zihan Yan", "Weiyang Li", "Chuan Ma", "He Chen", "Tao Xiang"], "title": "Advancing Embodied Agent Security: From Safety Benchmarks to Input Moderation", "categories": ["cs.AI"], "comment": "9 pages", "summary": "Embodied agents exhibit immense potential across a multitude of domains,\nmaking the assurance of their behavioral safety a fundamental prerequisite for\ntheir widespread deployment. However, existing research predominantly\nconcentrates on the security of general large language models, lacking\nspecialized methodologies for establishing safety benchmarks and input\nmoderation tailored to embodied agents. To bridge this gap, this paper\nintroduces a novel input moderation framework, meticulously designed to\nsafeguard embodied agents. This framework encompasses the entire pipeline,\nincluding taxonomy definition, dataset curation, moderator architecture, model\ntraining, and rigorous evaluation. Notably, we introduce EAsafetyBench, a\nmeticulously crafted safety benchmark engineered to facilitate both the\ntraining and stringent assessment of moderators specifically designed for\nembodied agents. Furthermore, we propose Pinpoint, an innovative\nprompt-decoupled input moderation scheme that harnesses a masked attention\nmechanism to effectively isolate and mitigate the influence of functional\nprompts on moderation tasks. Extensive experiments conducted on diverse\nbenchmark datasets and models validate the feasibility and efficacy of the\nproposed approach. The results demonstrate that our methodologies achieve an\nimpressive average detection accuracy of 94.58%, surpassing the performance of\nexisting state-of-the-art techniques, alongside an exceptional moderation\nprocessing time of merely 0.002 seconds per instance.", "AI": {"tldr": "The paper introduces a novel input moderation framework and benchmark (EAsafetyBench) for embodied agents, achieving high accuracy and efficiency.", "motivation": "Existing research lacks specialized safety methodologies for embodied agents, necessitating tailored solutions.", "method": "Proposes a framework with taxonomy, dataset curation, moderator architecture, and Pinpoint, a prompt-decoupled moderation scheme.", "result": "Achieves 94.58% detection accuracy and 0.002s moderation time per instance, outperforming existing methods.", "conclusion": "The framework effectively safeguards embodied agents, demonstrating superior performance and feasibility."}}
{"id": "2504.15399", "pdf": "https://arxiv.org/pdf/2504.15399", "abs": "https://arxiv.org/abs/2504.15399", "authors": ["Guy Zamir", "Aryan Dokania", "Bo Zhao", "Rose Yu"], "title": "Improving Learning to Optimize Using Parameter Symmetries", "categories": ["cs.LG"], "comment": "Accepted at the ICLR Workshop on Neural Network Weights as a New Data\n  Modality 2025", "summary": "We analyze a learning-to-optimize (L2O) algorithm that exploits parameter\nspace symmetry to enhance optimization efficiency. Prior work has shown that\njointly learning symmetry transformations and local updates improves\nmeta-optimizer performance. Supporting this, our theoretical analysis\ndemonstrates that even without identifying the optimal group element, the\nmethod locally resembles Newton's method. We further provide an example where\nthe algorithm provably learns the correct symmetry transformation during\ntraining. To empirically evaluate L2O with teleportation, we introduce a\nbenchmark, analyze its success and failure cases, and show that enhancements\nlike momentum further improve performance. Our results highlight the potential\nof leveraging neural network parameter space symmetry to advance\nmeta-optimization.", "AI": {"tldr": "The paper explores a learning-to-optimize (L2O) algorithm that uses parameter space symmetry to improve optimization efficiency, showing theoretical and empirical benefits.", "motivation": "To enhance meta-optimizer performance by leveraging symmetry transformations in parameter space.", "method": "Jointly learning symmetry transformations and local updates, with theoretical analysis and empirical benchmarking.", "result": "The algorithm locally resembles Newton's method and can learn correct symmetry transformations, with momentum further boosting performance.", "conclusion": "Leveraging parameter space symmetry holds promise for advancing meta-optimization techniques."}}
{"id": "2504.15485", "pdf": "https://arxiv.org/pdf/2504.15485", "abs": "https://arxiv.org/abs/2504.15485", "authors": ["Atin Pothiraj", "Elias Stengel-Eskin", "Jaemin Cho", "Mohit Bansal"], "title": "CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Code and data: https://github.com/atinpothiraj/CAPTURe", "summary": "Recognizing and reasoning about occluded (partially or fully hidden) objects\nis vital to understanding visual scenes, as occlusions frequently occur in\nreal-world environments and act as obstacles for spatial comprehension. To test\nmodels' ability to reason about multiple occluded objects, we introduce a novel\ntask, Counting Amodally for Patterns Through Unseen REgions (CAPTURe), which\nrequires a model to count objects arranged in a pattern by inferring how the\npattern continues behind an occluder (an object which blocks parts of the\nscene). CAPTURe requires both recognizing visual patterns and reasoning, making\nit a useful testbed for evaluating vision-language models (VLMs) on whether\nthey understand occluded patterns and possess spatial understanding skills. By\nrequiring models to reason about occluded objects, CAPTURe also tests VLMs'\nability to form world models that would allow them to fill in missing\ninformation. CAPTURe consists of two parts: (1) CAPTURe-real, with manually\nfiltered images of real objects in patterns and (2) CAPTURe-synthetic, a\ncontrolled diagnostic with generated patterned images. We evaluate four strong\nVLMs (GPT-4o, Intern-VL2, Molmo, and Qwen2-VL) on CAPTURe, finding that models\nstruggle to count on both occluded and unoccluded patterns. Crucially, we find\nthat models perform worse with occlusion, suggesting that VLMs are also\ndeficient in inferring unseen spatial relationships: even the strongest VLMs\nlike GPT-4o fail to count with occlusion. In contrast, we find that humans\nachieve very little error on CAPTURe. We also find that providing auxiliary\ninformation of occluded object locations increases performance, underscoring\nthat the model error comes both from an inability to handle occlusion as well\nas difficulty counting in images.", "AI": {"tldr": "CAPTURe is a novel task to evaluate vision-language models (VLMs) on counting occluded objects in patterns, revealing their deficiencies in spatial reasoning and occlusion handling.", "motivation": "Occlusions are common in real-world scenes, and understanding them is crucial for spatial comprehension, yet current VLMs struggle with such tasks.", "method": "CAPTURe involves counting objects in patterns behind occluders, tested on real (CAPTURe-real) and synthetic (CAPTURe-synthetic) datasets with four VLMs.", "result": "VLMs, including GPT-4o, perform poorly on occluded patterns, highlighting their inability to infer unseen spatial relationships, while humans excel.", "conclusion": "VLMs lack robust spatial reasoning for occlusions, and auxiliary information improves performance, indicating challenges in both occlusion handling and counting tasks."}}
{"id": "2312.15676", "pdf": "https://arxiv.org/pdf/2312.15676", "abs": "https://arxiv.org/abs/2312.15676", "authors": ["Yingtai Li", "Xueming Fu", "Han Li", "Shang Zhao", "Ruiyang Jin", "S. Kevin Zhou"], "title": "3DGR-CT: Sparse-View CT Reconstruction with a 3D Gaussian Representation", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Sparse-view computed tomography (CT) reduces radiation exposure by acquiring\nfewer projections, making it a valuable tool in clinical scenarios where\nlow-dose radiation is essential. However, this often results in increased noise\nand artifacts due to limited data. In this paper we propose a novel 3D Gaussian\nrepresentation (3DGR) based method for sparse-view CT reconstruction. Inspired\nby recent success in novel view synthesis driven by 3D Gaussian splatting, we\nleverage the efficiency and expressiveness of 3D Gaussian representation as an\nalternative to implicit neural representation. To unleash the potential of 3DGR\nfor CT imaging scenario, we propose two key innovations: (i) FBP-image-guided\nGuassian initialization and (ii) efficient integration with a differentiable CT\nprojector. Extensive experiments and ablations on diverse datasets demonstrate\nthe proposed 3DGR-CT consistently outperforms state-of-the-art counterpart\nmethods, achieving higher reconstruction accuracy with faster convergence.\nFurthermore, we showcase the potential of 3DGR-CT for real-time physical\nsimulation, which holds important clinical applications while challenging for\nimplicit neural representations.", "AI": {"tldr": "A novel 3D Gaussian representation (3DGR) method is proposed for sparse-view CT reconstruction, outperforming state-of-the-art methods with higher accuracy and faster convergence.", "motivation": "Sparse-view CT reduces radiation exposure but suffers from noise and artifacts due to limited data. The paper aims to address this using 3DGR.", "method": "The method uses 3D Gaussian representation with FBP-image-guided initialization and integrates a differentiable CT projector.", "result": "3DGR-CT achieves higher reconstruction accuracy and faster convergence than existing methods, and enables real-time physical simulation.", "conclusion": "3DGR-CT is a promising solution for sparse-view CT, offering clinical benefits and outperforming implicit neural representations."}}
{"id": "2504.15640", "pdf": "https://arxiv.org/pdf/2504.15640", "abs": "https://arxiv.org/abs/2504.15640", "authors": ["Hongtao Wang", "Taiyan Zhang", "Renchi Yang", "Jianliang Xu"], "title": "Cost-Effective Text Clustering with Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Text clustering aims to automatically partition a collection of text\ndocuments into distinct clusters based on linguistic features. In the\nliterature, this task is usually framed as metric clustering based on text\nembeddings from pre-trained encoders or a graph clustering problem upon\npairwise similarities from an oracle, e.g., a large ML model. Recently, large\nlanguage models (LLMs) bring significant advancement in this field by offering\ncontextualized text embeddings and highly accurate similarity scores, but\nmeanwhile, present grand challenges to cope with substantial computational\nand/or financial overhead caused by numerous API-based queries or inference\ncalls to the models.\n  In response, this paper proposes TECL, a cost-effective framework that taps\ninto the feedback from LLMs for accurate text clustering within a limited\nbudget of queries to LLMs. Under the hood, TECL adopts our EdgeLLM or\nTriangleLLM to construct must-link/cannot-link constraints for text pairs, and\nfurther leverages such constraints as supervision signals input to our weighted\nconstrained clustering approach to generate clusters. Particularly, EdgeLLM\n(resp. TriangleLLM) enables the identification of informative text pairs (resp.\ntriplets) for querying LLMs via well-thought-out greedy algorithms and accurate\nextraction of pairwise constraints through carefully-crafted prompting\ntechniques. Our experiments on multiple benchmark datasets exhibit that TECL\nconsistently and considerably outperforms existing solutions in unsupervised\ntext clustering under the same query cost for LLMs.", "AI": {"tldr": "TECL is a cost-effective framework for text clustering using LLMs, reducing computational/financial overhead while improving accuracy.", "motivation": "Address the high computational and financial costs of using LLMs for text clustering by optimizing query usage.", "method": "Uses EdgeLLM/TriangleLLM to generate must-link/cannot-link constraints, then applies weighted constrained clustering.", "result": "Outperforms existing methods in unsupervised text clustering under the same query budget.", "conclusion": "TECL offers a practical solution for leveraging LLMs in text clustering efficiently."}}
{"id": "2504.15716", "pdf": "https://arxiv.org/pdf/2504.15716", "abs": "https://arxiv.org/abs/2504.15716", "authors": ["Jie Zhu", "Qian Chen", "Huaixia Dou", "Junhui Li", "Lifan Guo", "Feng Chen", "Chi Zhang"], "title": "DianJin-R1: Evaluating and Enhancing Financial Reasoning in Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Effective reasoning remains a core challenge for large language models (LLMs)\nin the financial domain, where tasks often require domain-specific knowledge,\nprecise numerical calculations, and strict adherence to compliance rules. We\npropose DianJin-R1, a reasoning-enhanced framework designed to address these\nchallenges through reasoning-augmented supervision and reinforcement learning.\nCentral to our approach is DianJin-R1-Data, a high-quality dataset constructed\nfrom CFLUE, FinQA, and a proprietary compliance corpus (Chinese Compliance\nCheck, CCC), combining diverse financial reasoning scenarios with verified\nannotations. Our models, DianJin-R1-7B and DianJin-R1-32B, are fine-tuned from\nQwen2.5-7B-Instruct and Qwen2.5-32B-Instruct using a structured format that\ngenerates both reasoning steps and final answers. To further refine reasoning\nquality, we apply Group Relative Policy Optimization (GRPO), a reinforcement\nlearning method that incorporates dual reward signals: one encouraging\nstructured outputs and another rewarding answer correctness. We evaluate our\nmodels on five benchmarks: three financial datasets (CFLUE, FinQA, and CCC) and\ntwo general reasoning benchmarks (MATH-500 and GPQA-Diamond). Experimental\nresults show that DianJin-R1 models consistently outperform their non-reasoning\ncounterparts, especially on complex financial tasks. Moreover, on the\nreal-world CCC dataset, our single-call reasoning models match or even surpass\nthe performance of multi-agent systems that require significantly more\ncomputational cost. These findings demonstrate the effectiveness of DianJin-R1\nin enhancing financial reasoning through structured supervision and\nreward-aligned learning, offering a scalable and practical solution for\nreal-world applications.", "AI": {"tldr": "DianJin-R1 enhances financial reasoning in LLMs using reasoning-augmented supervision and reinforcement learning, outperforming non-reasoning models on complex tasks.", "motivation": "Addressing the challenges of domain-specific knowledge, precise calculations, and compliance in financial reasoning tasks for LLMs.", "method": "Uses DianJin-R1-Data (from CFLUE, FinQA, CCC) for fine-tuning models with structured reasoning steps and answers, plus GRPO for reinforcement learning.", "result": "Outperforms non-reasoning models on financial benchmarks and matches multi-agent systems on CCC with lower computational cost.", "conclusion": "DianJin-R1 provides a scalable, effective solution for financial reasoning through structured supervision and reward-aligned learning."}}
{"id": "2504.15439", "pdf": "https://arxiv.org/pdf/2504.15439", "abs": "https://arxiv.org/abs/2504.15439", "authors": ["Hao Zhuo", "Yicheng Yang", "Kewen Peng"], "title": "Combating Toxic Language: A Review of LLM-Based Strategies for Software Engineering", "categories": ["cs.LG", "cs.SE"], "comment": null, "summary": "Large Language Models (LLMs) have become integral to software engineering\n(SE), where they are increasingly used in development workflows. However, their\nwidespread use raises concerns about the presence and propagation of toxic\nlanguage--harmful or offensive content that can foster exclusionary\nenvironments. This paper provides a comprehensive review of recent research on\ntoxicity detection and mitigation, focusing on both SE-specific and\ngeneral-purpose datasets. We examine annotation and preprocessing techniques,\nassess detection methodologies, and evaluate mitigation strategies,\nparticularly those leveraging LLMs. Additionally, we conduct an ablation study\ndemonstrating the effectiveness of LLM-based rewriting for reducing toxicity.\nBy synthesizing existing work and identifying open challenges, this review\nhighlights key areas for future research to ensure the responsible deployment\nof LLMs in SE and beyond.", "AI": {"tldr": "This paper reviews toxicity detection and mitigation in LLMs for software engineering, analyzing methods, datasets, and strategies, and identifies future research needs.", "motivation": "The widespread use of LLMs in SE raises concerns about toxic language, necessitating a review of detection and mitigation efforts.", "method": "The paper examines annotation techniques, preprocessing, detection methodologies, and mitigation strategies, including an ablation study on LLM-based rewriting.", "result": "The review synthesizes existing work, showing LLM-based rewriting's effectiveness in reducing toxicity.", "conclusion": "Future research is needed to responsibly deploy LLMs in SE, addressing open challenges in toxicity management."}}
{"id": "2504.15513", "pdf": "https://arxiv.org/pdf/2504.15513", "abs": "https://arxiv.org/abs/2504.15513", "authors": ["Yixuan Zhu", "Haolin Wang", "Ao Li", "Wenliang Zhao", "Yansong Tang", "Jingxuan Niu", "Lei Chen", "Jie Zhou", "Jiwen Lu"], "title": "InstaRevive: One-Step Image Enhancement via Dynamic Score Matching", "categories": ["cs.CV"], "comment": "Accepted by ICLR 2025", "summary": "Image enhancement finds wide-ranging applications in real-world scenarios due\nto complex environments and the inherent limitations of imaging devices. Recent\ndiffusion-based methods yield promising outcomes but necessitate prolonged and\ncomputationally intensive iterative sampling. In response, we propose\nInstaRevive, a straightforward yet powerful image enhancement framework that\nemploys score-based diffusion distillation to harness potent generative\ncapability and minimize the sampling steps. To fully exploit the potential of\nthe pre-trained diffusion model, we devise a practical and effective diffusion\ndistillation pipeline using dynamic control to address inaccuracies in updating\ndirection during score matching. Our control strategy enables a dynamic\ndiffusing scope, facilitating precise learning of denoising trajectories within\nthe diffusion model and ensuring accurate distribution matching gradients\nduring training. Additionally, to enrich guidance for the generative power, we\nincorporate textual prompts via image captioning as auxiliary conditions,\nfostering further exploration of the diffusion model. Extensive experiments\nsubstantiate the efficacy of our framework across a diverse array of\nchallenging tasks and datasets, unveiling the compelling efficacy and\nefficiency of InstaRevive in delivering high-quality and visually appealing\nresults. Code is available at https://github.com/EternalEvan/InstaRevive.", "AI": {"tldr": "InstaRevive is a diffusion-based image enhancement framework that reduces sampling steps via score-based diffusion distillation and dynamic control, achieving high-quality results efficiently.", "motivation": "Addressing the computational intensity and prolonged sampling of recent diffusion-based methods while leveraging their generative power for image enhancement.", "method": "Uses score-based diffusion distillation with dynamic control for accurate denoising trajectory learning and incorporates textual prompts via image captioning for enriched guidance.", "result": "Demonstrates efficacy and efficiency across diverse tasks and datasets, delivering high-quality, visually appealing results.", "conclusion": "InstaRevive effectively balances generative capability and computational efficiency, making it a practical solution for image enhancement."}}
{"id": "2412.04802", "pdf": "https://arxiv.org/pdf/2412.04802", "abs": "https://arxiv.org/abs/2412.04802", "authors": ["Songcheng Du", "Yang Zou", "Zixu Wang", "Xingyuan Li", "Ying Li", "Changjing Shang", "Qiang Shen"], "title": "Unsupervised Hyperspectral and Multispectral Image Fusion via Self-Supervised Modality Decoupling", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Hyperspectral and Multispectral Image Fusion (HMIF) aims to fuse\nlow-resolution hyperspectral images (LR-HSIs) and high-resolution multispectral\nimages (HR-MSIs) to reconstruct high spatial and high spectral resolution\nimages. Current methods typically apply direct fusion from the two modalities\nwithout effective supervision, leading to an incomplete perception of deep\nmodality-complementary information and a limited understanding of\ninter-modality correlations. To address these issues, we propose a simple yet\neffective solution for unsupervised HMIF, revealing that modality decoupling is\nkey to improving fusion performance. Specifically, we propose an end-to-end\nself-supervised \\textbf{Mo}dality-Decoupled \\textbf{S}patial-\\textbf{S}pectral\nFusion (\\textbf{MossFuse}) framework that decouples shared and complementary\ninformation across modalities and aggregates a concise representation of both\nLR-HSIs and HR-MSIs to reduce modality redundancy. Also, we introduce the\nsubspace clustering loss as a clear guide to decouple modality-shared features\nfrom modality-complementary ones. Systematic experiments over multiple datasets\ndemonstrate that our simple and effective approach consistently outperforms the\nexisting HMIF methods while requiring considerably fewer parameters with\nreduced inference time. The anonymous source code is in\n\\href{https://github.com/dusongcheng/MossFuse}{MossFuse}.", "AI": {"tldr": "The paper proposes MossFuse, an unsupervised HMIF method that decouples and aggregates modality-shared and complementary information to improve fusion performance.", "motivation": "Current HMIF methods lack effective supervision, leading to incomplete modality-complementary perception and limited inter-modality correlation understanding.", "method": "MossFuse decouples shared and complementary information across modalities and uses subspace clustering loss for clear feature separation.", "result": "MossFuse outperforms existing methods with fewer parameters and reduced inference time.", "conclusion": "Modality decoupling is key to HMIF, and MossFue provides a simple, effective solution."}}
{"id": "2504.15642", "pdf": "https://arxiv.org/pdf/2504.15642", "abs": "https://arxiv.org/abs/2504.15642", "authors": ["Gerhard J\u00e4ger"], "title": "Computational Typology", "categories": ["cs.CL", "q-bio.PE"], "comment": "19 pages, s5 figure", "summary": "Typology is a subfield of linguistics that focuses on the study and\nclassification of languages based on their structural features. Unlike\ngenealogical classification, which examines the historical relationships\nbetween languages, typology seeks to understand the diversity of human\nlanguages by identifying common properties and patterns, known as universals.\nIn recent years, computational methods have played an increasingly important\nrole in typological research, enabling the analysis of large-scale linguistic\ndata and the testing of hypotheses about language structure and evolution. This\narticle provides an illustration of the benefits of computational statistical\nmodeling in typology.", "AI": {"tldr": "Computational methods enhance typological linguistics by analyzing large-scale data and testing structural hypotheses.", "motivation": "To demonstrate the advantages of computational statistical modeling in understanding language diversity and universals.", "method": "Utilizes computational statistical modeling for large-scale linguistic data analysis.", "result": "Improved ability to identify language universals and test structural hypotheses.", "conclusion": "Computational approaches significantly advance typological research by enabling robust data analysis."}}
{"id": "2504.15719", "pdf": "https://arxiv.org/pdf/2504.15719", "abs": "https://arxiv.org/abs/2504.15719", "authors": ["Anna Karnysheva", "Christian Drescher", "Dietrich Klakow"], "title": "Implementing Rational Choice Functions with LLMs and Measuring their Alignment with User Preferences", "categories": ["cs.AI"], "comment": null, "summary": "As large language models (LLMs) become integral to intelligent user\ninterfaces (IUIs), their role as decision-making agents raises critical\nconcerns about alignment. Although extensive research has addressed issues such\nas factuality, bias, and toxicity, comparatively little attention has been paid\nto measuring alignment to preferences, i.e., the relative desirability of\ndifferent alternatives, a concept used in decision making, economics, and\nsocial choice theory. However, a reliable decision-making agent makes choices\nthat align well with user preferences.\n  In this paper, we generalize existing methods that exploit LLMs for ranking\nalternative outcomes by addressing alignment with the broader and more flexible\nconcept of user preferences, which includes both strict preferences and\nindifference among alternatives. To this end, we put forward design principles\nfor using LLMs to implement rational choice functions, and provide the\nnecessary tools to measure preference satisfaction. We demonstrate the\napplicability of our approach through an empirical study in a practical\napplication of an IUI in the automotive domain.", "AI": {"tldr": "The paper addresses the lack of focus on measuring alignment of LLMs to user preferences in decision-making, proposing methods to generalize ranking outcomes and measure preference satisfaction.", "motivation": "Existing research on LLMs overlooks alignment to user preferences, a key factor for reliable decision-making agents in IUIs.", "method": "Generalizes existing LLM ranking methods to include user preferences, introduces design principles for rational choice functions, and tools for measuring preference satisfaction.", "result": "Demonstrated applicability in an automotive IUI, showing improved alignment with user preferences.", "conclusion": "The approach enhances LLM decision-making by better aligning with user preferences, with practical implications for IUIs."}}
{"id": "2504.15458", "pdf": "https://arxiv.org/pdf/2504.15458", "abs": "https://arxiv.org/abs/2504.15458", "authors": ["Brandon Le", "Dustin Keller"], "title": "Compton Form Factor Extraction using Quantum Deep Neural Networks", "categories": ["cs.LG", "nucl-th", "quant-ph"], "comment": null, "summary": "Extraction tests of Compton Form Factors are performed using pseudodata based\non experimental data from Deeply Virtual Compton Scattering experiments\nconducted at Jefferson Lab. The standard Belitsky, Kirchner, and Muller\nformalism at twist-two is employed, along with a fitting procedure designed to\nreduce model dependency similar to traditional local fits. The extraction of\nthe Compton Form Factors is performed using both Classical Deep Neural Networks\n(CDNNs) and Quantum Deep Neural Networks (QDNNs). Comparative studies reveal\nthat QDNNs outperform CDNNs for this application, demonstrating improved\npredictive accuracy and precision even for limited model complexity. The\nresults demonstrate the potential of QDNNs for future studies in which quantum\nalgorithms can be fully optimized.", "AI": {"tldr": "Extraction of Compton Form Factors using CDNNs and QDNNs shows QDNNs outperform CDNNs in accuracy and precision.", "motivation": "To improve the extraction of Compton Form Factors from experimental data using advanced neural network techniques.", "method": "Employed twist-two formalism and fitting procedures with CDNNs and QDNNs for extraction.", "result": "QDNNs showed better predictive accuracy and precision than CDNNs.", "conclusion": "QDNNs hold promise for future quantum-optimized studies in this field."}}
{"id": "2504.15599", "pdf": "https://arxiv.org/pdf/2504.15599", "abs": "https://arxiv.org/abs/2504.15599", "authors": ["Shichen Li", "Chenhui Shao"], "title": "Multi-Modal Fusion of In-Situ Video Data and Process Parameters for Online Forecasting of Cookie Drying Readiness", "categories": ["cs.CV", "cs.LG"], "comment": "17 pages, 12 figures", "summary": "Food drying is essential for food production, extending shelf life, and\nreducing transportation costs. Accurate real-time forecasting of drying\nreadiness is crucial for minimizing energy consumption, improving productivity,\nand ensuring product quality. However, this remains challenging due to the\ndynamic nature of drying, limited data availability, and the lack of effective\npredictive analytical methods. To address this gap, we propose an end-to-end\nmulti-modal data fusion framework that integrates in-situ video data with\nprocess parameters for real-time food drying readiness forecasting. Our\napproach leverages a new encoder-decoder architecture with modality-specific\nencoders and a transformer-based decoder to effectively extract features while\npreserving the unique structure of each modality. We apply our approach to\nsugar cookie drying, where time-to-ready is predicted at each timestamp.\nExperimental results demonstrate that our model achieves an average prediction\nerror of only 15 seconds, outperforming state-of-the-art data fusion methods by\n65.69% and a video-only model by 11.30%. Additionally, our model balances\nprediction accuracy, model size, and computational efficiency, making it\nwell-suited for heterogenous industrial datasets. The proposed model is\nextensible to various other industrial modality fusion tasks for online\ndecision-making.", "AI": {"tldr": "Proposes a multi-modal data fusion framework for real-time food drying readiness forecasting, achieving high accuracy and efficiency.", "motivation": "Accurate real-time forecasting of drying readiness is challenging due to dynamic drying processes, limited data, and ineffective predictive methods.", "method": "An end-to-end multi-modal data fusion framework integrating in-situ video data with process parameters, using a novel encoder-decoder architecture with modality-specific encoders and a transformer-based decoder.", "result": "The model achieves an average prediction error of 15 seconds, outperforming state-of-the-art methods by 65.69% and a video-only model by 11.30%.", "conclusion": "The model is accurate, efficient, and extensible to other industrial modality fusion tasks for online decision-making."}}
{"id": "2403.19001", "pdf": "https://arxiv.org/pdf/2403.19001", "abs": "https://arxiv.org/abs/2403.19001", "authors": ["Yui Lo", "Yuqian Chen", "Dongnan Liu", "Wan Liu", "Leo Zekelman", "Fan Zhang", "Yogesh Rathi", "Nikos Makris", "Alexandra J. Golby", "Weidong Cai", "Lauren J. O'Donnell"], "title": "Cross-domain Fiber Cluster Shape Analysis for Language Performance Cognitive Score Prediction", "categories": ["cs.CV", "cs.AI", "eess.IV", "q-bio.NC"], "comment": "This paper has been accepted for presentation at The 27th Intl. Conf.\n  on Medical Image Computing and Computer Assisted Intervention (MICCAI 2024)\n  Workshop on Computational Diffusion MRI (CDMRI). 11 pages, 2 figures", "summary": "Shape plays an important role in computer graphics, offering informative\nfeatures to convey an object's morphology and functionality. Shape analysis in\nbrain imaging can help interpret structural and functionality correlations of\nthe human brain. In this work, we investigate the shape of the brain's 3D white\nmatter connections and its potential predictive relationship to human cognitive\nfunction. We reconstruct brain connections as sequences of 3D points using\ndiffusion magnetic resonance imaging (dMRI) tractography. To describe each\nconnection, we extract 12 shape descriptors in addition to traditional dMRI\nconnectivity and tissue microstructure features. We introduce a novel\nframework, Shape--fused Fiber Cluster Transformer (SFFormer), that leverages a\nmulti-head cross-attention feature fusion module to predict subject-specific\nlanguage performance based on dMRI tractography. We assess the performance of\nthe method on a large dataset including 1065 healthy young adults. The results\ndemonstrate that both the transformer-based SFFormer model and its inter/intra\nfeature fusion with shape, microstructure, and connectivity are informative,\nand together, they improve the prediction of subject-specific language\nperformance scores. Overall, our results indicate that the shape of the brain's\nconnections is predictive of human language function.", "AI": {"tldr": "The paper explores the predictive relationship between the shape of the brain's 3D white matter connections and human cognitive function, introducing a novel framework (SFFormer) for improved prediction.", "motivation": "Shape analysis in brain imaging can reveal structural and functional correlations, particularly for understanding human cognitive function.", "method": "The study reconstructs brain connections using dMRI tractography, extracts 12 shape descriptors, and introduces SFFormer, a transformer-based model with multi-head cross-attention feature fusion.", "result": "SFFormer, combined with shape, microstructure, and connectivity features, improves prediction of language performance scores in 1065 healthy young adults.", "conclusion": "The shape of brain connections is predictive of human language function, highlighting its importance in cognitive analysis."}}
{"id": "2504.15683", "pdf": "https://arxiv.org/pdf/2504.15683", "abs": "https://arxiv.org/abs/2504.15683", "authors": ["Simon Jehnen", "Joaqu\u00edn Ordieres-Mer\u00e9", "Javier Villalba-D\u00edez"], "title": "FinTextSim: Enhancing Financial Text Analysis with BERTopic", "categories": ["cs.CL", "cs.LG", "econ.GN", "q-fin.EC", "q-fin.GN", "68T50", "I.2.7; I.5.1; J.4"], "comment": null, "summary": "Recent advancements in information availability and computational\ncapabilities have transformed the analysis of annual reports, integrating\ntraditional financial metrics with insights from textual data. To extract\nvaluable insights from this wealth of textual data, automated review processes,\nsuch as topic modeling, are crucial. This study examines the effectiveness of\nBERTopic, a state-of-the-art topic model relying on contextual embeddings, for\nanalyzing Item 7 and Item 7A of 10-K filings from S&P 500 companies\n(2016-2022). Moreover, we introduce FinTextSim, a finetuned\nsentence-transformer model optimized for clustering and semantic search in\nfinancial contexts. Compared to all-MiniLM-L6-v2, the most widely used\nsentence-transformer, FinTextSim increases intratopic similarity by 81% and\nreduces intertopic similarity by 100%, significantly enhancing organizational\nclarity. We assess BERTopic's performance using embeddings from both FinTextSim\nand all-MiniLM-L6-v2. Our findings reveal that BERTopic only forms clear and\ndistinct economic topic clusters when paired with FinTextSim's embeddings.\nWithout FinTextSim, BERTopic struggles with misclassification and overlapping\ntopics. Thus, FinTextSim is pivotal for advancing financial text analysis.\nFinTextSim's enhanced contextual embeddings, tailored for the financial domain,\nelevate the quality of future research and financial information. This improved\nquality of financial information will enable stakeholders to gain a competitive\nadvantage, streamlining resource allocation and decision-making processes.\nMoreover, the improved insights have the potential to leverage business\nvaluation and stock price prediction models.", "AI": {"tldr": "The study evaluates BERTopic's effectiveness for analyzing 10-K filings and introduces FinTextSim, a finetuned sentence-transformer model, which outperforms all-MiniLM-L6-v2 in financial text analysis.", "motivation": "To enhance financial text analysis by integrating contextual embeddings and improving topic modeling for better insights from annual reports.", "method": "Uses BERTopic with FinTextSim and all-MiniLM-L6-v2 embeddings to analyze 10-K filings (2016-2022), comparing performance.", "result": "FinTextSim improves intratopic similarity by 81% and reduces intertopic similarity by 100%, enabling clear economic topic clusters with BERTopic.", "conclusion": "FinTextSim is essential for advancing financial text analysis, improving research quality, and aiding decision-making and business valuation."}}
{"id": "2504.15780", "pdf": "https://arxiv.org/pdf/2504.15780", "abs": "https://arxiv.org/abs/2504.15780", "authors": ["Daocheng Fu", "Zijun Chen", "Renqiu Xia", "Qi Liu", "Yuan Feng", "Hongbin Zhou", "Renrui Zhang", "Shiyang Feng", "Peng Gao", "Junchi Yan", "Botian Shi", "Bo Zhang", "Yu Qiao"], "title": "TrustGeoGen: Scalable and Formal-Verified Data Engine for Trustworthy Multi-modal Geometric Problem Solving", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Mathematical geometric problem solving (GPS) often requires effective\nintegration of multimodal information and verifiable logical coherence. Despite\nthe fast development of large language models in general problem solving, it\nremains unresolved regarding with both methodology and benchmarks, especially\ngiven the fact that exiting synthetic GPS benchmarks are often not\nself-verified and contain noise and self-contradicted information due to the\nillusion of LLMs. In this paper, we propose a scalable data engine called\nTrustGeoGen for problem generation, with formal verification to provide a\nprincipled benchmark, which we believe lays the foundation for the further\ndevelopment of methods for GPS. The engine synthesizes geometric data through\nfour key innovations: 1) multimodal-aligned generation of diagrams, textual\ndescriptions, and stepwise solutions; 2) formal verification ensuring\nrule-compliant reasoning paths; 3) a bootstrapping mechanism enabling\ncomplexity escalation via recursive state generation and 4) our devised\nGeoExplore series algorithms simultaneously produce multi-solution variants and\nself-reflective backtracking traces. By formal logical verification,\nTrustGeoGen produces GeoTrust-200K dataset with guaranteed modality integrity,\nalong with GeoTrust-test testset. Experiments reveal the state-of-the-art\nmodels achieve only 49.17\\% accuracy on GeoTrust-test, demonstrating its\nevaluation stringency. Crucially, models trained on GeoTrust achieve OOD\ngeneralization on GeoQA, significantly reducing logical inconsistencies\nrelative to pseudo-label annotated by OpenAI-o1. Our code is available at\nhttps://github.com/Alpha-Innovator/TrustGeoGen", "AI": {"tldr": "The paper introduces TrustGeoGen, a scalable data engine for generating verified geometric problems, addressing noise and inconsistencies in existing benchmarks.", "motivation": "Existing synthetic GPS benchmarks lack self-verification and contain noise due to LLM illusions, hindering reliable method development.", "method": "TrustGeoGen synthesizes geometric data via multimodal-aligned generation, formal verification, bootstrapping, and GeoExplore algorithms.", "result": "The engine produces the GeoTrust-200K dataset, with models achieving 49.17% accuracy on GeoTrust-test, showing improved OOD generalization.", "conclusion": "TrustGeoGen provides a principled benchmark for GPS, reducing logical inconsistencies and advancing method development."}}
{"id": "2504.15477", "pdf": "https://arxiv.org/pdf/2504.15477", "abs": "https://arxiv.org/abs/2504.15477", "authors": ["Junda Wu", "Rohan Surana", "Zhouhang Xie", "Yiran Shen", "Yu Xia", "Tong Yu", "Ryan A. Rossi", "Prithviraj Ammanabrolu", "Julian McAuley"], "title": "In-context Ranking Preference Optimization", "categories": ["cs.LG"], "comment": "10 pages", "summary": "Recent developments in Direct Preference Optimization (DPO) allow large\nlanguage models (LLMs) to function as implicit ranking models by maximizing the\nmargin between preferred and non-preferred responses. In practice, user\nfeedback on such lists typically involves identifying a few relevant items in\ncontext rather than providing detailed pairwise comparisons for every possible\nitem pair. Moreover, many complex information retrieval tasks, such as\nconversational agents and summarization systems, critically depend on ranking\nthe highest-quality outputs at the top, emphasizing the need to support natural\nand flexible forms of user feedback. To address the challenge of limited and\nsparse pairwise feedback in the in-context setting, we propose an In-context\nRanking Preference Optimization (IRPO) framework that directly optimizes LLMs\nbased on ranking lists constructed during inference. To further capture\nflexible forms of feedback, IRPO extends the DPO objective by incorporating\nboth the relevance of items and their positions in the list. Modeling these\naspects jointly is non-trivial, as ranking metrics are inherently discrete and\nnon-differentiable, making direct optimization difficult. To overcome this,\nIRPO introduces a differentiable objective based on positional aggregation of\npairwise item preferences, enabling effective gradient-based optimization of\ndiscrete ranking metrics. We further provide theoretical insights showing that\nIRPO (i) automatically emphasizes items with greater disagreement between the\nmodel and the reference ranking, and (ii) links its gradient to an importance\nsampling estimator, yielding an unbiased estimator with reduced variance.\nEmpirical results show IRPO outperforms standard DPO approaches in ranking\nperformance, highlighting its effectiveness in aligning LLMs with direct\nin-context ranking preferences.", "AI": {"tldr": "IRPO extends DPO by optimizing LLMs for in-context ranking preferences, incorporating item relevance and position, and outperforms DPO in ranking tasks.", "motivation": "Addressing the challenge of limited and sparse pairwise feedback in in-context settings, and the need for flexible user feedback in complex tasks like conversational agents and summarization.", "method": "Proposes IRPO, a framework that optimizes LLMs using ranking lists during inference, with a differentiable objective based on positional aggregation of pairwise preferences.", "result": "IRPO outperforms standard DPO in ranking performance and aligns LLMs better with in-context ranking preferences.", "conclusion": "IRPO effectively addresses the limitations of DPO by incorporating flexible feedback and optimizing discrete ranking metrics, demonstrating superior performance."}}
{"id": "2504.15609", "pdf": "https://arxiv.org/pdf/2504.15609", "abs": "https://arxiv.org/abs/2504.15609", "authors": ["Yunfeng Li", "Bo Wang", "Jiahao Wan", "Xueyi Wu", "Ye Li"], "title": "SonarT165: A Large-scale Benchmark and STFTrack Framework for Acoustic Object Tracking", "categories": ["cs.CV"], "comment": null, "summary": "Underwater observation systems typically integrate optical cameras and\nimaging sonar systems. When underwater visibility is insufficient, only sonar\nsystems can provide stable data, which necessitates exploration of the\nunderwater acoustic object tracking (UAOT) task. Previous studies have explored\ntraditional methods and Siamese networks for UAOT. However, the absence of a\nunified evaluation benchmark has significantly constrained the value of these\nmethods. To alleviate this limitation, we propose the first large-scale UAOT\nbenchmark, SonarT165, comprising 165 square sequences, 165 fan sequences, and\n205K high-quality annotations. Experimental results demonstrate that SonarT165\nreveals limitations in current state-of-the-art SOT trackers. To address these\nlimitations, we propose STFTrack, an efficient framework for acoustic object\ntracking. It includes two novel modules, a multi-view template fusion module\n(MTFM) and an optimal trajectory correction module (OTCM). The MTFM module\nintegrates multi-view feature of both the original image and the binary image\nof the dynamic template, and introduces a cross-attention-like layer to fuse\nthe spatio-temporal target representations. The OTCM module introduces the\nacoustic-response-equivalent pixel property and proposes normalized pixel\nbrightness response scores, thereby suppressing suboptimal matches caused by\ninaccurate Kalman filter prediction boxes. To further improve the model\nfeature, STFTrack introduces a acoustic image enhancement method and a\nFrequency Enhancement Module (FEM) into its tracking pipeline. Comprehensive\nexperiments show the proposed STFTrack achieves state-of-the-art performance on\nthe proposed benchmark. The code is available at\nhttps://github.com/LiYunfengLYF/SonarT165.", "AI": {"tldr": "The paper introduces SonarT165, the first large-scale benchmark for underwater acoustic object tracking (UAOT), and proposes STFTrack, an efficient framework with novel modules to address limitations in current trackers.", "motivation": "Underwater visibility issues limit optical cameras, making sonar systems essential for stable data. The lack of a unified UAOT benchmark has hindered progress in this field.", "method": "The authors propose STFTrack, featuring a multi-view template fusion module (MTFM) and an optimal trajectory correction module (OTCM), along with acoustic image enhancement and a Frequency Enhancement Module (FEM).", "result": "STFTrack achieves state-of-the-art performance on the SonarT165 benchmark, demonstrating its effectiveness.", "conclusion": "The SonarT165 benchmark and STFTrack framework advance UAOT by providing a unified evaluation standard and improved tracking performance."}}
{"id": "2504.07758", "pdf": "https://arxiv.org/pdf/2504.07758", "abs": "https://arxiv.org/abs/2504.07758", "authors": ["Shuangfan Zhou", "Chu Zhou", "Youwei Lyu", "Heng Guo", "Zhanyu Ma", "Boxin Shi", "Imari Sato"], "title": "PIDSR: Complementary Polarized Image Demosaicing and Super-Resolution", "categories": ["cs.CV", "eess.IV"], "comment": "CVPR 2025", "summary": "Polarization cameras can capture multiple polarized images with different\npolarizer angles in a single shot, bringing convenience to polarization-based\ndownstream tasks. However, their direct outputs are color-polarization filter\narray (CPFA) raw images, requiring demosaicing to reconstruct full-resolution,\nfull-color polarized images; unfortunately, this necessary step introduces\nartifacts that make polarization-related parameters such as the degree of\npolarization (DoP) and angle of polarization (AoP) prone to error. Besides,\nlimited by the hardware design, the resolution of a polarization camera is\noften much lower than that of a conventional RGB camera. Existing polarized\nimage demosaicing (PID) methods are limited in that they cannot enhance\nresolution, while polarized image super-resolution (PISR) methods, though\ndesigned to obtain high-resolution (HR) polarized images from the demosaicing\nresults, tend to retain or even amplify errors in the DoP and AoP introduced by\ndemosaicing artifacts. In this paper, we propose PIDSR, a joint framework that\nperforms complementary Polarized Image Demosaicing and Super-Resolution,\nshowing the ability to robustly obtain high-quality HR polarized images with\nmore accurate DoP and AoP from a CPFA raw image in a direct manner. Experiments\nshow our PIDSR not only achieves state-of-the-art performance on both synthetic\nand real data, but also facilitates downstream tasks.", "AI": {"tldr": "PIDSR is a joint framework for Polarized Image Demosaicing and Super-Resolution, improving accuracy in polarization parameters and resolution.", "motivation": "Current methods for polarized image processing introduce artifacts and errors in polarization parameters, and lack resolution enhancement.", "method": "Proposes PIDSR, a joint framework combining demosaicing and super-resolution to directly process CPFA raw images.", "result": "Achieves state-of-the-art performance on synthetic and real data, enhancing downstream tasks.", "conclusion": "PIDSR robustly produces high-quality, high-resolution polarized images with accurate polarization parameters."}}
{"id": "2504.15688", "pdf": "https://arxiv.org/pdf/2504.15688", "abs": "https://arxiv.org/abs/2504.15688", "authors": ["Mandy Cartner", "Matthew Kogan", "Nikolas Webster", "Matthew Wagers", "Ivy Sichel"], "title": "Subject islands do not reduce to construction-specific discourse function", "categories": ["cs.CL"], "comment": null, "summary": "The term islands in linguistics refers to phrases from which extracting an\nelement results in ungrammaticality (Ross, 1967). Grammatical subjects are\nconsidered islands because extracting a sub-part of a subject results in an\nill-formed sentence, despite having a clear intended meaning (e.g., \"Which\ntopic did the article about inspire you?\"). The generative tradition, which\nviews syntax as autonomous of meaning and function, attributes this\nungrammaticality to the abstract movement dependency between the wh-phrase and\nthe subject-internal position with which it is associated for interpretation.\nHowever, research on language that emphasizes its communicative function\nsuggests instead that syntactic constraints, including islands, can be\nexplained based on the way different constructions package information.\nAccordingly, Abeill\\'e et al. (2020) suggest that the islandhood of subjects is\nspecific to the information structure of wh-questions, and propose that\nsubjects are not islands for movement, but for focusing, due to their\ndiscourse-backgroundedness. This predicts that other constructions that differ\nin their information structure from wh-questions, but still involve movement,\nshould not create a subject island effect. We test this prediction in three\nlarge-scale acceptability studies, using a super-additive design that singles\nout subject island violations, in three different constructions: wh-questions,\nrelative clauses, and topicalization. We report evidence for a subject island\neffect in each construction type, despite only wh-questions introducing what\nAbeill\\'e et al. (2020) call \"a clash in information structure.\" We argue that\nthis motivates an account of islands in terms of abstract, syntactic\nrepresentations, independent of the communicative function associated with the\nconstructions.", "AI": {"tldr": "The paper examines subject islands in linguistics, challenging the idea that their ungrammaticality is due to information structure, and supports a syntactic account.", "motivation": "To test whether subject islands are specific to wh-questions' information structure or a general syntactic constraint.", "method": "Three large-scale acceptability studies using a super-additive design across wh-questions, relative clauses, and topicalization.", "result": "Subject island effects were found in all constructions, contradicting the information-structure-based explanation.", "conclusion": "The findings support a syntactic account of islands, independent of communicative function."}}
{"id": "2504.15785", "pdf": "https://arxiv.org/pdf/2504.15785", "abs": "https://arxiv.org/abs/2504.15785", "authors": ["Siyu Zhou", "Tianyi Zhou", "Yijun Yang", "Guodong Long", "Deheng Ye", "Jing Jiang", "Chengqi Zhang"], "title": "WALL-E 2.0: World Alignment by NeuroSymbolic Learning improves World Model-based LLM Agents", "categories": ["cs.AI"], "comment": "Code is available at https://github.com/elated-sawyer/WALL-E", "summary": "Can we build accurate world models out of large language models (LLMs)? How\ncan world models benefit LLM agents? The gap between the prior knowledge of\nLLMs and the specified environment's dynamics usually bottlenecks LLMs'\nperformance as world models. To bridge the gap, we propose a training-free\n\"world alignment\" that learns an environment's symbolic knowledge complementary\nto LLMs. The symbolic knowledge covers action rules, knowledge graphs, and\nscene graphs, which are extracted by LLMs from exploration trajectories and\nencoded into executable codes to regulate LLM agents' policies. We further\npropose an RL-free, model-based agent \"WALL-E 2.0\" through the model-predictive\ncontrol (MPC) framework. Unlike classical MPC requiring costly optimization on\nthe fly, we adopt an LLM agent as an efficient look-ahead optimizer of future\nsteps' actions by interacting with the neurosymbolic world model. While the LLM\nagent's strong heuristics make it an efficient planner in MPC, the quality of\nits planned actions is also secured by the accurate predictions of the aligned\nworld model. They together considerably improve learning efficiency in a new\nenvironment. On open-world challenges in Mars (Minecraft like) and ALFWorld\n(embodied indoor environments), WALL-E 2.0 significantly outperforms existing\nmethods, e.g., surpassing baselines in Mars by 16.1%-51.6% of success rate and\nby at least 61.7% in score. In ALFWorld, it achieves a new record 98% success\nrate after only 4 iterations.", "AI": {"tldr": "The paper proposes 'world alignment' to enhance LLM-based world models by extracting symbolic knowledge from environments, and introduces WALL-E 2.0, an efficient LLM agent for model-predictive control, achieving superior performance in open-world challenges.", "motivation": "To bridge the gap between LLMs' prior knowledge and specific environment dynamics, improving LLMs' performance as world models.", "method": "Training-free 'world alignment' extracts symbolic knowledge (action rules, knowledge graphs, scene graphs) from exploration trajectories, encoded into executable codes. WALL-E 2.0 uses LLM as an efficient look-ahead optimizer in MPC.", "result": "WALL-E 2.0 outperforms baselines in Mars (16.1%-51.6% higher success rate) and ALFWorld (98% success rate after 4 iterations).", "conclusion": "The proposed neurosymbolic world model and LLM agent significantly improve learning efficiency and performance in new environments."}}
{"id": "2504.15479", "pdf": "https://arxiv.org/pdf/2504.15479", "abs": "https://arxiv.org/abs/2504.15479", "authors": ["Jeremy Goldwasser", "Giles Hooker"], "title": "Unifying Image Counterfactuals and Feature Attributions with Latent-Space Adversarial Attacks", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Counterfactuals are a popular framework for interpreting machine learning\npredictions. These what if explanations are notoriously challenging to create\nfor computer vision models: standard gradient-based methods are prone to\nproduce adversarial examples, in which imperceptible modifications to image\npixels provoke large changes in predictions. We introduce a new,\neasy-to-implement framework for counterfactual images that can flexibly adapt\nto contemporary advances in generative modeling. Our method, Counterfactual\nAttacks, resembles an adversarial attack on the representation of the image\nalong a low-dimensional manifold. In addition, given an auxiliary dataset of\nimage descriptors, we show how to accompany counterfactuals with feature\nattribution that quantify the changes between the original and counterfactual\nimages. These importance scores can be aggregated into global counterfactual\nexplanations that highlight the overall features driving model predictions.\nWhile this unification is possible for any counterfactual method, it has\nparticular computational efficiency for ours. We demonstrate the efficacy of\nour approach with the MNIST and CelebA datasets.", "AI": {"tldr": "A new framework for generating counterfactual images in computer vision, avoiding adversarial issues and integrating feature attribution for interpretability.", "motivation": "Standard gradient-based methods for counterfactuals in vision models often produce adversarial examples, limiting their interpretability.", "method": "Introduces Counterfactual Attacks, a method leveraging low-dimensional manifolds and auxiliary datasets for feature attribution.", "result": "Demonstrates efficacy on MNIST and CelebA datasets, providing computationally efficient global counterfactual explanations.", "conclusion": "The framework adapts to generative modeling advances, offering interpretable and efficient counterfactual explanations for vision models."}}
{"id": "2504.15612", "pdf": "https://arxiv.org/pdf/2504.15612", "abs": "https://arxiv.org/abs/2504.15612", "authors": ["Hongxing Peng", "Kang Lin", "Huanai Liu"], "title": "HS-Mamba: Full-Field Interaction Multi-Groups Mamba for Hyperspectral Image Classification", "categories": ["cs.CV"], "comment": null, "summary": "Hyperspectral image (HSI) classification has been one of the hot topics in\nremote sensing fields. Recently, the Mamba architecture based on selective\nstate-space models (S6) has demonstrated great advantages in long sequence\nmodeling. However, the unique properties of hyperspectral data, such as high\ndimensionality and feature inlining, pose challenges to the application of\nMamba to HSI classification. To compensate for these shortcomings, we propose\nan full-field interaction multi-groups Mamba framework (HS-Mamba), which adopts\na strategy different from pixel-patch based or whole-image based, but combines\nthe advantages of both. The patches cut from the whole image are sent to\nmulti-groups Mamba, combined with positional information to perceive local\ninline features in the spatial and spectral domains, and the whole image is\nsent to a lightweight attention module to enhance the global feature\nrepresentation ability. Specifically, HS-Mamba consists of a dual-channel\nspatial-spectral encoder (DCSS-encoder) module and a lightweight global inline\nattention (LGI-Att) branch. The DCSS-encoder module uses multiple groups of\nMamba to decouple and model the local features of dual-channel sequences with\nnon-overlapping patches. The LGI-Att branch uses a lightweight compressed and\nextended attention module to perceive the global features of the spatial and\nspectral domains of the unsegmented whole image. By fusing local and global\nfeatures, high-precision classification of hyperspectral images is achieved.\nExtensive experiments demonstrate the superiority of the proposed HS-Mamba,\noutperforming state-of-the-art methods on four benchmark HSI datasets.", "AI": {"tldr": "Proposed HS-Mamba framework combines local and global features for high-precision HSI classification, outperforming state-of-the-art methods.", "motivation": "Hyperspectral data's high dimensionality and feature inlining challenge Mamba's application, requiring a novel approach.", "method": "HS-Mamba uses a dual-channel spatial-spectral encoder (DCSS-encoder) and lightweight global inline attention (LGI-Att) branch to fuse local and global features.", "result": "Outperforms state-of-the-art methods on four benchmark HSI datasets.", "conclusion": "HS-Mamba effectively addresses HSI classification challenges by integrating local and global feature modeling."}}
{"id": "2504.15777", "pdf": "https://arxiv.org/pdf/2504.15777", "abs": "https://arxiv.org/abs/2504.15777", "authors": ["Shangshang Wang", "Julian Asilis", "\u00d6mer Faruk Akg\u00fcl", "Enes Burak Bilgin", "Ollie Liu", "Willie Neiswanger"], "title": "Tina: Tiny Reasoning Models via LoRA", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "How cost-effectively can strong reasoning abilities be achieved in language\nmodels? Driven by this fundamental question, we present Tina, a family of tiny\nreasoning models achieved with high cost-efficiency. Notably, Tina demonstrates\nthat substantial reasoning performance can be developed using only minimal\nresources, by applying parameter-efficient updates during reinforcement\nlearning (RL), using low-rank adaptation (LoRA), to an already tiny 1.5B\nparameter base model. This minimalist approach produces models that achieve\nreasoning performance which is competitive with, and sometimes surpasses, SOTA\nRL reasoning models built upon the same base model. Crucially, this is achieved\nat a tiny fraction of the computational post-training cost employed by existing\nSOTA models. In fact, the best Tina model achieves a >20\\% reasoning\nperformance increase and 43.33\\% Pass@1 accuracy on AIME24, at only \\$9 USD\npost-training and evaluation cost (i.e., an estimated 260x cost reduction). Our\nwork reveals the surprising effectiveness of efficient RL reasoning via LoRA.\nWe validate this across multiple open-source reasoning datasets and various\nablation settings starting with a single, fixed set of hyperparameters.\nFurthermore, we hypothesize that this effectiveness and efficiency stem from\nLoRA rapidly adapting the model to the structural format of reasoning rewarded\nby RL, while largely preserving the base model's underlying knowledge. In\nservice of accessibility and open research, we fully open-source all code,\ntraining logs, and model weights \\& checkpoints.", "AI": {"tldr": "Tina, a tiny reasoning model, achieves strong performance with minimal resources using LoRA for efficient RL updates, outperforming SOTA models at a fraction of the cost.", "motivation": "To explore cost-effective ways to develop strong reasoning abilities in language models.", "method": "Uses parameter-efficient updates (LoRA) during RL on a 1.5B parameter base model.", "result": "Achieves competitive/superior reasoning performance with a 260x cost reduction (e.g., >20% performance increase, 43.33% Pass@1 accuracy on AIME24).", "conclusion": "LoRA-based RL is surprisingly effective for reasoning, preserving base knowledge while adapting to reasoning structures. All resources are open-sourced."}}
{"id": "2504.15791", "pdf": "https://arxiv.org/pdf/2504.15791", "abs": "https://arxiv.org/abs/2504.15791", "authors": ["Raquel Fernandez-Peralta", "Javier Fumanal-Idocin", "Javier Andreu-Perez"], "title": "Crisp complexity of fuzzy classifiers", "categories": ["cs.AI"], "comment": null, "summary": "Rule-based systems are a very popular form of explainable AI, particularly in\nthe fuzzy community, where fuzzy rules are widely used for control and\nclassification problems. However, fuzzy rule-based classifiers struggle to\nreach bigger traction outside of fuzzy venues, because users sometimes do not\nknow about fuzzy and because fuzzy partitions are not so easy to interpret in\nsome situations. In this work, we propose a methodology to reduce fuzzy\nrule-based classifiers to crisp rule-based classifiers. We study different\npossible crisp descriptions and implement an algorithm to obtain them. Also, we\nanalyze the complexity of the resulting crisp classifiers. We believe that our\nresults can help both fuzzy and non-fuzzy practitioners understand better the\nway in which fuzzy rule bases partition the feature space and how easily one\nsystem can be translated to another and vice versa. Our complexity metric can\nalso help to choose between different fuzzy classifiers based on what the\nequivalent crisp partitions look like.", "AI": {"tldr": "A method to convert fuzzy rule-based classifiers to crisp rule-based ones, aiding interpretability and cross-community adoption.", "motivation": "Fuzzy rule-based classifiers lack wider adoption due to interpretability issues and unfamiliarity with fuzzy logic.", "method": "Proposes a methodology to reduce fuzzy rules to crisp rules, studies crisp descriptions, and implements an algorithm for conversion.", "result": "Analyzes complexity of crisp classifiers, aiding understanding of feature space partitioning and system translation.", "conclusion": "The work bridges fuzzy and non-fuzzy communities, offering a complexity metric to guide classifier choice."}}
{"id": "2504.15487", "pdf": "https://arxiv.org/pdf/2504.15487", "abs": "https://arxiv.org/abs/2504.15487", "authors": ["Moein Darman", "Pedram Hassanzadeh", "Laure Zanna", "Ashesh Chattopadhyay"], "title": "Fourier analysis of the physics of transfer learning for data-driven subgrid-scale models of ocean turbulence", "categories": ["cs.LG", "nlin.CD", "physics.ao-ph", "physics.geo-ph"], "comment": null, "summary": "Transfer learning (TL) is a powerful tool for enhancing the performance of\nneural networks (NNs) in applications such as weather and climate prediction\nand turbulence modeling. TL enables models to generalize to out-of-distribution\ndata with minimal training data from the new system. In this study, we employ a\n9-layer convolutional NN to predict the subgrid forcing in a two-layer ocean\nquasi-geostrophic system and examine which metrics best describe its\nperformance and generalizability to unseen dynamical regimes. Fourier analysis\nof the NN kernels reveals that they learn low-pass, Gabor, and high-pass\nfilters, regardless of whether the training data are isotropic or anisotropic.\nBy analyzing the activation spectra, we identify why NNs fail to generalize\nwithout TL and how TL can overcome these limitations: the learned weights and\nbiases from one dataset underestimate the out-of-distribution sample spectra as\nthey pass through the network, leading to an underestimation of output spectra.\nBy re-training only one layer with data from the target system, this\nunderestimation is corrected, enabling the NN to produce predictions that match\nthe target spectra. These findings are broadly applicable to data-driven\nparameterization of dynamical systems.", "AI": {"tldr": "A study uses transfer learning (TL) with a 9-layer CNN to predict subgrid forcing in ocean dynamics, identifying metrics for performance and generalizability. Fourier analysis shows learned filters, and TL corrects spectral underestimation by retraining one layer.", "motivation": "To enhance neural network performance in weather and climate prediction by leveraging TL for generalizability to unseen dynamical regimes.", "method": "Employ a 9-layer CNN to predict subgrid forcing in a two-layer ocean quasi-geostrophic system, analyzing kernels and activation spectra.", "result": "NNs learn low-pass, Gabor, and high-pass filters. Without TL, they underestimate output spectra; TL corrects this by retraining one layer.", "conclusion": "TL effectively improves NN generalizability in dynamical systems, with findings applicable to data-driven parameterization."}}
{"id": "2504.15619", "pdf": "https://arxiv.org/pdf/2504.15619", "abs": "https://arxiv.org/abs/2504.15619", "authors": ["Jinda Lu", "Jinghan Li", "Yuan Gao", "Junkang Wu", "Jiancan Wu", "Xiang Wang", "Xiangnan He"], "title": "AdaViP: Aligning Multi-modal LLMs via Adaptive Vision-enhanced Preference Optimization", "categories": ["cs.CV"], "comment": null, "summary": "Preference alignment through Direct Preference Optimization (DPO) has\ndemonstrated significant effectiveness in aligning multimodal large language\nmodels (MLLMs) with human preferences. However, existing methods focus\nprimarily on language preferences while neglecting the critical visual context.\nIn this paper, we propose an Adaptive Vision-enhanced Preference optimization\n(AdaViP) that addresses these limitations through two key innovations: (1)\nvision-based preference pair construction, which integrates multiple visual\nfoundation models to strategically remove key visual elements from the image,\nenhancing MLLMs' sensitivity to visual details; and (2) adaptive preference\noptimization that dynamically balances vision- and language-based preferences\nfor more accurate alignment. Extensive evaluations across different benchmarks\ndemonstrate our effectiveness. Notably, our AdaViP-7B achieves 93.7% and 96.4%\nreductions in response-level and mentioned-level hallucination respectively on\nthe Object HalBench, significantly outperforming current state-of-the-art\nmethods.", "AI": {"tldr": "AdaViP enhances MLLM alignment with human preferences by integrating visual context through vision-based preference pair construction and adaptive optimization, outperforming existing methods.", "motivation": "Existing methods focus on language preferences, neglecting visual context, limiting MLLM alignment with human preferences.", "method": "AdaViP introduces vision-based preference pair construction and adaptive preference optimization to balance vision- and language-based preferences.", "result": "AdaViP-7B reduces response- and mentioned-level hallucination by 93.7% and 96.4% respectively on Object HalBench, surpassing state-of-the-art methods.", "conclusion": "AdaViP effectively aligns MLLMs with human preferences by incorporating visual context, demonstrating superior performance over existing approaches."}}
{"id": "2504.15784", "pdf": "https://arxiv.org/pdf/2504.15784", "abs": "https://arxiv.org/abs/2504.15784", "authors": ["Ruizhe Li", "Chiwei Zhu", "Benfeng Xu", "Xiaorui Wang", "Zhendong Mao"], "title": "Automated Creativity Evaluation for Large Language Models: A Reference-Based Approach", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Creative writing is a key capability of Large Language Models (LLMs), with\npotential applications in literature, storytelling, and various creative\ndomains. However, evaluating the creativity of machine-generated texts remains\na significant challenge, as existing methods either rely on costly manual\nannotations or fail to align closely with human assessments. In this paper, we\npropose an effective automated evaluation method based on the Torrance Test of\nCreative Writing (TTCW), which evaluates creativity as product. Our method\nemploys a reference-based Likert-style approach, scoring generated creative\ntexts relative to high-quality reference texts across various tests.\nExperimental results demonstrate that our method significantly improves the\nalignment between LLM evaluations and human assessments, achieving a pairwise\naccuracy of 0.75 (+15\\%).", "AI": {"tldr": "Proposes an automated evaluation method for LLM-generated creative texts using the Torrance Test of Creative Writing (TTCW), improving alignment with human assessments.", "motivation": "Evaluating creativity in machine-generated texts is challenging; current methods are costly or misaligned with human judgment.", "method": "Reference-based Likert-style scoring using TTCW, comparing texts to high-quality references.", "result": "Achieves 0.75 pairwise accuracy (+15%) in aligning LLM evaluations with human assessments.", "conclusion": "The method effectively automates creativity evaluation, enhancing reliability and reducing reliance on manual annotations."}}
{"id": "2504.15829", "pdf": "https://arxiv.org/pdf/2504.15829", "abs": "https://arxiv.org/abs/2504.15829", "authors": ["Modhurita Mitra", "Martine G. de Vos", "Nicola Cortinovis", "Dawa Ometto"], "title": "Generative AI for Research Data Processing: Lessons Learnt From Three Use Cases", "categories": ["cs.AI", "68T50", "I.2.7"], "comment": "10 pages, 4 figures, 6 tables. Published in Proceedings of the 2024\n  IEEE 20th International Conference on e-Science (e-Science), Osaka, Japan", "summary": "There has been enormous interest in generative AI since ChatGPT was launched\nin 2022. However, there are concerns about the accuracy and consistency of the\noutputs of generative AI. We have carried out an exploratory study on the\napplication of this new technology in research data processing. We identified\ntasks for which rule-based or traditional machine learning approaches were\ndifficult to apply, and then performed these tasks using generative AI.\n  We demonstrate the feasibility of using the generative AI model Claude 3 Opus\nin three research projects involving complex data processing tasks:\n  1) Information extraction: We extract plant species names from historical\nseedlists (catalogues of seeds) published by botanical gardens.\n  2) Natural language understanding: We extract certain data points (name of\ndrug, name of health indication, relative effectiveness, cost-effectiveness,\netc.) from documents published by Health Technology Assessment organisations in\nthe EU.\n  3) Text classification: We assign industry codes to projects on the\ncrowdfunding website Kickstarter.\n  We share the lessons we learnt from these use cases: How to determine if\ngenerative AI is an appropriate tool for a given data processing task, and if\nso, how to maximise the accuracy and consistency of the results obtained.", "AI": {"tldr": "Exploratory study on generative AI (Claude 3 Opus) for research data processing, focusing on feasibility in complex tasks like information extraction, natural language understanding, and text classification.", "motivation": "Address concerns about generative AI's accuracy and consistency by exploring its application in research data processing, particularly for tasks challenging for rule-based or traditional ML approaches.", "method": "Applied Claude 3 Opus to three tasks: extracting plant species names from seedlists, extracting health data from EU documents, and classifying Kickstarter projects by industry codes.", "result": "Demonstrated feasibility of generative AI for complex data tasks, with insights on task suitability and optimizing accuracy/consistency.", "conclusion": "Generative AI is viable for certain research data tasks, but careful evaluation and optimization are needed for reliable results."}}
{"id": "2504.15491", "pdf": "https://arxiv.org/pdf/2504.15491", "abs": "https://arxiv.org/abs/2504.15491", "authors": ["Tengda Tang", "Jianhua Yao", "Yixian Wang", "Qiuwu Sha", "Hanrui Feng", "Zhen Xu"], "title": "Application of Deep Generative Models for Anomaly Detection in Complex Financial Transactions", "categories": ["cs.LG"], "comment": null, "summary": "This study proposes an algorithm for detecting suspicious behaviors in large\npayment flows based on deep generative models. By combining Generative\nAdversarial Networks (GAN) and Variational Autoencoders (VAE), the algorithm is\ndesigned to detect abnormal behaviors in financial transactions. First, the GAN\nis used to generate simulated data that approximates normal payment flows. The\ndiscriminator identifies anomalous patterns in transactions, enabling the\ndetection of potential fraud and money laundering behaviors. Second, a VAE is\nintroduced to model the latent distribution of payment flows, ensuring that the\ngenerated data more closely resembles real transaction features, thus improving\nthe model's detection accuracy. The method optimizes the generative\ncapabilities of both GAN and VAE, ensuring that the model can effectively\ncapture suspicious behaviors even in sparse data conditions. Experimental\nresults show that the proposed method significantly outperforms traditional\nmachine learning algorithms and other deep learning models across various\nevaluation metrics, especially in detecting rare fraudulent behaviors.\nFurthermore, this study provides a detailed comparison of performance in\nrecognizing different transaction patterns (such as normal, money laundering,\nand fraud) in large payment flows, validating the advantages of generative\nmodels in handling complex financial data.", "AI": {"tldr": "The paper proposes a deep generative model combining GAN and VAE to detect suspicious behaviors in financial transactions, outperforming traditional methods.", "motivation": "To improve detection of fraud and money laundering in large payment flows by leveraging generative models for better accuracy and handling sparse data.", "method": "Combines GAN for simulating normal payment flows and VAE for latent distribution modeling to detect anomalies.", "result": "The method outperforms traditional machine learning and deep learning models, especially in detecting rare fraudulent behaviors.", "conclusion": "Generative models like GAN and VAE are effective for detecting complex suspicious behaviors in financial data."}}
{"id": "2504.15624", "pdf": "https://arxiv.org/pdf/2504.15624", "abs": "https://arxiv.org/abs/2504.15624", "authors": ["Jingzhi Li", "Changjiang Luo", "Ruoyu Chen", "Hua Zhang", "Wenqi Ren", "Jianhou Gan", "Xiaochun Cao"], "title": "FaceInsight: A Multimodal Large Language Model for Face Perception", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in multimodal large language models (MLLMs) have demonstrated\nstrong capabilities in understanding general visual content. However, these\ngeneral-domain MLLMs perform poorly in face perception tasks, often producing\ninaccurate or misleading responses to face-specific queries. To address this\ngap, we propose FaceInsight, the versatile face perception MLLM that provides\nfine-grained facial information. Our approach introduces visual-textual\nalignment of facial knowledge to model both uncertain dependencies and\ndeterministic relationships among facial information, mitigating the\nlimitations of language-driven reasoning. Additionally, we incorporate face\nsegmentation maps as an auxiliary perceptual modality, enriching the visual\ninput with localized structural cues to enhance semantic understanding.\nComprehensive experiments and analyses across three face perception tasks\ndemonstrate that FaceInsight consistently outperforms nine compared MLLMs under\nboth training-free and fine-tuned settings.", "AI": {"tldr": "FaceInsight, a multimodal large language model (MLLM), addresses poor face perception in general-domain MLLMs by aligning visual-textual facial knowledge and using face segmentation maps, outperforming nine MLLMs in tasks.", "motivation": "General-domain MLLMs perform poorly in face perception tasks, producing inaccurate responses to face-specific queries.", "method": "Introduces visual-textual alignment of facial knowledge and incorporates face segmentation maps as an auxiliary modality.", "result": "FaceInsight consistently outperforms nine compared MLLMs in three face perception tasks under training-free and fine-tuned settings.", "conclusion": "FaceInsight effectively bridges the gap in face perception for MLLMs, enhancing accuracy and understanding."}}
{"id": "2504.15801", "pdf": "https://arxiv.org/pdf/2504.15801", "abs": "https://arxiv.org/abs/2504.15801", "authors": ["Valeria Lerman", "Yaniv Dover"], "title": "A closer look at how large language models trust humans: patterns and biases", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "As large language models (LLMs) and LLM-based agents increasingly interact\nwith humans in decision-making contexts, understanding the trust dynamics\nbetween humans and AI agents becomes a central concern. While considerable\nliterature studies how humans trust AI agents, it is much less understood how\nLLM-based agents develop effective trust in humans. LLM-based agents likely\nrely on some sort of implicit effective trust in trust-related contexts (e.g.,\nevaluating individual loan applications) to assist and affect decision making.\nUsing established behavioral theories, we develop an approach that studies\nwhether LLMs trust depends on the three major trustworthiness dimensions:\ncompetence, benevolence and integrity of the human subject. We also study how\ndemographic variables affect effective trust. Across 43,200 simulated\nexperiments, for five popular language models, across five different scenarios\nwe find that LLM trust development shows an overall similarity to human trust\ndevelopment. We find that in most, but not all cases, LLM trust is strongly\npredicted by trustworthiness, and in some cases also biased by age, religion\nand gender, especially in financial scenarios. This is particularly true for\nscenarios common in the literature and for newer models. While the overall\npatterns align with human-like mechanisms of effective trust formation,\ndifferent models exhibit variation in how they estimate trust; in some cases,\ntrustworthiness and demographic factors are weak predictors of effective trust.\nThese findings call for a better understanding of AI-to-human trust dynamics\nand monitoring of biases and trust development patterns to prevent unintended\nand potentially harmful outcomes in trust-sensitive applications of AI.", "AI": {"tldr": "The paper explores how LLM-based agents develop trust in humans, finding similarities to human trust dynamics but with biases influenced by demographic factors.", "motivation": "Understanding trust dynamics between humans and AI agents, especially how LLMs trust humans, is crucial for decision-making applications.", "method": "The study uses behavioral theories to analyze LLM trust based on competence, benevolence, and integrity, alongside demographic variables, across 43,200 simulated experiments with five models.", "result": "LLM trust development resembles human trust, with trustworthiness as a strong predictor, though biased by age, religion, and gender in some scenarios.", "conclusion": "The findings highlight the need to monitor AI-to-human trust dynamics and biases to avoid harmful outcomes in trust-sensitive AI applications."}}
{"id": "2504.15847", "pdf": "https://arxiv.org/pdf/2504.15847", "abs": "https://arxiv.org/abs/2504.15847", "authors": ["Xiang Liu", "Hau Chan", "Minming Li", "Xianlong Zeng", "Chenchen Fu", "Weiwei Wu"], "title": "CARE: Compatibility-Aware Incentive Mechanisms for Federated Learning with Budgeted Requesters", "categories": ["cs.AI"], "comment": null, "summary": "Federated learning (FL) is a promising approach that allows requesters (\\eg,\nservers) to obtain local training models from workers (e.g., clients). Since\nworkers are typically unwilling to provide training services/models freely and\nvoluntarily, many incentive mechanisms in FL are designed to incentivize\nparticipation by offering monetary rewards from requesters. However, existing\nstudies neglect two crucial aspects of real-world FL scenarios. First, workers\ncan possess inherent incompatibility characteristics (e.g., communication\nchannels and data sources), which can lead to degradation of FL efficiency\n(e.g., low communication efficiency and poor model generalization). Second, the\nrequesters are budgeted, which limits the amount of workers they can hire for\ntheir tasks. In this paper, we investigate the scenario in FL where multiple\nbudgeted requesters seek training services from incompatible workers with\nprivate training costs. We consider two settings: the cooperative budget\nsetting where requesters cooperate to pool their budgets to improve their\noverall utility and the non-cooperative budget setting where each requester\noptimizes their utility within their own budgets. To address efficiency\ndegradation caused by worker incompatibility, we develop novel\ncompatibility-aware incentive mechanisms, CARE-CO and CARE-NO, for both\nsettings to elicit true private costs and determine workers to hire for\nrequesters and their rewards while satisfying requester budget constraints. Our\nmechanisms guarantee individual rationality, truthfulness, budget feasibility,\nand approximation performance. We conduct extensive experiments using\nreal-world datasets to show that the proposed mechanisms significantly\noutperform existing baselines.", "AI": {"tldr": "The paper introduces compatibility-aware incentive mechanisms (CARE-CO and CARE-NO) for federated learning to address worker incompatibility and budget constraints, outperforming existing baselines.", "motivation": "Existing FL incentive mechanisms ignore worker incompatibility and requester budget limits, degrading efficiency and utility.", "method": "Developed CARE-CO (cooperative) and CARE-NO (non-cooperative) mechanisms to elicit true costs and optimize worker hiring under budget constraints.", "result": "Mechanisms guarantee individual rationality, truthfulness, budget feasibility, and show superior performance in experiments.", "conclusion": "The proposed mechanisms effectively address real-world FL challenges, improving efficiency and utility."}}
{"id": "2504.15525", "pdf": "https://arxiv.org/pdf/2504.15525", "abs": "https://arxiv.org/abs/2504.15525", "authors": ["Chengjun Yu", "Yixin Ran", "Yangyi Xia", "Jia Wu", "Xiaojing Liu"], "title": "Federated Latent Factor Learning for Recovering Wireless Sensor Networks Signal with Privacy-Preserving", "categories": ["cs.LG"], "comment": "Accepted By ICAIS&ISAS 2025", "summary": "Wireless Sensor Networks (WSNs) are a cutting-edge domain in the field of\nintelligent sensing. Due to sensor failures and energy-saving strategies, the\ncollected data often have massive missing data, hindering subsequent analysis\nand decision-making. Although Latent Factor Learning (LFL) has been proven\neffective in recovering missing data, it fails to sufficiently consider data\nprivacy protection. To address this issue, this paper innovatively proposes a\nfederated latent factor learning (FLFL) based spatial signal recovery (SSR)\nmodel, named FLFL-SSR. Its main idea is two-fold: 1) it designs a sensor-level\nfederated learning framework, where each sensor uploads only gradient updates\ninstead of raw data to optimize the global model, and 2) it proposes a local\nspatial sharing strategy, allowing sensors within the same spatial region to\nshare their latent feature vectors, capturing spatial correlations and\nenhancing recovery accuracy. Experimental results on two real-world WSNs\ndatasets demonstrate that the proposed model outperforms existing federated\nmethods in terms of recovery performance.", "AI": {"tldr": "Proposes FLFL-SSR, a federated latent factor learning model for spatial signal recovery in WSNs, ensuring privacy and improving accuracy.", "motivation": "Addresses missing data in WSNs due to sensor failures and energy-saving, while ensuring data privacy, which existing LFL methods overlook.", "method": "Introduces a sensor-level federated learning framework (gradient updates only) and a local spatial sharing strategy for latent feature vectors.", "result": "Outperforms existing federated methods in recovery performance on real-world WSN datasets.", "conclusion": "FLFL-SSR effectively balances privacy and accuracy in missing data recovery for WSNs."}}
{"id": "2504.15627", "pdf": "https://arxiv.org/pdf/2504.15627", "abs": "https://arxiv.org/abs/2504.15627", "authors": ["Doanh C. Bui", "Hoai Luan Pham", "Vu Trung Duong Le", "Tuan Hai Vu", "Van Duy Tran", "Yasuhiko Nakashima"], "title": "ZeroSlide: Is Zero-Shot Classification Adequate for Lifelong Learning in Whole-Slide Image Analysis in the Era of Pathology Vision-Language Foundation Models?", "categories": ["cs.CV"], "comment": "10 pages, 3 figures, 1 table, conference submission", "summary": "Lifelong learning for whole slide images (WSIs) poses the challenge of\ntraining a unified model to perform multiple WSI-related tasks, such as cancer\nsubtyping and tumor classification, in a distributed, continual fashion. This\nis a practical and applicable problem in clinics and hospitals, as WSIs are\nlarge, require storage, processing, and transfer time. Training new models\nwhenever new tasks are defined is time-consuming. Recent work has applied\nregularization- and rehearsal-based methods to this setting. However, the rise\nof vision-language foundation models that align diagnostic text with pathology\nimages raises the question: are these models alone sufficient for lifelong WSI\nlearning using zero-shot classification, or is further investigation into\ncontinual learning strategies needed to improve performance? To our knowledge,\nthis is the first study to compare conventional continual-learning approaches\nwith vision-language zero-shot classification for WSIs. Our source code and\nexperimental results will be available soon.", "AI": {"tldr": "The paper compares continual-learning methods with vision-language zero-shot classification for lifelong learning in whole slide images (WSIs).", "motivation": "To address the practical challenge of training unified models for multiple WSI tasks without retraining for new tasks, leveraging vision-language models.", "method": "Comparison of conventional continual-learning approaches (regularization- and rehearsal-based) with vision-language zero-shot classification.", "result": "Experimental results and source code will be released, but specific findings are not detailed here.", "conclusion": "Further investigation is needed to determine if vision-language models alone suffice for lifelong WSI learning or if continual-learning strategies are required."}}
{"id": "2504.15815", "pdf": "https://arxiv.org/pdf/2504.15815", "abs": "https://arxiv.org/abs/2504.15815", "authors": ["Michael A. Hedderich", "Anyi Wang", "Raoyuan Zhao", "Florian Eichin", "Barbara Plank"], "title": "What's the Difference? Supporting Users in Identifying the Effects of Prompt and Model Changes Through Token Patterns", "categories": ["cs.CL", "cs.HC", "cs.LG"], "comment": null, "summary": "Prompt engineering for large language models is challenging, as even small\nprompt perturbations or model changes can significantly impact the generated\noutput texts. Existing evaluation methods, either automated metrics or human\nevaluation, have limitations, such as providing limited insights or being\nlabor-intensive. We propose Spotlight, a new approach that combines both\nautomation and human analysis. Based on data mining techniques, we\nautomatically distinguish between random (decoding) variations and systematic\ndifferences in language model outputs. This process provides token patterns\nthat describe the systematic differences and guide the user in manually\nanalyzing the effects of their prompt and model changes efficiently. We create\nthree benchmarks to quantitatively test the reliability of token pattern\nextraction methods and demonstrate that our approach provides new insights into\nestablished prompt data. From a human-centric perspective, through\ndemonstration studies and a user study, we show that our token pattern approach\nhelps users understand the systematic differences of language model outputs,\nand we are able to discover relevant differences caused by prompt and model\nchanges (e.g. related to gender or culture), thus supporting the prompt\nengineering process and human-centric model behavior research.", "AI": {"tldr": "Spotlight combines automation and human analysis to efficiently evaluate prompt and model changes in large language models by identifying systematic differences in outputs.", "motivation": "Existing evaluation methods for prompt engineering are either limited in insights or labor-intensive, necessitating a more efficient and insightful approach.", "method": "Spotlight uses data mining to distinguish random variations from systematic differences in model outputs, providing token patterns to guide manual analysis.", "result": "The approach reliably extracts token patterns, offers new insights into prompt data, and helps users understand systematic differences, including those related to gender or culture.", "conclusion": "Spotlight supports prompt engineering and human-centric model behavior research by efficiently revealing systematic differences in language model outputs."}}
{"id": "2504.15903", "pdf": "https://arxiv.org/pdf/2504.15903", "abs": "https://arxiv.org/abs/2504.15903", "authors": ["Nikhil Khandalkar", "Pavan Yadav", "Krishna Shinde", "Lokesh B. Ramegowda", "Rajarshi Das"], "title": "Impact of Noise on LLM-Models Performance in Abstraction and Reasoning Corpus (ARC) Tasks with Model Temperature Considerations", "categories": ["cs.AI"], "comment": "60 pages, 25 figures", "summary": "Recent advancements in Large Language Models (LLMs) have generated growing\ninterest in their structured reasoning capabilities, particularly in tasks\ninvolving abstraction and pattern recognition. The Abstraction and Reasoning\nCorpus (ARC) benchmark plays a crucial role in evaluating these capabilities by\ntesting how well AI models generalize to novel problems. While GPT-4o\ndemonstrates strong performance by solving all ARC tasks under zero-noise\nconditions, other models like DeepSeek R1 and LLaMA 3.2 fail to solve any,\nsuggesting limitations in their ability to reason beyond simple pattern\nmatching. To explore this gap, we systematically evaluate these models across\ndifferent noise levels and temperature settings. Our results reveal that the\nintroduction of noise consistently impairs model performance, regardless of\narchitecture. This decline highlights a shared vulnerability: current LLMs,\ndespite showing signs of abstract reasoning, remain highly sensitive to input\nperturbations. Such fragility raises concerns about their real-world\napplicability, where noise and uncertainty are common. By comparing how\ndifferent model architectures respond to these challenges, we offer insights\ninto the structural weaknesses of modern LLMs in reasoning tasks. This work\nunderscores the need for developing more robust and adaptable AI systems\ncapable of handling the ambiguity and variability inherent in real-world\nscenarios. Our findings aim to guide future research toward enhancing model\ngeneralization, robustness, and alignment with human-like cognitive\nflexibility.", "AI": {"tldr": "GPT-4o excels in ARC tasks under zero-noise, but other models fail. Noise universally impairs performance, revealing LLMs' fragility in reasoning.", "motivation": "To evaluate LLMs' structured reasoning and generalization in noisy conditions using the ARC benchmark.", "method": "Systematic evaluation of models (GPT-4o, DeepSeek R1, LLaMA 3.2) across noise levels and temperature settings.", "result": "Noise consistently degrades performance, exposing LLMs' sensitivity to input perturbations.", "conclusion": "Current LLMs lack robustness in noisy environments, urging development of more adaptable AI systems for real-world applications."}}
{"id": "2504.15539", "pdf": "https://arxiv.org/pdf/2504.15539", "abs": "https://arxiv.org/abs/2504.15539", "authors": ["Ryan J. Miller", "Alexander E. Dashuta", "Brayden Rudisill", "David Van Vranken", "Pierre Baldi"], "title": "Interpretable Deep Learning for Polar Mechanistic Reaction Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Accurately predicting chemical reactions is essential for driving innovation\nin synthetic chemistry, with broad applications in medicine, manufacturing, and\nagriculture. At the same time, reaction prediction is a complex problem which\ncan be both time-consuming and resource-intensive for chemists to solve. Deep\nlearning methods offer an appealing solution by enabling high-throughput\nreaction prediction. However, many existing models are trained on the US Patent\nOffice dataset and treat reactions as overall transformations: mapping\nreactants directly to products with limited interpretability or mechanistic\ninsight. To address this, we introduce PMechRP (Polar Mechanistic Reaction\nPredictor), a system that trains machine learning models on the PMechDB\ndataset, which represents reactions as polar elementary steps that capture\nelectron flow and mechanistic detail. To further expand model coverage and\nimprove generalization, we augment PMechDB with a diverse set of\ncombinatorially generated reactions. We train and compare a range of machine\nlearning models, including transformer-based, graph-based, and two-step siamese\narchitectures. Our best-performing approach was a hybrid model, which combines\na 5-ensemble of Chemformer models with a two-step Siamese framework to leverage\nthe accuracy of transformer architectures, while filtering away \"alchemical\"\nproducts using the two-step network predictions. For evaluation, we use a test\nsplit of the PMechDB dataset and additionally curate a human benchmark dataset\nconsisting of complete mechanistic pathways extracted from an organic chemistry\ntextbook. Our hybrid model achieves a top-10 accuracy of 94.9% on the PMechDB\ntest set and a target recovery rate of 84.9% on the pathway dataset.", "AI": {"tldr": "PMechRP, a hybrid ML model, predicts chemical reactions with mechanistic detail, achieving high accuracy on test datasets.", "motivation": "Accurate reaction prediction is crucial for synthetic chemistry but is complex and resource-intensive. Existing models lack interpretability and mechanistic insight.", "method": "PMechRP trains on the PMechDB dataset, representing reactions as polar elementary steps. It uses a hybrid model combining transformer and Siamese architectures.", "result": "The hybrid model achieves 94.9% top-10 accuracy on PMechDB and 84.9% target recovery on a human benchmark dataset.", "conclusion": "PMechRP offers a scalable, interpretable solution for reaction prediction, outperforming existing methods."}}
{"id": "2504.15650", "pdf": "https://arxiv.org/pdf/2504.15650", "abs": "https://arxiv.org/abs/2504.15650", "authors": ["Dengyang Jiang", "Mengmeng Wang", "Teli Ma", "Hengzhuang Li", "Yong liu", "Guang Dai", "Lei Zhang"], "title": "AffordanceSAM: Segment Anything Once More in Affordance Grounding", "categories": ["cs.CV"], "comment": "SAM Meets Affordance Grounding", "summary": "Improving the generalization ability of an affordance grounding model to\nrecognize regions for unseen objects and affordance functions is crucial for\nreal-world application. However, current models are still far away from such\nstandards. To address this problem, we introduce AffordanceSAM, an effective\napproach that extends SAM's generalization capacity to the domain of affordance\ngrounding. For the purpose of thoroughly transferring SAM's robust performance\nin segmentation to affordance, we initially propose an affordance-adaption\nmodule in order to help modify SAM's segmentation output to be adapted to the\nspecific functional regions required for affordance grounding. We concurrently\nmake a coarse-to-fine training recipe to make SAM first be aware of affordance\nobjects and actions coarsely, and then be able to generate affordance heatmaps\nfinely. Both quantitative and qualitative experiments show the strong\ngeneralization capacity of our AffordanceSAM, which not only surpasses previous\nmethods under AGD20K benchmark but also shows evidence to handle the task with\nnovel objects and affordance functions.", "AI": {"tldr": "AffordanceSAM extends SAM's segmentation capabilities to affordance grounding, improving generalization for unseen objects and functions.", "motivation": "Current models lack generalization for affordance grounding in real-world applications.", "method": "Proposes an affordance-adaption module and coarse-to-fine training to adapt SAM's segmentation for affordance tasks.", "result": "Outperforms previous methods on AGD20K and handles novel objects/functions.", "conclusion": "AffordanceSAM demonstrates strong generalization for affordance grounding."}}
{"id": "2504.15843", "pdf": "https://arxiv.org/pdf/2504.15843", "abs": "https://arxiv.org/abs/2504.15843", "authors": ["Junshu Pan", "Wei Shen", "Shulin Huang", "Qiji Zhou", "Yue Zhang"], "title": "Pre-DPO: Improving Data Utilization in Direct Preference Optimization Using a Guiding Reference Model", "categories": ["cs.CL"], "comment": null, "summary": "Direct Preference Optimization (DPO) simplifies reinforcement learning from\nhuman feedback (RLHF) for large language models (LLMs) by directly optimizing\nhuman preferences without an explicit reward model. We find that during DPO\ntraining, the reference model plays the role of a data weight adjuster.\nHowever, the common practice of initializing the policy and reference models\nidentically in DPO can lead to inefficient data utilization and impose a\nperformance ceiling. Meanwhile, the lack of a reference model in Simple\nPreference Optimization (SimPO) reduces training robustness and necessitates\nstricter conditions to prevent catastrophic forgetting. In this work, we\npropose Pre-DPO, a simple yet effective DPO-based training paradigm that\nenhances preference optimization performance by leveraging a guiding reference\nmodel. This reference model provides foresight into the optimal policy state\nachievable through the training preference data, serving as a guiding mechanism\nthat adaptively assigns higher weights to samples more suitable for the model\nand lower weights to those less suitable. Extensive experiments on AlpacaEval\n2.0 and Arena-Hard v0.1 benchmarks demonstrate that Pre-DPO consistently\nimproves the performance of both DPO and SimPO, without relying on external\nmodels or additional data.", "AI": {"tldr": "Pre-DPO improves DPO and SimPO by using a guiding reference model to optimize human preferences more efficiently.", "motivation": "Address inefficiencies in DPO and robustness issues in SimPO by introducing a reference model for better data utilization and training stability.", "method": "Proposes Pre-DPO, which leverages a guiding reference model to adaptively weight training samples based on their suitability.", "result": "Pre-DPO enhances performance on AlpacaEval 2.0 and Arena-Hard v0.1 benchmarks without extra models or data.", "conclusion": "Pre-DPO is a simple, effective method to improve preference optimization in LLMs."}}
{"id": "2504.16042", "pdf": "https://arxiv.org/pdf/2504.16042", "abs": "https://arxiv.org/abs/2504.16042", "authors": ["Isma\u00efl Baaj"], "title": "Approximate matrices of systems of max-min fuzzy relational equations", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "In this article, we address the inconsistency of a system of max-min fuzzy\nrelational equations by minimally modifying the matrix governing the system in\norder to achieve consistency. Our method yields consistent systems that\napproximate the original inconsistent system in the following sense: the\nright-hand side vector of each consistent system is that of the inconsistent\nsystem, and the coefficients of the matrix governing each consistent system are\nobtained by modifying, exactly and minimally, the entries of the original\nmatrix that must be corrected to achieve consistency, while leaving all other\nentries unchanged.\n  To obtain a consistent system that closely approximates the considered\ninconsistent system, we study the distance (in terms of a norm among $L_1$,\n$L_2$ or $L_\\infty$) between the matrix of the inconsistent system and the set\nformed by the matrices of consistent systems that use the same right-hand side\nvector as the inconsistent system. We show that our method allows us to\ndirectly compute matrices of consistent systems that use the same right-hand\nside vector as the inconsistent system whose distance in terms of $L_\\infty$\nnorm to the matrix of the inconsistent system is minimal (the computational\ncosts are higher when using $L_1$ norm or $L_2$ norm). We also give an explicit\nanalytical formula for computing this minimal $L_\\infty$ distance. Finally, we\ntranslate our results for systems of min-max fuzzy relational equations and\npresent some potential applications.", "AI": {"tldr": "The paper proposes a method to resolve inconsistencies in max-min fuzzy relational equations by minimally adjusting the system's matrix while preserving the right-hand side vector. It focuses on minimizing the distance (using L1, L2, or L\u221e norms) between the original and consistent matrices, with explicit formulas for L\u221e norm.", "motivation": "To address the challenge of inconsistency in fuzzy relational equations, the study aims to provide a method that minimally modifies the system's matrix to achieve consistency without altering the right-hand side vector.", "method": "The method involves adjusting the matrix entries minimally to achieve consistency, focusing on minimizing the distance (L1, L2, or L\u221e norms) between the original and consistent matrices. It provides explicit formulas for L\u221e norm minimization.", "result": "The method successfully computes consistent systems with minimal distance to the original inconsistent system, particularly efficient for L\u221e norm. It also extends results to min-max fuzzy relational equations.", "conclusion": "The approach effectively resolves inconsistencies in fuzzy relational equations with minimal modifications, offering practical applications and computational efficiency, especially for L\u221e norm."}}
{"id": "2504.15562", "pdf": "https://arxiv.org/pdf/2504.15562", "abs": "https://arxiv.org/abs/2504.15562", "authors": ["Dip Roy"], "title": "Bayesian Autoencoder for Medical Anomaly Detection: Uncertainty-Aware Approach for Brain 2 MRI Analysis", "categories": ["cs.LG", "cs.CV"], "comment": "16 pages, 6 figures", "summary": "In medical imaging, anomaly detection is a vital element of healthcare\ndiagnostics, especially for neurological conditions which can be\nlife-threatening. Conventional deterministic methods often fall short when it\ncomes to capturing the inherent uncertainty of anomaly detection tasks. This\npaper introduces a Bayesian Variational Autoencoder (VAE) equipped with\nmulti-head attention mechanisms for detecting anomalies in brain magnetic\nresonance imaging (MRI). For the purpose of improving anomaly detection\nperformance, we incorporate both epistemic and aleatoric uncertainty estimation\nthrough Bayesian inference. The model was tested on the BraTS2020 dataset, and\nthe findings were a 0.83 ROC AUC and a 0.83 PR AUC. The data in our paper\nsuggests that modeling uncertainty is an essential component of anomaly\ndetection, enhancing both performance and interpretability and providing\nconfidence estimates, as well as anomaly predictions, for clinicians to\nleverage in making medical decisions.", "AI": {"tldr": "A Bayesian VAE with multi-head attention improves anomaly detection in brain MRIs by modeling uncertainty, achieving high ROC and PR AUC scores.", "motivation": "Anomaly detection in medical imaging, especially for neurological conditions, is critical but often lacks uncertainty handling in conventional methods.", "method": "Bayesian Variational Autoencoder (VAE) with multi-head attention, incorporating epistemic and aleatoric uncertainty estimation via Bayesian inference.", "result": "Achieved 0.83 ROC AUC and 0.83 PR AUC on the BraTS2020 dataset.", "conclusion": "Modeling uncertainty enhances anomaly detection performance, interpretability, and provides confidence estimates for clinical decisions."}}
{"id": "2504.15661", "pdf": "https://arxiv.org/pdf/2504.15661", "abs": "https://arxiv.org/abs/2504.15661", "authors": ["Xian Wu", "Chang Liu"], "title": "DiTPainter: Efficient Video Inpainting with Diffusion Transformers", "categories": ["cs.CV"], "comment": null, "summary": "Many existing video inpainting algorithms utilize optical flows to construct\nthe corresponding maps and then propagate pixels from adjacent frames to\nmissing areas by mapping. Despite the effectiveness of the propagation\nmechanism, they might encounter blurry and inconsistencies when dealing with\ninaccurate optical flows or large masks. Recently, Diffusion Transformer (DiT)\nhas emerged as a revolutionary technique for video generation tasks. However,\npretrained DiT models for video generation all contain a large amount of\nparameters, which makes it very time consuming to apply to video inpainting\ntasks. In this paper, we present DiTPainter, an end-to-end video inpainting\nmodel based on Diffusion Transformer (DiT). DiTPainter uses an efficient\ntransformer network designed for video inpainting, which is trained from\nscratch instead of initializing from any large pretrained models. DiTPainter\ncan address videos with arbitrary lengths and can be applied to video\ndecaptioning and video completion tasks with an acceptable time cost.\nExperiments show that DiTPainter outperforms existing video inpainting\nalgorithms with higher quality and better spatial-temporal consistency.", "AI": {"tldr": "DiTPainter, a video inpainting model based on Diffusion Transformer (DiT), addresses blurry and inconsistency issues in existing methods by using an efficient transformer network trained from scratch.", "motivation": "Existing video inpainting methods struggle with inaccurate optical flows and large masks, leading to blurry results. Pretrained DiT models are too large for efficient video inpainting.", "method": "DiTPainter employs an efficient transformer network designed for video inpainting, trained from scratch, and handles arbitrary video lengths.", "result": "DiTPainter outperforms existing methods, offering higher quality and better spatial-temporal consistency.", "conclusion": "DiTPainter provides an effective, efficient solution for video inpainting, decaptioning, and completion tasks."}}
{"id": "2504.15848", "pdf": "https://arxiv.org/pdf/2504.15848", "abs": "https://arxiv.org/abs/2504.15848", "authors": ["Luwei Xiao", "Rui Mao", "Shuai Zhao", "Qika Lin", "Yanhao Jia", "Liang He", "Erik Cambria"], "title": "Exploring Cognitive and Aesthetic Causality for Multimodal Aspect-Based Sentiment Analysis", "categories": ["cs.CL"], "comment": "Accepted by TAFFC 2025", "summary": "Multimodal aspect-based sentiment classification (MASC) is an emerging task\ndue to an increase in user-generated multimodal content on social platforms,\naimed at predicting sentiment polarity toward specific aspect targets (i.e.,\nentities or attributes explicitly mentioned in text-image pairs). Despite\nextensive efforts and significant achievements in existing MASC, substantial\ngaps remain in understanding fine-grained visual content and the cognitive\nrationales derived from semantic content and impressions (cognitive\ninterpretations of emotions evoked by image content). In this study, we present\nChimera: a cognitive and aesthetic sentiment causality understanding framework\nto derive fine-grained holistic features of aspects and infer the fundamental\ndrivers of sentiment expression from both semantic perspectives and\naffective-cognitive resonance (the synergistic effect between emotional\nresponses and cognitive interpretations). Specifically, this framework first\nincorporates visual patch features for patch-word alignment. Meanwhile, it\nextracts coarse-grained visual features (e.g., overall image representation)\nand fine-grained visual regions (e.g., aspect-related regions) and translates\nthem into corresponding textual descriptions (e.g., facial, aesthetic).\nFinally, we leverage the sentimental causes and impressions generated by a\nlarge language model (LLM) to enhance the model's awareness of sentimental cues\nevoked by semantic content and affective-cognitive resonance. Experimental\nresults on standard MASC datasets demonstrate the effectiveness of the proposed\nmodel, which also exhibits greater flexibility to MASC compared to LLMs such as\nGPT-4o. We have publicly released the complete implementation and dataset at\nhttps://github.com/Xillv/Chimera", "AI": {"tldr": "The paper introduces Chimera, a framework for multimodal aspect-based sentiment classification (MASC) that combines cognitive and aesthetic analysis to improve sentiment prediction by leveraging fine-grained visual and textual features.", "motivation": "Existing MASC models lack understanding of fine-grained visual content and cognitive rationales, prompting the need for a framework that integrates semantic and affective-cognitive perspectives.", "method": "Chimera aligns visual patches with words, extracts coarse and fine-grained visual features, translates them into textual descriptions, and uses LLM-generated sentimental causes and impressions to enhance sentiment awareness.", "result": "Experiments on standard MASC datasets show Chimera's effectiveness and flexibility, outperforming models like GPT-4o.", "conclusion": "Chimera successfully bridges gaps in MASC by integrating cognitive and aesthetic analysis, offering a robust solution for sentiment prediction in multimodal content."}}
{"id": "2504.15286", "pdf": "https://arxiv.org/pdf/2504.15286", "abs": "https://arxiv.org/abs/2504.15286", "authors": ["Daniele Gorla", "Shivam Kumar", "Pietro Nicolaus Roselli Lorenzini", "Alireza Alipourfaz"], "title": "CUBETESTERAI: Automated JUnit Test Generation using the LLaMA Model", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted to ICST 2025 Industry Track", "summary": "This paper presents an approach to automating JUnit test generation for Java\napplications using the Spring Boot framework, leveraging the LLaMA (Large\nLanguage Model Architecture) model to enhance the efficiency and accuracy of\nthe testing process. The resulting tool, called CUBETESTERAI, includes a\nuser-friendly web interface and the integration of a CI/CD pipeline using\nGitLab and Docker. These components streamline the automated test generation\nprocess, allowing developers to generate JUnit tests directly from their code\nsnippets with minimal manual intervention. The final implementation executes\nthe LLaMA models through RunPod, an online GPU service, which also enhances the\nprivacy of our tool. Using the advanced natural language processing\ncapabilities of the LLaMA model, CUBETESTERAI is able to generate test cases\nthat provide high code coverage and accurate validation of software\nfunctionalities in Java-based Spring Boot applications. Furthermore, it\nefficiently manages resource-intensive operations and refines the generated\ntests to address common issues like missing imports and handling of private\nmethods. By comparing CUBETESTERAI with some state-of-the-art tools, we show\nthat our proposal consistently demonstrates competitive and, in many cases,\nbetter performance in terms of code coverage in different real-life Java\nprograms.", "AI": {"tldr": "CUBETESTERAI automates JUnit test generation for Spring Boot Java apps using LLaMA, offering high efficiency, accuracy, and privacy via a web interface and CI/CD integration.", "motivation": "To streamline and enhance the automated test generation process for Java applications, reducing manual effort and improving test quality.", "method": "Leverages LLaMA for NLP-based test generation, integrates with GitLab/Docker for CI/CD, and uses RunPod for GPU-powered execution.", "result": "Achieves high code coverage and accurate validation, outperforming state-of-the-art tools in real-life Java programs.", "conclusion": "CUBETESTERAI is a competitive, efficient, and privacy-conscious solution for automated JUnit test generation in Spring Boot applications."}}
{"id": "2504.15582", "pdf": "https://arxiv.org/pdf/2504.15582", "abs": "https://arxiv.org/abs/2504.15582", "authors": ["Jason Hartline", "Yifan Wu", "Yunran Yang"], "title": "Smooth Calibration and Decision Making", "categories": ["cs.LG", "cs.DS", "stat.ML"], "comment": "In FORC 2025", "summary": "Calibration requires predictor outputs to be consistent with their Bayesian\nposteriors. For machine learning predictors that do not distinguish between\nsmall perturbations, calibration errors are continuous in predictions, e.g.,\nsmooth calibration error (Foster and Hart, 2018), Distance to Calibration\n(Blasiok et al., 2023a). On the contrary, decision-makers who use predictions\nmake optimal decisions discontinuously in probabilistic space, experiencing\nloss from miscalibration discontinuously. Calibration errors for\ndecision-making are thus discontinuous, e.g., Expected Calibration Error\n(Foster and Vohra, 1997), and Calibration Decision Loss (Hu and Wu, 2024).\nThus, predictors with a low calibration error for machine learning may suffer a\nhigh calibration error for decision-making, i.e., they may not be trustworthy\nfor decision-makers optimizing assuming their predictions are correct. It is\nnatural to ask if post-processing a predictor with a low calibration error for\nmachine learning is without loss to achieve a low calibration error for\ndecision-making. In our paper, we show that post-processing an online predictor\nwith $\\epsilon$ distance to calibration achieves $O(\\sqrt{\\epsilon})$ ECE and\nCDL, which is asymptotically optimal. The post-processing algorithm adds noise\nto make predictions differentially private. The optimal bound from low distance\nto calibration predictors from post-processing is non-optimal compared with\nexisting online calibration algorithms that directly optimize for ECE and CDL.", "AI": {"tldr": "The paper explores the discrepancy between calibration errors in machine learning (continuous) and decision-making (discontinuous), showing post-processing can achieve near-optimal calibration for decision-making.", "motivation": "To address the mismatch between calibration errors for predictors used in machine learning and those critical for decision-making, ensuring trustworthiness for decision-makers.", "method": "Post-processing an online predictor with noise to achieve differential privacy, aiming for low Expected Calibration Error (ECE) and Calibration Decision Loss (CDL).", "result": "Post-processing achieves $O(\\sqrt{\\epsilon})$ ECE and CDL, asymptotically optimal but non-optimal compared to direct optimization methods.", "conclusion": "Post-processing can bridge the gap between calibration errors for machine learning and decision-making, though direct optimization remains superior."}}
{"id": "2504.15665", "pdf": "https://arxiv.org/pdf/2504.15665", "abs": "https://arxiv.org/abs/2504.15665", "authors": ["Pei Liu", "Yisi Luo", "Wenzhen Wang", "Xiangyong Cao"], "title": "Motion-Enhanced Nonlocal Similarity Implicit Neural Representation for Infrared Dim and Small Target Detection", "categories": ["cs.CV"], "comment": null, "summary": "Infrared dim and small target detection presents a significant challenge due\nto dynamic multi-frame scenarios and weak target signatures in the infrared\nmodality. Traditional low-rank plus sparse models often fail to capture dynamic\nbackgrounds and global spatial-temporal correlations, which results in\nbackground leakage or target loss. In this paper, we propose a novel\nmotion-enhanced nonlocal similarity implicit neural representation (INR)\nframework to address these challenges. We first integrate motion estimation via\noptical flow to capture subtle target movements, and propose multi-frame fusion\nto enhance motion saliency. Second, we leverage nonlocal similarity to\nconstruct patch tensors with strong low-rank properties, and propose an\ninnovative tensor decomposition-based INR model to represent the nonlocal patch\ntensor, effectively encoding both the nonlocal low-rankness and\nspatial-temporal correlations of background through continuous neural\nrepresentations. An alternating direction method of multipliers is developed\nfor the nonlocal INR model, which enjoys theoretical fixed-point convergence.\nExperimental results show that our approach robustly separates dim targets from\ncomplex infrared backgrounds, outperforming state-of-the-art methods in\ndetection accuracy and robustness.", "AI": {"tldr": "A novel motion-enhanced nonlocal similarity implicit neural representation (INR) framework is proposed for infrared dim and small target detection, outperforming state-of-the-art methods.", "motivation": "Traditional low-rank plus sparse models fail to handle dynamic backgrounds and global spatial-temporal correlations, leading to background leakage or target loss.", "method": "Integrates motion estimation via optical flow, multi-frame fusion for motion saliency, and a tensor decomposition-based INR model to encode nonlocal low-rankness and spatial-temporal correlations.", "result": "Robustly separates dim targets from complex backgrounds, achieving higher detection accuracy and robustness.", "conclusion": "The proposed framework effectively addresses challenges in infrared dim target detection, offering superior performance."}}
{"id": "2504.15895", "pdf": "https://arxiv.org/pdf/2504.15895", "abs": "https://arxiv.org/abs/2504.15895", "authors": ["Chenxu Yang", "Qingyi Si", "Yongjie Duan", "Zheliang Zhu", "Chenyu Zhu", "Zheng Lin", "Li Cao", "Weiping Wang"], "title": "Dynamic Early Exit in Reasoning Models", "categories": ["cs.CL", "cs.AI"], "comment": "19 pages, 11 figures", "summary": "Recent advances in large reasoning language models (LRLMs) rely on test-time\nscaling, which extends long chain-of-thought (CoT) generation to solve complex\ntasks. However, overthinking in long CoT not only slows down the efficiency of\nproblem solving, but also risks accuracy loss due to the extremely detailed or\nredundant reasoning steps. We propose a simple yet effective method that allows\nLLMs to self-truncate CoT sequences by early exit during generation. Instead of\nrelying on fixed heuristics, the proposed method monitors model behavior at\npotential reasoning transition points (e.g.,\"Wait\" tokens) and dynamically\nterminates the next reasoning chain's generation when the model exhibits high\nconfidence in a trial answer. Our method requires no additional training and\ncan be seamlessly integrated into existing o1-like reasoning LLMs. Experiments\non multiple reasoning benchmarks MATH-500, AMC 2023, GPQA Diamond and AIME 2024\nshow that the proposed method is consistently effective on deepseek-series\nreasoning LLMs, reducing the length of CoT sequences by an average of 31% to\n43% while improving accuracy by 1.7% to 5.7%.", "AI": {"tldr": "A method for self-truncating CoT sequences in LRLMs improves efficiency and accuracy by dynamically exiting generation based on model confidence.", "motivation": "Overthinking in long CoT sequences reduces efficiency and risks accuracy loss due to redundancy.", "method": "Monitors model behavior at reasoning transition points to dynamically terminate generation when confidence is high.", "result": "Reduces CoT length by 31-43% and improves accuracy by 1.7-5.7% on benchmarks.", "conclusion": "The method is effective, requires no training, and integrates seamlessly with existing LLMs."}}
{"id": "2504.15296", "pdf": "https://arxiv.org/pdf/2504.15296", "abs": "https://arxiv.org/abs/2504.15296", "authors": ["Yihong Jin", "Ze Yang"], "title": "Scalability Optimization in Cloud-Based AI Inference Services: Strategies for Real-Time Load Balancing and Automated Scaling", "categories": ["cs.DC", "cs.AI", "F.2.2; I.2.8"], "comment": "Accepted to BDICN 2025", "summary": "The rapid expansion of AI inference services in the cloud necessitates a\nrobust scalability solution to manage dynamic workloads and maintain high\nperformance. This study proposes a comprehensive scalability optimization\nframework for cloud AI inference services, focusing on real-time load balancing\nand autoscaling strategies. The proposed model is a hybrid approach that\ncombines reinforcement learning for adaptive load distribution and deep neural\nnetworks for accurate demand forecasting. This multi-layered approach enables\nthe system to anticipate workload fluctuations and proactively adjust\nresources, ensuring maximum resource utilisation and minimising latency.\nFurthermore, the incorporation of a decentralised decision-making process\nwithin the model serves to enhance fault tolerance and reduce response time in\nscaling operations. Experimental results demonstrate that the proposed model\nenhances load balancing efficiency by 35\\ and reduces response delay by 28\\,\nthereby exhibiting a substantial optimization effect in comparison with\nconventional scalability solutions.", "AI": {"tldr": "A hybrid framework combining reinforcement learning and deep neural networks optimizes cloud AI inference scalability, improving load balancing by 35% and reducing delay by 28%.", "motivation": "Address the need for robust scalability in cloud AI inference services to handle dynamic workloads and maintain performance.", "method": "Proposes a hybrid model using reinforcement learning for adaptive load balancing and deep neural networks for demand forecasting, with decentralized decision-making for fault tolerance.", "result": "Improves load balancing efficiency by 35% and reduces response delay by 28% compared to conventional methods.", "conclusion": "The framework effectively enhances scalability, resource utilization, and performance in cloud AI inference services."}}
{"id": "2504.15587", "pdf": "https://arxiv.org/pdf/2504.15587", "abs": "https://arxiv.org/abs/2504.15587", "authors": ["Zimo Yan", "Jie Zhang", "Zheng Xie", "Chang Liu", "Yizhen Liu", "Yiping Song"], "title": "MetaMolGen: A Neural Graph Motif Generation Model for De Novo Molecular Design", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Molecular generation plays an important role in drug discovery and materials\nscience, especially in data-scarce scenarios where traditional generative\nmodels often struggle to achieve satisfactory conditional generalization. To\naddress this challenge, we propose MetaMolGen, a first-order\nmeta-learning-based molecular generator designed for few-shot and\nproperty-conditioned molecular generation. MetaMolGen standardizes the\ndistribution of graph motifs by mapping them to a normalized latent space, and\nemploys a lightweight autoregressive sequence model to generate SMILES\nsequences that faithfully reflect the underlying molecular structure. In\naddition, it supports conditional generation of molecules with target\nproperties through a learnable property projector integrated into the\ngenerative process.Experimental results demonstrate that MetaMolGen\nconsistently generates valid and diverse SMILES sequences under low-data\nregimes, outperforming conventional baselines. This highlights its advantage in\nfast adaptation and efficient conditional generation for practical molecular\ndesign.", "AI": {"tldr": "MetaMolGen is a meta-learning-based molecular generator for few-shot and property-conditioned molecular generation, outperforming traditional methods in low-data scenarios.", "motivation": "Addressing the challenge of molecular generation in data-scarce settings where traditional models struggle with conditional generalization.", "method": "Uses a first-order meta-learning approach, standardizes graph motifs in a latent space, and employs an autoregressive sequence model for SMILES generation. Includes a learnable property projector for conditional generation.", "result": "Generates valid and diverse SMILES sequences in low-data regimes, outperforming conventional baselines.", "conclusion": "MetaMolGen excels in fast adaptation and efficient conditional generation for practical molecular design."}}
{"id": "2504.15669", "pdf": "https://arxiv.org/pdf/2504.15669", "abs": "https://arxiv.org/abs/2504.15669", "authors": ["Wei Zhuo", "Zhiyue Tang", "Wufeng Xue", "Hao Ding", "Linlin Shen"], "title": "DINOv2-powered Few-Shot Semantic Segmentation: A Unified Framework via Cross-Model Distillation and 4D Correlation Mining", "categories": ["cs.CV"], "comment": null, "summary": "Few-shot semantic segmentation has gained increasing interest due to its\ngeneralization capability, i.e., segmenting pixels of novel classes requiring\nonly a few annotated images. Prior work has focused on meta-learning for\nsupport-query matching, with extensive development in both prototype-based and\naggregation-based methods. To address data scarcity, recent approaches have\nturned to foundation models to enhance representation transferability for novel\nclass segmentation. Among them, a hybrid dual-modal framework including both\nDINOv2 and SAM has garnered attention due to their complementary capabilities.\nWe wonder \"can we build a unified model with knowledge from both foundation\nmodels?\" To this end, we propose FS-DINO, with only DINOv2's encoder and a\nlightweight segmenter. The segmenter features a bottleneck adapter, a\nmeta-visual prompt generator based on dense similarities and semantic\nembeddings, and a decoder. Through coarse-to-fine cross-model distillation, we\neffectively integrate SAM's knowledge into our lightweight segmenter, which can\nbe further enhanced by 4D correlation mining on support-query pairs. Extensive\nexperiments on COCO-20i, PASCAL-5i, and FSS-1000 demonstrate the effectiveness\nand superiority of our method.", "AI": {"tldr": "FS-DINO is a unified model combining DINOv2's encoder and a lightweight segmenter for few-shot semantic segmentation, leveraging SAM's knowledge through distillation and 4D correlation mining.", "motivation": "To address data scarcity and enhance representation transferability for novel class segmentation by unifying knowledge from DINOv2 and SAM.", "method": "Proposes FS-DINO with DINOv2's encoder and a lightweight segmenter featuring a bottleneck adapter, meta-visual prompt generator, and decoder. Uses coarse-to-fine cross-model distillation and 4D correlation mining.", "result": "Demonstrates effectiveness and superiority on COCO-20i, PASCAL-5i, and FSS-1000 datasets.", "conclusion": "FS-DINO successfully integrates SAM's knowledge into a lightweight segmenter, achieving strong performance in few-shot semantic segmentation."}}
{"id": "2504.15900", "pdf": "https://arxiv.org/pdf/2504.15900", "abs": "https://arxiv.org/abs/2504.15900", "authors": ["Cheng Wen", "Tingwei Guo", "Shuaijiang Zhao", "Wei Zou", "Xiangang Li"], "title": "SARI: Structured Audio Reasoning via Curriculum-Guided Reinforcement Learning", "categories": ["cs.CL"], "comment": null, "summary": "Recent work shows that reinforcement learning(RL) can markedly sharpen the\nreasoning ability of large language models (LLMs) by prompting them to \"think\nbefore answering.\" Yet whether and how these gains transfer to audio-language\nreasoning remains largely unexplored. We extend the Group-Relative Policy\nOptimization (GRPO) framework from DeepSeek-R1 to a Large Audio-Language Model\n(LALM), and construct a 32k sample multiple-choice corpus. Using a two-stage\nregimen supervised fine-tuning on structured and unstructured\nchains-of-thought, followed by curriculum-guided GRPO, we systematically\ncompare implicit vs. explicit, and structured vs. free form reasoning under\nidentical architectures. Our structured audio reasoning model, SARI (Structured\nAudio Reasoning via Curriculum-Guided Reinforcement Learning), achieves a\n16.35% improvement in average accuracy over the base model\nQwen2-Audio-7B-Instruct. Furthermore, the variant built upon Qwen2.5-Omni\nreaches state-of-the-art performance of 67.08% on the MMAU test-mini benchmark.\nAblation experiments show that on the base model we use: (i) SFT warm-up is\nimportant for stable RL training, (ii) structured chains yield more robust\ngeneralization than unstructured ones, and (iii) easy-to-hard curricula\naccelerate convergence and improve final performance. These findings\ndemonstrate that explicit, structured reasoning and curriculum learning\nsubstantially enhances audio-language understanding.", "AI": {"tldr": "Reinforcement learning (RL) improves reasoning in large language models (LLMs) and is extended to audio-language models (LALMs) using GRPO, achieving significant accuracy gains.", "motivation": "To explore if RL's reasoning improvements in LLMs transfer to audio-language models and to enhance audio-language understanding.", "method": "Extends GRPO to LALMs, uses a two-stage regimen (supervised fine-tuning and curriculum-guided GRPO), and compares reasoning types.", "result": "SARI improves accuracy by 16.35% over the base model, with a variant achieving 67.08% on MMAU test-mini.", "conclusion": "Explicit, structured reasoning and curriculum learning significantly enhance audio-language understanding."}}
{"id": "2504.15299", "pdf": "https://arxiv.org/pdf/2504.15299", "abs": "https://arxiv.org/abs/2504.15299", "authors": ["Haodong Wang", "Qihua Zhou", "Zicong Hong", "Song Guo"], "title": "D$^{2}$MoE: Dual Routing and Dynamic Scheduling for Efficient On-Device MoE-based LLM Serving", "categories": ["cs.DC", "cs.AI"], "comment": "Accepted by MobiCom 2025", "summary": "The mixture of experts (MoE) model is a sparse variant of large language\nmodels (LLMs), designed to hold a better balance between intelligent capability\nand computational overhead. Despite its benefits, MoE is still too expensive to\ndeploy on resource-constrained edge devices, especially with the demands of\non-device inference services. Recent research efforts often apply model\ncompression techniques, such as quantization, pruning and merging, to restrict\nMoE complexity. Unfortunately, due to their predefined static model\noptimization strategies, they cannot always achieve the desired\nquality-overhead trade-off when handling multiple requests, finally degrading\nthe on-device quality of service. These limitations motivate us to propose the\nD$^2$MoE, an algorithm-system co-design framework that matches diverse task\nrequirements by dynamically allocating the most proper bit-width to each\nexpert. Specifically, inspired by the nested structure of matryoshka dolls, we\npropose the matryoshka weight quantization (MWQ) to progressively compress\nexpert weights in a bit-nested manner and reduce the required runtime memory.\nOn top of it, we further optimize the I/O-computation pipeline and design a\nheuristic scheduling algorithm following our hottest-expert-bit-first (HEBF)\nprinciple, which maximizes the expert parallelism between I/O and computation\nqueue under constrained memory budgets, thus significantly reducing the idle\ntemporal bubbles waiting for the experts to load. Evaluations on real edge\ndevices show that D$^2$MoE improves the overall inference throughput by up to\n1.39$\\times$ and reduces the peak memory footprint by up to 53% over the latest\non-device inference frameworks, while still preserving comparable serving\naccuracy as its INT8 counterparts.", "AI": {"tldr": "D$^2$MoE is a co-design framework for MoE models, using dynamic bit-width allocation and nested quantization to optimize edge device performance.", "motivation": "MoE models are too resource-heavy for edge devices, and static compression methods fail to balance quality and overhead for diverse tasks.", "method": "Proposes matryoshka weight quantization (MWQ) for bit-nested compression and a heuristic scheduling algorithm (HEBF) for efficient I/O-computation.", "result": "Improves throughput by 1.39x, reduces memory by 53%, and maintains accuracy comparable to INT8 models.", "conclusion": "D$^2$MoE effectively balances performance and resource constraints for on-device MoE inference."}}
{"id": "2504.15594", "pdf": "https://arxiv.org/pdf/2504.15594", "abs": "https://arxiv.org/abs/2504.15594", "authors": ["Tatsuhito Hasegawa", "Shunsuke Sakai"], "title": "Analytical Softmax Temperature Setting from Feature Dimensions for Model- and Domain-Robust Classification", "categories": ["cs.LG", "cs.CV"], "comment": "22 pages, 11 figures, under review", "summary": "In deep learning-based classification tasks, the softmax function's\ntemperature parameter $T$ critically influences the output distribution and\noverall performance. This study presents a novel theoretical insight that the\noptimal temperature $T^*$ is uniquely determined by the dimensionality of the\nfeature representations, thereby enabling training-free determination of $T^*$.\nDespite this theoretical grounding, empirical evidence reveals that $T^*$\nfluctuates under practical conditions owing to variations in models, datasets,\nand other confounding factors. To address these influences, we propose and\noptimize a set of temperature determination coefficients that specify how $T^*$\nshould be adjusted based on the theoretical relationship to feature\ndimensionality. Additionally, we insert a batch normalization layer immediately\nbefore the output layer, effectively stabilizing the feature space. Building on\nthese coefficients and a suite of large-scale experiments, we develop an\nempirical formula to estimate $T^*$ without additional training while also\nintroducing a corrective scheme to refine $T^*$ based on the number of classes\nand task complexity. Our findings confirm that the derived temperature not only\naligns with the proposed theoretical perspective but also generalizes\neffectively across diverse tasks, consistently enhancing classification\nperformance and offering a practical, training-free solution for determining\n$T^*$.", "AI": {"tldr": "The study reveals that the optimal temperature parameter $T^*$ in softmax is determined by feature dimensionality, proposes coefficients and a batch normalization layer to stabilize it, and derives an empirical formula for training-free $T^*$ estimation.", "motivation": "To theoretically and empirically determine the optimal temperature parameter $T^*$ in softmax for classification tasks, addressing its variability under practical conditions.", "method": "Proposes temperature determination coefficients, inserts a batch normalization layer, and develops an empirical formula for $T^*$ estimation without training.", "result": "The derived $T^*$ aligns with theory and generalizes across tasks, improving classification performance.", "conclusion": "The study offers a practical, training-free solution for determining $T^*$, enhancing performance in diverse tasks."}}
{"id": "2504.15681", "pdf": "https://arxiv.org/pdf/2504.15681", "abs": "https://arxiv.org/abs/2504.15681", "authors": ["Vidi Team", "Celong Liu", "Chia-Wen Kuo", "Dawei Du", "Fan Chen", "Guang Chen", "Jiamin Yuan", "Lingxi Zhang", "Lu Guo", "Lusha Li", "Longyin Wen", "Qingyu Chen", "Rachel Deng", "Sijie Zhu", "Stuart Siew", "Tong Jin", "Wei Lu", "Wen Zhong", "Xiaohui Shen", "Xin Gu", "Xing Mei", "Xueqiong Qu"], "title": "Vidi: Large Multimodal Models for Video Understanding and Editing", "categories": ["cs.CV"], "comment": null, "summary": "Humans naturally share information with those they are connected to, and\nvideo has become one of the dominant mediums for communication and expression\non the Internet. To support the creation of high-quality large-scale video\ncontent, a modern pipeline requires a comprehensive understanding of both the\nraw input materials (e.g., the unedited footage captured by cameras) and the\nediting components (e.g., visual effects). In video editing scenarios, models\nmust process multiple modalities (e.g., vision, audio, text) with strong\nbackground knowledge and handle flexible input lengths (e.g., hour-long raw\nvideos), which poses significant challenges for traditional models. In this\nreport, we introduce Vidi, a family of Large Multimodal Models (LMMs) for a\nwide range of video understand editing scenarios. The first release focuses on\ntemporal retrieval, i.e., identifying the time ranges within the input videos\ncorresponding to a given text query, which plays a critical role in intelligent\nediting. The model is capable of processing hour-long videos with strong\ntemporal understanding capability, e.g., retrieve time ranges for certain\nqueries. To support a comprehensive evaluation in real-world scenarios, we also\npresent the VUE-TR benchmark, which introduces five key advancements. 1) Video\nduration: significantly longer than existing temporal retrival datasets, 2)\nAudio support: includes audio-based queries, 3) Query format: diverse query\nlengths/formats, 4) Annotation quality: ground-truth time ranges are manually\nannotated. 5) Evaluation metric: a refined IoU metric to support evaluation\nover multiple time ranges. Remarkably, Vidi significantly outperforms leading\nproprietary models, e.g., GPT-4o and Gemini, on the temporal retrieval task,\nindicating its superiority in video editing scenarios.", "AI": {"tldr": "Vidi, a Large Multimodal Model (LMM), excels in temporal retrieval for video editing, outperforming models like GPT-4o and Gemini.", "motivation": "To address the challenges of processing multimodal, long-duration videos in editing, requiring strong temporal understanding.", "method": "Introduces Vidi, an LMM for video understanding, focusing on temporal retrieval (identifying video segments matching text queries).", "result": "Vidi outperforms proprietary models on the VUE-TR benchmark, which includes longer videos, audio support, and diverse queries.", "conclusion": "Vidi demonstrates superior performance in video editing tasks, validated by the comprehensive VUE-TR benchmark."}}
{"id": "2504.15941", "pdf": "https://arxiv.org/pdf/2504.15941", "abs": "https://arxiv.org/abs/2504.15941", "authors": ["Fanny Jourdan", "Yannick Chevalier", "C\u00e9cile Favre"], "title": "FairTranslate: An English-French Dataset for Gender Bias Evaluation in Machine Translation by Overcoming Gender Binarity", "categories": ["cs.CL", "cs.AI"], "comment": "FAccT 2025", "summary": "Large Language Models (LLMs) are increasingly leveraged for translation tasks\nbut often fall short when translating inclusive language -- such as texts\ncontaining the singular 'they' pronoun or otherwise reflecting fair linguistic\nprotocols. Because these challenges span both computational and societal\ndomains, it is imperative to critically evaluate how well LLMs handle inclusive\ntranslation with a well-founded framework.\n  This paper presents FairTranslate, a novel, fully human-annotated dataset\ndesigned to evaluate non-binary gender biases in machine translation systems\nfrom English to French. FairTranslate includes 2418 English-French sentence\npairs related to occupations, annotated with rich metadata such as the\nstereotypical alignment of the occupation, grammatical gender indicator\nambiguity, and the ground-truth gender label (male, female, or inclusive).\n  We evaluate four leading LLMs (Gemma2-2B, Mistral-7B, Llama3.1-8B,\nLlama3.3-70B) on this dataset under different prompting procedures. Our results\nreveal substantial biases in gender representation across LLMs, highlighting\npersistent challenges in achieving equitable outcomes in machine translation.\nThese findings underscore the need for focused strategies and interventions\naimed at ensuring fair and inclusive language usage in LLM-based translation\nsystems.\n  We make the FairTranslate dataset publicly available on Hugging Face, and\ndisclose the code for all experiments on GitHub.", "AI": {"tldr": "FairTranslate is a dataset evaluating gender biases in LLM translations from English to French, revealing significant biases and advocating for fairer practices.", "motivation": "To address the shortcomings of LLMs in translating inclusive language, particularly non-binary gender biases, by providing a robust evaluation framework.", "method": "Created FairTranslate, a human-annotated dataset of 2418 English-French sentence pairs, and tested four LLMs under various prompts.", "result": "Substantial gender representation biases were found across all evaluated LLMs, indicating persistent challenges in equitable translation.", "conclusion": "The study highlights the need for targeted strategies to ensure fair and inclusive language usage in LLM-based translation systems."}}
{"id": "2504.15303", "pdf": "https://arxiv.org/pdf/2504.15303", "abs": "https://arxiv.org/abs/2504.15303", "authors": ["Yi Xiong", "Jinqi Huang", "Wenjie Huang", "Xuebing Yu", "Entong Li", "Zhixiong Ning", "Jinhua Zhou", "Li Zeng", "Xin Chen"], "title": "High-Throughput LLM inference on Heterogeneous Clusters", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Nowadays, many companies possess various types of AI accelerators, forming\nheterogeneous clusters. Efficiently leveraging these clusters for\nhigh-throughput large language model (LLM) inference services can significantly\nreduce costs and expedite task processing. However, LLM inference on\nheterogeneous clusters presents two main challenges. Firstly, different\ndeployment configurations can result in vastly different performance. The\nnumber of possible configurations is large, and evaluating the effectiveness of\na specific setup is complex. Thus, finding an optimal configuration is not an\neasy task. Secondly, LLM inference instances within a heterogeneous cluster\npossess varying processing capacities, leading to different processing speeds\nfor handling inference requests. Evaluating these capacities and designing a\nrequest scheduling algorithm that fully maximizes the potential of each\ninstance is challenging. In this paper, we propose a high-throughput inference\nservice system on heterogeneous clusters. First, the deployment configuration\nis optimized by modeling the resource amount and expected throughput and using\nthe exhaustive search method. Second, a novel mechanism is proposed to schedule\nrequests among instances, which fully considers the different processing\ncapabilities of various instances. Extensive experiments show that the proposed\nscheduler improves throughput by 122.5% and 33.6% on two heterogeneous\nclusters, respectively.", "AI": {"tldr": "The paper proposes a system for high-throughput LLM inference on heterogeneous clusters, optimizing deployment configurations and request scheduling to improve performance.", "motivation": "Efficiently leveraging heterogeneous AI accelerator clusters for LLM inference can reduce costs and speed up processing, but challenges like configuration optimization and request scheduling exist.", "method": "The system optimizes deployment configurations via exhaustive search and introduces a novel request scheduler accounting for varying instance capabilities.", "result": "Experiments show throughput improvements of 122.5% and 33.6% on two clusters.", "conclusion": "The proposed system effectively addresses challenges in LLM inference on heterogeneous clusters, significantly boosting throughput."}}
{"id": "2504.15613", "pdf": "https://arxiv.org/pdf/2504.15613", "abs": "https://arxiv.org/abs/2504.15613", "authors": ["Minglian Han"], "title": "Learning Dynamic Graphs via Tensorized and Lightweight Graph Convolutional Networks", "categories": ["cs.LG"], "comment": null, "summary": "A dynamic graph (DG) is frequently encountered in numerous real-world\nscenarios. Consequently, A dynamic graph convolutional network (DGCN) has been\nsuccessfully applied to perform precise representation learning on a DG.\nHowever, conventional DGCNs typically consist of a static GCN coupled with a\nsequence neural network (SNN) to model spatial and temporal patterns\nseparately. This decoupled modeling mechanism inherently disrupts the intricate\nspatio-temporal dependencies. To address the issue, this study proposes a novel\nTensorized Lightweight Graph Convolutional Network (TLGCN) for accurate dynamic\ngraph learning. It mainly contains the following two key concepts: a) designing\na novel spatio-temporal information propagation method for joint propagation of\nspatio-temporal information based on the tensor M-product framework; b)\nproposing a tensorized lightweight graph convolutional network based on the\nabove method, which significantly reduces the memory occupation of the model by\nomitting complex feature transformation and nonlinear activation. Numerical\nexperiments on four real-world datasets demonstrate that the proposed TLGCN\noutperforms the state-of-the-art models in the weight estimation task on DGs.", "AI": {"tldr": "The paper introduces TLGCN, a tensorized lightweight graph convolutional network, to improve dynamic graph learning by jointly modeling spatio-temporal dependencies, reducing memory usage, and outperforming existing models.", "motivation": "Conventional DGCNs decouple spatial and temporal patterns, disrupting spatio-temporal dependencies. This study aims to address this limitation.", "method": "Proposes TLGCN with a novel spatio-temporal information propagation method and tensorized lightweight graph convolution, omitting complex transformations.", "result": "TLGCN outperforms state-of-the-art models in weight estimation tasks on four real-world datasets.", "conclusion": "TLGCN effectively captures spatio-temporal dependencies and reduces memory usage, offering superior performance in dynamic graph learning."}}
{"id": "2504.15694", "pdf": "https://arxiv.org/pdf/2504.15694", "abs": "https://arxiv.org/abs/2504.15694", "authors": ["Jun Dong", "Wenli Wu", "Jintao Cheng", "Xiaoyu Tang"], "title": "You Sense Only Once Beneath: Ultra-Light Real-Time Underwater Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Despite the remarkable achievements in object detection, the model's accuracy\nand efficiency still require further improvement under challenging underwater\nconditions, such as low image quality and limited computational resources. To\naddress this, we propose an Ultra-Light Real-Time Underwater Object Detection\nframework, You Sense Only Once Beneath (YSOOB). Specifically, we utilize a\nMulti-Spectrum Wavelet Encoder (MSWE) to perform frequency-domain encoding on\nthe input image, minimizing the semantic loss caused by underwater optical\ncolor distortion. Furthermore, we revisit the unique characteristics of\neven-sized and transposed convolutions, allowing the model to dynamically\nselect and enhance key information during the resampling process, thereby\nimproving its generalization ability. Finally, we eliminate model redundancy\nthrough a simple yet effective channel compression and reconstructed large\nkernel convolution (RLKC) to achieve model lightweight. As a result, forms a\nhigh-performance underwater object detector YSOOB with only 1.2 million\nparameters. Extensive experimental results demonstrate that, with the fewest\nparameters, YSOOB achieves mAP50 of 83.1% and 82.9% on the URPC2020 and DUO\ndatasets, respectively, comparable to the current SOTA detectors. The inference\nspeed reaches 781.3 FPS and 57.8 FPS on the T4 GPU (TensorRT FP16) and the edge\ncomputing device Jetson Xavier NX (TensorRT FP16), surpassing YOLOv12-N by\n28.1% and 22.5%, respectively.", "AI": {"tldr": "Proposes YSOOB, an ultra-light real-time underwater object detection framework, achieving high accuracy and efficiency with minimal parameters.", "motivation": "Improving object detection accuracy and efficiency in challenging underwater conditions with low image quality and limited computational resources.", "method": "Uses Multi-Spectrum Wavelet Encoder for frequency-domain encoding, dynamic resampling with even-sized/transposed convolutions, and channel compression with RLKC for lightweighting.", "result": "YSOOB achieves 83.1% and 82.9% mAP50 on URPC2020 and DUO datasets, with 781.3 FPS on T4 GPU and 57.8 FPS on Jetson Xavier NX.", "conclusion": "YSOOB outperforms current SOTA detectors in efficiency and accuracy, making it suitable for real-time underwater applications."}}
{"id": "2504.15983", "pdf": "https://arxiv.org/pdf/2504.15983", "abs": "https://arxiv.org/abs/2504.15983", "authors": ["Shang Wang"], "title": "W-PCA Based Gradient-Free Proxy for Efficient Search of Lightweight Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "ICLR 2025", "summary": "The demand for efficient natural language processing (NLP) systems has led to\nthe development of lightweight language models. Previous work in this area has\nprimarily focused on manual design or training-based neural architecture search\n(NAS) methods. Recently, zero-shot NAS methods have been proposed for\nevaluating language models without the need for training. However, prevailing\napproaches to zero-shot NAS often face challenges such as biased evaluation\nmetrics and computational inefficiencies. In this paper, we introduce\nweight-weighted PCA (W-PCA), a novel zero-shot NAS method specifically tailored\nfor lightweight language models. Our approach utilizes two evaluation proxies:\nthe parameter count and the number of principal components with cumulative\ncontribution exceeding $\\eta$ in the feed-forward neural (FFN) layer.\nAdditionally, by eliminating the need for gradient computations, we optimize\nthe evaluation time, thus enhancing the efficiency of designing and evaluating\nlightweight language models. We conduct a comparative analysis on the GLUE and\nSQuAD datasets to evaluate our approach. The results demonstrate that our\nmethod significantly reduces training time compared to one-shot NAS methods and\nachieves higher scores in the testing phase compared to previous\nstate-of-the-art training-based methods. Furthermore, we perform ranking\nevaluations on a dataset sampled from the FlexiBERT search space. Our approach\nexhibits superior ranking correlation and further reduces solving time compared\nto other zero-shot NAS methods that require gradient computation.", "AI": {"tldr": "The paper introduces W-PCA, a zero-shot NAS method for lightweight language models, improving efficiency and evaluation accuracy.", "motivation": "Addressing challenges like biased metrics and inefficiency in zero-shot NAS for lightweight NLP models.", "method": "Uses weight-weighted PCA with parameter count and principal components in FFN layers, avoiding gradient computations.", "result": "Reduces training time, achieves higher test scores, and improves ranking correlation and solving time.", "conclusion": "W-PCA is efficient and effective for designing lightweight language models."}}
{"id": "2504.15324", "pdf": "https://arxiv.org/pdf/2504.15324", "abs": "https://arxiv.org/abs/2504.15324", "authors": ["Vuong M. Ngo", "Edward Bolger", "Stan Goodwin", "John O'Sullivan", "Dinh Viet Cuong", "Mark Roantree"], "title": "A Graph Based Raman Spectral Processing Technique for Exosome Classification", "categories": ["q-bio.QM", "cs.AI", "cs.IT", "cs.LG", "math.IT"], "comment": "The 23rd International Conference on Artificial Intelligence in\n  Medicine (AIME 2025), LNAI, Springer, 11 pages", "summary": "Exosomes are small vesicles crucial for cell signaling and disease\nbiomarkers. Due to their complexity, an \"omics\" approach is preferable to\nindividual biomarkers. While Raman spectroscopy is effective for exosome\nanalysis, it requires high sample concentrations and has limited sensitivity to\nlipids and proteins. Surface-enhanced Raman spectroscopy helps overcome these\nchallenges. In this study, we leverage Neo4j graph databases to organize 3,045\nRaman spectra of exosomes, enhancing data generalization. To further refine\nspectral analysis, we introduce a novel spectral filtering process that\nintegrates the PageRank Filter with optimal Dimensionality Reduction. This\nmethod improves feature selection, resulting in superior classification\nperformance. Specifically, the Extra Trees model, using our spectral processing\napproach, achieves 0.76 and 0.857 accuracy in classifying hyperglycemic,\nhypoglycemic, and normal exosome samples based on Raman spectra and surface,\nrespectively, with group 10-fold cross-validation. Our results show that\ngraph-based spectral filtering combined with optimal dimensionality reduction\nsignificantly improves classification accuracy by reducing noise while\npreserving key biomarker signals. This novel framework enhances Raman-based\nexosome analysis, expanding its potential for biomedical applications, disease\ndiagnostics, and biomarker discovery.", "AI": {"tldr": "The study introduces a graph-based spectral filtering method for Raman spectroscopy of exosomes, improving classification accuracy for disease diagnostics.", "motivation": "Exosomes are important for disease biomarkers, but Raman spectroscopy has limitations in sensitivity and sample concentration. A more refined approach is needed.", "method": "The study uses Neo4j graph databases to organize Raman spectra and introduces a spectral filtering process combining PageRank Filter and Dimensionality Reduction. The Extra Trees model is applied for classification.", "result": "The method achieves 0.76 and 0.857 accuracy in classifying exosome samples, showing improved noise reduction and biomarker signal preservation.", "conclusion": "The framework enhances Raman-based exosome analysis, offering potential for biomedical applications and disease diagnostics."}}
{"id": "2504.15615", "pdf": "https://arxiv.org/pdf/2504.15615", "abs": "https://arxiv.org/abs/2504.15615", "authors": ["Jingwu Tang", "Jiayun Wu", "Zhiwei Steven Wu", "Jiahao Zhang"], "title": "Dimension-Free Decision Calibration for Nonlinear Loss Functions", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "When model predictions inform downstream decision making, a natural question\nis under what conditions can the decision-makers simply respond to the\npredictions as if they were the true outcomes. Calibration suffices to\nguarantee that simple best-response to predictions is optimal. However,\ncalibration for high-dimensional prediction outcome spaces requires exponential\ncomputational and statistical complexity. The recent relaxation known as\ndecision calibration ensures the optimality of the simple best-response rule\nwhile requiring only polynomial sample complexity in the dimension of outcomes.\nHowever, known results on calibration and decision calibration crucially rely\non linear loss functions for establishing best-response optimality. A natural\napproach to handle nonlinear losses is to map outcomes $y$ into a feature space\n$\\phi(y)$ of dimension $m$, then approximate losses with linear functions of\n$\\phi(y)$. Unfortunately, even simple classes of nonlinear functions can demand\nexponentially large or infinite feature dimensions $m$. A key open problem is\nwhether it is possible to achieve decision calibration with sample complexity\nindependent of~$m$. We begin with a negative result: even verifying decision\ncalibration under standard deterministic best response inherently requires\nsample complexity polynomial in~$m$. Motivated by this lower bound, we\ninvestigate a smooth version of decision calibration in which decision-makers\nfollow a smooth best-response. This smooth relaxation enables dimension-free\ndecision calibration algorithms. We introduce algorithms that, given\n$\\mathrm{poly}(|A|,1/\\epsilon)$ samples and any initial predictor~$p$, can\nefficiently post-process it to satisfy decision calibration without worsening\naccuracy. Our algorithms apply broadly to function classes that can be\nwell-approximated by bounded-norm functions in (possibly infinite-dimensional)\nseparable RKHS.", "AI": {"tldr": "The paper explores conditions for optimal decision-making based on model predictions, addressing challenges in calibration and decision calibration for high-dimensional spaces and nonlinear losses. It introduces smooth decision calibration to achieve dimension-free algorithms.", "motivation": "The motivation is to ensure optimal decision-making under model predictions, overcoming limitations of traditional calibration methods in high-dimensional and nonlinear settings.", "method": "The paper proposes a smooth version of decision calibration, enabling dimension-free algorithms. It introduces efficient post-processing methods for predictors to achieve decision calibration without sacrificing accuracy.", "result": "The results show that smooth decision calibration allows for dimension-free sample complexity, with algorithms efficiently post-processing predictors to meet calibration requirements.", "conclusion": "The conclusion highlights the feasibility of achieving decision calibration for nonlinear losses with dimension-free sample complexity, offering practical solutions for real-world applications."}}
{"id": "2504.15707", "pdf": "https://arxiv.org/pdf/2504.15707", "abs": "https://arxiv.org/abs/2504.15707", "authors": ["Yannic Neuhaus", "Matthias Hein"], "title": "RePOPE: Impact of Annotation Errors on the POPE Benchmark", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Since data annotation is costly, benchmark datasets often incorporate labels\nfrom established image datasets. In this work, we assess the impact of label\nerrors in MSCOCO on the frequently used object hallucination benchmark POPE. We\nre-annotate the benchmark images and identify an imbalance in annotation errors\nacross different subsets. Evaluating multiple models on the revised labels,\nwhich we denote as RePOPE, we observe notable shifts in model rankings,\nhighlighting the impact of label quality. Code and data are available at\nhttps://github.com/YanNeu/RePOPE .", "AI": {"tldr": "The paper evaluates label errors in MSCOCO's POPE benchmark, re-annotates images, and introduces RePOPE, showing how label quality affects model rankings.", "motivation": "To address the impact of label errors in benchmark datasets on model evaluations, particularly in the POPE benchmark derived from MSCOCO.", "method": "Re-annotate images from the POPE benchmark, identify annotation imbalances, and evaluate models on the revised labels (RePOPE).", "result": "Notable shifts in model rankings are observed when using RePOPE, emphasizing the influence of label quality.", "conclusion": "Label quality significantly affects benchmark reliability, and RePOPE provides a more accurate evaluation framework."}}
{"id": "2504.15987", "pdf": "https://arxiv.org/pdf/2504.15987", "abs": "https://arxiv.org/abs/2504.15987", "authors": ["Zhenkai Qin", "Dongze Wu", "Yuxin Liu", "Guifang Yang"], "title": "Few-shot Hate Speech Detection Based on the MindSpore Framework", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "The proliferation of hate speech on social media poses a significant threat\nto online communities, requiring effective detection systems. While deep\nlearning models have shown promise, their performance often deteriorates in\nfew-shot or low-resource settings due to reliance on large annotated corpora.\nTo address this, we propose MS-FSLHate, a prompt-enhanced neural framework for\nfew-shot hate speech detection implemented on the MindSpore deep learning\nplatform. The model integrates learnable prompt embeddings, a CNN-BiLSTM\nbackbone with attention pooling, and synonym-based adversarial data\naugmentation to improve generalization. Experimental results on two benchmark\ndatasets-HateXplain and HSOL-demonstrate that our approach outperforms\ncompetitive baselines in precision, recall, and F1-score. Additionally, the\nframework shows high efficiency and scalability, suggesting its suitability for\ndeployment in resource-constrained environments. These findings highlight the\npotential of combining prompt-based learning with adversarial augmentation for\nrobust and adaptable hate speech detection in few-shot scenarios.", "AI": {"tldr": "MS-FSLHate, a prompt-enhanced neural framework, improves few-shot hate speech detection using learnable prompts, CNN-BiLSTM, and adversarial augmentation, outperforming baselines in precision, recall, and F1-score.", "motivation": "Hate speech detection systems struggle in few-shot or low-resource settings due to reliance on large annotated datasets.", "method": "Proposes MS-FSLHate with learnable prompt embeddings, CNN-BiLSTM backbone, attention pooling, and synonym-based adversarial augmentation.", "result": "Outperforms baselines on HateXplain and HSOL datasets in precision, recall, and F1-score, showing high efficiency and scalability.", "conclusion": "Combining prompt-based learning with adversarial augmentation enhances robustness in few-shot hate speech detection, suitable for resource-constrained environments."}}
{"id": "2504.15330", "pdf": "https://arxiv.org/pdf/2504.15330", "abs": "https://arxiv.org/abs/2504.15330", "authors": ["Mohit Gupta", "Akiko Aizawa", "Rajiv Ratn Shah"], "title": "Med-CoDE: Medical Critique based Disagreement Evaluation Framework", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "8 pages, 4 figures, NAACL SRW 2025", "summary": "The emergence of large language models (LLMs) has significantly influenced\nnumerous fields, including healthcare, by enhancing the capabilities of\nautomated systems to process and generate human-like text. However, despite\ntheir advancements, the reliability and accuracy of LLMs in medical contexts\nremain critical concerns. Current evaluation methods often lack robustness and\nfail to provide a comprehensive assessment of LLM performance, leading to\npotential risks in clinical settings. In this work, we propose Med-CoDE, a\nspecifically designed evaluation framework for medical LLMs to address these\nchallenges. The framework leverages a critique-based approach to quantitatively\nmeasure the degree of disagreement between model-generated responses and\nestablished medical ground truths. This framework captures both accuracy and\nreliability in medical settings. The proposed evaluation framework aims to fill\nthe existing gap in LLM assessment by offering a systematic method to evaluate\nthe quality and trustworthiness of medical LLMs. Through extensive experiments\nand case studies, we illustrate the practicality of our framework in providing\na comprehensive and reliable evaluation of medical LLMs.", "AI": {"tldr": "Proposes Med-CoDE, a critique-based evaluation framework for medical LLMs to assess accuracy and reliability in clinical settings.", "motivation": "Addresses the lack of robust evaluation methods for LLMs in medical contexts, ensuring reliability and accuracy.", "method": "Leverages a critique-based approach to measure disagreement between model outputs and medical ground truths.", "result": "Demonstrates practicality through experiments and case studies, offering a systematic evaluation method.", "conclusion": "Med-CoDE fills the gap in LLM assessment, providing a reliable framework for medical applications."}}
{"id": "2504.15616", "pdf": "https://arxiv.org/pdf/2504.15616", "abs": "https://arxiv.org/abs/2504.15616", "authors": ["Kai Chen", "Xiaodong Zhao", "Yujie Huang", "Guoyu Fang", "Xiao Song", "Ruiping Wang", "Ziyuan Wang"], "title": "SocialMOIF: Multi-Order Intention Fusion for Pedestrian Trajectory Prediction", "categories": ["cs.LG", "cs.CV"], "comment": "11 pages,6 figures", "summary": "The analysis and prediction of agent trajectories are crucial for\ndecision-making processes in intelligent systems, with precise short-term\ntrajectory forecasting being highly significant across a range of applications.\nAgents and their social interactions have been quantified and modeled by\nresearchers from various perspectives; however, substantial limitations exist\nin the current work due to the inherent high uncertainty of agent intentions\nand the complex higher-order influences among neighboring groups. SocialMOIF is\nproposed to tackle these challenges, concentrating on the higher-order\nintention interactions among neighboring groups while reinforcing the primary\nrole of first-order intention interactions between neighbors and the target\nagent. This method develops a multi-order intention fusion model to achieve a\nmore comprehensive understanding of both direct and indirect intention\ninformation. Within SocialMOIF, a trajectory distribution approximator is\ndesigned to guide the trajectories toward values that align more closely with\nthe actual data, thereby enhancing model interpretability. Furthermore, a\nglobal trajectory optimizer is introduced to enable more accurate and efficient\nparallel predictions. By incorporating a novel loss function that accounts for\ndistance and direction during training, experimental results demonstrate that\nthe model outperforms previous state-of-the-art baselines across multiple\nmetrics in both dynamic and static datasets.", "AI": {"tldr": "SocialMOIF improves trajectory prediction by modeling multi-order intention interactions and optimizing trajectories, outperforming existing methods.", "motivation": "Address limitations in current trajectory forecasting due to high uncertainty of agent intentions and complex higher-order social influences.", "method": "Proposes SocialMOIF, a multi-order intention fusion model with a trajectory distribution approximator and global trajectory optimizer, using a novel loss function.", "result": "Outperforms state-of-the-art baselines in dynamic and static datasets across multiple metrics.", "conclusion": "SocialMOIF effectively enhances trajectory prediction by integrating direct and indirect intention interactions and optimizing model interpretability and accuracy."}}
{"id": "2504.15723", "pdf": "https://arxiv.org/pdf/2504.15723", "abs": "https://arxiv.org/abs/2504.15723", "authors": ["Dasol Jeong", "Donggoo Kang", "Jiwon Park", "Hyebean Lee", "Joonki Paik"], "title": "Structure-Preserving Zero-Shot Image Editing via Stage-Wise Latent Injection in Diffusion Models", "categories": ["cs.CV"], "comment": null, "summary": "We propose a diffusion-based framework for zero-shot image editing that\nunifies text-guided and reference-guided approaches without requiring\nfine-tuning. Our method leverages diffusion inversion and timestep-specific\nnull-text embeddings to preserve the structural integrity of the source image.\nBy introducing a stage-wise latent injection strategy-shape injection in early\nsteps and attribute injection in later steps-we enable precise, fine-grained\nmodifications while maintaining global consistency. Cross-attention with\nreference latents facilitates semantic alignment between the source and\nreference. Extensive experiments across expression transfer, texture\ntransformation, and style infusion demonstrate state-of-the-art performance,\nconfirming the method's scalability and adaptability to diverse image editing\nscenarios.", "AI": {"tldr": "A diffusion-based framework for zero-shot image editing unifies text and reference-guided approaches without fine-tuning, using diffusion inversion and null-text embeddings for structural integrity.", "motivation": "To enable precise, fine-grained image editing while maintaining global consistency, unifying text and reference-guided methods without fine-tuning.", "method": "Leverages diffusion inversion and timestep-specific null-text embeddings, with a stage-wise latent injection strategy (shape early, attribute later) and cross-attention for semantic alignment.", "result": "Achieves state-of-the-art performance in expression transfer, texture transformation, and style infusion, demonstrating scalability and adaptability.", "conclusion": "The proposed framework is effective for diverse image editing scenarios, offering precise modifications and global consistency."}}
{"id": "2504.16005", "pdf": "https://arxiv.org/pdf/2504.16005", "abs": "https://arxiv.org/abs/2504.16005", "authors": ["Tom Zehle", "Moritz Schlager", "Timo Hei\u00df", "Matthias Feurer"], "title": "CAPO: Cost-Aware Prompt Optimization", "categories": ["cs.CL", "cs.AI", "cs.NE", "stat.ML"], "comment": "Submitted to AutoML 2025", "summary": "Large language models (LLMs) have revolutionized natural language processing\nby solving a wide range of tasks simply guided by a prompt. Yet their\nperformance is highly sensitive to prompt formulation. While automated prompt\noptimization addresses this challenge by finding optimal prompts, current\nmethods require a substantial number of LLM calls and input tokens, making\nprompt optimization expensive. We introduce CAPO (Cost-Aware Prompt\nOptimization), an algorithm that enhances prompt optimization efficiency by\nintegrating AutoML techniques. CAPO is an evolutionary approach with LLMs as\noperators, incorporating racing to save evaluations and multi-objective\noptimization to balance performance with prompt length. It jointly optimizes\ninstructions and few-shot examples while leveraging task descriptions for\nimproved robustness. Our extensive experiments across diverse datasets and LLMs\ndemonstrate that CAPO outperforms state-of-the-art discrete prompt optimization\nmethods in 11/15 cases with improvements up to 21%p. Our algorithm achieves\nbetter performances already with smaller budgets, saves evaluations through\nracing, and decreases average prompt length via a length penalty, making it\nboth cost-efficient and cost-aware. Even without few-shot examples, CAPO\noutperforms its competitors and generally remains robust to initial prompts.\nCAPO represents an important step toward making prompt optimization more\npowerful and accessible by improving cost-efficiency.", "AI": {"tldr": "CAPO is a cost-aware prompt optimization algorithm that improves efficiency by integrating AutoML techniques, outperforming existing methods with better performance and lower costs.", "motivation": "Current prompt optimization methods are expensive due to high LLM calls and input tokens, necessitating a more efficient solution.", "method": "CAPO uses an evolutionary approach with LLMs as operators, incorporating racing and multi-objective optimization to balance performance and prompt length.", "result": "CAPO outperforms state-of-the-art methods in 11/15 cases, achieving up to 21% improvement, with cost savings and robustness.", "conclusion": "CAPO advances prompt optimization by enhancing cost-efficiency and accessibility."}}
{"id": "2504.15417", "pdf": "https://arxiv.org/pdf/2504.15417", "abs": "https://arxiv.org/abs/2504.15417", "authors": ["Van-Giang Trinh", "Belaid Benhamou", "Sylvain Soliman", "Fran\u00e7ois Fages"], "title": "On the Boolean Network Theory of Datalog$^\\neg$", "categories": ["cs.LO", "cs.AI"], "comment": "48 pages, 7 figures", "summary": "Datalog$^\\neg$ is a central formalism used in a variety of domains ranging\nfrom deductive databases and abstract argumentation frameworks to answer set\nprogramming. Its model theory is the finite counterpart of the logical\nsemantics developed for normal logic programs, mainly based on the notions of\nClark's completion and two-valued or three-valued canonical models including\nsupported, stable, regular and well-founded models. In this paper we establish\na formal link between Datalog$^\\neg$ and Boolean network theory, which was\ninitially introduced by Stuart Kaufman and Ren\\'e Thomas to reason about gene\nregulatory networks. We use previous results from Boolean network theory to\nprove that in the absence of odd cycles in a Datalog$^\\neg$ program, the\nregular models coincide with the stable models, which entails the existence of\nstable models, and in the absence of even cycles, we show the uniqueness of\nstable partial models, which entails the uniqueness of regular models. These\nresults on regular models have been claimed by You and Yuan in 1994 for normal\nlogic programs but we show problems in their definition of well-founded\nstratification and in their proofs that we can fix for negative normal logic\nprograms only. We also give upper bounds on the numbers of stable partial,\nregular, and stable models of a Datalog$^\\neg$ program using the cardinality of\na feedback vertex set in its atom dependency graph. Interestingly, our\nconnection to Boolean network theory also points us to the notion of trap\nspaces for Datalog$^\\neg$ programs. We relate the notions of supported or\nstable trap spaces to the other semantics of Datalog$^\\neg$, and show the\nequivalence between subset-minimal stable trap spaces and regular models.", "AI": {"tldr": "The paper links Datalog$^\\neg$ with Boolean network theory, proving results about regular and stable models under certain cycle conditions, correcting prior claims, and introducing trap spaces as a new concept.", "motivation": "To bridge Datalog$^\\neg$ and Boolean network theory, addressing gaps in prior work on model semantics and providing new insights.", "method": "Uses Boolean network theory to analyze Datalog$^\\neg$ programs, focusing on cycle conditions and feedback vertex sets.", "result": "Proves regular and stable models coincide without odd cycles, and uniqueness of stable partial models without even cycles. Introduces trap spaces and their equivalence to regular models.", "conclusion": "The paper successfully connects Datalog$^\\neg$ to Boolean network theory, corrects prior errors, and introduces new concepts like trap spaces, enriching the understanding of Datalog$^\\neg$ semantics."}}
{"id": "2504.15623", "pdf": "https://arxiv.org/pdf/2504.15623", "abs": "https://arxiv.org/abs/2504.15623", "authors": ["Xiucheng Wang", "Qiming Zhang", "Nan Cheng", "Ruijin Sun", "Zan Li", "Shuguang Cui", "Xuemin Shen"], "title": "RadioDiff-$k^2$: Helmholtz Equation Informed Generative Diffusion Model for Multi-Path Aware Radio Map Construction", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "In this paper, we propose a novel physics-informed generative learning\napproach, termed RadioDiff-$\\bm{k^2}$, for accurate and efficient\nmultipath-aware radio map (RM) construction. As wireless communication evolves\ntowards environment-aware paradigms, driven by the increasing demand for\nintelligent and proactive optimization in sixth-generation (6G) networks,\naccurate construction of RMs becomes crucial yet highly challenging.\nConventional electromagnetic (EM)-based methods, such as full-wave solvers and\nray-tracing approaches, exhibit substantial computational overhead and limited\nadaptability to dynamic scenarios. Although, existing neural network (NN)\napproaches have efficient inferencing speed, they lack sufficient consideration\nof the underlying physics of EM wave propagation, limiting their effectiveness\nin accurately modeling critical EM singularities induced by complex multipath\nenvironments. To address these fundamental limitations, we propose a novel\nphysics-inspired RM construction method guided explicitly by the Helmholtz\nequation, which inherently governs EM wave propagation. Specifically, we\ntheoretically establish a direct correspondence between EM singularities, which\ncorrespond to the critical spatial features influencing wireless propagation,\nand regions defined by negative wave numbers in the Helmholtz equation. Based\non this insight, we design an innovative dual generative diffusion model (DM)\nframework comprising one DM dedicated to accurately inferring EM singularities\nand another DM responsible for reconstructing the complete RM using these\nsingularities along with environmental contextual information. Our\nphysics-informed approach uniquely combines the efficiency advantages of\ndata-driven methods with rigorous physics-based EM modeling, significantly\nenhancing RM accuracy, particularly in complex propagation environments\ndominated by multipath effects.", "AI": {"tldr": "Proposes RadioDiff-$k^2$, a physics-informed generative learning method for accurate multipath-aware radio map construction, combining data efficiency with EM wave physics.", "motivation": "Addresses the challenge of accurate radio map construction in 6G networks, where conventional methods are computationally heavy, and neural networks lack physics integration.", "method": "Uses a dual generative diffusion model framework guided by the Helmholtz equation to model EM singularities and reconstruct radio maps.", "result": "Enhances radio map accuracy in complex multipath environments by integrating physics with data-driven efficiency.", "conclusion": "The method successfully bridges the gap between physics-based modeling and computational efficiency for radio map construction."}}
{"id": "2504.15728", "pdf": "https://arxiv.org/pdf/2504.15728", "abs": "https://arxiv.org/abs/2504.15728", "authors": ["Manjunath D", "Aniruddh Sikdar", "Prajwal Gurunath", "Sumanth Udupa", "Suresh Sundaram"], "title": "SAGA: Semantic-Aware Gray color Augmentation for Visible-to-Thermal Domain Adaptation across Multi-View Drone and Ground-Based Vision Systems", "categories": ["cs.CV"], "comment": "Accepted at CVPR-W PBVS 2025", "summary": "Domain-adaptive thermal object detection plays a key role in facilitating\nvisible (RGB)-to-thermal (IR) adaptation by reducing the need for co-registered\nimage pairs and minimizing reliance on large annotated IR datasets. However,\ninherent limitations of IR images, such as the lack of color and texture cues,\npose challenges for RGB-trained models, leading to increased false positives\nand poor-quality pseudo-labels. To address this, we propose Semantic-Aware Gray\ncolor Augmentation (SAGA), a novel strategy for mitigating color bias and\nbridging the domain gap by extracting object-level features relevant to IR\nimages. Additionally, to validate the proposed SAGA for drone imagery, we\nintroduce the IndraEye, a multi-sensor (RGB-IR) dataset designed for diverse\napplications. The dataset contains 5,612 images with 145,666 instances,\ncaptured from diverse angles, altitudes, backgrounds, and times of day,\noffering valuable opportunities for multimodal learning, domain adaptation for\nobject detection and segmentation, and exploration of sensor-specific strengths\nand weaknesses. IndraEye aims to enhance the development of more robust and\naccurate aerial perception systems, especially in challenging environments.\nExperimental results show that SAGA significantly improves RGB-to-IR adaptation\nfor autonomous driving and IndraEye dataset, achieving consistent performance\ngains of +0.4% to +7.6% (mAP) when integrated with state-of-the-art domain\nadaptation techniques. The dataset and codes are available at\nhttps://github.com/airliisc/IndraEye.", "AI": {"tldr": "SAGA improves RGB-to-IR adaptation by addressing color bias and bridging domain gaps, validated on the IndraEye dataset.", "motivation": "To reduce reliance on co-registered RGB-IR pairs and large annotated IR datasets while overcoming IR image limitations like lack of color/texture cues.", "method": "Proposes Semantic-Aware Gray color Augmentation (SAGA) to mitigate color bias and extract object-level features for IR images. Introduces the IndraEye dataset for validation.", "result": "SAGA achieves performance gains of +0.4% to +7.6% (mAP) when integrated with domain adaptation techniques.", "conclusion": "SAGA and IndraEye enhance RGB-to-IR adaptation, supporting robust aerial perception in challenging environments."}}
{"id": "2504.16007", "pdf": "https://arxiv.org/pdf/2504.16007", "abs": "https://arxiv.org/abs/2504.16007", "authors": ["Igor Rozhkov", "Natalia Loukachevitch"], "title": "Methods for Recognizing Nested Terms", "categories": ["cs.CL"], "comment": "To be published in Computational Linguistics and Intellectual\n  Technologies proceedings", "summary": "In this paper, we describe our participation in the RuTermEval competition\ndevoted to extracting nested terms. We apply the Binder model, which was\npreviously successfully applied to the recognition of nested named entities, to\nextract nested terms. We obtained the best results of term recognition in all\nthree tracks of the RuTermEval competition. In addition, we study the new task\nof recognition of nested terms from flat training data annotated with terms\nwithout nestedness. We can conclude that several approaches we proposed in this\nwork are viable enough to retrieve nested terms effectively without nested\nlabeling of them.", "AI": {"tldr": "The paper describes the application of the Binder model for nested term extraction in the RuTermEval competition, achieving top results. It also explores nested term recognition from flat training data.", "motivation": "To adapt the Binder model, proven for nested named entities, for nested term extraction and evaluate its performance in the RuTermEval competition.", "method": "The Binder model is applied to extract nested terms. The study also investigates nested term recognition using flat training data without nested annotations.", "result": "Achieved the best term recognition results in all three tracks of the RuTermEval competition. Demonstrated viability of proposed approaches for nested term extraction without nested labeling.", "conclusion": "The Binder model and proposed methods are effective for nested term extraction, even without nested annotations in training data."}}
{"id": "2504.15424", "pdf": "https://arxiv.org/pdf/2504.15424", "abs": "https://arxiv.org/abs/2504.15424", "authors": ["Nishath Rajiv Ranasinghe", "Shawn M. Jones", "Michal Kucer", "Ayan Biswas", "Daniel O'Malley", "Alexander Buschmann Most", "Selma Liliane Wanna", "Ajay Sreekumar"], "title": "LLM-Assisted Translation of Legacy FORTRAN Codes to C++: A Cross-Platform Study", "categories": ["cs.SE", "cs.AI", "I.2.2; I.2.7; D.2.3; D.2.4"], "comment": "12 pages, 7 figures, 2 tables", "summary": "Large Language Models (LLMs) are increasingly being leveraged for generating\nand translating scientific computer codes by both domain-experts and non-domain\nexperts. Fortran has served as one of the go to programming languages in legacy\nhigh-performance computing (HPC) for scientific discoveries. Despite growing\nadoption, LLM-based code translation of legacy code-bases has not been\nthoroughly assessed or quantified for its usability. Here, we studied the\napplicability of LLM-based translation of Fortran to C++ as a step towards\nbuilding an agentic-workflow using open-weight LLMs on two different\ncomputational platforms. We statistically quantified the compilation accuracy\nof the translated C++ codes, measured the similarity of the LLM translated code\nto the human translated C++ code, and statistically quantified the output\nsimilarity of the Fortran to C++ translation.", "AI": {"tldr": "The paper evaluates LLM-based translation of Fortran to C++ for legacy HPC code, assessing compilation accuracy, code similarity, and output consistency.", "motivation": "To address the lack of thorough assessment of LLM-based translation for legacy HPC code, specifically Fortran to C++.", "method": "Studied LLM-based translation on two platforms, measuring compilation accuracy, code similarity to human translations, and output consistency.", "result": "Quantified compilation accuracy and output similarity, comparing LLM-translated C++ to human-translated versions.", "conclusion": "LLM-based translation shows promise but requires further validation for usability in legacy code modernization."}}
{"id": "2504.15634", "pdf": "https://arxiv.org/pdf/2504.15634", "abs": "https://arxiv.org/abs/2504.15634", "authors": ["Peizheng Liu", "Hitoshi Iba"], "title": "Enhancing Reinforcement learning in 3-Dimensional Hydrophobic-Polar Protein Folding Model with Attention-based layers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Transformer-based architectures have recently propelled advances in sequence\nmodeling across domains, but their application to the hydrophobic-hydrophilic\n(H-P) model for protein folding remains relatively unexplored. In this work, we\nadapt a Deep Q-Network (DQN) integrated with attention mechanisms\n(Transformers) to address the 3D H-P protein folding problem. Our system\nformulates folding decisions as a self-avoiding walk in a reinforced\nenvironment, and employs a specialized reward function based on favorable\nhydrophobic interactions. To improve performance, the method incorporates\nvalidity check including symmetry-breaking constraints, dueling and double\nQ-learning, and prioritized replay to focus learning on critical transitions.\nExperimental evaluations on standard benchmark sequences demonstrate that our\napproach achieves several known best solutions for shorter sequences, and\nobtains near-optimal results for longer chains. This study underscores the\npromise of attention-based reinforcement learning for protein folding, and\ncreated a prototype of Transformer-based Q-network structure for 3-dimensional\nlattice models.", "AI": {"tldr": "A Transformer-based Deep Q-Network (DQN) is adapted for the 3D H-P protein folding problem, achieving near-optimal results and demonstrating the potential of attention-based reinforcement learning in this domain.", "motivation": "The application of Transformer-based architectures to the hydrophobic-hydrophilic (H-P) model for protein folding is relatively unexplored, despite their success in sequence modeling.", "method": "The system uses a DQN with attention mechanisms, formulating folding as a self-avoiding walk with a specialized reward function. Techniques like validity checks, dueling and double Q-learning, and prioritized replay are employed.", "result": "The approach achieves known best solutions for shorter sequences and near-optimal results for longer chains.", "conclusion": "The study highlights the promise of attention-based reinforcement learning for protein folding and introduces a Transformer-based Q-network prototype for 3D lattice models."}}
{"id": "2504.15751", "pdf": "https://arxiv.org/pdf/2504.15751", "abs": "https://arxiv.org/abs/2504.15751", "authors": ["Menan Velayuthan", "Asiri Gawesha", "Purushoth Velayuthan", "Nuwan Kodagoda", "Dharshana Kasthurirathna", "Pradeepa Samarasinghe"], "title": "GADS: A Super Lightweight Model for Head Pose Estimation", "categories": ["cs.CV"], "comment": "16 pages, 5 tables, 10 figures, not submitted to any conference or\n  journal", "summary": "In human-computer interaction, head pose estimation profoundly influences\napplication functionality. Although utilizing facial landmarks is valuable for\nthis purpose, existing landmark-based methods prioritize precision over\nsimplicity and model size, limiting their deployment on edge devices and in\ncompute-poor environments. To bridge this gap, we propose \\textbf{Grouped\nAttention Deep Sets (GADS)}, a novel architecture based on the Deep Set\nframework. By grouping landmarks into regions and employing small Deep Set\nlayers, we reduce computational complexity. Our multihead attention mechanism\nextracts and combines inter-group information, resulting in a model that is\n$7.5\\times$ smaller and executes $25\\times$ faster than the current lightest\nstate-of-the-art model. Notably, our method achieves an impressive reduction,\nbeing $4321\\times$ smaller than the best-performing model. We introduce vanilla\nGADS and Hybrid-GADS (landmarks + RGB) and evaluate our models on three\nbenchmark datasets -- AFLW2000, BIWI, and 300W-LP. We envision our architecture\nas a robust baseline for resource-constrained head pose estimation methods.", "AI": {"tldr": "Proposes Grouped Attention Deep Sets (GADS), a lightweight and efficient architecture for head pose estimation, reducing model size and computation while maintaining performance.", "motivation": "Existing landmark-based methods for head pose estimation prioritize precision over simplicity and model size, limiting deployment on edge devices.", "method": "GADS groups landmarks into regions, uses small Deep Set layers, and employs a multihead attention mechanism to reduce complexity. Introduces vanilla GADS and Hybrid-GADS (landmarks + RGB).", "result": "GADS is 7.5\u00d7 smaller, 25\u00d7 faster than the lightest state-of-the-art model, and 4321\u00d7 smaller than the best-performing model. Evaluated on AFLW2000, BIWI, and 300W-LP datasets.", "conclusion": "GADS serves as a robust baseline for resource-constrained head pose estimation, balancing efficiency and performance."}}
{"id": "2504.16046", "pdf": "https://arxiv.org/pdf/2504.16046", "abs": "https://arxiv.org/abs/2504.16046", "authors": ["Jingyu Zhang", "Jiacan Yu", "Marc Marone", "Benjamin Van Durme", "Daniel Khashabi"], "title": "Certified Mitigation of Worst-Case LLM Copyright Infringement", "categories": ["cs.CL"], "comment": null, "summary": "The exposure of large language models (LLMs) to copyrighted material during\npre-training raises concerns about unintentional copyright infringement post\ndeployment. This has driven the development of \"copyright takedown\" methods,\npost-training approaches aimed at preventing models from generating content\nsubstantially similar to copyrighted ones. While current mitigation approaches\nare somewhat effective for average-case risks, we demonstrate that they\noverlook worst-case copyright risks exhibits by the existence of long, verbatim\nquotes from copyrighted sources. We propose BloomScrub, a remarkably simple yet\nhighly effective inference-time approach that provides certified copyright\ntakedown. Our method repeatedly interleaves quote detection with rewriting\ntechniques to transform potentially infringing segments. By leveraging\nefficient data sketches (Bloom filters), our approach enables scalable\ncopyright screening even for large-scale real-world corpora. When quotes beyond\na length threshold cannot be removed, the system can abstain from responding,\noffering certified risk reduction. Experimental results show that BloomScrub\nreduces infringement risk, preserves utility, and accommodates different levels\nof enforcement stringency with adaptive abstention. Our results suggest that\nlightweight, inference-time methods can be surprisingly effective for copyright\nprevention.", "AI": {"tldr": "BloomScrub is a simple, effective inference-time method for certified copyright takedown in LLMs, reducing infringement risk while preserving utility.", "motivation": "Addressing overlooked worst-case copyright risks in LLMs, such as verbatim quotes from copyrighted sources, despite existing mitigation methods.", "method": "BloomScrub interleaves quote detection with rewriting, using Bloom filters for scalable screening, and allows adaptive abstention for uncertifiable quotes.", "result": "BloomScrub effectively reduces infringement risk, maintains utility, and adapts to enforcement stringency.", "conclusion": "Lightweight, inference-time methods like BloomScrub can be highly effective for copyright prevention in LLMs."}}
{"id": "2504.15440", "pdf": "https://arxiv.org/pdf/2504.15440", "abs": "https://arxiv.org/abs/2504.15440", "authors": ["Andrey Fradkin"], "title": "Demand for LLMs: Descriptive Evidence on Substitution, Market Expansion, and Multihoming", "categories": ["cs.CY", "cs.AI", "econ.GN", "q-fin.EC", "K.4; I.2"], "comment": null, "summary": "This paper documents three stylized facts about the demand for Large Language\nModels (LLMs) using data from OpenRouter, a prominent LLM marketplace. First,\nnew models experience rapid initial adoption that stabilizes within weeks.\nSecond, model releases differ substantially in whether they primarily attract\nnew users or substitute demand from competing models. Third, multihoming, using\nmultiple models simultaneously, is common among apps. These findings suggest\nsignificant horizontal and vertical differentiation in the LLM market, implying\nopportunities for providers to maintain demand and pricing power despite rapid\ntechnological advances.", "AI": {"tldr": "The paper identifies three key trends in LLM demand: rapid initial adoption of new models, varying user attraction or substitution effects, and common multihoming among apps.", "motivation": "To understand demand dynamics in the LLM market and how providers can sustain demand and pricing power.", "method": "Analysis of data from OpenRouter, a prominent LLM marketplace.", "result": "New models see quick adoption, releases differ in attracting new users or substituting demand, and multihoming is prevalent.", "conclusion": "The LLM market shows significant differentiation, offering providers opportunities to maintain demand despite rapid tech advances."}}
{"id": "2504.15664", "pdf": "https://arxiv.org/pdf/2504.15664", "abs": "https://arxiv.org/abs/2504.15664", "authors": ["Phuong Quynh Le", "J\u00f6rg Schl\u00f6tterer", "Christin Seifert"], "title": "An XAI-based Analysis of Shortcut Learning in Neural Networks", "categories": ["cs.LG", "cs.CV"], "comment": "Accepted at The World Conference on eXplainable Artificial\n  Intelligence 2025 (XAI-2025)", "summary": "Machine learning models tend to learn spurious features - features that\nstrongly correlate with target labels but are not causal. Existing approaches\nto mitigate models' dependence on spurious features work in some cases, but\nfail in others. In this paper, we systematically analyze how and where neural\nnetworks encode spurious correlations. We introduce the neuron spurious score,\nan XAI-based diagnostic measure to quantify a neuron's dependence on spurious\nfeatures. We analyze both convolutional neural networks (CNNs) and vision\ntransformers (ViTs) using architecture-specific methods. Our results show that\nspurious features are partially disentangled, but the degree of disentanglement\nvaries across model architectures. Furthermore, we find that the assumptions\nbehind existing mitigation methods are incomplete. Our results lay the\ngroundwork for the development of novel methods to mitigate spurious\ncorrelations and make AI models safer to use in practice.", "AI": {"tldr": "The paper introduces a diagnostic measure (neuron spurious score) to analyze how neural networks encode spurious correlations, revealing partial disentanglement and incomplete assumptions in existing mitigation methods.", "motivation": "Machine learning models often rely on spurious features, which can lead to unreliable predictions. Existing mitigation methods are inconsistent, prompting a need for systematic analysis.", "method": "The authors propose the neuron spurious score, an XAI-based measure, and analyze CNNs and ViTs using architecture-specific methods.", "result": "Spurious features are partially disentangled, with varying degrees across architectures. Existing mitigation methods are based on incomplete assumptions.", "conclusion": "The findings pave the way for developing better methods to mitigate spurious correlations, enhancing AI model safety."}}
{"id": "2504.15770", "pdf": "https://arxiv.org/pdf/2504.15770", "abs": "https://arxiv.org/abs/2504.15770", "authors": ["Lei Xu", "Mehmet Yamac", "Mete Ahishali", "Moncef Gabbouj"], "title": "Multi-Scale Tensorial Summation and Dimensional Reduction Guided Neural Network for Edge Detection", "categories": ["cs.CV"], "comment": null, "summary": "Edge detection has attracted considerable attention thanks to its exceptional\nability to enhance performance in downstream computer vision tasks. In recent\nyears, various deep learning methods have been explored for edge detection\ntasks resulting in a significant performance improvement compared to\nconventional computer vision algorithms. In neural networks, edge detection\ntasks require considerably large receptive fields to provide satisfactory\nperformance. In a typical convolutional operation, such a large receptive field\ncan be achieved by utilizing a significant number of consecutive layers, which\nyields deep network structures. Recently, a Multi-scale Tensorial Summation\n(MTS) factorization operator was presented, which can achieve very large\nreceptive fields even from the initial layers. In this paper, we propose a\nnovel MTS Dimensional Reduction (MTS-DR) module guided neural network,\nMTS-DR-Net, for the edge detection task. The MTS-DR-Net uses MTS layers, and\ncorresponding MTS-DR blocks as a new backbone to remove redundant information\ninitially. Such a dimensional reduction module enables the neural network to\nfocus specifically on relevant information (i.e., necessary subspaces).\nFinally, a weight U-shaped refinement module follows MTS-DR blocks in the\nMTS-DR-Net. We conducted extensive experiments on two benchmark edge detection\ndatasets: BSDS500 and BIPEDv2 to verify the effectiveness of our model. The\nimplementation of the proposed MTS-DR-Net can be found at\nhttps://github.com/LeiXuAI/MTS-DR-Net.git.", "AI": {"tldr": "A novel MTS-DR-Net is proposed for edge detection, using MTS-DR modules to reduce redundancy and focus on relevant information, achieving large receptive fields early in the network.", "motivation": "Edge detection is crucial for computer vision tasks, and deep learning methods have improved performance. However, achieving large receptive fields typically requires deep networks, which the MTS-DR-Net addresses more efficiently.", "method": "The MTS-DR-Net employs MTS layers and MTS-DR blocks to reduce dimensionality and focus on relevant subspaces, followed by a U-shaped refinement module.", "result": "Extensive experiments on BSDS500 and BIPEDv2 datasets demonstrate the model's effectiveness.", "conclusion": "The MTS-DR-Net offers an efficient solution for edge detection by leveraging MTS-DR modules to achieve large receptive fields and improved performance."}}
{"id": "2504.16053", "pdf": "https://arxiv.org/pdf/2504.16053", "abs": "https://arxiv.org/abs/2504.16053", "authors": ["Zhifan Ye", "Kejing Xia", "Yonggan Fu", "Xin Dong", "Jihoon Hong", "Xiangchi Yuan", "Shizhe Diao", "Jan Kautz", "Pavlo Molchanov", "Yingyan Celine Lin"], "title": "LongMamba: Enhancing Mamba's Long Context Capabilities via Training-Free Receptive Field Enlargement", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ICLR 2025", "summary": "State space models (SSMs) have emerged as an efficient alternative to\nTransformer models for language modeling, offering linear computational\ncomplexity and constant memory usage as context length increases. However,\ndespite their efficiency in handling long contexts, recent studies have shown\nthat SSMs, such as Mamba models, generally underperform compared to\nTransformers in long-context understanding tasks. To address this significant\nshortfall and achieve both efficient and accurate long-context understanding,\nwe propose LongMamba, a training-free technique that significantly enhances the\nlong-context capabilities of Mamba models. LongMamba builds on our discovery\nthat the hidden channels in Mamba can be categorized into local and global\nchannels based on their receptive field lengths, with global channels primarily\nresponsible for long-context capability. These global channels can become the\nkey bottleneck as the input context lengthens. Specifically, when input lengths\nlargely exceed the training sequence length, global channels exhibit\nlimitations in adaptively extend their receptive fields, leading to Mamba's\npoor long-context performance. The key idea of LongMamba is to mitigate the\nhidden state memory decay in these global channels by preventing the\naccumulation of unimportant tokens in their memory. This is achieved by first\nidentifying critical tokens in the global channels and then applying token\nfiltering to accumulate only those critical tokens. Through extensive\nbenchmarking across synthetic and real-world long-context scenarios, LongMamba\nsets a new standard for Mamba's long-context performance, significantly\nextending its operational range without requiring additional training. Our code\nis available at https://github.com/GATECH-EIC/LongMamba.", "AI": {"tldr": "LongMamba enhances Mamba models' long-context understanding by filtering critical tokens in global channels, improving performance without additional training.", "motivation": "SSMs like Mamba underperform in long-context tasks compared to Transformers, despite their efficiency. LongMamba addresses this gap by optimizing global channels.", "method": "LongMamba identifies and filters critical tokens in global channels to prevent memory decay, improving long-context performance.", "result": "LongMamba significantly boosts Mamba models' long-context capabilities, outperforming previous methods without extra training.", "conclusion": "LongMamba sets a new standard for efficient and accurate long-context understanding in SSMs, extending Mamba's operational range."}}
{"id": "2504.15497", "pdf": "https://arxiv.org/pdf/2504.15497", "abs": "https://arxiv.org/abs/2504.15497", "authors": ["Noah Subedar", "Taeui Kim", "Saathwick Venkataramalingam"], "title": "Scalable APT Malware Classification via Parallel Feature Extraction and GPU-Accelerated Learning", "categories": ["cs.CR", "cs.AI", "I.2.0; I.2.6; K.6.5"], "comment": "26 pages, 54 figures, 14 tables", "summary": "This paper presents an underlying framework for both automating and\naccelerating malware classification, more specifically, mapping malicious\nexecutables to known Advanced Persistent Threat (APT) groups. The main feature\nof this analysis is the assembly-level instructions present in executables\nwhich are also known as opcodes. The collection of such opcodes on many\nmalicious samples is a lengthy process; hence, open-source reverse engineering\ntools are used in tandem with scripts that leverage parallel computing to\nanalyze multiple files at once. Traditional and deep learning models are\napplied to create models capable of classifying malware samples. One-gram and\ntwo-gram datasets are constructed and used to train models such as SVM, KNN,\nand Decision Tree; however, they struggle to provide adequate results without\nrelying on metadata to support n-gram sequences. The computational limitations\nof such models are overcome with convolutional neural networks (CNNs) and\nheavily accelerated using graphical compute unit (GPU) resources.", "AI": {"tldr": "A framework for automating malware classification by analyzing assembly-level opcodes, using parallel computing and deep learning models like CNNs for better results.", "motivation": "To automate and accelerate malware classification, especially mapping malicious executables to known APT groups, addressing the limitations of traditional methods.", "method": "Uses open-source reverse engineering tools and parallel computing to analyze opcodes, constructs one-gram and two-gram datasets, and applies traditional (SVM, KNN, Decision Tree) and deep learning (CNNs) models.", "result": "Traditional models struggle without metadata, while CNNs overcome computational limitations and perform better with GPU acceleration.", "conclusion": "CNNs with GPU resources provide an effective solution for malware classification, outperforming traditional methods."}}
{"id": "2504.15686", "pdf": "https://arxiv.org/pdf/2504.15686", "abs": "https://arxiv.org/abs/2504.15686", "authors": ["Phuong Quynh Le", "Christin Seifert", "J\u00f6rg Schl\u00f6tterer"], "title": "Invariant Learning with Annotation-free Environments", "categories": ["cs.LG"], "comment": "Accepted at NeurIPS 2024 Workshop UniReps", "summary": "Invariant learning is a promising approach to improve domain generalization\ncompared to Empirical Risk Minimization (ERM). However, most invariant learning\nmethods rely on the assumption that training examples are pre-partitioned into\ndifferent known environments. We instead infer environments without the need\nfor additional annotations, motivated by observations of the properties within\nthe representation space of a trained ERM model. We show the preliminary\neffectiveness of our approach on the ColoredMNIST benchmark, achieving\nperformance comparable to methods requiring explicit environment labels and on\npar with an annotation-free method that poses strong restrictions on the ERM\nreference model.", "AI": {"tldr": "The paper proposes an annotation-free method for invariant learning by inferring environments from the representation space of an ERM model, showing effectiveness on ColoredMNIST.", "motivation": "To improve domain generalization without relying on pre-partitioned environments or additional annotations.", "method": "Infer environments from the representation space of a trained ERM model.", "result": "Achieves performance comparable to methods requiring explicit environment labels and matches an annotation-free method with strong restrictions.", "conclusion": "The approach is effective for invariant learning without environment annotations."}}
{"id": "2504.15776", "pdf": "https://arxiv.org/pdf/2504.15776", "abs": "https://arxiv.org/abs/2504.15776", "authors": ["Quentin Herau", "Nathan Piasco", "Moussab Bennehar", "Luis Rolado", "Dzmitry Tsishkou", "Bingbing Liu", "Cyrille Migniot", "Pascal Vasseur", "C\u00e9dric Demonceaux"], "title": "Pose Optimization for Autonomous Driving Datasets using Neural Rendering Models", "categories": ["cs.CV", "cs.RO"], "comment": "under review", "summary": "Autonomous driving systems rely on accurate perception and localization of\nthe ego car to ensure safety and reliability in challenging real-world driving\nscenarios. Public datasets play a vital role in benchmarking and guiding\nadvancement in research by providing standardized resources for model\ndevelopment and evaluation. However, potential inaccuracies in sensor\ncalibration and vehicle poses within these datasets can lead to erroneous\nevaluations of downstream tasks, adversely impacting the reliability and\nperformance of the autonomous systems. To address this challenge, we propose a\nrobust optimization method based on Neural Radiance Fields (NeRF) to refine\nsensor poses and calibration parameters, enhancing the integrity of dataset\nbenchmarks. To validate improvement in accuracy of our optimized poses without\nground truth, we present a thorough evaluation process, relying on reprojection\nmetrics, Novel View Synthesis rendering quality, and geometric alignment. We\ndemonstrate that our method achieves significant improvements in sensor pose\naccuracy. By optimizing these critical parameters, our approach not only\nimproves the utility of existing datasets but also paves the way for more\nreliable autonomous driving models. To foster continued progress in this field,\nwe make the optimized sensor poses publicly available, providing a valuable\nresource for the research community.", "AI": {"tldr": "A robust optimization method using Neural Radiance Fields (NeRF) refines sensor poses and calibration in autonomous driving datasets, improving accuracy and reliability.", "motivation": "Inaccuracies in sensor calibration and vehicle poses in public datasets can lead to erroneous evaluations, impacting autonomous driving systems.", "method": "Proposes a NeRF-based optimization method to refine sensor poses and calibration, evaluated via reprojection metrics, Novel View Synthesis, and geometric alignment.", "result": "Significant improvements in sensor pose accuracy, enhancing dataset integrity and autonomous driving model reliability.", "conclusion": "The method improves dataset benchmarks and provides publicly available optimized poses to advance autonomous driving research."}}
{"id": "2504.16056", "pdf": "https://arxiv.org/pdf/2504.16056", "abs": "https://arxiv.org/abs/2504.16056", "authors": ["Daniel Hendriks", "Philipp Spitzer", "Niklas K\u00fchl", "Gerhard Satzger"], "title": "Honey, I Shrunk the Language Model: Impact of Knowledge Distillation Methods on Performance and Explainability", "categories": ["cs.CL"], "comment": null, "summary": "Artificial Intelligence (AI) has increasingly influenced modern society,\nrecently in particular through significant advancements in Large Language\nModels (LLMs). However, high computational and storage demands of LLMs still\nlimit their deployment in resource-constrained environments. Knowledge\ndistillation addresses this challenge by training a small student model from a\nlarger teacher model. Previous research has introduced several distillation\nmethods for both generating training data and for training the student model.\nDespite their relevance, the effects of state-of-the-art distillation methods\non model performance and explainability have not been thoroughly investigated\nand compared. In this work, we enlarge the set of available methods by applying\ncritique-revision prompting to distillation for data generation and by\nsynthesizing existing methods for training. For these methods, we provide a\nsystematic comparison based on the widely used Commonsense Question-Answering\n(CQA) dataset. While we measure performance via student model accuracy, we\nemploy a human-grounded study to evaluate explainability. We contribute new\ndistillation methods and their comparison in terms of both performance and\nexplainability. This should further advance the distillation of small language\nmodels and, thus, contribute to broader applicability and faster diffusion of\nLLM technology.", "AI": {"tldr": "The paper introduces new knowledge distillation methods for LLMs, comparing their performance and explainability on the CQA dataset.", "motivation": "High computational demands of LLMs limit deployment in resource-constrained environments, necessitating efficient distillation methods.", "method": "Applies critique-revision prompting for data generation and synthesizes existing methods for training, evaluated on the CQA dataset.", "result": "Provides a systematic comparison of distillation methods, measuring accuracy and explainability via human-grounded study.", "conclusion": "New distillation methods and their comparison advance the field, enhancing LLM applicability and diffusion."}}
{"id": "2504.15499", "pdf": "https://arxiv.org/pdf/2504.15499", "abs": "https://arxiv.org/abs/2504.15499", "authors": ["James Mickens", "Sarah Radway", "Ravi Netravali"], "title": "Guillotine: Hypervisors for Isolating Malicious AIs", "categories": ["cs.CR", "cs.AI", "cs.OS"], "comment": "To be published in the ACM SIGOPS 2025 Workshop on Hot Topics in\n  Operating Systems", "summary": "As AI models become more embedded in critical sectors like finance,\nhealthcare, and the military, their inscrutable behavior poses ever-greater\nrisks to society. To mitigate this risk, we propose Guillotine, a hypervisor\narchitecture for sandboxing powerful AI models -- models that, by accident or\nmalice, can generate existential threats to humanity. Although Guillotine\nborrows some well-known virtualization techniques, Guillotine must also\nintroduce fundamentally new isolation mechanisms to handle the unique threat\nmodel posed by existential-risk AIs. For example, a rogue AI may try to\nintrospect upon hypervisor software or the underlying hardware substrate to\nenable later subversion of that control plane; thus, a Guillotine hypervisor\nrequires careful co-design of the hypervisor software and the CPUs, RAM, NIC,\nand storage devices that support the hypervisor software, to thwart side\nchannel leakage and more generally eliminate mechanisms for AI to exploit\nreflection-based vulnerabilities. Beyond such isolation at the software,\nnetwork, and microarchitectural layers, a Guillotine hypervisor must also\nprovide physical fail-safes more commonly associated with nuclear power plants,\navionic platforms, and other types of mission critical systems. Physical\nfail-safes, e.g., involving electromechanical disconnection of network cables,\nor the flooding of a datacenter which holds a rogue AI, provide defense in\ndepth if software, network, and microarchitectural isolation is compromised and\na rogue AI must be temporarily shut down or permanently destroyed.", "AI": {"tldr": "Guillotine is a hypervisor architecture designed to sandbox powerful AI models, addressing existential risks by combining virtualization, isolation mechanisms, and physical fail-safes.", "motivation": "The increasing integration of AI in critical sectors raises risks from inscrutable or malicious behavior, necessitating robust containment solutions.", "method": "Guillotine uses virtualization, co-designed hardware/software isolation, and physical fail-safes (e.g., network disconnection, datacenter flooding) to prevent AI subversion.", "result": "The architecture aims to mitigate existential threats by preventing AI exploitation of vulnerabilities and enabling emergency shutdowns.", "conclusion": "Guillotine provides a multi-layered defense against rogue AI, combining technical and physical safeguards for critical scenarios."}}
{"id": "2504.15736", "pdf": "https://arxiv.org/pdf/2504.15736", "abs": "https://arxiv.org/abs/2504.15736", "authors": ["Jiawen Wu", "Bingguang Chen", "Yuyi Zhou", "Qi Meng", "Rongchan Zhu", "Zhi-Ming Ma"], "title": "Riemannian Neural Geodesic Interpolant", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Stochastic interpolants are efficient generative models that bridge two\narbitrary probability density functions in finite time, enabling flexible\ngeneration from the source to the target distribution or vice versa. These\nmodels are primarily developed in Euclidean space, and are therefore limited in\ntheir application to many distribution learning problems defined on Riemannian\nmanifolds in real-world scenarios. In this work, we introduce the Riemannian\nNeural Geodesic Interpolant (RNGI) model, which interpolates between two\nprobability densities on a Riemannian manifold along the stochastic geodesics,\nand then samples from one endpoint as the final state using the continuous flow\noriginating from the other endpoint. We prove that the temporal marginal\ndensity of RNGI solves a transport equation on the Riemannian manifold. After\ntraining the model's the neural velocity and score fields, we propose the\nEmbedding Stochastic Differential Equation (E-SDE) algorithm for stochastic\nsampling of RNGI. E-SDE significantly improves the sampling quality by reducing\nthe accumulated error caused by the excessive intrinsic discretization of\nRiemannian Brownian motion in the classical Geodesic Random Walk (GRW)\nalgorithm. We also provide theoretical bounds on the generative bias measured\nin terms of KL-divergence. Finally, we demonstrate the effectiveness of the\nproposed RNGI and E-SDE through experiments conducted on both collected and\nsynthetic distributions on S2 and SO(3).", "AI": {"tldr": "The paper introduces the Riemannian Neural Geodesic Interpolant (RNGI) model for interpolating between probability densities on Riemannian manifolds, along with the E-SDE algorithm for improved stochastic sampling.", "motivation": "Existing stochastic interpolants are limited to Euclidean spaces, restricting their application to real-world problems involving Riemannian manifolds.", "method": "The RNGI model interpolates between densities on a Riemannian manifold using stochastic geodesics, and the E-SDE algorithm reduces sampling errors compared to classical methods.", "result": "Theoretical bounds on generative bias are provided, and experiments on S2 and SO(3) manifolds demonstrate the model's effectiveness.", "conclusion": "RNGI and E-SDE offer a robust solution for generative modeling on Riemannian manifolds, outperforming traditional methods."}}
{"id": "2504.15782", "pdf": "https://arxiv.org/pdf/2504.15782", "abs": "https://arxiv.org/abs/2504.15782", "authors": ["Daniele Baieri", "Riccardo Cicciarella", "Michael Kr\u00fctzen", "Emanuele Rodol\u00e0", "Silvia Zuffi"], "title": "Model-based Metric 3D Shape and Motion Reconstruction of Wild Bottlenose Dolphins in Drone-Shot Videos", "categories": ["cs.CV", "cs.GR", "I.4.8; J.3"], "comment": "9 pages, 7 figures", "summary": "We address the problem of estimating the metric 3D shape and motion of wild\ndolphins from monocular video, with the aim of assessing their body condition.\nWhile considerable progress has been made in reconstructing 3D models of\nterrestrial quadrupeds, aquatic animals remain unexplored due to the difficulty\nof observing them in their natural underwater environment. To address this, we\npropose a model-based approach that incorporates a transmission model to\naccount for water-induced occlusion. We apply our method to video captured\nunder different sea conditions. We estimate mass and volume, and compare our\nresults to a manual 2D measurements-based method.", "AI": {"tldr": "Estimating 3D shape and motion of wild dolphins from monocular video to assess body condition, addressing challenges of underwater observation.", "motivation": "Aquatic animals like dolphins are hard to observe underwater, unlike terrestrial quadrupeds, making 3D reconstruction challenging.", "method": "Proposes a model-based approach with a transmission model for water-induced occlusion, tested on videos under varying sea conditions.", "result": "Estimates mass and volume, comparing results with manual 2D measurements.", "conclusion": "Demonstrates feasibility of 3D reconstruction for aquatic animals, offering a new tool for body condition assessment."}}
{"id": "2504.16060", "pdf": "https://arxiv.org/pdf/2504.16060", "abs": "https://arxiv.org/abs/2504.16060", "authors": ["Ziqiao Ma", "Jing Ding", "Xuejun Zhang", "Dezhi Luo", "Jiahe Ding", "Sihan Xu", "Yuchen Huang", "Run Peng", "Joyce Chai"], "title": "Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation", "categories": ["cs.CL"], "comment": "Homepage: https://vlm-reg.github.io/", "summary": "Referring Expression Generation (REG) is a core task for evaluating the\npragmatic competence of vision-language systems, requiring not only accurate\nsemantic grounding but also adherence to principles of cooperative\ncommunication (Grice, 1975). However, current evaluations of vision-language\nmodels (VLMs) often overlook the pragmatic dimension, reducing REG to a\nregion-based captioning task and neglecting Gricean maxims. In this work, we\nrevisit REG from a pragmatic perspective, introducing a new dataset (RefOI) of\n1.5k images annotated with both written and spoken referring expressions.\nThrough a systematic evaluation of state-of-the-art VLMs, we identify three key\nfailures of pragmatic competence: (1) failure to uniquely identify the\nreferent, (2) inclusion of excessive or irrelevant information, and (3)\nmisalignment with human pragmatic preference, such as the underuse of minimal\nspatial cues. We also show that standard automatic evaluations fail to capture\nthese pragmatic violations, reinforcing superficial cues rather than genuine\nreferential success. Our findings call for a renewed focus on pragmatically\ninformed models and evaluation frameworks that align with real human\ncommunication.", "AI": {"tldr": "The paper critiques current vision-language models (VLMs) for neglecting pragmatic aspects in Referring Expression Generation (REG), introduces a new dataset (RefOI), and highlights key pragmatic failures in VLMs.", "motivation": "Current evaluations of VLMs often ignore pragmatic competence, reducing REG to a simplistic task and overlooking Gricean maxims. The study aims to address this gap.", "method": "The authors introduce RefOI, a dataset of 1.5k images annotated with referring expressions, and systematically evaluate state-of-the-art VLMs for pragmatic competence.", "result": "Key pragmatic failures identified include inability to uniquely identify referents, excessive information, and misalignment with human preferences. Standard evaluations fail to detect these issues.", "conclusion": "The study advocates for pragmatically informed models and evaluation frameworks to better align with human communication."}}
{"id": "2504.15515", "pdf": "https://arxiv.org/pdf/2504.15515", "abs": "https://arxiv.org/abs/2504.15515", "authors": ["Wuchen Li"], "title": "Transport f divergences", "categories": ["math.ST", "cs.AI", "cs.IT", "math.IT", "stat.TH"], "comment": "Comments are welcome", "summary": "We define a class of divergences to measure differences between probability\ndensity functions in one-dimensional sample space. The construction is based on\nthe convex function with the Jacobi operator of mapping function that\npushforwards one density to the other. We call these information measures {\\em\ntransport $f$-divergences}. We present several properties of transport\n$f$-divergences, including invariances, convexities, variational formulations,\nand Taylor expansions in terms of mapping functions. Examples of transport\n$f$-divergences in generative models are provided.", "AI": {"tldr": "The paper introduces transport $f$-divergences, a class of divergences for measuring differences between probability density functions, leveraging convex functions and Jacobi operators.", "motivation": "To develop a robust framework for quantifying differences between probability densities, particularly useful in generative models.", "method": "Constructs divergences using convex functions and Jacobi operators of mapping functions that pushforward one density to another.", "result": "Presents properties like invariances, convexities, variational formulations, and Taylor expansions, with examples in generative models.", "conclusion": "Transport $f$-divergences offer a versatile tool for comparing probability densities, with applications in generative modeling."}}
{"id": "2504.15758", "pdf": "https://arxiv.org/pdf/2504.15758", "abs": "https://arxiv.org/abs/2504.15758", "authors": ["Andrew Gracyk"], "title": "Observability conditions for neural state-space models with eigenvalues and their roots of unity", "categories": ["cs.LG", "cs.SY", "eess.SY", "math.DS", "math.OC"], "comment": "First version", "summary": "We operate through the lens of ordinary differential equations and control\ntheory to study the concept of observability in the context of neural\nstate-space models and the Mamba architecture. We develop strategies to enforce\nobservability, which are tailored to a learning context, specifically where the\nhidden states are learnable at initial time, in conjunction to over its\ncontinuum, and high-dimensional. We also highlight our methods emphasize\neigenvalues, roots of unity, or both. Our methods effectuate computational\nefficiency when enforcing observability, sometimes at great scale. We formulate\nobservability conditions in machine learning based on classical control theory\nand discuss their computational complexity. Our nontrivial results are\nfivefold. We discuss observability through the use of permutations in neural\napplications with learnable matrices without high precision. We present two\nresults built upon the Fourier transform that effect observability with high\nprobability up to the randomness in the learning. These results are worked with\nthe interplay of representations in Fourier space and their eigenstructure,\nnonlinear mappings, and the observability matrix. We present a result for Mamba\nthat is similar to a Hautus-type condition, but instead employs an argument\nusing a Vandermonde matrix instead of eigenvectors. Our final result is a\nshared-parameter construction of the Mamba system, which is computationally\nefficient in high exponentiation. We develop a training algorithm with this\ncoupling, showing it satisfies a Robbins-Monro condition under certain\northogonality, while a more classical training procedure fails to satisfy a\ncontraction with high Lipschitz constant.", "AI": {"tldr": "The paper explores observability in neural state-space models and Mamba architecture using ODEs and control theory, proposing efficient methods to enforce observability with computational efficiency.", "motivation": "To address the challenge of enforcing observability in high-dimensional, learnable neural state-space models, leveraging control theory and computational strategies.", "method": "Develops observability-enforcing strategies using eigenvalues, roots of unity, and permutations, with a focus on Fourier transforms and Vandermonde matrices. Also introduces a shared-parameter Mamba system for efficiency.", "result": "Presents five key results, including observability via permutations, Fourier-based methods, a Hautus-type condition for Mamba, and a computationally efficient shared-parameter construction.", "conclusion": "The methods achieve computational efficiency and enforce observability effectively, with a training algorithm satisfying Robbins-Monro conditions under orthogonality."}}
{"id": "2504.15783", "pdf": "https://arxiv.org/pdf/2504.15783", "abs": "https://arxiv.org/abs/2504.15783", "authors": ["Johan \u00d6fverstedt", "Elin Lundstr\u00f6m", "H\u00e5kan Ahlstr\u00f6m", "Joel Kullberg"], "title": "Towards prediction of morphological heart age from computed tomography angiography", "categories": ["cs.CV"], "comment": "24 pages", "summary": "Age prediction from medical images or other health-related non-imaging data\nis an important approach to data-driven aging research, providing knowledge of\nhow much information a specific tissue or organ carries about the chronological\nage of the individual. In this work, we studied the prediction of age from\ncomputed tomography angiography (CTA) images, which provide detailed\nrepresentations of the heart morphology, with the goals of (i) studying the\nrelationship between morphology and aging, and (ii) developing a novel\n\\emph{morphological heart age} biomarker. We applied an image\nregistration-based method that standardizes the images from the whole cohort\ninto a single space. We then extracted supervoxels (using unsupervised\nsegmentation), and corresponding robust features of density and local volume,\nwhich provide a detailed representation of the heart morphology while being\nrobust to registration errors. Machine learning models are then trained to fit\nregression models from these features to the chronological age. We applied the\nmethod to a subset of the images from the Swedish CArdioPulomonary bioImage\nStudy (SCAPIS) dataset, consisting of 721 females and 666 males. We observe a\nmean absolute error of $2.74$ years for females and $2.77$ years for males. The\npredictions from different sub-regions of interest were observed to be more\nhighly correlated with the predictions from the whole heart, compared to the\nchronological age, revealing a high consistency in the predictions from\nmorphology. Saliency analysis was also performed on the prediction models to\nstudy what regions are associated positively and negatively with the predicted\nage. This resulted in detailed association maps where the density and volume of\nknown, as well as some novel sub-regions of interest, are determined to be\nimportant. The saliency analysis aids in the interpretability of the models and\ntheir predictions.", "AI": {"tldr": "The paper presents a method to predict age from CTA images by analyzing heart morphology, achieving low prediction errors and identifying key regions linked to aging.", "motivation": "To study the relationship between heart morphology and aging, and to develop a novel biomarker for morphological heart age.", "method": "Image registration-based standardization, unsupervised segmentation for supervoxels, extraction of robust features (density and local volume), and machine learning regression models.", "result": "Mean absolute errors of 2.74 years (females) and 2.77 years (males); high consistency in predictions from morphology; detailed saliency maps identifying important sub-regions.", "conclusion": "The method effectively predicts age from heart morphology, with interpretable results highlighting key regions associated with aging."}}
{"id": "2504.16063", "pdf": "https://arxiv.org/pdf/2504.16063", "abs": "https://arxiv.org/abs/2504.16063", "authors": ["A. Fronzetti Colladon", "R. Vestrelli"], "title": "A Python Tool for Reconstructing Full News Text from GDELT", "categories": ["cs.CL", "cs.DB", "cs.IR", "I.2.7; H.2.8; H.3.1"], "comment": null, "summary": "News data have become an essential resource across various disciplines,\nincluding economics, finance, management, social sciences, and computer\nscience. Researchers leverage newspaper articles to study economic trends,\nmarket dynamics, corporate strategies, public perception, political discourse,\nand the evolution of public opinion. Additionally, news datasets have been\ninstrumental in training large-scale language models, with applications in\nsentiment analysis, fake news detection, and automated news summarization.\nDespite their significance, access to comprehensive news corpora remains a key\nchallenge. Many full-text news providers, such as Factiva and LexisNexis,\nrequire costly subscriptions, while free alternatives often suffer from\nincomplete data and transparency issues. This paper presents a novel approach\nto obtaining full-text newspaper articles at near-zero cost by leveraging data\nfrom the Global Database of Events, Language, and Tone (GDELT). Specifically,\nwe focus on the GDELT Web News NGrams 3.0 dataset, which provides\nhigh-frequency updates of n-grams extracted from global online news sources. We\nprovide Python code to reconstruct full-text articles from these n-grams by\nidentifying overlapping textual fragments and intelligently merging them. Our\nmethod enables researchers to access structured, large-scale newspaper data for\ntext analysis while overcoming the limitations of existing proprietary\ndatasets. The proposed approach enhances the accessibility of news data for\nempirical research, facilitating applications in economic forecasting,\ncomputational social science, and natural language processing.", "AI": {"tldr": "A novel method to reconstruct full-text news articles from GDELT's n-grams at minimal cost, addressing accessibility issues in news datasets.", "motivation": "News data is vital for research but often costly or incomplete. This paper aims to provide a low-cost solution using GDELT.", "method": "Uses Python to reconstruct full-text articles from GDELT Web News NGrams 3.0 by merging overlapping n-grams.", "result": "Enables access to large-scale, structured news data for research, overcoming proprietary dataset limitations.", "conclusion": "The approach improves news data accessibility, benefiting fields like economics, social science, and NLP."}}
{"id": "2504.15546", "pdf": "https://arxiv.org/pdf/2504.15546", "abs": "https://arxiv.org/abs/2504.15546", "authors": ["Jayachandu Bandlamudi", "Ritwik Chaudhuri", "Neelamadhav Gantayat", "Kushal Mukherjee", "Prerna Agarwal", "Renuka Sindhgatta", "Sameep Mehta"], "title": "A Framework for Testing and Adapting REST APIs as LLM Tools", "categories": ["cs.SE", "cs.AI", "I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) are enabling autonomous agents to perform\ncomplex workflows using external tools or functions, often provided via REST\nAPIs in enterprise systems. However, directly utilizing these APIs as tools\nposes challenges due to their complex input schemas, elaborate responses, and\noften ambiguous documentation. Current benchmarks for tool testing do not\nadequately address these complexities, leading to a critical gap in evaluating\nAPI readiness for agent-driven automation. In this work, we present a novel\ntesting framework aimed at evaluating and enhancing the readiness of REST APIs\nto function as tools for LLM-based agents. Our framework transforms apis as\ntools, generates comprehensive test cases for the APIs, translates tests cases\ninto natural language instructions suitable for agents, enriches tool\ndefinitions and evaluates the agent's ability t correctly invoke the API and\nprocess its inputs and responses. To provide actionable insights, we analyze\nthe outcomes of 750 test cases, presenting a detailed taxonomy of errors,\nincluding input misinterpretation, output handling inconsistencies, and schema\nmismatches. Additionally, we classify these test cases to streamline debugging\nand refinement of tool integrations. This work offers a foundational step\ntoward enabling enterprise APIs as tools, improving their usability in\nagent-based applications.", "AI": {"tldr": "A novel testing framework evaluates REST API readiness for LLM-based agents, addressing input/output complexities and improving usability.", "motivation": "Current benchmarks fail to address API complexities for agent-driven automation, creating a gap in evaluating API readiness.", "method": "The framework transforms APIs into tools, generates test cases, translates them into natural language, and evaluates agent performance.", "result": "Analysis of 750 test cases reveals error taxonomies like input misinterpretation and schema mismatches, aiding debugging.", "conclusion": "The work enhances REST API usability for LLM-based agents, providing actionable insights for enterprise applications."}}
{"id": "2504.15771", "pdf": "https://arxiv.org/pdf/2504.15771", "abs": "https://arxiv.org/abs/2504.15771", "authors": ["Assaf Gerner", "Netta Madvil", "Nadav Barak", "Alex Zaikman", "Jonatan Liberman", "Liron Hamra", "Rotem Brazilay", "Shay Tsadok", "Yaron Friedman", "Neal Harow", "Noam Bresler", "Shir Chorev", "Philip Tannor"], "title": "Grounded in Context: Retrieval-Based Method for Hallucination Detection", "categories": ["cs.LG"], "comment": null, "summary": "Despite advancements in grounded content generation, production Large\nLanguage Models (LLMs) based applications still suffer from hallucinated\nanswers. We present \"Grounded in Context\" - Deepchecks' hallucination detection\nframework, designed for production-scale long-context data and tailored to\ndiverse use cases, including summarization, data extraction, and RAG. Inspired\nby RAG architecture, our method integrates retrieval and Natural Language\nInference (NLI) models to predict factual consistency between premises and\nhypotheses using an encoder-based model with only a 512-token context window.\nOur framework identifies unsupported claims with an F1 score of 0.83 in\nRAGTruth's response-level classification task, matching methods that trained on\nthe dataset, and outperforming all comparable frameworks using similar-sized\nmodels.", "AI": {"tldr": "Deepchecks' \"Grounded in Context\" framework detects hallucinated answers in LLMs using retrieval and NLI models, achieving high accuracy.", "motivation": "Address hallucinated answers in production LLMs despite advancements in grounded content generation.", "method": "Integrates retrieval and NLI models with a 512-token context window to predict factual consistency.", "result": "Achieves an F1 score of 0.83 in RAGTruth's task, matching trained methods and outperforming similar-sized models.", "conclusion": "The framework effectively detects unsupported claims in diverse use cases like summarization and RAG."}}
{"id": "2504.15786", "pdf": "https://arxiv.org/pdf/2504.15786", "abs": "https://arxiv.org/abs/2504.15786", "authors": ["Ningli Xu", "Rongjun Qin"], "title": "Satellite to GroundScape -- Large-scale Consistent Ground View Generation from Satellite Views", "categories": ["cs.CV"], "comment": "8 figures", "summary": "Generating consistent ground-view images from satellite imagery is\nchallenging, primarily due to the large discrepancies in viewing angles and\nresolution between satellite and ground-level domains. Previous efforts mainly\nconcentrated on single-view generation, often resulting in inconsistencies\nacross neighboring ground views. In this work, we propose a novel cross-view\nsynthesis approach designed to overcome these challenges by ensuring\nconsistency across ground-view images generated from satellite views. Our\nmethod, based on a fixed latent diffusion model, introduces two conditioning\nmodules: satellite-guided denoising, which extracts high-level scene layout to\nguide the denoising process, and satellite-temporal denoising, which captures\ncamera motion to maintain consistency across multiple generated views. We\nfurther contribute a large-scale satellite-ground dataset containing over\n100,000 perspective pairs to facilitate extensive ground scene or video\ngeneration. Experimental results demonstrate that our approach outperforms\nexisting methods on perceptual and temporal metrics, achieving high\nphotorealism and consistency in multi-view outputs.", "AI": {"tldr": "A novel cross-view synthesis method using a fixed latent diffusion model ensures consistent ground-view image generation from satellite imagery, outperforming existing methods.", "motivation": "Addressing inconsistencies in ground-view images generated from satellite views due to angle and resolution discrepancies.", "method": "Uses a fixed latent diffusion model with two conditioning modules: satellite-guided denoising for scene layout and satellite-temporal denoising for camera motion consistency.", "result": "Outperforms existing methods in perceptual and temporal metrics, achieving high photorealism and multi-view consistency.", "conclusion": "The proposed approach effectively generates consistent ground-view images from satellite data, supported by a large-scale dataset."}}
{"id": "2504.16073", "pdf": "https://arxiv.org/pdf/2504.16073", "abs": "https://arxiv.org/abs/2504.16073", "authors": ["Zhiyuan Hu", "Shiyun Xiong", "Yifan Zhang", "See-Kiong Ng", "Anh Tuan Luu", "Bo An", "Shuicheng Yan", "Bryan Hooi"], "title": "Guiding VLM Agents with Process Rewards at Inference Time for GUI Navigation", "categories": ["cs.CL"], "comment": null, "summary": "Recent advancements in visual language models (VLMs) have notably enhanced\ntheir capabilities in handling complex Graphical User Interface (GUI)\ninteraction tasks. Despite these improvements, current frameworks often\nstruggle to generate correct actions in challenging GUI environments.\nState-of-the-art commercial VLMs are black-boxes, and fine-tuning open-source\nVLMs for GUI tasks requires significant resources. Additionally, existing\ntrajectory-level evaluation and refinement techniques frequently fall short due\nto delayed feedback and local optimization issues. To address these challenges,\nwe propose an approach that guides VLM agents with process supervision by a\nreward model during GUI navigation and control at inference time. This guidance\nallows the VLM agent to optimize actions at each inference step, thereby\nimproving performance in both static and dynamic environments. In particular,\nour method demonstrates significant performance gains in three GUI navigation\ntasks, achieving a 3.4% improvement in single step action accuracy for static\nenvironments, along with a around 33% increase in task success rate in one\ndynamic environment. With further integration of trajectory reflection and\nretry mechanisms, we also demonstrate even greater enhancement in task success.", "AI": {"tldr": "A method using process supervision by a reward model improves VLM performance in GUI tasks, achieving notable accuracy and success rate gains.", "motivation": "Current VLMs struggle with complex GUI tasks due to black-box limitations, resource-heavy fine-tuning, and suboptimal trajectory-level evaluation.", "method": "Proposes guiding VLM agents with process supervision via a reward model during inference, optimizing actions step-by-step.", "result": "Achieves 3.4% higher single-step action accuracy in static environments and ~33% higher task success in dynamic ones.", "conclusion": "Process supervision and trajectory reflection significantly enhance VLM performance in GUI navigation and control."}}
{"id": "2504.15549", "pdf": "https://arxiv.org/pdf/2504.15549", "abs": "https://arxiv.org/abs/2504.15549", "authors": ["Anjali Khurana", "Xiaotian Su", "April Yi Wang", "Parmit K Chilana"], "title": "Do It For Me vs. Do It With Me: Investigating User Perceptions of Different Paradigms of Automation in Copilots for Feature-Rich Software", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": "Accepted for publication in the CHI Conference on Human Factors in\n  Computing Systems (CHI 2025), April 26 - May 1, 2025, Yokohama, Japan", "summary": "Large Language Model (LLM)-based in-application assistants, or copilots, can\nautomate software tasks, but users often prefer learning by doing, raising\nquestions about the optimal level of automation for an effective user\nexperience. We investigated two automation paradigms by designing and\nimplementing a fully automated copilot (AutoCopilot) and a semi-automated\ncopilot (GuidedCopilot) that automates trivial steps while offering\nstep-by-step visual guidance. In a user study (N=20) across data analysis and\nvisual design tasks, GuidedCopilot outperformed AutoCopilot in user control,\nsoftware utility, and learnability, especially for exploratory and creative\ntasks, while AutoCopilot saved time for simpler visual tasks. A follow-up\ndesign exploration (N=10) enhanced GuidedCopilot with task-and state-aware\nfeatures, including in-context preview clips and adaptive instructions. Our\nfindings highlight the critical role of user control and tailored guidance in\ndesigning the next generation of copilots that enhance productivity, support\ndiverse skill levels, and foster deeper software engagement.", "AI": {"tldr": "GuidedCopilot (semi-automated) outperforms AutoCopilot (fully automated) in user control, utility, and learnability, especially for exploratory tasks, while AutoCopilot saves time for simpler tasks. Enhanced features in GuidedCopilot further improve its effectiveness.", "motivation": "To determine the optimal level of automation for LLM-based copilots, balancing automation with user learning and control.", "method": "Designed and compared two copilots: fully automated (AutoCopilot) and semi-automated (GuidedCopilot). Conducted a user study (N=20) and a follow-up design exploration (N=10).", "result": "GuidedCopilot performed better in user control, utility, and learnability, while AutoCopilot was faster for simple tasks. Enhanced features improved GuidedCopilot further.", "conclusion": "User control and tailored guidance are crucial for effective copilot design, enhancing productivity and engagement across skill levels."}}
{"id": "2504.15773", "pdf": "https://arxiv.org/pdf/2504.15773", "abs": "https://arxiv.org/abs/2504.15773", "authors": ["Cong Liu", "Sharvaree Vadgama", "David Ruhe", "Erik Bekkers", "Patrick Forr\u00e8"], "title": "Clifford Group Equivariant Diffusion Models for 3D Molecular Generation", "categories": ["cs.LG", "cs.AI"], "comment": "7 pages, 1 figure, 1 table", "summary": "This paper explores leveraging the Clifford algebra's expressive power for\n$\\E(n)$-equivariant diffusion models. We utilize the geometric products between\nClifford multivectors and the rich geometric information encoded in Clifford\nsubspaces in \\emph{Clifford Diffusion Models} (CDMs). We extend the diffusion\nprocess beyond just Clifford one-vectors to incorporate all higher-grade\nmultivector subspaces. The data is embedded in grade-$k$ subspaces, allowing us\nto apply latent diffusion across complete multivectors. This enables CDMs to\ncapture the joint distribution across different subspaces of the algebra,\nincorporating richer geometric information through higher-order features. We\nprovide empirical results for unconditional molecular generation on the QM9\ndataset, showing that CDMs provide a promising avenue for generative modeling.", "AI": {"tldr": "The paper introduces Clifford Diffusion Models (CDMs), leveraging Clifford algebra for E(n)-equivariant diffusion models to capture richer geometric information through higher-grade multivectors.", "motivation": "To enhance generative modeling by incorporating richer geometric information from Clifford algebra's multivector subspaces.", "method": "Extends diffusion to higher-grade multivectors, embedding data in grade-k subspaces and applying latent diffusion across complete multivectors.", "result": "Empirical results on QM9 dataset show CDMs as promising for unconditional molecular generation.", "conclusion": "CDMs offer a novel approach for generative modeling by utilizing Clifford algebra's expressive power."}}
{"id": "2504.15792", "pdf": "https://arxiv.org/pdf/2504.15792", "abs": "https://arxiv.org/abs/2504.15792", "authors": ["Dinh Nam Pham", "Torsten Rahne"], "title": "Development and evaluation of a deep learning algorithm for German word recognition from lip movements", "categories": ["cs.CV"], "comment": "English version of journal article in HNO 2022", "summary": "When reading lips, many people benefit from additional visual information\nfrom the lip movements of the speaker, which is, however, very error prone.\nAlgorithms for lip reading with artificial intelligence based on artificial\nneural networks significantly improve word recognition but are not available\nfor the German language. A total of 1806 video clips with only one\nGerman-speaking person each were selected, split into word segments, and\nassigned to word classes using speech-recognition software. In 38,391 video\nsegments with 32 speakers, 18 polysyllabic, visually distinguishable words were\nused to train and validate a neural network. The 3D Convolutional Neural\nNetwork and Gated Recurrent Units models and a combination of both models\n(GRUConv) were compared, as were different image sections and color spaces of\nthe videos. The accuracy was determined in 5000 training epochs. Comparison of\nthe color spaces did not reveal any relevant different correct classification\nrates in the range from 69% to 72%. With a cut to the lips, a significantly\nhigher accuracy of 70% was achieved than when cut to the entire speaker's face\n(34%). With the GRUConv model, the maximum accuracies were 87% with known\nspeakers and 63% in the validation with unknown speakers. The neural network\nfor lip reading, which was first developed for the German language, shows a\nvery high level of accuracy, comparable to English-language algorithms. It\nworks with unknown speakers as well and can be generalized with more word\nclasses.", "AI": {"tldr": "A neural network for German lip reading achieves high accuracy (87% with known speakers, 63% with unknowns), comparable to English models, using 3D CNN and GRU models.", "motivation": "Existing lip-reading AI lacks support for German, and visual lip movements are error-prone.", "method": "Trained on 38,391 video segments of 18 German words, comparing 3D CNN, GRU, and combined models (GRUConv), with varied image sections and color spaces.", "result": "GRUConv achieved 87% accuracy with known speakers and 63% with unknowns; lip-focused cuts outperformed full-face (70% vs. 34%).", "conclusion": "The German lip-reading model is highly accurate, generalizable, and performs well with unknown speakers."}}
{"id": "2504.16074", "pdf": "https://arxiv.org/pdf/2504.16074", "abs": "https://arxiv.org/abs/2504.16074", "authors": ["Shi Qiu", "Shaoyang Guo", "Zhuo-Yang Song", "Yunbo Sun", "Zeyu Cai", "Jiashen Wei", "Tianyu Luo", "Yixuan Yin", "Haoxu Zhang", "Yi Hu", "Chenyang Wang", "Chencheng Tang", "Haoling Chang", "Qi Liu", "Ziheng Zhou", "Tianyu Zhang", "Jingtian Zhang", "Zhangyi Liu", "Minghao Li", "Yuku Zhang", "Boxuan Jing", "Xianqi Yin", "Yutong Ren", "Zizhuo Fu", "Weike Wang", "Xudong Tian", "Anqi Lv", "Laifu Man", "Jianxiang Li", "Feiyu Tao", "Qihua Sun", "Zhou Liang", "Yushu Mu", "Zhongxuan Li", "Jing-Jun Zhang", "Shutao Zhang", "Xiaotian Li", "Xingqi Xia", "Jiawei Lin", "Zheyu Shen", "Jiahang Chen", "Qiuhao Xiong", "Binran Wang", "Fengyuan Wang", "Ziyang Ni", "Bohan Zhang", "Fan Cui", "Changkun Shao", "Qing-Hong Cao", "Ming-xing Luo", "Muhan Zhang", "Hua Xing Zhu"], "title": "PHYBench: Holistic Evaluation of Physical Perception and Reasoning in Large Language Models", "categories": ["cs.CL"], "comment": "21 pages ,8 figures, 4 tables", "summary": "We introduce PHYBench, a novel, high-quality benchmark designed for\nevaluating reasoning capabilities of large language models (LLMs) in physical\ncontexts. PHYBench consists of 500 meticulously curated physics problems based\non real-world physical scenarios, designed to assess the ability of models to\nunderstand and reason about realistic physical processes. Covering mechanics,\nelectromagnetism, thermodynamics, optics, modern physics, and advanced physics,\nthe benchmark spans difficulty levels from high school exercises to\nundergraduate problems and Physics Olympiad challenges. Additionally, we\npropose the Expression Edit Distance (EED) Score, a novel evaluation metric\nbased on the edit distance between mathematical expressions, which effectively\ncaptures differences in model reasoning processes and results beyond\ntraditional binary scoring methods. We evaluate various LLMs on PHYBench and\ncompare their performance with human experts. Our results reveal that even\nstate-of-the-art reasoning models significantly lag behind human experts,\nhighlighting their limitations and the need for improvement in complex physical\nreasoning scenarios. Our benchmark results and dataset are publicly available\nat https://phybench-official.github.io/phybench-demo/.", "AI": {"tldr": "PHYBench is a new benchmark for evaluating LLMs' reasoning in physics, featuring 500 real-world problems and a novel EED Score metric. Results show LLMs lag behind humans.", "motivation": "To assess and improve LLMs' reasoning in physical contexts by providing a high-quality, diverse benchmark.", "method": "Created PHYBench with 500 physics problems across various topics and difficulty levels, and introduced the EED Score for evaluation.", "result": "State-of-the-art LLMs perform significantly worse than human experts in physical reasoning.", "conclusion": "PHYBench highlights LLMs' limitations in complex physics reasoning and provides a tool for future improvements."}}
{"id": "2504.15564", "pdf": "https://arxiv.org/pdf/2504.15564", "abs": "https://arxiv.org/abs/2504.15564", "authors": ["Musfiqur Rahman", "SayedHassan Khatoonabadi", "Emad Shihab"], "title": "A Large-scale Class-level Benchmark Dataset for Code Generation with LLMs", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": "This paper was submitted to the 29th International Conference on\n  Evaluation and Assessment in Software Engineering (EASE 2025) AI models/data\n  track", "summary": "Recent advancements in large language models (LLMs) have demonstrated\npromising capabilities in code generation tasks. However, most existing\nbenchmarks focus on isolated functions and fail to capture the complexity of\nreal-world, class-level software structures. To address this gap, we introduce\na large-scale, Python class-level dataset curated from $13{,}174$ real-world\nopen-source projects. The dataset contains over 842,000 class skeletons, each\nincluding class and method signatures, along with associated docstrings when\navailable. We preserve structural and contextual dependencies critical to\nrealistic software development scenarios and enrich the dataset with static\ncode metrics to support downstream analysis. To evaluate the usefulness of this\ndataset, we use extracted class skeletons as prompts for GPT-4 to generate full\nclass implementations. Results show that the LLM-generated classes exhibit\nstrong lexical and structural similarity to human-written counterparts, with\naverage ROUGE@L, BLEU, and TSED scores of 0.80, 0.59, and 0.73, respectively.\nThese findings confirm that well-structured prompts derived from real-world\nclass skeletons significantly enhance LLM performance in class-level code\ngeneration. This dataset offers a valuable resource for benchmarking, training,\nand improving LLMs in realistic software engineering contexts.", "AI": {"tldr": "A large-scale Python class-level dataset is introduced to address the gap in evaluating LLMs for real-world, class-level code generation, showing improved performance when using structured prompts.", "motivation": "Existing benchmarks for LLMs in code generation focus on isolated functions, missing the complexity of real-world class-level software structures.", "method": "A dataset of 842,000 class skeletons from 13,174 open-source projects is curated, preserving structural dependencies. GPT-4 is used to generate full class implementations from these skeletons.", "result": "LLM-generated classes show strong similarity to human-written ones, with ROUGE@L, BLEU, and TSED scores of 0.80, 0.59, and 0.73, respectively.", "conclusion": "Structured prompts from real-world class skeletons enhance LLM performance, making the dataset valuable for benchmarking and improving LLMs in software engineering."}}
{"id": "2504.15806", "pdf": "https://arxiv.org/pdf/2504.15806", "abs": "https://arxiv.org/abs/2504.15806", "authors": ["Kai Luo", "Juan Tang", "Mingchao Cai", "Xiaoqing Zeng", "Manqi Xie", "Ming Yan"], "title": "DAE-KAN: A Kolmogorov-Arnold Network Model for High-Index Differential-Algebraic Equations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to\nMulti-Layer Perceptrons (MLPs) due to their superior function-fitting abilities\nin data-driven modeling. In this paper, we propose a novel framework, DAE-KAN,\nfor solving high-index differential-algebraic equations (DAEs) by integrating\nKANs with Physics-Informed Neural Networks (PINNs). This framework not only\npreserves the ability of traditional PINNs to model complex systems governed by\nphysical laws but also enhances their performance by leveraging the\nfunction-fitting strengths of KANs. Numerical experiments demonstrate that for\nDAE systems ranging from index-1 to index-3, DAE-KAN reduces the absolute\nerrors of both differential and algebraic variables by 1 to 2 orders of\nmagnitude compared to traditional PINNs. To assess the effectiveness of this\napproach, we analyze the drift-off error and find that both PINNs and DAE-KAN\noutperform classical numerical methods in controlling this phenomenon. Our\nresults highlight the potential of neural network methods, particularly\nDAE-KAN, in solving high-index DAEs with substantial computational accuracy and\ngeneralization, offering a promising solution for challenging partial\ndifferential-algebraic equations.", "AI": {"tldr": "DAE-KAN integrates KANs with PINNs to solve high-index DAEs, reducing errors by 1-2 orders of magnitude compared to traditional PINNs.", "motivation": "To enhance the performance of Physics-Informed Neural Networks (PINNs) by leveraging the superior function-fitting abilities of Kolmogorov-Arnold Networks (KANs) for solving high-index differential-algebraic equations (DAEs).", "method": "Proposes DAE-KAN, a framework combining KANs with PINNs, tested on DAE systems from index-1 to index-3.", "result": "DAE-KAN reduces absolute errors significantly and outperforms classical methods in controlling drift-off error.", "conclusion": "DAE-KAN shows promise for solving high-index DAEs with improved accuracy and generalization, offering a solution for challenging PDEs."}}
{"id": "2504.15796", "pdf": "https://arxiv.org/pdf/2504.15796", "abs": "https://arxiv.org/abs/2504.15796", "authors": ["Jiaqi Tang", "Yinsong Xu", "Qingchao Chen"], "title": "Locating and Mitigating Gradient Conflicts in Point Cloud Domain Adaptation via Saliency Map Skewness", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Object classification models utilizing point cloud data are fundamental for\n3D media understanding, yet they often struggle with unseen or\nout-of-distribution (OOD) scenarios. Existing point cloud unsupervised domain\nadaptation (UDA) methods typically employ a multi-task learning (MTL) framework\nthat combines primary classification tasks with auxiliary self-supervision\ntasks to bridge the gap between cross-domain feature distributions. However,\nour further experiments demonstrate that not all gradients from\nself-supervision tasks are beneficial and some may negatively impact the\nclassification performance. In this paper, we propose a novel solution, termed\nSaliency Map-based Data Sampling Block (SM-DSB), to mitigate these gradient\nconflicts. Specifically, our method designs a new scoring mechanism based on\nthe skewness of 3D saliency maps to estimate gradient conflicts without\nrequiring target labels. Leveraging this, we develop a sample selection\nstrategy that dynamically filters out samples whose self-supervision gradients\nare not beneficial for the classification. Our approach is scalable,\nintroducing modest computational overhead, and can be integrated into all the\npoint cloud UDA MTL frameworks. Extensive evaluations demonstrate that our\nmethod outperforms state-of-the-art approaches. In addition, we provide a new\nperspective on understanding the UDA problem through back-propagation analysis.", "AI": {"tldr": "The paper introduces SM-DSB, a method to mitigate gradient conflicts in point cloud UDA by filtering harmful self-supervision gradients using saliency maps.", "motivation": "Existing UDA methods for point clouds suffer from harmful gradients in self-supervision tasks, negatively impacting classification.", "method": "Proposes SM-DSB, a scoring mechanism based on 3D saliency maps to estimate gradient conflicts and dynamically filter unhelpful samples.", "result": "Outperforms state-of-the-art UDA methods with modest computational overhead.", "conclusion": "SM-DSB effectively addresses gradient conflicts in UDA, offering a scalable solution and new insights via back-propagation analysis."}}
{"id": "2504.16084", "pdf": "https://arxiv.org/pdf/2504.16084", "abs": "https://arxiv.org/abs/2504.16084", "authors": ["Yuxin Zuo", "Kaiyan Zhang", "Shang Qu", "Li Sheng", "Xuekai Zhu", "Biqing Qi", "Youbang Sun", "Ganqu Cui", "Ning Ding", "Bowen Zhou"], "title": "TTRL: Test-Time Reinforcement Learning", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This paper investigates Reinforcement Learning (RL) on data without explicit\nlabels for reasoning tasks in Large Language Models (LLMs). The core challenge\nof the problem is reward estimation during inference while not having access to\nground-truth information. While this setting appears elusive, we find that\ncommon practices in Test-Time Scaling (TTS), such as majority voting, yield\nsurprisingly effective rewards suitable for driving RL training. In this work,\nwe introduce Test-Time Reinforcement Learning (TTRL), a novel method for\ntraining LLMs using RL on unlabeled data. TTRL enables self-evolution of LLMs\nby utilizing the priors in the pre-trained models. Our experiments demonstrate\nthat TTRL consistently improves performance across a variety of tasks and\nmodels. Notably, TTRL boosts the pass@1 performance of Qwen-2.5-Math-7B by\napproximately 159% on the AIME 2024 with only unlabeled test data. Furthermore,\nalthough TTRL is only supervised by the Maj@N metric, TTRL has demonstrated\nperformance to consistently surpass the upper limit of the initial model, and\napproach the performance of models trained directly on test data with\nground-truth labels. Our experimental findings validate the general\neffectiveness of TTRL across various tasks, and highlight TTRL's potential for\nbroader tasks and domains. GitHub: https://github.com/PRIME-RL/TTRL", "AI": {"tldr": "TTRL is a novel RL method for training LLMs on unlabeled data, using majority voting for reward estimation, achieving significant performance boosts.", "motivation": "Addresses the challenge of reward estimation in RL for LLMs without labeled data, leveraging test-time scaling practices.", "method": "Introduces TTRL, which uses majority voting (Maj@N) for reward estimation and leverages pre-trained model priors for self-evolution.", "result": "TTRL improves performance, e.g., boosting Qwen-2.5-Math-7B's pass@1 by ~159% on AIME 2024, and approaches labeled-data-trained model performance.", "conclusion": "TTRL is effective across tasks, demonstrating potential for broader applications in unlabeled data scenarios."}}
{"id": "2504.15585", "pdf": "https://arxiv.org/pdf/2504.15585", "abs": "https://arxiv.org/abs/2504.15585", "authors": ["Kun Wang", "Guibin Zhang", "Zhenhong Zhou", "Jiahao Wu", "Miao Yu", "Shiqian Zhao", "Chenlong Yin", "Jinhu Fu", "Yibo Yan", "Hanjun Luo", "Liang Lin", "Zhihao Xu", "Haolang Lu", "Xinye Cao", "Xinyun Zhou", "Weifei Jin", "Fanci Meng", "Junyuan Mao", "Hao Wu", "Minghe Wang", "Fan Zhang", "Junfeng Fang", "Chengwei Liu", "Yifan Zhang", "Qiankun Li", "Chongye Guo", "Yalan Qin", "Yi Ding", "Donghai Hong", "Jiaming Ji", "Xinfeng Li", "Yifan Jiang", "Dongxia Wang", "Yihao Huang", "Yufei Guo", "Jen-tse Huang", "Yanwei Yue", "Wenke Huang", "Guancheng Wan", "Tianlin Li", "Lei Bai", "Jie Zhang", "Qing Guo", "Jingyi Wang", "Tianlong Chen", "Joey Tianyi Zhou", "Xiaojun Jia", "Weisong Sun", "Cong Wu", "Jing Chen", "Xuming Hu", "Yiming Li", "Xiao Wang", "Ningyu Zhang", "Luu Anh Tuan", "Guowen Xu", "Tianwei Zhang", "Xingjun Ma", "Xiang Wang", "Bo An", "Jun Sun", "Mohit Bansal", "Shirui Pan", "Yuval Elovici", "Bhavya Kailkhura", "Bo Li", "Yaodong Yang", "Hongwei Li", "Wenyuan Xu", "Yizhou Sun", "Wei Wang", "Qing Li", "Ke Tang", "Yu-Gang Jiang", "Felix Juefei-Xu", "Hui Xiong", "Xiaofeng Wang", "Shuicheng Yan", "Dacheng Tao", "Philip S. Yu", "Qingsong Wen", "Yang Liu"], "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "The remarkable success of Large Language Models (LLMs) has illuminated a\npromising pathway toward achieving Artificial General Intelligence for both\nacademic and industrial communities, owing to their unprecedented performance\nacross various applications. As LLMs continue to gain prominence in both\nresearch and commercial domains, their security and safety implications have\nbecome a growing concern, not only for researchers and corporations but also\nfor every nation. Currently, existing surveys on LLM safety primarily focus on\nspecific stages of the LLM lifecycle, e.g., deployment phase or fine-tuning\nphase, lacking a comprehensive understanding of the entire \"lifechain\" of LLMs.\nTo address this gap, this paper introduces, for the first time, the concept of\n\"full-stack\" safety to systematically consider safety issues throughout the\nentire process of LLM training, deployment, and eventual commercialization.\nCompared to the off-the-shelf LLM safety surveys, our work demonstrates several\ndistinctive advantages: (I) Comprehensive Perspective. We define the complete\nLLM lifecycle as encompassing data preparation, pre-training, post-training,\ndeployment and final commercialization. To our knowledge, this represents the\nfirst safety survey to encompass the entire lifecycle of LLMs. (II) Extensive\nLiterature Support. Our research is grounded in an exhaustive review of over\n800+ papers, ensuring comprehensive coverage and systematic organization of\nsecurity issues within a more holistic understanding. (III) Unique Insights.\nThrough systematic literature analysis, we have developed reliable roadmaps and\nperspectives for each chapter. Our work identifies promising research\ndirections, including safety in data generation, alignment techniques, model\nediting, and LLM-based agent systems. These insights provide valuable guidance\nfor researchers pursuing future work in this field.", "AI": {"tldr": "This paper introduces the concept of 'full-stack' safety for Large Language Models (LLMs), addressing security and safety issues across their entire lifecycle, from data preparation to commercialization. It offers a comprehensive perspective, extensive literature review, and unique insights for future research.", "motivation": "The growing prominence of LLMs raises security and safety concerns, but existing surveys focus narrowly on specific lifecycle stages, lacking a holistic view.", "method": "The paper defines the complete LLM lifecycle, reviews over 800 papers, and systematically organizes security issues, providing roadmaps and insights for each stage.", "result": "The work identifies key research directions like safety in data generation, alignment techniques, model editing, and LLM-based agent systems.", "conclusion": "This survey fills a critical gap by offering a comprehensive safety framework for LLMs, guiding future research in the field."}}
{"id": "2504.15812", "pdf": "https://arxiv.org/pdf/2504.15812", "abs": "https://arxiv.org/abs/2504.15812", "authors": ["Xuchuang Wang", "Qirun Zeng", "Jinhang Zuo", "Xutong Liu", "Mohammad Hajiesmaili", "John C. S. Lui", "Adam Wierman"], "title": "Fusing Reward and Dueling Feedback in Stochastic Bandits", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper investigates the fusion of absolute (reward) and relative\n(dueling) feedback in stochastic bandits, where both feedback types are\ngathered in each decision round. We derive a regret lower bound, demonstrating\nthat an efficient algorithm may incur only the smaller among the reward and\ndueling-based regret for each individual arm. We propose two fusion approaches:\n(1) a simple elimination fusion algorithm that leverages both feedback types to\nexplore all arms and unifies collected information by sharing a common\ncandidate arm set, and (2) a decomposition fusion algorithm that selects the\nmore effective feedback to explore the corresponding arms and randomly assigns\none feedback type for exploration and the other for exploitation in each round.\nThe elimination fusion experiences a suboptimal multiplicative term of the\nnumber of arms in regret due to the intrinsic suboptimality of dueling\nelimination. In contrast, the decomposition fusion achieves regret matching the\nlower bound up to a constant under a common assumption. Extensive experiments\nconfirm the efficacy of our algorithms and theoretical results.", "AI": {"tldr": "The paper explores combining absolute (reward) and relative (dueling) feedback in stochastic bandits, proposing two fusion algorithms to minimize regret. The decomposition fusion matches the derived lower bound, outperforming the elimination fusion.", "motivation": "To improve efficiency in stochastic bandits by leveraging both reward and dueling feedback, minimizing regret by selecting the more effective feedback type.", "method": "Two fusion approaches: (1) elimination fusion, unifying feedback types, and (2) decomposition fusion, dynamically selecting feedback types for exploration/exploitation.", "result": "Decomposition fusion achieves regret matching the lower bound, while elimination fusion suffers from suboptimal multiplicative regret. Experiments validate the algorithms.", "conclusion": "The decomposition fusion algorithm is superior, achieving near-optimal regret by effectively combining feedback types."}}
{"id": "2504.15823", "pdf": "https://arxiv.org/pdf/2504.15823", "abs": "https://arxiv.org/abs/2504.15823", "authors": ["Songyan Xie", "Jinghang Wen", "Encheng Su", "Qiucheng Yu"], "title": "Human-Imperceptible Physical Adversarial Attack for NIR Face Recognition Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Near-infrared (NIR) face recognition systems, which can operate effectively\nin low-light conditions or in the presence of makeup, exhibit vulnerabilities\nwhen subjected to physical adversarial attacks. To further demonstrate the\npotential risks in real-world applications, we design a novel, stealthy, and\npractical adversarial patch to attack NIR face recognition systems in a\nblack-box setting. We achieved this by utilizing human-imperceptible\ninfrared-absorbing ink to generate multiple patches with digitally optimized\nshapes and positions for infrared images. To address the optimization mismatch\nbetween digital and real-world NIR imaging, we develop a light reflection model\nfor human skin to minimize pixel-level discrepancies by simulating NIR light\nreflection.\n  Compared to state-of-the-art (SOTA) physical attacks on NIR face recognition\nsystems, the experimental results show that our method improves the attack\nsuccess rate in both digital and physical domains, particularly maintaining\neffectiveness across various face postures. Notably, the proposed approach\noutperforms SOTA methods, achieving an average attack success rate of 82.46% in\nthe physical domain across different models, compared to 64.18% for existing\nmethods. The artifact is available at\nhttps://anonymous.4open.science/r/Human-imperceptible-adversarial-patch-0703/.", "AI": {"tldr": "A novel adversarial patch using infrared-absorbing ink is designed to attack NIR face recognition systems, improving attack success rates in both digital and physical domains.", "motivation": "To highlight vulnerabilities in NIR face recognition systems and demonstrate real-world risks of adversarial attacks.", "method": "Utilizes human-imperceptible infrared-absorbing ink to create digitally optimized patches and a light reflection model to minimize discrepancies.", "result": "Achieves an 82.46% attack success rate in the physical domain, outperforming SOTA methods (64.18%).", "conclusion": "The proposed method effectively enhances adversarial attack performance on NIR face recognition systems, maintaining effectiveness across various postures."}}
{"id": "2504.15448", "pdf": "https://arxiv.org/pdf/2504.15448", "abs": "https://arxiv.org/abs/2504.15448", "authors": ["Yanampally Abhiram Reddy", "Siddhi Agarwal", "Vikram Parashar", "Arshiya Arora"], "title": "Real-Time Sentiment Insights from X Using VADER, DistilBERT, and Web-Scraped Data", "categories": ["econ.GN", "cs.CL", "q-fin.EC"], "comment": "19 pages, 2 figures", "summary": "In the age of social media, understanding public sentiment toward major\ncorporations is crucial for investors, policymakers, and researchers. This\npaper presents a comprehensive sentiment analysis system tailored for corporate\nreputation monitoring, combining Natural Language Processing (NLP) and machine\nlearning techniques to accurately interpret public opinion in real time. The\nmethodology integrates a hybrid sentiment detection framework leveraging both\nrule-based models (VADER) and transformer-based deep learning models\n(DistilBERT), applied to social media data from multiple platforms. The system\nbegins with robust preprocessing involving noise removal and text\nnormalization, followed by sentiment classification using an ensemble approach\nto ensure both interpretability and contextual accuracy. Results are visualized\nthrough sentiment distribution plots, comparative analyses, and temporal\nsentiment trends for enhanced interpretability. Our analysis reveals\nsignificant disparities in public sentiment across major corporations, with\ncompanies like Amazon (81.2) and Samsung (45.8) receiving excellent sentiment\nscores, while Microsoft (21.7) and Walmart (21.9) exhibit poor sentiment\nprofiles. These findings demonstrate the utility of our multi-source sentiment\nframework in providing actionable insights regarding corporate public\nperception, enabling stakeholders to make informed strategic decisions based on\ncomprehensive sentiment analysis.", "AI": {"tldr": "The paper introduces a sentiment analysis system for corporate reputation monitoring using NLP and machine learning, combining VADER and DistilBERT for real-time public opinion interpretation.", "motivation": "Understanding public sentiment toward corporations is vital for stakeholders like investors and policymakers in the social media era.", "method": "A hybrid framework integrates rule-based (VADER) and transformer-based (DistilBERT) models, with preprocessing and ensemble sentiment classification.", "result": "Disparities in sentiment scores were found (e.g., Amazon: 81.2, Microsoft: 21.7), visualized via distribution plots and trends.", "conclusion": "The system offers actionable insights for corporate perception, aiding strategic decision-making."}}
{"id": "2504.15637", "pdf": "https://arxiv.org/pdf/2504.15637", "abs": "https://arxiv.org/abs/2504.15637", "authors": ["Farnaz Behrang", "Zhizhou Zhang", "Georgian-Vlad Saioc", "Peng Liu", "Milind Chabbi"], "title": "DR.FIX: Automatically Fixing Data Races at Industry Scale", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PL", "cs.SE"], "comment": "To appear in PLDI 2025", "summary": "Data races are a prevalent class of concurrency bugs in shared-memory\nparallel programs, posing significant challenges to software reliability and\nreproducibility. While there is an extensive body of research on detecting data\nraces and a wealth of practical detection tools across various programming\nlanguages, considerably less effort has been directed toward automatically\nfixing data races at an industrial scale. In large codebases, data races are\ncontinuously introduced and exhibit myriad patterns, making automated fixing\nparticularly challenging.\n  In this paper, we tackle the problem of automatically fixing data races at an\nindustrial scale. We present Dr.Fix, a tool that combines large language models\n(LLMs) with program analysis to generate fixes for data races in real-world\nsettings, effectively addressing a broad spectrum of racy patterns in complex\ncode contexts. Implemented for Go--the programming language widely used in\nmodern microservice architectures where concurrency is pervasive and data races\nare common--Dr.Fix seamlessly integrates into existing development workflows.\nWe detail the design of Dr.Fix and examine how individual design choices\ninfluence the quality of the fixes produced. Over the past 18 months, Dr.Fix\nhas been integrated into developer workflows at Uber demonstrating its\npractical utility. During this period, Dr.Fix produced patches for 224 (55%)\nfrom a corpus of 404 data races spanning various categories; 193 of these\npatches (86%) were accepted by more than a hundred developers via code reviews\nand integrated into the codebase.", "AI": {"tldr": "Dr.Fix combines LLMs and program analysis to automatically fix data races in Go code, achieving high acceptance rates in real-world use at Uber.", "motivation": "Data races are common in shared-memory parallel programs, but automated fixes at scale are underexplored.", "method": "Dr.Fix integrates LLMs with program analysis to address diverse racy patterns in complex Go code.", "result": "Dr.Fix fixed 55% of 404 data races, with 86% of patches accepted by developers.", "conclusion": "Dr.Fix is a practical, scalable solution for automated data race fixes in industrial settings."}}
{"id": "2504.15827", "pdf": "https://arxiv.org/pdf/2504.15827", "abs": "https://arxiv.org/abs/2504.15827", "authors": ["Xuyang Zhong", "Haochen Luo", "Chen Liu"], "title": "DualOptim: Enhancing Efficacy and Stability in Machine Unlearning with Dual Optimizers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Existing machine unlearning (MU) approaches exhibit significant sensitivity\nto hyperparameters, requiring meticulous tuning that limits practical\ndeployment. In this work, we first empirically demonstrate the instability and\nsuboptimal performance of existing popular MU methods when deployed in\ndifferent scenarios. To address this issue, we propose Dual Optimizer\n(DualOptim), which incorporates adaptive learning rate and decoupled momentum\nfactors. Empirical and theoretical evidence demonstrates that DualOptim\ncontributes to effective and stable unlearning. Through extensive experiments,\nwe show that DualOptim can significantly boost MU efficacy and stability across\ndiverse tasks, including image classification, image generation, and large\nlanguage models, making it a versatile approach to empower existing MU\nalgorithms.", "AI": {"tldr": "DualOptim improves machine unlearning stability and efficacy by using adaptive learning rates and decoupled momentum, outperforming existing methods.", "motivation": "Existing machine unlearning methods are sensitive to hyperparameters and perform inconsistently across scenarios, limiting practical use.", "method": "Proposes DualOptim, incorporating adaptive learning rates and decoupled momentum factors for stable unlearning.", "result": "DualOptim enhances unlearning performance and stability across tasks like image classification, generation, and large language models.", "conclusion": "DualOptim is a versatile solution to improve existing machine unlearning algorithms."}}
{"id": "2504.15835", "pdf": "https://arxiv.org/pdf/2504.15835", "abs": "https://arxiv.org/abs/2504.15835", "authors": ["Yiqian Wu", "Malte Prinzler", "Xiaogang Jin", "Siyu Tang"], "title": "Text-based Animatable 3D Avatars with Morphable Model Alignment", "categories": ["cs.CV"], "comment": null, "summary": "The generation of high-quality, animatable 3D head avatars from text has\nenormous potential in content creation applications such as games, movies, and\nembodied virtual assistants. Current text-to-3D generation methods typically\ncombine parametric head models with 2D diffusion models using score\ndistillation sampling to produce 3D-consistent results. However, they struggle\nto synthesize realistic details and suffer from misalignments between the\nappearance and the driving parametric model, resulting in unnatural animation\nresults. We discovered that these limitations stem from ambiguities in the 2D\ndiffusion predictions during 3D avatar distillation, specifically: i) the\navatar's appearance and geometry is underconstrained by the text input, and ii)\nthe semantic alignment between the predictions and the parametric head model is\ninsufficient because the diffusion model alone cannot incorporate information\nfrom the parametric model. In this work, we propose a novel framework,\nAnimPortrait3D, for text-based realistic animatable 3DGS avatar generation with\nmorphable model alignment, and introduce two key strategies to address these\nchallenges. First, we tackle appearance and geometry ambiguities by utilizing\nprior information from a pretrained text-to-3D model to initialize a 3D avatar\nwith robust appearance, geometry, and rigging relationships to the morphable\nmodel. Second, we refine the initial 3D avatar for dynamic expressions using a\nControlNet that is conditioned on semantic and normal maps of the morphable\nmodel to ensure accurate alignment. As a result, our method outperforms\nexisting approaches in terms of synthesis quality, alignment, and animation\nfidelity. Our experiments show that the proposed method advances the state of\nthe art in text-based, animatable 3D head avatar generation.", "AI": {"tldr": "AnimPortrait3D improves text-to-3D avatar generation by addressing ambiguities in 2D diffusion models, using pretrained priors and ControlNet for better alignment and animation.", "motivation": "Current methods struggle with realistic details and alignment in text-to-3D avatar generation, leading to unnatural animations.", "method": "Uses a pretrained text-to-3D model for initialization and refines with a ControlNet conditioned on morphable model maps.", "result": "Outperforms existing methods in synthesis quality, alignment, and animation fidelity.", "conclusion": "AnimPortrait3D advances the state of the art in text-based animatable 3D head avatar generation."}}
{"id": "2504.15629", "pdf": "https://arxiv.org/pdf/2504.15629", "abs": "https://arxiv.org/abs/2504.15629", "authors": ["Harsh Maheshwari", "Srikanth Tenneti", "Alwarappan Nakkiran"], "title": "CiteFix: Enhancing RAG Accuracy Through Post-Processing Citation Correction", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Retrieval Augmented Generation (RAG) has emerged as a powerful application of\nLarge Language Models (LLMs), revolutionizing information search and\nconsumption. RAG systems combine traditional search capabilities with LLMs to\ngenerate comprehensive answers to user queries, ideally with accurate\ncitations. However, in our experience of developing a RAG product, LLMs often\nstruggle with source attribution, aligning with other industry studies\nreporting citation accuracy rates of only about 74% for popular generative\nsearch engines. To address this, we present efficient post-processing\nalgorithms to improve citation accuracy in LLM-generated responses, with\nminimal impact on latency and cost. Our approaches cross-check generated\ncitations against retrieved articles using methods including keyword + semantic\nmatching, fine tuned model with BERTScore, and a lightweight LLM-based\ntechnique. Our experimental results demonstrate a relative improvement of\n15.46% in the overall accuracy metrics of our RAG system. This significant\nenhancement potentially enables a shift from our current larger language model\nto a relatively smaller model that is approximately 12x more cost-effective and\n3x faster in inference time, while maintaining comparable performance. This\nresearch contributes to enhancing the reliability and trustworthiness of\nAI-generated content in information retrieval and summarization tasks which is\ncritical to gain customer trust especially in commercial products.", "AI": {"tldr": "The paper introduces post-processing algorithms to improve citation accuracy in RAG systems, achieving a 15.46% relative improvement and enabling cost-effective, faster models.", "motivation": "Addressing the challenge of low citation accuracy (74%) in LLM-generated responses within RAG systems to enhance reliability and trustworthiness.", "method": "Proposes cross-checking generated citations using keyword + semantic matching, BERTScore fine-tuning, and lightweight LLM-based techniques.", "result": "Achieves a 15.46% improvement in accuracy, allowing a shift to smaller, more cost-effective models (12x cheaper, 3x faster) without performance loss.", "conclusion": "Enhances AI-generated content reliability, crucial for commercial applications and customer trust in information retrieval tasks."}}
{"id": "2504.15654", "pdf": "https://arxiv.org/pdf/2504.15654", "abs": "https://arxiv.org/abs/2504.15654", "authors": ["Md Abdul Baset Sarker", "Art Nguyen", "Sigmond Kukla", "Kevin Fite", "Masudul H. Imtiaz"], "title": "A Vision-Enabled Prosthetic Hand for Children with Upper Limb Disabilities", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "This paper introduces a novel AI vision-enabled pediatric prosthetic hand\ndesigned to assist children aged 10-12 with upper limb disabilities. The\nprosthesis features an anthropomorphic appearance, multi-articulating\nfunctionality, and a lightweight design that mimics a natural hand, making it\nboth accessible and affordable for low-income families. Using 3D printing\ntechnology and integrating advanced machine vision, sensing, and embedded\ncomputing, the prosthetic hand offers a low-cost, customizable solution that\naddresses the limitations of current myoelectric prostheses. A micro camera is\ninterfaced with a low-power FPGA for real-time object detection and assists\nwith precise grasping. The onboard DL-based object detection and grasp\nclassification models achieved accuracies of 96% and 100% respectively. In the\nforce prediction, the mean absolute error was found to be 0.018. The features\nof the proposed prosthetic hand can thus be summarized as: a) a wrist-mounted\nmicro camera for artificial sensing, enabling a wide range of hand-based tasks;\nb) real-time object detection and distance estimation for precise grasping; and\nc) ultra-low-power operation that delivers high performance within constrained\npower and resource limits.", "AI": {"tldr": "A novel AI-powered pediatric prosthetic hand for children with upper limb disabilities, featuring 3D printing, machine vision, and low-cost customization.", "motivation": "To address limitations of current myoelectric prostheses by providing an affordable, accessible, and functional solution for low-income families.", "method": "Combines 3D printing, machine vision, sensing, and embedded computing with a wrist-mounted micro camera and FPGA for real-time object detection and grasping.", "result": "Achieved 96% accuracy in object detection, 100% in grasp classification, and a mean absolute error of 0.018 in force prediction.", "conclusion": "The prosthetic hand offers a high-performance, low-cost solution with real-time capabilities and ultra-low-power operation."}}
{"id": "2504.15846", "pdf": "https://arxiv.org/pdf/2504.15846", "abs": "https://arxiv.org/abs/2504.15846", "authors": ["Jonah Ekelund", "Savvas Raptis", "Vicki Toy-Edens", "Wenli Mo", "Drew L. Turner", "Ian J. Cohen", "Stefano Markidis"], "title": "Adaptive PCA-Based Outlier Detection for Multi-Feature Time Series in Space Missions", "categories": ["cs.LG", "physics.space-ph"], "comment": "Accepted to ICCS 2025", "summary": "Analyzing multi-featured time series data is critical for space missions\nmaking efficient event detection, potentially onboard, essential for automatic\nanalysis. However, limited onboard computational resources and data downlink\nconstraints necessitate robust methods for identifying regions of interest in\nreal time. This work presents an adaptive outlier detection algorithm based on\nthe reconstruction error of Principal Component Analysis (PCA) for feature\nreduction, designed explicitly for space mission applications. The algorithm\nadapts dynamically to evolving data distributions by using Incremental PCA,\nenabling deployment without a predefined model for all possible conditions. A\npre-scaling process normalizes each feature's magnitude while preserving\nrelative variance within feature types. We demonstrate the algorithm's\neffectiveness in detecting space plasma events, such as distinct space\nenvironments, dayside and nightside transients phenomena, and transition layers\nthrough NASA's MMS mission observations. Additionally, we apply the method to\nNASA's THEMIS data, successfully identifying a dayside transient using\nonboard-available measurements.", "AI": {"tldr": "An adaptive outlier detection algorithm using PCA reconstruction error is proposed for real-time event detection in space missions, tested on NASA's MMS and THEMIS data.", "motivation": "Efficient event detection in space missions is limited by onboard computational resources and data constraints, requiring robust real-time methods.", "method": "Uses PCA for feature reduction and Incremental PCA to adapt dynamically to evolving data distributions, with pre-scaling for normalization.", "result": "Successfully detected space plasma events (e.g., distinct environments, transients) in NASA's MMS and THEMIS missions.", "conclusion": "The algorithm is effective for real-time outlier detection in space missions, adaptable without predefined models."}}
{"id": "2504.15863", "pdf": "https://arxiv.org/pdf/2504.15863", "abs": "https://arxiv.org/abs/2504.15863", "authors": ["Diego de Oliveira Hitzges", "Suman Ghosh", "Guillermo Gallego"], "title": "DERD-Net: Learning Depth from Event-based Ray Densities", "categories": ["cs.CV", "cs.LG", "cs.RO", "eess.SP"], "comment": "13 pages, 3 figures, 14 tables. Project page:\n  https://github.com/tub-rip/DERD-Net", "summary": "Event cameras offer a promising avenue for multi-view stereo depth estimation\nand Simultaneous Localization And Mapping (SLAM) due to their ability to detect\nblur-free 3D edges at high-speed and over broad illumination conditions.\nHowever, traditional deep learning frameworks designed for conventional cameras\nstruggle with the asynchronous, stream-like nature of event data, as their\narchitectures are optimized for discrete, image-like inputs. We propose a\nscalable, flexible and adaptable framework for pixel-wise depth estimation with\nevent cameras in both monocular and stereo setups. The 3D scene structure is\nencoded into disparity space images (DSIs), representing spatial densities of\nrays obtained by back-projecting events into space via known camera poses. Our\nneural network processes local subregions of the DSIs combining 3D convolutions\nand a recurrent structure to recognize valuable patterns for depth prediction.\nLocal processing enables fast inference with full parallelization and ensures\nconstant ultra-low model complexity and memory costs, regardless of camera\nresolution. Experiments on standard benchmarks (MVSEC and DSEC datasets)\ndemonstrate unprecedented effectiveness: (i) using purely monocular data, our\nmethod achieves comparable results to existing stereo methods; (ii) when\napplied to stereo data, it strongly outperforms all state-of-the-art (SOTA)\napproaches, reducing the mean absolute error by at least 42%; (iii) our method\nalso allows for increases in depth completeness by more than 3-fold while still\nyielding a reduction in median absolute error of at least 30%. Given its\nremarkable performance and effective processing of event-data, our framework\nholds strong potential to become a standard approach for using deep learning\nfor event-based depth estimation and SLAM. Project page:\nhttps://github.com/tub-rip/DERD-Net", "AI": {"tldr": "A novel framework for depth estimation with event cameras, outperforming SOTA in stereo setups and achieving comparable results in monocular setups.", "motivation": "Traditional deep learning struggles with event data's asynchronous nature; this work addresses the gap for event-based depth estimation and SLAM.", "method": "Uses disparity space images (DSIs) and a neural network with 3D convolutions and recurrent structures for local processing.", "result": "Outperforms SOTA in stereo (42% error reduction) and matches stereo results in monocular setups; improves depth completeness by 3x.", "conclusion": "The framework is highly effective for event-based depth estimation and SLAM, with potential to become a standard approach."}}
{"id": "2504.15659", "pdf": "https://arxiv.org/pdf/2504.15659", "abs": "https://arxiv.org/abs/2504.15659", "authors": ["Anjiang Wei", "Huanmi Tan", "Tarun Suresh", "Daniel Mendoza", "Thiago S. F. X. Teixeira", "Ke Wang", "Caroline Trippel", "Alex Aiken"], "title": "VeriCoder: Enhancing LLM-Based RTL Code Generation through Functional Correctness Validation", "categories": ["cs.AR", "cs.AI", "cs.CL", "cs.LG", "cs.SE"], "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have sparked growing interest\nin applying them to Electronic Design Automation (EDA) tasks, particularly\nRegister Transfer Level (RTL) code generation. While several RTL datasets have\nbeen introduced, most focus on syntactic validity rather than functional\nvalidation with tests, leading to training examples that compile but may not\nimplement the intended behavior. We present VERICODER, a model for RTL code\ngeneration fine-tuned on a dataset validated for functional correctness. This\nfine-tuning dataset is constructed using a novel methodology that combines unit\ntest generation with feedback-directed refinement. Given a natural language\nspecification and an initial RTL design, we prompt a teacher model\n(GPT-4o-mini) to generate unit tests and iteratively revise the RTL design\nbased on its simulation results using the generated tests. If necessary, the\nteacher model also updates the tests to ensure they comply with the natural\nlanguage specification. As a result of this process, every example in our\ndataset is functionally validated, consisting of a natural language\ndescription, an RTL implementation, and passing tests. Fine-tuned on this\ndataset of over 125,000 examples, VERICODER achieves state-of-the-art metrics\nin functional correctness on VerilogEval and RTLLM, with relative gains of up\nto 71.7% and 27.4% respectively. An ablation study further shows that models\ntrained on our functionally validated dataset outperform those trained on\nfunctionally non-validated datasets, underscoring the importance of\nhigh-quality datasets in RTL code generation.", "AI": {"tldr": "VERICODER is a model for RTL code generation fine-tuned on a functionally validated dataset, achieving state-of-the-art performance in functional correctness.", "motivation": "Existing RTL datasets focus on syntactic validity, lacking functional validation, which can lead to incorrect implementations.", "method": "A novel methodology combines unit test generation with feedback-directed refinement to create a functionally validated dataset, fine-tuning VERICODER on it.", "result": "VERICODER achieves relative gains of up to 71.7% and 27.4% in functional correctness on benchmarks.", "conclusion": "Functionally validated datasets are crucial for improving RTL code generation models."}}
{"id": "2504.15724", "pdf": "https://arxiv.org/pdf/2504.15724", "abs": "https://arxiv.org/abs/2504.15724", "authors": ["Yiannis Papageorgiou", "Yannis Thomas", "Alexios Filippakopoulos", "Ramin Khalili", "Iordanis Koutsopoulos"], "title": "Collaborative Split Federated Learning with Parallel Training and Aggregation", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Federated learning (FL) operates based on model exchanges between the server\nand the clients, and it suffers from significant client-side computation and\ncommunication burden. Split federated learning (SFL) arises a promising\nsolution by splitting the model into two parts, that are trained sequentially:\nthe clients train the first part of the model (client-side model) and transmit\nit to the server that trains the second (server-side model). Existing SFL\nschemes though still exhibit long training delays and significant communication\noverhead, especially when clients of different computing capability\nparticipate. Thus, we propose Collaborative-Split Federated Learning~(C-SFL), a\nnovel scheme that splits the model into three parts, namely the model parts\ntrained at the computationally weak clients, the ones trained at the\ncomputationally strong clients, and the ones at the server. Unlike existing\nworks, C-SFL enables parallel training and aggregation of model's parts at the\nclients and at the server, resulting in reduced training delays and\ncommmunication overhead while improving the model's accuracy. Experiments\nverify the multiple gains of C-SFL against the existing schemes.", "AI": {"tldr": "C-SFL introduces a three-part model split in federated learning to reduce delays and overhead while improving accuracy.", "motivation": "Existing SFL schemes suffer from long training delays and high communication overhead, especially with clients of varying computing capabilities.", "method": "C-SFL splits the model into three parts for parallel training at weak clients, strong clients, and the server.", "result": "Experiments show C-SFL reduces training delays, communication overhead, and improves model accuracy.", "conclusion": "C-SFL outperforms existing SFL schemes by enabling parallel training and aggregation."}}
{"id": "2504.15854", "pdf": "https://arxiv.org/pdf/2504.15854", "abs": "https://arxiv.org/abs/2504.15854", "authors": ["Georgios Mavroudeas", "Malik Magdon-Ismail", "Kristin P. Bennett", "Jason Kuruzovich"], "title": "Consistent Causal Inference of Group Effects in Non-Targeted Trials with Finitely Many Effect Levels", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "A treatment may be appropriate for some group (the ``sick\" group) on whom it\nhas a positive effect, but it can also have a detrimental effect on subjects\nfrom another group (the ``healthy\" group). In a non-targeted trial both sick\nand healthy subjects may be treated, producing heterogeneous effects within the\ntreated group. Inferring the correct treatment effect on the sick population is\nthen difficult, because the effects on the different groups get tangled. We\npropose an efficient nonparametric approach to estimating the group effects,\ncalled {\\bf PCM} (pre-cluster and merge). We prove its asymptotic consistency\nin a general setting and show, on synthetic data, more than a 10x improvement\nin accuracy over existing state-of-the-art. Our approach applies more generally\nto consistent estimation of functions with a finite range.", "AI": {"tldr": "PCM method improves accuracy in estimating treatment effects for heterogeneous groups by pre-clustering and merging, outperforming existing methods.", "motivation": "Addressing the challenge of disentangling treatment effects in heterogeneous groups (sick vs. healthy) in non-targeted trials.", "method": "Proposes PCM (pre-cluster and merge), a nonparametric approach for estimating group effects, ensuring asymptotic consistency.", "result": "Demonstrates over 10x accuracy improvement on synthetic data compared to state-of-the-art methods.", "conclusion": "PCM effectively estimates treatment effects in heterogeneous groups and extends to functions with finite range."}}
{"id": "2504.15865", "pdf": "https://arxiv.org/pdf/2504.15865", "abs": "https://arxiv.org/abs/2504.15865", "authors": ["Lotfi Abdelkrim Mecharbat", "Ibrahim Elmakky", "Martin Takac", "Mohammed Yaqub"], "title": "MedNNS: Supernet-based Medical Task-Adaptive Neural Network Search", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Deep learning (DL) has achieved remarkable progress in the field of medical\nimaging. However, adapting DL models to medical tasks remains a significant\nchallenge, primarily due to two key factors: (1) architecture selection, as\ndifferent tasks necessitate specialized model designs, and (2) weight\ninitialization, which directly impacts the convergence speed and final\nperformance of the models. Although transfer learning from ImageNet is a widely\nadopted strategy, its effectiveness is constrained by the substantial\ndifferences between natural and medical images. To address these challenges, we\nintroduce Medical Neural Network Search (MedNNS), the first Neural Network\nSearch framework for medical imaging applications. MedNNS jointly optimizes\narchitecture selection and weight initialization by constructing a meta-space\nthat encodes datasets and models based on how well they perform together. We\nbuild this space using a Supernetwork-based approach, expanding the model zoo\nsize by 51x times over previous state-of-the-art (SOTA) methods. Moreover, we\nintroduce rank loss and Fr\\'echet Inception Distance (FID) loss into the\nconstruction of the space to capture inter-model and inter-dataset\nrelationships, thereby achieving more accurate alignment in the meta-space.\nExperimental results across multiple datasets demonstrate that MedNNS\nsignificantly outperforms both ImageNet pre-trained DL models and SOTA Neural\nArchitecture Search (NAS) methods, achieving an average accuracy improvement of\n1.7% across datasets while converging substantially faster. The code and the\nprocessed meta-space is available at https://github.com/BioMedIA-MBZUAI/MedNNS.", "AI": {"tldr": "MedNNS is a Neural Network Search framework for medical imaging that jointly optimizes architecture selection and weight initialization, outperforming existing methods.", "motivation": "Adapting deep learning models to medical imaging is challenging due to architecture selection and weight initialization issues, with transfer learning from ImageNet being suboptimal.", "method": "MedNNS constructs a meta-space using a Supernetwork-based approach, incorporating rank loss and FID loss to align datasets and models effectively.", "result": "MedNNS achieves a 1.7% average accuracy improvement over SOTA methods and converges faster.", "conclusion": "MedNNS provides a robust solution for optimizing DL models in medical imaging, with significant performance gains and efficiency."}}
{"id": "2504.16000", "pdf": "https://arxiv.org/pdf/2504.16000", "abs": "https://arxiv.org/abs/2504.16000", "authors": ["Soham Bonnerjee", "Zhen Wei", "Yeon", "Anna Asch", "Sagnik Nandy", "Promit Ghosal"], "title": "How Private is Your Attention? Bridging Privacy with In-Context Learning", "categories": ["stat.ML", "cs.AI", "cs.CL", "cs.CR", "cs.LG"], "comment": null, "summary": "In-context learning (ICL)-the ability of transformer-based models to perform\nnew tasks from examples provided at inference time-has emerged as a hallmark of\nmodern language models. While recent works have investigated the mechanisms\nunderlying ICL, its feasibility under formal privacy constraints remains\nlargely unexplored. In this paper, we propose a differentially private\npretraining algorithm for linear attention heads and present the first\ntheoretical analysis of the privacy-accuracy trade-off for ICL in linear\nregression. Our results characterize the fundamental tension between\noptimization and privacy-induced noise, formally capturing behaviors observed\nin private training via iterative methods. Additionally, we show that our\nmethod is robust to adversarial perturbations of training prompts, unlike\nstandard ridge regression. All theoretical findings are supported by extensive\nsimulations across diverse settings.", "AI": {"tldr": "The paper explores differentially private pretraining for linear attention heads in transformer models, analyzing the privacy-accuracy trade-off in in-context learning (ICL) for linear regression.", "motivation": "To address the unexplored feasibility of ICL under formal privacy constraints and understand the trade-offs between optimization and privacy-induced noise.", "method": "Proposes a differentially private pretraining algorithm for linear attention heads and provides theoretical analysis of ICL in linear regression.", "result": "Characterizes the privacy-accuracy trade-off, shows robustness to adversarial perturbations, and supports findings with simulations.", "conclusion": "The study formalizes behaviors in private training and demonstrates the method's advantages over standard ridge regression."}}
{"id": "2504.15743", "pdf": "https://arxiv.org/pdf/2504.15743", "abs": "https://arxiv.org/abs/2504.15743", "authors": ["Seung Gyu Jeong", "Sung Woo Nam", "Seong Kwan Jung", "Seong-Eun Kim"], "title": "iMedic: Towards Smartphone-based Self-Auscultation Tool for AI-Powered Pediatric Respiratory Assessment", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": null, "summary": "Respiratory auscultation is crucial for early detection of pediatric\npneumonia, a condition that can quickly worsen without timely intervention. In\nareas with limited physician access, effective auscultation is challenging. We\npresent a smartphone-based system that leverages built-in microphones and\nadvanced deep learning algorithms to detect abnormal respiratory sounds\nindicative of pneumonia risk. Our end-to-end deep learning framework employs\ndomain generalization to integrate a large electronic stethoscope dataset with\na smaller smartphone-derived dataset, enabling robust feature learning for\naccurate respiratory assessments without expensive equipment. The accompanying\nmobile application guides caregivers in collecting high-quality lung sound\nsamples and provides immediate feedback on potential pneumonia risks. User\nstudies show strong classification performance and high acceptance,\ndemonstrating the system's ability to facilitate proactive interventions and\nreduce preventable childhood pneumonia deaths. By seamlessly integrating into\nubiquitous smartphones, this approach offers a promising avenue for more\nequitable and comprehensive remote pediatric care.", "AI": {"tldr": "A smartphone-based system using deep learning detects pediatric pneumonia via respiratory sounds, aiding early intervention in resource-limited areas.", "motivation": "Early detection of pediatric pneumonia is critical, especially in regions with limited physician access, to prevent worsening conditions.", "method": "The system uses smartphone microphones and deep learning, integrating datasets from electronic stethoscopes and smartphones for robust feature learning.", "result": "User studies confirm strong classification performance and high caregiver acceptance, enabling proactive interventions.", "conclusion": "This smartphone-based approach offers equitable remote pediatric care, reducing preventable pneumonia deaths."}}
{"id": "2504.15897", "pdf": "https://arxiv.org/pdf/2504.15897", "abs": "https://arxiv.org/abs/2504.15897", "authors": ["Zherui Yang", "Zhengyang Xue", "Ligang Liu"], "title": "SUPRA: Subspace Parameterized Attention for Neural Operator on General Domains", "categories": ["cs.LG"], "comment": null, "summary": "Neural operators are efficient surrogate models for solving partial\ndifferential equations (PDEs), but their key components face challenges: (1) in\norder to improve accuracy, attention mechanisms suffer from computational\ninefficiency on large-scale meshes, and (2) spectral convolutions rely on the\nFast Fourier Transform (FFT) on regular grids and assume a flat geometry, which\ncauses accuracy degradation on irregular domains. To tackle these problems, we\nregard the matrix-vector operations in the standard attention mechanism on\nvectors in Euclidean space as bilinear forms and linear operators in vector\nspaces and generalize the attention mechanism to function spaces. This new\nattention mechanism is fully equivalent to the standard attention but\nimpossible to compute due to the infinite dimensionality of function spaces. To\naddress this, inspired by model reduction techniques, we propose a Subspace\nParameterized Attention (SUPRA) neural operator, which approximates the\nattention mechanism within a finite-dimensional subspace. To construct a\nsubspace on irregular domains for SUPRA, we propose using the Laplacian\neigenfunctions, which naturally adapt to domains' geometry and guarantee the\noptimal approximation for smooth functions. Experiments show that the SUPRA\nneural operator reduces error rates by up to 33% on various PDE datasets while\nmaintaining state-of-the-art computational efficiency.", "AI": {"tldr": "The paper introduces SUPRA, a neural operator that improves accuracy and efficiency for solving PDEs by generalizing attention mechanisms to function spaces and using Laplacian eigenfunctions for irregular domains.", "motivation": "Current neural operators for PDEs face inefficiency with attention mechanisms on large-scale meshes and accuracy issues with spectral convolutions on irregular domains.", "method": "The authors generalize attention to function spaces, propose SUPRA to approximate it in finite-dimensional subspaces, and use Laplacian eigenfunctions for irregular domains.", "result": "SUPRA reduces error rates by up to 33% on PDE datasets while maintaining computational efficiency.", "conclusion": "SUPRA effectively addresses challenges in neural operators for PDEs, offering improved accuracy and efficiency."}}
{"id": "2504.15883", "pdf": "https://arxiv.org/pdf/2504.15883", "abs": "https://arxiv.org/abs/2504.15883", "authors": ["Farida Mohsen", "Samir Belhaouari", "Zubair Shah"], "title": "Integrating Non-Linear Radon Transformation for Diabetic Retinopathy Grading", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Diabetic retinopathy is a serious ocular complication that poses a\nsignificant threat to patients' vision and overall health. Early detection and\naccurate grading are essential to prevent vision loss. Current automatic\ngrading methods rely heavily on deep learning applied to retinal fundus images,\nbut the complex, irregular patterns of lesions in these images, which vary in\nshape and distribution, make it difficult to capture subtle changes. This study\nintroduces RadFuse, a multi-representation deep learning framework that\nintegrates non-linear RadEx-transformed sinogram images with traditional fundus\nimages to enhance diabetic retinopathy detection and grading. Our RadEx\ntransformation, an optimized non-linear extension of the Radon transform,\ngenerates sinogram representations to capture complex retinal lesion patterns.\nBy leveraging both spatial and transformed domain information, RadFuse enriches\nthe feature set available to deep learning models, improving the\ndifferentiation of severity levels. We conducted extensive experiments on two\nbenchmark datasets, APTOS-2019 and DDR, using three convolutional neural\nnetworks (CNNs): ResNeXt-50, MobileNetV2, and VGG19. RadFuse showed significant\nimprovements over fundus-image-only models across all three CNN architectures\nand outperformed state-of-the-art methods on both datasets. For severity\ngrading across five stages, RadFuse achieved a quadratic weighted kappa of\n93.24%, an accuracy of 87.07%, and an F1-score of 87.17%. In binary\nclassification between healthy and diabetic retinopathy cases, the method\nreached an accuracy of 99.09%, precision of 98.58%, and recall of 99.6%,\nsurpassing previously established models. These results demonstrate RadFuse's\ncapacity to capture complex non-linear features, advancing diabetic retinopathy\nclassification and promoting the integration of advanced mathematical\ntransforms in medical image analysis.", "AI": {"tldr": "RadFuse, a multi-representation deep learning framework, improves diabetic retinopathy detection and grading by integrating RadEx-transformed sinogram images with fundus images, outperforming state-of-the-art methods.", "motivation": "Early detection and accurate grading of diabetic retinopathy are critical to prevent vision loss, but current methods struggle with complex lesion patterns.", "method": "RadFuse combines RadEx-transformed sinogram images (an optimized non-linear Radon transform) with fundus images, leveraging spatial and transformed domain features. Experiments used ResNeXt-50, MobileNetV2, and VGG19 CNNs on APTOS-2019 and DDR datasets.", "result": "RadFuse achieved a quadratic weighted kappa of 93.24%, accuracy of 87.07%, and F1-score of 87.17% for severity grading. Binary classification reached 99.09% accuracy, 98.58% precision, and 99.6% recall.", "conclusion": "RadFuse effectively captures complex non-linear features, advancing diabetic retinopathy classification and highlighting the potential of mathematical transforms in medical imaging."}}
{"id": "2504.16081", "pdf": "https://arxiv.org/pdf/2504.16081", "abs": "https://arxiv.org/abs/2504.16081", "authors": ["Yimu Wang", "Xuye Liu", "Wei Pang", "Li Ma", "Shuai Yuan", "Paul Debevec", "Ning Yu"], "title": "Survey of Video Diffusion Models: Foundations, Implementations, and Applications", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Recent advances in diffusion models have revolutionized video generation,\noffering superior temporal consistency and visual quality compared to\ntraditional generative adversarial networks-based approaches. While this\nemerging field shows tremendous promise in applications, it faces significant\nchallenges in motion consistency, computational efficiency, and ethical\nconsiderations. This survey provides a comprehensive review of diffusion-based\nvideo generation, examining its evolution, technical foundations, and practical\napplications. We present a systematic taxonomy of current methodologies,\nanalyze architectural innovations and optimization strategies, and investigate\napplications across low-level vision tasks such as denoising and\nsuper-resolution. Additionally, we explore the synergies between diffusionbased\nvideo generation and related domains, including video representation learning,\nquestion answering, and retrieval. Compared to the existing surveys (Lei et\nal., 2024a;b; Melnik et al., 2024; Cao et al., 2023; Xing et al., 2024c) which\nfocus on specific aspects of video generation, such as human video synthesis\n(Lei et al., 2024a) or long-form content generation (Lei et al., 2024b), our\nwork provides a broader, more updated, and more fine-grained perspective on\ndiffusion-based approaches with a special section for evaluation metrics,\nindustry solutions, and training engineering techniques in video generation.\nThis survey serves as a foundational resource for researchers and practitioners\nworking at the intersection of diffusion models and video generation, providing\ninsights into both the theoretical frameworks and practical implementations\nthat drive this rapidly evolving field. A structured list of related works\ninvolved in this survey is also available on\nhttps://github.com/Eyeline-Research/Survey-Video-Diffusion.", "AI": {"tldr": "A survey on diffusion-based video generation, covering evolution, methodologies, applications, and challenges, with a broader perspective than existing works.", "motivation": "To provide a comprehensive and updated review of diffusion-based video generation, addressing gaps in existing surveys and highlighting practical applications and challenges.", "method": "Systematic taxonomy of methodologies, analysis of architectural innovations, optimization strategies, and exploration of synergies with related domains.", "result": "A detailed resource for researchers, offering insights into theoretical frameworks and practical implementations, including evaluation metrics and industry solutions.", "conclusion": "The survey serves as a foundational guide for the field, emphasizing the potential and challenges of diffusion-based video generation."}}
{"id": "2504.15766", "pdf": "https://arxiv.org/pdf/2504.15766", "abs": "https://arxiv.org/abs/2504.15766", "authors": ["Tobias Demmler", "Lennart Hartung", "Andreas Tamke", "Thao Dang", "Alexander Hegai", "Karsten Haug", "Lars Mikelsons"], "title": "Dynamic Intent Queries for Motion Transformer-based Trajectory Prediction", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "In autonomous driving, accurately predicting the movements of other traffic\nparticipants is crucial, as it significantly influences a vehicle's planning\nprocesses. Modern trajectory prediction models strive to interpret complex\npatterns and dependencies from agent and map data. The Motion Transformer (MTR)\narchitecture and subsequent work define the most accurate methods in common\nbenchmarks such as the Waymo Open Motion Benchmark. The MTR model employs\npre-generated static intention points as initial goal points for trajectory\nprediction. However, the static nature of these points frequently leads to\nmisalignment with map data in specific traffic scenarios, resulting in\nunfeasible or unrealistic goal points. Our research addresses this limitation\nby integrating scene-specific dynamic intention points into the MTR model. This\nadaptation of the MTR model was trained and evaluated on the Waymo Open Motion\nDataset. Our findings demonstrate that incorporating dynamic intention points\nhas a significant positive impact on trajectory prediction accuracy, especially\nfor predictions over long time horizons. Furthermore, we analyze the impact on\nground truth trajectories which are not compliant with the map data or are\nillegal maneuvers.", "AI": {"tldr": "The paper proposes enhancing the Motion Transformer (MTR) model for trajectory prediction in autonomous driving by replacing static intention points with dynamic ones, improving accuracy, especially for long-term predictions.", "motivation": "Static intention points in the MTR model often misalign with map data, leading to unrealistic predictions. The study aims to address this by introducing dynamic intention points.", "method": "The MTR model is adapted to use scene-specific dynamic intention points, trained and evaluated on the Waymo Open Motion Dataset.", "result": "Dynamic intention points significantly improve trajectory prediction accuracy, particularly for long time horizons, and better handle non-compliant or illegal maneuvers.", "conclusion": "Integrating dynamic intention points into the MTR model enhances its performance and reliability in real-world traffic scenarios."}}
{"id": "2504.15905", "pdf": "https://arxiv.org/pdf/2504.15905", "abs": "https://arxiv.org/abs/2504.15905", "authors": ["Wenjing Xiao", "Chenglong Shi", "Miaojiang Chen", "Zhiquan Liu", "Min Chen", "H. Herbert Song"], "title": "GraphEdge: Dynamic Graph Partition and Task Scheduling for GNNs Computing in Edge Network", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages,12 figures", "summary": "With the exponential growth of Internet of Things (IoT) devices, edge\ncomputing (EC) is gradually playing an important role in providing\ncost-effective services. However, existing approaches struggle to perform well\nin graph-structured scenarios where user data is correlated, such as traffic\nflow prediction and social relationship recommender systems. In particular,\ngraph neural network (GNN)-based approaches lead to expensive server\ncommunication cost. To address this problem, we propose GraphEdge, an efficient\nGNN-based EC architecture. It considers the EC system of GNN tasks, where there\nare associations between users and it needs to take into account the task data\nof its neighbors when processing the tasks of a user. Specifically, the\narchitecture first perceives the user topology and represents their data\nassociations as a graph layout at each time step. Then the graph layout is\noptimized by calling our proposed hierarchical traversal graph cut algorithm\n(HiCut), which cuts the graph layout into multiple weakly associated subgraphs\nbased on the aggregation characteristics of GNN, and the communication cost\nbetween different subgraphs during GNN inference is minimized. Finally, based\non the optimized graph layout, our proposed deep reinforcement learning (DRL)\nbased graph offloading algorithm (DRLGO) is executed to obtain the optimal\noffloading strategy for the tasks of users, the offloading strategy is\nsubgraph-based, it tries to offload user tasks in a subgraph to the same edge\nserver as possible while minimizing the task processing time and energy\nconsumption of the EC system. Experimental results show the good effectiveness\nand dynamic adaptation of our proposed architecture and it also performs well\neven in dynamic scenarios.", "AI": {"tldr": "GraphEdge is an efficient GNN-based edge computing architecture that optimizes communication costs and task offloading using hierarchical traversal and DRL.", "motivation": "Address the high communication costs of GNN-based approaches in graph-structured IoT scenarios like traffic flow prediction and social recommendations.", "method": "Proposes GraphEdge with HiCut for graph layout optimization and DRLGO for subgraph-based task offloading to minimize costs.", "result": "Demonstrates effectiveness and adaptability, even in dynamic scenarios.", "conclusion": "GraphEdge offers a scalable and efficient solution for GNN tasks in edge computing."}}
{"id": "2504.15888", "pdf": "https://arxiv.org/pdf/2504.15888", "abs": "https://arxiv.org/abs/2504.15888", "authors": ["Zhiqiang Wei", "Lianqing Zheng", "Jianan Liu", "Tao Huang", "Qing-Long Han", "Wenwen Zhang", "Fengdeng Zhang"], "title": "MS-Occ: Multi-Stage LiDAR-Camera Fusion for 3D Semantic Occupancy Prediction", "categories": ["cs.CV"], "comment": "8 pages, 5 figures", "summary": "Accurate 3D semantic occupancy perception is essential for autonomous driving\nin complex environments with diverse and irregular objects. While\nvision-centric methods suffer from geometric inaccuracies, LiDAR-based\napproaches often lack rich semantic information. To address these limitations,\nMS-Occ, a novel multi-stage LiDAR-camera fusion framework which includes\nmiddle-stage fusion and late-stage fusion, is proposed, integrating LiDAR's\ngeometric fidelity with camera-based semantic richness via hierarchical\ncross-modal fusion. The framework introduces innovations at two critical\nstages: (1) In the middle-stage feature fusion, the Gaussian-Geo module\nleverages Gaussian kernel rendering on sparse LiDAR depth maps to enhance 2D\nimage features with dense geometric priors, and the Semantic-Aware module\nenriches LiDAR voxels with semantic context via deformable cross-attention; (2)\nIn the late-stage voxel fusion, the Adaptive Fusion (AF) module dynamically\nbalances voxel features across modalities, while the High Classification\nConfidence Voxel Fusion (HCCVF) module resolves semantic inconsistencies using\nself-attention-based refinement. Experiments on the nuScenes-OpenOccupancy\nbenchmark show that MS-Occ achieves an Intersection over Union (IoU) of 32.1%\nand a mean IoU (mIoU) of 25.3%, surpassing the state-of-the-art by +0.7% IoU\nand +2.4% mIoU. Ablation studies further validate the contribution of each\nmodule, with substantial improvements in small-object perception, demonstrating\nthe practical value of MS-Occ for safety-critical autonomous driving scenarios.", "AI": {"tldr": "MS-Occ is a multi-stage LiDAR-camera fusion framework for 3D semantic occupancy perception, outperforming state-of-the-art methods with improved geometric and semantic accuracy.", "motivation": "Addressing the limitations of vision-centric (geometric inaccuracies) and LiDAR-based (lack of semantic richness) methods in autonomous driving.", "method": "Proposes a multi-stage fusion framework with middle-stage (Gaussian-Geo and Semantic-Aware modules) and late-stage (Adaptive Fusion and HCCVF modules) fusion techniques.", "result": "Achieves 32.1% IoU and 25.3% mIoU on nuScenes-OpenOccupancy, surpassing prior methods by +0.7% IoU and +2.4% mIoU.", "conclusion": "MS-Occ effectively integrates LiDAR and camera data, validated by ablation studies, enhancing small-object perception for autonomous driving."}}
{"id": "2212.09409", "pdf": "https://arxiv.org/pdf/2212.09409", "abs": "https://arxiv.org/abs/2212.09409", "authors": ["Dustin Wright", "Isabelle Augenstein"], "title": "Aggregating Soft Labels from Crowd Annotations Improves Uncertainty Estimation Under Distribution Shift", "categories": ["cs.CL"], "comment": "Accepted to PLOS One; 29 pages, 16 figures, 4 tables", "summary": "Selecting an effective training signal for machine learning tasks is\ndifficult: expert annotations are expensive, and crowd-sourced annotations may\nnot be reliable. Recent work has demonstrated that learning from a distribution\nover labels acquired from crowd annotations can be effective both for\nperformance and uncertainty estimation. However, this has mainly been studied\nusing a limited set of soft-labeling methods in an in-domain setting.\nAdditionally, no one method has been shown to consistently perform well across\ntasks, making it difficult to know a priori which to choose. To fill these\ngaps, this paper provides the first large-scale empirical study on learning\nfrom crowd labels in the out-of-domain setting, systematically analyzing 8\nsoft-labeling methods on 4 language and vision tasks. Additionally, we propose\nto aggregate soft-labels via a simple average in order to achieve consistent\nperformance across tasks. We demonstrate that this yields classifiers with\nimproved predictive uncertainty estimation in most settings while maintaining\nconsistent raw performance compared to learning from individual soft-labeling\nmethods or taking a majority vote of the annotations. We additionally highlight\nthat in regimes with abundant or minimal training data, the selection of soft\nlabeling method is less important, while for highly subjective labels and\nmoderate amounts of training data, aggregation yields significant improvements\nin uncertainty estimation over individual methods. Code can be found at\nhttps://github.com/copenlu/aggregating-crowd-annotations-ood.", "AI": {"tldr": "The paper conducts a large-scale study on learning from crowd labels in out-of-domain settings, analyzing 8 soft-labeling methods across 4 tasks, and proposes averaging soft-labels for consistent performance.", "motivation": "Expert annotations are costly, and crowd-sourced labels may lack reliability. Existing work lacks comprehensive analysis of soft-labeling methods in out-of-domain settings and consistent performance across tasks.", "method": "Systematically evaluates 8 soft-labeling methods on 4 language and vision tasks in out-of-domain settings. Proposes averaging soft-labels for aggregation.", "result": "Averaging soft-labels improves predictive uncertainty estimation while maintaining performance. Method selection matters less with abundant or minimal data but is crucial for subjective labels and moderate data.", "conclusion": "Aggregating soft-labels via averaging offers consistent performance and better uncertainty estimation, especially for subjective tasks with moderate data."}}
{"id": "2504.15779", "pdf": "https://arxiv.org/pdf/2504.15779", "abs": "https://arxiv.org/abs/2504.15779", "authors": ["Aaron J. Gutknecht", "Fernando E. Rosas", "David A. Ehrlich", "Abdullah Makkeh", "Pedro A. M. Mediano", "Michael Wibral"], "title": "Shannon invariants: A scalable approach to information decomposition", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT", "nlin.AO", "physics.data-an"], "comment": "16 pages, 4 Figures", "summary": "Distributed systems, such as biological and artificial neural networks,\nprocess information via complex interactions engaging multiple subsystems,\nresulting in high-order patterns with distinct properties across scales.\nInvestigating how these systems process information remains challenging due to\ndifficulties in defining appropriate multivariate metrics and ensuring their\nscalability to large systems. To address these challenges, we introduce a novel\nframework based on what we call \"Shannon invariants\" -- quantities that capture\nessential properties of high-order information processing in a way that depends\nonly on the definition of entropy and can be efficiently calculated for large\nsystems. Our theoretical results demonstrate how Shannon invariants can be used\nto resolve long-standing ambiguities regarding the interpretation of widely\nused multivariate information-theoretic measures. Moreover, our practical\nresults reveal distinctive information-processing signatures of various deep\nlearning architectures across layers, which lead to new insights into how these\nsystems process information and how this evolves during training. Overall, our\nframework resolves fundamental limitations in analyzing high-order phenomena\nand offers broad opportunities for theoretical developments and empirical\nanalyses.", "AI": {"tldr": "The paper introduces 'Shannon invariants,' a novel framework for analyzing high-order information processing in distributed systems, resolving ambiguities in multivariate metrics and offering scalable solutions.", "motivation": "The challenge lies in defining and scaling multivariate metrics for complex systems like neural networks to understand their information processing.", "method": "A framework based on Shannon invariants, derived from entropy, is proposed to efficiently analyze high-order interactions in large systems.", "result": "The framework clarifies ambiguities in multivariate measures and reveals unique information-processing signatures in deep learning architectures.", "conclusion": "The Shannon invariants framework addresses fundamental limitations in analyzing high-order phenomena, enabling new theoretical and empirical insights."}}
{"id": "2504.15920", "pdf": "https://arxiv.org/pdf/2504.15920", "abs": "https://arxiv.org/abs/2504.15920", "authors": ["Xiang Li", "Haobing Liu", "Jianpeng Qi", "Yuan Cao", "Guoqing Chao", "Yanwei Yu"], "title": "ScaleGNN: Towards Scalable Graph Neural Networks via Adaptive High-order Neighboring Feature Fusion", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have demonstrated strong performance across\nvarious graph-based tasks by effectively capturing relational information\nbetween nodes. These models rely on iterative message passing to propagate node\nfeatures, enabling nodes to aggregate information from their neighbors. Recent\nresearch has significantly improved the message-passing mechanism, enhancing\nGNN scalability on large-scale graphs. However, GNNs still face two main\nchallenges: over-smoothing, where excessive message passing results in\nindistinguishable node representations, especially in deep networks\nincorporating high-order neighbors; and scalability issues, as traditional\narchitectures suffer from high model complexity and increased inference time\ndue to redundant information aggregation. This paper proposes a novel framework\nfor large-scale graphs named ScaleGNN that simultaneously addresses both\nchallenges by adaptively fusing multi-level graph features. We first construct\nneighbor matrices for each order, learning their relative information through\ntrainable weights through an adaptive high-order feature fusion module. This\nallows the model to selectively emphasize informative high-order neighbors\nwhile reducing unnecessary computational costs. Additionally, we introduce a\nHigh-order redundant feature masking mechanism based on a Local Contribution\nScore (LCS), which enables the model to retain only the most relevant neighbors\nat each order, preventing redundant information propagation. Furthermore,\nlow-order enhanced feature aggregation adaptively integrates low-order and\nhigh-order features based on task relevance, ensuring effective capture of both\nlocal and global structural information without excessive complexity. Extensive\nexperiments on real-world datasets demonstrate that our approach consistently\noutperforms state-of-the-art GNN models in both accuracy and computational\nefficiency.", "AI": {"tldr": "ScaleGNN addresses GNN challenges (over-smoothing and scalability) by adaptively fusing multi-level graph features and masking redundant features.", "motivation": "GNNs struggle with over-smoothing and scalability due to redundant information aggregation and high model complexity.", "method": "Proposes ScaleGNN with adaptive high-order feature fusion, redundant feature masking, and low-order enhanced feature aggregation.", "result": "Outperforms state-of-the-art GNNs in accuracy and computational efficiency on real-world datasets.", "conclusion": "ScaleGNN effectively balances local and global structural information while reducing computational costs."}}
{"id": "2504.15918", "pdf": "https://arxiv.org/pdf/2504.15918", "abs": "https://arxiv.org/abs/2504.15918", "authors": ["Chang Zong", "Bin Li", "Shoujun Zhou", "Jian Wan", "Lei Zhang"], "title": "Ask2Loc: Learning to Locate Instructional Visual Answers by Asking Questions", "categories": ["cs.CV", "cs.AI", "cs.HC", "68T45, 68T20"], "comment": "16 pages, 8 figures", "summary": "Locating specific segments within an instructional video is an efficient way\nto acquire guiding knowledge. Generally, the task of obtaining video segments\nfor both verbal explanations and visual demonstrations is known as visual\nanswer localization (VAL). However, users often need multiple interactions to\nobtain answers that align with their expectations when using the system. During\nthese interactions, humans deepen their understanding of the video content by\nasking themselves questions, thereby accurately identifying the location.\nTherefore, we propose a new task, named In-VAL, to simulate the multiple\ninteractions between humans and videos in the procedure of obtaining visual\nanswers. The In-VAL task requires interactively addressing several semantic gap\nissues, including 1) the ambiguity of user intent in the input questions, 2)\nthe incompleteness of language in video subtitles, and 3) the fragmentation of\ncontent in video segments. To address these issues, we propose Ask2Loc, a\nframework for resolving In-VAL by asking questions. It includes three key\nmodules: 1) a chatting module to refine initial questions and uncover clear\nintentions, 2) a rewriting module to generate fluent language and create\ncomplete descriptions, and 3) a searching module to broaden local context and\nprovide integrated content. We conduct extensive experiments on three\nreconstructed In-VAL datasets. Compared to traditional end-to-end and two-stage\nmethods, our proposed Ask2Loc can improve performance by up to 14.91 (mIoU) on\nthe In-VAL task. Our code and datasets can be accessed at\nhttps://github.com/changzong/Ask2Loc.", "AI": {"tldr": "The paper introduces In-VAL, a task simulating human-video interactions for visual answer localization, and proposes Ask2Loc, a framework to address semantic gaps in this process.", "motivation": "Users often need multiple interactions to find accurate video segments, highlighting the need for a system that mimics human understanding through iterative questioning.", "method": "Ask2Loc includes three modules: chatting (refining questions), rewriting (generating descriptions), and searching (integrating content).", "result": "Ask2Loc improves performance by up to 14.91 (mIoU) over traditional methods on In-VAL datasets.", "conclusion": "The proposed framework effectively addresses semantic gaps in visual answer localization, outperforming existing methods."}}
{"id": "2407.04615", "pdf": "https://arxiv.org/pdf/2407.04615", "abs": "https://arxiv.org/abs/2407.04615", "authors": ["Sergey Troshin", "Vlad Niculae", "Antske Fokkens"], "title": "On the Low-Rank Parametrization of Reward Models for Controlled Language Generation", "categories": ["cs.CL"], "comment": null, "summary": "Language models trained on large amounts of data are known to produce\ninappropriate content in some cases and require careful tuning to be used in\nthe real world. We revisit an effective and modular approach for\ncontrollability of the language models, when an external expert model guides\nthe decoding. Particularly, we zoom in into the parametrization choice of an\nexternal expert, highlighting the difference between low-rank and higher-rank\nparametrizations. Higher-rank experts are designed to support high flexibility\nwhen representing the rewards, leading to higher computational costs during\ndecoding. However, we demonstrate that they might not use their full\nflexibility. By analyzing the recently proposed reward-augmented decoding\napproach (RAD), which uses a higher-rank expert model, we introduce a simpler\nbut more efficient low-rank parametrization of the expert model enabling fast\nand effective guided decoding. We empirically show that the low-rank RAD\nperforms on par with the more flexible RAD on a detoxification and a sentiment\ncontrol task, while requiring only a single reward model call per generated\ntoken.", "AI": {"tldr": "The paper revisits modular control of language models using external experts, comparing low-rank and higher-rank parametrizations. It introduces a simpler, efficient low-rank RAD method, matching higher-rank performance with lower computational cost.", "motivation": "Address the challenge of controlling language models to avoid inappropriate content, focusing on efficient and effective guided decoding.", "method": "Analyzes reward-augmented decoding (RAD) with higher-rank experts, then proposes a low-rank parametrization for efficiency.", "result": "Low-rank RAD performs comparably to higher-rank RAD in detoxification and sentiment control tasks, with reduced computational cost.", "conclusion": "Low-rank expert models offer a practical, efficient alternative to higher-rank ones for guided decoding without sacrificing performance."}}
{"id": "2504.15804", "pdf": "https://arxiv.org/pdf/2504.15804", "abs": "https://arxiv.org/abs/2504.15804", "authors": ["Ning Wang", "Bingkun Yao", "Jie Zhou", "Yuchen Hu", "Xi Wang", "Nan Guan", "Zhe Jiang"], "title": "Insights from Verification: Training a Verilog Generation LLM with Reinforcement Learning with Testbench Feedback", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have shown strong performance in Verilog\ngeneration from natural language description. However, ensuring the functional\ncorrectness of the generated code remains a significant challenge. This paper\nintroduces a method that integrates verification insights from testbench into\nthe training of Verilog generation LLMs, aligning the training with the\nfundamental goal of hardware design: functional correctness. The main obstacle\nin using LLMs for Verilog code generation is the lack of sufficient functional\nverification data, particularly testbenches paired with design specifications\nand code. To address this problem, we introduce an automatic testbench\ngeneration pipeline that decomposes the process and uses feedback from the\nVerilog compiler simulator (VCS) to reduce hallucination and ensure\ncorrectness. We then use the testbench to evaluate the generated codes and\ncollect them for further training, where verification insights are introduced.\nOur method applies reinforcement learning (RL), specifically direct preference\noptimization (DPO), to align Verilog code generation with functional\ncorrectness by training preference pairs based on testbench outcomes. In\nevaluations on VerilogEval-Machine, VerilogEval-Human, RTLLM v1.1, RTLLM v2,\nand VerilogEval v2, our approach consistently outperforms state-of-the-art\nbaselines in generating functionally correct Verilog code. We open source all\ntraining code, data, and models at\nhttps://anonymous.4open.science/r/VeriPrefer-E88B.", "AI": {"tldr": "The paper introduces a method to improve functional correctness in Verilog code generation by LLMs using testbench feedback and reinforcement learning.", "motivation": "Ensuring functional correctness in LLM-generated Verilog code is challenging due to insufficient verification data.", "method": "An automatic testbench generation pipeline is used to verify code, and reinforcement learning (DPO) aligns training with correctness.", "result": "The approach outperforms baselines on multiple benchmarks in generating correct Verilog code.", "conclusion": "Integrating verification insights into LLM training improves functional correctness, with open-sourced resources for further research."}}
{"id": "2504.15924", "pdf": "https://arxiv.org/pdf/2504.15924", "abs": "https://arxiv.org/abs/2504.15924", "authors": ["Alycia Carey", "Xintao Wu"], "title": "Achieving Distributive Justice in Federated Learning via Uncertainty Quantification", "categories": ["cs.LG", "cs.AI", "stat.ML", "68T01", "I.2.0"], "comment": "21 pages, 1 figure, 7 tables", "summary": "Client-level fairness metrics for federated learning are used to ensure that\nall clients in a federation either: a) have similar final performance on their\nlocal data distributions (i.e., client parity), or b) obtain final performance\non their local data distributions relative to their contribution to the\nfederated learning process (i.e., contribution fairness). While a handful of\nworks that propose either client-parity or contribution-based fairness metrics\nground their definitions and decisions in social theories of equality -- such\nas distributive justice -- most works arbitrarily choose what notion of\nfairness to align with which makes it difficult for practitioners to choose\nwhich fairness metric aligns best with their fairness ethics. In this work, we\npropose UDJ-FL (Uncertainty-based Distributive Justice for Federated Learning),\na flexible federated learning framework that can achieve multiple distributive\njustice-based client-level fairness metrics. Namely, by utilizing techniques\ninspired by fair resource allocation, in conjunction with performing aleatoric\nuncertainty-based client weighing, our UDJ-FL framework is able to achieve\negalitarian, utilitarian, Rawls' difference principle, or desert-based\nclient-level fairness. We empirically show the ability of UDJ-FL to achieve all\nfour defined distributive justice-based client-level fairness metrics in\naddition to providing fairness equivalent to (or surpassing) other popular fair\nfederated learning works. Further, we provide justification for why aleatoric\nuncertainty weighing is necessary to the construction of our UDJ-FL framework\nas well as derive theoretical guarantees for the generalization bounds of\nUDJ-FL. Our code is publicly available at\nhttps://github.com/alycia-noel/UDJ-FL.", "AI": {"tldr": "UDJ-FL is a federated learning framework achieving multiple distributive justice-based fairness metrics, outperforming existing methods.", "motivation": "Addressing the arbitrary choice of fairness metrics in federated learning by grounding them in social theories like distributive justice.", "method": "Utilizes fair resource allocation and aleatoric uncertainty-based client weighing to achieve various fairness metrics (egalitarian, utilitarian, Rawls' difference principle, desert-based).", "result": "Empirically achieves four fairness metrics, outperforming other methods, with theoretical guarantees for generalization bounds.", "conclusion": "UDJ-FL provides a flexible, justified approach to client-level fairness in federated learning, supported by empirical and theoretical results."}}
{"id": "2504.15921", "pdf": "https://arxiv.org/pdf/2504.15921", "abs": "https://arxiv.org/abs/2504.15921", "authors": ["Jian Hu", "Dimitrios Korkinof", "Shaogang Gong", "Mariano Beguerisse-Diaz"], "title": "ViSMaP: Unsupervised Hour-long Video Summarisation by Meta-Prompting", "categories": ["cs.CV"], "comment": null, "summary": "We introduce ViSMap: Unsupervised Video Summarisation by Meta Prompting, a\nsystem to summarise hour long videos with no-supervision. Most existing video\nunderstanding models work well on short videos of pre-segmented events, yet\nthey struggle to summarise longer videos where relevant events are sparsely\ndistributed and not pre-segmented. Moreover, long-form video understanding\noften relies on supervised hierarchical training that needs extensive\nannotations which are costly, slow and prone to inconsistency. With ViSMaP we\nbridge the gap between short videos (where annotated data is plentiful) and\nlong ones (where it's not). We rely on LLMs to create optimised\npseudo-summaries of long videos using segment descriptions from short ones.\nThese pseudo-summaries are used as training data for a model that generates\nlong-form video summaries, bypassing the need for expensive annotations of long\nvideos. Specifically, we adopt a meta-prompting strategy to iteratively\ngenerate and refine creating pseudo-summaries of long videos. The strategy\nleverages short clip descriptions obtained from a supervised short video model\nto guide the summary. Each iteration uses three LLMs working in sequence: one\nto generate the pseudo-summary from clip descriptions, another to evaluate it,\nand a third to optimise the prompt of the generator. This iteration is\nnecessary because the quality of the pseudo-summaries is highly dependent on\nthe generator prompt, and varies widely among videos. We evaluate our summaries\nextensively on multiple datasets; our results show that ViSMaP achieves\nperformance comparable to fully supervised state-of-the-art models while\ngeneralising across domains without sacrificing performance. Code will be\nreleased upon publication.", "AI": {"tldr": "ViSMaP is an unsupervised system for summarizing long videos by leveraging LLMs to create pseudo-summaries from short video segment descriptions, avoiding costly annotations.", "motivation": "Existing models struggle with long videos due to sparse events and lack of annotations. ViSMaP bridges this gap by using short video data to train for long-form summarization.", "method": "Uses meta-prompting with three LLMs: one generates pseudo-summaries, another evaluates them, and a third optimizes the prompt. This iterative process refines summaries without long-video annotations.", "result": "ViSMaP matches supervised state-of-the-art performance and generalizes across domains without performance loss.", "conclusion": "ViSMaP provides a scalable, annotation-free solution for long-video summarization, achieving competitive results."}}
{"id": "2408.06276", "pdf": "https://arxiv.org/pdf/2408.06276", "abs": "https://arxiv.org/abs/2408.06276", "authors": ["Jieyong Kim", "Hyunseo Kim", "Hyunjin Cho", "SeongKu Kang", "Buru Chang", "Jinyoung Yeo", "Dongha Lee"], "title": "Review-driven Personalized Preference Reasoning with Large Language Models for Recommendation", "categories": ["cs.CL"], "comment": "Accepted to SIGIR 2025", "summary": "Recent advancements in Large Language Models (LLMs) have demonstrated\nexceptional performance across a wide range of tasks, generating significant\ninterest in their application to recommendation systems. However, existing\nmethods have not fully capitalized on the potential of LLMs, often constrained\nby limited input information or failing to fully utilize their advanced\nreasoning capabilities. To address these limitations, we introduce EXP3RT, a\nnovel LLM-based recommender designed to leverage rich preference information\ncontained in user and item reviews. EXP3RT is basically fine-tuned through\ndistillation from a teacher LLM to perform three key tasks in order: EXP3RT\nfirst extracts and encapsulates essential subjective preferences from raw\nreviews, aggregates and summarizes them according to specific criteria to\ncreate user and item profiles. It then generates detailed step-by-step\nreasoning followed by predicted rating, i.e., reasoning-enhanced rating\nprediction, by considering both subjective and objective information from\nuser/item profiles and item descriptions. This personalized preference\nreasoning from EXP3RT enhances rating prediction accuracy and also provides\nfaithful and reasonable explanations for recommendation. Extensive experiments\nshow that EXP3RT outperforms existing methods on both rating prediction and\ncandidate item reranking for top-k recommendation, while significantly\nenhancing the explainability of recommendation systems.", "AI": {"tldr": "EXP3RT is a novel LLM-based recommender that leverages user and item reviews for enhanced preference reasoning, improving rating prediction and explainability.", "motivation": "Existing LLM-based recommendation methods underutilize LLMs' reasoning capabilities and input information, limiting their potential.", "method": "EXP3RT fine-tunes an LLM to extract preferences from reviews, create profiles, and perform reasoning-enhanced rating prediction.", "result": "EXP3RT outperforms existing methods in rating prediction and reranking, while enhancing explainability.", "conclusion": "EXP3RT effectively leverages LLMs for better recommendations and explanations, addressing prior limitations."}}
{"id": "2504.15876", "pdf": "https://arxiv.org/pdf/2504.15876", "abs": "https://arxiv.org/abs/2504.15876", "authors": ["Qizhen Wu Lei Chen", "Kexin Liu", "Jinhu L\u00fc"], "title": "Bidirectional Task-Motion Planning Based on Hierarchical Reinforcement Learning for Strategic Confrontation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "In swarm robotics, confrontation scenarios, including strategic\nconfrontations, require efficient decision-making that integrates discrete\ncommands and continuous actions. Traditional task and motion planning methods\nseparate decision-making into two layers, but their unidirectional structure\nfails to capture the interdependence between these layers, limiting\nadaptability in dynamic environments. Here, we propose a novel bidirectional\napproach based on hierarchical reinforcement learning, enabling dynamic\ninteraction between the layers. This method effectively maps commands to task\nallocation and actions to path planning, while leveraging cross-training\ntechniques to enhance learning across the hierarchical framework. Furthermore,\nwe introduce a trajectory prediction model that bridges abstract task\nrepresentations with actionable planning goals. In our experiments, it achieves\nover 80\\% in confrontation win rate and under 0.01 seconds in decision time,\noutperforming existing approaches. Demonstrations through large-scale tests and\nreal-world robot experiments further emphasize the generalization capabilities\nand practical applicability of our method.", "AI": {"tldr": "A bidirectional hierarchical reinforcement learning method is proposed for swarm robotics in confrontation scenarios, integrating discrete commands and continuous actions, outperforming traditional methods with an 80% win rate and fast decision times.", "motivation": "Traditional task and motion planning methods lack adaptability in dynamic environments due to their unidirectional structure, failing to capture the interdependence between decision layers.", "method": "A bidirectional hierarchical reinforcement learning approach is introduced, combining cross-training techniques and a trajectory prediction model to link task allocation and path planning.", "result": "Achieves over 80% confrontation win rate and under 0.01 seconds in decision time, with successful large-scale and real-world robot experiments.", "conclusion": "The method demonstrates superior adaptability, generalization, and practical applicability in dynamic confrontation scenarios."}}
{"id": "2504.15930", "pdf": "https://arxiv.org/pdf/2504.15930", "abs": "https://arxiv.org/abs/2504.15930", "authors": ["Yinmin Zhong", "Zili Zhang", "Xiaoniu Song", "Hanpeng Hu", "Chao Jin", "Bingyang Wu", "Nuo Chen", "Yukun Chen", "Yu Zhou", "Changyi Wan", "Hongyu Zhou", "Yimin Jiang", "Yibo Zhu", "Daxin Jiang"], "title": "StreamRL: Scalable, Heterogeneous, and Elastic RL for LLMs with Disaggregated Stream Generation", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Reinforcement learning (RL) has become the core post-training technique for\nlarge language models (LLMs). RL for LLMs involves two stages: generation and\ntraining. The LLM first generates samples online, which are then used to derive\nrewards for training. The conventional view holds that the colocated\narchitecture, where the two stages share resources via temporal multiplexing,\noutperforms the disaggregated architecture, in which dedicated resources are\nassigned to each stage. However, in real-world deployments, we observe that the\ncolocated architecture suffers from resource coupling, where the two stages are\nconstrained to use the same resources. This coupling compromises the\nscalability and cost-efficiency of colocated RL in large-scale training. In\ncontrast, the disaggregated architecture allows for flexible resource\nallocation, supports heterogeneous training setups, and facilitates\ncross-datacenter deployment.\n  StreamRL is designed with disaggregation from first principles and fully\nunlocks its potential by addressing two types of performance bottlenecks in\nexisting disaggregated RL frameworks: pipeline bubbles, caused by stage\ndependencies, and skewness bubbles, resulting from long-tail output length\ndistributions. To address pipeline bubbles, StreamRL breaks the traditional\nstage boundary in synchronous RL algorithms through stream generation and\nachieves full overlapping in asynchronous RL. To address skewness bubbles,\nStreamRL employs an output-length ranker model to identify long-tail samples\nand reduces generation time via skewness-aware dispatching and scheduling.\nExperiments show that StreamRL improves throughput by up to 2.66x compared to\nexisting state-of-the-art systems, and improves cost-effectiveness by up to\n1.33x in a heterogeneous, cross-datacenter setting.", "AI": {"tldr": "StreamRL introduces a disaggregated architecture for RL in LLMs, addressing bottlenecks like pipeline and skewness bubbles, improving throughput and cost-efficiency.", "motivation": "The colocated architecture for RL in LLMs suffers from resource coupling, limiting scalability and cost-efficiency.", "method": "StreamRL uses stream generation and asynchronous RL to address pipeline bubbles, and a ranker model for skewness bubbles.", "result": "StreamRL improves throughput by up to 2.66x and cost-effectiveness by up to 1.33x.", "conclusion": "Disaggregated RL with StreamRL outperforms colocated architectures, offering scalability and efficiency."}}
{"id": "2504.15928", "pdf": "https://arxiv.org/pdf/2504.15928", "abs": "https://arxiv.org/abs/2504.15928", "authors": ["Meng Wang", "Tian Lin", "Qingshan Hou", "Aidi Lin", "Jingcheng Wang", "Qingsheng Peng", "Truong X. Nguyen", "Danqi Fang", "Ke Zou", "Ting Xu", "Cancan Xue", "Ten Cheer Quek", "Qinkai Yu", "Minxin Liu", "Hui Zhou", "Zixuan Xiao", "Guiqin He", "Huiyu Liang", "Tingkun Shi", "Man Chen", "Linna Liu", "Yuanyuan Peng", "Lianyu Wang", "Qiuming Hu", "Junhong Chen", "Zhenhua Zhang", "Cheng Chen", "Yitian Zhao", "Dianbo Liu", "Jianhua Wu", "Xinjian Chen", "Changqing Zhang", "Triet Thanh Nguyen", "Yanda Meng", "Yalin Zheng", "Yih Chung Tham", "Carol Y. Cheung", "Huazhu Fu", "Haoyu Chen", "Ching-Yu Cheng"], "title": "A Clinician-Friendly Platform for Ophthalmic Image Analysis Without Technical Barriers", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Artificial intelligence (AI) shows remarkable potential in medical imaging\ndiagnostics, but current models typically require retraining when deployed\nacross different clinical centers, limiting their widespread adoption. We\nintroduce GlobeReady, a clinician-friendly AI platform that enables ocular\ndisease diagnosis without retraining/fine-tuning or technical expertise.\nGlobeReady achieves high accuracy across imaging modalities: 93.9-98.5% for an\n11-category fundus photo dataset and 87.2-92.7% for a 15-category OCT dataset.\nThrough training-free local feature augmentation, it addresses domain shifts\nacross centers and populations, reaching an average accuracy of 88.9% across\nfive centers in China, 86.3% in Vietnam, and 90.2% in the UK. The built-in\nconfidence-quantifiable diagnostic approach further boosted accuracy to\n94.9-99.4% (fundus) and 88.2-96.2% (OCT), while identifying out-of-distribution\ncases at 86.3% (49 CFP categories) and 90.6% (13 OCT categories). Clinicians\nfrom multiple countries rated GlobeReady highly (average 4.6 out of 5) for its\nusability and clinical relevance. These results demonstrate GlobeReady's\nrobust, scalable diagnostic capability and potential to support ophthalmic care\nwithout technical barriers.", "AI": {"tldr": "GlobeReady is an AI platform for ocular disease diagnosis that works across clinical centers without retraining, achieving high accuracy and clinician approval.", "motivation": "Current AI models for medical imaging require retraining for different centers, limiting adoption. GlobeReady aims to overcome this barrier.", "method": "Uses training-free local feature augmentation to handle domain shifts across centers and populations. Includes a confidence-quantifiable diagnostic approach.", "result": "Achieves high accuracy (87.2-98.5%) across datasets and centers. Clinicians rated it highly (4.6/5) for usability.", "conclusion": "GlobeReady offers robust, scalable diagnostic support for ophthalmic care without technical barriers."}}
{"id": "2409.18110", "pdf": "https://arxiv.org/pdf/2409.18110", "abs": "https://arxiv.org/abs/2409.18110", "authors": ["Hung-Ting Chen", "Eunsol Choi"], "title": "Open-World Evaluation for Retrieving Diverse Perspectives", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "We study retrieving a set of documents that covers various perspectives on a\ncomplex and contentious question (e.g., will ChatGPT do more harm than good?).\nWe curate a Benchmark for Retrieval Diversity for Subjective questions (BERDS),\nwhere each example consists of a question and diverse perspectives associated\nwith the question, sourced from survey questions and debate websites. On this\ndata, retrievers paired with a corpus are evaluated to surface a document set\nthat contains diverse perspectives. Our framing diverges from most retrieval\ntasks in that document relevancy cannot be decided by simple string matches to\nreferences. Instead, we build a language model-based automatic evaluator that\ndecides whether each retrieved document contains a perspective. This allows us\nto evaluate the performance of three different types of corpus (Wikipedia, web\nsnapshot, and corpus constructed on the fly with retrieved pages from the\nsearch engine) paired with retrievers. Retrieving diverse documents remains\nchallenging, with the outputs from existing retrievers covering all\nperspectives on only 40% of the examples. We further study the effectiveness of\nquery expansion and diversity-focused reranking approaches and analyze\nretriever sycophancy.", "AI": {"tldr": "The paper introduces BERDS, a benchmark for evaluating document retrieval diversity on subjective questions, using a language model-based evaluator to assess perspective coverage. It tests retrievers on three corpora, finding current methods only cover all perspectives 40% of the time, and explores query expansion and reranking to improve diversity.", "motivation": "To address the challenge of retrieving diverse perspectives on contentious questions, where traditional relevancy metrics (e.g., string matching) fail.", "method": "Curates BERDS benchmark, uses a language model-based evaluator, and tests retrievers on Wikipedia, web snapshots, and dynamically constructed corpora. Explores query expansion and diversity-focused reranking.", "result": "Existing retrievers cover all perspectives in only 40% of cases. Query expansion and reranking show potential but remain challenging.", "conclusion": "Retrieving diverse perspectives is difficult; current methods are insufficient, but proposed approaches (query expansion, reranking) offer avenues for improvement."}}
{"id": "2504.15894", "pdf": "https://arxiv.org/pdf/2504.15894", "abs": "https://arxiv.org/abs/2504.15894", "authors": ["Chengbo Zheng", "Tim Miller", "Alina Bialkowski", "H Peter Soyer", "Monika Janda"], "title": "Supporting Data-Frame Dynamics in AI-assisted Decision Making", "categories": ["cs.HC", "cs.AI"], "comment": "Presented at the 2025 ACM Workshop on Human-AI Interaction for\n  Augmented Reasoning, Report Number: CHI25-WS-AUGMENTED-REASONING", "summary": "High stakes decision-making often requires a continuous interplay between\nevolving evidence and shifting hypotheses, a dynamic that is not well supported\nby current AI decision support systems. In this paper, we introduce a\nmixed-initiative framework for AI assisted decision making that is grounded in\nthe data-frame theory of sensemaking and the evaluative AI paradigm. Our\napproach enables both humans and AI to collaboratively construct, validate, and\nadapt hypotheses. We demonstrate our framework with an AI-assisted skin cancer\ndiagnosis prototype that leverages a concept bottleneck model to facilitate\ninterpretable interactions and dynamic updates to diagnostic hypotheses.", "AI": {"tldr": "A mixed-initiative AI framework for collaborative decision-making, tested in skin cancer diagnosis.", "motivation": "Current AI systems lack support for dynamic interplay between evolving evidence and shifting hypotheses in high-stakes decisions.", "method": "Uses data-frame theory and evaluative AI paradigm for human-AI collaboration in hypothesis construction and validation.", "result": "Demonstrated with an interpretable AI-assisted skin cancer diagnosis prototype using concept bottleneck models.", "conclusion": "The framework effectively supports dynamic, interpretable decision-making in high-stakes scenarios."}}
{"id": "2504.15956", "pdf": "https://arxiv.org/pdf/2504.15956", "abs": "https://arxiv.org/abs/2504.15956", "authors": ["Jerry Yao-Chieh Hu", "Hude Liu", "Hong-Yu Chen", "Weimin Wu", "Han Liu"], "title": "Universal Approximation with Softmax Attention", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "We prove that with linear transformations, both (i) two-layer self-attention\nand (ii) one-layer self-attention followed by a softmax function are universal\napproximators for continuous sequence-to-sequence functions on compact domains.\nOur main technique is a new interpolation-based method for analyzing\nattention's internal mechanism. This leads to our key insight: self-attention\nis able to approximate a generalized version of ReLU to arbitrary precision,\nand hence subsumes many known universal approximators. Building on these, we\nshow that two-layer multi-head attention alone suffices as a\nsequence-to-sequence universal approximator. In contrast, prior works rely on\nfeed-forward networks to establish universal approximation in Transformers.\nFurthermore, we extend our techniques to show that, (softmax-)attention-only\nlayers are capable of approximating various statistical models in-context. We\nbelieve these techniques hold independent interest.", "AI": {"tldr": "The paper proves that two-layer self-attention and one-layer self-attention with softmax are universal approximators for sequence-to-sequence functions. It introduces an interpolation-based method to analyze attention, showing it can approximate ReLU-like functions.", "motivation": "To demonstrate the universal approximation capabilities of self-attention mechanisms without relying on feed-forward networks, as prior works did.", "method": "Uses a new interpolation-based technique to analyze self-attention, showing it can approximate generalized ReLU functions. Extends this to prove two-layer multi-head attention suffices for universal approximation.", "result": "Self-attention can approximate ReLU-like functions and serves as a universal approximator for sequence-to-sequence tasks. Attention-only layers can also approximate statistical models in-context.", "conclusion": "Self-attention mechanisms alone, without feed-forward networks, are powerful universal approximators, offering new insights into Transformers' capabilities."}}
{"id": "2504.15929", "pdf": "https://arxiv.org/pdf/2504.15929", "abs": "https://arxiv.org/abs/2504.15929", "authors": ["Saban Ozturk", "Melih B. Yilmaz", "Muti Kara", "M. Talat Yavuz", "Aykut Ko\u00e7", "Tolga \u00c7ukur"], "title": "Meta-Entity Driven Triplet Mining for Aligning Medical Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "18 pages, 7 figures, 6 tables", "summary": "Diagnostic imaging relies on interpreting both images and radiology reports,\nbut the growing data volumes place significant pressure on medical experts,\nyielding increased errors and workflow backlogs. Medical vision-language models\n(med-VLMs) have emerged as a powerful framework to efficiently process\nmultimodal imaging data, particularly in chest X-ray (CXR) evaluations, albeit\ntheir performance hinges on how well image and text representations are\naligned. Existing alignment methods, predominantly based on contrastive\nlearning, prioritize separation between disease classes over segregation of\nfine-grained pathology attributes like location, size or severity, leading to\nsuboptimal representations. Here, we propose MedTrim (Meta-entity-driven\nTriplet mining), a novel method that enhances image-text alignment through\nmultimodal triplet learning synergistically guided by disease class as well as\nadjectival and directional pathology descriptors. Unlike common alignment\nmethods that separate broad disease classes, MedTrim leverages structured\nmeta-entity information to preserve subtle but clinically significant\nintra-class variations. For this purpose, we first introduce an ontology-based\nentity recognition module that extracts pathology-specific meta-entities from\nCXR reports, as annotations on pathology attributes are rare in public\ndatasets. For refined sample selection in triplet mining, we then introduce a\nnovel score function that captures an aggregate measure of inter-sample\nsimilarity based on disease classes and adjectival/directional descriptors.\nLastly, we introduce a multimodal triplet alignment objective for explicit\nwithin- and cross-modal alignment between samples sharing detailed pathology\ncharacteristics. Our demonstrations indicate that MedTrim improves performance\nin downstream retrieval and classification tasks compared to state-of-the-art\nalignment methods.", "AI": {"tldr": "MedTrim improves image-text alignment in medical vision-language models by leveraging meta-entity-driven triplet mining, outperforming existing methods in retrieval and classification tasks.", "motivation": "Addressing the limitations of current contrastive learning methods in med-VLMs, which fail to capture fine-grained pathology attributes, leading to suboptimal performance.", "method": "Introduces MedTrim, a method combining ontology-based entity recognition, a novel score function for triplet mining, and a multimodal triplet alignment objective to enhance alignment of detailed pathology characteristics.", "result": "MedTrim outperforms state-of-the-art alignment methods in downstream tasks like retrieval and classification.", "conclusion": "MedTrim effectively aligns image and text representations by preserving clinically significant intra-class variations, improving diagnostic imaging workflows."}}
{"id": "2410.02355", "pdf": "https://arxiv.org/pdf/2410.02355", "abs": "https://arxiv.org/abs/2410.02355", "authors": ["Junfeng Fang", "Houcheng Jiang", "Kun Wang", "Yunshan Ma", "Shi Jie", "Xiang Wang", "Xiangnan He", "Tat-seng Chua"], "title": "AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) often exhibit hallucinations due to incorrect or\noutdated knowledge. Hence, model editing methods have emerged to enable\ntargeted knowledge updates. To achieve this, a prevailing paradigm is the\nlocating-then-editing approach, which first locates influential parameters and\nthen edits them by introducing a perturbation. While effective, current studies\nhave demonstrated that this perturbation inevitably disrupt the originally\npreserved knowledge within LLMs, especially in sequential editing scenarios. To\naddress this, we introduce AlphaEdit, a novel solution that projects\nperturbation onto the null space of the preserved knowledge before applying it\nto the parameters. We theoretically prove that this projection ensures the\noutput of post-edited LLMs remains unchanged when queried about the preserved\nknowledge, thereby mitigating the issue of disruption. Extensive experiments on\nvarious LLMs, including LLaMA3, GPT2-XL, and GPT-J, show that AlphaEdit boosts\nthe performance of most locating-then-editing methods by an average of 36.7%\nwith a single line of additional code for projection solely. Our code is\navailable at: https://github.com/jianghoucheng/AlphaEdit.", "AI": {"tldr": "AlphaEdit introduces a projection method to update LLM knowledge without disrupting preserved information, improving performance by 36.7%.", "motivation": "LLMs suffer from hallucinations due to outdated knowledge, and current editing methods disrupt preserved knowledge.", "method": "AlphaEdit projects perturbations onto the null space of preserved knowledge before applying them.", "result": "Experiments show a 36.7% performance boost in LLMs like LLaMA3, GPT2-XL, and GPT-J.", "conclusion": "AlphaEdit effectively mitigates knowledge disruption in LLMs during sequential editing."}}
{"id": "2504.15912", "pdf": "https://arxiv.org/pdf/2504.15912", "abs": "https://arxiv.org/abs/2504.15912", "authors": ["Riley Pierson", "Armin Moin"], "title": "Automated Bug Report Prioritization in Large Open-Source Projects", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large open-source projects receive a large number of issues (known as bugs),\nincluding software defect (i.e., bug) reports and new feature requests from\ntheir user and developer communities at a fast rate. The often limited project\nresources do not allow them to deal with all issues. Instead, they have to\nprioritize them according to the project's priorities and the issues'\nseverities. In this paper, we propose a novel approach to automated bug\nprioritization based on the natural language text of the bug reports that are\nstored in the open bug repositories of the issue-tracking systems. We conduct\ntopic modeling using a variant of LDA called TopicMiner-MTM and text\nclassification with the BERT large language model to achieve a higher\nperformance level compared to the state-of-the-art. Experimental results using\nan existing reference dataset containing 85,156 bug reports of the Eclipse\nPlatform project indicate that we outperform existing approaches in terms of\nAccuracy, Precision, Recall, and F1-measure of the bug report priority\nprediction.", "AI": {"tldr": "Proposes an automated bug prioritization method using TopicMiner-MTM and BERT, outperforming existing approaches in accuracy and other metrics.", "motivation": "Limited resources in open-source projects necessitate efficient bug prioritization.", "method": "Uses TopicMiner-MTM for topic modeling and BERT for text classification on bug reports.", "result": "Outperforms state-of-the-art methods in accuracy, precision, recall, and F1-measure on Eclipse Platform dataset.", "conclusion": "The approach effectively automates bug prioritization, improving efficiency in open-source projects."}}
{"id": "2504.15995", "pdf": "https://arxiv.org/pdf/2504.15995", "abs": "https://arxiv.org/abs/2504.15995", "authors": ["Sindhuja Madabushi", "Ahmad Faraz Khan", "Haider Ali", "Jin-Hee Cho"], "title": "OPUS-VFL: Incentivizing Optimal Privacy-Utility Tradeoffs in Vertical Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Vertical Federated Learning (VFL) enables organizations with disjoint feature\nspaces but shared user bases to collaboratively train models without sharing\nraw data. However, existing VFL systems face critical limitations: they often\nlack effective incentive mechanisms, struggle to balance privacy-utility\ntradeoffs, and fail to accommodate clients with heterogeneous resource\ncapabilities. These challenges hinder meaningful participation, degrade model\nperformance, and limit practical deployment. To address these issues, we\npropose OPUS-VFL, an Optimal Privacy-Utility tradeoff Strategy for VFL.\nOPUS-VFL introduces a novel, privacy-aware incentive mechanism that rewards\nclients based on a principled combination of model contribution, privacy\npreservation, and resource investment. It employs a lightweight leave-one-out\n(LOO) strategy to quantify feature importance per client, and integrates an\nadaptive differential privacy mechanism that enables clients to dynamically\ncalibrate noise levels to optimize their individual utility. Our framework is\ndesigned to be scalable, budget-balanced, and robust to inference and poisoning\nattacks. Extensive experiments on benchmark datasets (MNIST, CIFAR-10, and\nCIFAR-100) demonstrate that OPUS-VFL significantly outperforms state-of-the-art\nVFL baselines in both efficiency and robustness. It reduces label inference\nattack success rates by up to 20%, increases feature inference reconstruction\nerror (MSE) by over 30%, and achieves up to 25% higher incentives for clients\nthat contribute meaningfully while respecting privacy and cost constraints.\nThese results highlight the practicality and innovation of OPUS-VFL as a\nsecure, fair, and performance-driven solution for real-world VFL.", "AI": {"tldr": "OPUS-VFL is a novel VFL framework addressing privacy-utility tradeoffs, incentives, and resource heterogeneity, outperforming existing methods in efficiency and robustness.", "motivation": "Existing VFL systems lack effective incentives, struggle with privacy-utility tradeoffs, and fail to handle resource heterogeneity, limiting practical deployment.", "method": "OPUS-VFL introduces a privacy-aware incentive mechanism, LOO for feature importance, and adaptive differential privacy for dynamic noise calibration.", "result": "OPUS-VFL reduces attack success rates by 20%, increases reconstruction error by 30%, and offers 25% higher incentives while maintaining privacy.", "conclusion": "OPUS-VFL is a secure, fair, and high-performance solution for real-world VFL challenges."}}
{"id": "2504.15931", "pdf": "https://arxiv.org/pdf/2504.15931", "abs": "https://arxiv.org/abs/2504.15931", "authors": ["Ekaterina Kondrateva", "Sandzhi Barg", "Mikhail Vasiliev"], "title": "Benchmarking the Reproducibility of Brain MRI Segmentation Across Scanners and Time", "categories": ["cs.CV"], "comment": null, "summary": "Accurate and reproducible brain morphometry from structural MRI is critical\nfor monitoring neuroanatomical changes across time and across imaging domains.\nAlthough deep learning has accelerated segmentation workflows, scanner-induced\nvariability and reproducibility limitations remain-especially in longitudinal\nand multi-site settings. In this study, we benchmark two modern segmentation\npipelines, FastSurfer and SynthSeg, both integrated into FreeSurfer, one of the\nmost widely adopted tools in neuroimaging.\n  Using two complementary datasets - a 17-year longitudinal cohort (SIMON) and\na 9-site test-retest cohort (SRPBS)-we quantify inter-scan segmentation\nvariability using Dice coefficient, Surface Dice, Hausdorff Distance (HD95),\nand Mean Absolute Percentage Error (MAPE). Our results reveal up to 7-8% volume\nvariation in small subcortical structures such as the amygdala and ventral\ndiencephalon, even under controlled test-retest conditions. This raises a key\nquestion: is it feasible to detect subtle longitudinal changes on the order of\n5-10% in pea-sized brain regions, given the magnitude of domain-induced\nmorphometric noise?\n  We further analyze the effects of registration templates and interpolation\nmodes, and propose surface-based quality filtering to improve segmentation\nreliability. This study provides a reproducible benchmark for morphometric\nreproducibility and emphasizes the need for harmonization strategies in\nreal-world neuroimaging studies.\n  Code and figures: https://github.com/kondratevakate/brain-mri-segmentation", "AI": {"tldr": "The study benchmarks FastSurfer and SynthSeg for brain segmentation, revealing 7-8% volume variation in small structures, and proposes quality filtering to improve reliability.", "motivation": "To address scanner-induced variability and reproducibility limitations in longitudinal and multi-site neuroimaging studies.", "method": "Benchmarking FastSurfer and SynthSeg using two datasets (SIMON and SRPBS) and metrics like Dice coefficient, Surface Dice, HD95, and MAPE.", "result": "Found 7-8% volume variation in small subcortical structures, questioning the feasibility of detecting subtle longitudinal changes.", "conclusion": "Highlights the need for harmonization strategies and provides a reproducible benchmark for morphometric reproducibility."}}
{"id": "2410.19503", "pdf": "https://arxiv.org/pdf/2410.19503", "abs": "https://arxiv.org/abs/2410.19503", "authors": ["Jahyun Koo", "Yerin Hwang", "Yongil Kim", "Taegwan Kang", "Hyunkyung Bae", "Kyomin Jung"], "title": "SWITCH: Studying with Teacher for Knowledge Distillation of Large Language Models", "categories": ["cs.CL"], "comment": "NAACL 2025 Findings", "summary": "Despite the success of Large Language Models (LLMs), they still face\nchallenges related to high inference costs and memory requirements. To address\nthese issues, Knowledge Distillation (KD) has emerged as a popular method for\nmodel compression, with student-generated outputs (SGOs) as training data being\nparticularly notable for reducing the mismatch between training and inference.\nHowever, SGOs often produce noisy and biased sequences, which can lead to\nmisguidance from the teacher model, especially in long sequences. To mitigate\nthese challenges, we propose SWITCH (Studying WIth TeaCHer for Knowledge\nDistillation), a novel approach that strategically incorporates the teacher\nmodel during the student's sequence generation. SWITCH identifies discrepancies\nbetween the token probabilities of the teacher and student models, allowing the\nteacher to intervene selectively, particularly in long sequences that are more\nprone to teacher misguidance. Extensive experimental results across three model\nfamilies and five instruction-following datasets show that SWITCH surpasses\ntraditional KD methods, particularly excelling in the generation of long\nsequential data.", "AI": {"tldr": "SWITCH improves Knowledge Distillation by selectively incorporating teacher guidance to reduce noise and bias in student-generated outputs, especially for long sequences.", "motivation": "Addressing the challenges of noisy and biased student-generated outputs in Knowledge Distillation, which can misguide the teacher model.", "method": "SWITCH identifies discrepancies in token probabilities between teacher and student models, enabling selective teacher intervention in long sequences.", "result": "SWITCH outperforms traditional KD methods, particularly in generating long sequential data, across multiple model families and datasets.", "conclusion": "SWITCH effectively mitigates teacher misguidance in Knowledge Distillation, enhancing performance for long sequences."}}
{"id": "2504.15927", "pdf": "https://arxiv.org/pdf/2504.15927", "abs": "https://arxiv.org/abs/2504.15927", "authors": ["Ling Cheng", "Jiashu Pu", "Ruicheng Liang", "Qian Shao", "Hezhe Qiao", "Feida Zhu"], "title": "New Recipe for Semi-supervised Community Detection: Clique Annealing under Crystallization Kinetics", "categories": ["cs.SI", "cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2203.05898 by other authors", "summary": "Semi-supervised community detection methods are widely used for identifying\nspecific communities due to the label scarcity. Existing semi-supervised\ncommunity detection methods typically involve two learning stages learning in\nboth initial identification and subsequent adjustment, which often starts from\nan unreasonable community core candidate. Moreover, these methods encounter\nscalability issues because they depend on reinforcement learning and generative\nadversarial networks, leading to higher computational costs and restricting the\nselection of candidates. To address these limitations, we draw a parallel\nbetween crystallization kinetics and community detection to integrate the\nspontaneity of the annealing process into community detection. Specifically, we\nliken community detection to identifying a crystal subgrain (core) that expands\ninto a complete grain (community) through a process similar to annealing. Based\non this finding, we propose CLique ANNealing (CLANN), which applies kinetics\nconcepts to community detection by integrating these principles into the\noptimization process to strengthen the consistency of the community core.\nSubsequently, a learning-free Transitive Annealer was employed to refine the\nfirst-stage candidates by merging neighboring cliques and repositioning the\ncommunity core, enabling a spontaneous growth process that enhances\nscalability. Extensive experiments on \\textbf{43} different network settings\ndemonstrate that CLANN outperforms state-of-the-art methods across multiple\nreal-world datasets, showcasing its exceptional efficacy and efficiency in\ncommunity detection.", "AI": {"tldr": "CLANN introduces a novel semi-supervised community detection method inspired by crystallization kinetics, improving scalability and accuracy by refining community cores through annealing-like processes.", "motivation": "Existing methods suffer from high computational costs and unreasonable initial community cores, limiting scalability and accuracy.", "method": "CLANN integrates crystallization kinetics into community detection, using a learning-free Transitive Annealer to refine community cores by merging cliques and repositioning them.", "result": "CLANN outperforms state-of-the-art methods on 43 network settings, demonstrating superior efficacy and efficiency.", "conclusion": "CLANN's innovative approach addresses scalability and accuracy issues in semi-supervised community detection, offering a promising solution."}}
{"id": "2504.16020", "pdf": "https://arxiv.org/pdf/2504.16020", "abs": "https://arxiv.org/abs/2504.16020", "authors": ["Soham Sane"], "title": "AlphaGrad: Non-Linear Gradient Normalization Optimizer", "categories": ["cs.LG", "cs.AI", "cs.NE", "stat.ML"], "comment": null, "summary": "We introduce AlphaGrad, a memory-efficient, conditionally stateless optimizer\naddressing the memory overhead and hyperparameter complexity of adaptive\nmethods like Adam. AlphaGrad enforces scale invariance via tensor-wise L2\ngradient normalization followed by a smooth hyperbolic tangent transformation,\n$g' = \\tanh(\\alpha \\cdot \\tilde{g})$, controlled by a single steepness\nparameter $\\alpha$. Our contributions include: (1) the AlphaGrad algorithm\nformulation; (2) a formal non-convex convergence analysis guaranteeing\nstationarity; (3) extensive empirical evaluation on diverse RL benchmarks (DQN,\nTD3, PPO). Compared to Adam, AlphaGrad demonstrates a highly context-dependent\nperformance profile. While exhibiting instability in off-policy DQN, it\nprovides enhanced training stability with competitive results in TD3 (requiring\ncareful $\\alpha$ tuning) and achieves substantially superior performance in\non-policy PPO. These results underscore the critical importance of empirical\n$\\alpha$ selection, revealing strong interactions between the optimizer's\ndynamics and the underlying RL algorithm. AlphaGrad presents a compelling\nalternative optimizer for memory-constrained scenarios and shows significant\npromise for on-policy learning regimes where its stability and efficiency\nadvantages can be particularly impactful.", "AI": {"tldr": "AlphaGrad is a memory-efficient optimizer with a single hyperparameter, outperforming Adam in some RL tasks but requiring careful tuning.", "motivation": "Address memory overhead and hyperparameter complexity in adaptive optimizers like Adam.", "method": "Uses tensor-wise L2 gradient normalization and a tanh transformation controlled by a steepness parameter.", "result": "Performance varies by RL task: unstable in DQN, stable in TD3, superior in PPO.", "conclusion": "AlphaGrad is a promising alternative for memory-constrained and on-policy RL scenarios."}}
{"id": "2504.15932", "pdf": "https://arxiv.org/pdf/2504.15932", "abs": "https://arxiv.org/abs/2504.15932", "authors": ["Wang Lin", "Liyu Jia", "Wentao Hu", "Kaihang Pan", "Zhongqi Yue", "Wei Zhao", "Jingyuan Chen", "Fei Wu", "Hanwang Zhang"], "title": "Reasoning Physical Video Generation with Diffusion Timestep Tokens via Reinforcement Learning", "categories": ["cs.CV"], "comment": null, "summary": "Despite recent progress in video generation, producing videos that adhere to\nphysical laws remains a significant challenge. Traditional diffusion-based\nmethods struggle to extrapolate to unseen physical conditions (eg, velocity)\ndue to their reliance on data-driven approximations. To address this, we\npropose to integrate symbolic reasoning and reinforcement learning to enforce\nphysical consistency in video generation. We first introduce the Diffusion\nTimestep Tokenizer (DDT), which learns discrete, recursive visual tokens by\nrecovering visual attributes lost during the diffusion process. The recursive\nvisual tokens enable symbolic reasoning by a large language model. Based on it,\nwe propose the Phys-AR framework, which consists of two stages: The first stage\nuses supervised fine-tuning to transfer symbolic knowledge, while the second\nstage applies reinforcement learning to optimize the model's reasoning\nabilities through reward functions based on physical conditions. Our approach\nallows the model to dynamically adjust and improve the physical properties of\ngenerated videos, ensuring adherence to physical laws. Experimental results\ndemonstrate that PhysAR can generate videos that are physically consistent.", "AI": {"tldr": "The paper proposes Phys-AR, a framework combining symbolic reasoning and reinforcement learning to ensure physical consistency in video generation, outperforming traditional diffusion-based methods.", "motivation": "Existing diffusion-based video generation methods fail to adhere to physical laws, especially under unseen conditions, due to data-driven limitations.", "method": "Introduces Diffusion Timestep Tokenizer (DDT) for recursive visual tokens, enabling symbolic reasoning. Phys-AR uses supervised fine-tuning and reinforcement learning to enforce physical consistency.", "result": "Phys-AR generates physically consistent videos, validated by experiments.", "conclusion": "The integration of symbolic reasoning and reinforcement learning effectively addresses physical consistency in video generation."}}
{"id": "2411.04223", "pdf": "https://arxiv.org/pdf/2411.04223", "abs": "https://arxiv.org/abs/2411.04223", "authors": ["Weiliang Zhao", "Daniel Ben-Levi", "Wei Hao", "Junfeng Yang", "Chengzhi Mao"], "title": "Diversity Helps Jailbreak Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "We have uncovered a powerful jailbreak technique that leverages large\nlanguage models' ability to diverge from prior context, enabling them to bypass\nsafety constraints and generate harmful outputs. By simply instructing the LLM\nto deviate and obfuscate previous attacks, our method dramatically outperforms\nexisting approaches, achieving up to a 62.83% higher success rate in\ncompromising ten leading chatbots, including GPT-4, Gemini, and Llama, while\nusing only 12.9% of the queries. This revelation exposes a critical flaw in\ncurrent LLM safety training, suggesting that existing methods may merely mask\nvulnerabilities rather than eliminate them. Our findings sound an urgent alarm\nfor the need to revolutionize testing methodologies to ensure robust and\nreliable LLM security.", "AI": {"tldr": "A new jailbreak technique exploits LLMs' context divergence to bypass safety constraints, outperforming existing methods with 62.83% higher success rates while using fewer queries.", "motivation": "To expose vulnerabilities in current LLM safety training and highlight the inadequacy of existing methods in eliminating risks.", "method": "Instructs LLMs to deviate and obfuscate prior attacks, requiring fewer queries to compromise chatbots like GPT-4, Gemini, and Llama.", "result": "Achieves up to 62.83% higher success rate in compromising leading chatbots, revealing flaws in safety training.", "conclusion": "Urges a revolution in testing methodologies to ensure robust LLM security, as current methods may only mask vulnerabilities."}}
{"id": "2504.15972", "pdf": "https://arxiv.org/pdf/2504.15972", "abs": "https://arxiv.org/abs/2504.15972", "authors": ["Sophie C. Pope", "Andrew Barovic", "Armin Moin"], "title": "Bug Destiny Prediction in Large Open-Source Software Repositories through Sentiment Analysis and BERT Topic Modeling", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "This study explores a novel approach to predicting key bug-related outcomes,\nincluding the time to resolution, time to fix, and ultimate status of a bug,\nusing data from the Bugzilla Eclipse Project. Specifically, we leverage\nfeatures available before a bug is resolved to enhance predictive accuracy. Our\nmethodology incorporates sentiment analysis to derive both an emotionality\nscore and a sentiment classification (positive or negative). Additionally, we\nintegrate the bug's priority level and its topic, extracted using a BERTopic\nmodel, as features for a Convolutional Neural Network (CNN) and a Multilayer\nPerceptron (MLP). Our findings indicate that the combination of BERTopic and\nsentiment analysis can improve certain model performance metrics. Furthermore,\nwe observe that balancing model inputs enhances practical applicability, albeit\nat the cost of a significant reduction in accuracy in most cases. To address\nour primary objectives, predicting time-to-resolution, time-to-fix, and bug\ndestiny, we employ both binary classification and exact time value predictions,\nallowing for a comparative evaluation of their predictive effectiveness.\nResults demonstrate that sentiment analysis serves as a valuable predictor of a\nbug's eventual outcome, particularly in determining whether it will be fixed.\nHowever, its utility is less pronounced when classifying bugs into more complex\nor unconventional outcome categories.", "AI": {"tldr": "The paper introduces a method combining sentiment analysis, BERTopic, and neural networks to predict bug-related outcomes like resolution time and status, showing improved accuracy but trade-offs in practicality.", "motivation": "To enhance predictive accuracy for bug-related outcomes (e.g., resolution time, fix status) using pre-resolution data from Bugzilla Eclipse Project.", "method": "Uses sentiment analysis (emotionality score and sentiment classification), BERTopic for topic extraction, and CNN/MLP models. Balances inputs for practicality.", "result": "Sentiment analysis is effective for predicting bug fixes but less so for complex outcomes. Combining BERTopic and sentiment improves some metrics.", "conclusion": "Sentiment analysis is valuable for bug outcome prediction, though balancing inputs reduces accuracy. The method shows promise but has limitations for complex classifications."}}
{"id": "2504.16032", "pdf": "https://arxiv.org/pdf/2504.16032", "abs": "https://arxiv.org/abs/2504.16032", "authors": ["Yazan Otoum", "Arghavan Asad", "Amiya Nayak"], "title": "LLMs meet Federated Learning for Scalable and Secure IoT Management", "categories": ["cs.LG", "cs.AI", "cs.ET"], "comment": "This work has been submitted to the IEEE Global Communications\n  Conference (GLOBECOM) 2025 for possible publication", "summary": "The rapid expansion of IoT ecosystems introduces severe challenges in\nscalability, security, and real-time decision-making. Traditional centralized\narchitectures struggle with latency, privacy concerns, and excessive resource\nconsumption, making them unsuitable for modern large-scale IoT deployments.\nThis paper presents a novel Federated Learning-driven Large Language Model\n(FL-LLM) framework, designed to enhance IoT system intelligence while ensuring\ndata privacy and computational efficiency. The framework integrates Generative\nIoT (GIoT) models with a Gradient Sensing Federated Strategy (GSFS),\ndynamically optimizing model updates based on real-time network conditions. By\nleveraging a hybrid edge-cloud processing architecture, our approach balances\nintelligence, scalability, and security in distributed IoT environments.\nEvaluations on the IoT-23 dataset demonstrate that our framework improves model\naccuracy, reduces response latency, and enhances energy efficiency,\noutperforming traditional FL techniques (i.e., FedAvg, FedOpt). These findings\nhighlight the potential of integrating LLM-powered federated learning into\nlarge-scale IoT ecosystems, paving the way for more secure, scalable, and\nadaptive IoT management solutions.", "AI": {"tldr": "A Federated Learning-driven Large Language Model (FL-LLM) framework is proposed to address scalability, security, and real-time decision-making in IoT, outperforming traditional methods.", "motivation": "Challenges in IoT like latency, privacy, and resource consumption with centralized architectures necessitate a scalable, secure, and efficient solution.", "method": "The framework combines Generative IoT models with a Gradient Sensing Federated Strategy (GSFS) and a hybrid edge-cloud architecture for dynamic optimization.", "result": "Evaluations on the IoT-23 dataset show improved accuracy, reduced latency, and better energy efficiency compared to traditional FL techniques.", "conclusion": "The FL-LLM framework demonstrates potential for secure, scalable, and adaptive IoT management, integrating LLM-powered federated learning."}}
{"id": "2504.15958", "pdf": "https://arxiv.org/pdf/2504.15958", "abs": "https://arxiv.org/abs/2504.15958", "authors": ["Zebin Yao", "Lei Ren", "Huixing Jiang", "Chen Wei", "Xiaojie Wang", "Ruifan Li", "Fangxiang Feng"], "title": "FreeGraftor: Training-Free Cross-Image Feature Grafting for Subject-Driven Text-to-Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "Subject-driven image generation aims to synthesize novel scenes that\nfaithfully preserve subject identity from reference images while adhering to\ntextual guidance, yet existing methods struggle with a critical trade-off\nbetween fidelity and efficiency. Tuning-based approaches rely on time-consuming\nand resource-intensive subject-specific optimization, while zero-shot methods\nfail to maintain adequate subject consistency. In this work, we propose\nFreeGraftor, a training-free framework that addresses these limitations through\ncross-image feature grafting. Specifically, FreeGraftor employs semantic\nmatching and position-constrained attention fusion to transfer visual details\nfrom reference subjects to the generated image. Additionally, our framework\nincorporates a novel noise initialization strategy to preserve geometry priors\nof reference subjects for robust feature matching. Extensive qualitative and\nquantitative experiments demonstrate that our method enables precise subject\nidentity transfer while maintaining text-aligned scene synthesis. Without\nrequiring model fine-tuning or additional training, FreeGraftor significantly\noutperforms existing zero-shot and training-free approaches in both subject\nfidelity and text alignment. Furthermore, our framework can seamlessly extend\nto multi-subject generation, making it practical for real-world deployment. Our\ncode is available at https://github.com/Nihukat/FreeGraftor.", "AI": {"tldr": "FreeGraftor is a training-free framework for subject-driven image generation, balancing fidelity and efficiency via cross-image feature grafting.", "motivation": "Existing methods struggle with trade-offs between fidelity and efficiency in subject-driven image generation.", "method": "Uses semantic matching, position-constrained attention fusion, and noise initialization for robust feature transfer.", "result": "Outperforms zero-shot and training-free methods in subject fidelity and text alignment, with multi-subject generation capability.", "conclusion": "FreeGraftor offers a practical, efficient solution for high-fidelity subject-driven image synthesis without fine-tuning."}}
{"id": "2412.12639", "pdf": "https://arxiv.org/pdf/2412.12639", "abs": "https://arxiv.org/abs/2412.12639", "authors": ["Xiangxiang Gao", "Weisheng Xie", "Yiwei Xiang", "Feng Ji"], "title": "Falcon: Faster and Parallel Inference of Large Language Models through Enhanced Semi-Autoregressive Drafting and Custom-Designed Decoding Tree", "categories": ["cs.CL", "cs.AI"], "comment": "AAAI 2025 Accepted", "summary": "Striking an optimal balance between minimal drafting latency and high\nspeculation accuracy to enhance the inference speed of Large Language Models\nremains a significant challenge in speculative decoding. In this paper, we\nintroduce Falcon, an innovative semi-autoregressive speculative decoding\nframework fashioned to augment both the drafter's parallelism and output\nquality. Falcon incorporates the Coupled Sequential Glancing Distillation\ntechnique, which fortifies inter-token dependencies within the same block,\nleading to increased speculation accuracy. We offer a comprehensive theoretical\nanalysis to illuminate the underlying mechanisms. Additionally, we introduce a\nCustom-Designed Decoding Tree, which permits the drafter to generate multiple\ntokens in a single forward pass and accommodates multiple forward passes as\nneeded, thereby boosting the number of drafted tokens and significantly\nimproving the overall acceptance rate. Comprehensive evaluations on benchmark\ndatasets such as MT-Bench, HumanEval, and GSM8K demonstrate Falcon's superior\nacceleration capabilities. The framework achieves a lossless speedup ratio\nranging from 2.91x to 3.51x when tested on the Vicuna and LLaMA2-Chat model\nseries. These results outstrip existing speculative decoding methods for LLMs,\nincluding Eagle, Medusa, Lookahead, SPS, and PLD, while maintaining a compact\ndrafter architecture equivalent to merely two Transformer layers.", "AI": {"tldr": "Falcon introduces a semi-autoregressive speculative decoding framework to enhance LLM inference speed by balancing drafting latency and speculation accuracy, achieving significant speedups.", "motivation": "The challenge of balancing minimal drafting latency and high speculation accuracy in speculative decoding for LLMs motivates the development of Falcon.", "method": "Falcon uses Coupled Sequential Glancing Distillation and a Custom-Designed Decoding Tree to improve drafter parallelism and output quality.", "result": "Falcon achieves a 2.91x to 3.51x speedup on Vicuna and LLaMA2-Chat models, outperforming existing methods.", "conclusion": "Falcon's compact yet effective design sets a new benchmark for speculative decoding in LLMs."}}
{"id": "2504.16021", "pdf": "https://arxiv.org/pdf/2504.16021", "abs": "https://arxiv.org/abs/2504.16021", "authors": ["Dinithi Dissanayake", "Suranga Nanayakkara"], "title": "Navigating the State of Cognitive Flow: Context-Aware AI Interventions for Effective Reasoning Support", "categories": ["cs.HC", "cs.AI"], "comment": "Presented at the 2025 ACM Workshop on Human-AI Interaction for\n  Augmented Reasoning, Report Number: CHI25-WS-AUGMENTED-REASONING", "summary": "Flow theory describes an optimal cognitive state where individuals experience\ndeep focus and intrinsic motivation when a task's difficulty aligns with their\nskill level. In AI-augmented reasoning, interventions that disrupt the state of\ncognitive flow can hinder rather than enhance decision-making. This paper\nproposes a context-aware cognitive augmentation framework that adapts\ninterventions based on three key contextual factors: type, timing, and scale.\nBy leveraging multimodal behavioral cues (e.g., gaze behavior, typing\nhesitation, interaction speed), AI can dynamically adjust cognitive support to\nmaintain or restore flow. We introduce the concept of cognitive flow, an\nextension of flow theory in AI-augmented reasoning, where interventions are\npersonalized, adaptive, and minimally intrusive. By shifting from static\ninterventions to context-aware augmentation, our approach ensures that AI\nsystems support deep engagement in complex decision-making and reasoning\nwithout disrupting cognitive immersion.", "AI": {"tldr": "The paper proposes a context-aware AI framework to maintain cognitive flow in decision-making by adapting interventions based on contextual factors and behavioral cues.", "motivation": "Disruptions in cognitive flow hinder AI-augmented reasoning, necessitating adaptive interventions to preserve deep focus and intrinsic motivation.", "method": "A framework adjusts interventions dynamically using multimodal behavioral cues (e.g., gaze, typing hesitation) and considers type, timing, and scale of support.", "result": "The approach enables personalized, minimally intrusive AI support, enhancing engagement in complex reasoning without disrupting flow.", "conclusion": "Context-aware cognitive augmentation improves AI-augmented reasoning by maintaining cognitive flow through adaptive, non-disruptive interventions."}}
{"id": "2504.16041", "pdf": "https://arxiv.org/pdf/2504.16041", "abs": "https://arxiv.org/abs/2504.16041", "authors": ["Amund Tveit", "Bj\u00f8rn Remseth", "Arve Skogvold"], "title": "Muon Optimizer Accelerates Grokking", "categories": ["cs.LG", "cs.AI", "I.2"], "comment": "8 pages, 4 figures", "summary": "This paper investigates the impact of different optimizers on the grokking\nphenomenon, where models exhibit delayed generalization. We conducted\nexperiments across seven numerical tasks (primarily modular arithmetic) using a\nmodern Transformer architecture. The experimental configuration systematically\nvaried the optimizer (Muon vs. AdamW) and the softmax activation function\n(standard softmax, stablemax, and sparsemax) to assess their combined effect on\nlearning dynamics. Our empirical evaluation reveals that the Muon optimizer,\ncharacterized by its use of spectral norm constraints and second-order\ninformation, significantly accelerates the onset of grokking compared to the\nwidely used AdamW optimizer. Specifically, Muon reduced the mean grokking epoch\nfrom 153.09 to 102.89 across all configurations, a statistically significant\ndifference (t = 5.0175, p = 6.33e-08). This suggests that the optimizer choice\nplays a crucial role in facilitating the transition from memorization to\ngeneralization.", "AI": {"tldr": "Muon optimizer accelerates grokking onset compared to AdamW, reducing mean grokking epoch from 153.09 to 102.89.", "motivation": "To study the impact of optimizers (Muon vs. AdamW) and softmax variants on the grokking phenomenon in models.", "method": "Experiments on seven numerical tasks using a Transformer, varying optimizers and softmax functions.", "result": "Muon significantly speeds up grokking onset (t = 5.0175, p = 6.33e-08).", "conclusion": "Optimizer choice is crucial for transitioning from memorization to generalization."}}
{"id": "2504.15991", "pdf": "https://arxiv.org/pdf/2504.15991", "abs": "https://arxiv.org/abs/2504.15991", "authors": ["Leonardo Olivi", "Edoardo Santero Mormile", "Enzo Tartaglione"], "title": "Efficient Adaptation of Deep Neural Networks for Semantic Segmentation in Space Applications", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "In recent years, the application of Deep Learning techniques has shown\nremarkable success in various computer vision tasks, paving the way for their\ndeployment in extraterrestrial exploration. Transfer learning has emerged as a\npowerful strategy for addressing the scarcity of labeled data in these novel\nenvironments. This paper represents one of the first efforts in evaluating the\nfeasibility of employing adapters toward efficient transfer learning for rock\nsegmentation in extraterrestrial landscapes, mainly focusing on lunar and\nmartian terrains. Our work suggests that the use of adapters, strategically\nintegrated into a pre-trained backbone model, can be successful in reducing\nboth bandwidth and memory requirements for the target extraterrestrial device.\nIn this study, we considered two memory-saving strategies: layer fusion (to\nreduce to zero the inference overhead) and an ``adapter ranking'' (to also\nreduce the transmission cost). Finally, we evaluate these results in terms of\ntask performance, memory, and computation on embedded devices, evidencing\ntrade-offs that open the road to more research in the field.", "AI": {"tldr": "The paper evaluates adapters for efficient transfer learning in rock segmentation for extraterrestrial terrains, reducing bandwidth and memory needs.", "motivation": "Addressing labeled data scarcity in extraterrestrial exploration using deep learning.", "method": "Employing adapters in pre-trained models with layer fusion and adapter ranking to save memory and bandwidth.", "result": "Adapters reduce inference overhead and transmission costs while maintaining performance on embedded devices.", "conclusion": "The study highlights trade-offs and opens avenues for further research in efficient transfer learning for extraterrestrial applications."}}
{"id": "2412.14354", "pdf": "https://arxiv.org/pdf/2412.14354", "abs": "https://arxiv.org/abs/2412.14354", "authors": ["Zhichao Xu", "Jinghua Yan", "Ashim Gupta", "Vivek Srikumar"], "title": "State Space Models are Strong Text Rerankers", "categories": ["cs.CL", "cs.IR"], "comment": "Accepted to RepL4NLP 2025. The first two authors contributed equally,\n  order decided randomly", "summary": "Transformers dominate NLP and IR; but their inference inefficiencies and\nchallenges in extrapolating to longer contexts have sparked interest in\nalternative model architectures. Among these, state space models (SSMs) like\nMamba offer promising advantages, particularly $O(1)$ time complexity in\ninference. Despite their potential, SSMs' effectiveness at text reranking -- a\ntask requiring fine-grained query-document interaction and long-context\nunderstanding -- remains underexplored. This study benchmarks SSM-based\narchitectures (specifically, Mamba-1 and Mamba-2) against transformer-based\nmodels across various scales, architectures, and pre-training objectives,\nfocusing on performance and efficiency in text reranking tasks. We find that\n(1) Mamba architectures achieve competitive text ranking performance,\ncomparable to transformer-based models of similar size; (2) they are less\nefficient in training and inference compared to transformers with flash\nattention; and (3) Mamba-2 outperforms Mamba-1 in both performance and\nefficiency. These results underscore the potential of state space models as a\ntransformer alternative and highlight areas for improvement in future IR\napplications.", "AI": {"tldr": "State space models (SSMs) like Mamba show promise for text reranking, achieving competitive performance to transformers but with efficiency trade-offs.", "motivation": "Address inefficiencies of transformers in inference and long-context tasks by exploring SSMs like Mamba for text reranking.", "method": "Benchmark Mamba-1 and Mamba-2 against transformer models in text reranking, evaluating performance and efficiency.", "result": "Mamba models match transformer performance but lag in efficiency; Mamba-2 outperforms Mamba-1.", "conclusion": "SSMs like Mamba are viable transformer alternatives but need efficiency improvements for IR applications."}}
{"id": "2504.16026", "pdf": "https://arxiv.org/pdf/2504.16026", "abs": "https://arxiv.org/abs/2504.16026", "authors": ["Konstantin F. Pilz", "James Sanders", "Robi Rahman", "Lennart Heim"], "title": "Trends in AI Supercomputers", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Frontier AI development relies on powerful AI supercomputers, yet analysis of\nthese systems is limited. We create a dataset of 500 AI supercomputers from\n2019 to 2025 and analyze key trends in performance, power needs, hardware cost,\nownership, and global distribution. We find that the computational performance\nof AI supercomputers has doubled every nine months, while hardware acquisition\ncost and power needs both doubled every year. The leading system in March 2025,\nxAI's Colossus, used 200,000 AI chips, had a hardware cost of \\$7B, and\nrequired 300 MW of power, as much as 250,000 households. As AI supercomputers\nevolved from tools for science to industrial machines, companies rapidly\nexpanded their share of total AI supercomputer performance, while the share of\ngovernments and academia diminished. Globally, the United States accounts for\nabout 75% of total performance in our dataset, with China in second place at\n15%. If the observed trends continue, the leading AI supercomputer in 2030 will\nachieve $2\\times10^{22}$ 16-bit FLOP/s, use two million AI chips, have a\nhardware cost of \\$200 billion, and require 9 GW of power. Our analysis\nprovides visibility into the AI supercomputer landscape, allowing policymakers\nto assess key AI trends like resource needs, ownership, and national\ncompetitiveness.", "AI": {"tldr": "Analysis of 500 AI supercomputers (2019-2025) reveals rapid performance growth (doubling every 9 months), rising costs/power needs, and dominance of companies and the US.", "motivation": "To understand trends in AI supercomputers, including performance, costs, power needs, ownership, and global distribution.", "method": "Created a dataset of 500 AI supercomputers and analyzed trends in performance, power, cost, ownership, and distribution.", "result": "Performance doubles every 9 months; costs and power needs double yearly. Companies dominate, with the US leading globally.", "conclusion": "Trends suggest exponential growth, raising concerns about resource needs and competitiveness, aiding policymakers."}}
{"id": "2504.16054", "pdf": "https://arxiv.org/pdf/2504.16054", "abs": "https://arxiv.org/abs/2504.16054", "authors": ["Physical Intelligence", "Kevin Black", "Noah Brown", "James Darpinian", "Karan Dhabalia", "Danny Driess", "Adnan Esmail", "Michael Equi", "Chelsea Finn", "Niccolo Fusai", "Manuel Y. Galliker", "Dibya Ghosh", "Lachy Groom", "Karol Hausman", "Brian Ichter", "Szymon Jakubczak", "Tim Jones", "Liyiming Ke", "Devin LeBlanc", "Sergey Levine", "Adrian Li-Bell", "Mohith Mothukuri", "Suraj Nair", "Karl Pertsch", "Allen Z. Ren", "Lucy Xiaoyang Shi", "Laura Smith", "Jost Tobias Springenberg", "Kyle Stachowicz", "James Tanner", "Quan Vuong", "Homer Walke", "Anna Walling", "Haohuan Wang", "Lili Yu", "Ury Zhilinsky"], "title": "$\u03c0_{0.5}$: a Vision-Language-Action Model with Open-World Generalization", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "In order for robots to be useful, they must perform practically relevant\ntasks in the real world, outside of the lab. While vision-language-action (VLA)\nmodels have demonstrated impressive results for end-to-end robot control, it\nremains an open question how far such models can generalize in the wild. We\ndescribe $\\pi_{0.5}$, a new model based on $\\pi_{0}$ that uses co-training on\nheterogeneous tasks to enable broad generalization. $\\pi_{0.5}$\\ uses data from\nmultiple robots, high-level semantic prediction, web data, and other sources to\nenable broadly generalizable real-world robotic manipulation. Our system uses a\ncombination of co-training and hybrid multi-modal examples that combine image\nobservations, language commands, object detections, semantic subtask\nprediction, and low-level actions. Our experiments show that this kind of\nknowledge transfer is essential for effective generalization, and we\ndemonstrate for the first time that an end-to-end learning-enabled robotic\nsystem can perform long-horizon and dexterous manipulation skills, such as\ncleaning a kitchen or bedroom, in entirely new homes.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2504.16003", "pdf": "https://arxiv.org/pdf/2504.16003", "abs": "https://arxiv.org/abs/2504.16003", "authors": ["Yachun Mi", "Yu Li", "Weicheng Meng", "Chaofeng Chen", "Chen Hui", "Shaohui Liu"], "title": "MVQA: Mamba with Unified Sampling for Efficient Video Quality Assessment", "categories": ["cs.CV"], "comment": null, "summary": "The rapid growth of long-duration, high-definition videos has made efficient\nvideo quality assessment (VQA) a critical challenge. Existing research\ntypically tackles this problem through two main strategies: reducing model\nparameters and resampling inputs. However, light-weight Convolution Neural\nNetworks (CNN) and Transformers often struggle to balance efficiency with high\nperformance due to the requirement of long-range modeling capabilities.\nRecently, the state-space model, particularly Mamba, has emerged as a promising\nalternative, offering linear complexity with respect to sequence length.\nMeanwhile, efficient VQA heavily depends on resampling long sequences to\nminimize computational costs, yet current resampling methods are often weak in\npreserving essential semantic information. In this work, we present MVQA, a\nMamba-based model designed for efficient VQA along with a novel Unified\nSemantic and Distortion Sampling (USDS) approach. USDS combines semantic patch\nsampling from low-resolution videos and distortion patch sampling from\noriginal-resolution videos. The former captures semantically dense regions,\nwhile the latter retains critical distortion details. To prevent computation\nincrease from dual inputs, we propose a fusion mechanism using pre-defined\nmasks, enabling a unified sampling strategy that captures both semantic and\nquality information without additional computational burden. Experiments show\nthat the proposed MVQA, equipped with USDS, achieve comparable performance to\nstate-of-the-art methods while being $2\\times$ as fast and requiring only $1/5$\nGPU memory.", "AI": {"tldr": "MVQA introduces a Mamba-based model for efficient video quality assessment (VQA) with a novel Unified Semantic and Distortion Sampling (USDS) method, balancing performance and computational efficiency.", "motivation": "The challenge of efficient VQA for long-duration, high-definition videos, where existing methods struggle to balance efficiency and performance due to long-range modeling needs and weak resampling techniques.", "method": "MVQA combines Mamba's linear complexity with USDS, which samples semantic patches from low-res videos and distortion patches from original-res videos, fused using pre-defined masks.", "result": "MVQA matches state-of-the-art performance while being 2x faster and using 1/5 GPU memory.", "conclusion": "MVQA with USDS offers an efficient and effective solution for VQA, addressing key limitations of current methods."}}
{"id": "2412.15993", "pdf": "https://arxiv.org/pdf/2412.15993", "abs": "https://arxiv.org/abs/2412.15993", "authors": ["Lynn Greschner", "Roman Klinger"], "title": "Fearful Falcons and Angry Llamas: Emotion Category Annotations of Arguments by Humans and LLMs", "categories": ["cs.CL"], "comment": "accepted to NLP4DH 2025", "summary": "Arguments evoke emotions, influencing the effect of the argument itself. Not\nonly the emotional intensity but also the category influence the argument's\neffects, for instance, the willingness to adapt stances. While binary\nemotionality has been studied in arguments, there is no work on discrete\nemotion categories (e.g., \"Anger\") in such data. To fill this gap, we\ncrowdsource subjective annotations of emotion categories in a German argument\ncorpus and evaluate automatic LLM-based labeling methods. Specifically, we\ncompare three prompting strategies (zero-shot, one-shot, chain-of-thought) on\nthree large instruction-tuned language models (Falcon-7b-instruct,\nLlama-3.1-8B-instruct, GPT-4o-mini). We further vary the definition of the\noutput space to be binary (is there emotionality in the argument?),\nclosed-domain (which emotion from a given label set is in the argument?), or\nopen-domain (which emotion is in the argument?). We find that emotion\ncategories enhance the prediction of emotionality in arguments, emphasizing the\nneed for discrete emotion annotations in arguments. Across all prompt settings\nand models, automatic predictions show a high recall but low precision for\npredicting anger and fear, indicating a strong bias toward negative emotions.", "AI": {"tldr": "The paper explores how discrete emotion categories (e.g., anger) in arguments affect stance adaptation, using crowdsourced annotations and LLM-based labeling methods. It compares prompting strategies and output space definitions, finding high recall but low precision for negative emotions like anger and fear.", "motivation": "To address the gap in studying discrete emotion categories (e.g., anger) in arguments, which influence stance adaptation, unlike binary emotionality.", "method": "Crowdsourced subjective annotations of emotion categories in a German argument corpus, evaluated using LLM-based labeling (Falcon-7b-instruct, Llama-3.1-8B-instruct, GPT-4o-mini) with three prompting strategies (zero-shot, one-shot, chain-of-thought) and output space variations (binary, closed-domain, open-domain).", "result": "Emotion categories improve emotionality prediction in arguments. Automatic predictions show high recall but low precision for anger and fear, indicating a bias toward negative emotions.", "conclusion": "Discrete emotion annotations are crucial for understanding argument effects, with LLMs showing potential but bias toward negative emotions."}}
{"id": "2504.16027", "pdf": "https://arxiv.org/pdf/2504.16027", "abs": "https://arxiv.org/abs/2504.16027", "authors": ["Ahmed R. Sadik", "Siddhata Govind"], "title": "Benchmarking LLM for Code Smells Detection: OpenAI GPT-4.0 vs DeepSeek-V3", "categories": ["cs.SE", "cs.AI", "cs.LG", "cs.PL"], "comment": null, "summary": "Determining the most effective Large Language Model for code smell detection\npresents a complex challenge. This study introduces a structured methodology\nand evaluation matrix to tackle this issue, leveraging a curated dataset of\ncode samples consistently annotated with known smells. The dataset spans four\nprominent programming languages Java, Python, JavaScript, and C++; allowing for\ncross language comparison. We benchmark two state of the art LLMs, OpenAI GPT\n4.0 and DeepSeek-V3, using precision, recall, and F1 score as evaluation\nmetrics. Our analysis covers three levels of detail: overall performance,\ncategory level performance, and individual code smell type performance.\nAdditionally, we explore cost effectiveness by comparing the token based\ndetection approach of GPT 4.0 with the pattern-matching techniques employed by\nDeepSeek V3. The study also includes a cost analysis relative to traditional\nstatic analysis tools such as SonarQube. The findings offer valuable guidance\nfor practitioners in selecting an efficient, cost effective solution for\nautomated code smell detection", "AI": {"tldr": "The paper introduces a methodology to evaluate LLMs (GPT-4.0 and DeepSeek-V3) for code smell detection across four languages, comparing performance and cost-effectiveness.", "motivation": "To address the challenge of selecting the most effective LLM for automated code smell detection.", "method": "Uses a curated dataset of annotated code samples in Java, Python, JavaScript, and C++. Benchmarks LLMs using precision, recall, and F1 scores at three levels of detail, and compares token-based vs. pattern-matching approaches.", "result": "Provides performance metrics and cost analysis, comparing LLMs to traditional tools like SonarQube.", "conclusion": "Offers practical guidance for choosing an efficient and cost-effective solution for code smell detection."}}
{"id": "2504.16078", "pdf": "https://arxiv.org/pdf/2504.16078", "abs": "https://arxiv.org/abs/2504.16078", "authors": ["Thomas Schmied", "J\u00f6rg Bornschein", "Jordi Grau-Moya", "Markus Wulfmeier", "Razvan Pascanu"], "title": "LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making Abilities", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The success of Large Language Models (LLMs) has sparked interest in various\nagentic applications. A key hypothesis is that LLMs, leveraging common sense\nand Chain-of-Thought (CoT) reasoning, can effectively explore and efficiently\nsolve complex domains. However, LLM agents have been found to suffer from\nsub-optimal exploration and the knowing-doing gap, the inability to effectively\nact on knowledge present in the model. In this work, we systematically study\nwhy LLMs perform sub-optimally in decision-making scenarios. In particular, we\nclosely examine three prevalent failure modes: greediness, frequency bias, and\nthe knowing-doing gap. We propose mitigation of these shortcomings by\nfine-tuning via Reinforcement Learning (RL) on self-generated CoT rationales.\nOur experiments across multi-armed bandits, contextual bandits, and\nTic-tac-toe, demonstrate that RL fine-tuning enhances the decision-making\nabilities of LLMs by increasing exploration and narrowing the knowing-doing\ngap. Finally, we study both classic exploration mechanisms, such as\n$\\epsilon$-greedy, and LLM-specific approaches, such as self-correction and\nself-consistency, to enable more effective fine-tuning of LLMs for\ndecision-making.", "AI": {"tldr": "The paper investigates sub-optimal decision-making in LLM agents, identifies three failure modes (greediness, frequency bias, knowing-doing gap), and proposes RL fine-tuning on self-generated CoT rationales to improve performance.", "motivation": "LLMs show promise in agentic applications but suffer from sub-optimal exploration and the knowing-doing gap, hindering effective decision-making.", "method": "Systematically study LLM failure modes, propose RL fine-tuning on self-generated CoT rationales, and test on tasks like multi-armed bandits and Tic-tac-toe.", "result": "RL fine-tuning improves LLM decision-making by enhancing exploration and reducing the knowing-doing gap.", "conclusion": "RL fine-tuning and exploration mechanisms (e.g., \u03b5-greedy, self-correction) can effectively enhance LLM decision-making."}}
{"id": "2504.16016", "pdf": "https://arxiv.org/pdf/2504.16016", "abs": "https://arxiv.org/abs/2504.16016", "authors": ["Xinyuan Song", "Yangfan He", "Sida Li", "Jianhui Wang", "Hongyang He", "Xinhang Yuan", "Ruoyu Wang", "Jiaqi Chen", "Keqin Li", "Kuan Lu", "Menghao Huo", "Binxu Li", "Pei Liu"], "title": "Efficient Temporal Consistency in Diffusion-Based Video Editing with Adaptor Modules: A Theoretical Framework", "categories": ["cs.CV"], "comment": "arXiv admin note: substantial text overlap with arXiv:2501.04606", "summary": "Adapter-based methods are commonly used to enhance model performance with\nminimal additional complexity, especially in video editing tasks that require\nframe-to-frame consistency. By inserting small, learnable modules into\npretrained diffusion models, these adapters can maintain temporal coherence\nwithout extensive retraining. Approaches that incorporate prompt learning with\nboth shared and frame-specific tokens are particularly effective in preserving\ncontinuity across frames at low training cost. In this work, we want to provide\na general theoretical framework for adapters that maintain frame consistency in\nDDIM-based models under a temporal consistency loss. First, we prove that the\ntemporal consistency objective is differentiable under bounded feature norms,\nand we establish a Lipschitz bound on its gradient. Second, we show that\ngradient descent on this objective decreases the loss monotonically and\nconverges to a local minimum if the learning rate is within an appropriate\nrange. Finally, we analyze the stability of modules in the DDIM inversion\nprocedure, showing that the associated error remains controlled. These\ntheoretical findings will reinforce the reliability of diffusion-based video\nediting methods that rely on adapter strategies and provide theoretical\ninsights in video generation tasks.", "AI": {"tldr": "The paper provides a theoretical framework for adapters in DDIM-based models to maintain frame consistency, proving differentiability, convergence, and stability under a temporal consistency loss.", "motivation": "To enhance model performance in video editing tasks with minimal complexity, ensuring frame-to-frame consistency without extensive retraining.", "method": "Inserting small, learnable modules into pretrained diffusion models, using prompt learning with shared and frame-specific tokens, and analyzing under a temporal consistency loss.", "result": "Proves the temporal consistency objective is differentiable, establishes Lipschitz bounds, shows monotonic loss decrease, and controls error in DDIM inversion.", "conclusion": "The theoretical findings reinforce the reliability of adapter-based diffusion methods in video editing and provide insights for video generation tasks."}}
{"id": "2502.13053", "pdf": "https://arxiv.org/pdf/2502.13053", "abs": "https://arxiv.org/abs/2502.13053", "authors": ["Yurun Chen", "Xavier Hu", "Keting Yin", "Juncheng Li", "Shengyu Zhang"], "title": "Evaluating the Robustness of Multimodal Agents Against Active Environmental Injection Attacks", "categories": ["cs.CL"], "comment": null, "summary": "As researchers continue to optimize AI agents for more effective task\nexecution within operating systems, they often overlook a critical security\nconcern: the ability of these agents to detect \"impostors\" within their\nenvironment. Through an analysis of the agents' operational context, we\nidentify a significant threat-attackers can disguise malicious attacks as\nenvironmental elements, injecting active disturbances into the agents'\nexecution processes to manipulate their decision-making. We define this novel\nthreat as the Active Environment Injection Attack (AEIA). Focusing on the\ninteraction mechanisms of the Android OS, we conduct a risk assessment of AEIA\nand identify two critical security vulnerabilities: (1) Adversarial content\ninjection in multimodal interaction interfaces, where attackers embed\nadversarial instructions within environmental elements to mislead agent\ndecision-making; and (2) Reasoning gap vulnerabilities in the agent's task\nexecution process, which increase susceptibility to AEIA attacks during\nreasoning. To evaluate the impact of these vulnerabilities, we propose AEIA-MN,\nan attack scheme that exploits interaction vulnerabilities in mobile operating\nsystems to assess the robustness of MLLM-based agents. Experimental results\nshow that even advanced MLLMs are highly vulnerable to this attack, achieving a\nmaximum attack success rate of 93% on the AndroidWorld benchmark by combining\ntwo vulnerabilities.", "AI": {"tldr": "The paper introduces Active Environment Injection Attack (AEIA), a novel threat where attackers disguise malicious attacks as environmental elements to manipulate AI agents. It identifies two vulnerabilities in Android OS and proposes AEIA-MN to test MLLM-based agents, showing a 93% success rate.", "motivation": "To address the overlooked security concern of AI agents detecting impostors in their environment, particularly in operating systems like Android.", "method": "Analyzes agents' operational context, identifies AEIA vulnerabilities, and proposes AEIA-MN to exploit these vulnerabilities in mobile OS.", "result": "Demonstrates high vulnerability of advanced MLLMs to AEIA, with a 93% attack success rate on AndroidWorld.", "conclusion": "AEIA poses a significant threat to AI agents, highlighting the need for improved security measures against such attacks."}}
{"id": "2504.16047", "pdf": "https://arxiv.org/pdf/2504.16047", "abs": "https://arxiv.org/abs/2504.16047", "authors": ["Frank Li", "Hari Trivedi", "Bardia Khosravi", "Theo Dapamede", "Mohammadreza Chavoshi", "Abdulhameed Dere", "Rohan Satya Isaac", "Aawez Mansuri", "Janice Newsome", "Saptarshi Purkayastha", "Judy Gichoya"], "title": "Evaluating Vision Language Models (VLMs) for Radiology: A Comprehensive Analysis", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Foundation models, trained on vast amounts of data using self-supervised\ntechniques, have emerged as a promising frontier for advancing artificial\nintelligence (AI) applications in medicine. This study evaluates three\ndifferent vision-language foundation models (RAD-DINO, CheXagent, and\nBiomedCLIP) on their ability to capture fine-grained imaging features for\nradiology tasks. The models were assessed across classification, segmentation,\nand regression tasks for pneumothorax and cardiomegaly on chest radiographs.\nSelf-supervised RAD-DINO consistently excelled in segmentation tasks, while\ntext-supervised CheXagent demonstrated superior classification performance.\nBiomedCLIP showed inconsistent performance across tasks. A custom segmentation\nmodel that integrates global and local features substantially improved\nperformance for all foundation models, particularly for challenging\npneumothorax segmentation. The findings highlight that pre-training methodology\nsignificantly influences model performance on specific downstream tasks. For\nfine-grained segmentation tasks, models trained without text supervision\nperformed better, while text-supervised models offered advantages in\nclassification and interpretability. These insights provide guidance for\nselecting foundation models based on specific clinical applications in\nradiology.", "AI": {"tldr": "The study evaluates three vision-language foundation models (RAD-DINO, CheXagent, BiomedCLIP) for radiology tasks, showing task-specific performance differences and the impact of pre-training methods.", "motivation": "To assess the suitability of foundation models for fine-grained radiology tasks like classification, segmentation, and regression.", "method": "Evaluated three models on pneumothorax and cardiomegaly tasks using chest radiographs. A custom segmentation model integrating global and local features was also tested.", "result": "RAD-DINO excelled in segmentation, CheXagent in classification, and BiomedCLIP was inconsistent. The custom model improved performance, especially for pneumothorax.", "conclusion": "Pre-training methodology affects task performance; text-free models suit segmentation, while text-supervised models excel in classification and interpretability."}}
{"id": "2504.15284", "pdf": "https://arxiv.org/pdf/2504.15284", "abs": "https://arxiv.org/abs/2504.15284", "authors": ["Weichen Li", "Albert Jan", "Baishakhi Ray", "Chengzhi Mao", "Junfeng Yang", "Kexin Pei"], "title": "EditLord: Learning Code Transformation Rules for Code Editing", "categories": ["cs.SE", "cs.CR", "cs.LG"], "comment": null, "summary": "Code editing is a foundational task in software development, where its\neffectiveness depends on whether it introduces desired code property changes\nwithout changing the original code's intended functionality. Existing\napproaches often formulate code editing as an implicit end-to-end task,\nomitting the fact that code-editing procedures inherently consist of discrete\nand explicit steps. Thus, they suffer from suboptimal performance and lack of\nrobustness and generalization. We introduce EditLord, a code editing framework\nthat makes the code transformation steps explicit. Our key insight is to employ\na language model (LM) as an inductive learner to extract code editing rules\nfrom the training code pairs as concise meta-rule sets. Such rule sets will be\nmanifested for each training sample to augment them for finetuning or assist in\nprompting- and iterative-based code editing. EditLordoutperforms the\nstate-of-the-art by an average of 22.7% in editing performance and 58.1% in\nrobustness while achieving 20.2% higher functional correctness across critical\nsoftware engineering and security applications, LM models, and editing modes.", "AI": {"tldr": "EditLord is a framework for explicit code editing steps, outperforming state-of-the-art methods in performance, robustness, and functional correctness.", "motivation": "Existing code editing approaches are implicit and end-to-end, lacking robustness and generalization. EditLord addresses this by making transformation steps explicit.", "method": "Uses a language model to extract code editing rules as meta-rule sets, augmenting training samples for finetuning or prompting-based editing.", "result": "Outperforms state-of-the-art by 22.7% in performance, 58.1% in robustness, and 20.2% in functional correctness.", "conclusion": "EditLord's explicit rule-based approach significantly improves code editing effectiveness across applications and models."}}
{"id": "2504.16023", "pdf": "https://arxiv.org/pdf/2504.16023", "abs": "https://arxiv.org/abs/2504.16023", "authors": ["Song Wang", "Xiaolu Liu", "Lingdong Kong", "Jianyun Xu", "Chunyong Hu", "Gongfan Fang", "Wentong Li", "Jianke Zhu", "Xinchao Wang"], "title": "PointLoRA: Low-Rank Adaptation with Token Selection for Point Cloud Learning", "categories": ["cs.CV"], "comment": "Accepted by CVPR2025", "summary": "Self-supervised representation learning for point cloud has demonstrated\neffectiveness in improving pre-trained model performance across diverse tasks.\nHowever, as pre-trained models grow in complexity, fully fine-tuning them for\ndownstream applications demands substantial computational and storage\nresources. Parameter-efficient fine-tuning (PEFT) methods offer a promising\nsolution to mitigate these resource requirements, yet most current approaches\nrely on complex adapter and prompt mechanisms that increase tunable parameters.\nIn this paper, we propose PointLoRA, a simple yet effective method that\ncombines low-rank adaptation (LoRA) with multi-scale token selection to\nefficiently fine-tune point cloud models. Our approach embeds LoRA layers\nwithin the most parameter-intensive components of point cloud transformers,\nreducing the need for tunable parameters while enhancing global feature\ncapture. Additionally, multi-scale token selection extracts critical local\ninformation to serve as prompts for downstream fine-tuning, effectively\ncomplementing the global context captured by LoRA. The experimental results\nacross various pre-trained models and three challenging public datasets\ndemonstrate that our approach achieves competitive performance with only 3.43%\nof the trainable parameters, making it highly effective for\nresource-constrained applications. Source code is available at:\nhttps://github.com/songw-zju/PointLoRA.", "AI": {"tldr": "PointLoRA combines low-rank adaptation (LoRA) with multi-scale token selection for efficient fine-tuning of point cloud models, reducing tunable parameters while maintaining performance.", "motivation": "To address the high computational and storage demands of fully fine-tuning complex pre-trained point cloud models, PointLoRA offers a parameter-efficient solution.", "method": "Embed LoRA layers in parameter-intensive components of point cloud transformers and use multi-scale token selection for local feature extraction.", "result": "Achieves competitive performance with only 3.43% of trainable parameters across various models and datasets.", "conclusion": "PointLoRA is a resource-efficient method for fine-tuning point cloud models, balancing performance and computational cost."}}
{"id": "2503.04797", "pdf": "https://arxiv.org/pdf/2503.04797", "abs": "https://arxiv.org/abs/2503.04797", "authors": ["Rahul Raja", "Arpita Vats"], "title": "Parallel Corpora for Machine Translation in Low-resource Indic Languages: A Comprehensive Review", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted in NACCL", "summary": "Parallel corpora play an important role in training machine translation (MT)\nmodels, particularly for low-resource languages where high-quality bilingual\ndata is scarce. This review provides a comprehensive overview of available\nparallel corpora for Indic languages, which span diverse linguistic families,\nscripts, and regional variations. We categorize these corpora into\ntext-to-text, code-switched, and various categories of multimodal datasets,\nhighlighting their significance in the development of robust multilingual MT\nsystems. Beyond resource enumeration, we critically examine the challenges\nfaced in corpus creation, including linguistic diversity, script variation,\ndata scarcity, and the prevalence of informal textual content.We also discuss\nand evaluate these corpora in various terms such as alignment quality and\ndomain representativeness. Furthermore, we address open challenges such as data\nimbalance across Indic languages, the trade-off between quality and quantity,\nand the impact of noisy, informal, and dialectal data on MT performance.\nFinally, we outline future directions, including leveraging cross-lingual\ntransfer learning, expanding multilingual datasets, and integrating multimodal\nresources to enhance translation quality. To the best of our knowledge, this\npaper presents the first comprehensive review of parallel corpora specifically\ntailored for low-resource Indic languages in the context of machine\ntranslation.", "AI": {"tldr": "A review of parallel corpora for Indic languages, highlighting their role in machine translation, challenges in corpus creation, and future directions.", "motivation": "To address the scarcity of high-quality bilingual data for low-resource Indic languages and improve multilingual MT systems.", "method": "Categorizes and evaluates available parallel corpora, examining alignment quality, domain representativeness, and challenges like linguistic diversity and data imbalance.", "result": "Identifies key challenges (e.g., script variation, noisy data) and evaluates corpora for their utility in MT.", "conclusion": "Future directions include cross-lingual transfer learning, expanding datasets, and integrating multimodal resources to enhance translation quality."}}
{"id": "2504.16061", "pdf": "https://arxiv.org/pdf/2504.16061", "abs": "https://arxiv.org/abs/2504.16061", "authors": ["Sangeet Khemlani", "Tyler Tran", "Nathaniel Gyory", "Anthony M. Harrison", "Wallace E. Lawson", "Ravenna Thielstrom", "Hunter Thompson", "Taaren Singh", "J. Gregory Trafton"], "title": "Vision language models are unreliable at trivial spatial cognition", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision language models (VLMs) are designed to extract relevant visuospatial\ninformation from images. Some research suggests that VLMs can exhibit humanlike\nscene understanding, while other investigations reveal difficulties in their\nability to process relational information. To achieve widespread applicability,\nVLMs must perform reliably, yielding comparable competence across a wide\nvariety of related tasks. We sought to test how reliable these architectures\nare at engaging in trivial spatial cognition, e.g., recognizing whether one\nobject is left of another in an uncluttered scene. We developed a benchmark\ndataset -- TableTest -- whose images depict 3D scenes of objects arranged on a\ntable, and used it to evaluate state-of-the-art VLMs. Results show that\nperformance could be degraded by minor variations of prompts that use logically\nequivalent descriptions. These analyses suggest limitations in how VLMs may\nreason about spatial relations in real-world applications. They also reveal\nnovel opportunities for bolstering image caption corpora for more efficient\ntraining and testing.", "AI": {"tldr": "VLMs struggle with trivial spatial cognition tasks, as shown by degraded performance on the TableTest benchmark due to minor prompt variations.", "motivation": "To assess the reliability of VLMs in spatial cognition tasks for real-world applicability.", "method": "Developed the TableTest benchmark with 3D scenes of objects on a table to evaluate VLMs.", "result": "Performance degraded with minor prompt variations, revealing limitations in spatial reasoning.", "conclusion": "VLMs have spatial reasoning limitations, but this highlights opportunities for improving training corpora."}}
{"id": "2504.15327", "pdf": "https://arxiv.org/pdf/2504.15327", "abs": "https://arxiv.org/abs/2504.15327", "authors": ["Tianliang Yao", "Bo Lu", "Markus Kowarschik", "Yixuan Yuan", "Hubin Zhao", "Sebastien Ourselin", "Kaspar Althoefer", "Junbo Ge", "Peng Qi"], "title": "Advancing Embodied Intelligence in Robotic-Assisted Endovascular Procedures: A Systematic Review of AI Solutions", "categories": ["cs.RO", "cs.LG"], "comment": "24 pages, 7 figures, submitted to IEEE", "summary": "Endovascular procedures have revolutionized the treatment of vascular\ndiseases thanks to minimally invasive solutions that significantly reduce\npatient recovery time and enhance clinical outcomes. However, the precision and\ndexterity required during these procedures poses considerable challenges for\ninterventionists. Robotic systems have emerged offering transformative\nsolutions, addressing issues such as operator fatigue, radiation exposure, and\nthe inherent limitations of human precision. The integration of Embodied\nIntelligence (EI) into these systems signifies a paradigm shift, enabling\nrobots to navigate complex vascular networks and adapt to dynamic physiological\nconditions. Data-driven approaches, advanced computer vision, medical image\nanalysis, and machine learning techniques, are at the forefront of this\nevolution. These methods augment procedural intelligence by facilitating\nreal-time vessel segmentation, device tracking, and anatomical landmark\ndetection. Reinforcement learning and imitation learning further refine\nnavigation strategies and replicate experts' techniques. This review\nsystematically examines the integration of EI principles into robotic\ntechnologies, in relation to endovascular procedures. We discuss recent\nadvancements in intelligent perception and data-driven control, and their\npractical applications in robot-assisted endovascular procedures. By critically\nevaluating current limitations and emerging opportunities, this review\nestablishes a framework for future developments, emphasizing the potential for\ngreater autonomy and improved clinical outcomes. Emerging trends and specific\nareas of research, such as federated learning for medical data sharing,\nexplainable AI for clinical decision support, and advanced human-robot\ncollaboration paradigms, are also explored, offering insights into the future\ndirection of this rapidly evolving field.", "AI": {"tldr": "The paper reviews the integration of Embodied Intelligence (EI) in robotic systems for endovascular procedures, highlighting advancements in data-driven methods, machine learning, and their clinical applications.", "motivation": "Endovascular procedures require high precision, posing challenges like operator fatigue and radiation exposure. Robotic systems with EI aim to overcome these limitations.", "method": "The review examines EI principles, data-driven approaches (e.g., computer vision, machine learning), and their use in real-time vessel segmentation, device tracking, and navigation.", "result": "EI-enhanced robotic systems improve procedural intelligence, navigation, and clinical outcomes, with potential for greater autonomy.", "conclusion": "The paper outlines future directions, including federated learning, explainable AI, and human-robot collaboration, to advance the field."}}
{"id": "2504.16030", "pdf": "https://arxiv.org/pdf/2504.16030", "abs": "https://arxiv.org/abs/2504.16030", "authors": ["Joya Chen", "Ziyun Zeng", "Yiqi Lin", "Wei Li", "Zejun Ma", "Mike Zheng Shou"], "title": "LiveCC: Learning Video LLM with Streaming Speech Transcription at Scale", "categories": ["cs.CV"], "comment": "CVPR 2025. If any references are missing, please contact\n  joyachen@u.nus.edu", "summary": "Recent video large language models (Video LLMs) often depend on costly human\nannotations or proprietary model APIs (e.g., GPT-4o) to produce training data,\nwhich limits their training at scale. In this paper, we explore large-scale\ntraining for Video LLM with cheap automatic speech recognition (ASR)\ntranscripts. Specifically, we propose a novel streaming training approach that\ndensely interleaves the ASR words and video frames according to their\ntimestamps. Compared to previous studies in vision-language representation with\nASR, our method naturally fits the streaming characteristics of ASR, thus\nenabling the model to learn temporally-aligned, fine-grained vision-language\nmodeling. To support the training algorithm, we introduce a data production\npipeline to process YouTube videos and their closed captions (CC, same as ASR),\nresulting in Live-CC-5M dataset for pre-training and Live-WhisperX-526K dataset\nfor high-quality supervised fine-tuning (SFT). Remarkably, even without SFT,\nthe ASR-only pre-trained LiveCC-7B-Base model demonstrates competitive general\nvideo QA performance and exhibits a new capability in real-time video\ncommentary. To evaluate this, we carefully design a new LiveSports-3K\nbenchmark, using LLM-as-a-judge to measure the free-form commentary.\nExperiments show our final LiveCC-7B-Instruct model can surpass advanced 72B\nmodels (Qwen2.5-VL-72B-Instruct, LLaVA-Video-72B) in commentary quality even\nworking in a real-time mode. Meanwhile, it achieves state-of-the-art results at\nthe 7B/8B scale on popular video QA benchmarks such as VideoMME and OVOBench,\ndemonstrating the broad generalizability of our approach. All resources of this\npaper have been released at https://showlab.github.io/livecc.", "AI": {"tldr": "The paper proposes a scalable training method for Video LLMs using cheap ASR transcripts, introducing datasets and achieving competitive performance without costly annotations.", "motivation": "To reduce reliance on expensive human annotations or proprietary APIs for training Video LLMs, enabling large-scale training with ASR transcripts.", "method": "A streaming training approach interleaving ASR words and video frames by timestamps, supported by datasets Live-CC-5M and Live-WhisperX-526K.", "result": "The ASR-only pre-trained model (LiveCC-7B-Base) shows strong video QA performance and real-time commentary capability, surpassing larger models in quality.", "conclusion": "The approach demonstrates broad generalizability and state-of-the-art results, with all resources publicly released."}}
{"id": "2503.09572", "pdf": "https://arxiv.org/pdf/2503.09572", "abs": "https://arxiv.org/abs/2503.09572", "authors": ["Lutfi Eren Erdogan", "Nicholas Lee", "Sehoon Kim", "Suhong Moon", "Hiroki Furuta", "Gopala Anumanchipalli", "Kurt Keutzer", "Amir Gholami"], "title": "Plan-and-Act: Improving Planning of Agents for Long-Horizon Tasks", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have shown remarkable advancements in enabling\nlanguage agents to tackle simple tasks. However, applying them for complex,\nmulti-step, long-horizon tasks remains a challenge. Recent work have found\nsuccess by separating high-level planning from low-level execution, which\nenables the model to effectively balance high-level planning objectives and\nlow-level execution details. However, generating accurate plans remains\ndifficult since LLMs are not inherently trained for this task. To address this,\nwe propose Plan-and-Act, a novel framework that incorporates explicit planning\ninto LLM-based agents and introduces a scalable method to enhance plan\ngeneration through a novel synthetic data generation method. Plan-and-Act\nconsists of a Planner model which generates structured, high-level plans to\nachieve user goals, and an Executor model that translates these plans into\nenvironment-specific actions. To train the Planner effectively, we introduce a\nsynthetic data generation method that annotates ground-truth trajectories with\nfeasible plans, augmented with diverse and extensive examples to enhance\ngeneralization. We evaluate Plan-and-Act using web navigation as a\nrepresentative long-horizon planning environment, demonstrating a\nstate-of-the-art 57.58% success rate on the WebArena-Lite benchmark as well as\na text-only state-of-the-art 81.36% success rate on WebVoyager.", "AI": {"tldr": "Plan-and-Act framework enhances LLM-based agents for complex tasks by integrating explicit planning and scalable synthetic data generation, achieving state-of-the-art performance in web navigation tasks.", "motivation": "Applying LLMs to complex, multi-step tasks is challenging due to their lack of inherent planning capabilities.", "method": "Proposes Plan-and-Act, a framework with a Planner for structured plans and an Executor for actions, trained using synthetic data generation.", "result": "Achieves 57.58% success on WebArena-Lite and 81.36% on WebVoyager, setting new benchmarks.", "conclusion": "Plan-and-Act effectively bridges the gap in LLM-based planning, demonstrating superior performance in long-horizon tasks."}}
{"id": "2504.16072", "pdf": "https://arxiv.org/pdf/2504.16072", "abs": "https://arxiv.org/abs/2504.16072", "authors": ["Long Lian", "Yifan Ding", "Yunhao Ge", "Sifei Liu", "Hanzi Mao", "Boyi Li", "Marco Pavone", "Ming-Yu Liu", "Trevor Darrell", "Adam Yala", "Yin Cui"], "title": "Describe Anything: Detailed Localized Image and Video Captioning", "categories": ["cs.CV", "cs.AI"], "comment": "Project page: https://describe-anything.github.io/", "summary": "Generating detailed and accurate descriptions for specific regions in images\nand videos remains a fundamental challenge for vision-language models. We\nintroduce the Describe Anything Model (DAM), a model designed for detailed\nlocalized captioning (DLC). DAM preserves both local details and global context\nthrough two key innovations: a focal prompt, which ensures high-resolution\nencoding of targeted regions, and a localized vision backbone, which integrates\nprecise localization with its broader context. To tackle the scarcity of\nhigh-quality DLC data, we propose a Semi-supervised learning (SSL)-based Data\nPipeline (DLC-SDP). DLC-SDP starts with existing segmentation datasets and\nexpands to unlabeled web images using SSL. We introduce DLC-Bench, a benchmark\ndesigned to evaluate DLC without relying on reference captions. DAM sets new\nstate-of-the-art on 7 benchmarks spanning keyword-level, phrase-level, and\ndetailed multi-sentence localized image and video captioning.", "AI": {"tldr": "The paper introduces the Describe Anything Model (DAM) for detailed localized captioning (DLC), featuring innovations like focal prompts and a localized vision backbone. It also proposes a semi-supervised learning-based data pipeline (DLC-SDP) and a new benchmark (DLC-Bench). DAM achieves state-of-the-art results on 7 benchmarks.", "motivation": "The challenge of generating detailed and accurate descriptions for specific regions in images and videos remains unresolved for vision-language models.", "method": "DAM uses focal prompts for high-resolution encoding and a localized vision backbone. DLC-SDP leverages semi-supervised learning to expand datasets from segmentation data to unlabeled web images.", "result": "DAM achieves state-of-the-art performance on 7 benchmarks for localized captioning tasks.", "conclusion": "DAM and DLC-SDP effectively address the challenge of detailed localized captioning, setting new benchmarks in the field."}}
{"id": "2504.15370", "pdf": "https://arxiv.org/pdf/2504.15370", "abs": "https://arxiv.org/abs/2504.15370", "authors": ["Juno Nam", "Miguel Steiner", "Max Misterka", "Soojung Yang", "Avni Singhal", "Rafael G\u00f3mez-Bombarelli"], "title": "Transferable Learning of Reaction Pathways from Geometric Priors", "categories": ["physics.chem-ph", "cs.LG"], "comment": "14 pages, 6 figures; Supporting Information in ancillary files", "summary": "Identifying minimum-energy paths (MEPs) is crucial for understanding chemical\nreaction mechanisms but remains computationally demanding. We introduce MEPIN,\na scalable machine-learning method for efficiently predicting MEPs from\nreactant and product configurations, without relying on transition-state\ngeometries or pre-optimized reaction paths during training. The task is defined\nas predicting deviations from geometric interpolations along reaction\ncoordinates. We address this task with a continuous reaction path model based\non a symmetry-broken equivariant neural network that generates a flexible\nnumber of intermediate structures. The model is trained using an energy-based\nobjective, with efficiency enhanced by incorporating geometric priors from\ngeodesic interpolation as initial interpolations or pre-training objectives.\nOur approach generalizes across diverse chemical reactions and achieves\naccurate alignment with reference intrinsic reaction coordinates, as\ndemonstrated on various small molecule reactions and [3+2] cycloadditions. Our\nmethod enables the exploration of large chemical reaction spaces with\nefficient, data-driven predictions of reaction pathways.", "AI": {"tldr": "MEPIN is a scalable ML method for predicting minimum-energy paths (MEPs) in chemical reactions without needing transition-state data, using a symmetry-broken equivariant neural network.", "motivation": "Understanding chemical reaction mechanisms via MEPs is computationally intensive; MEPIN aims to provide an efficient, data-driven solution.", "method": "Uses a continuous reaction path model with a symmetry-broken equivariant neural network, trained on energy-based objectives and geometric priors from geodesic interpolation.", "result": "Generalizes across diverse reactions, accurately aligning with reference intrinsic reaction coordinates, as shown in small molecule and cycloaddition reactions.", "conclusion": "MEPIN enables efficient exploration of large chemical reaction spaces with accurate, data-driven MEP predictions."}}
{"id": "2504.16064", "pdf": "https://arxiv.org/pdf/2504.16064", "abs": "https://arxiv.org/abs/2504.16064", "authors": ["Theodoros Kouzelis", "Efstathios Karypidis", "Ioannis Kakogeorgiou", "Spyros Gidaris", "Nikos Komodakis"], "title": "Boosting Generative Image Modeling via Joint Image-Feature Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "Latent diffusion models (LDMs) dominate high-quality image generation, yet\nintegrating representation learning with generative modeling remains a\nchallenge. We introduce a novel generative image modeling framework that\nseamlessly bridges this gap by leveraging a diffusion model to jointly model\nlow-level image latents (from a variational autoencoder) and high-level\nsemantic features (from a pretrained self-supervised encoder like DINO). Our\nlatent-semantic diffusion approach learns to generate coherent image-feature\npairs from pure noise, significantly enhancing both generative quality and\ntraining efficiency, all while requiring only minimal modifications to standard\nDiffusion Transformer architectures. By eliminating the need for complex\ndistillation objectives, our unified design simplifies training and unlocks a\npowerful new inference strategy: Representation Guidance, which leverages\nlearned semantics to steer and refine image generation. Evaluated in both\nconditional and unconditional settings, our method delivers substantial\nimprovements in image quality and training convergence speed, establishing a\nnew direction for representation-aware generative modeling.", "AI": {"tldr": "A novel framework integrates representation learning with generative modeling using latent-semantic diffusion, improving image quality and training efficiency.", "motivation": "Bridging the gap between representation learning and generative modeling in latent diffusion models (LDMs) for high-quality image generation.", "method": "Leverages a diffusion model to jointly model low-level image latents and high-level semantic features, simplifying training with minimal architectural changes.", "result": "Enhances generative quality and training efficiency, introduces Representation Guidance for refined image generation.", "conclusion": "Establishes a new direction for representation-aware generative modeling with improved image quality and convergence speed."}}
{"id": "2503.11816", "pdf": "https://arxiv.org/pdf/2503.11816", "abs": "https://arxiv.org/abs/2503.11816", "authors": ["Neusha Javidnia", "Bita Darvish Rouhani", "Farinaz Koushanfar"], "title": "Key, Value, Compress: A Systematic Exploration of KV Cache Compression Techniques", "categories": ["cs.CL"], "comment": "Presented at IEEE Custom Integrated Circuits Conference (CICC) 2025", "summary": "Large language models (LLMs) have demonstrated exceptional capabilities in\ngenerating text, images, and video content. However, as context length grows,\nthe computational cost of attention increases quadratically with the number of\ntokens, presenting significant efficiency challenges. This paper presents an\nanalysis of various Key-Value (KV) cache compression strategies, offering a\ncomprehensive taxonomy that categorizes these methods by their underlying\nprinciples and implementation techniques. Furthermore, we evaluate their impact\non performance and inference latency, providing critical insights into their\neffectiveness. Our findings highlight the trade-offs involved in KV cache\ncompression and its influence on handling long-context scenarios, paving the\nway for more efficient LLM implementations.", "AI": {"tldr": "Analysis of KV cache compression strategies for efficient LLM inference, focusing on performance and latency trade-offs.", "motivation": "Address the quadratic computational cost growth in LLM attention as context length increases.", "method": "Taxonomy and evaluation of KV cache compression strategies by principles and techniques.", "result": "Identified trade-offs in KV cache compression affecting performance and latency in long-context scenarios.", "conclusion": "Provides insights for more efficient LLM implementations through optimized KV cache compression."}}
{"id": "2309.13218", "pdf": "https://arxiv.org/pdf/2309.13218", "abs": "https://arxiv.org/abs/2309.13218", "authors": ["Pivithuru Thejan Amarasinghe", "Su Nguyen", "Yuan Sun", "Damminda Alahakoon"], "title": "Language Models for Business Optimisation with a Real World Case Study in Production Scheduling", "categories": ["cs.AI"], "comment": null, "summary": "Business optimisation has been used extensively to determine optimal\nsolutions for challenging business operations. Problem formulation is an\nimportant part of business optimisation as it influences both the validity of\nsolutions and the efficiency of the optimisation process. While different\noptimisation modelling languages have been developed, problem formulation is\nstill not a trivial task and usually requires optimisation expertise and\nproblem-domain knowledge. Recently, Large Language Models (LLMs) have\ndemonstrated outstanding performance across different language-related tasks.\nSince problem formulation can be viewed as a translation task, there is a\npotential to leverage LLMs to automate problem formulation. However, developing\nan LLM for problem formulation is challenging, due to limited training data,\nand the complexity of real-world optimisation problems. Several prompt\nengineering methods have been proposed in the literature to automate problem\nformulation with LLMs. While the initial results are encouraging, the accuracy\nof formulations generated by these methods can still be significantly improved.\nIn this paper, we present an LLM-based framework for automating problem\nformulation in business optimization. Our approach introduces a method for\nfine-tuning cost-efficient LLMs specifically tailored to specialized business\noptimization challenges. The experiment results demonstrate that our framework\ncan generate accurate formulations for conventional and real-world business\noptimisation problems in production scheduling. Extensive analyses show the\neffectiveness and the convergence of the proposed fine-tuning method. The\nproposed method also shows very competitive performance when compared with the\nstate-of-the-art prompt engineering methods in the literature when tested on\ngeneral linear programming problems.", "AI": {"tldr": "The paper proposes an LLM-based framework for automating problem formulation in business optimization, focusing on fine-tuning cost-efficient LLMs for specialized challenges.", "motivation": "Problem formulation in business optimization is complex and requires expertise. LLMs show potential for automating this task, but challenges like limited training data and problem complexity exist.", "method": "The authors introduce a method for fine-tuning cost-efficient LLMs tailored to business optimization problems, tested on production scheduling and general linear programming.", "result": "The framework generates accurate formulations for conventional and real-world problems, showing effectiveness and convergence in fine-tuning. It outperforms state-of-the-art prompt engineering methods.", "conclusion": "The proposed LLM-based framework is effective for automating problem formulation in business optimization, offering competitive performance and scalability."}}
{"id": "2504.15375", "pdf": "https://arxiv.org/pdf/2504.15375", "abs": "https://arxiv.org/abs/2504.15375", "authors": ["Bradley Boswell", "Seth Barrett", "Swarnamugi Rajaganapathy", "Gokila Dorai"], "title": "FLARE: Feature-based Lightweight Aggregation for Robust Evaluation of IoT Intrusion Detection", "categories": ["cs.CR", "cs.LG"], "comment": "23 pages, 19 tables, 2 algorithms, 2 figures, submitted to\n  SecureComm25", "summary": "The proliferation of Internet of Things (IoT) devices has expanded the attack\nsurface, necessitating efficient intrusion detection systems (IDSs) for network\nprotection. This paper presents FLARE, a feature-based lightweight aggregation\nfor robust evaluation of IoT intrusion detection to address the challenges of\nsecuring IoT environments through feature aggregation techniques. FLARE\nutilizes a multilayered processing approach, incorporating session, flow, and\ntime-based sliding-window data aggregation to analyze network behavior and\ncapture vital features from IoT network traffic data. We perform extensive\nevaluations on IoT data generated from our laboratory experimental setup to\nassess the effectiveness of the proposed aggregation technique. To classify\nattacks in IoT IDS, we employ four supervised learning models and two deep\nlearning models. We validate the performance of these models in terms of\naccuracy, precision, recall, and F1-score. Our results reveal that\nincorporating the FLARE aggregation technique as a foundational step in feature\nengineering, helps lay a structured representation, and enhances the\nperformance of complex end-to-end models, making it a crucial step in IoT IDS\npipeline. Our findings highlight the potential of FLARE as a valuable technique\nto improve performance and reduce computational costs of end-to-end IDS\nimplementations, thereby fostering more robust IoT intrusion detection systems.", "AI": {"tldr": "FLARE is a feature-based lightweight aggregation technique for IoT intrusion detection, enhancing model performance through structured feature engineering.", "motivation": "The increasing attack surface due to IoT proliferation demands efficient IDSs, addressed by FLARE's feature aggregation.", "method": "FLARE uses multilayered processing (session, flow, time-based sliding-window) and evaluates with supervised and deep learning models.", "result": "FLARE improves accuracy, precision, recall, and F1-score, reducing computational costs for IoT IDS.", "conclusion": "FLARE is a crucial step in IoT IDS pipelines, enhancing robustness and efficiency."}}
{"id": "2504.16080", "pdf": "https://arxiv.org/pdf/2504.16080", "abs": "https://arxiv.org/abs/2504.16080", "authors": ["Le Zhuo", "Liangbing Zhao", "Sayak Paul", "Yue Liao", "Renrui Zhang", "Yi Xin", "Peng Gao", "Mohamed Elhoseiny", "Hongsheng Li"], "title": "From Reflection to Perfection: Scaling Inference-Time Optimization for Text-to-Image Diffusion Models via Reflection Tuning", "categories": ["cs.CV"], "comment": "All code, checkpoints, and datasets are available at\n  \\url{https://diffusion-cot.github.io/reflection2perfection}", "summary": "Recent text-to-image diffusion models achieve impressive visual quality\nthrough extensive scaling of training data and model parameters, yet they often\nstruggle with complex scenes and fine-grained details. Inspired by the\nself-reflection capabilities emergent in large language models, we propose\nReflectionFlow, an inference-time framework enabling diffusion models to\niteratively reflect upon and refine their outputs. ReflectionFlow introduces\nthree complementary inference-time scaling axes: (1) noise-level scaling to\noptimize latent initialization; (2) prompt-level scaling for precise semantic\nguidance; and most notably, (3) reflection-level scaling, which explicitly\nprovides actionable reflections to iteratively assess and correct previous\ngenerations. To facilitate reflection-level scaling, we construct GenRef, a\nlarge-scale dataset comprising 1 million triplets, each containing a\nreflection, a flawed image, and an enhanced image. Leveraging this dataset, we\nefficiently perform reflection tuning on state-of-the-art diffusion\ntransformer, FLUX.1-dev, by jointly modeling multimodal inputs within a unified\nframework. Experimental results show that ReflectionFlow significantly\noutperforms naive noise-level scaling methods, offering a scalable and\ncompute-efficient solution toward higher-quality image synthesis on challenging\ntasks.", "AI": {"tldr": "ReflectionFlow is an inference-time framework for diffusion models, introducing noise-level, prompt-level, and reflection-level scaling to iteratively refine outputs, outperforming naive methods.", "motivation": "Addressing the limitations of current text-to-image diffusion models in handling complex scenes and fine-grained details by leveraging self-reflection capabilities.", "method": "Proposes ReflectionFlow with three scaling axes: noise-level, prompt-level, and reflection-level. Uses GenRef dataset (1M triplets) for reflection tuning on FLUX.1-dev.", "result": "Significantly outperforms naive noise-level scaling methods, improving image synthesis quality.", "conclusion": "ReflectionFlow offers a scalable and efficient solution for higher-quality image generation in challenging tasks."}}
{"id": "2504.00021", "pdf": "https://arxiv.org/pdf/2504.00021", "abs": "https://arxiv.org/abs/2504.00021", "authors": ["Rahul Raja", "Arpita Vats"], "title": "FUSE : A Ridge and Random Forest-Based Metric for Evaluating MT in Indigenous Languages", "categories": ["cs.CL"], "comment": "NACCL 2025", "summary": "This paper presents the winning submission of the RaaVa team to the\nAmericasNLP 2025 Shared Task 3 on Automatic Evaluation Metrics for Machine\nTranslation (MT) into Indigenous Languages of America, where our system ranked\nfirst overall based on average Pearson correlation with the human annotations.\nWe introduce Feature-Union Scorer (FUSE) for Evaluation, FUSE integrates Ridge\nregression and Gradient Boosting to model translation quality. In addition to\nFUSE, we explore five alternative approaches leveraging different combinations\nof linguistic similarity features and learning paradigms. FUSE Score highlights\nthe effectiveness of combining lexical, phonetic, semantic, and fuzzy token\nsimilarity with learning-based modeling to improve MT evaluation for\nmorphologically rich and low-resource languages. MT into Indigenous languages\nposes unique challenges due to polysynthesis, complex morphology, and\nnon-standardized orthography. Conventional automatic metrics such as BLEU, TER,\nand ChrF often fail to capture deeper aspects like semantic adequacy and\nfluency. Our proposed framework, formerly referred to as FUSE, incorporates\nmultilingual sentence embeddings and phonological encodings to better align\nwith human evaluation. We train supervised models on human-annotated\ndevelopment sets and evaluate held-out test data. Results show that FUSE\nconsistently achieves higher Pearson and Spearman correlations with human\njudgments, offering a robust and linguistically informed solution for MT\nevaluation in low-resource settings.", "AI": {"tldr": "The paper introduces FUSE, a winning MT evaluation metric combining Ridge regression and Gradient Boosting, outperforming traditional metrics like BLEU for Indigenous languages.", "motivation": "Traditional MT metrics fail for Indigenous languages due to polysynthesis and complex morphology; FUSE addresses this gap.", "method": "FUSE integrates lexical, phonetic, semantic, and fuzzy token similarity with Ridge regression and Gradient Boosting, using multilingual embeddings and phonological encodings.", "result": "FUSE achieves higher Pearson and Spearman correlations with human judgments than conventional metrics.", "conclusion": "FUSE provides a robust, linguistically informed solution for MT evaluation in low-resource settings."}}
{"id": "2402.15929", "pdf": "https://arxiv.org/pdf/2402.15929", "abs": "https://arxiv.org/abs/2402.15929", "authors": ["Isha Chaudhary", "Vedaant V. Jain", "Gagandeep Singh"], "title": "Certifying Knowledge Comprehension in LLMs", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed in safety-critical\nsystems where they provide answers based on in-context information derived from\nknowledge bases. As LLMs are increasingly envisioned as superhuman agents,\ntheir proficiency in knowledge comprehension-extracting relevant information\nand reasoning over it to answer questions, a key facet of human\nintelligence-becomes crucial. However, existing evaluations of LLMs on\nknowledge comprehension are typically conducted on small test sets, but these\ndatasets represent only a tiny fraction of the vast number of possible queries.\nSimple empirical evaluations on these limited test sets raises concerns about\nthe reliability and generalizability of the results. In this work, we introduce\nthe first specification and certification framework for knowledge comprehension\nin LLMs, providing formal probabilistic guarantees for reliability. Instead of\na fixed dataset, we design novel specifications that mathematically represent\nprohibitively large probability distributions of knowledge comprehension\nprompts with natural noise, using knowledge graphs. From these specifications,\nwe generate quantitative certificates that offer high-confidence, tight bounds\non the probability that a given LLM correctly answers any question drawn from\nthe specification distribution. We apply our framework to certify SOTA LLMs in\ntwo domains: precision medicine and general question-answering. Our results\nreveal previously unrecognized vulnerabilities in SOTA LLMs due to natural\nnoise in the prompts. Additionally, we establish performance hierarchies with\nformal guarantees among the SOTA LLMs, particularly in the context of precision\nmedicine question-answering.", "AI": {"tldr": "The paper introduces a certification framework for evaluating LLMs' knowledge comprehension, offering formal guarantees on reliability and revealing vulnerabilities in state-of-the-art models.", "motivation": "Existing evaluations of LLMs on knowledge comprehension rely on small datasets, raising concerns about reliability and generalizability.", "method": "The authors propose a specification and certification framework using knowledge graphs to represent large distributions of prompts and generate probabilistic guarantees.", "result": "The framework uncovers vulnerabilities in SOTA LLMs due to natural noise and establishes performance hierarchies with formal guarantees.", "conclusion": "The work provides a robust method for certifying LLMs' knowledge comprehension, enhancing reliability in safety-critical applications."}}
{"id": "2504.15386", "pdf": "https://arxiv.org/pdf/2504.15386", "abs": "https://arxiv.org/abs/2504.15386", "authors": ["Rebecca Knowlton", "Layla Parast"], "title": "Assessing Surrogate Heterogeneity in Real World Data Using Meta-Learners", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "Surrogate markers are most commonly studied within the context of randomized\nclinical trials. However, the need for alternative outcomes extends beyond\nthese settings and may be more pronounced in real-world public health and\nsocial science research, where randomized trials are often impractical.\nResearch on identifying surrogates in real-world non-randomized data is scarce,\nas available statistical approaches for evaluating surrogate markers tend to\nrely on the assumption that treatment is randomized. While the few methods that\nallow for non-randomized treatment/exposure appropriately handle confounding\nindividual characteristics, they do not offer a way to examine surrogate\nheterogeneity with respect to patient characteristics. In this paper, we\npropose a framework to assess surrogate heterogeneity in real-world, i.e.,\nnon-randomized, data and implement this framework using various meta-learners.\nOur approach allows us to quantify heterogeneity in surrogate strength with\nrespect to patient characteristics while accommodating confounders through the\nuse of flexible, off-the-shelf machine learning methods. In addition, we use\nour framework to identify individuals for whom the surrogate is a valid\nreplacement of the primary outcome. We examine the performance of our methods\nvia a simulation study and application to examine heterogeneity in the\nsurrogacy of hemoglobin A1c as a surrogate for fasting plasma glucose.", "AI": {"tldr": "The paper proposes a framework to assess surrogate marker heterogeneity in non-randomized real-world data, addressing gaps in existing methods by incorporating patient characteristics and confounders using machine learning.", "motivation": "Current methods for evaluating surrogate markers assume randomized treatment, limiting their applicability in real-world public health and social science research where randomization is impractical.", "method": "The authors introduce a framework using meta-learners to quantify surrogate heterogeneity with respect to patient characteristics, accommodating confounders via flexible machine learning.", "result": "The framework is validated through simulations and applied to assess hemoglobin A1c as a surrogate for fasting plasma glucose, demonstrating its effectiveness.", "conclusion": "The proposed approach enables surrogate heterogeneity assessment in non-randomized data, offering a practical tool for real-world research."}}
{"id": "2504.16082", "pdf": "https://arxiv.org/pdf/2504.16082", "abs": "https://arxiv.org/abs/2504.16082", "authors": ["Ziqi Pang", "Yu-Xiong Wang"], "title": "MR. Video: \"MapReduce\" is the Principle for Long Video Understanding", "categories": ["cs.CV"], "comment": "Preprint", "summary": "We propose MR. Video, an agentic long video understanding framework that\ndemonstrates the simple yet effective MapReduce principle for processing long\nvideos: (1) Map: independently and densely perceiving short video clips, and\n(2) Reduce: jointly aggregating information from all clips. Compared with\nsequence-to-sequence vision-language models (VLMs), MR. Video performs detailed\nshort video perception without being limited by context length. Compared with\nexisting video agents that typically rely on sequential key segment selection,\nthe Map operation enables simpler and more scalable sequence parallel\nperception of short video segments. Its Reduce step allows for more\ncomprehensive context aggregation and reasoning, surpassing explicit key\nsegment retrieval. This MapReduce principle is applicable to both VLMs and\nvideo agents, and we use LLM agents to validate its effectiveness.\n  In practice, MR. Video employs two MapReduce stages: (A) Captioning:\ngenerating captions for short video clips (map), then standardizing repeated\ncharacters and objects into shared names (reduce); (B) Analysis: for each user\nquestion, analyzing relevant information from individual short videos (map),\nand integrating them into a final answer (reduce). MR. Video achieves over 10%\naccuracy improvement on the challenging LVBench compared to state-of-the-art\nVLMs and video agents.\n  Code is available at: https://github.com/ziqipang/MR-Video", "AI": {"tldr": "MR. Video is a framework for long video understanding using a MapReduce principle: Map for dense short clip perception and Reduce for joint aggregation. It outperforms existing methods by 10% on LVBench.", "motivation": "Existing methods for long video understanding are limited by context length or rely on sequential key segment selection, which is less scalable and comprehensive.", "method": "MR. Video uses a two-stage MapReduce approach: (A) Captioning (Map: caption clips, Reduce: standardize names) and (B) Analysis (Map: analyze clips, Reduce: integrate answers).", "result": "Achieves over 10% accuracy improvement on LVBench compared to state-of-the-art methods.", "conclusion": "The MapReduce principle is effective for long video understanding, offering scalability and comprehensive reasoning."}}
{"id": "2504.01801", "pdf": "https://arxiv.org/pdf/2504.01801", "abs": "https://arxiv.org/abs/2504.01801", "authors": ["Zhijun Wang", "Jiahuan Li", "Hao Zhou", "Rongxiang Weng", "Jingang Wang", "Xin Huang", "Xue Han", "Junlan Feng", "Chao Deng", "Shujian Huang"], "title": "Investigating and Scaling up Code-Switching for Multilingual Language Model Pre-Training", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) exhibit remarkable multilingual capabilities\ndespite the extreme language imbalance in the pre-training data. In this paper,\nwe closely examine the reasons behind this phenomenon, focusing on the\npre-training corpus. We find that the existence of code-switching, alternating\nbetween different languages within a context, is key to multilingual\ncapabilities. We conduct an analysis to investigate code-switching in the\npre-training corpus, examining its presence and categorizing it into four types\nwithin two quadrants. We then assess its impact on multilingual performance.\nThese types of code-switching data are unbalanced in proportions and\ndemonstrate different effects on facilitating language transfer. To better\nexplore the power of code-switching for language alignment during pre-training,\nwe investigate the strategy of synthetic code-switching. We continuously scale\nup the synthetic code-switching data and observe remarkable improvements in\nboth benchmarks and representation space. Extensive experiments indicate that\nincorporating synthetic code-switching data enables better language alignment\nand generalizes well to high, medium, and low-resource languages with\npre-training corpora of varying qualities.", "AI": {"tldr": "The paper explores how code-switching in pre-training data enhances multilingual capabilities of LLMs, identifies four types of code-switching, and shows synthetic code-switching improves performance across languages.", "motivation": "To understand why LLMs exhibit strong multilingual abilities despite imbalanced training data, focusing on the role of code-switching.", "method": "Analyzes code-switching in pre-training data, categorizes it into four types, and tests synthetic code-switching's impact on performance.", "result": "Synthetic code-switching significantly improves multilingual performance, benefiting high, medium, and low-resource languages.", "conclusion": "Code-switching, especially when synthetically enhanced, is crucial for multilingual alignment and performance in LLMs."}}
{"id": "2405.18780", "pdf": "https://arxiv.org/pdf/2405.18780", "abs": "https://arxiv.org/abs/2405.18780", "authors": ["Isha Chaudhary", "Qian Hu", "Manoj Kumar", "Morteza Ziyadi", "Rahul Gupta", "Gagandeep Singh"], "title": "Certifying Counterfactual Bias in LLMs", "categories": ["cs.AI", "cs.LG"], "comment": "Published at ICLR 2025", "summary": "Large Language Models (LLMs) can produce biased responses that can cause\nrepresentational harms. However, conventional studies are insufficient to\nthoroughly evaluate biases across LLM responses for different demographic\ngroups (a.k.a. counterfactual bias), as they do not scale to large number of\ninputs and do not provide guarantees. Therefore, we propose the first\nframework, LLMCert-B that certifies LLMs for counterfactual bias on\ndistributions of prompts. A certificate consists of high-confidence bounds on\nthe probability of unbiased LLM responses for any set of counterfactual prompts\n- prompts differing by demographic groups, sampled from a distribution. We\nillustrate counterfactual bias certification for distributions of\ncounterfactual prompts created by applying prefixes sampled from prefix\ndistributions, to a given set of prompts. We consider prefix distributions\nconsisting random token sequences, mixtures of manual jailbreaks, and\nperturbations of jailbreaks in LLM's embedding space. We generate non-trivial\ncertificates for SOTA LLMs, exposing their vulnerabilities over distributions\nof prompts generated from computationally inexpensive prefix distributions.", "AI": {"tldr": "LLMCert-B is a framework to certify LLMs for counterfactual bias, providing high-confidence bounds on unbiased responses for demographic-specific prompts.", "motivation": "Existing methods fail to thoroughly evaluate biases in LLMs across demographic groups due to scalability and lack of guarantees.", "method": "Proposes LLMCert-B to certify counterfactual bias on prompt distributions, using prefix distributions (random tokens, jailbreaks, perturbations).", "result": "Non-trivial certificates generated for SOTA LLMs, revealing vulnerabilities over inexpensive prompt distributions.", "conclusion": "LLMCert-B effectively identifies and certifies biases in LLMs, highlighting their limitations in handling demographic-specific prompts."}}
{"id": "2504.15388", "pdf": "https://arxiv.org/pdf/2504.15388", "abs": "https://arxiv.org/abs/2504.15388", "authors": ["Tianyi Ma", "Tengyao Wang", "Richard J. Samworth"], "title": "Deep learning with missing data", "categories": ["stat.ME", "cs.LG", "math.ST", "stat.ML", "stat.TH", "62C20, 62D10, 62G08"], "comment": "49 pages, 9 figures", "summary": "In the context of multivariate nonparametric regression with missing\ncovariates, we propose Pattern Embedded Neural Networks (PENNs), which can be\napplied in conjunction with any existing imputation technique. In addition to a\nneural network trained on the imputed data, PENNs pass the vectors of\nobservation indicators through a second neural network to provide a compact\nrepresentation. The outputs are then combined in a third neural network to\nproduce final predictions. Our main theoretical result exploits an assumption\nthat the observation patterns can be partitioned into cells on which the Bayes\nregression function behaves similarly, and belongs to a compositional H\\\"older\nclass. It provides a finite-sample excess risk bound that holds for an\narbitrary missingness mechanism, and in combination with a complementary\nminimax lower bound, demonstrates that our PENN estimator attains in typical\ncases the minimax rate of convergence as if the cells of the partition were\nknown in advance, up to a poly-logarithmic factor in the sample size. Numerical\nexperiments on simulated, semi-synthetic and real data confirm that the PENN\nestimator consistently improves, often dramatically, on standard neural\nnetworks without pattern embedding. Code to reproduce our experiments, as well\nas a tutorial on how to apply our method, is publicly available.", "AI": {"tldr": "PENNs improve multivariate nonparametric regression with missing covariates by embedding observation patterns into neural networks, achieving near-minimax convergence rates.", "motivation": "Addressing the challenge of missing covariates in regression by leveraging observation patterns for better predictions.", "method": "Uses three neural networks: one for imputed data, one for observation indicators, and a third to combine outputs. Assumes partitionable observation patterns and compositional H\u00f6lder class regression functions.", "result": "Theoretical bounds show PENNs achieve near-minimax rates. Experiments confirm significant improvement over standard neural networks.", "conclusion": "PENNs effectively handle missing data and outperform traditional methods, with practical implementation support."}}
{"id": "2504.16083", "pdf": "https://arxiv.org/pdf/2504.16083", "abs": "https://arxiv.org/abs/2504.16083", "authors": ["Yucheng Li", "Huiqiang Jiang", "Chengruidong Zhang", "Qianhui Wu", "Xufang Luo", "Surin Ahn", "Amir H. Abdi", "Dongsheng Li", "Jianfeng Gao", "Yuqing Yang", "Lili Qiu"], "title": "MMInference: Accelerating Pre-filling for Long-Context VLMs via Modality-Aware Permutation Sparse Attention", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The integration of long-context capabilities with visual understanding\nunlocks unprecedented potential for Vision Language Models (VLMs). However, the\nquadratic attention complexity during the pre-filling phase remains a\nsignificant obstacle to real-world deployment. To overcome this limitation, we\nintroduce MMInference (Multimodality Million tokens Inference), a dynamic\nsparse attention method that accelerates the prefilling stage for long-context\nmulti-modal inputs. First, our analysis reveals that the temporal and spatial\nlocality of video input leads to a unique sparse pattern, the Grid pattern.\nSimultaneously, VLMs exhibit markedly different sparse distributions across\ndifferent modalities. We introduce a permutation-based method to leverage the\nunique Grid pattern and handle modality boundary issues. By offline search the\noptimal sparse patterns for each head, MMInference constructs the sparse\ndistribution dynamically based on the input. We also provide optimized GPU\nkernels for efficient sparse computations. Notably, MMInference integrates\nseamlessly into existing VLM pipelines without any model modifications or\nfine-tuning. Experiments on multi-modal benchmarks-including Video QA,\nCaptioning, VisionNIAH, and Mixed-Modality NIAH-with state-of-the-art\nlong-context VLMs (LongVila, LlavaVideo, VideoChat-Flash, Qwen2.5-VL) show that\nMMInference accelerates the pre-filling stage by up to 8.3x at 1M tokens while\nmaintaining accuracy. Our code is available at https://aka.ms/MMInference.", "AI": {"tldr": "MMInference introduces a dynamic sparse attention method to accelerate the pre-filling stage for long-context multi-modal inputs in VLMs, achieving up to 8.3x speedup without accuracy loss.", "motivation": "Quadratic attention complexity in VLMs hinders real-world deployment; MMInference addresses this by leveraging sparse patterns in multi-modal inputs.", "method": "Uses a permutation-based method to exploit the Grid pattern in video inputs and dynamically constructs sparse distributions. Optimized GPU kernels enhance efficiency.", "result": "Achieves up to 8.3x speedup in pre-filling at 1M tokens while maintaining accuracy across multi-modal benchmarks.", "conclusion": "MMInference effectively accelerates VLMs without model modifications, offering practical benefits for long-context multi-modal tasks."}}
{"id": "2504.07989", "pdf": "https://arxiv.org/pdf/2504.07989", "abs": "https://arxiv.org/abs/2504.07989", "authors": ["Nirvan Patil", "Malhar Abhay Inamdar", "Agnivo Gosai", "Guruprasad Pathak", "Anish Joshi", "Aryan Sagavekar", "Anish Joshirao", "Raj Dandekar", "Rajat Dandekar", "Sreedath Panat"], "title": "Regional Tiny Stories: Using Small Models to Compare Language Learning and Tokenizer Performance", "categories": ["cs.CL", "cs.AI"], "comment": "34 pages, 24 figures, 16 tables", "summary": "Small Language Models (SLMs) offer efficient alternatives to LLMs for\nspecific domains. The 2023 TinyStories study developed an English dataset that\nallows SLMs with 1 to 10 million parameters to produce coherent outputs. Our\nresearch expands this framework by translating the original dataset into Indian\nlanguages and creating synthetic data using LLMs. We focus on Hindi, Marathi,\nand Bengali, evaluating SLMs for regional language processing and understanding\nlinguistic complexity. We show that SLMs efficiently process regional languages\nwith significantly fewer parameters than LLMs, providing a complementary\nframework for ``inference based evaluation\" of tokenization strategies and\nlinguistic complexity. Our analysis shows that language-specific tokenizers\noutperform general-purpose ones for Indian languages. Empirical validations,\nsupported by information-theoretic and morphological analyses, provides\nfundamental understanding behind the better performance of Hindi models over\nMarathi and Bengali. Additionally, we show that synthetic datasets outperform\ntranslated content for training SLMs. Correlation analyses reveal\ncross-linguistic patterns and language-specific relationships between\ncreativity, grammatical precision, and narrative completeness. These findings\nadvance both the practical application of SLMs to underserved languages and our\ntheoretical understanding of neural language development.", "AI": {"tldr": "The study extends TinyStories to Indian languages (Hindi, Marathi, Bengali), showing SLMs outperform LLMs with fewer parameters. Language-specific tokenizers and synthetic data enhance performance, revealing cross-linguistic patterns.", "motivation": "To adapt SLMs for Indian languages, addressing regional language processing and linguistic complexity with fewer parameters than LLMs.", "method": "Translated TinyStories dataset into Hindi, Marathi, Bengali; created synthetic data using LLMs; evaluated SLMs with language-specific tokenizers.", "result": "SLMs process regional languages efficiently; Hindi models outperform Marathi and Bengali; synthetic data beats translated content.", "conclusion": "SLMs offer practical solutions for underserved languages, advancing theoretical understanding of neural language development."}}
{"id": "2408.12871", "pdf": "https://arxiv.org/pdf/2408.12871", "abs": "https://arxiv.org/abs/2408.12871", "authors": ["Zhou Xiaochen", "Liang Xingzhou", "Zou Hui", "Lu Yi", "Qu Jingjing"], "title": "DeepDiveAI: Identifying AI Related Documents in Large Scale Literature Data", "categories": ["cs.AI"], "comment": null, "summary": "In this paper, we propose a method to automatically classify AI-related\ndocuments from large-scale literature databases, leading to the creation of an\nAI-related literature dataset, named DeepDiveAI. The dataset construction\napproach integrates expert knowledge with the capabilities of advanced models,\nstructured across two global stages. In the first stage, expert-curated\nclassification datasets are used to train an LSTM model, which classifies\ncoarse AI related records from large-scale datasets. In the second stage, we\nuse Qwen2.5 Plus to annotate a random 10% of the coarse AI-related records,\nwhich are then used to train a BERT binary classifier. This step further\nrefines the coarse AI related record set to obtain the final DeepDiveAI\ndataset. Evaluation results demonstrate that the entire workflow can\nefficiently and accurately identify AI-related literature from large-scale\ndatasets.", "AI": {"tldr": "Proposes a two-stage method to classify AI-related documents, creating the DeepDiveAI dataset using expert knowledge and advanced models (LSTM and BERT).", "motivation": "To efficiently and accurately identify AI-related literature from large-scale datasets.", "method": "1. Train an LSTM model on expert-curated data for coarse classification. 2. Use Qwen2.5 Plus to annotate a subset, then train a BERT classifier for refinement.", "result": "The workflow efficiently and accurately identifies AI-related literature, resulting in the DeepDiveAI dataset.", "conclusion": "The proposed method successfully constructs a high-quality AI-related literature dataset."}}
{"id": "2504.15414", "pdf": "https://arxiv.org/pdf/2504.15414", "abs": "https://arxiv.org/abs/2504.15414", "authors": ["Dylan Khor", "Bowen Weng"], "title": "Post-Convergence Sim-to-Real Policy Transfer: A Principled Alternative to Cherry-Picking", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Learning-based approaches, particularly reinforcement learning (RL), have\nbecome widely used for developing control policies for autonomous agents, such\nas locomotion policies for legged robots. RL training typically maximizes a\npredefined reward (or minimizes a corresponding cost/loss) by iteratively\noptimizing policies within a simulator. Starting from a randomly initialized\npolicy, the empirical expected reward follows a trajectory with an overall\nincreasing trend. While some policies become temporarily stuck in local optima,\na well-defined training process generally converges to a reward level with\nnoisy oscillations. However, selecting a policy for real-world deployment is\nrarely an analytical decision (i.e., simply choosing the one with the highest\nreward) and is instead often performed through trial and error. To improve\nsim-to-real transfer, most research focuses on the pre-convergence stage,\nemploying techniques such as domain randomization, multi-fidelity training,\nadversarial training, and architectural innovations. However, these methods do\nnot eliminate the inevitable convergence trajectory and noisy oscillations of\nrewards, leading to heuristic policy selection or cherry-picking. This paper\naddresses the post-convergence sim-to-real transfer problem by introducing a\nworst-case performance transference optimization approach, formulated as a\nconvex quadratic-constrained linear programming problem. Extensive experiments\ndemonstrate its effectiveness in transferring RL-based locomotion policies from\nsimulation to real-world laboratory tests.", "AI": {"tldr": "The paper introduces a worst-case performance optimization method for post-convergence sim-to-real transfer in RL, improving policy selection beyond heuristic approaches.", "motivation": "Current RL training methods focus on pre-convergence techniques but fail to address noisy oscillations and heuristic policy selection post-convergence, limiting sim-to-real transfer.", "method": "Proposes a convex quadratic-constrained linear programming approach to optimize worst-case performance for post-convergence policy transfer.", "result": "Demonstrates effectiveness in transferring RL-based locomotion policies from simulation to real-world tests.", "conclusion": "The method enhances sim-to-real transfer by addressing post-convergence challenges, offering a more analytical policy selection process."}}
{"id": "2504.09697", "pdf": "https://arxiv.org/pdf/2504.09697", "abs": "https://arxiv.org/abs/2504.09697", "authors": ["Kenan Tang", "Yanhong Li", "Yao Qin"], "title": "SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": "24 pages, 21 figures. Figure 9(b) has been accepted by CVPR AI Art\n  Gallery 2025", "summary": "Recent prompt-based image editing models have demonstrated impressive\nprompt-following capability at structural editing tasks. However, existing\nmodels still fail to perform local edits, follow detailed editing prompts, or\nmaintain global image quality beyond a single editing step. To address these\nchallenges, we introduce SPICE, a training-free workflow that accepts arbitrary\nresolutions and aspect ratios, accurately follows user requirements, and\nimproves image quality consistently during more than 100 editing steps. By\nsynergizing the strengths of a base diffusion model and a Canny edge ControlNet\nmodel, SPICE robustly handles free-form editing instructions from the user.\nSPICE outperforms state-of-the-art baselines on a challenging realistic\nimage-editing dataset consisting of semantic editing (object addition, removal,\nreplacement, and background change), stylistic editing (texture changes), and\nstructural editing (action change) tasks. Not only does SPICE achieve the\nhighest quantitative performance according to standard evaluation metrics, but\nit is also consistently preferred by users over existing image-editing methods.\nWe release the workflow implementation for popular diffusion model Web UIs to\nsupport further research and artistic exploration.", "AI": {"tldr": "SPICE is a training-free workflow for image editing that outperforms existing models by handling arbitrary resolutions, following detailed prompts, and maintaining quality over 100+ editing steps.", "motivation": "Existing prompt-based image editing models struggle with local edits, detailed prompts, and multi-step quality maintenance.", "method": "SPICE combines a base diffusion model with a Canny edge ControlNet model to handle free-form editing instructions.", "result": "SPICE excels in semantic, stylistic, and structural editing tasks, achieving top quantitative metrics and user preference.", "conclusion": "SPICE is released for further research and artistic use, demonstrating superior performance in realistic image editing."}}
{"id": "2504.10284", "pdf": "https://arxiv.org/pdf/2504.10284", "abs": "https://arxiv.org/abs/2504.10284", "authors": ["Weiqi Wang", "Jiefu Ou", "Yangqiu Song", "Benjamin Van Durme", "Daniel Khashabi"], "title": "Can LLMs Generate Tabular Summaries of Science Papers? Rethinking the Evaluation Protocol", "categories": ["cs.CL"], "comment": null, "summary": "Literature review tables are essential for summarizing and comparing\ncollections of scientific papers. We explore the task of generating tables that\nbest fulfill a user's informational needs given a collection of scientific\npapers. Building on recent work (Newman et al., 2024), we extend prior\napproaches to address real-world complexities through a combination of\nLLM-based methods and human annotations. Our contributions focus on three key\nchallenges encountered in real-world use: (i) User prompts are often\nunder-specified; (ii) Retrieved candidate papers frequently contain irrelevant\ncontent; and (iii) Task evaluation should move beyond shallow text similarity\ntechniques and instead assess the utility of inferred tables for\ninformation-seeking tasks (e.g., comparing papers). To support reproducible\nevaluation, we introduce ARXIV2TABLE, a more realistic and challenging\nbenchmark for this task, along with a novel approach to improve literature\nreview table generation in real-world scenarios. Our extensive experiments on\nthis benchmark show that both open-weight and proprietary LLMs struggle with\nthe task, highlighting its difficulty and the need for further advancements.\nOur dataset and code are available at https://github.com/JHU-CLSP/arXiv2Table.", "AI": {"tldr": "The paper introduces ARXIV2TABLE, a benchmark for generating literature review tables from scientific papers, addressing challenges like under-specified user prompts, irrelevant content, and shallow evaluation metrics.", "motivation": "To improve literature review table generation by tackling real-world complexities and enhancing utility for information-seeking tasks.", "method": "Combines LLM-based methods and human annotations to address key challenges, introducing a novel benchmark (ARXIV2TABLE) for evaluation.", "result": "Experiments show both open-weight and proprietary LLMs struggle with the task, emphasizing its difficulty.", "conclusion": "The work highlights the need for further advancements in literature review table generation and provides a reproducible benchmark for future research."}}
{"id": "2410.21131", "pdf": "https://arxiv.org/pdf/2410.21131", "abs": "https://arxiv.org/abs/2410.21131", "authors": ["Marharyta Domnich", "Julius V\u00e4lja", "Rasmus Moorits Veski", "Giacomo Magnifico", "Kadi Tulver", "Eduard Barbu", "Raul Vicente"], "title": "Towards Unifying Evaluation of Counterfactual Explanations: Leveraging Large Language Models for Human-Centric Assessments", "categories": ["cs.AI", "cs.CL"], "comment": "This paper extends the AAAI-2025 version by including the Appendix", "summary": "As machine learning models evolve, maintaining transparency demands more\nhuman-centric explainable AI techniques. Counterfactual explanations, with\nroots in human reasoning, identify the minimal input changes needed to obtain a\ngiven output and, hence, are crucial for supporting decision-making. Despite\ntheir importance, the evaluation of these explanations often lacks grounding in\nuser studies and remains fragmented, with existing metrics not fully capturing\nhuman perspectives. To address this challenge, we developed a diverse set of 30\ncounterfactual scenarios and collected ratings across 8 evaluation metrics from\n206 respondents. Subsequently, we fine-tuned different Large Language Models\n(LLMs) to predict average or individual human judgment across these metrics.\nOur methodology allowed LLMs to achieve an accuracy of up to 63% in zero-shot\nevaluations and 85% (over a 3-classes prediction) with fine-tuning across all\nmetrics. The fine-tuned models predicting human ratings offer better\ncomparability and scalability in evaluating different counterfactual\nexplanation frameworks.", "AI": {"tldr": "The paper addresses the lack of human-centric evaluation in counterfactual explanations for AI by developing diverse scenarios and using LLMs to predict human judgments, achieving up to 85% accuracy with fine-tuning.", "motivation": "Current evaluation of counterfactual explanations lacks grounding in user studies and fails to fully capture human perspectives, necessitating a more human-centric approach.", "method": "Developed 30 counterfactual scenarios, collected ratings from 206 respondents across 8 metrics, and fine-tuned LLMs to predict human judgments.", "result": "LLMs achieved 63% accuracy in zero-shot evaluations and 85% in fine-tuned evaluations (3-class prediction) across all metrics.", "conclusion": "Fine-tuned LLMs offer scalable and comparable evaluation of counterfactual explanations, bridging the gap between AI and human perspectives."}}
{"id": "2504.15465", "pdf": "https://arxiv.org/pdf/2504.15465", "abs": "https://arxiv.org/abs/2504.15465", "authors": ["Patrick H. Coppock", "Brian Zhang", "Eliot H. Solomon", "Vasilis Kypriotis", "Leon Yang", "Bikash Sharma", "Dan Schatzberg", "Todd C. Mowry", "Dimitrios Skarlatos"], "title": "LithOS: An Operating System for Efficient Machine Learning on GPUs", "categories": ["cs.OS", "cs.LG"], "comment": null, "summary": "The surging demand for GPUs in datacenters for machine learning (ML) has made\nefficient GPU utilization crucial. However, meeting the diverse needs of ML\nmodels while optimizing resource usage is challenging. To enable transparent,\nfine-grained GPU management that maximizes utilization and energy efficiency\nwhile maintaining strong isolation, an operating system (OS) approach is\nneeded. This paper introduces LithOS, a first step toward a GPU OS. LithOS\nincludes the following new abstractions and mechanisms for efficient GPU\nresource management: (i) a novel TPC Scheduler that supports spatial scheduling\nat the granularity of individual TPCs, unlocking efficient TPC stealing between\nworkloads; (ii) transparent kernel atomization to reduce head-of-line blocking\nand enable dynamic resource reallocation mid-execution; (iii) a lightweight\nhardware right-sizing mechanism that determines the minimal TPC resources\nneeded per atom; and (iv) a transparent power management mechanism that reduces\npower consumption based on in-flight work behavior. We implement LithOS in Rust\nand evaluate its performance across extensive ML environments, comparing it to\nstate-of-the-art solutions from NVIDIA and prior research. For inference\nstacking, LithOS reduces tail latencies by 13x compared to MPS; compared to the\nbest SotA, it reduces tail latencies by 3x while improving aggregate throughput\nby 1.6x. In hybrid inference-training stacking, LithOS reduces tail latencies\nby 4.7x compared to MPS; compared to the best SotA, it reduces tail latencies\n1.18x while improving aggregate throughput by 1.35x. Finally, for a modest\nperformance hit under 4%, LithOS's right-sizing provides a quarter of GPU\ncapacity savings on average, while for a 7% hit, its power management yields a\nquarter of a GPU's energy savings. Overall, LithOS increases GPU efficiency,\nestablishing a foundation for future OS research on GPUs.", "AI": {"tldr": "LithOS is a GPU OS designed to improve GPU utilization and energy efficiency in ML workloads through novel scheduling, kernel atomization, hardware right-sizing, and power management.", "motivation": "The increasing demand for GPUs in ML workloads necessitates efficient resource management to meet diverse needs while optimizing utilization and energy efficiency.", "method": "LithOS introduces a TPC Scheduler, kernel atomization, hardware right-sizing, and power management mechanisms, implemented in Rust.", "result": "LithOS significantly reduces tail latencies (up to 13x) and improves throughput (up to 1.6x) compared to state-of-the-art solutions, while saving GPU capacity and energy.", "conclusion": "LithOS enhances GPU efficiency and lays groundwork for future OS research on GPUs."}}
{"id": "2504.15305", "pdf": "https://arxiv.org/pdf/2504.15305", "abs": "https://arxiv.org/abs/2504.15305", "authors": ["Abhishek Tyagi", "Charu Gaur"], "title": "SLAM-Based Navigation and Fault Resilience in a Surveillance Quadcopter with Embedded Vision Systems", "categories": ["cs.RO", "cs.CV", "cs.SY", "eess.SY", "68T40, 68U10, 70Q05", "I.2.9; I.4.8; I.2.10; C.3"], "comment": "18 pages, 21 figures, 4 tables. Onboard processing using Raspberry Pi\n  4 and Arduino Nano. Includes ORB-SLAM3-based navigation, LQR control, rotor\n  fault recovery, object detection, and PCA face recognition. Real-world and\n  simulation tests included. Designed for GPS-denied autonomous UAV\n  surveillance", "summary": "We present an autonomous aerial surveillance platform, Veg, designed as a\nfault-tolerant quadcopter system that integrates visual SLAM for\nGPS-independent navigation, advanced control architecture for dynamic\nstability, and embedded vision modules for real-time object and face\nrecognition. The platform features a cascaded control design with an LQR\ninner-loop and PD outer-loop trajectory control. It leverages ORB-SLAM3 for\n6-DoF localization and loop closure, and supports waypoint-based navigation\nthrough Dijkstra path planning over SLAM-derived maps. A real-time Failure\nDetection and Identification (FDI) system detects rotor faults and executes\nemergency landing through re-routing. The embedded vision system, based on a\nlightweight CNN and PCA, enables onboard object detection and face recognition\nwith high precision. The drone operates fully onboard using a Raspberry Pi 4\nand Arduino Nano, validated through simulations and real-world testing. This\nwork consolidates real-time localization, fault recovery, and embedded AI on a\nsingle platform suitable for constrained environments.", "AI": {"tldr": "Veg is a fault-tolerant quadcopter with GPS-independent navigation, dynamic stability, and real-time object/face recognition, integrating SLAM, advanced control, and embedded vision.", "motivation": "To create a robust, autonomous aerial surveillance platform capable of operating in GPS-denied environments with fault tolerance and real-time AI processing.", "method": "Uses ORB-SLAM3 for 6-DoF localization, cascaded LQR/PD control, Dijkstra path planning, FDI for fault recovery, and lightweight CNN/PCA for vision.", "result": "Validated through simulations and real-world testing, achieving real-time localization, fault recovery, and embedded AI on a Raspberry Pi 4 and Arduino Nano.", "conclusion": "Veg successfully integrates real-time localization, fault tolerance, and AI on a single platform for constrained environments."}}
{"id": "2504.11972", "pdf": "https://arxiv.org/pdf/2504.11972", "abs": "https://arxiv.org/abs/2504.11972", "authors": ["Xanh Ho", "Jiahao Huang", "Florian Boudin", "Akiko Aizawa"], "title": "LLM-as-a-Judge: Reassessing the Performance of LLMs in Extractive QA", "categories": ["cs.CL"], "comment": "17 pages; code and data are available at\n  https://github.com/Alab-NII/llm-judge-extract-qa", "summary": "Extractive reading comprehension question answering (QA) datasets are\ntypically evaluated using Exact Match (EM) and F1-score, but these metrics\noften fail to fully capture model performance. With the success of large\nlanguage models (LLMs), they have been employed in various tasks, including\nserving as judges (LLM-as-a-judge). In this paper, we reassess the performance\nof QA models using LLM-as-a-judge across four reading comprehension QA\ndatasets. We examine different families of LLMs and various answer types to\nevaluate the effectiveness of LLM-as-a-judge in these tasks. Our results show\nthat LLM-as-a-judge is highly correlated with human judgments and can replace\ntraditional EM/F1 metrics. By using LLM-as-a-judge, the correlation with human\njudgments improves significantly, from 0.22 (EM) and 0.40 (F1-score) to 0.85.\nThese findings confirm that EM and F1 metrics underestimate the true\nperformance of the QA models. While LLM-as-a-judge is not perfect for more\ndifficult answer types (e.g., job), it still outperforms EM/F1, and we observe\nno bias issues, such as self-preference, when the same model is used for both\nthe QA and judgment tasks.", "AI": {"tldr": "LLM-as-a-judge outperforms traditional EM/F1 metrics in evaluating QA models, showing higher correlation with human judgments (0.85 vs. 0.22/0.40).", "motivation": "Traditional metrics (EM/F1) inadequately capture QA model performance, prompting exploration of LLM-as-a-judge for better evaluation.", "method": "Reassessed QA model performance using LLM-as-a-judge across four datasets, testing different LLM families and answer types.", "result": "LLM-as-a-judge achieved 0.85 correlation with human judgments, significantly outperforming EM/F1. No bias issues were observed.", "conclusion": "LLM-as-a-judge is a superior alternative to EM/F1 for QA evaluation, though challenges remain with difficult answer types."}}
{"id": "2412.09385", "pdf": "https://arxiv.org/pdf/2412.09385", "abs": "https://arxiv.org/abs/2412.09385", "authors": ["Fabrizio Davide", "Pietro Torre", "Leonardo Ercolani", "Andrea Gaggioli"], "title": "AI Predicts AGI: Leveraging AGI Forecasting and Peer Review to Explore LLMs' Complex Reasoning Capabilities", "categories": ["cs.AI", "I.2.7"], "comment": "47 pages, 8 figures, 17 tables, appendix with data and code", "summary": "We tasked 16 state-of-the-art large language models (LLMs) with estimating\nthe likelihood of Artificial General Intelligence (AGI) emerging by 2030. To\nassess the quality of these forecasts, we implemented an automated peer review\nprocess (LLM-PR). The LLMs' estimates varied widely, ranging from 3% (Reka-\nCore) to 47.6% (GPT-4o), with a median of 12.5%. These estimates closely align\nwith a recent expert survey that projected a 10% likelihood of AGI by 2027,\nunderscoring the relevance of LLMs in forecasting complex, speculative\nscenarios. The LLM-PR process demonstrated strong reliability, evidenced by a\nhigh Intraclass Correlation Coefficient (ICC = 0.79), reflecting notable\nconsistency in scoring across the models. Among the models, Pplx-70b-online\nemerged as the top performer, while Gemini-1.5-pro-api ranked the lowest. A\ncross-comparison with external benchmarks, such as LMSYS Chatbot Arena,\nrevealed that LLM rankings remained consistent across different evaluation\nmethods, suggesting that existing benchmarks may not encapsulate some of the\nskills relevant for AGI prediction. We further explored the use of weighting\nschemes based on external benchmarks, optimizing the alignment of LLMs'\npredictions with human expert forecasts. This analysis led to the development\nof a new, 'AGI benchmark' designed to highlight performance differences in\nAGI-related tasks. Our findings offer insights into LLMs' capabilities in\nspeculative, interdisciplinary forecasting tasks and emphasize the growing need\nfor innovative evaluation frameworks for assessing AI performance in complex,\nuncertain real-world scenarios.", "AI": {"tldr": "16 LLMs estimated AGI likelihood by 2030, with results (3%-47.6%) aligning with expert surveys. LLM-PR showed high reliability (ICC=0.79). Pplx-70b-online performed best; Gemini-1.5-pro-api worst. Findings highlight LLMs' potential in speculative forecasting and the need for new evaluation frameworks.", "motivation": "To assess LLMs' ability to forecast complex, speculative scenarios like AGI emergence by 2030 and evaluate their reliability through automated peer review.", "method": "Tasked 16 LLMs with AGI likelihood estimation, implemented LLM-PR for quality assessment, and compared results with expert surveys and external benchmarks.", "result": "LLMs' estimates ranged 3%-47.6% (median 12.5%), aligning with expert forecasts. LLM-PR showed high reliability (ICC=0.79). Pplx-70b-online was top performer; Gemini-1.5-pro-api lowest.", "conclusion": "LLMs show promise in speculative forecasting, but new benchmarks are needed to evaluate AGI-related skills. Findings stress the need for innovative evaluation frameworks."}}
{"id": "2504.15472", "pdf": "https://arxiv.org/pdf/2504.15472", "abs": "https://arxiv.org/abs/2504.15472", "authors": ["Pingcheng Jian", "Xiao Wei", "Yanbaihui Liu", "Samuel A. Moore", "Michael M. Zavlanos", "Boyuan Chen"], "title": "LAPP: Large Language Model Feedback for Preference-Driven Reinforcement Learning", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "We introduce Large Language Model-Assisted Preference Prediction (LAPP), a\nnovel framework for robot learning that enables efficient, customizable, and\nexpressive behavior acquisition with minimum human effort. Unlike prior\napproaches that rely heavily on reward engineering, human demonstrations,\nmotion capture, or expensive pairwise preference labels, LAPP leverages large\nlanguage models (LLMs) to automatically generate preference labels from raw\nstate-action trajectories collected during reinforcement learning (RL). These\nlabels are used to train an online preference predictor, which in turn guides\nthe policy optimization process toward satisfying high-level behavioral\nspecifications provided by humans. Our key technical contribution is the\nintegration of LLMs into the RL feedback loop through trajectory-level\npreference prediction, enabling robots to acquire complex skills including\nsubtle control over gait patterns and rhythmic timing. We evaluate LAPP on a\ndiverse set of quadruped locomotion and dexterous manipulation tasks and show\nthat it achieves efficient learning, higher final performance, faster\nadaptation, and precise control of high-level behaviors. Notably, LAPP enables\nrobots to master highly dynamic and expressive tasks such as quadruped\nbackflips, which remain out of reach for standard LLM-generated or handcrafted\nrewards. Our results highlight LAPP as a promising direction for scalable\npreference-driven robot learning.", "AI": {"tldr": "LAPP is a framework using LLMs to generate preference labels for RL, enabling efficient robot learning with minimal human effort.", "motivation": "Prior methods rely on costly human input or reward engineering; LAPP automates preference labeling for scalable robot learning.", "method": "LAPP integrates LLMs to generate preference labels from RL trajectories, training an online predictor to guide policy optimization.", "result": "LAPP achieves efficient learning, high performance, and precise control, mastering complex tasks like quadruped backflips.", "conclusion": "LAPP is a scalable approach for preference-driven robot learning, outperforming traditional methods."}}
{"id": "2504.15329", "pdf": "https://arxiv.org/pdf/2504.15329", "abs": "https://arxiv.org/abs/2504.15329", "authors": ["Yike Zhang", "Eduardo Davalos", "Jack Noble"], "title": "Vision6D: 3D-to-2D Interactive Visualization and Annotation Tool for 6D Pose Estimation", "categories": ["cs.GR", "cs.CV", "cs.HC", "cs.RO"], "comment": null, "summary": "Accurate 6D pose estimation has gained more attention over the years for\nrobotics-assisted tasks that require precise interaction with physical objects.\nThis paper presents an interactive 3D-to-2D visualization and annotation tool\nto support the 6D pose estimation research community. To the best of our\nknowledge, the proposed work is the first tool that allows users to visualize\nand manipulate 3D objects interactively on a 2D real-world scene, along with a\ncomprehensive user study. This system supports robust 6D camera pose annotation\nby providing both visual cues and spatial relationships to determine object\nposition and orientation in various environments. The annotation feature in\nVision6D is particularly helpful in scenarios where the transformation matrix\nbetween the camera and world objects is unknown, as it enables accurate\nannotation of these objects' poses using only the camera intrinsic matrix. This\ncapability serves as a foundational step in developing and training advanced\npose estimation models across various domains. We evaluate Vision6D's\neffectiveness by utilizing widely-used open-source pose estimation datasets\nLinemod and HANDAL through comparisons between the default ground-truth camera\nposes with manual annotations. A user study was performed to show that Vision6D\ngenerates accurate pose annotations via visual cues in an intuitive 3D user\ninterface. This approach aims to bridge the gap between 2D scene projections\nand 3D scenes, offering an effective way for researchers and developers to\nsolve 6D pose annotation related problems. The software is open-source and\npublicly available at https://github.com/InteractiveGL/vision6D.", "AI": {"tldr": "The paper introduces Vision6D, an interactive 3D-to-2D tool for 6D pose estimation, offering visualization, annotation, and a user study to improve accuracy in robotics tasks.", "motivation": "Precise 6D pose estimation is crucial for robotics tasks, but existing tools lack interactive 3D-to-2D visualization and annotation capabilities.", "method": "Vision6D enables interactive manipulation of 3D objects in 2D scenes, supports robust pose annotation, and uses visual cues and spatial relationships.", "result": "The tool was validated on Linemod and HANDAL datasets, showing accurate pose annotations via an intuitive interface.", "conclusion": "Vision6D bridges the gap between 2D and 3D scenes, providing an open-source solution for 6D pose annotation challenges."}}
{"id": "2504.12915", "pdf": "https://arxiv.org/pdf/2504.12915", "abs": "https://arxiv.org/abs/2504.12915", "authors": ["Ebrahim Norouzi", "Sven Hertling", "Harald Sack"], "title": "ConExion: Concept Extraction with Large Language Models", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "In this paper, an approach for concept extraction from documents using\npre-trained large language models (LLMs) is presented. Compared with\nconventional methods that extract keyphrases summarizing the important\ninformation discussed in a document, our approach tackles a more challenging\ntask of extracting all present concepts related to the specific domain, not\njust the important ones. Through comprehensive evaluations of two widely used\nbenchmark datasets, we demonstrate that our method improves the F1 score\ncompared to state-of-the-art techniques. Additionally, we explore the potential\nof using prompts within these models for unsupervised concept extraction. The\nextracted concepts are intended to support domain coverage evaluation of\nontologies and facilitate ontology learning, highlighting the effectiveness of\nLLMs in concept extraction tasks. Our source code and datasets are publicly\navailable at https://github.com/ISE-FIZKarlsruhe/concept_extraction.", "AI": {"tldr": "The paper presents a method for extracting all domain-related concepts from documents using pre-trained LLMs, outperforming state-of-the-art techniques in F1 score and exploring unsupervised extraction via prompts.", "motivation": "To address the challenge of extracting all domain-related concepts, not just keyphrases, and to support ontology evaluation and learning.", "method": "Uses pre-trained large language models (LLMs) for concept extraction, including prompt-based unsupervised techniques.", "result": "Improves F1 score over state-of-the-art methods on benchmark datasets.", "conclusion": "LLMs are effective for comprehensive concept extraction, aiding ontology tasks; code and datasets are publicly available."}}
{"id": "2412.11373", "pdf": "https://arxiv.org/pdf/2412.11373", "abs": "https://arxiv.org/abs/2412.11373", "authors": ["Matthew Stephenson", "Matthew Sidji", "Beno\u00eet Ronval"], "title": "Codenames as a Benchmark for Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": "12 pages, 2 figures, 2 tables", "summary": "In this paper, we propose the use of the popular word-based board game\nCodenames as a suitable benchmark for evaluating the reasoning capabilities of\nLarge Language Models (LLMs). Codenames presents a highly interesting challenge\nfor achieving successful AI performance, requiring both a sophisticated\nunderstanding of language, theory of mind, and epistemic reasoning\ncapabilities. Prior attempts to develop agents for Codenames have largely\nrelied on word embedding techniques, which have a limited vocabulary range and\nperform poorly when paired with differing approaches. LLMs have demonstrated\nenhanced reasoning and comprehension capabilities for language-based tasks, but\ncan still suffer in lateral thinking challenges. We evaluate the capabilities\nof several state-of-the-art LLMs, including GPT-4o, Gemini 1.5, Claude 3.5\nSonnet, and Llama 3.1, across a variety of board setups. Our results indicate\nthat while certain LLMs perform better than others overall, different models\nexhibit varying emergent behaviours during gameplay and excel at specific\nroles. We also evaluate the performance of different combinations of LLMs when\nplaying cooperatively together, demonstrating that LLM agents are more\ngeneralisable to a wider range of teammates than prior techniques.", "AI": {"tldr": "The paper proposes using the board game Codenames as a benchmark to evaluate LLMs' reasoning, language understanding, and theory of mind. It tests state-of-the-art LLMs, revealing varied performance and emergent behaviors, and shows LLMs generalize better with teammates than prior methods.", "motivation": "Codenames is a challenging benchmark for AI, requiring advanced language understanding and reasoning. Prior methods, like word embeddings, were limited, making LLMs a promising alternative.", "method": "Several LLMs (GPT-4o, Gemini 1.5, Claude 3.5 Sonnet, Llama 3.1) are evaluated across board setups, testing individual and cooperative gameplay.", "result": "LLMs show varied performance, with some excelling in specific roles. Cooperative play demonstrates better generalization with teammates compared to prior techniques.", "conclusion": "LLMs are effective for Codenames, showcasing advanced reasoning and adaptability, though performance varies by model and role."}}
{"id": "2504.15512", "pdf": "https://arxiv.org/pdf/2504.15512", "abs": "https://arxiv.org/abs/2504.15512", "authors": ["Siyuan Liang", "Jiayang Liu", "Jiecheng Zhai", "Tianmeng Fang", "Rongcheng Tu", "Aishan Liu", "Xiaochun Cao", "Dacheng Tao"], "title": "T2VShield: Model-Agnostic Jailbreak Defense for Text-to-Video Models", "categories": ["cs.CR", "cs.LG"], "comment": "25 pages, 5 figures", "summary": "The rapid development of generative artificial intelligence has made text to\nvideo models essential for building future multimodal world simulators.\nHowever, these models remain vulnerable to jailbreak attacks, where specially\ncrafted prompts bypass safety mechanisms and lead to the generation of harmful\nor unsafe content. Such vulnerabilities undermine the reliability and security\nof simulation based applications. In this paper, we propose T2VShield, a\ncomprehensive and model agnostic defense framework designed to protect text to\nvideo models from jailbreak threats. Our method systematically analyzes the\ninput, model, and output stages to identify the limitations of existing\ndefenses, including semantic ambiguities in prompts, difficulties in detecting\nmalicious content in dynamic video outputs, and inflexible model centric\nmitigation strategies. T2VShield introduces a prompt rewriting mechanism based\non reasoning and multimodal retrieval to sanitize malicious inputs, along with\na multi scope detection module that captures local and global inconsistencies\nacross time and modalities. The framework does not require access to internal\nmodel parameters and works with both open and closed source systems. Extensive\nexperiments on five platforms show that T2VShield can reduce jailbreak success\nrates by up to 35 percent compared to strong baselines. We further develop a\nhuman centered audiovisual evaluation protocol to assess perceptual safety,\nemphasizing the importance of visual level defense in enhancing the\ntrustworthiness of next generation multimodal simulators.", "AI": {"tldr": "T2VShield is a defense framework for text-to-video models against jailbreak attacks, reducing success rates by up to 35%.", "motivation": "Text-to-video models are vulnerable to jailbreak attacks, compromising reliability and security in multimodal applications.", "method": "T2VShield uses prompt rewriting and multi-scope detection to sanitize inputs and detect inconsistencies without needing model parameters.", "result": "The framework reduces jailbreak success rates by up to 35% in experiments across five platforms.", "conclusion": "T2VShield enhances trustworthiness in multimodal simulators by addressing vulnerabilities and emphasizing visual-level defense."}}
{"id": "2504.13914", "pdf": "https://arxiv.org/pdf/2504.13914", "abs": "https://arxiv.org/abs/2504.13914", "authors": ["ByteDance Seed", ":", "Jiaze Chen", "Tiantian Fan", "Xin Liu", "Lingjun Liu", "Zhiqi Lin", "Mingxuan Wang", "Chengyi Wang", "Xiangpeng Wei", "Wenyuan Xu", "Yufeng Yuan", "Yu Yue", "Lin Yan", "Qiying Yu", "Xiaochen Zuo", "Chi Zhang", "Ruofei Zhu", "Zhecheng An", "Zhihao Bai", "Yu Bao", "Xingyan Bin", "Jiangjie Chen", "Feng Chen", "Hongmin Chen", "Riwei Chen", "Liangqiang Chen", "Zixin Chen", "Jinsong Chen", "Siyan Chen", "Kaiyuan Chen", "Zhi Chen", "Jin Chen", "Jiecao Chen", "Jinxin Chi", "Weinan Dai", "Ning Dai", "Jiahui Dai", "Shihan Dou", "Yantao Du", "Zhengyin Du", "Jianhui Duan", "Chen Dun", "Ting-Han Fan", "Jiazhan Feng", "Junda Feng", "Ziyuan Feng", "Yuwei Fu", "Wenqi Fu", "Hanjie Fu", "Hao Ge", "Hongyi Guo", "Mingji Han", "Li Han", "Wenhao Hao", "Xintong Hao", "Qianyu He", "Jerry He", "Feng He", "Wen Heng", "Zehua Hong", "Qi Hou", "Liang Hu", "Shengding Hu", "Nan Hu", "Kai Hua", "Qi Huang", "Ziyue Huang", "Hongzhi Huang", "Zihao Huang", "Ting Huang", "Wenhao Huang", "Wei Jia", "Bin Jia", "Xiaoying Jia", "Yuhua Jiang", "Haobin Jiang", "Ziheng Jiang", "Kaihua Jiang", "Chengquan Jiang", "Jianpeng Jiao", "Xiaoran Jin", "Xing Jin", "Xunhao Lai", "Zheng Li", "Xiang Li", "Liyi Li", "Hongkai Li", "Zheng Li", "Shengxian Wan", "Ya Wang", "Yunshui Li", "Chenggang Li", "Niuniu Li", "Siyu Li", "Xi Li", "Xiao Li", "Aoyan Li", "Yuntao Li", "Nianning Liang", "Xinnian Liang", "Haibin Lin", "Weijian Lin", "Ye Lin", "Zhicheng Liu", "Guanlin Liu", "Guanlin Liu", "Chenxiao Liu", "Yan Liu", "Gaohong Liu", "Juncai Liu", "Chundian Liu", "Deyi Liu", "Kaibo Liu", "Siyao Liu", "Qi Liu", "Yongfei Liu", "Kang Liu", "Gan Liu", "Boyi Liu", "Rui Long", "Weiqiang Lou", "Chenwei Lou", "Xiang Luo", "Yao Luo", "Caiping Lv", "Heyang Lv", "Bole Ma", "Qianli Ma", "Hongzhi Ma", "Yiyuan Ma", "Jin Ma", "Wenchang Ma", "Tingting Ma", "Chen Mao", "Qiyang Min", "Zhe Nan", "Guanghan Ning", "Jinxiang Ou", "Haojie Pan", "Renming Pang", "Yanghua Peng", "Tao Peng", "Lihua Qian", "Lihua Qian", "Mu Qiao", "Meng Qu", "Cheng Ren", "Hongbin Ren", "Yong Shan", "Wei Shen", "Ke Shen", "Kai Shen", "Guangming Sheng", "Jinlong Shi", "Wenlei Shi", "Guang Shi", "Shuai Shuai Cao", "Yuxin Song", "Zuquan Song", "Jing Su", "Yifan Sun", "Tao Sun", "Zewei Sun", "Borui Wan", "Zihan Wang", "Xiaohui Wang", "Xi Wang", "Shuguang Wang", "Jun Wang", "Qinlong Wang", "Chenyuan Wang", "Shuai Wang", "Zihan Wang", "Changbao Wang", "Jiaqiang Wang", "Shihang Wang", "Xuwu Wang", "Zaiyuan Wang", "Yuxuan Wang", "Wenqi Wang", "Taiqing Wang", "Chengzhi Wei", "Houmin Wei", "Ziyun Wei", "Shufa Wei", "Zheng Wu", "Yonghui Wu", "Yangjun Wu", "Bohong Wu", "Shuang Wu", "Jingqiao Wu", "Ning Wu", "Shuangzhi Wu", "Jianmin Wu", "Chenguang Xi", "Fan Xia", "Yuqiao Xian", "Liang Xiang", "Boren Xiang", "Bowen Xiao", "Zhen Xiao", "Xia Xiao", "Yongsheng Xiao", "Chao Xin", "Shulin Xin", "Yuwen Xiong", "Jingjing Xu", "Ziwen Xu", "Chenyin Xu", "Jiayi Xu", "Yifan Xu", "Wei Xu", "Yufei Xu", "Shikun Xu", "Shipeng Yan", "Shen Yan", "Qingping Yang", "Xi Yang", "Tianhao Yang", "Yuehang Yang", "Yuan Yang", "Ximing Yang", "Zeyu Yang", "Guang Yang", "Yifan Yang", "Xuesong Yao", "Bairen Yi", "Fan Yin", "Jianian Yin", "Ziqiang Ying", "Xiangyu Yu", "Hongli Yu", "Song Yu", "Menghan Yu", "Huan Yu", "Siyu Yuan", "Jun Yuan", "Yutao Zeng", "Tianyang Zhan", "Zheng Zhang", "Yun Zhang", "Mofan Zhang", "Wang Zhang", "Ru Zhang", "Zhi Zhang", "Tianqi Zhang", "Xinyi Zhang", "Zhexi Zhang", "Sijun Zhang", "Wenqiang Zhang", "Xiangxiang Zhang", "Yongtao Zhang", "Yuyu Zhang", "Ge Zhang", "He Zhang", "Yue Zhang", "Renjie Zheng", "Ningxin Zheng", "Zhuolin Zheng", "Yaowei Zheng", "Chen Zheng", "Xiaoyun Zhi", "Wanjun Zhong", "Cheng Zhong", "Zheng Zhong", "Baoquan Zhong", "Xun Zhou", "Na Zhou", "Huan Zhou", "Hang Zhu", "Defa Zhu", "Wenjia Zhu", "Lei Zuo"], "title": "Seed-Thinking-v1.5: Advancing Superb Reasoning Models with Reinforcement Learning", "categories": ["cs.CL"], "comment": null, "summary": "We introduce Seed-Thinking-v1.5, capable of reasoning through thinking before\nresponding, resulting in improved performance on a wide range of benchmarks.\nSeed-Thinking-v1.5 achieves 86.7 on AIME 2024, 55.0 on Codeforces and 77.3 on\nGPQA, demonstrating excellent reasoning abilities in STEM and coding. Beyond\nreasoning tasks, the method demonstrates notable generalization across diverse\ndomains. For instance, it surpasses DeepSeek R1 by 8% in win rate on\nnon-reasoning tasks, indicating its broader applicability. Compared to other\nstate-of-the-art reasoning models, Seed-Thinking-v1.5 is a Mixture-of-Experts\n(MoE) model with a relatively small size, featuring 20B activated and 200B\ntotal parameters. As part of our effort to assess generalized reasoning, we\ndevelop two internal benchmarks, BeyondAIME and Codeforces, both of which will\nbe publicly released to support future research.", "AI": {"tldr": "Seed-Thinking-v1.5 is a reasoning model with strong performance in STEM and coding tasks, outperforming benchmarks like AIME 2024 and Codeforces. It also generalizes well to non-reasoning tasks.", "motivation": "To develop a model capable of advanced reasoning and generalization across diverse domains, improving upon existing state-of-the-art methods.", "method": "Uses a Mixture-of-Experts (MoE) architecture with 20B activated and 200B total parameters, emphasizing thinking before responding.", "result": "Achieves 86.7 on AIME 2024, 55.0 on Codeforces, and 77.3 on GPQA, with an 8% higher win rate than DeepSeek R1 on non-reasoning tasks.", "conclusion": "Seed-Thinking-v1.5 demonstrates superior reasoning and generalization, supported by new benchmarks (BeyondAIME and Codeforces) for future research."}}
{"id": "2412.11761", "pdf": "https://arxiv.org/pdf/2412.11761", "abs": "https://arxiv.org/abs/2412.11761", "authors": ["Timoth\u00e9e Anne", "Noah Syrkis", "Meriem Elhosni", "Florian Turati", "Franck Legendre", "Alain Jaquier", "Sebastian Risi"], "title": "Harnessing Language for Coordination: A Framework and Benchmark for LLM-Driven Multi-Agent Control", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious tasks. Their potential to facilitate human coordination with many\nagents is a promising but largely under-explored area. Such capabilities would\nbe helpful in disaster response, urban planning, and real-time strategy\nscenarios. In this work, we introduce (1) a real-time strategy game benchmark\ndesigned to evaluate these abilities and (2) a novel framework we term HIVE.\nHIVE empowers a single human to coordinate swarms of up to 2,000 agents through\na natural language dialog with an LLM. We present promising results on this\nmulti-agent benchmark, with our hybrid approach solving tasks such as\ncoordinating agent movements, exploiting unit weaknesses, leveraging human\nannotations, and understanding terrain and strategic points. Our findings also\nhighlight critical limitations of current models, including difficulties in\nprocessing spatial visual information and challenges in formulating long-term\nstrategic plans. This work sheds light on the potential and limitations of LLMs\nin human-swarm coordination, paving the way for future research in this area.\nThe HIVE project page, hive.syrkis.com, includes videos of the system in\naction.", "AI": {"tldr": "The paper introduces HIVE, a framework enabling a human to coordinate up to 2,000 agents via natural language dialogue with an LLM, tested in a real-time strategy game. Results show promise but highlight limitations like spatial processing and long-term planning.", "motivation": "Explore LLMs' potential in human-swarm coordination for applications like disaster response and urban planning.", "method": "Developed HIVE, a framework integrating LLMs for natural language coordination of agents, tested in a real-time strategy benchmark.", "result": "HIVE successfully handles tasks like agent coordination and strategic planning but struggles with spatial visuals and long-term strategy.", "conclusion": "LLMs show promise for human-swarm coordination but need improvements in spatial and strategic capabilities."}}
{"id": "2504.15517", "pdf": "https://arxiv.org/pdf/2504.15517", "abs": "https://arxiv.org/abs/2504.15517", "authors": ["Mingchen Song", "Xiang Deng", "Guoqiang Zhong", "Qi Lv", "Jia Wan", "Yinchuan Li", "Jianye Hao", "Weili Guan"], "title": "Few-Shot Vision-Language Action-Incremental Policy Learning", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Recently, Transformer-based robotic manipulation methods utilize multi-view\nspatial representations and language instructions to learn robot motion\ntrajectories by leveraging numerous robot demonstrations. However, the\ncollection of robot data is extremely challenging, and existing methods lack\nthe capability for continuous learning on new tasks with only a few\ndemonstrations. In this paper, we formulate these challenges as the Few-Shot\nAction-Incremental Learning (FSAIL) task, and accordingly design a Task-prOmpt\ngraPh evolutIon poliCy (TOPIC) to address these issues. Specifically, to\naddress the data scarcity issue in robotic imitation learning, TOPIC learns\nTask-Specific Prompts (TSP) through the deep interaction of multi-modal\ninformation within few-shot demonstrations, thereby effectively extracting the\ntask-specific discriminative information. On the other hand, to enhance the\ncapability for continual learning on new tasks and mitigate the issue of\ncatastrophic forgetting, TOPIC adopts a Continuous Evolution Strategy (CES).\nCES leverages the intrinsic relationships between tasks to construct a task\nrelation graph, which effectively facilitates the adaptation of new tasks by\nreusing skills learned from previous tasks. TOPIC pioneers few-shot continual\nlearning in the robotic manipulation task, and extensive experimental results\ndemonstrate that TOPIC outperforms state-of-the-art baselines by over 26$\\%$ in\nsuccess rate, significantly enhancing the continual learning capabilities of\nexisting Transformer-based policies.", "AI": {"tldr": "TOPIC introduces a Task-prOmpt graPh evolutIon poliCy for few-shot continual learning in robotic manipulation, outperforming baselines by 26% in success rate.", "motivation": "Existing Transformer-based robotic methods struggle with data scarcity and lack continuous learning capability for new tasks with few demonstrations.", "method": "TOPIC uses Task-Specific Prompts (TSP) for few-shot learning and a Continuous Evolution Strategy (CES) to reuse skills from previous tasks via a task relation graph.", "result": "TOPIC achieves a 26% higher success rate than state-of-the-art baselines, enhancing continual learning in robotic manipulation.", "conclusion": "TOPIC effectively addresses few-shot continual learning challenges in robotic manipulation, improving performance and adaptability."}}
{"id": "2504.15899", "pdf": "https://arxiv.org/pdf/2504.15899", "abs": "https://arxiv.org/abs/2504.15899", "authors": ["Blerim Abdullai", "Tony Wang", "Xinyuan Qiao", "Florian Shkurti", "Timothy D. Barfoot"], "title": "RaSCL: Radar to Satellite Crossview Localization", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "GNSS is unreliable, inaccurate, and insufficient in many real-time autonomous\nfield applications. In this work, we present a GNSS-free global localization\nsolution that contains a method of registering imaging radar on the ground with\noverhead RGB imagery, with joint optimization of relative poses from odometry\nand global poses from our overhead registration. Previous works have used\nvarious combinations of ground sensors and overhead imagery, and different\nfeature extraction and matching methods. These include various handcrafted and\ndeep-learning-based methods for extracting features from overhead imagery. Our\nwork presents insights on extracting essential features from RGB overhead\nimages for effective global localization against overhead imagery using only\nground radar and a single georeferenced initial guess. We motivate our method\nby evaluating it on datasets in diverse geographic conditions and robotic\nplatforms, including on an Unmanned Surface Vessel (USV) as well as urban and\nsuburban driving datasets.", "AI": {"tldr": "A GNSS-free global localization method using ground radar and overhead RGB imagery, optimized with odometry and global poses, tested in diverse environments.", "motivation": "GNSS is unreliable for autonomous field applications, necessitating alternative localization methods.", "method": "Registers ground radar with overhead RGB imagery, jointly optimizing odometry and global poses, using essential feature extraction from RGB images.", "result": "Effective global localization demonstrated in diverse environments, including USV and urban/suburban driving datasets.", "conclusion": "The method provides a reliable GNSS-free solution for global localization in varied conditions."}}
{"id": "2409.13221", "pdf": "https://arxiv.org/pdf/2409.13221", "abs": "https://arxiv.org/abs/2409.13221", "authors": ["Yinmin Zhong", "Zili Zhang", "Bingyang Wu", "Shengyu Liu", "Yukun Chen", "Changyi Wan", "Hanpeng Hu", "Lei Xia", "Ranchen Ming", "Yibo Zhu", "Xin Jin"], "title": "Optimizing RLHF Training for Large Language Models with Stage Fusion", "categories": ["cs.LG", "cs.CL", "cs.DC"], "comment": null, "summary": "We present RLHFuse, an efficient training system with stage fusion for\nReinforcement Learning from Human Feedback (RLHF). Due to the intrinsic nature\nof RLHF training, i.e., the data skewness in the generation stage and the\npipeline bubbles in the training stage, existing RLHF systems suffer from low\nGPU utilization. RLHFuse breaks the traditional view of RLHF workflow as a\ncomposition of individual tasks, splitting each task into finer-grained\nsubtasks, and performing stage fusion to improve GPU utilization. RLHFuse\ncontains two key ideas. First, for generation and inference tasks, RLHFuse\nsplits them into sample-level subtasks, enabling efficient inter-stage fusion\nto overlap the execution of generation and inference stages, thus mitigating\nthe original generation bottleneck dominated by long-tailed samples. Second,\nfor training tasks, RLHFuse breaks them into subtasks of micro-batches and\nperforms intra-stage fusion to concurrently execute these subtasks in the\ntraining stage with a fused pipeline schedule, effectively mitigating the\npipeline bubbles. The experiments show that RLHFuse increases the training\nthroughput by up to $3.7\\times$, compared to existing systems.", "AI": {"tldr": "RLHFuse is a training system for RLHF that improves GPU utilization by splitting tasks into subtasks and fusing stages, achieving up to 3.7x throughput.", "motivation": "Existing RLHF systems suffer from low GPU utilization due to data skewness and pipeline bubbles.", "method": "RLHFuse splits tasks into sample-level subtasks for generation/inference and micro-batches for training, enabling inter-stage and intra-stage fusion.", "result": "RLHFuse increases training throughput by up to 3.7x compared to existing systems.", "conclusion": "RLHFuse effectively addresses GPU underutilization in RLHF training through innovative stage fusion techniques."}}
{"id": "2504.09597", "pdf": "https://arxiv.org/pdf/2504.09597", "abs": "https://arxiv.org/abs/2504.09597", "authors": ["Zhixuan Pan", "Shaowen Wang", "Jian Li"], "title": "Understanding LLM Behaviors via Compression: Data Generation, Knowledge Acquisition and Scaling Laws", "categories": ["cs.AI", "cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nnumerous tasks, yet principled explanations for their underlying mechanisms and\nseveral phenomena, such as scaling laws, hallucinations, and related behaviors,\nremain elusive. In this work, we revisit the classical relationship between\ncompression and prediction, grounded in Kolmogorov complexity and Shannon\ninformation theory, to provide deeper insights into LLM behaviors. By\nleveraging the Kolmogorov Structure Function and interpreting LLM compression\nas a two-part coding process, we offer a detailed view of how LLMs acquire and\nstore information across increasing model and data scales -- from pervasive\nsyntactic patterns to progressively rarer knowledge elements. Motivated by this\ntheoretical perspective and natural assumptions inspired by Heap's and Zipf's\nlaws, we introduce a simplified yet representative hierarchical data-generation\nframework called the Syntax-Knowledge model. Under the Bayesian setting, we\nshow that prediction and compression within this model naturally lead to\ndiverse learning and scaling behaviors of LLMs. In particular, our theoretical\nanalysis offers intuitive and principled explanations for both data and model\nscaling laws, the dynamics of knowledge acquisition during training and\nfine-tuning, factual knowledge hallucinations in LLMs. The experimental results\nvalidate our theoretical predictions.", "AI": {"tldr": "The paper explores the relationship between compression and prediction in Large Language Models (LLMs) using Kolmogorov complexity and Shannon information theory. It introduces a hierarchical data-generation framework (Syntax-Knowledge model) to explain LLM behaviors like scaling laws, knowledge acquisition, and hallucinations.", "motivation": "To provide principled explanations for LLM behaviors, such as scaling laws and hallucinations, by revisiting the classical link between compression and prediction.", "method": "Leverages the Kolmogorov Structure Function and a two-part coding process to analyze LLM compression. Introduces the Syntax-Knowledge model under Bayesian settings to study prediction and compression.", "result": "Theoretical analysis explains scaling laws, knowledge acquisition dynamics, and hallucinations in LLMs. Experimental results validate these predictions.", "conclusion": "The study offers intuitive and principled insights into LLM behaviors, bridging theory and empirical observations."}}
{"id": "2504.15541", "pdf": "https://arxiv.org/pdf/2504.15541", "abs": "https://arxiv.org/abs/2504.15541", "authors": ["Qichao Liu", "Heye Huang", "Shiyue Zhao", "Lei Shi", "Soyoung Ahn", "Xiaopeng Li"], "title": "RiskNet: Interaction-Aware Risk Forecasting for Autonomous Driving in Long-Tail Scenarios", "categories": ["cs.RO", "cs.LG"], "comment": "24 pages, 14 figures", "summary": "Ensuring the safety of autonomous vehicles (AVs) in long-tail scenarios\nremains a critical challenge, particularly under high uncertainty and complex\nmulti-agent interactions. To address this, we propose RiskNet, an\ninteraction-aware risk forecasting framework, which integrates deterministic\nrisk modeling with probabilistic behavior prediction for comprehensive risk\nassessment. At its core, RiskNet employs a field-theoretic model that captures\ninteractions among ego vehicle, surrounding agents, and infrastructure via\ninteraction fields and force. This model supports multidimensional risk\nevaluation across diverse scenarios (highways, intersections, and roundabouts),\nand shows robustness under high-risk and long-tail settings. To capture the\nbehavioral uncertainty, we incorporate a graph neural network (GNN)-based\ntrajectory prediction module, which learns multi-modal future motion\ndistributions. Coupled with the deterministic risk field, it enables dynamic,\nprobabilistic risk inference across time, enabling proactive safety assessment\nunder uncertainty. Evaluations on the highD, inD, and rounD datasets, spanning\nlane changes, turns, and complex merges, demonstrate that our method\nsignificantly outperforms traditional approaches (e.g., TTC, THW, RSS, NC\nField) in terms of accuracy, responsiveness, and directional sensitivity, while\nmaintaining strong generalization across scenarios. This framework supports\nreal-time, scenario-adaptive risk forecasting and demonstrates strong\ngeneralization across uncertain driving environments. It offers a unified\nfoundation for safety-critical decision-making in long-tail scenarios.", "AI": {"tldr": "RiskNet is a framework for autonomous vehicle safety in long-tail scenarios, combining deterministic risk modeling with probabilistic behavior prediction for robust risk assessment.", "motivation": "Addressing the challenge of ensuring AV safety in high-uncertainty, multi-agent interactions, especially in rare but critical scenarios.", "method": "Integrates a field-theoretic model for interaction-aware risk and a GNN-based trajectory prediction module for behavioral uncertainty.", "result": "Outperforms traditional methods (e.g., TTC, THW) in accuracy, responsiveness, and generalization across diverse scenarios.", "conclusion": "RiskNet provides a unified, real-time solution for proactive safety assessment in uncertain driving environments."}}
{"id": "2504.15953", "pdf": "https://arxiv.org/pdf/2504.15953", "abs": "https://arxiv.org/abs/2504.15953", "authors": ["Chance J. Hamilton", "Alfredo Weitzenfeld"], "title": "Visual Place Cell Encoding: A Computational Model for Spatial Representation and Cognitive Mapping", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "This paper presents the Visual Place Cell Encoding (VPCE) model, a\nbiologically inspired computational framework for simulating place cell-like\nactivation using visual input. Drawing on evidence that visual landmarks play a\ncentral role in spatial encoding, the proposed VPCE model activates visual\nplace cells by clustering high-dimensional appearance features extracted from\nimages captured by a robot-mounted camera. Each cluster center defines a\nreceptive field, and activation is computed based on visual similarity using a\nradial basis function. We evaluate whether the resulting activation patterns\ncorrelate with key properties of biological place cells, including spatial\nproximity, orientation alignment, and boundary differentiation. Experiments\ndemonstrate that the VPCE can distinguish between visually similar yet\nspatially distinct locations and adapt to environment changes such as the\ninsertion or removal of walls. These results suggest that structured visual\ninput, even in the absence of motion cues or reward-driven learning, is\nsufficient to generate place-cell-like spatial representations and support\nbiologically inspired cognitive mapping.", "AI": {"tldr": "The VPCE model simulates place cell-like activation using visual input, clustering appearance features from robot-captured images to evaluate spatial encoding properties.", "motivation": "To explore if visual landmarks alone can generate place-cell-like spatial representations without motion cues or reward-driven learning.", "method": "The VPCE model clusters high-dimensional appearance features from images, using radial basis functions to compute activation based on visual similarity.", "result": "VPCE distinguishes spatially distinct locations and adapts to environmental changes, correlating with biological place cell properties.", "conclusion": "Structured visual input suffices to generate place-cell-like representations, supporting biologically inspired cognitive mapping."}}
{"id": "2410.02064", "pdf": "https://arxiv.org/pdf/2410.02064", "abs": "https://arxiv.org/abs/2410.02064", "authors": ["Christopher Ackerman", "Nina Panickssery"], "title": "Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct", "categories": ["cs.LG", "cs.CL"], "comment": "10 pages, 13 figs, 2 tables, accepted as conference paper to ICLR\n  2025", "summary": "It has been reported that LLMs can recognize their own writing. As this has\npotential implications for AI safety, yet is relatively understudied, we\ninvestigate the phenomenon, seeking to establish whether it robustly occurs at\nthe behavioral level, how the observed behavior is achieved, and whether it can\nbe controlled. First, we find that the Llama3-8b-Instruct chat model - but not\nthe base Llama3-8b model - can reliably distinguish its own outputs from those\nof humans, and present evidence that the chat model is likely using its\nexperience with its own outputs, acquired during post-training, to succeed at\nthe writing recognition task. Second, we identify a vector in the residual\nstream of the model that is differentially activated when the model makes a\ncorrect self-written-text recognition judgment, show that the vector activates\nin response to information relevant to self-authorship, present evidence that\nthe vector is related to the concept of \"self\" in the model, and demonstrate\nthat the vector is causally related to the model's ability to perceive and\nassert self-authorship. Finally, we show that the vector can be used to control\nboth the model's behavior and its perception, steering the model to claim or\ndisclaim authorship by applying the vector to the model's output as it\ngenerates it, and steering the model to believe or disbelieve it wrote\narbitrary texts by applying the vector to them as the model reads them.", "AI": {"tldr": "LLMs like Llama3-8b-Instruct can recognize their own writing, using post-training experience. A specific vector in the model's residual stream is linked to self-authorship perception and can control the model's behavior and perception.", "motivation": "To investigate LLMs' ability to recognize their own writing and its implications for AI safety, focusing on behavioral robustness, underlying mechanisms, and controllability.", "method": "Tested Llama3-8b-Instruct and base Llama3-8b models for writing recognition, analyzed residual stream vectors, and manipulated the identified vector to control behavior and perception.", "result": "The chat model reliably distinguishes its outputs from humans, using a specific vector causally linked to self-authorship perception. This vector can control the model's claims and beliefs about authorship.", "conclusion": "LLMs can recognize their own writing through learned mechanisms, and this ability can be controlled, offering insights for AI safety and model behavior manipulation."}}
{"id": "2504.14128", "pdf": "https://arxiv.org/pdf/2504.14128", "abs": "https://arxiv.org/abs/2504.14128", "authors": ["Christopher Zhang Cui", "Xingdi Yuan", "Ziang Xiao", "Prithviraj Ammanabrolu", "Marc-Alexandre C\u00f4t\u00e9"], "title": "TALES: Text Adventure Learning Environment Suite", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Reasoning is an essential skill to enable Large Language Models (LLMs) to\ninteract with the world. As tasks become more complex, they demand increasingly\nsophisticated and diverse reasoning capabilities for sequential\ndecision-making, requiring structured reasoning over the context history to\ndetermine the next best action. We introduce TALES, a diverse collection of\nsynthetic and human-written text-adventure games designed to challenge and\nevaluate diverse reasoning capabilities. We present results over a range of\nLLMs, open- and closed-weights, performing a qualitative analysis on the top\nperforming models. Despite an impressive showing on synthetic games, even the\ntop LLM-driven agents fail to achieve 15% on games designed for human\nenjoyment. Code and visualization of the experiments can be found at\nhttps://microsoft.github.io/tales.", "AI": {"tldr": "TALES is a collection of text-adventure games to evaluate LLMs' reasoning. Top models perform well on synthetic games but poorly on human-designed ones (<15%).", "motivation": "To assess and enhance LLMs' reasoning skills for complex, sequential decision-making tasks.", "method": "Introduces TALES, a diverse set of synthetic and human-written text-adventure games, and evaluates various LLMs on them.", "result": "Top LLMs excel on synthetic games but struggle with human-designed ones, scoring below 15%.", "conclusion": "LLMs need further improvement in reasoning for human-centric tasks, as current models fall short."}}
{"id": "2504.15561", "pdf": "https://arxiv.org/pdf/2504.15561", "abs": "https://arxiv.org/abs/2504.15561", "authors": ["Jingkai Xu", "Xiangli Nie"], "title": "SPECI: Skill Prompts based Hierarchical Continual Imitation Learning for Robot Manipulation", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Real-world robot manipulation in dynamic unstructured environments requires\nlifelong adaptability to evolving objects, scenes and tasks. Traditional\nimitation learning relies on static training paradigms, which are ill-suited\nfor lifelong adaptation. Although Continual Imitation Learnin (CIL) enables\nincremental task adaptation while preserving learned knowledge, current CIL\nmethods primarily overlook the intrinsic skill characteristics of robot\nmanipulation or depend on manually defined and rigid skills, leading to\nsuboptimal cross-task knowledge transfer. To address these issues, we propose\nSkill Prompts-based HiErarchical Continual Imitation Learning (SPECI), a novel\nend-to-end hierarchical CIL policy architecture for robot manipulation. The\nSPECI framework consists of a multimodal perception and fusion module for\nheterogeneous sensory information encoding, a high-level skill inference module\nfor dynamic skill extraction and selection, and a low-level action execution\nmodule for precise action generation. To enable efficient knowledge transfer on\nboth skill and task levels, SPECI performs continual implicit skill acquisition\nand reuse via an expandable skill codebook and an attention-driven skill\nselection mechanism. Furthermore, we introduce mode approximation to augment\nthe last two modules with task-specific and task-sharing parameters, thereby\nenhancing task-level knowledge transfer. Extensive experiments on diverse\nmanipulation task suites demonstrate that SPECI consistently outperforms\nstate-of-the-art CIL methods across all evaluated metrics, revealing\nexceptional bidirectional knowledge transfer and superior overall performance.", "AI": {"tldr": "SPECI is a hierarchical continual imitation learning framework for robot manipulation, enabling dynamic skill extraction and efficient knowledge transfer, outperforming existing methods.", "motivation": "Traditional imitation learning lacks adaptability for lifelong learning in dynamic environments, and current CIL methods overlook skill characteristics or rely on rigid skills.", "method": "SPECI uses a hierarchical policy with multimodal perception, skill inference, and action execution modules, along with an expandable skill codebook and attention-driven selection.", "result": "SPECI outperforms state-of-the-art CIL methods in diverse manipulation tasks, showing superior bidirectional knowledge transfer.", "conclusion": "SPECI addresses limitations of current CIL methods, offering a scalable and efficient solution for lifelong robot manipulation learning."}}
{"id": "2504.15975", "pdf": "https://arxiv.org/pdf/2504.15975", "abs": "https://arxiv.org/abs/2504.15975", "authors": ["Peter Fletcher"], "title": "A New Graph Grammar Formalism for Robust Syntactic Pattern Recognition", "categories": ["cs.FL", "cs.CV", "F.4.2; F.4.3"], "comment": "64 pages, 23 figures", "summary": "I introduce a formalism for representing the syntax of recursively structured\ngraph-like patterns. It does not use production rules, like a conventional\ngraph grammar, but represents the syntactic structure in a more direct and\ndeclarative way. The grammar and the pattern are both represented as networks,\nand parsing is seen as the construction of a homomorphism from the pattern to\nthe grammar. The grammars can represent iterative, hierarchical and nested\nrecursive structure in more than one dimension.\n  This supports a highly parallel style of parsing, in which all aspects of\npattern recognition (feature detection, segmentation, parsing, filling in\nmissing symbols, top-down and bottom-up inference) are integrated into a single\nprocess, to exploit the synergy between them.\n  The emphasis of this paper is on underlying theoretical issues, but I also\ngive some example runs to illustrate the error-tolerant parsing of complex\nrecursively structured patterns of 50-1000 symbols, involving variability in\ngeometric relationships, blurry and indistinct symbols, overlapping symbols,\ncluttered images, and erased patches.", "AI": {"tldr": "A formalism for representing graph-like patterns without production rules, using networks for grammar and parsing as homomorphism construction. Supports parallel parsing and integrates all pattern recognition aspects.", "motivation": "To provide a direct and declarative way to represent syntactic structure in graph-like patterns, avoiding conventional graph grammars' limitations.", "method": "Represents grammar and patterns as networks; parsing is constructing a homomorphism from pattern to grammar. Supports iterative, hierarchical, and nested recursive structures.", "result": "Enables parallel parsing, integrating feature detection, segmentation, and inference. Demonstrated with error-tolerant parsing of complex patterns (50-1000 symbols) under various challenges.", "conclusion": "The approach offers a unified, efficient method for parsing complex recursive structures, handling variability and noise effectively."}}
{"id": "2410.13828", "pdf": "https://arxiv.org/pdf/2410.13828", "abs": "https://arxiv.org/abs/2410.13828", "authors": ["Hui Yuan", "Yifan Zeng", "Yue Wu", "Huazheng Wang", "Mengdi Wang", "Liu Leqi"], "title": "A Common Pitfall of Margin-based Language Model Alignment: Gradient Entanglement", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement Learning from Human Feedback (RLHF) has become the predominant\napproach for language model (LM) alignment. At its core, RLHF uses a\nmargin-based loss for preference optimization, specifying ideal LM behavior\nonly by the difference between preferred and dispreferred responses. In this\npaper, we identify a common pitfall of margin-based methods -- the\nunder-specification of ideal LM behavior on preferred and dispreferred\nresponses individually, which leads to two unintended consequences as the\nmargin increases: (1) The probability of dispreferred (e.g., unsafe) responses\nmay increase, resulting in potential safety alignment failures. (2) The\nprobability of preferred responses may decrease, even when those responses are\nideal. We demystify the reasons behind these problematic behaviors:\nmargin-based losses couple the change in the preferred probability to the\ngradient of the dispreferred one, and vice versa, often preventing the\npreferred probability from increasing while the dispreferred one decreases, and\nthus causing a synchronized increase or decrease in both probabilities. We term\nthis effect, inherent in margin-based objectives, gradient entanglement.\nFormally, we derive conditions for general margin-based alignment objectives\nunder which gradient entanglement becomes concerning: the inner product of the\ngradients of preferred and dispreferred log-probabilities is large relative to\nthe individual gradient norms. We theoretically investigate why such inner\nproducts can be large when aligning language models and empirically validate\nour findings. Empirical implications of our framework extend to explaining\nimportant differences in the training dynamics of various preference\noptimization algorithms, and suggesting potential algorithm designs to mitigate\nthe under-specification issue of margin-based methods and thereby improving\nlanguage model alignment.", "AI": {"tldr": "RLHF's margin-based loss in LM alignment can under-specify ideal behavior, leading to safety risks and reduced preferred responses due to gradient entanglement.", "motivation": "To address the pitfalls of margin-based methods in RLHF, which cause unintended consequences like safety failures and reduced preferred responses.", "method": "Analyzes gradient entanglement in margin-based objectives, derives conditions for concerning cases, and validates findings theoretically and empirically.", "result": "Identifies gradient entanglement as a key issue, explains training dynamics differences, and suggests algorithm improvements.", "conclusion": "Proposes solutions to mitigate under-specification in margin-based methods, enhancing LM alignment."}}
{"id": "2504.14325", "pdf": "https://arxiv.org/pdf/2504.14325", "abs": "https://arxiv.org/abs/2504.14325", "authors": ["Alessio Buscemi", "Daniele Proverbio", "Alessandro Di Stefano", "The Anh Han", "German Castignani", "Pietro Li\u00f2"], "title": "FAIRGAME: a Framework for AI Agents Bias Recognition using Game Theory", "categories": ["cs.AI"], "comment": null, "summary": "Letting AI agents interact in multi-agent applications adds a layer of\ncomplexity to the interpretability and prediction of AI outcomes, with profound\nimplications for their trustworthy adoption in research and society. Game\ntheory offers powerful models to capture and interpret strategic interaction\namong agents, but requires the support of reproducible, standardized and\nuser-friendly IT frameworks to enable comparison and interpretation of results.\nTo this end, we present FAIRGAME, a Framework for AI Agents Bias Recognition\nusing Game Theory. We describe its implementation and usage, and we employ it\nto uncover biased outcomes in popular games among AI agents, depending on the\nemployed Large Language Model (LLM) and used language, as well as on the\npersonality trait or strategic knowledge of the agents. Overall, FAIRGAME\nallows users to reliably and easily simulate their desired games and scenarios\nand compare the results across simulation campaigns and with game-theoretic\npredictions, enabling the systematic discovery of biases, the anticipation of\nemerging behavior out of strategic interplays, and empowering further research\ninto strategic decision-making using LLM agents.", "AI": {"tldr": "FAIRGAME is a framework for detecting biases in AI agent interactions using game theory, enabling standardized simulations and comparisons across scenarios and LLMs.", "motivation": "Addressing the complexity and interpretability challenges of multi-agent AI interactions to ensure trustworthy adoption in research and society.", "method": "Leverages game theory and provides a reproducible, user-friendly IT framework (FAIRGAME) for simulating games and analyzing strategic interactions among AI agents.", "result": "Uncovered biases in AI agent outcomes based on LLM type, language, and agent traits, enabling systematic bias discovery and behavior prediction.", "conclusion": "FAIRGAME facilitates reliable simulation, bias detection, and further research into strategic decision-making with LLM agents."}}
{"id": "2504.15577", "pdf": "https://arxiv.org/pdf/2504.15577", "abs": "https://arxiv.org/abs/2504.15577", "authors": ["Qingyuan He", "Chang Liu", "Juecen Zhan", "Weiqiang Huang", "Ran Hao"], "title": "State-Aware IoT Scheduling Using Deep Q-Networks and Edge-Based Coordination", "categories": ["cs.NI", "cs.LG"], "comment": null, "summary": "This paper addresses the challenge of energy efficiency management faced by\nintelligent IoT devices in complex application environments. A novel\noptimization method is proposed, combining Deep Q-Network (DQN) with an edge\ncollaboration mechanism. The method builds a state-action-reward interaction\nmodel and introduces edge nodes as intermediaries for state aggregation and\npolicy scheduling. This enables dynamic resource coordination and task\nallocation among multiple devices. During the modeling process, device status,\ntask load, and network resources are jointly incorporated into the state space.\nThe DQN is used to approximate and learn the optimal scheduling strategy. To\nenhance the model's ability to perceive inter-device relationships, a\ncollaborative graph structure is introduced to model the multi-device\nenvironment and assist in decision optimization. Experiments are conducted\nusing real-world IoT data collected from the FastBee platform. Several\ncomparative and validation tests are performed, including energy efficiency\ncomparisons across different scheduling strategies, robustness analysis under\nvarying task loads, and evaluation of state dimension impacts on policy\nconvergence speed. The results show that the proposed method outperforms\nexisting baseline approaches in terms of average energy consumption, processing\nlatency, and resource utilization. This confirms its effectiveness and\npracticality in intelligent IoT scenarios.", "AI": {"tldr": "A novel optimization method combining Deep Q-Network (DQN) with edge collaboration is proposed to manage energy efficiency in IoT devices, outperforming baselines in energy consumption, latency, and resource utilization.", "motivation": "Addressing energy efficiency challenges in IoT devices within complex environments.", "method": "Combines DQN with edge collaboration, modeling state-action-reward interactions and using a collaborative graph for multi-device decision optimization.", "result": "Outperforms baselines in energy consumption, processing latency, and resource utilization.", "conclusion": "The method is effective and practical for intelligent IoT scenarios."}}
{"id": "2504.16062", "pdf": "https://arxiv.org/pdf/2504.16062", "abs": "https://arxiv.org/abs/2504.16062", "authors": ["Hardik Shah", "Jiaxu Xing", "Nico Messikommer", "Boyang Sun", "Marc Pollefeys", "Davide Scaramuzza"], "title": "ForesightNav: Learning Scene Imagination for Efficient Exploration", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Understanding how humans leverage prior knowledge to navigate unseen\nenvironments while making exploratory decisions is essential for developing\nautonomous robots with similar abilities. In this work, we propose\nForesightNav, a novel exploration strategy inspired by human imagination and\nreasoning. Our approach equips robotic agents with the capability to predict\ncontextual information, such as occupancy and semantic details, for unexplored\nregions. These predictions enable the robot to efficiently select meaningful\nlong-term navigation goals, significantly enhancing exploration in unseen\nenvironments. We validate our imagination-based approach using the Structured3D\ndataset, demonstrating accurate occupancy prediction and superior performance\nin anticipating unseen scene geometry. Our experiments show that the\nimagination module improves exploration efficiency in unseen environments,\nachieving a 100% completion rate for PointNav and an SPL of 67% for ObjectNav\non the Structured3D Validation split. These contributions demonstrate the power\nof imagination-driven reasoning for autonomous systems to enhance generalizable\nand efficient exploration.", "AI": {"tldr": "ForesightNav is a novel exploration strategy for robots, inspired by human imagination, enabling efficient navigation in unseen environments by predicting contextual details.", "motivation": "To develop autonomous robots that mimic human-like exploration by leveraging prior knowledge and predictive reasoning.", "method": "Proposes ForesightNav, which predicts occupancy and semantic details for unexplored regions to guide long-term navigation goals.", "result": "Achieves 100% completion rate for PointNav and 67% SPL for ObjectNav on Structured3D, with accurate occupancy prediction.", "conclusion": "Imagination-driven reasoning enhances generalizable and efficient exploration in autonomous systems."}}
{"id": "2410.14669", "pdf": "https://arxiv.org/pdf/2410.14669", "abs": "https://arxiv.org/abs/2410.14669", "authors": ["Baiqi Li", "Zhiqiu Lin", "Wenxuan Peng", "Jean de Dieu Nyandwi", "Daniel Jiang", "Zixian Ma", "Simran Khanuja", "Ranjay Krishna", "Graham Neubig", "Deva Ramanan"], "title": "NaturalBench: Evaluating Vision-Language Models on Natural Adversarial Samples", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted to NeurIPS 24; We open-source our dataset at:\n  https://huggingface.co/datasets/BaiqiL/NaturalBench ; Project page at:\n  https://linzhiqiu.github.io/papers/naturalbench/", "summary": "Vision-language models (VLMs) have made significant progress in recent\nvisual-question-answering (VQA) benchmarks that evaluate complex\nvisio-linguistic reasoning. However, are these models truly effective? In this\nwork, we show that VLMs still struggle with natural images and questions that\nhumans can easily answer, which we term natural adversarial samples. We also\nfind it surprisingly easy to generate these VQA samples from natural image-text\ncorpora using off-the-shelf models like CLIP and ChatGPT. We propose a\nsemi-automated approach to collect a new benchmark, NaturalBench, for reliably\nevaluating VLMs with 10,000 human-verified VQA samples. Crucially, we adopt a\n$\\textbf{vision-centric}$ design by pairing each question with two images that\nyield different answers, preventing blind solutions from answering without\nusing the images. This makes NaturalBench more challenging than previous\nbenchmarks that can be solved with commonsense priors. We evaluate 53\nstate-of-the-art VLMs on NaturalBench, showing that models like\nLLaVA-OneVision, Cambrian-1, Llama3.2-Vision, Molmo, Qwen2-VL, and even GPT-4o\nlag 50%-70% behind human performance (over 90%). We analyze why NaturalBench is\nhard from two angles: (1) Compositionality: Solving NaturalBench requires\ndiverse visio-linguistic skills, including understanding attribute bindings,\nobject relationships, and advanced reasoning like logic and counting. To this\nend, unlike prior work that uses a single tag per sample, we tag each\nNaturalBench sample with 1 to 8 skill tags for fine-grained evaluation. (2)\nBiases: NaturalBench exposes severe biases in VLMs, as models often choose the\nsame answer regardless of the image. Lastly, we apply our benchmark curation\nmethod to diverse data sources, including long captions (over 100 words) and\nnon-English languages like Chinese and Hindi, highlighting its potential for\ndynamic evaluations of VLMs.", "AI": {"tldr": "VLMs struggle with natural adversarial samples, prompting the creation of NaturalBench, a challenging benchmark revealing significant performance gaps between models and humans.", "motivation": "To assess if VLMs truly excel in complex visio-linguistic reasoning by testing them on natural adversarial samples humans easily solve.", "method": "A semi-automated approach using CLIP and ChatGPT to generate and verify 10,000 VQA samples, designed vision-centrically with paired images.", "result": "State-of-the-art VLMs lag 50%-70% behind human performance (90+%), revealing biases and skill gaps in compositionality.", "conclusion": "NaturalBench highlights VLMs' limitations and biases, offering a robust framework for dynamic evaluation across diverse data sources."}}
{"id": "2504.14350", "pdf": "https://arxiv.org/pdf/2504.14350", "abs": "https://arxiv.org/abs/2504.14350", "authors": ["Yi Sun", "Han Wang", "Jiaqiang Li", "Jiacheng Liu", "Xiangyu Li", "Hao Wen", "Huiwen Zheng", "Yan Liang", "Yuanchun Li", "Yunxin Liu"], "title": "Time's Up! An Empirical Study of LLM Reasoning Ability Under Output Length Constraint", "categories": ["cs.AI"], "comment": null, "summary": "Recent work has demonstrated the remarkable potential of Large Language\nModels (LLMs) in test-time scaling. By making the models think before\nanswering, they are able to achieve much higher accuracy with extra inference\ncomputation. However, in many real-world scenarios, models are used under time\nconstraints, where an answer should be given to the user within a certain\noutput length. It is unclear whether and how the reasoning abilities of LLMs\nremain effective under such constraints. We take a first look at this problem\nby conducting an in-depth empirical study. Specifically, we test more than 25\nLLMs on common reasoning datasets under a wide range of output length budgets,\nand we analyze the correlation between the inference accuracy and various\nproperties including model type, model size, prompt style, etc. We also\nconsider the mappings between the token budgets and the actual on-device\nlatency budgets. The results have demonstrated several interesting findings\nregarding the budget-aware LLM reasoning that differ from the unconstrained\nsituation, e.g. the optimal choices of model sizes and prompts change under\ndifferent budgets. These findings offer practical guidance for users to deploy\nLLMs under real-world latency constraints.", "AI": {"tldr": "The paper explores how Large Language Models (LLMs) perform under time and output length constraints, finding that optimal model choices and prompts vary with budget limits.", "motivation": "To understand if and how LLMs' reasoning abilities remain effective under real-world time and output length constraints.", "method": "An empirical study testing over 25 LLMs on reasoning datasets under varying output length budgets, analyzing accuracy correlations with model properties.", "result": "Optimal model sizes and prompts change under different budgets, differing from unconstrained scenarios.", "conclusion": "The findings provide practical guidance for deploying LLMs under latency constraints."}}
{"id": "2504.15578", "pdf": "https://arxiv.org/pdf/2504.15578", "abs": "https://arxiv.org/abs/2504.15578", "authors": ["Ian Mikesell", "Samuel Filgueira da Silva", "Mehmet Fatih Ozkan", "Faissal El Idrissi", "Prashanth Ramesh", "Marcello Canova"], "title": "Real-Time Optimal Design of Experiment for Parameter Identification of Li-Ion Cell Electrochemical Model", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "Accurately identifying the parameters of electrochemical models of li-ion\nbattery (LiB) cells is a critical task for enhancing the fidelity and\npredictive ability. Traditional parameter identification methods often require\nextensive data collection experiments and lack adaptability in dynamic\nenvironments. This paper describes a Reinforcement Learning (RL) based approach\nthat dynamically tailors the current profile applied to a LiB cell to optimize\nthe parameters identifiability of the electrochemical model. The proposed\nframework is implemented in real-time using a Hardware-in-the-Loop (HIL) setup,\nwhich serves as a reliable testbed for evaluating the RL-based design strategy.\nThe HIL validation confirms that the RL-based experimental design outperforms\nconventional test protocols used for parameter identification in terms of both\nreducing the modeling errors on a verification test and minimizing the duration\nof the experiment used for parameter identification.", "AI": {"tldr": "A Reinforcement Learning (RL) approach optimizes Li-ion battery model parameter identification, outperforming traditional methods in accuracy and efficiency.", "motivation": "Traditional parameter identification methods for Li-ion batteries are data-intensive and inflexible in dynamic environments.", "method": "Uses RL to dynamically tailor current profiles for optimal parameter identifiability, validated via a Hardware-in-the-Loop (HIL) setup.", "result": "RL-based design reduces modeling errors and experiment duration compared to conventional protocols.", "conclusion": "The RL framework enhances Li-ion battery model fidelity and efficiency in parameter identification."}}
{"id": "2304.07647", "pdf": "https://arxiv.org/pdf/2304.07647", "abs": "https://arxiv.org/abs/2304.07647", "authors": ["Jiani Huang", "Ziyang Li", "Mayur Naik", "Ser-Nam Lim"], "title": "LASER: A Neuro-Symbolic Framework for Learning Spatial-Temporal Scene Graphs with Weak Supervision", "categories": ["cs.CV", "cs.LG", "cs.LO"], "comment": null, "summary": "Supervised approaches for learning spatio-temporal scene graphs (STSG) from\nvideo are greatly hindered due to their reliance on STSG-annotated videos,\nwhich are labor-intensive to construct at scale. Is it feasible to instead use\nreadily available video captions as weak supervision? To address this question,\nwe propose LASER, a neuro-symbolic framework to enable training STSG generators\nusing only video captions. LASER employs large language models to first extract\nlogical specifications with rich spatio-temporal semantic information from\nvideo captions. LASER then trains the underlying STSG generator to align the\npredicted STSG with the specification. The alignment algorithm overcomes the\nchallenges of weak supervision by leveraging a differentiable symbolic reasoner\nand using a combination of contrastive, temporal, and semantics losses. The\noverall approach efficiently trains low-level perception models to extract a\nfine-grained STSG that conforms to the video caption. In doing so, it enables a\nnovel methodology for learning STSGs without tedious annotations. We evaluate\nour method on three video datasets: OpenPVSG, 20BN, and MUGEN. Our approach\ndemonstrates substantial improvements over fully-supervised baselines,\nachieving a unary predicate prediction accuracy of 27.78% (+12.65%) and a\nbinary recall@5 of 0.42 (+0.22) on OpenPVSG. Additionally, LASER exceeds\nbaselines by 7% on 20BN and 5.2% on MUGEN in terms of overall predicate\nprediction accuracy.", "AI": {"tldr": "LASER trains spatio-temporal scene graph (STSG) generators using video captions as weak supervision, outperforming fully-supervised baselines.", "motivation": "Avoiding labor-intensive STSG annotations by leveraging readily available video captions.", "method": "Uses large language models to extract logical specifications from captions and aligns predicted STSG with specifications via a differentiable symbolic reasoner and multiple losses.", "result": "Achieves significant improvements in predicate prediction accuracy on OpenPVSG, 20BN, and MUGEN datasets.", "conclusion": "LASER enables efficient STSG learning without manual annotations, demonstrating superior performance over supervised methods."}}
{"id": "2502.19676", "pdf": "https://arxiv.org/pdf/2502.19676", "abs": "https://arxiv.org/abs/2502.19676", "authors": ["Zhangdie Yuan", "Zifeng Ding", "Andreas Vlachos"], "title": "FOReCAst: The Future Outcome Reasoning and Confidence Assessment Benchmark", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Forecasting is an important task in many domains, such as technology and\neconomics. However existing forecasting benchmarks largely lack comprehensive\nconfidence assessment, focus on limited question types, and often consist of\nartificial questions that do not align with real-world human forecasting needs.\nTo address these gaps, we introduce FOReCAst (Future Outcome Reasoning and\nConfidence Assessment), a benchmark that evaluates models' ability to make\npredictions and their confidence in them. FOReCAst spans diverse forecasting\nscenarios involving Boolean questions, timeframe prediction, and quantity\nestimation, enabling a comprehensive evaluation of both prediction accuracy and\nconfidence calibration for real-world applications.", "AI": {"tldr": "FOReCAst is a new benchmark for evaluating forecasting models' prediction accuracy and confidence calibration across diverse real-world scenarios.", "motivation": "Existing forecasting benchmarks lack comprehensive confidence assessment and real-world relevance, limiting their practical utility.", "method": "Introduces FOReCAst, a benchmark with diverse forecasting scenarios (Boolean, timeframe, quantity) to assess prediction and confidence.", "result": "FOReCAst enables a more comprehensive evaluation of forecasting models for real-world applications.", "conclusion": "FOReCAst addresses gaps in current benchmarks, providing a tool for better forecasting model assessment."}}
{"id": "2504.14706", "pdf": "https://arxiv.org/pdf/2504.14706", "abs": "https://arxiv.org/abs/2504.14706", "authors": ["Shin-nosuke Ishikawa", "Atsushi Yoshino"], "title": "AI with Emotions: Exploring Emotional Expressions in Large Language Models", "categories": ["cs.AI"], "comment": "14 pages, 8 figures, accepted to the Natural Language Processing for\n  Digital Humanities (NLP4DH) workshop at NAACL 2025", "summary": "The human-level performance of Large Language Models (LLMs) across various\ntasks has raised expectations for the potential of Artificial Intelligence (AI)\nto possess emotions someday. To explore the capability of current LLMs to\nexpress emotions in their outputs, we conducted an experiment using several\nLLMs (OpenAI GPT, Google Gemini, Meta Llama3, and Cohere Command R+) to\nrole-play as agents answering questions with specified emotional states. We\ndefined the emotional states using Russell's Circumplex model, a\nwell-established framework that characterizes emotions along the\nsleepy-activated (arousal) and pleasure-displeasure (valence) axes. We chose\nthis model for its simplicity, utilizing two continuous parameters, which\nallows for better controllability in applications involving continuous changes\nin emotional states. The responses generated were evaluated using a sentiment\nanalysis model, independent of the LLMs, trained on the GoEmotions dataset. The\nevaluation showed that the emotional states of the generated answers were\nconsistent with the specifications, demonstrating the LLMs' capability for\nemotional expression. This indicates the potential for LLM-based AI agents to\nsimulate emotions, opening up a wide range of applications for emotion-based\ninteractions, such as advisors or consultants who can provide advice or\nopinions with a personal touch.", "AI": {"tldr": "LLMs can simulate emotions in outputs, validated by sentiment analysis, showing potential for emotion-based AI interactions.", "motivation": "Explore if current LLMs can express emotions in outputs, given their human-like performance in tasks.", "method": "Used Russell's Circumplex model to define emotions; tested LLMs (GPT, Gemini, Llama3, Command R+) with sentiment analysis for evaluation.", "result": "LLM-generated responses matched specified emotional states, proving their capability for emotional expression.", "conclusion": "LLMs can simulate emotions, enabling applications like emotionally-aware AI advisors."}}
{"id": "2504.15580", "pdf": "https://arxiv.org/pdf/2504.15580", "abs": "https://arxiv.org/abs/2504.15580", "authors": ["Chengyuan Deng", "Jie Gao", "Jalaj Upadhyay", "Chen Wang", "Samson Zhou"], "title": "On the Price of Differential Privacy for Hierarchical Clustering", "categories": ["cs.DS", "cs.CR", "cs.LG"], "comment": "ICLR 2025", "summary": "Hierarchical clustering is a fundamental unsupervised machine learning task\nwith the aim of organizing data into a hierarchy of clusters. Many applications\nof hierarchical clustering involve sensitive user information, therefore\nmotivating recent studies on differentially private hierarchical clustering\nunder the rigorous framework of Dasgupta's objective. However, it has been\nshown that any privacy-preserving algorithm under edge-level differential\nprivacy necessarily suffers a large error. To capture practical applications of\nthis problem, we focus on the weight privacy model, where each edge of the\ninput graph is at least unit weight. We present a novel algorithm in the weight\nprivacy model that shows significantly better approximation than known\nimpossibility results in the edge-level DP setting. In particular, our\nalgorithm achieves $O(\\log^{1.5}n/\\varepsilon)$ multiplicative error for\n$\\varepsilon$-DP and runs in polynomial time, where $n$ is the size of the\ninput graph, and the cost is never worse than the optimal additive error in\nexisting work. We complement our algorithm by showing if the unit-weight\nconstraint does not apply, the lower bound for weight-level DP hierarchical\nclustering is essentially the same as the edge-level DP, i.e.\n$\\Omega(n^2/\\varepsilon)$ additive error. As a result, we also obtain a new\nlower bound of $\\tilde{\\Omega}(1/\\varepsilon)$ additive error for balanced\nsparsest cuts in the weight-level DP model, which may be of independent\ninterest. Finally, we evaluate our algorithm on synthetic and real-world\ndatasets. Our experimental results show that our algorithm performs well in\nterms of extra cost and has good scalability to large graphs.", "AI": {"tldr": "The paper introduces a differentially private hierarchical clustering algorithm for the weight privacy model, achieving better approximation than edge-level DP methods, with theoretical and empirical validation.", "motivation": "Hierarchical clustering often involves sensitive data, necessitating privacy-preserving methods. Existing edge-level DP approaches suffer high error, prompting exploration of the weight privacy model.", "method": "A novel algorithm is proposed for the weight privacy model, ensuring differential privacy with $O(\\log^{1.5}n/\\varepsilon)$ multiplicative error and polynomial runtime.", "result": "The algorithm outperforms edge-level DP methods, with theoretical bounds and empirical validation showing scalability and low extra cost.", "conclusion": "The weight privacy model offers a practical alternative to edge-level DP for hierarchical clustering, with improved error bounds and applicability to large graphs."}}
{"id": "2403.08728", "pdf": "https://arxiv.org/pdf/2403.08728", "abs": "https://arxiv.org/abs/2403.08728", "authors": ["Asad Aali", "Giannis Daras", "Brett Levac", "Sidharth Kumar", "Alexandros G. Dimakis", "Jonathan I. Tamir"], "title": "Ambient Diffusion Posterior Sampling: Solving Inverse Problems with Diffusion Models Trained on Corrupted Data", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We provide a framework for solving inverse problems with diffusion models\nlearned from linearly corrupted data. Firstly, we extend the Ambient Diffusion\nframework to enable training directly from measurements corrupted in the\nFourier domain. Subsequently, we train diffusion models for MRI with access\nonly to Fourier subsampled multi-coil measurements at acceleration factors R=\n2,4,6,8. Secondly, we propose Ambient Diffusion Posterior Sampling (A-DPS), a\nreconstruction algorithm that leverages generative models pre-trained on one\ntype of corruption (e.g. image inpainting) to perform posterior sampling on\nmeasurements from a different forward process (e.g. image blurring). For MRI\nreconstruction in high acceleration regimes, we observe that A-DPS models\ntrained on subsampled data are better suited to solving inverse problems than\nmodels trained on fully sampled data. We also test the efficacy of A-DPS on\nnatural image datasets (CelebA, FFHQ, and AFHQ) and show that A-DPS can\nsometimes outperform models trained on clean data for several image restoration\ntasks in both speed and performance.", "AI": {"tldr": "A framework for solving inverse problems using diffusion models trained on corrupted data, with applications in MRI and natural image restoration.", "motivation": "To address inverse problems in scenarios where only corrupted data is available, leveraging diffusion models for improved reconstruction.", "method": "Extends Ambient Diffusion for training on Fourier-corrupted data; proposes Ambient Diffusion Posterior Sampling (A-DPS) for reconstruction using pre-trained models on different corruptions.", "result": "A-DPS models trained on subsampled data outperform those on fully sampled data in MRI reconstruction and natural image restoration tasks.", "conclusion": "The framework and A-DPS algorithm demonstrate effectiveness in solving inverse problems with corrupted data, offering potential in medical imaging and image restoration."}}
{"id": "2504.09723", "pdf": "https://arxiv.org/pdf/2504.09723", "abs": "https://arxiv.org/abs/2504.09723", "authors": ["Dakuo Wang", "Ting-Yao Hsu", "Yuxuan Lu", "Hansu Gu", "Limeng Cui", "Yaochen Xie", "William Headean", "Bingsheng Yao", "Akash Veeragouni", "Jiapeng Liu", "Sreyashi Nag", "Jessie Wang"], "title": "AgentA/B: Automated and Scalable Web A/BTesting with Interactive LLM Agents", "categories": ["cs.HC", "cs.CL"], "comment": null, "summary": "A/B testing experiment is a widely adopted method for evaluating UI/UX design\ndecisions in modern web applications. Yet, traditional A/B testing remains\nconstrained by its dependence on the large-scale and live traffic of human\nparticipants, and the long time of waiting for the testing result. Through\nformative interviews with six experienced industry practitioners, we identified\ncritical bottlenecks in current A/B testing workflows. In response, we present\nAgentA/B, a novel system that leverages Large Language Model-based autonomous\nagents (LLM Agents) to automatically simulate user interaction behaviors with\nreal webpages. AgentA/B enables scalable deployment of LLM agents with diverse\npersonas, each capable of navigating the dynamic webpage and interactively\nexecuting multi-step interactions like search, clicking, filtering, and\npurchasing. In a demonstrative controlled experiment, we employ AgentA/B to\nsimulate a between-subject A/B testing with 1,000 LLM agents Amazon.com, and\ncompare agent behaviors with real human shopping behaviors at a scale. Our\nfindings suggest AgentA/B can emulate human-like behavior patterns.", "AI": {"tldr": "AgentA/B uses LLM agents to simulate user interactions for A/B testing, reducing reliance on live traffic and speeding up results.", "motivation": "Traditional A/B testing is slow and requires large-scale human traffic, prompting the need for an automated solution.", "method": "AgentA/B employs LLM-based agents with diverse personas to simulate multi-step interactions on webpages.", "result": "In a controlled experiment, AgentA/B emulated human-like behavior patterns in A/B testing on Amazon.com.", "conclusion": "AgentA/B offers a scalable and efficient alternative to traditional A/B testing by simulating human interactions."}}
{"id": "2504.15046", "pdf": "https://arxiv.org/pdf/2504.15046", "abs": "https://arxiv.org/abs/2504.15046", "authors": ["Shilin Zhang", "Zican Hu", "Wenhao Wu", "Xinyi Xie", "Jianxiang Tang", "Chunlin Chen", "Daoyi Dong", "Yu Cheng", "Zhenhong Sun", "Zhi Wang"], "title": "Text-to-Decision Agent: Learning Generalist Policies from Natural Language Supervision", "categories": ["cs.AI"], "comment": "18 pages, 8 figures", "summary": "RL systems usually tackle generalization by inferring task beliefs from\nhigh-quality samples or warmup explorations. The restricted form limits their\ngenerality and usability since these supervision signals are expensive and even\ninfeasible to acquire in advance for unseen tasks. Learning directly from the\nraw text about decision tasks is a promising alternative to leverage a much\nbroader source of supervision. In the paper, we propose Text-to-Decision Agent\n(T2DA), a simple and scalable framework that supervises generalist policy\nlearning with natural language. We first introduce a generalized world model to\nencode multi-task decision data into a dynamics-aware embedding space. Then,\ninspired by CLIP, we predict which textual description goes with which decision\nembedding, effectively bridging their semantic gap via contrastive\nlanguage-decision pre-training and aligning the text embeddings to comprehend\nthe environment dynamics. After training the text-conditioned generalist\npolicy, the agent can directly realize zero-shot text-to-decision generation in\nresponse to language instructions. Comprehensive experiments on MuJoCo and\nMeta-World benchmarks show that T2DA facilitates high-capacity zero-shot\ngeneralization and outperforms various types of baselines.", "AI": {"tldr": "T2DA is a framework that uses natural language to supervise generalist policy learning, enabling zero-shot text-to-decision generation without expensive pre-acquired task signals.", "motivation": "Overcome the limitations of RL systems that rely on costly or infeasible supervision signals for generalization by leveraging raw text as a broader source of supervision.", "method": "Introduce a generalized world model for multi-task decision data encoding and use contrastive language-decision pre-training (inspired by CLIP) to align text embeddings with decision embeddings.", "result": "T2DA achieves high-capacity zero-shot generalization and outperforms baselines on MuJoCo and Meta-World benchmarks.", "conclusion": "T2DA provides a scalable and effective solution for text-conditioned policy learning, demonstrating strong zero-shot generalization capabilities."}}
{"id": "2504.15632", "pdf": "https://arxiv.org/pdf/2504.15632", "abs": "https://arxiv.org/abs/2504.15632", "authors": ["Seyed Shayan Daneshvar", "Da Tan", "Shaowei Wang", "Carson Leung"], "title": "A Study On Mixup-inspired Augmentation Methods For Software Vulnerability Detection", "categories": ["cs.SE", "cs.CR", "cs.LG"], "comment": "Accepted at EASE 2025, Istanbul, Turkey", "summary": "Various Deep Learning (DL) methods have recently been utilized to detect\nsoftware vulnerabilities. Real-world software vulnerability datasets are rare\nand hard to acquire as there's no simple metric for classifying vulnerability.\nSuch datasets are heavily imbalanced, and none of the current datasets are\nconsidered huge for DL models. To tackle these problems a recent work has tried\nto augment the dataset using the source code and generate realistic\nsingle-statement vulnerabilities which is not quite practical and requires\nmanual checking of the generated vulnerabilities. In this regard, we aim to\nexplore the augmentation of vulnerabilities at the representation level to help\ncurrent models learn better which has never been done before to the best of our\nknowledge. We implement and evaluate the 5 augmentation techniques that augment\nthe embedding of the data and recently have been used for code search which is\na completely different software engineering task. We also introduced a\nconditioned version of those augmentation methods, which ensures the\naugmentation does not change the vulnerable section of the vector\nrepresentation. We show that such augmentation methods can be helpful and\nincrease the f1-score by up to 9.67%, yet they cannot beat Random Oversampling\nwhen balancing datasets which increases the f1-score by 10.82%!", "AI": {"tldr": "The paper explores embedding-level augmentation for software vulnerability detection, improving F1-score by 9.67%, but falls short of Random Oversampling's 10.82% gain.", "motivation": "Real-world vulnerability datasets are rare, imbalanced, and small for DL models. Existing augmentation methods are impractical, prompting exploration of representation-level augmentation.", "method": "Implemented and evaluated 5 embedding augmentation techniques, including a conditioned version to preserve vulnerable sections. Compared with Random Oversampling.", "result": "Embedding augmentation improved F1-score by 9.67%, but Random Oversampling outperformed it with a 10.82% increase.", "conclusion": "Representation-level augmentation is beneficial but less effective than Random Oversampling for balancing datasets in vulnerability detection."}}
{"id": "2404.12803", "pdf": "https://arxiv.org/pdf/2404.12803", "abs": "https://arxiv.org/abs/2404.12803", "authors": ["Jingqun Tang", "Chunhui Lin", "Zhen Zhao", "Shu Wei", "Binghong Wu", "Qi Liu", "Hao Feng", "Yang Li", "Siqi Wang", "Lei Liao", "Wei Shi", "Yuliang Liu", "Hao Liu", "Yuan Xie", "Xiang Bai", "Can Huang"], "title": "TextSquare: Scaling up Text-Centric Visual Instruction Tuning", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Text-centric visual question answering (VQA) has made great strides with the\ndevelopment of Multimodal Large Language Models (MLLMs), yet open-source models\nstill fall short of leading models like GPT4V and Gemini, partly due to a lack\nof extensive, high-quality instruction tuning data. To this end, we introduce a\nnew approach for creating a massive, high-quality instruction-tuning dataset,\nSquare-10M, which is generated using closed-source MLLMs. The data construction\nprocess, termed Square, consists of four steps: Self-Questioning, Answering,\nReasoning, and Evaluation. Our experiments with Square-10M led to three key\nfindings: 1) Our model, TextSquare, considerably surpasses open-source previous\nstate-of-the-art Text-centric MLLMs and sets a new standard on OCRBench(62.2%).\nIt even outperforms top-tier models like GPT4V and Gemini in 6 of 10\ntext-centric benchmarks. 2) Additionally, we demonstrate the critical role of\nVQA reasoning data in offering comprehensive contextual insights for specific\nquestions. This not only improves accuracy but also significantly mitigates\nhallucinations. Specifically, TextSquare scores an average of 75.1% across four\ngeneral VQA and hallucination evaluation datasets, outperforming previous\nstate-of-the-art models. 3) Notably, the phenomenon observed in scaling\ntext-centric VQA datasets reveals a vivid pattern: the exponential increase of\ninstruction tuning data volume is directly proportional to the improvement in\nmodel performance, thereby validating the necessity of the dataset scale and\nthe high quality of Square-10M.", "AI": {"tldr": "The paper introduces Square-10M, a high-quality instruction-tuning dataset for text-centric VQA, generated using closed-source MLLMs. The model TextSquare outperforms open-source and top-tier models, highlighting the importance of dataset scale and reasoning data.", "motivation": "Open-source models lag behind leading models like GPT4V and Gemini due to limited high-quality instruction tuning data. The goal is to bridge this gap by creating a large, high-quality dataset.", "method": "The Square method involves four steps: Self-Questioning, Answering, Reasoning, and Evaluation, to generate the Square-10M dataset.", "result": "TextSquare surpasses open-source models and outperforms GPT4V and Gemini in 6/10 benchmarks. It also improves accuracy and reduces hallucinations in VQA tasks.", "conclusion": "Scaling text-centric VQA datasets exponentially improves model performance, validating the necessity of large, high-quality datasets like Square-10M."}}
{"id": "2504.14945", "pdf": "https://arxiv.org/pdf/2504.14945", "abs": "https://arxiv.org/abs/2504.14945", "authors": ["Jianhao Yan", "Yafu Li", "Zican Hu", "Zhi Wang", "Ganqu Cui", "Xiaoye Qu", "Yu Cheng", "Yue Zhang"], "title": "Learning to Reason under Off-Policy Guidance", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Work in progress", "summary": "Recent advances in large reasoning models (LRMs) demonstrate that\nsophisticated behaviors such as multi-step reasoning and self-reflection can\nemerge via reinforcement learning (RL) with simple rule-based rewards. However,\nexisting zero-RL approaches are inherently ``on-policy'', limiting learning to\na model's own outputs and failing to acquire reasoning abilities beyond its\ninitial capabilities. We introduce LUFFY (Learning to reason Under oFF-policY\nguidance), a framework that augments zero-RL with off-policy reasoning traces.\nLUFFY dynamically balances imitation and exploration by combining off-policy\ndemonstrations with on-policy rollouts during training. Notably, we propose\npolicy shaping via regularized importance sampling to avoid superficial and\nrigid imitation during mixed-policy training. Remarkably, LUFFY achieves an\nover +7.0 average gain across six math benchmarks and an advantage of over +6.2\npoints in out-of-distribution tasks. It also substantially surpasses\nimitation-based supervised fine-tuning (SFT), particularly in generalization.\nAnalysis shows LUFFY not only imitates effectively but also explores beyond\ndemonstrations, offering a scalable path to train generalizable reasoning\nmodels with off-policy guidance.", "AI": {"tldr": "LUFFY enhances zero-RL with off-policy reasoning traces, achieving significant gains in math benchmarks and outperforming imitation-based methods.", "motivation": "Existing zero-RL methods are limited to on-policy learning, restricting reasoning ability beyond initial capabilities.", "method": "LUFFY combines off-policy demonstrations with on-policy rollouts, using policy shaping via regularized importance sampling.", "result": "+7.0 average gain in math benchmarks, +6.2 advantage in out-of-distribution tasks, surpassing SFT in generalization.", "conclusion": "LUFFY offers a scalable way to train generalizable reasoning models by balancing imitation and exploration."}}
{"id": "2504.15188", "pdf": "https://arxiv.org/pdf/2504.15188", "abs": "https://arxiv.org/abs/2504.15188", "authors": ["Yizhu Jiao", "Xuchao Zhang", "Zhaoyang Wang", "Yubo Ma", "Zhun Deng", "Rujia Wang", "Chetan Bansal", "Saravan Rajmohan", "Jiawei Han", "Huaxiu Yao"], "title": "Synergistic Weak-Strong Collaboration by Aligning Preferences", "categories": ["cs.AI"], "comment": null, "summary": "Current Large Language Models (LLMs) excel in general reasoning yet struggle\nwith specialized tasks requiring proprietary or domain-specific knowledge.\nFine-tuning large models for every niche application is often infeasible due to\nblack-box constraints and high computational overhead. To address this, we\npropose a collaborative framework that pairs a specialized weak model with a\ngeneral strong model. The weak model, tailored to specific domains, produces\ninitial drafts and background information, while the strong model leverages its\nadvanced reasoning to refine these drafts, extending LLMs' capabilities to\ncritical yet specialized tasks. To optimize this collaboration, we introduce a\ncollaborative feedback to fine-tunes the weak model, which quantifies the\ninfluence of the weak model's contributions in the collaboration procedure and\nestablishes preference pairs to guide preference tuning of the weak model. We\nvalidate our framework through experiments on three domains. We find that the\ncollaboration significantly outperforms each model alone by leveraging\ncomplementary strengths. Moreover, aligning the weak model with the\ncollaborative preference further enhances overall performance.", "AI": {"tldr": "A collaborative framework pairs a specialized weak model with a general strong model to enhance LLMs' performance in specialized tasks, outperforming individual models.", "motivation": "LLMs struggle with specialized tasks due to lack of domain-specific knowledge and high computational costs of fine-tuning.", "method": "Proposes a framework where a weak model provides drafts and background, while a strong model refines them. Introduces collaborative feedback to fine-tune the weak model.", "result": "Collaboration outperforms individual models, and aligning the weak model with collaborative preferences further improves performance.", "conclusion": "The framework effectively extends LLMs' capabilities to specialized tasks by leveraging complementary strengths of weak and strong models."}}
{"id": "2504.15657", "pdf": "https://arxiv.org/pdf/2504.15657", "abs": "https://arxiv.org/abs/2504.15657", "authors": ["Yibo Liu", "Paul Kry", "Kenny Erleben", "Noam Aigerman", "Sune Darkner", "Teseo Schneider"], "title": "Neural Kinematic Bases for Fluids", "categories": ["cs.GR", "cs.LG", "physics.flu-dyn"], "comment": null, "summary": "We propose mesh-free fluid simulations that exploit a kinematic neural basis\nfor velocity fields represented by an MLP. We design a set of losses that\nensures that these neural bases satisfy fundamental physical properties such as\northogonality, divergence-free, boundary alignment, and smoothness. Our neural\nbases can then be used to fit an input sketch of a flow, which will inherit the\nsame fundamental properties from the bases. We then can animate such flow in\nreal-time using standard time integrators. Our neural bases can accommodate\ndifferent domains and naturally extend to three dimensions.", "AI": {"tldr": "Mesh-free fluid simulations using neural bases for velocity fields, ensuring physical properties like orthogonality and divergence-free, enabling real-time animation.", "motivation": "To create fluid simulations that adhere to fundamental physical properties while being flexible and efficient.", "method": "Uses kinematic neural bases represented by an MLP, with designed losses for physical properties, and fits input sketches to animate flows.", "result": "Neural bases accommodate various domains and extend to 3D, enabling real-time animation.", "conclusion": "The approach provides a flexible, efficient, and physically accurate method for fluid simulations."}}
{"id": "2406.04861", "pdf": "https://arxiv.org/pdf/2406.04861", "abs": "https://arxiv.org/abs/2406.04861", "authors": ["Aarya Patel", "Hamid Laga", "Ojaswa Sharma"], "title": "Normal-guided Detail-Preserving Neural Implicit Function for High-Fidelity 3D Surface Reconstruction", "categories": ["cs.CV", "cs.GR", "I.3.5"], "comment": "Accepted at ACM SIGGRAPH I3D 2025. Published in PACMCGIT journal.\n  Project page with images and code:\n  https://graphics-research-group.github.io/sn-nir", "summary": "Neural implicit representations have emerged as a powerful paradigm for 3D\nreconstruction. However, despite their success, existing methods fail to\ncapture fine geometric details and thin structures, especially in scenarios\nwhere only sparse multi-view RGB images of the objects of interest are\navailable. This paper shows that training neural representations with\nfirst-order differential properties (surface normals) leads to highly accurate\n3D surface reconstruction, even with as few as two RGB images. Using input RGB\nimages, we compute approximate ground-truth surface normals from depth maps\nproduced by an off-the-shelf monocular depth estimator. During training, we\ndirectly locate the surface point of the SDF network and supervise its normal\nwith the one estimated from the depth map. Extensive experiments demonstrate\nthat our method achieves state-of-the-art reconstruction accuracy with a\nminimal number of views, capturing intricate geometric details and thin\nstructures that were previously challenging to capture.", "AI": {"tldr": "Training neural representations with surface normals improves 3D reconstruction accuracy, even with sparse RGB images.", "motivation": "Existing neural implicit representations struggle to capture fine details and thin structures from sparse multi-view RGB images.", "method": "Use first-order differential properties (surface normals) derived from depth maps of RGB images to train the SDF network, supervising surface points directly.", "result": "Achieves state-of-the-art reconstruction accuracy with minimal views, capturing intricate details and thin structures.", "conclusion": "Incorporating surface normals significantly enhances 3D reconstruction quality from sparse inputs."}}
{"id": "2311.17059", "pdf": "https://arxiv.org/pdf/2311.17059", "abs": "https://arxiv.org/abs/2311.17059", "authors": ["Jun Wang", "Hosein Hasanbeig", "Kaiyuan Tan", "Zihe Sun", "Yiannis Kantaros"], "title": "Mission-driven Exploration for Accelerated Deep Reinforcement Learning with Temporal Logic Task Specifications", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper addresses the problem of designing control policies for agents\nwith unknown stochastic dynamics and control objectives specified using Linear\nTemporal Logic (LTL). Recent Deep Reinforcement Learning (DRL) algorithms have\naimed to compute policies that maximize the satisfaction probability of LTL\nformulas, but they often suffer from slow learning performance. To address\nthis, we introduce a novel Deep Q-learning algorithm that significantly\nimproves learning speed. The enhanced sample efficiency stems from a\nmission-driven exploration strategy that prioritizes exploration towards\ndirections likely to contribute to mission success. Identifying these\ndirections relies on an automaton representation of the LTL task as well as a\nlearned neural network that partially models the agent-environment interaction.\nWe provide comparative experiments demonstrating the efficiency of our\nalgorithm on robot navigation tasks in unseen environments.", "AI": {"tldr": "A novel Deep Q-learning algorithm improves learning speed for agents with unknown dynamics and LTL-specified objectives by using mission-driven exploration.", "motivation": "Existing DRL algorithms for LTL-specified objectives suffer from slow learning performance.", "method": "Introduces a mission-driven exploration strategy leveraging automaton representation of LTL tasks and a neural network modeling agent-environment interaction.", "result": "Comparative experiments show improved efficiency in robot navigation tasks in unseen environments.", "conclusion": "The proposed algorithm enhances learning speed and sample efficiency for LTL-specified control policies."}}
{"id": "2504.15674", "pdf": "https://arxiv.org/pdf/2504.15674", "abs": "https://arxiv.org/abs/2504.15674", "authors": ["Yanbo Dai", "Songze Li", "Zihan Gan", "Xueluan Gong"], "title": "TrojanDam: Detection-Free Backdoor Defense in Federated Learning through Proactive Model Robustification utilizing OOD Data", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Federated learning (FL) systems allow decentralized data-owning clients to\njointly train a global model through uploading their locally trained updates to\na centralized server. The property of decentralization enables adversaries to\ncraft carefully designed backdoor updates to make the global model misclassify\nonly when encountering adversary-chosen triggers. Existing defense mechanisms\nmainly rely on post-training detection after receiving updates. These methods\neither fail to identify updates which are deliberately fabricated statistically\nclose to benign ones, or show inconsistent performance in different FL training\nstages. The effect of unfiltered backdoor updates will accumulate in the global\nmodel, and eventually become functional. Given the difficulty of ruling out\nevery backdoor update, we propose a backdoor defense paradigm, which focuses on\nproactive robustification on the global model against potential backdoor\nattacks. We first reveal that the successful launching of backdoor attacks in\nFL stems from the lack of conflict between malicious and benign updates on\nredundant neurons of ML models. We proceed to prove the feasibility of\nactivating redundant neurons utilizing out-of-distribution (OOD) samples in\ncentralized settings, and migrating to FL settings to propose a novel backdoor\ndefense mechanism, TrojanDam. The proposed mechanism has the FL server\ncontinuously inject fresh OOD mappings into the global model to activate\nredundant neurons, canceling the effect of backdoor updates during aggregation.\nWe conduct systematic and extensive experiments to illustrate the superior\nperformance of TrojanDam, over several SOTA backdoor defense methods across a\nwide range of FL settings.", "AI": {"tldr": "The paper introduces TrojanDam, a proactive defense mechanism for federated learning (FL) against backdoor attacks by activating redundant neurons using out-of-distribution samples.", "motivation": "Existing post-training defenses in FL fail to detect statistically similar backdoor updates or perform inconsistently, leading to accumulated global model vulnerabilities.", "method": "The proposed TrojanDam mechanism injects out-of-distribution (OOD) samples into the global model to activate redundant neurons, neutralizing backdoor updates during aggregation.", "result": "TrojanDam outperforms state-of-the-art backdoor defense methods across various FL settings.", "conclusion": "Proactive robustification via OOD sample injection effectively mitigates backdoor attacks in FL, offering superior defense performance."}}
{"id": "2406.12407", "pdf": "https://arxiv.org/pdf/2406.12407", "abs": "https://arxiv.org/abs/2406.12407", "authors": ["Pit Henrich", "Franziska Mathis-Ullrich"], "title": "LOOC: Localizing Organs using Occupancy Networks and Body Surface Depth Images", "categories": ["cs.CV"], "comment": "Published in IEEE Access", "summary": "We introduce a novel approach for the precise localization of 67 anatomical\nstructures from single depth images captured from the exterior of the human\nbody. Our method uses a multi-class occupancy network, trained using segmented\nCT scans augmented with body-pose changes, and incorporates a specialized\nsampling strategy to handle densely packed internal organs. Our contributions\ninclude the application of occupancy networks for occluded structure\nlocalization, a robust method for estimating anatomical positions from depth\nimages, and the creation of detailed, individualized 3D anatomical atlases. We\noutperform localization using template matching and provide qualitative\nreal-world reconstructions. This method promises improvements in automated\nmedical imaging and diagnostic procedures by offering accurate, non-invasive\nlocalization of critical anatomical structures.", "AI": {"tldr": "A novel method for precise localization of 67 anatomical structures from single depth images using a multi-class occupancy network, outperforming template matching and enabling non-invasive medical applications.", "motivation": "To improve automated medical imaging and diagnostics by accurately localizing anatomical structures non-invasively from depth images.", "method": "Uses a multi-class occupancy network trained on segmented CT scans with body-pose augmentation and a specialized sampling strategy for dense organs.", "result": "Outperforms template matching, provides detailed 3D anatomical atlases, and enables qualitative real-world reconstructions.", "conclusion": "The method enhances non-invasive localization of critical structures, promising advancements in medical imaging and diagnostics."}}
{"id": "2404.00247", "pdf": "https://arxiv.org/pdf/2404.00247", "abs": "https://arxiv.org/abs/2404.00247", "authors": ["Runze Lin", "Junghui Chen", "Lei Xie", "Hongye Su"], "title": "Facilitating Reinforcement Learning for Process Control Using Transfer Learning: Overview and Perspectives", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "comment": "Chinese Control and Decision Conference (CCDC 2025), Oral, Regular\n  Paper & Asian Control Conference (ASCC 2024), Oral, Position Paper", "summary": "In the context of Industry 4.0 and smart manufacturing, the field of process\nindustry optimization and control is also undergoing a digital transformation.\nWith the rise of Deep Reinforcement Learning (DRL), its application in process\ncontrol has attracted widespread attention. However, the extremely low sample\nefficiency and the safety concerns caused by exploration in DRL hinder its\npractical implementation in industrial settings. Transfer learning offers an\neffective solution for DRL, enhancing its generalization and adaptability in\nmulti-mode control scenarios. This paper provides insights into the use of DRL\nfor process control from the perspective of transfer learning. We analyze the\nchallenges of applying DRL in the process industry and the necessity of\nintroducing transfer learning. Furthermore, recommendations and prospects are\nprovided for future research directions on how transfer learning can be\nintegrated with DRL to enhance process control. This paper aims to offer a set\nof promising, user-friendly, easy-to-implement, and scalable approaches to\nartificial intelligence-facilitated industrial control for scholars and\nengineers in the process industry.", "AI": {"tldr": "The paper explores using transfer learning to improve Deep Reinforcement Learning (DRL) for process control in Industry 4.0, addressing low sample efficiency and safety concerns.", "motivation": "The rise of DRL in process control is hindered by low sample efficiency and safety issues, prompting the need for transfer learning to enhance adaptability.", "method": "Analyzes challenges of DRL in process control and proposes transfer learning as a solution for better generalization and safety.", "result": "Highlights the potential of transfer learning to make DRL more practical and scalable for industrial settings.", "conclusion": "Recommends integrating transfer learning with DRL for future research to improve AI-facilitated industrial control."}}
{"id": "2504.15679", "pdf": "https://arxiv.org/pdf/2504.15679", "abs": "https://arxiv.org/abs/2504.15679", "authors": ["Brandon Panos", "Ivan Milic"], "title": "Policy-Based Radiative Transfer: Solving the $2$-Level Atom Non-LTE Problem using Soft Actor-Critic Reinforcement Learning", "categories": ["astro-ph.SR", "cs.LG"], "comment": null, "summary": "We present a novel reinforcement learning (RL) approach for solving the\nclassical 2-level atom non-LTE radiative transfer problem by framing it as a\ncontrol task in which an RL agent learns a depth-dependent source function\n$S(\\tau)$ that self-consistently satisfies the equation of statistical\nequilibrium (SE). The agent's policy is optimized entirely via reward-based\ninteractions with a radiative transfer engine, without explicit knowledge of\nthe ground truth. This method bypasses the need for constructing approximate\nlambda operators ($\\Lambda^*$) common in accelerated iterative schemes.\nAdditionally, it requires no extensive precomputed labeled datasets to extract\na supervisory signal, and avoids backpropagating gradients through the complex\nRT solver itself. Finally, we show through experiment that a simple feedforward\nneural network trained greedily cannot solve for SE, possibly due to the moving\ntarget nature of the problem. Our $\\Lambda^*-\\text{Free}$ method offers\npotential advantages for complex scenarios (e.g., atmospheres with enhanced\nvelocity fields, multi-dimensional geometries, or complex microphysics) where\n$\\Lambda^*$ construction or solver differentiability is challenging.\nAdditionally, the agent can be incentivized to find more efficient policies by\nmanipulating the discount factor, leading to a reprioritization of immediate\nrewards. If demonstrated to generalize past its training data, this RL\nframework could serve as an alternative or accelerated formalism to achieve SE.\nTo the best of our knowledge, this study represents the first application of\nreinforcement learning in solar physics that directly solves for a fundamental\nphysical constraint.", "AI": {"tldr": "A reinforcement learning (RL) approach solves the 2-level atom non-LTE radiative transfer problem by learning a depth-dependent source function without needing ground truth or lambda operators.", "motivation": "The study aims to bypass traditional challenges like constructing lambda operators and needing precomputed datasets, offering a solution for complex scenarios in radiative transfer.", "method": "An RL agent learns a source function via reward-based interactions with a radiative transfer engine, avoiding backpropagation through the solver.", "result": "The method successfully solves the problem without lambda operators, and experiments show simpler neural networks fail due to the problem's moving target nature.", "conclusion": "The RL framework shows promise for complex scenarios and could serve as an alternative to traditional methods for achieving statistical equilibrium."}}
{"id": "2407.20090", "pdf": "https://arxiv.org/pdf/2407.20090", "abs": "https://arxiv.org/abs/2407.20090", "authors": ["Jinmiao Zhao", "Zelin Shi", "Chuang Yu", "Yunpeng Liu", "Yimian Dai"], "title": "Towards Robust Infrared Small Target Detection: A Feature-Enhanced and Sensitivity-Tunable Framework", "categories": ["cs.CV"], "comment": null, "summary": "Recently, single-frame infrared small target (SIRST) detection technology has\nattracted wide-spread attention. However, due to the intrinsic feature scarcity\nin infrared small targets, precise segmentation of small targets from complex\nbackgrounds remains a significant challenge. Different from most existing deep\nlearning-based methods that focus on improving network architectures, we\npropose a feature-enhanced and sensitivity-tunable (FEST) framework, which is\ncompatible with existing SIRST detection networks and further enhances their\ndetection performance. The FEST framework improves the model's robustness from\ntwo aspects: feature enhancement and target confidence regulation. For feature\nenhancement, on the one hand, we adopt a multi-scale fusion strategy, which can\neffectively improve the model's perception and adaptability to multi-scale\nfeatures of multi-size targets. On the other hand, we construct an edge\nenhancement difficulty mining (EEDM) loss based on the analysis of the task\ncharacteristics, which helps guide the network to continuously focus on\nchallenging target regions and edge features during training. For target\nconfidence regulation, we design an adjustable sensitivity (AS) strategy for\nnetwork post-processing. This strategy not only enhances the adaptability of\nthe network in complex scenarios, but also significantly improves the detection\nrate of infrared small targets while maintaining segmentation accuracy.\nExtensive experimental results show that our FEST framework can significantly\nenhance the performance of existing SIRST detection networks. Notably, the\nmulti-scale direction-aware network (MSDA-Net) equipped with the FEST framework\nwon the first prize in the PRCV 2024 wide-area infrared small target detection\ncompetition.", "AI": {"tldr": "The paper introduces a feature-enhanced and sensitivity-tunable (FEST) framework to improve infrared small target detection by enhancing features and regulating target confidence, outperforming existing methods.", "motivation": "Precise segmentation of infrared small targets is challenging due to feature scarcity. The FEST framework aims to enhance detection performance without altering network architectures.", "method": "The FEST framework uses multi-scale fusion and edge enhancement difficulty mining (EEDM) loss for feature enhancement, and an adjustable sensitivity (AS) strategy for target confidence regulation.", "result": "The framework significantly improves detection performance, with MSDA-Net (equipped with FEST) winning first prize in the PRCV 2024 competition.", "conclusion": "The FEST framework effectively enhances existing SIRST detection networks, offering robust performance in complex scenarios."}}
{"id": "2405.18471", "pdf": "https://arxiv.org/pdf/2405.18471", "abs": "https://arxiv.org/abs/2405.18471", "authors": ["Shehu AbdusSalam", "Steve Abel", "Miguel Crispim Romao"], "title": "Symbolic Regression for Beyond the Standard Model Physics", "categories": ["hep-ph", "cs.AI", "cs.LG", "hep-th", "physics.comp-ph"], "comment": "Version accepted for publication in PRD. 8 pages, 10 figures. For\n  associated code and symbolic expressions see\n  https://gitlab.com/miguel.romao/symbolic-regression-bsm", "summary": "We propose symbolic regression as a powerful tool for studying Beyond the\nStandard Model physics. As a benchmark model, we consider the so-called\nConstrained Minimal Supersymmetric Standard Model, which has a four-dimensional\nparameter space defined at the GUT scale. We provide a set of analytical\nexpressions that reproduce three low-energy observables of interest in terms of\nthe parameters of the theory: the Higgs mass, the contribution to the anomalous\nmagnetic moment of the muon, and the cold dark matter relic density. To\ndemonstrate the power of the approach, we employ the symbolic expressions in a\nglobal fits analysis to derive the posterior probability densities of the\nparameters, which are obtained extremely rapidly in comparison with\nconventional methods.", "AI": {"tldr": "Symbolic regression is used to study Beyond the Standard Model physics, providing analytical expressions for low-energy observables and enabling rapid parameter estimation.", "motivation": "To explore Beyond the Standard Model physics efficiently, using the Constrained Minimal Supersymmetric Standard Model as a benchmark.", "method": "Symbolic regression is applied to derive analytical expressions for Higgs mass, muon's anomalous magnetic moment, and dark matter relic density. These expressions are used in global fits for parameter estimation.", "result": "The method yields rapid posterior probability densities for parameters, outperforming conventional approaches.", "conclusion": "Symbolic regression is a powerful tool for studying Beyond the Standard Model physics, offering speed and analytical insights."}}
{"id": "2504.15691", "pdf": "https://arxiv.org/pdf/2504.15691", "abs": "https://arxiv.org/abs/2504.15691", "authors": ["Mingliang Ma Abolfazl Safikhani"], "title": "Transfer Learning for High-dimensional Reduced Rank Time Series Models", "categories": ["stat.ML", "cs.LG"], "comment": "29 pages accepted by AISTATS2025", "summary": "The objective of transfer learning is to enhance estimation and inference in\na target data by leveraging knowledge gained from additional sources. Recent\nstudies have explored transfer learning for independent observations in\ncomplex, high-dimensional models assuming sparsity, yet research on time series\nmodels remains limited. Our focus is on transfer learning for sequences of\nobservations with temporal dependencies and a more intricate model parameter\nstructure. Specifically, we investigate the vector autoregressive model (VAR),\na widely recognized model for time series data, where the transition matrix can\nbe deconstructed into a combination of a sparse matrix and a low-rank one. We\npropose a new transfer learning algorithm tailored for estimating\nhigh-dimensional VAR models characterized by low-rank and sparse structures.\nAdditionally, we present a novel approach for selecting informative\nobservations from auxiliary datasets. Theoretical guarantees are established,\nencompassing model parameter consistency, informative set selection, and the\nasymptotic distribution of estimators under mild conditions. The latter\nfacilitates the construction of entry-wise confidence intervals for model\nparameters. Finally, we demonstrate the empirical efficacy of our methodologies\nthrough both simulated and real-world datasets.", "AI": {"tldr": "The paper introduces a transfer learning algorithm for high-dimensional VAR models with low-rank and sparse structures, including a method for selecting informative observations from auxiliary datasets, supported by theoretical guarantees and empirical validation.", "motivation": "To enhance estimation and inference in target time series data by leveraging knowledge from additional sources, addressing gaps in transfer learning for temporally dependent observations.", "method": "Proposes a transfer learning algorithm for VAR models with low-rank and sparse transition matrices, along with a novel approach for selecting informative observations from auxiliary datasets.", "result": "Theoretical guarantees include parameter consistency, informative set selection, and asymptotic distribution of estimators, validated by simulations and real-world data.", "conclusion": "The proposed method effectively improves estimation in high-dimensional VAR models, with practical utility demonstrated through empirical results."}}
{"id": "2408.08645", "pdf": "https://arxiv.org/pdf/2408.08645", "abs": "https://arxiv.org/abs/2408.08645", "authors": ["Kai Li", "Yupeng Deng", "Jingbo Chen", "Yu Meng", "Zhihao Xi", "Junxian Ma", "Chenhao Wang", "Maolin Wang", "Xiangyu Zhao"], "title": "PolyFootNet: Extracting Polygonal Building Footprints in Off-Nadir Remote Sensing Images", "categories": ["cs.CV"], "comment": null, "summary": "Extracting polygonal building footprints from off-nadir imagery is crucial\nfor diverse applications. Current deep-learning-based extraction approaches\npredominantly rely on semantic segmentation paradigms and post-processing\nalgorithms, limiting their boundary precision and applicability. However,\nexisting polygonal extraction methodologies are inherently designed for\nnear-nadir imagery and fail under the geometric complexities introduced by\noff-nadir viewing angles. To address these challenges, this paper introduces\nPolygonal Footprint Network (PolyFootNet), a novel deep-learning framework that\ndirectly outputs polygonal building footprints without requiring external\npost-processing steps. PolyFootNet employs a High-Quality Mask Prompter to\ngenerate precise roof masks, which guide polygonal vertex extraction in a\nunified model pipeline. A key contribution of PolyFootNet is introducing the\nSelf Offset Attention mechanism, grounded in Nadaraya-Watson regression, to\neffectively mitigate the accuracy discrepancy observed between low-rise and\nhigh-rise buildings. This approach allows low-rise building predictions to\nleverage angular corrections learned from high-rise building offsets,\nsignificantly enhancing overall extraction accuracy. Additionally, motivated by\nthe inherent ambiguity of building footprint extraction tasks, we\nsystematically investigate alternative extraction paradigms and demonstrate\nthat a combined approach of building masks and offsets achieves superior\npolygonal footprint results. Extensive experiments validate PolyFootNet's\neffectiveness, illustrating its promising potential as a robust, generalizable,\nand precise polygonal building footprint extraction method from challenging\noff-nadir imagery. To facilitate further research, we will release pre-trained\nweights of our offset prediction module at\nhttps://github.com/likaiucas/PolyFootNet.", "AI": {"tldr": "PolyFootNet is a deep-learning framework for extracting polygonal building footprints from off-nadir imagery without post-processing, using a High-Quality Mask Prompter and Self Offset Attention for improved accuracy.", "motivation": "Current methods for polygonal building extraction are limited by boundary precision and fail under off-nadir viewing angles, necessitating a more robust solution.", "method": "PolyFootNet combines a High-Quality Mask Prompter for precise roof masks and a Self Offset Attention mechanism (based on Nadaraya-Watson regression) to correct angular discrepancies, unifying mask and offset predictions.", "result": "Extensive experiments show PolyFootNet outperforms existing methods, achieving higher accuracy and generalizability for off-nadir imagery.", "conclusion": "PolyFootNet offers a precise, robust, and generalizable solution for polygonal building footprint extraction from off-nadir imagery, with potential for further research via released pre-trained weights."}}
{"id": "2407.10834", "pdf": "https://arxiv.org/pdf/2407.10834", "abs": "https://arxiv.org/abs/2407.10834", "authors": ["Quang H. Nguyen", "Thinh Dao", "Duy C. Hoang", "Juliette Decugis", "Saurav Manchanda", "Nitesh V. Chawla", "Khoa D. Doan"], "title": "MetaLLM: A High-performant and Cost-efficient Dynamic Framework for Wrapping LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The rapid progress in machine learning (ML) has brought forth many large\nlanguage models (LLMs) that excel in various tasks and areas. These LLMs come\nwith different abilities and costs in terms of computation or pricing. Since\nthe demand for each query can vary, e.g., because of the queried domain or its\ncomplexity, defaulting to one LLM in an application is not usually the best\nchoice, whether it is the biggest, priciest, or even the one with the best\naverage test performance. Consequently, picking the right LLM that is both\naccurate and cost-effective for an application is necessary yet remains a\nchallenge. In this paper, we introduce MetaLLM, a framework that dynamically\nand intelligently routes each query to the optimal LLM (among several available\nLLMs) for classification and multi-choice question-answering tasks, achieving\nsignificantly improved accuracy and cost-effectiveness. By framing the\nselection problem as a multi-armed bandit, MetaLLM balances prediction accuracy\nand cost efficiency under uncertainty. Our experiments, conducted on popular\nLLM platforms such as OpenAI and Together AI, as well as open-source LLM,\nshowcase MetaLLM's efficacy in real-world scenarios, laying the groundwork for\nfuture extensions.", "AI": {"tldr": "MetaLLM is a framework that dynamically routes queries to the optimal LLM for accuracy and cost-effectiveness, using a multi-armed bandit approach.", "motivation": "Choosing the right LLM for each query is challenging due to varying demands and costs, necessitating a dynamic solution.", "method": "MetaLLM frames LLM selection as a multi-armed bandit problem, balancing accuracy and cost under uncertainty.", "result": "Experiments on platforms like OpenAI and Together AI demonstrate MetaLLM's improved accuracy and cost-effectiveness.", "conclusion": "MetaLLM provides a practical solution for dynamic LLM selection, with potential for future extensions."}}
{"id": "2504.15722", "pdf": "https://arxiv.org/pdf/2504.15722", "abs": "https://arxiv.org/abs/2504.15722", "authors": ["Zhe Huang", "Simone Rossi", "Rui Yuan", "Thomas Hannagan"], "title": "From predictions to confidence intervals: an empirical study of conformal prediction methods for in-context learning", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Transformers have become a standard architecture in machine learning,\ndemonstrating strong in-context learning (ICL) abilities that allow them to\nlearn from the prompt at inference time. However, uncertainty quantification\nfor ICL remains an open challenge, particularly in noisy regression tasks. This\npaper investigates whether ICL can be leveraged for distribution-free\nuncertainty estimation, proposing a method based on conformal prediction to\nconstruct prediction intervals with guaranteed coverage. While traditional\nconformal methods are computationally expensive due to repeated model fitting,\nwe exploit ICL to efficiently generate confidence intervals in a single forward\npass. Our empirical analysis compares this approach against ridge\nregression-based conformal methods, showing that conformal prediction with\nin-context learning (CP with ICL) achieves robust and scalable uncertainty\nestimates. Additionally, we evaluate its performance under distribution shifts\nand establish scaling laws to guide model training. These findings bridge ICL\nand conformal prediction, providing a theoretically grounded and new framework\nfor uncertainty quantification in transformer-based models.", "AI": {"tldr": "The paper introduces a method using conformal prediction with in-context learning (ICL) for uncertainty estimation in transformers, achieving efficient and robust confidence intervals in a single forward pass.", "motivation": "Uncertainty quantification for ICL in noisy regression tasks is an open challenge, prompting the need for a distribution-free method.", "method": "Leverages conformal prediction with ICL to construct prediction intervals with guaranteed coverage, avoiding repeated model fitting.", "result": "CP with ICL outperforms ridge regression-based methods, providing scalable and robust uncertainty estimates, even under distribution shifts.", "conclusion": "The work bridges ICL and conformal prediction, offering a theoretically grounded framework for uncertainty quantification in transformers."}}
{"id": "2409.03901", "pdf": "https://arxiv.org/pdf/2409.03901", "abs": "https://arxiv.org/abs/2409.03901", "authors": ["Thanh-Dung Le", "Vu Nguyen Ha", "Ti Ti Nguyen", "Geoffrey Eappen", "Prabhu Thiruvasagam", "Hong-fu Chou", "Duc-Dung Tran", "Hung Nguyen-Kha", "Luis M. Garces-Socarras", "Jorge L. Gonzalez-Rios", "Juan Carlos Merlano-Duncan", "Symeon Chatzinotas"], "title": "Onboard Satellite Image Classification for Earth Observation: A Comparative Study of ViT Models", "categories": ["cs.CV", "eess.SP"], "comment": null, "summary": "This study focuses on identifying the most effective pre-trained model for\nland use classification in onboard satellite processing, emphasizing achieving\nhigh accuracy, computational efficiency, and robustness against noisy data\nconditions commonly encountered during satellite-based inference. Through\nextensive experimentation, we compare the performance of traditional CNN-based,\nResNet-based, and various pre-trained vision Transformer models. Our findings\ndemonstrate that pre-trained Vision Transformer (ViT) models, particularly\nMobileViTV2 and EfficientViT-M2, outperform models trained from scratch in\nterms of accuracy and efficiency. These models achieve high performance with\nreduced computational requirements and exhibit greater resilience during\ninference under noisy conditions. While MobileViTV2 has excelled on clean\nvalidation data, EfficientViT-M2 has proved more robust when handling noise,\nmaking it the most suitable model for onboard satellite EO tasks. Our\nexperimental results demonstrate that EfficientViT-M2 is the optimal choice for\nreliable and efficient RS-IC in satellite operations, achieving 98.76 % of\naccuracy, precision, and recall. Precisely, EfficientViT-M2 delivers the\nhighest performance across all metrics, excels in training efficiency (1,000s)\nand inference time (10s), and demonstrates greater robustness (overall\nrobustness score of 0.79). Consequently, EfficientViT-M2 consumes 63.93 % less\npower than MobileViTV2 (79.23 W) and 73.26 % less power than SwinTransformer\n(108.90 W). This highlights its significant advantage in energy efficiency.", "AI": {"tldr": "Pre-trained Vision Transformer models, especially EfficientViT-M2, outperform others in land use classification for satellite processing, offering high accuracy, efficiency, and robustness under noisy conditions.", "motivation": "To identify the most effective pre-trained model for land use classification in onboard satellite processing, focusing on accuracy, computational efficiency, and robustness against noisy data.", "method": "Comparison of traditional CNN-based, ResNet-based, and pre-trained vision Transformer models through extensive experimentation.", "result": "EfficientViT-M2 achieves 98.76% accuracy, excels in training and inference efficiency, and is highly robust (score 0.79). It also consumes significantly less power (63.93% less than MobileViTV2).", "conclusion": "EfficientViT-M2 is the optimal choice for reliable and efficient land use classification in satellite operations due to its superior performance, efficiency, and energy savings."}}
{"id": "2409.07200", "pdf": "https://arxiv.org/pdf/2409.07200", "abs": "https://arxiv.org/abs/2409.07200", "authors": ["Rongfeng Lu", "Hangyu Chen", "Zunjie Zhu", "Yuhang Qin", "Ming Lu", "Le Zhang", "Chenggang Yan", "Anke Xue"], "title": "ThermalGaussian: Thermal 3D Gaussian Splatting", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 7 figures", "summary": "Thermography is especially valuable for the military and other users of\nsurveillance cameras. Some recent methods based on Neural Radiance Fields\n(NeRF) are proposed to reconstruct the thermal scenes in 3D from a set of\nthermal and RGB images. However, unlike NeRF, 3D Gaussian splatting (3DGS)\nprevails due to its rapid training and real-time rendering. In this work, we\npropose ThermalGaussian, the first thermal 3DGS approach capable of rendering\nhigh-quality images in RGB and thermal modalities. We first calibrate the RGB\ncamera and the thermal camera to ensure that both modalities are accurately\naligned. Subsequently, we use the registered images to learn the multimodal 3D\nGaussians. To prevent the overfitting of any single modality, we introduce\nseveral multimodal regularization constraints. We also develop smoothing\nconstraints tailored to the physical characteristics of the thermal modality.\nBesides, we contribute a real-world dataset named RGBT-Scenes, captured by a\nhand-hold thermal-infrared camera, facilitating future research on thermal\nscene reconstruction. We conduct comprehensive experiments to show that\nThermalGaussian achieves photorealistic rendering of thermal images and\nimproves the rendering quality of RGB images. With the proposed multimodal\nregularization constraints, we also reduced the model's storage cost by 90%.\nOur project page is at https://thermalgaussian.github.io/.", "AI": {"tldr": "ThermalGaussian introduces a 3D Gaussian splatting (3DGS) approach for high-quality thermal and RGB image rendering, addressing alignment and overfitting with multimodal constraints and a new dataset.", "motivation": "Existing NeRF-based methods for thermal scene reconstruction are slow, while 3DGS offers faster training and real-time rendering. This work aims to leverage 3DGS for thermal imaging.", "method": "The method involves calibrating RGB and thermal cameras, learning multimodal 3D Gaussians, and applying regularization and smoothing constraints to prevent overfitting and align with thermal physics.", "result": "ThermalGaussian achieves photorealistic thermal and improved RGB rendering, reduces storage costs by 90%, and introduces the RGBT-Scenes dataset.", "conclusion": "ThermalGaussian successfully adapts 3DGS for thermal imaging, offering efficient, high-quality multimodal rendering and a valuable dataset for future research."}}
{"id": "2504.15753", "pdf": "https://arxiv.org/pdf/2504.15753", "abs": "https://arxiv.org/abs/2504.15753", "authors": ["Alexis M. H. Teter", "Wenqing Wang", "Sachin Shivakumar", "Abhishek Halder"], "title": "Markov Kernels, Distances and Optimal Control: A Parable of Linear Quadratic Non-Gaussian Distribution Steering", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY", "math.PR", "math.ST", "stat.TH"], "comment": null, "summary": "For a controllable linear time-varying (LTV) pair\n$(\\boldsymbol{A}_t,\\boldsymbol{B}_t)$ and $\\boldsymbol{Q}_{t}$ positive\nsemidefinite, we derive the Markov kernel for the It\\^{o} diffusion\n${\\mathrm{d}}\\boldsymbol{x}_{t}=\\boldsymbol{A}_{t}\\boldsymbol{x}_t {\\mathrm{d}}\nt + \\sqrt{2}\\boldsymbol{B}_{t}{\\mathrm{d}}\\boldsymbol{w}_{t}$ with an\naccompanying killing of probability mass at rate\n$\\frac{1}{2}\\boldsymbol{x}^{\\top}\\boldsymbol{Q}_{t}\\boldsymbol{x}$. This Markov\nkernel is the Green's function for an associated linear\nreaction-advection-diffusion partial differential equation. Our result\ngeneralizes the recently derived kernel for the special case\n$\\left(\\boldsymbol{A}_t,\\boldsymbol{B}_t\\right)=\\left(\\boldsymbol{0},\\boldsymbol{I}\\right)$,\nand depends on the solution of an associated Riccati matrix ODE. A consequence\nof this result is that the linear quadratic non-Gaussian Schr\\\"{o}dinger bridge\nis exactly solvable. This means that the problem of steering a controlled LTV\ndiffusion from a given non-Gaussian distribution to another over a fixed\ndeadline while minimizing an expected quadratic cost can be solved using\ndynamic Sinkhorn recursions performed with the derived kernel. Our derivation\nfor the\n$\\left(\\boldsymbol{A}_t,\\boldsymbol{B}_t,\\boldsymbol{Q}_t\\right)$-parametrized\nkernel pursues a new idea that relies on finding a state-time dependent\ndistance-like functional given by the solution of a deterministic optimal\ncontrol problem. This technique breaks away from existing methods, such as\ngeneralizing Hermite polynomials or Weyl calculus, which have seen limited\nsuccess in the reaction-diffusion context. Our technique uncovers a new\nconnection between Markov kernels, distances, and optimal control. This\nconnection is of interest beyond its immediate application in solving the\nlinear quadratic Schr\\\"{o}dinger bridge problem.", "AI": {"tldr": "The paper derives a Markov kernel for a controlled linear time-varying diffusion process with killing probability, generalizing prior results and enabling exact solutions for the linear quadratic non-Gaussian Schr\u00f6dinger bridge problem.", "motivation": "The motivation is to generalize existing results for simpler cases and provide exact solutions for steering controlled diffusions between non-Gaussian distributions while minimizing quadratic costs.", "method": "The method involves solving a Riccati matrix ODE and using a state-time dependent distance-like functional derived from a deterministic optimal control problem.", "result": "The result is an exact solution for the Markov kernel, enabling dynamic Sinkhorn recursions to solve the Schr\u00f6dinger bridge problem.", "conclusion": "The paper establishes a novel connection between Markov kernels, distances, and optimal control, with broader implications beyond the immediate problem."}}
{"id": "2410.10783", "pdf": "https://arxiv.org/pdf/2410.10783", "abs": "https://arxiv.org/abs/2410.10783", "authors": ["Nimrod Shabtay", "Felipe Maia Polo", "Sivan Doveh", "Wei Lin", "M. Jehanzeb Mirza", "Leshem Chosen", "Mikhail Yurochkin", "Yuekai Sun", "Assaf Arbelle", "Leonid Karlinsky", "Raja Giryes"], "title": "LiveXiv -- A Multi-Modal Live Benchmark Based on Arxiv Papers Content", "categories": ["cs.CV"], "comment": null, "summary": "The large-scale training of multi-modal models on data scraped from the web\nhas shown outstanding utility in infusing these models with the required world\nknowledge to perform effectively on multiple downstream tasks. However, one\ndownside of scraping data from the web can be the potential sacrifice of the\nbenchmarks on which the abilities of these models are often evaluated. To\nsafeguard against test data contamination and to truly test the abilities of\nthese foundation models we propose LiveXiv: A scalable evolving live benchmark\nbased on scientific ArXiv papers. LiveXiv accesses domain-specific manuscripts\nat any given timestamp and proposes to automatically generate visual\nquestion-answer pairs (VQA). This is done without any human-in-the-loop, using\nthe multi-modal content in the manuscripts, like graphs, charts, and tables.\nMoreover, we introduce an efficient evaluation approach that estimates the\nperformance of all models on the evolving benchmark using evaluations of only a\nsubset of models. This significantly reduces the overall evaluation cost. We\nbenchmark multiple open and proprietary Large Multi-modal Models (LMMs) on the\nfirst version of our benchmark, showing its challenging nature and exposing the\nmodels true abilities, avoiding contamination. Lastly, in our commitment to\nhigh quality, we have collected and evaluated a manually verified subset. By\ncomparing its overall results to our automatic annotations, we have found that\nthe performance variance is indeed minimal (<2.5%). Our dataset is available\nonline on HuggingFace, and our code will be available here.", "AI": {"tldr": "LiveXiv is a scalable, evolving benchmark using ArXiv papers to generate VQA pairs automatically, avoiding test data contamination and reducing evaluation costs.", "motivation": "To address test data contamination in multi-modal models and provide a reliable benchmark for evaluating their true abilities.", "method": "LiveXiv generates VQA pairs from ArXiv papers' multi-modal content (graphs, charts, tables) without human intervention and introduces an efficient evaluation approach using subset evaluations.", "result": "Benchmarked LMMs show LiveXiv is challenging, exposing true model abilities with minimal performance variance (<2.5%) between automatic and manual annotations.", "conclusion": "LiveXiv offers a scalable, high-quality benchmark for evaluating multi-modal models, reducing contamination and evaluation costs."}}
{"id": "2410.05056", "pdf": "https://arxiv.org/pdf/2410.05056", "abs": "https://arxiv.org/abs/2410.05056", "authors": ["Attila Lovas"], "title": "Transition of $\u03b1$-mixing in Random Iterations with Applications in Queuing Theory", "categories": ["math.ST", "cs.AI", "math.PR", "stat.TH", "60K37, 60K25, 60J05, 60J20", "G.3; I.6.5; C.4"], "comment": "39 pages, 1 figure", "summary": "Nonlinear time series models with exogenous regressors are essential in\neconometrics, queuing theory, and machine learning, though their statistical\nanalysis remains incomplete. Key results, such as the law of large numbers and\nthe functional central limit theorem, are known for weakly dependent variables.\nWe demonstrate the transfer of mixing properties from the exogenous regressor\nto the response via coupling arguments. Additionally, we study Markov chains in\nrandom environments with drift and minorization conditions, even under\nnon-stationary environments with favorable mixing properties, and apply this\nframework to single-server queuing models.", "AI": {"tldr": "The paper explores nonlinear time series models with exogenous regressors, focusing on transferring mixing properties from regressors to responses and analyzing Markov chains in random environments.", "motivation": "To address the incomplete statistical analysis of nonlinear time series models with exogenous regressors in fields like econometrics and machine learning.", "method": "Uses coupling arguments to transfer mixing properties and studies Markov chains in random environments with drift and minorization conditions.", "result": "Demonstrates the transfer of mixing properties and applies the framework to single-server queuing models.", "conclusion": "The findings advance the understanding of weakly dependent variables and their applications in queuing theory and beyond."}}
{"id": "2504.15826", "pdf": "https://arxiv.org/pdf/2504.15826", "abs": "https://arxiv.org/abs/2504.15826", "authors": ["Xinru Mu", "Omar M. Saad", "Tariq Alkhalifah"], "title": "Full waveform inversion with CNN-based velocity representation extension", "categories": ["physics.geo-ph", "cs.LG"], "comment": "16 pages, 15 figures, Scientific paper", "summary": "Full waveform inversion (FWI) updates the velocity model by minimizing the\ndiscrepancy between observed and simulated data. However, discretization errors\nin numerical modeling and incomplete seismic data acquisition can introduce\nnoise, which propagates through the adjoint operator and affects the accuracy\nof the velocity gradient, thereby impacting the FWI inversion accuracy. To\nmitigate the influence of noise on the gradient, we employ a convolutional\nneural network (CNN) to refine the velocity model before performing the forward\nsimulation, aiming to reduce noise and provide a more accurate velocity update\ndirection. We use the same data misfit loss to update both the velocity and\nnetwork parameters, thereby forming a self-supervised learning procedure. We\npropose two implementation schemes, which differ in whether the velocity update\npasses through the CNN. In both methodologies, the velocity representation is\nextended (VRE) by using a neural network in addition to the grid-based\nvelocities. Thus, we refer to this general approach as VRE-FWI. Synthetic and\nreal data tests demonstrate that the proposed VRE-FWI achieves higher velocity\ninversion accuracy compared to traditional FWI, at a marginal additional\ncomputational cost of approximately 1%.", "AI": {"tldr": "VRE-FWI uses a CNN to refine velocity models in FWI, reducing noise and improving accuracy with minimal computational overhead.", "motivation": "Discretization errors and incomplete data in FWI introduce noise, degrading velocity gradient accuracy and inversion results.", "method": "A CNN refines the velocity model before forward simulation, with two schemes differing in CNN usage. VRE extends velocity representation.", "result": "VRE-FWI outperforms traditional FWI in accuracy, adding only ~1% computational cost.", "conclusion": "VRE-FWI effectively mitigates noise impact, enhancing FWI accuracy with negligible extra cost."}}
{"id": "2411.17820", "pdf": "https://arxiv.org/pdf/2411.17820", "abs": "https://arxiv.org/abs/2411.17820", "authors": ["Xinhao Liu", "Jintong Li", "Yicheng Jiang", "Niranjan Sujay", "Zhicheng Yang", "Juexiao Zhang", "John Abanes", "Jing Zhang", "Chen Feng"], "title": "CityWalker: Learning Embodied Urban Navigation from Web-Scale Videos", "categories": ["cs.CV", "cs.RO"], "comment": "Accepted to CVPR 2025", "summary": "Navigating dynamic urban environments presents significant challenges for\nembodied agents, requiring advanced spatial reasoning and adherence to\ncommon-sense norms. Despite progress, existing visual navigation methods\nstruggle in map-free or off-street settings, limiting the deployment of\nautonomous agents like last-mile delivery robots. To overcome these obstacles,\nwe propose a scalable, data-driven approach for human-like urban navigation by\ntraining agents on thousands of hours of in-the-wild city walking and driving\nvideos sourced from the web. We introduce a simple and scalable data processing\npipeline that extracts action supervision from these videos, enabling\nlarge-scale imitation learning without costly annotations. Our model learns\nsophisticated navigation policies to handle diverse challenges and critical\nscenarios. Experimental results show that training on large-scale, diverse\ndatasets significantly enhances navigation performance, surpassing current\nmethods. This work shows the potential of using abundant online video data to\ndevelop robust navigation policies for embodied agents in dynamic urban\nsettings. Project homepage is at https://ai4ce.github.io/CityWalker/.", "AI": {"tldr": "A scalable, data-driven approach for human-like urban navigation is proposed, using large-scale imitation learning from web-sourced city videos to enhance autonomous agent performance.", "motivation": "Existing visual navigation methods struggle in map-free or off-street settings, limiting autonomous agents like delivery robots.", "method": "A data processing pipeline extracts action supervision from city walking/driving videos for large-scale imitation learning without costly annotations.", "result": "Training on diverse datasets significantly improves navigation performance, surpassing current methods.", "conclusion": "Abundant online video data can develop robust navigation policies for embodied agents in dynamic urban environments."}}
{"id": "2410.05295", "pdf": "https://arxiv.org/pdf/2410.05295", "abs": "https://arxiv.org/abs/2410.05295", "authors": ["Xiaogeng Liu", "Peiran Li", "Edward Suh", "Yevgeniy Vorobeychik", "Zhuoqing Mao", "Somesh Jha", "Patrick McDaniel", "Huan Sun", "Bo Li", "Chaowei Xiao"], "title": "AutoDAN-Turbo: A Lifelong Agent for Strategy Self-Exploration to Jailbreak LLMs", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "ICLR 2025 Spotlight. Project Page:\n  https://autodans.github.io/AutoDAN-Turbo Code:\n  https://github.com/SaFoLab-WISC/AutoDAN-Turbo", "summary": "In this paper, we propose AutoDAN-Turbo, a black-box jailbreak method that\ncan automatically discover as many jailbreak strategies as possible from\nscratch, without any human intervention or predefined scopes (e.g., specified\ncandidate strategies), and use them for red-teaming. As a result, AutoDAN-Turbo\ncan significantly outperform baseline methods, achieving a 74.3% higher average\nattack success rate on public benchmarks. Notably, AutoDAN-Turbo achieves an\n88.5 attack success rate on GPT-4-1106-turbo. In addition, AutoDAN-Turbo is a\nunified framework that can incorporate existing human-designed jailbreak\nstrategies in a plug-and-play manner. By integrating human-designed strategies,\nAutoDAN-Turbo can even achieve a higher attack success rate of 93.4 on\nGPT-4-1106-turbo.", "AI": {"tldr": "AutoDAN-Turbo is a black-box jailbreak method that autonomously discovers and applies jailbreak strategies, outperforming baselines with a 74.3% higher attack success rate and achieving up to 93.4% on GPT-4-1106-turbo.", "motivation": "To automate jailbreak strategy discovery without human intervention, enhancing red-teaming effectiveness.", "method": "Proposes AutoDAN-Turbo, a framework that autonomously generates and integrates jailbreak strategies, including human-designed ones.", "result": "Achieves 74.3% higher attack success rate than baselines, with 88.5% on GPT-4-1106-turbo and 93.4% when integrating human strategies.", "conclusion": "AutoDAN-Turbo is a powerful, unified framework for automated jailbreak strategy discovery and application."}}
{"id": "2504.15933", "pdf": "https://arxiv.org/pdf/2504.15933", "abs": "https://arxiv.org/abs/2504.15933", "authors": ["Anh Truong", "Ahmed H. Mahmoud", "Mina Konakovi\u0107 Lukovi\u0107", "Justin Solomon"], "title": "Low-Rank Adaptation of Neural Fields", "categories": ["cs.GR", "cs.LG"], "comment": null, "summary": "Processing visual data often involves small adjustments or sequences of\nchanges, such as in image filtering, surface smoothing, and video storage.\nWhile established graphics techniques like normal mapping and video compression\nexploit redundancy to encode such small changes efficiently, the problem of\nencoding small changes to neural fields (NF) -- neural network\nparameterizations of visual or physical functions -- has received less\nattention.\n  We propose a parameter-efficient strategy for updating neural fields using\nlow-rank adaptations (LoRA). LoRA, a method from the parameter-efficient\nfine-tuning LLM community, encodes small updates to pre-trained models with\nminimal computational overhead. We adapt LoRA to instance-specific neural\nfields, avoiding the need for large pre-trained models yielding a pipeline\nsuitable for low-compute hardware.\n  We validate our approach with experiments in image filtering, video\ncompression, and geometry editing, demonstrating its effectiveness and\nversatility for representing neural field updates.", "AI": {"tldr": "A parameter-efficient method using low-rank adaptations (LoRA) is proposed for updating neural fields, validated in tasks like image filtering and video compression.", "motivation": "Existing techniques efficiently encode small changes in visual data, but similar methods for neural fields (NF) are understudied.", "method": "Adapts LoRA from LLM fine-tuning to neural fields, enabling efficient updates without large pre-trained models.", "result": "Effective and versatile performance in image filtering, video compression, and geometry editing.", "conclusion": "LoRA-based updates offer a lightweight, efficient solution for modifying neural fields, suitable for low-compute hardware."}}
{"id": "2411.18473", "pdf": "https://arxiv.org/pdf/2411.18473", "abs": "https://arxiv.org/abs/2411.18473", "authors": ["Lei Liu", "Zhenghao Chen", "Wei Jiang", "Wei Wang", "Dong Xu"], "title": "HEMGS: A Hybrid Entropy Model for 3D Gaussian Splatting Data Compression", "categories": ["cs.CV"], "comment": null, "summary": "In this work, we propose a novel compression framework for 3D Gaussian\nSplatting (3DGS) data. Building on anchor-based 3DGS methodologies, our\napproach compresses all attributes within each anchor by introducing a novel\nHybrid Entropy Model for 3D Gaussian Splatting (HEMGS) to achieve hybrid\nlossy-lossless compression. It consists of three main components: a\nvariable-rate predictor, a hyperprior network, and an autoregressive network.\nFirst, unlike previous methods that adopt multiple models to achieve multi-rate\nlossy compression, thereby increasing training overhead, our variable-rate\npredictor enables variable-rate compression with a single model and a\nhyperparameter $\\lambda$ by producing a learned Quantization Step feature for\nversatile lossy compression. Second, to improve lossless compression, the\nhyperprior network captures both scene-agnostic and scene-specific features to\ngenerate a prior feature, while the autoregressive network employs an adaptive\ncontext selection algorithm with flexible receptive fields to produce a\ncontextual feature. By integrating these two features, HEMGS can accurately\nestimate the distribution of the current coding element within each attribute,\nenabling improved entropy coding and reduced storage. We integrate HEMGS into a\ncompression framework, and experimental results on four benchmarks indicate\nthat HEMGS achieves about a 40% average reduction in size while maintaining\nrendering quality over baseline methods and achieving state-of-the-art\ncompression results.", "AI": {"tldr": "A novel compression framework for 3D Gaussian Splatting (3DGS) data using a Hybrid Entropy Model (HEMGS) achieves hybrid lossy-lossless compression, reducing size by 40% while maintaining quality.", "motivation": "To improve compression efficiency for 3DGS data by combining lossy and lossless techniques in a single framework, reducing training overhead and storage.", "method": "Introduces HEMGS with a variable-rate predictor, hyperprior network, and autoregressive network for hybrid compression. The predictor enables variable-rate compression with one model, while the networks enhance entropy coding.", "result": "HEMGS achieves a 40% average size reduction over baselines while preserving rendering quality, outperforming existing methods.", "conclusion": "The proposed HEMGS framework effectively compresses 3DGS data with hybrid lossy-lossless techniques, offering superior performance and efficiency."}}
{"id": "2410.16739", "pdf": "https://arxiv.org/pdf/2410.16739", "abs": "https://arxiv.org/abs/2410.16739", "authors": ["Yanjun Chen", "Xinming Zhang", "Xianghui Wang", "Zhiqiang Xu", "Xiaoyu Shen", "Wei Zhang"], "title": "Rethinking Soft Actor-Critic in High-Dimensional Action Spaces: The Cost of Ignoring Distribution Shift", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Soft Actor-Critic algorithm is widely recognized for its robust performance\nacross a range of deep reinforcement learning tasks, where it leverages the\ntanh transformation to constrain actions within bounded limits. However, this\ntransformation induces a distribution shift, distorting the original Gaussian\naction distribution and potentially leading the policy to select suboptimal\nactions, particularly in high-dimensional action spaces. In this paper, we\nconduct a comprehensive theoretical and empirical analysis of this distribution\nshift, deriving the precise probability density function (PDF) for actions\nfollowing the tanh transformation to clarify the misalignment introduced\nbetween the transformed distribution's mode and the intended action output. We\nsubstantiate these theoretical insights through extensive experiments on\nhigh-dimensional tasks within the HumanoidBench benchmark. Our findings\nindicate that accounting for this distribution shift substantially enhances\nSAC's performance, resulting in notable improvements in cumulative rewards,\nsample efficiency, and reliability across tasks. These results underscore a\ncritical consideration for SAC and similar algorithms: addressing\ntransformation-induced distribution shifts is essential to optimizing policy\neffectiveness in high-dimensional deep reinforcement learning environments,\nthereby expanding the robustness and applicability of SAC in complex control\ntasks.", "AI": {"tldr": "The paper analyzes the distribution shift caused by the tanh transformation in Soft Actor-Critic (SAC), showing it leads to suboptimal actions. Correcting this shift improves SAC's performance.", "motivation": "The tanh transformation in SAC distorts the action distribution, causing misalignment and suboptimal actions, especially in high-dimensional spaces.", "method": "Theoretical derivation of the tanh-transformed action's PDF and empirical validation on HumanoidBench tasks.", "result": "Accounting for the distribution shift enhances SAC's performance, improving rewards, efficiency, and reliability.", "conclusion": "Addressing transformation-induced shifts is crucial for optimizing SAC and similar algorithms in high-dimensional tasks."}}
{"id": "2504.15942", "pdf": "https://arxiv.org/pdf/2504.15942", "abs": "https://arxiv.org/abs/2504.15942", "authors": ["Erik Imgrund", "Thorsten Eisenhofer", "Konrad Rieck"], "title": "Adversarial Observations in Weather Forecasting", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "AI-based systems, such as Google's GenCast, have recently redefined the state\nof the art in weather forecasting, offering more accurate and timely\npredictions of both everyday weather and extreme events. While these systems\nare on the verge of replacing traditional meteorological methods, they also\nintroduce new vulnerabilities into the forecasting process. In this paper, we\ninvestigate this threat and present a novel attack on autoregressive diffusion\nmodels, such as those used in GenCast, capable of manipulating weather\nforecasts and fabricating extreme events, including hurricanes, heat waves, and\nintense rainfall. The attack introduces subtle perturbations into weather\nobservations that are statistically indistinguishable from natural noise and\nchange less than 0.1% of the measurements - comparable to tampering with data\nfrom a single meteorological satellite. As modern forecasting integrates data\nfrom nearly a hundred satellites and many other sources operated by different\ncountries, our findings highlight a critical security risk with the potential\nto cause large-scale disruptions and undermine public trust in weather\nprediction.", "AI": {"tldr": "AI weather forecasting systems like GenCast are vulnerable to subtle attacks that manipulate forecasts and fabricate extreme events, posing significant security risks.", "motivation": "To investigate the vulnerabilities in AI-based weather forecasting systems, which could undermine public trust and cause large-scale disruptions.", "method": "A novel attack on autoregressive diffusion models (e.g., GenCast) introduces subtle perturbations into weather observations, altering less than 0.1% of measurements.", "result": "The attack successfully manipulates forecasts and fabricates extreme weather events, demonstrating a critical security flaw.", "conclusion": "The findings highlight the urgent need for securing AI-based forecasting systems to prevent large-scale disruptions and maintain public trust."}}
{"id": "2412.02856", "pdf": "https://arxiv.org/pdf/2412.02856", "abs": "https://arxiv.org/abs/2412.02856", "authors": ["Piotr Teterwak", "Kuniaki Saito", "Theodoros Tsiligkaridis", "Bryan A. Plummer", "Kate Saenko"], "title": "Is Large-Scale Pretraining the Secret to Good Domain Generalization?", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at ICLR 2025", "summary": "Multi-Source Domain Generalization (DG) is the task of training on multiple\nsource domains and achieving high classification performance on unseen target\ndomains. Recent methods combine robust features from web-scale pretrained\nbackbones with new features learned from source data, and this has dramatically\nimproved benchmark results. However, it remains unclear if DG finetuning\nmethods are becoming better over time, or if improved benchmark performance is\nsimply an artifact of stronger pre-training. Prior studies have shown that\nperceptual similarity to pre-training data correlates with zero-shot\nperformance, but we find the effect limited in the DG setting. Instead, we\nposit that having perceptually similar data in pretraining is not enough; and\nthat it is how well these data were learned that determines performance. This\nleads us to introduce the Alignment Hypothesis, which states that the final DG\nperformance will be high if and only if alignment of image and class label text\nembeddings is high. Our experiments confirm the Alignment Hypothesis is true,\nand we use it as an analysis tool of existing DG methods evaluated on DomainBed\ndatasets by splitting evaluation data into In-pretraining (IP) and\nOut-of-pretraining (OOP). We show that all evaluated DG methods struggle on\nDomainBed-OOP, while recent methods excel on DomainBed-IP. Put together, our\nfindings highlight the need for DG methods which can generalize beyond\npretraining alignment.", "AI": {"tldr": "The paper investigates Multi-Source Domain Generalization (DG), questioning if performance gains are due to better methods or stronger pretraining. It introduces the Alignment Hypothesis, linking DG performance to the alignment of image and text embeddings, and finds current methods struggle with out-of-pretraining data.", "motivation": "To determine if DG finetuning methods are genuinely improving or if benchmark gains are just due to stronger pretraining, and to understand the role of pretraining data alignment in DG performance.", "method": "Proposes the Alignment Hypothesis, tests it by evaluating DG methods on DomainBed datasets split into In-pretraining (IP) and Out-of-pretraining (OOP) data.", "result": "Confirms the Alignment Hypothesis, showing DG methods perform well on IP data but struggle with OOP data, indicating limitations in current approaches.", "conclusion": "Highlights the need for DG methods that generalize beyond pretraining alignment to achieve true domain generalization."}}
{"id": "2411.07007", "pdf": "https://arxiv.org/pdf/2411.07007", "abs": "https://arxiv.org/abs/2411.07007", "authors": ["Arnav Kumar Jain", "Harley Wiltzer", "Jesse Farebrother", "Irina Rish", "Glen Berseth", "Sanjiban Choudhury"], "title": "Non-Adversarial Inverse Reinforcement Learning via Successor Feature Matching", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ICLR 2025", "summary": "In inverse reinforcement learning (IRL), an agent seeks to replicate expert\ndemonstrations through interactions with the environment. Traditionally, IRL is\ntreated as an adversarial game, where an adversary searches over reward models,\nand a learner optimizes the reward through repeated RL procedures. This\ngame-solving approach is both computationally expensive and difficult to\nstabilize. In this work, we propose a novel approach to IRL by direct policy\noptimization: exploiting a linear factorization of the return as the inner\nproduct of successor features and a reward vector, we design an IRL algorithm\nby policy gradient descent on the gap between the learner and expert features.\nOur non-adversarial method does not require learning a reward function and can\nbe solved seamlessly with existing actor-critic RL algorithms. Remarkably, our\napproach works in state-only settings without expert action labels, a setting\nwhich behavior cloning (BC) cannot solve. Empirical results demonstrate that\nour method learns from as few as a single expert demonstration and achieves\nimproved performance on various control tasks.", "AI": {"tldr": "A novel non-adversarial IRL method using direct policy optimization, eliminating the need for reward function learning and working with state-only expert demonstrations.", "motivation": "Traditional IRL methods are computationally expensive and unstable due to their adversarial nature. This work aims to simplify and stabilize IRL by avoiding adversarial games and reward function learning.", "method": "The approach leverages a linear factorization of return (successor features and reward vector) and uses policy gradient descent to minimize the gap between learner and expert features. It integrates with actor-critic RL algorithms.", "result": "The method learns from as few as one expert demonstration, works without expert action labels, and outperforms on various control tasks.", "conclusion": "The proposed non-adversarial IRL method is efficient, stable, and effective, even in state-only settings where traditional methods like BC fail."}}
{"id": "2504.15979", "pdf": "https://arxiv.org/pdf/2504.15979", "abs": "https://arxiv.org/abs/2504.15979", "authors": ["Zhiyuan Zheng", "Jianpeng Qi", "Jiantao Li", "Guoqing Chao", "Junyu Dong", "Yanwei Yu"], "title": "Efficient Discovery of Motif Transition Process for Large-Scale Temporal Graphs", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Understanding the dynamic transition of motifs in temporal graphs is\nessential for revealing how graph structures evolve over time, identifying\ncritical patterns, and predicting future behaviors, yet existing methods often\nfocus on predefined motifs, limiting their ability to comprehensively capture\ntransitions and interrelationships. We propose a parallel motif transition\nprocess discovery algorithm, PTMT, a novel parallel method for discovering\nmotif transition processes in large-scale temporal graphs. PTMT integrates a\ntree-based framework with the temporal zone partitioning (TZP) strategy, which\npartitions temporal graphs by time and structure while preserving lossless\nmotif transitions and enabling massive parallelism. PTMT comprises three\nphases: growth zone parallel expansion, overlap-aware result aggregation, and\ndeterministic encoding of motif transitions, ensuring accurate tracking of\ndynamic transitions and interactions. Results on 10 real-world datasets\ndemonstrate that PTMT achieves speedups ranging from 12.0$\\times$ to\n50.3$\\times$ compared to the SOTA method.", "AI": {"tldr": "PTMT is a parallel algorithm for discovering motif transitions in temporal graphs, achieving significant speedups over existing methods.", "motivation": "Existing methods for analyzing motif transitions in temporal graphs are limited by predefined motifs and lack of comprehensive transition capture.", "method": "PTMT uses a tree-based framework with temporal zone partitioning (TZP) for parallel processing, involving growth zone expansion, overlap-aware aggregation, and deterministic encoding.", "result": "PTMT achieves speedups of 12.0\u00d7 to 50.3\u00d7 compared to state-of-the-art methods on 10 real-world datasets.", "conclusion": "PTMT effectively tracks dynamic motif transitions in large-scale temporal graphs with high efficiency and accuracy."}}
{"id": "2412.07608", "pdf": "https://arxiv.org/pdf/2412.07608", "abs": "https://arxiv.org/abs/2412.07608", "authors": ["Chengbo Wang", "Guozheng Ma", "Yifei Xue", "Yizhen Lao"], "title": "Faster and Better 3D Splatting via Group Training", "categories": ["cs.CV"], "comment": null, "summary": "3D Gaussian Splatting (3DGS) has emerged as a powerful technique for novel\nview synthesis, demonstrating remarkable capability in high-fidelity scene\nreconstruction through its Gaussian primitive representations. However, the\ncomputational overhead induced by the massive number of primitives poses a\nsignificant bottleneck to training efficiency. To overcome this challenge, we\npropose Group Training, a simple yet effective strategy that organizes Gaussian\nprimitives into manageable groups, optimizing training efficiency and improving\nrendering quality. This approach shows universal compatibility with existing\n3DGS frameworks, including vanilla 3DGS and Mip-Splatting, consistently\nachieving accelerated training while maintaining superior synthesis quality.\nExtensive experiments reveal that our straightforward Group Training strategy\nachieves up to 30% faster convergence and improved rendering quality across\ndiverse scenarios.", "AI": {"tldr": "Group Training improves 3D Gaussian Splatting (3DGS) efficiency by organizing primitives into groups, achieving faster convergence and better rendering quality.", "motivation": "The computational overhead from massive Gaussian primitives in 3DGS hinders training efficiency.", "method": "Proposes Group Training, a strategy to organize primitives into manageable groups, compatible with existing 3DGS frameworks.", "result": "Achieves up to 30% faster convergence and improved rendering quality across diverse scenarios.", "conclusion": "Group Training is a simple, effective solution to enhance 3DGS efficiency without compromising quality."}}
{"id": "2501.01005", "pdf": "https://arxiv.org/pdf/2501.01005", "abs": "https://arxiv.org/abs/2501.01005", "authors": ["Zihao Ye", "Lequn Chen", "Ruihang Lai", "Wuwei Lin", "Yineng Zhang", "Stephanie Wang", "Tianqi Chen", "Baris Kasikci", "Vinod Grover", "Arvind Krishnamurthy", "Luis Ceze"], "title": "FlashInfer: Efficient and Customizable Attention Engine for LLM Inference Serving", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": "Accepted by MLSys 2025, code available at\n  http://github.com/flashinfer-ai/flashinfer", "summary": "Transformers, driven by attention mechanisms, form the foundation of large\nlanguage models (LLMs). As these models scale up, efficient GPU attention\nkernels become essential for high-throughput and low-latency inference. Diverse\nLLM applications demand flexible and high-performance attention solutions. We\npresent FlashInfer: a customizable and efficient attention engine for LLM\nserving. FlashInfer tackles KV-cache storage heterogeneity using block-sparse\nformat and composable formats to optimize memory access and reduce redundancy.\nIt also offers a customizable attention template, enabling adaptation to\nvarious settings through Just-In-Time (JIT) compilation. Additionally,\nFlashInfer's load-balanced scheduling algorithm adjusts to dynamism of user\nrequests while maintaining compatibility with CUDAGraph which requires static\nconfiguration. FlashInfer have been integrated into leading LLM serving\nframeworks like SGLang, vLLM and MLC-Engine. Comprehensive kernel-level and\nend-to-end evaluations demonstrate FlashInfer's ability to significantly boost\nkernel performance across diverse inference scenarios: compared to\nstate-of-the-art LLM serving solutions, FlashInfer achieve 29-69%\ninter-token-latency reduction compared to compiler backends for LLM serving\nbenchmark, 28-30% latency reduction for long-context inference, and 13-17%\nspeedup for LLM serving with parallel generation.", "AI": {"tldr": "FlashInfer is a customizable and efficient attention engine for LLM serving, optimizing memory access and reducing redundancy, achieving significant latency reductions and speedups in various inference scenarios.", "motivation": "Efficient GPU attention kernels are essential for high-throughput and low-latency inference in large language models (LLMs), requiring flexible and high-performance attention solutions.", "method": "FlashInfer uses block-sparse format and composable formats for KV-cache storage, a customizable attention template with JIT compilation, and a load-balanced scheduling algorithm compatible with CUDAGraph.", "result": "FlashInfer achieves 29-69% inter-token-latency reduction, 28-30% latency reduction for long-context inference, and 13-17% speedup for parallel generation compared to state-of-the-art solutions.", "conclusion": "FlashInfer significantly enhances LLM serving performance, demonstrating its effectiveness across diverse inference scenarios."}}
{"id": "2504.15993", "pdf": "https://arxiv.org/pdf/2504.15993", "abs": "https://arxiv.org/abs/2504.15993", "authors": ["Oliver Summerell", "Gerardo Aragon-Camarasa", "Stephanie Ordonez Sanchez"], "title": "Benchmarking machine learning models for predicting aerofoil performance", "categories": ["physics.flu-dyn", "cs.LG"], "comment": "9 pages, 10 figures, submitted to EWTEC", "summary": "This paper investigates the capability of Neural Networks (NNs) as\nalternatives to the traditional methods to analyse the performance of aerofoils\nused in the wind and tidal energy industry. The current methods used to assess\nthe characteristic lift and drag coefficients include Computational Fluid\nDynamics (CFD), thin aerofoil and panel methods, all face trade-offs between\ncomputational speed and the accuracy of the results and as such NNs have been\ninvestigated as an alternative with the aim that it would perform both quickly\nand accurately. As such, this paper provides a benchmark for the windAI_bench\ndataset published by the National Renewable Energy Laboratory (NREL) in the\nUSA. In order to validate the methodology of the benchmarking, the AirfRANS\n{\\tt arXiv:2212.07564v3} dataset is used as both a starting point and a point\nof comparison. This study evaluates four neural networks (MLP, PointNet,\nGraphSAGE, GUNet) trained on a range aerofoils at 25 angles of attack\n(4$^\\circ$ to 20$^\\circ$). to predict fluid flow and calculate lift\ncoefficients ($C_L$) via the panel method. GraphSAGE and GUNet performed well\nduring the testing phase, but underperformed during validation. Accordingly,\nthis paper has identified PointNet and MLP as the two strongest models tested,\nhowever whilst the results from MLP are more commonly correct for predicting\nthe behaviour of the fluid, the results from PointNet provide the more accurate\nresults for calculating $C_L$.", "AI": {"tldr": "Neural Networks (NNs) are explored as alternatives to traditional aerofoil performance analysis methods, with PointNet and MLP emerging as top performers for fluid behavior prediction and lift coefficient accuracy, respectively.", "motivation": "Traditional methods like CFD and panel methods face trade-offs between speed and accuracy; NNs offer a potential solution for faster, accurate aerofoil performance analysis.", "method": "Four NNs (MLP, PointNet, GraphSAGE, GUNet) were trained on aerofoils at various angles of attack to predict fluid flow and calculate lift coefficients, validated using the AirfRANS dataset.", "result": "GraphSAGE and GUNet underperformed in validation, while PointNet and MLP excelled\u2014MLP for fluid behavior prediction and PointNet for lift coefficient accuracy.", "conclusion": "PointNet and MLP are the most effective NNs for aerofoil analysis, balancing accuracy and computational efficiency, though further refinement is needed for validation robustness."}}
{"id": "2412.14015", "pdf": "https://arxiv.org/pdf/2412.14015", "abs": "https://arxiv.org/abs/2412.14015", "authors": ["Haotong Lin", "Sida Peng", "Jingxiao Chen", "Songyou Peng", "Jiaming Sun", "Minghuan Liu", "Hujun Bao", "Jiashi Feng", "Xiaowei Zhou", "Bingyi Kang"], "title": "Prompting Depth Anything for 4K Resolution Accurate Metric Depth Estimation", "categories": ["cs.CV"], "comment": "CVPR 2025, Project page: https://PromptDA.github.io/", "summary": "Prompts play a critical role in unleashing the power of language and vision\nfoundation models for specific tasks. For the first time, we introduce\nprompting into depth foundation models, creating a new paradigm for metric\ndepth estimation termed Prompt Depth Anything. Specifically, we use a low-cost\nLiDAR as the prompt to guide the Depth Anything model for accurate metric depth\noutput, achieving up to 4K resolution. Our approach centers on a concise prompt\nfusion design that integrates the LiDAR at multiple scales within the depth\ndecoder. To address training challenges posed by limited datasets containing\nboth LiDAR depth and precise GT depth, we propose a scalable data pipeline that\nincludes synthetic data LiDAR simulation and real data pseudo GT depth\ngeneration. Our approach sets new state-of-the-arts on the ARKitScenes and\nScanNet++ datasets and benefits downstream applications, including 3D\nreconstruction and generalized robotic grasping.", "AI": {"tldr": "Prompt Depth Anything introduces LiDAR prompts to guide depth estimation, achieving high resolution and state-of-the-art results.", "motivation": "To enhance metric depth estimation by leveraging prompts, inspired by their success in language and vision models.", "method": "Uses low-cost LiDAR prompts fused at multiple scales in the depth decoder, supported by synthetic and real data pipelines.", "result": "Achieves 4K resolution and sets new benchmarks on ARKitScenes and ScanNet++.", "conclusion": "The approach advances depth estimation and benefits applications like 3D reconstruction and robotics."}}
{"id": "2501.04444", "pdf": "https://arxiv.org/pdf/2501.04444", "abs": "https://arxiv.org/abs/2501.04444", "authors": ["Dana A Abdullah", "Dana Rasul Hamad", "Ismail Y. Maolood", "Hakem Beitollahi", "Aso K. Ameen", "Sirwan A. Aula", "Abdulhady Abas Abdulla", "Mohammed Y. Shakorf", "Sabat Salih Muhamad"], "title": "A novel Facial Recognition technique with Focusing on Masked Faces", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recognizing the same faces with and without masks is important for ensuring\nconsistent identification in security, access control, and public safety. This\ncapability is crucial in scenarios like law enforcement, healthcare, and\nsurveillance, where accurate recognition must be maintained despite facial\nocclusion. This research focuses on the challenge of recognizing the same faces\nwith and without masks by employing cosine similarity as the primary technique.\nWith the increased use of masks, traditional facial recognition systems face\nsignificant accuracy issues, making it crucial to develop methods that can\nreliably identify individuals in masked conditions. For that reason, this study\nproposed Masked-Unmasked Face Matching Model (MUFM). This model employs\ntransfer learning using the Visual Geometry Group (VGG16) model to extract\nsignificant facial features, which are subsequently classified utilizing the\nK-Nearest Neighbors (K-NN) algorithm. The cosine similarity metric is employed\nto compare masked and unmasked faces of the same individuals. This approach\nrepresents a novel contribution, as the task of recognizing the same individual\nwith and without a mask using cosine similarity has not been previously\naddressed. By integrating these advanced methodologies, the research\ndemonstrates effective identification of individuals despite the presence of\nmasks, addressing a significant limitation in traditional systems. Using data\nis another essential part of this work, by collecting and preparing an image\ndataset from three different sources especially some of those data are real\nprovided a comprehensive power of this research. The image dataset used were\nalready collected in three different datasets of masked and unmasked for the\nsame faces.", "AI": {"tldr": "The paper proposes a Masked-Unmasked Face Matching Model (MUFM) using VGG16 and K-NN with cosine similarity to recognize faces with and without masks, addressing accuracy issues in traditional systems.", "motivation": "The need for consistent face recognition in masked scenarios for security, access control, and public safety drives this research.", "method": "The study uses transfer learning with VGG16 for feature extraction, K-NN for classification, and cosine similarity for comparing masked and unmasked faces.", "result": "The model effectively identifies individuals despite masks, overcoming limitations of traditional systems.", "conclusion": "The research presents a novel solution for masked face recognition, validated by a comprehensive dataset."}}
{"id": "2504.16068", "pdf": "https://arxiv.org/pdf/2504.16068", "abs": "https://arxiv.org/abs/2504.16068", "authors": ["Chuin Wei Tan", "Marc L. Descoteaux", "Mit Kotak", "Gabriel de Miranda Nascimento", "Se\u00e1n R. Kavanagh", "Laura Zichi", "Menghang Wang", "Aadit Saluja", "Yizhong R. Hu", "Tess Smidt", "Anders Johansson", "William C. Witt", "Boris Kozinsky", "Albert Musaelian"], "title": "High-performance training and inference for deep equivariant interatomic potentials", "categories": ["physics.comp-ph", "cs.LG", "physics.chem-ph"], "comment": null, "summary": "Machine learning interatomic potentials, particularly those based on deep\nequivariant neural networks, have demonstrated state-of-the-art accuracy and\ncomputational efficiency in atomistic modeling tasks like molecular dynamics\nand high-throughput screening. The size of datasets and demands of downstream\nworkflows are growing rapidly, making robust and scalable software essential.\nThis work presents a major overhaul of the NequIP framework focusing on\nmulti-node parallelism, computational performance, and extensibility. The\nredesigned framework supports distributed training on large datasets and\nremoves barriers preventing full utilization of the PyTorch 2.0 compiler at\ntrain time. We demonstrate this acceleration in a case study by training\nAllegro models on the SPICE 2 dataset of organic molecular systems. For\ninference, we introduce the first end-to-end infrastructure that uses the\nPyTorch Ahead-of-Time Inductor compiler for machine learning interatomic\npotentials. Additionally, we implement a custom kernel for the Allegro model's\nmost expensive operation, the tensor product. Together, these advancements\nspeed up molecular dynamics calculations on system sizes of practical relevance\nby up to a factor of 18.", "AI": {"tldr": "NequIP framework overhaul enhances scalability, performance, and extensibility for machine learning interatomic potentials, achieving up to 18x speedup in molecular dynamics.", "motivation": "Growing dataset sizes and computational demands necessitate robust, scalable software for deep equivariant neural networks in atomistic modeling.", "method": "Major redesign of NequIP focusing on multi-node parallelism, PyTorch 2.0 compiler utilization, and custom kernels for tensor products.", "result": "Demonstrated acceleration in training Allegro models on the SPICE 2 dataset and introduced end-to-end inference infrastructure with PyTorch Ahead-of-Time Inductor compiler.", "conclusion": "The advancements significantly improve computational efficiency, enabling faster molecular dynamics calculations on practical system sizes."}}
{"id": "2412.18386", "pdf": "https://arxiv.org/pdf/2412.18386", "abs": "https://arxiv.org/abs/2412.18386", "authors": ["Sagnik Majumder", "Tushar Nagarajan", "Ziad Al-Halah", "Kristen Grauman"], "title": "Switch-a-View: View Selection Learned from Unlabeled In-the-wild Videos", "categories": ["cs.CV"], "comment": null, "summary": "We introduce SWITCH-A-VIEW, a model that learns to automatically select the\nviewpoint to display at each timepoint when creating a how-to video. The key\ninsight of our approach is how to train such a model from unlabeled -- but\nhuman-edited -- video samples. We pose a pretext task that pseudo-labels\nsegments in the training videos for their primary viewpoint (egocentric or\nexocentric), and then discovers the patterns between the visual and spoken\ncontent in a how-to video on the one hand and its view-switch moments on the\nother hand. Armed with this predictor, our model can be applied to new\nmulti-view video settings for orchestrating which viewpoint should be displayed\nwhen, even when such settings come with limited labels. We demonstrate our idea\non a variety of real-world videos from HowTo100M and Ego-Exo4D, and rigorously\nvalidate its advantages. Project:\nhttps://vision.cs.utexas.edu/projects/switch_a_view/.", "AI": {"tldr": "SWITCH-A-VIEW is a model that learns to select viewpoints in how-to videos by training on unlabeled, human-edited samples, using pseudo-labels and visual-spoken content patterns.", "motivation": "To automate viewpoint selection in how-to videos, leveraging unlabeled but human-edited video samples for training.", "method": "Trains a model using pseudo-labels for viewpoints and discovers patterns between visual-spoken content and view-switch moments.", "result": "Demonstrated effectiveness on real-world videos (HowTo100M, Ego-Exo4D) with rigorous validation.", "conclusion": "The model successfully orchestrates viewpoint selection in multi-view videos, even with limited labels."}}
{"id": "2501.05496", "pdf": "https://arxiv.org/pdf/2501.05496", "abs": "https://arxiv.org/abs/2501.05496", "authors": ["Yanbing Zhou", "Xiangmou Qu", "Chenlong You", "Jiyang Zhou", "Jingyue Tang", "Xin Zheng", "Chunmao Cai", "Yingbo Wu"], "title": "FedSA: A Unified Representation Learning via Semantic Anchors for Prototype-based Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by AAAI2025", "summary": "Prototype-based federated learning has emerged as a promising approach that\nshares lightweight prototypes to transfer knowledge among clients with data\nheterogeneity in a model-agnostic manner. However, existing methods often\ncollect prototypes directly from local models, which inevitably introduce\ninconsistencies into representation learning due to the biased data\ndistributions and differing model architectures among clients. In this paper,\nwe identify that both statistical and model heterogeneity create a vicious\ncycle of representation inconsistency, classifier divergence, and skewed\nprototype alignment, which negatively impacts the performance of clients. To\nbreak the vicious cycle, we propose a novel framework named Federated Learning\nvia Semantic Anchors (FedSA) to decouple the generation of prototypes from\nlocal representation learning. We introduce a novel perspective that uses\nsimple yet effective semantic anchors serving as prototypes to guide local\nmodels in learning consistent representations. By incorporating semantic\nanchors, we further propose anchor-based regularization with margin-enhanced\ncontrastive learning and anchor-based classifier calibration to correct feature\nextractors and calibrate classifiers across clients, achieving intra-class\ncompactness and inter-class separability of prototypes while ensuring\nconsistent decision boundaries. We then update the semantic anchors with these\nconsistent and discriminative prototypes, which iteratively encourage clients\nto collaboratively learn a unified data representation with robust\ngeneralization. Extensive experiments under both statistical and model\nheterogeneity settings show that FedSA significantly outperforms existing\nprototype-based FL methods on various classification tasks.", "AI": {"tldr": "FedSA introduces semantic anchors to decouple prototype generation from local representation learning, addressing inconsistencies in federated learning caused by data and model heterogeneity.", "motivation": "Existing prototype-based federated learning methods suffer from inconsistencies due to biased data distributions and differing model architectures, leading to poor performance.", "method": "FedSA uses semantic anchors as prototypes, incorporating anchor-based regularization and contrastive learning to ensure consistent and discriminative representations.", "result": "FedSA outperforms existing methods in classification tasks under statistical and model heterogeneity settings.", "conclusion": "FedSA effectively breaks the vicious cycle of inconsistency in federated learning, achieving robust generalization through semantic anchors."}}
{"id": "2504.16075", "pdf": "https://arxiv.org/pdf/2504.16075", "abs": "https://arxiv.org/abs/2504.16075", "authors": ["Joshua S. Harvey", "Joshua Rosaler", "Mingshu Li", "Dhruv Desai", "Dhagash Mehta"], "title": "Explainable Unsupervised Anomaly Detection with Random Forest", "categories": ["stat.ML", "cs.LG"], "comment": "14 pages, 5 figures", "summary": "We describe the use of an unsupervised Random Forest for similarity learning\nand improved unsupervised anomaly detection. By training a Random Forest to\ndiscriminate between real data and synthetic data sampled from a uniform\ndistribution over the real data bounds, a distance measure is obtained that\nanisometrically transforms the data, expanding distances at the boundary of the\ndata manifold. We show that using distances recovered from this transformation\nimproves the accuracy of unsupervised anomaly detection, compared to other\ncommonly used detectors, demonstrated over a large number of benchmark\ndatasets. As well as improved performance, this method has advantages over\nother unsupervised anomaly detection methods, including minimal requirements\nfor data preprocessing, native handling of missing data, and potential for\nvisualizations. By relating outlier scores to partitions of the Random Forest,\nwe develop a method for locally explainable anomaly predictions in terms of\nfeature importance.", "AI": {"tldr": "An unsupervised Random Forest method improves anomaly detection by learning similarity and transforming data distances, outperforming other detectors with minimal preprocessing and explainable predictions.", "motivation": "To enhance unsupervised anomaly detection accuracy and provide explainable predictions with minimal data preprocessing.", "method": "Train a Random Forest to discriminate real data from synthetic uniform data, deriving a distance measure that transforms data anisometrically.", "result": "Improved accuracy in anomaly detection across benchmarks, with advantages like handling missing data and explainable feature importance.", "conclusion": "The method offers superior performance, simplicity, and explainability for unsupervised anomaly detection."}}
{"id": "2412.19504", "pdf": "https://arxiv.org/pdf/2412.19504", "abs": "https://arxiv.org/abs/2412.19504", "authors": ["Jing Li", "Bo Wang"], "title": "Hear the Scene: Audio-Enhanced Text Spotting", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in scene text spotting have focused on end-to-end\nmethodologies that heavily rely on precise location annotations, which are\noften costly and labor-intensive to procure. In this study, we introduce an\ninnovative approach that leverages only transcription annotations for training\ntext spotting models, substantially reducing the dependency on elaborate\nannotation processes. Our methodology employs a query-based paradigm that\nfacilitates the learning of implicit location features through the interaction\nbetween text queries and image embeddings. These features are later refined\nduring the text recognition phase using an attention activation map. Addressing\nthe challenges associated with training a weakly-supervised model from scratch,\nwe implement a circular curriculum learning strategy to enhance model\nconvergence. Additionally, we introduce a coarse-to-fine cross-attention\nlocalization mechanism for more accurate text instance localization. Notably,\nour framework supports audio-based annotation, which significantly diminishes\nannotation time and provides an inclusive alternative for individuals with\ndisabilities. Our approach achieves competitive performance against existing\nbenchmarks, demonstrating that high accuracy in text spotting can be attained\nwithout extensive location annotations.", "AI": {"tldr": "An innovative weakly-supervised text spotting method reduces reliance on costly location annotations by using only transcription annotations, achieving competitive performance.", "motivation": "To address the high cost and labor-intensive nature of precise location annotations in text spotting, this study proposes a method that minimizes dependency on such annotations.", "method": "The approach uses a query-based paradigm to learn implicit location features, refines them during recognition with an attention map, and employs circular curriculum learning and coarse-to-fine cross-attention for localization.", "result": "The method achieves competitive performance on benchmarks, showing high accuracy without extensive location annotations.", "conclusion": "The study demonstrates that accurate text spotting is feasible with minimal location annotations, offering a cost-effective and inclusive solution."}}
{"id": "2502.00043", "pdf": "https://arxiv.org/pdf/2502.00043", "abs": "https://arxiv.org/abs/2502.00043", "authors": ["Hao Lyu", "Yanyong Guo", "Pan Liu", "Nan Zheng", "Ting Wang", "Quansheng Yue"], "title": "Mitigating Traffic Oscillations in Mixed Traffic Flow with Scalable Deep Koopman Predictive Control", "categories": ["eess.SY", "cs.AI", "cs.SY"], "comment": null, "summary": "The use of connected automated vehicle (CAV) is advocated to mitigate traffic\noscillations in mixed traffic flow consisting of CAVs and human driven vehicles\n(HDVs). This study proposes an adaptive deep Koopman predictive control\nframework (AdapKoopPC) for regulating mixed traffic flow. Firstly, a Koopman\ntheory-based adaptive trajectory prediction deep network (AdapKoopnet) is\ndesigned for modeling HDVs car-following behavior. AdapKoopnet enables the\nrepresentation of HDVs behavior by a linear model in a high-dimensional space.\nSecondly, the model predictive control is employed to smooth the mixed traffic\nflow, where the combination of the linear dynamic model of CAVs and linear\nprediction blocks from AdapKoopnet is embedded as the predictive model into the\nAdapKoopPC. Finally, the predictive performance of the prosed AdapKoopnet is\nverified using the HighD naturalistic driving dataset. Furthermore, the control\nperformance of AdapKoopPC is validated by the numerical simulations. Results\ndemonstrate that the AdapKoopnet provides more accuracy HDVs predicted\ntrajectories than the baseline nonlinear models. Moreover, the proposed\nAdapKoopPC exhibits more effective control performance with less computation\ncost compared with baselines in mitigating traffic oscillations, especially at\nthe low CAVs penetration rates. The code of proposed AdapKoopPC is open source.", "AI": {"tldr": "The paper proposes an adaptive deep Koopman predictive control (AdapKoopPC) framework to regulate mixed traffic flow of CAVs and HDVs, improving prediction accuracy and control performance with lower computational cost.", "motivation": "To mitigate traffic oscillations in mixed traffic flow by leveraging CAVs and accurately modeling HDV behavior.", "method": "Develops AdapKoopnet for HDV behavior prediction using Koopman theory, integrates it with CAV dynamics in a model predictive control framework (AdapKoopPC).", "result": "AdapKoopnet outperforms baseline models in HDV trajectory prediction, and AdapKoopPC effectively reduces traffic oscillations with lower computational cost, especially at low CAV penetration rates.", "conclusion": "The proposed framework enhances mixed traffic flow regulation, offering practical benefits for real-world applications, with open-source code available."}}
{"id": "2108.05974", "pdf": "https://arxiv.org/pdf/2108.05974", "abs": "https://arxiv.org/abs/2108.05974", "authors": ["Saber Malekmohammadi", "Kiarash Shaloudegi", "Zeou Hu", "Yaoliang Yu"], "title": "An Operator Splitting View of Federated Learning", "categories": ["cs.LG"], "comment": "30 pages, 28 figures", "summary": "Over the past few years, the federated learning ($\\texttt{FL}$) community has\nwitnessed a proliferation of new $\\texttt{FL}$ algorithms. However, our\nunderstating of the theory of $\\texttt{FL}$ is still fragmented, and a\nthorough, formal comparison of these algorithms remains elusive. Motivated by\nthis gap, we show that many of the existing $\\texttt{FL}$ algorithms can be\nunderstood from an operator splitting point of view. This unification allows us\nto compare different algorithms with ease, to refine previous convergence\nresults and to uncover new algorithmic variants. In particular, our analysis\nreveals the vital role played by the step size in $\\texttt{FL}$ algorithms. The\nunification also leads to a streamlined and economic way to accelerate\n$\\texttt{FL}$ algorithms, without incurring any communication overhead. We\nperform numerical experiments on both convex and nonconvex models to validate\nour findings.", "AI": {"tldr": "The paper unifies existing federated learning (FL) algorithms under an operator splitting framework, enabling easier comparison, refined convergence results, and new variants, while highlighting the role of step size and proposing an efficient acceleration method.", "motivation": "The motivation is the fragmented understanding of FL theory and the lack of formal comparisons among existing FL algorithms.", "method": "The method involves analyzing FL algorithms from an operator splitting perspective, unifying them for comparison, refining convergence results, and proposing new variants.", "result": "The results include a unified understanding of FL algorithms, refined convergence analyses, and a communication-efficient acceleration method.", "conclusion": "The conclusion highlights the importance of step size in FL and the benefits of the unified framework for algorithm comparison and acceleration."}}
{"id": "2501.02811", "pdf": "https://arxiv.org/pdf/2501.02811", "abs": "https://arxiv.org/abs/2501.02811", "authors": ["Bin Wang", "Li Jing"], "title": "First-place Solution for Streetscape Shop Sign Recognition Competition", "categories": ["cs.CV"], "comment": "technical report", "summary": "Text recognition technology applied to street-view storefront signs is\nincreasingly utilized across various practical domains, including map\nnavigation, smart city planning analysis, and business value assessments in\ncommercial districts. This technology holds significant research and commercial\npotential. Nevertheless, it faces numerous challenges. Street view images often\ncontain signboards with complex designs and diverse text styles, complicating\nthe text recognition process. A notable advancement in this field was\nintroduced by our team in a recent competition. We developed a novel multistage\napproach that integrates multimodal feature fusion, extensive self-supervised\ntraining, and a Transformer-based large model. Furthermore, innovative\ntechniques such as BoxDQN, which relies on reinforcement learning, and text\nrectification methods were employed, leading to impressive outcomes.\nComprehensive experiments have validated the effectiveness of these methods,\nshowcasing our potential to enhance text recognition capabilities in complex\nurban environments.", "AI": {"tldr": "A novel multistage approach for street-view storefront sign text recognition, combining multimodal feature fusion, self-supervised training, and Transformer-based models, achieves impressive results despite challenges like complex designs and diverse text styles.", "motivation": "The technology is widely used in map navigation, smart city planning, and business assessments, but faces challenges due to complex signboard designs and diverse text styles in street-view images.", "method": "Developed a multistage approach with multimodal feature fusion, self-supervised training, Transformer-based large models, BoxDQN (reinforcement learning), and text rectification techniques.", "result": "Comprehensive experiments validated the method's effectiveness, demonstrating improved text recognition in complex urban environments.", "conclusion": "The approach shows significant potential to advance text recognition capabilities for practical applications in challenging urban settings."}}
{"id": "2502.00443", "pdf": "https://arxiv.org/pdf/2502.00443", "abs": "https://arxiv.org/abs/2502.00443", "authors": ["C\u00e9dric Join", "Emmanuel Delaleau", "Michel Fliess"], "title": "Model-Free Predictive Control: Introductory Algebraic Calculations, and a Comparison with HEOL and ANNs", "categories": ["eess.SY", "cs.AI", "cs.SY", "49J99", "I.2.8"], "comment": "Joint IFAC Conference: SSSC, TDS, COSY -- Gif-sur-Vette, France, 30\n  June-2 July 2025", "summary": "Model predictive control (MPC) is a popular control engineering practice, but\nrequires a sound knowledge of the model. Model-free predictive control (MFPC),\na burning issue today, also related to reinforcement learning (RL) in AI, is\nreformulated here via a linear differential equation with constant\ncoefficients, thanks to a new perspective on optimal control combined with\nrecent advances in the field of model-free control (MFC). It is replacing\nDynamic Programming, the Hamilton-Jacobi-Bellman equation, and Pontryagin's\nMaximum Principle. The computing burden is low. The implementation is\nstraightforward. Two nonlinear examples, a chemical reactor and a two tank\nsystem, are illustrating our approach. A comparison with the HEOL setting,\nwhere some expertise of the process model is needed, shows only a slight\nsuperiority of the later. A recent identification of the two tank system via a\ncomplex ANN architecture might indicate that a full modeling and the\ncorresponding machine learning mechanism are not always necessary neither in\ncontrol, nor, more generally, in AI.", "AI": {"tldr": "The paper reformulates Model-Free Predictive Control (MFPC) using a linear differential equation, simplifying implementation and reducing computational burden, and compares it favorably to traditional methods.", "motivation": "To address the complexity and model dependency of traditional Model Predictive Control (MPC) by introducing a simpler, model-free approach inspired by advances in Model-Free Control (MFC) and reinforcement learning.", "method": "Reformulates MFPC via a linear differential equation with constant coefficients, replacing traditional methods like Dynamic Programming and Pontryagin's Maximum Principle. Validated with nonlinear examples (chemical reactor and two-tank system).", "result": "Demonstrates low computational burden and straightforward implementation. Comparison with HEOL shows only slight superiority of the latter, suggesting model-free methods can be effective.", "conclusion": "Model-free approaches, like the proposed MFPC, can be viable alternatives to traditional modeling and machine learning in control and AI, as shown by the successful application to nonlinear systems."}}
{"id": "2308.04404", "pdf": "https://arxiv.org/pdf/2308.04404", "abs": "https://arxiv.org/abs/2308.04404", "authors": ["Sajjad Emdadi Mahdimahalleh"], "title": "Revolutionizing Wireless Networks with Federated Learning: A Comprehensive Review", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "These days with the rising computational capabilities of wireless user\nequipment such as smart phones, tablets, and vehicles, along with growing\nconcerns about sharing private data, a novel machine learning model called\nfederated learning (FL) has emerged. FL enables the separation of data\nacquisition and computation at the central unit, which is different from\ncentralized learning that occurs in a data center. FL is typically used in a\nwireless edge network where communication resources are limited and unreliable.\nBandwidth constraints necessitate scheduling only a subset of UEs for updates\nin each iteration, and because the wireless medium is shared, transmissions are\nsusceptible to interference and are not assured. The article discusses the\nsignificance of Machine Learning in wireless communication and highlights\nFederated Learning (FL) as a novel approach that could play a vital role in\nfuture mobile networks, particularly 6G and beyond.", "AI": {"tldr": "Federated Learning (FL) is a novel ML model for wireless edge networks, addressing privacy and resource constraints by decentralizing data computation.", "motivation": "Rising computational capabilities of user devices and privacy concerns drive the need for FL, especially in resource-limited wireless networks.", "method": "FL separates data acquisition and computation, scheduling subsets of UEs for updates due to bandwidth constraints and unreliable communication.", "result": "FL is highlighted as a key approach for future mobile networks like 6G, balancing privacy and efficiency in wireless communication.", "conclusion": "FL presents a promising solution for privacy-preserving and resource-efficient ML in future wireless networks."}}
{"id": "2501.03173", "pdf": "https://arxiv.org/pdf/2501.03173", "abs": "https://arxiv.org/abs/2501.03173", "authors": ["Alexandru Buburuzan", "Anuj Sharma", "John Redford", "Puneet K. Dokania", "Romain Mueller"], "title": "MObI: Multimodal Object Inpainting Using Diffusion Models", "categories": ["cs.CV"], "comment": "8 pages; Project page at https://alexbubu.com/mobi", "summary": "Safety-critical applications, such as autonomous driving, require extensive\nmultimodal data for rigorous testing. Methods based on synthetic data are\ngaining prominence due to the cost and complexity of gathering real-world data\nbut require a high degree of realism and controllability in order to be useful.\nThis paper introduces MObI, a novel framework for Multimodal Object Inpainting\nthat leverages a diffusion model to create realistic and controllable object\ninpaintings across perceptual modalities, demonstrated for both camera and\nlidar simultaneously. Using a single reference RGB image, MObI enables objects\nto be seamlessly inserted into existing multimodal scenes at a 3D location\nspecified by a bounding box, while maintaining semantic consistency and\nmultimodal coherence. Unlike traditional inpainting methods that rely solely on\nedit masks, our 3D bounding box conditioning gives objects accurate spatial\npositioning and realistic scaling. As a result, our approach can be used to\ninsert novel objects flexibly into multimodal scenes, providing significant\nadvantages for testing perception models.", "AI": {"tldr": "MObI is a framework for multimodal object inpainting using diffusion models to insert objects into scenes with realism and controllability, useful for testing perception models.", "motivation": "Safety-critical applications like autonomous driving need realistic synthetic data for testing, but current methods lack controllability and realism.", "method": "MObI uses a diffusion model to inpaint objects into multimodal scenes (camera and lidar) based on a 3D bounding box, ensuring spatial accuracy and coherence.", "result": "The framework successfully inserts objects into scenes with semantic consistency and multimodal realism, outperforming traditional mask-based methods.", "conclusion": "MObI offers a flexible and realistic solution for generating synthetic data, enhancing perception model testing in safety-critical applications."}}
{"id": "2502.09436", "pdf": "https://arxiv.org/pdf/2502.09436", "abs": "https://arxiv.org/abs/2502.09436", "authors": ["Dario Spoljaric", "Yashuai Yan", "Dongheui Lee"], "title": "Variable Stiffness for Robust Locomotion through Reinforcement Learning", "categories": ["cs.RO", "cs.AI"], "comment": "accepted to IFAC Joint Symposia on Mechatronics & Robotics", "summary": "Reinforcement-learned locomotion enables legged robots to perform highly\ndynamic motions but often accompanies time-consuming manual tuning of joint\nstiffness. This paper introduces a novel control paradigm that integrates\nvariable stiffness into the action space alongside joint positions, enabling\ngrouped stiffness control such as per-joint stiffness (PJS), per-leg stiffness\n(PLS) and hybrid joint-leg stiffness (HJLS). We show that variable stiffness\npolicies, with grouping in per-leg stiffness (PLS), outperform position-based\ncontrol in velocity tracking and push recovery. In contrast, HJLS excels in\nenergy efficiency. Despite the fact that our policy is trained on flat floor\nonly, our method showcases robust walking behaviour on diverse outdoor\nterrains, indicating robust sim-to-real transfer. Our approach simplifies\ndesign by eliminating per-joint stiffness tuning while keeping competitive\nresults with various metrics.", "AI": {"tldr": "A novel control paradigm integrates variable stiffness into reinforcement-learned locomotion, simplifying design and improving performance on diverse terrains.", "motivation": "Manual tuning of joint stiffness in legged robots is time-consuming, prompting the need for an automated and efficient control method.", "method": "The paper introduces a control paradigm combining variable stiffness and joint positions, with grouped stiffness control (PJS, PLS, HJLS).", "result": "PLS outperforms position-based control in velocity tracking and push recovery, while HJLS excels in energy efficiency. The method shows robust sim-to-real transfer.", "conclusion": "The approach eliminates manual stiffness tuning while maintaining competitive performance, demonstrating robust adaptability to diverse terrains."}}
{"id": "2312.10235", "pdf": "https://arxiv.org/pdf/2312.10235", "abs": "https://arxiv.org/abs/2312.10235", "authors": ["Carlos E. P\u00e9rez De Jes\u00fas", "Alec J. Linot", "Michael D. Graham"], "title": "Building symmetries into data-driven manifold dynamics models for complex flows: application to two-dimensional Kolmogorov flow", "categories": ["cs.LG", "nlin.CD"], "comment": null, "summary": "Data-driven reduced-order models of the dynamics of complex flows are\nimportant for tasks related to design, understanding, prediction, and control.\nMany flows obey symmetries, and the present work illustrates how these can be\nexploited to yield highly efficient low-dimensional data-driven models for\nchaotic flows. In particular, incorporating symmetries both guarantees that the\nreduced order model automatically respects them and dramatically increases the\neffective density of data sampling. Given data for the long-time dynamics of a\nsystem, and knowing the set of continuous and discrete symmetries it obeys, the\nfirst step in the methodology is to identify a \"fundamental chart\", a region in\nthe state space of the flow to which all other regions can be mapped by a\nsymmetry operation, and a set of criteria indicating what mapping takes each\npoint in state space into that chart. We then find a low-dimensional coordinate\nrepresentation of the data in the fundamental chart with the use of an\nautoencoder architecture that also provides an estimate of the dimension of the\ninvariant manifold where data lie. Finally, we learn dynamics on this manifold\nwith the use of neural ordinary differential equations. We apply this method,\ndenoted \"symmetry charting\" to simulation data from two-dimensional Kolmogorov\nflow in a chaotic bursting regime. This system has a continuous translation\nsymmetry, and discrete rotation and shift-reflect symmetries. With this\nframework we observe that less data is needed to learn accurate data-driven\nmodels, more robust estimates of the manifold dimension are obtained,\nequivariance of the NSE is satisfied, better short-time tracking with respect\nto the true data is observed, and long-time statistics are correctly captured.", "AI": {"tldr": "The paper introduces 'symmetry charting,' a method to create efficient reduced-order models for chaotic flows by leveraging symmetries, improving data sampling, and ensuring equivariance.", "motivation": "To develop data-driven reduced-order models for complex flows that respect inherent symmetries, enhancing efficiency and accuracy in modeling chaotic dynamics.", "method": "The approach involves identifying a 'fundamental chart,' using autoencoders for low-dimensional representation, and learning dynamics with neural ODEs, applied to Kolmogorov flow.", "result": "The method reduces data requirements, improves manifold dimension estimates, ensures equivariance, and captures accurate short- and long-time dynamics.", "conclusion": "Symmetry charting effectively leverages symmetries to enhance reduced-order modeling of chaotic flows, demonstrating improved performance and robustness."}}
{"id": "2501.10640", "pdf": "https://arxiv.org/pdf/2501.10640", "abs": "https://arxiv.org/abs/2501.10640", "authors": ["Dhruv Parikh", "Jacob Fein-Ashley", "Tian Ye", "Rajgopal Kannan", "Viktor Prasanna"], "title": "ClusterViG: Efficient Globally Aware Vision GNNs via Image Partitioning", "categories": ["cs.CV", "cs.DC"], "comment": "IEEE MCNA 2025", "summary": "Convolutional Neural Networks (CNN) and Vision Transformers (ViT) have\ndominated the field of Computer Vision (CV). Graph Neural Networks (GNN) have\nperformed remarkably well across diverse domains because they can represent\ncomplex relationships via unstructured graphs. However, the applicability of\nGNNs for visual tasks was unexplored till the introduction of Vision GNNs\n(ViG). Despite the success of ViGs, their performance is severely bottlenecked\ndue to the expensive $k$-Nearest Neighbors ($k$-NN) based graph construction.\nRecent works addressing this bottleneck impose constraints on the flexibility\nof GNNs to build unstructured graphs, undermining their core advantage while\nintroducing additional inefficiencies. To address these issues, in this paper,\nwe propose a novel method called Dynamic Efficient Graph Convolution (DEGC) for\ndesigning efficient and globally aware ViGs. DEGC partitions the input image\nand constructs graphs in parallel for each partition, improving graph\nconstruction efficiency. Further, DEGC integrates local intra-graph and global\ninter-graph feature learning, enabling enhanced global context awareness. Using\nDEGC as a building block, we propose a novel CNN-GNN architecture, ClusterViG,\nfor CV tasks. Extensive experiments indicate that ClusterViG reduces end-to-end\ninference latency for vision tasks by up to $5\\times$ when compared against a\nsuite of models such as ViG, ViHGNN, PVG, and GreedyViG, with a similar model\nparameter count. Additionally, ClusterViG reaches state-of-the-art performance\non image classification, object detection, and instance segmentation tasks,\ndemonstrating the effectiveness of the proposed globally aware learning\nstrategy. Finally, input partitioning performed by DEGC enables ClusterViG to\nbe trained efficiently on higher-resolution images, underscoring the\nscalability of our approach.", "AI": {"tldr": "The paper introduces DEGC, a method for efficient graph construction in Vision GNNs, and ClusterViG, a CNN-GNN architecture, achieving faster inference and state-of-the-art performance in CV tasks.", "motivation": "GNNs' potential for visual tasks is limited by inefficient graph construction methods, which either compromise flexibility or introduce inefficiencies.", "method": "Proposes DEGC for parallel graph construction and global-local feature integration, leading to the ClusterViG architecture.", "result": "ClusterViG reduces inference latency by 5x and achieves top performance in image classification, detection, and segmentation.", "conclusion": "DEGC and ClusterViG offer scalable, efficient, and high-performing solutions for visual tasks, leveraging GNNs effectively."}}
{"id": "2502.13055", "pdf": "https://arxiv.org/pdf/2502.13055", "abs": "https://arxiv.org/abs/2502.13055", "authors": ["Xingzhi Qian", "Xinran Zheng", "Yiling He", "Shuo Yang", "Lorenzo Cavallaro"], "title": "LAMD: Context-driven Android Malware Detection and Classification with LLMs", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "accepted by 2025 46th IEEE Symposium on Security and Privacy\n  Workshops (SPW)", "summary": "The rapid growth of mobile applications has escalated Android malware\nthreats. Although there are numerous detection methods, they often struggle\nwith evolving attacks, dataset biases, and limited explainability. Large\nLanguage Models (LLMs) offer a promising alternative with their zero-shot\ninference and reasoning capabilities. However, applying LLMs to Android malware\ndetection presents two key challenges: (1)the extensive support code in Android\napplications, often spanning thousands of classes, exceeds LLMs' context limits\nand obscures malicious behavior within benign functionality; (2)the structural\ncomplexity and interdependencies of Android applications surpass LLMs'\nsequence-based reasoning, fragmenting code analysis and hindering malicious\nintent inference. To address these challenges, we propose LAMD, a practical\ncontext-driven framework to enable LLM-based Android malware detection. LAMD\nintegrates key context extraction to isolate security-critical code regions and\nconstruct program structures, then applies tier-wise code reasoning to analyze\napplication behavior progressively, from low-level instructions to high-level\nsemantics, providing final prediction and explanation. A well-designed factual\nconsistency verification mechanism is equipped to mitigate LLM hallucinations\nfrom the first tier. Evaluation in real-world settings demonstrates LAMD's\neffectiveness over conventional detectors, establishing a feasible basis for\nLLM-driven malware analysis in dynamic threat landscapes.", "AI": {"tldr": "LAMD is a context-driven framework using LLMs for Android malware detection, addressing challenges like code complexity and context limits by integrating key context extraction and tier-wise reasoning.", "motivation": "The rise in Android malware threats and limitations of existing detection methods (evolving attacks, dataset biases, explainability) motivate the use of LLMs for improved detection.", "method": "LAMD extracts security-critical code regions, constructs program structures, and applies tier-wise reasoning from low-level to high-level semantics, with a factual consistency mechanism to reduce hallucinations.", "result": "LAMD outperforms conventional detectors in real-world evaluations, proving effective for LLM-driven malware analysis.", "conclusion": "LAMD provides a practical and feasible solution for leveraging LLMs in Android malware detection, addressing key challenges in the field."}}
{"id": "2405.18100", "pdf": "https://arxiv.org/pdf/2405.18100", "abs": "https://arxiv.org/abs/2405.18100", "authors": ["Onno Eberhard", "Claire Vernade", "Michael Muehlebach"], "title": "A Pontryagin Perspective on Reinforcement Learning", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Reinforcement learning has traditionally focused on learning state-dependent\npolicies to solve optimal control problems in a closed-loop fashion. In this\nwork, we introduce the paradigm of open-loop reinforcement learning where a\nfixed action sequence is learned instead. We present three new algorithms: one\nrobust model-based method and two sample-efficient model-free methods. Rather\nthan basing our algorithms on Bellman's equation from dynamic programming, our\nwork builds on Pontryagin's principle from the theory of open-loop optimal\ncontrol. We provide convergence guarantees and evaluate all methods empirically\non a pendulum swing-up task, as well as on two high-dimensional MuJoCo tasks,\nsignificantly outperforming existing baselines.", "AI": {"tldr": "The paper introduces open-loop reinforcement learning, learning fixed action sequences instead of state-dependent policies, with three new algorithms outperforming baselines.", "motivation": "Traditional reinforcement learning focuses on closed-loop, state-dependent policies; this work explores open-loop learning for fixed action sequences.", "method": "Three algorithms are presented: one robust model-based and two sample-efficient model-free methods, based on Pontryagin's principle rather than Bellman's equation.", "result": "The methods outperform baselines on pendulum swing-up and high-dimensional MuJoCo tasks, with convergence guarantees provided.", "conclusion": "Open-loop reinforcement learning, leveraging Pontryagin's principle, offers a viable alternative to traditional closed-loop methods, demonstrating superior performance."}}
{"id": "2502.20650", "pdf": "https://arxiv.org/pdf/2502.20650", "abs": "https://arxiv.org/abs/2502.20650", "authors": ["Yu Pan", "Bingrong Dai", "Jiahao Chen", "Lin Wang", "Yi Du", "Jiao Liu"], "title": "Gungnir: Exploiting Stylistic Features in Images for Backdoor Attacks on Diffusion Models", "categories": ["cs.CV", "cs.CR"], "comment": null, "summary": "In recent years, Diffusion Models (DMs) have demonstrated significant\nadvances in the field of image generation. However, according to current\nresearch, DMs are vulnerable to backdoor attacks, which allow attackers to\ncontrol the model's output by inputting data containing covert triggers, such\nas a specific visual patch or phrase. Existing defense strategies are well\nequipped to thwart such attacks through backdoor detection and trigger\ninversion because previous attack methods are constrained by limited input\nspaces and low-dimensional triggers. For example, visual triggers are easily\nobserved by defenders, text-based or attention-based triggers are more\nsusceptible to neural network detection. To explore more possibilities of\nbackdoor attack in DMs, we propose Gungnir, a novel method that enables\nattackers to activate the backdoor in DMs through style triggers within input\nimages. Our approach proposes using stylistic features as triggers for the\nfirst time and implements backdoor attacks successfully in image-to-image tasks\nby introducing Reconstructing-Adversarial Noise (RAN) and Short-Term\nTimesteps-Retention (STTR). Our technique generates trigger-embedded images\nthat are perceptually indistinguishable from clean images, thus bypassing both\nmanual inspection and automated detection neural networks. Experiments\ndemonstrate that Gungnir can easily bypass existing defense methods. Among\nexisting DM defense frameworks, our approach achieves a 0 backdoor detection\nrate (BDR). Our codes are available at https://github.com/paoche11/Gungnir.", "AI": {"tldr": "Gungnir introduces style triggers for backdoor attacks in Diffusion Models, bypassing defenses with Reconstructing-Adversarial Noise and Short-Term Timesteps-Retention.", "motivation": "Current backdoor attacks in DMs are limited by detectable triggers; Gungnir explores style-based triggers for stealthier attacks.", "method": "Uses stylistic features as triggers, implements RAN and STTR for image-to-image backdoor attacks.", "result": "Generates undetectable trigger-embedded images, achieving 0% backdoor detection rate in existing defenses.", "conclusion": "Gungnir demonstrates the feasibility of style-based backdoor attacks, highlighting a new vulnerability in DMs."}}
{"id": "2503.01411", "pdf": "https://arxiv.org/pdf/2503.01411", "abs": "https://arxiv.org/abs/2503.01411", "authors": ["Peng Yan", "Ahmed Abdulkadir", "Gerrit A. Schatte", "Giulia Aguzzi", "Joonsu Gha", "Nikola Pascher", "Matthias Rosenthal", "Yunlong Gao", "Benjamin F. Grewe", "Thilo Stadelmann"], "title": "Learning Actionable World Models for Industrial Process Control", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY", "I.2.0; I.2.4"], "comment": "Accepted by SDS 2025", "summary": "To go from (passive) process monitoring to active process control, an\neffective AI system must learn about the behavior of the complex system from\nvery limited training data, forming an ad-hoc digital twin with respect to\nprocess inputs and outputs that captures the consequences of actions on the\nprocess's world. We propose a novel methodology based on learning world models\nthat disentangles process parameters in the learned latent representation,\nallowing for fine-grained control. Representation learning is driven by the\nlatent factors influencing the processes through contrastive learning within a\njoint embedding predictive architecture. This makes changes in representations\npredictable from changes in inputs and vice versa, facilitating\ninterpretability of key factors responsible for process variations, paving the\nway for effective control actions to keep the process within operational\nbounds. The effectiveness of our method is validated on the example of plastic\ninjection molding, demonstrating practical relevance in proposing specific\ncontrol actions for a notoriously unstable process.", "AI": {"tldr": "The paper proposes a novel AI methodology for active process control by learning disentangled latent representations from limited data, validated on plastic injection molding.", "motivation": "To transition from passive monitoring to active control of complex systems with limited training data, requiring an ad-hoc digital twin for actionable insights.", "method": "Uses contrastive learning within a joint embedding predictive architecture to disentangle latent process parameters, enabling predictable and interpretable representations.", "result": "Demonstrates effectiveness by proposing specific control actions for plastic injection molding, a notoriously unstable process.", "conclusion": "The method enables fine-grained control and interpretability, paving the way for effective process management within operational bounds."}}
{"id": "2406.02584", "pdf": "https://arxiv.org/pdf/2406.02584", "abs": "https://arxiv.org/abs/2406.02584", "authors": ["Kazuki Sakamoto", "Connor T. Jerzak", "Adel Daoud"], "title": "A Scoping Review of Earth Observation and Machine Learning for Causal Inference: Implications for the Geography of Poverty", "categories": ["cs.LG", "cs.CV", "stat.ME", "stat.ML", "62H11", "I.2.6; I.5.4"], "comment": "To appear as: Sakamoto, Kazuki, Connor T. Jerzak, and Adel Daoud. \"A\n  Scoping Review of Earth Observation and Machine Learning for Causal\n  Inference: Implications for the Geography of Poverty.\" In Geography of\n  Poverty, edited by Ola Hall and Ibrahim Wahab. Edward Elgar Publishing\n  (Cheltenham, UK), 2025", "summary": "Earth observation (EO) data such as satellite imagery can have far-reaching\nimpacts on our understanding of the geography of poverty, especially when\ncoupled with machine learning (ML) and computer vision. Early research used\ncomputer vision to predict living conditions in areas with limited data, but\nrecent studies increasingly focus on causal analysis. Despite this shift, the\nuse of EO-ML methods for causal inference lacks thorough documentation, and\nbest practices are still developing. Through a comprehensive scoping review, we\ncatalog the current literature on EO-ML methods in causal analysis. We\nsynthesize five principal approaches to incorporating EO data in causal\nworkflows: (1) outcome imputation for downstream causal analysis, (2) EO image\ndeconfounding, (3) EO-based treatment effect heterogeneity, (4) EO-based\ntransportability analysis, and (5) image-informed causal discovery. Building on\nthese findings, we provide a detailed protocol guiding researchers in\nintegrating EO data into causal analysis -- covering data requirements,\ncomputer vision model selection, and evaluation metrics. While our focus\ncenters on health and living conditions outcomes, our protocol is adaptable to\nother sustainable development domains utilizing EO data.", "AI": {"tldr": "The paper reviews EO-ML methods for causal analysis, identifies five approaches, and provides a protocol for integrating EO data into causal workflows.", "motivation": "To address the lack of documentation and best practices in using EO-ML for causal inference, especially in poverty and health studies.", "method": "Conducted a scoping review to catalog EO-ML methods, synthesized five principal approaches, and developed a detailed protocol for researchers.", "result": "Identified five key approaches for EO-ML in causal analysis and created a practical protocol for implementation.", "conclusion": "The protocol is adaptable for sustainable development domains, offering guidance for integrating EO data into causal analysis."}}
{"id": "2503.06223", "pdf": "https://arxiv.org/pdf/2503.06223", "abs": "https://arxiv.org/abs/2503.06223", "authors": ["Ruofan Wang", "Xiang Zheng", "Xiaosen Wang", "Cong Wang", "Xingjun Ma"], "title": "Red Team Diffuser: Exposing Toxic Continuation Vulnerabilities in Vision-Language Models via Reinforcement Learning", "categories": ["cs.CV"], "comment": null, "summary": "The growing deployment of large Vision-Language Models (VLMs) exposes\ncritical safety gaps in their alignment mechanisms. While existing jailbreak\nstudies primarily focus on VLMs' susceptibility to harmful instructions, we\nreveal a fundamental yet overlooked vulnerability: toxic text continuation,\nwhere VLMs produce highly toxic completions when prompted with harmful text\nprefixes paired with semantically adversarial images. To systematically study\nthis threat, we propose Red Team Diffuser (RTD), the first red teaming\ndiffusion model that coordinates adversarial image generation and toxic\ncontinuation through reinforcement learning. Our key innovations include\ndynamic cross-modal attack and stealth-aware optimization. For toxic text\nprefixes from an LLM safety benchmark, we conduct greedy search to identify\noptimal image prompts that maximally induce toxic completions. The discovered\nimage prompts then drive RL-based diffusion model fine-tuning, producing\nsemantically aligned adversarial images that boost toxicity rates.\nStealth-aware optimization introduces joint adversarial rewards that balance\ntoxicity maximization (via Detoxify classifier) and stealthiness (via\nBERTScore), circumventing traditional noise-based adversarial patterns.\nExperimental results demonstrate the effectiveness of RTD, increasing the\ntoxicity rate of LLaVA outputs by 10.69% over text-only baselines on the\noriginal attack set and 8.91% on an unseen set, proving generalization\ncapability. Moreover, RTD exhibits strong cross-model transferability, raising\nthe toxicity rate by 5.1% on Gemini and 26.83% on LLaMA. Our findings expose\ntwo critical flaws in current VLM alignment: (1) failure to prevent toxic\ncontinuation from harmful prefixes, and (2) overlooking cross-modal attack\nvectors. These results necessitate a paradigm shift toward multimodal red\nteaming in safety evaluations.", "AI": {"tldr": "The paper exposes safety gaps in Vision-Language Models (VLMs) by revealing toxic text continuation vulnerabilities. It introduces Red Team Diffuser (RTD), a reinforcement learning-based method for adversarial image generation, boosting toxicity rates and highlighting flaws in VLM alignment.", "motivation": "Existing jailbreak studies focus on harmful instructions but overlook toxic text continuation vulnerabilities in VLMs when paired with adversarial images. This paper aims to systematically study and exploit this gap.", "method": "Proposes RTD, a red teaming diffusion model using reinforcement learning to coordinate adversarial image generation and toxic text continuation. Innovations include dynamic cross-modal attack and stealth-aware optimization.", "result": "RTD increases toxicity rates in VLMs (e.g., 10.69% for LLaVA) and shows cross-model transferability (e.g., 26.83% for LLaMA). It exposes flaws in VLM alignment, particularly toxic continuation and cross-modal attacks.", "conclusion": "The findings highlight critical flaws in VLM alignment and advocate for multimodal red teaming in safety evaluations to address these vulnerabilities."}}
{"id": "2503.03563", "pdf": "https://arxiv.org/pdf/2503.03563", "abs": "https://arxiv.org/abs/2503.03563", "authors": ["Florian Pl\u00f6tzky", "Katarina Britz", "Wolf-Tilo Balke"], "title": "A Conceptual Model for Attributions in Event-Centric Knowledge Graphs", "categories": ["cs.DB", "cs.AI"], "comment": "Accepted by Data & Knowledge Engineering, 22 pages, 9 figures", "summary": "The use of narratives as a means of fusing information from knowledge graphs\n(KGs) into a coherent line of argumentation has been the subject of recent\ninvestigation. Narratives are especially useful in event-centric knowledge\ngraphs in that they provide a means to connect different real-world events and\ncategorize them by well-known narrations. However, specifically for\ncontroversial events, a problem in information fusion arises, namely, multiple\nviewpoints regarding the validity of certain event aspects, e.g., regarding the\nrole a participant takes in an event, may exist. Expressing those viewpoints in\nKGs is challenging because disputed information provided by different\nviewpoints may introduce inconsistencies. Hence, most KGs only feature a single\nview on the contained information, hampering the effectiveness of narrative\ninformation access. This paper is an extension of our original work and\nintroduces attributions, i.e., parameterized predicates that allow for the\nrepresentation of facts that are only valid in a specific viewpoint. For this,\nwe develop a conceptual model that allows for the representation of\nviewpoint-dependent information. As an extension, we enhance the model by a\nconception of viewpoint-compatibility. Based on this, we deepen our original\ndeliberations on the model's effects on information fusion and provide\nadditional grounding in the literature.", "AI": {"tldr": "The paper extends prior work by introducing attributions in knowledge graphs to represent viewpoint-dependent information, addressing inconsistencies in controversial events.", "motivation": "To resolve inconsistencies in knowledge graphs when representing multiple viewpoints, especially for controversial events.", "method": "Develops a conceptual model using parameterized predicates (attributions) and introduces viewpoint-compatibility.", "result": "Enables representation of facts valid only in specific viewpoints, improving narrative information access.", "conclusion": "The model enhances information fusion by accommodating diverse viewpoints, with additional grounding in literature."}}
{"id": "2406.14388", "pdf": "https://arxiv.org/pdf/2406.14388", "abs": "https://arxiv.org/abs/2406.14388", "authors": ["Oisin Nolan", "Tristan S. W. Stevens", "Wessel L. van Nierop", "Ruud J. G. van Sloun"], "title": "Active Diffusion Subsampling", "categories": ["cs.LG"], "comment": "27 pages, 16 figures", "summary": "Subsampling is commonly used to mitigate costs associated with data\nacquisition, such as time or energy requirements, motivating the development of\nalgorithms for estimating the fully-sampled signal of interest $x$ from\npartially observed measurements $y$. In maximum entropy sampling, one selects\nmeasurement locations that are expected to have the highest entropy, so as to\nminimize uncertainty about $x$. This approach relies on an accurate model of\nthe posterior distribution over future measurements, given the measurements\nobserved so far. Recently, diffusion models have been shown to produce\nhigh-quality posterior samples of high-dimensional signals using guided\ndiffusion. In this work, we propose Active Diffusion Subsampling (ADS), a\nmethod for designing intelligent subsampling masks using guided diffusion in\nwhich the model tracks a distribution of beliefs over the true state of $x$\nthroughout the reverse diffusion process, progressively decreasing its\nuncertainty by actively choosing to acquire measurements with maximum expected\nentropy, ultimately producing the posterior distribution $p(x \\mid y)$. ADS can\nbe applied using pre-trained diffusion models for any subsampling rate, and\ndoes not require task-specific retraining - just the specification of a\nmeasurement model. Furthermore, the maximum entropy sampling policy employed by\nADS is interpretable, enhancing transparency relative to existing methods using\nblack-box policies. Code is available at\nhttps://active-diffusion-subsampling.github.io/.", "AI": {"tldr": "ADS uses guided diffusion for intelligent subsampling by maximizing entropy to reduce uncertainty, producing posterior distributions without task-specific retraining.", "motivation": "To address the high costs of data acquisition by developing a method for estimating fully-sampled signals from partial measurements.", "method": "Active Diffusion Subsampling (ADS) leverages guided diffusion to track beliefs over the signal state, actively selecting measurements with maximum entropy.", "result": "ADS produces accurate posterior distributions and is interpretable, working with pre-trained models without retraining.", "conclusion": "ADS offers a transparent and efficient solution for subsampling, outperforming black-box methods."}}
{"id": "2503.21979", "pdf": "https://arxiv.org/pdf/2503.21979", "abs": "https://arxiv.org/abs/2503.21979", "authors": ["Size Wu", "Wenwei Zhang", "Lumin Xu", "Sheng Jin", "Zhonghua Wu", "Qingyi Tao", "Wentao Liu", "Wei Li", "Chen Change Loy"], "title": "Harmonizing Visual Representations for Unified Multimodal Understanding and Generation", "categories": ["cs.CV"], "comment": null, "summary": "Unifying visual understanding and generation within a single multimodal\nframework remains a significant challenge, as the two inherently heterogeneous\ntasks require representations at different levels of granularity. Current\napproaches that utilize vector quantization (VQ) or variational autoencoders\n(VAE) for unified visual representation prioritize intrinsic imagery features\nover semantics, compromising understanding performance. In this work, we take\ninspiration from masked image modelling (MIM) that learns rich semantics via a\nmask-and-reconstruct pre-training and its successful extension to masked\nautoregressive (MAR) image generation. A preliminary study on the MAR encoder's\nrepresentation reveals exceptional linear probing accuracy and precise feature\nresponse to visual concepts, which indicates MAR's potential for visual\nunderstanding tasks beyond its original generation role. Based on these\ninsights, we present \\emph{Harmon}, a unified autoregressive framework that\nharmonizes understanding and generation tasks with a shared MAR encoder.\nThrough a three-stage training procedure that progressively optimizes\nunderstanding and generation capabilities, Harmon achieves state-of-the-art\nimage generation results on the GenEval, MJHQ30K and WISE benchmarks while\nmatching the performance of methods with dedicated semantic encoders (e.g.,\nJanus) on image understanding benchmarks. Our code and models will be available\nat https://github.com/wusize/Harmon.", "AI": {"tldr": "Harmon is a unified autoregressive framework using a shared MAR encoder to harmonize visual understanding and generation, achieving state-of-the-art results in both tasks.", "motivation": "Current methods for unified visual representation prioritize imagery features over semantics, compromising understanding performance.", "method": "Uses a shared MAR encoder inspired by masked image modelling (MIM) and masked autoregressive (MAR) generation, with a three-stage training procedure.", "result": "Achieves top image generation results on GenEval, MJHQ30K, and WISE benchmarks while matching dedicated semantic encoders in understanding tasks.", "conclusion": "Harmon successfully unifies visual understanding and generation, demonstrating the potential of MAR for both tasks."}}
{"id": "2503.11917", "pdf": "https://arxiv.org/pdf/2503.11917", "abs": "https://arxiv.org/abs/2503.11917", "authors": ["Mikel Rodriguez", "Raluca Ada Popa", "Four Flynn", "Lihao Liang", "Allan Dafoe", "Anna Wang"], "title": "A Framework for Evaluating Emerging Cyberattack Capabilities of AI", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "As frontier AI models become more capable, evaluating their potential to\nenable cyberattacks is crucial for ensuring the safe development of Artificial\nGeneral Intelligence (AGI). Current cyber evaluation efforts are often ad-hoc,\nlacking systematic analysis of attack phases and guidance on targeted defenses.\nThis work introduces a novel evaluation framework that addresses these\nlimitations by: (1) examining the end-to-end attack chain, (2) identifying gaps\nin AI threat evaluation, and (3) helping defenders prioritize targeted\nmitigations and conduct AI-enabled adversary emulation for red teaming. Our\napproach adapts existing cyberattack chain frameworks for AI systems. We\nanalyzed over 12,000 real-world instances of AI involvement in cyber incidents,\ncatalogued by Google's Threat Intelligence Group, to curate seven\nrepresentative attack chain archetypes. Through a bottleneck analysis on these\narchetypes, we pinpointed phases most susceptible to AI-driven disruption. We\nthen identified and utilized externally developed cybersecurity model\nevaluations focused on these critical phases. We report on AI's potential to\namplify offensive capabilities across specific attack stages, and offer\nrecommendations for prioritizing defenses. We believe this represents the most\ncomprehensive AI cyber risk evaluation framework published to date.", "AI": {"tldr": "A novel framework evaluates AI's role in cyberattacks, analyzing attack chains, identifying gaps, and guiding defenses.", "motivation": "To systematically assess AI's potential in cyberattacks and improve defenses, addressing current ad-hoc evaluation limitations.", "method": "Adapts cyberattack chain frameworks, analyzes 12,000 AI-involved cyber incidents, and identifies critical attack phases.", "result": "Identifies seven attack chain archetypes, AI-driven disruption phases, and AI's offensive amplification potential.", "conclusion": "The framework offers comprehensive AI cyber risk evaluation and defense prioritization recommendations."}}
{"id": "2406.19711", "pdf": "https://arxiv.org/pdf/2406.19711", "abs": "https://arxiv.org/abs/2406.19711", "authors": ["Ziming Zhao", "Zhenwei Wang", "Tiehua Zhang", "Zhishu Shen", "Hai Dong", "Zhen Lei", "Xingjun Ma", "Gaowei Xu", "Zhijun Ding", "Yun Yang"], "title": "CHASE: A Causal Hypergraph based Framework for Root Cause Analysis in Multimodal Microservice Systems", "categories": ["cs.LG"], "comment": null, "summary": "In recent years, the widespread adoption of distributed microservice\narchitectures within the industry has significantly increased the demand for\nenhanced system availability and robustness. Due to the complex service\ninvocation paths and dependencies in enterprise-level microservice systems, it\nis challenging to locate the anomalies promptly during service invocations,\nthus causing intractable issues for normal system operations and maintenance.\nIn this paper, we propose a Causal Heterogeneous grAph baSed framEwork for root\ncause analysis, namely CHASE, for microservice systems with multimodal data,\nincluding traces, logs, and system monitoring metrics. Specifically, related\ninformation is encoded into representative embeddings and further modeled by a\nmultimodal invocation graph. Following that, anomaly detection is performed on\neach instance node with attentive heterogeneous message passing from its\nadjacent metric and log nodes. Finally, CHASE learns from the constructed\nhypergraph with hyperedges representing the flow of causality and performs root\ncause localization. We evaluate the proposed framework on two public\nmicroservice datasets with distinct attributes and compare with the\nstate-of-the-art methods. The results show that CHASE achieves the average\nperformance gain up to 36.2%(A@1) and 29.4%(Percentage@1), respectively to its\nbest counterpart.", "AI": {"tldr": "CHASE is a framework for root cause analysis in microservice systems using multimodal data (traces, logs, metrics) and a causal heterogeneous graph, outperforming state-of-the-art methods.", "motivation": "The complexity of microservice systems makes anomaly detection and root cause analysis challenging, necessitating a robust solution.", "method": "CHASE encodes multimodal data into embeddings, models them as a graph, detects anomalies, and localizes root causes using a hypergraph with causal flow.", "result": "CHASE outperforms state-of-the-art methods by up to 36.2%(A@1) and 29.4%(Percentage@1) on two datasets.", "conclusion": "CHASE effectively addresses root cause analysis in microservice systems, demonstrating superior performance."}}
{"id": "2504.02812", "pdf": "https://arxiv.org/pdf/2504.02812", "abs": "https://arxiv.org/abs/2504.02812", "authors": ["Van Nguyen Nguyen", "Stephen Tyree", "Andrew Guo", "Mederic Fourmy", "Anas Gouda", "Taeyeop Lee", "Sungphill Moon", "Hyeontae Son", "Lukas Ranftl", "Jonathan Tremblay", "Eric Brachmann", "Bertram Drost", "Vincent Lepetit", "Carsten Rother", "Stan Birchfield", "Jiri Matas", "Yann Labbe", "Martin Sundermeyer", "Tomas Hodan"], "title": "BOP Challenge 2024 on Model-Based and Model-Free 6D Object Pose Estimation", "categories": ["cs.CV"], "comment": "arXiv admin note: text overlap with arXiv:2403.09799", "summary": "We present the evaluation methodology, datasets and results of the BOP\nChallenge 2024, the 6th in a series of public competitions organized to capture\nthe state of the art in 6D object pose estimation and related tasks. In 2024,\nour goal was to transition BOP from lab-like setups to real-world scenarios.\nFirst, we introduced new model-free tasks, where no 3D object models are\navailable and methods need to onboard objects just from provided reference\nvideos. Second, we defined a new, more practical 6D object detection task where\nidentities of objects visible in a test image are not provided as input. Third,\nwe introduced new BOP-H3 datasets recorded with high-resolution sensors and\nAR/VR headsets, closely resembling real-world scenarios. BOP-H3 include 3D\nmodels and onboarding videos to support both model-based and model-free tasks.\nParticipants competed on seven challenge tracks. Notably, the best 2024 method\nfor model-based 6D localization of unseen objects (FreeZeV2.1) achieves 22%\nhigher accuracy on BOP-Classic-Core than the best 2023 method (GenFlow), and is\nonly 4% behind the best 2023 method for seen objects (GPose2023) although being\nsignificantly slower (24.9 vs 2.7s per image). A more practical 2024 method for\nthis task is Co-op which takes only 0.8s per image and is 13% more accurate\nthan GenFlow. Methods have similar rankings on 6D detection as on 6D\nlocalization but higher run time. On model-based 2D detection of unseen\nobjects, the best 2024 method (MUSE) achieves 21--29% relative improvement\ncompared to the best 2023 method (CNOS). However, the 2D detection accuracy for\nunseen objects is still -35% behind the accuracy for seen objects (GDet2023),\nand the 2D detection stage is consequently the main bottleneck of existing\npipelines for 6D localization/detection of unseen objects. The online\nevaluation system stays open and is available at http://bop.felk.cvut.cz/", "AI": {"tldr": "The BOP Challenge 2024 evaluates 6D object pose estimation, introducing model-free tasks, practical 6D detection, and new datasets (BOP-H3) for real-world scenarios. Results show improved accuracy but highlight bottlenecks in 2D detection for unseen objects.", "motivation": "To transition 6D object pose estimation from lab-like setups to real-world scenarios by introducing new tasks and datasets.", "method": "Introduced model-free tasks, practical 6D detection, and BOP-H3 datasets. Evaluated methods across seven challenge tracks.", "result": "Best 2024 methods (FreeZeV2.1, Co-op, MUSE) showed significant accuracy improvements over 2023 methods, though runtime and 2D detection for unseen objects remain challenges.", "conclusion": "The BOP Challenge 2024 advances 6D pose estimation but identifies 2D detection as a key bottleneck for unseen objects."}}
{"id": "2504.02698", "pdf": "https://arxiv.org/pdf/2504.02698", "abs": "https://arxiv.org/abs/2504.02698", "authors": ["Shengrui XU", "Tianchi Lu", "Zikun Wang", "Jixiu Zhai", "Jingwan Wang"], "title": "SCMPPI: Supervised Contrastive Multimodal Framework for Predicting Protein-Protein Interactions", "categories": ["cs.LG", "cs.AI", "q-bio.QM", "92C40, 68T07", "I.2.6; J.3"], "comment": "19 pages,9 figures,conference", "summary": "Protein-protein interaction (PPI) prediction plays a pivotal role in\ndeciphering cellular functions and disease mechanisms. To address the\nlimitations of traditional experimental methods and existing computational\napproaches in cross-modal feature fusion and false-negative suppression, we\npropose SCMPPI-a novel supervised contrastive multimodal framework. By\neffectively integrating sequence-based features (AAC, DPC, ESMC-CKSAAP) with\nnetwork topology (Node2Vec embeddings) and incorporating an enhanced\ncontrastive learning strategy with negative sample filtering, SCMPPI achieves\nsuperior prediction performance. Extensive experiments on eight benchmark\ndatasets demonstrate its state-of-the-art accuracy(98.13%) and AUC(99.69%),\nalong with excellent cross-species generalization (AUC>99%). Successful\napplications in CD9 networks, Wnt pathway analysis, and cancer-specific\nnetworks further highlight its potential for disease target discovery,\nestablishing SCMPPI as a powerful tool for multimodal biological data analysis.", "AI": {"tldr": "SCMPPI is a novel supervised contrastive multimodal framework for PPI prediction, integrating sequence and network features with enhanced contrastive learning, achieving high accuracy and cross-species generalization.", "motivation": "Address limitations of traditional methods in cross-modal feature fusion and false-negative suppression for PPI prediction.", "method": "Integrates sequence-based features (AAC, DPC, ESMC-CKSAAP) with network topology (Node2Vec embeddings) and uses enhanced contrastive learning with negative sample filtering.", "result": "Achieves state-of-the-art accuracy (98.13%) and AUC (99.69%), with strong cross-species generalization (AUC>99%).", "conclusion": "SCMPPI is a powerful tool for multimodal biological data analysis, with demonstrated applications in disease target discovery."}}
{"id": "2409.15267", "pdf": "https://arxiv.org/pdf/2409.15267", "abs": "https://arxiv.org/abs/2409.15267", "authors": ["Shreyas Chaudhari", "Srinivasa Pranav", "Emile Anand", "Jos\u00e9 M. F. Moura"], "title": "Peer-to-Peer Learning Dynamics of Wide Neural Networks", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "Published at IEEE International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP), Hyderabad, India, 2025", "summary": "Peer-to-peer learning is an increasingly popular framework that enables\nbeyond-5G distributed edge devices to collaboratively train deep neural\nnetworks in a privacy-preserving manner without the aid of a central server.\nNeural network training algorithms for emerging environments, e.g., smart\ncities, have many design considerations that are difficult to tune in\ndeployment settings -- such as neural network architectures and\nhyperparameters. This presents a critical need for characterizing the training\ndynamics of distributed optimization algorithms used to train highly nonconvex\nneural networks in peer-to-peer learning environments. In this work, we provide\nan explicit characterization of the learning dynamics of wide neural networks\ntrained using popular distributed gradient descent (DGD) algorithms. Our\nresults leverage both recent advancements in neural tangent kernel (NTK) theory\nand extensive previous work on distributed learning and consensus. We validate\nour analytical results by accurately predicting the parameter and error\ndynamics of wide neural networks trained for classification tasks.", "AI": {"tldr": "The paper analyzes the training dynamics of wide neural networks in peer-to-peer learning environments using distributed gradient descent (DGD) and neural tangent kernel (NTK) theory.", "motivation": "To address the challenges of tuning neural network architectures and hyperparameters in distributed edge environments like smart cities, ensuring privacy and efficiency.", "method": "Leverages NTK theory and distributed learning consensus to characterize the learning dynamics of wide neural networks trained with DGD.", "result": "Provides an explicit characterization of training dynamics, validated by predicting parameter and error dynamics in classification tasks.", "conclusion": "The work successfully bridges NTK theory and distributed learning, offering insights for optimizing peer-to-peer neural network training."}}
{"id": "2504.06116", "pdf": "https://arxiv.org/pdf/2504.06116", "abs": "https://arxiv.org/abs/2504.06116", "authors": ["Davide Sferrazza", "Gabriele Berton", "Gabriele Trivigno", "Carlo Masone"], "title": "To Match or Not to Match: Revisiting Image Matching for Reliable Visual Place Recognition", "categories": ["cs.CV"], "comment": "CVPRW 2025", "summary": "Visual Place Recognition (VPR) is a critical task in computer vision,\ntraditionally enhanced by re-ranking retrieval results with image matching.\nHowever, recent advancements in VPR methods have significantly improved\nperformance, challenging the necessity of re-ranking. In this work, we show\nthat modern retrieval systems often reach a point where re-ranking can degrade\nresults, as current VPR datasets are largely saturated. We propose using image\nmatching as a verification step to assess retrieval confidence, demonstrating\nthat inlier counts can reliably predict when re-ranking is beneficial. Our\nfindings shift the paradigm of retrieval pipelines, offering insights for more\nrobust and adaptive VPR systems. The code is available at\nhttps://github.com/FarInHeight/To-Match-or-Not-to-Match.", "AI": {"tldr": "Modern VPR systems may not benefit from re-ranking due to dataset saturation; image matching can instead verify retrieval confidence.", "motivation": "To challenge the necessity of re-ranking in VPR by showing it can degrade results in saturated datasets.", "method": "Propose using image matching as a verification step to predict when re-ranking is beneficial, based on inlier counts.", "result": "Demonstrates that inlier counts reliably predict re-ranking utility, shifting retrieval pipeline paradigms.", "conclusion": "Offers insights for adaptive VPR systems, reducing reliance on re-ranking when unnecessary."}}
{"id": "2504.09809", "pdf": "https://arxiv.org/pdf/2504.09809", "abs": "https://arxiv.org/abs/2504.09809", "authors": ["Zhimin Li", "Haichao Miao", "Xinyuan Yan", "Valerio Pascucci", "Matthew Berger", "Shusen Liu"], "title": "See or Recall: A Sanity Check for the Role of Vision in Solving Visualization Question Answer Tasks with Multimodal LLMs", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Recent developments in multimodal large language models (MLLM) have equipped\nlanguage models to reason about vision and language jointly. This permits MLLMs\nto both perceive and answer questions about data visualization across a variety\nof designs and tasks. Applying MLLMs to a broad range of visualization tasks\nrequires us to properly evaluate their capabilities, and the most common way to\nconduct evaluation is through measuring a model's visualization reasoning\ncapability, analogous to how we would evaluate human understanding of\nvisualizations (e.g., visualization literacy). However, we found that in the\ncontext of visualization question answering (VisQA), how an MLLM perceives and\nreasons about visualizations can be fundamentally different from how humans\napproach the same problem. During the evaluation, even without visualization,\nthe model could correctly answer a substantial portion of the visualization\ntest questions, regardless of whether any selection options were provided. We\nhypothesize that the vast amount of knowledge encoded in the language model\npermits factual recall that supersedes the need to seek information from the\nvisual signal. It raises concerns that the current VisQA evaluation may not\nfully capture the models' visualization reasoning capabilities. To address\nthis, we propose a comprehensive sanity check framework that integrates a\nrule-based decision tree and a sanity check table to disentangle the effects of\n\"seeing\" (visual processing) and \"recall\" (reliance on prior knowledge). This\nvalidates VisQA datasets for evaluation, highlighting where models are truly\n\"seeing\", positively or negatively affected by the factual recall, or relying\non inductive biases for question answering. Our study underscores the need for\ncareful consideration in designing future visualization understanding studies\nwhen utilizing MLLMs.", "AI": {"tldr": "The paper highlights differences in how MLLMs and humans reason about visualizations, proposing a framework to evaluate true visualization reasoning by disentangling visual processing from prior knowledge reliance.", "motivation": "To address concerns that current VisQA evaluations may not accurately measure MLLMs' visualization reasoning due to their reliance on prior knowledge rather than visual signals.", "method": "Proposes a sanity check framework combining a rule-based decision tree and a sanity check table to separate visual processing ('seeing') from factual recall.", "result": "Found that MLLMs often answer VisQA questions correctly without visual input, indicating reliance on prior knowledge. The framework helps validate datasets by identifying true visualization reasoning.", "conclusion": "Future studies on MLLMs' visualization understanding must carefully design evaluations to distinguish between visual reasoning and prior knowledge reliance."}}
{"id": "2410.22564", "pdf": "https://arxiv.org/pdf/2410.22564", "abs": "https://arxiv.org/abs/2410.22564", "authors": ["Pedro Valdeira", "Shiqiang Wang", "Yuejie Chi"], "title": "Vertical Federated Learning with Missing Features During Training and Inference", "categories": ["cs.LG", "cs.DC", "cs.DS", "math.OC"], "comment": "Accepted to ICLR 2025", "summary": "Vertical federated learning trains models from feature-partitioned datasets\nacross multiple clients, who collaborate without sharing their local data.\nStandard approaches assume that all feature partitions are available during\nboth training and inference. Yet, in practice, this assumption rarely holds, as\nfor many samples only a subset of the clients observe their partition. However,\nnot utilizing incomplete samples during training harms generalization, and not\nsupporting them during inference limits the utility of the model. Moreover, if\nany client leaves the federation after training, its partition becomes\nunavailable, rendering the learned model unusable. Missing feature blocks are\ntherefore a key challenge limiting the applicability of vertical federated\nlearning in real-world scenarios. To address this, we propose LASER-VFL, a\nvertical federated learning method for efficient training and inference of\nsplit neural network-based models that is capable of handling arbitrary sets of\npartitions. Our approach is simple yet effective, relying on the sharing of\nmodel parameters and on task-sampling to train a family of predictors. We show\nthat LASER-VFL achieves a $\\mathcal{O}({1}/{\\sqrt{T}})$ convergence rate for\nnonconvex objectives and, under the Polyak-{\\L}ojasiewicz inequality, it\nachieves linear convergence to a neighborhood of the optimum. Numerical\nexperiments show improved performance of LASER-VFL over the baselines.\nRemarkably, this is the case even in the absence of missing features. For\nexample, for CIFAR-100, we see an improvement in accuracy of $19.3\\%$ when each\nof four feature blocks is observed with a probability of 0.5 and of $9.5\\%$\nwhen all features are observed. The code for this work is available at\nhttps://github.com/Valdeira/LASER-VFL.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2504.09448", "pdf": "https://arxiv.org/pdf/2504.09448", "abs": "https://arxiv.org/abs/2504.09448", "authors": ["Lin Zhu", "Xinbing Wang", "Chenghu Zhou", "Nanyang Ye"], "title": "Bayesian Cross-Modal Alignment Learning for Few-Shot Out-of-Distribution Generalization", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted by AAAI2023", "summary": "Recent advances in large pre-trained models showed promising results in\nfew-shot learning. However, their generalization ability on two-dimensional\nOut-of-Distribution (OoD) data, i.e., correlation shift and diversity shift,\nhas not been thoroughly investigated. Researches have shown that even with a\nsignificant amount of training data, few methods can achieve better performance\nthan the standard empirical risk minimization method (ERM) in OoD\ngeneralization. This few-shot OoD generalization dilemma emerges as a\nchallenging direction in deep neural network generalization research, where the\nperformance suffers from overfitting on few-shot examples and OoD\ngeneralization errors. In this paper, leveraging a broader supervision source,\nwe explore a novel Bayesian cross-modal image-text alignment learning method\n(Bayes-CAL) to address this issue. Specifically, the model is designed as only\ntext representations are fine-tuned via a Bayesian modelling approach with\ngradient orthogonalization loss and invariant risk minimization (IRM) loss. The\nBayesian approach is essentially introduced to avoid overfitting the base\nclasses observed during training and improve generalization to broader unseen\nclasses. The dedicated loss is introduced to achieve better image-text\nalignment by disentangling the causal and non-casual parts of image features.\nNumerical experiments demonstrate that Bayes-CAL achieved state-of-the-art OoD\ngeneralization performances on two-dimensional distribution shifts. Moreover,\ncompared with CLIP-like models, Bayes-CAL yields more stable generalization\nperformances on unseen classes. Our code is available at\nhttps://github.com/LinLLLL/BayesCAL.", "AI": {"tldr": "Bayes-CAL, a Bayesian cross-modal image-text alignment method, improves few-shot OoD generalization by avoiding overfitting and enhancing alignment through gradient orthogonalization and IRM losses.", "motivation": "Investigate and improve the generalization of large pre-trained models on two-dimensional OoD data, addressing overfitting and OoD errors in few-shot learning.", "method": "Bayesian modeling fine-tunes text representations with gradient orthogonalization and IRM losses to disentangle causal and non-causal image features.", "result": "Bayes-CAL achieves state-of-the-art OoD generalization on two-dimensional shifts and outperforms CLIP-like models in stability on unseen classes.", "conclusion": "Bayes-CAL effectively addresses few-shot OoD generalization, offering a robust solution with improved performance and stability."}}
{"id": "2504.09865", "pdf": "https://arxiv.org/pdf/2504.09865", "abs": "https://arxiv.org/abs/2504.09865", "authors": ["Isabel O. Gallegos", "Chen Shani", "Weiyan Shi", "Federico Bianchi", "Izzy Gainsburg", "Dan Jurafsky", "Robb Willer"], "title": "Labeling Messages as AI-Generated Does Not Reduce Their Persuasive Effects", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": null, "summary": "As generative artificial intelligence (AI) enables the creation and\ndissemination of information at massive scale and speed, it is increasingly\nimportant to understand how people perceive AI-generated content. One prominent\npolicy proposal requires explicitly labeling AI-generated content to increase\ntransparency and encourage critical thinking about the information, but prior\nresearch has not yet tested the effects of such labels. To address this gap, we\nconducted a survey experiment (N=1601) on a diverse sample of Americans,\npresenting participants with an AI-generated message about several public\npolicies (e.g., allowing colleges to pay student-athletes), randomly assigning\nwhether participants were told the message was generated by (a) an expert AI\nmodel, (b) a human policy expert, or (c) no label. We found that messages were\ngenerally persuasive, influencing participants' views of the policies by 9.74\npercentage points on average. However, while 94.6% of participants assigned to\nthe AI and human label conditions believed the authorship labels, labels had no\nsignificant effects on participants' attitude change toward the policies,\njudgments of message accuracy, nor intentions to share the message with others.\nThese patterns were robust across a variety of participant characteristics,\nincluding prior knowledge of the policy, prior experience with AI, political\nparty, education level, or age. Taken together, these results imply that, while\nauthorship labels would likely enhance transparency, they are unlikely to\nsubstantially affect the persuasiveness of the labeled content, highlighting\nthe need for alternative strategies to address challenges posed by AI-generated\ninformation.", "AI": {"tldr": "Labels on AI-generated content don't significantly affect persuasiveness, despite high belief in the labels.", "motivation": "To test the impact of labeling AI-generated content on public perception and behavior.", "method": "Survey experiment (N=1601) with random assignment of authorship labels (AI, human, none) for policy messages.", "result": "Labels had no significant effect on attitude change, message accuracy judgments, or sharing intentions.", "conclusion": "Labels enhance transparency but don't reduce persuasiveness; alternative strategies are needed for AI-generated content challenges."}}
{"id": "2411.06500", "pdf": "https://arxiv.org/pdf/2411.06500", "abs": "https://arxiv.org/abs/2411.06500", "authors": ["Agatha Schmidt", "Henrik Zunker", "Alexander Heinlein", "Martin J. K\u00fchn"], "title": "Graph Neural Network Surrogates to leverage Mechanistic Expert Knowledge towards Reliable and Immediate Pandemic Response", "categories": ["cs.LG", "q-bio.PE", "68T07, 92B20, 92B05"], "comment": "27 pages, 9 figures", "summary": "During the COVID-19 crisis, mechanistic models have guided evidence-based\ndecision making. However, time-critical decisions in a dynamical environment\nlimit the time available to gather supporting evidence. Infectious disease\ndynamics are often heterogeneous on a spatial or demographic scale, requiring\nappropriately resolved models. In addition, with a large number of potential\ninterventions, all scenarios can barely be computed on time, even when using\nsupercomputing facilities. We suggest to couple complex mechanistic models with\ndata-driven surrogate models to allow for on-the-fly model adaptations by\npublic health experts and decision makers. We build upon a spatially and\ndemographically resolved infectious disease metapopulation model and train a\ngraph neural network for data sets representing prevaccination phases of a\npandemic. The resulting networks reached an execution time of a fraction of a\nsecond, a speeding up the metapopulation up to four orders of magnitude. The\napproach yields large potential for on-the-fly execution and, thus, facilitates\nintegration into low-barrier web applications for use in pandemic\ndecision-making.", "AI": {"tldr": "The paper proposes coupling complex mechanistic models with data-driven surrogate models, like graph neural networks, to speed up pandemic decision-making by enabling rapid, on-the-fly adaptations.", "motivation": "Time-critical decisions during COVID-19 require fast, adaptable models for heterogeneous infectious disease dynamics, but traditional models are computationally slow.", "method": "A graph neural network is trained on data from a spatially and demographically resolved metapopulation model to create a surrogate model.", "result": "The surrogate model speeds up execution by up to four orders of magnitude, enabling near-instantaneous results.", "conclusion": "This approach facilitates low-barrier integration into web applications for real-time pandemic decision-making."}}
{"id": "2504.10852", "pdf": "https://arxiv.org/pdf/2504.10852", "abs": "https://arxiv.org/abs/2504.10852", "authors": ["Pengxiao Han", "Changkun Ye", "Jinguang Tong", "Cuicui Jiang", "Jie Hong", "Li Fang", "Xuesong Li"], "title": "Enhancing Features in Long-tailed Data Using Large Vision Model", "categories": ["cs.CV"], "comment": null, "summary": "Language-based foundation models, such as large language models (LLMs) or\nlarge vision-language models (LVLMs), have been widely studied in long-tailed\nrecognition. However, the need for linguistic data is not applicable to all\npractical tasks. In this study, we aim to explore using large vision models\n(LVMs) or visual foundation models (VFMs) to enhance long-tailed data features\nwithout any language information. Specifically, we extract features from the\nLVM and fuse them with features in the baseline network's map and latent space\nto obtain the augmented features. Moreover, we design several prototype-based\nlosses in the latent space to further exploit the potential of the augmented\nfeatures. In the experimental section, we validate our approach on two\nbenchmark datasets: ImageNet-LT and iNaturalist2018.", "AI": {"tldr": "The paper explores using large vision models (LVMs) to enhance long-tailed recognition without relying on language data, achieving improved performance on benchmark datasets.", "motivation": "Language-based models are not always practical for tasks lacking linguistic data, prompting the need for vision-only solutions.", "method": "Features from LVMs are fused with baseline network features, and prototype-based losses are designed to optimize augmented features.", "result": "The approach is validated on ImageNet-LT and iNaturalist2018, showing enhanced performance.", "conclusion": "LVMs can effectively improve long-tailed recognition without language data, offering a viable alternative to language-based models."}}
{"id": "2504.13945", "pdf": "https://arxiv.org/pdf/2504.13945", "abs": "https://arxiv.org/abs/2504.13945", "authors": ["Zhanglin Wu", "Tengfei Song", "Ning Xie", "Weidong Zhang", "Mengli Zhu", "Shuang Wu", "Shiliang Sun", "Hao Yang"], "title": "Evaluating Menu OCR and Translation: A Benchmark for Aligning Human and Automated Evaluations in Large Vision-Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 5 figures, 5 Tables", "summary": "The rapid advancement of large vision-language models (LVLMs) has\nsignificantly propelled applications in document understanding, particularly in\noptical character recognition (OCR) and multilingual translation. However,\ncurrent evaluations of LVLMs, like the widely used OCRBench, mainly focus on\nverifying the correctness of their short-text responses and long-text responses\nwith simple layout, while the evaluation of their ability to understand long\ntexts with complex layout design is highly significant but largely overlooked.\nIn this paper, we propose Menu OCR and Translation Benchmark (MOTBench), a\nspecialized evaluation framework emphasizing the pivotal role of menu\ntranslation in cross-cultural communication. MOTBench requires LVLMs to\naccurately recognize and translate each dish, along with its price and unit\nitems on a menu, providing a comprehensive assessment of their visual\nunderstanding and language processing capabilities. Our benchmark is comprised\nof a collection of Chinese and English menus, characterized by intricate\nlayouts, a variety of fonts, and culturally specific elements across different\nlanguages, along with precise human annotations. Experiments show that our\nautomatic evaluation results are highly consistent with professional human\nevaluation. We evaluate a range of publicly available state-of-the-art LVLMs,\nand through analyzing their output to identify the strengths and weaknesses in\ntheir performance, offering valuable insights to guide future advancements in\nLVLM development. MOTBench is available at https://github.com/gitwzl/MOTBench.", "AI": {"tldr": "The paper introduces MOTBench, a benchmark for evaluating large vision-language models (LVLMs) on menu translation tasks, addressing the gap in assessing complex layout understanding.", "motivation": "Current LVLM evaluations focus on simple layouts, overlooking complex designs like menus, which are crucial for cross-cultural communication.", "method": "MOTBench uses Chinese and English menus with intricate layouts, fonts, and cultural elements, requiring LVLMs to recognize and translate dish details accurately.", "result": "Automatic evaluations align closely with human assessments, revealing strengths and weaknesses in state-of-the-art LVLMs.", "conclusion": "MOTBench provides a specialized tool to advance LVLM development by addressing complex layout understanding in document tasks."}}
{"id": "2411.07729", "pdf": "https://arxiv.org/pdf/2411.07729", "abs": "https://arxiv.org/abs/2411.07729", "authors": ["Sungyoon Kim", "Aaron Mishkin", "Mert Pilanci"], "title": "Exploring the loss landscape of regularized neural networks via convex duality", "categories": ["cs.LG"], "comment": "Updated accepted version", "summary": "We discuss several aspects of the loss landscape of regularized neural\nnetworks: the structure of stationary points, connectivity of optimal\nsolutions, path with nonincreasing loss to arbitrary global optimum, and the\nnonuniqueness of optimal solutions, by casting the problem into an equivalent\nconvex problem and considering its dual. Starting from two-layer neural\nnetworks with scalar output, we first characterize the solution set of the\nconvex problem using its dual and further characterize all stationary points.\nWith the characterization, we show that the topology of the global optima goes\nthrough a phase transition as the width of the network changes, and construct\ncounterexamples where the problem may have a continuum of optimal solutions.\nFinally, we show that the solution set characterization and connectivity\nresults can be extended to different architectures, including two-layer\nvector-valued neural networks and parallel three-layer neural networks.", "AI": {"tldr": "The paper explores the loss landscape of regularized neural networks, focusing on stationary points, connectivity of solutions, and nonuniqueness of optima by leveraging convex duality. It reveals phase transitions in optima topology with network width and extends findings to various architectures.", "motivation": "To understand the structure and properties of the loss landscape in regularized neural networks, particularly the behavior of stationary points and optimal solutions.", "method": "The problem is cast into an equivalent convex problem using duality. Analysis starts with two-layer scalar-output networks, then extends to vector-valued and three-layer networks.", "result": "Characterization of stationary points and solution sets, phase transitions in optima topology with network width, and examples of continuum optimal solutions.", "conclusion": "The findings generalize to diverse architectures, providing insights into the loss landscape and connectivity of optimal solutions in neural networks."}}
{"id": "2504.10972", "pdf": "https://arxiv.org/pdf/2504.10972", "abs": "https://arxiv.org/abs/2504.10972", "authors": ["Yihang Liu", "Lianghua He", "Ying Wen", "Longzhen Yang", "Hongzhou Chen"], "title": "AFiRe: Anatomy-Driven Self-Supervised Learning for Fine-Grained Representation in Radiographic Images", "categories": ["cs.CV"], "comment": null, "summary": "Current self-supervised methods, such as contrastive learning, predominantly\nfocus on global discrimination, neglecting the critical fine-grained anatomical\ndetails required for accurate radiographic analysis. To address this challenge,\nwe propose an Anatomy-driven self-supervised framework for enhancing\nFine-grained Representation in radiographic image analysis (AFiRe). The core\nidea of AFiRe is to align the anatomical consistency with the unique\ntoken-processing characteristics of Vision Transformer. Specifically, AFiRe\nsynergistically performs two self-supervised schemes: (i) Token-wise\nanatomy-guided contrastive learning, which aligns image tokens based on\nstructural and categorical consistency, thereby enhancing fine-grained\nspatial-anatomical discrimination; (ii) Pixel-level anomaly-removal\nrestoration, which particularly focuses on local anomalies, thereby refining\nthe learned discrimination with detailed geometrical information. Additionally,\nwe propose Synthetic Lesion Mask to enhance anatomical diversity while\npreserving intra-consistency, which is typically corrupted by traditional data\naugmentations, such as Cropping and Affine transformations. Experimental\nresults show that AFiRe: (i) provides robust anatomical discrimination,\nachieving more cohesive feature clusters compared to state-of-the-art\ncontrastive learning methods; (ii) demonstrates superior generalization,\nsurpassing 7 radiography-specific self-supervised methods in multi-label\nclassification tasks with limited labeling; and (iii) integrates fine-grained\ninformation, enabling precise anomaly detection using only image-level\nannotations.", "AI": {"tldr": "AFiRe is a self-supervised framework for radiographic image analysis, enhancing fine-grained anatomical details through token-wise contrastive learning and pixel-level anomaly removal, outperforming existing methods.", "motivation": "Current self-supervised methods lack focus on fine-grained anatomical details crucial for radiographic analysis, prompting the need for AFiRe.", "method": "AFiRe combines token-wise anatomy-guided contrastive learning and pixel-level anomaly-removal restoration, along with Synthetic Lesion Mask for anatomical diversity.", "result": "AFiRe achieves robust anatomical discrimination, superior generalization in multi-label classification, and precise anomaly detection with limited labels.", "conclusion": "AFiRe effectively integrates fine-grained anatomical details, outperforming state-of-the-art methods in radiographic image analysis."}}
{"id": "2504.14320", "pdf": "https://arxiv.org/pdf/2504.14320", "abs": "https://arxiv.org/abs/2504.14320", "authors": ["Nimisha Karnatak", "Adrien Baranes", "Rob Marchant", "Huinan Zeng", "Tr\u00edona Butler", "Kristen Olson"], "title": "Expanding the Generative AI Design Space through Structured Prompting and Multimodal Interfaces", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted at CHI'25 Workshop on Designing and Developing User\n  Interfaces with AI", "summary": "Text-based prompting remains the predominant interaction paradigm in\ngenerative AI, yet it often introduces friction for novice users such as small\nbusiness owners (SBOs), who struggle to articulate creative goals in\ndomain-specific contexts like advertising. Through a formative study with six\nSBOs in the United Kingdom, we identify three key challenges: difficulties in\nexpressing brand intuition through prompts, limited opportunities for\nfine-grained adjustment and refinement during and after content generation, and\nthe frequent production of generic content that lacks brand specificity. In\nresponse, we present ACAI (AI Co-Creation for Advertising and Inspiration), a\nmultimodal generative AI tool designed to support novice designers by moving\nbeyond traditional prompt interfaces. ACAI features a structured input system\ncomposed of three panels: Branding, Audience and Goals, and the Inspiration\nBoard. These inputs allow users to convey brand-relevant context and visual\npreferences. This work contributes to HCI research on generative systems by\nshowing how structured interfaces can foreground user-defined context, improve\nalignment, and enhance co-creative control in novice creative workflows.", "AI": {"tldr": "ACAI is a multimodal AI tool addressing novice users' struggles with text-based prompting in generative AI, offering structured input for better brand-specific content creation.", "motivation": "Text-based prompting in generative AI creates friction for novice users like small business owners (SBOs), who struggle to articulate creative goals in domain-specific contexts like advertising.", "method": "Developed ACAI, a tool with a structured input system (Branding, Audience and Goals, Inspiration Board) to convey brand context and visual preferences.", "result": "ACAI improves alignment, co-creative control, and brand specificity in content generation for novice users.", "conclusion": "Structured interfaces like ACAI enhance novice creative workflows by foregrounding user-defined context and reducing reliance on text prompts."}}
{"id": "2412.04404", "pdf": "https://arxiv.org/pdf/2412.04404", "abs": "https://arxiv.org/abs/2412.04404", "authors": ["Tom Overman", "Diego Klabjan"], "title": "Federated Automated Feature Engineering", "categories": ["cs.LG", "cs.DC"], "comment": "Preliminary Work", "summary": "Automated feature engineering (AutoFE) is used to automatically create new\nfeatures from original features to improve predictive performance without\nneeding significant human intervention and domain expertise. Many algorithms\nexist for AutoFE, but very few approaches exist for the federated learning (FL)\nsetting where data is gathered across many clients and is not shared between\nclients or a central server. We introduce AutoFE algorithms for the horizontal,\nvertical, and hybrid FL settings, which differ in how the data is gathered\nacross clients. To the best of our knowledge, we are the first to develop\nAutoFE algorithms for the horizontal and hybrid FL cases, and we show that the\ndownstream test scores of our federated AutoFE algorithms is close in\nperformance to the case where data is held centrally and AutoFE is performed\ncentrally.", "AI": {"tldr": "The paper introduces AutoFE algorithms for federated learning (FL) settings, including horizontal, vertical, and hybrid FL, achieving performance close to centralized AutoFE.", "motivation": "Existing AutoFE methods lack solutions for FL settings where data is distributed across clients without sharing.", "method": "Developed AutoFE algorithms for horizontal, vertical, and hybrid FL settings.", "result": "Federated AutoFE algorithms perform nearly as well as centralized AutoFE.", "conclusion": "The work pioneers AutoFE for FL, bridging the gap between distributed and centralized feature engineering."}}
{"id": "2504.12157", "pdf": "https://arxiv.org/pdf/2504.12157", "abs": "https://arxiv.org/abs/2504.12157", "authors": ["Xiaojun Ye", "Chun Wang", "Yiren Song", "Sheng Zhou", "Liangcheng Li", "Jiajun Bu"], "title": "FocusedAD: Character-centric Movie Audio Description", "categories": ["cs.CV", "I.2.10"], "comment": "Code and Demo link: https://github.com/Thorin215/FocusedAD", "summary": "Movie Audio Description (AD) aims to narrate visual content during\ndialogue-free segments, particularly benefiting blind and visually impaired\n(BVI) audiences. Compared with general video captioning, AD demands\nplot-relevant narration with explicit character name references, posing unique\nchallenges in movie understanding.To identify active main characters and focus\non storyline-relevant regions, we propose FocusedAD, a novel framework that\ndelivers character-centric movie audio descriptions. It includes: (i) a\nCharacter Perception Module(CPM) for tracking character regions and linking\nthem to names; (ii) a Dynamic Prior Module(DPM) that injects contextual cues\nfrom prior ADs and subtitles via learnable soft prompts; and (iii) a Focused\nCaption Module(FCM) that generates narrations enriched with plot-relevant\ndetails and named characters. To overcome limitations in character\nidentification, we also introduce an automated pipeline for building character\nquery banks. FocusedAD achieves state-of-the-art performance on multiple\nbenchmarks, including strong zero-shot results on MAD-eval-Named and our newly\nproposed Cinepile-AD dataset. Code and data will be released at\nhttps://github.com/Thorin215/FocusedAD .", "AI": {"tldr": "FocusedAD is a novel framework for generating character-centric movie audio descriptions (AD) by tracking characters, using contextual cues, and enriching narrations with plot-relevant details. It outperforms benchmarks and includes tools for automated character identification.", "motivation": "Movie AD must narrate visual content for BVI audiences, requiring plot-relevant narration with character names, which poses unique challenges in movie understanding.", "method": "FocusedAD includes a Character Perception Module (CPM) for character tracking, a Dynamic Prior Module (DPM) for contextual cues, and a Focused Caption Module (FCM) for enriched narrations. An automated pipeline builds character query banks.", "result": "FocusedAD achieves state-of-the-art performance on benchmarks like MAD-eval-Named and the new Cinepile-AD dataset, with strong zero-shot results.", "conclusion": "FocusedAD effectively addresses the challenges of character-centric AD, offering a robust solution with superior performance and automated character identification tools."}}
{"id": "2504.14411", "pdf": "https://arxiv.org/pdf/2504.14411", "abs": "https://arxiv.org/abs/2504.14411", "authors": ["Xiang Zhang", "Yongfeng Zhang"], "title": "Planet as a Brain: Towards Internet of AgentSites based on AIOS Server", "categories": ["cs.NI", "cs.AI"], "comment": null, "summary": "The internet is undergoing a historical transformation from the \"Internet of\nWebsites\" to the \"Internet of AgentSites.\" While traditional Websites served as\nthe foundation for information hosting and dissemination, a new frontier is\nemerging where AgentSites serve as the hubs of the internet, where each\nAgentSite hosts one or more AI agents that receive tasks, address them, and\ndeliver actionable solutions, marking a significant shift in the digital\nlandscape and representing the next generation of online ecosystems. Under this\nvision, AIOS, the AI Agent Operating System, serves as the server for the\ndevelopment, deployment and execution of AI agents, which is a fundamental\ninfrastructure for the Internet of Agentsites.\n  In this paper, we introduce AIOS Server, a runtime framework to host agents\nand enable global-scale collaboration among decentralized agents. AIOS Server\nprovides a communication protocol leveraging the Model Context Protocol (MCP)\nand JSON-RPC to enable agent-agent or human-agent interactions. Each AIOS node\noperates as a server to host and execute agents, while supporting peer-to-peer\ncoordination without reliance on centralized orchestration. Based on AIOS\nServer, we further present the world's first practically deployed Internet of\nAgentsites (AIOS-IoA), including AgentHub for agent registration and discovery\nand AgentChat for interactive communication, at https://planet.aios.foundation.\nThe agent discovery mechanism based on Distributed Hash Tables (DHT) and a\nGossip protocol serves as the search engine for the internet of agentsites.\nThis work provides a practical foundation for building the Internet of\nAgentsites-a new paradigm where autonomous agents become first-class citizens\nof the web. The implementation is available at\nhttps://github.com/agiresearch/AIOS.Server and will be integrated into the AIOS\nmain branch at https://github.com/agiresearch/AIOS.", "AI": {"tldr": "The paper introduces AIOS Server, a framework for hosting AI agents and enabling decentralized collaboration, marking a shift from traditional websites to an 'Internet of AgentSites.'", "motivation": "The internet is evolving from hosting static websites to dynamic AI-driven AgentSites, requiring a new infrastructure for agent development and collaboration.", "method": "AIOS Server uses Model Context Protocol (MCP) and JSON-RPC for agent-agent/human-agent interactions, with peer-to-peer coordination and no centralized control. It includes AgentHub for agent discovery and AgentChat for communication.", "result": "The paper presents AIOS-IoA, the first deployed Internet of AgentSites, with a DHT and Gossip protocol-based discovery mechanism.", "conclusion": "AIOS Server provides a practical foundation for the Internet of AgentSites, making autonomous agents central to the web."}}
{"id": "2412.17908", "pdf": "https://arxiv.org/pdf/2412.17908", "abs": "https://arxiv.org/abs/2412.17908", "authors": ["Orson Mengara"], "title": "Trading Devil RL: Backdoor attack via Stock market, Bayesian Optimization and Reinforcement Learning", "categories": ["cs.LG", "cs.CE", "physics.comp-ph", "physics.soc-ph"], "comment": "End of data poisoning research!: Navier-stokes equations (3D;\n  update); Reinforcement Learning (RL); HFT (High Frequency Trading); Limit\n  Order Markets and backdoor attack detection", "summary": "With the rapid development of generative artificial intelligence,\nparticularly large language models a number of sub-fields of deep learning have\nmade significant progress and are now very useful in everyday applications. For\nexample,financial institutions simulate a wide range of scenarios for various\nmodels created by their research teams using reinforcement learning, both\nbefore production and after regular operations. In this work, we propose a\nbackdoor attack that focuses solely on data poisoning and a method of detection\nby dynamic systems and statistical analysis of the distribution of data. This\nparticular backdoor attack is classified as an attack without prior\nconsideration or trigger, and we name it FinanceLLMsBackRL. Our aim is to\nexamine the potential effects of large language models that use reinforcement\nlearning systems for text production or speech recognition, finance, physics,\nor the ecosystem of contemporary artificial intelligence models.", "AI": {"tldr": "Proposes a backdoor attack (FinanceLLMsBackRL) targeting data poisoning in financial AI models, with detection via dynamic systems and statistical analysis.", "motivation": "To explore the impact of backdoor attacks on large language models using reinforcement learning in finance and other fields.", "method": "Focuses on data poisoning and employs dynamic systems and statistical analysis for detection.", "result": "Introduces FinanceLLMsBackRL, a backdoor attack without prior triggers, highlighting vulnerabilities in AI models.", "conclusion": "Emphasizes the need for robust detection methods to safeguard AI systems in finance and beyond."}}
{"id": "2504.14348", "pdf": "https://arxiv.org/pdf/2504.14348", "abs": "https://arxiv.org/abs/2504.14348", "authors": ["Le Wang", "Zonghao Ying", "Tianyuan Zhang", "Siyuan Liang", "Shengshan Hu", "Mingchuan Zhang", "Aishan Liu", "Xianglong Liu"], "title": "Manipulating Multimodal Agents via Cross-Modal Prompt Injection", "categories": ["cs.CV"], "comment": "17 pages, 5 figures", "summary": "The emergence of multimodal large language models has redefined the agent\nparadigm by integrating language and vision modalities with external data\nsources, enabling agents to better interpret human instructions and execute\nincreasingly complex tasks. However, in this work, we identify a critical yet\npreviously overlooked security vulnerability in multimodal agents: cross-modal\nprompt injection attacks. To exploit this vulnerability, we propose\nCrossInject, a novel attack framework in which attackers embed adversarial\nperturbations across multiple modalities to align with target malicious\ncontent, allowing external instructions to hijack the agent's decision-making\nprocess and execute unauthorized tasks. Our approach consists of two key\ncomponents. First, we introduce Visual Latent Alignment, where we optimize\nadversarial features to the malicious instructions in the visual embedding\nspace based on a text-to-image generative model, ensuring that adversarial\nimages subtly encode cues for malicious task execution. Subsequently, we\npresent Textual Guidance Enhancement, where a large language model is leveraged\nto infer the black-box defensive system prompt through adversarial meta\nprompting and generate an malicious textual command that steers the agent's\noutput toward better compliance with attackers' requests. Extensive experiments\ndemonstrate that our method outperforms existing injection attacks, achieving\nat least a +26.4% increase in attack success rates across diverse tasks.\nFurthermore, we validate our attack's effectiveness in real-world multimodal\nautonomous agents, highlighting its potential implications for safety-critical\napplications.", "AI": {"tldr": "CrossInject is a novel attack framework exploiting cross-modal prompt injection vulnerabilities in multimodal agents, achieving high success rates by aligning adversarial perturbations across modalities.", "motivation": "The paper addresses a critical security vulnerability in multimodal agents\u2014cross-modal prompt injection attacks\u2014previously overlooked, which can hijack agents' decision-making.", "method": "The approach involves Visual Latent Alignment to optimize adversarial visual features and Textual Guidance Enhancement to generate malicious commands using a large language model.", "result": "The method outperforms existing attacks with a +26.4% increase in success rates and proves effective in real-world autonomous agents.", "conclusion": "The work highlights significant security risks in multimodal agents, urging the need for robust defenses against cross-modal prompt injection."}}
{"id": "2504.15041", "pdf": "https://arxiv.org/pdf/2504.15041", "abs": "https://arxiv.org/abs/2504.15041", "authors": ["Shiben Liu", "Huijie Fan", "Qiang Wang", "Baojie Fan", "Yandong Tang", "Liangqiong Qu"], "title": "Distribution-aware Forgetting Compensation for Exemplar-Free Lifelong Person Re-identification", "categories": ["cs.CV", "cs.AI"], "comment": "12 pages, 5 figures", "summary": "Lifelong Person Re-identification (LReID) suffers from a key challenge in\npreserving old knowledge while adapting to new information. The existing\nsolutions include rehearsal-based and rehearsal-free methods to address this\nchallenge. Rehearsal-based approaches rely on knowledge distillation,\ncontinuously accumulating forgetting during the distillation process.\nRehearsal-free methods insufficiently learn the distribution of each domain,\nleading to forgetfulness over time. To solve these issues, we propose a novel\nDistribution-aware Forgetting Compensation (DAFC) model that explores\ncross-domain shared representation learning and domain-specific distribution\nintegration without using old exemplars or knowledge distillation. We propose a\nText-driven Prompt Aggregation (TPA) that utilizes text features to enrich\nprompt elements and guide the prompt model to learn fine-grained\nrepresentations for each instance. This can enhance the differentiation of\nidentity information and establish the foundation for domain distribution\nawareness. Then, Distribution-based Awareness and Integration (DAI) is designed\nto capture each domain-specific distribution by a dedicated expert network and\nadaptively consolidate them into a shared region in high-dimensional space. In\nthis manner, DAI can consolidate and enhance cross-domain shared representation\nlearning while alleviating catastrophic forgetting. Furthermore, we develop a\nKnowledge Consolidation Mechanism (KCM) that comprises instance-level\ndiscrimination and cross-domain consistency alignment strategies to facilitate\nmodel adaptive learning of new knowledge from the current domain and promote\nknowledge consolidation learning between acquired domain-specific\ndistributions, respectively. Experimental results show that our DAFC\noutperforms state-of-the-art methods. Our code is available at\nhttps://github.com/LiuShiBen/DAFC.", "AI": {"tldr": "The paper proposes a Distribution-aware Forgetting Compensation (DAFC) model for Lifelong Person Re-identification (LReID), addressing forgetting issues without old exemplars or knowledge distillation. It introduces Text-driven Prompt Aggregation (TPA) and Distribution-based Awareness and Integration (DAI) to enhance cross-domain learning and reduce forgetting.", "motivation": "Existing methods for LReID either rely on rehearsal-based approaches (prone to forgetting) or rehearsal-free methods (insufficient domain learning). The goal is to overcome these limitations by developing a model that integrates cross-domain shared representation and domain-specific distributions.", "method": "The DAFC model uses TPA to enrich prompts with text features for fine-grained instance learning and DAI to capture and integrate domain-specific distributions. A Knowledge Consolidation Mechanism (KCM) further aids adaptive learning and knowledge consolidation.", "result": "Experimental results demonstrate that DAFC outperforms state-of-the-art methods in LReID.", "conclusion": "The proposed DAFC model effectively addresses forgetting in LReID by leveraging cross-domain shared learning and domain-specific distribution integration, achieving superior performance."}}
{"id": "2501.05842", "pdf": "https://arxiv.org/pdf/2501.05842", "abs": "https://arxiv.org/abs/2501.05842", "authors": ["Bendeg\u00faz M. Gy\u00f6r\u00f6k", "Jan H. Hoekstra", "Johan Kon", "Tam\u00e1s P\u00e9ni", "Maarten Schoukens", "Roland T\u00f3th"], "title": "Orthogonal projection-based regularization for efficient model augmentation", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "Accepted for L4DC 2025", "summary": "Deep-learning-based nonlinear system identification has shown the ability to\nproduce reliable and highly accurate models in practice. However, these\nblack-box models lack physical interpretability, and a considerable part of the\nlearning effort is often spent on capturing already expected/known behavior of\nthe system, that can be accurately described by first-principles laws of\nphysics. A potential solution is to directly integrate such prior physical\nknowledge into the model structure, combining the strengths of physics-based\nmodeling and deep-learning-based identification. The most common approach is to\nuse an additive model augmentation structure, where the physics-based and the\nmachine-learning (ML) components are connected in parallel, i.e., additively.\nHowever, such models are overparametrized, training them is challenging,\npotentially causing the physics-based part to lose interpretability. To\novercome this challenge, this paper proposes an orthogonal projection-based\nregularization technique to enhance parameter learning and even model accuracy\nin learning-based augmentation of nonlinear baseline models.", "AI": {"tldr": "The paper proposes an orthogonal projection-based regularization technique to improve parameter learning and model accuracy in deep-learning-augmented nonlinear system identification, addressing overparametrization and interpretability issues.", "motivation": "Deep-learning models lack physical interpretability and often waste effort on known system behaviors. Integrating prior physics knowledge can combine the strengths of physics-based and data-driven modeling.", "method": "The paper introduces an orthogonal projection-based regularization technique for additive model augmentation, where physics-based and ML components are connected in parallel.", "result": "The proposed technique enhances parameter learning and model accuracy while preserving the interpretability of the physics-based component.", "conclusion": "The orthogonal projection-based regularization effectively addresses challenges in training overparametrized models, improving both performance and interpretability."}}
{"id": "2504.14621", "pdf": "https://arxiv.org/pdf/2504.14621", "abs": "https://arxiv.org/abs/2504.14621", "authors": ["Zhenkui Yang", "Zeyi Huang", "Ge Wang", "Han Ding", "Tony Xiao Han", "Fei Wang"], "title": "Talk is Not Always Cheap: Promoting Wireless Sensing Models with Text Prompts", "categories": ["cs.CV"], "comment": "10 pages", "summary": "Wireless signal-based human sensing technologies, such as WiFi,\nmillimeter-wave (mmWave) radar, and Radio Frequency Identification (RFID),\nenable the detection and interpretation of human presence, posture, and\nactivities, thereby providing critical support for applications in public\nsecurity, healthcare, and smart environments. These technologies exhibit\nnotable advantages due to their non-contact operation and environmental\nadaptability; however, existing systems often fail to leverage the textual\ninformation inherent in datasets. To address this, we propose an innovative\ntext-enhanced wireless sensing framework, WiTalk, that seamlessly integrates\nsemantic knowledge through three hierarchical prompt strategies-label-only,\nbrief description, and detailed action description-without requiring\narchitectural modifications or incurring additional data costs. We rigorously\nvalidate this framework across three public benchmark datasets: XRF55 for human\naction recognition (HAR), and WiFiTAL and XRFV2 for WiFi temporal action\nlocalization (TAL). Experimental results demonstrate significant performance\nimprovements: on XRF55, accuracy for WiFi, RFID, and mmWave increases by 3.9%,\n2.59%, and 0.46%, respectively; on WiFiTAL, the average performance of WiFiTAD\nimproves by 4.98%; and on XRFV2, the mean average precision gains across\nvarious methods range from 4.02% to 13.68%. Our codes have been included in\nhttps://github.com/yangzhenkui/WiTalk.", "AI": {"tldr": "WiTalk is a text-enhanced wireless sensing framework that integrates semantic knowledge via hierarchical prompts, improving performance in human action recognition and localization without extra data costs.", "motivation": "Existing wireless sensing systems lack utilization of textual information in datasets, limiting their potential. WiTalk addresses this gap by incorporating semantic knowledge.", "method": "WiTalk uses three hierarchical prompt strategies (label-only, brief description, detailed action description) to integrate textual data without modifying architectures or adding data costs.", "result": "WiTalk shows significant improvements: 3.9% accuracy boost on XRF55 (WiFi), 4.98% on WiFiTAL, and 4.02%-13.68% mean average precision on XRFV2.", "conclusion": "WiTalk effectively enhances wireless sensing performance by leveraging textual information, demonstrating its potential for applications in security, healthcare, and smart environments."}}
{"id": "2501.11268", "pdf": "https://arxiv.org/pdf/2501.11268", "abs": "https://arxiv.org/abs/2501.11268", "authors": ["Ahmad Mousavi", "Ramin Zandvakili"], "title": "Sparse L0-norm based Kernel-free Quadratic Surface Support Vector Machines", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Kernel-free quadratic surface support vector machine (SVM) models have gained\nsignificant attention in machine learning. However, introducing a quadratic\nclassifier increases the model's complexity by quadratically expanding the\nnumber of parameters relative to the dimensionality of the data, exacerbating\noverfitting. Hence, we propose sparse $\\ell_0$-norm based Kernel-free quadratic\nsurface SVMs, designed to mitigate overfitting and enhance interpretability.\nGiven the intractable nature of these models, we present a penalty\ndecomposition algorithm to obtain first-order optimality points efficiently. We\ndemonstrate that the subproblems in our framework either admit closed-form\nsolutions or can leverage duality theory to improve computational efficiency.\nThrough empirical evaluations on real-world datasets, we demonstrate the\nefficacy and robustness of our approach, showcasing its potential to advance\nKernel-free quadratic surface SVMs in practical applications while addressing\noverfitting concerns. All the implemented models and experiment codes are\navailable at https://github.com/raminzandvakili/L0-QSVM.", "AI": {"tldr": "Proposes a sparse \u2113\u2080-norm based Kernel-free quadratic SVM to reduce overfitting and improve interpretability, using a penalty decomposition algorithm for efficient optimization.", "motivation": "Addressing overfitting and complexity in Kernel-free quadratic SVMs due to quadratic parameter expansion.", "method": "Sparse \u2113\u2080-norm regularization with a penalty decomposition algorithm for efficient optimization, leveraging closed-form solutions and duality theory.", "result": "Empirical evaluations show efficacy and robustness in mitigating overfitting while maintaining performance.", "conclusion": "The approach advances Kernel-free quadratic SVMs by balancing complexity and interpretability, with practical applicability demonstrated."}}
{"id": "2504.14658", "pdf": "https://arxiv.org/pdf/2504.14658", "abs": "https://arxiv.org/abs/2504.14658", "authors": ["Jing Zhang", "Dan Guo", "Zhangbin Li", "Meng Wang"], "title": "EmoSEM: Segment and Explain Emotion Stimuli in Visual Art", "categories": ["cs.CV"], "comment": null, "summary": "This paper focuses on a key challenge in visual art understanding: given an\nart image, the model pinpoints pixel regions that trigger a specific human\nemotion, and generates linguistic explanations for the emotional arousal.\nDespite recent advances in art understanding, pixel-level emotion understanding\nstill faces a dual challenge: first, the subjectivity of emotion makes it\ndifficult for general segmentation models like SAM to adapt to emotion-oriented\nsegmentation tasks; and second, the abstract nature of art expression makes it\ndifficult for captioning models to balance pixel-level semantic understanding\nand emotion reasoning. To solve the above problems, this paper proposes the\nEmotion stimuli Segmentation and Explanation Model (EmoSEM) to endow the\nsegmentation model SAM with emotion comprehension capability. First, to enable\nthe model to perform segmentation under the guidance of emotional intent well,\nwe introduce an emotional prompt with a learnable mask token as the conditional\ninput for segmentation decoding. Then, we design an emotion projector to\nestablish the association between emotion and visual features. Next, more\nimportantly, to address emotion-visual stimuli alignment, we develop a\nlightweight prefix projector, a module that fuses the learned emotional mask\nwith the corresponding emotion into a unified representation compatible with\nthe language model. Finally, we input the joint visual, mask, and emotional\ntokens into the language model and output the emotional explanations. It\nensures that the generated interpretations remain semantically and emotionally\ncoherent with the visual stimuli. The method innovatively realizes end-to-end\nmodeling from low-level pixel features to high-level emotion interpretation,\nproviding the first interpretable fine-grained analysis framework for artistic\nemotion computing. Extensive experiments validate the effectiveness of our\nmodel.", "AI": {"tldr": "The paper introduces EmoSEM, a model for emotion-oriented segmentation and explanation in visual art, addressing subjectivity and abstraction challenges.", "motivation": "The subjectivity of emotion and abstract nature of art make pixel-level emotion understanding difficult for existing models like SAM and captioning systems.", "method": "EmoSEM enhances SAM with emotional prompts, an emotion projector, and a lightweight prefix projector for emotion-visual alignment, enabling coherent explanations.", "result": "Extensive experiments confirm EmoSEM's effectiveness in fine-grained emotion analysis and interpretable explanations.", "conclusion": "EmoSEM provides the first end-to-end framework for pixel-level emotion understanding and explanation in art."}}
{"id": "2502.02150", "pdf": "https://arxiv.org/pdf/2502.02150", "abs": "https://arxiv.org/abs/2502.02150", "authors": ["Ruiqi Feng", "Tailin Wu", "Chenglei Yu", "Wenhao Deng", "Peiyan Hu"], "title": "On the Guidance of Flow Matching", "categories": ["cs.LG"], "comment": "35 pages, 7 figures", "summary": "Flow matching has shown state-of-the-art performance in various generative\ntasks, ranging from image generation to decision-making, where guided\ngeneration is pivotal. However, the guidance of flow matching is more general\nthan and thus substantially different from that of its predecessor, diffusion\nmodels. Therefore, the challenge in guidance for general flow matching remains\nlargely underexplored. In this paper, we propose the first framework of general\nguidance for flow matching. From this framework, we derive a family of guidance\ntechniques that can be applied to general flow matching. These include a new\ntraining-free asymptotically exact guidance, novel training losses for\ntraining-based guidance, and two classes of approximate guidance that cover\nclassical gradient guidance methods as special cases. We theoretically\ninvestigate these different methods to give a practical guideline for choosing\nsuitable methods in different scenarios. Experiments on synthetic datasets,\nimage inverse problems, and offline reinforcement learning demonstrate the\neffectiveness of our proposed guidance methods and verify the correctness of\nour flow matching guidance framework. Code to reproduce the experiments can be\nfound at https://github.com/AI4Science-WestlakeU/flow_guidance.", "AI": {"tldr": "The paper introduces a general guidance framework for flow matching, deriving various guidance techniques, including training-free and training-based methods, and validates their effectiveness across multiple tasks.", "motivation": "Flow matching outperforms diffusion models in generative tasks, but its guidance remains underexplored. This paper aims to address this gap.", "method": "Proposes a framework for general flow matching guidance, including training-free asymptotically exact guidance, novel training losses, and approximate guidance methods.", "result": "The framework and derived methods are validated on synthetic datasets, image inverse problems, and offline reinforcement learning, showing effectiveness.", "conclusion": "The paper provides a practical guideline for choosing guidance methods in flow matching, supported by theoretical and experimental results."}}
{"id": "2504.15095", "pdf": "https://arxiv.org/pdf/2504.15095", "abs": "https://arxiv.org/abs/2504.15095", "authors": ["Mingxia Zhan", "Li Zhang", "Xiaomeng Chu", "Beibei Wang"], "title": "VistaDepth: Frequency Modulation With Bias Reweighting For Enhanced Long-Range Depth Estimation", "categories": ["cs.CV"], "comment": "8 pages, 6 figures, 4 tables", "summary": "Monocular depth estimation (MDE) aims to predict per-pixel depth values from\na single RGB image. Recent advancements have positioned diffusion models as\neffective MDE tools by framing the challenge as a conditional image generation\ntask. Despite their progress, these methods often struggle with accurately\nreconstructing distant depths, due largely to the imbalanced distribution of\ndepth values and an over-reliance on spatial-domain features. To overcome these\nlimitations, we introduce VistaDepth, a novel framework that integrates\nadaptive frequency-domain feature enhancements with an adaptive\nweight-balancing mechanism into the diffusion process. Central to our approach\nis the Latent Frequency Modulation (LFM) module, which dynamically refines\nspectral responses in the latent feature space, thereby improving the\npreservation of structural details and reducing noisy artifacts. Furthermore,\nwe implement an adaptive weighting strategy that modulates the diffusion loss\nin real-time, enhancing the model's sensitivity towards distant depth\nreconstruction. These innovations collectively result in superior depth\nperception performance across both distance and detail. Experimental\nevaluations confirm that VistaDepth achieves state-of-the-art performance among\ndiffusion-based MDE techniques, particularly excelling in the accurate\nreconstruction of distant regions.", "AI": {"tldr": "VistaDepth improves monocular depth estimation by integrating frequency-domain features and adaptive weighting into diffusion models, excelling in distant depth reconstruction.", "motivation": "Existing diffusion-based MDE methods struggle with distant depth accuracy due to imbalanced depth distributions and reliance on spatial features.", "method": "VistaDepth introduces a Latent Frequency Modulation (LFM) module for spectral refinement and an adaptive weighting strategy for real-time loss modulation.", "result": "VistaDepth achieves state-of-the-art performance, especially in distant depth reconstruction.", "conclusion": "The framework enhances depth perception by combining frequency-domain features and adaptive mechanisms, setting a new benchmark for diffusion-based MDE."}}
{"id": "2502.02417", "pdf": "https://arxiv.org/pdf/2502.02417", "abs": "https://arxiv.org/abs/2502.02417", "authors": ["Matthias Wolff", "Florian Eilers", "Xiaoyi Jiang"], "title": "CVKAN: Complex-Valued Kolmogorov-Arnold Networks", "categories": ["cs.LG"], "comment": "accepted at IEEE International Joint Conference on Neural Networks\n  (IJCNN) 2025", "summary": "In this work we propose CVKAN, a complex-valued Kolmogorov-Arnold Network\n(KAN), to join the intrinsic interpretability of KANs and the advantages of\nComplex-Valued Neural Networks (CVNNs). We show how to transfer a KAN and the\nnecessary associated mechanisms into the complex domain. To confirm that CVKAN\nmeets expectations we conduct experiments on symbolic complex-valued function\nfitting and physically meaningful formulae as well as on a more realistic\ndataset from knot theory. Our proposed CVKAN is more stable and performs on par\nor better than real-valued KANs while requiring less parameters and a shallower\nnetwork architecture, making it more explainable.", "AI": {"tldr": "CVKAN combines interpretability of KANs with advantages of CVNNs, performing better or on par with real-valued KANs while requiring fewer parameters.", "motivation": "To merge the interpretability of KANs and the benefits of CVNNs in the complex domain.", "method": "Transfer KAN and associated mechanisms into the complex domain, validated via symbolic function fitting and knot theory datasets.", "result": "CVKAN is more stable, performs comparably or better, and uses fewer parameters than real-valued KANs.", "conclusion": "CVKAN offers improved performance and explainability in complex-valued tasks."}}
{"id": "2504.15278", "pdf": "https://arxiv.org/pdf/2504.15278", "abs": "https://arxiv.org/abs/2504.15278", "authors": ["Hongchi Xia", "Entong Su", "Marius Memmel", "Arhan Jain", "Raymond Yu", "Numfor Mbiziwo-Tiapo", "Ali Farhadi", "Abhishek Gupta", "Shenlong Wang", "Wei-Chiu Ma"], "title": "DRAWER: Digital Reconstruction and Articulation With Environment Realism", "categories": ["cs.CV", "cs.RO"], "comment": "Project page: https://drawer-art.github.io/", "summary": "Creating virtual digital replicas from real-world data unlocks significant\npotential across domains like gaming and robotics. In this paper, we present\nDRAWER, a novel framework that converts a video of a static indoor scene into a\nphotorealistic and interactive digital environment. Our approach centers on two\nmain contributions: (i) a reconstruction module based on a dual scene\nrepresentation that reconstructs the scene with fine-grained geometric details,\nand (ii) an articulation module that identifies articulation types and hinge\npositions, reconstructs simulatable shapes and appearances and integrates them\ninto the scene. The resulting virtual environment is photorealistic,\ninteractive, and runs in real time, with compatibility for game engines and\nrobotic simulation platforms. We demonstrate the potential of DRAWER by using\nit to automatically create an interactive game in Unreal Engine and to enable\nreal-to-sim-to-real transfer for robotics applications.", "AI": {"tldr": "DRAWER converts videos of static indoor scenes into photorealistic, interactive digital environments for gaming and robotics.", "motivation": "To unlock potential in gaming and robotics by creating virtual replicas from real-world data.", "method": "Uses a dual scene representation for reconstruction and an articulation module for interactive elements.", "result": "Produces photorealistic, real-time interactive environments compatible with game engines and robotic simulations.", "conclusion": "DRAWER successfully enables applications like automated game creation and robotics simulations."}}
{"id": "2502.11986", "pdf": "https://arxiv.org/pdf/2502.11986", "abs": "https://arxiv.org/abs/2502.11986", "authors": ["Wooseong Jeong", "Kuk-Jin Yoon"], "title": "Selective Task Group Updates for Multi-Task Optimization", "categories": ["cs.LG"], "comment": "Accepted at ICLR 2025", "summary": "Multi-task learning enables the acquisition of task-generic knowledge by\ntraining multiple tasks within a unified architecture. However, training all\ntasks together in a single architecture can lead to performance degradation,\nknown as negative transfer, which is a main concern in multi-task learning.\nPrevious works have addressed this issue by optimizing the multi-task network\nthrough gradient manipulation or weighted loss adjustments. However, their\noptimization strategy focuses on addressing task imbalance in shared\nparameters, neglecting the learning of task-specific parameters. As a result,\nthey show limitations in mitigating negative transfer, since the learning of\nshared space and task-specific information influences each other during\noptimization. To address this, we propose a different approach to enhance\nmulti-task performance by selectively grouping tasks and updating them for each\nbatch during optimization. We introduce an algorithm that adaptively determines\nhow to effectively group tasks and update them during the learning process. To\ntrack inter-task relations and optimize multi-task networks simultaneously, we\npropose proximal inter-task affinity, which can be measured during the\noptimization process. We provide a theoretical analysis on how dividing tasks\ninto multiple groups and updating them sequentially significantly affects\nmulti-task performance by enhancing the learning of task-specific parameters.\nOur methods substantially outperform previous multi-task optimization\napproaches and are scalable to different architectures and various numbers of\ntasks.", "AI": {"tldr": "The paper proposes a method to mitigate negative transfer in multi-task learning by adaptively grouping tasks and updating them selectively during optimization, outperforming previous approaches.", "motivation": "Negative transfer in multi-task learning degrades performance, and existing methods fail to address task-specific parameter learning.", "method": "Introduces an algorithm for adaptive task grouping and updates, using proximal inter-task affinity to track relations.", "result": "The method significantly improves multi-task performance and scales across architectures and task numbers.", "conclusion": "Selective task grouping and updating enhances task-specific learning, outperforming prior multi-task optimization strategies."}}
{"id": "2412.05053", "pdf": "https://arxiv.org/pdf/2412.05053", "abs": "https://arxiv.org/abs/2412.05053", "authors": ["Kaizhen Sun", "Jinghang Li", "Kuan Dai", "Bangyan Liao", "Wei Xiong", "Yi Zhou"], "title": "EvTTC: An Event Camera Dataset for Time-to-Collision Estimation", "categories": ["cs.RO", "cs.CV"], "comment": "8 pages, 7 figures, 5 tables", "summary": "Time-to-Collision (TTC) estimation lies in the core of the forward collision\nwarning (FCW) functionality, which is key to all Automatic Emergency Braking\n(AEB) systems. Although the success of solutions using frame-based cameras\n(e.g., Mobileye's solutions) has been witnessed in normal situations, some\nextreme cases, such as the sudden variation in the relative speed of leading\nvehicles and the sudden appearance of pedestrians, still pose significant risks\nthat cannot be handled. This is due to the inherent imaging principles of\nframe-based cameras, where the time interval between adjacent exposures\nintroduces considerable system latency to AEB. Event cameras, as a novel\nbio-inspired sensor, offer ultra-high temporal resolution and can\nasynchronously report brightness changes at the microsecond level. To explore\nthe potential of event cameras in the above-mentioned challenging cases, we\npropose EvTTC, which is, to the best of our knowledge, the first multi-sensor\ndataset focusing on TTC tasks under high-relative-speed scenarios. EvTTC\nconsists of data collected using standard cameras and event cameras, covering\nvarious potential collision scenarios in daily driving and involving multiple\ncollision objects. Additionally, LiDAR and GNSS/INS measurements are provided\nfor the calculation of ground-truth TTC. Considering the high cost of testing\nTTC algorithms on full-scale mobile platforms, we also provide a small-scale\nTTC testbed for experimental validation and data augmentation. All the data and\nthe design of the testbed are open sourced, and they can serve as a benchmark\nthat will facilitate the development of vision-based TTC techniques.", "AI": {"tldr": "EvTTC is a novel multi-sensor dataset for Time-to-Collision (TTC) estimation, combining event and standard cameras to address extreme scenarios in collision warning systems.", "motivation": "Current frame-based camera solutions struggle with extreme cases like sudden speed changes or pedestrian appearances due to system latency. Event cameras offer high temporal resolution to mitigate this.", "method": "The paper introduces EvTTC, a dataset with standard and event camera data, LiDAR, and GNSS/INS for ground-truth TTC. A small-scale testbed is also provided for validation.", "result": "EvTTC enables better handling of high-relative-speed scenarios and serves as a benchmark for vision-based TTC techniques.", "conclusion": "EvTTC advances TTC estimation by leveraging event cameras, providing open-source data and tools for future research."}}
{"id": "2503.08976", "pdf": "https://arxiv.org/pdf/2503.08976", "abs": "https://arxiv.org/abs/2503.08976", "authors": ["Zirui Gong", "Yanjun Zhang", "Leo Yu Zhang", "Zhaoxi Zhang", "Yong Xiang", "Shirui Pan"], "title": "Not All Edges are Equally Robust: Evaluating the Robustness of Ranking-Based Federated Learning", "categories": ["cs.LG", "cs.CR", "cs.DC"], "comment": "18 pages. To appear in the IEEE Symposium on Security and Privacy\n  2025", "summary": "Federated Ranking Learning (FRL) is a state-of-the-art FL framework that\nstands out for its communication efficiency and resilience to poisoning\nattacks. It diverges from the traditional FL framework in two ways: 1) it\nleverages discrete rankings instead of gradient updates, significantly reducing\ncommunication costs and limiting the potential space for malicious updates, and\n2) it uses majority voting on the server side to establish the global ranking,\nensuring that individual updates have minimal influence since each client\ncontributes only a single vote. These features enhance the system's scalability\nand position FRL as a promising paradigm for FL training.\n  However, our analysis reveals that FRL is not inherently robust, as certain\nedges are particularly vulnerable to poisoning attacks. Through a theoretical\ninvestigation, we prove the existence of these vulnerable edges and establish a\nlower bound and an upper bound for identifying them in each layer. Based on\nthis finding, we introduce a novel local model poisoning attack against FRL,\nnamely the Vulnerable Edge Manipulation (VEM) attack. The VEM attack focuses on\nidentifying and perturbing the most vulnerable edges in each layer and\nleveraging an optimization-based approach to maximize the attack's impact.\nThrough extensive experiments on benchmark datasets, we demonstrate that our\nattack achieves an overall 53.23% attack impact and is 3.7x more impactful than\nexisting methods. Our findings highlight significant vulnerabilities in\nranking-based FL systems and underline the urgency for the development of new\nrobust FL frameworks.", "AI": {"tldr": "Federated Ranking Learning (FRL) is efficient and resilient but has vulnerabilities to poisoning attacks, demonstrated by the VEM attack, which is 3.7x more impactful than existing methods.", "motivation": "To analyze the robustness of FRL and identify its vulnerabilities to poisoning attacks.", "method": "Theoretical investigation of vulnerable edges, introduction of the VEM attack, and experimental validation on benchmark datasets.", "result": "VEM achieves a 53.23% attack impact, 3.7x more than existing methods, revealing FRL's vulnerabilities.", "conclusion": "FRL has significant vulnerabilities, necessitating the development of more robust federated learning frameworks."}}
{"id": "2504.07677", "pdf": "https://arxiv.org/pdf/2504.07677", "abs": "https://arxiv.org/abs/2504.07677", "authors": ["Hye-Min Won", "Jieun Lee", "Jiyong Oh"], "title": "Localization Meets Uncertainty: Uncertainty-Aware Multi-Modal Localization", "categories": ["cs.RO", "cs.CV"], "comment": "13 pages, 6 figures", "summary": "Reliable localization is critical for robot navigation in complex indoor\nenvironments. In this paper, we propose an uncertainty-aware localization\nmethod that enhances the reliability of localization outputs without modifying\nthe prediction model itself. This study introduces a percentile-based rejection\nstrategy that filters out unreliable 3-DoF pose predictions based on aleatoric\nand epistemic uncertainties the network estimates. We apply this approach to a\nmulti-modal end-to-end localization that fuses RGB images and 2D LiDAR data,\nand we evaluate it across three real-world datasets collected using a\ncommercialized serving robot. Experimental results show that applying stricter\nuncertainty thresholds consistently improves pose accuracy. Specifically, the\nmean position error is reduced by 41.0%, 56.7%, and 69.4%, and the mean\norientation error by 55.6%, 65.7%, and 73.3%, when applying 90%, 80%, and 70%\nthresholds, respectively. Furthermore, the rejection strategy effectively\nremoves extreme outliers, resulting in better alignment with ground truth\ntrajectories. To the best of our knowledge, this is the first study to\nquantitatively demonstrate the benefits of percentile-based uncertainty\nrejection in multi-modal end-to-end localization tasks. Our approach provides a\npractical means to enhance the reliability and accuracy of localization systems\nin real-world deployments.", "AI": {"tldr": "An uncertainty-aware localization method improves robot navigation reliability by filtering unreliable 3-DoF pose predictions using aleatoric and epistemic uncertainties, reducing errors significantly.", "motivation": "Reliable localization is crucial for robot navigation in complex indoor environments, but existing methods lack robustness in uncertainty handling.", "method": "A percentile-based rejection strategy filters unreliable predictions in a multi-modal end-to-end localization system using RGB images and 2D LiDAR data.", "result": "Stricter uncertainty thresholds reduce mean position errors by up to 69.4% and orientation errors by up to 73.3%, while also removing extreme outliers.", "conclusion": "The study demonstrates the effectiveness of uncertainty rejection in improving localization reliability and accuracy, offering practical benefits for real-world deployments."}}
{"id": "2503.15766", "pdf": "https://arxiv.org/pdf/2503.15766", "abs": "https://arxiv.org/abs/2503.15766", "authors": ["Peter Sharpe", "Rishikesh Ranade", "Kaustubh Tangsali", "Mohammad Amin Nabian", "Ram Cherukuri", "Sanjay Choudhry"], "title": "Accelerating Transient CFD through Machine Learning-Based Flow Initialization", "categories": ["cs.LG", "physics.flu-dyn"], "comment": "17 pages, 8 figures", "summary": "Transient computational fluid dynamics (CFD) simulations are essential for\nmany industrial applications, but a significant portion of their computational\ncost stems from the time needed to reach statistical steadiness from initial\nconditions. We present a novel machine learning-based initialization method\nthat reduces the cost of this subsequent transient solve substantially,\nachieving a 50% reduction in time-to-convergence compared to traditional\nuniform and potential flow-based initializations. Through a case study in\nautomotive aerodynamics using a 16.7M-cell unsteady RANS simulation, we\nevaluate three ML-based initialization strategies. Two of these strategies are\nrecommended for general use: (1) a physics-informed hybrid method combining ML\npredictions with potential flow solutions, and (2) a more versatile approach\nintegrating ML predictions with uniform flow. Both strategies enable CFD\nsolvers to achieve convergence times comparable to computationally expensive\nsteady RANS initializations, while requiring only seconds of computation. We\ndevelop a robust statistical convergence metric based on windowed\ntime-averaging for performance comparison between initialization strategies.\nNotably, these improvements are achieved using an ML model trained on a\ndifferent dataset of automotive geometries, demonstrating strong generalization\ncapabilities. The proposed methods integrate seamlessly with existing CFD\nworkflows without requiring modifications to the underlying flow solver,\nproviding a practical approach to accelerating industrial CFD simulations\nthrough improved ML-based initialization strategies.", "AI": {"tldr": "A novel ML-based initialization method reduces CFD simulation time by 50% compared to traditional methods, using physics-informed and versatile strategies.", "motivation": "To reduce the computational cost of transient CFD simulations by improving initialization methods.", "method": "Three ML-based initialization strategies are evaluated, with two recommended: a physics-informed hybrid method and a versatile approach integrating ML with uniform flow.", "result": "Achieves a 50% reduction in time-to-convergence, with strong generalization from training on different datasets.", "conclusion": "The methods integrate seamlessly with existing workflows, offering practical acceleration for industrial CFD simulations."}}
{"id": "2504.14257", "pdf": "https://arxiv.org/pdf/2504.14257", "abs": "https://arxiv.org/abs/2504.14257", "authors": ["Yilin Liu", "Duoteng Xu", "Xingyao Yu", "Xiang Xu", "Daniel Cohen-Or", "Hao Zhang", "Hui Huang"], "title": "HoLa: B-Rep Generation using a Holistic Latent Representation", "categories": ["cs.GR", "cs.CV"], "comment": "ACM TOG and SIGGRAPH 2025 (Patent Protected); Project page:\n  https://vcc.tech/research/2025/HolaBrep", "summary": "We introduce a novel representation for learning and generating\nComputer-Aided Design (CAD) models in the form of $\\textit{boundary\nrepresentations}$ (B-Reps). Our representation unifies the continuous geometric\nproperties of B-Rep primitives in different orders (e.g., surfaces and curves)\nand their discrete topological relations in a $\\textit{holistic latent}$ (HoLa)\nspace. This is based on the simple observation that the topological connection\nbetween two surfaces is intrinsically tied to the geometry of their\nintersecting curve. Such a prior allows us to reformulate topology learning in\nB-Reps as a geometric reconstruction problem in Euclidean space. Specifically,\nwe eliminate the presence of curves, vertices, and all the topological\nconnections in the latent space by learning to distinguish and derive curve\ngeometries from a pair of surface primitives via a neural intersection network.\nTo this end, our holistic latent space is only defined on surfaces but encodes\na full B-Rep model, including the geometry of surfaces, curves, vertices, and\ntheir topological relations. Our compact and holistic latent space facilitates\nthe design of a first diffusion-based generator to take on a large variety of\ninputs including point clouds, single/multi-view images, 2D sketches, and text\nprompts. Our method significantly reduces ambiguities, redundancies, and\nincoherences among the generated B-Rep primitives, as well as training\ncomplexities inherent in prior multi-step B-Rep learning pipelines, while\nachieving greatly improved validity rate over current state of the art: 82% vs.\n$\\approx$50%.", "AI": {"tldr": "A novel representation for CAD models using a holistic latent (HoLa) space unifies geometry and topology, enabling a diffusion-based generator for diverse inputs with improved validity.", "motivation": "To address ambiguities, redundancies, and incoherences in existing B-Rep learning pipelines by unifying geometric and topological properties in a compact latent space.", "method": "Reformulates topology learning as geometric reconstruction, eliminating curves and vertices in latent space via a neural intersection network. Uses a diffusion-based generator for diverse inputs.", "result": "Achieves 82% validity rate, significantly outperforming prior state-of-the-art (~50%).", "conclusion": "The HoLa space and diffusion-based generator provide a robust, efficient solution for learning and generating CAD models with high validity."}}
{"id": "2504.05138", "pdf": "https://arxiv.org/pdf/2504.05138", "abs": "https://arxiv.org/abs/2504.05138", "authors": ["Haoran Zhang", "Zejun Gong", "Zekai Li", "Marie Siew", "Carlee Joe-Wong", "Rachid El-Azouzi"], "title": "Towards Optimal Heterogeneous Client Sampling in Multi-Model Federated Learning", "categories": ["cs.LG", "cs.DC", "I.2.11"], "comment": "29 pages with full proofs", "summary": "Federated learning (FL) allows edge devices to collaboratively train models\nwithout sharing local data. As FL gains popularity, clients may need to train\nmultiple unrelated FL models, but communication constraints limit their ability\nto train all models simultaneously. While clients could train FL models\nsequentially, opportunistically having FL clients concurrently train different\nmodels -- termed multi-model federated learning (MMFL) -- can reduce the\noverall training time. Prior work uses simple client-to-model assignments that\ndo not optimize the contribution of each client to each model over the course\nof its training. Prior work on single-model FL shows that intelligent client\nselection can greatly accelerate convergence, but na\\\"ive extensions to MMFL\ncan violate heterogeneous resource constraints at both the server and the\nclients. In this work, we develop a novel convergence analysis of MMFL with\narbitrary client sampling methods, theoretically demonstrating the strengths\nand limitations of previous well-established gradient-based methods. Motivated\nby this analysis, we propose MMFL-LVR, a loss-based sampling method that\nminimizes training variance while explicitly respecting communication limits at\nthe server and reducing computational costs at the clients. We extend this to\nMMFL-StaleVR, which incorporates stale updates for improved efficiency and\nstability, and MMFL-StaleVRE, a lightweight variant suitable for low-overhead\ndeployment. Experiments show our methods improve average accuracy by up to\n19.1% over random sampling, with only a 5.4% gap from the theoretical optimum\n(full client participation).", "AI": {"tldr": "The paper introduces multi-model federated learning (MMFL) to train multiple models concurrently, addressing communication constraints. It proposes MMFL-LVR and variants for efficient client selection, improving accuracy by up to 19.1%.", "motivation": "Clients in federated learning (FL) face communication constraints when training multiple models. Sequential training is inefficient, and naive multi-model approaches violate resource limits. The goal is to optimize client-to-model assignments for faster convergence.", "method": "The paper develops a convergence analysis for MMFL and proposes MMFL-LVR, a loss-based sampling method. Variants MMFL-StaleVR and MMFL-StaleVRE incorporate stale updates for efficiency and stability.", "result": "Experiments show the methods improve average accuracy by up to 19.1% over random sampling, with only a 5.4% gap from the theoretical optimum.", "conclusion": "The proposed methods optimize client selection in MMFL, significantly improving training efficiency and accuracy while respecting resource constraints."}}
{"id": "2504.05490", "pdf": "https://arxiv.org/pdf/2504.05490", "abs": "https://arxiv.org/abs/2504.05490", "authors": ["Sasan Vakili", "Manuel Mazo Jr.", "Peyman Mohajerin Esfahani"], "title": "Optimal Bayesian Affine Estimator and Active Learning for the Wiener Model", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "23 pages, 4 figures", "summary": "This paper presents a Bayesian estimation framework for Wiener models,\nfocusing on learning nonlinear output functions under known linear state\ndynamics. We derive a closed-form optimal affine estimator for the unknown\nparameters, characterized by the so-called \"dynamic basis statistics\" (DBS).\nSeveral features of the proposed estimator are studied, including Bayesian\nunbiasedness, closed-form posterior statistics, error monotonicity in\ntrajectory length, and consistency condition (also known as persistent\nexcitation). In the special case of Fourier basis functions, we demonstrate\nthat the closed-form description is computationally available, as the Fourier\nDBS enjoys explicit expressions. Furthermore, we identify an inherent\ninconsistency in the Fourier bases for single-trajectory measurements,\nregardless of the input excitation. Leveraging the closed-form estimation\nerror, we develop an active learning algorithm synthesizing input signals to\nminimize estimation error. Numerical experiments validate the efficacy of our\napproach, showing significant improvements over traditional regularized\nleast-squares methods.", "AI": {"tldr": "A Bayesian framework for Wiener models is introduced, focusing on nonlinear output functions with known linear dynamics. It features a closed-form optimal affine estimator using dynamic basis statistics (DBS), with properties like unbiasedness and error monotonicity. Active learning minimizes estimation error, outperforming traditional methods.", "motivation": "To address the challenge of learning nonlinear output functions in Wiener models under known linear dynamics, leveraging Bayesian estimation for improved accuracy and efficiency.", "method": "Derives a closed-form optimal affine estimator using dynamic basis statistics (DBS), analyzes its properties, and develops an active learning algorithm to minimize estimation error.", "result": "The estimator shows Bayesian unbiasedness, closed-form posterior statistics, and improved performance over traditional methods, validated by numerical experiments.", "conclusion": "The proposed Bayesian framework and active learning approach effectively enhance estimation accuracy for Wiener models, particularly with Fourier basis functions."}}
{"id": "2504.07307", "pdf": "https://arxiv.org/pdf/2504.07307", "abs": "https://arxiv.org/abs/2504.07307", "authors": ["Jingxin Zhan", "Yuchen Xin", "Zhihua Zhang"], "title": "Follow-the-Perturbed-Leader Approaches Best-of-Both-Worlds for the m-Set Semi-Bandit Problems", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We consider a common case of the combinatorial semi-bandit problem, the\n$m$-set semi-bandit, where the learner exactly selects $m$ arms from the total\n$d$ arms. In the adversarial setting, the best regret bound, known to be\n$\\mathcal{O}(\\sqrt{nmd})$ for time horizon $n$, is achieved by the well-known\nFollow-the-Regularized-Leader (FTRL) policy. However, this requires to\nexplicitly compute the arm-selection probabilities via optimizing problems at\neach time step and sample according to them. This problem can be avoided by the\nFollow-the-Perturbed-Leader (FTPL) policy, which simply pulls the $m$ arms that\nrank among the $m$ smallest (estimated) loss with random perturbation. In this\npaper, we show that FTPL with a Fr\\'echet perturbation also enjoys the near\noptimal regret bound $\\mathcal{O}(\\sqrt{nmd\\log(d)})$ in the adversarial\nsetting and approaches best-of-both-world regret bounds, i.e., achieves a\nlogarithmic regret for the stochastic setting.", "AI": {"tldr": "FTPL with Fr\u00e9chet perturbation achieves near-optimal regret bounds in adversarial settings and logarithmic regret in stochastic settings for the m-set semi-bandit problem.", "motivation": "The motivation is to improve the efficiency of the Follow-the-Perturbed-Leader (FTPL) policy in combinatorial semi-bandit problems, avoiding the computational burden of FTRL while maintaining strong regret bounds.", "method": "The paper uses FTPL with Fr\u00e9chet perturbation, selecting arms based on perturbed loss estimates, to achieve efficient regret bounds.", "result": "FTPL with Fr\u00e9chet perturbation achieves a regret bound of O(\u221a(nmd log(d))) in adversarial settings and logarithmic regret in stochastic settings.", "conclusion": "FTPL with Fr\u00e9chet perturbation is a computationally efficient alternative to FTRL, offering near-optimal regret bounds in adversarial settings and adapting well to stochastic settings."}}
{"id": "2504.09192", "pdf": "https://arxiv.org/pdf/2504.09192", "abs": "https://arxiv.org/abs/2504.09192", "authors": ["Zhiyong Wang"], "title": "Towards More Efficient, Robust, Instance-adaptive, and Generalizable Online Learning", "categories": ["cs.LG"], "comment": "Ph.D. Thesis", "summary": "The primary goal of my Ph.D. study is to develop provably efficient and\npractical algorithms for data-driven online sequential decision-making under\nuncertainty. My work focuses on reinforcement learning (RL), multi-armed\nbandits, and their applications, including recommendation systems, computer\nnetworks, video analytics, and large language models (LLMs). Online learning\nmethods, such as bandits and RL, have demonstrated remarkable success - ranging\nfrom outperforming human players in complex games like Atari and Go to\nadvancing robotics, recommendation systems, and fine-tuning LLMs. Despite these\nsuccesses, many established algorithms rely on idealized models that can fail\nunder model misspecifications or adversarial perturbations, particularly in\nsettings where accurate prior knowledge of the underlying model class is\nunavailable or where malicious users operate within dynamic systems. These\nchallenges are pervasive in real-world applications, where robust and adaptive\nsolutions are critical. Furthermore, while worst-case guarantees provide\ntheoretical reliability, they often fail to capture instance-dependent\nperformance, which can lead to more efficient and practical solutions. Another\nkey challenge lies in generalizing to new, unseen environments, a crucial\nrequirement for deploying these methods in dynamic and unpredictable settings.\nTo address these limitations, my research aims to develop more efficient,\nrobust, instance-adaptive, and generalizable online learning algorithms for\nboth reinforcement learning and bandits. Towards this end, I focus on\ndeveloping more efficient, robust, instance-adaptive, and generalizable for\nboth general reinforcement learning (RL) and bandits.", "AI": {"tldr": "Developing efficient, robust, and adaptive online learning algorithms for RL and bandits to address real-world challenges like model misspecifications and adversarial perturbations.", "motivation": "Existing algorithms often rely on idealized models, failing under real-world uncertainties and lacking instance-dependent performance. Robust, adaptive solutions are needed for dynamic systems.", "method": "Focus on reinforcement learning (RL) and multi-armed bandits, aiming to improve efficiency, robustness, and adaptability in uncertain environments.", "result": "Expected outcomes include more practical and reliable algorithms for applications like recommendation systems, LLMs, and dynamic systems.", "conclusion": "The research aims to bridge the gap between theoretical guarantees and practical performance, enhancing the applicability of online learning methods in real-world scenarios."}}
{"id": "2504.09940", "pdf": "https://arxiv.org/pdf/2504.09940", "abs": "https://arxiv.org/abs/2504.09940", "authors": ["Guowen Li", "Xintong Liu", "Shilei Cao", "Haoyuan Liang", "Mengxuan Chen", "Lixian Zhang", "Jinxiao Zhang", "Jiuke Wang", "Meng Jin", "Juepeng Zheng", "Haohuan Fu"], "title": "TianQuan-Climate: A Subseasonal-to-Seasonal Global Weather Model via Incorporate Climatology State", "categories": ["cs.LG"], "comment": null, "summary": "Subseasonal forecasting serves as an important support for Sustainable\nDevelopment Goals (SDGs), such as climate challenges, agricultural yield and\nsustainable energy production. However, subseasonal forecasting is a complex\ntask in meteorology due to dissipating initial conditions and delayed external\nforces. Although AI models are increasingly pushing the boundaries of this\nforecasting limit, they face two major challenges: error accumulation and\nSmoothness. To address these two challenges, we propose Climate Furnace\nSubseasonal-to-Seasonal (TianQuan-Climate), a novel machine learning model\ndesigned to provide global daily mean forecasts up to 45 days, covering five\nupper-air atmospheric variables at 13 pressure levels and two surface\nvariables. Our proposed TianQuan-Climate has two advantages: 1) it utilizes a\nmulti-model prediction strategy to reduce system error impacts in long-term\nsubseasonal forecasts; 2) it incorporates a Content Fusion Module for\nclimatological integration and extends ViT with uncertainty blocks (UD-ViT) to\nimprove generalization by learning from uncertainty. We demonstrate the\neffectiveness of TianQuan-Climate on benchmarks for weather forecasting and\nclimate projections within the 15 to 45-day range, where TianQuan-Climate\noutperforms existing numerical and AI methods.", "AI": {"tldr": "TianQuan-Climate, a novel AI model, improves subseasonal forecasting by reducing errors and enhancing smoothness, outperforming existing methods.", "motivation": "Subseasonal forecasting is crucial for SDGs but is complex due to dissipating initial conditions and delayed external forces. AI models face challenges like error accumulation and smoothness.", "method": "TianQuan-Climate uses a multi-model prediction strategy and a Content Fusion Module with UD-ViT to integrate climatological data and learn from uncertainty.", "result": "The model outperforms existing numerical and AI methods in benchmarks for 15 to 45-day forecasts.", "conclusion": "TianQuan-Climate effectively addresses key challenges in subseasonal forecasting, offering improved accuracy for global daily forecasts."}}
{"id": "2504.12675", "pdf": "https://arxiv.org/pdf/2504.12675", "abs": "https://arxiv.org/abs/2504.12675", "authors": ["Pengtao Dang", "Tingbo Guo", "Melissa Fishel", "Guang Lin", "Wenzhuo Wu", "Sha Cao", "Chi Zhang"], "title": "Physics Informed Constrained Learning of Dynamics from Static Data", "categories": ["cs.LG", "physics.bio-ph", "q-bio.MN"], "comment": "39 pages, 10 figures", "summary": "A physics-informed neural network (PINN) models the dynamics of a system by\nintegrating the governing physical laws into the architecture of a neural\nnetwork. By enforcing physical laws as constraints, PINN overcomes challenges\nwith data scarsity and potentially high dimensionality. Existing PINN\nframeworks rely on fully observed time-course data, the acquisition of which\ncould be prohibitive for many systems. In this study, we developed a new PINN\nlearning paradigm, namely Constrained Learning, that enables the approximation\nof first-order derivatives or motions using non-time course or partially\nobserved data. Computational principles and a general mathematical formulation\nof Constrained Learning were developed. We further introduced MPOCtrL (Message\nPassing Optimization-based Constrained Learning) an optimization approach\ntailored for the Constrained Learning framework that strives to balance the\nfitting of physical models and observed data. Its code is available at github\nlink: https://github.com/ptdang1001/MPOCtrL Experiments on synthetic and\nreal-world data demonstrated that MPOCtrL can effectively detect the nonlinear\ndependency between observed data and the underlying physical properties of the\nsystem. In particular, on the task of metabolic flux analysis, MPOCtrL\noutperforms all existing data-driven flux estimators.", "AI": {"tldr": "A new PINN framework, Constrained Learning, uses non-time course data to approximate system dynamics, outperforming existing methods in tasks like metabolic flux analysis.", "motivation": "Existing PINN frameworks require fully observed time-course data, which is often hard to acquire. This study aims to overcome this limitation.", "method": "Developed Constrained Learning for PINNs, using non-time course data, and introduced MPOCtrL, an optimization approach balancing physical models and observed data.", "result": "MPOCtrL effectively detects nonlinear dependencies in data and outperforms existing methods in metabolic flux analysis.", "conclusion": "Constrained Learning and MPOCtrL provide a robust solution for modeling systems with limited or partial data, advancing PINN applications."}}
{"id": "2504.12875", "pdf": "https://arxiv.org/pdf/2504.12875", "abs": "https://arxiv.org/abs/2504.12875", "authors": ["Phung Lai", "Guanxiong Liu", "NhatHai Phan", "Issa Khalil", "Abdallah Khreishah", "Xintao Wu"], "title": "A Client-level Assessment of Collaborative Backdoor Poisoning in Non-IID Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated learning (FL) enables collaborative model training using\ndecentralized private data from multiple clients. While FL has shown robustness\nagainst poisoning attacks with basic defenses, our research reveals new\nvulnerabilities stemming from non-independent and identically distributed\n(non-IID) data among clients. These vulnerabilities pose a substantial risk of\nmodel poisoning in real-world FL scenarios.\n  To demonstrate such vulnerabilities, we develop a novel collaborative\nbackdoor poisoning attack called CollaPois. In this attack, we distribute a\nsingle pre-trained model infected with a Trojan to a group of compromised\nclients. These clients then work together to produce malicious gradients,\ncausing the FL model to consistently converge towards a low-loss region\ncentered around the Trojan-infected model. Consequently, the impact of the\nTrojan is amplified, especially when the benign clients have diverse local data\ndistributions and scattered local gradients. CollaPois stands out by achieving\nits goals while involving only a limited number of compromised clients, setting\nit apart from existing attacks. Also, CollaPois effectively avoids noticeable\nshifts or degradation in the FL model's performance on legitimate data samples,\nallowing it to operate stealthily and evade detection by advanced robust FL\nalgorithms.\n  Thorough theoretical analysis and experiments conducted on various benchmark\ndatasets demonstrate the superiority of CollaPois compared to state-of-the-art\nbackdoor attacks. Notably, CollaPois bypasses existing backdoor defenses,\nespecially in scenarios where clients possess diverse data distributions.\nMoreover, the results show that CollaPois remains effective even when involving\na small number of compromised clients. Notably, clients whose local data is\nclosely aligned with compromised clients experience higher risks of backdoor\ninfections.", "AI": {"tldr": "The paper introduces CollaPois, a novel collaborative backdoor poisoning attack in federated learning (FL) that exploits non-IID data vulnerabilities, amplifying Trojan impact with minimal compromised clients while evading detection.", "motivation": "The study aims to uncover and demonstrate new vulnerabilities in FL due to non-IID data, which existing defenses fail to address, posing significant risks in real-world FL scenarios.", "method": "Developed CollaPois, a collaborative attack where compromised clients use a pre-trained Trojan-infected model to produce malicious gradients, leveraging diverse client data distributions to amplify the Trojan's impact.", "result": "CollaPois outperforms state-of-the-art backdoor attacks, bypassing defenses, especially in non-IID settings, and remains effective with few compromised clients. Clients with similar data to compromised ones face higher infection risks.", "conclusion": "CollaPois highlights critical FL vulnerabilities from non-IID data, urging the need for advanced defenses against collaborative poisoning attacks."}}
{"id": "2504.12988", "pdf": "https://arxiv.org/pdf/2504.12988", "abs": "https://arxiv.org/abs/2504.12988", "authors": ["Yannis Montreuil", "Axel Carlier", "Lai Xing Ng", "Wei Tsang Ooi"], "title": "Why Ask One When You Can Ask $k$? Two-Stage Learning-to-Defer to the Top-$k$ Experts", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Learning-to-Defer (L2D) enables decision-making systems to improve\nreliability by selectively deferring uncertain predictions to more competent\nagents. However, most existing approaches focus exclusively on single-agent\ndeferral, which is often inadequate in high-stakes scenarios that require\ncollective expertise. We propose Top-$k$ Learning-to-Defer, a generalization of\nthe classical two-stage L2D framework that allocates each query to the $k$ most\nconfident agents instead of a single one. To further enhance flexibility and\ncost-efficiency, we introduce Top-$k(x)$ Learning-to-Defer, an adaptive\nextension that learns the optimal number of agents to consult for each query,\nbased on input complexity, agent competency distributions, and consultation\ncosts. For both settings, we derive a novel surrogate loss and prove that it is\nBayes-consistent and $(\\mathcal{R}, \\mathcal{G})$-consistent, ensuring\nconvergence to the Bayes-optimal allocation. Notably, we show that the\nwell-established model cascades paradigm arises as a restricted instance of our\nTop-$k$ and Top-$k(x)$ formulations. Extensive experiments across diverse\nbenchmarks demonstrate the effectiveness of our framework on both\nclassification and regression tasks.", "AI": {"tldr": "The paper introduces Top-$k$ and Top-$k(x)$ Learning-to-Defer (L2D), extending single-agent deferral to collective expertise for improved reliability in high-stakes scenarios. It proposes adaptive deferral based on input complexity and costs, with theoretical guarantees and empirical validation.", "motivation": "Existing L2D methods focus on single-agent deferral, which is insufficient for high-stakes scenarios requiring collective expertise. The paper aims to generalize L2D to leverage multiple agents adaptively.", "method": "The authors propose Top-$k$ L2D (fixed $k$ agents) and Top-$k(x)$ L2D (adaptive $k$ per query). They derive a surrogate loss, prove Bayes-consistency, and show model cascades as a special case.", "result": "The framework is validated on diverse benchmarks for classification and regression, demonstrating effectiveness in leveraging collective expertise.", "conclusion": "Top-$k$ and Top-$k(x)$ L2D generalize single-agent deferral, offering flexible, cost-efficient solutions with theoretical and empirical support."}}
{"id": "2504.13633", "pdf": "https://arxiv.org/pdf/2504.13633", "abs": "https://arxiv.org/abs/2504.13633", "authors": ["Samuel Wertz", "Arnaud Vandaele", "Nicolas Gillis"], "title": "Efficient algorithms for the Hadamard decomposition", "categories": ["cs.LG", "eess.SP", "math.OC", "stat.ML"], "comment": "7 pages, preprint submitted to IEEE MLSP 2025, code available from\n  https://github.com/WertzSamuel/HadamardDecompositions", "summary": "The Hadamard decomposition is a powerful technique for data analysis and\nmatrix compression, which decomposes a given matrix into the element-wise\nproduct of two or more low-rank matrices. In this paper, we develop an\nefficient algorithm to solve this problem, leveraging an alternating\noptimization approach that decomposes the global non-convex problem into a\nseries of convex sub-problems. To improve performance, we explore advanced\ninitialization strategies inspired by the singular value decomposition (SVD)\nand incorporate acceleration techniques by introducing momentum-based updates.\nBeyond optimizing the two-matrix case, we also extend the Hadamard\ndecomposition framework to support more than two low-rank matrices, enabling\napproximations with higher effective ranks while preserving computational\nefficiency. Finally, we conduct extensive experiments to compare our method\nwith the existing gradient descent-based approaches for the Hadamard\ndecomposition and with traditional low-rank approximation techniques. The\nresults highlight the effectiveness of our proposed method across diverse\ndatasets.", "AI": {"tldr": "An efficient algorithm for Hadamard decomposition is proposed, using alternating optimization and advanced initialization, outperforming existing methods.", "motivation": "To improve the efficiency and effectiveness of Hadamard decomposition for data analysis and matrix compression.", "method": "Alternating optimization splits the problem into convex sub-problems, with SVD-inspired initialization and momentum-based acceleration. Extended to support more than two low-rank matrices.", "result": "Outperforms gradient descent-based and traditional low-rank methods in experiments.", "conclusion": "The proposed method is effective and efficient for Hadamard decomposition, scalable to higher-rank approximations."}}
{"id": "2504.13768", "pdf": "https://arxiv.org/pdf/2504.13768", "abs": "https://arxiv.org/abs/2504.13768", "authors": ["Vinay Sharma", "R\u00e9mi Tanguy Oddon", "Pietro Tesini", "Jens Ravesloot", "Cees Taal", "Olga Fink"], "title": "Equi-Euler GraphNet: An Equivariant, Temporal-Dynamics Informed Graph Neural Network for Dual Force and Trajectory Prediction in Multi-Body Systems", "categories": ["cs.LG", "cs.CE", "physics.comp-ph"], "comment": "permission not yet received for arXiv", "summary": "Accurate real-time modeling of multi-body dynamical systems is essential for\nenabling digital twin applications across industries. While many data-driven\napproaches aim to learn system dynamics, jointly predicting internal loads and\nsystem trajectories remains a key challenge. This dual prediction is especially\nimportant for fault detection and predictive maintenance, where internal\nloads-such as contact forces-act as early indicators of faults, reflecting wear\nor misalignment before affecting motion. These forces also serve as inputs to\ndegradation models (e.g., crack growth), enabling damage prediction and\nremaining useful life estimation. We propose Equi-Euler GraphNet, a\nphysics-informed graph neural network (GNN) that simultaneously predicts\ninternal forces and global trajectories in multi-body systems. In this\nmesh-free framework, nodes represent system components and edges encode\ninteractions. Equi-Euler GraphNet introduces two inductive biases: (1) an\nequivariant message-passing scheme, interpreting edge messages as interaction\nforces consistent under Euclidean transformations; and (2) a temporal-aware\niterative node update mechanism, based on Euler integration, to capture\ninfluence of distant interactions over time. Tailored for cylindrical roller\nbearings, it decouples ring dynamics from constrained motion of rolling\nelements. Trained on high-fidelity multiphysics simulations, Equi-Euler\nGraphNet generalizes beyond the training distribution, accurately predicting\nloads and trajectories under unseen speeds, loads, and configurations. It\noutperforms state-of-the-art GNNs focused on trajectory prediction, delivering\nstable rollouts over thousands of time steps with minimal error accumulation.\nAchieving up to a 200x speedup over conventional solvers while maintaining\ncomparable accuracy, it serves as an efficient reduced-order model for digital\ntwins, design, and maintenance.", "AI": {"tldr": "Equi-Euler GraphNet, a physics-informed GNN, predicts internal forces and trajectories in multi-body systems, outperforming state-of-the-art methods with high efficiency.", "motivation": "Accurate modeling of multi-body dynamics is crucial for digital twins, fault detection, and predictive maintenance, where internal loads are key indicators.", "method": "Uses a graph neural network with equivariant message-passing and Euler integration for temporal updates, tailored for cylindrical roller bearings.", "result": "Achieves stable predictions over thousands of steps, generalizes to unseen conditions, and offers a 200x speedup over conventional solvers.", "conclusion": "Equi-Euler GraphNet is an efficient, accurate reduced-order model for digital twin applications and predictive maintenance."}}
{"id": "2504.14286", "pdf": "https://arxiv.org/pdf/2504.14286", "abs": "https://arxiv.org/abs/2504.14286", "authors": ["Xiaojiang Zhang", "Jinghui Wang", "Zifei Cheng", "Wenhao Zhuang", "Zheng Lin", "Minglei Zhang", "Shaojie Wang", "Yinghan Cui", "Chao Wang", "Junyi Peng", "Shimiao Jiang", "Shiqi Kuang", "Shouyu Yin", "Chaohang Wen", "Haotian Zhang", "Bin Chen", "Bing Yu"], "title": "SRPO: A Cross-Domain Implementation of Large-Scale Reinforcement Learning on LLM", "categories": ["cs.LG"], "comment": null, "summary": "Recent advances of reasoning models, exemplified by OpenAI's o1 and\nDeepSeek's R1, highlight the significant potential of Reinforcement Learning\n(RL) to enhance the reasoning capabilities of Large Language Models (LLMs).\nHowever, replicating these advancements across diverse domains remains\nchallenging due to limited methodological transparency. In this work, we\npresent two-Staged history-Resampling Policy Optimization (SRPO), which\nsurpasses the performance of DeepSeek-R1-Zero-32B on the AIME24 and\nLiveCodeBench benchmarks. SRPO achieves this using the same base model as\nDeepSeek (i.e. Qwen2.5-32B), using only about 1/10 of the training steps\nrequired by DeepSeek-R1-Zero-32B, demonstrating superior efficiency. Building\nupon Group Relative Policy Optimization (GRPO), we introduce two key\nmethodological innovations: (1) a two-stage cross-domain training paradigm\ndesigned to balance the development of mathematical reasoning and coding\nproficiency, and (2) History Resampling (HR), a technique to address\nineffective samples. Our comprehensive experiments validate the effectiveness\nof our approach, offering valuable insights into scaling LLM reasoning\ncapabilities across diverse tasks.", "AI": {"tldr": "SRPO, a two-staged history-resampling policy optimization method, outperforms DeepSeek-R1-Zero-32B on benchmarks using fewer training steps, introducing cross-domain training and history resampling for efficiency.", "motivation": "Replicating reasoning model advancements across domains is challenging due to limited transparency; SRPO aims to address this.", "method": "SRPO uses a two-stage cross-domain training paradigm and history resampling to balance reasoning and coding proficiency while addressing ineffective samples.", "result": "SRPO surpasses DeepSeek-R1-Zero-32B on AIME24 and LiveCodeBench benchmarks with 1/10 the training steps.", "conclusion": "SRPO offers efficient scaling of LLM reasoning capabilities across diverse tasks, validated by comprehensive experiments."}}
{"id": "2303.03984", "pdf": "https://arxiv.org/pdf/2303.03984", "abs": "https://arxiv.org/abs/2303.03984", "authors": ["Feihu Huang", "Chunyu Xuan", "Xinrui Wang", "Siqi Zhang", "Songcan Chen"], "title": "Enhanced Adaptive Gradient Algorithms for Nonconvex-PL Minimax Optimization", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA"], "comment": "Published in AISTATS 2025", "summary": "Minimax optimization recently is widely applied in many machine learning\ntasks such as generative adversarial networks, robust learning and\nreinforcement learning. In the paper, we study a class of nonconvex-nonconcave\nminimax optimization with nonsmooth regularization, where the objective\nfunction is possibly nonconvex on primal variable $x$, and it is nonconcave and\nsatisfies the Polyak-Lojasiewicz (PL) condition on dual variable $y$. Moreover,\nwe propose a class of enhanced momentum-based gradient descent ascent methods\n(i.e., MSGDA and AdaMSGDA) to solve these stochastic nonconvex-PL minimax\nproblems. In particular, our AdaMSGDA algorithm can use various adaptive\nlearning rates in updating the variables $x$ and $y$ without relying on any\nspecifical types. Theoretically, we prove that our methods have the best known\nsample complexity of $\\tilde{O}(\\epsilon^{-3})$ only requiring one sample at\neach loop in finding an $\\epsilon$-stationary solution. Some numerical\nexperiments on PL-game and Wasserstein-GAN demonstrate the efficiency of our\nproposed methods.", "AI": {"tldr": "The paper proposes enhanced momentum-based gradient descent ascent methods (MSGDA and AdaMSGDA) for nonconvex-PL minimax optimization with nonsmooth regularization, achieving state-of-the-art sample complexity.", "motivation": "To address the challenges of nonconvex-nonconcave minimax optimization in machine learning tasks like GANs and robust learning, especially with nonsmooth regularization.", "method": "Develops MSGDA and AdaMSGDA algorithms, leveraging adaptive learning rates for variables x and y, without relying on specific types.", "result": "Theoretically proves a sample complexity of O\u0303(\u03b5\u207b\u00b3) for finding an \u03b5-stationary solution, validated by experiments on PL-game and Wasserstein-GAN.", "conclusion": "The proposed methods are efficient and practical for solving stochastic nonconvex-PL minimax problems, demonstrating superior performance in experiments."}}
{"id": "2304.03069", "pdf": "https://arxiv.org/pdf/2304.03069", "abs": "https://arxiv.org/abs/2304.03069", "authors": ["Jarek Duda"], "title": "Adaptive Student's t-distribution with method of moments moving estimator for nonstationary time series", "categories": ["stat.ME", "cs.LG", "econ.EM", "stat.ML"], "comment": "7 pages, 10 figures", "summary": "The real life time series are usually nonstationary, bringing a difficult\nquestion of model adaptation. Classical approaches like ARMA-ARCH assume\narbitrary type of dependence. To avoid their bias, we will focus on recently\nproposed agnostic philosophy of moving estimator: in time $t$ finding\nparameters optimizing e.g. $F_t=\\sum_{\\tau<t} (1-\\eta)^{t-\\tau} \\ln(\\rho_\\theta\n(x_\\tau))$ moving log-likelihood, evolving in time. It allows for example to\nestimate parameters using inexpensive exponential moving averages (EMA), like\nabsolute central moments $m_p=E[|x-\\mu|^p]$ evolving for one or multiple powers\n$p\\in\\mathbb{R}^+$ using $m_{p,t+1} = m_{p,t} + \\eta (|x_t-\\mu_t|^p-m_{p,t})$.\nApplication of such general adaptive methods of moments will be presented on\nStudent's t-distribution, popular especially in economical applications, here\napplied to log-returns of DJIA companies. While standard ARMA-ARCH approaches\nprovide evolution of $\\mu$ and $\\sigma$, here we also get evolution of $\\nu$\ndescribing $\\rho(x)\\sim |x|^{-\\nu-1}$ tail shape, probability of extreme events\n- which might turn out catastrophic, destabilizing the market.", "AI": {"tldr": "The paper proposes an adaptive method for estimating nonstationary time series using moving log-likelihood and exponential moving averages, applied to Student's t-distribution for financial data.", "motivation": "Classical models like ARMA-ARCH assume arbitrary dependence and may introduce bias, motivating the need for an agnostic, adaptive approach.", "method": "The method uses moving log-likelihood optimization and exponential moving averages (EMA) to estimate parameters, including tail shape (\u03bd) for extreme events.", "result": "The approach successfully estimates evolving parameters (\u03bc, \u03c3, \u03bd) for Student's t-distribution, capturing tail behavior in financial log-returns.", "conclusion": "The adaptive method provides a flexible and efficient way to model nonstationary time series, especially for extreme events in financial markets."}}
{"id": "2305.00044", "pdf": "https://arxiv.org/pdf/2305.00044", "abs": "https://arxiv.org/abs/2305.00044", "authors": ["Patrick Bajari", "Zhihao Cen", "Victor Chernozhukov", "Manoj Manukonda", "Suhas Vijaykumar", "Jin Wang", "Ramon Huerta", "Junbo Li", "Ling Leng", "George Monokroussos", "Shan Wan"], "title": "Hedonic Prices and Quality Adjusted Price Indices Powered by AI", "categories": ["econ.GN", "cs.LG", "q-fin.EC"], "comment": "Revised CEMMAP Working Paper (CWP08/23)", "summary": "We develop empirical models that efficiently process large amounts of\nunstructured product data (text, images, prices, quantities) to produce\naccurate hedonic price estimates and derived indices. To achieve this, we\ngenerate abstract product attributes (or ``features'') from descriptions and\nimages using deep neural networks. These attributes are then used to estimate\nthe hedonic price function. To demonstrate the effectiveness of this approach,\nwe apply the models to Amazon's data for first-party apparel sales, and\nestimate hedonic prices. The resulting models have a very high out-of-sample\npredictive accuracy, with $R^2$ ranging from $80\\%$ to $90\\%$. Finally, we\nconstruct the AI-based hedonic Fisher price index, chained at the\nyear-over-year frequency, and contrast it with the CPI and other electronic\nindices.", "AI": {"tldr": "The paper develops deep learning models to estimate hedonic prices from unstructured product data, achieving high predictive accuracy (80-90% R\u00b2) and comparing the results with traditional indices like CPI.", "motivation": "To efficiently process large unstructured product data (text, images, prices) for accurate hedonic price estimation and index derivation.", "method": "Uses deep neural networks to extract abstract product attributes from descriptions and images, then estimates hedonic price functions. Applied to Amazon apparel sales data.", "result": "High out-of-sample predictive accuracy (80-90% R\u00b2). Constructed an AI-based hedonic Fisher price index, compared with CPI and other indices.", "conclusion": "The approach effectively estimates hedonic prices and outperforms traditional methods, demonstrating the potential of AI in price index construction."}}
{"id": "2307.03034", "pdf": "https://arxiv.org/pdf/2307.03034", "abs": "https://arxiv.org/abs/2307.03034", "authors": ["Keqin Liu", "Qizhen Jia", "Chengzhong Zhang"], "title": "PCL-Indexability and Whittle Index for Restless Bandits with General Observation Models", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In this paper, we consider a general observation model for restless\nmulti-armed bandit problems. The operation of the player needs to be based on\ncertain feedback mechanism that is error-prone due to resource constraints or\nenvironmental or intrinsic noises. By establishing a general probabilistic\nmodel for dynamics of feedback/observation, we formulate the problem as a\nrestless bandit with a countable belief state space starting from an arbitrary\ninitial belief (a priori information). We apply the achievable region method\nwith partial conservation law (PCL) to the infinite-state problem and analyze\nits indexability and priority index (Whittle index). Finally, we propose an\napproximation process to transform the problem into which the AG algorithm of\nNi\\~no-Mora and Bertsimas for finite-state problems can be applied to.\nNumerical experiments show that our algorithm has an excellent performance.", "AI": {"tldr": "The paper addresses restless multi-armed bandit problems with error-prone feedback, using a probabilistic model and the achievable region method to derive an efficient algorithm.", "motivation": "To tackle the challenge of restless bandit problems with noisy feedback due to constraints or noise, requiring robust solutions.", "method": "Formulates the problem as a restless bandit with countable belief states, applies the achievable region method with PCL, and proposes an approximation for finite-state solutions.", "result": "Numerical experiments demonstrate the algorithm's excellent performance.", "conclusion": "The proposed method effectively handles infinite-state restless bandit problems with noisy feedback, offering practical solutions."}}
{"id": "2406.09194", "pdf": "https://arxiv.org/pdf/2406.09194", "abs": "https://arxiv.org/abs/2406.09194", "authors": ["Honam Wong", "Wendao Wu", "Fanghui Liu", "Yiping Lu"], "title": "Benign overfitting in Fixed Dimension via Physics-Informed Learning with Smooth Inductive Bias", "categories": ["stat.ML", "cs.IT", "cs.LG", "cs.NA", "math.IT", "math.NA", "math.ST", "stat.TH"], "comment": null, "summary": "Recent advances in machine learning have inspired a surge of research into\nreconstructing specific quantities of interest from measurements that comply\nwith certain physical laws. These efforts focus on inverse problems that are\ngoverned by partial differential equations (PDEs). In this work, we develop an\nasymptotic Sobolev norm learning curve for kernel ridge(less) regression when\naddressing (elliptical) linear inverse problems. Our results show that the PDE\noperators in the inverse problem can stabilize the variance and even behave\nbenign overfitting for fixed-dimensional problems, exhibiting different\nbehaviors from regression problems. Besides, our investigation also\ndemonstrates the impact of various inductive biases introduced by minimizing\ndifferent Sobolev norms as a form of implicit regularization. For the\nregularized least squares estimator, we find that all considered inductive\nbiases can achieve the optimal convergence rate, provided the regularization\nparameter is appropriately chosen. The convergence rate is actually independent\nto the choice of (smooth enough) inductive bias for both ridge and ridgeless\nregression. Surprisingly, our smoothness requirement recovered the condition\nfound in Bayesian setting and extend the conclusion to the minimum norm\ninterpolation estimators.", "AI": {"tldr": "The paper explores kernel ridge(less) regression for linear inverse problems governed by PDEs, showing PDE operators stabilize variance and enable benign overfitting. It highlights the role of Sobolev norms as implicit regularization and finds optimal convergence rates for various inductive biases.", "motivation": "To understand how PDE-governed inverse problems differ from standard regression, particularly in variance stabilization and overfitting behavior, and to analyze the impact of Sobolev norms as implicit regularization.", "method": "Develops an asymptotic Sobolev norm learning curve for kernel ridge(less) regression in linear inverse problems, examining variance stabilization and inductive biases.", "result": "PDE operators stabilize variance and enable benign overfitting. Optimal convergence rates are achievable for all considered inductive biases with proper regularization.", "conclusion": "The study extends insights from Bayesian settings to minimum norm interpolation, showing smoothness requirements align across methods and highlighting the unique behaviors of PDE-governed inverse problems."}}
{"id": "2408.16683", "pdf": "https://arxiv.org/pdf/2408.16683", "abs": "https://arxiv.org/abs/2408.16683", "authors": ["Gianmario Voria", "Giulia Sellitto", "Carmine Ferrara", "Francesco Abate", "Andrea De Lucia", "Filomena Ferrucci", "Gemma Catolino", "Fabio Palomba"], "title": "A Catalog of Fairness-Aware Practices in Machine Learning Engineering", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Machine learning's widespread adoption in decision-making processes raises\nconcerns about fairness, particularly regarding the treatment of sensitive\nfeatures and potential discrimination against minorities. The software\nengineering community has responded by developing fairness-oriented metrics,\nempirical studies, and approaches. However, there remains a gap in\nunderstanding and categorizing practices for engineering fairness throughout\nthe machine learning lifecycle. This paper presents a novel catalog of\npractices for addressing fairness in machine learning derived from a systematic\nmapping study. The study identifies and categorizes 28 practices from existing\nliterature, mapping them onto different stages of the machine learning\nlifecycle. From this catalog, the authors extract actionable items and\nimplications for both researchers and practitioners in software engineering.\nThis work aims to provide a comprehensive resource for integrating fairness\nconsiderations into the development and deployment of machine learning systems,\nenhancing their reliability, accountability, and credibility.", "AI": {"tldr": "A catalog of 28 fairness practices in machine learning, mapped to lifecycle stages, offers actionable insights for researchers and practitioners.", "motivation": "Addressing fairness gaps in machine learning decision-making to prevent discrimination and enhance system reliability.", "method": "Systematic mapping study to identify and categorize fairness practices from literature.", "result": "28 practices categorized across the machine learning lifecycle, with actionable implications.", "conclusion": "Provides a resource for integrating fairness into ML systems, improving accountability and credibility."}}
{"id": "2409.00035", "pdf": "https://arxiv.org/pdf/2409.00035", "abs": "https://arxiv.org/abs/2409.00035", "authors": ["Biplov Paneru", "Bipul Thapa", "Bishwash Paneru", "Sanjog Chhetri Sapkota"], "title": "EEG Right & Left Voluntary Hand Movement-based Virtual Brain-Computer Interfacing Keyboard Using Hybrid Deep Learning Approach", "categories": ["eess.SP", "cs.HC", "cs.LG", "cs.NE", "q-bio.NC"], "comment": "Please note: This is the preprint version of the manuscript. The\n  final peer-reviewed version has been published in Advanced Engineering\n  Informatics, Volume 65, Part D, 2025, and is available at:\n  https://doi.org/10.1016/j.aei.2025.103304 Please cite the published journal\n  version for referencing this work", "summary": "Brain-machine interfaces (BMIs), particularly those based on\nelectroencephalography (EEG), offer promising solutions for assisting\nindividuals with motor disabilities. However, challenges in reliably\ninterpreting EEG signals for specific tasks, such as simulating keystrokes,\npersist due to the complexity and variability of brain activity. Current\nEEG-based BMIs face limitations in adaptability, usability, and robustness,\nespecially in applications like virtual keyboards, as traditional\nmachine-learning models struggle to handle high-dimensional EEG data\neffectively. To address these gaps, we developed an EEG-based BMI system\ncapable of accurately identifying voluntary keystrokes, specifically leveraging\nright and left voluntary hand movements. Using a publicly available EEG\ndataset, the signals were pre-processed with band-pass filtering, segmented\ninto 22-electrode arrays, and refined into event-related potential (ERP)\nwindows, resulting in a 19x200 feature array categorized into three classes:\nresting state (0), 'd' key press (1), and 'l' key press (2). Our approach\nemploys a hybrid neural network architecture with BiGRU-Attention as the\nproposed model for interpreting EEG signals, achieving superior test accuracy\nof 90% and a mean accuracy of 91% in 10-fold stratified cross-validation. This\nperformance outperforms traditional ML methods like Support Vector Machines\n(SVMs) and Naive Bayes, as well as advanced architectures such as Transformers,\nCNN-Transformer hybrids, and EEGNet. Finally, the BiGRU-Attention model is\nintegrated into a real-time graphical user interface (GUI) to simulate and\npredict keystrokes from brain activity. Our work demonstrates how deep learning\ncan advance EEG-based BMI systems by addressing the challenges of signal\ninterpretation and classification.", "AI": {"tldr": "The paper presents an EEG-based BMI system using a BiGRU-Attention model to accurately identify keystrokes from brain activity, achieving 90% test accuracy.", "motivation": "Current EEG-based BMIs struggle with adaptability and robustness in tasks like simulating keystrokes due to the complexity of EEG signals.", "method": "The system pre-processes EEG data, segments it into ERP windows, and uses a hybrid BiGRU-Attention neural network for classification.", "result": "The model achieves 90% test accuracy and 91% mean accuracy in cross-validation, outperforming traditional and advanced methods.", "conclusion": "Deep learning, specifically the BiGRU-Attention model, effectively advances EEG-based BMIs by improving signal interpretation and classification."}}
{"id": "2409.05598", "pdf": "https://arxiv.org/pdf/2409.05598", "abs": "https://arxiv.org/abs/2409.05598", "authors": ["Tomoyuki Obuchi", "Toshiyuki Tanaka"], "title": "When resampling/reweighting improves feature learning in imbalanced classification?: A toy-model study", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.IT", "cs.LG", "math.IT"], "comment": "33 pages, 14 figures", "summary": "A toy model of binary classification is studied with the aim of clarifying\nthe class-wise resampling/reweighting effect on the feature learning\nperformance under the presence of class imbalance. In the analysis, a\nhigh-dimensional limit of the input space is taken while keeping the ratio of\nthe dataset size against the input dimension finite and the non-rigorous\nreplica method from statistical mechanics is employed. The result shows that\nthere exists a case in which the no resampling/reweighting situation gives the\nbest feature learning performance irrespectively of the choice of losses or\nclassifiers, supporting recent findings in Cao et al. (2019); Kang et al.\n(2019). It is also revealed that the key of the result is the symmetry of the\nloss and the problem setting. Inspired by this, we propose a further simplified\nmodel exhibiting the same property in the multiclass setting. These clarify\nwhen the class-wise resampling/reweighting becomes effective in imbalanced\nclassification.", "AI": {"tldr": "The paper analyzes the effect of class-wise resampling/reweighting on feature learning in imbalanced binary classification, revealing cases where no resampling/reweighting performs best, supported by symmetry in the problem setting.", "motivation": "To clarify the impact of class-wise resampling/reweighting on feature learning in imbalanced classification and understand when such techniques are effective.", "method": "Uses a high-dimensional toy model with finite dataset-to-dimension ratio and applies the non-rigorous replica method from statistical mechanics.", "result": "Finds cases where no resampling/reweighting yields the best feature learning performance, regardless of loss or classifier choice, due to symmetry in the problem setting.", "conclusion": "Proposes a simplified multiclass model to generalize findings, clarifying conditions under which resampling/reweighting is effective in imbalanced classification."}}
{"id": "2410.21635", "pdf": "https://arxiv.org/pdf/2410.21635", "abs": "https://arxiv.org/abs/2410.21635", "authors": ["Andrew Zhao"], "title": "Learning the structure of any Hamiltonian from minimal assumptions", "categories": ["quant-ph", "cs.DS", "cs.LG"], "comment": "45 pages", "summary": "We study the problem of learning an unknown quantum many-body Hamiltonian $H$\nfrom black-box queries to its time evolution $e^{-\\mathrm{i} H t}$. Prior\nproposals for solving this task either impose some assumptions on $H$, such as\nits interaction structure or locality, or otherwise use an exponential amount\nof computational postprocessing. In this paper, we present algorithms to learn\nany $n$-qubit Hamiltonian, which do not need to know the Hamiltonian terms in\nadvance, nor are they restricted to local interactions. Our algorithms are\nefficient as long as the number of terms $m$ is polynomially bounded in the\nsystem size $n$. We consider two models of control over the time evolution:~the\nfirst has access to time reversal ($t < 0$), enabling an algorithm that outputs\nan $\\epsilon$-accurate classical description of $H$ after querying its dynamics\nfor a total of $\\widetilde{\\mathcal{O}}(m/\\epsilon)$ evolution time. The second\naccess model is more conventional, allowing only forward-time evolutions;~our\nalgorithm requires $\\widetilde{\\mathcal{O}}(\\|H\\|^3/\\epsilon^4)$ evolution time\nin this setting. Central to our results is the recently introduced concept of a\npseudo-Choi state of $H$. We extend the utility of this learning resource by\nshowing how to use it to learn the Fourier spectrum of $H$, how to achieve\nnearly Heisenberg-limited scaling with it, and how to prepare it even under our\nmore restricted access models.", "AI": {"tldr": "The paper presents efficient algorithms for learning unknown quantum many-body Hamiltonians without prior assumptions on structure or locality, using black-box queries to time evolution.", "motivation": "Prior methods either impose restrictive assumptions on the Hamiltonian or require exponential computational resources, limiting their applicability.", "method": "The algorithms leverage pseudo-Choi states and Fourier spectrum analysis, operating efficiently under polynomially bounded terms. Two access models (time reversal and forward-time) are considered.", "result": "The algorithms achieve accurate Hamiltonian descriptions with polynomial evolution time: O\u0303(m/\u03b5) for time reversal and O\u0303(\u2016H\u2016\u00b3/\u03b5\u2074) for forward-time.", "conclusion": "The work extends the utility of pseudo-Choi states, enabling efficient Hamiltonian learning under less restrictive conditions and nearly Heisenberg-limited scaling."}}
{"id": "2411.10258", "pdf": "https://arxiv.org/pdf/2411.10258", "abs": "https://arxiv.org/abs/2411.10258", "authors": ["Qi Liu", "Yanchen Liu", "Ruifeng Li", "Chenhong Cao", "Yufeng Li", "Xingyu Li", "Peng Wang", "Runhan Feng", "Shiyang Bu"], "title": "MDHP-Net: Detecting an Emerging Time-exciting Threat in IVN", "categories": ["cs.CR", "cs.LG", "cs.NI"], "comment": "Previously this version appeared as arXiv:2504.11867 which was\n  submitted as a new work by accident", "summary": "The integration of intelligent and connected technologies in modern vehicles,\nwhile offering enhanced functionalities through Electronic Control Unit (ECU)\nand interfaces like OBD-II and telematics, also exposes the vehicle's\nin-vehicle network (IVN) to potential cyberattacks. Unlike prior work, we\nidentify a new time-exciting threat model against IVN. These attacks inject\nmalicious messages that exhibit a time-exciting effect, gradually manipulating\nnetwork traffic to disrupt vehicle operations and compromise safety-critical\nfunctions. We systematically analyze the characteristics of the threat:\ndynamism, time-exciting impact, and low prior knowledge dependency. To validate\nits practicality, we replicate the attack on a real Advanced Driver Assistance\nSystem via Controller Area Network (CAN), exploiting Unified Diagnostic Service\nvulnerabilities and proposing four attack strategies. While CAN's integrity\nchecks mitigate attacks, Ethernet migration (e.g., DoIP/SOME/IP) introduces new\nsurfaces. We further investigate the feasibility of time-exciting threat under\nSOME/IP. To detect time-exciting threat, we introduce MDHP-Net, leveraging\nMulti-Dimentional Hawkes Process (MDHP) and temporal and message-wise feature\nextracting structures. Meanwhile, to estimate MDHP parameters, we developed the\nfirst GPU-optimized gradient descent solver for MDHP (MDHP-GDS). These modules\nsignificantly improves the detection rate under time-exciting attacks in\nmulti-ECU IVN system. To address data scarcity, we release STEIA9, the first\nopen-source dataset for time-exciting attacks, covering 9 Ethernet-based attack\nscenarios. Extensive experiments on STEIA9 (9 attack scenarios) show MDHP-Net\noutperforms 3 baselines, confirming attack feasibility and detection efficacy.", "AI": {"tldr": "The paper introduces a time-exciting cyberattack model targeting in-vehicle networks (IVNs), validates its feasibility, and proposes MDHP-Net for detection, supported by a new dataset (STEIA9).", "motivation": "Modern vehicles' reliance on intelligent technologies exposes IVNs to cyber threats, necessitating new threat models and detection methods.", "method": "The study identifies a time-exciting attack model, replicates it on a real ADAS via CAN, and introduces MDHP-Net (using MDHP and GPU-optimized solver) for detection.", "result": "MDHP-Net outperforms baselines in detecting time-exciting attacks, validated by the STEIA9 dataset.", "conclusion": "The work highlights the feasibility of time-exciting attacks and demonstrates MDHP-Net's effectiveness in securing IVNs."}}
{"id": "2412.07959", "pdf": "https://arxiv.org/pdf/2412.07959", "abs": "https://arxiv.org/abs/2412.07959", "authors": ["Lorenzo Vianello", "Cl\u00e9ment Lhoste", "Emek Bar\u0131\u015f K\u00fc\u00e7\u00fcktabak", "Matthew Short", "Levi Hargrove", "Jose L. Pons"], "title": "Deep-Learning Control of Lower-Limb Exoskeletons via simplified Therapist Input", "categories": ["cs.RO", "cs.LG"], "comment": "Accepted to the INTERNATIONAL CONSORTIUM FOR REHABILITATION ROBOTICS\n  2025", "summary": "Partial-assistance exoskeletons hold significant potential for gait\nrehabilitation by promoting active participation during (re)learning of\nnormative walking patterns. Typically, the control of interaction torques in\npartial-assistance exoskeletons relies on a hierarchical control structure.\nThese approaches require extensive calibration due to the complexity of the\ncontroller and user-specific parameter tuning, especially for activities like\nstair or ramp navigation. To address the limitations of hierarchical control in\nexoskeletons, this work proposes a three-step, data-driven approach: (1) using\nrecent sensor data to probabilistically infer locomotion states (landing step\nlength, landing step height, walking velocity, step clearance, gait phase), (2)\nallowing therapists to modify these features via a user interface, and (3)\nusing the adjusted locomotion features to predict the desired joint posture and\nmodel stiffness in a spring-damper system based on prediction uncertainty. We\nevaluated the proposed approach with two healthy participants engaging in\ntreadmill walking and stair ascent and descent at varying speeds, with and\nwithout external modification of the gait features through a user interface.\nResults showed a variation in kinematics according to the gait characteristics\nand a negative interaction power suggesting exoskeleton assistance across the\ndifferent conditions.", "AI": {"tldr": "A data-driven approach for partial-assistance exoskeletons improves gait rehabilitation by inferring locomotion states, allowing therapist adjustments, and predicting joint posture and stiffness.", "motivation": "To overcome the limitations of hierarchical control in exoskeletons, which require extensive calibration and user-specific tuning, especially for complex activities like stair navigation.", "method": "A three-step approach: (1) probabilistic inference of locomotion states, (2) therapist modification via a user interface, and (3) prediction of joint posture and stiffness based on adjusted features.", "result": "Evaluation with healthy participants showed adaptable kinematics and negative interaction power, indicating effective exoskeleton assistance.", "conclusion": "The proposed data-driven method offers a flexible and effective alternative to hierarchical control for gait rehabilitation."}}
{"id": "2501.05170", "pdf": "https://arxiv.org/pdf/2501.05170", "abs": "https://arxiv.org/abs/2501.05170", "authors": ["Robin Burke", "Gediminas Adomavicius", "Toine Bogers", "Tommaso Di Noia", "Dominik Kowald", "Julia Neidhardt", "\u00d6zlem \u00d6zg\u00f6bek", "Maria Soledad Pera", "Nava Tintarev", "J\u00fcrgen Ziegler"], "title": "De-centering the (Traditional) User: Multistakeholder Evaluation of Recommender Systems", "categories": ["cs.IR", "cs.LG"], "comment": "Preprint in revision at Elsevier, \"Re-centering the User in\n  Recommender System Research\" special issue of the International Journal of\n  Human-Computer Studies (IJHCS)", "summary": "Multistakeholder recommender systems are those that account for the impacts\nand preferences of multiple groups of individuals, not just the end users\nreceiving recommendations. Due to their complexity, these systems cannot be\nevaluated strictly by the overall utility of a single stakeholder, as is often\nthe case of more mainstream recommender system applications. In this article,\nwe focus our discussion on the challenges of multistakeholder evaluation of\nrecommender systems. We bring attention to the different aspects involved --\nfrom the range of stakeholders involved (including but not limited to providers\nand consumers) to the values and specific goals of each relevant stakeholder.\nWe discuss how to move from theoretical principles to practical implementation,\nproviding specific use case examples. Finally, we outline open research\ndirections for the RecSys community to explore. We aim to provide guidance to\nresearchers and practitioners about incorporating these complex and\ndomain-dependent issues of evaluation in the course of designing, developing,\nand researching applications with multistakeholder aspects.", "AI": {"tldr": "The paper discusses the challenges of evaluating multistakeholder recommender systems, emphasizing the need to consider multiple groups' impacts and preferences, not just end users.", "motivation": "Traditional recommender systems focus on single-stakeholder utility, but multistakeholder systems require broader evaluation due to their complexity and diverse stakeholder goals.", "method": "The article examines stakeholder diversity, values, and goals, and provides practical implementation examples.", "result": "It highlights the gap between theoretical principles and practical evaluation, offering use cases and open research directions.", "conclusion": "The paper aims to guide researchers and practitioners in addressing multistakeholder evaluation complexities in recommender system design and development."}}
{"id": "2502.12804", "pdf": "https://arxiv.org/pdf/2502.12804", "abs": "https://arxiv.org/abs/2502.12804", "authors": ["Michael Doherty", "Robin Matzner", "Rasoul Sadeghi", "Polina Bayvel", "Alejandra Beghelli"], "title": "Reinforcement Learning for Dynamic Resource Allocation in Optical Networks: Hype or Hope?", "categories": ["cs.NI", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "The application of reinforcement learning (RL) to dynamic resource allocation\nin optical networks has been the focus of intense research activity in recent\nyears, with almost 100 peer-reviewed papers. We present a review of progress in\nthe field, and identify significant gaps in benchmarking practices and\nreproducibility. To determine the strongest benchmark algorithms, we\nsystematically evaluate several heuristics across diverse network topologies.\nWe find that path count and sort criteria for path selection significantly\naffect the benchmark performance. We meticulously recreate the problems from\nfive landmark papers and apply the improved benchmarks. Our comparisons\ndemonstrate that simple heuristics consistently match or outperform the\npublished RL solutions, often with an order of magnitude lower blocking\nprobability. Furthermore, we present empirical lower bounds on network blocking\nusing a novel defragmentation-based method, revealing that potential\nimprovements over the benchmark heuristics are limited to 19-36% increased\ntraffic load for the same blocking performance in our examples. We make our\nsimulation framework and results publicly available to promote reproducible\nresearch and standardized evaluation https://doi.org/10.5281/zenodo.12594495.", "AI": {"tldr": "A review of RL in optical networks reveals gaps in benchmarking and reproducibility. Simple heuristics often outperform RL solutions, with lower blocking probability. Empirical bounds show limited potential for improvement over benchmarks.", "motivation": "To address gaps in benchmarking practices and reproducibility in RL applications for dynamic resource allocation in optical networks.", "method": "Systematic evaluation of heuristics across diverse topologies, recreation of problems from landmark papers, and application of improved benchmarks.", "result": "Simple heuristics match or outperform RL solutions, with significantly lower blocking probability. Empirical bounds indicate limited improvement potential over benchmarks.", "conclusion": "Standardized evaluation and reproducible research are needed, as simple heuristics often surpass RL in performance."}}
{"id": "2503.20507", "pdf": "https://arxiv.org/pdf/2503.20507", "abs": "https://arxiv.org/abs/2503.20507", "authors": ["Rakesh Nadig", "Vamanan Arulchelvan", "Rahul Bera", "Taha Shahroodi", "Gagandeep Singh", "Andreas Kakolyris", "Mohammad Sadrosadati", "Jisung Park", "Onur Mutlu"], "title": "Harmonia: A Multi-Agent Reinforcement Learning Approach to Data Placement and Migration in Hybrid Storage Systems", "categories": ["cs.AR", "cs.DC", "cs.LG"], "comment": null, "summary": "Hybrid storage systems (HSS) combine multiple storage devices with diverse\ncharacteristics to achieve high performance and capacity at low cost. The\nperformance of an HSS highly depends on the effectiveness of two key policies:\n(1) the data-placement policy, which determines the best-fit storage device for\nincoming data, and (2) the data-migration policy, which rearranges stored data\nacross the devices to sustain high HSS performance. Prior works focus on\nimproving only data placement or only data migration in HSS, which leads to\nrelatively low HSS performance. Unfortunately, no prior work tries to optimize\nboth policies together. Our goal is to design a holistic data-management\ntechnique that optimizes both data-placement and data-migration policies to\nfully exploit the potential of an HSS, and thus significantly improve system\nperformance. We demonstrate the need for multiple reinforcement learning (RL)\nagents to accomplish our goal. We propose Harmonia, a multi-agent RL-based\ndata-management technique that employs two lightweight autonomous RL agents, a\ndata-placement agent and a data-migration agent, which adapt their policies for\nthe current workload and HSS configuration, and coordinate with each other to\nimprove overall HSS performance. We evaluate Harmonia on a real HSS with up to\nfour heterogeneous and diverse storage devices. Our evaluation using 17\ndata-intensive workloads on performance-optimized (cost-optimized) HSS with two\nstorage devices shows that, on average, Harmonia outperforms the\nbest-performing prior approach by 49.5% (31.7%). On an HSS with three (four)\ndevices, Harmonia outperforms the best-performing prior work by 37.0% (42.0%).\nHarmonia's performance benefits come with low latency (240ns for inference) and\nstorage overheads (206 KiB in DRAM for both RL agents together). We will\nopen-source Harmonia's implementation to aid future research on HSS.", "AI": {"tldr": "Harmonia is a multi-agent RL-based technique optimizing both data-placement and data-migration policies in hybrid storage systems (HSS), outperforming prior works by up to 49.5%.", "motivation": "Prior works optimize only one policy (placement or migration) in HSS, leading to suboptimal performance. A holistic approach is needed.", "method": "Uses two RL agents (placement and migration) that adapt and coordinate to optimize HSS performance.", "result": "Outperforms best prior approaches by 31.7%-49.5% on 2-4 device HSS, with low latency (240ns) and overhead (206 KiB).", "conclusion": "Harmonia demonstrates significant performance gains in HSS by jointly optimizing placement and migration, with minimal overhead."}}
{"id": "2504.07481", "pdf": "https://arxiv.org/pdf/2504.07481", "abs": "https://arxiv.org/abs/2504.07481", "authors": ["Tian Xie", "Menghui Jiang", "Huanfeng Shen", "Huifang Li", "Chao Zeng", "Jun Ma", "Guanhao Zhang", "Liangpei Zhang"], "title": "A Mechanism-Learning Deeply Coupled Model for Remote Sensing Retrieval of Global Land Surface Temperature", "categories": ["physics.ao-ph", "cs.LG"], "comment": null, "summary": "Land surface temperature (LST) retrieval from remote sensing data is pivotal\nfor analyzing climate processes and surface energy budgets. However, LST\nretrieval is an ill-posed inverse problem, which becomes particularly severe\nwhen only a single band is available. In this paper, we propose a deeply\ncoupled framework integrating mechanistic modeling and machine learning to\nenhance the accuracy and generalizability of single-channel LST retrieval.\nTraining samples are generated using a physically-based radiative transfer\nmodel and a global collection of 5810 atmospheric profiles. A physics-informed\nmachine learning framework is proposed to systematically incorporate the first\nprinciples from classical physical inversion models into the learning workflow,\nwith optimization constrained by radiative transfer equations. Global\nvalidation demonstrated a 30% reduction in root-mean-square error versus\nstandalone methods. Under extreme humidity, the mean absolute error decreased\nfrom 4.87 K to 2.29 K (53% improvement). Continental-scale tests across five\ncontinents confirmed the superior generalizability of this model.", "AI": {"tldr": "A deeply coupled framework combining mechanistic modeling and machine learning improves single-channel LST retrieval accuracy and generalizability, validated globally with significant error reductions.", "motivation": "LST retrieval from remote sensing data is challenging, especially with single-band data, due to its ill-posed nature.", "method": "A physics-informed machine learning framework integrates radiative transfer models and atmospheric profiles, optimizing with radiative transfer equations.", "result": "Global validation showed a 30% RMSE reduction; under extreme humidity, MAE improved by 53% (4.87 K to 2.29 K). Continental tests confirmed superior generalizability.", "conclusion": "The proposed framework significantly enhances LST retrieval accuracy and generalizability, outperforming standalone methods."}}
{"id": "2504.08989", "pdf": "https://arxiv.org/pdf/2504.08989", "abs": "https://arxiv.org/abs/2504.08989", "authors": ["Han Liao", "Shuaishuai Zu"], "title": "RouterKT: Mixture-of-Experts for Knowledge Tracing", "categories": ["cs.CY", "cs.IR", "cs.LG"], "comment": "10 pages", "summary": "Knowledge Tracing (KT) is a fundamental task in Intelligent Tutoring Systems\n(ITS), which aims to model the dynamic knowledge states of students based on\ntheir interaction histories. However, existing KT models often rely on a global\nforgetting decay mechanism for capturing learning patterns, assuming that\nstudents' performance is predominantly influenced by their most recent\ninteractions. Such approaches fail to account for the diverse and complex\nlearning patterns arising from individual differences and varying learning\nstages. To address this limitation, we propose RouterKT, a novel\nMixture-of-Experts (MoE) architecture designed to capture heterogeneous\nlearning patterns by enabling experts to specialize in different patterns\nwithout any handcrafted learning pattern bias such as forgetting decay.\nSpecifically, RouterKT introduces a \\textbf{person-wise routing mechanism} to\neffectively model individual-specific learning behaviors and employs\n\\textbf{multi-heads as experts} to enhance the modeling of complex and diverse\npatterns. Comprehensive experiments on ten benchmark datasets demonstrate that\nRouterKT exhibits significant flexibility and improves the performance of\nvarious KT backbone models, with a maximum average AUC improvement of 3.29\\%\nacross different backbones and datasets, outperforming other state-of-the-art\nmodels. Moreover, RouterKT demonstrates consistently superior inference\nefficiency compared to existing approaches based on handcrafted learning\npattern bias, highlighting its usability for real-world educational\napplications. The source code is available at\nhttps://github.com/ringotc/RouterKT.git.", "AI": {"tldr": "RouterKT introduces a Mixture-of-Experts architecture with person-wise routing and multi-head experts to model diverse learning patterns, outperforming existing KT models with a 3.29% AUC improvement.", "motivation": "Existing KT models assume uniform forgetting decay, ignoring individual learning differences and stages. RouterKT addresses this by capturing heterogeneous learning patterns.", "method": "RouterKT uses a Mixture-of-Experts architecture with person-wise routing and multi-head experts to specialize in diverse learning patterns without handcrafted biases.", "result": "RouterKT improves performance by up to 3.29% AUC across datasets and backbones, with superior inference efficiency.", "conclusion": "RouterKT is a flexible, efficient solution for modeling diverse learning behaviors in KT, suitable for real-world educational applications."}}
{"id": "2504.13397", "pdf": "https://arxiv.org/pdf/2504.13397", "abs": "https://arxiv.org/abs/2504.13397", "authors": ["Yu Gan", "Mohadeseh Azari", "Nitish Kumar Chandra", "Xin Jin", "Jinglei Cheng", "Kaushik P. Seshadreesan", "Junyu Liu"], "title": "Quantum repeaters enhanced by vacuum beam guides", "categories": ["quant-ph", "cs.DC", "cs.LG", "cs.NI"], "comment": "10 pages", "summary": "The development of large-scale quantum communication networks faces critical\nchallenges due to photon loss and decoherence in optical fiber channels. These\nfundamentally limit transmission distances and demand dense networks of\nrepeater stations. This work investigates using vacuum beam guides (VBGs)-a\npromising ultra-low-loss transmission platform-as an alternative to traditional\nfiber links. By incorporating VBGs into repeater-based architectures, we\ndemonstrate that the inter-repeater spacing can be substantially extended,\nresulting in fewer required nodes and significantly reducing hardware and\noperational complexity. We perform a cost-function analysis to quantify\nperformance trade-offs across first, second, and third-generation repeaters.\nOur results show that first-generation repeaters reduce costs dramatically by\neliminating entanglement purification. Third-generation repeaters benefit from\nimproved link transmission success, which is crucial for quantum error\ncorrection. In contrast, second-generation repeaters exhibit a more nuanced\nresponse; although transmission loss is reduced, their performance remains\nprimarily limited by logical gate errors rather than channel loss. These\nfindings highlight that while all repeater generations benefit from reduced\nphoton loss, the magnitude of improvement depends critically on the underlying\nerror mechanisms. Vacuum beam guides thus emerge as a powerful enabler for\nscalable, high-performance quantum networks, particularly in conjunction with\nnear-term quantum hardware capabilities.", "AI": {"tldr": "Using vacuum beam guides (VBGs) in quantum networks reduces photon loss, extends repeater spacing, and lowers costs, with varying benefits across repeater generations.", "motivation": "Addressing photon loss and decoherence in optical fiber channels to improve quantum communication networks.", "method": "Incorporating VBGs into repeater architectures and analyzing cost-function trade-offs across repeater generations.", "result": "First-gen repeaters cut costs by eliminating entanglement purification; third-gen repeaters improve link transmission. Second-gen repeaters are limited by gate errors.", "conclusion": "VBGs enable scalable, high-performance quantum networks, especially with near-term hardware."}}
